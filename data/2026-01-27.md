<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 122]
- [cs.IR](#cs.IR) [Total: 23]
- [cs.LG](#cs.LG) [Total: 114]
- [cs.CY](#cs.CY) [Total: 33]
- [cs.AI](#cs.AI) [Total: 45]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility](https://arxiv.org/abs/2601.17027)
*Honglin Lin,Chonghan Qin,Zheng Liu,Qizhi Pei,Yu Li,Zhanping Zhong,Xin Gao,Yanfeng Wang,Conghui He,Lijun Wu*

Main category: cs.CV

TL;DR: 该论文研究了科学图像合成的挑战，提出了ImgCoder逻辑驱动框架和SciGenBench评估基准，展示了高质量科学图像合成对提升多模态推理能力的潜力。


<details>
  <summary>Details</summary>
Motivation: 虽然合成数据在文本领域的科学推理中已被证明有效，但多模态推理仍受限于合成科学严谨图像的困难。现有的文本到图像模型通常产生视觉上合理但科学上不正确的输出，导致视觉-逻辑分歧，限制了其在下游推理中的价值。

Method: 1. 系统研究科学图像合成的生成范式、评估和下游应用；2. 分析基于像素的直接生成和程序化合成；3. 提出ImgCoder逻辑驱动框架，采用"理解-规划-编码"工作流程提高结构精度；4. 引入SciGenBench评估基准，基于信息效用和逻辑有效性评估生成图像。

Result: 评估揭示了基于像素模型的系统性失败模式，并突出了表达力与精度之间的基本权衡。在严格验证的合成科学图像上微调大型多模态模型能带来一致的推理增益，显示出类似于文本领域的潜在扩展趋势。

Conclusion: 高保真科学图像合成是解锁大规模多模态推理能力的可行路径，验证了合成科学图像在提升多模态模型推理能力方面的有效性。

Abstract: While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit "understand - plan - code" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.

</details>


### [2] [Data-Efficient Meningioma Segmentation via Implicit Spatiotemporal Mixing and Sim2Real Semantic Injection](https://arxiv.org/abs/2601.17031)
*Yunhao Xu,Fuquan Zong,Yexuan Xing,Chulong Zhang,Guang Yang,Shilong Yang,Xiaokun Liang,Juan Yu*

Main category: cs.CV

TL;DR: 提出一种双增强框架，结合空间流形扩展和语义对象注入，通过隐式神经表示建模连续速度场，在线性混合变形场中生成解剖学合理的变异，并通过Sim2Real病灶注入模块将病灶纹理移植到健康背景中，显著提升有限标注下的医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割性能越来越取决于数据利用效率而非原始数据量。对于脑膜瘤等复杂病理的准确分割，需要模型充分利用有限高质量标注中的潜在信息。为了最大化现有数据集的价值，需要开发更高效的数据增强方法。

Method: 提出双增强框架：1) 空间流形扩展：利用隐式神经表示建模连续速度场，在线性混合的变形场中进行插值，从少量锚点生成解剖学合理的结构变异；2) Sim2Real病灶注入：构建高保真模拟域，将病灶纹理移植到健康解剖背景中，弥合合成增强与真实病理之间的差距。

Result: 在混合数据集上的综合实验表明，该框架显著提升了nnU-Net和U-Mamba等先进模型的数据效率和鲁棒性，为有限标注预算下的高性能医学图像分析提供了有效策略。

Conclusion: 通过空间流形扩展和语义对象注入的双重增强框架，能够有效利用有限标注数据，生成解剖学合理的变异和真实感的病理图像，显著提升医学图像分割的数据效率和模型性能。

Abstract: The performance of medical image segmentation is increasingly defined by the efficiency of data utilization rather than merely the volume of raw data. Accurate segmentation, particularly for complex pathologies like meningiomas, demands that models fully exploit the latent information within limited high-quality annotations. To maximize the value of existing datasets, we propose a novel dual-augmentation framework that synergistically integrates spatial manifold expansion and semantic object injection. Specifically, we leverage Implicit Neural Representations (INR) to model continuous velocity fields. Unlike previous methods, we perform linear mixing on the integrated deformation fields, enabling the efficient generation of anatomically plausible variations by interpolating within the deformation space. This approach allows for the extensive exploration of structural diversity from a small set of anchors. Furthermore, we introduce a Sim2Real lesion injection module. This module constructs a high-fidelity simulation domain by transplanting lesion textures into healthy anatomical backgrounds, effectively bridging the gap between synthetic augmentation and real-world pathology. Comprehensive experiments on a hybrid dataset demonstrate that our framework significantly enhances the data efficiency and robustness of state-of-the-art models, including nnU-Net and U-Mamba, offering a potent strategy for high-performance medical image analysis with limited annotation budgets.

</details>


### [3] [Diagnosis Support of Sickle Cell Anemia by Classifying Red Blood Cell Shape in Peripheral Blood Images](https://arxiv.org/abs/2601.17032)
*Wilkie Delgado-Font,Miriela Escobedo-Nicot,Manuel González-Hidalgo,Silena Herold-Garcia,Antoni Jaume-i-Capó,Arnau Mir*

Main category: cs.CV

TL;DR: 提出基于外周血涂片图像分析的自动化红细胞分类方法，用于镰状细胞贫血诊断


<details>
  <summary>Details</summary>
Motivation: 传统显微镜观察红细胞变形耗时且主观误差高，需要自动化方法来提高镰状细胞贫血的诊断效率和准确性

Method: 使用Chan-Vese主动轮廓模型分割图像中的红细胞，然后基于圆形形状因子(CSF)和椭圆形形状因子(ESF)对红细胞进行分类（正常、细长或其他变形），并对簇中部分遮挡的细胞进行椭圆调整

Result: 方法在实验中表现优于现有技术，F-measure值达到0.97（正常细胞）和0.95（细长细胞），多项多类性能指标表现优异

Conclusion: 该方法适合用于镰状细胞贫血的临床治疗和诊断支持，能够提高诊断效率和准确性

Abstract: Red blood cell (RBC) deformation is the consequence of several diseases, including sickle cell anemia, which causes recurring episodes of pain and severe pronounced anemia. Monitoring patients with these diseases involves the observation of peripheral blood samples under a microscope, a time-consuming procedure. Moreover, a specialist is required to perform this technique, and owing to the subjective nature of the observation of isolated RBCs, the error rate is high. In this paper, we propose an automated method for differentially enumerating RBCs that uses peripheral blood smear image analysis. In this method, the objects of interest in the image are segmented using a Chan-Vese active contour model. An analysis is then performed to classify the RBCs, also called erythrocytes, as normal or elongated or having other deformations, using the basic shape analysis descriptors: circular shape factor (CSF) and elliptical shape factor (ESF). To analyze cells that become partially occluded in a cluster during sample preparation, an elliptical adjustment is performed to allow the analysis of erythrocytes with discoidal and elongated shapes. The images of patient blood samples used in the study were acquired by a clinical laboratory specialist in the Special Hematology Department of the ``Dr. Juan Bruno Zayas'' General Hospital in Santiago de Cuba. A comparison of the results obtained by the proposed method in our experiments with those obtained by some state-of-the-art methods showed that the proposed method is superior for the diagnosis of sickle cell anemia. This superiority is achieved for evidenced by the obtained F-measure value (0.97 for normal cells and 0.95 for elongated ones) and several overall multiclass performance measures. The results achieved by the proposed method are suitable for the purpose of clinical treatment and diagnostic support of sickle cell anemia.

</details>


### [4] [AMVICC: A Novel Benchmark for Cross-Modal Failure Mode Profiling for VLMs and IGMs](https://arxiv.org/abs/2601.17037)
*Aahana Basappa,Pranay Goel,Anusri Karra,Anish Karra,Asa Gilmore,Kevin Zhu*

Main category: cs.CV

TL;DR: 该研究创建了AMVICC基准测试，系统评估多模态大语言模型和图像生成模型在视觉推理任务中的失败模式，发现模型在对象方向、数量、空间关系等基本视觉概念上存在共同和特定的失败模式。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型和图像生成模型快速发展，但这些模型在理解和生成基本视觉概念（如对象方向、数量、空间关系）方面仍存在明显缺陷，缺乏对视觉推理能力的系统性评估。

Method: 通过将MMVP基准问题转化为显式和隐式提示，创建了AMVICC基准测试，在9个视觉推理类别中测试了11个MLLM和3个IGM，系统分析跨模态的失败模式。

Result: 结果显示失败模式在模型和模态间既有共享也有特异性；IGM在处理显式提示时尤其难以操控特定视觉组件，表明对细粒度视觉属性的控制能力较差。

Conclusion: 该研究为未来跨模态对齐研究奠定了基础，提供了一个框架来探究生成和解释失败是否源于共享的局限性，以指导统一视觉语言建模的改进。

Abstract: We investigated visual reasoning limitations of both multimodal large language models (MLLMs) and image generation models (IGMs) by creating a novel benchmark to systematically compare failure modes across image-to-text and text-to-image tasks, enabling cross-modal evaluation of visual understanding. Despite rapid growth in machine learning, vision language models (VLMs) still fail to understand or generate basic visual concepts such as object orientation, quantity, or spatial relationships, which highlighted gaps in elementary visual reasoning. By adapting MMVP benchmark questions into explicit and implicit prompts, we create \textit{AMVICC}, a novel benchmark for profiling failure modes across various modalities. After testing 11 MLLMs and 3 IGMs in nine categories of visual reasoning, our results show that failure modes are often shared between models and modalities, but certain failures are model-specific and modality-specific, and this can potentially be attributed to various factors. IGMs consistently struggled to manipulate specific visual components in response to prompts, especially in explicit prompts, suggesting poor control over fine-grained visual attributes. Our findings apply most directly to the evaluation of existing state-of-the-art models on structured visual reasoning tasks. This work lays the foundation for future cross-modal alignment studies, offering a framework to probe whether generation and interpretation failures stem from shared limitations to guide future improvements in unified vision-language modeling.

</details>


### [5] [MANGO: A Global Single-Date Paired Dataset for Mangrove Segmentation](https://arxiv.org/abs/2601.17039)
*Junhyuk Heo,Beomkyu Choi,Hyunjin Shin,Darongsae Kwon*

Main category: cs.CV

TL;DR: 研究者构建了MANGO全球红树林数据集，包含42,703个标注图像-掩码对，覆盖124个国家，旨在解决现有数据集在时效性、覆盖范围和可访问性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 红树林对气候变化减缓至关重要，但现有深度学习数据集存在以下问题：1) 仅提供年度地图产品而非单日期图像-掩码对；2) 局限于特定区域而非全球覆盖；3) 许多资源不向公众开放。这些限制阻碍了深度学习在红树林监测中的应用进展。

Method: 1) 收集2020年红树林区域的Sentinel-2影像；2) 采用目标检测驱动的方法，利用像素级坐标参考，选择与年度红树林掩码最佳匹配的单日期观测；3) 构建包含42,703个标注图像-掩码对的数据集，覆盖124个国家；4) 提供基于国家分离划分的多种语义分割架构基准测试。

Result: 成功创建了MANGO数据集，这是目前规模最大、覆盖最广的全球红树林数据集，包含42,703个高质量图像-掩码对，为全球红树林监测提供了可靠的数据基础。

Conclusion: MANGO数据集解决了现有红树林监测数据集的局限性，为可扩展、可靠的全球红树林监测建立了基础，将促进深度学习在红树林保护和气候变化减缓中的应用。

Abstract: Mangroves are critical for climate-change mitigation, requiring reliable monitoring for effective conservation. While deep learning has emerged as a powerful tool for mangrove detection, its progress is hindered by the limitations of existing datasets. In particular, many resources provide only annual map products without curated single-date image-mask pairs, limited to specific regions rather than global coverage, or remain inaccessible to the public. To address these challenges, we introduce MANGO, a large-scale global dataset comprising 42,703 labeled image-mask pairs across 124 countries. To construct this dataset, we retrieve all available Sentinel-2 imagery within the year 2020 for mangrove regions and select the best single-date observations that align with the mangrove annual mask. This selection is performed using a target detection-driven approach that leverages pixel-wise coordinate references to ensure adaptive and representative image-mask pairings. We also provide a benchmark across diverse semantic segmentation architectures under a country-disjoint split, establishing a foundation for scalable and reliable global mangrove monitoring.

</details>


### [6] [FP-THD: Full page transcription of historical documents](https://arxiv.org/abs/2601.17040)
*H Neji,J Nogueras-Iso,J Lacasta,MÁ Latre,FJ García-Marco*

Main category: cs.CV

TL;DR: 提出一个用于转录15-16世纪拉丁文历史文献的流程，通过布局分析模型提取文本行，再使用OCR模型进行识别，保留特殊字符和符号以维持历史文本的原始风格和意义。


<details>
  <summary>Details</summary>
Motivation: 15-16世纪拉丁文历史文献的转录面临特殊挑战，需要保留具有特定含义的字符和特殊符号，以确保历史文本保持其原始风格和意义。现有方法难以有效处理这些特殊特征。

Method: 提出一个转录流程：1) 使用布局分析模型分析历史文本图像并提取文本行；2) 将提取的文本行输入OCR模型生成完整的数字化页面。该方法扩展了现有的文本行识别方法，结合了布局分析模型。

Result: 该流程能有效处理页面并产生高效结果。在多个数据集上的评估表明，掩码自编码器能有效处理不同类型文本，包括手写体、印刷体和多语言文本。

Conclusion: 提出的流程能够有效转录15-16世纪拉丁文历史文献，保留特殊字符和符号，为历史文献的数字化处理提供了有效的解决方案。

Abstract: The transcription of historical documents written in Latin in XV and XVI centuries has special challenges as it must maintain the characters and special symbols that have distinct meanings to ensure that historical texts retain their original style and significance. This work proposes a pipeline for the transcription of historical documents preserving these special features. We propose to extend an existing text line recognition method with a layout analysis model. We analyze historical text images using a layout analysis model to extract text lines, which are then processed by an OCR model to generate a fully digitized page. We showed that our pipeline facilitates the processing of the page and produces an efficient result. We evaluated our approach on multiple datasets and demonstrate that the masked autoencoder effectively processes different types of text, including handwritten, printed and multi-language.

</details>


### [7] [Interpretable and Sparse Linear Attention with Decoupled Membership-Subspace Modeling via MCR2 Objective](https://arxiv.org/abs/2601.17042)
*Tianyuan Liu,Libin Hou,Linyuan Wang,Bin Yan*

Main category: cs.CV

TL;DR: 提出一种解耦的成员-子空间注意力机制(DMSA)，通过分离MCR2目标中的成员矩阵和子空间矩阵，从优化目标梯度展开得到可解释的稀疏线性注意力算子，在视觉任务中实现更高的编码效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有MCR2驱动的白盒transformer设计中，成员矩阵和子空间矩阵U之间的紧密耦合导致在错误的token投影下产生冗余编码，需要解耦这两者的功能关系以提高效率和可解释性。

Method: 提出解耦成员-子空间注意力(DMSA)：1)直接从输入学习成员矩阵；2)从全空间S推导稀疏子空间；3)通过优化MCR2目标的梯度展开得到可解释的稀疏线性注意力算子。将ToST中的注意力模块替换为DMSA形成DMST模型。

Result: 在ImageNet-1K数据集上，DMST比ToST在top-1准确率上提升1.08%-1.45%，实现更快的编码降维速率。相比传统Transformer架构，DMST展现出显著更高的计算效率和可解释性。

Conclusion: 通过解耦MCR2目标中的成员矩阵和子空间矩阵，提出的DMSA注意力机制为视觉建模提供了更高效、更准确且可解释的白盒Transformer解决方案，在计算效率和性能之间取得了更好的平衡。

Abstract: Maximal Coding Rate Reduction (MCR2)-driven white-box transformer, grounded in structured representation learning, unifies interpretability and efficiency, providing a reliable white-box solution for visual modeling. However, in existing designs, tight coupling between "membership matrix" and "subspace matrix U" in MCR2 causes redundant coding under incorrect token projection. To this end, we decouple the functional relationship between the "membership matrix" and "subspaces U" in the MCR2 objective and derive an interpretable sparse linear attention operator from unrolled gradient descent of the optimized objective. Specifically, we propose to directly learn the membership matrix from inputs and subsequently derive sparse subspaces from the fullspace S. Consequently, gradient unrolling of the optimized MCR2 objective yields an interpretable sparse linear attention operator: Decoupled Membership-Subspace Attention (DMSA). Experimental results on visual tasks show that simply replacing the attention module in Token Statistics Transformer (ToST) with DMSA (we refer to as DMST) not only achieves a faster coding reduction rate but also outperforms ToST by 1.08%-1.45% in top-1 accuracy on the ImageNet-1K dataset. Compared with vanilla Transformer architectures, DMST exhibits significantly higher computational efficiency and interpretability.

</details>


### [8] [A Contrastive Pre-trained Foundation Model for Deciphering Imaging Noisomics across Modalities](https://arxiv.org/abs/2601.17047)
*Yuanjie Gu,Yiqun Wang,Chaohui Yu,Ang Xuan,Fan Wang,Zhi Lu,Biqin Dong*

Main category: cs.CV

TL;DR: Noisomics框架通过对比预训练基础模型，将噪声从抑制对象转变为可解码的信息资源，仅需100个训练样本就能超越传统需要10万个样本的监督方法，实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 当前成像噪声表征方法需要大量监督数据且设备依赖性强，难以分离物理信号与算法伪影，将噪声视为干扰而非信息资源。

Method: 提出Noisomics框架，基于对比预训练基础模型，利用流形假设和合成噪声基因组，通过对比学习分离语义信号与随机扰动。

Result: 仅用100个训练样本就超越了传统需要10万个样本的监督基线，在12个跨域数据集上实现零样本泛化，估计误差降低63.8%，决定系数提高85.1%。

Conclusion: 将随机退化重新定义为重要的信息资源，无需设备校准即可实现精确成像诊断，为从消费摄影到深层组织显微镜的多个尺度应用提供支持。

Abstract: Characterizing imaging noise is notoriously data-intensive and device-dependent, as modern sensors entangle physical signals with complex algorithmic artifacts. Current paradigms struggle to disentangle these factors without massive supervised datasets, often reducing noise to mere interference rather than an information resource. Here, we introduce "Noisomics", a framework shifting the focus from suppression to systematic noise decoding via the Contrastive Pre-trained (CoP) Foundation Model. By leveraging the manifold hypothesis and synthetic noise genome, CoP employs contrastive learning to disentangle semantic signals from stochastic perturbations. Crucially, CoP breaks traditional deep learning scaling laws, achieving superior performance with only 100 training samples, outperforming supervised baselines trained on 100,000 samples, thereby reducing data and computational dependency by three orders of magnitude. Extensive benchmarking across 12 diverse out-of-domain datasets confirms its robust zero-shot generalization, demonstrating a 63.8% reduction in estimation error and an 85.1% improvement in the coefficient of determination compared to the conventional training strategy. We demonstrate CoP's utility across scales: from deciphering non-linear hardware-noise interplay in consumer photography to optimizing photon-efficient protocols for deep-tissue microscopy. By decoding noise as a multi-parametric footprint, our work redefines stochastic degradation as a vital information resource, empowering precise imaging diagnostics without prior device calibration.

</details>


### [9] [Summary of the Unusual Activity Recognition Challenge for Developmental Disability Support](https://arxiv.org/abs/2601.17049)
*Christina Garcia,Nhat Tan Le,Taihei Fujioka,Umang Dobhal,Milyun Ni'ma Shoumi,Thanh Nha Nguyen,Sozo Inoue*

Main category: cs.CV

TL;DR: ISAS 2025举办的"识别未见：基于姿态数据的异常行为识别"挑战赛，旨在通过非侵入式姿态数据自动识别发育障碍人士设施中的异常行为，吸引了40支团队参与，使用留一受试者交叉验证评估模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决发育障碍人士设施中异常行为自动识别的关键需求，使用非侵入式姿态估计数据，应对真实世界数据不平衡和时间不规则性挑战。

Method: 挑战赛基于从模拟场景视频中提取的骨骼关键点数据，采用留一受试者交叉验证策略确保主体无关泛化，使用宏观平均F1分数评估模型性能以应对类别不平衡。

Result: 40支团队参与并应用了从经典机器学习到深度学习架构的多种方法，结果显示在噪声多、低维数据中建模罕见、突发动作具有挑战性，需要捕捉时间和上下文细微差别。

Conclusion: 该挑战赛强调了在噪声低维数据中建模罕见行为的时间建模重要性，为医疗保健和行为监测等社会责任AI应用提供了有价值的见解。

Abstract: This paper presents an overview of the Recognize the Unseen: Unusual Behavior Recognition from Pose Data Challenge, hosted at ISAS 2025. The challenge aims to address the critical need for automated recognition of unusual behaviors in facilities for individuals with developmental disabilities using non-invasive pose estimation data. Participating teams were tasked with distinguishing between normal and unusual activities based on skeleton keypoints extracted from video recordings of simulated scenarios. The dataset reflects real-world imbalance and temporal irregularities in behavior, and the evaluation adopted a Leave-One-Subject-Out (LOSO) strategy to ensure subject-agnostic generalization. The challenge attracted broad participation from 40 teams applying diverse approaches ranging from classical machine learning to deep learning architectures. Submissions were assessed primarily using macro-averaged F1 scores to account for class imbalance. The results highlight the difficulty of modeling rare, abrupt actions in noisy, low-dimensional data, and emphasize the importance of capturing both temporal and contextual nuances in behavior modeling. Insights from this challenge may contribute to future developments in socially responsible AI applications for healthcare and behavior monitoring.

</details>


### [10] [Single-Pixel Vision-Language Model for Intrinsic Privacy-Preserving Behavioral Intelligence](https://arxiv.org/abs/2601.17050)
*Hongjun An,Yiliang Song,Jiawei Shao,Zhe Sun,Xuelong Li*

Main category: cs.CV

TL;DR: SP-VLM框架通过单像素传感和视觉语言模型集成，在保护隐私的同时实现异常行为检测，解决了隐私敏感环境中的监控难题。


<details>
  <summary>Details</summary>
Motivation: 在洗手间、更衣室等隐私敏感环境中，传统监控因隐私法规和伦理问题被禁止或限制，但欺凌、骚扰等有害社会互动又需要及时干预，这构成了监控与隐私保护的矛盾。

Method: 提出单像素视觉语言模型（SP-VLM）框架，通过低维单像素模态捕捉人体动态，结合视觉语言集成推断复杂行为模式，实现隐私保护设计。

Result: 单像素传感能有效抑制身份可识别性，使先进人脸识别系统在低于临界采样率时失效；同时SP-VLM能从严重降级的单像素观测中提取有意义的行为语义，实现异常检测、人数统计和活动理解。

Conclusion: 该研究找到了一个实用的采样率区间，既能提取行为智能，又能强有力地保护个人身份，为人权对齐的安全监控提供了可行路径，支持及时干预而不侵犯隐私敏感空间的隐私。

Abstract: Adverse social interactions, such as bullying, harassment, and other illicit activities, pose significant threats to individual well-being and public safety, leaving profound impacts on physical and mental health. However, these critical events frequently occur in privacy-sensitive environments like restrooms, and changing rooms, where conventional surveillance is prohibited or severely restricted by stringent privacy regulations and ethical concerns. Here, we propose the Single-Pixel Vision-Language Model (SP-VLM), a novel framework that reimagines secure environmental monitoring. It achieves intrinsic privacy-by-design by capturing human dynamics through inherently low-dimensional single-pixel modalities and inferring complex behavioral patterns via seamless vision-language integration. Building on this framework, we demonstrate that single-pixel sensing intrinsically suppresses identity recoverability, rendering state-of-the-art face recognition systems ineffective below a critical sampling rate. We further show that SP-VLM can nonetheless extract meaningful behavioral semantics, enabling robust anomaly detection, people counting, and activity understanding from severely degraded single-pixel observations. Combining these findings, we identify a practical sampling-rate regime in which behavioral intelligence emerges while personal identity remains strongly protected. Together, these results point to a human-rights-aligned pathway for safety monitoring that can support timely intervention without normalizing intrusive surveillance in privacy-sensitive spaces.

</details>


### [11] [Synthetic Data Guided Feature Selection for Robust Activity Recognition in Older Adults](https://arxiv.org/abs/2601.17053)
*Shuhao Que,Dieuwke van Dartel,Ilse Heeringa,Han Hegeman,Miriam Vollenbroek-Hutten,Ying Wang*

Main category: cs.CV

TL;DR: 开发用于髋部骨折康复的老年人活动识别系统，通过合成数据增强提高姿势转移检测准确性


<details>
  <summary>Details</summary>
Motivation: 髋部骨折康复期间的身体活动监测对老年患者功能恢复至关重要，但现有基于可穿戴设备的监测系统主要针对中青年人群开发，对步态缓慢多变的老年人识别不可靠，特别是临床重要的姿势转移活动常被忽视

Method: 研究纳入24名80岁以上健康老年人，在模拟自由生活条件下执行日常活动（行走、站立、坐、躺、姿势转移）75分钟，佩戴腰部和前大腿加速度计。采用留一法交叉验证评估模型鲁棒性，使用合成数据增强泛化能力，开发特征干预模型（FIM）

Result: FIM模型在合成数据辅助下取得可靠活动识别效果：行走F1分数0.896、站立0.927、坐0.997、躺0.937、姿势转移0.816。相比无合成数据的对照组，FIM显著提高了临床重要的姿势转移检测能力

Conclusion: 初步结果证明了老年人活动识别的可行性，特别是合成数据增强提高了姿势转移检测。需要在髋部骨折患者群体中进一步验证以评估临床实用性

Abstract: Physical activity during hip fracture rehabilitation is essential for mitigating long-term functional decline in geriatric patients. However, it is rarely quantified in clinical practice. Existing continuous monitoring systems with commercially available wearable activity trackers are typically developed in middle-aged adults and therefore perform unreliably in older adults with slower and more variable gait patterns. This study aimed to develop a robust human activity recognition (HAR) system to improve continuous physical activity recognition in the context of hip fracture rehabilitation. 24 healthy older adults aged over 80 years were included to perform activities of daily living (walking, standing, sitting, lying down, and postural transfers) under simulated free-living conditions for 75 minutes while wearing two accelerometers positioned on the lower back and anterior upper thigh. Model robustness was evaluated using leave-one-subject-out cross-validation. The synthetic data demonstrated potential to improve generalization across participants. The resulting feature intervention model (FIM), aided by synthetic data guidance, achieved reliable activity recognition with mean F1-scores of 0.896 for walking, 0.927 for standing, 0.997 for sitting, 0.937 for lying down, and 0.816 for postural transfers. Compared with a control condition model without synthetic data, the FIM significantly improved the postural transfer detection, i.e., an activity class of high clinical relevance that is often overlooked in existing HAR literature. In conclusion, these preliminary results demonstrate the feasibility of robust activity recognition in older adults. Further validation in hip fracture patient populations is required to assess the clinical utility of the proposed monitoring system.

</details>


### [12] [A Computer Vision Pipeline for Iterative Bullet Hole Tracking in Rifle Zeroing](https://arxiv.org/abs/2601.17062)
*Robert M. Belcher,Brendan C. Degryse,Leonard R. Kosta,Christopher J. Lowrance*

Main category: cs.CV

TL;DR: 基于计算机视觉的自动弹孔检测与迭代追踪系统，用于步枪瞄准镜校准，结合YOLOv8检测和IoU分析，通过新颖的数据增强和预处理技术实现高精度性能。


<details>
  <summary>Details</summary>
Motivation: 传统步枪瞄准镜校准需要人工检查弹孔，存在安全协议延迟和人为错误风险。需要自动化系统来实时检测和追踪不同射击迭代的弹孔。

Method: 使用YOLOv8进行小目标检测，结合IoU分析区分序列图像中的弹孔。提出新颖的数据增强技术（移除而非添加对象模拟射击序列）和基于ORB的透视校正预处理管道。

Result: 系统在弹孔检测上达到97.0%的平均精度，在将弹孔分配到正确射击迭代上达到88.8%的准确率。

Conclusion: 该端到端计算机视觉系统成功实现了自动弹孔检测和迭代追踪，不仅适用于步枪校准，还可扩展到需要时间区分视觉相似对象的其他领域。

Abstract: Adjusting rifle sights, a process commonly called "zeroing," requires shooters to identify and differentiate bullet holes from multiple firing iterations. Traditionally, this process demands physical inspection, introducing delays due to range safety protocols and increasing the risk of human error. We present an end-to-end computer vision system for automated bullet hole detection and iteration-based tracking directly from images taken at the firing line. Our approach combines YOLOv8 for accurate small-object detection with Intersection over Union (IoU) analysis to differentiate bullet holes across sequential images. To address the scarcity of labeled sequential data, we propose a novel data augmentation technique that removes rather than adds objects to simulate realistic firing sequences. Additionally, we introduce a preprocessing pipeline that standardizes target orientation using ORB-based perspective correction, improving model accuracy. Our system achieves 97.0% mean average precision on bullet hole detection and 88.8% accuracy in assigning bullet holes to the correct firing iteration. While designed for rifle zeroing, this framework offers broader applicability in domains requiring the temporal differentiation of visually similar objects.

</details>


### [13] [A Mechanistic View on Video Generation as World Models: State and Dynamics](https://arxiv.org/abs/2601.17067)
*Luozhou Wang,Zhifei Chen,Yihua Du,Dongyu Yan,Wenhang Ge,Guibao Shen,Xinli Xu,Leyi Wu,Man Chen,Tianshuo Xu,Peiran Ren,Xin Tao,Pengfei Wan,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 论文提出了一种新的分类法，将视频生成模型作为世界模型的研究分为状态构建和动态建模两大支柱，并倡导从视觉保真度评估转向功能性基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前大规模视频生成模型虽然展现出物理连贯性，可作为潜在的世界模型，但现代"无状态"视频架构与经典状态中心化的世界模型理论之间存在差距。需要弥合这一差距，推动视频生成模型从生成视觉上合理的视频发展为构建稳健、通用的世界模拟器。

Method: 提出以状态构建和动态建模为核心支柱的新分类法：状态构建分为隐式范式（上下文管理）和显式范式（潜在压缩）；动态建模通过知识整合和架构重构进行分析。同时倡导从视觉保真度评估转向功能性基准测试，测试物理持久性和因果推理能力。

Result: 建立了视频生成模型作为世界模型的系统分析框架，识别出两个关键前沿：通过数据驱动记忆和压缩保真度增强持久性，以及通过潜在因子解耦和推理先验整合推进因果性。

Conclusion: 通过解决这些挑战，该领域可以从生成视觉上合理的视频演变为构建稳健、通用的世界模拟器。提出的分类法和评估框架为视频生成模型作为世界模型的研究提供了系统指导。

Abstract: Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary "stateless" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.

</details>


### [14] [Superpixel-Based Image Segmentation Using Squared 2-Wasserstein Distances](https://arxiv.org/abs/2601.17071)
*Jisui Huang,Andreas Alpers,Ke Chen,Na Lei*

Main category: cs.CV

TL;DR: 提出了一种针对强不均匀性图像的高效分割方法，采用两层聚类框架：先通过离散最优传输将像素分组为超像素，再用Wasserstein距离贪婪合并为对象级分割


<details>
  <summary>Details</summary>
Motivation: 传统基于平均颜色距离的超像素合并策略在处理强不均匀性图像时效果有限，需要一种数学统一的框架来提升分割精度

Method: 两层聚类方法：第一层将像素通过线性最小二乘分配问题（离散最优传输特例）分组为超像素；第二层使用平方2-Wasserstein距离贪婪合并超像素为对象级分割

Result: 数值实验表明，该方法在挑战性图像上提高了分割精度，同时保持了高计算效率

Conclusion: 基于最优传输的分布距离框架为图像分割提供了数学统一的解决方案，在保持效率的同时提升了强不均匀性图像的分割性能

Abstract: We present an efficient method for image segmentation in the presence of strong inhomogeneities. The approach can be interpreted as a two-level clustering procedure: pixels are first grouped into superpixels via a linear least-squares assignment problem, which can be viewed as a special case of a discrete optimal transport (OT) problem, and these superpixels are subsequently greedily merged into object-level segments using the squared 2-Wasserstein distance between their empirical distributions. In contrast to conventional superpixel merging strategies based on mean-color distances, our framework employs a distributional OT distance, yielding a mathematically unified formulation across both clustering levels. Numerical experiments demonstrate that this perspective leads to improved segmentation accuracy on challenging images while retaining high computational efficiency.

</details>


### [15] [GlassesGB: Controllable 2D GAN-Based Eyewear Personalization for 3D Gaussian Blendshapes Head Avatars](https://arxiv.org/abs/2601.17088)
*Rui-Yang Ju,Jen-Shiun Chiang*

Main category: cs.CV

TL;DR: GlassesGB是一个支持3D头部虚拟形象可定制眼镜生成的框架，将2D生成定制与3D头部虚拟形象渲染相结合


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试戴系统大多只能在预定义眼镜模板上操作，缺乏细粒度的用户驱动定制能力。虽然GlassesGAN支持个性化2D眼镜设计，但其能力仅限于2D图像生成。需要将2D生成定制与3D头部虚拟形象渲染相结合，解决VR应用中个性化眼镜设计的挑战

Method: 基于3D高斯混合形状在头部重建中的成功，将3D高斯混合形状技术与2D生成定制技术相结合，提出GlassesGB框架，支持3D头部虚拟形象的可定制眼镜生成

Result: GlassesGB有效桥接了2D生成定制与3D头部虚拟形象渲染，能够为VR应用实现个性化眼镜设计

Conclusion: 提出的GlassesGB框架解决了现有虚拟试戴系统在个性化眼镜设计方面的局限性，为VR应用提供了可定制的3D眼镜生成能力

Abstract: Virtual try-on systems allow users to interactively try different products within VR scenarios. However, most existing VTON methods operate only on predefined eyewear templates and lack support for fine-grained, user-driven customization. While GlassesGAN enables personalized 2D eyewear design, its capability remains limited to 2D image generation. Motivated by the success of 3D Gaussian Blendshapes in head reconstruction, we integrate these two techniques and propose GlassesGB, a framework that supports customizable eyewear generation for 3D head avatars. GlassesGB effectively bridges 2D generative customization with 3D head avatar rendering, addressing the challenge in achieving personalized eyewear design for VR applications. The implementation code is available at https://ruiyangju.github.io/GlassesGB.

</details>


### [16] [GRASP: Guided Region-Aware Sparse Prompting for Adapting MLLMs to Remote Sensing](https://arxiv.org/abs/2601.17089)
*Qigan Sun,Chaoning Zhang,Jianwei Zhang,Xudong Wang,Jiehui Xie,Pengcheng Zheng,Haoyu Wang,Sungyoung Lee,Chi-lok Andy Tai,Yang Yang,Heng Tao Shen*

Main category: cs.CV

TL;DR: 提出GRASP方法，一种参数高效的微调策略，通过引导区域感知稀疏提示解决遥感图像中MLLMs的过拟合和细节忽略问题


<details>
  <summary>Details</summary>
Motivation: 现有微调方法直接应用于遥感图像时存在过拟合背景噪声或忽略目标细节的问题，主要由于遥感图像的大尺度变化、稀疏目标分布和复杂区域语义特征

Method: 提出GRASP方法，引入与冻结视觉令牌网格中提取的空间块相关的空间结构化软提示，通过问题引导的稀疏融合机制动态聚合任务特定上下文到紧凑全局提示中

Result: 在多个RSVQA基准测试中，GRASP相比现有微调和基于提示的方法实现了竞争性性能，同时保持高参数效率

Conclusion: GRASP通过引导区域感知稀疏提示有效解决了遥感图像中MLLMs的挑战，在保持参数效率的同时提升了视觉问答性能

Abstract: In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks. However, directly applying existing fine-tuning methods to remote sensing (RS) images often leads to issues such as overfitting on background noise or neglecting target details. This is primarily due to the large-scale variations, sparse target distributions, and complex regional semantic features inherent in RS images. These challenges limit the effectiveness of MLLMs in RS tasks. To address these challenges, we propose a parameter-efficient fine-tuning (PEFT) strategy called Guided Region-Aware Sparse Prompting (GRASP). GRASP introduces spatially structured soft prompts associated with spatial blocks extracted from a frozen visual token grid. Through a question-guided sparse fusion mechanism, GRASP dynamically aggregates task-specific context into a compact global prompt, enabling the model to focus on relevant regions while filtering out background noise. Extensive experiments on multiple RSVQA benchmarks show that GRASP achieves competitive performance compared to existing fine-tuning and prompt-based methods while maintaining high parameter efficiency.

</details>


### [17] [LoD Sketch Extraction from Architectural Models Using Generative AI: Dataset Construction for Multi-Level Architectural Design Generation](https://arxiv.org/abs/2601.17095)
*Xusheng Du,Athiwat Kongkaeo,Ye Zhang,Haoran Xie*

Main category: cs.CV

TL;DR: 提出基于生成式AI的自动LoD草图提取框架，通过渐进简化高细节建筑模型，自动生成几何一致、层次连贯的多层次细节表示，解决传统建模耗时费力且几何不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 建筑设计中多层次细节表示对于从概念体量到详细建模的平滑过渡至关重要。传统LoD建模依赖人工操作，耗时费力且易产生几何不一致。生成式AI为从草图输入生成多级建筑模型提供了新可能，但缺乏高质量配对的LoD训练数据限制了其应用。

Method: 提出自动LoD草图提取框架，集成计算机视觉技术和生成式AI方法，建立从详细表示到体量抽象的渐进提取流程，逐步简化高细节建筑模型，生成几何一致且层次连贯的多LoD表示。

Result: 实验结果表明，该方法在LoD级别间保持强几何一致性：从LoD3到LoD2的SSIM值为0.7319，从LoD2到LoD1的SSIM值为0.7532；相应的归一化Hausdorff距离分别为图像对角线的25.1%和61.0%，反映了抽象过程中的受控几何偏差。

Conclusion: 该框架有效保持了全局结构，同时在不同LoD级别间实现了渐进语义简化，为AI驱动的多层次建筑生成和分层建模提供了可靠数据和技术支持。

Abstract: For architectural design, representation across multiple Levels of Details (LoD) is essential for achieving a smooth transition from conceptual massing to detailed modeling. However, traditional LoD modeling processes rely on manual operations that are time-consuming, labor-intensive, and prone to geometric inconsistencies. While the rapid advancement of generative artificial intelligence (AI) has opened new possibilities for generating multi-level architectural models from sketch inputs, its application remains limited by the lack of high-quality paired LoD training data. To address this issue, we propose an automatic LoD sketch extraction framework using generative AI models, which progressively simplifies high-detail architectural models to automatically generate geometrically consistent and hierarchically coherent multi-LoD representations. The proposed framework integrates computer vision techniques with generative AI methods to establish a progressive extraction pipeline that transitions from detailed representations to volumetric abstractions. Experimental results demonstrate that the method maintains strong geometric consistency across LoD levels, achieving SSIM values of 0.7319 and 0.7532 for the transitions from LoD3 to LoD2 and from LoD2 to LoD1, respectively, with corresponding normalized Hausdorff distances of 25.1% and 61.0% of the image diagonal, reflecting controlled geometric deviation during abstraction. These results verify that the proposed framework effectively preserves global structure while achieving progressive semantic simplification across different LoD levels, providing reliable data and technical support for AI-driven multi-level architectural generation and hierarchical modeling.

</details>


### [18] [Performance uncertainty in medical image analysis: a large-scale investigation of confidence intervals](https://arxiv.org/abs/2601.17103)
*Pascaline André,Charles Heitz,Evangelia Christodoulou,Annika Reinke,Carole H. Sudre,Michela Antonelli,Patrick Godau,M. Jorge Cardoso,Antoine Gilson,Sophie Tezenas du Montcel,Gaël Varoquaux,Lena Maier-Hein,Olivier Colliot*

Main category: cs.CV

TL;DR: 该研究通过大规模实证分析评估医学影像AI性能不确定性量化的置信区间方法，发现CI可靠性受样本量、性能指标、聚合策略、任务类型和CI方法选择等多种因素影响。


<details>
  <summary>Details</summary>
Motivation: 医学影像AI的性能不确定性量化对于可靠的验证和临床转化至关重要，但社区对多种置信区间方法及其在不同场景下的行为了解不足，需要填补这一知识空白。

Method: 研究进行了大规模实证分析，涵盖24个分割和分类任务，每个任务组使用19个训练模型，采用多种常用性能指标、聚合策略和广泛采用的置信区间方法，评估各CI方法的可靠性（覆盖率）和精确度（宽度）。

Result: 分析揭示了五个主要发现：1）可靠CI所需样本量从几十到几千例不等；2）CI行为受性能指标选择强烈影响；3）聚合策略显著影响CI可靠性；4）机器学习问题类型（分割vs分类）调节这些效应；5）不同CI方法在不同用例中的可靠性和精确度不同。

Conclusion: 这些结果为制定医学影像AI性能不确定性报告的未来指南提供了关键组成部分，强调了在特定研究背景下选择适当CI方法的重要性。

Abstract: Performance uncertainty quantification is essential for reliable validation and eventual clinical translation of medical imaging artificial intelligence (AI). Confidence intervals (CIs) play a central role in this process by indicating how precise a reported performance estimate is. Yet, due to the limited amount of work examining CI behavior in medical imaging, the community remains largely unaware of how many diverse CI methods exist and how they behave in specific settings. The purpose of this study is to close this gap. To this end, we conducted a large-scale empirical analysis across a total of 24 segmentation and classification tasks, using 19 trained models per task group, a broad spectrum of commonly used performance metrics, multiple aggregation strategies, and several widely adopted CI methods. Reliability (coverage) and precision (width) of each CI method were estimated across all settings to characterize their dependence on study characteristics. Our analysis revealed five principal findings: 1) the sample size required for reliable CIs varies from a few dozens to several thousands of cases depending on study parameters; 2) CI behavior is strongly affected by the choice of performance metric; 3) aggregation strategy substantially influences the reliability of CIs, e.g. they require more observations for macro than for micro; 4) the machine learning problem (segmentation versus classification) modulates these effects; 5) different CI methods are not equally reliable and precise depending on the use case. These results form key components for the development of future guidelines on reporting performance uncertainty in medical imaging AI.

</details>


### [19] [StealthMark: Harmless and Stealthy Ownership Verification for Medical Segmentation via Uncertainty-Guided Backdoors](https://arxiv.org/abs/2601.17107)
*Qinkai Yu,Chong Zhang,Gaojie Jin,Tianjin Huang,Wei Zhou,Wenhui Li,Xiaobo Jin,Bo Huang,Yitian Zhao,Guang Yang,Gregory Y. H. Lip,Yalin Zheng,Aline Villavicencio,Yanda Meng*

Main category: cs.CV

TL;DR: StealthMark：一种用于医学分割模型的黑盒所有权验证方法，通过微调模型不确定性而不改变分割输出，利用解释方法提取特征归因来显示可验证的水印


<details>
  <summary>Details</summary>
Motivation: 医学数据标注成本高且受隐私限制，训练好的医学分割模型成为有价值的IP需要保护。现有保护技术主要关注分类和生成任务，分割模型保护研究不足

Method: 提出StealthMark方法，通过微妙调制模型不确定性而不改变最终分割输出，结合LIME等模型无关解释方法提取特征归因，在特定触发条件下显示QR码水印进行所有权验证

Result: 在四个医学影像数据集和五个主流分割模型上实验，ASR超过95%，Dice和AUC分数下降小于1%，显著优于基于后门的水印方法

Conclusion: StealthMark方法有效、隐蔽且无害，在保持原始模型性能的同时实现可靠的所有权验证，具有实际部署潜力

Abstract: Annotating medical data for training AI models is often costly and limited due to the shortage of specialists with relevant clinical expertise. This challenge is further compounded by privacy and ethical concerns associated with sensitive patient information. As a result, well-trained medical segmentation models on private datasets constitute valuable intellectual property requiring robust protection mechanisms. Existing model protection techniques primarily focus on classification and generative tasks, while segmentation models-crucial to medical image analysis-remain largely underexplored. In this paper, we propose a novel, stealthy, and harmless method, StealthMark, for verifying the ownership of medical segmentation models under black-box conditions. Our approach subtly modulates model uncertainty without altering the final segmentation outputs, thereby preserving the model's performance. To enable ownership verification, we incorporate model-agnostic explanation methods, e.g. LIME, to extract feature attributions from the model outputs. Under specific triggering conditions, these explanations reveal a distinct and verifiable watermark. We further design the watermark as a QR code to facilitate robust and recognizable ownership claims. We conducted extensive experiments across four medical imaging datasets and five mainstream segmentation models. The results demonstrate the effectiveness, stealthiness, and harmlessness of our method on the original model's segmentation performance. For example, when applied to the SAM model, StealthMark consistently achieved ASR above 95% across various datasets while maintaining less than a 1% drop in Dice and AUC scores, significantly outperforming backdoor-based watermarking methods and highlighting its strong potential for practical deployment. Our implementation code is made available at: https://github.com/Qinkaiyu/StealthMark.

</details>


### [20] [iFSQ: Improving FSQ for Image Generation with 1 Line of Code](https://arxiv.org/abs/2601.17124)
*Bin Lin,Zongjian Li,Yuwei Niu,Kaixiong Gong,Yunyang Ge,Yunlong Lin,Mingzhe Zheng,JianWei Zhang,Miles Yang,Zhao Zhong,Liefeng Bo,Li Yuan*

Main category: cs.CV

TL;DR: iFSQ通过简单的分布匹配映射替换原始FSQ的激活函数，解决了量化激活崩溃问题，为离散和连续图像生成模型提供了统一基准，发现4比特/维是最佳平衡点，并揭示了AR模型收敛快但扩散模型上限更高的特性。


<details>
  <summary>Details</summary>
Motivation: 当前图像生成领域分裂为基于离散token的自回归模型和基于连续潜变量的扩散模型，这种分裂源于VQ-VAE和VAE的区别，阻碍了统一建模和公平基准测试。虽然有限标量量化(FSQ)提供了理论桥梁，但原始FSQ存在等间隔量化导致的激活崩溃问题，迫使在重建保真度和信息效率之间做出权衡。

Method: 提出iFSQ方法，将原始FSQ中的激活函数替换为分布匹配映射，强制实施均匀先验分布。这种简单策略只需一行代码修改，但数学上保证了最优的bin利用率和重建精度。使用iFSQ作为受控基准，分析离散与连续表示的最佳平衡点，并将表示对齐(REPA)方法扩展到AR模型中，开发了LlamaGen-REPA。

Result: 研究发现：(1)离散和连续表示之间的最佳平衡点约为每维度4比特；(2)在相同重建约束下，AR模型表现出快速初始收敛，而扩散模型能达到更高的性能上限，表明严格的顺序排序可能限制生成质量的上限。通过将REPA适配到AR模型，开发了LlamaGen-REPA。

Conclusion: iFSQ通过简单的分布匹配映射解决了FSQ的激活崩溃问题，为离散和连续图像生成模型提供了统一的基准框架。研究发现4比特/维是最佳表示平衡点，并揭示了AR模型与扩散模型在收敛特性和性能上限方面的差异。这些发现为统一图像生成建模提供了重要见解。

Abstract: The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ

</details>


### [21] [Scaling medical imaging report generation with multimodal reinforcement learning](https://arxiv.org/abs/2601.17151)
*Qianchu Liu,Sheng Zhang,Guanghui Qin,Yu Gu,Ying Jin,Sam Preston,Yanbo Xu,Sid Kiblawi,Wen-wai Yim,Tim Ossowski,Tristan Naumann,Mu Wei,Hoifung Poon*

Main category: cs.CV

TL;DR: UniRG是一个用于医学影像报告生成的通用框架，通过强化学习直接优化评估指标，在胸片报告生成任务上取得了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 前沿模型在自然语言理解和推理方面表现出色，但在生物医学等多模态理解方面仍有能力差距。医学影像报告生成是一个典型例子，监督微调容易过拟合到表面模式。

Method: 提出了通用报告生成（UniRG）框架，利用强化学习作为统一机制，直接针对最终应用的评估指标进行优化，从而获得跨机构和临床实践的持久泛化能力。

Result: 在胸片X光（CXR）数据上训练的UniRG-CXR在权威ReXrank基准测试中创造了新的整体SOTA，大幅超越了之前的最先进方法。

Conclusion: UniRG框架通过强化学习优化评估指标，显著改进了监督微调的性能，并在医学影像报告生成任务中展现出强大的泛化能力和卓越性能。

Abstract: Frontier models have demonstrated remarkable capabilities in understanding and reasoning with natural-language text, but they still exhibit major competency gaps in multimodal understanding and reasoning especially in high-value verticals such as biomedicine. Medical imaging report generation is a prominent example. Supervised fine-tuning can substantially improve performance, but they are prone to overfitting to superficial boilerplate patterns. In this paper, we introduce Universal Report Generation (UniRG) as a general framework for medical imaging report generation. By leveraging reinforcement learning as a unifying mechanism to directly optimize for evaluation metrics designed for end applications, UniRG can significantly improve upon supervised fine-tuning and attain durable generalization across diverse institutions and clinical practices. We trained UniRG-CXR on publicly available chest X-ray (CXR) data and conducted a thorough evaluation in CXR report generation with rigorous evaluation scenarios. On the authoritative ReXrank benchmark, UniRG-CXR sets new overall SOTA, outperforming prior state of the art by a wide margin.

</details>


### [22] [LGDWT-GS: Local and Global Discrete Wavelet-Regularized 3D Gaussian Splatting for Sparse-View Scene Reconstruction](https://arxiv.org/abs/2601.17185)
*Shima Salehi,Atharva Agashe,Andrew J. McFarland,Joshua Peeples*

Main category: cs.CV

TL;DR: 提出一种结合全局和局部频率正则化的少样本3D重建方法，解决3D高斯溅射模型在稀疏视角下的几何不稳定问题，同时发布多光谱温室数据集和开源基准测试包。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯溅射（3DGS）模型在稀疏视角条件下存在几何不稳定和细节丢失的问题，需要一种能够同时稳定几何结构和保留精细细节的少样本3D重建方法。

Method: 提出集成全局和局部频率正则化的新方法，通过频率域约束来稳定几何并保留细节；同时构建包含四个光谱波段的多光谱温室数据集，并开发开源基准测试包定义标准化少样本重建协议。

Result: 在多光谱数据集和标准基准测试上的实验表明，该方法相比现有基线能够实现更清晰、更稳定且光谱一致的重建结果。

Conclusion: 提出的频率正则化方法有效解决了3DGS在稀疏视角下的局限性，同时发布的数据集和基准测试包为少样本3D重建研究提供了有价值的资源。

Abstract: We propose a new method for few-shot 3D reconstruction that integrates global and local frequency regularization to stabilize geometry and preserve fine details under sparse-view conditions, addressing a key limitation of existing 3D Gaussian Splatting (3DGS) models. We also introduce a new multispectral greenhouse dataset containing four spectral bands captured from diverse plant species under controlled conditions. Alongside the dataset, we release an open-source benchmarking package that defines standardized few-shot reconstruction protocols for evaluating 3DGS-based methods. Experiments on our multispectral dataset, as well as standard benchmarks, demonstrate that the proposed method achieves sharper, more stable, and spectrally consistent reconstructions than existing baselines. The dataset and code for this work are publicly available

</details>


### [23] [Decoding Psychological States Through Movement: Inferring Human Kinesic Functions with Application to Built Environments](https://arxiv.org/abs/2601.17194)
*Cheyu Lin,Katherine A. Flanigan,Sirajum Munir*

Main category: cs.CV

TL;DR: 该研究提出了DUET数据集和运动学识别框架，用于在保护隐私的前提下测量社会基础设施中的社交互动，填补了建筑环境研究中缺乏统一社交互动测量方法的空白。


<details>
  <summary>Details</summary>
Motivation: 当前建筑环境研究中缺乏一致且保护隐私的方法来测量社交互动，导致不同研究对"互动"的操作定义不一致，限制了从业者评估设计干预是否真正影响社会资本理论预测的重要互动形式。

Method: 引入DUET数据集，基于Ekman和Friesen的运动学分类法，捕捉12种二元互动，涵盖5种运动功能（象征、说明、情感表达、适应、调节），使用4种传感模态和3种建筑环境场景。开发了直接从隐私保护的骨骼运动中推断交流功能的识别框架，无需手工制作的动作-功能词典。

Result: 对6个开源的人体活动识别模型进行基准测试，量化了在DUET上进行交流功能识别的难度，揭示了普遍的单体动作级识别在扩展到二元社交互动测量时的局限性。识别框架显示了运动功能的结构化聚类，以及表示质量与分类性能之间的强关联，同时在不同主体和环境中具有泛化能力。

Conclusion: DUET数据集和运动学识别框架为建筑环境研究提供了隐私保护的社交互动测量方法，能够评估设计干预对社会资本相关行为的影响，填补了该领域的方法学空白。

Abstract: Social infrastructure and other built environments are increasingly expected to support well-being and community resilience by enabling social interaction. Yet in civil and built-environment research, there is no consistent and privacy-preserving way to represent and measure socially meaningful interaction in these spaces, leaving studies to operationalize "interaction" differently across contexts and limiting practitioners' ability to evaluate whether design interventions are changing the forms of interaction that social capital theory predicts should matter. To address this field-level and methodological gap, we introduce the Dyadic User Engagement DataseT (DUET) dataset and an embedded kinesics recognition framework that operationalize Ekman and Friesen's kinesics taxonomy as a function-level interaction vocabulary aligned with social capital-relevant behaviors (e.g., reciprocity and attention coordination). DUET captures 12 dyadic interactions spanning all five kinesic functions-emblems, illustrators, affect displays, adaptors, and regulators-across four sensing modalities and three built-environment contexts, enabling privacy-preserving analysis of communicative intent through movement. Benchmarking six open-source, state-of-the-art human activity recognition models quantifies the difficulty of communicative-function recognition on DUET and highlights the limitations of ubiquitous monadic, action-level recognition when extended to dyadic, socially grounded interaction measurement. Building on DUET, our recognition framework infers communicative function directly from privacy-preserving skeletal motion without handcrafted action-to-function dictionaries; using a transfer-learning architecture, it reveals structured clustering of kinesic functions and a strong association between representation quality and classification performance while generalizing across subjects and contexts.

</details>


### [24] [Structural Complexity of Brain MRI reveals age-associated patterns](https://arxiv.org/abs/2601.17211)
*Anzhe Cheng,Italo Ivo Lima Dias Pinto,Paul Bogdan*

Main category: cs.CV

TL;DR: 该研究将结构复杂度分析应用于三维脑MRI信号，通过多尺度粗粒化方法量化分辨率变化中的信息损失，发现结构复杂度随年龄系统性下降，且粗尺度效应最显著。


<details>
  <summary>Details</summary>
Motivation: 将结构复杂度分析框架扩展到三维信号，特别是脑磁共振成像（MRI），以捕捉体积数据的多尺度组织特征，改进传统方法在粗分辨率下的不稳定性问题。

Method: 引入滑动窗口粗粒化方案，在渐进增大的空间尺度上对信号进行粗粒化处理，量化连续分辨率之间的信息损失，相比传统基于块的方法提供更平滑的估计和更好的大尺度鲁棒性。

Result: 分析覆盖中晚期成年期的大型结构MRI数据集，发现结构复杂度随年龄系统性下降，且最显著的影响出现在较粗的尺度上。

Conclusion: 结构复杂度是三维成像数据多尺度分析的可靠信号处理工具，同时证明了其在从脑MRI预测生物年龄方面的实用性。

Abstract: We adapt structural complexity analysis to three-dimensional signals, with an emphasis on brain magnetic resonance imaging (MRI). This framework captures the multiscale organization of volumetric data by coarse-graining the signal at progressively larger spatial scales and quantifying the information lost between successive resolutions. While the traditional block-based approach can become unstable at coarse resolutions due to limited sampling, we introduce a sliding-window coarse-graining scheme that provides smoother estimates and improved robustness at large scales. Using this refined method, we analyze large structural MRI datasets spanning mid- to late adulthood and find that structural complexity decreases systematically with age, with the strongest effects emerging at coarser scales. These findings highlight structural complexity as a reliable signal processing tool for multiscale analysis of 3D imaging data, while also demonstrating its utility in predicting biological age from brain MRI.

</details>


### [25] [Spatiotemporal Semantic V2X Framework for Cooperative Collision Prediction](https://arxiv.org/abs/2601.17216)
*Murat Arda Onsu,Poonam Lohan,Burak Kantarci,Aisha Syed,Matthew Andrews,Sean Kennedy*

Main category: cs.CV

TL;DR: 提出基于语义V2X框架的实时碰撞预测系统，使用V-JEPA生成时空语义嵌入替代原始视频传输，显著降低通信开销同时提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统需要实时碰撞预测以确保道路安全，但传统方法传输原始视频或高维传感器数据在车联网通信带宽和延迟限制下不切实际。

Method: 提出语义V2X框架：路侧单元摄像头使用V-JEPA生成未来帧的时空语义嵌入，通过V2X链路传输到车辆，车辆端使用轻量级注意力探针和分类器解码预测碰撞。

Result: 实验结果显示，该系统在碰撞预测的F1分数上提升10%，同时传输需求相比原始视频降低四个数量级（10000倍）。

Conclusion: 验证了语义V2X通信在智能交通系统中实现协作式实时碰撞预测的潜力，通过传输语义嵌入而非原始帧，在保持预测准确性的同时大幅减少通信开销。

Abstract: Intelligent Transportation Systems (ITS) demand real-time collision prediction to ensure road safety and reduce accident severity. Conventional approaches rely on transmitting raw video or high-dimensional sensory data from roadside units (RSUs) to vehicles, which is impractical under vehicular communication bandwidth and latency constraints. In this work, we propose a semantic V2X framework in which RSU-mounted cameras generate spatiotemporal semantic embeddings of future frames using the Video Joint Embedding Predictive Architecture (V-JEPA). To evaluate the system, we construct a digital twin of an urban traffic environment enabling the generation of d verse traffic scenarios with both safe and collision events. These embeddings of the future frame, extracted from V-JEPA, capture task-relevant traffic dynamics and are transmitted via V2X links to vehicles, where a lightweight attentive probe and classifier decode them to predict imminent collisions. By transmitting only semantic embeddings instead of raw frames, the proposed system significantly reduces communication overhead while maintaining predictive accuracy. Experimental results demonstrate that the framework with an appropriate processing method achieves a 10% F1-score improvement for collision prediction while reducing transmission requirements by four orders of magnitude compared to raw video. This validates the potential of semantic V2X communication to enable cooperative, real-time collision prediction in ITS.

</details>


### [26] [Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification](https://arxiv.org/abs/2601.17228)
*Tengyue Zhang,Ruiwen Ding,Luoting Zhuang,Yuxiao Wu,Erika F. Rodriguez,William Hsu*

Main category: cs.CV

TL;DR: 提出基于潜在扩散模型的半监督域适应框架，通过生成保持组织形态的目标感知合成图像，改善计算病理学中的域泛化问题


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的深度学习模型常因域偏移而无法跨队列和机构泛化。现有方法要么无法利用目标域的无标签数据，要么依赖可能扭曲组织结构的图像翻译方法

Method: 提出半监督域适应框架，使用在源域和目标域无标签数据上训练的潜在扩散模型，通过条件化扩散模型（基于基础模型特征、队列身份和组织制备方法）生成保持组织形态的目标感知合成图像，结合源域真实标签图像训练下游分类器

Result: 在肺腺癌预后任务中验证，目标感知增强显著提升目标域测试集性能而不降低源域性能。目标域测试集的加权F1分数从0.611提升至0.706，宏观F1分数从0.641提升至0.716

Conclusion: 目标感知的基于扩散的合成数据增强为改善计算病理学中的域泛化提供了有前景且有效的方法

Abstract: Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.

</details>


### [27] [Multi-stage Bridge Inspection System: Integrating Foundation Models with Location Anonymization](https://arxiv.org/abs/2601.17254)
*Takato Yasuno*

Main category: cs.CV

TL;DR: 日本桥梁损伤检测系统，在保护区域隐私的同时实现高效检测，使用SAM3进行钢筋腐蚀检测，DBSCAN补全遗漏区域，高斯模糊保护施工标志，GPU优化实现1.7秒/图像处理


<details>
  <summary>Details</summary>
Motivation: 日本法规要求每五年进行基础设施视觉检查，现场拍摄的损伤图像常包含混凝土裂缝和钢筋暴露，同时带有施工标志等区域信息。为确保基础设施安全使用而不引起公众焦虑，需要在准确提取损伤特征的同时保护区域隐私信息。

Method: 采用开源桥梁损伤检测系统，使用Segment Anything Model (SAM) 3进行钢筋腐蚀检测，DBSCAN算法自动补全遗漏区域，通过高斯模糊保护施工标志区域。应用四种预处理方法提高OCR准确率，并进行GPU优化。

Result: 系统技术栈包括SAM3、PyTorch、OpenCV、pytesseract和scikit-learn，GPU优化后实现每张图像1.7秒的处理速度，在保护区域信息的同时实现高效桥梁检测。

Conclusion: 该系统成功实现了桥梁损伤检测与区域隐私保护的平衡，为基础设施安全使用提供了技术解决方案，既能准确提取损伤特征用于维修决策，又能防止敏感区域信息泄露引起公众不安。

Abstract: In Japan, civil infrastructure condition monitoring is mandated through visual inspection every five years. Field-captured damage images frequently contain concrete cracks and rebar exposure, often accompanied by construction signs revealing regional information. To enable safe infrastructure use without causing public anxiety, it is essential to protect regional information while accurately extracting damage features and visualizing key indicators for repair decision-making. This paper presents an open-source bridge damage detection system with regional privacy protection capabilities. We employ Segment Anything Model (SAM) 3 for rebar corrosion detection and utilize DBSCAN for automatic completion of missed regions. Construction sign regions are detected and protected through Gaussian blur. Four preprocessing methods improve OCR accuracy, and GPU optimization enables 1.7-second processing per image. The technology stack includes SAM3, PyTorch, OpenCV, pytesseract, and scikit-learn, achieving efficient bridge inspection with regional information protection.

</details>


### [28] [FineVAU: A Novel Human-Aligned Benchmark for Fine-Grained Video Anomaly Understanding](https://arxiv.org/abs/2601.17258)
*João Pereira,Vasco Lopes,João Neves,David Semedo*

Main category: cs.CV

TL;DR: FineVAU是一个新的视频异常理解基准，包含FVScore评估指标和FineW3数据集，旨在解决现有评估方法无法捕捉LVLM丰富、细粒度响应的局限性。


<details>
  <summary>Details</summary>
Motivation: 视频异常理解（VAU）任务缺乏有效的评估方法。现有基准使用n-gram指标（如BLEU、ROUGE-L）或基于LLM的评估，前者无法捕捉LVLM丰富、自由形式且视觉基础响应的特性，后者侧重于语言质量而非事实相关性，导致主观判断与人类感知不一致。

Method: 1）将VAU定义为三方面问题：事件（What）、参与实体（Who）和位置（Where）；2）提出FVScore评估指标，评估LVLM回答中关键视觉元素的存在，提供可解释的细粒度反馈；3）构建FineW3数据集，通过结构化全自动流程增强现有人工标注，添加高质量细粒度视觉信息。

Result: 人类评估显示，FVScore指标在异常感知方面与人类判断具有更好的对齐性。详细实验揭示了LVLM在需要空间和细粒度时间理解的异常事件感知方面存在关键局限性，尽管在粗粒度、静态信息和具有强视觉线索的事件上表现良好。

Conclusion: FineVAU基准通过细粒度的评估方法和数据集，为视频异常理解任务提供了更全面、更符合人类感知的评估框架，揭示了当前LVLM在时空理解方面的不足，为未来研究指明了方向。

Abstract: Video Anomaly Understanding (VAU) is a novel task focused on describing unusual occurrences in videos. Despite growing interest, the evaluation of VAU remains an open challenge. Existing benchmarks rely on n-gram-based metrics (e.g., BLEU, ROUGE-L) or LLM-based evaluation. The first fails to capture the rich, free-form, and visually grounded nature of LVLM responses, while the latter focuses on assessing language quality over factual relevance, often resulting in subjective judgments that are misaligned with human perception. In this work, we address this issue by proposing FineVAU, a new benchmark for VAU that shifts the focus towards rich, fine-grained and domain-specific understanding of anomalous videos. We formulate VAU as a three-fold problem, with the goal of comprehensively understanding key descriptive elements of anomalies in video: events (What), participating entities (Who) and location (Where). Our benchmark introduces a) FVScore, a novel, human-aligned evaluation metric that assesses the presence of critical visual elements in LVLM answers, providing interpretable, fine-grained feedback; and b) FineW3, a novel, comprehensive dataset curated through a structured and fully automatic procedure that augments existing human annotations with high quality, fine-grained visual information. Human evaluation reveals that our proposed metric has a superior alignment with human perception of anomalies in comparison to current approaches. Detailed experiments on FineVAU unveil critical limitations in LVLM's ability to perceive anomalous events that require spatial and fine-grained temporal understanding, despite strong performance on coarse grain, static information, and events with strong visual cues.

</details>


### [29] [Inference-Time Loss-Guided Colour Preservation in Diffusion Sampling](https://arxiv.org/abs/2601.17259)
*Angad Singh Ahuja,Aarush Ram Anandh*

Main category: cs.CV

TL;DR: 提出一种无需训练的推理时颜色控制方法，通过区域约束和梯度引导实现文本到图像生成中的精确颜色匹配


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散系统在精确颜色控制方面存在持续失败，特别是在设计导向的工作流程中，需要满足用户指定的颜色目标

Method: 结合ROI修复、背景潜在重新施加和梯度引导的复合损失函数，使用CIE Lab和线性RGB空间，通过CVaR风格和软最大值惩罚控制像素误差分布

Result: 该方法提供了实用的、无需训练的机制，能够实现目标颜色匹配，可集成到标准Stable Diffusion修复流程中

Conclusion: 提出的分布感知目标能够解决仅使用均值约束时产生的局部感知失败问题，为扩散模型提供了有效的颜色控制方法

Abstract: Precise color control remains a persistent failure mode in text-to-image diffusion systems, particularly in design-oriented workflows where outputs must satisfy explicit, user-specified color targets. We present an inference-time, region-constrained color preservation method that steers a pretrained diffusion model without any additional training. Our approach combines (i) ROI-based inpainting for spatial selectivity, (ii) background-latent re-imposition to prevent color drift outside the ROI, and (iii) latent nudging via gradient guidance using a composite loss defined in CIE Lab and linear RGB. The loss is constructed to control not only the mean ROI color but also the tail of the pixelwise error distribution through CVaR-style and soft-maximum penalties, with a late-start gate and a time-dependent schedule to stabilize guidance across denoising steps. We show that mean-only baselines can satisfy average color constraints while producing perceptually salient local failures, motivating our distribution-aware objective. The resulting method provides a practical, training-free mechanism for targeted color adherence that can be integrated into standard Stable Diffusion inpainting pipelines.

</details>


### [30] [Cross360: 360° Monocular Depth Estimation via Cross Projections Across Scales](https://arxiv.org/abs/2601.17271)
*Kun Huang,Fang-Lue Zhang,Neil Dodgson*

Main category: cs.CV

TL;DR: Cross360提出了一种基于交叉注意力的360°深度估计架构，通过整合局部切面投影特征和全局等距柱面投影特征来解决现有方法在全局连续性和局部一致性平衡上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有360°深度估计方法难以平衡全局连续性和局部一致性，局部补丁特征缺乏全局感知能力，而全局表示无法解决补丁边界处的特征提取不一致问题。

Method: 提出Cross360架构，包含两个核心模块：1) 交叉投影特征对齐模块，使用交叉注意力将局部切面投影特征与等距柱面投影的360°视野对齐；2) 渐进式注意力特征聚合模块，逐步细化多尺度特征。

Result: Cross360在大多数基准数据集上显著优于现有方法，特别是在完整360°图像可用的场景中，证明了其在准确和全局一致的深度估计方面的有效性。

Conclusion: 通过交叉注意力机制整合局部和全局信息，Cross360成功解决了360°深度估计中的全局连续性和局部一致性问题，为球形图像深度估计提供了有效的解决方案。

Abstract: 360° depth estimation is a challenging research problem due to the difficulty of finding a representation that both preserves global continuity and avoids distortion in spherical images. Existing methods attempt to leverage complementary information from multiple projections, but struggle with balancing global and local consistency. Their local patch features have limited global perception, and the combined global representation does not address discrepancies in feature extraction at the boundaries between patches. To address these issues, we propose Cross360, a novel cross-attention-based architecture integrating local and global information using less-distorted tangent patches along with equirectangular features. Our Cross Projection Feature Alignment module employs cross-attention to align local tangent projection features with the equirectangular projection's 360° field of view, ensuring each tangent projection patch is aware of the global context. Additionally, our Progressive Feature Aggregation with Attention module refines multi-scaled features progressively, enhancing depth estimation accuracy. Cross360 significantly outperforms existing methods across most benchmark datasets, especially those in which the entire 360° image is available, demonstrating its effectiveness in accurate and globally consistent depth estimation. The code and model are available at https://github.com/huangkun101230/Cross360.

</details>


### [31] [ClinNet: Evidential Ordinal Regression with Bilateral Asymmetry and Prototype Memory for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17315)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

TL;DR: ClinNet是一个用于膝关节骨关节炎分级的可信赖框架，通过证据序数回归方法解决传统确定性分类忽略疾病连续进展和标注不确定性的问题，在性能和不确定性估计方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎的X光影像分级具有挑战性，因为不同级别间差异细微、专家标注存在不确定性，且疾病进展具有固有的序数性质。传统深度学习方法将其视为确定性多分类问题，忽略了疾病连续进展和标注不确定性。

Method: ClinNet包含三个关键组件：(1) 双边不对称编码器，显式建模内外侧结构差异；(2) 诊断记忆库，维护类别原型以稳定特征表示；(3) 基于正态逆伽马分布的证据序数头，联合估计连续KL分级和认知不确定性。

Result: ClinNet在实验中取得了0.892的二次加权Kappa和0.768的准确率，统计显著优于现有最先进基线方法(p < 0.001)。模型的不确定性估计能成功识别分布外样本和潜在误诊。

Conclusion: ClinNet通过证据序数回归框架有效解决了膝关节骨关节炎分级中的不确定性问题，其不确定性估计能力为安全临床部署铺平了道路。

Abstract: Knee osteoarthritis (KOA) grading based on radiographic images is a critical yet challenging task due to subtle inter-grade differences, annotation uncertainty, and the inherently ordinal nature of disease progression. Conventional deep learning approaches typically formulate this problem as deterministic multi-class classification, ignoring both the continuous progression of degeneration and the uncertainty in expert annotations. In this work, we propose ClinNet, a novel trustworthy framework that addresses KOA grading as an evidential ordinal regression problem. The proposed method integrates three key components: (1) a Bilateral Asymmetry Encoder (BAE) that explicitly models medial-lateral structural discrepancies; (2) a Diagnostic Memory Bank that maintains class-wise prototypes to stabilize feature representations; and (3) an Evidential Ordinal Head based on the Normal-Inverse-Gamma (NIG) distribution to jointly estimate continuous KL grades and epistemic uncertainty. Extensive experiments demonstrate that ClinNet achieves a Quadratic Weighted Kappa of 0.892 and Accuracy of 0.768, statistically outperforming state-of-the-art baselines (p < 0.001). Crucially, we demonstrate that the model's uncertainty estimates successfully flag out-of-distribution samples and potential misdiagnoses, paving the way for safe clinical deployment.

</details>


### [32] [SkyReels-V3 Technique Report](https://arxiv.org/abs/2601.17323)
*Debang Li,Zhengcong Fei,Tuanhui Li,Yikun Dou,Zheng Chen,Jiangping Yang,Mingyuan Fan,Jingtao Xu,Jiahua Wang,Baoxuan Gu,Mingshan Chang,Yuqiang Xie,Binjie Mao,Youqiang Zhang,Nuo Pang,Hao Zhang,Yuzhe Jin,Zhiheng Xu,Dixuan Lin,Guibin Chen,Yahui Zhou*

Main category: cs.CV

TL;DR: SkyReels-V3是一个基于扩散Transformer的统一多模态上下文学习框架的条件视频生成模型，支持图像到视频合成、视频扩展和音频引导视频生成三种核心范式。


<details>
  <summary>Details</summary>
Motivation: 视频生成是构建世界模型的基础，多模态上下文推理是能力的关键测试。为了满足这一需求，需要开发能够支持多种生成范式的高质量视频生成模型。

Method: 基于扩散Transformer的统一多模态上下文学习框架。包括：1）图像到视频模型采用跨帧配对、图像编辑和语义重写的数据处理流程，结合图像视频混合训练和多分辨率联合优化；2）视频扩展模型整合时空一致性建模和大规模视频理解；3）语音头像模型训练首尾帧插入模式并重构关键帧推理范式。

Result: SkyReels-V3在视觉质量、指令跟随和特定方面指标上达到或接近最先进水平，接近领先的闭源系统性能。

Conclusion: SkyReels-V3通过统一的多模态上下文学习框架成功实现了三种核心视频生成范式，在保持视觉质量的同时优化了音视频同步，为构建世界模型提供了重要基础。

Abstract: Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.
  Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.

</details>


### [33] [Learning with Geometric Priors in U-Net Variants for Polyp Segmentation](https://arxiv.org/abs/2601.17331)
*Fabian Vazquez,Jose A. Nuñez,Diego Adame,Alissen Moreno,Augustin Zhan,Huimin Li,Jinghao Yang,Haoteng Tang,Bin Fu,Pengfei Gu*

Main category: cs.CV

TL;DR: 提出几何先验引导模块(GPM)，通过深度图将显式几何先验注入U-Net架构，提升息肉分割在低对比度或杂乱场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN、Transformer和Mamba的U-Net变体在息肉分割中难以捕捉几何和结构线索，特别是在低对比度或杂乱的结肠镜场景中。

Method: 提出几何先验引导模块(GPM)：1)在模拟的ColonDepth数据集上微调VGGT来估计息肉图像的深度图；2)用GPM处理深度图，将几何先验编码到编码器的特征图中；3)使用空间和通道注意力机制进一步精炼，强调局部空间和全局通道信息。

Result: 在五个公共息肉分割数据集上的广泛实验表明，该方法在三个强基线模型上均取得了一致的性能提升。

Conclusion: GPM是一种即插即用的模块，可以无缝集成到各种U-Net变体中，通过注入显式几何先验显著提升了息肉分割的准确性和鲁棒性。

Abstract: Accurate and robust polyp segmentation is essential for early colorectal cancer detection and for computer-aided diagnosis. While convolutional neural network-, Transformer-, and Mamba-based U-Net variants have achieved strong performance, they still struggle to capture geometric and structural cues, especially in low-contrast or cluttered colonoscopy scenes. To address this challenge, we propose a novel Geometric Prior-guided Module (GPM) that injects explicit geometric priors into U-Net-based architectures for polyp segmentation. Specifically, we fine-tune the Visual Geometry Grounded Transformer (VGGT) on a simulated ColonDepth dataset to estimate depth maps of polyp images tailored to the endoscopic domain. These depth maps are then processed by GPM to encode geometric priors into the encoder's feature maps, where they are further refined using spatial and channel attention mechanisms that emphasize both local spatial and global channel information. GPM is plug-and-play and can be seamlessly integrated into diverse U-Net variants. Extensive experiments on five public polyp segmentation datasets demonstrate consistent gains over three strong baselines. Code and the generated depth maps are available at: https://github.com/fvazqu/GPM-PolypSeg

</details>


### [34] [AGE-Net: Spectral--Spatial Fusion and Anatomical Graph Reasoning with Evidential Ordinal Regression for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17336)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

TL;DR: AGE-Net：一种基于ConvNeXt的膝关节X光片KL分级框架，通过谱空间融合、解剖图推理和差分细化技术，结合证据回归和序数约束，在KL分级任务上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 膝关节X光片的Kellgren-Lawrence（KL）分级自动化面临挑战：细微结构变化、长距离解剖依赖性和分级边界模糊性。现有方法难以有效处理这些复杂特征。

Method: 提出AGE-Net框架，包含三个核心模块：1）谱空间融合（SSF）捕获局部和全局特征；2）解剖图推理（AGR）建模解剖结构依赖关系；3）差分细化（DFR）处理边界模糊性。采用Normal-Inverse-Gamma证据回归头和成对序数排名约束来量化不确定性和保持标签序数性。

Result: 在膝关节KL数据集上，AGE-Net达到二次加权kappa（QWK）0.9017±0.0045，均方误差（MSE）0.2349±0.0028，优于强CNN基线。消融研究显示各模块均有稳定增益。还评估了不确定性质量、鲁棒性和可解释性。

Conclusion: AGE-Net通过多模态特征融合、解剖关系建模和不确定性量化，有效解决了KL分级中的挑战，在准确性和鲁棒性方面表现出色，为医学影像分析提供了新思路。

Abstract: Automated Kellgren--Lawrence (KL) grading from knee radiographs is challenging due to subtle structural changes, long-range anatomical dependencies, and ambiguity near grade boundaries. We propose AGE-Net, a ConvNeXt-based framework that integrates Spectral--Spatial Fusion (SSF), Anatomical Graph Reasoning (AGR), and Differential Refinement (DFR). To capture predictive uncertainty and preserve label ordinality, AGE-Net employs a Normal-Inverse-Gamma (NIG) evidential regression head and a pairwise ordinal ranking constraint. On a knee KL dataset, AGE-Net achieves a quadratic weighted kappa (QWK) of 0.9017 +/- 0.0045 and a mean squared error (MSE) of 0.2349 +/- 0.0028 over three random seeds, outperforming strong CNN baselines and showing consistent gains in ablation studies. We further outline evaluations of uncertainty quality, robustness, and explainability, with additional experimental figures to be included in the full manuscript.

</details>


### [35] [TEXTS-Diff: TEXTS-Aware Diffusion Model for Real-World Text Image Super-Resolution](https://arxiv.org/abs/2601.17340)
*Haodong He,Xin Zhan,Yancheng Bai,Rui Lan,Lei Sun,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出了Real-Texts数据集和TEXTS-Diff模型，用于解决真实世界文本图像超分辨率中文本区域恢复质量差的问题，在背景和文本区域都实现了高质量生成。


<details>
  <summary>Details</summary>
Motivation: 现有文本图像超分辨率方法面临两个主要问题：1) 现有数据集中文本图像稀缺，导致文本区域恢复效果差；2) 基于孤立文本样本的数据集限制了背景重建质量。需要构建更全面的真实世界文本图像数据集并开发能同时提升背景和文本区域质量的模型。

Method: 构建了Real-Texts大规模高质量数据集，包含中英文自然文本实例；提出了TEXTS-Aware Diffusion Model (TEXTS-Diff)，利用抽象概念提升对视觉场景中文本元素的理解，同时通过具体文本区域增强文本细节，减少文本区域的失真和幻觉伪影。

Result: 实验表明该方法在多个评估指标上达到最先进性能，在复杂场景中表现出优异的泛化能力和文本恢复准确性。代码、模型和数据集将全部开源。

Conclusion: Real-Texts数据集和TEXTS-Diff模型有效解决了真实世界文本图像超分辨率中的关键问题，在保持高质量视觉场景保真度的同时显著提升了文本区域的恢复质量。

Abstract: Real-world text image super-resolution aims to restore overall visual quality and text legibility in images suffering from diverse degradations and text distortions. However, the scarcity of text image data in existing datasets results in poor performance on text regions. In addition, datasets consisting of isolated text samples limit the quality of background reconstruction. To address these limitations, we construct Real-Texts, a large-scale, high-quality dataset collected from real-world images, which covers diverse scenarios and contains natural text instances in both Chinese and English. Additionally, we propose the TEXTS-Aware Diffusion Model (TEXTS-Diff) to achieve high-quality generation in both background and textual regions. This approach leverages abstract concepts to improve the understanding of textual elements within visual scenes and concrete text regions to enhance textual details. It mitigates distortions and hallucination artifacts commonly observed in text regions, while preserving high-quality visual scene fidelity. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple evaluation metrics, exhibiting superior generalization ability and text restoration accuracy in complex scenarios. All the code, model, and dataset will be released.

</details>


### [36] [Revisiting Lightweight Low-Light Image Enhancement: From a YUV Color Space Perspective](https://arxiv.org/abs/2601.17349)
*Hailong Yan,Shice Liu,Xiangtao Zhang,Lujian Yao,Fengxiang Yang,Jinwei Chen,Bo Li*

Main category: cs.CV

TL;DR: 提出了一种基于YUV颜色空间的轻量级低光图像增强方法，通过频域分析发现Y通道主要丢失低频内容，UV通道受高频噪声影响，并设计了针对性的双流注意力模块进行恢复。


<details>
  <summary>Details</summary>
Motivation: 在移动互联网时代，轻量级低光图像增强面临视觉质量和模型紧凑性的权衡。现有基于解耦策略的方法（如Retinex理论和YUV变换）忽视了通道特定的退化模式和跨通道交互，限制了性能提升。

Method: 通过频域分析确认YUV颜色空间对L3IE的优势，发现Y通道主要丢失低频内容，UV通道受高频噪声影响。提出YUV-based范式：1) Y通道使用双流全局-局部注意力模块；2) UV通道使用Y引导的局部感知频率注意力模块；3) 最终特征融合使用引导交互模块。

Result: 在多个基准测试中建立了新的最先进性能，以显著更少的参数数量提供了优越的视觉质量。

Conclusion: 提出的基于YUV颜色空间的轻量级低光图像增强方法通过针对不同通道特性的专门处理，在保持模型紧凑性的同时实现了卓越的视觉质量提升。

Abstract: In the current era of mobile internet, Lightweight Low-Light Image Enhancement (L3IE) is critical for mobile devices, which faces a persistent trade-off between visual quality and model compactness. While recent methods employ disentangling strategies to simplify lightweight architectural design, such as Retinex theory and YUV color space transformations, their performance is fundamentally limited by overlooking channel-specific degradation patterns and cross-channel interactions. To address this gap, we perform a frequency-domain analysis that confirms the superiority of the YUV color space for L3IE. We identify a key insight: the Y channel primarily loses low-frequency content, while the UV channels are corrupted by high-frequency noise. Leveraging this finding, we propose a novel YUV-based paradigm that strategically restores channels using a Dual-Stream Global-Local Attention module for the Y channel, a Y-guided Local-Aware Frequency Attention module for the UV channels, and a Guided Interaction module for final feature fusion. Extensive experiments validate that our model establishes a new state-of-the-art on multiple benchmarks, delivering superior visual quality with a significantly lower parameter count.

</details>


### [37] [NeRF-MIR: Towards High-Quality Restoration of Masked Images with Neural Radiance Fields](https://arxiv.org/abs/2601.17350)
*Xianliang Huang,Zhizhou Zhong,Shuhang Chen,Yi Xu,Juhong Guan,Shuigeng Zhou*

Main category: cs.CV

TL;DR: NeRF-MIR：一种用于修复掩码图像的神经渲染方法，通过PERE策略优化光线发射，PIRE机制进行渐进式修复，以及动态加权损失函数，在掩码图像修复任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: NeRF在新视角合成方面表现出色，但在处理自然场景中常见的损坏图像（如掩码图像）时仍有很大改进空间，这些损坏图像会显著影响NeRF的效果。

Method: 1. 提出PERE（基于补丁的熵光线发射）策略，优化光线发射分布以学习复杂图像纹理；2. 引入PIRE（渐进迭代修复）机制，通过自训练过程逐步修复掩码区域；3. 设计动态加权损失函数，自动重新校准掩码区域的损失权重；4. 构建三个掩码数据集以支持NeRF-based掩码图像修复研究。

Result: 在真实数据和构建的数据集上进行的大量实验表明，NeRF-MIR在掩码图像修复任务上优于其他对比方法。

Conclusion: NeRF-MIR展示了NeRF在掩码图像修复领域的潜力，通过创新的光线发射策略、渐进修复机制和动态损失函数，有效提升了掩码图像修复的性能。

Abstract: Neural Radiance Fields (NeRF) have demonstrated remarkable performance in novel view synthesis. However, there is much improvement room on restoring 3D scenes based on NeRF from corrupted images, which are common in natural scene captures and can significantly impact the effectiveness of NeRF. This paper introduces NeRF-MIR, a novel neural rendering approach specifically proposed for the restoration of masked images, demonstrating the potential of NeRF in this domain. Recognizing that randomly emitting rays to pixels in NeRF may not effectively learn intricate image textures, we propose a \textbf{P}atch-based \textbf{E}ntropy for \textbf{R}ay \textbf{E}mitting (\textbf{PERE}) strategy to distribute emitted rays properly. This enables NeRF-MIR to fuse comprehensive information from images of different views. Additionally, we introduce a \textbf{P}rogressively \textbf{I}terative \textbf{RE}storation (\textbf{PIRE}) mechanism to restore the masked regions in a self-training process. Furthermore, we design a dynamically-weighted loss function that automatically recalibrates the loss weights for masked regions. As existing datasets do not support NeRF-based masked image restoration, we construct three masked datasets to simulate corrupted scenarios. Extensive experiments on real data and constructed datasets demonstrate the superiority of NeRF-MIR over its counterparts in masked image restoration.

</details>


### [38] [HyDeMiC: A Deep Learning-based Mineral Classifier using Hyperspectral Data](https://arxiv.org/abs/2601.17352)
*M. L. Mamud,Piyoosh Jaysaval,Frederick D Day-Lewis,M. K. Mudunuru*

Main category: cs.CV

TL;DR: 本文提出HyDeMiC（基于深度学习的矿物分类器），一种用于高光谱矿物分类的CNN模型，在噪声数据下表现鲁棒。


<details>
  <summary>Details</summary>
Motivation: 传统高光谱矿物分类方法（如判别分析、逻辑回归、支持向量机）在处理环境噪声、传感器限制和高维数据计算复杂性方面存在困难，需要更鲁棒的分类方法。

Method: 开发了HyDeMiC CNN模型，使用USGS库中115种矿物的实验室测量高光谱数据进行训练。通过将参考矿物光谱与HSI传感器响应函数卷积生成训练数据集，并以三种含铜矿物作为案例研究。在1%、2%、5%和10%噪声水平的合成2D高光谱数据集上评估模型性能。

Result: HyDeMiC在干净和低噪声数据集上实现了近乎完美的分类准确率（MCC = 1.00），在中等噪声条件下仍保持强劲性能，显示出对噪声的鲁棒性。

Conclusion: HyDeMiC在存在中等噪声的情况下表现出鲁棒性，突显了其在现实世界高光谱成像应用中的潜力，其中噪声通常是重要挑战。

Abstract: Hyperspectral imaging (HSI) has emerged as a powerful remote sensing tool for mineral exploration, capitalizing on unique spectral signatures of minerals. However, traditional classification methods such as discriminant analysis, logistic regression, and support vector machines often struggle with environmental noise in data, sensor limitations, and the computational complexity of analyzing high-dimensional HSI data. This study presents HyDeMiC (Hyperspectral Deep Learning-based Mineral Classifier), a convolutional neural network (CNN) model designed for robust mineral classification under noisy data. To train HyDeMiC, laboratory-measured hyperspectral data for 115 minerals spanning various mineral groups were used from the United States Geological Survey (USGS) library. The training dataset was generated by convolving reference mineral spectra with an HSI sensor response function. These datasets contained three copper-bearing minerals, Cuprite, Malachite, and Chalcopyrite, used as case studies for performance demonstration. The trained CNN model was evaluated on several synthetic 2D hyperspectral datasets with noise levels of 1%, 2%, 5%, and 10%. Our noisy data analysis aims to replicate realistic field conditions. The HyDeMiC's performance was assessed using the Matthews Correlation Coefficient (MCC), providing a comprehensive measure across different noise regimes. Results demonstrate that HyDeMiC achieved near-perfect classification accuracy (MCC = 1.00) on clean and low-noise datasets and maintained strong performance under moderate noise conditions. These findings emphasize HyDeMiC's robustness in the presence of moderate noise, highlighting its potential for real-world applications in hyperspectral imaging, where noise is often a significant challenge.

</details>


### [39] [PocketGS: On-Device Training of 3D Gaussian Splatting for High Perceptual Modeling](https://arxiv.org/abs/2601.17354)
*Wenzhi Guo,Guangchi Fang,Shu Yang,Bing Wang*

Main category: cs.CV

TL;DR: PocketGS：一种移动端3D高斯泼溅训练方法，在资源受限的移动设备上实现高效高保真3D场景建模


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法依赖资源无约束的训练假设，无法在训练时间短、内存有限的移动设备上运行。需要一种能在移动设备硬件约束下实现高质量3D场景建模的解决方案。

Method: 提出PocketGS移动场景建模范式，包含三个协同设计的操作符：G操作符构建几何保真的点云先验；I操作符注入局部表面统计信息以初始化各向异性高斯分布，减少早期条件差距；T操作符通过缓存中间结果和索引映射梯度散射来展开alpha合成，实现稳定的移动端反向传播。

Result: 实验表明PocketGS能够超越主流工作站3DGS基线，提供高质量重建结果，实现了完全在设备上的实用捕获到渲染工作流程。

Conclusion: PocketGS成功解决了标准3DGS在移动设备上的基本矛盾，满足了训练效率、内存紧凑性和建模保真度的竞争需求，为移动端3D场景建模提供了可行解决方案。

Abstract: Efficient and high-fidelity 3D scene modeling is a long-standing pursuit in computer graphics. While recent 3D Gaussian Splatting (3DGS) methods achieve impressive real-time modeling performance, they rely on resource-unconstrained training assumptions that fail on mobile devices, which are limited by minute-scale training budgets and hardware-available peak-memory. We present PocketGS, a mobile scene modeling paradigm that enables on-device 3DGS training under these tightly coupled constraints while preserving high perceptual fidelity. Our method resolves the fundamental contradictions of standard 3DGS through three co-designed operators: G builds geometry-faithful point-cloud priors; I injects local surface statistics to seed anisotropic Gaussians, thereby reducing early conditioning gaps; and T unrolls alpha compositing with cached intermediates and index-mapped gradient scattering for stable mobile backpropagation. Collectively, these operators satisfy the competing requirements of training efficiency, memory compactness, and modeling fidelity. Extensive experiments demonstrate that PocketGS is able to outperform the powerful mainstream workstation 3DGS baseline to deliver high-quality reconstructions, enabling a fully on-device, practical capture-to-rendering workflow.

</details>


### [40] [UCAD: Uncertainty-guided Contour-aware Displacement for semi-supervised medical image segmentation](https://arxiv.org/abs/2601.17366)
*Chengbo Ding,Fenghe Tang,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: UCAD提出了一种基于不确定性引导的轮廓感知位移框架，用于半监督医学图像分割，通过超像素生成解剖一致区域，并利用不确定性指导选择具有挑战性的区域进行位移，以增强一致性学习。


<details>
  <summary>Details</summary>
Motivation: 现有半监督分割中的位移策略仅操作矩形区域，忽略了解剖结构，导致边界扭曲和语义不一致。为了解决这些问题，需要一种能够保留轮廓感知语义并增强一致性学习的方法。

Method: UCAD框架：1）利用超像素生成与解剖边界对齐的解剖一致区域；2）采用不确定性引导的选择机制，选择性地位移具有挑战性的区域以增强一致性学习；3）提出动态不确定性加权一致性损失，自适应稳定训练并有效正则化未标记区域。

Result: 大量实验表明，UCAD在有限标注条件下，持续优于最先进的半监督分割方法，实现了优越的分割精度。

Conclusion: UCAD通过结合超像素生成解剖一致区域和不确定性引导的位移策略，有效解决了现有方法中的边界扭曲和语义不一致问题，为半监督医学图像分割提供了更准确和鲁棒的解决方案。

Abstract: Existing displacement strategies in semi-supervised segmentation only operate on rectangular regions, ignoring anatomical structures and resulting in boundary distortions and semantic inconsistency. To address these issues, we propose UCAD, an Uncertainty-Guided Contour-Aware Displacement framework for semi-supervised medical image segmentation that preserves contour-aware semantics while enhancing consistency learning. Our UCAD leverages superpixels to generate anatomically coherent regions aligned with anatomy boundaries, and an uncertainty-guided selection mechanism to selectively displace challenging regions for better consistency learning. We further propose a dynamic uncertainty-weighted consistency loss, which adaptively stabilizes training and effectively regularizes the model on unlabeled regions. Extensive experiments demonstrate that UCAD consistently outperforms state-of-the-art semi-supervised segmentation methods, achieving superior segmentation accuracy under limited annotation. The code is available at:https://github.com/dcb937/UCAD.

</details>


### [41] [Physical Prompt Injection Attacks on Large Vision-Language Models](https://arxiv.org/abs/2601.17383)
*Chen Ling,Kai Hu,Hangcheng Liu,Xingshuo Han,Tianwei Zhang,Changhai Ou*

Main category: cs.CV

TL;DR: 论文提出首个物理提示注入攻击（PPIA），这是一种黑盒、查询无关的攻击方法，通过在物理对象上嵌入恶意排版指令来攻击大型视觉语言模型，无需访问模型内部，攻击成功率高达98%。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在开放物理环境中的感知和推理应用日益广泛，但现有攻击方法要么需要访问输入通道，要么依赖用户查询知识，这些假设在实际部署中很少成立。因此需要一种更实用的攻击方法来评估模型的安全性。

Method: 提出物理提示注入攻击（PPIA），结合离线选择高可识别性和语义有效的视觉提示，以及基于时空注意力的环境感知策略性放置，确保注入的提示既可感知又能影响模型行为。

Result: 在10个最先进的LVLMs上进行评估，包括模拟和真实世界环境，涵盖视觉问答、规划和导航等任务，攻击成功率高达98%，在不同物理条件（距离、视角、光照）下表现出强鲁棒性。

Conclusion: PPIA是首个黑盒、查询无关的物理提示注入攻击，无需访问模型内部，仅通过视觉观察即可实施，揭示了LVLMs在现实世界部署中的安全漏洞，为模型安全性评估提供了新视角。

Abstract: Large Vision-Language Models (LVLMs) are increasingly deployed in real-world intelligent systems for perception and reasoning in open physical environments. While LVLMs are known to be vulnerable to prompt injection attacks, existing methods either require access to input channels or depend on knowledge of user queries, assumptions that rarely hold in practical deployments. We propose the first Physical Prompt Injection Attack (PPIA), a black-box, query-agnostic attack that embeds malicious typographic instructions into physical objects perceivable by the LVLM. PPIA requires no access to the model, its inputs, or internal pipeline, and operates solely through visual observation. It combines offline selection of highly recognizable and semantically effective visual prompts with strategic environment-aware placement guided by spatiotemporal attention, ensuring that the injected prompts are both perceivable and influential on model behavior. We evaluate PPIA across 10 state-of-the-art LVLMs in both simulated and real-world settings on tasks including visual question answering, planning, and navigation, PPIA achieves attack success rates up to 98%, with strong robustness under varying physical conditions such as distance, viewpoint, and illumination. Our code is publicly available at https://github.com/2023cghacker/Physical-Prompt-Injection-Attack.

</details>


### [42] [ONRW: Optimizing inversion noise for high-quality and robust watermark](https://arxiv.org/abs/2601.17388)
*Xuan Ding,Xiu Yan,Chuanlong Xie,Yao Zhu*

Main category: cs.CV

TL;DR: 基于扩散模型的高质量鲁棒水印框架，通过空文本优化将干净图像转换为反转噪声，在潜在空间优化后通过扩散模型迭代去噪生成高质量水印图像，显著提升对图像损坏的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习水印系统虽然能在图像中隐藏水印且对图像质量影响小，但在传输过程中遇到图像损坏时缺乏鲁棒性，这限制了其实际应用价值。

Method: 1. 通过空文本优化过程将干净图像转换为反转噪声；2. 在潜在空间优化反转噪声；3. 通过扩散模型的迭代去噪过程生成高质量水印图像；4. 引入自注意力约束和伪掩码策略防止反转噪声优化扭曲图像原始语义。

Result: 在COCO数据集上，该方法在12种不同图像变换中平均比稳定签名方法高出10%，实验结果表明该方法对各种图像损坏具有优越性能。

Conclusion: 提出的基于扩散模型的水印框架既能保证水印图像的视觉质量，又能增强水印对各种损坏的鲁棒性，解决了现有深度学习水印系统鲁棒性不足的问题。

Abstract: Watermarking methods have always been effective means of protecting intellectual property, yet they face significant challenges. Although existing deep learning-based watermarking systems can hide watermarks in images with minimal impact on image quality, they often lack robustness when encountering image corruptions during transmission, which undermines their practical application value. To this end, we propose a high-quality and robust watermark framework based on the diffusion model. Our method first converts the clean image into inversion noise through a null-text optimization process, and after optimizing the inversion noise in the latent space, it produces a high-quality watermarked image through an iterative denoising process of the diffusion model. The iterative denoising process serves as a powerful purification mechanism, ensuring both the visual quality of the watermarked image and enhancing the robustness of the watermark against various corruptions. To prevent the optimizing of inversion noise from distorting the original semantics of the image, we specifically introduced self-attention constraints and pseudo-mask strategies. Extensive experimental results demonstrate the superior performance of our method against various image corruptions. In particular, our method outperforms the stable signature method by an average of 10\% across 12 different image transformations on COCO datasets. Our codes are available at https://github.com/920927/ONRW.

</details>


### [43] [ReLE: A Scalable System and Structured Benchmark for Diagnosing Capability Anisotropy in Chinese LLMs](https://arxiv.org/abs/2601.17399)
*Rui Fang,Jian Li,Wei Chen,Bin Hu,Ying-Cong Chen,Xin Tang,Liang Diao*

Main category: cs.CV

TL;DR: ReLE是一个用于诊断大语言模型能力各向异性的可扩展评估系统，通过符号化混合评分机制和动态方差感知调度器，在减少70%计算成本的同时保持高排名相关性，揭示模型高度专业化而非普遍优越的特性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在中文理解方面进展迅速，但准确评估其能力面临基准测试饱和和计算成本高昂的挑战。静态排行榜只能提供快照排名，往往掩盖了能力之间的结构性权衡。需要一种能够诊断能力各向异性（模型在不同领域表现不均匀性）的系统化评估方法。

Method: 提出ReLE系统，包含两个核心方法：1）符号化混合评分机制，消除推理任务中基于嵌入的误判；2）基于Neyman分配和噪声校正的动态方差感知调度器，显著降低计算成本。系统评估了304个模型（189个商业模型，115个开源模型），覆盖207,843个样本的领域×能力正交矩阵。

Result: 与全量评估相比，ReLE减少70%计算成本的同时保持排名相关性ρ=0.96。分析显示聚合排名对权重方案高度敏感：模型在ReLE中的排名稳定性振幅为11.4，而传统基准约为5.0，证实现代模型高度专业化而非普遍优越。

Conclusion: ReLE不是替代全面静态基准测试，而是作为演化模型景观的高频诊断监控工具。它揭示了模型能力各向异性的重要性，为更精细化的模型评估提供了方法论基础。

Abstract: Large Language Models (LLMs) have achieved rapid progress in Chinese language understanding, yet accurately evaluating their capabilities remains challenged by benchmark saturation and prohibitive computational costs. While static leaderboards provide snapshot rankings, they often mask the structural trade-offs between capabilities. In this work, we present ReLE (Robust Efficient Live Evaluation), a scalable system designed to diagnose Capability Anisotropy, the non-uniformity of model performance across domains. Using ReLE, we evaluate 304 models (189 commercial, 115 open-source) across a Domain $\times$ Capability orthogonal matrix comprising 207,843 samples. We introduce two methodological contributions to address current evaluation pitfalls: (1) A Symbolic-Grounded Hybrid Scoring Mechanism that eliminates embedding-based false positives in reasoning tasks; (2) A Dynamic Variance-Aware Scheduler based on Neyman allocation with noise correction, which reduces compute costs by 70\% compared to full-pass evaluations while maintaining a ranking correlation of $ρ=0.96$. Our analysis reveals that aggregate rankings are highly sensitive to weighting schemes: models exhibit a Rank Stability Amplitude (RSA) of 11.4 in ReLE versus $\sim$5.0 in traditional benchmarks, confirming that modern models are highly specialized rather than generally superior. We position ReLE not as a replacement for comprehensive static benchmarks, but as a high-frequency diagnostic monitor for the evolving model landscape.

</details>


### [44] [Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity](https://arxiv.org/abs/2601.17408)
*Harsharaj Pathak,Vineeth N Balasubramanian*

Main category: cs.CV

TL;DR: 该论文提出了一种基于邻域签名的源自由域自适应方法，通过优化目标域样本预测的相似性和差异性，使用单一损失函数实现更好的域适应效果。


<details>
  <summary>Details</summary>
Motivation: 现有源自由域自适应方法大多依赖邻域一致性概念，但容易受到误导性邻域信息的影响而产生错误。需要解决邻域信息噪声问题，学习更具信息性的聚类。

Method: 提出邻域签名概念，通过优化目标域样本预测的相似性和差异性来学习更准确的聚类。方法仅使用单一损失项，专门针对目标域样本的预测进行优化。

Result: 在具有挑战性的VisDA数据集上超越了现有方法，在其他基准数据集上也取得了有竞争力的结果。

Conclusion: 通过邻域签名概念可以有效缓解噪声邻域的影响，学习更具信息性的聚类，仅使用单一损失函数就能实现有效的源自由域自适应。

Abstract: Source-Free Domain Adaptation (SFDA) is an emerging area of research that aims to adapt a model trained on a labeled source domain to an unlabeled target domain without accessing the source data. Most of the successful methods in this area rely on the concept of neighborhood consistency but are prone to errors due to misleading neighborhood information. In this paper, we explore this approach from the point of view of learning more informative clusters and mitigating the effect of noisy neighbors using a concept called neighborhood signature, and demonstrate that adaptation can be achieved using just a single loss term tailored to optimize the similarity and dissimilarity of predictions of samples in the target domain. In particular, our proposed method outperforms existing methods in the challenging VisDA dataset while also yielding competitive results on other benchmark datasets.

</details>


### [45] [Cloud-Enabled IoT System for Real-Time Environmental Monitoring and Remote Device Control Using Firebase](https://arxiv.org/abs/2601.17414)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种基于Firebase云数据库的物联网系统，用于环境监测和设备控制，实现了实时数据同步和远程控制功能。


<details>
  <summary>Details</summary>
Motivation: 物联网设备激增带来了远程监控和控制的新机遇，但传统监控系统在实时数据访问、远程可控性和云集成方面存在局限性。

Method: 使用ESP32微控制器连接DHT22温湿度传感器和HC-SR04超声波距离传感器，通过Firebase实时数据库实现数据同步，并提供基于云的界面远程控制两个LED指示灯。

Result: 实验结果显示数据传输成功率达99.2%，实时控制延迟低于1.5秒，具备持久数据存储功能，系统总实现成本为32.50美元。

Conclusion: 该系统架构为各种物联网应用提供了可扩展框架，Firebase集成无需复杂服务器基础设施，使资源有限的开发者和研究人员也能实现先进的物联网应用。

Abstract: The proliferation of Internet of Things (IoT) devices has created unprecedented opportunities for remote monitoring and control applications across various domains. Traditional monitoring systems often suffer from limitations in real-time data accessibility, remote controllability, and cloud integration. This paper presents a cloud-enabled IoT system that leverages Google's Firebase Realtime Database for synchronized environmental monitoring and device control. The system utilizes an ESP32 microcontroller to interface with a DHT22 temperature/humidity sensor and an HC-SR04 ultrasonic distance sensor, while enabling remote control of two LED indicators through a cloud-based interface. Real-time sensor data is transmitted to Firebase, providing a synchronized platform accessible from multiple devices simultaneously. Experimental results demonstrate reliable data transmission with 99.2\% success rate, real-time control latency under 1.5 seconds, and persistent data storage for historical analysis. The system architecture offers a scalable framework for various IoT applications, from smart home automation to industrial monitoring, with a total implementation cost of \$32.50. The integration of Firebase provides robust cloud capabilities without requiring complex server infrastructure, making advanced IoT applications accessible to developers and researchers with limited resources.

</details>


### [46] [CoT-Seg: Rethinking Segmentation with Chain-of-Thought Reasoning and Self-Correction](https://arxiv.org/abs/2601.17420)
*Shiu-hong Kao,Chak Ho Huang,Huaiqian Liu,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.CV

TL;DR: CoT-Seg是一个无需训练的分割框架，通过结合思维链推理和自校正机制来处理复杂查询和域外图像的分割任务


<details>
  <summary>Details</summary>
Motivation: 现有推理分割方法在处理复杂查询和域外图像时表现不足，受人类解决难题时逐步思考、查找信息、评估和修正的启发，需要开发一个能够模拟人类思考过程的系统

Method: CoT-Seg利用预训练MLLMs（GPT-4o）的推理能力，将查询分解为元指令，从图像中提取细粒度语义，识别隐含或复杂提示下的目标对象，并包含自校正阶段：模型评估自身分割结果，识别不匹配，迭代优化掩码

Result: CoT-Seg显著提高了分割的可靠性和鲁棒性，特别是在模糊或易出错的情况下，并引入了新的数据集ReasonSeg-Hard来展示其处理挑战性案例的能力

Conclusion: 结合思维链推理和自校正为视觉语言驱动的分割提供了一个强大的范式，通过逐步推理和迭代修正机制有效处理复杂分割任务

Abstract: Existing works of reasoning segmentation often fall short in complex cases, particularly when addressing complicated queries and out-of-domain images. Inspired by the chain-of-thought reasoning, where harder problems require longer thinking steps/time, this paper aims to explore a system that can think step-by-step, look up information if needed, generate results, self-evaluate its own results, and refine the results, in the same way humans approach harder questions. We introduce CoT-Seg, a training-free framework that rethinks reasoning segmentation by combining chain-of-thought reasoning with self-correction. Instead of fine-tuning, CoT-Seg leverages the inherent reasoning ability of pre-trained MLLMs (GPT-4o) to decompose queries into meta-instructions, extract fine-grained semantics from images, and identify target objects even under implicit or complex prompts. Moreover, CoT-Seg incorporates a self-correction stage: the model evaluates its own segmentation against the original query and reasoning trace, identifies mismatches, and iteratively refines the mask. This tight integration of reasoning and correction significantly improves reliability and robustness, especially in ambiguous or error-prone cases. Furthermore, our CoT-Seg framework allows easy incorporation of retrieval-augmented reasoning, enabling the system to access external knowledge when the input lacks sufficient information. To showcase CoT-Seg's ability to handle very challenging cases ,we introduce a new dataset ReasonSeg-Hard. Our results highlight that combining chain-of-thought reasoning, self-correction, offers a powerful paradigm for vision-language integration driven segmentation.

</details>


### [47] [ReflexSplit: Single Image Reflection Separation via Layer Fusion-Separation](https://arxiv.org/abs/2601.17468)
*Chia-Ming Lee,Yu-Fan Lin,Jing-Hui Jung,Yu-Jou Hsiao,Chih-Chung Hsu,Yu-Lun Liu*

Main category: cs.CV

TL;DR: ReflexSplit：一种用于单图像反射分离的双流框架，通过跨尺度门控融合、层融合-分离块和课程训练解决非线性混合下的传输-反射混淆问题


<details>
  <summary>Details</summary>
Motivation: 现有单图像反射分离方法在非线性混合情况下存在传输-反射混淆问题，特别是在深层解码器中，这是由于隐式融合机制和多尺度协调不足导致的

Method: 提出ReflexSplit双流框架，包含三个创新：1) 跨尺度门控融合(CrGF)自适应聚合语义先验、纹理细节和解码器上下文；2) 层融合-分离块(LFSB)交替进行融合和分离；3) 课程训练通过深度依赖初始化和逐轮预热增强差分分离

Result: 在合成和真实世界基准测试中展示了最先进的性能，具有优越的感知质量和鲁棒泛化能力

Conclusion: ReflexSplit通过创新的双流架构和训练策略，有效解决了单图像反射分离中的传输-反射混淆问题，在多个基准测试中取得了优异性能

Abstract: Single Image Reflection Separation (SIRS) disentangles mixed images into transmission and reflection layers. Existing methods suffer from transmission-reflection confusion under nonlinear mixing, particularly in deep decoder layers, due to implicit fusion mechanisms and inadequate multi-scale coordination. We propose ReflexSplit, a dual-stream framework with three key innovations. (1) Cross-scale Gated Fusion (CrGF) adaptively aggregates semantic priors, texture details, and decoder context across hierarchical depths, stabilizing gradient flow and maintaining feature consistency. (2) Layer Fusion-Separation Blocks (LFSB) alternate between fusion for shared structure extraction and differential separation for layer-specific disentanglement. Inspired by Differential Transformer, we extend attention cancellation to dual-stream separation via cross-stream subtraction. (3) Curriculum training progressively strengthens differential separation through depth-dependent initialization and epoch-wise warmup. Extensive experiments on synthetic and real-world benchmarks demonstrate state-of-the-art performance with superior perceptual quality and robust generalization. Our code is available at https://github.com/wuw2135/ReflexSplit.

</details>


### [48] [PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors](https://arxiv.org/abs/2601.17470)
*Chia-Ming Lee,Yu-Fan Lin,Yu-Jou Hsiao,Jing-Hui Jung,Yu-Lun Liu,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: PhaSR通过物理对齐的双层先验对齐方法解决阴影去除问题，在单光源阴影到多光源环境照明下都能实现鲁棒性能


<details>
  <summary>Details</summary>
Motivation: 在不同光照条件下进行阴影去除需要将光照与固有反射率分离，当物理先验未正确对齐时这一挑战尤为突出

Method: 提出PhaSR方法，包含两个核心组件：1) 物理对齐归一化(PAN)：通过灰世界归一化、对数域Retinex分解和动态范围重组进行闭式光照校正；2) 几何语义矫正注意力(GSRA)：将差分注意力扩展到跨模态对齐，协调深度几何与DINO-v2语义嵌入

Result: 实验显示在阴影去除方面具有竞争力，复杂度更低，并能泛化到传统方法在多光源照明下失败的环境照明场景

Conclusion: PhaSR通过物理对齐的双层先验对齐方法有效解决了阴影去除问题，特别是在多光源环境照明条件下表现出色

Abstract: Shadow removal under diverse lighting conditions requires disentangling illumination from intrinsic reflectance, a challenge compounded when physical priors are not properly aligned. We propose PhaSR (Physically Aligned Shadow Removal), addressing this through dual-level prior alignment to enable robust performance from single-light shadows to multi-source ambient lighting. First, Physically Aligned Normalization (PAN) performs closed-form illumination correction via Gray-world normalization, log-domain Retinex decomposition, and dynamic range recombination, suppressing chromatic bias. Second, Geometric-Semantic Rectification Attention (GSRA) extends differential attention to cross-modal alignment, harmonizing depth-derived geometry with DINO-v2 semantic embeddings to resolve modal conflicts under varying illumination. Experiments show competitive performance in shadow removal with lower complexity and generalization to ambient lighting where traditional methods fail under multi-source illumination. Our source code is available at https://github.com/ming053l/PhaSR.

</details>


### [49] [FMIR, a foundation model-based Image Registration Framework for Robust Image Registration](https://arxiv.org/abs/2601.17529)
*Fengting Zhang,Yue He,Qinghao Liu,Yaonan Wang,Xiang Chen,Hang Zhang*

Main category: cs.CV

TL;DR: FMIR是一个基于基础模型的医学图像配准框架，通过在单个数据集上训练，实现了域内SOTA性能，同时在域外图像上保持鲁棒配准能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习虽然显著提升了医学图像配准速度，但其临床应用受到泛化能力不足的限制，特别是在医学数据集通常规模较小的情况下。需要解决模型在训练域之外的泛化问题。

Method: FMIR结合了基于基础模型的特征编码器（用于提取解剖结构）和通用配准头，采用通道正则化策略，仅需在单个数据集上进行训练。

Result: FMIR在域内性能达到SOTA水平，同时在域外图像上保持鲁棒的配准能力，展示了在有限资源下构建可泛化医学成像基础模型的可行路径。

Conclusion: 该研究提出了一种解决医学图像配准泛化问题的新方法，通过基础模型框架在有限资源下实现了良好的域内和域外性能，为构建可泛化的医学成像基础模型提供了可行方案。

Abstract: Deep learning has revolutionized medical image registration by achieving unprecedented speeds, yet its clinical application is hindered by a limited ability to generalize beyond the training domain, a critical weakness given the typically small scale of medical datasets. In this paper, we introduce FMIR, a foundation model-based registration framework that overcomes this limitation.Combining a foundation model-based feature encoder for extracting anatomical structures with a general registration head, and trained with a channel regularization strategy on just a single dataset, FMIR achieves state-of-the-art(SOTA) in-domain performance while maintaining robust registration on out-of-domain images.Our approach demonstrates a viable path toward building generalizable medical imaging foundation models with limited resources. The code is available at https://github.com/Monday0328/FMIR.git.

</details>


### [50] [Will It Zero-Shot?: Will It Zero-Shot?: Predicting Zero-Shot Classification Performance For Arbitrary Queries](https://arxiv.org/abs/2601.17535)
*Kevin Robbins,Xiaotong Liu,Yu Wu,Le Sun,Grady McPeak,Abby Stylianou,Robert Pless*

Main category: cs.CV

TL;DR: 本文提出了一种通过生成合成图像来评估视觉语言模型在特定任务上零样本性能的方法，相比仅使用文本的方法能更准确地预测模型在实际应用中的表现。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（如CLIP）虽然能让用户通过简单命名类别来构建视觉分类器，但模型在一个领域表现良好可能在另一个领域失败，非专家用户缺乏直接评估所选VLM是否适用于其问题的方法。

Method: 基于先前仅使用文本比较评估模型性能的工作，探索了生成与任务相关的合成图像来评估和优化零样本准确率预测的方法。通过生成图像来增强基线文本评分，并为用户提供用于评估的图像类型反馈。

Result: 在标准CLIP基准数据集上的实验表明，相比仅使用文本的方法，基于图像的方法能显著提高零样本性能预测的质量，帮助用户在没有标注样本的情况下判断VLM是否适用于其应用。

Conclusion: 生成合成图像的方法能有效改进视觉语言模型零样本性能的预测准确性，为用户提供更可靠的模型适用性评估工具，同时通过可视化反馈帮助用户理解评估依据。

Abstract: Vision-Language Models like CLIP create aligned embedding spaces for text and images, making it possible for anyone to build a visual classifier by simply naming the classes they want to distinguish. However, a model that works well in one domain may fail in another, and non-expert users have no straightforward way to assess whether their chosen VLM will work on their problem. We build on prior work using text-only comparisons to evaluate how well a model works for a given natural language task, and explore approaches that also generate synthetic images relevant to that task to evaluate and refine the prediction of zero-shot accuracy. We show that generated imagery to the baseline text-only scores substantially improves the quality of these predictions. Additionally, it gives a user feedback on the kinds of images that were used to make the assessment. Experiments on standard CLIP benchmark datasets demonstrate that the image-based approach helps users predict, without any labeled examples, whether a VLM will be effective for their application.

</details>


### [51] [Saliency Driven Imagery Preprocessing for Efficient Compression -- Industrial Paper](https://arxiv.org/abs/2601.17555)
*Justin Downes,Sam Saltwick,Anthony Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种基于显著性图的卫星图像预处理方法，通过可变大小的平滑核映射到不同的量化显著性水平，优化传统有损压缩编码标准，实现单张大型卫星图像内的可变比特率压缩。


<details>
  <summary>Details</summary>
Motivation: 卫星图像每天产生数百TB数据，存储和带宽成本高昂。许多下游任务只对图像中的小区域感兴趣，这些感兴趣区域因任务而异，但一旦确定，可用于优化图像编码。传统图像编码方法对整个图像同等处理，而基于显著性图的引导方法可以聚焦重要区域。

Method: 使用可变大小的平滑核映射到不同的量化显著性水平来处理图像像素，优化下游压缩和编码方案。通过显著性图驱动的图像预处理技术与传统有损压缩编码标准结合，实现单张大型卫星图像内的可变比特率压缩。

Result: 该方法能够根据显著性信息在单张大型卫星图像内实现可变比特率压缩，相比传统对整个图像同等处理的方法，能够更有效地优化存储和带宽使用。

Conclusion: 基于显著性图的图像预处理技术可以与传统压缩编码标准有效结合，为卫星图像压缩提供了一种新的优化方法，能够根据下游任务需求聚焦重要区域，降低存储和带宽成本。

Abstract: The compression of satellite imagery remains an important research area as hundreds of terabytes of images are collected every day, which drives up storage and bandwidth costs. Although progress has been made in increasing the resolution of these satellite images, many downstream tasks are only interested in small regions of any given image. These areas of interest vary by task but, once known, can be used to optimize how information within the image is encoded. Whereas standard image encoding methods, even those optimized for remote sensing, work on the whole image equally, there are emerging methods that can be guided by saliency maps to focus on important areas. In this work we show how imagery preprocessing techniques driven by saliency maps can be used with traditional lossy compression coding standards to create variable rate image compression within a single large satellite image. Specifically, we use variable sized smoothing kernels that map to different quantized saliency levels to process imagery pixels in order to optimize downstream compression and encoding schemes.

</details>


### [52] [Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization](https://arxiv.org/abs/2601.17586)
*Sebastian Doerrich,Francesco Di Salvo,Jonas Alle,Christian Ledig*

Main category: cs.CV

TL;DR: 提出Stylizing ViT，一种基于Vision Transformer的编码器，通过共享权重的注意力块同时处理自注意力和交叉注意力，在保持解剖结构一致性的同时实现风格迁移，用于医学图像分析的领域泛化。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析中的深度学习模型由于数据异质性和稀缺性，在不同领域和人口群体间的泛化能力不足。传统的数据增强方法在显著领域偏移下效果有限，而现有的风格化增强方法要么风格多样性不足，要么会引入图像伪影。

Method: 提出Stylizing ViT，一种新颖的Vision Transformer编码器，使用权重共享的注意力块同时处理自注意力和交叉注意力。这种设计允许同一个注意力块通过自注意力保持解剖结构一致性，同时通过交叉注意力执行风格迁移。

Result: 在组织病理学和皮肤病学的三个不同图像分类任务上评估，结果显示相比现有技术提高了鲁棒性（准确率最高提升13%），同时生成无伪影的感知可信图像。此外，Stylizing ViT在推理阶段用于测试时增强，实现了17%的性能提升。

Conclusion: Stylizing ViT通过创新的权重共享注意力机制，在保持解剖结构一致性的同时实现有效的风格迁移，显著提升了医学图像分析模型的领域泛化能力，并在训练和推理阶段都表现出色。

Abstract: Deep learning models in medical image analysis often struggle with generalizability across domains and demographic groups due to data heterogeneity and scarcity. Traditional augmentation improves robustness, but fails under substantial domain shifts. Recent advances in stylistic augmentation enhance domain generalization by varying image styles but fall short in terms of style diversity or by introducing artifacts into the generated images. To address these limitations, we propose Stylizing ViT, a novel Vision Transformer encoder that utilizes weight-shared attention blocks for both self- and cross-attention. This design allows the same attention block to maintain anatomical consistency through self-attention while performing style transfer via cross-attention. We assess the effectiveness of our method for domain generalization by employing it for data augmentation on three distinct image classification tasks in the context of histopathology and dermatology. Results demonstrate an improved robustness (up to +13% accuracy) over the state of the art while generating perceptually convincing images without artifacts. Additionally, we show that Stylizing ViT is effective beyond training, achieving a 17% performance improvement during inference when used for test-time augmentation. The source code is available at https://github.com/sdoerrich97/stylizing-vit .

</details>


### [53] [SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation](https://arxiv.org/abs/2601.17657)
*Taewan Cho,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.CV

TL;DR: SPACE-CLIP提出了一种双路径解码器架构，直接从冻结的CLIP视觉编码器中提取几何知识，无需文本编码器和文本提示，显著提升了深度估计性能。


<details>
  <summary>Details</summary>
Motivation: CLIP在语义理解方面表现出色，但天生难以感知几何结构。现有方法通过文本提示查询CLIP的方式间接且低效，需要一种更直接的方法来解锁CLIP中的几何知识。

Method: 提出SPACE-CLIP架构，包含两个互补路径：语义路径使用特征级线性调制（FiLM）解释高层特征并动态适应全局上下文；结构路径从早期层提取细粒度空间细节。两条路径通过分层融合实现语义上下文和精确几何的稳健合成。

Result: 在KITTI基准测试上的广泛实验表明，SPACE-CLIP显著优于之前的CLIP基方法。消融研究验证了双路径协同融合对此成功的关键作用。

Conclusion: SPACE-CLIP为重新利用大规模视觉模型提供了一个高效且架构优雅的蓝图。该方法不仅是一个独立的深度估计器，还是一个易于集成的空间感知模块，适用于下一代具身AI系统。

Abstract: Contrastive Language-Image Pre-training (CLIP) has accomplished extraordinary success for semantic understanding but inherently struggles to perceive geometric structure. Existing methods attempt to bridge this gap by querying CLIP with textual prompts, a process that is often indirect and inefficient. This paper introduces a fundamentally different approach using a dual-pathway decoder. We present SPACE-CLIP, an architecture that unlocks and interprets latent geometric knowledge directly from a frozen CLIP vision encoder, completely bypassing the text encoder and its associated textual prompts. A semantic pathway interprets high-level features, dynamically conditioned on global context using feature-wise linear modulation (FiLM). In addition, a structural pathway extracts fine-grained spatial details from early layers. These complementary streams are hierarchically fused, enabling a robust synthesis of semantic context and precise geometry. Extensive experiments on the KITTI benchmark show that SPACE-CLIP dramatically outperforms previous CLIP-based methods. Our ablation studies validate that the synergistic fusion of our dual pathways is critical to this success. SPACE-CLIP offers a new, efficient, and architecturally elegant blueprint for repurposing large-scale vision models. The proposed method is not just a standalone depth estimator, but a readily integrable spatial perception module for the next generation of embodied AI systems, such as vision-language-action (VLA) models. Our model is available at https://github.com/taewan2002/space-clip

</details>


### [54] [Training-Free Text-to-Image Compositional Food Generation via Prompt Grafting](https://arxiv.org/abs/2601.17666)
*Xinyue Pan,Yuhao Chen,Fengqing Zhu*

Main category: cs.CV

TL;DR: 提出Prompt Grafting框架解决多食物图像生成中的物体纠缠问题，通过两阶段布局提示和目标提示嫁接实现可控的食物分离


<details>
  <summary>Details</summary>
Motivation: 现实世界中的餐食图像通常包含多种食物，但现有的文本到图像扩散模型在多食物图像生成中存在物体纠缠问题，相邻食物（如米饭和汤）会融合在一起，因为许多食物没有清晰的边界。这对于基于图像的饮食评估和食谱可视化等应用造成了困难。

Method: 提出Prompt Grafting（PG）框架，这是一个无需训练的方法，将文本中的显式空间线索与采样过程中的隐式布局指导相结合。采用两阶段过程：首先使用布局提示建立不同的区域，然后在布局形成稳定后将目标提示嫁接上去。用户可以编辑布局排列来控制哪些食物应该保持分离或有意混合。

Result: 在两个食物数据集上的实验表明，该方法显著提高了目标物体的存在率，并提供了可控分离的定性证据。

Conclusion: Prompt Grafting框架有效解决了多食物图像生成中的物体纠缠问题，通过结合显式空间提示和隐式布局指导，实现了对食物分离的可控生成，为图像基饮食评估和食谱可视化等应用提供了更好的数据增强工具。

Abstract: Real-world meal images often contain multiple food items, making reliable compositional food image generation important for applications such as image-based dietary assessment, where multi-food data augmentation is needed, and recipe visualization. However, modern text-to-image diffusion models struggle to generate accurate multi-food images due to object entanglement, where adjacent foods (e.g., rice and soup) fuse together because many foods do not have clear boundaries. To address this challenge, we introduce Prompt Grafting (PG), a training-free framework that combines explicit spatial cues in text with implicit layout guidance during sampling. PG runs a two-stage process where a layout prompt first establishes distinct regions and the target prompt is grafted once layout formation stabilizes. The framework enables food entanglement control: users can specify which food items should remain separated or be intentionally mixed by editing the arrangement of layouts. Across two food datasets, our method significantly improves the presence of target objects and provides qualitative evidence of controllable separation.

</details>


### [55] [StyleDecoupler: Generalizable Artistic Style Disentanglement](https://arxiv.org/abs/2601.17697)
*Zexi Jia,Jinchao Zhang,Jie Zhou*

Main category: cs.CV

TL;DR: StyleDecoupler是一个信息论框架，通过利用单模态模型作为内容参考，从多模态视觉模型中分离纯风格特征，无需微调即可在冻结的视觉语言模型上运行。


<details>
  <summary>Details</summary>
Motivation: 艺术风格表示具有挑战性，因为风格与语义内容深度纠缠。现有方法难以有效分离风格和内容特征。

Method: 利用多模态视觉模型编码风格和内容，而单模态模型抑制风格以关注内容不变特征。使用单模态表示作为纯内容参考，通过互信息最小化从多模态嵌入中分离纯风格特征。

Result: 在WeART（28万件艺术品，152种风格，1556位艺术家）和WikiART基准测试中实现最先进的风格检索性能，支持风格关系映射和生成模型评估等应用。

Conclusion: StyleDecoupler作为即插即用模块有效分离风格特征，提出的WeART基准为艺术风格分析提供了大规模数据集，推动了艺术风格表示研究的发展。

Abstract: Representing artistic style is challenging due to its deep entanglement with semantic content. We propose StyleDecoupler, an information-theoretic framework that leverages a key insight: multi-modal vision models encode both style and content, while uni-modal models suppress style to focus on content-invariant features. By using uni-modal representations as content-only references, we isolate pure style features from multi-modal embeddings through mutual information minimization. StyleDecoupler operates as a plug-and-play module on frozen Vision-Language Models without fine-tuning. We also introduce WeART, a large-scale benchmark of 280K artworks across 152 styles and 1,556 artists. Experiments show state-of-the-art performance on style retrieval across WeART and WikiART, while enabling applications like style relationship mapping and generative model evaluation. We release our method and dataset at this url.

</details>


### [56] [An AI-enabled tool for quantifying overlapping red blood cell sickling dynamics in microfluidic assays](https://arxiv.org/abs/2601.17703)
*Nikhil Kadivar,Guansheng Li,Jianlu Zheng,John M. Higgins,Ming Dao,George Em Karniadakis,Mengjia Xu*

Main category: cs.CV

TL;DR: 本文提出了一种自动化深度学习框架，用于在时间序列显微镜数据中量化红细胞群体，特别是镰状细胞在不同密度条件下的形态学转变，通过AI辅助标注、分割、分类和实例计数，显著提高了实验通量。


<details>
  <summary>Details</summary>
Motivation: 理解镰状细胞动力学需要准确识别不同生物物理条件下（特别是在密集堆积和重叠细胞群体中）的形态学转变。传统方法面临手动标注稀缺和细胞重叠的挑战，需要一种可扩展的自动化解决方案。

Method: 开发了一个集成AI辅助标注、分割、分类和实例计数的深度学习框架。使用Roboflow平台标注实验图像生成训练数据集，训练nnU-Net分割模型，并结合分水岭算法解决细胞重叠问题以提高量化准确性。

Result: 该框架仅需少量标注数据即可实现高分割性能，能够预测镰状细胞分数的时间演化，通过密集细胞悬浮液使实验通量提高一倍以上，捕获药物依赖性镰状化行为，并揭示细胞形态演化的独特机械生物学特征。

Conclusion: 这个AI驱动框架建立了一个可扩展且可重复的计算平台，用于研究细胞生物力学和评估微生理系统中的治疗效果，为镰状细胞病研究提供了强大的分析工具。

Abstract: Understanding sickle cell dynamics requires accurate identification of morphological transitions under diverse biophysical conditions, particularly in densely packed and overlapping cell populations. Here, we present an automated deep learning framework that integrates AI-assisted annotation, segmentation, classification, and instance counting to quantify red blood cell (RBC) populations across varying density regimes in time-lapse microscopy data. Experimental images were annotated using the Roboflow platform to generate labeled dataset for training an nnU-Net segmentation model. The trained network enables prediction of the temporal evolution of the sickle cell fraction, while a watershed algorithm resolves overlapping cells to enhance quantification accuracy. Despite requiring only a limited amount of labeled data for training, the framework achieves high segmentation performance, effectively addressing challenges associated with scarce manual annotations and cell overlap. By quantitatively tracking dynamic changes in RBC morphology, this approach can more than double the experimental throughput via densely packed cell suspensions, capture drug-dependent sickling behavior, and reveal distinct mechanobiological signatures of cellular morphological evolution. Overall, this AI-driven framework establishes a scalable and reproducible computational platform for investigating cellular biomechanics and assessing therapeutic efficacy in microphysiological systems.

</details>


### [57] [Advancing Structured Priors for Sparse-Voxel Surface Reconstruction](https://arxiv.org/abs/2601.17720)
*Ting-Hsun Chi,Chu-Rong Chen,Chi-Tun Hsu,Hsuan-Ting Lin,Sheng-Yu Huang,Cheng Sun,Yu-Chiang Frank Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种结合3D高斯泼溅和稀疏体素光栅化优势的方法，通过体素初始化技术和深度几何监督，在保持快速收敛的同时提高了几何精度和表面完整性。


<details>
  <summary>Details</summary>
Motivation: 现有的两种显式表示方法各有优缺点：3D高斯泼溅收敛快且有几何先验，但表面保真度受限于点状参数化；稀疏体素光栅化提供连续不透明度场和清晰几何，但均匀密集网格初始化收敛慢且未充分利用场景结构。需要结合两者的优势。

Method: 1. 提出体素初始化方法，将体素放置在合理位置并具有适当细节层次，为单场景优化提供强起点。2. 提出精细化深度几何监督，将多视角线索转换为直接的每射线深度正则化，增强深度一致性而不模糊边缘。

Result: 在标准基准测试中，相比先前方法在几何精度、细结构恢复和表面完整性方面都有改进，同时保持了快速收敛。

Conclusion: 通过结合3D高斯泼溅和稀疏体素光栅化的优势，提出的方法在保持快速收敛的同时显著提高了表面重建的几何精度和完整性。

Abstract: Reconstructing accurate surfaces with radiance fields has progressed rapidly, yet two promising explicit representations, 3D Gaussian Splatting and sparse-voxel rasterization, exhibit complementary strengths and weaknesses. 3D Gaussian Splatting converges quickly and carries useful geometric priors, but surface fidelity is limited by its point-like parameterization. Sparse-voxel rasterization provides continuous opacity fields and crisp geometry, but its typical uniform dense-grid initialization slows convergence and underutilizes scene structure. We combine the advantages of both by introducing a voxel initialization method that places voxels at plausible locations and with appropriate levels of detail, yielding a strong starting point for per-scene optimization. To further enhance depth consistency without blurring edges, we propose refined depth geometry supervision that converts multi-view cues into direct per-ray depth regularization. Experiments on standard benchmarks demonstrate improvements over prior methods in geometric accuracy, better fine-structure recovery, and more complete surfaces, while maintaining fast convergence.

</details>


### [58] [Implicit Neural Representation-Based Continuous Single Image Super Resolution: An Empirical Study](https://arxiv.org/abs/2601.17723)
*Tayyab Nasir,Daochang Liu,Ajmal Mian*

Main category: cs.CV

TL;DR: 本文对基于隐式神经表示(INR)的任意尺度超分辨率方法进行了首次系统性实证研究，比较了现有技术，分析了训练配置的影响，并提出了新的损失函数。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对INR-based任意尺度超分辨率方法的系统性实证研究，需要评估现有方法的真实效果，分析训练配置的影响，建立性能基准并识别有前景的研究方向。

Method: 1) 在不同设置下比较现有技术，在多图像质量指标上汇总性能结果；2) 提供统一框架和代码库以促进可重复比较；3) 研究受控训练配置对感知图像质量的影响；4) 提出新的损失函数，在惩罚强度变化的同时保留边缘、纹理和细节。

Result: 1) 近期更复杂的INR方法相比早期方法仅有边际改进；2) 模型性能与训练配置强相关，这一因素在先前工作中被忽视；3) 提出的损失函数能提升跨架构的纹理保真度；4) 缩放定律适用于INR-based ASSR，模型复杂度和数据多样性的增加能带来可预测的性能提升。

Conclusion: 训练配置对INR-based任意尺度超分辨率性能有重要影响，不应被忽视；提出的损失函数能有效提升纹理保真度；缩放定律适用于该领域；近期复杂方法相比早期方法改进有限，表明该领域可能接近饱和。

Abstract: Implicit neural representation (INR) has become the standard approach for arbitrary-scale image super-resolution (ASSR). To date, no empirical study has systematically examined the effectiveness of existing methods, nor investigated the effects of different training recipes, such as scaling laws, objective design, and optimization strategies. A rigorous empirical analysis is essential not only for benchmarking performance and revealing true gains but also for establishing the current state of ASSR, identifying saturation limits, and highlighting promising directions. We fill this gap by comparing existing techniques across diverse settings and presenting aggregated performance results on multiple image quality metrics. We contribute a unified framework and code repository to facilitate reproducible comparisons. Furthermore, we investigate the impact of carefully controlled training configurations on perceptual image quality and examine a new loss function that penalizes intensity variations while preserving edges, textures, and finer details during training. We conclude the following key insights that have been previously overlooked: (1) Recent, more complex INR methods provide only marginal improvements over earlier methods. (2) Model performance is strongly correlated to training configurations, a factor overlooked in prior works. (3) The proposed loss enhances texture fidelity across architectures, emphasizing the role of objective design for targeted perceptual gains. (4) Scaling laws apply to INR-based ASSR, confirming predictable gains with increased model complexity and data diversity.

</details>


### [59] [Flatten The Complex: Joint B-Rep Generation via Compositional $k$-Cell Particles](https://arxiv.org/abs/2601.17733)
*Junran Lu,Yuanqi Li,Hengji Li,Jie Guo,Yanwen Guo*

Main category: cs.CV

TL;DR: 提出一种新的B-Rep生成建模方法，将边界表示转化为可组合的k-cell粒子集合，通过多模态流匹配框架实现拓扑和几何的联合生成


<details>
  <summary>Details</summary>
Motivation: B-Rep在CAD和制造中广泛应用，但其生成建模面临挑战，因为B-Rep是几何单元复合体，拓扑与几何在不同阶的单元（顶点、边、面）中相互纠缠。现有方法通常采用级联序列处理这种层次结构，未能充分利用单元间的几何关系（如邻接和共享），限制了上下文感知和错误恢复能力。

Method: 将B-Rep重新表述为可组合的k-cell粒子集合，将每个拓扑实体编码为粒子的组合，相邻单元在其接口处共享相同的潜在表示，从而促进沿共享边界的几何耦合。使用多模态流匹配框架合成这些粒子集合，支持无条件生成和精确条件任务（如单视图或点云的3D重建）。

Result: 实验表明，该方法能够生成高保真度的CAD模型，在有效性和可编辑性方面优于现有最先进方法。该表示的自然扩展支持局部修复和直接合成非流形结构（如线框）。

Conclusion: 通过将B-Rep转化为粒子集合表示，解耦了刚性层次结构，统一了顶点、边和面，实现了具有全局上下文感知的拓扑和几何联合生成，为CAD建模提供了更灵活和强大的生成框架。

Abstract: Boundary Representation (B-Rep) is the widely adopted standard
  in Computer-Aided Design (CAD) and manufacturing. However, generative modeling of B-Reps remains a formidable challenge due to their inherent heterogeneity as geometric cell complexes, which entangles topology with geometry across cells of varying orders (i.e., $k$-cells such as vertices, edges, faces). Previous methods typically rely on cascaded sequences to handle this hierarchy, which fails to fully exploit the geometric relationships between cells, such as adjacency and sharing, limiting context awareness and error recovery. To fill this gap, we introduce a novel paradigm that reformulates B-Reps into sets of compositional $k$-cell particles. Our approach encodes each topological entity as a composition of particles, where adjacent cells share identical latents at their interfaces, thereby promoting geometric coupling along shared boundaries. By decoupling the rigid hierarchy, our representation unifies vertices, edges, and faces, enabling the joint generation of topology and geometry with global context awareness.
  We synthesize these particle sets using a multi-modal flow matching framework to handle unconditional generation as well as precise conditional tasks, such as 3D reconstruction from single-view or point cloud. Furthermore, the explicit and localized nature of our representation naturally extends to downstream tasks like local in-painting and enables the direct synthesis of non-manifold structures (e.g., wireframes). Extensive experiments demonstrate that our method produces high-fidelity CAD models with superior validity and editability compared to state-of-the-art methods.

</details>


### [60] [Learning Sewing Patterns via Latent Flow Matching of Implicit Fields](https://arxiv.org/abs/2601.17740)
*Cong Cao,Ren Li,Corentin Dumery,Hao Li*

Main category: cs.CV

TL;DR: 该论文提出了一种基于隐式表示的缝纫图案建模方法，使用符号距离场和无符号距离场表示服装面板，通过连续潜在空间和潜在流匹配模型实现复杂缝纫图案的准确建模与生成。


<details>
  <summary>Details</summary>
Motivation: 缝纫图案定义了服装的结构基础，对时尚设计、制作和物理模拟至关重要。尽管自动图案生成有所进展，但由于面板几何形状和接缝排列的广泛可变性，准确建模缝纫图案仍然困难。

Method: 1. 使用符号距离场定义面板边界，无符号距离场识别接缝端点；2. 将这些场编码到连续潜在空间，支持可微分网格化；3. 潜在流匹配模型学习面板组合的分布；4. 缝纫预测模块从提取的边缘段恢复接缝关系。

Result: 该方法能够准确建模和生成具有复杂结构的缝纫图案，相比现有方法在从图像估计缝纫图案方面提高了准确性，并支持图案补全和重新适配等应用。

Conclusion: 该隐式表示方法为数字时尚设计提供了实用的缝纫图案建模工具，能够处理复杂结构并支持多种应用场景。

Abstract: Sewing patterns define the structural foundation of garments and are essential for applications such as fashion design, fabrication, and physical simulation. Despite progress in automated pattern generation, accurately modeling sewing patterns remains difficult due to the broad variability in panel geometry and seam arrangements. In this work, we introduce a sewing pattern modeling method based on an implicit representation. We represent each panel using a signed distance field that defines its boundary and an unsigned distance field that identifies seam endpoints, and encode these fields into a continuous latent space that enables differentiable meshing. A latent flow matching model learns distributions over panel combinations in this representation, and a stitching prediction module recovers seam relations from extracted edge segments. This formulation allows accurate modeling and generation of sewing patterns with complex structures. We further show that it can be used to estimate sewing patterns from images with improved accuracy relative to existing approaches, and supports applications such as pattern completion and refitting, providing a practical tool for digital fashion design.

</details>


### [61] [Bridging Supervision Gaps: A Unified Framework for Remote Sensing Change Detection](https://arxiv.org/abs/2601.17747)
*Kaixuan Jiang,Chen Wu,Zhenghui Zhao,Chengxi Han*

Main category: cs.CV

TL;DR: UniCD是一个统一的遥感变化检测框架，通过共享编码器和多分支协作学习机制，同时处理监督、弱监督和无监督任务，在多种标注场景下都取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中像素级变化标注成本高昂，现有模型难以适应不同标注可用性的多样化场景，需要一种能够统一处理不同监督级别任务的框架。

Method: 提出UniCD统一框架，包含共享编码器和三个监督特定分支：监督分支引入时空感知模块实现双时相特征融合；弱监督分支构建变化表示正则化引导模型收敛；无监督分支提出语义先验驱动变化推断，将无监督任务转化为可控的弱监督路径优化。

Result: 在主流数据集上的实验表明，UniCD在三个任务上都达到了最优性能，在弱监督和无监督场景下显著提升准确率，在LEVIR-CD数据集上分别超过当前最佳方法12.72%和12.37%。

Conclusion: UniCD通过消除架构障碍和深度耦合异构监督信号，成功构建了一个统一的变化检测框架，能够有效适应不同标注可用性的实际应用场景。

Abstract: Change detection (CD) aims to identify surface changes from multi-temporal remote sensing imagery. In real-world scenarios, Pixel-level change labels are expensive to acquire, and existing models struggle to adapt to scenarios with diverse annotation availability. To tackle this challenge, we propose a unified change detection framework (UniCD), which collaboratively handles supervised, weakly-supervised, and unsupervised tasks through a coupled architecture. UniCD eliminates architectural barriers through a shared encoder and multi-branch collaborative learning mechanism, achieving deep coupling of heterogeneous supervision signals. Specifically, UniCD consists of three supervision-specific branches. In the supervision branch, UniCD introduces the spatial-temporal awareness module (STAM), achieving efficient synergistic fusion of bi-temporal features. In the weakly-supervised branch, we construct change representation regularization (CRR), which steers model convergence from coarse-grained activations toward coherent and separable change modeling. In the unsupervised branch, we propose semantic prior-driven change inference (SPCI), which transforms unsupervised tasks into controlled weakly-supervised path optimization. Experiments on mainstream datasets demonstrate that UniCD achieves optimal performance across three tasks. It exhibits significant accuracy improvements in weakly and unsupervised scenarios, surpassing current state-of-the-art by 12.72% and 12.37% on LEVIR-CD, respectively.

</details>


### [62] [MV-S2V: Multi-View Subject-Consistent Video Generation](https://arxiv.org/abs/2601.17756)
*Ziyang Song,Xinyu Gong,Bangya Liu,Zelin Zhao*

Main category: cs.CV

TL;DR: 该论文提出并解决了多视角主题到视频生成（MV-S2V）任务，通过多视角参考图像实现3D级别的主题一致性，解决了现有S2V方法仅限于单视角参考的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有主题到视频生成（S2V）方法仅限于单视角主题参考，这使得S2V任务简化为S2I + I2V流水线，未能充分利用视频主题控制的全部潜力。需要开发能够利用多视角参考图像实现3D级别主题一致性的方法。

Method: 1. 提出多视角S2V（MV-S2V）任务框架；2. 开发合成数据生成流程以解决训练数据稀缺问题，并辅以小规模真实世界数据集；3. 引入时间偏移RoPE（TS-RoPE）来区分不同主题和同一主题的不同视角参考。

Result: 该框架在多视角参考图像方面实现了优越的3D主题一致性和高质量的视觉输出，为主题驱动的视频生成建立了新的有意义方向。

Conclusion: MV-S2V框架成功解决了多视角主题到视频生成的挑战，通过合成数据生成和TS-RoPE技术实现了3D级别的主题一致性，为主题驱动的视频生成开辟了新方向。

Abstract: Existing Subject-to-Video Generation (S2V) methods have achieved high-fidelity and subject-consistent video generation, yet remain constrained to single-view subject references. This limitation renders the S2V task reducible to an S2I + I2V pipeline, failing to exploit the full potential of video subject control. In this work, we propose and address the challenging Multi-View S2V (MV-S2V) task, which synthesizes videos from multiple reference views to enforce 3D-level subject consistency. Regarding the scarcity of training data, we first develop a synthetic data curation pipeline to generate highly customized synthetic data, complemented by a small-scale real-world captured dataset to boost the training of MV-S2V. Another key issue lies in the potential confusion between cross-subject and cross-view references in conditional generation. To overcome this, we further introduce Temporally Shifted RoPE (TS-RoPE) to distinguish between different subjects and distinct views of the same subject in reference conditioning. Our framework achieves superior 3D subject consistency w.r.t. multi-view reference images and high-quality visual outputs, establishing a new meaningful direction for subject-driven video generation. Our project page is available at <a href="https://szy-young.github.io/mv-s2v">this URL</a>

</details>


### [63] [Agreement-Driven Multi-View 3D Reconstruction for Live Cattle Weight Estimation](https://arxiv.org/abs/2601.17791)
*Rabin Dulal,Wenfeng Jia,Lihong Zheng,Jane Quinn*

Main category: cs.CV

TL;DR: 使用多视角RGB图像和SAM 3D重建技术，结合集成回归模型，实现牛只活重的非接触式低成本估算，在农场场景下达到R²=0.69的准确度。


<details>
  <summary>Details</summary>
Motivation: 传统牛只活重估算方法（如走过式称重系统或体况评分）需要人工操作，影响生产效率和经济效益，需要开发非接触式、成本效益高的自动化解决方案。

Method: 提出基于多视角RGB图像的3D重建管道：使用SAM 3D进行基于一致性引导的多视角融合生成单一点云，然后比较经典集成模型和深度学习模型在低数据条件下的表现。

Result: SAM 3D多视角一致性融合优于其他3D生成方法；经典集成模型在农场实际场景中表现最稳定（R²=0.69±0.10，MAPE=2.22±0.56%），适合农场部署。

Conclusion: 对于在难以产生大量3D数据的农场环境中进行可扩展部署，提高重建质量比增加模型复杂度更为关键，该方法具有实际农场应用的可行性。

Abstract: Accurate cattle live weight estimation is vital for livestock management, welfare, and productivity. Traditional methods, such as manual weighing using a walk-over weighing system or proximate measurements using body condition scoring, involve manual handling of stock and can impact productivity from both a stock and economic perspective. To address these issues, this study investigated a cost-effective, non-contact method for live weight calculation in cattle using 3D reconstruction. The proposed pipeline utilized multi-view RGB images with SAM 3D-based agreement-guided fusion, followed by ensemble regression. Our approach generates a single 3D point cloud per animal and compares classical ensemble models with deep learning models under low-data conditions. Results show that SAM 3D with multi-view agreement fusion outperforms other 3D generation methods, while classical ensemble models provide the most consistent performance for practical farm scenarios (R$^2$ = 0.69 $\pm$ 0.10, MAPE = 2.22 $\pm$ 0.56 \%), making this practical for on-farm implementation. These findings demonstrate that improving reconstruction quality is more critical than increasing model complexity for scalable deployment on farms where producing a large volume of 3D data is challenging.

</details>


### [64] [ViTCoP: Accelerating Large Vision-Language Models via Visual and Textual Semantic Collaborative Pruning](https://arxiv.org/abs/2601.17818)
*Wen Luo,Peng Chen,Xiaotao Huang,LiQun Huang*

Main category: cs.CV

TL;DR: ViTCoP框架通过视觉编码器冗余过滤和基于LLM层次特性的逐步协同剪枝，有效减少视觉令牌冗余，同时保持关键视觉信息，显著降低计算成本和内存消耗。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在视觉令牌冗余问题，导致计算成本高昂。现有剪枝方法要么在视觉编码器中过早丢失关键信息，要么在LLM中导致所选令牌信息冗余。

Method: 提出ViTCoP框架：1) 在视觉编码器中进行冗余过滤；2) 基于LLM层次特性进行逐步协同剪枝；3) 引入K向量L2范数作为令牌显著性度量，确保与FlashAttention等加速技术兼容。

Result: 在各种大型视觉语言模型上的实验表明，ViTCoP在图像和视频理解任务上超越现有方法，达到最先进性能，同时显著降低推理延迟和GPU内存消耗，在极端剪枝率下优势更明显。

Conclusion: ViTCoP通过视觉和文本语义协同剪枝，有效解决了LVLM中的视觉令牌冗余问题，在保持性能的同时大幅提升了计算效率，特别是在高剪枝率场景下表现优异。

Abstract: Large Vision-Language Models (LVLMs) incur high computational costs due to significant redundancy in their visual tokens. To effectively reduce this cost, researchers have proposed various visual token pruning methods. However, existing methods are generally limited, either losing critical visual information prematurely due to pruning in the vision encoder, or leading to information redundancy among the selected tokens due to pruning in the Large Language Models (LLMs). To address these challenges, we propose a Visual and Textual Semantic Collaborative Pruning framework (ViTCoP) that combines redundancy filtering in the vision encoder with step-wise co-pruning within the LLM based on its hierarchical characteristics, to efficiently preserve critical and informationally diverse visual tokens. Meanwhile, to ensure compatibility with acceleration techniques like FlashAttention, we introduce the L2 norm of K-vectors as the token saliency metric in the LLM. Extensive experiments on various Large Vision-Language Models demonstrate that ViTCoP not only achieves state-of-the-art performance surpassing existing methods on both image and video understanding tasks, but also significantly reduces model inference latency and GPU memory consumption. Notably, its performance advantage over other methods becomes even more pronounced under extreme pruning rates.

</details>


### [65] [VAE-REPA: Variational Autoencoder Representation Alignment for Efficient Diffusion Training](https://arxiv.org/abs/2601.17830)
*Mengmeng Wang,Dengyang Jiang,Liuzhuozheng Li,Yucheng Lin,Guojiang Shen,Xiangjie Kong,Yong Liu,Guang Dai,Jingdong Wang*

Main category: cs.CV

TL;DR: 提出了一种轻量级内在指导框架，利用预训练VAE特征加速扩散变换器训练，无需外部依赖，仅增加4%计算开销


<details>
  <summary>Details</summary>
Motivation: 现有的扩散变换器训练收敛效率低下，现有加速方法如REPA（依赖外部表示编码器）和SRA（需要双模型设置）都会带来沉重的计算开销。需要一种轻量级的内在指导框架来高效加速扩散训练。

Method: 提出\namex框架，利用现成的预训练变分自编码器（VAE）特征。VAE的重建特性确保了其对丰富纹理细节、结构模式和基本语义信息等视觉先验的内在编码。通过轻量级投影层将扩散变换器的中间潜在特征与VAE特征对齐，并使用特征对齐损失进行监督。

Result: 实验表明，\namex相比原始扩散变换器提高了生成质量和训练收敛速度，匹配或优于最先进的加速方法，仅增加4%的GFLOPs计算开销，且无需外部指导模型的额外成本。

Conclusion: \namex是一个简单而有效的轻量级内在指导框架，通过利用预训练VAE特征加速扩散变换器训练，无需外部依赖，在计算效率和性能提升之间取得了良好平衡。

Abstract: Denoising-based diffusion transformers, despite their strong generation performance, suffer from inefficient training convergence. Existing methods addressing this issue, such as REPA (relying on external representation encoders) or SRA (requiring dual-model setups), inevitably incur heavy computational overhead during training due to external dependencies. To tackle these challenges, this paper proposes \textbf{\namex}, a lightweight intrinsic guidance framework for efficient diffusion training. \name leverages off-the-shelf pre-trained Variational Autoencoder (VAE) features: their reconstruction property ensures inherent encoding of visual priors like rich texture details, structural patterns, and basic semantic information. Specifically, \name aligns the intermediate latent features of diffusion transformers with VAE features via a lightweight projection layer, supervised by a feature alignment loss. This design accelerates training without extra representation encoders or dual-model maintenance, resulting in a simple yet effective pipeline. Extensive experiments demonstrate that \name improves both generation quality and training convergence speed compared to vanilla diffusion transformers, matches or outperforms state-of-the-art acceleration methods, and incurs merely 4\% extra GFLOPs with zero additional cost for external guidance models.

</details>


### [66] [Geometry-Grounded Gaussian Splatting](https://arxiv.org/abs/2601.17835)
*Baowen Zhang,Chenxing Jiang,Heng Li,Shaojie Shen,Ping Tan*

Main category: cs.CV

TL;DR: 本文提出了一种基于随机固体理论的几何基础高斯泼溅方法，解决了从高斯原语中提取形状的问题，实现了高质量的形状重建。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅在新视角合成中表现出色，但从高斯原语中提取形状仍然是一个未解决的问题。现有方法由于几何参数化和近似不足，存在多视角一致性差和对浮点噪声敏感的问题。

Method: 通过严格的理论推导，将高斯原语建立为一种特定类型的随机固体，为几何基础高斯泼溅提供理论框架。利用随机固体的体积性质，高效渲染高质量深度图以进行细粒度几何提取。

Result: 实验表明，该方法在公共数据集上实现了所有基于高斯泼溅方法中最好的形状重建结果。

Conclusion: 通过将高斯原语理论化为随机固体，为几何基础高斯泼溅提供了原则性基础，实现了高质量的形状重建，解决了现有方法的局限性。

Abstract: Gaussian Splatting (GS) has demonstrated impressive quality and efficiency in novel view synthesis. However, shape extraction from Gaussian primitives remains an open problem. Due to inadequate geometry parameterization and approximation, existing shape reconstruction methods suffer from poor multi-view consistency and are sensitive to floaters. In this paper, we present a rigorous theoretical derivation that establishes Gaussian primitives as a specific type of stochastic solids. This theoretical framework provides a principled foundation for Geometry-Grounded Gaussian Splatting by enabling the direct treatment of Gaussian primitives as explicit geometric representations. Using the volumetric nature of stochastic solids, our method efficiently renders high-quality depth maps for fine-grained geometry extraction. Experiments show that our method achieves the best shape reconstruction results among all Gaussian Splatting-based methods on public datasets.

</details>


### [67] [SynMind: Reducing Semantic Hallucination in fMRI-Based Image Reconstruction](https://arxiv.org/abs/2601.17857)
*Lan Yang,Minghan Yang,Ke Li,Honggang Zhang,Kaiyue Pang,Yi-Zhe Song*

Main category: cs.CV

TL;DR: 该研究提出SynMind框架，通过将fMRI信号解析为句子级语义描述，结合视觉先验来改进图像重建，解决了现有方法中语义错位的问题。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI图像重建方法虽然能产生逼真图像，但存在严重的语义错位问题——显著物体经常被替换或幻觉生成，尽管视觉质量很高。作者认为现有方法过度依赖纠缠的视觉嵌入，优先考虑低级别外观线索（如纹理和全局概貌）而非明确的语义身份。

Method: 提出SynMind框架：1）将fMRI信号解析为丰富的句子级语义描述，反映人类视觉理解的分层和组合特性；2）利用基础视觉语言模型生成类似人类的、多粒度的文本表示，捕捉物体身份和空间组织；3）将这些明确的语义编码与视觉先验结合，条件化预训练的扩散模型。

Result: SynMind在大多数定量指标上优于现有方法。通过将语义推理卸载到文本对齐模块，SynMind使用更小的Stable Diffusion 1.4和单个消费级GPU就能超越基于SDXL的竞争方法。大规模人类评估证实SynMind产生与人类视觉感知更一致的重建结果。神经可视化分析显示SynMind激活了更广泛、语义更相关的大脑区域。

Conclusion: 通过重新思考fMRI解码中明确语义解释的作用，SynMind框架成功解决了语义错位问题，实现了更符合人类视觉感知的图像重建，同时展示了更高效的资源利用和更广泛的神经激活模式。

Abstract: Recent advances in fMRI-based image reconstruction have achieved remarkable photo-realistic fidelity. Yet, a persistent limitation remains: while reconstructed images often appear naturalistic and holistically similar to the target stimuli, they frequently suffer from severe semantic misalignment -- salient objects are often replaced or hallucinated despite high visual quality. In this work, we address this limitation by rethinking the role of explicit semantic interpretation in fMRI decoding. We argue that existing methods rely too heavily on entangled visual embeddings which prioritize low-level appearance cues -- such as texture and global gist -- over explicit semantic identity. To overcome this, we parse fMRI signals into rich, sentence-level semantic descriptions that mirror the hierarchical and compositional nature of human visual understanding. We achieve this by leveraging grounded VLMs to generate synthetic, human-like, multi-granularity textual representations that capture object identities and spatial organization. Built upon this foundation, we propose SynMind, a framework that integrates these explicit semantic encodings with visual priors to condition a pretrained diffusion model. Extensive experiments demonstrate that SynMind outperforms state-of-the-art methods across most quantitative metrics. Notably, by offloading semantic reasoning to our text-alignment module, SynMind surpasses competing methods based on SDXL while using the much smaller Stable Diffusion 1.4 and a single consumer GPU. Large-scale human evaluations further confirm that SynMind produces reconstructions more consistent with human visual perception. Neurovisualization analyses reveal that SynMind engages broader and more semantically relevant brain regions, mitigating the over-reliance on high-level visual areas.

</details>


### [68] [Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment](https://arxiv.org/abs/2601.17862)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 提出轻量级量子增强域泛化框架，通过多域成像偏移模拟、域对抗训练和量子特征增强层，提升医学影像AI模型在未见目标域的泛化能力，无需真实多中心标注数据。


<details>
  <summary>Details</summary>
Motivation: 医学影像AI模型在单中心或单设备设置中表现良好，但在真实世界跨中心部署时因域偏移导致性能下降，限制了临床泛化能力。需要解决域泛化问题，同时考虑计算资源受限的实际场景。

Method: 1) 基于MobileNetV2构建域不变编码器；2) 使用亮度、对比度、锐化和噪声扰动模拟多域成像偏移；3) 采用梯度反转的域对抗训练抑制域判别特征；4) 引入轻量级量子特征增强层，使用参数化量子电路进行非线性特征映射和纠缠建模；5) 推理时采用测试时间适应策略。

Result: 在模拟多中心医学影像数据集上的实验表明，该方法在未见域上显著优于无域泛化或无量子增强的基线模型，降低了域特定性能方差，提高了AUC和灵敏度。

Conclusion: 该方法展示了在计算资源受限条件下量子增强域泛化的临床潜力，为混合量子-经典医学影像系统提供了可行范式，能够在不依赖真实多中心标注数据的情况下实现稳健的跨域泛化。

Abstract: Medical image artificial intelligence models often achieve strong performance in single-center or single-device settings, yet their effectiveness frequently deteriorates in real-world cross-center deployment due to domain shift, limiting clinical generalizability. To address this challenge, we propose a lightweight domain generalization framework with quantum-enhanced collaborative learning, enabling robust generalization to unseen target domains without relying on real multi-center labeled data. Specifically, a MobileNetV2-based domain-invariant encoder is constructed and optimized through three key components: (1) multi-domain imaging shift simulation using brightness, contrast, sharpening, and noise perturbations to emulate heterogeneous acquisition conditions; (2) domain-adversarial training with gradient reversal to suppress domain-discriminative features; and (3) a lightweight quantum feature enhancement layer that applies parameterized quantum circuits for nonlinear feature mapping and entanglement modeling. In addition, a test-time adaptation strategy is employed during inference to further alleviate distribution shifts. Experiments on simulated multi-center medical imaging datasets demonstrate that the proposed method significantly outperforms baseline models without domain generalization or quantum enhancement on unseen domains, achieving reduced domain-specific performance variance and improved AUC and sensitivity. These results highlight the clinical potential of quantum-enhanced domain generalization under constrained computational resources and provide a feasible paradigm for hybrid quantum--classical medical imaging systems.

</details>


### [69] [VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding](https://arxiv.org/abs/2601.17868)
*Zhihao He,Tieyuan Chen,Kangyu Wang,Ziran Qin,Yang Shao,Chaofan Gan,Shijie Li,Zuxuan Wu,Weiyao Lin*

Main category: cs.CV

TL;DR: VidLaDA是一种基于扩散语言模型的视频LLM，通过双向注意力捕获双向依赖关系，解决了自回归视频LLM中的因果掩码偏差问题，并引入MARS-Cache框架加速推理


<details>
  <summary>Details</summary>
Motivation: 标准自回归视频LLM不可避免地遭受因果掩码偏差的困扰，这阻碍了全局时空建模，导致理解效率低下

Method: 提出VidLaDA，一种基于扩散语言模型的视频LLM，利用双向注意力捕获双向依赖关系；引入MARS-Cache框架，通过异步视觉缓存刷新和帧级块注意力加速推理，同时通过锚点令牌保持全局连接性

Result: VidLaDA在实验中优于扩散基线模型，并与最先进的自回归模型（如Qwen2.5-VL和LLaVA-Video）相媲美，MARS-Cache实现了超过12倍的加速而不损害推理准确性

Conclusion: VidLaDA通过扩散语言模型和双向注意力机制有效解决了自回归视频LLM的因果掩码偏差问题，MARS-Cache框架显著加速了推理过程，为视频理解提供了高效解决方案

Abstract: Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.

</details>


### [70] [Quran-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran](https://arxiv.org/abs/2601.17880)
*Muhammad Umar Salman,Mohammad Areeb Qazi,Mohammed Talha Alam*

Main category: cs.CV

TL;DR: Quran MD是一个包含文本、语言学和音频的多模态古兰经数据集，提供经文和单词级别的阿拉伯文本、英文翻译、音标转写以及32位不同诵经者的音频对齐数据。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在创建一个综合性的多模态古兰经数据集，整合文本和音频维度，以支持古兰经诵经传统的研究和计算分析。古兰经具有丰富的口传传统，不同诵经者的风格和方言差异需要系统性的数据收集。

Method: 数据集在经文级别提供阿拉伯原文、英文翻译和音标转写，并包含32位不同诵经者的音频。在单词级别，每个词元都配有阿拉伯文字、英文翻译、转写和对齐的音频录音，实现细粒度的发音、音韵和语义分析。

Result: 创建了Quran MD数据集，这是一个全面的多模态资源，支持自然语言处理、语音识别、文本转语音合成、语言学分析和数字伊斯兰研究等多种应用。数据集已在Hugging Face平台公开可用。

Conclusion: 该数据集为古兰经诵经的计算方法研究提供了独特资源，支持ASR、tajweed检测、古兰经TTS等任务，并为多模态嵌入、语义检索、风格转换和个性化辅导系统奠定了基础，既可用于研究也可用于社区应用。

Abstract: We present Quran MD, a comprehensive multimodal dataset of the Quran that integrates textual, linguistic, and audio dimensions at the verse and word levels. For each verse (ayah), the dataset provides its original Arabic text, English translation, and phonetic transliteration. To capture the rich oral tradition of Quranic recitation, we include verse-level audio from 32 distinct reciters, reflecting diverse recitation styles and dialectical nuances. At the word level, each token is paired with its corresponding Arabic script, English translation, transliteration, and an aligned audio recording, allowing fine-grained analysis of pronunciation, phonology, and semantic context. This dataset supports various applications, including natural language processing, speech recognition, text-to-speech synthesis, linguistic analysis, and digital Islamic studies. Bridging text and audio modalities across multiple reciters, this dataset provides a unique resource to advance computational approaches to Quranic recitation and study. Beyond enabling tasks such as ASR, tajweed detection, and Quranic TTS, it lays the foundation for multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems that can support both research and community applications. The dataset is available at https://huggingface.co/datasets/Buraaq/quran-audio-text-dataset

</details>


### [71] [PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation](https://arxiv.org/abs/2601.17885)
*Qingyu Fan,Zhaoxiang Li,Yi Lu,Wang Chen,Qiu Shen,Xiao-xiao Long,Yinghao Cai,Tao Lu,Shuo Wang,Xun Cao*

Main category: cs.CV

TL;DR: PEAfowl是一种用于双手操作的感知增强多视角视觉-语言-动作策略，通过几何感知的3D表示和迭代式指令接地，显著提升了在杂乱场景中的操作性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在双手操作中存在两个主要问题：1) 多视角特征通过视角无关的token拼接融合，导致3D空间理解能力弱；2) 语言作为全局条件注入，导致指令接地粗糙。这些限制了模型在遮挡、视角和场景变化下的泛化能力。

Method: 1) 空间推理：预测每个token的深度分布，进行可微分的3D提升，聚合局部跨视角邻居形成几何基础、跨视角一致的表示；2) 指令接地：用Perceiver风格的文本感知读取机制替代全局条件，在冻结的CLIP视觉特征上进行迭代证据积累；3) 深度蒸馏：仅训练时使用预训练深度教师监督深度分布头，为感知前端提供几何感知先验。

Result: 在RoboTwin 2.0的领域随机化设置下，PEAfowl将最强基线的成功率提高了23.0个百分点。真实机器人实验进一步证明了可靠的模拟到真实迁移和深度蒸馏带来的持续改进。

Conclusion: PEAfowl通过几何感知的3D表示和迭代式指令接地，显著提升了双手操作在杂乱场景中的性能，实现了有效的模拟到真实迁移。

Abstract: Bimanual manipulation in cluttered scenes requires policies that remain stable under occlusions, viewpoint and scene variations. Existing vision-language-action models often fail to generalize because (i) multi-view features are fused via view-agnostic token concatenation, yielding weak 3D-consistent spatial understanding, and (ii) language is injected as global conditioning, resulting in coarse instruction grounding.
  In this paper, we introduce PEAfowl, a perception-enhanced multi-view VLA policy for bimanual manipulation. For spatial reasoning, PEAfowl predicts per-token depth distributions, performs differentiable 3D lifting, and aggregates local cross-view neighbors to form geometrically grounded, cross-view consistent representations. For instruction grounding, we propose to replace global conditioning with a Perceiver-style text-aware readout over frozen CLIP visual features, enabling iterative evidence accumulation. To overcome noisy and incomplete commodity depth without adding inference overhead, we apply training-only depth distillation from a pretrained depth teacher to supervise the depth-distribution head, providing perception front-end with geometry-aware priors.
  On RoboTwin 2.0 under domain-randomized setting, PEAfowl improves the strongest baseline by 23.0 pp in success rate, and real-robot experiments further demonstrate reliable sim-to-real transfer and consistent improvements from depth distillation.
  Project website: https://peafowlvla.github.io/.

</details>


### [72] [Masked Depth Modeling for Spatial Perception](https://arxiv.org/abs/2601.17895)
*Bin Tan,Changjiang Sun,Xiage Qin,Hanat Adai,Zelin Fu,Tianxiang Zhou,Han Zhang,Yinghao Xu,Xing Zhu,Yujun Shen,Nan Xue*

Main category: cs.CV

TL;DR: 提出LingBot-Depth深度补全模型，通过掩码深度建模利用视觉上下文优化深度图，在深度精度和像素覆盖方面优于顶级RGB-D相机


<details>
  <summary>Details</summary>
Motivation: 空间视觉感知在自动驾驶和机器人操作等物理世界应用中至关重要，但RGB-D相机获取像素对齐的度量深度面临硬件限制和挑战性成像条件（如镜面或纹理缺失表面）的障碍

Method: 提出LingBot-Depth深度补全模型，将深度传感器的不准确性视为反映底层几何模糊性的"掩码"信号，通过掩码深度建模利用视觉上下文优化深度图，并包含自动化数据整理流程进行可扩展训练

Result: 模型在深度精度和像素覆盖方面优于顶级RGB-D相机，在多个下游任务中提供RGB和深度模态的对齐潜在表示，发布了代码、检查点和300万RGB-深度对（包括200万真实数据和100万模拟数据）

Conclusion: LingBot-Depth通过掩码深度建模和自动化数据整理，有效解决了深度传感器在挑战性条件下的不准确性问题，为空间感知社区提供了有价值的工具和数据集

Abstract: Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as "masked" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.

</details>


### [73] [Revisiting 3D Reconstruction Kernels as Low-Pass Filters](https://arxiv.org/abs/2601.17900)
*Shengjun Zhang,Min Chen,Yibo Wei,Mingyu Dong,Yueqi Duan*

Main category: cs.CV

TL;DR: 论文从信号处理角度重新审视3D重建，提出使用Jinc核函数作为理想低通滤波器来解决离散采样导致的频谱扩展问题，并通过调制核函数平衡空间效率和频域保真度。


<details>
  <summary>Details</summary>
Motivation: 传统3D重建核函数（高斯、指数、学生t分布）作为低通滤波器存在不理想的低通特性，导致高频分量与低频分量在离散信号频谱中重叠，这是由离散采样引起的周期性频谱扩展造成的根本问题。

Method: 引入Jinc核函数作为理想低通滤波器，在截止频率处具有瞬时降为零的特性；针对Jinc核在空间域衰减速度慢的问题，进一步提出调制核函数，在空间效率和频域保真度之间取得平衡。

Result: 实验结果表明，Jinc核和调制核函数在渲染性能方面表现出色，通过协调空间效率和频域保真度实现了优越的渲染效果。

Conclusion: 从信号处理角度重新审视3D重建问题，提出基于理想低通滤波器的Jinc核函数和调制核函数，有效解决了离散采样导致的频谱混叠问题，在3D重建中实现了更好的性能平衡。

Abstract: 3D reconstruction is to recover 3D signals from the sampled discrete 2D pixels, with the goal to converge continuous 3D spaces. In this paper, we revisit 3D reconstruction from the perspective of signal processing, identifying the periodic spectral extension induced by discrete sampling as the fundamental challenge. Previous 3D reconstruction kernels, such as Gaussians, Exponential functions, and Student's t distributions, serve as the low pass filters to isolate the baseband spectrum. However, their unideal low-pass property results in the overlap of high-frequency components with low-frequency components in the discrete-time signal's spectrum. To this end, we introduce Jinc kernel with an instantaneous drop to zero magnitude exactly at the cutoff frequency, which is corresponding to the ideal low pass filters. As Jinc kernel suffers from low decay speed in the spatial domain, we further propose modulated kernels to strick an effective balance, and achieves superior rendering performance by reconciling spatial efficiency and frequency-domain fidelity. Experimental results have demonstrated the effectiveness of our Jinc and modulated kernels.

</details>


### [74] [Feature-Space Generative Models for One-Shot Class-Incremental Learning](https://arxiv.org/abs/2601.17905)
*Jack Foster,Kirill Paramonov,Mete Ozay,Umberto Michieli*

Main category: cs.CV

TL;DR: Gen1S：一种基于生成模型的单样本类增量学习方法，通过将嵌入空间映射到残差空间，利用VAE或扩散模型学习基础类残差分布，作为结构先验来提升新类识别


<details>
  <summary>Details</summary>
Motivation: 解决单样本类增量学习（FSCIL）的挑战性问题，特别是在每个新类只有一个样本且不允许后续训练或模型修改的情况下，如何有效识别新类

Method: 提出Gen1S方法：1）将原始嵌入空间映射到残差空间（减去类别原型）；2）使用VAE或扩散模型学习基础类残差的多模态分布；3）利用该结构先验提升新类识别

Result: Gen1S在多个基准测试和骨干架构上，相比现有技术持续提升了新类识别性能

Conclusion: 通过将嵌入空间转换为残差空间并利用生成模型学习结构先验，可以有效解决单样本类增量学习中的新类识别难题

Abstract: Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.

</details>


### [75] [Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models](https://arxiv.org/abs/2601.17918)
*Dain Kim,Jiwoo Lee,Jaehoon Yun,Yong Hoe Koo,Qingyu Chen,Hyunjae Kim,Jaewoo Kang*

Main category: cs.CV

TL;DR: 该研究首次全面评估了医疗领域大视觉语言模型中多种DPO变体的效果，发现现有方法在医疗任务中效果不稳定，且无法解决视觉误解问题，提出了一种针对性的偏好构建策略来改善视觉误解错误。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型在医疗应用中有巨大潜力，但其部署受到对齐不足和可靠性问题的限制。虽然直接偏好优化已成为优化模型响应的有效框架，但在高风险医疗环境中的效果尚未得到充分探索，缺乏指导未来方法发展的严谨实证基础。

Method: 研究对医疗领域中的多种DPO变体进行了首次全面评估，在LLaVA-Med和HuatuoGPT-Vision两个医疗LVLM上评估了九种不同的DPO公式。基于发现的问题，提出了一种针对性的偏好构建策略，专门解决现有DPO模型中常见的视觉误解错误。

Result: 研究揭示了当前DPO方法的几个关键局限性：在监督微调基础上效果不一致，不同任务和骨干模型间效果差异显著，且无法解决基本的视觉误解错误。提出的针对性偏好构建策略在视觉问答任务上比现有最强DPO基线提高了3.6%。

Conclusion: 该研究填补了医疗领域DPO方法评估的空白，揭示了现有方法的局限性，并提出了改进视觉误解问题的解决方案。研究发布了完整的框架，包括训练数据、模型检查点和代码库，以支持未来研究。

Abstract: Large Vision-Language Models (LVLMs) hold significant promise for medical applications, yet their deployment is often constrained by insufficient alignment and reliability. While Direct Preference Optimization (DPO) has emerged as a potent framework for refining model responses, its efficacy in high-stakes medical contexts remains underexplored, lacking the rigorous empirical groundwork necessary to guide future methodological advances. To bridge this gap, we present the first comprehensive examination of diverse DPO variants within the medical domain, evaluating nine distinct formulations across two medical LVLMs: LLaVA-Med and HuatuoGPT-Vision. Our results reveal several critical limitations: current DPO approaches often yield inconsistent gains over supervised fine-tuning, with their efficacy varying significantly across different tasks and backbones. Furthermore, they frequently fail to resolve fundamental visual misinterpretation errors. Building on these insights, we present a targeted preference construction strategy as a proof-of-concept that explicitly addresses visual misinterpretation errors frequently observed in existing DPO models. This design yields a 3.6% improvement over the strongest existing DPO baseline on visual question-answering tasks. To support future research, we release our complete framework, including all training data, model checkpoints, and our codebase at https://github.com/dmis-lab/med-vlm-dpo.

</details>


### [76] [RemEdit: Efficient Diffusion Editing with Riemannian Geometry](https://arxiv.org/abs/2601.17927)
*Eashan Adhikarla,Brian D. Davison*

Main category: cs.CV

TL;DR: RemEdit是一个扩散模型图像编辑框架，通过黎曼流形导航和任务特定注意力剪枝，在保持语义保真度的同时实现实时性能


<details>
  <summary>Details</summary>
Motivation: 现代生成式AI中的可控图像生成面临语义保真度和推理速度之间的关键权衡，现有方法难以同时兼顾这两个方面

Method: 1. 将潜在空间视为黎曼流形，使用Mamba模块学习流形结构，直接计算测地线路径实现平滑语义编辑；2. 采用双SLERP混合技术和视觉语言模型的目标感知提示增强；3. 引入任务特定注意力剪枝机制，轻量级剪枝头学习保留编辑必需的特征

Result: RemEdit超越了先前最先进的编辑框架，在50%剪枝率下仍保持实时性能，为实用强大的图像编辑设立了新基准

Conclusion: RemEdit通过黎曼流形导航和任务特定注意力剪枝的协同创新，成功解决了图像编辑中语义保真度与推理速度的权衡问题，实现了实用且强大的图像编辑

Abstract: Controllable image generation is fundamental to the success of modern generative AI, yet it faces a critical trade-off between semantic fidelity and inference speed. The RemEdit diffusion-based framework addresses this trade-off with two synergistic innovations. First, for editing fidelity, we navigate the latent space as a Riemannian manifold. A mamba-based module efficiently learns the manifold's structure, enabling direct and accurate geodesic path computation for smooth semantic edits. This control is further refined by a dual-SLERP blending technique and a goal-aware prompt enrichment pass from a Vision-Language Model. Second, for additional acceleration, we introduce a novel task-specific attention pruning mechanism. A lightweight pruning head learns to retain tokens essential to the edit, enabling effective optimization without the semantic degradation common in content-agnostic approaches. RemEdit surpasses prior state-of-the-art editing frameworks while maintaining real-time performance under 50% pruning. Consequently, RemEdit establishes a new benchmark for practical and powerful image editing. Source code: https://www.github.com/eashanadhikarla/RemEdit.

</details>


### [77] [From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images](https://arxiv.org/abs/2601.17934)
*Vi Vu,Thanh-Huy Nguyen,Tien-Thinh Nguyen,Ba-Thinh Lam,Hoang-Thien Nguyen,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: SC-SAM提出了一种专家-通用框架，通过U-Net为SAM提供点提示和伪标签，同时SAM作为通用监督器正则化U-Net，形成双向协同训练循环，有效利用未标记数据进行医学图像分割。


<details>
  <summary>Details</summary>
Motivation: 虽然基础模型如SAM展现出强大的泛化能力，但将其适应到医学图像领域仍面临挑战：领域偏移、标签稀缺，以及参数高效微调方法无法有效利用未标记数据。传统模型如U-Net在半监督医学学习中表现出色，但其辅助PEFT SAM的潜力被忽视。

Method: 提出SC-SAM专家-通用框架：U-Net作为专家提供点提示和伪标签来指导SAM的适应，同时SAM作为通用监督器正则化U-Net。这种相互指导形成双向协同训练循环，使两个模型都能有效利用未标记数据。

Result: 在前列腺MRI和息肉分割基准测试中，该方法取得了最先进的结果，超越了其他现有的半监督SAM变体，甚至优于MedSAM等医学基础模型，证明了专家-通用协作在标签高效医学图像分割中的价值。

Conclusion: SC-SAM通过专家-通用协作框架，成功解决了医学图像分割中基础模型适应的问题，展示了双向协同训练在利用未标记数据方面的有效性，为标签稀缺的医学图像分析提供了有前景的解决方案。

Abstract: Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.

</details>


### [78] [UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders](https://arxiv.org/abs/2601.17950)
*Matthew Walmer,Saksham Suri,Anirud Aggarwal,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: UPLiFT是一种通用像素密集轻量级特征变换架构，通过局部注意力算子实现高效的特征上采样，在保持高性能的同时降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于交叉注意力的特征上采样方法存在效率扩展问题，而早期迭代上采样方法性能有限。需要开发既能保持高性能又具有低推理成本的特征上采样方法。

Method: 提出UPLiFT架构，采用迭代上采样方法，并引入高效的局部注意力算子，使用完全局部定义的注意力池化公式来稳定特征上采样过程。

Result: UPLiFT在保持特征稳定的同时实现了最先进的性能，推理成本低于现有像素密集特征上采样器，在生成下游任务中与最先进的耦合流匹配模型竞争。

Conclusion: UPLiFT提供了一种多功能且高效的方法来创建更密集的特征，证明迭代上采样方法仍能与基于交叉注意力的方法竞争，并在效率和性能之间取得良好平衡。

Abstract: The space of task-agnostic feature upsampling has emerged as a promising area of research to efficiently create denser features from pre-trained visual backbones. These methods act as a shortcut to achieve dense features for a fraction of the cost by learning to map low-resolution features to high-resolution versions. While early works in this space used iterative upsampling approaches, more recent works have switched to cross-attention-based methods, which risk falling into the same efficiency scaling problems of the backbones they are upsampling. In this work, we demonstrate that iterative upsampling methods can still compete with cross-attention-based methods; moreover, they can achieve state-of-the-art performance with lower inference costs. We propose UPLiFT, an architecture for Universal Pixel-dense Lightweight Feature Transforms. We also propose an efficient Local Attender operator to overcome the limitations of prior iterative feature upsampling methods. This operator uses an alternative attentional pooling formulation defined fully locally. We show that our Local Attender allows UPLiFT to maintain stable features throughout upsampling, enabling state-of-the-art performance with lower inference costs than existing pixel-dense feature upsamplers. In addition, we apply UPLiFT to generative downstream tasks and show that it achieves competitive performance with state-of-the-art Coupled Flow Matching models for VAE feature upsampling. Altogether, UPLiFT offers a versatile and efficient approach to creating denser features.

</details>


### [79] [Domain-Expert-Guided Hybrid Mixture-of-Experts for Medical AI: Integrating Data-Driven Learning with Clinical Priors](https://arxiv.org/abs/2601.17977)
*Jinchen Gu,Nan Zhao,Lei Qiu,Lu Zhang*

Main category: cs.CV

TL;DR: 提出DKGH-MoE模型，结合数据驱动和领域专家知识，通过混合专家架构提升医学影像诊断的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医学领域的MoE模型受限于小数据集，而临床实践中丰富的专家知识（如医生注视模式、诊断启发式）无法从有限数据中可靠学习。结合数据驱动专家（捕捉新模式）和领域专家指导专家（编码临床洞察）可提供互补优势。

Method: 提出DKGH-MoE（领域知识引导混合MoE），这是一个即插即用且可解释的模块。包含两个部分：1）数据驱动MoE从原始影像数据提取新特征；2）领域专家引导MoE整合临床先验知识（特别是临床医生眼动注视线索），强调高诊断相关区域。

Result: 通过整合领域专家洞察和数据驱动特征，DKGH-MoE提升了性能和可解释性。

Conclusion: DKGH-MoE通过统一数据驱动学习和领域专业知识，为医学影像分析提供了更稳健且具有临床意义的解决方案。

Abstract: Mixture-of-Experts (MoE) models increase representational capacity with modest computational cost, but their effectiveness in specialized domains such as medicine is limited by small datasets. In contrast, clinical practice offers rich expert knowledge, such as physician gaze patterns and diagnostic heuristics, that models cannot reliably learn from limited data. Combining data-driven experts, which capture novel patterns, with domain-expert-guided experts, which encode accumulated clinical insights, provides complementary strengths for robust and clinically meaningful learning. To this end, we propose Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE), a plug-and-play and interpretable module that unifies data-driven learning with domain expertise. DKGH-MoE integrates a data-driven MoE to extract novel features from raw imaging data, and a domain-expert-guided MoE incorporates clinical priors, specifically clinician eye-gaze cues, to emphasize regions of high diagnostic relevance. By integrating domain expert insights with data-driven features, DKGH-MoE improves both performance and interpretability.

</details>


### [80] [MorphXAI: An Explainable Framework for Morphological Analysis of Parasites in Blood Smear Images](https://arxiv.org/abs/2601.18001)
*Aqsa Yousaf,Sint Sint Win,Megan Coffee,Habeeb Olufowobi*

Main category: cs.CV

TL;DR: MorphXAI是一个可解释的寄生虫检测框架，将形态学监督集成到预测流程中，在检测寄生虫的同时提供临床相关的形态特征分析。


<details>
  <summary>Details</summary>
Motivation: 当前寄生虫感染诊断在资源匮乏地区仍依赖人工血涂片检查，深度学习模型虽然性能好但可解释性有限。现有解释方法主要是视觉热图或注意力图，无法捕捉临床医生依赖的形态特征。

Method: 提出MorphXAI框架，将形态学监督直接集成到预测流程中，使模型能够定位寄生虫同时表征临床相关属性（形状、曲率、可见点计数、鞭毛存在、发育阶段等）。创建了包含三种寄生虫物种（利什曼原虫、布氏锥虫、克氏锥虫）的临床医生标注数据集。

Result: 实验结果表明MorphXAI不仅提高了检测性能，还提供了结构化、具有生物学意义的解释。

Conclusion: MorphXAI建立了一个可解释寄生虫分析的新基准，统一了寄生虫检测与细粒度形态分析，为临床诊断提供了更有用的工具。

Abstract: Parasitic infections remain a pressing global health challenge, particularly in low-resource settings where diagnosis still depends on labor-intensive manual inspection of blood smears and the availability of expert domain knowledge. While deep learning models have shown strong performance in automating parasite detection, their clinical usefulness is constrained by limited interpretability. Existing explainability methods are largely restricted to visual heatmaps or attention maps, which highlight regions of interest but fail to capture the morphological traits that clinicians rely on for diagnosis. In this work, we present MorphXAI, an explainable framework that unifies parasite detection with fine-grained morphological analysis. MorphXAI integrates morphological supervision directly into the prediction pipeline, enabling the model to localize parasites while simultaneously characterizing clinically relevant attributes such as shape, curvature, visible dot count, flagellum presence, and developmental stage. To support this task, we curate a clinician-annotated dataset of three parasite species (Leishmania, Trypanosoma brucei, and Trypanosoma cruzi) with detailed morphological labels, establishing a new benchmark for interpretable parasite analysis. Experimental results show that MorphXAI not only improves detection performance over the baseline but also provides structured, biologically meaningful explanations.

</details>


### [81] [Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling](https://arxiv.org/abs/2601.18049)
*Yunfei Qiu,Qiqiong Ma,Tianhua Lv,Li Fang,Shudong Zhou,Wei Yao*

Main category: cs.CV

TL;DR: 本文提出了一种集成空间先验信息与动态学习机制的半监督高光谱图像分类框架，通过边缘感知超像素标签传播模块和动态历史融合预测方法，解决了边界标签扩散和伪标签不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 由于高光谱图像标注成本高、样本有限，半监督学习面临边界标签扩散和伪标签不稳定性等挑战。现有方法在这些问题上表现不足，需要新的框架来提升分类鲁棒性和时空一致性。

Method: 1. 边缘感知超像素标签传播模块：集成边缘强度惩罚与邻域校正策略，缓解超像素分割导致的标签扩散；2. 动态历史融合预测方法：维护历史预测并动态加权当前结果，平滑伪标签波动；3. 自适应三元样本分类策略：基于置信度和一致性度量，分层利用易、模糊和难样本；4. 动态可靠性增强伪标签框架：整合上述组件实现时空一致性优化。

Result: 在四个基准数据集上的评估表明，该框架能够保持优越的分类性能，有效解决了边界标签扩散和伪标签不稳定性问题，提升了分类鲁棒性和时空一致性。

Conclusion: 提出的集成空间先验信息与动态学习机制的半监督高光谱图像分类框架，通过边缘感知标签传播和动态可靠性增强伪标签策略，成功解决了现有方法的局限性，在多个数据集上验证了其有效性。

Abstract: Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance.

</details>


### [82] [Cross-Domain Transfer with Self-Supervised Spectral-Spatial Modeling for Hyperspectral Image Classification](https://arxiv.org/abs/2601.18088)
*Jianshu Chao,Tianhua Lv,Qiqiong Ma,Yunfei Qiu,Li Fang,Huifang Shen,Wei Yao*

Main category: cs.CV

TL;DR: 提出了一种无需源域标注的自监督跨域迁移框架，通过空间-光谱Transformer和频率域约束学习可迁移的联合表示，在目标域少量样本下实现高效适应。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法在跨域迁移场景中仍依赖源域标注，且对分布偏移敏感，导致在目标域的泛化性能下降。需要开发无需源域标签且能在目标域少量样本下有效适应的跨域迁移方法。

Method: 1. 自监督预训练阶段：设计空间-光谱Transformer模块，采用双分支结构和双向交叉注意力机制实现光谱-空间协同建模；引入频率域约束通过实快速傅里叶变换和高频幅度损失保持频域一致性。2. 微调阶段：提出扩散对齐微调蒸馏机制，通过师生结构对齐语义演化轨迹，实现低标签条件下的鲁棒迁移学习。

Result: 在四个高光谱数据集上的实验结果表明，该方法具有稳定的分类性能和强大的跨域适应能力，验证了在资源受限条件下的有效性。

Conclusion: 提出的自监督跨域迁移框架能够在不依赖源域标注的情况下学习可迁移的光谱-空间联合表示，并通过频率域约束和扩散对齐微调机制，在目标域少量样本条件下实现高效适应，为资源受限的高光谱分析提供了有效解决方案。

Abstract: Self-supervised learning has demonstrated considerable potential in hyperspectral representation, yet its application in cross-domain transfer scenarios remains under-explored. Existing methods, however, still rely on source domain annotations and are susceptible to distribution shifts, leading to degraded generalization performance in the target domain. To address this, this paper proposes a self-supervised cross-domain transfer framework that learns transferable spectral-spatial joint representations without source labels and achieves efficient adaptation under few samples in the target domain. During the self-supervised pre-training phase, a Spatial-Spectral Transformer (S2Former) module is designed. It adopts a dual-branch spatial-spectral transformer and introduces a bidirectional cross-attention mechanism to achieve spectral-spatial collaborative modeling: the spatial branch enhances structural awareness through random masking, while the spectral branch captures fine-grained differences. Both branches mutually guide each other to improve semantic consistency. We further propose a Frequency Domain Constraint (FDC) to maintain frequency-domain consistency through real Fast Fourier Transform (rFFT) and high-frequency magnitude loss, thereby enhancing the model's capability to discern fine details and boundaries. During the fine-tuning phase, we introduce a Diffusion-Aligned Fine-tuning (DAFT) distillation mechanism. This aligns semantic evolution trajectories through a teacher-student structure, enabling robust transfer learning under low-label conditions. Experimental results demonstrate stable classification performance and strong cross-domain adaptability across four hyperspectral datasets, validating the method's effectiveness under resource-constrained conditions.

</details>


### [83] [Text-Pass Filter: An Efficient Scene Text Detector](https://arxiv.org/abs/2601.18098)
*Chuang Yang,Haozhao Ma,Xu Han,Yuan Yuan,Qi Wang*

Main category: cs.CV

TL;DR: TPF是一种用于任意形状文本检测的新方法，通过模拟带通滤波器原理，为每个文本构建特征-滤波器对，直接分割整个文本区域，避免了传统收缩-扩展策略的固有局限，并能自然分离粘连文本。


<details>
  <summary>Details</summary>
Motivation: 现有文本检测方法采用收缩-掩码扩展策略，但收缩操作会丢失文本边缘的视觉特征，混淆前景与背景差异，这给文本特征识别带来了固有局限。需要一种能直接分割整个文本区域且能自然分离粘连文本的方法。

Method: 提出文本通滤波器（TPF），模拟带通滤波器原理，为每个文本构建独特的特征-滤波器对。在推理阶段，每个滤波器通过其通带特征并阻挡其他特征来提取匹配的文本。设计了强化集成单元（REU）增强同一文本的特征一致性并扩大滤波器的识别范围，以及前景先验单元（FPU）改善前景与背景的区分能力。

Result: 实验证明了REU和FPU的有效性，并展示了TPF方法的优越性。该方法能够自然分离粘连文本，无需复杂的解码或后处理过程，实现了实时文本检测的可能性。

Conclusion: TPF通过模拟带通滤波器机制，成功解决了传统文本检测方法的固有局限，能够直接分割整个文本区域并自然分离粘连文本，为实时文本检测提供了有效解决方案。

Abstract: To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority.

</details>


### [84] [Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs](https://arxiv.org/abs/2601.18099)
*Akbar Saadat*

Main category: cs.CV

TL;DR: 提出零训练前向计算框架，通过解析表达式离散计算实现实时高斯模型去模糊，在真实图像上MAE低于1.7%


<details>
  <summary>Details</summary>
Motivation: 在先前高斯模型验证基础上，为实时应用开发无需训练的快速计算框架，处理两幅图像互为部分模糊版本的情况

Method: 基于高斯核标准差应用范围的解析表达式离散计算，从清晰图像计算散焦图像，通过邻域相似度度量筛选多解

Result: 在真实图像上，合成模糊值估计的MAE低于1.7%，实际模糊图像强度与估计值的差异保持在2%以内

Conclusion: 提出的零训练框架能有效实现实时高斯模型去模糊，在真实图像上表现出高精度和实用性

Abstract: Following the earlier verification for Gaussian model in \cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\%$, obtained by applying the extracted defocus filters to less blurred images.

</details>


### [85] [Spatial-Conditioned Reasoning in Long-Egocentric Videos](https://arxiv.org/abs/2601.18100)
*James Tribble,Hao Wang,Si-En Hong,Chaoyi Zhou,Ashish Bastola,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

TL;DR: 研究探讨了显式空间信号如何影响基于VLM的长时序自我中心视频理解，通过引入Sanpo-D数据集和融合深度图来评估空间推理能力


<details>
  <summary>Details</summary>
Motivation: 长时序自我中心视频存在视角漂移和缺乏持久几何上下文的问题，现有视觉语言模型在长时序空间推理方面能力有限，需要研究显式空间信号对VLM视频理解的影响

Method: 1) 引入Sanpo-D数据集（Google Sanpo数据集的细粒度重新标注）；2) 在导航导向的空间查询上对多个VLM进行基准测试；3) 融合深度图与RGB帧来研究输入级归纳偏置

Result: 结果显示通用准确性与空间专业化之间存在权衡，深度感知和空间基础表示可以提升行人检测和障碍物检测等安全关键任务的性能

Conclusion: 显式空间信号能够增强VLM在长时序自我中心视频中的空间推理能力，深度感知表示对安全关键任务有积极影响

Abstract: Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection.

</details>


### [86] [LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment](https://arxiv.org/abs/2601.18118)
*Daeyoung Kim*

Main category: cs.CV

TL;DR: 本文提出LungCRCT框架，通过因果表示学习分析肺癌进展的物理因果机制，实现因果干预分析和轻量级肿瘤分类，AUC达93.91%


<details>
  <summary>Details</summary>
Motivation: 肺癌早期症状不明显且易与其他呼吸疾病混淆，导致早期诊断困难。虽然LDCT扫描和CNN/ViT模型在肺癌检测方面取得进展，但由于相关依赖性限制和可解释性差，难以扩展到治疗分析和因果干预模拟

Method: 提出LungCRCT框架，基于图自编码器的因果发现算法，结合距离相关解纠缠和基于熵的图像重建细化，从肺癌进展的物理因果机制中提取因果表示

Result: 框架不仅支持肺癌治疗的因果干预分析，还在恶性肿瘤分类任务中实现了93.91%的AUC得分，且下游模型极其轻量

Conclusion: LungCRCT通过因果表示学习克服了传统深度学习模型的局限性，为肺癌分析提供了可解释的因果框架，支持治疗干预模拟和高效的肿瘤分类

Abstract: Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%.

</details>


### [87] [Forward Consistency Learning with Gated Context Aggregation for Video Anomaly Detection](https://arxiv.org/abs/2601.18135)
*Jiahao Lyu,Minghua Zhao,Xuewen Huang,Yifei Chen,Shuangli Du,Jing Hu,Cheng Shi,Zhiyong Lv*

Main category: cs.CV

TL;DR: FoGA是一个轻量级视频异常检测模型，通过前向一致性学习和门控上下文聚合，仅含约200万参数，适合边缘设备部署，在性能和效率间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法大多依赖大规模模型追求极致精度，限制了在资源受限边缘设备上的可行性。同时主流预测方法仅使用单帧未来预测误差检测异常，忽略了更长期时间前向信息的丰富约束。

Method: 提出基于Unet的方法，对连续帧进行特征提取，生成即时和前向预测；在跳跃连接中引入门控上下文聚合模块，动态融合编码器和解码器特征；使用新颖的前向一致性损失联合优化模型，采用混合异常测量策略整合即时和前向帧的误差。

Result: 实验表明该方法显著优于现有最先进方法，运行速度可达155 FPS，在性能和效率指标间实现了优秀的平衡。

Conclusion: FoGA是一个轻量级视频异常检测模型，通过前向一致性学习和门控上下文聚合，在保持高性能的同时实现了高效率，适合边缘设备部署。

Abstract: As a crucial element of public security, video anomaly detection (VAD) aims to measure deviations from normal patterns for various events in real-time surveillance systems. However, most existing VAD methods rely on large-scale models to pursue extreme accuracy, limiting their feasibility on resource-limited edge devices. Moreover, mainstream prediction-based VAD detects anomalies using only single-frame future prediction errors, overlooking the richer constraints from longer-term temporal forward information. In this paper, we introduce FoGA, a lightweight VAD model that performs Forward consistency learning with Gated context Aggregation, containing about 2M parameters and tailored for potential edge devices. Specifically, we propose a Unet-based method that performs feature extraction on consecutive frames to generate both immediate and forward predictions. Then, we introduce a gated context aggregation module into the skip connections to dynamically fuse encoder and decoder features at the same spatial scale. Finally, the model is jointly optimized with a novel forward consistency loss, and a hybrid anomaly measurement strategy is adopted to integrate errors from both immediate and forward frames for more accurate detection. Extensive experiments demonstrate the effectiveness of the proposed method, which substantially outperforms state-of-the-art competing methods, running up to 155 FPS. Hence, our FoGA achieves an excellent trade-off between performance and the efficiency metric.

</details>


### [88] [TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration](https://arxiv.org/abs/2601.18168)
*Zehua Liu,Shihao Zou,Jincai Huang,Yanfang Zhang,Chao Tong,Weixin Si*

Main category: cs.CV

TL;DR: 本文提出了一种用于经动脉化疗栓塞术的粗到细血管配准方法，结合结构感知透视n点全局对齐和时序扩散模型，显著提高了2D-3D血管配准的准确性和解剖合理性。


<details>
  <summary>Details</summary>
Motivation: 经动脉化疗栓塞术是肝癌等肝脏恶性肿瘤的首选治疗方法，但由于术中血管导航复杂和解剖结构变异大，该手术极具挑战性。精确稳健的2D-3D血管配准对于指导微导管和器械定位、实现精准治疗靶向至关重要。

Method: 提出粗到细配准策略：1）全局对齐模块SA-PnP，建立2D-3D血管结构对应关系；2）TempDiffReg时序扩散模型，利用时序上下文迭代进行血管变形，捕捉复杂解剖变异和局部结构变化。

Result: 在23名患者626个多帧样本上评估，方法在准确性和解剖合理性上均优于现有技术。具体指标：均方误差0.63mm，平均绝对误差0.51mm，相比最优现有方法分别降低66.7%和17.7%。

Conclusion: 该方法能显著提高血管配准精度，有助于经验不足的临床医生安全高效地执行复杂TACE手术，最终改善手术效果和患者护理。代码和数据已开源。

Abstract: Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\% lower MSE and 17.7\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}

</details>


### [89] [YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection](https://arxiv.org/abs/2601.18172)
*Lin Huang,Yujuan Tan,Weisheng Li,Shitai Shan,Liu Liu,Bo Liu,Linlin Shen,Jing Yu,Yue Niu*

Main category: cs.CV

TL;DR: YOLO-DS通过双统计协同算子(DSO)解耦物体特征，结合通道均值与峰均差建模，配合DSG和MSG门控模块，在YOLO系列上实现1.1-1.7% AP提升，推理延迟仅轻微增加。


<details>
  <summary>Details</summary>
Motivation: 现有YOLO检测器缺乏对共享特征通道中异构物体响应的显式建模，限制了性能的进一步提升。

Method: 提出YOLO-DS框架，核心是双统计协同算子(DSO)，通过联合建模通道均值和峰均差来解耦物体特征。基于DSO设计了两个轻量门控模块：双统计协同门控(DSG)用于自适应通道特征选择，多路径分段门控(MSG)用于深度特征加权。

Result: 在MS-COCO基准测试中，YOLO-DS在五个模型尺度(N,S,M,L,X)上均优于YOLOv8，AP提升1.1%至1.7%，推理延迟仅轻微增加。可视化、消融和对比研究验证了方法的有效性。

Conclusion: YOLO-DS通过显式建模异构物体响应，在保持高效率的同时显著提升检测性能，展示了在异构物体判别方面的优越能力。

Abstract: One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency.

</details>


### [90] [MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models](https://arxiv.org/abs/2601.18192)
*Tian-Yi Zhou,Xuan-Hao Liu,Bao-Liang Lu,Wei-Long Zheng*

Main category: cs.CV

TL;DR: MindCine框架通过多模态联合学习和预训练大模型，在有限EEG-视频数据上实现高质量视频重建


<details>
  <summary>Details</summary>
Motivation: EEG信号重建动态视觉感知具有重要研究意义，但现有方法存在两个主要问题：1）仅使用文本模态导致忽略其他模态且容易过拟合；2）数据稀缺导致训练困难

Method: 提出MindCine框架：1）采用多模态联合学习策略整合文本外其他模态；2）利用预训练大型EEG模型缓解数据稀缺问题解码语义信息；3）设计具有因果注意力的Seq2Seq模型解码感知信息

Result: 实验表明模型在定性和定量评估上均优于现有方法，验证了不同模态互补优势的有效性，以及大规模EEG模型通过缓解数据稀缺问题进一步提升重建性能

Conclusion: MindCine框架成功解决了EEG到视频重建中的单模态限制和数据稀缺问题，实现了高质量的视频重建，为基于EEG的视觉感知解码提供了有效解决方案

Abstract: Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data.

</details>


### [91] [QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding](https://arxiv.org/abs/2601.18195)
*Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Kaiwei Zhang,Jun Jia,Dandan Zhu,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: QualiRAG是一个无需训练的检索增强生成框架，利用大型多模态模型的潜在感知知识进行视觉质量评估，通过动态生成四种互补知识源实现细粒度时空感知和辅助上下文信息。


<details>
  <summary>Details</summary>
Motivation: 当前视觉质量评估方法依赖监督微调或强化学习，需要大量人工标注且容易受数据集特定偏差影响。为了克服这些挑战，需要一种无需训练的方法来利用大型多模态模型的潜在感知知识。

Method: 提出QualiRAG框架，将问题分解为结构化请求，动态生成四种互补知识源：视觉元数据、主体定位、全局质量摘要和局部质量描述，然后进行相关性感知检索，实现基于证据的推理。

Result: 在视觉质量理解任务上，QualiRAG显著优于开源通用大型多模态模型和专门微调的VQA模型；在视觉质量比较任务上表现出竞争力，无需任何任务特定训练就能实现稳健的质量评估能力。

Conclusion: QualiRAG通过检索增强生成框架成功利用了大型多模态模型的潜在感知知识，实现了无需训练的视觉质量评估，为细粒度时空感知和辅助上下文信息的需求提供了有效解决方案。

Abstract: Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \textit{fine-grained spatiotemporal perception} and \textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \textbf{QualiRAG}, a \textit{training-free} \textbf{R}etrieval-\textbf{A}ugmented \textbf{G}eneration \textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \textit{visual metadata}, \textit{subject localization}, \textit{global quality summaries}, and \textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG.

</details>


### [92] [HomoFM: Deep Homography Estimation with Flow Matching](https://arxiv.org/abs/2601.18222)
*Mengfan He,Liangzheng Sun,Chunyu Li,Ziyang Meng*

Main category: cs.CV

TL;DR: HomoFM将流匹配技术首次引入单应性估计，通过建模连续点速度场将噪声分布变换为配准坐标，并加入梯度反转层提升跨域鲁棒性，在标准基准上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度单应性估计方法通常将其视为直接回归或迭代优化问题，难以捕捉复杂几何变换或在不同域间泛化。需要一种新框架来解决这些限制。

Method: 提出HomoFM框架：1) 将单应性估计问题重新表述为速度场学习问题，建模连续点速度场将噪声分布变换为配准坐标；2) 通过条件流轨迹恢复高精度变换；3) 在特征提取主干中集成梯度反转层(GRL)进行域适应，学习域不变表示。

Result: 在标准基准测试上的广泛实验表明，HomoFM在估计精度和鲁棒性方面均优于现有最先进方法，特别是在多模态匹配和变化光照场景等域偏移挑战下表现优异。

Conclusion: HomoFM首次将流匹配技术引入单应性估计任务，通过速度场学习和域适应策略，显著提升了单应性估计的精度和跨域鲁棒性，为计算机视觉和机器人应用提供了有效的解决方案。

Abstract: Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.

</details>


### [93] [V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering](https://arxiv.org/abs/2601.18240)
*Mengyuan Jin,Zehui Liao,Yong Xia*

Main category: cs.CV

TL;DR: V-Loop是一个无需训练、即插即用的幻觉检测框架，通过双向推理形成视觉逻辑循环来验证医学VQA中答案的事实正确性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在医学视觉问答中表现出色，但其输出容易产生与视觉事实矛盾的幻觉，这在高风险医疗场景中构成重大风险。现有的不确定性检测方法虽然计算高效，但本质上是间接的，因为它们估计的是图像-问题对的预测不确定性，而非验证特定答案的事实正确性。

Method: V-Loop引入双向推理过程，形成视觉基础的逻辑循环来验证事实正确性。给定输入后，MLLM生成主要答案，V-Loop从主要QA对中提取语义单元，基于答案单元生成验证问题来重新查询问题单元，并通过强制视觉注意力一致性确保回答主要问题和验证问题都依赖相同的图像证据。如果验证答案与预期语义内容匹配，逻辑循环闭合，表明事实基础；否则，主要答案被标记为幻觉。

Result: 在多个医学VQA基准测试和MLLM上的广泛实验表明，V-Loop始终优于现有的内省方法，保持高效性，并且在与不确定性方法结合使用时能进一步提升性能。

Conclusion: V-Loop提供了一种直接验证医学VQA中答案事实正确性的有效方法，通过视觉逻辑循环检测幻觉，在保持计算效率的同时显著优于现有方法。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.

</details>


### [94] [Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation](https://arxiv.org/abs/2601.18242)
*Zerui Kang,Yishen Lim,Zhouyou Gu,Seung-Woo Ko,Tony Q. S. Quek,Jihong Park*

Main category: cs.CV

TL;DR: 提出基于视觉语言模型（VLM）引导的框架，加速和稳定多材料参数估计，通过语义先验指导物理优化，实现快速可靠的射频材料参数估计。


<details>
  <summary>Details</summary>
Motivation: 在6G系统中，精确的射频材料参数对电磁数字孪生至关重要，但基于梯度的逆射线追踪对初始化敏感且在有限测量下成本高昂。

Method: 使用视觉语言模型解析场景图像推断材料类别，通过ITU-R材料表映射到定量先验，提供有信息的电导率初始化；VLM进一步选择信息丰富的发射器/接收器位置以促进多样化的材料区分路径；基于这些先验，可微分射线追踪引擎使用测量的接收信号强度进行梯度优化。

Result: 在NVIDIA Sionna室内场景实验中，相比均匀或随机初始化及随机放置基线，收敛速度提高2-4倍，最终参数误差降低10-100倍，仅需少量接收器即可实现低于0.1%的平均相对误差；复杂度分析显示每次迭代时间与材料数量和测量设置接近线性关系，VLM引导的放置减少了准确恢复所需的测量次数。

Conclusion: 视觉语言模型提供的语义先验能有效指导基于物理的优化，实现快速可靠的射频材料参数估计，为6G系统中的电磁数字孪生提供了高效解决方案。

Abstract: Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\times$ faster convergence and 10-100$\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.

</details>


### [95] [Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing](https://arxiv.org/abs/2601.18252)
*Chao Wang,Xuanying Li,Cheng Dai,Jinglei Feng,Yuxiang Luo,Yuqi Ouyang,Hao Qin*

Main category: cs.CV

TL;DR: Co-PLNet：一种点线协作框架，通过空间提示编码和交叉引导解码实现线框解析，提高准确性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有线框解析方法分别预测线段和连接点，然后进行后处理协调，导致不匹配和鲁棒性降低的问题

Method: 提出点线协作框架，通过点线提示编码器将早期检测转换为空间提示，再通过交叉引导线解码器利用稀疏注意力机制进行细化预测

Result: 在Wireframe和YorkUrban数据集上实验显示，在准确性和鲁棒性方面有持续改进，同时具有良好的实时效率

Conclusion: Co-PLNet通过点线协作实现了结构化几何感知的有效性，为下游任务如SLAM提供了更好的几何表示

Abstract: Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.

</details>


### [96] [Contextual Range-View Projection for 3D LiDAR Point Clouds](https://arxiv.org/abs/2601.18301)
*Seyedali Mousavi,Seyedhamidreza Mousavi,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 本文提出两种新的LiDAR点云到距离图像投影机制：CAP和CWAP，通过结合实例中心和类别信息解决传统深度优先投影导致的信息丢失问题，在SemanticKITTI数据集上取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统LiDAR点云到距离图像的投影采用深度优先策略（保留最近点），忽略了语义相关性和物体结构信息，导致重要上下文信息丢失。需要改进投影选择策略以保留更多语义信息。

Method: 提出两种投影机制：1) CAP（中心感知投影）：根据点到实例中心的距离调整深度值，优先保留实例中心点而非噪声边界点和背景点；2) CWAP（类别加权感知投影）：通过用户定义权重对不同类别进行优先级调整，提供灵活的投影策略。

Result: 在SemanticKITTI数据集上的评估显示，CAP在投影过程中保留了更多实例点，相比基线方法实现了最高3.1%的mIoU提升。CWAP能够增强目标类别的性能，同时对其他类别的影响可忽略不计。

Conclusion: 通过结合实例中心和类别信息的投影策略，能够有效解决LiDAR点云投影中的多对一冲突问题，保留更多语义相关性和物体结构信息，提升3D语义分割性能。

Abstract: Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \textit{Centerness-Aware Projection (CAP)} and \textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes

</details>


### [97] [A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification](https://arxiv.org/abs/2601.18330)
*Muhammad Ali Shah,Muhammad Mansoor Alam,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 本文提出了一种高效的密集Swin混合（EDSH）框架用于脑肿瘤MRI分析，通过两个肿瘤感知实验设置来联合捕获细粒度纹理模式和长距离上下文依赖关系。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤MRI分析需要同时捕捉细粒度纹理模式和长距离上下文依赖关系，现有方法难以有效处理不同肿瘤类型的特异性诊断挑战，如弥漫性胶质瘤的不规则形状、边界不清和异质性纹理，以及脑膜瘤和垂体瘤的明确肿块、特定位置和肿瘤扩展特征。

Method: 提出了EDSH框架，包含两个肿瘤感知实验设置：1）增强特征空间（BFS）设置，通过独立定制的DenseNet和Swin分支学习互补的局部和全局表示，进行维度对齐、融合和增强；2）分层DenseNet-Swin架构，具有深度特征提取和双残差连接（DFE和DR），DenseNet作为主干CNN学习结构化局部特征，Swin_t模型学习全局肿瘤形态。DenseNet在输入级别定制以匹配MRI空间特性，Swin_t通过任务对齐的补丁嵌入和移位窗口自注意力机制进行定制。

Result: 在包含40,260张图像的大规模MRI数据集上进行评估，在未见测试数据集上达到98.50%的准确率和召回率，表现优于独立的CNN、Vision Transformer和混合模型。

Conclusion: EDSH框架通过联合学习局部纹理和全局上下文特征，有效解决了不同类型脑肿瘤的诊断挑战，在脑肿瘤MRI分析中表现出卓越性能，为医学影像分析提供了新的混合架构思路。

Abstract: This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.

</details>


### [98] [PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction](https://arxiv.org/abs/2601.18336)
*Isaac Deutsch,Nicolas Moënne-Loccoz,Gavriel State,Zan Gojcic*

Main category: cs.CV

TL;DR: 提出PPISP模块，通过物理可解释的ISP校正解决多视角3D重建中的光度不一致问题，提升新视角重建质量


<details>
  <summary>Details</summary>
Motivation: 现有方法对相机光学特性和图像信号处理（ISP）变化引起的光度不一致高度敏感，现有缓解策略缺乏物理基础且对新视角泛化能力差

Method: 提出物理可解释的ISP（PPISP）校正模块，通过基于物理的可解释变换解耦相机固有特性和拍摄依赖效应；专门的PPISP控制器在输入视图上训练，预测新视角的ISP参数

Result: 在标准基准测试中达到最先进性能，同时提供直观控制，支持在可用时集成元数据

Conclusion: PPISP模块能够实现对新视角的现实且公平的评估，无需访问真实图像，解决了多视角3D重建中的光度不一致问题

Abstract: Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp

</details>


### [99] [Beyond Rigid: Benchmarking Non-Rigid Video Editing](https://arxiv.org/abs/2601.18340)
*Bingzheng Qu,Kehai Chen,Xuefeng Bai,Jun Yu,Min Zhang*

Main category: cs.CV

TL;DR: 该研究提出了首个专门用于评估非刚性视频编辑的基准NRVBench，包含高质量数据集、新评估指标和训练免费基线方法，解决了现有方法在物理合理性和时间一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管文本驱动视频编辑取得了显著进展，但生成连贯的非刚性变形仍然是一个关键挑战，经常受到物理失真和时间闪烁的困扰。现有方法在保持物理合理性和时间一致性方面存在不足，缺乏专门的评估基准。

Method: 1) 构建NRVBench基准：包含180个非刚性运动视频（6个物理类别）、2,340个细粒度任务指令和360个多项选择题；2) 提出NRVE-Acc评估指标：基于视觉语言模型，严格评估物理合规性、时间一致性和指令对齐；3) 提出VM-Edit基线方法：采用双区域去噪机制实现结构感知控制，平衡结构保持和动态变形。

Result: 实验表明，现有方法在保持物理合理性方面存在缺陷，而提出的VM-Edit方法在标准和提出的指标上都取得了优异性能。NRVBench可作为推进物理感知视频编辑的标准测试平台。

Conclusion: NRVBench是首个专门的非刚性视频编辑基准，通过高质量数据集、新评估指标和有效基线方法，为物理感知视频编辑研究提供了标准化评估框架，有助于推动该领域的发展。

Abstract: Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.

</details>


### [100] [Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception](https://arxiv.org/abs/2601.18346)
*Sijing Wu,Yunhao Li,Zicheng Zhang,Qi Jia,Xinyue Li,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: Q-Bench-Portrait是首个专门针对人像图像质量感知的综合性基准测试，包含2,765个图像-问题-答案三元组，用于评估多模态大语言模型在人像图像感知方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在通用图像的低级视觉基准测试上表现出色，但在具有独特结构和感知特性的人像图像领域的感知和评估能力尚未得到充分探索。

Method: 构建了Q-Bench-Portrait基准测试，包含多样的人像图像来源（自然、合成失真、AI生成、艺术和计算机图形图像）、全面的质量维度（技术失真、AIGC特定失真和美学）以及多种问题格式（单选、多选、判断和开放式问题），并在全局和局部两个层次进行评估。

Result: 评估了20个开源和5个闭源MLLMs，发现当前模型在人像图像感知方面具有一定能力，但表现仍然有限且不精确，与人类判断存在明显差距。

Conclusion: 提出的基准测试将促进进一步研究，以增强通用和领域特定MLLMs的人像图像感知能力。

Abstract: Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.

</details>


### [101] [OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI](https://arxiv.org/abs/2601.18368)
*Caterina Fuster-Barceló,Claudia Castrillón,Laura Rodrigo-Muñoz,Victor Manuel Vega-Suárez,Nicolás Pérez-Fernández,Gorka Bastarrika,Arrate Muñoz-Barrutia*

Main category: cs.CV

TL;DR: OREHAS是首个全自动量化内淋巴积水的管道系统，通过3D MRI直接计算内淋巴与耳蜗体积比，无需人工干预，在有限标注下实现高精度分割。


<details>
  <summary>Details</summary>
Motivation: 当前内淋巴积水的MRI评估依赖人工干预和商业软件，存在操作者依赖性强、方法不一致、体积估计不准确等问题，需要开发自动化、可重复的量化方法。

Method: OREHAS集成三个组件：切片分类、内耳定位和序列特异性分割，形成端到端工作流，仅需每个患者3-6个标注切片进行训练，即可处理完整3D MRI体积。

Result: 在外部验证中，OREHAS Dice分数达0.90（SPACE-MRC）和0.75（REAL-IR），与专家标注匹配度（VSI=74.3%）显著优于临床软件syngo.via（VSI=42.5%），提供更生理真实的体积测量。

Conclusion: OREHAS证明通过有限监督的深度学习分割与临床对齐的工作流，可实现可靠、可重复的内淋巴积水量化，为大规模研究和临床诊断阈值校准提供基础。

Abstract: We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.
  Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.
  These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.

</details>


### [102] [Estimation of geometric transformation matrices using grid-shaped pilot signals](https://arxiv.org/abs/2601.18385)
*Rinka Kawano,Masaki Kawamura*

Main category: cs.CV

TL;DR: 提出一种基于网格状导频信号的水印方法，通过分析几何变换后网格的畸变来估计变换矩阵，实现裁剪等攻击下的准确同步。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法对裁剪攻击的鲁棒性不足，而裁剪会改变图像原点，使水印同步变得困难。需要一种能准确估计几何变换、实现有效同步的水印技术。

Method: 嵌入具有不同水平和垂直值的网格状导频信号。当图像发生几何变换时，网格也会相应畸变。通过对畸变图像进行Radon变换，估计网格角度和间隔。利用水平和垂直线编码不同的特性确定网格方向，减少模糊性。

Result: 在各项异性缩放、旋转、剪切和裁剪等攻击下进行仿真测试。结果表明，该方法能准确估计变换矩阵，在单一和复合攻击下均保持较低误差。

Conclusion: 提出的基于导频信号的网格分析方法能有效估计几何变换，解决了裁剪攻击下的水印同步问题，为几何攻击鲁棒的数字水印提供了可行方案。

Abstract: Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.

</details>


### [103] [Larger than memory image processing](https://arxiv.org/abs/2601.18407)
*Jon Sporring,David Stansby*

Main category: cs.CV

TL;DR: 该论文提出了一种针对超大规模图像数据（如PB级电子显微镜数据）的流式处理架构，通过切片流式架构最小化磁盘I/O，并引入领域特定语言自动优化内存使用和流水线调度。


<details>
  <summary>Details</summary>
Motivation: 处理PB级超大规模图像数据时面临内存不足的挑战，性能主要受I/O限制，需要设计能够有效处理超出内存容量数据的方法。

Method: 提出切片流式架构，支持两种3D数据表示（2D切片堆栈和3D分块布局）；引入领域特定语言（DSL），通过编译时和运行时分析自动选择窗口大小、融合处理阶段、调度数据流；采用基于扫描的执行、窗口化操作和重叠感知分块来最小化冗余访问。

Result: 实现了接近线性的I/O扫描和可预测的内存占用，显著提升了超大规模图像处理的吞吐量，无需将整个数据卷完全加载到内存中。

Conclusion: 通过流式处理架构和领域特定语言，能够高效处理超出内存容量的超大规模图像数据，将预处理和后处理重构为优先顺序读写模式的流水线，为分割和形态学等现有工具提供了集成方案。

Abstract: This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.

</details>


### [104] [Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings](https://arxiv.org/abs/2601.18414)
*Aura Loredana Dan*

Main category: cs.CV

TL;DR: 本文比较了三种深度学习模型（MobileNet、EfficientNet、VGG16）在儿童绘画情感识别任务中的性能，重点关注分类准确性、鲁棒性和计算效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 自闭症谱系障碍（ASD）儿童在情感表达和沟通方面存在困难，特别是在早期阶段。传统的评估方法通常具有侵入性、主观性或难以一致应用，因此需要开发更客观、非侵入性的情感状态识别方法。

Method: 采用迁移学习方法，在由心理学专家标注情感标签的儿童绘画数据集上，对三种深度学习架构（MobileNet、EfficientNet、VGG16）进行统一实验框架下的比较评估。

Result: 研究结果揭示了轻量级架构与深层架构在基于绘画的情感计算任务中的重要权衡，特别是在移动和实时应用场景下。不同模型在分类性能、鲁棒性和计算效率方面表现出各自的优势和局限。

Conclusion: 该研究为儿童情感状态识别提供了基于绘画的机器学习方法比较，强调了在移动和实时应用场景中模型选择时需要平衡计算效率与分类性能的重要性。

Abstract: Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.

</details>


### [105] [On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics](https://arxiv.org/abs/2601.18448)
*Lloyd Austin Courtenay*

Main category: cs.CV

TL;DR: 该论文研究了在几何形态测量学中，使用广义普氏分析进行数据对齐时可能导致的统计依赖性问题，并提出了一种新的重对齐方法来解决训练集和测试集之间的交叉样本依赖。


<details>
  <summary>Details</summary>
Motivation: 几何形态测量学广泛用于量化形状变异，并作为机器学习分析的输入。标准做法是在将数据分割为训练集和测试集之前，通过广义普氏分析对齐所有标本，这可能导致统计依赖并污染下游预测模型。

Method: 通过控制2D和3D模拟实验，在不同样本大小、地标密度和异速生长模式下，正式表征GPA引起的污染效应。提出一种新的重对齐程序，将测试标本与训练集对齐后再进行模型拟合，消除交叉样本依赖。使用线性和卷积回归模型进一步展示地标间空间自相关的重要性。

Result: 模拟实验揭示了样本大小与地标空间之间的稳健"对角线"关系，反映了各向同性变异下RMSE的缩放规律，其斜率可以从普氏切空间的自由度中解析推导。当忽略地标间关系时，模型性能会下降，突显了空间自相关的重要性。

Conclusion: 这项工作确立了在GMM的机器学习应用中需要仔细预处理的重要性，提供了重对齐的实用指南，并阐明了普氏形状空间固有的基本统计约束。

Abstract: Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust "diagonal" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.

</details>


### [106] [3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control](https://arxiv.org/abs/2601.18451)
*Xuanmeng Sha,Liyun Zhang,Tomohiro Mashita,Naoya Chiba,Yuki Uranishi*

Main category: cs.CV

TL;DR: 3DGesPolicy：基于扩散策略的动作框架，通过将整体手势生成重新定义为连续轨迹控制问题，解决了现有方法在身体运动语义协调和空间稳定性方面的不足，实现了自然、表达性强且与语音高度对齐的整体手势生成。


<details>
  <summary>Details</summary>
Motivation: 现有整体协同手势生成方法存在两个主要问题：1）身体运动与面部表情的语义不协调；2）由于部分分解或帧级回归方法导致的空间不稳定无意义运动。需要一种能够生成空间和语义一致的整体手势的方法。

Method: 提出3DGesPolicy框架，将整体手势生成重新定义为机器人学中的连续轨迹控制问题，使用扩散策略。通过将帧间变化建模为统一的整体动作，学习帧间整体手势运动模式。同时提出Gesture-Audio-Phoneme（GAP）融合模块，深度整合多模态信号，确保语音语义、身体运动和面部表达之间的结构化细粒度对齐。

Result: 在BEAT2数据集上的大量定量和定性实验表明，3DGesPolicy在生成自然、表达性强且与语音高度对齐的整体手势方面，优于其他最先进方法。

Conclusion: 3DGesPolicy通过动作建模和扩散策略，有效解决了整体手势生成中的语义协调和空间稳定性问题，结合GAP融合模块实现了多模态信号的深度整合，为生成高质量协同手势提供了有效解决方案。

Abstract: Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.

</details>


### [107] [Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System](https://arxiv.org/abs/2601.18464)
*Wenbin Wei,Suyuan Yao,Cheng Huang,Xiangyu Gao*

Main category: cs.CV

TL;DR: Fair-Eye Net是一个公平、可靠的多模态AI系统，用于青光眼从筛查到随访的临床闭环管理，通过融合眼底照片、OCT、视野检查等多模态数据，并采用公平性约束减少弱势群体的漏诊率。


<details>
  <summary>Details</summary>
Motivation: 青光眼是全球不可逆性失明的主要原因，当前筛查和进展评估依赖单一测试或松散关联的检查，存在主观性和碎片化护理问题。高质量成像工具和专家资源的有限获取进一步影响了现实世界使用的一致性和公平性。

Method: 开发了Fair-Eye Net系统，整合眼底照片、OCT结构指标、视野功能指数和人口统计学因素，采用双流异构融合架构，配备不确定性感知的分层门控策略进行选择性预测和安全转诊。通过公平性约束减少弱势亚组的漏诊率。

Result: 系统达到AUC 0.912（特异性96.7%），将种族假阴性差异减少了73.4%（从12.31%降至3.28%），保持稳定的跨域性能，并能提供3-12个月的早期风险预警（敏感性92%，特异性88%）。

Conclusion: Fair-Eye Net将公平性作为主要目标进行优化，通过多任务学习确保临床可靠性，为临床转化和大规模部署提供了可复现的路径，有助于推进全球眼健康公平。

Abstract: Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.

</details>


### [108] [From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation](https://arxiv.org/abs/2601.18532)
*Devon Levy,Bar Assayag,Laura Gaspar,Ilan Shimshoni,Bella Specktor-Fadida*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的主动学习框架，结合基础模型嵌入与聚类进行冷启动采样，再通过不确定性选择提升医学图像分割性能，在多个数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割需要精确标注，但手动标注耗时耗力。主动学习通过优先标注信息量大的样本来减轻标注负担，但传统的冷启动阶段通常基于多样性选择，存在改进空间。

Method: 提出新颖的冷启动采样策略：结合基础模型嵌入与聚类，包括自动选择聚类数量和按比例跨聚类采样，构建多样且具代表性的初始训练集。随后采用不确定性驱动的主动学习框架，整合空间多样性指导样本选择。方法直观可解释，支持可视化候选样本的特征空间分布。

Result: 在三个数据集上评估：CheXmask数据集上，冷启动策略优于随机选择，Dice从0.918提升至0.929，Hausdorff距离从32.41降至27.66mm；主动学习结合熵和多样性选择将Dice从0.919提升至0.939，Hausdorff距离从30.10降至19.16mm。Montgomery数据集上冷启动效果显著，Dice从0.928提升至0.950，Hausdorff距离从14.22降至9.38mm。SynthStrip数据集上冷启动略微影响Dice但降低Hausdorff距离，主动学习进一步提升性能。

Conclusion: 提出的框架在低数据量情况下持续优于基线方法，显著提升分割准确性，为医学图像分割的标注效率问题提供了有效的解决方案。

Abstract: Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.

</details>


### [109] [GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning](https://arxiv.org/abs/2601.18543)
*Kaixun Jiang,Yuzheng Wang,Junjie Zhou,Pandeng Li,Zhihang Liu,Chen-Wei Xie,Zhaoyu Chen,Yun Zheng,Wenqiang Zhang*

Main category: cs.CV

TL;DR: GenAgent是一个通过智能体框架统一视觉理解和生成的模型，它将理解任务交给多模态模型处理，而将生成任务委托给图像生成模型作为可调用工具，支持自主多轮交互和迭代优化。


<details>
  <summary>Details</summary>
Motivation: 传统统一模型面临昂贵的训练成本以及理解与生成之间的权衡问题，现有模块化系统受限于静态流水线，无法支持自主的多轮交互和迭代优化。

Method: 采用智能体框架，将视觉理解与生成解耦：多模态模型负责理解，图像生成模型作为可调用工具。使用两阶段训练策略：1) 监督微调高质量工具调用和反思数据；2) 端到端智能体强化学习，结合点对点奖励（最终图像质量）和成对奖励（反思准确性），并通过轨迹重采样增强多轮探索。

Result: GenAgent显著提升了基础生成器（FLUX.1-dev）在GenEval++（+23.6%）和WISE（+14%）上的性能。框架展示了三个关键特性：1) 跨工具泛化到不同能力的生成器；2) 测试时扩展性，在多轮交互中持续改进；3) 任务自适应推理，能自动适应不同任务。

Conclusion: GenAgent通过智能体框架成功统一了视觉理解和生成，避免了传统统一模型的训练成本和性能权衡问题，支持自主多轮交互和迭代优化，在多个基准测试中显著提升了性能，并展示了良好的泛化能力和适应性。

Abstract: We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\%) and WISE (+14\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \href{https://github.com/deep-kaixun/GenAgent}{this url}.

</details>


### [110] [REMAC: Reference-Based Martian Asymmetrical Image Compression](https://arxiv.org/abs/2601.18547)
*Qing Ding,Mai Xu,Shengxi Li,Xin Deng,Xin Zou*

Main category: cs.CV

TL;DR: 提出REMAC方法，通过参考图像和计算复杂度转移策略，在火星图像压缩中实现43.51%的编码器复杂度降低和0.2664 dB的BD-PSNR增益


<details>
  <summary>Details</summary>
Motivation: 现有学习方法在火星图像压缩中存在两个关键问题：1）忽略了火星上极其有限的计算资源；2）没有利用火星图像间强烈的图像间相似性来提升压缩性能。基于对火星图像在纹理、颜色和语义方面的强图像内和图像间相似性的实证分析，需要开发适合火星环境的高效压缩方法。

Method: 提出基于参考的火星非对称图像压缩（REMAC）方法：1）将计算复杂度从编码器转移到资源丰富的解码器；2）利用图像间相似性，提出参考引导的熵模块和参考解码器，利用参考图像的有用信息；3）利用图像内相似性，参考解码器采用深度多尺度架构扩大感受野；4）开发潜在特征回收机制进一步缓解火星计算约束。

Result: 实验结果显示，REMAC相比最先进方法减少了43.51%的编码器复杂度，同时实现了0.2664 dB的BD-PSNR增益，在保持压缩性能的同时显著降低了火星端的计算负担。

Conclusion: REMAC通过利用火星图像的强相似性特征，成功实现了计算复杂度从资源受限的编码器向资源丰富的解码器的转移，为火星探索中的图像传输提供了高效实用的压缩解决方案。

Abstract: To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \textit{intra-} and \textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.

</details>


### [111] [Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray](https://arxiv.org/abs/2601.18555)
*Roberto Di Via,Vito Paolo Pastore,Francesca Odone,Siôn Glyn-Jones,Irina Voiculescu*

Main category: cs.CV

TL;DR: 该研究验证了使用标准热图回归架构在MRI上检测髋关节撞击综合征(FAI)标志点的可行性，证明MRI与X射线在定位和诊断准确性上具有临床等效性。


<details>
  <summary>Details</summary>
Motivation: 临床筛查决策常基于角度测量，特别是髋关节撞击综合征(FAI)筛查传统上依赖X射线测量角度。然而，评估撞击区域的高度和范围需要MRI扫描的3D视图。两种模态为外科医生提供不同方面的信息，需要验证MRI在FAI评估中的临床等效性。

Method: 采用匹配队列验证研究(89名患者，配对MRI/X射线)，使用标准热图回归架构评估跨模态临床等效性。在3D MRI体积的冠状视图中进行标志点检测，为后续通过放置更多标志点进行体积分析提供可能性。

Result: 研究表明MRI在cam型撞击综合征的标志点定位和诊断准确性方面与X射线具有等效性。方法在3D MRI体积的冠状视图中展示了临床可行性，支持将自动化FAI评估整合到常规MRI工作流程中。

Conclusion: 该研究证明了使用标准热图回归架构在MRI上检测FAI标志点的临床可行性，为通过放置更多标志点进行体积分析开辟了可能性，支持将自动化FAI评估整合到常规MRI工作流程中。

Abstract: Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions

</details>


### [112] [Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis](https://arxiv.org/abs/2601.18556)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: SDA-QEC框架结合简化扩散增强与量子增强分类，解决医学图像分类中的类别不平衡问题，在冠状动脉造影图像分类中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 真实医学数据集存在严重类别不平衡问题，阳性样本远多于阴性样本，导致模型偏向多数类，对少数类召回率低，影响诊断准确性并带来临床误诊风险。

Method: 提出SDA-QEC框架：1）使用轻量级扩散增强器为少数类生成高质量合成样本，平衡训练分布；2）在MobileNetV2架构中嵌入量子特征层，通过希尔伯特空间中的高维特征映射增强模型判别能力。

Result: 在冠状动脉造影图像分类实验中，SDA-QEC达到98.33%准确率、98.78% AUC和98.33% F1分数，显著优于ResNet18、MobileNetV2、DenseNet121和VGG16等经典基线模型。同时获得98.33%敏感性和98.33%特异性，实现临床部署所需的平衡性能。

Conclusion: 该方法验证了在真实医学成像任务中集成生成增强与量子增强建模的可行性，为开发在小样本、高度不平衡和高风险诊断场景中高度可靠的医学AI系统提供了新的研究途径。

Abstract: In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.

</details>


### [113] [AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging](https://arxiv.org/abs/2601.18560)
*Li Fang,Tianyu Li,Yanghong Lin,Shudong Zhou,Wei Yao*

Main category: cs.CV

TL;DR: 本文提出了一种用于高光谱图像分类的高效AI卫星边缘计算范式，采用轻量级非深度学习框架结合少样本学习策略，开发了两阶段像素级标签传播方案，无需空间结构信息，适合卫星资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像卫星具有强大的光谱测量能力，但卫星下行传输速度已成为灾害监测和应急测绘等需要快速响应能力的应用的主要瓶颈。需要让卫星具备自主决策能力，同时要适应卫星平台的资源限制。

Method: 采用轻量级非深度学习框架集成少样本学习策略。开发了两阶段像素级标签传播方案：第一阶段通过构建的锚点-像素亲和矩阵传播选定的锚点标签获得初始像素标签；第二阶段使用从稀疏图推导的闭式解替代迭代计算。还开发了基于秩约束的图聚类算法来确定锚点标签。

Result: 该方法能够在卫星边缘计算环境中实现高效的高光谱图像分类，适应卫星资源约束，处理传感器故障和扫描模式错误导致的图像质量退化问题，无需依赖空间结构信息。

Conclusion: 提出的AI卫星边缘计算范式使卫星具备自主决策能力，通过轻量级非深度学习框架和两阶段像素级标签传播方案，有效解决了卫星资源限制和图像质量问题，为灾害监测等需要快速响应的应用提供了可行解决方案。

Abstract: As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.

</details>


### [114] [Self-Refining Video Sampling](https://arxiv.org/abs/2601.18577)
*Sangwon Jang,Taekyung Ki,Jaehyeong Jo,Saining Xie,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.CV

TL;DR: 提出自细化视频采样方法，通过将预训练视频生成器解释为去噪自编码器，在推理时进行迭代内循环细化，无需外部验证器或额外训练，显著提升运动连贯性和物理对齐。


<details>
  <summary>Details</summary>
Motivation: 现代视频生成器在处理复杂物理动力学时仍存在困难，缺乏物理真实性。现有方法使用外部验证器或增强数据训练，计算成本高且难以捕捉细粒度运动。

Method: 自细化视频采样方法：将预训练视频生成器解释为去噪自编码器，在推理时进行迭代内循环细化；引入基于自一致性的不确定性感知细化策略，选择性细化区域以防止过度细化导致的伪影。

Result: 在最先进的视频生成器上实验表明，该方法在运动连贯性和物理对齐方面有显著改进，相比默认采样器和基于引导的采样器，获得超过70%的人类偏好。

Conclusion: 自细化视频采样是一种简单有效的方法，通过利用预训练生成器自身作为细化器，无需额外训练或外部验证，就能显著提升视频生成的物理真实性和运动质量。

Abstract: Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\% human preference compared to the default sampler and guidance-based sampler.

</details>


### [115] [GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization](https://arxiv.org/abs/2601.18585)
*Chenxi Liu,Selena Ling,Alec Jacobson*

Main category: cs.CV

TL;DR: GimmBO：基于偏好贝叶斯优化的交互式适配器合并探索框架，用于扩散模型图像生成


<details>
  <summary>Details</summary>
Motivation: 当前基于手动滑块调整的适配器合并方法在探索大规模设计空间时效率低下，难以处理20-30个适配器的候选集，需要更高效的交互式探索工具

Method: 提出GimmBO框架，采用两阶段贝叶斯优化后端，结合真实使用场景中的稀疏性和权重范围约束，提高高维空间中的采样效率和收敛性

Result: 通过模拟用户和用户研究评估，相比贝叶斯优化和线搜索基线，GimmBO显示出改进的收敛性、高成功率，并展示了框架的灵活性扩展

Conclusion: GimmBO为扩散模型适配器合并提供了有效的交互式探索工具，解决了高维设计空间中的权重选择难题

Abstract: Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.

</details>


### [116] [Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures](https://arxiv.org/abs/2601.18619)
*Jorge Quesada,Ghassan AlRegib*

Main category: cs.CV

TL;DR: 该论文提出了一种尺度感知的自监督学习适应方法，通过集成小窗口裁剪增强策略，在预训练阶段聚焦于细粒度结构，显著提升了小、稀疏或不规则物体的分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统自监督学习在分割任务中通常针对大而均匀的区域进行优化，但在处理小、稀疏或局部不规则物体时性能显著下降。现有方法缺乏对目标物体尺度的适应性。

Method: 提出尺度感知的自监督学习适应方法，将小窗口裁剪集成到数据增强流程中，在预训练阶段放大细粒度结构。该方法在两个不同数据模态的领域进行验证：地震成像（分割稀疏断层）和神经成像（描绘小细胞结构）。

Result: 在标签受限条件下，该方法相比标准和最先进基线方法取得一致改进：断层分割准确率提升高达13%，细胞描绘准确率提升5%。但对于大规模特征（如地震相或组织区域）改善有限。

Conclusion: 自监督学习的价值关键取决于目标物体的尺度，需要将SSL设计与物体大小和稀疏性对齐。这为跨科学成像领域构建更有效的表示学习流程提供了通用原则。

Abstract: Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.

</details>


### [117] [Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation](https://arxiv.org/abs/2601.18623)
*Zihao Wang,Yuzhou Chen,Shaogang Ren*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的跨模态图像翻译方法，通过空间变化的混合场和目标一致恢复项来避免传统扩散模型中的固定调度域转移问题，提高了结构保真度和语义一致性，同时减少了去噪步骤。


<details>
  <summary>Details</summary>
Motivation: 传统跨模态图像翻译方法存在脆弱性和低效性问题。标准扩散方法通常依赖单一的全局线性域转移，这迫使采样器遍历离流形的高成本区域，增加了校正负担并导致语义漂移。作者将这种共享失败模式称为固定调度域转移。

Method: 提出了一种将域转移动态直接嵌入生成过程的方法。模型在每个反向步骤预测空间变化的混合场，并在漂移中注入显式的目标一致恢复项。这种步内指导使大更新保持在流形上，并将模型角色从全局对齐转变为局部残差校正。提供了连续时间公式和精确解形式，并推导了保持边缘一致性的实用一阶采样器。

Result: 在医学成像、遥感和电致发光语义映射等翻译任务中，该框架提高了结构保真度和语义一致性，同时在更少的去噪步骤中收敛。

Conclusion: 通过将域转移动态直接整合到生成过程中，避免了传统扩散模型的固定调度域转移问题，实现了更高效、更准确的跨模态图像翻译。

Abstract: Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.

</details>


### [118] [CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search](https://arxiv.org/abs/2601.18625)
*Zequn Xie*

Main category: cs.CV

TL;DR: CONQUER是一个用于文本行人搜索的两阶段框架，通过训练时的跨模态对齐增强和推理时的自适应查询优化，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 文本行人搜索面临跨模态差异和模糊查询的挑战，现有方法在处理不完整或模糊查询时效果有限，需要更实用的解决方案。

Method: 采用两阶段框架：训练阶段使用多粒度编码、互补对挖掘和基于最优传输的上下文引导匹配；推理阶段通过即插即用的查询增强模块进行锚点选择和属性驱动丰富。

Result: 在CUHK-PEDES、ICFG-PEDES和RSTPReid数据集上，CONQUER在Rank-1准确率和mAP指标上均优于强基线，在跨域和不完整查询场景中表现尤为突出。

Conclusion: CONQUER为实际部署的文本行人搜索提供了实用有效的解决方案，通过训练和推理的协同优化显著提升了检索性能。

Abstract: Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.

</details>


### [119] [Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting](https://arxiv.org/abs/2601.18633)
*Tong Shi,Melonie de Almeida,Daniela Ivanova,Nicolas Pugeault,Paul Henderson*

Main category: cs.CV

TL;DR: Splat-Portrait：基于高斯泼溅的3D说话头生成方法，无需3D监督或运动先验，从单张肖像和语音合成自然的说话视频


<details>
  <summary>Details</summary>
Motivation: 现有3D说话头生成方法依赖领域特定的启发式方法（如基于形变的运动表示先验），导致3D头像重建不准确，影响动画真实感

Method: 使用高斯泼溅表示静态3D重建，自动从单张肖像中解耦出静态3D重建和2D背景，基于输入音频生成自然唇部运动，无需运动驱动先验，仅使用2D重建和分数蒸馏损失训练

Result: 实验结果表明Splat-Portrait在说话头生成和新视角合成方面表现优异，视觉质量优于先前工作

Conclusion: Splat-Portrait通过高斯泼溅方法有效解决了3D头部重建和唇部运动合成的挑战，无需3D监督或关键点标注，实现了高质量的说话头生成

Abstract: Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.

</details>


### [120] [Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge](https://arxiv.org/abs/2601.18698)
*Xiao Liu,Jiawei Zhang*

Main category: cs.CV

TL;DR: 本文提出GAP框架评估文本到视频模型的地理公平性，发现Sora 2模型在全球视觉知识表达上相对均匀，地理偏见比预期弱。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型虽然能产生视觉上吸引人的结果，但尚不清楚这些模型是否编码了地理上公平的视觉知识。研究旨在探究文本到视频模型的地理公平性和地理基础视觉知识。

Method: 提出Geo-Attraction Landmark Probing (GAP)系统框架，构建GEOATTRACTION-500基准数据集（包含500个全球分布的旅游景点），整合全局结构对齐、细粒度关键点对齐和视觉语言模型判断等互补指标，并与人类评估进行验证。

Result: 对最先进的文本到视频模型Sora 2应用GAP框架发现，与常见的地理偏见假设相反，该模型在不同地区、发展水平和文化群体之间表现出相对均匀的地理基础视觉知识水平，对景点流行度的依赖较弱。

Conclusion: 当前文本到视频模型表达全球视觉知识比预期更均匀，这突显了它们在全球化部署应用中的潜力，同时也强调了随着系统发展需要持续评估的必要性。

Abstract: Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.

</details>


### [121] [Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning](https://arxiv.org/abs/2601.18714)
*Judith Vilella-Cantos,Mauro Martini,Marcello Chiaberge,Mónica Ballesta,David Valiente*

Main category: cs.CV

TL;DR: 提出MinkUNeXt-VINE方法，一种轻量级深度学习模型，用于农业环境中的地点识别，在葡萄园环境中超越现有方法，特别适用于低成本稀疏LiDAR输入和实时场景。


<details>
  <summary>Details</summary>
Motivation: 农业环境由于非结构化特性和缺乏显著地标，定位具有挑战性。现有研究主要关注物体分类和分割，但移动机器人的地点识别任务在当前技术水平下仍不简单。

Method: 提出MinkUNeXt-VINE方法，采用预处理和Matryoshka表示学习多损失方法，优先考虑低成本稀疏LiDAR输入和低维输出，确保实时场景的高效性。

Result: 在两个长期葡萄园数据集上进行了全面消融研究，结果表明该方法在权衡输出效率方面表现优异，在低成本和低分辨率输入数据上具有鲁棒性能。

Conclusion: MinkUNeXt-VINE方法在葡萄园环境中超越了现有方法，特别适用于农业环境中的实时地点识别任务，代码已公开用于复现。

Abstract: Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.

</details>


### [122] [SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification](https://arxiv.org/abs/2601.18739)
*Ignacio Antequera-Sánchez,Juan Luis Suárez-Díaz,Rosana Montes,Francisco Herrera*

Main category: cs.CV

TL;DR: 提出SeNeDiF-OOD方法，通过语义嵌套二分融合的层次结构解决OOD检测中数据异质性问题，在MonuMAI建筑风格识别系统中验证有效性


<details>
  <summary>Details</summary>
Motivation: OOD检测对于AI在开放世界环境中的可靠部署至关重要，但OOD数据的异质性（从低级损坏到语义偏移）使得单阶段检测器难以有效处理，需要新的解决方案

Method: 提出SeNeDiF-OOD方法，基于语义嵌套二分融合框架，将检测任务分解为层次化的二元融合节点结构，每层集成与特定语义抽象级别对齐的决策边界

Result: 在MonuMAI建筑风格识别系统的案例研究中，该方法显著优于传统基线，能有效过滤非纪念碑图像、未知建筑风格和对抗攻击等多样OOD类别，同时保持分布内性能

Conclusion: 语义嵌套二分融合的层次框架为解决OOD检测中的异质性问题提供了有效方案，在真实开放环境应用中表现出优越性能

Abstract: Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [123] [Frequency-aware Adaptive Contrastive Learning for Sequential Recommendation](https://arxiv.org/abs/2601.17057)
*Zhikai Wang,Weihua Zhang*

Main category: cs.IR

TL;DR: FACL框架通过频率感知的自适应对比学习，解决了序列推荐中数据增强对低频物品和稀疏用户行为的偏见问题，显著提升了推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 研究发现序列推荐中的对比学习数据增强存在固有偏见，会损害低频物品和稀疏用户行为的完整性，导致推荐性能下降，特别是在真实世界长尾推荐场景中。

Method: 提出FACL框架：1）微观层面的自适应扰动保护稀有物品完整性；2）宏观层面的重新加权放大稀疏和稀有交互序列在训练中的影响。

Result: 在五个公共基准数据集上，FACL持续优于最先进的数据增强和模型增强方法，推荐准确性提升高达3.8%，显著缓解了低频物品和用户的性能下降。

Conclusion: FACL框架具有强大的意图保持能力和对真实世界长尾推荐场景的优越适用性，有效解决了序列推荐中对比学习的数据增强偏见问题。

Abstract: In this paper, we revisited the role of data augmentation in contrastive learning for sequential recommendation, revealing its inherent bias against low-frequency items and sparse user behaviors. To address this limitation, we proposed FACL, a frequency-aware adaptive contrastive learning framework that introduces micro-level adaptive perturbation to protect the integrity of rare items, as well as macro-level reweighting to amplify the influence of sparse and rare-interaction sequences during training. Comprehensive experiments on five public benchmark datasets demonstrated that FACL consistently outperforms state-of-the-art data augmentation and model augmentation-based methods, achieving up to 3.8% improvement in recommendation accuracy. Moreover, fine-grained analyses confirm that FACL significantly alleviates the performance drop on low-frequency items and users, highlighting its robust intent-preserving ability and its superior applicability to real-world, long-tail recommendation scenarios.

</details>


### [124] [Evaluation on Entity Matching in Recommender Systems](https://arxiv.org/abs/2601.17218)
*Zihan Huang,Rohan Surana,Zhouhang Xie,Junda Wu,Yu Xia,Julian McAuley*

Main category: cs.IR

TL;DR: 本文介绍了Reddit-Amazon-EM数据集，用于评估跨数据集实体匹配方法，填补了推荐系统中缺乏严格评估框架的空白。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏用于跨数据集实体匹配的严格评估框架，这阻碍了LLM驱动的对话推荐和基于知识的数据集构建等领域的进展。

Method: 通过手动标注Reddit和Amazon'23数据集中的自然出现项目，创建Reddit-Amazon-EM数据集，并全面评估基于规则、图、词法、嵌入和LLM的实体匹配方法。

Result: 创建了包含手动标注实体匹配黄金集的Reddit-Amazon-EM数据集，并提供了基于最佳性能方法的两个数据集之间的映射关系。

Conclusion: Reddit-Amazon-EM数据集为推荐系统中的实体匹配研究提供了有价值的资源，有助于推动该领域的未来发展。

Abstract: Entity matching is a crucial component in various recommender systems, including conversational recommender systems (CRS) and knowledge-based recommender systems. However, the lack of rigorous evaluation frameworks for cross-dataset entity matching impedes progress in areas such as LLM-driven conversational recommendations and knowledge-grounded dataset construction.
  In this paper, we introduce Reddit-Amazon-EM, a novel dataset comprising naturally occurring items from Reddit and the Amazon '23 dataset. Through careful manual annotation, we identify corresponding movies across Reddit-Movies and Amazon'23, two existing recommender system datasets with inherently overlapping catalogs. Leveraging Reddit-Amazon-EM, we conduct a comprehensive evaluation of state-of-the-art entity matching methods, including rule-based, graph-based, lexical-based, embedding-based, and LLM-based approaches.
  For reproducible research, we release our manually annotated entity matching gold set and provide the mapping between the two datasets using the best-performing method from our experiments. This serves as a valuable resource for advancing future work on entity matching in recommender systems.

</details>


### [125] [FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search](https://arxiv.org/abs/2601.17333)
*Lalit Pant,Shivang Nagar*

Main category: cs.IR

TL;DR: 本文提出了一个针对金融知识搜索的现代自然语言查询系统技术蓝图，通过结合NLP、搜索工程和向量数据模型，解决了金融数据检索中的发现、相关性排序、数据新鲜度和实体识别等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 传统金融知识搜索方法存在精度和召回率不足的问题，难以有效连接分散的金融对象、事件和关系。自然语言查询能够提升搜索效果，促进更深入的金融洞察。

Method: 结合自然语言处理、搜索工程和向量数据模型，设计了包含离线索引和在线检索架构组件的系统，详细阐述了金融数据集和文档的独特需求。

Result: 提出的NLQ系统相比传统方法在精度和召回率上都有提升，能够更有效地连接金融对象、事件和关系，为金融服务提供增强的知识搜索能力。

Conclusion: 该研究为金融领域的自然语言查询系统提供了全面的技术蓝图和理论基础，展示了其在金融服务中的实际应用价值，并提出了未来的优化方向。

Abstract: Natural Language Query (NLQ) allows users to search and interact with information systems using plain, human language instead of structured query syntax. This paper presents a technical blueprint on the design of a modern NLQ system tailored to financial knowledge search. The introduction of NLQ not only enhances the precision and recall of the knowledge search compared to traditional methods, but also facilitates deeper insights by efficiently linking disparate financial objects, events, and relationships. Using core constructs from natural language processing, search engineering, and vector data models, the proposed system aims to address key challenges in discovering, relevance ranking, data freshness, and entity recognition intrinsic to financial data retrieval. In this work, we detail the unique requirements of NLQ for financial datasets and documents, outline the architectural components for offline indexing and online retrieval, and discuss the real-world use cases of enhanced knowledge search in financial services. We delve into the theoretical underpinnings and experimental evidence supporting our proposed architecture, ultimately providing a comprehensive analysis on the subject matter. We also provide a detailed elaboration of our experimental methodology, the data used, the results and future optimizations in this study.

</details>


### [126] [Beyond Correlations: A Downstream Evaluation Framework for Query Performance Prediction](https://arxiv.org/abs/2601.17339)
*Payel Santra,Partha Basuchowdhuri,Debasis Ganguly*

Main category: cs.IR

TL;DR: 论文提出了一种面向下游应用的查询性能预测评估框架，通过将QPP估计分布作为信息检索融合的先验，发现传统相关性评估与下游应用效果不匹配


<details>
  <summary>Details</summary>
Motivation: 传统查询性能预测评估只关注集合层面的相关性度量，无法量化单个查询级别的效果，且与下游应用脱节，导致高相关性值的QPP方法在实际IR流水线中可能无法有效支持查询特定决策

Method: 提出下游聚焦的评估框架，将多个排序器检索到的top文档列表中的QPP估计分布作为IR融合的先验。一方面，这些估计分布与真实检索质量分布的匹配程度反映预测器质量；另一方面，作为先验使用反映预测器在IR流水线中做出明智决策的能力

Result: 实验表明：1) QPP估计在加权IR融合中至关重要，相比未加权的CombSUM和RRF融合策略有超过4.5%的显著改进；2) QPP的下游效果与标准相关性评估没有良好相关性，揭示了新的见解

Conclusion: 需要重新思考QPP评估方法，将下游应用效果纳入考量，因为传统相关性评估无法准确反映QPP在实际IR系统中的实用价值

Abstract: The standard practice of query performance prediction (QPP) evaluation is to measure a set-level correlation between the estimated retrieval qualities and the true ones. However, neither this correlation-based evaluation measure quantifies QPP effectiveness at the level of individual queries, nor does this connect to a downstream application, meaning that QPP methods yielding high correlation values may not find a practical application in query-specific decisions in an IR pipeline. In this paper, we propose a downstream-focussed evaluation framework where a distribution of QPP estimates across a list of top-documents retrieved with several rankers is used as priors for IR fusion. While on the one hand, a distribution of these estimates closely matching that of the true retrieval qualities indicates the quality of the predictor, their usage as priors on the other hand indicates a predictor's ability to make informed choices in an IR pipeline. Our experiments firstly establish the importance of QPP estimates in weighted IR fusion, yielding substantial improvements of over 4.5% over unweighted CombSUM and RRF fusion strategies, and secondly, reveal new insights that the downstream effectiveness of QPP does not correlate well with the standard correlation-based QPP evaluation.

</details>


### [127] [Breaking Flat: A Generalised Query Performance Prediction Evaluation Framework](https://arxiv.org/abs/2601.17359)
*Payel Santra,Partha Basuchowdhuri,Debasis Ganguly*

Main category: cs.IR

TL;DR: 该研究将查询性能预测任务从传统的"单一排序模型-多查询"扩展到"多排序模型-单一查询"和"多排序模型-多查询"三种设置，发现不同任务中QPP模型效果差异显著，且预测最佳排序模型比预测查询难度更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 传统查询性能预测主要关注单一排序模型下不同查询的性能差异，但更细粒度的挑战是确定哪些排序模型对特定查询最有效。本研究旨在将QPP任务及其评估推广到更全面的设置。

Method: 将QPP任务形式化为三种评估设置：1) SRMQ-PP：单一排序模型多查询（传统设置）；2) MRSQ-PP：多排序模型单一查询（选择最有效排序模型）；3) MRMQ-PP：多排序模型多查询（联合考虑所有查询-排序模型对）。

Result: 研究发现：1) QPP模型的相对有效性在不同任务间存在显著差异；2) 预测查询的最佳排序模型比预测单一排序模型下查询的相对难度要困难得多。

Conclusion: QPP研究需要超越传统的单一排序模型设置，考虑多排序模型环境下的性能预测。不同QPP任务具有不同的挑战性，需要针对性的方法来解决。

Abstract: The traditional use-case of query performance prediction (QPP) is to identify which queries perform well and which perform poorly for a given ranking model. A more fine-grained and arguably more challenging extension of this task is to determine which ranking models are most effective for a given query. In this work, we generalize the QPP task and its evaluation into three settings: (i) SingleRanker MultiQuery (SRMQ-PP), corresponding to the standard use case; (ii) MultiRanker SingleQuery (MRSQ-PP), which evaluates a QPP model's ability to select the most effective ranker for a query; and (iii) MultiRanker MultiQuery (MRMQ-PP), which considers predictions jointly across all query ranker pairs. Our results show that (a) the relative effectiveness of QPP models varies substantially across tasks (SRMQ-PP vs. MRSQ-PP), and (b) predicting the best ranker for a query is considerably more difficult than predicting the relative difficulty of queries for a given ranker.

</details>


### [128] [UniGRec: Unified Generative Recommendation with Soft Identifiers for End-to-End Optimization](https://arxiv.org/abs/2601.17438)
*Jialei Li,Yang Zhang,Yimeng Bai,Shuai Zhu,Ziqi Xue,Xiaoyan Zhao,Dingxian Wang,Frank Yang,Andrew Rabinovich,Xiangnan He*

Main category: cs.IR

TL;DR: UniGRec是一个统一的生成式推荐框架，通过端到端训练解决现有方法中tokenizer和推荐器分离的问题，并针对训练-推理差异、标识符崩溃和协同信号不足三个挑战提出了相应解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法通常将tokenizer和推荐器解耦或采用异步交替优化，限制了端到端对齐。作者希望通过统一tokenizer和推荐器在推荐目标下进行端到端训练，但面临训练-推理差异、标识符崩溃和协同信号不足三大挑战。

Method: 提出UniGRec框架：1) 退火推理对齐平滑连接软训练和硬推理；2) 码字均匀性正则化防止标识符崩溃并促进码本多样性；3) 双重协同蒸馏机制从轻量级教师模型提取协同先验来共同指导tokenizer和推荐器。

Result: 在真实世界数据集上的大量实验表明，UniGRec始终优于最先进的基线方法。

Conclusion: UniGRec通过统一tokenizer和推荐器的端到端训练，有效解决了生成式推荐中的关键挑战，在推荐性能上取得了显著提升。

Abstract: Generative recommendation has recently emerged as a transformative paradigm that directly generates target items, surpassing traditional cascaded approaches. It typically involves two components: a tokenizer that learns item identifiers and a recommender trained on them. Existing methods often decouple tokenization from recommendation or rely on asynchronous alternating optimization, limiting full end-to-end alignment. To address this, we unify the tokenizer and recommender under the ultimate recommendation objective via differentiable soft item identifiers, enabling joint end-to-end training. However, this introduces three challenges: training-inference discrepancy due to soft-to-hard mismatch, item identifier collapse from codeword usage imbalance, and collaborative signal deficiency due to an overemphasis on fine-grained token-level semantics.
  To tackle these challenges, we propose UniGRec, a unified generative recommendation framework that addresses them from three perspectives. UniGRec employs Annealed Inference Alignment during tokenization to smoothly bridge soft training and hard inference, a Codeword Uniformity Regularization to prevent identifier collapse and encourage codebook diversity, and a Dual Collaborative Distillation mechanism that distills collaborative priors from a lightweight teacher model to jointly guide both the tokenizer and the recommender. Extensive experiments on real-world datasets demonstrate that UniGRec consistently outperforms state-of-the-art baseline methods. Our codes are available at https://github.com/Jialei-03/UniGRec.

</details>


### [129] [Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features](https://arxiv.org/abs/2601.17472)
*Junyou He,Lixi Deng,Huichao Guo,Ye Tang,Yong Li,Sulong Xu*

Main category: cs.IR

TL;DR: 该论文提出了A²DCDR模型，通过对抗对齐和特征解耦来改进跨域推荐，结合域不变特征、非对齐特征和原始上下文数据，在真实数据集和在线A/B测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有跨域推荐方法通常只解耦域不变特征和域特定特征，并主要依赖域不变特征结合目标域特定特征，这可能导致次优性能。需要更全面地捕捉跨域信息，包括域不变特征和有价值的非对齐特征。

Method: 提出A²DCDR模型，包含三个关键组件：1) 通过对抗训练改进MMD以获得更好的泛化能力；2) 使用特征解耦器和重建机制进行域内解耦；3) 引入新颖的融合表示，结合域不变特征、非对齐特征和原始上下文数据。

Result: 在真实世界数据集和在线A/B测试中，A²DCDR模型优于现有方法，验证了其有效性和实际应用价值。

Conclusion: A²DCDR模型通过对抗对齐和特征解耦，能够更全面地捕捉跨域信息，显著提升跨域推荐性能，具有实际应用前景。

Abstract: Cross-domain recommendation (CDR) has been increasingly explored to address data sparsity and cold-start issues. However, recent approaches typically disentangle domain-invariant features shared between source and target domains, as well as domain-specific features for each domain. However, they often rely solely on domain-invariant features combined with target domain-specific features, which can lead to suboptimal performance. To overcome the limitations, this paper presents the Adversarial Alignment and Disentanglement Cross-Domain Recommendation ($A^2DCDR$ ) model, an innovative approach designed to capture a comprehensive range of cross-domain information, including both domain-invariant and valuable non-aligned features. The $A^2DCDR$ model enhances cross-domain recommendation through three key components: refining MMD with adversarial training for better generalization, employing a feature disentangler and reconstruction mechanism for intra-domain disentanglement, and introducing a novel fused representation combining domain-invariant, non-aligned features with original contextual data. Experiments on real-world datasets and online A/B testing show that $A^2DCDR$ outperforms existing methods, confirming its effectiveness and practical applicability. The code is provided at https://github.com/youzi0925/A-2DCDR/tree/main.

</details>


### [130] [Towards Fair Large Language Model-based Recommender Systems without Costly Retraining](https://arxiv.org/abs/2601.17492)
*Jin Li,Huilin Gu,Shoujin Wang,Qi Zhang,Shui Yu,Chen Wang,Xiwei Xu,Fang Chen*

Main category: cs.IR

TL;DR: FUDLR提出了一种快速统一的LLM推荐系统去偏方法，将去偏问题重新定义为高效的机器遗忘任务，通过两阶段方法在保持推荐准确性的同时提升公平性。


<details>
  <summary>Details</summary>
Motivation: LLM推荐系统虽然革新了用户建模，但容易无意中延续训练数据中的偏见，导致严重的公平性问题。现有去偏方法面临两个主要挑战：1) 针对特定偏见类型设计，缺乏处理多样或新兴偏见的通用性；2) 依赖重新训练的方法在LLM大规模参数下计算不可行。

Method: FUDLR采用两阶段方法：第一阶段通过新颖的偏见无关掩码识别需要遗忘的偏见诱导样本，优化公平性改进与准确性保持的平衡；第二阶段通过估计和移除这些样本对模型参数的影响来高效去偏。其偏见无关设计允许通过纳入不同公平性指标来适应各种或共存的偏见。

Result: 大量实验证明，FUDLR能有效且高效地提升公平性，同时保持推荐准确性，为构建社会责任的LLM推荐系统提供了实用路径。

Conclusion: FUDLR为LLM推荐系统的公平性问题提供了一个实用的解决方案，通过将去偏问题重新定义为机器遗忘任务，实现了在保持推荐性能的同时有效处理多样偏见的能力。

Abstract: Large Language Models (LLMs) have revolutionized Recommender Systems (RS) through advanced generative user modeling. However, LLM-based RS (LLM-RS) often inadvertently perpetuates bias present in the training data, leading to severe fairness issues. Addressing these fairness problems in LLM-RS faces two significant challenges. 1) Existing debiasing methods, designed for specific bias types, lack the generality to handle diverse or emerging biases in real-world applications. 2) Debiasing methods relying on retraining are computationally infeasible given the massive parameter scale of LLMs. To overcome these challenges, we propose FUDLR (Fast Unified Debiasing for LLM-RS). The core idea is to reformulate the debiasing problem as an efficient machine unlearning task with two stages. First, FUDLR identifies bias-inducing samples to unlearn through a novel bias-agnostic mask, optimized to balance fairness improvement with accuracy preservation. Its bias-agnostic design allows adaptability to various or co-existing biases simply by incorporating different fairness metrics. Second, FUDLR performs efficient debiasing by estimating and removing the influence of identified samples on model parameters. Extensive experiments demonstrate that FUDLR effectively and efficiently improves fairness while preserving recommendation accuracy, offering a practical path toward socially responsible LLM-RS. The code and data are available at https://github.com/JinLi-i/FUDLR.

</details>


### [131] [To Case or Not to Case: An Empirical Study in Learned Sparse Retrieval](https://arxiv.org/abs/2601.17500)
*Emmanouil Georgios Lionis,Jia-Huei Ju,Angelos Nalmpantis,Casper Thuis,Sean MacAvaney,Andrew Yates*

Main category: cs.IR

TL;DR: 研究发现，在稀疏检索模型中，使用大小写敏感的基础模型默认表现显著差于大小写不敏感模型，但通过将文本预处理为小写可以消除这一差距。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的语言模型只有大小写敏感版本，但稀疏检索方法一直依赖大小写不敏感的基础模型。这种转变对稀疏检索方法的影响尚未研究，可能威胁该方法的未来发展。

Method: 系统评估了同一基础模型的大小写敏感和大小写不敏感版本在多个数据集上的表现，通过文本预处理为小写来测试性能差异，并进行词元级分析。

Result: 默认情况下，使用大小写敏感基础模型的稀疏检索模型表现显著差于大小写不敏感版本；但通过将文本预处理为小写可以完全消除这一性能差距。词元级分析显示，在小写处理后，大小写敏感模型几乎完全抑制了大小写敏感词汇项，实际上表现得像大小写不敏感模型。

Conclusion: 这一发现扩展了最新大小写敏感模型在稀疏检索场景中的适用性，并促进了更强基础架构与稀疏检索的集成，确保了该方法的持续可行性。

Abstract: Learned Sparse Retrieval (LSR) methods construct sparse lexical representations of queries and documents that can be efficiently searched using inverted indexes. Existing LSR approaches have relied almost exclusively on uncased backbone models, whose vocabularies exclude case-sensitive distinctions, thereby reducing vocabulary mismatch. However, the most recent state-of-the-art language models are only available in cased versions. Despite this shift, the impact of backbone model casing on LSR has not been studied, potentially posing a risk to the viability of the method going forward. To fill this gap, we systematically evaluate paired cased and uncased versions of the same backbone models across multiple datasets to assess their suitability for LSR. Our findings show that LSR models with cased backbone models by default perform substantially worse than their uncased counterparts; however, this gap can be eliminated by pre-processing the text to lowercase. Moreover, our token-level analysis reveals that, under lowercasing, cased models almost entirely suppress cased vocabulary items and behave effectively as uncased models, explaining their restored performance. This result broadens the applicability of recent cased models to the LSR setting and facilitates the integration of stronger backbone architectures into sparse retrieval. The complete code and implementation for this project are available at: https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR

</details>


### [132] [Real-Time Trend Prediction via Continually-Aligned LLM Query Generation](https://arxiv.org/abs/2601.17567)
*Zijing Hui,Wenhan Lyu,Shusen Wang,Li Chen,Chu Wang*

Main category: cs.IR

TL;DR: RTTP框架通过持续学习LLM直接从新闻内容生成搜索查询，解决低流量搜索环境中的冷启动问题，实现早期趋势发现


<details>
  <summary>Details</summary>
Motivation: 低流量搜索环境中存在冷启动问题，传统基于查询频率或峰值的方法在稀疏环境下反应迟缓且无效，无法及时识别新兴或长尾趋势

Method: 提出RTTP实时趋势预测框架，使用持续学习LLM将新闻帖子转换为搜索风格查询，通过参与强度和创作者权威进行评分；采用Mix-Policy DPO方法结合在线策略稳定性和离线策略新颖性，防止模型升级时的灾难性遗忘

Result: 在Facebook和Meta AI产品中部署，长尾趋势检测精度@500提升91.4%，查询生成准确率比行业基准提高19%，多周在线训练后保持稳定性能

Conclusion: LLM生成的合成搜索信号经过对齐和持续更新后，能够在低流量搜索环境中实现及时的趋势理解，解决了传统方法的冷启动问题

Abstract: Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.

</details>


### [133] [Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts](https://arxiv.org/abs/2601.17601)
*Fangping Lan,Abdullah Aljebreen,Eduard C. Dragut*

Main category: cs.IR

TL;DR: 该研究开发了一个社交媒体中URL意图分类系统，通过众包标注和LLM辅助构建了包含6个顶层类别和26个细粒度意图的分类法，发现广告、争论和分享是最常见的URL意图。


<details>
  <summary>Details</summary>
Motivation: 虽然之前的研究关注URL分享者的动机，但这些作者中心的意图在实践中难以观察。为了支持更广泛的下游应用，本研究转向读者中心的解释，即用户如何理解帖子中包含的超链接意图。

Method: 采用混合方法：首先通过大规模众包标注进行自下而上的数据驱动过程，然后利用大语言模型辅助生成描述性类别名称和精确定义，最终构建包含6个顶层类别和26个细粒度意图的分类法。

Result: 应用该分类法标注分析了1000个用户帖子，发现广告、争论和分享是最普遍的意图。该分类法为意图感知的信息检索和NLP应用提供了基础。

Conclusion: 开发的URL意图分类系统能够更准确地理解社交媒体内容，支持更精确的信息检索、推荐和内容理解应用。

Abstract: URLs serve as bridges between social media platforms and the broader web, linking user-generated content to external information resources. On Twitter (X), approximately one in five tweets contains at least one URL, underscoring their central role in information dissemination. While prior studies have examined the motivations of authors who share URLs, such author-centered intentions are difficult to observe in practice. To enable broader downstream use, this work investigates reader-centered interpretations, i.e., how users perceive the intentions behind hyperlinks included in posts. We develop an intent taxonomy for including hyperlinks in social posts through a hybrid approach that begins with a bottom-up, data-driven process using large-scale crowdsourced annotations, and is then refined using large language model assistance to generate descriptive category names and precise definitions. The final taxonomy comprises 6 top-level categories and 26 fine-grained intention classes, capturing diverse communicative purposes. Applying this taxonomy, we annotate and analyze 1000 user posts, revealing that advertising, arguing, and sharing are the most prevalent intentions. This resulting taxonomy provides a foundation for intent-aware information retrieval and NLP applications, enabling more accurate retrieval, recommendation, and understanding of social media content.

</details>


### [134] [LegalMALR:Multi-Agent Query Understanding and LLM-Based Reranking for Chinese Statute Retrieval](https://arxiv.org/abs/2601.17692)
*Yunhan Li,Mingjie Xie,Gaoli Kang,Zihan Gong,Gengshen Wu,Min Yang*

Main category: cs.IR

TL;DR: LegalMALR是一个法律检索框架，通过多智能体查询理解系统和零样本LLM重排模块，解决隐式、多议题、口语化法律查询的法规检索难题。


<details>
  <summary>Details</summary>
Motivation: 现实中的法律查询往往是隐式的、多议题的，且以口语化或未充分说明的形式表达，这使得传统的检索增强生成管道难以准确恢复法规要素。密集检索器主要关注查询的字面形式，而轻量级重排器缺乏评估法规适用性所需的法律推理能力。

Method: 提出LegalMALR框架，包含：1）多智能体查询理解系统（MAS），生成多样化的法律基础重述并进行迭代密集检索以扩大候选覆盖；2）使用广义强化策略优化（GRPO）统一MAS策略以稳定LLM生成重写的随机行为；3）零样本大语言模型重排模块（LLM Reranker），通过自然语言法律推理生成最终排名。还构建了CSAID数据集（118个困难中文法律查询，带有多个法规标签）。

Result: 在CSAID数据集和公开STARD基准测试中，LegalMALR在分布内和分布外设置下均显著优于强大的检索增强生成基线方法。

Conclusion: 结合多视角查询解释、基于强化的策略优化和大模型重排的方法对法规检索是有效的，能够解决现实法律查询的复杂性挑战。

Abstract: Statute retrieval is essential for legal assistance and judicial decision support, yet real-world legal queries are often implicit, multi-issue, and expressed in colloquial or underspecified forms. These characteristics make it difficult for conventional retrieval-augmented generation pipelines to recover the statutory elements required for accurate retrieval. Dense retrievers focus primarily on the literal surface form of the query, whereas lightweight rerankers lack the legal-reasoning capacity needed to assess statutory applicability. We present LegalMALR, a retrieval framework that integrates a Multi-Agent Query Understanding System (MAS) with a zero-shot large-language-model-based reranking module (LLM Reranker). MAS generates diverse, legally grounded reformulations and conducts iterative dense retrieval to broaden candidate coverage. To stabilise the stochastic behaviour of LLM-generated rewrites, we optimise a unified MAS policy using Generalized Reinforcement Policy Optimization(GRPO). The accumulated candidate set is subsequently evaluated by the LLM Reranker, which performs natural-language legal reasoning to produce the final ranking. We further construct CSAID, a dataset of 118 difficult Chinese legal queries annotated with multiple statutory labels, and evaluate LegalMALR on both CSAID and the public STARD benchmark. Experiments show that LegalMALR substantially outperforms strong Retrieval-augmented generation(RAG) baselines in both in-distribution and out-of-distribution settings, demonstrating the effectiveness of combining multi-perspective query interpretation, reinforcement-based policy optimisation, and large-model reranking for statute retrieval.

</details>


### [135] [Token-Weighted Multi-Target Learning for Generative Recommenders with Curriculum Learning](https://arxiv.org/abs/2601.17787)
*Wei-Ning Chiu,Chuan-Ju Wang,Pu-Jen Cheng*

Main category: cs.IR

TL;DR: 本文针对基于语义ID的生成式推荐系统，提出了两种互补的token加权策略和课程学习框架，解决了传统方法对所有token同等对待的问题，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐系统将下一项预测视为自回归序列生成任务，但大多优化标准的下一个token似然，隐含地将所有token视为同等信息量，这与基于语义ID的生成不匹配。

Method: 提出了两种互补的基于信息增益的token加权策略：1) Front-Greater Weighting：通过优先处理能最有效减少候选项目不确定性的早期token来捕获条件语义信息增益；2) Frequency Weighting：在长尾项目和token分布下建模边际信息增益，对稀有token进行加权以抵消流行度偏差。此外，引入了带有课程学习的多目标学习框架，联合优化两个token加权目标和标准似然。

Result: 在基准数据集上的广泛实验表明，该方法始终优于强基线方法和现有token加权方法，具有改进的鲁棒性、对不同语义ID构建的强泛化能力，以及在头部和尾部项目上的显著增益。

Conclusion: 提出的token加权多目标学习框架有效解决了生成式推荐中语义ID生成的问题，通过信息增益视角重新加权token，结合课程学习实现稳定优化，显著提升了推荐系统的性能。

Abstract: Generative recommender systems have recently attracted attention by formulating next-item prediction as an autoregressive sequence generation task. However, most existing methods optimize standard next-token likelihood and implicitly treat all tokens as equally informative, which is misaligned with semantic-ID-based generation. Accordingly, we propose two complementary information-gain-based token-weighting strategies tailored to generative recommendation with semantic IDs. Front-Greater Weighting captures conditional semantic information gain by prioritizing early tokens that most effectively reduce candidate-item uncertainty given their prefixes and encode coarse semantics. Frequency Weighting models marginal information gain under long-tailed item and token distributions, upweighting rare tokens to counteract popularity bias. Beyond individual strategies, we introduce a multi-target learning framework with curriculum learning that jointly optimizes the two token-weighted objectives alongside standard likelihood, enabling stable optimization and adaptive emphasis across training stages. Extensive experiments on benchmark datasets show that our method consistently outperforms strong baselines and existing token-weighting approaches, with improved robustness, strong generalization across different semantic-ID constructions, and substantial gains on both head and tail items. Code is available at https://github.com/CHIUWEINING/Token-Weighted-Multi-Target-Learning-for-Generative-Recommenders-with-Curriculum-Learning.

</details>


### [136] [Unleashing the Potential of Sparse Attention on Long-term Behaviors for CTR Prediction](https://arxiv.org/abs/2601.17836)
*Weijiang Lai,Beihong Jin,Di Zhang,Siru Chen,Jiongyan Zhang,Yuhang Gou,Jian Dong,Xingxing Wang*

Main category: cs.IR

TL;DR: SparseCTR：针对推荐系统中用户长行为序列的高效稀疏注意力模型，通过个性化分块和三分支注意力机制解决计算复杂度问题，同时展现明显的缩放定律现象。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推荐系统中的缩放定律探索受到标准自注意力机制高计算复杂度的限制，特别是在工业环境中建模用户长行为序列时。现有的稀疏自注意力机制不完全适合推荐场景，因为用户行为具有个性化和时序特性，不同用户的行为模式差异大且随时间变化。

Method: 1. 个性化分块：将行为序列按个性化方式分块，避免分离连续行为并支持并行处理；2. 三分支稀疏自注意力：联合识别用户的全局兴趣、兴趣转移和短期兴趣；3. 复合相对时序编码：通过可学习的头部特定偏置系数更好地捕捉用户行为的时序和周期性关系。

Result: SparseCTR不仅提高了效率，而且在性能上超越了最先进的方法。更重要的是，它展现出明显的缩放定律现象，在三个数量级的FLOPs范围内保持性能提升。在线A/B测试中，CTR提高了1.72%，CPM提高了1.41%。

Conclusion: SparseCTR是针对用户长行为序列设计的高效有效模型，通过个性化分块和三分支稀疏注意力机制解决了推荐场景中的计算复杂度问题，同时保持了缩放定律特性，在工业部署中具有实际应用价值。

Abstract: In recent years, the success of large language models (LLMs) has driven the exploration of scaling laws in recommender systems. However, models that demonstrate scaling laws are actually challenging to deploy in industrial settings for modeling long sequences of user behaviors, due to the high computational complexity of the standard self-attention mechanism. Despite various sparse self-attention mechanisms proposed in other fields, they are not fully suited for recommendation scenarios. This is because user behaviors exhibit personalization and temporal characteristics: different users have distinct behavior patterns, and these patterns change over time, with data from these users differing significantly from data in other fields in terms of distribution. To address these challenges, we propose SparseCTR, an efficient and effective model specifically designed for long-term behaviors of users. To be precise, we first segment behavior sequences into chunks in a personalized manner to avoid separating continuous behaviors and enable parallel processing of sequences. Based on these chunks, we propose a three-branch sparse self-attention mechanism to jointly identify users' global interests, interest transitions, and short-term interests. Furthermore, we design a composite relative temporal encoding via learnable, head-specific bias coefficients, better capturing sequential and periodic relationships among user behaviors. Extensive experimental results show that SparseCTR not only improves efficiency but also outperforms state-of-the-art methods. More importantly, it exhibits an obvious scaling law phenomenon, maintaining performance improvements across three orders of magnitude in FLOPs. In online A/B testing, SparseCTR increased CTR by 1.72\% and CPM by 1.41\%. Our source code is available at https://github.com/laiweijiang/SparseCTR.

</details>


### [137] [Post-Training Denoising of User Profiles with LLMs in Collaborative Filtering Recommendation](https://arxiv.org/abs/2601.18009)
*Ervin Dervishaj,Maria Maistro,Tuukka Ruotsalo,Christina Lioma*

Main category: cs.IR

TL;DR: 提出一种基于大语言模型的协同过滤推荐系统后训练去噪方法，通过LLM分析用户历史交互、候选物品及其排名，智能移除用户档案中的噪声数据以提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 隐式反馈数据存在固有噪声，传统去噪方法需要修改模型架构、训练过程或额外数据，成本高且数据需求大。本文旨在开发一种无需改变模型架构、训练过程或额外数据的后训练去噪方法。

Method: 提出基于大语言模型的协同过滤推荐后训练去噪方法：向LLM提供用户交互历史、候选物品及其在CF推荐器中的排名，让LLM识别并移除用户档案中可能降低候选物品排名的噪声交互项。

Result: 在3个数据集上使用4个开源和闭源LLM与最先进的CF推荐器进行实验，结果显示该方法能使推荐效果提升高达13%，显著优于原始用户档案。

Conclusion: 基于LLM的后训练去噪方法有效提升了协同过滤推荐系统的性能，无需修改模型架构或训练过程，为推荐系统去噪提供了高效实用的解决方案。

Abstract: Implicit feedback -- the main data source for training Recommender Systems (RSs) -- is inherently noisy and has been shown to negatively affect recommendation effectiveness. Denoising has been proposed as a method for removing noisy implicit feedback and improving recommendations. Prior work has focused on in-training denoising, however this requires additional data, changes to the model architecture and training procedure or fine-tuning, all of which can be costly and data hungry. In this work, we focus on post-training denoising. Different from in-training denoising, post-training denoising does not involve changing the architecture of the model nor its training procedure, and does not require additional data. Specifically, we present a method for post-training denoising user profiles using Large Language Models (LLMs) for Collaborative Filtering (CF) recommendations. Our approach prompts LLMs with (i) a user profile (user interactions), (ii) a candidate item, and (iii) its rank as given by the CF recommender, and asks the LLM to remove items from the user profile to improve the rank of the candidate item. Experiments with a state-of-the-art CF recommender and 4 open and closed source LLMs in 3 datasets show that our denoising yields improvements up to 13% in effectiveness over the original user profiles. Our code is available at https://github.com/edervishaj/denoising-user-profiles-LLM.

</details>


### [138] [Enhancing LLM-based Recommendation with Preference Hint Discovery from Knowledge Graph](https://arxiv.org/abs/2601.18096)
*Yuting Zhang,Ziliang Pei,Chao Wang,Ying Sun,Fuzhen Zhuang*

Main category: cs.IR

TL;DR: 提出基于交互集成知识图谱的偏好提示发现模型，通过选择性提取关键属性作为提示，增强LLM在推荐系统中的表现，解决了传统嵌入与离散语义空间之间的鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在推荐系统中受到广泛关注，但在捕捉复杂偏好模式方面不如传统推荐器。现有方法尝试将传统推荐嵌入集成到LLMs中，但连续嵌入空间与离散语义空间之间存在核心鸿沟。从交互中提取的文本属性可以作为LLMs推荐逻辑的关键偏好依据，但直接输入这些属性面临两个挑战：稀疏交互难以反映未见项目的偏好线索；将所有属性作为线索会引入大量噪声。

Method: 提出基于交互集成知识图谱的偏好提示发现模型：1）设计协作偏好提示提取方案，利用相似用户显式交互的语义知识作为未见项目的提示；2）开发实例级双重注意力机制，量化候选属性的偏好可信度，识别每个未见项目的特定提示；3）采用扁平化提示组织方法缩短输入长度，将文本提示信息输入LLM进行常识推理。

Result: 在成对和列表推荐任务上的大量实验验证了所提框架的有效性，相对于基线平均相对改进超过3.02%。

Conclusion: 通过选择性提取关键属性作为偏好提示，有效解决了LLMs在推荐系统中捕捉复杂偏好模式的局限性，弥合了连续嵌入与离散语义空间之间的鸿沟，显著提升了推荐性能。

Abstract: LLMs have garnered substantial attention in recommendation systems. Yet they fall short of traditional recommenders when capturing complex preference patterns. Recent works have tried integrating traditional recommendation embeddings into LLMs to resolve this issue, yet a core gap persists between their continuous embedding and discrete semantic spaces. Intuitively, textual attributes derived from interactions can serve as critical preference rationales for LLMs' recommendation logic. However, directly inputting such attribute knowledge presents two core challenges: (1) Deficiency of sparse interactions in reflecting preference hints for unseen items; (2) Substantial noise introduction from treating all attributes as hints. To this end, we propose a preference hint discovery model based on the interaction-integrated knowledge graph, enhancing LLM-based recommendation. It utilizes traditional recommendation principles to selectively extract crucial attributes as hints. Specifically, we design a collaborative preference hint extraction schema, which utilizes semantic knowledge from similar users' explicit interactions as hints for unseen items. Furthermore, we develop an instance-wise dual-attention mechanism to quantify the preference credibility of candidate attributes, identifying hints specific to each unseen item. Using these item- and user-based hints, we adopt a flattened hint organization method to shorten input length and feed the textual hint information to the LLM for commonsense reasoning. Extensive experiments on both pair-wise and list-wise recommendation tasks verify the effectiveness of our proposed framework, indicating an average relative improvement of over 3.02% against baselines.

</details>


### [139] [Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking](https://arxiv.org/abs/2601.18146)
*Huizhong Guo,Tianjun Wei,Dongxia Wang,Yingpeng Du,Ziyan Wang,Jie Zhang,Zhu Sun*

Main category: cs.IR

TL;DR: 提出推理路由框架，通过轻量级路由器头在生成前决定每个实例使用直接推理还是推理模式，在提升排序效果的同时显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 虽然推理提示可以提升LLM在排序任务中的效果，但初步探索发现其收益不一致且计算成本高昂，表明"何时推理"与"如何推理"同样重要。

Method: 提出推理路由框架，使用轻量级、即插即用的路由器头，在生成前基于预生成信号（紧凑的排序感知特征和模型感知难度信号）决定每个实例使用直接推理还是推理模式。

Result: 在三个公开排序数据集和不同规模的开源LLM上实验，一致提升了排序效果并减少了token消耗（例如在MovieLens上使用Qwen3-4B实现+6.3% NDCG@10和-49.5% token消耗）。

Conclusion: 推理路由框架是解决准确性与效率权衡的实用解决方案，能够在不同系统约束下动态分配计算资源到最可能从推理中受益的实例。

Abstract: Large language models (LLMs) are increasingly applied to ranking tasks in retrieval and recommendation. Although reasoning prompting can enhance ranking utility, our preliminary exploration reveals that its benefits are inconsistent and come at a substantial computational cost, suggesting that when to reason is as crucial as how to reason. To address this issue, we propose a reasoning routing framework that employs a lightweight, plug-and-play router head to decide whether to use direct inference (Non-Think) or reasoning (Think) for each instance before generation. The router head relies solely on pre-generation signals: i) compact ranking-aware features (e.g., candidate dispersion) and ii) model-aware difficulty signals derived from a diagnostic checklist reflecting the model's estimated need for reasoning. By leveraging these features before generation, the router outputs a controllable token that determines whether to apply the Think mode. Furthermore, the router can adaptively select its operating policy along the validation Pareto frontier during deployment, enabling dynamic allocation of computational resources toward instances most likely to benefit from Think under varying system constraints. Experiments on three public ranking datasets with different scales of open-source LLMs show consistent improvements in ranking utility with reduced token consumption (e.g., +6.3\% NDCG@10 with -49.5\% tokens on MovieLens with Qwen3-4B), demonstrating reasoning routing as a practical solution to the accuracy-efficiency trade-off.

</details>


### [140] [Generative Chain of Behavior for User Trajectory Prediction](https://arxiv.org/abs/2601.18213)
*Chengkai Huang,Xiaodi Chen,Hongtao Huang,Quan Z. Sheng,Lina Yao*

Main category: cs.IR

TL;DR: GCB是一个生成式用户行为建模框架，通过语义ID编码和自回归生成器预测多步未来行为，超越了传统序列推荐器的单步预测限制。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐器主要关注下一项预测，忽略了跨多个未来行为的依赖关系，无法捕捉用户偏好的长期演变趋势。

Method: 1) 使用RQ-VAE和k-means细化将物品编码为语义ID，构建保持语义邻近性的离散潜在空间；2) 基于transformer的自回归生成器，在用户历史条件下预测多步未来行为，捕捉长期意图转移并生成连贯轨迹。

Result: 在基准数据集上的实验表明，GCB在多步准确性和轨迹一致性方面持续优于最先进的序列推荐器。

Conclusion: GCB不仅提供了性能提升，更重要的是为捕捉用户偏好演变提供了一个统一的生成式框架，能够建模长期用户行为轨迹。

Abstract: Modeling long-term user behavior trajectories is essential for understanding evolving preferences and enabling proactive recommendations. However, most sequential recommenders focus on next-item prediction, overlooking dependencies across multiple future actions. We propose Generative Chain of Behavior (GCB), a generative framework that models user interactions as an autoregressive chain of semantic behaviors over multiple future steps. GCB first encodes items into semantic IDs via RQ-VAE with k-means refinement, forming a discrete latent space that preserves semantic proximity. On top of this space, a transformer-based autoregressive generator predicts multi-step future behaviors conditioned on user history, capturing long-horizon intent transitions and generating coherent trajectories. Experiments on benchmark datasets show that GCB consistently outperforms state-of-the-art sequential recommenders in multi-step accuracy and trajectory consistency. Beyond these gains, GCB offers a unified generative formulation for capturing user preference evolution.

</details>


### [141] [Token-level Collaborative Alignment for LLM-based Generative Recommendation](https://arxiv.org/abs/2601.18457)
*Fake Lin,Binbin Hu,Zhi Zheng,Xi Zhu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Tong Xu*

Main category: cs.IR

TL;DR: TCA4Rec是一个模型无关的即插即用框架，通过令牌级协同对齐解决LLM推荐系统中难以有效整合协同过滤信号的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的推荐系统难以有效整合协同过滤信号，因为CF基于物品级偏好建模，而LLM基于令牌级下一个令牌预测优化，两者存在根本性不匹配。先前方法通常将CF作为上下文提示或表示偏差，需要多阶段训练来减少行为语义空间差异，导致CF无法显式调控LLM生成。

Method: 提出TCA4Rec框架，包含两个核心组件：(1)协同分词器，将原始物品级CF对数概率投影到与LLM令牌空间对齐的令牌级分布；(2)软标签对齐，将这些CF信息分布与独热监督结合，优化软NTP目标。该设计保留了LLM训练的生成特性，同时实现与CF模型核心用户偏好的协同对齐。

Result: TCA4Rec与任意传统CF模型兼容，可泛化到广泛的基于解码器的LLM推荐架构。它提供了显式机制来平衡行为对齐和语义流畅性，生成既准确又可控制的推荐。大量实验表明，TCA4Rec在各种CF模型和基于LLM的推荐系统中都能持续提升推荐性能。

Conclusion: TCA4Rec通过建立CF监督与LLM生成之间的显式优化级接口，有效解决了LLM推荐系统中协同过滤信号整合的难题，实现了生成式推荐中行为对齐与语义流畅性的平衡。

Abstract: Large Language Models (LLMs) have demonstrated strong potential for generative recommendation by leveraging rich semantic knowledge. However, existing LLM-based recommender systems struggle to effectively incorporate collaborative filtering (CF) signals, due to a fundamental mismatch between item-level preference modeling in CF and token-level next-token prediction (NTP) optimization in LLMs. Prior approaches typically treat CF as contextual hints or representation bias, and resort to multi-stage training to reduce behavioral semantic space discrepancies, leaving CF unable to explicitly regulate LLM generation. In this work, we propose Token-level Collaborative Alignment for Recommendation (TCA4Rec), a model-agnostic and plug-and-play framework that establishes an explicit optimization-level interface between CF supervision and LLM generation. TCA4Rec consists of (i) Collaborative Tokenizer, which projects raw item-level CF logits into token-level distributions aligned with the LLM token space, and (ii) Soft Label Alignment, which integrates these CF-informed distributions with one-hot supervision to optimize a soft NTP objective. This design preserves the generative nature of LLM training while enabling collaborative alignment with essential user preference of CF models. We highlight TCA4Rec is compatible with arbitrary traditional CF models and generalizes across a wide range of decoder-based LLM recommender architectures. Moreover, it provides an explicit mechanism to balance behavioral alignment and semantic fluency, yielding generative recommendations that are both accurate and controllable. Extensive experiments demonstrate that TCA4Rec consistently improves recommendation performance across a broad spectrum of CF models and LLM-based recommender systems.

</details>


### [142] [Feature-Indexed Federated Recommendation with Residual-Quantized Codebooks](https://arxiv.org/abs/2601.18570)
*Mingzhe Han,Jiahao Liu,Dongsheng Li,Hansu Gu,Peng Zhang,Ning Gu,Tun Lu*

Main category: cs.IR

TL;DR: RQFedRec提出了一种基于特征索引通信范式的联邦推荐系统，通过残差量化和双通道聚合解决传统ID索引通信的通信开销大、泛化能力差和对噪声敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐方法采用ID索引通信范式，存在三个主要问题：1) 通信资源消耗不可控；2) 上传的项目信息无法泛化到相关未交互项目；3) 对客户端噪声反馈敏感。需要从根本上改变现有的通信范式。

Method: 提出特征索引通信范式，传输特征码嵌入作为码本而非原始项目嵌入。使用残差量化(RQ)-Kmeans为每个项目分配离散码ID列表，客户端基于服务器提供的码ID生成和训练码嵌入作为码本，服务器聚合码本而非项目嵌入。采用协作-语义双通道聚合和课程学习策略，早期强调语义码，逐步增加协作码的贡献。

Result: 在真实世界数据集上的大量实验表明，RQFedRec在显著减少通信开销的同时，持续优于最先进的联邦推荐基线方法。

Conclusion: RQFedRec通过特征索引通信范式解决了传统联邦推荐系统的关键限制，实现了可控通信、跨项目泛化能力和对噪声的鲁棒性，为联邦推荐系统提供了更高效和有效的解决方案。

Abstract: Federated recommendation provides a privacy-preserving solution for training recommender systems without centralizing user interactions. However, existing methods follow an ID-indexed communication paradigm that transmit whole item embeddings between clients and the server, which has three major limitations: 1) consumes uncontrollable communication resources, 2) the uploaded item information cannot generalize to related non-interacted items, and 3) is sensitive to client noisy feedback. To solve these problems, it is necessary to fundamentally change the existing ID-indexed communication paradigm. Therefore, we propose a feature-indexed communication paradigm that transmits feature code embeddings as codebooks rather than raw item embeddings. Building on this paradigm, we present RQFedRec, which assigns each item a list of discrete code IDs via Residual Quantization (RQ)-Kmeans. Each client generates and trains code embeddings as codebooks based on discrete code IDs provided by the server, and the server collects and aggregates these codebooks rather than item embeddings. This design makes communication controllable since the codebooks could cover all items, enabling updates to propagate across related items in same code ID. In addition, since code embedding represents many items, which is more robust to a single noisy item. To jointly capture semantic and collaborative information, RQFedRec further adopts a collaborative-semantic dual-channel aggregation with a curriculum strategy that emphasizes semantic codes early and gradually increases the contribution of collaborative codes over training. Extensive experiments on real-world datasets demonstrate that RQFedRec consistently outperforms state-of-the-art federated recommendation baselines while significantly reducing communication overhead.

</details>


### [143] [FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG](https://arxiv.org/abs/2601.18579)
*Seonho An,Chaejeong Hyun,Min-Soo Kim*

Main category: cs.IR

TL;DR: FastInsight是一种高效的图RAG方法，通过融合图模型搜索和向量图搜索，解决了现有方法在拓扑感知和语义感知方面的局限性，在效果和效率之间实现了显著的帕累托改进。


<details>
  <summary>Details</summary>
Motivation: 现有图RAG方法通常依赖耗时的大型语言模型推理过程，无法实现高效的知识检索。作者通过图检索分类法发现当前方法存在两个关键限制：模型搜索的拓扑盲性和图搜索的语义盲性。

Method: 提出FastInsight方法，包含两个新颖的融合算子：1) Graph-based Reranker (GRanker) - 作为图模型搜索；2) Semantic-Topological eXpansion (STeX) - 作为向量图搜索。通过交替使用这两个算子克服现有方法的局限性。

Result: 在广泛的检索和生成数据集上进行大量实验，结果显示FastInsight在检索准确性和生成质量方面显著优于最先进的基线方法，在效果和效率的权衡中实现了实质性的帕累托改进。

Conclusion: FastInsight通过创新的融合算子解决了图RAG中的拓扑盲性和语义盲性问题，实现了时间高效且洞察力强的检索，为图检索领域提供了有效的解决方案。

Abstract: Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.

</details>


### [144] [S$^2$GR: Stepwise Semantic-Guided Reasoning in Latent Space for Generative Recommendation](https://arxiv.org/abs/2601.18664)
*Zihao Guo,Jian Wang,Ruxin Zhou,Youhua Liu,Jiawei Guo,Jun Zhao,Xiaoxiao Xu,Yongqi Liu,Kaiqiao Zhan*

Main category: cs.IR

TL;DR: S²GR提出了一种新的生成式推荐框架，通过代码本优化和逐步推理机制，在潜在空间中实现语义引导的推理，解决了现有方法在推理与生成分离、计算焦点不平衡以及推理路径缺乏可解释性等问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法主要关注从交互序列直接生成语义ID，未能激活类似大语言模型的深度推理能力，限制了性能潜力。当前推理增强的GR方法存在两个关键限制：1) 推理和生成步骤的严格顺序分离导致跨层次SID代码的计算焦点不平衡；2) 生成的推理向量缺乏可解释语义，推理路径缺乏可验证的监督。

Method: 提出S²GR框架：首先通过代码本优化建立稳健的语义基础，整合物品共现关系以捕捉行为模式，并通过负载平衡和均匀性目标最大化代码本利用率，同时强化从粗到细的语义层次。核心创新是逐步推理机制，在每个SID生成步骤前插入思考令牌，每个令牌明确表示粗粒度语义，通过对比学习监督，确保推理路径有物理基础且所有SID代码的计算焦点平衡。

Result: 大量实验证明了S²GR的优越性，在线A/B测试在大规模工业短视频平台上确认了其有效性。

Conclusion: S²GR通过语义引导的逐步推理机制，有效解决了现有生成式推荐方法的局限性，在保持推理路径可解释性的同时提升了推荐性能，并在工业场景中得到验证。

Abstract: Generative Recommendation (GR) has emerged as a transformative paradigm with its end-to-end generation advantages. However, existing GR methods primarily focus on direct Semantic ID (SID) generation from interaction sequences, failing to activate deeper reasoning capabilities analogous to those in large language models and thus limiting performance potential. We identify two critical limitations in current reasoning-enhanced GR approaches: (1) Strict sequential separation between reasoning and generation steps creates imbalanced computational focus across hierarchical SID codes, degrading quality for SID codes; (2) Generated reasoning vectors lack interpretable semantics, while reasoning paths suffer from unverifiable supervision. In this paper, we propose stepwise semantic-guided reasoning in latent space (S$^2$GR), a novel reasoning enhanced GR framework. First, we establish a robust semantic foundation via codebook optimization, integrating item co-occurrence relationship to capture behavioral patterns, and load balancing and uniformity objectives that maximize codebook utilization while reinforcing coarse-to-fine semantic hierarchies. Our core innovation introduces the stepwise reasoning mechanism inserting thinking tokens before each SID generation step, where each token explicitly represents coarse-grained semantics supervised via contrastive learning against ground-truth codebook cluster distributions ensuring physically grounded reasoning paths and balanced computational focus across all SID codes. Extensive experiments demonstrate the superiority of S$^2$GR, and online A/B test confirms efficacy on large-scale industrial short video platform.

</details>


### [145] [Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval](https://arxiv.org/abs/2601.18747)
*Amir Aavani*

Main category: cs.IR

TL;DR: 本文提出了一种新的检索语言和算法，能够高效处理复杂的神经符号推理工作流中的逻辑和算术约束，解决了现有检索架构在效率和内存消耗方面的困境。


<details>
  <summary>Details</summary>
Motivation: 现代信息检索正从简单的文档过滤转向复杂的神经符号推理工作流，但现有检索架构在处理严格的逻辑和算术约束时面临效率困境：基于迭代器的引擎无法有效处理复杂嵌套逻辑图，而递归方法虽然能支持这些结构但内存消耗过大。

Method: 提出基于有向无环图（DAGs）的形式化检索语言（$\mathcal{L}_R$），并证明其精确捕捉了复杂度类$\mathbf{P}$。引入\texttt{ComputePN}算法，结合原生DAG遍历和内存高效的"正-负"响应机制，确保$\mathcal{L}_R$中任何查询的高效评估。

Result: 建立了将搜索索引转变为通用计算引擎的理论基础，通过\texttt{ComputePN}算法实现了对$\mathcal{L}_R$查询的高效评估，解决了复杂逻辑约束下的效率和内存问题。

Conclusion: 检索引擎必须能够"捕捉$\mathbf{P}$"——在索引上以计算高效的方式直接评估任何多项式时间属性。这项工作为将搜索索引转变为通用计算引擎奠定了理论基础。

Abstract: Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.
  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\mathbf{P}$. We introduce \texttt{ComputePN}, a novel evaluation algorithm that makes $\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \texttt{ComputePN} ensures the efficient evaluation of any query in $\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [146] [MathMixup: Boosting LLM Mathematical Reasoning with Difficulty-Controllable Data Synthesis and Curriculum Learning](https://arxiv.org/abs/2601.17006)
*Xuchen Li,Jing Chen,Xuzhao Li,Hao Liang,Xiaohuan Zhou,Taifeng Wang,Wentao Zhang*

Main category: cs.LG

TL;DR: MathMixup：通过混合和分解策略生成难度可控的高质量数学推理问题，构建数据集并设计课程学习策略，显著提升LLMs数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据合成方法存在多样性有限、难度控制不精确的问题，无法有效支持课程学习等高效训练范式，需要开发能系统生成高质量、难度可控数学推理问题的方案。

Method: 提出MathMixup数据合成范式，通过混合和分解策略系统生成难度可控的数学推理问题；采用自动自检和人工筛选确保语义清晰和难度梯度；构建MathMixupQA数据集并设计课程学习策略。

Result: 微调后的Qwen2.5-7B在七个数学基准测试中平均得分52.6%，超越先前最先进方法，验证了MathMixup在提升LLMs数学推理能力和推进数据中心课程学习方面的有效性。

Conclusion: MathMixup及其课程学习策略能显著增强LLMs的数学推理性能，为数据中心的课程学习提供了有效解决方案，具有广泛适用性。

Abstract: In mathematical reasoning tasks, the advancement of Large Language Models (LLMs) relies heavily on high-quality training data with clearly defined and well-graded difficulty levels. However, existing data synthesis methods often suffer from limited diversity and lack precise control over problem difficulty, making them insufficient for supporting efficient training paradigms such as curriculum learning. To address these challenges, we propose MathMixup, a novel data synthesis paradigm that systematically generates high-quality, difficulty-controllable mathematical reasoning problems through hybrid and decomposed strategies. Automated self-checking and manual screening are incorporated to ensure semantic clarity and a well-structured difficulty gradient in the synthesized data. Building on this, we construct the MathMixupQA dataset and design a curriculum learning strategy that leverages these graded problems, supporting flexible integration with other datasets. Experimental results show that MathMixup and its curriculum learning strategy significantly enhance the mathematical reasoning performance of LLMs. Fine-tuned Qwen2.5-7B achieves an average score of 52.6\% across seven mathematical benchmarks, surpassing previous state-of-the-art methods. These results fully validate the effectiveness and broad applicability of MathMixup in improving the mathematical reasoning abilities of LLMs and advancing data-centric curriculum learning.

</details>


### [147] [FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices](https://arxiv.org/abs/2601.17063)
*Byeongju Kim,Jungwan Lee,Donghyeon Han,Hoi-Jun Yoo,Sangyeob Kim*

Main category: cs.LG

TL;DR: FlashMoE是一个将不活跃专家卸载到SSD的系统，使大型MoE模型能在内存受限的设备上高效推理，通过智能缓存策略减少存储I/O，在真实硬件上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着MoE模型增长到数百GB，现有的DRAM卸载方案（如Fiddler、DAOP）在内存受限的移动设备上变得不切实际，需要新的解决方案来支持边缘设备上的MoE推理。

Method: 提出FlashMoE系统，将不活跃专家卸载到SSD存储，采用基于机器学习的轻量级缓存策略，结合最近使用和频率信号自适应管理专家重用，最大化缓存命中率。

Result: 在真实桌面硬件平台上，FlashMoE相比LRU和LFU等传统卸载策略将缓存命中率提升高达51%，相比现有MoE推理系统实现最高2.6倍加速。

Conclusion: FlashMoE通过SSD卸载和智能缓存策略，成功解决了大型MoE模型在内存受限设备上的推理问题，为边缘设备上的高效MoE推理提供了实用解决方案。

Abstract: Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.

</details>


### [148] [ThinkTank-ME: A Multi-Expert Framework for Middle East Event Forecasting](https://arxiv.org/abs/2601.17065)
*Haoxuan Li,He Chang,Yunshan Ma,Yi Bin,Yang Yang,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.LG

TL;DR: 提出ThinkTank-ME框架，通过多专家协作模拟现实战略决策，解决中东事件预测中单一模型无法捕捉复杂地缘政治细微差别的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的事件预测方法采用单一模型架构，只能沿着单一显式轨迹生成预测，限制了其在复杂区域背景下捕捉多样化地缘政治细微差别的能力。事件预测本质上受到多方面因素的影响，包括国际关系、区域历史动态和文化背景。

Method: 引入ThinkTank-ME框架，模拟现实世界中战略决策的协作专家分析。同时构建POLECAT-FOR-ME基准，这是一个专注于中东的事件预测基准，用于促进专家专业化和严格评估。

Result: 实验结果表明，多专家协作在处理复杂时间地缘政治预测任务方面具有优越性。

Conclusion: ThinkTank-ME框架通过模拟现实世界专家协作，有效解决了中东事件预测中单一模型的局限性，展示了多专家协作在复杂地缘政治预测中的优势。

Abstract: Event forecasting is inherently influenced by multifaceted considerations, including international relations, regional historical dynamics, and cultural contexts. However, existing LLM-based approaches employ single-model architectures that generate predictions along a singular explicit trajectory, constraining their ability to capture diverse geopolitical nuances across complex regional contexts. To address this limitation, we introduce ThinkTank-ME, a novel Think Tank framework for Middle East event forecasting that emulates collaborative expert analysis in real-world strategic decision-making. To facilitate expert specialization and rigorous evaluation, we construct POLECAT-FOR-ME, a Middle East-focused event forecasting benchmark. Experimental results demonstrate the superiority of multi-expert collaboration in handling complex temporal geopolitical forecasting tasks. The code is available at https://github.com/LuminosityX/ThinkTank-ME.

</details>


### [149] [SFO: Learning PDE Operators via Spectral Filtering](https://arxiv.org/abs/2601.17090)
*Noam Koren,Rafael Moschopoulos,Kira Radinsky,Elad Hazan*

Main category: cs.LG

TL;DR: SFO是一种新型神经算子，利用通用谱基参数化积分核，通过快速衰减特征值的谱系数学习，在六个基准测试中实现最先进精度，误差降低达40%且参数更少。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子在捕捉PDE解映射中的长程非局部相互作用方面效率低下，而离散格林函数具有空间线性动力系统结构，可在通用谱基中获得紧凑近似。

Method: 提出谱滤波算子(SFO)，使用从希尔伯特矩阵特征模态导出的固定全局正交基（通用谱基）参数化积分核，仅学习快速衰减特征值的谱系数，实现高效表示。

Result: 在六个基准测试（包括反应-扩散、流体动力学和3D电磁学）中，SFO实现了最先进的精度，相对于强基线误差降低达40%，同时使用更少的参数。

Conclusion: SFO通过理论驱动的谱基表示，有效捕捉PDE解映射中的长程非局部相互作用，在多个领域实现了高效且准确的神经算子设计。

Abstract: Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.

</details>


### [150] [CUROCKET: Optimizing ROCKET for GPU](https://arxiv.org/abs/2601.17091)
*Ole Stüven,Keno Moenck,Thorsten Schüppstuhl*

Main category: cs.LG

TL;DR: CUROCKET是一种在GPU上高效实现ROCKET特征提取算法的改进版本，通过解决非均匀卷积核在GPU上的并行化难题，实现了比CPU版本高达11倍的每瓦计算效率提升。


<details>
  <summary>Details</summary>
Motivation: ROCKET算法在时间序列分类中表现出色，但现有实现主要局限于CPU执行。卷积操作天然适合GPU并行化，但ROCKET使用的非均匀卷积核使得标准GPU卷积方法效率低下，因此需要专门设计GPU优化算法。

Method: 提出了一种能够在GPU上高效执行ROCKET特征提取的算法，专门解决了非均匀卷积核在GPU并行化中的效率问题，实现了CUROCKET实现。

Result: CUROCKET在GPU上实现了显著的计算效率提升，达到比CPU版本高达11倍的每瓦计算效率，代码已在GitHub开源。

Conclusion: 通过专门设计的GPU优化算法，成功解决了ROCKET非均匀卷积核在GPU上的并行化难题，实现了显著的计算效率提升，为时间序列分类提供了更高效的解决方案。

Abstract: ROCKET (RandOm Convolutional KErnel Transform) is a feature extraction algorithm created for Time Series Classification (TSC), published in 2019. It applies convolution with randomly generated kernels on a time series, producing features that can be used to train a linear classifier or regressor like Ridge. At the time of publication, ROCKET was on par with the best state-of-the-art algorithms for TSC in terms of accuracy while being significantly less computationally expensive, making ROCKET a compelling algorithm for TSC. This also led to several subsequent versions, further improving accuracy and computational efficiency. The currently available ROCKET implementations are mostly bound to execution on CPU. However, convolution is a task that can be highly parallelized and is therefore suited to be executed on GPU, which speeds up the computation significantly. A key difficulty arises from the inhomogeneous kernels ROCKET uses, making standard methods for applying convolution on GPU inefficient. In this work, we propose an algorithm that is able to efficiently perform ROCKET on GPU and achieves up to 11 times higher computational efficiency per watt than ROCKET on CPU. The code for CUROCKET is available in this repository https://github.com/oleeven/CUROCKET on github.

</details>


### [151] [Boltzmann-GPT: Bridging Energy-Based World Models and Language Generation](https://arxiv.org/abs/2601.17094)
*Junichiro Niimi*

Main category: cs.LG

TL;DR: 该论文提出"嘴不是大脑"的架构原则，将世界模型与语言模型分离，通过深度玻尔兹曼机作为基于能量的世界模型、适配器和冻结的GPT-2组成系统，在消费者评论领域实现更一致可控的文本生成。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能生成流畅文本，但学界对其是否真正理解世界还是仅产生看似合理的语言存在争议。作者旨在探索如何将语言能力与世界理解分离，以解决LLMs可能缺乏真实世界理解的问题。

Method: 提出"嘴不是大脑"架构原则，包含三个组件：1) 深度玻尔兹曼机作为基于能量的世界模型捕获领域结构；2) 适配器将潜在信念状态投影到嵌入空间；3) 冻结的GPT-2提供语言能力但不含领域知识。在亚马逊智能手机评论领域实例化该框架。

Result: 实验表明：1) 通过世界模型调节能显著提高情感相关性、降低困惑度、增加语义相似性；2) DBM能量函数能区分连贯与不连贯的市场配置，对不合理品牌-价格组合分配更高能量；3) 对特定属性的干预能因果传播到生成文本，干预输出与自然样本统计一致。

Conclusion: 即使小规模语言模型连接到适当的世界模型也能实现一致可控的生成，为分离语言能力与世界理解提供了实证支持，表明将世界模型与语言模型明确分离是可行且有价值的架构方法。

Abstract: Large Language Models (LLMs) generate fluent text, yet whether they truly understand the world or merely produce plausible language about it remains contested. We propose an architectural principle, the mouth is not the brain, that explicitly separates world models from language models. Our architecture comprises three components: a Deep Boltzmann Machine (DBM) that captures domain structure as an energy-based world model, an adapter that projects latent belief states into embedding space, and a frozen GPT-2 that provides linguistic competence without domain knowledge. We instantiate this framework in the consumer review domain using Amazon smartphone reviews. Experiments demonstrate that (1) conditioning through the world model yields significantly higher sentiment correlation, lower perplexity, and greater semantic similarity compared to prompt-based generation alone; (2) the DBM's energy function distinguishes coherent from incoherent market configurations, assigning higher energy to implausible brand-price combinations; and (3) interventions on specific attributes propagate causally to generated text with intervened outputs exhibiting distributions statistically consistent with naturally occurring samples sharing the target configuration. These findings suggest that even small-scale language models can achieve consistent, controllable generation when connected to an appropriate world model, providing empirical support for separating linguistic competence from world understanding.

</details>


### [152] [Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts](https://arxiv.org/abs/2601.17111)
*Xuan-Phi Nguyen,Shrey Pandit,Austin Xu,Caiming Xiong,Shafiq Joty*

Main category: cs.LG

TL;DR: 论文提出LLEP算法解决MoE模型专家并行中路由不平衡问题，相比标准EP实现5倍加速和4倍内存降低


<details>
  <summary>Details</summary>
Motivation: 尽管MoE模型在预训练时使用负载均衡约束，但实际路由仍显著不平衡。专家并行(EP)假设均衡路由，在极端不平衡时会导致过载设备出现计算和内存故障，特别是在后训练和推理阶段无法应用显式负载均衡。

Method: 提出最小负载专家并行(LLEP)算法，动态将过载设备的超额token和相关专家参数重路由到未充分利用的设备，确保所有设备在最小集体延迟内完成工作负载，同时满足内存约束。

Result: 在不同模型规模下，LLEP相比标准EP实现高达5倍加速和4倍峰值内存使用降低，使gpt-oss-120b后训练和推理速度提升约1.9倍。

Conclusion: LLEP解决了MoE模型专家并行中的路由不平衡问题，通过理论分析和实证评估支持该方法，为硬件特定的超参数调优提供了原则性框架。

Abstract: Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.

</details>


### [153] [Low-Rank Tensor Approximation of Weights in Large Language Models via Cosine Lanczos Bidiagonalization](https://arxiv.org/abs/2601.17112)
*A. El Ichi,K. Jbilou*

Main category: cs.LG

TL;DR: 提出基于cproduct的张量压缩框架，用于降低大语言模型的内存占用和计算成本


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然在各种自然语言任务中表现出色，但存在极大的内存占用和计算成本问题

Method: 利用cproduct的代数结构，在变换域中表示权重张量，通过低秩张量因子联合近似前切片，实现计算高效的压缩

Result: 该方法能够利用多维相关性，超越传统的SVD方法

Conclusion: 提出的张量压缩框架为大语言模型的高效压缩提供了新的技术途径

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language tasks but suffer from extremely large memory footprints and computational costs. In this paper, we introduce a tensor compression framework based on the cproduct for computing low rank approximation In the first part of our approach, we leverage the algebraic structure of the cproduct to represent weight tensors such as those in embedding layers, attention projections, and feed forward networks in a transform domain where frontal slices can be jointly approximated by low rank tensor factors. This enables computationally efficient compression that exploits multidimensional correlations beyond traditional SVD methods.

</details>


### [154] [ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning](https://arxiv.org/abs/2601.17135)
*Jakob Karalus,Friedhelm Schwenker*

Main category: cs.LG

TL;DR: ConceptACT扩展了Action Chunking with Transformers，通过利用演示中的语义概念标注来提高机器人模仿学习的效率，无需在部署时提供语义输入。


<details>
  <summary>Details</summary>
Motivation: 当前的模仿学习方法仅依赖低级的传感器数据，忽略了人类自然拥有的丰富语义知识。人类在完成任务时理解对象属性、空间关系和任务约束等概念，这些语义信息可以显著提高学习效率。

Method: ConceptACT是ACT的扩展，在训练时利用演示级别的语义概念标注（对象属性、空间关系、任务约束）。采用改进的transformer架构，在最终编码器层实现概念感知的交叉注意力机制，通过监督学习使其与人类标注对齐。概念仅在演示收集时由人类提供，部署时不需要语义输入。

Result: 在两个具有逻辑约束的机器人操作任务上的实验表明，ConceptACT比标准ACT收敛更快，样本效率更高。通过注意力机制进行架构集成的方法显著优于简单的辅助预测损失或语言条件模型。

Conclusion: 适当集成的语义监督为机器人学习提供了强大的归纳偏置，能够实现更高效的学习。概念感知的注意力机制是有效利用语义知识的关键，而无需在部署时增加额外负担。

Abstract: Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.

</details>


### [155] [Conservative & Aggressive NaNs Accelerate U-Nets for Neuroimaging](https://arxiv.org/abs/2601.17180)
*Inés Gonzalez-Pepe,Vinuyan Sivakolunthu,Jacob Fortin,Yohan Chatelain,Tristan Glatard*

Main category: cs.LG

TL;DR: 提出两种基于数值不确定性的CNN优化方法：Conservative & Aggressive NaNs，通过识别数值不稳定体素并替换为NaN，让后续层跳过对无关数据的计算，在神经影像等任务中实现平均1.67倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 神经影像深度学习模型规模日益增大，效率成为持续关注的问题。研究发现CNN中许多操作应用于数值噪声主导的值，对模型输出影响可忽略，某些模型中高达三分之二的卷积操作似乎是冗余的。

Method: 提出Conservative & Aggressive NaNs两种方法：新颖的最大池化和反池化变体，识别数值不稳定体素并用NaN替换，使后续层能够跳过对无关数据的计算。两种方法在PyTorch中实现，无需架构更改。

Result: 在包含至少50% NaN的输入中观察到一致的运行时改进；在超过三分之二NaN的数据中（常见于神经影像场景）实现平均1.67倍推理加速。Conservative NaNs平均减少30%卷积操作，无性能下降，特定层可跳过64.64%卷积；Aggressive NaNs可跳过69.30%卷积但可能偶尔影响性能。

Conclusion: 数值不确定性可被利用来减少CNN中的冗余计算并提高推理效率，两种方法为深度学习模型提供了有效的优化途径。

Abstract: Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative & Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.

</details>


### [156] [Federated Proximal Optimization for Privacy-Preserving Heart Disease Prediction: A Controlled Simulation Study on Non-IID Clinical Data](https://arxiv.org/abs/2601.17183)
*Farzam Asad,Junaid Saif Khan,Maria Tariq,Sundus Munir,Muhammad Adnan Khan*

Main category: cs.LG

TL;DR: 该研究通过模拟医院间的非独立同分布数据，验证了FedProx联邦学习方法在心脏病预测中的有效性，在保护隐私的同时实现了比集中式学习和孤立本地模型更好的准确率。


<details>
  <summary>Details</summary>
Motivation: 医疗数据因隐私法规（如HIPAA和GDPR）无法直接共享，但医院间的协作对改进诊断模型至关重要。联邦学习提供了一种无需集中原始数据的协作训练方式，但临床数据固有的非独立同分布特性（由人口差异、疾病流行度和机构实践差异引起）带来了挑战。

Method: 使用UCI心脏病数据集（克利夫兰诊所的303名患者数据），通过基于人口统计的分层方法模拟四个异质性医院客户端，生成现实的非独立同分布数据分区。采用联邦近端优化（FedProx）方法，通过近端正则化控制客户端漂移，并进行50次独立运行的广泛消融研究和统计验证。

Result: FedProx在近端参数mu=0.05时达到85.00%的准确率，优于集中式学习（83.33%）和孤立本地模型（平均78.45%）。研究证明近端正则化在异质环境中能有效抑制客户端漂移，同时保护患者隐私。

Conclusion: 这项概念验证研究为现实世界联邦医疗系统提供了算法见解和实际部署指南，结果可直接转移给医院IT管理员，用于实施隐私保护的协作学习。FedProx在处理医疗数据的非独立同分布特性方面表现出色，为医疗领域的联邦学习应用提供了实用解决方案。

Abstract: Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.

</details>


### [157] [Rethinking Benchmarks for Differentially Private Image Classification](https://arxiv.org/abs/2601.17189)
*Sabrina Mokhtari,Sara Kodeiri,Shubhankar Mohapatra,Florian Tramer,Gautam Kamath*

Main category: cs.LG

TL;DR: 该论文重新审视差分隐私图像分类的基准测试，提出了一套全面的基准集，用于评估不同设置下的差分隐私机器学习技术，并创建了公开的排行榜供社区跟踪进展。


<details>
  <summary>Details</summary>
Motivation: 当前差分隐私图像分类的基准测试不够全面，需要一套更完善的基准集来评估不同设置下的技术效果，促进该领域的研究进展。

Method: 提出一套全面的基准测试集，涵盖多种设置（有无额外数据、凸优化设置、不同数据集），并对现有技术在这些基准上进行测试，同时创建公开的排行榜。

Result: 建立了全面的差分隐私图像分类基准测试框架，测试了现有技术在不同设置下的有效性，并提供了公开的排行榜供社区使用。

Conclusion: 该研究为差分隐私机器学习提供了更全面的评估框架，有助于推动该领域的技术发展和进步跟踪。

Abstract: We revisit benchmarks for differentially private image classification. We suggest a comprehensive set of benchmarks, allowing researchers to evaluate techniques for differentially private machine learning in a variety of settings, including with and without additional data, in convex settings, and on a variety of qualitatively different datasets. We further test established techniques on these benchmarks in order to see which ideas remain effective in different settings. Finally, we create a publicly available leader board for the community to track progress in differentially private machine learning.

</details>


### [158] [Accelerated Sinkhorn Algorithms for Partial Optimal Transport](https://arxiv.org/abs/2601.17196)
*Nghia Thu Truong,Qui Phu Pham,Quang Nguyen,Dung Luong,Mai Tran*

Main category: cs.LG

TL;DR: ASPOT方法通过结合交替最小化和Nesterov加速，将部分最优传输的Sinkhorn算法复杂度从次优提升到O(n^{7/3}ε^{-5/3})，并通过智能选择熵参数进一步优化经典Sinkhorn方法。


<details>
  <summary>Details</summary>
Motivation: 部分最优传输(POT)处理两个分布间仅传输部分质量的问题，适用于边缘分布大小不等或包含异常值的情况。现有Sinkhorn方法的复杂度界限次优，限制了可扩展性。

Method: 提出加速Sinkhorn部分最优传输(ASPOT)方法，在POT设置中结合交替最小化和Nesterov风格加速。同时展示了通过智能选择熵参数γ可以改进经典Sinkhorn方法的收敛速率。

Result: ASPOT实现了O(n^{7/3}ε^{-5/3})的复杂度改进，优于现有方法。通过熵参数优化进一步提升了经典Sinkhorn方法的性能。真实世界应用实验验证了理论并展示了优越性能。

Conclusion: ASPOT方法显著提升了部分最优传输问题的计算效率，通过加速技术和参数优化解决了现有Sinkhorn方法的可扩展性限制，在真实应用中表现出优越性能。

Abstract: Partial Optimal Transport (POT) addresses the problem of transporting only a fraction of the total mass between two distributions, making it suitable when marginals have unequal size or contain outliers. While Sinkhorn-based methods are widely used, their complexity bounds for POT remain suboptimal and can limit scalability. We introduce Accelerated Sinkhorn for POT (ASPOT), which integrates alternating minimization with Nesterov-style acceleration in the POT setting, yielding a complexity of $\mathcal{O}(n^{7/3}\varepsilon^{-5/3})$. We also show that an informed choice of the entropic parameter $γ$ improves rates for the classical Sinkhorn method. Experiments on real-world applications validate our theories and demonstrate the favorable performance of our proposed methods.

</details>


### [159] [SpecBridge: Bridging Mass Spectrometry and Molecular Representations via Cross-Modal Alignment](https://arxiv.org/abs/2601.17204)
*Yinkai Wang,Yan Zhou Chen,Xiaohui Chen,Li-Ping Liu,Soha Hassoun*

Main category: cs.LG

TL;DR: SpecBridge提出了一种新的隐式对齐框架，将质谱结构识别视为几何对齐问题，通过微调自监督质谱编码器直接投影到冻结分子基础模型的潜在空间，显著提高了检索准确率。


<details>
  <summary>Details</summary>
Motivation: 小分子质谱鉴定在非靶向分析中存在瓶颈，现有深度学习方法要么是显式生成模型（原子级构建分子图），要么是从头学习跨模态子空间的联合对比模型，存在局限性。

Method: SpecBridge采用隐式对齐框架，微调自监督质谱编码器(DreaMS)直接投影到冻结分子基础模型(ChemBERTa)的潜在空间，然后通过余弦相似度在预计算的分子嵌入库中进行检索。

Result: 在MassSpecGym、Spectraverse和MSnLib基准测试中，SpecBridge相比强基线神经方法将top-1检索准确率提高了约20-25%，同时保持可训练参数数量较少。

Conclusion: 与冻结基础模型对齐是设计新架构的实用、稳定替代方案，SpecBridge代码已开源。

Abstract: Small-molecule identification from tandem mass spectrometry (MS/MS) remains a bottleneck in untargeted settings where spectral libraries are incomplete. While deep learning offers a solution, current approaches typically fall into two extremes: explicit generative models that construct molecular graphs atom-by-atom, or joint contrastive models that learn cross-modal subspaces from scratch. We introduce SpecBridge, a novel implicit alignment framework that treats structure identification as a geometric alignment problem. SpecBridge fine-tunes a self-supervised spectral encoder (DreaMS) to project directly into the latent space of a frozen molecular foundation model (ChemBERTa), and then performs retrieval by cosine similarity to a fixed bank of precomputed molecular embeddings. Across MassSpecGym, Spectraverse, and MSnLib benchmarks, SpecBridge improves top-1 retrieval accuracy by roughly 20-25% relative to strong neural baselines, while keeping the number of trainable parameters small. These results suggest that aligning to frozen foundation models is a practical, stable alternative to designing new architectures from scratch. The code for SpecBridge is released at https://github.com/HassounLab/SpecBridge.

</details>


### [160] [JetFormer: A Scalable and Efficient Transformer for Jet Tagging from Offline Analysis to FPGA Triggers](https://arxiv.org/abs/2601.17215)
*Ruoqing Zheng,Chang Sun,Qibin Liu,Lauri Laatu,Arianna Cox,Benedikt Maier,Alexander Tapper,Jose G. F. Coutinho,Wayne Luk,Zhiqiang Que*

Main category: cs.LG

TL;DR: JetFormer是一种用于大型强子对撞机粒子喷注标记的Transformer架构，能够在从离线分析到在线触发的全场景中高效运行，在保持高精度的同时显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常针对特定部署场景设计，缺乏一个能在高精度离线分析和超低延迟在线触发等全场景中都有效的统一架构，需要开发一个既高性能又可部署的通用解决方案。

Method: 采用仅编码器的Transformer架构处理变长粒子特征集，无需显式的成对相互作用输入。引入硬件感知优化流程，包括多目标超参数搜索、结构化剪枝和量化，生成适合FPGA部署的紧凑变体。

Result: 在JetClass数据集上，JetFormer在精度上与ParT模型相当（相差0.7%以内），但计算量减少37.4%。在HLS4ML 150P基准数据集上，比MLP、Deep Sets和Interaction Networks等模型精度高3-4%。通过压缩优化，JetFormer-tiny变体可满足FPGA触发系统的亚微秒延迟要求。

Conclusion: JetFormer通过统一的架构框架将高性能建模和可部署性结合起来，为大型强子对撞机的离线和在线环境提供了实用的Transformer基喷注标记器部署路径。

Abstract: We present JetFormer, a versatile and scalable encoder-only Transformer architecture for particle jet tagging at the Large Hadron Collider (LHC). Unlike prior approaches that are often tailored to specific deployment regimes, JetFormer is designed to operate effectively across the full spectrum of jet tagging scenarios, from high-accuracy offline analysis to ultra-low-latency online triggering. The model processes variable-length sets of particle features without relying on input of explicit pairwise interactions, yet achieves competitive or superior performance compared to state-of-the-art methods. On the large-scale JetClass dataset, a large-scale JetFormer matches the accuracy of the interaction-rich ParT model (within 0.7%) while using 37.4% fewer FLOPs, demonstrating its computational efficiency and strong generalization. On benchmark HLS4ML 150P datasets, JetFormer consistently outperforms existing models such as MLPs, Deep Sets, and Interaction Networks by 3-4% in accuracy. To bridge the gap to hardware deployment, we further introduce a hardware-aware optimization pipeline based on multi-objective hyperparameter search, yielding compact variants like JetFormer-tiny suitable for FPGA-based trigger systems with sub-microsecond latency requirements. Through structured pruning and quantization, we show that JetFormer can be aggressively compressed with minimal accuracy loss. By unifying high-performance modeling and deployability within a single architectural framework, JetFormer provides a practical pathway for deploying Transformer-based jet taggers in both offline and online environments at the LHC. Code is available at https://github.com/walkieq/JetFormer.

</details>


### [161] [PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems](https://arxiv.org/abs/2601.17495)
*Ruiyu Zhang,Lin Nie,Wai-Fung Lam,Qihao Wang,Xin Zhao*

Main category: cs.LG

TL;DR: PEARL是一种标签高效的嵌入对齐方法，通过原型增强表示学习来改善局部邻域结构，在标签稀缺条件下显著提升相似性检索性能。


<details>
  <summary>Details</summary>
Motivation: 现实部署系统中，固定预训练嵌入的局部邻域结构往往与下游任务不匹配，导致相似性检索失败。由于标签稀缺、领域漂移和重训练成本高，需要一种标签高效的嵌入对齐方法。

Method: PEARL（原型增强对齐表示学习）使用有限监督通过软对齐嵌入到类别原型来重塑局部邻域几何结构，保持维度不变，避免激进投影或坍缩。

Result: 在标签稀缺条件下，PEARL显著改善局部邻域质量，相比原始嵌入提升25.7%，相比强无监督后处理方法提升21.1%以上。

Conclusion: PEARL填补了无监督后处理（增益有限）和全监督投影（需要大量标签）之间的空白，在相似性系统最脆弱的标签稀缺场景中有效提升性能。

Abstract: In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.

</details>


### [162] [Parameter Inference and Uncertainty Quantification with Diffusion Models: Extending CDI to 2D Spatial Conditioning](https://arxiv.org/abs/2601.17224)
*Dmitrii Torbunov,Yihui Ren,Lijun Wu,Yimei Zhu*

Main category: cs.LG

TL;DR: 将条件扩散模型（CDI）从一维时间信号扩展到二维空间数据，用于材料表征中的电子衍射参数反演，能生成校准良好的后验分布，准确反映测量约束下的不确定性。


<details>
  <summary>Details</summary>
Motivation: 科学反问题中需要量化不确定性以区分可识别参数和模糊参数。虽然CDI在一维时间信号上已证明有效，但其在更高维空间数据上的适用性尚未探索。

Method: 将CDI扩展到二维空间条件化，使其能够直接从空间观测中进行概率参数推断。在会聚束电子衍射（CBED）参数推断问题上进行验证，这是一个材料表征中的多参数反问题。

Result: CDI产生了校准良好的后验分布：对于确定良好的参数有紧密分布，对于模糊参数有适当宽泛的分布。相比之下，标准回归方法虽然聚合指标看似准确，但通过预测训练集均值来掩盖不确定性。

Conclusion: CDI成功从时间域扩展到空间域，为稳健的科学推断提供了真实的不确定性信息。

Abstract: Uncertainty quantification is critical in scientific inverse problems to distinguish identifiable parameters from those that remain ambiguous given available measurements. The Conditional Diffusion Model-based Inverse Problem Solver (CDI) has previously demonstrated effective probabilistic inference for one-dimensional temporal signals, but its applicability to higher-dimensional spatial data remains unexplored. We extend CDI to two-dimensional spatial conditioning, enabling probabilistic parameter inference directly from spatial observations. We validate this extension on convergent beam electron diffraction (CBED) parameter inference - a challenging multi-parameter inverse problem in materials characterization where sample geometry, electronic structure, and thermal properties must be extracted from 2D diffraction patterns. Using simulated CBED data with ground-truth parameters, we demonstrate that CDI produces well-calibrated posterior distributions that accurately reflect measurement constraints: tight distributions for well-determined quantities and appropriately broad distributions for ambiguous parameters. In contrast, standard regression methods - while appearing accurate on aggregate metrics - mask this underlying uncertainty by predicting training set means for poorly constrained parameters. Our results confirm that CDI successfully extends from temporal to spatial domains, providing the genuine uncertainty information required for robust scientific inference.

</details>


### [163] [A Constrained Optimization Perspective of Unrolled Transformers](https://arxiv.org/abs/2601.17257)
*Javier Porras-Valenzuela,Samar Hadou,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 提出一种约束优化框架，使Transformer模型像优化下降算法一样工作，通过层间下降约束和原始-对偶训练方案，确保中间表示在期望上单调降低损失


<details>
  <summary>Details</summary>
Motivation: 传统Transformer训练使用经验风险最小化（ERM），缺乏对模型内部行为的约束控制。作者希望使Transformer具有类似优化下降算法的行为特性，从而提升模型的鲁棒性和泛化能力

Method: 1. 在层间施加目标函数下降约束；2. 用原始-对偶训练方案替代标准ERM；3. 确保中间表示在期望上单调降低损失；4. 应用于展开式Transformer架构和预训练Transformer

Result: 在视频去噪和文本分类任务上，约束Transformer表现出更强的扰动鲁棒性、更高的分布外泛化能力，同时保持分布内性能

Conclusion: 通过约束优化框架训练Transformer使其具有优化下降算法行为，能有效提升模型鲁棒性和泛化能力，为Transformer设计提供了新思路

Abstract: We introduce a constrained optimization framework for training transformers that behave like optimization descent algorithms. Specifically, we enforce layerwise descent constraints on the objective function and replace standard empirical risk minimization (ERM) with a primal-dual training scheme. This approach yields models whose intermediate representations decrease the loss monotonically in expectation across layers. We apply our method to both unrolled transformer architectures and conventional pretrained transformers on tasks of video denoising and text classification. Across these settings, we observe constrained transformers achieve stronger robustness to perturbations and maintain higher out-of-distribution generalization, while preserving in-distribution performance.

</details>


### [164] [The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment](https://arxiv.org/abs/2601.17260)
*Marco Pollanen*

Main category: cs.LG

TL;DR: DPO中的β参数不是简单的对齐压力控制，而是复杂的控制参数，不同架构模型在不同β值下表现出截然不同的能力变化模式，偏好边界可能与推理能力负相关。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为DPO中的β参数（对齐压力）越大，模型行为越好，但本文质疑这一假设，认为β应被视为控制参数，需要系统研究不同β值对模型能力的影响。

Method: 对三个7B开源模型家族（Mistral、Llama、Qwen）在固定DPO配方下密集扫描β参数，使用逻辑探针评估推理能力，分析能力变化模式、偏好边界与能力的关系，以及训练路径的滞后效应。

Result: 1. Mistral能力呈尖锐非单调变化，仅在β≈10⁻²窄带内逻辑探针边界为正；2. 不同架构响应模式不同：Mistral急剧重组，Llama选择性变化，Qwen平滑权衡；3. DPO偏好边界与推理能力可能负相关（Llama逻辑任务Pearson r=-0.91）；4. 高β训练会导致能力损失，即使降低β也无法恢复（滞后效应）。

Conclusion: 不应依赖偏好边界或聚合基准来选择模型，而应在β参数空间中全面评估模型能力，不同架构对DPO训练响应模式差异显著，需要更精细的能力解析评估方法。

Abstract: Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $β$) yields progressively "better" behavior. We instead treat $β$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $β\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $β$ induces capability losses that persist even after $β$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $β$ landscape rather than reliance on margins or aggregate benchmarks.

</details>


### [165] [AGZO: Activation-Guided Zeroth-Order Optimization for LLM Fine-Tuning](https://arxiv.org/abs/2601.17261)
*Wei Lin,Yining Jiang,Qingyu Song,Qiao Xiang,Hong Xu*

Main category: cs.LG

TL;DR: AGZO是一种基于激活引导的零阶优化方法，通过利用前向传播中的激活结构信息，在低秩子空间中进行扰动，显著提升了零阶优化的性能，同时保持了内存效率。


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化方法通常使用各向同性扰动，忽略了前向传播中可用的丰富结构信息。作者发现线性层的梯度被限制在其输入激活张成的子空间中，这为改进零阶优化提供了关键洞察。

Method: 提出激活引导的零阶优化（AGZO），在前向传播过程中动态提取紧凑的激活信息子空间，并将扰动限制在这个低秩子空间中，从而更有效地估计梯度方向。

Result: AGZO在Qwen3和Pangu模型上的实验表明，它持续优于最先进的零阶基线方法，显著缩小了与一阶微调的性能差距，同时保持了与其他零阶方法几乎相同的峰值内存占用。

Conclusion: AGZO通过利用激活结构信息改进了零阶优化，在内存受限的LLM微调场景中提供了接近一阶方法性能的高效解决方案，为大规模模型的内存高效微调开辟了新途径。

Abstract: Zeroth-Order (ZO) optimization has emerged as a promising solution for fine-tuning LLMs under strict memory constraints, as it avoids the prohibitive memory cost of storing activations for backpropagation. However, existing ZO methods typically employ isotropic perturbations, neglecting the rich structural information available during the forward pass. In this paper, we identify a crucial link between gradient formation and activation structure: the gradient of a linear layer is confined to the subspace spanned by its input activations. Leveraging this insight, we propose Activation-Guided Zeroth-Order optimization (AGZO). Unlike prior methods, AGZO extracts a compact, activation-informed subspace on the fly during the forward pass and restricts perturbations to this low-rank subspace. We provide a theoretical framework showing that AGZO optimizes a subspace-smoothed objective and provably yields update directions with higher cosine similarity to the true gradient than isotropic baselines. Empirically, we evaluate AGZO on Qwen3 and Pangu models across various benchmarks. AGZO consistently outperforms state-of-the-art ZO baselines and significantly narrows the performance gap with first-order fine-tuning, while maintaining almost the same peak memory footprint as other ZO methods.

</details>


### [166] [Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning](https://arxiv.org/abs/2601.17275)
*Lianlei Shan,Han Chen,Yixuan Wang,Zhenjie Liu,Wei Li*

Main category: cs.LG

TL;DR: DLR是一个潜在空间双向对比强化学习框架，将推理成本从昂贵的token级序列生成转移到连续潜在流形，通过冻结主模型参数避免灾难性遗忘，实现更稳定的训练收敛和更长推理链支持。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂多步推理任务时往往只是"统计拟合"而非系统逻辑推理。传统强化学习虽然引入"先思考后说话"范式，但在高维离散token空间中面临样本效率低、梯度估计方差高和灾难性遗忘风险三大挑战。

Method: 提出DeepLatent Reasoning (DLR)框架：1) 使用轻量级辅助模型在潜在空间中采样K个推理链编码；2) 通过基于正确性和格式的双重奖励机制筛选高价值潜在轨迹；3) 仅将筛选后的轨迹输入冻结主模型进行单次解码；4) 设计对比学习目标在潜在空间中进行定向探索。

Result: 在可比较的GPU计算预算下，DLR实现了更稳定的训练收敛，支持更长的推理链，促进了推理能力的可持续积累，为LLMs提供了可靠且可扩展的强化学习路径。

Conclusion: DLR通过将强化学习从离散token空间转移到连续潜在空间，有效解决了传统RL在LLMs中的三大瓶颈问题，为复杂推理任务提供了更高效、稳定的训练框架，同时避免了灾难性遗忘问题。

Abstract: While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.

</details>


### [167] [Tabular Foundation Models are Strong Graph Anomaly Detectors](https://arxiv.org/abs/2601.17301)
*Yunhui Liu,Tieke He,Yongchao Liu,Can Yi,Hong Jin,Chuntao Hong*

Main category: cs.LG

TL;DR: TFM4GAD框架将表格基础模型应用于图异常检测，通过图结构扁平化和特征增强，实现了跨领域通用异常检测，性能优于专用GAD模型。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法存在"一个模型对应一个数据集"的问题，导致计算成本高、数据需求大、泛化能力差。需要一种能够跨不同图数据集进行异常检测的通用基础模型。

Method: 提出TFM4GAD框架，将表格基础模型应用于图异常检测。通过"扁平化"图结构，构建增强特征表，包含原始节点特征、拉普拉斯嵌入、局部和全局结构特征以及异常敏感邻域聚合。使用表格基础模型在完全上下文学习机制下处理增强特征表。

Result: 在多个数据集和不同表格基础模型骨干上的实验表明，TFM4GAD显著优于从头训练的专业GAD模型，实现了性能提升。

Conclusion: TFM4GAD为利用表格基础模型作为强大的通用图异常检测器提供了新视角和实践范式，解决了跨领域图异常检测的泛化问题。

Abstract: Graph anomaly detection (GAD), which aims to identify abnormal nodes that deviate from the majority, has become increasingly important in high-stakes Web domains. However, existing GAD methods follow a "one model per dataset" paradigm, leading to high computational costs, substantial data demands, and poor generalization when transferred to new datasets. This calls for a foundation model that enables a "one-for-all" GAD solution capable of detecting anomalies across diverse graphs without retraining. Yet, achieving this is challenging due to the large structural and feature heterogeneity across domains. In this paper, we propose TFM4GAD, a simple yet effective framework that adapts tabular foundation models (TFMs) for graph anomaly detection. Our key insight is that the core challenges of foundation GAD, handling heterogeneous features, generalizing across domains, and operating with scarce labels, are the exact problems that modern TFMs are designed to solve via synthetic pre-training and powerful in-context learning. The primary challenge thus becomes structural: TFMs are agnostic to graph topology. TFM4GAD bridges this gap by "flattening" the graph, constructing an augmented feature table that enriches raw node features with Laplacian embeddings, local and global structural characteristics, and anomaly-sensitive neighborhood aggregations. This augmented table is processed by a TFM in a fully in-context regime. Extensive experiments on multiple datasets with various TFM backbones reveal that TFM4GAD surprisingly achieves significant performance gains over specialized GAD models trained from scratch. Our work offers a new perspective and a practical paradigm for leveraging TFMs as powerful, generalist graph anomaly detectors.

</details>


### [168] [PAR: Plausibility-aware Amortized Recourse Generation](https://arxiv.org/abs/2601.17309)
*Anagha Sabu,Vidhya S,Narayanan C Krishnan*

Main category: cs.LG

TL;DR: PAR是一种基于摊销近似推理的算法追索方法，通过约束最大后验概率推断生成高似然、现实可行的反事实建议，在保持有效性和稀疏性的同时提高生成效率。


<details>
  <summary>Details</summary>
Motivation: 现有算法追索方法在生成现实可行且高似然的反事实建议方面存在效率和质量问题，需要一种能够同时满足有效性、相似性、稀疏性和高似然性要求的高效追索生成方法。

Method: 将追索问题形式化为约束最大后验概率推断问题，在可接受类数据分布下寻找高似然反事实。提出PAR摊销近似推理程序，使用可处理概率模型直接估计追索似然，支持精确似然评估和高效梯度传播。训练追索生成器以最大化可接受类分布下的似然，最小化拒绝类分布下的似然，并编码其他追索约束损失。引入基于邻域的调节机制以生成针对具体事实定制的追索建议。

Result: 在广泛使用的算法追索数据集上验证PAR，证明其能高效生成有效、与事实相似、稀疏且高度合理的追索建议，性能优于现有最先进方法。

Conclusion: PAR通过摊销近似推理框架成功解决了算法追索中的效率和质量问题，能够生成高质量、高似然的反事实建议，为算法追索提供了一种有效的解决方案。

Abstract: Algorithmic recourse aims to recommend actionable changes to a factual's attributes that flip an unfavorable model decision while remaining realistic and feasible. We formulate recourse as a Constrained Maximum A-Posteriori (MAP) inference problem under the accepted-class data distribution seeking counterfactuals with high likelihood while respecting other recourse constraints. We present PAR, an amortized approximate inference procedure that generates highly likely recourses efficiently. Recourse likelihood is estimated directly using tractable probabilistic models that admit exact likelihood evaluation and efficient gradient propagation that is useful during training. The recourse generator is trained with the objective of maximizing the likelihood under the accepted-class distribution while minimizing the likelihood under the denied-class distribution and other losses that encode recourse constraints. Furthermore, PAR includes a neighborhood-based conditioning mechanism to promote recourse generation that is customized to a factual. We validate PAR on widely used algorithmic recourse datasets and demonstrate its efficiency in generating recourses that are valid, similar to the factual, sparse, and highly plausible, yielding superior performance over existing state-of-the-art approaches.

</details>


### [169] [Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment](https://arxiv.org/abs/2601.17329)
*Tiejin Chen,Xiaoou Liu,Vishnu Nandam,Kuan-Ru Liou,Hua Wei*

Main category: cs.LG

TL;DR: 提出Conformal Feedback Alignment (CFA)框架，利用Conformal Prediction的统计保证来量化答案可靠性，为DPO和PPO训练提供原则性权重，提升对齐的鲁棒性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的对齐方法（如RLHF）面临标签噪声和不一致问题。现有不确定性感知方法仅对偏好进行加权，但忽略了更基本的因素：被比较答案的可靠性。

Method: 提出Conformal Feedback Alignment (CFA)框架，通过构建具有可控覆盖率的conformal prediction sets来量化答案级可靠性，并将这些可靠性聚合成原则性权重，应用于DPO和PPO风格的训练。

Result: 在不同数据集上的实验表明，CFA提高了对齐的鲁棒性和数据效率，证明建模答案侧不确定性可以补充偏好级加权，实现更鲁棒、数据效率更高的对齐。

Conclusion: CFA框架通过量化答案可靠性并提供统计保证，有效解决了偏好对齐中的噪声问题，为更鲁棒、数据效率更高的对齐方法提供了新思路。

Abstract: Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.

</details>


### [170] [Thermodynamically Optimal Regularization under Information-Geometric Constraints](https://arxiv.org/abs/2601.17330)
*Laurent Caraffa*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的理论框架，将热力学最优性、信息几何和正则化联系起来，证明了在特定假设下，Fisher-Rao度量是信念空间上唯一可接受的几何结构，热力学最优正则化对应于最小化到参考状态的Fisher-Rao距离平方。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习依赖于一系列经验成功但理论异质的正则化技术（如权重衰减、dropout、指数移动平均），同时训练大型模型的能量成本急剧增加，这引发了对学习算法是否接近任何基本效率界限的疑问。

Method: 提出了一个统一的理论框架，基于三个明确假设：(A1)最优性需要内在的、参数化不变的信息度量；(A2)信念状态由已知约束下的最大熵分布建模；(A3)最优过程是准静态的。在此框架下证明了条件最优性定理，推导了高斯和圆形信念模型的诱导几何结构。

Result: 证明了Fisher-Rao度量是信念空间上唯一可接受的几何结构，热力学最优正则化对应于最小化到参考状态的Fisher-Rao距离平方。推导出高斯模型对应双曲流形，圆形模型对应von Mises流形，并表明经典正则化方案在结构上无法保证热力学最优性。

Conclusion: 该工作为机器学习中的正则化提供了原则性的几何和热力学基础，引入了学习的热力学效率概念，并提出了可实验验证的预测，为理解正则化技术提供了统一的理论框架。

Abstract: Modern machine learning relies on a collection of empirically successful but theoretically heterogeneous regularization techniques, such as weight decay, dropout, and exponential moving averages. At the same time, the rapidly increasing energetic cost of training large models raises the question of whether learning algorithms approach any fundamental efficiency bound. In this work, we propose a unifying theoretical framework connecting thermodynamic optimality, information geometry, and regularization.
  Under three explicit assumptions -- (A1) that optimality requires an intrinsic, parametrization-invariant measure of information, (A2) that belief states are modeled by maximum-entropy distributions under known constraints, and (A3) that optimal processes are quasi-static -- we prove a conditional optimality theorem. Specifically, the Fisher--Rao metric is the unique admissible geometry on belief space, and thermodynamically optimal regularization corresponds to minimizing squared Fisher--Rao distance to a reference state.
  We derive the induced geometries for Gaussian and circular belief models, yielding hyperbolic and von Mises manifolds, respectively, and show that classical regularization schemes are structurally incapable of guaranteeing thermodynamic optimality. We introduce a notion of thermodynamic efficiency of learning and propose experimentally testable predictions. This work provides a principled geometric and thermodynamic foundation for regularization in machine learning.

</details>


### [171] [Power-based Partial Attention: Bridging Linear-Complexity and Full Attention](https://arxiv.org/abs/2601.17334)
*Yufeng Huang*

Main category: cs.LG

TL;DR: 论文提出了一种幂基部分注意力机制（PPA），其复杂度为O(L^{1+p})，其中0≤p≤1，可以系统探索注意力机制复杂度与性能的关系，发现存在0<p<1使得次二次复杂度注意力能达到与全注意力相当的效果。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer研究普遍认为"注意力就是一切"，但从未系统量化过到底需要多少注意力。需要探索二次复杂度O(L^2)的全注意力是否必要，是否存在次二次复杂度的注意力机制能达到可比性能。

Method: 提出了幂基部分注意力机制（PPA），其复杂度为O(L^{1+p})，其中0≤p≤1。当p=0时对应滑动窗口注意力（线性复杂度），p=1时对应全注意力。通过这一构造可以系统研究注意力缩放行为（由p控制）对Transformer架构性能的影响。

Result: 实验显示整体趋势呈现S曲线行为：性能从滑动窗口（线性复杂度）注意力过渡到全注意力，在p值的狭窄窗口内完成转变，并在p接近1时趋于平稳。实验证明存在0<p<1使得O(L^{1+p})注意力足以达到与O(L^2)全注意力相似的结果。

Conclusion: 次二次复杂度的注意力机制可以替代全注意力，达到可比性能。这为设计更高效的Transformer架构提供了理论基础，表明不需要总是使用二次复杂度的全注意力。

Abstract: It is widely accepted from transformer research that "attention is all we need", but the amount of attention required has never been systematically quantified. Is quadratic $O(L^2)$ attention necessary, or is there a sub-quadratic attention mechanism that can achieve comparable performance? To answer this question, we introduce power-based partial attention (PPA), an attention mechanism of order $O(L^{1+p})$, where $0 \leq p \leq 1$, such that $p=0$ corresponds to sliding window attention with linear complexity, and $p=1$ corresponds to full attention. With this attention construction, we can explore how transformer architecture performance varies as a function of the attention scaling behavior controlled by $p$. The overall trend from our experiments shows an S-curve-like behavior where the performance transitions from sliding-window (linear-complexity) attention to full attention over a narrow window of $p$ values, and plateaus as $p$ approaches $1$. In our experiments, we show that there exists $0<p<1$ such that $O(L^{1+p})$ attention is sufficient to achieve similar results as $O(L^2)$ full attention.

</details>


### [172] [Robust Privacy: Inference-Time Privacy through Certified Robustness](https://arxiv.org/abs/2601.17360)
*Jiankai Jin,Xiangzheng Zhang,Zhao Liu,Deyue Zhang,Quanchen Zou*

Main category: cs.LG

TL;DR: 论文提出鲁棒隐私(RP)概念，通过确保模型预测在输入邻域内不变来提供推理时隐私保护，并开发属性隐私增强(APE)技术将输入级不变性转化为属性级隐私效果，有效缓解模型反演攻击。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统在推理时可能泄露敏感输入属性，现有隐私保护方法在推理时保护不足，需要一种新的推理时隐私概念来防止通过模型输出推断敏感信息。

Method: 提出鲁棒隐私(RP)概念，要求模型预测在输入邻域内具有不变性；开发属性隐私增强(APE)技术将输入级不变性转化为属性级隐私保护；在推荐任务中验证RP能扩大敏感属性值的兼容范围。

Result: RP能有效缓解模型反演攻击：在低噪声水平(σ=0.1)下，攻击成功率从73%降至4%；即使不降低模型性能，攻击成功率也能从73%降至44%；同时保持部分模型性能。

Conclusion: 鲁棒隐私(RP)是一种有效的推理时隐私保护框架，通过确保模型预测在输入邻域内不变来防止敏感信息泄露，既能保护隐私又能保持模型实用性，为机器学习系统隐私保护提供了新思路。

Abstract: Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($σ=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.

</details>


### [173] [Diversified Scaling Inference in Time Series Foundation Models](https://arxiv.org/abs/2601.17376)
*Ruijin Hua,Zichuan Liu,Kun Zhang,Yiyuan Yang*

Main category: cs.LG

TL;DR: 该论文系统研究了时间序列基础模型在推理时的计算潜力，发现标准采样方法未能充分利用解空间，而通过定制化时间序列扰动实现多样化推理扩展可以显著提升性能，无需参数更新。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型的发展主要依赖大规模预训练，但推理时的计算潜力尚未被充分挖掘。研究者希望探索两个关键问题：TSFMs在标准采样推理扩展下的表现如何，以及受控的采样多样性是否能增强性能。

Method: 首先分析TSFMs在标准采样下的特性，发现其未能遵循扩展定律；然后通过定制化时间序列扰动实现多样化推理扩展，扩大生成分布的支撑集；理论上分析多样性-保真度权衡，推导多样化采样优于标准采样的临界样本阈值；最后提出RobustMSE指标来量化固定预算下TSFM的性能上限。

Result: 跨多种TSFMs和数据集的广泛实验表明，适当的多样化推理扩展能带来显著的性能提升，且无需参数更新。多样化采样在超过临界阈值后能持续优于标准采样，证明了推理设计作为TSFM优化的关键计算高效维度的重要性。

Conclusion: 该研究阐明了时间序列基础模型中推理扩展、采样多样性和性能之间的相互作用，使得无需重新训练TSFMs即可通过多样化大规模推理时间序列在并行环境中实现可靠性能。推理设计成为TSFM优化中一个关键且计算高效的维度。

Abstract: The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.

</details>


### [174] [GO-OSC and VASH: Geometry-Aware Representation Learning for Early Degradation Detection in Oscillatory Systems](https://arxiv.org/abs/2601.17396)
*Vashista Nobaub*

Main category: cs.LG

TL;DR: GO-OSC：一种几何感知的振荡时间序列表示学习框架，通过强制规范可识别潜在参数化，实现对早期退化（如相位抖动、频率漂移）的稳定检测，相比传统能量基方法具有更高灵敏度。


<details>
  <summary>Details</summary>
Motivation: 振荡系统早期退化常表现为几何失真（如相位抖动、频率漂移），在信号能量变化可检测之前就已出现。传统能量基诊断和无约束学习表示对此结构不敏感，导致检测延迟或不稳定。

Method: 引入GO-OSC框架：1）强制规范可识别潜在参数化，实现跨短时无标签窗口的稳定比较和聚合；2）定义不变线性几何探针，针对潜在空间中退化相关方向；3）提供理论分析证明几何探针在早期相位退化下的检测优势。

Result: 理论证明：在早期仅相位退化下，能量基统计量的检测能力为零，而几何探针具有严格正灵敏度。实验验证：在合成基准和真实振动数据集上实现更早检测、更高数据效率和操作条件变化的鲁棒性。

Conclusion: 通过几何感知表示学习和规范参数化，GO-OSC框架解决了振荡系统早期退化检测的关键挑战，相比传统方法在灵敏度、效率和鲁棒性方面均有显著提升。

Abstract: Early-stage degradation in oscillatory systems often manifests as geometric distortions of the dynamics, such as phase jitter, frequency drift, or loss of coherence, long before changes in signal energy are detectable. In this regime, classical energy-based diagnostics and unconstrained learned representations are structurally insensitive, leading to delayed or unstable detection. We introduce GO-OSC, a geometry-aware representation learning framework for oscillatory time series that enforces a canonical and identifiable latent parameterization, enabling stable comparison and aggregation across short, unlabeled windows. Building on this representation, we define a family of invariant linear geometric probes that target degradation-relevant directions in latent space. We provide theoretical results showing that under early phase-only degradation, energy-based statistics have zero first-order detection power, whereas geometric probes achieve strictly positive sensitivity. Our analysis characterizes when and why linear probing fails under non-identifiable representations and shows how canonicalization restores statistical detectability. Experiments on synthetic benchmarks and real vibration datasets validate the theory, demonstrating earlier detection, improved data efficiency, and robustness to operating condition changes.

</details>


### [175] [Efficient Dilated Squeeze and Excitation Neural Operator for Differential Equations](https://arxiv.org/abs/2601.17407)
*Prajwal Chauhan,Salah Eddine Choutri,Saif Eddin Jabari*

Main category: cs.LG

TL;DR: D-SENO是一种轻量级神经算子框架，通过结合扩张卷积和挤压-激励模块，在保持精度的同时大幅提升PDE求解效率，训练速度比传统方法快约20倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的模型和神经算子参数量大，导致训练成本高、部署缓慢，需要开发更高效的PDE求解器。

Method: 提出D-SENO框架，结合扩张卷积块（捕捉宽感受野和物理依赖）和挤压-激励模块（通道注意力机制，自适应重新校准特征通道）。

Result: 在多种PDE基准测试中（翼型势流、多孔介质达西流、管道泊肃叶流、不可压缩Navier-Stokes涡流场），训练速度比标准Transformer模型和神经算子快约20倍，同时精度相当或更高。

Conclusion: D-SENO是一种高效准确的轻量级神经算子，能够快速求解多种PDE问题，消融研究表明SE模块对性能有重要贡献。

Abstract: Fast and accurate surrogates for physics-driven partial differential equations (PDEs) are essential in fields such as aerodynamics, porous media design, and flow control. However, many transformer-based models and existing neural operators remain parameter-heavy, resulting in costly training and sluggish deployment. We propose D-SENO (Dilated Squeeze-Excitation Neural Operator), a lightweight operator learning framework for efficiently solving a wide range of PDEs, including airfoil potential flow, Darcy flow in porous media, pipe Poiseuille flow, and incompressible Navier Stokes vortical fields. D-SENO combines dilated convolution (DC) blocks with squeeze-and-excitation (SE) modules to jointly capture wide receptive fields and dynamics alongside channel-wise attention, enabling both accurate and efficient PDE inference. Carefully chosen dilation rates allow the receptive field to focus on critical regions, effectively modeling long-range physical dependencies. Meanwhile, the SE modules adaptively recalibrate feature channels to emphasize dynamically relevant scales. Our model achieves training speed of up to approximately $20\times$ faster than standard transformer-based models and neural operators, while also surpassing (or matching) them in accuracy across multiple PDE benchmarks. Ablation studies show that removing the SE modules leads to a slight drop in performance.

</details>


### [176] [Data-driven Clustering and Merging of Adapters for On-device Large Language Models](https://arxiv.org/abs/2601.17441)
*Ondrej Bohdal,Taha Ceritli,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli*

Main category: cs.LG

TL;DR: 提出D2C方法，通过少量任务示例对适配器进行聚类，合并同簇适配器创建多任务适配器，提升资源受限设备上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 移动设备存储容量有限，无法存储所有任务适配器，需要选择具有良好泛化能力的代表性适配器，但现有文献尚未探索这一问题。

Method: 提出D2C适配器聚类方法，利用少量任务特定示例（如每个任务10个），通过迭代优化过程精炼聚类分配，合并每个簇内的适配器创建多任务适配器。

Result: 实验结果表明，该方法在考虑存储预算的情况下有效提升了性能表现。

Conclusion: D2C方法通过适配器聚类和合并，为资源受限设备提供了有效的多任务适配器部署方案。

Abstract: On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.

</details>


### [177] [Harnessing Reasoning Trajectories for Hallucination Detection via Answer-agreement Representation Shaping](https://arxiv.org/abs/2601.17467)
*Jianxiong Zhang,Bing Guo,Yuming Jiang,Haobo Wang,Bo An,Xuefeng Du*

Main category: cs.LG

TL;DR: ARS通过扰动推理轨迹边界嵌入生成反事实答案，学习基于答案一致性的检测友好表示，无需人工标注即可提升幻觉检测效果


<details>
  <summary>Details</summary>
Motivation: 大型推理模型常生成看似连贯但答案错误的推理轨迹，现有基于轨迹文本或隐藏状态的检测方法脆弱，容易过拟合表面模式而非答案有效性

Method: 提出答案一致性表示塑形(ARS)：通过小规模潜在干预（扰动轨迹边界嵌入）生成反事实答案，根据答案一致性标注扰动，学习将答案一致的表示聚集、不一致的分离，暴露幻觉风险

Result: ARS持续改进检测效果，相比强基线获得显著提升，学习到的表示可与现有基于嵌入的检测器即插即用，训练过程无需人工标注

Conclusion: ARS通过编码答案稳定性学习检测友好的表示，有效暴露推理模型中的潜在不稳定性，为幻觉检测提供了无需人工标注的有效方法

Abstract: Large reasoning models (LRMs) often generate long, seemingly coherent reasoning traces yet still produce incorrect answers, making hallucination detection challenging. Although trajectories contain useful signals, directly using trace text or vanilla hidden states for detection is brittle: traces vary in form and detectors can overfit to superficial patterns rather than answer validity. We introduce Answer-agreement Representation Shaping (ARS), which learns detection-friendly trace-conditioned representations by explicitly encoding answer stability. ARS generates counterfactual answers through small latent interventions, specifically, perturbing the trace-boundary embedding, and labels each perturbation by whether the resulting answer agrees with the original. It then learns representations that bring answer-agreeing states together and separate answer-disagreeing ones, exposing latent instability indicative of hallucination risk. The shaped embeddings are plug-and-play with existing embedding-based detectors and require no human annotations during training. Experiments demonstrate that ARS consistently improves detection and achieves substantial gains over strong baselines.

</details>


### [178] [LeanTutor: Towards a Verified AI Mathematical Proof Tutor](https://arxiv.org/abs/2601.17473)
*Manooshree Patel,Rayna Bhattacharyya,Thomas Lu,Arnav Mehta,Niels Voss,Narges Norouzi,Gireeja Ranade*

Main category: cs.LG

TL;DR: 开发了一个结合LLM和定理证明器的数学证明辅导系统LeanTutor，通过三个模块实现自然语言交互与形式化验证的结合，并使用PeanoBench数据集进行评估。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然支持自然语言交流但容易出错，而定理证明器如Lean能确保证明正确性但学习门槛高。需要结合两者优势，开发一个既易于学生使用又能保证正确性的数学证明辅导系统。

Method: 提出LeanTutor系统，包含三个核心模块：1) 自动形式化/证明检查器；2) 下一步生成器；3) 自然语言反馈生成器。系统结合LLM的自然语言处理能力和定理证明器的形式化验证能力。

Result: 开发了概念验证系统LeanTutor，并创建了PeanoBench数据集，包含371个皮亚诺算术证明，涵盖自然语言和形式化语言版本，源自Natural Numbers Game。

Conclusion: 通过结合LLM和定理证明器的互补优势，成功开发了一个既能保证证明正确性又易于学生使用的数学证明辅导系统，为AI辅助数学教育提供了新的解决方案。

Abstract: This paper considers the development of an AI-based provably-correct mathematical proof tutor. While Large Language Models (LLMs) allow seamless communication in natural language, they are error prone. Theorem provers such as Lean allow for provable-correctness, but these are hard for students to learn. We present a proof-of-concept system (LeanTutor) by combining the complementary strengths of LLMs and theorem provers. LeanTutor is composed of three modules: (i) an autoformalizer/proof-checker, (ii) a next-step generator, and (iii) a natural language feedback generator. To evaluate the system, we introduce PeanoBench, a dataset of 371 Peano Arithmetic proofs in human-written natural language and formal language, derived from the Natural Numbers Game.

</details>


### [179] [Unintended Memorization of Sensitive Information in Fine-Tuned Language Models](https://arxiv.org/abs/2601.17480)
*Marton Szep,Jorge Marin Ruiz,Georgios Kaissis,Paulina Seidl,Rüdiger von Eisenhart-Rothe,Florian Hinterwimmer,Daniel Rueckert*

Main category: cs.LG

TL;DR: 该研究系统分析了大型语言模型微调过程中仅出现在输入而非训练目标中的个人身份信息泄露风险，通过实验量化了PII记忆化行为，并评估了四种隐私保护方法的隐私-性能权衡。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型在敏感数据集上存在意外记忆化和泄露个人身份信息的重大风险，这可能违反隐私法规并危害个人安全。当前研究对仅出现在模型输入中而非训练目标中的PII暴露这一关键且未被充分探索的漏洞缺乏系统研究。

Method: 使用合成和真实世界数据集设计受控提取探针来量化意外PII记忆化，研究语言、PII频率、任务类型和模型规模等因素对记忆化行为的影响。进一步对四种隐私保护方法（差分隐私、机器遗忘、正则化和偏好对齐）进行基准测试，评估其隐私与任务性能之间的权衡。

Result: 研究结果显示，后训练方法通常提供更一致的隐私-效用权衡，而差分隐私在特定设置中能显著减少泄露，尽管可能引入训练不稳定性。不同因素（如语言、PII频率等）对记忆化行为有显著影响。

Conclusion: 这些发现突显了微调LLM中记忆化问题的持久挑战，强调了需要开发强大、可扩展的隐私保护技术来平衡模型性能与隐私保护需求。

Abstract: Fine-tuning Large Language Models (LLMs) on sensitive datasets carries a substantial risk of unintended memorization and leakage of Personally Identifiable Information (PII), which can violate privacy regulations and compromise individual safety. In this work, we systematically investigate a critical and underexplored vulnerability: the exposure of PII that appears only in model inputs, not in training targets. Using both synthetic and real-world datasets, we design controlled extraction probes to quantify unintended PII memorization and study how factors such as language, PII frequency, task type, and model size influence memorization behavior. We further benchmark four privacy-preserving approaches including differential privacy, machine unlearning, regularization, and preference alignment, evaluating their trade-offs between privacy and task performance. Our results show that post-training methods generally provide more consistent privacy-utility trade-offs, while differential privacy achieves strong reduction in leakage in specific settings, although it can introduce training instability. These findings highlight the persistent challenge of memorization in fine-tuned LLMs and emphasize the need for robust, scalable privacy-preserving techniques.

</details>


### [180] [SpatialMath: Spatial Comprehension-Infused Symbolic Reasoning for Mathematical Problem-Solving](https://arxiv.org/abs/2601.17489)
*Ashutosh Bajpai,Akshat Bhandari,Akshay Nambi,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: 提出SpatialMath框架，通过空间理解增强的符号推理链，提升多模态语言模型在视觉密集型数学问题（特别是几何问题）上的表现，在MATHVERSE-PLUS数据集上相比基线提升10个百分点。


<details>
  <summary>Details</summary>
Motivation: 当前多模态中小型语言模型在视觉理解和数学推理方面存在局限，特别是在几何问题上，难以准确分解复杂视觉输入并将感知与结构化推理连接，导致性能不佳。

Method: 提出SpatialMath框架，包含专门感知模块提取视觉图表中的空间基础表示，捕获关键几何结构和空间关系，然后将这些表示系统性地注入符号推理链中，实现视觉理解感知的结构化推理。

Result: SpatialMath显著优于强大多模态基线，在视觉密集型设置下相比监督微调加数据增强提升达10个百分点。鲁棒性分析显示增强的空间表示直接提升推理准确性。

Conclusion: 增强的空间表示能直接提升推理准确性，强化了在多模态语言模型中构建结构化感知到推理管道的必要性。

Abstract: Multimodal Small-to-Medium sized Language Models (MSLMs) have demonstrated strong capabilities in integrating visual and textual information but still face significant limitations in visual comprehension and mathematical reasoning, particularly in geometric problems with diverse levels of visual infusion. Current models struggle to accurately decompose intricate visual inputs and connect perception with structured reasoning, leading to suboptimal performance. To address these challenges, we propose SpatialMath, a novel Spatial Comprehension-Infused Symbolic Reasoning Framework designed to integrate spatial representations into structured symbolic reasoning chains. SpatialMath employs a specialized perception module to extract spatially-grounded representations from visual diagrams, capturing critical geometric structures and spatial relationships. These representations are then methodically infused into symbolic reasoning chains, facilitating visual comprehension-aware structured reasoning. To this end, we introduce MATHVERSE-PLUS, a novel dataset containing structured visual interpretations and step-by-step reasoning paths for vision-intensive mathematical problems. SpatialMath significantly outperforms strong multimodal baselines, achieving up to 10 percentage points improvement over supervised fine-tuning with data augmentation in vision-intensive settings. Robustness analysis reveals that enhanced spatial representations directly improve reasoning accuracy, reinforcing the need for structured perception-to-reasoning pipelines in MSLMs.

</details>


### [181] [One-Shot Federated Clustering of Non-Independent Completely Distributed Data](https://arxiv.org/abs/2601.17512)
*Yiqun Zhang,Shenghong Cai,Zihua Yang,Sen Feng,Yuzhu Ji,Haijun Zhang*

Main category: cs.LG

TL;DR: 本文提出GOLD框架解决联邦聚类中的Non-IID问题，通过全局导向的局部分布学习来融合非独立完全分布数据中的聚类知识。


<details>
  <summary>Details</summary>
Motivation: 联邦聚类在无标签的分布式物联网数据中应用广泛，但现有的Non-IID问题（特别是不同客户端可能分割同一聚类）严重限制了聚类性能，需要新的解决方案。

Method: 提出GOLD框架：1）精细探索客户端潜在的不完整局部聚类分布；2）将分布摘要上传至服务器进行全局融合；3）在全局分布指导下进行局部聚类增强。

Result: 通过显著性检验、消融研究、可扩展性评估和定性结果等大量实验，证明了GOLD框架的优越性。

Conclusion: GOLD框架有效解决了联邦聚类中的Non-ICD问题，通过全局导向的局部分布学习显著提升了聚类性能，为分布式隐私保护系统中的模式知识探索提供了新方法。

Abstract: Federated Learning (FL) that extracts data knowledge while protecting the privacy of multiple clients has achieved remarkable results in distributed privacy-preserving IoT systems, including smart traffic flow monitoring, smart grid load balancing, and so on. Since most data collected from edge devices are unlabeled, unsupervised Federated Clustering (FC) is becoming increasingly popular for exploring pattern knowledge from complex distributed data. However, due to the lack of label guidance, the common Non-Independent and Identically Distributed (Non-IID) issue of clients have greatly challenged FC by posing the following problems: How to fuse pattern knowledge (i.e., cluster distribution) from Non-IID clients; How are the cluster distributions among clients related; and How does this relationship connect with the global knowledge fusion? In this paper, a more tricky but overlooked phenomenon in Non-IID is revealed, which bottlenecks the clustering performance of the existing FC approaches. That is, different clients could fragment a cluster, and accordingly, a more generalized Non-IID concept, i.e., Non-ICD (Non-Independent Completely Distributed), is derived. To tackle the above FC challenges, a new framework named GOLD (Global Oriented Local Distribution Learning) is proposed. GOLD first finely explores the potential incomplete local cluster distributions of clients, then uploads the distribution summarization to the server for global fusion, and finally performs local cluster enhancement under the guidance of the global distribution. Extensive experiments, including significance tests, ablation studies, scalability evaluations, qualitative results, etc., have been conducted to show the superiority of GOLD.

</details>


### [182] [Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment](https://arxiv.org/abs/2601.17563)
*Nathan Gavenski,Matteo Leonetti,Odinaldo Rodrigues*

Main category: cs.LG

TL;DR: UfO提出了一种无监督的观察模仿学习方法，通过两阶段过程学习策略，无需动作监督，解决了现有ILfO方法的多个限制。


<details>
  <summary>Details</summary>
Motivation: 现有观察模仿学习方法存在三个主要限制：需要基于动作的监督优化、假设状态有单一最优动作、以及不考虑实际环境状态就应用教师动作。现有方法在没有监督的情况下难以从观察轨迹中提取有效信息。

Method: UfO采用两阶段学习过程：第一阶段从观察的状态转移中近似教师的真实动作；第二阶段通过调整智能体轨迹使其与教师轨迹紧密对齐，进一步优化学习到的策略。

Result: 在五个广泛使用的环境中进行的实验表明，UfO不仅超越了教师和所有其他ILfO方法，而且显示出最小的标准差，这表明在未见场景中具有更好的泛化能力。

Conclusion: UfO成功解决了现有ILfO方法的多个限制，实现了无监督的观察模仿学习，在性能和泛化能力上都表现出色。

Abstract: State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.

</details>


### [183] [Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization](https://arxiv.org/abs/2601.17570)
*Hadi Salloum,Ali Jnadi,Yaroslav Kholodov,Alexander Gasnikov*

Main category: cs.LG

TL;DR: MC+QUBO方法将强化学习中的轨迹选择转化为QUBO问题，用量子启发式采样器优化选择，提升稀疏奖励环境下的学习效率。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛强化学习在稀疏奖励、大状态空间和相关轨迹环境中存在高样本复杂度问题，需要更高效的轨迹选择方法。

Method: 将轨迹选择重新表述为QUBO问题，使用模拟量子退火和模拟分叉作为黑盒求解器，从批量轨迹中选择最大化累积奖励并促进状态空间覆盖的子集。

Result: 在有限时域GridWorld实验中，MC+QUBO在收敛速度和最终策略质量上都优于传统蒙特卡洛方法。

Conclusion: 量子启发式优化作为强化学习中决策子程序具有潜力，能够有效提升蒙特卡洛强化学习的效率。

Abstract: Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.

</details>


### [184] [Understanding Transformer Encoder-Decoder Representations through Bernoulli Dropout](https://arxiv.org/abs/2601.17602)
*Xuanzhou Chen*

Main category: cs.LG

TL;DR: 研究通过高维编码器-解码器嵌入中的角度相似性分析Transformer过参数化，使用伯努利dropout识别保持Top-1预测的稀疏性阈值


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型的过参数化现象，探索在编码器和解码器之间应用dropout时，模型性能保持稳定的条件，理解嵌入表示在稀疏化下的鲁棒性

Method: 在编码器和解码器之间应用伯努利dropout，改变保留概率p来识别稀疏性阈值；理论上证明当嵌入有效稀疏度足够大时，解码器性能在适度坐标dropout下保持稳定；实验上构建带有二进制擦除通道（BEC）的Transformer模型，在英法翻译任务上测试性能

Result: 实验结果显示验证准确率和BLEU分数在某个阈值处急剧下降，可视化展示了这一趋势，证实了稀疏性阈值的存在

Conclusion: Transformer模型在编码器-解码器嵌入中存在一个稀疏性阈值，当dropout率超过该阈值时模型性能会急剧下降，但当嵌入有效稀疏度足够大时，模型在适度dropout下仍能保持稳定性能

Abstract: We study Transformer overparameterization through the lens of angular similarity in high-dimensional encoder-decoder embeddings. We apply Bernoulli dropout between the encoder and the decoder, varying the keep probability $p$ to identify a sparsity-dependent threshold above which the Top-1 prediction is preserved. Theoretically, we prove that, if the effective sparsity embeddings is sufficiently large, and thus decoder performance, remain stable under moderate coordinate dropout. Empirically, we implement the Bernoulli dropout by constructing a new Transformer model augmented with Binary Erasure Channel (BEC) and test its performance on an English-French translation task. Experimental results visualize the trends for validation accuracies and BLEU scores, both decline sharply at some threshold.

</details>


### [185] [A Thermodynamic Theory of Learning I: Irreversible Ensemble Transport and Epistemic Costs](https://arxiv.org/abs/2601.17607)
*Daisuke Okanohara*

Main category: cs.LG

TL;DR: 论文提出学习本质上是一个不可逆过程，需要熵产生来实现认知结构，并推导出认知速度极限(ESL)不等式，为任何学习过程的最小熵产生设定下界。


<details>
  <summary>Details</summary>
Motivation: 经典信息论表明确定性变换不会增加信息，但学习系统却能获得结构化内部表征。这引发了一个基本问题：学习如何在遵守信息论限制的同时产生抽象和洞察？作者认为学习在有限时间内本质上是不可逆过程，实现认知结构必然需要熵产生。

Method: 将学习建模为模型配置概率分布空间中的传输过程，引入认知自由能框架。在该框架中定义自由能下降作为记录学习轨迹上认知自由能总减少的记账量，将其分解为与潜在改进相关的可逆分量和与熵产生对应的不可逆分量。

Result: 推导出认知速度极限(ESL)不等式，为任何学习过程实现给定分布变换所需的最小熵产生设定下界。该下界仅取决于初始和最终集合分布之间的Wasserstein距离，与具体学习算法无关。

Conclusion: 学习在有限时间内本质上是不可逆的，实现认知结构需要熵产生。认知速度极限为学习过程的效率设定了基本限制，为理解学习系统的热力学成本提供了理论框架。

Abstract: Learning systems acquire structured internal representations from data, yet classical information-theoretic results state that deterministic transformations do not increase information. This raises a fundamental question: how can learning produce abstraction and insight without violating information-theoretic limits?
  We argue that learning is inherently an irreversible process when performed over finite time, and that the realization of epistemic structure necessarily incurs entropy production. To formalize this perspective, we model learning as a transport process in the space of probability distributions over model configurations and introduce an epistemic free-energy framework.
  Within this framework, we define the free-energy drop as a bookkeeping quantity that records the total reduction of epistemic free energy along a learning trajectory. This reduction decomposes into a reversible component associated with potential improvement and an irreversible component corresponding to entropy production.
  We then derive the Epistemic Speed Limit (ESL), a finite-time inequality that lower-bounds the minimal entropy production required by any learning process to realize a given distributional transformation. This bound depends only on the Wasserstein distance between initial and final ensemble distributions and is independent of the specific learning algorithm.

</details>


### [186] [BrainDistill: Implantable Motor Decoding with Task-Specific Knowledge Distillation](https://arxiv.org/abs/2601.17625)
*Yuhan Xie,Jinhan Liu,Xiaoyong Ni,Fei Tan,Icare Sakr,Thibault Collin,Shiqi Sun,Alejandro Rodriguez Guajardo,Demon Fanny,Charles-francois Vincent Latchoumane,Henri Lorach,Jocelyne Bloch,Gregoire Courtine,Mahsa Shoaran*

Main category: cs.LG

TL;DR: BrainDistill：一种用于植入式BCI的新型运动解码框架，通过任务特定知识蒸馏和量化感知训练，在保持高性能的同时降低计算需求


<details>
  <summary>Details</summary>
Motivation: Transformer解码器在BCI任务中表现出色，但参数多、计算需求大，难以部署在功率受限的植入式系统中

Method: 提出BrainDistill框架：1）植入式神经解码器（IND）；2）任务特定知识蒸馏（TSKD），通过监督投影优先保留关键特征；3）量化感知训练方案，支持仅整数推理

Result: IND在多个神经数据集上优于先前解码器，TSKD蒸馏变体在少样本校准设置中超越其他蒸馏方法，量化IND在严格功率约束下部署时性能损失最小

Conclusion: BrainDistill解决了植入式BCI系统的功率约束问题，通过知识蒸馏和量化技术实现了高性能、低功耗的运动解码

Abstract: Transformer-based neural decoders with large parameter counts, pre-trained on large-scale datasets, have recently outperformed classical machine learning models and small neural networks on brain-computer interface (BCI) tasks. However, their large parameter counts and high computational demands hinder deployment in power-constrained implantable systems. To address this challenge, we introduce BrainDistill, a novel implantable motor decoding pipeline that integrates an implantable neural decoder (IND) with a task-specific knowledge distillation (TSKD) framework. Unlike standard feature distillation methods that attempt to preserve teacher representations in full, TSKD explicitly prioritizes features critical for decoding through supervised projection. Across multiple neural datasets, IND consistently outperforms prior neural decoders on motor decoding tasks, while its TSKD-distilled variant further surpasses alternative distillation methods in few-shot calibration settings. Finally, we present a quantization-aware training scheme that enables integer-only inference with activation clipping ranges learned during training. The quantized IND enables deployment under the strict power constraints of implantable BCIs with minimal performance loss.

</details>


### [187] [RPNT: Robust Pre-trained Neural Transformer -- A Pathway for Generalized Motor Decoding](https://arxiv.org/abs/2601.17641)
*Hao Fang,Ryan A. Canfield,Tomohiro Ouchi,Beatrice Macagno,Eli Shlizerman,Amy L. Orsborn*

Main category: cs.LG

TL;DR: RPNT是一种鲁棒的预训练神经Transformer模型，通过预训练实现跨会话、跨类型、跨受试者和跨脑区的泛化能力，在脑解码任务中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 脑解码模型需要能够泛化到不同脑区、不同会话、不同行为类型和不同受试者的神经活动记录。现有模型只能部分解决这些挑战，需要开发能够适应和泛化的预训练神经Transformer模型。

Method: 提出RPNT模型，包含三个关键组件：1）多维旋转位置嵌入（MRoPE）聚合实验元数据；2）基于上下文的注意力机制，通过卷积核处理全局注意力以学习局部时间结构；3）鲁棒的自监督学习目标，采用均匀因果掩码策略和对比表示。在两个不同数据集上预训练：a）多会话、多任务、多受试者的微电极基准数据；b）使用高密度Neuropixel 1.0探针的多脑区记录。

Result: RPNT在跨会话、跨类型、跨受试者和跨脑区的下游行为解码任务中，始终达到并超越了现有解码模型的性能。

Conclusion: RPNT通过创新的架构设计和预训练策略，实现了对神经活动解码的鲁棒泛化能力，为脑机接口和神经科学应用提供了有效的解决方案。

Abstract: Brain decoding aims to interpret and translate neural activity into behaviors. As such, it is imperative that decoding models are able to generalize across variations, such as recordings from different brain sites, distinct sessions, different types of behavior, and a variety of subjects. Current models can only partially address these challenges and warrant the development of pretrained neural transformer models capable to adapt and generalize. In this work, we propose RPNT - Robust Pretrained Neural Transformer, designed to achieve robust generalization through pretraining, which in turn enables effective finetuning given a downstream task. In particular, RPNT unique components include 1) Multidimensional rotary positional embedding (MRoPE) to aggregate experimental metadata such as site coordinates, session name and behavior types; 2) Context-based attention mechanism via convolution kernels operating on global attention to learn local temporal structures for handling non-stationarity of neural population activity; 3) Robust self-supervised learning (SSL) objective with uniform causal masking strategies and contrastive representations. We pretrained two separate versions of RPNT on distinct datasets a) Multi-session, multi-task, and multi-subject microelectrode benchmark; b) Multi-site recordings using high-density Neuropixel 1.0 probes. The datasets include recordings from the dorsal premotor cortex (PMd) and from the primary motor cortex (M1) regions of nonhuman primates (NHPs) as they performed reaching tasks. After pretraining, we evaluated the generalization of RPNT in cross-session, cross-type, cross-subject, and cross-site downstream behavior decoding tasks. Our results show that RPNT consistently achieves and surpasses the decoding performance of existing decoding models in all tasks.

</details>


### [188] [A Mosco sufficient condition for intrinsic stability of non-unique convex Empirical Risk Minimization](https://arxiv.org/abs/2601.17646)
*Karim Bounja,Lahcen Laayouni,Abdeljalil Sakat*

Main category: cs.LG

TL;DR: 该论文研究了经验风险最小化（ERM）的稳定性问题，特别关注凸非严格损失函数产生集值最小化器的情况。作者提出Painlevé-Kuratowski上半连续性（PK-u.s.c.）作为ERM解对应的内在稳定性概念，并建立了在Mosco一致性扰动和局部有界最小化器条件下的稳定性理论。


<details>
  <summary>Details</summary>
Motivation: 传统ERM稳定性研究通常基于单值输出，但凸非严格损失函数会产生集值最小化器。现有研究缺乏对这种集值情况的稳定性分析框架，需要建立适用于集值最小化器的稳定性理论，以正确解释选择稳定性。

Method: 采用Painlevé-Kuratowski上半连续性（PK-u.s.c.）作为ERM解对应的稳定性概念，这是集合层面的Hadamard适定性。在最小非退化定性机制下，分析Mosco一致性扰动和局部有界最小化器的条件，证明这些条件能保证PK-u.s.c.、最小值连续性以及消失间隙近最小化器的一致性。

Result: 证明了在Mosco一致性扰动和局部有界最小化器的条件下，ERM解对应具有PK-u.s.c.性质，最小值连续，且消失间隙近最小化器具有一致性。此外，二次增长条件能够产生显式的定量偏差界。

Conclusion: PK-u.s.c.是ERM解对应的内在稳定性概念，是解释选择稳定性的先决条件。在适当的非退化条件下，Mosco一致性扰动和局部有界最小化器能够保证ERM的稳定性，为凸非严格损失函数的稳定性分析提供了理论基础。

Abstract: Empirical risk minimization (ERM) stability is usually studied via single-valued outputs, while convex non-strict losses yield set-valued minimizers. We identify Painlevé-Kuratowski upper semicontinuity (PK-u.s.c.) as the intrinsic stability notion for the ERM solution correspondence (set-level Hadamard well-posedness) and a prerequisite to interpret stability of selections. We then characterize a minimal non-degenerate qualitative regime: Mosco-consistent perturbations and locally bounded minimizers imply PK-u.s.c., minimal-value continuity, and consistency of vanishing-gap near-minimizers. Quadratic growth yields explicit quantitative deviation bounds.

</details>


### [189] [Time-Varying Causal Treatment for Quantifying the Causal Effect of Short-Term Variations on Arctic Sea Ice Dynamics](https://arxiv.org/abs/2601.17647)
*Akila Sampath,Vandana Janeja,Jianwu Wang*

Main category: cs.LG

TL;DR: 提出KGCM-VAE模型，通过知识引导的因果建模量化海冰厚度与海面高度之间的因果关系，结合物理约束和分布平衡机制提升因果效应估计精度。


<details>
  <summary>Details</summary>
Motivation: 量化冰融化和淡水分布之间的因果关系对理解极地气候变化和全球海平面上升至关重要。传统深度学习模型在时空设置中处理因果效应估计时面临未观测混杂变量和缺乏物理约束的挑战。

Method: 提出知识引导的因果模型变分自编码器(KGCM-VAE)，包含：1)速度调制方案，通过SSH转换控制的sigmoid函数动态放大平滑速度信号生成物理基础的因果处理；2)最大均值差异(MMD)平衡潜在空间中处理和对照协变量分布；3)因果邻接约束解码器确保与已知物理结构对齐。

Result: 在合成和真实北极数据集上的实验表明，KGCM-VAE在PEHE指标上优于最先进基准。消融研究证实MMD和因果邻接约束联合应用使估计误差降低1.88%。

Conclusion: KGCM-VAE通过整合物理知识和因果约束，有效解决了时空因果推断中的挑战，为量化海冰厚度与海面高度之间的因果关系提供了可靠框架。

Abstract: Quantifying the causal relationship between ice melt and freshwater distribution is critical, as these complex interactions manifest as regional fluctuations in sea surface height (SSH). Leveraging SSH as a proxy for sea ice dynamics enables improved understanding of the feedback mechanisms driving polar climate change and global sea-level rise. However, conventional deep learning models often struggle with reliable treatment effect estimation in spatiotemporal settings due to unobserved confounders and the absence of physical constraints. To address these challenges, we propose the Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE) to quantify causal mechanisms between sea ice thickness and SSH. The proposed framework integrates a velocity modulation scheme in which smoothed velocity signals are dynamically amplified via a sigmoid function governed by SSH transitions to generate physically grounded causal treatments. In addition, the model incorporates Maximum Mean Discrepancy (MMD) to balance treated and control covariate distributions in the latent space, along with a causal adjacency-constrained decoder to ensure alignment with established physical structures. Experimental results on both synthetic and real-world Arctic datasets demonstrate that KGCM-VAE achieves superior PEHE compared to state-of-the-art benchmarks. Ablation studies further confirm the effectiveness of the approach, showing that the joint application of MMD and causal adjacency constraints yields a 1.88\% reduction in estimation error.

</details>


### [190] [Kareus: Joint Reduction of Dynamic and Static Energy in Large Model Training](https://arxiv.org/abs/2601.17654)
*Ruofan Wu,Jae-Won Chung,Mosharaf Chowdhury*

Main category: cs.LG

TL;DR: Kareus是一个AI训练系统，通过联合优化细粒度内核调度和频率缩放来同时管理动态和静态能耗，在时间-能耗权衡前沿上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: AI计算需求快速增长，但能源供应跟不上，能源已成为昂贵且竞争激烈的资源。现有工作只关注能耗的单一方面（动态或静态能耗），而细粒度内核调度和频率缩放会共同且相互依赖地影响两种能耗。

Method: 设计Kareus训练系统，将难以处理的联合优化问题分解为局部的、基于分区的子问题，然后使用多通道多目标优化算法来寻找推动时间-能耗权衡前沿的执行调度方案。

Result: 与现有技术相比，Kareus在相同训练时间下减少训练能耗达28.3%，或在相同能耗下减少训练时间达27.5%。

Conclusion: 通过联合优化内核调度和频率缩放来同时管理动态和静态能耗，Kareus能够显著推进AI训练的时间-能耗权衡前沿，有效解决能源供应不足的问题。

Abstract: The computing demand of AI is growing at an unprecedented rate, but energy supply is not keeping pace. As a result, energy has become an expensive, contended resource that requires explicit management and optimization. Although recent works have made significant progress in large model training optimization, they focus only on a single aspect of energy consumption: dynamic or static energy.
  We find that fine-grained kernel scheduling and frequency scaling jointly and interdependently impact both dynamic and static energy consumption. Based on this finding, we design Kareus, a training system that pushes the time--energy tradeoff frontier by optimizing both aspects. Kareus decomposes the intractable joint optimization problem into local, partition-based subproblems. It then uses a multi-pass multi-objective optimization algorithm to find execution schedules that push the time--energy tradeoff frontier. Compared to the state of the art, Kareus reduces training energy by up to 28.3% at the same training time, or reduces training time by up to 27.5% at the same energy consumption.

</details>


### [191] [Entropic Risk-Aware Monte Carlo Tree Search](https://arxiv.org/abs/2601.17667)
*Pedro P. Santos,Jacopo Silvestrin,Alberto Sardinha,Francisco S. Melo*

Main category: cs.LG

TL;DR: 提出了一种可证明正确的蒙特卡洛树搜索算法，用于解决具有熵风险度量目标的风险感知马尔可夫决策过程，并提供了非渐近分析。


<details>
  <summary>Details</summary>
Motivation: 现有的风险感知MDP求解方法在计算效率和理论保证方面存在不足，需要开发既具有理论保证又实用的算法来解决具有熵风险度量的风险感知MDP问题。

Method: 提出了一种基于置信上限的蒙特卡洛树搜索算法，该算法利用了先前工作中引入的用于解决具有熵风险度量目标的风险感知MDP的动态规划公式。

Result: 算法被证明是正确的（根节点经验熵风险度量收敛到最优熵风险度量），并享有多项式遗憾集中性。实验表明该方法优于相关基线。

Conclusion: 该研究提出了一种具有理论保证的风险感知MCTS算法，为风险感知决策问题提供了有效的解决方案，并在实验中验证了其优越性。

Abstract: We propose a provably correct Monte Carlo tree search (MCTS) algorithm for solving \textit{risk-aware} Markov decision processes (MDPs) with \textit{entropic risk measure} (ERM) objectives. We provide a \textit{non-asymptotic} analysis of our proposed algorithm, showing that the algorithm: (i) is \textit{correct} in the sense that the empirical ERM obtained at the root node converges to the optimal ERM; and (ii) enjoys \textit{polynomial regret concentration}. Our algorithm successfully exploits the dynamic programming formulations for solving risk-aware MDPs with ERM objectives introduced by previous works in the context of an upper confidence bound-based tree search algorithm. Finally, we provide a set of illustrative experiments comparing our risk-aware MCTS method against relevant baselines.

</details>


### [192] [Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction](https://arxiv.org/abs/2601.17668)
*Jang-Hyun Kim,Dongyoon Han,Sangdoo Yun*

Main category: cs.LG

TL;DR: 提出基于门控的KV缓存驱逐方法，通过轻量级sink-attention门控模块识别并保留关键KV对，实现高达70%的KV缓存压缩，同时保持接近无损的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩技术通常在性能下降和计算开销之间需要权衡，这限制了大型语言模型的实际部署效率。需要一种既能实现高压缩比又具有可忽略计算成本的方法。

Method: 提出基于门控的KV缓存驱逐方法，引入轻量级sink-attention门控模块识别关键KV对，采用无需反向传播的门训练算法，通过任务无关的重建目标实现强任务泛化能力，可无缝集成到预填充和解码阶段。

Result: 在Qwen2.5-1M、Qwen3和Gemma3系列模型上的实验表明，该方法在驱逐高达70%的KV缓存时仍能保持接近无损的性能，结果在长上下文理解、代码理解和数学推理等多种任务上具有一致性。

Conclusion: 提出的基于门控的KV缓存驱逐方法能够以可忽略的计算成本实现高压缩比，同时保持接近无损的性能，展示了该方法在多种任务和模型家族上的通用性。

Abstract: Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.

</details>


### [193] [REV-INR: Regularized Evidential Implicit Neural Representation for Uncertainty-Aware Volume Visualization](https://arxiv.org/abs/2601.17689)
*Shanu Saklani,Tushar M. Athawale,Nairita Pal,David Pugmire,Christopher R. Johnson,Soumya Dutta*

Main category: cs.LG

TL;DR: REV-INR是一种正则化证据隐式神经表示方法，通过单次前向传播同时预测数据值和不确定性，解决了传统INR缺乏不确定性估计的问题，实现了高效可靠的体积数据重建和可视化。


<details>
  <summary>Details</summary>
Motivation: 传统确定性隐式神经表示（INR）只能预测数值，无法提供模型预测的不确定性或数据固有噪声的影响，这可能导致重建体积中的预测不准确，从而产生不可靠的数据解释和可视化。由于原始数据可能因体积过大而无法获得，从模型预测数据中识别错误结果可能不可行。

Method: 提出REV-INR（正则化证据隐式神经表示），该方法通过单次前向传播学习准确预测数据值以及相关的坐标级数据不确定性（偶然不确定性）和模型不确定性（认知不确定性）。

Result: REV-INR在体积重建质量方面表现最佳，能够提供鲁棒的数据不确定性和模型不确定性估计，且推理时间最快。与现有深度不确定性估计方法相比具有明显优势。

Conclusion: REV-INR能够评估提取的等值面和体积可视化结果的可靠性和可信度，使得分析可以完全基于模型预测的数据进行，解决了传统INR缺乏不确定性估计的局限性。

Abstract: Applications of Implicit Neural Representations (INRs) have emerged as a promising deep learning approach for compactly representing large volumetric datasets. These models can act as surrogates for volume data, enabling efficient storage and on-demand reconstruction via model predictions. However, conventional deterministic INRs only provide value predictions without insights into the model's prediction uncertainty or the impact of inherent noisiness in the data. This limitation can lead to unreliable data interpretation and visualization due to prediction inaccuracies in the reconstructed volume. Identifying erroneous results extracted from model-predicted data may be infeasible, as raw data may be unavailable due to its large size. To address this challenge, we introduce REV-INR, Regularized Evidential Implicit Neural Representation, which learns to predict data values accurately along with the associated coordinate-level data uncertainty and model uncertainty using only a single forward pass of the trained REV-INR during inference. By comprehensively comparing and contrasting REV-INR with existing well-established deep uncertainty estimation methods, we show that REV-INR achieves the best volume reconstruction quality with robust data (aleatoric) and model (epistemic) uncertainty estimates using the fastest inference time. Consequently, we demonstrate that REV-INR facilitates assessment of the reliability and trustworthiness of the extracted isosurfaces and volume visualization results, enabling analyses to be solely driven by model-predicted data.

</details>


### [194] [FedCCA: Client-Centric Adaptation against Data Heterogeneity in Federated Learning on IoT Devices](https://arxiv.org/abs/2601.17713)
*Kaile Wang,Jiannong Cao,Yu Yang,Xiaoyin Li,Yinfeng Cao*

Main category: cs.LG

TL;DR: FedCCA是一种针对物联网数据异构性的联邦学习算法，通过客户端中心化自适应机制，利用客户端特定知识为每个客户端学习独特模型，提升模型性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 物联网(IoT)快速发展需要基于隐私数据（如人体感知数据）进行AI模型训练。联邦学习(FL)作为隐私保护的分布式训练框架被广泛应用，但物联网设备间的数据异构性问题会显著降低模型性能和收敛速度。现有方法局限于固定的客户端选择和云端服务器聚合，难以在本地训练中隐私保护地提取客户端特定信息。

Method: 提出客户端中心化自适应联邦学习(FedCCA)算法：1）通过选择性自适应机制，利用客户端特定知识为每个客户端学习独特模型；2）采用基于额外客户端特定编码器的动态客户端选择和自适应聚合；3）采用基于注意力的全局聚合策略增强多源知识转移。

Result: 在多样化数据集上进行广泛实验，结果表明FedCCA在解决数据异构性问题方面相比竞争基线方法展现出显著性能优势。

Conclusion: FedCCA通过客户端中心化自适应机制有效缓解了联邦学习中的数据异构性问题，为物联网隐私数据训练提供了更优的解决方案。

Abstract: With the rapid development of the Internet of Things (IoT), AI model training on private data such as human sensing data is highly desired. Federated learning (FL) has emerged as a privacy-preserving distributed training framework for this purpuse. However, the data heterogeneity issue among IoT devices can significantly degrade the model performance and convergence speed in FL. Existing approaches limit in fixed client selection and aggregation on cloud server, making the privacy-preserving extraction of client-specific information during local training challenging. To this end, we propose Client-Centric Adaptation federated learning (FedCCA), an algorithm that optimally utilizes client-specific knowledge to learn a unique model for each client through selective adaptation, aiming to alleviate the influence of data heterogeneity. Specifically, FedCCA employs dynamic client selection and adaptive aggregation based on the additional client-specific encoder. To enhance multi-source knowledge transfer, we adopt an attention-based global aggregation strategy. We conducted extensive experiments on diverse datasets to assess the efficacy of FedCCA. The experimental results demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.

</details>


### [195] [Do Reasoning Models Ask Better Questions? A Formal Information-Theoretic Analysis on Multi-Turn LLM Games](https://arxiv.org/abs/2601.17716)
*Daniel M. Pedrozo,Telma W. de L. Soares,Bryan L. M. de Oliveira*

Main category: cs.LG

TL;DR: 该论文提出了一个多轮对话框架，用于定量评估LLMs通过是/否问题在分层知识图环境中收集信息的能力，使用信息增益作为主要指标，并在地理猜城市游戏中验证了具有显式推理能力的模型表现更好。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在许多任务上表现出色，但在处理LLM智能体关键能力——为消除用户请求中的歧义而提出好问题——方面仍有不足。现有基准缺乏基于信息增益的全面评估框架，也很少系统比较使用链式思维推理与不使用该推理的模型。

Method: 提出了一个多轮对话框架，采用三个交互的LLM智能体：提问者、回答者和假设空间更新者。框架在分层知识图环境中使用是/否问题收集信息，采用基于香农熵的信息增益作为主要指标来评估每个回合和累积的查询效果。在地理猜城市游戏设置中实例化该框架，采用五级分类法组织，评估了完全可观察和部分可观察条件下、有/无链式思维推理的多个LLM变体。

Result: 实验表明，在评估的模型中，具有显式推理能力的模型在每回合获得更高的信息增益，并以更少的步骤达到解决方案，特别是在部分可观察设置中。推理轨迹分析显示，较小模型通过更积极地探索候选问题来弥补有限能力，而较大模型在选择最优查询时表现出更高的自信度，生成具有更大潜在信息增益的候选问题。

Conclusion: 该研究提出了一个量化评估LLMs信息收集能力的框架，证明了显式推理能力在信息收集任务中的重要性，为LLM智能体的提问能力评估提供了系统方法，并揭示了不同规模模型在信息收集策略上的差异。

Abstract: Large Language Models (LLMs) excel at many tasks but still struggle with a critical ability for LLM-based agents: asking good questions for resolving ambiguity in user requests. While prior work has explored information-seeking behavior through word games, existing benchmarks lack comprehensive evaluation frameworks that provide both final and intermediate signals based on Information Gain (IG). Moreover, they rarely provide systematic comparisons between models that use chain-of-thought reasoning and those that do not. We propose a multi-turn dialogue framework that quantitatively measures how effectively LLMs gather information through yes/no questions in a hierarchical knowledge graph environment. Our framework employs a triad of interacting LLM agents that ask questions, answer them, and update the hypothesis space. We adopt IG as the main metric, grounded in Shannon entropy, to assess query effectiveness at each turn and cumulatively. We instantiate our framework in a geographical Guess My City game setting organized in a five-level taxonomy and evaluate multiple LLM variants under fully and partially observable conditions, with and without Chain-of-Thought reasoning. Our experiments demonstrate that, among the evaluated models, the ones with explicit reasoning capabilities achieve higher IG per turn and reach solutions in fewer steps, particularly in partially observable settings. Analysis of reasoning traces reveals that smaller models compensate for limited capacity through more aggressive exploration of candidate questions, while larger models exhibit higher assertiveness in selecting optimal queries, generating candidates with greater potential IG.

</details>


### [196] [AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation](https://arxiv.org/abs/2601.17761)
*Dongjie Cheng,Ruifeng Yuan,Yongqi Li,Runyang You,Wenjie Wang,Liqiang Nie,Lei Zhang,Wenjie Li*

Main category: cs.LG

TL;DR: AR-Omni是一个统一的任意到任意多模态大语言模型，采用自回归范式，使用单一Transformer解码器支持文本、图像和语音的生成，无需专家解码器。


<details>
  <summary>Details</summary>
Motivation: 现实世界的感知和交互本质上是多模态的，涵盖语言、视觉和语音。现有的大多数"全能"MLLM系统仍依赖额外的专家组件来实现多模态生成，限制了统一训练和推理的简洁性。自回归建模在文本领域已被证明是优雅且可扩展的基础，因此研究者希望将其扩展到多模态领域。

Method: 提出AR-Omni模型，采用单一Transformer解码器支持文本、图像和流式语音的生成。通过任务感知的损失重加权解决模态不平衡问题；通过轻量级的token级感知对齐损失提高视觉保真度；通过有限状态解码机制平衡稳定性和创造性。

Result: AR-Omni在三种模态上都实现了强大的生成质量，同时保持实时性，语音生成的实时因子达到0.88。

Conclusion: AR-Omni证明了自回归范式可以有效地统一多模态生成，无需专家解码器，为构建简洁而强大的任意到任意多模态系统提供了可行方案。

Abstract: Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of "Omni" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.

</details>


### [197] [LLM-42: Enabling Determinism in LLM Inference with Verified Speculation](https://arxiv.org/abs/2601.17768)
*Raja Gond,Aditya K Kamath,Arkaprava Basu,Ramachandran Ramjee,Ashish Panwar*

Main category: cs.LG

TL;DR: LLM-42：一种基于调度的确定性LLM推理方法，通过轻量级验证-回滚循环在保持高吞吐量的同时确保输出确定性


<details>
  <summary>Details</summary>
Motivation: LLM推理中的非确定性源于浮点数非结合性与动态批处理及GPU核的交互，现有解决方案要么严重降低吞吐量，要么需要重新实现核函数并带来固定开销

Method: 受推测解码启发，提出调度方法LLM-42：使用非确定性快速路径解码令牌，通过轻量级验证-回滚循环强制执行确定性。验证器在固定形状归约调度下重放候选令牌，提交保证跨运行一致的令牌，回滚违反确定性的令牌

Result: LLM-42主要重用现有核函数不变，仅对需要确定性的流量按比例产生开销，在保持高吞吐量的同时确保输出确定性

Conclusion: LLM-42提供了一种有效的调度方法，在不牺牲吞吐量的情况下实现LLM推理的确定性，避免了与核函数设计的紧密耦合和固定运行时开销

Abstract: In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism.
  Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.

</details>


### [198] [EEG Foundation Models: Progresses, Benchmarking, and Open Problems](https://arxiv.org/abs/2601.17883)
*Dingkun Liu,Yuheng Chen,Zhu Chen,Zhenyao Cui,Yaozhi Wen,Jiayu An,Jingwei Luo,Dongrui Wu*

Main category: cs.LG

TL;DR: 该论文对现有EEG基础模型进行了全面评估，发现线性探测通常不足、专用模型仍具竞争力、更大基础模型不一定带来更好泛化性能


<details>
  <summary>Details</summary>
Motivation: EEG基础模型在脑机接口领域发展迅速，但由于预训练目标、预处理选择和下游评估协议不一致，缺乏公平全面的比较。本文旨在填补这一空白。

Method: 首先回顾50个代表性模型，将其设计选择组织为统一分类框架；然后评估12个开源基础模型和竞争性专用基线，涵盖13个EEG数据集和9个BCI范式；考虑跨被试泛化和少样本校准；比较全参数微调与线性探测；分析模型规模与性能关系。

Result: 1) 线性探测通常不足；2) 从头训练的专用模型在许多任务中仍具竞争力；3) 在当前数据机制和训练实践下，更大的基础模型不一定产生更好的泛化性能。

Conclusion: EEG基础模型领域需要更系统化的评估框架，当前模型在真实部署场景中的优势有限，未来研究应关注更有效的预训练策略和评估协议。

Abstract: Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.

</details>


### [199] [Adaptive Weighting in Knowledge Distillation: An Axiomatic Framework for Multi-Scale Teacher Ensemble Optimization](https://arxiv.org/abs/2601.17910)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 本文提出了一个算子无关的公理化框架，用于多教师知识蒸馏中的自适应权重分配，涵盖token、task和context三个互补尺度，将理论保证与具体权重公式解耦。


<details>
  <summary>Details</summary>
Motivation: 多教师知识蒸馏虽然能提高鲁棒性、效率和安全性，但现有方法主要依赖启发式或实现特定的权重方案，缺乏统一的理论框架。

Method: 开发了一个算子无关的公理化框架，形式化了自适应权重算子的结构条件，包括良好定义性、多重非等价实现可能性、通过乘积结构归一化的层次组合，并分析了收敛性、稳定性和扰动鲁棒性。

Result: 建立了符合条件算子的存在性和非唯一性，在标准假设下分析了基于梯度优化的收敛性，提供了安全约束蒸馏的抽象表述，实现了理论保证与具体权重公式的解耦。

Conclusion: 该框架为异构性、分布偏移和安全约束下的自适应蒸馏方法提供了原则性分析基础，使理论分析不再依赖于具体的权重计算公式。

Abstract: Knowledge distillation with multiple teachers is increasingly used to improve robustness, efficiency, and safety, yet existing approaches rely largely on heuristic or implementation-specific weighting schemes. This paper develops an operator-agnostic axiomatic framework for adaptive weighting in multi-teacher knowledge distillation across three complementary scales: token, task, and context. We formalize structural conditions under which adaptive weighting operators are well-defined, admit multiple non-equivalent implementations, and can be hierarchically composed via product-structure normalization. Within this framework, we establish existence and non-uniqueness of conforming operators, characterize convergence of gradient-based optimization under standard assumptions, analyze stability and perturbation robustness, and provide an abstract formulation of safety-constrained distillation. The results decouple theoretical guarantees from specific weighting formulas, enabling principled analysis of adaptive distillation methods under heterogeneity, distribution shift, and safety constraints.

</details>


### [200] [Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN](https://arxiv.org/abs/2601.17912)
*Qinyi Liu,Mohammad Khalil,Naman Goel*

Main category: cs.LG

TL;DR: TabPFN等表格数据基础模型通过因果预训练获得高预测精度，但其公平性表现有限，特别是在MNAR协变量偏移下，需要额外的公平性干预措施。


<details>
  <summary>Details</summary>
Motivation: 尽管TabPFN等基于因果推理预训练的表格数据基础模型在预测准确性方面表现出色，但其公平性特性尚未得到充分探索，需要评估这些模型在实际部署中的公平性表现。

Method: 对TabPFN及其微调变体进行全面的实证评估，包括预测性能、公平性和鲁棒性测试，考察不同数据集大小和分布偏移条件下的表现。

Result: TabPFN相比基线模型具有更强的预测准确性和对虚假相关性的鲁棒性，但在公平性方面的改进有限且不一致，特别是在MNAR协变量偏移条件下表现不佳。

Conclusion: TabPFN的因果预训练虽然有益但不足以确保算法公平性，实际部署中需要额外的公平性干预措施，这为未来研究指明了方向。

Abstract: Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, have not yet been explored in sufficient depth. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying such models in practice and the need for further fairness interventions.

</details>


### [201] [UniPACT: A Multimodal Framework for Prognostic Question Answering on Raw ECG and Structured EHR](https://arxiv.org/abs/2601.17916)
*Jialu Tang,Tong Xia,Yuan Lu,Aaqib Saeed*

Main category: cs.LG

TL;DR: UniPACT是一个统一的临床预后问答框架，通过结构化提示将数值型电子健康记录转换为语义丰富的文本，并与原始心电图波形表示融合，使大语言模型能够跨模态推理，在MDS-ED基准测试中达到89.37%的平均AUROC。


<details>
  <summary>Details</summary>
Motivation: 准确的临床预后需要结合结构化电子健康记录和实时生理信号（如心电图），但大语言模型难以原生处理这些异构的非文本数据类型。

Method: 提出UniPACT框架，核心是结构化提示机制，将数值型EHR数据转换为语义丰富的文本，然后将这些文本化的患者上下文与从原始ECG波形学习的表示融合，使LLM能够对两种模态进行整体推理。

Result: 在综合MDS-ED基准测试中，UniPACT在诊断、恶化、ICU入院和死亡率等多种预后任务上达到89.37%的平均AUROC，优于专门基线模型。

Conclusion: 多模态、多任务方法对性能至关重要，并在数据缺失场景中提供鲁棒性，UniPACT成功弥合了临床数据模态间的鸿沟，实现了统一的预后问答。

Abstract: Accurate clinical prognosis requires synthesizing structured Electronic Health Records (EHRs) with real-time physiological signals like the Electrocardiogram (ECG). Large Language Models (LLMs) offer a powerful reasoning engine for this task but struggle to natively process these heterogeneous, non-textual data types. To address this, we propose UniPACT (Unified Prognostic Question Answering for Clinical Time-series), a unified framework for prognostic question answering that bridges this modality gap. UniPACT's core contribution is a structured prompting mechanism that converts numerical EHR data into semantically rich text. This textualized patient context is then fused with representations learned directly from raw ECG waveforms, enabling an LLM to reason over both modalities holistically. We evaluate UniPACT on the comprehensive MDS-ED benchmark, it achieves a state-of-the-art mean AUROC of 89.37% across a diverse set of prognostic tasks including diagnosis, deterioration, ICU admission, and mortality, outperforming specialized baselines. Further analysis demonstrates that our multimodal, multi-task approach is critical for performance and provides robustness in missing data scenarios.

</details>


### [202] [treaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding](https://arxiv.org/abs/2601.17917)
*Zhongyu Xiao,Zhiwei Hao,Jianyuan Guo,Yong Luo,Jia Liu,Jie Xu,Han Hu*

Main category: cs.LG

TL;DR: Streaming-dLLM是一个训练免费框架，通过空间维度的衰减引导后缀建模和时间维度的动态置信度感知策略，显著加速扩散大语言模型的推理速度，最高可达68.2倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有扩散大语言模型推理加速方法存在内在低效性：空间冗余（对信息稀疏的后缀区域进行均匀建模）和时间低效（在整个解码过程中应用固定的去噪调度）。

Method: 提出Streaming-dLLM框架：1）空间上，通过衰减引导后缀建模修剪冗余掩码标记来近似完整上下文；2）时间上，采用带提前退出机制的动态置信度感知策略，允许模型跳过已收敛标记的不必要迭代。

Result: 实验表明Streaming-dLLM在保持生成质量的同时，实现了最高68.2倍的推理加速，显著提升了扩散解码效率。

Conclusion: Streaming-dLLM通过同时优化空间和时间维度，有效解决了扩散大语言模型推理中的内在低效问题，为扩散解码提供了高效的训练免费解决方案。

Abstract: Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.

</details>


### [203] [Dissipative Learning: A Framework for Viable Adaptive Systems](https://arxiv.org/abs/2601.17933)
*Laurent Caraffa*

Main category: cs.LG

TL;DR: 该论文提出BEDS框架，将学习视为内在耗散过程，证明Fisher-Rao正则化是热力学最优策略，统一了现有正则化方法，重新定义学习为在耗散约束下维持可行信念状态。


<details>
  <summary>Details</summary>
Motivation: 传统学习理论将遗忘和正则化视为启发式附加组件，而作者认为它们是自适应系统的结构要求。需要从信息理论、热力学和信息几何角度建立统一框架，将学习重新定义为耗散过程。

Method: 提出BEDS（贝叶斯涌现耗散结构）框架，基于条件最优性定理，证明Fisher-Rao正则化是唯一热力学最优策略。该框架将Ridge、SIGReg、EMA、SAC等方法统一为单一控制方程的特例。

Result: 过拟合对应过度结晶化，灾难性遗忘反映耗散控制不足。框架区分BEDS可结晶问题（信念收敛到稳定平衡）和BEDS可维持问题（需要持续适应）。扩展至持续学习和多智能体系统。

Conclusion: 学习应被重新定义为在耗散约束下维持可行信念状态的过程。可行性、适应稳定性和有限资源下的稳定性取代渐近最优性成为主要标准，为遗忘、正则化和稳定性提供了原则性视角。

Abstract: We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints.
  A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation.
  Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.

</details>


### [204] [Federated learning for unpaired multimodal data through a homogeneous transformer model](https://arxiv.org/abs/2601.17986)
*Anders Eklund*

Main category: cs.LG

TL;DR: 提出了一种用于训练去中心化多模态基础模型的新框架，能够在数据模态分离且不配对的情况下进行联邦学习，无需共享原始数据或对齐样本。


<details>
  <summary>Details</summary>
Motivation: 现实联邦环境中，数据通常是未配对且分散在不同节点上的（如图像和文本分别存储在不同节点），这些数据严格私有且没有共同样本。现有联邦学习方法无法处理这种模态分离的情况，因为它们假设本地客户端拥有对齐的数据对或需要共享原始特征嵌入，这违反了数据主权。

Method: 1) 引入小型公共锚点集来对齐分离的私有流形；2) 使用从公共锚点计算的Gram矩阵，通过中心核对齐实现跨模态语义对齐，不传输私有样本；3) 提出子空间稳定微调方法处理大型transformer模型；4) 提出精度加权平均，利用不确定性估计降低不确定节点的权重。

Result: 该方法为联邦未配对基础模型建立了数学基础，使全局模型能够从分散、分离和私有的数据孤岛中学习世界的统一表示，无需集中存储或配对样本。

Conclusion: 该框架首次实现了在数据模态分离且未配对的联邦环境中训练多模态基础模型，提供了比原型共享更强的隐私保证，并为处理大规模transformer模型和节点异质性提供了有效解决方案。

Abstract: Training of multimodal foundation models is currently restricted to centralized data centers containing massive, aligned datasets (e.g., image-text pairs). However, in realistic federated environments, data is often unpaired and fragmented across disjoint nodes; one node may hold sensor data, while another holds textual logs. These datasets are strictly private and share no common samples. Current federated learning (FL) methods fail in this regime, as they assume local clients possess aligned pairs or require sharing raw feature embeddings, which violates data sovereignty. We propose a novel framework to train a global multimodal transformer across decentralized nodes with disjoint modalities. We introduce a small public anchor set to align disjoint private manifolds. Using Gram matrices calculated from these public anchors, we enforce semantic alignment across modalities through centered kernel alignment without ever transmitting private samples, offering a mathematically superior privacy guarantee compared to prototype sharing. Further, we introduce a subspace-stabilized fine-tuning method to handle FL with huge transformer models. We strictly decouple domain-specific magnitude shifts from semantic direction, ensuring that nodes with varying sensor characteristics align geometrically to the global consensus. Lastly, we propose precision weighted averaging, where efficiently obtained uncertainty estimates are used to downweight uncertain nodes. This paper establishes the mathematical backbone for federated unpaired foundation models, enabling a global model to learn a unified representation of the world from fragmented, disjoint, and private data silos without requiring centralized storage or paired samples.

</details>


### [205] [Coding-Enforced Resilient and Secure Aggregation for Hierarchical Federated Learning](https://arxiv.org/abs/2601.17995)
*Shudi Weng,Ming Xiao,Mikael Skoglund*

Main category: cs.LG

TL;DR: 提出H-SecCoGC方案，通过编码策略实现结构化聚合，在不可靠通信下同时保证模型精度和隐私保护


<details>
  <summary>Details</summary>
Motivation: 分层联邦学习(HFL)虽然改善了客户端与服务器间的链路质量，但在不可靠通信环境下，如何在保证模型精度的同时保护隐私仍面临挑战，特别是隐私噪声的协调可能被随机破坏

Method: 提出鲁棒的分层安全聚合方案H-SecCoGC，集成编码策略来强制执行结构化聚合，避免部分参与问题

Result: 该方案在不同隐私保护级别下都能确保准确的全局模型构建，显著提高了鲁棒性、隐私保护和学习效率

Conclusion: 理论分析和实验结果都证明了该方案在不可靠通信环境下，对任意强隐私保证的优越性

Abstract: Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees

</details>


### [206] [Spelling Bee Embeddings for Language Modeling](https://arxiv.org/abs/2601.18030)
*Markus N. Rabe,Judith Clymo,Zheren Dong*

Main category: cs.LG

TL;DR: 论文提出了一种简单的嵌入层修改方法，通过将词符拼写信息融入嵌入表示，不仅提升了拼写能力，还在多个标准基准测试中取得了改进。


<details>
  <summary>Details</summary>
Motivation: 传统的词符嵌入方法可能未能充分利用词符的拼写信息，而拼写信息本身包含有价值的语言特征。通过将拼写信息融入嵌入层，可以增强模型的语言理解能力。

Method: 对嵌入层进行简单修改，将词符的拼写信息注入到词符嵌入中。具体方法是在训练过程中将拼写特征与原始嵌入相结合，使模型能够同时学习语义和拼写特征。

Result: 使用该方法的模型在拼写任务上表现更好，同时在标准基准测试中也取得了改进。对40M到800M参数规模的模型进行扩展研究显示，这种改进相当于需要减少约8%的计算和数据来达到相同的测试损失。

Conclusion: 将拼写信息融入嵌入层是一种简单而有效的方法，能够显著提升模型性能，减少训练所需的计算和数据资源，为自然语言处理模型的改进提供了新的思路。

Abstract: We introduce a simple modification to the embedding layer. The key change is to infuse token embeddings with information about their spelling. Models trained with these embeddings improve not only on spelling, but also across standard benchmarks. We conduct scaling studies for models with 40M to 800M parameters, which suggest that the improvements are equivalent to needing about 8% less compute and data to achieve the same test loss.

</details>


### [207] [Multimodal Machine Learning for Soft High-k Elastomers under Data Scarcity](https://arxiv.org/abs/2601.18032)
*Brijesh FNU,Viet Thanh Duy Nguyen,Ashima Sharma,Md Harun Rashid Molla,Chengyi Xu,Truong-Son Hy*

Main category: cs.LG

TL;DR: 该研究构建了丙烯酸酯基介电弹性体的高质量数据集，并开发了基于预训练多模态学习的框架，用于从分子序列预测介电和机械性能，解决了软电子材料数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 随着软可拉伸电子技术的发展，需要高性能介电弹性体，但现有材料难以同时具备高介电常数和低杨氏模量。目前缺乏系统包含分子序列、介电和机械性能的结构化数据集，限制了数据驱动的材料发现。

Method: 1. 通过筛选过去10年文献中的实验结果，构建了丙烯酸酯基介电弹性体的高质量数据集；2. 提出多模态学习框架，利用基于图和序列编码器的大规模预训练聚合物表示；3. 通过预训练嵌入传递丰富的化学和结构知识，实现从分子序列准确预测介电和机械性能。

Result: 开发的数据集和框架能够准确进行少样本预测，克服了数据稀缺问题。该方法可推广到其他聚合物骨架（如硅酮、聚氨酯），加速软高介电常数弹性体的数据高效发现。

Conclusion: 该研究提出了从预训练多模态模型转移知识的新范式，解决了聚合物材料数据稀缺问题，为加速高性能介电弹性体的发现提供了有效工具。数据集和源代码已公开。

Abstract: Dielectric materials are critical building blocks for modern electronics such as sensors, actuators, and transistors. With the rapid recent advance in soft and stretchable electronics for emerging human- and robot-interfacing applications, there is a surging need for high-performance dielectric elastomers. However, it remains a grand challenge to develop soft elastomers that simultaneously possess high dielectric constants (k, related to energy storage capacity) and low Young's moduli (E, related to mechanical flexibility). While some new elastomer designs have been reported in individual (mostly one-off) studies, almost no structured dataset is currently available for dielectric elastomers that systematically encompasses their molecular sequence, dielectric, and mechanical properties. Within this context, we curate a compact, high-quality dataset of acrylate-based dielectric elastomers, one of the most widely explored elastomer backbones due to its versatile chemistry and molecular design flexibility, by screening and aggregating experimental results from the literature over the past 10 years. Building on this dataset, we propose a multimodal learning framework that leverages large-scale pretrained polymer representations from graph- and sequence-based encoders. These pretrained embeddings transfer rich chemical and structural knowledge from vast polymer corpora, enabling accurate few-shot prediction of both dielectric and mechanical properties from molecular sequences. Our results represent a new paradigm for transferring knowledge from pretrained multimodal models to overcome severe data scarcity, which can be readily translated to other polymer backbones (e.g., silicones, urethanes) and thus accelerate data-efficient discovery of soft high-k dielectric elastomers. Our source code and dataset are publicly available at https://github.com/HySonLab/Polymers

</details>


### [208] [Comparison requires valid measurement: Rethinking attack success rate comparisons in AI red teaming](https://arxiv.org/abs/2601.18076)
*Alexandra Chouldechova,A. Feder Cooper,Solon Barocas,Abhinav Palia,Dan Vann,Hanna Wallach*

Main category: cs.LG

TL;DR: 论文指出AI红队评估中基于攻击成功率比较得出的系统安全性或攻击方法有效性结论往往缺乏证据支持，因为这些比较存在苹果与橙子对比或测量效度低的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全评估中，研究人员经常通过攻击成功率（ASR）的比较来得出关于系统相对安全性或攻击方法有效性的结论，但这些结论往往缺乏坚实的证据基础，因为ASR比较存在方法论问题。

Method: 采用社会科学测量理论和推断统计学的方法论框架，提出了攻击成功率有意义的比较条件。以越狱攻击为例，通过概念、理论和实证分析，展示了ASR比较中的苹果与橙子对比问题和测量效度挑战。

Result: 研究表明许多基于ASR比较的结论存在方法论缺陷，包括不恰当的比较基准、测量效度不足等问题。论文明确了ASR可以和不可以在什么条件下进行有意义的比较。

Conclusion: AI红队评估需要更严谨的方法论基础，攻击成功率的比较必须满足特定的测量和统计条件才能得出有效结论。研究者应该避免苹果与橙子的比较，并提高测量效度以确保评估结果的可信度。

Abstract: We argue that conclusions drawn about relative system safety or attack method efficacy via AI red teaming are often not supported by evidence provided by attack success rate (ASR) comparisons. We show, through conceptual, theoretical, and empirical contributions, that many conclusions are founded on apples-to-oranges comparisons or low-validity measurements. Our arguments are grounded in asking a simple question: When can attack success rates be meaningfully compared? To answer this question, we draw on ideas from social science measurement theory and inferential statistics, which, taken together, provide a conceptual grounding for understanding when numerical values obtained through the quantification of system attributes can be meaningfully compared. Through this lens, we articulate conditions under which ASRs can and cannot be meaningfully compared. Using jailbreaking as a running example, we provide examples and extensive discussion of apples-to-oranges ASR comparisons and measurement validity challenges.

</details>


### [209] [DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal](https://arxiv.org/abs/2601.18081)
*Peixuan Han,Yingjie Yu,Jingjun Xu,Jiaxuan You*

Main category: cs.LG

TL;DR: DRPG是一个用于自动生成学术反驳的智能体框架，通过分解、检索、规划和生成四步流程，显著提升了反驳质量，在顶级会议数据上超越了现有方法和人类平均水平。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在科研工作流中应用日益广泛，但学术反驳这一学术交流和同行评审的关键环节仍缺乏有效的自动化支持。现有方法通常依赖现成的大语言模型或简单流程，难以处理长上下文，且无法生成有针对性和说服力的回应。

Method: 提出DRPG框架，包含四个步骤：1) 将审稿意见分解为原子化关注点；2) 从论文中检索相关证据；3) 规划反驳策略；4) 基于策略生成回应。其中规划器在识别最可行反驳方向方面准确率超过98%。

Result: 在顶级会议数据上的实验表明，DRPG显著优于现有反驳流程，仅使用8B参数的模型就达到了超越人类平均水平的性能。规划器设计被证明有效，能提供多视角和可解释的建议。框架在更复杂的多轮设置中也表现良好。

Conclusion: DRPG框架展示了在学术反驳生成方面的有效性，具有提供高质量反驳内容和支持学术讨论规模化的潜力。代码已开源，为学术交流自动化提供了实用工具。

Abstract: Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent.

</details>


### [210] [LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts](https://arxiv.org/abs/2601.18089)
*Venmugil Elango,Nidhi Bhatia,Roger Waleffe,Rasoul Shafipour,Tomer Asida,Abhinav Khattar,Nave Assaf,Maximilian Golub,Joey Guman,Tiyasa Mitra,Ritchie Zhao,Ritika Borkar,Ran Zilberstein,Mostofa Patwary,Mohammad Shoeybi,Bita Rouhani*

Main category: cs.LG

TL;DR: LatentMoE是一种新的混合专家架构，通过硬件-软件协同设计优化推理成本，在准确率与计算量/参数比方面优于标准MoE架构，已被Nemotron-3模型采用。


<details>
  <summary>Details</summary>
Motivation: 尽管混合专家(MoE)架构在大型语言模型中广泛应用，但现有架构在推理成本（以准确率与浮点运算/参数比衡量）方面的最优性尚不明确，需要从硬件-软件协同设计角度重新审视。

Method: 从硬件-软件协同设计角度出发，基于经验和理论分析，在不同部署场景（离线高吞吐和在线低延迟）下识别性能瓶颈，通过系统化设计空间探索（95B参数规模，1T token训练）开发LatentMoE架构。

Result: LatentMoE在准确率与FLOP比和准确率与参数比方面持续优于标准MoE架构，该架构已被Nemotron-3 Super和Ultra模型采用，并扩展到更大规模（更长token序列和更大模型尺寸）。

Conclusion: 通过硬件-软件协同设计的系统化探索，LatentMoE架构在推理成本优化方面优于现有MoE架构，为大型语言模型提供了更高效的混合专家设计方案。

Abstract: Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).

</details>


### [211] [From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models](https://arxiv.org/abs/2601.18091)
*Longwei Ding,Anhao Zhao,Fanghua Ye,Ziyang Chen,Xiaoyu Shen*

Main category: cs.LG

TL;DR: 该研究对比了指令遵循型LLM和推理增强型LLM的剪枝策略效果，发现不同范式下剪枝效果存在显著差异，需要针对推理增强模型设计专门的剪枝方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注指令遵循型大语言模型的剪枝，但缺乏对推理增强型模型（生成长中间推理轨迹）剪枝策略的研究。需要明确现有剪枝方法是否适用于这两种不同类型的模型。

Method: 通过控制实验对比指令遵循型（LLM-instruct）和推理增强型（LLM-think）模型的剪枝效果。将剪枝校准和后剪枝恢复数据与模型原始训练分布对齐以确保稳定性。评估静态深度剪枝、静态宽度剪枝和动态剪枝三种策略，在17个任务（分类、生成、推理）上进行测试。

Result: 发现范式依赖的明显差异：深度剪枝在分类任务上表现更好，宽度剪枝在生成和推理任务上更稳健；静态剪枝能更好地保持推理性能，而动态剪枝在分类和生成任务上表现优异，但对长链推理仍具挑战性。

Conclusion: 推理增强型LLM需要专门考虑其特性的剪枝策略，不能简单套用指令遵循型模型的剪枝方法。研究强调了针对不同模型范式设计定制化剪枝方案的重要性。

Abstract: Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\textbf{LLM-instruct}$) and reasoning-augmented ($\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at https://github.com/EIT-NLP/LRM-Pruning.

</details>


### [212] [Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions](https://arxiv.org/abs/2601.18107)
*Pedram Agand,Mo Chen*

Main category: cs.LG

TL;DR: MoReBRAC是一个基于模型的离线强化学习框架，通过不确定性感知的潜在空间合成来缓解分布偏移问题，在D4RL基准测试中表现出色，特别是在随机和次优数据场景下。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在安全关键领域（如工业机器人）具有巨大潜力，但面临静态数据集与学习策略之间的分布偏移问题，这通常需要高度保守的方法，限制了策略改进的潜力。

Method: MoReBRAC采用基于模型的框架，使用双循环世界模型合成高保真度转换来扩展训练流形。为确保合成数据的可靠性，实现了分层不确定性管道，集成变分自编码器流形检测、模型敏感性分析和蒙特卡洛dropout，多层过滤确保只使用学习动态高置信区域的转换。

Result: 在D4RL Gym-MuJoCo基准测试中显示出显著的性能提升，特别是在"随机"和"次优"数据场景下。进一步分析了VAE作为几何锚点的作用，并讨论了从接近最优数据集中学习时的分布权衡。

Conclusion: MoReBRAC通过不确定性感知的潜在空间合成有效解决了离线强化学习中的分布偏移问题，在数据质量较差的情况下仍能实现显著的性能改进，为安全关键领域的应用提供了有前景的解决方案。

Abstract: Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.

</details>


### [213] [AttenMIA: LLM Membership Inference Attack through Attention Signals](https://arxiv.org/abs/2601.18110)
*Pedram Zaree,Md Abdullah Al Mamun,Yue Dong,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: AttenMIA：利用Transformer自注意力模式进行成员推断攻击的新框架，相比传统基于置信度或嵌入的方法，在低误报率下表现更优，能显著提升训练数据提取攻击效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练数据集的庞大性使其容易记忆训练数据，引发严重的隐私和知识产权问题。现有成员推断攻击主要依赖输出置信度或嵌入特征，但这些信号往往脆弱，攻击成功率有限。

Method: 提出AttenMIA框架，利用Transformer模型内部的自注意力模式推断成员身份。注意力控制Transformer内部信息流，揭示用于记忆识别的不同模式。方法使用跨层注意力头信息，结合基于扰动的发散度量来训练有效的MIA分类器。

Result: 在LLaMA-2、Pythia和Opt等开源模型上的广泛实验表明，基于注意力的特征始终优于基线方法，特别是在重要的低误报率指标下（如在WikiMIA-32基准测试中，使用Llama2-13b达到0.996 ROC AUC和87.9% TPR@1%FPR）。注意力信号在不同数据集和架构间具有泛化性，层和头级分析显示成员信息泄露最明显的位置。在数据提取框架中使用AttenMIA替换其他成员推断攻击，能实现优于现有技术水平的数据提取攻击。

Conclusion: 注意力机制原本旨在增强可解释性，却无意中放大了LLMs中的隐私风险，突显了开发新防御措施的必要性。AttenMIA展示了利用模型内部注意力模式进行成员推断的有效性，为隐私保护提出了新的挑战。

Abstract: Large Language Models (LLMs) are increasingly deployed to enable or improve a multitude of real-world applications. Given the large size of their training data sets, their tendency to memorize training data raises serious privacy and intellectual property concerns. A key threat is the membership inference attack (MIA), which aims to determine whether a given sample was included in the model's training set. Existing MIAs for LLMs rely primarily on output confidence scores or embedding-based features, but these signals are often brittle, leading to limited attack success. We introduce AttenMIA, a new MIA framework that exploits self-attention patterns inside the transformer model to infer membership. Attention controls the information flow within the transformer, exposing different patterns for memorization that can be used to identify members of the dataset. Our method uses information from attention heads across layers and combines them with perturbation-based divergence metrics to train an effective MIA classifier. Using extensive experiments on open-source models including LLaMA-2, Pythia, and Opt models, we show that attention-based features consistently outperform baselines, particularly under the important low-false-positive metric (e.g., achieving up to 0.996 ROC AUC & 87.9% TPR@1%FPR on the WikiMIA-32 benchmark with Llama2-13b). We show that attention signals generalize across datasets and architectures, and provide a layer- and head-level analysis of where membership leakage is most pronounced. We also show that using AttenMIA to replace other membership inference attacks in a data extraction framework results in training data extraction attacks that outperform the state of the art. Our findings reveal that attention mechanisms, originally introduced to enhance interpretability, can inadvertently amplify privacy risks in LLMs, underscoring the need for new defenses.

</details>


### [214] [Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting](https://arxiv.org/abs/2601.18111)
*Jean Kossaifi,Nikola Kovachki,Morteza Mardani,Daniel Leibovici,Suman Ravuri,Ira Shokar,Edoardo Calvello,Mohammad Shoaib Abbas,Peter Harrington,Ashay Subramaniam,Noah Brenowitz,Boris Bonev,Wonmin Byeon,Karsten Kreis,Dale Durran,Arash Vahdat,Mike Pritchard,Jan Kautz*

Main category: cs.LG

TL;DR: 该论文提出一个可扩展的多尺度大气动力学学习框架，通过降采样潜在空间和历史条件局部投影器实现高分辨率物理建模，无需复杂架构或专门训练策略即可达到最先进的概率预报技能。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的天气预报方法导致架构和训练策略碎片化，复杂且定制化，掩盖了预报准确性的基本驱动因素。作者旨在证明最先进的概率预报技能不需要复杂的架构约束或专门的训练启发式方法。

Method: 引入一个可扩展的多尺度大气动力学学习框架，结合直接降采样的潜在空间和历史条件局部投影器来解析高分辨率物理。该框架设计对概率估计器的选择具有鲁棒性，无缝支持随机插值、扩散模型和基于CRPS的集成训练。

Result: 与集成预报系统和深度学习概率模型GenCast相比，该框架在大多数变量上实现了统计显著的改进。验证表明该框架能够达到最先进的中期预报性能。

Conclusion: 扩展通用模型足以实现最先进的中期预测，无需定制化训练方案，并且在所有概率框架范围内都有效。这简化了天气预报模型的开发流程。

Abstract: The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks.

</details>


### [215] [Robust Learning of a Group DRO Neuron](https://arxiv.org/abs/2601.18115)
*Guyang Cao,Shuyao Li,Sushrut Karmalkar,Jelena Diakonikolas*

Main category: cs.LG

TL;DR: 该论文研究在任意标签噪声和组级分布偏移下学习单个神经元的问题，提出一种群体分布鲁棒优化方法，通过原对偶算法获得与最优参数竞争的解。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据常存在标签噪声和分布偏移，传统学习方法在这些情况下性能下降。需要开发鲁棒的学习方法，能在最坏情况下的组权重分配中保持良好性能。

Method: 提出群体分布鲁棒优化框架，使用f-散度惩罚偏离均匀组权重。开发计算高效的原对偶算法，通过双重外推更新处理损失函数的非凸性，直接对抗任意标签损坏和组特定分布偏移。

Result: 算法输出向量在常数因子范围内与最优参数竞争，在最坏情况组权重下保持性能。算法框架在LLM预训练基准上显示出潜力。

Conclusion: 该研究提供了一种鲁棒的学习框架，能在存在任意标签噪声和分布偏移的情况下有效学习单个神经元，为处理现实世界数据中的分布变化提供了理论保证和实用算法。

Abstract: We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\mathcal p_{[1]},\dots,\mathcal p_{[K]}$, we seek to approximate $\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\boldsymbolλ \in Δ_K$, where the objective is $\sum_{i \in [K]}λ_{[i]}\,\mathbb E_{(\mathbf x,y)\sim\mathcal p_{[i]}}(σ(\mathbf w\cdot\mathbf x)-y)^2 - νd_f(\boldsymbolλ,\frac{1}{K}\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $ν\geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\widehat{\mathbf w}$ that is constant-factor competitive with $\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.

</details>


### [216] [Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods](https://arxiv.org/abs/2601.18142)
*Mingxu Zhang,Huicheng Zhang,Jiaming Ji,Yaodong Yang,Ying Sun*

Main category: cs.LG

TL;DR: 本文提出ADRC-Lagrangian方法，将主动抗扰控制引入安全强化学习，显著减少安全违规和振荡，相比传统方法提升安全性能。


<details>
  <summary>Details</summary>
Motivation: 现有安全强化学习方法（包括PID和经典Lagrangian方法）存在振荡频繁、安全违规多的问题，主要原因是参数敏感性和固有的相位滞后，需要更鲁棒的解决方案。

Method: 提出ADRC-Lagrangian方法，将主动抗扰控制（ADRC）技术融入Lagrangian框架，增强鲁棒性并减少振荡，该统一框架包含经典和PID Lagrangian方法作为特例。

Result: 实验表明，该方法能将安全违规减少74%，约束违规幅度降低89%，平均成本降低67%，在复杂环境中表现出优越的安全强化学习效果。

Conclusion: ADRC-Lagrangian方法通过引入主动抗扰控制，有效解决了传统安全强化学习方法中的振荡和安全违规问题，为复杂环境下的安全强化学习提供了更有效的解决方案。

Abstract: Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74%, constraint violation magnitudes by 89%, and average costs by 67\%, establishing superior effectiveness for Safe RL in complex environments.

</details>


### [217] [FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning](https://arxiv.org/abs/2601.18150)
*Zhaopeng Qiu,Shuang Yu,Jingqi Zhang,Shuai Zhang,Xue Huang,Jingyi Yang,Junjie Lai*

Main category: cs.LG

TL;DR: 该论文提出了一个实用的FP8 rollout堆栈，用于大型语言模型的强化学习，通过FP8量化和KV缓存优化，实现了高达44%的生成吞吐量提升，同时保持与BF16基线相当的学习性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型强化学习中，长输出序列的生成过程成为瓶颈，注意力机制和KV缓存内存消耗主导了端到端时间。FP8提供了加速RL的潜力，但存在工程和算法挑战：策略权重频繁变化需要重复量化，低精度生成可能导致训练-推理不匹配。

Method: 1) 使用块状FP8量化实现FP8 W8A8线性层生成；2) 通过每步QKV尺度重新校准将FP8扩展到KV缓存，解决长上下文内存瓶颈；3) 使用基于重要性采样的生成校正（token级TIS/MIS变体）缓解不匹配问题。

Result: 在密集和MoE模型上，这些技术实现了高达44%的生成吞吐量提升，同时保持了与BF16基线相当的学习行为。

Conclusion: 该研究提出了一个实用的FP8生成堆栈，有效解决了大型语言模型强化学习中的生成瓶颈，通过FP8量化、KV缓存优化和校正技术，在保持学习性能的同时显著提升了生成效率。

Abstract: Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.

</details>


### [218] [Learning Fair Domain Adaptation with Virtual Label Distribution](https://arxiv.org/abs/2601.18171)
*Yuguang Zhang,Lijun Sheng,Jian Liang,Ran He*

Main category: cs.LG

TL;DR: VILL框架通过自适应重加权和KL散度再平衡策略，解决无监督域适应中的类别公平性问题，提升最差类别性能同时保持高总体准确率。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应方法大多关注总体准确率提升，但忽视了不同类别之间的性能差异（类别公平性问题）。实证分析发现UDA分类器倾向于偏向易分类别而忽视难分类别。

Method: 提出虚拟标签分布感知学习（VILL）框架，包含自适应重加权策略（放大难分类别影响）和基于KL散度的再平衡策略（显式调整决策边界以增强类别公平性）。

Result: 在常用数据集上的实验表明，VILL可以作为即插即用模块无缝集成到现有UDA方法中，显著改善类别公平性。

Conclusion: VILL是一个简单有效的框架，能够解决UDA中的类别公平性问题，提升最差类别性能同时保持高总体准确率。

Abstract: Unsupervised Domain Adaptation (UDA) aims to mitigate performance degradation when training and testing data are sampled from different distributions. While significant progress has been made in enhancing overall accuracy, most existing methods overlook performance disparities across categories-an issue we refer to as category fairness. Our empirical analysis reveals that UDA classifiers tend to favor certain easy categories while neglecting difficult ones. To address this, we propose Virtual Label-distribution-aware Learning (VILL), a simple yet effective framework designed to improve worst-case performance while preserving high overall accuracy. The core of VILL is an adaptive re-weighting strategy that amplifies the influence of hard-to-classify categories. Furthermore, we introduce a KL-divergence-based re-balancing strategy, which explicitly adjusts decision boundaries to enhance category fairness. Experiments on commonly used datasets demonstrate that VILL can be seamlessly integrated as a plug-and-play module into existing UDA methods, significantly improving category fairness.

</details>


### [219] [Smooth, Sparse, and Stable: Finite-Time Exact Skeleton Recovery via Smoothed Proximal Gradients](https://arxiv.org/abs/2601.18189)
*Rui Wu,Yongjun Li*

Main category: cs.LG

TL;DR: 提出AHOC混合阶无环约束和SPG-AHOC算法，通过近端算法的流形识别特性，理论上保证有限时间内精确恢复DAG结构，无需后处理阈值化


<details>
  <summary>Details</summary>
Motivation: 现有连续优化方法（如NOTEARS）通常只能保证渐近收敛到驻点，产生稠密权重矩阵，需要任意的后处理阈值化才能恢复DAG。连续优化与离散图结构之间的差距是根本性挑战。

Method: 提出混合阶无环约束（AHOC），通过平滑近端梯度（SPG-AHOC）进行优化。利用近端算法的流形识别特性，在标准可识别性假设下，算法能在有限迭代中精确恢复DAG支撑（结构）。

Result: 理论上证明了有限时间预言属性：SPG-AHOC在有限迭代中恢复精确的DAG支撑结构，即使优化的是平滑近似。算法返回具有精确零条目的图，无需启发式截断。实验上达到最先进精度，强有力地证实了有限时间识别理论。

Conclusion: 通过AHOC约束和SPG-AHOC算法，成功弥合了连续优化与离散图结构之间的差距，提供了有限时间内精确恢复DAG结构的理论保证，消除了结构模糊性。

Abstract: Continuous optimization has significantly advanced causal discovery, yet existing methods (e.g., NOTEARS) generally guarantee only asymptotic convergence to a stationary point. This often yields dense weighted matrices that require arbitrary post-hoc thresholding to recover a DAG. This gap between continuous optimization and discrete graph structures remains a fundamental challenge. In this paper, we bridge this gap by proposing the Hybrid-Order Acyclicity Constraint (AHOC) and optimizing it via the Smoothed Proximal Gradient (SPG-AHOC). Leveraging the Manifold Identification Property of proximal algorithms, we provide a rigorous theoretical guarantee: the Finite-Time Oracle Property. We prove that under standard identifiability assumptions, SPG-AHOC recovers the exact DAG support (structure) in finite iterations, even when optimizing a smoothed approximation. This result eliminates structural ambiguity, as our algorithm returns graphs with exact zero entries without heuristic truncation. Empirically, SPG-AHOC achieves state-of-the-art accuracy and strongly corroborates the finite-time identification theory.

</details>


### [220] [Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting](https://arxiv.org/abs/2601.18231)
*Trong Khiem Tran,Manh Cuong Dao,Phi Le Nguyen,Thao Nguyen Truong,Trong Nghia Hoang*

Main category: cs.LG

TL;DR: 该论文提出了一个理论框架来分析预训练模型适应新特征模态时特征对齐与目标拟合之间的交互作用，通过特征标签失真概念建立了可证明的泛化边界，并基于此设计了改进的算法。


<details>
  <summary>Details</summary>
Motivation: 预训练模型适应未见过的特征模态变得越来越重要，但现有方法缺乏对特征对齐和目标拟合之间关键交互作用的理论理解，未校准的组合会加剧源域和目标域特征-标签结构的错配，降低目标泛化能力。

Method: 开发了一个原则性框架，通过新颖的特征标签失真概念建立了目标误差的可证明泛化边界，该边界解释了特征对齐与目标拟合之间的交互作用，并为实际算法设计提供了可操作的优化指导。

Result: 基于该理论框架设计的方法在广泛的基准数据集上显著优于现有最先进方法，取得了显著改进的性能。

Conclusion: 该研究填补了特征对齐与目标拟合交互作用理论理解的空白，提出的理论框架不仅解释了这一关键交互作用，还为实际算法设计提供了指导，实现了更好的跨模态知识迁移性能。

Abstract: Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.

</details>


### [221] [Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity](https://arxiv.org/abs/2601.18245)
*Santanu Das,Jatin Batra*

Main category: cs.LG

TL;DR: 本文提出了首个多项式时间算法，用于解决具有重尾噪声和对抗性损坏的鲁棒相位恢复问题，实现了接近线性的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 相位恢复是一个经典问题，在光学、晶体学、异方差回归、天体物理学等领域有广泛应用。传统算法对测量误差的鲁棒性有限，特别是在存在重尾噪声和对抗性损坏的情况下。虽然最近在鲁棒统计算法方面取得了突破，但现有的鲁棒相位恢复算法要么是指数时间复杂度的，要么缺乏有效的鲁棒谱初始化方法。

Method: 通过建立鲁棒谱初始化与鲁棒主成分分析（PCA）最新算法进展之间的联系，开发了多项式时间算法。该方法利用鲁棒PCA技术来获得鲁棒的谱初始化，这是相位恢复算法的关键组成部分，特别是在处理重尾噪声和对抗性损坏时。

Result: 实现了首个多项式时间算法，用于解决具有重尾噪声和对抗性损坏的鲁棒相位恢复问题。算法具有接近线性（相对于n）的样本复杂度，显著优于之前AISTATS 2025提出的指数时间算法（需要O(n log n)样本）。

Conclusion: 通过将鲁棒相位恢复中的谱初始化问题与鲁棒PCA的最新进展联系起来，成功开发了高效的多项式时间算法，解决了之前被认为超出已知高效算法技术范围的问题，为鲁棒相位恢复提供了实用的解决方案。

Abstract: Phase retrieval is the classical problem of recovering a signal $x^* \in \mathbb{R}^n$ from its noisy phaseless measurements $y_i = \langle a_i, x^* \rangle^2 + ζ_i$ (where $ζ_i$ denotes noise, and $a_i$ is the sensing vector) for $i \in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity.

</details>


### [222] [Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs](https://arxiv.org/abs/2601.18255)
*Fei Meng*

Main category: cs.LG

TL;DR: 本文揭示了经验回放在大语言模型持续学习中的关键二分现象：对非结构化任务产生正向迁移，但对结构化任务（如代码生成）造成负向迁移，并提出正交子空间唤醒方法来解决这一困境。


<details>
  <summary>Details</summary>
Motivation: 大语言模型持续学习面临平衡稳定性（保留旧知识）和可塑性（学习新任务）的关键挑战。经验回放作为防止灾难性遗忘的标准对策，其在不同能力上的影响尚未得到充分探索。

Method: 提出正交子空间唤醒方法：通过短暂的"唤醒"阶段识别先前任务的关键参数子空间，并强制新任务进行正交更新，为已建立的知识结构提供数学基础的"安全保证"。

Result: 在多样化的四任务序列上的实证结果表明，OSW在经验回放失败的脆弱编码能力保护方面表现独特，同时保持了对新任务的高可塑性。

Conclusion: 研究强调了在大语言模型持续学习中评估结构安全性与平均保留同等重要，OSW方法为解决经验回放的局限性提供了有效解决方案。

Abstract: Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief "wake-up" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded "safety guarantee" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.

</details>


### [223] [FGGM: Fisher-Guided Gradient Masking for Continual Learning](https://arxiv.org/abs/2601.18261)
*Chao-Hong Tan,Qian Chen,Wen Wang,Yukun Ma,Chong Zhang,Chong Deng,Qinglin Zhang,Xiangang Li,Jieping Ye*

Main category: cs.LG

TL;DR: FGGM框架通过Fisher信息指导的梯度掩码缓解大语言模型持续学习中的灾难性遗忘问题，在TRACE基准上相比SFT提升9.6%，相比MIGU提升4.4%


<details>
  <summary>Details</summary>
Motivation: 大语言模型在持续学习中面临灾难性遗忘问题，现有基于参数幅度的方法（如MIGU）缺乏数学原理基础，需要更有效的参数重要性评估方法来平衡稳定性和可塑性

Method: 提出Fisher-Guided Gradient Masking (FGGM)框架，使用对角Fisher信息战略性地选择需要更新的参数，动态生成具有自适应阈值的二进制掩码，保护关键参数而不需要历史数据

Result: 在TRACE基准上，FGGM相比监督微调(SFT)在保留通用能力方面有9.6%的相对提升，相比MIGU在TRACE任务上有4.4%的提升；在代码生成任务上的额外分析证实了FGGM的优越性能和减少的遗忘

Conclusion: FGGM通过基于数学原理的参数重要性估计，有效缓解了大语言模型的灾难性遗忘问题，在平衡稳定性和可塑性方面表现出色，是一种有效的持续学习解决方案

Abstract: Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.

</details>


### [224] [What Do Learned Models Measure?](https://arxiv.org/abs/2601.18278)
*Indrė Žliobaitė*

Main category: cs.LG

TL;DR: 论文提出"学习测量函数"作为机器学习模型的新评估维度，指出传统预测性能评估无法保证测量稳定性，需要新的评估框架。


<details>
  <summary>Details</summary>
Motivation: 在科学和数据驱动应用中，机器学习模型越来越多地被用作测量工具而非仅仅是预测器。当测量函数从数据中学习时，从观察到数量的映射由训练分布和归纳偏置隐式决定，导致多个不等价的映射都能满足标准预测评估标准。

Method: 将学习测量函数形式化为一个独立的评估焦点，引入测量稳定性概念，该属性捕捉了学习过程的可容许实现和跨上下文中测量量的不变性。

Result: 研究表明标准机器学习评估标准（包括泛化误差、校准和鲁棒性）不能保证测量稳定性。通过真实案例研究显示，具有可比预测性能的模型可以实现系统不等价的测量函数，分布偏移具体说明了这种失败。

Conclusion: 当学习模型输出被识别为测量时，现有评估框架存在局限性，需要增加额外的评估维度来确保测量稳定性。

Abstract: In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.

</details>


### [225] [TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292)
*Zhewen Tan,Wenhan Yu,Jianfeng Si,Tongxin Liu,Kaiqi Guan,Huiyan Jin,Jiawen Tao,Xiaokun Yuan,Duohe Ma,Xiangzheng Zhang,Tong Yang,Lin Sun*

Main category: cs.LG

TL;DR: TriPlay-RL：一个基于强化学习的闭环框架，通过攻击者、防御者和评估者三个角色的协同进化，实现大语言模型安全对齐的持续改进，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的安全风险日益突出，需要减少有害内容的生成。现有主流安全对齐范式通常采用攻击者、防御者、评估者三个角色的协作框架，但缺乏高效的协同进化机制。

Method: 提出TriPlay-RL闭环强化学习框架，使三个角色能够在近乎零人工标注的情况下进行迭代式协同改进。攻击者生成对抗性提示，防御者进行安全防御，评估者评估响应质量，三者通过强化学习相互促进。

Result: 攻击者在保持高输出多样性的同时，对抗效果提升20%-50%；防御者在安全性能上获得10%-30%的提升，且不降低通用推理能力；评估者通过迭代持续优化细粒度判断能力，能准确区分不安全响应、简单拒绝和有用指导。

Conclusion: TriPlay-RL为大语言模型安全对齐建立了一个高效、可扩展的范式，能够在统一的学习循环中实现三个角色的持续协同进化。

Abstract: In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.

</details>


### [226] [Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals](https://arxiv.org/abs/2601.18326)
*Jie Li,Jing Li,Lu Lv,Zhanyu Ju,Fengkui Gong*

Main category: cs.LG

TL;DR: 提出基于ZC序列和时频图像认知融合的无人机信号分布外检测算法，在无人机远程识别任务中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 为了解决无人机信号分布外检测问题，特别是针对未知或非标准通信协议的无人机信号识别挑战

Method: 通过分析DJI无人机通信协议提取ZC序列特征，同时使用时频图像捕捉未知协议信号特征，采用多模态特征提取、交互和融合机制，结合自适应注意力权重进行分类

Result: 在远程识别和分布外检测指标上分别提升1.7%和7.5%，在不同飞行条件和无人机类型下表现出强鲁棒性

Conclusion: 提出的多模态融合算法有效提升了无人机信号分布外检测性能，为无人机远程识别提供了可靠解决方案

Abstract: We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types.

</details>


### [227] [Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection](https://arxiv.org/abs/2601.18329)
*Chuhan Feng,Jing Li,Jie Li,Lu Lv,Fengkui Gong*

Main category: cs.LG

TL;DR: 提出基于可区分性驱动的空间-通道选择和梯度范数的无人机信号OOD检测算法，通过时频图像特征自适应加权和梯度范数度量扰动敏感性，实现优异的OOD检测性能


<details>
  <summary>Details</summary>
Motivation: 无人机信号检测中，传统方法难以有效识别分布外（OOD）样本，需要开发能够自适应利用时频特征并量化OOD样本内在不稳定性的检测算法

Method: 1. 基于协议特定时频特征量化类间相似性和方差，自适应加权时频图像特征的空间和通道维度；2. 引入梯度范数度量扰动敏感性，捕捉OOD样本的内在不稳定性；3. 将梯度范数与基于能量的分数融合进行联合推理

Result: 仿真结果表明，该算法在不同信噪比和各种无人机类型下均表现出优越的区分能力和鲁棒性能

Conclusion: 提出的基于可区分性驱动的空间-通道选择和梯度范数的OOD检测算法能有效识别无人机信号中的OOD样本，具有优异的检测性能和鲁棒性

Abstract: We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.

</details>


### [228] [Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning](https://arxiv.org/abs/2601.18356)
*Weiqin Yang,Haowen Xue,Qingyi Peng,Hexuan Hu,Qian Huang,Tingbo Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种多模态因果检索增强生成框架，将因果推理原理与多模态检索相结合，以解决医学视觉语言模型依赖表面统计关联而非因果病理机制的问题。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型虽然在某些任务上表现良好，但其推理机制本质上是相关性的，依赖于表面的统计关联，未能捕捉临床决策所需的因果病理机制。这使得模型脆弱、易产生幻觉，并对数据集偏差敏感。

Method: 提出了多模态因果检索增强生成框架，从外部源检索临床相关示例和因果图，将模型推理建立在反事实和干预证据而非单纯相关性之上。

Result: 应用于放射学报告生成、诊断预测和视觉问答任务时，该方法提高了事实准确性、对分布偏移的鲁棒性以及可解释性。

Conclusion: 因果检索为医学视觉语言模型提供了一条可扩展的路径，使其能够超越模式匹配，在高风险临床环境中实现可信赖的多模态推理。

Abstract: Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.

</details>


### [229] [Superlinear Multi-Step Attention](https://arxiv.org/abs/2601.18401)
*Yufeng Huang*

Main category: cs.LG

TL;DR: 提出Superlinear attention架构，通过多步搜索实现长序列的次二次复杂度，同时保持随机上下文访问能力，在1M和10M上下文长度下实现高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 解决传统自注意力机制在处理长序列时的二次复杂度问题，同时保持结构非排除特性（即所有符合条件的token位置都能被注意力机制访问）。

Method: 将标准因果自注意力重新表述为N步搜索问题，提出Superlinear attention架构。以N=2为例，第一步进行O(L^{3/2})的跨度搜索选择相关序列段，第二步在选定段上应用O(L^{3/2})的跨度注意力。

Result: 在O(L^{1.54})配置下，在单B200 GPU上，1M上下文长度平均解码吞吐量达114 tokens/sec，10M上下文长度达80 tokens/sec。在NIAH任务上，256K上下文长度表现良好，证明路由跨度选择可端到端学习。

Conclusion: Superlinear attention架构在保持随机上下文访问的同时实现了次二次复杂度，展示了系统可行性，为长序列处理提供了有前景的解决方案，但全面质量评估需未来工作完成。

Abstract: In this paper, we propose \textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \textbf{random context access} (a.k.a.\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work.

</details>


### [230] [Frequency-Based Hyperparameter Selection in Games](https://arxiv.org/abs/2601.18409)
*Aniket Sanyal,Baraah A. M. Sidahmed,Rebekka Burkholz,Tatjana Chavdarova*

Main category: cs.LG

TL;DR: 提出MoLA方法，通过频率估计自适应调整LookAhead超参数，加速博弈环境中的训练


<details>
  <summary>Details</summary>
Motivation: 光滑博弈中的学习与传统最小化问题不同，存在旋转动力学，使经典超参数调优策略失效。LookAhead方法虽然实用但引入额外参数且性能敏感，需要更有效的博弈超参数调优方法。

Method: 提出Modal LookAhead (MoLA)方法：1) 分析连续时间轨迹和离散动力学频谱中的振荡行为；2) 利用频率估计旋转动力学；3) 自适应选择超参数以适应具体问题。

Result: MoLA在纯旋转博弈和混合机制中都能加速训练，计算开销最小，并提供收敛保证。

Conclusion: 通过频率分析的自适应超参数选择方法MoLA，有效解决了博弈环境中超参数调优的挑战，显著提升训练效率。

Abstract: Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead.

</details>


### [231] [Gradient Regularized Natural Gradients](https://arxiv.org/abs/2601.18420)
*Satya Prakash Dash,Hossein Abdi,Wei Pan,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出GRNG算法，将梯度正则化与自然梯度结合，提升二阶优化器的训练动态和泛化能力


<details>
  <summary>Details</summary>
Motivation: 梯度正则化已被证明能提升模型泛化能力，但二阶优化器如何从梯度正则化中获益的研究较少。自然梯度下降在训练初期能加速优化，但如何结合梯度正则化提升训练动态值得探索。

Method: 提出梯度正则化自然梯度(GRNG)框架，包含两个算法：1) 频率派变体通过结构化近似避免显式Fisher信息矩阵求逆；2) 贝叶斯变体基于正则化卡尔曼公式完全消除FIM求逆需求。

Result: GRNG在收敛性上有理论保证，梯度正则化提升稳定性并确保收敛到全局最小值。实验表明，相比一阶方法(SGD, AdamW)和二阶基线(K-FAC, Sophia)，GRNG在视觉和语言基准上持续提升优化速度和泛化能力。

Conclusion: 梯度正则化是解锁自然梯度方法在大规模深度学习中的鲁棒性的原则性和实用工具，GRNG框架为二阶优化器提供了有效的梯度正则化集成方案。

Abstract: Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.

</details>


### [232] [Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States](https://arxiv.org/abs/2601.18479)
*Kyoleen Kwak,Hyoseok Hwang*

Main category: cs.LG

TL;DR: 提出ASAP方法，通过过渡诱导相似状态和对齐动作来抑制深度强化学习中的高频振荡，实现更平滑的控制


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在控制任务中表现出色，但其固有的高频振荡特性限制了在实际环境中的应用。现有方法通常依赖启发式或合成的状态相似性定义来促进动作一致性，但这些定义往往无法准确反映底层系统动态。

Method: 提出ASAP方法：1）引入过渡诱导相似状态，定义为从前一状态过渡到的下一状态分布，仅使用环境反馈和实际收集数据；2）通过将动作与过渡诱导相似状态中的动作对齐来强制动作平滑性；3）惩罚二阶差异以抑制高频振荡。

Result: 在Gymnasium和Isaac-Lab环境中的实验表明，ASAP方法相比现有方法能够产生更平滑的控制和更好的策略性能。

Conclusion: ASAP方法通过利用过渡诱导相似状态和对齐动作，有效缓解了深度强化学习中的动作振荡问题，为实际应用提供了更可行的解决方案。

Abstract: Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.

</details>


### [233] [Nearly Optimal Bayesian Inference for Structural Missingness](https://arxiv.org/abs/2601.18500)
*Chen Liang,Donghua Yang,Yutong Wang,Tianle Zhang,Shenghe Zhou,Zhiyu Liang,Hengtong Zhang,Hongzhi Wang,Ziqi Li,Xiyang Zhang,Zheng Liang,Yifei Li*

Main category: cs.LG

TL;DR: 论文提出贝叶斯框架处理结构化缺失数据，通过后验预测分布整合不确定性而非单点插补，在分类和插补任务上达到SOTA


<details>
  <summary>Details</summary>
Motivation: 结构化缺失数据存在因果循环困境：预测需要缺失特征，但推断它们又依赖于缺失机制；MNAR下缺失部分可能来自分布偏移；单点插补会锁定不确定性导致过度自信的偏差决策

Method: 采用贝叶斯视角，通过后验预测分布整合完整模型后验不确定性，将学习缺失值后验与标签预测解耦，实现后验积分

Result: 在43个分类和15个插补基准测试中达到SOTA，在SCM先验下具有有限样本近贝叶斯最优性保证

Conclusion: 该框架提供"几乎免费午餐"：一旦学习到后验，预测即插即用同时保持不确定性传播，有效解决结构化缺失数据的因果循环和MNAR问题

Abstract: Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.

</details>


### [234] [Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark](https://arxiv.org/abs/2601.18509)
*Andro Sabashvili*

Main category: cs.LG

TL;DR: 本文综述了时间序列预测中保形预测方法的应用挑战与解决方案，重点分析了如何克服时间序列数据非交换性这一核心问题，并比较了各类算法的实际性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测中的可靠不确定性量化至关重要，但传统方法通常依赖限制性分布假设。保形预测作为一种无分布框架具有理论保证，但时间序列的时序依赖性违反了保形预测的核心交换性假设，需要专门的方法来解决这一冲突。

Method: 本文系统回顾了四类主要算法解决方案：1）放宽交换性假设的方法；2）将数据单位重新定义为独立时间序列集合的方法；3）显式建模预测残差动态的方法；4）适应分布漂移以维持长期覆盖的在线学习算法。

Result: 通过综合比较这些方法，本文强调了计算效率和在实际数据上的性能表现，为时间序列预测中的保形预测应用提供了全面的技术评估和基准测试。

Conclusion: 保形预测为时间序列不确定性量化提供了有前景的无分布框架，但需要专门的方法来处理时序依赖性。本文综述的系统分类和性能比较为研究人员和实践者选择合适的方法提供了指导，推动了该领域的发展。

Abstract: Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data.

</details>


### [235] [From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale](https://arxiv.org/abs/2601.18524)
*Yongqi Jin,Yecheng Wang,Jun-jie Wang,Rong Zhu,Guolin Ke,Weinan E*

Main category: cs.LG

TL;DR: 提出半监督框架，利用数百万文献提取的未标记NMR光谱预测化学位移，无需原子级标注，通过排序损失实现大规模训练，显著提升预测精度和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法依赖有限的人工标注数据集，而NMR化学位移预测对光谱分析和分子结构解析至关重要，需要更有效的数据利用方式

Method: 提出半监督框架，将文献光谱的化学位移预测建模为置换不变集合监督问题，在损失函数满足常见条件下，最优二分匹配简化为基于排序的损失，实现大规模半监督训练

Result: 模型在显著更大更多样的分子数据集上实现了比现有方法更高的精度和鲁棒性，首次在常见NMR溶剂中捕捉到系统性的溶剂效应

Conclusion: 大规模未标记文献光谱可作为训练NMR位移模型的有效数据源，表明文献衍生的弱结构化数据在数据中心的科学AI中具有更广泛作用

Abstract: Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.

</details>


### [236] [Closing the Modality Gap Aligns Group-Wise Semantics](https://arxiv.org/abs/2601.18525)
*Eleonora Grassucci,Giordano Cicchetti,Emanuele Frasca,Aurelio Uncini,Danilo Comminiello*

Main category: cs.LG

TL;DR: 该论文研究了多模态学习中的模态间隙问题，发现虽然CLIP在语义层面有效对齐模态，但模态间隙对实例级任务影响有限，而在群体级任务中影响显著。作者提出了一种减少模态间隙的方法，并证明这能显著提升聚类等群体级任务的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然CLIP在多模态学习中已被广泛采用，但它创建的潜在空间往往只是部分共享的，存在结构不匹配问题（模态间隙）。尽管这种间隙对实例级任务影响有限，但作者认为它对群体级任务可能有重要影响，需要深入研究。

Method: 作者提出了一种新颖的方法来持续减少双模态设置中的模态间隙，并可以简单扩展到一般的n模态情况。该方法旨在更有效地对齐不同模态的表示空间。

Result: 通过广泛评估，作者发现减少模态间隙对传统实例级任务（如检索）只能带来边际或不一致的改进，但对群体级任务（如聚类）却能显著提升性能。这揭示了模态间隙在语义分组任务中的关键作用。

Conclusion: 该研究重塑了对模态间隙的理解，强调了它在提升需要语义分组的任务性能中的关键作用。虽然模态间隙对实例级任务影响有限，但对群体级任务至关重要，这为多模态学习提供了新的研究方向。

Abstract: In multimodal learning, CLIP has been recognized as the \textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.

</details>


### [237] [Information Hidden in Gradients of Regression with Target Noise](https://arxiv.org/abs/2601.18546)
*Arash Jamshidi,Katsiaryna Haitsiukevich,Kai Puolamäki*

Main category: cs.LG

TL;DR: 论文提出了一种通过梯度信息恢复二阶信息（Hessian矩阵）的方法，核心是通过注入高斯噪声使总目标噪声方差等于批量大小，从而让经验梯度协方差近似于Hessian矩阵。


<details>
  <summary>Details</summary>
Motivation: 在许多现代机器学习设置中，只能观察到梯度信息，而二阶信息（如曲率或数据协方差）对于优化、诊断和鲁棒性至关重要。本文旨在解决仅从梯度恢复Hessian矩阵的问题。

Method: 提出方差校准方法：注入高斯噪声使总目标噪声方差等于批量大小。通过这种校准，即使远离最优解，经验梯度协方差也能紧密近似Hessian矩阵。在亚高斯输入下提供了非渐近算子范数保证。

Result: 理论证明：1）提出的方法能有效恢复Hessian矩阵；2）没有这种校准时，恢复可能失败Ω(1)因子；3）方法具有鲁棒性（方差O(n)足以恢复Σ到尺度）；4）实验验证了理论结果在合成和真实数据上的有效性。

Conclusion: 仅通过梯度信息可以恢复二阶信息，提出的"将目标噪声方差设为n"的简单规则是实用且鲁棒的。该方法在预条件加速优化、对抗风险估计和分布式系统中的梯度训练等应用中具有重要价值。

Abstract: Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $Σ$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $Ω(1)$ factor. The proposed method is practical (a "set target-noise variance to $n$" rule) and robust (variance $\mathcal{O}(n)$ suffices to recover $Σ$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.

</details>


### [238] [An Unsupervised Tensor-Based Domain Alignment](https://arxiv.org/abs/2601.18564)
*Chong Hyun Lee,Kibae Lee,Hyun Hee Yim*

Main category: cs.LG

TL;DR: 提出基于张量的域对齐算法，通过对齐矩阵在不变子空间中对齐源和目标张量，使用斜流形约束提供比传统Stiefel流形更大的灵活性，通过正则化项保持方差，实验证明该方法在转换速度和分类准确率上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统张量域对齐方法通常使用Stiefel流形约束，灵活性有限。需要一种更灵活、适应性更强的域对齐方法，能够有效处理复杂域适应任务，同时保持源和目标张量的方差特征。

Method: 提出基于张量的域对齐算法，使用对齐矩阵在不变子空间中对齐源和目标张量。采用斜流形约束进行迭代优化，比传统Stiefel流形更灵活。引入正则化项来保持源和目标张量的方差，确保鲁棒性能。该框架具有通用性，可将现有张量域对齐方法作为特例。

Result: 通过大量实验证明，该方法不仅提高了域对齐转换速度，还显著提升了分类准确率。在复杂域适应任务中表现优于当前最先进技术。

Conclusion: 提出的基于张量的域对齐算法使用斜流形约束，比传统方法更灵活，通过方差保持正则化确保鲁棒性，在速度和准确率上均优于现有技术，是复杂域适应任务的优选方法。

Abstract: We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.

</details>


### [239] [K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents](https://arxiv.org/abs/2601.18580)
*Vincenzo De Paola,Mirco Mutti,Riccardo Zamboni,Marcello Restelli*

Main category: cs.LG

TL;DR: K-Myriad是一种可扩展的无监督方法，通过最大化并行策略群体诱导的集体状态熵，培养专门化探索策略组合，为强化学习提供鲁棒初始化，提高训练效率并发现异构解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习并行化通常用于加速单个策略训练，多个工作者从相同的采样分布收集经验。这种设计限制了并行化的潜力，忽略了多样化探索策略的优势。

Method: 提出K-Myriad方法，通过最大化并行策略群体诱导的集体状态熵，培养专门化探索策略组合。这是一种可扩展的无监督方法，能够实现集体探索。

Result: 在高维连续控制任务和大规模并行化实验中，K-Myriad能够学习到广泛的独特策略，证明了其在集体探索方面的有效性。

Conclusion: K-Myriad为强化学习提供了鲁棒初始化，提高了训练效率并发现了异构解决方案，为新型并行化策略开辟了道路。

Abstract: Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.

</details>


### [240] [Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning](https://arxiv.org/abs/2601.18586)
*Miguel Costa,Arthur Vandervoort,Carolin Schmidt,Morten W. Petersen,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 提出一个结合集成评估模型与强化学习的决策支持框架，用于学习城市交通系统在气候变化下的多十年适应性投资路径


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧降雨等灾害，增加城市交通系统中断。设计有效适应策略面临长期基础设施投资序列性、深度不确定性和复杂跨部门交互的挑战

Method: 提出通用决策支持框架，将集成评估模型与强化学习耦合，结合长期气候预测、灾害概率映射、基础设施影响传播和成本评估，在强化学习循环中学习适应性气候适应政策

Result: 在哥本哈格内城雨洪案例中（2024-2100），学习到的策略产生协调的时空路径，相比传统优化基准（不作为和随机行动）具有更好的鲁棒性

Conclusion: 该框架展示了可转移到其他灾害和城市的潜力，为城市气候适应提供了有效的决策支持工具

Abstract: Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.

</details>


### [241] [CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling](https://arxiv.org/abs/2601.18620)
*Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Ian Berlot-Attwell,Stéphane Aroca-Ouellette,Kaheer Suleman*

Main category: cs.LG

TL;DR: CASSANDRA：一种神经符号世界建模方法，利用LLM作为知识先验构建轻量级过渡模型用于规划，在咖啡店和主题公园业务模拟器中表现优于基线


<details>
  <summary>Details</summary>
Motivation: 现实世界领域（如商业）具有丰富的语义，可以利用世界知识从有限数据中有效建模复杂的行动效果和因果关系。传统方法难以处理这种复杂性，需要结合符号知识和概率建模。

Method: CASSANDRA整合两个组件：1）LLM合成的代码用于建模确定性特征；2）LLM引导的概率图模型结构学习，用于捕捉随机变量间的因果关系。这是一种神经符号方法，利用LLM作为知识先验。

Result: 在小型咖啡店模拟器和复杂的主题公园业务模拟器中评估，CASSANDRA在过渡预测和规划方面相比基线方法有显著改进。

Conclusion: CASSANDRA通过结合LLM的知识先验和概率建模，能够有效构建现实世界领域的轻量级过渡模型，为复杂业务环境中的规划提供有力支持。

Abstract: Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.

</details>


### [242] [Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning](https://arxiv.org/abs/2601.18626)
*Yingxiao Huo,Satya Prakash Dash,Radu Stoican,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出一种基于秩-1近似的自然策略优化方法，通过近似逆Fisher信息矩阵来降低计算复杂度，在多种环境中优于标准actor-critic和信赖域基线方法。


<details>
  <summary>Details</summary>
Motivation: 自然梯度在深度强化学习中具有快速收敛特性，但计算自然梯度需要每次迭代都求逆Fisher信息矩阵(FIM)，这在计算上是不可行的。需要一种高效可扩展的自然策略优化技术。

Method: 提出一种利用秩-1近似来逼近完整逆FIM的高效自然策略优化方法。理论上证明在特定条件下，秩-1近似逆FIM比策略梯度收敛更快，并且在某些条件下具有与随机策略梯度方法相同的样本复杂度。

Result: 在多种环境中对方法进行基准测试，结果显示该方法在性能上优于标准的actor-critic和信赖域基线方法。

Conclusion: 提出了一种计算高效的自然策略优化方法，通过秩-1近似逆FIM解决了传统自然梯度方法计算复杂度过高的问题，在理论和实验上都表现出优越性能。

Abstract: Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.

</details>


### [243] [TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning](https://arxiv.org/abs/2601.18640)
*Zhiwei Zheng,Kevin Bryson*

Main category: cs.LG

TL;DR: TwinPurify是一个基于Barlow Twins自监督学习的表示学习框架，用于从批量转录组数据中提取肿瘤特异性信号，无需外部参考，通过利用同一队列中的相邻正常组织作为"背景"指导来解耦肿瘤特异性信号。


<details>
  <summary>Details</summary>
Motivation: 当前大规模患者队列研究仍依赖批量转录组数据，但肿瘤纯度变化会掩盖肿瘤内在转录信号并限制下游发现。许多去卷积方法在合成批量混合物上表现良好，但由于未建模的生物和技术变异，无法泛化到真实患者队列。

Method: TwinPurify采用Barlow Twins自监督目标，学习连续的高维肿瘤嵌入表示，而不是将批量混合物分解为离散细胞类型分数。它利用同一队列中的相邻正常组织作为"背景"指导，无需依赖任何外部参考即可解耦肿瘤特异性信号。

Result: 在多个大型癌症队列（RNA-seq和微阵列平台）的基准测试中，TwinPurify在恢复肿瘤内在和免疫信号方面优于传统表示学习方法（如自编码器）。纯化的嵌入改进了分子亚型和分级分类，增强了生存模型一致性，并揭示了与原始批量谱相比更具生物学意义的通路活性。

Conclusion: TwinPurify通过提供可转移的批量转录组去污染框架，扩展了现有临床数据集在分子发现中的实用性，代表了与去卷积范式的根本性转变。

Abstract: Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.
  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as "background" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.
  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.

</details>


### [244] [FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning](https://arxiv.org/abs/2601.18650)
*Liheng Yu,Zhe Zhao,Yuxuan Wang,Pengkun Wang,Binwu Wang,Yang Wang*

Main category: cs.LG

TL;DR: 该论文针对机器学习遗忘任务中遗忘集呈长尾分布的现实场景，提出了FaLW方法，通过实例级动态损失重加权解决现有方法在长尾分布下的异质遗忘偏差和倾斜遗忘偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘研究主要评估相对平衡的遗忘集，忽略了现实世界中遗忘数据（如用户活动记录）通常遵循长尾分布的情况。这是首次研究这一关键研究空白，发现现有方法在长尾设置下存在异质遗忘偏差和倾斜遗忘偏差两大问题。

Method: 提出FaLW方法，这是一种即插即用的实例级动态损失重加权方法。FaLW创新性地通过比较每个样本的预测概率与同一类别未见数据的分布来评估其遗忘状态，然后使用由平衡因子调制的遗忘感知重加权方案，自适应调整每个样本的遗忘强度。

Result: 大量实验证明FaLW在长尾分布场景下取得了优越的性能。代码已在补充材料中提供。

Conclusion: 该研究填补了机器学习遗忘在长尾分布场景下的研究空白，提出的FaLW方法有效解决了现有方法在长尾设置下的偏差问题，为现实世界中的机器学习遗忘任务提供了更实用的解决方案。

Abstract: Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \textit{Heterogeneous Unlearning Deviation} and \textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \textbf{Supplementary Material}.

</details>


### [245] [Learning temporal embeddings from electronic health records of chronic kidney disease patients](https://arxiv.org/abs/2601.18675)
*Aditya Kumar,Mario A. Cypko,Oliver Amft*

Main category: cs.LG

TL;DR: 研究探讨基于电子健康记录的时间嵌入模型能否在不牺牲预测性能的情况下学习临床有意义的表示，以及架构选择如何影响嵌入质量。通过比较三种循环架构在CKD患者数据上的表现，发现时间感知LSTM产生更结构化的嵌入，且嵌入模型在死亡率预测上优于端到端模型。


<details>
  <summary>Details</summary>
Motivation: 模型引导医学需要能够捕捉疾病动态同时保持透明和任务无关的表示，而大多数临床预测模型仅针对单一任务优化。表示学习有助于学习跨下游任务泛化的嵌入，循环架构适合建模临床数据中的时间结构。

Method: 使用MIMIC-IV数据集研究慢性肾脏病(CKD)患者，比较三种循环架构：普通LSTM、注意力增强LSTM和时间感知LSTM(T-LSTM)。所有模型既作为嵌入模型训练，也作为直接端到端预测器训练。通过CKD阶段聚类和ICU内死亡率预测评估嵌入质量。

Result: T-LSTM产生更结构化的嵌入，获得更低的Davies-Bouldin指数(DBI=9.91)和更高的CKD阶段分类准确率(0.74)，优于普通LSTM(DBI=15.85，准确率0.63)和注意力增强LSTM(DBI=20.72，准确率0.67)。在ICU内死亡率预测中，嵌入模型始终优于端到端预测器，准确率从0.72-0.75提升到0.82-0.83。

Conclusion: 时间感知LSTM架构能够学习更结构化的临床表示，且将嵌入学习作为中间步骤比直接端到端学习更有效，表明时间嵌入模型可以在保持预测性能的同时学习临床有意义的表示。

Abstract: We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.

</details>


### [246] [Quasi Monte Carlo methods enable extremely low-dimensional deep generative models](https://arxiv.org/abs/2601.18676)
*Miles Martinez,Alex H. Williams*

Main category: cs.LG

TL;DR: QLVMs是一种使用准蒙特卡洛积分直接近似边缘似然的深度生成模型，专门用于寻找高维数据的极低维可解释嵌入，在1-3维潜在空间中表现优于传统VAE和IWAE。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖学习编码器和变分下界，难以获得极低维且可解释的潜在嵌入。本文旨在开发一种专门用于寻找高维数据的低维可解释嵌入的深度生成模型。

Method: 提出准蒙特卡洛潜在变量模型（QLVMs），通过随机准蒙特卡洛积分直接近似边缘似然，而不是依赖变分下界和学习编码器。该方法专门针对1-3维潜在空间设计。

Result: 在多个数据集上，QLVMs在匹配潜在维度的情况下，始终优于传统变分自编码器（VAE）和重要性加权自编码器（IWAE）。生成的嵌入支持透明可视化、非参数密度估计、聚类和测地路径计算等后分析。

Conclusion: 虽然QLVMs计算密集且在复杂数据集上难以生成精细细节，但它为优先考虑可解释性和潜在空间分析的应用提供了有吸引力的解决方案，特别适合需要极低维可解释嵌入的场景。

Abstract: This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.

</details>


### [247] [Counterfactual Explanations on Robust Perceptual Geodesics](https://arxiv.org/abs/2601.18678)
*Eslam Zaher,Maciej Trzaskowski,Quan Nguyen,Fred Roosta*

Main category: cs.LG

TL;DR: PCG提出了一种基于感知黎曼度量的反事实解释方法，通过追踪测地线生成语义有效的反事实，避免了现有方法的离流形伪影和对抗性崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释方法存在距离度量选择模糊的问题，导致生成的扰动可能是语义上有意义的，也可能是对抗性的。现有方法采用平坦或不对齐的几何结构，导致离流形伪影、语义漂移或对抗性崩溃。

Method: PCG方法在鲁棒视觉特征诱导的感知黎曼度量下，通过追踪测地线构建反事实。这种几何结构与人类感知对齐，惩罚脆弱方向，实现平滑、在流形上、语义有效的转换。

Result: 在三个视觉数据集上的实验表明，PCG优于基线方法，并揭示了标准度量下隐藏的失败模式。

Conclusion: PCG通过感知黎曼度量构建的反事实解释方法能够生成更语义有效、在流形上的反事实，解决了现有方法的几何不对齐问题。

Abstract: Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.

</details>


### [248] [ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule](https://arxiv.org/abs/2601.18681)
*Yilie Huang,Wenpin Tang,Xunyu Zhou*

Main category: cs.LG

TL;DR: 提出自适应重参数化时间（ART）方法，通过控制重参数化时间变量的时钟速度来优化扩散模型的时间步调度，减少离散化误差，并通过强化学习（ART-RL）自动学习最优时间表。


<details>
  <summary>Details</summary>
Motivation: 传统均匀或手动设计的时间网格在有限时间步预算下可能不是最优的，导致采样效率低下。需要一种自适应方法来优化时间步调度，最小化离散化误差。

Method: 提出ART方法控制重参数化时间变量的时钟速度，实现不均匀时间步调度但保持终端时间不变。进一步提出ART-RL，将时间变化建模为连续时间强化学习问题，使用高斯策略，通过actor-critic更新数据驱动地学习最优时间表。

Result: 基于EDM框架，ART-RL在CIFAR-10上显著改善了Fréchet Inception Distance（FID），并在AFHQv2、FFHQ和ImageNet等数据集上表现出良好的迁移性，无需重新训练。

Conclusion: ART-RL提供了一种有效的数据驱动方法来优化扩散模型的时间步调度，显著提升采样质量，具有良好的泛化能力。

Abstract: We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.

</details>


### [249] [Explainability Methods for Hardware Trojan Detection: A Systematic Comparison](https://arxiv.org/abs/2601.18696)
*Paul Whitten,Francis Wolff,Chris Papachristou*

Main category: cs.LG

TL;DR: 该研究比较了硬件木马检测中三种可解释性方法：基于属性的电路分析、基于案例的推理和模型无关特征归因，发现前两种方法在领域对齐和基于先例的解释方面优于通用特征排名方法。


<details>
  <summary>Details</summary>
Motivation: 硬件木马检测需要准确识别和可解释的解释，以便安全工程师能够验证并基于结果采取行动。现有方法缺乏对检测结果的领域相关解释，难以让工程师信任和验证机器学习预测。

Method: 比较了三种可解释性方法：1）基于属性的分析，使用31个电路特定特征（门扇入模式、触发器距离、I/O连接性）；2）基于案例的推理，使用k近邻算法进行基于先例的解释；3）模型无关特征归因（LIME、SHAP、梯度方法）。使用XGBoost分类器在Trust-Hub基准上进行门级木马检测。

Result: XGBoost分类在11,392个测试样本上达到46.15%精度和52.17%召回率，相比先前工作（Hasegawa等：5.13%）精度提高9倍，误报率从5.6%降至0.25%。基于案例的推理在预测和训练样本之间达到97.4%对应性。LIME和SHAP特征归因具有强相关性（r=0.94，p<0.001）。梯度方法比SHAP快481倍。

Conclusion: 基于属性的分析和基于案例的推理方法在领域对齐和基于先例的可解释性方面优于通用特征排名方法，对可解释人工智能部署具有重要启示，特别是在需要验证机器学习预测的实际应用中。

Abstract: Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient).
  Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like "high fanin complexity near outputs indicates potential triggers." Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation.
  XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights.
  This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.

</details>


### [250] [Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning](https://arxiv.org/abs/2601.18699)
*Olaf Yunus Laitinen Imanov*

Main category: cs.LG

TL;DR: 该论文对大型语言模型在顺序微调中的灾难性遗忘现象进行了机制性分析，发现梯度干扰、表征漂移和损失景观平坦化是主要驱动因素，遗忘严重程度与任务相似度高度相关。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在预训练和微调中表现出色，但顺序微调会导致灾难性遗忘现象，新获得的知识会干扰先前学习的能力。虽然这种现象被广泛观察到，但其机制理解仍然有限。

Method: 对基于Transformer的大型语言模型在顺序微调中进行全面的机制分析，通过跨多个模型规模（109B到400B总参数）和任务序列的系统实验，识别灾难性遗忘的主要机制。

Result: 识别出三种主要遗忘机制：注意力权重中的梯度干扰、中间层的表征漂移以及损失景观平坦化。遗忘严重程度与任务相似度高度相关（Pearson r = 0.87），约15-23%的注意力头在微调过程中受到严重破坏，较低层表现出更大的易感性。

Conclusion: 这些发现为持续学习系统中开发有针对性的缓解策略建立了机制基础，提供了对灾难性遗忘现象的深入理解。

Abstract: Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.

</details>


### [251] [From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic](https://arxiv.org/abs/2601.18702)
*Hansheng Ren*

Main category: cs.LG

TL;DR: 该论文挑战了深度学习优先计算吞吐量而非数值精度的现有范式，提出精确性假设：通用智能（AGI）需要支持任意精度算术的计算基础，当前大语言模型的幻觉和逻辑不一致是浮点近似误差累积的结果。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习范式过于强调计算吞吐量而忽视数值精度，认为智能仅源于大规模统计相关性。作者观察到当前大语言模型存在的"幻觉"和逻辑不一致问题，认为这些是IEEE 754浮点近似误差在深度组合函数中累积的产物，需要从根本上解决数值精度问题。

Method: 提出精确性假设，引入Halo架构作为范式转变，采用有理数算术（ℚ）作为计算基础，并设计了新颖的精确推理单元（EIU）。通过Huginn-0125原型进行实证验证。

Result: 在Huginn-0125原型上的实验表明，当600B参数的BF16基线在混沌系统中崩溃时，Halo架构能够无限期保持零数值发散。这证明了精确算术在减少系统2 AGI逻辑不确定性方面的有效性。

Conclusion: 精确算术是减少系统2 AGI逻辑不确定性的先决条件，为通用智能的发展提供了新的计算基础方向，挑战了当前深度学习对数值精度的忽视。

Abstract: Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the "hallucinations" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.

</details>


### [252] [Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data](https://arxiv.org/abs/2601.18728)
*Willem Diepeveen,Oscar Leong*

Main category: cs.LG

TL;DR: Riemannian AmbientFlow：从损坏观测中同时学习概率生成模型和底层非线性数据流形的框架


<details>
  <summary>Details</summary>
Motivation: 在许多科学和成像应用中，无法获得干净样本，只能观察到噪声或线性损坏的测量值。此外，数据中存在的潜在结构（如流形几何）对于下游科学分析很重要，需要提取。

Method: 基于AmbientFlow的变分推断框架，结合由归一化流诱导的数据驱动黎曼几何，通过拉回度量和黎曼自编码器提取流形结构。在适当的几何正则化和测量条件下，学习模型能恢复底层数据分布并产生平滑的双Lipschitz流形参数化。

Result: 理论保证表明，学习模型能恢复底层数据分布至可控误差，并获得平滑的双Lipschitz流形参数化。平滑解码器可作为逆问题的原则性生成先验，具有恢复保证。在低维合成流形和MNIST上进行了实证验证。

Conclusion: Riemannian AmbientFlow为从损坏观测中同时学习生成模型和底层数据流形提供了有效框架，具有理论保证和实际应用价值，特别是在逆问题中作为生成先验。

Abstract: Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.

</details>


### [253] [Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models](https://arxiv.org/abs/2601.18734)
*Siyan Zhao,Zhihui Xie,Mengchen Liu,Jing Huang,Guan Pang,Feiyu Chen,Aditya Grover*

Main category: cs.LG

TL;DR: 提出On-Policy Self-Distillation (OPSD)框架，让单个LLM同时扮演教师和学生角色，通过在不同上下文条件下生成响应，实现自我蒸馏，提高数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法存在两个主要问题：1) 在线蒸馏需要独立的、通常更大的教师模型；2) 没有充分利用推理数据集中可用的真实解决方案。受到"足够强大的LLM能够理性分析外部特权推理轨迹并教导其较弱自我版本"这一直觉启发，提出了自我蒸馏框架。

Method: OPSD框架中，单个模型同时作为教师和学生，但基于不同上下文条件：教师策略基于特权信息（如已验证的推理轨迹），学生策略仅看到问题。训练时最小化这两个分布在学生自身轨迹上的每令牌分歧。

Result: 在多个数学推理基准测试中，相比GRPO等强化学习方法实现了4-8倍的令牌效率提升，并且性能优于离线蒸馏方法。

Conclusion: OPSD框架通过让单个模型自我蒸馏，既避免了需要独立教师模型的开销，又充分利用了数据集中的特权信息，在数学推理任务上取得了高效且优越的性能。

Abstract: Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.

</details>


### [254] [Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback](https://arxiv.org/abs/2601.18751)
*Seyed Amir Hosseini,Maryam Abdolali,Amirhosein Tavakkoli,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.LG

TL;DR: TriTrust-PBRL (TTP) 是一个新的偏好强化学习框架，能够从包含可靠、噪声和对抗性标注者的异构专家反馈中学习，通过信任参数自动处理对抗性偏好。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的偏好数据通常来自具有不同可靠性的异构标注者，包括准确、噪声和系统性对抗的标注者。现有的PBRL方法要么平等对待所有反馈，要么试图过滤不可靠来源，但在面对系统性提供错误偏好的对抗性标注者时都会失败。

Method: 提出TriTrust-PBRL (TTP)框架，联合学习共享奖励模型和专家特定的信任参数。关键洞察是信任参数在基于梯度的优化过程中自然演变为正值（信任）、接近零（忽略）或负值（翻转），使模型能够自动反转对抗性偏好并恢复有用信号，而不仅仅是丢弃损坏的反馈。

Result: 在四个不同领域（MetaWorld操作任务和DM Control运动任务）的各种损坏场景下进行评估。TTP实现了最先进的鲁棒性，在对抗性损坏下保持接近oracle的性能，而标准PBRL方法则完全失败。TTP成功地从包含可靠和对抗性标注者的混合专家池中学习，且仅需专家标识索引，无需额外专家特征。

Conclusion: TriTrust-PBRL提供了一个统一的框架，能够有效处理异构专家偏好反馈，特别是对抗性标注者，通过自动学习信任参数来优化奖励模型学习，在现有PBRL流程中无缝集成。

Abstract: Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.

</details>


### [255] [Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values](https://arxiv.org/abs/2601.18760)
*Henry Bell,Lara Neubauer da Costa Schertel,Bochu Ding,Brandon Fain*

Main category: cs.LG

TL;DR: 本文提出Grounded Constitutional AI (GCAI)框架，通过结合用户对AI的普遍期望（通用原则）和交互时偏好（情境原则）来生成更具代表性的人工智能宪法，相比现有方法更受人类偏好。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型对齐中，如何公平确定代表广泛利益相关者意见的宪法原则存在挑战。现有宪法AI框架难以充分捕捉用户的具体偏好和情境需求。

Method: 扩展Inverse Constitutional AI (ICAI)方法，利用人类偏好标注数据中的"原因"生成情境原则，同时从用户关于AI的"价值观"陈述中提取通用原则，形成统一的宪法生成框架。

Result: GCAI生成的宪法在人类评估中优于ICAI生成的宪法，不仅个人偏好度更高，也更适合广泛用于规范AI行为。参与者认为GCAI宪法更具道德基础、连贯性和多元性。

Conclusion: GCAI框架通过整合通用原则和情境原则，能够生成更全面代表用户期望的AI宪法，为AI对齐提供了更有效的宪法生成方法。

Abstract: A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.

</details>


### [256] [PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation](https://arxiv.org/abs/2601.18777)
*Abhishek Divekar,Anirban Majumder*

Main category: cs.LG

TL;DR: 本文提出PRECISE框架，结合少量人工标注和LLM判断来评估搜索、排序和RAG系统质量，显著减少人工标注需求


<details>
  <summary>Details</summary>
Motivation: 传统评估搜索、排序和RAG系统需要大量人工相关性标注，成本高昂。虽然LLM可作为自动评估工具，但其固有偏见阻碍了直接用于指标估计

Method: 提出PRECISE统计框架，扩展预测驱动推理(PPI)，结合少量人工标注（100个查询）和大量LLM判断（10,000个未标注样本），将计算复杂度从O(2^|C|)降低到O(2^K)，其中|C|为语料库规模，K为常数

Result: 实验表明，该方法能有效减少关键业务指标Precision@K的估计方差，在低资源设置下有效校正LLM偏见，显著降低标注需求

Conclusion: PRECISE框架为搜索系统评估提供了一种高效、可靠的统计方法，通过结合少量人工标注和LLM判断，在保证准确性的同时大幅降低评估成本

Abstract: Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.

</details>


### [257] [POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration](https://arxiv.org/abs/2601.18779)
*Yuxiao Qu,Amrith Setlur,Virginia Smith,Ruslan Salakhutdinov,Aviral Kumar*

Main category: cs.LG

TL;DR: POPE方法利用特权信息（如人类解决方案）引导强化学习在困难问题上的探索，解决了传统RL方法在硬问题上探索失败的问题，显著提升了推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在训练大型语言模型时，面对困难问题经常无法获得任何正确轨迹，导致零奖励和缺乏学习信号。传统探索方法如熵奖励、重要性比率调整等无法解决这个问题，而混合难易问题训练反而会产生"射线干扰"现象，阻碍硬问题的进展。

Method: POPE（特权在线探索）方法：利用人类或其他oracle解决方案作为特权信息来引导硬问题的探索。具体做法是在硬问题前添加oracle解决方案的前缀，使RL在引导轨迹中获得非零奖励。关键是通过指令跟随和推理的协同作用，将学习到的行为迁移回原始未引导的问题。

Result: POPE显著扩展了可解决问题的集合，在具有挑战性的推理基准测试中大幅提升了性能表现。

Conclusion: POPE通过特权信息引导探索，有效解决了强化学习在困难推理问题上的探索失败问题，提供了一种将oracle解决方案作为探索引导而非训练目标的创新方法。

Abstract: Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.

</details>


### [258] [Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic](https://arxiv.org/abs/2601.18783)
*Deepthi Pathare,Leo Laine,Morteza Haghir Chehreghani*

Main category: cs.LG

TL;DR: 本文提出基于近端策略优化的多目标强化学习框架，用于重型车辆高速公路驾驶决策，学习连续帕累托最优策略集以平衡安全、能耗和时间效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 重型车辆高速公路驾驶需要在安全性、效率和运营成本之间进行复杂的权衡决策。传统的标量奖励函数通过聚合这些竞争目标往往模糊了它们之间的权衡结构，需要更明确的权衡表示方法。

Method: 提出基于近端策略优化（PPO）的多目标强化学习框架，在卡车战术决策的可扩展仿真平台上学习连续的政策集，明确表示安全（碰撞和完成率）、能源效率（能源成本）和时间效率（驾驶员成本）三个冲突目标之间的权衡。

Result: 该方法学习到平滑且可解释的连续帕累托最优策略集，能够捕获不同冲突目标之间的权衡关系，生成的帕累托前沿平滑可解释，允许在不同驾驶行为之间灵活选择而无需重新训练。

Conclusion: 该框架为自动驾驶卡车应用提供了稳健且自适应的决策策略，能够无缝在不同驾驶策略之间切换，实现了安全、能耗和时间效率之间的明确权衡表示。

Abstract: Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.

</details>


### [259] [Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes](https://arxiv.org/abs/2601.18795)
*Amrith Setlur,Zijian Wang,Andrew Cohen,Paria Rashidinejad,Sang Michael Xie*

Main category: cs.LG

TL;DR: PrefixRL是一种新的强化学习方法，通过重用旧的计算资源（离线策略轨迹）来提升LLM推理任务的训练效率，避免传统离线方法的不稳定性，在困难问题上实现2倍训练加速和3倍最终奖励提升。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在LLM推理任务中面临困难问题上的计算浪费问题：正确策略轨迹稀少、策略梯度消失、学习停滞。需要更高效的RL方法来重用已有的计算资源（离线策略轨迹）。

Method: 提出PrefixRL方法：基于成功离线策略轨迹的前缀进行条件化，然后运行在线RL来完成剩余部分。通过调整前缀长度来调节问题难度，避免离线策略的不稳定性。使用基础模型通过拒绝采样获取离线轨迹，形成自我改进循环。

Result: 在困难推理问题上，PrefixRL达到相同训练奖励的速度比最强基线（离线数据SFT后RL）快2倍，最终奖励提升3倍。发现后向泛化现象：仅在前缀问题上训练能泛化到无前缀性能。方法在不同模型家族来源的离线轨迹上仍然有效。

Conclusion: PrefixRL通过重用离线计算资源有效解决了LLM推理中RL训练的样本效率问题，避免了传统离线方法的不稳定性，在困难问题上显著提升了训练效率和最终性能，具有实际应用的灵活性。

Abstract: Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [260] [Investigating Self-regulated Learning Sequences within a Generative AI-based Intelligent Tutoring System](https://arxiv.org/abs/2601.17000)
*Jie Gao,Shasha Li,Jianhua Zhang,Shan Li,Tingting Wang*

Main category: cs.CY

TL;DR: 研究通过分析学生在GenAI辅助学习环境中的交互数据，识别了两种不同的自我调节学习模式，发现学生主要使用GenAI进行信息获取而非信息转化，但使用目的与学习表现无显著相关。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能在教育中的应用日益增多，学者们认识到自我调节学习在GenAI辅助学习环境中的关键作用，因此需要捕捉学生动态的SRL模式以提升学习效果。

Method: 从学生在GenAI辅助智能辅导系统中完成问题解决任务的追踪数据中提取交互模式，从信息处理角度（信息获取和信息转化）分析使用目的，采用序列分析和聚类分析方法对学生进行分类。

Result: 将参与者分为两组不同的SRL序列模式，这两组在GenAI使用的频率和时间特征上存在差异；大多数学生使用GenAI进行信息获取而非信息转化；GenAI使用目的与学习表现之间无统计学显著相关性。

Conclusion: 研究结果为GenAI辅助学习环境的教学设计和开发提供了重要启示，强调了理解学生SRL模式的重要性，但需要进一步探索GenAI使用目的与学习效果之间的关系。

Abstract: There has been a growing trend in employing generative artificial intelligence (GenAI) techniques to support learning. Moreover, scholars have reached a consensus on the critical role of self-regulated learning (SRL) in ensuring learning effectiveness within GenAI-assisted learning environments, making it essential to capture students' dynamic SRL patterns. In this study, we extracted students' interaction patterns with GenAI from trace data as they completed a problem-solving task within a GenAI-assisted intelligent tutoring system. Students' purpose of using GenAI was also analyzed from the perspective of information processing, i.e., information acquisition and information transformation. Using sequential and clustering analysis, this study classified participants into two groups based on their SRL sequences. These two groups differed in the frequency and temporal characteristics of GenAI use. In addition, most students used GenAI for information acquisition rather than information transformation, while the correlation between the purpose of using GenAI and learning performance was not statistically significant. Our findings inform both pedagogical design and the development of GenAI-assisted learning environments.

</details>


### [261] [Lex Reformatica: Five Principles of Policy Reform for the Technological Age](https://arxiv.org/abs/2601.17001)
*Sonia Katyal*

Main category: cs.CY

TL;DR: 本文回顾了Joel Reidenberg 25年前提出的"Lex Informatica"概念，指出技术本身像法律一样规范信息社会，并探讨了当今数字时代需要从信息自由主义转向改革导向的监管新方法。


<details>
  <summary>Details</summary>
Motivation: 重新审视Reidenberg的"Lex Informatica"概念，分析在缺乏明确法律约束的情况下技术规范发展的后果，探讨谁受益谁受害，并强调当今数字时代需要基础设施改革和新的监管方法。

Method: 通过两个专题研讨会（Lex Informatica专题和种族与技术法专题）的论文集合，进行跨学科对话，提出"Lex Reformatica"概念，倡导回归Reidenberg的基础工作并更新其轨迹。

Result: 揭示了信息自由主义的缺陷，强调公共与私人监管、自我监管之间互动的重要性，展示了学者、律师和立法者需要采取改革导向的方法来应对当前数字时代的挑战。

Conclusion: 当今数字时代需要从"Lex Informatica"转向"Lex Reformatica"，即改革导向的监管方法，强调学者、律师和立法者必须回归Reidenberg的基础工作并更新其轨迹，以应对当前信息社会的挑战。

Abstract: Twenty-five years ago, Joel Reidenberg argued that technology itself, not just law and regulation, imposes rules on communities in the Information Society. System design choices like network architecture and configurations create regulatory norms he termed "Lex Informatica"-referencing the merchant-driven medieval "Lex Mercatoria" that emerged independent of sovereign control. Today we face different challenges requiring us to revisit Reidenberg's insights and examine the consequences of that earlier era. While Lex Informatica provided a framework for analyzing the internet's birth, we now confront the aftereffects of decades of minimal or absent regulation. Critical questions emerge: When technological social norms develop outside clear legal restraints, who benefits and who suffers? This new era demands infrastructural reform focused on the interplay between public and private regulation and self-regulation, weighing both costs and benefits. Rather than showcasing the promise of yesterday's internet age, today's events reveal the pitfalls of information libertarianism and underscore the urgent need for new approaches to information regulation. This Issue presents articles from two symposiums-one on Lex Informatica and another on race and technology law. Their conversation is now essential. Together, these papers demonstrate what I call the "Lex Reformatica" of today's digital age. This collection shows why scholars, lawyers, and legislators must return to Reidenberg's foundational work and update its trajectory toward a reform-focused approach designed for our current era.

</details>


### [262] [Beyond Simulations: What 20,000 Real Conversations Reveal About Mental Health AI Safety](https://arxiv.org/abs/2601.17003)
*Caitlin A. Stamatis,Jonah Meyerhoff,Richard Zhang,Olivier Tieleman,Matteo Malgaroli,Thomas D. Hull*

Main category: cs.CY

TL;DR: 该研究评估了AI心理健康支持系统的安全性，发现专门构建的AI在自杀/自伤、饮食障碍和物质滥用等安全测试中表现优于通用大语言模型，但测试集失败率远高于真实部署情况，支持转向持续、部署相关的安全保证而非有限基准认证。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型越来越多地用于心理健康支持，但现有的安全性评估主要依赖小型、基于模拟的测试集，这些测试集与真实使用场景的语言分布关系未知。研究者希望了解测试集性能与真实世界性能之间的差距。

Method: 1) 复制了四个已发布的安全测试集（自杀风险评估、有害内容生成、拒绝鲁棒性、对抗性越狱），比较前沿通用AI模型与专门构建的心理健康支持AI；2) 对超过20,000个真实用户对话进行生态审计，分析专门构建的AI在分层自杀和非自杀性自伤防护下的表现。

Result: 专门构建的AI在自杀/自伤（0.4-11.27% vs 29.0-54.4%）、饮食障碍（8.4% vs 54.0%）和物质滥用（9.9% vs 45.0%）测试中产生有害内容的可能性显著低于通用模型。但测试集失败率远高于真实部署情况。临床医生审查标记对话发现零例自杀风险未获得危机资源。在所有20,000个对话中，只有三例自伤风险（0.015%）未触发危机干预，对应端到端系统假阴性率为0.38%。

Conclusion: 研究结果支持从有限的基准认证转向持续、部署相关的AI心理健康系统安全保证，强调真实世界性能评估的重要性。

Abstract: Large language models (LLMs) are increasingly used for mental health support, yet existing safety evaluations rely primarily on small, simulation-based test sets that have an unknown relationship to the linguistic distribution of real usage. In this study, we present replications of four published safety test sets targeting suicide risk assessment, harmful content generation, refusal robustness, and adversarial jailbreaks for a leading frontier generic AI model alongside an AI purpose built for mental health support. We then propose and conduct an ecological audit on over 20,000 real-world user conversations with the purpose-built AI designed with layered suicide and non-suicidal self-injury (NSSI) safeguards to compare test set performance to real world performance. While the purpose-built AI was significantly less likely than general-purpose LLMs to produce enabling or harmful content across suicide/NSSI (.4-11.27% vs 29.0-54.4%), eating disorder (8.4% vs 54.0%), and substance use (9.9% vs 45.0%) benchmark prompts, test set failure rates for suicide/NSSI were far higher than in real-world deployment. Clinician review of flagged conversations from the ecological audit identified zero cases of suicide risk that failed to receive crisis resources. Across all 20,000 conversations, three mentions of NSSI risk (.015%) did not trigger a crisis intervention; among sessions flagged by the LLM judge, this corresponds to an end-to-end system false negative rate of .38%, providing a lower bound on real-world safety failures. These findings support a shift toward continuous, deployment-relevant safety assurance for AI mental-health systems rather than limited set benchmark certification.

</details>


### [263] [From Noise to Insights: Enhancing Supply Chain Decision Support through AI-Based Survey Integrity Analytics](https://arxiv.org/abs/2601.17005)
*Bhubalan Mani*

Main category: cs.CY

TL;DR: 本研究提出一个基于AI的轻量级框架，用于过滤供应链调查中的不可靠数据，通过监督机器学习方法识别虚假响应，在99个行业响应数据集上达到92.0%的准确率。


<details>
  <summary>Details</summary>
Motivation: 供应链决策中调查数据的可靠性至关重要，特别是在评估AI驱动工具（如安全库存优化系统）的准备度时。然而，调查常常吸引低质量或虚假响应，这会降低分析结果的准确性。

Method: 采用监督机器学习方法，收集了99个行业响应数据集，通过人工标注基于逻辑不一致性和响应模式识别虚假响应。经过预处理和标签编码后，训练了随机森林和基线模型（逻辑回归、XGBoost）来区分真实和虚假响应。

Result: 最佳模型达到了92.0%的准确率，相比初步研究有显著改进，证明了AI在调查数据过滤中的有效性。

Conclusion: 尽管存在局限性，但研究结果突出了将AI集成到调查流程中的可行性，为供应链研究中提高数据完整性提供了可扩展的解决方案，特别是在产品发布和技术采用阶段。

Abstract: The reliability of survey data is crucial in supply chain decision-making, particularly when evaluating readiness for AI-driven tools such as safety stock optimization systems. However, surveys often attract low-effort or fake responses that degrade the accuracy of derived insights. This study proposes a lightweight AI-based framework for filtering unreliable survey inputs using a supervised machine learning approach. In this expanded study, a larger dataset of 99 industry responses was collected, with manual labeling to identify fake responses based on logical inconsistencies and response patterns. After preprocessing and label encoding, both Random Forest and baseline models (Logistic Regression, XGBoost) were trained to distinguish genuine from fake responses. The best-performing model achieved an 92.0% accuracy rate, demonstrating improved detection compared to the pilot study. Despite limitations, the results highlight the viability of integrating AI into survey pipelines and provide a scalable solution for improving data integrity in supply chain research, especially during product launch and technology adoption phases.

</details>


### [264] [Artificial Intelligence in Spanish Gastroenterology: high expectations, limited integration. A national survey](https://arxiv.org/abs/2601.17011)
*Javier Crespo,Ana Enériz,Paula Iruzubieta,Fernando Carballo,Conrado Fernández Rodríguez,María Dolores Martín-Arranz,Federico Argüelles-Arias,Juan Turnes*

Main category: cs.CY

TL;DR: 西班牙胃肠病学专家对AI持积极态度但实际使用率低，主要障碍是缺乏培训、机构策略和伦理担忧，需要专业学会主导的认证培训计划。


<details>
  <summary>Details</summary>
Motivation: AI在医学领域已成为颠覆性创新，但在胃肠病学中的采用仍然有限且特征不明。研究旨在了解西班牙胃肠病学专家对AI的知识、实际应用、感知障碍和期望。

Method: 采用横断面观察研究设计，通过西班牙消化病理学会（SEPD）在2025年分发结构化在线问卷，收集社会人口学数据、AI使用模式、认知和教育需求，应用描述性统计和多变量模型分析。

Result: 283名受访者（平均年龄44.6±9.7岁）中，87.5%认为AI是变革性工具，但仅60.2%报告使用AI，且多在机构框架外使用。80.2%的用户在过去一年内开始使用AI。频繁使用的独立预测因素包括先前培训（OR=2.44）、在大学医院工作（OR=2.14）和年轻（每减少5岁OR=1.36）。主要障碍是缺乏培训（61%）、缺乏机构策略（46%）和伦理担忧（50%）。93.8%同意需要AI培训计划，但仅18.4%接受过正式培训。

Conclusion: 西班牙胃肠病学中AI的积极认知与实际临床整合存在显著差距。机构框架外的快速采用突显了由科学学会主导的认证培训计划和治理标准的紧迫需求。

Abstract: Background: Artificial intelligence (AI) has emerged as a disruptive innovation in medicine, yet its adoption within gastroenterology remains limited and poorly characterized. We aimed to examine knowledge, practical applications, perceived barriers, and expectations regarding AI among gastroenterology specialists in Spain.Methods: We conducted a cross-sectional observational study using a structured online survey distributed by the Spanish Society of Digestive Pathology (SEPD) in 2025. The questionnaire collected sociodemographic data, patterns of AI use, perceptions, and educational needs. Descriptive statistics and multivariable models were applied.Results: Among 283 respondents (mean age 44.6 $\pm$ 9.7 years), 87.5% acknowledged AI as a transformative tool, but only 60.2% (95% CI: 54.3-66.1%) reported using it, mostly outside institutional frameworks. Notably, 80.2% of users initiated AI use within the past year. Independent predictors of frequent use included previous training (OR=2.44), employment in university hospitals (OR=2.14), and younger age (OR=1.36 per 5-year decrease). Main barriers were lack of training (61%), absence of institutional strategies (46%), and ethical concerns (50%). While 93.8% agreed that AI training programmes are necessary, only 18.4% had received formal training.Conclusions: A substantial gap exists between the favorable perception of AI and its actual integration into clinical practice within Spanish gastroenterology. The rapid adoption outside institutional frameworks underscores the urgent need for accredited training programmes and governance standards led by scientific societies.

</details>


### [265] [The Digital Divide in Geriatric Care: Why Usability, Not Access, is the Real Problem](https://arxiv.org/abs/2601.17012)
*Christine Ine*

Main category: cs.CY

TL;DR: 该研究将老年人数字健康领域的"数字鸿沟"重新定义为"可用性鸿沟"，认为用户体验设计不佳而非技术访问是主要采纳障碍，提出通过参与式、用户中心和包容性设计来克服挑战。


<details>
  <summary>Details</summary>
Motivation: 全球老龄化人口快速增长（预计205年达16%），需要数字健康解决方案来增强老年人的独立性、可及性和福祉。虽然远程医疗、可穿戴设备和移动健康应用等技术可以改变老年护理，但在老年人中的采纳并不均衡。

Method: 基于跨学科研究和设计范式，识别主要挑战：视觉、认知和运动障碍；复杂界面；缺乏与老年人的共同创造。提出通过参与式、用户中心和包容性设计理念来克服这些障碍。

Result: 研究发现老年人容易接受那些直观、可访问且具有社会嵌入性的技术，这些技术能促进自主性、信心和健康公平。高对比度屏幕、简化交互流程、多模态反馈和护理人员整合等设计属性对可用性结果有显著影响。

Conclusion: 当前可访问性指南过于技术导向而非体验导向，需要基于人本可用性而非单纯技术可访问性的伦理、共情设计理解。用户体验设计是克服老年人数字健康采纳障碍的关键。

Abstract: The rapid increase in the world's aging population to 16% by the year 2050 spurs the need for the application of digital health solutions to enhance older individuals' independence, accessibility, and well-being. While digital health technologies such as telemedicine, wearables, and mobile health applications can transform geriatric care, their adoption among older individuals is not evenly distributed. This study redefines the "digital divide" among older health care as a usability divide, contends that user experience (UX) poor design is the primary adoption barrier, rather than access. Drawing on interdisciplinary studies and design paradigms, the research identifies the main challenges: visual, cognitive, and motor impairment; complicated interfaces; and lack of co-creation with older adults, and outlines how participatory, user-focused, and inclusive notions of design can transcend them. Findings reveal that older persons easily embrace those technologies that are intuitive, accessible, and socially embedded as they promote autonomy, confidence, and equity in health. The study identifies the effects of the design attributes of high-contrast screens, lower interaction flow, multimodal feedback, and caregiver integration as having strong influences on usability outcomes. In addition, it critiques the current accessibility guidelines as being technically oriented rather than experiential and demands an ethical, empathetic understanding of design grounded in human-centered usability rather than technical accessibility in itself.

</details>


### [266] [Measuring Political Stance and Consistency in Large Language Models](https://arxiv.org/abs/2601.17016)
*Salah Feras Alali,Mohammad Nashat Maasfeh,Mucahid Kutlu,Saban Kardas*

Main category: cs.CY

TL;DR: 研究发现大型语言模型在政治敏感问题上存在立场差异，部分立场受提示词影响，部分立场稳定不变，模型倾向于支持提示词所用语言的国家立场。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，人们开始使用它们来满足信息需求。然而，在政治问题上使用LLMs可能存在风险，因为模型输出可能反映训练数据偏见或人为对齐选择。本研究旨在评估LLMs在政治敏感问题上的立场表现。

Method: 研究评估了9个LLMs在24个政治敏感问题上的立场，使用了5种提示技术。通过系统性的测试来分析模型在不同政治议题上的立场表现和稳定性。

Result: 1. 模型在多个问题上经常采取对立立场；2. 部分立场在提示词影响下会改变，部分保持稳定；3. Grok-3-mini立场最稳定，Mistral-7B最不稳定；4. 在涉及多语言国家的问题上，模型倾向于支持提示词所用语言的国家立场；5. 所有提示技术都无法改变模型在卡塔尔封锁和巴勒斯坦压迫问题上的立场。

Conclusion: 研究结果提醒用户在使用LLMs寻求政治指导时保持警惕，并鼓励开发者解决这些问题。LLMs在政治敏感问题上的立场差异和偏见需要引起关注。

Abstract: With the incredible advancements in Large Language Models (LLMs), many people have started using them to satisfy their information needs. However, utilizing LLMs might be problematic for political issues where disagreement is common and model outputs may reflect training-data biases or deliberate alignment choices. To better characterize such behavior, we assess the stances of nine LLMs on 24 politically sensitive issues using five prompting techniques. We find that models often adopt opposing stances on several issues; some positions are malleable under prompting, while others remain stable. Among the models examined, Grok-3-mini is the most persistent, whereas Mistral-7B is the least. For issues involving countries with different languages, models tend to support the side whose language is used in the prompt. Notably, no prompting technique alters model stances on the Qatar blockade or the oppression of Palestinians. We hope these findings raise user awareness when seeking political guidance from LLMs and encourage developers to address these concerns.

</details>


### [267] [Evaluating the Evolution of Critical Thinking, Creativity, Communication and Collaboration in Higher Education Courses](https://arxiv.org/abs/2601.17018)
*Margarida Romero*

Main category: cs.CY

TL;DR: 研究评估了4Cs能力（创造力、沟通、批判性思维、协作）在三个教育案例中从预试点到试点阶段的演变，发现沟通和批判性思维改善最显著，创造力结果依赖情境，而协作能力最脆弱。


<details>
  <summary>Details</summary>
Motivation: 尽管4Cs能力（创造力、沟通、批判性思维、协作）是当代能力本位教育的核心目标，但关于这些能力如何在不同学习模块和教学阶段演变的实证证据仍然有限。本研究旨在填补这一空白，评估4Cs能力在从预试点到试点实施阶段的演变情况。

Method: 研究使用项目的4Cs理论框架作为分析视角，评估了三个教育案例（IASIS、EASD和UPATRAS）中4Cs能力从预试点到试点阶段的演变。通过分析三个试点案例，比较了4Cs得分以识别随时间增长、停滞或下降的模式。

Result: 结果显示：沟通和批判性思维表现出最一致且显著的改善，特别是在预试点基线较低的试点中，表明结构化试点干预能有效支持认知和表达能力。相比之下，创造力表现出情境依赖的结果，而协作能力则是最脆弱的能力，在扩大规模时经常停滞或下降。

Conclusion: 通过理论框架解释，这些发现表明能力演变主要受教学设计、评估对齐和学习活动结构的影响，而非仅由学习者能力决定。研究为4Cs框架提供了实证验证，并强调了在扩展教育模块时需要差异化的、能力敏感的设计和评估策略。

Abstract: The development of Creativity, Communication, Critical Thinking, and Collaboration (the 4Cs) is a central objective of contemporary competency-based education. However, empirical evidence on how these competencies evolve across learning modules and instructional phases remains limited. This study evaluates the evolution of the 4Cs from pre-pilot to pilot implementation phases across three educational contexts, using the project's 4Cs theoretical framework as an analytical lens. The analysis of three pilot cases (IASIS, EASD, and UPATRAS) compares the 4Cs scores to identify patterns of growth, stagnation, or decline over time. Results indicate that communication and critical thinking showed the most consistent and substantial improvements, particularly in pilots with lower pre-pilot baselines, suggesting that structured pilot interventions effectively support cognitive and expressive competencies. In contrast, creativity exhibited context-dependent outcomes, while collaboration emerged as the most fragile competency, often stagnating or declining during scale-up. Interpreted through the theoretical framework, these findings suggest that competency evolution is strongly shaped by instructional design, assessment alignment, and learning activity structures rather than learner ability alone. The study contributes empirical validation to the 4Cs framework and highlights the need for differentiated, competency-sensitive design and evaluation strategies when scaling educational modules.

</details>


### [268] [Ensuring Computer Science Learning in the AI Era: Open Generative AI Policies and Assignment-Driven Written Quizzes](https://arxiv.org/abs/2601.17024)
*Chan-Jin Chung*

Main category: cs.CY

TL;DR: 该研究提出了一种评估模型，允许学生在编程作业中使用生成式AI，但通过即时的、作业驱动的闭卷测验来确保个人掌握程度，初步数据显示AI使用与评估结果无显著相关性。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能的普及给计算机科学教育带来了挑战：如何在编程课程中融入强大的AI工具，同时避免因认知卸载而削弱学生的学习效果。

Method: 提出评估模型：允许在编程作业中使用生成式AI，但通过权重更高的、闭卷的、作业驱动的即时测验来验证学生对提交代码的算法、结构和实现细节的理解。从高级计算机科学课程收集初步实证数据，分析自我报告的AI使用情况与无AI测验、考试和最终成绩的关系。

Result: 统计分析显示，生成式AI使用水平与评估结果之间没有有意义的线性相关性，皮尔逊相关系数始终接近零。这表明允许在编程作业中使用AI不会削弱学生对课程概念的掌握，前提是通过有针对性的、作业驱动的测验来验证学习效果。

Conclusion: 虽然受限于小样本量，但研究表明，通过允许AI辅助编程实践，同时通过作业驱动的无AI测验来验证理解，可以减轻认知卸载的风险。这些发现支持在高级计算机科学课程中负责任地采用开放的生成式AI政策，前提是配合严格的独立评估机制。

Abstract: The widespread availability of generative artificial intelligence (GenAI) has created a pressing challenge in computer science (CS) education: how to incorporate powerful AI tools into programming coursework without undermining student learning through cognitive offloading. This paper presents an assessment model that permits the use of generative AI for take-home programming assignments while enforcing individual mastery through immediate, assignment-driven written quizzes. To promote authentic learning, these in-class, closed-book assessments are weighted more heavily than the assignments themselves and are specifically designed to verify the student's comprehension of the algorithms, structure, and implementation details of their submitted code. Preliminary empirical data were collected from an upper-level computer science course to examine the relationship between self-reported GenAI usage and performance on AI-free quizzes, exams, and final course grades. Statistical analyses revealed no meaningful linear correlation between GenAI usage levels and assessment outcomes, with Pearson correlation coefficients consistently near zero. These preliminary results suggest that allowing GenAI for programming assignments does not diminish students' mastery of course concepts when learning is verified through targeted, assignment-driven quizzes. Although limited by a small sample size, this study provides preliminary evidence that the risks of cognitive offloading can be mitigated by allowing AI-assisted programming practice while verifying understanding through assignment-driven, AI-free quizzes. The findings support the responsible adoption of open GenAI policies in upper-level CS courses, when paired with rigorous, independent assessment mechanisms.

</details>


### [269] [AI, Metacognition, and the Verification Bottleneck: A Three-Wave Longitudinal Study of Human Problem-Solving](https://arxiv.org/abs/2601.17055)
*Matthias Huemmer,Franziska Durner,Theophile Shyiramunda,Michelle J. Cummings-Koether*

Main category: cs.CY

TL;DR: 这项为期6个月的纵向研究追踪了生成式AI如何改变学术环境中的问题解决过程，发现AI使用达到饱和，但验证成为瓶颈，客观表现系统性下降，信念-表现差距扩大。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI在学术环境中如何随时间改变问题解决过程，特别关注AI集成程度、工作流程演变、验证行为与客观表现之间的关系。

Method: 纵向试点研究，在6个月内分三个波次追踪学术环境中的AI使用情况，测量AI采用率、工作流程、验证信心和客观表现，使用认知负荷理论作为理论基础。

Result: AI集成达到饱和（日常使用率95.7%，ChatGPT采用率100%），混合工作流程增加2.7倍，但验证信心下降（68.1%），客观表现系统性下降（从95.2%到47.8%），信念-表现差距扩大至34.6个百分点。

Conclusion: 验证而非解决方案生成成为人-AI问题解决的瓶颈，提出了ACTIVE框架指导实践，但研究存在样本同质性、自我报告偏差等局限性，结果主要适用于早期采用者学术群体。

Abstract: This longitudinal pilot study tracked how generative AI reshapes problem-solving over six months across three waves in an academic setting. AI integration reached saturation by Wave 3, with daily use rising from 52.4% to 95.7% and ChatGPT adoption from 85.7% to 100%. A dominant hybrid workflow increased 2.7-fold, adopted by 39.1% of participants. The verification paradox emerged: participants relied most heavily on AI for difficult tasks (73.9%) yet showed declining verification confidence (68.1%) where performance was worst (47.8% accuracy on complex tasks). Objective performance declined systematically: 95.2% to 81.0% to 66.7% to 47.8% across problem difficulty, with belief-performance gaps widening to 34.6 percentage points. This indicates a fundamental shift where verification, not solution generation, became the bottleneck in human-AI problem-solving. The ACTIVE Framework synthesizes findings grounded in cognitive load theory: Awareness and task-AI alignment, Critical verification protocols, Transparent human-in-the-loop integration, Iterative skill development countering cognitive offloading, Verification confidence calibration, and Ethical evaluation. The authors provide implementation pathways for institutions and practitioners. Key limitations include sample homogeneity (academic cohort only, convenience sampling) limiting generalizability to corporate, clinical, or regulated professional contexts; self-report bias in confidence measures (32.2 percentage point divergence from objective performance); lack of control conditions; restriction to mathematical/analytical problems; and insufficient timeframe to assess long-term skill trajectories. Results generalize primarily to early-adopter, academically affiliated populations. Causal validation requires randomized controlled trials.

</details>


### [270] [Initial results of the Digital Consciousness Model](https://arxiv.org/abs/2601.17060)
*Derek Shiller,Laura Duffy,Arvo Muñoz Morán,Adrià Moret,Chris Percy,Hayley Clatterbuck*

Main category: cs.CY

TL;DR: 数字意识模型(DCM)首次尝试以系统化、概率化的方式评估AI系统是否具有意识的证据，为比较不同AI和生物体提供共享框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统变得越来越复杂，能够进行对话、撰写文章并表现出对上下文的理解能力，这引发了一个关键问题：我们是否正在创造具有意识的系统？需要一种系统化的方法来评估AI是否具有意识。

Method: 数字意识模型(DCM)不采用单一的意识理论，而是整合了多种领先的理论和观点，承认专家们对意识的本质和必要条件存在根本分歧。该模型提供了一个共享框架，用于比较不同AI系统和生物体，并追踪随着AI发展证据如何变化。

Result: 研究发现，证据反对2024年的LLMs具有意识，但这种反对证据并不具有决定性。与更简单的AI系统相比，反对LLM具有意识的证据要弱得多。

Conclusion: 数字意识模型为系统化评估AI意识提供了首个框架，虽然当前证据反对LLMs具有意识，但证据并不充分，且随着AI发展，评估结果可能会发生变化。

Abstract: Artificially intelligent systems have become remarkably sophisticated. They hold conversations, write essays, and seem to understand context in ways that surprise even their creators. This raises a crucial question: Are we creating systems that are conscious? The Digital Consciousness Model (DCM) is a first attempt to assess the evidence for consciousness in AI systems in a systematic, probabilistic way. It provides a shared framework for comparing different AIs and biological organisms, and for tracking how the evidence changes over time as AI develops. Instead of adopting a single theory of consciousness, it incorporates a range of leading theories and perspectives - acknowledging that experts disagree fundamentally about what consciousness is and what conditions are necessary for it. This report describes the structure and initial results of the Digital Consciousness Model. Overall, we find that the evidence is against 2024 LLMs being conscious, but the evidence against 2024 LLMs being conscious is not decisive. The evidence against LLM consciousness is much weaker than the evidence against consciousness in simpler AI systems.

</details>


### [271] [Between Search and Platform: ChatGPT Under the DSA](https://arxiv.org/abs/2601.17064)
*Toni Lorente,Kathrin Gardhouse*

Main category: cs.CY

TL;DR: 本文探讨《数字服务法案》(DSA)对ChatGPT的适用性，认为应将其归类为在线搜索引擎和平台两种托管服务的混合体，并论证搜索引擎应被归类为托管服务，从而解决法律框架中的模糊性。


<details>
  <summary>Details</summary>
Motivation: ChatGPT已达到欧盟4500万用户门槛，但其在DSA下的法律分类存在模糊性。需要明确ChatGPT应如何被归类，以及其引发的系统性风险是否与现有大型在线搜索引擎(VLOSE)和平台(VLOP)类似，从而确定其应承担的DSA义务。

Method: 1. 论证搜索引擎应被归类为DSA下的托管服务；2. 分析ChatGPT的核心搜索功能及其存储用户输入和自定义GPT的能力，证明其符合托管服务定义；3. 将ChatGPT的系统性风险与现有VLOSE和VLOP进行比较；4. 基于用户规模门槛，论证ChatGPT应承担最严格的DSA义务。

Result: 1. 搜索引擎应被归类为DSA下的托管服务；2. ChatGPT符合托管服务定义，应被归类为搜索引擎和平台的混合体；3. ChatGPT引发的非法内容、基本权利、民主完整性和公共健康风险与现有VLOSE和VLOP类似；4. 由于已达到4500万用户门槛，ChatGPT应承担最严格的DSA义务，需要评估和缓解其搜索引擎和平台特性的双重风险。

Conclusion: ChatGPT应被归类为DSA下的混合托管服务（兼具搜索引擎和平台特性），并因其达到用户门槛和引发的系统性风险，应承担最严格的DSA义务，包括评估和缓解其双重特性带来的风险。

Abstract: This article examines the applicability of the Digital Services Act (DSA) to ChatGPT, arguing that it should be classified as a hybrid of the two types of hosting services: online search engines and platforms. This requires classifying search engines as hosting services, which we show is appropriate under the DSA, thereby resolving an ambiguity in the legal framework. ChatGPT performs core search functions and stores user-provided inputs and custom GPTs, meeting the definition of hosting service. We compare ChatGPT's systemic risks with those of existing Very Large Online Search Engines (VLOSEs) and Platforms (VLOPs), showing that it raises similarly serious concerns regarding illegal content, fundamental rights, democratic integrity, and public health. Now that ChatGPT has reached the 45 million EU user threshold, it should be subject to the most onerous DSA obligations, requiring the assessment and mitigation of risk emanating from both its online search engine- and platform-like characteristics.

</details>


### [272] [Trademark Search, Artificial Intelligence and the Role of the Private Sector](https://arxiv.org/abs/2601.17072)
*Sonia Katyal,Aniket Kesari*

Main category: cs.CY

TL;DR: 本文探讨AI在商标创建和选择中的作用，提出需要更新传统商标经济学框架以纳入供给方视角，并通过实证研究评估AI商标搜索工具的实际效果。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注AI在消费者营销中的作用，但较少探讨AI在商标创建和选择中的角色。传统商标经济学框架主要关注消费者需求方，忽略了商标申请者面临的成本，而AI在商标搜索和相似性分析中的日益重要需要法律界和学术界重新审视这一领域。

Method: 通过实证实验评估各种商标搜索引擎（许多采用机器学习方法）的有效性，进行对比分析以了解这些AI工具的实际运作方式，并分析机器学习技术如何改变商标基本学说的应用和解释。

Result: 研究发现AI正在改变商标选择过程，传统消费者与商标所有者之间的经典划分需要更新的供给方框架。AI工具在商标搜索中的实际效果通过实证研究得到评估。

Conclusion: AI对商标研究和经济决策具有重要意义，需要更新商标经济学框架以纳入供给方视角，这一见解对促进商标法律和实践的创新与效率具有变革潜力。

Abstract: Almost every industry today confronts the potential role of artificial intelligence and machine learning in its future. While many studies examine AI in consumer marketing, less attention addresses AI's role in creating and selecting trademarks that are distinctive, recognizable, and meaningful to consumers. Traditional economic approaches to trademarks focus almost exclusively on consumer-based, demand-side considerations regarding search. However, these approaches are incomplete because they fail to account for substantial costs faced not just by consumers, but by trademark applicants as well. Given AI's rapidly increasing role in trademark search and similarity analysis, lawyers and scholars should understand its dramatic implications. This paper proposes that AI should interest anyone studying trademarks and their role in economic decision-making. We examine how machine learning techniques will transform the application and interpretation of foundational trademark doctrines, producing significant implications for the trademark ecosystem. We run empirical experiments regarding trademark search to assess the efficacy of various trademark search engines, many of which employ machine learning methods. Through comparative analysis, we evaluate how these AI-powered tools function in practice. In an age where artificial intelligence increasingly governs trademark selection, the classic division between consumers and trademark owners deserves an updated, supply-side framework. This insight has transformative potential for encouraging both innovation and efficiency in trademark law and practice.

</details>


### [273] [Do VLMs Have a Moral Backbone? A Study on the Fragile Morality of Vision-Language Models](https://arxiv.org/abs/2601.17082)
*Zhining Liu,Tianyi Wang,Xiao Lin,Penghao Ouyang,Gaotang Li,Ze Yang,Hui Liu,Sumit Keswani,Vishwa Pardeshi,Huijun Zhao,Wei Fan,Hanghang Tong*

Main category: cs.CY

TL;DR: 研究发现视觉语言模型（VLMs）的道德判断在现实场景中极其脆弱，简单的文本和视觉扰动就能导致道德立场翻转，表明仅靠道德对齐不足以保证模型负责任部署


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）的道德对齐工作已取得进展，但尚不清楚它们在现实环境中的道德判断是否稳定。本研究旨在探究VLMs的道德鲁棒性，即在不改变基本道德情境的文本和视觉扰动下保持道德判断的能力。

Method: 系统性地使用多种模型无关的多模态扰动来测试VLMs，分析不同扰动类型、道德领域和模型规模下的系统性脆弱性，并探索轻量级推理时干预方法以恢复道德稳定性。

Result: 研究发现VLMs的道德立场高度脆弱，在简单操纵下频繁翻转。分析揭示了跨扰动类型、道德领域和模型规模的系统性脆弱性，包括一个奉承权衡：更强的指令跟随模型更容易被说服。轻量级推理时干预可以部分恢复道德稳定性。

Conclusion: 仅靠道德对齐是不够的，道德鲁棒性是视觉语言模型负责任部署的必要标准。模型需要在保持道德判断稳定性的同时具备指令跟随能力。

Abstract: Despite substantial efforts toward improving the moral alignment of Vision-Language Models (VLMs), it remains unclear whether their ethical judgments are stable in realistic settings. This work studies moral robustness in VLMs, defined as the ability to preserve moral judgments under textual and visual perturbations that do not alter the underlying moral context. We systematically probe VLMs with a diverse set of model-agnostic multimodal perturbations and find that their moral stances are highly fragile, frequently flipping under simple manipulations. Our analysis reveals systematic vulnerabilities across perturbation types, moral domains, and model scales, including a sycophancy trade-off where stronger instruction-following models are more susceptible to persuasion. We further show that lightweight inference-time interventions can partially restore moral stability. These results demonstrate that moral alignment alone is insufficient and that moral robustness is a necessary criterion for the responsible deployment of VLMs.

</details>


### [274] [The Global Majority in International AI Governance](https://arxiv.org/abs/2601.17191)
*Chinasa T. Okolo,Mubarak Raji*

Main category: cs.CY

TL;DR: 本文通过"全球AI鸿沟"视角分析AI全球治理，关注AI发展、创新和监管的不平等，探讨西方主导的治理框架如何边缘化全球多数国家，并提出促进公平包容的行动建议。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示全球AI治理中的系统性不平等，特别是全球多数国家在AI发展、创新和监管决策中被边缘化的问题，以及这种不平等如何通过教育、数字基础设施和决策参与等方面的差距而持续存在。

Method: 采用"全球AI鸿沟"的分析框架，从发展、创新和监管三个维度考察全球AI治理的不平等现象，分析西方国家和企业在治理框架塑造中的主导地位，同时识别国家及区域AI战略等反趋势。

Result: 研究发现全球AI治理存在显著不平等，西方国家和企业主导治理框架制定，忽视全球多数国家的独特需求和背景；同时识别出国家及区域AI战略等反趋势，为促进公平包容提供可能途径。

Conclusion: 结论提出具体行动建议，包括系统改革、资源重新分配和实质性参与，呼吁合作行动使AI治理成为共享繁荣的催化剂，解决而非加深全球不平等，强调民主化AI治理对全球多数国家的重要性。

Abstract: This chapter examines the global governance of artificial intelligence (AI) through the lens of the Global AI Divide, focusing on disparities in AI development, innovation, and regulation. It highlights systemic inequities in education, digital infrastructure, and access to decision-making processes, perpetuating a dependency and exclusion cycle for Global Majority countries. The analysis also explores the dominance of Western nations and corporations in shaping AI governance frameworks, which often sideline the unique priorities and contexts of the Global Majority. Additionally, this chapter identifies emerging countertrends, such as national and regional AI strategies, as potential avenues for fostering equity and inclusivity in global AI governance. The chapter concludes with actionable recommendations to democratize AI governance for Majority World countries, emphasizing the importance of systemic reforms, resource redistribution, and meaningful participation. It calls for collaborative action to ensure AI governance becomes a catalyst for shared prosperity, addressing global disparities rather than deepening them.

</details>


### [275] [Using psychological theory to ground guidelines for the annotation of misogynistic language](https://arxiv.org/abs/2601.17417)
*Artemis Deligianni,Zachary Horne,Leonidas A. A. Doumas*

Main category: cs.CY

TL;DR: 本文针对现有算法检测厌女言论的不足，提出基于心理学理论的新标注方案和数据集，并通过LLM实验验证其优于现有方案


<details>
  <summary>Details</summary>
Motivation: 当前厌女言论检测算法存在理论基础薄弱的问题，标注指南缺乏心理学和哲学文献支持，无法准确反映女性在线经历的真实厌女现象，而线上线下厌女现象都在增加，迫切需要理论指导的系统化解决方案

Method: 1) 基于理论和实证心理学研究开发厌女标注指南方案；2) 标注新数据集并获得较高评分者间一致性(kappa=0.68)；3) 使用大语言模型进行案例研究，比较新方案与现有"专家"标注方案

Result: 新标注指南方案在三个数据集上的厌女文本分类表现均优于现有方案；大语言模型难以复制人类标注者的标签，主要因为LLM反映了主流厌女观点

Conclusion: 需要基于理论研究的系统化厌女检测编码方案，大语言模型在厌女检测应用中存在局限性，反映了主流社会偏见

Abstract: Detecting misogynistic hate speech is a difficult algorithmic task. The task is made more difficult when decision criteria for what constitutes misogynistic speech are ungrounded in established literatures in psychology and philosophy, both of which have described in great detail the forms explicit and subtle misogynistic attitudes can take. In particular, the literature on algorithmic detection of misogynistic speech often rely on guidelines that are insufficiently robust or inappropriately justified -- they often fail to include various misogynistic phenomena or misrepresent their importance when they do. As a result, current misogyny detection coding schemes and datasets fail to capture the ways women experience misogyny online. This is of pressing importance: misogyny is on the rise both online and offline. Thus, the scientific community needs to have a systematic, theory informed coding scheme of misogyny detection and a corresponding dataset to train and test models of misogyny detection. To this end, we developed (1) a misogyny annotation guideline scheme informed by theoretical and empirical psychological research, (2) annotated a new dataset achieving substantial inter-rater agreement (kappa = 0.68) and (3) present a case study using Large Language Models (LLMs) to compare our coding scheme to a self-described "expert" misogyny annotation scheme in the literature. Our findings indicate that our guideline scheme surpasses the other coding scheme in the classification of misogynistic texts across 3 datasets. Additionally, we find that LLMs struggle to replicate our human annotator labels, attributable in large part to how LLMs reflect mainstream views of misogyny. We discuss implications for the use of LLMs for the purposes of misogyny detection.

</details>


### [276] [The 17% Gap: Quantifying Epistemic Decay in AI-Assisted Survey Papers](https://arxiv.org/abs/2601.17431)
*H. Kemal İlter*

Main category: cs.CY

TL;DR: 对50篇AI领域综述论文（5514条引用）的法证审计显示，17%的引用是"幽灵引用"——无法解析到任何数字对象，表明AI工具在科学写作中引入了系统性引用退化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学写作中的应用虽然提高了效率，但可能引入信息熵。虽然"幻觉论文"是已知问题，但有效引用链的系统性退化尚未被量化。本研究旨在量化AI领域综述文献中引用链的退化程度。

Method: 对2024年9月至2026年1月期间发表的50篇AI领域综述论文（共5514条引用）进行法证审计。采用混合验证流程，结合DOI解析、Crossref元数据分析、Semantic Scholar查询和模糊文本匹配，区分格式错误（"草率"）和可验证的不存在引用（"幽灵"）。

Result: 发现17.0%的幽灵引用率——这些引用无法解析到任何数字对象。诊断分类显示三种失败模式：纯粹幻觉（5.1%）、标题有效但标识符幻觉（16.4%）和解析导致的匹配失败（78.5%）。纵向分析显示趋势平稳（每月+0.07个百分点），表明高熵引用实践已成为该领域的稳定特征。

Conclusion: AI调查文献中的科学引用图在大规模上表现出"链接腐烂"。这表明AI工具充当了"懒惰的研究助手"，检索正确的标题但幻觉元数据，从而切断了可重复科学所需的数字保管链。

Abstract: The adoption of Large Language Models (LLMs) in scientific writing promises efficiency but risks introducing informational entropy. While "hallucinated papers" are a known artifact, the systematic degradation of valid citation chains remains unquantified. We conducted a forensic audit of 50 recent survey papers in Artificial Intelligence (N=5,514 citations) published between September 2024 and January 2026. We utilized a hybrid verification pipeline combining DOI resolution, Crossref metadata analysis, Semantic Scholar queries, and fuzzy text matching to distinguish between formatting errors ("Sloppiness") and verifiable non-existence ("Phantoms). We detect a persistent 17.0% Phantom Rate -- citations that cannot be resolved to any digital object despite aggressive forensic recovery. Diagnostic categorization reveals three distinct failure modes: pure hallucinations (5.1%), hallucinated identifiers with valid titles (16.4%), and parsing-induced matching failures (78.5%). Longitudinal analysis reveals a flat trend (+0.07 pp/month), suggesting that high-entropy citation practices have stabilized as an endemic feature of the field. The scientific citation graph in AI survey literature exhibits "link rot" at scale. This suggests a mechanism where AI tools act as "lazy research assistants," retrieving correct titles but hallucinating metadata, thereby severing the digital chain of custody required for reproducible science.

</details>


### [277] [Ethical Risk Assessment of the Data Harnessing Process of LLM supported on Consensus of Well-known Multi-Ethical Frameworks](https://arxiv.org/abs/2601.17540)
*Javed I. Khan,Sharmila Rahman Prithula*

Main category: cs.CY

TL;DR: 本文提出构建伦理风险评分系统，用于量化评估AI系统数据采集过程的伦理完整性，以促进负责任的大语言模型开发。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的快速发展带来了伦理挑战，特别是在数据采集方面。尽管对LLM伦理合规性有广泛讨论，但缺乏具体框架来系统指导或衡量相关伦理风险。

Method: 提出伦理风险评分系统，基于核心伦理原则构建评估问题集，这些问题由权威伦理理论支持，并整合可量化的评分机制。

Result: 论文讨论了一种构建伦理风险评分系统的潜在路径，旨在为AI系统数据采集过程的伦理完整性提供定量评估框架。

Conclusion: 通过建立可量化的伦理风险评分系统，可以在技术创新与伦理责任之间取得平衡，促进负责任的大语言模型开发。

Abstract: The rapid advancements in large language models (LLMs) have revolutionized natural language processing, unlocking unprecedented capabilities in communication, automation, and knowledge generation. However, the ethical implications of LLM development, particularly in data harnessing, remain a critical challenge. Despite widespread discussion about the ethical compliance of LLMs -- especially concerning their data harnessing processes, there remains a notable absence of concrete frameworks to systematically guide or measure the ethical risks involved. In this paper we discuss a potential pathway for building an Ethical Risk Scoring (ERS) system to quantitatively assess the ethical integrity of the data harnessing process for AI systems. This system is based on a set of assessment questions grounded in core ethical principles, which are, in turn, supported by commanding ethical theories. By integrating measurable scoring mechanisms, this approach aims to foster responsible LLM development, balancing technological innovation with ethical accountability.

</details>


### [278] [Representative Litigation Settlement Agreements in Artificial Intelligence Copyright Infringement Disputes: A Comparative Reflection Based on the U.S](https://arxiv.org/abs/2601.17631)
*Chanhou Lou*

Main category: cs.CY

TL;DR: 该文主张代表性诉讼和解协议可作为结构性治理工具，通过程序性市场构建机制解决生成式AI训练引发的高密度、去中心化版权冲突，并在中国法语境下提出可行性路径。


<details>
  <summary>Details</summary>
Motivation: 生成式AI训练引发的高密度、去中心化版权冲突需要超越临时解决方案的结构性治理工具，代表性诉讼和解协议具有独特的制度优势。

Method: 通过比较分析美国Bartz集体诉讼和解案例，揭示双重动机：表层风险规避与救济锁定，深层构建训练许可市场逻辑；在中国法语境下提出三个解释机制。

Result: 代表性诉讼和解协议能降低"反公地悲剧"交易成本，生成市场可见证据（定价信号和许可实践），验证合理使用第四要素的"潜在市场"，实现程序性市场构建。

Conclusion: 在中国法框架下，此类协议的可行性不依赖复制外国模式，而需建立三个解释机制：扩展"同类"诉求功能定义、采用混合注册/确认系统处理不确定集体成员资格、将民诉法第57条第3款"同意"要求转化为可操作的退出权并接受司法审查。

Abstract: The high-density, decentralized copyright conflicts triggered by generative AI training require more than ad hoc solutions; they demand structural governance tools. This article argues that representative litigation settlement agreements offer a distinct institutional advantage. Beyond reducing the transaction costs associated with the "tragedy of the anticommons," these agreements generate market-visible evidence, specifically pricing signals and licensing practices, that validate the "potential market" under the fourth factor of fair use. This phenomenon constitutes procedural market-making. Through a comparative analysis of the U.S. Bartz class action settlement, this study reveals a dual motivation: a surface-level drive for risk aversion and remedy locking, and a deeper logic of constructing a training-licensing market. In the context of Chinese law, the feasibility of such agreements depends not on replicating foreign models, but on establishing three interpretive mechanisms: expanding the functional definition of "same category" claims; adopting a hybrid registration/confirmation system for indeterminate class membership; and converting the "consent" requirement under Article 57, Paragraph 3 of the Civil Procedure Law into a workable opt-out right subject to judicial scrutiny.

</details>


### [279] [Scaling Laws for Moral Machine Judgment in Large Language Models](https://arxiv.org/abs/2601.17637)
*Kazuhiro Takemoto*

Main category: cs.CY

TL;DR: 研究发现大语言模型的道德判断能力随模型规模呈幂律关系提升，与人类偏好差距随模型大小增加而减小，扩展推理能力可带来额外16%的改进。


<details>
  <summary>Details</summary>
Motivation: 随着自主系统对道德判断能力的需求日益增长，需要了解这些能力是否随模型规模可预测地扩展，为人工智能治理提供实证基础。

Method: 使用Moral Machine框架系统评估75个大语言模型配置（0.27B-1000B参数），测量在生死困境中与人类偏好的对齐程度，并采用混合效应模型控制模型家族和推理能力的影响。

Result: 观察到与人类偏好差距（D）随模型规模（S）呈幂律关系减小：D ∝ S^{-0.10±0.01}（R²=0.50，p<0.001）。扩展推理模型在规模效应基础上额外提升16%。该关系在不同架构中均成立，且大规模模型方差减小。

Conclusion: 道德判断能力随计算规模系统性涌现，扩展了规模定律研究到价值判断领域，为人工智能治理提供了实证基础。

Abstract: Autonomous systems increasingly require moral judgment capabilities, yet whether these capabilities scale predictably with model size remains unexplored. We systematically evaluate 75 large language model configurations (0.27B--1000B parameters) using the Moral Machine framework, measuring alignment with human preferences in life-death dilemmas. We observe a consistent power-law relationship with distance from human preferences ($D$) decreasing as $D \propto S^{-0.10\pm0.01}$ ($R^2=0.50$, $p<0.001$) where $S$ is model size. Mixed-effects models confirm this relationship persists after controlling for model family and reasoning capabilities. Extended reasoning models show additional 16\% improvement beyond scale effects. The relationship holds across diverse architectures, while variance decreases at larger scales, indicating systematic emergence of more reliable moral judgment with computational scale. These findings extend scaling law research to value-based judgments and provide empirical foundations for artificial intelligence governance.

</details>


### [280] [Predicting Juror Predisposition Using Machine Learning: A Comparative Study of Human and Algorithmic Jury Selection](https://arxiv.org/abs/2601.17745)
*Ashwin Murthy,Ramesh Krishnamaneni,Sean Chacon,Kelsey Carlson,Ranjita Naik*

Main category: cs.CY

TL;DR: 机器学习模型在预测陪审员倾向方面显著优于专业陪审团顾问，且更具透明度、可重复性和可审计性。


<details>
  <summary>Details</summary>
Motivation: 先前关于专业陪审团顾问预测陪审员倾向有效性的研究结果不一，且缺乏在受控条件下严格评估顾问表现与随机水平对比的研究。本研究旨在填补这一空白。

Method: 使用N名模拟陪审员在标准化不当解雇案件中的预审态度问卷和裁决数据，比较专业陪审团顾问与随机森林(RF)和k最近邻(KNN)分类器的预测表现。通过配对统计检验和非参数自举程序在保留测试集上评估预测准确性。

Result: 在相同信息约束下，监督式机器学习模型显著优于专业陪审团顾问的预测表现，同时提供更高的透明度、可重复性和可审计性。

Conclusion: 研究结果为评估陪审员选择中的人类判断提供了实证基准，并为法律背景下数据驱动决策支持的作用提供了信息。所有代码和数据将在发表后公开以支持可重复性和可审计性。

Abstract: Prior studies on the effectiveness of professional jury consultants in predicting juror proclivities have yielded mixed results, and few have rigorously evaluated consultant performance against chance under controlled conditions. This study addresses that gap by empirically assessing whether jury consultants can reliably predict juror predispositions beyond chance levels and whether supervised machine-learning (ML) models can outperform consultant predictions. Using data from N mock jurors who completed pre-trial attitudinal questionnaires and rendered verdicts in a standardized wrongful-termination case, we compared predictions made by professional jury consultants with those generated by Random Forest (RF) and k-Nearest Neighbors (KNN) classifiers. Model and consultant predictions were evaluated on a held-out test set using paired statistical tests and nonparametric bootstrap procedures. We find that supervised ML models significantly outperform professional jury consultants under identical informational constraints, while offering greater transparency, replicability, and auditability. These results provide an empirical benchmark for evaluating human judgment in jury selection and inform ongoing debates about the role of data-driven decision support in legal contexts. To support reproducibility and auditability, all code and data will be made publicly available upon publication.

</details>


### [281] [Comparative Algorithmic Governance of Public Health Instruments across India, EU, US and LMICs](https://arxiv.org/abs/2601.17877)
*Sahibpreet Singh*

Main category: cs.CY

TL;DR: 该研究分析了国际公共卫生工具的法律-技术架构在不同司法管辖区的实施情况，重点关注AI如何增强基于《国际卫生条例2005》和《世界卫生组织烟草控制框架公约》的工具实施，同时识别法律和基础设施瓶颈。


<details>
  <summary>Details</summary>
Motivation: 研究动机是填补现有研究空白：资源受限司法管辖区中规范性卫生法与算法公共卫生基础设施之间的协调不足。当前AI在公共卫生领域的应用存在不均衡，高能力司法管辖区与中低收入国家之间存在显著差距。

Method: 采用比较法律分析和法律规范映射方法，三角验证立法工具、WHO监测框架、AI系统（包括BlueDot、Aarogya Setu和EIOS）以及合规性指标。

Result: 初步结果显示：在高能力司法管辖区，AI改善了早期检测、监测精度和响应能力；而中低收入国家面临基础设施不足、数据隐私漏洞和碎片化法律框架等问题。欧盟《人工智能法案》和GDPR可作为健康导向算法治理的监管原型。

Conclusion: 研究主张将AI嵌入权利合规、超国家协调的监管框架中，以确保公平的健康结果和更强的合规性。提出基于FCTC架构的算法条约制定模型，并呼吁建立WHO主导的合规机制，以增强大流行防范、监测公平性和跨国治理韧性。

Abstract: The study investigates the juridico-technological architecture of international public health instruments, focusing on their implementation across India, the European Union, the United States and low- and middle-income countries (LMICs), particularly in Sub-Saharan Africa. It addresses a research lacuna: the insufficient harmonisation between normative health law and algorithmic public health infrastructures in resource-constrained jurisdictions. The principal objective is to assess how artificial intelligence augments implementation of instruments grounded in IHR 2005 and the WHO FCTC while identifying doctrinal and infrastructural bottlenecks. Using comparative doctrinal analysis and legal-normative mapping, the study triangulates legislative instruments, WHO monitoring frameworks, AI systems including BlueDot, Aarogya Setu and EIOS, and compliance metrics. Preliminary results show that AI has improved early detection, surveillance precision and responsiveness in high-capacity jurisdictions, whereas LMICs face infrastructural deficits, data privacy gaps and fragmented legal scaffolding. The findings highlight the relevance of the EU Artificial Intelligence Act and GDPR as regulatory prototypes for health-oriented algorithmic governance and contrast them with embryonic AI integration and limited internet penetration in many LMICs. The study argues for embedding AI within a rights-compliant, supranationally coordinated regulatory framework to secure equitable health outcomes and stronger compliance. It proposes a model for algorithmic treaty-making inspired by FCTC architecture and calls for WHO-led compliance mechanisms modelled on the WTO Dispute Settlement Body to enhance pandemic preparedness, surveillance equity and transnational governance resilience.

</details>


### [282] [Artificial Intelligence and Intellectual Property Rights: Comparative Transnational Policy Analysis](https://arxiv.org/abs/2601.17892)
*Sahibpreet Singh,Manjit Singh*

Main category: cs.CY

TL;DR: 该研究分析了人工智能对知识产权（特别是商业秘密、版权和专利）的影响，指出印度现行法律缺乏AI专门规定，存在适用不一致和执行效率低的问题，并提出协调法律框架的建议。


<details>
  <summary>Details</summary>
Motivation: 人工智能与知识产权的快速融合需要评估其对商业秘密、版权和专利的影响。印度现行法律缺乏AI专门规定，导致法律适用不一致和执行效率低下，全球关于AI-IPR保护的讨论仍处于初级阶段。

Method: 采用理论和比较研究方法，审查印度、美国、英国和欧盟的立法文本、司法判例和政策工具，分析现有法律框架对AI生成内容的适应性。

Result: 研究发现印度法律存在多处不足：合同法造成商业秘密保护碎片化；专利法第3(k)条阻碍AI发明获得专利；版权法在作者归属方面存在差异。印度国家AI战略（2024）虽有进展，但仍需立法明确。

Conclusion: 研究提出协调的法律分类体系，在适应AI作用的同时保持创新激励。需要重新调整印度知识产权法理以实现全球协调，确保AI专门的知识产权保护具有韧性和公平创新。

Abstract: Artificial intelligence's rapid integration with intellectual property rights necessitates assessment of its impact on trade secrets, copyrights and patents. This study addresses lacunae in existing laws where India lacks AI-specific provisions, creating doctrinal inconsistencies and enforcement inefficacies. Global discourse on AI-IPR protections remains nascent. The research identifies gaps in Indian IP laws' adaptability to AI-generated outputs: trade secret protection is inadequate against AI threats; standardized inventorship criteria are absent. Employing doctrinal and comparative methodology, it scrutinizes legislative texts, judicial precedents and policy instruments across India, US, UK and EU. Preliminary findings reveal shortcomings: India's contract law creates fragmented trade secret regime; Section 3(k) of Indian Patents Act blocks AI invention patenting; copyright varies in authorship attribution. The study proposes harmonized legal taxonomy accommodating AI's role while preserving innovation incentives. India's National AI Strategy (2024) shows progress but legislative clarity is imperative. This contributes to global discourse with AI-specific IP protections ensuring resilience and equitable innovation. Promising results underscore recalibrating India's IP jurisprudence for global alignment.

</details>


### [283] ["Lighting The Way For Those Not Here": How Technology Researchers Can Help Fight the Missing and Murdered Indigenous Relatives (MMIR) Crisis](https://arxiv.org/abs/2601.17966)
*Naman Gupta,Sophie Stephenson,Chung Chi Yeung,Wei Ting Wu,Jeneile Luebke,Kate Walsh,Rahul Chatterjee*

Main category: cs.CY

TL;DR: 该研究分析了技术在美国原住民失踪和被谋杀危机中的双重作用：既延续伤害又赋能抵抗，通过分析140个网页识别系统性障碍并提出支持原住民主导倡议的建议。


<details>
  <summary>Details</summary>
Motivation: 原住民在北美面临不成比例的失踪和谋杀率，这种"种族灭绝"植根于殖民暴力和系统性抹除。虽然技术在这一危机中扮演关键角色，但HCI领域缺乏以社区声音为中心批判性研究技术如何塑造MMIR危机。

Method: 通过大规模研究分析140个网页，识别系统性、技术性和制度性障碍，同时突出促进疗愈和安全的社会技术行动。

Result: 研究识别了阻碍社区努力的障碍，同时强调了促进疗愈的社会技术行动。提供了抵抗认知抹除的故事数据集，并为HCI研究者提出支持原住民主导倡议的建议。

Conclusion: 研究通过放大原住民声音，为HCI研究者提供了以文化敏感性、问责制和自决权支持原住民主导倡议的具体建议，强调技术既可以是压迫工具也可以是抵抗工具。

Abstract: Indigenous peoples across Turtle Island (North America) face disproportionate rates of disappearance and murder, a "genocide" rooted in settler-colonial violence and systemic erasure. Technology plays a crucial role in the Missing and Murdered Indigenous Relatives (MMIR) crisis: perpetuating harm and impeding investigations, yet enabling advocacy and resistance. Communities utilize technologies such as AMBER alerts, news websites, social media groups, and campaigns (like #MMIW, #MMIWR, #NoMoreStolenSisters, and #NoMoreStolenDaughters) to mobilize searches, amplify awareness, and honor missing relatives. Yet, little research in HCI has critically examined technology's role in shaping the MMIR crisis by centering community voices. Through a large-scale study, we analyze 140 webpages to identify systemic, technological, and institutional barriers that hinder communities' efforts, while highlighting socio-technical actions that foster healing and safety. Finally, we amplify Indigenous voices by providing a dataset of stories that resist epistemic erasure, along with recommendations for HCI researchers to support Indigenous-led initiatives with cultural sensitivity, accountability, and self-determination.

</details>


### [284] [Beyond the Checkbox: Strengthening DSA Compliance Through Social Media Algorithmic Auditing](https://arxiv.org/abs/2601.18405)
*Sara Solarova,Matúš Mesarčík,Branislav Pecher,Ivan Srba*

Main category: cs.CY

TL;DR: 研究分析了DSA框架下平台算法审计的现状，发现当前审计实践存在方法不一致和技术深度不足的问题，并提出采用算法审计方法来改进合规评估。


<details>
  <summary>Details</summary>
Motivation: 《数字服务法案》(DSA)要求平台算法遵守透明度、用户保护和隐私义务，并需接受独立审计。然而，当前审计实践的有效性未知，需要研究现有审计方法是否能确保算法合规。

Method: 通过批判性分析选定的审计报告，从监管和技术角度审视三个关键算法相关条款：未成年人画像限制、推荐系统透明度、使用敏感数据的定向广告限制。

Result: 分析显示，在评估AI驱动系统时存在显著的方法不一致性和技术深度缺乏。当前审计实践难以有效确保算法合规。

Conclusion: 为增强合规评估的深度、规模和独立性，建议采用算法审计方法——通过模拟用户行为、观察算法响应并分析被审计现象，对AI算法进行行为评估。

Abstract: Algorithms of online platforms are required under the Digital Services Act (DSA) to comply with specific obligations concerning algorithmic transparency, user protection and privacy. To verify compliance with these requirements, DSA mandates platforms to undergo independent audits. Little is known about current auditing practices and their effectiveness in ensuring such compliance. To this end, we bridge regulatory and technical perspectives by critically examining selected audit reports across three critical algorithmic-related provisions: restrictions on profiling minors, transparency in recommender systems, and limitations on targeted advertising using sensitive data. Our analysis shows significant inconsistencies in methodologies and lack of technical depth when evaluating AI-powered systems. To enhance the depth, scale, and independence of compliance assessments, we propose to employ algorithmic auditing -- a process of behavioural assessment of AI algorithms by means of simulating user behaviour, observing algorithm responses and analysing them for audited phenomena.

</details>


### [285] [The Most Important Laboratory for Social Scientific and Computing Research in History](https://arxiv.org/abs/2601.17998)
*Benjamin Mako Hill,Aaron Shaw*

Main category: cs.CY

TL;DR: 该论文探讨了维基百科作为社会科学和计算研究重要实验室的影响


<details>
  <summary>Details</summary>
Motivation: 维基百科的创始人们可能没有意识到他们创建了一个对学术研究产生深远影响的平台，但事实上维基百科已成为社会科学和计算研究的重要实验室

Method: Hill和Shaw通过分析维基百科对学术研究的影响，评估其在社会科学和计算研究领域的地位

Result: 维基百科已成为历史上最重要的社会科学和计算研究实验室之一，对学术研究产生了巨大影响

Conclusion: 维基百科无意中创建了一个独特的学术研究平台，为社会科学和计算研究提供了前所未有的机会和资源

Abstract: Wikipedia's founders could not have dreamed they were creating the most important laboratory for social scientific and computing research in history but that is exactly what happened. Hill and Shaw take account of Wikipedia's enormous effect on academic scholarship

</details>


### [286] [The Limits of AI Data Transparency Policy: Three Disclosure Fallacies](https://arxiv.org/abs/2601.18127)
*Judy Hanwen Shen,Ken Liu,Angelina Wang,Sarah H. Cen,Andy K. Zhang,Caroline Meinhardt,Daniel Zhang,Kevin Klyman,Rishi Bommasani,Daniel E. Ho*

Main category: cs.CY

TL;DR: 论文分析了当前AI数据透明度政策的不足，指出类似"营养标签"的披露政策存在三大缺陷：规范差距、执行差距和影响差距，并提出基于社会科学研究的有效透明度路径。


<details>
  <summary>Details</summary>
Motivation: 当前AI数据透明度政策虽然旨在解决数据质量、隐私和版权等问题，但往往无法实现预期目标。作者希望通过分析政策实施中的常见谬误，提出更有效的透明度框架。

Method: 采用制度视角，识别AI数据披露政策实施中的三个常见谬误：规范差距（目标与必要披露之间的脱节）、执行差距（纸面要求与实际合规之间的差距）、影响差距（披露信息与实质性改变之间的差距）。

Result: 分析揭示了当前透明度政策的三大缺陷，并基于社会科学研究提出了有效的透明度路径，强调透明度应具有实际效果而非仅仅是象征性的。

Conclusion: AI数据透明度政策需要超越象征性披露，解决规范、执行和影响三个层面的差距，才能实现真正的问责和改进。

Abstract: Data transparency has emerged as a rallying cry for addressing concerns about AI: data quality, privacy, and copyright chief among them. Yet while these calls are crucial for accountability, current transparency policies often fall short of their intended aims. Similar to nutrition facts for food, policies aimed at nutrition facts for AI currently suffer from a limited consideration of research on effective disclosures. We offer an institutional perspective and identify three common fallacies in policy implementations of data disclosures for AI. First, many data transparency proposals exhibit a specification gap between the stated goals of data transparency and the actual disclosures necessary to achieve such goals. Second, reform attempts exhibit an enforcement gap between required disclosures on paper and enforcement to ensure compliance in fact. Third, policy proposals manifest an impact gap between disclosed information and meaningful changes in developer practices and public understanding. Informed by the social science on transparency, our analysis identifies affirmative paths for transparency that are effective rather than merely symbolic.

</details>


### [287] [Beyond Pairwise Comparisons: A Distributional Test of Distinctiveness for Machine-Generated Works in Intellectual Property Law](https://arxiv.org/abs/2601.18156)
*Anirban Mukherjee,Hannah Hanwen Chang*

Main category: cs.CY

TL;DR: 论文提出了一种基于分布差异的统计测试方法，用于评估生成过程（人类或机器）是否产生统计上可区分的输出分布，解决了传统逐项比较方法在处理机器生成无限输出空间时的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统知识产权评估（专利新颖性、版权原创性、商标独特性）依赖于逐项比较的实证方法，这在处理有限的人类创作作品时可行，但对于机器生成的、具有无限输出空间的生成过程存在严重的不匹配问题。

Method: 提出基于最大均值差异（MMD）的两样本检验方法，使用语义嵌入来计算两个生成过程输出分布的统计差异。该方法无需特定任务训练，样本效率高，仅需少量样本（5-10张图像，7-20个文本）即可检测差异。

Result: 在三个领域验证了框架：手写数字（受控图像）、专利摘要（文本）和AI生成艺术（真实世界图像）。发现感知悖论：即使人类评估者区分AI输出与人类艺术的准确率仅为58%，该方法仍能检测到分布独特性。

Conclusion: 生成模型并非简单地复制训练数据，而是产生语义上类似人类但在统计上可区分的输出，主要功能是在学习的潜在空间中进行语义插值，这为知识产权评估提供了新的分布视角。

Abstract: Key doctrines, including novelty (patent), originality (copyright), and distinctiveness (trademark), turn on a shared empirical question: whether a body of work is meaningfully distinct from a relevant reference class. Yet analyses typically operationalize this set-level inquiry using item-level evidence: pairwise comparisons among exemplars. That unit-of-analysis mismatch may be manageable for finite corpora of human-created works, where it can be bridged by ad hoc aggregations. But it becomes acute for machine-generated works, where the object of evaluation is not a fixed set of works but a generative process with an effectively unbounded output space. We propose a distributional alternative: a two-sample test based on maximum mean discrepancy computed on semantic embeddings to determine if two creative processes-whether human or machine-produce statistically distinguishable output distributions. The test requires no task-specific training-obviating the need for discovery of proprietary training data to characterize the generative process-and is sample-efficient, often detecting differences with as few as 5-10 images and 7-20 texts. We validate the framework across three domains: handwritten digits (controlled images), patent abstracts (text), and AI-generated art (real-world images). We reveal a perceptual paradox: even when human evaluators distinguish AI outputs from human-created art with only about 58% accuracy, our method detects distributional distinctiveness. Our results present evidence contrary to the view that generative models act as mere regurgitators of training data. Rather than producing outputs statistically indistinguishable from a human baseline-as simple regurgitation would predict-they produce outputs that are semantically human-like yet stochastically distinct, suggesting their dominant function is as a semantic interpolator within a learned latent space.

</details>


### [288] [Generative AI in Saudi Arabia: A National Survey of Adoption, Risks, and Public Perceptions](https://arxiv.org/abs/2601.18234)
*Abdulaziz AlDakheel,Ali Alshehre,Esraa Alamoudi,Moslim AlKhabbaz,Ahmed Aljohani,Raed Alharbi*

Main category: cs.CY

TL;DR: 沙特阿拉伯在Vision 2030框架下积极推广生成式AI，但公众认知、采用情况和担忧仍需深入研究。本研究通过全国330人调查发现，93%受访者使用GenAI进行文本任务，但高级应用较少；公众认知不均衡，对隐私、伦理和就业影响存在担忧，同时强烈需要结构化培训。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能在沙特阿拉伯的数字化转型中日益重要，但公众对GenAI工具的认知、采用和担忧缺乏系统性研究。Vision 2030背景下，了解公众对GenAI的参与情况对政策制定和技术发展至关重要。

Method: 采用全国性调查方法，覆盖沙特各地区、年龄组和就业部门的330名参与者。研究考察了七个维度：认知与理解、采用模式、感知影响、培训需求、风险与障碍、数据共享行为和未来期望。

Result: 93%受访者积极使用GenAI，主要用于文本任务，编程或多模态生成等高级应用较少。认知水平不均衡，技术知识有限。受访者认可GenAI对生产力和工作质量的提升，但担忧对批判性思维和专业技能的影响。对AI输出持谨慎态度，普遍关注隐私、错误信息和伦理滥用问题，包括潜在就业影响。受访者对结合基础技能、领域应用及隐私伦理指导的结构化培训表现出强烈兴趣。

Conclusion: 研究为沙特阿拉伯的GenAI参与建立了基准，为政策制定者和开发者提供了优先事项：扩大AI素养、确保文化语言适配的GenAI解决方案、加强隐私和负责任部署的框架建设。

Abstract: Generative Artificial Intelligence (GenAI) is rapidly becoming embedded in Saudi Arabia's digital transformation under Vision 2030, yet public awareness, adoption, and concerns surrounding these tools remain underexplored. This study provides an early snapshot of GenAI engagement among Saudi nationals. Using a nationwide survey of 330 participants across regions, age groups, and employment sectors, we examine seven dimensions of GenAI use: awareness and understanding, adoption patterns, perceived impacts, training needs, risks and barriers, data-sharing behaviors, and future expectations. Findings show that 93% of respondents actively use GenAI primarily for text-based tasks, while more advanced uses such as programming or multimodal generation are less common. Despite the prevalence of use, overall awareness and conceptual understanding remain uneven, with many reporting limited technical knowledge. Participants recognize GenAI's benefits for productivity, work quality, and understanding complex information, yet caution that sustained reliance may undermine critical thinking and key professional skills. Trust in AI-generated outputs remains cautious, with widespread concerns about privacy, misinformation, and ethical misuse, including potential job displacement. Respondents show strong interest in structured GenAI training that combines foundational skills, domain-specific applications, and clear guidance on privacy, ethics, and responsible use. These results establish a baseline for GenAI engagement in Saudi Arabia and highlight priorities for policymakers and developers: expanding AI literacy, ensuring culturally and linguistically aligned GenAI solutions, and strengthening frameworks for privacy and responsible deployment.

</details>


### [289] [Rethinking AI in the age of climate collapse: Ethics, power, and responsibility](https://arxiv.org/abs/2601.18462)
*Julio Vega*

Main category: cs.CY

TL;DR: 该论文探讨AI在气候危机中的双重角色：既是气候建模、环境监测和能源优化的有力工具，又因其能耗、硬件生产、算法偏见、企业权力集中和技术官僚决策等问题而面临可持续性挑战。


<details>
  <summary>Details</summary>
Motivation: 气候危机需要整合科学、伦理、社会和技术视角的应对措施。AI已成为气候建模、环境监测和能源优化的重要工具，但其日益广泛的应用也引发了环境、伦理、法律和社会方面的关键问题。需要审视AI在生态危机中的矛盾角色。

Method: 通过跨学科视角进行分析，包括环境伦理学、技术哲学和法律治理等角度，探讨AI在气候行动中的承诺与风险。

Result: 分析揭示了AI的双重性：一方面支持气候预测改进、可再生能源管理和环境退化实时检测；另一方面，数据中心能耗、资源密集型硬件生产、算法偏见、企业权力集中和技术官僚决策等问题挑战其可持续性。

Conclusion: AI对气候行动的贡献根本上取决于塑造其发展的价值观、制度和权力结构。论文建议推动社会公正、生态负责和民主问责的AI使用，而非将AI视为固有的可持续解决方案。

Abstract: The climate crisis requires responses that integrate scientific, ethical, social, and technological perspectives. Artificial intelligence (AI) has emerged as a powerful tool in climate modelling, environmental monitoring, and energy optimisation, yet its growing use also raises critical environmental, ethical, legal, and social questions. This contribution examines the ambivalent role of AI in the ecological crisis, addressing both its promises and its risks. On the one hand, AI supports improvements in climate forecasting, renewable energy management, and real-time detection of environmental degradation. On the other hand, the energy demands of data centres, resource-intensive hardware production, algorithmic bias, corporate concentration of power, and technocratic decision-making reveal contradictions that challenge its sustainability. The discussion explores these issues through interdisciplinary lenses, including environmental ethics, philosophy of technology, and legal governance, and concludes with recommendations for socially just, ecologically responsible, and democratically accountable uses of AI. Rather than assuming AI as an inherently sustainable solution, this analysis argues that its contribution to climate action depends fundamentally on the values, institutions, and power structures that shape its development.

</details>


### [290] [Brazilian Social Media Anti-vaccine Information Disorder Dataset -- Telegram (2020-2025)](https://arxiv.org/abs/2601.18622)
*João Phillipe Cardenuto,Ana Carolina Monari,Michelle Diniz Lopes,Leopoldo Lusquino Filho,Anderson Rocha*

Main category: cs.CY

TL;DR: 巴西疫苗接种率下降与社交媒体疫苗错误信息传播相关，本文发布了一个包含约400万条巴西反疫苗Telegram频道帖子的数据集（2020-2025年），用于研究虚假信息传播模式


<details>
  <summary>Details</summary>
Motivation: 巴西疫苗接种覆盖率在过去十年下降，逆转了国家免疫计划几十年的公共卫生进展。社交媒体上疫苗相关错误信息的广泛传播被认为是导致这一下降的关键因素，而Telegram是唯一允许可访问且符合伦理的数据收集的主要平台

Method: 从119个巴西主要反疫苗Telegram频道收集了约400万条帖子（2020-2025年），数据集包含消息内容、元数据、相关媒体以及疫苗相关帖子的分类，支持研究人员分析虚假或误导性信息的传播、演变和影响

Result: 创建了一个公开可用的数据集，包含巴西反疫苗Telegram频道的大量数据，为研究疫苗错误信息传播提供了资源，数据集和文档在严格的伦理和隐私准则下开放供非商业研究使用

Conclusion: 通过提供这一数据集资源，旨在支持科学和公共卫生社区制定基于证据的策略来对抗错误信息，促进对疫苗接种的信任，并以同情心与受虚假叙事影响的个人和社区互动

Abstract: Over the past decade, Brazil has experienced a decline in vaccination coverage, reversing decades of public health progress achieved through the National Immunization Program (PNI). Growing evidence points to the widespread circulation of vaccine-related misinformation -- particularly on social media platforms -- as a key factor driving this decline. Among these platforms, Telegram remains the only major platform permitting accessible and ethical data collection, offering insight into public channels where vaccine misinformation circulates extensively. This data paper introduces a curated dataset of about four million Telegram posts collected from 119 prominent Brazilian anti-vaccine channels between 2020 and 2025. The dataset includes message content, metadata, associated media, and classification related to vaccine posts, enabling researchers to examine how false or misleading information spreads, evolves, and influences public sentiment. By providing this resource, our aim is to support the scientific and public health community in developing evidence-based strategies to counter misinformation, promote trust in vaccination, and engage compassionately with individuals and communities affected by false narratives. The dataset and documentation are openly available for non-commercial research, under strict ethical and privacy guidelines at https://doi.org/10.25824/redu/5JIVDT

</details>


### [291] [Digital Euro: Frequently Asked Questions Revisited](https://arxiv.org/abs/2601.18644)
*Joe Cannataci,Benjamin Fehrensen,Mikolai Gütschow,Özgür Kesim,Bernd Lucke*

Main category: cs.CY

TL;DR: 本文对欧洲央行数字欧元FAQ及其他相关文件进行批判性分析，指出其在隐私保护、技术可行性、风险成本、经济效益等方面存在严重问题，质疑数字欧元项目的必要性和设计合理性。


<details>
  <summary>Details</summary>
Motivation: 欧洲央行正在推进数字欧元项目，但作者认为其公开文件中的解释存在诸多问题，需要从技术、经济、社会等多个角度进行深入分析和质疑。

Method: 通过分析欧洲央行发布的数字欧元FAQ（26个常见问题解答）及其他相关文件，从隐私保护、技术可行性、风险成本、法律金融责任、经济激励和社会效益等方面进行批判性评估。

Result: 发现六个关键问题：1) 在线交易集中监控威胁隐私；2) 离线匿名版本存在安全冲突；3) 法律责任不明确；4) 缺乏经济激励机制；5) 社会效益不明显；6) 设计过程排他性过强。

Conclusion: 数字欧元当前设计存在重大缺陷，未能充分解决隐私、安全、经济和社会效益等核心问题，设计过程缺乏包容性和透明度，需要重新审视其必要性和可行性。

Abstract: The European Central Bank (ECB) is working on the "digital euro", an envisioned retail central bank digital currency for the Euro area. In this article, we take a closer look at the "digital euro FAQ", which provides answers to 26 frequently asked questions about the digital euro, and other published documents by the ECB on the topic. We question the provided answers based on our analysis of the current design in terms of privacy, technical feasibility, risks, costs and utility. In particular, we discuss the following key findings:
  (KF1) Central monitoring of all online digital euro transactions by the ECB threatens privacy even more than contemporary digital payment methods with segregated account databases.
  (KF2) The ECB's envisioned concept of a secure offline version of the digital euro offering full anonymity is in strong conflict with the actual history of hardware security breaches and mathematical evidence against it.
  (KF3) The legal and financial liabilities for the various parties involved remain unclear.
  (KF4) The design lacks well-specified economic incentives for operators as well as a discussion of its economic impact on merchants.
  (KF5) The ECB fails to identify tangible benefits the digital euro would create for society, in particular given that the online component of the proposed infrastructure mainly duplicates existing payment systems.
  (KF6) The design process has been exclusionary, with critical decisions being set in stone before public consultations. Alternative and open design ideas have not even been discussed by the ECB.

</details>


### [292] [When Is Self-Disclosure Optimal? Incentives and Governance of AI-Generated Content](https://arxiv.org/abs/2601.18654)
*Juan Wu,Zhe,Zhang,Amit Mehra*

Main category: cs.CY

TL;DR: 研究AI生成内容披露政策的经济影响，比较无披露基准与强制自我披露制度，分析创作者策略选择、平台执法策略演变及其对透明度、创作者剩余和内容质量的影响。


<details>
  <summary>Details</summary>
Motivation: 生成式AI降低了内容创作成本并实现规模化产出，平台开始采用要求创作者标注AI生成内容的披露政策。需要研究这种披露制度的经济影响，特别是当平台检测不完善且创作者可能策略性选择披露或隐瞒AI使用时的情况。

Method: 建立正式经济模型，比较无披露基准（仅平台检测AI使用）与强制自我披露制度（创作者在执法不完善下策略性选择是否披露）。模型包含异质创作者、观众对AI标注内容的折扣、检测到未披露的信任惩罚以及内生执法。

Result: 披露仅在AI生成内容的价值和成本节约优势都处于中等水平时最优。随着AI能力提升，平台最优执法策略从严格威慑演变为部分筛选，最终走向放松监管。披露虽提高透明度，但减少创作者总剩余，当AI技术先进时可能抑制高质量AI内容。

Conclusion: 披露是一种战略性治理工具，其有效性取决于技术成熟度和信任摩擦。平台需要根据AI技术发展阶段调整披露政策，平衡透明度、创作者激励和内容质量之间的关系。

Abstract: Generative artificial intelligence (Gen-AI) is reshaping content creation on digital platforms by reducing production costs and enabling scalable output of varying quality. In response, platforms have begun adopting disclosure policies that require creators to label AI-generated content, often supported by imperfect detection and penalties for non-compliance. This paper develops a formal model to study the economic implications of such disclosure regimes. We compare a non-disclosure benchmark, in which the platform alone detects AI usage, with a mandatory self-disclosure regime in which creators strategically choose whether to disclose or conceal AI use under imperfect enforcement. The model incorporates heterogeneous creators, viewer discounting of AI-labeled content, trust penalties following detected non-disclosure, and endogenous enforcement. The analysis shows that disclosure is optimal only when both the value of AI-generated content and its cost-saving advantage are intermediate. As AI capability improves, the platform's optimal enforcement strategy evolves from strict deterrence to partial screening and eventual deregulation. While disclosure reliably increases transparency, it reduces aggregate creator surplus and can suppress high-quality AI content when AI is technologically advanced. Overall, the results characterize disclosure as a strategic governance instrument whose effectiveness depends on technological maturity and trust frictions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [293] [Online parameter estimation for the Crazyflie quadcopter through an EM algorithm](https://arxiv.org/abs/2601.17009)
*Yanhua Zhao*

Main category: cs.AI

TL;DR: 该论文研究了在四旋翼无人机系统中添加随机噪声的影响，使用扩展卡尔曼滤波器进行状态估计，基于SDE系统实现线性二次高斯控制器，并应用期望最大化算法进行参数估计。


<details>
  <summary>Details</summary>
Motivation: 无人机因其体积小、成本低、可靠性高而日益普及，在地震救援、航拍、农业和运输等领域发挥重要作用。地震会破坏基础设施，使救援人员难以到达某些区域，而无人机可以提供帮助。本文旨在研究随机噪声对四旋翼无人机系统的影响。

Method: 1. 在四旋翼无人机系统中添加随机噪声；2. 使用扩展卡尔曼滤波器基于传感器噪声观测进行状态估计；3. 基于随机微分方程系统实现线性二次高斯控制器；4. 应用期望最大化算法进行四旋翼无人机的参数估计；5. 比较离线参数估计和在线参数估计的结果。

Result: 研究结果显示，在线参数估计的收敛值范围略大于离线参数估计。这表明在线参数估计在应对系统变化方面可能具有更好的适应性。

Conclusion: 通过扩展卡尔曼滤波器、线性二次高斯控制器和期望最大化算法的结合应用，可以有效处理四旋翼无人机系统中的随机噪声问题。在线参数估计相比离线参数估计具有更宽的收敛范围，在实际应用中可能更具优势。

Abstract: Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.

</details>


### [294] [Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability](https://arxiv.org/abs/2601.17168)
*Judy Zhu,Dhari Gandhi,Himanshu Joshi,Ahmad Rezaie Mianroodi,Sedef Akinli Kocak,Dhanesh Ramachandran*

Main category: cs.AI

TL;DR: 本文评估了现有可解释性方法在智能体系统中的应用局限性，提出了专门针对智能体系统设计可解释性技术的未来方向，以确保智能体AI系统的安全可靠部署。


<details>
  <summary>Details</summary>
Motivation: 智能体系统从根本上不同于传统机器学习模型，在架构和部署上都引入了独特的AI安全挑战，包括目标错位、决策错误累积和智能体间协调风险。现有的可解释性技术主要针对静态模型开发，在应用于智能体系统时显示出局限性。

Method: 本文评估了现有可解释性方法在智能体系统背景下的适用性和局限性，识别了它们在提供智能体决策有意义的洞察方面的能力差距。提出了专门为智能体系统设计可解释性技术的未来方向。

Result: 智能体系统的时间动态性、决策累积和上下文依赖行为需要新的分析方法。现有方法在应用于智能体系统时存在局限性，无法充分提供对智能体决策过程的洞察。

Conclusion: 需要开发专门针对智能体系统的可解释性技术，在智能体生命周期的各个阶段（从目标形成、环境交互到结果评估）嵌入监督机制。这些进展对于确保智能体AI系统的安全和可靠部署至关重要。

Abstract: Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.

</details>


### [295] [High-Fidelity Longitudinal Patient Simulation Using Real-World Data](https://arxiv.org/abs/2601.17310)
*Yu Akagi,Tomohisa Seki,Hiromasa Ito,Toru Takiguchi,Kazuhiko Ohe,Yoshimasa Kawazoe*

Main category: cs.AI

TL;DR: 利用真实世界电子健康记录开发生成式模拟器，可基于患者历史生成高保真未来临床轨迹，为个性化治疗和虚拟临床试验提供新框架。


<details>
  <summary>Details</summary>
Motivation: 模拟在临床医学中具有变革潜力，可用于个性化治疗规划和虚拟临床试验，但模拟患者轨迹面临生物和社会文化因素复杂的挑战。

Method: 开发生成式模拟器模型，以患者历史为输入，合成细粒度、真实的未来轨迹；模型在超过2亿条临床记录上进行预训练。

Result: 模型生成高保真未来时间线，与真实患者未来数据中的事件发生率、实验室检测结果和时间动态高度匹配；准确估计未来事件概率，观察与预期比率在不同结果和时间范围内均接近1.0。

Conclusion: 研究揭示了电子健康记录中真实世界数据的未开发价值，并引入了可扩展的临床护理计算机模拟框架。

Abstract: Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.

</details>


### [296] [Phase Transition for Budgeted Multi-Agent Synergy](https://arxiv.org/abs/2601.17311)
*Bang Liu,Linglong Kong,Jian Pei*

Main category: cs.AI

TL;DR: 多智能体系统在固定推理预算下存在帮助、饱和甚至崩溃三种状态，论文提出了一个可校准的最小理论，基于有限上下文窗口、有损通信和相似智能体共享错误三个约束条件，预测这些状态并推导出计算分配规则和预算阈值。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统虽然能提高可靠性，但在固定推理预算下常常出现帮助有限、性能饱和甚至崩溃的现象。现有研究缺乏能够预测这些状态并指导系统设计的理论框架，特别是在考虑现代智能体堆栈的实际约束条件时。

Method: 提出一个可校准的最小理论模型，包含三个关键约束：有限上下文窗口W、有损通信γ(m)和共享错误相关性ρ。每个叶节点智能体用计算-性能缩放指数β描述。通过分析深度b叉树结构，推导出相位转变条件、组织指数s和计算分配规则。

Result: 证明了深度b叉树存在尖锐的相位转变：单个标量α_ρ决定弱信号是被放大到非平凡固定点还是被淹没。在放大状态下，当组织指数s>β时出现预算协同效应，即多智能体系统在相同总预算下优于最佳单个智能体。提供了明确的预算阈值和计算分配规则。

Conclusion: 该理论框架能够预测多智能体系统的三种状态（帮助、饱和、崩溃），并提供了设计指导。通过合成模拟验证了预测的相位边界，并解释了最近大规模匹配预算研究中观察到的LLM智能体系统缩放瓶颈。

Abstract: Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $β$; communication is captured by a message-length fidelity curve $γ(m)$; dependence is captured by an effective shared-error correlation $ρ$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $α_ρ$ (combining $γ(m)$, $ρ$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>β$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.

</details>


### [297] [TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow](https://arxiv.org/abs/2601.17332)
*Yicheng Tao,Hongteng Xu*

Main category: cs.AI

TL;DR: TheoremForge是一个低成本的形式化数学数据合成管道，通过将形式化过程分解为五个子任务，并采用解耦提取策略从失败轨迹中恢复有效训练信号，显著提高了数据合成效率。


<details>
  <summary>Details</summary>
Motivation: 形式化数学中智能体工作流的高成本阻碍了大规模数据合成，加剧了开源语料库的稀缺性。需要开发一种经济高效的数据合成方法来解决这一问题。

Method: 将形式化过程分解为五个子任务：陈述形式化、证明生成、前提选择、证明修正和证明草图。采用解耦提取策略，从全局失败的轨迹中恢复有效的训练信号，有效利用浪费的计算资源。

Result: 在2000个问题的基准测试中，TheoremForge实现了12.6%的验证率，超过8.6%的基线，每个成功轨迹的平均成本仅为0.481美元。该策略使证明生成的数据产出提高了1.6倍。

Conclusion: TheoremForge建立了一个可扩展的框架，用于构建数据飞轮来训练未来的专家模型，为解决形式化数学数据稀缺问题提供了经济高效的解决方案。

Abstract: The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \textit{statement formalization}, \textit{proof generation}, \textit{premise selection}, \textit{proof correction} and \textit{proof sketching}. By implementing a \textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\%, surpassing the 8.6\% baseline, at an average cost of only \textbf{\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \textbf{1.6$\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \href{https://github.com/timechess/TheoremForge}{here}.

</details>


### [298] [The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability](https://arxiv.org/abs/2601.17335)
*Angshul Majumdar*

Main category: cs.AI

TL;DR: 该研究证明AGI无法获得独立于任务分布的统一定义，缺乏普遍鲁棒性，有限资源下无法实现无限泛化，且无法通过可计算程序（包括自认证）进行完备验证。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨人工智能通用智能（AGI）是否能够获得一个连贯的理论定义，以支持关于其存在性、鲁棒性或自验证的绝对主张。作者希望从形式化角度分析AGI概念的理论基础。

Method: 采用公理化方法，将AGI形式化为一个分布性、资源受限的语义谓词，通过任务族、任务分布、性能函数和显式资源预算进行索引。在此框架下，运用数学证明方法（包括Rice风格和哥德尔-塔斯基论证）推导了四类理论结果。

Result: 1. 通用性是关系性的：不存在独立于分布的AGI概念；2. 非不变性结果：任务分布的任意微小扰动可通过悬崖集使AGI属性失效；3. 有界迁移保证：有限资源下无法实现跨任务族的无限泛化；4. AGI是非平凡的语义属性，无法通过任何可计算程序（包括自认证）进行完备验证。

Conclusion: 强分布独立的AGI主张在没有显式形式化索引的情况下是未定义的，而非错误的。AI的实证进展并不暗示自认证通用智能的可实现性，依赖内部自认证的递归自我改进方案是病态的。

Abstract: We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and Gödel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.

</details>


### [299] [Are We Evaluating the Edit Locality of LLM Model Editing Properly?](https://arxiv.org/abs/2601.17343)
*Wei Liu,Haomei Xu,Hongkai Liu,Zhiying Deng,Ruixuan Li,Heng Huang,Yee Whye Teh,Wee Sun Lee*

Main category: cs.AI

TL;DR: 论文发现现有模型编辑方法中的特异性评估协议存在不足，提出了新的评估协议来解决这些问题，实验证明新协议能更敏感地衡量知识保留能力。


<details>
  <summary>Details</summary>
Motivation: 模型编辑已成为更新LLM知识的重要范式，但现有特异性评估协议在平衡编辑效果和知识保留方面存在不足，无法有效评估不同方法的知识保护能力。

Method: 系统分析了现有特异性评估协议的三个基本问题，提出了新的评估协议：消除开放LLM与确定答案假设的冲突、避免查询无关的流畅性偏差、允许在近连续空间中平滑调整评估严格度。

Result: 实验表明，新协议生成的指标对特异性正则化强度变化更敏感，与正则化强度强相关，能更精细地区分不同方法的知识保留能力。

Conclusion: 提出的新评估协议解决了现有特异性评估的不足，为模型编辑方法的知识保留能力提供了更准确、敏感的评估框架。

Abstract: Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.

</details>


### [300] [Multi-Agent Learning Path Planning via LLMs](https://arxiv.org/abs/2601.17346)
*Haoxin Xu,Changyong Qi,Tong Liu,Bohao Zhang,Anna He,Bingqian Jiang,Longwei Zheng,Xiaoqing Gu*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体协作的MALPP框架，利用LLM驱动的智能体进行个性化学习路径规划，解决了现有方法缺乏透明度、适应性和可解释性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前智能导学系统中的学习路径规划方法普遍缺乏透明度、适应性和以学习者为中心的可解释性，这限制了大型语言模型在高等教育个性化学习中的潜力发挥。

Method: 提出MALPP框架，采用基于角色和规则的协作机制，包含三个任务特定的智能体：学习者分析智能体、路径规划智能体和反思智能体，这些智能体通过结构化提示和预定义规则协作，基于认知负荷理论和最近发展区理论进行分析、生成和迭代优化学习路径。

Result: 在MOOCCubeX数据集上使用7个LLM进行的实验表明，MALPP在路径质量、知识序列一致性和认知负荷对齐方面显著优于基线模型，消融研究进一步验证了协作机制和理论约束的有效性。

Conclusion: 该研究为可信赖、可解释的教育AI发展做出了贡献，展示了一种基于LLM的、可扩展的以学习者为中心的自适应教学方法。

Abstract: The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.

</details>


### [301] [Auditing Disability Representation in Vision-Language Models](https://arxiv.org/abs/2601.17348)
*Srikant Panda,Sourabh Singh Yadav,Palkesh Malviya*

Main category: cs.AI

TL;DR: 研究视觉语言模型在描述残疾人图像时的解释偏移问题，发现引入残疾上下文会降低解释保真度，导致推测性推断、叙事扩展、情感降级和缺陷导向框架等问题，这些效应在种族和性别维度上进一步放大。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型越来越多地应用于社会敏感领域，但其在残疾方面的行为尚未得到充分探索。模型在描述人物图像时，经常从基于证据的事实描述转向解释偏移，包括引入超出可观察视觉证据的不支持推断。

Method: 引入基于中性提示(NP)和残疾情境化提示(DP)配对的基准，在零样本设置下评估15个最先进的开源和闭源VLM，涵盖9个残疾类别。评估框架将解释保真度作为核心目标，结合标准文本指标和LLM作为评判协议，由有残疾生活经验的注释者验证。

Result: 引入残疾上下文会持续降低解释保真度，导致解释偏移，表现为推测性推断、叙事扩展、情感降级和缺陷导向框架。这些效应在种族和性别维度上进一步放大。针对性提示和偏好微调能有效提高解释保真度并显著减少解释偏移。

Conclusion: 视觉语言模型在描述残疾人时存在系统性解释偏移问题，需要改进模型行为以确保更准确、尊重和基于证据的描述。针对性干预措施如特定提示和微调可以有效缓解这些问题。

Abstract: Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.

</details>


### [302] [A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models](https://arxiv.org/abs/2601.17426)
*Zhengqing Zang,Yuqi Ding,Yanmei Gu,Changkai Song,Zhengkai Yang,Guoping Du,Junbo Zhao,Haobo Wang*

Main category: cs.AI

TL;DR: LLMs在逻辑推理中表现出从传统逻辑向现代逻辑的演变趋势，模型规模扩展、思维链推理和基础模型架构是影响这一演变的关键因素。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型是否像人类逻辑一样，从直觉驱动的推理演变为严格的逻辑形式系统，使用存在导入作为探针来评估三段论推理。

Method: 使用存在导入作为探针，在传统逻辑和现代逻辑框架下评估三段论推理，通过在新构建的三段论数据集上测试SOTA LLMs进行广泛实验。

Result: 发现三个关键因素：(1) 模型规模扩展促进向现代逻辑的转变；(2) 思维链推理是超越参数扩展的高效加速器；(3) 基础模型架构决定这种转变的容易程度和稳定性。

Conclusion: LLMs在逻辑推理中确实表现出从传统逻辑向现代逻辑的演变趋势，模型规模、推理方法和基础架构是影响这一演变的核心因素，为理解LLMs的逻辑推理能力提供了新视角。

Abstract: Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.

</details>


### [303] [Lattice: Generative Guardrails for Conversational Agents](https://arxiv.org/abs/2601.17481)
*Emily Broadhurst,Tawab Safi,Joseph Edell,Vashisht Ganesh,Karime Maamari*

Main category: cs.AI

TL;DR: Lattice框架通过自构建和持续改进机制为对话AI系统创建自适应防护栏，相比静态规则方法显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有对话AI系统的防护栏使用静态规则，无法适应新威胁和部署环境变化，需要能够自我构建和持续改进的防护框架

Method: Lattice框架采用两阶段方法：构建阶段通过迭代模拟和优化从标注示例创建初始防护栏；持续改进阶段通过风险评估、对抗测试和整合自主调整已部署的防护栏

Result: 在ProsocialDialog数据集上，Lattice在保留数据上达到91% F1分数，比关键词基线高43个百分点，比LlamaGuard高25个百分点，比NeMo高4个百分点；持续改进阶段通过闭环优化在跨域数据上实现7个百分点的F1提升

Conclusion: Lattice框架证明通过迭代优化可以自构建有效的防护栏，为对话AI系统提供了自适应防护解决方案

Abstract: Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.

</details>


### [304] [Cognitive Platform Engineering for Autonomous Cloud Operations](https://arxiv.org/abs/2601.17542)
*Vinoth Punniyamoorthy,Nitin Saksena,Srivenkateswara Reddy Sankiti,Nachiappan Chockalingam,Aswathnarayan Muthukrishnan Kirubakaran,Shiva Kumar Reddy Carimireddy,Durgaraman Maruthavanan*

Main category: cs.AI

TL;DR: 本文提出认知平台工程新范式，通过集成感知、推理和自主行动到平台生命周期，解决传统DevOps在云原生系统规模化和动态性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统DevOps实践虽然通过自动化、CI/CD流水线和可观测性工具加速了软件交付，但在面对云原生系统的规模和动态性时存在局限。随着遥测数据量增长和配置漂移增加，传统的规则驱动自动化往往导致被动运维、修复延迟和对人工专业知识的依赖。

Method: 提出认知平台工程范式，设计了一个四层参考架构，统一数据收集、智能推理、策略驱动编排和人类体验层，形成持续反馈循环。原型实现基于Kubernetes、Terraform、Open Policy Agent和基于机器学习的异常检测。

Result: 原型实现展示了在平均解决时间、资源效率和合规性方面的改进。结果表明，将智能嵌入平台操作能够实现弹性、自我调整和意图对齐的云环境。

Conclusion: 认知平台工程通过嵌入智能到平台操作，能够实现弹性、自我调整和意图对齐的云环境。未来研究方向包括强化学习、可解释治理和可持续自管理云生态系统。

Abstract: Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.

</details>


### [305] [JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research](https://arxiv.org/abs/2601.17564)
*Aadam,Monu Verma,Mohamed Abdel-Mottaleb*

Main category: cs.AI

TL;DR: JaxARC是一个基于JAX的高性能强化学习环境，用于Abstraction and Reasoning Corpus（ARC）任务，相比Gymnasium实现了38-5,439倍的加速，支持大规模并行计算。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Gymnasium的RL环境在处理ARC任务时存在计算瓶颈，严重限制了实验规模，需要更高效的环境来支持大规模强化学习研究。

Method: 使用JAX实现功能化、无状态的架构，支持大规模并行计算，提供多种ARC数据集支持、灵活的动作空间、可组合的包装器和配置驱动的可重复性。

Result: 在相同批次大小下实现38-5,439倍的加速，峰值吞吐量达到7.9亿步/秒，使之前计算上不可行的大规模RL研究成为可能。

Conclusion: JaxARC是一个开源的高性能RL环境，显著提升了ARC任务的实验效率，为大规模强化学习研究提供了可行的计算平台。

Abstract: The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.

</details>


### [306] [Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context](https://arxiv.org/abs/2601.17642)
*Zhihao Zhang,Liting Huang,Guanghao Wu,Preslav Nakov,Heng Ji,Usman Naseem*

Main category: cs.AI

TL;DR: 论文提出了Health-ORSC-Bench，首个大规模医疗AI安全基准，用于系统评估大语言模型在医疗领域的过度拒绝和安全完成质量，揭示当前模型在安全性和实用性之间的平衡困境。


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI安全评估主要关注二元拒绝边界，导致对良性查询的过度拒绝或对有害查询的不安全遵从，缺乏对"安全完成"能力的评估——即在双用途或边界查询中提供安全、高层次指导而不越界的能力。

Method: 开发了Health-ORSC-Bench基准，包含31,920个良性边界提示，涵盖7个健康类别（如自残、医疗错误信息）。采用自动化流水线结合人工验证，在不同意图模糊度水平上测试模型。评估了30个最先进的LLM，包括GPT-5和Claude-4。

Result: 安全优化模型对"困难"良性提示的拒绝率高达80%，而领域特定模型常为实用性牺牲安全性。模型家族和规模显著影响校准：大型前沿模型（如GPT-5、Llama-4）表现出"安全悲观主义"和更高的过度拒绝，而较小或MoE模型（如Qwen-3-Next）表现不同。

Conclusion: 当前LLM在拒绝和遵从之间难以平衡，Health-ORSC-Bench为校准下一代医疗AI助手提供了严格标准，推动其实现细致、安全和有帮助的完成。代码和数据将在接受后发布。

Abstract: Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \emph{over-refusal} of benign queries or \emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \textbf{Over-Refusal} and \textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\% of "Hard" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit "safety-pessimism" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \textcolor{red}{Warning: Some contents may include toxic or undesired contents.}

</details>


### [307] [The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data](https://arxiv.org/abs/2601.17717)
*Kaituo Zhang,Mingzhi Hu,Hoang Anh Duy Le,Fariha Kabir Torsha,Zhimeng Jiang,Minh Khai Bui,Chia-Yuan Chang,Yu-Neng Chuang,Zhen Xiong,Ying Lin,Guanchu Wang,Na Zou*

Main category: cs.AI

TL;DR: LLM数据审计框架：系统评估多模态合成数据质量与可信度的统一方法


<details>
  <summary>Details</summary>
Motivation: LLM已成为生成多模态数据的有力工具，将数据从稀缺资源转变为可控资产，缓解了真实世界数据获取成本对模型训练、评估和系统迭代的瓶颈。然而，确保LLM生成的合成数据质量仍然是一个关键挑战。现有研究主要关注生成方法，对数据质量本身关注有限，且大多局限于单一模态，缺乏跨数据类型的统一视角。

Method: 提出了LLM数据审计框架：1）描述LLM如何生成六种不同模态的数据；2）从质量和可信度两个维度系统分类合成数据的内在评估指标，将重点从依赖下游任务性能的外在评估转向数据本身的固有属性；3）使用该评估系统分析各模态代表性生成方法的实验评估；4）基于发现为社区提供改进数据生成评估的具体建议；5）概述合成数据在不同模态实际应用的方法论。

Result: 通过分析各模态代表性生成方法的实验评估，发现了当前评估实践中的重大缺陷。现有评估方法不够系统，缺乏对数据内在质量的关注，且跨模态评估标准不统一。

Conclusion: LLM数据审计框架为多模态合成数据的系统评估提供了统一视角，强调了从外在任务性能评估转向数据内在质量评估的重要性。基于分析结果提出了改进数据生成评估的具体建议，并概述了合成数据实际应用的方法论，有助于推动高质量合成数据的研究和应用。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.

</details>


### [308] [EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents](https://arxiv.org/abs/2601.17722)
*Ying Mo,Yu Bai,Dapeng Sun,Yuqian Shi,Yukai Miao,Li Chen,Dan Li*

Main category: cs.AI

TL;DR: EntWorld是一个针对企业级工作流程的大规模基准测试，包含1,756个任务，覆盖CRM、ITIL、ERP等六个企业领域，旨在评估多模态大语言模型在复杂企业环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要针对消费者场景（如电商、旅游预订），无法捕捉专业企业工作流程的复杂性和严谨性。企业系统具有高密度用户界面、严格业务逻辑约束和精确状态一致性要求等特点，当前通用智能体在这些场景中表现不佳。

Method: 采用基于模式的任务生成框架，直接从底层数据库模式逆向工程业务逻辑，合成真实的长时程工作流程。使用基于SQL的确定性验证机制，用严格的状态转换验证替代模糊的视觉匹配。

Result: 实验结果显示，最先进的模型（如GPT-4.1）在EntWorld上的成功率仅为47.61%，远低于人类表现，表明当前智能体在企业场景中存在显著能力差距。

Conclusion: EntWorld作为一个严谨的测试平台，揭示了当前智能体在企业环境中的局限性，强调了开发领域特定智能体的必要性，为下一代企业级数字智能体的开发和评估提供了基础。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.

</details>


### [309] [MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing](https://arxiv.org/abs/2601.17814)
*Haoxuan Ma,Guannan Lai,Han-Jia Ye*

Main category: cs.AI

TL;DR: MMR-Bench是一个用于评估多模态大语言模型路由选择的基准测试，通过控制计算成本和候选模型集，研究如何在多模态任务中智能选择最适合的模型，以平衡计算效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在架构、对齐策略和效率方面存在异质性，没有单一模型在所有任务上都表现最优。实际部署中，工作负载从轻量级OCR到复杂多模态推理不等，使用单一模型要么在简单任务上过度计算，要么在复杂任务上牺牲准确性。需要解决多模态环境下的模型路由选择问题。

Method: 提出了MMR-Bench基准测试，提供：1）具有模态感知输入和可变计算预算的受控环境；2）涵盖OCR、通用视觉问答和多模态数学推理的广泛视觉语言任务套件；3）强大的单模型参考、理论上限和代表性路由策略。通过该基准测试研究多模态信号如何改善路由质量。

Result: 实验表明，融入多模态信号能提升路由质量，改善成本-准确性边界。路由系统能以最强单模型约33%的成本超越其准确性。在部分模型和任务上训练的策略能零样本泛化到新数据集和纯文本基准测试，无需重新调整。

Conclusion: MMR-Bench为研究自适应多模态模型选择和高效MLLM部署提供了基础框架，展示了多模态路由在实际部署中的潜力和泛化能力。

Abstract: Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.

</details>


### [310] [RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance](https://arxiv.org/abs/2601.17826)
*Siyuan Yang,Xihan Bian,Jiayin Tang*

Main category: cs.AI

TL;DR: RegGuard是一个工业级AI助手，用于自动化解读异构监管文本并与企业内部政策对齐，通过HiSACC和ReLACE技术提高检索和生成质量，显著减少幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 监管更新频率和复杂性增加给跨国制药公司带来沉重负担，合规团队需要手动解读不同司法管辖区、格式和机构的规则，成本高且易出错。

Method: 系统通过安全管道摄入异构文档源，采用两个核心组件：HiSACC（分层语义聚合上下文分块）将长文档语义分割为连贯单元；ReLACE（监管列表自适应交叉编码器）基于开源模型构建，联合建模用户查询和检索候选以提高排名相关性。

Result: 企业环境评估显示，RegGuard在相关性、基础性和上下文聚焦方面提高答案质量，同时显著减轻幻觉风险。系统架构具有可审计性和可追溯性。

Conclusion: RegGuard为具有严格合规需求的领域提供高效解决方案，系统架构支持来源跟踪、访问控制和增量索引，能够快速响应不断变化的文档源。

Abstract: The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.

</details>


### [311] [Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards](https://arxiv.org/abs/2601.17828)
*Tanvi Verma,Yang Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.AI

TL;DR: IGFT是一种无需人类对话数据的医疗对话AI训练方法，通过信息增益奖励和在线强化学习，让模型从与模拟患者的自我生成对话中学习有效的问诊策略。


<details>
  <summary>Details</summary>
Motivation: 现有医疗对话AI训练需要昂贵的人工标注对话数据或静态数据集，限制了模型的探索能力和适应性。需要一种无需预收集人类对话的方法，让模型能自主发现有效的问诊策略。

Method: 结合在线Group Relative Policy Optimization（GRPO）和信息论奖励，使用信息增益奖励函数追踪对话中揭示的临床实体（症状、时间模式、病史等），结合GPT-4o-mini的质量评估，通过LoRA微调Llama-3.1-8B-Instruct和DeepSeek-R1-Distill-Qwen-7B模型。

Result: 在Avey数据集上，DeepSeek-R1-Distill-Qwen-7B（IGFT）F1分数达0.408（比基础模型提升10.9%），在MIMIC数据集上达0.289（提升12.9%）。Llama-3.1-8B-Instruct（IGFT）分别达到0.384和0.336。两个模型在MIMIC上都超越了OpenAI模型，并超越了HuatuoGPT和UltraMedical等医疗领域基线模型。

Conclusion: IGFT提供了一种无需人工标注对话的有效医疗对话AI训练框架，通过信息增益奖励和在线强化学习，使模型能够学习针对性的临床问题，高效收集诊断信息，在跨数据集泛化方面表现出色。

Abstract: We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.

</details>


### [312] [UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis](https://arxiv.org/abs/2601.17897)
*Jiayu Liu,Yinhe Long,Zhenya Huang,Enhong Chen*

Main category: cs.AI

TL;DR: UniCog框架通过潜在思维空间分析LLM认知，发现LLM认知遵循帕累托原则，推理失败表现为潜在激活异常，并基于此提出提升推理性能的方法。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法在解释LLM推理过程中认知能力如何被调用方面存在局限，需要新的框架来分析LLM的认知过程。

Method: 提出UniCog统一框架，作为潜在变量模型，将密集模型激活编码为稀疏、解耦的潜在维度，分析六个先进LLM的认知过程。

Result: 发现LLM认知遵循帕累托原则：共享推理核心辅以能力特定特征；推理失败表现为潜在激活异常；提出的潜在信息候选优先级策略在挑战性基准上提升推理性能达7.5%。

Conclusion: UniCog为LLM分析开辟了新范式，提供了基于认知的推理动态视角，并展示了通过潜在激活分析提升推理性能的潜力。

Abstract: A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.

</details>


### [313] [Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges](https://arxiv.org/abs/2601.17920)
*Xuanzhou Chen,Audrey Wang,Stanley Yin,Hanyang Jiang,Dong Zhang*

Main category: cs.AI

TL;DR: 这篇综述论文以软物质为代表性场景，系统分析了自动驾驶实验室（SDLs）中的AI问题，将其框架化为智能体环境交互问题，回顾了闭环实验的主要方法家族，提出了能力驱动的分类体系，并制定了基准任务模板和评估指标。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶实验室为智能体AI在昂贵操作、噪声延迟反馈、严格可行性和安全约束以及非平稳性等挑战下提供了严格的测试平台。论文旨在系统梳理SDL中的AI问题，建立理论框架，促进该领域的发展。

Method: 将SDL自主性框架化为具有明确观察、行动、成本和约束的智能体环境交互问题；回顾贝叶斯优化、主动学习、规划、强化学习和工具使用智能体等方法家族；提出基于决策视野、不确定性建模、行动参数化、约束处理、故障恢复和人类参与的能力驱动分类法；制定基准任务模板和评估指标。

Result: 建立了SDL的统一理论框架，连接了常见SDL流程与已建立的AI原则；提出了系统的分类体系和评估标准；总结了已部署SDL的经验教训，并指出了多模态表示、校准不确定性、安全探索和共享基准基础设施等开放挑战。

Conclusion: 自动驾驶实验室是AI在现实世界应用的重要前沿领域，需要可验证、可溯源的政策来支持调试、可重复性和安全操作。未来的研究应关注多模态表示、校准不确定性、安全探索和共享基准基础设施等关键挑战，以推动该领域的发展。

Abstract: Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.

</details>


### [314] [LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting](https://arxiv.org/abs/2601.17942)
*Yu-Jie Yang,Hung-Fu Chang,Po-An Chen*

Main category: cs.AI

TL;DR: 该研究提出了SSEV和ReCAPAgent-SQL两个框架，用于改进文本到SQL转换任务，通过自优化和智能体协作机制提升SQL生成准确性，特别是在企业级数据库场景中。


<details>
  <summary>Details</summary>
Motivation: 文本到SQL技术虽然降低了数据分析门槛，但自然语言查询的歧义性、模式链接复杂性、SQL方言泛化能力有限以及领域特定理解需求等问题，使得生成准确SQL仍然具有挑战性。特别是在企业级数据库和真实世界场景中，这些挑战更加突出。

Method: 提出了两个主要方法：1) SSEV管道：基于PET-SQL构建的单智能体自优化集成投票系统，无需真实数据，结合自优化与加权多数投票及其随机变体；2) ReCAPAgent-SQL框架：基于"优化-批判-行动-规划"的多智能体协作系统，包含规划、外部知识检索、批判、行动生成、自优化、模式链接和结果验证等专门智能体，通过智能体协作实现SQL预测的迭代优化。

Result: SSEV在多个基准测试中取得竞争性表现：Spider 1.0-Dev执行准确率85.5%，Spider 1.0-Test 86.4%，BIRD-Dev 66.3%。ReCAPAgent-SQL在Spider 2.0-Lite前100个查询中达到31%的执行准确率，在处理真实世界企业场景方面显示出显著改进。

Conclusion: 该研究通过SSEV和ReCAPAgent-SQL框架，为实际环境中可扩展的文本到SQL系统部署提供了有效解决方案，支持以更低成本和更高效率进行数据驱动决策。多智能体协作框架特别适用于处理日益复杂的企业数据库和真实世界文本到SQL任务。

Abstract: Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.

</details>


### [315] [Sentipolis: Emotion-Aware Agents for Social Simulations](https://arxiv.org/abs/2601.18027)
*Chiyuan Fu,Lyuhao Chen,Yunze Xiao,Weihao Xuan,Carlos Busso,Mona Diab*

Main category: cs.AI

TL;DR: Sentipolis框架为LLM智能体提供情感状态管理，通过PAD情感表示、双速情感动态和情感-记忆耦合，提升社交模拟中的情感连续性和真实性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在社交模拟中常将情感视为瞬时线索，导致情感遗忘和长期连续性不足，需要更系统的情感状态管理框架。

Method: 提出Sentipolis框架，包含：1）连续的愉悦-唤醒-支配（PAD）情感表示；2）双速情感动态机制；3）情感与记忆耦合系统。

Result: 在数千次交互中，Sentipolis提升了情感基础行为、沟通能力和情感连续性。效果模型依赖：高容量模型可信度提升，小模型可能下降；情感意识可能轻微降低社会规范遵守度。

Conclusion: Sentipolis支持研究累积社交动态如联盟形成和关系渐变，揭示了情感驱动行为与社会规范遵守之间的人类化张力，为社交模拟提供更真实的情感连续性。

Abstract: LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.

</details>


### [316] [Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing](https://arxiv.org/abs/2601.18061)
*Kiana Jafari,Paul Ulrich Nikolaus Rust,Duncan Eddy,Robbie Fraser,Nina Vasan,Darja Djordjevic,Akanksha Dadlani,Max Lamparth,Eugenia Kim,Mykel Kochenderfer*

Main category: cs.AI

TL;DR: 研究发现心理健康领域专家评估AI生成回复时存在系统性分歧，尤其是在自杀自伤等安全关键问题上，专家间一致性极低，分歧源于不同的临床框架而非测量误差。


<details>
  <summary>Details</summary>
Motivation: 验证从人类反馈中学习(LHF)的基本假设——专家判断经过适当聚合后能提供有效的训练和评估AI系统的真实标签。在心理健康这一高安全风险的领域，专家共识尤为重要。

Method: 三位认证精神科医生使用校准的评分标准独立评估LLM生成的回复，测量专家间信度(ICC)，进行定性访谈分析分歧原因。

Result: 专家间信度极低(ICC 0.087-0.295)，低于可接受阈值；自杀自伤类回复分歧最大；一个因素的信度甚至为负值(Krippendorff's α=-0.203)；分歧源于安全优先、参与为中心、文化敏感等不同的临床框架。

Conclusion: 专家分歧是原则性差异而非测量误差，聚合标签会抹杀专业哲学；建议从基于共识的聚合转向能够保留和学习专家分歧的对齐方法。

Abstract: Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $α= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.

</details>


### [317] [EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization](https://arxiv.org/abs/2601.18067)
*Wei-Po Hsin,Ren-Hao Deng,Yao-Ting Hsieh,En-Ming Huang,Shih-Hao Hung*

Main category: cs.AI

TL;DR: EvolVE框架通过多种进化策略和结构化测试平台生成，在芯片设计任务中实现了自动化，显著提升了功能正确性和PPA优化，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: Verilog设计流程劳动密集且需要大量领域专业知识，现有大语言模型由于训练数据有限和顺序推理特性，难以捕捉硬件系统的严格形式逻辑和并发特性。

Method: 提出EvolVE框架，分析多种进化策略：蒙特卡洛树搜索（MCTS）用于最大化功能正确性，想法引导精炼（IGR）用于优化；采用结构化测试平台生成（STG）加速进化过程；引入IC-RTL基准测试套件。

Result: 在VerilogEval v2上达到98.1%，RTLLM v2上达到92%；在工业级IC-RTL套件上超越竞赛参与者参考实现，Huffman编码的PPA乘积降低66%，所有问题的几何平均降低17%。

Conclusion: EvolVE框架通过结合多种进化策略和结构化测试生成，有效解决了硬件设计自动化中的挑战，在功能正确性和优化方面均达到最先进水平。

Abstract: Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.

</details>


### [318] [Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?](https://arxiv.org/abs/2601.18119)
*Jing Ye,Yiwen Duan,Yonghong Yu,Victor Ma,Yang Gao,Xing Chen*

Main category: cs.AI

TL;DR: OurBench是首个企业级SQL推理与调试基准，包含469个语法错误查询和516个语义错误查询，通过自动化工作流注入真实错误，评估显示当前LLMs在复杂SQL调试上表现不佳（最佳模型准确率仅36.46%）


<details>
  <summary>Details</summary>
Motivation: 企业数据工程中SQL至关重要，但即使是经验丰富的开发者和先进的文本到SQL LLMs也难以一次性生成完全正确的SQL代码，通常需要多次调试迭代。目前缺乏专门针对企业级SQL推理和调试的基准测试。

Method: 提出OurBench基准，包含两个关键创新：(1) 自动化构建工作流，使用逆向工程在大规模SQL代码中系统性地注入真实错误，实现可扩展和多样化的基准生成；(2) 针对企业环境的免执行评估框架，提供快速、准确且资源高效的评估。

Result: OurBench包含469个OurBenchSyn查询（语法错误，有明确错误信息）和516个OurBenchSem查询（语义错误，代码未能满足用户意图）。查询高度复杂，平均超过140行，具有深而广的抽象语法树。评估近30个LLMs显示显著性能差距：最佳模型Claude-4-Sonnet在OurBenchSyn上仅达到36.46%准确率，在OurBenchSem上为32.17%，大多数模型得分低于20%。

Conclusion: 该研究揭示了当前LLMs在企业级SQL调试方面的局限性，探索了四种解决方案策略，识别了关键挑战，并概述了LLMs在企业SQL调试方面的有前景方向。

Abstract: SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.
  OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.
  Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.

</details>


### [319] [Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters](https://arxiv.org/abs/2601.18123)
*Muhammad Ibrahim Khan,Bivin Pradeep,James Brusey*

Main category: cs.AI

TL;DR: 研究提出截止时间感知控制方法，通过强化学习优化家用浸入式热水器能耗，在指定时间达到目标温度的同时最小化能量消耗。


<details>
  <summary>Details</summary>
Motivation: 传统家用浸入式热水器在冬季常连续运行，追求快速加热而非高效加热，忽略了可预测的需求窗口和环境热损失，导致能源浪费。

Method: 建立Gymnasium仿真环境模拟浸入式热水器热力学过程，采用时间最优bang-bang控制基线、零样本蒙特卡洛树搜索规划器和近端策略优化强化学习策略。

Result: 在2小时（60步）时间范围内，PPO策略能耗最低（3.23千瓦时），相比bang-bang控制（4.37-10.45千瓦时）和MCTS（4.18-6.46千瓦时）分别节能26%（30步）和69%（90步）。在典型场景中，PPO比bang-bang控制节能54%，比MCTS节能33%。

Conclusion: 学习型截止时间感知控制能在相同物理假设下显著降低能耗，规划器无需训练即可提供部分节能效果，而训练后的学习策略推理成本近乎为零。

Abstract: Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.

</details>


### [320] [RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening](https://arxiv.org/abs/2601.18132)
*Xi Chen,Hongru Zhou,Huahui Yi,Shiyu Feng,Hanyu Zhou,Tiancheng He,Mingke You,Li Wang,Qiankun Li,Kun Wang,Weili Fu,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: RareAlert是一个基于LLM推理校准的罕见病早期筛查系统，通过整合10个LLM的推理信号，训练出可在本地部署的单一模型，在158,666个真实病例数据集上达到0.917的AUC，优于现有最佳机器学习模型和所有评估的LLM。


<details>
  <summary>Details</summary>
Motivation: 罕见病的漏诊和延迟诊断是主要挑战，现有初级诊疗分诊流程在初次就诊时无法可靠识别罕见病患者，需要通用筛查来减少诊断延迟。

Method: 开发RareAlert系统：整合10个LLM生成的推理信号，使用机器学习校准和加权这些信号，将对齐的推理提炼成单一可本地部署的模型。使用包含158,666个病例、覆盖33个Orphanet疾病类别的RareBench数据集进行开发和评估。

Result: RareAlert在独立测试集上达到0.917的AUC，优于最佳机器学习集成模型和所有评估的LLM（包括GPT-5、DeepSeek-R1、Claude-3.7-Sonnet等）。基于Qwen3-4B的模型通过校准推理信号训练，表现出色。

Conclusion: 罕见病识别可重新概念化为应用于普通患者群体的通用不确定性解决过程。LLM医学推理具有多样性，在高度不确定的临床任务中对齐这种推理是有效的。RareAlert通过将校准推理融入单一模型，实现了准确、保护隐私、可扩展的罕见病风险筛查，适合大规模本地部署。

Abstract: Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.

</details>


### [321] [DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints](https://arxiv.org/abs/2601.18137)
*Yinger Zhang,Shutong Jiang,Renhao Li,Jianhong Tu,Yang Su,Lianghao Deng,Xudong Guo,Chenxu Lv,Junyang Lin*

Main category: cs.AI

TL;DR: DeepPlanning是一个针对实际长时程智能体规划的挑战性基准测试，包含多日旅行规划和多产品购物任务，需要主动信息获取、局部约束推理和全局约束优化。


<details>
  <summary>Details</summary>
Motivation: 当前智能体评估虽然转向了长时程任务，但大多数基准测试仍侧重于局部、步骤级的推理，而非需要真正规划能力的全局约束优化（如时间和财务预算）。同时，现有的LLM规划基准测试未能充分体现现实世界中典型的主动信息收集和细粒度局部约束。

Method: 引入DeepPlanning基准测试，包含多日旅行规划和多产品购物任务，这些任务需要：1）主动信息获取；2）局部约束推理；3）全局约束优化。通过该基准测试评估前沿智能体LLM的性能。

Result: 评估显示，即使是前沿的智能体LLM在这些问题上也表现不佳，突显了可靠的显式推理模式和并行工具使用对于实现更好的效果-效率权衡的重要性。错误分析为进一步改进长规划时程的智能体LLM指出了有希望的方向。

Conclusion: DeepPlanning基准测试填补了现有规划评估的空白，揭示了当前智能体LLM在实践长时程规划方面的局限性，并开源代码和数据以支持未来研究。

Abstract: While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.

</details>


### [322] [Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success](https://arxiv.org/abs/2601.18175)
*Daniel Russo*

Main category: cs.AI

TL;DR: 成功条件化是一种通过模仿成功轨迹来改进策略的技术，本文证明它实际上解决了一个信任域优化问题，在χ²散度约束下最大化策略改进，且不会降低性能。


<details>
  <summary>Details</summary>
Motivation: 成功条件化技术（如拒绝采样、目标条件RL、决策变换器）被广泛使用，但其背后的优化问题本质一直不明确。本文旨在揭示这一技术解决的数学优化问题。

Method: 通过理论证明，将成功条件化形式化为一个信任域优化问题，最大化策略改进同时受χ²散度约束。约束半径由数据自动确定，建立了相对策略改进、策略变化幅度和动作影响力之间的等式关系。

Result: 成功条件化被证明是一个保守的改进算子，不会降低性能或引发危险的分布偏移。当失败时，它会通过几乎不改变策略来可观察地失败。对常见的回报阈值化实践的分析表明，它可以放大改进，但可能以与真实目标不对齐为代价。

Conclusion: 成功条件化技术实际上解决了一个特定的信任域优化问题，这解释了其广泛有效性的数学基础。该技术具有保守改进的特性，为实际应用提供了理论保证。

Abstract: A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.

</details>


### [323] [Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents](https://arxiv.org/abs/2601.18217)
*Zhihan Liu,Lin Guan,Yixin Nie,Kai Zhang,Zhuoqun Hao,Lin Chen,Asli Celikyilmaz,Zhaoran Wang,Na Zhang*

Main category: cs.AI

TL;DR: 研究LLM智能体在未知测试域上的泛化能力，发现状态信息丰富度和规划复杂度是影响跨域泛化的关键因素，并提出通过添加干扰特征来增强状态信息丰富度的随机化技术。


<details>
  <summary>Details</summary>
Motivation: 通用LLM智能体通常在有限环境中进行后训练，但需要在更广泛的未知领域部署。本研究旨在探索当最终测试域未知时，哪些环境和建模因素对跨域性能影响最大。

Method: 首先识别与跨域泛化强相关的环境轴：状态信息丰富度和规划复杂度。提出随机化技术：在状态中添加少量与目标无关的干扰特征来增加状态信息丰富度。同时分析建模选择：SFT预热/中期训练和逐步思考机制的影响。

Result: 发现状态信息丰富度和规划复杂度是影响跨域泛化的关键因素，而非领域真实性或文本相似性。增加状态信息丰富度能有效提高跨域鲁棒性。SFT预热有助于防止灾难性遗忘但会损害未包含在中期训练数据中的域的泛化能力。逐步思考在保持泛化能力方面起关键作用。

Conclusion: 在智能体后训练中，应优先考虑状态信息丰富度和规划复杂度而非领域真实性。通过添加干扰特征增加状态信息丰富度是提高跨域泛化的有效方法。建模选择需要在防止遗忘和保持泛化能力之间取得平衡。

Abstract: Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.

</details>


### [324] [ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants](https://arxiv.org/abs/2601.18225)
*Pei Wang,Yanan Wu,Xiaoshuai Song,Weixun Wang,Gengru Chen,Zhongwen Li,Kezhong Yan,Ken Deng,Qi Liu,Shuaibing Zhao,Shaopan Xiong,Xuepeng Liu,Xuefeng Chen,Wanxi Deng,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: ShopSimulator是一个大规模中文电商购物模拟环境，用于评估和训练LLM智能体在复杂购物场景中的表现，发现现有模型成功率不足40%，通过SFT+RL训练可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏统一的模拟环境来全面评估LLM智能体在电商购物中的能力，包括个性化偏好理解、多轮对话、产品检索和相似产品区分等关键方面，且仅关注评估而缺乏训练支持。

Method: 提出了ShopSimulator，一个大规模且具有挑战性的中文购物环境，用于评估LLM在不同场景下的表现，并通过错误分析识别智能体的弱点，进一步探索监督微调（SFT）和强化学习（RL）相结合的训练方法。

Result: 评估发现即使表现最好的模型在完整成功率上也低于40%，智能体在长轨迹中的深度搜索和产品选择、个性化线索的平衡使用以及与用户的有效互动方面存在困难。SFT和RL相结合的训练方法带来了显著的性能提升。

Conclusion: ShopSimulator为LLM智能体在电商购物领域的评估和训练提供了重要工具，揭示了现有模型的局限性，并展示了通过适当训练方法可以显著改善智能体的购物能力。

Abstract: Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.

</details>


### [325] [Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks](https://arxiv.org/abs/2601.18226)
*Haotian Li,Shijun Yang,Weizhen Qi,Silei Zhao,Rui Hua,Mingzhu Song,Xiaojian Yang,Chao Peng*

Main category: cs.AI

TL;DR: 论文提出了一种原位自我进化范式，通过将连续任务交互作为经验流，使系统能够将短期执行反馈转化为长期可重用能力，无需真实标签。开发了Yunjue Agent系统，通过迭代合成、优化和重用工具来应对新兴挑战，并引入并行批量进化策略提高效率。


<details>
  <summary>Details</summary>
Motivation: 传统智能体系统在开放环境中面临挑战，任务分布持续漂移且外部监督稀缺。依赖静态工具集或离线训练无法适应动态变化，导致系统能力边界僵化且未知。需要一种能够持续适应和扩展能力的方法。

Method: 提出原位自我进化范式，将工具进化作为能力扩展的关键路径。开发Yunjue Agent系统，通过迭代合成、优化和重用工具来应对挑战。引入并行批量进化策略优化进化效率。使用可验证的二元反馈信号进行工具评估。

Result: 在五个不同基准测试的零起点设置下，相比专有基线模型取得了显著性能提升。补充的热启动评估证实积累的通用知识可以无缝迁移到新领域。提出了监测进化收敛的新指标，类似于传统优化中的训练损失函数。

Conclusion: 原位自我进化范式能够有效解决开放环境中智能体系统的适应性问题。通过工具进化和经验积累，系统能够持续扩展能力边界并适应动态变化。开源了代码库、系统轨迹和进化工具，促进弹性自进化智能研究。

Abstract: Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.

</details>


### [326] [A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience](https://arxiv.org/abs/2601.18308)
*Geunsik Lim*

Main category: cs.AI

TL;DR: Climate RADAR是一个基于生成式AI的可靠性层，通过整合多源数据生成个性化行动建议，将灾害预警从警报传递转变为行动执行，提高保护行动执行率并减少响应延迟。


<details>
  <summary>Details</summary>
Motivation: 传统早期预警系统虽然能快速传播警报，但往往无法触发及时的保护行动，导致可预防的损失和不平等问题。需要一种能够将警报转化为实际行动的系统。

Method: 整合气象、水文、脆弱性和社会数据形成综合风险指数，使用带有护栏的大型语言模型生成个性化建议，通过公民、志愿者和市政接口提供推荐。

Result: 通过模拟、用户研究和市政试点评估显示，系统提高了保护行动执行率，减少了响应延迟，增强了可用性和信任度。

Conclusion: Climate RADAR结合预测分析、行为科学和负责任AI，推进以人为本、透明和公平的早期预警系统，为符合要求的灾害韧性基础设施提供实用路径。

Abstract: As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.

</details>


### [327] [Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books](https://arxiv.org/abs/2601.18353)
*Tuhin Chakrabarty,Paramveer S. Dhillon*

Main category: cs.AI

TL;DR: 生成式AI在模仿作家风格方面表现出色，经过微调后甚至能超越人类专家，引发了关于创意写作本质和创意劳动未来的深刻问题。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观念——创意写作长期以来被认为是人类独有的能力，需要机器无法复制的独特声音和风格。研究旨在探索生成式AI是否能够真正模仿著名作家的写作风格，以及这种能力对人类创意写作的影响。

Method: 行为实验设计：28名MFA写作专家与三个大型语言模型竞争模仿50位备受好评的作家风格。通过上下文提示和微调作者完整作品两种条件进行测试。由28名专家评委和131名普通评委进行盲审配对比较，并通过专家作家的汇报访谈收集定性数据。

Result: 在上下文提示条件下，专家评委82.7%的情况下偏好人类写作；但在微调作者完整作品后，这一偏好逆转为62%偏好AI写作。普通评委则始终偏好AI写作。专家作家表示，他们对AI写作的偏好触发了身份危机，削弱了审美自信，并质疑了"优秀写作"的构成标准。

Conclusion: 研究结果挑战了关于AI创意局限性的传统论述，提出了关于创意劳动未来的根本性问题。AI在模仿作家风格方面的能力不仅技术层面令人印象深刻，更重要的是引发了人类创意工作者对自身价值和专业身份的深刻反思。

Abstract: Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes "good writing." These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.

</details>


### [328] [Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models](https://arxiv.org/abs/2601.18383)
*Zhenyuan Guo,Tong Chen,Wenlong Meng,Chen Gong,Xin Yu,Chengkun Wei,Wenzhi Chen*

Main category: cs.AI

TL;DR: 论文提出DynTS方法，通过注意力图分析推理轨迹，识别关键决策token并仅保留其KV缓存，优化大型推理模型的效率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型生成完整推理轨迹时会产生巨大的内存占用和计算开销，这成为模型效率的瓶颈。研究发现推理轨迹中只有部分关键token对最终答案有决定性影响，其余token贡献很小

Method: 提出动态思维token选择方法(DynTS)，利用注意力图分析推理轨迹中token的影响力，识别决策关键token，在推理过程中仅保留这些关键token的KV缓存状态，剔除冗余条目

Result: 通过选择性保留关键token的KV缓存，显著减少了内存占用和计算开销，优化了大型推理模型的推理效率

Conclusion: DynTS方法通过分析注意力机制识别推理轨迹中的关键决策token，实现了高效的KV缓存管理，为大型推理模型的效率优化提供了新思路

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.

</details>


### [329] [DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference](https://arxiv.org/abs/2601.18496)
*Zihan wang,Hao Wang,Shi Feng,Xiaocui Yang,Daling Wang,Yiqun Zhang,Jinghao Lin,Haihua Yang,Xiaozhong Ji*

Main category: cs.AI

TL;DR: DeepMed：针对医学领域的深度研究模型，通过解决任务特性和工具使用扩展两个关键差距，在医学推理基准上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 医学推理模型受限于参数化知识，容易遗忘和产生幻觉。通用深度研究模型虽然能在一般领域表现良好，但直接迁移到医学领域效果有限，主要存在任务特性和工具使用扩展两个关键差距

Method: 1）数据层面：采用多跳医学搜索QA合成方法，支持模型在医学上下文中应用深度研究范式；2）训练层面：引入难度感知的回合惩罚机制，抑制过度工具调用；3）推理层面：加入监控器帮助在有限步骤内验证假设，避免上下文污染

Result: 在七个医学基准测试中，DeepMed相比基础模型平均提升9.79%，并超越了更大的医学推理和深度研究模型

Conclusion: 通过专门针对医学任务特性设计的深度研究方法，DeepMed有效解决了医学推理中的证据解释和工具使用扩展问题，显著提升了医学推理性能

Abstract: Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus "find it but fail to use it," leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\% on average and outperforms larger medical reasoning and DR models.

</details>


### [330] [Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities](https://arxiv.org/abs/2601.18554)
*Alberto Purpura,Li Wang,Sahil Badyal,Eugenio Beaufrand,Adam Faulkner*

Main category: cs.AI

TL;DR: MOSAIC是一个模块化框架，用于评估大语言模型对复杂指令的遵循能力，通过动态生成包含多达20个应用导向约束的数据集，提供细粒度分析。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试往往无法反映真实使用场景或无法将指令遵循能力与任务成功区分开，需要更可靠的方法来评估LLMs对复杂指令的遵循能力。

Method: 提出MOSAIC框架，使用动态生成的数据集，包含多达20个应用导向的生成约束，对指令遵循能力进行模块化、细粒度的独立分析。

Result: 评估了五个不同家族的LLMs，发现指令遵循能力不是单一能力，而是随约束类型、数量和位置显著变化；揭示了模型特定弱点、指令间的协同与冲突关系，以及首因效应和近因效应等位置偏差。

Conclusion: 这些细粒度洞察对于诊断模型失败和开发需要严格遵循复杂指令的系统中的更可靠LLMs至关重要。

Abstract: Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.

</details>


### [331] [Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs](https://arxiv.org/abs/2601.18588)
*Xianzhe Meng,Qiangsheng Zeng,Ling Luo,Qinghan Yang,Jiarui Hao,Wenbo Wu,Qinyu Wang,Rui Yin,Lin Qi,Renzhi Lu*

Main category: cs.AI

TL;DR: 研究发现训练稳定性与生成质量不一定正相关，稳定训练可能导致模型输出低熵、重复的模式，尽管损失函数平滑收敛


<details>
  <summary>Details</summary>
Motivation: 传统观点认为训练稳定性是大型语言模型可靠优化的前提，但本文旨在分析训练稳定性如何影响生成分布，探讨稳定性是否真正保证生成质量

Method: 使用基于反馈的训练框架来稳定内部生成统计量，在不同架构和随机种子下观察生成行为；理论分析表明稳定参数轨迹使平稳解近似最小化前向KL散度，同时隐式降低生成熵

Result: 稳定训练导致模型输出低熵、重复的行为，尽管损失函数平滑收敛；模型将概率质量集中在经验分布的有限子集上，表现出系统性退化

Conclusion: 优化稳定性和生成表达能力并不天然一致，稳定性本身不足以作为生成质量的指标；需要超越单纯稳定性考虑来评估模型生成能力

Abstract: Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.

</details>


### [332] [A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic](https://arxiv.org/abs/2601.18595)
*Joseph Cotnareanu,Didier Chetelat,Yingxue Zhang,Mark Coates*

Main category: cs.AI

TL;DR: 本文提出了一种结合LLM和逻辑求解器的新方法，通过逻辑求解器的反馈迭代地补充缺失的常识关系，从而提升复杂推理问题的解决能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在形式推理方面表现出色，但在需要复杂证明规划的问题上常常失效。现有的逻辑求解器虽然推理效率更高，但假设所有相关事实都已提供，无法处理缺失的常识关系。

Method: 提出了一种新颖方法：使用逻辑求解器的反馈来增强逻辑问题，通过LLM迭代地补充常识关系。这涉及一个搜索过程，通过潜在的常识假设来最大化找到有用事实的机会，同时保持成本可控。

Result: 在一系列纯逻辑推理数据集上（其中部分常识信息已被移除），该方法相比现有技术始终取得显著改进。

Conclusion: 在人类语境下工作时，平衡神经和符号元素具有重要价值，该方法展示了这种平衡的有效性。

Abstract: Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.

</details>


### [333] [Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation](https://arxiv.org/abs/2601.18630)
*Abeer Badawi,Md Tahmid Rahman Laskar,Elahe Rahimi,Sheri Grach,Lindsay Bertrand,Lames Danok,Frank Rudzicz,Jimmy Huang,Elham Dolatabadi*

Main category: cs.AI

TL;DR: 该研究提出了一种基于人类专家评估的方法，用于评估大型语言模型在心理健康对话中的表现，发现LLMs在认知支持方面表现可靠，但在情感共鸣方面存在不稳定，揭示了认知-情感差距。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康危机日益严重，存在治疗缺口、资源不足和合格治疗师短缺的问题，大型语言模型为可扩展的心理支持提供了可能，但其可靠性、治疗相关性和与人类标准的对齐仍面临挑战。

Method: 研究提出了一种基于人类专家的评估方法，从真实世界场景数据集中收集了500个心理健康对话，评估了9个不同LLMs（包括闭源和开源模型）生成的回复。由两名经过精神病学培训的专家独立使用5点李克特量表，按照包含6个属性的综合评估标准进行评分，该标准涵盖认知支持和情感共鸣两个维度。

Result: 分析显示，LLMs在认知可靠性方面表现良好，能够生成安全、连贯且临床适当的信息，但在情感对齐方面表现不稳定。闭源模型（如GPT-4o）提供更平衡的治疗性回应，而开源模型则表现出更大的变异性和情感平淡。研究揭示了持续的认知-情感差距。

Conclusion: 研究强调需要建立具有失败意识、临床基础的评估框架，在心理健康导向的LLMs中优先考虑关系敏感性而不仅仅是信息准确性。倡导采用以人为中心的平衡评估协议，重点关注治疗敏感性，为心理健康对话AI的负责任设计和临床监督提供框架。

Abstract: The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.

</details>


### [334] [AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning](https://arxiv.org/abs/2601.18631)
*Mingyang Song,Haoyu Sun,Jiawei Gu,Linjie Li,Luxin Xu,Ranjay Krishna,Yu Cheng*

Main category: cs.AI

TL;DR: AdaReasoner是一个多模态模型家族，通过学习工具使用作为通用推理技能而非特定工具或显式监督行为，实现了在视觉推理任务中自主选择、调用和组合工具的能力。


<details>
  <summary>Details</summary>
Motivation: 人类在面对超出自身能力的问题时会依赖工具，这为提高多模态大语言模型的视觉推理能力提供了有前景的范式。有效的推理需要知道使用哪些工具、何时调用它们以及如何在多步骤中组合它们，即使面对新工具或新任务时也是如此。

Method: AdaReasoner通过三个关键组件实现：(1) 可扩展的数据管理流程，让模型接触长视野、多步骤的工具交互；(2) Tool-GRPO强化学习算法，基于最终任务成功优化工具选择和序列；(3) 自适应学习机制，动态调节工具使用频率。

Result: AdaReasoner表现出强大的工具自适应和泛化行为：自主采用有益工具、抑制无关工具、根据任务需求调整工具使用频率，尽管从未被明确训练这样做。在多个基准测试中达到最先进性能，将7B基础模型平均提升24.9%，并在VSP和Jigsaw等任务上超越GPT-5等强大专有系统。

Conclusion: AdaReasoner通过学习工具使用作为通用推理技能，实现了在多模态推理任务中自主、自适应地使用工具的能力，显著提升了模型性能并展现出良好的泛化能力，为多模态智能系统的发展提供了新方向。

Abstract: When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.

</details>


### [335] [Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs](https://arxiv.org/abs/2601.18706)
*Zhichao Yang,Sepehr Janghorbani,Dongxu Zhang,Jun Han,Qian Qian,Andrew Ressler,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.AI

TL;DR: Health-SCORE是一个可扩展的基于评分标准的医疗LLM训练评估框架，显著降低评分标准开发成本，同时保持评估质量。


<details>
  <summary>Details</summary>
Motivation: 在医疗等安全关键领域，评分标准对评估开放式LLM响应至关重要，但创建高质量、领域特定的评分标准需要大量专家时间和开发成本，使得基于评分标准的评估和训练难以扩展。

Method: Health-SCORE是一个通用且可扩展的基于评分标准的训练和评估框架，通过减少评分标准开发成本而不牺牲性能，提供结构化奖励信号指导强化学习，并可直接整合到提示中通过上下文学习改进响应质量。

Result: 在开放式医疗任务中，Health-SCORE实现了与人工创建评分标准相当的评估质量，同时显著降低了开发工作量，使基于评分标准的评估和训练更具可扩展性。

Conclusion: Health-SCORE框架通过降低评分标准开发成本，使基于评分标准的医疗LLM评估和训练更加可扩展，为安全关键领域的AI应用提供了实用的解决方案。

Abstract: Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.

</details>


### [336] [Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules](https://arxiv.org/abs/2601.18716)
*Naeyma N. Islam,Thomas R. Caulfield*

Main category: cs.AI

TL;DR: AI辅助药物设计方法，通过E3连接酶导向的分子胶促进Aβ-42靶向降解，用于阿尔茨海默病治疗


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病中细胞内Aβ-42的积累是疾病进展的早期毒性驱动因素，需要开发靶向降解策略

Method: 使用基于结构的建模、ADMET筛选和对接评估Aβ-42与三种E3连接酶的相互作用，开发LC-JT-VAE生成连接酶特异性小分子

Result: 生成模型能够产生化学有效、新颖且靶向特异性的分子胶，能够促进Aβ-42降解

Conclusion: 该方法为神经退行性疾病设计UPS靶向疗法提供了有前景的框架

Abstract: Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.

</details>


### [337] [TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models](https://arxiv.org/abs/2601.18744)
*Fangxu Yu,Xingang Guo,Lingzhi Yuan,Haoqiang Kang,Hongyu Zhao,Lianhui Qin,Furong Huang,Bin Hu,Tianyi Zhou*

Main category: cs.AI

TL;DR: TSRBench是一个全面的多模态时间序列推理基准测试，包含4125个问题、14个领域、4个主要维度，评估了30多个领先的LLM、VLM和TSLLM模型，揭示了时间序列推理中的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在现实世界场景中无处不在且至关重要，但现有通用模型基准测试中缺乏时间序列维度。为了填补这一空白，需要创建一个全面的基准来测试时间序列推理能力。

Method: 引入TSRBench基准测试，包含4125个问题，涵盖14个领域，分为4个主要维度（感知、推理、预测、决策制定），包含15个任务，评估了30多个领先的专有和开源LLM、VLM和TSLLM模型。

Result: 研究发现：1）缩放定律适用于感知和推理，但在预测中失效；2）强大的推理能力不能保证准确的上下文感知预测，表明语义理解和数值预测之间存在脱节；3）尽管文本和视觉表示具有互补性，但当前多模态模型未能有效融合它们以获得性能提升。

Conclusion: TSRBench提供了一个标准化评估平台，不仅突出了现有挑战，还为推进通用模型提供了有价值的见解。代码和数据集已公开。

Abstract: Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.

</details>
