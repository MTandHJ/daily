<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 66]
- [cs.IR](#cs.IR) [Total: 14]
- [cs.LG](#cs.LG) [Total: 76]
- [cs.CY](#cs.CY) [Total: 10]
- [cs.AI](#cs.AI) [Total: 42]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [WorldVQA: Measuring Atomic World Knowledge in Multimodal Large Language Models](https://arxiv.org/abs/2602.02537)
*Runjie Zhou,Youbo Shao,Haoyu Lu,Bowei Xing,Tongtong Bai,Yujie Chen,Jie Zhao,Lin Sui,Haotian Yao,Zijia Zhao,Hao Yang,Haoning Wu,Zaida Zhou,Jinguo Zhu,Zhiqi Huang,Yiping Bao,Yangyang Liu,Y. Charles,Xinyu Zhou*

Main category: cs.CV

TL;DR: WorldVQA是一个评估多模态大语言模型原子视觉世界知识的基准，通过解耦视觉知识检索与推理能力，严格测量模型记忆的视觉事实性。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法往往混淆视觉知识检索与推理能力，无法准确衡量模型真正记忆的视觉世界知识。需要建立一个严格评估模型视觉事实性、百科全书广度和幻觉率的基准。

Method: 设计WorldVQA基准，解耦视觉知识检索与推理能力，专注于测量"模型记忆了什么"。通过分层分类法评估从常见头部类别到长尾稀有实体的视觉实体定位和命名能力。

Result: WorldVQA基准能够严格测试多模态大语言模型的视觉事实性，为评估当前和下一代前沿模型的百科全书广度和幻觉率建立标准。

Conclusion: WorldVQA作为一个严谨的视觉世界知识评估基准，能够准确衡量多模态大语言模型的原子视觉知识能力，为模型视觉事实性评估提供标准化工具。

Abstract: We introduce WorldVQA, a benchmark designed to evaluate the atomic visual world knowledge of Multimodal Large Language Models (MLLMs). Unlike current evaluations, which often conflate visual knowledge retrieval with reasoning, WorldVQA decouples these capabilities to strictly measure "what the model memorizes." The benchmark assesses the atomic capability of grounding and naming visual entities across a stratified taxonomy, spanning from common head-class objects to long-tail rarities. We expect WorldVQA to serve as a rigorous test for visual factuality, thereby establishing a standard for assessing the encyclopedic breadth and hallucination rates of current and next-generation frontier models.

</details>


### [2] [AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process](https://arxiv.org/abs/2602.02676)
*Xintong Zhang,Xiaowen Zhang,Jongrong Wu,Zhi Gao,Shilin Yan,Zhenxin Diao,Kunpeng Gao,Xuanyan Chen,Yuwei Wu,Yunde Jia,Qing Li*

Main category: cs.CV

TL;DR: 提出了AdaptMMBench基准，用于评估视觉语言模型的自适应多模态推理能力，通过动态识别任务难度和MCC指标来分离元认知能力，发现自适应选择与最终准确率解耦


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖静态难度标签和简单指标，无法捕捉相对于不同模型能力的动态难度特性，混淆了自适应模式选择与一般性能的区别，且缺乏细粒度过程分析

Method: 提出AdaptMMBench基准，涵盖五个领域（现实世界、OCR、GUI、知识、数学），包含直接感知和复杂推理任务。使用MCC指标评估不同推理模式的选择合理性，通过动态识别基于模型能力边界的任务难度来分离元认知能力，并提供多维度过程评估（关键步骤覆盖、工具有效性、计算效率）

Result: 评估发现：自适应模式选择随模型容量扩展，但与最终准确率显著解耦；关键步骤覆盖与性能一致，但工具有效性在不同模型架构间高度不一致

Conclusion: AdaptMMBench提供了一个全面评估自适应多模态推理的基准，能够分离元认知能力并支持细粒度过程分析，揭示了自适应选择与最终性能之间的复杂关系

Abstract: Adaptive multimodal reasoning has emerged as a promising frontier in Vision-Language Models (VLMs), aiming to dynamically modulate between tool-augmented visual reasoning and text reasoning to enhance both effectiveness and efficiency. However, existing evaluations rely on static difficulty labels and simplistic metrics, which fail to capture the dynamic nature of difficulty relative to varying model capacities. Consequently, they obscure the distinction between adaptive mode selection and general performance while neglecting fine-grained process analyses. In this paper, we propose AdaptMMBench, a comprehensive benchmark for adaptive multimodal reasoning across five domains: real-world, OCR, GUI, knowledge, and math, encompassing both direct perception and complex reasoning tasks. AdaptMMBench utilizes a Matthews Correlation Coefficient (MCC) metric to evaluate the selection rationality of different reasoning modes, isolating this meta-cognition ability by dynamically identifying task difficulties based on models' capability boundaries. Moreover, AdaptMMBench facilitates multi-dimensional process evaluation across key step coverage, tool effectiveness, and computational efficiency. Our evaluation reveals that while adaptive mode selection scales with model capacity, it notably decouples from final accuracy. Conversely, key step coverage aligns with performance, though tool effectiveness remains highly inconsistent across model architectures.

</details>


### [3] [End-to-end reconstruction of OCT optical properties and speckle-reduced structural intensity via physics-based learning](https://arxiv.org/abs/2602.02721)
*Jinglun Yu,Yaning Wang,Wenhan Guo,Yuan Gao,Yu Sun,Jin U. Kang*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的正则化端到端框架，用于光学相干断层扫描（OCT）的逆散射问题，同时重建光学参数图和去散斑的OCT结构强度图像。


<details>
  <summary>Details</summary>
Motivation: OCT逆散射问题旨在恢复结构图像和内在组织光学特性（折射率、散射系数、各向异性），但由于衰减、散斑噪声和参数间的强耦合，这一逆问题具有挑战性。

Method: 提出了一个正则化端到端深度学习框架，结合基于物理的OCT前向模型，使用蒙特卡洛模拟的真实数据进行训练，通过物理一致性监督实现参数恢复和伪影抑制。

Result: 在合成角膜OCT数据集上的实验表明，该方法在噪声下能够稳健地恢复光学参数图，提高了分辨率并增强了结构保真度。

Conclusion: 该方法实现了定量多参数组织表征，并展示了将物理信息建模与深度学习相结合在计算OCT中的优势。

Abstract: Inverse scattering in optical coherence tomography (OCT) seeks to recover both structural images and intrinsic tissue optical properties, including refractive index, scattering coefficient, and anisotropy. This inverse problem is challenging due to attenuation, speckle noise, and strong coupling among parameters. We propose a regularized end-to-end deep learning framework that jointly reconstructs optical parameter maps and speckle-reduced OCT structural intensity for layer visualization. Trained with Monte Carlo-simulated ground truth, our network incorporates a physics-based OCT forward model that generates predicted signals from the estimated parameters, providing physics-consistent supervision for parameter recovery and artifact suppression. Experiments on the synthetic corneal OCT dataset demonstrate robust optical map recovery under noise, improved resolution, and enhanced structural fidelity. This approach enables quantitative multi-parameter tissue characterization and highlights the benefit of combining physics-informed modeling with deep learning for computational OCT.

</details>


### [4] [SVD-ViT: Does SVD Make Vision Transformers Attend More to the Foreground?](https://arxiv.org/abs/2602.02765)
*Haruhiko Murata,Kazuhiro Hotta*

Main category: cs.CV

TL;DR: SVD-ViT通过奇异值分解增强Vision Transformer的前景特征学习，抑制背景噪声，提升分类性能


<details>
  <summary>Details</summary>
Motivation: Vision Transformer由于自注意力机制全局操作，缺乏明确区分前景与背景的机制，可能学习到不必要的背景特征和伪影，导致分类性能下降

Method: 提出SVD-ViT，包含三个组件：SPC模块、SSVA和ID-RSVD，利用奇异值分解提取和聚合捕捉物体前景信息的奇异向量，抑制任务无关的背景噪声和伪影

Result: 实验结果表明该方法提高了分类准确率，有效学习了信息丰富的前景表示，同时减少了背景噪声的影响

Conclusion: SVD-ViT通过奇异值分解机制增强了Vision Transformer的前景特征学习能力，改善了分类性能，为视觉Transformer提供了更好的前景-背景区分机制

Abstract: Vision Transformers (ViT) have been established as large-scale foundation models. However, because self-attention operates globally, they lack an explicit mechanism to distinguish foreground from background. As a result, ViT may learn unnecessary background features and artifacts, leading to degraded classification performance. To address this issue, we propose SVD-ViT, which leverages singular value decomposition (SVD) to prioritize the learning of foreground features. SVD-ViT consists of three components-\textbf{SPC module}, \textbf{SSVA}, and \textbf{ID-RSVD}-and suppresses task-irrelevant factors such as background noise and artifacts by extracting and aggregating singular vectors that capture object foreground information. Experimental results demonstrate that our method improves classification accuracy and effectively learns informative foreground representations while reducing the impact of background noise.

</details>


### [5] [LmPT: Conditional Point Transformer for Anatomical Landmark Detection on 3D Point Clouds](https://arxiv.org/abs/2602.02808)
*Matteo Bastico,Pierre Onghena,David Ryckelynck,Beatriz Marcotegui,Santiago Velasco-Forero,Laurent Corté,Caroline Robine--Decourcelle,Etienne Decencière*

Main category: cs.CV

TL;DR: 提出Landmark Point Transformer (LmPT)方法，用于点云上的自动解剖标志检测，能够利用不同物种的同源骨骼进行跨物种学习和转化研究。


<details>
  <summary>Details</summary>
Motivation: 传统手动标注解剖标志耗时且存在观察者间差异，基于规则的方法通常针对特定几何形状或有限标志集。需要一种能够处理点云表示、适应不同输入类型并支持跨物种学习的方法。

Method: 提出Landmark Point Transformer (LmPT)模型，包含条件机制使其能够适应不同输入类型，进行跨物种学习。使用点云表示解剖表面，专注于股骨标志检测，评估了人类和新标注的狗股骨数据。

Result: 该方法在人类和狗股骨数据集上展示了良好的泛化能力和有效性，证明了跨物种学习的可行性。代码和狗股骨数据集将公开提供。

Conclusion: LmPT是一种有效的自动解剖标志检测方法，能够处理点云数据并支持跨物种学习，为转化研究提供了有价值的工具。

Abstract: Accurate identification of anatomical landmarks is crucial for various medical applications. Traditional manual landmarking is time-consuming and prone to inter-observer variability, while rule-based methods are often tailored to specific geometries or limited sets of landmarks. In recent years, anatomical surfaces have been effectively represented as point clouds, which are lightweight structures composed of spatial coordinates. Following this strategy and to overcome the limitations of existing landmarking techniques, we propose Landmark Point Transformer (LmPT), a method for automatic anatomical landmark detection on point clouds that can leverage homologous bones from different species for translational research. The LmPT model incorporates a conditioning mechanism that enables adaptability to different input types to conduct cross-species learning. We focus the evaluation of our approach on femoral landmarking using both human and newly annotated dog femurs, demonstrating its generalization and effectiveness across species. The code and dog femur dataset will be publicly available at: https://github.com/Pierreoo/LandmarkPointTransformer.

</details>


### [6] [Self-Supervised Uncalibrated Multi-View Video Anonymization in the Operating Room](https://arxiv.org/abs/2602.02850)
*Keqi Chen,Vinkle Srivastav,Armine Vardazaryan,Cindy Rolland,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: 提出了一种无需标注或相机标定的自监督多视角视频匿名化框架，通过检索假阴性检测并进行自监督域适应，在手术室视频中实现超过97%的召回率。


<details>
  <summary>Details</summary>
Motivation: 手术室视频研究需要隐私保护，但现有方法存在两个可扩展性瓶颈：1) 需要为新临床站点手动标注；2) 多相机设置需要重新标定。需要一种无需标注和标定的自动化解决方案。

Method: 提出自监督多视角视频匿名化框架，包含全身人员检测和姿态估计。核心策略：使用低阈值运行现成检测器收集候选检测，通过跟踪和自监督未标定多视角关联检索假阴性检测，将其作为伪标签迭代微调检测器，最后使用自身高置信度预测微调姿态模型。

Result: 在模拟手术的4D-OR数据集和真实手术数据集上验证，方法实现超过97%的召回率。使用伪标签训练实时全身检测器，性能可比，展示了实际应用价值。

Conclusion: 提出了一种无需标注或相机标定的自监督多视角视频匿名化方法，有效解决了现有方法的可扩展性问题，在手术室隐私保护中具有实际应用价值。

Abstract: Privacy preservation is a prerequisite for using video data in Operating Room (OR) research. Effective anonymization relies on the exhaustive localization of every individual; even a single missed detection necessitates extensive manual correction. However, existing approaches face two critical scalability bottlenecks: (1) they usually require manual annotations of each new clinical site for high accuracy; (2) while multi-camera setups have been widely adopted to address single-view ambiguity, camera calibration is typically required whenever cameras are repositioned. To address these problems, we propose a novel self-supervised multi-view video anonymization framework consisting of whole-body person detection and whole-body pose estimation, without annotation or camera calibration. Our core strategy is to enhance the single-view detector by "retrieving" false negatives using temporal and multi-view context, and conducting self-supervised domain adaptation. We first run an off-the-shelf whole-body person detector in each view with a low-score threshold to gather candidate detections. Then, we retrieve the low-score false negatives that exhibit consistency with the high-score detections via tracking and self-supervised uncalibrated multi-view association. These recovered detections serve as pseudo labels to iteratively fine-tune the whole-body detector. Finally, we apply whole-body pose estimation on each detected person, and fine-tune the pose model using its own high-score predictions. Experiments on the 4D-OR dataset of simulated surgeries and our dataset of real surgeries show the effectiveness of our approach achieving over 97% recall. Moreover, we train a real-time whole-body detector using our pseudo labels, achieving comparable performance and highlighting our method's practical applicability. Code is available at https://github.com/CAMMA-public/OR_anonymization.

</details>


### [7] [ViThinker: Active Vision-Language Reasoning via Dynamic Perceptual Querying](https://arxiv.org/abs/2602.02873)
*Weihang You,Qingchan Zhu,David Liu,Yi Pan,Geng Yuan,Hanqi Jiang*

Main category: cs.CV

TL;DR: ViThinker框架通过主动生成查询令牌来触发专家对齐的视觉特征合成，解决了视觉语言模型中CoT推理因过早视觉到文本转换而丢失连续信息的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型中的CoT推理存在两个主要问题：1) 过早的视觉到文本转换会丢失几何和空间布局等连续信息；2) 现有方法（如静态枚举或基于注意力的选择）是被动处理预计算输入，而非主动寻找任务相关细节。受人类主动感知启发，需要让模型能够主动查询所需视觉信息。

Method: 提出ViThinker框架：1) 模型自主生成决策（查询）令牌，触发按需合成的专家对齐视觉特征；2) 训练期间内化视觉专家能力，推理时无需外部工具调用；3) 采用两阶段课程学习：第一阶段将冻结专家蒸馏到模型参数中，第二阶段通过稀疏性惩罚学习任务驱动的查询，发现每个推理步骤的最小充分感知。

Result: 在多个视觉中心基准测试中展示了一致的改进，验证了主动查询生成在感知基础和推理准确性方面优于被动方法。

Conclusion: ViThinker通过主动感知机制显著提升了视觉语言模型的推理能力，证明了主动查询生成比被动处理方法在视觉推理任务中更有效。

Abstract: Chain-of-Thought (CoT) reasoning excels in language models but struggles in vision-language models due to premature visual-to-text conversion that discards continuous information such as geometry and spatial layout. While recent methods enhance CoT through static enumeration or attention-based selection, they remain passive, i.e., processing pre-computed inputs rather than actively seeking task-relevant details. Inspired by human active perception, we introduce ViThinker, a framework that enables vision-language models to autonomously generate decision (query) tokens triggering the synthesis of expert-aligned visual features on demand. ViThinker internalizes vision-expert capabilities during training, performing generative mental simulation during inference without external tool calls. Through a two-stage curriculum: first distilling frozen experts into model parameters, then learning task-driven querying via sparsity penalties, i.e., ViThinker discovers minimal sufficient perception for each reasoning step. Evaluations across vision-centric benchmarks demonstrate consistent improvements, validating that active query generation outperforms passive approaches in both perceptual grounding and reasoning accuracy.

</details>


### [8] [DoubleTake: Contrastive Reasoning for Faithful Decision-Making in Medical Imaging](https://arxiv.org/abs/2602.02894)
*Daivik Patel,Shrenik Patel*

Main category: cs.CV

TL;DR: 提出了一种用于医学图像决策的对比性、文档感知的参考选择框架，通过构建优化的证据集来区分易混淆病症，而非依赖相似性检索。


<details>
  <summary>Details</summary>
Motivation: 医学影像决策需要区分易混淆病症之间的细微视觉差异，但现有方法主要依赖最近邻检索，这种方法返回冗余证据并强化单一假设，无法有效支持对比性推理。

Method: 1. 引入对比性、文档感知的参考选择框架，构建紧凑的证据集，通过平衡视觉相关性、嵌入多样性和源级来源来优化区分能力；2. 基于ROCO嵌入和元数据；3. 提出反事实对比推理框架，执行结构化成对视觉比较，使用基于边界的决策规则和忠实弃权来聚合证据。

Result: 在MediConfusion基准测试中，该方法实现了最先进的性能，相对于先前方法，集合级准确率提高了近15%，同时减少了混淆并提高了个体准确性。

Conclusion: 通过对比性参考选择和结构化视觉比较，可以显著改善医学图像决策中的区分能力，为易混淆病症的准确诊断提供了更有效的框架。

Abstract: Accurate decision making in medical imaging requires reasoning over subtle visual differences between confusable conditions, yet most existing approaches rely on nearest neighbor retrieval that returns redundant evidence and reinforces a single hypothesis. We introduce a contrastive, document-aware reference selection framework that constructs compact evidence sets optimized for discrimination rather than similarity by explicitly balancing visual relevance, embedding diversity, and source-level provenance using ROCO embeddings and metadata. While ROCO provides large-scale image-caption pairs, it does not specify how references should be selected for contrastive reasoning, and naive retrieval frequently yields near-duplicate figures from the same document. To address this gap, we release a reproducible reference selection protocol and curated reference bank that enable a systematic study of contrastive retrieval in medical image reasoning. Building on these contrastive evidence sets, we propose Counterfactual-Contrastive Inference, a confidence-aware reasoning framework that performs structured pairwise visual comparisons and aggregates evidence using margin-based decision rules with faithful abstention. On the MediConfusion benchmark, our approach achieves state-of-the-art performance, improving set-level accuracy by nearly 15% relative to prior methods while reducing confusion and improving individual accuracy.

</details>


### [9] [FaceLinkGen: Rethinking Identity Leakage in Privacy-Preserving Face Recognition with Identity Extraction](https://arxiv.org/abs/2602.02914)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: 现有基于变换的隐私保护人脸识别系统主要关注像素级重建抵抗性，但FaceLinkGen攻击表明这种评估方法存在结构性缺陷，攻击者无需恢复原始像素即可实现身份链接匹配和面部再生，准确率极高。


<details>
  <summary>Details</summary>
Motivation: 当前隐私保护人脸识别系统的评估主要基于PSNR和SSIM等像素级重建指标，但作者认为这种重建中心视角存在缺陷，无法真正衡量隐私保护效果，需要揭示像素失真指标与实际隐私之间的结构性差距。

Method: 提出FaceLinkGen身份提取攻击方法，直接从受保护的模板中执行链接/匹配和面部再生，无需恢复原始像素。在三个最新的PPFR系统上进行测试，包括近零知识设置下的攻击。

Result: 在三个PPFR系统上，FaceLinkGen达到超过98.5%的匹配准确率和96%以上的再生成功率；在近零知识设置下，仍超过92%的匹配准确率和94%的再生成功率。

Conclusion: 视觉混淆无法有效保护身份信息，像素失真指标与真实隐私之间存在结构性差距，现有PPFR系统的隐私保护存在严重漏洞，需要重新设计评估方法和保护机制。

Abstract: Transformation-based privacy-preserving face recognition (PPFR) aims to verify identities while hiding facial data from attackers and malicious service providers. Existing evaluations mostly treat privacy as resistance to pixel-level reconstruction, measured by PSNR and SSIM. We show that this reconstruction-centric view fails. We present FaceLinkGen, an identity extraction attack that performs linkage/matching and face regeneration directly from protected templates without recovering original pixels. On three recent PPFR systems, FaceLinkGen reaches over 98.5\% matching accuracy and above 96\% regeneration success, and still exceeds 92\% matching and 94\% regeneration in a near zero knowledge setting. These results expose a structural gap between pixel distortion metrics, which are widely used in PPFR evaluation, and real privacy. We show that visual obfuscation leaves identity information broadly exposed to both external intruders and untrusted service providers.

</details>


### [10] [A Multi-scale Linear-time Encoder for Whole-Slide Image Analysis](https://arxiv.org/abs/2602.02918)
*Jagan Mohan Reddy Dwarampudi,Joshua Wong,Hien Van Nguyen,Tania Banerjee*

Main category: cs.CV

TL;DR: MARBLE是首个纯Mamba基础的多状态多实例学习框架，用于全切片图像分析，通过并行处理多放大级别并在线性时间状态空间模型中集成从粗到细的推理，显著提升了WSI分析性能。


<details>
  <summary>Details</summary>
Motivation: 全切片图像分析面临千兆像素分辨率和层次化放大的挑战，现有MIL方法通常只在单一尺度操作，而基于Transformer的方法存在二次注意力计算成本问题，需要更高效的多尺度分析方法。

Method: MARBLE采用并行多尺度处理与线性时间序列建模相结合的方法，在状态空间模型中实现从粗到细的推理，以最小参数开销捕获跨尺度依赖关系。

Result: 在五个公共数据集上的实验显示，AUC提升高达6.9%，准确率提升20.3%，C-index提升2.3%，证明了MARBLE在多尺度WSI分析中的高效性和泛化能力。

Conclusion: MARBLE为基于注意力的架构提供了可扩展和模块化的替代方案，建立了高效且可泛化的多尺度WSI分析框架。

Abstract: We introduce Multi-scale Adaptive Recurrent Biomedical Linear-time Encoder (MARBLE), the first \textit{purely Mamba-based} multi-state multiple instance learning (MIL) framework for whole-slide image (WSI) analysis. MARBLE processes multiple magnification levels in parallel and integrates coarse-to-fine reasoning within a linear-time state-space model, efficiently capturing cross-scale dependencies with minimal parameter overhead. WSI analysis remains challenging due to gigapixel resolutions and hierarchical magnifications, while existing MIL methods typically operate at a single scale and transformer-based approaches suffer from quadratic attention costs. By coupling parallel multi-scale processing with linear-time sequence modeling, MARBLE provides a scalable and modular alternative to attention-based architectures. Experiments on five public datasets show improvements of up to \textbf{6.9\%} in AUC, \textbf{20.3\%} in accuracy, and \textbf{2.3\%} in C-index, establishing MARBLE as an efficient and generalizable framework for multi-scale WSI analysis.

</details>


### [11] [SRA-Seg: Synthetic to Real Alignment for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2602.02944)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: SRA-Seg框架通过语义特征对齐解决合成数据与真实医学图像之间的域差距问题，仅用10%标注真实数据和90%合成数据就能在医学图像分割任务上达到与使用真实未标注数据方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 合成数据虽然视觉逼真，但由于与真实医学图像存在于不同的语义特征空间，存在域差距问题，导致现有半监督学习方法无法有效利用合成数据提升分割性能。

Method: 提出SRA-Seg框架：1）使用冻结的DINOv2嵌入计算相似性对齐损失，将合成特征拉向语义空间中最近的真实对应特征；2）采用软边缘混合技术创建平滑的解剖过渡和连续标签；3）通过EMA教师模型为合成图像生成伪标签，并应用考虑混合区域不确定性的软分割损失。

Result: 在仅使用10%标注真实数据和90%合成未标注数据的情况下，SRA-Seg在ACDC数据集上达到89.34% Dice分数，在FIVES数据集上达到84.42% Dice分数，显著优于现有半监督方法，并与使用真实未标注数据的方法性能相当。

Conclusion: SRA-Seg通过显式对齐合成与真实特征分布，有效解决了医学图像分割中合成数据的域差距问题，为利用合成数据提升分割性能提供了有效框架。

Abstract: Synthetic data, an appealing alternative to extensive expert-annotated data for medical image segmentation, consistently fails to improve segmentation performance despite its visual realism. The reason being that synthetic and real medical images exist in different semantic feature spaces, creating a domain gap that current semi-supervised learning methods cannot bridge. We propose SRA-Seg, a framework explicitly designed to align synthetic and real feature distributions for medical image segmentation. SRA-Seg introduces a similarity-alignment (SA) loss using frozen DINOv2 embeddings to pull synthetic representations toward their nearest real counterparts in semantic space. We employ soft edge blending to create smooth anatomical transitions and continuous labels, eliminating the hard boundaries from traditional copy-paste augmentation. The framework generates pseudo-labels for synthetic images via an EMA teacher model and applies soft-segmentation losses that respect uncertainty in mixed regions. Our experiments demonstrate strong results: using only 10% labeled real data and 90% synthetic unlabeled data, SRA-Seg achieves 89.34% Dice on ACDC and 84.42% on FIVES, significantly outperforming existing semi-supervised methods and matching the performance of methods using real unlabeled data.

</details>


### [12] [Nüwa: Mending the Spatial Integrity Torn by VLM Token Pruning](https://arxiv.org/abs/2602.02951)
*Yihong Huang,Fei Ma,Yihua Shao,Jingcai Guo,Zitong Yu,Laizhong Cui,Qi Tian*

Main category: cs.CV

TL;DR: Nüwa是一个两阶段视觉令牌剪枝框架，通过保留全局空间锚点和文本引导剪枝，在视觉语言模型中实现高效特征聚合同时保持空间完整性，显著提升视觉定位任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉令牌剪枝方法在视觉问答任务上表现良好，但在视觉定位任务上性能大幅下降。研究发现，基于全局语义相似性和注意力分数的策略会丢失全局空间参考框架，而该框架源于令牌位置信息的交互。

Method: 提出两阶段令牌剪枝框架Nüwa：第一阶段在视觉编码器后，采用分离、对齐和聚合三个操作（受群体智能算法启发）保留信息丰富的全局空间锚点；第二阶段在LLM内部，执行文本引导剪枝以保留任务相关的视觉令牌。

Result: 在多个VQA基准测试中达到SOTA性能（从94%提升到95%），在视觉定位任务上获得显著改进（从7%提升到47%）。

Conclusion: Nüwa框架通过保留全局空间参考框架和任务相关视觉信息，有效解决了现有剪枝方法在视觉定位任务上的性能下降问题，实现了视觉语言模型的高效加速同时保持多任务性能。

Abstract: Vision token pruning has proven to be an effective acceleration technique for the efficient Vision Language Model (VLM). However, existing pruning methods demonstrate excellent performance preservation in visual question answering (VQA) and suffer substantial degradation on visual grounding (VG) tasks. Our analysis of the VLM's processing pipeline reveals that strategies utilizing global semantic similarity and attention scores lose the global spatial reference frame, which is derived from the interactions of tokens' positional information. Motivated by these findings, we propose $\text{Nüwa}$, a two-stage token pruning framework that enables efficient feature aggregation while maintaining spatial integrity. In the first stage, after the vision encoder, we apply three operations, namely separation, alignment, and aggregation, which are inspired by swarm intelligence algorithms to retain information-rich global spatial anchors. In the second stage, within the LLM, we perform text-guided pruning to retain task-relevant visual tokens. Extensive experiments demonstrate that $\text{Nüwa}$ achieves SOTA performance on multiple VQA benchmarks (from 94% to 95%) and yields substantial improvements on visual grounding tasks (from 7% to 47%).

</details>


### [13] [TRACE: Temporal Radiology with Anatomical Change Explanation for Grounded X-ray Report Generation](https://arxiv.org/abs/2602.02963)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: TRACE是首个结合时间比较、变化分类和空间定位的模型，用于胸部X光片的时间变化检测，能生成自然语言描述变化并定位病灶位置。


<details>
  <summary>Details</summary>
Motivation: 胸部X光片的时间比较在临床放射学中至关重要，用于检测疾病进展、治疗反应和新发现。现有视觉语言模型只支持单图像报告生成和视觉定位，缺乏结合这两种能力进行时间变化检测的方法。

Method: 提出TRACE模型，给定先前的和当前的胸部X光片，模型能联合执行时间比较、变化分类和空间定位，生成描述区间变化的自然语言（恶化、改善、稳定），同时用边界框坐标定位每个发现。

Result: TRACE在空间定位方面表现出色，定位准确率超过90%，为这一具有挑战性的新任务奠定了基础。消融研究发现了一个新兴能力：只有当时间比较和空间定位联合学习时，变化检测才会出现，单独任一项都无法实现有意义的变化检测。

Conclusion: TRACE是首个结合时间比较、变化分类和空间定位的模型，为胸部X光片的时间变化检测提供了新方法。研究发现定位提供了空间注意力机制，这对时间推理至关重要，表明联合学习是实现有效变化检测的关键。

Abstract: Temporal comparison of chest X-rays is fundamental to clinical radiology, enabling detection of disease progression, treatment response, and new findings. While vision-language models have advanced single-image report generation and visual grounding, no existing method combines these capabilities for temporal change detection. We introduce Temporal Radiology with Anatomical Change Explanation (TRACE), the first model that jointly performs temporal comparison, change classification, and spatial localization. Given a prior and current chest X-ray, TRACE generates natural language descriptions of interval changes (worsened, improved, stable) while grounding each finding with bounding box coordinates. TRACE demonstrates effective spatial localization with over 90% grounding accuracy, establishing a foundation for this challenging new task. Our ablation study uncovers an emergent capability: change detection arises only when temporal comparison and spatial grounding are jointly learned, as neither alone enables meaningful change detection. This finding suggests that grounding provides a spatial attention mechanism essential for temporal reasoning.

</details>


### [14] [Fisheye Stereo Vision: Depth and Range Error](https://arxiv.org/abs/2602.02973)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.CV

TL;DR: 该研究推导了鱼眼立体视觉系统的深度和距离误差解析表达式，特别考虑了在大角度情况下的精度问题


<details>
  <summary>Details</summary>
Motivation: 鱼眼立体视觉系统在大角度情况下存在精度问题，需要建立准确的误差模型来评估系统性能

Method: 推导了深度和距离误差的解析表达式，考虑了物体距离的函数关系，特别关注大角度情况下的精度分析

Result: 获得了鱼眼立体视觉系统深度和距离误差的解析表达式，能够准确评估在不同距离和大角度情况下的系统精度

Conclusion: 该研究为鱼眼立体视觉系统的误差分析提供了理论框架，特别适用于大角度情况下的精度评估

Abstract: This study derives analytical expressions for the depth and range error of fisheye stereo vision systems as a function of object distance, specifically accounting for accuracy at large angles.

</details>


### [15] [Aligning Forest and Trees in Images and Long Captions for Visually Grounded Understanding](https://arxiv.org/abs/2602.02977)
*Byeongju Woo,Zilin Wang,Byeonghyun Pak,Sangwoo Mo,Stella X. Yu*

Main category: cs.CV

TL;DR: CAFT提出了一种跨域层次对齐框架，通过耦合细粒度视觉编码器和层次化文本转换器，在无需像素级监督的情况下对齐图像与长文本的全局和局部语义，在长文本检索任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（如CLIP）将图像和文本作为整体对齐，难以处理长文本描述。细粒度视觉语言理解需要捕获跨视觉和文本域的层次语义，但语言层次（语法/语义）与视觉组织不匹配，纯视觉层次倾向于将场景分割为外观驱动的部分而缺乏语义焦点。

Method: 提出CAFT框架：1）耦合从细到粗的视觉编码器和层次化文本转换器；2）使用层次对齐损失，在匹配整体图像与整体描述的同时，偏置区域-句子对应关系；3）确保粗粒度语义基于细粒度证据构建，而非脱离部分级基础的聚合。

Result: 在3000万图像-文本对上进行训练，在6个长文本检索基准测试中达到最先进性能，并表现出强大的扩展行为。实验表明，层次跨域对齐能够在没有显式区域级监督的情况下，实现细粒度、视觉基础的图像-文本表示。

Conclusion: CAFT通过层次化跨域对齐框架，成功解决了长文本视觉语言理解中的语义对齐问题，在无需像素级监督的情况下实现了细粒度的图像-文本表示学习，为视觉语言模型处理复杂长文本描述提供了有效解决方案。

Abstract: Large vision-language models such as CLIP struggle with long captions because they align images and texts as undifferentiated wholes. Fine-grained vision-language understanding requires hierarchical semantics capturing both global context and localized details across visual and textual domains. Yet linguistic hierarchies from syntax or semantics rarely match visual organization, and purely visual hierarchies tend to fragment scenes into appearance-driven parts without semantic focus. We propose CAFT (Cross-domain Alignment of Forests and Trees), a hierarchical image-text representation learning framework that aligns global and local semantics across images and long captions without pixel-level supervision. Coupling a fine-to-coarse visual encoder with a hierarchical text transformer, it uses a hierarchical alignment loss that matches whole images with whole captions while biasing region-sentence correspondences, so that coarse semantics are built from fine-grained evidence rather than from aggregation untethered to part-level grounding. Trained on 30M image-text pairs, CAFT achieves state-of-the-art performance on six long-text retrieval benchmarks and exhibits strong scaling behavior. Experiments show that hierarchical cross-domain alignment enables fine-grained, visually grounded image-text representations to emerge without explicit region-level supervision.

</details>


### [16] [SharpTimeGS: Sharp and Stable Dynamic Gaussian Splatting via Lifespan Modulation](https://arxiv.org/abs/2602.02989)
*Zhanfeng Liao,Jiajun Zhang,Hanzhang Tu,Zhixi Wang,Yunqi Gao,Hongwen Zhang,Yebin Liu*

Main category: cs.CV

TL;DR: SharpTimeGS是一种基于4D高斯表示的寿命感知框架，通过可学习的寿命参数实现静态和动态区域的时域自适应建模，在保持实时渲染的同时提升长期稳定性和动态保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯表示的方法在平衡长期静态区域和短期动态区域的表示与优化方面存在困难，需要一种统一的框架来同时处理静态和动态区域的时间特性。

Method: 提出可学习的寿命参数，将时间可见性从高斯衰减重新定义为平顶轮廓；通过学习的寿命调节每个基元的运动；设计寿命-速度感知的致密化策略来平衡静态和动态区域的优化。

Result: 在多个基准测试中达到最先进性能，支持在单个RTX 4090上以100 FPS的帧率进行4K分辨率的实时渲染。

Conclusion: SharpTimeGS通过寿命感知的4D高斯框架成功实现了静态和动态区域的时域自适应建模，在保持实时渲染能力的同时显著提升了长期稳定性和动态保真度。

Abstract: Novel view synthesis of dynamic scenes is fundamental to achieving photorealistic 4D reconstruction and immersive visual experiences. Recent progress in Gaussian-based representations has significantly improved real-time rendering quality, yet existing methods still struggle to maintain a balance between long-term static and short-term dynamic regions in both representation and optimization. To address this, we present SharpTimeGS, a lifespan-aware 4D Gaussian framework that achieves temporally adaptive modeling of both static and dynamic regions under a unified representation. Specifically, we introduce a learnable lifespan parameter that reformulates temporal visibility from a Gaussian-shaped decay into a flat-top profile, allowing primitives to remain consistently active over their intended duration and avoiding redundant densification. In addition, the learned lifespan modulates each primitives' motion, reducing drift in long-lived static points while retaining unrestricted motion for short-lived dynamic ones. This effectively decouples motion magnitude from temporal duration, improving long-term stability without compromising dynamic fidelity. Moreover, we design a lifespan-velocity-aware densification strategy that mitigates optimization imbalance between static and dynamic regions by allocating more capacity to regions with pronounced motion while keeping static areas compact and stable. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art performance while supporting real-time rendering up to 4K resolution at 100 FPS on one RTX 4090.

</details>


### [17] [Video-OPD: Efficient Post-Training of Multimodal Large Language Models for Temporal Video Grounding via On-Policy Distillation](https://arxiv.org/abs/2602.02994)
*Jiaze Li,Hao Yin,Haoran Xu,Boshen Xu,Wenhui Tan,Zewen He,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: Video-OPD：一种基于策略蒸馏的高效时序视频定位后训练框架，通过教师模型提供密集的token级监督，结合TVDF课程学习策略，显著提升训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRPO的时序视频定位方法存在稀疏奖励信号和计算开销大的问题，需要一种既能保持策略优化特性又能提高训练效率的替代方案。

Method: 提出Video-OPD框架：1）直接从当前策略采样轨迹，保持训练与推理分布对齐；2）使用前沿教师模型通过反向KL散度提供密集的token级监督；3）引入TVDF课程学习，迭代优先选择教师可靠且对学生信息量最大的轨迹。

Result: Video-OPD在性能上持续优于GRPO方法，同时实现更快的收敛速度和更低的计算成本，验证了策略蒸馏作为传统强化学习替代方案的有效性。

Conclusion: 策略蒸馏是时序视频定位中传统强化学习的有力替代方案，Video-OPD通过保持策略优化特性、提供密集监督和智能课程学习，在效率和性能上都取得了显著提升。

Abstract: Reinforcement learning has emerged as a principled post-training paradigm for Temporal Video Grounding (TVG) due to its on-policy optimization, yet existing GRPO-based methods remain fundamentally constrained by sparse reward signals and substantial computational overhead. We propose Video-OPD, an efficient post-training framework for TVG inspired by recent advances in on-policy distillation. Video-OPD optimizes trajectories sampled directly from the current policy, thereby preserving alignment between training and inference distributions, while a frontier teacher supplies dense, token-level supervision via a reverse KL divergence objective. This formulation preserves the on-policy property critical for mitigating distributional shift, while converting sparse, episode-level feedback into fine-grained, step-wise learning signals. Building on Video-OPD, we introduce Teacher-Validated Disagreement Focusing (TVDF), a lightweight training curriculum that iteratively prioritizes trajectories that are both teacher-reliable and maximally informative for the student, thereby improving training efficiency. Empirical results demonstrate that Video-OPD consistently outperforms GRPO while achieving substantially faster convergence and lower computational cost, establishing on-policy distillation as an effective alternative to conventional reinforcement learning for TVG.

</details>


### [18] [VOILA: Value-of-Information Guided Fidelity Selection for Cost-Aware Multimodal Question Answering](https://arxiv.org/abs/2602.03007)
*Rahul Atul Bhope,K. R. Jayaram,Vinod Muthusamy,Ritesh Kumar,Vatche Isahagian,Nalini Venkatasubramanian*

Main category: cs.CV

TL;DR: VOILA是一个基于信息价值驱动的自适应保真度选择框架，用于视觉问答任务，通过预测不同保真度下的正确率并考虑检索成本，实现50-60%的成本降低同时保持90-95%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前多模态视觉语言系统通常以固定的保真度运行，但获取和处理高保真度视觉输入的成本很高。需要一种方法在模型执行前优化信息检索，根据查询需求自适应选择适当的保真度。

Method: VOILA采用两阶段流水线：1）使用梯度提升回归器仅从问题特征估计每个保真度的正确率可能性；2）使用等渗校准器精炼这些概率以进行可靠决策。系统选择最小成本的保真度，最大化给定预测准确率和检索成本的期望效用。

Result: 在三个部署场景、五个数据集（VQA-v2、GQA、TextVQA、LoCoMo、FloodNet）和六个参数规模从7B到235B的视觉语言模型上评估，VOILA始终实现50-60%的成本降低，同时保持90-95%的全分辨率准确率。

Conclusion: 检索前的保真度选择对于在资源约束下优化多模态推理至关重要，VOILA框架证明了通过信息价值驱动的自适应保真度选择可以在显著降低成本的同时保持高准确率。

Abstract: Despite significant costs from retrieving and processing high-fidelity visual inputs, most multimodal vision-language systems operate at fixed fidelity levels. We introduce VOILA, a framework for Value-Of-Information-driven adaptive fidelity selection in Visual Question Answering (VQA) that optimizes what information to retrieve before model execution. Given a query, VOILA uses a two-stage pipeline: a gradient-boosted regressor estimates correctness likelihood at each fidelity from question features alone, then an isotonic calibrator refines these probabilities for reliable decision-making. The system selects the minimum-cost fidelity maximizing expected utility given predicted accuracy and retrieval costs. We evaluate VOILA across three deployment scenarios using five datasets (VQA-v2, GQA, TextVQA, LoCoMo, FloodNet) and six Vision-Language Models (VLMs) with 7B-235B parameters. VOILA consistently achieves 50-60% cost reductions while retaining 90-95% of full-resolution accuracy across diverse query types and model architectures, demonstrating that pre-retrieval fidelity selection is vital to optimize multimodal inference under resource constraints.

</details>


### [19] [Thinking inside the Convolution for Image Inpainting: Reconstructing Texture via Structure under Global and Local Side](https://arxiv.org/abs/2602.03013)
*Haipeng Liu,Yang Wang,Biao Qian,Yong Rui,Meng Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种通过结构-纹理特征图相互指导来缓解卷积下采样过程中信息损失的方法，改善了图像修复的上采样恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法在卷积下采样过程中会不可避免地丢失结构和纹理特征信息，导致上采样恢复效果不理想。作者旨在探索结构和纹理特征图能否相互帮助来缓解这种信息损失。

Method: 采用统计归一化和反归一化策略，在卷积下采样过程中利用结构和纹理特征图相互提供重建指导。

Result: 实验结果表明该方法在256×256和512×512分辨率图像上优于现有技术，特别是在将所有编码器替换为该方法时效果显著。

Conclusion: 通过结构和纹理特征图的相互指导可以有效缓解卷积下采样过程中的信息损失，提升图像修复的上采样恢复质量。

Abstract: Image inpainting has earned substantial progress, owing to the encoder-and-decoder pipeline, which is benefited from the Convolutional Neural Networks (CNNs) with convolutional downsampling to inpaint the masked regions semantically from the known regions within the encoder, coupled with an upsampling process from the decoder for final inpainting output. Recent studies intuitively identify the high-frequency structure and low-frequency texture to be extracted by CNNs from the encoder, and subsequently for a desirable upsampling recovery. However, the existing arts inevitably overlook the information loss for both structure and texture feature maps during the convolutional downsampling process, hence suffer from a non-ideal upsampling output. In this paper, we systematically answer whether and how the structure and texture feature map can mutually help to alleviate the information loss during the convolutional downsampling. Given the structure and texture feature maps, we adopt the statistical normalization and denormalization strategy for the reconstruction guidance during the convolutional downsampling process. The extensive experimental results validate its advantages to the state-of-the-arts over the images from low-to-high resolutions including 256*256 and 512*512, especially holds by substituting all the encoders by ours. Our code is available at https://github.com/htyjers/ConvInpaint-TSGL

</details>


### [20] [A Vision-Based Analysis of Congestion Pricing in New York City](https://arxiv.org/abs/2602.03015)
*Mehmet Kerem Turkcan,Jhonatan Tavori,Javad Ghaderi,Gil Zussman,Zoran Kostic,Andrew Smyth*

Main category: cs.CV

TL;DR: 通过计算机视觉分析纽约市900多个交通摄像头数据，评估2024年11月至2026年1月期间拥堵收费政策对曼哈顿交通模式的影响


<details>
  <summary>Details</summary>
Motivation: 评估纽约市拥堵收费政策的实际效果，通过客观的交通数据分析政策实施前后的交通模式变化

Method: 建立计算机视觉处理流水线，分析分布在曼哈顿和纽约市的900多个交通摄像头数据，对比2024年11月（政策实施前）到2026年1月（政策实施后）的交通模式

Result: 建立了基准交通模式，识别出监控区域内车辆密度的系统性变化

Conclusion: 通过大规模交通摄像头数据的自动化分析，能够客观评估拥堵收费政策对城市交通模式的实际影响

Abstract: We examine the impact of New York City's congestion pricing program through automated analysis of traffic camera data. Our computer vision pipeline processes footage from over 900 cameras distributed throughout Manhattan and New York, comparing traffic patterns from November 2024 through the program's implementation in January 2025 until January 2026. We establish baseline traffic patterns and identify systematic changes in vehicle density across the monitored region.

</details>


### [21] [MUSE: A Multi-agent Framework for Unconstrained Story Envisioning via Closed-Loop Cognitive Orchestration](https://arxiv.org/abs/2602.03028)
*Wenzhang Sun,Zhenyu Wang,Zhangchi Hu,Chunfeng Wang,Hao Li,Wei Chen*

Main category: cs.CV

TL;DR: MUSE：一个多智能体框架，通过规划-执行-验证-修订的闭环循环来生成长篇音视频故事，解决了长序列生成中的语义漂移和身份不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从简短用户提示生成长篇音视频故事时存在意图-执行差距，容易导致语义漂移和身份不一致，需要更好的方法来保持高级叙事意图在长序列中的连贯性。

Method: 将故事讲述建模为闭环约束执行问题，提出MUSE多智能体框架，通过迭代的规划-执行-验证-修订循环协调生成过程，将叙事意图转化为对身份、空间构图和时间连续性的显式控制。

Result: MUSE在长时叙事连贯性、跨模态身份一致性和电影质量方面显著优于代表性基线方法，通过MUSEBench无参考评估协议验证了其有效性。

Conclusion: MUSE框架通过闭环约束执行和多智能体协调，有效解决了长篇音视频故事生成中的意图-执行差距问题，提高了生成内容的一致性和质量。

Abstract: Generating long-form audio-visual stories from a short user prompt remains challenging due to an intent-execution gap, where high-level narrative intent must be preserved across coherent, shot-level multimodal generation over long horizons. Existing approaches typically rely on feed-forward pipelines or prompt-only refinement, which often leads to semantic drift and identity inconsistency as sequences grow longer. We address this challenge by formulating storytelling as a closed-loop constraint enforcement problem and propose MUSE, a multi-agent framework that coordinates generation through an iterative plan-execute-verify-revise loop. MUSE translates narrative intent into explicit, machine-executable controls over identity, spatial composition, and temporal continuity, and applies targeted multimodal feedback to correct violations during generation. To evaluate open-ended storytelling without ground-truth references, we introduce MUSEBench, a reference-free evaluation protocol validated by human judgments. Experiments demonstrate that MUSE substantially improves long-horizon narrative coherence, cross-modal identity consistency, and cinematic quality compared with representative baselines.

</details>


### [22] [Bongards at the Boundary of Perception and Reasoning: Programs or Language?](https://arxiv.org/abs/2602.03038)
*Cassidy Langenfeld,Claas Beger,Gloria Geng,Wasu Top Piriyakulkij,Keya Hu,Yewen Pu,Kevin Ellis*

Main category: cs.CV

TL;DR: 本文提出了一种神经符号方法来解决Bongard视觉推理问题，结合LLM生成程序化规则表示和贝叶斯优化进行参数拟合。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在日常视觉任务中取得进展，但人类能够在全新情境中运用视觉推理能力，而Bongard问题正是测试这种能力的经典挑战。现有方法难以解决这类需要抽象推理的视觉问题。

Method: 采用神经符号方法：1）给定Bongard问题的假设解规则，利用LLM生成参数化的程序化规则表示；2）使用贝叶斯优化进行参数拟合；3）在已知规则和从零开始两种情况下评估方法。

Result: 方法在Bongard问题图像分类（已知真实规则）以及从零开始解决问题两方面进行评估，展示了神经符号方法在视觉推理挑战中的有效性。

Conclusion: 结合LLM的程序生成能力和贝叶斯优化的参数拟合，为Bongard等复杂视觉推理问题提供了一种有效的神经符号解决方案，扩展了AI在抽象视觉推理领域的能力。

Abstract: Vision-Language Models (VLMs) have made great strides in everyday visual tasks, such as captioning a natural image, or answering commonsense questions about such images. But humans possess the puzzling ability to deploy their visual reasoning abilities in radically new situations, a skill rigorously tested by the classic set of visual reasoning challenges known as the Bongard problems. We present a neurosymbolic approach to solving these problems: given a hypothesized solution rule for a Bongard problem, we leverage LLMs to generate parameterized programmatic representations for the rule and perform parameter fitting using Bayesian optimization. We evaluate our method on classifying Bongard problem images given the ground truth rule, as well as on solving the problems from scratch.

</details>


### [23] [IVC-Prune: Revealing the Implicit Visual Coordinates in LVLMs for Vision Token Pruning](https://arxiv.org/abs/2602.03060)
*Zhichao Sun,Yidong Ma,Gang Liu,Yibo Chen,Xu Tang,Yao Hu,Yongchao Xu*

Main category: cs.CV

TL;DR: IVC-Prune是一种无需训练、提示感知的视觉token剪枝方法，通过保留隐式视觉坐标token和语义相关前景token，在减少约50%视觉token的同时保持≥99%的原始性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在处理高分辨率视觉输入时推理成本过高，现有视觉token剪枝方法主要关注语义相关性，但往往会丢弃对空间推理至关重要的token。

Method: 提出IVC-Prune方法：1）通过分析RoPE的数学特性识别隐式视觉坐标token（IVC token）；2）通过两阶段过程识别前景token（语义种子发现和基于值向量相似度的上下文细化）；3）结合保留IVC token和前景token进行剪枝。

Result: 在四个代表性LVLM和二十个多样化基准测试上的广泛评估显示，IVC-Prune减少约50%视觉token的同时，保持≥99%的原始性能，甚至在某些基准上实现性能提升。

Conclusion: IVC-Prune通过识别和保留对空间推理至关重要的隐式视觉坐标token，解决了现有视觉token剪枝方法在空间推理方面的不足，为高效LVLM推理提供了有效解决方案。

Abstract: Large Vision-Language Models (LVLMs) achieve impressive performance across multiple tasks. A significant challenge, however, is their prohibitive inference cost when processing high-resolution visual inputs. While visual token pruning has emerged as a promising solution, existing methods that primarily focus on semantic relevance often discard tokens that are crucial for spatial reasoning. We address this gap through a novel insight into \emph{how LVLMs process spatial reasoning}. Specifically, we reveal that LVLMs implicitly establish visual coordinate systems through Rotary Position Embeddings (RoPE), where specific token positions serve as \textbf{implicit visual coordinates} (IVC tokens) that are essential for spatial reasoning. Based on this insight, we propose \textbf{IVC-Prune}, a training-free, prompt-aware pruning strategy that retains both IVC tokens and semantically relevant foreground tokens. IVC tokens are identified by theoretically analyzing the mathematical properties of RoPE, targeting positions at which its rotation matrices approximate identity matrix or the $90^\circ$ rotation matrix. Foreground tokens are identified through a robust two-stage process: semantic seed discovery followed by contextual refinement via value-vector similarity. Extensive evaluations across four representative LVLMs and twenty diverse benchmarks show that IVC-Prune reduces visual tokens by approximately 50\% while maintaining $\geq$ 99\% of the original performance and even achieving improvements on several benchmarks. Source codes are available at https://github.com/FireRedTeam/IVC-Prune.

</details>


### [24] [Finding Optimal Video Moment without Training: Gaussian Boundary Optimization for Weakly Supervised Video Grounding](https://arxiv.org/abs/2602.03071)
*Sunoh Kim,Kimin Yun,Daeho Um*

Main category: cs.CV

TL;DR: 提出GBO框架，通过优化问题直接预测视频片段边界，无需启发式映射，显著提升弱监督视频时序定位性能


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯分布的弱监督视频时序定位方法依赖启发式映射从高斯参数到片段边界，导致定位性能不理想

Method: 提出高斯边界优化（GBO）框架，通过求解平衡提案覆盖度和片段紧凑性的优化问题来预测片段边界，推导出闭式解并分析不同惩罚机制下的最优性条件

Result: GBO显著提升定位性能，在标准基准测试中达到最先进结果，实验证明其高效性和对各种提案方案的泛化能力

Conclusion: GBO为弱监督视频时序定位提供了理论严谨且实用的推理框架，无需训练且兼容多种高斯提案架构

Abstract: Weakly supervised temporal video grounding aims to localize query-relevant segments in untrimmed videos using only video-sentence pairs, without requiring ground-truth segment annotations that specify exact temporal boundaries. Recent approaches tackle this task by utilizing Gaussian-based temporal proposals to represent query-relevant segments. However, their inference strategies rely on heuristic mappings from Gaussian parameters to segment boundaries, resulting in suboptimal localization performance. To address this issue, we propose Gaussian Boundary Optimization (GBO), a novel inference framework that predicts segment boundaries by solving a principled optimization problem that balances proposal coverage and segment compactness. We derive a closed-form solution for this problem and rigorously analyze the optimality conditions under varying penalty regimes. Beyond its theoretical foundations, GBO offers several practical advantages: it is training-free and compatible with both single-Gaussian and mixture-based proposal architectures. Our experiments show that GBO significantly improves localization, achieving state-of-the-art results across standard benchmarks. Extensive experiments demonstrate the efficiency and generalizability of GBO across various proposal schemes. The code is available at \href{https://github.com/sunoh-kim/gbo}{https://github.com/sunoh-kim/gbo}.

</details>


### [25] [A generalizable large-scale foundation model for musculoskeletal radiographs](https://arxiv.org/abs/2602.03076)
*Shinn Kim,Soobin Lee,Kyoungseob Shin,Han-Soo Kim,Yongsung Kim,Minsu Kim,Juhong Nam,Somang Ko,Daeheon Kwon,Wook Huh,Ilkyu Han,Sunghoon Kwon*

Main category: cs.CV

TL;DR: SKELEX是一个基于120万张肌肉骨骼X光片训练的大规模基础模型，通过自监督学习实现，在骨折检测、骨关节炎分级和骨肿瘤分类等12个下游任务中表现优异，并能进行零样本异常定位。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在肌肉骨骼疾病检测中存在任务特定性、标注依赖性强、泛化能力有限的问题，且公开数据集规模小、多样性不足，无法训练覆盖多种疾病和解剖部位的基础模型。

Method: 使用自监督学习方法在120万张多样化、富含病理信息的肌肉骨骼X光片上训练SKELEX基础模型，并开发了可解释的区域引导模型用于骨肿瘤预测。

Result: SKELEX在12个下游诊断任务中普遍优于基线模型，特别是在骨折检测、骨关节炎分级和骨肿瘤分类方面。模型展示了零样本异常定位能力，无需特定任务训练即可生成病理区域错误图。基于此开发的骨肿瘤预测模型在独立外部数据集上保持稳健性能，并已部署为公开可访问的Web应用。

Conclusion: SKELEX为肌肉骨骼影像提供了一个可扩展、标签高效且泛化能力强的AI框架，为临床转化和肌肉骨骼放射学中的数据高效研究奠定了基础。

Abstract: Artificial intelligence (AI) has shown promise in detecting and characterizing musculoskeletal diseases from radiographs. However, most existing models remain task-specific, annotation-dependent, and limited in generalizability across diseases and anatomical regions. Although a generalizable foundation model trained on large-scale musculoskeletal radiographs is clinically needed, publicly available datasets remain limited in size and lack sufficient diversity to enable training across a wide range of musculoskeletal conditions and anatomical sites. Here, we present SKELEX, a large-scale foundation model for musculoskeletal radiographs, trained using self-supervised learning on 1.2 million diverse, condition-rich images. The model was evaluated on 12 downstream diagnostic tasks and generally outperformed baselines in fracture detection, osteoarthritis grading, and bone tumor classification. Furthermore, SKELEX demonstrated zero-shot abnormality localization, producing error maps that identified pathologic regions without task-specific training. Building on this capability, we developed an interpretable, region-guided model for predicting bone tumors, which maintained robust performance on independent external datasets and was deployed as a publicly accessible web application. Overall, SKELEX provides a scalable, label-efficient, and generalizable AI framework for musculoskeletal imaging, establishing a foundation for both clinical translation and data-efficient research in musculoskeletal radiology.

</details>


### [26] [Gromov Wasserstein Optimal Transport for Semantic Correspondences](https://arxiv.org/abs/2602.03105)
*Francis Snelgar,Stephen Gould,Ming Xu,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: 该论文提出了一种新的语义匹配方法，用带有Gromov Wasserstein空间平滑先验的最优传输算法替代标准最近邻匹配，显著提升了DINOv2的性能，在保持竞争力的同时实现了5-10倍的计算效率提升。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的语义对应方法需要结合DINOv2和Stable Diffusion的特征，虽然性能出色但计算成本高昂。DINOv2特征准确但稀疏，Stable Diffusion特征空间一致但需要额外计算。作者希望找到一种既能保持空间一致性又更高效的方法。

Method: 采用不同的方法，不结合Stable Diffusion特征，而是用带有Gromov Wasserstein空间平滑先验的最优传输算法替代标准最近邻匹配。这种方法为DINOv2特征匹配注入了空间一致性，避免了使用计算昂贵的Stable Diffusion模型。

Result: 该方法显著提升了DINOv2基线的性能，与使用Stable Diffusion特征的最先进方法相比具有竞争力甚至有时更优，同时计算效率提高了5-10倍。

Conclusion: 通过用最优传输算法替代标准最近邻匹配，可以在不依赖计算昂贵的Stable Diffusion特征的情况下实现高质量的语义对应，为语义匹配任务提供了更高效的解决方案。

Abstract: Establishing correspondences between image pairs is a long studied problem in computer vision. With recent large-scale foundation models showing strong zero-shot performance on downstream tasks including classification and segmentation, there has been interest in using the internal feature maps of these models for the semantic correspondence task. Recent works observe that features from DINOv2 and Stable Diffusion (SD) are complementary, the former producing accurate but sparse correspondences, while the latter produces spatially consistent correspondences. As a result, current state-of-the-art methods for semantic correspondence involve combining features from both models in an ensemble. While the performance of these methods is impressive, they are computationally expensive, requiring evaluating feature maps from large-scale foundation models. In this work we take a different approach, instead replacing SD features with a superior matching algorithm which is imbued with the desirable spatial consistency property. Specifically, we replace the standard nearest neighbours matching with an optimal transport algorithm that includes a Gromov Wasserstein spatial smoothness prior. We show that we can significantly boost the performance of the DINOv2 baseline, and be competitive and sometimes surpassing state-of-the-art methods using Stable Diffusion features, while being 5--10x more efficient. We make code available at https://github.com/fsnelgar/semantic_matching_gwot .

</details>


### [27] [Beyond Cropping and Rotation: Automated Evolution of Powerful Task-Specific Augmentations with Generative Models](https://arxiv.org/abs/2602.03123)
*Judah Goldfeder,Shreyes Kaliyur,Vaibhav Sourirajan,Patrick Minwan Puma,Philippe Martin Wyder,Yuhang Hu,Jiong Lin,Hod Lipson*

Main category: cs.CV

TL;DR: EvoAug是一个自动化增强学习框架，利用生成模型和进化算法学习任务特定的图像增强策略，通过分层组合增强操作实现结构化自适应变换。


<details>
  <summary>Details</summary>
Motivation: 传统数据增强方法（如裁剪、旋转）虽然能减少过拟合，但多样性有限。生成模型（如条件扩散、few-shot NeRFs）能合成更多样、更真实的数据，但若与任务不匹配可能损害性能。需要自动化学习任务特定的最优增强策略。

Method: 提出EvoAug自动化增强学习流程：1）利用生成模型合成多样化数据；2）采用高效进化算法学习最优任务特定增强；3）引入随机增强树，分层组合增强操作实现结构化自适应变换。

Result: 在细粒度分类和少样本学习任务中表现出色。即使在低数据设置下，也能发现与领域知识一致的增强策略。验证了学习生成增强的潜力。

Conclusion: EvoAug展示了学习生成增强方法的潜力，为鲁棒模型训练开辟了新可能性。自动化学习任务特定增强策略能有效提升模型性能，特别是在数据有限的情况下。

Abstract: Data augmentation has long been a cornerstone for reducing overfitting in vision models, with methods like AutoAugment automating the design of task-specific augmentations. Recent advances in generative models, such as conditional diffusion and few-shot NeRFs, offer a new paradigm for data augmentation by synthesizing data with significantly greater diversity and realism. However, unlike traditional augmentations like cropping or rotation, these methods introduce substantial changes that enhance robustness but also risk degrading performance if the augmentations are poorly matched to the task. In this work, we present EvoAug, an automated augmentation learning pipeline, which leverages these generative models alongside an efficient evolutionary algorithm to learn optimal task-specific augmentations. Our pipeline introduces a novel approach to image augmentation that learns stochastic augmentation trees that hierarchically compose augmentations, enabling more structured and adaptive transformations. We demonstrate strong performance across fine-grained classification and few-shot learning tasks. Notably, our pipeline discovers augmentations that align with domain knowledge, even in low-data settings. These results highlight the potential of learned generative augmentations, unlocking new possibilities for robust model training.

</details>


### [28] [Flexible Geometric Guidance for Probabilistic Human Pose Estimation with Diffusion Models](https://arxiv.org/abs/2602.03126)
*Francis Snelgar,Ming Xu,Stephen Gould,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: 该论文提出了一种基于扩散模型的3D人体姿态估计框架，可以从2D图像中采样生成多个合理的3D姿态，解决了深度模糊和遮挡问题，无需成对的2D-3D训练数据。


<details>
  <summary>Details</summary>
Motivation: 从2D图像估计3D人体姿态存在深度模糊和遮挡问题，导致任务不确定——可能存在多个甚至无限个与图像一致的合理姿态。现有方法通常假设确定性映射并估计单一姿态，且基于机器学习的方法需要大量成对的2D-3D训练数据，泛化能力有限。

Method: 提出基于扩散模型的框架，使用条件生成引导方法：首先在仅使用3D数据训练的无条件扩散模型上进行采样，然后利用2D关键点检测器热图的梯度来引导采样，生成与2D图像一致的合理3D姿态分布。

Result: 在Human 3.6M数据集上使用最佳m个假设评估，在无需成对2D-3D训练数据的方法中达到最先进性能。在MPI-INF-3DHP和3DPW数据集上展示了良好的泛化能力。框架还支持姿态生成和姿态补全等新任务。

Conclusion: 扩散模型框架能够从概率分布中采样生成多个合理的3D姿态，解决了姿态估计的不确定性问题，无需成对训练数据，具有良好的泛化能力和任务灵活性。

Abstract: 3D human pose estimation from 2D images is a challenging problem due to depth ambiguity and occlusion. Because of these challenges the task is underdetermined, where there exists multiple -- possibly infinite -- poses that are plausible given the image. Despite this, many prior works assume the existence of a deterministic mapping and estimate a single pose given an image. Furthermore, methods based on machine learning require a large amount of paired 2D-3D data to train and suffer from generalization issues to unseen scenarios. To address both of these issues, we propose a framework for pose estimation using diffusion models, which enables sampling from a probability distribution over plausible poses which are consistent with a 2D image. Our approach falls under the guidance framework for conditional generation, and guides samples from an unconditional diffusion model, trained only on 3D data, using the gradients of the heatmaps from a 2D keypoint detector. We evaluate our method on the Human 3.6M dataset under best-of-$m$ multiple hypothesis evaluation, showing state-of-the-art performance among methods which do not require paired 2D-3D data for training. We additionally evaluate the generalization ability using the MPI-INF-3DHP and 3DPW datasets and demonstrate competitive performance. Finally, we demonstrate the flexibility of our framework by using it for novel tasks including pose generation and pose completion, without the need to train bespoke conditional models. We make code available at https://github.com/fsnelgar/diffusion_pose .

</details>


### [29] [SwiftVLM: Efficient Vision-Language Model Inference via Cross-Layer Token Bypass](https://arxiv.org/abs/2602.03134)
*Chen Qian,Xinran Yu,Danyang Li,Guoxuan Chi,Zheng Yang,Qiang Ma,Xin Miao*

Main category: cs.CV

TL;DR: SwiftVLM是一种新的视觉语言模型剪枝方法，通过"旁路"机制保留未选中的视觉token供后续层重新评估，避免了早期剪枝造成的关键信息丢失，在保持效率的同时显著提升了细粒度视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉token剪枝方法在粗粒度推理任务上有效，但在需要细粒度视觉细节的任务上性能显著下降。研究发现不同层间视觉token重要性存在显著差异，浅层被认为不重要的token可能在后续层变得高度相关，早期剪枝决策会导致不可逆的关键信息丢失。

Method: 提出新的剪枝范式"旁路"，保留未选中的视觉token并转发到后续剪枝阶段重新评估。基于此提出SwiftVLM方法：1)在具有强视觉token选择能力的模型特定层进行剪枝；2)允许跨层独立剪枝决策；3)无需训练。

Result: 在多个视觉语言模型和基准测试上的实验表明，SwiftVLM始终优于现有剪枝策略，实现了更优的准确率-效率权衡，并展现出更可靠的视觉token选择行为。

Conclusion: SwiftVLM通过旁路机制解决了早期剪枝导致的关键信息丢失问题，为视觉语言模型提供了一种简单、无需训练的高效剪枝方法，在保持计算效率的同时显著提升了细粒度视觉任务的性能。

Abstract: Visual token pruning is a promising approach for reducing the computational cost of vision-language models (VLMs), and existing methods often rely on early pruning decisions to improve efficiency. While effective on coarse-grained reasoning tasks, they suffer from significant performance degradation on tasks requiring fine-grained visual details. Through layer-wise analysis, we reveal substantial discrepancies in visual token importance across layers, showing that tokens deemed unimportant at shallow layers can later become highly relevant for text-conditioned reasoning. To avoid irreversible critical information loss caused by premature pruning, we introduce a new pruning paradigm, termed bypass, which preserves unselected visual tokens and forwards them to subsequent pruning stages for re-evaluation. Building on this paradigm, we propose SwiftVLM, a simple and training-free method that performs pruning at model-specific layers with strong visual token selection capability, while enabling independent pruning decisions across layers. Experiments across multiple VLMs and benchmarks demonstrate that SwiftVLM consistently outperforms existing pruning strategies, achieving superior accuracy-efficiency trade-offs and more faithful visual token selection behavior.

</details>


### [30] [Fully Kolmogorov-Arnold Deep Model in Medical Image Segmentation](https://arxiv.org/abs/2602.03156)
*Xingyu Qiu,Xinghua Ma,Dong Liang,Gongning Luo,Wei Wang,Kuanquan Wang,Shuo Li*

Main category: cs.CV

TL;DR: 该研究提出了首个完全基于Kolmogorov-Arnold（KA）表示的深度学习模型，通过Share-activation KAN（SaKAN）和Grad-Free Spline技术解决了深度KAN训练困难和内存消耗大的问题，在医学图像分割任务中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 深度堆叠的KANs由于训练困难和高内存需求而难以实现，现有研究只能使用少量KAN层，限制了KANs的全面探索。本研究旨在克服这些限制，开发完全基于KA表示的深度模型。

Method: 1. 提出Share-activation KAN（SaKAN），基于Sprecher变体的Kolmogorov-Arnold表示定理，简化参数化并增加训练样本密度以降低训练难度；2. 提出Grad-Free Spline技术，消除样条梯度计算，显著减少内存使用和计算开销；3. 基于这两项创新构建ALL U-KAN模型，用KA和KAonv层完全替代传统的FC和Conv层。

Result: 在三个医学图像分割任务上的评估表明，完全KA架构相比部分KA架构和传统架构具有更高的分割精度。与直接深度堆叠KAN相比，ALL U-KAN参数数量减少10倍，内存消耗降低20倍以上。

Conclusion: 本研究成功实现了首个完全基于KA表示的深度模型，证明了KA层可以完全替代传统深度学习架构，并展现出优越的学习能力，为深度KAN架构的探索开辟了新方向。

Abstract: Deeply stacked KANs are practically impossible due to high training difficulties and substantial memory requirements. Consequently, existing studies can only incorporate few KAN layers, hindering the comprehensive exploration of KANs. This study overcomes these limitations and introduces the first fully KA-based deep model, demonstrating that KA-based layers can entirely replace traditional architectures in deep learning and achieve superior learning capacity. Specifically, (1) the proposed Share-activation KAN (SaKAN) reformulates Sprecher's variant of Kolmogorov-Arnold representation theorem, which achieves better optimization due to its simplified parameterization and denser training samples, to ease training difficulty, (2) this paper indicates that spline gradients contribute negligibly to training while consuming huge GPU memory, thus proposes the Grad-Free Spline to significantly reduce memory usage and computational overhead. (3) Building on these two innovations, our ALL U-KAN is the first representative implementation of fully KA-based deep model, where the proposed KA and KAonv layers completely replace FC and Conv layers. Extensive evaluations on three medical image segmentation tasks confirm the superiority of the full KA-based architecture compared to partial KA-based and traditional architectures, achieving all higher segmentation accuracy. Compared to directly deeply stacked KAN, ALL U-KAN achieves 10 times reduction in parameter count and reduces memory consumption by more than 20 times, unlocking the new explorations into deep KAN architectures.

</details>


### [31] [Human-in-the-loop Adaptation in Group Activity Feature Learning for Team Sports Video Retrieval](https://arxiv.org/abs/2602.03157)
*Chihiro Nakatani,Hiroaki Kawashima,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出了一种无需群体活动标注的人类在环自适应群体活动特征学习方法，通过交互式微调提升群体活动视频检索性能。


<details>
  <summary>Details</summary>
Motivation: 传统群体活动识别方法需要大量标注数据，且通常局限于预定义的活动类别。本文旨在开发一种无需群体活动标注的自适应检索系统，通过人类在环交互提升检索性能。

Method: 方法包含两个阶段：1）自监督预训练群体活动特征空间；2）交互式微调过程，通过数据高效的视频选择策略让用户标注正负样本，使用对比学习更新特征空间。

Result: 在两个团队运动数据集上的实验表明，该方法显著提升了检索性能。消融研究证实了人类在环自适应中多个组件对性能改进的贡献。

Conclusion: 本文提出的无需群体活动标注的人类在环自适应方法有效提升了群体活动视频检索性能，为群体活动分析提供了新的解决方案。

Abstract: This paper proposes human-in-the-loop adaptation for Group Activity Feature Learning (GAFL) without group activity annotations. This human-in-the-loop adaptation is employed in a group-activity video retrieval framework to improve its retrieval performance. Our method initially pre-trains the GAF space based on the similarity of group activities in a self-supervised manner, unlike prior work that classifies videos into pre-defined group activity classes in a supervised learning manner. Our interactive fine-tuning process updates the GAF space to allow a user to better retrieve videos similar to query videos given by the user. In this fine-tuning, our proposed data-efficient video selection process provides several videos, which are selected from a video database, to the user in order to manually label these videos as positive or negative. These labeled videos are used to update (i.e., fine-tune) the GAF space, so that the positive and negative videos move closer to and farther away from the query videos through contrastive learning. Our comprehensive experimental results on two team sports datasets validate that our method significantly improves the retrieval performance. Ablation studies also demonstrate that several components in our human-in-the-loop adaptation contribute to the improvement of the retrieval performance. Code: https://github.com/chihina/GAFL-FINE-CVIU.

</details>


### [32] [LSGQuant: Layer-Sensitivity Guided Quantization for One-Step Diffusion Real-World Video Super-Resolution](https://arxiv.org/abs/2602.03182)
*Tianxing Wu,Zheng Chen,Cirou Xu,Bowen Chai,Yong Guo,Yutong Liu,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: LSGQuant：一种用于一步扩散视频超分辨率的层敏感度引导量化方法，通过动态范围自适应量化器、方差导向层训练策略和量化感知优化，在保持性能的同时显著压缩模型


<details>
  <summary>Details</summary>
Motivation: 一步扩散模型在真实世界视频超分辨率中展现出良好能力和快速推理，但扩散变换器的大模型尺寸和高计算成本限制了实际应用。虽然低位量化是常见的模型压缩方法，但输入潜变量的高动态范围和不同层行为的多样性给量化模型的有效性带来了挑战

Method: 提出LSGQuant方法，包含三个核心组件：1）动态范围自适应量化器（DRAQ）来适应视频令牌激活；2）通过分析校准中的层间统计来估计层敏感度，并实施方差导向层训练策略（VOLTS）；3）引入量化感知优化（QAO）来联合优化量化分支和保留的高精度分支

Result: 大量实验表明，该方法在保持与原始全精度模型相近性能的同时，显著超越了现有的量化技术

Conclusion: LSGQuant为一步扩散视频超分辨率提供了一种有效的量化压缩方案，解决了高动态范围输入和层行为多样性带来的挑战，在保持性能的同时实现了显著的模型压缩

Abstract: One-Step Diffusion Models have demonstrated promising capability and fast inference in video super-resolution (VSR) for real-world. Nevertheless, the substantial model size and high computational cost of Diffusion Transformers (DiTs) limit downstream applications. While low-bit quantization is a common approach for model compression, the effectiveness of quantized models is challenged by the high dynamic range of input latent and diverse layer behaviors. To deal with these challenges, we introduce LSGQuant, a layer-sensitivity guided quantizing approach for one-step diffusion-based real-world VSR. Our method incorporates a Dynamic Range Adaptive Quantizer (DRAQ) to fit video token activations. Furthermore, we estimate layer sensitivity and implement a Variance-Oriented Layer Training Strategy (VOLTS) by analyzing layer-wise statistics in calibration. We also introduce Quantization-Aware Optimization (QAO) to jointly refine the quantized branch and a retained high-precision branch. Extensive experiments demonstrate that our method has nearly performance to origin model with full-precision and significantly exceeds existing quantization techniques. Code is available at: https://github.com/zhengchen1999/LSGQuant.

</details>


### [33] [From Single Scan to Sequential Consistency: A New Paradigm for LIDAR Relocalization](https://arxiv.org/abs/2602.03198)
*Minghang Zhu,Zhijing Wang,Yuxin Guo,Wen Li,Sheng Ao,Cheng Wang*

Main category: cs.CV

TL;DR: TempLoc是一个新的LiDAR重定位框架，通过建模序列一致性增强定位鲁棒性，包含全局坐标估计、先验坐标生成和不确定性引导坐标融合三个模块，在NCLT和Oxford Robot-Car基准上大幅超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于回归的LiDAR重定位方法在动态或模糊场景中容易出错，因为它们要么仅依赖单帧推理，要么忽略了扫描间的时空一致性。需要一种能够有效建模序列一致性的方法来提高定位的鲁棒性。

Method: 提出TempLoc框架，包含三个模块：1) 全局坐标估计模块预测每帧LiDAR扫描的点级全局坐标和不确定性；2) 先验坐标生成模块通过注意力机制估计帧间点对应关系；3) 不确定性引导坐标融合模块以端到端方式整合两种预测，生成更一致准确的6自由度全局位姿。

Result: 在NCLT和Oxford Robot-Car基准测试中，TempLoc大幅超越了现有最先进方法，证明了时序感知对应关系建模在LiDAR重定位中的有效性。

Conclusion: TempLoc通过有效建模序列一致性，显著提高了LiDAR重定位的鲁棒性和准确性，特别是在动态或模糊场景中。该方法展示了时序感知对应关系建模的重要性。

Abstract: LiDAR relocalization aims to estimate the global 6-DoF pose of a sensor in the environment. However, existing regression-based approaches are prone to dynamic or ambiguous scenarios, as they either solely rely on single-frame inference or neglect the spatio-temporal consistency across scans. In this paper, we propose TempLoc, a new LiDAR relocalization framework that enhances the robustness of localization by effectively modeling sequential consistency. Specifically, a Global Coordinate Estimation module is first introduced to predict point-wise global coordinates and associated uncertainties for each LiDAR scan. A Prior Coordinate Generation module is then presented to estimate inter-frame point correspondences by the attention mechanism. Lastly, an Uncertainty-Guided Coordinate Fusion module is deployed to integrate both predictions of point correspondence in an end-to-end fashion, yielding a more temporally consistent and accurate global 6-DoF pose. Experimental results on the NCLT and Oxford Robot-Car benchmarks show that our TempLoc outperforms stateof-the-art methods by a large margin, demonstrating the effectiveness of temporal-aware correspondence modeling in LiDAR relocalization. Our code will be released soon.

</details>


### [34] [Hand3R: Online 4D Hand-Scene Reconstruction in the Wild](https://arxiv.org/abs/2602.03200)
*Wendi Hu,Haonan Zhou,Wenhao Hu,Gaoang Wang*

Main category: cs.CV

TL;DR: Hand3R是首个从单目视频进行联合4D手部-场景重建的在线框架，通过场景感知视觉提示机制将预训练手部专家与4D场景基础模型结合，实现准确手部网格和密集度量尺度场景几何的同时重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多在局部坐标系中恢复孤立的手部，忽略了周围的3D环境，而理解物理交互需要同时重建动态手部和密集场景上下文。

Method: Hand3R通过场景感知视觉提示机制，将预训练的手部专家与4D场景基础模型协同工作，将高保真手部先验注入到持久场景记忆中，实现单次前向传播中的同时重建。

Result: 实验表明Hand3R无需依赖离线优化，在局部手部重建和全局定位方面都表现出有竞争力的性能。

Conclusion: Hand3R是首个能够从单目视频在线联合重建4D手部-场景的框架，为理解物理交互提供了重要工具。

Abstract: For Embodied AI, jointly reconstructing dynamic hands and the dense scene context is crucial for understanding physical interaction. However, most existing methods recover isolated hands in local coordinates, overlooking the surrounding 3D environment. To address this, we present Hand3R, the first online framework for joint 4D hand-scene reconstruction from monocular video. Hand3R synergizes a pre-trained hand expert with a 4D scene foundation model via a scene-aware visual prompting mechanism. By injecting high-fidelity hand priors into a persistent scene memory, our approach enables simultaneous reconstruction of accurate hand meshes and dense metric-scale scene geometry in a single forward pass. Experiments demonstrate that Hand3R bypasses the reliance on offline optimization and delivers competitive performance in both local hand reconstruction and global positioning.

</details>


### [35] [VIRAL: Visual In-Context Reasoning via Analogy in Diffusion Transformers](https://arxiv.org/abs/2602.03210)
*Zhiwen Li,Zhongjie Duan,Jinyan Ye,Cen Chen,Daoyuan Chen,Yaliang Li,Yingda Chen*

Main category: cs.CV

TL;DR: VIRAL框架通过视觉类比将上下文学习重新定义为条件生成，利用预训练图像编辑模型进行视觉推理，在多种视觉任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉中的上下文学习（ICL）由于任务异质性而难以实现，需要一种统一的视觉ICL范式来处理多样化的视觉任务。

Method: 提出VIRAL框架，将ICL重新定义为通过视觉类比的条件生成（x_s : x_t :: x_q : y_q），使用角色感知多图像条件化调整冻结的扩散变换器（DiT），并引入专家混合LoRA来减轻跨任务梯度干扰。同时构建了一个大规模视觉上下文数据集。

Result: 实验表明VIRAL在多种视觉任务上优于现有方法，验证了统一的视觉ICL范式可以处理大多数视觉任务，包括开放域编辑。

Conclusion: VIRAL框架成功地将上下文学习范式扩展到计算机视觉领域，通过视觉类比和条件生成实现了跨多种视觉任务的统一处理能力。

Abstract: Replicating In-Context Learning (ICL) in computer vision remains challenging due to task heterogeneity. We propose \textbf{VIRAL}, a framework that elicits visual reasoning from a pre-trained image editing model by formulating ICL as conditional generation via visual analogy ($x_s : x_t :: x_q : y_q$). We adapt a frozen Diffusion Transformer (DiT) using role-aware multi-image conditioning and introduce a Mixture-of-Experts LoRA to mitigate gradient interference across diverse tasks. Additionally, to bridge the gaps in current visual context datasets, we curate a large-scale dataset spanning perception, restoration, and editing. Experiments demonstrate that VIRAL outperforms existing methods, validating that a unified V-ICL paradigm can handle the majority of visual tasks, including open-domain editing. Our code is available at https://anonymous.4open.science/r/VIRAL-744A

</details>


### [36] [ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask](https://arxiv.org/abs/2602.03213)
*Zhuoran Yang,Yanyong Zhang*

Main category: cs.CV

TL;DR: ConsisDrive是一个保持身份一致性的驾驶世界模型，通过实例掩码注意力和实例掩码损失来解决自动驾驶视频生成中的身份漂移问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要大规模高质量多视角驾驶视频数据，现有世界模型虽然能生成逼真驾驶数据，但存在身份漂移问题——同一物体在不同帧中外观或类别发生变化，缺乏实例级时间约束。

Method: 提出两个关键组件：1) 实例掩码注意力：在注意力块中应用实例身份掩码和轨迹掩码，确保视觉标记仅与对应实例特征在时空维度交互；2) 实例掩码损失：通过概率性实例掩码自适应强调前景区域，减少背景噪声同时保持场景保真度。

Result: 在nuScenes数据集上实现了最先进的驾驶视频生成质量，并在下游自动驾驶任务中表现出显著改进。

Conclusion: ConsisDrive通过实例级时间一致性约束有效解决了驾驶世界模型中的身份漂移问题，提升了生成数据的质量和实用性。

Abstract: Autonomous driving relies on robust models trained on large-scale, high-quality multi-view driving videos. Although world models provide a cost-effective solution for generating realistic driving data, they often suffer from identity drift, where the same object changes its appearance or category across frames due to the absence of instance-level temporal constraints. We introduce ConsisDrive, an identity-preserving driving world model designed to enforce temporal consistency at the instance level. Our framework incorporates two key components: (1) Instance-Masked Attention, which applies instance identity masks and trajectory masks within attention blocks to ensure that visual tokens interact only with their corresponding instance features across spatial and temporal dimensions, thereby preserving object identity consistency; and (2) Instance-Masked Loss, which adaptively emphasizes foreground regions with probabilistic instance masking, reducing background noise while maintaining overall scene fidelity. By integrating these mechanisms, ConsisDrive achieves state-of-the-art driving video generation quality and demonstrates significant improvements in downstream autonomous driving tasks on the nuScenes dataset. Our project page is https://shanpoyang654.github.io/ConsisDrive/page.html.

</details>


### [37] [FARTrack: Fast Autoregressive Visual Tracking with High Performance](https://arxiv.org/abs/2602.03214)
*Guijie Wang,Tong Lin,Yifan Bai,Anjia Cao,Shiyi Liang,Wangbo Zhao,Xing Wei*

Main category: cs.CV

TL;DR: FARTrack是一个快速自回归跟踪框架，通过任务特定自蒸馏和帧间自回归稀疏化技术，在保持高性能的同时实现高效执行，在GPU上达到343 FPS，CPU上121 FPS。


<details>
  <summary>Details</summary>
Motivation: 视觉跟踪领域存在高性能跟踪器处理速度慢的问题，难以在资源受限设备上部署。需要一种既能保持高性能又能实现高效执行的跟踪框架。

Method: 提出FARTrack框架，包含两个核心技术：1) 任务特定自蒸馏：通过逐层蒸馏任务特定token实现模型压缩，避免手动分配师生层对；2) 帧间自回归稀疏化：顺序压缩多个模板，学习时间全局最优稀疏化策略，避免额外运行时开销。

Result: FARTrack在GOT-10k上达到70.6%的AO（平均重叠率），实现实时跟踪。最快模型在GPU上达到343 FPS，CPU上达到121 FPS，表现出卓越的速度和竞争力性能。

Conclusion: FARTrack通过自回归框架结合任务特定自蒸馏和帧间自回归稀疏化，成功解决了高性能跟踪器速度慢的问题，在多种设备上实现了高效执行，为资源受限设备的视觉跟踪部署提供了有效解决方案。

Abstract: Inference speed and tracking performance are two critical evaluation metrics in the field of visual tracking. However, high-performance trackers often suffer from slow processing speeds, making them impractical for deployment on resource-constrained devices. To alleviate this issue, we propose FARTrack, a Fast Auto-Regressive Tracking framework. Since autoregression emphasizes the temporal nature of the trajectory sequence, it can maintain high performance while achieving efficient execution across various devices. FARTrack introduces Task-Specific Self-Distillation and Inter-frame Autoregressive Sparsification, designed from the perspectives of shallow-yet-accurate distillation and redundant-to-essential token optimization, respectively. Task-Specific Self-Distillation achieves model compression by distilling task-specific tokens layer by layer, enhancing the model's inference speed while avoiding suboptimal manual teacher-student layer pairs assignments. Meanwhile, Inter-frame Autoregressive Sparsification sequentially condenses multiple templates, avoiding additional runtime overhead while learning a temporally-global optimal sparsification strategy. FARTrack demonstrates outstanding speed and competitive performance. It delivers an AO of 70.6% on GOT-10k in real-time. Beyond, our fastest model achieves a speed of 343 FPS on the GPU and 121 FPS on the CPU.

</details>


### [38] [Spiral RoPE: Rotate Your Rotary Positional Embeddings in the 2D Plane](https://arxiv.org/abs/2602.03227)
*Haoyu Liu,Sucheng Ren,Tingyu Zhu,Peng Wang,Cihang Xie,Alan Yuille,Zeyu Zheng,Feng Wang*

Main category: cs.CV

TL;DR: Spiral RoPE是一种改进的2D旋转位置编码方法，通过将嵌入通道分组并分配到多个均匀分布的方向，克服了标准轴向RoPE只能编码轴对齐方向的位置关系的限制。


<details>
  <summary>Details</summary>
Motivation: 标准轴向2D RoPE将二维空间位置分解为水平和垂直分量，这限制了位置编码只能处理轴对齐方向的关系。然而，自然图像中存在许多倾斜的空间关系，这种方向约束成为了一个根本性限制。

Method: 提出Spiral RoPE方法，将嵌入通道划分为多个组，每个组与均匀分布的方向相关联。每个组根据补丁位置在其对应方向上的投影进行旋转，从而实现在水平和垂直轴之外的多方向位置编码。

Result: 在包括分类、分割和生成在内的广泛视觉任务中，Spiral RoPE都一致地提高了性能。注意力图的定性分析显示，Spiral RoPE在语义相关对象上表现出更集中的激活，并能更好地尊重局部对象边界。

Conclusion: Spiral RoPE通过实现多方向位置编码，克服了标准轴向2D RoPE的方向限制，在视觉Transformer中实现了更好的空间关系建模，强调了多方向位置编码在视觉Transformer中的重要性。

Abstract: Rotary Position Embedding (RoPE) is the de facto positional encoding in large language models due to its ability to encode relative positions and support length extrapolation. When adapted to vision transformers, the standard axial formulation decomposes two-dimensional spatial positions into horizontal and vertical components, implicitly restricting positional encoding to axis-aligned directions. We identify this directional constraint as a fundamental limitation of the standard axial 2D RoPE, which hinders the modeling of oblique spatial relationships that naturally exist in natural images. To overcome this limitation, we propose Spiral RoPE, a simple yet effective extension that enables multi-directional positional encoding by partitioning embedding channels into multiple groups associated with uniformly distributed directions. Each group is rotated according to the projection of the patch position onto its corresponding direction, allowing spatial relationships to be encoded beyond the horizontal and vertical axes. Across a wide range of vision tasks including classification, segmentation, and generation, Spiral RoPE consistently improves performance. Qualitative analysis of attention maps further show that Spiral RoPE exhibits more concentrated activations on semantically relevant objects and better respects local object boundaries, highlighting the importance of multi-directional positional encoding in vision transformers.

</details>


### [39] [EventFlash: Towards Efficient MLLMs for Event-Based Vision](https://arxiv.org/abs/2602.03230)
*Shaoyu Liu,Jianing Li,Guanghui Zhao,Yunjian Zhang,Wen Jiang,Ming Li,Xiangyang Ji*

Main category: cs.CV

TL;DR: EventFlash：一种高效的事件型多模态大语言模型，通过时空令牌稀疏化减少数据冗余并加速推理，相比基线实现12.4倍吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于事件的MLLMs通常采用密集图像式处理范式，忽视了事件流的时空稀疏性，导致计算成本高昂。需要探索更高效的处理方法来利用事件数据的稀疏特性。

Method: 1) 构建EventMind大规模多样化数据集（50万+指令集）；2) 自适应时间窗口聚合模块进行高效时间采样；3) 稀疏密度引导注意力模块提升空间令牌效率；4) 采用课程训练策略。

Result: EventFlash相比基线（EventFlash-Zero）实现12.4倍吞吐量提升，同时保持可比性能。支持长达1000个bin的长范围事件流处理，显著优于EventGPT的5-bin限制。

Conclusion: EventFlash通过探索时空令牌稀疏化，有效减少了事件流的数据冗余并加速了推理，为基于事件的视觉任务提供了一个高效的基础模型。

Abstract: Event-based multimodal large language models (MLLMs) enable robust perception in high-speed and low-light scenarios, addressing key limitations of frame-based MLLMs. However, current event-based MLLMs often rely on dense image-like processing paradigms, overlooking the spatiotemporal sparsity of event streams and resulting in high computational cost. In this paper, we propose EventFlash, a novel and efficient MLLM to explore spatiotemporal token sparsification for reducing data redundancy and accelerating inference. Technically, we build EventMind, a large-scale and scene-diverse dataset with over 500k instruction sets, providing both short and long event stream sequences to support our curriculum training strategy. We then present an adaptive temporal window aggregation module for efficient temporal sampling, which adaptively compresses temporal tokens while retaining key temporal cues. Finally, a sparse density-guided attention module is designed to improve spatial token efficiency by selecting informative regions and suppressing empty or sparse areas. Experimental results show that EventFlash achieves a $12.4\times$ throughput improvement over the baseline (EventFlash-Zero) while maintaining comparable performance. It supports long-range event stream processing with up to 1,000 bins, significantly outperforming the 5-bin limit of EventGPT. We believe EventFlash serves as an efficient foundation model for event-based vision.

</details>


### [40] [InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation](https://arxiv.org/abs/2602.03242)
*Zhuoran Yang,Xi Guo,Chenjing Ding,Chiyu Wang,Wei Wu,Yanyong Zhang*

Main category: cs.CV

TL;DR: InstaDrive框架通过实例流引导器和空间几何对齐器增强驾驶视频生成，解决世界模型中实例级时间一致性和空间几何保真度问题，提升自动驾驶任务性能


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要高质量的大规模多视角驾驶视频，但现有世界模型在生成驾驶视频时存在实例级时间一致性不足和空间几何保真度差的问题

Method: 提出InstaDrive框架，包含两个核心组件：1) 实例流引导器 - 提取并跨帧传播实例特征以强制时间一致性；2) 空间几何对齐器 - 改进空间推理，确保精确实例定位并显式建模遮挡层次

Result: 在nuScenes数据集上实现了最先进的视频生成质量，并提升了下游自动驾驶任务性能；同时利用CARLA自动驾驶系统程序化模拟安全关键场景进行严格评估

Conclusion: InstaDrive通过实例感知机制有效解决了驾驶视频生成中的时间一致性和空间几何保真度问题，为自动驾驶系统提供了更真实、更可靠的训练数据和评估环境

Abstract: Autonomous driving relies on robust models trained on high-quality, large-scale multi-view driving videos. While world models offer a cost-effective solution for generating realistic driving videos, they struggle to maintain instance-level temporal consistency and spatial geometric fidelity. To address these challenges, we propose InstaDrive, a novel framework that enhances driving video realism through two key advancements: (1) Instance Flow Guider, which extracts and propagates instance features across frames to enforce temporal consistency, preserving instance identity over time. (2) Spatial Geometric Aligner, which improves spatial reasoning, ensures precise instance positioning, and explicitly models occlusion hierarchies. By incorporating these instance-aware mechanisms, InstaDrive achieves state-of-the-art video generation quality and enhances downstream autonomous driving tasks on the nuScenes dataset. Additionally, we utilize CARLA's autopilot to procedurally and stochastically simulate rare but safety-critical driving scenarios across diverse maps and regions, enabling rigorous safety evaluation for autonomous systems. Our project page is https://shanpoyang654.github.io/InstaDrive/page.html.

</details>


### [41] [Global Geometry Is Not Enough for Vision Representations](https://arxiv.org/abs/2602.03282)
*Jiwan Chung,Seon Joo Kim*

Main category: cs.CV

TL;DR: 研究发现全局几何嵌入无法有效预测组合绑定能力，而功能敏感性（输入-输出雅可比矩阵）能可靠追踪这一能力，表明全局几何仅捕捉了表征能力的部分视图。


<details>
  <summary>Details</summary>
Motivation: 当前表示学习普遍假设全局分布良好的嵌入支持鲁棒和可泛化的表示，但全局几何主要编码元素存在性，对元素组合方式不敏感。研究旨在探索几何指标在预测组合绑定能力方面的局限性。

Method: 通过测试21个视觉编码器中几何指标预测组合绑定的能力，比较标准几何统计量与功能敏感性（输入-输出雅可比矩阵）的表现，并提供理论分析解释这种差异源于目标函数设计。

Result: 标准几何统计量与组合绑定能力几乎零相关，而功能敏感性（雅可比矩阵）能可靠追踪这一能力。理论分析表明现有损失函数明确约束嵌入几何但未约束局部输入-输出映射。

Conclusion: 全局嵌入几何仅捕捉了表征能力的部分视图，功能敏感性是建模复合结构的关键补充维度，为表示学习提供了新的评估和设计方向。

Abstract: A common assumption in representation learning is that globally well-distributed embeddings support robust and generalizable representations. This focus has shaped both training objectives and evaluation protocols, implicitly treating global geometry as a proxy for representational competence. While global geometry effectively encodes which elements are present, it is often insensitive to how they are composed. We investigate this limitation by testing the ability of geometric metrics to predict compositional binding across 21 vision encoders. We find that standard geometry-based statistics exhibit near-zero correlation with compositional binding. In contrast, functional sensitivity, as measured by the input-output Jacobian, reliably tracks this capability. We further provide an analytic account showing that this disparity arises from objective design, as existing losses explicitly constrain embedding geometry but leave the local input-output mapping unconstrained. These results suggest that global embedding geometry captures only a partial view of representational competence and establish functional sensitivity as a critical complementary axis for modeling composite structure.

</details>


### [42] [A3-TTA: Adaptive Anchor Alignment Test-Time Adaptation for Image Segmentation](https://arxiv.org/abs/2602.03292)
*Jianghao Wu,Xiangde Luo,Yubo Zhou,Lianming Wu,Guotai Wang,Shaoting Zhang*

Main category: cs.CV

TL;DR: A3-TTA是一种基于锚点引导监督的测试时自适应框架，通过识别置信度高的目标域图像作为锚点来生成可靠的伪标签，解决了传统伪标签方法因扰动集成启发式导致的训练信号不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于伪标签的测试时自适应方法通常依赖扰动集成启发式（如dropout采样、测试时增强、高斯噪声），这些方法缺乏分布基础，产生不稳定的训练信号，容易导致错误累积和灾难性遗忘。

Method: 提出A3-TTA框架：1）使用类紧凑密度度量识别置信度高的目标域图像作为锚点；2）通过语义一致性和边界感知熵最小化正则化伪标签生成；3）引入自适应指数移动平均策略减轻标签噪声并稳定模型更新。

Result: 在医学图像（心脏结构和前列腺分割）和自然图像上评估，A3-TTA相比源模型将平均Dice分数提高了10.40到17.68个百分点，优于多种最先进的TTA方法，并在连续TTA中表现出强大的抗遗忘能力。

Conclusion: A3-TTA通过锚点引导监督构建可靠的伪标签，有效解决了传统TTA方法中的训练信号不稳定问题，在多种分割任务和架构中表现出优越性能，特别是在连续域适应中保持高精度。

Abstract: Test-Time Adaptation (TTA) offers a practical solution for deploying image segmentation models under domain shift without accessing source data or retraining. Among existing TTA strategies, pseudo-label-based methods have shown promising performance. However, they often rely on perturbation-ensemble heuristics (e.g., dropout sampling, test-time augmentation, Gaussian noise), which lack distributional grounding and yield unstable training signals. This can trigger error accumulation and catastrophic forgetting during adaptation. To address this, we propose \textbf{A3-TTA}, a TTA framework that constructs reliable pseudo-labels through anchor-guided supervision. Specifically, we identify well-predicted target domain images using a class compact density metric, under the assumption that confident predictions imply distributional proximity to the source domain. These anchors serve as stable references to guide pseudo-label generation, which is further regularized via semantic consistency and boundary-aware entropy minimization. Additionally, we introduce a self-adaptive exponential moving average strategy to mitigate label noise and stabilize model update during adaptation. Evaluated on both multi-domain medical images (heart structure and prostate segmentation) and natural images, A3-TTA significantly improves average Dice scores by 10.40 to 17.68 percentage points compared to the source model, outperforming several state-of-the-art TTA methods under different segmentation model architectures. A3-TTA also excels in continual TTA, maintaining high performance across sequential target domains with strong anti-forgetting ability. The code will be made publicly available at https://github.com/HiLab-git/A3-TTA.

</details>


### [43] [LEVIO: Lightweight Embedded Visual Inertial Odometry for Resource-Constrained Devices](https://arxiv.org/abs/2602.03294)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: LEVIO是一个针对超低功耗计算平台优化的视觉惯性里程计（VIO）系统，能够在资源受限的硬件上实现6自由度实时运动跟踪，功耗低于100mW，达到20FPS性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的VIO系统计算需求过高，无法在微无人机、智能眼镜等资源受限的硬件上运行，需要开发专门针对超低功耗平台的VIO解决方案。

Method: 采用硬件-软件协同优化方法，整合ORB特征跟踪和束调整等成熟VIO组件，重点设计计算高效架构，包括并行化和低内存使用，适用于嵌入式微控制器和低功耗SoC。

Result: 在并行处理的超低功耗RISC-V SoC上验证，实现20FPS性能，功耗低于100mW，在公开VIO数据集上基准测试，在效率和精度之间取得良好平衡。

Conclusion: LEVIO为移动机器人和增强现实应用提供了可行的超低功耗VIO解决方案，通过开源实现促进可重复性和采用。

Abstract: Accurate, infrastructure-less sensor systems for motion tracking are essential for mobile robotics and augmented reality (AR) applications. The most popular state-of-the-art visual-inertial odometry (VIO) systems, however, are too computationally demanding for resource-constrained hardware, such as micro-drones and smart glasses. This work presents LEVIO, a fully featured VIO pipeline optimized for ultra-low-power compute platforms, allowing six-degrees-of-freedom (DoF) real-time sensing. LEVIO incorporates established VIO components such as Oriented FAST and Rotated BRIEF (ORB) feature tracking and bundle adjustment, while emphasizing a computationally efficient architecture with parallelization and low memory usage to suit embedded microcontrollers and low-power systems-on-chip (SoCs). The paper proposes and details the algorithmic design choices and the hardware-software co-optimization approach, and presents real-time performance on resource-constrained hardware. LEVIO is validated on a parallel-processing ultra-low-power RISC-V SoC, achieving 20 FPS while consuming less than 100 mW, and benchmarked against public VIO datasets, offering a compelling balance between efficiency and accuracy. To facilitate reproducibility and adoption, the complete implementation is released as open-source.

</details>


### [44] [Full end-to-end diagnostic workflow automation of 3D OCT via foundation model-driven AI for retinal diseases](https://arxiv.org/abs/2602.03302)
*Jinze Zhang,Jian Zhong,Li Lin,Jiaxiong Li,Ke Ma,Naiyang Li,Meng Li,Yuan Pan,Zeyu Meng,Mengyun Zhou,Shang Huang,Shilong Yu,Zhengyu Duan,Sutong Li,Honghui Xia,Juping Liu,Dan Liang,Yantao Wei,Xiaoying Tang,Jin Yuan,Peng Xiao*

Main category: cs.CV

TL;DR: FOCUS是一个基于光学相干断层扫描（OCT）的端到端自动化视网膜疾病诊断系统，使用基础模型驱动框架，通过图像质量评估、异常检测和多疾病分类，实现从图像到诊断的完整流程自动化。


<details>
  <summary>Details</summary>
Motivation: 尽管OCT在视网膜疾病诊断中具有高分辨率和三维成像优势，但其在临床实践中的全自动化诊断仍受限于多阶段工作流程和传统的单切片单任务AI模型。需要开发端到端的自动化系统来提高诊断效率和可及性。

Method: FOCUS采用基础模型驱动框架，依次执行：1）使用EfficientNetV2-S进行图像质量评估；2）使用微调的视觉基础模型进行异常检测和多疾病分类；3）通过统一的适应性聚合方法将2D切片级预测智能整合为全面的3D患者级诊断。

Result: 在3,300名患者（40,672个切片）上训练和测试，并在四个不同层级中心的1,345名患者（18,498个切片）上进行外部验证。FOCUS在质量评估（99.01% F1）、异常检测（97.46% F1）和患者级诊断（94.39% F1）方面均取得高分。真实世界验证显示稳定性能（F1：90.22%-95.24%）。在人机对比中，FOCUS在异常检测（95.47% vs 90.91%）和多疾病诊断（93.49% vs 91.35%）方面与专家表现相当，且效率更高。

Conclusion: FOCUS实现了从图像到诊断的完整流程自动化，代表了向无人眼科发展的关键进展，为自主筛查提供了经过验证的蓝图，有望提高人群规模视网膜护理的可及性和效率。

Abstract: Optical coherence tomography (OCT) has revolutionized retinal disease diagnosis with its high-resolution and three-dimensional imaging nature, yet its full diagnostic automation in clinical practices remains constrained by multi-stage workflows and conventional single-slice single-task AI models. We present Full-process OCT-based Clinical Utility System (FOCUS), a foundation model-driven framework enabling end-to-end automation of 3D OCT retinal disease diagnosis. FOCUS sequentially performs image quality assessment with EfficientNetV2-S, followed by abnormality detection and multi-disease classification using a fine-tuned Vision Foundation Model. Crucially, FOCUS leverages a unified adaptive aggregation method to intelligently integrate 2D slices-level predictions into comprehensive 3D patient-level diagnosis. Trained and tested on 3,300 patients (40,672 slices), and externally validated on 1,345 patients (18,498 slices) across four different-tier centers and diverse OCT devices, FOCUS achieved high F1 scores for quality assessment (99.01%), abnormally detection (97.46%), and patient-level diagnosis (94.39%). Real-world validation across centers also showed stable performance (F1: 90.22%-95.24%). In human-machine comparisons, FOCUS matched expert performance in abnormality detection (F1: 95.47% vs 90.91%) and multi-disease diagnosis (F1: 93.49% vs 91.35%), while demonstrating better efficiency. FOCUS automates the image-to-diagnosis pipeline, representing a critical advance towards unmanned ophthalmology with a validated blueprint for autonomous screening to enhance population scale retinal care accessibility and efficiency.

</details>


### [45] [Invisible Clean-Label Backdoor Attacks for Generative Data Augmentation](https://arxiv.org/abs/2602.03316)
*Ting Xiang,Jinhui Zhao,Changjian Chen,Zhuo Tang*

Main category: cs.CV

TL;DR: 提出InvLBA方法，通过潜在空间扰动实现生成式数据增强中的不可见干净标签后门攻击，相比现有像素级攻击方法显著提升攻击成功率


<details>
  <summary>Details</summary>
Motivation: 生成式数据增强在数据稀缺时有效，但易受干净标签后门攻击。现有像素级攻击方法（如COMBAT）在生成图像上攻击成功率低，需要转向潜在特征层面的攻击方法

Method: 提出InvLBA方法，通过潜在空间扰动实现不可见干净标签后门攻击，理论证明其泛化性能，在多个数据集上进行实验验证

Result: 实验显示InvLBA平均提升攻击成功率46.43%，几乎不影响干净准确率，对现有防御方法具有高鲁棒性

Conclusion: 潜在特征层面的攻击比像素级攻击更有效，InvLBA在生成式数据增强中实现了高效、隐蔽的后门攻击

Abstract: With the rapid advancement of image generative models, generative data augmentation has become an effective way to enrich training images, especially when only small-scale datasets are available. At the same time, in practical applications, generative data augmentation can be vulnerable to clean-label backdoor attacks, which aim to bypass human inspection. However, based on theoretical analysis and preliminary experiments, we observe that directly applying existing pixel-level clean-label backdoor attack methods (e.g., COMBAT) to generated images results in low attack success rates. This motivates us to move beyond pixel-level triggers and focus instead on the latent feature level. To this end, we propose InvLBA, an invisible clean-label backdoor attack method for generative data augmentation by latent perturbation. We theoretically prove that the generalization of the clean accuracy and attack success rates of InvLBA can be guaranteed. Experiments on multiple datasets show that our method improves the attack success rate by 46.43% on average, with almost no reduction in clean accuracy and high robustness against SOTA defense methods.

</details>


### [46] [MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning](https://arxiv.org/abs/2602.03320)
*Shengyuan Liu,Liuxin Bao,Qi Yang,Wanting Geng,Boyun Zheng,Chenxin Li,Wenting Chen,Houwen Peng,Yixuan Yuan*

Main category: cs.CV

TL;DR: MedSAM-Agent是一个将医学图像分割重构为多步自主决策过程的框架，通过混合提示策略和两阶段训练管道，在6种医学模态和21个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于多模态大语言模型（MLLMs）的医学图像分割方法通常采用单轮、僵化的交互策略，缺乏过程级监督训练，无法充分利用交互工具的动态潜力，导致冗余操作。需要弥合这一差距。

Method: 1. 提出混合提示策略用于专家轨迹生成，使模型内化类人决策启发式和自适应细化策略；2. 开发两阶段训练管道，整合多轮端到端结果验证与临床保真度过程奖励设计，促进交互简洁性和决策效率。

Result: 在6种医学模态和21个数据集上的广泛实验表明，MedSAM-Agent实现了最先进的性能，有效统一了自主医学推理与稳健的迭代优化。

Conclusion: MedSAM-Agent成功将医学图像分割重构为多步自主决策过程，通过创新的训练策略实现了高效、自适应的交互分割，为通用医学图像分析框架提供了新思路。

Abstract: Medical image segmentation is evolving from task-specific models toward generalizable frameworks. Recent research leverages Multi-modal Large Language Models (MLLMs) as autonomous agents, employing reinforcement learning with verifiable reward (RLVR) to orchestrate specialized tools like the Segment Anything Model (SAM). However, these approaches often rely on single-turn, rigid interaction strategies and lack process-level supervision during training, which hinders their ability to fully exploit the dynamic potential of interactive tools and leads to redundant actions. To bridge this gap, we propose MedSAM-Agent, a framework that reformulates interactive segmentation as a multi-step autonomous decision-making process. First, we introduce a hybrid prompting strategy for expert-curated trajectory generation, enabling the model to internalize human-like decision heuristics and adaptive refinement strategies. Furthermore, we develop a two-stage training pipeline that integrates multi-turn, end-to-end outcome verification with a clinical-fidelity process reward design to promote interaction parsimony and decision efficiency. Extensive experiments across 6 medical modalities and 21 datasets demonstrate that MedSAM-Agent achieves state-of-the-art performance, effectively unifying autonomous medical reasoning with robust, iterative optimization. Code is available \href{https://github.com/CUHK-AIM-Group/MedSAM-Agent}{here}.

</details>


### [47] [PWAVEP: Purifying Imperceptible Adversarial Perturbations in 3D Point Clouds via Spectral Graph Wavelets](https://arxiv.org/abs/2602.03333)
*Haoran Li,Renyang Liu,Hongjia Liu,Chen Wang,Long Yin,Jian Xu*

Main category: cs.CV

TL;DR: PWAVEP是一种针对3D点云对抗攻击的即插即用防御机制，通过谱域分析和分层净化策略有效去除对抗噪声，无需修改模型或额外训练。


<details>
  <summary>Details</summary>
Motivation: 当前3D点云对抗攻击在空间不可感知性和高攻击性能方面取得进展，给防御带来挑战。现有防御方法通常需要侵入式模型修改、昂贵的训练过程或辅助数据访问，使用不便。

Method: 提出基于谱域理论的PWAVEP净化框架：1)计算每个点的谱图小波域显著性得分和局部稀疏度得分；2)采用分层策略：消除最显著的难以恢复的对抗异常点；3)对中等显著点应用谱滤波，利用图小波变换衰减与目标点相关的高频系数。

Result: 广泛评估表明，PWAVEP在准确性和鲁棒性方面优于现有方法，推进了3D点云净化的最先进水平。

Conclusion: PWAVEP提供了一种有效的即插即用、非侵入式防御机制，通过谱域分析和分层净化策略成功应对3D点云对抗攻击的挑战。

Abstract: Recent progress in adversarial attacks on 3D point clouds, particularly in achieving spatial imperceptibility and high attack performance, presents significant challenges for defenders. Current defensive approaches remain cumbersome, often requiring invasive model modifications, expensive training procedures or auxiliary data access. To address these threats, in this paper, we propose a plug-and-play and non-invasive defense mechanism in the spectral domain, grounded in a theoretical and empirical analysis of the relationship between imperceptible perturbations and high-frequency spectral components. Building upon these insights, we introduce a novel purification framework, termed PWAVEP, which begins by computing a spectral graph wavelet domain saliency score and local sparsity score for each point. Guided by these values, PWAVEP adopts a hierarchical strategy, it eliminates the most salient points, which are identified as hardly recoverable adversarial outliers. Simultaneously, it applies a spectral filtering process to a broader set of moderately salient points. This process leverages a graph wavelet transform to attenuate high-frequency coefficients associated with the targeted points, thereby effectively suppressing adversarial noise. Extensive evaluations demonstrate that the proposed PWAVEP achieves superior accuracy and robustness compared to existing approaches, advancing the state-of-the-art in 3D point cloud purification. Code and datasets are available at https://github.com/a772316182/pwavep

</details>


### [48] [Composable Visual Tokenizers with Generator-Free Diagnostics of Learnability](https://arxiv.org/abs/2602.03339)
*Bingchen Zhao,Qiushan Guo,Ye Wang,Yixuan Huang,Zhonghua Zhai,Yu Tian*

Main category: cs.CV

TL;DR: CompTok是一个学习视觉tokenizer的训练框架，通过token条件扩散解码器和InfoGAN风格目标，增强token的组合性，支持图像间的token交换实现语义编辑。


<details>
  <summary>Details</summary>
Motivation: 现有视觉tokenizer在组合性控制方面存在不足，token可能被解码器忽略，且难以实现图像间的高层语义编辑。需要开发能增强token组合性并支持语义交换的tokenizer框架。

Method: 使用token条件扩散解码器，采用InfoGAN风格目标训练识别模型预测用于条件解码的token，防止解码器忽略token。通过在图像间交换token子集进行训练，并使用对抗流正则化器保持未配对交换生成在自然图像分布上。

Result: CompTok在图像类别条件生成上达到最先进性能，支持通过交换token实现图像的高层语义编辑。提出的两个token空间度量显示CompTok在组合性和生成器学习难度方面均有改善。

Conclusion: CompTok框架成功增强了视觉tokenizer的组合性，不仅提升了类别条件生成性能，还实现了语义编辑能力，为token空间的组合性控制提供了有效解决方案。

Abstract: We introduce CompTok, a training framework for learning visual tokenizers whose tokens are enhanced for compositionality. CompTok uses a token-conditioned diffusion decoder. By employing an InfoGAN-style objective, where we train a recognition model to predict the tokens used to condition the diffusion decoder using the decoded images, we enforce the decoder to not ignore any of the tokens. To promote compositional control, besides the original images, CompTok also trains on tokens formed by swapping token subsets between images, enabling more compositional control of the token over the decoder. As the swapped tokens between images do not have ground truth image targets, we apply a manifold constraint via an adversarial flow regularizer to keep unpaired swap generations on the natural-image distribution. The resulting tokenizer not only achieves state-of-the-art performance on image class-conditioned generation, but also demonstrates properties such as swapping tokens between images to achieve high level semantic editing of an image. Additionally, we propose two metrics that measures the landscape of the token space that can be useful to describe not only the compositionality of the tokens, but also how easy to learn the landscape is for a generator to be trained on this space. We show in experiments that CompTok can improve on both of the metrics as well as supporting state-of-the-art generators for class conditioned generation.

</details>


### [49] [Tiled Prompts: Overcoming Prompt Underspecification in Image and Video Super-Resolution](https://arxiv.org/abs/2602.03342)
*Bryan Sangwoo Kim,Jonghyun Park,Jong Chul Ye*

Main category: cs.CV

TL;DR: Tiled Prompts框架通过为每个潜在瓦片生成特定提示，解决了图像和视频超分辨率中全局提示导致的提示不足问题，提升了感知质量和文本对齐。


<details>
  <summary>Details</summary>
Motivation: 现代超分辨率管道通常依赖潜在瓦片扩展到高分辨率，但单个全局标题会导致提示不足。粗粒度的全局提示常常错过局部细节（提示稀疏性）并提供局部不相关的指导（提示误导），这些问题可能被无分类器指导放大。

Method: 提出Tiled Prompts统一框架，为每个潜在瓦片生成瓦片特定的提示，并在局部文本条件后验下执行超分辨率，提供高信息指导，以最小开销解决提示不足问题。

Result: 在高分辨率真实世界图像和视频上的实验显示，相对于全局提示基线，该方法在感知质量和文本对齐方面获得了一致的提升，同时减少了幻觉和瓦片级伪影。

Conclusion: Tiled Prompts框架通过局部文本条件指导有效解决了高分辨率超分辨率中的提示不足问题，为图像和视频超分辨率提供了更精确的语义先验。

Abstract: Text-conditioned diffusion models have advanced image and video super-resolution by using prompts as semantic priors, but modern super-resolution pipelines typically rely on latent tiling to scale to high resolutions, where a single global caption causes prompt underspecification. A coarse global prompt often misses localized details (prompt sparsity) and provides locally irrelevant guidance (prompt misguidance) that can be amplified by classifier-free guidance. We propose Tiled Prompts, a unified framework for image and video super-resolution that generates a tile-specific prompt for each latent tile and performs super-resolution under locally text-conditioned posteriors, providing high-information guidance that resolves prompt underspecification with minimal overhead. Experiments on high resolution real-world images and videos show consistent gains in perceptual quality and text alignment, while reducing hallucinations and tile-level artifacts relative to global-prompt baselines.

</details>


### [50] [Z3D: Zero-Shot 3D Visual Grounding from Images](https://arxiv.org/abs/2602.03361)
*Nikita Drozdov,Andrey Lemeshko,Nikita Gavrilov,Anton Konushin,Danila Rukhovich,Maksim Kolodiazhnyi*

Main category: cs.CV

TL;DR: Z3D：无需几何监督或物体先验的零样本3D视觉定位方法，仅使用多视角图像，通过零样本3D实例分割生成高质量3D边界框提案，结合基于提示的分割实现先进推理。


<details>
  <summary>Details</summary>
Motivation: 探索仅使用多视角图像、无需几何监督或物体先验的零样本3D视觉定位，解决现有零样本方法性能显著下降的关键瓶颈问题。

Method: 提出Z3D通用定位流程：1）使用最先进的零样本3D实例分割方法生成高质量3D边界框提案；2）通过基于提示的分割利用现代视觉语言模型的完整能力进行先进推理；可灵活操作多视角图像，可选加入相机位姿和深度图。

Result: 在ScanRefer和Nr3D基准测试中，该方法在零样本方法中实现了最先进的性能。

Conclusion: Z3D展示了仅使用多视角图像实现零样本3D视觉定位的可行性，通过高质量的3D提案生成和先进的视觉语言模型推理能力，显著提升了零样本方法的性能。

Abstract: 3D visual grounding (3DVG) aims to localize objects in a 3D scene based on natural language queries. In this work, we explore zero-shot 3DVG from multi-view images alone, without requiring any geometric supervision or object priors. We introduce Z3D, a universal grounding pipeline that flexibly operates on multi-view images while optionally incorporating camera poses and depth maps. We identify key bottlenecks in prior zero-shot methods causing significant performance degradation and address them with (i) a state-of-the-art zero-shot 3D instance segmentation method to generate high-quality 3D bounding box proposals and (ii) advanced reasoning via prompt-based segmentation, which utilizes full capabilities of modern VLMs. Extensive experiments on the ScanRefer and Nr3D benchmarks demonstrate that our approach achieves state-of-the-art performance among zero-shot methods. Code is available at https://github.com/col14m/z3d .

</details>


### [51] [Symbol-Aware Reasoning with Masked Discrete Diffusion for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2602.03370)
*Takaya Kawakatsu,Ryo Ishiyama*

Main category: cs.CV

TL;DR: 该论文提出了一种基于离散扩散框架的手写数学表达式识别方法，通过迭代符号精炼而非序列生成来解决自回归模型的曝光偏差和句法不一致问题。


<details>
  <summary>Details</summary>
Motivation: 手写数学表达式识别需要处理多样化的符号和二维结构布局，但现有的自回归模型存在曝光偏差和句法不一致的问题，限制了识别性能。

Method: 采用离散扩散框架，将HMER重新定义为迭代符号精炼过程；通过多步重掩码技术逐步精炼符号和结构关系；引入符号感知标记化和随机掩码互学习机制来增强句法对齐和对书写多样性的鲁棒性。

Result: 在MathWriting基准测试中达到5.56%的字符错误率和60.42%的精确匹配率，优于强大的Transformer模型和商业基线；在CROHME 2014-2023数据集上取得一致性的性能提升。

Conclusion: 离散扩散框架为结构感知的视觉识别提供了超越生成建模的新范式，能够有效解决手写数学表达式识别中的结构一致性问题。

Abstract: Handwritten Mathematical Expression Recognition (HMER) requires reasoning over diverse symbols and 2D structural layouts, yet autoregressive models struggle with exposure bias and syntactic inconsistency. We present a discrete diffusion framework that reformulates HMER as iterative symbolic refinement instead of sequential generation. Through multi-step remasking, the proposal progressively refines both symbols and structural relations, removing causal dependencies and improving structural consistency. A symbol-aware tokenization and Random-Masking Mutual Learning further enhance syntactic alignment and robustness to handwriting diversity. On the MathWriting benchmark, the proposal achieves 5.56\% CER and 60.42\% EM, outperforming strong Transformer and commercial baselines. Consistent gains on CROHME 2014--2023 demonstrate that discrete diffusion provides a new paradigm for structure-aware visual recognition beyond generative modeling.

</details>


### [52] [Multi-Resolution Alignment for Voxel Sparsity in Camera-Based 3D Semantic Scene Completion](https://arxiv.org/abs/2602.03371)
*Zhiwen Yang,Yuxin Peng*

Main category: cs.CV

TL;DR: 本文提出了一种多分辨率对齐方法来解决基于相机的3D语义场景补全中的体素稀疏性问题，通过场景级和实例级的多分辨率特征对齐作为辅助监督。


<details>
  <summary>Details</summary>
Motivation: 现有基于相机的3D语义场景补全方法仅依赖体素标签监督，面临体素稀疏性问题（自动驾驶场景中大部分体素为空），限制了优化效率和模型性能。

Method: 提出多分辨率对齐方法：1）多分辨率视图变换器模块，将2D图像特征投影到多分辨率3D特征并进行场景级对齐；2）立方语义各向异性模块，识别每个体素的实例级语义重要性；3）关键分布对齐模块，选择关键体素作为实例级锚点，应用循环损失进行跨分辨率关键特征分布一致性的辅助监督。

Result: 该方法在SemanticKITTI和nuScenes数据集上验证有效，代码已开源。

Conclusion: 通过多分辨率对齐方法有效缓解了体素稀疏性问题，提高了基于相机的3D语义场景补全的性能。

Abstract: Camera-based 3D semantic scene completion (SSC) offers a cost-effective solution for assessing the geometric occupancy and semantic labels of each voxel in the surrounding 3D scene with image inputs, providing a voxel-level scene perception foundation for the perception-prediction-planning autonomous driving systems. Although significant progress has been made in existing methods, their optimization rely solely on the supervision from voxel labels and face the challenge of voxel sparsity as a large portion of voxels in autonomous driving scenarios are empty, which limits both optimization efficiency and model performance. To address this issue, we propose a \textit{Multi-Resolution Alignment (MRA)} approach to mitigate voxel sparsity in camera-based 3D semantic scene completion, which exploits the scene and instance level alignment across multi-resolution 3D features as auxiliary supervision. Specifically, we first propose the Multi-resolution View Transformer module, which projects 2D image features into multi-resolution 3D features and aligns them at the scene level through fusing discriminative seed features. Furthermore, we design the Cubic Semantic Anisotropy module to identify the instance-level semantic significance of each voxel, accounting for the semantic differences of a specific voxel against its neighboring voxels within a cubic area. Finally, we devise a Critical Distribution Alignment module, which selects critical voxels as instance-level anchors with the guidance of cubic semantic anisotropy, and applies a circulated loss for auxiliary supervision on the critical feature distribution consistency across different resolutions. The code is available at https://github.com/PKU-ICST-MIPL/MRA_TIP.

</details>


### [53] [Quasi-multimodal-based pathophysiological feature learning for retinal disease diagnosis](https://arxiv.org/abs/2602.03622)
*Lu Zhang,Huizhen Yu,Zuowei Wang,Fu Gui,Yatu Guo,Wei Zhang,Mengyu Jia*

Main category: cs.CV

TL;DR: 提出统一框架整合多模态数据合成与融合，用于视网膜疾病分类与分级，通过合成FFA、MSI和显著性图，并行学习模态特定表征，自适应校准特征，在多项指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视网膜疾病诊断需要多模态数据，但实践中面临数据异质性、潜在侵入性、配准复杂性等挑战，需要统一框架来整合多模态数据合成与融合。

Method: 提出统一框架：1）合成多模态数据（FFA、MSI、显著性图）；2）并行训练模型学习模态特定表征；3）自适应校准特征进行信息剪枝和灵活整合；4）通过图像和特征空间可视化解释学习系统。

Result: 在两个公共数据集上验证：多标签分类任务（F1-score: 0.683, AUC: 0.953）和糖尿病视网膜病变分级（Accuracy: 0.842, Kappa: 0.861），均优于现有最先进方法。

Conclusion: 该工作不仅提高了视网膜疾病筛查的准确性和效率，还为各种医学成像模态的数据增强提供了可扩展框架。

Abstract: Retinal diseases spanning a broad spectrum can be effectively identified and diagnosed using complementary signals from multimodal data. However, multimodal diagnosis in ophthalmic practice is typically challenged in terms of data heterogeneity, potential invasiveness, registration complexity, and so on. As such, a unified framework that integrates multimodal data synthesis and fusion is proposed for retinal disease classification and grading. Specifically, the synthesized multimodal data incorporates fundus fluorescein angiography (FFA), multispectral imaging (MSI), and saliency maps that emphasize latent lesions as well as optic disc/cup regions. Parallel models are independently trained to learn modality-specific representations that capture cross-pathophysiological signatures. These features are then adaptively calibrated within and across modalities to perform information pruning and flexible integration according to downstream tasks. The proposed learning system is thoroughly interpreted through visualizations in both image and feature spaces. Extensive experiments on two public datasets demonstrated the superiority of our approach over state-of-the-art ones in the tasks of multi-label classification (F1-score: 0.683, AUC: 0.953) and diabetic retinopathy grading (Accuracy:0.842, Kappa: 0.861). This work not only enhances the accuracy and efficiency of retinal disease screening but also offers a scalable framework for data augmentation across various medical imaging modalities.

</details>


### [54] [MM-SCALE: Grounded Multimodal Moral Reasoning via Scalar Judgment and Listwise Alignment](https://arxiv.org/abs/2602.03665)
*Eunkyu Park,Wesley Hanwen Deng,Cheyon Jin,Matheus Kunzler Maldaner,Jordan Wheeler,Jason I. Hong,Hong Shen,Adam Perer,Ken Holstein,Motahhare Eslami,Gunhee Kim*

Main category: cs.CV

TL;DR: MM-SCALE是一个大规模多模态道德对齐数据集，通过5点标量评分和显式模态标注来改进视觉语言模型的道德判断能力，相比传统二元监督提供更丰富的对齐信号。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在多模态和社会模糊情境中仍难以做出道德判断。现有方法通常依赖二元或成对监督，无法捕捉人类道德推理的连续性和多元性。

Method: 构建MM-SCALE数据集，包含图像-场景对，通过专门设计的界面进行人工标注，包括道德可接受性分数（5点标量）和显式模态标注，支持基于排序场景集的列表偏好优化。

Result: 在MM-SCALE上微调的视觉语言模型比使用二元信号训练的模型具有更高的排序保真度和更稳定的安全校准。

Conclusion: 从离散监督转向标量监督能够为多模态道德推理提供更丰富的对齐信号和更精细的校准，提升视觉语言模型的道德判断能力。

Abstract: Vision-Language Models (VLMs) continue to struggle to make morally salient judgments in multimodal and socially ambiguous contexts. Prior works typically rely on binary or pairwise supervision, which often fail to capture the continuous and pluralistic nature of human moral reasoning. We present MM-SCALE (Multimodal Moral Scale), a large-scale dataset for aligning VLMs with human moral preferences through 5-point scalar ratings and explicit modality grounding. Each image-scenario pair is annotated with moral acceptability scores and grounded reasoning labels by humans using an interface we tailored for data collection, enabling listwise preference optimization over ranked scenario sets. By moving from discrete to scalar supervision, our framework provides richer alignment signals and finer calibration of multimodal moral reasoning. Experiments show that VLMs fine-tuned on MM-SCALE achieve higher ranking fidelity and more stable safety calibration than those trained with binary signals.

</details>


### [55] [Referring Industrial Anomaly Segmentation](https://arxiv.org/abs/2602.03673)
*Pengfei Yue,Xiaokang Jiang,Yilin Lu,Jianghang Lin,Shengchuan Zhang,Liujuan Cao*

Main category: cs.CV

TL;DR: 提出RIAS范式，利用语言指导工业异常检测，通过文本描述生成精确掩码，无需人工阈值，使用通用提示检测多种异常，仅需单一模型


<details>
  <summary>Details</summary>
Motivation: 传统工业异常检测方法面临挑战：无监督方法需要人工阈值，监督方法因数据稀缺和不平衡而过拟合，且都受限于"一种异常一个模型"的限制

Method: 提出Referring Industrial Anomaly Segmentation (RIAS)范式，引入MVTec-Ref数据集，设计DQFormer基准模型，采用双查询令牌和语言门控多级聚合机制

Result: 实验证明RIAS在工业异常检测中的有效性，推动IAD向开放集能力发展，能够处理95%的小异常

Conclusion: RIAS通过语言引导的范式解决了传统工业异常检测的局限性，实现了无需人工阈值、单一模型检测多种异常的目标，为开放集工业异常检测提供了新方向

Abstract: Industrial Anomaly Detection (IAD) is vital for manufacturing, yet traditional methods face significant challenges: unsupervised approaches yield rough localizations requiring manual thresholds, while supervised methods overfit due to scarce, imbalanced data. Both suffer from the "One Anomaly Class, One Model" limitation. To address this, we propose Referring Industrial Anomaly Segmentation (RIAS), a paradigm leveraging language to guide detection. RIAS generates precise masks from text descriptions without manual thresholds and uses universal prompts to detect diverse anomalies with a single model. We introduce the MVTec-Ref dataset to support this, designed with diverse referring expressions and focusing on anomaly patterns, notably with 95% small anomalies. We also propose the Dual Query Token with Mask Group Transformer (DQFormer) benchmark, enhanced by Language-Gated Multi-Level Aggregation (LMA) to improve multi-scale segmentation. Unlike traditional methods using redundant queries, DQFormer employs only "Anomaly" and "Background" tokens for efficient visual-textual integration. Experiments demonstrate RIAS's effectiveness in advancing IAD toward open-set capabilities. Code: https://github.com/swagger-coder/RIAS-MVTec-Ref.

</details>


### [56] [Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment](https://arxiv.org/abs/2602.03742)
*Johny J. Lopez,Md Meftahul Ferdaus,Mahdi Abdelguerfi*

Main category: cs.CV

TL;DR: 本文提出了一种用于地下基础设施缺陷检测和总结的两阶段边缘计算管道，结合轻量级分割模型和微调视觉语言模型，实现实时自动化检查报告生成。


<details>
  <summary>Details</summary>
Motivation: 地下基础设施（如下水道和涵洞系统）的自主检查对公共安全和城市可持续性至关重要。虽然配备视觉传感器的机器人平台可以高效检测结构缺陷，但从这些检测结果自动生成人类可读的总结仍然是一个重大挑战，特别是在资源受限的边缘设备上。

Method: 提出了一种新颖的两阶段管道：第一阶段使用轻量级RAPID-SCAN分割模型（仅0.64M参数）进行缺陷分割；第二阶段使用微调的Phi-3.5视觉语言模型从分割输出生成简洁的领域特定自然语言总结。采用后训练量化和硬件特定优化实现实时性能。

Result: RAPID-SCAN模型达到0.834 F1分数；完整的管道在移动机器人平台上成功部署和评估，展示了在实际检查场景中的有效性。通过量化显著减少了模型大小和推理延迟，同时保持了总结质量。

Conclusion: 该研究展示了边缘可部署集成AI系统在连接自动缺陷检测和基础设施维护可行见解方面的潜力，为更可扩展和自主的检查解决方案铺平了道路。

Abstract: Autonomous inspection of underground infrastructure, such as sewer and culvert systems, is critical to public safety and urban sustainability. Although robotic platforms equipped with visual sensors can efficiently detect structural deficiencies, the automated generation of human-readable summaries from these detections remains a significant challenge, especially on resource-constrained edge devices. This paper presents a novel two-stage pipeline for end-to-end summarization of underground deficiencies, combining our lightweight RAPID-SCAN segmentation model with a fine-tuned Vision-Language Model (VLM) deployed on an edge computing platform. The first stage employs RAPID-SCAN (Resource-Aware Pipeline Inspection and Defect Segmentation using Compact Adaptive Network), achieving 0.834 F1-score with only 0.64M parameters for efficient defect segmentation. The second stage utilizes a fine-tuned Phi-3.5 VLM that generates concise, domain-specific summaries in natural language from the segmentation outputs. We introduce a curated dataset of inspection images with manually verified descriptions for VLM fine-tuning and evaluation. To enable real-time performance, we employ post-training quantization with hardware-specific optimization, achieving significant reductions in model size and inference latency without compromising summarization quality. We deploy and evaluate our complete pipeline on a mobile robotic platform, demonstrating its effectiveness in real-world inspection scenarios. Our results show the potential of edge-deployable integrated AI systems to bridge the gap between automated defect detection and actionable insights for infrastructure maintenance, paving the way for more scalable and autonomous inspection solutions.

</details>


### [57] [LIVE: Long-horizon Interactive Video World Modeling](https://arxiv.org/abs/2602.03747)
*Junchao Huang,Ziyang Ye,Xinting Hu,Tianyu He,Guiyu Zhang,Shaoshuai Shi,Jiang Bian,Li Jiang*

Main category: cs.CV

TL;DR: LIVE提出了一种通过循环一致性目标约束误差累积的长时域交互视频世界模型，无需教师蒸馏即可生成超出训练时长的稳定高质量视频


<details>
  <summary>Details</summary>
Motivation: 自回归视频世界模型在短时域预测有效，但在长时域生成中因小误差累积而表现不佳。现有方法需要预训练教师模型和序列级分布匹配，计算成本高且无法防止超出训练时长的误差传播。

Method: 提出LIVE模型，通过新颖的循环一致性目标强制有界误差累积：1）从真实帧进行前向展开；2）应用反向生成过程重建初始状态；3）在重建的终止状态计算扩散损失，显式约束长时域误差传播。同时提供统一视角并引入渐进训练课程以稳定训练。

Result: 实验表明LIVE在长时域基准测试中达到最先进性能，能够生成远超训练展开长度的稳定高质量视频。

Conclusion: LIVE通过循环一致性目标有效解决了长时域视频生成中的误差累积问题，无需教师蒸馏即可实现稳定高质量的长时域视频预测。

Abstract: Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-horizon Interactive Video world modEl that enforces bounded error accumulation via a novel cycle-consistency objective, thereby eliminating the need for teacher-based distillation. Specifically, LIVE first performs a forward rollout from ground-truth frames and then applies a reverse generation process to reconstruct the initial state. The diffusion loss is subsequently computed on the reconstructed terminal state, providing an explicit constraint on long-horizon error propagation. Moreover, we provide an unified view that encompasses different approaches and introduce progressive training curriculum to stabilize training. Experiments demonstrate that LIVE achieves state-of-the-art performance on long-horizon benchmarks, generating stable, high-quality videos far beyond training rollout lengths.

</details>


### [58] [See-through: Single-image Layer Decomposition for Anime Characters](https://arxiv.org/abs/2602.03749)
*Jian Lin,Chengze Li,Haoyun Qin,Kwun Wang Chan,Yanghua Jin,Hanyuan Liu,Stephen Chun Wang Choy,Xueting Liu*

Main category: cs.CV

TL;DR: 提出一个自动化框架，将静态动漫插画转换为可操控的2.5D模型，通过解构图像为语义分层的可重构图层，解决传统手动分割和遮挡区域"幻觉"的繁琐问题。


<details>
  <summary>Details</summary>
Motivation: 当前专业工作流程需要繁琐的手动分割和遮挡区域的艺术"幻觉"才能实现动画效果，这限制了动漫角色动画化的效率和可扩展性。

Method: 1. 从单张图像分解为完全修复的语义分层图层；2. 使用可扩展引擎从商业Live2D模型获取高质量监督数据；3. 结合基于扩散的身体部位一致性模块和像素级伪深度推理机制，解决动漫角色复杂分层问题。

Result: 该方法能够生成高保真、可操控的模型，适用于专业的实时动画应用，能够处理复杂的动漫角色分层结构（如交织的发丝）。

Conclusion: 提出的框架成功实现了静态动漫插画到可操控2.5D模型的自动化转换，解决了训练数据稀缺问题，为专业动画应用提供了高效解决方案。

Abstract: We introduce a framework that automates the transformation of static anime illustrations into manipulatable 2.5D models. Current professional workflows require tedious manual segmentation and the artistic ``hallucination'' of occluded regions to enable motion. Our approach overcomes this by decomposing a single image into fully inpainted, semantically distinct layers with inferred drawing orders. To address the scarcity of training data, we introduce a scalable engine that bootstraps high-quality supervision from commercial Live2D models, capturing pixel-perfect semantics and hidden geometry. Our methodology couples a diffusion-based Body Part Consistency Module, which enforces global geometric coherence, with a pixel-level pseudo-depth inference mechanism. This combination resolves the intricate stratification of anime characters, e.g., interleaving hair strands, allowing for dynamic layer reconstruction. We demonstrate that our approach yields high-fidelity, manipulatable models suitable for professional, real-time animation applications.

</details>


### [59] [Test-Time Conditioning with Representation-Aligned Visual Features](https://arxiv.org/abs/2602.03753)
*Nicolas Sereyjol-Garros,Ellington Kirby,Victor Letzelter,Victor Besnier,Nermin Samet*

Main category: cs.CV

TL;DR: REPA-G是一种利用自监督模型对齐表示进行推理时条件控制的扩散模型框架，通过优化相似性目标在推理过程中引导去噪，实现从细粒度纹理到语义的多尺度控制


<details>
  <summary>Details</summary>
Motivation: 虽然表示对齐已被证明能改进扩散模型训练，但其在推理时条件控制方面的潜力尚未充分探索。现有方法主要依赖模糊的文本提示或粗糙的类别标签，缺乏灵活精确的控制能力

Method: 提出表示对齐引导（REPA-G）框架，在推理时通过优化相似性目标（势函数）来引导去噪过程，使其朝向从预训练特征提取器提取的条件表示。支持从单patch的细粒度纹理匹配到全局图像特征token的语义引导，并可扩展到多概念组合

Result: 在ImageNet和COCO数据集上的定量结果表明，该方法能生成高质量、多样化的图像。理论分析证明了该方法能从势函数诱导的倾斜分布中采样

Conclusion: REPA-G提供了一种完全在推理时操作的灵活精确条件控制方法，可作为模糊文本提示或粗糙类别标签的替代方案，实现从细粒度到语义的多尺度控制

Abstract: While representation alignment with self-supervised models has been shown to improve diffusion model training, its potential for enhancing inference-time conditioning remains largely unexplored. We introduce Representation-Aligned Guidance (REPA-G), a framework that leverages these aligned representations, with rich semantic properties, to enable test-time conditioning from features in generation. By optimizing a similarity objective (the potential) at inference, we steer the denoising process toward a conditioned representation extracted from a pre-trained feature extractor. Our method provides versatile control at multiple scales, ranging from fine-grained texture matching via single patches to broad semantic guidance using global image feature tokens. We further extend this to multi-concept composition, allowing for the faithful combination of distinct concepts. REPA-G operates entirely at inference time, offering a flexible and precise alternative to often ambiguous text prompts or coarse class labels. We theoretically justify how this guidance enables sampling from the potential-induced tilted distribution. Quantitative results on ImageNet and COCO demonstrate that our approach achieves high-quality, diverse generations. Code is available at https://github.com/valeoai/REPA-G.

</details>


### [60] [RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images](https://arxiv.org/abs/2602.03760)
*Mishal Fatima,Shashank Agnihotri,Kanchana Vaishnavi Gandikota,Michael Moeller,Margret Keuper*

Main category: cs.CV

TL;DR: RAWDet-7数据集包含约25k训练和7.6k测试RAW图像，支持在低比特量化下研究目标检测和描述任务，填补了RAW图像机器感知研究的空白。


<details>
  <summary>Details</summary>
Motivation: 传统视觉模型使用经过ISP处理的RGB图像，这些图像针对人类感知优化，但可能丢失传感器级别的有用信息。RAW图像保留了未处理的场景数据，包含更丰富的机器推理线索。

Method: 构建RAWDet-7大规模数据集，包含多样相机、光照条件和环境下的RAW图像，按照MS-COCO和LVIS标准密集标注7个目标类别，并提供从对应sRGB图像提取的目标级描述。

Result: 数据集支持模拟4位、6位和8位量化评估，反映真实传感器约束，为研究低比特RAW图像处理中的检测性能、描述质量和泛化能力提供基准。

Conclusion: RAWDet-7填补了RAW图像机器感知研究的空白，支持探索RAW图像在目标检测和描述任务中的优势，特别是在低比特量化条件下的性能表现。

Abstract: Most vision models are trained on RGB images processed through ISP pipelines optimized for human perception, which can discard sensor-level information useful for machine reasoning. RAW images preserve unprocessed scene data, enabling models to leverage richer cues for both object detection and object description, capturing fine-grained details, spatial relationships, and contextual information often lost in processed images. To support research in this domain, we introduce RAWDet-7, a large-scale dataset of ~25k training and 7.6k test RAW images collected across diverse cameras, lighting conditions, and environments, densely annotated for seven object categories following MS-COCO and LVIS conventions. In addition, we provide object-level descriptions derived from the corresponding high-resolution sRGB images, facilitating the study of object-level information preservation under RAW image processing and low-bit quantization. The dataset allows evaluation under simulated 4-bit, 6-bit, and 8-bit quantization, reflecting realistic sensor constraints, and provides a benchmark for studying detection performance, description quality & detail, and generalization in low-bit RAW image processing. Dataset & code upon acceptance.

</details>


### [61] [FOVI: A biologically-inspired foveated interface for deep vision models](https://arxiv.org/abs/2602.03766)
*Nicholas M. Blauch,George A. Alvarez,Talia Konkle*

Main category: cs.CV

TL;DR: 提出基于人眼视网膜和初级视觉皮层的仿生视觉接口FOVI，将可变分辨率视网膜式传感器阵列转换为均匀密集的V1式传感器流形，通过k近邻卷积实现高效的高分辨率视觉处理。


<details>
  <summary>Details</summary>
Motivation: 人类视觉具有中央凹特性，分辨率从中心向周边递减，这种主动感知机制能高效处理大视野图像。而传统计算机视觉系统采用均匀分辨率编码，处理全视野高分辨率图像时计算效率低下。

Method: 基于人眼视网膜和初级视觉皮层设计FOVI接口，将视网膜式可变分辨率传感器阵列重新格式化为均匀密集的V1式传感器流形。在传感器流形上定义k近邻感受野，通过新型核映射技术实现k近邻卷积。

Result: 开发了两种应用：端到端k近邻卷积架构，以及对DINOv3 ViT模型的中央凹适应版本（使用低秩适应LoRA）。这些模型在计算成本仅为非中央凹基线一小部分的情况下，实现了竞争性性能。

Conclusion: FOVI为高效、可扩展的主动感知开辟了新途径，特别适用于高分辨率第一人称视觉任务，代码和预训练模型已开源。

Abstract: Human vision is foveated, with variable resolution peaking at the center of a large field of view; this reflects an efficient trade-off for active sensing, allowing eye-movements to bring different parts of the world into focus with other parts of the world in context. In contrast, most computer vision systems encode the visual world at a uniform resolution, raising challenges for processing full-field high-resolution images efficiently. We propose a foveated vision interface (FOVI) based on the human retina and primary visual cortex, that reformats a variable-resolution retina-like sensor array into a uniformly dense, V1-like sensor manifold. Receptive fields are defined as k-nearest-neighborhoods (kNNs) on the sensor manifold, enabling kNN-convolution via a novel kernel mapping technique. We demonstrate two use cases: (1) an end-to-end kNN-convolutional architecture, and (2) a foveated adaptation of the foundational DINOv3 ViT model, leveraging low-rank adaptation (LoRA). These models provide competitive performance at a fraction of the computational cost of non-foveated baselines, opening pathways for efficient and scalable active sensing for high-resolution egocentric vision. Code and pre-trained models are available at https://github.com/nblauch/fovi and https://huggingface.co/fovi-pytorch.

</details>


### [62] [QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization](https://arxiv.org/abs/2602.03782)
*Yuhao Xu,Yantai Yang,Zhenyang Fan,Yufan Liu,Yuming Li,Bing Li,Zhipeng Zhang*

Main category: cs.CV

TL;DR: QVLA提出首个面向具身控制的动作中心量化框架，通过通道级比特分配策略，在保持98.9%性能的同时将VRAM需求降至29.2%，相比传统LLM量化方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作（VLA）模型在具身智能中具有重要价值，但其巨大的计算需求严重阻碍了在资源受限机器人平台上的部署。现有从大语言模型（LLM）继承的统一比特量化方法不适用于机器人控制，因为这些方法只关注被动数据保真度，而忽略了微小动作偏差会累积成灾难性任务失败的问题。

Method: QVLA引入了高度细粒度的通道级比特分配策略，核心机制是直接测量量化每个单独通道到不同比特宽度时对最终动作空间的敏感性。这一过程产生精确的每通道重要性度量，指导全局优化，将量化和剪枝（0比特）统一到单一框架中。

Result: 在LIBERO基准测试中，使用QVLA量化的OpenVLA-OFT版本仅需原始模型29.2%的VRAM，同时保持98.9%的原始性能，实现1.49倍加速。相比LLM衍生方法SmoothQuant有22.6%的性能提升。

Conclusion: QVLA为机器人领域VLA模型压缩建立了新的原则性基础，为在现实硬件上部署强大、大规模模型铺平了道路。

Abstract: The advent of Vision-Language-Action (VLA) models represents a significant leap for embodied intelligence, yet their immense computational demands critically hinder deployment on resource-constrained robotic platforms. Intuitively, low-bit quantization is a prevalent and preferred technique for large-scale model compression. However, we find that a systematic analysis of VLA model's quantization is fundamentally lacking. We argue that naively applying uniform-bit quantization from Large Language Models (LLMs) to robotics is flawed, as these methods prioritize passive data fidelity while ignoring how minor action deviations compound into catastrophic task failures. To bridge this gap, we introduce QVLA, the first action-centric quantization framework specifically designed for embodied control. In a sharp departure from the rigid, uniform-bit quantization of LLM-based methods, QVLA introduces a highly granular, channel-wise bit allocation strategy. Its core mechanism is to directly measure the final action-space sensitivity when quantizing each individual channel to various bit-widths. This process yields a precise, per-channel importance metric that guides a global optimization, which elegantly unifies quantization and pruning (0-bit) into a single, cohesive framework. Extensive evaluations on different baselines demonstrate the superiority of our approach. In the LIBERO, the quantization version of OpenVLA-OFT with our method requires only 29.2% of the original model's VRAM while maintaining 98.9% of its original performance and achieving a 1.49x speedup. This translates to a 22.6% performance improvement over the LLM-derived method SmoothQuant. Our work establishes a new, principled foundation for compressing VLA models in robotics, paving the way for deploying powerful, large-scale models on real-world hardware. Code will be released.

</details>


### [63] [From Pre- to Intra-operative MRI: Predicting Brain Shift in Temporal Lobe Resection for Epilepsy Surgery](https://arxiv.org/abs/2602.03785)
*Jingjing Peng,Giorgio Fiore,Yang Liu,Ksenia Ellum,Debayan Daspupta,Keyoumars Ashkan,Andrew McEvoy,Anna Miserocchi,Sebastien Ourselin,John Duncan,Alejandro Granados*

Main category: cs.CV

TL;DR: NeuralShift是一个基于U-Net的模型，仅使用术前MRI预测脑移位，用于颞叶切除手术，能够准确预测全局变形和局部位移。


<details>
  <summary>Details</summary>
Motivation: 神经外科手术中，脑移位会使术前MRI失效，影响手术导航精度。需要能够补偿脑移位的术中MRI更新来提高手术精度和患者预后。

Method: 提出NeuralShift模型，基于U-Net架构，仅使用术前MRI预测颞叶切除手术中的脑移位。通过目标配准误差（TREs）和解剖标志点DICE分数进行评估。

Result: 模型能够准确预测脑的全局变形（DICE分数0.97）和局部位移（标志点TRE低至1.12毫米），有效补偿颞叶切除手术中的大范围脑移位。

Conclusion: 该模型仅使用术前图像就能预测颞叶切除手术中的脑变形，为手术团队提供了提高神经外科手术安全性和效率的潜在机会，改善患者预后。

Abstract: Introduction: In neurosurgery, image-guided Neurosurgery Systems (IGNS) highly rely on preoperative brain magnetic resonance images (MRI) to assist surgeons in locating surgical targets and determining surgical paths. However, brain shift invalidates the preoperative MRI after dural opening. Updated intraoperative brain MRI with brain shift compensation is crucial for enhancing the precision of neuronavigation systems and ensuring the optimal outcome of surgical interventions. Methodology: We propose NeuralShift, a U-Net-based model that predicts brain shift entirely from pre-operative MRI for patients undergoing temporal lobe resection. We evaluated our results using Target Registration Errors (TREs) computed on anatomical landmarks located on the resection side and along the midline, and DICE scores comparing predicted intraoperative masks with masks derived from intraoperative MRI. Results: Our experimental results show that our model can predict the global deformation of the brain (DICE of 0.97) with accurate local displacements (achieve landmark TRE as low as 1.12 mm), compensating for large brain shifts during temporal lobe removal neurosurgery. Conclusion: Our proposed model is capable of predicting the global deformation of the brain during temporal lobe resection using only preoperative images, providing potential opportunities to the surgical team to increase safety and efficiency of neurosurgery and better outcomes to patients. Our contributions will be publicly available after acceptance in https://github.com/SurgicalDataScienceKCL/NeuralShift.

</details>


### [64] [Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning](https://arxiv.org/abs/2602.03815)
*Dingkun Zhang,Shuhan Qi,Yulin Wu,Xinyu Xiao,Xuan Wang,Long Chen*

Main category: cs.CV

TL;DR: DualSpeed提出了一种用于多模态大语言模型高效训练的双速框架，通过快速模式（视觉令牌剪枝）和慢速模式（完整序列训练）相结合，在保持性能的同时显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在严重的训练效率问题，主要源于模型规模庞大和视觉令牌数量多。现有高效训练方法主要关注减少模型规模或可训练参数，而视觉令牌剪枝在推理阶段已证明有效，但在训练阶段应用会导致训练-推理不匹配问题。

Method: 提出DualSpeed双速框架：1）快速模式作为主要模式，集成现有视觉令牌剪枝方法作为插件来减少视觉令牌，并采用模式隔离器隔离模型行为；2）慢速模式作为辅助模式，在完整视觉序列上训练以保持训练-推理一致性，并通过自蒸馏从充分训练的快速模式中学习。

Result: 实验表明，DualSpeed将LLaVA-1.5的训练速度提升2.1倍，将LLaVA-NeXT的训练速度提升4.0倍，同时保持超过99%的性能。

Conclusion: DualSpeed框架通过双速训练策略，成功解决了视觉令牌剪枝在训练阶段的应用问题，实现了训练效率与性能的平衡，为多模态大语言模型的高效训练提供了新方向。

Abstract: Multimodal Large Language Models (MLLMs) suffer from severe training inefficiency issue, which is associated with their massive model sizes and visual token numbers. Existing efforts in efficient training focus on reducing model sizes or trainable parameters. Inspired by the success of Visual Token Pruning (VTP) in improving inference efficiency, we are exploring another substantial research direction for efficient training by reducing visual tokens. However, applying VTP at the training stage results in a training-inference mismatch: pruning-trained models perform poorly when inferring on non-pruned full visual token sequences. To close this gap, we propose DualSpeed, a fast-slow framework for efficient training of MLLMs. The fast-mode is the primary mode, which incorporates existing VTP methods as plugins to reduce visual tokens, along with a mode isolator to isolate the model's behaviors. The slow-mode is the auxiliary mode, where the model is trained on full visual sequences to retain training-inference consistency. To boost its training, it further leverages self-distillation to learn from the sufficiently trained fast-mode. Together, DualSpeed can achieve both training efficiency and non-degraded performance. Experiments show DualSpeed accelerates the training of LLaVA-1.5 by 2.1$\times$ and LLaVA-NeXT by 4.0$\times$, retaining over 99% performance. Code: https://github.com/dingkun-zhang/DualSpeed

</details>


### [65] [Continuous Control of Editing Models via Adaptive-Origin Guidance](https://arxiv.org/abs/2602.03826)
*Alon Wolf,Chen Katzir,Kfir Aberman,Or Patashnik*

Main category: cs.CV

TL;DR: 提出AdaOr方法解决扩散编辑模型中编辑强度连续控制问题，通过自适应原点调整实现从输入到编辑结果的平滑过渡


<details>
  <summary>Details</summary>
Motivation: 现有扩散编辑模型缺乏对文本引导编辑强度的平滑控制机制，虽然CFG影响提示符遵循度，但缩放CFG无法产生从输入到编辑结果的平滑过渡

Method: 提出自适应原点引导(AdaOr)方法，用身份条件自适应原点调整标准引导原点，通过身份指令对应身份操作，根据编辑强度在身份预测和标准无条件预测之间插值

Result: 在图像和视频编辑任务上评估，相比当前基于滑块的编辑方法，AdaOr提供更平滑一致的控制，无需每编辑过程或依赖专门数据集

Conclusion: AdaOr方法通过身份指令集成到标准训练框架，在推理时实现细粒度控制，解决了扩散编辑模型中编辑强度连续控制的关键问题

Abstract: Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt adherence, suggesting it as a potential control for edit intensity in editing models. However, we show that scaling CFG in these models does not produce a smooth transition between the input and the edited result. We attribute this behavior to the unconditional prediction, which serves as the guidance origin and dominates the generation at low guidance scales, while representing an arbitrary manipulation of the input content. To enable continuous control, we introduce Adaptive-Origin Guidance (AdaOr), a method that adjusts this standard guidance origin with an identity-conditioned adaptive origin, using an identity instruction corresponding to the identity manipulation. By interpolating this identity prediction with the standard unconditional prediction according to the edit strength, we ensure a continuous transition from the input to the edited result. We evaluate our method on image and video editing tasks, demonstrating that it provides smoother and more consistent control compared to current slider-based editing approaches. Our method incorporates an identity instruction into the standard training framework, enabling fine-grained control at inference time without per-edit procedure or reliance on specialized datasets.

</details>


### [66] [EventNeuS: 3D Mesh Reconstruction from a Single Event Camera](https://arxiv.org/abs/2602.03847)
*Shreyas Sachan,Viktor Rudnev,Mohamed Elgharib,Christian Theobalt,Vladislav Golyanik*

Main category: cs.CV

TL;DR: EventNeuS：首个结合SDF和密度场学习的自监督神经模型，从单目彩色事件流中学习3D表示，显著提升事件相机的3D重建精度


<details>
  <summary>Details</summary>
Motivation: 事件相机在许多场景中比RGB相机更有优势，但现有事件相机3D重建技术精度严重受限，密集3D网格重建研究较少

Method: 1. 首次将3D有符号距离函数和密度场学习与事件监督相结合
2. 引入球谐函数编码以增强处理视角相关效果的能力
3. 自监督神经模型从单目彩色事件流学习3D表示

Result: 显著优于现有方法：平均Chamfer距离降低34%，平均绝对误差降低31%，相比之前最佳方法

Conclusion: EventNeuS通过创新性地结合SDF、密度场学习和事件监督，显著提升了事件相机的3D重建精度，为事件相机在3D重建领域的应用提供了有力工具

Abstract: Event cameras offer a considerable alternative to RGB cameras in many scenarios. While there are recent works on event-based novel-view synthesis, dense 3D mesh reconstruction remains scarcely explored and existing event-based techniques are severely limited in their 3D reconstruction accuracy. To address this limitation, we present EventNeuS, a self-supervised neural model for learning 3D representations from monocular colour event streams. Our approach, for the first time, combines 3D signed distance function and density field learning with event-based supervision. Furthermore, we introduce spherical harmonics encodings into our model for enhanced handling of view-dependent effects. EventNeuS outperforms existing approaches by a significant margin, achieving 34% lower Chamfer distance and 31% lower mean absolute error on average compared to the best previous method.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [67] [Design and Evaluation of Whole-Page Experience Optimization for E-commerce Search](https://arxiv.org/abs/2602.02514)
*Pratik Lahiri,Bingqing Ge,Zhou Qin,Aditya Jumde,Shuning Huo,Lucas Scottini,Yi Liu,Mahmoud Mamlouk,Wenyang Liu*

Main category: cs.IR

TL;DR: 提出一个全页面体验优化框架，解决电商搜索结果页从线性列表向复杂非线性布局转变带来的挑战，同时优化长期用户满意度指标。


<details>
  <summary>Details</summary>
Motivation: 电商搜索结果页正从线性列表演变为复杂的非线性布局，传统基于位置的排序模型已不适用。现有优化框架通常只最大化短期信号（如点击、当日收入），而长期满意度指标（如预期两周收入）涉及延迟反馈和长期信用分配挑战。

Method: 提出全页面体验优化框架，明确建模商品相关性、2D位置布局和视觉元素之间的相互作用。使用因果框架基于准实验数据开发长期用户满意度度量指标。

Result: 通过行业规模的A/B测试验证，模型在品牌相关性（主要客户体验指标）上提升了1.86%，同时实现了+0.05%的统计显著收入提升。

Conclusion: 该框架成功解决了电商搜索结果页布局复杂化和长期满意度优化的问题，为电商搜索体验优化提供了有效解决方案。

Abstract: E-commerce Search Results Pages (SRPs) are evolving from linear lists to complex, non-linear layouts, rendering traditional position-biased ranking models insufficient. Moreover, existing optimization frameworks typically maximize short-term signals (e.g., clicks, same-day revenue) because long-term satisfaction metrics (e.g., expected two-week revenue) involve delayed feedback and challenging long-horizon credit attribution. To bridge these gaps, we propose a novel Whole-Page Experience Optimization Framework. Unlike traditional list-wise rankers, our approach explicitly models the interplay between item relevance, 2D positional layout, and visual elements. We use a causal framework to develop metrics for measuring long-term user satisfaction based on quasi-experimental data. We validate our approach through industry-scale A/B testing, where the model demonstrated a 1.86% improvement in brand relevance (our primary customer experience metric) while simultaneously achieving a statistically significant revenue uplift of +0.05%

</details>


### [68] [Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval](https://arxiv.org/abs/2602.02827)
*Roi Pony,Adi Raz,Oshri Naparstek,Idan Friedman,Udi Barzelay*

Main category: cs.IR

TL;DR: Col-Bandit是一种查询时剪枝算法，通过将重排序建模为有限总体Top-K识别问题，自适应地揭示必要的MaxSim条目，在保持排序质量的同时将计算量减少5倍。


<details>
  <summary>Details</summary>
Motivation: 多向量延迟交互检索器（如ColBERT）虽然检索质量优秀，但查询时计算成本过高，需要为每个候选文档计算token级别的MaxSim交互。现有单向量近似方法虽然降低了成本，但往往导致显著的准确率损失。

Method: Col-Bandit将重排序建模为有限总体Top-K识别问题，维护部分观察文档分数的不确定性感知边界，自适应地揭示必要的（文档，查询token）MaxSim条目，在统计决策边界下确定top结果。该方法作为零样本、即插即用层运行在标准多向量系统之上，无需索引修改、离线预处理或模型重训练。

Result: 在文本（BEIR）和多模态（REAL-MM-RAG）基准测试中，Col-Bandit在保持排序保真度的同时，将MaxSim FLOPs减少了高达5倍，表明密集延迟交互评分存在大量冗余，可以在查询时高效识别和剪枝。

Conclusion: Col-Bandit通过查询时自适应剪枝，有效解决了多向量延迟交互检索器的计算效率问题，在保持检索质量的同时显著降低了计算成本，为高效检索系统提供了实用解决方案。

Abstract: Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-$K$ identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5$\times$, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time.

</details>


### [69] [Efficiency Optimizations for Superblock-based Sparse Retrieval](https://arxiv.org/abs/2602.02883)
*Parker Carlson,Wentai Xie,Rohil Shah,Tao Yang*

Main category: cs.IR

TL;DR: 本文提出了一种简单有效的超级块剪枝方案，用于学习型稀疏检索（LSR），通过减少超级块分数计算开销同时保持竞争力，结合紧凑索引结构和零配置方法，在MS MARCO和BEIR数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 学习型稀疏检索（LSR）结合了语言模型的语义匹配和高效的CPU友好算法，成为流行的第一阶段检索方法。先前工作通过将块聚合成"超级块"并使用高级剪枝启发式方法快速跳过块的访问，但存在计算开销问题。

Method: 提出简单有效的超级块剪枝方案，减少超级块分数计算开销；结合紧凑索引结构；采用鲁棒的零配置方法，适用于不同LSR模型和多个数据集。

Result: 在MS MARCO和BEIR数据集上进行评估，证明该方案在保持竞争力的相关性的同时，显著减少了计算开销，成为高效稀疏检索的强有力替代方案。

Conclusion: 提出的超级块剪枝方案简单有效，结合紧凑索引和零配置方法，为学习型稀疏检索提供了高效且通用的解决方案，可作为高效稀疏检索的强有力替代方案。

Abstract: Learned sparse retrieval (LSR) is a popular method for first-stage retrieval because it combines the semantic matching of language models with efficient CPU-friendly algorithms. Previous work aggregates blocks into "superblocks" to quickly skip the visitation of blocks during query processing by using an advanced pruning heuristic. This paper proposes a simple and effective superblock pruning scheme that reduces the overhead of superblock score computation while preserving competitive relevance. It combines this scheme with a compact index structure and a robust zero-shot configuration that is effective across LSR models and multiple datasets. This paper provides an analytical justification and evaluation on the MS MARCO and BEIR datasets, demonstrating that the proposed scheme can be a strong alternative for efficient sparse retrieval.

</details>


### [70] [ALPBench: A Benchmark for Attribution-level Long-term Personal Behavior Understanding](https://arxiv.org/abs/2602.03056)
*Lu Ren,Junda She,Xinchen Luo,Tao Wang,Xin Ye,Xu Zhang,Muxuan Wang,Xiao Yang,Chenguang Wang,Fei Xie,Yiwei Zhou,Danjun Wu,Guodong Zhang,Yifei Hu,Guoying Zheng,Shujie Yang,Xingmei Wang,Shiyao Wang,Yukun Zhou,Fan Yang,Size Li,Kuo Cai,Qiang Luo,Ruiming Tang,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: ALPBench是一个用于评估大语言模型在个性化推荐中理解用户长期行为的基准测试，专注于预测用户感兴趣的属性组合而非具体物品。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在个性化推荐中展现潜力，但准确捕捉用户偏好仍是关键挑战。现有基准测试主要关注物品推荐，缺乏对用户长期行为理解的细粒度评估。

Method: 引入ALPBench基准测试，将用户历史行为表示为自然语言序列，预测用户感兴趣的属性组合而非具体物品，支持对新物品进行真实评估。

Result: ALPBench能够对个性化推荐进行细粒度评估，重点关注属性组合预测任务，这对当前大语言模型具有挑战性，需要捕捉多个属性间的复杂交互并推理长期用户行为序列。

Conclusion: ALPBench为评估大语言模型在理解用户长期行为方面的能力提供了系统框架，支持基于推理的可解释个性化推荐，有助于推动该领域的研究进展。

Abstract: Recent advances in large language models have highlighted their potential for personalized recommendation, where accurately capturing user preferences remains a key challenge. Leveraging their strong reasoning and generalization capabilities, LLMs offer new opportunities for modeling long-term user behavior. To systematically evaluate this, we introduce ALPBench, a Benchmark for Attribution-level Long-term Personal Behavior Understanding. Unlike item-focused benchmarks, ALPBench predicts user-interested attribute combinations, enabling ground-truth evaluation even for newly introduced items. It models preferences from long-term historical behaviors rather than users' explicitly expressed requests, better reflecting enduring interests. User histories are represented as natural language sequences, allowing interpretable, reasoning-based personalization. ALPBench enables fine-grained evaluation of personalization by focusing on the prediction of attribute combinations task that remains highly challenging for current LLMs due to the need to capture complex interactions among multiple attributes and reason over long-term user behavior sequences.

</details>


### [71] [PAMAS: Self-Adaptive Multi-Agent System with Perspective Aggregation for Misinformation Detection](https://arxiv.org/abs/2602.03158)
*Zongwei Wang,Min Gao,Junliang Yu,Tong Chen,Chenghua Lin*

Main category: cs.IR

TL;DR: PAMAS是一个基于多智能体系统的虚假信息检测框架，通过视角聚合机制解决传统多智能体系统中的信息淹没问题，提高检测准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的虚假信息对信息可信度构成严重威胁，其多样性和上下文依赖性使得检测变得复杂。传统多智能体系统存在信息淹没问题，即大量真实内容淹没了稀疏且微弱的欺骗线索，导致检测效果不佳。

Method: 提出PAMAS框架，采用层次化、视角感知的聚合机制来突出异常线索。系统包含三种角色：审计员从专业特征子集中捕获异常线索；协调员聚合这些视角以增强覆盖范围同时保持多样性；决策者配备演化记忆和完整上下文访问权限，综合所有下级洞察做出最终判断。此外，系统还包含自适应机制用于动态拓扑优化和基于路由的推理。

Result: 在多个基准数据集上的广泛实验表明，PAMAS在准确性和效率方面都表现出色，为虚假信息检测提供了可扩展且可信赖的方法。

Conclusion: PAMAS通过视角聚合机制有效解决了多智能体系统中的信息淹没问题，提高了虚假信息检测的性能，同时通过自适应机制增强了系统的效率和可扩展性。

Abstract: Misinformation on social media poses a critical threat to information credibility, as its diverse and context-dependent nature complicates detection. Large language model-empowered multi-agent systems (MAS) present a promising paradigm that enables cooperative reasoning and collective intelligence to combat this threat. However, conventional MAS suffer from an information-drowning problem, where abundant truthful content overwhelms sparse and weak deceptive cues. With full input access, agents tend to focus on dominant patterns, and inter-agent communication further amplifies this bias. To tackle this issue, we propose PAMAS, a multi-agent framework with perspective aggregation, which employs hierarchical, perspective-aware aggregation to highlight anomaly cues and alleviate information drowning. PAMAS organizes agents into three roles: Auditors, Coordinators, and a Decision-Maker. Auditors capture anomaly cues from specialized feature subsets; Coordinators aggregate their perspectives to enhance coverage while maintaining diversity; and the Decision-Maker, equipped with evolving memory and full contextual access, synthesizes all subordinate insights to produce the final judgment. Furthermore, to improve efficiency in multi-agent collaboration, PAMAS incorporates self-adaptive mechanisms for dynamic topology optimization and routing-based inference, enhancing both efficiency and scalability. Extensive experiments on multiple benchmark datasets demonstrate that PAMAS achieves superior accuracy and efficiency, offering a scalable and trustworthy way for misinformation detection.

</details>


### [72] [Distribution-Aware End-to-End Embedding for Streaming Numerical Features in Click-Through Rate Prediction](https://arxiv.org/abs/2602.03223)
*Jiahao Liu,Hongji Ruan,Weimin Zhang,Ziye Tong,Derick Tang,Zhanpeng Zeng,Qinsong Zeng,Peng Zhang,Tun Lu,Ning Gu*

Main category: cs.IR

TL;DR: DAES：面向流式训练场景的端到端数值特征嵌入框架，通过自适应调制机制整合分布信息，显著提升点击率预测性能


<details>
  <summary>Details</summary>
Motivation: 传统静态分箱方法依赖离线统计，存在语义漂移问题；神经嵌入方法虽支持端到端学习但忽略显式分布信息。流式环境中数值特征违反i.i.d.假设，且分布的关键上下文依赖性常被忽视

Method: 提出DAES框架：1）基于水库采样的高效分布估计方法；2）两种场感知分布调制策略，捕捉流式分布和场依赖语义

Result: DAES在离线和在线实验中显著优于现有方法，已在拥有数亿日活用户的领先短视频平台全面部署

Conclusion: DAES成功解决了流式训练中数值特征嵌入的挑战，通过整合分布信息和自适应调制机制，实现了端到端的高效学习

Abstract: This paper explores effective numerical feature embedding for Click-Through Rate prediction in streaming environments. Conventional static binning methods rely on offline statistics of numerical distributions; however, this inherently two-stage process often triggers semantic drift during bin boundary updates. While neural embedding methods enable end-to-end learning, they often discard explicit distributional information. Integrating such information end-to-end is challenging because streaming features often violate the i.i.d. assumption, precluding unbiased estimation of the population distribution via the expectation of order statistics. Furthermore, the critical context dependency of numerical distributions is often neglected. To this end, we propose DAES, an end-to-end framework designed to tackle numerical feature embedding in streaming training scenarios by integrating distributional information with an adaptive modulation mechanism. Specifically, we introduce an efficient reservoir-sampling-based distribution estimation method and two field-aware distribution modulation strategies to capture streaming distributions and field-dependent semantics. DAES significantly outperforms existing approaches as demonstrated by extensive offline and online experiments and has been fully deployed on a leading short-video platform with hundreds of millions of daily active users.

</details>


### [73] [Learning to Select: Query-Aware Adaptive Dimension Selection for Dense Retrieval](https://arxiv.org/abs/2602.03306)
*Zhanyu Wu,Richong Zhang,Zhijie Nie*

Main category: cs.IR

TL;DR: 本文提出了一种查询感知自适应维度选择框架，通过学习从查询嵌入直接预测每个维度的重要性，无需伪相关反馈，提高了密集检索的效果。


<details>
  <summary>Details</summary>
Motivation: 密集检索将查询和文档表示为高维嵌入，但这些表示在查询级别可能存在冗余：对于给定的信息需求，只有部分维度对排序有帮助。现有方法要么依赖噪声伪相关反馈信号，要么学习全局变换而不显式建模查询感知的维度重要性。

Method: 提出查询感知自适应维度选择框架：1）使用监督相关性标签构建嵌入维度的oracle维度重要性分布；2）训练预测器将查询嵌入映射到这些标签蒸馏的重要性分数；3）在推理时，预测器仅基于查询嵌入选择查询感知的维度子集进行相似度计算。

Result: 在多个密集检索器和基准测试上的实验表明，学习的维度选择器在检索效果上优于全维度基线、基于PRF的掩码方法和监督适配器基线。

Conclusion: 该框架能够直接学习从查询嵌入预测维度重要性，无需伪相关反馈，有效提高了密集检索的性能，为查询感知的维度选择提供了新思路。

Abstract: Dense retrieval represents queries and docu-002 ments as high-dimensional embeddings, but003 these representations can be redundant at the004 query level: for a given information need, only005 a subset of dimensions is consistently help-006 ful for ranking. Prior work addresses this via007 pseudo-relevance feedback (PRF) based dimen-008 sion importance estimation, which can produce009 query-aware masks without labeled data but010 often relies on noisy pseudo signals and heuris-011 tic test-time procedures. In contrast, super-012 vised adapter methods leverage relevance labels013 to improve embedding quality, yet they learn014 global transformations shared across queries015 and do not explicitly model query-aware di-016 mension importance. We propose a Query-017 Aware Adaptive Dimension Selection frame-018 work that learns to predict per-dimension im-019 portance directly from query embedding. We020 first construct oracle dimension importance dis-021 tributions over embedding dimensions using022 supervised relevance labels, and then train a023 predictor to map a query embedding to these024 label-distilled importance scores. At inference,025 the predictor selects a query-aware subset of026 dimensions for similarity computation based027 solely on the query embedding, without pseudo-028 relevance feedback. Experiments across multi-029 ple dense retrievers and benchmarks show that030 our learned dimension selector improves re-031 trieval effectiveness over the full-dimensional032 baseline as well as PRF-based masking and033 supervised adapter baselines.

</details>


### [74] [SCASRec: A Self-Correcting and Auto-Stopping Model for Generative Route List Recommendation](https://arxiv.org/abs/2602.03324)
*Chao Chen,Longfei Xu,Daohan Su,Tengfei Liu,Hanyu Guo,Yihai Duan,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: SCASRec是一个统一的生成式推荐框架，将排序和冗余消除集成到端到端过程中，解决了多阶段推荐系统的三个关键限制：离线/在线指标不对齐、冗余消除规则僵化、排序阶段分离导致的次优性能。


<details>
  <summary>Details</summary>
Motivation: 传统多阶段推荐系统存在三个关键问题：1) 离线训练目标与在线指标不对齐，离线增益不一定转化为在线改进；2) 冗余消除依赖僵化的手工规则，无法适应用户意图的高方差和现实场景的复杂性；3) 精细排序和重排序阶段的严格分离导致次优性能，各模块孤立优化无法实现全局最优。

Method: 提出SCASRec统一生成框架，将排序和冗余消除集成到端到端过程中。引入逐步校正奖励(SCR)通过关注困难样本来指导列表级优化，并使用可学习的推荐结束(EOR)令牌在预期无进一步改进时自适应终止生成。

Result: 在两个大规模开源路线推荐数据集上的实验表明，SCASRec在离线和在线设置中都达到了最先进水平。该模型已在真实世界导航应用中全面部署，证明了其有效性。

Conclusion: SCASRec通过统一的端到端生成框架成功解决了传统多阶段推荐系统的三个关键限制，实现了更好的离线/在线性能对齐、自适应冗余消除和全局优化，为实际推荐系统提供了有效的解决方案。

Abstract: Route recommendation systems commonly adopt a multi-stage pipeline involving fine-ranking and re-ranking to produce high-quality ordered recommendations. However, this paradigm faces three critical limitations. First, there is a misalignment between offline training objectives and online metrics. Offline gains do not necessarily translate to online improvements. Actual performance must be validated through A/B testing, which may potentially compromise the user experience. Second, redundancy elimination relies on rigid, handcrafted rules that lack adaptability to the high variance in user intent and the unstructured complexity of real-world scenarios. Third, the strict separation between fine-ranking and re-ranking stages leads to sub-optimal performance. Since each module is optimized in isolation, the fine-ranking stage remains oblivious to the list-level objectives (e.g., diversity) targeted by the re-ranker, thereby preventing the system from achieving a jointly optimized global optimum. To overcome these intertwined challenges, we propose \textbf{SCASRec} (\textbf{S}elf-\textbf{C}orrecting and \textbf{A}uto-\textbf{S}topping \textbf{Rec}ommendation), a unified generative framework that integrates ranking and redundancy elimination into a single end-to-end process. SCASRec introduces a stepwise corrective reward (SCR) to guide list-wise refinement by focusing on hard samples, and employs a learnable End-of-Recommendation (EOR) token to terminate generation adaptively when no further improvement is expected. Experiments on two large-scale, open-sourced route recommendation datasets demonstrate that SCASRec establishes an SOTA in offline and online settings. SCASRec has been fully deployed in a real-world navigation app, demonstrating its effectiveness.

</details>


### [75] [Beyond Exposure: Optimizing Ranking Fairness with Non-linear Time-Income Functions](https://arxiv.org/abs/2602.03345)
*Xuancheng Li,Tao Yang,Yujia Zhou,Qingyao Ai,Yiqun Liu*

Main category: cs.IR

TL;DR: 该论文提出了一种新的收入公平性概念，用于解决现有曝光公平性仅考虑位置因素而忽略时间等其他影响收入因素的局限性，并开发了相应的度量指标和优化算法。


<details>
  <summary>Details</summary>
Motivation: 当前排名优化中，曝光公平性主要依赖位置决定曝光，忽略了时间等其他显著影响收入的因素，导致公平性概念不完整，无法准确反映项目提供者的实际收入公平。

Method: 提出收入公平性的正式定义和度量指标，开发基于动态收入导数的排名公平算法（DIDRF），利用当前时间步的边际收入增益和基于泰勒展开的梯度来同时优化效果和收入公平。

Result: 模拟实验显示，现有基于曝光公平性的排名算法无法优化收入公平性。在具有不同时间-收入函数的离线和在线设置中，DIDRF算法始终优于最先进的方法。

Conclusion: 收入公平性比传统的曝光公平性更全面地考虑了影响提供者收入的因素，DIDRF算法能有效同时优化排名效果和收入公平性，为实际应用提供了更好的解决方案。

Abstract: Ranking is central to information distribution in web search and recommendation. Nowadays, in ranking optimization, the fairness to item providers is viewed as a crucial factor alongside ranking relevance for users. There are currently numerous concepts of fairness and one widely recognized fairness concept is Exposure Fairness. However, it relies primarily on exposure determined solely by position, overlooking other factors that significantly influence income, such as time. To address this limitation, we propose to study ranking fairness when the provider utility is influenced by other contextual factors and is neither equal to nor proportional to item exposure. We give a formal definition of Income Fairness and develop a corresponding measurement metric. Simulated experiments show that existing-exposure-fairness-based ranking algorithms fail to optimize the proposed income fairness. Therefore, we propose the Dynamic-Income-Derivative-aware Ranking Fairness algorithm, which, based on the marginal income gain at the present timestep, uses Taylor-expansion-based gradients to simultaneously optimize effectiveness and income fairness. In both offline and online settings with diverse time-income functions, DIDRF consistently outperforms state-of-the-art methods.

</details>


### [76] [AesRec: A Dataset for Aesthetics-Aligned Clothing Outfit Recommendation](https://arxiv.org/abs/2602.03416)
*Wenxin Ye,Lin Li,Ming Li,Yang Shen,Kanghong Wang,Jimmy Xiangji Huang*

Main category: cs.IR

TL;DR: 该论文提出了AesRec基准数据集，通过系统化的定量美学标注来增强服装推荐系统，将美学维度纳入推荐过程，超越了传统的用户-物品交互模式。


<details>
  <summary>Details</summary>
Motivation: 现有服装推荐方法主要依赖用户-物品-搭配交互行为，忽视了服装美学的显式表示。服装推荐不仅是生成个性化搭配，更是提供美学指导的重要媒介，因此需要建立美学对齐的推荐系统。

Method: 基于专业服装质量标准和时尚美学原则，定义多维美学指标：单品层面评估轮廓、色彩、材质、工艺、穿着性和单品印象6个维度；搭配层面保留前5个核心属性，新增风格协同、视觉和谐和搭配印象3个指标。利用视觉语言模型进行大规模美学评分，并在时尚数据集上进行严格的人机一致性验证。

Result: 通过人机一致性验证确认了生成评分的可靠性。基于AesRec的实验结果表明，将量化的美学信息整合到服装推荐模型中，可以在满足用户个性化需求的同时提供美学指导。

Conclusion: AesRec基准数据集填补了现有服装推荐方法中美学表示的空白，通过系统化的美学标注实现了美学对齐的推荐系统，为同时满足个性化需求和美学指导提供了有效途径。

Abstract: Clothing recommendation extends beyond merely generating personalized outfits; it serves as a crucial medium for aesthetic guidance. However, existing methods predominantly rely on user-item-outfit interaction behaviors while overlooking explicit representations of clothing aesthetics. To bridge this gap, we present the AesRec benchmark dataset featuring systematic quantitative aesthetic annotations, thereby enabling the development of aesthetics-aligned recommendation systems. Grounded in professional apparel quality standards and fashion aesthetic principles, we define a multidimensional set of indicators. At the item level, six dimensions are independently assessed: silhouette, chromaticity, materiality, craftsmanship, wearability, and item-level impression. Transitioning to the outfit level, the evaluation retains the first five core attributes while introducing stylistic synergy, visual harmony, and outfit-level impression as distinct metrics to capture the collective aesthetic impact. Given the increasing human-like proficiency of Vision-Language Models in multimodal understanding and interaction, we leverage them for large-scale aesthetic scoring. We conduct rigorous human-machine consistency validation on a fashion dataset, confirming the reliability of the generated ratings. Experimental results based on AesRec further demonstrate that integrating quantified aesthetic information into clothing recommendation models can provide aesthetic guidance for users while fulfilling their personalized requirements.

</details>


### [77] [RankSteer: Activation Steering for Pointwise LLM Ranking](https://arxiv.org/abs/2602.03422)
*Yumeng Wang,Catherine Chen,Suzan Verberne*

Main category: cs.IR

TL;DR: RankSteer：通过激活向量控制提升LLM零样本排序性能的后处理框架，无需修改模型权重或复杂提示工程


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为零样本排序器性能对提示工程敏感，特别是角色扮演指令。研究发现角色相关信号与查询-文档表示在激活通道上分离，这为直接在激活层面控制排序行为提供了可能

Method: 提出RankSteer后处理激活控制框架，在表示空间中解耦出三个可控制方向：决策方向（映射隐藏状态到相关性分数）、证据方向（捕获未被决策头利用的相关性信号）、角色方向（调节模型行为但不注入相关性信息）。通过推理时的投影干预联合控制这些方向

Result: 在TREC DL 20和多个BEIR基准测试中，RankSteer仅使用少量锚点查询就能一致提升排序质量，表明点式LLM排序器中存在大量未被充分利用的排序能力。几何分析显示控制通过稳定排序几何和减少离散度来改进排序

Conclusion: 激活层面控制为改进LLM排序器提供了一种有前景的替代方案，无需修改模型权重或引入显式的跨文档比较。研究揭示了LLM内部如何表示和校准相关性判断的新见解

Abstract: Large language models (LLMs) have recently shown strong performance as zero-shot rankers, yet their effectiveness is highly sensitive to prompt formulation, particularly role-play instructions. Prior analyses suggest that role-related signals are encoded along activation channels that are largely separate from query-document representations, raising the possibility of steering ranking behavior directly at the activation level rather than through brittle prompt engineering. In this work, we propose RankSteer, a post-hoc activation steering framework for zero-shot pointwise LLM ranking. We characterize ranking behavior through three disentangled and steerable directions in representation space: a \textbf{decision direction} that maps hidden states to relevance scores, an \textbf{evidence direction} that captures relevance signals not directly exploited by the decision head, and a \textbf{role direction} that modulates model behavior without injecting relevance information. Using projection-based interventions at inference time, RankSteer jointly controls these directions to calibrate ranking behavior without modifying model weights or introducing explicit cross-document comparisons. Experiments on TREC DL 20 and multiple BEIR benchmarks show that RankSteer consistently improves ranking quality using only a small number of anchor queries, demonstrating that substantial ranking capacity remains under-utilized in pointwise LLM rankers. We further provide a geometric analysis revealing that steering improves ranking by stabilizing ranking geometry and reducing dispersion, offering new insight into how LLMs internally represent and calibrate relevance judgments.

</details>


### [78] [Tutorial on Reasoning for IR & IR for Reasoning](https://arxiv.org/abs/2602.03640)
*Mohanna Hoveyda,Panagiotis Efstratiadis,Arjen de Vries,Maarten de Rijke*

Main category: cs.IR

TL;DR: 该教程为信息检索领域提出了一个统一的推理分析框架，将跨学科的研究方法映射到核心维度上，帮助IR研究者理解不同推理方法的权衡与互补关系。


<details>
  <summary>Details</summary>
Motivation: 传统信息检索主要关注语义相关性排序，但现实信息需求需要逻辑约束、多步推理和证据合成等推理能力。当前AI社区中的推理研究分散在不同学科，IR研究者难以识别最相关的思路和机会。

Method: 首先在信息检索背景下明确定义推理概念，并从中推导出统一的分析框架。该框架将现有方法映射到反映定义核心组件的多个维度上，提供全面的方法概述和映射分析。

Result: 通过框架分析揭示了不同推理方法的权衡与互补关系，展示了IR如何从跨学科进展中受益，以及检索过程本身如何在更广泛的推理系统中发挥核心作用。

Conclusion: 该教程为参与者提供了概念框架和实践指导，用于增强具备推理能力的IR系统，同时将IR定位为既受益于又能贡献于更广泛推理方法发展的领域。

Abstract: Information retrieval has long focused on ranking documents by semantic relatedness. Yet many real-world information needs demand more: enforcement of logical constraints, multi-step inference, and synthesis of multiple pieces of evidence. Addressing these requirements is, at its core, a problem of reasoning. Across AI communities, researchers are developing diverse solutions for the problem of reasoning, from inference-time strategies and post-training of LLMs, to neuro-symbolic systems, Bayesian and probabilistic frameworks, geometric representations, and energy-based models. These efforts target the same problem: to move beyond pattern-matching systems toward structured, verifiable inference. However, they remain scattered across disciplines, making it difficult for IR researchers to identify the most relevant ideas and opportunities. To help navigate the fragmented landscape of research in reasoning, this tutorial first articulates a working definition of reasoning within the context of information retrieval and derives from it a unified analytical framework. The framework maps existing approaches along axes that reflect the core components of the definition. By providing a comprehensive overview of recent approaches and mapping current methods onto the defined axes, we expose their trade-offs and complementarities, highlight where IR can benefit from cross-disciplinary advances, and illustrate how retrieval process itself can play a central role in broader reasoning systems. The tutorial will equip participants with both a conceptual framework and practical guidance for enhancing reasoning-capable IR systems, while situating IR as a domain that both benefits and contributes to the broader development of reasoning methodologies.

</details>


### [79] [Bringing Reasoning to Generative Recommendation Through the Lens of Cascaded Ranking](https://arxiv.org/abs/2602.03692)
*Xinyu Lin,Pengyuan Liu,Wenjie Wang,Yicheng Hu,Chen Xu,Fuli Feng,Qifan Wang,Tat-Seng Chua*

Main category: cs.IR

TL;DR: CARE框架通过渐进式历史编码和查询锚定推理机制解决生成式推荐中的偏差放大问题，提高推荐多样性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐模型存在偏差放大问题，随着token生成过程推进，token级偏差会不断放大，限制了推荐多样性并损害用户体验。与传统多阶段流水线相比，生成式推荐存在两个局限性：对编码历史的同质依赖，以及固定的计算预算阻碍了更深层次的用户偏好理解。

Method: 提出CARE框架，包含两个核心机制：1) 渐进式历史编码机制，随着生成过程推进逐步纳入更细粒度的历史信息；2) 查询锚定推理机制，通过并行推理步骤对历史信息进行更深层次理解，分配更多计算资源。

Result: 在三个生成式推荐骨干模型上实例化CARE，在四个数据集上的实验结果表明，CARE在推荐准确性、多样性、效率和可扩展性方面均表现出优越性。

Conclusion: CARE框架通过引入异构信息和动态计算资源分配，有效解决了生成式推荐中的偏差放大问题，提高了推荐系统的整体性能。

Abstract: Generative Recommendation (GR) has become a promising end-to-end approach with high FLOPS utilization for resource-efficient recommendation. Despite the effectiveness, we show that current GR models suffer from a critical \textbf{bias amplification} issue, where token-level bias escalates as token generation progresses, ultimately limiting the recommendation diversity and hurting the user experience. By comparing against the key factor behind the success of traditional multi-stage pipelines, we reveal two limitations in GR that can amplify the bias: homogeneous reliance on the encoded history, and fixed computational budgets that prevent deeper user preference understanding.
  To combat the bias amplification issue, it is crucial for GR to 1) incorporate more heterogeneous information, and 2) allocate greater computational resources at each token generation step. To this end, we propose CARE, a simple yet effective cascaded reasoning framework for debiased GR. To incorporate heterogeneous information, we introduce a progressive history encoding mechanism, which progressively incorporates increasingly fine-grained history information as the generation process advances. To allocate more computations, we propose a query-anchored reasoning mechanism, which seeks to perform a deeper understanding of historical information through parallel reasoning steps. We instantiate CARE on three GR backbones. Empirical results on four datasets show the superiority of CARE in recommendation accuracy, diversity, efficiency, and promising scalability. The codes and datasets are available at https://github.com/Linxyhaha/CARE.

</details>


### [80] [Multimodal Generative Recommendation for Fusing Semantic and Collaborative Signals](https://arxiv.org/abs/2602.03713)
*Moritz Vandenhirtz,Kaveh Hassani,Shervin Ghasemlou,Shuai Shao,Hamid Eghbalzadeh,Fuchun Peng,Jun Liu,Michael Louis Iuzzolino*

Main category: cs.IR

TL;DR: MSCGRec是一种多模态语义和协作生成推荐系统，通过结合多种语义模态、自监督量化学习和协作特征融合，在大型数据集上超越了传统序列推荐和生成推荐方法。


<details>
  <summary>Details</summary>
Motivation: 传统生成推荐方法虽然通过离散语义编码减少内存开销，但在大型项目集上表现不如传统序列推荐方法，限制了其在实际应用中的采用。

Method: 1) 结合多模态语义信息；2) 基于DINO框架的图像自监督量化学习；3) 将序列推荐器提取的协作特征作为单独模态进行融合；4) 提出约束序列学习，在训练时限制输出空间到允许的标记集。

Result: 在三个大型真实世界数据集上，MSCGRec超越了序列推荐和生成推荐的基线方法，并通过广泛的消融研究验证了各组件的影响。

Conclusion: MSCGRec通过多模态语义融合、协作特征集成和约束序列学习，成功解决了生成推荐在大型项目集上的性能瓶颈，为生成推荐的实际应用提供了有效解决方案。

Abstract: Sequential recommender systems rank relevant items by modeling a user's interaction history and computing the inner product between the resulting user representation and stored item embeddings. To avoid the significant memory overhead of storing large item sets, the generative recommendation paradigm instead models each item as a series of discrete semantic codes. Here, the next item is predicted by an autoregressive model that generates the code sequence corresponding to the predicted item. However, despite promising ranking capabilities on small datasets, these methods have yet to surpass traditional sequential recommenders on large item sets, limiting their adoption in the very scenarios they were designed to address. To resolve this, we propose MSCGRec, a Multimodal Semantic and Collaborative Generative Recommender. MSCGRec incorporates multiple semantic modalities and introduces a novel self-supervised quantization learning approach for images based on the DINO framework. Additionally, MSCGRec fuses collaborative and semantic signals by extracting collaborative features from sequential recommenders and treating them as a separate modality. Finally, we propose constrained sequence learning that restricts the large output space during training to the set of permissible tokens. We empirically demonstrate on three large real-world datasets that MSCGRec outperforms both sequential and generative recommendation baselines and provide an extensive ablation study to validate the impact of each component.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [81] [UNSO: Unified Newton Schulz Orthogonalization](https://arxiv.org/abs/2602.02500)
*Chen Hu,Qianxi Zhao,Yuming Li,Mingyu Zhou,Xiyin Li*

Main category: cs.LG

TL;DR: 提出UNSO框架改进牛顿-舒尔茨正交化，通过可学习系数优化多项式，避免传统迭代范式中的重复矩阵乘积计算负担


<details>
  <summary>Details</summary>
Motivation: 传统牛顿-舒尔茨迭代在效率和稳定性方面存在不足，现有改进方法仍受限于传统迭代范式，导致沿长维度重复矩阵乘积计算负担大

Method: 将迭代结构整合为统一框架UNSO，避免多项式展开，评估各矩阵幂次作用，移除不重要项，提供带可学习系数的推荐多项式，优化这些系数

Result: 方法实现了出色的性能和稳定收敛，代码已开源

Conclusion: UNSO框架通过可学习系数优化多项式，有效解决了传统牛顿-舒尔茨迭代的效率和稳定性问题

Abstract: The Newton-Schulz (NS) iteration has gained increasing interest for its role in the Muon optimizer and the Stiefel manifold. However, the conventional NS iteration suffers from inefficiency and instability. Although various improvements have been introduced to NS iteration, they fail to deviate from the conventional iterative paradigm, which could increase computation burden largely due to the matrix products along the long dimension repeatedly. To address this, we consolidate the iterative structure into a unified framework, named Unified Newton-Schulz Orthogonalization (UNSO). To do so, we could avoid a polynomial expansion. Instead, we evaluate the role of each matrix power, remove the insignificant terms, and provide a recommended polynomial with learnable coefficients. These learnable coefficients are then optimized, and achieve an outstanding performance with stable convergence. The code of our method is available: https://github.com/greekinRoma/Unified_Newton_Schulz_Orthogonalization.

</details>


### [82] [Variational Sparse Paired Autoencoders (vsPAIR) for Inverse Problems and Uncertainty Quantification](https://arxiv.org/abs/2602.02948)
*Jack Michael Solomon,Rishi Leburu,Matthias Chung*

Main category: cs.LG

TL;DR: vsPAIR是一种用于逆问题的变分稀疏配对自编码器，能够提供可解释的结构化不确定性估计


<details>
  <summary>Details</summary>
Motivation: 逆问题在科学和工程中普遍存在，需要从噪声测量中重建隐藏量。许多应用不仅需要点估计，还需要可解释的不确定性。提供快速推理和不确定性估计在许多应用中具有挑战性但很必要。

Method: 提出变分稀疏配对自编码器(vsPAIR)，将标准VAE编码观测与稀疏VAE编码感兴趣量配对，通过学习的潜在映射连接。采用硬混凝土尖峰-平板松弛实现可微分训练，使用beta超先验实现自适应稀疏度。

Result: 在盲修复和计算机断层扫描实验中验证了vsPAIR的有效性，证明其能够作为逆问题求解器提供可解释的结构化不确定性估计。

Conclusion: vsPAIR通过变分结构实现不确定性估计，配对架构通过将感兴趣量表示锚定到干净数据来增强可解释性，稀疏编码通过将信息集中到可识别因子中提供结构。

Abstract: Inverse problems are fundamental to many scientific and engineering disciplines; they arise when one seeks to reconstruct hidden, underlying quantities from noisy measurements. Many applications demand not just point estimates but interpretable uncertainty. Providing fast inference alongside uncertainty estimates remains challenging yet desirable in numerous applications.
  We propose the Variational Sparse Paired Autoencoder (vsPAIR) to address this challenge. The architecture pairs a standard VAE encoding observations with a sparse VAE encoding quantities of interest, connected through a learned latent mapping. The variational structure enables uncertainty estimation, the paired architecture encourages interpretability by anchoring QoI representations to clean data, and sparse encodings provide structure by concentrating information into identifiable factors rather than diffusing across all dimensions. We also propose modifications to existing sparse VAE methods: a hard-concrete spike-and-slab relaxation for differentiable training and a beta hyperprior for adaptive sparsity levels. To validate the effectiveness of our proposed architecture, we conduct experiments on blind inpainting and computed tomography, demonstrating that vsPAIR is a capable inverse problem solver that can provide interpretable and structured uncertainty estimates.

</details>


### [83] [Sparse Adapter Fusion for Continual Learning in NLP](https://arxiv.org/abs/2602.02502)
*Min Zeng,Xi Chen,Haiqin Yang,Yike Guo*

Main category: cs.LG

TL;DR: SAFM是一种稀疏适配器融合方法，通过动态融合新旧适配器解决持续学习中的参数效率问题，在保持性能的同时减少60%以上的参数使用。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法面临参数重用效率低、任务相似性差时易发生灾难性遗忘、以及为每个任务不必要地引入新参数阻碍知识共享等问题。

Method: SAFM采用两阶段方法：决策阶段决定是否引入新适配器、重用现有适配器或添加空适配器；调优阶段采用分层损失促进适配器间的差异化，有效捕获任务内知识。

Result: 实验结果表明SAFM优于现有SOTA方法，在保持相当性能的同时使用不到60%的参数。

Conclusion: SAFM通过动态融合适配器有效解决了持续学习中的参数效率和知识共享问题，实现了高效且性能优越的持续学习解决方案。

Abstract: Continual learning in natural language processing plays a crucial role in adapting to evolving data and preventing catastrophic forgetting. Despite significant progress, existing methods still face challenges, such as inefficient parameter reuse across tasks, risking catastrophic forgetting when tasks are dissimilar, and the unnecessary introduction of new parameters for each task, which hampers knowledge sharing among similar tasks. To tackle these issues, we propose a Sparse Adapter Fusion Method (SAFM), which dynamically fuses old and new adapters to address these challenges. SAFM operates in two stages: the decision stage and the tuning stage. In the decision stage, SAFM determines whether to incorporate a new adapter, reuse an existing one, or add an empty adapter. The architecture search procedure, designed to prioritize reusing or adding empty adapters, minimizes parameter consumption and maximizes reuse. In the tuning stage, SAFM especially facilitates a layer-wise loss to encourage differentiation between adapters, effectively capturing knowledge within the same task. Experimental results consistently show that SAFM outperforms state-of-the-art (SOTA) methods, achieving comparable performance while utilizing less than 60% of the parameters.

</details>


### [84] [FlashSinkhorn: IO-Aware Entropic Optimal Transport](https://arxiv.org/abs/2602.03067)
*Felix X. -F. Ye,Xingjie Li,An Yu,Ming-Ching Chang,Linsong Chu,Davis Wertheimer*

Main category: cs.LG

TL;DR: FlashSinkhorn是一个针对熵最优传输的高效GPU求解器，通过将Sinkhorn迭代重写为类似Transformer注意力的LogSumExp归约，实现FlashAttention风格的融合和分块，大幅减少内存访问，在A100上相比现有方法实现32倍前向和161倍端到端加速。


<details>
  <summary>Details</summary>
Motivation: 当前熵最优传输的GPU求解器效率低下：张量化实现存在二次内存访问开销，而现有的在线后端虽然避免存储稠密矩阵，但仍依赖通用的分块归约核，融合能力有限。需要一种IO感知的高效求解器来提升大规模计算性能。

Method: 将稳定化对数域Sinkhorn更新重写为带偏置点积分数的行向LogSumExp归约，这与Transformer注意力机制相同。采用FlashAttention风格的融合和分块技术：融合的Triton核通过片上SRAM流式处理分块，并在单次遍历中更新对偶势，大幅减少每次迭代的HBM IO，同时保持线性内存操作。还提供了传输应用的流式核，支持可扩展的一阶和二阶优化。

Result: 在A100 GPU上，FlashSinkhorn在点云最优传输任务上相比最先进的在线基线实现了高达32倍的前向加速和161倍的端到端加速。在基于最优传输的下游任务中提升了可扩展性。开源实现已发布。

Conclusion: FlashSinkhorn通过将熵最优传输计算重新表述为类似Transformer注意力的操作，并应用IO感知的融合分块技术，显著提升了GPU上的计算效率，为大规模最优传输应用提供了高效的解决方案。

Abstract: Entropic optimal transport (EOT) via Sinkhorn iterations is widely used in modern machine learning, yet GPU solvers remain inefficient at scale. Tensorized implementations suffer quadratic HBM traffic from dense $n\times m$ interactions, while existing online backends avoid storing dense matrices but still rely on generic tiled map-reduce reduction kernels with limited fusion. We present \textbf{FlashSinkhorn}, an IO-aware EOT solver for squared Euclidean cost that rewrites stabilized log-domain Sinkhorn updates as row-wise LogSumExp reductions of biased dot-product scores, the same normalization as transformer attention. This enables FlashAttention-style fusion and tiling: fused Triton kernels stream tiles through on-chip SRAM and update dual potentials in a single pass, substantially reducing HBM IO per iteration while retaining linear-memory operations. We further provide streaming kernels for transport application, enabling scalable first- and second-order optimization. On A100 GPUs, FlashSinkhorn achieves up to $32\times$ forward-pass and $161\times$ end-to-end speedups over state-of-the-art online baselines on point-cloud OT, improves scalability on OT-based downstream tasks. For reproducibility, we release an open-source implementation at https://github.com/ot-triton-lab/ot_triton.

</details>


### [85] [Learning ORDER-Aware Multimodal Representations for Composite Materials Design](https://arxiv.org/abs/2602.02513)
*Xinyao Li,Hangwei Qian,Jingjing Li,Ivor Tsang*

Main category: cs.LG

TL;DR: ORDER是一个多模态预训练框架，通过建立序数性作为复合材料表征的核心原则，解决复合材料连续非线性设计空间在极端数据稀缺下的表征学习问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于图表示的材料发现方法在复合材料上失效，因为复合材料具有连续非线性设计空间，缺乏明确的图结构。现有多模态框架基于离散、唯一的图-属性映射假设，无法处理极端数据稀缺下的高度连续复合材料设计空间。

Method: 提出ORDinal-aware imagE-tabulaR alignment (ORDER)多模态预训练框架，将序数性作为复合材料表征的核心原则，确保具有相似目标属性的材料在潜在空间中占据相邻区域，从而保留复合材料属性的连续性质，并能在稀疏观测的设计之间进行有意义的插值。

Result: 在公开的纳米纤维增强复合材料数据集和内部构建的模拟碳纤维T700数据集上，ORDER在属性预测、跨模态检索和微观结构生成任务上均优于最先进的多模态基线方法。

Conclusion: ORDER通过建立序数性作为复合材料表征的核心原则，成功解决了复合材料连续设计空间在极端数据稀缺下的多模态学习问题，为复合材料发现提供了有效的表征学习框架。

Abstract: Artificial intelligence (AI) has shown remarkable success in materials discovery and property prediction, particularly for crystalline and polymer systems where material properties and structures are dominated by discrete graph representations. Such graph-central paradigm breaks down on composite materials, which possess continuous and nonlinear design spaces that lack well-defined graph structures. General composite descriptors, e.g., fiber volume and misalignment angle, cannot fully capture the fiber distributions that fundamentally determine microstructural characteristics, necessitating the integration of heterogeneous data sources through multimodal learning. Existing alignment-oriented multimodal frameworks have proven effective on abundant crystal or polymer data under discrete, unique graph-property mapping assumptions, but fail to address the highly continuous composite design space under extreme data scarcity. In this work, we introduce ORDinal-aware imagE-tabulaR alignment (ORDER), a multimodal pretraining framework that establishes ordinality as a core principle for composite material representations. ORDER ensures that materials with similar target properties occupy nearby regions in the latent space, which effectively preserves the continuous nature of composite properties and enables meaningful interpolation between sparsely observed designs. We evaluate ORDER on a public Nanofiber-enforced composite dataset and an internally curated dataset that simulates the construction of carbon fiber T700 with diverse fiber distributions. ORDER achieves consistent improvements over state-of-the-art multimodal baselines across property prediction, cross-modal retrieval, and microstructure generation tasks.

</details>


### [86] [GraphDancer: Training LLMs to Explore and Reason over Graphs via Curriculum Reinforcement Learning](https://arxiv.org/abs/2602.02518)
*Yuyang Bai,Zhuofeng Li,Ping Nie,Jianwen Xie,Yu Zhang*

Main category: cs.LG

TL;DR: GraphDancer：基于强化学习的框架，教LLM通过交替推理和函数执行来导航异构图，实现跨域泛化


<details>
  <summary>Details</summary>
Motivation: 现实世界知识源通常以异构图而非纯文本形式组织，LLM需要精确的函数调用而非基于相似性的检索来导航结构化关系，复杂问题需要多跳证据聚合

Method: 提出GraphDancer强化学习框架，通过图感知课程调度训练，使用易到难的偏置采样器按信息寻求轨迹的结构复杂度安排训练

Result: 仅使用3B骨干模型，GraphDancer在跨域基准测试中优于配备14B骨干或GPT-4o-mini的基线，展示了图探索和推理技能的鲁棒跨域泛化能力

Conclusion: GraphDancer通过强化学习有效教会LLM导航异构图，在中等规模模型上实现跨域泛化，为结构化知识推理提供了新方法

Abstract: Large language models (LLMs) increasingly rely on external knowledge to improve factuality, yet many real-world knowledge sources are organized as heterogeneous graphs rather than plain text. Reasoning over such graph-structured knowledge poses two key challenges: (1) navigating structured, schema-defined relations requires precise function calls rather than similarity-based retrieval, and (2) answering complex questions often demands multi-hop evidence aggregation through iterative information seeking. We propose GraphDancer, a reinforcement learning (RL) framework that teaches LLMs to navigate graphs by interleaving reasoning and function execution. To make RL effective for moderate-sized LLMs, we introduce a graph-aware curriculum that schedules training by the structural complexity of information-seeking trajectories using an easy-to-hard biased sampler. We evaluate GraphDancer on a multi-domain benchmark by training on one domain only and testing on unseen domains and out-of-distribution question types. Despite using only a 3B backbone, GraphDancer outperforms baselines equipped with either a 14B backbone or GPT-4o-mini, demonstrating robust cross-domain generalization of graph exploration and reasoning skills. Our code and models can be found at https://yuyangbai.com/graphdancer/ .

</details>


### [87] [Scaled Dot-Product Attention implements projection of inputs onto a common surface](https://arxiv.org/abs/2602.02521)
*Terence D Sanger*

Main category: cs.LG

TL;DR: 该论文重新解释了缩放点积注意力机制，将其从传统的"查询-键-值"框架重构为输入向量在共同表面上的投影，揭示了其发现时间依赖和上下文依赖非线性依赖关系的本质。


<details>
  <summary>Details</summary>
Motivation: 传统缩放点积注意力机制基于数据库理论的"查询、键、值"概念，难以与数学信号处理的标准方法相协调。作者希望为SDPA提供更符合信号处理理论的数学解释。

Method: 将SDPA重写为数学等价但形式不同的表达式，将其表示为输入向量在由输入自身确定的共同表面上的投影。这种重构揭示了SDPA发现时间依赖和上下文依赖非线性依赖关系的本质。

Result: 新形式不仅提高了前向传播和学习算法的速度，更重要的是为SDPA的扩展提供了可能性。在语言处理背景下，SDPA被重新解释为寻找由输入向量所在表面确定的时间依赖上下文意义。

Conclusion: SDPA的核心功能是发现输入中时间变化的本地区域非线性依赖关系，这为SDPA在时间序列数据处理中的应用提供了强有力的理论依据，与传统的"自注意力"概念有本质区别。

Abstract: Scaled dot-product attention (SDPA) is a fundamental component responsible for the success of large-language models and other nonlinear signal processing applications. The rationale for SDPA has been based upon "query, key, value" concepts borrowed from database theory, but these concepts are difficult to reconcile with standard methods in mathematical signal processing. We show that SDPA can be rewritten in a different but mathematically equivalent form as a projection of the input vectors onto a common surface determined by the inputs themselves. Therefore SDPA discovers nonlinear dependencies in the input that are time-dependent and context-dependent. The rewritten form of SDPA permits increased speed of both feedforward and learning algorithms, but more importantly suggests potential extensions. In the context of language, we re-interpret the role of SDPA as finding a time-dependent contextual meaning determined by the surface on which the set of input vectors lies. Input token embeddings are then modified by the local context surface. This interpretation differs substantially from the concept of "self-attention", and provides a strong justification for the use of SDPA for time-series data with time-varying local nonlinear dependencies.

</details>


### [88] [IMU-1: Sample-Efficient Pre-training of Small Language Models](https://arxiv.org/abs/2602.02522)
*George Grigorev*

Main category: cs.LG

TL;DR: IMU-1是一个430M参数的语言模型，仅用72B tokens训练就达到了需要56倍数据量训练模型的基准性能


<details>
  <summary>Details</summary>
Motivation: 研究如何通过优化的训练配方和架构改进，用更少的数据量达到与大规模数据训练模型相当的性能，降低训练成本

Method: 结合多种架构干预（QK-norm注意力、每头门控、值残差、LayerNorm缩放）与优化进展（NorMuon谨慎权重衰减、muP参数化），采用三阶段训练计划和后验检查点EMA

Result: IMU-1仅用72B tokens训练就接近了需要56倍数据量（约4T tokens）训练模型的基准性能，实现了显著的数据效率提升

Conclusion: 通过精心设计的训练配方和架构优化，可以在大幅减少训练数据量的情况下获得与大规模数据训练模型相当的性能，为高效语言模型训练提供了可行方案

Abstract: We present IMU-1, a 430M-parameter language model trained on 72B tokens that approaches the benchmark performance of models trained on 56x more data. We describe a validated training recipe combining recent architectural interventions (QK-norm attention, per-head gating, value residuals, LayerNorm scaling) with optimization advances (NorMuon with cautious weight decay, muP parametrization) and a three-stage training schedule with post-hoc checkpoint EMA. We provide ablations for each component and release code, weights and data to enable reproduction: https://huggingface.co/thepowerfuldeez/imu1_base

</details>


### [89] [The "Robert Boulton" Singularity: Semantic Tunneling and Manifold Unfolding in Recursive AI](https://arxiv.org/abs/2602.02526)
*Pengyue Hou*

Main category: cs.LG

TL;DR: 研究发现传统困惑度指标在上下文稳定区域具有欺骗性，揭示了"语义隧道"失效模式，并提出MNCIS框架通过流形展开解决语义多样性崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 传统使用困惑度监控生成式AI在递归合成数据上的稳定性存在缺陷，特别是在上下文稳定区域，需要更准确的评估指标来检测语义多样性的真实变化。

Method: 采用严格的滑动窗口协议（N=1500），识别"语义隧道"失效模式；应用多尺度负耦合信息系统框架，特别是自适应谱负耦合作为拓扑算子，实现"流形展开"。

Result: 基线模型虽然保持高语法流畅性（困惑度约83.9），但在七代内语义多样性灾难性损失，收敛到单一低熵叙事吸引子；MNCIS将有效秩从3.62提升到5.35，构建抵抗语义吸引子引力的人工流形。

Conclusion: 困惑度在上下文稳定区域是欺骗性指标，语义隧道现象导致语义多样性崩溃；MNCIS框架通过流形展开有效保持训练数据的长尾分布，防止语义吸引子收敛。

Abstract: The stability of generative artificial intelligence trained on recursive synthetic data is conventionally monitored via Perplexity (PPL). We demonstrate that PPL is a deceptive metric in context-stabilized regimes (L=128). Using a rigorous sliding-window protocol (N=1500), we identify a novel failure mode termed "Semantic Tunneling." While the Baseline model maintains high grammatical fluency (PPL approx. 83.9), it suffers a catastrophic loss of semantic diversity, converging within seven generations to a single, low-entropy narrative attractor: the "Robert Boulton" Singularity. This phenomenon represents a total collapse of the latent manifold (Global Effective Rank 3.62 -> 2.22), where the model discards diverse world knowledge to optimize for statistically safe syntactic templates. To address this, we apply the Multi-Scale Negative Coupled Information Systems (MNCIS) framework recently established in Hou (2026) [arXiv:2601.11594]. We demonstrate that Adaptive Spectral Negative Coupling (ASNC) acts as a topological operator that actively induces "Manifold Unfolding." MNCIS forces the model to expand its effective rank from the anisotropic baseline of 3.62 to a hyper-diverse state of 5.35, effectively constructing an "Artificial Manifold" that resists the gravitational pull of semantic attractors and preserves the long-tail distribution of the training data.

</details>


### [90] [A Comparative Simulation Study of the Fairness and Accuracy of Predictive Policing Systems in Baltimore City](https://arxiv.org/abs/2602.02566)
*Samin Semsar,Kiran Laxmikant Prabhu,Gabriella Waters,James Foulds*

Main category: cs.LG

TL;DR: 本研究对巴尔的摩的预测警务系统进行了全面的模拟比较分析，发现其公平性和准确性比传统热点警务在短期内更好，但会更快放大偏见，可能导致更差的长期表现。


<details>
  <summary>Details</summary>
Motivation: 现有关于预测警务系统（如洛杉矶和巴尔的摩部署的系统）存在不公平性和种族偏见的讨论，研究表明不公平性可能源于反馈循环和历史偏见数据训练。然而，对预测警务系统的比较研究较少且不够全面。

Method: 在巴尔的摩进行全面的模拟比较研究，评估预测警务技术的公平性和准确性，并与传统热点警务方法进行对比。

Result: 预测警务确实存在先前报道的反馈循环偏见，但传统热点警务也有类似问题。预测警务在短期内比热点警务更公平和准确，但会更快放大偏见，可能导致更差的长期行为。在巴尔的摩的某些情况下，这些系统的偏见倾向于过度监管白人社区，这与先前研究不同。

Conclusion: 预测警务中的偏见问题比先前假设的更复杂。本研究展示了一种针对特定城市的评估方法和预测警务系统的行为趋势比较方法，表明此类模拟可以揭示不公平性和长期趋势。

Abstract: There are ongoing discussions about predictive policing systems, such as those deployed in Los Angeles, California and Baltimore, Maryland, being unfair, for example, by exhibiting racial bias. Studies found that unfairness may be due to feedback loops and being trained on historically biased recorded data. However, comparative studies on predictive policing systems are few and are not sufficiently comprehensive. In this work, we perform a comprehensive comparative simulation study on the fairness and accuracy of predictive policing technologies in Baltimore. Our results suggest that the situation around bias in predictive policing is more complex than was previously assumed. While predictive policing exhibited bias due to feedback loops as was previously reported, we found that the traditional alternative, hot spots policing, had similar issues. Predictive policing was found to be more fair and accurate than hot spots policing in the short term, although it amplified bias faster, suggesting the potential for worse long-run behavior. In Baltimore, in some cases the bias in these systems tended toward over-policing in White neighborhoods, unlike in previous studies. Overall, this work demonstrates a methodology for city-specific evaluation and behavioral-tendency comparison of predictive policing systems, showing how such simulations can reveal inequities and long-term tendencies.

</details>


### [91] [Hypersonic Flow Control: Generalized Deep Reinforcement Learning for Hypersonic Intake Unstart Control under Uncertainty](https://arxiv.org/abs/2602.02531)
*Trishit Mondal,Ameya D. Jagtap*

Main category: cs.LG

TL;DR: 使用深度强化学习控制高超声速进气道不起动现象，在Mach 5条件下实现稳定控制并展示零样本泛化能力


<details>
  <summary>Details</summary>
Motivation: 高超声速不起动现象在Mach 5及以上速度下对吸气式推进可靠性构成重大挑战，强激波-边界层相互作用和快速压力波动会破坏进气道稳定性

Method: 采用深度强化学习主动流动控制策略，结合高保真CFD模拟和自适应网格细化，学习物理一致的实时控制策略

Result: DRL控制器在广泛背压范围内稳定进气道，对未见场景（不同背压、雷诺数、传感器配置）具有强零样本泛化能力，在噪声测量下保持鲁棒性

Conclusion: 建立了一种数据驱动方法，可在实际运行不确定性下实现实时高超声速流动控制，为实际应用提供了可行方案

Abstract: The hypersonic unstart phenomenon poses a major challenge to reliable air-breathing propulsion at Mach 5 and above, where strong shock-boundary-layer interactions and rapid pressure fluctuations can destabilize inlet operation. Here, we demonstrate a deep reinforcement learning (DRL)- based active flow control strategy to control unstart in a canonical two-dimensional hypersonic inlet at Mach 5 and Reynolds number $5\times 10^6$. The in-house CFD solver enables high-fidelity simulations with adaptive mesh refinement, resolving key flow features, including shock motion, boundary-layer dynamics, and flow separation, that are essential for learning physically consistent control policies suitable for real-time deployment. The DRL controller robustly stabilizes the inlet over a wide range of back pressures representative of varying combustion chamber conditions. It further generalizes to previously unseen scenarios, including different back-pressure levels, Reynolds numbers, and sensor configurations, while operating with noisy measurements, thereby demonstrating strong zero-shot generalization. Control remains robust in the presence of noisy sensor measurements, and a minimal, optimally selected sensor set achieves comparable performance, enabling practical implementation. These results establish a data-driven approach for real-time hypersonic flow control under realistic operational uncertainties.

</details>


### [92] [CADENT: Gated Hybrid Distillation for Sample-Efficient Transfer in Reinforcement Learning](https://arxiv.org/abs/2602.02532)
*Mahyar Alinejad,Yue Wang,George Atia*

Main category: cs.LG

TL;DR: CADENT框架通过经验门控信任机制，将战略自动机知识与战术策略知识统一为连贯的指导信号，在强化学习迁移中实现40-60%的样本效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有迁移学习方法在处理源域和目标域之间的领域偏移时存在困难。策略蒸馏能提供战术指导但无法传递长期战略知识，而基于自动机的方法能捕捉任务结构但缺乏细粒度动作指导。

Method: CADENT框架将战略自动机知识与战术策略知识统一为连贯的指导信号，核心创新是经验门控信任机制，在状态-动作层面动态权衡教师指导与学生自身经验。

Result: 在从稀疏奖励网格世界到连续控制任务的各种挑战性环境中，CADENT比基线方法实现了40-60%的样本效率提升，同时保持优异的渐近性能。

Conclusion: CADENT为强化学习中的自适应知识迁移建立了稳健的方法，通过动态信任机制实现了战略与战术知识的有效统一。

Abstract: Transfer learning promises to reduce the high sample complexity of deep reinforcement learning (RL), yet existing methods struggle with domain shift between source and target environments. Policy distillation provides powerful tactical guidance but fails to transfer long-term strategic knowledge, while automaton-based methods capture task structure but lack fine-grained action guidance. This paper introduces Context-Aware Distillation with Experience-gated Transfer (CADENT), a framework that unifies strategic automaton-based knowledge with tactical policy-level knowledge into a coherent guidance signal. CADENT's key innovation is an experience-gated trust mechanism that dynamically weighs teacher guidance against the student's own experience at the state-action level, enabling graceful adaptation to target domain specifics. Across challenging environments, from sparse-reward grid worlds to continuous control tasks, CADENT achieves 40-60\% better sample efficiency than baselines while maintaining superior asymptotic performance, establishing a robust approach for adaptive knowledge transfer in RL.

</details>


### [93] [From Sparse Decisions to Dense Reasoning: A Multi-attribute Trajectory Paradigm for Multimodal Moderation](https://arxiv.org/abs/2602.02536)
*Tianle Gu,Kexin Huang,Lingyu Li,Ruilin Luo,Shiyang Huang,Zongqi Wang,Yujiu Yang,Yan Teng,Yingchun Wang*

Main category: cs.LG

TL;DR: UniMod提出了一种新的多模态安全审核学习范式，通过从稀疏决策转向密集推理轨迹，构建结构化轨迹来防止捷径学习，使用多维度奖励模型提供监督，在较少训练数据下达到竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 多模态安全审核面临数据和监督的双重稀疏性，传统的二值标签导致捷径学习，掩盖了有效的多模态分类边界。

Method: 提出UniMod学习范式，构建包含证据定位、模态评估、风险映射、策略决策和响应生成的结构化轨迹；开发多头部标量奖励模型UniRM提供多维度监督；引入专门优化策略解耦任务特定参数并重新平衡训练动态。

Result: UniMod在文本审核方面达到竞争性性能，并在多模态审核方面设定新基准，仅使用领先基线不到40%的训练数据。

Conclusion: UniMod通过多属性轨迹推理为多模态审核提供了一个有效且高效的框架，防止模型收敛于表面捷径，强制模型基于明确的安全语义进行决策。

Abstract: Safety moderation is pivotal for identifying harmful content. Despite the success of textual safety moderation, its multimodal counterparts remain hindered by a dual sparsity of data and supervision. Conventional reliance on binary labels lead to shortcut learning, which obscures the intrinsic classification boundaries necessary for effective multimodal discrimination. Hence, we propose a novel learning paradigm (UniMod) that transitions from sparse decision-making to dense reasoning traces. By constructing structured trajectories encompassing evidence grounding, modality assessment, risk mapping, policy decision, and response generation, we reformulate monolithic decision tasks into a multi-dimensional boundary learning process. This approach forces the model to ground its decision in explicit safety semantics, preventing the model from converging on superficial shortcuts. To facilitate this paradigm, we develop a multi-head scalar reward model (UniRM). UniRM provides multi-dimensional supervision by assigning attribute-level scores to the response generation stage. Furthermore, we introduce specialized optimization strategies to decouple task-specific parameters and rebalance training dynamics, effectively resolving interference between diverse objectives in multi-task learning. Empirical results show UniMod achieves competitive textual moderation performance and sets a new multimodal benchmark using less than 40\% of the training data used by leading baselines. Ablations further validate our multi-attribute trajectory reasoning, offering an effective and efficient framework for multimodal moderation. Supplementary materials are available at \href{https://trustworthylab.github.io/UniMod/}{project website}.

</details>


### [94] [Enhancing Post-Training Quantization via Future Activation Awareness](https://arxiv.org/abs/2602.02538)
*Zheqi Lv,Zhenxuan Fan,Qi Tian,Wenqiao Zhang,Yueting Zhuang*

Main category: cs.LG

TL;DR: FAQ是一种后训练量化方法，通过利用未来层激活来指导量化，减少量化偏差和误差累积，在边缘部署中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统后训练量化方法通常基于当前层激活设置量化超参数，这种方法虽然高效，但存在量化偏差和误差累积问题，特别是在校准数据有偏差时会导致次优和不稳定的量化结果。

Method: 提出Future-Aware Quantization (FAQ)方法，利用未来层激活来指导量化，更好地识别和保护重要权重，减少对校准噪声的敏感性。引入窗口式预览机制来软聚合多个未来层激活，避免过度依赖任何单一层。使用预搜索配置来最小化开销，避免昂贵的贪婪搜索。

Result: 实验表明，FAQ在可忽略的额外成本下持续优于先前方法，无需反向传播、数据重建或调优，非常适合边缘部署。

Conclusion: FAQ通过利用未来层信息改进了后训练量化，解决了传统方法的偏差和误差累积问题，为边缘部署提供了高效稳定的量化解决方案。

Abstract: Post-training quantization (PTQ) is a widely used method to compress large language models (LLMs) without fine-tuning. It typically sets quantization hyperparameters (e.g., scaling factors) based on current-layer activations. Although this method is efficient, it suffers from quantization bias and error accumulation, resulting in suboptimal and unstable quantization, especially when the calibration data is biased. To overcome these issues, we propose Future-Aware Quantization (FAQ), which leverages future-layer activations to guide quantization. This allows better identification and preservation of important weights, while reducing sensitivity to calibration noise. We further introduce a window-wise preview mechanism to softly aggregate multiple future-layer activations, mitigating over-reliance on any single layer. To avoid expensive greedy search, we use a pre-searched configuration to minimize overhead. Experiments show that FAQ consistently outperforms prior methods with negligible extra cost, requiring no backward passes, data reconstruction, or tuning, making it well-suited for edge deployment.

</details>


### [95] [How Much Information Can a Vision Token Hold? A Scaling Law for Recognition Limits in VLMs](https://arxiv.org/abs/2602.02539)
*Shuxin Zhuang,Zi Liang,Runsheng Yu,Hongzong Li,Rong Feng,Shiqin Tang,Youzhi Zhang*

Main category: cs.LG

TL;DR: 该论文研究了视觉编码器在长上下文建模中的信息容量上限，通过压力测试发现了视觉令牌信息负载的三个相变阶段，并提出了统一的概率缩放定律。


<details>
  <summary>Details</summary>
Motivation: 尽管以DeepSeek-OCR为代表的视觉中心方法在长上下文建模中取得了显著进展，通过视觉令牌实现高压缩率而不牺牲识别精度，但将视觉编码器视为具有有限表示能力的损失通道引发了一个基本问题：视觉令牌的信息上限是什么？

Method: 通过控制压力测试，逐步增加图像中的信息量（字符数量），观察视觉令牌信息负载的相变现象。分析这些相变的机械起源和关键因素，并制定统一的概率缩放定律，将平均视觉令牌负载和视觉密度整合到一个潜在难度度量中。

Result: 观察到三个明显的相变阶段：近乎完美的稳定阶段、误差方差增加的失稳阶段和完全崩溃阶段。提出的缩放定律在各种视觉语言模型中表现出普遍性，为优化视觉上下文压缩的效率-准确性权衡提供了关键经验指导。

Conclusion: 该研究揭示了视觉编码器的信息容量限制，提出的缩放定律为视觉上下文压缩系统的设计和优化提供了理论基础和实用指导，有助于在效率和准确性之间找到最佳平衡点。

Abstract: Recent vision-centric approaches have made significant strides in long-context modeling. Represented by DeepSeek-OCR, these models encode rendered text into continuous vision tokens, achieving high compression rates without sacrificing recognition precision. However, viewing the vision encoder as a lossy channel with finite representational capacity raises a fundamental question: what is the information upper bound of visual tokens? To investigate this limit, we conduct controlled stress tests by progressively increasing the information quantity (character count) within an image. We observe a distinct phase-transition phenomenon characterized by three regimes: a near-perfect Stable Phase, an Instability Phase marked by increased error variance, and a total Collapse Phase. We analyze the mechanical origins of these transitions and identify key factors. Furthermore, we formulate a probabilistic scaling law that unifies average vision token load and visual density into a latent difficulty metric. Extensive experiments across various Vision-Language Models demonstrate the universality of this scaling law, providing critical empirical guidance for optimizing the efficiency-accuracy trade-off in visual context compression.

</details>


### [96] [Toward Ultra-Long-Horizon Sequential Model Editing](https://arxiv.org/abs/2602.02543)
*Mingda Liu,Zhenghan Zhu,Ze'an Miao,Katsuki Fujisawa*

Main category: cs.LG

TL;DR: 论文提出Norm-Anchor Scaling (NAS)方法，通过约束MLP权重范数增长来防止模型编辑中的崩溃问题，将崩溃点延迟4倍以上，性能提升72.2%


<details>
  <summary>Details</summary>
Motivation: 现有的定位-编辑(L&E)方法在连续编辑时会出现模型崩溃问题，研究发现这与编辑后MLP权重范数的爆炸性增长密切相关，需要解决这一根本问题

Method: 提出Norm-Anchor Scaling (NAS)策略，这是一种即插即用的范数约束方法，通过控制MLP权重范数增长来防止模型崩溃，仅需一行代码且计算开销可忽略

Result: NAS将代表性L&E算法的崩溃点延迟4倍以上，编辑性能平均相对提升72.2%，计算开销极小

Conclusion: 通过约束MLP权重范数可以有效防止模型编辑中的崩溃问题，NAS为L&E框架提供了简单有效的解决方案

Abstract: Model editing has emerged as a practical approach for mitigating factual errors and outdated knowledge in large language models (LLMs). Among existing methods, the Locate-and-Edit (L&E) paradigm is the dominant framework: it locates MLP parameters implicated in expressing a target fact, and then performs a localized update to rewrite that fact. However, long sequences of edits often trigger abrupt model collapse in L&E beyond a critical point. We empirically identify a strong correlation between collapse and explosive growth of edited MLP weight norms, and formally prove that commonly used L&E update rules can induce exponential norm growth across sequential edits in the absence of explicit norm control. To address this issue, we propose Norm-Anchor Scaling NAS, a plug-and-play norm-constrained strategy. Across extensive experiments, NAS delays the collapse point of representative L&E algorithms by more than 4 times and yields a 72.2% average relative gain in editing performance, requiring only a single additional line of code and incurring negligible computational overhead.

</details>


### [97] [Beyond Alignment: Expanding Reasoning Capacity via Manifold-Reshaping Policy Optimization](https://arxiv.org/abs/2602.02545)
*Dayu Wang,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li*

Main category: cs.LG

TL;DR: MRPO通过几何干预扩展LLM推理空间，超越传统RLVR的局限性，在数学任务上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 针对现有研究质疑RL是否真正扩展LLM推理能力还是仅对齐已有潜在能力的问题，挑战"可访问边界假设"，认为可以通过几何干预从根本上扩展潜在推理空间

Method: 提出流形重塑策略优化(MRPO)框架：1) 谱正交探索(SOE)将策略初始化弹射到偏置流形的零空间；2) 在策略优化目标中集成有效秩正则化项，激励发现和维护高维推理轨迹

Result: 4B参数方法在数学任务上达到最先进性能，显著超越更大模型(如Qwen3-32B)，扩展了标准GRPO的能力边界

Conclusion: 通过几何干预可以突破预训练模型的低秩偏置流形限制，从根本上扩展LLM的推理能力，验证了推理空间可扩展性假设

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated remarkable success in enhancing the reasoning capabilities of Large Language Models (LLMs). However, recent studies question whether RL genuinely expands reasoning capacity or merely aligns existing latent capabilities, arguing that exploration remains confined within the pre-trained model's low-rank bias manifold. In this work, we challenge this accessibility boundary hypothesis by demonstrating that the latent reasoning space can be fundamentally expanded through targeted geometric interventions. We propose Manifold-Reshaping Policy Optimization (MRPO), a geometric framework designed to fundamentally restructure the inference space of LLMs. MRPO operates in two stages: first, we employ Spectral Orthogonal Exploration (SOE) to eject the policy initialization into the null space of the bias manifold; second, we integrate an Effective Rank regularization term into the policy optimization objective. This approach incentivizes the discovery and maintenance of high-dimensional reasoning trajectories against the entropy-reducing tendency of standard RL. Empirically, our 4B-parameter method achieves state-of-the-art performance on mathematical tasks, significantly outperforming larger models (e.g., Qwen3-32B) and expanding the capability boundary beyond standard GRPO. Our code is available at https://anonymous.4open.science/r/MRPO-D57B/

</details>


### [98] [D$^2$Quant: Accurate Low-bit Post-Training Weight Quantization for LLMs](https://arxiv.org/abs/2602.02546)
*Xianglong Yan,ChengZhu Bao,Zhiteng Li,Tianao Zhang,Shaoqiu Zhang,Ruobing Xie,Samm Sun,Yulun Zhang*

Main category: cs.LG

TL;DR: D²Quant：一种新颖的仅权重后训练量化框架，通过双尺度量化器和偏差感知校正，在4位以下精度下显著提升大语言模型的量化性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型的计算和内存成本高，在资源受限场景中部署困难。仅权重后训练量化虽然能减少内存使用并实现实际加速，但在4位以下精度时准确率显著下降。研究发现两个主要原因：1）下投影矩阵是量化瓶颈，保持其保真度需要额外比特宽度；2）权重量化导致激活偏差，但有效的校正策略尚未充分探索。

Method: 提出D²Quant框架，从权重和激活两个角度改进量化：1）权重侧：设计针对下投影矩阵的双尺度量化器（DSQ），采用可吸收的缩放因子，在不增加比特预算的情况下显著提高准确率；2）激活侧：提出偏差感知校正（DAC），在LayerNorm中融入均值偏移校正，缓解量化引起的激活分布偏移。

Result: 在多个大语言模型家族和评估指标上的广泛实验表明，D²Quant在4位以下精度的仅权重后训练量化中提供了优越的性能。

Conclusion: D²Quant通过创新的双尺度量化器和偏差感知校正机制，有效解决了仅权重量化在低比特精度下的准确率下降问题，为大语言模型在资源受限环境中的高效部署提供了实用解决方案。

Abstract: Large language models (LLMs) deliver strong performance, but their high compute and memory costs make deployment difficult in resource-constrained scenarios. Weight-only post-training quantization (PTQ) is appealing, as it reduces memory usage and enables practical speedup without low-bit operators or specialized hardware. However, accuracy often degrades significantly in weight-only PTQ at sub-4-bit precision, and our analysis identifies two main causes: (1) down-projection matrices are a well-known quantization bottleneck, but maintaining their fidelity often requires extra bit-width; (2) weight quantization induces activation deviations, but effective correction strategies remain underexplored. To address these issues, we propose D$^2$Quant, a novel weight-only PTQ framework that improves quantization from both the weight and activation perspectives. On the weight side, we design a Dual-Scale Quantizer (DSQ) tailored to down-projection matrices, with an absorbable scaling factor that significantly improves accuracy without increasing the bit budget. On the activation side, we propose Deviation-Aware Correction (DAC), which incorporates a mean-shift correction within LayerNorm to mitigate quantization-induced activation distribution shifts. Extensive experiments across multiple LLM families and evaluation metrics show that D$^2$Quant delivers superior performance for weight-only PTQ at sub-4-bit precision. The code and models will be available at https://github.com/XIANGLONGYAN/D2Quant.

</details>


### [99] [HyPAC: Cost-Efficient LLMs-Human Hybrid Annotation with PAC Error Guarantees](https://arxiv.org/abs/2602.02550)
*Hao Zeng,Huipeng Huang,Xinhao Qu,Jianguo Huang,Bingyi Jing,Hongxin Wei*

Main category: cs.LG

TL;DR: HyPAC是一种自适应路由方法，将输入数据分配到最经济高效的标注源（如LLM、推理模型、人类专家），同时提供分布无关的标注错误保证，实验显示可减少78.51%的标注成本。


<details>
  <summary>Details</summary>
Motivation: 数据标注通常涉及多个具有不同成本-质量权衡的标注源（如快速LLM、慢速推理模型、人类专家），需要一种方法能够自适应地将输入路由到最经济高效的标注源，同时控制测试实例的标注错误。

Method: HyPAC使用重要性采样和置信上界校准两个决策阈值，根据不确定性将输入划分为三个区域，并将每个区域路由到适当的标注源。该方法提供分布无关的标注错误保证，并实现最小期望成本。

Result: 在常见基准测试中，HyPAC在严格控制标注错误的同时，将标注成本降低了78.51%。该方法实现了最小期望成本，并提供了概率近似正确（PAC）的标注错误保证。

Conclusion: HyPAC是一种有效的自适应路由方法，能够在多个标注源之间智能分配输入数据，在保证标注质量的同时显著降低标注成本，且不依赖于数据分布和预训练模型。

Abstract: Data annotation often involves multiple sources with different cost-quality trade-offs, such as fast large language models (LLMs), slow reasoning models, and human experts. In this work, we study the problem of routing inputs to the most cost-efficient annotation source while controlling the labeling error on test instances. We propose \textbf{HyPAC}, a method that adaptively labels inputs to the most cost-efficient annotation source while providing distribution-free guarantees on annotation error. HyPAC calibrates two decision thresholds using importance sampling and upper confidence bounds, partitioning inputs into three regions based on uncertainty and routing each to the appropriate annotation source. We prove that HyPAC achieves the minimum expected cost with a probably approximately correct (PAC) guarantee on the annotation error, free of data distribution and pre-trained models. Experiments on common benchmarks demonstrate the effectiveness of our method, reducing the annotation cost by 78.51\% while tightly controlling the annotation error.

</details>


### [100] [EEO-TFV: Escape-Explore Optimizer for Web-Scale Time-Series Forecasting and Vision Analysis](https://arxiv.org/abs/2602.02551)
*Hua Wang,Jinghao Lu,Fan Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种轻量级Transformer架构和新型逃逸探索优化器(EEO)，解决了传统Transformer在多变量长序列预测中的误差累积问题、图像任务中对分布外样本的脆弱性，以及大规模Web数据分析中的优化困难。


<details>
  <summary>Details</summary>
Motivation: Transformer基础模型在时间序列预测和图像分割等任务中取得了显著进展，但在多变量长序列预测中存在误差累积问题，在图像相关任务中对分布外样本表现出脆弱性。这些挑战在大规模Web数据分析任务中尤为突出，这些任务通常涉及复杂的时序模式和多模态特征，增加了优化难度，使模型容易在高维参数空间中陷入鞍点。

Method: 提出了一种轻量级Transformer架构，并结合新型逃逸探索优化器(EEO)。该优化器增强了探索能力和泛化能力，同时有效避免了尖锐最小值和鞍点陷阱。

Result: 实验结果表明，在代表性Web数据场景中，该方法在11个时间序列基准数据集和Synapse医学图像分割任务上达到了与最先进模型相当的性能。同时表现出更优的泛化能力和稳定性。

Conclusion: 该方法验证了其作为Web规模数据挖掘和分析的通用跨任务基础模型的潜力，为解决大规模Web数据分析中的优化和泛化问题提供了有效方案。

Abstract: Transformer-based foundation models have achieved remarkable progress in tasks such as time-series forecasting and image segmentation. However, they frequently suffer from error accumulation in multivariate long-sequence prediction and exhibit vulnerability to out-of-distribution samples in image-related tasks. Furthermore, these challenges become particularly pronounced in large-scale Web data analysis tasks, which typically involve complex temporal patterns and multimodal features. This complexity substantially increases optimization difficulty, rendering models prone to stagnation at saddle points within high-dimensional parameter spaces. To address these issues, we propose a lightweight Transformer architecture in conjunction with a novel Escape-Explore Optimizer (EEO). The optimizer enhances both exploration and generalization while effectively avoiding sharp minima and saddle-point traps. Experimental results show that, in representative Web data scenarios, our method achieves performance on par with state-of-the-art models across 11 time-series benchmark datasets and the Synapse medical image segmentation task. Moreover, it demonstrates superior generalization and stability, thereby validating its potential as a versatile cross-task foundation model for Web-scale data mining and analysis.

</details>


### [101] [BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation](https://arxiv.org/abs/2602.02554)
*Jingwen Xu,Yiyang Lu,Zisu Huang,Changze Lv,Xiaohua Wang,Shizheng Li,Zhibo Xu,Zhengkang Guo,Zhengyuan Wang,Muzhao Tian,Xuanjing Huang,Xiaoqing Zheng*

Main category: cs.LG

TL;DR: BatCoder是一个自监督强化学习框架，通过代码-文档的互译训练，仅使用代码数据就能同时优化代码生成和文档生成能力。


<details>
  <summary>Details</summary>
Motivation: 训练代码相关任务的LLMs通常依赖高质量的代码-文档对，但这些数据成本高昂且对于小众编程语言往往稀缺。

Method: 采用回译策略：首先生成代码的文档，然后用生成的文档重构原始代码。原始代码与重构代码之间的语义相似度作为隐式奖励，通过强化学习同时提升代码生成和文档生成能力。

Result: 在HumanEval和MBPP基准测试中，7B模型分别达到83.5%和81.0%的pass@1，优于强大的开源基线模型。框架在训练语料规模和模型容量方面都表现出良好的扩展性。

Conclusion: BatCoder框架仅使用代码数据就能有效训练模型，解决了高质量代码-文档对稀缺的问题，在代码生成和文档生成任务上都取得了优异性能。

Abstract: Training LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, a self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production. BatCoder employs a back-translation strategy: a documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward, enabling reinforcement learning to improve the model's performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with a 7B model, BatCoder achieved 83.5% and 81.0% pass@1, outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity.

</details>


### [102] [Learning to Explore with Parameter-Space Noise: A Deep Dive into Parameter-Space Noise for Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2602.02555)
*Bizhe Bai,Xinyue Wang,Peng Ye,Tao Chen*

Main category: cs.LG

TL;DR: PSN-RLVR通过参数扰动和截断重要性采样解决RLVR探索不足问题，在数学推理基准上显著提升大采样预算下的性能


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在探索天花板问题，主要重新加权已有解决方案轨迹而非发现新策略，限制了在大采样预算下的性能提升

Method: 提出PSN-RLVR：1) 在rollout生成前扰动策略参数，实现时间一致、轨迹级别的探索；2) 使用截断重要性采样缓解采样-更新不匹配；3) 设计基于语义多样性和归一化自确定性的轻量级自适应噪声调度器

Result: 在多个数学推理基准和模型家族上，PSN-GRPO持续扩展有效推理能力边界，在大采样预算下获得更高的pass-at-k性能，优于先前的探索导向RLVR方法

Conclusion: PSN-RLVR通过参数扰动探索机制有效解决了RLVR的探索限制问题，且方法正交可组合，为进一步性能提升提供了基础

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) improves LLM reasoning, yet growing evidence indicates an exploration ceiling: it often reweights existing solution traces rather than discovering new strategies, limiting gains under large sampling budgets (e.g., pass-at-256). We address this limitation with PSN-RLVR, which perturbs policy parameters before rollout generation to induce temporally consistent, trajectory-level exploration that better preserves long-horizon chain-of-thought coherence than action-space noise. To mitigate the resulting sampling-update mismatch, we incorporate truncated importance sampling (TIS). To avoid expensive KL-based adaptive noise control, we propose a computationally efficient real-time adaptive noise scheduler driven by a lightweight surrogate that combines semantic diversity with normalized self-certainty. Instantiated on GRPO, a widely used RLVR method, PSN-GRPO consistently expands the effective reasoning capability boundary across multiple mathematical reasoning benchmarks and model families, yielding higher pass-at-k under large sampling budgets and outperforming prior exploration-oriented RLVR methods (e.g., Pass-at-k-style training) while remaining orthogonal and thus composable for additional gains.

</details>


### [103] [Beyond Experience Retrieval: Learning to Generate Utility-Optimized Structured Experience for Frozen LLMs](https://arxiv.org/abs/2602.02556)
*Xuancheng Li,Haitao Li,Yujia Zhou,Yiqun Liu,Qingyao Ai*

Main category: cs.LG

TL;DR: SEAM是一种轻量级插件模块，通过存储经验参数并生成结构化经验条目来指导冻结的LLM执行器，在数学推理基准上实现了准确率提升且开销低。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常是静态的，会重复推理或错误。现有的经验重用方法依赖外部检索，存在相似性噪声和延迟问题，需要更高效的经验利用机制。

Method: 提出SEAM（结构化经验适配器模块），这是一个轻量级、执行器特定的插件，在其参数中存储经验，并通过单次前向传播生成结构化、实例定制的经验条目来指导冻结的LLM执行器。使用执行器rollouts和GRPO进行效用训练，保持执行器冻结，部署后可通过监督微调进一步改进。

Result: 在数学推理基准测试中，SEAM在不同执行器上均实现了持续的准确率提升，且开销较低。广泛的消融实验和分析进一步阐明了SEAM有效性和鲁棒性的机制。

Conclusion: SEAM提供了一种高效的经验重用方法，通过轻量级适配器模块在保持执行器冻结的同时提升LLM性能，为静态语言模型的经验利用提供了新思路。

Abstract: Large language models (LLMs) are largely static and often redo reasoning or repeat mistakes. Prior experience reuse typically relies on external retrieval, which is similarity-based, can introduce noise, and adds latency. We introduce SEAM (Structured Experience Adapter Module), a lightweight, executor-specific plug-in that stores experience in its parameters and generates a structured, instance-tailored experience entry in a single forward pass to guide a frozen LLM executor. SEAM is trained for utility via executor rollouts and GRPO while keeping the executor frozen, and it can be further improved after deployment with supervised fine-tuning on logged successful trajectories. Experiments on mathematical reasoning benchmarks show consistent accuracy gains across executors with low overhead. Extensive ablations and analyses further elucidate the mechanisms underlying SEAM's effectiveness and robustness.

</details>


### [104] [The Alignment Curse: Cross-Modality Jailbreak Transfer in Omni-Models](https://arxiv.org/abs/2602.02557)
*Yupeng Chen,Junchi Yu,Aoxi Liu,Philip Torr,Adel Bibi*

Main category: cs.LG

TL;DR: 该研究探索了从文本到音频的越狱攻击跨模态转移，发现文本转移的音频越狱攻击效果与现有音频越狱相当甚至更好，可作为未来音频红队测试的简单有效基线。


<details>
  <summary>Details</summary>
Motivation: 端到端训练的全能模型在多模态理解方面取得进展，安全红队测试已从文本扩展到音频越狱攻击，但文本与音频越狱之间的跨模态转移研究不足。研究者基于两种模态的语义相似性和文本越狱方法的成熟性，探索这一桥梁。

Method: 首先分析模态对齐与跨模态越狱转移的关系，发现强对齐可能无意中将文本漏洞传播到音频模态（称为"对齐诅咒"）。基于此分析，对文本越狱、文本转移的音频越狱和现有音频越狱在最新全能模型上进行实证评估。

Result: 文本转移的音频越狱攻击表现与音频越狱相当甚至更好，成为未来音频红队测试的简单而强大的基线。研究还展示了强大的跨模型可转移性，即使在更严格的纯音频访问威胁模型下，文本转移的音频攻击仍然有效。

Conclusion: 文本到音频的跨模态越狱转移是一个重要且有效的攻击向量，文本转移的音频越狱可作为音频红队测试的强基线，揭示了模态对齐在安全漏洞传播中的双重作用。

Abstract: Recent advances in end-to-end trained omni-models have significantly improved multimodal understanding. At the same time, safety red-teaming has expanded beyond text to encompass audio-based jailbreak attacks. However, an important bridge between textual and audio jailbreaks remains underexplored. In this work, we study the cross-modality transfer of jailbreak attacks from text to audio, motivated by the semantic similarity between the two modalities and the maturity of textual jailbreak methods. We first analyze the connection between modality alignment and cross-modality jailbreak transfer, showing that strong alignment can inadvertently propagate textual vulnerabilities to the audio modality, which we term the alignment curse. Guided by this analysis, we conduct an empirical evaluation of textual jailbreaks, text-transferred audio jailbreaks, and existing audio-based jailbreaks on recent omni-models. Our results show that text-transferred audio jailbreaks perform comparably to, and often better than, audio-based jailbreaks, establishing them as simple yet powerful baselines for future audio red-teaming. We further demonstrate strong cross-model transferability and show that text-transferred audio attacks remain effective even under a stricter audio-only access threat model.

</details>


### [105] [Auditing Sybil: Explaining Deep Lung Cancer Risk Prediction Through Generative Interventional Attributions](https://arxiv.org/abs/2602.02560)
*Bartlomiej Sobieski,Jakub Grzywaczewski,Karol Dobiczek,Mateusz Wójcik,Tomasz Bartczak,Patryk Szatkowski,Przemysław Bombiński,Matthew Tivnan,Przemyslaw Biecek*

Main category: cs.LG

TL;DR: S(H)NAP框架对Sybil肺癌风险预测模型进行因果验证审计，发现模型虽能区分良恶性结节，但存在对临床无关伪影的敏感性和径向偏差等关键失效模式


<details>
  <summary>Details</summary>
Motivation: 尽管Sybil深度学习模型在肺癌CT筛查中表现出高精度，但现有评估仅基于观察性指标，缺乏对模型实际推理机制的因果验证，需要确保临床部署前的稳健决策

Method: 提出S(H)NAP模型无关审计框架，利用真实3D扩散桥建模系统修改解剖特征，构建生成干预归因并由放射科专家验证，隔离对象特异性因果贡献

Result: 首次对Sybil进行干预审计，发现模型常表现出类似专家放射科医生的行为，能区分恶性与良性肺结节，但存在对临床不合理伪影的危险敏感性和明显径向偏差等关键失效模式

Conclusion: 需要从相关性评估转向因果验证以确保临床部署前的稳健决策，S(H)NAP框架为深度学习模型提供了重要的审计工具，揭示了Sybil模型的潜在风险

Abstract: Lung cancer remains the leading cause of cancer mortality, driving the development of automated screening tools to alleviate radiologist workload. Standing at the frontier of this effort is Sybil, a deep learning model capable of predicting future risk solely from computed tomography (CT) with high precision. However, despite extensive clinical validation, current assessments rely purely on observational metrics. This correlation-based approach overlooks the model's actual reasoning mechanism, necessitating a shift to causal verification to ensure robust decision-making before clinical deployment. We propose S(H)NAP, a model-agnostic auditing framework that constructs generative interventional attributions validated by expert radiologists. By leveraging realistic 3D diffusion bridge modeling to systematically modify anatomical features, our approach isolates object-specific causal contributions to the risk score. Providing the first interventional audit of Sybil, we demonstrate that while the model often exhibits behavior akin to an expert radiologist, differentiating malignant pulmonary nodules from benign ones, it suffers from critical failure modes, including dangerous sensitivity to clinically unjustified artifacts and a distinct radial bias.

</details>


### [106] [Mitigating Task-Order Sensitivity and Forgetting via Hierarchical Second-Order Consolidation](https://arxiv.org/abs/2602.02568)
*Protik Nag,Krishnan Raghavan,Vignesh Narayanan*

Main category: cs.LG

TL;DR: HTCL是一个分层泰勒级数持续学习框架，通过快速局部适应和保守二阶全局整合来应对任务顺序随机性带来的高方差问题，显著提升性能并降低方差。


<details>
  <summary>Details</summary>
Motivation: 传统持续学习系统面临任务顺序随机性带来的高方差问题，这会影响学习稳定性和最终性能。需要一种能够处理任务顺序效应并实现多尺度知识整合的方法。

Method: HTCL框架结合快速局部适应和基于Hessian正则化泰勒展开的保守二阶全局整合。首先识别组内最佳任务序列，然后通过Hessian正则化的泰勒展开整合局部更新，形成具有理论保证的整合步骤。该方法可扩展到L级层次结构，支持多尺度知识整合。

Result: 在多种数据集和基准方法上，HTCL作为模型无关的整合层，持续提升性能，平均准确率提高7%到25%，同时将最终准确率的标准差降低高达68%。

Conclusion: HTCL通过分层泰勒级数方法有效解决了持续学习中任务顺序随机性带来的挑战，实现了更稳定、高性能的多尺度知识整合，为持续学习系统提供了理论保证的解决方案。

Abstract: We introduce $\textbf{Hierarchical Taylor Series-based Continual Learning (HTCL)}$, a framework that couples fast local adaptation with conservative, second-order global consolidation to address the high variance introduced by random task ordering. To address task-order effects, HTCL identifies the best intra-group task sequence and integrates the resulting local updates through a Hessian-regularized Taylor expansion, yielding a consolidation step with theoretical guarantees. The approach naturally extends to an $L$-level hierarchy, enabling multiscale knowledge integration in a manner not supported by conventional single-level CL systems. Across a wide range of datasets and replay and regularization baselines, HTCL acts as a model-agnostic consolidation layer that consistently enhances performance, yielding mean accuracy gains of $7\%$ to $25\%$ while reducing the standard deviation of final accuracy by up to $68\%$ across random task permutations.

</details>


### [107] [Reward Shaping for Inference-Time Alignment: A Stackelberg Game Perspective](https://arxiv.org/abs/2602.02572)
*Haichuan Wang,Tao Lin,Lingkai Kong,Ce Li,Hezi Jiang,Milind Tambe*

Main category: cs.LG

TL;DR: 论文提出通过奖励模型优化解决KL正则化导致的基策略偏差问题，使用Stackelberg博弈框架和简单的奖励塑形方案，在推理时对齐设置中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法直接使用从用户偏好数据学习的奖励模型来优化LLM策略，并采用相对于基策略的KL正则化。这种做法在最大化用户效用方面是次优的，因为KL正则化可能导致LLM继承基策略中与用户偏好冲突的偏差。

Method: 将奖励模型优化问题形式化为Stackelberg博弈，提出一种简单的奖励塑形方案来有效近似最优奖励模型。该方法可无缝集成到现有对齐方法中，开销最小。

Result: 在推理时对齐设置中进行实证评估，该方法一致提高了平均奖励，在所有基线对比中平均胜率超过66%，在各种评估设置中均表现优异。

Conclusion: 通过优化奖励模型设计而非直接使用从偏好数据学习的奖励模型，可以有效解决KL正则化导致的基策略偏差问题，显著提升对齐效果和用户效用。

Abstract: Existing alignment methods directly use the reward model learned from user preference data to optimize an LLM policy, subject to KL regularization with respect to the base policy. This practice is suboptimal for maximizing user's utility because the KL regularization may cause the LLM to inherit the bias in the base policy that conflicts with user preferences. While amplifying rewards for preferred outputs can mitigate this bias, it also increases the risk of reward hacking. This tradeoff motivates the problem of optimally designing reward models under KL regularization. We formalize this reward model optimization problem as a Stackelberg game, and show that a simple reward shaping scheme can effectively approximate the optimal reward model. We empirically evaluate our method in inference-time alignment settings and demonstrate that it integrates seamlessly into existing alignment methods with minimal overhead. Our method consistently improves average reward and achieves win-tie rates exceeding 66% against all baselines, averaged across evaluation settings.

</details>


### [108] [QuantLRM: Quantization of Large Reasoning Models via Fine-Tuning Signals](https://arxiv.org/abs/2602.02581)
*Nan Zhang,Eugene Kwek,Yusen Zhang,Muyu Pan,Suhang Wang,Prasenjit Mitra,Rui Zhang*

Main category: cs.LG

TL;DR: QuantLRM：一种基于微调信号的大推理模型权重量化方法，通过保护权重更新幅度最大和最小的两端，相比传统方法平均提升6.55%性能


<details>
  <summary>Details</summary>
Motivation: 研究大推理模型（LRMs）量化时，权重更新幅度是否能提供有价值的量化信号。受经典幅度剪枝启发，探索微调过程中的权重更新幅度是否对量化有指导意义。

Method: 提出QuantLRM方法：1）验证"保护两端"假设（最小和最大的权重更新更重要）；2）在权重更新上拟合受限二次函数来保护两端；3）通过二次函数平均值与通道零更新计数的乘积计算通道重要性；4）支持伪微调获取信号以增强适用性。

Result: 在四个推理基准（AIME-120、FOLIO、时序序列、GPQA-Diamond）上量化各种微调模型（监督学习、直接偏好优化、强化学习微调），QuantLRM为LRMs量化带来一致改进，在强化学习微调模型上平均提升6.55%。

Conclusion: 权重更新幅度确实为LRMs量化提供有效信号，"保护两端"假设成立。QuantLRM方法简单有效，比使用激活或二阶信息更有效，且通过伪微调支持非微调模型，增强了适用性。

Abstract: Weight-only quantization is important for compressing Large Language Models (LLMs). Inspired by the spirit of classical magnitude pruning, we study whether the magnitude of weight updates during reasoning-incentivized fine-tuning can provide valuable signals for quantizing Large Reasoning Models (LRMs). We hypothesize that the smallest and largest weight updates during fine-tuning are more important than those of intermediate magnitude, a phenomenon we term "protecting both ends". Upon hypothesis validation, we introduce QuantLRM, which stands for weight quantization of LRMs via fine-tuning signals. We fit simple restricted quadratic functions on weight updates to protect both ends. By multiplying the average quadratic values with the count of zero weight updates of channels, we compute channel importance that is more effective than using activation or second-order information. We run QuantLRM to quantize various fine-tuned models (including supervised, direct preference optimization, and reinforcement learning fine-tuning) over four reasoning benchmarks (AIME-120, FOLIO, temporal sequences, and GPQA-Diamond) and empirically find that QuantLRM delivers a consistent improvement for LRMs quantization, with an average improvement of 6.55% on a reinforcement learning fine-tuned model. Also supporting non-fine-tuned LRMs, QuantLRM gathers effective signals via pseudo-fine-tuning, which greatly enhances its applicability.

</details>


### [109] [Copula-Based Aggregation and Context-Aware Conformal Prediction for Reliable Renewable Energy Forecasting](https://arxiv.org/abs/2602.02583)
*Alireza Moradi,Mathieu Tanneau,Reza Zandehshahvar,Pascal Van Hentenryck*

Main category: cs.LG

TL;DR: 提出一个校准的概率聚合框架，将站点级概率预测直接转换为可靠的舰队级预测，解决可再生能源聚合预测中的依赖性和校准问题。


<details>
  <summary>Details</summary>
Motivation: 可再生能源渗透率快速增长，需要可靠的舰队级概率预测支持电网运营。但系统运营商通常无法获得舰队级概率模型，只能依赖第三方提供的异构站点级预测。从这些输入构建一致且校准的舰队级概率预测具有挑战性，因为存在复杂的跨站点依赖性和聚合引起的校准偏差。

Method: 提出校准的概率聚合框架，结合基于copula的依赖建模来捕捉跨站点相关性，以及上下文感知的保形预测（CACP）来校正聚合级别的校准偏差。这种方法在无法训练或维护系统级模型的情况下，能够实现依赖感知的聚合，同时提供有效的覆盖范围并保持锐利的预测区间。

Result: 在MISO、ERCOT和SPP的大规模太阳能发电数据集上的实验表明，提出的Copula+CACP方法始终实现接近标称的覆盖范围，并且比未校准的聚合基线具有显著更锐利的预测区间。

Conclusion: 该框架为系统运营商提供了一种实用解决方案，能够从异构的站点级预测直接生成可靠、校准的舰队级概率预测，解决了可再生能源聚合预测中的关键挑战。

Abstract: The rapid growth of renewable energy penetration has intensified the need for reliable probabilistic forecasts to support grid operations at aggregated (fleet or system) levels. In practice, however, system operators often lack access to fleet-level probabilistic models and instead rely on site-level forecasts produced by heterogeneous third-party providers. Constructing coherent and calibrated fleet-level probabilistic forecasts from such inputs remains challenging due to complex cross-site dependencies and aggregation-induced miscalibration. This paper proposes a calibrated probabilistic aggregation framework that directly converts site-level probabilistic forecasts into reliable fleet-level forecasts in settings where system-level models cannot be trained or maintained. The framework integrates copula-based dependence modeling to capture cross-site correlations with Context-Aware Conformal Prediction (CACP) to correct miscalibration at the aggregated level. This combination enables dependence-aware aggregation while providing valid coverage and maintaining sharp prediction intervals. Experiments on large-scale solar generation datasets from MISO, ERCOT, and SPP demonstrate that the proposed Copula+CACP approach consistently achieves near-nominal coverage with significantly sharper intervals than uncalibrated aggregation baselines.

</details>


### [110] [Effective Frontiers: A Unification of Neural Scaling Laws](https://arxiv.org/abs/2602.02593)
*Jiaxuan Zou,Zixuan Gong,Ye Su,Huayi Tang,Yong Liu*

Main category: cs.LG

TL;DR: 该论文提出了一个统一框架，将学习任务抽象为从长尾分布中逐步覆盖模式的过程，通过引入有效边界概念解释神经缩放定律，并证明不同缩放定律是同一约束优化问题在不同瓶颈下的均衡解。


<details>
  <summary>Details</summary>
Motivation: 现有理论对神经缩放定律的解释往往依赖于特定架构或复杂的核方法，缺乏直观的普适性。作者希望建立一个统一的理论框架来解释模型容量、数据量和计算资源如何影响模型性能的幂律改进。

Method: 提出将一般学习任务抽象为从长尾（Zipfian）分布中逐步覆盖模式的过程，引入有效边界概念作为模式排序空间中的阈值，将已学知识与未学习的尾部区分开来。基于此框架推导出N、D、C的精确缩放定律，并通过最大瓶颈原则统一这些机制。

Result: 证明了可约损失渐近地由尾部概率质量决定，该质量受资源依赖的边界截断影响。推导出模型容量、数据覆盖和优化瓶颈分别对应的精确缩放定律，并证明Kaplan和Chinchilla缩放定律不是矛盾的，而是同一约束优化问题在不同活跃瓶颈下的均衡解。

Conclusion: 该研究提供了一个统一的框架来解释神经缩放定律，将模型容量、数据量和计算资源的缩放效应统一到同一理论框架下，揭示了不同缩放定律之间的内在联系，为理解和预测大规模模型性能提供了理论基础。

Abstract: Neural scaling laws govern the prediction power-law improvement of test loss with respect to model capacity ($N$), datasize ($D$), and compute ($C$). However, existing theoretical explanations often rely on specific architectures or complex kernel methods, lacking intuitive universality. In this paper, we propose a unified framework that abstracts general learning tasks as the progressive coverage of patterns from a long-tail (Zipfian) distribution. We introduce the Effective Frontier ($k_\star$), a threshold in the pattern rank space that separates learned knowledge from the unlearned tail. We prove that reducible loss is asymptotically determined by the probability mass of the tail a resource-dependent frontier truncation. Based on our framework, we derive the precise scaling laws for $N$, $D$, and $C$, attributing them to capacity, coverage, and optimization bottlenecks, respectively. Furthermore, we unify these mechanisms via a Max-Bottleneck principle, demonstrating that the Kaplan and Chinchilla scaling laws are not contradictory, but equilibrium solutions to the same constrained optimization problem under different active bottlenecks.

</details>


### [111] [Fubini Study geometry of representation drift in high dimensional data](https://arxiv.org/abs/2602.02596)
*Arturo Tozzi*

Main category: cs.LG

TL;DR: 该论文提出使用Fubini-Study度量来量化高维表示漂移，通过投影几何视角分离内在数据变化与参数化引入的规范变换，相比欧氏距离和余弦距离能更准确地捕捉表示的本质演化。


<details>
  <summary>Details</summary>
Motivation: 现有量化高维表示漂移的方法（如欧氏距离、余弦距离）假设固定坐标系，会将数据内在变化与任意参数化引入的规范变换（如全局缩放、符号翻转）混为一谈，导致对表示变化的系统性高估。

Method: 引入投影几何视角，基于Fubini-Study度量构建表示轨迹，该度量在规范变换下保持不变。通过计算累积几何漂移，比较欧氏距离、余弦距离和Fubini-Study距离在表示轨迹上的差异，并定义余弦距离与Fubini-Study距离之差作为可计算的单调量来捕捉规范自由度导致的表示变动。

Result: 在经验高维数据集上，传统度量（欧氏距离、余弦距离）在表示存在真实投影模糊性时会系统性高估变化，而Fubini-Study度量能通过保持规范变换不变性来分离内在演化。余弦距离与Fubini-Study距离之差可直接量化规范自由度导致的表示变动。

Conclusion: 建立了评估高维系统表示稳定性的几何标准，明确了角度距离的局限性。将表示动态嵌入投影空间将数据分析与已有几何程序连接起来，产生了可在经验工作流中直接测试的可观测量，为区分有意义的结构演化与参数化伪影提供了诊断工具。

Abstract: High dimensional representation drift is commonly quantified using Euclidean or cosine distances, which presuppose fixed coordinates when comparing representations across time, training or preprocessing stages. While effective in many settings, these measures entangle intrinsic changes in the data with variations induced by arbitrary parametrizations. We introduce a projective geometric view of representation drift grounded in the Fubini Study metric, which identifies representations that differ only by gauge transformations such as global rescalings or sign flips. Applying this framework to empirical high dimensional datasets, we explicitly construct representation trajectories and track their evolution through cumulative geometric drift. Comparing Euclidean, cosine and Fubini Study distances along these trajectories reveals that conventional metrics systematically overestimate change whenever representations carry genuine projective ambiguity. By contrast, the Fubini Study metric isolates intrinsic evolution by remaining invariant under gauge-induced fluctuations. We further show that the difference between cosine and Fubini Study drift defines a computable, monotone quantity that directly captures representation churn attributable to gauge freedom. This separation provides a diagnostic for distinguishing meaningful structural evolution from parametrization artifacts, without introducing model-specific assumptions. Overall, we establish a geometric criterion for assessing representation stability in high-dimensional systems and clarify the limits of angular distances. Embedding representation dynamics in projective space connects data analysis with established geometric programs and yields observables that are directly testable in empirical workflows.

</details>


### [112] [ContextEvolve: Multi-Agent Context Compression for Systems Code Optimization](https://arxiv.org/abs/2602.02597)
*Hongyuan Su,Yu Zheng,Yong Li*

Main category: cs.LG

TL;DR: ContextEvolve是一个多智能体框架，通过将优化上下文分解为三个正交维度，在参数不可见的约束下实现强化学习级别的搜索效率，用于优化LLM生成的系统算法代码。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM能生成看似合理的代码，但要满足系统对正确性和性能的严格要求需要迭代优化。测试时强化学习搜索效率高但需要参数更新，这在仅API访问下不可行；而现有的免训练进化方法存在上下文利用效率低和搜索无方向的问题。

Method: ContextEvolve将优化上下文分解为三个正交维度：Summarizer Agent通过代码到语言的抽象来浓缩语义状态，Navigator Agent通过轨迹分析提炼优化方向，Sampler Agent通过优先示例检索来管理经验分布。这种编排形成了与强化学习的函数同构，实现了文本潜在空间中的原则性优化。

Result: 在ADRS基准测试中，ContextEvolve比最先进的基线方法性能提升33.3%，同时减少29.0%的token消耗。

Conclusion: ContextEvolve通过多智能体框架在参数不可见的约束下实现了强化学习级别的搜索效率，为LLM生成的系统算法优化提供了有效的解决方案。

Abstract: Large language models are transforming systems research by automating the discovery of performance-critical algorithms for computer systems. Despite plausible codes generated by LLMs, producing solutions that meet the stringent correctness and performance requirements of systems demands iterative optimization. Test-time reinforcement learning offers high search efficiency but requires parameter updates infeasible under API-only access, while existing training-free evolutionary methods suffer from inefficient context utilization and undirected search. We introduce ContextEvolve, a multi-agent framework that achieves RL-level search efficiency under strict parameter-blind constraints by decomposing optimization context into three orthogonal dimensions: a Summarizer Agent condenses semantic state via code-to-language abstraction, a Navigator Agent distills optimization direction from trajectory analysis, and a Sampler Agent curates experience distribution through prioritized exemplar retrieval. This orchestration forms a functional isomorphism with RL-mapping to state representation, policy gradient, and experience replay-enabling principled optimization in a textual latent space. On the ADRS benchmark, ContextEvolve outperforms state-of-the-art baselines by 33.3% while reducing token consumption by 29.0%. Codes for our work are released at https://anonymous.4open.science/r/ContextEvolve-ACC

</details>


### [113] [RAP: KV-Cache Compression via RoPE-Aligned Pruning](https://arxiv.org/abs/2602.02599)
*Jihao Xin,Tian Lvu,Hatem Ltaief,David Keyes,Marco Canini*

Main category: cs.LG

TL;DR: RAP通过修剪RoPE对齐的列对，解决了RoPE-based LLMs中低秩分解KV压缩失败的问题，实现了KV-Cache、注意力参数和FLOPs的联合减少，同时保持准确性并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理在大型语言模型中越来越受到KV-Cache内存和计算成本的瓶颈。低秩分解通过W≈A*B压缩KV投影，但在现代基于RoPE的LLMs中，RoPE迫使潜在KV状态重建到完整维度，重新引入了大量内存和计算开销。

Method: 提出RoPE对齐剪枝(RAP)，修剪整个RoPE对齐的列对，以保留RoPE的2x2旋转结构，恢复B吸收，并消除重建。该方法在LLaMA-3-8B和Mistral-7B上进行评估。

Result: RAP能够同时将KV-Cache、注意力参数和FLOPs减少20-30%，同时保持强准确性。注意力延迟降低到基线的83%（预填充）和77%（解码）。

Conclusion: RAP通过结构化的剪枝方法有效解决了RoPE-based LLMs中KV压缩的挑战，实现了内存、计算和延迟的联合优化，为长上下文推理提供了实用的解决方案。

Abstract: Long-context inference in large language models is increasingly bottlenecked by the memory and compute cost of the KV-Cache. Low-rank factorization compresses KV projections by writing $W \approx A * B$, where A produces latent KV states and B can be absorbed into downstream weights. In modern RoPE-based LLMs, this absorption fails: RoPE forces latent KV states to be reconstructed to full dimension, reintroducing substantial memory and compute overhead. We propose RoPE-Aligned Pruning (RAP), which prunes entire RoPE-aligned column pairs to preserve RoPE's 2x2 rotation structure, restore B absorption, and eliminate reconstruction. Our evaluation on LLaMA-3-8B and Mistral-7B shows that RAP enables joint reduction of KV-Cache, attention parameters, and FLOPs by 20-30%, all at once, while maintaining strong accuracy. Notably, RAP reduces attention latency to 83% (prefill) and 77% (decode) of baseline.

</details>


### [114] [Step-Wise Refusal Dynamics in Autoregressive and Diffusion Language Models](https://arxiv.org/abs/2602.02600)
*Eliron Rahimi,Elad Hirshel,Rom Himelstein,Amit LeVi,Avi Mendelson,Chaim Baskin*

Main category: cs.LG

TL;DR: 本文提出了一种分析扩散语言模型拒绝行为的新框架，揭示了采样策略对安全性的核心作用，并引入SRI信号来改进模型安全性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散语言模型在生成质量和并行解码方面表现出色，但其采样机制如何影响拒绝行为和越狱鲁棒性仍不清楚。需要理解采样策略在安全性中的作用，以改进模型的安全防御能力。

Method: 提出了逐步拒绝动态分析框架，比较自回归和扩散采样。引入SRI信号来捕捉内部恢复动态，识别有害生成中的异常行为，并开发轻量级推理时检测器。

Result: SRI信号的几何结构能有效捕捉内部恢复动态，识别文本层面不可见的异常行为。基于SRI的检测器能泛化到未见攻击，性能优于现有防御方法，推理开销降低100倍以上。

Conclusion: 采样策略本身是影响模型安全行为的关键因素，独立于底层学习表示。SRI框架为模型安全提供了可解释的分析工具和高效的防御机制。

Abstract: Diffusion language models (DLMs) have recently emerged as a promising alternative to autoregressive (AR) models, offering parallel decoding and controllable sampling dynamics while achieving competitive generation quality at scale. Despite this progress, the role of sampling mechanisms in shaping refusal behavior and jailbreak robustness remains poorly understood. In this work, we present a fundamental analytical framework for step-wise refusal dynamics, enabling comparison between AR and diffusion sampling. Our analysis reveals that the sampling strategy itself plays a central role in safety behavior, as a factor distinct from the underlying learned representations. Motivated by this analysis, we introduce the Step-Wise Refusal Internal Dynamics (SRI) signal, which supports interpretability and improved safety for both AR and DLMs. We demonstrate that the geometric structure of SRI captures internal recovery dynamics, and identifies anomalous behavior in harmful generations as cases of \emph{incomplete internal recovery} that are not observable at the text level. This structure enables lightweight inference-time detectors that generalize to unseen attacks while matching or outperforming existing defenses with over $100\times$ lower inference overhead.

</details>


### [115] [Discovering Data Manifold Geometry via Non-Contracting Flows](https://arxiv.org/abs/2602.02611)
*David Vigouroux,Lucas Drumetz,Ronan Fablet,François Rousseau*

Main category: cs.LG

TL;DR: 提出一种无监督方法，通过在环境空间中学习向量场来构建全局参考系统，这些向量场跨越未知数据流形的切空间，从而定义可解释的内在坐标。


<details>
  <summary>Details</summary>
Motivation: 现有等距目标方法隐含假设流形平坦性，无法有效构建全局坐标系统。需要一种能够学习切向量场的方法，将样本传输到共同参考点，从而定义全局可解释的内在坐标。

Method: 学习环境空间中的切向量场，其流将所有样本传输到可学习的共同参考点。为防止退化崩溃，施加非收缩约束，并基于流匹配思想推导出可扩展、无需积分的优化目标。

Result: 理论证明最小化该目标可在存在全局坐标图时恢复它。实验显示在合成流形上获得正确的切向对齐和连贯的全局坐标结构，在CIFAR-10上学习到的坐标在下游分类任务中达到有竞争力的性能。

Conclusion: 该方法成功构建了全局参考系统，学习到的切向量场能够定义可解释的内在坐标，在理论和实证上都验证了其有效性，并展示了在实际数据集上的可扩展性。

Abstract: We introduce an unsupervised approach for constructing a global reference system by learning, in the ambient space, vector fields that span the tangent spaces of an unknown data manifold. In contrast to isometric objectives, which implicitly assume manifold flatness, our method learns tangent vector fields whose flows transport all samples to a common, learnable reference point. The resulting arc-lengths along these flows define interpretable intrinsic coordinates tied to a shared global frame. To prevent degenerate collapse, we enforce a non-shrinking constraint and derive a scalable, integration-free objective inspired by flow matching. Within our theoretical framework, we prove that minimizing the proposed objective recovers a global coordinate chart when one exists. Empirically, we obtain correct tangent alignment and coherent global coordinate structure on synthetic manifolds. We also demonstrate the scalability of our method on CIFAR-10, where the learned coordinates achieve competitive downstream classification performance.

</details>


### [116] [A Semi-Supervised Pipeline for Generalized Behavior Discovery from Animal-Borne Motion Time Series](https://arxiv.org/abs/2602.02618)
*Fatemeh Karimi Nejadasl,Judy Shamoun-Baranes,Eldar Rakhimberdiev*

Main category: cs.LG

TL;DR: 提出基于KDE+HDR包含度分数的半监督行为发现方法，用于从动物传感器数据中发现新行为类别，解决标签稀缺、类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 动物传感器数据的行为分类面临标签稀缺、类别高度不平衡、未标注行为可能存在的挑战，需要开发能够发现新行为类别的通用方法。

Method: 提出三步半监督发现流程：1)从标注子集学习嵌入函数；2)在标注和未标注样本的嵌入空间中进行标签引导聚类；3)使用KDE+HDR包含度分数判断发现的行为组是否真正新颖。

Result: 在完全从监督中排除某个行为类别的实验中，方法能够恢复出不同的聚类，包含度分数通过低重叠度标记新颖性；在无新行为的负控制设置中，重叠度始终较高。

Conclusion: 基于HDR的包含度分数为生态运动时间序列中的广义类别发现提供了实用、定量的测试方法，适用于有限标注和严重类别不平衡的情况。

Abstract: Learning behavioral taxonomies from animal-borne sensors is challenging because labels are scarce, classes are highly imbalanced, and behaviors may be absent from the annotated set. We study generalized behavior discovery in short multivariate motion snippets from gulls, where each sample is a sequence with 3-axis IMU acceleration (20 Hz) and GPS speed, spanning nine expert-annotated behavior categories. We propose a semi-supervised discovery pipeline that (i) learns an embedding function from the labeled subset, (ii) performs label-guided clustering over embeddings of both labeled and unlabeled samples to form candidate behavior groups, and (iii) decides whether a discovered group is truly novel using a containment score. Our key contribution is a KDE + HDR (highest-density region) containment score that measures how much a discovered cluster distribution is contained within, or contains, each known-class distribution; the best-match containment score serves as an interpretable novelty statistic. In experiments where an entire behavior is withheld from supervision and appears only in the unlabeled pool, the method recovers a distinct cluster and the containment score flags novelty via low overlap, while a negative-control setting with no novel behavior yields consistently higher overlaps. These results suggest that HDR-based containment provides a practical, quantitative test for generalized class discovery in ecological motion time series under limited annotation and severe class imbalance.

</details>


### [117] [daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently](https://arxiv.org/abs/2602.02619)
*Mohan Jiang,Dayuan Fu,Junhao Shi,Ji Zeng,Weiye Si,Keyu Li,Xuefeng Li,Yang Xiao,Wenjie Li,Dequan Wang,Pengfei Liu*

Main category: cs.LG

TL;DR: daVinci-Agency：通过挖掘GitHub Pull Request序列中的真实软件演化轨迹，为长时程智能体工作流提供高质量监督数据，显著提升LLM在复杂任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在短时任务上表现出色，但在长时程智能体工作流中面临挑战。核心瓶颈在于缺乏能够捕捉真实长依赖结构和跨阶段演化动态的训练数据。现有数据合成方法要么局限于模型分布约束的单特征场景，要么需要高昂的人工标注成本，无法提供可扩展的高质量监督。

Method: 提出daVinci-Agency方法，通过三个相互关联的机制从Pull Request序列中挖掘结构化监督：(1) 通过连续提交实现渐进式任务分解；(2) 通过统一功能目标强制执行长期一致性；(3) 从真实的bug修复轨迹中获得可验证的改进。该方法基于真实软件演化过程，保留了因果依赖和迭代改进模式。

Result: 生成的轨迹平均包含85k tokens和116个工具调用，数据效率显著。在GLM-4.6模型上仅使用239个daVinci-Agency样本进行微调，就在多个基准测试中取得广泛改进，特别是在Toolathlon上获得47%的相对增益。

Conclusion: 通过重新概念化数据合成，利用真实软件演化过程（特别是Pull Request序列）为长时程智能体学习提供高质量监督信号，daVinci-Agency方法在保持数据效率的同时显著提升了模型性能，为长时程工作流学习提供了新的方向。

Abstract: While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics--existing synthesis methods either confine to single-feature scenarios constrained by model distribution, or incur prohibitive human annotation costs, failing to provide scalable, high-quality supervision. We address this by reconceptualizing data synthesis through the lens of real-world software evolution. Our key insight: Pull Request (PR) sequences naturally embody the supervision signals for long-horizon learning. They decompose complex objectives into verifiable submission units, maintain functional coherence across iterations, and encode authentic refinement patterns through bug-fix histories. Building on this, we propose daVinci-Agency, which systematically mines structured supervision from chain-of-PRs through three interlocking mechanisms: (1) progressive task decomposition via continuous commits, (2) long-term consistency enforcement through unified functional objectives, and (3) verifiable refinement from authentic bug-fix trajectories. Unlike synthetic trajectories that treat each step independently, daVinci-Agency's PR-grounded structure inherently preserves the causal dependencies and iterative refinements essential for teaching persistent goal-directed behavior and enables natural alignment with project-level, full-cycle task modeling. The resulting trajectories are substantial--averaging 85k tokens and 116 tool calls--yet remarkably data-efficient: fine-tuning GLM-4.6 on 239 daVinci-Agency samples yields broad improvements across benchmarks, notably achieving a 47% relative gain on Toolathlon. Beyond benchmark performance, our analysis confirms...

</details>


### [118] [A Reduction from Delayed to Immediate Feedback for Online Convex Optimization with Improved Guarantees](https://arxiv.org/abs/2602.02634)
*Alexander Ryabchenko,Idan Attias,Daniel M. Roy*

Main category: cs.LG

TL;DR: 提出基于约简的在线学习延迟反馈框架，改进了一阶和bandit凸优化的现有结果，通过连续时间模型将遗憾分解为延迟无关学习项和延迟诱导漂移项。


<details>
  <summary>Details</summary>
Motivation: 现有在线学习延迟反馈方法存在局限性，特别是在bandit凸优化中延迟依赖项的遗憾界不够紧致，需要更统一、更优的分析框架。

Method: 引入连续时间模型，将遗憾分解为延迟无关学习项和延迟诱导漂移项，提出延迟自适应约简方法，可将任何在线线性优化算法转换为处理轮次依赖延迟的算法。

Result: 对于bandit凸优化，显著改进了现有遗憾界，延迟依赖项达到最优一阶速率；对于一阶反馈，通过更简单统一的分析恢复了最优遗憾界。具体地，将延迟依赖项从O(min{√(T d_max),(Td_tot)^(1/3)})改进到O(√d_tot)。

Conclusion: 提出的约简框架为在线学习延迟反馈提供了统一分析方法，显著改进了bandit凸优化的理论结果，延迟依赖项达到最优，且分析更简洁。

Abstract: We develop a reduction-based framework for online learning with delayed feedback that recovers and improves upon existing results for both first-order and bandit convex optimization. Our approach introduces a continuous-time model under which regret decomposes into a delay-independent learning term and a delay-induced drift term, yielding a delay-adaptive reduction that converts any algorithm for online linear optimization into one that handles round-dependent delays. For bandit convex optimization, we significantly improve existing regret bounds, with delay-dependent terms matching state-of-the-art first-order rates. For first-order feedback, we recover state-of-the-art regret bounds via a simpler, unified analysis. Quantitatively, for bandit convex optimization we obtain $O(\sqrt{d_{\text{tot}}} + T^{\frac{3}{4}}\sqrt{k})$ regret, improving the delay-dependent term from $O(\min\{\sqrt{T d_{\text{max}}},(Td_{\text{tot}})^{\frac{1}{3}}\})$ in previous work to $O(\sqrt{d_{\text{tot}}})$. Here, $k$, $T$, $d_{\text{max}}$, and $d_{\text{tot}}$ denote the dimension, time horizon, maximum delay, and total delay, respectively. Under strong convexity, we achieve $O(\min\{σ_{\text{max}} \ln T, \sqrt{d_{\text{tot}}}\} + (T^2\ln T)^{\frac{1}{3}} {k}^{\frac{2}{3}})$, improving the delay-dependent term from $O(d_{\text{max}} \ln T)$ in previous work to $O(\min\{σ_{\text{max}} \ln T, \sqrt{d_{\text{tot}}}\})$, where $σ_{\text{max}}$ denotes the maximum number of outstanding observations and may be considerably smaller than $d_{\text{max}}$.

</details>


### [119] [hSNMF: Hybrid Spatially Regularized NMF for Image-Derived Spatial Transcriptomics](https://arxiv.org/abs/2602.02638)
*Md Ishtyaq Mahmud,Veena Kochat,Suresh Satpati,Jagan Mohan Reddy Dwarampudi,Humaira Anzum,Kunal Rai,Tania Banerjee*

Main category: cs.LG

TL;DR: 该研究针对高分辨率空间转录组学数据（如Xenium平台）的维度挑战，提出了两种空间正则化的非负矩阵分解方法：SNMF和hSNMF，显著提升了聚类结果的空间紧凑性和生物学一致性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率空间转录组学平台（如Xenium）生成的数据具有极高维度，这给表示学习和聚类带来了重大挑战。需要开发能够有效利用空间信息的分析方法来改善聚类质量。

Method: 提出了两种空间正则化的非负矩阵分解方法：1) SNMF：通过将每个细胞的NMF因子向量在其空间邻域内扩散来强制局部空间平滑性；2) hSNMF：执行空间正则化NMF，然后在混合邻接矩阵上进行Leiden聚类，该矩阵通过可调参数α整合空间邻近性（通过接触半径图）和转录组相似性。

Result: 在胆管癌数据集上的评估显示，SNMF和hSNMF相比其他空间基线方法，显著改善了空间紧凑性（CHAOS < 0.004，Moran's I > 0.96）、聚类可分离性（Silhouette > 0.12，DBI < 1.8）和生物学一致性（CMC和富集分析）。

Conclusion: 该研究提出的空间正则化NMF方法能够有效处理高分辨率空间转录组学数据，通过整合空间信息显著提升了聚类质量，为空间转录组学分析提供了新的工具。

Abstract: High-resolution spatial transcriptomics platforms, such as Xenium, generate single-cell images that capture both molecular and spatial context, but their extremely high dimensionality poses major challenges for representation learning and clustering. In this study, we analyze data from the Xenium platform, which captures high-resolution images of tumor microarray (TMA) tissues and converts them into cell-by-gene matrices suitable for computational analysis. We benchmark and extend nonnegative matrix factorization (NMF) for spatial transcriptomics by introducing two spatially regularized variants. First, we propose Spatial NMF (SNMF), a lightweight baseline that enforces local spatial smoothness by diffusing each cell's NMF factor vector over its spatial neighborhood. Second, we introduce Hybrid Spatial NMF (hSNMF), which performs spatially regularized NMF followed by Leiden clustering on a hybrid adjacency that integrates spatial proximity (via a contact-radius graph) and transcriptomic similarity through a tunable mixing parameter alpha. Evaluated on a cholangiocarcinoma dataset, SNMF and hSNMF achieve markedly improved spatial compactness (CHAOS < 0.004, Moran's I > 0.96), greater cluster separability (Silhouette > 0.12, DBI < 1.8), and higher biological coherence (CMC and enrichment) compared to other spatial baselines. Availability and implementation: https://github.com/ishtyaqmahmud/hSNMF

</details>


### [120] [MARA: Continuous SE(3)-Equivariant Attention for Molecular Force Fields](https://arxiv.org/abs/2602.02671)
*Francesco Leonardi,Boris Bonev,Kaspar Riesen*

Main category: cs.LG

TL;DR: MARA是一种用于分子力场的模块化角度-径向注意力机制，通过扩展球形注意力到SE(3)等变架构，提供灵活、几何感知的局部环境加权，提升原子模型的表达能力和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习力场大多依赖固定的角度展开，限制了局部几何相互作用的加权灵活性，需要更灵活、几何感知的注意力机制来提升原子建模的准确性和鲁棒性。

Method: 提出模块化角度-径向注意力(MARA)，将球形注意力扩展到分子领域和SE(3)等变性，直接在相邻原子的角度和径向坐标上操作，实现灵活、几何感知的局部环境加权，可即插即用地集成到MACE等模型中。

Result: 在分子基准测试中，MARA改善了能量和力的预测，减少了高误差事件，增强了模型的鲁棒性，证明了连续球形注意力作为几何算子的有效性和泛化能力。

Conclusion: 连续球形注意力是一种有效且可泛化的几何算子，能够提高原子模型的表达能力、稳定性和可靠性，为机器学习力场提供了更灵活的几何感知注意力机制。

Abstract: Machine learning force fields (MLFFs) have become essential for accurate and efficient atomistic modeling. Despite their high accuracy, most existing approaches rely on fixed angular expansions, limiting flexibility in weighting local geometric interactions. We introduce Modular Angular-Radial Attention (MARA), a module that extends spherical attention -- originally developed for SO(3) tasks -- to the molecular domain and SE(3), providing an efficient approximation of equivariant interactions. MARA operates directly on the angular and radial coordinates of neighboring atoms, enabling flexible, geometrically informed, and modular weighting of local environments. Unlike existing attention mechanisms in SE(3)-equivariant architectures, MARA can be integrated in a plug-and-play manner into models such as MACE without architectural modifications. Across molecular benchmarks, MARA improves energy and force predictions, reduces high-error events, and enhances robustness. These results demonstrate that continuous spherical attention is an effective and generalizable geometric operator that increases the expressiveness, stability, and reliability of atomistic models.

</details>


### [121] [Expert-Data Alignment Governs Generation Quality in Decentralized Diffusion Models](https://arxiv.org/abs/2602.02685)
*Marcos Villagra,Bidhan Roy,Raihan Seraj,Zhiying Jiang*

Main category: cs.LG

TL;DR: 研究发现去中心化扩散模型（DDMs）中，生成质量的关键因素是专家与数据的对齐程度，而非采样稳定性。稀疏路由（如Top-2）通过选择训练数据与当前去噪状态最匹配的专家，实现了更好的生成质量。


<details>
  <summary>Details</summary>
Motivation: 去中心化扩散模型（DDMs）使用在不相交数据集群上独立训练的专家进行去噪，但这些专家的预测可能存在严重分歧。目前尚不清楚是什么因素主导着这种系统的生成质量，传统认为最小化去噪轨迹敏感性（即采样过程中扰动的放大程度）应该决定生成质量，但这一假设需要验证。

Method: 通过系统研究DDMs的生成质量决定因素，比较了不同路由策略：全集成路由（所有专家预测组合）和稀疏路由（如Top-2）。使用三种分析方法验证专家-数据对齐原则：(1) 数据-集群距离分析，确认稀疏路由选择的专家其训练数据集群最接近当前去噪状态；(2) 按专家分析，显示被选专家比未被选专家产生更准确的预测；(3) 专家分歧分析，显示专家分歧时生成质量下降。

Result: 发现稳定性与质量之间存在分离：全集成路由实现了最稳定的采样动态和最佳数值收敛，但生成质量最差（FID 47.9）。相反，稀疏Top-2路由实现了更好的生成质量（FID 22.6）。专家-数据对齐是主导因素：生成质量取决于将输入路由到训练分布覆盖当前去噪状态的专家。这一发现在两个不同的DDM系统中得到验证。

Conclusion: 对于DDM部署，路由应优先考虑专家-数据对齐，而不是数值稳定性指标。专家-数据对齐原则是决定去中心化扩散模型生成质量的关键因素，这为优化DDM系统提供了新的设计方向。

Abstract: Decentralized Diffusion Models (DDMs) route denoising through experts trained independently on disjoint data clusters, which can strongly disagree in their predictions. What governs the quality of generations in such systems? We present the first ever systematic investigation of this question. A priori, the expectation is that minimizing denoising trajectory sensitivity -- minimizing how perturbations amplify during sampling -- should govern generation quality. We demonstrate this hypothesis is incorrect: a stability-quality dissociation. Full ensemble routing, which combines all expert predictions at each step, achieves the most stable sampling dynamics and best numerical convergence while producing the worst generation quality (FID 47.9 vs. 22.6 for sparse Top-2 routing). Instead, we identify expert-data alignment as the governing principle: generation quality depends on routing inputs to experts whose training distribution covers the current denoising state. Across two distinct DDM systems, we validate expert-data alignment using (i) data-cluster distance analysis, confirming sparse routing selects experts with data clusters closest to the current denoising state, and (ii) per-expert analysis, showing selected experts produce more accurate predictions than non-selected ones, and (iii) expert disagreement analysis, showing quality degrades when experts disagree. For DDM deployment, our findings establish that routing should prioritize expert-data alignment over numerical stability metrics.

</details>


### [122] [Sparsely Supervised Diffusion](https://arxiv.org/abs/2602.02699)
*Wenshuai Zhao,Zhiyuan Li,Yi Zhao,Mohammad Hassan Vali,Martin Trapp,Joni Pajarinen,Juho Kannala,Arno Solin*

Main category: cs.LG

TL;DR: 提出了一种用于扩散模型的稀疏监督学习方法，通过简单的掩码策略解决空间不一致生成问题，可在训练时安全地掩码高达98%的像素


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成任务中表现出色，但存在空间不一致生成的问题，这可能是由于其去噪机制固有的局部性导致的，会产生局部合理但全局不一致的样本

Method: 提出稀疏监督学习，采用简单的掩码策略，只需几行代码即可实现。实验表明在扩散模型训练期间可以安全地掩码高达98%的像素

Result: 该方法在各种实验中实现了有竞争力的FID分数，最重要的是在小数据集上避免了训练不稳定性。掩码策略减少了记忆化，促进了生成过程中对基本上下文信息的使用

Conclusion: 稀疏监督学习是一种简单有效的扩散模型改进方法，通过掩码策略解决了空间不一致性问题，提高了生成质量和训练稳定性

Abstract: Diffusion models have shown remarkable success across a wide range of generative tasks. However, they often suffer from spatially inconsistent generation, arguably due to the inherent locality of their denoising mechanisms. This can yield samples that are locally plausible but globally inconsistent. To mitigate this issue, we propose sparsely supervised learning for diffusion models, a simple yet effective masking strategy that can be implemented with only a few lines of code. Interestingly, the experiments show that it is safe to mask up to 98\% of pixels during diffusion model training. Our method delivers competitive FID scores across experiments and, most importantly, avoids training instability on small datasets. Moreover, the masking strategy reduces memorization and promotes the use of essential contextual information during generation.

</details>


### [123] [Every Bit Counts: A Theoretical Study of Precision-Expressivity Tradeoffs in Quantized Transformers](https://arxiv.org/abs/2602.02707)
*Sayak Chakrabarti,Toniann Pitassi,Josh Alman*

Main category: cs.LG

TL;DR: 论文证明了Transformer量化精度与表达能力之间的精细权衡：对于每个精度p，存在一个函数Γ（受相等函数启发），单层softmax Transformer可以用p位精度计算Γ，但不能用p-1位精度计算。


<details>
  <summary>Details</summary>
Motivation: 量化广泛用于加速Transformer推理，但其对表达能力的影响缺乏理论分析。本文旨在从理论上解释量化导致表达能力损失的普遍现象，并为实践者提供量化精度选择的指导。

Method: 结合显式有限精度Transformer构造与通信复杂度下界证明方法，建立紧致的"一位"阈值理论。

Result: 证明了量化精度与表达能力之间的精细权衡：对于每个精度p，存在函数Γ，单层softmax Transformer可以用p位精度计算但不能用p-1位精度计算。这解释了量化导致表达能力损失的现象，并表明需要相等比较的任务对量化特别敏感。

Conclusion: 量化精度选择应基于具体任务所需的相等比较长度，为实践者提供了量化精度选择的启发式指导，并建立了Transformer量化理论分析的基础框架。

Abstract: Quantization reduces the numerical precision of Transformer computations and is widely used to accelerate inference, yet its effect on expressivity remains poorly characterized. We demonstrate a fine-grained theoretical tradeoff between expressivity and precision: For every p we exhibit a function Γ, inspired by the equality function, and prove that a one-layer softmax Transformer can compute Γ, with p bits of precision, but not with p-1 bits of precision.
  This result concretely explains the widely observed phenomenon of empirical loss of expressivity when quantization is used. Practically, it suggests that tasks requiring equality-like comparisons (exact match, membership, etc.) are especially sensitive to quantization. Dropping even one bit can cross a threshold where the model cannot represent the needed comparison reliably. Thus, it paves the way for developing heuristics that will help practitioners choose how much quantization is possible: the precision should be chosen as a function of the length of equality to be checked for the specific task.
  Our proofs combine explicit finite-precision Transformer constructions with communication-complexity lower bounds, yielding a tight "one-bit" threshold.

</details>


### [124] [BinaryPPO: Efficient Policy Optimization for Binary Classification](https://arxiv.org/abs/2602.02708)
*Punya Syon Pandey,Zhijing Jin*

Main category: cs.LG

TL;DR: BinaryPPO：将二元分类重构为奖励最大化问题的离线强化学习框架，在标签噪声、类别不平衡或稀疏监督等现实场景中显著优于监督微调方法


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）在二元分类任务（如毒性检测、事实性验证、因果推理）中表现不佳，特别是在现实场景中存在标签噪声、类别不平衡或稀疏监督的情况下。需要一种更鲁棒的方法来处理这些挑战。

Method: BinaryPPO是一个离线强化学习框架，将二元分类重新定义为奖励最大化问题。该方法使用Proximal Policy Optimization（PPO）的变体，结合置信度加权的奖励函数，惩罚不确定或不正确的预测，使模型能够从静态数据集中学习鲁棒的决策策略，无需在线交互。

Result: 在八个领域特定基准测试和多种不同架构的模型中，BinaryPPO将准确率提高了40-60个百分点，最高达到99%，显著优于监督基线方法。研究还深入分析了奖励塑造、优势缩放和政策稳定性在实现这一改进中的作用。

Conclusion: 基于置信度的奖励设计为二元分类提供了比监督微调更鲁棒的替代方案。BinaryPPO框架在处理现实世界数据挑战方面表现出色，为分类任务提供了新的强化学习视角。

Abstract: Supervised fine-tuning (SFT) is the standard approach for binary classification tasks such as toxicity detection, factuality verification, and causal inference. However, SFT often performs poorly in real-world settings with label noise, class imbalance, or sparse supervision. We introduce BinaryPPO, an offline reinforcement learning large language model (LLM) framework that reformulates binary classification as a reward maximization problem. Our method leverages a variant of Proximal Policy Optimization (PPO) with a confidence-weighted reward function that penalizes uncertain or incorrect predictions, enabling the model to learn robust decision policies from static datasets without online interaction. Across eight domain-specific benchmarks and multiple models with differing architectures, BinaryPPO improves accuracy by 40-60 percentage points, reaching up to 99%, substantially outperforming supervised baselines. We provide an in-depth analysis of the role of reward shaping, advantage scaling, and policy stability in enabling this improvement. Overall, we demonstrate that confidence-based reward design provides a robust alternative to SFT for binary classification. Our code is available at https://github.com/psyonp/BinaryPPO.

</details>


### [125] [Maximum Likelihood Reinforcement Learning](https://arxiv.org/abs/2602.02710)
*Fahim Tajwar,Guanning Zeng,Yueer Zhou,Yuda Song,Daman Arora,Yiding Jiang,Jeff Schneider,Ruslan Salakhutdinov,Haiwen Feng,Andrea Zanette*

Main category: cs.LG

TL;DR: MaxRL是一种新的强化学习框架，通过采样计算来逼近最大似然估计，在采样设置中优于传统RL方法


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在基于采样的二元结果反馈设置（如导航、代码生成、数学问题求解）中，只优化了正确轨迹似然的下阶近似，而非最大化似然本身

Method: 提出最大似然强化学习（MaxRL），定义了一个计算索引的基于采样的目标函数族，随着采样计算资源的增加，在标准RL和精确最大似然之间插值，使用简单无偏的策略梯度估计器

Result: MaxRL在所有测试的模型和任务中都帕累托优于现有方法，相比GRPO训练的对应模型实现了高达20倍的测试时缩放效率增益，在额外数据和计算方面也表现出更好的扩展性

Conclusion: MaxRL是基于正确性设置中扩展RL训练的有前景框架，能够更有效地利用采样计算资源来逼近最大似然优化

Abstract: Reinforcement learning is the method of choice to train models in sampling-based setups with binary outcome feedback, such as navigation, code generation, and mathematical problem solving. In such settings, models implicitly induce a likelihood over correct rollouts. However, we observe that reinforcement learning does not maximize this likelihood, and instead optimizes only a lower-order approximation. Inspired by this observation, we introduce Maximum Likelihood Reinforcement Learning (MaxRL), a sampling-based framework to approximate maximum likelihood using reinforcement learning techniques. MaxRL addresses the challenges of non-differentiable sampling by defining a compute-indexed family of sample-based objectives that interpolate between standard reinforcement learning and exact maximum likelihood as additional sampling compute is allocated. The resulting objectives admit a simple, unbiased policy-gradient estimator and converge to maximum likelihood optimization in the infinite-compute limit. Empirically, we show that MaxRL Pareto-dominates existing methods in all models and tasks we tested, achieving up to 20x test-time scaling efficiency gains compared to its GRPO-trained counterpart. We also observe MaxRL to scale better with additional data and compute. Our results suggest MaxRL is a promising framework for scaling RL training in correctness based settings.

</details>


### [126] [A Single Revision Step Improves Token-Efficient LLM Reasoning](https://arxiv.org/abs/2602.02828)
*Yingchuan Zhang,Terry Ma,Wenxuan Zhong,Ping Ma*

Main category: cs.LG

TL;DR: PACER是一种无需训练、仅在推理时使用的框架，通过让推理轨迹相互"同行评审"来解决大语言模型在复杂推理任务中的"盲点"问题，显著提升准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过多轨迹采样增加测试时计算来提高推理准确性，但传统聚合方法（如多数投票或基于个体置信度的过滤）存在根本性"盲点"：它们孤立评估每个轨迹。随着问题难度增加，模型常生成具有误导性高置信度的幻觉路径，导致真实解决方案在传统投票中被微弱优势压制。

Method: 提出Packet-Conditioned Revision (PACER)框架：1）对生成的轨迹进行初步筛选；2）构建紧凑的共识包，包含独特候选答案、聚合置信度分数和每个候选答案的代表性推理摘要；3）个体轨迹基于此包进行有针对性的自我审查，识别与广泛共识分歧的逻辑节点并在发现原始推理有缺陷时进行调整；4）最终通过修订后轨迹的置信度加权投票获得预测。

Result: 在AIME和BRUMO等具有挑战性的数学竞赛基准测试中，PACER达到或超过256样本多数投票的准确性，显著优于原始集成基线，将简单共识转化为协作逻辑精炼过程。

Conclusion: PACER通过让推理轨迹相互"同行评审"，解决了传统聚合方法的根本性盲点，将简单共识转化为协作逻辑精炼过程，显著提升大语言模型在复杂推理任务中的准确性。

Abstract: Large language models (LLMs) achieve higher accuracy on challenging reasoning tasks by scaling test-time compute through multiple trajectory sampling. However, standard aggregation methods like majority voting or individual confidence-based filtering face a fundamental "blind spot": they evaluate each trace in isolation. As problems scale in difficulty, models often generate hallucinated paths that exhibit misleadingly high confidence, causing the true solution to be suppressed by a narrow margin in traditional voting. We ask: can we enable traces to "peer-review" each other to resolve these near-miss errors?
  We introduce Packet-Conditioned Revision (PACER), a training-free, inference-only framework that enables reasoning traces to revise their conclusions through a structured coordination step. After a preliminary screening of generated traces, PACER constructs a compact consensus packet containing (i) unique candidate answers, (ii) their aggregated confidence scores, and (iii) representative reasoning summaries for each candidate answer. Individual traces then perform a targeted self-review conditioned on this packet, allowing them to identify specific logical junctions where they diverged from the broader consensus and pivot if their original reasoning is found to be flawed. Final predictions are obtained via confidence-weighted voting over these revised trajectories. On challenging competitive math benchmarks such as AIME and BRUMO, PACER matches or exceeds the accuracy of 256-sample majority voting, significantly outperforming raw ensemble baselines by transforming simple consensus into a collaborative logical refinement process.

</details>


### [127] [SC3D: Dynamic and Differentiable Causal Discovery for Temporal and Instantaneous Graphs](https://arxiv.org/abs/2602.02830)
*Sourajit Das,Dibyajyoti Chakraborthy,Romit Maulik*

Main category: cs.LG

TL;DR: SC3D是一个两阶段可微分框架，用于从多元时间序列中发现跨多个滞后的因果结构和可能的瞬时依赖关系。


<details>
  <summary>Details</summary>
Motivation: 从多元时间序列中发现因果结构具有挑战性，因为交互跨越多个滞后且可能涉及瞬时依赖，同时动态图的搜索空间本质上是组合性的。

Method: 提出SC3D两阶段可微分框架：第一阶段通过节点预测进行边预选，获得滞后边和瞬时边的掩码；第二阶段通过优化稀疏性似然并强制瞬时块的无环性来细化这些掩码。

Result: 在合成和基准动态系统上的数值结果表明，SC3D相比现有时间基线方法，在滞后和瞬时因果结构的恢复方面实现了更高的稳定性和准确性。

Conclusion: SC3D框架能够有效发现多元时间序列中的跨滞后因果结构和瞬时依赖关系，在因果结构恢复方面优于现有方法。

Abstract: Discovering causal structures from multivariate time series is a key problem because interactions span across multiple lags and possibly involve instantaneous dependencies. Additionally, the search space of the dynamic graphs is combinatorial in nature. In this study, we propose \textit{Stable Causal Dynamic Differentiable Discovery (SC3D)}, a two-stage differentiable framework that jointly learns lag-specific adjacency matrices and, if present, an instantaneous directed acyclic graph (DAG). In Stage 1, SC3D performs edge preselection through node-wise prediction to obtain masks for lagged and instantaneous edges, whereas Stage 2 refines these masks by optimizing a likelihood with sparsity along with enforcing acyclicity on the instantaneous block. Numerical results across synthetic and benchmark dynamical systems demonstrate that SC3D achieves improved stability and more accurate recovery of both lagged and instantaneous causal structures compared to existing temporal baselines.

</details>


### [128] [Tabula RASA: Exposing and Breaking the Relational Bottleneck in Transformers](https://arxiv.org/abs/2602.02834)
*Jonas Petersen,Camilla Mazzoleni,Riccardo Maggioni*

Main category: cs.LG

TL;DR: RASA通过添加边类型嵌入和稀疏注意力掩码，改进了Transformer在多跳关系推理任务上的表现，在MetaQA和WebQuestionsSP上超越标准Transformer并接近GPT-4性能。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer在处理需要多跳关系推理的结构化数据任务时表现不佳，其电路复杂度限制使其需要Ω(k)层来完成k跳推理。需要一种最小化修改的方法来提升Transformer在这类任务上的性能。

Method: 提出RASA（关系感知稀疏注意力），包含两个关键修改：1）边类型嵌入：将关系结构注入注意力分数；2）稀疏掩码：将注意力限制在图相邻位置。稀疏掩码将注意力搜索空间从O(2^{n^2})减少到O(2^m)，边偏置提供显式关系路由。

Result: 在MetaQA（1/2/3跳）和WebQuestionsSP数据集上，RASA优于标准Transformer，在较低成本下达到与GPT-4相当的性能，且推理深度越大优势越明显（3跳任务上提升7.1分）。

Conclusion: 尽管没有形式化的可学习性保证，但实证表明最小的结构修改能显著提升Transformer在多跳关系推理任务上的性能，为解决结构化数据推理问题提供了有效途径。

Abstract: Transformers achieve remarkable performance across many domains, yet struggle with tasks requiring multi-hop relational reasoning over structured data. We analyze this limitation through circuit complexity: standard transformers are $\mathsf{TC}^0$-complete and require $Ω(k)$ layers for $k$-hop reasoning. We introduce RASA (Relation-Aware Sparse Attention), a minimal modification adding: (1) edge-type embeddings that inject relational structure into attention scores, and (2) sparse masking that restricts attention to graph-adjacent positions. While RASA has the same asymptotic depth requirements, sparse masking reduces the attention search space from $O(2^{n^2})$ to $O(2^m)$ patterns, and edge biases provide explicit relation routing. Empirically, on MetaQA (1/2/3-hop) and WebQuestionsSP, RASA outperforms standard transformers and matches GPT-4 at lower cost, with advantages growing with reasoning depth (+7.1 points on 3-hop). We do not claim formal learnability guarantees; the contribution is empirical validation that minimal structural modifications substantially improve multi-hop reasoning.

</details>


### [129] [Semantics-Aware Generative Latent Data Augmentation for Learning in Low-Resource Domains](https://arxiv.org/abs/2602.02841)
*Jae-Sung Bae,Minje Kim*

Main category: cs.LG

TL;DR: GeLDA是一个语义感知的生成式潜在数据增强框架，利用条件扩散模型在基础模型诱导的潜在空间中合成样本，以解决数据稀缺场景下的深度学习性能问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习在数据丰富时表现良好，但在实际常见的数据稀缺场景下表现不佳。虽然基础模型通过大规模数据训练提取通用特征，但在下游微调时仍面临标记数据稀缺的问题。

Method: 提出GeLDA框架：1）在基础模型诱导的低维潜在空间中进行数据生成；2）使用条件扩散模型；3）利用捕捉类别或子域间语义关系的辅助特征向量来条件化生成；4）该潜在空间相比输入空间维度更低且集中了任务相关信息。

Result: 1）在零样本语言特定语音情感识别任务中，GeLDA将Whisper-large基线的未加权平均召回率提高了6.13%；2）在长尾图像分类任务中，在ImageNet-LT上实现了74.7%的尾部类别准确率，创造了新的最先进结果。

Conclusion: GeLDA通过在高信息密度的潜在空间中进行语义感知的数据增强，有效解决了数据稀缺问题，在多个大规模识别任务中显著提升了性能。

Abstract: Despite strong performance in data-rich regimes, deep learning often underperforms in the data-scarce settings common in practice. While foundation models (FMs) trained on massive datasets demonstrate strong generalization by extracting general-purpose features, they can still suffer from scarce labeled data during downstream fine-tuning. To address this, we propose GeLDA, a semantics-aware generative latent data augmentation framework that leverages conditional diffusion models to synthesize samples in an FM-induced latent space. Because this space is low-dimensional and concentrates task-relevant information compared to the input space, GeLDA enables efficient, high-quality data generation. GeLDA conditions generation on auxiliary feature vectors that capture semantic relationships among classes or subdomains, facilitating data augmentation in low-resource domains. We validate GeLDA in two large-scale recognition tasks: (a) in zero-shot language-specific speech emotion recognition, GeLDA improves the Whisper-large baseline's unweighted average recall by 6.13%; and (b) in long-tailed image classification, it achieves 74.7% tail-class accuracy on ImageNet-LT, setting a new state-of-the-art result.

</details>


### [130] [Causal Flow Q-Learning for Robust Offline Reinforcement Learning](https://arxiv.org/abs/2602.02847)
*Mingxuan Li,Junzhe Zhang,Elias Bareinboim*

Main category: cs.LG

TL;DR: 该论文提出了一种针对离线强化学习中观测混淆问题的因果方法，通过流匹配策略学习，在像素级任务上比现有方法提升120%成功率


<details>
  <summary>Details</summary>
Motivation: 现有基于流匹配的强化学习方法假设数据中不存在未测量的混淆变量，但在像素级演示任务中，演示者和学习者的感知能力不匹配会导致隐式混淆偏差，影响策略学习效果

Method: 从因果视角研究离线强化学习中的观测混淆问题，提出新的因果离线RL目标函数，优化策略在最坏混淆偏差下的性能，实现基于深度判别器的流匹配策略学习

Result: 在25个像素级任务上的实验表明，提出的混淆鲁棒增强方法比不考虑混淆的最先进离线RL方法成功率提高120%

Conclusion: 通过因果视角处理观测混淆问题，能够显著提升基于像素演示的离线强化学习性能，为存在感知能力不匹配的实际应用场景提供有效解决方案

Abstract: Expressive policies based on flow-matching have been successfully applied in reinforcement learning (RL) more recently due to their ability to model complex action distributions from offline data. These algorithms build on standard policy gradients, which assume that there is no unmeasured confounding in the data. However, this condition does not necessarily hold for pixel-based demonstrations when a mismatch exists between the demonstrator's and the learner's sensory capabilities, leading to implicit confounding biases in offline data. We address the challenge by investigating the problem of confounded observations in offline RL from a causal perspective. We develop a novel causal offline RL objective that optimizes policies' worst-case performance that may arise due to confounding biases. Based on this new objective, we introduce a practical implementation that learns expressive flow-matching policies from confounded demonstrations, employing a deep discriminator to assess the discrepancy between the target policy and the nominal behavioral policy. Experiments across 25 pixel-based tasks demonstrate that our proposed confounding-robust augmentation procedure achieves a success rate 120\% that of confounding-unaware, state-of-the-art offline RL methods.

</details>


### [131] [Zero Sum SVD: Balancing Loss Sensitivity for Low Rank LLM Compression](https://arxiv.org/abs/2602.02848)
*Ali Abbasi,Chayne Thrash,Haoran Qin,Shansita Sharma,Sepehr Seifi,Soheil Kolouri*

Main category: cs.LG

TL;DR: ZS-SVD是一种后训练SVD压缩方法，通过激活白化和一阶校准损失估计进行全局奇异分量选择，使用零和规则自动分配异构秩，无需显式优化，可显著提升LLM压缩性能。


<details>
  <summary>Details</summary>
Motivation: 现有SVD压缩方法通常对相似大小的矩阵使用同质秩分配，忽略了不同矩阵对损失的敏感度差异，或者依赖昂贵的迭代预截断优化来确定每个矩阵的秩。需要一种更高效、更智能的秩分配方法。

Method: 提出ZS-SVD方法：1) 使用激活白化和一阶校准损失估计在全局范围内选择奇异分量；2) 采用零和规则，保持累积预测损失变化接近零，自动产生异构秩分配；3) 可选轻量级校正，应用单次投影梯度更新后重新截断。

Result: 在多种LLM架构上的广泛实验表明，该方法在不同基准测试和压缩比下均能获得一致的性能提升，优于现有SVD压缩方法。

Conclusion: ZS-SVD提供了一种高效的后训练SVD压缩方法，通过全局奇异分量选择和零和规则自动分配异构秩，无需显式优化，显著提升了LLM压缩的性能和效率。

Abstract: Advances in large language models have driven strong performance across many tasks, but their memory and compute costs still hinder deployment. SVD-based compression reduces storage and can speed up inference via low-rank factors, yet performance depends on how rank is allocated under a global compression ratio. Prior methods often use homogeneous ranks for similarly sized matrices, despite large differences in loss sensitivity, or rely on expensive iterative pre-truncation optimization to determine per matrix ranks. We propose \textbf{Zero Sum SVD} (\textbf{ZS-SVD}), a post-training method that performs \emph{global} singular component selection using activation whitening and first-order calibration loss estimates in whitened coordinates. \textbf{ZS-SVD} prunes components across the whole model with a \textbf{zero sum} rule that keeps the cumulative predicted loss change near zero, automatically yielding heterogeneous ranks without solving a rank allocation optimization. Motivated by evidence that gradients near pretrained solutions exhibit low rank structure, we also introduce an optional lightweight correction that applies a \textbf{single} projected gradient update after truncation, followed by re-truncation. Extensive experiments across multiple LLM architectures show consistent gains across diverse benchmarks and compression ratios. Code is available at https://github.com/mint-vu/Zero-Sum-SVD

</details>


### [132] [When pre-training hurts LoRA fine-tuning: a dynamical analysis via single-index models](https://arxiv.org/abs/2602.02855)
*Gibbs Nwemadji,Bruno Loureiro,Jean Barbier*

Main category: cs.LG

TL;DR: 过度预训练可能反而会减缓下游任务的微调优化速度，即使预训练任务与下游任务对齐良好


<details>
  <summary>Details</summary>
Motivation: 传统观点认为预训练总是有助于下游任务的微调，但本文通过数学分析发现这种直觉并不总是成立，过度预训练可能计算上减缓微调优化

Method: 研究低秩适应（LoRA）微调在单索引模型上的表现，使用一阶SGD训练，通过总结统计量描述微调动态，分析收敛速率对初始微调对齐度和目标任务非线性程度的依赖关系

Result: 即使预训练与下游任务对齐良好，强预训练也可能导致延长搜索阶段并阻碍收敛，预训练强度和任务难度共同以非平凡方式塑造LoRA微调的动态和局限性

Conclusion: 预训练并不总是加速微调，过度预训练可能计算上减缓下游任务的优化，这为理解预训练强度与任务难度如何共同影响LoRA微调提供了统一的理论框架

Abstract: Pre-training on a source task is usually expected to facilitate fine-tuning on similar downstream problems. In this work, we mathematically show that this naive intuition is not always true: excessive pre-training can computationally slow down fine-tuning optimization. We study this phenomenon for low-rank adaptation (LoRA) fine-tuning on single-index models trained under one-pass SGD. Leveraging a summary statistics description of the fine-tuning dynamics, we precisely characterize how the convergence rate depends on the initial fine-tuning alignment and the degree of non-linearity of the target task. The key take away is that even when the pre-training and down- stream tasks are well aligned, strong pre-training can induce a prolonged search phase and hinder convergence. Our theory thus provides a unified picture of how pre-training strength and task difficulty jointly shape the dynamics and limitations of LoRA fine-tuning in a nontrivial tractable model.

</details>


### [133] [A Geometry-Aware Efficient Algorithm for Compositional Entropic Risk Minimization](https://arxiv.org/abs/2602.02877)
*Xiyuan Wei,Linli Zhou,Bokun Wang,Chih-Jen Lin,Tianbao Yang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为SCENT的几何感知随机算法，用于解决组合熵风险最小化问题，该算法通过随机近端镜像下降更新对偶变量，在凸问题上实现了O(1/√T)的收敛率，并在多个机器学习任务中优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 组合熵风险最小化问题在许多机器学习任务中出现，但现有优化算法存在非收敛、数值不稳定和收敛速度慢等基本限制。Log-E-Exp函数作为LogSumExp函数的抽象，当对数内的显式求和涉及大量项时计算成本高昂，需要更有效的优化方法。

Method: 提出SCENT算法，将熵风险最小化问题转化为min-min优化问题的对偶形式。核心设计是使用负指数函数诱导的Bregman散度来捕获目标函数的几何结构，对偶变量采用随机近端镜像下降更新。

Result: 理论分析表明：(1) SCENT算法在凸问题上达到O(1/√T)的收敛率；(2) SPMD在对偶变量优化上优于标准SGD更新；(3) 在极端分类、部分AUC最大化、对比学习和分布鲁棒优化等任务中，SCENT始终优于现有基线方法。

Conclusion: SCENT算法通过几何感知的随机近端镜像下降方法，有效解决了组合熵风险最小化问题的优化挑战，在理论和实证上都表现出优越性能，为相关机器学习任务提供了有效的优化解决方案。

Abstract: This paper studies optimization for a family of problems termed $\textbf{compositional entropic risk minimization}$, in which each data's loss is formulated as a Log-Expectation-Exponential (Log-E-Exp) function. The Log-E-Exp formulation serves as an abstraction of the Log-Sum-Exponential (LogSumExp) function when the explicit summation inside the logarithm is taken over a gigantic number of items and is therefore expensive to evaluate. While entropic risk objectives of this form arise in many machine learning problems, existing optimization algorithms suffer from several fundamental limitations including non-convergence, numerical instability, and slow convergence rates. To address these limitations, we propose a geometry-aware stochastic algorithm, termed $\textbf{SCENT}$, for the dual formulation of entropic risk minimization cast as a min--min optimization problem. The key to our design is a $\textbf{stochastic proximal mirror descent (SPMD)}$ update for the dual variable, equipped with a Bregman divergence induced by a negative exponential function that faithfully captures the geometry of the objective. Our main contributions are threefold: (i) we establish an $O(1/\sqrt{T})$ convergence rate of the proposed SCENT algorithm for convex problems; (ii) we theoretically characterize the advantages of SPMD over standard SGD update for optimizing the dual variable; and (iii) we demonstrate the empirical effectiveness of SCENT on extreme classification, partial AUC maximization, contrastive learning and distributionally robust optimization, where it consistently outperforms existing baselines.

</details>


### [134] [Mixture of Concept Bottleneck Experts](https://arxiv.org/abs/2602.02886)
*Francesco De Santis,Gabriele Ciravegna,Giovanni De Felice,Arianna Casanova,Francesco Giannini,Michelangelo Diligenti,Mateo Espinosa Zarlenga,Pietro Barbiero,Johannes Schneider,Danilo Giordano*

Main category: cs.LG

TL;DR: M-CBEs框架通过混合多个专家模型扩展概念瓶颈模型，提供线性专家和符号回归专家两种实现，在准确性和可解释性之间提供灵活权衡。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型通常固定为单一线性或布尔表达式，限制了预测准确性和对不同用户需求的适应性，需要更灵活的设计空间。

Method: 提出混合概念瓶颈专家框架，从专家数量和功能形式两个维度扩展CBMs，实现线性M-CBE（学习有限线性表达式集合）和符号M-CBE（使用符号回归从数据中发现专家函数）。

Result: 实证评估表明，通过调整混合规模和功能形式，可以在准确性和可解释性之间进行权衡，适应不同用户和任务需求。

Conclusion: M-CBEs框架为概念瓶颈模型提供了更灵活的设计空间，通过混合专家方法在保持可解释性的同时提升预测性能，并能适应多样化的用户需求。

Abstract: Concept Bottleneck Models (CBMs) promote interpretability by grounding predictions in human-understandable concepts. However, existing CBMs typically fix their task predictor to a single linear or Boolean expression, limiting both predictive accuracy and adaptability to diverse user needs. We propose Mixture of Concept Bottleneck Experts (M-CBEs), a framework that generalizes existing CBMs along two dimensions: the number of experts and the functional form of each expert, exposing an underexplored region of the design space. We investigate this region by instantiating two novel models: Linear M-CBE, which learns a finite set of linear expressions, and Symbolic M-CBE, which leverages symbolic regression to discover expert functions from data under user-specified operator vocabularies. Empirical evaluation demonstrates that varying the mixture size and functional form provides a robust framework for navigating the accuracy-interpretability trade-off, adapting to different user and task needs.

</details>


### [135] [Self-Soupervision: Cooking Model Soups without Labels](https://arxiv.org/abs/2602.02890)
*Anthony Fuller,James R. Green,Evan Shelhamer*

Main category: cs.LG

TL;DR: 该论文提出Self-Souping方法，将模型汤技术扩展到自监督学习领域，通过混合不同自监督学习算法的参数来提升模型鲁棒性和准确性


<details>
  <summary>Details</summary>
Motivation: 传统模型汤技术仅限于监督学习，且需要优化相同的损失函数。研究者希望将模型汤扩展到自监督学习领域，以利用未标记数据提升模型在迁移学习和鲁棒性方面的表现

Method: 提出Self-Souping方法：1）在基础模型上使用不同自监督学习算法（如MAE、MoCoV3、MMCR）或不同超参数训练多个"配料"模型；2）将这些模型的参数混合成"汤"模型；3）在测试数据上使用Self-Souping，然后在未污染的训练数据上进行微调

Result: 在ImageNet-C上鲁棒性提升3.5%，在LAION-C上提升7%；首次证明不同自监督学习算法（MAE、MoCoV3、MMCR）的混合模型比任何单一算法更准确

Conclusion: Self-Souping成功将模型汤技术扩展到自监督学习领域，通过混合不同自监督学习算法的参数，显著提升了模型的鲁棒性和准确性，为模型集成提供了新思路

Abstract: Model soups are strange and strangely effective combinations of parameters. They take a model (the stock), fine-tune it into multiple models (the ingredients), and then mix their parameters back into one model (the soup) to improve predictions. While all known soups require supervised learning, and optimize the same loss on labeled data, our recipes for Self-\emph{Soup}ervision generalize soups to self-supervised learning (SSL). Our Self-Souping lets us flavor ingredients on new data sources, e.g. from unlabeled data from a task for transfer or from a shift for robustness. We show that Self-Souping on corrupted test data, then fine-tuning back on uncorrupted train data, boosts robustness by +3.5\% (ImageNet-C) and +7\% (LAION-C). Self-\emph{Soup}ervision also unlocks countless SSL algorithms to cook the diverse ingredients needed for more robust soups. We show for the first time that ingredients can differ in their SSL hyperparameters -- and more surprisingly, in their SSL algorithms. We cook soups of MAE, MoCoV3, and MMCR ingredients that are more accurate than any one single SSL ingredient.

</details>


### [136] [Controlled disagreement improves generalization in decentralized training](https://arxiv.org/abs/2602.02899)
*Zesen Wang,Mikael Johansson*

Main category: cs.LG

TL;DR: DSGD-AC通过保留非零共识误差作为结构化扰动，引导优化趋向平坦最小值，在图像分类和机器翻译任务中超越了标准DSGD和集中式SGD。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点：去中心化训练通常被认为劣于集中式训练，因为共识误差被认为会损害收敛和泛化能力。本文提出共识误差实际上可以作为有用的隐式正则化器。

Method: 提出DSGD-AC（去中心化SGD与自适应共识），通过时间相关的缩放机制有意保留非零共识误差，这些误差不是随机噪声，而是与主导Hessian子空间对齐的结构化扰动。

Result: 在图像分类和机器翻译基准测试中，DSGD-AC在测试准确性和解平坦度方面一致超越了标准DSGD和集中式SGD。

Conclusion: 共识误差是有用的隐式正则化器，为去中心化学习算法的设计开辟了新视角。

Abstract: Decentralized training is often regarded as inferior to centralized training because the consensus errors between workers are thought to undermine convergence and generalization, even with homogeneous data distributions. This work challenges this view by introducing decentralized SGD with Adaptive Consensus (DSGD-AC), which intentionally preserves non-vanishing consensus errors through a time-dependent scaling mechanism. We prove that these errors are not random noise but systematically align with the dominant Hessian subspace, acting as structured perturbations that guide optimization toward flatter minima. Across image classification and machine translation benchmarks, DSGD-AC consistently surpasses both standard DSGD and centralized SGD in test accuracy and solution flatness. Together, these results establish consensus errors as a useful implicit regularizer and open a new perspective on the design of decentralized learning algorithms.

</details>


### [137] [Manifold-Constrained Energy-Based Transition Models for Offline Reinforcement Learning](https://arxiv.org/abs/2602.02900)
*Zeyu Fang,Zuyuan Zhang,Mahdi Imani,Tian Lan*

Main category: cs.LG

TL;DR: MC-ETM提出基于流形的能量转移模型，通过流形投影-扩散负采样训练条件能量模型，学习下一个状态的潜在流形，生成近流形硬负样本，提升对分布外偏差的敏感性，并通过能量信号截断rollout和悲观惩罚稳定策略优化。


<details>
  <summary>Details</summary>
Motivation: 基于模型的离线强化学习在分布偏移下很脆弱：策略改进会将rollout驱动到数据集支持较弱的状态-动作区域，其中复合模型误差会导致严重的价值高估问题。

Method: 1. 使用流形投影-扩散负采样器训练条件能量转移模型；2. 学习下一个状态的潜在流形，通过扰动潜在代码和在潜在空间中运行Langevin动力学生成近流形硬负样本；3. 使用学习到的能量作为可靠性信号：当采样下一个状态的最小能量超过阈值时截断rollout；4. 通过基于Q值在能量引导样本上分散度的悲观惩罚稳定Bellman备份；5. 通过混合悲观MDP公式化MC-ETM。

Result: MC-ETM提高了多步动态保真度，在标准离线控制基准测试中获得了更高的归一化回报，特别是在不规则动态和稀疏数据覆盖情况下表现更优。

Conclusion: MC-ETM通过流形约束的能量转移模型解决了离线强化学习中的分布偏移问题，通过能量信号截断和悲观惩罚机制，在保持策略改进的同时有效控制了模型误差的传播，提高了离线强化学习的鲁棒性和性能。

Abstract: Model-based offline reinforcement learning is brittle under distribution shift: policy improvement drives rollouts into state--action regions weakly supported by the dataset, where compounding model error yields severe value overestimation. We propose Manifold-Constrained Energy-based Transition Models (MC-ETM), which train conditional energy-based transition models using a manifold projection--diffusion negative sampler. MC-ETM learns a latent manifold of next states and generates near-manifold hard negatives by perturbing latent codes and running Langevin dynamics in latent space with the learned conditional energy, sharpening the energy landscape around the dataset support and improving sensitivity to subtle out-of-distribution deviations. For policy optimization, the learned energy provides a single reliability signal: rollouts are truncated when the minimum energy over sampled next states exceeds a threshold, and Bellman backups are stabilized via pessimistic penalties based on Q-value-level dispersion across energy-guided samples. We formalize MC-ETM through a hybrid pessimistic MDP formulation and derive a conservative performance bound separating in-support evaluation error from truncation risk. Empirically, MC-ETM improves multi-step dynamics fidelity and yields higher normalized returns on standard offline control benchmarks, particularly under irregular dynamics and sparse data coverage.

</details>


### [138] [A Random Matrix Theory Perspective on the Consistency of Diffusion Models](https://arxiv.org/abs/2602.02908)
*Binxu Wang,Jacob Zavatone-Veth,Cengiz Pehlevan*

Main category: cs.LG

TL;DR: 扩散模型在不同数据子集上训练时，使用相同噪声种子会产生相似输出，这源于数据的高斯统计特性。研究通过随机矩阵理论量化有限数据集如何影响去噪器和采样映射，揭示了跨数据分割不一致的三个关键因素。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解释为什么在不同、非重叠数据子集上训练的扩散模型，使用相同噪声种子会产生惊人相似的输出。这揭示了扩散模型训练中的可重复性问题，需要理解有限数据集如何影响生成过程。

Method: 采用随机矩阵理论框架，在线性设置下量化有限数据集如何塑造学习到的去噪器和采样映射的期望和方差。扩展确定性等价工具到分数矩阵幂，分析整个采样轨迹。在UNet和DiT架构的非记忆化区域验证理论预测。

Result: 理论揭示了采样变异性通过自洽关系 σ² ↦ κ(σ²) 重新归一化噪声水平，解释了有限数据过度收缩低方差方向并将样本拉向数据集均值。方差公式揭示了跨分割不一致的三个关键因素：特征模的各向异性、输入的非均匀性以及数据集大小的整体缩放。

Conclusion: 该理论准确预测了线性扩散模型的行为，为扩散训练的可重复性提供了原则性基线，将数据的光谱特性与生成输出的稳定性联系起来。研究识别了样本在不同训练数据分割中偏离的位置和方式。

Abstract: Diffusion models trained on different, non-overlapping subsets of a dataset often produce strikingly similar outputs when given the same noise seed. We trace this consistency to a simple linear effect: the shared Gaussian statistics across splits already predict much of the generated images. To formalize this, we develop a random matrix theory (RMT) framework that quantifies how finite datasets shape the expectation and variance of the learned denoiser and sampling map in the linear setting. For expectations, sampling variability acts as a renormalization of the noise level through a self-consistent relation $σ^2 \mapsto κ(σ^2)$, explaining why limited data overshrink low-variance directions and pull samples toward the dataset mean. For fluctuations, our variance formulas reveal three key factors behind cross-split disagreement: \textit{anisotropy} across eigenmodes, \textit{inhomogeneity} across inputs, and overall scaling with dataset size. Extending deterministic-equivalence tools to fractional matrix powers further allows us to analyze entire sampling trajectories. The theory sharply predicts the behavior of linear diffusion models, and we validate its predictions on UNet and DiT architectures in their non-memorization regime, identifying where and how samples deviates across training data split. This provides a principled baseline for reproducibility in diffusion training, linking spectral properties of data to the stability of generative outputs.

</details>


### [139] [Notes on the Reward Representation of Posterior Updates](https://arxiv.org/abs/2602.02912)
*Pedro A. Ortega*

Main category: cs.LG

TL;DR: 论文探讨了将决策作为推断的理念何时能成为字面意义而非隐喻。研究发现，在特定条件下，KL正则化的软更新可以精确对应贝叶斯后验，此时行为变化仅由证据驱动，这导致激励信号的相对性可识别但绝对奖励存在模糊性。


<details>
  <summary>Details</summary>
Motivation: 现代控制和强化学习中常将决策视为推断，但这一理念通常是隐喻性的。本文旨在探索在何种条件下这种"决策即推断"的理念可以成为字面意义，即更新过程真正对应信息传输的通道，行为变化仅由证据驱动。

Method: 研究KL正则化软更新在单一固定概率模型中精确对应贝叶斯后验的特殊情况。分析更新变量作为信息传输通道的特性，探讨行为变化如何仅由该通道携带的证据驱动，并推导出相应的识别结果。

Result: 发现后验更新决定了相对、上下文相关的激励信号，但无法唯一确定绝对奖励，后者在上下文特定基线范围内保持模糊。要求在不同更新方向上可重复使用的延续值进一步增加了与不同条件顺序相关的奖励描述之间的连贯性约束。

Conclusion: 当KL正则化软更新精确对应贝叶斯后验时，决策作为推断的理念成为字面意义，行为变化仅由证据驱动。这提供了激励信号的相对识别性，但绝对奖励存在固有模糊性，需要额外的连贯性约束来链接不同条件顺序下的奖励描述。

Abstract: Many ideas in modern control and reinforcement learning treat decision-making as inference: start from a baseline distribution and update it when a signal arrives. We ask when this can be made literal rather than metaphorical. We study the special case where a KL-regularized soft update is exactly a Bayesian posterior inside a single fixed probabilistic model, so the update variable is a genuine channel through which information is transmitted. In this regime, behavioral change is driven only by evidence carried by that channel: the update must be explainable as an evidence reweighing of the baseline. This yields a sharp identification result: posterior updates determine the relative, context-dependent incentive signal that shifts behavior, but they do not uniquely determine absolute rewards, which remain ambiguous up to context-specific baselines. Requiring one reusable continuation value across different update directions adds a further coherence constraint linking the reward descriptions associated with different conditioning orders.

</details>


### [140] [Weighted Temporal Decay Loss for Learning Wearable PPG Data with Sparse Clinical Labels](https://arxiv.org/abs/2602.02917)
*Yunsung Chung,Keum San Chun,Migyeong Gwak,Han Feng,Yingshuo Liu,Chanho Lim,Viswam Nathan,Nassir Marrouche,Sharanya Arcot Desai*

Main category: cs.LG

TL;DR: 提出一种基于PPG信号的时间衰减加权训练策略，解决临床标签稀疏问题，通过学习生物标志物特定的样本权重衰减函数来提升健康监测算法的性能。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备和AI技术的发展推动了基于PPG的健康监测研究，但临床标签稀疏导致远离实验室采血时间的生物信号监督可靠性下降，需要解决时间间隔对标签可靠性的影响。

Method: 提出一种简单的训练策略，通过学习生物标志物特定的样本权重衰减函数，根据生物信号段与其真实标签之间的时间间隔来调整样本权重，并在损失函数中使用该权重，同时加入正则化项防止平凡解。

Result: 在450名参与者的10个生物标志物智能手表PPG数据上，该方法优于基线模型。在按受试者划分的设置中，平均AUPRC达到0.715，优于微调的自监督基线（0.674）和基于特征的随机森林（0.626）。四种衰减函数比较显示，简单的线性衰减函数平均表现最稳健。

Conclusion: 该方法不仅提高了基于PPG的生物标志物预测准确性，还通过学习到的衰减率总结了每个生物标志物PPG证据随时间失效的速度，提供了对时间敏感性的可解释视角。

Abstract: Advances in wearable computing and AI have increased interest in leveraging PPG for health monitoring over the past decade. One of the biggest challenges in developing health algorithms based on such biosignals is the sparsity of clinical labels, which makes biosignals temporally distant from lab draws less reliable for supervision. To address this problem, we introduce a simple training strategy that learns a biomarker-specific decay of sample weight over the time gap between a segment and its ground truth label and uses this weight in the loss with a regularizer to prevent trivial solutions. On smartwatch PPG from 450 participants across 10 biomarkers, the approach improves over baselines. In the subject-wise setting, the proposed approach averages 0.715 AUPRC, compared to 0.674 for a fine-tuned self-supervised baseline and 0.626 for a feature-based Random Forest. A comparison of four decay families shows that a simple linear decay function is most robust on average. Beyond accuracy, the learned decay rates summarize how quickly each biomarker's PPG evidence becomes stale, providing an interpretable view of temporal sensitivity.

</details>


### [141] [A Reproducible Framework for Bias-Resistant Machine Learning on Small-Sample Neuroimaging Data](https://arxiv.org/abs/2602.02920)
*Jagan Mohan Reddy Dwarampudi,Jennifer L Purks,Joshua Wong,Renjie Hu,Tania Banerjee*

Main category: cs.LG

TL;DR: 提出一个可重复、抗偏见的机器学习框架，整合领域知识特征工程、嵌套交叉验证和校准决策阈值优化，用于小样本神经影像数据，解决了传统交叉验证的乐观偏差问题。


<details>
  <summary>Details</summary>
Motivation: 传统交叉验证框架在模型选择和性能评估中重复使用相同数据折叠，导致结果存在乐观偏差，限制了可重复性和泛化能力，特别是在小样本神经影像数据中这一问题尤为突出。

Method: 开发了一个集成框架，包括：1）基于领域知识的特征工程；2）嵌套交叉验证（避免数据重用偏差）；3）校准决策阈值优化；4）通过重要性引导排序选择紧凑、可解释的特征子集。

Result: 在深部脑刺激认知结果的高维结构MRI数据集上，该框架实现了嵌套交叉验证平衡准确率为0.660±0.068，使用了一个紧凑且可解释的特征子集。

Conclusion: 该框架通过结合可解释性和无偏评估，为数据有限的生物医学领域提供了可靠机器学习的通用计算蓝图，具有良好泛化能力。

Abstract: We introduce a reproducible, bias-resistant machine learning framework that integrates domain-informed feature engineering, nested cross-validation, and calibrated decision-threshold optimization for small-sample neuroimaging data. Conventional cross-validation frameworks that reuse the same folds for both model selection and performance estimation yield optimistically biased results, limiting reproducibility and generalization. Demonstrated on a high-dimensional structural MRI dataset of deep brain stimulation cognitive outcomes, the framework achieved a nested-CV balanced accuracy of 0.660\,$\pm$\,0.068 using a compact, interpretable subset selected via importance-guided ranking. By combining interpretability and unbiased evaluation, this work provides a generalizable computational blueprint for reliable machine learning in data-limited biomedical domains.

</details>


### [142] [How Does the Lagrangian Guide Safe Reinforcement Learning through Diffusion Models?](https://arxiv.org/abs/2602.02924)
*Xiaoyuan Cheng,Wenxuan Yuan,Boyang Li,Yuanchao Xu,Yiming Yang,Hao Liang,Bei Peng,Robert Loftin,Zhuo Sun,Yukun Hu*

Main category: cs.LG

TL;DR: ALGD是一种用于离策略安全强化学习的新算法，通过增强拉格朗日方法稳定扩散策略采样，解决了现有方法在在线安全设置中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的强化学习方法主要关注离线环境下的奖励最大化，对在线环境中的安全性考虑有限。传统方法在非凸拉格朗日景观下存在不稳定性问题。

Method: 提出增强拉格朗日引导扩散算法（ALGD），通过引入增强拉格朗日函数局部凸化能量景观，稳定策略生成和训练过程，而不改变最优策略的分布。

Result: 理论分析和大量实验表明，ALGD在理论上有坚实基础，在实证上有效，在多样化环境中实现了强大且稳定的性能。

Conclusion: ALGD成功解决了扩散基安全强化学习中的稳定性问题，为在线安全强化学习提供了有效的解决方案。

Abstract: Diffusion policy sampling enables reinforcement learning (RL) to represent multimodal action distributions beyond suboptimal unimodal Gaussian policies. However, existing diffusion-based RL methods primarily focus on offline settings for reward maximization, with limited consideration of safety in online settings. To address this gap, we propose Augmented Lagrangian-Guided Diffusion (ALGD), a novel algorithm for off-policy safe RL. By revisiting optimization theory and energy-based model, we show that the instability of primal-dual methods arises from the non-convex Lagrangian landscape. In diffusion-based safe RL, the Lagrangian can be interpreted as an energy function guiding the denoising dynamics. Counterintuitively, direct usage destabilizes both policy generation and training. ALGD resolves this issue by introducing an augmented Lagrangian that locally convexifies the energy landscape, yielding a stabilized policy generation and training process without altering the distribution of the optimal policy. Theoretical analysis and extensive experiments demonstrate that ALGD is both theoretically grounded and empirically effective, achieving strong and stable performance across diverse environments.

</details>


### [143] [Distance Marching for Generative Modeling](https://arxiv.org/abs/2602.02928)
*Zimo Wang,Ishit Mehta,Haolin Lu,Chung-En Sun,Ge Yan,Tsui-Wei Weng,Tzu-Mao Li*

Main category: cs.LG

TL;DR: Distance Marching：一种新的无条件时间生成模型，通过距离场建模改进去噪方向，在CIFAR-10和ImageNet上比现有无条件时间基线提升13.5% FID，甚至超越有条件的时间流匹配方法。


<details>
  <summary>Details</summary>
Motivation: 传统无条件时间生成模型学习时间独立的去噪向量场，但同一噪声输入可能对应多个噪声水平和不同的去噪方向，这会干扰监督信号。需要一种更原则性的方法来改进无条件时间生成。

Method: 提出Distance Marching方法，受距离场建模启发，设计专注于更近目标的损失函数，产生更指向数据流形的去噪方向。包含两种原则性的推理方法。

Result: 在CIFAR-10和ImageNet上比近期无条件时间基线持续提升13.5% FID；对于类别条件ImageNet生成，尽管移除了时间输入，仍超越流匹配方法，使用60%采样步骤达到更低FID，平均降低13.6% FID。距离预测还有助于采样早期停止和OOD检测。

Conclusion: 距离场建模可以作为生成建模的原则性视角，Distance Marching方法在无条件时间生成中表现出色，甚至超越有条件方法，展示了距离预测在生成任务中的多方面应用价值。

Abstract: Time-unconditional generative models learn time-independent denoising vector fields. But without time conditioning, the same noisy input may correspond to multiple noise levels and different denoising directions, which interferes with the supervision signal. Inspired by distance field modeling, we propose Distance Marching, a new time-unconditional approach with two principled inference methods. Crucially, we design losses that focus on closer targets. This yields denoising directions better directed toward the data manifold. Across architectures, Distance Marching consistently improves FID by 13.5% on CIFAR-10 and ImageNet over recent time-unconditional baselines. For class-conditional ImageNet generation, despite removing time input, Distance Marching surpasses flow matching using our losses and inference methods. It achieves lower FID than flow matching's final performance using 60% of the sampling steps and 13.6% lower FID on average across backbone sizes. Moreover, our distance prediction is also helpful for early stopping during sampling and for OOD detection. We hope distance field modeling can serve as a principled lens for generative modeling.

</details>


### [144] [RPG-AE: Neuro-Symbolic Graph Autoencoders with Rare Pattern Mining for Provenance-Based Anomaly Detection](https://arxiv.org/abs/2602.02929)
*Asif Tauhid,Sidahmed Benabderrahmane,Mohamad Altrabulsi,Ahamed Foisal,Talal Rahwan*

Main category: cs.LG

TL;DR: 提出一种结合图自动编码器与稀有模式挖掘的神经符号异常检测框架，用于在系统级溯源数据中检测高级持续性威胁活动，相比基线方法显著提升异常排名质量。


<details>
  <summary>Details</summary>
Motivation: 高级持续性威胁（APTs）具有隐蔽性强、持续时间长、难以检测的特点，因为它们通常伪装成正常系统行为。现有检测方法在识别APT类活动方面存在挑战，需要结合深度学习与模式挖掘的优势来提高检测效果和可解释性。

Method: 1. 基于特征相似度使用k近邻构建进程行为图；2. 使用图自动编码器学习正常关系结构；3. 通过观测图与重构图之间的偏差识别异常候选；4. 集成稀有模式挖掘模块，发现不频繁的行为共现模式，并利用这些模式提升具有稀有特征的进程的异常分数。

Result: 在DARPA透明计算数据集上评估，稀有模式增强相比基线图自动编码器在异常排名质量上取得显著提升。与现有无监督方法相比，单一统一模型持续优于基于上下文的单个检测器，性能与需要多个独立检测器的集成聚合方法相当。

Conclusion: 将基于图的表示学习与经典模式挖掘相结合，能够提高溯源安全异常检测的有效性和可解释性，为检测APT类活动提供了有价值的神经符号方法。

Abstract: Advanced Persistent Threats (APTs) are sophisticated, long-term cyberattacks that are difficult to detect because they operate stealthily and often blend into normal system behavior. This paper presents a neuro-symbolic anomaly detection framework that combines a Graph Autoencoder (GAE) with rare pattern mining to identify APT-like activities in system-level provenance data. Our approach first constructs a process behavioral graph using k-Nearest Neighbors based on feature similarity, then learns normal relational structure using a Graph Autoencoder. Anomaly candidates are identified through deviations between observed and reconstructed graph structure. To further improve detection, we integrate an rare pattern mining module that discovers infrequent behavioral co-occurrences and uses them to boost anomaly scores for processes exhibiting rare signatures. We evaluate the proposed method on the DARPA Transparent Computing datasets and show that rare-pattern boosting yields substantial gains in anomaly ranking quality over the baseline GAE. Compared with existing unsupervised approaches on the same benchmark, our single unified model consistently outperforms individual context-based detectors and achieves performance competitive with ensemble aggregation methods that require multiple separate detectors. These results highlight the value of coupling graph-based representation learning with classical pattern mining to improve both effectiveness and interpretability in provenance-based security anomaly detection.

</details>


### [145] [3D-Learning: Diffusion-Augmented Distributionally Robust Decision-Focused Learning](https://arxiv.org/abs/2602.02943)
*Jiaqi Wen,Lei Fan,Jianyi Yang*

Main category: cs.LG

TL;DR: 提出3D-Learning框架，通过扩散模型参数化搜索最坏情况分布，提升预测-优化管道在分布外条件下的决策性能


<details>
  <summary>Details</summary>
Motivation: 预测-优化管道在实际系统中广泛应用，但机器学习预测器对分布外样本敏感，导致预测误差大和决策性能下降。现有方法在分布外泛化方面存在不足，需要新的框架来提升鲁棒性。

Method: 提出分布鲁棒的决策聚焦学习框架，使用扩散模型参数化搜索最坏情况分布，而不是传统的分布鲁棒优化方法。通过扩散模型的强大分布建模能力，在保持数据真实性的同时找到最坏情况分布。

Result: 在LLM资源供应任务上的实验结果表明，3D-Learning在分布外泛化性能上优于现有的分布鲁棒优化和数据增强方法。

Conclusion: 3D-Learning框架通过扩散模型搜索最坏情况分布，在平均情况和最坏情况之间取得良好平衡，有效提升了预测-优化管道在分布外条件下的决策性能。

Abstract: Predict-then-Optimize (PTO) pipelines are widely employed in computing and networked systems, where Machine Learning (ML) models are used to predict critical contextual information for downstream decision-making tasks such as cloud LLM serving, data center demand response, and edge workload scheduling. However, these ML predictors are often vulnerable to out-of-distribution (OOD) samples at test time, leading to significant decision performance degradation due to large prediction errors. To address the generalization challenges under OOD conditions, we present the framework of Distributionally Robust Decision-Focused Learning (DR-DFL), which trains ML models to optimize decision performance under the worst-case distribution. Instead of relying on classical Distributionally Robust Optimization (DRO) techniques, we propose Diffusion-Augmented Distributionally Robust Decision-Focused Learning (3D-Learning), which searches for the worst-case distribution within the parameterized space of a diffusion model. By leveraging the powerful distribution modeling capabilities of diffusion models, 3D-Learning identifies worst-case distributions that remain consistent with real data, achieving a favorable balance between average and worst-case scenarios. Empirical results on an LLM resource provisioning task demonstrate that 3D-Learning outperforms existing DRO and Data Augmentation methods in OOD generalization performance.

</details>


### [146] [Q-ShiftDP: A Differentially Private Parameter-Shift Rule for Quantum Machine Learning](https://arxiv.org/abs/2602.02962)
*Hoang M. Ngo,Nhat Hoang-Xuan,Quan Nguyen,Nguyen Do,Incheol Shin,My T. Thai*

Main category: cs.LG

TL;DR: 提出了首个专门为量子机器学习设计的隐私保护机制Q-ShiftDP，利用量子梯度计算的固有特性改进隐私-效用权衡


<details>
  <summary>Details</summary>
Motivation: 量子机器学习虽然具有计算优势，但训练数据隐私保护面临挑战。经典的差分隐私随机梯度下降方法无法充分利用量子梯度估计的独特性质

Method: 提出差分隐私参数偏移规则(Q-ShiftDP)，利用参数偏移规则计算的量子梯度的固有有界性和随机性，结合校准的高斯噪声和固有量子噪声

Result: Q-ShiftDP在基准数据集上始终优于经典的差分隐私方法，通过利用量子噪声进一步改善了隐私-效用权衡

Conclusion: Q-ShiftDP是首个专门为量子机器学习设计的隐私机制，通过利用量子梯度的独特特性实现了更优的隐私保护效果

Abstract: Quantum Machine Learning (QML) promises significant computational advantages, but preserving training data privacy remains challenging. Classical approaches like differentially private stochastic gradient descent (DP-SGD) add noise to gradients but fail to exploit the unique properties of quantum gradient estimation. In this work, we introduce the Differentially Private Parameter-Shift Rule (Q-ShiftDP), the first privacy mechanism tailored to QML. By leveraging the inherent boundedness and stochasticity of quantum gradients computed via the parameter-shift rule, Q-ShiftDP enables tighter sensitivity analysis and reduces noise requirements. We combine carefully calibrated Gaussian noise with intrinsic quantum noise to provide formal privacy and utility guarantees, and show that harnessing quantum noise further improves the privacy-utility trade-off. Experiments on benchmark datasets demonstrate that Q-ShiftDP consistently outperforms classical DP methods in QML.

</details>


### [147] [Why Some Models Resist Unlearning: A Linear Stability Perspective](https://arxiv.org/abs/2602.02986)
*Wei-Kai Chang,Rajiv Khanna*

Main category: cs.LG

TL;DR: 本文从理论角度分析机器学习中的"遗忘学习"问题，通过渐近线性稳定性框架研究优化动态与数据几何的相互作用，提出了数据相干性作为关键分析量，并建立了遗忘学习的稳定性阈值。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习中的遗忘学习研究大多停留在经验层面，缺乏理论理解。作者旨在填补这一空白，从理论角度理解遗忘学习何时以及为何有效，为隐私保护、法规遵从和效率提升提供理论基础。

Method: 采用渐近线性稳定性框架分析优化动态与数据几何的相互作用，提出数据相干性概念并沿三个维度分解：保留集内、遗忘集内、以及两者之间。使用两层ReLU CNN在信号加噪声模型下进行研究，并应用随机矩阵理论工具进行分析。

Result: 证明了紧致的稳定性阈值，区分了收敛与发散。发现较强的记忆化使遗忘更容易：当信噪比较低时，跨样本对齐较弱，相干性降低，使遗忘更容易；反之，高信噪比、高度对齐的模型抵抗遗忘。Hessian测试和CNN热图与预测边界高度一致。

Conclusion: 该研究首次从原理上解释了记忆化、相干性和遗忘学习之间的权衡关系，为理解梯度基础遗忘学习的稳定性边界提供了理论框架，并展示了数据批处理、混合和数据/模型对齐如何影响遗忘效果。

Abstract: Machine unlearning, the ability to erase the effect of specific training samples without retraining from scratch, is critical for privacy, regulation, and efficiency. However, most progress in unlearning has been empirical, with little theoretical understanding of when and why unlearning works. We tackle this gap by framing unlearning through the lens of asymptotic linear stability to capture the interaction between optimization dynamics and data geometry. The key quantity in our analysis is data coherence which is the cross sample alignment of loss surface directions near the optimum. We decompose coherence along three axes: within the retain set, within the forget set, and between them, and prove tight stability thresholds that separate convergence from divergence. To further link data properties to forgettability, we study a two layer ReLU CNN under a signal plus noise model and show that stronger memorization makes forgetting easier: when the signal to noise ratio (SNR) is lower, cross sample alignment is weaker, reducing coherence and making unlearning easier; conversely, high SNR, highly aligned models resist unlearning. For empirical verification, we show that Hessian tests and CNN heatmaps align closely with the predicted boundary, mapping the stability frontier of gradient based unlearning as a function of batching, mixing, and data/model alignment. Our analysis is grounded in random matrix theory tools and provides the first principled account of the trade offs between memorization, coherence, and unlearning.

</details>


### [148] [Adaptive Batch Sizes Using Non-Euclidean Gradient Noise Scales for Stochastic Sign and Spectral Descent](https://arxiv.org/abs/2602.03001)
*Hiroki Naganuma,Shagun Gupta,Youssef Briki,Ioannis Mitliagkas,Irina Rish,Parameswaran Raman,Hao-Jun Michael Shi*

Main category: cs.LG

TL;DR: 本文提出了针对signSGD和specSGD优化的非欧几里得梯度噪声尺度，通过分布式系统中的局部小批量梯度进行高效估计，实现了自适应批量大小策略，在160M参数Llama模型上减少了66%的训练步骤。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习系统通常使用大型恒定或手动调整的批量大小调度，依赖脆弱且调优成本高的启发式方法。现有的基于梯度噪声尺度的自适应策略假设SGD的欧几里得几何，与基于广义范数的流行优化器（如signSGD/Signum和specSGD/Muon）存在根本性不匹配。

Method: 推导了signSGD和specSGD的梯度噪声尺度，这些尺度自然地从它们各自对偶范数的几何中产生。提出了一种高效的方差估计程序，利用分布式数据并行系统中不同rank上的局部小批量梯度来实际估计这些非欧几里得度量。

Result: 实验表明，使用非欧几里得梯度噪声尺度的自适应批量大小策略能够匹配恒定批量基线的验证损失，同时在160M参数Llama模型上，为Signum和Muon优化器减少了高达66%的训练步骤。

Conclusion: 通过从优化器的几何结构中推导出合适的梯度噪声尺度，并利用分布式系统中的局部梯度进行高效估计，可以实现针对非欧几里得优化器的自适应批量大小策略，显著提高训练效率。

Abstract: To maximize hardware utilization, modern machine learning systems typically employ large constant or manually tuned batch size schedules, relying on heuristics that are brittle and costly to tune. Existing adaptive strategies based on gradient noise scale (GNS) offer a principled alternative. However, their assumption of SGD's Euclidean geometry creates a fundamental mismatch with popular optimizers based on generalized norms, such as signSGD / Signum ($\ell_\infty$) and stochastic spectral descent (specSGD) / Muon ($\mathcal{S}_\infty$). In this work, we derive gradient noise scales for signSGD and specSGD that naturally emerge from the geometry of their respective dual norms. To practically estimate these non-Euclidean metrics, we propose an efficient variance estimation procedure that leverages the local mini-batch gradients on different ranks in distributed data-parallel systems. Our experiments demonstrate that adaptive batch size strategies using non-Euclidean GNS enable us to match the validation loss of constant-batch baselines while reducing training steps by up to 66% for Signum and Muon on a 160 million parameter Llama model.

</details>


### [149] [Causal Graph Spatial-Temporal Autoencoder for Reliable and Interpretable Process Monitoring](https://arxiv.org/abs/2602.03004)
*Xiangrui Zhang,Chunyue Song,Wei Dai,Zheng Zhang,Kaihua Gao,Furong Gao*

Main category: cs.LG

TL;DR: 本文提出了一种因果图时空自编码器（CGSTAE），通过结合空间自注意力机制的相关图结构学习模块和图卷积长短时记忆的时空编码-解码模块，提高工业过程监控的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 提高工业过程监控的可靠性和可解释性，传统方法往往缺乏对变量间因果关系的建模，难以解释故障的根本原因。

Method: CGSTAE包含两个主要组件：1）基于空间自注意力机制（SSAM）的相关图结构学习模块，捕捉变量间的动态关系；2）基于图卷积长短时记忆（GCLSTM）的时空编码-解码模块。提出新颖的三步因果图结构学习算法，利用因果不变性原理的反向视角从变化的相关图中推导出不变的因果图。

Result: 在田纳西伊士曼过程和实际空气分离过程上进行验证，CGSTAE通过特征空间和残差空间的两个统计量实现了有效的过程监控和故障检测。

Conclusion: CGSTAE能够有效提高工业过程监控的可靠性和可解释性，通过因果图学习揭示变量间的因果关系，为故障诊断提供更深入的洞察。

Abstract: To improve the reliability and interpretability of industrial process monitoring, this article proposes a Causal Graph Spatial-Temporal Autoencoder (CGSTAE). The network architecture of CGSTAE combines two components: a correlation graph structure learning module based on spatial self-attention mechanism (SSAM) and a spatial-temporal encoder-decoder module utilizing graph convolutional long-short term memory (GCLSTM). The SSAM learns correlation graphs by capturing dynamic relationships between variables, while a novel three-step causal graph structure learning algorithm is introduced to derive a causal graph from these correlation graphs. The algorithm leverages a reverse perspective of causal invariance principle to uncover the invariant causal graph from varying correlations. The spatial-temporal encoder-decoder, built with GCLSTM units, reconstructs time-series process data within a sequence-to-sequence framework. The proposed CGSTAE enables effective process monitoring and fault detection through two statistics in the feature space and residual space. Finally, we validate the effectiveness of CGSTAE in process monitoring through the Tennessee Eastman process and a real-world air separation process.

</details>


### [150] [From Zero to Hero: Advancing Zero-Shot Foundation Models for Tabular Outlier Detection](https://arxiv.org/abs/2602.03018)
*Xueying Ding,Haomin Wen,Simon Klütterman,Leman Akoglu*

Main category: cs.LG

TL;DR: OUTFORMER是一个用于异常检测的先进基础模型，通过合成先验混合和自演化课程训练改进FoMo-0D，实现零样本快速推理，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 异常检测在实际应用中面临缺乏标记异常数据的挑战，这使得算法和超参数选择变得困难。虽然FoMo-0D作为首个异常检测基础模型取得了显著进展，但仍需进一步改进。

Method: OUTFORMER采用两种关键技术：1）合成先验混合，通过多种合成标记数据集进行预训练；2）自演化课程训练。模型仅使用新任务的训练数据作为上下文输入，通过前向传播进行零样本推理，无需标记异常数据或额外训练。

Result: OUTFORMER在AdBench基准测试以及作者新引入的两个大规模异常检测基准（包含超过1,500个数据集）上实现了最先进的性能，同时保持快速的推理速度。

Conclusion: OUTFORMER通过合成先验混合和自演化课程训练显著提升了异常检测基础模型的性能，实现了真正的即插即用部署，为零样本异常检测提供了有效的解决方案。

Abstract: Outlier detection (OD) is widely used in practice; but its effective deployment on new tasks is hindered by lack of labeled outliers, which makes algorithm and hyperparameter selection notoriously hard. Foundation models (FMs) have transformed ML, and OD is no exception: Shen et. al. (2025) introduced FoMo-0D, the first FM for OD, achieving remarkable performance against numerous baselines. This work introduces OUTFORMER, which advances FoMo-0D with (1) a mixture of synthetic priors and (2) self-evolving curriculum training. OUTFORMER is pretrained solely on synthetic labeled datasets and infers test labels of a new task by using its training data as in-context input. Inference is fast and zero-shot, requiring merely forward pass and no labeled outliers. Thanks to in-context learning, it requires zero additional work-no OD model training or bespoke model selection-enabling truly plug-and-play deployment. OUTFORMER achieves state-of-the-art performance on the prominent AdBench, as well as two new large-scale OD benchmarks that we introduce, comprising over 1,500 datasets, while maintaining speedy inference.

</details>


### [151] [FedKRSO: Communication and Memory Efficient Federated Fine-Tuning of Large Language Models](https://arxiv.org/abs/2602.03019)
*Guohao Yang,Tongle Wu,Yuanxiong Guo,Ying Sun,Yanmin Gong*

Main category: cs.LG

TL;DR: FedKRSO是一种新颖的联邦学习方法，通过随机低维子空间优化实现通信和内存高效的全参数微调，克服了参数高效微调方法的性能限制。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在LLM微调中面临通信和计算成本高的挑战，参数高效微调方法虽然能降低成本但会牺牲模型性能，需要一种既能保持全参数微调性能又能降低开销的方法。

Method: 提出FedKRSO方法：服务器生成共享的随机低维子空间，客户端在子空间内更新模型以节省内存；客户端只传输子空间上的模型更新累加器而非完整参数，实现高效的全局聚合和分发。

Result: FedKRSO在GLUE基准测试中表现出色，在多种联邦学习场景下实现了接近全参数微调的性能，同时显著降低了通信和内存开销。

Conclusion: FedKRSO为资源受限边缘环境下的联邦LLM微调提供了可行方案，通过随机子空间优化在保持性能的同时大幅降低通信和内存成本。

Abstract: Fine-tuning is essential to adapt general-purpose large language models (LLMs) to domain-specific tasks. As a privacy-preserving framework to leverage decentralized data for collaborative model training, Federated Learning (FL) is gaining popularity in LLM fine-tuning, but remains challenging due to the high cost of transmitting full model parameters and computing full gradients on resource-constrained clients. While Parameter-Efficient Fine-Tuning (PEFT) methods are widely used in FL to reduce communication and memory costs, they often sacrifice model performance compared to FFT. This paper proposes FedKRSO (Federated $K$-Seed Random Subspace Optimization), a novel method that enables communication and memory efficient FFT of LLMs in federated settings. In FedKRSO, clients update the model within a shared set of random low-dimension subspaces generated by the server to save memory usage. Furthermore, instead of transmitting full model parameters in each FL round, clients send only the model update accumulators along the subspaces to the server, enabling efficient global model aggregation and dissemination. By using these strategies, FedKRSO can substantially reduce communication and memory overhead while overcoming the performance limitations of PEFT, closely approximating the performance of federated FFT. The convergence properties of FedKRSO are analyzed rigorously under general FL settings. Extensive experiments on the GLUE benchmark across diverse FL scenarios demonstrate that FedKRSO achieves both superior performance and low communication and memory overhead, paving the way towards on federated LLM fine-tuning at the resource-constrained edge.

</details>


### [152] [CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs](https://arxiv.org/abs/2602.03048)
*Zhiyuan Yao,Yi-Kai Zhang,Yuxin Chen,Yueqing Sun,Zishan Xu,Yu Yang,Tianhao Hu,Qi Gu,Hui Su,Xunliang Cai*

Main category: cs.LG

TL;DR: CoBA-RL是一种自适应分配计算资源的强化学习算法，通过能力导向的价值函数评估样本训练价值，使用堆贪心策略优化资源分配，提升LLM后训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法使用统一的rollout预算导致资源效率低下，而现有的自适应方法依赖实例级指标（如任务通过率），无法捕捉模型的动态学习状态。

Method: 提出CoBA-RL算法：1）使用能力导向价值函数将任务映射到潜在训练收益；2）采用基于堆的贪心策略自校准计算资源分配，将更多资源分配给高训练价值的样本。

Result: 在多个具有挑战性的基准测试中，CoBA-RL有效协调了探索与利用的权衡，带来了一致的泛化性能提升。

Conclusion: 量化样本训练价值并优化预算分配对于提升LLM后训练效率至关重要，CoBA-RL为这一方向提供了有效解决方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key approach for enhancing LLM reasoning.However, standard frameworks like Group Relative Policy Optimization (GRPO) typically employ a uniform rollout budget, leading to resource inefficiency. Moreover, existing adaptive methods often rely on instance-level metrics, such as task pass rates, failing to capture the model's dynamic learning state. To address these limitations, we propose CoBA-RL, a reinforcement learning algorithm designed to adaptively allocate rollout budgets based on the model's evolving capability. Specifically, CoBA-RL utilizes a Capability-Oriented Value function to map tasks to their potential training gains and employs a heap-based greedy strategy to efficiently self-calibrate the distribution of computational resources to samples with high training value. Extensive experiments demonstrate that our approach effectively orchestrates the trade-off between exploration and exploitation, delivering consistent generalization improvements across multiple challenging benchmarks. These findings underscore that quantifying sample training value and optimizing budget allocation are pivotal for advancing LLM post-training efficiency.

</details>


### [153] [Beyond Variance: Prompt-Efficient RLVR via Rare-Event Amplification and Bidirectional Pairing](https://arxiv.org/abs/2602.03452)
*Xin Sheng,Jiaxin Li,Yujuan Pang,Ran Peng,Yong Ma*

Main category: cs.LG

TL;DR: 本文提出了一种名为"正负配对"的提示选择方法，结合加权GRPO算法，通过同时提供可靠的正锚点和明确的负学习信号，显著提升了强化学习在确定性推理任务中的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在提示选择时主要基于训练准确率方差，这导致优化方向不稳定且迁移能力较弱。作者从机制层面重新审视提示选择，认为有效的minibatch应同时提供可靠的正锚点和明确的负学习信号。

Method: 提出正负配对方法：在每个更新步骤中，采样一个困难但可解的提示q⁺（低成功率）和一个容易但脆弱的提示q⁻（高成功率但不完美）。进一步引入加权GRPO算法，在配对级别重新加权二元结果，并使用组归一化优势来放大q⁺上的罕见成功作为强烈正指导，同时将q⁻上的罕见失败转化为强负惩罚。

Result: 在Qwen2.5-Math-7B模型上，每次更新使用单个配对minibatch持续优于基于方差选择启发式的GRPO基线：AIME 2025 Pass@8从16.8提升到22.2，AMC23 Pass@64从94.0提升到97.0，同时与使用1209个训练提示的大规模RLVR训练保持竞争力。在Qwen2.5-Math-7B-Instruct模型上也观察到类似增益。

Conclusion: 正负配对方法通过提供双向学习信号（成功和失败），在不抑制探索的情况下提高了样本效率，为强化学习在确定性推理任务中的提示选择提供了更有效的机制。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is effective for training large language models on deterministic outcome reasoning tasks. Prior work shows RLVR works with few prompts, but prompt selection is often based only on training-accuracy variance, leading to unstable optimization directions and weaker transfer. We revisit prompt selection from a mechanism-level view and argue that an effective minibatch should provide both (i) a reliable positive anchor and (ii) explicit negative learning signals from rare failures. Based on this principle, we propose \emph{positive--negative pairing}: at each update, we sample a hard-but-solvable $q^{+}$ and an easy-but-brittle prompt $q^{-}$(high success rate but not perfect), characterized by low and high empirical success rates under multiple rollouts. We further introduce Weighted GRPO, which reweights binary outcomes at the pair level and uses group-normalized advantages to amplify rare successes on $q^{+}$ into sharp positive guidance while turning rare failures on $q^{-}$ into strong negative penalties. This bidirectional signal provides informative learning feedback for both successes and failures, improving sample efficiency without suppressing exploration. On Qwen2.5-Math-7B, a single paired minibatch per update consistently outperforms a GRPO baseline that selects two prompts via commonly used variance-based selection heuristics: AIME~2025 Pass@8 improves from 16.8 to 22.2, and AMC23 Pass@64 from 94.0 to 97.0, while remaining competitive with large-scale RLVR trained from a pool of 1209 training prompts. Similar gains are observed on Qwen2.5-Math-7B-Instruct.

</details>


### [154] [Reasoning with Latent Tokens in Diffusion Language Models](https://arxiv.org/abs/2602.03769)
*Andre He,Sean Welleck,Daniel Fried*

Main category: cs.LG

TL;DR: 离散扩散模型在语言建模中与自回归模型竞争，推理时计算量更大但全局一致性更好。研究发现联合预测机制是关键，通过调节潜在token数量可在推理速度与质量间权衡，该机制也可提升自回归模型在推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在语言建模中表现出色，尤其在需要规划和全局一致性的推理任务上优于自回归模型，但推理时计算成本更高。研究旨在理解这种权衡背后的机制，并探索如何平衡推理速度与样本质量。

Method: 1. 分析扩散模型的联合预测机制；2. 通过消融实验验证联合预测的重要性；3. 引入调节潜在token数量的方法；4. 将潜在token机制引入自回归模型，通过辅助多token预测目标提升性能。

Result: 1. 联合预测机制是扩散模型性能优势的关键，消融后推理速度提升但性能下降；2. 调节潜在token数量可实现推理速度与样本质量的平滑权衡；3. 将潜在token机制引入自回归模型后，在传统表现不佳的推理任务上获得显著提升。

Conclusion: 潜在token是扩散模型中自然产生的机制，代表了一种通用的改进方法，能够提升需要全局一致性或前瞻性任务的性能。该机制不仅解释了扩散模型的优势，还可应用于自回归模型，为语言建模提供新的优化方向。

Abstract: Discrete diffusion models have recently become competitive with autoregressive models for language modeling, even outperforming them on reasoning tasks requiring planning and global coherence, but they require more computation at inference time. We trace this trade-off to a key mechanism: diffusion models are trained to jointly predict a distribution over all unknown tokens, including those that will not actually be decoded in the current step. Ablating this joint prediction yields faster inference but degrades performance, revealing that accurate prediction at the decoded position relies on joint reasoning about the distribution of undecoded tokens. We interpret these as latent tokens and introduce a method for modulating their number, demonstrating empirically that this enables a smooth tradeoff between inference speed and sample quality. Furthermore, we demonstrate that latent tokens can be introduced into autoregressive models through an auxiliary multi-token prediction objective, yielding substantial improvements on the same reasoning tasks where they have traditionally struggled. Our results suggest that latent tokens, while arising naturally in diffusion, represent a general mechanism for improving performance on tasks requiring global coherence or lookahead.

</details>


### [155] [Inference-time Unlearning Using Conformal Prediction](https://arxiv.org/abs/2602.03787)
*Somnath Basu Roy Chowdhury,Rahul Kidambi,Avinava Dubey,David Wang,Gokhan Mergen,Amr Ahmed,Aranyak Mehta*

Main category: cs.LG

TL;DR: 提出了一种基于推理时遗忘的新框架，通过验证器反馈迭代优化生成质量，无需更新模型参数，显著降低遗忘误差


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法通常需要重新训练部分模型参数，但在实际应用中假设常被挑战，特别是对生成模型，且会损害模型在预训练中获得的一般能力

Method: 采用推理时遗忘范式，为生成模型配备验证器判断响应是否满足遗忘保证，利用验证器反馈迭代优化生成质量，结合共形预测降低计算开销并提供分布无关的遗忘保证

Result: 在具有挑战性的遗忘基准测试中，该方法显著优于现有最先进方法，将遗忘误差降低了高达93%

Conclusion: 推理时遗忘框架通过验证器反馈和共形预测，在不更新模型参数的情况下有效实现机器学习遗忘，为实际应用提供了可行的解决方案

Abstract: Machine unlearning is the process of efficiently removing specific information from a trained machine learning model without retraining from scratch. Existing unlearning methods, which often provide provable guarantees, typically involve retraining a subset of model parameters based on a forget set. While these approaches show promise in certain scenarios, their underlying assumptions are often challenged in real-world applications -- particularly when applied to generative models. Furthermore, updating parameters using these unlearning procedures often degrades the general-purpose capabilities the model acquired during pre-training. Motivated by these shortcomings, this paper considers the paradigm of inference time unlearning -- wherein, the generative model is equipped with an (approximately correct) verifier that judges whether the model's response satisfies appropriate unlearning guarantees. This paper introduces a framework that iteratively refines the quality of the generated responses using feedback from the verifier without updating the model parameters. The proposed framework leverages conformal prediction to reduce computational overhead and provide distribution-free unlearning guarantees. This paper's approach significantly outperforms existing state-of-the-art methods, reducing unlearning error by up to 93% across challenging unlearning benchmarks.

</details>


### [156] [Prediction of Critical Heat Flux in Rod Bundles Using Tube-Based Hybrid Machine Learning Models in CTF](https://arxiv.org/abs/2602.03805)
*Aidan Furlong,Robert Salko,Xingang Zhao,Xu Wu*

Main category: cs.LG

TL;DR: 研究探讨了机器学习CHF预测模型从管状数据到棒束几何的泛化能力，在CTF子通道代码中实现了三种ML模型，在5×5棒束测试中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于管状数据的ML CHF预测模型在棒束几何中需要验证泛化能力，因为棒束存在复杂的交叉流、定位格架损失等热工水力现象，与孤立子通道不同。

Method: 在CTF子通道代码中实现纯数据驱动的DNN和两种混合偏置校正模型，使用管状CHF数据训练，然后在Combustion Engineering 5×5棒束CHF测试系列中预测CHF位置和大小。

Result: 所有三种ML方法在CHF大小和位置预测上平均都优于W-3关联式、Bowring关联式和Groeneveld查表法等基准模型，其中混合查表模型表现出最有利的性能指标。

Conclusion: ML模型能够从管状数据泛化到棒束几何，混合查表模型在棒束CHF预测中表现最佳，为全堆芯模拟提供了有前景的解决方案。

Abstract: The prediction of critical heat flux (CHF) using machine learning (ML) approaches has become a highly active research activity in recent years, the goal of which is to build models more accurate than current conventional approaches such as empirical correlations or lookup tables (LUTs). Previous work developed and deployed tube-based pure and hybrid ML models in the CTF subchannel code, however, full-scale reactor core simulations require the use of rod bundle geometries. Unlike isolated subchannels, rod bundles experience complex thermal hydraulic phenomena such as channel crossflow, spacer grid losses, and effects from unheated conductors. This study investigates the generalization of ML-based CHF prediction models in rod bundles after being trained on tube-based CHF data. A purely data-driven DNN and two hybrid bias-correction models were implemented in the CTF subchannel code and used to predict CHF location and magnitude in the Combustion Engineering 5-by-5 bundle CHF test series. The W-3 correlation, Bowring correlation, and Groeneveld LUT were used as baseline comparators. On average, all three ML-based approaches produced magnitude and location predictions more accurate than the baseline models, with the hybrid LUT model exhibiting the most favorable performance metrics.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [157] [CodeGuard: Improving LLM Guardrails in CS Education](https://arxiv.org/abs/2602.02509)
*Nishat Raihan,Noah Erdachew,Jayoti Devi,Joanna C. S. Santos,Marcos Zampieri*

Main category: cs.CY

TL;DR: CodeGuard是一个针对CS教育中LLM使用的安全防护框架，包含分类法、数据集和实时检测模型，能有效减少30-65%的有害代码生成。


<details>
  <summary>Details</summary>
Motivation: LLM在CS教育中广泛用于代码生成和评估，但其对恶意或无关提示的敏感性威胁学生学习效果和学术诚信，现有防护措施存在不足。

Method: 提出CodeGuard框架：1) 首创的提示分类法；2) 包含8,000个提示的CodeGuard数据集；3) PromptShield轻量级句子编码器模型，用于实时检测不安全提示。

Result: PromptShield达到0.93 F1分数，优于现有防护方法；CodeGuard能将有害或违反政策的代码生成减少30-65%，同时不影响合法教育任务的性能。

Conclusion: CodeGuard为教育AI系统提供了有效的安全防护框架，解决了LLM在CS教育中的安全漏洞，相关资源已开源供社区使用。

Abstract: Large language models (LLMs) are increasingly embedded in Computer Science (CS) classrooms to automate code generation, feedback, and assessment. However, their susceptibility to adversarial or ill-intentioned prompts threatens student learning and academic integrity. To cope with this important issue, we evaluate existing off-the-shelf LLMs in handling unsafe and irrelevant prompts within the domain of CS education. We identify important shortcomings in existing LLM guardrails which motivates us to propose CodeGuard, a comprehensive guardrail framework for educational AI systems. CodeGuard includes (i) a first-of-its-kind taxonomy for classifying prompts; (ii) the CodeGuard dataset, a collection of 8,000 prompts spanning the taxonomy; and (iii) PromptShield, a lightweight sentence-encoder model fine-tuned to detect unsafe prompts in real time. Experiments show that PromptShield achieves 0.93 F1 score, surpassing existing guardrail methods. Additionally, further experimentation reveals that CodeGuard reduces potentially harmful or policy-violating code completions by 30-65% without degrading performance on legitimate educational tasks. The code, datasets, and evaluation scripts are made freely available to the community.

</details>


### [158] [Beyond Translation: Cross-Cultural Meme Transcreation with Vision-Language Models](https://arxiv.org/abs/2602.02510)
*Yuming Zhao,Peiyi Zhang,Oana Ignat*

Main category: cs.CY

TL;DR: 该研究提出了一种基于视觉语言模型的混合框架，用于跨文化表情包转创，并构建了大规模中英表情包数据集，发现当前模型在跨文化转创中存在方向不对称性。


<details>
  <summary>Details</summary>
Motivation: 表情包已成为在线交流的普遍形式，但其文化特异性给跨文化适应带来了重大挑战。研究旨在解决跨文化表情包转创问题，即在保持沟通意图和幽默感的同时，适应文化特定参考。

Method: 提出了基于视觉语言模型的混合转创框架，并引入了一个大规模双向的中美表情包数据集。使用人工判断和自动评估方法，分析了6,315个表情包对，评估不同文化方向的转创质量。

Result: 结果显示，当前视觉语言模型能在一定程度上进行跨文化表情包转创，但表现出明显的方向不对称性：美中方向的转创质量始终高于中美方向。研究进一步识别了幽默感和视觉文本设计中哪些方面能跨文化转移，哪些仍具挑战性。

Conclusion: 研究提出了评估跨文化多模态生成的框架，并公开了代码和数据集。当前模型在跨文化表情包转创方面能力有限，且存在方向不对称性，为未来研究提供了重要方向。

Abstract: Memes are a pervasive form of online communication, yet their cultural specificity poses significant challenges for cross-cultural adaptation. We study cross-cultural meme transcreation, a multimodal generation task that aims to preserve communicative intent and humor while adapting culture-specific references. We propose a hybrid transcreation framework based on vision-language models and introduce a large-scale bidirectional dataset of Chinese and US memes. Using both human judgments and automated evaluation, we analyze 6,315 meme pairs and assess transcreation quality across cultural directions. Our results show that current vision-language models can perform cross-cultural meme transcreation to a limited extent, but exhibit clear directional asymmetries: US-Chinese transcreation consistently achieves higher quality than Chinese-US. We further identify which aspects of humor and visual-textual design transfer across cultures and which remain challenging, and propose an evaluation framework for assessing cross-cultural multimodal generation. Our code and dataset are publicly available at https://github.com/AIM-SCU/MemeXGen.

</details>


### [159] [Training Data Governance for Brain Foundation Models](https://arxiv.org/abs/2602.02511)
*Margot Hanley,Jiunn-Tyng Yeh,Ryan Rodriguez,Jack Pilkington,Nita Farahany*

Main category: cs.CY

TL;DR: 本文探讨了基于大脑数据（如EEG、fMRI）训练的基础模型所带来的伦理挑战，包括隐私、同意、偏见、利益分享和治理等问题，并提出了相应的保障措施。


<details>
  <summary>Details</summary>
Motivation: 大脑基础模型将基础模型范式引入神经科学领域，但神经数据相比文本和图像数据具有更强的保护需求和历史监管背景。当前模型训练涉及大规模数据重新利用、跨情境拼接和开放式下游应用，而治理框架却分散不明确，这带来了新的伦理挑战。

Method: 首先描述大脑基础模型的技术基础和训练数据生态系统，然后结合AI伦理、神经伦理和生物伦理学的视角，系统分析隐私、同意、偏见、利益分享和治理等方面的关切。

Result: 识别出大脑基础模型带来的独特伦理挑战：神经数据的身体来源特性使其需要更强保护，而基础模型范式却使其面临大规模重新利用和跨情境应用的风险，同时治理框架不明确且参与主体更加多元化。

Conclusion: 大脑基础模型开辟了新的规范领域，需要建立相应的伦理框架和治理机制。作者为每个伦理关切领域提出了议程设定问题和基线保障措施，以指导该领域的健康发展。

Abstract: Brain foundation models bring the foundation model paradigm to the field of neuroscience. Like language and image foundation models, they are general-purpose AI systems pretrained on large-scale datasets that adapt readily to downstream tasks. Unlike text-and-image based models, however, they train on brain data: large-datasets of EEG, fMRI, and other neural data types historically collected within tightly governed clinical and research settings. This paper contends that training foundation models on neural data opens new normative territory. Neural data carry stronger expectations of, and claims to, protection than text or images, given their body-derived nature and historical governance within clinical and research settings. Yet the foundation model paradigm subjects them to practices of large-scale repurposing, cross-context stitching, and open-ended downstream application. Furthermore, these practices are now accessible to a much broader range of actors, including commercial developers, against a backdrop of fragmented and unclear governance. To map this territory, we first describe brain foundation models' technical foundations and training-data ecosystem. We then draw on AI ethics, neuroethics, and bioethics to organize concerns across privacy, consent, bias, benefit sharing, and governance. For each, we propose both agenda-setting questions and baseline safeguards as the field matures.

</details>


### [160] [Measuring Individual User Fairness with User Similarity and Effectiveness Disparity](https://arxiv.org/abs/2602.02516)
*Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Christina Lioma*

Main category: cs.CY

TL;DR: 提出PUF（Pairwise User unFairness）评估指标，同时考虑推荐效果差异和用户相似性，填补现有个体用户公平性评估指标的空白。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统中的个体用户公平性评估指标存在缺陷：要么只关注推荐效果差异而忽略用户相似性，要么只关注相似用户的推荐差异而忽略项目相关性。这两种方法都未能完整地定义公平性。

Method: 提出PUF（Pairwise User unFairness）评估指标，该指标同时考虑用户相似性和推荐效果差异。通过成对用户比较，结合相似性权重和效果差异来量化不公平性。

Result: 在4个数据集和7个排序器上的实证验证表明，PUF能够一致地同时捕捉用户相似性和效果差异。相比之下，其他指标要么对效果差异几乎不敏感，要么完全忽略用户相似性。

Conclusion: PUF是第一个能够可靠地同时考虑用户相似性和推荐效果差异的个体用户公平性评估指标，填补了现有评估方法的空白，为推荐系统公平性评估提供了更全面的工具。

Abstract: Individual user fairness is commonly understood as treating similar users similarly. In Recommender Systems (RSs), several evaluation measures exist for quantifying individual user fairness. These measures evaluate fairness via either: (i) the disparity in RS effectiveness scores regardless of user similarity, or (ii) the disparity in items recommended to similar users regardless of item relevance. Both disparity in recommendation effectiveness and user similarity are very important in fairness, yet no existing individual user fairness measure simultaneously accounts for both. In brief, current user fairness evaluation measures implement a largely incomplete definition of fairness. To fill this gap, we present Pairwise User unFairness (PUF), a novel evaluation measure of individual user fairness that considers both effectiveness disparity and user similarity. PUF is the only measure that can express this important distinction. We empirically validate that PUF does this consistently across 4 datasets and 7 rankers, and robustly when varying user similarity or effectiveness. In contrast, all other measures are either almost insensitive to effectiveness disparity or completely insensitive to user similarity. We contribute the first RS evaluation measure to reliably capture both user similarity and effectiveness in individual user fairness. Our code: https://github.com/theresiavr/PUF-individual-user-fairness-recsys.

</details>


### [161] [Evaluation of Large Language Models' educational feedback in Higher Education: potential, limitations and implications for educational practice](https://arxiv.org/abs/2602.02519)
*Daniele Agostini,Federica Picasso*

Main category: cs.CY

TL;DR: 该研究评估了大型语言模型（LLMs）在高等教育中生成反馈的潜力，发现LLMs能够生成结构良好的反馈，具有作为可持续反馈工具的潜力，但需要清晰的上下文信息和明确的指导。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术在教育领域的应用日益广泛，理解AI对反馈生成的影响对于识别其潜在益处和建立有效实施策略至关重要。反馈在高等教育中对于提升教学、学习和评估过程具有重要作用。

Method: 研究采用已建立的分析框架评估AI生成反馈对学生学习的支持。具体方法包括：1）使用七个不同的LLMs；2）基于大学教师开发的结构化评分标准；3）LLMs根据评分标准生成定量评估和定性反馈；4）使用Hughes、Smith和Creese的框架分析AI生成反馈的结构和促进形成性学习体验的有效性。

Result: 研究发现LLMs能够生成结构良好的反馈，具有作为可持续且有意义的反馈工具的潜力。AI生成反馈的有效性取决于清晰的上下文信息和明确的指导。

Conclusion: LLMs在高等教育反馈实践中具有重要潜力，可以作为有效的反馈工具。然而，要实现这一潜力，需要提供清晰的上下文信息和明确的指导，这将在结论部分进一步探讨。

Abstract: The importance of managing feedback practices in higher education has been widely recognised, as they play a crucial role in enhancing teaching, learning, and assessment processes. In today's educational landscape, feedback practices are increasingly influenced by technological advancements, particularly artificial intelligence (AI). Understanding the impact of AI on feedback generation is essential for identifying its potential benefits and establishing effective implementation strategies. This study examines how AI-generated feedback supports student learning using a well-established analytical framework. Specifically, feedback produced by different Large Language Models (LLMs) was assessed in relation to student-designed projects within a training course on inclusive teaching and learning. The evaluation process involved providing seven LLMs with a structured rubric, developed by the university instructor, which defined specific criteria and performance levels. The LLMs were tasked with generating both quantitative assessments and qualitative feedback based on this rubric. The AI-generated feedback was then analysed using Hughes, Smith, and Creese's framework to evaluate its structure and effectiveness in fostering formative learning experiences. Overall, these findings indicate that LLMs can generate well-structured feedback and hold great potential as a sustainable and meaningful feedback tool, provided they are guided by clear contextual information and a well-defined instructions that will be explored further in the conclusions.

</details>


### [162] [Artificial Intelligence for Inclusive Engineering Education: Advancing Equality, Diversity, and Ethical Leadership](https://arxiv.org/abs/2602.02520)
*Mona G. Ibrahim,Riham Hilal*

Main category: cs.CY

TL;DR: 本文探讨了AI技术如何通过适应性平台促进工程教育的公平、多样性和包容性，特别关注性别平等和减少不平等，支持联合国2030可持续发展议程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI技术在教育领域取得了显著进展，但在性别平等、全球文化代表性以及STEM教育机会获取方面仍存在差距。本文旨在通过伦理导向的AI应用来支持联合国可持续发展目标（特别是目标5性别平等和目标10减少不平等）。

Method: 采用综合策略，结合批判性思维方法，分析全球范围内使用AI适应性平台解决教育包容性差距的案例研究。提出了包含伦理领导力和数据驱动的包容性测量模型。

Result: 研究表明，AI技术不仅提高了教育包容性，还促进了STEM教育机会获取的公平性，为教育系统的全球转型提供了实证支持。

Conclusion: AI技术有潜力将教育转变为全球性系统，通过伦理框架和可持续发展思维实现真正的教育公平和包容性。

Abstract: AI technology development has transformed the field of engineering education with its adaptivity-driven, data-based, and ethical-led learning platforms that promote equity, diversity, and inclusivity. But with so much progress being made in so many areas, there are unfortunately gaps in gender equity, representation in cultures around the world, and access to education and jobs in stem education. The paper describes an ethical approach to using AI technology that supports the United Nations 2030 agenda for sustainability. In particular, this includes both Goal 5--Gender Equity--and Goal 10--Reducing Inequalities. Based on a synthesis strategy using both critical thinking strategies related to case studies around the world using AI-based adaptivity platforms to address equity gaps related to education inclusion. The model presented offers a synthesis solution that includes ethical leadership data-related to equity to measure inclusivity based upon sustainability thinking. The result has demonstrated that using AI technology not only increases inclusivity but promotes equity related to access to education in stem education access. Finally, there are concluding remarks related to transforming education into a global system.

</details>


### [163] [The First Mass Protest on Threads: Multimodal Mobilization and AI-Generated Visuals in Taiwan's Bluebird Movement](https://arxiv.org/abs/2602.02640)
*Ho-Chun Herbert Chang,Tracy Weener*

Main category: cs.CY

TL;DR: 研究分析了2024年台湾蓝鸟运动在Threads平台上的抗议传播模式，发现党派内容曝光与用户认可存在不对称性，文本和视觉策略对病毒传播有不同影响，生成式AI创造了"可爱毒性"的政治攻击新形式。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解数字环境变化下的抗议传播机制，特别是Threads平台在台湾的高渗透率如何影响2024年蓝鸟运动的传播动态，以及生成式AI如何重塑当代抗议的符号库。

Method: 研究方法包括：收集62,321条帖子和21,572张图像的数据集；使用LLM零样本标注、梯度提升树和SHAP解释器来分析注意力的供给与需求；结合文本和视觉模态分析抗议传播模式。

Result: 研究发现三个主要动态：1）算法曝光与用户认可存在党派不对称性，反民进党内容曝光更广，但反国民党和亲民进党内容更活跃传播；2）纪念活动、个人证言和行动呼吁是病毒传播的关键文本策略；3）视觉策略分化，人类照片集中曝光和讨论，而AI生成的动植物符号作为动员工具和党派攻击手段。

Conclusion: Threads平台既是民主争议的放大器也是过滤器，通过"可爱毒性"现象扩展了情感和视觉传染理论，展示了生成式AI如何通过可爱美学包装的政治攻击重塑当代抗议的符号库。

Abstract: The 2024 Bluebird Movement in Taiwan marked one of the largest youth-led protests in the country's democratic history, mobilizing over 100,000 demonstrators in response to parliamentary reforms. Unlike the 2014 Sunflower Movement, Bluebird unfolded within a transformed digital environment dominated by Threads, Meta's new microblogging platform that$\unicode{x2013}$uniquely$\unicode{x2013}$draws 24% of its global traffic from Taiwan. Leveraging a dataset of 62,321 posts and 21,572 images, this study analyzes how protest communication developed across textual and visual modalities. We combine LLM zero-shot annotation, gradient-boosting trees, and SHAP explainers to disambiguate the supply and demand of attention. Results reveal three dynamics: (1) partisan asymmetries between algorithmic exposure and user endorsement, with anti-DPP content surfaced more widely but anti-KMT and pro-DPP content more actively recirculated; (2) textual repertoires centered on commemorations, personal testimonies, and calls to action as key drivers of virality; and (3) a bifurcation in visual strategies, where human photographs concentrated exposure and discussion, while AI-generated animal and plant symbols circulated as mobilization tools and partisan attacks. These findings demonstrate how Threads functioned as both an amplifier and filter of democratic contention, extending theories of emotional and visual contagion by showing how generative AI reshapes symbolic repertoires in contemporary protest through what we term kawaii toxicity$\unicode{x2013}$political attacks cloaked in aesthetics of cuteness.

</details>


### [164] [Reshaping Perception Through Technology: From Ancient Script to Large Language Models](https://arxiv.org/abs/2602.02794)
*Parham Pourdavood,Michael Jacob*

Main category: cs.CY

TL;DR: 论文探讨大型语言模型作为媒介如何重塑认知，而非仅仅是工具，强调媒介本身对感知的塑造作用及其带来的创造力与风险并存的双重影响。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型的讨论多集中于其作为工具的功能性，而忽视了媒介本身对认知的塑造作用。论文旨在从媒介理论视角重新审视LLMs，揭示不同媒介技术如何独特地影响人类感知和认知方式。

Method: 采用媒介理论框架，特别是马歇尔·麦克卢汉的"媒介即信息"观点，追溯从DNA、神经系统到语言、文字、音乐再到LLMs的技术谱系，分析不同媒介如何塑造感知模式。

Result: 研究发现随着技术日益先进并与生理解耦，媒介既带来更大的创造潜力（高效的游戏、存储和传输），也引入人工性、不真实性和操纵风险。LLMs尤其突出地体现了这种张力，能够生成与人类创作难以区分的内容。

Conclusion: 应将AI视为重塑感知技能和实现新形式创造力的媒介，而非竞争对手。人类历史上对新技术的智力投射倾向（如古代对文字的反应）提醒我们，需要以媒介视角理解LLMs的认知影响。

Abstract: Large language models are reshaping how we create and access information, yet we typically view perception as merely reactive to stimuli, overlooking how the physical qualities of different media uniquely shape cognition. Drawing on Marshall McLuhan's insight that the medium is the massage, we trace a lineage of technologies -- from DNA and the nervous system to language, writing, music, and now LLMs -- that mold perception in distinct ways. We observe that as technologies become more advanced and decoupled from our physiology, they introduce both greater creative potential and greater risk: they enable more efficient play, storage, and transmission, while also introducing artificiality and the potential for inauthenticity and manipulation. This tension is particularly acute with LLMs, which allow rapid, playful generation of content increasingly indistinguishable from human-created work. Noting that humans have a recurring tendency to project intelligence onto novel technologies (a pattern visible in ancient responses to writing), we argue that AI should be framed not as a competitor but as a medium that reshapes perceptual skills and enables new forms of creativity.

</details>


### [165] [Reading Between the Tokens: Improving Preference Predictions through Mechanistic Forecasting](https://arxiv.org/abs/2602.02882)
*Sarah Ball,Simeon Allmendinger,Niklas Kühl,Frauke Kreuter*

Main category: cs.CY

TL;DR: 本文提出"机制预测"方法，通过探测大语言模型内部表征而非仅分析输出，来预测人类偏好（以选举预测为例），发现内部知识能提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 当前使用大语言模型预测人类偏好的方法仅依赖模型输出分析，忽略了底层机制。作者希望探索通过探测模型内部表征是否能提供更有效的人类偏好预测方法。

Method: 提出"机制预测"方法，以选举预测为测试案例，通过分析超过2400万种配置（涵盖7个模型、6个国家选举、多种人物属性和提示变体），系统研究人口统计和意识形态信息如何激活模型内部的政党编码组件。

Result: 利用内部知识的机制预测相比仅依赖表面预测能提高准确性，效果因人口统计vs意见属性、政党、国家背景和模型而异。大语言模型的潜在表征结构包含系统化、可利用的人类偏好信息。

Conclusion: 大语言模型的内部表征包含系统化的人类偏好信息，机制预测为在社会科学预测任务中使用语言模型开辟了新路径。

Abstract: Large language models are increasingly used to predict human preferences in both scientific and business endeavors, yet current approaches rely exclusively on analyzing model outputs without considering the underlying mechanisms. Using election forecasting as a test case, we introduce mechanistic forecasting, a method that demonstrates that probing internal model representations offers a fundamentally different - and sometimes more effective - approach to preference prediction. Examining over 24 million configurations across 7 models, 6 national elections, multiple persona attributes, and prompt variations, we systematically analyze how demographic and ideological information activates latent party-encoding components within the respective models. We find that leveraging this internal knowledge via mechanistic forecasting (opposed to solely relying on surface-level predictions) can improve prediction accuracy. The effects vary across demographic versus opinion-based attributes, political parties, national contexts, and models. Our findings demonstrate that the latent representational structure of LLMs contains systematic, exploitable information about human preferences, establishing a new path for using language models in social science prediction tasks.

</details>


### [166] [From Hanging Out to Figuring It Out: Socializing Online as a Pathway to Computational Thinking](https://arxiv.org/abs/2602.03017)
*Samantha Shorey,Benjamin Mako Hill,Samuel C. Woolley*

Main category: cs.CY

TL;DR: 该研究通过分析Scratch平台上14000多条评论，提出了"参与式调试"概念，并识别了促进这种学习实践的三个社会前因：持续社区、可识别问题和话题渗透性。


<details>
  <summary>Details</summary>
Motivation: 尽管社交互动是推动青少年在线参与的强大动力，但平台难以利用这种参与来促进学习。研究者希望理解在线平台如何能够将社交参与转化为学习机会。

Method: 采用多阶段分析方法：1) 归纳性发展"参与式调试"概念；2) 通过内容分析确定该实践在Scratch平台上的普遍程度；3) 通过定性分析用户随时间变化的活动，识别促进参与式调试的三个社会前因。

Result: 研究发现参与式调试是Scratch平台上常见的学习实践，并识别了三个关键社会前因：持续社区、可识别问题和话题渗透性（即对话能够跨越多个话题）。

Conclusion: 研究提出了一个理论框架，强调在促进学习的目标与驱动用户参与的兴趣导向子社区之间存在一种富有成效的张力，这种张力有助于理解新媒体环境中社交参与如何转化为学习机会。

Abstract: Although socializing is a powerful driver of youth engagement online, platforms struggle to leverage engagement to promote learning. We seek to understand this dynamic using a multi-stage analysis of over 14,000 comments on Scratch, an online platform designed to support learning about programming. First, we inductively develop the concept of "participatory debugging" -- a practice through which users learn through collaborative technical troubleshooting. Second, we use a content analysis to establish how common the practice is on Scratch. Third, we conduct a qualitative analysis of user activity over time and identify three factors that serve as social antecedents of participatory debugging: (1) sustained community, (2) identifiable problems, and (3) what we call "topic porousness" to describe conversations that are able to span multiple topics. We integrate these findings in a theoretical framework that highlights a productive tension between the desire to promote learning and the interest-driven sub-communities that drive user engagement in many new media environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [167] [Uncertainty and Fairness Awareness in LLM-Based Recommendation Systems](https://arxiv.org/abs/2602.02582)
*Chandan Kumar Sah,Xiaoli Lian,Li Zhang,Tony Xu,Syed Shazaib Shah*

Main category: cs.AI

TL;DR: 该论文研究了大型语言模型在零样本推荐中的不确定性、偏见和公平性问题，提出了包含不确定性评估和人格感知公平性的评估框架，并在电影和音乐领域进行了实证分析。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能够利用广泛的上下文知识进行零样本推荐，但其预测不确定性和嵌入偏见会威胁推荐的可靠性和公平性。需要系统评估这些因素如何影响LLM生成推荐的准确性、一致性和可信度。

Method: 1. 引入包含精心设计指标的基准和数据集，标注了8个人口统计属性（31个分类值），涵盖电影和音乐两个领域；2. 通过深度案例研究量化预测不确定性（通过熵）；3. 分析Google DeepMind的Gemini 1.5 Flash在敏感属性上的系统性不公平；4. 在提示扰动（如拼写错误和多语言输入）下测试差异的持续性；5. 将人格感知公平性整合到RecLLM评估流程中，揭示人格相关的偏见模式；6. 提出新颖的不确定性感知评估方法。

Result: 1. Gemini 1.5 Flash表现出对某些敏感属性的系统性不公平，相似性差距指标SNSR为0.1363，SNSV为0.0507；2. 这些差异在提示扰动下持续存在；3. 揭示了人格个性化与群体公平性之间的权衡；4. 建立了人格档案知情的公平性基准，提升了LLM推荐的可解释性和公平性。

Conclusion: 该研究为更安全、更可解释的RecLLM奠定了基础，提出了不确定性感知评估方法和人格感知公平性基准，推动了LLM推荐系统的可信部署，并激励未来在多模型基准和自适应校准方面的研究。

Abstract: Large language models (LLMs) enable powerful zero-shot recommendations by leveraging broad contextual knowledge, yet predictive uncertainty and embedded biases threaten reliability and fairness. This paper studies how uncertainty and fairness evaluations affect the accuracy, consistency, and trustworthiness of LLM-generated recommendations. We introduce a benchmark of curated metrics and a dataset annotated for eight demographic attributes (31 categorical values) across two domains: movies and music. Through in-depth case studies, we quantify predictive uncertainty (via entropy) and demonstrate that Google DeepMind's Gemini 1.5 Flash exhibits systematic unfairness for certain sensitive attributes; measured similarity-based gaps are SNSR at 0.1363 and SNSV at 0.0507. These disparities persist under prompt perturbations such as typographical errors and multilingual inputs. We further integrate personality-aware fairness into the RecLLM evaluation pipeline to reveal personality-linked bias patterns and expose trade-offs between personalization and group fairness. We propose a novel uncertainty-aware evaluation methodology for RecLLMs, present empirical insights from deep uncertainty case studies, and introduce a personality profile-informed fairness benchmark that advances explainability and equity in LLM recommendations. Together, these contributions establish a foundation for safer, more interpretable RecLLMs and motivate future work on multi-model benchmarks and adaptive calibration for trustworthy deployment.

</details>


### [168] [A Positive Case for Faithfulness: LLM Self-Explanations Help Predict Model Behavior](https://arxiv.org/abs/2602.02639)
*Harry Mayne,Justin Singh Kang,Dewi Gould,Kannan Ramchandran,Adam Mahdi,Noah Y. Siegel*

Main category: cs.AI

TL;DR: LLM自我解释的忠实性难以评估，现有指标有局限。研究者提出标准化模拟增益（NSG）新指标，评估18个前沿模型发现：自我解释能显著提升行为预测（11-37% NSG），优于外部模型解释，但5-15%的自我解释严重误导。自我解释虽不完美，但确实包含预测模型行为的有用信息。


<details>
  <summary>Details</summary>
Motivation: LLM自我解释常被视为AI监督的有力工具，但其对模型真实推理过程的忠实性了解甚少。现有忠实性指标存在关键局限，通常依赖对抗性提示识别不忠实性或检测推理错误，忽略了解释的预测价值。

Method: 提出标准化模拟增益（NSG）指标，基于"忠实解释应让观察者学习模型的决策标准，从而更好预测相关输入行为"的理念。评估18个前沿专有和开源模型（如Gemini 3、GPT-5.2、Claude 4.5），在健康、商业、伦理等领域的7,000个反事实数据集上进行测试。

Result: 自我解释显著提升模型行为预测能力（11-37% NSG）。自我解释比外部模型生成的解释提供更多预测信息，即使外部模型更强。这表明自我知识带来的优势是外部解释方法无法复制的。同时发现，不同模型中5-15%的自我解释严重误导。

Conclusion: 尽管存在不完美，但自我解释确实编码了有助于预测模型行为的信息，为自我解释提供了积极案例。自我知识带来的优势使自我解释在预测价值上优于外部解释方法。

Abstract: LLM self-explanations are often presented as a promising tool for AI oversight, yet their faithfulness to the model's true reasoning process is poorly understood. Existing faithfulness metrics have critical limitations, typically relying on identifying unfaithfulness via adversarial prompting or detecting reasoning errors. These methods overlook the predictive value of explanations. We introduce Normalized Simulatability Gain (NSG), a general and scalable metric based on the idea that a faithful explanation should allow an observer to learn a model's decision-making criteria, and thus better predict its behavior on related inputs. We evaluate 18 frontier proprietary and open-weight models, e.g., Gemini 3, GPT-5.2, and Claude 4.5, on 7,000 counterfactuals from popular datasets covering health, business, and ethics. We find self-explanations substantially improve prediction of model behavior (11-37% NSG). Self-explanations also provide more predictive information than explanations generated by external models, even when those models are stronger. This implies an advantage from self-knowledge that external explanation methods cannot replicate. Our approach also reveals that, across models, 5-15% of self-explanations are egregiously misleading. Despite their imperfections, we show a positive case for self-explanations: they encode information that helps predict model behavior.

</details>


### [169] [MARS: Modular Agent with Reflective Search for Automated AI Research](https://arxiv.org/abs/2602.02660)
*Jiefeng Chen,Bhavana Dalvi Mishra,Jaehyun Nam,Rui Meng,Tomas Pfister,Jinsung Yoon*

Main category: cs.AI

TL;DR: MARS框架通过预算感知规划、模块化构建和比较反思记忆三大支柱，优化自主AI研究，在MLE-Bench上达到开源框架最佳性能


<details>
  <summary>Details</summary>
Motivation: AI研究自动化与一般软件工程不同，存在计算成本高（如模型训练）和性能归因不透明的问题。当前基于LLM的智能体往往生成忽略执行成本和因果因素的单体脚本，需要更优的解决方案

Method: MARS框架包含三大支柱：1) 预算感知规划：使用成本约束的蒙特卡洛树搜索平衡性能与执行成本；2) 模块化构建：采用"设计-分解-实现"流程管理复杂研究仓库；3) 比较反思记忆：通过分析解决方案差异来提取高信号洞察，解决信用分配问题

Result: 在MLE-Bench上，MARS在可比设置下达到开源框架的最先进性能，与全球排行榜的顶级方法保持竞争力。63%的已使用经验来自跨分支转移，表明智能体能有效跨搜索路径泛化洞察

Conclusion: MARS框架通过系统化的预算管理、模块化设计和反思学习机制，有效解决了AI研究自动化中的计算成本和信用分配挑战，实现了高质量的自主研究能力

Abstract: Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution. Current LLM-based agents struggle here, often generating monolithic scripts that ignore execution costs and causal factors. We introduce MARS (Modular Agent with Reflective Search), a framework optimized for autonomous AI research. MARS relies on three pillars: (1) Budget-Aware Planning via cost-constrained Monte Carlo Tree Search (MCTS) to explicitly balance performance with execution expense; (2) Modular Construction, employing a "Design-Decompose-Implement" pipeline to manage complex research repositories; and (3) Comparative Reflective Memory, which addresses credit assignment by analyzing solution differences to distill high-signal insights. MARS achieves state-of-the-art performance among open-source frameworks on MLE-Bench under comparable settings, maintaining competitiveness with the global leaderboard's top methods. Furthermore, the system exhibits qualitative "Aha!" moments, where 63% of all utilized lessons originate from cross-branch transfer, demonstrating that the agent effectively generalizes insights across search paths.

</details>


### [170] [Dynamic Mix Precision Routing for Efficient Multi-step LLM Interaction](https://arxiv.org/abs/2602.02711)
*Yuanzhe Li,Jianing Deng,Jingtong Hu,Tianlong Chen,Song Wang,Huanrui Yang*

Main category: cs.AI

TL;DR: 本文提出了一种动态混合精度路由框架，用于在长时程决策任务中自适应选择高精度和低精度LLM，以平衡任务成功率和推理成本。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在长时程决策任务中表现优异，但使用大型LLM进行多步交互会产生高昂的推理成本。现有方法通常认为更高的任务成功率需要使用更大更强的LLM模型，但这会导致成本过高的问题。

Method: 基于观察到不同交互步骤对精度敏感度不同的现象，提出了动态混合精度路由框架。该框架在每一步决策时自适应选择高精度或低精度LLM。路由器通过两阶段管道训练：第一阶段使用KL散度监督学习识别精度敏感步骤，第二阶段使用组相对策略优化（GRPO）进一步提高任务成功率。

Result: 在ALFWorld上的实验表明，该方法在准确率-成本权衡方面相比单精度基线和启发式路由方法有显著提升。

Conclusion: 动态混合精度路由框架能够有效平衡长时程决策任务中的性能与成本，通过自适应选择不同精度的LLM，在保持高任务成功率的同时显著降低推理成本。

Abstract: Large language models (LLM) achieve strong performance in long-horizon decision-making tasks through multi-step interaction and reasoning at test time. While practitioners commonly believe a higher task success rate necessitates the use of a larger and stronger LLM model, multi-step interaction with a large LLM incurs prohibitive inference cost. To address this problem, we explore the use of low-precision quantized LLM in the long-horizon decision-making process. Based on the observation of diverse sensitivities among interaction steps, we propose a dynamic mix-precision routing framework that adaptively selects between high-precision and low-precision LLMs at each decision step. The router is trained via a two-stage pipeline, consisting of KL-divergence-based supervised learning that identifies precision-sensitive steps, followed by Group-Relative Policy Optimization (GRPO) to further improve task success rates. Experiments on ALFWorld demonstrate that our approach achieves a great improvement on accuracy-cost trade-off over single-precision baselines and heuristic routing methods.

</details>


### [171] [Scaling-Aware Adapter for Structure-Grounded LLM Reasoning](https://arxiv.org/abs/2602.02780)
*Zihao Jing,Qiuhao Zeng,Ruiyi Fang,Yan Yi Li,Yan Sun,Boyu Wang,Pingzhao Hu*

Main category: cs.AI

TL;DR: Cuttlefish是一个统一的全原子LLM，通过自适应缩放的结构补丁和几何接地适配器，在保持几何线索的同时实现异构结构推理，解决了现有方法的结构幻觉和模态融合瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生物分子结构推理中存在两个主要问题：1）通过序列化标记或固定长度连接器压缩结构输入，忽略了必要的几何基础，导致结构幻觉；2）采用不灵活的模态融合瓶颈，同时过度压缩和次优分配结构标记，阻碍了通用全原子推理的实现。

Method: Cuttlefish采用两个核心技术：1）缩放感知补丁：通过指令条件门控机制在结构图上生成可变大小的补丁，根据结构复杂性自适应缩放查询标记预算，缓解固定长度连接器瓶颈；2）几何接地适配器：通过跨注意力到模态嵌入来细化这些自适应标记，并将生成的模态标记注入LLM，暴露显式几何线索以减少结构幻觉。

Result: 在多样化的全原子基准测试中，Cuttlefish在异构结构接地推理方面实现了卓越性能。

Conclusion: Cuttlefish通过自适应缩放结构标记和显式几何接地，成功解决了现有方法在生物分子结构推理中的局限性，实现了更有效的全原子语言模型推理。

Abstract: Large language models (LLMs) are enabling reasoning over biomolecular structures, yet existing methods remain modality-specific and typically compress structural inputs through sequence-based tokenization or fixed-length query connectors. Such architectures either omit the geometric groundings requisite for mitigating structural hallucinations or impose inflexible modality fusion bottlenecks that concurrently over-compress and suboptimally allocate structural tokens, thereby impeding the realization of generalized all-atom reasoning. We introduce Cuttlefish, a unified all-atom LLM that grounds language reasoning in geometric cues while scaling modality tokens with structural complexity. First, Scaling-Aware Patching leverages an instruction-conditioned gating mechanism to generate variable-size patches over structural graphs, adaptively scaling the query token budget with structural complexity to mitigate fixed-length connector bottlenecks. Second, Geometry Grounding Adapter refines these adaptive tokens via cross-attention to modality embeddings and injects the resulting modality tokens into the LLM, exposing explicit geometric cues to reduce structural hallucination. Experiments across diverse all-atom benchmarks demonstrate that Cuttlefish achieves superior performance in heterogeneous structure-grounded reasoning. Code is available at the project repository.

</details>


### [172] [AutoSizer: Automatic Sizing of Analog and Mixed-Signal Circuits via Large Language Model (LLM) Agents](https://arxiv.org/abs/2602.02849)
*Xi Yu,Dmitrii Torbunov,Soumyajit Mandal,Yihui Ren*

Main category: cs.AI

TL;DR: AutoSizer是一个基于大语言模型的反射式元优化框架，用于模拟混合信号集成电路的晶体管尺寸优化，通过内外双循环机制结合电路理解和自适应搜索空间构建，显著提升了优化效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 模拟混合信号集成电路设计严重依赖专家知识，晶体管尺寸优化面临非线性行为、高维设计空间和严格性能约束等挑战。现有EDA方法通常将尺寸优化视为静态黑盒优化，导致效率低下且鲁棒性差。大语言模型虽具备强大推理能力，但不适合AMS尺寸优化的精确数值优化。

Method: 提出AutoSizer框架，采用反射式LLM驱动的元优化方法，统一电路理解、自适应搜索空间构建和优化编排。采用双循环优化框架：内循环负责电路尺寸优化，外循环分析优化动态和约束，根据仿真反馈迭代优化搜索空间。同时创建了AMS-SizingBench基准测试集。

Result: 实验表明AutoSizer在解决方案质量、收敛速度和成功率方面均优于传统优化方法和现有LLM智能体，能够适应不同电路难度，表现更优。

Conclusion: AutoSizer成功地将LLM的推理能力与数值优化相结合，为AMS电路尺寸优化提供了高效、自适应的解决方案，显著提升了自动化设计水平。

Abstract: The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints. Existing Electronic Design Automation (EDA) methods typically frame sizing as static black-box optimization, resulting in inefficient and less robust solutions. Although Large Language Models (LLMs) exhibit strong reasoning abilities, they are not suited for precise numerical optimization in AMS sizing. To address this gap, we propose AutoSizer, a reflective LLM-driven meta-optimization framework that unifies circuit understanding, adaptive search-space construction, and optimization orchestration in a closed loop. It employs a two-loop optimization framework, with an inner loop for circuit sizing and an outer loop that analyzes optimization dynamics and constraints to iteratively refine the search space from simulation feedback. We further introduce AMS-SizingBench, an open benchmark comprising 24 diverse AMS circuits in SKY130 CMOS technology, designed to evaluate adaptive optimization policies under realistic simulator-based constraints. AutoSizer experimentally achieves higher solution quality, faster convergence, and higher success rate across varying circuit difficulties, outperforming both traditional optimization methods and existing LLM-based agents.

</details>


### [173] [STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search](https://arxiv.org/abs/2602.02862)
*Eric Yang,Jong Ha Lee,Jonathan Amar,Elissa Ye,Yugang Jia*

Main category: cs.AI

TL;DR: STEER框架通过进化多样性搜索构建自然语言角色群体，在推理时通过单一可解释参数实现决策保守性的单调调整，解决LLM在序数决策任务中的模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在平均正确性训练下容易出现模式崩溃，在需要权衡特异性和敏感性的序数决策任务（如临床分诊）中缺乏可调节控制能力，标准对齐方法移除了基于上下文约束调整ROC操作点的能力。

Method: 提出STEER框架：通过离线约束质量-多样性搜索构建自然语言角色群体，确保行为覆盖同时强制执行最低安全、推理和稳定性阈值。推理时通过单一可解释控制参数将用户指定的风险百分位数映射到选定角色，实现决策保守性的单调调整。

Result: 在两个临床分诊基准测试中，STEER相比基于温度的采样和静态角色集成获得更广泛的行为覆盖；与代表性后训练方法相比，在明确紧急病例上保持显著更高的准确性，同时在模糊决策上提供可比较的控制能力。

Conclusion: STEER作为一种安全保护的风险控制范式，能够在保持领域能力的同时引导行为，为解决LLM在序数决策任务中的模式崩溃问题提供了有效方案。

Abstract: Large Language Models (LLMs) trained for average correctness often exhibit mode collapse, producing narrow decision behaviors on tasks where multiple responses may be reasonable. This limitation is particularly problematic in ordinal decision settings such as clinical triage, where standard alignment removes the ability to trade off specificity and sensitivity (the ROC operating point) based on contextual constraints. We propose STEER (Steerable Tuning via Evolutionary Ensemble Refinement), a training-free framework that reintroduces this tunable control. STEER constructs a population of natural-language personas through an offline, constrained quality-diversity search that promotes behavioral coverage while enforcing minimum safety, reasoning, and stability thresholds. At inference time, STEER exposes a single, interpretable control parameter that maps a user-specified risk percentile to a selected persona, yielding a monotonic adjustment of decision conservativeness. On two clinical triage benchmarks, STEER achieves broader behavioral coverage compared to temperature-based sampling and static persona ensembles. Compared to a representative post-training method, STEER maintains substantially higher accuracy on unambiguous urgent cases while providing comparable control over ambiguous decisions. These results demonstrate STEER as a safety-preserving paradigm for risk control, capable of steering behavior without compromising domain competence.

</details>


### [174] [Aligning Language Model Benchmarks with Pairwise Preferences](https://arxiv.org/abs/2602.02898)
*Marco Gutierrez,Xinyi Leng,Hannah Cyberey,Jonathan Richard Schwarz,Ahmed Alaa,Thomas Hartvigsen*

Main category: cs.AI

TL;DR: 该论文提出了BenchAlign方法，通过使用有限的模型性能信息自动更新离线基准测试，使基准测试能更好地预测模型在实际部署中的表现偏好。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型基准测试虽然计算效率高，但往往无法准确预测模型在真实世界中的实际效用。许多研究发现基准测试与真实性能之间存在差距，需要建立更好的桥梁。

Method: 提出了BenchAlign方法，这是首个解决基准对齐问题的方案。该方法利用语言模型在问题级别的性能数据，结合部署期间收集的模型排序对，学习与偏好对齐的基准问题权重，生成能根据这些偏好对新模型进行排序的新基准。

Result: 实验表明，对齐后的基准测试能够准确根据人类偏好模型对未见过的模型进行排序，即使在不同模型规模下也能保持有效性，同时保持可解释性。

Conclusion: 这项工作为基准测试与实用人类偏好的对齐提供了见解，有望加速模型开发向真实效用的方向发展，提高基准测试对实际性能的预测能力。

Abstract: Language model benchmarks are pervasive and computationally-efficient proxies for real-world performance. However, many recent works find that benchmarks often fail to predict real utility. Towards bridging this gap, we introduce benchmark alignment, where we use limited amounts of information about model performance to automatically update offline benchmarks, aiming to produce new static benchmarks that predict model pairwise preferences in given test settings. We then propose BenchAlign, the first solution to this problem, which learns preference-aligned weight- ings for benchmark questions using the question-level performance of language models alongside ranked pairs of models that could be collected during deployment, producing new benchmarks that rank previously unseen models according to these preferences. Our experiments show that our aligned benchmarks can accurately rank unseen models according to models of human preferences, even across different sizes, while remaining interpretable. Overall, our work provides insights into the limits of aligning benchmarks with practical human preferences, which stands to accelerate model development towards real utility.

</details>


### [175] [Reasoning about Reasoning: BAPO Bounds on Chain-of-Thought Token Complexity in LLMs](https://arxiv.org/abs/2602.02909)
*Kiran Tomlinson,Tobias Schnabel,Adith Swaminathan,Jennifer Neville*

Main category: cs.AI

TL;DR: 该论文研究了思维链推理所需的最小推理token数量，证明了三个典型任务需要Ω(n)个推理token，并通过实验验证了理论下界。


<details>
  <summary>Details</summary>
Motivation: 思维链推理虽然能显著提升LLM性能，但带来了巨大的延迟和计算成本。论文旨在解决一个基础理论问题：随着输入规模增长，解决问题需要多少推理token？

Method: 扩展了有界注意力前缀预言机模型，证明了三个BAPO-hard任务（二进制多数、三元组匹配、图可达性）的推理token下界，并通过显式构造提供了匹配或接近匹配的上界，最后用前沿推理模型进行实验验证。

Result: 理论证明三个任务都需要Ω(n)个推理token，实验显示前沿推理模型在这些任务上表现出近似线性的推理token缩放，当限制在较小推理预算时会失败，与理论下界一致。

Conclusion: 研究识别了通过思维链进行推理时计算的基本瓶颈，并提供了一个分析最优推理长度的原则性工具。

Abstract: Inference-time scaling via chain-of-thought (CoT) reasoning is a major driver of state-of-the-art LLM performance, but it comes with substantial latency and compute costs. We address a fundamental theoretical question: how many reasoning tokens are required to solve a problem as input size grows? By extending the bounded attention prefix oracle (BAPO) model--an abstraction of LLMs that quantifies the information flow required to solve a task--we prove lower bounds on the CoT tokens required for three canonical BAPO-hard tasks: binary majority, triplet matching, and graph reachability. We show that each requires $Ω(n)$ reasoning tokens when the input size is $n$. We complement these results with matching or near-matching upper bounds via explicit constructions. Finally, our experiments with frontier reasoning models show approximately linear reasoning token scaling on these tasks and failures when constrained to smaller reasoning budgets, consistent with our theoretical lower bounds. Together, our results identify fundamental bottlenecks in inference-time compute through CoT and offer a principled tool for analyzing optimal reasoning length.

</details>


### [176] [DeltaEvolve: Accelerating Scientific Discovery through Momentum-Driven Evolution](https://arxiv.org/abs/2602.02919)
*Jiachen Jiang,Tianyu Ding,Zhihui Zhu*

Main category: cs.AI

TL;DR: DeltaEvolve：一种基于语义增量的动量驱动进化框架，替代传统基于完整代码历史的进化方法，通过结构化语义增量捕获程序修改的核心思想，减少token消耗并提升进化效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的进化系统（如AlphaEvolve）依赖完整代码历史，存在上下文效率低和进化指导弱的问题。完整代码快照包含冗余实现细节，稀释了核心算法思想，难以提供清晰的进化灵感。

Method: 将进化智能体形式化为期望最大化框架：语言模型采样候选程序（E步），系统基于评估反馈更新控制上下文（M步）。提出DeltaEvolve框架，用结构化语义增量替代完整代码历史，捕获连续节点间修改的"如何"和"为何"影响性能。通过多级数据库和渐进披露机制组织语义增量，进一步减少输入token。

Result: 在多个科学领域的任务上进行实证评估，结果表明该框架能够以更少的token消耗发现比基于完整代码的进化智能体更好的解决方案。

Conclusion: DeltaEvolve通过结构化语义增量方法解决了传统进化系统中上下文效率低的问题，提供更清晰的进化指导，在减少计算资源消耗的同时提升了科学发现的效果。

Abstract: LLM-driven evolutionary systems have shown promise for automated science discovery, yet existing approaches such as AlphaEvolve rely on full-code histories that are context-inefficient and potentially provide weak evolutionary guidance. In this work, we first formalize the evolutionary agents as a general Expectation-Maximization framework, where the language model samples candidate programs (E-step) and the system updates the control context based on evaluation feedback (M-step). Under this view, constructing context via full-code snapshots constitutes a suboptimal M-step, as redundant implement details dilutes core algorithmic ideas, making it difficult to provide clear inspirations for evolution. To address this, we propose DeltaEvolve, a momentum-driven evolutionary framework that replaces full-code history with structured semantic delta capturing how and why modifications between successive nodes affect performance. As programs are often decomposable, semantic delta usually contains many effective components which are transferable and more informative to drive improvement. By organizing semantic delta through multi-level database and progressive disclosure mechanism, input tokens are further reduced. Empirical evaluations on tasks across diverse scientific domains show that our framework can discover better solution with less token consumption over full-code-based evolutionary agents.

</details>


### [177] [UAT-LITE: Inference-Time Uncertainty-Aware Attention for Pretrained Transformers](https://arxiv.org/abs/2602.02952)
*Elias Hossain,Shubhashis Roy Dipta,Subash Neupane,Rajib Rana,Ravid Shwartz-Ziv,Ivan Garibay,Niloofar Yousefi*

Main category: cs.AI

TL;DR: UAT-LITE：一种推理时框架，通过蒙特卡洛dropout在预训练transformer分类器中实现自注意力不确定性感知，无需修改权重或训练目标，显著降低校准误差


<details>
  <summary>Details</summary>
Motivation: 神经NLP模型经常存在校准问题，对错误预测分配高置信度，这影响了选择性预测和高风险部署。现有后处理校准方法只调整输出概率而不改变内部计算，而集成和贝叶斯方法虽然能改善不确定性但需要高昂的训练或存储成本。

Method: 提出UAT-LITE推理时框架，通过蒙特卡洛dropout在预训练transformer分类器中实现近似贝叶斯推断。从随机前向传播中估计token级认知不确定性，并用其调制自注意力机制。还引入了层间方差分解来诊断预测不确定性如何在transformer深度中累积。

Result: 在SQuAD 2.0可回答性、MNLI和SST-2任务上，UAT-LITE相比微调BERT-base基线平均减少约20%的预期校准误差，同时保持任务准确性，并改善了选择性预测和分布偏移下的鲁棒性。

Conclusion: UAT-LITE提供了一种轻量级、无需训练的方法来增强预训练transformer模型的不确定性感知能力，显著改善模型校准，为高风险NLP应用提供了实用的不确定性估计解决方案。

Abstract: Neural NLP models are often miscalibrated, assigning high confidence to incorrect predictions, which undermines selective prediction and high-stakes deployment. Post-hoc calibration methods adjust output probabilities but leave internal computation unchanged, while ensemble and Bayesian approaches improve uncertainty at substantial training or storage cost. We propose UAT-LITE, an inference-time framework that makes self-attention uncertainty-aware using approximate Bayesian inference via Monte Carlo dropout in pretrained transformer classifiers. Token-level epistemic uncertainty is estimated from stochastic forward passes and used to modulate self-attention during contextualization, without modifying pretrained weights or training objectives. We additionally introduce a layerwise variance decomposition to diagnose how predictive uncertainty accumulates across transformer depth. Across the SQuAD 2.0 answerability, MNLI, and SST-2, UAT-LITE reduces Expected Calibration Error by approximately 20% on average relative to a fine-tuned BERT-base baseline while preserving task accuracy, and improves selective prediction and robustness under distribution shift.

</details>


### [178] [Structuring Value Representations via Geometric Coherence in Markov Decision Processes](https://arxiv.org/abs/2602.02978)
*Zuyuan Zhang,Zeyu Fang,Tian Lan*

Main category: cs.AI

TL;DR: GCR-RL：基于序理论的强化学习新框架，通过部分有序集（poset）的几何一致性正则化提升学习效率和稳定性


<details>
  <summary>Details</summary>
Motivation: 现有方法利用几何特性（如对称结构、几何感知数据增强等）来稳定和加速强化学习，但缺乏从序理论角度系统性地处理价值函数估计的几何一致性

Method: 提出GCR-RL框架，将价值函数估计重新构建为学习期望的部分有序集（poset），通过超poset精化序列确保价值函数底层poset序列的几何一致性，开发了基于Q学习和actor-critic的高效算法

Result: 理论分析了算法的性质和收敛速率，在多种任务上的实证评估显示，相比强基线方法，GCR-RL在样本效率和稳定性能方面均有显著提升

Conclusion: 从序理论视角重新审视强化学习，通过几何一致性正则化框架GCR-RL有效提升了学习效率和稳定性，为强化学习中的几何结构利用提供了新的理论和方法基础

Abstract: Geometric properties can be leveraged to stabilize and speed reinforcement learning. Existing examples include encoding symmetry structure, geometry-aware data augmentation, and enforcing structural restrictions. In this paper, we take a novel view of RL through the lens of order theory and recast value function estimates into learning a desired poset (partially ordered set). We propose \emph{GCR-RL} (Geometric Coherence Regularized Reinforcement Learning) that computes a sequence of super-poset refinements -- by refining posets in previous steps and learning additional order relationships from temporal difference signals -- thus ensuring geometric coherence across the sequence of posets underpinning the learned value functions. Two novel algorithms by Q-learning and by actor--critic are developed to efficiently realize these super-poset refinements. Their theoretical properties and convergence rates are analyzed. We empirically evaluate GCR-RL in a range of tasks and demonstrate significant improvements in sample efficiency and stable performance over strong baselines.

</details>


### [179] [Are LLMs Biased Like Humans? Causal Reasoning as a Function of Prior Knowledge, Irrelevant Information, and Reasoning Budget](https://arxiv.org/abs/2602.02983)
*Hanna M. Dettki,Charley M. Wu,Bob Rehder*

Main category: cs.AI

TL;DR: 该研究比较了20多个大语言模型与人类在11个因果判断任务上的表现，发现LLMs表现出比人类更规则化的推理策略，且不反映人类特有的共因偏差，思维链提示能提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在需要因果推理的领域应用增多，需要了解其因果判断是基于规范计算、人类式捷径还是脆弱的模式匹配，以评估其安全有效部署的适用性。

Method: 使用共因结构(C₁→E←C₂)设计了11个因果判断任务，将20多个LLMs与匹配的人类基线进行对比，并测试了语义抽象和提示过载下的鲁棒性，同时评估思维链提示的效果。

Result: LLMs的因果判断可通过小型可解释模型很好压缩；大多数LLMs表现出比人类更规则化的推理策略；LLMs不反映人类特有的弱解释消除和马尔可夫违反偏差；思维链提示能提升许多LLMs的鲁棒性。

Conclusion: LLMs与人类在因果推理上的差异表明，当已知的人类偏见不可取时，LLMs可以补充人类判断，但其规则化推理在不确定性本质存在时可能失效，需要深入表征LLMs的推理策略以确保安全有效部署。

Abstract: Large language models (LLMs) are increasingly used in domains where causal reasoning matters, yet it remains unclear whether their judgments reflect normative causal computation, human-like shortcuts, or brittle pattern matching. We benchmark 20+ LLMs against a matched human baseline on 11 causal judgment tasks formalized by a collider structure ($C_1 \!\rightarrow\! E\! \leftarrow \!C_2$). We find that a small interpretable model compresses LLMs' causal judgments well and that most LLMs exhibit more rule-like reasoning strategies than humans who seem to account for unmentioned latent factors in their probability judgments. Furthermore, most LLMs do not mirror the characteristic human collider biases of weak explaining away and Markov violations. We probe LLMs' causal judgment robustness under (i) semantic abstraction and (ii) prompt overloading (injecting irrelevant text), and find that chain-of-thought (CoT) increases robustness for many LLMs. Together, this divergence suggests LLMs can complement humans when known biases are undesirable, but their rule-like reasoning may break down when uncertainty is intrinsic -- highlighting the need to characterize LLM reasoning strategies for safe, effective deployment.

</details>


### [180] [Large Language Models Can Take False First Steps at Inference-time Planning](https://arxiv.org/abs/2602.02991)
*Haijiang Yan,Jian-Qiao Zhu,Adam Sanborn*

Main category: cs.AI

TL;DR: LLMs在训练中获得了序列级规划能力，但在推理时表现出短视和不一致的规划行为，这源于自生成上下文驱动的规划偏移


<details>
  <summary>Details</summary>
Motivation: 解释LLMs在训练中获得的规划能力与推理时表现出的短视规划行为之间的差距，提出理论解释

Method: 提出贝叶斯解释框架，将规划行为基于演化的生成上下文；通过两个受控实验验证：随机生成任务展示人类提示下的受限规划和自生成上下文积累时规划强度增加，高斯采样任务展示基于自生成序列时初始偏见的减少

Result: 实验验证了自生成上下文驱动规划偏移的假设，展示了规划强度随上下文积累而增加，以及基于自生成序列时初始偏见的减少

Conclusion: 为LLMs在推理时如何进行前瞻规划提供了理论解释和实证证据，解释了训练能力与推理行为之间的差距源于自生成上下文驱动的规划偏移

Abstract: Large language models (LLMs) have been shown to acquire sequence-level planning abilities during training, yet their planning behavior exhibited at inference time often appears short-sighted and inconsistent with these capabilities. We propose a Bayesian account for this gap by grounding planning behavior in the evolving generative context: given the subtle differences between natural language and the language internalized by LLMs, accumulated self-generated context drives a planning-shift during inference and thereby creates the appearance of compromised planning behavior. We further validate the proposed model through two controlled experiments: a random-generation task demonstrating constrained planning under human prompts and increasing planning strength as self-generated context accumulates, and a Gaussian-sampling task showing reduced initial bias when conditioning on self-generated sequences. These findings provide a theoretical explanation along with empirical evidence for characterizing how LLMs plan ahead during inference.

</details>


### [181] [Methods and Open Problems in Differentiable Social Choice: Learning Mechanisms, Decisions, and Alignment](https://arxiv.org/abs/2602.03003)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 本文综述了可微分社会选择这一新兴范式，将投票规则、机制和聚合过程构建为可从数据中学习的可微分模型，连接了机器学习、经济学和民主理论。


<details>
  <summary>Details</summary>
Motivation: 社会选择已从政治理论和经济学的边缘问题转变为现代机器学习系统的核心组成部分。从拍卖、资源分配到联邦学习、参与式治理和大语言模型对齐，机器学习系统越来越多地聚合异质偏好、激励和判断来做出集体决策，但往往缺乏明确的规范审查。

Method: 采用可微分社会选择范式，将投票规则、机制和聚合过程构建为可学习的可微分模型，通过数据优化。综合了拍卖、投票、预算分配、流动民主、去中心化聚合和逆向机制学习等领域的工作。

Result: 展示了经典公理和不可能性定理如何重新表现为目标、约束和优化权衡。识别了36个开放性问题，为机器学习、经济学和民主理论的交叉领域定义了新的研究议程。

Conclusion: 可微分社会选择为理解和设计现代机器学习系统中的集体决策机制提供了新框架，将规范理论、算法设计和实证学习相结合，为解决社会选择在机器学习应用中的挑战开辟了新途径。

Abstract: Social choice is no longer a peripheral concern of political theory or economics-it has become a foundational component of modern machine learning systems. From auctions and resource allocation to federated learning, participatory governance, and the alignment of large language models, machine learning pipelines increasingly aggregate heterogeneous preferences, incentives, and judgments into collective decisions. In effect, many contemporary machine learning systems already implement social choice mechanisms, often implicitly and without explicit normative scrutiny.
  This Review surveys differentiable social choice: an emerging paradigm that formulates voting rules, mechanisms, and aggregation procedures as learnable, differentiable models optimized from data. We synthesize work across auctions, voting, budgeting, liquid democracy, decentralized aggregation, and inverse mechanism learning, showing how classical axioms and impossibility results reappear as objectives, constraints, and optimization trade-offs. We conclude by identifying 36 open problems defining a new research agenda at the intersection of machine learning, economics, and democratic theory.

</details>


### [182] [Distilling LLM Reasoning into Graph of Concept Predictors](https://arxiv.org/abs/2602.03006)
*Ziyang Yu,Liang Zhao*

Main category: cs.AI

TL;DR: GCP框架通过将LLM推理过程外部化为有向无环图，用模块化概念预测器训练紧凑学生模型，提高样本效率、训练稳定性和可解释性


<details>
  <summary>Details</summary>
Motivation: 传统主动蒸馏方法仅使用最终标签，丢弃了中间推理信号，缺乏对缺失推理的诊断能力，限制了在推理延迟、计算和API成本方面的优化效果

Method: 提出图概念预测器(GCP)框架：1)将教师模型的决策过程外部化为有向无环图；2)用模块化概念预测器构建学生模型；3)采用图感知获取策略针对关键推理节点的不确定性和分歧；4)执行目标子模块重训练，将下游损失归因于特定概念预测器

Result: 在8个NLP分类基准测试中，GCP在有限标注预算下提高了性能，同时获得了更可解释和可控的训练动态

Conclusion: GCP框架通过显式建模推理过程，实现了更高效的主动蒸馏，在保持性能的同时提高了样本效率、训练稳定性和模型可解释性

Abstract: Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher's decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.

</details>


### [183] [RC-GRPO: Reward-Conditioned Group Relative Policy Optimization for Multi-Turn Tool Calling Agents](https://arxiv.org/abs/2602.03025)
*Haitian Zhong,Jixiu Zhai,Lei Song,Jiang Bian,Qiang Liu,Tieniu Tan*

Main category: cs.AI

TL;DR: 提出RC-GRPO方法解决多轮工具调用中奖励稀疏和探索成本高的问题，通过奖励条件化轨迹策略和离散奖励令牌改善组内多样性，在BFCLv4基准上超越基线并达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 多轮工具调用对大型语言模型具有挑战性，因为奖励稀疏且探索成本高。传统的SFT+GRPO方法在组内奖励变化低时（如组内多数rollout获得全0或全1奖励）会停滞，导致组归一化优势信息不足和更新消失

Method: 提出RC-GRPO（奖励条件化组相对策略优化）：1）首先微调奖励条件化轨迹策略（RCTP），在混合质量轨迹中注入奖励目标特殊令牌（如<|high_reward|>, <|low_reward|>），使模型能按需生成不同质量轨迹；2）在RL阶段，在每个GRPO组内采样多样奖励令牌，并将rollout条件化于采样令牌，提高组内多样性以改善优势增益

Result: 在Berkeley Function Calling Leaderboard v4多轮基准测试中，该方法相比基线获得持续改进的性能，Qwen-2.5-7B-Instruct模型甚至超越了所有闭源API模型

Conclusion: RC-GRPO通过将探索视为可控的转向问题，使用离散奖励令牌有效解决了多轮工具调用中组内多样性不足的问题，显著提升了模型性能并达到最先进水平

Abstract: Multi-turn tool calling is challenging for Large Language Models (LLMs) because rewards are sparse and exploration is expensive. A common recipe, SFT followed by GRPO, can stall when within-group reward variation is low (e.g., more rollouts in a group receive the all 0 or all 1 reward), making the group-normalized advantage uninformative and yielding vanishing updates. To address this problem, we propose RC-GRPO (Reward-Conditioned Group Relative Policy Optimization), which treats exploration as a controllable steering problem via discrete reward tokens. We first fine-tune a Reward-Conditioned Trajectory Policy (RCTP) on mixed-quality trajectories with reward goal special tokens (e.g., <|high_reward|>, <|low_reward|>) injected into the prompts, enabling the model to learn how to generate distinct quality trajectories on demand. Then during RL, we sample diverse reward tokens within each GRPO group and condition rollouts on the sampled token to improve within-group diversity, improving advantage gains. On the Berkeley Function Calling Leaderboard v4 (BFCLv4) multi-turn benchmark, our method yields consistently improved performance than baselines, and the performance on Qwen-2.5-7B-Instruct even surpasses all closed-source API models.

</details>


### [184] [Visual Reasoning over Time Series via Multi-Agent System](https://arxiv.org/abs/2602.03026)
*Weilin Ruan,Yuxuan Liang*

Main category: cs.AI

TL;DR: MAS4TS是一个基于工具驱动的多智能体系统，用于通用时间序列任务，通过分析器-推理器-执行器范式整合视觉推理和潜在重建，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分析方法在整合直观视觉推理和跨任务泛化方面存在局限，特别是缺乏自适应工具使用能力。需要一种能够结合视觉理解和灵活工具调用的统一框架。

Method: 提出MAS4TS系统，采用分析器-推理器-执行器范式，包含三个专门智能体通过共享内存和门控通信协调工作。首先使用视觉语言模型对时间序列图进行视觉推理以提取时间结构，然后在潜在空间中重建预测轨迹。路由器选择任务特定的工具链执行。

Result: 在多个基准测试上的广泛实验表明，MAS4TS在广泛的时间序列任务中实现了最先进的性能，同时展现出强大的泛化能力和高效的推理效率。

Conclusion: MAS4TS通过整合多智能体协作、视觉推理和潜在重建，为时间序列分析提供了一个统一且强大的框架，能够有效处理多样化的时间序列任务并实现优异的泛化性能。

Abstract: Time series analysis underpins many real-world applications, yet existing time-series-specific methods and pretrained large-model-based approaches remain limited in integrating intuitive visual reasoning and generalizing across tasks with adaptive tool usage. To address these limitations, we propose MAS4TS, a tool-driven multi-agent system for general time series tasks, built upon an Analyzer-Reasoner-Executor paradigm that integrates agent communication, visual reasoning, and latent reconstruction within a unified framework. MAS4TS first performs visual reasoning over time series plots with structured priors using a Vision-Language Model to extract temporal structures, and subsequently reconstructs predictive trajectories in latent space. Three specialized agents coordinate via shared memory and gated communication, while a router selects task-specific tool chains for execution. Extensive experiments on multiple benchmarks demonstrate that MAS4TS achieves state-of-the-art performance across a wide range of time series tasks, while exhibiting strong generalization and efficient inference.

</details>


### [185] [KANFIS A Neuro-Symbolic Framework for Interpretable and Uncertainty-Aware Learning](https://arxiv.org/abs/2602.03034)
*Binbin Yong,Haoran Pei,Jun Shen,Haoran Li,Qingguo Zhou,Zhao Su*

Main category: cs.AI

TL;DR: 提出KANFIS（Kolmogorov-Arnold神经模糊推理系统），一种紧凑的神经符号架构，通过加性函数分解统一模糊推理，解决传统ANFIS在高维空间规则指数爆炸的问题。


<details>
  <summary>Details</summary>
Motivation: 传统ANFIS架构存在结构复杂性问题，基于乘积的推理机制在高维空间会导致规则数量指数级爆炸，需要更紧凑且可解释的神经模糊系统。

Method: 提出KANFIS架构，采用加性聚合机制而非乘积机制，使模型参数和规则复杂度随输入维度线性而非指数增长。兼容Type-1和Interval Type-2模糊逻辑系统，使用稀疏掩码机制生成紧凑结构化规则集。

Result: KANFIS在性能上与代表性神经和神经模糊基线模型具有竞争力，同时保持内在可解释性、清晰的规则语义和透明的推理过程。

Conclusion: KANFIS成功解决了传统ANFIS的结构复杂性问题，提供了一种紧凑、可扩展且可解释的神经模糊推理系统，能够有效处理高维空间中的模糊推理任务。

Abstract: Adaptive Neuro-Fuzzy Inference System (ANFIS) was designed to combine the learning capabilities of neural network with the reasoning transparency of fuzzy logic. However, conventional ANFIS architectures suffer from structural complexity, where the product-based inference mechanism causes an exponential explosion of rules in high-dimensional spaces. We herein propose the Kolmogorov-Arnold Neuro-Fuzzy Inference System (KANFIS), a compact neuro-symbolic architecture that unifies fuzzy reasoning with additive function decomposition. KANFIS employs an additive aggregation mechanism, under which both model parameters and rule complexity scale linearly with input dimensionality rather than exponentially. Furthermore, KANFIS is compatible with both Type-1 (T1) and Interval Type-2 (IT2) fuzzy logic systems, enabling explicit modeling of uncertainty and ambiguity in fuzzy representations. By using sparse masking mechanisms, KANFIS generates compact and structured rule sets, resulting in an intrinsically interpretable model with clear rule semantics and transparent inference processes. Empirical results demonstrate that KANFIS achieves competitive performance against representative neural and neuro-fuzzy baselines.

</details>


### [186] [MAS-ProVe: Understanding the Process Verification of Multi-Agent Systems](https://arxiv.org/abs/2602.03053)
*Vishal Venkataramani,Haizhou Shi,Zixuan Ke,Austin Xu,Xiaoxiao He,Yingbo Zhou,Semih Yavuz,Hao Wang,Shafiq Joty*

Main category: cs.AI

TL;DR: 本研究系统评估了基于大语言模型的多智能体系统中过程验证的有效性，发现过程级验证并不能稳定提升性能，且存在高方差问题，表明可靠评估部分多智能体轨迹仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在推理轨迹上存在高方差，过程验证（评估中间步骤）在一般推理场景中显示出潜力，但其在多智能体系统中的实际效果尚不明确，需要系统性的实证研究来填补这一空白。

Method: 提出了MAS-ProVe框架，系统研究了三种验证范式（LLM-as-a-Judge、奖励模型、过程奖励模型），在两个验证粒度（智能体级和迭代级）上进行评估，考察了五个代表性验证器和四种上下文管理策略，在六个不同的多智能体框架和多个推理基准上进行实验。

Result: 过程级验证不能一致提升性能且经常表现出高方差；LLM-as-a-Judge方法通常优于基于奖励的方法，训练过的法官优于通用LLM；发现LLM作为法官与作为单智能体之间的性能差距较小，并识别出验证中的上下文长度-性能权衡。

Conclusion: 有效且鲁棒的多智能体过程验证仍然是一个开放挑战，需要超越当前范式的进一步进展。当前方法在可靠评估部分多智能体轨迹方面存在困难。

Abstract: Multi-Agent Systems (MAS) built on Large Language Models (LLMs) often exhibit high variance in their reasoning trajectories. Process verification, which evaluates intermediate steps in trajectories, has shown promise in general reasoning settings, and has been suggested as a potential tool for guiding coordination of MAS; however, its actual effectiveness in MAS remains unclear. To fill this gap, we present MAS-ProVe, a systematic empirical study of process verification for multi-agent systems (MAS). Our study spans three verification paradigms (LLM-as-a-Judge, reward models, and process reward models), evaluated across two levels of verification granularity (agent-level and iteration-level). We further examine five representative verifiers and four context management strategies, and conduct experiments over six diverse MAS frameworks on multiple reasoning benchmarks. We find that process-level verification does not consistently improve performance and frequently exhibits high variance, highlighting the difficulty of reliably evaluating partial multi-agent trajectories. Among the methods studied, LLM-as-a-Judge generally outperforms reward-based approaches, with trained judges surpassing general-purpose LLMs. We further observe a small performance gap between LLMs acting as judges and as single agents, and identify a context-length-performance trade-off in verification. Overall, our results suggest that effective and robust process verification for MAS remains an open challenge, requiring further advances beyond current paradigms. Code is available at https://github.com/Wang-ML-Lab/MAS-ProVe.

</details>


### [187] [Risky-Bench: Probing Agentic Safety Risks under Real-World Deployment](https://arxiv.org/abs/2602.03100)
*Jingnan Zheng,Yanzhen Luo,Jingjun Xu,Bingnan Liu,Yuxin Chen,Chenhang Cui,Gelei Deng,Chaochao Lu,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.AI

TL;DR: Risky-Bench是一个系统化的智能体安全评估框架，通过领域无关的安全原则和上下文感知的安全标准，在真实世界部署条件下评估智能体的安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有智能体安全评估方法存在局限性：依赖针对特定设置的风险导向任务，安全风险空间覆盖有限；无法评估智能体在长期、交互式任务执行中的安全行为；对特定设置的专门化限制了跨不同智能体配置的适应性。

Method: 提出Risky-Bench框架，围绕领域无关的安全原则组织评估，推导上下文感知的安全标准来界定安全空间；通过在不同威胁假设下的真实任务执行，系统评估整个安全空间的风险。

Result: 在生活辅助智能体设置中应用Risky-Bench，发现在现实执行条件下，最先进的智能体存在显著的安全风险。该框架具有良好的结构化评估流程，不仅限于生活辅助场景，可适应其他部署设置。

Conclusion: Risky-Bench提供了一个可扩展的智能体安全评估方法学，能够系统评估智能体在复杂真实世界部署中的安全风险，填补了现有评估方法的空白。

Abstract: Large Language Models (LLMs) are increasingly deployed as agents that operate in real-world environments, introducing safety risks beyond linguistic harm. Existing agent safety evaluations rely on risk-oriented tasks tailored to specific agent settings, resulting in limited coverage of safety risk space and failing to assess agent safety behavior during long-horizon, interactive task execution in complex real-world deployments. Moreover, their specialization to particular agent settings limits adaptability across diverse agent configurations. To address these limitations, we propose Risky-Bench, a framework that enables systematic agent safety evaluation grounded in real-world deployment. Risky-Bench organizes evaluation around domain-agnostic safety principles to derive context-aware safety rubrics that delineate safety space, and systematically evaluates safety risks across this space through realistic task execution under varying threat assumptions. When applied to life-assist agent settings, Risky-Bench uncovers substantial safety risks in state-of-the-art agents under realistic execution conditions. Moreover, as a well-structured evaluation pipeline, Risky-Bench is not confined to life-assist scenarios and can be adapted to other deployment settings to construct environment-specific safety evaluations, providing an extensible methodology for agent safety assessment.

</details>


### [188] [Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis](https://arxiv.org/abs/2602.03128)
*Abdelghny Orogat,Ana Rostam,Essam Mansour*

Main category: cs.AI

TL;DR: MAFBench：首个统一的多智能体LLM框架评估套件，揭示架构设计对系统性能（延迟、准确率、协调成功率）的显著影响，并提出设计原则和选择指南。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM框架广泛使用，但不同框架的架构设计对系统性能（延迟、吞吐量、准确性、可扩展性）的影响缺乏系统研究。现有基准测试仅关注单一能力，缺乏标准化的框架级评估。

Method: 1) 提出多智能体LLM框架的架构分类法，从基本维度系统比较框架；2) 开发MAFBench统一评估套件，将现有基准测试集成到标准化执行流程中；3) 在多个广泛使用的框架上进行受控实证研究。

Result: 框架级设计选择单独就能导致延迟增加超过100倍，规划准确率降低高达30%，协调成功率从90%以上降至30%以下。不同框架在编排开销、内存行为、规划、专业化和协调等方面表现差异显著。

Conclusion: 多智能体LLM框架的架构设计对系统性能有重大影响。研究结果为框架选择提供了具体指导，并提出了架构设计原则和未来研究方向，强调需要标准化的框架级评估方法。

Abstract: Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coordinate tasks. However, their impact on system performance remains poorly understood. This gap is critical, as architectural choices alone can induce order-of-magnitude differences in latency and throughput, as well as substantial variation in accuracy and scalability. Addressing this challenge requires (i) jointly evaluating multiple capabilities, such as orchestration overhead, memory behavior, planning, specialization, and coordination, and (ii) conducting these evaluations under controlled, framework-level conditions to isolate architectural effects. Existing benchmarks focus on individual capabilities and lack standardized framework-level evaluation. We address these limitations by (i) introducing an architectural taxonomy for systematically comparing multi-agent LLM frameworks along fundamental dimensions, and (ii) developing MAFBench, a unified evaluation suite that integrates existing benchmarks under a standardized execution pipeline. Using MAFBench, we conduct a controlled empirical study across several widely used frameworks. Our results show that framework-level design choices alone can increase latency by over 100x, reduce planning accuracy by up to 30%, and lower coordination success from above 90% to below 30%. Finally, we translate our findings into concrete architectural design principles and framework selection guidance, and outline promising future research directions.

</details>


### [189] [General Agents Contain World Models, even under Partial Observability and Stochasticity](https://arxiv.org/abs/2602.03146)
*Santiago Cifuentes*

Main category: cs.AI

TL;DR: 该研究扩展了先前关于智能体世界模型的理论，从确定性智能体扩展到随机性智能体，从完全可观测环境扩展到部分可观测环境，证明了随机性智能体也无法避免学习其环境模型。


<details>
  <summary>Details</summary>
Motivation: 先前研究证明了在特定框架下，几乎最优的通用智能体必然包含足够的环境知识，但这些结果依赖于智能体是确定性的且环境完全可观测的假设。本研究旨在移除这些限制，探索在更一般情况下的智能体世界模型存在性。

Method: 通过理论扩展，将原有定理推广到随机性智能体和部分可观测环境。同时通过弱化"通用性"的概念，证明即使能力较弱的智能体也包含其操作环境的世界模型。

Result: 成功证明了随机性智能体在部分可观测环境中也无法避免学习其环境模型。同时通过弱化通用性概念，扩展了世界模型存在性的适用范围。

Conclusion: 随机性智能体同样必须学习其环境模型，随机化并不能避免这一要求。这一结果深化了对智能体认知能力本质的理解，为评估智能体能力提供了理论基础。

Abstract: Deciding whether an agent possesses a model of its surrounding world is a fundamental step toward understanding its capabilities and limitations. In [10], it was shown that, within a particular framework, every almost optimal and general agent necessarily contains sufficient knowledge of its environment to allow an approximate reconstruction of it by querying the agent as a black box. This result relied on the assumptions that the agent is deterministic and that the environment is fully observable.
  In this work, we remove both assumptions by extending the theorem to stochastic agents operating in partially observable environments. Fundamentally, this shows that stochastic agents cannot avoid learning their environment through the usage of randomization. We also strengthen the result by weakening the notion of generality, proving that less powerful agents already contain a model of the world in which they operate.

</details>


### [190] [Enhancing Foundation VLM Robustness to Missing Modality: Scalable Diffusion for Bi-directional Feature Restoration](https://arxiv.org/abs/2602.03151)
*Wei Dai,Haoyu Wang,Honghao Chang,Lijun He,Fan Li,Jian Sun,Haixia Bi*

Main category: cs.AI

TL;DR: 提出了一种通用的缺失模态恢复策略，通过增强扩散模型作为可插拔模块，动态模态门控和跨模态互学习机制，有效恢复缺失特征并保持VLM泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在推理时假设完整模态输入，但实际应用中某些模态可能缺失或不完整。现有方法存在两个主要问题：基于提示的方法难以恢复缺失的关键特征并损害VLM泛化能力；基于插补的方法缺乏有效指导，容易生成语义无关的噪声。如何在恢复精确语义的同时保持VLM泛化能力仍然具有挑战性。

Method: 提出一种通用的缺失模态恢复策略：1）引入增强扩散模型作为可插拔的中期训练模块来有效恢复缺失特征；2）动态模态门控机制，自适应利用条件特征指导生成语义一致的特征；3）跨模态互学习机制，桥接双编码器的语义空间实现双向对齐。

Result: 在基准数据集上的零样本评估表明，该方法优于现有基线方法。大量实验和消融研究证实，该模型在缺失模态场景下是VLM的鲁棒且可扩展的扩展，确保在不同缺失率和环境下的可靠性。

Conclusion: 提出的通用缺失模态恢复策略通过动态模态门控和跨模态互学习机制，有效解决了VLM在模态缺失情况下的性能下降问题，为VLM在现实应用中的可靠性提供了有力保障。

Abstract: Vision Language Models (VLMs) typically assume complete modality input during inference. However, their effectiveness drops sharply when certain modalities are unavailable or incomplete. Current research primarily faces two dilemmas: Prompt-based methods struggle to restore missing yet indispensable features and impair generalization of VLMs. Imputation-based approaches, lacking effective guidance, are prone to generating semantically irrelevant noise. Restoring precise semantics while sustaining VLM generalization remains challenging. Therefore, we propose a general missing modality restoration strategy in this paper. We introduce an enhanced diffusion model as a pluggable mid-stage training module to effectively restore missing features. Our strategy introduces two key innovations: (I) Dynamic Modality Gating, which adaptively leverages conditional features to steer the generation of semantically consistent features; (II) Cross-Modal Mutual Learning mechanism, which bridges the semantic spaces of dual encoders to achieve bidirectional alignment. Zero-shot evaluations across benchmark datasets demonstrate that our approach outperforms existing baseline methods. Extensive experiments and ablation studies confirm our model as a robust and scalable extension for VLMs in missing modality scenarios, ensuring reliability across diverse missing rates and environments. Our code and models will be publicly available.

</details>


### [191] [VALUEFLOW: Toward Pluralistic and Steerable Value-based Alignment in Large Language Models](https://arxiv.org/abs/2602.03160)
*Woojin Kim,Sieun Hyeon,Jusang Oh,Jaeyoung Do*

Main category: cs.AI

TL;DR: VALUEFLOW是一个统一框架，用于提取、评估和以校准强度控制LLM的价值对齐，包含分层价值嵌入空间、价值强度数据库和基于锚点的评估器。


<details>
  <summary>Details</summary>
Motivation: 当前LLM价值对齐存在三个主要问题：提取方法忽略分层结构，评估只能检测存在性而非校准强度，以及LLM在可控强度下的可操控性理解不足。需要更系统的方法来处理价值对齐的复杂性。

Method: 提出VALUEFLOW框架，包含三个核心组件：1) HIVES分层价值嵌入空间，捕捉理论和跨理论的价值结构；2) VIDB价值强度数据库，大规模价值标注文本资源，基于排名聚合获得强度估计；3) 基于锚点的评估器，通过将模型输出与VIDB面板排名来产生一致的强度分数。

Result: 在10个模型和4个价值理论上的大规模研究，发现了可操控性的不对称性和多价值控制的组合规律。建立了评估和控制价值强度的可扩展基础设施。

Conclusion: VALUEFLOW为LLM的多元价值对齐提供了系统框架，能够处理价值强度的校准控制，推进了LLM的多元价值对齐研究。

Abstract: Aligning Large Language Models (LLMs) with the diverse spectrum of human values remains a central challenge: preference-based methods often fail to capture deeper motivational principles. Value-based approaches offer a more principled path, yet three gaps persist: extraction often ignores hierarchical structure, evaluation detects presence but not calibrated intensity, and the steerability of LLMs at controlled intensities remains insufficiently understood. To address these limitations, we introduce VALUEFLOW, the first unified framework that spans extraction, evaluation, and steering with calibrated intensity control. The framework integrates three components: (i) HIVES, a hierarchical value embedding space that captures intra- and cross-theory value structure; (ii) the Value Intensity DataBase (VIDB), a large-scale resource of value-labeled texts with intensity estimates derived from ranking-based aggregation; and (iii) an anchor-based evaluator that produces consistent intensity scores for model outputs by ranking them against VIDB panels. Using VALUEFLOW, we conduct a comprehensive large-scale study across ten models and four value theories, identifying asymmetries in steerability and composition laws for multi-value control. This paper establishes a scalable infrastructure for evaluating and controlling value intensity, advancing pluralistic alignment of LLMs.

</details>


### [192] [Beyond Quantity: Trajectory Diversity Scaling for Code Agents](https://arxiv.org/abs/2602.03219)
*Guhong Chen,Chenghao Sun,Cheng Fu,Qiyao Wang,Zhihong Huang,Chaopeng Wei,Guangxu Chen,Feiteng Fang,Ahmadreza Argha,Bing Zhao,Xander Xu,Qi Han,Hamid Alinejad-Rokny,Qiang Qu,Binhua Li,Shiwen Ni,Min Yang,Hu Wei,Yongbin Li*

Main category: cs.AI

TL;DR: TDScaling是一个基于轨迹多样性扩展的代码智能体数据合成框架，通过增加轨迹多样性而非单纯增加数据量来提升模型性能，解决了传统数量扩展的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 随着代码大语言模型通过MCP协议演变为工具交互智能体，其泛化能力受到低质量合成数据和数量扩展收益递减的限制。传统的数量中心扩展存在早期瓶颈，未能充分利用轨迹数据。

Method: TDScaling框架包含四个创新：1) 业务集群机制捕捉真实服务逻辑依赖；2) 蓝图驱动的多智能体范式确保轨迹连贯性；3) 自适应进化机制使用领域熵、推理模式熵和累积动作复杂度引导合成向长尾场景发展；4) 沙盒化代码工具防止内在编码能力的灾难性遗忘。

Result: 在通用工具使用基准(BFCL, tau^2-Bench)和代码智能体任务(RebenchT, CodeCI, BIRD)上的实验表明，TDScaling实现了双赢结果：既提升了工具使用的泛化能力，又增强了固有的编码能力。

Conclusion: TDScaling通过轨迹多样性扩展而非数量扩展，在固定训练预算下实现了更好的性能-成本权衡，为代码智能体训练提供了更高效的数据合成框架。

Abstract: As code large language models (LLMs) evolve into tool-interactive agents via the Model Context Protocol (MCP), their generalization is increasingly limited by low-quality synthetic data and the diminishing returns of quantity scaling. Moreover, quantity-centric scaling exhibits an early bottleneck that underutilizes trajectory data. We propose TDScaling, a Trajectory Diversity Scaling-based data synthesis framework for code agents that scales performance through diversity rather than raw volume. Under a fixed training budget, increasing trajectory diversity yields larger gains than adding more trajectories, improving the performance-cost trade-off for agent training. TDScaling integrates four innovations: (1) a Business Cluster mechanism that captures real-service logical dependencies; (2) a blueprint-driven multi-agent paradigm that enforces trajectory coherence; (3) an adaptive evolution mechanism that steers synthesis toward long-tail scenarios using Domain Entropy, Reasoning Mode Entropy, and Cumulative Action Complexity to prevent mode collapse; and (4) a sandboxed code tool that mitigates catastrophic forgetting of intrinsic coding capabilities. Experiments on general tool-use benchmarks (BFCL, tau^2-Bench) and code agent tasks (RebenchT, CodeCI, BIRD) demonstrate a win-win outcome: TDScaling improves both tool-use generalization and inherent coding proficiency. We plan to release the full codebase and the synthesized dataset (including 30,000+ tool clusters) upon publication.

</details>


### [193] [TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking](https://arxiv.org/abs/2602.03224)
*Yu Cheng,Jiuan Zhou,Yongkang Hu,Yihang Chen,Huichi Zhou,Mingang Chen,Zhizhong Zhang,Kun Shao,Yuan Xie,Zhaoxia Yin*

Main category: cs.AI

TL;DR: 该论文研究了智能体在测试时记忆演化过程中出现的信任度下降问题（Agent Memory Misevolution），提出了Trust-Memevo基准进行评估，并设计了TAME双记忆演化框架来同时保持任务性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 智能体通过测试时记忆演化积累经验是实现AGI的关键途径，但即使在良性任务演化过程中，智能体的安全对齐仍然脆弱，存在"Agent Memory Misevolution"现象，即信任度会随着记忆演化而下降。

Method: 提出了TAME双记忆演化框架：1）构建Trust-Memevo基准评估多维度信任度；2）分离演化执行器记忆（提升任务性能）和评估器记忆（基于历史反馈优化安全和效用评估）；3）通过记忆过滤、草稿生成、可信度精炼、执行和双轨记忆更新的闭环流程。

Result: 实验表明Trust-Memevo基准揭示了在各种任务领域和评估设置中信任度的整体下降趋势，而TAME框架能够有效缓解记忆误演化问题，在保持任务性能的同时显著提升信任度。

Conclusion: 智能体记忆演化过程中的信任度下降是一个重要问题，TAME框架通过分离演化执行器和评估器记忆，实现了任务性能和信任度的协同提升，为安全可靠的AGI发展提供了解决方案。

Abstract: Test-time evolution of agent memory serves as a pivotal paradigm for achieving AGI by bolstering complex reasoning through experience accumulation. However, even during benign task evolution, agent safety alignment remains vulnerable-a phenomenon known as Agent Memory Misevolution. To evaluate this phenomenon, we construct the Trust-Memevo benchmark to assess multi-dimensional trustworthiness during benign task evolution, revealing an overall decline in trustworthiness across various task domains and evaluation settings. To address this issue, we propose TAME, a dual-memory evolutionary framework that separately evolves executor memory to improve task performance by distilling generalizable methodologies, and evaluator memory to refine assessments of both safety and task utility based on historical feedback. Through a closed loop of memory filtering, draft generation, trustworthy refinement, execution, and dual-track memory updating, TAME preserves trustworthiness without sacrificing utility. Experiments demonstrate that TAME mitigates misevolution, achieving a joint improvement in both trustworthiness and task performance.

</details>


### [194] [The Necessity of a Unified Framework for LLM-Based Agent Evaluation](https://arxiv.org/abs/2602.03238)
*Pengyu Zhu,Li Sun,Philip S. Yu,Sen Su*

Main category: cs.AI

TL;DR: 本文提出需要统一的智能体评估框架来解决当前评估中存在的系统提示、工具配置、环境动态等混杂因素问题，以促进该领域的严谨发展。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，通用智能体取得了根本性进展，但评估这些智能体面临独特挑战。当前智能体基准测试受到系统提示、工具集配置、环境动态等外部因素的严重干扰，现有评估依赖于碎片化的研究者特定框架，使得难以将性能提升归因于模型本身。缺乏标准化环境数据导致不可追踪的错误和不可复现的结果，这种标准化缺失给领域带来了严重的不公平和不透明。

Method: 本文提出建立一个统一的智能体评估框架，旨在标准化智能体评估过程。虽然摘要中没有详细说明具体技术方法，但核心是创建一个标准化的评估体系来解决当前评估中的混杂因素问题。

Result: 摘要中未报告具体实验结果，但提出了标准化智能体评估框架的提案，旨在解决当前评估中的不公平、不透明和不可复现性问题。

Conclusion: 统一的评估框架对于智能体评估的严谨发展至关重要。作者提出的标准化提案旨在解决当前评估中的混杂因素问题，促进该领域的公平、透明和可复现性发展。

Abstract: With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts, toolset configurations, and environmental dynamics. Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.

</details>


### [195] [Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning](https://arxiv.org/abs/2602.03249)
*Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Wenlei Shi,Yiwei Wang,Xiaodan Liang,Jing Tang*

Main category: cs.AI

TL;DR: Accordion-Thinking框架让LLM学习通过动态总结来自我调节推理步骤粒度，实现推理上下文压缩，在保持准确性的同时大幅提升推理效率


<details>
  <summary>Details</summary>
Motivation: 传统的长链式思维推理虽然能显著提升推理能力，但由于KV缓存的线性增长和注意力机制的二次复杂度，在实际应用中面临计算和内存限制

Method: 提出Accordion-Thinking端到端框架，让LLM学习通过动态总结来自我调节推理步骤粒度，包括Fold推理模式（定期总结思维过程并丢弃历史标记），并应用强化学习进一步激励这种能力

Result: 训练过程中，高效的Fold模式与详尽的Unfold模式之间的准确率差距逐渐缩小并最终消失；在48GB GPU内存配置下实现3倍吞吐量提升，同时保持准确性；结构化步骤总结提供了人类可读的推理过程记录

Conclusion: 通过学习的自我压缩，LLM可以在不依赖大量历史标记的情况下处理复杂推理任务，同时不损害解决方案质量，实现了推理效率与准确性的平衡

Abstract: Scaling test-time compute via long Chain-ofThought unlocks remarkable gains in reasoning capabilities, yet it faces practical limits due to the linear growth of KV cache and quadratic attention complexity. In this paper, we introduce Accordion-Thinking, an end-to-end framework where LLMs learn to self-regulate the granularity of the reasoning steps through dynamic summarization. This mechanism enables a Fold inference mode, where the model periodically summarizes its thought process and discards former thoughts to reduce dependency on historical tokens. We apply reinforcement learning to incentivize this capability further, uncovering a critical insight: the accuracy gap between the highly efficient Fold mode and the exhaustive Unfold mode progressively narrows and eventually vanishes over the course of training. This phenomenon demonstrates that the model learns to encode essential reasoning information into compact summaries, achieving effective compression of the reasoning context. Our Accordion-Thinker demonstrates that with learned self-compression, LLMs can tackle complex reasoning tasks with minimal dependency token overhead without compromising solution quality, and it achieves a 3x throughput while maintaining accuracy on a 48GB GPU memory configuration, while the structured step summaries provide a human-readable account of the reasoning process.

</details>


### [196] [CSR-Bench: A Benchmark for Evaluating the Cross-modal Safety and Reliability of MLLMs](https://arxiv.org/abs/2602.03263)
*Yuxuan Liu,Yuntian Shi,Kun Wang,Haoting Shen,Kun Yang*

Main category: cs.AI

TL;DR: CSR-Bench是一个评估多模态大语言模型跨模态可靠性的基准测试，通过四种压力测试模式（安全性、过度拒绝、偏见、幻觉）评估模型在需要图像-文本联合理解任务中的表现，发现现有模型存在系统性跨模态对齐差距。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs的安全行为可能由单模态捷径驱动而非真正的联合意图理解，需要评估模型在需要跨模态整合理解任务中的可靠性，诊断模态引发的行为变化。

Method: 引入CSR-Bench基准，包含四种压力测试交互模式（安全性、过度拒绝、偏见、幻觉），涵盖61种细粒度类型。每个实例都需要图像-文本联合解释，并提供配对的纯文本控制组以诊断模态引发的行为变化。评估了16个最先进的MLLMs。

Result: 观察到系统性跨模态对齐差距：模型表现出弱安全意识、在干扰下强烈的语言主导性、从纯文本控制到多模态输入的持续性能下降。还观察到减少过度拒绝与保持安全非歧视行为之间的明显权衡，表明一些表面安全增益可能来自拒绝导向的启发式而非鲁棒的意图理解。

Conclusion: MLLMs存在系统性跨模态可靠性问题，需要开发真正理解联合意图而非依赖单模态捷径的模型。CSR-Bench为评估和改进跨模态对齐提供了重要工具。

Abstract: Multimodal large language models (MLLMs) enable interaction over both text and images, but their safety behavior can be driven by unimodal shortcuts instead of true joint intent understanding. We introduce CSR-Bench, a benchmark for evaluating cross-modal reliability through four stress-testing interaction patterns spanning Safety, Over-rejection, Bias, and Hallucination, covering 61 fine-grained types. Each instance is constructed to require integrated image-text interpretation, and we additionally provide paired text-only controls to diagnose modality-induced behavior shifts. We evaluate 16 state-of-the-art MLLMs and observe systematic cross-modal alignment gaps. Models show weak safety awareness, strong language dominance under interference, and consistent performance degradation from text-only controls to multimodal inputs. We also observe a clear trade-off between reducing over-rejection and maintaining safe, non-discriminatory behavior, suggesting that some apparent safety gains may come from refusal-oriented heuristics rather than robust intent understanding. WARNING: This paper contains unsafe contents.

</details>


### [197] [Rejecting Arguments Based on Doubt in Structured Bipolar Argumentation](https://arxiv.org/abs/2602.03286)
*Michael A. Müller,Srdjan Vesic,Bruno Yun*

Main category: cs.AI

TL;DR: 本文提出了一种受哲学和语言学启发的新型计算论证方法，引入结构化双极论证框架，允许基于怀疑拒绝论证，并提供句子层面的语义扩展。


<details>
  <summary>Details</summary>
Motivation: 现有计算论证文献很少考虑两个重要观点：1）智能体可以基于怀疑理性地拒绝某些论证，而非必须接受所有可辩护的论证；2）在辩论中，有时更自然地思考哪些句子或主张被接受，而非哪些论证被接受。

Method: 首先定义结构化双极论证框架，其中论证由句子组成，包含攻击和支持两种关系。然后为SBAF提供新的语义，具有两个特点：1）不像基于完备性的语义那样强制接受所有被辩护的论证；2）除了论证扩展外，还提供语言扩展来指定可接受的句子集合。

Result: 提出的语义位于抽象论证的可接受语义和完备语义之间，代表智能体在辩论中可能采取的合理立场。该方法为现有方法提供了新视角，可以指定智能体忽略论证间支持关系的条件，并证明演绎支持语义是该方法的特例。

Conclusion: 本文开发了一种融合哲学和语言学洞见的计算论证新方法，通过结构化双极论证框架和灵活的语义，更好地模拟了人类理性辩论中的实际推理过程。

Abstract: This paper develops a new approach to computational argumentation that is informed by philosophical and linguistic views. Namely, it takes into account two ideas that have received little attention in the literature on computational argumentation: First, an agent may rationally reject an argument based on mere doubt, thus not all arguments they could defend must be accepted; and, second, that it is sometimes more natural to think in terms of which individual sentences or claims an agent accepts in a debate, rather than which arguments. In order to incorporate these two ideas into a computational approach, we first define the notion of structured bipolar argumentation frameworks (SBAFs), where arguments consist of sentences and we have both an attack and a support relation between them. Then, we provide semantics for SBAFs with two features: (1) Unlike with completeness-based semantics, our semantics do not force agents to accept all defended arguments. (2) In addition to argument extensions, which give acceptable sets of arguments, we also provide semantics for language extensions that specify acceptable sets of sentences. These semantics represent reasonable positions an agent might have in a debate. Our semantics lie between the admissible and complete semantics of abstract argumentation. Further, our approach can be used to provide a new perspective on existing approaches. For instance, we can specify the conditions under which an agent can ignore support between arguments (i.e. under which the use of abstract argumentation is warranted) and we show that deductive support semantics is a special case of our approach.

</details>


### [198] [Memora: A Harmonic Memory Representation Balancing Abstraction and Specificity](https://arxiv.org/abs/2602.03315)
*Menglin Xia,Xuchao Zhang,Shantanu Dixit,Paramaguru Harimurugan,Rujia Wang,Victor Ruhle,Robert Sim,Chetan Bansal,Saravan Rajmohan*

Main category: cs.AI

TL;DR: Memora是一种谐波记忆表示方法，通过抽象与具体性的结构平衡来扩展智能体记忆系统，在LoCoMo和LongMemEval基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 智能体记忆系统需要处理持续增长的信息，同时支持高效、上下文感知的检索。抽象对于扩展记忆至关重要，但通常会牺牲具体性，掩盖有效推理所需的细粒度细节。

Method: 引入Memora谐波记忆表示，通过主要抽象索引具体记忆值，将相关更新整合为统一记忆条目；使用线索锚点扩展跨记忆多方面的检索访问并连接相关记忆；采用主动利用记忆连接的检索策略。

Result: 理论上证明标准RAG和基于知识图谱的记忆系统是本框架的特例；在LoCoMo和LongMemEval基准测试中达到最先进水平，展示出更好的检索相关性和随着记忆扩展的推理有效性。

Conclusion: Memora通过结构平衡抽象与具体性，解决了智能体记忆扩展中的关键挑战，为大规模记忆系统提供了有效的表示和检索框架。

Abstract: Agent memory systems must accommodate continuously growing information while supporting efficient, context-aware retrieval for downstream tasks. Abstraction is essential for scaling agent memory, yet it often comes at the cost of specificity, obscuring the fine-grained details required for effective reasoning. We introduce Memora, a harmonic memory representation that structurally balances abstraction and specificity. Memora organizes information via its primary abstractions that index concrete memory values and consolidate related updates into unified memory entries, while cue anchors expand retrieval access across diverse aspects of the memory and connect related memories. Building on this structure, we employ a retrieval policy that actively exploits these memory connections to retrieve relevant information beyond direct semantic similarity. Theoretically, we show that standard Retrieval-Augmented Generation (RAG) and Knowledge Graph (KG)-based memory systems emerge as special cases of our framework. Empirically, Memora establishes a new state-of-the-art on the LoCoMo and LongMemEval benchmarks, demonstrating better retrieval relevance and reasoning effectiveness as memory scales.

</details>


### [199] [MentalSeek-Dx: Towards Progressive Hypothetico-Deductive Reasoning for Real-world Psychiatric Diagnosis](https://arxiv.org/abs/2602.03340)
*Xiao Sun,Yuming Yang,Junnan Zhu,Jiang Zhong,Xinyu Zhou,Kaiwen Wei*

Main category: cs.AI

TL;DR: 本文介绍了MentalDx Bench基准测试和MentalSeek-Dx模型，前者是首个针对真实临床环境中精神障碍级别诊断的基准，后者是通过监督轨迹构建和课程强化学习训练的专业医学LLM，在仅有14B参数下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在精神健康评估中虽有潜力，但现有基准缺乏生态效度和细粒度诊断监督，限制了其临床实用性。需要建立更贴近真实临床环境的评估框架。

Method: 1) 构建MentalDx Bench基准：包含712份去标识化电子健康记录，由认证精神科医生按ICD-11标准标注，涵盖16个诊断类别的76种障碍；2) 开发MentalSeek-Dx模型：通过监督轨迹构建和课程强化学习训练医学专业化LLM，内化临床推理过程。

Result: 评估18个LLM发现关键范式错位：在粗粒度诊断分类表现良好，但在障碍级别诊断系统性失败。MentalSeek-Dx在MentalDx Bench上实现最先进性能，仅用14B参数。

Conclusion: 研究揭示了LLM基于模式建模与临床假设演绎推理之间的差距，提出的MentalSeek-Dx为可靠精神科诊断建立了临床基础框架，推动了AI在精神健康领域的临床应用。

Abstract: Mental health disorders represent a burgeoning global public health challenge. While Large Language Models (LLMs) have demonstrated potential in psychiatric assessment, their clinical utility is severely constrained by benchmarks that lack ecological validity and fine-grained diagnostic supervision. To bridge this gap, we introduce \textbf{MentalDx Bench}, the first benchmark dedicated to disorder-level psychiatric diagnosis within real-world clinical settings. Comprising 712 de-identified electronic health records annotated by board-certified psychiatrists under ICD-11 guidelines, the benchmark covers 76 disorders across 16 diagnostic categories. Evaluation of 18 LLMs reveals a critical \textit{paradigm misalignment}: strong performance at coarse diagnostic categorization contrasts with systematic failure at disorder-level diagnosis, underscoring a gap between pattern-based modeling and clinical hypothetico-deductive reasoning. In response, we propose \textbf{MentalSeek-Dx}, a medical-specialized LLM trained to internalize this clinical reasoning process through supervised trajectory construction and curriculum-based reinforcement learning. Experiments on MentalDx Bench demonstrate that MentalSeek-Dx achieves state-of-the-art (SOTA) performance with only 14B parameters, establishing a clinically grounded framework for reliable psychiatric diagnosis.

</details>


### [200] [Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility](https://arxiv.org/abs/2602.03402)
*Mengxuan Wang,Yuxin Chen,Gang Xu,Tao He,Hongjie Jiang,Ming Li*

Main category: cs.AI

TL;DR: 论文提出了一种名为风险感知注入（RAI）的轻量级免训练安全校准框架，通过放大视觉语言模型中的不安全信号来恢复其类似大语言模型的风险识别能力，有效防御多模态越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在多模态越狱攻击面前非常脆弱，现有防御方法要么需要大量安全微调成本，要么通过激进的token操作严重损害模型效用。研究发现大语言模型本身能识别文本中的不安全内容，但视觉输入会稀释风险信号，因此需要恢复视觉语言模型类似大语言模型的风险识别能力。

Method: RAI框架从语言嵌入中构建不安全原型子空间，对选定的高风险视觉token进行针对性调制，在跨模态特征空间中显式激活安全关键信号。这种方法保留了原始token的语义完整性用于跨模态推理，同时恢复了模型从视觉输入中检测不安全内容的能力。

Result: 在多个越狱攻击和效用基准测试上的广泛实验表明，RAI显著降低了攻击成功率，同时没有损害任务性能，实现了安全性和实用性的良好平衡。

Conclusion: RAI提供了一种轻量级、免训练的安全校准方法，通过放大视觉语言模型中的不安全信号来恢复其类似大语言模型的风险识别能力，有效防御多模态越狱攻击，同时保持模型效用。

Abstract: Vision language models (VLMs) extend the reasoning capabilities of large language models (LLMs) to cross-modal settings, yet remain highly vulnerable to multimodal jailbreak attacks. Existing defenses predominantly rely on safety fine-tuning or aggressive token manipulations, incurring substantial training costs or significantly degrading utility. Recent research shows that LLMs inherently recognize unsafe content in text, and the incorporation of visual inputs in VLMs frequently dilutes risk-related signals. Motivated by this, we propose Risk Awareness Injection (RAI), a lightweight and training-free framework for safety calibration that restores LLM-like risk recognition by amplifying unsafe signals in VLMs. Specifically, RAI constructs an Unsafe Prototype Subspace from language embeddings and performs targeted modulation on selected high-risk visual tokens, explicitly activating safety-critical signals within the cross-modal feature space. This modulation restores the model's LLM-like ability to detect unsafe content from visual inputs, while preserving the semantic integrity of original tokens for cross-modal reasoning. Extensive experiments across multiple jailbreak and utility benchmarks demonstrate that RAI substantially reduces attack success rate without compromising task performance.

</details>


### [201] [Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations](https://arxiv.org/abs/2602.03403)
*Guangming Lang,Mingchuan Shang,Mengjun Hu,Jie Zhou,Feng Xu*

Main category: cs.AI

TL;DR: 该论文提出了一种基于直觉模糊偏好的三支冲突分析方法，通过引入直觉模糊偏好关系来更精细地描述智能体对议题对的态度，克服了传统偏好模型中仅使用三种定性关系的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的冲突分析模型仅依赖偏好、逆偏好和中性这三种定性关系来描述智能体对议题对的态度，这种粗糙的表示方式严重限制了模型捕捉冲突本质的能力。需要一种更细粒度的表示方法来更准确地描述智能体的态度。

Method: 1. 引入直觉模糊偏好冲突情境概念，使用直觉模糊偏好关系更精细地描述智能体对议题对的态度；2. 在该框架内开发直觉模糊偏好冲突度量；3. 构建三支冲突分析模型，用于对智能体对集合、智能体集合和议题集合进行三支划分；4. 基于提出的冲突函数构建相对损失函数来计算三支冲突分析的阈值；5. 提出基于调整机制的可行策略，同时考虑调整幅度和冲突程度，并提供构建此类策略的算法。

Result: 提出了一个完整的直觉模糊偏好冲突分析框架，包括冲突情境建模、冲突度量、三支划分方法、阈值计算算法和可行策略构建机制。通过一个示例验证了所提模型的有效性。

Conclusion: 该研究通过引入直觉模糊偏好关系，显著提升了三支冲突分析模型的表达能力，能够更精细地描述智能体对议题对的态度，为冲突分析提供了更强大的理论框架和实用工具。

Abstract: In three-way conflict analysis, preference-based conflict situations characterize agents' attitudes towards issues by formally modeling their preferences over pairs of issues. However, existing preference-based conflict models rely exclusively on three qualitative relations, namely, preference, converse, and indifference, to describe agents' attitudes towards issue pairs, which significantly limits their capacity in capturing the essence of conflict. To overcome this limitation, we introduce the concept of an intuitionistic fuzzy preference-based conflict situation that captures agents' attitudes towards issue pairs with finer granularity than that afforded by classical preference-based models. Afterwards, we develop intuitionistic fuzzy preference-based conflict measures within this framework, and construct three-way conflict analysis models for trisecting the set of agent pairs, the agent set, and the issue set. Additionally, relative loss functions built on the proposed conflict functions are employed to calculate thresholds for three-way conflict analysis. Finally, we present adjustment mechanism-based feasible strategies that simultaneously account for both adjustment magnitudes and conflict degrees, together with an algorithm for constructing such feasible strategies, and provide an illustrative example to demonstrate the validity and effectiveness of the proposed model.

</details>


### [202] [DiscoverLLM: From Executing Intents to Discovering Them](https://arxiv.org/abs/2602.03429)
*Tae Soo Kim,Yoonjoo Lee,Jaesang Yu,John Joon Young Chung,Juho Kim*

Main category: cs.AI

TL;DR: DiscoverLLM是一个训练大语言模型帮助用户形成和发现意图的框架，通过模拟用户认知状态和意图层次结构，让模型学会在意图不明确时探索选项，在意图明确时细化实现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型处理模糊和开放式请求时，通常只是询问用户澄清问题，但当用户自己也不知道想要什么时，这种方法就会失败。用户之所以模糊，往往是因为他们还没有形成明确的意图，需要通过观察和探索结果来发现自己想要什么。

Method: 提出DiscoverLLM框架，核心是一个新颖的用户模拟器，用层次化的意图结构建模认知状态，意图随着模型展示相关选项而逐步具体化。具体化程度作为奖励信号，模型可以训练优化这个信号。模型学会与用户协作：当意图不明确时自适应地发散（探索选项），当意图具体化时收敛（细化和实现）。

Result: 在创意写作、技术写作和SVG绘图等交互基准测试中，DiscoverLLM实现了超过10%的任务性能提升，同时将对话长度减少了40%。在75名人类参与者的用户研究中，DiscoverLLM相比基线方法提高了对话满意度和效率。

Conclusion: DiscoverLLM框架通过训练大语言模型帮助用户形成和发现意图，解决了传统澄清问题方法的局限性，在多个领域实现了更好的任务性能和更高效的对话交互。

Abstract: To handle ambiguous and open-ended requests, Large Language Models (LLMs) are increasingly trained to interact with users to surface intents they have not yet expressed (e.g., ask clarification questions). However, users are often ambiguous because they have not yet formed their intents: they must observe and explore outcomes to discover what they want. Simply asking "what kind of tone do you want?" fails when users themselves do not know. We introduce DiscoverLLM, a novel and generalizable framework that trains LLMs to help users form and discover their intents. Central to our approach is a novel user simulator that models cognitive state with a hierarchy of intents that progressively concretize as the model surfaces relevant options -- where the degree of concretization serves as a reward signal that models can be trained to optimize. Resulting models learn to collaborate with users by adaptively diverging (i.e., explore options) when intents are unclear, and converging (i.e., refine and implement) when intents concretize. Across proposed interactive benchmarks in creative writing, technical writing, and SVG drawing, DiscoverLLM achieves over 10% higher task performance while reducing conversation length by up to 40%. In a user study with 75 human participants, DiscoverLLM improved conversation satisfaction and efficiency compared to baselines.

</details>


### [203] [CRL-VLA: Continual Vision-Language-Action Learning](https://arxiv.org/abs/2602.03445)
*Qixin Zeng,Shuo Zhang,Hongyin Zhang,Renjie Wang,Han Zhao,Libang Zhao,Runze Li,Donglin Wang,Chao Huang*

Main category: cs.AI

TL;DR: CRL-VLA框架通过理论推导和双评论家架构解决VLA模型在持续强化学习中的稳定性-可塑性权衡问题


<details>
  <summary>Details</summary>
Motivation: 在开放世界环境中，终身学习对具身智能体至关重要。持续强化学习是VLA模型在终身机器人场景中部署的有前景途径，但现有方法在平衡稳定性（保留旧技能）和可塑性（学习新技能）方面面临巨大挑战。

Method: 提出CRL-VLA框架，通过理论推导建立统一性能边界，将稳定性-可塑性权衡与目标条件优势幅度和策略散度联系起来。采用非对称调节方法：限制先前任务的优势幅度，同时允许新任务上的受控增长。实现方式是通过具有新颖目标条件价值公式的双评论家架构，其中冻结评论家锚定语义一致性，可训练估计器驱动适应。

Result: 在LIBERO基准测试中，CRL-VLA有效地协调了这些冲突目标，在抗遗忘和正向适应方面均优于基线方法。

Conclusion: CRL-VLA框架为VLA模型的持续后训练提供了理论保证和有效实现，成功解决了持续强化学习中的稳定性-可塑性权衡问题，为终身机器人学习提供了有前景的解决方案。

Abstract: Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environmental interaction. Thus, Continual Reinforcement Learning (CRL) is a promising pathway for deploying VLA models in lifelong robotic scenarios, yet balancing stability (retaining old skills) and plasticity (learning new ones) remains a formidable challenge for existing methods. We introduce CRL-VLA, a framework for continual post-training of VLA models with rigorous theoretical bounds. We derive a unified performance bound linking the stability-plasticity trade-off to goal-conditioned advantage magnitude, scaled by policy divergence. CRL-VLA resolves this dilemma via asymmetric regulation: constraining advantage magnitudes on prior tasks while enabling controlled growth on new tasks. This is realized through a simple but effective dual-critic architecture with novel Goal-Conditioned Value Formulation (GCVF), where a frozen critic anchors semantic consistency and a trainable estimator drives adaptation. Experiments on the LIBERO benchmark demonstrate that CRL-VLA effectively harmonizes these conflicting objectives, outperforming baselines in both anti-forgetting and forward adaptation.

</details>


### [204] [The Dual Role of Abstracting over the Irrelevant in Symbolic Explanations: Cognitive Effort vs. Understanding](https://arxiv.org/abs/2602.03467)
*Zeynep G. Saribatur,Johannes Langer,Ute Schmid*

Main category: cs.AI

TL;DR: 该研究探讨如何通过形式化抽象（移除和聚类）改进符号AI解释的可理解性，实验表明聚类提高理解，移除降低认知负荷


<details>
  <summary>Details</summary>
Motivation: 虽然符号AI为可解释性提供了透明基础，但原始逻辑追踪往往带来较高的外部认知负荷，需要研究如何通过抽象化改进人类对AI解释的理解

Method: 使用答案集编程（ASP）作为形式框架，定义不相关细节的抽象概念，通过认知实验让参与者基于ASP程序生成的解释对跨领域刺激进行分类

Result: 实验显示：聚类细节显著提高参与者的理解能力，而移除细节显著降低认知努力，支持抽象化增强以人为中心的符号解释的假设

Conclusion: 形式化抽象（特别是移除和聚类）能有效提升符号AI解释的人类可理解性，为设计更人性化的AI解释系统提供了实证支持

Abstract: Explanations are central to human cognition, yet AI systems often produce outputs that are difficult to understand. While symbolic AI offers a transparent foundation for interpretability, raw logical traces often impose a high extraneous cognitive load. We investigate how formal abstractions, specifically removal and clustering, impact human reasoning performance and cognitive effort. Utilizing Answer Set Programming (ASP) as a formal framework, we define a notion of irrelevant details to be abstracted over to obtain simplified explanations. Our cognitive experiments, in which participants classified stimuli across domains with explanations derived from an answer set program, show that clustering details significantly improve participants' understanding, while removal of details significantly reduce cognitive effort, supporting the hypothesis that abstraction enhances human-centered symbolic explanations.

</details>


### [205] [When Routing Collapses: On the Degenerate Convergence of LLM Routers](https://arxiv.org/abs/2602.03478)
*Guannan Lai,Han-Jia Ye*

Main category: cs.AI

TL;DR: 论文发现现有LLM路由系统存在"路由崩溃"现象：随着成本预算增加，路由器会系统性地选择最强大但最昂贵的模型，即使更便宜的模型已经足够，导致小模型利用率不足。作者提出EquiRouter直接学习模型排名来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由系统存在一个普遍但未被充分探索的失败模式：随着用户成本预算增加，路由器会系统性地默认选择最强大、最昂贵的模型，即使更便宜的模型已经足够。这导致小模型利用率不足，浪费计算资源和金钱成本，违背了路由的核心承诺。

Method: 作者提出EquiRouter，一种决策感知的路由器，直接学习模型排名而非预测标量性能分数。这种方法解决了目标-决策不匹配问题：现有路由器训练预测性能分数，但路由决策实际上依赖于候选模型之间的离散比较。

Result: 在RouterBench上，EquiRouter在达到GPT-4级别性能时，相比先前最强的路由器减少了约17%的成本。该方法恢复了小模型的作用，缓解了路由崩溃现象。

Conclusion: 路由崩溃是现有LLM路由系统的一个普遍问题，源于目标-决策不匹配。EquiRouter通过直接学习模型排名来解决这一问题，在保持高质量的同时显著降低成本，实现了更好的质量-成本权衡。

Abstract: LLM routing aims to achieve a favorable quality--cost trade-off by dynamically assigning easy queries to smaller models and harder queries to stronger ones. However, across both unimodal and multimodal settings, we uncover a pervasive yet underexplored failure mode in existing routers: as the user's cost budget increases, routers systematically default to the most capable and most expensive model even when cheaper models already suffice. As a result, current routers under-utilize small models, wasting computation and monetary cost and undermining the core promise of routing; we term this phenomenon routing collapse. We attribute routing collapse to an objective--decision mismatch: many routers are trained to predict scalar performance scores, whereas routing decisions ultimately depend on discrete comparisons among candidate models. Consequently, small prediction errors can flip relative orderings and trigger suboptimal selections. To bridge this gap, we propose EquiRouter, a decision-aware router that directly learns model rankings, restoring the role of smaller models and mitigating routing collapse. On RouterBench, EquiRouter reduces cost by about 17\% at GPT-4-level performance compared to the strongest prior router. Our code is available at https://github.com/AIGNLAI/EquiRouter.

</details>


### [206] [Group Selection as a Safeguard Against AI Substitution](https://arxiv.org/abs/2602.03541)
*Qiankun Zhong,Thomas F. Eisenmann,Julian Garcia,Iyad Rahwan*

Main category: cs.AI

TL;DR: 研究AI使用对人类文化演化的长期影响，发现AI替代型用户（依赖AI生成内容）在个体选择中占优但会减少文化多样性，而AI补充型用户（寻求建议但保持主导）在群体选择中有利于文化探索和变异维持。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的广泛使用可能减少文化变异和多样性，这已经导致了模型崩溃和幻觉等问题。研究旨在探索AI使用对人类文化演化的长期后果，特别是AI使用可能导致"文化崩溃"的条件——即依赖AI生成内容会减少人类变异和创新，减缓累积文化演化。

Method: 使用基于主体的模型和演化博弈论，比较两种AI使用类型：补充型和替代型。AI补充型用户寻求建议和指导，但仍然是最终输出的主要生产者；AI替代型用户提供最小输入，依赖AI产生大部分输出。研究这些使用策略在演化动态下的竞争和传播。

Result: 研究发现，尽管AI替代型用户会更强地减少文化变异，但在个体层面选择中占优势。相比之下，AI补充型用户通过维持探索所需的变异来使群体受益，因此在群体边界强时可以通过文化群体选择得到青睐。

Conclusion: 研究结果揭示了AI采用对人口层面的长期影响，为减轻这些风险的政策和组织策略提供了信息。AI补充型使用策略在群体层面有助于维持文化多样性和创新，而AI替代型使用虽然个体层面占优但可能导致文化变异减少。

Abstract: Reliance on generative AI can reduce cultural variance and diversity, especially in creative work. This reduction in variance has already led to problems in model performance, including model collapse and hallucination. In this paper, we examine the long-term consequences of AI use for human cultural evolution and the conditions under which widespread AI use may lead to "cultural collapse", a process in which reliance on AI-generated content reduces human variation and innovation and slows cumulative cultural evolution. Using an agent-based model and evolutionary game theory, we compare two types of AI use: complement and substitute. AI-complement users seek suggestions and guidance while remaining the main producers of the final output, whereas AI-substitute users provide minimal input, and rely on AI to produce most of the output. We then study how these use strategies compete and spread under evolutionary dynamics. We find that AI-substitute users prevail under individual-level selection despite the stronger reduction in cultural variance. By contrast, AI-complement users can benefit their groups by maintaining the variance needed for exploration, and can therefore be favored under cultural group selection when group boundaries are strong. Overall, our findings shed light on the long-term, population-level effects of AI adoption and inform policy and organizational strategies to mitigate these risks.

</details>


### [207] [EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories](https://arxiv.org/abs/2602.03569)
*Linjie Mu,Zhongzhen Huang,Yannian Gu,Shengqian Qin,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: EHRWorld：基于因果序列范式训练的医疗世界模型，显著优于传统LLM基线，能实现更稳定的长期临床模拟和敏感事件建模


<details>
  <summary>Details</summary>
Motivation: 传统LLM在医疗领域作为动态世界模型存在局限，难以在序列干预下保持患者状态一致性，导致长期模拟中的误差累积。需要开发专门针对医疗领域、基于因果序列范式训练的世界模型。

Method: 提出EHRWorld模型，采用因果序列范式训练，并构建了EHRWorld-110K大规模纵向临床数据集，该数据集源自真实世界电子健康记录，具有时间演化特性。

Result: EHRWorld显著优于基于LLM的基线方法，在长期模拟稳定性、临床敏感事件建模和推理效率方面表现优异，证明了在因果基础、时间演化临床数据上训练的必要性。

Conclusion: 训练在因果基础、时间演化临床数据上的专门医疗世界模型对于实现可靠、稳健的医疗世界建模至关重要，EHRWorld为此类模型提供了有效框架。

Abstract: World models offer a principled framework for simulating future states under interventions, but realizing such models in complex, high-stakes domains like medicine remains challenging. Recent large language models (LLMs) have achieved strong performance on static medical reasoning tasks, raising the question of whether they can function as dynamic medical world models capable of simulating disease progression and treatment outcomes over time. In this work, we show that LLMs only incorporating medical knowledge struggle to maintain consistent patient states under sequential interventions, leading to error accumulation in long-horizon clinical simulation. To address this limitation, we introduce EHRWorld, a patient-centric medical world model trained under a causal sequential paradigm, together with EHRWorld-110K, a large-scale longitudinal clinical dataset derived from real-world electronic health records. Extensive evaluations demonstrate that EHRWorld significantly outperforms naive LLM-based baselines, achieving more stable long-horizon simulation, improved modeling of clinically sensitive events, and favorable reasoning efficiency, highlighting the necessity of training on causally grounded, temporally evolving clinical data for reliable and robust medical world modeling.

</details>


### [208] [TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System](https://arxiv.org/abs/2602.03688)
*Wenzhe Fan,Tommaso Tognoli,Henry Peng Zou,Chunyu Miao,Yibo Wang,Xinhua Zhang*

Main category: cs.AI

TL;DR: TodyComm是一种面向任务的动态通信算法，为多轮LLM多智能体系统提供行为驱动的协作拓扑，能够根据每轮动态变化（如对抗者、任务进展、通信约束）自适应调整通信结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法在推理时使用固定的通信拓扑，无法适应现实应用中智能体角色可能跨轮次变化的情况，如动态对抗者、任务进展或时变通信带宽约束。

Method: 提出TodyComm算法，通过策略梯度优化任务效用，生成行为驱动的协作拓扑，使通信结构能够适应每轮的动态变化。

Result: 在五个基准测试上的实验表明，在动态对抗者和通信预算约束下，TodyComm在任务有效性方面表现优异，同时保持了令牌效率和可扩展性。

Conclusion: TodyComm通过动态调整通信拓扑，有效解决了多轮LLM多智能体系统中固定通信结构的局限性，在动态环境中实现了更好的协作效果。

Abstract: Multi-round LLM-based multi-agent systems rely on effective communication structures to support collaboration across rounds. However, most existing methods employ a fixed communication topology during inference, which falls short in many realistic applications where the agents' roles may change \textit{across rounds} due to dynamic adversary, task progression, or time-varying constraints such as communication bandwidth. In this paper, we propose addressing this issue through TodyComm, a \textbf{t}ask-\textbf{o}riented \textbf{dy}namic \textbf{comm}unication algorithm. It produces behavior-driven collaboration topologies that adapt to the dynamics at each round, optimizing the utility for the task through policy gradient. Experiments on five benchmarks demonstrate that under both dynamic adversary and communications budgets, TodyComm delivers superior task effectiveness while retaining token efficiency and scalability.

</details>
