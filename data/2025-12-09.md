<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 159]
- [cs.IR](#cs.IR) [Total: 8]
- [cs.AI](#cs.AI) [Total: 30]
- [cs.LG](#cs.LG) [Total: 85]
- [cs.CY](#cs.CY) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [FishDetector-R1: Unified MLLM-Based Framework with Reinforcement Fine-Tuning for Weakly Supervised Fish Detection, Segmentation, and Counting](https://arxiv.org/abs/2512.05996)
*Yi Liu,Jingyu Song,Vedanth Kallakuri,Katherine A. Skinner*

Main category: cs.CV

TL;DR: FishDetector-R1是一个基于MLLM的弱监督框架，用于水下鱼类检测、分割和计数，在DeepFish数据集上显著提升了性能指标。


<details>
  <summary>Details</summary>
Motivation: 水下鱼类图像分析对生态监测至关重要，但面临视觉质量下降和标注成本高的挑战，需要开发弱监督的高效解决方案。

Method: 提出统一MLLM框架，包含两个关键组件：1) 检测到计数的提示机制，确保空间一致的检测和计数；2) 基于可验证奖励的强化学习(RLVR)，利用稀疏点标签的可扩展范式。

Result: 在DeepFish数据集上，AP提升20%，mIoU提升10%，MAE降低30%，GAME降低35%。消融研究验证了奖励设计的有效性，且在其他水下数据集上表现出良好的跨域鲁棒性。

Conclusion: FishDetector-R1通过弱监督为海洋视觉理解提供了可靠且可扩展的解决方案，显著提升了水下鱼类分析的准确性和效率。

Abstract: Analyzing underwater fish imagery is critical for ecological monitoring but remains difficult due to visual degradation and costly annotations. We introduce FishDetector-R1, a unified MLLM-based framework for fish detection, segmentation, and counting under weak supervision. On the DeepFish dataset, our framework achieves substantial gains over baselines, improving AP by 20% and mIoU by 10%, while reducing MAE by 30% and GAME by 35%. These improvements stem from two key components: a novel detect-to-count prompt that enforces spatially consistent detections and counts, and Reinforcement Learning from Verifiable Reward (RLVR) with a complementary scalable paradigm leveraging sparse point labels. Ablation studies further validate the effectiveness of this reward design. Moreover, the improvement generalizes well to other underwater datasets, confirming strong cross-domain robustness. Overall, FishDetector-R1 provides a reliable and scalable solution for accurate marine visual understanding via weak supervision. The project page for FishDetector-R1 is https://umfieldrobotics.github.io/FishDetector-R1.

</details>


### [2] [Video Models Start to Solve Chess, Maze, Sudoku, Mental Rotation, and Raven' Matrices](https://arxiv.org/abs/2512.05969)
*Hokin Deng*

Main category: cs.CV

TL;DR: 视频生成模型现在可以进行推理任务，在象棋、迷宫、数独、心理旋转和瑞文矩阵等任务上，Sora-2等领先模型达到60%成功率。研究建立了基于"任务对"设计的实验范式，并开发了支持该范式的代码框架。


<details>
  <summary>Details</summary>
Motivation: 探索视频生成模型是否具备推理能力，建立可扩展的评估范式来系统测试视频模型在各种推理任务上的表现。

Method: 采用"任务对"实验设计，构建了VMEvalKit代码框架，支持39个模型，可轻松添加新模型和任务。通过自动化评估与人工判断的相关性验证评估方法的可靠性。

Result: 在象棋、迷宫、数独、心理旋转和瑞文矩阵等推理任务上，Sora-2等领先视频生成模型达到约60%的成功率。自动化评估与人工判断高度相关，验证了评估范式的有效性。

Conclusion: 视频生成模型已具备一定的推理能力，建立的评估范式具有高度可扩展性，为通过强化学习提升视频模型推理能力提供了机会。

Abstract: We show that video generation models could reason now. Testing on tasks such as chess, maze, Sudoku, mental rotation, and Raven's Matrices, leading models such as Sora-2 achieve sixty percent success rates. We establish a robust experimental paradigm centered on the "Task Pair" design. We build a code framework, with 39 models available already, that supports this paradigm and allows for easy scaling - users can add models and tasks efficiently. We show our automated evaluation strongly correlates with human judgment, and therefore this paradigm is highly scalable. We see an opportunity, given the availability of our paradigm, to do reinforcement learning for improving reasoning in video models. You could checkout all of our raw $\href{https://grow-ai-like-a-child.com/video-reason/}{results}$ and our $\href{https://github.com/hokindeng/VMEvalKit}{VMEvalKit}$ codebase.

</details>


### [3] [Adaptive Dataset Quantization: A New Direction for Dataset Pruning](https://arxiv.org/abs/2512.05987)
*Chenyue Yu,Jianyu Yu*

Main category: cs.CV

TL;DR: 提出一种新颖的数据集量化方法，通过减少样本内冗余来压缩大规模数据集，适用于资源受限的边缘设备，在保持模型训练性能的同时实现显著压缩


<details>
  <summary>Details</summary>
Motivation: 解决资源受限边缘设备中大规模数据集的存储和通信成本问题，传统的数据集剪枝和蒸馏方法主要关注样本间冗余，而本方法专注于减少样本内冗余

Method: 首先应用线性对称量化获取每个样本的初始量化范围和尺度，然后引入自适应量化分配算法，为具有不同精度要求的样本分配不同的量化比率，同时保持总压缩比恒定

Result: 在CIFAR-10、CIFAR-100和ImageNet-1K数据集上的实验验证了方法的有效性，在相同压缩比下优于传统量化和数据集剪枝基线方法

Conclusion: 该方法首次使用有限比特表示数据集以减少存储，引入具有自适应比率分配的数据集级量化算法，在保持模型训练性能的同时实现显著的数据集压缩

Abstract: This paper addresses the challenges of storage and communication costs for large-scale datasets in resource-constrained edge devices by proposing a novel dataset quantization approach to reduce intra-sample redundancy. Unlike traditional dataset pruning and distillation methods that focus on inter-sample redundancy, the proposed method compresses each image by reducing redundant or less informative content within samples while preserving essential features. It first applies linear symmetric quantization to obtain an initial quantization range and scale for each sample. Then, an adaptive quantization allocation algorithm is introduced to distribute different quantization ratios for samples with varying precision requirements, maintaining a constant total compression ratio. The main contributions include: (1) being the first to use limited bits to represent datasets for storage reduction; (2) introducing a dataset-level quantization algorithm with adaptive ratio allocation; and (3) validating the method's effectiveness through extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K. Results show that the method maintains model training performance while achieving significant dataset compression, outperforming traditional quantization and dataset pruning baselines under the same compression ratios.

</details>


### [4] [EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head](https://arxiv.org/abs/2512.05991)
*Chang Liu,Tianjiao Jing,Chengcheng Ma,Xuanqi Zhou,Zhengxuan Lian,Qin Jin,Hongliang Yuan,Shi-Sheng Huang*

Main category: cs.CV

TL;DR: EmoDiffTalk：首个支持基于动作单元（AU）表情空间进行连续多模态情感编辑的3D高斯泼溅说话头生成框架，通过情感感知高斯扩散实现精细面部动画和准确文本到AU情感控制。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的真实感3D说话头在情感表达操纵方面存在显著不足，特别是在使用多模态控制进行细粒度和扩展性动态情感编辑方面。

Method: 提出情感感知高斯扩散方法，包括：1）动作单元提示高斯扩散过程用于细粒度面部动画；2）准确的文本到AU情感控制器，通过文本输入提供精确且扩展的动态情感编辑。

Result: 在公开的EmoTalk3D和RenderMe-360数据集上实验表明，EmoDiffTalk在情感细腻度、唇形同步保真度和可控性方面优于先前工作，建立了高质量、扩散驱动、多模态可编辑3D说话头合成的原则性路径。

Conclusion: EmoDiffTalk是首批支持在基于AU的表情空间内进行连续多模态情感编辑的3D高斯泼溅说话头生成框架之一，为高质量、可编辑的3D说话头合成提供了新方向。

Abstract: Recent photo-realistic 3D talking head via 3D Gaussian Splatting still has significant shortcoming in emotional expression manipulation, especially for fine-grained and expansive dynamics emotional editing using multi-modal control. This paper introduces a new editable 3D Gaussian talking head, i.e. EmoDiffTalk. Our key idea is a novel Emotion-aware Gaussian Diffusion, which includes an action unit (AU) prompt Gaussian diffusion process for fine-grained facial animator, and moreover an accurate text-to-AU emotion controller to provide accurate and expansive dynamic emotional editing using text input. Experiments on public EmoTalk3D and RenderMe-360 datasets demonstrate superior emotional subtlety, lip-sync fidelity, and controllability of our EmoDiffTalk over previous works, establishing a principled pathway toward high-quality, diffusion-driven, multimodal editable 3D talking-head synthesis. To our best knowledge, our EmoDiffTalk is one of the first few 3D Gaussian Splatting talking-head generation framework, especially supporting continuous, multimodal emotional editing within the AU-based expression space.

</details>


### [5] [Domain-Specific Foundation Model Improves AI-Based Analysis of Neuropathology](https://arxiv.org/abs/2512.05993)
*Ruchika Verma,Shrishtee Kandoi,Robina Afzal,Shengjia Chen,Jannes Jegminat,Michael W. Karlovich,Melissa Umphlett,Timothy E. Richardson,Kevin Clare,Quazi Hossain,Jorge Samanamud,Phyllis L. Faust,Elan D. Louis,Ann C. McKee,Thor D. Stein,Jonathan D. Cherry,Jesse Mez,Anya C. McGoldrick,Dalilah D. Quintana Mora,Melissa J. Nirenberg,Ruth H. Walker,Yolfrankcis Mendez,Susan Morgello,Dennis W. Dickson,Melissa E. Murray,Carlos Cordon-Cardo,Nadejda M. Tsankova,Jamie M. Walker,Diana K. Dangoor,Stephanie McQuillan,Emma L. Thorn,Claudia De Sanctis,Shuying Li,Thomas J. Fuchs,Kurt Farrell,John F. Crary,Gabriele Campanella*

Main category: cs.CV

TL;DR: NeuroFM是一个专门针对神经病理学领域训练的病理学基础模型，相比通用模型在神经退行性疾病分析任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有病理学基础模型主要基于外科病理数据训练，这些数据富含非神经组织，过度代表肿瘤、炎症等非神经系统疾病。神经病理学具有独特的细胞类型、细胞结构和疾病特征，这种领域不匹配限制了通用模型捕捉神经退行性疾病关键形态学模式的能力。

Method: 开发了NeuroFM，这是一个专门在脑组织全切片图像上训练的基础模型，涵盖了多种神经退行性病理。

Result: NeuroFM在多个神经病理学特定下游任务中表现出优于通用模型的性能，包括混合性痴呆疾病分类、海马区域分割以及神经退行性共济失调识别（涵盖小脑性特发性震颤和脊髓小脑性共济失调亚型）。

Conclusion: 针对脑组织训练的领域专业化基础模型比通用外科病理数据集训练的模型能更好地捕捉神经病理学特定特征，为数字病理学专业领域的领域特定模型开发树立了先例。

Abstract: Foundation models have transformed computational pathology by providing generalizable representations from large-scale histology datasets. However, existing models are predominantly trained on surgical pathology data, which is enriched for non-nervous tissue and overrepresents neoplastic, inflammatory, metabolic, and other non-neurological diseases. Neuropathology represents a markedly different domain of histopathology, characterized by unique cell types (neurons, glia, etc.), distinct cytoarchitecture, and disease-specific pathological features including neurofibrillary tangles, amyloid plaques, Lewy bodies, and pattern-specific neurodegeneration. This domain mismatch may limit the ability of general-purpose foundation models to capture the morphological patterns critical for interpreting neurodegenerative diseases such as Alzheimer's disease, Parkinson's disease, and cerebellar ataxias. To address this gap, we developed NeuroFM, a foundation model trained specifically on whole-slide images of brain tissue spanning diverse neurodegenerative pathologies. NeuroFM demonstrates superior performance compared to general-purpose models across multiple neuropathology-specific downstream tasks, including mixed dementia disease classification, hippocampal region segmentation, and neurodegenerative ataxia identification encompassing cerebellar essential tremor and spinocerebellar ataxia subtypes. This work establishes that domain-specialized foundation models trained on brain tissue can better capture neuropathology-specific features than models trained on general surgical pathology datasets. By tailoring foundation models to the unique morphological landscape of neurodegenerative diseases, NeuroFM enables more accurate and reliable AI-based analysis for brain disease diagnosis and research, setting a precedent for domain-specific model development in specialized areas of digital pathology.

</details>


### [6] [High-Throughput Unsupervised Profiling of the Morphology of 316L Powder Particles for Use in Additive Manufacturing](https://arxiv.org/abs/2512.06012)
*Emmanuel Akeweje,Conall Kirk,Chi-Wai Chan,Denis Dowling,Mimi Zhang*

Main category: cs.CV

TL;DR: 开发了一种基于机器学习的自动化框架，通过高通量成像、形状提取和聚类分析来大规模表征金属粉末形态，为SLM工艺提供快速、自动化的粉末质量评估方法。


<details>
  <summary>Details</summary>
Motivation: 选择性激光熔化(SLM)工艺的零件质量严重依赖于原料粉末的形态特征，但传统的粉末表征方法通量低、定性化，无法捕捉工业规模批次的异质性，需要开发自动化、高通量的表征技术。

Method: 提出了一个自动化机器学习框架，结合高通量成像、形状提取和聚类分析。开发并评估了三种聚类流程：自编码器流程、形状描述符流程和功能数据流程。在约126,000个粉末图像数据集(直径0.5-102微米)上进行测试。

Result: 内部有效性指标确定傅里叶描述符+k-means流程最为有效，实现了最低的Davies-Bouldin指数和最高的Calinski-Harabasz分数，同时在标准桌面工作站上保持每个颗粒亚毫秒级的运行时间。

Conclusion: 这种无监督学习框架能够快速、自动化地评估粉末形态，支持跟踪粉末在重复使用周期中的形状演变，为SLM工作流程中的实时原料监控提供了路径。虽然当前工作重点是建立形态聚类框架，但得到的形状分组为未来研究其与流动性、堆积密度和SLM零件质量的关系奠定了基础。

Abstract: Selective Laser Melting (SLM) is a powder-bed additive manufacturing technique whose part quality depends critically on feedstock morphology. However, conventional powder characterization methods are low-throughput and qualitative, failing to capture the heterogeneity of industrial-scale batches. We present an automated, machine learning framework that couples high-throughput imaging with shape extraction and clustering to profile metallic powder morphology at scale. We develop and evaluate three clustering pipelines: an autoencoder pipeline, a shape-descriptor pipeline, and a functional-data pipeline. Across a dataset of approximately 126,000 powder images (0.5-102 micrometer diameter), internal validity metrics identify the Fourier-descriptor + k-means pipeline as the most effective, achieving the lowest Davies-Bouldin index and highest Calinski-Harabasz score while maintaining sub-millisecond runtime per particle on a standard desktop workstation. Although the present work focuses on establishing the morphological-clustering framework, the resulting shape groups form a basis for future studies examining their relationship to flowability, packing density, and SLM part quality. Overall, this unsupervised learning framework enables rapid, automated assessment of powder morphology and supports tracking of shape evolution across reuse cycles, offering a path toward real-time feedstock monitoring in SLM workflows.

</details>


### [7] [VAT: Vision Action Transformer by Unlocking Full Representation of ViT](https://arxiv.org/abs/2512.06013)
*Wenhao Li,Chengwei Ma,Weixin Mao*

Main category: cs.CV

TL;DR: VAT是一种基于ViT的新型机器人学习架构，通过利用ViT所有层的特征层次结构，实现感知与动作生成的深度渐进融合，在模拟操作任务中达到98.15%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习方法通常只使用ViT最后一层的特征，丢弃了有价值的中间层信息，导致视觉表示不够充分。

Method: 提出Vision Action Transformer (VAT)，扩展自ViT架构，通过在所有transformer层中处理专门的动作token与视觉特征，实现感知与动作生成的深度渐进融合。

Result: 在四个LIBERO基准测试中达到98.15%的平均成功率，超越了OpenVLA-OFT等先前方法，建立了新的最先进水平。

Conclusion: VAT不仅是一个强大的模仿学习模型，还证明了利用视觉模型的完整"表示轨迹"对于推进机器人策略的关键重要性。

Abstract: In robot learning, Vision Transformers (ViTs) are standard for visual perception, yet most methods discard valuable information by using only the final layer's features. We argue this provides an insufficient representation and propose the Vision Action Transformer (VAT), a novel architecture that is extended from ViT and unlocks the full feature hierarchy of ViT. VAT processes specialized action tokens with visual features across all transformer layers, enabling a deep and progressive fusion of perception and action generation. On a suite of simulated manipulation tasks, VAT achieves a 98.15\% average success rate across four LIBERO benchmarks, establishing a new state-of-the-art by outperforming prior methods like OpenVLA-OFT. Our work presents not only a powerful model for imitation learning but also demonstrates the critical importance of leveraging the complete ''representation trajectory'' of vision models to advance robotic policy. The GitHub URL for the project code is https://github.com/sellerbubble/VAT.

</details>


### [8] [Benchmarking CXR Foundation Models With Publicly Available MIMIC-CXR and NIH-CXR14 Datasets](https://arxiv.org/abs/2512.06014)
*Jiho Shin,Dominic Marshall,Matthieu Komorowski*

Main category: cs.CV

TL;DR: 该研究对两个大规模胸部X光嵌入模型（CXR-Foundation和MedImageInsight）在公开数据集上进行基准测试，比较它们在医学图像表示学习中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在医学图像表示学习方面表现出色，但它们在跨数据集上的比较行为尚未得到充分探索。本研究旨在建立标准化的评估基准，为未来的多模态和临床整合研究提供可重复的基础。

Method: 使用统一的预处理流程和固定的下游分类器，在MIMIC-CR和NIH ChestX-ray14数据集上评估两个模型。直接从预训练编码器提取嵌入，训练轻量级LightGBM分类器处理多种疾病标签，报告平均AUROC和F1分数及95%置信区间。

Result: MedImageInsight在大多数任务中表现略优，而CXR-Foundation展现出更强的跨数据集稳定性。MedImageInsight嵌入的无监督聚类进一步揭示了与定量结果一致的疾病特异性结构。

Conclusion: 研究结果强调了医学基础模型标准化评估的必要性，并为未来的多模态和临床整合研究建立了可重复的基准。两个模型各有优势，MedImageInsight在性能上略胜一筹，而CXR-Foundation在跨数据集稳定性方面表现更好。

Abstract: Recent foundation models have demonstrated strong performance in medical image representation learning, yet their comparative behaviour across datasets remains underexplored. This work benchmarks two large-scale chest X-ray (CXR) embedding models (CXR-Foundation (ELIXR v2.0) and MedImagelnsight) on public MIMIC-CR and NIH ChestX-ray14 datasets. Each model was evaluated using a unified preprocessing pipeline and fixed downstream classifiers to ensure reproducible comparison. We extracted embeddings directly from pre-trained encoders, trained lightweight LightGBM classifiers on multiple disease labels, and reported mean AUROC, and F1-score with 95% confidence intervals. MedImageInsight achieved slightly higher performance across most tasks, while CXR-Foundation exhibited strong cross-dataset stability. Unsupervised clustering of MedImageIn-sight embeddings further revealed a coherent disease-specific structure consistent with quantitative results. The results highlight the need for standardised evaluation of medical foundation models and establish reproducible baselines for future multimodal and clinical integration studies.

</details>


### [9] [PrefGen: Multimodal Preference Learning for Preference-Conditioned Image Generation](https://arxiv.org/abs/2512.06020)
*Wenyi Mo,Tianyu Zhang,Yalong Bai,Ligong Han,Ying Ba,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: 提出基于多模态大语言模型的个性化图像生成框架，通过提取用户偏好表征并注入扩散模型，实现同时满足文本提示和用户审美偏好的图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有个性化图像生成方法要么无法捕捉用户细微偏好，要么缺乏有效编码个性化视觉信号的机制，需要更有效的方法来适应个体用户的审美选择。

Method: 1) 训练MLLM进行偏好导向的视觉问答以捕捉细粒度语义线索；2) 引入两个互补的探测任务：用户间区分（区分不同用户）和用户内区分（区分喜欢与不喜欢内容）；3) 设计基于最大均值差异的对齐损失，弥合模态差距同时保持多模态结构；4) 将生成的嵌入用于条件化图像生成器。

Result: 大量实验表明，该方法在图像质量和偏好对齐方面显著优于强基线，证明了表征提取和对齐在个性化生成中的有效性。

Conclusion: 提出的多模态框架通过有效提取用户偏好表征并将其与扩散模型对齐，实现了高质量的个性化图像生成，在同时满足文本提示和用户偏好方面表现出色。

Abstract: Preference-conditioned image generation seeks to adapt generative models to individual users, producing outputs that reflect personal aesthetic choices beyond the given textual prompt. Despite recent progress, existing approaches either fail to capture nuanced user preferences or lack effective mechanisms to encode personalized visual signals. In this work, we propose a multimodal framework that leverages multimodal large language models (MLLMs) to extract rich user representations and inject them into diffusion-based image generation. We train the MLLM with a preference-oriented visual question answering task to capture fine-grained semantic cues. To isolate preference-relevant features, we introduce two complementary probing tasks: inter-user discrimination to distinguish between different users, and intra-user discrimination to separate liked from disliked content. To ensure compatibility with diffusion text encoders, we design a maximum mean discrepancy-based alignment loss that bridges the modality gap while preserving multimodal structure. The resulting embeddings are used to condition the generator, enabling faithful adherence to both prompts and user preferences. Extensive experiments demonstrate that our method substantially outperforms strong baselines in both image quality and preference alignment, highlighting the effectiveness of representation extraction and alignment for personalized generation.

</details>


### [10] [The SAM2-to-SAM3 Gap in the Segment Anything Model Family: Why Prompt-Based Expertise Fails in Concept-Driven Image Segmentation](https://arxiv.org/abs/2512.06032)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.CV

TL;DR: SAM2和SAM3之间存在根本性断裂：SAM2是基于空间提示的纯视觉-时间分割模型，而SAM3是统一视觉-语言架构，具备开放词汇推理、语义基础、对比对齐和基于示例的概念理解能力。


<details>
  <summary>Details</summary>
Motivation: 研究SAM2和SAM3之间的根本性不连续性，解释为什么SAM2基于提示的分割专业知识无法转移到SAM3的多模态概念驱动范式中，确立SAM3作为新一代分割基础模型的地位。

Method: 通过五个核心组件进行结构化分析：(1)概念断裂：对比SAM2的空间提示语义与SAM3的多模态融合和文本条件掩码生成；(2)架构差异：SAM2的纯视觉-时间设计与SAM3的视觉-语言编码器、几何和示例编码器、融合模块、DETR风格解码器、对象查询和MoE模糊处理；(3)数据集和标注差异：SA-V视频掩码与SAM3的多模态概念标注语料库；(4)训练和超参数区别；(5)评估、指标和失败模式：从几何IoU指标到语义、开放词汇评估的转变。

Result: 分析确立了SAM3作为一个新的分割基础模型类别，其范式从SAM2的几何分割转变为概念驱动的分割，具备开放词汇推理、语义基础和概念理解能力。

Conclusion: SAM3代表了分割模型的新时代，从SAM2的提示驱动范式转变为概念驱动范式，为新兴的概念驱动分割时代指明了未来发展方向。

Abstract: This paper investigates the fundamental discontinuity between the latest two Segment Anything Models: SAM2 and SAM3. We explain why the expertise in prompt-based segmentation of SAM2 does not transfer to the multimodal concept-driven paradigm of SAM3. SAM2 operates through spatial prompts points, boxes, and masks yielding purely geometric and temporal segmentation. In contrast, SAM3 introduces a unified vision-language architecture capable of open-vocabulary reasoning, semantic grounding, contrastive alignment, and exemplar-based concept understanding. We structure this analysis through five core components: (1) a Conceptual Break Between Prompt-Based and Concept-Based Segmentation, contrasting spatial prompt semantics of SAM2 with multimodal fusion and text-conditioned mask generation of SAM3; (2) Architectural Divergence, detailing pure vision-temporal design of SAM2 versus integration of vision-language encoders, geometry and exemplar encoders, fusion modules, DETR-style decoders, object queries, and ambiguity-handling via Mixture-of-Experts in SAM3; (3) Dataset and Annotation Differences, contrasting SA-V video masks with multimodal concept-annotated corpora of SAM3; (4) Training and Hyperparameter Distinctions, showing why SAM2 optimization knowledge does not apply to SAM3; and (5) Evaluation, Metrics, and Failure Modes, outlining the transition from geometric IoU metrics to semantic, open-vocabulary evaluation. Together, these analyses establish SAM3 as a new class of segmentation foundation model and chart future directions for the emerging concept-driven segmentation era.

</details>


### [11] [EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing](https://arxiv.org/abs/2512.06065)
*Runjia Li,Moayed Haji-Ali,Ashkan Mirzaei,Chaoyang Wang,Arpit Sahni,Ivan Skorokhodov,Aliaksandr Siarohin,Tomas Jakab,Junlin Han,Sergey Tulyakov,Philip Torr,Willi Menapace*

Main category: cs.CV

TL;DR: 提出EgoEdit生态系统，用于解决第一人称视频编辑中的特殊挑战，包括快速自我运动和频繁的手物交互，支持实时交互式AR应用。


<details>
  <summary>Details</summary>
Motivation: 现有AI视频编辑器在第三人称视频上表现良好，但第一人称视角存在独特挑战：快速自我运动和频繁的手物交互造成显著领域差距。现有离线编辑流程延迟高，限制了实时交互。

Method: 构建EgoEditData数据集（专门为第一人称编辑场景设计，包含丰富的手物交互并明确保留手部）；开发EgoEdit模型（支持单GPU实时流式推理的指令跟随第一人称视频编辑器）；创建EgoEditBench评估套件（针对指令忠实度、手部和交互保留、自我运动下的时间稳定性）。

Result: EgoEdit在第一人称编辑基准上取得明显优势（现有方法在此表现不佳），同时在通用编辑任务上保持与最强基线相当的性能，能够产生时间稳定、指令忠实的结果，并具有交互式延迟。

Conclusion: 提出了完整的EgoEdit生态系统，包括专门数据集、实时编辑模型和评估套件，有效解决了第一人称视频编辑的独特挑战，为交互式AR应用提供了实用解决方案。

Abstract: We study instruction-guided editing of egocentric videos for interactive AR applications. While recent AI video editors perform well on third-person footage, egocentric views present unique challenges - including rapid egomotion and frequent hand-object interactions - that create a significant domain gap. Moreover, existing offline editing pipelines suffer from high latency, limiting real-time interaction. To address these issues, we present a complete ecosystem for egocentric video editing. First, we construct EgoEditData, a carefully designed and manually curated dataset specifically designed for egocentric editing scenarios, featuring rich hand-object interactions, while explicitly preserving hands. Second, we develop EgoEdit, an instruction-following egocentric video editor that supports real-time streaming inference on a single GPU. Finally, we introduce EgoEditBench, an evaluation suite targeting instruction faithfulness, hand and interaction preservation, and temporal stability under egomotion. Across both egocentric and general editing tasks, EgoEdit produces temporally stable, instruction-faithful results with interactive latency. It achieves clear gains on egocentric editing benchmarks-where existing methods struggle-while maintaining performance comparable to the strongest baselines on general editing tasks. EgoEditData and EgoEditBench will be made public for the research community. See our website at https://snap-research.github.io/EgoEdit

</details>


### [12] [Shoot-Bounce-3D: Single-Shot Occlusion-Aware 3D from Lidar by Decomposing Two-Bounce Light](https://arxiv.org/abs/2512.06080)
*Tzofi Klinghoffer,Siddharth Somasundaram,Xiaoyu Xiang,Yuchen Fan,Christian Richardt,Akshat Dave,Ramesh Raskar,Rakesh Ranjan*

Main category: cs.CV

TL;DR: 利用单光子激光雷达通过多弹跳光信息恢复遮挡几何和镜面反射场景的3D重建方法


<details>
  <summary>Details</summary>
Motivation: 单视角3D场景重建在存在遮挡区域和镜面材料（如镜子）时具有挑战性。传统方法难以处理这些复杂情况，而单光子激光雷达可以测量多次弹跳的光信号，这些信号包含额外的场景信息。

Method: 提出数据驱动方法反演单光子激光雷达中的光传输。创建首个大规模室内场景激光雷达瞬态数据集（约10万个样本），学习复杂光传输先验，将测量的双弹跳光分解为每个激光点的组成贡献。

Result: 实验证明分解后的光可用于从单次测量中推断具有遮挡和镜子的场景的3D几何结构。代码和数据集已开源。

Conclusion: 通过数据驱动方法利用单光子激光雷达的多弹跳光信息，能够有效解决遮挡和镜面反射场景的3D重建问题，为实际应用提供了可行方案。

Abstract: 3D scene reconstruction from a single measurement is challenging, especially in the presence of occluded regions and specular materials, such as mirrors. We address these challenges by leveraging single-photon lidars. These lidars estimate depth from light that is emitted into the scene and reflected directly back to the sensor. However, they can also measure light that bounces multiple times in the scene before reaching the sensor. This multi-bounce light contains additional information that can be used to recover dense depth, occluded geometry, and material properties. Prior work with single-photon lidar, however, has only demonstrated these use cases when a laser sequentially illuminates one scene point at a time. We instead focus on the more practical - and challenging - scenario of illuminating multiple scene points simultaneously. The complexity of light transport due to the combined effects of multiplexed illumination, two-bounce light, shadows, and specular reflections is challenging to invert analytically. Instead, we propose a data-driven method to invert light transport in single-photon lidar. To enable this approach, we create the first large-scale simulated dataset of ~100k lidar transients for indoor scenes. We use this dataset to learn a prior on complex light transport, enabling measured two-bounce light to be decomposed into the constituent contributions from each laser spot. Finally, we experimentally demonstrate how this decomposed light can be used to infer 3D geometry in scenes with occlusions and mirrors from a single measurement. Our code and dataset are released at https://shoot-bounce-3d.github.io.

</details>


### [13] [BeLLA: End-to-End Birds Eye View Large Language Assistant for Autonomous Driving](https://arxiv.org/abs/2512.06096)
*Karthik Mohan,Sonam Singh,Amit Arvind Kale*

Main category: cs.CV

TL;DR: BeLLA是一个端到端架构，将360°鸟瞰图表示与大型语言模型连接，用于自动驾驶问答任务，在需要空间推理的问题上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在自动驾驶研究中存在局限性：要么使用单视角编码器无法利用多摄像头系统的空间结构，要么使用聚合的多视角特征缺乏统一的空间表示，难以进行自我中心方向、物体关系和上下文推理。

Method: 提出BeLLA端到端架构，将统一的360°鸟瞰图表示与大型语言模型连接，用于自动驾驶问答。该方法利用BEV表示提供统一的空间参考框架。

Result: 在NuScenes-QA和DriveLM基准测试中，BeLLA在需要空间推理的问题上（如相对物体定位和附近物体行为理解）持续优于现有方法，某些任务获得高达+9.3%的绝对提升。在其他类别中也表现具有竞争力。

Conclusion: BeLLA通过连接统一BEV表示与语言模型，显著提升了自动驾驶问答中的空间推理能力，能够处理多样化的问题类型。

Abstract: The rapid development of Vision-Language models (VLMs) and Multimodal Language Models (MLLMs) in autonomous driving research has significantly reshaped the landscape by enabling richer scene understanding, context-aware reasoning, and more interpretable decision-making. However, a lot of existing work often relies on either single-view encoders that fail to exploit the spatial structure of multi-camera systems or operate on aggregated multi-view features, which lack a unified spatial representation, making it more challenging to reason about ego-centric directions, object relations, and the wider context. We thus present BeLLA, an end-to-end architecture that connects unified 360° BEV representations with a large language model for question answering in autonomous driving. We primarily evaluate our work using two benchmarks - NuScenes-QA and DriveLM, where BeLLA consistently outperforms existing approaches on questions that require greater spatial reasoning, such as those involving relative object positioning and behavioral understanding of nearby objects, achieving up to +9.3% absolute improvement in certain tasks. In other categories, BeLLA performs competitively, demonstrating the capability of handling a diverse range of questions.

</details>


### [14] [Explainable Melanoma Diagnosis with Contrastive Learning and LLM-based Report Generation](https://arxiv.org/abs/2512.06105)
*Junwen Zheng,Xinran Xu,Li Rong Wang,Chang Cai,Lucinda Siyun Tan,Dingyuan Wang,Hong Liang Tey,Xiuyi Fan*

Main category: cs.CV

TL;DR: 提出CEFM框架，通过对比学习将临床诊断标准（ABC规则）映射到视觉Transformer嵌入空间，生成结构化文本解释，提高黑色素瘤分类的可解释性和临床信任度。


<details>
  <summary>Details</summary>
Motivation: 深度学习在黑色素瘤分类中已达到专家级性能，但模型的不透明性和缺乏可解释性阻碍了临床采用。临床医生难以信任黑盒模型的决策过程，需要建立模型决策与临床诊断标准之间的透明联系。

Method: 提出CEFM框架，核心机制是对比学习。使用双投影头将临床诊断标准（不对称性、边界、颜色）映射到Vision Transformer嵌入空间，使临床语义与视觉特征对齐。然后将对齐的表征通过自然语言生成转换为结构化文本解释。

Result: 在公共数据集上达到92.79%的准确率和0.961的AUC，在多个可解释性指标上有显著提升。定性分析显示学习到的嵌入空间排列与临床医生应用的ABC规则一致。

Conclusion: CEFM框架成功地将高性能分类与临床信任联系起来，通过学习到的嵌入空间与临床诊断标准的对齐，为黑色素瘤诊断提供了透明且可解释的决策过程。

Abstract: Deep learning has demonstrated expert-level performance in melanoma classification, positioning it as a powerful tool in clinical dermatology. However, model opacity and the lack of interpretability remain critical barriers to clinical adoption, as clinicians often struggle to trust the decision-making processes of black-box models. To address this gap, we present a Cross-modal Explainable Framework for Melanoma (CEFM) that leverages contrastive learning as the core mechanism for achieving interpretability. Specifically, CEFM maps clinical criteria for melanoma diagnosis-namely Asymmetry, Border, and Color (ABC)-into the Vision Transformer embedding space using dual projection heads, thereby aligning clinical semantics with visual features. The aligned representations are subsequently translated into structured textual explanations via natural language generation, creating a transparent link between raw image data and clinical interpretation. Experiments on public datasets demonstrate 92.79% accuracy and an AUC of 0.961, along with significant improvements across multiple interpretability metrics. Qualitative analyses further show that the spatial arrangement of the learned embeddings aligns with clinicians' application of the ABC rule, effectively bridging the gap between high-performance classification and clinical trust.

</details>


### [15] [Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation](https://arxiv.org/abs/2512.06158)
*Su Sun,Cheng Zhao,Himangi Mittal,Gaurav Mittal,Rohith Kukkala,Yingjie Victor Chen,Mei Chen*

Main category: cs.CV

TL;DR: Track4DGen是一个两阶段框架，通过结合多视角视频扩散模型、基础点追踪器和混合4D高斯泼溅重建器，从稀疏输入生成动态4D对象，解决了外观和运动一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 从稀疏输入生成动态4D对象很困难，因为需要同时保持跨视角和时间的外观和运动一致性，同时抑制伪影和时间漂移。现有方法主要依赖像素或潜在空间的视频扩散损失监督，缺乏明确的时间感知、特征级追踪指导。

Method: 提出Track4DGen两阶段框架：第一阶段在多视角视频扩散生成器中强制密集特征级点对应关系，产生时间一致的特征；第二阶段使用混合运动编码重建动态4D高斯泼溅，将扩散特征（携带追踪先验）与Hex-plane特征拼接，并用4D球谐函数增强动态建模。

Result: Track4DGen在多视角视频生成和4D生成基准测试中超越了基线方法，产生了时间稳定、可文本编辑的4D资产。同时创建了Sketchfab28高质量数据集，用于基准测试和未来研究。

Conclusion: 通过显式注入追踪器导出的运动先验到中间特征表示中，Track4DGen有效解决了动态4D对象生成中的时间一致性和跨视角相干性问题，为高质量4D资产生成提供了有效解决方案。

Abstract: Generating dynamic 4D objects from sparse inputs is difficult because it demands joint preservation of appearance and motion coherence across views and time while suppressing artifacts and temporal drift. We hypothesize that the view discrepancy arises from supervision limited to pixel- or latent-space video-diffusion losses, which lack explicitly temporally aware, feature-level tracking guidance. We present \emph{Track4DGen}, a two-stage framework that couples a multi-view video diffusion model with a foundation point tracker and a hybrid 4D Gaussian Splatting (4D-GS) reconstructor. The central idea is to explicitly inject tracker-derived motion priors into intermediate feature representations for both multi-view video generation and 4D-GS. In Stage One, we enforce dense, feature-level point correspondences inside the diffusion generator, producing temporally consistent features that curb appearance drift and enhance cross-view coherence. In Stage Two, we reconstruct a dynamic 4D-GS using a hybrid motion encoding that concatenates co-located diffusion features (carrying Stage-One tracking priors) with Hex-plane features, and augment them with 4D Spherical Harmonics for higher-fidelity dynamics modeling. \emph{Track4DGen} surpasses baselines on both multi-view video generation and 4D generation benchmarks, yielding temporally stable, text-editable 4D assets. Lastly, we curate \emph{Sketchfab28}, a high-quality dataset for benchmarking object-centric 4D generation and fostering future research.

</details>


### [16] [Automated Annotation of Shearographic Measurements Enabling Weakly Supervised Defect Detection](https://arxiv.org/abs/2512.06171)
*Jessica Plassmann,Nicolas Schuler,Michael Schuth,Georg von Freymann*

Main category: cs.CV

TL;DR: 提出基于深度学习的自动化工作流，从剪切散斑测量中生成缺陷标注，减少人工标注工作量，支持可扩展的数据集创建


<details>
  <summary>Details</summary>
Motivation: 剪切散斑技术虽然对表面位移梯度敏感，能有效检测安全关键部件的内部缺陷，但其工业应用受到高质量标注数据集缺乏的限制。人工标注劳动密集、主观性强且难以标准化。

Method: 引入自动化工作流，利用深度学习从剪切散斑测量中生成缺陷标注，包括高分辨率分割和边界框标签。

Result: 与专家标注数据对比评估显示，该方法具有足够准确性，能够支持弱监督训练，减少人工工作量。

Conclusion: 该自动化工作流能够支持可扩展的数据集创建，为稳健的缺陷检测提供支持，促进剪切散斑技术在工业中的应用。

Abstract: Shearography is an interferometric technique sensitive to surface displacement gradients, providing high sensitivity for detecting subsurface defects in safety-critical components. A key limitation to industrial adoption is the lack of high-quality annotated datasets, since manual labeling remains labor-intensive, subjective, and difficult to standardize. We introduce an automated workflow that generates defect annotations from shearography measurements using deep learning, producing high-resolution segmentation and bounding-box labels. Evaluation against expert-labeled data demonstrates sufficient accuracy to enable weakly supervised training, reducing manual effort and supporting scalable dataset creation for robust defect detection.

</details>


### [17] [Physics-Grounded Shadow Generation from Monocular 3D Geometry Priors and Approximate Light Direction](https://arxiv.org/abs/2512.06174)
*Shilin Hu,Jingyi Xu,Akshat Dave,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 该论文提出了一种将显式物理建模（几何与光照）融入深度学习阴影生成的新框架，通过单目RGB图像获取3D几何和主光方向，基于阴影形成物理原理生成初始阴影估计，再用扩散模型进行精细化处理。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的阴影生成方法很少利用显式的物理建模，而阴影形成本质上遵循物理规律（遮挡物阻挡光线形成阴影）。该研究旨在将几何和光照的显式物理建模融入深度学习框架，以生成更符合物理真实性的阴影。

Method: 1. 从单目RGB图像获取密集点云表示的近似3D几何，并预测主导光方向；2. 基于阴影形成物理原理计算初始阴影位置和形状；3. 将物理基础估计集成到扩散框架中，精细化阴影外观，确保与场景几何和光照的一致性。

Result: 在DESOBAV2数据集上训练，模型生成的阴影既视觉逼真又物理一致，在复杂几何或模糊光照场景中表现优于现有方法。

Conclusion: 将显式物理建模（几何与光照）融入深度学习阴影生成框架，能够产生更真实、物理一致的阴影，特别是在复杂场景中表现出色，为阴影生成任务提供了新的有效方法。

Abstract: Shadow generation aims to produce photorealistic shadows that are visually consistent with object geometry and scene illumination. In the physics of shadow formation, the occluder blocks some light rays casting from the light source that would otherwise arrive at the surface, creating a shadow that follows the silhouette of the occluder. However, such explicit physical modeling has rarely been used in deep-learning-based shadow generation. In this paper, we propose a novel framework that embeds explicit physical modeling - geometry and illumination - into deep-learning-based shadow generation. First, given a monocular RGB image, we obtain approximate 3D geometry in the form of dense point maps and predict a single dominant light direction. These signals allow us to recover fairly accurate shadow location and shape based on the physics of shadow formation. We then integrate this physics-based initial estimate into a diffusion framework that refines the shadow into a realistic, high-fidelity appearance while ensuring consistency with scene geometry and illumination. Trained on DESOBAV2, our model produces shadows that are both visually realistic and physically coherent, outperforming existing approaches, especially in scenes with complex geometry or ambiguous lighting.

</details>


### [18] [Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction](https://arxiv.org/abs/2512.06179)
*Shilin Hu,Jingyi Xu,Sagnik Das,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 该论文提出了首个联合检测投射阴影和附着阴影的框架，通过光照和几何推理的闭环系统提升附着阴影检测效果，并创建了包含两种阴影标注的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有阴影检测方法主要针对投射阴影，缺乏专门检测附着阴影的数据集和模型。附着阴影对于理解物体三维结构和场景理解至关重要，因此需要填补这一空白。

Method: 提出一个联合检测框架，包含阴影检测模块（分别预测两种阴影）和光照估计模块（从阴影推断光照方向）。利用估计的光照方向和表面法线推导几何一致的部分遮挡图，通过闭环推理过程迭代优化阴影分割和光照估计。

Result: 实验结果表明，该迭代几何-光照推理方法显著提升了附着阴影检测效果，BER降低至少33%，同时保持了良好的整体阴影和投射阴影检测性能。

Conclusion: 通过联合推理阴影、光照和几何关系，该框架有效解决了附着阴影检测问题，为场景理解和三维结构分析提供了重要工具。

Abstract: Attached shadows occur on the surface of the occluder where light cannot reach because of self-occlusion. They are crucial for defining the three-dimensional structure of objects and enhancing scene understanding. Yet existing shadow detection methods mainly target cast shadows, and there are no dedicated datasets or models for detecting attached shadows. To address this gap, we introduce a framework that jointly detects cast and attached shadows by reasoning about their mutual relationship with scene illumination and geometry. Our system consists of a shadow detection module that predicts both shadow types separately, and a light estimation module that infers the light direction from the detected shadows. The estimated light direction, combined with surface normals, allows us to derive a geometry-consistent partial map that identifies regions likely to be self-occluded. This partial map is then fed back to refine shadow predictions, forming a closed-loop reasoning process that iteratively improves both shadow segmentation and light estimation. In order to train our method, we have constructed a dataset of 1,458 images with separate annotations for cast and attached shadows, enabling training and quantitative evaluation of both. Experimental results demonstrate that this iterative geometry-illumination reasoning substantially improves the detection of attached shadows, with at least 33% BER reduction, while maintaining strong full and cast shadow performance.

</details>


### [19] [Multi-Modal Zero-Shot Prediction of Color Trajectories in Food Drying](https://arxiv.org/abs/2512.06190)
*Shichen Li,Ahmadreza Eslaminia,Chenhui Shao*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态颜色轨迹预测方法，通过整合高维时间颜色信息和干燥工艺参数，实现准确且数据高效的颜色轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖低维颜色特征，无法充分捕捉食品样品复杂的动态颜色轨迹，且现有建模方法缺乏对未见工艺条件的泛化能力。

Method: 开发了一种多模态颜色轨迹预测方法，整合高维时间颜色信息与干燥工艺参数，实现准确且数据高效的颜色轨迹预测。

Result: 在未见干燥条件下，模型在饼干干燥中达到2.12的RMSE，苹果干燥中达到1.29的RMSE，相比基线模型误差降低超过90%。

Conclusion: 该方法在准确性、鲁棒性和广泛适用性方面表现出色，为食品干燥过程中的颜色质量监控提供了有效的解决方案。

Abstract: Food drying is widely used to reduce moisture content, ensure safety, and extend shelf life. Color evolution of food samples is an important indicator of product quality in food drying. Although existing studies have examined color changes under different drying conditions, current approaches primarily rely on low-dimensional color features and cannot fully capture the complex, dynamic color trajectories of food samples. Moreover, existing modeling approaches lack the ability to generalize to unseen process conditions. To address these limitations, we develop a novel multi-modal color-trajectory prediction method that integrates high-dimensional temporal color information with drying process parameters to enable accurate and data-efficient color trajectory prediction. Under unseen drying conditions, the model attains RMSEs of 2.12 for cookie drying and 1.29 for apple drying, reducing errors by over 90% compared with baseline models. These experimental results demonstrate the model's superior accuracy, robustness, and broad applicability.

</details>


### [20] [The MICCAI Federated Tumor Segmentation (FeTS) Challenge 2024: Efficient and Robust Aggregation Methods for Federated Learning](https://arxiv.org/abs/2512.06206)
*Akis Linardos,Sarthak Pati,Ujjwal Baid,Brandon Edwards,Patrick Foley,Kevin Ta,Verena Chung,Micah Sheller,Muhammad Irfan Khan,Mojtaba Jafaritadi,Elina Kontio,Suleiman Khan,Leon Mächler,Ivan Ezhov,Suprosanna Shit,Johannes C. Paetzold,Gustav Grimberg,Manuel A. Nickel,David Naccache,Vasilis Siomos,Jonathan Passerat-Palmbach,Giacomo Tarroni,Daewoon Kim,Leonard L. Klausmann,Prashant Shah,Bjoern Menze,Dimitrios Makris,Spyridon Bakas*

Main category: cs.CV

TL;DR: MICCAI FeTS 2024挑战赛评估了联邦学习在胶质瘤亚区分割中的应用，PID控制器方法在分割性能和通信效率上均表现最佳，超越了以往方法。


<details>
  <summary>Details</summary>
Motivation: 该挑战赛旨在评估联邦学习在多机构胶质瘤MRI分割中的新权重聚合方法，以提高鲁棒性和效率，推动医学影像联邦学习的发展。

Method: 使用标准化的联邦学习设置和多机构数据集（BraTS基准），包含1251个训练案例、219个验证案例和570个隐藏测试案例。评估了六支参赛团队，采用累积评分系统综合考虑分割性能（DSC和HD95）和通信效率（收敛分数）。

Result: 基于PID控制器的方法获得最高排名，ET、TC、WT的平均DSC分别为0.733、0.761、0.751，HD95分别为33.922mm、33.623mm、32.309mm，通信效率最高（收敛分数0.764），超越了以往挑战赛的最佳方法。

Conclusion: PID控制器是稳定和优化联邦学习中权重聚合的有效机制，该挑战赛推动了医学影像联邦学习的发展，代码已开源。

Abstract: We present the design and results of the MICCAI Federated Tumor Segmentation (FeTS) Challenge 2024, which focuses on federated learning (FL) for glioma sub-region segmentation in multi-parametric MRI and evaluates new weight aggregation methods aimed at improving robustness and efficiency. Six participating teams were evaluated using a standardized FL setup and a multi-institutional dataset derived from the BraTS glioma benchmark, consisting of 1,251 training cases, 219 validation cases, and 570 hidden test cases with segmentations for enhancing tumor (ET), tumor core (TC), and whole tumor (WT). Teams were ranked using a cumulative scoring system that considered both segmentation performance, measured by Dice Similarity Coefficient (DSC) and the 95th percentile Hausdorff Distance (HD95), and communication efficiency assessed through the convergence score. A PID-controller-based method achieved the top overall ranking, obtaining mean DSC values of 0.733, 0.761, and 0.751 for ET, TC, and WT, respectively, with corresponding HD95 values of 33.922 mm, 33.623 mm, and 32.309 mm, while also demonstrating the highest communication efficiency with a convergence score of 0.764. These findings advance the state of federated learning for medical imaging, surpassing top-performing methods from previous challenge iterations and highlighting PID controllers as effective mechanisms for stabilizing and optimizing weight aggregation in FL. The challenge code is available at https://github.com/FeTS-AI/Challenge.

</details>


### [21] [Revisiting SVD and Wavelet Difference Reduction for Lossy Image Compression: A Reproducibility Study](https://arxiv.org/abs/2512.06221)
*Alena Makarova*

Main category: cs.CV

TL;DR: 该研究对结合SVD和WDR的图像压缩方法进行了独立复现，发现其性能并未如原论文声称的那样优于JPEG2000和WDR


<details>
  <summary>Details</summary>
Motivation: 验证原论文声称的SVD+WDR图像压缩技术优于JPEG2000和WDR的结论，并评估该方法的可复现性

Method: 重新实现SVD+WDR方法，填补原论文缺失的实现细节，复现原始实验，并在新图像上进行额外测试，使用PSNR和SSIM作为评估指标

Result: 与原始声称相反，SVD+WDR在PSNR方面通常不优于JPEG2000或WDR，仅在SSIM方面部分优于JPEG2000；研究还发现原论文描述存在模糊之处（如量化和阈值初始化）

Conclusion: 原论文的SVD+WDR方法并未如声称那样优于现有技术，研究强调了论文描述不清晰对可复现性和性能报告的显著影响

Abstract: This work presents an independent reproducibility study of a lossy image compression technique that integrates singular value decomposition (SVD) and wavelet difference reduction (WDR). The original paper claims that combining SVD and WDR yields better visual quality and higher compression ratios than JPEG2000 and standalone WDR. I re-implemented the proposed method, carefully examined missing implementation details, and replicated the original experiments as closely as possible. I then conducted additional experiments on new images and evaluated performance using PSNR and SSIM. In contrast to the original claims, my results indicate that the SVD+WDR technique generally does not surpass JPEG2000 or WDR in terms of PSNR, and only partially improves SSIM relative to JPEG2000. The study highlights ambiguities in the original description (e.g., quantization and threshold initialization) and illustrates how such gaps can significantly impact reproducibility and reported performance.

</details>


### [22] [Opinion: Learning Intuitive Physics May Require More than Visual Data](https://arxiv.org/abs/2512.06232)
*Ellen Su,Solim Legris,Todd M. Gureckis,Mengye Ren*

Main category: cs.CV

TL;DR: 研究探索数据分布而非数据量是否对学习直觉物理原理更重要，使用发展心理学真实的儿童视角视频数据集训练V-JEPA模型，发现即使数据量仅为SOTA模型的0.01%，在IntPhys2基准测试中性能提升有限。


<details>
  <summary>Details</summary>
Motivation: 人类通过丰富的内部模型和直觉物理理解来导航世界，而尽管深度学习模型在大量互联网视频数据上训练，在直觉物理基准测试上仍达不到人类水平。本研究旨在探究数据分布（而非数据量）是否是学习这些物理原理的关键。

Method: 使用SAYCam数据集（发展心理学真实的、以自我为中心的儿童日常视觉体验视频）预训练Video Joint Embedding Predictive Architecture (V-JEPA)模型。该数据集仅占SOTA模型训练数据量的0.01%。

Result: 在IntPhys2基准测试中，使用这种发展心理学真实数据集训练并未带来显著的性能提升。结果表明，仅在当前架构上使用发展心理学真实数据集训练不足以学习支持直觉物理的表征。

Conclusion: 仅改变视觉数据量和分布可能不足以构建具有人工直觉物理的系统。需要更深入的方法来使AI系统获得类似人类的物理直觉理解能力。

Abstract: Humans expertly navigate the world by building rich internal models founded on an intuitive understanding of physics. Meanwhile, despite training on vast quantities of internet video data, state-of-the-art deep learning models still fall short of human-level performance on intuitive physics benchmarks. This work investigates whether data distribution, rather than volume, is the key to learning these principles. We pretrain a Video Joint Embedding Predictive Architecture (V-JEPA) model on SAYCam, a developmentally realistic, egocentric video dataset partially capturing three children's everyday visual experiences. We find that training on this dataset, which represents 0.01% of the data volume used to train SOTA models, does not lead to significant performance improvements on the IntPhys2 benchmark. Our results suggest that merely training on a developmentally realistic dataset is insufficient for current architectures to learn representations that support intuitive physics. We conclude that varying visual data volume and distribution alone may not be sufficient for building systems with artificial intuitive physics.

</details>


### [23] [Language-driven Fine-grained Retrieval](https://arxiv.org/abs/2512.06255)
*Shijie Wang,Xin Yu,Yadan Luo,Zijian Wang,Pengfei Zhang,Zi Huang*

Main category: cs.CV

TL;DR: LaFG是一个语言驱动的细粒度图像检索框架，使用大语言模型和视觉语言模型将类别名称转换为属性级监督，以解决传统方法在未见类别上泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有细粒度图像检索方法使用基于类别名称的稀疏one-hot标签作为监督，虽然对已见类别有效，但忽略了类别名称中丰富的语义信息，无法建模跨类别细节的可比性，限制了模型对未见类别的泛化能力。

Method: LaFG框架：1）使用LLM将类别名称生成为详细的属性导向描述；2）利用冻结的VLM将这些描述投影到视觉对齐空间，聚类形成数据集范围的属性词汇表；3）通过全局提示模板选择类别相关属性，聚合成类别特定的语言原型；4）用这些原型监督检索模型。

Result: 论文摘要未提供具体实验结果，但方法旨在通过语言驱动的属性级监督提升细粒度图像检索在未见类别上的泛化能力。

Conclusion: LaFG通过将类别名称转换为丰富的属性级监督，利用语言模型和视觉语言模型的协同作用，能够更好地建模跨类别细节的可比性，从而提升细粒度图像检索对未见类别的泛化性能。

Abstract: Existing fine-grained image retrieval (FGIR) methods learn discriminative embeddings by adopting semantically sparse one-hot labels derived from category names as supervision. While effective on seen classes, such supervision overlooks the rich semantics encoded in category names, hindering the modeling of comparability among cross-category details and, in turn, limiting generalization to unseen categories. To tackle this, we introduce LaFG, a Language-driven framework for Fine-Grained Retrieval that converts class names into attribute-level supervision using large language models (LLMs) and vision-language models (VLMs). Treating each name as a semantic anchor, LaFG prompts an LLM to generate detailed, attribute-oriented descriptions. To mitigate attribute omission in these descriptions, it leverages a frozen VLM to project them into a vision-aligned space, clustering them into a dataset-wide attribute vocabulary while harvesting complementary attributes from related categories. Leveraging this vocabulary, a global prompt template selects category-relevant attributes, which are aggregated into category-specific linguistic prototypes. These prototypes supervise the retrieval model to steer

</details>


### [24] [Knowing the Answer Isn't Enough: Fixing Reasoning Path Failures in LVLMs](https://arxiv.org/abs/2512.06258)
*Chaoyang Wang,Yangfan He,Yiyang Zhou,Yixuan Wang,Jiaqi Liu,Peng Xia,Zhengzhong Tu,Mohit Bansal,Huaxiu Yao*

Main category: cs.CV

TL;DR: 论文揭示大型视觉语言模型存在路径选择偏差问题：模型即使知道正确答案，也常通过错误推理路径得出结果，核心是推理搜索空间中的路径选择偏差而非知识缺乏。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在一个关键但未被充分探索的缺陷：即使模型知道正确答案，也经常通过错误的推理路径得出结果。核心问题不是知识缺乏，而是在广阔的推理搜索空间中的路径选择偏差。

Method: 提出PSO（路径选择优化）两阶段后训练框架：第一阶段使用GRPO（组相对策略优化）配合模板和答案奖励来培养结构化逐步推理；第二阶段进行在线偏好优化，模型从GRPO生成数据中采样推理路径，自我评估并朝向优选轨迹对齐。错误或次优路径存储在负向回放记忆中作为硬负例，定期回顾以防止重复错误并促进持续推理改进。

Result: 大量实验表明PSO有效修剪无效推理路径，显著提升推理准确性（平均提升7.4%），并产生更稳定一致的思维链。

Conclusion: PSO框架成功解决了LVLMs中的路径选择偏差问题，通过两阶段优化显著提升了模型的推理性能和稳定性，为大型视觉语言模型的可靠性改进提供了有效方法。

Abstract: We reveal a critical yet underexplored flaw in Large Vision-Language Models (LVLMs): even when these models know the correct answer, they frequently arrive there through incorrect reasoning paths. The core issue is not a lack of knowledge, but a path selection bias within the vast reasoning search space. Although LVLMs are often capable of sampling correct solution trajectories, they disproportionately favor unstable or logically inconsistent ones, leading to erratic and unreliable outcomes. The substantial disparity between Pass@K (with large K) and Pass@1 across numerous models provides compelling evidence that such failures primarily stem from misreasoning rather than ignorance. To systematically investigate and address this issue, we propose PSO (Path-Select Optimization), a two-stage post-training framework designed to enhance both the reasoning performance and stability of existing LVLMs. In the first stage, we employ Group Relative Policy Optimization (GRPO) with template and answer-based rewards to cultivate structured, step-by-step reasoning. In the second stage, we conduct online preference optimization, where the model samples reasoning paths from GRPO-generated data, self-evaluates them, and aligns itself toward the preferred trajectories. Incorrect or suboptimal paths are concurrently stored in a Negative Replay Memory (NRM) as hard negatives, which are periodically revisited to prevent the model from repeating prior mistakes and to facilitate continual reasoning refinement. Extensive experiments show that PSO effectively prunes invalid reasoning paths, substantially enhances reasoning accuracy (with 7.4% improvements on average), and yields more stable and consistent chains of thought. Our code will be available at https://github.com/aiming-lab/PSO.

</details>


### [25] [TriaGS: Differentiable Triangulation-Guided Geometric Consistency for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06269)
*Quan Tran,Tuan Dang*

Main category: cs.CV

TL;DR: 该论文提出了一种通过约束多视角三角测量来增强3D高斯重建几何一致性的新方法，解决了现有方法因仅依赖光度损失导致的浮游伪影和几何不一致问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术虽然能实时合成新视角并渲染逼真图像，但仅依赖光度损失进行重建会导致几何不一致性，产生"浮游"伪影和无结构几何，难以提取高质量表面。

Method: 提出一种通过约束多视角三角测量来强制全局几何一致性的方法。利用多个估计视角达成物理世界3D表示的共识，通过惩罚渲染3D点与自监督方式从相邻视角束重新三角化的鲁棒共识点之间的偏差来优化过程。

Result: 在多个数据集上验证了方法的有效性，取得了最先进的结果。在DTU数据集上获得了0.50毫米的平均倒角距离，优于同类显式方法。

Conclusion: 该方法通过强制全局几何一致性显著改善了3D高斯重建质量，解决了浮游伪影和几何不一致问题，代码将开源以确保可复现性。

Abstract: 3D Gaussian Splatting is crucial for real-time novel view synthesis due to its efficiency and ability to render photorealistic images. However, building a 3D Gaussian is guided solely by photometric loss, which can result in inconsistencies in reconstruction. This under-constrained process often results in "floater" artifacts and unstructured geometry, preventing the extraction of high-fidelity surfaces. To address this issue, our paper introduces a novel method that improves reconstruction by enforcing global geometry consistency through constrained multi-view triangulation. Our approach aims to achieve a consensus on 3D representation in the physical world by utilizing various estimated views. We optimize this process by penalizing the deviation of a rendered 3D point from a robust consensus point, which is re-triangulated from a bundle of neighboring views in a self-supervised fashion. We demonstrate the effectiveness of our method across multiple datasets, achieving state-of-the-art results. On the DTU dataset, our method attains a mean Chamfer Distance of 0.50 mm, outperforming comparable explicit methods. We will make our code open-source to facilitate community validation and ensure reproducibility.

</details>


### [26] [FacePhys: State of the Heart Learning](https://arxiv.org/abs/2512.06275)
*Kegang Wang,Jiankai Tang,Yuntao Wang,Xin Liu,Yuxuan Fan,Jiatong Ji,Yuanchun Shi,Daniel McDuff*

Main category: cs.CV

TL;DR: FacePhys：基于时空状态空间对偶性的内存高效rPPG算法，解决了模型可扩展性、跨数据集泛化和实时操作的三难问题，在误差减少49%的同时实现3.6MB内存占用和9.46ms每帧延迟。


<details>
  <summary>Details</summary>
Motivation: 基于摄像头的生命体征测量（特别是远程光电容积描记术rPPG）为舒适、普适的健康监测提供了机会，但实际部署受到前端设备计算限制和数据压缩传输导致信号质量下降的制约。

Method: 提出FacePhys算法，基于时空状态空间对偶性构建，利用可转移的心脏状态捕获视频帧间的细微周期性变化，同时保持最小计算开销，支持长视频序列训练和低延迟推理。

Result: FacePhys实现了49%的误差减少，达到新的最先进水平；内存占用仅3.6MB，每帧延迟9.46ms，比现有方法提升83%到99%；支持实际部署中的可靠实时性能。

Conclusion: FacePhys通过创新的时空状态空间对偶性方法，成功解决了rPPG技术在实际部署中的计算约束和精度下降问题，为实时健康监测应用提供了高效可行的解决方案。

Abstract: Vital sign measurement using cameras presents opportunities for comfortable, ubiquitous health monitoring. Remote photoplethysmography (rPPG), a foundational technology, enables cardiac measurement through minute changes in light reflected from the skin. However, practical deployment is limited by the computational constraints of performing analysis on front-end devices and the accuracy degradation of transmitting data through compressive channels that reduce signal quality. We propose a memory efficient rPPG algorithm - \emph{FacePhys} - built on temporal-spatial state space duality, which resolves the trilemma of model scalability, cross-dataset generalization, and real-time operation. Leveraging a transferable heart state, FacePhys captures subtle periodic variations across video frames while maintaining a minimal computational overhead, enabling training on extended video sequences and supporting low-latency inference. FacePhys establishes a new state-of-the-art, with a substantial 49\% reduction in error. Our solution enables real-time inference with a memory footprint of 3.6 MB and per-frame latency of 9.46 ms -- surpassing existing methods by 83\% to 99\%. These results translate into reliable real-time performance in practical deployments, and a live demo is available at https://www.facephys.com/.

</details>


### [27] [RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension](https://arxiv.org/abs/2512.06276)
*Tianyi Gao,Hao Li,Han Fang,Xin Wei,Xiaodong Dong,Hongbo Sun,Ye Yuan,Zhongjiang He,Jinglin Xu,Jingmin Xin,Hao Sun*

Main category: cs.CV

TL;DR: RefBench-PRO：一个将指代表达式理解分解为感知和推理两个维度的综合基准，包含六个渐进挑战性任务，并提出了Ref-R1强化学习方案来提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有REC基准主要评估感知能力，缺乏可解释的评分机制，无法揭示多模态大语言模型在不同认知能力上的接地能力。需要开发一个能够分解指代表达式核心维度的综合基准。

Method: 1. 引入RefBench-PRO基准，将指代表达式分解为感知和推理两个核心维度，进一步细分为六个渐进挑战性任务（属性、位置、交互、常识、关系和拒绝）。2. 开发全自动数据生成管道，为这六个子维度生成多样化的指代表达式。3. 提出Ref-R1强化学习方案，结合基于动态IoU的GRPO来提升复杂推理条件下的定位精度。

Result: 大量实验表明，RefBench-PRO能够对MLLM在指代表达式理解上进行可解释的评估，在感知和推理方面都提出了更大的挑战。该基准为REC建立了更强的基线。

Conclusion: RefBench-PRO是一个全面的REC基准，通过分解指代表达式的认知维度实现了可解释的评估，同时提出的Ref-R1学习方案提升了定位精度，为多模态大语言模型的指代表达式理解能力评估提供了更好的工具。

Abstract: Referring Expression Comprehension (REC) is a vision-language task that localizes a specific image region based on a textual description. Existing REC benchmarks primarily evaluate perceptual capabilities and lack interpretable scoring mechanisms, which cannot reveal the grounding capability of Multi-modal Large Language Model (MLLM) across different cognitive abilities. To address this limitation, we introduce RefBench-PRO, a comprehensive REC benchmark, which decomposes referring expressions into two core dimensions, i.e., perception and reasoning, and further subdivides them into six progressively challenging tasks, such as attribute, position, interaction, commonsense, relation and reject. We also develop a fully automated data-generation pipeline that produces diverse referring expressions across these six sub-dimensions. Furthermore, We propose Ref-R1, an RL-based learning scheme, which incorporates Dynamic IoU-based GRPO to improve localization accuracy under increasingly complex reasoning conditions, establishing a stronger baseline for REC. Extensive experiments demonstrate that our RefBench-PRO enables interpretable evaluation of MLLM on referring expression comprehension, presenting greater challenges in both perception and reasoning.

</details>


### [28] [A Sleep Monitoring System Based on Audio, Video and Depth Information](https://arxiv.org/abs/2512.06282)
*Lyn Chao-ling Chen,Kuan-Wen Chen,Yi-Ping Hung*

Main category: cs.CV

TL;DR: 开发基于事件方法的非侵入式睡眠监测系统，通过红外深度传感器、RGB摄像头和四麦克风阵列检测运动、开关灯和噪音三类事件，用于家庭环境下的睡眠障碍定量评估。


<details>
  <summary>Details</summary>
Motivation: 开发非侵入式睡眠监测系统，用于家庭环境下睡眠障碍的定量评估，解决传统监测方法侵入性强、不便在家庭环境中使用的问题。

Method: 使用红外深度传感器、RGB摄像头和四麦克风阵列设备，在几乎无光源环境中监测睡眠。建立深度信号背景模型检测运动幅度，建立彩色图像背景模型检测光照变化，采用事件检测算法从三类传感器处理数据中检测事件发生。

Result: 系统在睡眠条件下进行测试，实验结果验证了系统的可靠性，能够有效检测运动事件、开关灯事件和噪音事件。

Conclusion: 提出的基于事件方法的非侵入式睡眠监测系统能够可靠地检测睡眠障碍相关事件，为家庭环境下的睡眠质量评估提供了有效的技术方案。

Abstract: For quantitative evaluation of sleep disturbances, a noninvasive monitoring system is developed by introducing an event-based method. We observe sleeping in home context and classify the sleep disturbances into three types of events: motion events, light-on/off events and noise events. A device with an infrared depth sensor, a RGB camera, and a four-microphone array is used in sleep monitoring in an environment with barely light sources. One background model is established in depth signals for measuring magnitude of movements. Because depth signals cannot observe lighting changes, another background model is established in color images for measuring magnitude of lighting effects. An event detection algorithm is used to detect occurrences of events from the processed data of the three types of sensors. The system was tested in sleep condition and the experiment result validates the system reliability.

</details>


### [29] [ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models](https://arxiv.org/abs/2512.06328)
*Jiahao Li,Yusheng Luo,Yunzhong Lou,Xiangdong Zhou*

Main category: cs.CV

TL;DR: ReCAD是一个强化学习框架，通过引导预训练大模型生成精确的参数化CAD模型，在文本到CAD和图像到CAD任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖监督微调注入知识，对可编辑性支持有限，且未能充分利用预训练大模型的强大生成先验。需要一种能够利用大模型内在生成能力，从多模态输入生成精确参数化CAD模型的方法。

Method: 1) 微调视觉语言模型，使其具备基本CAD模型生成能力，将CAD脚本重写为参数化代码用于生成准确的文本描述进行监督；2) 提出新颖的强化学习策略，将参数化代码作为指导增强模型对挑战性问题的推理；3) 采用分层基元学习过程，在统一奖励函数下逐步教授结构化和组合技能。

Result: 在文本到CAD和图像到CAD任务中均达到最先进水平，显著提高了几何精度。在图像到CAD任务中，将平均Chamfer距离从73.47降至29.61（分布内）和从272.06降至80.23（分布外），大幅超越现有基线。

Conclusion: ReCAD框架成功利用预训练大模型的生成能力，通过强化学习引导生成精确的参数化CAD模型，在保持几何精度和语义保真度的同时，支持复杂CAD操作，为多模态CAD生成提供了有效解决方案。

Abstract: We present ReCAD, a reinforcement learning (RL) framework that bootstraps pretrained large models (PLMs) to generate precise parametric computer-aided design (CAD) models from multimodal inputs by leveraging their inherent generative capabilities. With just access to simple functional interfaces (e.g., point coordinates), our approach enables the emergence of complex CAD operations (e.g., pattern replication and mirror). This stands in contrast to previous methods, which typically rely on knowledge injected through supervised fine-tuning (SFT), offer limited support for editability, and fail to exploit the strong generative priors of PLMs. Specifically, the ReCAD framework begins by fine-tuning vision-language models (VLMs) to equip them with basic CAD model generation capabilities, where we rewrite CAD scripts into parameterized code that is leveraged to generate accurate textual descriptions for supervision. Then, we propose a novel RL strategy that incorporates parameterized code as guidance to enhance the model's reasoning on challenging questions. Furthermore, we employ a hierarchical primitive learning process to progressively teach structured and compositional skills under a unified reward function that ensures both geometric accuracy and semantic fidelity. ReCAD sets a new state-of-the-art in both text-to-CAD and image-to-CAD tasks, significantly improving geometric accuracy across in-distribution and out-of-distribution settings. In the image-to-CAD task, for instance, it reduces the mean Chamfer Distance from 73.47 to 29.61 (in-distribution) and from 272.06 to 80.23 (out-of-distribution), outperforming existing baselines by a substantial margin.

</details>


### [30] [S2WMamba: A Spectral-Spatial Wavelet Mamba for Pansharpening](https://arxiv.org/abs/2512.06330)
*Haoyu Zhang,Junhan Luo,Yugang Cao,Siran Peng,Jie Huang,Liangjian-Deng*

Main category: cs.CV

TL;DR: S2WMamba：使用2D/1D小波变换和Mamba跨模态交互的遥感图像融合方法，通过频域解耦提升空间细节与光谱保真度


<details>
  <summary>Details</summary>
Motivation: 全色锐化中同时处理PAN和MS图像容易导致空间细节与光谱保真度相互纠缠，现有方法难以有效分离频域信息，导致融合质量受限

Method: 1) 对PAN图像应用2D Haar DWT定位空间边缘和纹理；2) 对每个像素的光谱应用通道级1D Haar DWT分离高低频成分；3) 构建光谱分支（注入空间细节）和空间分支（利用光谱信息）；4) 基于Mamba的跨调制实现线性复杂度的长程依赖建模；5) 多尺度动态门自适应融合分支输出

Result: 在WV3、GF2和QB数据集上超越FusionMamba、CANNet、U2Net、ARConv等基线方法，PSNR提升最高0.23dB，在WV3全分辨率上达到HQNR 0.956

Conclusion: 通过显式频域解耦和轻量级跨模态交互，S2WMamba有效解决了全色锐化中的空间-光谱纠缠问题，在多个数据集上取得了优越的融合性能

Abstract: Pansharpening fuses a high-resolution PAN image with a low-resolution multispectral (LRMS) image to produce an HRMS image. A key difficulty is that jointly processing PAN and MS often entangles spatial detail with spectral fidelity. We propose S2WMamba, which explicitly disentangles frequency information and then performs lightweight cross-modal interaction. Concretely, a 2D Haar DWT is applied to PAN to localize spatial edges and textures, while a channel-wise 1D Haar DWT treats each pixel's spectrum as a 1D signal to separate low/high-frequency components and limit spectral distortion. The resulting Spectral branch injects wavelet-extracted spatial details into MS features, and the Spatial branch refines PAN features using spectra from the 1D pyramid; the two branches exchange information through Mamba-based cross-modulation that models long-range dependencies with linear complexity. A multi-scale dynamic gate (multiplicative + additive) then adaptively fuses branch outputs.On WV3, GF2, and QB, S2WMamba matches or surpasses recent strong baselines (FusionMamba, CANNet, U2Net, ARConv), improving PSNR by up to 0.23 dB and reaching HQNR 0.956 on full-resolution WV3. Ablations justify the choice of 2D/1D DWT placement, parallel dual branches, and the fusion gate. Our code is available at https://github.com/KagUYa66/S2WMamba.

</details>


### [31] [Beyond Hallucinations: A Multimodal-Guided Task-Aware Generative Image Compression for Ultra-Low Bitrate](https://arxiv.org/abs/2512.06344)
*Kaile Wang,Lijun He,Haisheng Fu,Haixia Bi,Fan Li*

Main category: cs.CV

TL;DR: MTGC框架通过多模态引导和任务感知语义压缩，在超低比特率下提升生成式图像压缩的语义一致性，同时改善感知质量和像素级保真度。


<details>
  <summary>Details</summary>
Motivation: 生成式图像压缩在超低比特率下存在语义偏差问题，限制了其在6G语义通信场景中的可靠部署。需要解决生成幻觉导致的语义不一致问题。

Method: 提出MTGC框架：1) 集成三种引导模态：文本描述、高压缩图像和语义伪词；2) 设计任务感知语义压缩模块提取任务相关语义；3) 采用多模态引导扩散解码器，通过双路径协作机制将三种引导注入扩散过程。

Result: 实验表明MTGC显著提升语义一致性（如DIV2K数据集上DISTS下降10.59%），同时在超低比特率下实现感知质量和像素级保真度的显著提升。

Conclusion: MTGC通过多模态引导和任务感知语义压缩，有效解决了超低比特率下生成式图像压缩的语义偏差问题，为6G语义通信提供了可靠解决方案。

Abstract: Generative image compression has recently shown impressive perceptual quality, but often suffers from semantic deviations caused by generative hallucinations at ultra-low bitrate (bpp < 0.05), limiting its reliable deployment in bandwidth-constrained 6G semantic communication scenarios. In this work, we reassess the positioning and role of of multimodal guidance, and propose a Multimodal-Guided Task-Aware Generative Image Compression (MTGC) framework. Specifically, MTGC integrates three guidance modalities to enhance semantic consistency: a concise but robust text caption for global semantics, a highly compressed image (HCI) retaining low-level visual information, and Semantic Pseudo-Words (SPWs) for fine-grained task-relevant semantics. The SPWs are generated by our designed Task-Aware Semantic Compression Module (TASCM), which operates in a task-oriented manner to drive the multi-head self-attention mechanism to focus on and extract semantics relevant to the generation task while filtering out redundancy. Subsequently, to facilitate the synergistic guidance of these modalities, we design a Multimodal-Guided Diffusion Decoder (MGDD) employing a dual-path cooperative guidance mechanism that synergizes cross-attention and ControlNet additive residuals to precisely inject these three guidance into the diffusion process, and leverages the diffusion model's powerful generative priors to reconstruct the image. Extensive experiments demonstrate that MTGC consistently improves semantic consistency (e.g., DISTS drops by 10.59% on the DIV2K dataset) while also achieving remarkable gains in perceptual quality and pixel-level fidelity at ultra-low bitrate.

</details>


### [32] [CLUENet: Cluster Attention Makes Neural Networks Have Eyes](https://arxiv.org/abs/2512.06345)
*Xiangshuai Song,Jun-Jie Huang,Tianrui Liu,Ke Liang,Chang Tang*

Main category: cs.CV

TL;DR: CLUENet是一种基于聚类范式的透明深度架构，通过全局软聚合硬分配、温度缩放余弦注意力、门控残差连接、硬共享特征调度和改进的聚类池化策略，在视觉语义理解任务中实现了准确性、效率和可解释性的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统卷积和注意力模型存在刚性感受野和复杂架构的问题，限制了其对不规则空间模式的建模能力，并且可解释性较差。聚类范式虽然提供良好的可解释性和灵活的语义建模，但存在准确性有限、效率低下和训练中梯度消失等问题。

Method: 提出了CLUENet（CLUster attEntion Network），包含三个关键创新：1）全局软聚合硬分配机制，结合温度缩放余弦注意力和门控残差连接增强局部建模；2）块间硬共享特征调度；3）改进的聚类池化策略。

Result: 在CIFAR-100和Mini-ImageNet数据集上的实验表明，CLUENet超越了现有的聚类方法和主流视觉模型，在分类性能和视觉可解释性方面都有显著提升。

Conclusion: CLUENet为视觉语义理解提供了一种透明深度架构，在准确性、效率和透明度之间实现了有吸引力的平衡，解决了传统模型在可解释性和不规则模式建模方面的局限性。

Abstract: Despite the success of convolution- and attention-based models in vision tasks, their rigid receptive fields and complex architectures limit their ability to model irregular spatial patterns and hinder interpretability, therefore posing challenges for tasks requiring high model transparency. Clustering paradigms offer promising interpretability and flexible semantic modeling, but suffer from limited accuracy, low efficiency, and gradient vanishing during training. To address these issues, we propose CLUster attEntion Network (CLUENet), an transparent deep architecture for visual semantic understanding. We propose three key innovations include (i) a Global Soft Aggregation and Hard Assignment with a Temperature-Scaled Cosin Attention and gated residual connections for enhanced local modeling, (ii) inter-block Hard and Shared Feature Dispatching, and (iii) an improved cluster pooling strategy. These enhancements significantly improve both classification performance and visual interpretability. Experiments on CIFAR-100 and Mini-ImageNet demonstrate that CLUENet outperforms existing clustering methods and mainstream visual models, offering a compelling balance of accuracy, efficiency, and transparency.

</details>


### [33] [TreeQ: Pushing the Quantization Boundary of Diffusion Transformer via Tree-Structured Mixed-Precision Search](https://arxiv.org/abs/2512.06353)
*Kaicheng Yang,Kaisen Yang,Baiting Wu,Xun Zhang,Qianrui Yang,Haotong Qin,He Zhang,Yulun Zhang*

Main category: cs.CV

TL;DR: TreeQ是一个统一的DiT量化框架，通过树结构搜索、环境噪声引导和通用Monarch分支解决DiT量化中的关键挑战，首次在DiT模型上实现接近无损的4位PTQ性能。


<details>
  <summary>Details</summary>
Motivation: DiT模型在图像生成方面表现出色，但实际部署面临高计算和内存需求。混合精度量化在U-Net上取得成功，但在DiT架构中的应用有限且未充分探索，需要专门针对DiT的量化解决方案。

Method: 提出TreeQ框架：1) 树结构搜索(TSS)利用DiT的线性特性在O(n)时间内遍历解空间；2) 环境噪声引导(ENG)统一PTQ和QAT优化目标；3) 通用Monarch分支(GMB)防止超低位量化中的信息瓶颈。

Result: 在DiT-XL/2模型上，W3A3和W4A4 PTQ/PEFT设置下达到最先进性能，首次实现DiT模型上接近无损的4位PTQ性能。

Conclusion: TreeQ为DiT量化提供了有效的统一框架，解决了搜索效率、目标对齐和信息瓶颈等关键问题，显著降低了DiT的部署成本。

Abstract: Diffusion Transformers (DiTs) have emerged as a highly scalable and effective backbone for image generation, outperforming U-Net architectures in both scalability and performance. However, their real-world deployment remains challenging due to high computational and memory demands. Mixed-Precision Quantization (MPQ), designed to push the limits of quantization, has demonstrated remarkable success in advancing U-Net quantization to sub-4bit settings while significantly reducing computational and memory overhead. Nevertheless, its application to DiT architectures remains limited and underexplored. In this work, we propose TreeQ, a unified framework addressing key challenges in DiT quantization. First, to tackle inefficient search and proxy misalignment, we introduce Tree Structured Search (TSS). This DiT-specific approach leverages the architecture's linear properties to traverse the solution space in O(n) time while improving objective accuracy through comparison-based pruning. Second, to unify optimization objectives, we propose Environmental Noise Guidance (ENG), which aligns Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT) configurations using a single hyperparameter. Third, to mitigate information bottlenecks in ultra-low-bit regimes, we design the General Monarch Branch (GMB). This structured sparse branch prevents irreversible information loss, enabling finer detail generation. Through extensive experiments, our TreeQ framework demonstrates state-of-the-art performance on DiT-XL/2 under W3A3 and W4A4 PTQ/PEFT settings. Notably, our work is the first to achieve near-lossless 4-bit PTQ performance on DiT models. The code and models will be available at https://github.com/racoonykc/TreeQ

</details>


### [34] [Rectifying Latent Space for Generative Single-Image Reflection Removal](https://arxiv.org/abs/2512.06358)
*Mingjia Li,Jin Hu,Hainuo Wang,Qiming Hu,Jiarui Wang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 该研究将潜在扩散模型改造用于单图像反射去除，通过反射等变VAE、可学习任务特定文本嵌入和深度引导早期分支采样三个组件，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 单图像反射去除是一个高度不适定问题，现有方法难以推理被污染区域的组成，导致在真实场景中恢复和泛化能力不足。研究指出关键问题在于语义编码器的潜在空间缺乏解释复合图像作为其组成层线性叠加的内在结构。

Method: 1) 反射等变VAE：将潜在空间与反射形成的线性物理对齐；2) 可学习任务特定文本嵌入：提供精确指导，绕过模糊语言描述；3) 深度引导早期分支采样策略：利用生成随机性获得有希望的结果。

Result: 模型在多个基准测试中达到新的最先进性能，并在具有挑战性的真实世界案例中表现出良好的泛化能力。

Conclusion: 通过重构编辑目的的潜在扩散模型，使其能够有效感知和处理高度模糊的分层图像输入，解决了单图像反射去除的关键挑战，实现了高质量的恢复效果。

Abstract: Single-image reflection removal is a highly ill-posed problem, where existing methods struggle to reason about the composition of corrupted regions, causing them to fail at recovery and generalization in the wild. This work reframes an editing-purpose latent diffusion model to effectively perceive and process highly ambiguous, layered image inputs, yielding high-quality outputs. We argue that the challenge of this conversion stems from a critical yet overlooked issue, i.e., the latent space of semantic encoders lacks the inherent structure to interpret a composite image as a linear superposition of its constituent layers. Our approach is built on three synergistic components, including a reflection-equivariant VAE that aligns the latent space with the linear physics of reflection formation, a learnable task-specific text embedding for precise guidance that bypasses ambiguous language, and a depth-guided early-branching sampling strategy to harness generative stochasticity for promising results. Extensive experiments reveal that our model achieves new SOTA performance on multiple benchmarks and generalizes well to challenging real-world cases.

</details>


### [35] [Spoofing-aware Prompt Learning for Unified Physical-Digital Facial Attack Detection](https://arxiv.org/abs/2512.06363)
*Jiabao Guo,Yadian Wang,Hui Ma,Yuhao Fu,Ju Jia,Hui Liu,Shengeng Tang,Lechao Cheng,Yunfeng Diao,Ajian Liu*

Main category: cs.CV

TL;DR: 提出SPL-UAD框架，通过解耦物理和数字攻击的优化分支，实现统一的物理-数字攻击检测，解决了现有方法中优化方向冲突的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的人脸识别系统容易受到物理呈现攻击和数字伪造攻击的双重威胁，需要统一的物理-数字防御框架。现有方法使用CLIP加正则化约束，但在相同类别提示空间下，物理和数字攻击检测存在优化方向冲突的问题。

Method: 提出SPL-UAD框架：1）构建可学习的并行提示分支，通过自适应欺骗上下文提示生成，实现对每种攻击类型的独立优化控制；2）设计线索感知增强，利用双提示机制在数据上生成具有挑战性的样本挖掘任务，增强模型对未见攻击类型的鲁棒性。

Result: 在大型UniAttackDataPlus数据集上的广泛实验表明，该方法在统一攻击检测任务中取得了显著的性能提升。

Conclusion: SPL-UAD框架通过解耦物理和数字攻击的优化分支，有效解决了现有方法的局限性，实现了更全面的生物特征数据保护。

Abstract: Real-world face recognition systems are vulnerable to both physical presentation attacks (PAs) and digital forgery attacks (DFs). We aim to achieve comprehensive protection of biometric data by implementing a unified physical-digital defense framework with advanced detection. Existing approaches primarily employ CLIP with regularization constraints to enhance model generalization across both tasks. However, these methods suffer from conflicting optimization directions between physical and digital attack detection under same category prompt spaces. To overcome this limitation, we propose a Spoofing-aware Prompt Learning for Unified Attack Detection (SPL-UAD) framework, which decouples optimization branches for physical and digital attacks in the prompt space. Specifically, we construct a learnable parallel prompt branch enhanced with adaptive Spoofing Context Prompt Generation, enabling independent control of optimization for each attack type. Furthermore, we design a Cues-awareness Augmentation that leverages the dual-prompt mechanism to generate challenging sample mining tasks on data, significantly enhancing the model's robustness against unseen attack types. Extensive experiments on the large-scale UniAttackDataPlus dataset demonstrate that the proposed method achieves significant performance improvements in unified attack detection tasks.

</details>


### [36] [VG-Refiner: Towards Tool-Refined Referring Grounded Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2512.06373)
*Yuji Wang,Wenlong Liu,Jingxuan Niu,Haoji Zhang,Yansong Tang*

Main category: cs.CV

TL;DR: VG-Refiner框架通过两阶段思考-重新思考机制和细化奖励，解决工具集成视觉推理中不可靠工具输出导致的幻觉推理问题，在指代和定位任务中显著提升准确性和修正能力。


<details>
  <summary>Details</summary>
Motivation: 现有工具集成视觉推理范式主要关注通过强化学习整合各种视觉工具，但缺乏处理不可靠或错误工具输出的有效响应机制。这在指代和定位任务中尤为突出，不准确的检测工具预测经常误导模型产生幻觉推理。

Method: 提出VG-Refiner框架，引入两阶段思考-重新思考机制，使模型能够明确分析和响应工具反馈；同时设计细化奖励，鼓励对不良工具结果进行有效修正。还提出两个新指标并建立公平评估协议来系统衡量模型的细化能力。

Result: 使用少量任务特定数据增强VG-Refiner的细化能力，在指代和推理定位基准测试中实现了准确性和修正能力的显著提升，同时保持了预训练模型的通用能力。

Conclusion: VG-Refiner是首个面向工具细化的指代定位推理框架，通过有效的工具反馈响应机制解决了现有TiVR模型在处理不可靠工具输出时的局限性，为视觉推理系统提供了更可靠的解决方案。

Abstract: Tool-integrated visual reasoning (TiVR) has demonstrated great potential in enhancing multimodal problem-solving. However, existing TiVR paradigms mainly focus on integrating various visual tools through reinforcement learning, while neglecting to design effective response mechanisms for handling unreliable or erroneous tool outputs. This limitation is particularly pronounced in referring and grounding tasks, where inaccurate detection tool predictions often mislead TiVR models into generating hallucinated reasoning. To address this issue, we propose the VG-Refiner, the first framework aiming at the tool-refined referring grounded reasoning. Technically, we introduce a two-stage think-rethink mechanism that enables the model to explicitly analyze and respond to tool feedback, along with a refinement reward that encourages effective correction in response to poor tool results. In addition, we propose two new metrics and establish fair evaluation protocols to systematically measure the refinement ability of current models. We adopt a small amount of task-specific data to enhance the refinement capability of VG-Refiner, achieving a significant improvement in accuracy and correction ability on referring and reasoning grounding benchmarks while preserving the general capabilities of the pretrained model.

</details>


### [37] [Are AI-Generated Driving Videos Ready for Autonomous Driving? A Diagnostic Evaluation Framework](https://arxiv.org/abs/2512.06376)
*Xinhao Xiang,Abhijeet Rastogi,Jiawei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一个诊断框架来评估AI生成的驾驶视频（AIGV）是否可靠支持自动驾驶模型的训练和评估，发现原始AIGV会降低感知性能，但通过提出的ADGVE评估器过滤后能改善视频质量和下游模型性能。


<details>
  <summary>Details</summary>
Motivation: 文本到视频模型能够生成高分辨率驾驶场景，为自动驾驶提供了低成本、可扩展的替代数据源。但关键问题是：这些AI生成的驾驶视频能否可靠地支持自动驾驶模型的训练和评估？

Method: 1. 提出了AIGV常见故障模式的分类法（视觉伪影、物理上不可能的运动、交通语义违规）；2. 构建了ADGV-Bench基准数据集，包含人工质量标注和多感知任务的密集标签；3. 提出了ADGVE评估器，结合静态语义、时序线索、车道遵守信号和视觉语言模型引导的推理，为每个视频片段生成单一质量评分。

Result: 实验表明：盲目添加原始AIGV会降低感知性能（目标检测、跟踪和实例分割），但使用ADGVE过滤AIGV能持续改善一般视频质量评估指标和下游自动驾驶模型性能，使AIGV成为真实世界数据的有益补充。

Conclusion: 研究揭示了AIGV的风险和潜力，并提供了实用工具，为未来在自动驾驶流程中安全利用大规模视频生成提供了指导。通过适当的过滤和评估，AIGV可以成为真实驾驶数据的有价值补充。

Abstract: Recent text-to-video models have enabled the generation of high-resolution driving scenes from natural language prompts. These AI-generated driving videos (AIGVs) offer a low-cost, scalable alternative to real or simulator data for autonomous driving (AD). But a key question remains: can such videos reliably support training and evaluation of AD models? We present a diagnostic framework that systematically studies this question. First, we introduce a taxonomy of frequent AIGV failure modes, including visual artifacts, physically implausible motion, and violations of traffic semantics, and demonstrate their negative impact on object detection, tracking, and instance segmentation. To support this analysis, we build ADGV-Bench, a driving-focused benchmark with human quality annotations and dense labels for multiple perception tasks. We then propose ADGVE, a driving-aware evaluator that combines static semantics, temporal cues, lane obedience signals, and Vision-Language Model(VLM)-guided reasoning into a single quality score for each clip. Experiments show that blindly adding raw AIGVs can degrade perception performance, while filtering them with ADGVE consistently improves both general video quality assessment metrics and downstream AD models, and turns AIGVs into a beneficial complement to real-world data. Our study highlights both the risks and the promise of AIGVs, and provides practical tools for safely leveraging large-scale video generation in future AD pipelines.

</details>


### [38] [Perceptual Region-Driven Infrared-Visible Co-Fusion for Extreme Scene Enhancement](https://arxiv.org/abs/2512.06400)
*Jing Tao,Yonghong Zong,Banglei Guana,Pengju Sun,Taihang Lei,Yang Shanga,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出基于区域感知的红外与可见光融合框架，使用空间变曝光相机结合多曝光与多模态成像，在极端环境下保持几何保真度与热辐射信息。


<details>
  <summary>Details</summary>
Motivation: 现有方法在融合红外与可见光谱时，往往牺牲可见光图像质量，影响测量精度，特别是在极端条件下难以同时保持几何保真度和热辐射信息。

Method: 提出区域感知融合框架：1) 使用空间变曝光相机获取多曝光多模态数据；2) 基于区域感知的特征融合确保精确多模态配准；3) 自适应融合与对比度增强；4) 区域显著性图引导的结构相似性补偿机制优化光谱融合；5) 适应单曝光场景。

Result: 在合成和真实数据上的实验表明，该方法在图像清晰度和性能方面优于现有方法，定量和视觉评估均证实了其优越性。

Conclusion: 提出的区域感知融合框架有效解决了极端环境下红外与可见光融合的挑战，在保持几何保真度的同时整合热辐射信息，为摄影测量应用提供了可靠解决方案。

Abstract: In photogrammetry, accurately fusing infrared (IR) and visible (VIS) spectra while preserving the geometric fidelity of visible features and incorporating thermal radiation is a significant challenge, particularly under extreme conditions. Existing methods often compromise visible imagery quality, impacting measurement accuracy. To solve this, we propose a region perception-based fusion framework that combines multi-exposure and multi-modal imaging using a spatially varying exposure (SVE) camera. This framework co-fuses multi-modal and multi-exposure data, overcoming single-exposure method limitations in extreme environments. The framework begins with region perception-based feature fusion to ensure precise multi-modal registration, followed by adaptive fusion with contrast enhancement. A structural similarity compensation mechanism, guided by regional saliency maps, optimizes IR-VIS spectral integration. Moreover, the framework adapts to single-exposure scenarios for robust fusion across different conditions. Experiments conducted on both synthetic and real-world data demonstrate superior image clarity and improved performance compared to state-of-the-art methods, as evidenced by both quantitative and visual evaluations.

</details>


### [39] [Rethinking Training Dynamics in Scale-wise Autoregressive Generation](https://arxiv.org/abs/2512.06421)
*Gengze Zhou,Chongjian Ge,Hao Tan,Feng Liu,Yicong Hong*

Main category: cs.CV

TL;DR: 本文提出了一种名为SAR（Self-Autoregressive Refinement）的后训练方法，用于解决自回归生成模型中存在的曝光偏差问题，通过交错尺度展开和对比学生强制损失来提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 自回归生成模型在媒体合成方面取得了显著进展，但尺度自回归模型存在曝光偏差问题，这会损害生成质量。作者识别出两个主要原因：1）训练-测试不匹配，模型在推理时必须依赖自身不完美的预测；2）尺度间学习难度不平衡，某些尺度具有不成比例的高优化复杂度。

Method: 提出了自回归细化（SAR）方法，包含两个核心组件：1）交错尺度展开（SSR）机制，执行轻量级自回归展开，使模型接触自身中间预测，从而对齐训练-测试模式；2）对比学生强制损失（CSFL），为自生成上下文提供充分监督，确保训练稳定。

Result: 实验结果表明，将SAR应用于预训练的自回归模型能持续提升生成质量，且计算开销最小。例如，在ImageNet 256上训练的FlexVAR-d16模型上，SAR在10个epoch内（32xA100 GPU上5小时）实现了5.2%的FID降低。

Conclusion: SAR因其高效性、可扩展性和有效性，有望成为视觉自回归生成的可靠后训练方法，能够显著改善现有自回归模型的生成质量。

Abstract: Recent advances in autoregressive (AR) generative models have produced increasingly powerful systems for media synthesis. Among them, next-scale prediction has emerged as a popular paradigm, where models generate images in a coarse-to-fine manner. However, scale-wise AR models suffer from exposure bias, which undermines generation quality. We identify two primary causes of this issue: (1) train-test mismatch, where the model must rely on its own imperfect predictions during inference, and (2) imbalance in scale-wise learning difficulty, where certain scales exhibit disproportionately higher optimization complexity. Through a comprehensive analysis of training dynamics, we propose Self-Autoregressive Refinement (SAR) to address these limitations. SAR introduces a Stagger-Scale Rollout (SSR) mechanism that performs lightweight autoregressive rollouts to expose the model to its own intermediate predictions, thereby aligning train-test patterns, and a complementary Contrastive Student-Forcing Loss (CSFL) that provides adequate supervision for self-generated contexts to ensure stable training. Experimental results show that applying SAR to pretrained AR models consistently improves generation quality with minimal computational overhead. For instance, SAR yields a 5.2% FID reduction on FlexVAR-d16 trained on ImageNet 256 within 10 epochs (5 hours on 32xA100 GPUs). Given its efficiency, scalability, and effectiveness, we expect SAR to serve as a reliable post-training method for visual autoregressive generation.

</details>


### [40] [When Gender is Hard to See: Multi-Attribute Support for Long-Range Recognition](https://arxiv.org/abs/2512.06426)
*Nzakiese Mbongo,Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 提出双路径Transformer框架，利用CLIP联合建模视觉和属性线索，实现远距离性别识别，在U-DetAGReID数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 远距离图像中的性别识别面临空间分辨率低、视角变化大、面部线索缺失等挑战，需要更鲁棒的解决方案。

Method: 双路径Transformer框架：1）直接视觉路径通过选择性微调CLIP图像编码器上层；2）属性中介路径通过软生物特征提示（发型、服装、配饰）在CLIP文本-图像空间中推断性别；使用空间通道注意力模块增强判别性定位。

Result: 在U-DetAGReID数据集上超越现有人员属性和重识别基线方法，在macro-F1、准确率、AUC等多个指标上表现优异，对距离、角度、高度变化具有鲁棒性。

Conclusion: 语言引导的双路径学习为无约束远距离场景下的负责任性别识别提供了原则性、可扩展的基础。

Abstract: Accurate gender recognition from extreme long-range imagery remains a challenging problem due to limited spatial resolution, viewpoint variability, and loss of facial cues. For such purpose, we present a dual-path transformer framework that leverages CLIP to jointly model visual and attribute-driven cues for gender recognition at a distance. The framework integrates two complementary streams: (1) a direct visual path that refines a pre-trained CLIP image encoder through selective fine-tuning of its upper layers, and (2) an attribute-mediated path that infers gender from a set of soft-biometric prompts (e.g., hairstyle, clothing, accessories) aligned in the CLIP text-image space. Spatial channel attention modules further enhance discriminative localization under occlusion and low resolution. To support large-scale evaluation, we construct U-DetAGReID, a unified long-range gender dataset derived from DetReIDx and AG-ReID.v2, harmonized under a consistent ternary labeling scheme (Male, Female, Unknown). Extensive experiments suggest that the proposed solution surpasses state-of-the-art person-attribute and re-identification baselines across multiple metrics (macro-F1, accuracy, AUC), with consistent robustness to distance, angle, and height variations. Qualitative attention visualizations confirm interpretable attribute localization and responsible abstention behavior. Our results show that language-guided dual-path learning offers a principled, extensible foundation for responsible gender recognition in unconstrained long-range scenarios.

</details>


### [41] [Towards Stable Cross-Domain Depression Recognition under Missing Modalities](https://arxiv.org/abs/2512.06447)
*Jiuyi Chen,Mingkui Tan,Haifeng Lu,Qiuna Xu,Zhihua Wang,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: 提出SCD-MLLM框架，通过多源数据输入适配器和模态感知自适应融合模块，实现跨域抑郁症识别的统一稳定解决方案，在完整和部分模态情况下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 抑郁症筛查具有公共卫生重要性，但现有多模态自动抑郁症检测方法缺乏统一的通用框架，对真实世界中常见的模态缺失情况稳定性不足，需要开发能够处理异构数据源并保持模态缺失稳定性的解决方案。

Method: 提出SCD-MLLM框架，包含两个关键组件：1) 多源数据输入适配器(MDIA)，使用掩码机制和任务特定提示将异构输入转换为统一标记序列；2) 模态感知自适应融合模块(MAFM)，通过共享投影机制自适应整合音频和视觉特征，增强模态缺失情况下的鲁棒性。

Result: 在五个公开抑郁症数据集(CMDC、AVEC2014、DAIC-WOZ、DVlog、EATD)上进行多数据集联合训练实验，在完整和部分模态设置下均优于现有SOTA模型和领先商业大语言模型(Gemini和GPT)，展示了优越的跨域泛化能力、多模态线索捕捉能力和模态缺失稳定性。

Conclusion: SCD-MLLM为跨域抑郁症识别提供了一个统一且稳定的框架，能够有效处理异构数据源并保持模态缺失情况下的性能稳定性，在真实世界应用中具有重要价值。

Abstract: Depression poses serious public health risks, including suicide, underscoring the urgency of timely and scalable screening. Multimodal automatic depression detection (ADD) offers a promising solution; however, widely studied audio- and video-based ADD methods lack a unified, generalizable framework for diverse depression recognition scenarios and show limited stability to missing modalities, which are common in real-world data. In this work, we propose a unified framework for Stable Cross-Domain Depression Recognition based on Multimodal Large Language Model (SCD-MLLM). The framework supports the integration and processing of heterogeneous depression-related data collected from varied sources while maintaining stability in the presence of incomplete modality inputs. Specifically, SCD-MLLM introduces two key components: (i) Multi-Source Data Input Adapter (MDIA), which employs masking mechanism and task-specific prompts to transform heterogeneous depression-related inputs into uniform token sequences, addressing inconsistency across diverse data sources; (ii) Modality-Aware Adaptive Fusion Module (MAFM), which adaptively integrates audio and visual features via a shared projection mechanism, enhancing resilience under missing modality conditions. e conduct comprehensive experiments under multi-dataset joint training settings on five publicly available and heterogeneous depression datasets from diverse scenarios: CMDC, AVEC2014, DAIC-WOZ, DVlog, and EATD. Across both complete and partial modality settings, SCD-MLLM outperforms state-of-the-art (SOTA) models as well as leading commercial LLMs (Gemini and GPT), demonstrating superior cross-domain generalization, enhanced ability to capture multimodal cues of depression, and strong stability to missing modality cases in real-world applications.

</details>


### [42] [Sanvaad: A Multimodal Accessibility Framework for ISL Recognition and Voice-Based Interaction](https://arxiv.org/abs/2512.06485)
*Kush Revankar,Shreyas Deshpande,Araham Sayeed,Ansh Tandale,Sarika Bobde*

Main category: cs.CV

TL;DR: Sanvaad是一个轻量级多模态无障碍框架，支持聋人、视障用户与听力正常人群之间的实时双向通信，结合计算机视觉和语音处理技术，可在边缘设备上运行。


<details>
  <summary>Details</summary>
Motivation: 当前聋人、视障用户与听力正常人群之间的通信工具通常只支持单向交互，存在沟通障碍。需要一种支持实时双向通信的无障碍解决方案。

Method: 1. 为聋人用户：基于MediaPipe地标构建印度手语识别模块，支持语音到手语的转换（语音检测映射到预定义短语，生成GIF或字母可视化）
2. 为视障用户：提供无屏幕语音界面，集成多语言语音识别、文本摘要和文本转语音生成
3. 通过Streamlit界面整合所有组件，支持桌面和移动环境

Result: 开发了一个轻量级多模态无障碍框架Sanvaad，能够在边缘设备上流畅运行，无需专用硬件，支持实时双向通信。

Conclusion: Sanvaad通过结合轻量级计算机视觉和语音处理工具，为包容性通信提供了实用且可访问的途径，解决了聋人和视障用户与听力正常人群之间的沟通障碍。

Abstract: Communication between deaf users, visually im paired users, and the general hearing population often relies on tools that support only one direction of interaction. To address this limitation, this work presents Sanvaad, a lightweight multimodal accessibility framework designed to support real time, two-way communication. For deaf users, Sanvaad includes an ISL recognition module built on MediaPipe landmarks. MediaPipe is chosen primarily for its efficiency and low computational load, enabling the system to run smoothly on edge devices without requiring dedicated hardware. Spoken input from a phone can also be translated into sign representations through a voice-to-sign component that maps detected speech to predefined phrases and produces corresponding GIFs or alphabet-based visualizations. For visually impaired users, the framework provides a screen free voice interface that integrates multilingual speech recognition, text summarization, and text-to-speech generation. These components work together through a Streamlit-based interface, making the system usable on both desktop and mobile environments. Overall, Sanvaad aims to offer a practical and accessible pathway for inclusive communication by combining lightweight computer vision and speech processing tools within a unified framework.

</details>


### [43] [Method of UAV Inspection of Photovoltaic Modules Using Thermal and RGB Data Fusion](https://arxiv.org/abs/2512.06504)
*Andrii Lysyi,Anatoliy Sachenko,Pavlo Radiuk,Mykola Lysyi,Oleksandr Melnychenko,Diana Zahorodnia*

Main category: cs.CV

TL;DR: 开发了一个智能集成框架，用于光伏基础设施的自动化检测，解决了传统方法的热调色板偏差、数据冗余和高通信带宽需求等关键缺陷。


<details>
  <summary>Details</summary>
Motivation: 传统光伏检测方法存在热调色板偏差、数据冗余和高通信带宽需求等问题，需要开发一个全面的多模态系统来自动化监控工作流程，提高电站安全性和运营效率。

Method: 采用协同架构：1) 通过强制表示一致性学习调色板不变的热嵌入；2) 通过门控机制与对比归一化的RGB流融合；3) 使用基于罗德里格斯更新的闭环自适应重采集控制器确认模糊异常；4) 基于DBSCAN和半正矢距离的地理空间去重模块。

Result: 在公开PVF-10基准测试中达到0.903的平均精度(mAP@0.5)，比单模态基线提高12-15%；现场验证召回率达96%；去重过程减少重复引起的假阳性15-20%；仅相关遥测数据减少空中数据传输60-70%。

Conclusion: 建立了一个主动式光伏检测的新范式，系统性能显著优于传统方法，具备现场应用准备度，能有效减少数据冗余和通信负担。

Abstract: The subject of this research is the development of an intelligent, integrated framework for the automated inspection of photovoltaic (PV) infrastructure that addresses the critical shortcomings of conventional methods, including thermal palette bias, data redundancy, and high communication bandwidth requirements. The goal of this study is to design, develop, and validate a comprehensive, multi-modal system that fully automates the monitoring workflow, from data acquisition to the generation of actionable, geo-located maintenance alerts, thereby enhancing plant safety and operational efficiency. The methods employed involve a synergistic architecture that begins with a palette-invariant thermal embedding, learned by enforcing representational consistency, which is fused with a contrast-normalized RGB stream via a gated mechanism. This is supplemented by a closed-loop, adaptive re-acquisition controller that uses Rodrigues-based updates for targeted confirmation of ambiguous anomalies and a geospatial deduplication module that clusters redundant alerts using DBSCAN over the haversine distance. In conclusion, this study establishes a powerful new paradigm for proactive PV inspection, with the proposed system achieving a mean Average Precision (mAP@0.5) of 0.903 on the public PVF-10 benchmark, a significant 12-15% improvement over single-modality baselines. Field validation confirmed the system's readiness, achieving 96% recall, while the de-duplication process reduced duplicate-induced false positives by 15-20%, and relevance-only telemetry cut airborne data transmission by 60-70%.

</details>


### [44] [On The Role of K-Space Acquisition in MRI Reconstruction Domain-Generalization](https://arxiv.org/abs/2512.06530)
*Mohammed Wattad,Tamir Shor,Alex Bronstein*

Main category: cs.CV

TL;DR: 该论文研究了学习型k空间采集模式在加速磁共振成像中的跨域泛化能力，提出了一种通过引入采集不确定性来增强域鲁棒性的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多针对单一数据集或模态优化k空间采集模式，缺乏对跨成像域可迁移性的考虑。作者旨在探索学习型k空间采样在域偏移下的泛化能力。

Method: 提出了一种增强域鲁棒性的新方法：在训练过程中引入采集不确定性，通过随机扰动k空间轨迹来模拟不同扫描仪和成像条件的变异性。

Result: 通过跨数据集和采集范式的系统评估，表明使用学习采样模式训练的模型在跨域设置下表现出更好的泛化性能。提出的不确定性方法进一步提升了域鲁棒性。

Conclusion: k空间轨迹设计不仅是加速机制，更是提高MRI重建中域泛化能力的重要自由度。学习型采样模式具有跨域泛化潜力，通过引入采集不确定性可进一步增强鲁棒性。

Abstract: Recent work has established learned k-space acquisition patterns as a promising direction for improving reconstruction quality in accelerated Magnetic Resonance Imaging (MRI). Despite encouraging results, most existing research focuses on acquisition patterns optimized for a single dataset or modality, with limited consideration of their transferability across imaging domains. In this work, we demonstrate that the benefits of learned k-space sampling can extend beyond the training domain, enabling superior reconstruction performance under domain shifts. Our study presents two main contributions. First, through systematic evaluation across datasets and acquisition paradigms, we show that models trained with learned sampling patterns exhibitimproved generalization under cross-domain settings. Second, we propose a novel method that enhances domain robustness by introducing acquisition uncertainty during training-stochastically perturbing k-space trajectories to simulate variability across scanners and imaging conditions. Our results highlight the importance of treating kspace trajectory design not merely as an acceleration mechanism, but as an active degree of freedom for improving domain generalization in MRI reconstruction.

</details>


### [45] [GNC-Pose: Geometry-Aware GNC-PnP for Accurate 6D Pose Estimation](https://arxiv.org/abs/2512.06565)
*Xiujin Liu*

Main category: cs.CV

TL;DR: GNC-Pose是一个无需学习的单目6D物体姿态估计方法，通过渲染初始化、几何感知对应点加权和GNC优化实现，在YCB数据集上达到与学习方法竞争的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的6D姿态估计方法通常依赖学习特征或类别先验，本文旨在开发一个完全无需学习的鲁棒方法，仅基于几何一致性实现准确的姿态估计。

Method: 1) 通过特征匹配和渲染对齐获得粗略的2D-3D对应点；2) 引入几何感知的聚类加权机制，基于3D结构一致性为每个点分配置信度；3) 使用GNC（渐进非凸性）优化处理异常值；4) 最后进行LM（Levenberg-Marquardt）细化。

Result: 在YCB物体和模型集上测试，尽管无需学习特征、训练数据或类别特定先验，GNC-Pose在准确性上与基于学习的方法和无学习方法都相当，提供了简单、鲁棒且实用的解决方案。

Conclusion: GNC-Pose通过几何感知加权和GNC优化，实现了无需学习的鲁棒6D姿态估计，为纹理物体的单目姿态估计提供了有效的替代方案。

Abstract: We present GNC--Pose, a fully learning--free monocular 6D object pose estimation pipeline for textured objects that combines rendering--based initialization, geometry--aware correspondence weighting, and robust GNC optimization. Starting from coarse 2D--3D correspondences obtained through feature matching and rendering--based alignment, our method builds upon the Graduated Non--Convexity (GNC) principle and introduces a geometry--aware, cluster--based weighting mechanism that assigns robust per point confidence based on the 3D structural consistency of the model. This geometric prior and weighting strategy significantly stabilizes the optimization under severe outlier contamination. A final LM refinement further improve accuracy. We tested GNC--Pose on The YCB Object and Model Set, despite requiring no learned features, training data, or category-specific priors, GNC--Pose achieves competitive accuracy compared with both learning-based and learning--free methods, and offers a simple, robust, and practical solution for learning-free 6D pose estimation.

</details>


### [46] [MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding](https://arxiv.org/abs/2512.06581)
*Yuhao Su,Anwesa Choudhuri,Zhongpai Gao,Benjamin Planche,Van Nguyen Nguyen,Meng Zheng,Yuhan Shen,Arun Innanje,Terrence Chen,Ehsan Elhamifar,Ziyan Wu*

Main category: cs.CV

TL;DR: 该研究针对医学视频理解任务，提出了MedVidBench基准数据集和MedGRPO强化学习框架，解决了现有视觉语言模型在医学领域空间精度、时序推理和临床语义理解方面的不足。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医学视频理解方面存在困难，特别是在空间精度、时序推理和临床语义理解等关键维度。现有方法缺乏专门的医学视频基准和有效的训练方法。

Method: 1) 构建MedVidBench基准数据集：包含531,850个视频-指令对，涵盖8个医学来源，通过专家引导提示和双模型验证的质量保证流程；2) 提出MedGRPO强化学习框架：采用跨数据集奖励归一化平衡不同难度数据集的优化，并使用医学LLM法官通过五个临床维度评估字幕质量。

Result: 在MedVidBench上监督微调Qwen2.5-VL-7B模型显著优于GPT-4.1和Gemini-2.5-Flash。MedGRPO框架进一步提升了SFT基线在定位和字幕任务上的性能。

Conclusion: 该研究为医学领域的视觉语言模型建立了基础性基准和稳健的训练方法，推动了医学视频理解技术的发展。

Abstract: Large vision-language models struggle with medical video understanding, where spatial precision, temporal reasoning, and clinical semantics are critical. To address this, we first introduce \textbf{MedVidBench}, a large-scale benchmark of 531,850 video-instruction pairs across 8 medical sources spanning video, segment, and frame-level tasks, curated through a rigorous quality assurance pipeline with expert-guided prompting and dual-model validation. While supervised fine-tuning on MedVidBench yields noticeable gains, standard Reinforcement Learning (RL) fails due to imbalanced reward scales across datasets, which destabilizes optimization and leads to training collapse. To overcome this, we introduce \textbf{MedGRPO}, a novel RL framework for balanced multi-dataset training with two key innovations: (1) \emph{cross-dataset reward normalization} that maps each dataset's median performance to a common reward value, ensuring fair optimization regardless of difficulty, and (2) a \emph{medical LLM judge} that evaluates caption quality on five clinical dimensions through comparative similarity scoring. Supervised fine-tuning Qwen2.5-VL-7B on MedVidBench substantially outperforms GPT-4.1 and Gemini-2.5-Flash across all tasks, demonstrating MedVidBench's efficacy, while our MedGRPO framework further improves upon the SFT baseline across grounding and captioning tasks. Our work establishes a foundational benchmark and robust training methodology for advancing vision-language models in medical domains. Our project website is available at https://yuhaosu.github.io/MedGRPO/.

</details>


### [47] [Learning Relative Gene Expression Trends from Pathology Images in Spatial Transcriptomics](https://arxiv.org/abs/2512.06612)
*Kazuya Nishimura,Haruka Hirose,Ryoma Bise,Kaito Shiku,Yasuhiro Kojima*

Main category: cs.CV

TL;DR: 提出STRank损失函数，通过建模基因相对表达模式而非绝对表达水平，来降低RNA测序噪声和批次效应的影响


<details>
  <summary>Details</summary>
Motivation: 病理图像中基因表达估计可降低RNA测序成本，但现有方法使用逐点损失函数预测绝对表达值，由于测序技术复杂性和细胞内在变异性，观测到的基因表达包含随机噪声和批次效应，准确估计绝对表达值仍具挑战性

Method: 提出学习相对表达模式而非绝对水平的新目标，假设基因相对表达水平在独立实验中呈现一致模式，即使绝对表达值受批次效应和随机噪声影响。基于此假设建模关系，提出STRank损失函数

Result: 在合成数据集和真实数据集上的实验证明了所提方法的有效性

Conclusion: 通过关注相对表达模式而非绝对表达值，STRank损失函数能够更稳健地处理噪声和批次效应，提高病理图像中基因表达估计的准确性

Abstract: Gene expression estimation from pathology images has the potential to reduce the RNA sequencing cost. Point-wise loss functions have been widely used to minimize the discrepancy between predicted and absolute gene expression values. However, due to the complexity of the sequencing techniques and intrinsic variability across cells, the observed gene expression contains stochastic noise and batch effects, and estimating the absolute expression values accurately remains a significant challenge. To mitigate this, we propose a novel objective of learning relative expression patterns rather than absolute levels. We assume that the relative expression levels of genes exhibit consistent patterns across independent experiments, even when absolute expression values are affected by batch effects and stochastic noise in tissue samples. Based on the assumption, we model the relation and propose a novel loss function called STRank that is robust to noise and batch effects. Experiments using synthetic datasets and real datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/naivete5656/STRank.

</details>


### [48] [Masked Autoencoder Pretraining on Strong-Lensing Images for Joint Dark-Matter Model Classification and Super-Resolution](https://arxiv.org/abs/2512.06642)
*Achmad Ardani Prasha,Clavino Ourizqi Rachmadi,Muhamad Fauzan Ibnu Syahlan,Naufal Rahfi Anugerah,Nanda Garin Raditya,Putri Amelia,Sabrina Laila Mutiara,Hilman Syachr Ramadhan*

Main category: cs.CV

TL;DR: 使用掩码自编码器（MAE）在强引力透镜模拟图像上进行预训练，学习可泛化表示，用于暗物质模型分类和图像超分辨率任务，效果优于从头训练的模型。


<details>
  <summary>Details</summary>
Motivation: 强引力透镜可以揭示暗物质亚结构的影响，但从噪声、低分辨率图像中分析这些效应具有挑战性。需要开发能够处理多个下游任务的通用表示学习方法。

Method: 在DeepLense ML4SCI基准的模拟强透镜图像上使用掩码自编码器（MAE）预训练Vision Transformer编码器，采用掩码图像建模目标。然后分别针对两个下游任务微调编码器：(1) 暗物质模型分类（冷暗物质、轴子类或无亚结构），(2) 通过超分辨率增强低分辨率透镜图像。

Result: MAE预训练结合适当的掩码比例调整，产生的共享编码器性能匹配或超过从头训练的ViT。在90%掩码比例下，分类器达到宏观AUC 0.968和准确率88.65%（基线：AUC 0.957，准确率82.46%）。超分辨率任务（16x16到64x64）中，MAE预训练模型重建图像PSNR约33 dB，SSIM 0.961，略优于从头训练。掩码比例分析显示权衡关系：更高掩码比例改善分类但略微降低重建保真度。

Conclusion: MAE预训练在物理丰富的模拟数据上提供了灵活、可重用的编码器，适用于多个强透镜分析任务，展示了自监督学习在天体物理数据分析中的潜力。

Abstract: Strong gravitational lensing can reveal the influence of dark-matter substructure in galaxies, but analyzing these effects from noisy, low-resolution images poses a significant challenge. In this work, we propose a masked autoencoder (MAE) pretraining strategy on simulated strong-lensing images from the DeepLense ML4SCI benchmark to learn generalizable representations for two downstream tasks: (i) classifying the underlying dark matter model (cold dark matter, axion-like, or no substructure) and (ii) enhancing low-resolution lensed images via super-resolution. We pretrain a Vision Transformer encoder using a masked image modeling objective, then fine-tune the encoder separately for each task. Our results show that MAE pretraining, when combined with appropriate mask ratio tuning, yields a shared encoder that matches or exceeds a ViT trained from scratch. Specifically, at a 90% mask ratio, the fine-tuned classifier achieves macro AUC of 0.968 and accuracy of 88.65%, compared to the scratch baseline (AUC 0.957, accuracy 82.46%). For super-resolution (16x16 to 64x64), the MAE-pretrained model reconstructs images with PSNR ~33 dB and SSIM 0.961, modestly improving over scratch training. We ablate the MAE mask ratio, revealing a consistent trade-off: higher mask ratios improve classification but slightly degrade reconstruction fidelity. Our findings demonstrate that MAE pretraining on physics-rich simulations provides a flexible, reusable encoder for multiple strong-lensing analysis tasks.

</details>


### [49] [Personalized Image Descriptions from Attention Sequences](https://arxiv.org/abs/2512.06662)
*Ruoyu Xue,Hieu Le,Jingyi Xu,Sounak Mondal,Abe Leite,Gregory Zelinsky,Minh Hoai,Dimitris Samaras*

Main category: cs.CV

TL;DR: DEPER模型通过同时学习语言风格和观看行为来生成个性化图像描述，相比仅关注语言风格的现有方法有显著改进


<details>
  <summary>Details</summary>
Motivation: 现有个性化图像描述模型只关注语言风格，忽略了个人观看图像时的注意力模式差异，而不同人观看同一图像时会关注不同区域、对象和细节，导致描述存在显著差异

Method: DEPER方法学习一个主体嵌入，同时捕捉语言风格和观看行为，通过辅助注意力预测任务进行指导，使用轻量级适配器与冻结的视觉语言模型对齐，实现少样本个性化而无需重新训练

Result: 在四个数据集上（涵盖不同观看任务和简短/详细描述），DEPER平均提升了24%，表明建模个性化注意力能产生更符合人类认知和更高质量的描述

Conclusion: 理解人们如何观看图像有助于预测他们会说什么；在多媒体系统中建模人类感知的多样性可以同时提升性能和人类对齐度

Abstract: People can view the same image differently: they focus on different regions, objects, and details in varying orders and describe them in distinct linguistic styles. This leads to substantial variability in image descriptions. However, existing models for personalized image description focus on linguistic style alone, with no prior work leveraging individual viewing patterns. We address this gap by explicitly modeling personalized viewing behavior as a core factor in description generation. Our method, DEPER (DEscription-PERception persona encoder), learns a subject embedding that captures both linguistic style and viewing behavior, guided by an auxiliary attention-prediction task. A lightweight adapter aligns these embeddings with a frozen vision-language model, enabling few-shot personalization without retraining. Across four datasets spanning diverse viewing tasks and both short and detailed descriptions, DEPER achieves a 24% average improvement, showing that modeling personalized attention produces more human-aligned and high-quality descriptions. We posit that understanding how people see helps predict what they say; modeling human diversity in perception can improve both performance and human alignment in multimodal systems.

</details>


### [50] [1 + 1 > 2: Detector-Empowered Video Large Language Model for Spatio-Temporal Grounding and Reasoning](https://arxiv.org/abs/2512.06673)
*Shida Gao,Feng Xue,Xiangfeng Wang,Anlong Ming,Teng Long,Yihua Shao,Haozhe Wang,Zhaowen Lin,Wei Wang,Nicu Sebe*

Main category: cs.CV

TL;DR: DEViL提出了一种结合视频大语言模型和开放词汇检测器的方法，通过参考语义令牌实现端到端学习，解决时空定位中的空间误差累积和时间漂移问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在时空定位任务中采用自回归空间解码，导致输出序列过长，空间误差随时间累积，定位结果在视频中逐渐漂移。需要一种更有效的方法来同时处理时空定位和语义推理。

Method: 提出DEViL框架，将视频大语言模型与开放词汇检测器耦合。通过参考语义令牌将用户查询蒸馏为丰富的语义表示，既作为控制信号又替代检测器的文本嵌入。同时提出管内时间正则化，驱动检测器生成时间一致的目标查询。

Result: 实验表明DEViL在各种细粒度视频理解任务上表现优异，特别是在时空视频定位和基于视觉问答的定位任务上取得显著效果。

Conclusion: DEViL通过结合大语言模型和检测器，有效解决了时空定位中的误差累积问题，实现了更好的时空一致性和定位精度，为细粒度视频理解提供了新思路。

Abstract: Spatio-temporal grounding and reasoning aims to locate the temporal segment and spatial region of an event in a video given a user query, while also reasoning about semantics such as causality, temporal order, and action relationships. To achieve this, current MLLMs primarily treats bounding boxes as text tokens and generates them autoregressively. However, such autoregressive spatial decoding leads to very-long output sequences, causing spatial errors to accumulated over time and the localization results to progressively drift across a video. To address this, we present a Detector-Empowered Video LLM, short for DEViL, which couples a Video LLM with an open-vocabulary detector (OVD). Specifically, the MLLM and detector are connected via a reference-semantic token (RST) that distills the user query into a rich semantic representation. Unlike tokens that merely serve as spatial prompts or segmentor switches, the RST functions as both a control signal and a replacement for the OVD's text embedding, enabling end-to-end learning of both referential understanding and spatial localization. Furthermore, we propose a tube-mined temporal regularization (TTReg) within OVD, which drives the OVD to generate temporally-consistent queries for target objects, thereby ensuring effective temporal association. Experiments demonstrate that DEViL achieves strong performance across various fine-grained video understanding tasks, particularly STVG and GroundedVQA. Code will be released on https://github.com/gaostar123/DeViL.

</details>


### [51] [RunawayEvil: Jailbreaking the Image-to-Video Generative Models](https://arxiv.org/abs/2512.06674)
*Songping Wang,Rufan Qian,Yueming Lyu,Qinglong Liu,Linzhuang Zou,Jie Qin,Songhua Liu,Caifeng Shan*

Main category: cs.CV

TL;DR: RunawayEvil：首个针对图像到视频生成模型的多模态越狱框架，采用"策略-战术-行动"范式，通过强化学习和LLM实现自我进化的攻击能力，在商业I2V模型上达到最先进的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 图像到视频生成系统虽然提供了重要的创意控制能力，但其安全性特别是对越狱攻击的脆弱性尚未得到充分研究。当前缺乏针对这类多模态系统的安全漏洞分析工具。

Method: 基于"策略-战术-行动"范式构建多模态越狱框架，包含三个核心组件：1) 策略感知命令单元（通过强化学习和LLM实现策略自我进化）；2) 多模态战术规划单元（生成协调的文本越狱指令和图像篡改指南）；3) 战术行动单元（执行和评估多模态协调攻击）。

Result: 在Open-Sora 2.0和CogVideoX等商业I2V模型上实现了最先进的攻击成功率，在COCO2017数据集上比现有方法提升58.5%到79%。

Conclusion: 该工作为I2V模型的漏洞分析提供了关键工具，为构建更鲁棒的视频生成系统奠定了基础，揭示了多模态生成系统在安全方面的薄弱环节。

Abstract: Image-to-Video (I2V) generation synthesizes dynamic visual content from image and text inputs, providing significant creative control. However, the security of such multimodal systems, particularly their vulnerability to jailbreak attacks, remains critically underexplored. To bridge this gap, we propose RunawayEvil, the first multimodal jailbreak framework for I2V models with dynamic evolutionary capability. Built on a "Strategy-Tactic-Action" paradigm, our framework exhibits self-amplifying attack through three core components: (1) Strategy-Aware Command Unit that enables the attack to self-evolve its strategies through reinforcement learning-driven strategy customization and LLM-based strategy exploration; (2) Multimodal Tactical Planning Unit that generates coordinated text jailbreak instructions and image tampering guidelines based on the selected strategies; (3) Tactical Action Unit that executes and evaluates the multimodal coordinated attacks. This self-evolving architecture allows the framework to continuously adapt and intensify its attack strategies without human intervention. Extensive experiments demonstrate RunawayEvil achieves state-of-the-art attack success rates on commercial I2V models, such as Open-Sora 2.0 and CogVideoX. Specifically, RunawayEvil outperforms existing methods by 58.5 to 79 percent on COCO2017. This work provides a critical tool for vulnerability analysis of I2V models, thereby laying a foundation for more robust video generation systems.

</details>


### [52] [EMGauss: Continuous Slice-to-3D Reconstruction via Dynamic Gaussian Modeling in Volume Electron Microscopy](https://arxiv.org/abs/2512.06684)
*Yumeng He,Zanwei Zhou,Yekun Zheng,Chen Liang,Yunbo Wang,Xiaokang Yang*

Main category: cs.CV

TL;DR: EMGauss：基于高斯溅射的3D重建框架，用于从平面扫描的2D切片重建各向异性体积电子显微镜数据，无需大规模预训练即可实现连续切片合成。


<details>
  <summary>Details</summary>
Motivation: 体积电子显微镜（vEM）存在采集权衡，导致各向异性体积和有限的轴向分辨率。现有深度学习方法基于各向同性假设，但在形态各向异性结构上失效。

Method: 将切片到3D重建重新定义为基于高斯溅射的3D动态场景渲染问题，将轴向切片进展建模为2D高斯点云的时间演化。采用教师-学生引导机制，利用未观测切片的高置信度预测作为伪监督信号。

Result: 相比基于扩散和GAN的重建方法，EMGauss显著提高了插值质量，实现了连续切片合成，且无需大规模预训练。

Conclusion: EMGauss为vEM提供了一种通用的切片到3D重建解决方案，克服了各向同性方法的局限性，并可能推广到其他成像领域。

Abstract: Volume electron microscopy (vEM) enables nanoscale 3D imaging of biological structures but remains constrained by acquisition trade-offs, leading to anisotropic volumes with limited axial resolution. Existing deep learning methods seek to restore isotropy by leveraging lateral priors, yet their assumptions break down for morphologically anisotropic structures. We present EMGauss, a general framework for 3D reconstruction from planar scanned 2D slices with applications in vEM, which circumvents the inherent limitations of isotropy-based approaches. Our key innovation is to reframe slice-to-3D reconstruction as a 3D dynamic scene rendering problem based on Gaussian splatting, where the progression of axial slices is modeled as the temporal evolution of 2D Gaussian point clouds. To enhance fidelity in data-sparse regimes, we incorporate a Teacher-Student bootstrapping mechanism that uses high-confidence predictions on unobserved slices as pseudo-supervisory signals. Compared with diffusion- and GAN-based reconstruction methods, EMGauss substantially improves interpolation quality, enables continuous slice synthesis, and eliminates the need for large-scale pretraining. Beyond vEM, it potentially provides a generalizable slice-to-3D solution across diverse imaging domains.

</details>


### [53] [Lightweight Wasserstein Audio-Visual Model for Unified Speech Enhancement and Separation](https://arxiv.org/abs/2512.06689)
*Jisoo Park,Seonghak Lee,Guisik Kim,Taewoo Kim,Junseok Kwon*

Main category: cs.CV

TL;DR: UniVoiceLite是一个轻量级无监督的视听框架，统一了语音增强和语音分离任务，利用唇部运动和面部身份线索，无需配对噪声-干净数据。


<details>
  <summary>Details</summary>
Motivation: 现实世界音频通常同时包含背景噪声和重叠说话者，需要统一解决方案。现有方法多为多阶段架构，参数复杂且依赖监督训练，限制了可扩展性和泛化能力。

Method: 提出UniVoiceLite框架，利用唇部运动和面部身份线索引导语音提取，采用Wasserstein距离正则化稳定潜在空间，无需配对噪声-干净数据。

Result: 实验结果表明UniVoiceLite在噪声和多说话者场景下都表现出色，实现了效率与鲁棒泛化的结合。

Conclusion: UniVoiceLite成功统一了语音增强和语音分离任务，提供了一个轻量级、无监督的解决方案，具有良好的性能和泛化能力。

Abstract: Speech Enhancement (SE) and Speech Separation (SS) have traditionally been treated as distinct tasks in speech processing. However, real-world audio often involves both background noise and overlapping speakers, motivating the need for a unified solution. While recent approaches have attempted to integrate SE and SS within multi-stage architectures, these approaches typically involve complex, parameter-heavy models and rely on supervised training, limiting scalability and generalization. In this work, we propose UniVoiceLite, a lightweight and unsupervised audio-visual framework that unifies SE and SS within a single model. UniVoiceLite leverages lip motion and facial identity cues to guide speech extraction and employs Wasserstein distance regularization to stabilize the latent space without requiring paired noisy-clean data. Experimental results demonstrate that UniVoiceLite achieves strong performance in both noisy and multi-speaker scenarios, combining efficiency with robust generalization. The source code is available at https://github.com/jisoo-o/UniVoiceLite.

</details>


### [54] [The Role of Entropy in Visual Grounding: Analysis and Optimization](https://arxiv.org/abs/2512.06726)
*Shuo Li,Jiajun Sun,Zhihao Zhang,Xiaoran Fan,Senjie Jin,Hui Li,Yuming Yang,Junjie Ye,Lixing Shen,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 本文提出ECVGPO算法，通过熵控制优化视觉定位任务中多模态大语言模型的强化学习微调，平衡探索与利用，在多个基准测试中取得广泛改进。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在强化学习微调方面取得显著进展，但熵在视觉定位等感知导向任务中的作用和特性，以及有效控制策略仍未被充分探索。

Method: 提出ECVGPO（熵控制视觉定位策略优化）算法，这是一种可解释的算法，专门设计用于有效的熵调节。通过分析视觉定位任务中熵的作用和特性，并与推理任务进行比较，基于这些发现构建算法。

Result: 实验表明，ECVGPO通过熵控制更好地平衡了探索与利用之间的权衡，在多个基准测试和模型上都取得了广泛的改进。

Conclusion: ECVGPO算法为视觉定位任务中的熵控制提供了有效的解决方案，通过平衡探索与利用，显著提升了多模态大语言模型在感知导向任务中的性能。

Abstract: Recent advances in fine-tuning multimodal large language models (MLLMs) using reinforcement learning have achieved remarkable progress, particularly with the introduction of various entropy control techniques. However, the role and characteristics of entropy in perception-oriented tasks like visual grounding, as well as effective strategies for controlling it, remain largely unexplored. To address this issue, we focus on the visual grounding task and analyze the role and characteristics of entropy in comparison to reasoning tasks. Building on these findings, we introduce ECVGPO (Entropy Control Visual Grounding Policy Optimization), an interpretable algorithm designed for effective entropy regulation. Through entropy control, the trade-off between exploration and exploitation is better balanced. Experiments show that ECVGPO achieves broad improvements across various benchmarks and models.

</details>


### [55] [FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation](https://arxiv.org/abs/2512.06738)
*M Yashwanth,Sampath Koti,Arunabh Singh,Shyam Marjit,Anirban Chakraborty*

Main category: cs.CV

TL;DR: FedSCAl是一个联邦学习框架，通过服务器-客户端对齐机制解决联邦源自由域自适应问题，在存在显著客户端域差距的情况下提高伪标签准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦源自由域自适应（FFreeDA）问题中，客户端持有未标记数据且存在显著的客户端间域差距，传统的源自由域自适应方法在联邦学习环境中由于数据异质性导致客户端漂移和不可靠的伪标签。

Method: 提出FedSCAl框架，采用服务器-客户端对齐机制，通过对齐客户端和服务器模型的预测来正则化客户端更新，从而减轻客户端漂移问题。

Result: 在基准视觉数据集上的实验表明，FedSCAl在FFreeDA设置下的分类任务中始终优于最先进的联邦学习方法，显著提高了客户端的伪标签准确性。

Conclusion: FedSCAl通过服务器-客户端对齐机制有效解决了联邦源自由域自适应中的客户端漂移问题，为存在显著域差距的联邦学习场景提供了有效的解决方案。

Abstract: We address the Federated source-Free Domain Adaptation (FFreeDA) problem, with clients holding unlabeled data with significant inter-client domain gaps. The FFreeDA setup constrains the FL frameworks to employ only a pre-trained server model as the setup restricts access to the source dataset during the training rounds. Often, this source domain dataset has a distinct distribution to the clients' domains. To address the challenges posed by the FFreeDA setup, adaptation of the Source-Free Domain Adaptation (SFDA) methods to FL struggles with client-drift in real-world scenarios due to extreme data heterogeneity caused by the aforementioned domain gaps, resulting in unreliable pseudo-labels. In this paper, we introduce FedSCAl, an FL framework leveraging our proposed Server-Client Alignment (SCAl) mechanism to regularize client updates by aligning the clients' and server model's predictions. We observe an improvement in the clients' pseudo-labeling accuracy post alignment, as the SCAl mechanism helps to mitigate the client-drift. Further, we present extensive experiments on benchmark vision datasets showcasing how FedSCAl consistently outperforms state-of-the-art FL methods in the FFreeDA setup for classification tasks.

</details>


### [56] [Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2512.06746)
*Ruoxin Chen,Jiahui Gao,Kaiqing Lin,Keyue Zhang,Yandan Zhao,Isabel Guan,Taiping Yao,Shouhong Ding*

Main category: cs.CV

TL;DR: 该论文提出任务-模型对齐原则，通过将AI生成图像检测分解为语义一致性检查和像素伪影检测两个互补任务，分别用VLM和像素伪影专家处理，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型（VLM）的AI生成图像检测方法需要大量资源，且存在严重幻觉问题。研究发现VLM对语义敏感但对像素伪影不敏感，而传统像素伪影检测器则相反，存在任务-模型不匹配问题。

Method: 提出任务-模型对齐原则，将AIGI检测形式化为两个互补任务：语义一致性检查和像素伪影检测。实现为AlignGemini双分支检测器，一个分支使用纯语义监督微调VLM，另一个分支使用纯像素伪影监督训练像素伪影专家。

Result: 在五个野外基准测试中，AlignGemini实现了平均准确率+9.5%的提升，证明了任务-模型对齐原则在可泛化AIGI检测中的有效性。

Conclusion: 任务-模型对齐是提升AI生成图像检测性能的有效途径，通过将检测任务分解为互补的子任务并匹配相应的模型架构，可以克服现有方法的局限性。

Abstract: Vision Language Models (VLMs) are increasingly adopted for AI-generated images (AIGI) detection, yet converting VLMs into detectors requires substantial resource, while the resulting models still exhibit severe hallucinations. To probe the core issue, we conduct an empirical analysis and observe two characteristic behaviors: (i) fine-tuning VLMs on high-level semantic supervision strengthens semantic discrimination and well generalize to unseen data; (ii) fine-tuning VLMs on low-level pixel-artifact supervision yields poor transfer. We attribute VLMs' underperformance to task-model misalignment: semantics-oriented VLMs inherently lack sensitivity to fine-grained pixel artifacts, and semantically non-discriminative pixel artifacts thus exceeds their inductive biases. In contrast, we observe that conventional pixel-artifact detectors capture low-level pixel artifacts yet exhibit limited semantic awareness relative to VLMs, highlighting that distinct models are better matched to distinct tasks. In this paper, we formalize AIGI detection as two complementary tasks--semantic consistency checking and pixel-artifact detection--and show that neglecting either induces systematic blind spots. Guided by this view, we introduce the Task-Model Alignment principle and instantiate it as a two-branch detector, AlignGemini, comprising a VLM fine-tuned exclusively with pure semantic supervision and a pixel-artifact expert trained exclusively with pure pixel-artifact supervision. By enforcing orthogonal supervision on two simplified datasets, each branch trains to its strengths, producing complementary discrimination over semantic and pixel cues. On five in-the-wild benchmarks, AlignGemini delivers a +9.5 gain in average accuracy, supporting task-model alignment as an effective path to generalizable AIGI detection.

</details>


### [57] [UARE: A Unified Vision-Language Model for Image Quality Assessment, Restoration, and Enhancement](https://arxiv.org/abs/2512.06750)
*Weiqi Li,Xuanyu Zhang,Bin Chen,Jingfen Xie,Yan Wang,Kexin Zhang,Junlin Li,Li Zhang,Jian Zhang,Shijie Zhao*

Main category: cs.CV

TL;DR: UARE是首个统一图像质量评估、修复和增强的视觉语言模型，通过两阶段训练框架实现多任务协同训练，利用IQA信号指导图像修复和增强。


<details>
  <summary>Details</summary>
Motivation: 虽然图像质量评估(IQA)和图像修复在概念上紧密相关，但现有工作大多将它们孤立处理。统一的多模态理解-生成模型的最新进展表明，更强的理解能力可以提升生成性能，这促使研究者探索将IQA和修复统一到单一模型中，研究IQA如何指导修复。

Method: 基于预训练的统一理解和生成模型，采用两阶段训练框架：1) 渐进式从单一类型失真扩展到高阶混合退化的训练计划，使模型能处理多种退化；2) 使用交错文本-图像数据进行统一微调，将IQA信号与修复目标对齐，通过多任务协同训练让IQA提升修复和增强性能。

Result: 在IQA、修复和增强任务上的广泛实验证明了UARE的有效性。模型代码将在GitHub上公开。

Conclusion: UARE是首个统一图像质量评估、修复和增强的视觉语言模型，通过多任务协同训练成功实现了IQA对修复和增强的指导作用，为低层视觉任务提供了新的统一解决方案。

Abstract: Image quality assessment (IQA) and image restoration are fundamental problems in low-level vision. Although IQA and restoration are closely connected conceptually, most existing work treats them in isolation. Recent advances in unified multimodal understanding-generation models demonstrate promising results and indicate that stronger understanding can improve generative performance. This motivates a single model that unifies IQA and restoration and explicitly studies how IQA can guide restoration, a setting that remains largely underexplored yet highly valuable. In this paper, we propose UARE, to our knowledge the first Unified vision-language model for image quality Assessment, Restoration, and Enhancement. Built on pretrained unified understanding and generation models, we introduce a two-stage training framework. First, a progressive, easy-to-hard schedule expands from single-type distortions to higher-order mixed degradations, enabling UARE to handle multiple degradations. Second, we perform unified fine-tuning of quality understanding and restoration with interleaved text-image data, aligning IQA signals with restoration objectives. Through multi-task co-training, UARE leverages IQA to boost restoration and enhancement performance. Extensive experiments across IQA, restoration, and enhancement tasks demonstrate the effectiveness of UARE. The code and models will be available at https://github.com/lwq20020127/UARE.

</details>


### [58] [VisChainBench: A Benchmark for Multi-Turn, Multi-Image Visual Reasoning Beyond Language Priors](https://arxiv.org/abs/2512.06759)
*Wenbo Lyu,Yingjun Du,Jinglin Zhao,Xianton Zhen,Ling Shao*

Main category: cs.CV

TL;DR: VisChainBench是一个用于评估大型视觉语言模型多步视觉推理能力的大规模基准测试，包含1,457个任务和20,000多张图像，覆盖日常场景和工程故障排除等领域。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注静态或水平比较（如发现视觉差异或评估适当性），且过度依赖语言线索，忽视了渐进式、上下文相关的推理以及视觉到视觉推理的挑战。

Method: 使用多智能体生成管道构建基准测试，确保高视觉多样性和受控的语言偏见，包含三个不同领域的1,457个任务和20,000多张图像，模拟真实世界的决策过程。

Result: 创建了VisChainBench基准测试，包含1,457个任务和20,000多张图像，覆盖日常场景、工程故障排除等领域，所有数据和代码已公开。

Conclusion: VisChainBench填补了现有基准测试在评估大型视觉语言模型多步视觉推理能力方面的空白，为研究社区提供了一个重要的评估工具。

Abstract: Understanding multi-image, multi-turn scenarios is a critical yet underexplored capability for Large Vision-Language Models (LVLMs). Existing benchmarks predominantly focus on static or horizontal comparisons -- e.g., spotting visual differences or assessing appropriateness -- while relying heavily on language cues. Such settings overlook progressive, context-dependent reasoning and the challenge of visual-to-visual inference. To bridge this gap, we present VisChainBench, a large-scale benchmark designed to rigorously evaluate LVLMs' ability to perform multi-step visual reasoning across sequential, interdependent tasks with minimal language guidance. VisChainBench contains 1,457 tasks spanning over 20,000 images across three diverse domains (e.g., daily scenarios, engineering troubleshooting), structured to mimic real-world decision-making processes. Uniquely, the benchmark is constructed using a multi-agent generation pipeline, ensuring high visual diversity and controlled language bias. All the benchmark data and code for benchmark construction are available for viewing and download via following Link: https://huggingface.co/datasets/eyehole/VisChainBench

</details>


### [59] [Stitch and Tell: A Structured Multimodal Data Augmentation Method for Spatial Understanding](https://arxiv.org/abs/2512.06769)
*Hang Yin,Xiaomin He,PeiWen Yuan,Yiwei Li,Jiayi Shi,Wenxiao Fan,Shaoxiong Feng,Kan Li*

Main category: cs.CV

TL;DR: 提出Stitch and Tell方法，通过拼接图像和生成空间感知描述来增强视觉语言模型的空间理解能力，减少空间幻觉问题


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型存在空间幻觉问题，即错误描述图像中物体的相对位置。作者认为这主要源于图像和文本之间的不对称特性，需要增强模型的空间理解能力。

Method: 提出Stitch and Tell方法，通过沿空间轴拼接图像并基于拼接图像的布局生成空间感知的标题或问答对，无需昂贵的高级模型或人工标注，可即插即用。

Result: 在三种架构（LLaVA-v1.5-7B、LLaVA-Qwen2-1.5B、HALVA-7B）、两个训练数据集和八个基准测试上评估。结果显示SiTe显著改善了空间理解任务（MME_Position +5.50%，Spatial-MM +4.19%），同时保持或改善了通用视觉语言基准测试的性能（COCO-QA +1.02%，MMBench +4.76%）。

Conclusion: 将空间感知结构显式注入训练数据是缓解空间幻觉、提高空间理解能力的有效方法，同时能保持通用视觉语言能力。

Abstract: Existing vision-language models often suffer from spatial hallucinations, i.e., generating incorrect descriptions about the relative positions of objects in an image. We argue that this problem mainly stems from the asymmetric properties between images and text. To enrich the spatial understanding ability of vision-language models, we propose a simple, annotation-free, plug-and-play method named $\text{Stitch and Tell}$ (abbreviated as SiTe), which injects structured spatial supervision into data. It constructs stitched image-text pairs by stitching images along a spatial axis and generating spatially-aware captions or question answer pairs based on the layout of stitched image, without relying on costly advanced models or human involvement. We evaluate SiTe across three architectures including LLaVA-v1.5-7B, LLaVA-Qwen2-1.5B and HALVA-7B, two training datasets, and eight benchmarks. Experiments show that SiTe improves spatial understanding tasks such as $\text{MME}_{\text{Position}}$ (+5.50%) and Spatial-MM (+4.19%), while maintaining or improving performance on general vision-language benchmarks including COCO-QA (+1.02%) and MMBench (+4.76%). Our findings suggest that explicitly injecting spatially-aware structure into training data offers an effective way to mitigate spatial hallucinations and improve spatial understanding, while preserving general vision-language capabilities.

</details>


### [60] [Physics Informed Human Posture Estimation Based on 3D Landmarks from Monocular RGB-Videos](https://arxiv.org/abs/2512.06783)
*Tobias Leuthold,Michele Xiloyannis,Yves Zimmermann*

Main category: cs.CV

TL;DR: 提出一种实时后处理算法，融合BlazePose的3D和2D姿态估计，通过加权优化结合骨骼长度和生物力学模型约束，显著提升姿态估计的准确性和解剖一致性。


<details>
  <summary>Details</summary>
Motivation: 当前基于单目视频流的物理训练自动指导应用（如物理治疗）需要准确稳健的姿态估计。虽然BlazePose等先进模型在实时姿态跟踪方面表现出色，但由于缺乏解剖学约束，仍有改进空间。通过融入物理知识可以提升性能。

Method: 提出实时后处理算法，融合BlazePose的3D和2D估计结果，采用加权优化方法，惩罚与预期骨骼长度和生物力学模型的偏差。使用卡尔曼滤波器根据个体解剖结构自适应调整骨骼长度估计。

Result: 在Physio2.2M数据集上的评估显示，相比BlazePose 3D估计，3D MPJPE降低了10.2%，身体节段间角度误差减少了16.6%。算法计算高效，适合在消费级笔记本电脑和移动设备上运行。

Conclusion: 该方法提供了一种稳健、解剖学一致性的姿态估计方案，基于计算高效的视频到3D姿态估计，适用于自动物理治疗、医疗保健和运动指导。后处理在后台运行，仅使用匿名数据。

Abstract: Applications providing automated coaching for physical training are increasing in popularity, for example physical therapy. These applications rely on accurate and robust pose estimation using monocular video streams. State-of-the-art models like BlazePose excel in real-time pose tracking, but their lack of anatomical constraints indicates improvement potential by including physical knowledge. We present a real-time post-processing algorithm fusing the strengths of BlazePose 3D and 2D estimations using a weighted optimization, penalizing deviations from expected bone length and biomechanical models. Bone length estimations are refined to the individual anatomy using a Kalman filter with adapting measurement trust. Evaluation using the Physio2.2M dataset shows a 10.2 percent reduction in 3D MPJPE and a 16.6 percent decrease in errors of angles between body segments compared to BlazePose 3D estimation. Our method provides a robust, anatomically consistent pose estimation based on a computationally efficient video-to-3D pose estimation, suitable for automated physiotherapy, healthcare, and sports coaching on consumer-level laptops and mobile devices. The refinement runs on the backend with anonymized data only.

</details>


### [61] [VDOT: Efficient Unified Video Creation via Optimal Transport Distillation](https://arxiv.org/abs/2512.06802)
*Yutong Wang,Haiyu Zhang,Tianfan Xue,Yu Qiao,Yaohui Wang,Chang Xu,Xinyuan Chen*

Main category: cs.CV

TL;DR: VDOT是一种高效的统一视频生成模型，采用分布匹配蒸馏范式，结合最优传输技术优化真实与生成分数分布差异，仅需4步推理即可达到传统方法100步的效果。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型要么只能处理少数特定条件，要么因复杂推理过程导致生成时间过长，难以在实际应用中部署。需要开发既高效又能处理多种条件的统一视频生成模型。

Method: 采用分布匹配蒸馏范式，用最优传输技术替代KL散度来优化真实与生成分数分布的差异，避免少步生成场景下的梯度崩溃问题。同时集成判别器提升生成质量，并构建自动化视频数据标注过滤管道支持多任务训练。

Result: 仅需4步推理的VDOT模型在性能上优于或匹配需要100步去噪的基线方法，显著提升了生成效率。同时构建了UVCBench统一测试基准用于标准化评估。

Conclusion: VDOT通过最优传输技术和分布匹配蒸馏，实现了高效、稳定的统一视频生成，仅需极少推理步骤即可达到高质量生成效果，为实际应用提供了可行方案。

Abstract: The rapid development of generative models has significantly advanced image and video applications. Among these, video creation, aimed at generating videos under various conditions, has gained substantial attention. However, existing video creation models either focus solely on a few specific conditions or suffer from excessively long generation times due to complex model inference, making them impractical for real-world applications. To mitigate these issues, we propose an efficient unified video creation model, named VDOT. Concretely, we model the training process with the distribution matching distillation (DMD) paradigm. Instead of using the Kullback-Leibler (KL) minimization, we additionally employ a novel computational optimal transport (OT) technique to optimize the discrepancy between the real and fake score distributions. The OT distance inherently imposes geometric constraints, mitigating potential zero-forcing or gradient collapse issues that may arise during KL-based distillation within the few-step generation scenario, and thus, enhances the efficiency and stability of the distillation process. Further, we integrate a discriminator to enable the model to perceive real video data, thereby enhancing the quality of generated videos. To support training unified video creation models, we propose a fully automated pipeline for video data annotation and filtering that accommodates multiple video creation tasks. Meanwhile, we curate a unified testing benchmark, UVCBench, to standardize evaluation. Experiments demonstrate that our 4-step VDOT outperforms or matches other baselines with 100 denoising steps.

</details>


### [62] [MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2512.06810)
*Yueqian Wang,Songxiang Liu,Disong Wang,Nuo Xu,Guanglu Wan,Huishuai Zhang,Dongyan Zhao*

Main category: cs.CV

TL;DR: MMDuet2：一种基于强化学习的主动式视频多模态大语言模型，能够在视频播放过程中自主决定何时回复，无需精确回复时间标注。


<details>
  <summary>Details</summary>
Motivation: 现有视频MLLM大多采用回合制交互，用户说完后模型才能回复。而实际应用中，模型需要在视频播放过程中主动决定何时回复，这对实时应用至关重要但具有挑战性。

Method: 提出文本到文本的主动交互方法，模型基于对话历史和当前视频帧自主决定回复或保持沉默。引入多回合强化学习训练方法，鼓励及时准确回复，无需精确回复时间标注。在52k视频数据集上通过SFT和RL训练MMDuet2模型。

Result: MMDuet2在回复时机和质量上优于现有主动式视频MLLM基线，在ProactiveVideoQA基准测试中达到最先进性能。

Conclusion: 该方法有效解决了主动式视频交互中的回复时机决策问题，无需手动调整阈值或精确时间标注，为实时视频应用提供了实用解决方案。

Abstract: Recent advances in video multimodal large language models (Video MLLMs) have significantly enhanced video understanding and multi-modal interaction capabilities. While most existing systems operate in a turn-based manner where the model can only reply after user turns, proactively deciding when to reply during video playback presents a promising yet challenging direction for real-time applications. In this work, we propose a novel text-to-text approach to proactive interaction, where the model autonomously determines whether to respond or remain silent at each turn based on dialogue history and visual context up to current frame of an streaming video. To overcome difficulties in previous methods such as manually tuning response decision thresholds and annotating precise reply times, we introduce a multi-turn RL based training method that encourages timely and accurate responses without requiring precise response time annotations. We train our model MMDuet2 on a dataset of 52k videos with two types of dialogues via SFT and RL. Experimental results demonstrate that MMDuet2 outperforms existing proactive Video MLLM baselines in response timing and quality, achieving state-of-the-art performance on the ProactiveVideoQA benchmark.

</details>


### [63] [RMAdapter: Reconstruction-based Multi-Modal Adapter for Vision-Language Models](https://arxiv.org/abs/2512.06811)
*Xiang Lin,Weixin Li,Shu Guo,Lihong Wang,Di Huang*

Main category: cs.CV

TL;DR: RMAdapter是一种新颖的重建式多模态适配器，采用双分支架构平衡任务特定适应与通用知识保留，在少样本场景下显著提升视觉语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型在少样本场景下的微调面临平衡任务特定适应与泛化能力的挑战。现有研究主要关注基于提示的适应方法，而基于适配器的方法探索不足且性能存在明显差距。

Method: 提出重建式多模态适配器（RMAdapter），采用双分支架构：1）适应分支通过参数高效微调注入任务特定知识；2）重建分支通过将潜在空间特征重建回原始特征空间来保留通用知识。通过局部计算重建损失和共享投影模块保持轻量化，并加入一致性约束来平衡判别性与泛化能力。

Result: 在不依赖数据增强或重复提示设计的情况下，RMAdapter在三个代表性任务（新类别泛化、新目标数据集泛化、领域泛化）的所有评估指标上均优于最先进方法。

Conclusion: RMAdapter通过创新的双分支架构有效平衡了任务特定知识与通用知识，为视觉语言模型的少样本适应提供了高效且性能优越的解决方案。

Abstract: Pre-trained Vision-Language Models (VLMs), \textit{e.g.} CLIP, have become essential tools in multimodal transfer learning. However, fine-tuning VLMs in few-shot scenarios poses significant challenges in balancing task-specific adaptation and generalization in the obtained model. Meanwhile, current researches have predominantly focused on prompt-based adaptation methods, leaving adapter-based approaches underexplored and revealing notable performance gaps. To address these challenges, we introduce a novel Reconstruction-based Multimodal Adapter (RMAdapter), which leverages a dual-branch architecture. Unlike conventional single-branch adapters, RMAdapter consists of: (1) an adaptation branch that injects task-specific knowledge through parameter-efficient fine-tuning, and (2) a reconstruction branch that preserves general knowledge by reconstructing latent space features back into the original feature space. This design facilitates a dynamic balance between general and task-specific knowledge. Importantly, although RMAdapter introduces an additional reconstruction branch, it is carefully optimized to remain lightweight. By computing reconstruction loss locally at each layer and sharing projection modules, the overall computational overhead is kept minimal. A consistency constraint is also incorporated to better regulate the trade-off between discriminability and generalization. We comprehensively evaluate the effectiveness of RMAdapter on three representative tasks: generalization to new categories, generalization to new target datasets, and domain generalization. Without relying on data augmentation or duplicate prompt designs, our RMAdapter consistently outperforms state-of-the-art approaches across all evaluation metrics.

</details>


### [64] [MeshSplatting: Differentiable Rendering with Opaque Meshes](https://arxiv.org/abs/2512.06818)
*Jan Held,Sanghyun Son,Renaud Vandeghen,Daniel Rebain,Matheus Gadelha,Yi Zhou,Anthony Cioppa,Ming C. Lin,Marc Van Droogenbroeck,Andrea Tagliasacchi*

Main category: cs.CV

TL;DR: MeshSplatting是一种基于网格的重建方法，通过可微分渲染联合优化几何和外观，生成平滑、高质量的网格，在实时3D引擎中高效渲染，比现有方法性能更好、训练更快、内存使用更少。


<details>
  <summary>Details</summary>
Motivation: 现有的基于基元（如3D高斯泼溅）的点表示方法与AR/VR和游戏引擎中基于网格的流程不兼容，需要一种能够与现有3D引擎无缝集成的网格重建方法。

Method: 通过可微分渲染联合优化几何和外观，使用受限Delaunay三角剖分强制连接性，并优化表面一致性，创建端到端平滑的网格。

Result: 在Mip-NeRF360数据集上，比当前最先进的MiLo方法在基于网格的新视角合成上PSNR提升+0.69 dB，训练速度快2倍，内存使用少2倍。

Conclusion: MeshSplatting通过生成高质量的网格表示，弥合了神经渲染和交互式3D图形之间的差距，实现了无缝的实时场景交互。

Abstract: Primitive-based splatting methods like 3D Gaussian Splatting have revolutionized novel view synthesis with real-time rendering. However, their point-based representations remain incompatible with mesh-based pipelines that power AR/VR and game engines. We present MeshSplatting, a mesh-based reconstruction approach that jointly optimizes geometry and appearance through differentiable rendering. By enforcing connectivity via restricted Delaunay triangulation and refining surface consistency, MeshSplatting creates end-to-end smooth, visually high-quality meshes that render efficiently in real-time 3D engines. On Mip-NeRF360, it boosts PSNR by +0.69 dB over the current state-of-the-art MiLo for mesh-based novel view synthesis, while training 2x faster and using 2x less memory, bridging neural rendering and interactive 3D graphics for seamless real-time scene interaction. The project page is available at https://meshsplatting.github.io/.

</details>


### [65] [SparseCoop: Cooperative Perception with Kinematic-Grounded Queries](https://arxiv.org/abs/2512.06838)
*Jiahao Wang,Zhongwei Jiang,Wenchao Sun,Jiaru Zhong,Haibao Yu,Yuner Zhang,Chenyang Lu,Chuang Zhang,Lei He,Shaobing Xu,Jianqiang Wang*

Main category: cs.CV

TL;DR: SparseCoop是一个完全稀疏的协同感知框架，用于3D检测和跟踪，完全摒弃了中间BEV表示，通过实例查询、粗到精聚合和协同实例去噪实现高效协同感知。


<details>
  <summary>Details</summary>
Motivation: 当前协同感知方法存在通信成本高、缺乏灵活性、几何表示不足等问题。基于BEV特征共享的方法通信成本呈二次方增长，且缺乏跨异步或不同视角的精确对齐灵活性；而稀疏查询方法则存在几何表示不足、融合策略次优和训练不稳定等问题。

Method: 提出SparseCoop框架，包含三个创新：1) 基于运动学的实例查询，使用包含3D几何和速度的显式状态向量进行精确时空对齐；2) 粗到精聚合模块实现鲁棒融合；3) 协同实例去噪任务加速和稳定训练。完全摒弃中间BEV表示。

Result: 在V2X-Seq和Griffin数据集上达到最先进性能，具有优越的计算效率、低传输成本和强大的通信延迟鲁棒性。

Conclusion: SparseCoop通过完全稀疏的协同感知框架，解决了现有方法的通信成本、灵活性和训练稳定性问题，在保持高性能的同时实现了高效计算和低通信开销。

Abstract: Cooperative perception is critical for autonomous driving, overcoming the inherent limitations of a single vehicle, such as occlusions and constrained fields-of-view. However, current approaches sharing dense Bird's-Eye-View (BEV) features are constrained by quadratically-scaling communication costs and the lack of flexibility and interpretability for precise alignment across asynchronous or disparate viewpoints. While emerging sparse query-based methods offer an alternative, they often suffer from inadequate geometric representations, suboptimal fusion strategies, and training instability. In this paper, we propose SparseCoop, a fully sparse cooperative perception framework for 3D detection and tracking that completely discards intermediate BEV representations. Our framework features a trio of innovations: a kinematic-grounded instance query that uses an explicit state vector with 3D geometry and velocity for precise spatio-temporal alignment; a coarse-to-fine aggregation module for robust fusion; and a cooperative instance denoising task to accelerate and stabilize training. Experiments on V2X-Seq and Griffin datasets show SparseCoop achieves state-of-the-art performance. Notably, it delivers this with superior computational efficiency, low transmission cost, and strong robustness to communication latency. Code is available at https://github.com/wang-jh18-SVM/SparseCoop.

</details>


### [66] [CADE: Continual Weakly-supervised Video Anomaly Detection with Ensembles](https://arxiv.org/abs/2512.06840)
*Satoshi Hashimoto,Tatsuya Konishi,Tomoya Kaichi,Kazunori Matsumoto,Mori Kurokawa*

Main category: cs.CV

TL;DR: 该论文提出了CADE方法，首次将持续学习与弱监督视频异常检测相结合，通过双生成器和多判别器集成解决数据不平衡、标签不确定性和遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测方法主要针对静态数据集，忽视了数据域可能变化的问题。当数据域发生变化时，仅用新数据训练会导致对先前数据的性能下降（遗忘），因此需要从持续学习的角度来解决这一问题。

Method: 提出CADE方法，包含两个核心组件：1）双生成器解决WVAD中的数据不平衡和标签不确定性；2）多判别器集成来捕捉因遗忘而错过的过去场景中的异常模式，缓解模型偏向特定异常模式导致的"不完整性"问题。

Result: 在ShanghaiTech和Charlotte Anomaly等多场景VAD数据集上的大量实验表明，CADE显著优于现有的视频异常检测方法。

Conclusion: CADE是首个将持续学习与弱监督视频异常检测相结合的工作，通过双生成器和多判别器集成有效解决了数据域变化时的遗忘问题，提升了多场景异常检测性能。

Abstract: Video anomaly detection (VAD) has long been studied as a crucial problem in public security and crime prevention. In recent years, weakly-supervised VAD (WVAD) have attracted considerable attention due to their easy annotation process and promising research results. While existing WVAD methods tackle mainly on static datasets, the possibility that the domain of data can vary has been neglected. To adapt such domain-shift, the continual learning (CL) perspective is required because otherwise additional training only with new coming data could easily cause performance degradation for previous data, i.e., forgetting. Therefore, we propose a brand-new approach, called Continual Anomaly Detection with Ensembles (CADE) that is the first work combining CL and WVAD viewpoints. Specifically, CADE uses the Dual-Generator(DG) to address data imbalance and label uncertainty in WVAD. We also found that forgetting exacerbates the "incompleteness'' where the model becomes biased towards certain anomaly modes, leading to missed detections of various anomalies. To address this, we propose to ensemble Multi-Discriminator (MD) that capture missed anomalies in past scenes due to forgetting, using multiple models. Extensive experiments show that CADE significantly outperforms existing VAD methods on the common multi-scene VAD datasets, such as ShanghaiTech and Charlotte Anomaly datasets.

</details>


### [67] [Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior](https://arxiv.org/abs/2512.06866)
*Yulin Li,Haokun Gui,Ziyang Fan,Junjie Wang,Bin Kang,Bin Chen,Zhuotao Tian*

Main category: cs.CV

TL;DR: DyToK是一种无需训练的VLLM动态令牌压缩方法，利用VLLM注意力机制中的关键帧先验，动态调整每帧令牌保留比例，在保持准确性的同时显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在处理长视频时面临二次计算复杂度增长的问题，而传统关键帧采样方法在特征编码前引入额外计算成本，且二元帧选择范式不够优化。

Method: 提出DyToK方法，利用VLLM注意力层自然编码的查询条件关键帧先验，动态调整每帧令牌保留比例，优先保留语义丰富的帧同时抑制冗余信息。

Result: DyToK实现了最先进的效率-准确性权衡，与现有压缩方法兼容，在LLaVA-OneVision和Qwen2.5-VL等多个VLLM上实现4.3倍推理加速同时保持准确性。

Conclusion: DyToK提供了一种无需训练的动态令牌压缩范式，有效解决了VLLM处理长视频时的计算效率瓶颈，具有即插即用兼容性。

Abstract: Recent advances in Video Large Language Models (VLLMs) have achieved remarkable video understanding capabilities, yet face critical efficiency bottlenecks due to quadratic computational growth with lengthy visual token sequences of long videos. While existing keyframe sampling methods can improve temporal modeling efficiency, additional computational cost is introduced before feature encoding, and the binary frame selection paradigm is found suboptimal. Therefore, in this work, we propose Dynamic Token compression via LLM-guided Keyframe prior (DyToK), a training-free paradigm that enables dynamic token compression by harnessing VLLMs' inherent attention mechanisms. Our analysis reveals that VLLM attention layers naturally encoding query-conditioned keyframe priors, by which DyToK dynamically adjusts per-frame token retention ratios, prioritizing semantically rich frames while suppressing redundancies. Extensive experiments demonstrate that DyToK achieves state-of-the-art efficiency-accuracy tradeoffs. DyToK shows plug-and-play compatibility with existing compression methods, such as VisionZip and FastV, attaining 4.3x faster inference while preserving accuracy across multiple VLLMs, such as LLaVA-OneVision and Qwen2.5-VL. Code is available at https://github.com/yu-lin-li/DyToK .

</details>


### [68] [Pseudo Anomalies Are All You Need: Diffusion-Based Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2512.06845)
*Satoshi Hashimoto,Hitoshi Nishimura,Yanan Wang,Mori Kurokawa*

Main category: cs.CV

TL;DR: PA-VAD：一种无需真实异常视频的生成驱动视频异常检测方法，通过合成伪异常视频与真实正常视频配对训练，在标准弱监督设置下达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 实际部署视频异常检测面临真实异常视频稀缺且收集成本高的问题，需要一种无需真实异常数据就能训练高性能检测器的方法。

Method: 1）使用CLIP选择类别相关初始图像，通过视觉语言模型优化文本提示，调用视频扩散模型合成伪异常视频；2）通过域对齐正则化模块缓解合成异常中的过度时空幅度问题，结合域对齐和内存使用感知更新。

Result: 在ShanghaiTech数据集上达到98.2%，在UCF-Crime上达到82.5%，分别比最强的真实异常方法高+0.6%，比UVAD SOTA方法高+1.9%。

Conclusion: 无需收集真实异常即可获得高精度异常检测，为可扩展部署提供了实用路径。

Abstract: Deploying video anomaly detection in practice is hampered by the scarcity and collection cost of real abnormal footage. We address this by training without any real abnormal videos while evaluating under the standard weakly supervised split, and we introduce PA-VAD, a generation-driven approach that learns a detector from synthesized pseudo-abnormal videos paired with real normal videos, using only a small set of real normal images to drive synthesis. For synthesis, we select class-relevant initial images with CLIP and refine textual prompts with a vision-language model to improve fidelity and scene consistency before invoking a video diffusion model. For training, we mitigate excessive spatiotemporal magnitude in synthesized anomalies by an domain-aligned regularized module that combines domain alignment and memory usage-aware updates. Extensive experiments show that our approach reaches 98.2% on ShanghaiTech and 82.5% on UCF-Crime, surpassing the strongest real-abnormal method on ShanghaiTech by +0.6% and outperforming the UVAD state-of-the-art on UCF-Crime by +1.9%. The results demonstrate that high-accuracy anomaly detection can be obtained without collecting real anomalies, providing a practical path toward scalable deployment.

</details>


### [69] [Hide-and-Seek Attribution: Weakly Supervised Segmentation of Vertebral Metastases in CT](https://arxiv.org/abs/2512.06849)
*Matan Atad,Alexander W. Marka,Lisa Steinhelfer,Anna Curto-Vilalta,Yannik Leonhardt,Sarah C. Foreman,Anna-Sophia Walburga Dietrich,Robert Graf,Alexandra S. Gersing,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke,Hendrik Möller*

Main category: cs.CV

TL;DR: 提出了一种弱监督方法，仅使用椎体级别的健康/恶性标签（无需病灶掩码）来分割CT中的椎体转移灶，通过扩散自编码器生成健康编辑图像，结合像素级差异图和"捉迷藏"归因技术实现准确分割。


<details>
  <summary>Details</summary>
Motivation: CT中椎体转移灶的准确分割在临床上很重要但难以规模化，因为体素级标注稀缺，且溶骨性和成骨性病变常与良性退行性变化相似。

Method: 结合扩散自编码器（DAE）生成椎体的健康编辑图像，使用像素级差异图提出候选病灶区域，引入"捉迷藏归因"技术：依次揭示每个候选区域并隐藏其他区域，通过DAE将编辑图像投影回数据流形，使用潜在空间分类器量化该组件的孤立恶性贡献，高评分区域形成最终的分割结果。

Result: 在保留的放射科医生标注上，尽管没有掩码监督，仍实现了强大的成骨性/溶骨性性能（F1：0.91/0.85；Dice：0.87/0.78），超过了基线方法（F1：0.79/0.67；Dice：0.74/0.55）。

Conclusion: 椎体级别的标签可以转化为可靠的病灶掩码，表明生成式编辑结合选择性遮挡支持CT中准确的弱监督分割。

Abstract: Accurate segmentation of vertebral metastasis in CT is clinically important yet difficult to scale, as voxel-level annotations are scarce and both lytic and blastic lesions often resemble benign degenerative changes. We introduce a weakly supervised method trained solely on vertebra-level healthy/malignant labels, without any lesion masks. The method combines a Diffusion Autoencoder (DAE) that produces a classifier-guided healthy edit of each vertebra with pixel-wise difference maps that propose candidate lesion regions. To determine which regions truly reflect malignancy, we introduce Hide-and-Seek Attribution: each candidate is revealed in turn while all others are hidden, the edited image is projected back to the data manifold by the DAE, and a latent-space classifier quantifies the isolated malignant contribution of that component. High-scoring regions form the final lytic or blastic segmentation. On held-out radiologist annotations, we achieve strong blastic/lytic performance despite no mask supervision (F1: 0.91/0.85; Dice: 0.87/0.78), exceeding baselines (F1: 0.79/0.67; Dice: 0.74/0.55). These results show that vertebra-level labels can be transformed into reliable lesion masks, demonstrating that generative editing combined with selective occlusion supports accurate weakly supervised segmentation in CT.

</details>


### [70] [JoPano: Unified Panorama Generation via Joint Modeling](https://arxiv.org/abs/2512.06885)
*Wancheng Feng,Chen An,Zhenliang He,Meina Kan,Shiguang Shan,Lukun Wang*

Main category: cs.CV

TL;DR: JoPano提出了一种基于DiT的统一全景图生成方法，通过联合面适配器和条件切换机制，将文本到全景图和视图到全景图两个核心任务整合到单一模型中，解决了现有方法视觉质量受限和建模冗余的问题。


<details>
  <summary>Details</summary>
Motivation: 现有全景图生成方法面临两个主要挑战：1）基于U-Net的架构限制了生成全景图的视觉质量；2）通常将文本到全景图和视图到全景图两个核心任务独立处理，导致建模冗余和效率低下。

Method: 1）提出基于DiT的联合面全景图生成方法；2）设计联合面适配器，利用全景图的立方体贴图表示，使预训练DiT能够联合建模和生成全景图的不同视图；3）应用泊松融合减少立方体面边界处的接缝不一致；4）引入接缝一致性评估指标Seam-SSIM和Seam-Sobel；5）提出条件切换机制，在单一模型中统一文本到全景图和视图到全景图任务。

Result: JoPano在文本到全景图和视图到全景图生成任务中都能生成高质量的全景图，在FID、CLIP-FID、IS和CLIP-Score等指标上达到了最先进的性能。

Conclusion: JoPano通过统一架构解决了现有全景图生成方法的局限性，实现了高质量的全景图生成，并为两个核心任务提供了高效的解决方案。

Abstract: Panorama generation has recently attracted growing interest in the research community, with two core tasks, text-to-panorama and view-to-panorama generation. However, existing methods still face two major challenges: their U-Net-based architectures constrain the visual quality of the generated panoramas, and they usually treat the two core tasks independently, which leads to modeling redundancy and inefficiency. To overcome these challenges, we propose a joint-face panorama (JoPano) generation approach that unifies the two core tasks within a DiT-based model. To transfer the rich generative capabilities of existing DiT backbones learned from natural images to the panorama domain, we propose a Joint-Face Adapter built on the cubemap representation of panoramas, which enables a pretrained DiT to jointly model and generate different views of a panorama. We further apply Poisson Blending to reduce seam inconsistencies that often appear at the boundaries between cube faces. Correspondingly, we introduce Seam-SSIM and Seam-Sobel metrics to quantitatively evaluate the seam consistency. Moreover, we propose a condition switching mechanism that unifies text-to-panorama and view-to-panorama tasks within a single model. Comprehensive experiments show that JoPano can generate high-quality panoramas for both text-to-panorama and view-to-panorama generation tasks, achieving state-of-the-art performance on FID, CLIP-FID, IS, and CLIP-Score metrics.

</details>


### [71] [Omni-Referring Image Segmentation](https://arxiv.org/abs/2512.06862)
*Qiancheng Zheng,Yunhang Shen,Gen Luo,Baiyang Song,Xing Sun,Xiaoshuai Sun,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出Omni-Referring Image Segmentation (OmniRIS)任务，支持文本指令和带掩码/框/涂鸦的参考图像作为全方位提示，实现高度泛化的图像分割。


<details>
  <summary>Details</summary>
Motivation: 现有单模态条件分割任务（如RIS和视觉RIS）无法充分利用文本和视觉模态的各自优势。文本模态擅长细粒度属性指代，视觉模态擅长罕见对象定位，需要一种能同时利用两种模态优势的通用分割方法。

Method: 1) 提出OmniRIS任务框架，支持文本指令和带掩码/框/涂鸦的参考图像作为全方位提示；2) 构建大型数据集OmniRef，包含30,956张图像的186,939个全方位提示；3) 设计强基线模型OmniSegNet，解决全方位提示编码等关键挑战。

Result: 实验验证了OmniSegNet能够有效遵循全方位模态指令，并展示了OmniRIS在高度泛化图像分割方面的优越性。构建的数据集和评估系统为相关研究提供了基础。

Conclusion: OmniRIS通过结合文本和视觉模态的优势，实现了高度泛化的图像分割，支持多种分割设置，具有重要的实际应用价值。提出的数据集、评估系统和基线模型为该领域的研究奠定了基础。

Abstract: In this paper, we propose a novel task termed Omni-Referring Image Segmentation (OmniRIS) towards highly generalized image segmentation. Compared with existing unimodally conditioned segmentation tasks, such as RIS and visual RIS, OmniRIS supports the input of text instructions and reference images with masks, boxes or scribbles as omni-prompts. This property makes it can well exploit the intrinsic merits of both text and visual modalities, i.e., granular attribute referring and uncommon object grounding, respectively. Besides, OmniRIS can also handle various segmentation settings, such as one v.s. many and many v.s. many, further facilitating its practical use. To promote the research of OmniRIS, we also rigorously design and construct a large dataset termed OmniRef, which consists of 186,939 omni-prompts for 30,956 images, and establish a comprehensive evaluation system. Moreover, a strong and general baseline termed OmniSegNet is also proposed to tackle the key challenges of OmniRIS, such as omni-prompt encoding. The extensive experiments not only validate the capability of OmniSegNet in following omni-modal instructions, but also show the superiority of OmniRIS for highly generalized image segmentation.

</details>


### [72] [NeuroABench: A Multimodal Evaluation Benchmark for Neurosurgical Anatomy Identification](https://arxiv.org/abs/2512.06921)
*Ziyang Song,Zelin Zang,Xiaofan Ye,Boqiang Xu,Long Bai,Jinlin Wu,Hongliang Ren,Hongbin Liu,Jiebo Luo,Zhen Lei*

Main category: cs.CV

TL;DR: 该研究提出了首个神经外科解剖学理解多模态基准测试NeuroABench，包含9小时标注视频，评估68个解剖结构识别，发现当前最佳MLLM模型准确率仅40.87%，远低于神经外科学员平均46.5%的水平。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM研究主要关注手术流程理解，忽视了临床实践中至关重要的解剖学理解能力。神经外科医生依赖精确的解剖知识来解读手术视频，但缺乏专门评估解剖学理解的多模态基准。

Method: 提出了NeuroABench基准，包含9小时标注的神经外科视频，涵盖89种不同手术。采用新颖的多模态标注流程和多重审核循环，评估68个临床解剖结构的识别能力。

Result: 测试了10多个SOTA MLLM模型，最佳模型在解剖识别任务中仅达到40.87%准确率。神经外科学员测试结果显示：最佳学员56%，最低28%，平均46.5%。最佳MLLM表现与最低分学员相当，但显著低于学员平均水平。

Conclusion: MLLM在解剖学理解方面已取得进展，但与人类水平仍有显著差距。NeuroABench为评估和改进MLLM的解剖学理解能力提供了标准化框架，对推进手术教育和辅助具有重要意义。

Abstract: Multimodal Large Language Models (MLLMs) have shown significant potential in surgical video understanding. With improved zero-shot performance and more effective human-machine interaction, they provide a strong foundation for advancing surgical education and assistance. However, existing research and datasets primarily focus on understanding surgical procedures and workflows, while paying limited attention to the critical role of anatomical comprehension. In clinical practice, surgeons rely heavily on precise anatomical understanding to interpret, review, and learn from surgical videos. To fill this gap, we introduce the Neurosurgical Anatomy Benchmark (NeuroABench), the first multimodal benchmark explicitly created to evaluate anatomical understanding in the neurosurgical domain. NeuroABench consists of 9 hours of annotated neurosurgical videos covering 89 distinct procedures and is developed using a novel multimodal annotation pipeline with multiple review cycles. The benchmark evaluates the identification of 68 clinical anatomical structures, providing a rigorous and standardized framework for assessing model performance. Experiments on over 10 state-of-the-art MLLMs reveal significant limitations, with the best-performing model achieving only 40.87% accuracy in anatomical identification tasks. To further evaluate the benchmark, we extract a subset of the dataset and conduct an informative test with four neurosurgical trainees. The results show that the best-performing student achieves 56% accuracy, with the lowest scores of 28% and an average score of 46.5%. While the best MLLM performs comparably to the lowest-scoring student, it still lags significantly behind the group's average performance. This comparison underscores both the progress of MLLMs in anatomical understanding and the substantial gap that remains in achieving human-level performance.

</details>


### [73] [Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training](https://arxiv.org/abs/2512.06864)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS是一个无监督视频实例分割框架，通过质量引导的自训练方法，在不需要人工标注的情况下实现了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 视频实例分割面临像素级掩码和时间一致性标注的双重挑战。现有无监督方法如VideoCutLER虽然通过合成数据消除了光流依赖，但仍受限于合成到真实域的差距。

Method: 提出质量引导的自训练框架，在伪标签生成和自动质量评估之间建立闭环系统，实现从合成视频到真实视频的渐进式适应。

Result: 在YouTubeVIS-2019验证集上达到52.6 AP50，比之前的SOTA方法VideoCutLER提升4.4%，且不需要任何人工标注。

Conclusion: 证明了质量感知自训练在无监督视频实例分割中的可行性，为克服合成到真实域差距提供了有效解决方案。

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due to its dual requirements of pixel-level masks and temporal consistency labels. While recent unsupervised methods like VideoCutLER eliminate optical flow dependencies through synthetic data, they remain constrained by the synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised framework that bridges this gap through quality-guided self-training. Our approach establishes a closed-loop system between pseudo-label generation and automatic quality assessment, enabling progressive adaptation from synthetic to real videos. Experiments demonstrate state-of-the-art performance with 52.6 $\text{AP}_{50}$ on YouTubeVIS-2019 $\texttt{val}$ set, surpassing the previous state-of-the-art VideoCutLER by 4.4%, while requiring no human annotations. This demonstrates the viability of quality-aware self-training for unsupervised VIS. We will release the code at https://github.com/wcbup/AutoQ-VIS.

</details>


### [74] [Spatial Retrieval Augmented Autonomous Driving](https://arxiv.org/abs/2512.06865)
*Xiaosong Jia,Chenhe Zhang,Yule Jiang,Songbur Wong,Zhiyuan Zhang,Chen Chen,Shaofeng Zhang,Xuanhe Zhou,Xue Yang,Junchi Yan,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 论文提出空间检索范式，通过引入离线检索的地理图像作为额外输入，增强自动驾驶系统的感知能力，特别是在视野受限、遮挡或极端条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统依赖车载传感器进行环境感知，但受限于实时感知范围，在视野受限、遮挡、黑暗或雨天等极端条件下表现不佳。人类驾驶员能够在能见度差时回忆道路结构，因此希望赋予模型这种"回忆"能力。

Method: 提出空间检索范式，从离线缓存（如Google Maps或存储的自动驾驶数据集）中检索地理图像作为额外输入。扩展nuScenes数据集，通过Google Maps API检索地理图像并与自车轨迹对齐。在五个核心自动驾驶任务上建立基准：目标检测、在线建图、占用预测、端到端规划和生成式世界建模。

Result: 大量实验表明，扩展的模态能够提升某些任务的性能。论文将开源数据集构建代码、数据和基准，供进一步研究这一新的自动驾驶范式。

Conclusion: 空间检索范式为自动驾驶系统提供了"回忆"能力，通过引入离线地理图像作为额外输入，能够增强系统在视野受限和极端条件下的感知性能，且无需额外传感器，可作为现有AD任务的即插即用扩展。

Abstract: Existing autonomous driving systems rely on onboard sensors (cameras, LiDAR, IMU, etc) for environmental perception. However, this paradigm is limited by the drive-time perception horizon and often fails under limited view scope, occlusion or extreme conditions such as darkness and rain. In contrast, human drivers are able to recall road structure even under poor visibility. To endow models with this ``recall" ability, we propose the spatial retrieval paradigm, introducing offline retrieved geographic images as an additional input. These images are easy to obtain from offline caches (e.g, Google Maps or stored autonomous driving datasets) without requiring additional sensors, making it a plug-and-play extension for existing AD tasks.
  For experiments, we first extend the nuScenes dataset with geographic images retrieved via Google Maps APIs and align the new data with ego-vehicle trajectories. We establish baselines across five core autonomous driving tasks: object detection, online mapping, occupancy prediction, end-to-end planning, and generative world modeling. Extensive experiments show that the extended modality could enhance the performance of certain tasks. We will open-source dataset curation code, data, and benchmarks for further study of this new autonomous driving paradigm.

</details>


### [75] [Towards Robust Pseudo-Label Learning in Semantic Segmentation: An Encoding Perspective](https://arxiv.org/abs/2512.06870)
*Wangkai Li,Rui Sun,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: ECOCSeg提出了一种基于纠错输出码的语义分割新方法，通过细粒度编码和位级标签去噪机制，有效解决了伪标签学习中的错误传播问题，在无监督域适应和半监督学习基准上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 伪标签学习在语义分割中广泛应用，特别是在标签稀缺的场景如无监督域适应和半监督学习中。然而，这种范式会产生错误的伪标签，并且由于使用one-hot编码，这些错误在训练过程中会被进一步放大。需要一种方法来处理伪标签中的错误，提高模型的稳定性和泛化能力。

Method: 提出了ECOCSeg方法，基于纠错输出码为每个类别创建细粒度编码。主要包含两个核心组件：1) 基于ECOC的分类器，将类别解耦为属性，能够处理部分不准确的比特位；2) 位级标签去噪机制，生成更高质量的伪标签。该方法可以轻松集成到现有方法中。

Result: ECOCSeg在多个无监督域适应和半监督学习基准测试中，与不同的分割架构结合，都表现出显著的性能改进。代码已开源。

Conclusion: ECOCSeg通过纠错输出码提供了一种新颖的语义分割视角，能够有效处理伪标签学习中的错误传播问题，提高模型的稳定性和泛化能力，在标签稀缺场景下表现出优越性能。

Abstract: Pseudo-label learning is widely used in semantic segmentation, particularly in label-scarce scenarios such as unsupervised domain adaptation (UDA) and semisupervised learning (SSL). Despite its success, this paradigm can generate erroneous pseudo-labels, which are further amplified during training due to utilization of one-hot encoding. To address this issue, we propose ECOCSeg, a novel perspective for segmentation models that utilizes error-correcting output codes (ECOC) to create a fine-grained encoding for each class. ECOCSeg offers several advantages. First, an ECOC-based classifier is introduced, enabling model to disentangle classes into attributes and handle partial inaccurate bits, improving stability and generalization in pseudo-label learning. Second, a bit-level label denoising mechanism is developed to generate higher-quality pseudo-labels, providing adequate and robust supervision for unlabeled images. ECOCSeg can be easily integrated with existing methods and consistently demonstrates significant improvements on multiple UDA and SSL benchmarks across different segmentation architectures. Code is available at https://github.com/Woof6/ECOCSeg.

</details>


### [76] [SceneMixer: Exploring Convolutional Mixing Networks for Remote Sensing Scene Classification](https://arxiv.org/abs/2512.06877)
*Mohammed Q. Alkhatib,Ali Jamali,Swalpa Kumar Roy*

Main category: cs.CV

TL;DR: 本文提出了一种基于卷积混合器范式的轻量级遥感场景分类架构，通过多尺度深度卷积和逐点操作交替进行空间和通道混合，在保持低参数和计算量的同时有效提取局部和上下文信息。


<details>
  <summary>Details</summary>
Motivation: 遥感场景分类在地球观测中至关重要，但现有CNN和ViT模型在空间分辨率、视角、方向和背景条件变化下泛化能力有限，需要更高效且鲁棒的解决方案。

Method: 采用卷积混合器架构，交替使用多尺度深度卷积进行空间混合和逐点操作进行通道混合，在保持轻量化的同时有效提取局部和上下文特征。

Result: 在AID数据集上获得74.7%总体准确率、74.57%平均准确率和73.79 Kappa值；在EuroSAT数据集上获得93.90%总体准确率、93.93%平均准确率和93.22 Kappa值。

Conclusion: 提出的方法在准确性和效率之间取得了良好平衡，相比广泛使用的CNN和transformer模型表现出色，代码将在GitHub上公开。

Abstract: Remote sensing scene classification plays a key role in Earth observation by enabling the automatic identification of land use and land cover (LULC) patterns from aerial and satellite imagery. Despite recent progress with convolutional neural networks (CNNs) and vision transformers (ViTs), the task remains challenging due to variations in spatial resolution, viewpoint, orientation, and background conditions, which often reduce the generalization ability of existing models. To address these challenges, this paper proposes a lightweight architecture based on the convolutional mixer paradigm. The model alternates between spatial mixing through depthwise convolutions at multiple scales and channel mixing through pointwise operations, enabling efficient extraction of both local and contextual information while keeping the number of parameters and computations low. Extensive experiments were conducted on the AID and EuroSAT benchmarks. The proposed model achieved overall accuracy, average accuracy, and Kappa values of 74.7%, 74.57%, and 73.79 on the AID dataset, and 93.90%, 93.93%, and 93.22 on EuroSAT, respectively. These results demonstrate that the proposed approach provides a good balance between accuracy and efficiency compared with widely used CNN- and transformer-based models. Code will be publicly available on: https://github.com/mqalkhatib/SceneMixer

</details>


### [77] [Hierarchical Image-Guided 3D Point Cloud Segmentation in Industrial Scenes via Multi-View Bayesian Fusion](https://arxiv.org/abs/2512.06882)
*Yu Zhu,Naoya Chiba,Koichi Hashimoto*

Main category: cs.CV

TL;DR: 提出分层图像引导的3D分割框架，通过实例级到部件级的渐进式分割，解决工业场景中遮挡严重、物体尺度差异大的3D分割难题。


<details>
  <summary>Details</summary>
Motivation: 工业环境中密集布局和多尺度物体的复杂场景对3D分割提出挑战：严重遮挡削弱几何边界，尺度差异导致端到端模型难以同时捕捉粗粒度和细粒度细节。现有方法存在标注成本高或跨视图语义不一致的问题。

Method: 分层图像引导框架：1) 实例分割：渲染俯视图，用YOLO-World提示SAM生成掩码，投影回3D点云；2) 部件级分割：对每个实例渲染多视图图像，在各视图重复2D分割和反向投影，通过贝叶斯更新融合确保跨视图语义一致性。

Result: 在真实工厂数据上的实验表明，该方法能有效处理遮挡和结构复杂性，获得一致高的每类mIoU分数。在公共数据集上的额外评估证实了框架的泛化能力，突显其鲁棒性、标注效率和适应多样化3D环境的能力。

Conclusion: 提出的分层图像引导3D分割框架通过渐进式从实例到部件的分割策略，有效解决了工业场景中的遮挡和尺度差异问题，实现了高效、鲁棒且可泛化的3D分割。

Abstract: Reliable 3D segmentation is critical for understanding complex scenes with dense layouts and multi-scale objects, as commonly seen in industrial environments. In such scenarios, heavy occlusion weakens geometric boundaries between objects, and large differences in object scale will cause end-to-end models fail to capture both coarse and fine details accurately. Existing 3D point-based methods require costly annotations, while image-guided methods often suffer from semantic inconsistencies across views. To address these challenges, we propose a hierarchical image-guided 3D segmentation framework that progressively refines segmentation from instance-level to part-level. Instance segmentation involves rendering a top-view image and projecting SAM-generated masks prompted by YOLO-World back onto the 3D point cloud. Part-level segmentation is subsequently performed by rendering multi-view images of each instance obtained from the previous stage and applying the same 2D segmentation and back-projection process at each view, followed by Bayesian updating fusion to ensure semantic consistency across views. Experiments on real-world factory data demonstrate that our method effectively handles occlusion and structural complexity, achieving consistently high per-class mIoU scores. Additional evaluations on public dataset confirm the generalization ability of our framework, highlighting its robustness, annotation efficiency, and adaptability to diverse 3D environments.

</details>


### [78] [Balanced Learning for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2512.06886)
*Wangkai Li,Rui Sun,Bohao Liao,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: BLDA提出了一种平衡学习方法来解决无监督域自适应语义分割中的类别不平衡问题，通过分析预测logits分布来识别过预测和欠预测类别，使用共享锚点分布对齐logits，并在损失函数中加入logits校正项来生成无偏伪标签。


<details>
  <summary>Details</summary>
Motivation: 在无监督域自适应语义分割中，由于类别不平衡和域间数据/标签空间分布偏移，自训练方法难以平衡地学习各个类别。现有方法缺乏直接评估和缓解类别偏差的机制，且通常需要先验的分布偏移知识。

Method: 1) 通过分析预测logits分布识别过预测和欠预测类别；2) 使用共享锚点分布对logits分布进行后处理对齐；3) 在线估计logits分布并在损失函数中加入logits校正项以生成无偏伪标签；4) 利用累积密度作为域共享结构知识连接源域和目标域。

Result: 在两个标准UDA语义分割基准上的大量实验表明，BLDA在集成到多种现有方法中时能持续提升性能，特别是对欠预测类别的改进效果显著。

Conclusion: BLDA提供了一种无需先验分布偏移知识的有效方法来直接评估和缓解类别偏差，通过平衡学习策略改善了无监督域自适应语义分割的性能，特别是在处理类别不平衡问题上表现出色。

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to transfer knowledge from a labeled source domain to an unlabeled target domain. Despite the effectiveness of self-training techniques in UDA, they struggle to learn each class in a balanced manner due to inherent class imbalance and distribution shift in both data and label space between domains. To address this issue, we propose Balanced Learning for Domain Adaptation (BLDA), a novel approach to directly assess and alleviate class bias without requiring prior knowledge about the distribution shift. First, we identify over-predicted and under-predicted classes by analyzing the distribution of predicted logits. Subsequently, we introduce a post-hoc approach to align the logits distributions across different classes using shared anchor distributions. To further consider the network's need to generate unbiased pseudo-labels during self-training, we estimate logits distributions online and incorporate logits correction terms into the loss function. Moreover, we leverage the resulting cumulative density as domain-shared structural knowledge to connect the source and target domains. Extensive experiments on two standard UDA semantic segmentation benchmarks demonstrate that BLDA consistently improves performance, especially for under-predicted classes, when integrated into various existing methods. Code is available at https://github.com/Woof6/BLDA.

</details>


### [79] [Overcoming Small Data Limitations in Video-Based Infant Respiration Estimation](https://arxiv.org/abs/2512.06888)
*Liyang Song,Hardik Bishnoi,Sai Kumar Reddy Manne,Sarah Ostadabbas,Briana J. Taylor,Michael Wan*

Main category: cs.CV

TL;DR: 开发首个可复现的婴儿呼吸监测系统，包括400个视频的数据集和基于计算机视觉的呼吸估计算法，用于早期检测婴儿呼吸异常。


<details>
  <summary>Details</summary>
Motivation: 婴儿呼吸异常与神经发育障碍和婴儿猝死综合征相关，但现有呼吸监测技术主要针对成人，缺乏专门针对婴儿的公共视频数据集和可复现算法。

Method: 1) 创建包含400个视频的婴儿呼吸数据集(AIR-400)，其中275个为新采集的标注视频；2) 开发基于婴儿特定感兴趣区域检测和时空神经处理的呼吸估计算法，结合光流输入增强；3) 建立可复现的基准测试流程。

Result: 建立了首个可复现的婴儿呼吸估计基准，提供了完整的公开数据集、代码库和训练模型，填补了婴儿无接触呼吸监测领域的空白。

Conclusion: 该研究为婴儿无接触呼吸监测提供了首个完整的解决方案，包括数据集、算法和基准，有望推动婴儿呼吸异常的早期检测和治疗。

Abstract: The development of contactless respiration monitoring for infants could enable advances in the early detection and treatment of breathing irregularities, which are associated with neurodevelopmental impairments and conditions like sudden infant death syndrome (SIDS). But while respiration estimation for adults is supported by a robust ecosystem of computer vision algorithms and video datasets, only one small public video dataset with annotated respiration data for infant subjects exists, and there are no reproducible algorithms which are effective for infants. We introduce the annotated infant respiration dataset of 400 videos (AIR-400), contributing 275 new, carefully annotated videos from 10 recruited subjects to the public corpus. We develop the first reproducible pipelines for infant respiration estimation, based on infant-specific region-of-interest detection and spatiotemporal neural processing enhanced by optical flow inputs. We establish, through comprehensive experiments, the first reproducible benchmarks for the state-of-the-art in vision-based infant respiration estimation. We make our dataset, code repository, and trained models available for public use.

</details>


### [80] [Scaling Zero-Shot Reference-to-Video Generation](https://arxiv.org/abs/2512.06905)
*Zijian Zhou,Shikun Liu,Haozhe Liu,Haonan Qiu,Zhaochong An,Weiming Ren,Zhiheng Liu,Xiaoke Huang,Kam Woh Ng,Tian Xie,Xiao Han,Yuren Cong,Hang Li,Chuyan Zhu,Aditya Patel,Tao Xiang,Sen He*

Main category: cs.CV

TL;DR: Saber是一个无需显式参考图像-视频-文本三元组数据的零样本参考到视频生成框架，通过掩码训练策略和注意力模型设计实现身份一致性和参考感知表示


<details>
  <summary>Details</summary>
Motivation: 当前参考到视频生成方法依赖昂贵的显式参考图像-视频-文本三元组数据，这些数据的构建成本高且难以扩展，需要绕过这一瓶颈

Method: 提出Saber框架，仅使用视频-文本对进行训练，采用掩码训练策略和定制的基于注意力的模型设计，学习身份一致和参考感知的表示，并集成掩码增强技术减少复制粘贴伪影

Result: 在OpenS2V-Eval基准测试中表现优于使用R2V数据训练的方法，展示了在不同数量参考图像下的出色泛化能力

Conclusion: Saber提供了一个可扩展的零样本参考到视频生成框架，无需昂贵的显式三元组数据，通过创新的训练策略和模型设计实现了高质量的视频生成

Abstract: Reference-to-video (R2V) generation aims to synthesize videos that align with a text prompt while preserving the subject identity from reference images. However, current R2V methods are hindered by the reliance on explicit reference image-video-text triplets, whose construction is highly expensive and difficult to scale. We bypass this bottleneck by introducing Saber, a scalable zero-shot framework that requires no explicit R2V data. Trained exclusively on video-text pairs, Saber employs a masked training strategy and a tailored attention-based model design to learn identity-consistent and reference-aware representations. Mask augmentation techniques are further integrated to mitigate copy-paste artifacts common in reference-to-video generation. Moreover, Saber demonstrates remarkable generalization capabilities across a varying number of references and achieves superior performance on the OpenS2V-Eval benchmark compared to methods trained with R2V data.

</details>


### [81] [Power of Boundary and Reflection: Semantic Transparent Object Segmentation using Pyramid Vision Transformer with Transparent Cues](https://arxiv.org/abs/2512.07034)
*Tuan-Anh Vu,Hai Nguyen-Truong,Ziqiang Zheng,Binh-Son Hua,Qing Guo,Ivor Tsang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: TransCues：一种用于透明物体分割的Transformer架构，通过边界特征增强和反射特征增强模块，在多个基准数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 玻璃等透明物体由于透明性和反射特性，现有分割方法难以将其与不透明材料区分。人类感知依赖边界和反射物体特征来识别玻璃，但现有文献未能充分捕捉这两种特性。

Method: 提出TransCues框架，采用金字塔Transformer编码器-解码器架构，包含边界特征增强模块和反射特征增强模块，以相互促进的方式整合这两种视觉线索。

Result: 在多个基准数据集上大幅超越现有方法：Trans10K-v2 (+4.2% mIoU)、MSD (+5.6% mIoU)、RGBD-Mirror (+10.1% mIoU)、TROSD (+13.1% mIoU)、Stanford2D3D (+8.3% mIoU)。

Conclusion: 通过同时利用边界特征和反射特征，TransCues能有效分割透明物体，在多个数据集上取得显著性能提升，证明了该方法对玻璃物体处理的有效性。

Abstract: Glass is a prevalent material among solid objects in everyday life, yet segmentation methods struggle to distinguish it from opaque materials due to its transparency and reflection. While it is known that human perception relies on boundary and reflective-object features to distinguish glass objects, the existing literature has not yet sufficiently captured both properties when handling transparent objects. Hence, we propose incorporating both of these powerful visual cues via the Boundary Feature Enhancement and Reflection Feature Enhancement modules in a mutually beneficial way. Our proposed framework, TransCues, is a pyramidal transformer encoder-decoder architecture to segment transparent objects. We empirically show that these two modules can be used together effectively, improving overall performance across various benchmark datasets, including glass object semantic segmentation, mirror object semantic segmentation, and generic segmentation datasets. Our method outperforms the state-of-the-art by a large margin, achieving +4.2% mIoU on Trans10K-v2, +5.6% mIoU on MSD, +10.1% mIoU on RGBD-Mirror, +13.1% mIoU on TROSD, and +8.3% mIoU on Stanford2D3D, showing the effectiveness of our method against glass objects.

</details>


### [82] [DAUNet: A Lightweight UNet Variant with Deformable Convolutions and Parameter-Free Attention for Medical Image Segmentation](https://arxiv.org/abs/2512.07051)
*Adnan Munir,Shujaat Khan*

Main category: cs.CV

TL;DR: DAUNet是一种轻量级UNet变体，结合可变形卷积和参数自由注意力机制，在医学图像分割任务中实现了更好的空间适应性和上下文感知特征融合，同时保持模型参数高效。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在自动化诊断和治疗规划系统中至关重要。现有模型在处理几何变化和低对比度区域时存在局限性，需要开发既高效又具有强空间适应性的轻量级模型。

Method: 提出DAUNet，集成Deformable V2 Convolutions和Parameter-Free Attention (SimAM)。瓶颈层使用动态可变形核处理几何变化，解码器和跳跃连接路径通过SimAM注意力模块进行显著性感知细化。

Result: 在两个挑战性数据集（FH-PS-AoP超声图像和FUMPE CT肺栓塞检测）上评估，DAUNet在Dice分数、HD95和ASD指标上优于最先进模型，同时保持优越的参数效率。消融研究验证了可变形卷积和SimAM注意力的各自贡献。

Conclusion: DAUNet对缺失上下文和低对比度区域的鲁棒性使其适合在实时和资源受限的临床环境中部署，为医学图像分割提供了高效且性能优越的解决方案。

Abstract: Medical image segmentation plays a pivotal role in automated diagnostic and treatment planning systems. In this work, we present DAUNet, a novel lightweight UNet variant that integrates Deformable V2 Convolutions and Parameter-Free Attention (SimAM) to improve spatial adaptability and context-aware feature fusion without increasing model complexity. DAUNet's bottleneck employs dynamic deformable kernels to handle geometric variations, while the decoder and skip pathways are enhanced using SimAM attention modules for saliency-aware refinement. Extensive evaluations on two challenging datasets, FH-PS-AoP (fetal head and pubic symphysis ultrasound) and FUMPE (CT-based pulmonary embolism detection), demonstrate that DAUNet outperforms state-of-the-art models in Dice score, HD95, and ASD, while maintaining superior parameter efficiency. Ablation studies highlight the individual contributions of deformable convolutions and SimAM attention. DAUNet's robustness to missing context and low-contrast regions establishes its suitability for deployment in real-time and resource-constrained clinical environments.

</details>


### [83] [Selective Masking based Self-Supervised Learning for Image Semantic Segmentation](https://arxiv.org/abs/2512.06981)
*Yuemin Wang,Ian Stavness*

Main category: cs.CV

TL;DR: 提出了一种基于选择性掩码图像重建的自监督学习方法，用于语义分割预训练，相比随机掩码方法在多个数据集上取得更好的下游分割精度。


<details>
  <summary>Details</summary>
Motivation: 大多数掩码图像建模预训练方法使用随机掩码增强，但这种方法可能不是最优的。本文旨在通过选择性掩码策略改进自监督预训练效果，特别是在有限模型容量和计算资源要求的场景下。

Method: 提出选择性掩码图像重建方法，通过迭代步骤将图像重建预训练分解，利用已训练模型的知识选择重建损失最高的图像块进行掩码，而不是随机掩码。

Result: 在两个通用数据集（Pascal VOC和Cityscapes）和两个杂草分割数据集（Nassar 2020和Sugarbeets 2016）上，选择性掩码方法比传统随机掩码方法和监督ImageNet预训练在下游分割精度上分别提升2.9%和2.5%。同时显著改善了最低性能类别的准确性。

Conclusion: 选择性掩码图像重建方法为改进端到端语义分割工作流程提供了有效实用的解决方案，特别适用于需要有限模型容量以满足推理速度和计算资源要求的场景。使用相同的预训练和下游数据集可获得最佳的低预算自监督预训练效果。

Abstract: This paper proposes a novel self-supervised learning method for semantic segmentation using selective masking image reconstruction as the pretraining task. Our proposed method replaces the random masking augmentation used in most masked image modelling pretraining methods. The proposed selective masking method selectively masks image patches with the highest reconstruction loss by breaking the image reconstruction pretraining into iterative steps to leverage the trained model's knowledge. We show on two general datasets (Pascal VOC and Cityscapes) and two weed segmentation datasets (Nassar 2020 and Sugarbeets 2016) that our proposed selective masking method outperforms the traditional random masking method and supervised ImageNet pretraining on downstream segmentation accuracy by 2.9% for general datasets and 2.5% for weed segmentation datasets. Furthermore, we found that our selective masking method significantly improves accuracy for the lowest-performing classes. Lastly, we show that using the same pretraining and downstream dataset yields the best result for low-budget self-supervised pretraining. Our proposed Selective Masking Image Reconstruction method provides an effective and practical solution to improve end-to-end semantic segmentation workflows, especially for scenarios that require limited model capacity to meet inference speed and computational resource requirements.

</details>


### [84] [Evaluating and Preserving High-level Fidelity in Super-Resolution](https://arxiv.org/abs/2512.07037)
*Josep M. Rocafort,Shaolin Su,Javier Vazquez-Corral,Alexandra Gomez-Villa*

Main category: cs.CV

TL;DR: 该论文提出衡量超分辨率模型的高层语义保真度作为补充评价标准，构建首个带保真度标注的数据集，分析现有指标相关性，并展示通过保真度反馈微调可同时提升语义保真度和感知质量。


<details>
  <summary>Details</summary>
Motivation: 当前超分辨率模型虽然能生成视觉质量高的图像，但强大的生成能力有时会产生幻觉，改变图像内容。这种高层语义变化容易被人类识别，但现有低层图像质量指标未能很好衡量。需要建立高层保真度测量作为补充标准，以评估生成式超分辨率模型的可靠性。

Method: 1. 构建首个带保真度标注的超分辨率数据集，包含不同模型生成结果；2. 评估SOTA超分辨率模型在保持高层保真度方面的表现；3. 分析现有图像质量指标与保真度测量的相关性；4. 展示基础模型能更好地处理高层语义任务；5. 基于保真度反馈微调超分辨率模型。

Result: 1. 建立了高层保真度测量作为超分辨率模型的重要补充评价标准；2. 创建了首个带保真度标注的数据集；3. 发现现有图像质量指标与高层保真度相关性不足；4. 基础模型在高层语义任务上表现更好；5. 通过保真度反馈微调可同时提升语义保真度和感知质量。

Conclusion: 高层保真度测量对于评估和优化生成式超分辨率模型具有重要价值，可作为现有低层质量指标的有效补充。通过保真度反馈微调模型能够同时改善语义准确性和视觉质量，展示了该标准在模型评估和优化中的潜在应用价值。

Abstract: Recent image Super-Resolution (SR) models are achieving impressive effects in reconstructing details and delivering visually pleasant outputs. However, the overpowering generative ability can sometimes hallucinate and thus change the image content despite gaining high visual quality. This type of high-level change can be easily identified by humans yet not well-studied in existing low-level image quality metrics. In this paper, we establish the importance of measuring high-level fidelity for SR models as a complementary criterion to reveal the reliability of generative SR models. We construct the first annotated dataset with fidelity scores from different SR models, and evaluate how state-of-the-art (SOTA) SR models actually perform in preserving high-level fidelity. Based on the dataset, we then analyze how existing image quality metrics correlate with fidelity measurement, and further show that this high-level task can be better addressed by foundation models. Finally, by fine-tuning SR models based on our fidelity feedback, we show that both semantic fidelity and perceptual quality can be improved, demonstrating the potential value of our proposed criteria, both in model evaluation and optimization. We will release the dataset, code, and models upon acceptance.

</details>


### [85] [RAVE: Rate-Adaptive Visual Encoding for 3D Gaussian Splatting](https://arxiv.org/abs/2512.07052)
*Hoang-Nhat Tran,Francesco Di Sario,Gabriele Spadaro,Giuseppe Valenzise,Enzo Tartaglione*

Main category: cs.CV

TL;DR: 提出了一种支持任意速率插值的灵活3D高斯泼溅压缩方案，无需重新训练即可适应不同带宽和设备限制


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）虽然能实现实时逼真渲染，但存在内存需求大、训练成本高的问题。现有压缩方法只能在固定速率下工作，无法适应变化的带宽和设备限制

Method: 提出了一种灵活的3DGS压缩方案，支持在预定义边界之间进行任意速率的插值。该方法计算轻量，无需为不同速率重新训练

Result: 实验表明，该方法在广泛的运行点上都能保持渲染质量，实现了高效、高质量的压缩，同时提供动态速率控制

Conclusion: 该方法适合在沉浸式应用中实际部署，代码将在论文接受后开源

Abstract: Recent advances in neural scene representations have transformed immersive multimedia, with 3D Gaussian Splatting (3DGS) enabling real-time photorealistic rendering. Despite its efficiency, 3DGS suffers from large memory requirements and costly training procedures, motivating efforts toward compression. Existing approaches, however, operate at fixed rates, limiting adaptability to varying bandwidth and device constraints. In this work, we propose a flexible compression scheme for 3DGS that supports interpolation at any rate between predefined bounds. Our method is computationally lightweight, requires no retraining for any rate, and preserves rendering quality across a broad range of operating points. Experiments demonstrate that the approach achieves efficient, high-quality compression while offering dynamic rate control, making it suitable for practical deployment in immersive applications. The code will be provided open-source upon acceptance of the work.

</details>


### [86] [A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning](https://arxiv.org/abs/2512.07136)
*Siyang Jiang,Mu Yuan,Xiang Ji,Bufang Yang,Zeyu Liu,Lilin Xu,Yang Li,Yuting He,Liran Dong,Wenrui Lu,Zhenyu Yan,Xiaofan Jiang,Wei Gao,Hongkai Chen,Guoliang Xing*

Main category: cs.CV

TL;DR: CUHK-X是一个大规模多模态数据集和基准套件，用于人类动作识别、理解和推理任务，包含58,445个样本覆盖40个动作，解决了现有数据集缺乏细粒度标注的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型和视觉语言模型在处理非RGB模态（如深度、IMU、毫米波）时存在困难，因为缺乏大规模的数据-描述资源。现有的人类动作识别数据集主要提供粗糙的数据标签标注，不足以捕捉人类动作理解和推理所需的细粒度动作动态。

Method: 提出CUHK-X数据集，包含58,445个样本覆盖40个动作，由30名参与者在两个室内环境中完成。采用基于提示的场景创建方法，利用大型语言模型生成逻辑连贯的活动序列，然后进行人工验证，以提高描述的一致性。

Result: 实验报告了平均准确率：人类动作识别76.52%，人类动作理解40.76%，人类动作推理70.25%。数据集包含三个基准和六个评估任务。

Conclusion: CUHK-X旨在使研究社区能够应用和开发数据密集型学习方法，用于鲁棒的多模态人类活动分析，填补了现有数据集在细粒度标注方面的空白。

Abstract: Multimodal human action recognition (HAR) leverages complementary sensors for activity classification. Beyond recognition, recent advances in large language models (LLMs) enable detailed descriptions and causal reasoning, motivating new tasks: human action understanding (HAU) and human action reasoning (HARn). However, most LLMs, especially large vision language models (LVLMs), struggle with non-RGB modalities such as depth, IMU, and mmWave due to the lack of large-scale data-caption resources. Existing HAR datasets mainly provide coarse data-label annotations, which are insufficient to capture fine-grained action dynamics needed for HAU and HARn. We consider two ground-truth pair types: (1) data label (discrete category) and (2) data caption (textual description). Naively generating captions from labels often lacks logical and spatiotemporal consistency. We introduce CUHK-X, a large-scale multimodal dataset and benchmark suite for HAR, HAU, and HARn. CUHK-X contains 58,445 samples covering 40 actions performed by 30 participants across two indoor environments. To improve caption consistency, we propose a prompt-based scene creation method that leverages LLMs to generate logically connected activity sequences, followed by human validation. CUHK-X includes three benchmarks with six evaluation tasks. Experiments report average accuracies of 76.52% (HAR), 40.76% (HAU), and 70.25% (HARn). CUHK-X aims to enable the community to apply and develop data-intensive learning methods for robust, multimodal human activity analysis. Project page and code: https://openaiotlab.github.io/CUHK-X/ and https://github.com/openaiotlab/CUHK-X.

</details>


### [87] [Context-measure: Contextualizing Metric for Camouflage](https://arxiv.org/abs/2512.07076)
*Chen-Yang Wang,Gepeng Ji,Song Shao,Ming-Ming Cheng,Deng-Ping Fan*

Main category: cs.CV

TL;DR: 本文提出了一种新的上下文感知评估范式Context-measure，用于评估伪装场景，通过概率像素感知相关框架考虑空间依赖性和像素级伪装量化，比现有上下文无关指标更可靠。


<details>
  <summary>Details</summary>
Motivation: 当前伪装场景的评估指标忽略了上下文依赖性这一关键因素，这些指标原本是为评估一般或显著对象设计的，假设空间上下文不相关，无法准确评估伪装效果。

Method: 提出Context-measure评估范式，基于概率像素感知相关框架，通过纳入空间依赖性和像素级伪装量化，更好地与人类感知对齐。

Result: 在三个具有挑战性的伪装对象分割数据集上的广泛实验表明，Context-measure比现有的上下文无关指标提供更可靠的评估结果。

Conclusion: Context-measure可以为涉及伪装模式的各种计算机视觉应用提供基础评估基准，包括农业、工业和医疗场景。

Abstract: Camouflage is primarily context-dependent yet current metrics for camouflaged scenarios overlook this critical factor. Instead, these metrics are originally designed for evaluating general or salient objects, with an inherent assumption of uncorrelated spatial context. In this paper, we propose a new contextualized evaluation paradigm, Context-measure, built upon a probabilistic pixel-aware correlation framework. By incorporating spatial dependencies and pixel-wise camouflage quantification, our measure better aligns with human perception. Extensive experiments across three challenging camouflaged object segmentation datasets show that Context-measure delivers more reliability than existing context-independent metrics. Our measure can provide a foundational evaluation benchmark for various computer vision applications involving camouflaged patterns, such as agricultural, industrial, and medical scenarios. Code is available at https://github.com/pursuitxi/Context-measure.

</details>


### [88] [COREA: Coarse-to-Fine 3D Representation Alignment Between Relightable 3D Gaussians and SDF via Bidirectional 3D-to-3D Supervision](https://arxiv.org/abs/2512.07107)
*Jaeyoon Lee,Hojoon Jung,Sungtae Hwang,Jihyong Oh,Jongwon Choi*

Main category: cs.CV

TL;DR: COREA是首个联合学习可重光照3D高斯和SDF的统一框架，通过3D到3D的对齐策略实现精确几何重建和忠实重光照


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯方法从2D渲染学习几何，导致表面粗糙和BRDF-光照分解不可靠，需要直接在3D空间中学习几何信号

Method: 引入粗到细的双向3D到3D对齐策略：深度提供粗对齐，深度梯度和法线细化精细结构；密度控制机制稳定高斯增长

Result: 在标准基准测试中，COREA在新视角合成、网格重建和PBR方面均取得优越性能

Conclusion: COREA通过统一框架实现了精确几何重建和忠实重光照，解决了现有方法在几何精度和BRDF-光照分解方面的局限性

Abstract: We present COREA, the first unified framework that jointly learns relightable 3D Gaussians and a Signed Distance Field (SDF) for accurate geometry reconstruction and faithful relighting. While recent 3D Gaussian Splatting (3DGS) methods have extended toward mesh reconstruction and physically-based rendering (PBR), their geometry is still learned from 2D renderings, leading to coarse surfaces and unreliable BRDF-lighting decomposition. To address these limitations, COREA introduces a coarse-to-fine bidirectional 3D-to-3D alignment strategy that allows geometric signals to be learned directly in 3D space. Within this strategy, depth provides coarse alignment between the two representations, while depth gradients and normals refine fine-scale structure, and the resulting geometry supports stable BRDF-lighting decomposition. A density-control mechanism further stabilizes Gaussian growth, balancing geometric fidelity with memory efficiency. Experiments on standard benchmarks demonstrate that COREA achieves superior performance in novel-view synthesis, mesh reconstruction, and PBR within a unified framework.

</details>


### [89] [START: Spatial and Textual Learning for Chart Understanding](https://arxiv.org/abs/2512.07186)
*Zhuoming Liu,Xiaofeng Gao,Feiyang Niu,Qiaozi Gao,Liu Liu,Robinson Piramuthu*

Main category: cs.CV

TL;DR: START提出了一种结合空间和文本学习的图表理解方法，通过图表元素定位和图表到代码生成来增强多模态大语言模型对图表视觉布局和数据细节的理解能力。


<details>
  <summary>Details</summary>
Motivation: 图表理解对于多模态大语言模型在现实场景中的应用至关重要。与自然图像不同，图表同时包含结构化视觉布局（空间属性）和底层数据表示（文本属性），理解这两者对于精确的细粒度图表推理是必要的。

Method: 提出START方法，包含两个核心组件：1) 图表元素定位，2) 图表到代码生成。同时构建START-Dataset数据集，通过创新的数据生成流程，首先利用MLLM将真实图表图像转换为可执行图表代码，然后使用LLM演化代码以确定捕获图表视觉结构的元素位置。

Result: START在不同模型大小和基准测试上都取得了持续的性能提升，明显超越了先前的最先进方法。还提出了Chart Spatial understanding Benchmark (CS-Bench)来评估模型对图表空间结构的理解能力。

Conclusion: 通过结合空间和文本学习，START显著提升了多模态大语言模型的图表理解能力，填补了现有方法在处理图表视觉结构方面的不足，为全面的图表理解评估提供了新的基准。

Abstract: Chart understanding is crucial for deploying multimodal large language models (MLLMs) in real-world scenarios such as analyzing scientific papers and technical reports. Unlike natural images, charts pair a structured visual layout (spatial property) with an underlying data representation (textual property) -- grasping both is essential for precise, fine-grained chart reasoning. Motivated by this observation, we propose START, the Spatial and Textual learning for chART understanding. Specifically, we introduce (i) chart-element grounding and (ii) chart-to-code generation to strengthen an MLLM's understanding of both chart visual layout and data details. To facilitate spatial and textual learning, we propose the START-Dataset generated with a novel data-generation pipeline that first leverages an MLLM to translate real chart images into executable chart code, recovering the underlying data representation while preserving the visual distribution of real-world charts. We then evolve the code with a Large Language Model (LLM) to ascertain the positions of chart elements that capture the chart's visual structure, addressing challenges that existing methods cannot handle. To evaluate a model's ability to understand chart spatial structures, we propose the Chart Spatial understanding Benchmark (CS-Bench), filling a critical gap in comprehensive chart understanding evaluation. Leveraging spatial and textual learning, START delivers consistent gains across model sizes and benchmarks over the base models and surpasses prior state-of-the-art by a clear margin. Code, data and models will be publicly available.

</details>


### [90] [Training-free Clothing Region of Interest Self-correction for Virtual Try-On](https://arxiv.org/abs/2512.07126)
*Shengjie Lu,Zhibin Wan,Jiejie Liu,Quan Zhang,Mingjie Sun*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的虚拟试穿方法，通过能量函数约束注意力机制，使生成结果更好地保留目标服装细节，并设计了新的评估指标VTID来更全面地评估试穿效果。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法在生成服装时存在图案、纹理和边界方面的差异，且现有评估指标只关注图像真实性而忽略与目标元素的匹配度。

Method: 使用能量函数对生成过程中的注意力图施加约束，使注意力更集中于服装感兴趣区域，从而生成更符合目标服装细节的结果。同时设计了新的评估指标VTID。

Result: 在VITON-HD和DressCode数据集上，该方法在LPIPS、FID、KID和VTID指标上分别优于先前SOTA方法1.4%、2.3%、12.3%和5.8%。在下游CC-Reid任务中，在LTCC、PRCC、VC-Clothes数据集上Rank-1指标分别提升2.5%、1.1%和1.6%。

Conclusion: 提出的基于能量函数约束的注意力机制能有效改善虚拟试穿效果，新设计的VTID指标能更全面地评估试穿质量，方法在多个数据集和下游任务中均表现出优越性能。

Abstract: VTON (Virtual Try-ON) aims at synthesizing the target clothing on a certain person, preserving the details of the target clothing while keeping the rest of the person unchanged. Existing methods suffer from the discrepancies between the generated clothing results and the target ones, in terms of the patterns, textures and boundaries. Therefore, we propose to use an energy function to impose constraints on the attention map extracted through the generation process. Thus, at each generation step, the attention can be more focused on the clothing region of interest, thereby influencing the generation results to be more consistent with the target clothing details. Furthermore, to address the limitation that existing evaluation metrics concentrate solely on image realism and overlook the alignment with target elements, we design a new metric, Virtual Try-on Inception Distance (VTID), to bridge this gap and ensure a more comprehensive assessment. On the VITON-HD and DressCode datasets, our approach has outperformed the previous state-of-the-art (SOTA) methods by 1.4%, 2.3%, 12.3%, and 5.8% in the traditional metrics of LPIPS, FID, KID, and the new VTID metrics, respectively. Additionally, by applying the generated data to downstream Clothing-Change Re-identification (CC-Reid) methods, we have achieved performance improvements of 2.5%, 1.1%, and 1.6% on the LTCC, PRCC, VC-Clothes datasets in the metrics of Rank-1. The code of our method is public at https://github.com/MrWhiteSmall/CSC-VTON.git.

</details>


### [91] [VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation](https://arxiv.org/abs/2512.07215)
*Md Selim Sarowar,Sungho Kim*

Main category: cs.CV

TL;DR: 本文比较了基于CLIP和DINOv2的视觉基础模型在手持物体抓取场景中的3D姿态估计性能，发现CLIP在语义理解方面表现优异，而DINOv2在几何特征提取方面更胜一筹。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型和视觉语言模型为计算机视觉提供了丰富的语义和几何表示。本研究旨在全面比较基于CLIP和DINOv2的方法在手持物体抓取场景中的3D姿态估计性能，以了解这两种模型的互补优势。

Method: 在手持物体抓取场景中对基于CLIP和DINOv2的方法进行全面的视觉比较，评估两种模型在6D物体姿态估计任务上的表现，通过基准数据集上的大量实验进行分析。

Result: 实验表明，基于CLIP的方法在语义一致性方面表现更好，而基于DINOv2的方法在几何精度方面具有竞争优势，两种模型展现出互补的优势：CLIP通过语言基础在语义理解方面表现出色，DINOv2提供更优的密集几何特征。

Conclusion: 该分析为机器人操作和抓取应用中选择合适的视觉模型提供了见解，表明需要根据具体任务需求（语义理解或几何精度）来选择CLIP或DINOv2模型。

Abstract: Vision Foundation Models (VFMs) and Vision Language Models (VLMs) have revolutionized computer vision by providing rich semantic and geometric representations. This paper presents a comprehensive visual comparison between CLIP based and DINOv2 based approaches for 3D pose estimation in hand object grasping scenarios. We evaluate both models on the task of 6D object pose estimation and demonstrate their complementary strengths: CLIP excels in semantic understanding through language grounding, while DINOv2 provides superior dense geometric features. Through extensive experiments on benchmark datasets, we show that CLIP based methods achieve better semantic consistency, while DINOv2 based approaches demonstrate competitive performance with enhanced geometric precision. Our analysis provides insights for selecting appropriate vision models for robotic manipulation and grasping, picking applications.

</details>


### [92] [MulCLIP: A Multi-level Alignment Framework for Enhancing Fine-grained Long-context CLIP](https://arxiv.org/abs/2512.07128)
*Chau Truong,Hieu Ta Quang,Dung D. Le*

Main category: cs.CV

TL;DR: MulCLIP是一个端到端的多层次对齐框架，通过全局对比对齐、token重建对齐和子标题聚合补丁对齐三种策略，解决CLIP模型在处理长文本描述时的性能问题，相比基于区域建议的方法具有更好的细粒度理解能力和更低的部署成本。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（如CLIP）在短文本描述上表现良好，但在处理长文本、详细描述时性能下降。虽然近期有研究使用区域建议信息来映射视觉区域与长文本句子，但这种方法部署成本较高。因此需要一种既能处理长文本描述，又具有较低部署成本的新方法。

Method: MulCLIP采用多层次对齐框架：1）保持图像与摘要/长标题的全局对比对齐，并扩展位置嵌入以支持更长文本序列；2）通过局部校准特征的token重建对齐来加强单词与图像补丁之间的语义连接；3）子标题聚合补丁对齐，自动提取和聚合每个子标题的上下文丰富补丁。

Result: 在多个基准测试上的实验结果表明，MulCLIP方法能持续提升下游任务性能。消融研究证实其多尺度对齐是驱动比区域建议辅助方法更好细粒度能力的关键因素，使其特别适合多样化的实际应用场景。

Conclusion: MulCLIP通过创新的多层次对齐策略，有效解决了CLIP模型在处理长文本描述时的局限性，相比基于区域建议的方法具有更好的细粒度理解能力和更低的部署成本，为实际应用提供了更优的解决方案。

Abstract: Vision-language models like CLIP show impressive ability to align images and text, but their training on short, concise captions makes them struggle with lengthy, detailed descriptions. Recent advances mitigate this challenge by leveraging region-proposal information to map visual regions with corresponding sentences from lengthy captions, yet incurring notable deployment costs. We introduce MulCLIP, a novel end-to-end multi-level alignment framework that bridges natural long-text structures with image components. MulCLIP first preserves global contrastive alignment between images and both summary and long captions, while extending positional embeddings for longer text sequences. To further enhance fine-grained understanding, we propose two novel strategies: (1) a token reconstruction alignment over locally calibrated features to strengthen semantic connections between words and image patches, and (2) a subcaption-aggregated patch alignment that automatically extracts and aggregates context-rich patches for each subcaption. Experimental results across diverse benchmarks demonstrate our method consistently improves downstream performance, while ablation studies confirm its multi-scale alignment is the key factor driving better fine-grained capability than region-proposal-assisted approaches, making it particularly suitable for diverse real-world applications.

</details>


### [93] [Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models](https://arxiv.org/abs/2512.07234)
*Biao Chen,Lin Zuo,Mengmeng Jing,Kunbin He,Yuchen Wang*

Main category: cs.CV

TL;DR: Dropout Prompt Learning：一种通过应用dropout到视觉语言模型的文本和视觉分支token上，结合残差熵正则化，提升模型在低样本学习、长尾分类和分布外泛化等挑战场景中鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: Dropout作为广泛使用的正则化技术能提升模型泛化能力，但传统的dropout方法在视觉语言模型中应用有限。本文旨在通过改进dropout机制来提升视觉语言模型在挑战性场景下的鲁棒性。

Method: 提出Dropout Prompt Learning方法：1）在文本和视觉分支的token上应用dropout；2）考虑模态内上下文和模态间对齐来评估token重要性，为每个token设置灵活的dropout概率；3）引入残差熵正则化，在保持语义对齐的同时鼓励dropout带来的多样化表示。

Result: 在15个基准测试上验证了方法的有效性，特别是在低样本学习、长尾分类和分布外泛化等挑战场景中表现优异。在base-to-novel泛化任务上，性能超越正则化方法KgCoOp 5.10%，超越PromptSRC 2.13%。

Conclusion: Dropout Prompt Learning通过改进的dropout机制和残差熵正则化，有效提升了视觉语言模型在多种挑战性场景下的鲁棒性和泛化能力，为视觉语言模型的正则化提供了新思路。

Abstract: Dropout is a widely used regularization technique which improves the generalization ability of a model by randomly dropping neurons. In light of this, we propose Dropout Prompt Learning, which aims for applying dropout to improve the robustness of the vision-language models. Different from the vanilla dropout, we apply dropout on the tokens of the textual and visual branches, where we evaluate the token significance considering both intra-modal context and inter-modal alignment, enabling flexible dropout probabilities for each token. Moreover, to maintain semantic alignment for general knowledge transfer while encouraging the diverse representations that dropout introduces, we further propose residual entropy regularization. Experiments on 15 benchmarks show our method's effectiveness in challenging scenarios like low-shot learning, long-tail classification, and out-of-distribution generalization. Notably, our method surpasses regularization-based methods including KgCoOp by 5.10% and PromptSRC by 2.13% in performance on base-to-novel generalization.

</details>


### [94] [Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models](https://arxiv.org/abs/2512.07141)
*Fenghua Weng,Chaochao Lu,Xia Hu,Wenqi Shao,Wenjie Wang*

Main category: cs.CV

TL;DR: TRR（Think-Reflect-Revise）是一个三阶段训练框架，通过策略引导的自我反思增强大型视觉语言模型的安全对齐能力，将安全响应率从42.8%提升到87.7%。


<details>
  <summary>Details</summary>
Motivation: 现有单次推理的安全导向方法虽然提高了安全意识和可解释性，但仍容易受到上下文或视觉越狱攻击，关键缺陷在于单次推理可能忽略自身输出中的显性有害内容。

Method: 提出Think-Reflect-Revise三阶段框架：1）构建包含5000个遵循think-reflect-revise过程的ReSafe数据集；2）使用ReSafe数据集微调目标模型以初始化反思行为；3）通过强化学习强化策略引导的反思。

Result: TRR显著提升了LVLMs的安全性能，在Qwen2.5-VL-7B上将整体安全响应率从42.8%提高到87.7%，同时在MMMU和MMStar等通用基准上保持稳定性能。

Conclusion: 通过利用首次推理中揭示的恶意内容进行反思，TRR框架能够实现真正的自我修正，防止不安全生成，显著增强大型视觉语言模型的安全对齐能力。

Abstract: As multimodal reasoning improves the overall capabilities of Large Vision Language Models (LVLMs), recent studies have begun to explore safety-oriented reasoning, aiming to enhance safety awareness by analyzing potential safety risks during the reasoning process before generating the final response. Although such approaches improve safety awareness and interpretability, this single-pass think-then-answer paradigm remains vulnerable to contextual or visual jailbreak attacks. This reveals a critical flaw: single-pass reasoning may overlook explicit harmful content in its own output. Our key insight is to exploit this wasted signal through reflection, which can effectively leverage the malicious content revealed in the first-pass reasoning to enable genuine self-correction and prevent unsafe generations. Motivated by this, we propose Think-Reflect-Revise (TRR), a three-stage training framework designed to enhance the safety alignment of LVLMs through policy-guided self-reflection. We first build a Reflective Safety Reasoning (ReSafe) dataset with 5,000 examples that follow a think-reflect-revise process. We then fine-tune the target model using the ReSafe dataset to initialize reflective behavior, and finally reinforce policy-guided reflection through reinforcement learning. Experimental results show that TRR substantially improves the safety performance of LVLMs across both safety-awareness benchmarks and jailbreak attack evaluations, increasing the overall safe response rate from 42.8% to 87.7% on Qwen2.5-VL-7B, while preserving stable performance on general benchmarks such as MMMU and MMStar. The project page is available at https://think-reflect-revise.github.io/.

</details>


### [95] [DGGAN: Degradation Guided Generative Adversarial Network for Real-time Endoscopic Video Enhancement](https://arxiv.org/abs/2512.07253)
*Handing Xu,Zhenguo Nie,Tairan Peng,Huimin Pan,Xin-Jun Liu*

Main category: cs.CV

TL;DR: 提出了一种基于退化感知的实时内窥镜视频增强框架，通过跨帧传播退化表示实现高质量实时增强


<details>
  <summary>Details</summary>
Motivation: 内窥镜手术依赖术中视频，但视频常因光照不均、组织散射、遮挡和运动模糊而质量下降，影响手术安全和效果。现有深度学习方法计算量大，难以满足实时手术需求。

Method: 提出退化感知框架：1) 使用对比学习从图像中提取退化表示；2) 引入融合机制，用退化表示调制图像特征来指导单帧增强模型；3) 在退化图像和恢复图像之间采用循环一致性约束训练，提高鲁棒性和泛化能力。

Result: 实验表明，该框架在性能和效率之间取得了优越的平衡，优于多种最先进方法，证明了退化感知建模对实时内窥镜视频增强的有效性。

Conclusion: 通过隐式学习和传播退化表示，为临床应用提供了实用途径，实现了实时高质量的内窥镜视频增强。

Abstract: Endoscopic surgery relies on intraoperative video, making image quality a decisive factor for surgical safety and efficacy. Yet, endoscopic videos are often degraded by uneven illumination, tissue scattering, occlusions, and motion blur, which obscure critical anatomical details and complicate surgical manipulation. Although deep learning-based methods have shown promise in image enhancement, most existing approaches remain too computationally demanding for real-time surgical use. To address this challenge, we propose a degradation-aware framework for endoscopic video enhancement, which enables real-time, high-quality enhancement by propagating degradation representations across frames. In our framework, degradation representations are first extracted from images using contrastive learning. We then introduce a fusion mechanism that modulates image features with these representations to guide a single-frame enhancement model, which is trained with a cycle-consistency constraint between degraded and restored images to improve robustness and generalization. Experiments demonstrate that our framework achieves a superior balance between performance and efficiency compared with several state-of-the-art methods. These results highlight the effectiveness of degradation-aware modeling for real-time endoscopic video enhancement. Nevertheless, our method suggests that implicitly learning and propagating degradation representation offer a practical pathway for clinical application.

</details>


### [96] [CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics](https://arxiv.org/abs/2512.07155)
*Dahyeon Kye,Jeahun Sung,MinKyu Jeon,Jihyong Oh*

Main category: cs.CV

TL;DR: CHIMERA是一个零样本扩散模型框架，通过自适应缓存注入和语义锚提示实现平滑的图像变形，解决了现有方法在结构对齐和语义一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在图像变形任务中往往产生突兀的过渡或过饱和的外观，主要原因是缺乏自适应的结构和语义对齐机制。

Method: 提出CHIMERA框架，将变形任务构建为缓存反转引导的去噪过程。采用自适应缓存注入(ACI)在DDIM反转期间缓存输入特征并在去噪时自适应重新注入，以及语义锚提示(SAP)利用视觉语言模型生成共享锚提示作为语义桥梁。

Result: 实验和用户研究表明，CHIMERA相比现有方法实现了更平滑、语义更一致的过渡，在图像变形任务中达到了新的最先进水平。

Conclusion: CHIMERA通过创新的缓存注入机制和语义锚提示，有效解决了图像变形中的结构和语义对齐问题，为扩散模型在图像变形任务中的应用提供了新思路。

Abstract: Diffusion models exhibit remarkable generative ability, yet achieving smooth and semantically consistent image morphing remains a challenge. Existing approaches often yield abrupt transitions or over-saturated appearances due to the lack of adaptive structural and semantic alignments. We propose CHIMERA, a zero-shot diffusion-based framework that formulates morphing as a cached inversion-guided denoising process. To handle large semantic and appearance disparities, we propose Adaptive Cache Injection and Semantic Anchor Prompting. Adaptive Cache Injection (ACI) caches down, mid, and up blocks features from both inputs during DDIM inversion and re-injects them adaptively during denoising, enabling spatial and semantic alignment in depth- and time-adaptive manners and enabling natural feature fusion and smooth transitions. Semantic Anchor Prompting (SAP) leverages a vision-language model to generate a shared anchor prompt that serves as a semantic anchor, bridging dissimilar inputs and guiding the denoising process toward coherent results. Finally, we introduce the Global-Local Consistency Score (GLCS), a morphing-oriented metric that simultaneously evaluates the global harmonization of the two inputs and the smoothness of the local morphing transition. Extensive experiments and user studies show that CHIMERA achieves smoother and more semantically aligned transitions than existing methods, establishing a new state of the art in image morphing. The code and project page will be publicly released.

</details>


### [97] [ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.07328)
*Ziyang Mai,Yu-Wing Tai*

Main category: cs.CV

TL;DR: ContextAnyone是一个上下文感知的扩散框架，通过单张参考图像实现角色一致性的文本到视频生成，解决了现有方法在保持角色身份一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成方法在保持角色身份一致性方面存在局限，特别是无法保留发型、服装、体型等更广泛的上下文线索，这些对于视觉连贯性至关重要。

Method: 提出上下文感知扩散框架ContextAnyone，通过Emphasize-Attention模块选择性增强参考感知特征，防止跨帧身份漂移；采用双引导损失结合扩散和参考重建目标；提出Gap-RoPE位置嵌入分离参考和视频标记以稳定时序建模。

Result: 实验表明ContextAnyone在身份一致性和视觉质量方面优于现有的参考到视频方法，能够跨不同动作和场景生成连贯且保持上下文的角色视频。

Conclusion: ContextAnyone通过上下文感知的扩散框架有效解决了角色一致性视频生成的挑战，在保持角色身份完整性的同时实现了高质量的文本到视频生成。

Abstract: Text-to-video (T2V) generation has advanced rapidly, yet maintaining consistent character identities across scenes remains a major challenge. Existing personalization methods often focus on facial identity but fail to preserve broader contextual cues such as hairstyle, outfit, and body shape, which are critical for visual coherence. We propose \textbf{ContextAnyone}, a context-aware diffusion framework that achieves character-consistent video generation from text and a single reference image. Our method jointly reconstructs the reference image and generates new video frames, enabling the model to fully perceive and utilize reference information. Reference information is effectively integrated into a DiT-based diffusion backbone through a novel Emphasize-Attention module that selectively reinforces reference-aware features and prevents identity drift across frames. A dual-guidance loss combines diffusion and reference reconstruction objectives to enhance appearance fidelity, while the proposed Gap-RoPE positional embedding separates reference and video tokens to stabilize temporal modeling. Experiments demonstrate that ContextAnyone outperforms existing reference-to-video methods in identity consistency and visual quality, generating coherent and context-preserving character videos across diverse motions and scenes. Project page: \href{https://github.com/ziyang1106/ContextAnyone}{https://github.com/ziyang1106/ContextAnyone}.

</details>


### [98] [TIDE: Two-Stage Inverse Degradation Estimation with Guided Prior Disentanglement for Underwater Image Restoration](https://arxiv.org/abs/2512.07171)
*Shravan Venkatraman,Rakesh Raj Madavan,Pavan Kumar S,Muthu Subash Kavitha*

Main category: cs.CV

TL;DR: TIDE是一个两阶段水下图像恢复框架，通过专门先验分解显式建模退化特征，针对性地处理空间变化的多种水下退化问题。


<details>
  <summary>Details</summary>
Motivation: 水下图像恢复对海洋应用至关重要，但现有方法通常对整个图像采用统一的恢复策略，难以处理空间变化且同时发生的多种退化问题。

Method: TIDE将水下退化分解为颜色失真、雾霾、细节损失和噪声四个关键因素，为每个因素设计专门的恢复专家，生成专门的恢复假设，并根据局部退化模式自适应融合，最后通过渐进细化阶段校正残留伪影。

Result: 在标准基准和挑战性浑浊水条件下的广泛实验表明，TIDE在基于参考的保真度指标上具有竞争力，同时在非参考感知质量指标上优于现有方法，在颜色校正和对比度增强方面有显著改进。

Conclusion: TIDE通过显式建模退化特征和专门先验分解，有效解决了水下图像恢复中空间变化的多重退化问题，为复杂水下环境提供了高质量的图像恢复方案。

Abstract: Underwater image restoration is essential for marine applications ranging from ecological monitoring to archaeological surveys, but effectively addressing the complex and spatially varying nature of underwater degradations remains a challenge. Existing methods typically apply uniform restoration strategies across the entire image, struggling to handle multiple co-occurring degradations that vary spatially and with water conditions. We introduce TIDE, a $\underline{t}$wo stage $\underline{i}$nverse $\underline{d}$egradation $\underline{e}$stimation framework that explicitly models degradation characteristics and applies targeted restoration through specialized prior decomposition. Our approach disentangles the restoration process into multiple specialized hypotheses that are adaptively fused based on local degradation patterns, followed by a progressive refinement stage that corrects residual artifacts. Specifically, TIDE decomposes underwater degradations into four key factors, namely color distortion, haze, detail loss, and noise, and designs restoration experts specialized for each. By generating specialized restoration hypotheses, TIDE balances competing degradation factors and produces natural results even in highly degraded regions. Extensive experiments across both standard benchmarks and challenging turbid water conditions show that TIDE achieves competitive performance on reference based fidelity metrics while outperforming state of the art methods on non reference perceptual quality metrics, with strong improvements in color correction and contrast enhancement. Our code is available at: https://rakesh-123-cryp.github.io/TIDE.

</details>


### [99] [DeepAgent: A Dual Stream Multi Agent Fusion for Robust Multimodal Deepfake Detection](https://arxiv.org/abs/2512.07351)
*Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Reem E. Mohamed,Md Rafiqul Islam,Asif Karim,Sami Azam*

Main category: cs.CV

TL;DR: DeepAgent是一个多智能体协作框架，通过视觉和音频双模态检测深度伪造视频，使用随机森林元分类器融合决策，在多个基准数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 合成媒体特别是深度伪造的日益使用给数字内容验证带来挑战。现有方法通常将音频和视觉信息集成在单一模型中，容易受到模态不匹配、噪声和操纵的影响。

Method: 提出DeepAgent多智能体协作框架：Agent-1使用基于AlexNet的CNN检测深度伪造操作痕迹；Agent-2通过声学特征、Whisper音频转录和EasyOCR帧读取检测视听不一致性；使用随机森林元分类器融合两个智能体的决策。

Result: Agent-1在Celeb-DF和FakeAVCeleb数据集上达到94.35%测试准确率；Agent-2在FakeAVCeleb上达到93.69%；元分类器在FakeAVCeleb上达到81.56%，在DeepFakeTIMIT跨数据集验证中达到97.49%准确率。

Conclusion: 基于层次结构的融合通过减轻单个模态的弱点增强了鲁棒性，多智能体方法能有效处理深度伪造中的多样化操纵类型。

Abstract: The increasing use of synthetic media, particularly deepfakes, is an emerging challenge for digital content verification. Although recent studies use both audio and visual information, most integrate these cues within a single model, which remains vulnerable to modality mismatches, noise, and manipulation. To address this gap, we propose DeepAgent, an advanced multi-agent collaboration framework that simultaneously incorporates both visual and audio modalities for the effective detection of deepfakes. DeepAgent consists of two complementary agents. Agent-1 examines each video with a streamlined AlexNet-based CNN to identify the symbols of deepfake manipulation, while Agent-2 detects audio-visual inconsistencies by combining acoustic features, audio transcriptions from Whisper, and frame-reading sequences of images through EasyOCR. Their decisions are fused through a Random Forest meta-classifier that improves final performance by taking advantage of the different decision boundaries learned by each agent. This study evaluates the proposed framework using three benchmark datasets to demonstrate both component-level and fused performance. Agent-1 achieves a test accuracy of 94.35% on the combined Celeb-DF and FakeAVCeleb datasets. On the FakeAVCeleb dataset, Agent-2 and the final meta-classifier attain accuracies of 93.69% and 81.56%, respectively. In addition, cross-dataset validation on DeepFakeTIMIT confirms the robustness of the meta-classifier, which achieves a final accuracy of 97.49%, and indicates a strong capability across diverse datasets. These findings confirm that hierarchy-based fusion enhances robustness by mitigating the weaknesses of individual modalities and demonstrate the effectiveness of a multi-agent approach in addressing diverse types of manipulations in deepfakes.

</details>


### [100] [Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2512.07360)
*Qiming Huang,Hao Ai,Jianbo Jiao*

Main category: cs.CV

TL;DR: 提出结构感知特征校正方法，通过区域邻接图利用图像的低级特征来优化CLIP特征，解决开放词汇语义分割中局部区域预测不一致的问题。


<details>
  <summary>Details</summary>
Motivation: CLIP等视觉语言模型在大规模数据集上预训练，注重全局语义对齐，但在细粒度视觉区域与文本关联时表现不佳，导致局部区域预测噪声大且不一致。这源于对比训练范式产生的分散偏差，仅用CLIP特征难以缓解。

Method: 提出结构感知特征校正方法：基于低级特征（颜色、纹理）构建区域邻接图（RAG）来捕捉局部结构关系，利用该图通过增强局部判别性来优化CLIP特征。

Result: 大量实验表明，该方法能有效抑制分割噪声，提高区域级一致性，在多个开放词汇分割基准上取得强劲性能。

Conclusion: 通过结合图像特定的实例先验信息，提出的结构感知特征校正方法能够改善CLIP特征在细粒度区域关联中的局限性，提升开放词汇语义分割的质量和一致性。

Abstract: Benefiting from the inductive biases learned from large-scale datasets, open-vocabulary semantic segmentation (OVSS) leverages the power of vision-language models, such as CLIP, to achieve remarkable progress without requiring task-specific training. However, due to CLIP's pre-training nature on image-text pairs, it tends to focus on global semantic alignment, resulting in suboptimal performance when associating fine-grained visual regions with text. This leads to noisy and inconsistent predictions, particularly in local areas. We attribute this to a dispersed bias stemming from its contrastive training paradigm, which is difficult to alleviate using CLIP features alone. To address this, we propose a structure-aware feature rectification approach that incorporates instance-specific priors derived directly from the image. Specifically, we construct a region adjacency graph (RAG) based on low-level features (e.g., colour and texture) to capture local structural relationships and use it to refine CLIP features by enhancing local discrimination. Extensive experiments show that our method effectively suppresses segmentation noise, improves region-level consistency, and achieves strong performance on multiple open-vocabulary segmentation benchmarks.

</details>


### [101] [Data-driven Exploration of Mobility Interaction Patterns](https://arxiv.org/abs/2512.07415)
*Gabriele Galatolo,Mirco Nanni*

Main category: cs.CV

TL;DR: 该论文提出了一种基于数据挖掘的方法，从移动数据中直接发现个体间的相互影响模式，而不是从预定义的行为模型出发。


<details>
  <summary>Details</summary>
Motivation: 理解个体移动行为及其对外部世界的反应是模拟人类动态的关键，特别是在人群模拟和应急管理中，需要考虑个体间的相互影响。现有方法通常基于预定义的行为模型，缺乏直接从数据中发现交互模式的能力。

Method: 采用数据挖掘视角，从移动数据中搜索可能反映个体间相互作用的移动事件，在此基础上寻找复杂、持久的事件模式和随时间演化的配置模式。

Result: 在两个真实案例研究（汽车和行人）上进行了完整的实验评估，包括性能、参数敏感性和结果解释等方面。

Conclusion: 通过研究这些模式可以获得关于个体间移动交互机制的新见解，有助于改进现有的模拟模型。

Abstract: Understanding the movement behaviours of individuals and the way they react to the external world is a key component of any problem that involves the modelling of human dynamics at a physical level. In particular, it is crucial to capture the influence that the presence of an individual can have on the others. Important examples of applications include crowd simulation and emergency management, where the simulation of the mass of people passes through the simulation of the individuals, taking into consideration the others as part of the general context. While existing solutions basically start from some preconceived behavioural model, in this work we propose an approach that starts directly from the data, adopting a data mining perspective. Our method searches the mobility events in the data that might be possible evidences of mutual interactions between individuals, and on top of them looks for complex, persistent patterns and time evolving configurations of events. The study of these patterns can provide new insights on the mechanics of mobility interactions between individuals, which can potentially help in improving existing simulation models. We instantiate the general methodology on two real case studies, one on cars and one on pedestrians, and a full experimental evaluation is performed, both in terms of performances, parameter sensitivity and interpretation of sample results.

</details>


### [102] [SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting](https://arxiv.org/abs/2512.07197)
*Seokhyun Youn,Soohyun Lee,Geonho Kim,Weeyoung Kwon,Sung-Ho Bae,Jihyong Oh*

Main category: cs.CV

TL;DR: 该论文是关于高效3D/4D高斯溅射技术的综述，系统分类了参数压缩和结构压缩方法，总结了数据集、评估指标和基准比较，并讨论了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射虽然能实现实时高保真3D重建和新视角合成，但其存储和渲染数百万高斯需要大量内存和计算资源，特别是在4D动态场景中更为严重，因此需要高效压缩技术来解决这些实际问题。

Method: 该综述论文采用系统分类方法，将现有高效3D和4D高斯溅射技术分为两大方向：参数压缩和结构压缩。对每个类别总结了核心思想和方法趋势，并涵盖了广泛使用的数据集、评估指标和代表性基准比较。

Result: 提供了首个统一的高效3D和4D高斯溅射技术概述，建立了系统分类框架，总结了当前技术发展现状，为研究人员提供了全面的技术路线图和比较基准。

Conclusion: 论文指出了当前技术的局限性，并展望了未来研究方向，旨在实现可扩展、紧凑且实时的静态和动态3D场景表示的高斯溅射技术。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful explicit representation enabling real-time, high-fidelity 3D reconstruction and novel view synthesis. However, its practical use is hindered by the massive memory and computational demands required to store and render millions of Gaussians. These challenges become even more severe in 4D dynamic scenes. To address these issues, the field of Efficient Gaussian Splatting has rapidly evolved, proposing methods that reduce redundancy while preserving reconstruction quality. This survey provides the first unified overview of efficient 3D and 4D Gaussian Splatting techniques. For both 3D and 4D settings, we systematically categorize existing methods into two major directions, Parameter Compression and Restructuring Compression, and comprehensively summarize the core ideas and methodological trends within each category. We further cover widely used datasets, evaluation metrics, and representative benchmark comparisons. Finally, we discuss current limitations and outline promising research directions toward scalable, compact, and real-time Gaussian Splatting for both static and dynamic 3D scene representation.

</details>


### [103] [When normalization hallucinates: unseen risks in AI-powered whole slide image processing](https://arxiv.org/abs/2512.07426)
*Karel Moens,Matthew B. Blaschko,Tinne Tuytelaars,Bart Diricx,Jonas De Vylder,Mustafa Yousif*

Main category: cs.CV

TL;DR: WSI归一化模型在真实临床数据上会产生难以察觉的幻觉伪影，现有评估方法无法检测，本文提出新的图像比较度量来自动检测这些幻觉


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的全切片图像归一化方法倾向于输出平均值，可能掩盖诊断重要特征，更严重的是会产生视觉上难以检测的幻觉伪影，这对下游分析构成严重威胁，而现有评估方法往往忽视这一问题

Method: 提出一种新颖的图像比较度量方法，专门设计用于自动检测归一化输出中的幻觉伪影，并使用该度量系统地评估多个在真实临床数据上重新训练的知名归一化方法

Result: 在真实临床数据上重新训练的模型显示出令人担忧的幻觉频率，使用新提出的度量方法揭示了传统指标无法捕捉的显著不一致性和失败案例

Conclusion: 幻觉风险真实存在且被低估，需要更鲁棒、可解释的归一化技术和更严格的临床部署验证协议

Abstract: Whole slide image (WSI) normalization remains a vital preprocessing step in computational pathology. Increasingly driven by deep learning, these models learn to approximate data distributions from training examples. This often results in outputs that gravitate toward the average, potentially masking diagnostically important features. More critically, they can introduce hallucinated content, artifacts that appear realistic but are not present in the original tissue, posing a serious threat to downstream analysis. These hallucinations are nearly impossible to detect visually, and current evaluation practices often overlook them. In this work, we demonstrate that the risk of hallucinations is real and underappreciated. While many methods perform adequately on public datasets, we observe a concerning frequency of hallucinations when these same models are retrained and evaluated on real-world clinical data. To address this, we propose a novel image comparison measure designed to automatically detect hallucinations in normalized outputs. Using this measure, we systematically evaluate several well-cited normalization methods retrained on real-world data, revealing significant inconsistencies and failures that are not captured by conventional metrics. Our findings underscore the need for more robust, interpretable normalization techniques and stricter validation protocols in clinical deployment.

</details>


### [104] [Generating Storytelling Images with Rich Chains-of-Reasoning](https://arxiv.org/abs/2512.07198)
*Xiujie Song,Qi Jia,Shota Watanabe,Xiaoyi Pang,Ruijie Chen,Mengyue Wu,Kenny Q. Zhu*

Main category: cs.CV

TL;DR: 该论文提出了"叙事图像生成"任务，通过结合大语言模型的创造性推理能力和文本到图像模型的视觉合成能力，生成具有丰富语义和逻辑连接的叙事图像。


<details>
  <summary>Details</summary>
Motivation: 叙事图像通过呈现丰富、逻辑连接的视觉线索来传达引人入胜的故事，具有广泛的应用价值。但由于其复杂的语义性质，这类图像难以创建且相对稀缺，因此需要探索如何利用生成式AI模型来创建此类图像。

Method: 提出了两阶段流水线StorytellingPainter：1）利用大语言模型进行创造性推理生成故事内容；2）使用文本到图像模型进行视觉合成。同时开发了包含语义复杂性评估器、KNN多样性评估器和故事-图像对齐评估器的专用评估框架。还探索了针对故事生成的训练策略，开发了名为Mini-Storytellers的轻量级有效模型。

Result: 实验结果表明，所提方法的可行性和有效性得到了验证。通过结合LLMs的推理能力和T2I模型的视觉合成能力，能够成功生成具有丰富语义连接的叙事图像。

Conclusion: 该研究成功定义了叙事图像生成任务，并提出了一套完整的解决方案，包括生成流水线、评估框架和轻量级模型，为生成具有复杂语义连接的叙事图像提供了有效途径，推动了这一领域的发展。

Abstract: An image can convey a compelling story by presenting rich, logically connected visual clues. These connections form Chains-of-Reasoning (CoRs) within the image, enabling viewers to infer events, causal relationships, and other information, thereby understanding the underlying story. In this paper, we focus on these semantically rich images and define them as Storytelling Images. Such images have diverse applications beyond illustration creation and cognitive screening, leveraging their ability to convey multi-layered information visually and inspire active interpretation. However, due to their complex semantic nature, Storytelling Images are inherently challenging to create, and thus remain relatively scarce. To address this challenge, we introduce the Storytelling Image Generation task, which explores how generative AI models can be leveraged to create such images. Specifically, we propose a two-stage pipeline, StorytellingPainter, which combines the creative reasoning abilities of Large Language Models (LLMs) with the visual synthesis capabilities of Text-to-Image (T2I) models to generate Storytelling Images. Alongside this pipeline, we develop a dedicated evaluation framework comprising three main evaluators: a Semantic Complexity Evaluator, a KNN-based Diversity Evaluator and a Story-Image Alignment Evaluator. Given the critical role of story generation in the Storytelling Image Generation task and the performance disparity between open-source and proprietary LLMs, we further explore tailored training strategies to reduce this gap, resulting in a series of lightweight yet effective models named Mini-Storytellers. Experimental results demonstrate the feasibility and effectiveness of our approaches. The code is available at https://github.com/xiujiesong/StorytellingImageGeneration.

</details>


### [105] [MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning](https://arxiv.org/abs/2512.07203)
*Xuhui Zheng,Kang An,Ziliang Wang,Yuhang Wang,Faqiang Qian,Yichao Wu*

Main category: cs.CV

TL;DR: MMRPT是一个基于强化学习的掩码多模态预训练框架，通过奖励视觉基础而非文本模仿来增强多模态大模型的视觉推理能力


<details>
  <summary>Details</summary>
Motivation: 当前多模态预训练受限于图像-描述对的描述性偏差，导致模型更倾向于依赖表面语言线索而非基于视觉的理解。需要一种能强化视觉推理能力的预训练方法

Method: MMRPT首次将强化学习直接融入大型视觉语言模型的预训练中。通过注意力机制估计句子级别的视觉依赖度，掩码高度依赖视觉的文本片段，模型通过视觉基础推理重建这些片段，并由语义-视觉奖励引导

Result: 实验显示在多种基准测试中取得一致的零样本性能提升，在监督微调下显著提高了鲁棒性，证明强化驱动的掩码推理为多模态模型提供了更可靠和可泛化的预训练目标

Conclusion: 基于强化学习的掩码多模态预训练框架能够有效增强模型的视觉推理能力，提供比传统方法更可靠和可泛化的预训练目标

Abstract: Multimodal pre-training remains constrained by the descriptive bias of image-caption pairs, leading models to favor surface linguistic cues over grounded visual understanding. We introduce MMRPT, a masked multimodal reinforcement pre-training framework that strengthens visual reasoning in MLLMs. We are the first to incorporate reinforcement learning directly into the pre-training of large vision-language models, enabling learning signals that reward visual grounding rather than caption imitation. MMRPT constructs masked multimodal data by estimating sentence-level visual dependency via attention over visual tokens and masking highly vision-dependent segments; the model reconstructs these spans through vision-grounded reasoning guided by a semantic-visual reward. Experiments show consistent zero-shot gains across diverse benchmarks and substantially improved robustness under supervised fine-tuning, demonstrating that reinforcement-driven masked reasoning provides a more reliable and generalizable pre-training objective for multimodal models.

</details>


### [106] [AutoLugano: A Deep Learning Framework for Fully Automated Lymphoma Segmentation and Lugano Staging on FDG-PET/CT](https://arxiv.org/abs/2512.07206)
*Boyang Pan,Zeyu Zhang,Hongyu Meng,Bin Cui,Yingying Zhang,Wenli Hou,Junhao Li,Langdi Zhong,Xiaoxiao Chen,Xiaoyu Xu,Changjin Zuo,Chao Cheng,Nan-Jie Gong*

Main category: cs.CV

TL;DR: AutoLugano是一个全自动深度学习系统，能够从基线FDG-PET/CT扫描中实现淋巴瘤的端到端分类，包括病灶分割、解剖定位和自动化Lugano分期。


<details>
  <summary>Details</summary>
Motivation: 开发一个全自动系统，将单个基线FDG-PET/CT扫描转化为完整的Lugano分期，以辅助初始分期、治疗分层和临床决策支持。

Method: 系统包含三个顺序模块：1) 解剖信息病灶分割（基于3D nnU-Net模型）；2) 基于图谱的解剖定位（使用TotalSegmentator工具包将病灶映射到21个预定义淋巴结区域）；3) 自动化Lugano分期（将受累区域的空间分布转化为Lugano分期和治疗组）。

Result: 在外部验证集上，区域受累检测的总体准确率为88.31%，敏感性74.47%，特异性94.21%，F1分数80.80%。对于治疗分层（局限期vs进展期），准确率达到85.07%，特异性90.48%，敏感性82.61%。

Conclusion: AutoLugano是首个能够将单个基线FDG-PET/CT扫描转化为完整Lugano分期的全自动端到端流程，显示出在辅助初始分期、治疗分层和临床决策支持方面的强大潜力。

Abstract: Purpose: To develop a fully automated deep learning system, AutoLugano, for end-to-end lymphoma classification by performing lesion segmentation, anatomical localization, and automated Lugano staging from baseline FDG-PET/CT scans. Methods: The AutoLugano system processes baseline FDG-PET/CT scans through three sequential modules:(1) Anatomy-Informed Lesion Segmentation, a 3D nnU-Net model, trained on multi-channel inputs, performs automated lesion detection (2) Atlas-based Anatomical Localization, which leverages the TotalSegmentator toolkit to map segmented lesions to 21 predefined lymph node regions using deterministic anatomical rules; and (3) Automated Lugano Staging, where the spatial distribution of involved regions is translated into Lugano stages and therapeutic groups (Limited vs. Advanced Stage).The system was trained on the public autoPET dataset (n=1,007) and externally validated on an independent cohort of 67 patients. Performance was assessed using accuracy, sensitivity, specificity, F1-scorefor regional involvement detection and staging agreement. Results: On the external validation set, the proposed model demonstrated robust performance, achieving an overall accuracy of 88.31%, sensitivity of 74.47%, Specificity of 94.21% and an F1-score of 80.80% for regional involvement detection,outperforming baseline models. Most notably, for the critical clinical task of therapeutic stratification (Limited vs. Advanced Stage), the system achieved a high accuracy of 85.07%, with a specificity of 90.48% and a sensitivity of 82.61%.Conclusion: AutoLugano represents the first fully automated, end-to-end pipeline that translates a single baseline FDG-PET/CT scan into a complete Lugano stage. This study demonstrates its strong potential to assist in initial staging, treatment stratification, and supporting clinical decision-making.

</details>


### [107] [Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models](https://arxiv.org/abs/2512.07564)
*Kassoum Sanogo,Renzo Ardiccioni*

Main category: cs.CV

TL;DR: 提出无需训练的视觉语言模型自校正框架，通过不确定性引导的视觉重注意机制迭代修正幻觉内容，在保持模型冻结状态下显著降低幻觉率


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型经常生成看似合理但实际错误的幻觉内容，现有方法通常需要重新训练或微调，缺乏无需训练的自校正机制来直接修正这些错误

Method: 基于多维不确定性量化（令牌熵、注意力分散度、语义一致性、声明置信度）结合注意力引导的裁剪技术，对未充分探索的图像区域进行重新关注，通过迭代自校正框架修正响应

Result: 在POPE和MMHAL BENCH基准测试中，使用Qwen2.5-VL-7B架构，幻觉率相比基线降低9.8个百分点，对抗性分割中的物体存在准确率提升4.7分

Conclusion: 提出的无需训练自校正框架能有效减少视觉语言模型的幻觉问题，通过不确定性引导的视觉重注意机制成功将修正基于视觉证据，为可信多模态系统研究提供新方向

Abstract: Vision-language models (VLMs) frequently generate hallucinated content plausible but incorrect claims about image content. We propose a training-free self-correction framework enabling VLMs to iteratively refine responses through uncertainty-guided visual re-attention. Our method combines multidimensional uncertainty quantification (token entropy, attention dispersion, semantic consistency, claim confidence) with attention-guided cropping of under-explored regions. Operating entirely with frozen, pretrained VLMs, our framework requires no gradient updates. We validate our approach on the POPE and MMHAL BENCH benchmarks using the Qwen2.5-VL-7B [23] architecture. Experimental results demonstrate that our method reduces hallucination rates by 9.8 percentage points compared to the baseline, while improving object existence accuracy by 4.7 points on adversarial splits. Furthermore, qualitative analysis confirms that uncertainty-guided re-attention successfully grounds corrections in visual evidence where standard decoding fails. We validate our approach on Qwen2.5-VL-7B [23], with plans to extend validation across diverse architectures in future versions. We release our code and methodology to facilitate future research in trustworthy multimodal systems.

</details>


### [108] [ReLKD: Inter-Class Relation Learning with Knowledge Distillation for Generalized Category Discovery](https://arxiv.org/abs/2512.07229)
*Fang Zhou,Zhiqiang Chen,Martin Pavlovski,Yizhong Zhang*

Main category: cs.CV

TL;DR: ReLKD是一个端到端框架，通过利用隐式类间关系来增强广义类别发现中新颖类别的分类性能，包含目标粒度、粗粒度和蒸馏三个关键模块。


<details>
  <summary>Details</summary>
Motivation: 广义类别发现(GCD)面临对包含已知和未知类别的未标记数据进行分类的挑战，现有方法通常独立处理每个类别，忽略了固有的类间关系，而直接获取这些关系在实际场景中具有显著挑战。

Method: 提出ReLKD框架，包含三个关键模块：1)目标粒度模块学习判别性表示；2)粗粒度模块捕获层次化类间关系；3)蒸馏模块将粗粒度模块的知识转移到目标粒度模块，优化表示学习。

Result: 在四个数据集上的广泛实验证明了ReLKD的有效性，特别是在标记数据有限的情况下表现优异。

Conclusion: ReLKD通过有效利用隐式类间关系并转移知识来增强新颖类别的分类，为广义类别发现提供了一种有效的解决方案。

Abstract: Generalized Category Discovery (GCD) faces the challenge of categorizing unlabeled data containing both known and novel classes, given only labels for known classes. Previous studies often treat each class independently, neglecting the inherent inter-class relations. Obtaining such inter-class relations directly presents a significant challenge in real-world scenarios. To address this issue, we propose ReLKD, an end-to-end framework that effectively exploits implicit inter-class relations and leverages this knowledge to enhance the classification of novel classes. ReLKD comprises three key modules: a target-grained module for learning discriminative representations, a coarse-grained module for capturing hierarchical class relations, and a distillation module for transferring knowledge from the coarse-grained module to refine the target-grained module's representation learning. Extensive experiments on four datasets demonstrate the effectiveness of ReLKD, particularly in scenarios with limited labeled data. The code for ReLKD is available at https://github.com/ZhouF-ECNU/ReLKD.

</details>


### [109] [STRinGS: Selective Text Refinement in Gaussian Splatting](https://arxiv.org/abs/2512.07230)
*Abhinav Raundhal,Gaurav Behera,P J Narayanan,Ravi Kiran Sarvadevabhatla,Makarand Tapaswi*

Main category: cs.CV

TL;DR: STRinGS是一个针对3D高斯泼溅（3DGS）的文本感知选择性优化框架，通过分别处理文本和非文本区域，显著提升文本可读性，在7K迭代下相对改进63.6%。


<details>
  <summary>Details</summary>
Motivation: 真实场景中的文本（如标志、标签、说明）包含重要上下文信息，但现有3D表示方法（如3DGS）难以保留细粒度文本细节，小的文本重建错误会导致显著的语义损失。

Method: 提出STRinGS框架，将文本和非文本区域分开处理：先优化文本区域，再与优化后的非文本区域合并进行全场景优化。同时创建了STRinGS-360数据集来评估3D重建中的文本可读性。

Result: STRinGS在具有挑战性的配置下也能产生清晰可读的文本，使用OCR字符错误率（CER）评估显示，在仅7K迭代下相对3DGS有63.6%的改进。

Conclusion: STRinGS方法和数据集共同推动了文本丰富环境中3D场景理解的边界，为更鲁棒的文本感知重建方法铺平了道路。

Abstract: Text as signs, labels, or instructions is a critical element of real-world scenes as they can convey important contextual information. 3D representations such as 3D Gaussian Splatting (3DGS) struggle to preserve fine-grained text details, while achieving high visual fidelity. Small errors in textual element reconstruction can lead to significant semantic loss. We propose STRinGS, a text-aware, selective refinement framework to address this issue for 3DGS reconstruction. Our method treats text and non-text regions separately, refining text regions first and merging them with non-text regions later for full-scene optimization. STRinGS produces sharp, readable text even in challenging configurations. We introduce a text readability measure OCR Character Error Rate (CER) to evaluate the efficacy on text regions. STRinGS results in a 63.6% relative improvement over 3DGS at just 7K iterations. We also introduce a curated dataset STRinGS-360 with diverse text scenarios to evaluate text readability in 3D reconstruction. Our method and dataset together push the boundaries of 3D scene understanding in text-rich environments, paving the way for more robust text-aware reconstruction methods.

</details>


### [110] [Unified Camera Positional Encoding for Controlled Video Generation](https://arxiv.org/abs/2512.07237)
*Cheng Zhang,Boying Li,Meng Wei,Yan-Pei Cao,Camilo Cruz Gambardella,Dinh Phung,Jianfei Cai*

Main category: cs.CV

TL;DR: 本文提出UCPE（统一相机位置编码），通过相对光线编码和绝对方向编码统一表示相机姿态、内参和镜头畸变，在相机可控文本到视频生成任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有相机编码方法通常基于简化的针孔模型假设，限制了在真实世界相机多样内参和镜头畸变情况下的泛化能力。需要一种几何一致的表示方法来统一完整的相机信息。

Method: 提出相对光线编码（Relative Ray Encoding）统一表示相机6自由度姿态、内参和镜头畸变；识别俯仰和横滚作为绝对方向编码的有效组件；构建UCPE并通过轻量级空间注意力适配器集成到预训练视频扩散Transformer中。

Result: UCPE仅增加不到1%的可训练参数，在相机可控视频生成任务中实现了最先进的相机控制能力和视觉保真度。构建了覆盖广泛相机运动和镜头类型的大型视频数据集用于系统训练和评估。

Conclusion: UCPE作为Transformer的通用相机表示，在相机可控视频生成中表现出色，并有望在未来多视图、视频和3D任务中作为通用相机表示发挥作用。

Abstract: Transformers have emerged as a universal backbone across 3D perception, video generation, and world models for autonomous driving and embodied AI, where understanding camera geometry is essential for grounding visual observations in three-dimensional space. However, existing camera encoding methods often rely on simplified pinhole assumptions, restricting generalization across the diverse intrinsics and lens distortions in real-world cameras. We introduce Relative Ray Encoding, a geometry-consistent representation that unifies complete camera information, including 6-DoF poses, intrinsics, and lens distortions. To evaluate its capability under diverse controllability demands, we adopt camera-controlled text-to-video generation as a testbed task. Within this setting, we further identify pitch and roll as two components effective for Absolute Orientation Encoding, enabling full control over the initial camera orientation. Together, these designs form UCPE (Unified Camera Positional Encoding), which integrates into a pretrained video Diffusion Transformer through a lightweight spatial attention adapter, adding less than 1% trainable parameters while achieving state-of-the-art camera controllability and visual fidelity. To facilitate systematic training and evaluation, we construct a large video dataset covering a wide range of camera motions and lens types. Extensive experiments validate the effectiveness of UCPE in camera-controllable video generation and highlight its potential as a general camera representation for Transformers across future multi-view, video, and 3D tasks. Code will be available at https://github.com/chengzhag/UCPE.

</details>


### [111] [An AI-Powered Autonomous Underwater System for Sea Exploration and Scientific Research](https://arxiv.org/abs/2512.07652)
*Hamad Almazrouei,Mariam Al Nasseri,Maha Alzaabi*

Main category: cs.CV

TL;DR: 本文提出了一种AI驱动的自主水下航行器系统，结合YOLOv12 Nano实时检测、ResNet50特征提取、PCA降维、K-Means++聚类和GPT-4o Mini生成报告，用于自动化水下物体检测与分析。


<details>
  <summary>Details</summary>
Motivation: 传统海洋勘探面临极端条件、能见度有限和高成本等挑战，导致大量海洋区域未被探索。需要自动化系统来减少人类潜水风险，提高任务效率，并增强水下数据分析的深度和速度。

Method: 系统集成YOLOv12 Nano进行实时物体检测，ResNet50进行特征提取，PCA进行降维（保留98%方差），K-Means++进行基于视觉特征的聚类，以及GPT-4o Mini生成结构化报告和摘要。

Result: 在超过55,000张图像的DeepFish和OzFish数据集上评估，系统达到mAP@0.5为0.512，精度0.535，召回率0.438。PCA有效降维，K-Means成功聚类，LLM能生成有洞察力的检测摘要。

Conclusion: 该集成方法显著降低了人类潜水风险，提高了任务效率，增强了水下数据分析的速度和深度，为在挑战性海洋环境中进行更有效的科学研究铺平了道路。

Abstract: Traditional sea exploration faces significant challenges due to extreme conditions, limited visibility, and high costs, resulting in vast unexplored ocean regions. This paper presents an innovative AI-powered Autonomous Underwater Vehicle (AUV) system designed to overcome these limitations by automating underwater object detection, analysis, and reporting. The system integrates YOLOv12 Nano for real-time object detection, a Convolutional Neural Network (CNN) (ResNet50) for feature extraction, Principal Component Analysis (PCA) for dimensionality reduction, and K-Means++ clustering for grouping marine objects based on visual characteristics. Furthermore, a Large Language Model (LLM) (GPT-4o Mini) is employed to generate structured reports and summaries of underwater findings, enhancing data interpretation. The system was trained and evaluated on a combined dataset of over 55,000 images from the DeepFish and OzFish datasets, capturing diverse Australian marine environments. Experimental results demonstrate the system's capability to detect marine objects with a mAP@0.5 of 0.512, a precision of 0.535, and a recall of 0.438. The integration of PCA effectively reduced feature dimensionality while preserving 98% variance, facilitating K-Means clustering which successfully grouped detected objects based on visual similarities. The LLM integration proved effective in generating insightful summaries of detections and clusters, supported by location data. This integrated approach significantly reduces the risks associated with human diving, increases mission efficiency, and enhances the speed and depth of underwater data analysis, paving the way for more effective scientific research and discovery in challenging marine environments.

</details>


### [112] [Zero-Shot Textual Explanations via Translating Decision-Critical Features](https://arxiv.org/abs/2512.07245)
*Toshinori Yamauchi,Hiroshi Kera,Kazuhiko Kawamoto*

Main category: cs.CV

TL;DR: TEXTER是一种新的零样本图像分类器解释方法，通过识别决策关键特征并映射到CLIP特征空间来生成更忠实、可解释的文本解释


<details>
  <summary>Details</summary>
Motivation: 现有零样本解释方法将全局图像特征与语言对齐，只能描述可见内容而非驱动预测的关键因素。大型视觉语言模型虽能生成字幕，但专为通用视觉理解设计，而非分类器特定推理

Method: TEXTER首先识别对预测有贡献的神经元，强调这些神经元编码的决策关键特征，然后将这些强调的特征映射到CLIP特征空间以检索反映模型推理的文本解释。稀疏自编码器进一步提高可解释性，特别是对Transformer架构

Result: 大量实验表明，TEXTER比现有方法生成更忠实和可解释的解释

Conclusion: TEXTER通过隔离决策关键特征再对齐的方法，克服了现有零样本解释方法的局限性，能更好地揭示图像分类器的推理过程

Abstract: Textual explanations make image classifier decisions transparent by describing the prediction rationale in natural language. Large vision-language models can generate captions but are designed for general visual understanding, not classifier-specific reasoning. Existing zero-shot explanation methods align global image features with language, producing descriptions of what is visible rather than what drives the prediction. We propose TEXTER, which overcomes this limitation by isolating decision-critical features before alignment. TEXTER identifies the neurons contributing to the prediction and emphasizes the features encoded in those neurons -- i.e., the decision-critical features. It then maps these emphasized features into the CLIP feature space to retrieve textual explanations that reflect the model's reasoning. A sparse autoencoder further improves interpretability, particularly for Transformer architectures. Extensive experiments show that TEXTER generates more faithful and interpretable explanations than existing methods. The code will be publicly released.

</details>


### [113] [DIST-CLIP: Arbitrary Metadata and Image Guided MRI Harmonization via Disentangled Anatomy-Contrast Representations](https://arxiv.org/abs/2512.07674)
*Mehmet Yigit Avci,Pedro Borges,Virginia Fernandez,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso*

Main category: cs.CV

TL;DR: DIST-CLIP是一个用于MRI图像标准化的统一框架，通过解耦解剖内容和图像对比度，利用CLIP编码器和自适应风格迁移模块，支持目标图像或DICOM元数据指导，显著提升风格转换保真度和解剖结构保留。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学影像分析中应用受限，主要障碍是数据异质性。MRI中扫描仪硬件差异、采集协议多样性和序列参数变化导致显著的域偏移，掩盖了潜在的生物信号。现有图像标准化方法需要目标图像，而文本引导方法依赖过于简化的标签，无法捕捉复杂采集细节，且通常局限于有限变异性的数据集，难以应对真实临床环境的异质性。

Method: 提出DIST-CLIP框架，明确解耦解剖内容与图像对比度。使用预训练的CLIP编码器提取对比度表示，通过新颖的自适应风格迁移模块将这些对比度嵌入整合到解剖内容中。该框架灵活支持使用目标图像或DICOM元数据进行指导。

Result: 在多样化的真实临床数据集上训练和评估DIST-CLIP，与最先进方法相比，在风格转换保真度和解剖结构保留方面均显示出显著改进。提供了灵活的MRI数据标准化解决方案。

Conclusion: DIST-CLIP为MRI标准化提供了一个统一框架，能够有效处理真实临床环境中的数据异质性问题，通过解耦解剖内容和图像对比度，结合CLIP指导和自适应风格迁移，显著提升了MRI数据标准化的性能。

Abstract: Deep learning holds immense promise for transforming medical image analysis, yet its clinical generalization remains profoundly limited. A major barrier is data heterogeneity. This is particularly true in Magnetic Resonance Imaging, where scanner hardware differences, diverse acquisition protocols, and varying sequence parameters introduce substantial domain shifts that obscure underlying biological signals. Data harmonization methods aim to reduce these instrumental and acquisition variability, but existing approaches remain insufficient. When applied to imaging data, image-based harmonization approaches are often restricted by the need for target images, while existing text-guided methods rely on simplistic labels that fail to capture complex acquisition details or are typically restricted to datasets with limited variability, failing to capture the heterogeneity of real-world clinical environments. To address these limitations, we propose DIST-CLIP (Disentangled Style Transfer with CLIP Guidance), a unified framework for MRI harmonization that flexibly uses either target images or DICOM metadata for guidance. Our framework explicitly disentangles anatomical content from image contrast, with the contrast representations being extracted using pre-trained CLIP encoders. These contrast embeddings are then integrated into the anatomical content via a novel Adaptive Style Transfer module. We trained and evaluated DIST-CLIP on diverse real-world clinical datasets, and showed significant improvements in performance when compared against state-of-the-art methods in both style translation fidelity and anatomical preservation, offering a flexible solution for style transfer and standardizing MRI data. Our code and weights will be made publicly available upon publication.

</details>


### [114] [AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing](https://arxiv.org/abs/2512.07247)
*Ziming Hong,Tianyu Huang,Runnan Chen,Shanshan Ye,Mingming Gong,Bo Han,Tongliang Liu*

Main category: cs.CV

TL;DR: AdLift是首个针对3D高斯泼溅的编辑保护方法，通过将严格有界的2D对抗扰动提升到3D高斯表示中，防止任意视角和维度的指令驱动编辑。


<details>
  <summary>Details</summary>
Motivation: 随着基于扩散的指令驱动2D图像编辑扩展到3D高斯泼溅(3DGS)，虽然促进了3D内容创作，但也使3DGS资产面临未经授权编辑和恶意篡改的风险。现有针对扩散模型的对抗扰动方法在保护2D图像方面有效，但应用于3DGS面临两个主要挑战：视角通用性保护以及在不可见性和保护能力之间的平衡。

Method: 提出AdLift方法，通过将严格有界的2D对抗扰动提升到3D高斯表示的保护机制中。采用定制的Lifted PGD进行渐进优化：1)在渲染图像上对编辑模型进行梯度截断；2)应用投影梯度严格约束图像级扰动；3)通过图像到高斯的拟合操作将扰动反向传播到保护高斯参数。交替进行梯度截断和图像到高斯拟合，实现跨不同视角的一致对抗保护性能。

Result: 实验结果表明，AdLift能有效防止最先进的指令驱动2D图像和3DGS编辑，在定性和定量评估中都表现出色。

Conclusion: AdLift是首个针对3D高斯泼溅的编辑保护框架，成功解决了视角通用性保护和不可见性与保护能力平衡的挑战，为3DGS资产提供了有效的安全保障。

Abstract: Recent studies have extended diffusion-based instruction-driven 2D image editing pipelines to 3D Gaussian Splatting (3DGS), enabling faithful manipulation of 3DGS assets and greatly advancing 3DGS content creation. However, it also exposes these assets to serious risks of unauthorized editing and malicious tampering. Although imperceptible adversarial perturbations against diffusion models have proven effective for protecting 2D images, applying them to 3DGS encounters two major challenges: view-generalizable protection and balancing invisibility with protection capability. In this work, we propose the first editing safeguard for 3DGS, termed AdLift, which prevents instruction-driven editing across arbitrary views and dimensions by lifting strictly bounded 2D adversarial perturbations into 3D Gaussian-represented safeguard. To ensure both adversarial perturbations effectiveness and invisibility, these safeguard Gaussians are progressively optimized across training views using a tailored Lifted PGD, which first conducts gradient truncation during back-propagation from the editing model at the rendered image and applies projected gradients to strictly constrain the image-level perturbation. Then, the resulting perturbation is backpropagated to the safeguard Gaussian parameters via an image-to-Gaussian fitting operation. We alternate between gradient truncation and image-to-Gaussian fitting, yielding consistent adversarial-based protection performance across different viewpoints and generalizes to novel views. Empirically, qualitative and quantitative results demonstrate that AdLift effectively protects against state-of-the-art instruction-driven 2D image and 3DGS editing.

</details>


### [115] [Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment](https://arxiv.org/abs/2512.07702)
*Sangha Park,Eunji Kim,Yeongtak Oh,Jooyoung Choi,Sungroh Yoon*

Main category: cs.CV

TL;DR: NPC提出了一种自动化负提示生成方法，通过识别和应用负提示来抑制生成图像中的非预期内容，从而提升文本-图像对齐精度。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像生成取得了显著进展，但对于具有丰富组合结构或想象元素的提示，实现精确的文本-图像对齐仍然具有挑战性。现有方法在处理复杂提示时难以避免生成非预期内容。

Method: NPC采用自动化流水线：1) 分析交叉注意力模式解释目标负提示（与对齐错误直接相关）和非目标负提示（与提示无关但出现在图像中的标记）如何增强对齐；2) 使用验证器-描述器-提议器框架生成候选负提示；3) 通过显著文本空间评分对候选提示进行排序，无需额外图像合成即可有效选择。

Result: 在GenEval++和Imagine-Bench基准测试中，NPC表现优于强基线方法：在GenEval++上达到0.571 vs 0.371，在Imagine-Bench上获得最佳整体性能。

Conclusion: 通过指导模型不生成什么内容，NPC为扩散模型提供了原则性、完全自动化的途径，以实现更强的文本-图像对齐。该方法通过负提示机制有效抑制非预期内容生成。

Abstract: Despite substantial progress in text-to-image generation, achieving precise text-image alignment remains challenging, particularly for prompts with rich compositional structure or imaginative elements. To address this, we introduce Negative Prompting for Image Correction (NPC), an automated pipeline that improves alignment by identifying and applying negative prompts that suppress unintended content. We begin by analyzing cross-attention patterns to explain why both targeted negatives-those directly tied to the prompt's alignment error-and untargeted negatives-tokens unrelated to the prompt but present in the generated image-can enhance alignment. To discover useful negatives, NPC generates candidate prompts using a verifier-captioner-proposer framework and ranks them with a salient text-space score, enabling effective selection without requiring additional image synthesis. On GenEval++ and Imagine-Bench, NPC outperforms strong baselines, achieving 0.571 vs. 0.371 on GenEval++ and the best overall performance on Imagine-Bench. By guiding what not to generate, NPC provides a principled, fully automated route to stronger text-image alignment in diffusion models. Code is released at https://github.com/wiarae/NPC.

</details>


### [116] [A graph generation pipeline for critical infrastructures based on heuristics, images and depth data](https://arxiv.org/abs/2512.07269)
*Mike Diessner,Yannick Tarant*

Main category: cs.CV

TL;DR: 提出基于摄影测量的图生成流水线，使用立体相机获取RGB图像和深度数据，通过深度学习进行目标检测和实例分割，结合启发式规则推断关系，为关键基础设施创建虚拟表示


<details>
  <summary>Details</summary>
Motivation: 传统基于激光扫描的3D点云方法成本高且需要专业知识，需要更经济高效的方法为关键基础设施创建虚拟表示用于模拟和数字孪生

Method: 基于摄影测量的图生成流水线，使用立体相机获取RGB图像和深度数据，采用深度学习进行目标检测和实例分割，结合用户定义的启发式规则推断对象间关系

Result: 在两个液压系统上的实验结果表明，该方法生成的图接近真实情况，具有灵活性可针对特定应用定制，透明度高适合关键基础设施的高风险决策

Conclusion: 提出的基于摄影测量的图生成方法比传统激光扫描更经济高效，能够为关键基础设施创建准确的虚拟表示，适用于数字孪生和模拟应用

Abstract: Virtual representations of physical critical infrastructures, such as water or energy plants, are used for simulations and digital twins to ensure resilience and continuity of their services. These models usually require 3D point clouds from laser scanners that are expensive to acquire and require specialist knowledge to use. In this article, we present a graph generation pipeline based on photogrammetry. The pipeline detects relevant objects and predicts their relation using RGB images and depth data generated by a stereo camera. This more cost-effective approach uses deep learning for object detection and instance segmentation of the objects, and employs user-defined heuristics or rules to infer their relations. Results of two hydraulic systems show that this strategy can produce graphs close to the ground truth while its flexibility allows the method to be tailored to specific applications and its transparency qualifies it to be used in the high stakes decision-making that is required for critical infrastructures.

</details>


### [117] [RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2512.07273)
*Zhi Rao,Yucheng Zhou,Benjia Zhou,Yiqing Huang,Sergio Escalera,Jun Wan*

Main category: cs.CV

TL;DR: 提出RVLF框架解决手语翻译中视觉表示不足和语义对齐问题，通过融合骨架运动与视觉特征，结合GRPO强化学习优化，在多个数据集上显著提升BLEU分数。


<details>
  <summary>Details</summary>
Motivation: 当前无注释手语翻译面临两个主要挑战：1) 手语表示不足，无法捕捉细微视觉线索；2) 基于LLM的方法存在句子级语义错位，限制了翻译质量。

Method: 提出三阶段强化视觉语言框架RVLF：1) 构建专门的手语大视觉语言模型，融合骨架运动线索和DINOv2提取的视觉特征；2) 通过指令调优获得SLT-SFT基线模型；3) 引入GRPO优化策略，结合BLEU和ROUGE奖励函数微调模型，得到SLT-GRPO模型。

Result: 在CSL-Daily、PHOENIX-2014T、How2Sign和OpenASL数据集上，BLEU-4分数分别提升+5.1、+1.11、+1.4和+1.61，无需外部大规模手语数据集预训练。

Conclusion: RVLF框架有效解决了手语翻译中的表示和语义对齐问题，首次将GRPO引入手语翻译领域，实验验证了该方法在提升翻译质量和语义一致性方面的有效性。

Abstract: Gloss-free sign language translation (SLT) is hindered by two key challenges: **inadequate sign representation** that fails to capture nuanced visual cues, and **sentence-level semantic misalignment** in current LLM-based methods, which limits translation quality. To address these issues, we propose a three-stage **r**einforcing **v**ision-**l**anguage **f**ramework (**RVLF**). We build a large vision-language model (LVLM) specifically designed for sign language, and then combine it with reinforcement learning (RL) to adaptively enhance translation performance. First, for a sufficient representation of sign language, RVLF introduces an effective semantic representation learning mechanism that fuses skeleton-based motion cues with semantically rich visual features extracted via DINOv2, followed by instruction tuning to obtain a strong SLT-SFT baseline. Then, to improve sentence-level semantic misalignment, we introduce a GRPO-based optimization strategy that fine-tunes the SLT-SFT model with a reward function combining translation fidelity (BLEU) and sentence completeness (ROUGE), yielding the optimized model termed SLT-GRPO. Our conceptually simple framework yields substantial gains under the gloss-free SLT setting without pre-training on any external large-scale sign language datasets, improving BLEU-4 scores by +5.1, +1.11, +1.4, and +1.61 on the CSL-Daily, PHOENIX-2014T, How2Sign, and OpenASL datasets, respectively. To the best of our knowledge, this is the first work to incorporate GRPO into SLT. Extensive experiments and ablation studies validate the effectiveness of GRPO-based optimization in enhancing both translation quality and semantic consistency.

</details>


### [118] [SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination](https://arxiv.org/abs/2512.07730)
*Sangha Park,Seungryong Yoo,Jisoo Mok,Sungroh Yoon*

Main category: cs.CV

TL;DR: SAVE框架通过稀疏自编码器特征引导，增强视觉理解并减少多模态大语言模型中的物体幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）取得了显著进展，但它们仍然容易受到语言先验和视觉信息丢失导致的物体幻觉问题影响。

Method: 提出SAVE框架，通过稀疏自编码器（SAE）潜在特征引导模型。使用二元物体存在问答探针识别最能反映模型视觉信息处理的SAE特征（视觉理解特征），然后沿这些特征引导模型以增强基于视觉的理解。

Result: 在标准基准测试中优于最先进的无训练方法，在CHAIR_S上提升10个百分点，在POPE和MMHal-Bench上获得一致增益。多模型和多层评估证实了方法的鲁棒性和泛化性。

Conclusion: SAVE通过稀疏自编码器特征引导有效减少多模态大语言模型的物体幻觉，增强视觉理解，且设计简单高效。

Abstract: Although Multimodal Large Language Models (MLLMs) have advanced substantially, they remain vulnerable to object hallucination caused by language priors and visual information loss. To address this, we propose SAVE (Sparse Autoencoder-Driven Visual Information Enhancement), a framework that mitigates hallucination by steering the model along Sparse Autoencoder (SAE) latent features. A binary object-presence question-answering probe identifies the SAE features most indicative of the model's visual information processing, referred to as visual understanding features. Steering the model along these identified features reinforces grounded visual understanding and effectively reduces hallucination. With its simple design, SAVE outperforms state-of-the-art training-free methods on standard benchmarks, achieving a 10\%p improvement in CHAIR\_S and consistent gains on POPE and MMHal-Bench. Extensive evaluations across multiple models and layers confirm the robustness and generalizability of our approach. Further analysis reveals that steering along visual understanding features suppresses the generation of uncertain object tokens and increases attention to image tokens, mitigating hallucination. Code is released at https://github.com/wiarae/SAVE.

</details>


### [119] [Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery](https://arxiv.org/abs/2512.07276)
*Mai Tsujimoto,Junjue Wang,Weihao Xuan,Naoto Yokoya*

Main category: cs.CV

TL;DR: Geo3DVQA是一个用于评估视觉语言模型在仅使用RGB遥感图像进行三维地理空间推理能力的基准测试，包含11万个问题-答案对，涵盖16个任务类别和三个复杂度级别。


<details>
  <summary>Details</summary>
Motivation: 当前三维地理空间分析方法依赖昂贵专业传感器（如LiDAR和多光谱），限制了全球可访问性。现有方法难以整合多个3D线索、处理多样化查询并提供可解释推理。

Method: 创建Geo3DVQA基准测试，强调整合高程、天空视角因子和土地覆盖模式的真实场景。包含11万个精心策划的问题-答案对，涵盖16个任务类别和三个复杂度级别：单特征推理、多特征推理和应用级空间分析。

Result: 评估10个最先进的视觉语言模型显示RGB到3D推理的困难性：GPT-4o准确率28.6%，Gemini-2.5-Flash准确率33.0%。领域特定微调的Qwen2.5-VL-7B达到49.6%准确率（提升24.8个百分点）。

Conclusion: Geo3DVQA揭示了当前视觉语言模型的局限性，展示了领域适应的有效性，为可扩展、可访问和全面的三维地理空间分析引入了新的挑战前沿。

Abstract: Three-dimensional geospatial analysis is critical to applications in urban planning, climate adaptation, and environmental assessment. Current methodologies depend on costly, specialized sensors (e.g., LiDAR and multispectral), which restrict global accessibility. Existing sensor-based and rule-driven methods further struggle with tasks requiring the integration of multiple 3D cues, handling diverse queries, and providing interpretable reasoning. We hereby present Geo3DVQA, a comprehensive benchmark for evaluating vision-language models (VLMs) in height-aware, 3D geospatial reasoning using RGB-only remote sensing imagery. Unlike conventional sensor-based frameworks, Geo3DVQA emphasizes realistic scenarios that integrate elevation, sky view factors, and land cover patterns. The benchmark encompasses 110k curated question-answer pairs spanning 16 task categories across three complexity levels: single-feature inference, multi-feature reasoning, and application-level spatial analysis. The evaluation of ten state-of-the-art VLMs highlights the difficulty of RGB-to-3D reasoning. GPT-4o and Gemini-2.5-Flash achieved only 28.6% and 33.0% accuracy respectively, while domain-specific fine-tuning of Qwen2.5-VL-7B achieved 49.6% (+24.8 points). These results reveal both the limitations of current VLMs and the effectiveness of domain adaptation. Geo3DVQA introduces new challenge frontiers for scalable, accessible, and holistic 3D geospatial analysis. The dataset and code will be released upon publication at https://github.com/mm1129/Geo3DVQA.

</details>


### [120] [WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling](https://arxiv.org/abs/2512.07821)
*Shaoheng Fang,Hanwen Jiang,Yunpeng Bai,Niloy J. Mitra,Qixing Huang*

Main category: cs.CV

TL;DR: WorldReel是一个4D视频生成器，通过联合生成RGB帧和4D场景表示（点云图、相机轨迹、密集光流映射），实现原生时空一致性，解决了现有视频生成器在3D一致性方面的根本缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成器虽然在照片真实感方面取得了显著进展，但在3D一致性方面存在根本缺陷。为了解决视频生成中的时空不一致问题，特别是在大范围非刚性运动和显著相机移动情况下，需要开发能够保持几何和外观一致性的4D视频生成方法。

Method: WorldReel采用显式4D表示方法，联合生成RGB帧和4D场景表示（包括点云图、相机轨迹和密集光流映射）。通过结合合成数据和真实数据进行训练：合成数据提供精确的4D监督（几何、运动和相机），真实视频贡献视觉多样性和真实感。

Result: 实验表明，WorldReel在动态场景和移动相机下的视频生成方面达到了新的最先进水平，在几何一致性、运动连贯性和减少视时伪影等指标上优于竞争方法，能够泛化到野外拍摄的视频同时保持强大的几何保真度。

Conclusion: WorldReel通过显式4D表示实现了原生时空一致性，将视频生成推向4D一致的世界建模，使智能体能够通过单一稳定的时空表示来渲染、交互和推理场景。

Abstract: Recent video generators achieve striking photorealism, yet remain fundamentally inconsistent in 3D. We present WorldReel, a 4D video generator that is natively spatio-temporally consistent. WorldReel jointly produces RGB frames together with 4D scene representations, including pointmaps, camera trajectory, and dense flow mapping, enabling coherent geometry and appearance modeling over time. Our explicit 4D representation enforces a single underlying scene that persists across viewpoints and dynamic content, yielding videos that remain consistent even under large non-rigid motion and significant camera movement. We train WorldReel by carefully combining synthetic and real data: synthetic data providing precise 4D supervision (geometry, motion, and camera), while real videos contribute visual diversity and realism. This blend allows WorldReel to generalize to in-the-wild footage while preserving strong geometric fidelity. Extensive experiments demonstrate that WorldReel sets a new state-of-the-art for consistent video generation with dynamic scenes and moving cameras, improving metrics of geometric consistency, motion coherence, and reducing view-time artifacts over competing methods. We believe that WorldReel brings video generation closer to 4D-consistent world modeling, where agents can render, interact, and reason about scenes through a single and stable spatiotemporal representation.

</details>


### [121] [One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation](https://arxiv.org/abs/2512.07829)
*Yuan Gao,Chen Chen,Tianrong Chen,Jiatao Gu*

Main category: cs.CV

TL;DR: FAE是一种简单有效的框架，通过两个独立的深度解码器将预训练视觉表征适配到适合生成的低维潜在空间中，仅需单个注意力层即可实现高质量图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将预训练视觉表征适配到生成模型时面临挑战，因为理解导向的特征与生成友好的潜在空间存在根本性不匹配。表征编码器需要高维潜在空间来捕捉多样化假设，而生成模型需要低维潜在空间来保持注入噪声的保真度。

Method: 提出FAE框架，通过耦合两个独立的深度解码器：一个训练用于重建原始特征空间，另一个将重建特征作为输入进行图像生成。该方法仅需单个注意力层，可适配多种自监督编码器（如DINO、SigLIP）并集成到扩散模型和归一化流等生成模型中。

Result: 在ImageNet 256×256上，带CFG的扩散模型达到接近SOTA的FID 1.29（800轮）和1.70（80轮）；不带CFG时达到SOTA的FID 1.48（800轮）和2.08（80轮），展示了高质量和快速学习能力。

Conclusion: FAE提供了一种简单而通用的方法，能够有效将预训练视觉表征适配到生成友好的低维潜在空间中，在保持重建和理解能力的同时实现高质量的图像生成。

Abstract: Visual generative models (e.g., diffusion models) typically operate in compressed latent spaces to balance training efficiency and sample quality. In parallel, there has been growing interest in leveraging high-quality pre-trained visual representations, either by aligning them inside VAEs or directly within the generative model. However, adapting such representations remains challenging due to fundamental mismatches between understanding-oriented features and generation-friendly latent spaces. Representation encoders benefit from high-dimensional latents that capture diverse hypotheses for masked regions, whereas generative models favor low-dimensional latents that must faithfully preserve injected noise. This discrepancy has led prior work to rely on complex objectives and architectures. In this work, we propose FAE (Feature Auto-Encoder), a simple yet effective framework that adapts pre-trained visual representations into low-dimensional latents suitable for generation using as little as a single attention layer, while retaining sufficient information for both reconstruction and understanding. The key is to couple two separate deep decoders: one trained to reconstruct the original feature space, and a second that takes the reconstructed features as input for image generation. FAE is generic; it can be instantiated with a variety of self-supervised encoders (e.g., DINO, SigLIP) and plugged into two distinct generative families: diffusion models and normalizing flows. Across class-conditional and text-to-image benchmarks, FAE achieves strong performance. For example, on ImageNet 256x256, our diffusion model with CFG attains a near state-of-the-art FID of 1.29 (800 epochs) and 1.70 (80 epochs). Without CFG, FAE reaches the state-of-the-art FID of 1.48 (800 epochs) and 2.08 (80 epochs), demonstrating both high quality and fast learning.

</details>


### [122] [Relational Visual Similarity](https://arxiv.org/abs/2512.07833)
*Thao Nguyen,Sicheng Mo,Krishna Kumar Singh,Yilin Wang,Jing Shi,Nicholas Kolkin,Eli Shechtman,Yong Jae Lee,Yuheng Li*

Main category: cs.CV

TL;DR: 该论文提出了一种超越传统视觉属性相似度的关系相似度度量方法，通过匿名化描述场景关系逻辑的数据集微调视觉语言模型，首次实现了基于图像内部关系结构而非表面外观的相似度评估。


<details>
  <summary>Details</summary>
Motivation: 现有视觉相似度度量方法（如LPIPS、CLIP、DINO）仅关注感知属性相似度，无法捕捉人类能够感知的丰富关系相似度。人类不仅能识别苹果和桃子都是红色水果这样的属性相似，还能识别地球和桃子之间的结构相似性（地壳对应果皮、地幔对应果肉、地核对应果核）。这种关系相似度感知能力被认为是人类区别于其他物种的关键特征。

Method: 首先将关系图像相似度形式化为可测量问题：当两幅图像的内部关系或视觉元素之间的功能对应时，即使视觉属性不同，它们也具有关系相似性。然后构建了包含11.4万张图像-标题的数据集，其中标题经过匿名化处理，描述场景的底层关系逻辑而非表面内容。使用该数据集微调视觉语言模型，以测量图像之间的关系相似度。

Result: 开发出了首个能够基于图像底层关系结构而非可见外观来连接图像的模型。研究表明，虽然关系相似度具有许多现实应用，但现有的图像相似度模型无法捕捉这种相似度，揭示了视觉计算领域的一个重要空白。

Conclusion: 该研究填补了视觉计算中关系相似度度量的空白，提出的方法能够捕捉人类感知的丰富关系相似性，为超越表面视觉属性的图像理解开辟了新途径，具有重要的理论和应用价值。

Abstract: Humans do not just see attribute similarity -- we also see relational similarity. An apple is like a peach because both are reddish fruit, but the Earth is also like a peach: its crust, mantle, and core correspond to the peach's skin, flesh, and pit. This ability to perceive and recognize relational similarity, is arguable by cognitive scientist to be what distinguishes humans from other species. Yet, all widely used visual similarity metrics today (e.g., LPIPS, CLIP, DINO) focus solely on perceptual attribute similarity and fail to capture the rich, often surprising relational similarities that humans perceive. How can we go beyond the visible content of an image to capture its relational properties? How can we bring images with the same relational logic closer together in representation space? To answer these questions, we first formulate relational image similarity as a measurable problem: two images are relationally similar when their internal relations or functions among visual elements correspond, even if their visual attributes differ. We then curate 114k image-caption dataset in which the captions are anonymized -- describing the underlying relational logic of the scene rather than its surface content. Using this dataset, we finetune a Vision-Language model to measure the relational similarity between images. This model serves as the first step toward connecting images by their underlying relational structure rather than their visible appearance. Our study shows that while relational similarity has a lot of real-world applications, existing image similarity models fail to capture it -- revealing a critical gap in visual computing.

</details>


### [123] [Generalized Referring Expression Segmentation on Aerial Photos](https://arxiv.org/abs/2512.07338)
*Luís Marnoto,Alexandre Bernardino,Bruno Martins*

Main category: cs.CV

TL;DR: Aerial-D是一个新的大规模航空图像指代表达分割数据集，包含37,288张图像和1,522,523个指代表达，涵盖259,709个标注目标，覆盖21个类别，支持现代和历史航空图像的分割任务。


<details>
  <summary>Details</summary>
Motivation: 航空图像指代表达分割面临独特挑战：空间分辨率差异大、颜色使用不一致、目标像素少、场景物体密度高且存在部分遮挡。现有数据集不足以应对这些挑战，需要专门针对航空图像的大规模数据集。

Method: 采用全自动流水线构建数据集，结合基于规则的系统化表达生成和大型语言模型增强程序，丰富语言多样性和视觉细节关注。使用滤波器模拟历史成像条件。采用RSRefSeg架构，在Aerial-D和现有航空数据集上联合训练模型。

Result: 联合训练在当代基准测试中取得有竞争力的性能，同时在单色、棕褐色和颗粒状退化的档案航空摄影条件下保持强健的准确性。数据集、训练模型和完整软件流水线已公开。

Conclusion: Aerial-D为航空图像指代表达分割提供了大规模、多样化的数据集，通过联合训练实现了现代和历史航空图像的统一实例和语义分割，推动了该领域的发展。

Abstract: Referring expression segmentation is a fundamental task in computer vision that integrates natural language understanding with precise visual localization of target regions. Considering aerial imagery (e.g., modern aerial photos collected through drones, historical photos from aerial archives, high-resolution satellite imagery, etc.) presents unique challenges because spatial resolution varies widely across datasets, the use of color is not consistent, targets often shrink to only a few pixels, and scenes contain very high object densities and objects with partial occlusions. This work presents Aerial-D, a new large-scale referring expression segmentation dataset for aerial imagery, comprising 37,288 images with 1,522,523 referring expressions that cover 259,709 annotated targets, spanning across individual object instances, groups of instances, and semantic regions covering 21 distinct classes that range from vehicles and infrastructure to land coverage types. The dataset was constructed through a fully automatic pipeline that combines systematic rule-based expression generation with a Large Language Model (LLM) enhancement procedure that enriched both the linguistic variety and the focus on visual details within the referring expressions. Filters were additionally used to simulate historic imaging conditions for each scene. We adopted the RSRefSeg architecture, and trained models on Aerial-D together with prior aerial datasets, yielding unified instance and semantic segmentation from text for both modern and historical images. Results show that the combined training achieves competitive performance on contemporary benchmarks, while maintaining strong accuracy under monochrome, sepia, and grainy degradations that appear in archival aerial photography. The dataset, trained models, and complete software pipeline are publicly available at https://luispl77.github.io/aerial-d .

</details>


### [124] [Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting](https://arxiv.org/abs/2512.07345)
*Shilong Jin,Haoran Duan,Litao Hua,Wentao Huang,Yuan Zhou*

Main category: cs.CV

TL;DR: TD-Attn是一个解决T2I扩散模型中先验视角偏置问题的框架，通过3D感知注意力引导和分层注意力调制来提高3D任务的多视角一致性。


<details>
  <summary>Details</summary>
Motivation: 从文本到图像扩散模型蒸馏的3D任务（如生成或编辑）因不依赖大量3D训练数据而备受关注，但这些模型存在先验视角偏置问题，导致不同视角间外观冲突。主体词在交叉注意力计算中优先激活先验视角特征，而不考虑目标视角条件。

Method: 提出TD-Attn框架，包含两个关键组件：1）3D感知注意力引导模块（3D-AAG）构建视角一致的3D注意力高斯分布，强制注意力聚焦区域的空间一致性；2）分层注意力调制模块（HAM）使用语义引导树指导语义响应分析器定位和调制对视角条件高度敏感的交叉注意力层。

Result: 大量实验证实TD-Attn有潜力作为通用插件，显著提升3D任务中的多视角一致性。

Conclusion: TD-Attn通过数学分析揭示先验视角偏置的根本原因，并提出有效解决方案，能够作为通用插件增强各种3D任务的多视角一致性，同时支持可控和精确的3D编辑。

Abstract: Versatile 3D tasks (e.g., generation or editing) that distill from Text-to-Image (T2I) diffusion models have attracted significant research interest for not relying on extensive 3D training data. However, T2I models exhibit limitations resulting from prior view bias, which produces conflicting appearances between different views of an object. This bias causes subject-words to preferentially activate prior view features during cross-attention (CA) computation, regardless of the target view condition. To overcome this limitation, we conduct a comprehensive mathematical analysis to reveal the root cause of the prior view bias in T2I models. Moreover, we find different UNet layers show different effects of prior view in CA. Therefore, we propose a novel framework, TD-Attn, which addresses multi-view inconsistency via two key components: (1) the 3D-Aware Attention Guidance Module (3D-AAG) constructs a view-consistent 3D attention Gaussian for subject-words to enforce spatial consistency across attention-focused regions, thereby compensating for the limited spatial information in 2D individual view CA maps; (2) the Hierarchical Attention Modulation Module (HAM) utilizes a Semantic Guidance Tree (SGT) to direct the Semantic Response Profiler (SRP) in localizing and modulating CA layers that are highly responsive to view conditions, where the enhanced CA maps further support the construction of more consistent 3D attention Gaussians. Notably, HAM facilitates semantic-specific interventions, enabling controllable and precise 3D editing. Extensive experiments firmly establish that TD-Attn has the potential to serve as a universal plugin, significantly enhancing multi-view consistency across 3D tasks.

</details>


### [125] [MICo-150K: A Comprehensive Dataset Advancing Multi-Image Composition](https://arxiv.org/abs/2512.07348)
*Xinyu Wei,Kangrui Cen,Hongyang Wei,Zhen Guo,Bairui Li,Zeqing Wang,Jinrui Zhang,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出了MICo-150K数据集、MICo-Bench基准测试和Qwen-MICo基线模型，用于解决多图像组合（MICo）任务中缺乏高质量训练数据的问题。


<details>
  <summary>Details</summary>
Motivation: 在可控图像生成中，从多个参考输入合成连贯一致的图像（即多图像组合MICo）仍然是一个挑战，部分原因是缺乏高质量的训练数据。为了填补这一空白，作者对MICo进行了系统研究。

Method: 1. 将MICo分类为7个代表性任务；2. 收集高质量源图像并构建多样化的MICo提示；3. 利用强大的专有模型合成大量平衡的复合图像；4. 通过人工循环过滤和精炼，创建MICo-150K数据集；5. 构建分解与重组（De&Re）子集；6. 建立MICo-Bench基准测试；7. 提出新的评估指标Weighted-Ref-VIEScore；8. 在MICo-150K上微调多个模型。

Result: MICo-150K数据集有效提升了模型的MICo能力，基线模型Qwen-MICo在3图像组合任务中与Qwen-Image-2509表现相当，同时支持任意多图像输入，突破了后者的限制。

Conclusion: 本文提出的数据集、基准测试和基线模型为多图像组合的进一步研究提供了有价值的资源，能够有效提升模型的MICo能力，支持更灵活的多图像输入组合。

Abstract: In controllable image generation, synthesizing coherent and consistent images from multiple reference inputs, i.e., Multi-Image Composition (MICo), remains a challenging problem, partly hindered by the lack of high-quality training data. To bridge this gap, we conduct a systematic study of MICo, categorizing it into 7 representative tasks and curate a large-scale collection of high-quality source images and construct diverse MICo prompts. Leveraging powerful proprietary models, we synthesize a rich amount of balanced composite images, followed by human-in-the-loop filtering and refinement, resulting in MICo-150K, a comprehensive dataset for MICo with identity consistency. We further build a Decomposition-and-Recomposition (De&Re) subset, where 11K real-world complex images are decomposed into components and recomposed, enabling both real and synthetic compositions. To enable comprehensive evaluation, we construct MICo-Bench with 100 cases per task and 300 challenging De&Re cases, and further introduce a new metric, Weighted-Ref-VIEScore, specifically tailored for MICo evaluation. Finally, we fine-tune multiple models on MICo-150K and evaluate them on MICo-Bench. The results show that MICo-150K effectively equips models without MICo capability and further enhances those with existing skills. Notably, our baseline model, Qwen-MICo, fine-tuned from Qwen-Image-Edit, matches Qwen-Image-2509 in 3-image composition while supporting arbitrary multi-image inputs beyond the latter's limitation. Our dataset, benchmark, and baseline collectively offer valuable resources for further research on Multi-Image Composition.

</details>


### [126] [Tessellation GS: Neural Mesh Gaussians for Robust Monocular Reconstruction of Dynamic Objects](https://arxiv.org/abs/2512.07381)
*Shuohan Tao,Boyao Zhou,Hanzhang Tu,Yuwang Wang,Yebin Liu*

Main category: cs.CV

TL;DR: Tessellation GS：一种基于网格面的结构化2D高斯泼溅方法，用于从单摄像头重建动态场景，通过自适应面细分和重建基础模型先验，显著提升稀疏视角和动态场景的重建性能。


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯泼溅在视角外推方面存在困难，容易过拟合且泛化能力差，特别是在稀疏视角和动态场景重建中表现不佳。需要一种能够从单摄像头（连续移动或静态）重建动态场景的鲁棒方法。

Method: 提出Tessellation GS方法：1) 将2D高斯约束在网格面的局部区域；2) 通过网格面上的分层神经特征推断高斯属性；3) 采用由细节感知损失函数驱动的自适应面细分策略指导高斯细分；4) 利用重建基础模型的先验初始化高斯变形，支持从单静态摄像头重建一般动态物体。

Result: 方法在表观和网格重建任务上显著优于先前SOTA方法：LPIPS降低29.1%，Chamfer距离降低49.2%。能够从单静态摄像头鲁棒重建一般动态物体，这在基于优化的方法中以前极具挑战性。

Conclusion: Tessellation GS通过结构化2D高斯泼溅方法，结合网格面约束、自适应细分和基础模型先验，有效解决了3D高斯泼溅在动态场景重建中的局限性，实现了从单摄像头的高质量动态场景重建。

Abstract: 3D Gaussian Splatting (GS) enables highly photorealistic scene reconstruction from posed image sequences but struggles with viewpoint extrapolation due to its anisotropic nature, leading to overfitting and poor generalization, particularly in sparse-view and dynamic scene reconstruction. We propose Tessellation GS, a structured 2D GS approach anchored on mesh faces, to reconstruct dynamic scenes from a single continuously moving or static camera. Our method constrains 2D Gaussians to localized regions and infers their attributes via hierarchical neural features on mesh faces. Gaussian subdivision is guided by an adaptive face subdivision strategy driven by a detail-aware loss function. Additionally, we leverage priors from a reconstruction foundation model to initialize Gaussian deformations, enabling robust reconstruction of general dynamic objects from a single static camera, previously extremely challenging for optimization-based methods. Our method outperforms previous SOTA method, reducing LPIPS by 29.1% and Chamfer distance by 49.2% on appearance and mesh reconstruction tasks.

</details>


### [127] [LogicCBMs: Logic-Enhanced Concept-Based Learning](https://arxiv.org/abs/2512.07383)
*Deepika SN Vemuri,Gautham Bellamkonda,Aditya Pola,Vineeth N Balasubramanian*

Main category: cs.CV

TL;DR: 论文提出LogicCBM，在概念瓶颈模型基础上引入可微逻辑模块，通过命题逻辑操作连接概念，超越简单的线性组合，提高模型表达能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型主要关注可解释性，通过语义概念的线性组合进行预测，但这种线性组合存在固有局限性，需要更丰富的概念组合方式。

Method: 提出LogicCBM，在概念瓶颈模型中引入精心设计的逻辑模块，通过可微逻辑操作连接学习到的概念，支持各种逻辑运算生成最终预测，同时保持端到端可学习性。

Result: 在知名基准数据集和合成数据集上的实证研究表明，这些模型具有更好的准确性，能够执行有效的干预，并且具有高度可解释性。

Conclusion: 通过命题逻辑增强概念学习模型，LogicCBM能够超越简单的加权概念组合，利用逻辑操作捕捉概念间关系，同时提高模型在逻辑运算方面的表达能力。

Abstract: Concept Bottleneck Models (CBMs) provide a basis for semantic abstractions within a neural network architecture. Such models have primarily been seen through the lens of interpretability so far, wherein they offer transparency by inferring predictions as a linear combination of semantic concepts. However, a linear combination is inherently limiting. So we propose the enhancement of concept-based learning models through propositional logic. We introduce a logic module that is carefully designed to connect the learned concepts from CBMs through differentiable logic operations, such that our proposed LogicCBM can go beyond simple weighted combinations of concepts to leverage various logical operations to yield the final predictions, while maintaining end-to-end learnability. Composing concepts using a set of logic operators enables the model to capture inter-concept relations, while simultaneously improving the expressivity of the model in terms of logic operations. Our empirical studies on well-known benchmarks and synthetic datasets demonstrate that these models have better accuracy, perform effective interventions and are highly interpretable.

</details>


### [128] [How Far are Modern Trackers from UAV-Anti-UAV? A Million-Scale Benchmark and New Baseline](https://arxiv.org/abs/2512.07385)
*Chunhui Zhang,Li Liu,Zhipeng Zhang,Yong Wang,Hao Wen,Xi Zhou,Shiming Ge,Yanfeng Wang*

Main category: cs.CV

TL;DR: 提出新的无人机反无人机多模态视觉跟踪任务UAV-Anti-UAV，构建百万级数据集，并开发基于Mamba的基线方法MambaSTS，实验显示该领域仍有很大改进空间。


<details>
  <summary>Details</summary>
Motivation: 当前反无人机研究主要关注固定地面摄像头捕获的RGB、红外或RGB-IR视频，缺乏从移动无人机平台跟踪目标无人机的研究。无人机反无人机任务面临双动态干扰的挑战，需要新的解决方案。

Method: 提出MambaSTS方法，基于Mamba和Transformer模型分别学习全局语义和空间特征，利用状态空间模型在长序列建模中的优势，通过时间令牌传播机制建立视频级长期上下文。

Result: 构建了包含1,810个视频的百万级数据集，每个视频都有人工标注的边界框、语言提示和15个跟踪属性。对50种现代深度跟踪算法的实验评估表明，UAV-Anti-UAV领域仍有显著改进空间。

Conclusion: 提出了新的无人机反无人机跟踪任务和数据集，开发了有效的基线方法，为这一具有挑战性的领域提供了研究基础，并展示了该领域未来发展的潜力。

Abstract: Unmanned Aerial Vehicles (UAVs) offer wide-ranging applications but also pose significant safety and privacy violation risks in areas like airport and infrastructure inspection, spurring the rapid development of Anti-UAV technologies in recent years. However, current Anti-UAV research primarily focuses on RGB, infrared (IR), or RGB-IR videos captured by fixed ground cameras, with little attention to tracking target UAVs from another moving UAV platform. To fill this gap, we propose a new multi-modal visual tracking task termed UAV-Anti-UAV, which involves a pursuer UAV tracking a target adversarial UAV in the video stream. Compared to existing Anti-UAV tasks, UAV-Anti-UAV is more challenging due to severe dual-dynamic disturbances caused by the rapid motion of both the capturing platform and the target. To advance research in this domain, we construct a million-scale dataset consisting of 1,810 videos, each manually annotated with bounding boxes, a language prompt, and 15 tracking attributes. Furthermore, we propose MambaSTS, a Mamba-based baseline method for UAV-Anti-UAV tracking, which enables integrated spatial-temporal-semantic learning. Specifically, we employ Mamba and Transformer models to learn global semantic and spatial features, respectively, and leverage the state space model's strength in long-sequence modeling to establish video-level long-term context via a temporal token propagation mechanism. We conduct experiments on the UAV-Anti-UAV dataset to validate the effectiveness of our method. A thorough experimental evaluation of 50 modern deep tracking algorithms demonstrates that there is still significant room for improvement in the UAV-Anti-UAV domain. The dataset and codes will be available at {\color{magenta}https://github.com/983632847/Awesome-Multimodal-Object-Tracking}.

</details>


### [129] [Reconstructing Objects along Hand Interaction Timelines in Egocentric Video](https://arxiv.org/abs/2512.07394)
*Zhifan Zhu,Siddhant Bansal,Shashank Tripathi,Dima Damen*

Main category: cs.CV

TL;DR: 提出ROHIT任务，通过手交互时间线(HIT)建模物体姿态约束，使用COP框架传播姿态实现更好的重建，在无3D真值情况下评估重建质量


<details>
  <summary>Details</summary>
Motivation: 研究手与物体交互过程中的物体姿态变化，特别是在稳定抓握阶段，提出无需3D真值即可评估物体重建的方法

Method: 定义手交互时间线(HIT)，建模物体在不同阶段的姿态约束，提出约束优化与传播(COP)框架来传播物体姿态

Result: 在HOT3D和EPIC-Kitchens数据集上评估，COP框架将稳定抓握重建提升6.2-11.3%，HIT重建提升达24.5%

Conclusion: ROHIT任务和COP框架能有效重建手交互过程中的物体，特别是在稳定抓握阶段，为无3D真值的视频物体重建提供了新方法

Abstract: We introduce the task of Reconstructing Objects along Hand Interaction Timelines (ROHIT). We first define the Hand Interaction Timeline (HIT) from a rigid object's perspective. In a HIT, an object is first static relative to the scene, then is held in hand following contact, where its pose changes. This is usually followed by a firm grip during use, before it is released to be static again w.r.t. to the scene. We model these pose constraints over the HIT, and propose to propagate the object's pose along the HIT enabling superior reconstruction using our proposed Constrained Optimisation and Propagation (COP) framework. Importantly, we focus on timelines with stable grasps - i.e. where the hand is stably holding an object, effectively maintaining constant contact during use. This allows us to efficiently annotate, study, and evaluate object reconstruction in videos without 3D ground truth. We evaluate our proposed task, ROHIT, over two egocentric datasets, HOT3D and in-the-wild EPIC-Kitchens. In HOT3D, we curate 1.2K clips of stable grasps. In EPIC-Kitchens, we annotate 2.4K clips of stable grasps including 390 object instances across 9 categories from videos of daily interactions in 141 environments. Without 3D ground truth, we utilise 2D projection error to assess the reconstruction. Quantitatively, COP improves stable grasp reconstruction by 6.2-11.3% and HIT reconstruction by up to 24.5% with constrained pose propagation.

</details>


### [130] [InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs](https://arxiv.org/abs/2512.07410)
*Bin Li,Ruichi Zhang,Han Liang,Jingyan Zhang,Juze Zhang,Xin Chen,Lan Xu,Jingyi Yu,Jingya Wang*

Main category: cs.CV

TL;DR: InterAgent是首个基于物理的文本驱动多智能体人形控制端到端框架，通过自回归扩散变换器和多流块设计，实现物理合理且语义一致的多智能体交互行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要局限于单智能体场景，忽略了多智能体交互中必要的物理合理交互作用，需要开发能够模拟人类社交行为复杂协调的多智能体控制框架。

Method: 提出自回归扩散变换器配备多流块，解耦本体感觉、外感受和动作以避免跨模态干扰；引入交互图外感受表示捕获细粒度关节间空间依赖；设计稀疏边基注意力机制动态修剪冗余连接并强调关键智能体间空间关系。

Result: InterAgent在广泛实验中始终优于多个强基线，达到最先进性能，能够仅从文本提示生成连贯、物理合理且语义忠实的多智能体行为。

Conclusion: InterAgent成功填补了多智能体物理交互控制的空白，为文本驱动的多智能体人形控制提供了首个端到端解决方案，其代码和数据将公开发布以促进未来研究。

Abstract: Humanoid agents are expected to emulate the complex coordination inherent in human social behaviors. However, existing methods are largely confined to single-agent scenarios, overlooking the physically plausible interplay essential for multi-agent interactions. To bridge this gap, we propose InterAgent, the first end-to-end framework for text-driven physics-based multi-agent humanoid control. At its core, we introduce an autoregressive diffusion transformer equipped with multi-stream blocks, which decouples proprioception, exteroception, and action to mitigate cross-modal interference while enabling synergistic coordination. We further propose a novel interaction graph exteroception representation that explicitly captures fine-grained joint-to-joint spatial dependencies to facilitate network learning. Additionally, within it we devise a sparse edge-based attention mechanism that dynamically prunes redundant connections and emphasizes critical inter-agent spatial relations, thereby enhancing the robustness of interaction modeling. Extensive experiments demonstrate that InterAgent consistently outperforms multiple strong baselines, achieving state-of-the-art performance. It enables producing coherent, physically plausible, and semantically faithful multi-agent behaviors from only text prompts. Our code and data will be released to facilitate future research.

</details>


### [131] [Unified Video Editing with Temporal Reasoner](https://arxiv.org/abs/2512.07469)
*Xiangpeng Yang,Ji Xie,Yiyuan Yang,Yan Huang,Min Xu,Qiang Wu*

Main category: cs.CV

TL;DR: VideoCoF提出了一种基于帧链推理的视频编辑方法，通过预测编辑区域潜在表示实现无掩码的精确指令到区域对齐，仅需5万视频对即可达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法面临关键权衡：专家模型依赖任务特定先验（如掩码）难以统一，而统一的时间上下文学习模型虽无需掩码但缺乏显式空间线索，导致指令到区域映射不精确。

Method: 提出VideoCoF框架，受思维链启发采用"看、推理、再编辑"流程，强制视频扩散模型先预测推理标记（编辑区域潜在表示）再生成目标视频标记；引入RoPE对齐策略利用推理标记确保运动对齐并支持长度外推。

Result: 仅使用5万视频对数据，在VideoCoF-Bench上达到最先进性能，验证了方法的效率和有效性，实现了无掩码的精确指令到区域对齐和细粒度视频编辑。

Conclusion: VideoCoF通过显式推理步骤解决了视频编辑中精度与统一性的冲突，无需用户提供掩码即可实现精确的指令到区域对齐，为视频编辑提供了高效统一的解决方案。

Abstract: Existing video editing methods face a critical trade-off: expert models offer precision but rely on task-specific priors like masks, hindering unification; conversely, unified temporal in-context learning models are mask-free but lack explicit spatial cues, leading to weak instruction-to-region mapping and imprecise localization. To resolve this conflict, we propose VideoCoF, a novel Chain-of-Frames approach inspired by Chain-of-Thought reasoning. VideoCoF enforces a ``see, reason, then edit" procedure by compelling the video diffusion model to first predict reasoning tokens (edit-region latents) before generating the target video tokens. This explicit reasoning step removes the need for user-provided masks while achieving precise instruction-to-region alignment and fine-grained video editing. Furthermore, we introduce a RoPE alignment strategy that leverages these reasoning tokens to ensure motion alignment and enable length extrapolation beyond the training duration. We demonstrate that with a minimal data cost of only 50k video pairs, VideoCoF achieves state-of-the-art performance on VideoCoF-Bench, validating the efficiency and effectiveness of our approach. Our code, weight, data are available at https://github.com/knightyxp/VideoCoF.

</details>


### [132] [Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance](https://arxiv.org/abs/2512.07480)
*Naifu Xue,Zhaoyang Jia,Jiahao Li,Bin Li,Zihan Zheng,Yuan Zhang,Yan Lu*

Main category: cs.CV

TL;DR: S2VC是一种基于单步扩散的视频编解码器，通过条件编码框架和高效单步扩散生成器，在低比特率下实现逼真重建，同时降低采样成本。


<details>
  <summary>Details</summary>
Motivation: 传统和神经视频编解码器在低比特率下的感知质量提升仍然具有挑战性。现有方法要么受限于生成能力导致伪影，要么依赖预训练扩散模型但采样复杂度高。需要一种既能提高感知质量又能降低计算成本的方法。

Method: 提出S2VC单步扩散视频编解码器：1）结合条件编码框架与高效单步扩散生成器；2）引入上下文语义指导，从缓冲特征中提取帧自适应语义，替代文本描述；3）在扩散U-Net中加入时间一致性指导，确保帧间时序连贯性。

Result: 实验表明S2VC实现了最先进的感知质量，相比之前的感知方法平均节省52.73%的比特率，证明了单步扩散在高效高质量视频压缩中的潜力。

Conclusion: S2VC通过单步扩散生成器和创新的语义与时序指导机制，在低比特率下实现了高质量的感知重建，显著降低了计算复杂度，为视频压缩提供了新的高效解决方案。

Abstract: While traditional and neural video codecs (NVCs) have achieved remarkable rate-distortion performance, improving perceptual quality at low bitrates remains challenging. Some NVCs incorporate perceptual or adversarial objectives but still suffer from artifacts due to limited generation capacity, whereas others leverage pretrained diffusion models to improve quality at the cost of heavy sampling complexity. To overcome these challenges, we propose S2VC, a Single-Step diffusion based Video Codec that integrates a conditional coding framework with an efficient single-step diffusion generator, enabling realistic reconstruction at low bitrates with reduced sampling cost. Recognizing the importance of semantic conditioning in single-step diffusion, we introduce Contextual Semantic Guidance to extract frame-adaptive semantics from buffered features. It replaces text captions with efficient, fine-grained conditioning, thereby improving generation realism. In addition, Temporal Consistency Guidance is incorporated into the diffusion U-Net to enforce temporal coherence across frames and ensure stable generation. Extensive experiments show that S2VC delivers state-of-the-art perceptual quality with an average 52.73% bitrate saving over prior perceptual methods, underscoring the promise of single-step diffusion for efficient, high-quality video compression.

</details>


### [133] [MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer](https://arxiv.org/abs/2512.07500)
*Penghui Liu,Jiangshan Wang,Yutong Shen,Shanhui Mo,Chenyang Qi,Yue Ma*

Main category: cs.CV

TL;DR: MultiMotion是一个用于多对象视频运动迁移的统一框架，通过Mask-aware Attention Motion Flow和RectPC采样器解决了DiT架构中的运动纠缠和对象级控制问题。


<details>
  <summary>Details</summary>
Motivation: 多对象视频运动迁移对Diffusion Transformer架构存在挑战，主要问题是运动纠缠和缺乏对象级控制，需要解决这些限制以实现精确的多对象运动迁移。

Method: 提出Mask-aware Attention Motion Flow，利用SAM2掩码在DiT流程中显式解缠和控制多对象运动特征；引入RectPC高阶预测-校正采样器用于高效准确采样；构建首个基于DiT的多对象运动迁移基准数据集。

Result: MultiMotion实现了精确、语义对齐且时间一致的多对象运动迁移，保持了DiT的高质量和可扩展性，在构建的基准数据集上表现出色。

Conclusion: MultiMotion框架成功解决了DiT在多对象视频运动迁移中的核心挑战，通过AMF和RectPC实现了对多个不同对象的精确运动控制，为相关研究提供了新方法和基准。

Abstract: Multi-object video motion transfer poses significant challenges for Diffusion Transformer (DiT) architectures due to inherent motion entanglement and lack of object-level control. We present MultiMotion, a novel unified framework that overcomes these limitations. Our core innovation is Maskaware Attention Motion Flow (AMF), which utilizes SAM2 masks to explicitly disentangle and control motion features for multiple objects within the DiT pipeline. Furthermore, we introduce RectPC, a high-order predictor-corrector solver for efficient and accurate sampling, particularly beneficial for multi-entity generation. To facilitate rigorous evaluation, we construct the first benchmark dataset specifically for DiT-based multi-object motion transfer. MultiMotion demonstrably achieves precise, semantically aligned, and temporally coherent motion transfer for multiple distinct objects, maintaining DiT's high quality and scalability. The code is in the supp.

</details>


### [134] [SJD++: Improved Speculative Jacobi Decoding for Training-free Acceleration of Discrete Auto-regressive Text-to-Image Generation](https://arxiv.org/abs/2512.07503)
*Yao Teng,Zhihuan Jiang,Han Shi,Xian Liu,Xuefei Ning,Guohao Dai,Yu Wang,Zhenguo Li,Xihui Liu*

Main category: cs.CV

TL;DR: SJD++是一种无需训练的概率并行解码算法，通过多令牌预测和草稿验证机制，将自回归文本到图像生成的推理速度提升2-3倍，步骤压缩2-7倍，同时保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 大型自回归模型虽然能生成高质量高分辨率图像，但推理速度缓慢，因为需要数百到数千次顺序前向传递进行下一个令牌预测。需要加速自回归文本到图像生成过程。

Method: 提出Speculative Jacobi Decoding++ (SJD++)算法，结合Jacobi解码的迭代多令牌预测机制和推测采样的概率草稿验证机制。关键创新是在每次验证后重用高置信度草稿令牌而不是全部重新采样。

Result: 在多个代表性自回归文本到图像生成模型上的实验表明，SJD++实现了2-3倍的推理延迟减少和2-7倍的步骤压缩，同时保持视觉质量无明显下降。

Conclusion: SJD++是一种有效的训练免费加速方法，显著提升自回归图像生成效率，为实际应用提供了可行的解决方案。

Abstract: Large autoregressive models can generate high-quality, high-resolution images but suffer from slow generation speed, because these models require hundreds to thousands of sequential forward passes for next-token prediction during inference. To accelerate autoregressive text-to-image generation, we propose Speculative Jacobi Decoding++ (SJD++), a training-free probabilistic parallel decoding algorithm. Unlike traditional next-token prediction, SJD++ performs multi-token prediction in each forward pass, drastically reducing generation steps. Specifically, it integrates the iterative multi-token prediction mechanism from Jacobi decoding, with the probabilistic drafting-and-verification mechanism from speculative sampling. More importantly, for further acceleration, SJD++ reuses high-confidence draft tokens after each verification phase instead of resampling them all. We conduct extensive experiments on several representative autoregressive text-to-image generation models and demonstrate that SJD++ achieves $2\times$ to $3\times$ inference latency reduction and $2\times$ to $7\times$ step compression, while preserving visual quality with no observable degradation.

</details>


### [135] [ControlVP: Interactive Geometric Refinement of AI-Generated Images with Consistent Vanishing Points](https://arxiv.org/abs/2512.07504)
*Ryota Okumura,Kaede Shiohara,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: ControlVP：一种用户引导的框架，用于纠正生成图像中的消失点不一致问题，提高几何一致性


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型（如Stable Diffusion）虽然视觉质量出色，但经常存在几何不一致问题，特别是消失点不一致，导致平行线在2D空间中无法正确收敛，破坏了场景的结构真实感，尤其是在建筑场景中。

Method: 提出了ControlVP框架，扩展预训练扩散模型，通过建筑轮廓的结构引导和几何约束，显式鼓励图像边缘与透视线索对齐。

Result: 该方法增强了全局几何一致性，同时保持了与基线相当的视觉保真度，特别适用于需要准确空间结构的应用（如图像到3D重建）。

Conclusion: ControlVP通过用户引导的消失点校正，有效解决了生成图像中的几何不一致问题，提高了场景的结构真实感。

Abstract: Recent text-to-image models, such as Stable Diffusion, have achieved impressive visual quality, yet they often suffer from geometric inconsistencies that undermine the structural realism of generated scenes. One prominent issue is vanishing point inconsistency, where projections of parallel lines fail to converge correctly in 2D space. This leads to structurally implausible geometry that degrades spatial realism, especially in architectural scenes. We propose ControlVP, a user-guided framework for correcting vanishing point inconsistencies in generated images. Our approach extends a pre-trained diffusion model by incorporating structural guidance derived from building contours. We also introduce geometric constraints that explicitly encourage alignment between image edges and perspective cues. Our method enhances global geometric consistency while maintaining visual fidelity comparable to the baselines. This capability is particularly valuable for applications that require accurate spatial structure, such as image-to-3D reconstruction. The dataset and source code are available at https://github.com/RyotaOkumura/ControlVP .

</details>


### [136] [MeshRipple: Structured Autoregressive Generation of Artist-Meshes](https://arxiv.org/abs/2512.07514)
*Junkai Lin,Hang Long,Huipeng Guo,Jielei Zhang,JiaYi Yang,Tianle Guo,Yang Yang,Jianwen Li,Wenxiao Zhang,Matthias Nießner,Wei Yang*

Main category: cs.CV

TL;DR: MeshRipple通过前沿感知的BFS标记化、扩展预测策略和稀疏注意力全局内存，解决了自回归网格生成中长距离几何依赖断裂的问题，生成具有高表面保真度和拓扑完整性的网格。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归网格生成方法将面序列化并训练截断段，使用滑动窗口推理来应对内存限制，但这种不匹配破坏了长距离几何依赖关系，导致孔洞和碎片化组件。

Method: MeshRipple包含三个关键创新：1）前沿感知的BFS标记化，使生成顺序与表面拓扑对齐；2）扩展预测策略，保持连贯、连接的表面增长；3）稀疏注意力全局内存，提供有效无界的感受野来解决长距离拓扑依赖。

Result: MeshRipple能够生成具有高表面保真度和拓扑完整性的网格，在性能上超越了近期强大的基线方法。

Conclusion: MeshRipple通过其集成设计解决了自回归网格生成中的关键限制，实现了连贯的网格生成，避免了传统方法中的孔洞和碎片化问题。

Abstract: Meshes serve as a primary representation for 3D assets. Autoregressive mesh generators serialize faces into sequences and train on truncated segments with sliding-window inference to cope with memory limits. However, this mismatch breaks long-range geometric dependencies, producing holes and fragmented components. To address this critical limitation, we introduce MeshRipple, which expands a mesh outward from an active generation frontier, akin to a ripple on a surface.MeshRipple rests on three key innovations: a frontier-aware BFS tokenization that aligns the generation order with surface topology; an expansive prediction strategy that maintains coherent, connected surface growth; and a sparse-attention global memory that provides an effectively unbounded receptive field to resolve long-range topological dependencies.This integrated design enables MeshRipple to generate meshes with high surface fidelity and topological completeness, outperforming strong recent baselines.

</details>


### [137] [LongCat-Image Technical Report](https://arxiv.org/abs/2512.07584)
*Meituan LongCat Team,Hanghang Ma,Haoxian Tan,Jiale Huang,Junqiang Wu,Jun-Yan He,Lishuai Gao,Songlin Xiao,Xiaoming Wei,Xiaoqi Ma,Xunliang Cai,Yayong Guan,Jie Hu*

Main category: cs.CV

TL;DR: LongCat-Image是一个开源的英中双语图像生成基础模型，在文本渲染、真实感、部署效率和开发者可访问性方面取得突破，通过6B参数实现高效部署，并建立了完整的开源生态系统。


<details>
  <summary>Details</summary>
Motivation: 解决当前主流模型在多语言文本渲染（特别是中文字符）、真实感、部署效率和开发者可访问性方面的核心挑战，推动视觉内容创作的前沿发展。

Method: 采用严格的数据策展策略，涵盖预训练、中期训练和SFT阶段，并在强化学习阶段协调使用精心设计的奖励模型；采用紧凑的6B参数扩散模型设计，显著小于常见的20B+ MoE架构。

Result: 1) 在文本渲染能力和真实感方面达到新的SOTA水平；2) 为中文字符渲染设定了新的行业标准，支持复杂和罕见字符，在覆盖范围和准确性上超越开源和商业方案；3) 6B参数模型实现高效部署，VRAM使用最小化，推理速度快；4) 在图像编辑任务上也达到SOTA结果，编辑一致性优于其他开源工作。

Conclusion: LongCat-Image通过创新的训练策略和紧凑架构，在多语言文本渲染、真实感和部署效率方面取得突破性进展，并通过完整的开源生态系统为开发者和研究人员提供强大支持，推动视觉内容创作的发展。

Abstract: We introduce LongCat-Image, a pioneering open-source and bilingual (Chinese-English) foundation model for image generation, designed to address core challenges in multilingual text rendering, photorealism, deployment efficiency, and developer accessibility prevalent in current leading models. 1) We achieve this through rigorous data curation strategies across the pre-training, mid-training, and SFT stages, complemented by the coordinated use of curated reward models during the RL phase. This strategy establishes the model as a new state-of-the-art (SOTA), delivering superior text-rendering capabilities and remarkable photorealism, and significantly enhancing aesthetic quality. 2) Notably, it sets a new industry standard for Chinese character rendering. By supporting even complex and rare characters, it outperforms both major open-source and commercial solutions in coverage, while also achieving superior accuracy. 3) The model achieves remarkable efficiency through its compact design. With a core diffusion model of only 6B parameters, it is significantly smaller than the nearly 20B or larger Mixture-of-Experts (MoE) architectures common in the field. This ensures minimal VRAM usage and rapid inference, significantly reducing deployment costs. Beyond generation, LongCat-Image also excels in image editing, achieving SOTA results on standard benchmarks with superior editing consistency compared to other open-source works. 4) To fully empower the community, we have established the most comprehensive open-source ecosystem to date. We are releasing not only multiple model versions for text-to-image and image editing, including checkpoints after mid-training and post-training stages, but also the entire toolchain of training procedure. We believe that the openness of LongCat-Image will provide robust support for developers and researchers, pushing the frontiers of visual content creation.

</details>


### [138] [More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery](https://arxiv.org/abs/2512.07596)
*Wenzhen Dong,Jieming Yu,Yiming Huang,Hongqiu Wang,Lei Zhu,Albert C. S. Chung,Hongliang Ren,Long Bai*

Main category: cs.CV

TL;DR: SAM 3在机器人辅助手术中表现出色，在图像和视频分割方面相比SAM和SAM 2有明显改进，支持零样本分割和3D重建，但语言提示在手术领域表现欠佳，复杂动态场景仍有局限。


<details>
  <summary>Details</summary>
Motivation: 评估SAM 3在机器人辅助手术中的性能，特别是其零样本分割能力（点、边界框和语言提示）以及3D重建功能，探索其在动态手术场景中的应用潜力。

Method: 使用MICCAI EndoVis 2017和EndoVis 2018基准测试SAM 3的图像和视频分割性能，通过SCARED、StereoMIS和EndoNeRF数据集进行零样本评估，测试其单目深度估计和3D器械重建能力。

Result: SAM 3在空间提示下的图像和视频分割性能明显优于SAM和SAM 2；在单目深度估计和3D器械重建方面表现良好；但语言提示在手术领域表现不理想；复杂动态手术场景仍存在局限性。

Conclusion: SAM 3在机器人辅助手术中展现出显著进步，特别是在空间提示分割和3D重建方面，但需要针对手术领域进行专门训练以改进语言提示性能，并需进一步提升在复杂动态场景中的表现。

Abstract: The recent Segment Anything Model (SAM) 3 has introduced significant advancements over its predecessor, SAM 2, particularly with the integration of language-based segmentation and enhanced 3D perception capabilities. SAM 3 supports zero-shot segmentation across a wide range of prompts, including point, bounding box, and language-based prompts, allowing for more flexible and intuitive interactions with the model. In this empirical evaluation, we assess the performance of SAM 3 in robot-assisted surgery, benchmarking its zero-shot segmentation with point and bounding box prompts and exploring its effectiveness in dynamic video tracking, alongside its newly introduced language prompt segmentation. While language prompts show potential, their performance in the surgical domain is currently suboptimal, highlighting the need for further domain-specific training. Additionally, we investigate SAM 3's 3D reconstruction abilities, demonstrating its capacity to process surgical scene data and reconstruct 3D anatomical structures from 2D images. Through comprehensive testing on the MICCAI EndoVis 2017 and EndoVis 2018 benchmarks, SAM 3 shows clear improvements over SAM and SAM 2 in both image and video segmentation under spatial prompts, while zero-shot evaluations on SCARED, StereoMIS, and EndoNeRF indicate strong monocular depth estimation and realistic 3D instrument reconstruction, yet also reveal remaining limitations in complex, highly dynamic surgical scenes.

</details>


### [139] [Online Segment Any 3D Thing as Instance Tracking](https://arxiv.org/abs/2512.07599)
*Hanshi Wang,Zijian Cai,Jin Gao,Yiwei Zhang,Weiming Hu,Ke Wang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: AutoSeg3D将在线3D分割重构为实例跟踪问题，通过对象查询进行时空信息传播，在多个数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的3D分割方法主要关注空间信息传播，忽视了感知的动态性和时间维度理解的重要性。在具身智能体环境中，视角变化导致物体部分可见，需要时间信息来建立完整的物体理解。

Method: 1. 将在线3D分割重构为实例跟踪问题；2. 使用对象查询进行时间信息传播：长期实例关联保持特征和身份一致性，短期实例更新丰富即时观测；3. 引入空间一致性学习缓解VFMs的碎片化问题；4. 通过稀疏对象查询实现时间信息交换，避免密集点云交互的计算负担。

Result: 在ScanNet200上超越ESAM 2.8 AP，在ScanNet、SceneNN和3RScan数据集上均取得一致性能提升，建立了新的SOTA。

Conclusion: 通过将3D分割重构为实例跟踪问题，利用对象查询进行时间信息传播和空间一致性学习，显著提升了具身智能体的时空环境感知能力，同时保持了计算效率。

Abstract: Online, real-time, and fine-grained 3D segmentation constitutes a fundamental capability for embodied intelligent agents to perceive and comprehend their operational environments. Recent advancements employ predefined object queries to aggregate semantic information from Vision Foundation Models (VFMs) outputs that are lifted into 3D point clouds, facilitating spatial information propagation through inter-query interactions. Nevertheless, perception is an inherently dynamic process, rendering temporal understanding a critical yet overlooked dimension within these prevailing query-based pipelines. Therefore, to further unlock the temporal environmental perception capabilities of embodied agents, our work reconceptualizes online 3D segmentation as an instance tracking problem (AutoSeg3D). Our core strategy involves utilizing object queries for temporal information propagation, where long-term instance association promotes the coherence of features and object identities, while short-term instance update enriches instant observations. Given that viewpoint variations in embodied robotics often lead to partial object visibility across frames, this mechanism aids the model in developing a holistic object understanding beyond incomplete instantaneous views. Furthermore, we introduce spatial consistency learning to mitigate the fragmentation problem inherent in VFMs, yielding more comprehensive instance information for enhancing the efficacy of both long-term and short-term temporal learning. The temporal information exchange and consistency learning facilitated by these sparse object queries not only enhance spatial comprehension but also circumvent the computational burden associated with dense temporal point cloud interactions. Our method establishes a new state-of-the-art, surpassing ESAM by 2.8 AP on ScanNet200 and delivering consistent gains on ScanNet, SceneNN, and 3RScan datasets.

</details>


### [140] [Decomposition Sampling for Efficient Region Annotations in Active Learning](https://arxiv.org/abs/2512.07606)
*Jingna Qiu,Frauke Wilm,Mathias Öttl,Jonas Utz,Maja Schlereth,Moritz Schillinger,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

TL;DR: DECOMP是一种新的主动学习采样策略，针对密集预测任务，通过分解图像为类别特定组件并采样每个类别的区域，提高标注多样性和少数类性能。


<details>
  <summary>Details</summary>
Motivation: 在医学影像等密集预测任务中，标注成本高且耗时。现有方法存在计算内存成本高、区域选择不相关、过度依赖不确定性采样等问题，需要更高效的主动学习策略。

Method: DECOMP使用伪标签将图像分解为类别特定组件，从每个类别中采样区域，并结合类别预测置信度指导采样过程，确保困难类别获得更多标注。

Result: 在ROI分类、2D分割和3D分割任务中，DECOMP始终优于基线方法，能更好地采样少数类区域并提升这些困难类别的性能。

Conclusion: DECOMP通过分解采样策略有效解决了密集预测任务中的主动学习挑战，提高了标注效率和模型性能，特别是在处理少数类别方面表现优异。

Abstract: Active learning improves annotation efficiency by selecting the most informative samples for annotation and model training. While most prior work has focused on selecting informative images for classification tasks, we investigate the more challenging setting of dense prediction, where annotations are more costly and time-intensive, especially in medical imaging. Region-level annotation has been shown to be more efficient than image-level annotation for these tasks. However, existing methods for representative annotation region selection suffer from high computational and memory costs, irrelevant region choices, and heavy reliance on uncertainty sampling. We propose decomposition sampling (DECOMP), a new active learning sampling strategy that addresses these limitations. It enhances annotation diversity by decomposing images into class-specific components using pseudo-labels and sampling regions from each class. Class-wise predictive confidence further guides the sampling process, ensuring that difficult classes receive additional annotations. Across ROI classification, 2-D segmentation, and 3-D segmentation, DECOMP consistently surpasses baseline methods by better sampling minority-class regions and boosting performance on these challenging classes. Code is in https://github.com/JingnaQiu/DECOMP.git.

</details>


### [141] [MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation](https://arxiv.org/abs/2512.07628)
*Zhiqi Li,Wenhuan Li,Tengfei Wang,Zhenwei Wang,Junta Wu,Haoyuan Wang,Yunhan Yang,Zehuan Huang,Yang Li,Peidong Liu,Chunchao Guo*

Main category: cs.CV

TL;DR: MoCA是一种可扩展的组合式3D生成模型，通过重要性组件路由和未选组件压缩技术解决现有方法因全局注意力二次复杂度导致的扩展性问题


<details>
  <summary>Details</summary>
Motivation: 现有的部分感知3D生成方法在增加组件数量时，由于全局注意力的二次复杂度导致扩展性差，限制了组合式3D对象和场景生成的发展

Method: 提出MoCA模型，包含两个关键设计：(1) 基于重要性的组件路由，选择top-k相关组件进行稀疏全局注意力计算；(2) 不重要组件压缩，在保留未选组件上下文先验的同时降低全局注意力的计算复杂度

Result: 大量实验表明，MoCA在组合式对象和场景生成任务上均优于基线方法，实现了高效、细粒度的组合式3D资产创建

Conclusion: MoCA通过创新的稀疏注意力机制解决了组合式3D生成中的扩展性问题，为可扩展的组合式3D生成提供了有效解决方案

Abstract: Compositionality is critical for 3D object and scene generation, but existing part-aware 3D generation methods suffer from poor scalability due to quadratic global attention costs when increasing the number of components. In this work, we present MoCA, a compositional 3D generative model with two key designs: (1) importance-based component routing that selects top-k relevant components for sparse global attention, and (2) unimportant components compression that preserve contextual priors of unselected components while reducing computational complexity of global attention. With these designs, MoCA enables efficient, fine-grained compositional 3D asset creation with scalable number of components. Extensive experiments show MoCA outperforms baselines on both compositional object and scene generation tasks. Project page: https://lizhiqi49.github.io/MoCA

</details>


### [142] [Liver Fibrosis Quantification and Analysis: The LiQA Dataset and Baseline Method](https://arxiv.org/abs/2512.07651)
*Yuanye Liu,Hanxiao Zhang,Nannan Shi,Yuxin Shi,Arif Mahmood,Murtaza Taj,Xiahai Zhuang*

Main category: cs.CV

TL;DR: LiQA数据集为肝脏纤维化分期提供多中心MRI基准，结合半监督学习和多视图共识方法提升模型鲁棒性


<details>
  <summary>Details</summary>
Motivation: 肝脏纤维化是全球重大健康负担，需要准确分期以进行有效临床管理。现有算法在复杂真实世界条件下（如领域偏移、模态缺失、空间错位）的评估不足。

Method: 建立LiQA数据集（440名患者的多期相、多中心MRI扫描），用于肝脏分割和纤维化分期基准测试。采用半监督学习框架结合外部数据进行稳健分割，使用多视图共识方法配合CAM正则化进行分期。

Result: 评估表明，利用多源数据和解剖约束显著增强了模型在临床环境中的鲁棒性。该方法在CARE 2024挑战赛中表现最佳。

Conclusion: LiQA数据集为肝脏纤维化评估提供了重要的基准资源，集成多源数据和解剖约束的方法能够有效应对临床环境中的复杂挑战，提升模型在实际应用中的可靠性。

Abstract: Liver fibrosis represents a significant global health burden, necessitating accurate staging for effective clinical management. This report introduces the LiQA (Liver Fibrosis Quantification and Analysis) dataset, established as part of the CARE 2024 challenge. Comprising $440$ patients with multi-phase, multi-center MRI scans, the dataset is curated to benchmark algorithms for Liver Segmentation (LiSeg) and Liver Fibrosis Staging (LiFS) under complex real-world conditions, including domain shifts, missing modalities, and spatial misalignment. We further describe the challenge's top-performing methodology, which integrates a semi-supervised learning framework with external data for robust segmentation, and utilizes a multi-view consensus approach with Class Activation Map (CAM)-based regularization for staging. Evaluation of this baseline demonstrates that leveraging multi-source data and anatomical constraints significantly enhances model robustness in clinical settings.

</details>


### [143] [Optimization-Guided Diffusion for Interactive Scene Generation](https://arxiv.org/abs/2512.07661)
*Shiaho Li,Naisheng Ye,Tianyu Li,Kashyap Chitta,Tuo An,Peng Su,Boyang Wang,Haiou Liu,Chen Lv,Hongyang Li*

Main category: cs.CV

TL;DR: OMEGA：基于优化的训练免费框架，通过约束优化引导扩散采样，生成物理合理且行为一致的交通场景，特别针对安全关键事件生成


<details>
  <summary>Details</summary>
Motivation: 自动驾驶评估需要真实多样的多智能体驾驶场景，但安全关键事件在现有数据集中罕见且代表性不足。现有数据驱动场景生成方法缺乏可控性或产生违反物理/社会约束的样本，限制了实用性。

Method: 提出OMEGA框架，在基于扩散的场景生成模型采样过程中，通过约束优化重新锚定每个反向扩散步骤，引导生成物理合理且行为一致的轨迹。将自车-攻击者交互建模为分布空间的博弈论优化，近似纳什均衡以生成真实的安全关键对抗场景。

Result: 在nuPlan和Waymo数据集上，OMEGA将物理和行为有效场景比例从32.35%提升至72.27%（自由探索能力），从11%提升至80%（可控性生成）。能生成5倍多的碰撞前3秒内时间帧，同时保持整体场景真实性。

Conclusion: OMEGA通过优化引导的扩散采样框架，显著提高了场景生成的物理合理性、行为一致性和可控性，为自动驾驶系统评估提供了更真实的安全关键场景生成能力。

Abstract: Realistic and diverse multi-agent driving scenes are crucial for evaluating autonomous vehicles, but safety-critical events which are essential for this task are rare and underrepresented in driving datasets. Data-driven scene generation offers a low-cost alternative by synthesizing complex traffic behaviors from existing driving logs. However, existing models often lack controllability or yield samples that violate physical or social constraints, limiting their usability. We present OMEGA, an optimization-guided, training-free framework that enforces structural consistency and interaction awareness during diffusion-based sampling from a scene generation model. OMEGA re-anchors each reverse diffusion step via constrained optimization, steering the generation towards physically plausible and behaviorally coherent trajectories. Building on this framework, we formulate ego-attacker interactions as a game-theoretic optimization in the distribution space, approximating Nash equilibria to generate realistic, safety-critical adversarial scenarios. Experiments on nuPlan and Waymo show that OMEGA improves generation realism, consistency, and controllability, increasing the ratio of physically and behaviorally valid scenes from 32.35% to 72.27% for free exploration capabilities, and from 11% to 80% for controllability-focused generation. Our approach can also generate $5\times$ more near-collision frames with a time-to-collision under three seconds while maintaining the overall scene realism.

</details>


### [144] [EgoCampus: Egocentric Pedestrian Eye Gaze Model and Dataset](https://arxiv.org/abs/2512.07668)
*Ronan John,Aditya Kesari,Vincenzo DiMatteo,Kristin Dana*

Main category: cs.CV

TL;DR: 提出了EgoCampus数据集和EgoCampusNet模型，用于预测户外校园环境中行人导航时的视觉注意力


<details>
  <summary>Details</summary>
Motivation: 解决在真实世界导航中预测人类视觉注意力的挑战，现有数据集多关注室内任务或缺乏眼动数据

Method: 使用Meta的Project Aria眼镜收集数据，包含眼动追踪、RGB摄像头、惯性传感器和GPS，开发EgoCampusNet模型预测行人导航时的眼动注视

Result: 创建了EgoCampus数据集，包含25条独特户外路径、6公里范围、80多名行人的眼动标注视频，为研究真实世界注意力提供了新资源

Conclusion: 该工作为研究真实世界注意力提供了新数据集和模型，有助于未来导航中眼动预测模型的发展

Abstract: We address the challenge of predicting human visual attention during real-world navigation by measuring and modeling egocentric pedestrian eye gaze in an outdoor campus setting. We introduce the EgoCampus dataset, which spans 25 unique outdoor paths over 6 km across a university campus with recordings from more than 80 distinct human pedestrians, resulting in a diverse set of gaze-annotated videos. The system used for collection, Meta's Project Aria glasses, integrates eye tracking, front-facing RGB cameras, inertial sensors, and GPS to provide rich data from the human perspective. Unlike many prior egocentric datasets that focus on indoor tasks or exclude eye gaze information, our work emphasizes visual attention while subjects walk in outdoor campus paths. Using this data, we develop EgoCampusNet, a novel method to predict eye gaze of navigating pedestrians as they move through outdoor environments. Our contributions provide both a new resource for studying real-world attention and a resource for future work in gaze prediction models for navigation. Dataset and code are available upon request, and will be made publicly available at a later date at https://github.com/ComputerVisionRutgers/EgoCampus .

</details>


### [145] [sim2art: Accurate Articulated Object Modeling from a Single Video using Synthetic Training Data Only](https://arxiv.org/abs/2512.07698)
*Arslan Artykov,Corentin Sautier,Vincent Lepetit*

Main category: cs.CV

TL;DR: 首个从单目视频中联合预测部件分割和关节参数的数据驱动方法，使用自由移动摄像头，仅用合成数据训练，在真实物体上表现良好


<details>
  <summary>Details</summary>
Motivation: 理解铰接物体是机器人和数字孪生创建的基础挑战，需要恢复部件分割和关节参数。先前工作主要关注多视角系统、物体扫描或静态摄像头，缺乏从自由移动单目视频中理解铰接物体的方法。

Method: 提出首个数据驱动方法，从自由移动摄像头拍摄的单目视频中联合预测部件分割和关节参数。仅使用合成数据进行训练，能够直接处理随意录制的视频。

Result: 方法在真实世界物体上表现出强大的泛化能力，为铰接物体理解提供了可扩展且实用的解决方案，适用于动态环境中的实时应用。

Conclusion: 该方法首次实现了从单目视频中联合预测铰接物体的部件分割和关节参数，仅需合成数据训练，在真实场景中表现良好，为铰接物体理解提供了实用且可扩展的解决方案。

Abstract: Understanding articulated objects is a fundamental challenge in robotics and digital twin creation. To effectively model such objects, it is essential to recover both part segmentation and the underlying joint parameters. Despite the importance of this task, previous work has largely focused on setups like multi-view systems, object scanning, or static cameras. In this paper, we present the first data-driven approach that jointly predicts part segmentation and joint parameters from monocular video captured with a freely moving camera. Trained solely on synthetic data, our method demonstrates strong generalization to real-world objects, offering a scalable and practical solution for articulated object understanding. Our approach operates directly on casually recorded video, making it suitable for real-time applications in dynamic environments. Project webpage: https://aartykov.github.io/sim2art/

</details>


### [146] [UnCageNet: Tracking and Pose Estimation of Caged Animal](https://arxiv.org/abs/2512.07712)
*Sayak Dutta,Harish Katti,Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出三阶段预处理流水线解决动物追踪和姿态估计在笼子结构遮挡下的性能下降问题


<details>
  <summary>Details</summary>
Motivation: 现有动物追踪和姿态估计系统（如STEP和ViTPose）在处理带有笼子结构和系统性遮挡的图像视频时性能显著下降

Method: 三阶段预处理流水线：1) 使用Gabor增强的ResNet-UNet架构进行笼子分割；2) 使用CRFill进行内容感知的笼子修复；3) 在修复后的帧上进行姿态估计和追踪评估

Result: 实验验证表明，通过该流水线去除笼子遮挡后，姿态估计和追踪性能可达到与无遮挡环境相当的水平，关键点检测精度和轨迹一致性显著提升

Conclusion: 提出的三阶段预处理流水线有效解决了笼子结构遮挡对动物追踪和姿态估计系统的影响，显著提升了系统在复杂遮挡环境下的性能

Abstract: Animal tracking and pose estimation systems, such as STEP (Simultaneous Tracking and Pose Estimation) and ViTPose, experience substantial performance drops when processing images and videos with cage structures and systematic occlusions. We present a three-stage preprocessing pipeline that addresses this limitation through: (1) cage segmentation using a Gabor-enhanced ResNet-UNet architecture with tunable orientation filters, (2) cage inpainting using CRFill for content-aware reconstruction of occluded regions, and (3) evaluation of pose estimation and tracking on the uncaged frames. Our Gabor-enhanced segmentation model leverages orientation-aware features with 72 directional kernels to accurately identify and segment cage structures that severely impair the performance of existing methods. Experimental validation demonstrates that removing cage occlusions through our pipeline enables pose estimation and tracking performance comparable to that in environments without occlusions. We also observe significant improvements in keypoint detection accuracy and trajectory consistency.

</details>


### [147] [ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation](https://arxiv.org/abs/2512.07720)
*Fan Yang,Heyuan Li,Peihao Li,Weihao Yuan,Lingteng Qiu,Chaoyue Song,Cheng Chen,Yisheng He,Shifeng Zhang,Xiaoguang Han,Steven Hoi,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出一种结合3D重建模型和视频扩散模型的新方法，从单张输入图像生成高质量的上半身3D虚拟形象，解决现有方法在纹理模糊、运动僵硬和结构不稳定等问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D虚拟形象生成方法存在两个主要问题：基于大型重建模型的方法虽然快速且能产生稳定身体结构，但经常出现模糊纹理和僵硬不自然的运动；而生成式视频模型虽然能合成逼真动态结果，但存在身体结构错误和身份漂移等不稳定行为。需要结合两者的优势来解决这些局限性。

Method: 提出一个新颖框架，使用3D重建模型提供稳健的结构和外观先验，然后引导一个实时自回归视频扩散模型进行渲染。这种方法结合了几何稳定性和生成能力，能够合成高频、逼真的细节和流畅动态。

Result: 实验表明，该方法显著减少了伪影，在视觉质量上相比领先方法有实质性改进。能够有效减少纹理模糊和运动僵硬，同时防止视频生成方法中常见的结构不一致问题。

Conclusion: 通过将3D重建的几何稳定性与视频模型的生成能力相结合，该方法能够生成具有逼真外观和动态、时间一致运动的高保真数字虚拟形象，为游戏和虚拟现实等实时应用提供了稳健高效的解决方案。

Abstract: Generating high-fidelity upper-body 3D avatars from one-shot input image remains a significant challenge. Current 3D avatar generation methods, which rely on large reconstruction models, are fast and capable of producing stable body structures, but they often suffer from artifacts such as blurry textures and stiff, unnatural motion. In contrast, generative video models show promising performance by synthesizing photorealistic and dynamic results, but they frequently struggle with unstable behavior, including body structural errors and identity drift. To address these limitations, we propose a novel approach that combines the strengths of both paradigms. Our framework employs a 3D reconstruction model to provide robust structural and appearance priors, which in turn guides a real-time autoregressive video diffusion model for rendering. This process enables the model to synthesize high-frequency, photorealistic details and fluid dynamics in real time, effectively reducing texture blur and motion stiffness while preventing the structural inconsistencies common in video generation methods. By uniting the geometric stability of 3D reconstruction with the generative capabilities of video models, our method produces high-fidelity digital avatars with realistic appearance and dynamic, temporally coherent motion. Experiments demonstrate that our approach significantly reduces artifacts and achieves substantial improvements in visual quality over leading methods, providing a robust and efficient solution for real-time applications such as gaming and virtual reality. Project page: https://lhyfst.github.io/visa

</details>


### [148] [SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery](https://arxiv.org/abs/2512.07733)
*Meng Cao,Xingyu Li,Xue Liu,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: SpatialDreamer是一个基于强化学习的框架，通过主动探索、视觉想象和证据推理的闭环过程，提升多模态大语言模型在复杂空间推理任务中的表现，特别是需要心理模拟的任务。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在需要心理模拟的复杂空间推理任务上表现有限，现有方法主要依赖被动观察空间数据，缺乏主动的心理意象过程。需要开发能够进行主动空间心理模拟的方法。

Method: 提出SpatialDreamer强化学习框架，包含主动探索、通过世界模型进行视觉想象、以及基于证据的推理的闭环过程。为解决长序列推理任务中细粒度奖励监督不足的问题，提出了几何策略优化（GeoPO），引入树结构采样和具有几何一致性约束的步骤级奖励估计。

Result: 在多个具有挑战性的基准测试中，SpatialDreamer取得了极具竞争力的结果，标志着在多模态大语言模型实现类人主动空间心理模拟方面的重要进展。

Conclusion: SpatialDreamer通过强化学习和主动心理模拟机制，显著提升了多模态大语言模型在复杂空间推理任务中的能力，为解决需要心理意象的空间推理问题提供了有效方案。

Abstract: Despite advancements in Multi-modal Large Language Models (MLLMs) for scene understanding, their performance on complex spatial reasoning tasks requiring mental simulation remains significantly limited. Current methods often rely on passive observation of spatial data, failing to internalize an active mental imagery process. To bridge this gap, we propose SpatialDreamer, a reinforcement learning framework that enables spatial reasoning through a closedloop process of active exploration, visual imagination via a world model, and evidence-grounded reasoning. To address the lack of fine-grained reward supervision in longhorizontal reasoning tasks, we propose Geometric Policy Optimization (GeoPO), which introduces tree-structured sampling and step-level reward estimation with geometric consistency constraints. Extensive experiments demonstrate that SpatialDreamer delivers highly competitive results across multiple challenging benchmarks, signifying a critical advancement in human-like active spatial mental simulation for MLLMs.

</details>


### [149] [HLTCOE Evaluation Team at TREC 2025: VQA Track](https://arxiv.org/abs/2512.07738)
*Dengjia Zhang,Charles Weng,Katherine Guerrerio,Yi Lu,Kenton Murray,Alexander Martin,Reno Kriz,Benjamin Van Durme*

Main category: cs.CV

TL;DR: HLTCOE团队在TREC VQA的答案生成任务中提出了一个列表学习框架，通过候选答案重排序提高语义精度和排序一致性。


<details>
  <summary>Details</summary>
Motivation: 改进视频问答中的答案生成质量，特别是提高语义精度和排序一致性，解决时序推理和语义消歧等复杂问题。

Method: 采用两阶段方法：1) 基础多模态模型生成多个候选答案；2) 使用新颖的Masked Pointer Cross-Entropy Loss with Rank Weights训练的重排序模型对候选答案进行重排序。

Result: 实验显示在准确性和排序稳定性方面获得一致提升，特别是在需要时序推理和语义消歧的问题上表现更佳。

Conclusion: 通过将生成式建模与判别式排序相结合的方法，能够产生连贯、细粒度的答案列表，有效提升视频问答系统的性能。

Abstract: The HLTCOE Evaluation team participated in TREC VQA's Answer Generation (AG) task, for which we developed a listwise learning framework that aims to improve semantic precision and ranking consistency in answer generation. Given a video-question pair, a base multimodal model first generates multiple candidate answers, which are then reranked using a model trained with a novel Masked Pointer Cross-Entropy Loss with Rank Weights. This objective integrates pointer-based candidate selection, rank-dependent weighting, and masked cross-entropy under vocabulary restriction, enabling stable and interpretable listwise optimization. By bridging generative modeling with discriminative ranking, our method produces coherent, fine-grained answer lists. Experiments reveal consistent gains in accuracy and ranking stability, especially for questions requiring temporal reasoning and semantic disambiguation.

</details>


### [150] [Unison: A Fully Automatic, Task-Universal, and Low-Cost Framework for Unified Understanding and Generation](https://arxiv.org/abs/2512.07747)
*Shihao Zhao,Yitong Chen,Zeyinzi Jiang,Bojia Zi,Shaozhe Hao,Yu Liu,Chaojie Mao,Kwan-Yee K. Wong*

Main category: cs.CV

TL;DR: Unison是一个低成本的多模态统一理解与生成模型，采用两阶段方案，仅需50万训练样本和50GPU小时，能自动识别任务类型和提取元信息，覆盖多种理解与生成任务。


<details>
  <summary>Details</summary>
Motivation: 当前多模态统一理解与生成存在两种方法：自回归训练需要大量计算资源，两阶段方案虽然成本较低但任务覆盖有限且生成质量不佳。两种方法都缺乏自动解析输入元信息的能力，需要手动配置参数。

Method: 采用两阶段方案，在保持预训练模型能力的同时，通过低成本训练覆盖多种多模态任务。模型具备自动解析用户意图、确定任务类型、提取所需元信息的能力，实现全自动化处理。

Result: 实验表明，仅使用50万训练样本和50GPU小时的低成本设置下，模型能准确自动识别任务和提取相关参数，在多种理解和生成任务上取得优异性能。

Conclusion: Unison通过创新的两阶段方案，以极低训练成本实现了多模态统一理解与生成，并具备自动任务识别和参数提取能力，为普通研究者提供了可行的解决方案。

Abstract: Unified understanding and generation is a highly appealing research direction in multimodal learning. There exist two approaches: one trains a transformer via an auto-regressive paradigm, and the other adopts a two-stage scheme connecting pre-trained understanding and generative models for alignment fine-tuning. The former demands massive data and computing resources unaffordable for ordinary researchers. Though the latter requires a lower training cost, existing works often suffer from limited task coverage or poor generation quality. Both approaches lack the ability to parse input meta-information (such as task type, image resolution, video duration, etc.) and require manual parameter configuration that is tedious and non-intelligent. In this paper, we propose Unison which adopts the two-stage scheme while preserving the capabilities of the pre-trained models well. With an extremely low training cost, we cover a variety of multimodal understanding tasks, including text, image, and video understanding, as well as diverse generation tasks, such as text-to-visual content generation, editing, controllable generation, and IP-based reference generation. We also equip our model with the ability to automatically parse user intentions, determine the target task type, and accurately extract the meta-information required for the corresponding task. This enables full automation of various multimodal tasks without human intervention. Experiments demonstrate that, under a low-cost setting of only 500k training samples and 50 GPU hours, our model can accurately and automatically identify tasks and extract relevant parameters, and achieve superior performance across a variety of understanding and generation tasks.

</details>


### [151] [UltrasODM: A Dual Stream Optical Flow Mamba Network for 3D Freehand Ultrasound Reconstruction](https://arxiv.org/abs/2512.07756)
*Mayank Anand,Ujair Alam,Surya Prakash,Priya Shukla,Gora Chand Nandi,Domenec Puig*

Main category: cs.CV

TL;DR: UltrasODM是一个双流框架，通过每帧不确定性校准、显著性诊断和可操作提示来辅助超声操作者，减少重建误差，提高临床可信度。


<details>
  <summary>Details</summary>
Motivation: 临床超声采集高度依赖操作者，快速探头运动和亮度波动常导致重建误差，降低临床可信度和实用性，需要提高重建可靠性和临床工作流程安全性。

Method: UltrasODM集成三个核心模块：(1)对比排序模块按运动相似性分组帧；(2)光流流与Dual-Mamba时间模块融合用于鲁棒的6自由度位姿估计；(3)人机交互层结合贝叶斯不确定性、临床校准阈值和显著性图。当不确定性超过阈值时，系统发出非侵入性警报建议纠正措施。

Result: 在临床自由手超声数据集上评估，相比UltrasOM，UltrasODM将漂移减少15.2%，距离误差减少12.1%，Hausdorff距离减少10.1%，同时生成每帧不确定性和显著性输出。

Conclusion: 通过强调透明度和临床医生反馈，UltrasODM提高了重建可靠性，支持更安全、更可信的临床工作流程，代码已公开。

Abstract: Clinical ultrasound acquisition is highly operator-dependent, where rapid probe motion and brightness fluctuations often lead to reconstruction errors that reduce trust and clinical utility. We present UltrasODM, a dual-stream framework that assists sonographers during acquisition through calibrated per-frame uncertainty, saliency-based diagnostics, and actionable prompts. UltrasODM integrates (i) a contrastive ranking module that groups frames by motion similarity, (ii) an optical-flow stream fused with Dual-Mamba temporal modules for robust 6-DoF pose estimation, and (iii) a Human-in-the-Loop (HITL) layer combining Bayesian uncertainty, clinician-calibrated thresholds, and saliency maps highlighting regions of low confidence. When uncertainty exceeds the threshold, the system issues unobtrusive alerts suggesting corrective actions such as re-scanning highlighted regions or slowing the sweep. Evaluated on a clinical freehand ultrasound dataset, UltrasODM reduces drift by 15.2%, distance error by 12.1%, and Hausdorff distance by 10.1% relative to UltrasOM, while producing per-frame uncertainty and saliency outputs. By emphasizing transparency and clinician feedback, UltrasODM improves reconstruction reliability and supports safer, more trustworthy clinical workflows. Our code is publicly available at https://github.com/AnandMayank/UltrasODM.

</details>


### [152] [Modality-Aware Bias Mitigation and Invariance Learning for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2512.07760)
*Menglin Wang,Xiaojin Gong,Jiachen Li,Genlin Ji*

Main category: cs.CV

TL;DR: 本文提出了一种无监督可见光-红外行人重识别方法，通过模态感知Jaccard距离缓解模态差异带来的距离偏差，并采用"分割-对比"策略学习模态不变表示，在基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 无监督可见光-红外行人重识别面临跨模态关联不可靠的挑战。现有方法通常使用最优传输关联模态内聚类，容易传播局部聚类错误，且忽视了全局实例级关系。本文通过挖掘和关注可见光-红外模态偏差，从两个方面解决跨模态学习问题。

Method: 1. 提出模态感知Jaccard距离来缓解由模态差异引起的距离偏差，从而通过全局聚类估计更可靠的跨模态关联；2. 设计"分割-对比"策略获取模态特定的全局原型，在全局关联指导下显式对齐这些原型，实现模态不变且身份可区分的表示学习。

Result: 该方法在基准可见光-红外行人重识别数据集上取得了最先进的性能，显著优于现有方法，验证了其有效性。

Conclusion: 通过模态感知距离校正和模态不变表示学习，本文提出的方法能够有效解决无监督可见光-红外行人重识别中的跨模态关联挑战，在概念简单的同时实现了优异的性能。

Abstract: Unsupervised visible-infrared person re-identification (USVI-ReID) aims to match individuals across visible and infrared cameras without relying on any annotation. Given the significant gap across visible and infrared modality, estimating reliable cross-modality association becomes a major challenge in USVI-ReID. Existing methods usually adopt optimal transport to associate the intra-modality clusters, which is prone to propagating the local cluster errors, and also overlooks global instance-level relations. By mining and attending to the visible-infrared modality bias, this paper focuses on addressing cross-modality learning from two aspects: bias-mitigated global association and modality-invariant representation learning. Motivated by the camera-aware distance rectification in single-modality re-ID, we propose modality-aware Jaccard distance to mitigate the distance bias caused by modality discrepancy, so that more reliable cross-modality associations can be estimated through global clustering. To further improve cross-modality representation learning, a `split-and-contrast' strategy is designed to obtain modality-specific global prototypes. By explicitly aligning these prototypes under global association guidance, modality-invariant yet ID-discriminative representation learning can be achieved. While conceptually simple, our method obtains state-of-the-art performance on benchmark VI-ReID datasets and outperforms existing methods by a significant margin, validating its effectiveness.

</details>


### [153] [Distribution Matching Variational AutoEncoder](https://arxiv.org/abs/2512.07778)
*Sen Ye,Jianning Pei,Mengde Xu,Shuyang Gu,Chunyu Wang,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: DMVAE通过显式匹配编码器潜在分布与任意参考分布，系统研究哪种潜在分布更适合生成建模，发现自监督学习特征分布能平衡重建保真度和建模效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成模型（如VAE和基础模型对齐编码器）隐式约束潜在空间而不显式塑造其分布，不清楚哪种分布最适合建模。

Method: 提出Distribution-Matching VAE (DMVAE)，通过分布匹配约束显式对齐编码器潜在分布与任意参考分布，超越传统VAE的高斯先验。

Result: 发现自监督学习特征分布在重建保真度和建模效率之间提供最佳平衡，在ImageNet上仅用64个训练周期达到gFID=3.2。

Conclusion: 选择合适的潜在分布结构（通过分布级对齐实现）而非依赖固定先验，是弥合易建模潜在空间与高保真图像合成之间差距的关键。

Abstract: Most visual generative models compress images into a latent space before applying diffusion or autoregressive modelling. Yet, existing approaches such as VAEs and foundation model aligned encoders implicitly constrain the latent space without explicitly shaping its distribution, making it unclear which types of distributions are optimal for modeling. We introduce \textbf{Distribution-Matching VAE} (\textbf{DMVAE}), which explicitly aligns the encoder's latent distribution with an arbitrary reference distribution via a distribution matching constraint. This generalizes beyond the Gaussian prior of conventional VAEs, enabling alignment with distributions derived from self-supervised features, diffusion noise, or other prior distributions. With DMVAE, we can systematically investigate which latent distributions are more conducive to modeling, and we find that SSL-derived distributions provide an excellent balance between reconstruction fidelity and modeling efficiency, reaching gFID equals 3.2 on ImageNet with only 64 training epochs. Our results suggest that choosing a suitable latent distribution structure (achieved via distribution-level alignment), rather than relying on fixed priors, is key to bridging the gap between easy-to-model latents and high-fidelity image synthesis. Code is avaliable at https://github.com/sen-ye/dmvae.

</details>


### [154] [OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory](https://arxiv.org/abs/2512.07802)
*Zhaochong An,Menglin Jia,Haonan Qiu,Zijian Zhou,Xiaoke Huang,Zhiheng Liu,Weiming Ren,Kumara Kahatapitiya,Ding Liu,Sen He,Chenyang Zhang,Tao Xiang,Fanny Yang,Serge Belongie,Tian Xie*

Main category: cs.CV

TL;DR: OneStory提出了一种新的多镜头视频生成方法，通过将多镜头视频生成重新定义为"下一个镜头生成"任务，使用全局记忆和自适应条件模块来建模跨镜头上下文，实现一致且可扩展的叙事生成。


<details>
  <summary>Details</summary>
Motivation: 现有多镜头视频生成方法在建模长距离跨镜头上下文方面存在困难，因为它们依赖有限的时间窗口或单关键帧条件，导致在复杂叙事下性能下降。需要一种能够有效建模全局跨镜头上下文的方法来生成一致且连贯的叙事视频。

Method: 1. 将多镜头视频生成重新定义为"下一个镜头生成"任务，实现自回归镜头合成；2. 引入帧选择模块，基于先前镜头中的信息丰富帧构建语义相关的全局记忆；3. 设计自适应条件模块，执行重要性引导的补丁化以生成紧凑的上下文进行直接条件化；4. 策划高质量的多镜头数据集并设计有效的训练策略。

Result: 在策划的60K数据集上对预训练的I2V模型进行微调后，OneStory在文本和图像条件设置下，在多样化和复杂场景中实现了最先进的叙事连贯性，能够生成可控且沉浸式的长格式视频叙事。

Conclusion: OneStory通过全局但紧凑的跨镜头上下文建模，解决了现有多镜头视频生成方法的局限性，实现了更一致、连贯且可扩展的叙事视频生成，为可控和沉浸式的长格式视频叙事提供了有效解决方案。

Abstract: Storytelling in real-world videos often unfolds through multiple shots -- discontinuous yet semantically connected clips that together convey a coherent narrative. However, existing multi-shot video generation (MSV) methods struggle to effectively model long-range cross-shot context, as they rely on limited temporal windows or single keyframe conditioning, leading to degraded performance under complex narratives. In this work, we propose OneStory, enabling global yet compact cross-shot context modeling for consistent and scalable narrative generation. OneStory reformulates MSV as a next-shot generation task, enabling autoregressive shot synthesis while leveraging pretrained image-to-video (I2V) models for strong visual conditioning. We introduce two key modules: a Frame Selection module that constructs a semantically-relevant global memory based on informative frames from prior shots, and an Adaptive Conditioner that performs importance-guided patchification to generate compact context for direct conditioning. We further curate a high-quality multi-shot dataset with referential captions to mirror real-world storytelling patterns, and design effective training strategies under the next-shot paradigm. Finetuned from a pretrained I2V model on our curated 60K dataset, OneStory achieves state-of-the-art narrative coherence across diverse and complex scenes in both text- and image-conditioned settings, enabling controllable and immersive long-form video storytelling.

</details>


### [155] [Multi-view Pyramid Transformer: Look Coarser to See Broader](https://arxiv.org/abs/2512.07806)
*Gyeongjin Kang,Seungkwon Yang,Seungtae Nam,Younggeun Lee,Jungwoo Kim,Eunbyung Park*

Main category: cs.CV

TL;DR: MVP是一种可扩展的多视角Transformer架构，能够从数十到数百张图像中单次前向传播重建大型3D场景，采用局部到全局的视角层次和精细到粗糙的空间层次设计。


<details>
  <summary>Details</summary>
Motivation: 为了解决从大量图像中高效重建大型复杂3D场景的挑战，需要一种既能处理大规模视角配置又能保持计算效率的架构。

Method: 提出Multi-view Pyramid Transformer (MVP)，基于两个核心设计原则：1) 局部到全局的视角间层次结构，从局部视角逐步扩展到组视角再到完整场景；2) 精细到粗糙的视角内层次结构，从详细空间表示逐步聚合为紧凑的信息密集token。

Result: 在多样化数据集上验证表明，当与3D高斯泼溅作为底层3D表示结合时，MVP实现了最先进的泛化重建质量，同时在广泛的视角配置范围内保持高效率和可扩展性。

Conclusion: MVP通过双层次结构设计实现了计算效率和表示丰富性的平衡，能够快速重建大型复杂场景，为大规模3D场景重建提供了有效的解决方案。

Abstract: We propose Multi-view Pyramid Transformer (MVP), a scalable multi-view transformer architecture that directly reconstructs large 3D scenes from tens to hundreds of images in a single forward pass. Drawing on the idea of ``looking broader to see the whole, looking finer to see the details," MVP is built on two core design principles: 1) a local-to-global inter-view hierarchy that gradually broadens the model's perspective from local views to groups and ultimately the full scene, and 2) a fine-to-coarse intra-view hierarchy that starts from detailed spatial representations and progressively aggregates them into compact, information-dense tokens. This dual hierarchy achieves both computational efficiency and representational richness, enabling fast reconstruction of large and complex scenes. We validate MVP on diverse datasets and show that, when coupled with 3D Gaussian Splatting as the underlying 3D representation, it achieves state-of-the-art generalizable reconstruction quality while maintaining high efficiency and scalability across a wide range of view configurations.

</details>


### [156] [Lang3D-XL: Language Embedded 3D Gaussians for Large-scale Scenes](https://arxiv.org/abs/2512.07807)
*Shai Krakovsky,Gal Fiebelman,Sagie Benaim,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 提出了一种在3D高斯表示中嵌入语言场的新方法，通过极低维语义瓶颈特征和多分辨率哈希编码器提高效率，并引入衰减下采样器和正则化解决语义特征对齐问题。


<details>
  <summary>Details</summary>
Motivation: 在3D表示中嵌入语言场可以实现空间环境的语义理解，支持自然语言查询和编辑场景，但现有特征蒸馏方法在处理大规模互联网数据时存在语义特征对齐问题和效率低下。

Method: 1) 在3D高斯表示中引入极低维语义瓶颈特征；2) 使用多分辨率特征哈希编码器处理这些特征；3) 提出衰减下采样器模块和多种正则化方法解决2D特征语义对齐问题。

Result: 在HolyScenes数据集上的评估表明，该方法在性能和效率方面都超越了现有方法。

Conclusion: 该方法有效解决了大规模场景中语言场嵌入的语义对齐和效率问题，为3D场景的语义理解和自然语言交互提供了更优解决方案。

Abstract: Embedding a language field in a 3D representation enables richer semantic understanding of spatial environments by linking geometry with descriptive meaning. This allows for a more intuitive human-computer interaction, enabling querying or editing scenes using natural language, and could potentially improve tasks like scene retrieval, navigation, and multimodal reasoning. While such capabilities could be transformative, in particular for large-scale scenes, we find that recent feature distillation approaches cannot effectively learn over massive Internet data due to challenges in semantic feature misalignment and inefficiency in memory and runtime. To this end, we propose a novel approach to address these challenges. First, we introduce extremely low-dimensional semantic bottleneck features as part of the underlying 3D Gaussian representation. These are processed by rendering and passing them through a multi-resolution, feature-based, hash encoder. This significantly improves efficiency both in runtime and GPU memory. Second, we introduce an Attenuated Downsampler module and propose several regularizations addressing the semantic misalignment of ground truth 2D features. We evaluate our method on the in-the-wild HolyScenes dataset and demonstrate that it surpasses existing approaches in both performance and efficiency.

</details>


### [157] [OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing](https://arxiv.org/abs/2512.07826)
*Haoyang He,Jie Wang,Jiangning Zhang,Zhucun Xue,Xingyuan Bu,Qiangpeng Yang,Shilei Wen,Lei Xie*

Main category: cs.CV

TL;DR: OpenVE-3M是一个开源的大规模高质量指令视频编辑数据集，包含空间对齐和非空间对齐两类编辑任务，通过精心设计的数据流水线生成，在规模、多样性、指令长度和质量上超越现有开源数据集。同时构建了OpenVE-Bench基准测试，并训练了OpenVE-Edit模型，在基准测试中超越了包括14B基线在内的所有先前开源模型。


<details>
  <summary>Details</summary>
Motivation: 指令式图像编辑数据集的质量和多样性不断提升，但大规模高质量的指令式视频编辑数据集仍然稀缺。为了填补这一空白，需要构建一个开源、大规模、高质量的指令视频编辑数据集。

Method: 1. 构建OpenVE-3M数据集：包含空间对齐编辑（全局风格、背景变化、局部变化、局部移除、局部添加、字幕编辑）和非空间对齐编辑（摄像机多镜头编辑和创意编辑）两类；2. 通过精心设计的数据流水线生成所有编辑类型，并进行严格的质量过滤；3. 构建OpenVE-Bench基准测试，包含431个视频-编辑对，涵盖多样编辑任务，使用三个与人类判断高度一致的关键指标；4. 在数据集上训练OpenVE-Edit模型（5B参数）。

Result: 1. OpenVE-3M在规模、编辑类型多样性、指令长度和整体质量上超越现有开源数据集；2. OpenVE-Edit模型在OpenVE-Bench基准测试中取得了新的最先进性能，超越了包括14B基线在内的所有先前开源模型，展示了卓越的效率和效果。

Conclusion: 该工作填补了指令式视频编辑领域大规模高质量数据集的空白，提供了OpenVE-3M数据集、OpenVE-Bench基准测试和OpenVE-Edit模型，为视频编辑研究建立了统一的评估框架，并展示了在相对较小参数规模下实现优越性能的可能性。

Abstract: The quality and diversity of instruction-based image editing datasets are continuously increasing, yet large-scale, high-quality datasets for instruction-based video editing remain scarce. To address this gap, we introduce OpenVE-3M, an open-source, large-scale, and high-quality dataset for instruction-based video editing. It comprises two primary categories: spatially-aligned edits (Global Style, Background Change, Local Change, Local Remove, Local Add, and Subtitles Edit) and non-spatially-aligned edits (Camera Multi-Shot Edit and Creative Edit). All edit types are generated via a meticulously designed data pipeline with rigorous quality filtering. OpenVE-3M surpasses existing open-source datasets in terms of scale, diversity of edit types, instruction length, and overall quality. Furthermore, to address the lack of a unified benchmark in the field, we construct OpenVE-Bench, containing 431 video-edit pairs that cover a diverse range of editing tasks with three key metrics highly aligned with human judgment. We present OpenVE-Edit, a 5B model trained on our dataset that demonstrates remarkable efficiency and effectiveness by setting a new state-of-the-art on OpenVE-Bench, outperforming all prior open-source models including a 14B baseline. Project page is at https://github.com/lewandofskee/OpenVE.

</details>


### [158] [UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation](https://arxiv.org/abs/2512.07831)
*Jiehui Huang,Yuechen Zhang,Xu He,Yuan Gao,Zhi Cen,Bin Xia,Yan Zhou,Xin Tao,Pengfei Wan,Jiaya Jia*

Main category: cs.CV

TL;DR: UnityVideo是一个统一的多模态视频生成框架，通过联合学习分割掩码、人体骨架、DensePose、光流和深度图等多种模态，实现世界感知的视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型受限于单模态条件约束，缺乏跨模态交互和模态多样性，限制了其对世界的全面理解能力。

Method: 提出两个核心组件：1) 动态噪声化统一异构训练范式；2) 模态切换器配合上下文学习器，通过模块化参数和上下文学习实现统一处理。构建了包含130万样本的大规模统一数据集。

Result: 通过联合优化，UnityVideo加速了收敛过程，显著提升了零样本泛化能力到未见数据。实验表明，UnityVideo在视频质量、一致性以及与物理世界约束的对齐方面表现优异。

Conclusion: UnityVideo通过统一的多模态学习框架，解决了现有视频生成模型的世界理解局限性，为世界感知的视频生成提供了有效的解决方案。

Abstract: Recent video generation models demonstrate impressive synthesis capabilities but remain limited by single-modality conditioning, constraining their holistic world understanding. This stems from insufficient cross-modal interaction and limited modal diversity for comprehensive world knowledge representation. To address these limitations, we introduce UnityVideo, a unified framework for world-aware video generation that jointly learns across multiple modalities (segmentation masks, human skeletons, DensePose, optical flow, and depth maps) and training paradigms. Our approach features two core components: (1) dynamic noising to unify heterogeneous training paradigms, and (2) a modality switcher with an in-context learner that enables unified processing via modular parameters and contextual learning. We contribute a large-scale unified dataset with 1.3M samples. Through joint optimization, UnityVideo accelerates convergence and significantly enhances zero-shot generalization to unseen data. We demonstrate that UnityVideo achieves superior video quality, consistency, and improved alignment with physical world constraints. Code and data can be found at: https://github.com/dvlab-research/UnityVideo

</details>


### [159] [Voxify3D: Pixel Art Meets Volumetric Rendering](https://arxiv.org/abs/2512.07834)
*Yi-Chuan Huang,Jiewen Chan,Hao-Jen Chien,Yu-Lun Liu*

Main category: cs.CV

TL;DR: Voxify3D是一个两阶段可微分框架，通过正交像素艺术监督、基于补丁的CLIP对齐和调色板约束的Gumbel-Softmax量化，实现从3D网格到体素艺术的自动生成，解决了几何抽象、语义保持和离散颜色一致性的冲突需求。


<details>
  <summary>Details</summary>
Motivation: 体素艺术在游戏和数字媒体中广泛应用，但从3D网格自动生成面临挑战：现有方法要么过度简化几何，要么无法实现像素级精确、调色板约束的体素艺术美学。需要解决几何抽象、语义保持和离散颜色一致性之间的冲突需求。

Method: 提出Voxify3D两阶段可微分框架：1) 正交像素艺术监督消除透视畸变，实现体素-像素精确对齐；2) 基于补丁的CLIP对齐在不同离散化级别保持语义；3) 调色板约束的Gumbel-Softmax量化，在离散颜色空间进行可微分优化，支持可控调色板策略。

Result: 实验显示优越性能：CLIP-IQA得分37.12，用户偏好率77.90%，在多样化角色上表现良好，支持可控抽象（2-8种颜色，20x-50x分辨率）。

Conclusion: Voxify3D通过协同整合三个核心组件，解决了极端离散化下的语义保持、通过体积渲染实现像素艺术美学，以及端到端离散优化的基本挑战，为3D网格到体素艺术的自动生成提供了有效解决方案。

Abstract: Voxel art is a distinctive stylization widely used in games and digital media, yet automated generation from 3D meshes remains challenging due to conflicting requirements of geometric abstraction, semantic preservation, and discrete color coherence. Existing methods either over-simplify geometry or fail to achieve the pixel-precise, palette-constrained aesthetics of voxel art. We introduce Voxify3D, a differentiable two-stage framework bridging 3D mesh optimization with 2D pixel art supervision. Our core innovation lies in the synergistic integration of three components: (1) orthographic pixel art supervision that eliminates perspective distortion for precise voxel-pixel alignment; (2) patch-based CLIP alignment that preserves semantics across discretization levels; (3) palette-constrained Gumbel-Softmax quantization enabling differentiable optimization over discrete color spaces with controllable palette strategies. This integration addresses fundamental challenges: semantic preservation under extreme discretization, pixel-art aesthetics through volumetric rendering, and end-to-end discrete optimization. Experiments show superior performance (37.12 CLIP-IQA, 77.90\% user preference) across diverse characters and controllable abstraction (2-8 colors, 20x-50x resolutions). Project page: https://yichuanh.github.io/Voxify-3D/

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [160] [Enhanced Multimodal Video Retrieval System: Integrating Query Expansion and Cross-modal Temporal Event Retrieval](https://arxiv.org/abs/2512.06334)
*Van-Thinh Vo,Minh-Khoi Nguyen,Minh-Huy Tran,Anh-Quan Nguyen-Tran,Duy-Tan Nguyen,Khanh-Loi Nguyen,Anh-Minh Phan*

Main category: cs.IR

TL;DR: 提出跨模态时序事件检索框架，支持不同查询模态描述序列中的不同场景，通过KDE-GMM算法自适应确定场景转换阈值，提取关键帧作为视觉范例，结合LLM优化查询，在AI挑战赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频多模态检索系统通常在整个序列中使用单一查询模态，在复杂时序上下文中的鲁棒性有限，需要更灵活的跨模态时序检索方法。

Method: 1. 提出跨模态时序事件检索框架，允许不同查询模态描述序列中的不同场景；2. 开发KDE-GMM算法自适应确定场景转换和幻灯片变化的决策阈值；3. 提取关键帧作为紧凑高质量的视觉范例；4. 结合LLM优化和扩展用户查询。

Result: 系统在胡志明市AI挑战赛2025中表现出色，证明了其有效性和鲁棒性，提高了检索精度和效率。

Conclusion: 提出的跨模态时序事件检索框架通过自适应阈值确定、关键帧提取和LLM查询优化，显著提升了视频多媒体信息检索的性能和灵活性。

Abstract: Multimedia information retrieval from videos remains a challenging problem. While recent systems have advanced multimodal search through semantic, object, and OCR queries - and can retrieve temporally consecutive scenes - they often rely on a single query modality for an entire sequence, limiting robustness in complex temporal contexts. To overcome this, we propose a cross-modal temporal event retrieval framework that enables different query modalities to describe distinct scenes within a sequence. To determine decision thresholds for scene transition and slide change adaptively, we build Kernel Density Gaussian Mixture Thresholding (KDE-GMM) algorithm, ensuring optimal keyframe selection. These extracted keyframes act as compact, high-quality visual exemplars that retain each segment's semantic essence, improving retrieval precision and efficiency. Additionally, the system incorporates a large language model (LLM) to refine and expand user queries, enhancing overall retrieval performance. The proposed system's effectiveness and robustness were demonstrated through its strong results in the Ho Chi Minh AI Challenge 2025.

</details>


### [161] [Enhancing Medical Cross-Modal Hashing Retrieval using Dropout-Voting Mixture-of-Experts Fusion](https://arxiv.org/abs/2512.06449)
*Jaewon Ahn,Woosung Jang,Beakcheol Jang*

Main category: cs.IR

TL;DR: 提出MCMFH模型，将dropout投票和混合专家对比融合模块集成到CLIP跨模态哈希检索结构中，实现医疗图像-文本跨模态检索的高精度和快速检索


<details>
  <summary>Details</summary>
Motivation: 医疗领域多模态数据丰富，跨模态检索对图像解释、诊断支持和医学教育日益重要。随着分布式医疗数据整合增加，需要在速度、内存效率和检索准确性方面优化检索系统性能，以应对医疗数据量激增的挑战。

Method: 提出MCMFH框架，将dropout投票和基于混合专家的对比融合模块集成到CLIP跨模态哈希检索结构中，并应用混合损失函数。该方法能在低内存环境下同时实现高精度和快速检索。

Result: 在放射学和非放射学医疗数据集上进行了实验验证，模型在低内存环境下实现了高精度和快速检索。

Conclusion: 提出的MCMFH模型通过创新的dropout投票和混合专家对比融合模块，有效解决了医疗跨模态检索中速度、内存效率和准确性之间的平衡问题，为医疗数据检索提供了高效解决方案。

Abstract: In recent years, cross-modal retrieval using images and text has become an active area of research, especially in the medical domain. The abundance of data in various modalities in this field has led to a growing importance of cross-modal retrieval for efficient image interpretation, data-driven diagnostic support, and medical education. In the context of the increasing integration of distributed medical data across healthcare facilities with the objective of enhancing interoperability, it is imperative to optimize the performance of retrieval systems in terms of the speed, memory efficiency, and accuracy of the retrieved data. This necessity arises in response to the substantial surge in data volume that characterizes contemporary medical practices. In this study, we propose a novel framework that incorporates dropout voting and mixture-of-experts (MoE) based contrastive fusion modules into a CLIP-based cross-modal hashing retrieval structure. We also propose the application of hybrid loss. So we now call our model MCMFH which is a medical cross-modal fusion hashing retrieval. Our method enables the simultaneous achievement of high accuracy and fast retrieval speed in low-memory environments. The model is demonstrated through experiments on radiological and non-radiological medical datasets.

</details>


### [162] [Foresight Prediction Enhanced Live-Streaming Recommendation](https://arxiv.org/abs/2512.06700)
*Jiangxia Cao,Ruochen Yang,Xiang Chen,Changxin Lao,Yueyang Liu,Yusheng Huang,Yuanhao Tian,Xiangyu Wu,Shuang Yang,Zhaojie Liu,Guorui Zhou*

Main category: cs.IR

TL;DR: 该论文提出了一种针对直播内容的推荐算法，通过语义量化直播片段、编码历史序列和建模语义演化趋势，实现对未来内容的预见性预测，从而提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 直播作为一种新兴媒体，其内容动态性和时间敏感性对推荐算法提出了更高要求。研究发现用户在直播高光时刻有更好的体验和更积极的行为，但由于推荐时无法获取未来内容，而用户参与度又取决于后续内容是否符合其兴趣，因此需要预测未来直播内容。

Method: 1. 对直播片段进行语义量化，获得语义ID（Sid）；2. 编码历史Sid序列以捕捉作者特征；3. 建模Sid演化趋势以实现对未来内容的预见性预测；4. 通过精炼的特征增强排序模型。

Result: 大量的离线和在线实验证明了该方法的有效性。

Conclusion: 通过语义量化、序列编码和演化趋势建模，实现了对直播未来内容的预见性预测，有效提升了直播推荐算法的性能。

Abstract: Live-streaming, as an emerging media enabling real-time interaction between authors and users, has attracted significant attention. Unlike the stable playback time of traditional TV live or the fixed content of short video, live-streaming, due to the dynamics of content and time, poses higher requirements for the recommendation algorithm of the platform - understanding the ever-changing content in real time and push it to users at the appropriate moment. Through analysis, we find that users have a better experience and express more positive behaviors during highlight moments of the live-streaming. Furthermore, since the model lacks access to future content during recommendation, yet user engagement depends on how well subsequent content aligns with their interests, an intuitive solution is to predict future live-streaming content. Therefore, we perform semantic quantization on live-streaming segments to obtain Semantic ids (Sid), encode the historical Sid sequence to capture the author's characteristics, and model Sid evolution trend to enable foresight prediction of future content. This foresight enhances the ranking model through refined features. Extensive offline and online experiments demonstrate the effectiveness of our method.

</details>


### [163] [WisPaper: Your AI Scholar Search Engine](https://arxiv.org/abs/2512.06879)
*Li Ju,Jun Zhao,Mingxu Chai,Ziyu Shen,Xiangyang Wang,Yage Geng,Chunchun Ma,Hao Peng,Guangbin Li,Tao Li,Chengyong Liao,Fu Wang,Xiaolong Wang,Junshen Chen,Rui Gong,Shijia Liang,Feiyan Li,Ming Zhang,Kexin Tan,Jujie Ye,Zhiheng Xi,Shihan Dou,Tao Gui,Yuankai Ying,Yang Shi,Yue Zhang,Qi Zhang*

Main category: cs.IR

TL;DR: WisPaper是一个智能学术检索与文献管理平台，通过学者搜索、文献库和AI推送三大功能，为研究人员提供从文献发现到管理的闭环工作流，显著减少文献筛选时间。


<details>
  <summary>Details</summary>
Motivation: 随着科学出版物呈指数级增长，研究人员难以高效定位和管理相关文献，现有学术工具无法提供从发现到管理的完整工作流程。

Method: WisPaper平台集成了三大核心功能：1) 学者搜索（支持快速关键词搜索和深度智能搜索）；2) 文献库（可定制的知识库用于系统化文献组织）；3) AI推送（基于用户兴趣自动推荐相关新文献的智能系统）。

Result: 该系统为多语言、多学科平台，显著减少了不同背景研究人员在文献筛选和管理上的时间，使他们能够专注于核心研究活动。平台已公开可用，服务于学术界和工业界的研究人员。

Conclusion: WisPaper提供了一个无缝连接文献发现、管理和研究前沿持续追踪的闭环工作流，解决了现有学术工具的局限性，有效提升了研究效率。

Abstract: Researchers struggle to efficiently locate and manage relevant literature within the exponentially growing body of scientific publications. We present \textsc{WisPaper}, an intelligent academic retrieval and literature management platform that addresses this challenge through three integrated capabilities: (1) \textit{Scholar Search}, featuring both quick keyword-based and deep agentic search modes for efficient paper discovery; (2) \textit{Library}, a customizable knowledge base for systematic literature organization; and (3) \textit{AI Feeds}, an intelligent recommendation system that automatically delivers relevant new publications based on user interests. Unlike existing academic tools, \textsc{WisPaper} provides a closed-loop workflow that seamlessly connects literature discovery, management, and continuous tracking of research frontiers. Our multilingual and multidisciplinary system significantly reduces the time researchers from diverse backgrounds spend on paper screening and management, enabling them to focus on their core research activities. The platform is publicly accessible and serves researchers across academia and industry.

</details>


### [164] [Structural and Disentangled Adaptation of Large Vision Language Models for Multimodal Recommendation](https://arxiv.org/abs/2512.06883)
*Zhongtao Rao,Peilin Zhou,Dading Chong,Zhiwei Chen,Shoujin Wang,Nan Tang*

Main category: cs.IR

TL;DR: SDA框架通过结构对齐和模态解耦适配，解决大视觉语言模型在推荐系统中的表示对齐和梯度冲突问题，显著提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 多模态推荐依赖高质量的跨模态表示学习，大视觉语言模型提供了统一的表示学习能力，但直接应用于推荐面临两个挑战：表示不对齐（领域差异导致嵌入空间不一致）和梯度冲突（共享适配器导致干扰和判别能力不足）

Method: 提出SDA框架，包含两个核心组件：跨模态结构对齐（CMSA）使用模态内结构作为软教师对齐嵌入；模态解耦适配（MoDA）通过专家化、门控低秩路径解耦梯度流，缓解梯度冲突

Result: 在三个Amazon数据集上实验，SDA与现有多模态和序列推荐器无缝集成，平均提升Hit@10 6.15%，NDCG@10 8.64%，在长尾物品上分别提升12.83%和18.70%，推理开销最小

Conclusion: SDA框架有效解决LVLMs在推荐中的表示对齐和梯度冲突问题，显著提升推荐性能，特别是在长尾物品上表现优异，为多模态推荐提供了轻量级适配方案

Abstract: Multimodal recommendation enhances accuracy by leveraging visual and textual signals, and its success largely depends on learning high-quality cross-modal representations. Recent advances in Large Vision-Language Models (LVLMs) offer unified multimodal representation learning, making them a promising backbone. However, applying LVLMs to recommendation remains challenging due to (i) representation misalignment, where domain gaps between item data and general pre-training lead to unaligned embedding spaces, and (ii) gradient conflicts during fine-tuning, where shared adapters cause interference and a lack of discriminative power. To address this, we propose SDA, a lightweight framework for Structural and Disentangled Adaptation, which integrates two components: Cross-Modal Structural Alignment (CMSA) and Modality-Disentangled Adaptation. CMSA aligns embeddings using intra-modal structures as a soft teacher, while MoDA mitigates gradient conflicts via expertized, gated low-rank paths to disentangle gradient flows. Experiments on three public Amazon datasets show SDA integrates seamlessly with existing multimodal and sequential recommenders, yielding average gains of 6.15% in Hit@10 and 8.64% in NDCG@10. It also achieves up to 12.83% and 18.70% gains on long-tail items with minimal inference overhead. Our code and full experimental results are available at https://github.com/RaoZhongtao/SDA.

</details>


### [165] [OnePiece: The Great Route to Generative Recommendation -- A Case Study from Tencent Algorithm Competition](https://arxiv.org/abs/2512.07424)
*Jiangxia Cao,Shuo Yang,Zijun Wang,Qinghai Tan*

Main category: cs.IR

TL;DR: 论文探讨生成式推荐系统是否存在类似语言模型的缩放定律，通过统一的编码器-解码器框架验证了ANN和自回归两种技术范式都严格遵循幂律缩放定律。


<details>
  <summary>Details</summary>
Motivation: 受OpenAI缩放定律启发，研究生成式推荐系统是否也存在类似的缩放定律。生成式推荐通常指检索阶段，但缺乏真实的下一个物品作为监督信号，因此需要验证其缩放潜力。

Method: 设计统一的编码器-解码器框架，同时验证两种生成式推荐技术范式：1) ANN-based框架（如Kuaiformer），使用压缩的用户嵌入在嵌入空间中检索最近邻物品；2) Auto-regressive-based框架（如OneRec），使用束搜索从整个空间解码物品。

Result: 实证发现两种范式的损失都严格遵循幂律缩放定律（R²>0.9），在统一架构下验证了生成式推荐系统存在缩放定律。

Conclusion: 生成式推荐系统确实存在缩放定律，类似于语言模型的缩放定律，这为通过扩展模型参数来提升推荐性能提供了理论依据。

Abstract: In past years, the OpenAI's Scaling-Laws shows the amazing intelligence with the next-token prediction paradigm in neural language modeling, which pointing out a free-lunch way to enhance the model performance by scaling the model parameters. In RecSys, the retrieval stage is also follows a 'next-token prediction' paradigm, to recall the hunderds of items from the global item set, thus the generative recommendation usually refers specifically to the retrieval stage (without Tree-based methods). This raises a philosophical question: without a ground-truth next item, does the generative recommendation also holds a potential scaling law? In retrospect, the generative recommendation has two different technique paradigms: (1) ANN-based framework, utilizing the compressed user embedding to retrieve nearest other items in embedding space, e.g, Kuaiformer. (2) Auto-regressive-based framework, employing the beam search to decode the item from whole space, e.g, OneRec. In this paper, we devise a unified encoder-decoder framework to validate their scaling-laws at same time. Our empirical finding is that both of their losses strictly adhere to power-law Scaling Laws ($R^2$>0.9) within our unified architecture.

</details>


### [166] [From Show Programmes to Data: Designing a Workflow to Make Performing Arts Ephemera Accessible Through Language Models](https://arxiv.org/abs/2512.07452)
*Clarisse Bardiot,Pierre-Carl Langlais,Bernard Jacquemin,Jacob Hart,Antonios Lagarias,Nicolas Foucault,Aurélie Lemaître-Legargeant,Jeanne Fras*

Main category: cs.IR

TL;DR: 提出一个结合多模态大语言模型、本体推理模型和Linked Art框架的工作流，将剧院节目单转化为结构化数据，实现98%以上的准确提取，支持大规模表演艺术数据分析。


<details>
  <summary>Details</summary>
Motivation: 文化遗产机构拥有大量剧院节目单，但由于其复杂布局和缺乏结构化元数据，这些资源未被充分利用。需要一种方法将这些文档转化为结构化数据以支持研究。

Method: 使用多模态大语言模型解析和转录数字节目单；训练基于本体的推理模型POntAvignon，采用强化学习结合形式化和语义奖励；扩展Linked Art框架；通过阿维尼翁艺术节语料库进行案例研究。

Result: 视觉语言模型能够准确解析和转录节目单，正确提取率超过98%；推理模型支持自动生成RDF三元组并与现有知识图谱对齐；展示了大规模、本体驱动的表演艺术数据分析潜力。

Conclusion: 该工作流为剧院节目单的数字化处理提供了有效解决方案，实现了可互操作、可解释和可持续的计算戏剧史学分析，为文化遗产数据的结构化处理开辟了新可能性。

Abstract: Many heritage institutions hold extensive collections of theatre programmes, which remain largely underused due to their complex layouts and lack of structured metadata. In this paper, we present a workflow for transforming such documents into structured data using a combination of multimodal large language models (LLMs), an ontology-based reasoning model, and a custom extension of the Linked Art framework. We show how vision-language models can accurately parse and transcribe born-digital and digitised programmes, achieving over 98% of correct extraction. To overcome the challenges of semantic annotation, we train a reasoning model (POntAvignon) using reinforcement learning with both formal and semantic rewards. This approach enables automated RDF triple generation and supports alignment with existing knowledge graphs. Through a case study based on the Festival d'Avignon corpus, we demonstrate the potential for large-scale, ontology-driven analysis of performing arts data. Our results open new possibilities for interoperable, explainable, and sustainable computational theatre historiography.

</details>


### [167] [Exploring Test-time Scaling via Prediction Merging on Large-Scale Recommendation](https://arxiv.org/abs/2512.07650)
*Fuyuan Lyu,Zhentai Chen,Jingyan Jiang,Lingjie Li,Xing Tang,Xiuqiang He,Xue Liu*

Main category: cs.IR

TL;DR: 该论文提出在推荐系统中应用测试时扩展方法，通过模型架构异质性或同构模型随机初始化来生成多样化输出，相比训练时参数扩展能更高效利用计算资源。


<details>
  <summary>Details</summary>
Motivation: 受语言模型成功启发，深度推荐系统扩展成为趋势，但现有方法主要在训练时扩展参数，测试时如何高效利用计算资源扩展仍待探索，这可为推荐系统带来正交改进。

Method: 提出两种测试时扩展方法：1) 利用不同模型架构的异质性；2) 在同构架构下利用模型初始化的随机性。在8个模型（经典和SOTA）和3个基准上评估。

Result: 充分证明两种方案的有效性，在相同推理预算下，测试时扩展能超越参数扩展。测试时扩展还可随并行服务器增加无缝加速，不影响用户端推理时间。

Conclusion: 测试时扩展是推荐系统扩展的有效方法，能高效利用计算资源，提供正交改进，且部署时可通过增加并行服务器加速而不影响用户体验。

Abstract: Inspired by the success of language models (LM), scaling up deep learning recommendation systems (DLRS) has become a recent trend in the community. All previous methods tend to scale up the model parameters during training time. However, how to efficiently utilize and scale up computational resources during test time remains underexplored, which can prove to be a scaling-efficient approach and bring orthogonal improvements in LM domains. The key point in applying test-time scaling to DLRS lies in effectively generating diverse yet meaningful outputs for the same instance. We propose two ways: One is to explore the heterogeneity of different model architectures. The other is to utilize the randomness of model initialization under a homogeneous architecture. The evaluation is conducted across eight models, including both classic and SOTA models, on three benchmarks. Sufficient evidence proves the effectiveness of both solutions. We further prove that under the same inference budget, test-time scaling can outperform parameter scaling. Our test-time scaling can also be seamlessly accelerated with the increase in parallel servers when deployed online, without affecting the inference time on the user side. Code is available.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [168] [Smart Spatial Planning in Egypt: An Algorithm-Driven Approach to Public Service Evaluation in Qena City](https://arxiv.org/abs/2512.06431)
*Mohamed Shamroukh,Mohamed Alkhuzamy Aziz*

Main category: cs.AI

TL;DR: 本研究为埃及基纳市开发了定制化的城市规划模型，使用Python编程和Voronoi图算法生成智能空间分析，评估公共服务覆盖效率，发现平均覆盖率为81.3%，并识别了服务分布不均的问题。


<details>
  <summary>Details</summary>
Motivation: 埃及国家公共服务规划标准往往无法适应地方独特特征，本研究旨在填补这一空白，为基纳市开发量身定制的规划模型。

Method: 采用混合方法（描述性、分析性和实验性），利用Python编程开发基于Voronoi图的智能空间分析算法，生成城市特定的规划标准并评估当前公共服务设施覆盖情况。

Result: 应用模型显示平均服务覆盖率为81.3%，救护车站效率最高（99.8%），公园和开放空间覆盖率最低（10%）。空间分析显示市中心服务密度高（>45个/平方公里），郊区显著减少（<5个/平方公里），Hajer基纳区未服务区域最多，第一区服务覆盖率最高。

Conclusion: 本研究成功推导出本地化规划标准模型并部署了自动化算法评估服务效率，为埃及城市提供了可复制的数据驱动城市规划框架。

Abstract: National planning standards for public services in Egypt often fail to align with unique local characteristics. Addressing this gap, this study develops a tailored planning model for Qena City. Using a hybrid methodology (descriptive, analytical, and experimental), the research utilizes Python programming to generate an intelligent spatial analysis algorithm based on Voronoi Diagrams. This approach creates city-specific planning criteria and evaluates the current coverage of public facilities. The primary contribution of this study is the successful derivation of a localized planning standards model and the deployment of an automated algorithm to assess service efficiency. Application of this model reveals a general service coverage average of 81.3%. Ambulance stations demonstrated the highest efficiency (99.8%) due to recent upgrades, while parks and open spaces recorded the lowest coverage (10%) caused by limited land availability. Spatial analysis indicates a high service density in midtown (>45 services/km^2), which diminishes significantly towards the outskirts (<5 services/km^2). Consequently, the Hajer Qena district contains the highest volume of unserved areas, while the First District (Qesm 1) exhibits the highest level of service coverage. This model offers a replicable framework for data-driven urban planning in Egyptian cities.

</details>


### [169] [PICKT: Practical Interlinked Concept Knowledge Tracing for Personalized Learning using Knowledge Map Concept Relations](https://arxiv.org/abs/2512.07179)
*Wonbeen Lee,Channyoung Lee,Junho Sohn,Hansam Cho*

Main category: cs.AI

TL;DR: 提出PICKT模型解决知识追踪中的冷启动问题，通过知识图谱处理多种输入数据格式，提升在真实ITS环境中的实用性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 个性化学习需求增长，智能导学系统需要准确追踪学生知识状态并提供个性化学习路径。现有知识追踪模型存在输入数据格式受限、新学生/新问题冷启动问题、真实服务环境稳定性不足等局限性。

Method: 提出PICKT模型，利用知识图谱结构化概念间关系，考虑问题和概念文本信息，有效处理多种类型输入数据，解决冷启动问题。

Result: 在反映真实操作环境的实验中，模型表现出优异性能和实用性，在新学生注册和新问题添加两个核心冷启动挑战上显著优于现有模型。

Conclusion: PICKT模型为下一代智能导学系统的实际实施提供了关键的理论和技术基础，通过精细的实验设计验证了模型的稳定性和实用性。

Abstract: With the recent surge in personalized learning, Intelligent Tutoring Systems (ITS) that can accurately track students' individual knowledge states and provide tailored learning paths based on this information are in demand as an essential task. This paper focuses on the core technology of Knowledge Tracing (KT) models that analyze students' sequences of interactions to predict their knowledge acquisition levels. However, existing KT models suffer from limitations such as restricted input data formats, cold start problems arising with new student enrollment or new question addition, and insufficient stability in real-world service environments. To overcome these limitations, a Practical Interlinked Concept Knowledge Tracing (PICKT) model that can effectively process multiple types of input data is proposed. Specifically, a knowledge map structures the relationships among concepts considering the question and concept text information, thereby enabling effective knowledge tracing even in cold start situations. Experiments reflecting real operational environments demonstrated the model's excellent performance and practicality. The main contributions of this research are as follows. First, a model architecture that effectively utilizes diverse data formats is presented. Second, significant performance improvements are achieved over existing models for two core cold start challenges: new student enrollment and new question addition. Third, the model's stability and practicality are validated through delicate experimental design, enhancing its applicability in real-world product environments. This provides a crucial theoretical and technical foundation for the practical implementation of next-generation ITS.

</details>


### [170] [Going All-In on LLM Accuracy: Fake Prediction Markets, Real Confidence Signals](https://arxiv.org/abs/2512.05998)
*Michael Todasco*

Main category: cs.AI

TL;DR: 通过虚构预测市场让LLM用虚拟货币下注来评估其他模型，发现下注机制能产生可读的置信度信号，大额下注准确率高达99%，小额下注仅74%。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型评估其他模型时通常缺乏置信度表示，需要探索如何让LLM表达其内部信念的确定性。

Method: 生成100个数学逻辑问题，让6个基线模型回答，然后让3个预测模型在两种条件下预测基线模型的回答是否正确：控制组（简单正确/错误预测）和激励组（预测加下注1-100,000虚拟货币）。

Result: 激励组准确率略高（81.5% vs 79.1%），学习速度显著更快（第1轮到第4轮改进12.0% vs 2.9%）。下注金额与置信度相关：4万+大额下注准确率约99%，小额下注（<1000）准确率仅74%。

Conclusion: 简单的金融框架可以帮助LLM成为风险感知的预测器，使其内部信念变得可见可用，为元评估系统和LLM间预测市场奠定基础。

Abstract: Large language models are increasingly used to evaluate other models, yet these judgments typically lack any representation of confidence. This pilot study tests whether framing an evaluation task as a betting game (a fictional prediction market with its own LLM currency) improves forecasting accuracy and surfaces calibrated confidence signals. We generated 100 math and logic questions with verifiable answers. Six Baseline models (three current-generation, three prior-generation) answered all items. Three Predictor models then forecasted, for each question-baseline pair, if the baseline would answer correctly. Each predictor completed matched runs in two conditions: Control (simple correct/incorrect predictions) and Incentive (predictions plus wagers of 1-100,000 LLMCoin under even odds, starting from a 1,000,000 LLMCoin bankroll). Across 5,400 predictions per condition, Incentive runs showed modestly higher accuracy (81.5% vs. 79.1%, p = .089, d = 0.86) and significantly faster learning across rounds (12.0 vs. 2.9 percentage-point improvement from Round 1 to Round 4, p = .011). Most notably, stake size tracked confidence. "Whale" bets of 40,000+ coins were correct ~99% of the time, while small bets (<1,000 coins) showed only ~74% accuracy. The key finding is not that fictional money makes models smarter; accuracy gains were modest and did not reach statistical significance (p = .089) in this pilot. Rather, the betting mechanic created a legible confidence signal absent from binary yes/no outputs. This suggests that simple financial framing may help transform LLMs into risk-aware forecasters, making their internal beliefs visible and usable. The protocol offers a foundation for future work for meta-evaluation systems and what may become LLM-to-LLM prediction markets.

</details>


### [171] [Deep learning for autism detection using clinical notes: A comparison of transfer learning for a transparent and black-box approach](https://arxiv.org/abs/2512.06161)
*Gondy Leroy,Prakash Bisht,Sai Madhuri Kandula,Nell Maltman,Sydney Rice*

Main category: cs.AI

TL;DR: 本研究提出了一种基于BioBERT的透明可解释机器学习方法，用于分析临床文本并自动化自闭症谱系障碍诊断，通过混合数据集训练策略获得了97%敏感性和98%特异性的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 自闭症谱系障碍诊断需求日益增长，但现有机器学习模型多为黑箱且通常基于单一数据集训练，限制了其泛化能力和临床可信度。

Method: 使用BioBERT语言模型分析非结构化临床文本，训练模型标注行为描述并映射到诊断标准，然后分配最终标签（ASD或非ASD）。评估了迁移学习能力，比较了顺序训练和混合训练策略，并与黑箱方法进行对比。

Result: 透明模型表现出稳健性能，混合数据训练策略获得最佳结果（97%敏感性，98%特异性）。顺序训练导致性能略有下降，黑箱模型性能较差（90%敏感性，96%特异性）。透明方法整体优于黑箱方法。

Conclusion: 混合数据集训练可获得更好性能，应为实际应用中的首选方法。这项工作为神经发育诊断中更可信、可泛化且临床可操作的人工智能工具铺平了道路。

Abstract: Autism spectrum disorder (ASD) is a complex neurodevelopmental condition whose rising prevalence places increasing demands on a lengthy diagnostic process. Machine learning (ML) has shown promise in automating ASD diagnosis, but most existing models operate as black boxes and are typically trained on a single dataset, limiting their generalizability. In this study, we introduce a transparent and interpretable ML approach that leverages BioBERT, a state-of-the-art language model, to analyze unstructured clinical text. The model is trained to label descriptions of behaviors and map them to diagnostic criteria, which are then used to assign a final label (ASD or not). We evaluate transfer learning, the ability to transfer knowledge to new data, using two distinct real-world datasets. We trained on datasets sequentially and mixed together and compared the performance of the best models and their ability to transfer to new data. We also created a black-box approach and repeated this transfer process for comparison. Our transparent model demonstrated robust performance, with the mixed-data training strategy yielding the best results (97 % sensitivity, 98 % specificity). Sequential training across datasets led to a slight drop in performance, highlighting the importance of training data order. The black-box model performed worse (90 % sensitivity, 96 % specificity) when trained sequentially or with mixed data. Overall, our transparent approach outperformed the black-box approach. Mixing datasets during training resulted in slightly better performance and should be the preferred approach when practically possible. This work paves the way for more trustworthy, generalizable, and clinically actionable AI tools in neurodevelopmental diagnostics.

</details>


### [172] [ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment](https://arxiv.org/abs/2512.06196)
*Charlie Masters,Marta Grześkiewicz,Stefano V. Albrecht*

Main category: cs.AI

TL;DR: ARCANE框架通过将AI对齐问题转化为多智能体协作问题，使用自然语言评分标准动态表示利益相关者偏好，实现可解释、无需重新训练即可调整的对齐方法。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体越来越多地部署到长期任务中，保持其与利益相关者偏好的一致性变得至关重要。需要可解释的奖励模型让利益相关者能够理解和审计模型目标，并且能够在交互时引导智能体，无需重新训练即可纳入偏好变化。

Method: 引入ARCANE框架，将对齐问题构建为多智能体协作问题，动态地将利益相关者偏好表示为自然语言评分标准（可验证的加权标准集合）。受效用理论启发，将评分标准学习制定为重构问题，应用正则化的组序列策略优化(GSPO)程序，平衡可解释性、忠实性和计算效率。

Result: 使用从GDPVal基准派生的219个标记评分标准语料库，在需要多步推理和工具使用的挑战性任务上评估ARCANE。学习的评分标准产生紧凑、易读的评估，并支持可配置的权衡（如正确性与简洁性），无需重新训练。

Conclusion: 基于评分标准的奖励模型为复杂、长期AI系统提供了一条有前景的路径，实现了可解释、测试时可适应的对齐方法。

Abstract: As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context. Inspired by utility theory, we formulate rubric learning as a reconstruction problem and apply a regularized Group-Sequence Policy Optimization (GSPO) procedure that balances interpretability, faithfulness, and computational efficiency. Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use. The learned rubrics produce compact, legible evaluations and enable configurable trade-offs (e.g., correctness vs. conciseness) without retraining. Our results show that rubric-based reward models offer a promising path toward interpretable, test-time adaptive alignment for complex, long-horizon AI systems.

</details>


### [173] [On measuring grounding and generalizing grounding problems](https://arxiv.org/abs/2512.06205)
*Daniel Quigley,Eric Maynard*

Main category: cs.AI

TL;DR: 论文将符号接地问题从二元判断重新构建为包含真实性、保持性、忠实性、鲁棒性和组合性五个维度的审计框架，应用于四种接地模式，并通过三个案例研究展示了不同系统的接地能力差异。


<details>
  <summary>Details</summary>
Motivation: 传统符号接地问题过于简化，需要更精细的框架来评估不同系统中符号如何获得意义，为哲学家、计算机科学家、语言学家和数学家提供共同语言和技术工具。

Method: 提出基于评估元组（上下文、意义类型、威胁模型、参考分布）的审计框架，包含五个核心要求：真实性、保持性、忠实性（相关性和病因性）、鲁棒性、组合性。将此框架应用于四种接地模式（符号、指称、向量、关系）和三个案例研究。

Result: 模型论语义学实现精确组合但缺乏病因性保证；大语言模型在语言任务上显示相关性拟合和局部鲁棒性，但在无接地交互的世界任务上缺乏成功选择；人类语言通过进化和发育获得强真实性，满足所有要求。

Conclusion: 通过将哲学表征问题操作化，为跨学科研究者提供了系统研究接地和意义的共同语言和技术框架，揭示了不同系统在符号接地能力上的根本差异。

Abstract: The symbol grounding problem asks how tokens like cat can be about cats, as opposed to mere shapes manipulated in a calculus. We recast grounding from a binary judgment into an audit across desiderata, each indexed by an evaluation tuple (context, meaning type, threat model, reference distribution): authenticity (mechanisms reside inside the agent and, for strong claims, were acquired through learning or evolution); preservation (atomic meanings remain intact); faithfulness, both correlational (realized meanings match intended ones) and etiological (internal mechanisms causally contribute to success); robustness (graceful degradation under declared perturbations); compositionality (the whole is built systematically from the parts). We apply this framework to four grounding modes (symbolic; referential; vectorial; relational) and three case studies: model-theoretic semantics achieves exact composition but lacks etiological warrant; large language models show correlational fit and local robustness for linguistic tasks, yet lack selection-for-success on world tasks without grounded interaction; human language meets the desiderata under strong authenticity through evolutionary and developmental acquisition. By operationalizing a philosophical inquiry about representation, we equip philosophers of science, computer scientists, linguists, and mathematicians with a common language and technical framework for systematic investigation of grounding and meaning.

</details>


### [174] [AI Application in Anti-Money Laundering for Sustainable and Transparent Financial Systems](https://arxiv.org/abs/2512.06240)
*Chuanhao Nie,Yunbo Liu,Chao Wang*

Main category: cs.AI

TL;DR: 该论文探讨了人工智能在反洗钱（AML）工作流程中的应用，提出了基于图检索增强生成（RAG-Graph）的KYC系统，实验证明能提高检测准确性、降低误报率，并增强KYC流程的效率和透明度。


<details>
  <summary>Details</summary>
Motivation: 洗钱和金融欺诈每年造成数万亿美元损失，严重威胁全球金融稳定。传统反洗钱监管面临效率低下、误报率高、人工调查负担重等挑战，需要现代化技术手段来改进。

Method: 论文提出AI驱动的KYC应用，整合图检索增强生成（RAG Graph）与生成模型，构建了RAG-Graph架构。该方法结合了联邦学习、公平可解释AI、强化学习和人机协同可视化系统等前沿技术。

Result: 实验结果表明，RAG-Graph架构在不同评估场景下展现出高忠实度和强答案相关性，显著提高了KYC客户尽职调查/增强尽职调查（CDD/EDD）工作流程的效率和透明度。

Conclusion: AI技术能够现代化反洗钱工作流程，提高检测精度、降低误报、减轻操作负担。RAG-Graph架构为下一代AML系统提供了透明、可问责且鲁棒的解决方案，有助于实现更可持续、资源优化的合规实践。

Abstract: Money laundering and financial fraud remain major threats to global financial stability, costing trillions annually and challenging regulatory oversight. This paper reviews how artificial intelligence (AI) applications can modernize Anti-Money Laundering (AML) workflows by improving detection accuracy, lowering false-positive rates, and reducing the operational burden of manual investigations, thereby supporting more sustainable development. It further highlights future research directions including federated learning for privacy-preserving collaboration, fairness-aware and interpretable AI, reinforcement learning for adaptive defenses, and human-in-the-loop visualization systems to ensure that next-generation AML architectures remain transparent, accountable, and robust. In the final part, the paper proposes an AI-driven KYC application that integrates graph-based retrieval-augmented generation (RAG Graph) with generative models to enhance efficiency, transparency, and decision support in KYC processes related to money-laundering detection. Experimental results show that the RAG-Graph architecture delivers high faithfulness and strong answer relevancy across diverse evaluation settings, thereby enhancing the efficiency and transparency of KYC CDD/EDD workflows and contributing to more sustainable, resource-optimized compliance practices.

</details>


### [175] [How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge Graph Completion](https://arxiv.org/abs/2512.06296)
*Sooho Moon,Yunyong Ko*

Main category: cs.AI

TL;DR: PROBE是一个新的知识图谱补全评估框架，通过考虑预测锐度和流行度偏差鲁棒性两个关键视角，提供更全面可靠的KGC模型评估。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱补全评估指标存在不足，忽略了两个关键视角：预测锐度（评估单个预测的严格程度）和流行度偏差鲁棒性（预测低流行度实体的能力）。

Method: 提出PROBE评估框架，包含两个组件：1）秩变换器（RT）根据所需的预测锐度水平估计每个预测的分数；2）秩聚合器（RA）以流行度感知的方式聚合所有分数。

Result: 在真实世界知识图谱上的实验表明，现有指标倾向于高估或低估KGC模型的准确性，而PROBE能够提供对KGC模型的全面理解和可靠的评估结果。

Conclusion: PROBE框架通过同时考虑预测锐度和流行度偏差鲁棒性，为知识图谱补全评估提供了更全面、可靠的评估方法，解决了现有评估指标的局限性。

Abstract: Knowledge graph completion (KGC) aims to predict missing facts from the observed KG. While a number of KGC models have been studied, the evaluation of KGC still remain underexplored. In this paper, we observe that existing metrics overlook two key perspectives for KGC evaluation: (A1) predictive sharpness -- the degree of strictness in evaluating an individual prediction, and (A2) popularity-bias robustness -- the ability to predict low-popularity entities. Toward reflecting both perspectives, we propose a novel evaluation framework (PROBE), which consists of a rank transformer (RT) estimating the score of each prediction based on a required level of predictive sharpness and a rank aggregator (RA) aggregating all the scores in a popularity-aware manner. Experiments on real-world KGs reveal that existing metrics tend to over- or under-estimate the accuracy of KGC models, whereas PROBE yields a comprehensive understanding of KGC models and reliable evaluation results.

</details>


### [176] [DaGRPO: Rectifying Gradient Conflict in Reasoning via Distinctiveness-Aware Group Relative Policy Optimization](https://arxiv.org/abs/2512.06337)
*Xuan Xie,Xuan Wang,Wenjie Wang*

Main category: cs.AI

TL;DR: DaGRPO通过序列级梯度矫正和离策略数据增强解决GRPO训练不稳定和样本效率低的问题，在数学推理和OOD泛化基准上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: GRPO在激发大语言模型后训练推理能力方面表现出色，但存在训练不稳定和样本效率低的问题。研究发现根本原因是策略内样本缺乏区分度：常规查询中高度同质化样本导致破坏性梯度冲突，而困难查询中有效正样本稀缺导致优化无效。

Method: 提出Distinctiveness-aware Group Relative Policy Optimization (DaGRPO)，包含两个核心机制：1) 序列级梯度矫正：使用细粒度评分动态屏蔽低区分度的样本对，从源头消除梯度冲突；2) 离策略数据增强：引入高质量锚点恢复困难任务的训练信号。

Result: 在9个数学推理和分布外泛化基准上的实验表明，DaGRPO显著超越现有SFT、GRPO和混合基线，实现新的SOTA性能（如在数学基准上平均准确率提升+4.7%）。深入分析证实DaGRPO有效缓解梯度爆炸并加速长链推理能力的出现。

Conclusion: DaGRPO通过解决GRPO的区分度问题，显著提升了训练稳定性和样本效率，为大语言模型的长时域推理能力训练提供了更有效的优化框架。

Abstract: The evolution of Large Language Models (LLMs) has catalyzed a paradigm shift from superficial instruction following to rigorous long-horizon reasoning. While Group Relative Policy Optimization (GRPO) has emerged as a pivotal mechanism for eliciting such post-training reasoning capabilities due to its exceptional performance, it remains plagued by significant training instability and poor sample efficiency. We theoretically identify the root cause of these issues as the lack of distinctiveness within on-policy rollouts: for routine queries, highly homogeneous samples induce destructive gradient conflicts; whereas for hard queries, the scarcity of valid positive samples results in ineffective optimization. To bridge this gap, we propose Distinctiveness-aware Group Relative Policy Optimization (DaGRPO). DaGRPO incorporates two core mechanisms: (1) Sequence-level Gradient Rectification, which utilizes fine-grained scoring to dynamically mask sample pairs with low distinctiveness, thereby eradicating gradient conflicts at the source; and (2) Off-policy Data Augmentation, which introduces high-quality anchors to recover training signals for challenging tasks. Extensive experiments across 9 mathematical reasoning and out-of-distribution (OOD) generalization benchmarks demonstrate that DaGRPO significantly surpasses existing SFT, GRPO, and hybrid baselines, achieving new state-of-the-art performance (e.g., a +4.7% average accuracy gain on math benchmarks). Furthermore, in-depth analysis confirms that DaGRPO effectively mitigates gradient explosion and accelerates the emergence of long-chain reasoning capabilities.

</details>


### [177] [Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression](https://arxiv.org/abs/2512.06393)
*Qiming Bao,Xiaoxuan Fu*

Main category: cs.AI

TL;DR: LLMs在逻辑推理任务中对语义保持的逻辑变换具有稳定性，但对缺失或冲突证据表现出根本性脆弱性


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在自然语言任务中表现出色，但其在逻辑上下文中的结构扰动泛化能力仍不清楚，需要系统评估其推理可靠性

Method: 引入受控评估框架，通过四种针对性压力测试：规则删除（冗余与必要规则）、矛盾证据注入、逻辑保持重写（六种等价定律）、多定律等价堆叠（2-5个同时变换）

Result: 所有模型在基础任务上达到完美准确率，对冗余规则删除和所有等价重写（单或多定律）完全泛化，但在必要规则删除时准确率降至25%，面对明确矛盾时完全崩溃（0%准确率）

Conclusion: LLMs对语义保持的逻辑变换具有稳定不变性，但对缺失或冲突证据存在根本性脆弱性，该框架为诊断推理失败模式提供了清晰工具，突显了当前LLMs逻辑泛化能力的持续差距

Abstract: Large language models (LLMs) excel across many natural language tasks, yet their generalisation to structural perturbations in logical contexts remains poorly understood. We introduce a controlled evaluation framework that probes reasoning reliability through four targeted stress tests: (1) rule deletion, removing either redundant or essential rules from a multi-step inference chain; (2) contradictory evidence injection; (3) logic-preserving rewrites generated through several families of equivalence laws (contrapositive, double negation, implication, De Morgan, identity, and commutativity); and (4) multi-law equivalence stacking that introduces 2-5 simultaneous logical transformations.
  Across three representative model families: BERT, Qwen2, and LLaMA-like models. Our experiments reveal a strikingly consistent pattern: all models achieve perfect accuracy on the base tasks and remain fully generalise to redundant rule deletion and all equivalence-based rewrites (single or multi-law), but fail sharply under essential rule deletion (dropping to 25% accuracy) and collapse completely in the presence of explicit contradictions (0% accuracy). These results demonstrate that LLMs possess stable invariance to semantic-preserving logical transformations, yet remain fundamentally brittle to missing or conflicting evidence. Our framework provides a clean diagnostic tool for isolating such reasoning failure modes and highlights persistent gaps in the logical generalisation abilities of current LLMs.

</details>


### [178] [UncertaintyZoo: A Unified Toolkit for Quantifying Predictive Uncertainty in Deep Learning Systems](https://arxiv.org/abs/2512.06406)
*Xianzong Wu,Xiaohong Li,Lili Quan,Qiang Hu*

Main category: cs.AI

TL;DR: UncertaintyZoo是一个统一的不确定性量化工具包，集成了29种方法，用于评估大语言模型输出的置信度，特别是在代码漏洞检测任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在现实应用中的错误预测可能导致安全关键场景的损失，现有不确定性量化方法缺乏统一工具，阻碍了实际应用和未来研究。

Method: 开发UncertaintyZoo统一工具包，集成29种不确定性量化方法，涵盖五大类别，提供标准化接口，并在CodeBERT和ChatGLM3模型上进行代码漏洞检测任务评估。

Result: UncertaintyZoo能够有效揭示模型预测的不确定性，在代码漏洞检测任务中验证了现有不确定性量化方法的实用性。

Conclusion: UncertaintyZoo填补了不确定性量化工具的空缺，促进了该领域的实际应用和未来研究，特别是在大语言模型的安全关键应用中具有重要意义。

Abstract: Large language models(LLMs) are increasingly expanding their real-world applications across domains, e.g., question answering, autonomous driving, and automatic software development. Despite this achievement, LLMs, as data-driven systems, often make incorrect predictions, which can lead to potential losses in safety-critical scenarios. To address this issue and measure the confidence of model outputs, multiple uncertainty quantification(UQ) criteria have been proposed. However, even though important, there are limited tools to integrate these methods, hindering the practical usage of UQ methods and future research in this domain. To bridge this gap, in this paper, we introduce UncertaintyZoo, a unified toolkit that integrates 29 uncertainty quantification methods, covering five major categories under a standardized interface. Using UncertaintyZoo, we evaluate the usefulness of existing uncertainty quantification methods under the code vulnerability detection task on CodeBERT and ChatGLM3 models. The results demonstrate that UncertaintyZoo effectively reveals prediction uncertainty. The tool with a demonstration video is available on the project site https://github.com/Paddingbuta/UncertaintyZoo.

</details>


### [179] [The Effect of Belief Boxes and Open-mindedness on Persuasion](https://arxiv.org/abs/2512.06573)
*Onur Bilgin,Abdullah As Sami,Sriram Sai Vujjini,John Licato*

Main category: cs.AI

TL;DR: 该研究探索了在LLM智能体中引入"信念盒"（包含信念陈述的提示空间）如何影响其行为、信念改变倾向以及在多智能体场景中的说服力，同时考察了"开放心态"指令的作用。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体系统在推理和决策应用中的普及，需要让基于LLM的智能体具备类似命题信念的能力。当前简单方法是在提示空间中包含信念陈述（信念盒），但这种方法如何实际影响智能体行为、信念倾向以及在多智能体场景中的说服力尚不清楚。

Method: 通过一系列实验探索信念盒技术的影响：1）在提示空间中包含信念陈述及其强度；2）测试智能体对相反观点的抵抗力和说服力；3）考察"开放心态"指令如何影响信念改变倾向；4）在辩论场景中测试少数派情境（同伴压力）下的信念变化。

Result: 研究发现：1）"开放心态"指令确实影响智能体对信念改变的接受度；2）信念陈述及其强度影响智能体对相反观点的抵抗力和说服力；3）在辩论中被相反观点包围（同伴压力）时，信念改变的可能性增加；4）信念盒技术在推理和决策任务中具有可行性和有效性。

Conclusion: 信念盒技术是有效的，能够显著影响LLM智能体的信念相关行为，包括信念改变倾向、说服力和对同伴压力的反应。这为在多智能体系统中实现更复杂的信念推理和决策提供了可行方法。

Abstract: As multi-agent systems are increasingly utilized for reasoning and decision-making applications, there is a greater need for LLM-based agents to have something resembling propositional beliefs. One simple method for doing so is to include statements describing beliefs maintained in the prompt space (in what we'll call their belief boxes). But when agents have such statements in belief boxes, how does it actually affect their behaviors and dispositions towards those beliefs? And does it significantly affect agents' ability to be persuasive in multi-agent scenarios? Likewise, if the agents are given instructions to be open-minded, how does that affect their behaviors? We explore these and related questions in a series of experiments. Our findings confirm that instructing agents to be open-minded affects how amenable they are to belief change. We show that incorporating belief statements and their strengths influences an agent's resistance to (and persuasiveness against) opposing viewpoints. Furthermore, it affects the likelihood of belief change, particularly when the agent is outnumbered in a debate by opposing viewpoints, i.e., peer pressure scenarios. The results demonstrate the feasibility and validity of the belief box technique in reasoning and decision-making tasks.

</details>


### [180] [FlatFormer: A Flat Transformer Knowledge Tracing Model Based on Cognitive Bias Injection](https://arxiv.org/abs/2512.06629)
*Xiao-li Xia,Hou-biao Li*

Main category: cs.AI

TL;DR: FlatFormer通过"信息注入而非结构堆叠"的设计范式，使用轻量级注入机制在扁平Transformer中实现高性能知识追踪，解决了性能与复杂度之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 知识追踪模型面临"性能-复杂度陷阱"：捕捉复杂认知动态需要深层层次架构，但这会导致实时部署时计算成本过高。需要一种既能保持高性能又能降低复杂度的解决方案。

Method: 提出FlatFormer架构，基于"信息注入而非结构堆叠"的设计范式。采用标准扁平Transformer，并加入两个轻量级注入机制：1) 混合输入编码策略（可学习会话标识符+固定正弦步长嵌入）；2) 预计算幂律偏置直接集成到注意力对数中，显式建模遗忘曲线。

Result: 在四个大规模数据集（如EdNet、Junyi）上的实验表明，FlatFormer达到最先进性能。在EdNet数据集上，相比最强层次基线（HiTSKT），绝对AUC提升8.3%，参数使用量不到15%，推理速度约快3倍。

Conclusion: 高认知保真度并不需要架构复杂性。FlatFormer通过信息注入而非结构堆叠的设计范式，在保持高性能的同时显著降低了计算复杂度，为实时知识追踪部署提供了可行方案。

Abstract: Knowledge Tracing (KT) models face a critical ``Performance-Complexity Trap'': capturing complex cognitive dynamics like learning sessions and memory decay typically requires deep hierarchical architectures, which incur prohibitive computational costs for real-time deployment. To resolve this, we propose FlatFormer, a streamlined architecture based on the novel design paradigm of ``Information Injection over Structural Stacking.'' Unlike parameter-heavy hierarchical models, FlatFormer leverages a standard flat Transformer augmented with two lightweight injection mechanisms: (i) a hybrid input encoding strategy combining learnable session identifiers with fixed sinusoidal step embeddings; and (ii) a pre-computed power-law bias integrated directly into attention logits to explicitly model the forgetting curve. Extensive experiments on four large-scale datasets (e.g., EdNet, Junyi) show that FlatFormer achieves state-of-the-art performance. For example, on the EdNet dataset, compared to the strongest hierarchical baseline (HiTSKT), its absolute AUC increased by 8.3%, while using less than 15% of parameters, and inference speed was about three times faster. These results validate that high cognitive fidelity does not necessitate architectural complexity.

</details>


### [181] [LightSearcher: Efficient DeepSearch via Experiential Memory](https://arxiv.org/abs/2512.06653)
*Hengzhi Lan,Yue Yu,Li Qian,Li Peng,Jie Wu,Wei Liu,Jian Luan,Ting Bai*

Main category: cs.AI

TL;DR: LightSearcher是一个高效的强化学习框架，通过结合文本经验记忆和自适应奖励机制，在保持准确性的同时显著减少DeepSearch范式中的工具调用次数和计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有RL驱动的DeepSearch系统存在准确性与效率之间的权衡问题：频繁调用外部搜索工具可以提高事实准确性，但会导致不必要的计算开销和效率下降。

Method: 提出LightSearcher框架：1) 通过学习对比推理轨迹生成可解释的成功推理模式摘要，融入文本经验记忆；2) 采用自适应奖励塑造机制，仅在正确答案场景中惩罚冗余工具调用。

Result: 在四个多跳QA基准测试中，LightSearcher在保持与SOTA基线ReSearch相当的准确性的同时，将搜索工具调用减少39.6%，推理时间减少48.6%，token消耗减少21.2%。

Conclusion: LightSearcher通过创新的文本经验记忆和自适应奖励机制，有效平衡了DeepSearch范式中的准确性-效率权衡，实现了高效且准确的深度推理。

Abstract: DeepSearch paradigms have become a core enabler for deep reasoning models, allowing them to invoke external search tools to access up-to-date, domain-specific knowledge beyond parametric boundaries, thereby enhancing the depth and factual reliability of reasoning. Building upon this foundation, recent advances in reinforcement learning (RL) have further empowered models to autonomously and strategically control search tool usage, optimizing when and how to query external knowledge sources. Yet, these RL-driven DeepSearch systems often reveal a see-saw trade-off between accuracy and efficiency-frequent tool invocations can improve factual correctness but lead to unnecessary computational overhead and diminished efficiency. To address this challenge, we propose LightSearcher, an efficient RL framework that incorporates textual experiential memory by learning contrastive reasoning trajectories to generate interpretable summaries of successful reasoning patterns. In addition, it employs an adaptive reward shaping mechanism that penalizes redundant tool calls only in correct-answer scenarios. This design effectively balances the inherent accuracy-efficiency trade-off in DeepSearch paradigms. Experiments on four multi-hop QA benchmarks show that LightSearcher maintains accuracy comparable to SOTA baseline ReSearch, while reducing search tool invocations by 39.6%, inference time by 48.6%, and token consumption by 21.2%, demonstrating its superior efficiency.

</details>


### [182] [Academic journals' AI policies fail to curb the surge in AI-assisted academic writing](https://arxiv.org/abs/2512.06705)
*Yongyuan He,Yi Bu*

Main category: cs.AI

TL;DR: 期刊AI政策对研究者使用AI写作工具的实际影响有限，尽管70%期刊有政策，但AI使用率仍大幅增长，且政策有无期刊间无显著差异，AI使用披露率极低仅0.1%


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在学术写作中的快速应用，期刊和出版商制定了大量政策回应，但这些政策的实际效果尚不清楚，需要评估AI使用指南在现实世界中的真实影响

Method: 分析5,114种期刊和超过520万篇论文，评估AI使用指南的实际影响；对164,000篇科学出版物进行全文分析，特别关注2023年以来发表的75,000篇论文的AI使用披露情况

Result: 70%期刊采用了AI政策（主要是要求披露），但研究者使用AI写作工具在各学科中急剧增加，有政策和无政策期刊间无显著差异；非英语国家、物理科学和高开放获取期刊增长最快；2023年以来发表的论文中仅76篇（0.1%）明确披露了AI使用

Conclusion: 当前政策在促进透明度或限制AI采用方面基本失败，需要重新评估伦理框架以促进科学中负责任的AI整合

Abstract: The rapid integration of generative AI into academic writing has prompted widespread policy responses from journals and publishers. However, the effectiveness of these policies remains unclear. Here, we analyze 5,114 journals and over 5.2 million papers to evaluate the real-world impact of AI usage guidelines. We show that despite 70% of journals adopting AI policies (primarily requiring disclosure), researchers' use of AI writing tools has increased dramatically across disciplines, with no significant difference between journals with or without policies. Non-English-speaking countries, physical sciences, and high-OA journals exhibit the highest growth rates. Crucially, full-text analysis on 164k scientific publications reveals a striking transparency gap: Of the 75k papers published since 2023, only 76 (0.1%) explicitly disclosed AI use. Our findings suggest that current policies have largely failed to promote transparency or restrain AI adoption. We urge a re-evaluation of ethical frameworks to foster responsible AI integration in science.

</details>


### [183] [Decouple to Generalize: Context-First Self-Evolving Learning for Data-Scarce Vision-Language Reasoning](https://arxiv.org/abs/2512.06835)
*Tingyu Li,Zheng Sun,Jingxuan Wei,Siyuan Li,Conghui He,Lijun Wu,Cheng Tan*

Main category: cs.AI

TL;DR: DoGe提出双解耦框架，通过分离思考者和解决者角色，引导模型从上下文学习而非直接解题，避免奖励黑客问题，并构建演化课程学习管道提升数据多样性，实现自演化大型视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型通过强化学习实现推理，但在专业领域（如化学、地球科学、多模态数学）面临高质量多模态数据稀缺问题。现有方法如合成数据和自奖励机制存在分布有限和对齐困难，导致奖励黑客问题，模型利用高奖励模式导致策略熵崩溃和训练不稳定。

Method: DoGe采用双解耦框架：1）将学习过程解耦为思考者和解决者两个组件，合理量化奖励信号，采用两阶段强化学习后训练方法（从自由探索上下文到实际解决任务）；2）构建演化课程学习管道，包括扩展的本地领域知识语料库和迭代演化的种子问题池，增加训练数据多样性。

Result: 实验表明，DoGe方法在各种基准测试中持续优于基线方法，为实现自演化大型视觉语言模型提供了可扩展的途径。

Conclusion: DoGe通过双解耦框架和演化课程学习管道，有效解决了视觉语言模型在专业领域强化学习中的数据稀缺和奖励黑客问题，为实现连续自演化的大型视觉语言模型提供了可行方案。

Abstract: Recent vision-language models (VLMs) achieve remarkable reasoning through reinforcement learning (RL), which provides a feasible solution for realizing continuous self-evolving large vision-language models (LVLMs) in the era of experience. However, RL for VLMs requires abundant high-quality multimodal data, especially challenging in specialized domains like chemistry, earth sciences, and multimodal mathematics. Existing strategies such as synthetic data and self-rewarding mechanisms suffer from limited distributions and alignment difficulties, ultimately causing reward hacking: models exploit high-reward patterns, collapsing policy entropy and destabilizing training. We propose DoGe (Decouple to Generalize), a dual-decoupling framework that guides models to first learn from context rather than problem solving by refocusing on the problem context scenarios overlooked by synthetic data methods. By decoupling learning process into dual components (Thinker and Solver), we reasonably quantify the reward signals of this process and propose a two-stage RL post-training approach from freely exploring context to practically solving tasks. Second, to increase the diversity of training data, DoGe constructs an evolving curriculum learning pipeline: an expanded native domain knowledge corpus and an iteratively evolving seed problems pool. Experiments show that our method consistently outperforms the baseline across various benchmarks, providing a scalable pathway for realizing self-evolving LVLMs.

</details>


### [184] [JT-DA: Enhancing Data Analysis with Tool-Integrated Table Reasoning Large Language Models](https://arxiv.org/abs/2512.06859)
*Ce Chi,Xing Wang,Zhendong Wang,Xiaofan Liu,Ce Li,Zhiyan Song,Chen Zhao,Kexin Yang,Boshen Shi,Jingjing Yang,Chao Deng,Junlan Feng*

Main category: cs.AI

TL;DR: JT-DA-8B是一个专门用于复杂表格推理任务的8B参数大语言模型，通过构建包含34个表格推理任务的多样化训练语料，采用自动管道生成多步分析任务，并结合监督微调和强化学习进行优化，在多种表格推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 针对表格推理场景中高质量监督数据缺乏的问题，需要构建专门的大语言模型来处理现实世界中的复杂表格推理任务。

Method: 1) 构建包含34个表格推理任务的多样化训练语料，整合29个公开表格QA数据集和300万张表格；2) 提出自动管道生成现实多步分析任务；3) 基于开源JT-Coder-8B模型，采用LLM评分和工作流对齐过滤蒸馏高质量表格中心数据；4) 结合监督微调(SFT)和强化学习(RL)优化模型；5) 提出四阶段表格推理工作流：表格预处理、表格感知、工具集成推理和提示工程。

Result: JT-DA-8B在各种表格推理任务中取得了强劲的性能表现，证明了数据中心的生成和工作流驱动的优化方法的有效性。

Conclusion: 通过构建全面的训练语料、采用自动数据生成管道、结合SFT和RL优化以及设计四阶段推理工作流，JT-DA-8B成功解决了表格推理中的监督数据缺乏问题，为复杂表格推理任务提供了有效的解决方案。

Abstract: In this work, we present JT-DA-8B (JiuTian Data Analyst 8B), a specialized large language model designed for complex table reasoning tasks across diverse real-world scenarios. To address the lack of high-quality supervision in tabular reasoning scenarios, we construct a comprehensive and diverse training corpus with 34 well-defined table reasoning tasks, by aggregating 29 public table QA datasets and 3 million tables. An automatic pipeline is proposed to generate realistic multi-step analytical tasks involving reasoning patterns. The model is trained upon open-source JT-Coder-8B model, an 8B-parameter decoder-only foundation model trained from scratch. In the training stage, we leverage LLM-based scoring and workflow-aligned filtering to distill high-quality, table-centric data. Both supervised fine-tuning (SFT) and Reinforcement learning (RL) are adopted to optimize our model. Afterwards, a four-stage table reasoning workflow is proposed, including table preprocessing, table sensing, tool-integrated reasoning, and prompt engineering, to improve model interpretability and execution accuracy. Experimental results show that JT-DA-8B achieves strong performance in various table reasoning tasks, demonstrating the effectiveness of data-centric generation and workflow-driven optimization.

</details>


### [185] [Do Persona-Infused LLMs Affect Performance in a Strategic Reasoning Game?](https://arxiv.org/abs/2512.06867)
*John Licato,Stephen Steinle,Brayden Hollis*

Main category: cs.AI

TL;DR: 研究探讨了人格提示对大型语言模型在战略游戏PERIL中决策表现的影响，发现通过中介翻译过程将人格映射为启发式值能提升游戏表现，而直接推断的启发式效果有限。


<details>
  <summary>Details</summary>
Motivation: 虽然人格提示能触发不同风格的文本生成，但尚不清楚这些差异是否转化为可测量的行为差异，特别是在对抗性战略环境中的决策影响。研究旨在探究人格提示对战略表现的实际效果。

Method: 使用PERIL世界统治棋盘游戏作为测试环境，比较人格衍生的启发式策略与手动选择策略的效果。引入基于探索性因子分析的结构化翻译过程作为中介，将LLM生成的人格清单响应映射为启发式值。

Result: 某些与战略思维相关的人格确实能提升游戏表现，但仅当使用中介翻译过程时有效。该方法相比直接推断的启发式，提高了启发式的可靠性和表面效度，能更好地研究人格类型对决策的影响。

Conclusion: 人格提示确实影响LLM的决策制定，但需要通过结构化翻译过程才能有效转化为行为差异。研究提出的启发式生成方法将心理测量学原理应用于LLM，为理解人格提示对决策的影响提供了新途径。

Abstract: Although persona prompting in large language models appears to trigger different styles of generated text, it is unclear whether these translate into measurable behavioral differences, much less whether they affect decision-making in an adversarial strategic environment that we provide as open-source. We investigate the impact of persona prompting on strategic performance in PERIL, a world-domination board game. Specifically, we compare the effectiveness of persona-derived heuristic strategies to those chosen manually. Our findings reveal that certain personas associated with strategic thinking improve game performance, but only when a mediator is used to translate personas into heuristic values. We introduce this mediator as a structured translation process, inspired by exploratory factor analysis, that maps LLM-generated inventory responses into heuristics. Results indicate our method enhances heuristic reliability and face validity compared to directly inferred heuristics, allowing us to better study the effect of persona types on decision making. These insights advance our understanding of how persona prompting influences LLM-based decision-making and propose a heuristic generation method that applies psychometric principles to LLMs.

</details>


### [186] [On Memory: A comparison of memory mechanisms in world models](https://arxiv.org/abs/2512.06983)
*Eli J. Laird,Corey Clark*

Main category: cs.AI

TL;DR: 本文研究了基于Transformer的世界模型的有效记忆跨度，分析了多种记忆增强机制，提出了区分记忆编码和记忆注入的分类法，并通过状态回忆任务评估了不同机制的记忆召回能力。


<details>
  <summary>Details</summary>
Motivation: 世界模型使智能体能够在想象环境中进行规划，但基于Transformer的世界模型在长时程规划中受到有效记忆跨度的限制，导致长序列生成中的感知漂移，阻碍了在想象轨迹中完成闭环检测的能力。

Method: 通过分析多种记忆增强机制，提出了区分记忆编码和记忆注入的分类法，从残差流动态的角度理解这些机制如何扩展世界模型的记忆。使用状态回忆评估任务来测量每种机制的记忆召回能力，并分析各自的权衡。

Result: 研究发现记忆机制能够提高视觉Transformer的有效记忆跨度，并为在世界模型的想象中完成闭环检测提供了路径。

Conclusion: 记忆增强机制对于扩展基于Transformer的世界模型的记忆能力至关重要，能够改善长时程规划中的感知漂移问题，使智能体能够在想象环境中更有效地进行闭环检测和长期规划。

Abstract: World models enable agents to plan within imagined environments by predicting future states conditioned on past observations and actions. However, their ability to plan over long horizons is limited by the effective memory span of the backbone architecture. This limitation leads to perceptual drift in long rollouts, hindering the model's capacity to perform loop closures within imagined trajectories. In this work, we investigate the effective memory span of transformer-based world models through an analysis of several memory augmentation mechanisms. We introduce a taxonomy that distinguishes between memory encoding and memory injection mechanisms, motivating their roles in extending the world model's memory through the lens of residual stream dynamics. Using a state recall evaluation task, we measure the memory recall of each mechanism and analyze its respective trade-offs. Our findings show that memory mechanisms improve the effective memory span in vision transformers and provide a path to completing loop closures within a world model's imagination.

</details>


### [187] [ClinNoteAgents: An LLM Multi-Agent System for Predicting and Interpreting Heart Failure 30-Day Readmission from Clinical Notes](https://arxiv.org/abs/2512.07081)
*Rongjia Zhou,Chengzhuo Li,Carl Yang,Jiaying Lu*

Main category: cs.AI

TL;DR: 本文提出了ClinNoteAgents框架，利用LLM多智能体系统从自由文本临床笔记中提取心衰再入院风险因素，实现结构化表示和预测分析。


<details>
  <summary>Details</summary>
Motivation: 心衰是美国老年人再住院的主要原因之一。临床笔记包含丰富的患者信息，占电子健康记录的很大部分，但在心衰再入院风险分析中未得到充分利用。传统模型依赖专家规则、医学词库和本体来解释临床笔记，但这些笔记通常存在拼写错误、缩写和领域特定术语。

Method: 提出ClinNoteAgents框架，这是一个基于LLM的多智能体系统，将自由文本临床笔记转化为：(1) 临床和社会风险因素的结构化表示用于关联分析；(2) 临床医生风格的抽象表示用于心衰30天再入院预测。

Result: 在3,544份笔记（来自2,065名患者，再入院率35.16%）上评估ClinNoteAgents，在从自由文本提取风险因素、识别关键贡献因素和预测再入院风险方面表现出色。

Conclusion: 通过减少对结构化字段的依赖，最小化手动标注和模型训练，ClinNoteAgents为数据有限的医疗系统提供了一个可扩展且可解释的基于笔记的心衰再入院风险建模方法。

Abstract: Heart failure (HF) is one of the leading causes of rehospitalization among older adults in the United States. Although clinical notes contain rich, detailed patient information and make up a large portion of electronic health records (EHRs), they remain underutilized for HF readmission risk analysis. Traditional computational models for HF readmission often rely on expert-crafted rules, medical thesauri, and ontologies to interpret clinical notes, which are typically written under time pressure and may contain misspellings, abbreviations, and domain-specific jargon. We present ClinNoteAgents, an LLM-based multi-agent framework that transforms free-text clinical notes into (1) structured representations of clinical and social risk factors for association analysis and (2) clinician-style abstractions for HF 30-day readmission prediction. We evaluate ClinNoteAgents on 3,544 notes from 2,065 patients (readmission rate=35.16%), demonstrating strong performance in extracting risk factors from free-text, identifying key contributing factors, and predicting readmission risk. By reducing reliance on structured fields and minimizing manual annotation and model training, ClinNoteAgents provides a scalable and interpretable approach to note-based HF readmission risk modeling in data-limited healthcare systems.

</details>


### [188] [A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy](https://arxiv.org/abs/2512.07109)
*Miguel Ingram,Arthur Joseph Merritt*

Main category: cs.AI

TL;DR: 本文提出了首个针对400个任务的9类别分类法，验证了Transformer在抽象推理任务中存在神经亲和力天花板效应，揭示了局部模式学习与全局合成之间的组合性鸿沟。


<details>
  <summary>Details</summary>
Motivation: 响应Hodel等人对任务相关性正式定义的需求，研究旨在系统分析抽象推理任务中Transformer架构的局限性，揭示神经亲和力对性能的影响。

Method: 1) 开发9类别任务分类法并通过规则代码分析验证；2) 使用CNN在原始网格像素上训练验证分类法的视觉一致性；3) 在302个任务上微调170万参数Transformer；4) 应用分类法分析ARC-AGI-2测试集和独立研究数据。

Result: 1) 分类法准确率达97.5%；2) CNN验证分类视觉一致性（S3准确率95.24%）；3) 发现35.3%任务对Transformer亲和力低；4) 揭示组合性鸿沟：69.5%任务局部准确率>80%但全局准确率<10%；5) 低亲和力任务性能上限明显（51.9% vs 77.7%）。

Conclusion: Transformer在抽象推理任务中存在神经亲和力天花板效应，性能受架构适宜性限制而非训练数据。未来进展需要开发具有亲和力对齐模块的混合架构。分类法为任务诊断和架构设计提供了精确工具。

Abstract: Responding to Hodel et al.'s (2024) call for a formal definition of task relatedness in re-arc, we present the first 9-category taxonomy of all 400 tasks, validated at 97.5% accuracy via rule-based code analysis. We prove the taxonomy's visual coherence by training a CNN on raw grid pixels (95.24% accuracy on S3, 36.25% overall, 3.3x chance), then apply the taxonomy diagnostically to the original ARC-AGI-2 test set. Our curriculum analysis reveals 35.3% of tasks exhibit low neural affinity for Transformers--a distributional bias mirroring ARC-AGI-2. To probe this misalignment, we fine-tuned a 1.7M-parameter Transformer across 302 tasks, revealing a profound Compositional Gap: 210 of 302 tasks (69.5%) achieve >80% cell accuracy (local patterns) but <10% grid accuracy (global synthesis). This provides direct evidence for a Neural Affinity Ceiling Effect, where performance is bounded by architectural suitability, not curriculum. Applying our framework to Li et al.'s independent ViTARC study (400 specialists, 1M examples each) confirms its predictive power: Very Low affinity tasks achieve 51.9% versus 77.7% for High affinity (p<0.001), with a task at 0% despite massive data. The taxonomy enables precise diagnosis: low-affinity tasks (A2) hit hard ceilings, while high-affinity tasks (C1) reach 99.8%. These findings indicate that progress requires hybrid architectures with affinity-aligned modules. We release our validated taxonomy,

</details>


### [189] [ContextualSHAP : Enhancing SHAP Explanations Through Contextual Language Generation](https://arxiv.org/abs/2512.07178)
*Latifa Dwiyanti,Sergio Ryan Wibisono,Hidetaka Nambo*

Main category: cs.AI

TL;DR: 提出一个Python包，将SHAP与大型语言模型（GPT）集成，为特征重要性解释生成上下文文本描述，提高非技术用户的可理解性。


<details>
  <summary>Details</summary>
Motivation: SHAP虽然能有效可视化特征重要性，但缺乏对非技术背景终端用户有意义的上下文解释，需要更用户友好的解释方法。

Method: 开发Python包，将SHAP与OpenAI的GPT集成，通过用户定义的参数（特征别名、描述、背景信息）生成上下文文本解释。

Result: 在医疗相关案例研究中应用，通过李克特量表和访谈的用户评估显示，生成的解释比纯可视化输出更易理解和上下文适当。

Conclusion: 可视化与上下文文本结合可能支持更用户友好和可信的模型解释，初步结果表明这种方法有潜力。

Abstract: Explainable Artificial Intelligence (XAI) has become an increasingly important area of research, particularly as machine learning models are deployed in high-stakes domains. Among various XAI approaches, SHAP (SHapley Additive exPlanations) has gained prominence due to its ability to provide both global and local explanations across different machine learning models. While SHAP effectively visualizes feature importance, it often lacks contextual explanations that are meaningful for end-users, especially those without technical backgrounds. To address this gap, we propose a Python package that extends SHAP by integrating it with a large language model (LLM), specifically OpenAI's GPT, to generate contextualized textual explanations. This integration is guided by user-defined parameters (such as feature aliases, descriptions, and additional background) to tailor the explanation to both the model context and the user perspective. We hypothesize that this enhancement can improve the perceived understandability of SHAP explanations. To evaluate the effectiveness of the proposed package, we applied it in a healthcare-related case study and conducted user evaluations involving real end-users. The results, based on Likert-scale surveys and follow-up interviews, indicate that the generated explanations were perceived as more understandable and contextually appropriate compared to visual-only outputs. While the findings are preliminary, they suggest that combining visualization with contextualized text may support more user-friendly and trustworthy model explanations.

</details>


### [190] [M-STAR: Multi-Scale Spatiotemporal Autoregression for Human Mobility Modeling](https://arxiv.org/abs/2512.07314)
*Yuxiao Luo,Songming Zhang,Sijie Ruan,Siran Chen,Kang Liu,Yang Xu,Yu Zheng,Ling Yin*

Main category: cs.AI

TL;DR: M-STAR是一个多尺度时空自回归框架，通过从粗到细的时空预测过程生成长轨迹，在保真度和生成速度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于自回归和扩散模型的方法在生成长期轨迹（如周轨迹）时效率低下，且缺乏显式的时空多尺度建模能力，限制了实际应用。

Method: 提出M-STAR框架，包含多尺度时空标记器和基于Transformer的解码器，通过从粗到细的时空预测过程生成长期轨迹。

Result: 在两个真实世界数据集上的实验表明，M-STAR在轨迹保真度方面优于现有方法，并显著提高了生成速度。

Conclusion: M-STAR通过多尺度时空建模有效解决了长期轨迹生成的效率和保真度问题，为交通规划和流行病建模等应用提供了更好的工具。

Abstract: Modeling human mobility is vital for extensive applications such as transportation planning and epidemic modeling. With the rise of the Artificial Intelligence Generated Content (AIGC) paradigm, recent works explore synthetic trajectory generation using autoregressive and diffusion models. While these methods show promise for generating single-day trajectories, they remain limited by inefficiencies in long-term generation (e.g., weekly trajectories) and a lack of explicit spatiotemporal multi-scale modeling. This study proposes Multi-Scale Spatio-Temporal AutoRegression (M-STAR), a new framework that generates long-term trajectories through a coarse-to-fine spatiotemporal prediction process. M-STAR combines a Multi-scale Spatiotemporal Tokenizer that encodes hierarchical mobility patterns with a Transformer-based decoder for next-scale autoregressive prediction. Experiments on two real-world datasets show that M-STAR outperforms existing methods in fidelity and significantly improves generation speed. The data and codes are available at https://github.com/YuxiaoLuo0013/M-STAR.

</details>


### [191] [A Geometric Unification of Concept Learning with Concept Cones](https://arxiv.org/abs/2512.07355)
*Alexandre Rocchi--Henry,Thomas Fel,Gianni Franchi*

Main category: cs.AI

TL;DR: 该论文提出了一个统一框架，将监督式的概念瓶颈模型（CBMs）和无监督的稀疏自编码器（SAEs）视为学习激活空间中概念锥的两种方法，并建立了量化评估SAEs学习概念与人类定义概念对齐程度的度量标准。


<details>
  <summary>Details</summary>
Motivation: 概念可解释性领域存在两个平行发展但很少对话的传统：CBMs通过监督学习指定概念，SAEs通过无监督学习发现概念。研究者希望建立一个统一框架来连接这两种范式，提供量化评估SAEs学习概念与人类概念对齐程度的方法。

Method: 提出几何统一框架，将CBMs和SAEs都视为学习激活空间中的线性方向集合，其非负组合形成概念锥。建立包含性框架，用CBM提供的人类定义几何作为参考，评估SAEs学习锥的近似或包含程度。开发量化指标，将稀疏度、扩展比等归纳偏置与概念对齐联系起来。

Result: 发现了稀疏度和扩展因子的"最佳点"，能最大化与CBM概念的几何和语义对齐。建立了连接监督和无监督概念发现的统一几何框架，提供了评估SAEs进展和概念对齐的原则性度量标准。

Conclusion: 监督和无监督概念发现方法在本质上共享相同的几何结构，差异仅在于概念锥的选择方式。提出的框架为评估SAEs学习概念与人类概念的对齐提供了量化工具，有助于推动概念可解释性研究的进展。

Abstract: Two traditions of interpretability have evolved side by side but seldom spoken to each other: Concept Bottleneck Models (CBMs), which prescribe what a concept should be, and Sparse Autoencoders (SAEs), which discover what concepts emerge. While CBMs use supervision to align activations with human-labeled concepts, SAEs rely on sparse coding to uncover emergent ones. We show that both paradigms instantiate the same geometric structure: each learns a set of linear directions in activation space whose nonnegative combinations form a concept cone. Supervised and unsupervised methods thus differ not in kind but in how they select this cone. Building on this view, we propose an operational bridge between the two paradigms. CBMs provide human-defined reference geometries, while SAEs can be evaluated by how well their learned cones approximate or contain those of CBMs. This containment framework yields quantitative metrics linking inductive biases -- such as SAE type, sparsity, or expansion ratio -- to emergence of plausible\footnote{We adopt the terminology of \citet{jacovi2020towards}, who distinguish between faithful explanations (accurately reflecting model computations) and plausible explanations (aligning with human intuition and domain knowledge). CBM concepts are plausible by construction -- selected or annotated by humans -- though not necessarily faithful to the true latent factors that organise the data manifold.} concepts. Using these metrics, we uncover a ``sweet spot'' in both sparsity and expansion factor that maximizes both geometric and semantic alignment with CBM concepts. Overall, our work unifies supervised and unsupervised concept discovery through a shared geometric framework, providing principled metrics to measure SAE progress and assess how well discovered concept align with plausible human concepts.

</details>


### [192] [LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services](https://arxiv.org/abs/2512.07436)
*Hang He,Chuhuai Yue,Chengqi Dong,Mingxue Tian,Zhenfeng Liu,Jiajun Chai,Xiaohan Wang,Yufei Zhang,Qun Liao,Guojun Yin,Wei Lin,Chengcheng Wan,Haiying Sun,Ting Su*

Main category: cs.AI

TL;DR: LocalSearchBench是首个针对本地生活服务的智能搜索基准测试，包含超过15万条高质量数据，构建了300个多跳问答任务，实验显示即使是当前最先进的大模型也仅能达到34.34%的正确率。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型研究主要集中在通用信息检索领域，很少关注具有独特挑战的垂直领域。本地生活服务领域的查询通常具有模糊性，需要在商户和产品之间进行多跳推理，这些挑战尚未得到充分解决。

Method: 构建了LocalSearchBench基准测试，包含来自不同城市和业务类型的超过15万条高质量条目；基于真实用户查询构建了300个多跳问答任务；开发了LocalPlayground统一环境，集成了多种工具供智能体交互。

Result: 实验结果显示，即使是当前最先进的大模型（DeepSeek-V3.1）在LocalSearchBench上仅能达到34.34%的正确率；大多数模型在完整性（平均77.33%）和忠实度（平均61.99%）方面存在问题。

Conclusion: 本地生活服务领域需要专门的基准测试和领域特定的智能体训练，当前的大模型在该领域仍面临显著挑战，突显了进一步研究和改进的必要性。

Abstract: Recent advances in large reasoning models (LRMs) have enabled agentic search systems to perform complex multi-step reasoning across multiple sources. However, most studies focus on general information retrieval and rarely explores vertical domains with unique challenges. In this work, we focus on local life services and introduce LocalSearchBench, which encompass diverse and complex business scenarios. Real-world queries in this domain are often ambiguous and require multi-hop reasoning across merchants and products, remaining challenging and not fully addressed. As the first comprehensive benchmark for agentic search in local life services, LocalSearchBench includes over 150,000 high-quality entries from various cities and business types. We construct 300 multi-hop QA tasks based on real user queries, challenging agents to understand questions and retrieve information in multiple steps. We also developed LocalPlayground, a unified environment integrating multiple tools for agent interaction. Experiments show that even state-of-the-art LRMs struggle on LocalSearchBench: the best model (DeepSeek-V3.1) achieves only 34.34% correctness, and most models have issues with completeness (average 77.33%) and faithfulness (average 61.99%). This highlights the need for specialized benchmarks and domain-specific agent training in local life services. Code, Benchmark, and Leaderboard are available at localsearchbench.github.io.

</details>


### [193] [Comparative Analysis and Parametric Tuning of PPO, GRPO, and DAPO for LLM Reasoning Enhancement](https://arxiv.org/abs/2512.07611)
*Yongsheng Lian*

Main category: cs.AI

TL;DR: 本研究系统比较了三种强化学习算法（PPO、GRPO、DAPO）在提升大语言模型复杂推理能力方面的表现，通过控制性迁移学习评估发现RL训练模型在所有任务上都优于基础模型，但改进程度因基准而异。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索强化学习算法如何有效提升大语言模型的复杂推理能力，通过系统比较不同RL算法在专门任务上的训练效果，为RL-based LLM训练提供实用指导。

Method: 采用控制性迁移学习方法：首先在专门的Countdown Game上对模型进行微调，然后在通用推理基准套件上进行评估。对三种RL算法（PPO、GRPO、DAPO）进行参数分析，包括组大小、KL惩罚系数和动态采样组件的影响。

Result: 所有RL训练模型在各项任务上都优于对应的基础模型，但改进程度因基准而异。增加GRPO和DAPO中的组大小能带来更稳定的训练动态和更高准确率，KL惩罚系数的影响是非单调的。DAPO中的动态采样组件并未改善性能，禁用DS时DAPO取得最佳整体结果。

Conclusion: 强化学习能有效提升大语言模型的复杂推理能力，但不同算法和参数设置对性能有显著影响。GRPO和DAPO的组大小优化、KL惩罚系数的适当选择是关键，而DAPO的动态采样组件在实际应用中可能不需要。

Abstract: This study presents a systematic comparison of three Reinforcement Learning (RL) algorithms (PPO, GRPO, and DAPO) for improving complex reasoning in large language models (LLMs). Our main contribution is a controlled transfer-learning evaluation: models are first fine-tuned on the specialized Countdown Game and then assessed on a suite of general-purpose reasoning benchmarks. Across all tasks, RL-trained models outperform their corresponding base models, although the degree of improvement differs by benchmark.
  Our parametric analysis offers practical guidance for RL-based LLM training. Increasing the group size in GRPO and DAPO leads to more stable training dynamics and higher accuracy, while the impact of the KL-penalty coefficient is non-monotonic. Additionally, we find that the Dynamic Sampling (DS) component in DAPO does not improve performance; in fact, the best overall results are achieved with DAPO when DS is disabled.

</details>


### [194] [The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds](https://arxiv.org/abs/2512.07631)
*Shahar Lutati*

Main category: cs.AI

TL;DR: 本文提出了Agent Capability Problem (ACP)框架，用于预测智能体在资源约束下能否解决问题，将问题解决视为信息获取过程，通过信息论方法预测资源需求。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖经验启发式，缺乏理论框架来预测智能体在资源约束下能否成功解决问题。需要一种能够提前预测资源需求的理论框架，以优化智能体的决策过程。

Method: 将问题解决建模为信息获取过程：智能体需要获取Itotal比特信息来识别解决方案，每个动作获得Istep比特信息，成本为Cstep。由此推导出有效成本Ceff = (Itotal/Istep)·Cstep，用于预测资源需求。提供了Ceff的下界证明和紧概率上界。

Result: 实验验证显示ACP预测与智能体实际性能高度一致，能够有效约束搜索努力，在效率上优于贪婪和随机策略。该框架适用于基于LLM和智能体工作流，将主动学习、贝叶斯优化和强化学习原则统一到信息论视角下。

Conclusion: ACP提供了一个统一的信息论框架，能够提前预测智能体在资源约束下的问题解决能力，为智能体资源分配决策提供了理论基础，并展示了跨不同智能体系统的泛化能力。

Abstract: When should an autonomous agent commit resources to a task? We introduce the Agent Capability Problem (ACP), a framework for predicting whether an agent can solve a problem under resource constraints. Rather than relying on empirical heuristics, ACP frames problem-solving as information acquisition: an agent requires $\Itotal$ bits to identify a solution and gains $\Istep$ bits per action at cost $\Cstep$, yielding an effective cost $\Ceff = (\Itotal/\Istep), \Cstep$ that predicts resource requirements before search. We prove that $\Ceff$ lower-bounds expected cost and provide tight probabilistic upper bounds. Experimental validation shows that ACP predictions closely track actual agent performance, consistently bounding search effort while improving efficiency over greedy and random strategies. The framework generalizes across LLM-based and agentic workflows, linking principles from active learning, Bayesian optimization, and reinforcement learning through a unified information-theoretic lens. \

</details>


### [195] [Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE](https://arxiv.org/abs/2512.07710)
*Anxiang Zeng,Haibo Zhang,Hailing Zhang,Kaixiang Mo,Liang Yao,Ling Hu,Long Zhang,Shuman Liu,Shuyi Xie,Yanshi Li,Yizhang Chen,Yuepeng Sheng,Yuwei Huang,Zhaochen Xu,Zhiqiang Zhou,Ziqin Liew*

Main category: cs.AI

TL;DR: CompassMax-V3-Thinking是一个千亿规模的MoE推理模型，采用新的RL框架训练，核心原则是"每个提示都必须重要"。通过多阶段零方差消除、ESPO优化方法、路由器回放策略和高吞吐RL系统等技术，解决了大规模RL训练中的效率问题。


<details>
  <summary>Details</summary>
Motivation: 将RL扩展到千亿规模时暴露了关键效率问题：零方差提示浪费rollout资源、长时域重要性采样不稳定、标准奖励模型导致优势反转，以及rollout处理中的系统性瓶颈。需要解决这些挑战以实现大规模MoE模型的稳定高效RL训练。

Method: 1. 多阶段零方差消除：过滤非信息性提示，稳定基于群体的策略优化；2. ESPO：熵自适应优化方法，平衡token级和序列级重要性采样；3. 路由器回放策略：对齐训练时MoE路由器决策与推理时行为，配合奖励模型调整防止优势反转；4. 高吞吐RL系统：FP8精度rollout、重叠奖励计算和长度感知调度。

Result: 这些创新形成了一个统一的pipeline，使千亿规模MoE模型的RL训练变得稳定高效。最终模型在内部和公开评估中都表现出色。

Conclusion: 通过解决大规模RL训练中的关键效率问题，成功构建了一个稳定高效的训练框架，使千亿规模MoE推理模型能够实现强性能表现。

Abstract: We present CompassMax-V3-Thinking, a hundred-billion-scale MoE reasoning model trained with a new RL framework built on one principle: each prompt must matter. Scaling RL to this size exposes critical inefficiencies-zero-variance prompts that waste rollouts, unstable importance sampling over long horizons, advantage inversion from standard reward models, and systemic bottlenecks in rollout processing. To overcome these challenges, we introduce several unified innovations: (1) Multi-Stage Zero-Variance Elimination, which filters out non-informative prompts and stabilizes group-based policy optimization (e.g. GRPO) by removing wasted rollouts; (2) ESPO, an entropy-adaptive optimization method that balances token-level and sequence-level importance sampling to maintain stable learning dynamics; (3) a Router Replay strategy that aligns training-time MoE router decisions with inference-time behavior to mitigate train-infer discrepancies, coupled with a reward model adjustment to prevent advantage inversion; (4) a high-throughput RL system with FP8-precision rollouts, overlapped reward computation, and length-aware scheduling to eliminate performance bottlenecks. Together, these contributions form a cohesive pipeline that makes RL on hundred-billion-scale MoE models stable and efficient. The resulting model delivers strong performance across both internal and public evaluations.

</details>


### [196] [RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models](https://arxiv.org/abs/2512.07761)
*Xiqiao Xiong,Ouxiang Li,Zhuo Liu,Moxin Li,Wentao Shi,Fuli Feng,Xiangnan He*

Main category: cs.AI

TL;DR: 该论文提出了一种基于强化学习的多轮越狱攻击方法，通过训练攻击者LLM来从黑盒模型中引出有害内容，相比单轮优化方法显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到越狱攻击的威胁，影响其在现实应用中的安全部署。现有方法通常依赖单轮优化，不足以学习长期攻击策略，因此需要开发更有效的多轮攻击方法。

Method: 将问题形式化为多轮强化学习任务，直接优化最终轮输出的有害性作为结果奖励。提出两种启发式过程奖励：1）控制中间输出的有害性以避免触发黑盒模型的拒绝机制；2）保持中间输出的语义相关性以避免偏离到无关内容。

Result: 在多个基准测试上的实验结果显示，该方法在多个模型上持续提高了攻击成功率，证明了方法的有效性。

Conclusion: 提出的基于强化学习的多轮越狱攻击方法能够有效训练攻击者LLM，通过多轮交互从黑盒模型中引出有害内容，相比传统单轮优化方法具有更好的攻击效果。

Abstract: Large language models are vulnerable to jailbreak attacks, threatening their safe deployment in real-world applications. This paper studies black-box multi-turn jailbreaks, aiming to train attacker LLMs to elicit harmful content from black-box models through a sequence of prompt-output interactions. Existing approaches typically rely on single turn optimization, which is insufficient for learning long-term attack strategies. To bridge this gap, we formulate the problem as a multi-turn reinforcement learning task, directly optimizing the harmfulness of the final-turn output as the outcome reward. To mitigate sparse supervision and promote long-term attack strategies, we propose two heuristic process rewards: (1) controlling the harmfulness of intermediate outputs to prevent triggering the black-box model's rejection mechanisms, and (2) maintaining the semantic relevance of intermediate outputs to avoid drifting into irrelevant content. Experimental results on multiple benchmarks show consistently improved attack success rates across multiple models, highlighting the effectiveness of our approach. The code is available at https://github.com/xxiqiao/RL-MTJail. Warning: This paper contains examples of harmful content.

</details>


### [197] [ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning](https://arxiv.org/abs/2512.07795)
*Nearchos Potamitis,Lars Klein,Akhil Arora*

Main category: cs.AI

TL;DR: ReasonBENCH是首个专门量化大语言模型推理不稳定性的基准测试，通过多轮运行协议提供统计可靠的性能和质量指标，揭示当前推理方法普遍存在的高不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理评估主要报告单次运行准确率，忽略了随机解码带来的内在不确定性，导致无法可靠评估方法的稳定性、可重复性和成本一致性，存在评估盲点。

Method: 提出ReasonBENCH基准测试，包括：1）标准化推理框架、模型和任务的模块化评估库；2）报告质量和成本统计可靠指标的多轮运行协议；3）鼓励方差感知报告的公共排行榜。

Result: 跨多个领域任务发现，绝大多数推理策略和模型表现出高不稳定性。即使平均性能相似的策略，置信区间宽度可能相差四倍，且性能最佳的方法通常成本更高且更不稳定。

Conclusion: 推理不稳定性损害了跨运行的可重复性和报告性能的可靠性。可重复性是可靠LLM推理的关键维度，ReasonBENCH为未来推理方法和不确定性量化技术提供了基础。

Abstract: Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess whether a method's reported performance is stable, reproducible, or cost-consistent. We introduce ReasonBENCH, the first benchmark designed to quantify the underlying instability in LLM reasoning. ReasonBENCH provides (i) a modular evaluation library that standardizes reasoning frameworks, models, and tasks, (ii) a multi-run protocol that reports statistically reliable metrics for both quality and cost, and (iii) a public leaderboard to encourage variance-aware reporting. Across tasks from different domains, we find that the vast majority of reasoning strategies and models exhibit high instability. Notably, even strategies with similar average performance can display confidence intervals up to four times wider, and the top-performing methods often incur higher and less stable costs. Such instability compromises reproducibility across runs and, consequently, the reliability of reported performance. To better understand these dynamics, we further analyze the impact of prompts, model families, and scale on the trade-off between solve rate and stability. Our results highlight reproducibility as a critical dimension for reliable LLM reasoning and provide a foundation for future reasoning methods and uncertainty quantification techniques. ReasonBENCH is publicly available at https://github.com/au-clan/ReasonBench .

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [198] [A self-driving lab for solution-processed electrochromic thin films](https://arxiv.org/abs/2512.05989)
*Selma Dahms,Luca Torresi,Shahbaz Tareq Bandesha,Jan Hansmann,Holger Röhm,Alexander Colsmann,Marco Schott,Pascal Friederich*

Main category: cs.LG

TL;DR: 使用自驱动实验室结合自动化与机器学习加速电致变色涂层的开发，通过贝叶斯优化高效探索处理参数


<details>
  <summary>Details</summary>
Motivation: 溶液处理电致变色材料在节能智能窗户和显示器中具有高潜力，但其性能随材料选择和加工条件变化。电致变色薄膜电极需要光滑无缺陷涂层以获得最佳对比度，而优化旋涂电致变色薄膜层的复杂性给快速开发带来挑战

Method: 使用自驱动实验室将自动化与机器学习相结合，系统结合自动数据采集、图像处理、光谱分析和贝叶斯优化来高效探索处理参数

Result: 该方法不仅提高了通量，还能有针对性地搜索最优处理参数，可以应用于各种溶液处理材料

Conclusion: 自驱动实验室在增强材料发现和工艺优化方面具有巨大潜力，为电致变色涂层开发提供了加速路径

Abstract: Solution-processed electrochromic materials offer high potential for energy-efficient smart windows and displays. Their performance varies with material choice and processing conditions. Electrochromic thin film electrodes require a smooth, defect-free coating for optimal contrast between bleached and colored states. The complexity of optimizing the spin-coated electrochromic thin layer poses challenges for rapid development. This study demonstrates the use of self-driving laboratories to accelerate the development of electrochromic coatings by coupling automation with machine learning. Our system combines automated data acquisition, image processing, spectral analysis, and Bayesian optimization to explore processing parameters efficiently. This approach not only increases throughput but also enables a pointed search for optimal processing parameters. The approach can be applied to various solution-processed materials, highlighting the potential of self-driving labs in enhancing materials discovery and process optimization.

</details>


### [199] [Memory-Amortized Inference: A Topological Unification of Search, Closure, and Structure](https://arxiv.org/abs/2512.05990)
*Xin Li*

Main category: cs.LG

TL;DR: MAI框架将学习和记忆统一为单一几何基质的相变，通过同调奇偶原理区分内容与上下文，将高复杂度搜索转化为低复杂度查找，实现认知效率提升。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习系统将参数静态结构与推理动态流程分离，缺乏生物认知的样本效率和热力学经济性，需要新的理论框架来统一学习和记忆过程。

Method: 提出基于代数拓扑的记忆摊销推理（MAI）框架，引入同调奇偶原理区分偶维同调（稳定内容）和奇维同调（动态上下文），通过拓扑三一变换（搜索→闭合→结构）实现认知过程。

Result: 建立了认知从高复杂度递归搜索（NPSPACE）向低复杂度查找（P）转化的理论机制，通过拓扑循环闭合和Wake-Sleep算法的拓扑推广实现学习和推理的统一。

Conclusion: MAI框架为快速思维（直觉）从慢速思维（推理）的涌现提供了严格解释，并为后图灵架构提供了基于拓扑共振计算的设计蓝图。

Abstract: Contemporary ML separates the static structure of parameters from the dynamic flow of inference, yielding systems that lack the sample efficiency and thermodynamic frugality of biological cognition. In this theoretical work, we propose \textbf{Memory-Amortized Inference (MAI)}, a formal framework rooted in algebraic topology that unifies learning and memory as phase transitions of a single geometric substrate. Central to our theory is the \textbf{Homological Parity Principle}, which posits a fundamental dichotomy: even-dimensional homology ($H_{even}$) physically instantiates stable \textbf{Content} (stable scaffolds or ``what''), while odd-dimensional homology ($H_{odd}$) instantiates dynamic \textbf{Context} (dynamic flows or ``where''). We derive the logical flow of MAI as a topological trinity transformation: \textbf{Search $\to$ Closure $\to$ Structure}. Specifically, we demonstrate that cognition operates by converting high-complexity recursive search (modeled by \textit{Savitch's Theorem} in NPSPACE) into low-complexity lookup (modeled by \textit{Dynamic Programming} in P) via the mechanism of \textbf{Topological Cycle Closure}. We further show that this consolidation process is governed by a topological generalization of the Wake-Sleep algorithm, functioning as a coordinate descent that alternates between optimizing the $H_{odd}$ flow (inference/wake) and condensing persistent cycles into the $H_{even}$ scaffold (learning/sleep). This framework offers a rigorous explanation for the emergence of fast-thinking (intuition) from slow-thinking (reasoning) and provides a blueprint for post-Turing architectures that compute via topological resonance.

</details>


### [200] [ARC-AGI Without Pretraining](https://arxiv.org/abs/2512.06104)
*Isaac Liao,Albert Gu*

Main category: cs.LG

TL;DR: CompressARC是一个仅76K参数、无需预训练的模型，通过最小化描述长度（MDL）在推理时解决ARC-AGI视觉谜题，在极度数据限制下仍能解决20%的评估谜题。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点：反驳LLM时代认为解决ARC-AGI视觉谜题需要大规模预训练能力的观念，探索在极度数据限制下实现智能的替代路径。

Method: 使用仅76K参数的模型，不进行任何预训练，在推理时通过最小化目标谜题的描述长度（MDL）来解决问题。模型仅在单个目标谜题样本上训练（移除最终解决方案信息），不使用ARC-AGI提供的训练集。

Result: 在极度数据限制条件下，CompressARC能够解决20%的评估谜题，表现出深度学习中罕见的极端泛化能力，成功解决了多样化的创造性ARC-AGI谜题。

Conclusion: 最小化描述长度（MDL）是除了传统预训练之外，实现智能的另一种可行途径，展示了在极度数据限制下仍能产生智能的可能性。

Abstract: Conventional wisdom in the age of LLMs dictates that solving IQ-test-like visual puzzles from the ARC-AGI-1 benchmark requires capabilities derived from massive pretraining. To counter this, we introduce CompressARC, a 76K parameter model without any pretraining that solves 20% of evaluation puzzles by minimizing the description length (MDL) of the target puzzle purely during inference time. The MDL endows CompressARC with extreme generalization abilities typically unheard of in deep learning. To our knowledge, CompressARC is the only deep learning method for ARC-AGI where training happens only on a single sample: the target inference puzzle itself, with the final solution information removed. Moreover, CompressARC does not train on the pre-provided ARC-AGI "training set". Under these extremely data-limited conditions, we do not ordinarily expect any puzzles to be solvable at all. Yet CompressARC still solves a diverse distribution of creative ARC-AGI puzzles, suggesting MDL to be an alternative feasible way to produce intelligence, besides conventional pretraining.

</details>


### [201] [A Prescriptive Framework for Determining Optimal Days for Short-Term Traffic Counts](https://arxiv.org/abs/2512.06111)
*Arthur Mukwaya,Nancy Kasamala,Nana Kankam Gyimah,Judith Mwakalonge,Gurcan Comert,Saidi Siuhi,Denis Ruganuza,Mark Ngotonie*

Main category: cs.LG

TL;DR: 本研究提出了一种机器学习框架，用于识别进行短期交通计数的最佳代表日，以提高年度平均日交通量预测精度。该方法在德克萨斯州交通数据上验证，相比传统方法显著降低了误差。


<details>
  <summary>Details</summary>
Motivation: 美国联邦公路管理局要求各州交通部门收集可靠的年度平均日交通量数据，但许多部门难以获得准确数据，尤其是未监测道路的数据。连续计数站虽然准确但成本高昂，难以广泛部署，迫使机构依赖短期交通计数。目前大多数交通部门采用的短期计数方法缺乏优化选择，导致AADT预测精度有限。

Method: 提出机器学习框架，通过迭代选择对AADT估计最具信息量的"最优日"进行短期计数。使用德克萨斯州2022-2023年交通量数据，比较"最优日"方法和反映当前实践的"非最优日"基线。利用连续计数数据模拟24小时短期计数，采用留一法技术生成无偏的代表性日交通特征。

Result: 最优日方法在前5天均优于基线，最佳日（第186天）的误差显著降低：RMSE从11,185.00降至7,871.15，MAE从5,118.57降至3,645.09，MAPE从14.42%降至11.95%，R²从0.9499提升至0.9756。

Conclusion: 该研究为交通部门提供了替代传统短期计数实践的方法，能够改进AADT估计精度，支持公路性能监测系统合规性，并降低全州交通数据收集的运营成本。

Abstract: The Federal Highway Administration (FHWA) mandates that state Departments of Transportation (DOTs) collect reliable Annual Average Daily Traffic (AADT) data. However, many U.S. DOTs struggle to obtain accurate AADT, especially for unmonitored roads. While continuous count (CC) stations offer accurate traffic volume data, their implementation is expensive and difficult to deploy widely, compelling agencies to rely on short-duration traffic counts. This study proposes a machine learning framework, the first to our knowledge, to identify optimal representative days for conducting short count (SC) data collection to improve AADT prediction accuracy. Using 2022 and 2023 traffic volume data from the state of Texas, we compare two scenarios: an 'optimal day' approach that iteratively selects the most informative days for AADT estimation and a 'no optimal day' baseline reflecting current practice by most DOTs. To align with Texas DOT's traffic monitoring program, continuous count data were utilized to simulate the 24 hour short counts. The actual field short counts were used to enhance feature engineering through using a leave-one-out (LOO) technique to generate unbiased representative daily traffic features across similar road segments. Our proposed methodology outperforms the baseline across the top five days, with the best day (Day 186) achieving lower errors (RMSE: 7,871.15, MAE: 3,645.09, MAPE: 11.95%) and higher R^2 (0.9756) than the baseline (RMSE: 11,185.00, MAE: 5,118.57, MAPE: 14.42%, R^2: 0.9499). This research offers DOTs an alternative to conventional short-duration count practices, improving AADT estimation, supporting Highway Performance Monitoring System compliance, and reducing the operational costs of statewide traffic data collection.

</details>


### [202] [Physics-Informed Neural Koopman Machine for Interpretable Longitudinal Personalized Alzheimer's Disease Forecasting](https://arxiv.org/abs/2512.06134)
*Georgi Hrusanov,Duy-Thanh Vu,Duy-Cat Can,Sophie Tascedda,Margaret Ryan,Julien Bodelet,Katarzyna Koscielska,Carsten Magnus,Oliver Y. Chén*

Main category: cs.LG

TL;DR: 提出Neural Koopman Machine (NKM)架构，用于阿尔茨海默病认知衰退的个性化预测，通过融合多模态数据和可解释的注意力机制，在ADNI数据集上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病认知衰退的早期预测对疾病评估和管理至关重要，但现有方法难以在保持可解释性的同时整合多模态数据进行纵向个性化预测。

Method: 提出Neural Koopman Machine (NKM)架构，结合动力系统和注意力机制，使用遗传、神经影像、蛋白质组和人口统计学等多模态数据预测多个认知评分。通过融合分组感知分层注意力机制，将复杂非线性轨迹转化为可解释的线性表示。

Result: 在ADNI数据集上，NKM在预测认知衰退轨迹方面持续优于传统机器学习和深度学习模型。能够同时预测多个认知评分变化，量化不同生物标志物对预测的贡献，并识别与认知恶化最相关的大脑区域。

Conclusion: NKM通过可解释的显式系统，利用过去的多模态数据推进了AD认知衰退的个性化预测，并揭示了AD进展的潜在多模态生物学基础。

Abstract: Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($α$) and biological ($β$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression.

</details>


### [203] [gp2Scale: A Class of Compactly-Supported Non-Stationary Kernels and Distributed Computing for Exact Gaussian Processes on 10 Million Data Points](https://arxiv.org/abs/2512.06143)
*Marcus M. Noack,Mark D. Risser,Hengrui Luo,Vardaan Tekriwal,Ronald J. Pandolfi*

Main category: cs.LG

TL;DR: gp2Scale方法通过利用紧凑支持的非平稳核函数识别协方差矩阵中的稀疏结构，将精确高斯过程扩展到1000万+数据点，无需诱导点或近似方法，同时保持核函数设计的灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有高斯过程扩展方法在计算速度、预测精度和不确定性量化之间存在权衡，因为它们依赖各种近似方法，降低了准确性并限制了核函数和噪声模型设计的灵活性，而当前许多领域正需要表达性强的非平稳核函数。

Method: 提出gp2Scale方法，利用高度灵活、紧凑支持的非平稳核函数识别协方差矩阵中自然出现的稀疏结构，然后利用这种稀疏性进行线性系统求解和对数行列式计算，从而实现精确高斯过程的扩展。

Result: 该方法能够将精确高斯过程扩展到超过1000万个数据点，不依赖诱导点、核插值或基于邻域的近似，在多个真实数据集上展示了优越的近似性能，同时保持对任意GP定制（核设计、噪声和均值函数）的灵活性。

Conclusion: gp2Scale方法通过利用核函数设计中的稀疏性，解决了高斯过程扩展中的计算瓶颈，同时保持了核函数设计的完全灵活性，特别适合现代高斯过程应用中需要高度定制化核函数的情况。

Abstract: Despite a large corpus of recent work on scaling up Gaussian processes, a stubborn trade-off between computational speed, prediction and uncertainty quantification accuracy, and customizability persists. This is because the vast majority of existing methodologies exploit various levels of approximations that lower accuracy and limit the flexibility of kernel and noise-model designs -- an unacceptable drawback at a time when expressive non-stationary kernels are on the rise in many fields. Here, we propose a methodology we term \emph{gp2Scale} that scales exact Gaussian processes to more than 10 million data points without relying on inducing points, kernel interpolation, or neighborhood-based approximations, and instead leveraging the existing capabilities of a GP: its kernel design. Highly flexible, compactly supported, and non-stationary kernels lead to the identification of naturally occurring sparse structure in the covariance matrix, which is then exploited for the calculations of the linear system solution and the log-determinant for training. We demonstrate our method's functionality on several real-world datasets and compare it with state-of-the-art approximation algorithms. Although we show superior approximation performance in many cases, the method's real power lies in its agnosticism toward arbitrary GP customizations -- core kernel design, noise, and mean functions -- and the type of input space, making it optimally suited for modern Gaussian process applications.

</details>


### [204] [Learning Invariant Graph Representations Through Redundant Information](https://arxiv.org/abs/2512.06154)
*Barproda Halder,Pasan Dissanayake,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: 该论文提出了一种基于部分信息分解的冗余引导不变图学习框架，用于解决图数据分布外泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于经典信息论的图表示学习方法难以有效分离虚假成分，导致学习到的表示保留虚假信息，影响分布外泛化能力。需要更精确地识别和处理虚假子图与不变子图之间的冗余信息。

Method: 提出RIG框架：1) 使用部分信息分解识别虚假子图和不变子图；2) 构建多级优化框架，最大化冗余信息同时分离虚假和因果子图；3) 交替估计冗余信息下界并最大化该下界及相关目标。

Result: 在合成和真实世界图数据集上的实验表明，RIG框架在多种分布偏移下具有良好的泛化能力。

Conclusion: 部分信息分解为图表示学习提供了超越经典信息论的新工具，RIG框架通过精确处理冗余信息有效提升了图数据的分布外泛化性能。

Abstract: Learning invariant graph representations for out-of-distribution (OOD) generalization remains challenging because the learned representations often retain spurious components. To address this challenge, this work introduces a new tool from information theory called Partial Information Decomposition (PID) that goes beyond classical information-theoretic measures. We identify limitations in existing approaches for invariant representation learning that solely rely on classical information-theoretic measures, motivating the need to precisely focus on redundant information about the target $Y$ shared between spurious subgraphs $G_s$ and invariant subgraphs $G_c$ obtained via PID. Next, we propose a new multi-level optimization framework that we call -- Redundancy-guided Invariant Graph learning (RIG) -- that maximizes redundant information while isolating spurious and causal subgraphs, enabling OOD generalization under diverse distribution shifts. Our approach relies on alternating between estimating a lower bound of redundant information (which itself requires an optimization) and maximizing it along with additional objectives. Experiments on both synthetic and real-world graph datasets demonstrate the generalization capabilities of our proposed RIG framework.

</details>


### [205] [PMA-Diffusion: A Physics-guided Mask-Aware Diffusion Framework for TSE from Sparse Observations](https://arxiv.org/abs/2512.06183)
*Lindong Liu,Zhixiong Jin,Seongjin Choi*

Main category: cs.LG

TL;DR: PMA-Diffusion：一种物理引导的掩码感知扩散框架，用于从稀疏、不完整的观测数据中重建高速公路速度场，在5%可见度下仍优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 高速公路交通状态信息对智能交通系统至关重要，但现有的环形探测器和探测车辆采集的数据通常过于稀疏和嘈杂，无法捕捉交通流的详细动态。

Method: 提出PMA-Diffusion框架，使用两种掩码感知训练策略（单掩码和双掩码）直接在稀疏观测的速度场上训练扩散先验。在推理阶段，物理引导的后验采样器交替进行反向扩散更新、观测投影和基于自适应各向异性平滑的物理引导投影。

Result: 在I-24 MOTION数据集上测试，即使在5%可见度的严重稀疏情况下，PMA-Diffusion在三个重建误差指标上都优于其他基线方法。使用稀疏观测训练的PMA-Diffusion性能接近基于完整观测训练的基线模型。

Conclusion: 将掩码感知扩散先验与物理引导后验采样器相结合，为实际传感稀疏条件下的交通状态估计提供了可靠且灵活的解决方案。

Abstract: High-resolution highway traffic state information is essential for Intelligent Transportation Systems, but typical traffic data acquired from loop detectors and probe vehicles are often too sparse and noisy to capture the detailed dynamics of traffic flow. We propose PMA-Diffusion, a physics-guided mask-aware diffusion framework that reconstructs unobserved highway speed fields from sparse, incomplete observations. Our approach trains a diffusion prior directly on sparsely observed speed fields using two mask-aware training strategies: Single-Mask and Double-Mask. At the inference phase, the physics-guided posterior sampler alternates reverse-diffusion updates, observation projection, and physics-guided projection based on adaptive anisotropic smoothing to reconstruct the missing speed fields. The proposed framework is tested on the I-24 MOTION dataset with varying visibility ratios. Even under severe sparsity, with only 5% visibility, PMA-Diffusion outperforms other baselines across three reconstruction error metrics. Furthermore, PMA-diffusion trained with sparse observation nearly matches the performance of the baseline model trained on fully observed speed fields. The results indicate that combining mask-aware diffusion priors with a physics-guided posterior sampler provides a reliable and flexible solution for traffic state estimation under realistic sensing sparsity.

</details>


### [206] [How Should We Evaluate Data Deletion in Graph-Based ANN Indexes?](https://arxiv.org/abs/2512.06200)
*Tomohiro Yamashita,Daichi Amagata,Yusuke Matsui*

Main category: cs.LG

TL;DR: 该研究提出了一个评估动态近似最近邻搜索（ANNS）中数据删除效率的实验框架和综合评估指标，将图基ANNS的数据删除方法分为三类并形式化，最后应用于HNSW方法并提出动态选择删除方法的Deletion Control技术。


<details>
  <summary>Details</summary>
Motivation: 随着检索增强生成等应用的发展，动态数据的ANNS算法需求日益增长，但数据删除在ANNS中的综合评估方法尚未建立，需要系统化的评估框架来指导实践应用。

Method: 1. 提出实验框架和综合评估指标来评估ANNS索引的数据删除效率；2. 将图基ANNS的数据删除方法分为三类并数学形式化；3. 在准确性、查询速度等指标上评估性能；4. 将框架应用于HNSW方法分析数据删除效果；5. 提出Deletion Control方法，在所需搜索精度下动态选择适当的删除方法。

Result: 建立了ANNS数据删除的综合评估框架，对图基ANNS的删除方法进行了系统分类和形式化，通过HNSW的实际应用验证了框架有效性，并开发了能够根据精度需求动态选择删除方法的Deletion Control技术。

Conclusion: 该研究填补了ANNS数据删除评估方法的空白，为动态ANNS系统的设计和优化提供了系统化工具，Deletion Control方法能够有效平衡删除效率和搜索精度，对实际应用具有重要指导意义。

Abstract: Approximate Nearest Neighbor Search (ANNS) has recently gained significant attention due to its many applications, such as Retrieval-Augmented Generation. Such applications require ANNS algorithms that support dynamic data, so the ANNS problem on dynamic data has attracted considerable interest. However, a comprehensive evaluation methodology for data deletion in ANNS has yet to be established. This study proposes an experimental framework and comprehensive evaluation metrics to assess the efficiency of data deletion for ANNS indexes under practical use cases. Specifically, we categorize data deletion methods in graph-based ANNS into three approaches and formalize them mathematically. The performance is assessed in terms of accuracy, query speed, and other relevant metrics. Finally, we apply the proposed evaluation framework to Hierarchical Navigable Small World, one of the state-of-the-art ANNS methods, to analyze the effects of data deletion, and propose Deletion Control, a method which dynamically selects the appropriate deletion method under a required search accuracy.

</details>


### [207] [K2-V2: A 360-Open, Reasoning-Enhanced LLM](https://arxiv.org/abs/2512.06201)
*K2 Team,Zhengzhong Liu,Liping Tang,Linghao Jin,Haonan Li,Nikhil Ranjan,Desai Fan,Shaurya Rohatgi,Richard Fan,Omkar Pangarkar,Huijuan Wang,Zhoujun Cheng,Suqi Sun,Seungwook Han,Bowen Tan,Gurpreet Gosal,Xudong Han,Varad Pimpalkhute,Shibo Hao,Ming Shan Hee,Joel Hestness,Haolong Jia,Liqun Ma,Aaryamonvikram Singh,Daria Soboleva,Natalia Vassilieva,Renxi Wang,Yingquan Wu,Yuekai Sun,Taylor Killian,Alexander Moreno,John Maggs,Hector Ren,Guowei He,Hongyi Wang,Xuezhe Ma,Yuqi Wang,Mikhail Yurochkin,Eric P. Xing*

Main category: cs.LG

TL;DR: K2-V2是一个从头开始构建的360度开放大语言模型，专注于推理能力，在72B规模中表现优异，超越Qwen2.5-72B并接近Qwen3-235B的性能。


<details>
  <summary>Details</summary>
Motivation: 构建一个专门针对推理任务优化的开放基础模型，为复杂推理任务提供强大的基础，同时支持对话、知识检索等通用功能，并推动开源社区的发展。

Method: 从头开始训练，在训练过程中主动注入领域知识、推理能力、长上下文和工具使用能力；采用简单的监督微调建立强基线；发布完整的训练历史和数据组成。

Result: K2-V2成为最强的完全开放模型，在相同规模类别中与领先的开源权重模型竞争，超越Qwen2.5-72B并接近Qwen3-235B的性能。

Conclusion: K2-V2为复杂推理任务提供了强大的基础模型，通过发布完整的训练历史和数据，最大化持续训练的效果，为社区提供了以推理为中心的能力基础。

Abstract: We introduce K2-V2, a 360-open LLM built from scratch as a superior base for reasoning adaptation, in addition to functions such as conversation and knowledge retrieval from general LLMs. It stands as the strongest fully open model, rivals open-weight leaders in its size class, outperforms Qwen2.5-72B and approaches the performance of Qwen3-235B. We actively infuse domain knowledge, reasoning, long-context, and tool use throughout the training process. This explicitly prepares the model for complex reasoning tasks. We demonstrate this potential using simple supervised fine-tuning, establishing a strong baseline that indicates significant headroom for advanced alignment. By releasing the full training history and data composition, we maximize the effectiveness of continuous training, a key open source production scenario. We release the model weights and signature LLM360 artifacts, such as complete training data, to empower the community with a capable, reasoning-centric foundation.

</details>


### [208] [Estimating Black Carbon Concentration from Urban Traffic Using Vision-Based Machine Learning](https://arxiv.org/abs/2512.06649)
*Camellia Zakaria,Aryan Sadeghi,Weaam Jaafar,Junshi Xu,Alex Mariakakis,Marianne Hatzopoulou*

Main category: cs.LG

TL;DR: 利用交通监控视频和天气数据，通过机器学习模型估计街道级黑碳浓度，填补交通监测与环境影响之间的数据鸿沟。


<details>
  <summary>Details</summary>
Motivation: 城市黑碳排放主要来自交通，但监测成本高、数据稀缺，而交通监控系统广泛部署，存在交通状况与环境影响数据不平衡的问题。

Method: 从交通视频中提取车辆行为和状况的视觉信息，结合天气数据，构建机器学习模型来估计街道级黑碳浓度。

Result: 模型取得了R平方值0.72和RMSE 129.42 ng/m³的良好性能，能够准确估计街道级黑碳浓度。

Conclusion: 该研究利用现有城市基础设施资源，为地方市政层面的污染减排、城市规划、公共卫生和环境正义提供了可操作的数据支持。

Abstract: Black carbon (BC) emissions in urban areas are primarily driven by traffic, with hotspots near major roads disproportionately affecting marginalized communities. Because BC monitoring is typically performed using costly and specialized instruments. there is little to no available data on BC from local traffic sources that could help inform policy interventions targeting local factors. By contrast, traffic monitoring systems are widely deployed in cities around the world, highlighting the imbalance between what we know about traffic conditions and what do not know about their environmental consequences. To bridge this gap, we propose a machine learning-driven system that extracts visual information from traffic video to capture vehicles behaviors and conditions. Combining these features with weather data, our model estimates BC at street level, achieving an R-squared value of 0.72 and RMSE of 129.42 ng/m3 (nanogram per cubic meter). From a sustainability perspective, this work leverages resources already supported by urban infrastructure and established modeling techniques to generate information relevant to traffic emission. Obtaining BC concentration data provides actionable insights to support pollution reduction, urban planning, public health, and environmental justice at the local municipal level.

</details>


### [209] [Interpretive Efficiency: Information-Geometric Foundations of Data Usefulness](https://arxiv.org/abs/2512.06341)
*Ronald Katende*

Main category: cs.LG

TL;DR: 提出"解释效率"指标，量化解释性表示传递任务相关信息的能力，基于五条公理，与互信息相关，具有理论保证和实际应用价值


<details>
  <summary>Details</summary>
Motivation: 现有可解释性指标很少能有效量化数据对解释性表示的支持程度，需要一种能够测量解释通道传递任务相关信息效率的指标

Method: 提出解释效率这一归一化、任务感知的函数，基于五条公理（有界性、Blackwell式单调性、数据处理稳定性、容许不变性、渐近一致性），与互信息建立联系，推导局部Fisher几何展开，使用标准经验过程工具建立渐近和有限样本估计保证

Result: 在受控图像和信号任务实验中，该指标能恢复理论排序，揭示被准确率掩盖的表示冗余，并与鲁棒性相关，成为实用的理论支持表示设计诊断工具

Conclusion: 解释效率是一个实用且有理论支持的表示设计诊断指标，能够量化解释性表示传递任务相关信息的能力，为可信机器学习提供新的评估工具

Abstract: Interpretability is central to trustworthy machine learning, yet existing metrics rarely quantify how effectively data support an interpretive representation. We propose Interpretive Efficiency, a normalized, task-aware functional that measures the fraction of task-relevant information transmitted through an interpretive channel. The definition is grounded in five axioms ensuring boundedness, Blackwell-style monotonicity, data-processing stability, admissible invariance, and asymptotic consistency. We relate the functional to mutual information and derive a local Fisher-geometric expansion, then establish asymptotic and finite-sample estimation guarantees using standard empirical-process tools. Experiments on controlled image and signal tasks demonstrate that the measure recovers theoretical orderings, exposes representational redundancy masked by accuracy, and correlates with robustness, making it a practical, theory-backed diagnostic for representation design.

</details>


### [210] [A Unifying Human-Centered AI Fairness Framework](https://arxiv.org/abs/2512.06944)
*Munshi Mahbubur Rahman,Shimei Pan,James R. Foulds*

Main category: cs.LG

TL;DR: 提出统一的人类中心公平框架，涵盖8种公平指标，帮助利益相关者根据价值观和情境选择公平干预措施，并在四个真实数据集上展示权衡分析。


<details>
  <summary>Details</summary>
Motivation: AI在关键社会领域应用增加引发公平性担忧，但现有方法在多种公平概念与预测准确性之间的权衡存在挑战，阻碍公平AI系统的实际部署。

Method: 引入统一的人类中心公平框架，系统覆盖8种公平指标，结合个体与群体公平、边际内与交叉假设、结果导向与机会平等视角，采用一致易懂的公式化表达，支持利益相关者分配权重。

Result: 在UCI Adult收入预测、COMPAS犯罪再犯、德国信用风险评估和MEPS医疗利用四个真实数据集上应用，展示调整权重如何揭示不同公平指标间的微妙权衡。

Conclusion: 通过司法决策和医疗保健案例研究，证明该框架能够为公平AI系统的实际和价值敏感部署提供指导，促进多利益相关者妥协。

Abstract: The increasing use of Artificial Intelligence (AI) in critical societal domains has amplified concerns about fairness, particularly regarding unequal treatment across sensitive attributes such as race, gender, and socioeconomic status. While there has been substantial work on ensuring AI fairness, navigating trade-offs between competing notions of fairness as well as predictive accuracy remains challenging, creating barriers to the practical deployment of fair AI systems. To address this, we introduce a unifying human-centered fairness framework that systematically covers eight distinct fairness metrics, formed by combining individual and group fairness, infra-marginal and intersectional assumptions, and outcome-based and equality-of-opportunity (EOO) perspectives. This structure allows stakeholders to align fairness interventions with their values and contextual considerations. The framework uses a consistent and easy-to-understand formulation for all metrics to reduce the learning curve for non-experts. Rather than privileging a single fairness notion, the framework enables stakeholders to assign weights across multiple fairness objectives, reflecting their priorities and facilitating multi-stakeholder compromises. We apply this approach to four real-world datasets: the UCI Adult census dataset for income prediction, the COMPAS dataset for criminal recidivism, the German Credit dataset for credit risk assessment, and the MEPS dataset for healthcare utilization. We show that adjusting weights reveals nuanced trade-offs between different fairness metrics. Finally, through case studies in judicial decision-making and healthcare, we demonstrate how the framework can inform practical and value-sensitive deployment of fair AI systems.

</details>


### [211] [Quantization Blindspots: How Model Compression Breaks Backdoor Defenses](https://arxiv.org/abs/2512.06243)
*Rohan Pandey,Eric Ye*

Main category: cs.LG

TL;DR: 量化（INT8/INT4）使现有后门防御失效，攻击成功率仍高于99%，暴露了防御评估与模型实际部署之间的不匹配


<details>
  <summary>Details</summary>
Motivation: 研究现有后门防御在标准量化流程下的表现，因为实际部署中模型通常会被量化以减少内存和延迟，而现有防御主要在FP32模型上评估

Method: 对5种代表性后门防御进行系统实证研究，在3种精度设置（FP32、INT8动态、INT4模拟）和2个标准视觉基准上使用BadNet攻击进行测试

Result: INT8量化将所有防御的检测率降至0%，攻击成功率仍高于99%；INT4量化显示数据集依赖性，Neural Cleanse在GTSRB上有效但在CIFAR-10上失败，攻击成功率仍高于90%

Conclusion: 量化鲁棒性应成为未来后门防御评估和设计的必要维度，需要解决防御评估（FP32）与模型实际部署（量化形式）之间的不匹配问题

Abstract: Backdoor attacks embed input-dependent malicious behavior into neural networks while preserving high clean accuracy, making them a persistent threat for deployed ML systems. At the same time, real-world deployments almost never serve full-precision models: post-training quantization to INT8 or lower precision is now standard practice for reducing memory and latency. This work asks a simple question: how do existing backdoor defenses behave under standard quantization pipelines? We conduct a systematic empirical study of five representative defenses across three precision settings (FP32, INT8 dynamic, INT4 simulated) and two standard vision benchmarks using a canonical BadNet attack. We observe that INT8 quantization reduces the detection rate of all evaluated defenses to 0% while leaving attack success rates above 99%. For INT4, we find a pronounced dataset dependence: Neural Cleanse remains effective on GTSRB but fails on CIFAR-10, even though backdoors continue to survive quantization with attack success rates above 90%. Our results expose a mismatch between how defenses are commonly evaluated (on FP32 models) and how models are actually deployed (in quantized form), and they highlight quantization robustness as a necessary axis in future evaluations and designs of backdoor defenses.

</details>


### [212] [Auto-exploration for online reinforcement learning](https://arxiv.org/abs/2512.06244)
*Caleb Ju,Guanghui Lan*

Main category: cs.LG

TL;DR: 提出具有自动探索功能的强化学习方法，无需先验知识或算法相关参数，在表格和线性函数逼近两种设置下实现O(ε⁻²)样本复杂度


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法需要假设充分探索状态和动作空间，这导致算法不可实现且性能次优。需要解决探索-利用困境，开发无需先验知识、参数自由的自动探索方法。

Method: 提出两类具有自动探索功能的方法：表格设置版本和线性函数逼近版本。采用动态混合时间、折扣状态分布采样、鲁棒梯度估计器和优势差距函数等新算法创新。

Result: 在存在探索最优策略的算法独立假设下，两种方法都能达到O(ε⁻²)样本复杂度来解决ε误差问题。复杂度不包含先前工作中可能任意大的算法相关参数。

Conclusion: 提出的自动探索方法解决了强化学习中的探索-利用困境，实现了参数自由、易于实现且具有最优样本复杂度的算法，无需估计未知参数或依赖先验知识。

Abstract: The exploration-exploitation dilemma in reinforcement learning (RL) is a fundamental challenge to efficient RL algorithms. Existing algorithms for finite state and action discounted RL problems address this by assuming sufficient exploration over both state and action spaces. However, this yields non-implementable algorithms and sub-optimal performance. To resolve these limitations, we introduce a new class of methods with auto-exploration, or methods that automatically explore both state and action spaces in a parameter-free way, i.e.,~without a priori knowledge of problem-dependent parameters. We present two variants: one for the tabular setting and one for linear function approximation. Under algorithm-independent assumptions on the existence of an exploring optimal policy, both methods attain $O(ε^{-2})$ sample complexity to solve to $ε$ error. Crucially, these complexities are novel since they are void of algorithm-dependent parameters seen in prior works, which may be arbitrarily large. The methods are also simple to implement because they are parameter-free and do not directly estimate the unknown parameters. These feats are achieved by new algorithmic innovations for RL, including a dynamic mixing time, a discounted state distribution for sampling, a simple robust gradient estimator, and a recent advantage gap function to certify convergence.

</details>


### [213] [Learning Without Time-Based Embodiment Resets in Soft-Actor Critic](https://arxiv.org/abs/2512.06252)
*Homayoon Farrahi,A. Rupam Mahmood*

Main category: cs.LG

TL;DR: 本文研究了在强化学习中不使用环境重置和回合终止的学习挑战，提出了继续版SAC算法，并探索了在无实体重置情况下的探索问题解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习任务通常使用环境重置、回合终止等辅助组件来加速学习，但这些设置在实际应用中不自然且可能阻碍长期性能。本文旨在探索在不使用回合终止和机器人实体重置的情况下进行学习的挑战。

Method: 提出了继续版Soft Actor-Critic (SAC)算法，通过简单修改现有任务的奖励函数实现。在无实体重置的情况下，通过增加策略的熵来改善状态空间探索，当性能变差或停滞时增加策略熵作为有效干预措施。

Result: 继续版SAC在性能上可以达到或优于回合版SAC，同时减少对折扣率γ值的敏感性。在无实体重置的情况下，发现实体重置有助于SAC算法的状态空间探索，移除重置会导致探索不足和学习失败或显著变慢。增加策略熵能有效恢复因不使用实体重置而损失的性能。

Conclusion: 本文展示了在不使用传统任务辅助组件的情况下进行强化学习的可行性，提出了继续版SAC算法和通过增加策略熵来改善探索的方法，为在更自然、连续的环境中部署强化学习算法提供了实用解决方案。

Abstract: When creating new reinforcement learning tasks, practitioners often accelerate the learning process by incorporating into the task several accessory components, such as breaking the environment interaction into independent episodes and frequently resetting the environment. Although they can enable the learning of complex intelligent behaviors, such task accessories can result in unnatural task setups and hinder long-term performance in the real world. In this work, we explore the challenges of learning without episode terminations and robot embodiment resets using the Soft Actor-Critic (SAC) algorithm. To learn without terminations, we present a continuing version of the SAC algorithm and show that, with simple modifications to the reward functions of existing tasks, continuing SAC can perform as well as or better than episodic SAC while reducing the sensitivity of performance to the value of the discount rate $γ$. On a modified Gym Reacher task, we investigate possible explanations for the failure of continuing SAC when learning without embodiment resets. Our results suggest that embodiment resets help with exploration of the state space in the SAC algorithm, and removing embodiment resets can lead to poor exploration of the state space and failure of or significantly slower learning. Finally, on additional simulated tasks and a real-robot vision task, we show that increasing the entropy of the policy when performance trends worse or remains static is an effective intervention for recovering the performance lost due to not using embodiment resets.

</details>


### [214] [Importance-aware Topic Modeling for Discovering Public Transit Risk from Noisy Social Media](https://arxiv.org/abs/2512.06293)
*Fatima Ashraf,Muhammad Ayub Sabir,Jiaxin Deng,Junbiao Pang,Haitao Yu*

Main category: cs.LG

TL;DR: 该论文提出了一种新的主题建模方法PDF，通过联合建模语言交互和用户影响力，从稀疏的社交媒体数据中检测城市交通服务风险。


<details>
  <summary>Details</summary>
Motivation: 城市交通机构使用社交媒体监控服务风险（如拥挤、延误、安全事件），但相关信号稀疏、简短，容易被日常讨论淹没，需要更有效的检测方法。

Method: 构建影响力加权的关键词共现图，提出泊松反卷积分解(PDF)模型，将图分解为低秩主题结构和主题局部残差交互，使用去相关正则化促进主题区分，通过一致性驱动的扫描选择主题数量。

Result: 在大规模社交数据流上，该模型实现了最先进的主题一致性和强多样性，优于现有基线方法。

Conclusion: 提出的PDF框架能有效从稀疏社交媒体数据中提取可解释的城市交通风险主题，为交通机构提供实用的监控工具。

Abstract: Urban transit agencies increasingly turn to social media to monitor emerging service risks such as crowding, delays, and safety incidents, yet the signals of concern are sparse, short, and easily drowned by routine chatter. We address this challenge by jointly modeling linguistic interactions and user influence. First, we construct an influence-weighted keyword co-occurrence graph from cleaned posts so that socially impactful posts contributes proportionally to the underlying evidence. The core of our framework is a Poisson Deconvolution Factorization (PDF) that decomposes this graph into a low-rank topical structure and topic-localized residual interactions, producing an interpretable topic--keyword basis together with topic importance scores. A decorrelation regularizer \emph{promotes} distinct topics, and a lightweight optimization procedure ensures stable convergence under nonnegativity and normalization constraints. Finally, the number of topics is selected through a coherence-driven sweep that evaluates the quality and distinctness of the learned topics. On large-scale social streams, the proposed model achieves state-of-the-art topic coherence and strong diversity compared with leading baselines. The code and dataset are publicly available at https://github.com/pangjunbiao/Topic-Modeling_ITS.git

</details>


### [215] [Optimizing Optimizers for Fast Gradient-Based Learning](https://arxiv.org/abs/2512.06370)
*Jaerin Lee,Kyoung Mu Lee*

Main category: cs.LG

TL;DR: 提出基于贪婪原则的优化器自动设计理论框架，将优化器设计问题转化为最大化损失瞬时减少的凸优化问题，能够自动推导出最优优化器及其超参数。


<details>
  <summary>Details</summary>
Motivation: 为梯度学习中的优化器自动设计建立理论基础，解决传统优化器设计依赖经验和手动调参的问题，实现系统化的优化器设计和超参数调整。

Method: 基于贪婪原则，将优化器设计问题形式化为最大化损失瞬时减少的优化问题。将优化器视为将梯度信号映射为参数运动的函数，将问题简化为在优化器空间上的凸优化问题。在不同约束条件下求解这些凸优化问题。

Result: 该方法不仅能够以闭式解的形式恢复多种流行优化器，还能自动推导出针对具体问题的最优超参数。实现了根据训练过程中收集的梯度统计信息系统化设计优化器及其超参数，并支持动态优化。

Conclusion: 建立了优化器自动设计的理论框架，实现了"优化的优化"，能够系统化地设计和调整优化器，为梯度学习中的优化器设计提供了理论基础和实用方法。

Abstract: We lay the theoretical foundation for automating optimizer design in gradient-based learning. Based on the greedy principle, we formulate the problem of designing optimizers as maximizing the instantaneous decrease in loss. By treating an optimizer as a function that translates loss gradient signals into parameter motions, the problem reduces to a family of convex optimization problems over the space of optimizers. Solving these problems under various constraints not only recovers a wide range of popular optimizers as closed-form solutions, but also produces the optimal hyperparameters of these optimizers with respect to the problems at hand. This enables a systematic approach to design optimizers and tune their hyperparameters according to the gradient statistics that are collected during the training process. Furthermore, this optimization of optimization can be performed dynamically during training.

</details>


### [216] [RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs](https://arxiv.org/abs/2512.06392)
*Runlong Zhou,Lefan Zhang,Shang-Chen Wu,Kelvin Zou,Hanzhi Zhou,Ke Ye,Yihao Feng,Dong Yin,Alex Guillen Garcia,Dmytro Babych,Rohit Chatterjee,Matthew Hopkins,Xiang Kong,Chang Lan,Lezhi Li,Yiping Ma,Daniele Molinari,Senyu Tong,Yanchao Sun,Thomas Voice,Jianyu Wang,Chong Wang,Simon Wang,Floris Weers,Yechen Xu,Guolin Yin,Muyang Yu,Yi Zhang,Zheng Zhou,Danyang Zhuo,Ruoming Pang,Cheng Leong*

Main category: cs.LG

TL;DR: RLAX是一个在TPU上可扩展的强化学习框架，采用参数服务器架构，通过系统优化和数据集管理技术，显著提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习已成为提升大语言模型推理能力的主流方法，但需要可扩展且能处理训练中断的框架来支持大规模训练。

Method: 开发RLAX框架，采用参数服务器架构：主训练器定期推送模型权重到参数服务器，推理工作器拉取最新权重生成新数据。引入系统技术支持可扩展和可中断的RL训练，并设计新的数据集管理和对齐技术。

Result: 大规模评估显示，RLAX在1024个v5p TPU上仅用12小时48分钟就将QwQ-32B模型的pass@8准确率提升了12.8%，同时在训练中断时保持鲁棒性。

Conclusion: RLAX是一个高效、可扩展的强化学习框架，能够显著加速大语言模型的训练收敛并提升模型质量，同时具备处理训练中断的鲁棒性。

Abstract: Reinforcement learning (RL) has emerged as the de-facto paradigm for improving the reasoning capabilities of large language models (LLMs). We have developed RLAX, a scalable RL framework on TPUs. RLAX employs a parameter-server architecture. A master trainer periodically pushes updated model weights to the parameter server while a fleet of inference workers pull the latest weights and generates new rollouts. We introduce a suite of system techniques to enable scalable and preemptible RL for a diverse set of state-of-art RL algorithms. To accelerate convergence and improve model quality, we have devised new dataset curation and alignment techniques. Large-scale evaluations show that RLAX improves QwQ-32B's pass@8 accuracy by 12.8% in just 12 hours 48 minutes on 1024 v5p TPUs, while remaining robust to preemptions during training.

</details>


### [217] [Hankel-FNO: Fast Underwater Acoustic Charting Via Physics-Encoded Fourier Neural Operator](https://arxiv.org/abs/2512.06417)
*Yifan Sun,Lei Cheng,Jianlong Li,Peter Gerstoft*

Main category: cs.LG

TL;DR: Hankel-FNO是一种基于傅里叶神经算子的高效水下声学制图模型，结合声传播知识和地形数据，在保持高计算速度的同时实现高精度，优于传统数值求解器和数据驱动方法。


<details>
  <summary>Details</summary>
Motivation: 传统水下声学制图方法依赖计算昂贵的数值求解器，不适合大规模或实时应用；现有的深度学习替代模型存在固定分辨率限制或依赖显式偏微分方程公式等问题，限制了其在不同环境中的适用性和泛化能力。

Method: 提出Hankel-FNO模型，基于傅里叶神经算子框架，结合声传播知识和地形数据，实现高效准确的水下声学制图。

Result: Hankel-FNO在速度上优于传统求解器，在精度上超越数据驱动替代方法，尤其在长距离预测中表现突出；模型对多样化环境和声源设置具有良好适应性，仅需少量微调。

Conclusion: Hankel-FNO为水下声学制图提供了一种高效准确的解决方案，能够满足下游任务如环境感知传感器部署优化和自主车辆路径规划的需求。

Abstract: Fast and accurate underwater acoustic charting is crucial for downstream tasks such as environment-aware sensor placement optimization and autonomous vehicle path planning. Conventional methods rely on computationally expensive while accurate numerical solvers, which are not scalable for large-scale or real-time applications. Although deep learning-based surrogate models can accelerate these computations, they often suffer from limitations such as fixed-resolution constraints or dependence on explicit partial differential equation formulations. These issues hinder their applicability and generalization across diverse environments. We propose Hankel-FNO, a Fourier Neural Operator (FNO)-based model for efficient and accurate acoustic charting. By incorporating sound propagation knowledge and bathymetry, our method has high accuracy while maintaining high computational speed. Results demonstrate that Hankel-FNO outperforms traditional solvers in speed and surpasses data-driven alternatives in accuracy, especially in long-range predictions. Experiments show the model's adaptability to diverse environments and sound source settings with minimal fine-tuning.

</details>


### [218] [BitStopper: An Efficient Transformer Attention Accelerator via Stage-fusion and Early Termination](https://arxiv.org/abs/2512.06457)
*Huizheng Wang,Hongbin Wang,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.LG

TL;DR: BitStopper是一种针对注意力机制中动态稀疏性的算法-架构协同设计，通过比特级处理、预测阶段融合和自适应令牌选择，显著提升了Transformer加速器的性能和能效。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的大型语言模型存在二次计算成本问题，动态稀疏注意力虽然能缓解但受限于预测阶段开销和内存流量，硬件效率不高。

Method: 提出BitStopper：1) 比特串行使能阶段融合机制，重用内存访问并合并预测与执行阶段；2) 轻量自适应令牌选择策略；3) 比特级异步处理策略；4) 精心设计的硬件架构。

Result: 相比最先进的Transformer加速器，BitStopper在Sanger上实现2.03倍加速，SOFA上实现1.89倍加速，能效分别提升2.4倍和2.1倍。

Conclusion: BitStopper通过消除预测阶段开销、减少内存流量和提升计算利用率，为动态稀疏注意力提供了高效的算法-架构协同解决方案。

Abstract: Attention-based large language models (LLMs) have transformed modern AI applications, but the quadratic cost of self-attention imposes significant compute and memory overhead. Dynamic sparsity (DS) attention mitigates this, yet its hardware efficiency is limited by the added prediction stage and the heavy memory traffic it entails. To address these limitations, this paper proposes BitStopper, a fine-grained algorithm-architecture co-design that operates without a sparsity predictor. First, a bit-serial enable stage fusion (BESF) mechanism is proposed to reuse and minimize the memory access by progressively terminating trivial tokens and merging the prediction stage into the execution stage. Second, a lightweight and adaptive token selection (LATS) strategy is developed to work in concert with the bit-level sparsity speculation. Third, a bit-level asynchronous processing (BAP) strategy is employed to improve compute utilization during the on-demand bit-grained memory fetching. Finally, an elaborate architecture is designed to translate the theoretical complexity reduction into practical performance improvement. Extensive evaluations demonstrate that, compared to state-of-the-art (SOTA) Transformer accelerators, BitStopper achieves 2.03x and 1.89x speedups over Sanger and SOFA, respectively, while delivering 2.4x and 2.1x improvements in energy efficiency.

</details>


### [219] [Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control](https://arxiv.org/abs/2512.06471)
*Nathan P. Lawrence,Ali Mesbah*

Main category: cs.LG

TL;DR: 本文分析了基于最优控制的目标条件强化学习，推导了传统二次型目标与目标条件奖励之间的最优性差距，并探讨了其在部分可观测马尔可夫决策过程中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究目标条件强化学习与传统最优控制方法之间的关系，解释为什么传统"密集"奖励有时会失败，而目标条件RL却能成功。

Method: 基于最优控制理论分析目标条件RL，推导传统二次型目标与目标条件奖励之间的最优性差距；将状态估计与概率奖励联系起来，应用于部分可观测马尔可夫决策过程和双重控制问题。

Result: 阐明了目标条件RL的成功原因，证明了目标条件策略在非线性和不确定环境中的优势，并通过RL和预测控制技术进行了验证。

Conclusion: 目标条件RL与最优控制理论有深刻联系，特别适合处理部分可观测环境和双重控制问题，在复杂不确定环境中具有显著优势。

Abstract: Goal-conditioned reinforcement learning (RL) concerns the problem of training an agent to maximize the probability of reaching target goal states. This paper presents an analysis of the goal-conditioned setting based on optimal control. In particular, we derive an optimality gap between more classical, often quadratic, objectives and the goal-conditioned reward, elucidating the success of goal-conditioned RL and why classical ``dense'' rewards can falter. We then consider the partially observed Markov decision setting and connect state estimation to our probabilistic reward, further making the goal-conditioned reward well suited to dual control problems. The advantages of goal-conditioned policies are validated on nonlinear and uncertain environments using both RL and predictive control techniques.

</details>


### [220] [Optimizing LLMs Using Quantization for Mobile Execution](https://arxiv.org/abs/2512.06490)
*Agatsya Yadav,Renta Chintala Bhargavi*

Main category: cs.LG

TL;DR: 该论文研究使用4位后训练量化技术压缩大语言模型，使其能够在移动设备上运行，成功将Llama 3.2 3B模型压缩68.66%并在Android设备上部署。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然功能强大，但其庞大的规模和计算需求阻碍了在资源受限的移动设备上的部署。需要找到一种方法来压缩模型，使其能够在移动环境中高效运行。

Method: 使用BitsAndBytes库和Hugging Face Transformers框架对Meta的Llama 3.2 3B模型进行4位后训练量化，然后将量化后的模型转换为GGUF格式，最后在Android设备上使用Termux环境和Ollama框架进行部署和推理。

Result: 通过4位量化实现了68.66%的模型大小缩减，量化后的模型能够在Android设备上成功执行推理任务，证明了在移动设备上运行量化大语言模型的可行性。

Conclusion: 4位后训练量化结合GGUF等移动优化格式，为大语言模型在移动设备上的部署提供了实用途径，在模型大小和性能之间取得了良好平衡。

Abstract: Large Language Models (LLMs) offer powerful capabilities, but their significant size and computational requirements hinder deployment on resource-constrained mobile devices. This paper investigates Post-Training Quantization (PTQ) for compressing LLMs for mobile execution. We apply 4-bit PTQ using the BitsAndBytes library with the Hugging Face Transformers framework to Meta's Llama 3.2 3B model. The quantized model is converted to GGUF format using llama.cpp tools for optimized mobile inference. The PTQ workflow achieves a 68.66% reduction in model size through 4-bit quantization, enabling the Llama 3.2 3B model to run efficiently on an Android device. Qualitative validation shows that the 4-bit quantized model can perform inference tasks successfully. We demonstrate the feasibility of running the quantized GGUF model on an Android device using the Termux environment and the Ollama framework. PTQ, especially at 4-bit precision combined with mobile-optimized formats like GGUF, provides a practical pathway for deploying capable LLMs on mobile devices, balancing model size and performance.

</details>


### [221] [Diagnosis-based mortality prediction for intensive care unit patients via transfer learning](https://arxiv.org/abs/2512.06511)
*Mengqi Xu,Subha Maity,Joel Dubin*

Main category: cs.LG

TL;DR: 该研究评估了迁移学习在ICU诊断特异性死亡率预测中的应用，发现迁移学习模型优于仅使用诊断特异性数据或APACHE IVa评分的模型，且校准性更好。


<details>
  <summary>Details</summary>
Motivation: ICU中危重病的病因在不同诊断间差异很大，但现有的预测模型未能系统性地考虑诊断异质性，存在研究空白。

Method: 使用eICU协作研究数据库，评估基于GLM和XGBoost的迁移学习方法用于诊断特异性死亡率预测，并与仅使用诊断特异性数据、APACHE IVa评分以及合并数据训练的模型进行比较。

Result: 迁移学习模型在诊断特异性死亡率预测中始终优于仅使用诊断特异性数据的模型和APACHE IVa评分，校准性优于合并数据训练的模型。研究还发现Youden截断值比传统的0.5更适合作为二元结果的决策阈值，且迁移学习在不同截断标准下均保持高预测性能。

Conclusion: 迁移学习是ICU诊断特异性死亡率预测的有效方法，能更好地处理诊断异质性，提高预测性能，且Youden截断值比传统阈值更合适。

Abstract: In the intensive care unit, the underlying causes of critical illness vary substantially across diagnoses, yet prediction models accounting for diagnostic heterogeneity have not been systematically studied. To address the gap, we evaluate transfer learning approaches for diagnosis-specific mortality prediction and apply both GLM- and XGBoost-based models to the eICU Collaborative Research Database. Our results demonstrate that transfer learning consistently outperforms models trained only on diagnosis-specific data and those using a well-known ICU severity-of-illness score, i.e., APACHE IVa, alone, while also achieving better calibration than models trained on the pooled data. Our findings also suggest that the Youden cutoff is a more appropriate decision threshold than the conventional 0.5 for binary outcomes, and that transfer learning maintains consistently high predictive performance across various cutoff criteria.

</details>


### [222] [Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning](https://arxiv.org/abs/2512.06533)
*Ming Chen,Sheng Tang,Rong-Xi Tan,Ziniu Li,Jiacheng Chen,Ke Xue,Chao Qian*

Main category: cs.LG

TL;DR: 本文提出使用强化学习改进基于解码的回归方法，通过序列级奖励增强数值预测的全局一致性，显著提升预测精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 基于解码的回归方法将回归任务转化为序列生成任务，但现有方法存在离散token级目标与连续数值之间的不对齐问题，token级约束难以捕捉目标值的全局幅度，限制了预测精度和泛化能力。

Method: 将生成过程建模为马尔可夫决策过程，使用强化学习方法（特别是ReMax和GRPO），通过序列级奖励来强制全局数值一致性，而非传统的token级约束。

Result: 在表格回归和代码度量回归任务上的广泛实验表明，该方法在预测精度和泛化能力上均优于最先进的token级基线和传统回归头，强化学习显著提高了采样效率和预测精度。

Conclusion: 强化学习通过引入序列级信号，成功解锁了基于解码的回归方法的潜力，使其成为通用数值预测的稳健且准确的范式。

Abstract: Decoding-based regression, which reformulates regression as a sequence generation task, has emerged as a promising paradigm of applying large language models for numerical prediction. However, its progress is hindered by the misalignment between discrete token-level objectives (e.g., cross-entropy) and continuous numerical values. Existing approaches relying on token-level constraints often fail to capture the global magnitude of the target value, limiting their precision and generalization. In this paper, we propose to unlock the potential of decoding-based regression via Reinforcement Learning (RL). We formulate the generation process as a Markov Decision Process, utilizing sequence-level rewards to enforce global numerical coherence. Extensive experiments on tabular regression and code metric regression demonstrate that our method (specifically with ReMax and GRPO) consistently outperforms both state-of-the-art token-level baselines and traditional regression heads, showing the superiority of introducing sequence-level signals. Our analysis further reveals that RL significantly enhances sampling efficiency and predictive precision, establishing decoding-based regression as a robust and accurate paradigm for general-purpose numerical prediction.

</details>


### [223] [On fine-tuning Boltz-2 for protein-protein affinity prediction](https://arxiv.org/abs/2512.06592)
*James King,Lewis Cornwall,Andrei Cristian Nica,James Day,Aaron Sim,Neil Dalchau,Lilly Wollman,Joshua Meyers*

Main category: cs.LG

TL;DR: 将蛋白质-配体亲和力预测模型Boltz-2适配用于蛋白质-蛋白质亲和力预测，但在TCR3d和PPB-affinity数据集上表现不如序列模型，结合两者能获得互补改进


<details>
  <summary>Details</summary>
Motivation: 准确预测蛋白质-蛋白质结合亲和力对于理解分子相互作用和设计治疗方法至关重要。现有基于结构的蛋白质-配体亲和力预测器能否有效应用于蛋白质-蛋白质亲和力预测需要验证

Method: 将最先进的基于结构的蛋白质-配体亲和力预测器Boltz-2适配为Boltz-2-PPI，用于蛋白质-蛋白质亲和力回归。在两个数据集(TCR3d和PPB-affinity)上进行评估，并与序列模型比较。还将Boltz-2-PPI的嵌入与序列模型的嵌入结合

Result: 尽管结构准确性高，但Boltz-2-PPI在小规模和较大规模数据体系下都表现不如序列模型。结合Boltz-2-PPI嵌入与序列嵌入能产生互补改进，特别是对于较弱的序列模型，表明序列和结构模型学习了不同的信号

Conclusion: 结果反映了与结构数据训练相关的已知偏差，表明当前基于结构的表示方法尚未准备好进行高性能的亲和力预测。序列和结构模型的结合可能提供更好的解决方案

Abstract: Accurate prediction of protein-protein binding affinity is vital for understanding molecular interactions and designing therapeutics. We adapt Boltz-2, a state-of-the-art structure-based protein-ligand affinity predictor, for protein-protein affinity regression and evaluate it on two datasets, TCR3d and PPB-affinity. Despite high structural accuracy, Boltz-2-PPI underperforms relative to sequence-based alternatives in both small- and larger-scale data regimes. Combining embeddings from Boltz-2-PPI with sequence-based embeddings yields complementary improvements, particularly for weaker sequence models, suggesting different signals are learned by sequence- and structure-based models. Our results echo known biases associated with training with structural data and suggest that current structure-based representations are not primed for performant affinity prediction.

</details>


### [224] [A Fast and Effective Solution to the Problem of Look-ahead Bias in LLMs](https://arxiv.org/abs/2512.06607)
*Humzah Merchant,Bradford Levy*

Main category: cs.LG

TL;DR: 提出一种在推理时通过调整大模型logits来消除前瞻性偏差的方法，使用一对小模型分别微调于需要遗忘和保留的信息，有效解决了金融预测中LLMs的前瞻偏差问题。


<details>
  <summary>Details</summary>
Motivation: 将LLMs应用于金融预测任务时面临前瞻性偏差的挑战，因为LLMs在长时间序列数据上训练，导致无法进行金融领域典型的回测。从头开始重新训练前沿模型到特定知识截止点成本过高。

Method: 在推理时通过调整大基础模型的logits来引导生成，使用一对较小的专用模型：一个微调于需要遗忘的信息，另一个微调于需要保留的信息。

Result: 该方法有效移除了字面和语义知识，纠正了偏差，并且优于先前的方法。

Conclusion: 提出了一种快速、有效且低成本的替代方案，解决了金融预测中LLMs的前瞻偏差问题，使模型能够进行可靠的金融回测。

Abstract: Applying LLMs to predictive tasks in finance is challenging due to look-ahead bias resulting from their training on long time-series data. This precludes the backtests typically employed in finance since retraining frontier models from scratch with a specific knowledge cutoff is prohibitive. In this paper, we introduce a fast, effective, and low-cost alternative. Our method guides generation at inference time by adjusting the logits of a large base model using a pair of smaller, specialized models -- one fine-tuned on information to be forgotten and another on information to be retained. We demonstrate that our method effectively removes both verbatim and semantic knowledge, corrects biases, and outperforms prior methods.

</details>


### [225] [Vector Quantization using Gaussian Variational Autoencoder](https://arxiv.org/abs/2512.06609)
*Tongda Xu,Wendi Zheng,Jiajun He,Jose Miguel Hernandez-Lobato,Yan Wang,Ya-Qin Zhang,Jie Tang*

Main category: cs.LG

TL;DR: 提出Gaussian Quant技术，无需训练即可将高斯VAE转换为VQ-VAE，通过随机高斯噪声作为码本，理论证明码本大小超过高斯VAE的bits-back编码率时可保证小量化误差。


<details>
  <summary>Details</summary>
Motivation: VQ-VAE由于离散化难以训练，需要一种更简单有效的方法来获得离散表示。

Method: 提出Gaussian Quant技术：1) 生成随机高斯噪声作为码本；2) 找到后验均值最接近的噪声；3) 提出目标散度约束(TDC)启发式训练高斯VAE以优化GQ效果。

Result: GQ在UNet和ViT架构上均优于VQGAN、FSQ、LFQ、BSQ等现有VQ-VAE方法；TDC也改进了TokenBridge等高斯VAE离散化方法。

Conclusion: Gaussian Quant提供了一种无需训练即可从高斯VAE获得高质量离散表示的有效方法，理论保证和实际效果均优于现有方法。

Abstract: Vector quantized variational autoencoder (VQ-VAE) is a discrete auto-encoder that compresses images into discrete tokens. It is difficult to train due to discretization. In this paper, we propose a simple yet effective technique, dubbed Gaussian Quant (GQ), that converts a Gaussian VAE with certain constraint into a VQ-VAE without training. GQ generates random Gaussian noise as a codebook and finds the closest noise to the posterior mean. Theoretically, we prove that when the logarithm of the codebook size exceeds the bits-back coding rate of the Gaussian VAE, a small quantization error is guaranteed. Practically, we propose a heuristic to train Gaussian VAE for effective GQ, named target divergence constraint (TDC). Empirically, we show that GQ outperforms previous VQ-VAEs, such as VQGAN, FSQ, LFQ, and BSQ, on both UNet and ViT architectures. Furthermore, TDC also improves upon previous Gaussian VAE discretization methods, such as TokenBridge. The source code is provided in https://github.com/tongdaxu/VQ-VAE-from-Gaussian-VAE.

</details>


### [226] [Adaptive Test-Time Training for Predicting Need for Invasive Mechanical Ventilation in Multi-Center Cohorts](https://arxiv.org/abs/2512.06652)
*Xiaolei Lu,Shamim Nemati*

Main category: cs.LG

TL;DR: AdaTTT：一种用于ICU患者有创机械通气预测的自适应测试时训练框架，通过自监督学习、原型学习和部分最优传输来应对跨机构领域偏移问题。


<details>
  <summary>Details</summary>
Motivation: ICU患者有创机械通气预测模型在跨机构部署时面临领域偏移问题，导致泛化性能下降。测试时训练虽然能动态适应，但需要改进以适应电子健康记录数据的特殊性。

Method: 提出自适应测试时训练框架AdaTTT：1）基于信息论推导测试时预测误差边界；2）设计自监督学习框架，包含重构和掩码特征建模任务，采用动态掩码策略；3）引入原型学习和部分最优传输进行特征对齐，保持临床有意义的患者表示。

Result: 在多中心ICU队列实验中，该框架在不同测试时适应基准上展现出有竞争力的分类性能。

Conclusion: AdaTTT框架能有效应对ICU电子健康记录数据的领域偏移问题，提高有创机械通气预测模型的跨机构泛化能力，为临床决策提供更可靠的工具。

Abstract: Accurate prediction of the need for invasive mechanical ventilation (IMV) in intensive care units (ICUs) patients is crucial for timely interventions and resource allocation. However, variability in patient populations, clinical practices, and electronic health record (EHR) systems across institutions introduces domain shifts that degrade the generalization performance of predictive models during deployment. Test-Time Training (TTT) has emerged as a promising approach to mitigate such shifts by adapting models dynamically during inference without requiring labeled target-domain data. In this work, we introduce Adaptive Test-Time Training (AdaTTT), an enhanced TTT framework tailored for EHR-based IMV prediction in ICU settings. We begin by deriving information-theoretic bounds on the test-time prediction error and demonstrate that it is constrained by the uncertainty between the main and auxiliary tasks. To enhance their alignment, we introduce a self-supervised learning framework with pretext tasks: reconstruction and masked feature modeling optimized through a dynamic masking strategy that emphasizes features critical to the main task. Additionally, to improve robustness against domain shifts, we incorporate prototype learning and employ Partial Optimal Transport (POT) for flexible, partial feature alignment while maintaining clinically meaningful patient representations. Experiments across multi-center ICU cohorts demonstrate competitive classification performance on different test-time adaptation benchmarks.

</details>


### [227] [The Meta-Learning Gap: Combining Hydra and Quant for Large-Scale Time Series Classification](https://arxiv.org/abs/2512.06666)
*Urav Maniar*

Main category: cs.LG

TL;DR: 研究时间序列分类中精度与计算效率的权衡，探索两种高效算法（Hydra和Quant）的组合能否在保持计算可行性的同时获得集成学习的好处。在10个大规模MONSTER数据集上测试6种集成配置，发现特征拼接方法表现最佳，但当前元学习策略未能充分利用算法互补性。


<details>
  <summary>Details</summary>
Motivation: 时间序列分类面临精度与计算效率的根本权衡。像HIVE-COTE 2.0这样的全面集成方法虽然能达到最先进的精度，但在UCR基准测试上需要340小时的训练时间，对于大规模数据集来说不切实际。研究旨在探索两种来自互补范式的高效算法（Hydra和Quant）的有针对性组合，能否在保持计算可行性的同时捕获集成学习的好处。

Method: 结合Hydra（竞争卷积核）和Quant（分层区间分位数）两种算法，在6种不同的集成配置下进行评估。使用10个大规模MONSTER数据集（训练实例从7,898到1,168,774个）进行实验。比较了预测组合集成和特征拼接方法，并分析了算法互补性与集成增益的相关性。

Result: 最强配置将平均精度从0.829提高到0.836，在10个数据集中的7个上取得成功。然而，预测组合集成仅捕获了11%的理论oracle潜力，显示出显著的元学习优化差距。特征拼接方法通过学习新的决策边界超过了oracle边界，而预测级别的互补性与集成增益呈中等相关性。

Conclusion: 核心发现：挑战已经从确保算法不同转变为学习如何有效组合它们。当前的元学习策略难以利用oracle分析确认存在的互补性。改进的组合策略可能使集成增益在不同时间序列分类应用中翻倍甚至三倍。

Abstract: Time series classification faces a fundamental trade-off between accuracy and computational efficiency. While comprehensive ensembles like HIVE-COTE 2.0 achieve state-of-the-art accuracy, their 340-hour training time on the UCR benchmark renders them impractical for large-scale datasets. We investigate whether targeted combinations of two efficient algorithms from complementary paradigms can capture ensemble benefits while maintaining computational feasibility. Combining Hydra (competing convolutional kernels) and Quant (hierarchical interval quantiles) across six ensemble configurations, we evaluate performance on 10 large-scale MONSTER datasets (7,898 to 1,168,774 training instances). Our strongest configuration improves mean accuracy from 0.829 to 0.836, succeeding on 7 of 10 datasets. However, prediction-combination ensembles capture only 11% of theoretical oracle potential, revealing a substantial meta-learning optimization gap. Feature-concatenation approaches exceeded oracle bounds by learning novel decision boundaries, while prediction-level complementarity shows moderate correlation with ensemble gains. The central finding: the challenge has shifted from ensuring algorithms are different to learning how to combine them effectively. Current meta-learning strategies struggle to exploit the complementarity that oracle analysis confirms exists. Improved combination strategies could potentially double or triple ensemble gains across diverse time series classification applications.

</details>


### [228] [GradientSpace: Unsupervised Data Clustering for Improved Instruction Tuning](https://arxiv.org/abs/2512.06678)
*Shrihari Sridharan,Deepak Ravikumar,Anand Raghunathan,Kaushik Roy*

Main category: cs.LG

TL;DR: GradientSpace框架通过在全维梯度空间中聚类样本，使用在线SVD算法识别潜在技能，训练专门的LoRA专家和轻量级路由器，在推理时选择最佳专家，显著提升性能并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集通常是异构的，包含多样信息，导致梯度干扰问题，即冲突的梯度将模型拉向相反方向，降低性能。现有方法基于语义或嵌入相似性分组数据，但无法捕捉数据如何影响模型参数学习；而直接聚类梯度的方法需要随机投影降维导致精度损失，且依赖专家集成增加推理成本。

Method: 提出GradientSpace框架：1) 在全维梯度空间中直接聚类样本，避免降维精度损失；2) 引入基于LoRA梯度的在线SVD算法，识别潜在技能而无需存储所有样本梯度；3) 为每个聚类训练专门的LoRA专家；4) 训练轻量级路由器在推理时选择最佳专家。

Result: 在数学推理、代码生成、金融和创意写作任务上的实验表明，GradientSpace实现了连贯的专家专业化，相比最先进的聚类方法和微调技术获得一致的准确率提升。路由到单个适当专家优于先前工作中的专家集成，同时显著降低推理延迟。

Conclusion: GradientSpace通过在全维梯度空间中聚类样本，有效解决了异构数据集中的梯度干扰问题，实现了更好的专家专业化，在保持高性能的同时降低了推理成本，为指令调优提供了更有效的解决方案。

Abstract: Instruction tuning is one of the key steps required for adapting large language models (LLMs) to a broad spectrum of downstream applications. However, this procedure is difficult because real-world datasets are rarely homogeneous; they consist of a mixture of diverse information, causing gradient interference, where conflicting gradients pull the model in opposing directions, degrading performance. A common strategy to mitigate this issue is to group data based on semantic or embedding similarity. However, this fails to capture how data influences model parameters during learning. While recent works have attempted to cluster gradients directly, they randomly project gradients into lower dimensions to manage memory, which leads to accuracy loss. Moreover, these methods rely on expert ensembles which necessitates multiple inference passes and expensive on-the-fly gradient computations during inference. To address these limitations, we propose GradientSpace, a framework that clusters samples directly in full-dimensional gradient space. We introduce an online SVD-based algorithm that operates on LoRA gradients to identify latent skills without the infeasible cost of storing all sample gradients. Each cluster is used to train a specialized LoRA expert along with a lightweight router trained to select the best expert during inference. We show that routing to a single, appropriate expert outperforms expert ensembles used in prior work, while significantly reducing inference latency. Our experiments across mathematical reasoning, code generation, finance, and creative writing tasks demonstrate that GradientSpace leads to coherent expert specialization and consistent accuracy gains over state-of-the-art clustering methods and finetuning techniques.

</details>


### [229] [State Diversity Matters in Offline Behavior Distillation](https://arxiv.org/abs/2512.06692)
*Shiye Lei,Zhihao Cheng,Dacheng Tao*

Main category: cs.LG

TL;DR: 本文发现离线行为蒸馏中原始数据集与合成数据集存在不对齐问题，提出状态多样性在训练损失较大时比状态质量更重要，并设计了状态密度加权算法来增强合成数据的状态多样性。


<details>
  <summary>Details</summary>
Motivation: 离线行为蒸馏（OBD）将大量离线RL数据压缩成紧凑的合成行为数据集，但研究发现高质量原始数据集不一定产生优质合成数据集，存在原始数据集与合成数据集之间的不对齐问题。

Method: 通过实证分析不同训练损失水平下的策略性能，建立理论分析框架将状态质量和多样性分别与关键误差和周围误差关联，提出状态密度加权（SDW）OBD算法，使用状态密度的倒数加权蒸馏目标以增强状态多样性。

Result: 实验表明：1）当训练损失较大时（OBD常见情况），状态多样性更大的数据集表现更好；2）当训练损失较小时，状态质量更高的数据集表现更好；3）SDW算法在原始数据集状态多样性有限时显著提升OBD性能。

Conclusion: 状态多样性在离线行为蒸馏中至关重要，特别是在训练损失较大的情况下。提出的状态密度加权算法通过强调状态多样性，有效解决了原始数据集与合成数据集之间的不对齐问题，提升了OBD性能。

Abstract: Offline Behavior Distillation (OBD), which condenses massive offline RL data into a compact synthetic behavioral dataset, offers a promising approach for efficient policy training and can be applied across various downstream RL tasks. In this paper, we uncover a misalignment between original and distilled datasets, observing that a high-quality original dataset does not necessarily yield a superior synthetic dataset. Through an empirical analysis of policy performance under varying levels of training loss, we show that datasets with greater state diversity outperforms those with higher state quality when training loss is substantial, as is often the case in OBD, whereas the relationship reverses under minimal loss, which contributes to the misalignment. By associating state quality and diversity in reducing pivotal and surrounding error, respectively, our theoretical analysis establishes that surrounding error plays a more crucial role in policy performance when pivotal error is large, thereby highlighting the importance of state diversity in OBD scenario. Furthermore, we propose a novel yet simple algorithm, state density weighted (SDW) OBD, which emphasizes state diversity by weighting the distillation objective using the reciprocal of state density, thereby distilling a more diverse state information into synthetic data. Extensive experiments across multiple D4RL datasets confirm that SDW significantly enhances OBD performance when the original dataset exhibits limited state diversity.

</details>


### [230] [Mitigating Barren plateaus in quantum denoising diffusion probabilistic models](https://arxiv.org/abs/2512.06695)
*Haipeng Cao,Kaining Zhang,Dacheng Tao,Zhaofeng Su*

Main category: cs.LG

TL;DR: 量子去噪扩散概率模型(QuDDPM)存在训练高原问题，改进版本通过使用与Haar分布保持距离的输入分布解决了这一问题，提升了训练效率和生成质量。


<details>
  <summary>Details</summary>
Motivation: 量子生成模型利用量子叠加和纠缠特性提升学习效率，QuDDPM作为量子生成学习框架在量子噪声模型、多体相和拓扑结构学习方面表现出色，但存在训练高原问题限制了其性能。

Method: 通过理论分析和实验验证确认原始QuDDPM存在训练高原问题，提出改进的QuDDPM，使用与Haar分布保持一定距离的分布作为去噪过程的输入，确保更好的可训练性。

Result: 实验结果表明改进方法有效缓解了训练高原问题，生成了更高质量的样本，为可扩展和高效的量子生成学习铺平了道路。

Conclusion: 通过避免使用2-design状态作为输入，改进的QuDDPM解决了训练高原问题，显著提升了量子生成模型的训练效率和生成质量。

Abstract: Quantum generative models leverage quantum superposition and entanglement to enhance learning efficiency for both classical and quantum data. The quantum denoising diffusion probabilistic model (QuDDPM), inspired by its classical counterpart, has been proposed as a promising framework for quantum generative learning. QuDDPM is capable of efficiently learning and generating quantum data, and it demonstrates excellent performance in learning correlated quantum noise models, quantum many-body phases, and the topological structure of quantum data. However, we show that barren plateaus emerge in QuDDPMs due to the use of 2-design states as the input for the denoising process, which severely undermines the performance of QuDDPM. Through theoretical analysis and experimental validation, we confirm the presence of barren plateaus in the original QuDDPM. To address this issue, we introduce an improved QuDDPM that utilizes a distribution maintaining a certain distance from the Haar distribution, ensuring better trainability. Experimental results demonstrate that our approach effectively mitigates the barren plateau problem and generates samples with higher quality, paving the way for scalable and efficient quantum generative learning.

</details>


### [231] [Pathway to $O(\sqrt{d})$ Complexity bound under Wasserstein metric of flow-based models](https://arxiv.org/abs/2512.06702)
*Xiangjun Meng,Zhongjian Wang*

Main category: cs.LG

TL;DR: 该论文为基于流的生成模型提供了可实现的误差分析工具，证明了在Wasserstein度量下，最优采样迭代复杂度与维度呈$O(\sqrt{d})$关系，误差由两部分控制：反向流前推映射的Lipschitz性质（与维度无关）和局部离散化误差（$O(\sqrt{d})$）。


<details>
  <summary>Details</summary>
Motivation: 为基于流的生成模型提供可实现的误差分析工具，建立Wasserstein度量下的误差估计和最优采样迭代复杂度界限，特别关注维度依赖关系。

Method: 提出分析方法将误差分解为两部分：反向流前推映射的Lipschitz性质（与维度无关）和局部离散化误差（$O(\sqrt{d})$）。这些假设在Föllmer过程和1-整流流相关的流生成模型下，在满足高斯尾假设时成立。

Result: 证明了采样迭代复杂度与协方差算子迹的平方根呈线性关系，即$O(\sqrt{d})$，这与前向过程不变分布的协方差结构相关。

Conclusion: 该研究为流生成模型提供了理论分析框架，揭示了采样复杂度的维度依赖关系，特别指出在Föllmer过程和1-整流流模型中，最优采样迭代复杂度为$O(\sqrt{d})$。

Abstract: We provide attainable analytical tools to estimate the error of flow-based generative models under the Wasserstein metric and to establish the optimal sampling iteration complexity bound with respect to dimension as $O(\sqrt{d})$. We show this error can be explicitly controlled by two parts: the Lipschitzness of the push-forward maps of the backward flow which scales independently of the dimension; and a local discretization error scales $O(\sqrt{d})$ in terms of dimension. The former one is related to the existence of Lipschitz changes of variables induced by the (heat) flow. The latter one consists of the regularity of the score function in both spatial and temporal directions.
  These assumptions are valid in the flow-based generative model associated with the Föllmer process and $1$-rectified flow under the Gaussian tail assumption. As a consequence, we show that the sampling iteration complexity grows linearly with the square root of the trace of the covariance operator, which is related to the invariant distribution of the forward process.

</details>


### [232] [A Novel Multimodal RUL Framework for Remaining Useful Life Estimation with Layer-wise Explanations](https://arxiv.org/abs/2512.06708)
*Waleed Razzaq,Yun-Bo Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的多模态RUL估计框架，结合图像表示和时间频率表示，通过注意力机制和可解释性技术，在减少训练数据需求的同时提高了预测性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 滚动轴承是机械故障的常见原因，现有RUL估计方法存在泛化能力差、鲁棒性不足、数据需求高和可解释性有限等问题，需要更有效的解决方案。

Method: 提出多模态RUL框架：1) 使用Bresenham线算法将振动信号转换为图像表示(ImR)；2) 使用连续小波变换转换为时频表示(TFR)；3) 三个分支架构：ImR和TFR分支使用扩张卷积块提取空间退化特征，融合分支通过LSTM建模时间模式；4) 多头注意力机制突出重要特征；5) 引入多模态层相关传播(multimodal-LRP)增强可解释性。

Result: 在XJTU-SY和PRONOSTIA基准数据集上验证，方法在已知和未知工况下均达到或超越现有最佳方法，XJTU-SY减少28%训练数据，PRONOSTIA减少48%训练数据，模型具有强噪声鲁棒性，multimodal-LRP可视化确认了预测的可解释性和可信度。

Conclusion: 该多模态框架通过结合图像和时频表示，在减少数据需求的同时提高了RUL估计性能、鲁棒性和可解释性，非常适合实际工业部署。

Abstract: Estimating the Remaining Useful Life (RUL) of mechanical systems is pivotal in Prognostics and Health Management (PHM). Rolling-element bearings are among the most frequent causes of machinery failure, highlighting the need for robust RUL estimation methods. Existing approaches often suffer from poor generalization, lack of robustness, high data demands, and limited interpretability. This paper proposes a novel multimodal-RUL framework that jointly leverages image representations (ImR) and time-frequency representations (TFR) of multichannel, nonstationary vibration signals. The architecture comprises three branches: (1) an ImR branch and (2) a TFR branch, both employing multiple dilated convolutional blocks with residual connections to extract spatial degradation features; and (3) a fusion branch that concatenates these features and feeds them into an LSTM to model temporal degradation patterns. A multi-head attention mechanism subsequently emphasizes salient features, followed by linear layers for final RUL regression. To enable effective multimodal learning, vibration signals are converted into ImR via the Bresenham line algorithm and into TFR using Continuous Wavelet Transform. We also introduce multimodal Layer-wise Relevance Propagation (multimodal-LRP), a tailored explainability technique that significantly enhances model transparency. The approach is validated on the XJTU-SY and PRONOSTIA benchmark datasets. Results show that our method matches or surpasses state-of-the-art baselines under both seen and unseen operating conditions, while requiring ~28 % less training data on XJTU-SY and ~48 % less on PRONOSTIA. The model exhibits strong noise resilience, and multimodal-LRP visualizations confirm the interpretability and trustworthiness of predictions, making the framework highly suitable for real-world industrial deployment.

</details>


### [233] [A Novel Deep Neural Network Architecture for Real-Time Water Demand Forecasting](https://arxiv.org/abs/2512.06714)
*Tony Salloom,Okyay Kaynak,Wei He*

Main category: cs.LG

TL;DR: 提出一种基于数据扩展和GRU-K-means混合模型的短期用水需求预测方法，显著降低极端点误差和模型复杂度


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在短期用水需求预测中存在两个主要问题：1）模型参数过多导致复杂度高；2）极端点预测误差大。需要开发更高效准确的预测方法

Method: 1）提出数据扩展方法，在真实数据中插入虚拟数据以缓解极端点非线性问题；2）构建GRU-K-means混合模型，GRU处理时序关系，K-means无监督分类创建新特征以减少参数数量

Result: 1）模型复杂度降低至文献方法的六分之一，同时保持相同精度；2）数据扩展使预测误差降低约30%；3）使用中国两个水厂的实际数据验证了模型有效性

Conclusion: 提出的方法有效解决了短期用水需求预测中的极端点误差和模型复杂度问题，虽然数据扩展会增加训练时间，但在精度和效率方面取得了显著改进

Abstract: Short-term water demand forecasting (StWDF) is the foundation stone in the derivation of an optimal plan for controlling water supply systems. Deep learning (DL) approaches provide the most accurate solutions for this purpose. However, they suffer from complexity problem due to the massive number of parameters, in addition to the high forecasting error at the extreme points. In this work, an effective method to alleviate the error at these points is proposed. It is based on extending the data by inserting virtual data within the actual data to relieve the nonlinearity around them. To our knowledge, this is the first work that considers the problem related to the extreme points. Moreover, the water demand forecasting model proposed in this work is a novel DL model with relatively low complexity. The basic model uses the gated recurrent unit (GRU) to handle the sequential relationship in the historical demand data, while an unsupervised classification method, K-means, is introduced for the creation of new features to enhance the prediction accuracy with less number of parameters. Real data obtained from two different water plants in China are used to train and verify the model proposed. The prediction results and the comparison with the state-of-the-art illustrate that the method proposed reduces the complexity of the model six times of what achieved in the literature while conserving the same accuracy. Furthermore, it is found that extending the data set significantly reduces the error by about 30%. However, it increases the training time.

</details>


### [234] [KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models](https://arxiv.org/abs/2512.06727)
*Sourjya Roy,Shrihari Sridharan,Surya Selvam,Anand Raghunathan*

Main category: cs.LG

TL;DR: KV CAR是一个统一的、架构无关的KV缓存压缩框架，通过轻量级自编码器和相似性驱动的重用机制，在保持模型保真度的同时显著减少KV缓存存储需求。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模和上下文长度的增加，KV缓存的内存需求已成为自回归解码的主要瓶颈。KV缓存随序列长度和嵌入维度增长，常常超过模型本身的内存占用，限制了可实现的批处理大小和上下文窗口。

Method: KV CAR结合两种互补技术：1) 轻量级自编码器沿嵌入维度学习键值张量的紧凑表示，在存储到KV缓存前压缩它们并在检索时恢复；2) 相似性驱动的重用机制识别在相邻层间重用特定注意力头KV张量的机会。

Result: 在GPT-2和TinyLLaMA模型上的评估显示，KV CAR实现了高达47.85%的KV缓存内存减少，对困惑度和零样本准确率影响最小。在NVIDIA A40 GPU上的系统级测量表明，减少的KV占用直接转化为推理过程中更长的序列长度和更大的批处理大小。

Conclusion: KV CAR通过减少KV张量的维度和结构冗余，无需改变Transformer架构，有效实现了内存高效的大语言模型推理。

Abstract: As Large Language Models (LLMs) scale in size and context length, the memory requirements of the key value (KV) cache have emerged as a major bottleneck during autoregressive decoding. The KV cache grows with sequence length and embedding dimension, often exceeding the memory footprint of the model itself and limiting achievable batch sizes and context windows. To address this challenge, we present KV CAR, a unified and architecture agnostic framework that significantly reduces KV cache storage while maintaining model fidelity. KV CAR combines two complementary techniques. First, a lightweight autoencoder learns compact representations of key and value tensors along the embedding dimension, compressing them before they are stored in the KV cache and restoring them upon retrieval. Second, a similarity driven reuse mechanism identifies opportunities to reuse KV tensors of specific attention heads across adjacent layers. Together, these methods reduce the dimensional and structural redundancy in KV tensors without requiring changes to the transformer architecture. Evaluations on GPT 2 and TinyLLaMA models across Wikitext, C4, PIQA, and Winogrande datasets demonstrate that KV CAR achieves up to 47.85 percent KV cache memory reduction with minimal impact on perplexity and zero shot accuracy. System level measurements on an NVIDIA A40 GPU show that the reduced KV footprint directly translates into longer sequence lengths and larger batch sizes during inference. These results highlight the effectiveness of KV CAR in enabling memory efficient LLM inference.

</details>


### [235] [Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics](https://arxiv.org/abs/2512.06737)
*Nikhil Verma,Joonas Linnosmaa,Espinosa-Leal Leonardo,Napat Vajragupta*

Main category: cs.LG

TL;DR: ArcGD优化器在非凸基准函数和真实ML数据集上均表现优异，超越了Adam等主流优化器，展示了更好的泛化能力和抗过拟合特性。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的优化器ArcGD，旨在解决现有优化器（如Adam）在非凸优化问题中的局限性，特别是在高维空间和长时间训练中可能出现的性能退化问题。

Method: 提出了ArcGD优化器，首先在具有挑战性的Rosenbrock函数上进行评估（从2D到50,000D），然后在CIFAR-10图像分类数据集上测试，使用8种不同的MLP架构，与Adam、AdamW、Lion、SGD等优化器进行对比。

Result: ArcGD在Rosenbrock函数上一致优于Adam；在CIFAR-10上获得最高平均测试准确率（50.7%），在8种架构中6种获胜或持平。ArcGD在长时间训练中持续改进，而Adam和AdamW在早期收敛后出现性能退化。

Conclusion: ArcGD优化器在非凸优化和深度学习任务中表现出色，具有更好的泛化能力和抗过拟合特性，无需早期停止调优。研究还发现ArcGD变体可解释为Lion优化器的特例，揭示了不同优化方法之间的内在联系。

Abstract: The paper presents the formulation, implementation, and evaluation of the ArcGD optimiser. The evaluation is conducted initially on a non-convex benchmark function and subsequently on a real-world ML dataset. The initial comparative study using the Adam optimiser is conducted on a stochastic variant of the highly non-convex and notoriously challenging Rosenbrock function, renowned for its narrow, curved valley, across dimensions ranging from 2D to 1000D and an extreme case of 50,000D. Two configurations were evaluated to eliminate learning-rate bias: (i) both using ArcGD's effective learning rate and (ii) both using Adam's default learning rate. ArcGD consistently outperformed Adam under the first setting and, although slower under the second, achieved super ior final solutions in most cases. In the second evaluation, ArcGD is evaluated against state-of-the-art optimizers (Adam, AdamW, Lion, SGD) on the CIFAR-10 image classification dataset across 8 diverse MLP architectures ranging from 1 to 5 hidden layers. ArcGD achieved the highest average test accuracy (50.7%) at 20,000 iterations, outperforming AdamW (46.6%), Adam (46.8%), SGD (49.6%), and Lion (43.4%), winning or tying on 6 of 8 architectures. Notably, while Adam and AdamW showed strong early convergence at 5,000 iterations, but regressed with extended training, whereas ArcGD continued improving, demonstrating generalization and resistance to overfitting without requiring early stopping tuning. Strong performance on geometric stress tests and standard deep-learning benchmarks indicates broad applicability, highlighting the need for further exploration. Moreover, it is also shown that a variant of ArcGD can be interpreted as a special case of the Lion optimiser, highlighting connections between the inherent mechanisms of such optimisation methods.

</details>


### [236] [Optimal Analysis for Bandit Learning in Matching Markets with Serial Dictatorship](https://arxiv.org/abs/2512.06758)
*Zilong Wang,Shuai Li*

Main category: cs.LG

TL;DR: 本文提出了一种多级连续选择算法，在序列独裁假设下的匹配市场中实现了与已知下界匹配的遗憾上界O(Nlog(T)/Δ² + Klog(T)/Δ)。


<details>
  <summary>Details</summary>
Motivation: 在线匹配市场中，参与者通常不确定自己的偏好，需要通过多轮交互学习。现有研究存在下界Ω(Nlog(T)/Δ² + Klog(T)/Δ)和上界O(Klog(T)/Δ²)之间的差距，范围从N到K。不清楚是需要改进下界还是上界。

Method: 提出了一种多级连续选择算法，在满足序列独裁假设的市场中工作。序列独裁假设认为所有参与者（臂）具有相同的偏好，这在现实中当一方参与者有统一评估标准时很常见。

Result: 算法获得了O(Nlog(T)/Δ² + Klog(T)/Δ)的遗憾上界，与已知下界匹配。据作者所知，这是第一个在匹配市场与多臂赌博机问题中匹配下界的算法。

Conclusion: 成功解决了在线匹配市场中下界与上界之间的差距问题，提出了第一个匹配已知下界的算法，为序列独裁假设下的匹配市场学习问题提供了最优解决方案。

Abstract: The problem of two-sided matching markets is well-studied in computer science and economics, owing to its diverse applications across numerous domains. Since market participants are usually uncertain about their preferences in various online matching platforms, an emerging line of research is dedicated to the online setting where one-side participants (players) learn their unknown preferences through multiple rounds of interactions with the other side (arms). Sankararaman et al. provide an $Ω\left( \frac{N\log(T)}{Δ^2} + \frac{K\log(T)}Δ \right)$ regret lower bound for this problem under serial dictatorship assumption, where $N$ is the number of players, $K (\geq N)$ is the number of arms, $Δ$ is the minimum reward gap across players and arms, and $T$ is the time horizon. Serial dictatorship assumes arms have the same preferences, which is common in reality when one side participants have a unified evaluation standard. Recently, the work of Kong and Li proposes the ET-GS algorithm and achieves an $O\left( \frac{K\log(T)}{Δ^2} \right)$ regret upper bound, which is the best upper bound attained so far. Nonetheless, a gap between the lower and upper bounds, ranging from $N$ to $K$, persists. It remains unclear whether the lower bound or the upper bound needs to be improved. In this paper, we propose a multi-level successive selection algorithm that obtains an $O\left( \frac{N\log(T)}{Δ^2} + \frac{K\log(T)}Δ \right)$ regret bound when the market satisfies serial dictatorship. To the best of our knowledge, we are the first to propose an algorithm that matches the lower bound in the problem of matching markets with bandits.

</details>


### [237] [Angular Regularization for Positive-Unlabeled Learning on the Hypersphere](https://arxiv.org/abs/2512.06785)
*Vasileios Sevetlidis,George Pavlidis,Antonios Gasteratos*

Main category: cs.LG

TL;DR: AngularPU：一种基于余弦相似度和角度间隔的PU学习新框架，使用可学习的正类原型向量，通过阈值化余弦相似度进行分类，无需显式负类建模，在稀疏正样本和高维嵌入场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有PU学习方法要么依赖强分布假设（负风险估计），要么在高维设置中容易崩溃（伪标签方法），需要一种更稳健且无需显式负类建模的PU学习框架。

Method: 提出AngularPU框架：1）在单位超球面上操作，使用余弦相似度和角度间隔；2）用可学习的原型向量表示正类；3）通过阈值化嵌入向量与原型之间的余弦相似度进行分类；4）引入角度正则化器，鼓励未标记样本在超球面上分散分布，改善分离效果。

Result: 在基准数据集上的实验表明，AngularPU相比最先进的PU方法取得了竞争性或更优的性能，特别是在正样本稀缺和高维嵌入的设置中，同时提供几何可解释性和可扩展性。

Conclusion: AngularPU提供了一种无需显式负类建模的PU学习新范式，具有理论保证、几何可解释性和实际有效性，特别适合高维和正样本稀缺的场景。

Abstract: Positive-Unlabeled (PU) learning addresses classification problems where only a subset of positive examples is labeled and the remaining data is unlabeled, making explicit negative supervision unavailable. Existing PU methods often rely on negative-risk estimation or pseudo-labeling, which either require strong distributional assumptions or can collapse in high-dimensional settings. We propose AngularPU, a novel PU framework that operates on the unit hypersphere using cosine similarity and angular margin. In our formulation, the positive class is represented by a learnable prototype vector, and classification reduces to thresholding the cosine similarity between an embedding and this prototype-eliminating the need for explicit negative modeling. To counteract the tendency of unlabeled embeddings to cluster near the positive prototype, we introduce an angular regularizer that encourages dispersion of the unlabeled set over the hypersphere, improving separation. We provide theoretical guarantees on the Bayes-optimality of the angular decision rule, consistency of the learned prototype, and the effect of the regularizer on the unlabeled distribution. Experiments on benchmark datasets demonstrate that AngularPU achieves competitive or superior performance compared to state-of-the-art PU methods, particularly in settings with scarce positives and high-dimensional embeddings, while offering geometric interpretability and scalability.

</details>


### [238] [Small-Gain Nash: Certified Contraction to Nash Equilibria in Differentiable Games](https://arxiv.org/abs/2512.06791)
*Vedansh Sharma*

Main category: cs.LG

TL;DR: 论文提出SGN（Small-Gain Nash）方法，通过自定义块加权几何中的块小增益条件，为梯度学习在非单调游戏中提供收敛保证，即使伪梯度在欧几里得几何中不满足单调性条件。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的游戏学习收敛保证需要伪梯度在欧几里得几何中具有（强）单调性，但这一条件在具有强跨玩家耦合的简单游戏中经常失效。需要一种新方法来处理非单调游戏中的收敛问题。

Method: 引入SGN（Small-Gain Nash）方法，在自定义块加权几何中建立块小增益条件。该方法将局部曲率和跨玩家Lipschitz耦合边界转化为可处理的收缩证书，构建加权块度量使伪梯度在特定区域变为强单调，即使它在欧几里得意义上非单调。使用投影欧拉和RK4离散化，并从SGN裕度和局部Lipschitz常数推导出显式步长边界。

Result: 连续流在设计的几何中呈指数收缩，离散化在显式步长边界下收敛。SGN揭示了一个认证的"时间尺度带"，这是一个非渐近的、基于度量的证书，类似于TTUR的作用。在欧几里得单调性分析失败的二次游戏中，SGN成功认证了收敛性，并将构造扩展到马尔可夫游戏中的镜像/Fisher几何用于熵正则化策略梯度。

Conclusion: SGN提供了一个离线认证流程，可在紧凑区域估计曲率、耦合和Lipschitz参数，优化块权重以扩大SGN裕度，并返回一个结构化的、可计算的收敛证书，包括度量、收缩率和安全步长，适用于非单调游戏。

Abstract: Classical convergence guarantees for gradient-based learning in games require the pseudo-gradient to be (strongly) monotone in Euclidean geometry as shown by rosen(1965), a condition that often fails even in simple games with strong cross-player couplings. We introduce Small-Gain Nash (SGN), a block small-gain condition in a custom block-weighted geometry. SGN converts local curvature and cross-player Lipschitz coupling bounds into a tractable certificate of contraction. It constructs a weighted block metric in which the pseudo-gradient becomes strongly monotone on any region where these bounds hold, even when it is non-monotone in the Euclidean sense. The continuous flow is exponentially contracting in this designed geometry, and projected Euler and RK4 discretizations converge under explicit step-size bounds derived from the SGN margin and a local Lipschitz constant. Our analysis reveals a certified ``timescale band'', a non-asymptotic, metric-based certificate that plays a TTUR-like role: rather than forcing asymptotic timescale separation via vanishing, unequal step sizes, SGN identifies a finite band of relative metric weights for which a single-step-size dynamics is provably contractive. We validate the framework on quadratic games where Euclidean monotonicity analysis fails to predict convergence, but SGN successfully certifies it, and extend the construction to mirror/Fisher geometries for entropy-regularized policy gradient in Markov games. The result is an offline certification pipeline that estimates curvature, coupling, and Lipschitz parameters on compact regions, optimizes block weights to enlarge the SGN margin, and returns a structural, computable convergence certificate consisting of a metric, contraction rate, and safe step-sizes for non-monotone games.

</details>


### [239] [Neural Factorization-based Bearing Fault Diagnosis](https://arxiv.org/abs/2512.06837)
*Zhenhao Li,Xu Cheng,Yi Zhou*

Main category: cs.LG

TL;DR: 提出基于神经分解的分类框架用于高铁轴承故障诊断，通过嵌入振动时间序列到多模态潜在特征向量，利用神经分解原理融合这些向量，有效挖掘原始时间序列中的复杂潜在故障特征。


<details>
  <summary>Details</summary>
Motivation: 高铁轴承作为列车运行系统的核心部件，其健康状况直接关系到列车运行安全。传统诊断方法在复杂条件下面临诊断精度不足的挑战，需要更有效的故障诊断方法。

Method: 提出神经分解分类框架，包含两个核心思想：1）将振动时间序列嵌入到多个模态特定的潜在特征向量中，捕捉不同的故障相关模式；2）利用神经分解原理将这些向量融合成统一的振动表示。基于CP和Tucker融合方案分别实例化为CP-NFC和Tucker-NFC模型。

Result: 实验结果表明，两种模型相比传统机器学习方法都取得了优越的诊断性能。比较分析为高铁轴承监测中选择有效诊断策略提供了有价值的经验证据和实践指导。

Conclusion: 提出的神经分解分类框架能够有效挖掘原始时间序列数据中的复杂潜在故障特征，为高铁轴承故障诊断提供了新的有效方法，两种实例化模型均表现出优越的诊断性能。

Abstract: This paper studies the key problems of bearing fault diagnosis of high-speed train. As the core component of the train operation system, the health of bearings is directly related to the safety of train operation. The traditional diagnostic methods are facing the challenge of insufficient diagnostic accuracy under complex conditions. To solve these problems, we propose a novel Neural Factorization-based Classification (NFC) framework for bearing fault diagnosis. It is built on two core idea: 1) Embedding vibration time series into multiple mode-wise latent feature vectors to capture diverse fault-related patterns; 2) Leveraging neural factorization principles to fuse these vectors into a unified vibration representation. This design enables effective mining of complex latent fault characteristics from raw time-series data. We further instantiate the framework with two models CP-NFC and Tucker-NFC based on CP and Tucker fusion schemes, respectively. Experimental results show that both models achieve superior diagnostic performance compared with traditional machine learning methods. The comparative analysis provides valuable empirical evidence and practical guidance for selecting effective diagnostic strategies in high-speed train bearing monitoring.

</details>


### [240] [Know your Trajectory -- Trustworthy Reinforcement Learning deployment through Importance-Based Trajectory Analysis](https://arxiv.org/abs/2512.06917)
*Clifford F,Devika Jay,Abhishek Sarkar,Satheesh K Perepu,Santhosh G S,Kaushik Dey,Balaraman Ravindran*

Main category: cs.LG

TL;DR: 本文提出了一种新的可解释强化学习框架，通过轨迹级分析和新的状态重要性度量来评估智能体的长期行为，能够识别最优轨迹并提供"为什么选择这个而不是那个"的解释。


<details>
  <summary>Details</summary>
Motivation: 随着强化学习智能体在现实世界应用中的部署，确保其行为透明可信变得至关重要。当前可解释强化学习主要关注局部单步决策，缺乏对智能体长期行为的解释能力。

Method: 引入一个新颖框架，通过定义和聚合新的状态重要性度量来对完整轨迹进行排序。该度量结合了经典的Q值差异和捕捉智能体达成目标亲和力的"激进项"，提供了更细致的状态关键性衡量。

Result: 该方法成功从智能体经验集合中识别出最优轨迹。通过从关键状态生成反事实推演，证明智能体选择的路径明显优于替代方案。在标准OpenAI Gym环境中的实验验证了所提重要性度量在识别最优行为方面比经典方法更有效。

Conclusion: 该框架为解释智能体长期行为提供了有力工具，通过轨迹级分析和"为什么选择这个而不是那个"的解释，向可信赖的自主系统迈出了重要一步。

Abstract: As Reinforcement Learning (RL) agents are increasingly deployed in real-world applications, ensuring their behavior is transparent and trustworthy is paramount. A key component of trust is explainability, yet much of the work in Explainable RL (XRL) focuses on local, single-step decisions. This paper addresses the critical need for explaining an agent's long-term behavior through trajectory-level analysis. We introduce a novel framework that ranks entire trajectories by defining and aggregating a new state-importance metric. This metric combines the classic Q-value difference with a "radical term" that captures the agent's affinity to reach its goal, providing a more nuanced measure of state criticality. We demonstrate that our method successfully identifies optimal trajectories from a heterogeneous collection of agent experiences. Furthermore, by generating counterfactual rollouts from critical states within these trajectories, we show that the agent's chosen path is robustly superior to alternatives, thereby providing a powerful "Why this, and not that?" explanation. Our experiments in standard OpenAI Gym environments validate that our proposed importance metric is more effective at identifying optimal behaviors compared to classic approaches, offering a significant step towards trustworthy autonomous systems.

</details>


### [241] [Parent-Guided Semantic Reward Model (PGSRM): Embedding-Based Reward Functions for Reinforcement Learning of Transformer Language Models](https://arxiv.org/abs/2512.06920)
*Alexandr Plashchinsky*

Main category: cs.LG

TL;DR: PGSRM是一种轻量级奖励框架，使用父模型参考输出嵌入与子模型生成输出的余弦相似度作为语义奖励，替代传统奖励建模方法。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法需要二元正确性信号、人类偏好数据或训练奖励模型，这些方法成本高且复杂。PGSRM旨在提供一种无需人工标注或额外模型训练的轻量级语义奖励框架。

Method: PGSRM使用父模型的参考输出嵌入与子模型生成输出的余弦相似度作为奖励信号。这种方法产生密集的、有语义意义的奖励，无需人工标注或额外模型训练。

Result: 在五个语言任务上应用PGSRM，发现相比二元奖励基线，它能产生更平滑的奖励改进和更稳定的PPO动态，表明基于嵌入的语义奖励是RLHF风格奖励建模的实用替代方案。

Conclusion: 嵌入式语义奖励是小型transformer模型中父引导对齐的实用替代方案，PGSRM为强化学习提供了一种轻量级、无需人工标注的奖励框架。

Abstract: We introduce the Parent-Guided Semantic Reward Model (PGSRM), a lightweight reward framework for reinforcement learning (RL) of transformer language models. PGSRM replaces binary correctness signals, human preference data, and trained reward models with a simple signal: cosine similarity between a parent model's reference output embedding and a child model's generated output for the same input. This yields a dense, semantically meaningful reward with no human annotation or additional model training. We apply PGSRM on five language tasks and find that it produces smoother reward improvement and more stable PPO dynamics than a binary reward baseline, suggesting that embedding-based semantic rewards are a practical alternative to RLHF-style reward modeling for parent-guided alignment in smaller transformer models.

</details>


### [242] [Deep Reinforcement Learning for Phishing Detection with Transformer-Based Semantic Features](https://arxiv.org/abs/2512.06925)
*Aseer Al Faisal*

Main category: cs.LG

TL;DR: 该研究提出了一种结合RoBERTa语义嵌入和手工特征词特征的QR-DQN方法，用于钓鱼网站检测，在105,000个URL数据集上取得了99.86%的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击通过欺诈消息、误导广告和合法网站漏洞欺骗用户泄露个人信息，造成经济损失。传统DQN方法估计单一标量Q值，存在稳定性和泛化能力不足的问题。

Method: 提出Quantile Regression Deep Q-Network (QR-DQN)方法，结合RoBERTa语义嵌入和手工特征词特征，利用分位数回归建模回报分布，提高模型稳定性和泛化能力。

Result: 在105,000个URL数据集上，QR-DQN获得测试准确率99.86%、精确率99.75%、召回率99.96%、F1分数99.85%。相比传统DQN，泛化差距从1.66%降至0.04%，五折交叉验证平均准确率99.90%。

Conclusion: 提出的混合QR-DQN方法能有效识别钓鱼威胁，适应不断演变的攻击策略，对未见数据具有良好的泛化能力，显著提高了钓鱼检测的鲁棒性。

Abstract: Phishing is a cybercrime in which individuals are deceived into revealing personal information, often resulting in financial loss. These attacks commonly occur through fraudulent messages, misleading advertisements, and compromised legitimate websites. This study proposes a Quantile Regression Deep Q-Network (QR-DQN) approach that integrates RoBERTa semantic embeddings with handcrafted lexical features to enhance phishing detection while accounting for uncertainties. Unlike traditional DQN methods that estimate single scalar Q-values, QR-DQN leverages quantile regression to model the distribution of returns, improving stability and generalization on unseen phishing data. A diverse dataset of 105,000 URLs was curated from PhishTank, OpenPhish, Cloudflare, and other sources, and the model was evaluated using an 80/20 train-test split. The QR-DQN framework achieved a test accuracy of 99.86%, precision of 99.75%, recall of 99.96%, and F1-score of 99.85%, demonstrating high effectiveness. Compared to standard DQN with lexical features, the hybrid QR-DQN with lexical and semantic features reduced the generalization gap from 1.66% to 0.04%, indicating significant improvement in robustness. Five-fold cross-validation confirmed model reliability, yielding a mean accuracy of 99.90% with a standard deviation of 0.04%. These results suggest that the proposed hybrid approach effectively identifies phishing threats, adapts to evolving attack strategies, and generalizes well to unseen data.

</details>


### [243] [Evaluating the Sensitivity of BiLSTM Forecasting Models to Sequence Length and Input Noise](https://arxiv.org/abs/2512.06926)
*Salma Albelali,Moataz Ahmed*

Main category: cs.LG

TL;DR: 该研究系统分析了双向LSTM时间序列预测模型对输入序列长度和加性噪声的敏感性，发现长序列会增加过拟合风险，噪声会降低预测精度，两者同时存在时模型稳定性下降最显著。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在时间序列预测中应用广泛，特别是双向LSTM架构能有效捕捉复杂时间依赖关系。然而，现有文献对这类模型的鲁棒性和泛化能力如何受输入数据特性影响的研究不足，特别是输入序列长度和加性噪声这两个关键数据中心因素。

Method: 开发了模块化、可复现的预测流程，包含标准化预处理、序列生成、模型训练、验证和评估。在三个不同采样频率的真实世界数据集上进行控制实验，评估双向LSTM在不同输入条件下的性能表现。

Result: 三个关键发现：1) 较长的输入序列显著增加过拟合和数据泄露风险，特别是在数据受限环境中；2) 加性噪声在不同采样频率下都会持续降低预测精度；3) 两个因素同时存在时模型稳定性下降最显著。虽然高观测频率的数据集表现出更强的鲁棒性，但当两个输入挑战同时存在时仍然脆弱。

Conclusion: 研究揭示了当前基于深度学习的预测流程的重要局限性，强调了数据感知设计策略的必要性。这项工作有助于更深入理解深度学习模型在动态时间序列环境中的行为，并为开发更可靠、更可泛化的预测系统提供了实用见解。

Abstract: Deep learning (DL) models, a specialized class of multilayer neural networks, have become central to time-series forecasting in critical domains such as environmental monitoring and the Internet of Things (IoT). Among these, Bidirectional Long Short-Term Memory (BiLSTM) architectures are particularly effective in capturing complex temporal dependencies. However, the robustness and generalization of such models are highly sensitive to input data characteristics - an aspect that remains underexplored in existing literature. This study presents a systematic empirical analysis of two key data-centric factors: input sequence length and additive noise. To support this investigation, a modular and reproducible forecasting pipeline is developed, incorporating standardized preprocessing, sequence generation, model training, validation, and evaluation. Controlled experiments are conducted on three real-world datasets with varying sampling frequencies to assess BiLSTM performance under different input conditions. The results yield three key findings: (1) longer input sequences significantly increase the risk of overfitting and data leakage, particularly in data-constrained environments; (2) additive noise consistently degrades predictive accuracy across sampling frequencies; and (3) the simultaneous presence of both factors results in the most substantial decline in model stability. While datasets with higher observation frequencies exhibit greater robustness, they remain vulnerable when both input challenges are present. These findings highlight important limitations in current DL-based forecasting pipelines and underscore the need for data-aware design strategies. This work contributes to a deeper understanding of DL model behavior in dynamic time-series environments and provides practical insights for developing more reliable and generalizable forecasting systems.

</details>


### [244] [Adaptive Normalization Mamba with Multi Scale Trend Decomposition and Patch MoE Encoding](https://arxiv.org/abs/2512.06929)
*MinCheol Jeon*

Main category: cs.LG

TL;DR: AdaMamba是一个统一的时间序列预测架构，通过自适应归一化、多尺度趋势提取和上下文序列建模来解决非平稳性、多尺度时间模式和分布偏移等挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列预测面临非平稳性、多尺度时间模式和分布偏移等挑战，这些因素会降低模型的稳定性和准确性。传统方法在处理这些复杂时间动态时存在局限性。

Method: 1. 自适应归一化块：通过多尺度卷积趋势提取和通道级重新校准去除非平稳成分；2. 上下文编码器：结合补丁嵌入、位置编码和Mamba增强的Transformer层；3. 轻量级预测头生成多步预测；4. 去归一化机制通过重新整合局部趋势重建输出。

Result: 实验评估表明，AdaMamba结合自适应归一化和专家增强的上下文建模，在稳定性和准确性方面相比传统Transformer基线模型取得了持续改进。

Conclusion: AdaMamba提供了强大的表示能力和模块化可扩展性，有效缓解协变量偏移，增强跨异构数据集的预测可靠性，支持确定性预测并与概率扩展兼容。

Abstract: Time series forecasting in real world environments faces significant challenges non stationarity, multi scale temporal patterns, and distributional shifts that degrade model stability and accuracy. This study propose AdaMamba, a unified forecasting architecture that integrates adaptive normalization, multi scale trend extraction, and contextual sequence modeling to address these challenges. AdaMamba begins with an Adaptive Normalization Block that removes non stationary components through multi scale convolutional trend extraction and channel wise recalibration, enabling consistent detrending and variance stabilization. The normalized sequence is then processed by a Context Encoder that combines patch wise embeddings, positional encoding, and a Mamba enhanced Transformer layer with a mixture of experts feed forward module, allowing efficient modeling of both long range dependencies and local temporal dynamics. A lightweight prediction head generates multi horizon forecasts, and a denormalization mechanism reconstructs outputs by reintegrating local trends to ensure robustness under varying temporal conditions. AdaMamba provides strong representational capacity with modular extensibility, supporting deterministic prediction and compatibility with probabilistic extensions. Its design effectively mitigates covariate shift and enhances predictive reliability across heterogeneous datasets. Experimental evaluations demonstrate that AdaMamba's combination of adaptive normalization and expert augmented contextual modeling yields consistent improvements in stability and accuracy over conventional Transformer based baselines.

</details>


### [245] [Hidden Leaks in Time Series Forecasting: How Data Leakage Affects LSTM Evaluation Across Configurations and Validation Strategies](https://arxiv.org/abs/2512.06932)
*Salma Albelali,Moataz Ahmed*

Main category: cs.LG

TL;DR: 该研究评估了数据泄露对LSTM时间序列预测模型性能的影响，发现验证设计方法显著影响泄露敏感性，其中10折交叉验证的RMSE增益最高可达20.5%，而2路和3路分割更稳健。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测中广泛使用的LSTM模型常因数据泄露问题导致评估结果失真，特别是当输入输出序列在数据集划分前构建时，未来信息可能无意中影响训练过程。本研究旨在探究数据泄露对性能的影响，并分析不同验证设计如何调节泄露敏感性。

Method: 研究比较了三种常用验证技术（2路分割、3路分割和10折交叉验证）在有泄露（划分前生成序列）和无泄露（划分后生成序列）条件下的表现。使用RMSE增益指标量化泄露影响，该指标计算泄露设置与无泄露设置之间RMSE的相对百分比差异。同时分析了输入窗口大小和滞后步长对泄露敏感性的影响。

Result: 10折交叉验证表现出最高的泄露敏感性，在较长滞后步长下RMSE增益可达20.5%。相比之下，2路和3路分割更为稳健，在各种配置下RMSE增益通常保持在5%以下。较小的输入窗口和较长的滞后步长会增加泄露风险，而较大的窗口有助于减少泄露。

Conclusion: 研究强调了配置感知、抗泄露评估流程的重要性，以确保时间序列预测模型性能评估的可靠性。验证设计选择、输入窗口大小和滞后步长配置都会显著影响数据泄露的敏感性，需要谨慎设计评估流程以避免性能估计偏差。

Abstract: Deep learning models, particularly Long Short-Term Memory (LSTM) networks, are widely used in time series forecasting due to their ability to capture complex temporal dependencies. However, evaluation integrity is often compromised by data leakage, a methodological flaw in which input-output sequences are constructed before dataset partitioning, allowing future information to unintentionally influence training. This study investigates the impact of data leakage on performance, focusing on how validation design mediates leakage sensitivity. Three widely used validation techniques (2-way split, 3-way split, and 10-fold cross-validation) are evaluated under both leaky (pre-split sequence generation) and clean conditions, with the latter mitigating leakage risk by enforcing temporal separation during data splitting prior to sequence construction. The effect of leakage is assessed using RMSE Gain, which measures the relative increase in RMSE caused by leakage, computed as the percentage difference between leaky and clean setups. Empirical results show that 10-fold cross-validation exhibits RMSE Gain values of up to 20.5% at extended lag steps. In contrast, 2-way and 3-way splits demonstrate greater robustness, typically maintaining RMSE Gain below 5% across diverse configurations. Moreover, input window size and lag step significantly influence leakage sensitivity: smaller windows and longer lags increase the risk of leakage, whereas larger windows help reduce it. These findings underscore the need for configuration-aware, leakage-resistant evaluation pipelines to ensure reliable performance estimation.

</details>


### [246] [Prediction with Expert Advice under Local Differential Privacy](https://arxiv.org/abs/2512.06971)
*Ben Jacobsen,Kassem Fawaz*

Main category: cs.LG

TL;DR: 该论文研究了在局部差分隐私约束下的专家建议预测问题，提出了两种新算法RW-AdaBatch和RW-Meta，在真实COVID-19医院数据上表现优于传统方法和中心化差分隐私算法。


<details>
  <summary>Details</summary>
Motivation: 研究在局部差分隐私约束下进行专家建议预测的经典问题，旨在开发既能保护隐私又能保持预测性能的算法。

Method: 首先证明经典算法自然满足LDP，然后设计了两种新算法：1) RW-AdaBatch利用LDP诱导的有限切换行为提供新型隐私放大；2) RW-Meta开发了在非平凡学习算法专家之间进行隐私选择的一般方法。两种算法都基于随机游走理论进行分析。

Result: RW-AdaBatch在更简单的数据上提供更强的隐私放大且几乎没有效用损失；RW-Meta在LDP背景下没有额外隐私成本，且后悔界限与专家间的独立性程度成反比。在COVID-19医院数据上，RW-Meta比传统基线和最先进的中心化DP算法性能提升1.5-3倍。

Conclusion: 该研究成功开发了在局部差分隐私约束下进行专家建议预测的有效算法，特别是在真实医疗数据上展示了优越性能，为隐私保护的在线学习提供了新方法。

Abstract: We study the classic problem of prediction with expert advice under the constraint of local differential privacy (LDP). In this context, we first show that a classical algorithm naturally satisfies LDP and then design two new algorithms that improve it: RW-AdaBatch and RW-Meta. For RW-AdaBatch, we exploit the limited-switching behavior induced by LDP to provide a novel form of privacy amplification that grows stronger on easier data, analogous to the shuffle model in offline learning. Drawing on the theory of random walks, we prove that this improvement carries essentially no utility cost. For RW-Meta, we develop a general method for privately selecting between experts that are themselves non-trivial learning algorithms, and we show that in the context of LDP this carries no extra privacy cost. In contrast, prior work has only considered data-independent experts. We also derive formal regret bounds that scale inversely with the degree of independence between experts. Our analysis is supplemented by evaluation on real-world data reported by hospitals during the COVID-19 pandemic; RW-Meta outperforms both the classical baseline and a state-of-the-art \textit{central} DP algorithm by 1.5-3$\times$ on the task of predicting which hospital will report the highest density of COVID patients each week.

</details>


### [247] [LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding](https://arxiv.org/abs/2512.06982)
*Yu Yu,Qian Xie,Nairen Cao,Li Jin*

Main category: cs.LG

TL;DR: 提出一种基于大语言模型的神经架构搜索方法，用于设计多源强化学习中的复合状态编码器，相比传统NAS方法能以更少评估次数发现性能更好的架构。


<details>
  <summary>Details</summary>
Motivation: 多源强化学习中需要处理传感器测量、时序信号、图像观测和文本指令等多种信息源，现有的状态编码器设计方法通常需要手动设计且缺乏系统性探索。现有的神经架构搜索方法忽略了模块中间输出的有用信息，限制了多源强化学习中的样本效率。

Method: 将多源状态编码器设计形式化为复合神经架构搜索问题，提出基于大语言模型的NAS流程，利用语言模型先验和中间输出信号来指导样本高效的搜索过程。该方法联合优化多个源特定模块和一个融合模块。

Result: 在混合自主交通控制任务上，该方法相比传统NAS基准和基于LLM的GENIUS框架，能够以更少的候选评估次数发现性能更高的架构。

Conclusion: 提出的LLM驱动的NAS方法能够有效解决多源强化学习中复合状态编码器的设计问题，通过利用语言模型先验和中间输出信息，实现了更高效的架构搜索。

Abstract: Designing state encoders for reinforcement learning (RL) with multiple information sources -- such as sensor measurements, time-series signals, image observations, and textual instructions -- remains underexplored and often requires manual design. We formalize this challenge as a problem of composite neural architecture search (NAS), where multiple source-specific modules and a fusion module are jointly optimized. Existing NAS methods overlook useful side information from the intermediate outputs of these modules -- such as their representation quality -- limiting sample efficiency in multi-source RL settings. To address this, we propose an LLM-driven NAS pipeline that leverages language-model priors and intermediate-output signals to guide sample-efficient search for high-performing composite state encoders. On a mixed-autonomy traffic control task, our approach discovers higher-performing architectures with fewer candidate evaluations than traditional NAS baselines and the LLM-based GENIUS framework.

</details>


### [248] [OXtal: An All-Atom Diffusion Model for Organic Crystal Structure Prediction](https://arxiv.org/abs/2512.06987)
*Emily Jin,Andrei Cristian Nica,Mikhail Galkin,Jarrid Rector-Brooks,Kin Long Kelvin Lee,Santiago Miret,Frances H. Arnold,Michael Bronstein,Avishek Joey Bose,Alexander Tong,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: OXtal是一个100M参数的全原子扩散模型，直接从2D化学图预测3D分子晶体结构，通过数据增强和晶格无关训练方案，在600K实验验证晶体结构上实现数量级改进。


<details>
  <summary>Details</summary>
Motivation: 从2D化学图准确预测实验可实现的3D分子晶体结构是计算化学中长期存在的开放挑战（晶体结构预测CSP）。高效解决这个问题对制药、有机半导体等领域有重要意义，因为晶体堆积直接影响有机固体的物理化学性质。

Method: 提出OXtal大规模全原子扩散模型，放弃显式等变架构，采用数据增强策略；提出新颖的结晶启发式晶格无关训练方案S^4（Stoichiometric Stochastic Shell Sampling），高效捕获长程相互作用，避免显式晶格参数化。

Result: 在600K实验验证晶体结构数据集上，OXtal相比先前的从头算机器学习CSP方法实现数量级改进，同时比传统量子化学方法便宜数量级。具体恢复实验结构时，构象RMSD1<0.5 Å，达到超过80%的堆积相似率。

Conclusion: OXtal能够建模分子结晶的热力学和动力学规律，展示了直接从化学图预测晶体结构的可行性，为晶体结构预测领域提供了高效准确的解决方案。

Abstract: Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion model that directly learns the conditional joint distribution over intramolecular conformations and periodic packing. To efficiently scale OXtal, we abandon explicit equivariant architectures imposing inductive bias arising from crystal symmetries in favor of data augmentation strategies. We further propose a novel crystallization-inspired lattice-free training scheme, Stoichiometric Stochastic Shell Sampling ($S^4$), that efficiently captures long-range interactions while sidestepping explicit lattice parametrization -- thus enabling more scalable architectural choices at all-atom resolution. By leveraging a large dataset of 600K experimentally validated crystal structures (including rigid and flexible molecules, co-crystals, and solvates), OXtal achieves orders-of-magnitude improvements over prior ab initio machine learning CSP methods, while remaining orders of magnitude cheaper than traditional quantum-chemical approaches. Specifically, OXtal recovers experimental structures with conformer $\text{RMSD}_1<0.5$ Å and attains over 80\% packing similarity rate, demonstrating its ability to model both thermodynamic and kinetic regularities of molecular crystallization.

</details>


### [249] [Toward Reliable Machine Unlearning: Theory, Algorithms, and Evaluation](https://arxiv.org/abs/2512.06993)
*Ali Ebrahimpour-Boroojeny*

Main category: cs.LG

TL;DR: 本文提出了两种新的机器学习遗忘方法：AMUN用于样本遗忘，TRW用于类别遗忘，均优于现有方法。AMUN通过对抗样本降低模型对遗忘样本的置信度，TRW通过调整类别分布来模拟从头训练模型的行为。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘方法在保护隐私和合规性方面存在不足，无法有效模拟从头训练模型的行为，导致隐私泄露风险。需要开发更有效的遗忘方法来确保模型在移除特定数据或类别后不会泄露原始训练信息。

Method: 1. AMUN方法：通过生成对抗样本来微调模型，降低模型对遗忘样本的置信度，同时保持对保留样本的性能。2. FastClip方法：通过层谱范数裁剪控制模型的Lipschitz常数，提高模型平滑性。3. TRW方法：通过估计类别间相似性，调整目标分布来模拟从头训练模型的行为。

Result: AMUN在图像分类任务中超越了现有最先进的遗忘方法，基于SOTA MIA评分。TRW在多个基准测试中匹配或超越了现有遗忘方法。研究还发现模型平滑性提高有助于对抗样本的迁移，支持了AMUN的性能提升。

Conclusion: 本文提出的AMUN和TRW方法为机器学习的样本遗忘和类别遗忘提供了有效的解决方案，能够更好地保护隐私并满足合规要求。这些方法通过模拟从头训练模型的行为，显著降低了隐私泄露风险。

Abstract: We propose new methodologies for both unlearning random set of samples and class unlearning and show that they outperform existing methods. The main driver of our unlearning methods is the similarity of predictions to a retrained model on both the forget and remain samples. We introduce Adversarial Machine UNlearning (AMUN), which surpasses prior state-of-the-art methods for image classification based on SOTA MIA scores. AMUN lowers the model's confidence on forget samples by fine-tuning on their corresponding adversarial examples. Through theoretical analysis, we identify factors governing AMUN's performance, including smoothness. To facilitate training of smooth models with a controlled Lipschitz constant, we propose FastClip, a scalable method that performs layer-wise spectral-norm clipping of affine layers. In a separate study, we show that increased smoothness naturally improves adversarial example transfer, thereby supporting the second factor above.
  Following the same principles for class unlearning, we show that existing methods fail in replicating a retrained model's behavior by introducing a nearest-neighbor membership inference attack (MIA-NN) that uses the probabilities assigned to neighboring classes to detect unlearned samples and demonstrate the vulnerability of such methods. We then propose a fine-tuning objective that mitigates this leakage by approximating, for forget-class inputs, the distribution over remaining classes that a model retrained from scratch would produce. To construct this approximation, we estimate inter-class similarity and tilt the target model's distribution accordingly. The resulting Tilted ReWeighting(TRW) distribution serves as the desired target during fine-tuning. Across multiple benchmarks, TRW matches or surpasses existing unlearning methods on prior metrics.

</details>


### [250] [Block Sparse Flash Attention](https://arxiv.org/abs/2512.07011)
*Daniel Ohayon,Itay Lamprecht,Itay Hubara,Israel Cohen,Daniel Soudry,Noam Elata*

Main category: cs.LG

TL;DR: BSFA是一种无需训练的注意力加速方法，通过计算精确的查询-键相似度来选择最重要的值块，跳过约50%的计算和内存传输，在保持模型质量的同时实现长上下文推理加速。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型需要处理长上下文，但注意力机制的二次复杂度造成了严重的计算瓶颈，需要一种既能加速推理又能保持模型质量的解决方案。

Method: BSFA通过计算精确的查询-键相似度，为每个查询选择top-k最重要的值块，通过比较每个块的最大分数与校准阈值，跳过约50%的计算和内存传输。该方法无需训练，只需在小数据集上进行一次性阈值校准来学习每层和每个头的注意力分数分布。

Result: 在Llama-3.1-8B上，BSFA在真实世界推理基准测试中实现最高1.10倍加速，在"大海捞针"检索任务中实现最高1.24倍加速，同时保持99%以上的基线准确率，某些配置甚至通过关注最相关内容提高了准确率，显著优于现有的稀疏注意力方法。

Conclusion: BSFA是一种有效的训练无关注意力加速方法，可作为FlashAttention的直接替代品，在保持模型质量的同时显著加速长上下文推理，为解决注意力二次复杂度瓶颈提供了实用解决方案。

Abstract: Modern large language models increasingly require long contexts for reasoning and multi-document tasks, but attention's quadratic complexity creates a severe computational bottleneck. We present Block-Sparse FlashAttention (BSFA), a drop-in replacement that accelerates long-context inference while preserving model quality. Unlike methods that predict importance before computing scores, BSFA computes exact query-key similarities to select the top-k most important value blocks for each query. By comparing per-block maximum scores against calibrated thresholds, we skip approximately 50% of the computation and memory transfers for pruned blocks. Our training-free approach requires only a one-time threshold calibration on a small dataset to learn the per-layer and per-head attention score distributions. We provide a CUDA kernel implementation that can be used as a drop-in replacement for FlashAttention. On Llama-3.1-8B, BSFA achieves up to 1.10x speedup on real-world reasoning benchmarks and up to 1.24x for needle-in-a-haystack retrieval tasks while maintaining above 99% baseline accuracy, with certain configurations even improving accuracy by focusing on the most relevant content, substantially outperforming existing sparse attention methods. The implementation is available at https://github.com/Danielohayon/Block-Sparse-Flash-Attention

</details>


### [251] [Transferring Clinical Knowledge into ECGs Representation](https://arxiv.org/abs/2512.07021)
*Jose Geraldo Fernandes,Luiz Facury de Souza,Pedro Robles Dutenhefner,Gisele L. Pappa,Wagner Meira*

Main category: cs.LG

TL;DR: 提出一种三阶段训练范式，通过多模态临床数据预训练增强单模态心电图编码器性能，同时通过预测实验室异常指标提供模型解释性


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在心电图分类中表现出高准确性，但其黑盒性质缺乏可解释性，阻碍了临床采用。需要开发既准确又可信赖的心电图分类模型。

Method: 提出三阶段训练范式：1）自监督联合嵌入预训练，从多模态临床数据（实验室检查、生命体征、生物特征）中转移知识到心电图编码器；2）仅使用心电图信号进行推理；3）训练模型从心电图嵌入中预测相关实验室异常，作为间接解释模型输出的方法

Result: 在MIMIC-IV-ECG数据集上评估，模型在多标签诊断分类中优于标准信号基线，显著缩小了与需要所有数据推理的完全多模态模型之间的性能差距

Conclusion: 该方法为创建更准确、可信赖的心电图分类模型提供了实用有效的方法，通过将抽象预测转化为基于生理学的解释，为AI安全集成到临床工作流程提供了有前景的路径

Abstract: Deep learning models have shown high accuracy in classifying electrocardiograms (ECGs), but their black box nature hinders clinical adoption due to a lack of trust and interpretability. To address this, we propose a novel three-stage training paradigm that transfers knowledge from multimodal clinical data (laboratory exams, vitals, biometrics) into a powerful, yet unimodal, ECG encoder. We employ a self-supervised, joint-embedding pre-training stage to create an ECG representation that is enriched with contextual clinical information, while only requiring the ECG signal at inference time. Furthermore, as an indirect way to explain the model's output we train it to also predict associated laboratory abnormalities directly from the ECG embedding. Evaluated on the MIMIC-IV-ECG dataset, our model outperforms a standard signal-only baseline in multi-label diagnosis classification and successfully bridges a substantial portion of the performance gap to a fully multimodal model that requires all data at inference. Our work demonstrates a practical and effective method for creating more accurate and trustworthy ECG classification models. By converting abstract predictions into physiologically grounded \emph{explanations}, our approach offers a promising path toward the safer integration of AI into clinical workflows.

</details>


### [252] [Self-Supervised Learning on Molecular Graphs: A Systematic Investigation of Masking Design](https://arxiv.org/abs/2512.07064)
*Jiannan Yang,Veronika Thost,Tengfei Ma*

Main category: cs.LG

TL;DR: 该研究将分子图的自监督学习预训练-微调流程统一到概率框架中，通过控制实验评估掩码策略的三个核心设计维度，发现对于节点级预测任务，复杂掩码分布相比均匀采样并无优势，而预测目标与编码器架构的协同更为关键。


<details>
  <summary>Details</summary>
Motivation: 当前分子表示学习中，许多基于掩码的预训练方法创新缺乏系统性评估，难以确定哪些设计选择真正有效。研究旨在通过统一框架实现掩码策略的透明比较和深入理解。

Method: 将整个预训练-微调流程统一到概率框架中，在严格控制条件下研究三个核心设计维度：掩码分布、预测目标和编码器架构。使用信息论度量评估预训练信号的信息量，并将其与下游性能基准测试相关联。

Result: 研究发现：1）对于常见节点级预测任务，复杂掩码分布相比均匀采样没有一致优势；2）预测目标的选择及其与编码器架构的协同更为关键；3）转向语义更丰富的预测目标能带来显著的下游性能提升，特别是与表达能力强的图Transformer编码器结合时。

Conclusion: 研究为开发更有效的分子图自监督学习方法提供了实用指导：应更关注预测目标的选择及其与编码器架构的协同，而非过度优化掩码分布策略。

Abstract: Self-supervised learning (SSL) plays a central role in molecular representation learning. Yet, many recent innovations in masking-based pretraining are introduced as heuristics and lack principled evaluation, obscuring which design choices are genuinely effective. This work cast the entire pretrain-finetune workflow into a unified probabilistic framework, enabling a transparent comparison and deeper understanding of masking strategies. Building on this formalism, we conduct a controlled study of three core design dimensions: masking distribution, prediction target, and encoder architecture, under rigorously controlled settings. We further employ information-theoretic measures to assess the informativeness of pretraining signals and connect them to empirically benchmarked downstream performance. Our findings reveal a surprising insight: sophisticated masking distributions offer no consistent benefit over uniform sampling for common node-level prediction tasks. Instead, the choice of prediction target and its synergy with the encoder architecture are far more critical. Specifically, shifting to semantically richer targets yields substantial downstream improvements, particularly when paired with expressive Graph Transformer encoders. These insights offer practical guidance for developing more effective SSL methods for molecular graphs.

</details>


### [253] [Procrustean Bed for AI-Driven Retrosynthesis: A Unified Framework for Reproducible Evaluation](https://arxiv.org/abs/2512.07079)
*Anton Morgunov,Victor S. Batista*

Main category: cs.LG

TL;DR: RetroCast是一个统一的评估套件，用于标准化计算机辅助合成规划（CASP）模型的评估，通过分层抽样和置信区间提供统计严谨的比较，揭示高"可解性"分数与化学有效性之间的差异。


<details>
  <summary>Details</summary>
Motivation: 当前计算机辅助合成规划领域缺乏标准化评估基础设施，现有指标过于关注拓扑完成度而忽视化学有效性，导致模型比较困难且结果不可靠。

Method: 开发RetroCast评估套件，将异构模型输出标准化为统一模式；建立可复现的基准测试流程，包含分层抽样和自助法置信区间；创建SynthArena交互平台用于定性路线检查；使用该基础设施评估主流搜索基和序列基算法。

Result: 分析发现"可解性"（库存终止率）与路线质量存在差异：高可解性分数常掩盖化学无效性或与实验真实情况不符；识别出"复杂性悬崖"现象，搜索基方法在重建长程合成计划时性能急剧下降，而序列基方法表现更好。

Conclusion: RetroCast为CASP领域提供了透明、可复现的评估框架，揭示了当前评估指标的局限性，并发布了完整框架、基准定义和标准化预测数据库以支持该领域的健康发展。

Abstract: Progress in computer-aided synthesis planning (CASP) is obscured by the lack of standardized evaluation infrastructure and the reliance on metrics that prioritize topological completion over chemical validity. We introduce RetroCast, a unified evaluation suite that standardizes heterogeneous model outputs into a common schema to enable statistically rigorous, apples-to-apples comparison. The framework includes a reproducible benchmarking pipeline with stratified sampling and bootstrapped confidence intervals, accompanied by SynthArena, an interactive platform for qualitative route inspection. We utilize this infrastructure to evaluate leading search-based and sequence-based algorithms on a new suite of standardized benchmarks. Our analysis reveals a divergence between "solvability" (stock-termination rate) and route quality; high solvability scores often mask chemical invalidity or fail to correlate with the reproduction of experimental ground truths. Furthermore, we identify a "complexity cliff" in which search-based methods, despite high solvability rates, exhibit a sharp performance decay in reconstructing long-range synthetic plans compared to sequence-based approaches. We release the full framework, benchmark definitions, and a standardized database of model predictions to support transparent and reproducible development in the field.

</details>


### [254] [TRACE: A Generalizable Drift Detector for Streaming Data-Driven Optimization](https://arxiv.org/abs/2512.07082)
*Yuan-Ting Zhong,Ting Huang,Xiaolin Xiao,Yue-Jiao Gong*

Main category: cs.LG

TL;DR: TRACE是一个可迁移的概念漂移估计器，用于检测流数据中的分布变化，具有跨数据集泛化能力，可集成到流优化器中实现自适应优化。


<details>
  <summary>Details</summary>
Motivation: 流数据驱动的优化任务面临未知概念漂移的挑战，现有方法通常基于固定漂移间隔和完全环境可观测性等限制性假设，难以适应多样化的动态环境。

Method: TRACE采用原则性的标记化策略从数据流中提取统计特征，使用基于注意力的序列学习建模漂移模式，实现跨数据集的概念漂移检测。

Result: 在多样化基准测试中，TRACE展现出优越的泛化能力、鲁棒性和有效性，能够准确检测未见数据集中的概念漂移。

Conclusion: TRACE作为一个即插即用的概念漂移检测器，能够有效提升流数据驱动优化在未知漂移环境下的自适应能力，具有实际应用价值。

Abstract: Many optimization tasks involve streaming data with unknown concept drifts, posing a significant challenge as Streaming Data-Driven Optimization (SDDO). Existing methods, while leveraging surrogate model approximation and historical knowledge transfer, are often under restrictive assumptions such as fixed drift intervals and fully environmental observability, limiting their adaptability to diverse dynamic environments. We propose TRACE, a TRAnsferable C}oncept-drift Estimator that effectively detects distributional changes in streaming data with varying time scales. TRACE leverages a principled tokenization strategy to extract statistical features from data streams and models drift patterns using attention-based sequence learning, enabling accurate detection on unseen datasets and highlighting the transferability of learned drift patterns. Further, we showcase TRACE's plug-and-play nature by integrating it into a streaming optimizer, facilitating adaptive optimization under unknown drifts. Comprehensive experimental results on diverse benchmarks demonstrate the superior generalization, robustness, and effectiveness of our approach in SDDO scenarios.

</details>


### [255] [The Geometry of Persona: Disentangling Personality from Reasoning in Large Language Models](https://arxiv.org/abs/2512.07092)
*Zhixiang Wang*

Main category: cs.LG

TL;DR: Soul Engine框架通过线性表示假设，在不微调基础模型的情况下实现个性化LLM，解决了稳定性-可塑性困境，避免了"对齐税"问题。


<details>
  <summary>Details</summary>
Motivation: 当前个性化大语言模型的部署受到稳定性-可塑性困境的限制，传统对齐方法（如监督微调）依赖随机权重更新，常常导致"对齐税"——降低通用推理能力。

Method: 基于线性表示假设，提出Soul Engine框架，认为人格特质存在于正交线性子空间中。通过动态上下文采样构建SoulBench数据集，在冻结的Qwen-2.5基础模型上使用双头架构提取解耦的人格向量，不修改主干权重。

Result: 实验展示了三个突破：1) 高精度分析：模型对心理学真实数据的均方误差为0.011；2) 几何正交性：T-SNE可视化确认人格流形是独特且连续的，支持"零样本人格注入"同时保持原始模型智能；3) 确定性引导：通过向量运算实现行为稳健控制，并通过广泛消融研究验证。

Conclusion: 这项工作挑战了微调对个性化的必要性。通过从概率提示转向确定性潜在干预，为安全、可控的AI个性化提供了数学严谨的基础。

Abstract: Background: The deployment of personalized Large Language Models (LLMs) is currently constrained by the stability-plasticity dilemma. Prevailing alignment methods, such as Supervised Fine-Tuning (SFT), rely on stochastic weight updates that often incur an "alignment tax" -- degrading general reasoning capabilities.
  Methods: We propose the Soul Engine, a framework based on the Linear Representation Hypothesis, which posits that personality traits exist as orthogonal linear subspaces. We introduce SoulBench, a dataset constructed via dynamic contextual sampling. Using a dual-head architecture on a frozen Qwen-2.5 base, we extract disentangled personality vectors without modifying the backbone weights.
  Results: Our experiments demonstrate three breakthroughs. First, High-Precision Profiling: The model achieves a Mean Squared Error (MSE) of 0.011 against psychological ground truth. Second, Geometric Orthogonality: T-SNE visualization confirms that personality manifolds are distinct and continuous, allowing for "Zero-Shot Personality Injection" that maintains original model intelligence. Third, Deterministic Steering: We achieve robust control over behavior via vector arithmetic, validated through extensive ablation studies.
  Conclusion: This work challenges the necessity of fine-tuning for personalization. By transitioning from probabilistic prompting to deterministic latent intervention, we provide a mathematically rigorous foundation for safe, controllable AI personalization.

</details>


### [256] [FOAM: Blocked State Folding for Memory-Efficient LLM Training](https://arxiv.org/abs/2512.07112)
*Ziqing Wen,Jiahuan Wang,Ping Luo,Dongsheng Li,Tao Sun*

Main category: cs.LG

TL;DR: FOAM是一种通过计算分块梯度均值压缩优化器状态的内存高效优化方法，在保持Adam收敛速度的同时减少约50%训练内存和90%优化器状态内存开销。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练面临严重内存瓶颈，特别是使用Adam等内存密集型优化器时。现有内存高效方法存在计算开销大、需要额外内存或性能下降等问题。

Method: 提出FOAM方法：通过计算分块梯度均值压缩优化器状态，并引入残差校正来恢复丢失的信息，理论上在非凸优化设置下能达到与标准Adam相当的收敛速度。

Result: FOAM减少约50%总训练内存，消除高达90%的优化器状态内存开销，加速收敛，且与其他内存高效优化器兼容，性能匹配或超越现有基准。

Conclusion: FOAM是一种有效解决LLM训练内存瓶颈的方法，在保持性能的同时显著减少内存使用，为大规模模型训练提供了实用的内存高效优化方案。

Abstract: Large language models (LLMs) have demonstrated remarkable performance due to their large parameter counts and extensive training data. However, their scale leads to significant memory bottlenecks during training, especially when using memory-intensive optimizers like Adam. Existing memory-efficient approaches often rely on techniques such as singular value decomposition (SVD), projections, or weight freezing, which can introduce substantial computational overhead, require additional memory for projections, or degrade model performance. In this paper, we propose Folded Optimizer with Approximate Moment (FOAM), a method that compresses optimizer states by computing block-wise gradient means and incorporates a residual correction to recover lost information. Theoretically, FOAM achieves convergence rates equivalent to vanilla Adam under standard non-convex optimization settings. Empirically, FOAM reduces total training memory by approximately 50\%, eliminates up to 90\% of optimizer state memory overhead, and accelerates convergence. Furthermore, FOAM is compatible with other memory-efficient optimizers, delivering performance and throughput that match or surpass both full-rank and existing memory-efficient baselines.

</details>


### [257] [PlantBiMoE: A Bidirectional Foundation Model with SparseMoE for Plant Genomes](https://arxiv.org/abs/2512.07113)
*Kepeng Lin,Qizhe Zhang,Rui Wang,Xuehai Hu,Wei Xu*

Main category: cs.LG

TL;DR: PlantBiMoE：一个轻量级且表达能力强的植物基因组语言模型，结合双向Mamba和稀疏专家混合框架，在31个数据集上取得20个最佳性能


<details>
  <summary>Details</summary>
Motivation: 现有植物基因组模型如AgroNT和PDLLMs存在参数过大或无法有效建模DNA双链双向性的问题，需要开发更高效且能捕捉双向依赖的模型

Method: 提出PlantBiMoE模型，集成双向Mamba以捕捉DNA正反链的结构依赖，采用稀疏专家混合框架减少活跃参数数量，提高计算效率

Result: 在MPGB基准测试中，PlantBiMoE在31个数据集的20个上取得最佳性能，平均表现优于现有模型，序列长度范围50-6000bp

Conclusion: PlantBiMoE能有效表示植物基因组序列，为植物基因组学、基因编辑和合成生物学提供强大计算工具，代码已开源

Abstract: Understanding the underlying linguistic rules of plant genomes remains a fundamental challenge in computational biology. Recent advances including AgroNT and PDLLMs have made notable progress although, they suffer from excessive parameter size and limited ability to model the bidirectional nature of DNA strands respectively. To address these limitations, we propose PlantBiMoE, a lightweight and expressive plant genome language model that integrates bidirectional Mamba and a Sparse Mixture-of-Experts (SparseMoE) framework. The bidirectional Mamba enables the model to effectively capture structural dependencies across both the forward and reverse DNA strands, while SparseMoE significantly reduces the number of active parameters, improving computational efficiency without sacrificing modeling capacity. We evaluated and tested our model on the Modified Plants Genome Benchmark (MPGB), an enhanced genomic benchmark, which consolidates 31 datasets across 11 representative tasks, with input sequence lengths ranging from 50 to 6,000 bp. Experimental results demonstrate that PlantBiMoE achieves the best performance on 20 out of 31 datasets and the average best when comparing with existing models. In summary, all above results demonstrate that our model can effectively represent plant genomic sequences, serving as a robust computational tool for diverse genomic tasks, while making substantive contributions to plant genomics, gene editing, and synthetic biology. The code is available at: https://github.com/HUST-Keep-Lin/PlantBiMoE

</details>


### [258] [FlowLPS: Langevin-Proximal Sampling for Flow-based Inverse Problem Solvers](https://arxiv.org/abs/2512.07150)
*Jonghyun Park,Jong Chul Ye*

Main category: cs.LG

TL;DR: FlowLPS：一种基于预训练流模型解决逆问题的新框架，通过Langevin Proximal Sampling策略，在FFHQ和DIV2K数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的训练自由方法在应用于潜在流模型时，常常无法收敛到后验模式或在潜在空间中遭受流形偏差。需要一种能够平衡重建保真度和感知质量的新方法。

Method: 提出FlowLPS框架，结合Langevin动力学进行流形一致探索和近端优化进行精确模式搜索，形成Langevin Proximal Sampling策略。

Result: 在FFHQ和DIV2K数据集上的多个逆任务中，FlowLPS在重建保真度和感知质量之间实现了优越的平衡，超越了现有的最先进逆问题求解器。

Conclusion: FlowLPS为使用预训练流模型解决逆问题提供了一个有效的训练自由框架，通过Langevin Proximal Sampling策略解决了现有方法的收敛和流形偏差问题。

Abstract: Deep generative models have become powerful priors for solving inverse problems, and various training-free methods have been developed. However, when applied to latent flow models, existing methods often fail to converge to the posterior mode or suffer from manifold deviation within latent spaces. To mitigate this, here we introduce a novel training-free framework, FlowLPS, that solves inverse problems with pretrained flow models via a Langevin Proximal Sampling (LPS) strategy. Our method integrates Langevin dynamics for manifold-consistent exploration with proximal optimization for precise mode seeking, achieving a superior balance between reconstruction fidelity and perceptual quality across multiple inverse tasks on FFHQ and DIV2K, outperforming state of the art inverse solvers.

</details>


### [259] [Improving the Throughput of Diffusion-based Large Language Models via a Training-Free Confidence-Aware Calibration](https://arxiv.org/abs/2512.07173)
*Jucheng Shen,Gaurav Sarkar,Yeonju Ro,Sharath Nittur Sridhar,Zhangyang Wang,Aditya Akella,Souvik Kundu*

Main category: cs.LG

TL;DR: CadLLM是一种无需训练的方法，通过动态调整生成块大小、步长和阈值来加速基于扩散的大语言模型推理吞吐量，同时通过动态词汇子集减少softmax开销，实现最高2.28倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型推理速度较慢，现有方法存在效率瓶颈。研究者观察到token unmasking置信度在不同块和步骤间存在动态变化，这为优化推理效率提供了机会。

Method: 1. 分析token unmasking置信度在块和步骤间的动态特性；2. 基于平均置信度设计轻量级自适应方法，控制生成块大小、步长和阈值；3. 通过动态利用词汇子集减少softmax计算开销；4. 兼容基于KV缓存的扩散大语言模型，即插即用。

Result: 在四个流行任务上的实验表明，CadLLM相比最先进的基线方法，在保持竞争性准确度的同时，实现了最高2.28倍的吞吐量提升。

Conclusion: CadLLM是一种有效且通用的扩散大语言模型推理加速方法，无需额外训练，通过自适应策略显著提升推理效率，同时保持模型性能。

Abstract: We present CadLLM, a training-free method to accelerate the inference throughput of diffusion-based LLMs (dLLMs). We first investigate the dynamic nature of token unmasking confidence across blocks and steps. Based on this observation, we present a lightweight adaptive approach that controls the generation block size, step size, and threshold based on the average confidence of unmasked tokens. We further reduce softmax overhead by dynamically leveraging a subset of the vocabulary to regulate sampling breadth. CadLLM is a plug-and-play, model-agnostic method compatible with KV-cache-based dLLMs. Extensive experiments on four popular tasks demonstrate that CadLLM yields up to 2.28x throughput improvement over the state-of-the-art baseline with competitive accuracy.

</details>


### [260] [SPACE: Noise Contrastive Estimation Stabilizes Self-Play Fine-Tuning for Large Language Models](https://arxiv.org/abs/2512.07175)
*Yibo Wang,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Lijun Zhang*

Main category: cs.LG

TL;DR: SPACE是一种新的自博弈微调方法，通过噪声对比估计来捕捉真实数据分布，解决了现有基于奖励差距方法的稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有自博弈微调方法主要关注真实数据和合成数据之间的奖励差距，忽略了绝对奖励值，导致目标函数可能退化，存在不稳定的演化问题。

Method: 提出SPACE方法，使用噪声对比估计将合成样本作为辅助成分，以二分类方式区分真实数据和合成数据，独立优化每种数据的绝对奖励值。

Result: 理论上证明SPACE的最优解与真实数据的基础分布一致，并能保证稳定收敛；实证显示SPACE在各种任务上显著提升LLM性能，优于使用更多真实样本的监督微调。

Conclusion: SPACE通过噪声对比估计解决了自博弈微调中的稳定性问题，在理论和实证上都表现出优越性能，为有限真实数据下的LLM微调提供了更稳定有效的方法。

Abstract: Self-play fine-tuning has demonstrated promising abilities in adapting large language models (LLMs) to downstream tasks with limited real-world data. The basic principle is to iteratively refine the model with real samples and synthetic ones generated from itself. However, the existing methods primarily focus on the relative gaps between the rewards for two types of data, neglecting their absolute values. Through theoretical analysis, we identify that the gap-based methods suffer from unstable evolution, due to the potentially degenerated objectives. To address this limitation, we introduce a novel self-play fine-tuning method, namely Self-PlAy via Noise Contrastive Estimation (SPACE), which leverages noise contrastive estimation to capture the real-world data distribution. Specifically, SPACE treats synthetic samples as auxiliary components, and discriminates them from the real ones in a binary classification manner. As a result, SPACE independently optimizes the absolute reward values for each type of data, ensuring a consistently meaningful objective and thereby avoiding the instability issue. Theoretically, we show that the optimal solution of the objective in SPACE aligns with the underlying distribution of real-world data, and SPACE guarantees a provably stable convergence to the optimal distribution. Empirically, we show that SPACE significantly improves the performance of LLMs over various tasks, and outperforms supervised fine-tuning that employs much more real-world samples. Compared to gap-based self-play fine-tuning methods, SPACE exhibits remarkable superiority and stable evolution.

</details>


### [261] [UniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting](https://arxiv.org/abs/2512.07184)
*Da Zhang,Bingyu Li,Zhuyuan Zhao,Junyu Gao,Feiping Nie,Xuelong Li*

Main category: cs.LG

TL;DR: UniDiff是一个用于多模态时间序列预测的统一扩散框架，能够同时处理数值序列、时间戳和文本信息，通过并行融合模块和新型分类器自由引导机制实现跨模态信息的高效整合。


<details>
  <summary>Details</summary>
Motivation: 随着多模态数据在现实应用中的激增，利用文本和时间戳等异构信息进行准确的时间序列预测成为关键挑战。现有的扩散模型主要局限于单模态数值序列建模，忽视了复杂异构数据中丰富的跨模态信号。

Method: 1) 将时间序列分块并映射到嵌入空间；2) 核心是统一的并行融合模块，使用单一交叉注意力机制在一步中自适应地加权和整合时间戳的结构信息和文本的语义上下文；3) 引入针对多源条件的新型分类器自由引导机制，可在推理过程中解耦控制文本和时间信息的引导强度。

Result: 在八个领域的真实世界基准数据集上进行广泛实验，结果表明UniDiff模型实现了最先进的性能。

Conclusion: UniDiff通过统一扩散框架有效解决了多模态时间序列预测问题，能够灵活高效地整合异构信息，显著提升了模型鲁棒性和预测准确性。

Abstract: As multimodal data proliferates across diverse real-world applications, leveraging heterogeneous information such as texts and timestamps for accurate time series forecasting (TSF) has become a critical challenge. While diffusion models demonstrate exceptional performance in generation tasks, their application to TSF remains largely confined to modeling single-modality numerical sequences, overlooking the abundant cross-modal signals inherent in complex heterogeneous data. To address this gap, we propose UniDiff, a unified diffusion framework for multimodal time series forecasting. To process the numerical sequence, our framework first tokenizes the time series into patches, preserving local temporal dynamics by mapping each patch to an embedding space via a lightweight MLP. At its core lies a unified and parallel fusion module, where a single cross-attention mechanism adaptively weighs and integrates structural information from timestamps and semantic context from texts in one step, enabling a flexible and efficient interplay between modalities. Furthermore, we introduce a novel classifier-free guidance mechanism designed for multi-source conditioning, allowing for decoupled control over the guidance strength of textual and temporal information during inference, which significantly enhances model robustness. Extensive experiments on real-world benchmark datasets across eight domains demonstrate that the proposed UniDiff model achieves state-of-the-art performance.

</details>


### [262] [Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction](https://arxiv.org/abs/2512.07200)
*Zhen Huang,Jiaxin Deng,Jiayu Xu,Junbiao Pang,Haitao Yu*

Main category: cs.LG

TL;DR: 提出基于强化学习的非均匀道路分段方法，用于公交车到达时间预测，通过两阶段解耦实现高效自适应分段，优于传统均匀分段方法。


<details>
  <summary>Details</summary>
Motivation: 传统公交车到达时间预测系统采用均匀道路分段策略，无法考虑道路条件、交叉口、兴趣点等物理约束的变化，限制了预测效率。需要一种能够自适应学习非均匀道路分段的方法来提升预测性能。

Method: 提出基于强化学习的两阶段方法：1）使用RL框架根据影响分数提取非均匀道路分段；2）在线性预测模型中对选定分段进行预测。该方法在保持计算效率的同时实现最优分段选择。

Result: 实验结果表明，该方法在大规模基准测试中不仅提高了效率，还提升了学习性能。线性方法甚至比更复杂的方法表现更好，证明了"少即是多"的理念。

Conclusion: 基于强化学习的自适应非均匀道路分段方法显著优于传统均匀分段策略，为公交车到达时间预测提供了更高效、更准确的解决方案。数据集和代码已开源。

Abstract: In bus arrival time prediction, the process of organizing road infrastructure network data into homogeneous entities is known as segmentation. Segmenting a road network is widely recognized as the first and most critical step in developing an arrival time prediction system, particularly for auto-regressive-based approaches. Traditional methods typically employ a uniform segmentation strategy, which fails to account for varying physical constraints along roads, such as road conditions, intersections, and points of interest, thereby limiting prediction efficiency. In this paper, we propose a Reinforcement Learning (RL)-based approach to efficiently and adaptively learn non-uniform road segments for arrival time prediction. Our method decouples the prediction process into two stages: 1) Non-uniform road segments are extracted based on their impact scores using the proposed RL framework; and 2) A linear prediction model is applied to the selected segments to make predictions. This method ensures optimal segment selection while maintaining computational efficiency, offering a significant improvement over traditional uniform approaches. Furthermore, our experimental results suggest that the linear approach can even achieve better performance than more complex methods. Extensive experiments demonstrate the superiority of the proposed method, which not only enhances efficiency but also improves learning performance on large-scale benchmarks. The dataset and the code are publicly accessible at: https://github.com/pangjunbiao/Less-is-More.

</details>


### [263] [Geometric Prior-Guided Federated Prompt Calibration](https://arxiv.org/abs/2512.07208)
*Fei Luo,Ziwei Zhao,Mingxuan Wang,Duoyang Li,Zhe Qian,Jiayi Tuo,Chenyue Zhou,Yanbiao Ma*

Main category: cs.LG

TL;DR: GGTPC提出了一种几何引导的文本提示校准框架，通过提供全局几何先验来直接纠正联邦提示学习中由数据异质性导致的局部训练偏差，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦提示学习（FPL）虽然提供了参数高效的协作训练方案，但其性能受到数据异质性的严重影响，导致局部训练的提示产生偏差。现有方法主要关注聚合或正则化，未能解决局部训练偏差的根本原因。

Method: 提出几何引导文本提示校准（GGTPC）框架，通过隐私保护方式在服务器端重构全局数据分布的几何先验（基于协方差矩阵），客户端使用新颖的几何先验校准层（GPCL）在训练过程中将局部特征分布与全局先验对齐。

Result: 在标签倾斜的CIFAR-100数据集上（β=0.1），GGTPC比现有最佳方法提升2.15%；在极端倾斜情况下（β=0.01），比基线提升9.17%；在域倾斜的Office-Home数据集上作为即插即用模块，将FedAvg性能提升4.60%。

Conclusion: GGTPC通过纠正局部训练偏差的根本原因，有效缓解了数据异质性问题，可作为增强各种联邦学习算法的通用模块。

Abstract: Federated Prompt Learning (FPL) offers a parameter-efficient solution for collaboratively training large models, but its performance is severely hindered by data heterogeneity, which causes locally trained prompts to become biased. Existing methods, focusing on aggregation or regularization, fail to address this root cause of local training bias. To this end, we propose Geometry-Guided Text Prompt Calibration (GGTPC), a novel framework that directly corrects this bias by providing clients with a global geometric prior. This prior, representing the shape of the global data distribution derived from the covariance matrix, is reconstructed on the server in a privacy-preserving manner. Clients then use a novel Geometry-Prior Calibration Layer (GPCL) to align their local feature distributions with this global prior during training. Extensive experiments show GGTPC's effectiveness. On the label-skewed CIFAR-100 dataset ($β$=0.1), it outperforms the state-of-the-art by 2.15\%. Under extreme skew ($β$=0.01), it improves upon the baseline by 9.17\%. Furthermore, as a plug-and-play module on the domain-skewed Office-Home dataset, it boosts FedAvg's performance by 4.60\%. These results demonstrate that GGTPC effectively mitigates data heterogeneity by correcting the fundamental local training bias, serving as a versatile module to enhance various FL algorithms.

</details>


### [264] [Pay Less Attention to Function Words for Free Robustness of Vision-Language Models](https://arxiv.org/abs/2512.07222)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Chao Shen*

Main category: cs.LG

TL;DR: FDA方法通过函数词去注意力机制解决VLM鲁棒性与性能的权衡问题，在多种攻击下显著降低攻击成功率，同时保持性能


<details>
  <summary>Details</summary>
Motivation: 研究发现函数词是VLM对抗跨模态攻击的脆弱点，需要解决鲁棒性与性能之间的权衡问题

Method: 提出函数词去注意力机制，在注意力头中计算原始注意力与函数词注意力，通过差分减法减少函数词影响

Result: 在3个模型上平均降低18/13/53%攻击成功率，性能仅下降0.2/0.3/0.6%；视觉定位任务降低90%攻击成功率，性能提升0.3%

Conclusion: FDA方法能有效提升VLM的鲁棒性，同时保持或轻微提升性能，具有良好的可扩展性和泛化能力

Abstract: To address the trade-off between robustness and performance for robust VLM, we observe that function words could incur vulnerability of VLMs against cross-modal adversarial attacks, and propose Function-word De-Attention (FDA) accordingly to mitigate the impact of function words. Similar to differential amplifiers, our FDA calculates the original and the function-word cross-attention within attention heads, and differentially subtracts the latter from the former for more aligned and robust VLMs. Comprehensive experiments include 2 SOTA baselines under 6 different attacks on 2 downstream tasks, 3 datasets, and 3 models. Overall, our FDA yields an average 18/13/53% ASR drop with only 0.2/0.3/0.6% performance drops on the 3 tested models on retrieval, and a 90% ASR drop with a 0.3% performance gain on visual grounding. We demonstrate the scalability, generalization, and zero-shot performance of FDA experimentally, as well as in-depth ablation studies and analysis. Code will be made publicly at https://github.com/michaeltian108/FDA.

</details>


### [265] [Learning-Augmented Ski Rental with Discrete Distributions: A Bayesian Approach](https://arxiv.org/abs/2512.07313)
*Bosun Kang,Hyejun Park,Chenglin Fan*

Main category: cs.LG

TL;DR: 本文重新审视经典的滑雪板租赁问题，提出基于贝叶斯决策和机器学习预测的统一框架，通过维护精确的后验分布实现不确定性量化，在准确先验下达到接近最优性能，同时保持鲁棒的worst-case保证。


<details>
  <summary>Details</summary>
Motivation: 传统算法在不做假设的情况下最小化最坏情况成本，而最近的学习增强方法利用噪声预测提供鲁棒性保证。本文旨在统一这两种视角，为具有不完美预测的在线决策问题提供更实用的解决方案。

Method: 提出离散贝叶斯框架，维护时间范围上的精确后验分布，实现原则性的不确定性量化和专家先验的无缝整合。算法能够优雅地在最坏情况和完全知情设置之间插值。

Result: 算法实现了先验依赖的竞争性保证，在广泛场景下表现出优越的实证性能：在准确先验下达到接近最优结果，同时保持鲁棒的最坏情况保证。框架自然扩展到多预测、非均匀先验和上下文信息。

Conclusion: 贝叶斯推理在具有不完美预测的在线决策问题中具有实际优势，该框架为滑雪板租赁问题提供了统一的解决方案，平衡了预测准确性和鲁棒性要求。

Abstract: We revisit the classic ski rental problem through the lens of Bayesian decision-making and machine-learned predictions. While traditional algorithms minimize worst-case cost without assumptions, and recent learning-augmented approaches leverage noisy forecasts with robustness guarantees, our work unifies these perspectives. We propose a discrete Bayesian framework that maintains exact posterior distributions over the time horizon, enabling principled uncertainty quantification and seamless incorporation of expert priors. Our algorithm achieves prior-dependent competitive guarantees and gracefully interpolates between worst-case and fully-informed settings. Our extensive experimental evaluation demonstrates superior empirical performance across diverse scenarios, achieving near-optimal results under accurate priors while maintaining robust worst-case guarantees. This framework naturally extends to incorporate multiple predictions, non-uniform priors, and contextual information, highlighting the practical advantages of Bayesian reasoning in online decision problems with imperfect predictions.

</details>


### [266] [Local-Curvature-Aware Knowledge Graph Embedding: An Extended Ricci Flow Approach](https://arxiv.org/abs/2512.07332)
*Zhengquan Luo,Guy Tadmor,Or Amar,David Zeevi,Zhiqiang Xu*

Main category: cs.LG

TL;DR: RicciKGE提出了一种将知识图谱嵌入损失梯度与局部曲率耦合的Ricci流方法，使实体嵌入与底层流形几何共同演化，自适应知识图谱的异质结构。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱嵌入方法将所有实体放置在单一均匀流形上（欧几里得、球面、双曲或其乘积/多曲率变体），但预定义的均匀流形无法适应真实图谱中局部区域急剧变化的曲率。这种几何先验与知识图谱局部曲率的不匹配会扭曲实体间距离，损害嵌入的表达能力。

Method: 提出RicciKGE方法，将KGE损失梯度与局部曲率在扩展的Ricci流中耦合，使实体嵌入与底层流形几何动态共同演化，实现相互适应。理论上证明了当耦合系数有界且适当选择时，所有边曲率呈指数衰减（流形趋向欧几里得平坦），且KGE距离严格收敛到全局最优。

Result: 在链接预测和节点分类基准测试中，RicciKGE相比现有方法表现出改进效果，证明了其在适应异质知识图谱结构方面的有效性。

Conclusion: RicciKGE通过将嵌入优化与几何平坦化相互促进，能够自适应知识图谱的异质结构，解决了传统方法中预定义均匀流形与真实图谱局部曲率不匹配的问题。

Abstract: Knowledge graph embedding (KGE) relies on the geometry of the embedding space to encode semantic and structural relations. Existing methods place all entities on one homogeneous manifold, Euclidean, spherical, hyperbolic, or their product/multi-curvature variants, to model linear, symmetric, or hierarchical patterns. Yet a predefined, homogeneous manifold cannot accommodate the sharply varying curvature that real-world graphs exhibit across local regions. Since this geometry is imposed a priori, any mismatch with the knowledge graph's local curvatures will distort distances between entities and hurt the expressiveness of the resulting KGE. To rectify this, we propose RicciKGE to have the KGE loss gradient coupled with local curvatures in an extended Ricci flow such that entity embeddings co-evolve dynamically with the underlying manifold geometry towards mutual adaptation. Theoretically, when the coupling coefficient is bounded and properly selected, we rigorously prove that i) all the edge-wise curvatures decay exponentially, meaning that the manifold is driven toward the Euclidean flatness; and ii) the KGE distances strictly converge to a global optimum, which indicates that geometric flattening and embedding optimization are promoting each other. Experimental improvements on link prediction and node classification benchmarks demonstrate RicciKGE's effectiveness in adapting to heterogeneous knowledge graph structures.

</details>


### [267] [LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples](https://arxiv.org/abs/2512.07375)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: LUNE是一个基于LoRA的轻量级遗忘框架，通过仅更新低秩适配器来执行负向遗忘，在保持主干模型冻结的同时，以极低的计算和内存成本实现知识遗忘。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然拥有海量知识，但无法按需移除特定信息，这给隐私保护、偏见缓解和知识修正带来了困难。传统的模型遗忘方法需要昂贵的微调或直接权重编辑，难以在实际部署中应用。

Method: 提出LoRA-based Unlearning with Negative Examples (LUNE)框架，采用低秩适配器技术，仅更新低秩适配器而冻结主干模型，通过针对中间表示来抑制或替换目标知识，实现负向遗忘。

Result: 在多个事实遗忘任务上的实验表明：1）LUNE在效果上与全微调和内存编辑方法相当；2）计算成本比全微调或直接权重编辑降低约一个数量级。

Conclusion: LUNE提供了一种轻量级、高效的模型遗忘解决方案，通过局部化编辑避免了破坏性的全局更改，为隐私保护、偏见缓解和知识修正等实际应用提供了可行的技术路径。

Abstract: Large language models (LLMs) possess vast knowledge acquired from extensive training corpora, but they often cannot remove specific pieces of information when needed, which makes it hard to handle privacy, bias mitigation, and knowledge correction. Traditional model unlearning approaches require computationally expensive fine-tuning or direct weight editing, making them impractical for real-world deployment. In this work, we introduce LoRA-based Unlearning with Negative Examples (LUNE), a lightweight framework that performs negative-only unlearning by updating only low-rank adapters while freezing the backbone, thereby localizing edits and avoiding disruptive global changes. Leveraging Low-Rank Adaptation (LoRA), LUNE targets intermediate representations to suppress (or replace) requested knowledge with an order-of-magnitude lower compute and memory than full fine-tuning or direct weight editing. Extensive experiments on multiple factual unlearning tasks show that LUNE: (I) achieves effectiveness comparable to full fine-tuning and memory-editing methods, and (II) reduces computational cost by about an order of magnitude.

</details>


### [268] [Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood](https://arxiv.org/abs/2512.07390)
*Gilhyun Nam,Taewon Kim,Joonhyun Jeong,Eunho Yang*

Main category: cs.LG

TL;DR: SICL框架利用风格不变性进行鲁棒不确定性估计，通过测量预测在不同风格变体间的一致性来估计实例级正确性似然，无需反向传播，可与任何TTA方法兼容。


<details>
  <summary>Details</summary>
Motivation: 测试时适应（TTA）方法虽然能高效适应部署模型，但往往导致预测不确定性校准不佳，这在自动驾驶、金融和医疗等高风险领域是关键问题。现有校准方法通常假设固定模型或静态分布，在现实世界动态测试条件下性能下降。

Method: 提出SICL框架，利用风格不变性进行鲁棒不确定性估计。通过测量预测在不同风格变体间的一致性来估计实例级正确性似然，仅需模型前向传播，无需反向传播，可作为即插即用的校准模块与任何TTA方法兼容。

Result: 在4个基线、5种TTA方法和2个现实场景、3种模型架构的综合评估中，SICL相比传统校准方法平均减少13个百分点的校准误差。

Conclusion: SICL框架通过风格不变性实现了鲁棒的不确定性估计，解决了TTA方法在动态测试环境下的校准问题，为高风险领域的模型部署提供了可靠的校准解决方案。

Abstract: Test-time adaptation (TTA) enables efficient adaptation of deployed models, yet it often leads to poorly calibrated predictive uncertainty - a critical issue in high-stakes domains such as autonomous driving, finance, and healthcare. Existing calibration methods typically assume fixed models or static distributions, resulting in degraded performance under real-world, dynamic test conditions. To address these challenges, we introduce Style Invariance as a Correctness Likelihood (SICL), a framework that leverages style-invariance for robust uncertainty estimation. SICL estimates instance-wise correctness likelihood by measuring prediction consistency across style-altered variants, requiring only the model's forward pass. This makes it a plug-and-play, backpropagation-free calibration module compatible with any TTA method. Comprehensive evaluations across four baselines, five TTA methods, and two realistic scenarios with three model architecture demonstrate that SICL reduces calibration error by an average of 13 percentage points compared to conventional calibration approaches.

</details>


### [269] [Empirical Results for Adjusting Truncated Backpropagation Through Time while Training Neural Audio Effects](https://arxiv.org/abs/2512.07393)
*Yann Bourdin,Pierrick Legrand,Fanny Roche*

Main category: cs.LG

TL;DR: 该研究优化了截断时间反向传播(TBPTT)在数字音频效果建模中的训练，重点研究了序列数、批大小和序列长度等超参数对动态范围压缩模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是优化TBPTT在数字音频效果建模中的训练过程，特别是针对动态范围压缩任务，通过调整关键超参数来提高模型性能、训练稳定性并降低计算需求。

Method: 采用卷积-循环架构，通过大量实验评估TBPTT的三个关键超参数：序列数、批大小和序列长度。实验在有无用户控制条件的数据集上进行，使用客观评估和主观听力测试来验证优化效果。

Result: 实验结果表明，精心调整TBPTT超参数能够显著提升模型精度和训练稳定性，同时降低计算需求。客观评估显示优化设置改善了性能，主观听力测试表明修订的TBPTT配置保持了高感知质量。

Conclusion: 研究得出结论，在数字音频效果建模中，特别是动态范围压缩任务中，仔细调整TBPTT的超参数（序列数、批大小和序列长度）对于实现更好的模型性能、训练稳定性和计算效率至关重要。

Abstract: This paper investigates the optimization of Truncated Backpropagation Through Time (TBPTT) for training neural networks in digital audio effect modeling, with a focus on dynamic range compression. The study evaluates key TBPTT hyperparameters -- sequence number, batch size, and sequence length -- and their influence on model performance. Using a convolutional-recurrent architecture, we conduct extensive experiments across datasets with and without conditionning by user controls. Results demonstrate that carefully tuning these parameters enhances model accuracy and training stability, while also reducing computational demands. Objective evaluations confirm improved performance with optimized settings, while subjective listening tests indicate that the revised TBPTT configuration maintains high perceptual quality.

</details>


### [270] [MIDG: Mixture of Invariant Experts with knowledge injection for Domain Generalization in Multimodal Sentiment Analysis](https://arxiv.org/abs/2512.07430)
*Yangle Li,Danli Luo,Haifeng Hu*

Main category: cs.LG

TL;DR: 本文提出了一种用于多模态情感分析领域泛化的新框架MIDG，通过混合不变专家模型提取领域不变特征，并设计跨模态适配器注入跨模态知识，解决了现有方法忽视模态间协同作用和跨模态知识碎片化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感分析领域泛化方法在提取不变特征时忽视了模态间的协同作用，无法准确捕捉多模态数据的丰富语义信息。同时，现有的知识注入技术存在跨模态知识碎片化问题，忽略了超越单模态界限的特定表示。

Method: 1. 混合不变专家模型：提取领域不变特征，增强模型学习模态间协同关系的能力；2. 跨模态适配器：通过跨模态知识注入增强多模态表示的语义丰富性。

Result: 在三个数据集上进行的广泛领域实验表明，提出的MIDG框架取得了优越的性能。

Conclusion: 提出的MIDG框架通过混合不变专家模型和跨模态适配器，有效解决了多模态情感分析领域泛化中的模态协同和知识碎片化问题，在多个数据集上表现出优越性能。

Abstract: Existing methods in domain generalization for Multimodal Sentiment Analysis (MSA) often overlook inter-modal synergies during invariant features extraction, which prevents the accurate capture of the rich semantic information within multimodal data. Additionally, while knowledge injection techniques have been explored in MSA, they often suffer from fragmented cross-modal knowledge, overlooking specific representations that exist beyond the confines of unimodal. To address these limitations, we propose a novel MSA framework designed for domain generalization. Firstly, the framework incorporates a Mixture of Invariant Experts model to extract domain-invariant features, thereby enhancing the model's capacity to learn synergistic relationships between modalities. Secondly, we design a Cross-Modal Adapter to augment the semantic richness of multimodal representations through cross-modal knowledge injection. Extensive domain experiments conducted on three datasets demonstrate that the proposed MIDG achieves superior performance.

</details>


### [271] [Mitigating Bias in Graph Hyperdimensional Computing](https://arxiv.org/abs/2512.07433)
*Yezi Liu,William Youngwoo Chung,Yang Ni,Hanning Chen,Mohsen Imani*

Main category: cs.LG

TL;DR: 本文研究了图超维计算中的公平性问题，提出了FairGHDC框架来减轻数据表示和决策规则中的偏见，在保持准确性的同时显著减少公平性差距，并实现约10倍的训练加速。


<details>
  <summary>Details</summary>
Motivation: 图超维计算作为一种有前景的认知计算范式，虽然在图结构数据上具有鲁棒性和效率优势，但其公平性影响尚未得到充分探索。数据表示和决策规则中的偏见可能导致对不同群体的不平等对待。

Method: 提出了FairGHDC框架，引入基于差距的人口统计平等正则化器推导出的偏差校正项，将其转换为标量公平因子，用于缩放真实标签类超向量的更新。该方法直接在超向量空间中进行去偏，无需修改图编码器或反向传播。

Result: 在六个基准数据集上的实验结果表明，FairGHDC显著减少了人口统计平等和机会平等差距，同时保持了与标准GNN和公平感知GNN相当的准确性。在GPU上实现了约10倍的训练时间加速。

Conclusion: FairGHDC框架有效解决了图超维计算中的公平性问题，在保持计算效率优势的同时实现了公平性改进，为脑启发式计算中的公平性研究提供了新思路。

Abstract: Graph hyperdimensional computing (HDC) has emerged as a promising paradigm for cognitive tasks, emulating brain-like computation with high-dimensional vectors known as hypervectors. While HDC offers robustness and efficiency on graph-structured data, its fairness implications remain largely unexplored. In this paper, we study fairness in graph HDC, where biases in data representation and decision rules can lead to unequal treatment of different groups. We show how hypervector encoding and similarity-based classification can propagate or even amplify such biases, and we propose a fairness-aware training framework, FairGHDC, to mitigate them. FairGHDC introduces a bias correction term, derived from a gap-based demographic-parity regularizer, and converts it into a scalar fairness factor that scales the update of the class hypervector for the ground-truth label. This enables debiasing directly in the hypervector space without modifying the graph encoder or requiring backpropagation. Experimental results on six benchmark datasets demonstrate that FairGHDC substantially reduces demographic-parity and equal-opportunity gaps while maintaining accuracy comparable to standard GNNs and fairness-aware GNNs. At the same time, FairGHDC preserves the computational advantages of HDC, achieving up to about one order of magnitude ($\approx 10\times$) speedup in training time on GPU compared to GNN and fairness-aware GNN baselines.

</details>


### [272] [KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models](https://arxiv.org/abs/2512.07437)
*Chenwei Shi,Xueyu Luan*

Main category: cs.LG

TL;DR: KAN-Dreamer将KAN和FastKAN架构集成到DreamerV3框架中，替换了原有的MLP和卷积组件，在DeepMind Control Suite上实现了与原始MLP架构相当的性能表现。


<details>
  <summary>Details</summary>
Motivation: DreamerV3是目前最先进的在线模型强化学习算法，具有卓越的样本效率。KAN作为MLP的有前景替代方案，提供了更好的参数效率和可解释性。本研究旨在探索将KAN架构集成到DreamerV3框架中的可能性。

Method: 提出了KAN-Dreamer，将DreamerV3中的特定MLP和卷积组件替换为KAN和FastKAN层。为了在JAX-based World Model中确保效率，实现了定制化的完全向量化版本，并简化了网格管理。研究分为三个子系统：视觉感知、潜在预测和行为学习。

Result: 在DeepMind Control Suite（walker_walk）上的实验评估表明，使用改进的FastKAN作为奖励和继续预测器的直接替代品，能够实现与原始MLP架构相当的性能，在样本效率和训练速度方面都保持同等水平。

Conclusion: KAN-Dreamer作为KAN-based世界模型的初步研究，证明了将KAN架构集成到DreamerV3框架中的可行性，为未来KAN-based世界模型的发展奠定了基础。

Abstract: DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs' computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models.

</details>


### [273] [Parallel Algorithms for Combined Regularized Support Vector Machines: Application in Music Genre Classification](https://arxiv.org/abs/2512.07463)
*Rongmei Liang,Zizheng Liu,Xiaofei Wu,Jingwen Tu*

Main category: cs.LG

TL;DR: 提出基于共识结构的统一优化框架，开发分布式并行ADMM算法处理分布式存储大数据中的组合正则化支持向量机，引入高斯回代法确保收敛，应用于音乐信息检索


<details>
  <summary>Details</summary>
Motivation: 在人工智能快速发展的时代，组合正则化支持向量机（CR-SVMs）能有效处理数据特征间的结构信息，但在分布式存储的大数据场景下缺乏高效算法

Method: 提出基于共识结构的统一优化框架，开发分布式并行交替方向乘子法（ADMM）算法，引入高斯回代法确保收敛，并引入稀疏组套索支持向量机（SGL-SVM）模型

Result: 理论分析表明算法计算复杂度不受不同正则化项和损失函数影响，实验在合成和免费音乐档案数据集上验证了算法的可靠性、稳定性和效率

Conclusion: 提出的统一优化框架和分布式并行ADMM算法能有效处理分布式存储大数据中的组合正则化支持向量机问题，具有强可扩展性和通用性

Abstract: In the era of rapid development of artificial intelligence, its applications span across diverse fields, relying heavily on effective data processing and model optimization. Combined Regularized Support Vector Machines (CR-SVMs) can effectively handle the structural information among data features, but there is a lack of efficient algorithms in distributed-stored big data. To address this issue, we propose a unified optimization framework based on consensus structure. This framework is not only applicable to various loss functions and combined regularization terms but can also be effectively extended to non-convex regularization terms, showing strong scalability. Based on this framework, we develop a distributed parallel alternating direction method of multipliers (ADMM) algorithm to efficiently compute CR-SVMs when data is stored in a distributed manner. To ensure the convergence of the algorithm, we also introduce the Gaussian back-substitution method. Meanwhile, for the integrity of the paper, we introduce a new model, the sparse group lasso support vector machine (SGL-SVM), and apply it to music information retrieval. Theoretical analysis confirms that the computational complexity of the proposed algorithm is not affected by different regularization terms and loss functions, highlighting the universality of the parallel algorithm. Experiments on synthetic and free music archiv datasets demonstrate the reliability, stability, and efficiency of the algorithm.

</details>


### [274] [Materium: An Autoregressive Approach for Material Generation](https://arxiv.org/abs/2512.07486)
*Niklas Dobberstein,Jan Hamaekers*

Main category: cs.LG

TL;DR: Materium是一个用于生成晶体结构的自回归Transformer模型，通过将3D材料表示转换为包含元素、氧化态、分数坐标和晶格参数的token序列，实现快速、可扩展的晶体结构生成。


<details>
  <summary>Details</summary>
Motivation: 当前扩散方法需要多次去噪步骤迭代优化原子位置，计算成本高且速度慢。需要开发一种能够快速、精确生成晶体结构的方法，支持多种属性条件约束。

Method: 采用自回归Transformer架构，将3D材料表示转换为token序列，包括元素（含氧化态）、分数坐标和晶格参数。模型在单GPU上训练数小时，能够在GPU和CPU上快速生成样本。

Result: 模型在单一条件和组合条件下均表现良好，生成的候选结构符合输入要求。相比扩散方法，Materium能够更快地生成样本，支持密度、空间群、带隙和磁密度等多种属性条件。

Conclusion: Materium提供了一种高效、快速的晶体结构生成方法，克服了扩散方法的计算瓶颈，为材料发现和设计提供了实用的工具。

Abstract: We present Materium: an autoregressive transformer for generating crystal structures that converts 3D material representations into token sequences. These sequences include elements with oxidation states, fractional coordinates and lattice parameters. Unlike diffusion approaches, which refine atomic positions iteratively through many denoising steps, Materium places atoms at precise fractional coordinates, enabling fast, scalable generation. With this design, the model can be trained in a few hours on a single GPU and generate samples much faster on GPUs and CPUs than diffusion-based approaches. The model was trained and evaluated using multiple properties as conditions, including fundamental properties, such as density and space group, as well as more practical targets, such as band gap and magnetic density. In both single and combined conditions, the model performs consistently well, producing candidates that align with the requested inputs.

</details>


### [275] [Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent](https://arxiv.org/abs/2512.07490)
*Zhiyu Liu,Zhi Han,Yandong Tang,Jun Fan,Yao Wang*

Main category: cs.LG

TL;DR: 提出交替预条件梯度下降(APGD)算法解决低管秩张量估计问题，在过参数化情况下加速收敛，收敛率与张量条件数无关


<details>
  <summary>Details</summary>
Motivation: 低管秩张量估计是信号处理、机器学习和图像科学中的基础问题。传统方法计算成本高，不适用于大规模张量。现有因子分解方法需要准确估计张量秩，当秩被高估时梯度下降收敛缓慢甚至发散。

Method: 提出交替预条件梯度下降(APGD)算法，在原始梯度上添加预条件项，交替更新两个因子张量。算法在过参数化设置下加速收敛。

Result: 基于几何假设建立了线性收敛保证，特别分析了低管秩张量分解和恢复的具体情况。理论结果表明APGD在过参数化下仍能实现线性收敛，且收敛率与张量条件数无关。合成数据实验验证了理论断言。

Conclusion: APGD算法有效解决了低管秩张量估计中的过参数化问题，在秩被高估的情况下仍能保持快速收敛，为大规模张量处理提供了高效解决方案。

Abstract: The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science. Traditional approaches tackle such a problem by performing tensor singular value decomposition, which is computationally expensive and becomes infeasible for large-scale tensors. Recent approaches address this issue by factorizing the tensor into two smaller factor tensors and solving the resulting problem using gradient descent. However, this kind of approach requires an accurate estimate of the tensor rank, and when the rank is overestimated, the convergence of gradient descent and its variants slows down significantly or even diverges. To address this problem, we propose an Alternating Preconditioned Gradient Descent (APGD) algorithm, which accelerates convergence in the over-parameterized setting by adding a preconditioning term to the original gradient and updating these two factors alternately. Based on certain geometric assumptions on the objective function, we establish linear convergence guarantees for more general low-tubal-rank tensor estimation problems. Then we further analyze the specific cases of low-tubal-rank tensor factorization and low-tubal-rank tensor recovery. Our theoretical results show that APGD achieves linear convergence even under over-parameterization, and the convergence rate is independent of the tensor condition number. Extensive simulations on synthetic data are carried out to validate our theoretical assertions.

</details>


### [276] [FRWKV:Frequency-Domain Linear Attention for Long-Term Time Series Forecasting](https://arxiv.org/abs/2512.07539)
*Qingyuan Yang,Shizhuo,Dongyue Chen,Da Teng,Zehua Gan*

Main category: cs.LG

TL;DR: FRWKV：一种结合线性注意力与频域分析的框架，用于长序列时间序列预测，实现O(T)计算复杂度并在多个数据集上取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在长序列时间序列预测中存在两个主要瓶颈：1）二次方复杂度O(T²)导致计算效率低下；2）未能有效利用频域信息。需要开发一种既能降低计算复杂度又能充分利用频域特征的模型。

Method: 提出FRWKV框架，结合线性注意力机制（受RWKV启发）与频域分析。通过线性注意力实现O(T)计算复杂度，同时引入频域编码器来增强时间特征表示，实现可扩展的长序列建模。

Result: 在8个真实世界数据集上，FRWKV取得了平均排名第一的优异表现。消融研究证实了线性注意力和频域编码器两个组件的关键作用。

Conclusion: 这项工作展示了线性注意力与频域分析之间的强大协同效应，为可扩展的时间序列建模建立了新范式。代码已开源。

Abstract: Traditional Transformers face a major bottleneck in long-sequence time series forecasting due to their quadratic complexity $(\mathcal{O}(T^2))$ and their limited ability to effectively exploit frequency-domain information. Inspired by RWKV's $\mathcal{O}(T)$ linear attention and frequency-domain modeling, we propose FRWKV, a frequency-domain linear-attention framework that overcomes these limitations. Our model integrates linear attention mechanisms with frequency-domain analysis, achieving $\mathcal{O}(T)$ computational complexity in the attention path while exploiting spectral information to enhance temporal feature representations for scalable long-sequence modeling. Across eight real-world datasets, FRWKV achieves a first-place average rank. Our ablation studies confirm the critical roles of both the linear attention and frequency-encoder components. This work demonstrates the powerful synergy between linear attention and frequency analysis, establishing a new paradigm for scalable time series modeling. Code is available at this repository: https://github.com/yangqingyuan-byte/FRWKV.

</details>


### [277] [ReLaX: Reasoning with Latent Exploration for Large Reasoning Models](https://arxiv.org/abs/2512.07558)
*Shimin Zhang,Xianwei Chen,Yufan Shen,Ziyuan Ye,Jibin Wu*

Main category: cs.LG

TL;DR: 该论文提出ReLaX方法，通过分析大语言模型的潜在动态来改善强化学习中的探索-利用权衡，解决RLVR方法中的熵崩溃和过早收敛问题。


<details>
  <summary>Details</summary>
Motivation: RLVR方法虽然能增强大语言模型的推理能力，但会导致熵崩溃，造成策略过早收敛和性能饱和。现有的token级熵操纵方法虽然有效，但作者认为token生成背后的潜在动态包含更丰富的计算结构，能更好地指导策略优化中的探索-利用权衡。

Method: 利用Koopman算子理论获得大语言模型隐藏状态动态的线性化表示，引入动态谱分散度(DSD)指标量化模型潜在动态的异质性，作为策略探索的直接指标。基于此提出ReLaX方法，在策略优化中显式地结合潜在动态来调节探索和利用。

Result: 在广泛的多模态和纯文本推理基准测试中，ReLaX显著缓解了过早收敛问题，并持续实现了最先进的性能表现。

Conclusion: 通过分析大语言模型的潜在动态来指导探索-利用权衡是有效的，ReLaX方法为解决RLVR中的熵崩溃问题提供了新思路，并在多个推理任务中表现出优越性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated remarkable potential in enhancing the reasoning capability of Large Reasoning Models (LRMs). However, RLVR often leads to entropy collapse, resulting in premature policy convergence and performance saturation. While manipulating token-level entropy has proven effective for promoting policy exploration, we argue that the latent dynamics underlying token generation encode a far richer computational structure for steering policy optimization toward a more effective exploration-exploitation tradeoff. To enable tractable analysis and intervention of the latent dynamics of LRMs, we leverage Koopman operator theory to obtain a linearized representation of their hidden-state dynamics. This enables us to introduce Dynamic Spectral Dispersion (DSD), a new metric to quantify the heterogeneity of the model's latent dynamics, serving as a direct indicator of policy exploration. Building upon these foundations, we propose Reasoning with Latent eXploration (ReLaX), a paradigm that explicitly incorporates latent dynamics to regulate exploration and exploitation during policy optimization. Comprehensive experiments across a wide range of multimodal and text-only reasoning benchmarks show that ReLaX significantly mitigates premature convergence and consistently achieves state-of-the-art performance.

</details>


### [278] [Time Series Foundation Models for Process Model Forecasting](https://arxiv.org/abs/2512.07624)
*Yongbo Yu,Jari Peeperkorn,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: 本文研究了时间序列基础模型在过程模型预测中的应用，发现预训练的时间序列基础模型在零样本设置下就能超越传统方法和专门训练的模型，展示了跨领域时间结构迁移的有效性。


<details>
  <summary>Details</summary>
Motivation: 过程模型预测旨在预测过程控制流结构随时间的变化，但现有机器学习方法由于直接跟随关系时间序列的稀疏性和异质性，相比统计基线提升有限。本文探索时间序列基础模型作为替代方案，研究其跨领域时间结构迁移能力。

Method: 使用真实事件日志生成的直接跟随关系时间序列，比较时间序列基础模型的零样本使用（无额外训练）与在PMF特定数据上微调的变体。与传统方法和专门训练的模型进行对比，评估MAE和RMSE等预测误差指标。

Result: 时间序列基础模型通常比传统方法和专门训练的模型获得更低的预测误差，表明从非过程领域有效迁移了时间结构。微调虽能进一步提升准确性，但增益通常较小，在较小或更复杂的数据集上可能消失，因此零样本使用仍然是强大的默认选择。

Conclusion: 时间序列基础模型在过程相关时间序列预测中展现出良好的泛化能力和数据效率，为过程模型预测提供了新的有效方法，也是首次对时间基础模型在PMF中的系统性评估。

Abstract: Process Model Forecasting (PMF) aims to predict how the control-flow structure of a process evolves over time by modeling the temporal dynamics of directly-follows (DF) relations, complementing predictive process monitoring that focuses on single-case prefixes. Prior benchmarks show that machine learning and deep learning models provide only modest gains over statistical baselines, mainly due to the sparsity and heterogeneity of the DF time series. We investigate Time Series Foundation Models (TSFMs), large pre-trained models for generic time series, as an alternative for PMF. Using DF time series derived from real-life event logs, we compare zero-shot use of TSFMs, without additional training, with fine-tuned variants adapted on PMF-specific data. TSFMs generally achieve lower forecasting errors (MAE and RMSE) than traditional and specialized models trained from scratch on the same logs, indicating effective transfer of temporal structure from non-process domains. While fine-tuning can further improve accuracy, the gains are often small and may disappear on smaller or more complex datasets, so zero-shot use remains a strong default. Our study highlights the generalization capability and data efficiency of TSFMs for process-related time series and, to the best of our knowledge, provides the first systematic evaluation of temporal foundation models for PMF.

</details>


### [279] [A Mathematical Theory of Top-$k$ Sparse Attention via Total Variation Distance](https://arxiv.org/abs/2512.07647)
*Georgios Tzachristas,Lei Deng,Ioannis Tzachristas,Gong Zhang,Renhai Chen*

Main category: cs.LG

TL;DR: 该论文为Top-k注意力截断开发了一个统一的数学框架，量化了分布和输出层面的近似误差，提供了确定性的误差界限和渐近规则。


<details>
  <summary>Details</summary>
Motivation: 现有的Top-k注意力截断方法缺乏严格的误差分析，需要量化截断对注意力分布和最终输出的影响，为实际应用提供可靠的误差保证。

Method: 建立统一的数学框架，推导总变差距离与丢弃的softmax尾部质量的关系，提出基于排序logits的确定性误差界限，使用头尾分解分析输出误差，并在高斯评分模型下推导闭式解。

Result: 证明了总变差距离等于丢弃的softmax尾部质量，输出误差可分解为TV距离与头尾均值差的乘积，推导了渐近规则k_ε/n≈Φ_c(σ+Φ^{-1}(ε))，实验显示平均可减少2-4倍的键值对计算。

Conclusion: 该框架为Top-k注意力截断提供了严格的误差保证，能够显著减少计算量同时满足预设的误差预算，为高效注意力机制的设计提供了理论基础。

Abstract: We develop a unified mathematical framework for certified Top-$k$ attention truncation that quantifies approximation error at both the distribution and output levels. For a single attention distribution $P$ and its Top-$k$ truncation $\hat P$, we show that the total-variation distance coincides with the discarded softmax tail mass and satisfies $\mathrm{TV}(P,\hat P)=1-e^{-\mathrm{KL}(\hat P\Vert P)}$, yielding sharp Top-$k$-specific bounds in place of generic inequalities. From this we derive non-asymptotic deterministic bounds -- from a single boundary gap through multi-gap and blockwise variants -- that control $\mathrm{TV}(P,\hat P)$ using only the ordered logits. Using an exact head-tail decomposition, we prove that the output error factorizes as $\|\mathrm{Attn}(q,K,V)-\mathrm{Attn}_k(q,K,V)\|_2=τ\|μ_{\mathrm{tail}}-μ_{\mathrm{head}}\|_2$ with $τ=\mathrm{TV}(P,\hat P)$, yielding a new head-tail diameter bound $\|\mathrm{Attn}(q,K,V)-\mathrm{Attn}_k(q,K,V)\|_2\leτ\,\mathrm{diam}_{H,T}$ and refinements linking the error to $\mathrm{Var}_P(V)$. Under an i.i.d. Gaussian score model $s_i\sim\mathcal N(μ,σ^2)$ we derive closed-form tail masses and an asymptotic rule for the minimal $k_\varepsilon$ ensuring $\mathrm{TV}(P,\hat P)\le\varepsilon$, namely $k_\varepsilon/n\approxΦ_c(σ+Φ^{-1}(\varepsilon))$. Experiments on bert-base-uncased and synthetic logits confirm the predicted scaling of $k_\varepsilon/n$ and show that certified Top-$k$ can reduce scored keys by 2-4$\times$ on average while meeting the prescribed total-variation budget.

</details>


### [280] [Enabling Delayed-Full Charging Through Transformer-Based Real-Time-to-Departure Modeling for EV Battery Longevity](https://arxiv.org/abs/2512.07723)
*Yonggeon Lee,Jibin Hwang,Alfred Malengo Kondoro,Juhyun Song,Youngtae Noh*

Main category: cs.LG

TL;DR: 提出基于Transformer的实时事件预测模型，用于准确预测电动汽车用户出发时间，以优化充电策略延长电池寿命


<details>
  <summary>Details</summary>
Motivation: 电动汽车锂离子电池在高电量状态下会加速退化，可以通过延迟充满电至出发前缓解，但需要准确预测用户出发时间

Method: 使用Transformer架构的实时事件预测模型，将每天的时间离散化为网格化token序列，利用流式上下文信息而非仅依赖历史模式

Result: 在93名用户的真实世界研究中，该方法能有效捕捉个人日常中的不规则出发模式，性能优于基线模型

Conclusion: 该方法具有实际部署潜力，可为可持续交通系统做出贡献

Abstract: Electric vehicles (EVs) are key to sustainable mobility, yet their lithium-ion batteries (LIBs) degrade more rapidly under prolonged high states of charge (SOC). This can be mitigated by delaying full charging \ours until just before departure, which requires accurate prediction of user departure times. In this work, we propose Transformer-based real-time-to-event (TTE) model for accurate EV departure prediction. Our approach represents each day as a TTE sequence by discretizing time into grid-based tokens. Unlike previous methods primarily dependent on temporal dependency from historical patterns, our method leverages streaming contextual information to predict departures. Evaluation on a real-world study involving 93 users and passive smartphone data demonstrates that our method effectively captures irregular departure patterns within individual routines, outperforming baseline models. These results highlight the potential for practical deployment of the \ours algorithm and its contribution to sustainable transportation systems.

</details>


### [281] [GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory](https://arxiv.org/abs/2512.07782)
*Jiaxu Liu,Yuhe Bai,Christos-Savvas Bouganis*

Main category: cs.LG

TL;DR: 提出GatedFWA：一种内存门控的滑动窗口注意力机制，在保持SWA线性时间效率的同时，通过可学习的收缩门控稳定内存更新和控制梯度流。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer的Softmax全注意力存在二次复杂度问题，而滑动窗口注意力(SWA)虽然实现了线性时间编码/解码，但在关联内存解释下其差分式更新导致训练目标无界。Softmax注意力则存在内存收缩和梯度消失问题。

Method: 提出GatedFWA：通过在每个token/head上累积门控作为衰减偏置添加到注意力logits中，作为内存递归中的可学习收缩。实现了融合的单次门预处理和与FlashAttention兼容的内核，在滑动掩码下注入门控，确保I/O效率和数值稳定性。

Result: 在语言建模基准测试中，GatedFWA以可忽略的开销实现了竞争性的吞吐量，更好地利用了全局上下文，并且能够与NSA等token压缩/选择方法无缝集成，泛化到各种自回归领域。

Conclusion: GatedFWA在保持滑动窗口注意力效率优势的同时，通过门控机制解决了内存更新不稳定和梯度流控制问题，为高效的自回归建模提供了新的解决方案。

Abstract: Modern autoregressive models rely on attention, yet the Softmax full attention in Transformers scales quadratically with sequence length. Sliding Window Attention (SWA) achieves linear-time encoding/decoding by constraining the attention pattern, but under an \textit{Associative Memory} interpretation, its difference-style update renders the training objective effectively \emph{unbounded}. In contrast, Softmax attention normalizes updates, leading to \emph{memory shrinkage and gradient vanishing}. We propose GatedFWA: a Memory-\underline{Gated} (\underline{F}lash) \underline{W}indowed \underline{A}ttention mechanism that preserves SWAs efficiency while stabilizing memory updates and making gradient flow controllable. In essence, GatedFWA accumulate a per-token/head gate into a decay bias added to the attention logits, acting as a learnable contraction in the memory recurrence. We implement a fused one-pass gate preprocessing and a FlashAttention-compatible kernel that injects the gate under a sliding mask, ensuring I/O efficiency and numerical stability. On language modelling benchmarks, GatedFWA delivers competitive throughput with negligible overhead and better use of global context, and it integrates cleanly with token compression/selection methods such as NSA and generalizes to various autoregressive domains.

</details>


### [282] [Group Representational Position Encoding](https://arxiv.org/abs/2512.07805)
*Yifan Zhang,Zixiang Chen,Yifeng Liu,Zhen Qin,Huizhuo Yuan,Kangping Xu,Yang Yuan,Quanquan Gu,Andrew Chi-Chih Yao*

Main category: cs.LG

TL;DR: GRAPE是一个基于群作用的统一位置编码框架，包含乘法旋转和加法logit偏置两种机制，将RoPE和ALiBi作为特例包含在内。


<details>
  <summary>Details</summary>
Motivation: 为长上下文模型提供一个有理论基础的、统一的位置编码设计空间，将现有的RoPE和ALiBi等位置编码方法纳入统一的群作用框架中。

Method: 基于群作用理论，提出了两种位置编码机制：1）乘法GRAPE（SO(d)群中的乘法旋转），使用指数映射生成相对、组合、保范的变换；2）加法GRAPE（GL群中的单能作用），产生加法logit偏置。通过调整生成器和作用方式，可以恢复RoPE和ALiBi等现有方法。

Result: GRAPE框架统一了位置编码方法，将RoPE和ALiBi作为精确特例包含在内。乘法GRAPE通过可学习的交换子空间和非交换混合扩展了几何表示能力，加法GRAPE保持了精确的相对定律和流式缓存能力。

Conclusion: GRAPE为长上下文模型提供了一个有理论基础的、统一的位置编码设计空间，通过群作用理论将现有方法系统化，并为未来位置编码设计提供了扩展方向。

Abstract: We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\mathrm{GL}$. In Multiplicative GRAPE, a position $n \in \mathbb{Z}$ (or $t \in \mathbb{R}$) acts as $\mathbf{G}(n)=\exp(n\,ω\,\mathbf{L})$ with a rank-2 skew generator $\mathbf{L} \in \mathbb{R}^{d \times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes are the canonical coordinate pairs with log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project Page: https://github.com/model-architectures/GRAPE.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [283] [The Tragedy of Productivity: A Unified Framework for Diagnosing Coordination Failures in Labor Markets and AI Governance](https://arxiv.org/abs/2512.05995)
*Ali Dasdan*

Main category: cs.CY

TL;DR: 论文识别了生产力竞争和AI治理中的结构性悲剧，证明它们具有相同的博弈论结构，并开发了一个悲剧指数显示AI治理的协调难度比气候变化或核武器高几个数量级。


<details>
  <summary>Details</summary>
Motivation: 尽管生产力自凯恩斯预测以来增长了八倍，但全球工人工作时间仍约为预测的两倍；同时AI发展加速，尽管存在存在性风险警告。论文旨在证明这些失败具有相同的博弈论结构，并开发一个框架来理解结构性悲剧。

Method: 提出了五个必要且充分的条件来表征结构性悲剧：N参与者结构、具有负外部性的二元选择、背叛产生更高收益的优势、合作优于相互背叛的帕累托无效性，以及结构性障碍导致的执行困难。通过条件强度扩展框架，引入悲剧指数，并在生产力竞争和AI治理案例中验证。

Result: 验证了该框架在经典案例中的适用性，悲剧指数显示AI治理面临比气候变化或核武器高几个数量级的协调难度。在生产力竞争中证明企业面临协调失败，生产力增长无法转化为工人福利；在AI治理中证明发展具有相同结构但在八个维度上强度更大。俄乌无人机战争验证了这一点。

Conclusion: 分析是诊断性的而非规范性的，识别了协调的结构性障碍而非提出解决方案。生产力竞争和AI治理中的失败共享相同的结构性悲剧模式，AI治理面临特别严峻的协调挑战。

Abstract: Despite productivity increasing eightfold since Keynes's 1930
  prediction of 15-hour workweeks, workers globally still work roughly
  double these hours. Separately, AI development accelerates despite
  existential risk warnings from leading researchers. We demonstrate
  these failures share identical game-theoretic structure.
  We synthesize five necessary and sufficient conditions
  characterizing structural tragedies: N-player structure,
  binary choices with negative externalities, dominance where
  defection yields higher payoffs, Pareto-inefficiency where
  cooperation dominates mutual defection, and enforcement difficulty
  from structural barriers. We validate this framework across canonical
  cases and extend it through condition intensities, introducing a
  Tragedy Index revealing AI governance faces orders-of-magnitude
  greater coordination difficulty than climate change or nuclear
  weapons.
  Applied to productivity competition, we prove firms face
  coordination failure preventing productivity gains from translating
  to worker welfare. European evidence shows that even under favorable
  conditions, productivity-welfare decoupling persists. Applied to AI
  governance, we demonstrate development faces the same structure but
  with amplified intensity across eight dimensions compared to
  successful arms control. The Russia-Ukraine drone war validates this:
  both sides escalated from zero to thousands of drones monthly within
  two years despite prior governance dialogue.
  The analysis is diagnostic rather than prescriptive, identifying
  structural barriers to coordination rather than proposing solutions.

</details>


### [284] [Protocol Futuring: Speculating Second-Order Dynamics of Protocols in Sociotechnical Infrastructural Futures](https://arxiv.org/abs/2512.06108)
*Botao 'Amber' Hu,Samuel Chua,Helena Rong*

Main category: cs.CY

TL;DR: 本文提出"协议未来化"方法框架，将协议作为推测性探究的主要材料，通过案例研究展示协议规则在长期时间尺度上的演变过程。


<details>
  <summary>Details</summary>
Motivation: 基于HCI和CSCW中的基础设施研究，传统设计未来化方法关注离散的未来人工制品，而忽略了协议规则在长期时间尺度上的演变和影响。需要一种方法来分析协议如何随时间推移产生漂移、阻塞等二阶效应。

Method: 提出"协议未来化"方法框架，将协议作为推测性探究的主要材料。通过"知识未来拉玛"案例研究，采用多团队参与式工作坊形式，使用接力格式让团队继承和重新解释部分形成的设计，观察协议在不同社区和时代间的演变。

Result: 工作坊揭示了协议在跨社区和时代传播过程中的变化机制：模糊的交接、对抗性重新解释、文化规范变迁和危机动态。这些因素共同导致协议规则随时间推移产生漂移和阻塞等二阶效应。

Conclusion: 协议未来化方法使基础设施政治和长期后果在分析上变得可见，为研究影响在延长时间尺度上展开的新兴社会技术系统提供了有价值的工具。讨论了该方法的优势、局限性和对研究者的启示。

Abstract: Drawing on infrastructure studies in HCI and CSCW, this paper introduces Protocol Futuring, a methodological framework that extends design futuring by foregrounding protocols-rules, standards, and coordination mechanisms-as the primary material of speculative inquiry. Rather than imagining discrete future artifacts, Protocol Futuring examines how protocol rules accumulate drift, jam, and other second-order effects over long temporal horizons. We demonstrate the method through a case study of Knowledge Futurama, a multi-team participatory workshop exploring millennial-scale knowledge preservation. Using a relay format in which teams inherited and reinterpreted partially formed designs, the workshop revealed how ambiguous handovers, adversarial reinterpretations, shifting cultural norms, and crisis dynamics transform protocols as they move across communities and epochs. The case shows how Protocol Futuring makes infrastructural politics and long-run consequences analytically visible. We discuss the method's strengths, limitations, and implications for researchers seeking to investigate emergent sociotechnical systems whose impacts unfold over extended timescales.

</details>


### [285] [The Role of Smart Cities in Ethical Design Framework Yijun](https://arxiv.org/abs/2512.06336)
*Yijun Chen*

Main category: cs.CY

TL;DR: 本文运用Beard和Longstaff框架，通过理论分析和案例研究探讨智慧城市技术实施中的伦理挑战，包括数据隐私、公平性、包容性和透明度等问题，并提出监管沙盒、参与式治理等建议。


<details>
  <summary>Details</summary>
Motivation: 随着数字技术融入城市规划形成"智慧城市"，旨在提升生活质量和运营效率，但技术实施带来了数据隐私、公平性、包容性和透明度等伦理挑战，需要系统分析和解决。

Method: 采用Beard和Longstaff分析框架，结合理论分析和案例研究方法，聚焦自决、公平、可及性和目的性原则，考察智慧城市倡议中的治理模式、利益相关者角色和伦理困境。

Result: 研究识别了智慧城市发展中的关键伦理挑战，包括数据隐私保护、数字鸿沟、治理透明度等问题，并提出了具体解决方案。

Conclusion: 为确保智慧城市符合社会价值观，建议采用监管沙盒、促进参与式治理、弥合数字鸿沟等措施，推动包容性和伦理的城市发展。

Abstract: The integration of digital technologies into urban planning has given rise to "smart cities," aiming to enhance quality of life and operational efficiency. However, the implementation of such technologies introduces ethical challenges, including data privacy, equity, inclusion, and transparency. This article employs the Beard and Longstaff framework to discuss these challenges through a combination of theoretical analysis and case studies. Focusing on principles of self-determination, fairness, accessibility, and purpose, the study examines governance models, stakeholder roles, and ethical dilemmas inherent in smart city initiatives. Recommendations include adopting regulatory sandboxes, fostering participatory governance, and bridging digital divides to ensure that smart cities align with societal values, promoting inclusivity and ethical urban development.

</details>


### [286] [Why They Disagree: Decoding Differences in Opinions about AI Risk on the Lex Fridman Podcast](https://arxiv.org/abs/2512.06350)
*Nghi Truong,Phanish Puranam,Özgecan Koçak*

Main category: cs.CY

TL;DR: 该论文分析AI风险辩论中的"末日论者"与"繁荣论者"分歧，发现分歧源于对复杂系统设计vs涌现、以及过去理论适用性vs革命性变化的不同因果前提，而非道德价值观差异。


<details>
  <summary>Details</summary>
Motivation: 尽管AI辩论各方都希望AI造福人类并避免灾难性后果，但社会分歧依然存在。论文旨在解析这些分歧的本质，识别争论的关键点，以促进更有建设性的对话。

Method: 使用定义性、事实性、因果性和道德性前提框架分析AI风险辩论，将分歧分解为不同层面的前提差异。采用LLM集成方法大规模分析文本数据，解析推理链条。

Result: 发现关于存在性风险（X-risk）的分歧主要源于对复杂系统中设计vs涌现的不同因果前提；关于就业风险（E-risks）的分歧则源于对过去理论（进化论）适用性vs不适用性（革命性）的不同因果前提。两种分歧都不涉及重大道德价值观差异，且都可描述为对人类理性有限程度的不同看法。

Conclusion: 该分析方法可识别任何公共风险辩论中的关键争议点，有助于将分歧从价值观冲突转向事实和因果前提的讨论，促进更有成效的对话和决策。

Abstract: The emergence of transformative technologies often surfaces deep societal divisions, nowhere more evident than in contemporary debates about artificial intelligence (AI). A striking feature of these divisions is that they persist despite shared interests in ensuring that AI benefits humanity and avoiding catastrophic outcomes. This paper analyzes contemporary debates about AI risk, parsing the differences between the "doomer" and "boomer" perspectives into definitional, factual, causal, and moral premises to identify key points of contention. We find that differences in perspectives about existential risk ("X-risk") arise fundamentally from differences in causal premises about design vs. emergence in complex systems, while differences in perspectives about employment risks ("E-risks") pertain to different causal premises about the applicability of past theories (evolution) vs their inapplicability (revolution). Disagreements about these two forms of AI risk appear to share two properties: neither involves significant disagreements on moral values and both can be described in terms of differing views on the extent of boundedness of human rationality. Our approach to analyzing reasoning chains at scale, using an ensemble of LLMs to parse textual data, can be applied to identify key points of contention in debates about risk to the public in any arena.

</details>


### [287] [The Missing Variable: Socio-Technical Alignment in Risk Evaluation](https://arxiv.org/abs/2512.06354)
*Niclas Flehmig,Mary Ann Lundteigen,Shen Yin*

Main category: cs.CY

TL;DR: 该论文针对AI赋能安全关键系统的风险评估空白，提出将社会技术对齐变量STA整合到基础风险方程中，以捕捉传统方法忽略的人机组织交互风险。


<details>
  <summary>Details</summary>
Motivation: 现有风险评估方法未能充分考虑AI赋能安全关键系统中复杂的人机组织交互，这些系统本质上是社会技术系统，但标准风险评估缺乏对社会技术因素的考量。

Method: 通过社会技术系统和AI赋能系统的属性比较分析，以及对现有风险评估方法的回顾，确认社会技术因素在标准风险表达中的缺失，并设计社会技术对齐变量STA整合到基础风险方程中。

Result: 在AI赋能液氢加注系统的案例研究中，通过比较朴素设计和安全防护设计，展示了STA增强的风险表达能够捕捉传统方法忽略的社会技术安全影响。

Conclusion: STA变量为AI赋能安全关键系统提供了更全面的风险评估基础，能够更好地反映复杂社会技术交互中的安全影响。

Abstract: This paper addresses a critical gap in the risk assessment of AI-enabled safety-critical systems. While these systems, where AI systems assists human operators, function as complex socio-technical systems, existing risk evaluation methods fail to account for the associated complex interaction between human, technical, and organizational elements. Through a comparative analysis of system attributes from both socio-technical and AI-enabled systems and a review of current risk evaluation methods, we confirm the absence of socio-technical considerations in standard risk expressions. To bridge this gap, we introduce a novel socio-technical alignment $STA$ variable designed to be integrated into the foundational risk equation. This variable estimates the degree of harmonious interaction between the AI systems, human operators, and organizational processes. A case study on an AI-enabled liquid hydrogen bunkering system demonstrates the variable's relevance. By comparing a naive and a safeguarded system design, we illustrate how the $STA$-augmented expression captures socio-technical safety implications that traditional risk evaluation overlooks, providing a more holistic basis for risk evaluation.

</details>


### [288] [Code vs. Context: STEM Students' Resistance to Non-STEM Coursework](https://arxiv.org/abs/2512.06529)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CY

TL;DR: 研究发现工程学生抵制非技术课程主要源于角色模糊（专业身份冲突），而非认知转换成本或工作负荷；减少角色模糊能提高学习意愿和长期技能应用。


<details>
  <summary>Details</summary>
Motivation: STEM项目要求学生修读非技术课程以培养软技能，但工程学生常抵制这一要求。先前研究多归因于课业负担，但对认知和身份认同机制了解不足。本研究旨在填补这一知识空白。

Method: 收集212名计算机科学和工程本科生的调查数据，使用顺序OLS回归测试认知转换成本、工作负荷、角色模糊对情感抵制的影响，以及后续对参与意愿和长期技能应用的影响。

Result: 角色模糊是情感抵制的最强预测因子（β=0.47，p<0.001），超过工作负荷（β=0.20，p=0.007）和认知转换成本（β=0.14，p=0.038）。情感抵制显著降低参与意愿（β=-0.25，p<0.001），而参与意愿是长期技能应用的强预测因子（β=0.55，p<0.001）。

Conclusion: 学生抵制主要源于非技术内容与学生新兴专业身份的不一致，而非认知努力或工作负荷。为改善结果，课程应通过将人文社科材料置于明确的工程背景中来减少角色模糊。

Abstract: Many STEM programs now require students to take non-technical courses to develop the soft skills necessary for professional practice, yet engineering students frequently resist this requirement. While prior research often attributes this resistance to heavy workloads, little is known about its cognitive and identity-related mechanisms. This study fills this knowledge gap by examining the effects of Cognitive Switching Costs, Work Overload, and Role Ambiguity on students' Affective Resistance to non-STEM coursework, as well as the subsequent impact on their Willingness to Engage and Long-Term Adoption of skills. We collected survey data from 212 undergraduate Computer Science and Engineering students and tested directional relationships using sequential OLS regression. Role Ambiguity emerged as the strongest predictor of Affective Resistance (beta of 0.47, p less than 0.001), exceeding the effects of Work Overload (beta of 0.20, p equals 0.007) and Cognitive Switching Cost (beta of 0.14, p equals 0.038). In turn, Affective Resistance significantly reduced Willingness to Engage (beta of -0.25, p less than 0.001), while Willingness to Engage served as a strong predictor of Long-Term Adoption (beta of 0.55, p less than 0.001). These results indicate that student resistance is driven primarily by the incongruence between non-technical content and students' emergent professional identities, rather than by cognitive effort or workload alone. To improve outcomes, curricula should focus on reducing role ambiguity by placing humanities and social science material in clear engineering contexts.

</details>


### [289] [Generic visuality of war? How image-generative AI models (mis)represent Russia's war against Ukraine](https://arxiv.org/abs/2512.06570)
*Mykola Makhortykh,Miglė Bareikytė*

Main category: cs.CY

TL;DR: 该研究通过对比美国Midjourney和俄罗斯Kandinsky两个图像生成AI模型对俄乌战争的表征，发现上下文因素导致战争表征存在差异，但同时也存在可能导致战争美学同质化的模式。


<details>
  <summary>Details</summary>
Motivation: 生成式AI可能改变社会现实的表征方式，包括现代战争。现有研究主要关注AI的军事应用，而生成式AI对战争描绘、记忆和解释方式的影响尚未充分探讨。特别是不同文化背景的AI模型如何表征暴力事件存在研究空白。

Method: 以俄罗斯侵略乌克兰为案例研究，审计美国Midjourney和俄罗斯Kandinsky两个图像生成模型对战争虚构和事实事件的表征。分析模型对战争相关提示的响应，以及生成图像的美学和内容特征。

Result: 研究发现上下文因素导致战争表征存在差异，既存在于不同模型之间，也存在于同一模型的输出内部。然而，也存在一些一致的表征模式，这些模式可能导致战争美学的同质化。

Conclusion: 生成式AI对战争的表征受到文化背景和上下文因素的影响，但同时也存在跨模型的同质化趋势，这可能影响公众对暴力的理解和记忆方式。

Abstract: The rise of generative AI (genAI) can transform the representation of different aspects of social reality, including modern wars. While scholarship has largely focused on the military applications of AI, the growing adoption of genAI technologies may have major implications for how wars are portrayed, remembered, and interpreted. A few initial scholarly inquiries highlight the risks of genAI in this context, specifically regarding its potential to distort the representation of mass violence, particularly by sanitising and homogenising it. However, little is known about how genAI representation practices vary between different episodes of violence portrayed by Western and non-Western genAI models. Using the Russian aggression against Ukraine as a case study, we audit how two image-generative models, the US-based Midjourney and the Russia-based Kandinsky, represent both fictional and factual episodes of the war. We then analyse the models' responsiveness to the war-related prompts, together with the aesthetic and content-based aspects of the resulting images. Our findings highlight that contextual factors lead to variation in the representation of war, both between models and within the outputs of the same model. However, there are some consistent patterns of representation that may contribute to the homogenization of war aesthetics.

</details>


### [290] [When Does Regulation by Insurance Work? The Case of Frontier AI](https://arxiv.org/abs/2512.06597)
*Cristian Trout*

Main category: cs.CY

TL;DR: 论文提出一个评估保险对减少危害净效应的分析框架，识别保险可能产生监管效果而非道德风险的条件，并应用于前沿AI行业


<details>
  <summary>Details</summary>
Motivation: 保险在分散风险和简化理赔方面的作用毋庸置疑，但关于保险能否通过减少危害来提高福利（尽管存在道德风险）的时机和方式存在争议。需要建立一个原则性框架来评估保险在特定情境下的净效应。

Method: 收集保险成功或失败产生净监管效应的案例，借鉴广泛的经济学文献，开发一个分析框架。识别特定扭曲（如责任限制、竞争动态、行为偏差）创造净监管效应的潜力，并分析投保人类型、风险类型、保险公司类型和保险市场结构如何影响这种潜力的实现。

Result: 分析表明，对于灾难性非产品事故，保险监管可能特别有效，因为市场机制提供不足的约束且心理偏差最强。将框架应用于前沿AI行业，显示出显著的净监管效应潜力，但也需要政策干预来实现这种潜力。

Conclusion: 保险可以通过监管效应减少危害，特别是在特定条件下。对于前沿AI行业，建议设计精心制定的强制保险，鼓励成立专业保险公司或互助组织，专注于灾难性而非常规风险，并禁止纯粹的专属保险公司。

Abstract: No one doubts the utility of insurance for its ability to spread risk or streamline claims management; much debated is when and how insurance uptake can improve welfare by reducing harm, despite moral hazard. Proponents and dissenters of "regulation by insurance" have now documented a number of cases of insurers succeeding or failing to have such a net regulatory effect (in contrast with a net hazard effect). Collecting these examples together and drawing on an extensive economics literature, this Article develops a principled framework for evaluating insurance uptake's effect in a given context. The presence of certain distortions - including judgment-proofness, competitive dynamics, and behavioral biases - creates potential for a net regulatory effect. How much of that potential gets realized then depends on the type of policyholder, type of risk, type of insurer, and the structure of the insurance market. The analysis suggests regulation by insurance can be particularly effective for catastrophic non-product accidents where market mechanisms provide insufficient discipline and psychological biases are strongest. As a demonstration, the framework is applied to the frontier AI industry, revealing significant potential for a net regulatory effect but also the need for policy intervention to realize that potential. One option is a carefully designed mandate that encourages forming a specialized insurer or mutual, focuses on catastrophic rather than routine risks, and bars pure captives.

</details>


### [291] [A Framework for Data Valuation and Monetisation](https://arxiv.org/abs/2512.07664)
*Eduardo Vyhmeister,Bastien Pietropaoli,UdoBub,Rob Schneider,Andrea Visentin*

Main category: cs.CY

TL;DR: 本文提出了一个统一的数据估值框架，将经济、治理和战略视角整合到连贯的决策支持模型中，帮助组织将数据资产转化为可衡量的商业价值。


<details>
  <summary>Details</summary>
Motivation: 组织日益认识到数据作为战略资源的重要性，但面临将信息资产转化为可衡量商业价值的挑战。现有估值方法分散，往往分离经济、治理和战略视角，缺乏适合实际环境的操作机制。

Method: 采用设计科学方法，基于DATAMITE项目的两个构件（数据质量和性能指标分类法，以及用于推导相对重要性的ANP工具），开发混合估值模型。该模型结合定性评分、成本和效用估算、相关性/质量索引以及多标准加权，通过平衡计分卡框架将指标和估值结果与组织战略对齐。

Result: 在分析的用例中，该框架展示了估值中的灵活性、透明度和减少随意性，为组织提供了将数据资产与战略和经济结果联系起来的结构化基础。

Conclusion: 该统一估值框架通过整合多个视角，为组织提供了透明、系统的数据价值定义方法，能够评估数据即服务、信息即服务和答案即服务路径的货币化潜力，并将估值考虑映射到平衡计分卡视角。

Abstract: As organisations increasingly recognise data as a strategic resource, they face the challenge of translating informational assets into measurable business value. Existing valuation approaches remain fragmented, often separating economic, governance, and strategic perspectives and lacking operational mechanisms suitable for real settings. This paper introduces a unified valuation framework that integrates these perspectives into a coherent decision-support model. Building on two artefacts from the Horizon Europe DATAMITE project, a taxonomy of data-quality and performance metrics, and an Analytic Network Process (ANP) tool for deriving relative importance, we develop a hybrid valuation model. The model combines qualitative scoring, cost- and utility-based estimation, relevance/quality indexing, and multi-criteria weighting to define data value transparently and systematically. Anchored in the Balanced Scorecard (BSC), the framework aligns indicators and valuation outcomes with organisational strategy, enabling firms to assess monetisation potential across Data-as-a-Service, Information-as-a-Service, and Answers-as-a-Service pathways. Methodologically, the study follows a Design Science approach complemented by embedded case studies with industrial partners, which informed continual refinement of the model. Because the evaluation is connected to a high-level taxonomy, the approach also reveals how valuation considerations map to BSC perspectives. Across the analysed use cases, the framework demonstrated flexibility, transparency, and reduced arbitrariness in valuation, offering organisations a structured basis for linking data assets to strategic and economic outcomes.

</details>


### [292] [LLM Use for Mental Health: Crowdsourcing Users' Sentiment-based Perspectives and Values from Social Discussions](https://arxiv.org/abs/2512.07797)
*Lingyao Li,Xiaoshan Huang,Renkai Ma,Ben Zefeng Zhang,Haolun Wu,Fan Yang,Chen Chen*

Main category: cs.CY

TL;DR: 研究通过社交媒体数据分析发现，LLM聊天机器人在心理健康支持中的使用具有条件特异性，神经多样性用户更积极，高风险障碍用户更消极，需要转向条件特异性、价值敏感的设计。


<details>
  <summary>Details</summary>
Motivation: LLM聊天机器人越来越多地用于心理健康支持，虽然提供了可访问的治疗支持，但也引发了关于错误信息、过度依赖以及在心理健康高风险情境中的担忧。需要了解用户如何在不同心理健康条件下与LLM聊天机器人互动。

Method: 从六个主要社交媒体平台众包大规模用户帖子，采用基于价值敏感设计(VSD)的LLM辅助分析流程，映射用户报告的情感、心理健康状况、观点和价值观之间的关系。

Result: LLM聊天机器人的使用具有条件特异性：神经多样性状况(如ADHD、ASD)用户报告强烈积极情感和工具性或评价性支持，而高风险障碍(如精神分裂症、双相情感障碍)则显示更多负面情感。用户观点与身份认同、自主权、隐私等潜在价值观共同出现。

Conclusion: 需要从"一刀切"的聊天机器人设计转向条件特异性、价值敏感的LLM设计，考虑不同心理健康状况用户的特定需求和价值观。

Abstract: Large language models (LLMs) chatbots like ChatGPT are increasingly used for mental health support. They offer accessible, therapeutic support but also raise concerns about misinformation, over-reliance, and risks in high-stakes contexts of mental health. We crowdsource large-scale users' posts from six major social media platforms to examine how people discuss their interactions with LLM chatbots across different mental health conditions. Through an LLM-assisted pipeline grounded in Value-Sensitive Design (VSD), we mapped the relationships across user-reported sentiments, mental health conditions, perspectives, and values. Our results reveal that the use of LLM chatbots is condition-specific. Users with neurodivergent conditions (e.g., ADHD, ASD) report strong positive sentiments and instrumental or appraisal support, whereas higher-risk disorders (e.g., schizophrenia, bipolar disorder) show more negative sentiments. We further uncover how user perspectives co-occur with underlying values, such as identity, autonomy, and privacy. Finally, we discuss shifting from "one-size-fits-all" chatbot design toward condition-specific, value-sensitive LLM design.

</details>
