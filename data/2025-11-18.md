<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 225]
- [cs.IR](#cs.IR) [Total: 16]
- [cs.CY](#cs.CY) [Total: 31]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.LG](#cs.LG) [Total: 186]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Psychological stress during Examination and its estimation by handwriting in answer script](https://arxiv.org/abs/2511.11633)
*Abhijeet Kumar,Chetan Agarwal,Pronoy B. Neogi,Mayank Goswami*

Main category: cs.CV

TL;DR: 该研究结合笔迹学与人工智能，通过分析学生手写考试试卷来量化心理压力水平，使用OCR和基于Transformer的情感分析模型，提供超越传统评分系统的数据驱动方法。


<details>
  <summary>Details</summary>
Motivation: 探索通过分析学生手写考试试卷来量化心理压力水平，为传统评分系统提供更深入的认知和情感状态洞察。

Method: 集成高分辨率图像处理、TrOCR和使用RoBERTa模型的情感熵融合，通过五模型投票机制和无监督异常检测实现鲁棒性。

Result: 开发了一个能够生成数值化压力指数的创新框架，在学术取证领域具有创新性。

Conclusion: 该方法成功实现了通过手写分析量化学生考试期间心理压力的目标，为学术评估提供了新的维度。

Abstract: This research explores the fusion of graphology and artificial intelligence to quantify psychological stress levels in students by analyzing their handwritten examination scripts. By leveraging Optical Character Recognition and transformer based sentiment analysis models, we present a data driven approach that transcends traditional grading systems, offering deeper insights into cognitive and emotional states during examinations. The system integrates high resolution image processing, TrOCR, and sentiment entropy fusion using RoBERTa based models to generate a numerical Stress Index. Our method achieves robustness through a five model voting mechanism and unsupervised anomaly detection, making it an innovative framework in academic forensics.

</details>


### [2] [Real-time pothole detection with onboard sensors and camera on vehicles](https://arxiv.org/abs/2511.11643)
*Aswath Muthuselvam,Jeevak Raj S,Mohanaprasad K*

Main category: cs.CV

TL;DR: 使用车辆传感器和SVM分类器实时检测道路坑洞，在2公里路段上达到98.1%的准确率。


<details>
  <summary>Details</summary>
Motivation: 道路状况对日常通勤至关重要，车辆数量增加需要频繁评估路况以确保交通顺畅，小裂缝可能发展成大坑洞。

Method: 利用车辆内置传感器收集数据，采用SVM分类器进行坑洞检测。

Result: 在2公里路段（包含26个坑洞）上测试，达到98.1%的检测准确率。

Conclusion: 该方法能够有效实时检测道路坑洞，为大规模坑洞管理和分析提供有用数据。

Abstract: Road conditions play an important role in our everyday commute. With the proliferating number of vehicles on the road each year, it has become necessary to access the road conditions very frequently, this would ensure that the traffic also flows smoothly. Even the smallest crack in the road could be easily be chipped into a large pothole due to changing surface temperatures of the road and from the force of vehicles riding over it. In this paper, we have addressed how we could better identify these potholes in realtime with the help of onboard sensors in vehicles so that the data could be useful for analysis and better management of potholes on a large scale. For the implementation, we used an SVM classifier to detect potholes, we achieved 98.1% accuracy based on data collected from a local road for about 2 km which had 26 potholes distributed along the road. Code is available at: https://github.com/aswathselvam/Potholes

</details>


### [3] [AGENet: Adaptive Edge-aware Geodesic Distance Learning for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2511.11662)
*Ziyuan Gao*

Main category: cs.CV

TL;DR: AGENet是一种用于医学图像少样本分割的新框架，通过边缘感知测地距离学习整合空间关系，在有限标注数据下实现精确边界分割。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割需要大量标注数据，这在临床应用中形成了显著瓶颈。现有少样本分割方法在医学图像精确边界划分方面表现欠佳，特别是在解剖结构相似且缺乏足够空间上下文的情况下。

Method: 提出AGENet框架，包含三个主要组件：(1)边缘感知测地距离学习模块，通过迭代快速行进细化来尊重解剖边界；(2)自适应原型提取，通过空间加权聚合捕获全局结构和局部边界细节；(3)自适应参数学习，自动适应不同器官特征。

Result: 在多样化医学成像数据集上的广泛实验表明，该方法优于现有最先进方法，显著减少了边界误差，同时保持计算效率。

Conclusion: AGENet在有限标注数据下实现了精确的医学图像分割，计算效率高，非常适合需要精确分割的临床应用。

Abstract: Medical image segmentation requires large annotated datasets, creating a significant bottleneck for clinical applications. While few-shot segmentation methods can learn from minimal examples, existing approaches demonstrate suboptimal performance in precise boundary delineation for medical images, particularly when anatomically similar regions appear without sufficient spatial context. We propose AGENet (Adaptive Geodesic Edge-aware Network), a novel framework that incorporates spatial relationships through edge-aware geodesic distance learning. Our key insight is that medical structures follow predictable geometric patterns that can guide prototype extraction even with limited training data. Unlike methods relying on complex architectural components or heavy neural networks, our approach leverages computationally lightweight geometric modeling. The framework combines three main components: (1) An edge-aware geodesic distance learning module that respects anatomical boundaries through iterative Fast Marching refinement, (2) adaptive prototype extraction that captures both global structure and local boundary details via spatially-weighted aggregation, and (3) adaptive parameter learning that automatically adjusts to different organ characteristics. Extensive experiments across diverse medical imaging datasets demonstrate improvements over state-of-the-art methods. Notably, our method reduces boundary errors compared to existing approaches while maintaining computational efficiency, making it highly suitable for clinical applications requiring precise segmentation with limited annotated data.

</details>


### [4] [Task-Aware 3D Affordance Segmentation via 2D Guidance and Geometric Refinement](https://arxiv.org/abs/2511.11702)
*Lian He,Meng Liu,Qilang Ye,Yu Zhou,Xiang Deng,Gangyi Ding*

Main category: cs.CV

TL;DR: TASA是一个新颖的几何优化框架，用于3D场景级可操作性分割，通过联合利用2D语义线索和3D几何推理，在准确性和效率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注对象级可操作性或将2D预测提升到3D，忽略了点云中的丰富几何结构信息且计算成本高。需要解决语义推理和空间定位的挑战。

Method: TASA采用从粗到细的方法，包含任务感知的2D可操作性检测模块来识别可操作点，以及3D可操作性细化模块来整合2D语义先验与局部3D几何信息。

Result: 在SceneFun3D数据集上的实验表明，TASA在场景级可操作性分割的准确性和效率方面显著优于基线方法。

Conclusion: TASA通过联合利用2D语义线索和3D几何推理，有效解决了3D场景级可操作性分割的挑战，实现了准确且空间一致的3D可操作性掩码。

Abstract: Understanding 3D scene-level affordances from natural language instructions is essential for enabling embodied agents to interact meaningfully in complex environments. However, this task remains challenging due to the need for semantic reasoning and spatial grounding. Existing methods mainly focus on object-level affordances or merely lift 2D predictions to 3D, neglecting rich geometric structure information in point clouds and incurring high computational costs. To address these limitations, we introduce Task-Aware 3D Scene-level Affordance segmentation (TASA), a novel geometry-optimized framework that jointly leverages 2D semantic cues and 3D geometric reasoning in a coarse-to-fine manner. To improve the affordance detection efficiency, TASA features a task-aware 2D affordance detection module to identify manipulable points from language and visual inputs, guiding the selection of task-relevant views. To fully exploit 3D geometric information, a 3D affordance refinement module is proposed to integrate 2D semantic priors with local 3D geometry, resulting in accurate and spatially coherent 3D affordance masks. Experiments on SceneFun3D demonstrate that TASA significantly outperforms the baselines in both accuracy and efficiency in scene-level affordance segmentation.

</details>


### [5] [Target-Balanced Score Distillation](https://arxiv.org/abs/2511.11710)
*Zhou Xu,Qi Wang,Yuxiao Yang,Luyuan Zhang,Zhang Liang,Yang Li*

Main category: cs.CV

TL;DR: 本文提出了Target-Balanced Score Distillation (TBSD)方法，通过多目标优化策略解决了SDS方法在纹理优化和形状保持之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统SDS方法存在过饱和和过平滑问题，而引入负提示的变体方法面临纹理优化有限或纹理增益但形状失真的关键权衡。

Method: 提出TBSD方法，将生成建模为多目标优化问题，采用自适应策略平衡目标负提示的使用，有效解决纹理与形状的权衡。

Result: 大量实验表明，TBSD显著优于现有最先进方法，生成具有高保真纹理和几何精确形状的3D资产。

Conclusion: TBSD通过系统分析和自适应策略，成功解决了SDS方法在纹理优化和形状保持之间的根本权衡问题。

Abstract: Score Distillation Sampling (SDS) enables 3D asset generation by distilling priors from pretrained 2D text-to-image diffusion models, but vanilla SDS suffers from over-saturation and over-smoothing. To mitigate this issue, recent variants have incorporated negative prompts. However, these methods face a critical trade-off: limited texture optimization, or significant texture gains with shape distortion. In this work, we first conduct a systematic analysis and reveal that this trade-off is fundamentally governed by the utilization of the negative prompts, where Target Negative Prompts (TNP) that embed target information in the negative prompts dramatically enhancing texture realism and fidelity but inducing shape distortions. Informed by this key insight, we introduce the Target-Balanced Score Distillation (TBSD). It formulates generation as a multi-objective optimization problem and introduces an adaptive strategy that effectively resolves the aforementioned trade-off. Extensive experiments demonstrate that TBSD significantly outperforms existing state-of-the-art methods, yielding 3D assets with high-fidelity textures and geometrically accurate shape.

</details>


### [6] [Exposing DeepFakes via Hyperspectral Domain Mapping](https://arxiv.org/abs/2511.11732)
*Aditya Mehta,Swarnim Chaudhary,Pratik Narang,Jagat Sesh Challa*

Main category: cs.CV

TL;DR: HSI-Detect是一个两阶段深度伪造检测方法，通过将RGB图像重建为31通道高光谱图像，在高光谱域进行检测，相比RGB域能放大伪造痕迹。


<details>
  <summary>Details</summary>
Motivation: 现代生成和扩散模型产生的图像高度逼真，可能误导人类感知和自动化检测系统。现有检测方法主要在RGB空间分析三个光谱通道，限制了检测能力。

Method: 提出两阶段检测流程：1）从标准RGB输入重建31通道高光谱图像；2）在高光谱域进行检测。通过扩展输入表示到更密集的光谱带，放大RGB域中弱或不可见的操作伪影。

Result: 在FaceForensics++数据集上的评估显示，相比仅使用RGB的基线方法，HSI-Detect取得了持续改进。

Conclusion: 高光谱域映射在深度伪造检测中具有良好前景，能有效增强检测性能。

Abstract: Modern generative and diffusion models produce highly realistic images that can mislead human perception and even sophisticated automated detection systems. Most detection methods operate in RGB space and thus analyze only three spectral channels. We propose HSI-Detect, a two-stage pipeline that reconstructs a 31-channel hyperspectral image from a standard RGB input and performs detection in the hyperspectral domain. Expanding the input representation into denser spectral bands amplifies manipulation artifacts that are often weak or invisible in the RGB domain, particularly in specific frequency bands. We evaluate HSI-Detect across FaceForensics++ dataset and show the consistent improvements over RGB-only baselines, illustrating the promise of spectral-domain mapping for Deepfake detection.

</details>


### [7] [Batch Transformer Architecture: Case of Synthetic Image Generation for Emotion Expression Facial Recognition](https://arxiv.org/abs/2511.11754)
*Stanislav Selitskiy*

Main category: cs.CV

TL;DR: 提出了一种新型的隐式稀疏风格Transformer架构——Batch Transformers，通过对重要维度（主成分）进行注意力机制，而非传统Transformer中对整个维度序列或批次的关注，从而显著减少编码器-解码器ANN架构中的瓶颈大小。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在处理序列或批次实体时关注整个维度，导致计算复杂度高。本文旨在通过关注重要维度来减少模型瓶颈，提高效率。

Method: 提出Batch Transformers架构，采用隐式稀疏风格，对重要维度（主成分）实施注意力机制，而非传统Transformer中对整个维度的关注。

Result: 在面部识别任务的合成图像生成中，针对化妆和遮挡数据集进行了测试，能够增加有限原始数据集的变异性。

Conclusion: Batch Transformers通过关注重要维度实现了编码器-解码器架构瓶颈的显著减小，在面部识别任务中表现出良好的数据增强能力。

Abstract: A novel Transformer variation architecture is proposed in the implicit sparse style. Unlike "traditional" Transformers, instead of attention to sequential or batch entities in their entirety of whole dimensionality, in the proposed Batch Transformers, attention to the "important" dimensions (primary components) is implemented. In such a way, the "important" dimensions or feature selection allows for a significant reduction of the bottleneck size in the encoder-decoder ANN architectures. The proposed architecture is tested on the synthetic image generation for the face recognition task in the case of the makeup and occlusion data set, allowing for increased variability of the limited original data set.

</details>


### [8] [Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing](https://arxiv.org/abs/2511.11780)
*Hossein Mohebbi,Mohammed Abdulrahman,Yanting Miao,Pascal Poupart,Suraj Kothawade*

Main category: cs.CV

TL;DR: Image-POSER是一个基于强化学习的文本到图像生成框架，通过动态任务分解和专家模型组合来处理长复合提示，在多个基准测试中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型在处理长复合提示时表现不佳，缺乏可靠的端到端执行能力，无法满足创意工作流程的需求。

Method: 采用反射强化学习框架，协调预训练文本到图像和图像到图像专家模型，通过马尔可夫决策过程进行动态任务分解，并使用视觉语言模型批评器提供结构化反馈。

Result: 在行业标准和自定义基准测试中，Image-POSER在一致性、保真度和美学方面均优于基线模型（包括前沿模型），并在人工评估中持续获得偏好。

Conclusion: 强化学习能够赋予AI系统自主分解、重新排序和组合视觉模型的能力，推动向通用视觉助手的发展。

Abstract: Recent advances in text-to-image generation have produced strong single-shot models, yet no individual system reliably executes the long, compositional prompts typical of creative workflows. We introduce Image-POSER, a reflective reinforcement learning framework that (i) orchestrates a diverse registry of pretrained text-to-image and image-to-image experts, (ii) handles long-form prompts end-to-end through dynamic task decomposition, and (iii) supervises alignment at each step via structured feedback from a vision-language model critic. By casting image synthesis and editing as a Markov Decision Process, we learn non-trivial expert pipelines that adaptively combine strengths across models. Experiments show that Image-POSER outperforms baselines, including frontier models, across industry-standard and custom benchmarks in alignment, fidelity, and aesthetics, and is consistently preferred in human evaluations. These results highlight that reinforcement learning can endow AI systems with the capacity to autonomously decompose, reorder, and combine visual models, moving towards general-purpose visual assistants.

</details>


### [9] [SOTFormer: A Minimal Transformer for Unified Object Tracking and Trajectory Prediction](https://arxiv.org/abs/2511.11824)
*Zhongping Dong,Pengyang Yu,Shuangjian Li,Liming Chen,Mohand Tahar Kechadi*

Main category: cs.CV

TL;DR: SOTFormer是一个统一目标检测、跟踪和短期轨迹预测的端到端框架，通过最小化常数内存的时间transformer实现稳定的身份传播和实时推理。


<details>
  <summary>Details</summary>
Motivation: 解决在遮挡、尺度变化和时间漂移等挑战下，单目标跟踪和短期运动预测的准确性问题，这些因素破坏了实时感知所需的时间一致性。

Method: 采用基于真实标注启动的内存和燃烧锚点损失来稳定初始化，使用单个轻量级时间注意力层跨帧优化嵌入，实现固定GPU内存的实时推理。

Result: 在Mini-LaSOT基准测试上达到76.3 AUC和53.7 FPS（4.3 GB VRAM），在快速运动、尺度变化和遮挡条件下优于TrackFormer和MOTRv2等transformer基线模型。

Conclusion: SOTFormer通过统一框架和高效的时间建模，在保持实时性能的同时显著提升了跟踪和预测的准确性。

Abstract: Accurate single-object tracking and short-term motion forecasting remain challenging under occlusion, scale variation, and temporal drift, which disrupt the temporal coherence required for real-time perception. We introduce \textbf{SOTFormer}, a minimal constant-memory temporal transformer that unifies object detection, tracking, and short-horizon trajectory prediction within a single end-to-end framework. Unlike prior models with recurrent or stacked temporal encoders, SOTFormer achieves stable identity propagation through a ground-truth-primed memory and a burn-in anchor loss that explicitly stabilizes initialization. A single lightweight temporal-attention layer refines embeddings across frames, enabling real-time inference with fixed GPU memory. On the Mini-LaSOT (20%) benchmark, SOTFormer attains 76.3 AUC and 53.7 FPS (AMP, 4.3 GB VRAM), outperforming transformer baselines such as TrackFormer and MOTRv2 under fast motion, scale change, and occlusion.

</details>


### [10] [MP-GFormer: A 3D-Geometry-Aware Dynamic Graph Transformer Approach for Machining Process Planning](https://arxiv.org/abs/2511.11837)
*Fatemeh Elhambakhsh,Gaurav Ameta,Aditi Roy,Hyunwoong Ko*

Main category: cs.CV

TL;DR: MP-GFormer是一种3D几何感知的动态图变换器，通过将演化的3D几何表示集成到动态图学习中，用于预测加工操作序列，相比现有方法在主要和子操作预测准确率上分别提升24%和36%。


<details>
  <summary>Details</summary>
Motivation: 现有动态图学习方法在加工工艺规划中虽然能捕捉时空依赖关系，但未能融入零件的三维几何信息，缺乏领域感知能力，限制了加工操作序列预测的准确性。

Method: 提出MP-GFormer方法，利用StereoLithography表面网格表示每个加工操作后的零件3D几何，通过注意力机制将演化的3D几何表示集成到动态图变换器中。

Result: 在合成数据集上的评估显示，该方法在主要操作和子操作预测准确率上分别比最先进方法提升了24%和36%。

Conclusion: 将3D几何信息集成到动态图学习中能显著提升加工操作序列预测性能，证明了3D几何感知在加工工艺规划中的重要性。

Abstract: Machining process planning (MP) is inherently complex due to structural and geometrical dependencies among part features and machining operations. A key challenge lies in capturing dynamic interdependencies that evolve with distinct part geometries as operations are performed. Machine learning has been applied to address challenges in MP, such as operation selection and machining sequence prediction. Dynamic graph learning (DGL) has been widely used to model dynamic systems, thanks to its ability to integrate spatio-temporal relationships. However, in MP, while existing DGL approaches can capture these dependencies, they fail to incorporate three-dimensional (3D) geometric information of parts and thus lack domain awareness in predicting machining operation sequences. To address this limitation, we propose MP-GFormer, a 3D-geometry-aware dynamic graph transformer that integrates evolving 3D geometric representations into DGL through an attention mechanism to predict machining operation sequences. Our approach leverages StereoLithography surface meshes representing the 3D geometry of a part after each machining operation, with the boundary representation method used for the initial 3D designs. We evaluate MP-GFormer on a synthesized dataset and demonstrate that the method achieves improvements of 24\% and 36\% in accuracy for main and sub-operation predictions, respectively, compared to state-of-the-art approaches.

</details>


### [11] [Defending Unauthorized Model Merging via Dual-Stage Weight Protection](https://arxiv.org/abs/2511.11851)
*Wei-Jia Chen,Min-Yen Tsai,Cheng-Yi Lee,Chia-Mu Yu*

Main category: cs.CV

TL;DR: MergeGuard是一个双阶段权重保护框架，通过重新分配任务相关信息并注入结构化扰动来破坏模型合并兼容性，同时保持原始模型功能完整。


<details>
  <summary>Details</summary>
Motivation: 预训练模型和开源仓库的快速扩散使得模型合并成为便捷但有风险的做法，未经授权的模型合并侵犯知识产权并破坏模型所有权和问责制。

Method: 第一阶段通过L2正则化优化重新分配任务相关信息，第二阶段注入结构化扰动来错位任务子空间，破坏损失景观中的曲率兼容性。

Result: 在视觉和语言模型上的广泛实验表明，MergeGuard能将合并模型准确率降低高达90%，同时保护模型的性能损失小于1.5%。

Conclusion: MergeGuard通过重塑模型参数几何形状，使合并模型崩溃为破坏性干扰，同时保护模型保持完全功能，有效防止未经授权的模型合并。

Abstract: The rapid proliferation of pretrained models and open repositories has made model merging a convenient yet risky practice, allowing free-riders to combine fine-tuned models into a new multi-capability model without authorization. Such unauthorized model merging not only violates intellectual property rights but also undermines model ownership and accountability. To address this issue, we present MergeGuard, a proactive dual-stage weight protection framework that disrupts merging compatibility while maintaining task fidelity. In the first stage, we redistribute task-relevant information across layers via L2-regularized optimization, ensuring that important gradients are evenly dispersed. In the second stage, we inject structured perturbations to misalign task subspaces, breaking curvature compatibility in the loss landscape. Together, these stages reshape the model's parameter geometry such that merged models collapse into destructive interference while the protected model remains fully functional. Extensive experiments on both vision (ViT-L-14) and language (Llama2, Gemma2, Mistral) models demonstrate that MergeGuard reduces merged model accuracy by up to 90% with less than 1.5% performance loss on the protected model.

</details>


### [12] [Lacking Data? No worries! How synthetic images can alleviate image scarcity in wildlife surveys: a case study with muskox (Ovibos moschatus)](https://arxiv.org/abs/2511.11882)
*Simon Durand,Samuel Foucher,Alexandre Delplanque,Joëlle Taillon,Jérôme Théau*

Main category: cs.CV

TL;DR: 本研究探讨了使用合成图像补充有限训练数据来提高麝牛检测性能，在零样本和少样本设置中验证了合成图像的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统野生动物调查方法资源密集且受限于后勤挑战，而深度学习目标检测模型在稀疏分布物种（如麝牛）的小数据集上效果有限，需要寻找替代方案。

Method: 比较了基于真实图像的基线模型与5个零样本和5个少样本模型，这些模型在训练集中逐步加入更多合成图像。

Result: 零样本模型中，添加合成图像提高了检测性能，但超过基线模型训练数据集100%后出现收益递减；少样本模型中，真实图像与合成图像结合可获得更好的召回率和略高的准确率。

Conclusion: 合成图像在数据稀缺时训练准确目标检测模型具有潜力，可为野生动物监测提供重要视角，特别是在监测稀有或难以接近物种时。

Abstract: Accurate population estimates are essential for wildlife management, providing critical insights into species abundance and distribution. Traditional survey methods, including visual aerial counts and GNSS telemetry tracking, are widely used to monitor muskox populations in Arctic regions. These approaches are resource intensive and constrained by logistical challenges. Advances in remote sensing, artificial intelligence, and high resolution aerial imagery offer promising alternatives for wildlife detection. Yet, the effectiveness of deep learning object detection models (ODMs) is often limited by small datasets, making it challenging to train robust ODMs for sparsely distributed species like muskoxen. This study investigates the integration of synthetic imagery (SI) to supplement limited training data and improve muskox detection in zero shot (ZS) and few-shot (FS) settings. We compared a baseline model trained on real imagery with 5 ZS and 5 FS models that incorporated progressively more SI in the training set. For the ZS models, where no real images were included in the training set, adding SI improved detection performance. As more SI were added, performance in precision, recall and F1 score increased, but eventually plateaued, suggesting diminishing returns when SI exceeded 100% of the baseline model training dataset. For FS models, combining real and SI led to better recall and slightly higher overall accuracy compared to using real images alone, though these improvements were not statistically significant. Our findings demonstrate the potential of SI to train accurate ODMs when data is scarce, offering important perspectives for wildlife monitoring by enabling rare or inaccessible species to be monitored and to increase monitoring frequency. This approach could be used to initiate ODMs without real data and refine it as real images are acquired over time.

</details>


### [13] [Advancing Annotat3D with Harpia: A CUDA-Accelerated Library For Large-Scale Volumetric Data Segmentation](https://arxiv.org/abs/2511.11890)
*Camila Machado de Araujo,Egon P. B. S. Borges,Ricardo Marcelo Canteiro Grangeiro,Allan Pinto*

Main category: cs.CV

TL;DR: 本文介绍了Harpia——一个基于CUDA的处理库，集成到Annotat3D中，用于支持大规模3D数据集的可扩展、交互式分割工作流，特别适用于高性能计算和远程访问环境。


<details>
  <summary>Details</summary>
Motivation: 高分辨率体积成像技术（如X射线断层扫描和先进显微镜）生成的数据集越来越大，现有工具在处理效率、分割和交互探索方面面临挑战。

Method: 开发了Harpia库，具有严格内存控制、原生分块执行和一套GPU加速的过滤、注释和量化工具，支持在超过单个GPU内存容量的数据集上可靠运行。

Result: 实验结果显示，与NVIDIA cuCIM和scikit-image等广泛使用的框架相比，在处理速度、内存效率和可扩展性方面都有显著改进。

Conclusion: 该系统结合了交互式人机界面和高效的GPU资源管理，特别适合在共享HPC基础设施中的协作科学成像工作流。

Abstract: High-resolution volumetric imaging techniques, such as X-ray tomography and advanced microscopy, generate increasingly large datasets that challenge existing tools for efficient processing, segmentation, and interactive exploration. This work introduces new capabilities to Annotat3D through Harpia, a new CUDA-based processing library designed to support scalable, interactive segmentation workflows for large 3D datasets in high-performance computing (HPC) and remote-access environments. Harpia features strict memory control, native chunked execution, and a suite of GPU-accelerated filtering, annotation, and quantification tools, enabling reliable operation on datasets exceeding single-GPU memory capacity. Experimental results demonstrate significant improvements in processing speed, memory efficiency, and scalability compared to widely used frameworks such as NVIDIA cuCIM and scikit-image. The system's interactive, human-in-the-loop interface, combined with efficient GPU resource management, makes it particularly suitable for collaborative scientific imaging workflows in shared HPC infrastructures.

</details>


### [14] [Prompt Triage: Structured Optimization Enhances Vision-Language Model Performance on Medical Imaging Benchmarks](https://arxiv.org/abs/2511.11898)
*Arnav Singhvi,Vasiliki Bikia,Asad Aali,Akshay Chaudhari,Roxana Daneshjou*

Main category: cs.CV

TL;DR: 本文提出使用DSPy框架进行自动化提示优化，在医学视觉语言系统中显著提升性能，相比零样本提示基线获得53%的中位数相对改进。


<details>
  <summary>Details</summary>
Motivation: 视觉语言基础模型在医学基准测试中表现不佳，传统方法如模型微调需要大量领域特定数据和计算资源，手动提示工程难以泛化且不易部署，因此需要探索不依赖人工设计提示的可扩展方法。

Method: 采用DSPy框架进行结构化自动提示优化，在放射学、胃肠病学和皮肤病学的五个医学成像任务中实现提示管道，评估10个开源VLM和四种提示优化技术。

Result: 优化后的管道在零样本提示基线上实现了53%的中位数相对改进，在零样本性能较低的任务上最大增益达到300%至3,400%。

Conclusion: 自动化提示优化在医学AI系统中具有巨大潜力，能够显著提升需要准确临床图像解释的视觉应用性能，同时减少对提示设计的依赖，让临床医生专注于患者护理和临床决策。

Abstract: Vision-language foundation models (VLMs) show promise for diverse imaging tasks but often underperform on medical benchmarks. Prior efforts to improve performance include model finetuning, which requires large domain-specific datasets and significant compute, or manual prompt engineering, which is hard to generalize and often inaccessible to medical institutions seeking to deploy these tools. These challenges motivate interest in approaches that draw on a model's embedded knowledge while abstracting away dependence on human-designed prompts to enable scalable, weight-agnostic performance improvements. To explore this, we adapt the Declarative Self-improving Python (DSPy) framework for structured automated prompt optimization in medical vision-language systems through a comprehensive, formal evaluation. We implement prompting pipelines for five medical imaging tasks across radiology, gastroenterology, and dermatology, evaluating 10 open-source VLMs with four prompt optimization techniques. Optimized pipelines achieved a median relative improvement of 53% over zero-shot prompting baselines, with the largest gains ranging from 300% to 3,400% on tasks where zero-shot performance is low. These results highlight the substantial potential of applying automated prompt optimization to medical AI systems, demonstrating significant gains for vision-based applications requiring accurate clinical image interpretation. By reducing dependence on prompt design to elicit intended outputs, these techniques allow clinicians to focus on patient care and clinical decision-making. Furthermore, our experiments offer scalability and preserve data privacy, demonstrating performance improvement on open-source VLMs. We publicly release our evaluation pipelines to support reproducible research on specialized medical tasks, available at https://github.com/DaneshjouLab/prompt-triage-lab.

</details>


### [15] [MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2511.12449)
*Zhanheng Nie,Chenghan Fu,Daoze Zhang,Junxian Wu,Wanxian Guan,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: MOON2.0是一个动态模态平衡的多模态表示学习框架，用于解决电商产品理解中的模态不平衡、内在对齐关系利用不足和数据噪声问题，通过模态驱动的专家混合模块、双级对齐方法和基于MLLM的图像文本协同增强策略实现改进。


<details>
  <summary>Details</summary>
Motivation: 解决电商多模态模型面临的三个挑战：模态混合训练导致的模态不平衡、产品内视觉和文本信息内在对齐关系利用不足，以及电商多模态数据噪声处理有限。

Method: 提出MOON2.0框架，包含：(1) 模态驱动的专家混合模块，根据模态组成自适应处理输入样本；(2) 双级对齐方法，更好利用产品内语义对齐特性；(3) 基于MLLM的图像文本协同增强策略，结合动态样本过滤提高训练数据质量。

Result: 在MBE2.0基准和多个公共数据集上实现了最先进的零样本性能，注意力热图可视化提供了改进多模态对齐的定性证据。

Conclusion: MOON2.0通过动态模态平衡的多模态表示学习有效解决了电商产品理解中的关键挑战，在多个基准测试中表现出优越性能。

Abstract: The rapid growth of e-commerce calls for multimodal models that comprehend rich visual and textual product information. Although recent multimodal large language models (MLLMs) for product understanding exhibit strong capability in representation learning for e-commerce, they still face three challenges: (i) the modality imbalance induced by modality mixed training; (ii) underutilization of the intrinsic alignment relationships among visual and textual information within a product; and (iii) limited handling of noise in e-commerce multimodal data. To address these, we propose MOON2.0, a dynamic modality-balanced multimodal representation learning framework for e-commerce product understanding. MOON2.0 comprises: (1) a Modality-driven Mixture-of-Experts (MoE) module that adaptively processes input samples by their modality composition, enabling Multimodal Joint Learning to mitigate the modality imbalance; (2) a Dual-level Alignment method to better leverage semantic alignment properties inside individual products; and (3) an MLLM-based Image-text Co-augmentation strategy that integrates textual enrichment with visual expansion, coupled with Dynamic Sample Filtering to improve training data quality. We further introduce MBE2.0, a co-augmented multimodal representation benchmark for e-commerce representation learning and evaluation. Experiments show that MOON2.0 delivers state-of-the-art zero-shot performance on MBE2.0 and multiple public datasets. Furthermore, attention-based heatmap visualization provides qualitative evidence of improved multimodal alignment of MOON2.0.

</details>


### [16] [Seeing the Forest and the Trees: Query-Aware Tokenizer for Long-Video Multimodal Language Models](https://arxiv.org/abs/2511.11910)
*Siyou Li,Huanan Wu,Juexi Shao,Yinghao Ma,Yujian Gan,Yihao Luo,Yuwei Wang,Dong Nie,Lu Wang,Wengqing Wu,Le Zhang,Massimo Poesio,Juntao Yu*

Main category: cs.CV

TL;DR: QTSplus是一个轻量级但强大的视觉token选择模块，通过动态选择与文本查询最相关的视觉证据来解决长视频理解中的计算开销问题，在保持准确性的同时显著压缩视觉流和降低延迟。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在长视频理解中面临的视觉token数量随视频长度线性增长导致的注意力成本、内存和延迟爆炸问题。

Method: 提出QTSplus模块：(1)通过交叉注意力对视觉token评分；(2)基于查询复杂度预测实例特定的保留预算；(3)训练时使用可微分直通估计器选择Top-n token，推理时使用硬门控；(4)使用小型重新编码器保持时间顺序。

Result: 在Qwen2.5-VL中集成QTSplus，视觉流压缩高达89%，端到端延迟降低28%，在八个长视频理解基准测试中保持接近原始模型的准确性，在TempCompass方向准确率和顺序准确率上分别比原始模型提升20.5和5.6个百分点。

Conclusion: QTSplus是一种有效且通用的机制，能够在保持任务相关证据的同时将MLLM扩展到真实世界的长视频场景。

Abstract: Despite the recent advances in the video understanding ability of multimodal large language models (MLLMs), long video understanding remains a challenge. One of the main issues is that the number of vision tokens grows linearly with video length, which causes an explosion in attention cost, memory, and latency. To solve this challenge, we present Query-aware Token Selector (\textbf{QTSplus}), a lightweight yet powerful visual token selection module that serves as an information gate between the vision encoder and LLMs. Given a text query and video tokens, QTSplus dynamically selects the most important visual evidence for the input text query by (i) scoring visual tokens via cross-attention, (ii) \emph{predicting} an instance-specific retention budget based on the complexity of the query, and (iii) \emph{selecting} Top-$n$ tokens with a differentiable straight-through estimator during training and a hard gate at inference. Furthermore, a small re-encoder preserves temporal order using absolute time information, enabling second-level localization while maintaining global coverage.
  Integrated into Qwen2.5-VL, QTSplus compresses the vision stream by up to \textbf{89\%} and reduces end-to-end latency by \textbf{28\%} on long videos. The evaluation on eight long video understanding benchmarks shows near-parity accuracy overall when compared with the original Qwen models and outperforms the original model by \textbf{+20.5} and \textbf{+5.6} points respectively on TempCompass direction and order accuracies. These results show that QTSplus is an effective, general mechanism for scaling MLLMs to real-world long-video scenarios while preserving task-relevant evidence.
  We will make all code, data, and trained models' weights publicly available.

</details>


### [17] [From Events to Clarity: The Event-Guided Diffusion Framework for Dehazing](https://arxiv.org/abs/2511.11944)
*Ling Wang,Yunfan Lu,Wenzong Ma,Huizai Yao,Pengteng Li,Hui Xiong*

Main category: cs.CV

TL;DR: 本文首次使用事件相机进行图像去雾，提出事件引导的扩散模型，通过将事件的高动态范围信息融入扩散模型来重建清晰图像，在真实雾霾场景中取得最先进效果。


<details>
  <summary>Details</summary>
Motivation: 传统基于RGB图像的去雾方法受限于动态范围不足，容易丢失结构和光照细节。事件相机具有高动态范围和微秒级延迟，适合雾霾场景，但缺乏真实配对数据使得HDR信息转移困难。

Method: 提出事件引导的扩散模型，设计事件引导模块将稀疏HDR事件特征映射到扩散潜在空间，为生成过程提供精确的结构指导。

Result: 在两种基准测试和自建的重雾霾无人机数据集上实现了最先进的去雾效果。

Conclusion: 事件相机结合扩散模型能够有效解决雾霾场景下的图像去雾问题，通过HDR信息转移显著提升图像质量。

Abstract: Clear imaging under hazy conditions is a critical task. Prior-based and neural methods have improved results. However, they operate on RGB frames, which suffer from limited dynamic range. Therefore, dehazing remains ill-posed and can erase structure and illumination details. To address this, we use event cameras for dehazing for the \textbf{first time}. Event cameras offer much higher HDR ($120 dBvs.60 dB$) and microsecond latency, therefore they suit hazy scenes. In practice, transferring HDR cues from events to frames is hard because real paired data are scarce. To tackle this, we propose an event-guided diffusion model that utilizes the strong generative priors of diffusion models to reconstruct clear images from hazy inputs by effectively transferring HDR information from events. Specifically, we design an event-guided module that maps sparse HDR event features, \textit{e.g.,} edges, corners, into the diffusion latent space. This clear conditioning provides precise structural guidance during generation, improves visual realism, and reduces semantic drift. For real-world evaluation, we collect a drone dataset in heavy haze (AQI = 341) with synchronized RGB and event sensors. Experiments on two benchmarks and our dataset achieve state-of-the-art results.

</details>


### [18] [FGNet: Leveraging Feature-Guided Attention to Refine SAM2 for 3D EM Neuron Segmentation](https://arxiv.org/abs/2511.13063)
*Zhenghua Li,Hang Chen,Zihao Sun,Kai Li,Xiaolin Hu*

Main category: cs.CV

TL;DR: 该论文提出了一种将自然图像预训练的Segment Anything 2模型知识迁移到电子显微镜图像神经元分割任务的新框架，通过特征引导注意力模块和双亲和度解码器，在冻结SAM2权重时达到SOTA水平，微调后显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 电子显微镜图像中的神经元分割面临复杂形态、低信噪比和标注稀缺等挑战，现有方法的准确性和泛化能力有限。作者希望利用在大量自然图像上训练的视觉基础模型的先验知识来解决这些问题。

Method: 提出新颖框架：1）使用SAM2提取通用特征；2）引入特征引导注意力模块，利用SAM2语义线索指导轻量级精细编码器关注困难区域；3）双亲和度解码器生成粗粒度和精炼的亲和度图。

Result: 实验结果表明，在冻结SAM2权重时，方法性能与SOTA方法相当；在EM数据上进一步微调后，显著超越现有SOTA方法。

Conclusion: 研究表明，将自然图像预训练的表征与针对性的领域自适应指导相结合，可以有效解决神经元分割中的特定挑战。

Abstract: Accurate segmentation of neural structures in Electron Microscopy (EM) images is paramount for neuroscience. However, this task is challenged by intricate morphologies, low signal-to-noise ratios, and scarce annotations, limiting the accuracy and generalization of existing methods. To address these challenges, we seek to leverage the priors learned by visual foundation models on a vast amount of natural images to better tackle this task. Specifically, we propose a novel framework that can effectively transfer knowledge from Segment Anything 2 (SAM2), which is pre-trained on natural images, to the EM domain. We first use SAM2 to extract powerful, general-purpose features. To bridge the domain gap, we introduce a Feature-Guided Attention module that leverages semantic cues from SAM2 to guide a lightweight encoder, the Fine-Grained Encoder (FGE), in focusing on these challenging regions. Finally, a dual-affinity decoder generates both coarse and refined affinity maps. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art (SOTA) approaches with the SAM2 weights frozen. Upon further fine-tuning on EM data, our method significantly outperforms existing SOTA methods. This study validates that transferring representations pre-trained on natural images, when combined with targeted domain-adaptive guidance, can effectively address the specific challenges in neuron segmentation.

</details>


### [19] [Evaluation of Attention Mechanisms in U-Net Architectures for Semantic Segmentation of Brazilian Rock Art Petroglyphs](https://arxiv.org/abs/2511.11959)
*Leonardi Melo,Luís Gustavo,Dimmy Magalhães,Lucciani Vieira,Mauro Araújo*

Main category: cs.CV

TL;DR: 本研究比较了三种基于U-Net的架构用于巴西考古遗址岩画岩刻的语义分割，其中Attention-Residual BEGL-UNet表现最佳，Dice得分为0.710。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估不同U-Net架构在考古遗产数字保护中的有效性，特别是针对岩画岩刻的语义分割任务。

Method: 比较了三种U-Net架构：(1) BEGL-UNet；(2) Attention-Residual BEGL-UNet，包含残差块和门控注意力机制；(3) Spatial Channel Attention BEGL-UNet，采用基于卷积块注意力模块的空间通道注意力模块。所有实现都使用结合二元交叉熵和高斯边缘增强的BEGL损失函数，并在巴西Poço da Bebidinha考古遗址图像上使用5折交叉验证进行实验。

Result: Attention-Residual BEGL-UNet获得最佳整体性能，Dice得分为0.710，验证损失为0.067，最高召回率为0.854。Spatial Channel Attention BEGL-UNet性能相当，DSC为0.707，召回率为0.857。基线BEGL-UNet的DSC为0.690。注意力机制相比基线带来2.5-2.9%的Dice得分提升。

Conclusion: 研究证明了注意力机制在考古遗产数字保护中的有效性，特别是Attention-Residual BEGL-UNet架构在岩画岩刻语义分割任务中表现最佳。

Abstract: This study presents a comparative analysis of three U-Net-based architectures for semantic segmentation of rock art petroglyphs from Brazilian archaeological sites. The investigated architectures were: (1) BEGL-UNet with Border-Enhanced Gaussian Loss function; (2) Attention-Residual BEGL-UNet, incorporating residual blocks and gated attention mechanisms; and (3) Spatial Channel Attention BEGL-UNet, which employs spatial-channel attention modules based on Convolutional Block Attention Module. All implementations employed the BEGL loss function combining binary cross-entropy with Gaussian edge enhancement. Experiments were conducted on images from the Poço da Bebidinha Archaeological Complex, Piauí, Brazil, using 5-fold cross-validation. Among the architectures, Attention-Residual BEGL-UNet achieved the best overall performance with Dice Score of 0.710, validation loss of 0.067, and highest recall of 0.854. Spatial Channel Attention BEGL-UNet obtained comparable performance with DSC of 0.707 and recall of 0.857. The baseline BEGL-UNet registered DSC of 0.690. These results demonstrate the effectiveness of attention mechanisms for archaeological heritage digital preservation, with Dice Score improvements of 2.5-2.9% over the baseline.

</details>


### [20] [Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework](https://arxiv.org/abs/2511.13189)
*Diego Ortego,Marlon Rodríguez,Mario Almagro,Kunal Dahiya,David Jiménez,Juan C. SanMiguel*

Main category: cs.CV

TL;DR: 本文提出ViXML框架，通过结合解码器模型和视觉信息来改进极端多标签分类，在保持计算效率的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何在极端多标签分类中有效利用大型解码器模型和视觉信息，同时保持计算效率。

Method: 提出ViXML框架，集成基础视觉模型生成单图像嵌入，结合解码器模型进行多模态学习。

Result: 在四个公开数据集上验证，ViXML在最大数据集上P@1指标比之前最优方法提升8.21%。

Conclusion: 视觉信息在极端多标签分类中具有重要价值，ViXML框架成功平衡了性能与效率，为多模态XMC提供了有效解决方案。

Abstract: Foundation models have revolutionized artificial intelligence across numerous domains, yet their transformative potential remains largely untapped in Extreme Multi-label Classification (XMC). Queries in XMC are associated with relevant labels from extremely large label spaces, where it is critical to strike a balance between efficiency and performance. Therefore, many recent approaches efficiently pose XMC as a maximum inner product search between embeddings learned from small encoder-only transformer architectures. In this paper, we address two important aspects in XMC: how to effectively harness larger decoder-only models, and how to exploit visual information while maintaining computational efficiency. We demonstrate that both play a critical role in XMC separately and can be combined for improved performance. We show that a few billion-size decoder can deliver substantial improvements while keeping computational overhead manageable. Furthermore, our Vision-enhanced eXtreme Multi-label Learning framework (ViXML) efficiently integrates foundation vision models by pooling a single embedding per image. This limits computational growth while unlocking multi-modal capabilities. Remarkably, ViXML with small encoders outperforms text-only decoder in most cases, showing that an image is worth billions of parameters. Finally, we present an extension of existing text-only datasets to exploit visual metadata and make them available for future benchmarking. Comprehensive experiments across four public text-only datasets and their corresponding image enhanced versions validate our proposals' effectiveness, surpassing previous state-of-the-art by up to +8.21\% in P@1 on the largest dataset. ViXML's code is available at https://github.com/DiegoOrtego/vixml.

</details>


### [21] [BeyondFacial: Identity-Preserving Personalized Generation Beyond Facial Close-ups](https://arxiv.org/abs/2511.11989)
*Songsong Zhang,Chuanqi Tang,Hongguang Zhang,Guijian Tang,Minglong Li,Xueqiong Li,Shaowu Yang,Yuanxi Peng,Wenjing Yang,Jing Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种突破面部特写限制的身份保持个性化生成方法，通过双线推理管道、身份自适应融合策略和身份聚合前置模块，解决了传统方法中身份特征嵌入削弱生成模型语义表达能力的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的身份保持个性化生成方法过度强调面部区域，导致输出被面部特写主导，视觉叙事性弱且在复杂文本提示下语义一致性差。核心问题在于身份特征嵌入削弱了生成模型的语义表达能力。

Method: 设计了身份语义分离的双线推理管道，提出身份自适应融合策略将身份语义融合推迟到噪声预测阶段，引入身份聚合前置模块来聚合身份信息并替换随机初始化。

Result: 实验验证该方法在超越面部特写的身份保持个性化生成任务中实现了稳定有效的性能，无需手动遮罩或微调即可高效生成。

Conclusion: 该方法可作为即插即用组件快速部署到现有框架中，解决了对面部特写的过度依赖，促进了电影级角色场景创作，为相关领域提供了更丰富的个性化生成能力。

Abstract: Identity-Preserving Personalized Generation (IPPG) has advanced film production and artistic creation, yet existing approaches overemphasize facial regions, resulting in outputs dominated by facial close-ups.These methods suffer from weak visual narrativity and poor semantic consistency under complex text prompts, with the core limitation rooted in identity (ID) feature embeddings undermining the semantic expressiveness of generative models. To address these issues, this paper presents an IPPG method that breaks the constraint of facial close-ups, achieving synergistic optimization of identity fidelity and scene semantic creation. Specifically, we design a Dual-Line Inference (DLI) pipeline with identity-semantic separation, resolving the representation conflict between ID and semantics inherent in traditional single-path architectures. Further, we propose an Identity Adaptive Fusion (IdAF) strategy that defers ID-semantic fusion to the noise prediction stage, integrating adaptive attention fusion and noise decision masking to avoid ID embedding interference on semantics without manual masking. Finally, an Identity Aggregation Prepending (IdAP) module is introduced to aggregate ID information and replace random initializations, further enhancing identity preservation. Experimental results validate that our method achieves stable and effective performance in IPPG tasks beyond facial close-ups, enabling efficient generation without manual masking or fine-tuning. As a plug-and-play component, it can be rapidly deployed in existing IPPG frameworks, addressing the over-reliance on facial close-ups, facilitating film-level character-scene creation, and providing richer personalized generation capabilities for related domains.

</details>


### [22] [Uncertainty-Guided Selective Adaptation Enables Cross-Platform Predictive Fluorescence Microscopy](https://arxiv.org/abs/2511.12006)
*Kai-Wen K. Yang,Andrew Bai,Alexandra Bermudez,Yunqi Hong,Zoe Latham,Iris Sloan,Michael Liu,Vishrut Goyal,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.CV

TL;DR: SIT-ADDA-Auto是一个自配置框架，通过仅调整早期卷积层并冻结深层，结合浅层对抗对齐和预测不确定性来自动选择适应深度，在显微镜图像跨域适应中优于全编码器适应方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习在显微镜应用中面临模型在新仪器或采集设置下失效的问题，传统对抗域适应方法会破坏已学习的语义表示。

Method: 提出SIT-ADDA-Auto框架，仅适应最早期的卷积层并冻结深层，集成浅层对抗对齐和预测不确定性来自动选择适应深度，无需目标标签。

Result: 在曝光和光照变化、跨仪器迁移、多种染色等场景下，SIT-ADDA在重建和下游分割任务中优于全编码器适应和非对抗基线方法，减少了语义特征的漂移。

Conclusion: 该研究为显微镜中的无标签适应提供了设计规则和现场应用方案，代码已公开。

Abstract: Deep learning is transforming microscopy, yet models often fail when applied to images from new instruments or acquisition settings. Conventional adversarial domain adaptation (ADDA) retrains entire networks, often disrupting learned semantic representations. Here, we overturn this paradigm by showing that adapting only the earliest convolutional layers, while freezing deeper layers, yields reliable transfer. Building on this principle, we introduce Subnetwork Image Translation ADDA with automatic depth selection (SIT-ADDA-Auto), a self-configuring framework that integrates shallow-layer adversarial alignment with predictive uncertainty to automatically select adaptation depth without target labels. We demonstrate robustness via multi-metric evaluation, blinded expert assessment, and uncertainty-depth ablations. Across exposure and illumination shifts, cross-instrument transfer, and multiple stains, SIT-ADDA improves reconstruction and downstream segmentation over full-encoder adaptation and non-adversarial baselines, with reduced drift of semantic features. Our results provide a design rule for label-free adaptation in microscopy and a recipe for field settings; the code is publicly available.

</details>


### [23] [Enhancing Road Safety Through Multi-Camera Image Segmentation with Post-Encroachment Time Analysis](https://arxiv.org/abs/2511.12018)
*Shounak Ray Chaudhuri,Arash Jahangiri,Christopher Paolini*

Main category: cs.CV

TL;DR: 本文提出了一种基于多摄像头计算机视觉的实时交通安全评估框架，通过在加州丘拉维斯塔的交叉路口进行验证，使用PET计算来识别高风险区域。


<details>
  <summary>Details</summary>
Motivation: 传统基于事故的交通安全分析受限于数据稀疏性和延迟问题，需要开发实时、高分辨率的评估方法。

Method: 使用四个同步摄像头提供连续视觉覆盖，在NVIDIA Jetson AGX Xavier设备上使用YOLOv11分割进行车辆检测，通过单应矩阵将检测到的车辆多边形转换为统一的鸟瞰图，并开发了像素级PET算法。

Result: 框架能够以亚秒级精度识别高风险区域，在边缘设备上实现实时处理，平均帧率为2.68 FPS，生成800×800像素的对数热图。

Conclusion: 研究验证了基于分散式视觉的PET分析在智能交通系统中的可行性，为高分辨率、实时和可扩展的交叉路口安全评估提供了可复制的方法论。

Abstract: Traffic safety analysis at signalized intersections is vital for reducing vehicle and pedestrian collisions, yet traditional crash-based studies are limited by data sparsity and latency. This paper presents a novel multi-camera computer vision framework for real-time safety assessment through Post-Encroachment Time (PET) computation, demonstrated at the intersection of H Street and Broadway in Chula Vista, California. Four synchronized cameras provide continuous visual coverage, with each frame processed on NVIDIA Jetson AGX Xavier devices using YOLOv11 segmentation for vehicle detection. Detected vehicle polygons are transformed into a unified bird's-eye map using homography matrices, enabling alignment across overlapping camera views. A novel pixel-level PET algorithm measures vehicle position without reliance on fixed cells, allowing fine-grained hazard visualization via dynamic heatmaps, accurate to 3.3 sq-cm. Timestamped vehicle and PET data is stored in an SQL database for long-term monitoring. Results over various time intervals demonstrate the framework's ability to identify high-risk regions with sub-second precision and real-time throughput on edge devices, producing data for an 800 x 800 pixel logarithmic heatmap at an average of 2.68 FPS. This study validates the feasibility of decentralized vision-based PET analysis for intelligent transportation systems, offering a replicable methodology for high-resolution, real-time, and scalable intersection safety evaluation.

</details>


### [24] [LIHE: Linguistic Instance-Split Hyperbolic-Euclidean Framework for Generalized Weakly-Supervised Referring Expression Comprehension](https://arxiv.org/abs/2511.12020)
*Xianglong Shi,Silin Cheng,Sirui Zhao,Yunhan Jiang,Enhong Chen,Yang Liu,Sebastien Ourselin*

Main category: cs.CV

TL;DR: 本文提出了一种新的弱监督广义指代表达理解框架LIHE，解决了现有方法无法处理零个或多个目标表达式的限制，通过两阶段方法结合双曲几何和欧氏几何来防止语义崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督指代表达理解方法受限于一对一映射假设，无法处理现实场景中对应零个或多个目标的表达式，因此需要开发更实用的广义指代表达理解方法。

Method: 提出LIHE框架，包含两个阶段：指称解耦阶段预测目标对象数量并分解复杂表达式；指称定位阶段使用HEMix混合相似度模块，结合欧氏几何的精确对齐能力和双曲几何的层次建模优势。

Result: 在gRefCOCO和Ref-ZOM数据集上建立了首个有效的弱监督WGREC基线，HEMix在标准REC基准测试中持续改进，IoU@0.5提升高达2.5%。

Conclusion: LIHE框架成功解决了弱监督广义指代表达理解任务中的监督信号模糊和语义表示崩溃问题，为更实用的指代表达理解系统提供了有效解决方案。

Abstract: Existing Weakly-Supervised Referring Expression Comprehension (WREC) methods, while effective, are fundamentally limited by a one-to-one mapping assumption, hindering their ability to handle expressions corresponding to zero or multiple targets in realistic scenarios. To bridge this gap, we introduce the Weakly-Supervised Generalized Referring Expression Comprehension task (WGREC), a more practical paradigm that handles expressions with variable numbers of referents. However, extending WREC to WGREC presents two fundamental challenges: supervisory signal ambiguity, where weak image-level supervision is insufficient for training a model to infer the correct number and identity of referents, and semantic representation collapse, where standard Euclidean similarity forces hierarchically-related concepts into non-discriminative clusters, blurring categorical boundaries. To tackle these challenges, we propose a novel WGREC framework named Linguistic Instance-Split Hyperbolic-Euclidean (LIHE), which operates in two stages. The first stage, Referential Decoupling, predicts the number of target objects and decomposes the complex expression into simpler sub-expressions. The second stage, Referent Grounding, then localizes these sub-expressions using HEMix, our innovative hybrid similarity module that synergistically combines the precise alignment capabilities of Euclidean proximity with the hierarchical modeling strengths of hyperbolic geometry. This hybrid approach effectively prevents semantic collapse while preserving fine-grained distinctions between related concepts. Extensive experiments demonstrate LIHE establishes the first effective weakly supervised WGREC baseline on gRefCOCO and Ref-ZOM, while HEMix achieves consistent improvements on standard REC benchmarks, improving IoU@0.5 by up to 2.5\%. The code is available at https://anonymous.4open.science/r/LIHE.

</details>


### [25] [Null-Space Diffusion Distillation for Efficient Photorealistic Lensless Imaging](https://arxiv.org/abs/2511.12024)
*Jose Reinaldo Cunha Santos A V Silva Neto,Hodaka Kawachi,Yasushi Yagi,Tomoya Nakamura*

Main category: cs.CV

TL;DR: 本文提出了Null-Space Diffusion Distillation (NSDD)方法，通过分离范围空间约束和零空间扩散先验更新，在无配对监督的情况下实现快速、逼真的无透镜图像重建。


<details>
  <summary>Details</summary>
Motivation: 现有的无透镜相机逼真重建方法通常依赖配对的无透镜-有透镜监督，这会因透镜-无透镜域不匹配而产生偏差。为了避免这个问题，无真实数据的扩散先验很有吸引力，但通用方法在噪声、高度复用且病态的无透镜反卷积设置下往往失效。

Method: 引入Null-Space Diffusion Distillation (NSDD)：一个单次通过的学生模型，它蒸馏迭代DDNM+求解器的零空间分量，以无透镜测量和范围空间锚点为条件。NSDD保持测量一致性，无需配对监督即可实现逼真结果。

Result: 在Lensless-FFHQ和PhlatCam数据集上，NSDD是第二快的方法（仅次于Wiener），实现了接近教师的感知质量（第二好的LPIPS，低于DDNM+），优于DPS和经典凸优化基线。

Conclusion: 这些结果表明了实现快速、无真实数据、逼真的无透镜成像的实用路径。

Abstract: State-of-the-art photorealistic reconstructions for lensless cameras often rely on paired lensless-lensed supervision, which can bias models due to lens-lensless domain mismatch. To avoid this, ground-truth-free diffusion priors are attractive; however, generic formulations tuned for conventional inverse problems often break under the noisy, highly multiplexed, and ill-posed lensless deconvolution setting. We observe that methods which separate range-space enforcement from null-space diffusion-prior updates yield stable, realistic reconstructions. Building on this, we introduce Null-Space Diffusion Distillation (NSDD): a single-pass student that distills the null-space component of an iterative DDNM+ solver, conditioned on the lensless measurement and on a range-space anchor. NSDD preserves measurement consistency and achieves photorealistic results without paired supervision at a fraction of the runtime and memory. On Lensless-FFHQ and PhlatCam, NSDD is the second fastest, behind Wiener, and achieves near-teacher perceptual quality (second-best LPIPS, below DDNM+), outperforming DPS and classical convex baselines. These results suggest a practical path toward fast, ground-truth-free, photorealistic lensless imaging.

</details>


### [26] [Bridging Vision and Language for Robust Context-Aware Surgical Point Tracking: The VL-SurgPT Dataset and Benchmark](https://arxiv.org/abs/2511.12026)
*Rulin Zhou,Wenlong He,An Wang,Jianhang Zhang,Xuanhui Zeng,Xi Zhang,Chaowei Zhu,Haijun Hu,Hongliang Ren*

Main category: cs.CV

TL;DR: VL-SurgPT是首个大规模多模态手术点跟踪数据集，结合视觉跟踪与文本描述，包含908个体内视频片段，涵盖组织和器械跟踪。提出TG-SurgPT文本引导跟踪方法，在视觉挑战条件下显著提升跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 手术环境中复杂视觉条件（烟雾遮挡、镜面反射、组织变形）使精确点跟踪具有挑战性，现有数据集缺乏理解跟踪失败机制的语义上下文。

Method: 引入VL-SurgPT数据集，包含754个组织跟踪视频（17,171个标注点）和154个器械跟踪视频（7种器械类型）。建立8种最先进跟踪方法的基准，提出TG-SurgPT文本引导跟踪方法，利用语义描述提升鲁棒性。

Result: 实验结果表明，融入点状态信息显著提高了跟踪精度和可靠性，特别是在视觉挑战场景中，传统纯视觉方法表现不佳。

Conclusion: 通过桥接视觉和语言模态，VL-SurgPT能够开发上下文感知跟踪系统，这对推进计算机辅助手术应用至关重要，即使在挑战性术中条件下也能保持性能。

Abstract: Accurate point tracking in surgical environments remains challenging due to complex visual conditions, including smoke occlusion, specular reflections, and tissue deformation. While existing surgical tracking datasets provide coordinate information, they lack the semantic context necessary to understand tracking failure mechanisms. We introduce VL-SurgPT, the first large-scale multimodal dataset that bridges visual tracking with textual descriptions of point status in surgical scenes. The dataset comprises 908 in vivo video clips, including 754 for tissue tracking (17,171 annotated points across five challenging scenarios) and 154 for instrument tracking (covering seven instrument types with detailed keypoint annotations). We establish comprehensive benchmarks using eight state-of-the-art tracking methods and propose TG-SurgPT, a text-guided tracking approach that leverages semantic descriptions to improve robustness in visually challenging conditions. Experimental results demonstrate that incorporating point status information significantly improves tracking accuracy and reliability, particularly in adverse visual scenarios where conventional vision-only methods struggle. By bridging visual and linguistic modalities, VL-SurgPT enables the development of context-aware tracking systems crucial for advancing computer-assisted surgery applications that can maintain performance even under challenging intraoperative conditions.

</details>


### [27] [VPHO: Joint Visual-Physical Cue Learning and Aggregation for Hand-Object Pose Estimation](https://arxiv.org/abs/2511.12030)
*Jun Zhou,Chi Xu,Kaifeng Tang,Yuting Ge,Tingrui Guo,Li Cheng*

Main category: cs.CV

TL;DR: 提出了一种结合视觉和物理线索的联合框架，用于从单张RGB图像估计手和物体的3D姿态，通过视觉-物理线索联合学习和候选姿态聚合，实现视觉一致且物理合理的结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，往往产生违反物理约束的结果，而现有的物理推理方法通常依赖后优化或不可微物理引擎，影响视觉一致性和端到端可训练性。

Method: 1) 视觉-物理线索联合学习：训练模型提取2D视觉线索和3D物理线索；2) 候选姿态聚合：利用扩散生成的多个候选姿态，结合视觉和物理预测进行聚合优化。

Result: 大量实验表明，该方法在姿态精度和物理合理性方面显著优于现有最先进方法。

Conclusion: 提出的联合视觉-物理框架能够有效解决手-物体姿态估计中的物理约束问题，实现视觉一致且物理合理的结果。

Abstract: Estimating the 3D poses of hands and objects from a single RGB image is a fundamental yet challenging problem, with broad applications in augmented reality and human-computer interaction. Existing methods largely rely on visual cues alone, often producing results that violate physical constraints such as interpenetration or non-contact. Recent efforts to incorporate physics reasoning typically depend on post-optimization or non-differentiable physics engines, which compromise visual consistency and end-to-end trainability. To overcome these limitations, we propose a novel framework that jointly integrates visual and physical cues for hand-object pose estimation. This integration is achieved through two key ideas: 1) joint visual-physical cue learning: The model is trained to extract 2D visual cues and 3D physical cues, thereby enabling more comprehensive representation learning for hand-object interactions; 2) candidate pose aggregation: A novel refinement process that aggregates multiple diffusion-generated candidate poses by leveraging both visual and physical predictions, yielding a final estimate that is visually consistent and physically plausible. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art approaches in both pose accuracy and physical plausibility.

</details>


### [28] [Improved Masked Image Generation with Knowledge-Augmented Token Representations](https://arxiv.org/abs/2511.12032)
*Guotao Liang,Baoquan Zhang,Zhiyuan Wen,Zihao Han,Yunming Ye*

Main category: cs.CV

TL;DR: KA-MIG是一个知识增强的掩码图像生成框架，通过引入三种类型的token知识图（共现图、语义相似图、位置token不兼容图）作为先验知识，来增强模型捕捉语义依赖关系的能力，从而提高图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有掩码图像生成方法仅依赖模型自身学习视觉token序列的语义依赖关系，但由于单个token缺乏明确语义含义且序列通常较长，直接从数据中学习这些依赖关系具有挑战性。

Method: 提出KA-MIG框架，构建三种token知识图作为先验知识，设计图感知编码器学习token和位置感知表示，并通过轻量级融合机制将这些丰富表示集成到现有MIG方法中。

Result: 实验结果表明，该方法在ImageNet上的类条件图像生成任务中优于现有MIG方法。

Conclusion: 通过引入token级语义依赖关系的显式知识作为先验，KA-MIG有效增强了模型捕捉语义依赖的能力，提高了生成质量。

Abstract: Masked image generation (MIG) has demonstrated remarkable efficiency and high-fidelity images by enabling parallel token prediction. Existing methods typically rely solely on the model itself to learn semantic dependencies among visual token sequences. However, directly learning such semantic dependencies from data is challenging because the individual tokens lack clear semantic meanings, and these sequences are usually long. To address this limitation, we propose a novel Knowledge-Augmented Masked Image Generation framework, named KA-MIG, which introduces explicit knowledge of token-level semantic dependencies (\emph{i.e.}, extracted from the training data) as priors to learn richer representations for improving performance. In particular, we explore and identify three types of advantageous token knowledge graphs, including two positive and one negative graphs (\emph{i.e.}, the co-occurrence graph, the semantic similarity graph, and the position-token incompatibility graph). Based on three prior knowledge graphs, we design a graph-aware encoder to learn token and position-aware representations. After that, a lightweight fusion mechanism is introduced to integrate these enriched representations into the existing MIG methods. Resorting to such prior knowledge, our method effectively enhances the model's ability to capture semantic dependencies, leading to improved generation quality. Experimental results demonstrate that our method improves upon existing MIG for class-conditional image generation on ImageNet.

</details>


### [29] [Calibrated Multimodal Representation Learning with Missing Modalities](https://arxiv.org/abs/2511.12034)
*Xiaohao Liu,Xiaobo Xia,Jiaheng Wei,Shuo Yang,Xiu Su,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 提出了CalMRL方法，用于解决多模态表示学习中因模态缺失导致的对齐偏差问题，通过表示级插补和双步学习来校准不完整对齐。


<details>
  <summary>Details</summary>
Motivation: 现有多模态表示学习方法需要所有模态都存在才能实现有效对齐，而实际数据集中普遍存在模态缺失问题，导致对齐偏差。

Method: 利用模态先验和内在联系在表示级对缺失模态进行建模，采用双步学习方法结合共享潜在变量的后验分布闭式解来解决优化困境。

Result: 理论验证了方法能够缓解锚点偏移并保证收敛，实验证明CalMRL的优越性，为吸收缺失模态数据提供了新的灵活性。

Conclusion: CalMRL有效解决了多模态表示学习中模态缺失导致的对齐问题，通过校准对齐机制提升了方法的实用性和性能。

Abstract: Multimodal representation learning harmonizes distinct modalities by aligning them into a unified latent space. Recent research generalizes traditional cross-modal alignment to produce enhanced multimodal synergy but requires all modalities to be present for a common instance, making it challenging to utilize prevalent datasets with missing modalities. We provide theoretical insights into this issue from an anchor shift perspective. Observed modalities are aligned with a local anchor that deviates from the optimal one when all modalities are present, resulting in an inevitable shift. To address this, we propose CalMRL for multimodal representation learning to calibrate incomplete alignments caused by missing modalities. Specifically, CalMRL leverages the priors and the inherent connections among modalities to model the imputation for the missing ones at the representation level. To resolve the optimization dilemma, we employ a bi-step learning method with the closed-form solution of the posterior distribution of shared latents. We validate its mitigation of anchor shift and convergence with theoretical guidance. By equipping the calibrated alignment with the existing advanced method, we offer new flexibility to absorb data with missing modalities, which is originally unattainable. Extensive experiments and comprehensive analyses demonstrate the superiority of CalMRL. Our code, model checkpoints, and evaluation raw data will be publicly available.

</details>


### [30] [SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images](https://arxiv.org/abs/2511.12040)
*Xinyuan Hu,Changyue Shi,Chuxiao Yang,Minghao Chen,Jiajun Ding,Tao Wei,Chen Wei,Zhou Yu,Min Tan*

Main category: cs.CV

TL;DR: SRSplat是一个前馈框架，能够从少量低分辨率图像重建高分辨率3D场景，通过结合外部高质量参考图像和内部纹理线索来补偿纹理信息不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法从稀疏低分辨率图像进行3D重建时往往无法恢复精细纹理细节，这源于低分辨率输入中高频信息的固有缺乏。

Method: 构建场景特定参考图库，使用多模态大语言模型和扩散模型生成；引入参考引导特征增强模块对齐和融合低分辨率输入图像与参考图像的特征；训练解码器预测高斯基元；使用纹理感知密度控制自适应调整高斯密度。

Result: 在RealEstate10K、ACID和DTU等多个数据集上的广泛实验表明，SRSplat优于现有方法，并展现出强大的跨数据集和跨分辨率泛化能力。

Conclusion: SRSplat通过有效整合外部参考信息和内部纹理线索，成功解决了从稀疏低分辨率图像重建高分辨率3D场景时纹理细节恢复不足的问题。

Abstract: Feed-forward 3D reconstruction from sparse, low-resolution (LR) images is a crucial capability for real-world applications, such as autonomous driving and embodied AI. However, existing methods often fail to recover fine texture details. This limitation stems from the inherent lack of high-frequency information in LR inputs. To address this, we propose \textbf{SRSplat}, a feed-forward framework that reconstructs high-resolution 3D scenes from only a few LR views. Our main insight is to compensate for the deficiency of texture information by jointly leveraging external high-quality reference images and internal texture cues. We first construct a scene-specific reference gallery, generated for each scene using Multimodal Large Language Models (MLLMs) and diffusion models. To integrate this external information, we introduce the \textit{Reference-Guided Feature Enhancement (RGFE)} module, which aligns and fuses features from the LR input images and their reference twin image. Subsequently, we train a decoder to predict the Gaussian primitives using the multi-view fused feature obtained from \textit{RGFE}. To further refine predicted Gaussian primitives, we introduce \textit{Texture-Aware Density Control (TADC)}, which adaptively adjusts Gaussian density based on the internal texture richness of the LR inputs. Extensive experiments demonstrate that our SRSplat outperforms existing methods on various datasets, including RealEstate10K, ACID, and DTU, and exhibits strong cross-dataset and cross-resolution generalization capabilities.

</details>


### [31] [FedSDA: Federated Stain Distribution Alignment for Non-IID Histopathological Image Classification](https://arxiv.org/abs/2511.12044)
*Cheng-Chang Tsai,Kai-Wen Cheng,Chun-Shien Lu*

Main category: cs.CV

TL;DR: 提出了FedSDA方法，通过扩散模型和染色分离技术来对齐联邦学习中非IID组织病理学图像的染色分布，以缓解客户端间的分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中非IID数据分布是不可避免的挑战，特别是在组织病理学图像中，特征分布偏移会严重影响模型性能。

Method: 基于扩散模型拟合数据分布的能力，利用染色分离提取与组织病理学图像非IID特性相关的关键特征，在联邦学习框架中对齐每个客户端的染色分布到目标分布。

Result: 实验结果表明FedSDA不仅有效改善了关注客户端模型更新差异的基线方法，还优于从数据分布角度解决非IID问题的基线方法。

Conclusion: FedSDA为计算病理学社区提供了有价值的实用见解，能够有效缓解联邦学习中的非IID数据问题。

Abstract: Federated learning (FL) has shown success in collaboratively training a model among decentralized data resources without directly sharing privacy-sensitive training data. Despite recent advances, non-IID (non-independent and identically distributed) data poses an inevitable challenge that hinders the use of FL. In this work, we address the issue of non-IID histopathological images with feature distribution shifts from an intuitive perspective that has only received limited attention. Specifically, we address this issue from the perspective of data distribution by solely adjusting the data distributions of all clients. Building on the success of diffusion models in fitting data distributions and leveraging stain separation to extract the pivotal features that are closely related to the non-IID properties of histopathological images, we propose a Federated Stain Distribution Alignment (FedSDA) method. FedSDA aligns the stain distribution of each client with a target distribution in an FL framework to mitigate distribution shifts among clients. Furthermore, considering that training diffusion models on raw data in FL has been shown to be susceptible to privacy leakage risks, we circumvent this problem while still effectively achieving alignment. Extensive experimental results show that FedSDA is not only effective in improving baselines that focus on mitigating disparities across clients' model updates but also outperforms baselines that address the non-IID data issues from the perspective of data distribution. We show that FedSDA provides valuable and practical insights for the computational pathology community.

</details>


### [32] [DCMM-Transformer: Degree-Corrected Mixed-Membership Attention for Medical Imaging](https://arxiv.org/abs/2511.12047)
*Huimin Cheng,Xiaowei Yu,Shushan Wu,Luyang Fang,Chao Cao,Jing Zhang,Tianming Liu,Dajiang Zhu,Wenxuan Zhong,Ping Ma*

Main category: cs.CV

TL;DR: DCMM-Transformer是一种用于医学图像分析的Vision Transformer架构，通过引入度校正混合成员模型作为自注意力中的加性偏置，解决了标准ViT无法利用解剖结构的问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像存在潜在的解剖分组结构（如器官、组织和病理区域），但标准Vision Transformer无法有效利用这些结构。现有方法如SBM-Transformer存在不可微分、训练不稳定和无法建模复杂社区结构的问题。

Method: 提出DCMM-Transformer，将度校正混合成员模型作为自注意力中的加性偏置引入，以完全可微分和可解释的方式建模社区结构和度异质性，避免了乘性掩码和二值采样。

Result: 在包括脑部、胸部、乳腺和眼部等多种医学成像数据集上的综合实验表明，该方法具有优越的性能和泛化能力。

Conclusion: 学习到的分组结构和结构化注意力调制显著增强了可解释性，产生了具有解剖意义和语义一致性的注意力图。

Abstract: Medical images exhibit latent anatomical groupings, such as organs, tissues, and pathological regions, that standard Vision Transformers (ViTs) fail to exploit. While recent work like SBM-Transformer attempts to incorporate such structures through stochastic binary masking, they suffer from non-differentiability, training instability, and the inability to model complex community structure. We present DCMM-Transformer, a novel ViT architecture for medical image analysis that incorporates a Degree-Corrected Mixed-Membership (DCMM) model as an additive bias in self-attention. Unlike prior approaches that rely on multiplicative masking and binary sampling, our method introduces community structure and degree heterogeneity in a fully differentiable and interpretable manner. Comprehensive experiments across diverse medical imaging datasets, including brain, chest, breast, and ocular modalities, demonstrate the superior performance and generalizability of the proposed approach. Furthermore, the learned group structure and structured attention modulation substantially enhance interpretability by yielding attention maps that are anatomically meaningful and semantically coherent.

</details>


### [33] [DeiTFake: Deepfake Detection Model using DeiT Multi-Stage Training](https://arxiv.org/abs/2511.12048)
*Saksham Kumar,Ashish Singh,Srinivasarao Thota,Sunil Kumar Singh,Chandan Kumar*

Main category: cs.CV

TL;DR: 提出DeiTFake方法，基于DeiT变换器，采用两阶段渐进训练策略，通过知识蒸馏捕获深度伪造的细微痕迹，在OpenForensics数据集上达到99.22%准确率和0.9997 AUROC。


<details>
  <summary>Details</summary>
Motivation: 深度伪造对数字媒体完整性构成重大威胁，需要开发更有效的检测方法来应对这一挑战。

Method: 使用DeiT变换器架构，提出两阶段渐进训练策略：第一阶段使用标准增强进行迁移学习，第二阶段使用高级仿射和深度伪造特定增强进行微调，利用知识蒸馏模型捕捉细微操作痕迹。

Result: 在OpenForensics数据集（190,335张图像）上，第一阶段达到98.71%准确率，第二阶段达到99.22%准确率和0.9997 AUROC，优于最新的OpenForensics基线方法。

Conclusion: DeiTFake方法通过两阶段渐进训练和知识蒸馏，显著提升了面部深度伪造检测性能，为实际应用提供了实用基准。

Abstract: Deepfakes are major threats to the integrity of digital media. We propose DeiTFake, a DeiT-based transformer and a novel two-stage progressive training strategy with increasing augmentation complexity. The approach applies an initial transfer-learning phase with standard augmentations followed by a fine-tuning phase using advanced affine and deepfake-specific augmentations. DeiT's knowledge distillation model captures subtle manipulation artifacts, increasing robustness of the detection model. Trained on the OpenForensics dataset (190,335 images), DeiTFake achieves 98.71\% accuracy after stage one and 99.22\% accuracy with an AUROC of 0.9997, after stage two, outperforming the latest OpenForensics baselines. We analyze augmentation impact and training schedules, and provide practical benchmarks for facial deepfake detection.

</details>


### [34] [UniABG: Unified Adversarial View Bridging and Graph Correspondence for Unsupervised Cross-View Geo-Localization](https://arxiv.org/abs/2511.12054)
*Cuiqun Chen,Qi Chen,Bin Yang,Xingyi Zhang*

Main category: cs.CV

TL;DR: UniABG是一个新颖的双阶段无监督跨视角地理定位框架，通过对抗性视角桥接和图基对应校准来解决跨视角域差距问题，在无监督设置下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 监督方法依赖大量成对标注限制了可扩展性，而无监督方法由于跨视角域差距导致伪标签噪声严重，需要解决这些限制。

Method: 提出双阶段框架：首先使用视图感知对抗桥接(VAAB)建模视图不变特征并增强伪标签鲁棒性；随后通过异构图过滤校准(HGFC)构建双跨视图结构图来精化跨视图关联。

Result: 在University-1652数据集上卫星→无人机AP提升+10.63%，在SUES-200数据集上提升+16.73%，甚至超过了监督基线方法。

Conclusion: UniABG通过集成对抗性视图桥接和图基对应校准，有效解决了无监督跨视角地理定位中的伪标签噪声问题，实现了优异的性能表现。

Abstract: Cross-view geo-localization (CVGL) matches query images ($\textit{e.g.}$, drone) to geographically corresponding opposite-view imagery ($\textit{e.g.}$, satellite). While supervised methods achieve strong performance, their reliance on extensive pairwise annotations limits scalability. Unsupervised alternatives avoid annotation costs but suffer from noisy pseudo-labels due to intrinsic cross-view domain gaps. To address these limitations, we propose $\textit{UniABG}$, a novel dual-stage unsupervised cross-view geo-localization framework integrating adversarial view bridging with graph-based correspondence calibration. Our approach first employs View-Aware Adversarial Bridging (VAAB) to model view-invariant features and enhance pseudo-label robustness. Subsequently, Heterogeneous Graph Filtering Calibration (HGFC) refines cross-view associations by constructing dual inter-view structure graphs, achieving reliable view correspondence. Extensive experiments demonstrate state-of-the-art unsupervised performance, showing that UniABG improves Satellite $\rightarrow$ Drone AP by +10.63\% on University-1652 and +16.73\% on SUES-200, even surpassing supervised baselines. The source code is available at https://github.com/chenqi142/UniABG

</details>


### [35] [PipeDiT: Accelerating Diffusion Transformers in Video Generation with Task Pipelining and Model Decoupling](https://arxiv.org/abs/2511.12056)
*Sijie Wang,Qiang Wang,Shaohuai Shi*

Main category: cs.CV

TL;DR: PipeDiT是一个用于加速视频生成的流水线框架，通过序列并行、解耦VAE和注意力协同处理三个创新方法，在8-GPU系统上实现了1.06-4.02倍的加速。


<details>
  <summary>Details</summary>
Motivation: 基于扩散变换器的视频生成模型虽然性能出色，但实际部署受到推理速度慢和内存消耗高的限制，需要优化方案。

Method: 1. 设计序列并行流水线算法(PipeSP)实现GPU间计算与通信的流水线化；2. 提出DeDiVAE将扩散模块和VAE模块解耦到不同GPU组并行执行；3. 提出注意力协同处理(Aco)方法优化VAE组GPU资源利用。

Result: 在OpenSoraPlan和HunyuanVideo两个开源框架上集成PipeDiT，在多种常见分辨率和时间步配置下，相比原框架实现了1.06-4.02倍的加速效果。

Conclusion: PipeDiT框架通过创新的流水线设计有效解决了视频生成模型的推理延迟和内存消耗问题，为实际部署提供了可行的加速方案。

Abstract: Video generation has been advancing rapidly, and diffusion transformer (DiT) based models have demonstrated remark- able capabilities. However, their practical deployment is of- ten hindered by slow inference speeds and high memory con- sumption. In this paper, we propose a novel pipelining frame- work named PipeDiT to accelerate video generation, which is equipped with three main innovations. First, we design a pipelining algorithm (PipeSP) for sequence parallelism (SP) to enable the computation of latent generation and commu- nication among multiple GPUs to be pipelined, thus reduc- ing inference latency. Second, we propose DeDiVAE to de- couple the diffusion module and the variational autoencoder (VAE) module into two GPU groups, whose executions can also be pipelined to reduce memory consumption and infer- ence latency. Third, to better utilize the GPU resources in the VAE group, we propose an attention co-processing (Aco) method to further reduce the overall video generation latency. We integrate our PipeDiT into both OpenSoraPlan and Hun- yuanVideo, two state-of-the-art open-source video generation frameworks, and conduct extensive experiments on two 8- GPU systems. Experimental results show that, under many common resolution and timestep configurations, our PipeDiT achieves 1.06x to 4.02x speedups over OpenSoraPlan and HunyuanVideo.

</details>


### [36] [MovSemCL: Movement-Semantics Contrastive Learning for Trajectory Similarity](https://arxiv.org/abs/2511.12061)
*Zhichen Lai,Hua Lu,Huan Li,Jialiang Li,Christian S. Jensen*

Main category: cs.CV

TL;DR: MovSemCL是一个基于运动语义对比学习的轨迹相似度计算框架，通过将GPS轨迹转换为运动语义特征并分块处理，使用内外注意力机制编码局部和全局模式，结合曲率引导的数据增强策略，在保持物理合理性的同时提升计算效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于学习的轨迹相似度计算方法存在的三个关键问题：(1) 对轨迹语义和层次结构建模不足；(2) 逐点编码导致计算成本高；(3) 使用物理上不合理的增强方法扭曲轨迹语义。

Method: 提出MovSemCL框架：首先将原始GPS轨迹转换为运动语义特征并分块，然后使用内外注意力机制编码局部和全局轨迹模式，实现高效层次表示；采用曲率引导的增强策略，保留信息丰富的片段（如转弯和交叉口）并屏蔽冗余部分。

Result: 在真实世界数据集上的实验表明，MovSemCL在相似度搜索任务中达到接近理想值1的平均排名，在启发式近似方面提升高达20.3%，同时推理延迟降低高达43.4%，优于现有最先进方法。

Conclusion: MovSemCL通过有效的运动语义建模、层次表示学习和物理合理的增强策略，显著提升了轨迹相似度计算的性能和效率，为轨迹聚类、预测和异常检测等应用提供了更好的基础功能。

Abstract: Trajectory similarity computation is fundamental functionality that is used for, e.g., clustering, prediction, and anomaly detection. However, existing learning-based methods exhibit three key limitations: (1) insufficient modeling of trajectory semantics and hierarchy, lacking both movement dynamics extraction and multi-scale structural representation; (2) high computational costs due to point-wise encoding; and (3) use of physically implausible augmentations that distort trajectory semantics. To address these issues, we propose MovSemCL, a movement-semantics contrastive learning framework for trajectory similarity computation. MovSemCL first transforms raw GPS trajectories into movement-semantics features and then segments them into patches. Next, MovSemCL employs intra- and inter-patch attentions to encode local as well as global trajectory patterns, enabling efficient hierarchical representation and reducing computational costs. Moreover, MovSemCL includes a curvature-guided augmentation strategy that preserves informative segments (e.g., turns and intersections) and masks redundant ones, generating physically plausible augmented views. Experiments on real-world datasets show that MovSemCL is capable of outperforming state-of-the-art methods, achieving mean ranks close to the ideal value of 1 at similarity search tasks and improvements by up to 20.3% at heuristic approximation, while reducing inference latency by up to 43.4%.

</details>


### [37] [DCA-LUT: Deep Chromatic Alignment with 5D LUT for Purple Fringing Removal](https://arxiv.org/abs/2511.12066)
*Jialang Lu,Shuning Sun,Pu Wang,Chen Wu,Feng Gao,Lina Gong,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: DCA-LUT是首个基于深度学习的紫色边缘去除框架，通过色度感知坐标变换模块分离紫色边缘到专用维度，并使用5D查找表进行高效非线性色彩映射，在合成和真实数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统紫色边缘去除方法依赖昂贵的消色差镜头硬件和手工特征提取，忽视了数据驱动方法。为了解决这个问题，作者提出了首个深度学习框架来处理由镜头色差引起的紫色边缘问题。

Method: 提出DCA-LUT框架，包含色度感知坐标变换(CA-CT)模块来学习图像自适应色彩空间，将紫色边缘分离到专用维度，然后使用5D查找表进行色彩校正。构建了大规模合成紫色边缘数据集(PF-Synth)用于训练和评估。

Result: 在合成和真实数据集上的广泛实验表明，该方法在紫色边缘去除方面达到了最先进的性能。

Conclusion: DCA-LUT框架通过数据驱动方法有效解决了紫色边缘问题，超越了传统硬件依赖和手工特征提取的方法，为数字成像质量提升提供了新的解决方案。

Abstract: Purple fringing, a persistent artifact caused by Longitudinal Chromatic Aberration (LCA) in camera lenses, has long degraded the clarity and realism of digital imaging. Traditional solutions rely on complex and expensive apochromatic (APO) lens hardware and the extraction of handcrafted features, ignoring the data-driven approach. To fill this gap, we introduce DCA-LUT, the first deep learning framework for purple fringing removal. Inspired by the physical root of the problem, the spatial misalignment of RGB color channels due to lens dispersion, we introduce a novel Chromatic-Aware Coordinate Transformation (CA-CT) module, learning an image-adaptive color space to decouple and isolate fringing into a dedicated dimension. This targeted separation allows the network to learn a precise ``purple fringe channel", which then guides the accurate restoration of the luminance channel. The final color correction is performed by a learned 5D Look-Up Table (5D LUT), enabling efficient and powerful% non-linear color mapping. To enable robust training and fair evaluation, we constructed a large-scale synthetic purple fringing dataset (PF-Synth). Extensive experiments in synthetic and real-world datasets demonstrate that our method achieves state-of-the-art performance in purple fringing removal.

</details>


### [38] [Learning to Hear by Seeing: It's Time for Vision Language Models to Understand Artistic Emotion from Sight and Sound](https://arxiv.org/abs/2511.12077)
*Dengming Zhang,Weitao You,Jingxiong Li,Weishen Lin,Wenda Shi,Xue Zhao,Heda Zuo,Junxian Wu,Lingyun Sun*

Main category: cs.CV

TL;DR: VAEmotionLLM是一个两阶段框架，通过有限的音频预训练教会视觉语言模型听觉能力，并增强跨模态情感理解。该方法在艺术情感基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在情感理解方面存在不足，而艺术作品通过视听元素联合设计传达情感，但先前工作多为单模态或人类中心，忽略了艺术作品有意表达的情感。同时，当前视听语言模型需要大规模音频预训练，限制了可扩展性。

Method: 提出两阶段框架：第一阶段通过视觉引导音频对齐（VG-Align）将冻结的视觉通路蒸馏到新的音频通路，实现无需大规模音频数据集的听觉能力；第二阶段通过轻量级跨模态情感适配器（EmoAdapter）注入情感敏感残差并应用情感监督来增强跨模态情感理解。

Result: 在构建的ArtEmoBenchmark艺术情感基准测试中，VAEmotionLLM在音频、视觉和视听输入下均优于音频、视觉和视听基线模型，达到最先进水平。消融实验表明所提组件具有互补性。

Conclusion: VAEmotionLLM成功实现了通过有限音频预训练赋予视觉语言模型听觉能力，并显著提升了跨模态情感理解性能，为构建更通用、可靠且与人类对齐的语言模型提供了有效途径。

Abstract: Emotion understanding is critical for making Large Language Models (LLMs) more general, reliable, and aligned with humans. Art conveys emotion through the joint design of visual and auditory elements, yet most prior work is human-centered or single-modality, overlooking the emotion intentionally expressed by the artwork. Meanwhile, current Audio-Visual Language Models (AVLMs) typically require large-scale audio pretraining to endow Visual Language Models (VLMs) with hearing, which limits scalability. We present Vision Anchored Audio-Visual Emotion LLM (VAEmotionLLM), a two-stage framework that teaches a VLM to hear by seeing with limited audio pretraining and to understand emotion across modalities. In Stage 1, Vision-Guided Audio Alignment (VG-Align) distills the frozen visual pathway into a new audio pathway by aligning next-token distributions of the shared LLM on synchronized audio-video clips, enabling hearing without a large audio dataset. In Stage 2, a lightweight Cross-Modal Emotion Adapter (EmoAdapter), composed of the Emotion Enhancer and the Emotion Supervisor, injects emotion-sensitive residuals and applies emotion supervision to enhance cross-modal emotion understanding. We also construct ArtEmoBenchmark, an art-centric emotion benchmark that evaluates content and emotion understanding under audio-only, visual-only, and audio-visual inputs. VAEmotionLLM achieves state-of-the-art results on ArtEmoBenchmark, outperforming audio-only, visual-only, and audio-visual baselines. Ablations show that the proposed components are complementary.

</details>


### [39] [Point Cloud Quantization through Multimodal Prompting for 3D Understanding](https://arxiv.org/abs/2511.12079)
*Hongxuan Li,Wencheng Zhu,Huiying Xu,Xinzhong Zhu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 提出了一种基于多模态提示驱动的点云量化框架，利用文本嵌入作为原型先验，通过双约束量化空间和Gumbel-Softmax松弛实现几何与语义信息的联合编码。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的向量量化方法在代表性和可解释性方面存在不足，而多模态对齐在视觉语言模型中展现出潜力，但需要解决视觉-语言语义鸿沟问题。

Method: 使用预训练模型的文本嵌入作为原型先验，通过多模态提示自适应优化原型，构建双约束量化空间（紧凑性和分离性正则化），并采用Gumbel-Softmax实现可微离散化。

Result: 在ModelNet40和ScanObjectNN数据集上的大量实验证明该方法具有优越的有效性。

Conclusion: 提出的多模态提示驱动量化框架成功解决了原型代表性和语义鸿沟问题，实现了几何与语义信息的有效联合编码。

Abstract: Vector quantization has emerged as a powerful tool in large-scale multimodal models, unifying heterogeneous representations through discrete token encoding. However, its effectiveness hinges on robust codebook design. Current prototype-based approaches relying on trainable vectors or clustered centroids fall short in representativeness and interpretability, even as multimodal alignment demonstrates its promise in vision-language models. To address these limitations, we propose a simple multimodal prompting-driven quantization framework for point cloud analysis. Our methodology is built upon two core insights: 1) Text embeddings from pre-trained models inherently encode visual semantics through many-to-one contrastive alignment, naturally serving as robust prototype priors; and 2) Multimodal prompts enable adaptive refinement of these prototypes, effectively mitigating vision-language semantic gaps. The framework introduces a dual-constrained quantization space, enforced by compactness and separation regularization, which seamlessly integrates visual and prototype features, resulting in hybrid representations that jointly encode geometric and semantic information. Furthermore, we employ Gumbel-Softmax relaxation to achieve differentiable discretization while maintaining quantization sparsity. Extensive experiments on the ModelNet40 and ScanObjectNN datasets clearly demonstrate the superior effectiveness of the proposed method.

</details>


### [40] [Supervised Multilabel Image Classification Using Residual Networks with Probabilistic Reasoning](https://arxiv.org/abs/2511.12082)
*Lokender Singh,Saksham Kumar,Chandan Kumar*

Main category: cs.CV

TL;DR: 提出了一种基于改进ResNet-101架构和概率推理的多标签图像分类方法，在COCO-2014数据集上实现了0.794 mAP的优异性能。


<details>
  <summary>Details</summary>
Motivation: 多标签图像分类在计算机视觉应用中具有广泛需求，但传统方法难以有效处理标签依赖性和不确定性。

Method: 使用改进的ResNet-101架构，通过概率推理模拟标签依赖性和不确定性来提升预测准确性。

Result: 在COCO-2014数据集上达到0.794 mAP，优于ResNet-SRN(0.771)和Vision Transformer基线(0.785)。

Conclusion: 将概率推理集成到深度学习模型中能有效解决多标签场景的挑战，取得了接近最先进水平的性能。

Abstract: Multilabel image categorization has drawn interest recently because of its numerous computer vision applications. The proposed work introduces a novel method for classifying multilabel images using the COCO-2014 dataset and a modified ResNet-101 architecture. By simulating label dependencies and uncertainties, the approach uses probabilistic reasoning to improve prediction accuracy. Extensive tests show that the model outperforms earlier techniques and approaches to state-of-the-art outcomes in multilabel categorization. The work also thoroughly assesses the model's performance using metrics like precision-recall score and achieves 0.794 mAP on COCO-2014, outperforming ResNet-SRN (0.771) and Vision Transformer baselines (0.785). The novelty of the work lies in integrating probabilistic reasoning into deep learning models to effectively address the challenges presented by multilabel scenarios.

</details>


### [41] [SemanticStitch: Enhancing Image Coherence through Foreground-Aware Seam Carving](https://arxiv.org/abs/2511.12084)
*Ji-Ping Jin,Chen-Bin Feng,Rui Fan,Chi-Man Vong*

Main category: cs.CV

TL;DR: 提出SemanticStitch框架，通过深度学习结合语义先验信息解决图像拼接中的前景对象完整性问题，显著提升拼接质量。


<details>
  <summary>Details</summary>
Motivation: 传统图像拼接方法因拍摄角度、位置差异和物体运动导致错位和视觉差异，且传统接缝雕刻方法忽略语义信息，破坏前景连续性。

Method: 引入SemanticStitch深度学习框架，结合前景对象的语义先验，提出新颖的损失函数强调显著对象的语义完整性。

Result: 实验结果表明相比传统技术有显著改进，提供了两个专门的真实世界数据集验证方法有效性。

Conclusion: 该方法为实际应用提供了强有力的支持，能够有效保持前景对象的完整性并增强视觉连贯性。

Abstract: Image stitching often faces challenges due to varying capture angles, positional differences, and object movements, leading to misalignments and visual discrepancies. Traditional seam carving methods neglect semantic information, causing disruptions in foreground continuity. We introduce SemanticStitch, a deep learning-based framework that incorporates semantic priors of foreground objects to preserve their integrity and enhance visual coherence. Our approach includes a novel loss function that emphasizes the semantic integrity of salient objects, significantly improving stitching quality. We also present two specialized real-world datasets to evaluate our method's effectiveness. Experimental results demonstrate substantial improvements over traditional techniques, providing robust support for practical applications.

</details>


### [42] [Teaching Prompts to Coordinate: Hierarchical Layer-Grouped Prompt Tuning for Continual Learning](https://arxiv.org/abs/2511.12090)
*Shengqin Jiang,Tianqi Kong,Yuankai Qi,Haokui Zhang,Lina Yao,Quan Z. Sheng,Qingshan Liu,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出了一种分层分组提示调优方法，通过层分组共享提示和使用根提示生成子提示，减少层间独立更新，缓解灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于提示的持续学习方法在每个层独立添加任务特定提示，虽然灵活性高但容易导致某些层不必要更新，可能覆盖先前任务的重要特征表示，增加灾难性遗忘风险。

Method: 分层分组提示调优方法：1) 同一组层共享大致相同的提示，通过位置编码调整；2) 使用单一任务特定根提示学习为每个层组生成子提示，增强子提示间的协同性。

Result: 在四个基准测试上的广泛实验表明，该方法相比多种最先进方法取得了优越性能。

Conclusion: 该方法通过分层分组提示调优提高了模型稳定性，有效缓解了灾难性遗忘问题，在持续学习任务中表现优异。

Abstract: Prompt-based continual learning methods fine-tune only a small set of additional learnable parameters while keeping the pre-trained model's parameters frozen. It enables efficient adaptation to new tasks while mitigating the risk of catastrophic forgetting. These methods typically attach one independent task-specific prompt to each layer of pre-trained models to locally modulate its features, ensuring that the layer's representation aligns with the requirements of the new task. However, although introducing learnable prompts independently at each layer provides high flexibility for adapting to new tasks, this overly flexible tuning could make certain layers susceptible to unnecessary updates. As all prompts till the current task are added together as a final prompt for all seen tasks, the model may easily overwrite feature representations essential to previous tasks, which increases the risk of catastrophic forgetting. To address this issue, we propose a novel hierarchical layer-grouped prompt tuning method for continual learning. It improves model stability in two ways: (i) Layers in the same group share roughly the same prompts, which are adjusted by position encoding. This helps preserve the intrinsic feature relationships and propagation pathways of the pre-trained model within each group. (ii) It utilizes a single task-specific root prompt to learn to generate sub-prompts for each layer group. In this way, all sub-prompts are conditioned on the same root prompt, enhancing their synergy and reducing independence. Extensive experiments across four benchmarks demonstrate that our method achieves favorable performance compared with several state-of-the-art methods.

</details>


### [43] [Sparse by Rule: Probability-Based N:M Pruning for Spiking Neural Networks](https://arxiv.org/abs/2511.12097)
*Shuhan Ye,Yi Yu,Qixin Zhang,Chenqi Kong,Qiangqiang Wu,Xudong Jiang,Dacheng Tao*

Main category: cs.CV

TL;DR: SpikeNM是首个面向SNN的半结构化(N:M)剪枝框架，通过M路基对数参数化和可微分top-k采样器，将复杂度从指数级降低到线性，并结合神经科学启发的资格蒸馏方法，在高稀疏度下保持甚至提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决SNN深度架构参数膨胀问题，现有剪枝方法要么难以硬件加速（非结构化），要么缺乏灵活性且精度下降（结构化），需要一种既能硬件友好又能保持精度的半结构化剪枝方案。

Method: 采用M路基对数参数化和可微分top-k采样器线性化复杂度，提出资格启发蒸馏(EID)将时间累积信用转换为块级软目标，对齐掩码概率与脉冲动态。

Result: 在2:4稀疏度下，SpikeNM在主流数据集上保持甚至提升性能，同时产生硬件友好的稀疏模式，与内在脉冲稀疏性互补。

Conclusion: SpikeNM成功实现了SNN的高效半结构化剪枝，平衡了硬件加速需求和模型精度，为边缘部署提供了可行方案。

Abstract: Brain-inspired Spiking neural networks (SNNs) promise energy-efficient intelligence via event-driven, sparse computation, but deeper architectures inflate parameters and computational cost, hindering their edge deployment. Recent progress in SNN pruning helps alleviate this burden, yet existing efforts fall into only two families: \emph{unstructured} pruning, which attains high sparsity but is difficult to accelerate on general hardware, and \emph{structured} pruning, which eases deployment but lack flexibility and often degrades accuracy at matched sparsity. In this work, we introduce \textbf{SpikeNM}, the first SNN-oriented \emph{semi-structured} \(N{:}M\) pruning framework that learns sparse SNNs \emph{from scratch}, enforcing \emph{at most \(N\)} non-zeros per \(M\)-weight block. To avoid the combinatorial space complexity \(\sum_{k=1}^{N}\binom{M}{k}\) growing exponentially with \(M\), SpikeNM adopts an \(M\)-way basis-logit parameterization with a differentiable top-\(k\) sampler, \emph{linearizing} per-block complexity to \(\mathcal O(M)\) and enabling more aggressive sparsification. Further inspired by neuroscience, we propose \emph{eligibility-inspired distillation} (EID), which converts temporally accumulated credits into block-wise soft targets to align mask probabilities with spiking dynamics, reducing sampling variance and stabilizing search under high sparsity. Experiments show that at \(2{:}4\) sparsity, SpikeNM maintains and even with gains across main-stream datasets, while yielding hardware-amenable patterns that complement intrinsic spike sparsity.

</details>


### [44] [DINOv3-Guided Cross Fusion Framework for Semantic-aware CT generation from MRI and CBCT](https://arxiv.org/abs/2511.12098)
*Xianhao Zhou,Jianghao Wu,Ku Zhao,Jinlong He,Huangxuan Zhao,Lei Chen,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: 提出了DINOv3引导的交叉融合框架，通过结合冻结的自监督DINOv3 Transformer和可训练的CNN编码器-解码器，在医学图像合成任务中实现局部外观和上下文表示的平衡，在SynthRAD2023盆腔数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CNN的模型缺乏全局语义理解，而Transformer由于高模型容量和弱归纳偏置容易在小型医学数据集上过拟合，需要解决这些局限性以实现更准确的医学图像合成。

Method: 提出DINOv3引导的交叉融合框架，通过可学习的交叉融合模块层次化融合Transformer的全局表示和CNN的局部特征，并引入多级DINOv3感知损失来鼓励合成CT与真实CT在DINOv3特征空间中的语义相似性。

Result: 在SynthRAD2023盆腔数据集上，DGCF在MRI→CT和CBCT→CT转换任务中，在MS-SSIM、PSNR和基于分割的指标方面都达到了最先进的性能。

Conclusion: 这是首个在医学图像翻译中使用DINOv3表示的工作，展示了自监督Transformer引导在语义感知CT合成中的潜力。

Abstract: Generating synthetic CT images from CBCT or MRI has a potential for efficient radiation dose planning and adaptive radiotherapy. However, existing CNN-based models lack global semantic understanding, while Transformers often overfit small medical datasets due to high model capacity and weak inductive bias. To address these limitations, we propose a DINOv3-Guided Cross Fusion (DGCF) framework that integrates a frozen self-supervised DINOv3 Transformer with a trainable CNN encoder-decoder. It hierarchically fuses global representation of Transformer and local features of CNN via a learnable cross fusion module, achieving balanced local appearance and contextual representation. Furthermore, we introduce a Multi-Level DINOv3 Perceptual (MLDP) loss that encourages semantic similarity between synthetic CT and the ground truth in DINOv3's feature space. Experiments on the SynthRAD2023 pelvic dataset demonstrate that DGCF achieved state-of-the-art performance in terms of MS-SSIM, PSNR and segmentation-based metrics on both MRI$\rightarrow$CT and CBCT$\rightarrow$CT translation tasks. To the best of our knowledge, this is the first work to employ DINOv3 representations for medical image translation, highlighting the potential of self-supervised Transformer guidance for semantic-aware CT synthesis. The code is available at https://github.com/HiLab-git/DGCF.

</details>


### [45] [Adaptive Begin-of-Video Tokens for Autoregressive Video Diffusion Models](https://arxiv.org/abs/2511.12099)
*Tianle Cheng,Zeyan Zhang,Kaifeng Gao,Jun Xiao*

Main category: cs.CV

TL;DR: 提出Adaptive Begin-of-Video Tokens (ada-BOV)用于自回归视频扩散模型，通过自适应层归一化调制吸收去噪的前帧，保持全局一致性并改善局部动态质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型在生成长视频时存在两种主要范式：基于块的扩展和流去噪。前者存在去噪延迟和误差累积问题，后者在一致性保持和运动动态方面表现不佳。

Method: 提出ada-BOV可学习嵌入，通过自适应层归一化调制吸收前帧信息；提出流去噪细化策略，解耦采样轨迹长度与注意力窗口约束；提出扰动增强训练噪声调度。

Result: 在多个指标上取得了令人信服的定性和定量结果，显著改善了长视频生成的连贯性和动态质量。

Conclusion: ada-BOV方法有效解决了自回归视频扩散模型在长视频生成中的一致性和动态质量问题，为高质量长视频生成提供了可行方案。

Abstract: Recent advancements in diffusion-based video generation have produced impressive and high-fidelity short videos. To extend these successes to generate coherent long videos, most video diffusion models (VDMs) generate videos in an autoregressive manner, i.e., generating subsequent frames conditioned on previous ones. There are generally two primary paradigms: chunk-based extension and stream denoising. The former directly concatenates previous clean frames as conditioning, suffering from denoising latency and error accumulation. The latter maintains the denoising sequence with monotonically increasing noise levels. In each denoising iteration, one clean frame is produced while a new pure noise is simultaneously appended, enabling live-stream sampling. However, it struggles with fragile consistency and poor motion dynamics. In this paper, we propose Adaptive Begin-of-Video Tokens (ada-BOV) for autoregressive VDMs. The BOV tokens are special learnable embeddings on VDMs. They adaptively absorb denoised preceding frames via an adaptive-layer-norm-like modulation. This design preserves the global consistency while allowing for flexible conditioning in dynamic scenarios. To ensure the quality of local dynamics essential in modulating BOV tokens, we further propose a refinement strategy for stream denoising. It decouples the sampling trajectory length from the attention window size constraint, leading to improved local guidance and overall imaging quality. We also propose a disturbance-augmented training noise schedule, which balances the convergence speed with model robustness for the stream denoising. Extensive experiments demonstrate that our method achieves compelling qualitative and quantitative results across multiple metrics.

</details>


### [46] [Did Models Sufficient Learn? Attribution-Guided Training via Subset-Selected Counterfactual Augmentation](https://arxiv.org/abs/2511.12100)
*Yannan Chen,Ruoyu Chen,Bin Zeng,Wei Wang,Shiming Liu,Qunli Zhang,Zheng Hu,Laiyuan Wang,Yaowei Wang,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出SS-CA方法，通过反事实增强来纠正视觉模型对有限因果特征的依赖，提高模型在分布内和分布外数据上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型仅依赖有限的充分原因进行预测，使其对分布偏移或关键特征缺失敏感。模型与人类在识别反事实样本时的差异表明模型学习到的依赖关系可能不够因果充分。

Method: 基于LIMA归因方法开发Counterfactual LIMA，识别最小空间区域集，其移除可选择性改变模型预测。利用这些归因，提出数据增强策略，将识别区域替换为自然背景，并在增强和原始样本上联合训练模型。

Result: 在多个ImageNet变体上的实验表明，SS-CA提高了分布内测试数据的泛化能力，并在ImageNet-R和ImageNet-S等分布外基准上获得优越性能。在噪声等扰动下，SS-CA训练的模型也表现出增强的泛化能力。

Conclusion: SS-CA方法有效利用可解释性洞察来纠正模型缺陷，提高性能和鲁棒性，证明将反事实解释直接整合到训练过程中可以缓解不完整因果学习问题。

Abstract: In current visual model training, models often rely on only limited sufficient causes for their predictions, which makes them sensitive to distribution shifts or the absence of key features. Attribution methods can accurately identify a model's critical regions. However, masking these areas to create counterfactuals often causes the model to misclassify the target, while humans can still easily recognize it. This divergence highlights that the model's learned dependencies may not be sufficiently causal. To address this issue, we propose Subset-Selected Counterfactual Augmentation (SS-CA), which integrates counterfactual explanations directly into the training process for targeted intervention. Building on the subset-selection-based LIMA attribution method, we develop Counterfactual LIMA to identify minimal spatial region sets whose removal can selectively alter model predictions. Leveraging these attributions, we introduce a data augmentation strategy that replaces the identified regions with natural background, and we train the model jointly on both augmented and original samples to mitigate incomplete causal learning. Extensive experiments across multiple ImageNet variants show that SS-CA improves generalization on in-distribution (ID) test data and achieves superior performance on out-of-distribution (OOD) benchmarks such as ImageNet-R and ImageNet-S. Under perturbations including noise, models trained with SS-CA also exhibit enhanced generalization, demonstrating that our approach effectively uses interpretability insights to correct model deficiencies and improve both performance and robustness.

</details>


### [47] [BdSL-SPOTER: A Transformer-Based Framework for Bengali Sign Language Recognition with Cultural Adaptation](https://arxiv.org/abs/2511.12103)
*Sayad Ibna Azad,Md. Atiqur Rahman*

Main category: cs.CV

TL;DR: BdSL-SPOTER是一个基于姿态的transformer框架，用于准确高效地识别孟加拉手语（BdSL），在BdSLW60基准测试中达到97.92%的Top-1验证准确率，比Bi-LSTM基线提升22.82%，同时保持低计算成本。


<details>
  <summary>Details</summary>
Motivation: 为孟加拉手语开发一个准确且高效的手语识别框架，解决低资源区域手语识别的问题，并为其他低资源区域手语提供可扩展模型。

Method: 扩展SPOTER范式，采用文化特定的预处理，使用紧凑的四层transformer编码器，优化可学习位置编码，并应用课程学习来增强在有限数据上的泛化能力和加速收敛。

Result: 在BdSLW60基准测试中达到97.92%的Top-1验证准确率，比Bi-LSTM基线提升22.82%，同时具有更少的参数、更低的FLOPs和更高的FPS。

Conclusion: BdSL-SPOTER为现实世界可访问性应用提供了一个实用框架，并可作为其他低资源区域手语的可扩展模型。

Abstract: We introduce BdSL-SPOTER, a pose-based transformer framework for accurate and efficient recognition of Bengali Sign Language (BdSL). BdSL-SPOTER extends the SPOTER paradigm with cultural specific preprocessing and a compact four-layer transformer encoder featuring optimized learnable positional encodings, while employing curriculum learning to enhance generalization on limited data and accelerate convergence. On the BdSLW60 benchmark, it achieves 97.92% Top-1 validation accuracy, representing a 22.82% improvement over the Bi-LSTM baseline, all while keeping computational costs low. With its reduced number of parameters, lower FLOPs, and higher FPS, BdSL-SPOTER provides a practical framework for real-world accessibility applications and serves as a scalable model for other low-resource regional sign languages.

</details>


### [48] [TEMPO: Global Temporal Building Density and Height Estimation from Satellite Imagery](https://arxiv.org/abs/2511.12104)
*Tammy Glazer,Gilles Q. Hacheme,Akram Zaytar,Luana Marotti,Amy Michaels,Girmaw Abebe Tadesse,Kevin White,Rahul Dodhia,Andrew Zolli,Inbal Becker-Reshef,Juan M. Lavista Ferres,Caleb Robinson*

Main category: cs.CV

TL;DR: TEMPO是一个全球性的、时间分辨的建筑密度和高度数据集，通过深度学习模型从高分辨率卫星图像中提取，提供从2018年第一季度到2025年第二季度的季度更新数据。


<details>
  <summary>Details</summary>
Motivation: 为了大规模监测发展模式和气候影响，支持全球韧性和适应工作，需要一种计算成本较低的方法来捕捉建成区的季度变化。

Method: 将现有数据集的建筑足迹和高度数据与季度PlanetScope卫星图像配对，训练多任务深度学习模型，预测37.6米/像素分辨率的建筑密度和高度。

Result: 验证显示在不同人工标记子集上F1分数达到85%-88%，时间稳定性高，五年趋势一致性得分为0.96，计算成本远低于可比方法。

Conclusion: TEMPO能够以较低计算成本捕捉建成区的季度变化，为大规模监测发展模式和气候影响提供了有效工具。

Abstract: We present TEMPO, a global, temporally resolved dataset of building density and height derived from high-resolution satellite imagery using deep learning models. We pair building footprint and height data from existing datasets with quarterly PlanetScope basemap satellite images to train a multi-task deep learning model that predicts building density and building height at a 37.6-meter per pixel resolution. We apply this model to global PlanetScope basemaps from Q1 2018 through Q2 2025 to create global, temporal maps of building density and height. We validate these maps by comparing against existing building footprint datasets. Our estimates achieve an F1 score between 85% and 88% on different hand-labeled subsets, and are temporally stable, with a 0.96 five-year trend-consistency score. TEMPO captures quarterly changes in built settlements at a fraction of the computational cost of comparable approaches, unlocking large-scale monitoring of development patterns and climate impacts essential for global resilience and adaptation efforts.

</details>


### [49] [MediRound: Multi-Round Entity-Level Reasoning Segmentation in Medical Images](https://arxiv.org/abs/2511.12110)
*Qinyue Tong,Ziqian Lu,Jun Liu,Rui Zuo,Zheming Lu*

Main category: cs.CV

TL;DR: MEMR-Seg是一个新的多轮实体级医学推理分割任务，通过构建MR-MedSeg数据集和提出MediRound模型来解决传统医学分割方法缺乏交互性和多轮推理能力的问题。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法多为任务特定且缺乏交互性，文本提示方法局限于单轮对话，无法进行多轮推理。

Method: 构建MR-MedSeg数据集（17.7万条多轮医学分割对话），提出MediRound基线模型，并引入轻量级的判断与校正机制来缓解多轮分割中的错误传播问题。

Result: 实验结果表明该方法有效解决了MEMR-Seg任务，性能优于传统的医学参考分割方法。

Conclusion: MEMR-Seg任务和MediRound模型为医学图像分割提供了多轮交互推理的新范式，显著提升了分割的灵活性和准确性。

Abstract: Despite the progress in medical image segmentation, most existing methods remain task-specific and lack interactivity. Although recent text-prompt-based segmentation approaches enhance user-driven and reasoning-based segmentation, they remain confined to single-round dialogues and fail to perform multi-round reasoning. In this work, we introduce Multi-Round Entity-Level Medical Reasoning Segmentation (MEMR-Seg), a new task that requires generating segmentation masks through multi-round queries with entity-level reasoning. To support this task, we construct MR-MedSeg, a large-scale dataset of 177K multi-round medical segmentation dialogues, featuring entity-based reasoning across rounds. Furthermore, we propose MediRound, an effective baseline model designed for multi-round medical reasoning segmentation. To mitigate the inherent error propagation in the chain-like pipeline of multi-round segmentation, we introduce a lightweight yet effective Judgment & Correction Mechanism during model inference. Experimental results demonstrate that our method effectively addresses the MEMR-Seg task and outperforms conventional medical referring segmentation methods.

</details>


### [50] [RadarMP: Motion Perception for 4D mmWave Radar in Autonomous Driving](https://arxiv.org/abs/2511.12117)
*Ruiqi Cheng,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: RadarMP是一种使用4D毫米波雷达信号进行精确3D场景运动感知的新方法，通过联合建模雷达目标检测和运动估计，在恶劣天气条件下实现可靠的自动驾驶感知。


<details>
  <summary>Details</summary>
Motivation: 4D毫米波雷达具有全天候工作能力，但稀疏和嘈杂的雷达点往往导致运动感知不精确，在光学传感器性能下降时限制了自动驾驶车辆的感知能力。

Method: 提出RadarMP方法，使用两帧连续的低级雷达回波信号，在统一架构中联合建模雷达目标检测和运动估计，设计基于多普勒频移和回波强度的自监督损失函数。

Result: 在公共数据集上的广泛实验表明，RadarMP在各种天气和光照条件下实现了可靠的运动感知，优于基于雷达的解耦运动感知流程。

Conclusion: RadarMP增强了全场景自动驾驶系统的感知能力，为恶劣天气条件下的可靠运动感知提供了有效解决方案。

Abstract: Accurate 3D scene motion perception significantly enhances the safety and reliability of an autonomous driving system. Benefiting from its all-weather operational capability and unique perceptual properties, 4D mmWave radar has emerged as an essential component in advanced autonomous driving. However, sparse and noisy radar points often lead to imprecise motion perception, leaving autonomous vehicles with limited sensing capabilities when optical sensors degrade under adverse weather conditions. In this paper, we propose RadarMP, a novel method for precise 3D scene motion perception using low-level radar echo signals from two consecutive frames. Unlike existing methods that separate radar target detection and motion estimation, RadarMP jointly models both tasks in a unified architecture, enabling consistent radar point cloud generation and pointwise 3D scene flow prediction. Tailored to radar characteristics, we design specialized self-supervised loss functions guided by Doppler shifts and echo intensity, effectively supervising spatial and motion consistency without explicit annotations. Extensive experiments on the public dataset demonstrate that RadarMP achieves reliable motion perception across diverse weather and illumination conditions, outperforming radar-based decoupled motion perception pipelines and enhancing perception capabilities for full-scenario autonomous driving systems.

</details>


### [51] [OAD-Promoter: Enhancing Zero-shot VQA using Large Language Models with Object Attribute Description](https://arxiv.org/abs/2511.12131)
*Quanxing Xu,Ling Zhou,Feifei Zhang,Jinyu Tian,Rubing Huang*

Main category: cs.CV

TL;DR: OAD-Promoter是一种新颖的方法，通过减轻语言偏见和提升领域迁移鲁棒性来增强基于LLM的视觉问答性能。该方法包含三个模块：OEG模块生成全局描述和对象集中样本，MKA模块通过检索相关知识处理OOD样本，OAD Prompt整合前两个模块的输出优化LLM推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在视觉问答中面临两个关键限制：(1)由于偏见利用导致预测不可靠，(2)尽管具有强大的知识推理能力，但在分布外泛化方面仍有困难。

Method: 提出OAD-Promoter方法，包含三个组件：OEG模块生成全局描述和对象集中样本以增强视觉信息输入并减轻偏见；MKA模块从存储的示例中检索相关知识以支持未见领域的问答；OAD Prompt整合前两个模块的输出优化LLM推理。

Result: 实验表明OAD-Promoter在少样本或零样本设置下显著提升了基于LLM的视觉问答方法的性能，取得了新的最先进结果。

Conclusion: OAD-Promoter通过减轻语言偏见和提升领域迁移鲁棒性，有效解决了LLM在视觉问答中的关键限制，在少样本和零样本场景下实现了卓越性能。

Abstract: Large Language Models (LLMs) have become a crucial tool in Visual Question Answering (VQA) for handling knowledge-intensive questions in few-shot or zero-shot scenarios. However, their reliance on massive training datasets often causes them to inherit language biases during the acquisition of knowledge. This limitation imposes two key constraints on existing methods: (1) LLM predictions become less reliable due to bias exploitation, and (2) despite strong knowledge reasoning capabilities, LLMs still struggle with out-of-distribution (OOD) generalization. To address these issues, we propose Object Attribute Description Promoter (OAD-Promoter), a novel approach for enhancing LLM-based VQA by mitigating language bias and improving domain-shift robustness. OAD-Promoter comprises three components: the Object-concentrated Example Generation (OEG) module, the Memory Knowledge Assistance (MKA) module, and the OAD Prompt. The OEG module generates global captions and object-concentrated samples, jointly enhancing visual information input to the LLM and mitigating bias through complementary global and regional visual cues. The MKA module assists the LLM in handling OOD samples by retrieving relevant knowledge from stored examples to support questions from unseen domains. Finally, the OAD Prompt integrates the outputs of the preceding modules to optimize LLM inference. Experiments demonstrate that OAD-Promoter significantly improves the performance of LLM-based VQA methods in few-shot or zero-shot settings, achieving new state-of-the-art results.

</details>


### [52] [MAVIS: A Benchmark for Multimodal Source Attribution in Long-form Visual Question Answering](https://arxiv.org/abs/2511.12142)
*Seokwon Song,Minsu Park,Gunhee Kim*

Main category: cs.CV

TL;DR: MAVIS是首个评估多模态来源归因系统的基准，包含157K视觉问答实例，每个答案都有事实级引用指向多模态文档。研究发现多模态RAG能生成更信息丰富和流畅的答案，但在图像文档的可靠性方面较弱，存在信息丰富性与可靠性的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注纯文本场景，忽视了多模态在来源归因中的作用，需要开发能理解视觉问题意图、检索多模态证据并生成带引用长答案的系统。

Method: 开发MAVIS基准数据集，包含157K视觉问答实例，每个答案标注事实级引用；提出基于信息丰富性、可靠性和流畅性的细粒度自动评估指标；比较不同提示方法下的多模态RAG系统性能。

Result: 多模态RAG比单模态RAG生成更信息丰富和流畅的答案；但在图像文档的可靠性方面表现较弱，这一差距在多模态设置中被放大；不同提示方法在信息丰富性和可靠性之间存在权衡。

Conclusion: 缓解图像文档解释中的上下文偏见是未来研究的关键方向；MAVIS为评估多模态来源归因系统提供了重要基准。

Abstract: Source attribution aims to enhance the reliability of AI-generated answers by including references for each statement, helping users validate the provided answers. However, existing work has primarily focused on text-only scenario and largely overlooked the role of multimodality. We introduce MAVIS, the first benchmark designed to evaluate multimodal source attribution systems that understand user intent behind visual questions, retrieve multimodal evidence, and generate long-form answers with citations. Our dataset comprises 157K visual QA instances, where each answer is annotated with fact-level citations referring to multimodal documents. We develop fine-grained automatic metrics along three dimensions of informativeness, groundedness, and fluency, and demonstrate their strong correlation with human judgments. Our key findings are threefold: (1) LVLMs with multimodal RAG generate more informative and fluent answers than unimodal RAG, but they exhibit weaker groundedness for image documents than for text documents, a gap amplified in multimodal settings. (2) Given the same multimodal documents, there is a trade-off between informativeness and groundedness across different prompting methods. (3) Our proposed method highlights mitigating contextual bias in interpreting image documents as a crucial direction for future research. The dataset and experimental code are available at https://github.com/seokwon99/MAVIS

</details>


### [53] [FIA-Edit: Frequency-Interactive Attention for Efficient and High-Fidelity Inversion-Free Text-Guided Image Editing](https://arxiv.org/abs/2511.12151)
*Kaixiang Yang,Boyang Shen,Xin Li,Yuchen Dai,Yuxuan Luo,Yueran Ma,Wei Fang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: FIA-Edit是一个基于频率交互注意力的免反演图像编辑框架，通过频率表示交互和特征注入模块实现高保真编辑，在计算效率和编辑质量上优于现有方法，并首次应用于医学图像增强。


<details>
  <summary>Details</summary>
Motivation: 现有基于流的免反演方法虽然效率高，但缺乏有效的源信息整合，导致背景保留差、空间不一致和过度编辑问题。

Method: 提出频率交互注意力框架，包含频率表示交互模块（在自注意力中交换源和目标特征的频率分量）和特征注入模块（在交叉注意力中显式引入源侧查询、键、值和文本嵌入）。

Result: 在RTX 4090上每张512*512图像仅需约6秒，在视觉质量、背景保真度和可控性方面优于现有方法，并成功应用于医学出血分类的数据增强。

Conclusion: FIA-Edit实现了高效高保真的文本引导图像编辑，为医学图像处理开辟了新途径，显著提升了下游分类任务的性能。

Abstract: Text-guided image editing has advanced rapidly with the rise of diffusion models. While flow-based inversion-free methods offer high efficiency by avoiding latent inversion, they often fail to effectively integrate source information, leading to poor background preservation, spatial inconsistencies, and over-editing due to the lack of effective integration of source information. In this paper, we present FIA-Edit, a novel inversion-free framework that achieves high-fidelity and semantically precise edits through a Frequency-Interactive Attention. Specifically, we design two key components: (1) a Frequency Representation Interaction (FRI) module that enhances cross-domain alignment by exchanging frequency components between source and target features within self-attention, and (2) a Feature Injection (FIJ) module that explicitly incorporates source-side queries, keys, values, and text embeddings into the target branch's cross-attention to preserve structure and semantics. Comprehensive and extensive experiments demonstrate that FIA-Edit supports high-fidelity editing at low computational cost (~6s per 512 * 512 image on an RTX 4090) and consistently outperforms existing methods across diverse tasks in visual quality, background fidelity, and controllability. Furthermore, we are the first to extend text-guided image editing to clinical applications. By synthesizing anatomically coherent hemorrhage variations in surgical images, FIA-Edit opens new opportunities for medical data augmentation and delivers significant gains in downstream bleeding classification. Our project is available at: https://github.com/kk42yy/FIA-Edit.

</details>


### [54] [Codebook-Centric Deep Hashing: End-to-End Joint Learning of Semantic Hash Centers and Neural Hash Function](https://arxiv.org/abs/2511.12162)
*Shuo Yin,Zhiyuan Yin,Yuqing Hou,Rui Liu,Yong Chen,Dell Zhang*

Main category: cs.CV

TL;DR: 提出了Center-Reassigned Hashing (CRH)方法，通过动态重新分配预设码本中的哈希中心并联合优化哈希函数，避免了传统两阶段方法的复杂性和性能损失。


<details>
  <summary>Details</summary>
Motivation: 现有基于哈希中心的方法存在随机初始化忽略类间语义关系的问题，而两阶段方法虽然缓解了这一问题，但引入了额外复杂性和阶段间差异导致的次优性能。

Method: CRH采用端到端框架，动态重新分配预设码本中的哈希中心，无需显式的中心优化阶段，同时使用多头机制增强哈希中心的表示能力。

Result: 在三个基准数据集上的实验表明，CRH能够学习到具有语义意义的哈希中心，并在检索任务中优于最先进的深度哈希方法。

Conclusion: CRH通过动态哈希中心重新分配和端到端优化，有效整合了语义关系，提升了哈希检索性能。

Abstract: Hash center-based deep hashing methods improve upon pairwise or triplet-based approaches by assigning fixed hash centers to each class as learning targets, thereby avoiding the inefficiency of local similarity optimization. However, random center initialization often disregards inter-class semantic relationships. While existing two-stage methods mitigate this by first refining hash centers with semantics and then training the hash function, they introduce additional complexity, computational overhead, and suboptimal performance due to stage-wise discrepancies. To address these limitations, we propose $\textbf{Center-Reassigned Hashing (CRH)}$, an end-to-end framework that $\textbf{dynamically reassigns hash centers}$ from a preset codebook while jointly optimizing the hash function. Unlike previous methods, CRH adapts hash centers to the data distribution $\textbf{without explicit center optimization phases}$, enabling seamless integration of semantic relationships into the learning process. Furthermore, $\textbf{a multi-head mechanism}$ enhances the representational capacity of hash centers, capturing richer semantic structures. Extensive experiments on three benchmarks demonstrate that CRH learns semantically meaningful hash centers and outperforms state-of-the-art deep hashing methods in retrieval tasks.

</details>


### [55] [Rethinking Multimodal Point Cloud Completion: A Completion-by-Correction Perspective](https://arxiv.org/abs/2511.12170)
*Wang Luo,Di Wu,Hengyuan Na,Yinlin Zhu,Miao Hu,Guocong Quan*

Main category: cs.CV

TL;DR: 本文提出了一种新的点云补全范式Completion-by-Correction，通过从预训练图像到3D模型生成拓扑完整的形状先验，并在特征空间进行校正来对齐部分观测，从而避免传统补全方法的结构不一致问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于修复的点云补全方法由于几何和语义约束有限，经常导致结构不一致和拓扑伪影。作者重新思考任务本质，提出从无约束合成转向引导精炼的新范式。

Method: 提出了PGNet多阶段框架：进行双特征编码以锚定生成先验，合成结构对齐的粗粒度支架，并通过分层校正逐步细化几何细节。

Result: 在ShapeNetViPC数据集上的实验表明，PGNet在平均Chamfer距离上优于现有最优方法23.5%，F-score提升7.1%。

Conclusion: Completion-by-Correction范式通过将补全任务重新定义为从拓扑完整先验的引导精炼，实现了结构一致且观测对齐的重建，显著提升了点云补全性能。

Abstract: Point cloud completion aims to reconstruct complete 3D shapes from partial observations, which is a challenging problem due to severe occlusions and missing geometry. Despite recent advances in multimodal techniques that leverage complementary RGB images to compensate for missing geometry, most methods still follow a Completion-by-Inpainting paradigm, synthesizing missing structures from fused latent features. We empirically show that this paradigm often results in structural inconsistencies and topological artifacts due to limited geometric and semantic constraints. To address this, we rethink the task and propose a more robust paradigm, termed Completion-by-Correction, which begins with a topologically complete shape prior generated by a pretrained image-to-3D model and performs feature-space correction to align it with the partial observation. This paradigm shifts completion from unconstrained synthesis to guided refinement, enabling structurally consistent and observation-aligned reconstruction. Building upon this paradigm, we introduce PGNet, a multi-stage framework that conducts dual-feature encoding to ground the generative prior, synthesizes a coarse yet structurally aligned scaffold, and progressively refines geometric details via hierarchical correction. Experiments on the ShapeNetViPC dataset demonstrate the superiority of PGNet over state-of-the-art baselines in terms of average Chamfer Distance (-23.5%) and F-score (+7.1%).

</details>


### [56] [MixAR: Mixture Autoregressive Image Generation](https://arxiv.org/abs/2511.12181)
*Jinyuan Hu,Jiayou Zhang,Shaobo Cui,Kun Zhang,Guangyi Chen*

Main category: cs.CV

TL;DR: MixAR是一个新颖的自回归图像生成框架，通过离散-连续混合训练范式，利用离散token作为先验指导来提升连续自回归建模的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的自回归方法将图像表示为有限码本中的离散token序列，但量化过程和有限码本大小会丢弃细粒度信息，限制了生成保真度。虽然连续潜在空间的自回归建模能提供更高质量，但连续表示存在于广阔无结构空间中，给高效自回归建模带来挑战。

Method: MixAR采用因子化公式，利用离散token作为连续自回归预测的先验指导。研究了多种离散-连续混合策略：自注意力(DC-SA)、交叉注意力(DC-CA)和简单方法(DC-Mix)。还提出了训练-推理混合(TI-Mix)来弥合训练和生成分布之间的差距。

Result: 实验表明DC-Mix策略在计算效率和生成保真度之间取得了良好平衡，TI-Mix带来了持续改进。

Conclusion: MixAR框架通过离散-连续混合训练有效提升了连续自回归图像生成的质量和效率。

Abstract: Autoregressive (AR) approaches, which represent images as sequences of discrete tokens from a finite codebook, have achieved remarkable success in image generation. However, the quantization process and the limited codebook size inevitably discard fine-grained information, placing bottlenecks on fidelity. Motivated by this limitation, recent studies have explored autoregressive modeling in continuous latent spaces, which offers higher generation quality. Yet, unlike discrete tokens constrained by a fixed codebook, continuous representations lie in a vast and unstructured space, posing significant challenges for efficient autoregressive modeling. To address these challenges, we introduce MixAR, a novel framework that leverages mixture training paradigms to inject discrete tokens as prior guidance for continuous AR modeling. MixAR is a factorized formulation that leverages discrete tokens as prior guidance for continuous autoregressive prediction. We investigate several discrete-continuous mixture strategies, including self-attention (DC-SA), cross-attention (DC-CA), and a simple approach (DC-Mix) that replaces homogeneous mask tokens with informative discrete counterparts. Moreover, to bridge the gap between ground-truth training tokens and inference tokens produced by the pre-trained AR model, we propose Training-Inference Mixture (TI-Mix) to achieve consistent training and generation distributions. In our experiments, we demonstrate a favorable balance of the DC-Mix strategy between computational efficiency and generation fidelity, and consistent improvement of TI-Mix.

</details>


### [57] [Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System](https://arxiv.org/abs/2511.12196)
*Aditi Bhalla,Christian Hellert,Enkelejda Kasneci*

Main category: cs.CV

TL;DR: 提出了一种两阶段跨视图、跨模态无监督域自适应框架，用于解决驾驶员活动识别中的视角变化和域偏移问题，显著提升了模型在真实部署中的性能。


<details>
  <summary>Details</summary>
Motivation: 驾驶员分心是交通事故的主要原因，现有方法单独处理跨视图泛化或无监督域自适应，无法应对真实部署中同时存在的视角变化和域偏移挑战。

Method: 采用两阶段方法：第一阶段使用对比学习在多视图数据上学习视图不变和动作判别特征；第二阶段使用信息瓶颈损失进行跨模态域自适应，无需新域的标注数据。

Result: 在Drive&Act数据集上，相比监督对比学习方法，RGB视频数据的top-1准确率提升近50%；相比仅使用无监督域自适应的方法，性能提升达5%。

Conclusion: 该联合框架能够有效解决驾驶员监控中的跨视图和跨模态挑战，为模型在多样化车辆配置中的稳健部署提供了可行方案。

Abstract: Driver distraction remains a leading cause of road traffic accidents, contributing to thousands of fatalities annually across the globe. While deep learning-based driver activity recognition methods have shown promise in detecting such distractions, their effectiveness in real-world deployments is hindered by two critical challenges: variations in camera viewpoints (cross-view) and domain shifts such as change in sensor modality or environment. Existing methods typically address either cross-view generalization or unsupervised domain adaptation in isolation, leaving a gap in the robust and scalable deployment of models across diverse vehicle configurations. In this work, we propose a novel two-phase cross-view, cross-modal unsupervised domain adaptation framework that addresses these challenges jointly on real-time driver monitoring data. In the first phase, we learn view-invariant and action-discriminative features within a single modality using contrastive learning on multi-view data. In the second phase, we perform domain adaptation to a new modality using information bottleneck loss without requiring any labeled data from the new domain. We evaluate our approach using state-of-the art video transformers (Video Swin, MViT) and multi modal driver activity dataset called Drive&Act, demonstrating that our joint framework improves top-1 accuracy on RGB video data by almost 50% compared to a supervised contrastive learning-based cross-view method, and outperforms unsupervised domain adaptation-only methods by up to 5%, using the same video transformer backbone.

</details>


### [58] [OmniSparse: Training-Aware Fine-Grained Sparse Attention for Long-Video MLLMs](https://arxiv.org/abs/2511.12201)
*Feng Chen,Yefei He,Shaoxuan He,Yuanyu He,Jing Liu,Lequan Lin,Akide Liu,Zhaoyang Li,Jiyuan Zhang,Zhenbang Sun,Bohan Zhuang,Qi Wu*

Main category: cs.CV

TL;DR: OmniSparse是一个训练感知的细粒度稀疏注意力框架，用于长视频多模态大语言模型，通过动态令牌预算分配在训练和推理中实现加速和内存优化。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法主要针对推理时加速，采用预定义稀疏模式选择关键令牌，但无法弥合训练-推理差距，缺乏跨查询、键值对和注意力头的细粒度令牌选择能力，导致性能次优和加速效果有限。

Method: OmniSparse包含三种自适应互补机制：1）通过惰性-主动分类进行查询选择，保留捕捉广泛语义相似性的主动查询；2）基于头级动态预算分配的键值对选择，根据最平坦头确定共享预算；3）键值缓存精简，根据头级解码查询模式选择性获取视觉键值缓存。

Result: 实验结果显示，OmniSparse在保持完整注意力性能的同时，实现了预填充阶段2.7倍加速和解码阶段2.4倍内存减少。

Conclusion: OmniSparse框架有效解决了训练-推理差距问题，通过细粒度稀疏注意力机制在长视频MLLMs中实现了显著的性能提升和计算效率优化。

Abstract: Existing sparse attention methods primarily target inference-time acceleration by selecting critical tokens under predefined sparsity patterns. However, they often fail to bridge the training-inference gap and lack the capacity for fine-grained token selection across multiple dimensions such as queries, key-values (KV), and heads, leading to suboptimal performance and limited acceleration gains. In this paper, we introduce OmniSparse, a training-aware fine-grained sparse attention framework for long-video MLLMs, which operates in both training and inference with dynamic token budget allocation. Specifically, OmniSparse contains three adaptive and complementary mechanisms: (1) query selection via lazy-active classification, retaining active queries that capture broad semantic similarity while discarding most lazy ones that focus on limited local context and exhibit high functional redundancy; (2) KV selection with head-level dynamic budget allocation, where a shared budget is determined based on the flattest head and applied uniformly across all heads to ensure attention recall; and (3) KV cache slimming to reduce head-level redundancy by selectively fetching visual KV cache according to the head-level decoding query pattern. Experimental results show that OmniSparse matches the performance of full attention while achieving up to 2.7x speedup during prefill and 2.4x memory reduction during decoding.

</details>


### [59] [LSS3D: Learnable Spatial Shifting for Consistent and High-Quality 3D Generation from Single-Image](https://arxiv.org/abs/2511.12202)
*Zhuojiang Cai,Yiheng Zhang,Meitong Guo,Mingdao Wang,Yuwang Wang*

Main category: cs.CV

TL;DR: LSS3D是一种高质量图像到3D生成方法，通过可学习空间偏移解决多视图不一致性和非正面输入视角问题，在几何细节和纹理质量方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图扩散3D生成方法存在形状和纹理不对齐问题，导致3D生成质量低，如几何细节不完整和纹理重影。同时，这些方法主要针对正面视角优化，对倾斜视角输入鲁棒性差。

Method: 提出LSS3D方法，为每个视图分配可学习空间偏移参数，在重建网格的指导下将每个视图调整到空间一致的目标，从而获得高质量3D生成。同时将输入视图作为额外约束，增强对非正面输入角度的鲁棒性。

Result: 大量实验表明，该方法在几何和纹理评估指标上始终取得领先结果，特别是在更灵活的输入视角下表现优异。

Conclusion: LSS3D通过可学习空间偏移机制有效解决了多视图不一致性和非正面输入视角问题，实现了高质量的3D生成，并提供了全面的定量评估流程以促进社区性能比较。

Abstract: Recently, multi-view diffusion-based 3D generation methods have gained significant attention. However, these methods often suffer from shape and texture misalignment across generated multi-view images, leading to low-quality 3D generation results, such as incomplete geometric details and textural ghosting. Some methods are mainly optimized for the frontal perspective and exhibit poor robustness to oblique perspective inputs. In this paper, to tackle the above challenges, we propose a high-quality image-to-3D approach, named LSS3D, with learnable spatial shifting to explicitly and effectively handle the multiview inconsistencies and non-frontal input view. Specifically, we assign learnable spatial shifting parameters to each view, and adjust each view towards a spatially consistent target, guided by the reconstructed mesh, resulting in high-quality 3D generation with more complete geometric details and clean textures. Besides, we include the input view as an extra constraint for the optimization, further enhancing robustness to non-frontal input angles, especially for elevated viewpoint inputs. We also provide a comprehensive quantitative evaluation pipeline that can contribute to the community in performance comparisons. Extensive experiments demonstrate that our method consistently achieves leading results in both geometric and texture evaluation metrics across more flexible input viewpoints.

</details>


### [60] [GeoMVD: Geometry-Enhanced Multi-View Generation Model Based on Geometric Information Extraction](https://arxiv.org/abs/2511.12204)
*Jiaqi Wu,Yaosen Chen,Shuyuan Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种几何引导的多视图扩散模型，通过提取多视图几何信息并调整几何特征强度，生成跨视图一致且细节丰富的图像。


<details>
  <summary>Details</summary>
Motivation: 多视图图像生成在3D重建、虚拟现实和增强现实等领域具有重要应用价值。现有方法在保持跨视图一致性和生成高分辨率输出方面面临显著计算挑战。

Method: 设计了多视图几何信息提取模块，利用深度图、法线图和前景分割掩码构建共享几何结构；开发了解耦几何增强注意力机制；采用自适应学习策略；包含迭代细化过程；提出动态几何信息强度调整机制。

Result: 模型能够生成跨视图一致且细节丰富的图像，提高了整体图像质量和细节保留能力。

Conclusion: 所提出的几何引导多视图扩散模型有效解决了多视图图像生成中的一致性和细节问题，为相关应用提供了高质量解决方案。

Abstract: Multi-view image generation holds significant application value in computer vision, particularly in domains like 3D reconstruction, virtual reality, and augmented reality. Most existing methods, which rely on extending single images, face notable computational challenges in maintaining cross-view consistency and generating high-resolution outputs. To address these issues, we propose the Geometry-guided Multi-View Diffusion Model, which incorporates mechanisms for extracting multi-view geometric information and adjusting the intensity of geometric features to generate images that are both consistent across views and rich in detail. Specifically, we design a multi-view geometry information extraction module that leverages depth maps, normal maps, and foreground segmentation masks to construct a shared geometric structure, ensuring shape and structural consistency across different views. To enhance consistency and detail restoration during generation, we develop a decoupled geometry-enhanced attention mechanism that strengthens feature focus on key geometric details, thereby improving overall image quality and detail preservation. Furthermore, we apply an adaptive learning strategy that fine-tunes the model to better capture spatial relationships and visual coherence between the generated views, ensuring realistic results. Our model also incorporates an iterative refinement process that progressively improves the output quality through multiple stages of image generation. Finally, a dynamic geometry information intensity adjustment mechanism is proposed to adaptively regulate the influence of geometric data, optimizing overall quality while ensuring the naturalness of generated images. More details can be found on the project page: https://github.com/SobeyMIL/GeoMVD.com.

</details>


### [61] [A Novel AI-Driven System for Real-Time Detection of Mirror Absence, Helmet Non-Compliance, and License Plates Using YOLOv8 and OCR](https://arxiv.org/abs/2511.12206)
*Nishant Vasantkumar Hegde,Aditi Agarwal,Minal Moharir*

Main category: cs.CV

TL;DR: 本文提出了一个基于AI的自动化交通违规检测系统，使用YOLOv8进行目标检测和EasyOCR进行车牌识别，能够检测头盔违规、摩托车后视镜缺失等违规行为，并提取车辆注册号。


<details>
  <summary>Details</summary>
Motivation: 道路安全是全球关注的重要问题，手动执行头盔法规和车辆安全标准既耗费资源又不一致。需要自动化解决方案来提高执法效率和道路安全。

Method: 系统结合YOLOv8进行目标检测和EasyOCR进行车牌识别，使用自定义标注图像数据集（经过数据增强），通过Streamlit界面实现实时监控和违规记录。

Result: 模型整体精度达到0.9147，召回率0.886，平均精度(mAP@50)为0.843，mAP@50-95为0.503，表明在严格IoU阈值下仍具有强大的检测能力。

Conclusion: 这项工作展示了一个实用有效的自动化交通规则执法解决方案，并讨论了实际部署的考虑因素。

Abstract: Road safety is a critical global concern, with manual enforcement of helmet laws and vehicle safety standards (e.g., rear-view mirror presence) being resource-intensive and inconsistent. This paper presents an AI-powered system to automate traffic violation detection, significantly enhancing enforcement efficiency and road safety. The system leverages YOLOv8 for robust object detection and EasyOCR for license plate recognition. Trained on a custom dataset of annotated images (augmented for diversity), it identifies helmet non-compliance, the absence of rear-view mirrors on motorcycles, an innovative contribution to automated checks, and extracts vehicle registration numbers. A Streamlit-based interface facilitates real-time monitoring and violation logging. Advanced image preprocessing enhances license plate recognition, particularly under challenging conditions. Based on evaluation results, the model achieves an overall precision of 0.9147, a recall of 0.886, and a mean Average Precision (mAP@50) of 0.843. The mAP@50 95 of 0.503 further indicates strong detection capability under stricter IoU thresholds. This work demonstrates a practical and effective solution for automated traffic rule enforcement, with considerations for real-world deployment discussed.

</details>


### [62] [Mixture of States: Routing Token-Level Dynamics for Multimodal Generation](https://arxiv.org/abs/2511.12207)
*Haozhe Liu,Ding Liu,Mingchen Zhuge,Zijian Zhou,Tian Xie,Sen He,Yukang Yang,Shuming Liu,Yuren Cong,Jiadong Guo,Hongyu Xu,Ke Xu,Kam-Woh Ng,Juan C. Pérez,Juan-Manuel~Pérez-Rúa,Tao Xiang,Wei Liu,Shikun Liu,Jürgen Schmidhuber*

Main category: cs.CV

TL;DR: MoS是一种新颖的多模态扩散模型融合范式，通过可学习的token级路由器实现模态间状态交互，在文本到图像生成和编辑任务中达到最先进性能，仅需3B-5B参数即可匹配或超越参数多4倍的模型。


<details>
  <summary>Details</summary>
Motivation: 开发一种灵活且计算高效的多模态扩散模型融合方法，解决现有方法在模态交互和计算效率方面的局限性。

Method: 使用可学习的token级路由器，基于去噪时间步和输入创建模态间隐藏状态的交互，通过ε-greedy策略稀疏选择前k个隐藏状态，实现精确的token级特征对齐。

Result: 在文本到图像生成(MoS-Image)和编辑(MoS-Editing)任务中取得最先进结果，仅用3B-5B参数即可匹配或超越参数多4倍的模型，计算开销可忽略不计。

Conclusion: MoS为扩展多模态扩散模型提供了一个灵活且计算高效的范式，在保持高性能的同时显著减少了参数数量和计算成本。

Abstract: We introduce MoS (Mixture of States), a novel fusion paradigm for multimodal diffusion models that merges modalities using flexible, state-based interactions. The core of MoS is a learnable, token-wise router that creates denoising timestep- and input-dependent interactions between modalities' hidden states, precisely aligning token-level features with the diffusion trajectory. This router sparsely selects the top-$k$ hidden states and is trained with an $ε$-greedy strategy, efficiently selecting contextual features with minimal learnable parameters and negligible computational overhead. We validate our design with text-to-image generation (MoS-Image) and editing (MoS-Editing), which achieve state-of-the-art results. With only 3B to 5B parameters, our models match or surpass counterparts up to $4\times$ larger. These findings establish MoS as a flexible and compute-efficient paradigm for scaling multimodal diffusion models.

</details>


### [63] [FaNe: Towards Fine-Grained Cross-Modal Contrast with False-Negative Reduction and Text-Conditioned Sparse Attention](https://arxiv.org/abs/2511.12215)
*Peng Zhang,Zhihui Lai,Wenting Chen,Xu Wu,Heng Kong*

Main category: cs.CV

TL;DR: FaNe是一个语义增强的医学视觉语言预训练框架，通过语义感知的正对挖掘、文本条件稀疏注意力池化和硬负样本感知对比损失，解决了假阴性和细粒度跨模态对齐不足的问题，在多个医学影像下游任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言预训练方法存在两个主要限制：由语义相似文本引起的假阴性问题，以及细粒度跨模态对齐不足。这些问题影响了模型对医学图像的理解能力。

Method: 1. 语义感知正对挖掘策略：基于文本-文本相似性进行自适应归一化
2. 文本条件稀疏注意力池化模块：通过文本引导的局部视觉表示实现细粒度图像-文本对齐
3. 硬负样本感知对比损失：自适应重加权语义相似的负样本以增强模态内区分度

Result: 在五个下游医学影像基准测试上的广泛实验表明，FaNe在图像分类、目标检测和语义分割任务中均达到了最先进的性能。

Conclusion: FaNe框架通过解决假阴性和细粒度对齐问题，有效提升了医学视觉语言预训练的性能，验证了所提出方法的有效性。

Abstract: Medical vision-language pre-training (VLP) offers significant potential for advancing medical image understanding by leveraging paired image-report data. However, existing methods are limited by Fa}lse Negatives (FaNe) induced by semantically similar texts and insufficient fine-grained cross-modal alignment. To address these limitations, we propose FaNe, a semantic-enhanced VLP framework. To mitigate false negatives, we introduce a semantic-aware positive pair mining strategy based on text-text similarity with adaptive normalization. Furthermore, we design a text-conditioned sparse attention pooling module to enable fine-grained image-text alignment through localized visual representations guided by textual cues. To strengthen intra-modal discrimination, we develop a hard-negative aware contrastive loss that adaptively reweights semantically similar negatives. Extensive experiments on five downstream medical imaging benchmarks demonstrate that FaNe achieves state-of-the-art performance across image classification, object detection, and semantic segmentation, validating the effectiveness of our framework.

</details>


### [64] [Suppressing VLM Hallucinations with Spectral Representation Filtering](https://arxiv.org/abs/2511.12220)
*Ameen Ali,Tamim Zoabi,Lior Wolf*

Main category: cs.CV

TL;DR: SRF是一种无需训练的方法，通过分析模型表示的协方差结构来抑制视觉语言模型中的幻觉现象，在多种VLM模型上显著降低幻觉率且不影响推理速度。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型经常由于过度依赖语言先验和跨模态对齐不精确而产生幻觉，描述图像中不存在的对象、属性或关系。

Method: 通过特征分解识别真实描述和幻觉描述特征差异协方差中的低秩幻觉模式，使用软谱滤波器在深层vLLM层的前馈投影权重中衰减这些模式，均衡特征方差同时保持语义保真度。

Result: 在LLaVA-1.5、MiniGPT-4和mPLUG-Owl2等VLM模型上，SRF在MSCOCO、POPE-VQA等视觉任务基准上持续降低幻觉率，达到最先进的忠实度。

Conclusion: SRF是一种轻量级、无需训练的后处理方法，无需推理开销和架构修改，能有效抑制VLM幻觉同时保持描述质量。

Abstract: Vision-language models (VLMs) frequently produce hallucinations in the form of descriptions of objects, attributes, or relations that do not exist in the image due to over-reliance on language priors and imprecise cross-modal grounding. We introduce Spectral Representation Filtering (SRF), a lightweight, training-free method to suppress such hallucinations by analyzing and correcting the covariance structure of the model's representations. SRF identifies low-rank hallucination modes through eigendecomposition of the covariance of the differences between features collected for truthful and hallucinatory captions, revealing structured biases in the feature space. A soft spectral filter then attenuates these modes in the feed-forward projection weights of deeper vLLM layers, equalizing feature variance while preserving semantic fidelity. Unlike decoding or retraining-based approaches, SRF operates entirely post-hoc, incurs zero inference overhead, and requires no architectural modifications. Across three families of VLMs (LLaVA-1.5, MiniGPT-4, and mPLUG-Owl2), SRF consistently reduces hallucination rates on MSCOCO, POPE-VQA, and other visual tasks benchmarks, achieving state-of-the-art faithfulness without degrading caption quality.

</details>


### [65] [MiniGPT-Pancreas: Multimodal Large Language Model for Pancreas Cancer Classification and Detection](https://arxiv.org/abs/2412.15925)
*Andrea Moglia,Elia Clement Nastasio,Luca Mainardi,Pietro Cerveri*

Main category: cs.CV

TL;DR: MiniGPT-Pancreas是一个基于MiniGPT-v2的多模态大语言模型，通过级联微调实现胰腺检测、肿瘤分类和肿瘤检测，为临床医生提供胰腺癌诊断支持。


<details>
  <summary>Details</summary>
Motivation: 胰腺放射影像学成像具有挑战性，因为胰腺器官体积小、边界模糊，且在不同患者中形状和位置存在变异性。

Method: 使用NIH、MSD和AbdomenCT-1k数据集，对通用MLLM MiniGPT-v2进行级联微调，结合问题和计算机断层扫描的多模态提示，实现胰腺检测、肿瘤分类和肿瘤检测。

Result: 在NIH和MSD数据集上胰腺检测IoU分别为0.595和0.550；MSD数据集上胰腺癌分类准确率0.876、精确率0.874、召回率0.878；多器官检测中肝脏IoU 0.8399、肾脏0.722、脾脏0.705、胰腺0.497；胰腺肿瘤检测IoU为0.168。

Conclusion: MiniGPT-Pancreas是支持临床医生进行胰腺肿瘤图像分类的有前景解决方案，未来研究需要改进检测任务性能，特别是胰腺肿瘤检测。

Abstract: Problem: Pancreas radiological imaging is challenging due to the small size, blurred boundaries, and variability of shape and position of the organ among patients. Goal: In this work we present MiniGPT-Pancreas, a Multimodal Large Language Model (MLLM), as an interactive chatbot to support clinicians in pancreas cancer diagnosis by integrating visual and textual information. Methods: MiniGPT-v2, a general-purpose MLLM, was fine-tuned in a cascaded way for pancreas detection, tumor classification, and tumor detection with multimodal prompts combining questions and computed tomography scans from the National Institute of Health (NIH), and Medical Segmentation Decathlon (MSD) datasets. The AbdomenCT-1k dataset was used to detect the liver, spleen, kidney, and pancreas. Results: MiniGPT-Pancreas achieved an Intersection over Union (IoU) of 0.595 and 0.550 for the detection of pancreas on NIH and MSD datasets, respectively. For the pancreas cancer classification task on the MSD dataset, accuracy, precision, and recall were 0.876, 0.874, and 0.878, respectively. When evaluating MiniGPT-Pancreas on the AbdomenCT-1k dataset for multi-organ detection, the IoU was 0.8399 for the liver, 0.722 for the kidney, 0.705 for the spleen, and 0.497 for the pancreas. For the pancreas tumor detection task, the IoU score was 0.168 on the MSD dataset. Conclusions: MiniGPT-Pancreas represents a promising solution to support clinicians in the classification of pancreas images with pancreas tumors. Future research is needed to improve the score on the detection task, especially for pancreas tumors.

</details>


### [66] [Fusionista2.0: Efficiency Retrieval System for Large-Scale Datasets](https://arxiv.org/abs/2511.12255)
*Huy M. Le,Dat Tien Nguyen,Phuc Binh Nguyen,Gia-Bao Le-Tran,Phu Truong Thien,Cuong Dinh,Minh Nguyen,Nga Nguyen,Thuy T. N. Nguyen,Huy Gia Ngo,Tan Nhat Nguyen,Binh T. Nguyen,Monojit Choudhury*

Main category: cs.CV

TL;DR: Fusionista2.0是一个优化的视频检索系统，通过重新设计核心模块（关键帧提取、OCR、语音识别）和轻量级视觉语言模型，将检索时间减少75%，同时提高准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: Video Browser Showdown (VBS) 挑战赛要求系统在严格时间限制下提供准确结果，需要开发高效快速的视频检索系统。

Method: 使用ffmpeg进行快速关键帧提取，Vintern-1B-v3.5进行多语言OCR，faster-whisper进行实时语音识别，轻量级视觉语言模型进行问答，并重新设计用户界面。

Result: 检索时间减少高达75%，准确性和用户满意度均有提高。

Conclusion: Fusionista2.0是一个具有竞争力且用户友好的大规模视频搜索系统。

Abstract: The Video Browser Showdown (VBS) challenges systems to deliver accurate results under strict time constraints. To meet this demand, we present Fusionista2.0, a streamlined video retrieval system optimized for speed and usability. All core modules were re-engineered for efficiency: preprocessing now relies on ffmpeg for fast keyframe extraction, optical character recognition uses Vintern-1B-v3.5 for robust multilingual text recognition, and automatic speech recognition employs faster-whisper for real-time transcription. For question answering, lightweight vision-language models provide quick responses without the heavy cost of large models. Beyond these technical upgrades, Fusionista2.0 introduces a redesigned user interface with improved responsiveness, accessibility, and workflow efficiency, enabling even non-expert users to retrieve relevant content rapidly. Evaluations demonstrate that retrieval time was reduced by up to 75% while accuracy and user satisfaction both increased, confirming Fusionista2.0 as a competitive and user-friendly system for large-scale video search.

</details>


### [67] [Prompt-Conditioned FiLM and Multi-Scale Fusion on MedSigLIP for Low-Dose CT Quality Assessment](https://arxiv.org/abs/2511.12256)
*Tolga Demiroglu,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: cs.CV

TL;DR: 提出了基于MedSigLIP的提示条件框架，通过FiLM和多尺度池化注入文本先验，实现数据高效学习和快速适应，在LDCTIQA2023挑战中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 开发能够通过文本提示条件化临床意图的医学图像质量评估方法，实现数据高效学习和快速适应。

Method: 基于MedSigLIP框架，使用FiLM注入文本先验，结合全局、局部和纹理感知的多尺度池化，通过轻量级MLP融合不同回归头，采用成对排序损失训练。

Result: 在LDCTIQA2023挑战的1000张训练图像上，获得PLCC=0.9575、SROCC=0.9561、KROCC=0.8301，超越已发表的最佳挑战提交结果。

Conclusion: 提示引导方法在医学图像质量评估中表现出色，验证了文本条件化在数据稀缺场景下的有效性。

Abstract: We propose a prompt-conditioned framework built on MedSigLIP that injects textual priors via Feature-wise Linear Modulation (FiLM) and multi-scale pooling. Text prompts condition patch-token features on clinical intent, enabling data-efficient learning and rapid adaptation. The architecture combines global, local, and texture-aware pooling through separate regression heads fused by a lightweight MLP, trained with pairwise ranking loss. Evaluated on the LDCTIQA2023 (a public LDCT quality assessment challenge) with 1,000 training images, we achieve PLCC = 0.9575, SROCC = 0.9561, and KROCC = 0.8301, surpassing the top-ranked published challenge submissions and demonstrating the effectiveness of our prompt-guided approach.

</details>


### [68] [A Disease-Aware Dual-Stage Framework for Chest X-ray Report Generation](https://arxiv.org/abs/2511.12259)
*Puzhen Wu,Hexin Dong,Yi Lin,Yihao Ding,Yifan Peng*

Main category: cs.CV

TL;DR: 提出了一种新颖的双阶段疾病感知框架用于胸部X光报告生成，通过疾病感知语义标记和视觉-语言对齐来提升临床准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉表示中缺乏足够的疾病感知能力，视觉-语言对齐不足，导致忽略关键病理特征且难以生成临床准确的报告。

Method: 第一阶段学习疾病感知语义标记并通过对比学习对齐视觉和语言表示；第二阶段引入疾病-视觉注意力融合模块和双模态相似性检索机制。

Result: 在多个基准数据集上的实验表明，该框架在胸部X光报告生成方面达到了最先进的性能，临床准确性和语言质量显著提升。

Conclusion: 所提出的疾病感知框架能够有效解决现有方法的局限性，在胸部X光报告生成任务中表现出优越性能。

Abstract: Radiology report generation from chest X-rays is an important task in artificial intelligence with the potential to greatly reduce radiologists' workload and shorten patient wait times. Despite recent advances, existing approaches often lack sufficient disease-awareness in visual representations and adequate vision-language alignment to meet the specialized requirements of medical image analysis. As a result, these models usually overlook critical pathological features on chest X-rays and struggle to generate clinically accurate reports. To address these limitations, we propose a novel dual-stage disease-aware framework for chest X-ray report generation. In Stage~1, our model learns Disease-Aware Semantic Tokens (DASTs) corresponding to specific pathology categories through cross-attention mechanisms and multi-label classification, while simultaneously aligning vision and language representations via contrastive learning. In Stage~2, we introduce a Disease-Visual Attention Fusion (DVAF) module to integrate disease-aware representations with visual features, along with a Dual-Modal Similarity Retrieval (DMSR) mechanism that combines visual and disease-specific similarities to retrieve relevant exemplars, providing contextual guidance during report generation. Extensive experiments on benchmark datasets (i.e., CheXpert Plus, IU X-ray, and MIMIC-CXR) demonstrate that our disease-aware framework achieves state-of-the-art performance in chest X-ray report generation, with significant improvements in clinical accuracy and linguistic quality.

</details>


### [69] [CrossVid: A Comprehensive Benchmark for Evaluating Cross-Video Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2511.12263)
*Jingyao Li,Jingyun Wang,Molin Tan,Haochen Wang,Cilin Yan,Likun Shi,Jiayin Cai,Xiaolong Jiang,Yao Hu*

Main category: cs.CV

TL;DR: CrossVid是首个专门评估多模态大语言模型在跨视频推理能力方面的基准，包含4个高级维度和10个具体任务，提供5,331个视频和9,015个问答对。实验显示当前MLLMs在跨视频推理方面表现不佳，主要原因是难以整合和比较多个视频中的证据。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准主要关注单视频分析，无法评估MLLMs同时推理多个视频的能力。虽然近期有评估多视角视频的基准，但其有限的任务无法全面评估MLLMs在多样化真实世界跨视频推理场景中的表现。

Method: 提出了CrossVid基准，涵盖广泛的分层任务，包括四个高级维度和十个具体任务，提供5,331个视频和9,015个具有挑战性的问答对，涵盖单选、多选和开放式问题格式。

Result: 通过对各种开源和闭源MLLMs的广泛实验，发现Gemini-2.5-Pro在CrossVid上表现最佳，平均准确率为50.4%。深入的案例研究表明，大多数当前MLLMs在跨视频推理任务上表现挣扎。

Conclusion: CrossVid基准有潜力指导未来增强MLLMs跨视频推理能力的发展，当前MLLMs的主要瓶颈在于无法整合或比较分布在多个视频中的证据进行推理。

Abstract: Cross-Video Reasoning (CVR) presents a significant challenge in video understanding, which requires simultaneous understanding of multiple videos to aggregate and compare information across groups of videos. Most existing video understanding benchmarks focus on single-video analysis, failing to assess the ability of multimodal large language models (MLLMs) to simultaneously reason over various videos. Recent benchmarks evaluate MLLMs' capabilities on multi-view videos that capture different perspectives of the same scene. However, their limited tasks hinder a thorough assessment of MLLMs in diverse real-world CVR scenarios. To this end, we introduce CrossVid, the first benchmark designed to comprehensively evaluate MLLMs' spatial-temporal reasoning ability in cross-video contexts. Firstly, CrossVid encompasses a wide spectrum of hierarchical tasks, comprising four high-level dimensions and ten specific tasks, thereby closely reflecting the complex and varied nature of real-world video understanding. Secondly, CrossVid provides 5,331 videos, along with 9,015 challenging question-answering pairs, spanning single-choice, multiple-choice, and open-ended question formats. Through extensive experiments on various open-source and closed-source MLLMs, we observe that Gemini-2.5-Pro performs best on CrossVid, achieving an average accuracy of 50.4%. Notably, our in-depth case study demonstrates that most current MLLMs struggle with CVR tasks, primarily due to their inability to integrate or compare evidence distributed across multiple videos for reasoning. These insights highlight the potential of CrossVid to guide future advancements in enhancing MLLMs' CVR capabilities.

</details>


### [70] [ZoomEarth: Active Perception for Ultra-High-Resolution Geospatial Vision-Language Tasks](https://arxiv.org/abs/2511.12267)
*Ruixun Liu,Bowen Fu,Jiayi Song,Kaiyu Li,Wanchen Li,Lanxuan Xue,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.CV

TL;DR: 本文提出了一种主动感知范式ZoomEarth，通过自适应裁剪缩放框架处理超高分辨率遥感图像，在LRS-GRO基准数据集上实现最先进性能，并能无缝集成到下游任务中。


<details>
  <summary>Details</summary>
Motivation: 现有动态分辨率和令牌剪枝方法受限于被动感知范式，在处理更精细视觉输入时会产生冗余。本文探索新的主动感知范式，使模型能够重新访问信息丰富区域。

Method: 提出ZoomEarth自适应裁剪缩放框架，采用区域引导奖励机制，通过监督微调和组相对策略优化进行训练。

Result: 在LRS-GRO基准上实现最先进性能，在零样本设置下在三个公共超高分辨率遥感基准上表现优异。

Conclusion: ZoomEarth框架具有强大的多功能性和可扩展性，可无缝集成到云去除、去噪、分割和图像编辑等下游任务中。

Abstract: Ultra-high-resolution (UHR) remote sensing (RS) images offer rich fine-grained information but also present challenges in effective processing. Existing dynamic resolution and token pruning methods are constrained by a passive perception paradigm, suffering from increased redundancy when obtaining finer visual inputs. In this work, we explore a new active perception paradigm that enables models to revisit information-rich regions. First, we present LRS-GRO, a large-scale benchmark dataset tailored for active perception in UHR RS processing, encompassing 17 question types across global, region, and object levels, annotated via a semi-automatic pipeline. Building on LRS-GRO, we propose ZoomEarth, an adaptive cropping-zooming framework with a novel Region-Guided reward that provides fine-grained guidance. Trained via supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), ZoomEarth achieves state-of-the-art performance on LRS-GRO and, in the zero-shot setting, on three public UHR remote sensing benchmarks. Furthermore, ZoomEarth can be seamlessly integrated with downstream models for tasks such as cloud removal, denoising, segmentation, and image editing through simple tool interfaces, demonstrating strong versatility and extensibility.

</details>


### [71] [TM-UNet: Token-Memory Enhanced Sequential Modeling for Efficient Medical Image Segmentation](https://arxiv.org/abs/2511.12270)
*Yaxuan Jiao,Qing Xu,Yuxiang Luo,Xiangjian He,Zhen Chen,Wenting Duan*

Main category: cs.CV

TL;DR: TM-UNet是一种轻量级医学图像分割框架，通过多尺度令牌-内存块将2D空间特征转换为令牌序列，利用矩阵内存单元选择性保留和传播判别性上下文信息，在显著降低计算成本的同时实现高效全局推理。


<details>
  <summary>Details</summary>
Motivation: 基于transformer的方法在医学图像分割中取得了显著成果，但其高计算成本阻碍了临床部署，因此需要开发轻量级的高效分割框架。

Method: 提出多尺度令牌-内存块，通过空间扫描将2D特征转换为令牌序列，利用矩阵内存单元选择性保留上下文信息，采用指数门控识别令牌有效性，并通过并行池化操作实现多尺度上下文提取。

Result: TM-UNet在多种医学分割任务中优于现有最先进方法，同时显著降低了计算成本。

Conclusion: TM-UNet通过创新的令牌-内存机制实现了高效的医学图像分割，为临床部署提供了可行的轻量级解决方案。

Abstract: Medical image segmentation is essential for clinical diagnosis and treatment planning. Although transformer-based methods have achieved remarkable results, their high computational cost hinders clinical deployment. To address this issue, we propose TM-UNet, a novel lightweight framework that integrates token sequence modeling with an efficient memory mechanism for efficient medical segmentation. Specifically, we introduce a multi-scale token-memory (MSTM) block that transforms 2D spatial features into token sequences through strategic spatial scanning, leveraging matrix memory cells to selectively retain and propagate discriminative contextual information across tokens. This novel token-memory mechanism acts as a dynamic knowledge store that captures long-range dependencies with linear complexity, enabling efficient global reasoning without redundant computation. Our MSTM block further incorporates exponential gating to identify token effectiveness and multi-scale contextual extraction via parallel pooling operations, enabling hierarchical representation learning without computational overhead. Extensive experiments demonstrate that TM-UNet outperforms state-of-the-art methods across diverse medical segmentation tasks with substantially reduced computation cost. The code is available at https://github.com/xq141839/TM-UNet.

</details>


### [72] [D$^{3}$ToM: Decider-Guided Dynamic Token Merging for Accelerating Diffusion MLLMs](https://arxiv.org/abs/2511.12280)
*Shuochen Chang,Xiaofeng Zhang,Qingyang Liu,Li Niu*

Main category: cs.CV

TL;DR: D³ToM是一种用于加速扩散式多模态大语言模型推理的方法，通过动态合并冗余视觉令牌来减少计算复杂度，在保持性能的同时显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 扩散式多模态大语言模型虽然具有强大的非自回归生成能力，但由于每个去噪步骤都需要对整个序列进行双向自注意力计算，导致立方级的解码复杂度，推理速度远慢于自回归模型。

Method: 提出D³ToM方法，使用前一步生成的决策令牌构建重要性映射，保留最显著的视觉令牌并通过相似性聚合合并冗余令牌，动态调整合并比例以适应不同去噪步骤。

Result: 实验表明D³ToM在保持竞争性能的同时显著加速了推理过程，该方法作为即插即用模块集成到单个Transformer层中，无需改变模型参数。

Conclusion: D³ToM有效解决了扩散式多模态大语言模型推理速度慢的问题，通过动态令牌合并实现了计算效率与性能的良好平衡。

Abstract: Diffusion-based multimodal large language models (Diffusion MLLMs) have recently demonstrated impressive non-autoregressive generative capabilities across vision-and-language tasks. However, Diffusion MLLMs exhibit substantially slower inference than autoregressive models: Each denoising step employs full bidirectional self-attention over the entire sequence, resulting in cubic decoding complexity that becomes computationally impractical with thousands of visual tokens. To address this challenge, we propose D$^{3}$ToM, a Decider-guided dynamic token merging method that dynamically merges redundant visual tokens at different denoising steps to accelerate inference in Diffusion MLLMs. At each denoising step, D$^{3}$ToM uses decider tokens-the tokens generated in the previous denoising step-to build an importance map over all visual tokens. Then it maintains a proportion of the most salient tokens and merges the remainder through similarity-based aggregation. This plug-and-play module integrates into a single transformer layer, physically shortening the visual token sequence for all subsequent layers without altering model parameters. Moreover, D$^{3}$ToM employs a merge ratio that dynamically varies with each denoising step, aligns with the native decoding process of Diffusion MLLMs, achieving superior performance under equivalent computational budgets. Extensive experiments show that D$^{3}$ToM accelerates inference while preserving competitive performance. The code is released at https://github.com/bcmi/D3ToM-Diffusion-MLLM.

</details>


### [73] [One target to align them all: LiDAR, RGB and event cameras extrinsic calibration for Autonomous Driving](https://arxiv.org/abs/2511.12291)
*Andrea Bertogalli,Giacomo Boracchi,Luca Magri*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态外参标定框架，可同时估计事件相机、LiDAR和RGB相机之间的相对位姿，特别关注具有挑战性的事件相机标定问题。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶等复杂视觉系统中，精确的多传感器对齐至关重要。现有方法通常依赖分离的成对标定，而本文旨在实现一次性联合外参标定。

Method: 设计并构建了新型3D标定靶标，包含平面特征、ChArUco图案和主动LED模式，分别针对LiDAR、RGB相机和事件相机的独特特性。通过这一靶标实现一次性联合标定流程。

Result: 在定制数据集上进行了广泛的实验评估，使用先进的自动驾驶传感器设置进行记录，验证了方法的准确性和鲁棒性。

Conclusion: 该方法能够准确标定自动驾驶环境中的复杂视觉系统，提供了一种高效的多传感器联合标定解决方案。

Abstract: We present a novel multi-modal extrinsic calibration framework designed to simultaneously estimate the relative poses between event cameras, LiDARs, and RGB cameras, with particular focus on the challenging event camera calibration. Core of our approach is a novel 3D calibration target, specifically designed and constructed to be concurrently perceived by all three sensing modalities. The target encodes features in planes, ChArUco, and active LED patterns, each tailored to the unique characteristics of LiDARs, RGB cameras, and event cameras respectively. This unique design enables a one-shot, joint extrinsic calibration process, in contrast to existing approaches that typically rely on separate, pairwise calibrations. Our calibration pipeline is designed to accurately calibrate complex vision systems in the context of autonomous driving, where precise multi-sensor alignment is critical. We validate our approach through an extensive experimental evaluation on a custom built dataset, recorded with an advanced autonomous driving sensor setup, confirming the accuracy and robustness of our method.

</details>


### [74] [Rethinking Bias in Generative Data Augmentation for Medical AI: a Frequency Recalibration Method](https://arxiv.org/abs/2511.12301)
*Chi Liu,Jincheng Liu,Congcong Zhu,Minghao Wang,Sheng Shen,Jia Gu,Tianqing Zhu,Wanlei Zhou*

Main category: cs.CV

TL;DR: 本文提出频率重校准方法来解决医学图像生成数据增强中的频率失准问题，通过统计高频替换和重建高频映射来改善合成图像质量，提升下游分类任务性能。


<details>
  <summary>Details</summary>
Motivation: 医学AI开发依赖大数据集但面临数据稀缺问题，生成数据增强方法存在频率失准风险，可能引入有害特征损害下游任务性能。

Method: 提出频率重校准方法，包含统计高频替换来粗略对齐高频成分，以及重建高频映射来增强图像质量并重建高频细节。

Result: 在脑部MRI、胸部X光、眼底图像等多个医学数据集上的实验表明，该方法显著提升了下游医学图像分类性能。

Conclusion: 频率重校准是一个独立的后处理步骤，兼容任何生成模型，可无缝集成到常见医学生成数据增强流程中。

Abstract: Developing Medical AI relies on large datasets and easily suffers from data scarcity. Generative data augmentation (GDA) using AI generative models offers a solution to synthesize realistic medical images. However, the bias in GDA is often underestimated in medical domains, with concerns about the risk of introducing detrimental features generated by AI and harming downstream tasks. This paper identifies the frequency misalignment between real and synthesized images as one of the key factors underlying unreliable GDA and proposes the Frequency Recalibration (FreRec) method to reduce the frequency distributional discrepancy and thus improve GDA. FreRec involves (1) Statistical High-frequency Replacement (SHR) to roughly align high-frequency components and (2) Reconstructive High-frequency Mapping (RHM) to enhance image quality and reconstruct high-frequency details. Extensive experiments were conducted in various medical datasets, including brain MRIs, chest X-rays, and fundus images. The results show that FreRec significantly improves downstream medical image classification performance compared to uncalibrated AI-synthesized samples. FreRec is a standalone post-processing step that is compatible with any generative model and can integrate seamlessly with common medical GDA pipelines.

</details>


### [75] [LiDAR-GS++:Improving LiDAR Gaussian Reconstruction via Diffusion Priors](https://arxiv.org/abs/2511.12304)
*Qifeng Chen,Jiarun Liu,Rengan Xie,Tao Tang,Sicong Du,Yiru Zhao,Yuchi Huo,Sheng Yang*

Main category: cs.CV

TL;DR: LiDAR-GS++ 是一种基于高斯溅射的LiDAR重建方法，通过扩散先验增强，解决了单次扫描重建不完整导致的视点外推伪影问题，实现了实时高保真重模拟。


<details>
  <summary>Details</summary>
Motivation: 现有的基于高斯溅射的LiDAR渲染方法在视点外推时会出现伪影，主要原因是单次遍历扫描的重建不完整。

Method: 提出可控的LiDAR生成模型，基于粗略外推渲染生成额外的几何一致扫描，并采用有效的蒸馏机制进行扩展重建。

Result: 在多个公共数据集上的实验表明，LiDAR-GS++在插值和外推视点上都达到了最先进的性能，超越了现有的GS和NeRF方法。

Conclusion: 通过将重建扩展到欠拟合区域，该方法确保了外推新视点的全局几何一致性，同时保留了传感器捕获的详细场景表面。

Abstract: Recent GS-based rendering has made significant progress for LiDAR, surpassing Neural Radiance Fields (NeRF) in both quality and speed. However, these methods exhibit artifacts in extrapolated novel view synthesis due to the incomplete reconstruction from single traversal scans. To address this limitation, we present LiDAR-GS++, a LiDAR Gaussian Splatting reconstruction method enhanced by diffusion priors for real-time and high-fidelity re-simulation on public urban roads. Specifically, we introduce a controllable LiDAR generation model conditioned on coarsely extrapolated rendering to produce extra geometry-consistent scans and employ an effective distillation mechanism for expansive reconstruction. By extending reconstruction to under-fitted regions, our approach ensures global geometric consistency for extrapolative novel views while preserving detailed scene surfaces captured by sensors. Experiments on multiple public datasets demonstrate that LiDAR-GS++ achieves state-of-the-art performance for both interpolated and extrapolated viewpoints, surpassing existing GS and NeRF-based methods.

</details>


### [76] [Learning Time in Static Classifiers](https://arxiv.org/abs/2511.12321)
*Xi Ding,Lei Wang,Piotr Koniusz,Yongsheng Gao*

Main category: cs.CV

TL;DR: 提出了一种简单有效的框架，为前馈分类器添加时间推理能力，无需修改模型架构或引入循环模块。通过SEQ学习范式构建时间连贯轨迹，学习类别特定时间原型，并使用可微分soft-DTW损失对齐预测序列。


<details>
  <summary>Details</summary>
Motivation: 现实世界视觉数据通常随时间逐渐演变，但传统分类器基于时间独立性假设训练，无法捕捉这种动态变化。需要在不改变模型架构的情况下增强时间推理能力。

Method: 采用支持-范例-查询(SEQ)学习范式，将训练数据组织成时间连贯轨迹。学习类别特定时间原型，使用可微分soft-DTW损失对齐预测序列，并通过多目标函数促进语义一致性和时间平滑性。

Result: 在静态和时序任务中均表现优异：提升了细粒度和超细粒度图像分类性能，在视频异常检测中提供精确且时间一致的预测。

Conclusion: 该方法通过损失设计引入强时间归纳偏置，以模块化和数据高效的方式桥接静态和时序学习，仅需在预提取特征上使用简单分类器。

Abstract: Real-world visual data rarely presents as isolated, static instances. Instead, it often evolves gradually over time through variations in pose, lighting, object state, or scene context. However, conventional classifiers are typically trained under the assumption of temporal independence, limiting their ability to capture such dynamics. We propose a simple yet effective framework that equips standard feedforward classifiers with temporal reasoning, all without modifying model architectures or introducing recurrent modules. At the heart of our approach is a novel Support-Exemplar-Query (SEQ) learning paradigm, which structures training data into temporally coherent trajectories. These trajectories enable the model to learn class-specific temporal prototypes and align prediction sequences via a differentiable soft-DTW loss. A multi-term objective further promotes semantic consistency and temporal smoothness. By interpreting input sequences as evolving feature trajectories, our method introduces a strong temporal inductive bias through loss design alone. This proves highly effective in both static and temporal tasks: it enhances performance on fine-grained and ultra-fine-grained image classification, and delivers precise, temporally consistent predictions in video anomaly detection. Despite its simplicity, our approach bridges static and temporal learning in a modular and data-efficient manner, requiring only a simple classifier on top of pre-extracted features.

</details>


### [77] [SpaceVLM: Sub-Space Modeling of Negation in Vision-Language Models](https://arxiv.org/abs/2511.12331)
*Sepehr Kazemi Ranjbar,Kumail Alhamoud,Marzyeh Ghassemi*

Main category: cs.CV

TL;DR: 提出了一种无需训练的方法，将否定建模为嵌入空间中的子空间而非单点，通过构建球形区域来同时接近肯定概念和远离否定概念，显著提升了视觉语言模型的否定理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在理解否定概念时表现不佳，而通过微调大型否定数据集的方法往往会损害模型在肯定提示上的零样本性能。

Method: 基于CLIP等模型的嵌入空间可划分为语义一致子空间的特性，构建两个球形区域分别围绕肯定概念A和否定概念N的嵌入，通过寻找同时接近A且远离N的区域中心方向来匹配图像。

Result: 在检索、多项选择和文本到图像任务中，该方法将否定理解能力平均提升了约30%，缩小了肯定提示和否定提示之间的性能差距，同时保持了零样本性能。

Conclusion: 该方法无需训练即可有效提升视觉语言模型的否定理解能力，在保持零样本性能的同时显著改善了否定处理效果。

Abstract: Vision-Language Models (VLMs) struggle with negation. Given a prompt like "retrieve (or generate) a street scene without pedestrians," they often fail to respect the "not." Existing methods address this limitation by fine-tuning on large negation datasets, but such retraining often compromises the model's zero-shot performance on affirmative prompts. We show that the embedding space of VLMs, such as CLIP, can be divided into semantically consistent subspaces. Based on this property, we propose a training-free framework that models negation as a subspace in the joint embedding space rather than a single point (Figure 1). To find the matching image for a caption such as "A but not N," we construct two spherical caps around the embeddings of A and N, and we score images by the central direction of the region that is close to A and far from N. Across retrieval, MCQ, and text-to-image tasks, our method improves negation understanding by about 30% on average over prior methods. It closes the gap between affirmative and negated prompts while preserving the zero-shot performance that fine-tuned models fail to maintain. Code will be released upon publication.

</details>


### [78] [Ground Plane Projection for Improved Traffic Analytics at Intersections](https://arxiv.org/abs/2511.12342)
*Sajjad Pakdamansavoji,Kumar Vaibhav Jha,Baher Abdulhai,James H Elder*

Main category: cs.CV

TL;DR: 该论文探讨了通过将基础设施摄像头检测到的车辆反投影到地面平面进行3D坐标分析，以提高交叉口转向运动计数的准确性。研究发现单摄像头系统的反投影能提供更准确的轨迹分类和转向计数，而多摄像头的弱融合能进一步提高精度。


<details>
  <summary>Details</summary>
Motivation: 交叉口的准确转向运动计数对于信号控制、交通管理和城市规划至关重要。传统基于图像平面的计算机视觉系统存在局限性，因此探索在地面平面进行3D坐标分析的优势。

Method: 将基础设施摄像头检测到的车辆反投影到地面平面，在真实世界3D坐标中进行分析。比较单摄像头系统和多摄像头弱融合方法。

Result: 单摄像头系统的反投影能获得更准确的轨迹分类和转向运动计数。多摄像头的弱融合方法能进一步提高计数精度。

Conclusion: 交通分析应该在地面平面进行，而不是在图像平面，这能显著提高转向运动计数的准确性。

Abstract: Accurate turning movement counts at intersections are important for signal control, traffic management and urban planning. Computer vision systems for automatic turning movement counts typically rely on visual analysis in the image plane of an infrastructure camera. Here we explore potential advantages of back-projecting vehicles detected in one or more infrastructure cameras to the ground plane for analysis in real-world 3D coordinates. For single-camera systems we find that back-projection yields more accurate trajectory classification and turning movement counts. We further show that even higher accuracy can be achieved through weak fusion of back-projected detections from multiple cameras. These results suggeest that traffic should be analyzed on the ground plane, not the image plane

</details>


### [79] [CLAReSNet: When Convolution Meets Latent Attention for Hyperspectral Image Classification](https://arxiv.org/abs/2511.12346)
*Asmit Bandyopadhyay,Anindita Das Bhattacharjee,Rakesh Das*

Main category: cs.CV

TL;DR: CLAReSNet是一种混合架构，结合多尺度卷积提取和Transformer风格注意力，通过自适应潜在瓶颈降低计算复杂度，在高光谱图像分类中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决高光谱图像分类面临的高光谱维度、复杂光谱-空间相关性和有限训练样本等问题，克服CNN和Transformer单独应用的局限性。

Method: 集成多尺度卷积提取与Transformer风格注意力，使用自适应潜在瓶颈降低复杂度，结合双向RNN和多尺度光谱潜在注意力模块。

Result: 在Indian Pines和Salinas数据集上分别达到99.71%和99.96%的总体准确率，显著超越现有方法，学习到的嵌入具有优越的类间分离性和类内紧凑性。

Conclusion: CLAReSNet在有限样本和严重类别不平衡条件下有效，验证了混合架构在高光谱图像分类中的优势。

Abstract: Hyperspectral image (HSI) classification faces critical challenges, including high spectral dimensionality, complex spectral-spatial correlations, and limited training samples with severe class imbalance. While CNNs excel at local feature extraction and transformers capture long-range dependencies, their isolated application yields suboptimal results due to quadratic complexity and insufficient inductive biases. We propose CLAReSNet (Convolutional Latent Attention Residual Spectral Network), a hybrid architecture that integrates multi-scale convolutional extraction with transformer-style attention via an adaptive latent bottleneck. The model employs a multi-scale convolutional stem with deep residual blocks and an enhanced Convolutional Block Attention Module for hierarchical spatial features, followed by spectral encoder layers combining bidirectional RNNs (LSTM/GRU) with Multi-Scale Spectral Latent Attention (MSLA). MSLA reduces complexity from $\mathcal{O}(T^2D)$ to $\mathcal{O}(T\log(T)D)$ by adaptive latent token allocation (8-64 tokens) that scales logarithmically with the sequence length. Hierarchical cross-attention fusion dynamically aggregates multi-level representations for robust classification. Experiments conducted on the Indian Pines and Salinas datasets show state-of-the-art performance, achieving overall accuracies of 99.71% and 99.96%, significantly surpassing HybridSN, SSRN, and SpectralFormer. The learned embeddings exhibit superior inter-class separability and compact intra-class clustering, validating CLAReSNet's effectiveness under limited samples and severe class imbalance.

</details>


### [80] [Explainable AI-Generated Image Detection RewardBench](https://arxiv.org/abs/2511.12363)
*Michael Yang,Shijian Deng,William T. Doan,Kai Wang,Tianyu Yang,Harsh Singh,Yapeng Tian*

Main category: cs.CV

TL;DR: 该论文提出了XAIGID-RewardBench基准，用于评估多模态大语言模型在判断AI生成图像检测解释质量方面的能力，发现当前最佳模型与人类表现仍有明显差距。


<details>
  <summary>Details</summary>
Motivation: 传统基于分类的AI生成图像检测方法无法提供人类专家可理解的解释，降低了检测工具的可信度和说服力。虽然使用MLLMs作为解决方案成为趋势，但MLLMs在评估自身或其他MLLMs生成的检测解释方面的表现尚未得到充分研究。

Method: 构建包含约3000个标注三元组的基准数据集，这些数据来自各种图像生成模型和作为检测器的MLLMs，用于评估当前MLLMs作为奖励模型（评判者）的能力。

Result: 当前最佳奖励模型在该基准上得分为88.76%，而人类标注者间一致性达到98.30%，表明当前MLLMs的推理能力与人类水平表现之间仍存在明显差距。

Conclusion: 需要进一步改进MLLMs的推理能力以缩小与人类表现的差距，论文还分析了这些模型常见的缺陷，为未来研究提供了基准和分析框架。

Abstract: Conventional, classification-based AI-generated image detection methods cannot explain why an image is considered real or AI-generated in a way a human expert would, which reduces the trustworthiness and persuasiveness of these detection tools for real-world applications. Leveraging Multimodal Large Language Models (MLLMs) has recently become a trending solution to this issue. Further, to evaluate the quality of generated explanations, a common approach is to adopt an "MLLM as a judge" methodology to evaluate explanations generated by other MLLMs. However, how well those MLLMs perform when judging explanations for AI-generated image detection generated by themselves or other MLLMs has not been well studied. We therefore propose \textbf{XAIGID-RewardBench}, the first benchmark designed to evaluate the ability of current MLLMs to judge the quality of explanations about whether an image is real or AI-generated. The benchmark consists of approximately 3,000 annotated triplets sourced from various image generation models and MLLMs as policy models (detectors) to assess the capabilities of current MLLMs as reward models (judges). Our results show that the current best reward model scored 88.76\% on this benchmark (while human inter-annotator agreement reaches 98.30\%), demonstrating that a visible gap remains between the reasoning abilities of today's MLLMs and human-level performance. In addition, we provide an analysis of common pitfalls that these models frequently encounter. Code and benchmark are available at https://github.com/RewardBench/XAIGID-RewardBench.

</details>


### [81] [Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning](https://arxiv.org/abs/2511.12365)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: DT-R1是一个基于强化学习的框架，通过训练大语言模型构建复杂多模态视觉输入的数字孪生表示，并基于这些高级表示进行统一视觉推理。


<details>
  <summary>Details</summary>
Motivation: 现有视觉推理方法依赖于特定任务的监督微调和架构设计，缺乏统一解决方案，限制了跨任务和跨模态的泛化能力。

Method: 使用GRPO强化学习框架，结合新颖的奖励机制来验证结构完整性和输出准确性，训练LLM构建数字孪生表示并进行推理。

Result: 在六个视觉推理基准测试中，涵盖两种模态和四种任务类型，DT-R1始终优于最先进的特定任务模型。

Conclusion: DT-R1为视觉推理开辟了新方向，即通过数字孪生表示的强化学习实现统一的视觉推理能力。

Abstract: Visual reasoning may require models to interpret images and videos and respond to implicit text queries across diverse output formats, from pixel-level segmentation masks to natural language descriptions. Existing approaches rely on supervised fine-tuning with task-specific architectures. For example, reasoning segmentation, grounding, summarization, and visual question answering each demand distinct model designs and training, preventing unified solutions and limiting cross-task and cross-modality generalization. Hence, we propose DT-R1, a reinforcement learning framework that trains large language models to construct digital twin representations of complex multi-modal visual inputs and then reason over these high-level representations as a unified approach to visual reasoning. Specifically, we train DT-R1 using GRPO with a novel reward that validates both structural integrity and output accuracy. Evaluations in six visual reasoning benchmarks, covering two modalities and four task types, demonstrate that DT-R1 consistently achieves improvements over state-of-the-art task-specific models. DT-R1 opens a new direction where visual reasoning emerges from reinforcement learning with digital twin representations.

</details>


### [82] [Fast Reasoning Segmentation for Images and Videos](https://arxiv.org/abs/2511.12368)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: FastReasonSeg通过数字孪生表示将感知与推理解耦，提出了一种有效的蒸馏方法，包括基于教师生成推理链的监督微调和联合奖励的强化微调，在保持高性能的同时大幅减少了模型参数和计算需求。


<details>
  <summary>Details</summary>
Motivation: 现有推理分割方法需要数十亿参数的多模态大语言模型，超出了边缘设备的计算能力。现有蒸馏方法无法有效传递推理分割所需的多步推理能力，因为它们主要关注输出预测和中间特征的匹配，而不是保留推理链。

Method: 采用数字孪生表示将感知与推理解耦，首先在教师生成的推理链上进行监督微调，然后使用同时评估分割准确性和推理质量对齐的联合奖励进行强化微调。

Result: 在两个视频基准（JiTBench、RVTBench）和两个图像基准（ReasonSeg、LLM-Seg40K）上的实验表明，FastReasonSeg实现了最先进的推理分割性能。蒸馏后的0.6B变体在性能上优于参数多20倍的模型，同时达到7.79 FPS的吞吐量，仅消耗2.1GB内存。

Conclusion: FastReasonSeg的高效性使其能够在资源受限的环境中部署，实现实时推理分割，为在边缘设备上部署的具身AI系统提供了可行的解决方案。

Abstract: Reasoning segmentation enables open-set object segmentation via implicit text queries, therefore serving as a foundation for embodied agents that should operate autonomously in real-world environments. However, existing methods for reasoning segmentation require multimodal large language models with billions of parameters that exceed the computational capabilities of edge devices that typically deploy the embodied AI systems. Distillation offers a pathway to compress these models while preserving their capabilities. Yet, existing distillation approaches fail to transfer the multi-step reasoning capabilities that reasoning segmentation demands, as they focus on matching output predictions and intermediate features rather than preserving reasoning chains. The emerging paradigm of reasoning over digital twin representations presents an opportunity for more effective distillation by re-framing the problem. Consequently, we propose FastReasonSeg, which employs digital twin representations that decouple perception from reasoning to enable more effective distillation. Our distillation scheme first relies on supervised fine-tuning on teacher-generated reasoning chains. Then it is followed by reinforcement fine-tuning with joint rewards evaluating both segmentation accuracy and reasoning quality alignment. Experiments on two video (JiTBench, RVTBench) and two image benchmarks (ReasonSeg, LLM-Seg40K) demonstrate that our FastReasonSeg achieves state-of-the-art reasoning segmentation performance. Moreover, the distilled 0.6B variant outperforms models with 20 times more parameters while achieving 7.79 FPS throughput with only 2.1GB memory consumption. This efficiency enables deployment in resource-constrained environments to enable real-time reasoning segmentation.

</details>


### [83] [Changes in Real Time: Online Scene Change Detection with Multi-View Fusion](https://arxiv.org/abs/2511.12370)
*Chamuditha Jayanga Galappaththige,Jason Lai,Lloyd Windrim,Donald Dansereau,Niko Sünderhauf,Dimity Miller*

Main category: cs.CV

TL;DR: 本文提出了一种首个姿态无关、无需标签、保证多视角一致性的在线场景变化检测方法，在超过10FPS的速度下实现了新的最先进性能，甚至超越了最佳离线方法。


<details>
  <summary>Details</summary>
Motivation: 在线场景变化检测是一个极具挑战性的问题，现有在线方法准确率远低于离线方法。需要开发一种能够在无约束视角下实时检测相关变化的方法。

Method: 引入新的自监督融合损失从多个线索和观察中推断场景变化，基于PnP的快速姿态估计，以及针对3D高斯泼溅场景表示的快速变化引导更新策略。

Result: 在复杂真实世界数据集上的广泛实验表明，该方法超越了在线和离线基线方法，实现了最先进的性能。

Conclusion: 提出的方法在保持实时性能的同时，显著提升了在线场景变化检测的准确性，为实时场景理解应用提供了有效的解决方案。

Abstract: Online Scene Change Detection (SCD) is an extremely challenging problem that requires an agent to detect relevant changes on the fly while observing the scene from unconstrained viewpoints. Existing online SCD methods are significantly less accurate than offline approaches. We present the first online SCD approach that is pose-agnostic, label-free, and ensures multi-view consistency, while operating at over 10 FPS and achieving new state-of-the-art performance, surpassing even the best offline approaches. Our method introduces a new self-supervised fusion loss to infer scene changes from multiple cues and observations, PnP-based fast pose estimation against the reference scene, and a fast change-guided update strategy for the 3D Gaussian Splatting scene representation. Extensive experiments on complex real-world datasets demonstrate that our approach outperforms both online and offline baselines.

</details>


### [84] [Reasoning Text-to-Video Retrieval via Digital Twin Video Representations and Large Language Models](https://arxiv.org/abs/2511.12371)
*Yiqing Shen,Chenxiao Fan,Chenjia Li,Mathias Unberath*

Main category: cs.CV

TL;DR: 该论文提出了推理文本到视频检索的新范式，通过数字孪生表示视频内容，使用大型语言模型进行推理，解决了传统方法无法处理隐含查询的问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频检索方法只能处理显式查询，无法应对需要推理的隐含查询，因此需要开发能够进行推理的检索系统。

Method: 采用两阶段框架：首先通过组合对齐将分解的子查询与数字孪生表示匹配识别候选视频，然后使用大型语言模型进行推理，并通过即时细化调用专业模型填补信息空白。

Result: 在ReasonT2VBench-135上达到81.2%的R@1，比最强基线提升超过50个百分点；在ReasonT2VBench-1000上保持81.7%的R@1，并在三个传统基准测试中取得最先进结果。

Conclusion: 通过数字孪生表示和大型语言模型推理，成功实现了对隐含查询的文本到视频检索，大幅提升了检索性能。

Abstract: The goal of text-to-video retrieval is to search large databases for relevant videos based on text queries. Existing methods have progressed to handling explicit queries where the visual content of interest is described explicitly; however, they fail with implicit queries where identifying videos relevant to the query requires reasoning. We introduce reasoning text-to-video retrieval, a paradigm that extends traditional retrieval to process implicit queries through reasoning while providing object-level grounding masks that identify which entities satisfy the query conditions. Instead of relying on vision-language models directly, we propose representing video content as digital twins, i.e., structured scene representations that decompose salient objects through specialist vision models. This approach is beneficial because it enables large language models to reason directly over long-horizon video content without visual token compression. Specifically, our two-stage framework first performs compositional alignment between decomposed sub-queries and digital twin representations for candidate identification, then applies large language model-based reasoning with just-in-time refinement that invokes additional specialist models to address information gaps. We construct a benchmark of 447 manually created implicit queries with 135 videos (ReasonT2VBench-135) and another more challenging version of 1000 videos (ReasonT2VBench-1000). Our method achieves 81.2% R@1 on ReasonT2VBench-135, outperforming the strongest baseline by greater than 50 percentage points, and maintains 81.7% R@1 on the extended configuration while establishing state-of-the-art results in three conventional benchmarks (MSR-VTT, MSVD, and VATEX).

</details>


### [85] [AGGRNet: Selective Feature Extraction and Aggregation for Enhanced Medical Image Classification](https://arxiv.org/abs/2511.12382)
*Ansh Makwe,Akansh Agrawal,Prateek Jain,Akshan Agrawal,Priyanka Bagade*

Main category: cs.CV

TL;DR: AGGRNet框架通过提取信息性和非信息性特征来区分医学图像中的细微类别差异，在多个医学影像数据集上实现最先进性能，在Kvasir数据集上比现有最佳模型提升5%。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分析中由于类别间视觉模式复杂相似、标记数据稀缺以及专家解释差异导致的严重分级和疾病亚型分类挑战。现有注意力模型难以有效区分细微类别，无法捕捉类间相似性和类内变异性。

Method: 提出AGGRNet框架，提取信息性和非信息性特征，以有效理解细粒度视觉模式并改进复杂医学图像分析任务的分类性能。

Result: 实验结果显示，该模型在多个医学影像数据集上达到最先进性能，在Kvasir数据集上比现有最佳模型提升5%。

Conclusion: AGGRNet框架能够有效解决医学图像分析中的细微类别区分问题，在复杂医学图像分类任务中表现出优越性能。

Abstract: Medical image analysis for complex tasks such as severity grading and disease subtype classification poses significant challenges due to intricate and similar visual patterns among classes, scarcity of labeled data, and variability in expert interpretations. Despite the usefulness of existing attention-based models in capturing complex visual patterns for medical image classification, underlying architectures often face challenges in effectively distinguishing subtle classes since they struggle to capture inter-class similarity and intra-class variability, resulting in incorrect diagnosis. To address this, we propose AGGRNet framework to extract informative and non-informative features to effectively understand fine-grained visual patterns and improve classification for complex medical image analysis tasks. Experimental results show that our model achieves state-of-the-art performance on various medical imaging datasets, with the best improvement up to 5% over SOTA models on the Kvasir dataset.

</details>


### [86] [Calibrated Decomposition of Aleatoric and Epistemic Uncertainty in Deep Features for Inference-Time Adaptation](https://arxiv.org/abs/2511.12389)
*Divake Kumar,Patrick Poggi,Sina Tayebati,Devashri Naik,Nilesh Ahuja,Amit Ranjan Trivedi*

Main category: cs.CV

TL;DR: 提出了一种轻量级推理时间框架，在深度特征空间中解耦数据驱动和模型驱动的不确定性，用于指导自适应模型选择和计算分配。


<details>
  <summary>Details</summary>
Motivation: 大多数估计器将所有不确定性模式压缩为单一置信度分数，无法可靠判断何时需要分配更多计算或调整推理过程。

Method: 使用正则化全局密度模型估计数据不确定性，通过三个互补组件（局部支持不足、流形谱崩溃、跨层特征不一致）估计模型不确定性，无需采样、集成或额外前向传播。

Result: 在MOT17数据集上减少约60%计算量且精度损失可忽略，不确定性分解比总不确定性基线提高13.6个百分点的计算节省。

Conclusion: 该方法实现了实用的自调节视觉推理，通过正交不确定性分解显著提高了计算效率。

Abstract: Most estimators collapse all uncertainty modes into a single confidence score, preventing reliable reasoning about when to allocate more compute or adjust inference. We introduce Uncertainty-Guided Inference-Time Selection, a lightweight inference time framework that disentangles aleatoric (data-driven) and epistemic (model-driven) uncertainty directly in deep feature space. Aleatoric uncertainty is estimated using a regularized global density model, while epistemic uncertainty is formed from three complementary components that capture local support deficiency, manifold spectral collapse, and cross-layer feature inconsistency. These components are empirically orthogonal and require no sampling, no ensembling, and no additional forward passes. We integrate the decomposed uncertainty into a distribution free conformal calibration procedure that yields significantly tighter prediction intervals at matched coverage. Using these components for uncertainty guided adaptive model selection reduces compute by approximately 60 percent on MOT17 with negligible accuracy loss, enabling practical self regulating visual inference. Additionally, our ablation results show that the proposed orthogonal uncertainty decomposition consistently yields higher computational savings across all MOT17 sequences, improving margins by 13.6 percentage points over the total-uncertainty baseline.

</details>


### [87] [VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving](https://arxiv.org/abs/2511.12405)
*Hyunki Seong,Seongwoo Moon,Hojin Ahn,Jehun Kang,David Hyunchul Shim*

Main category: cs.CV

TL;DR: 提出了VLA-R框架，将开放世界感知与视觉-动作检索范式结合，用于端到端自动驾驶，在未见过的非结构化环境中表现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶在非结构化户外环境中经常遇到训练时未见过的条件，需要强大的泛化能力来处理开放世界情况。

Method: 利用冻结的视觉语言模型进行开放世界检测和分割，通过Q-Former瓶颈聚合细粒度视觉表示和语言对齐的视觉特征，并引入视觉-动作对比学习方案来对齐视觉语言和动作嵌入。

Result: 在真实世界机器人平台上的实验表明，即使在数据有限的情况下，也能在未见过的非结构化环境中表现出强大的泛化和探索性能。

Conclusion: VLA-R框架成功地将开放世界感知与动作检索相结合，为端到端自动驾驶提供了有效的开放世界推理能力。

Abstract: Exploring open-world situations in an end-to-end manner is a promising yet challenging task due to the need for strong generalization capabilities. In particular, end-to-end autonomous driving in unstructured outdoor environments often encounters conditions that were unfamiliar during training. In this work, we present Vision-Language Action Retrieval (VLA-R), an open-world end-to-end autonomous driving (OW-E2EAD) framework that integrates open-world perception with a novel vision-action retrieval paradigm. We leverage a frozen vision-language model for open-world detection and segmentation to obtain multi-scale, prompt-guided, and interpretable perception features without domain-specific tuning. A Q-Former bottleneck aggregates fine-grained visual representations with language-aligned visual features, bridging perception and action domains. To learn transferable driving behaviors, we introduce a vision-action contrastive learning scheme that aligns vision-language and action embeddings for effective open-world reasoning and action retrieval. Our experiments on a real-world robotic platform demonstrate strong generalization and exploratory performance in unstructured, unseen environments, even with limited data. Demo videos are provided in the supplementary material.

</details>


### [88] [Towards Rotation-only Imaging Geometry: Rotation Estimation](https://arxiv.org/abs/2511.12415)
*Xinrui Li,Qi Cai,Yuanxin Wu*

Main category: cs.CV

TL;DR: 本文提出了一种基于旋转流形的仅旋转优化框架，用于结构运动重建任务，通过将平移表示为旋转的函数，在旋转流形上压缩成像几何表示，在精度和鲁棒性方面优于现有最先进的旋转估计方法。


<details>
  <summary>Details</summary>
Motivation: 现有的仅位姿成像几何通过位姿调整展示了更好的SfM性能，本文继续从仅位姿视角探索场景结构、旋转和平移之间的关键关系，希望为更准确、高效和可靠的3D视觉计算做出贡献。

Method: 提出基于重投影误差的仅旋转优化框架，适用于双视图和多视图场景，通过将平移表示为旋转的函数，将成像几何表示压缩到旋转流形上。

Result: 实验结果表明，该方法在精度和鲁棒性方面优于当前最先进的旋转估计方法，甚至可与多次束调整迭代结果相媲美。

Conclusion: 这项工作有望为更准确、高效和可靠的3D视觉计算做出贡献，展示了仅旋转优化框架在结构运动重建任务中的优越性能。

Abstract: Structure from Motion (SfM) is a critical task in computer vision, aiming to recover the 3D scene structure and camera motion from a sequence of 2D images. The recent pose-only imaging geometry decouples 3D coordinates from camera poses and demonstrates significantly better SfM performance through pose adjustment. Continuing the pose-only perspective, this paper explores the critical relationship between the scene structures, rotation and translation. Notably, the translation can be expressed in terms of rotation, allowing us to condense the imaging geometry representation onto the rotation manifold. A rotation-only optimization framework based on reprojection error is proposed for both two-view and multi-view scenarios. The experiment results demonstrate superior accuracy and robustness performance over the current state-of-the-art rotation estimation methods, even comparable to multiple bundle adjustment iteration results. Hopefully, this work contributes to even more accurate, efficient and reliable 3D visual computing.

</details>


### [89] [Seeing Through the Rain: Resolving High-Frequency Conflicts in Deraining and Super-Resolution via Diffusion Guidance](https://arxiv.org/abs/2511.12419)
*Wenjie Li,Jinglei Shi,Jin Han,Heng Guo,Zhanyu Ma*

Main category: cs.CV

TL;DR: DHGM模型通过整合预训练扩散先验和高通滤波器，同时去除雨纹伪影并增强结构细节，解决了天气恢复和超分辨率之间的冲突问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界图像常受恶劣天气影响而退化，但天气恢复方法可能会牺牲对分析小物体至关重要的高频细节。简单地级联恢复和超分辨率方法难以解决它们之间的内在冲突：恢复旨在去除高频天气噪声，而超分辨率旨在从现有细节中生成高频纹理。

Method: 提出DHGM（基于扩散的高频引导模型），整合预训练扩散先验与高通滤波器，同时去除雨纹伪影并增强结构细节。

Result: 大量实验表明，DHGM在性能上优于现有方法，且成本更低。

Conclusion: DHGM能够有效生成干净且高分辨率的图像，解决了天气恢复和超分辨率之间的冲突问题。

Abstract: Clean images are crucial for visual tasks such as small object detection, especially at high resolutions. However, real-world images are often degraded by adverse weather, and weather restoration methods may sacrifice high-frequency details critical for analyzing small objects. A natural solution is to apply super-resolution (SR) after weather removal to recover both clarity and fine structures. However, simply cascading restoration and SR struggle to bridge their inherent conflict: removal aims to remove high-frequency weather-induced noise, while SR aims to hallucinate high-frequency textures from existing details, leading to inconsistent restoration contents. In this paper, we take deraining as a case study and propose DHGM, a Diffusion-based High-frequency Guided Model for generating clean and high-resolution images. DHGM integrates pre-trained diffusion priors with high-pass filters to simultaneously remove rain artifacts and enhance structural details. Extensive experiments demonstrate that DHGM achieves superior performance over existing methods, with lower costs.

</details>


### [90] [MFI-ResNet: Efficient ResNet Architecture Optimization via MeanFlow Compression and Selective Incubation](https://arxiv.org/abs/2511.12422)
*Nuolin Sun,Linyuan Wang,Haonan Wei,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: 本文提出MFI-ResNet，通过压缩-扩展策略结合MeanFlow模块改进ResNet的参数效率和判别性能，在CIFAR数据集上显著减少参数同时提高准确率。


<details>
  <summary>Details</summary>
Motivation: 受流匹配模型MeanFlow启发，探索生成式流场如何有效表征ResNet中的特征变换过程，为理解生成式建模与判别式学习关系提供新视角。

Method: 采用压缩-扩展策略：压缩阶段将每个ResNet阶段简化为1-2个MeanFlow模块构建轻量元模型；扩展阶段对前三阶段选择性孵化匹配基线配置，最后一阶段保持MeanFlow形式并微调。

Result: 在CIFAR-10和CIFAR-100上，相比ResNet-50分别减少46.28%和45.59%参数，同时准确率提高0.23%和0.17%。

Conclusion: 生成式流场能有效表征ResNet特征变换过程，为理解生成式建模与判别式学习关系提供了新视角，实现了参数效率与判别性能的联合提升。

Abstract: ResNet has achieved tremendous success in computer vision through its residual connection mechanism. ResNet can be viewed as a discretized form of ordinary differential equations (ODEs). From this perspective, the multiple residual blocks within a single ResNet stage essentially perform multi-step discrete iterations of the feature transformation for that stage. The recently proposed flow matching model, MeanFlow, enables one-step generative modeling by learning the mean velocity field to transform distributions. Inspired by this, we propose MeanFlow-Incubated ResNet (MFI-ResNet), which employs a compression-expansion strategy to jointly improve parameter efficiency and discriminative performance. In the compression phase, we simplify the multi-layer structure within each ResNet stage to one or two MeanFlow modules to construct a lightweight meta model. In the expansion phase, we apply a selective incubation strategy to the first three stages, expanding them to match the residual block configuration of the baseline ResNet model, while keeping the last stage in MeanFlow form, and fine-tune the incubated model. Experimental results show that on CIFAR-10 and CIFAR-100 datasets, MFI-ResNet achieves remarkable parameter efficiency, reducing parameters by 46.28% and 45.59% compared to ResNet-50, while still improving accuracy by 0.23% and 0.17%, respectively. This demonstrates that generative flow-fields can effectively characterize the feature transformation process in ResNet, providing a new perspective for understanding the relationship between generative modeling and discriminative learning.

</details>


### [91] [RedVTP: Training-Free Acceleration of Diffusion Vision-Language Models Inference via Masked Token-Guided Visual Token Pruning](https://arxiv.org/abs/2511.12428)
*Jingqi Xu,Jingxi Lu,Chenghao Li,Sreetama Sarkar,Souvik Kundu,Peter A. Beerel*

Main category: cs.CV

TL;DR: RedVTP是一种针对扩散视觉语言模型（DVLMs）的响应驱动视觉令牌剪枝策略，通过利用推理动态来提升模型效率，在不损失准确性的情况下显著提高生成吞吐量并降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 扩散视觉语言模型（DVLMs）虽然支持并行令牌解码，但大量视觉令牌严重影响了推理效率。虽然自回归视觉语言模型（AVLMs）的视觉令牌剪枝已有广泛研究，但DVLMs的剪枝方法仍未被充分探索。

Method: 提出RedVTP策略，利用DVLMs的推理动态来估计视觉令牌重要性。方法使用掩码响应令牌的注意力来评估重要性，基于重要性分数在推理步骤间保持一致的观察，在第一步推理后从掩码令牌中剪枝重要性较低的视觉令牌。

Result: 实验显示RedVTP将LLaDA-V和LaViDa的令牌生成吞吐量分别提高了186%和28.05%，推理延迟分别降低了64.97%和21.87%，且在不损失甚至在某些情况下提高了准确性的前提下实现这些改进。

Conclusion: RedVTP是一种有效的DVLMs视觉令牌剪枝方法，能够显著提升模型推理效率，为扩散视觉语言模型的实用化部署提供了重要技术支持。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in multimodal reasoning and generation, yet their high computational demands remain a major challenge. Diffusion Vision-Language Models (DVLMs) are particularly attractive because they enable parallel token decoding, but the large number of visual tokens still significantly hinders their inference efficiency. While visual token pruning has been extensively studied for autoregressive VLMs (AVLMs), it remains largely unexplored for DVLMs. In this work, we propose RedVTP, a response-driven visual token pruning strategy that leverages the inference dynamics of DVLMs. Our method estimates visual token importance using attention from the masked response tokens. Based on the observation that these importance scores remain consistent across steps, RedVTP prunes the less important visual tokens from the masked tokens after the first inference step, thereby maximizing inference efficiency. Experiments show that RedVTP improves token generation throughput of LLaDA-V and LaViDa by up to 186% and 28.05%, respectively, and reduces inference latency by up to 64.97% and 21.87%, without compromising-and in some cases improving-accuracy.

</details>


### [92] [Text-Guided Channel Perturbation and Pretrained Knowledge Integration for Unified Multi-Modality Image Fusion](https://arxiv.org/abs/2511.12432)
*Xilai Li,Xiaosong Li,Weijun Jiang*

Main category: cs.CV

TL;DR: 提出UP-Fusion框架，通过通道扰动和预训练知识集成解决多模态图像融合中的梯度冲突问题，提升融合质量和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 统一模型在多模态图像融合中面临梯度冲突问题，而引入模态特定编码器会降低泛化能力，需要克服这一限制。

Method: 提出语义感知通道剪枝模块(SCPM)过滤增强特征通道，几何仿射调制模块(GAM)保持特征编码器模态区分性，文本引导通道扰动模块(TCPM)重塑通道分布。

Result: 在多项多模态图像融合和下游任务实验中，该算法优于现有方法。

Conclusion: UP-Fusion框架通过通道扰动和预训练知识集成有效提升了多模态图像融合的性能和泛化能力。

Abstract: Multi-modality image fusion enhances scene perception by combining complementary information. Unified models aim to share parameters across modalities for multi-modality image fusion, but large modality differences often cause gradient conflicts, limiting performance. Some methods introduce modality-specific encoders to enhance feature perception and improve fusion quality. However, this strategy reduces generalisation across different fusion tasks. To overcome this limitation, we propose a unified multi-modality image fusion framework based on channel perturbation and pre-trained knowledge integration (UP-Fusion). To suppress redundant modal information and emphasize key features, we propose the Semantic-Aware Channel Pruning Module (SCPM), which leverages the semantic perception capability of a pre-trained model to filter and enhance multi-modality feature channels. Furthermore, we proposed the Geometric Affine Modulation Module (GAM), which uses original modal features to apply affine transformations on initial fusion features to maintain the feature encoder modal discriminability. Finally, we apply a Text-Guided Channel Perturbation Module (TCPM) during decoding to reshape the channel distribution, reducing the dependence on modality-specific channels. Extensive experiments demonstrate that the proposed algorithm outperforms existing methods on both multi-modality image fusion and downstream tasks.

</details>


### [93] [DenseAnnotate: Enabling Scalable Dense Caption Collection for Images and 3D Scenes via Spoken Descriptions](https://arxiv.org/abs/2511.12452)
*Xiaoyu Lin,Aniket Ghorpade,Hansheng Zhu,Justin Qiu,Dea Rrozhani,Monica Lama,Mick Yang,Zixuan Bian,Ruohan Ren,Alan B. Hong,Jiatao Gu,Chris Callison-Burch*

Main category: cs.CV

TL;DR: DenseAnnotate是一个音频驱动的在线标注平台，通过语音描述和区域标记创建密集、细粒度的图像和3D资产标注，解决了传统文本标注方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型训练数据主要依赖稀疏的互联网挖掘或手动输入标注，这些方法只能捕获图像视觉内容的一小部分。密集标注更有价值但稀缺，传统文本标注管道在表达性、速度和专业领域覆盖方面存在不足。

Method: 开发音频驱动的在线标注平台，标注者通过语音描述观察内容，同时将口语短语与图像区域或3D场景部分同步链接，结合语音转文本和注意力区域标记技术。

Result: 通过1,000多名标注者在两个领域进行案例研究，创建了包含3,531张图像、898个3D场景和7,460个3D对象的多模态数据集，包含20种语言的音频对齐密集标注。基于此数据集训练的模型在多项能力上显著提升。

Conclusion: 该平台为未来视觉语言研究提供了可行方法，可应用于各种任务和多样化数据类型，显著提升了多模态模型的多语言、文化对齐和3D空间能力。

Abstract: With the rapid adoption of multimodal large language models (MLLMs) across diverse applications, there is a pressing need for task-centered, high-quality training data. A key limitation of current training datasets is their reliance on sparse annotations mined from the Internet or entered via manual typing that capture only a fraction of an image's visual content. Dense annotations are more valuable but remain scarce. Traditional text-based annotation pipelines are poorly suited for creating dense annotations: typing limits expressiveness, slows annotation speed, and underrepresents nuanced visual features, especially in specialized areas such as multicultural imagery and 3D asset annotation. In this paper, we present DenseAnnotate, an audio-driven online annotation platform that enables efficient creation of dense, fine-grained annotations for images and 3D assets. Annotators narrate observations aloud while synchronously linking spoken phrases to image regions or 3D scene parts. Our platform incorporates speech-to-text transcription and region-of-attention marking. To demonstrate the effectiveness of DenseAnnotate, we conducted case studies involving over 1,000 annotators across two domains: culturally diverse images and 3D scenes. We curate a human-annotated multi-modal dataset of 3,531 images, 898 3D scenes, and 7,460 3D objects, with audio-aligned dense annotations in 20 languages, including 8,746 image captions, 2,000 scene captions, and 19,000 object captions. Models trained on this dataset exhibit improvements of 5% in multilingual, 47% in cultural alignment, and 54% in 3D spatial capabilities. Our results show that our platform offers a feasible approach for future vision-language research and can be applied to various tasks and diverse types of data.

</details>


### [94] [Co-Layout: LLM-driven Co-optimization for Interior Layout](https://arxiv.org/abs/2511.12474)
*Chucheng Xiang,Ruchao Bao,Biyin Feng,Wenzheng Wu,Zhongyuan Liu,Yirui Guan,Ligang Liu*

Main category: cs.CV

TL;DR: 提出了一种结合大语言模型和网格整数规划的自动化室内设计框架，联合优化房间布局和家具摆放。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段设计流程在解决方案质量和计算效率方面存在不足，需要一种能够联合优化房间布局和家具摆放的自动化方法。

Method: 使用LLM驱动的智能体工作流提取结构化设计约束，将其编码到基于网格的统一表示中，采用粗到细的优化策略，从低分辨率网格开始简化问题求解。

Result: 在多样化场景下的实验结果表明，该联合优化方法在解决方案质量上显著优于现有的两阶段设计流程，并通过粗到细策略实现了显著的计算效率提升。

Conclusion: 该框架成功地将大语言模型与整数规划相结合，为自动化室内设计提供了一种高效且高质量的解决方案。

Abstract: We present a novel framework for automated interior design that combines large language models (LLMs) with grid-based integer programming to jointly optimize room layout and furniture placement. Given a textual prompt, the LLM-driven agent workflow extracts structured design constraints related to room configurations and furniture arrangements. These constraints are encoded into a unified grid-based representation inspired by ``Modulor". Our formulation accounts for key design requirements, including corridor connectivity, room accessibility, spatial exclusivity, and user-specified preferences. To improve computational efficiency, we adopt a coarse-to-fine optimization strategy that begins with a low-resolution grid to solve a simplified problem and guides the solution at the full resolution. Experimental results across diverse scenarios demonstrate that our joint optimization approach significantly outperforms existing two-stage design pipelines in solution quality, and achieves notable computational efficiency through the coarse-to-fine strategy.

</details>


### [95] [Towards Temporal Fusion Beyond the Field of View for Camera-based Semantic Scene Completion](https://arxiv.org/abs/2511.12498)
*Jongseong Bae,Junwoo Ha,Jinnyeong Heo,Yeongin Lee,Ha Young Kim*

Main category: cs.CV

TL;DR: 提出C3DFusion模块，通过显式对齐当前和历史帧的3D点特征来生成隐藏区域感知的3D特征几何，解决现有方法在重建车辆侧方不可见区域时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于相机的3D语义场景补全方法主要关注增强帧内区域，但在重建车辆侧方关键不可见区域方面存在困难，尽管历史帧通常包含这些不可见区域的有价值上下文信息。

Method: 提出当前中心上下文3D融合(C3DFusion)模块，通过历史上下文模糊和当前中心特征密集化两种互补技术进行增强的时间融合，抑制不准确扭曲历史点特征的噪声，增强当前点特征的体积贡献。

Result: 在SemanticKITTI和SSCBench-KITTI-360数据集上显著优于最先进方法，并展现出强大的泛化能力，应用于其他基线模型时也获得显著性能提升。

Conclusion: C3DFusion模块简单集成到标准SSC架构中即可展现强大效果，通过显式对齐当前和历史帧的3D特征，有效解决了隐藏区域重建问题。

Abstract: Recent camera-based 3D semantic scene completion (SSC) methods have increasingly explored leveraging temporal cues to enrich the features of the current frame. However, while these approaches primarily focus on enhancing in-frame regions, they often struggle to reconstruct critical out-of-frame areas near the sides of the ego-vehicle, although previous frames commonly contain valuable contextual information about these unseen regions. To address this limitation, we propose the Current-Centric Contextual 3D Fusion (C3DFusion) module, which generates hidden region-aware 3D feature geometry by explicitly aligning 3D-lifted point features from both current and historical frames. C3DFusion performs enhanced temporal fusion through two complementary techniques-historical context blurring and current-centric feature densification-which suppress noise from inaccurately warped historical point features by attenuating their scale, and enhance current point features by increasing their volumetric contribution. Simply integrated into standard SSC architectures, C3DFusion demonstrates strong effectiveness, significantly outperforming state-of-the-art methods on the SemanticKITTI and SSCBench-KITTI-360 datasets. Furthermore, it exhibits robust generalization, achieving notable performance gains when applied to other baseline models.

</details>


### [96] [DINO-Detect: A Simple yet Effective Framework for Blur-Robust AI-Generated Image Detection](https://arxiv.org/abs/2511.12511)
*Jialiang Shen,Jiyang Zheng,Yunqi Xue,Huajie Chen,Yu Yao,Hui Kang,Ruiqi Liu,Helin Gong,Yang Yang,Dadong Wang,Tongliang Liu*

Main category: cs.CV

TL;DR: 提出了一种基于师生知识蒸馏的模糊鲁棒AI生成图像检测框架，通过冻结在清晰图像上训练的教师模型（DINOv3），将其特征和logit响应蒸馏到在模糊图像上训练的学生模型，使模型在运动模糊条件下仍能保持一致的表示能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在真实世界退化（特别是运动模糊）下性能严重下降，运动模糊会扭曲精细纹理并抑制高频伪影，限制了实际应用。

Method: 采用师生知识蒸馏框架，使用在清晰图像上训练的DINOv3作为冻结的教师模型，将其特征和logit响应蒸馏到在模糊图像上训练的学生模型，实现模糊条件下的鲁棒检测。

Result: 在运动模糊和清晰条件下的基准测试中均达到最先进性能，显示出改进的泛化能力和实际适用性。

Conclusion: 该方法有效解决了AI生成图像检测在运动模糊条件下的性能下降问题，提升了检测器在真实世界场景中的实用性。

Abstract: With growing concerns over image authenticity and digital safety, the field of AI-generated image (AIGI) detection has progressed rapidly. Yet, most AIGI detectors still struggle under real-world degradations, particularly motion blur, which frequently occurs in handheld photography, fast motion, and compressed video. Such blur distorts fine textures and suppresses high-frequency artifacts, causing severe performance drops in real-world settings. We address this limitation with a blur-robust AIGI detection framework based on teacher-student knowledge distillation. A high-capacity teacher (DINOv3), trained on clean (i.e., sharp) images, provides stable and semantically rich representations that serve as a reference for learning. By freezing the teacher to maintain its generalization ability, we distill its feature and logit responses from sharp images to a student trained on blurred counterparts, enabling the student to produce consistent representations under motion degradation. Extensive experiments benchmarks show that our method achieves state-of-the-art performance under both motion-blurred and clean conditions, demonstrating improved generalization and real-world applicability. Source codes will be released at: https://github.com/JiaLiangShen/Dino-Detect-for-blur-robust-AIGC-Detection.

</details>


### [97] [D$^{2}$-VPR: A Parameter-efficient Visual-foundation-model-based Visual Place Recognition Method via Knowledge Distillation and Deformable Aggregation](https://arxiv.org/abs/2511.12528)
*Zheyuan Zhang,Jiwei Zhang,Boyu Zhou,Linzhimeng Duan,Hong Chen*

Main category: cs.CV

TL;DR: D²-VPR是一个基于蒸馏和可变形聚合的视觉位置识别框架，旨在保持视觉基础模型强大特征提取能力的同时显著减少模型参数和计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决DINOv2等视觉基础模型在VPR任务中虽然性能优越但模型复杂度和计算开销过大，难以在资源受限设备上部署的问题。

Method: 采用两阶段训练策略结合知识蒸馏和微调，引入蒸馏恢复模块(DRM)对齐师生模型特征空间，设计基于自上而下注意力的可变形聚合器(TDDA)动态调整感兴趣区域。

Result: 在保持竞争力的性能同时，相比CricaVPR减少了约64.2%的参数和62.6%的FLOPs。

Conclusion: D²-VPR框架在视觉位置识别任务中实现了更好的性能-效率权衡，为资源受限环境下的VPR应用提供了可行解决方案。

Abstract: Visual Place Recognition (VPR) aims to determine the geographic location of a query image by retrieving its most visually similar counterpart from a geo-tagged reference database. Recently, the emergence of the powerful visual foundation model, DINOv2, trained in a self-supervised manner on massive datasets, has significantly improved VPR performance. This improvement stems from DINOv2's exceptional feature generalization capabilities but is often accompanied by increased model complexity and computational overhead that impede deployment on resource-constrained devices. To address this challenge, we propose $D^{2}$-VPR, a $D$istillation- and $D$eformable-based framework that retains the strong feature extraction capabilities of visual foundation models while significantly reducing model parameters and achieving a more favorable performance-efficiency trade-off. Specifically, first, we employ a two-stage training strategy that integrates knowledge distillation and fine-tuning. Additionally, we introduce a Distillation Recovery Module (DRM) to better align the feature spaces between the teacher and student models, thereby minimizing knowledge transfer losses to the greatest extent possible. Second, we design a Top-Down-attention-based Deformable Aggregator (TDDA) that leverages global semantic features to dynamically and adaptively adjust the Regions of Interest (ROI) used for aggregation, thereby improving adaptability to irregular structures. Extensive experiments demonstrate that our method achieves competitive performance compared to state-of-the-art approaches. Meanwhile, it reduces the parameter count by approximately 64.2% and FLOPs by about 62.6% (compared to CricaVPR).Code is available at https://github.com/tony19980810/D2VPR.

</details>


### [98] [HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models](https://arxiv.org/abs/2511.12547)
*Zhiguang Lu,Qianqian Xu,Peisong Wen,Siran Da,Qingming Huang*

Main category: cs.CV

TL;DR: 本文提出HiGFA方法，通过分层引导策略在扩散模型采样过程中结合文本、轮廓和细粒度分类器引导，生成高质量的细粒度图像用于数据增强。


<details>
  <summary>Details</summary>
Motivation: 解决生成扩散模型在细粒度任务中难以准确捕捉类别定义性细微特征的问题，避免标准方法生成误导性样本导致分类器性能下降。

Method: HiGFA利用扩散采样过程的时间动态性，在早期阶段使用强文本和轮廓引导建立整体场景和结构，在最后阶段激活细粒度分类器引导并基于预测置信度动态调制所有引导信号强度。

Result: 在多个细粒度视觉分类数据集上的实验证明了HiGFA的有效性。

Conclusion: HiGFA通过分层、置信度驱动的协调机制，能够生成多样化且忠实的合成图像，平衡全局结构形成与精确细节优化。

Abstract: Generative diffusion models show promise for data augmentation. However, applying them to fine-grained tasks presents a significant challenge: ensuring synthetic images accurately capture the subtle, category-defining features critical for high fidelity. Standard approaches, such as text-based Classifier-Free Guidance (CFG), often lack the required specificity, potentially generating misleading examples that degrade fine-grained classifier performance. To address this, we propose Hierarchically Guided Fine-grained Augmentation (HiGFA). HiGFA leverages the temporal dynamics of the diffusion sampling process. It employs strong text and transformed contour guidance with fixed strengths in the early-to-mid sampling stages to establish overall scene, style, and structure. In the final sampling stages, HiGFA activates a specialized fine-grained classifier guidance and dynamically modulates the strength of all guidance signals based on prediction confidence. This hierarchical, confidence-driven orchestration enables HiGFA to generate diverse yet faithful synthetic images by intelligently balancing global structure formation with precise detail refinement. Experiments on several FGVC datasets demonstrate the effectiveness of HiGFA.

</details>


### [99] [EmoVerse: A MLLMs-Driven Emotion Representation Dataset for Interpretable Visual Emotion Analysis](https://arxiv.org/abs/2511.12554)
*Yijie Guo,Dexiang Hong,Weidong Chen,Zihan She,Cheng Ye,Xiaojun Chang,Zhendong Mao*

Main category: cs.CV

TL;DR: EmoVerse是一个大规模开源数据集，通过多层级、知识图谱启发的标注实现可解释的视觉情感分析，包含超过21.9万张图像，支持离散和连续情感表示。


<details>
  <summary>Details</summary>
Motivation: 现有视觉情感分析研究缺乏开源和可解释的数据集，大多数研究仅给整张图像分配单一离散情感标签，无法揭示视觉元素如何贡献于情感。

Method: 通过将情感分解为背景-属性-主体三元组并将每个元素定位到视觉区域，采用多阶段标注流程确保高可靠性，并引入可解释模型将视觉线索映射到维度情感空间。

Result: 构建了包含219k+图像的大规模数据集，提供类别情感状态和维度情感空间的双重标注，支持词级和主体级情感推理。

Conclusion: EmoVerse数据集、标注流程和模型共同为推进可解释的高层情感理解提供了全面基础。

Abstract: Visual Emotion Analysis (VEA) aims to bridge the affective gap between visual content and human emotional responses. Despite its promise, progress in this field remains limited by the lack of open-source and interpretable datasets. Most existing studies assign a single discrete emotion label to an entire image, offering limited insight into how visual elements contribute to emotion. In this work, we introduce EmoVerse, a large-scale open-source dataset that enables interpretable visual emotion analysis through multi-layered, knowledge-graph-inspired annotations. By decomposing emotions into Background-Attribute-Subject (B-A-S) triplets and grounding each element to visual regions, EmoVerse provides word-level and subject-level emotional reasoning. With over 219k images, the dataset further includes dual annotations in Categorical Emotion States (CES) and Dimensional Emotion Space (DES), facilitating unified discrete and continuous emotion representation. A novel multi-stage pipeline ensures high annotation reliability with minimal human effort. Finally, we introduce an interpretable model that maps visual cues into DES representations and provides detailed attribution explanations. Together, the dataset, pipeline, and model form a comprehensive foundation for advancing explainable high-level emotion understanding.

</details>


### [100] [SEMC: Structure-Enhanced Mixture-of-Experts Contrastive Learning for Ultrasound Standard Plane Recognition](https://arxiv.org/abs/2511.12559)
*Qing Cai,Guihao Yan,Fan Zhang,Cheng Zhang,Zhi Liu*

Main category: cs.CV

TL;DR: 本文提出SEMC框架，结合结构感知特征融合与专家引导对比学习，解决超声标准平面识别中浅层结构信息利用不足和细粒度语义差异捕获困难的问题，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效利用浅层结构信息，且难以通过图像增强生成的对比样本捕获细粒度语义差异，导致超声标准平面识别中结构和判别细节识别效果不佳。

Method: 提出SEMC框架：1）语义结构融合模块(SSFM)利用多尺度结构信息，对齐浅层和深层特征；2）专家混合对比识别模块(MCRM)使用MoE机制在多级特征上进行分层对比学习和分类。

Result: 在内部数据集和两个公共数据集上的广泛实验表明，SEMC在各种指标上均优于现有最先进方法。

Conclusion: SEMC框架通过结构增强和专家混合对比学习，显著提升了超声标准平面识别的性能，证明了该方法的有效性。

Abstract: Ultrasound standard plane recognition is essential for clinical tasks such as disease screening, organ evaluation, and biometric measurement. However, existing methods fail to effectively exploit shallow structural information and struggle to capture fine-grained semantic differences through contrastive samples generated by image augmentations, ultimately resulting in suboptimal recognition of both structural and discriminative details in ultrasound standard planes. To address these issues, we propose SEMC, a novel Structure-Enhanced Mixture-of-Experts Contrastive learning framework that combines structure-aware feature fusion with expert-guided contrastive learning. Specifically, we first introduce a novel Semantic-Structure Fusion Module (SSFM) to exploit multi-scale structural information and enhance the model's ability to perceive fine-grained structural details by effectively aligning shallow and deep features. Then, a novel Mixture-of-Experts Contrastive Recognition Module (MCRM) is designed to perform hierarchical contrastive learning and classification across multi-level features using a mixture-of-experts (MoE) mechanism, further improving class separability and recognition performance. More importantly, we also curate a large-scale and meticulously annotated liver ultrasound dataset containing six standard planes. Extensive experimental results on our in-house dataset and two public datasets demonstrate that SEMC outperforms recent state-of-the-art methods across various metrics.

</details>


### [101] [Through-Foliage Surface-Temperature Reconstruction for early Wildfire Detection](https://arxiv.org/abs/2511.12572)
*Mohamed Youssef,Lukas Brunner,Klaus Rundhammer,Gerald Czech,Oliver Bimber*

Main category: cs.CV

TL;DR: 提出了一种结合信号处理和机器学习的新方法，用于通过遮挡的森林植被重建地表温度，实现无人机自主监测野火，在烟雾或火焰可见前早期检测地面火灾。


<details>
  <summary>Details</summary>
Motivation: 实现无人机自主监测野火，在烟雾或火焰可见前早期检测地面火灾。合成孔径感知虽然减轻了树冠和阳光的遮挡，但引入了热模糊，掩盖了实际地表温度。

Method: 训练视觉状态空间模型从模糊数据中恢复部分遮挡土壤和火灾热点的细微热信号。通过潜在扩散模型和向量量化生成大量真实地表温度模拟数据，结合温度增强和程序化热森林模拟来克服真实训练数据稀缺问题。

Result: 在不同环境温度、地表温度、森林密度和阳光条件下的模拟数据上，该方法将RMSE降低了2到2.5倍。在高温热点现场实验中，改进更为显著，与传统热成像相比RMSE增益达12.8倍，与未校正SA图像相比增益达2.6倍。

Conclusion: 该方法不仅能重建火灾和人体特征的完整形态，还能推广到其他热信号应用，如搜救中的人体特征检测，而传统成像方法在部分遮挡情况下会失效。

Abstract: We introduce a novel method for reconstructing surface temperatures through occluding forest vegetation by combining signal processing and machine learning. Our goal is to enable fully automated aerial wildfire monitoring using autonomous drones, allowing for the early detection of ground fires before smoke or flames are visible. While synthetic aperture (SA) sensing mitigates occlusion from the canopy and sunlight, it introduces thermal blur that obscures the actual surface temperatures. To address this, we train a visual state space model to recover the subtle thermal signals of partially occluded soil and fire hotspots from this blurred data. A key challenge was the scarcity of real-world training data. We overcome this by integrating a latent diffusion model into a vector quantized to generated a large volume of realistic surface temperature simulations from real wildfire recordings, which we further expanded through temperature augmentation and procedural thermal forest simulation. On simulated data across varied ambient and surface temperatures, forest densities, and sunlight conditions, our method reduced the RMSE by a factor of 2 to 2.5 compared to conventional thermal and uncorrected SA imaging. In field experiments focused on high-temperature hotspots, the improvement was even more significant, with a 12.8-fold RMSE gain over conventional thermal and a 2.6-fold gain over uncorrected SA images. We also demonstrate our model's generalization to other thermal signals, such as human signatures for search and rescue. Since simple thresholding is frequently inadequate for detecting subtle thermal signals, the morphological characteristics are equally essential for accurate classification. Our experiments demonstrated another clear advantage: we reconstructed the complete morphology of fire and human signatures, whereas conventional imaging is defeated by partial occlusion.

</details>


### [102] [Beyond Pixels: Semantic-aware Typographic Attack for Geo-Privacy Protection](https://arxiv.org/abs/2511.12575)
*Jiayi Zhu,Yihao Huang,Yue Cao,Xiaojun Jia,Qing Guo,Felix Juefei-Xu,Geguang Pu,Bin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于文本攻击的地理隐私保护方法，通过在图像外部添加欺骗性文本来干扰大型视觉语言模型的地理位置推断，相比传统对抗性扰动能更好地保持图像视觉质量。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型能够从社交媒体图像中推断用户地理位置，造成严重的隐私泄露风险。现有的对抗性图像扰动方法需要强失真才能有效保护隐私，但会显著降低图像视觉质量。

Method: 采用两阶段语义感知的文本攻击方法，在图像视觉内容外部添加欺骗性文本，研究有效的文本语义来干扰地理位置推断。

Result: 在三个数据集上的广泛实验表明，该方法显著降低了五种最先进商业LVLMs的地理位置预测准确率。

Conclusion: 该方法建立了一种实用且视觉保持的地理隐私保护策略，有效应对新兴的地理隐私威胁。

Abstract: Large Visual Language Models (LVLMs) now pose a serious yet overlooked privacy threat, as they can infer a social media user's geolocation directly from shared images, leading to unintended privacy leakage. While adversarial image perturbations provide a potential direction for geo-privacy protection, they require relatively strong distortions to be effective against LVLMs, which noticeably degrade visual quality and diminish an image's value for sharing. To overcome this limitation, we identify typographical attacks as a promising direction for protecting geo-privacy by adding text extension outside the visual content. We further investigate which textual semantics are effective in disrupting geolocation inference and design a two-stage, semantics-aware typographical attack that generates deceptive text to protect user privacy. Extensive experiments across three datasets demonstrate that our approach significantly reduces geolocation prediction accuracy of five state-of-the-art commercial LVLMs, establishing a practical and visually-preserving protection strategy against emerging geo-privacy threats.

</details>


### [103] [TempoMaster: Efficient Long Video Generation via Next-Frame-Rate Prediction](https://arxiv.org/abs/2511.12578)
*Yukuo Ma,Cong Liu,Junke Wang,Junqi Liu,Haibin Huang,Zuxuan Wu,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TempoMaster是一个新颖的长视频生成框架，将长视频生成建模为下一帧率预测任务，通过从低帧率到高帧率的渐进式生成实现高效并行合成。


<details>
  <summary>Details</summary>
Motivation: 解决长视频生成中保持长时间一致性同时实现高效并行合成的挑战。

Method: 首先生成低帧率视频作为粗粒度蓝图，然后逐步提高帧率来细化视觉细节和运动连续性；在每帧率级别使用双向注意力，在帧率间进行自回归。

Result: 在广泛实验中，TempoMaster在长视频生成方面建立了新的最先进水平，在视觉和时间质量方面都表现出色。

Conclusion: TempoMaster通过下一帧率预测的框架设计，成功实现了长视频的高质量生成，在保持长时间一致性的同时实现了高效并行合成。

Abstract: We present TempoMaster, a novel framework that formulates long video generation as next-frame-rate prediction. Specifically, we first generate a low-frame-rate clip that serves as a coarse blueprint of the entire video sequence, and then progressively increase the frame rate to refine visual details and motion continuity. During generation, TempoMaster employs bidirectional attention within each frame-rate level while performing autoregression across frame rates, thus achieving long-range temporal coherence while enabling efficient and parallel synthesis. Extensive experiments demonstrate that TempoMaster establishes a new state-of-the-art in long video generation, excelling in both visual and temporal quality.

</details>


### [104] [Rank-Aware Agglomeration of Foundation Models for Immunohistochemistry Image Cell Counting](https://arxiv.org/abs/2511.12588)
*Zuqi Huang,Mengxin Tian,Huan Liu,Wentao Li,Baobao Liang,Jie Wu,Fang Yan,Zhaoqing Tang,Zhongyu Li*

Main category: cs.CV

TL;DR: 提出CountIHC框架，通过排名感知的教师选择策略和多模态微调，实现IHC图像中多类细胞的高精度计数。


<details>
  <summary>Details</summary>
Motivation: 解决IHC图像中细胞计数面临的染色重叠、生物标记物变异和细胞形态多样性等挑战，探索基础模型在回归计数范式中的潜力。

Method: 采用排名感知的聚合框架，设计RATS策略进行样本级教师选择，并通过视觉语言对齐进行多类细胞计数微调。

Result: 在12种IHC生物标记物和5种组织类型上超越现有方法，与病理学家评估高度一致，在H&E染色数据上也表现良好。

Conclusion: CountIHC框架有效解决了IHC图像多类细胞计数问题，具有良好的可扩展性和实用性。

Abstract: Accurate cell counting in immunohistochemistry (IHC) images is critical for quantifying protein expression and aiding cancer diagnosis. However, the task remains challenging due to the chromogen overlap, variable biomarker staining, and diverse cellular morphologies. Regression-based counting methods offer advantages over detection-based ones in handling overlapped cells, yet rarely support end-to-end multi-class counting. Moreover, the potential of foundation models remains largely underexplored in this paradigm. To address these limitations, we propose a rank-aware agglomeration framework that selectively distills knowledge from multiple strong foundation models, leveraging their complementary representations to handle IHC heterogeneity and obtain a compact yet effective student model, CountIHC. Unlike prior task-agnostic agglomeration strategies that either treat all teachers equally or rely on feature similarity, we design a Rank-Aware Teacher Selecting (RATS) strategy that models global-to-local patch rankings to assess each teacher's inherent counting capacity and enable sample-wise teacher selection. For multi-class cell counting, we introduce a fine-tuning stage that reformulates the task as vision-language alignment. Discrete semantic anchors derived from structured text prompts encode both category and quantity information, guiding the regression of class-specific density maps and improving counting for overlapping cells. Extensive experiments demonstrate that CountIHC surpasses state-of-the-art methods across 12 IHC biomarkers and 5 tissue types, while exhibiting high agreement with pathologists' assessments. Its effectiveness on H&E-stained data further confirms the scalability of the proposed method.

</details>


### [105] [Seg-VAR: Image Segmentation with Visual Autoregressive Modeling](https://arxiv.org/abs/2511.12594)
*Rongkun Zheng,Lu Qi,Xi Chen,Yi Wang,Kun Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Seg-VAR将分割任务重新定义为条件自回归掩码生成问题，通过多尺度建模和潜在学习过程，在多个分割任务和验证基准上超越了之前的判别性和生成性方法。


<details>
  <summary>Details</summary>
Motivation: 视觉自回归建模策略在图像生成方面已取得进展，但其在需要精确低层空间感知的分割任务中的潜力尚未被探索。

Method: 提出Seg-VAR框架，包含三个核心组件：图像编码器生成潜在先验、空间感知的seglat编码器将分割掩码映射为离散潜在标记、解码器从这些潜在重建掩码。采用三阶段训练策略：首先通过图像-seglat联合训练学习seglat表示，然后精炼潜在变换，最后对齐图像编码器导出的潜在与seglat分布。

Result: 实验表明Seg-VAR在各种分割任务和验证基准上超越了之前的判别性和生成性方法。

Conclusion: 通过将分割构建为顺序层次预测任务，Seg-VAR为将自回归推理集成到空间感知视觉系统中开辟了新途径。

Abstract: While visual autoregressive modeling (VAR) strategies have shed light on image generation with the autoregressive models, their potential for segmentation, a task that requires precise low-level spatial perception, remains unexplored. Inspired by the multi-scale modeling of classic Mask2Former-based models, we propose Seg-VAR, a novel framework that rethinks segmentation as a conditional autoregressive mask generation problem. This is achieved by replacing the discriminative learning with the latent learning process. Specifically, our method incorporates three core components: (1) an image encoder generating latent priors from input images, (2) a spatial-aware seglat (a latent expression of segmentation mask) encoder that maps segmentation masks into discrete latent tokens using a location-sensitive color mapping to distinguish instances, and (3) a decoder reconstructing masks from these latents. A multi-stage training strategy is introduced: first learning seglat representations via image-seglat joint training, then refining latent transformations, and finally aligning image-encoder-derived latents with seglat distributions. Experiments show Seg-VAR outperforms previous discriminative and generative methods on various segmentation tasks and validation benchmarks. By framing segmentation as a sequential hierarchical prediction task, Seg-VAR opens new avenues for integrating autoregressive reasoning into spatial-aware vision systems. Code will be available at https://github.com/rkzheng99/Seg-VAR.

</details>


### [106] [LoRA-Enhanced Vision Transformer for Single Image based Morphing Attack Detection via Knowledge Distillation from EfficientNet](https://arxiv.org/abs/2511.12602)
*Ria Shekhawat,Sushrut Patwardhan,Raghavendra Ramachandra,Praveen Kumar Chandaliya,Kishor P. Upla*

Main category: cs.CV

TL;DR: 提出一种基于师生框架的单图像形态攻击检测方法，结合CNN教师模型和ViT学生模型，使用LoRA微调提高效率，在包含10种形态生成算法的数据集上验证了优越的检测性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统对安全至关重要，但容易受到形态攻击的威胁，其中合成图像融合了多个个体的生物特征，需要开发有效的单图像检测方法。

Method: 采用师生框架，CNN教师模型指导ViT学生模型，集成低秩适应（LoRA）进行微调以降低计算成本，在三个公开人脸数据集构建的形态数据集上进行实验。

Result: 在包含10种不同形态生成算法的数据集上，与6种最先进的S-MAD技术相比，该方法展示了优越的检测性能和计算效率。

Conclusion: 所提出的师生框架结合LoRA微调的单图像形态攻击检测方法，在保持高检测精度的同时显著提高了计算效率，为人脸识别系统的安全防护提供了有效解决方案。

Abstract: Face Recognition Systems (FRS) are critical for security but remain vulnerable to morphing attacks, where synthetic images blend biometric features from multiple individuals. We propose a novel Single-Image Morphing Attack Detection (S-MAD) approach using a teacher-student framework, where a CNN-based teacher model refines a ViT-based student model. To improve efficiency, we integrate Low-Rank Adaptation (LoRA) for fine-tuning, reducing computational costs while maintaining high detection accuracy. Extensive experiments are conducted on a morphing dataset built from three publicly available face datasets, incorporating ten different morphing generation algorithms to assess robustness. The proposed method is benchmarked against six state-of-the-art S-MAD techniques, demonstrating superior detection performance and computational efficiency.

</details>


### [107] [OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding](https://arxiv.org/abs/2511.12614)
*Artem Moroz,Vít Zeman,Martin Mikšík,Elizaveta Isianova,Miroslav David,Pavel Burget,Varun Burde*

Main category: cs.CV

TL;DR: 本文提出了一个统一的端到端框架，将物体检测和姿态估计与灵活的onboarding过程相结合。系统支持从3D CAD模型或通过多视角图像重建神经表示来生成物体表示，使用CNOS检测器定位目标物体，并通过新型姿态估计模块OPFormer推断精确的6D姿态。


<details>
  <summary>Details</summary>
Motivation: 为了解决物体检测和姿态估计在模型可用和不可用场景下的统一处理问题，开发一个既能处理传统3D模型又能从图像重建物体表示的灵活系统。

Method: 1. onboarding阶段：从3D CAD模型或通过多视角图像重建NeRF生成物体表示
2. 检测阶段：使用CNOS检测器定位目标物体
3. 姿态估计：OPFormer模块采用transformer架构，结合基础模型特征提取，联合编码多个模板视图，并使用NOCS增强3D几何先验，通过解码器建立2D-3D对应关系确定最终姿态

Result: 在具有挑战性的BOP基准测试中，集成系统在准确性和效率之间表现出良好的平衡，展示了在模型基和无模型场景中的实际适用性。

Conclusion: 该框架提供了一个统一的解决方案，能够灵活处理不同物体表示来源的场景，在保持高精度的同时具备良好的实用性。

Abstract: We introduce a unified, end-to-end framework that seamlessly integrates object detection and pose estimation with a versatile onboarding process. Our pipeline begins with an onboarding stage that generates object representations from either traditional 3D CAD models or, in their absence, by rapidly reconstructing a high-fidelity neural representation (NeRF) from multi-view images. Given a test image, our system first employs the CNOS detector to localize target objects. For each detection, our novel pose estimation module, OPFormer, infers the precise 6D pose. The core of OPFormer is a transformer-based architecture that leverages a foundation model for robust feature extraction. It uniquely learns a comprehensive object representation by jointly encoding multiple template views and enriches these features with explicit 3D geometric priors using Normalized Object Coordinate Space (NOCS). A decoder then establishes robust 2D-3D correspondences to determine the final pose. Evaluated on the challenging BOP benchmarks, our integrated system demonstrates a strong balance between accuracy and efficiency, showcasing its practical applicability in both model-based and model-free scenarios.

</details>


### [108] [C3Net: Context-Contrast Network for Camouflaged Object Detection](https://arxiv.org/abs/2511.12627)
*Baber Jan,Aiman H. El-Maleh,Abdul Jabbar Siddiqui,Abdul Bais,Saeed Anwar*

Main category: cs.CV

TL;DR: C3Net提出了一种专门的双路径解码器架构来解决伪装目标检测中的六大挑战，通过边缘细化路径和上下文定位路径的协同工作，在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 伪装目标检测面临传统分割方法和现代基础模型的失败，主要由于伪装目标与背景在颜色、纹理和模式上的高度相似性，需要专门的架构解决方案。

Method: 提出C3Net双路径解码器架构：边缘细化路径使用梯度初始化边缘增强模块恢复精确边界；上下文定位路径采用基于图像的上下文引导机制实现内在显著性抑制；通过注意力融合模块协同结合两条路径。

Result: 在COD10K数据集上S-measure达到0.898，CAMO数据集0.904，NC4K数据集0.913，实现了最先进的性能，同时保持高效处理。

Conclusion: C3Net证明复杂多方面的检测挑战需要架构创新，专门组件协同工作能够实现超越孤立改进的全面覆盖，为伪装目标检测提供了有效的解决方案。

Abstract: Camouflaged object detection identifies objects that blend seamlessly with their surroundings through similar colors, textures, and patterns. This task challenges both traditional segmentation methods and modern foundation models, which fail dramatically on camouflaged objects. We identify six fundamental challenges in COD: Intrinsic Similarity, Edge Disruption, Extreme Scale Variation, Environmental Complexities, Contextual Dependencies, and Salient-Camouflaged Object Disambiguation. These challenges frequently co-occur and compound the difficulty of detection, requiring comprehensive architectural solutions. We propose C3Net, which addresses all challenges through a specialized dual-pathway decoder architecture. The Edge Refinement Pathway employs gradient-initialized Edge Enhancement Modules to recover precise boundaries from early features. The Contextual Localization Pathway utilizes our novel Image-based Context Guidance mechanism to achieve intrinsic saliency suppression without external models. An Attentive Fusion Module synergistically combines the two pathways via spatial gating. C3Net achieves state-of-the-art performance with S-measures of 0.898 on COD10K, 0.904 on CAMO, and 0.913 on NC4K, while maintaining efficient processing. C3Net demonstrates that complex, multifaceted detection challenges require architectural innovation, with specialized components working synergistically to achieve comprehensive coverage beyond isolated improvements. Code, model weights, and results are available at https://github.com/Baber-Jan/C3Net.

</details>


### [109] [Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation](https://arxiv.org/abs/2511.12631)
*Yushe Cao,Dianxi Shi,Xing Fu,Xuechao Zou,Haikuo Peng,Xueqi Li,Chun Yu,Junliang Xing*

Main category: cs.CV

TL;DR: MDiTFace是一个基于扩散变换器的多模态人脸生成框架，通过统一的标记化策略处理语义掩码和文本输入，使用多元变换器块实现跨模态交互，并设计了分离注意力机制来减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统多模态特征融合方法在语义掩码和文本描述的人脸生成中，难以实现有效的跨模态交互，导致生成效果不理想。

Method: 采用统一的标记化策略处理异质模态输入，使用堆叠的多元变换器块同步处理所有条件，并设计分离注意力机制将内部计算分为动态和静态路径以减少计算开销。

Result: 实验表明MDiTFace在面部保真度和条件一致性方面显著优于其他竞争方法，同时将掩码条件引入的额外计算开销减少了94%以上。

Conclusion: MDiTFace通过创新的统一标记化和分离注意力机制，有效解决了多模态人脸生成中的跨模态交互问题，在保持性能的同时大幅降低了计算成本。

Abstract: While significant progress has been achieved in multimodal facial generation using semantic masks and textual descriptions, conventional feature fusion approaches often fail to enable effective cross-modal interactions, thereby leading to suboptimal generation outcomes. To address this challenge, we introduce MDiTFace--a customized diffusion transformer framework that employs a unified tokenization strategy to process semantic mask and text inputs, eliminating discrepancies between heterogeneous modality representations. The framework facilitates comprehensive multimodal feature interaction through stacked, newly designed multivariate transformer blocks that process all conditions synchronously. Additionally, we design a novel decoupled attention mechanism by dissociating implicit dependencies between mask tokens and temporal embeddings. This mechanism segregates internal computations into dynamic and static pathways, enabling caching and reuse of features computed in static pathways after initial calculation, thereby reducing additional computational overhead introduced by mask condition by over 94% while maintaining performance. Extensive experiments demonstrate that MDiTFace significantly outperforms other competing methods in terms of both facial fidelity and conditional consistency.

</details>


### [110] [Denoising Vision Transformer Autoencoder with Spectral Self-Regularization](https://arxiv.org/abs/2511.12633)
*Xunzhi Xiang,Xingye Tian,Guiyu Zhang,Yabo Chen,Shaofeng Zhang,Xuebo Wang,Xin Tao,Qi Fan*

Main category: cs.CV

TL;DR: 该论文分析了高维VAE潜在空间中冗余高频分量对扩散模型训练收敛的负面影响，提出了Denoising-VAE来抑制高频噪声，实现了更快的收敛速度和更好的生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统VAE在高维潜在空间中存在优化困境：高维度提升重建质量但损害生成性能。现有方法依赖外部视觉基础模型进行正则化，但高维潜在空间如何影响生成模型优化仍不明确。

Method: 提出光谱自正则化策略来抑制冗余高频噪声同时保持重建质量，开发了不依赖VFMs的Denoising-VAE，并引入光谱对齐策略来优化基于Denoising-VAE的生成模型。

Result: 在ImageNet 256×256基准上，扩散模型收敛速度比SD-VAE快约2倍，达到最先进的重建质量（rFID=0.28，PSNR=27.26）和竞争性生成性能（gFID=1.82）。

Conclusion: Denoising-VAE通过抑制高维潜在空间中的冗余高频噪声，有效解决了VAE的优化困境，显著提升了扩散模型的训练效率和生成质量。

Abstract: Variational autoencoders (VAEs) typically encode images into a compact latent space, reducing computational cost but introducing an optimization dilemma: a higher-dimensional latent space improves reconstruction fidelity but often hampers generative performance. Recent methods attempt to address this dilemma by regularizing high-dimensional latent spaces using external vision foundation models (VFMs). However, it remains unclear how high-dimensional VAE latents affect the optimization of generative models. To our knowledge, our analysis is the first to reveal that redundant high-frequency components in high-dimensional latent spaces hinder the training convergence of diffusion models and, consequently, degrade generation quality. To alleviate this problem, we propose a spectral self-regularization strategy to suppress redundant high-frequency noise while simultaneously preserving reconstruction quality. The resulting Denoising-VAE, a ViT-based autoencoder that does not rely on VFMs, produces cleaner, lower-noise latents, leading to improved generative quality and faster optimization convergence. We further introduce a spectral alignment strategy to facilitate the optimization of Denoising-VAE-based generative models. Our complete method enables diffusion models to converge approximately 2$\times$ faster than with SD-VAE, while achieving state-of-the-art reconstruction quality (rFID = 0.28, PSNR = 27.26) and competitive generation performance (gFID = 1.82) on the ImageNet 256$\times$256 benchmark.

</details>


### [111] [Medical Knowledge Intervention Prompt Tuning for Medical Image Classification](https://arxiv.org/abs/2511.12639)
*Ye Du,Nanxi Yu,Shujun Wang*

Main category: cs.CV

TL;DR: CILMP是一种将大型语言模型(LLMs)集成到视觉语言模型(VLMs)提示调优中的方法，通过提取疾病特定表示并在低秩线性子空间中进行干预，生成疾病特定提示，在医学图像分类任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有提示调优方法无法精确区分不同类型的医学概念，缺乏特定疾病相关特征。大型语言模型(LLMs)在提供专业医学知识方面表现出色，因此将其集成到提示调优过程中以增强医学图像分类性能。

Method: 提出CILMP方法：从LLMs提取疾病特定表示，在低秩线性子空间中进行干预，创建疾病特定提示；引入条件机制，根据每个医学图像生成实例自适应提示。

Result: 在多个医学图像数据集上的广泛实验表明，CILMP始终优于最先进的提示调优方法，证明了其有效性。

Conclusion: CILMP成功地将LLMs与VLMs桥接，促进了医学知识向VLM提示的转移，显著提升了医学图像分类任务的性能。

Abstract: Vision-language foundation models (VLMs) have shown great potential in feature transfer and generalization across a wide spectrum of medical-related downstream tasks. However, fine-tuning these models is resource-intensive due to their large number of parameters. Prompt tuning has emerged as a viable solution to mitigate memory usage and reduce training time while maintaining competitive performance. Nevertheless, the challenge is that existing prompt tuning methods cannot precisely distinguish different kinds of medical concepts, which miss essentially specific disease-related features across various medical imaging modalities in medical image classification tasks. We find that Large Language Models (LLMs), trained on extensive text corpora, are particularly adept at providing this specialized medical knowledge. Motivated by this, we propose incorporating LLMs into the prompt tuning process. Specifically, we introduce the CILMP, Conditional Intervention of Large Language Models for Prompt Tuning, a method that bridges LLMs and VLMs to facilitate the transfer of medical knowledge into VLM prompts. CILMP extracts disease-specific representations from LLMs, intervenes within a low-rank linear subspace, and utilizes them to create disease-specific prompts. Additionally, a conditional mechanism is incorporated to condition the intervention process on each individual medical image, generating instance-adaptive prompts and thus enhancing adaptability. Extensive experiments across diverse medical image datasets demonstrate that CILMP consistently outperforms state-of-the-art prompt tuning methods, demonstrating its effectiveness. Code is available at https://github.com/usr922/cilmp.

</details>


### [112] [DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry](https://arxiv.org/abs/2511.12653)
*Cheng Liao*

Main category: cs.CV

TL;DR: DPVO-QAT++是一个层次化量化优化框架，通过可学习尺度参数化、VO前后端异构精度设计（前端FP16/FP32伪量化，后端全精度）和GPU原生核融合技术，在保持轨迹精度的同时显著降低内存占用并提升处理速度。


<details>
  <summary>Details</summary>
Motivation: 深度学习视觉SLAM系统具有出色的几何推理能力，但其过高的计算开销严重限制了在资源受限自主平台上的部署。

Method: 采用可学习尺度参数化、异构精度设计（前端浮点伪量化，后端全精度）和GPU原生核融合技术，开发了层次化量化优化框架DPVO-QAT++。

Result: 在TartanAir数据集上平均FPS提升52.1%，中位延迟降低29.1%，峰值GPU内存占用减少64.9%；在EuRoC数据集上平均FPS提升30.1%，中位延迟降低23.1%，峰值GPU内存占用减少37.7%，同时保持与原始模型相当的轨迹精度。

Conclusion: DPVO-QAT++有效弥合了高精度深度VO与实际部署效率需求之间的差距，为在真实嵌入式平台上的应用提供了可行的工程范式。

Abstract: Deep learning-based Visual SLAM (vSLAM) systems exhibit exceptional geometric reasoning capabilities, yet their prohibitive computational overhead severely restricts deployment on resource-constrained autonomous platforms. This paper presents a hierarchical quantization optimization framework, DPVO-QAT++ (DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry). Through the synergistic integration of learnable scale parameterization, a heterogeneous precision design for the Visual Odometry (VO) front-end and back-end (front-end floating-point fake quantization with FP16/FP32; back-end full precision), and GPU-native kernel fusion for fake quantization (custom CUDA kernels), our framework significantly reduces memory footprint and increases processing speed while preserving the trajectory accuracy of the original model. On the TartanAir dataset, our framework achieves an average FPS increase of 52.1%, a 29.1% reduction in median latency, and a 64.9% reduction in peak GPU memory reservation, while maintaining trajectory accuracy (ATE) comparable to the original DPVO model across 32 validation sequences. On the EuRoC dataset, it realizes an average FPS increase of 30.1%, a 23.1% reduction in median latency, and a 37.7% reduction in peak GPU memory reservation, maintaining comparable trajectory accuracy (ATE) across 11 validation sequences. Experimental results demonstrate that DPVO-QAT++ effectively bridges the gap between high-precision deep VO and the efficiency requirements for practical deployment, offering a viable engineering paradigm for the application of this technology on real-world embedded platforms.
  Keywords: Visual Odometry, Heterogeneous Precision Architecture, Quantization-Aware Training, CUDA Kernel Fusion, Scale-Only Training, Deep Patch Visual Odometry, GPU-Native Kernel Fusion.

</details>


### [113] [Toward Real-world Text Image Forgery Localization: Structured and Interpretable Data Synthesis](https://arxiv.org/abs/2511.12658)
*Zeqin Yu,Haotao Xie,Jian Zhang,Jiangqun Ni,Wenkan Su,Jiwu Huang*

Main category: cs.CV

TL;DR: 提出FSTS框架，通过傅里叶级数启发的分层建模方法合成篡改文本图像，解决现有T-IFL方法因合成数据与真实篡改分布差异导致的泛化能力差问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本图像伪造定位方法泛化能力差，主要原因是真实世界数据集规模有限，且合成数据无法捕捉真实篡改的复杂性，导致分布差异。

Method: 收集16,750个真实篡改实例，通过结构化流水线记录人类编辑痕迹，建立分层建模框架：个体层面用基操作-参数配置组合表示篡改参数，群体层面聚合这些行为构建分布，基于傅里叶级数思想进行可解释逼近。

Result: 在四个评估协议上的广泛实验表明，使用FSTS数据训练的模型在真实世界数据集上实现了显著改进的泛化能力。

Conclusion: FSTS框架能够合成多样且真实的训练数据，更好地反映真实世界伪造痕迹，有效提升文本图像伪造定位模型的泛化性能。

Abstract: Existing Text Image Forgery Localization (T-IFL) methods often suffer from poor generalization due to the limited scale of real-world datasets and the distribution gap caused by synthetic data that fails to capture the complexity of real-world tampering. To tackle this issue, we propose Fourier Series-based Tampering Synthesis (FSTS), a structured and interpretable framework for synthesizing tampered text images. FSTS first collects 16,750 real-world tampering instances from five representative tampering types, using a structured pipeline that records human-performed editing traces via multi-format logs (e.g., video, PSD, and editing logs). By analyzing these collected parameters and identifying recurring behavioral patterns at both individual and population levels, we formulate a hierarchical modeling framework. Specifically, each individual tampering parameter is represented as a compact combination of basis operation-parameter configurations, while the population-level distribution is constructed by aggregating these behaviors. Since this formulation draws inspiration from the Fourier series, it enables an interpretable approximation using basis functions and their learned weights. By sampling from this modeled distribution, FSTS synthesizes diverse and realistic training data that better reflect real-world forgery traces. Extensive experiments across four evaluation protocols demonstrate that models trained with FSTS data achieve significantly improved generalization on real-world datasets. Dataset is available at \href{https://github.com/ZeqinYu/FSTS}{Project Page}.

</details>


### [114] [Hi-Reco: High-Fidelity Real-Time Conversational Digital Humans](https://arxiv.org/abs/2511.12662)
*Hongbin Huang,Junwei Li,Tianxin Xie,Zhuang Li,Cekai Weng,Yaodong Yang,Yue Luo,Li Liu,Jing Tang,Zhijing Shao,Zeyu Wang*

Main category: cs.CV

TL;DR: 提出了一种高保真、实时的对话数字人系统，结合了视觉逼真的3D虚拟形象、人物驱动的表达性语音合成和基于知识的对话生成，通过异步执行管道实现低延迟多模态协调。


<details>
  <summary>Details</summary>
Motivation: 当前高保真数字人类在交互应用中面临视觉真实性与实时响应性难以兼顾的挑战，需要开发既能保持视觉逼真度又能实现实时交互的系统。

Method: 采用异步执行管道协调多模态组件，结合唤醒词检测、情感表达韵律和上下文感知响应生成，利用检索增强方法包括历史增强和基于意图的路由进行高效知识访问。

Result: 开发了一个集成系统，支持响应迅速且可信的数字人类，适用于通信、教育和娱乐等沉浸式应用场景。

Conclusion: 该系统成功实现了高保真数字人类在视觉真实性和实时交互性方面的平衡，为沉浸式应用提供了可行的解决方案。

Abstract: High-fidelity digital humans are increasingly used in interactive applications, yet achieving both visual realism and real-time responsiveness remains a major challenge. We present a high-fidelity, real-time conversational digital human system that seamlessly combines a visually realistic 3D avatar, persona-driven expressive speech synthesis, and knowledge-grounded dialogue generation. To support natural and timely interaction, we introduce an asynchronous execution pipeline that coordinates multi-modal components with minimal latency. The system supports advanced features such as wake word detection, emotionally expressive prosody, and highly accurate, context-aware response generation. It leverages novel retrieval-augmented methods, including history augmentation to maintain conversational flow and intent-based routing for efficient knowledge access. Together, these components form an integrated system that enables responsive and believable digital humans, suitable for immersive applications in communication, education, and entertainment.

</details>


### [115] [DensePercept-NCSSD: Vision Mamba towards Real-time Dense Visual Perception with Non-Causal State Space Duality](https://arxiv.org/abs/2511.12671)
*Tushar Anand,Advik Sinha,Abhijit Das*

Main category: cs.CV

TL;DR: 提出了一种基于非因果选择性状态空间的实时光学流和视差估计模型，用于密集感知任务


<details>
  <summary>Details</summary>
Motivation: 解决实时应用中光学流和视差估计的高精度与低延迟需求之间的矛盾

Method: 使用非因果Mamba块融合成对输入图像，构建快速高效的密集感知模型

Result: 模型在保持高精度的同时显著减少推理时间，降低GPU使用率

Conclusion: 该模型适用于统一的实时高精度3D密集感知估计任务

Abstract: In this work, we propose an accurate and real-time optical flow and disparity estimation model by fusing pairwise input images in the proposed non-causal selective state space for dense perception tasks. We propose a non-causal Mamba block-based model that is fast and efficient and aptly manages the constraints present in a real-time applications. Our proposed model reduces inference times while maintaining high accuracy and low GPU usage for optical flow and disparity map generation. The results and analysis, and validation in real-life scenario justify that our proposed model can be used for unified real-time and accurate 3D dense perception estimation tasks. The code, along with the models, can be found at https://github.com/vimstereo/DensePerceptNCSSD

</details>


### [116] [R$^{2}$Seg: Training-Free OOD Medical Tumor Segmentation via Anatomical Reasoning and Statistical Rejection](https://arxiv.org/abs/2511.12691)
*Shuaike Shen,Ke Liu,Jiaqing Xie,Shangde Gao,Chunhua Shen,Ge Liu,Mireia Crispin-Ortuzar,Shangqi Gao*

Main category: cs.CV

TL;DR: R²Seg是一个无需训练的鲁棒OOD肿瘤分割框架，通过两阶段推理-拒绝过程处理分布外肿瘤分割问题，显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割基础模型在分布外偏移下表现不佳，容易产生碎片化假阳性结果，需要一种无需训练就能提升OOD肿瘤分割鲁棒性的方法。

Method: 采用两阶段方法：1）推理阶段使用LLM引导的解剖推理规划器定位器官锚点并生成多尺度ROI；2）拒绝阶段对基础模型在ROI内生成的候选区域应用双样本统计测试，仅保留与正常组织显著不同的候选区域。

Result: 在多中心多模态肿瘤分割基准测试中，R²Seg在Dice系数、特异性和敏感性方面显著优于强基线方法和原始基础模型。

Conclusion: R²Seg提供了一种无需参数更新的训练免费框架，能够有效抑制假阳性，提升OOD肿瘤分割的鲁棒性，同时避免灾难性遗忘问题。

Abstract: Foundation models for medical image segmentation struggle under out-of-distribution (OOD) shifts, often producing fragmented false positives on OOD tumors. We introduce R$^{2}$Seg, a training-free framework for robust OOD tumor segmentation that operates via a two-stage Reason-and-Reject process. First, the Reason step employs an LLM-guided anatomical reasoning planner to localize organ anchors and generate multi-scale ROIs. Second, the Reject step applies two-sample statistical testing to candidates generated by a frozen foundation model (BiomedParse) within these ROIs. This statistical rejection filter retains only candidates significantly different from normal tissue, effectively suppressing false positives. Our framework requires no parameter updates, making it compatible with zero-update test-time augmentation and avoiding catastrophic forgetting. On multi-center and multi-modal tumor segmentation benchmarks, R$^{2}$Seg substantially improves Dice, specificity, and sensitivity over strong baselines and the original foundation models. Code are available at https://github.com/Eurekashen/R2Seg.

</details>


### [117] [HEDGE: Hallucination Estimation via Dense Geometric Entropy for VQA with Vision-Language Models](https://arxiv.org/abs/2511.12693)
*Sushant Gautam,Michael A. Riegler,Pål Halvorsen*

Main category: cs.CV

TL;DR: HEDGE是一个统一的幻觉检测框架，通过结合受控视觉扰动、语义聚类和鲁棒不确定性度量来检测视觉语言模型的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型容易产生幻觉，需要系统化的检测方法来评估多模态可靠性。

Method: HEDGE框架整合了采样、失真合成、聚类（基于蕴含和嵌入）和度量计算，形成可复现的流水线。

Result: 评估显示幻觉可检测性在具有密集视觉标记化的统一融合模型中最高，在标记化受限的架构中最低。VASE度量与嵌入聚类结合时提供最鲁棒的幻觉信号。

Conclusion: HEDGE通过将幻觉检测构建为几何鲁棒性问题，为评估多模态可靠性提供了原则性基础，并提供了可复现的基准测试工具。

Abstract: Vision-language models (VLMs) enable open-ended visual question answering but remain prone to hallucinations. We present HEDGE, a unified framework for hallucination detection that combines controlled visual perturbations, semantic clustering, and robust uncertainty metrics. HEDGE integrates sampling, distortion synthesis, clustering (entailment- and embedding-based), and metric computation into a reproducible pipeline applicable across multimodal architectures.
  Evaluations on VQA-RAD and KvasirVQA-x1 with three representative VLMs (LLaVA-Med, Med-Gemma, Qwen2.5-VL) reveal clear architecture- and prompt-dependent trends. Hallucination detectability is highest for unified-fusion models with dense visual tokenization (Qwen2.5-VL) and lowest for architectures with restricted tokenization (Med-Gemma). Embedding-based clustering often yields stronger separation when applied directly to the generated answers, whereas NLI-based clustering remains advantageous for LLaVA-Med and for longer, sentence-level responses. Across configurations, the VASE metric consistently provides the most robust hallucination signal, especially when paired with embedding clustering and a moderate sampling budget (n ~ 10-15). Prompt design also matters: concise, label-style outputs offer clearer semantic structure than syntactically constrained one-sentence responses.
  By framing hallucination detection as a geometric robustness problem shaped jointly by sampling scale, prompt structure, model architecture, and clustering strategy, HEDGE provides a principled, compute-aware foundation for evaluating multimodal reliability. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE .

</details>


### [118] [FSDAM: Few-Shot Driving Attention Modeling via Vision-Language Coupling](https://arxiv.org/abs/2511.12708)
*Kaiser Hamid,Can Cui,Khandakar Ashrafi Akbar,Ziran Wang,Nade Liang*

Main category: cs.CV

TL;DR: FSDAM是一个少样本驾驶注意力建模框架，仅需约100个标注样本即可实现联合注意力预测和描述生成，比现有方法少两个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有模型依赖大规模注视数据集，但这些数据集收集成本高且耗时。需要开发在数据受限场景下仍能有效工作的驾驶员注意力系统。

Method: 采用双路径架构，包含空间预测和描述生成两个独立模块，通过跨模态对齐保持语义一致性。

Result: 在注意力预测方面表现具有竞争力，能生成连贯且上下文感知的解释，并在多个驾驶基准测试中展现出强大的零样本泛化能力。

Conclusion: 证明了在有限监督下实现有效的注意力条件生成是可行的，为在数据受限场景中部署可解释的驾驶员注意力系统开辟了新可能。

Abstract: Understanding where drivers look and why they shift their attention is essential for autonomous systems that read human intent and justify their actions. Most existing models rely on large-scale gaze datasets to learn these patterns; however, such datasets are labor-intensive to collect and time-consuming to curate. We present FSDAM (Few-Shot Driver Attention Modeling), a framework that achieves joint attention prediction and caption generation with approximately 100 annotated examples, two orders of magnitude fewer than existing approaches. Our approach introduces a dual-pathway architecture where separate modules handle spatial prediction and caption generation while maintaining semantic consistency through cross-modal alignment. Despite minimal supervision, FSDAM achieves competitive performance on attention prediction, generates coherent, and context-aware explanations. The model demonstrates robust zero-shot generalization across multiple driving benchmarks. This work shows that effective attention-conditioned generation is achievable with limited supervision, opening new possibilities for practical deployment of explainable driver attention systems in data-constrained scenarios.

</details>


### [119] [Backdoor Attacks on Open Vocabulary Object Detectors via Multi-Modal Prompt Tuning](https://arxiv.org/abs/2511.12735)
*Ankita Raj,Chetan Arora*

Main category: cs.CV

TL;DR: 本文首次研究开放词汇目标检测器（OVODs）的后门攻击，提出TrAP攻击方法，通过联合优化图像和文本模态的提示参数以及视觉触发器，在不重新训练基础模型权重的情况下植入后门。


<details>
  <summary>Details</summary>
Motivation: 随着OVODs在机器人、自动驾驶和监控等高风险应用中的普及，理解其安全风险变得至关重要。本文旨在揭示由提示调优引入的新攻击面。

Method: 提出TrAP（Trigger-Aware Prompt tuning）多模态后门注入策略，采用基于课程学习的训练策略逐步缩小触发器尺寸，使用轻量级可学习提示令牌植入后门。

Result: 在多个数据集上的实验表明，TrAP在对象误分类和对象消失攻击中均实现高攻击成功率，同时在下游数据集上相比零样本设置提高了干净图像性能。

Conclusion: TrAP方法能够有效植入隐藏后门，同时保持模型的泛化能力，揭示了OVODs中由提示调优引入的安全风险。

Abstract: Open-vocabulary object detectors (OVODs) unify vision and language to detect arbitrary object categories based on text prompts, enabling strong zero-shot generalization to novel concepts. As these models gain traction in high-stakes applications such as robotics, autonomous driving, and surveillance, understanding their security risks becomes crucial. In this work, we conduct the first study of backdoor attacks on OVODs and reveal a new attack surface introduced by prompt tuning. We propose TrAP (Trigger-Aware Prompt tuning), a multi-modal backdoor injection strategy that jointly optimizes prompt parameters in both image and text modalities along with visual triggers. TrAP enables the attacker to implant malicious behavior using lightweight, learnable prompt tokens without retraining the base model weights, thus preserving generalization while embedding a hidden backdoor. We adopt a curriculum-based training strategy that progressively shrinks the trigger size, enabling effective backdoor activation using small trigger patches at inference. Experiments across multiple datasets show that TrAP achieves high attack success rates for both object misclassification and object disappearance attacks, while also improving clean image performance on downstream datasets compared to the zero-shot setting.

</details>


### [120] [Direct Visual Grounding by Directing Attention of Visual Tokens](https://arxiv.org/abs/2511.12738)
*Parsa Esmaeilkhani,Longin Jan Latecki*

Main category: cs.CV

TL;DR: 论文提出了一种新的注意力监督损失函数KLAL，通过直接监督视觉标记的注意力分布来改善视觉语言模型在视觉任务中的表现，解决了现有模型在最终层对相关视觉标记关注不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型中，与查询最相关的视觉标记在LLM模块的最终层很少或没有受到答案标记的关注，这可能导致视觉问答错误。标准的下一标记预测损失无法有效引导对视觉标记的注意力。

Method: 提出KL注意力损失（KLAL），通过KL散度将视觉标记的注意力分布与真实注意力图对齐。真实注意力图来自合成案例中的任务几何或真实图像中的标准标注，无需新标签。KLAL与NTP损失结合使用。

Result: 该方法在几何任务、指向和指代表达理解等任务上取得了显著改进，在合成和真实世界数据上都表现出色。还引入了新的线追踪能力评估数据集，发现即使商业VLM在该任务上表现也不佳。

Conclusion: 直接监督视觉标记的注意力分布可以有效改善VLM在视觉任务中的性能，KLAL损失函数提供了一种有效的注意力引导机制。

Abstract: Vision Language Models (VLMs) mix visual tokens and text tokens. A puzzling issue is the fact that visual tokens most related to the query receive little to no attention in the final layers of the LLM module of VLMs from the answer tokens, where all tokens are treated equally, in particular, visual and language tokens in the LLM attention layers. This fact may result in wrong answers to visual questions, as our experimental results confirm. It appears that the standard next-token prediction (NTP) loss provides an insufficient signal for directing attention to visual tokens. We hypothesize that a more direct supervision of the attention of visual tokens to corresponding language tokens in the LLM module of VLMs will lead to improved performance on visual tasks. To demonstrate that this is indeed the case, we propose a novel loss function that directly supervises the attention of visual tokens. It directly grounds the answer language tokens in images by directing their attention to the relevant visual tokens. This is achieved by aligning the attention distribution of visual tokens to ground truth attention maps with KL divergence. The ground truth attention maps are obtained from task geometry in synthetic cases or from standard grounding annotations (e.g., bounding boxes or point annotations) in real images, and are used inside the LLM for attention supervision without requiring new labels. The obtained KL attention loss (KLAL) when combined with NTP encourages VLMs to attend to relevant visual tokens while generating answer tokens. This results in notable improvements across geometric tasks, pointing, and referring expression comprehension on both synthetic and real-world data, as demonstrated by our experiments. We also introduce a new dataset to evaluate the line tracing abilities of VLMs. Surprisingly, even commercial VLMs do not perform well on this task.

</details>


### [121] [Deep Imbalanced Multi-Target Regression: 3D Point Cloud Voxel Content Estimation in Simulated Forests](https://arxiv.org/abs/2511.12740)
*Amirhossein Hassanzadeh,Bartosz Krawczyk,Michael Saunders,Rob Wible,Keith Krause,Dimah Dera,Jan van Aardt*

Main category: cs.CV

TL;DR: 本研究探索从体素化LiDAR点云数据推断体素内目标占用百分比的方法，使用KPConv和多目标回归处理类别不平衡问题，通过敏感性分析发现较大体素尺寸（2米）误差较低，而较小体素尺寸（0.25-0.5米）在树冠区域误差较高。


<details>
  <summary>Details</summary>
Motivation: 体素化虽然能降低LiDAR数据处理的计算成本，但会导致细尺度结构信息丢失。本研究旨在探索是否可以从高级体素化LiDAR点云数据中推断低级的体素内容信息（目标占用百分比）。

Method: 提出基于核点卷积（KPConv）的多目标回归方法，采用密度相关（DBR）的成本敏感学习处理类别不平衡，使用加权均方误差、焦点回归和正则化来优化KPConv。对体素尺寸（0.25-2米）进行敏感性分析。

Result: 敏感性分析显示，较大体素尺寸（如2米）由于变异性降低而误差较小，而较小体素尺寸（如0.25或0.5米）误差较高，特别是在树冠区域。对于树皮和树叶目标，小体素尺寸数据集的误差值显著高于大体素尺寸数据集。

Conclusion: 体素尺寸的选择取决于具体应用。本研究填补了深度不平衡学习模型在多目标回归和森林3D LiDAR点云模拟数据集方面的空白。

Abstract: Voxelization is an effective approach to reduce the computational cost of processing Light Detection and Ranging (LiDAR) data, yet it results in a loss of fine-scale structural information. This study explores whether low-level voxel content information, specifically target occupancy percentage within a voxel, can be inferred from high-level voxelized LiDAR point cloud data collected from Digital Imaging and remote Sensing Image Generation (DIRSIG) software. In our study, the targets include bark, leaf, soil, and miscellaneous materials. We propose a multi-target regression approach in the context of imbalanced learning using Kernel Point Convolutions (KPConv). Our research leverages cost-sensitive learning to address class imbalance called density-based relevance (DBR). We employ weighted Mean Saquared Erorr (MSE), Focal Regression (FocalR), and regularization to improve the optimization of KPConv. This study performs a sensitivity analysis on the voxel size (0.25 - 2 meters) to evaluate the effect of various grid representations in capturing the nuances of the forest. This sensitivity analysis reveals that larger voxel sizes (e.g., 2 meters) result in lower errors due to reduced variability, while smaller voxel sizes (e.g., 0.25 or 0.5 meter) exhibit higher errors, particularly within the canopy, where variability is greatest. For bark and leaf targets, error values at smaller voxel size datasets (0.25 and 0.5 meter) were significantly higher than those in larger voxel size datasets (2 meters), highlighting the difficulty in accurately estimating within-canopy voxel content at fine resolutions. This suggests that the choice of voxel size is application-dependent. Our work fills the gap in deep imbalance learning models for multi-target regression and simulated datasets for 3D LiDAR point clouds of forests.

</details>


### [122] [Which Way from B to A: The role of embedding geometry in image interpolation for Stable Diffusion](https://arxiv.org/abs/2511.12757)
*Nicholas Karris,Luke Durell,Javier Flores,Tegan Emerson*

Main category: cs.CV

TL;DR: 论文发现Stable Diffusion对CLIP嵌入矩阵具有排列不变性，因此可将嵌入视为Wasserstein空间中的点云而非欧几里得空间中的矩阵。通过将嵌入插值问题重构为最优传输问题，计算嵌入之间的最短路径，从而在Stable Diffusion中生成更平滑、更连贯的插值图像。


<details>
  <summary>Details</summary>
Motivation: 受Stable Diffusion对CLIP嵌入矩阵排列不变性的启发，探索将嵌入解释为Wasserstein空间中的点云而非欧几里得空间中的矩阵，以更好地理解嵌入空间的几何结构。

Method: 将嵌入插值问题重构为最优传输问题，通过求解该问题计算嵌入之间的最短路径（测地线），在Stable Diffusion生成模型中进行图像插值。

Result: 实验表明，基于最优传输的方法相比其他标准插值方法能产生更平滑的图像插值效果。

Conclusion: 将嵌入视为点云而非矩阵能更好地反映和利用嵌入空间的几何特性，基于最优传输的插值方法能产生更自然的图像过渡效果。

Abstract: It can be shown that Stable Diffusion has a permutation-invariance property with respect to the rows of Contrastive Language-Image Pretraining (CLIP) embedding matrices. This inspired the novel observation that these embeddings can naturally be interpreted as point clouds in a Wasserstein space rather than as matrices in a Euclidean space. This perspective opens up new possibilities for understanding the geometry of embedding space. For example, when interpolating between embeddings of two distinct prompts, we propose reframing the interpolation problem as an optimal transport problem. By solving this optimal transport problem, we compute a shortest path (or geodesic) between embeddings that captures a more natural and geometrically smooth transition through the embedding space. This results in smoother and more coherent intermediate (interpolated) images when rendered by the Stable Diffusion generative model. We conduct experiments to investigate this effect, comparing the quality of interpolated images produced using optimal transport to those generated by other standard interpolation methods. The novel optimal transport--based approach presented indeed gives smoother image interpolations, suggesting that viewing the embeddings as point clouds (rather than as matrices) better reflects and leverages the geometry of the embedding space.

</details>


### [123] [RoCoISLR: A Romanian Corpus for Isolated Sign Language Recognition](https://arxiv.org/abs/2511.12767)
*Cătălin-Alexandru Rîpanu,Andrei-Theodor Hotnog,Giulia-Stefania Imbrea,Dumitru-Clementin Cercel*

Main category: cs.CV

TL;DR: 该论文介绍了罗马尼亚孤立手语识别(RoISLR)的首个大规模数据集RoCoISLR，包含9000多个视频样本和近6000个标准化词汇。通过评估7种最先进的视频识别模型，发现基于Transformer的架构表现最佳，Swin Transformer达到34.1%的Top-1准确率。


<details>
  <summary>Details</summary>
Motivation: 目前大多数手语识别数据集专注于美国手语，而罗马尼亚孤立手语识别缺乏大规模标准化数据集，限制了该领域的研究进展。

Method: 构建RoCoISLR数据集，包含9000多个视频样本和近6000个标准化词汇。在一致的实验设置下评估7种视频识别模型：I3D、SlowFast、Swin Transformer、TimeSformer、Uniformer、VideoMAE和PoseConv3D。

Result: 基于Transformer的架构优于卷积基线模型，Swin Transformer获得34.1%的Top-1准确率。研究还揭示了低资源手语中长尾类分布带来的挑战。

Conclusion: RoCoISLR为系统性的罗马尼亚孤立手语识别研究提供了初步基础，基准结果显示了该领域的挑战和机遇。

Abstract: Automatic sign language recognition plays a crucial role in bridging the communication gap between deaf communities and hearing individuals; however, most available datasets focus on American Sign Language. For Romanian Isolated Sign Language Recognition (RoISLR), no large-scale, standardized dataset exists, which limits research progress. In this work, we introduce a new corpus for RoISLR, named RoCoISLR, comprising over 9,000 video samples that span nearly 6,000 standardized glosses from multiple sources. We establish benchmark results by evaluating seven state-of-the-art video recognition models-I3D, SlowFast, Swin Transformer, TimeSformer, Uniformer, VideoMAE, and PoseConv3D-under consistent experimental setups, and compare their performance with that of the widely used WLASL2000 corpus. According to the results, transformer-based architectures outperform convolutional baselines; Swin Transformer achieved a Top-1 accuracy of 34.1%. Our benchmarks highlight the challenges associated with long-tail class distributions in low-resource sign languages, and RoCoISLR provides the initial foundation for systematic RoISLR research.

</details>


### [124] [Lightweight Optimal-Transport Harmonization on Edge Devices](https://arxiv.org/abs/2511.12785)
*Maria Larchenko,Dmitry Guskov,Alexander Lobashev,Georgy Derevyanko*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的颜色协调方法MKL-Harmonizer，用于增强现实(AR)场景中的实时颜色协调，通过训练紧凑编码器预测Monge-Kantorovich传输映射来实现设备端推理。


<details>
  <summary>Details</summary>
Motivation: 解决AR管道中缺乏实时颜色协调算法的问题，使插入对象的颜色与周围图像感知匹配，实现无缝合成。

Method: 利用经典最优传输理论，训练紧凑编码器预测Monge-Kantorovich传输映射，支持设备端推理。

Result: 在真实AR合成图像上，MKL-Harmonizer方法获得了最佳综合得分，优于现有最先进方法。

Conclusion: 该方法成功实现了AR场景的实时颜色协调，并发布了专门的AR合成图像数据集和工具包以支持进一步研究。

Abstract: Color harmonization adjusts the colors of an inserted object so that it perceptually matches the surrounding image, resulting in a seamless composite. The harmonization problem naturally arises in augmented reality (AR), yet harmonization algorithms are not currently integrated into AR pipelines because real-time solutions are scarce. In this work, we address color harmonization for AR by proposing a lightweight approach that supports on-device inference. For this, we leverage classical optimal transport theory by training a compact encoder to predict the Monge-Kantorovich transport map. We benchmark our MKL-Harmonizer algorithm against state-of-the-art methods and demonstrate that for real composite AR images our method achieves the best aggregated score. We release our dedicated AR dataset of composite images with pixel-accurate masks and data-gathering toolkit to support further data acquisition by researchers.

</details>


### [125] [Video Finetuning Improves Reasoning Between Frames](https://arxiv.org/abs/2511.12868)
*Ruiqi Yang,Tian Yun,Zihan Wang,Ellie Pavlick*

Main category: cs.CV

TL;DR: 本文提出了视觉思维链（vCoT）方法，通过生成连续帧之间的过渡事件描述来增强多模态大语言模型的视频理解能力，并比较了仅图像模型与视频微调模型在长视频问答任务中的表现差异。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视频理解方面通常只是简单拼接帧标记，缺乏对帧间过渡的显式建模，因此需要研究视频微调对模型能力的具体影响。

Method: 提出视觉思维链（vCoT）方法，生成连续帧之间的过渡事件描述作为显式推理过程，并系统比较仅图像模型与视频微调模型在有无过渡线索情况下的表现。

Result: vCoT显著提升了仅图像模型在长视频问答任务中的性能，但对视频微调模型仅有边际增益；视频微调模型能够将时序推理能力迁移到静态视觉推理任务中。

Conclusion: 视频微调模型已经隐式掌握了帧间过渡推理能力，而vCoT为仅图像模型提供了有效的显式推理支持，视频模型还具备向静态任务迁移时序推理能力的特点。

Abstract: Multimodal large language models (LLMs) have made rapid progress in visual understanding, yet their extension from images to videos often reduces to a naive concatenation of frame tokens. In this work, we investigate what video finetuning brings to multimodal LLMs. We propose Visual Chain-of-Thought (vCoT), an explicit reasoning process that generates transitional event descriptions between consecutive frames. Using vCoT, we systematically compare image-only LVLMs with their video-finetuned counterparts, both with and without access to these transitional cues. Our experiments show that vCoT significantly improves the performance of image-only models on long-form video question answering, while yielding only marginal gains for video-finetuned models. This suggests that the latter already capture frame-to-frame transitions implicitly. Moreover, we find that video models transfer this temporal reasoning ability to purely static settings, outperforming image models' baselines on relational visual reasoning tasks.

</details>


### [126] [Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views](https://arxiv.org/abs/2511.12878)
*Junyi Ma,Wentao Bao,Jingyi Xu,Guanzhong Sun,Yu Zheng,Erhang Zhang,Xieyuanli Chen,Hesheng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为EgoLoc的零样本方法，用于在自我中心视频中定位手与物体接触和分离的时间戳，解决了现有方法在精确定位交互关键时刻方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注交互动作的行为范式（"如何交互"），但更挑战性的细粒度问题——捕捉手与目标物体接触和分离的关键时刻（"何时交互"）仍未充分探索，这对混合现实中的沉浸式交互体验和机器人运动规划至关重要。

Method: 提出EgoLoc方法，引入手动力学引导采样生成高质量视觉提示，利用视觉语言模型识别接触/分离属性、定位特定时间戳，并提供闭环反馈进行进一步优化。该方法无需物体掩码和动词-名词分类法。

Result: 在公共数据集和新型基准测试上的综合实验表明，EgoLoc在自我中心视频中实现了可信的时间交互定位，并验证了其在自我中心视觉和机器人操作任务中有效促进多个下游应用的能力。

Conclusion: EgoLoc方法消除了对物体掩码和动词-名词分类法的需求，实现了可推广的零样本实现，为自我中心视觉和机器人操作任务提供了有效的交互时刻定位解决方案。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR applications and human-robot policy transfer. Existing research has mostly focused on modeling the behavior paradigm of interactive actions (i.e., "how to interact"). However, the more challenging and fine-grained problem of capturing the critical moments of contact and separation between the hand and the target object (i.e., "when to interact") is still underexplored, which is crucial for immersive interactive experiences in mixed reality and robotic motion planning. Therefore, we formulate this problem as temporal interaction localization (TIL). Some recent works extract semantic masks as TIL references, but suffer from inaccurate object grounding and cluttered scenarios. Although current temporal action localization (TAL) methods perform well in detecting verb-noun action segments, they rely on category annotations during training and exhibit limited precision in localizing hand-object contact/separation moments. To address these issues, we propose a novel zero-shot approach dubbed EgoLoc to localize hand-object contact and separation timestamps in egocentric videos. EgoLoc introduces hand-dynamics-guided sampling to generate high-quality visual prompts. It exploits the vision-language model to identify contact/separation attributes, localize specific timestamps, and provide closed-loop feedback for further refinement. EgoLoc eliminates the need for object masks and verb-noun taxonomies, leading to generalizable zero-shot implementation. Comprehensive experiments on the public dataset and our novel benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric videos. It is also validated to effectively facilitate multiple downstream applications in egocentric vision and robotic manipulation tasks. Code and relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [127] [Simple Lines, Big Ideas: Towards Interpretable Assessment of Human Creativity from Drawings](https://arxiv.org/abs/2511.12880)
*Zihao Lin,Zhenshan Shi,Sasa Zhao,Hanwei Zhu,Lingyu Zhu,Baoliang Chen,Lei Mo*

Main category: cs.CV

TL;DR: 本文提出了一种数据驱动的自动可解释绘图创造力评估框架，通过多模态多任务学习同时预测创造力分数、分类内容类型和提取风格特征。


<details>
  <summary>Details</summary>
Motivation: 当前创造力评估主要依赖专家主观评分，既耗时又主观。受认知科学启发，将创造力重新解释为内容（画什么）和风格（怎么画）两个互补维度的函数。

Method: 首先扩展现有创造力标注数据集，增加内容类别标注；然后提出多模态多任务学习框架，引入条件学习机制，根据绘图的风格和语义线索动态调整视觉特征提取。

Result: 实验结果表明，该模型相比现有基于回归的方法达到了最先进的性能，并提供与人类判断一致的可解释可视化结果。

Conclusion: 该框架能够自动且可解释地评估绘图创造力，代码和标注将公开提供。

Abstract: Assessing human creativity through visual outputs, such as drawings, plays a critical role in fields including psychology, education, and cognitive science. However, current assessment practices still rely heavily on expert-based subjective scoring, which is both labor-intensive and inherently subjective. In this paper, we propose a data-driven framework for automatic and interpretable creativity assessment from drawings. Motivated by the cognitive understanding that creativity can emerge from both what is drawn (content) and how it is drawn (style), we reinterpret the creativity score as a function of these two complementary dimensions.Specifically, we first augment an existing creativity labeled dataset with additional annotations targeting content categories. Based on the enriched dataset, we further propose a multi-modal, multi-task learning framework that simultaneously predicts creativity scores, categorizes content types, and extracts stylistic features. In particular, we introduce a conditional learning mechanism that enables the model to adapt its visual feature extraction by dynamically tuning it to creativity-relevant signals conditioned on the drawing's stylistic and semantic cues.Experimental results demonstrate that our model achieves state-of-the-art performance compared to existing regression-based approaches and offers interpretable visualizations that align well with human judgments. The code and annotations will be made publicly available at https://github.com/WonderOfU9/CSCA_PRCV_2025

</details>


### [128] [Reconstructing 3D Scenes in Native High Dynamic Range](https://arxiv.org/abs/2511.12895)
*Kaixuan Zhang,Minxian Li,Mingwu Ren,Jiankang Deng,Xiatian Zhu*

Main category: cs.CV

TL;DR: 本文提出了NH-3DGS方法，首次实现了直接从原生HDR观测数据中进行3D场景重建，通过新颖的亮度-色度分解技术，在整个重建流程中保持完整动态范围。


<details>
  <summary>Details</summary>
Motivation: 专业数字媒体制作需要HDR成像，但现有3D场景重建主要基于LDR数据，限制了在专业工作流程中的应用。现有方法依赖多曝光融合或逆色调映射，增加了捕获复杂性并依赖合成监督。

Method: 提出Native High dynamic range 3D Gaussian Splatting (NH-3DGS)方法，采用新颖的亮度-色度分解颜色表示，直接从原生HDR相机数据进行优化，保持完整动态范围。

Result: 在合成和真实多视角HDR数据集上的实验表明，NH-3DGS在重建质量和动态范围保持方面显著优于现有方法，能够直接从原生HDR捕获实现专业级3D重建。

Conclusion: NH-3DGS是首个直接从原生HDR观测数据建模的3D场景重建方法，通过亮度-色度分解技术实现了专业级的重建效果，代码和数据集将公开。

Abstract: High Dynamic Range (HDR) imaging is essential for professional digital media creation, e.g., filmmaking, virtual production, and photorealistic rendering. However, 3D scene reconstruction has primarily focused on Low Dynamic Range (LDR) data, limiting its applicability to professional workflows. Existing approaches that reconstruct HDR scenes from LDR observations rely on multi-exposure fusion or inverse tone-mapping, which increase capture complexity and depend on synthetic supervision. With the recent emergence of cameras that directly capture native HDR data in a single exposure, we present the first method for 3D scene reconstruction that directly models native HDR observations. We propose {\bf Native High dynamic range 3D Gaussian Splatting (NH-3DGS)}, which preserves the full dynamic range throughout the reconstruction pipeline. Our key technical contribution is a novel luminance-chromaticity decomposition of the color representation that enables direct optimization from native HDR camera data. We demonstrate on both synthetic and real multi-view HDR datasets that NH-3DGS significantly outperforms existing methods in reconstruction quality and dynamic range preservation, enabling professional-grade 3D reconstruction directly from native HDR captures. Code and datasets will be made available.

</details>


### [129] [FDP: A Frequency-Decomposition Preprocessing Pipeline for Unsupervised Anomaly Detection in Brain MRI](https://arxiv.org/abs/2511.12899)
*Hao Li,Zhenfeng Zhuang,Jingyu Lin,Yu Liu,Yifei Chen,Qiong Peng,Lequan Yu,Liansheng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于频域分解预处理（FDP）的无监督脑MRI异常检测方法，通过分析病理特征的频域特性，在保持解剖结构的同时抑制病理信号，显著提升了现有方法的检测性能。


<details>
  <summary>Details</summary>
Motivation: 由于脑解剖结构的多样性和标注数据的稀缺性，脑MRI的无监督异常检测面临挑战。现有方法使用模拟噪声训练生成模型，但缺乏真实临床病变的生物物理保真度和形态复杂性。

Method: 提出频率分解预处理（FDP）框架，首次利用频域重建同时实现病理抑制和解剖结构保持。该方法可与现有异常模拟技术无缝集成。

Result: 实验结果表明FDP能持续提升异常检测性能，与LDM结合时DICE分数提高了17.63%，并在多个基准方法上都保持了稳健的改进。

Conclusion: FDP通过频域分析有效提升了脑MRI无监督异常检测的性能，为临床诊断提供了更可靠的解决方案。

Abstract: Due to the diversity of brain anatomy and the scarcity of annotated data, supervised anomaly detection for brain MRI remains challenging, driving the development of unsupervised anomaly detection (UAD) approaches. Current UAD methods typically utilize artificially generated noise perturbations on healthy MRIs to train generative models for normal anatomy reconstruction, enabling anomaly detection via residual mapping. However, such simulated anomalies lack the biophysical fidelity and morphological complexity characteristic of true clinical lesions. To advance UAD in brain MRI, we conduct the first systematic frequency-domain analysis of pathological signatures, revealing two key properties: (1) anomalies exhibit unique frequency patterns distinguishable from normal anatomy, and (2) low-frequency signals maintain consistent representations across healthy scans. These insights motivate our Frequency-Decomposition Preprocessing (FDP) framework, the first UAD method to leverage frequency-domain reconstruction for simultaneous pathology suppression and anatomical preservation. FDP can integrate seamlessly with existing anomaly simulation techniques, consistently enhancing detection performance across diverse architectures while maintaining diagnostic fidelity. Experimental results demonstrate that FDP consistently improves anomaly detection performance when integrated with existing methods. Notably, FDP achieves a 17.63% increase in DICE score with LDM while maintaining robust improvements across multiple baselines. The code is available at https://github.com/ls1rius/MRI_FDP.

</details>


### [130] [DeepSport: A Multimodal Large Language Model for Comprehensive Sports Video Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2511.12908)
*Junbo Zou,Haotian Xia,Zhen Ye,Shengjie Zhang,Christopher Lai,Vicente Ordonez,Weining Shen,Hanjie Chen*

Main category: cs.CV

TL;DR: DeepSport是首个端到端训练的多任务、多运动视频理解MLLM框架，通过主动迭代推理和专用帧提取工具实现"视频思考"，在6.7k问题测试基准上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有体育视频理解方法存在单运动中心化、任务局限或缺乏学习推理过程的问题，需要解决高速动态感知、复杂规则理解和长时序上下文推理的独特挑战。

Method: 提出数据蒸馏管道从10个数据源合成高质量思维链轨迹，采用两阶段训练策略（监督微调+带门控工具使用奖励的强化学习），通过专用帧提取工具实现主动迭代推理。

Result: 在6.7k问题测试基准上，DeepSport显著优于专有模型和开源模型基线，实现了最先进的性能表现。

Conclusion: 这项工作为领域特定视频推理建立了新基础，能够应对多样化体育的复杂性。

Abstract: Sports video understanding presents unique challenges, requiring models to perceive high-speed dynamics, comprehend complex rules, and reason over long temporal contexts. While Multimodal Large Language Models (MLLMs) have shown promise in genral domains, the current state of research in sports remains narrowly focused: existing approaches are either single-sport centric, limited to specific tasks, or rely on training-free paradigms that lack robust, learned reasoning process. To address this gap, we introduce DeepSport, the first end-to-end trained MLLM framework designed for multi-task, multi-sport video understanding. DeepSport shifts the paradigm from passive frame processing to active, iterative reasoning, empowering the model to ``think with videos'' by dynamically interrogating content via a specialized frame-extraction tool. To enable this, we propose a data distillation pipeline that synthesizes high-quality Chain-of-Thought (CoT) trajectories from 10 diverse data source, creating a unified resource of 78k training data. We then employ a two-stage training strategy, Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) with a novel gated tool-use reward, to optimize the model's reasoning process. Extensive experiments on the testing benchmark of 6.7k questions demonstrate that DeepSport achieves state-of-the-art performance, significantly outperforming baselines of both proprietary model and open-source models. Our work establishes a new foundation for domain-specific video reasoning to address the complexities of diverse sports.

</details>


### [131] [CASL: Curvature-Augmented Self-supervised Learning for 3D Anomaly Detection](https://arxiv.org/abs/2511.12909)
*Yaohua Zha,Xue Yuerong,Chunlin Fan,Yuansong Wang,Tao Dai,Ke Chen,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 本文提出了一种基于曲率增强自监督学习(CASL)的3D异常检测框架，通过多尺度曲率提示引导解码器重建点云坐标，无需特定异常检测机制即可在统一微调范式下实现领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D异常检测方法缺乏泛化性，而经典自监督点云模型在异常检测任务上表现不佳，这促使作者开发一个更通用的3D模型，能够有效检测异常且不依赖任务特定设计。

Method: 基于U-Net架构，引入多尺度曲率提示来指导解码器预测每个点的空间坐标，通过重建范式实现曲率增强的自监督学习。

Result: 仅使用点曲率作为异常评分已超越多个经典自监督和专用异常检测模型，CASL框架在异常检测中达到领先性能，且学到的表示在标准3D理解任务中泛化良好。

Conclusion: 曲率在3D异常检测中起关键作用，CASL框架通过简单异常分类微调即可实现优异性能，证明了其作为通用3D模型的潜力。

Abstract: Deep learning-based 3D anomaly detection methods have demonstrated significant potential in industrial manufacturing. However, many approaches are specifically designed for anomaly detection tasks, which limits their generalizability to other 3D understanding tasks. In contrast, self-supervised point cloud models aim for general-purpose representation learning, yet our investigation reveals that these classical models are suboptimal at anomaly detection under the unified fine-tuning paradigm. This motivates us to develop a more generalizable 3D model that can effectively detect anomalies without relying on task-specific designs. Interestingly, we find that using only the curvature of each point as its anomaly score already outperforms several classical self-supervised and dedicated anomaly detection models, highlighting the critical role of curvature in 3D anomaly detection. In this paper, we propose a Curvature-Augmented Self-supervised Learning (CASL) framework based on a reconstruction paradigm. Built upon the classical U-Net architecture, our approach introduces multi-scale curvature prompts to guide the decoder in predicting the spatial coordinates of each point. Without relying on any dedicated anomaly detection mechanisms, it achieves leading detection performance through straightforward anomaly classification fine-tuning. Moreover, the learned representations generalize well to standard 3D understanding tasks such as point cloud classification. The code is available at https://github.com/zyh16143998882/CASL.

</details>


### [132] [Explore How to Inject Beneficial Noise in MLLMs](https://arxiv.org/abs/2511.12917)
*Ruishu Zhu,Sida Huang,Ziheng Jiao,Hongyuan Zhang*

Main category: cs.CV

TL;DR: 提出了一种通过注入有益随机噪声的新型微调策略MuNG，在仅调整1-2%额外参数的情况下，性能超过完整微调和其他现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法往往忽略跨模态异质性，限制了多模态大语言模型的潜力。

Method: 从变分推理角度重新制定MLLMs推理过程，设计多模态噪声生成器动态分析图像-文本对的跨模态关系，生成任务自适应的有益噪声。

Result: 在QwenVL和LLaVA上的实验表明，该方法超越完整参数微调和其他现有微调方法，同时仅需调整约1-2%的额外参数。

Conclusion: 注入定制化噪声能有效抑制不相关语义成分，显著改善跨模态表示对齐，提升下游任务性能。

Abstract: Multimodal Large Language Models (MLLMs) have played an increasingly important role in multimodal intelligence. However, the existing fine-tuning methods often ignore cross-modal heterogeneity, limiting their full potential. In this work, we propose a novel fine-tuning strategy by injecting beneficial random noise, which outperforms previous methods and even surpasses full fine-tuning, with minimal additional parameters. The proposed Multimodal Noise Generator (MuNG) enables efficient modality fine-tuning by injecting customized noise into the frozen MLLMs. Specifically, we reformulate the reasoning process of MLLMs from a variational inference perspective, upon which we design a multimodal noise generator that dynamically analyzes cross-modal relationships in image-text pairs to generate task-adaptive beneficial noise. Injecting this type of noise into the MLLMs effectively suppresses irrelevant semantic components, leading to significantly improved cross-modal representation alignment and enhanced performance on downstream tasks. Experiments on two mainstream MLLMs, QwenVL and LLaVA, demonstrate that our method surpasses full-parameter fine-tuning and other existing fine-tuning approaches, while requiring adjustments to only about $1\sim2\%$ additional parameters. The relevant code is uploaded in the supplementary.

</details>


### [133] [CoordAR: One-Reference 6D Pose Estimation of Novel Objects via Autoregressive Coordinate Map Generation](https://arxiv.org/abs/2511.12919)
*Dexin Zuo,Ang Li,Wei Wang,Wenxian Yu,Danping Zou*

Main category: cs.CV

TL;DR: CoordAR是一个用于单参考视图6D姿态估计的自回归框架，通过将3D-3D对应关系建模为离散token序列，解决了现有方法在对称性和遮挡场景下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于单参考视图的6D姿态估计方法存在全局一致性不足和缺乏不确定性建模的问题，特别是在对称或遮挡场景下表现不佳。

Method: 提出CoordAR框架：1）坐标图token化实现概率预测；2）模态解耦编码策略分别处理RGB外观和坐标线索；3）自回归transformer解码器结合位置对齐查询特征和部分生成token序列。

Result: 在多个基准测试中显著优于现有方法，在对称性、遮挡等真实世界挑战中表现出强鲁棒性。

Conclusion: CoordAR通过自回归和概率建模方法有效解决了单参考6D姿态估计中的对称性和遮挡问题，为无3D模型的对象姿态估计提供了新思路。

Abstract: Object 6D pose estimation, a crucial task for robotics and augmented reality applications, becomes particularly challenging when dealing with novel objects whose 3D models are not readily available. To reduce dependency on 3D models, recent studies have explored one-reference-based pose estimation, which requires only a single reference view instead of a complete 3D model. However, existing methods that rely on real-valued coordinate regression suffer from limited global consistency due to the local nature of convolutional architectures and face challenges in symmetric or occluded scenarios owing to a lack of uncertainty modeling. We present CoordAR, a novel autoregressive framework for one-reference 6D pose estimation of unseen objects. CoordAR formulates 3D-3D correspondences between the reference and query views as a map of discrete tokens, which is obtained in an autoregressive and probabilistic manner. To enable accurate correspondence regression, CoordAR introduces 1) a novel coordinate map tokenization that enables probabilistic prediction over discretized 3D space; 2) a modality-decoupled encoding strategy that separately encodes RGB appearance and coordinate cues; and 3) an autoregressive transformer decoder conditioned on both position-aligned query features and the partially generated token sequence. With these novel mechanisms, CoordAR significantly outperforms existing methods on multiple benchmarks and demonstrates strong robustness to symmetry, occlusion, and other challenges in real-world tests.

</details>


### [134] [Generative Photographic Control for Scene-Consistent Video Cinematic Editing](https://arxiv.org/abs/2511.12921)
*Huiqiang Sun,Liao Shen,Zhan Peng,Kun Wang,Size Wu,Yuhang Zang,Tianqi Liu,Zihao Huang,Xingyu Zeng,Zhiguo Cao,Wei Li,Chen Change Loy*

Main category: cs.CV

TL;DR: CineCtrl是首个视频电影编辑框架，提供对专业相机参数（如散景、快门速度）的精细控制，通过解耦交叉注意力机制分离相机运动和摄影输入，并利用综合数据生成策略构建大规模训练数据集。


<details>
  <summary>Details</summary>
Motivation: 现有生成视频模型大多仅限于相机运动控制，难以控制摄影元素（如景深、曝光）来传达情绪和创造美学吸引力。

Method: 提出解耦交叉注意力机制分离相机运动和摄影输入，开发综合数据生成策略包括模拟摄影效果和真实世界收集流程，构建大规模训练数据集。

Result: 模型生成具有精确控制的用户指定摄影相机效果的高保真视频。

Conclusion: CineCtrl框架成功实现了对专业相机参数的精细控制，为视频电影编辑提供了新的可能性。

Abstract: Cinematic storytelling is profoundly shaped by the artful manipulation of photographic elements such as depth of field and exposure. These effects are crucial in conveying mood and creating aesthetic appeal. However, controlling these effects in generative video models remains highly challenging, as most existing methods are restricted to camera motion control. In this paper, we propose CineCtrl, the first video cinematic editing framework that provides fine control over professional camera parameters (e.g., bokeh, shutter speed). We introduce a decoupled cross-attention mechanism to disentangle camera motion from photographic inputs, allowing fine-grained, independent control without compromising scene consistency. To overcome the shortage of training data, we develop a comprehensive data generation strategy that leverages simulated photographic effects with a dedicated real-world collection pipeline, enabling the construction of a large-scale dataset for robust model training. Extensive experiments demonstrate that our model generates high-fidelity videos with precisely controlled, user-specified photographic camera effects.

</details>


### [135] [Text2Traffic: A Text-to-Image Generation and Editing Method for Traffic Scenes](https://arxiv.org/abs/2511.12932)
*Feng Lv,Haoxuan Feng,Zilu Zhang,Chunlong Xia,Yanfeng Li*

Main category: cs.CV

TL;DR: 提出统一的文本驱动交通场景图像生成与编辑框架，通过可控掩码机制整合两项任务，利用多视角数据增强几何多样性，采用两阶段训练策略提升文本-图像对齐和细节质量，引入掩码区域加权损失改善小尺度交通元素生成效果。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中文本驱动图像生成与编辑技术存在语义丰富度不足、视角受限、视觉保真度低、文本-内容对齐差等问题，需要开发更有效的解决方案。

Method: 1. 统一文本驱动框架整合图像生成与编辑；2. 可控掩码机制无缝连接两项任务；3. 车辆侧和路侧多视角数据增强几何多样性；4. 两阶段训练：大规模粗粒度文本-图像数据概念学习 + 细粒度描述数据微调；5. 掩码区域加权损失动态关注关键小区域。

Result: 大量实验表明，该方法在交通场景的文本驱动图像生成和编辑方面达到了领先性能。

Conclusion: 所提出的统一框架有效解决了交通场景图像生成与编辑中的关键挑战，显著提升了生成质量和对齐精度。

Abstract: With the rapid advancement of intelligent transportation systems, text-driven image generation and editing techniques have demonstrated significant potential in providing rich, controllable visual scene data for applications such as traffic monitoring and autonomous driving. However, several challenges remain, including insufficient semantic richness of generated traffic elements, limited camera viewpoints, low visual fidelity of synthesized images, and poor alignment between textual descriptions and generated content. To address these issues, we propose a unified text-driven framework for both image generation and editing, leveraging a controllable mask mechanism to seamlessly integrate the two tasks. Furthermore, we incorporate both vehicle-side and roadside multi-view data to enhance the geometric diversity of traffic scenes. Our training strategy follows a two-stage paradigm: first, we perform conceptual learning using large-scale coarse-grained text-image data; then, we fine-tune with fine-grained descriptive data to enhance text-image alignment and detail quality. Additionally, we introduce a mask-region-weighted loss that dynamically emphasizes small yet critical regions during training, thereby substantially enhancing the generation fidelity of small-scale traffic elements. Extensive experiments demonstrate that our method achieves leading performance in text-based image generation and editing within traffic scenes.

</details>


### [136] [Semi-Supervised High Dynamic Range Image Reconstructing via Bi-Level Uncertain Area Masking](https://arxiv.org/abs/2511.12939)
*Wei Jiang,Jiahao Cui,Yizheng Wu,Zhan Peng,Zhiyu Pan,Zhiguo Cao*

Main category: cs.CV

TL;DR: 本文提出了一种基于半监督学习的高动态范围图像重建方法，通过教师模型生成伪HDR标签，并使用不确定性掩码机制过滤不可靠区域，仅需6.7%的HDR真实标签即可达到全监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的HDR图像重建方法需要LDR-HDR图像对，但这些数据对难以获取，因此需要研究如何在有限HDR真实标签下实现可比较性能的标注高效方法。

Method: 采用半监督学习框架，教师模型为无标签的LDR样本生成伪HDR标签，学生模型从伪标签学习。提出基于不确定性的像素级和块级掩码过程，过滤伪标签中的不可靠部分。

Result: 该方法不仅优于先前的标注高效算法，而且仅使用6.7%的HDR真实标签就能达到最新全监督方法的可比性能。

Conclusion: 通过不确定性掩码机制有效缓解了确认偏差问题，证明了半监督学习在HDR图像重建任务中的有效性，显著降低了标注需求。

Abstract: Reconstructing high dynamic range (HDR) images from low dynamic range (LDR) bursts plays an essential role in the computational photography. Impressive progress has been achieved by learning-based algorithms which require LDR-HDR image pairs. However, these pairs are hard to obtain, which motivates researchers to delve into the problem of annotation-efficient HDR image reconstructing: how to achieve comparable performance with limited HDR ground truths (GTs). This work attempts to address this problem from the view of semi-supervised learning where a teacher model generates pseudo HDR GTs for the LDR samples without GTs and a student model learns from pseudo GTs. Nevertheless, the confirmation bias, i.e., the student may learn from the artifacts in pseudo HDR GTs, presents an impediment. To remove this impediment, an uncertainty-based masking process is proposed to discard unreliable parts of pseudo GTs at both pixel and patch levels, then the trusted areas can be learned from by the student. With this novel masking process, our semi-supervised HDR reconstructing method not only outperforms previous annotation-efficient algorithms, but also achieves comparable performance with up-to-date fully-supervised methods by using only 6.7% HDR GTs.

</details>


### [137] [T2I-Based Physical-World Appearance Attack against Traffic Sign Recognition Systems in Autonomous Driving](https://arxiv.org/abs/2511.12956)
*Chen Ma,Ningfei Wang,Junhao Zheng,Qing Guo,Qian Wang,Qi Alfred Chen,Chao Shen*

Main category: cs.CV

TL;DR: DiffSign是一个基于文本到图像扩散模型的交通标志识别系统对抗攻击框架，通过集成CLIP损失和掩码提示来提升攻击效果和可控性，并提出了两种风格定制方法来改善攻击隐蔽性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有交通标志识别系统的对抗攻击方法存在隐蔽性差、泛化能力弱、迁移性不足等问题，需要开发更有效的物理世界攻击框架。

Method: 提出DiffSign框架，集成CLIP损失和掩码提示来增强攻击聚焦和可控性，并设计两种风格定制方法指导视觉外观，提高跨域交通标志攻击的泛化能力和隐蔽性。

Result: 在多种真实世界条件下（不同距离、角度、光照条件和标志类别）的广泛评估显示，DiffSign实现了83.3%的平均物理世界攻击成功率，具有很高的攻击迁移性。

Conclusion: DiffSign框架能够生成物理鲁棒、高效、可迁移、实用且隐蔽的外观攻击，显著优于现有方法，为交通标志识别系统的安全性提供了重要见解。

Abstract: Traffic Sign Recognition (TSR) systems play a critical role in Autonomous Driving (AD) systems, enabling real-time detection of road signs, such as STOP and speed limit signs. While these systems are increasingly integrated into commercial vehicles, recent research has exposed their vulnerability to physical-world adversarial appearance attacks. In such attacks, carefully crafted visual patterns are misinterpreted by TSR models as legitimate traffic signs, while remaining inconspicuous or benign to human observers. However, existing adversarial appearance attacks suffer from notable limitations. Pixel-level perturbation-based methods often lack stealthiness and tend to overfit to specific surrogate models, resulting in poor transferability to real-world TSR systems. On the other hand, text-to-image (T2I) diffusion model-based approaches demonstrate limited effectiveness and poor generalization to out-of-distribution sign types.
  In this paper, we present DiffSign, a novel T2I-based appearance attack framework designed to generate physically robust, highly effective, transferable, practical, and stealthy appearance attacks against TSR systems. To overcome the limitations of prior approaches, we propose a carefully designed attack pipeline that integrates CLIP-based loss and masked prompts to improve attack focus and controllability. We also propose two novel style customization methods to guide visual appearance and improve out-of-domain traffic sign attack generalization and attack stealthiness. We conduct extensive evaluations of DiffSign under varied real-world conditions, including different distances, angles, light conditions, and sign categories. Our method achieves an average physical-world attack success rate of 83.3%, leveraging DiffSign's high effectiveness in attack transferability.

</details>


### [138] [EndoSight AI: Deep Learning-Driven Real-Time Gastrointestinal Polyp Detection and Segmentation for Enhanced Endoscopic Diagnostics](https://arxiv.org/abs/2511.12962)
*Daniel Cavadia*

Main category: cs.CV

TL;DR: EndoSight AI是一个深度学习架构，用于内窥镜手术中精确实时检测胃肠道息肉，在检测和分割任务上表现出色，并支持实时推理。


<details>
  <summary>Details</summary>
Motivation: 在内窥镜手术中精确实时检测胃肠道息肉对于结直肠癌的早期诊断和预防至关重要。

Method: 利用公开的Hyper-Kvasir数据集，采用深度学习架构，结合临床相关性能指标和热感知程序确保模型鲁棒性和效率。

Result: 系统在息肉检测上达到88.3%的平均精度(mAP)，分割任务Dice系数达69%，GPU硬件上实时推理速度超过35帧/秒。

Conclusion: 该集成AI解决方案设计用于无缝部署到内窥镜工作流程中，有望提高胃肠道医疗的诊断准确性和临床决策能力。

Abstract: Precise and real-time detection of gastrointestinal polyps during endoscopic procedures is crucial for early diagnosis and prevention of colorectal cancer. This work presents EndoSight AI, a deep learning architecture developed and evaluated independently to enable accurate polyp localization and detailed boundary delineation. Leveraging the publicly available Hyper-Kvasir dataset, the system achieves a mean Average Precision (mAP) of 88.3% for polyp detection and a Dice coefficient of up to 69% for segmentation, alongside real-time inference speeds exceeding 35 frames per second on GPU hardware. The training incorporates clinically relevant performance metrics and a novel thermal-aware procedure to ensure model robustness and efficiency. This integrated AI solution is designed for seamless deployment in endoscopy workflows, promising to advance diagnostic accuracy and clinical decision-making in gastrointestinal healthcare.

</details>


### [139] [CalibrateMix: Guided-Mixup Calibration of Image Semi-Supervised Models](https://arxiv.org/abs/2511.12964)
*Mehrab Mustafy Rahman,Jayanth Mohan,Tiberiu Sosea,Cornelia Caragea*

Main category: cs.CV

TL;DR: 本文提出CalibrateMix方法，通过有针对性的mixup策略改善半监督学习模型的校准性能，在保持或提高分类准确率的同时降低预期校准误差。


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习方法存在校准不佳的问题，模型往往产生过度自信的预测。虽然mixup在监督学习中改善了校准，但在半监督学习中由于伪标签的不可靠性而面临挑战。

Method: 利用训练动态识别'易学'和'难学'样本，然后对这些样本进行有针对性的mixup操作。

Result: 在多个基准图像数据集上的实验表明，该方法相比现有半监督学习方法获得了更低的预期校准误差和更高的准确率。

Conclusion: CalibrateMix方法有效解决了半监督学习中的模型校准问题，同时保持了分类性能。

Abstract: Semi-supervised learning (SSL) has demonstrated high performance in image classification tasks by effectively utilizing both labeled and unlabeled data. However, existing SSL methods often suffer from poor calibration, with models yielding overconfident predictions that misrepresent actual prediction likelihoods. Recently, neural networks trained with {\tt mixup} that linearly interpolates random examples from the training set have shown better calibration in supervised settings. However, calibration of neural models remains under-explored in semi-supervised settings. Although effective in supervised model calibration, random mixup of pseudolabels in SSL presents challenges due to the overconfidence and unreliability of pseudolabels. In this work, we introduce CalibrateMix, a targeted mixup-based approach that aims to improve the calibration of SSL models while maintaining or even improving their classification accuracy. Our method leverages training dynamics of labeled and unlabeled samples to identify ``easy-to-learn'' and ``hard-to-learn'' samples, which in turn are utilized in a targeted mixup of easy and hard samples. Experimental results across several benchmark image datasets show that our method achieves lower expected calibration error (ECE) and superior accuracy compared to existing SSL approaches.

</details>


### [140] [GrOCE:Graph-Guided Online Concept Erasure for Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.12968)
*Ning Han,Zhenyu Ge,Feng Han,Yuhua Sun,Chengqing Li,Jingjing Chen*

Main category: cs.CV

TL;DR: GrOCE是一个无需训练的概念擦除框架，通过图引导的语义推理实现精确、自适应的有害内容移除，同时保留非目标语义。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法要么依赖昂贵的微调，要么采用粗粒度语义分离，往往会退化无关概念且缺乏对动态概念集的适应性。

Method: 提出图引导在线概念擦除框架，包含三个组件：动态拓扑图构建、自适应聚类识别和选择性边切断，通过图结构建模概念间关系进行精确语义隔离。

Result: 在概念相似度和Fréchet Inception距离指标上达到最先进性能，实现了高效、准确且稳定的概念擦除。

Conclusion: GrOCE提供了一种无需重新训练的高效概念擦除解决方案，能够精确移除目标概念同时保持全局语义完整性。

Abstract: Concept erasure aims to remove harmful, inappropriate, or copyrighted content from text-to-image diffusion models while preserving non-target semantics. However, existing methods either rely on costly fine-tuning or apply coarse semantic separation, often degrading unrelated concepts and lacking adaptability to evolving concept sets. To alleviate this issue, we propose Graph-Guided Online Concept Erasure (GrOCE), a training-free framework that performs precise and adaptive concept removal through graph-based semantic reasoning. GrOCE models concepts and their interrelations as a dynamic semantic graph, enabling principled reasoning over dependencies and fine-grained isolation of undesired content. It comprises three components: (1) Dynamic Topological Graph Construction for incremental graph building, (2) Adaptive Cluster Identification for multi-hop traversal with similarity-decay scoring, and (3) Selective Edge Severing for targeted edge removal while preserving global semantics. Extensive experiments demonstrate that GrOCE achieves state-of-the-art performance on Concept Similarity (CS) and Fréchet Inception Distance (FID) metrics, offering efficient, accurate, and stable concept erasure without retraining.

</details>


### [141] [HiFusion: Hierarchical Intra-Spot Alignment and Regional Context Fusion for Spatial Gene Expression Prediction from Histopathology](https://arxiv.org/abs/2511.12969)
*Ziqiao Weng,Yaoyu Fang,Jiahe Qian,Xinkun Wang,Lee AD Cooper,Weidong Cai,Bo Zhou*

Main category: cs.CV

TL;DR: HiFusion是一个深度学习框架，通过分层建模和跨尺度融合从H&E染色病理图像预测空间转录组基因表达，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 空间转录组技术面临临床应用的障碍，包括技术复杂性和高昂成本。现有方法难以捕捉spot内的生物异质性，且在整合周围组织上下文信息时易受形态学噪声影响。

Method: HiFusion包含两个互补组件：分层spot内建模模块通过多分辨率子块分解提取细粒度形态表征；上下文感知跨尺度融合模块使用交叉注意力选择性地整合生物相关区域上下文。

Result: 在两个基准ST数据集上的广泛实验表明，HiFusion在2D切片交叉验证和更具挑战性的3D样本特定场景中均达到最先进性能。

Conclusion: HiFusion作为一个稳健、准确且可扩展的解决方案，具有从常规病理学推断空间转录组的潜力。

Abstract: Spatial transcriptomics (ST) bridges gene expression and tissue morphology but faces clinical adoption barriers due to technical complexity and prohibitive costs. While computational methods predict gene expression from H&E-stained whole-slide images (WSIs), existing approaches often fail to capture the intricate biological heterogeneity within spots and are susceptible to morphological noise when integrating contextual information from surrounding tissue. To overcome these limitations, we propose HiFusion, a novel deep learning framework that integrates two complementary components. First, we introduce the Hierarchical Intra-Spot Modeling module that extracts fine-grained morphological representations through multi-resolution sub-patch decomposition, guided by a feature alignment loss to ensure semantic consistency across scales. Concurrently, we present the Context-aware Cross-scale Fusion module, which employs cross-attention to selectively incorporate biologically relevant regional context, thereby enhancing representational capacity. This architecture enables comprehensive modeling of both cellular-level features and tissue microenvironmental cues, which are essential for accurate gene expression prediction. Extensive experiments on two benchmark ST datasets demonstrate that HiFusion achieves state-of-the-art performance across both 2D slide-wise cross-validation and more challenging 3D sample-specific scenarios. These results underscore HiFusion's potential as a robust, accurate, and scalable solution for ST inference from routine histopathology.

</details>


### [142] [ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes](https://arxiv.org/abs/2511.12977)
*Yixuan Yang,Luyang Xie,Zhen Luo,Zixiang Zhao,Mingqi Gao,Feng Zheng*

Main category: cs.CV

TL;DR: ArtiWorld是一个场景感知管道，能够从文本场景描述中定位可关节化对象，并重建可执行的URDF模型，同时保持原始几何形状。核心组件Arti4URDF利用3D点云、大语言模型先验知识和URDF导向提示设计，将刚性对象快速转换为交互式URDF关节对象。


<details>
  <summary>Details</summary>
Motivation: 现有模拟环境中的3D资产大多是刚性的，手动将其转换为关节对象极其耗时耗力。需要一种自动识别场景中可关节化对象并将其转换为关节资产的方法。

Method: 使用Arti4URDF组件，结合3D点云、大语言模型先验知识和URDF导向提示设计，从文本场景描述中定位候选可关节化对象，并重建可执行的URDF模型。

Result: 在3D模拟对象、完整3D模拟场景和真实世界扫描场景三个层面进行评估，方法始终优于现有方法，达到最先进性能，同时保持对象几何形状并正确捕捉对象交互性。

Conclusion: 该方法为直接从现有3D资产构建交互式、机器人就绪的模拟环境提供了一条实用路径。

Abstract: Building interactive simulators and scalable robot-learning environments requires a large number of articulated assets. However, most existing 3D assets in simulation are rigid, and manually converting them into articulated objects is extremely labor- and cost-intensive. This raises a natural question: can we automatically identify articulable objects in a scene and convert them into articulated assets directly? In this paper, we present ArtiWorld, a scene-aware pipeline that localizes candidate articulable objects from textual scene descriptions and reconstructs executable URDF models that preserve the original geometry. At the core of this pipeline is Arti4URDF, which leverages 3D point cloud, prior knowledge of a large language model (LLM), and a URDF-oriented prompt design to rapidly convert rigid objects into interactive URDF-based articulated objects while maintaining their 3D shape. We evaluate ArtiWorld at three levels: 3D simulated objects, full 3D simulated scenes, and real-world scan scenes. Across all three settings, our method consistently outperforms existing approaches and achieves state-of-the-art performance, while preserving object geometry and correctly capturing object interactivity to produce usable URDF-based articulated models. This provides a practical path toward building interactive, robot-ready simulation environments directly from existing 3D assets. Code and data will be released.

</details>


### [143] [Concept Regions Matter: Benchmarking CLIP with a New Cluster-Importance Approach](https://arxiv.org/abs/2511.12978)
*Aishwarya Agarwal,Srikrishna Karanam,Vineet Gandhi*

Main category: cs.CV

TL;DR: 本文提出了CCI方法，利用CLIP的补丁嵌入对空间补丁进行语义聚类和掩码，评估模型预测的相对变化，在忠实性基准测试中达到新SOTA。还提出了COVAR基准来系统分离前景和背景影响，对18个CLIP变体进行全面评估。


<details>
  <summary>Details</summary>
Motivation: 对比视觉语言模型如CLIP在零样本识别方面表现强劲，但容易受到虚假相关性的影响，特别是对背景的过度依赖问题。现有基准如CounterAnimals仅依赖准确性，隐含地将所有性能下降归因于背景相关性，这种假设是不完整的。

Method: 提出了CCI方法：使用CLIP自身的补丁嵌入将空间补丁分组为语义连贯的簇，掩码这些簇，并评估模型预测的相对变化。结合GroundedSAM自动将预测分类为前景驱动或背景驱动。还提出了COVAR基准来系统变化对象前景和背景。

Result: CCI在忠实性基准测试中创造了新SOTA，在MS COCO检索的删除AUC指标上实现了超过两倍的改进。通过CCI与COVAR的结合，对18个CLIP变体进行了全面评估，揭示了除了背景相关性外，视角变化、尺度偏移和细粒度对象混淆也是错误的重要来源。

Conclusion: CCI方法提供了关键的诊断能力，COVAR基准能够系统分离不同影响因素。这些方法学进展和实证证据为构建更鲁棒的视觉语言模型指明了方向。

Abstract: Contrastive vision-language models (VLMs) such as CLIP achieve strong zero-shot recognition yet remain vulnerable to spurious correlations, particularly background over-reliance. We introduce Cluster-based Concept Importance (CCI), a novel interpretability method that uses CLIP's own patch embeddings to group spatial patches into semantically coherent clusters, mask them, and evaluate relative changes in model predictions. CCI sets a new state of the art on faithfulness benchmarks, surpassing prior methods by large margins; for example, it yields more than a twofold improvement on the deletion-AUC metric for MS COCO retrieval. We further propose that CCI, when combined with GroundedSAM, automatically categorizes predictions as foreground- or background-driven, providing a crucial diagnostic ability. Existing benchmarks such as CounterAnimals, however, rely solely on accuracy and implicitly attribute all performance degradation to background correlations. Our analysis shows this assumption to be incomplete, since many errors arise from viewpoint variation, scale shifts, and fine-grained object confusions. To disentangle these effects, we introduce COVAR, a benchmark that systematically varies object foregrounds and backgrounds. Leveraging CCI with COVAR, we present a comprehensive evaluation of eighteen CLIP variants, offering methodological advances and empirical evidence that chart a path toward more robust VLMs.

</details>


### [144] [UNSEEN: Enhancing Dataset Pruning from a Generalization Perspective](https://arxiv.org/abs/2511.12988)
*Furui Xu,Shaobo Wang,Jiajun Zhang,Chenghao Sun,Haixiang Tang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出UNSEEN框架，从泛化角度进行数据集剪枝，通过使用未在训练中见过的模型来评分样本，解决了传统方法中样本评分密集分布的问题，并在多步场景中优化核心集质量。


<details>
  <summary>Details</summary>
Motivation: 深度学习数据集规模增长带来计算挑战，传统数据集剪枝方法基于训练阶段模型性能评分，导致样本评分密集分布，难以有效区分样本重要性。

Method: 提出UNSEEN框架，从泛化角度评分样本，使用未在训练中见过的模型；扩展到多步场景，通过在不同核心集上训练的模型进行增量选择，动态优化核心集质量。

Result: 在CIFAR-10、CIFAR-100和ImageNet-1K上显著优于现有SOTA方法，在ImageNet-1K上减少30%训练数据的同时实现无损性能。

Conclusion: 从泛化角度进行数据集剪枝能有效解决传统方法的局限性，UNSEEN框架在多个数据集上表现出色，为大规模数据集的高效训练提供了有效解决方案。

Abstract: The growing scale of datasets in deep learning has introduced significant computational challenges. Dataset pruning addresses this challenge by constructing a compact but informative coreset from the full dataset with comparable performance. Previous approaches typically establish scoring metrics based on specific criteria to identify representative samples. However, these methods predominantly rely on sample scores obtained from the model's performance during the training (i.e., fitting) phase. As scoring models achieve near-optimal performance on training data, such fitting-centric approaches induce a dense distribution of sample scores within a narrow numerical range. This concentration reduces the distinction between samples and hinders effective selection. To address this challenge, we conduct dataset pruning from the perspective of generalization, i.e., scoring samples based on models not exposed to them during training. We propose a plug-and-play framework, UNSEEN, which can be integrated into existing dataset pruning methods. Additionally, conventional score-based methods are single-step and rely on models trained solely on the complete dataset, providing limited perspective on the importance of samples. To address this limitation, we scale UNSEEN to multi-step scenarios and propose an incremental selection technique through scoring models trained on varying coresets, and optimize the quality of the coreset dynamically. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art (SOTA) methods on CIFAR-10, CIFAR-100, and ImageNet-1K. Notably, on ImageNet-1K, UNSEEN achieves lossless performance while reducing training data by 30\%.

</details>


### [145] [Semantic Prioritization in Visual Counterfactual Explanations with Weighted Segmentation and Auto-Adaptive Region Selection](https://arxiv.org/abs/2511.12992)
*Lintong Zhang,Kang Yin,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 本文提出WSAE-Net方法，通过加权语义图和自适应候选编辑序列解决传统视觉反事实解释中语义相关性问题，提升模型可解释性和编辑效率。


<details>
  <summary>Details</summary>
Motivation: 传统非生成式视觉反事实解释方法在替换图像区域时忽略语义相关性，损害模型可解释性并阻碍编辑流程，需要改进。

Method: 提出WSAE-Net方法，包含两个关键创新：1）生成加权语义图以减少非语义特征单元计算；2）设计自适应候选编辑序列确定最优计算顺序。

Result: 通过全面实验验证，该方法表现出优越性能，有助于更清晰深入地理解视觉反事实解释。

Conclusion: WSAE-Net方法有效解决了传统视觉反事实解释中的语义相关性问题，提升了计算效率和模型可解释性。

Abstract: In the domain of non-generative visual counterfactual explanations (CE), traditional techniques frequently involve the substitution of sections within a query image with corresponding sections from distractor images. Such methods have historically overlooked the semantic relevance of the replacement regions to the target object, thereby impairing the model's interpretability and hindering the editing workflow. Addressing these challenges, the present study introduces an innovative methodology named as Weighted Semantic Map with Auto-adaptive Candidate Editing Network (WSAE-Net). Characterized by two significant advancements: the determination of an weighted semantic map and the auto-adaptive candidate editing sequence. First, the generation of the weighted semantic map is designed to maximize the reduction of non-semantic feature units that need to be computed, thereby optimizing computational efficiency. Second, the auto-adaptive candidate editing sequences are designed to determine the optimal computational order among the feature units to be processed, thereby ensuring the efficient generation of counterfactuals while maintaining the semantic relevance of the replacement feature units to the target object. Through comprehensive experimentation, our methodology demonstrates superior performance, contributing to a more lucid and in-depth understanding of visual counterfactual explanations.

</details>


### [146] [PerTouch: VLM-Driven Agent for Personalized and Semantic Image Retouching](https://arxiv.org/abs/2511.12998)
*Zewei Chang,Zheng-Peng Duan,Jianxing Zhang,Chun-Le Guo,Siyu Liu,Hyungju Chun,Hyunhee Park,Zikun Liu,Chongyi Li*

Main category: cs.CV

TL;DR: PerTouch是一个基于扩散模型的统一图像润色框架，支持语义级图像润色同时保持全局美学。通过参数映射、语义感知训练机制和VLM驱动的智能体，实现细粒度控制和个性化偏好对齐。


<details>
  <summary>Details</summary>
Motivation: 解决图像润色中可控性与主观性平衡的挑战，满足用户个性化审美偏好需求。

Method: 使用包含语义区域属性值的参数映射作为输入，构建显式参数到图像的映射；引入语义替换和参数扰动机制提升语义边界感知；开发VLM驱动的智能体处理强弱用户指令，配备反馈驱动重思考和场景感知记忆机制。

Result: 广泛实验验证了各组件有效性，PerTouch在个性化图像润色中表现出优越性能。

Conclusion: PerTouch框架成功实现了语义级图像润色与个性化偏好的有效对齐，为图像润色提供了可控且主观的解决方案。

Abstract: Image retouching aims to enhance visual quality while aligning with users' personalized aesthetic preferences. To address the challenge of balancing controllability and subjectivity, we propose a unified diffusion-based image retouching framework called PerTouch. Our method supports semantic-level image retouching while maintaining global aesthetics. Using parameter maps containing attribute values in specific semantic regions as input, PerTouch constructs an explicit parameter-to-image mapping for fine-grained image retouching. To improve semantic boundary perception, we introduce semantic replacement and parameter perturbation mechanisms in the training process. To connect natural language instructions with visual control, we develop a VLM-driven agent that can handle both strong and weak user instructions. Equipped with mechanisms of feedback-driven rethinking and scene-aware memory, PerTouch better aligns with user intent and captures long-term preferences. Extensive experiments demonstrate each component's effectiveness and the superior performance of PerTouch in personalized image retouching. Code is available at: https://github.com/Auroral703/PerTouch.

</details>


### [147] [Medal S: Spatio-Textual Prompt Model for Medical Segmentation](https://arxiv.org/abs/2511.13001)
*Pengcheng Shi,Jiawei Chen,Jiaqi Liu,Xinglin Zhang,Tao Chen,Lei Li*

Main category: cs.CV

TL;DR: Medal S是一个医学分割基础模型，支持原生分辨率空间和文本提示的端到端训练框架，在BiomedSegFM数据集上支持多达243个类别，在五模态验证集上DSC达到75.44，相比SAT有显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本方法缺乏空间感知能力的问题，通过通道对齐机制缓解分辨率不匹配带来的不准确性，实现高效的并行多类别分割。

Method: 采用轻量级3D卷积模块进行体素空间细化，支持文本提示和空间提示两种模式，提出动态重采样处理目标-补丁比例不平衡，并开发了优化的文本预处理、两阶段推理策略和后处理技术。

Result: 在24类分割任务中，并行空间提示比顺序提示减少90%以上的推理时间；在五模态验证集上，DSC为75.44（vs SAT 69.83），NSD为77.34（vs 71.06），F1为38.24（vs 24.88），DSC TP为65.46（vs 46.97）。

Conclusion: Medal S通过协调空间精度与语义文本指导，在多类别医学分割任务中展现出卓越的效率和准确性，优于基于顺序提示的方法。

Abstract: We introduce Medal S, a medical segmentation foundation model that supports native-resolution spatial and textual prompts within an end-to-end trainable framework. Unlike text-only methods lacking spatial awareness, Medal S achieves channel-wise alignment between volumetric prompts and text embeddings, mitigating inaccuracies from resolution mismatches. By preserving full 3D context, it efficiently processes multiple native-resolution masks in parallel, enhancing multi-class segmentation performance. A lightweight 3D convolutional module enables precise voxel-space refinement guided by both prompt types, supporting up to 243 classes across CT, MRI, PET, ultrasound, and microscopy modalities in the BiomedSegFM dataset. Medal S offers two prompting modes: a text-only mode, where model predictions serve as spatial prompts for self-refinement without human input, and a hybrid mode, incorporating manual annotations for enhanced flexibility. For 24-class segmentation, parallel spatial prompting reduces inference time by more than 90% compared to sequential prompting. We propose dynamic resampling to address target-patch ratio imbalance, extending SAT and nnU-Net for data augmentation. Furthermore, we develop optimized text preprocessing, a two-stage inference strategy, and post-processing techniques to improve memory efficiency, precision, and inference speed. On the five-modality average on the validation set, Medal S outperforms SAT with a DSC of 75.44 (vs. 69.83), NSD of 77.34 (vs. 71.06), F1 of 38.24 (vs. 24.88), and DSC TP of 65.46 (vs. 46.97). Medal S achieves excellent performance by harmonizing spatial precision with semantic textual guidance, demonstrating superior efficiency and accuracy in multi-class medical segmentation tasks compared to sequential prompt-based approaches. Medal S will be publicly available at https://github.com/yinghemedical/Medal-S.

</details>


### [148] [Infinite-Story: A Training-Free Consistent Text-to-Image Generation](https://arxiv.org/abs/2511.13002)
*Jihun Park,Kyoungmin Lee,Jongmin Gim,Hyeonseo Jo,Minseok Oh,Wonhyeok Choi,Kyumin Hwang,Jaeyeul Kim,Minwoo Choi,Sunghoon Im*

Main category: cs.CV

TL;DR: Infinite-Story是一个无需训练、基于尺度自回归模型的文本到图像生成框架，专门针对多提示词讲故事场景，解决了身份和风格不一致问题，推理速度比现有最快模型快6倍以上。


<details>
  <summary>Details</summary>
Motivation: 解决多提示词文本到图像生成中的身份不一致和风格不一致问题，同时避免现有方法需要微调或推理速度慢的缺点。

Method: 采用三种互补技术：身份提示词替换来减轻文本编码器的上下文偏差；统一注意力引导机制，包括自适应风格注入和同步引导适配，共同强制执行全局风格和身份外观一致性。

Result: 在广泛实验中，该方法实现了最先进的生成性能，推理速度达到每张图像1.72秒，比现有最快的一致文本到图像模型快6倍以上。

Conclusion: Infinite-Story框架在保持提示词保真度的同时，提供了高身份和风格一致性，展示了其在现实世界视觉讲故事应用中的有效性和实用性。

Abstract: We present Infinite-Story, a training-free framework for consistent text-to-image (T2I) generation tailored for multi-prompt storytelling scenarios. Built upon a scale-wise autoregressive model, our method addresses two key challenges in consistent T2I generation: identity inconsistency and style inconsistency. To overcome these issues, we introduce three complementary techniques: Identity Prompt Replacement, which mitigates context bias in text encoders to align identity attributes across prompts; and a unified attention guidance mechanism comprising Adaptive Style Injection and Synchronized Guidance Adaptation, which jointly enforce global style and identity appearance consistency while preserving prompt fidelity. Unlike prior diffusion-based approaches that require fine-tuning or suffer from slow inference, Infinite-Story operates entirely at test time, delivering high identity and style consistency across diverse prompts. Extensive experiments demonstrate that our method achieves state-of-the-art generation performance, while offering over 6X faster inference (1.72 seconds per image) than the existing fastest consistent T2I models, highlighting its effectiveness and practicality for real-world visual storytelling.

</details>


### [149] [SAGE: Spuriousness-Aware Guided Prompt Exploration for Mitigating Multimodal Bias](https://arxiv.org/abs/2511.13005)
*Wenqian Ye,Di Wang,Guangtao Zheng,Bohan Liu,Aidong Zhang*

Main category: cs.CV

TL;DR: 本文提出SAGE方法，通过引导提示选择来缓解CLIP模型中的多模态伪偏差问题，无需训练或微调即可提升零样本分类的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: CLIP等大视觉语言模型在零样本分类中表现出色，但存在多模态伪偏差问题，即模型倾向于依赖虚假特征（如背景）而非核心特征进行推断，这严重影响了模型在分布外数据上的鲁棒性。现有方法通常需要下游数据微调或先验偏差知识，限制了CLIP的开箱即用性。

Method: 提出SAGE方法，首先理论分析多模态伪偏差对零样本分类的影响，然后通过引导提示选择来缓解偏差。SAGE无需训练、微调或外部标注，通过探索提示模板空间并选择能诱导最大类别语义分离的提示，从而改善最差组鲁棒性。

Result: 在四个真实世界基准数据集和五个流行骨干模型上的广泛实验表明，SAGE能持续提升零样本性能和泛化能力，优于先前无需外部知识或模型更新的零样本方法。

Conclusion: SAGE是一种简单有效的零样本方法，能够在不依赖训练或外部知识的情况下缓解CLIP模型的多模态伪偏差，显著提升模型在分布外数据上的鲁棒性和泛化性能。

Abstract: Large vision-language models, such as CLIP, have shown strong zero-shot classification performance by aligning images and text in a shared embedding space. However, CLIP models often develop multimodal spurious biases, which is the undesirable tendency to rely on spurious features. For example, CLIP may infer object types in images based on frequently co-occurring backgrounds rather than the object's core features. This bias significantly impairs the robustness of pre-trained CLIP models on out-of-distribution data, where such cross-modal associations no longer hold. Existing methods for mitigating multimodal spurious bias typically require fine-tuning on downstream data or prior knowledge of the bias, which undermines the out-of-the-box usability of CLIP. In this paper, we first theoretically analyze the impact of multimodal spurious bias in zero-shot classification. Based on this insight, we propose Spuriousness-Aware Guided Exploration (SAGE), a simple and effective method that mitigates spurious bias through guided prompt selection. SAGE requires no training, fine-tuning, or external annotations. It explores a space of prompt templates and selects the prompts that induce the largest semantic separation between classes, thereby improving worst-group robustness. Extensive experiments on four real-world benchmark datasets and five popular backbone models demonstrate that SAGE consistently improves zero-shot performance and generalization, outperforming previous zero-shot approaches without any external knowledge or model updates.

</details>


### [150] [You Only Look Omni Gradient Backpropagation for Moving Infrared Small Target Detection](https://arxiv.org/abs/2511.13013)
*Guoyi Zhang,Guangsheng Xu,Siyang Chen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: 提出BP-FPN，一种基于反向传播的特征金字塔架构，通过梯度隔离低层捷径和方向梯度正则化来改进红外小目标检测，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法主要关注时空特征聚合，但增益有限，表明根本瓶颈在于模糊的单帧特征表示而非时空建模本身。

Method: 提出BP-FPN架构，包含梯度隔离低层捷径(GILS)来有效整合细粒度目标细节而不引发捷径学习，以及方向梯度正则化(DGR)来在反向传播中强制层次特征一致性。

Result: 在多个公共数据集上的广泛实验表明，BP-FPN始终建立新的最先进性能。

Conclusion: 这是首个完全从反向传播角度为该任务设计的FPN，设计具有理论依据，引入可忽略的计算开销，并能无缝集成到现有框架中。

Abstract: Moving infrared small target detection is a key component of infrared search and tracking systems, yet it remains extremely challenging due to low signal-to-clutter ratios, severe target-background imbalance, and weak discriminative features. Existing deep learning methods primarily focus on spatio-temporal feature aggregation, but their gains are limited, revealing that the fundamental bottleneck lies in ambiguous per-frame feature representations rather than spatio-temporal modeling itself. Motivated by this insight, we propose BP-FPN, a backpropagation-driven feature pyramid architecture that fundamentally rethinks feature learning for small target. BP-FPN introduces Gradient-Isolated Low-Level Shortcut (GILS) to efficiently incorporate fine-grained target details without inducing shortcut learning, and Directional Gradient Regularization (DGR) to enforce hierarchical feature consistency during backpropagation. The design is theoretically grounded, introduces negligible computational overhead, and can be seamlessly integrated into existing frameworks. Extensive experiments on multiple public datasets show that BP-FPN consistently establishes new state-of-the-art performance. To the best of our knowledge, it is the first FPN designed for this task entirely from the backpropagation perspective.

</details>


### [151] [MeanFlow Transformers with Representation Autoencoders](https://arxiv.org/abs/2511.13019)
*Zheyuan Hu,Chieh-Hsin Lai,Ge Wu,Yuki Mitsufuji,Stefano Ermon*

Main category: cs.CV

TL;DR: 提出了一种在表示自编码器（RAE）潜在空间中训练MeanFlow的高效方法，通过一致性中期训练和两阶段方案解决梯度爆炸问题，显著降低了训练和采样成本，并在ImageNet上取得了优异的生成质量。


<details>
  <summary>Details</summary>
Motivation: MeanFlow（MF）作为扩散模型虽然能实现高效少步生成，但在实际应用中存在训练计算量大、不稳定、推理成本高以及需要复杂引导参数等问题。

Method: 在RAE潜在空间中训练MF，采用一致性中期训练进行轨迹感知初始化，使用两阶段方案：先通过预训练流匹配教师进行蒸馏以加速收敛和减少方差，然后使用单点速度估计器进行可选的自举阶段以减少与理想平均流的偏差。

Result: 在ImageNet 256上实现了1步FID为2.03，优于原始MF的3.43，同时采样GFLOPS减少38%，总训练成本降低83%。在ImageNet 512上达到竞争性的1步FID 3.23，在所有基线中GFLOPS最低。

Conclusion: 该方法消除了对引导的需求，简化了训练配置，显著降低了训练和采样计算成本，同时保持了优异的生成质量，为高效生成模型提供了可行的解决方案。

Abstract: MeanFlow (MF) is a diffusion-motivated generative model that enables efficient few-step generation by learning long jumps directly from noise to data. In practice, it is often used as a latent MF by leveraging the pre-trained Stable Diffusion variational autoencoder (SD-VAE) for high-dimensional data modeling. However, MF training remains computationally demanding and is often unstable. During inference, the SD-VAE decoder dominates the generation cost, and MF depends on complex guidance hyperparameters for class-conditional generation. In this work, we develop an efficient training and sampling scheme for MF in the latent space of a Representation Autoencoder (RAE), where a pre-trained vision encoder (e.g., DINO) provides semantically rich latents paired with a lightweight decoder. We observe that naive MF training in the RAE latent space suffers from severe gradient explosion. To stabilize and accelerate training, we adopt Consistency Mid-Training for trajectory-aware initialization and use a two-stage scheme: distillation from a pre-trained flow matching teacher to speed convergence and reduce variance, followed by an optional bootstrapping stage with a one-point velocity estimator to further reduce deviation from the oracle mean flow. This design removes the need for guidance, simplifies training configurations, and reduces computation in both training and sampling. Empirically, our method achieves a 1-step FID of 2.03, outperforming vanilla MF's 3.43, while reducing sampling GFLOPS by 38% and total training cost by 83% on ImageNet 256. We further scale our approach to ImageNet 512, achieving a competitive 1-step FID of 3.23 with the lowest GFLOPS among all baselines. Code is available at https://github.com/sony/mf-rae.

</details>


### [152] [SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction](https://arxiv.org/abs/2511.13020)
*Yufei Wen,Yuting Zhang,Jingdan Kang,Hao Ren,Weibin Cheng,Jintai Chen,Kaishun Wu*

Main category: cs.CV

TL;DR: 提出了SpectralAdapt半监督域适应框架，通过光谱密度掩蔽和光谱端元表示对齐技术，解决医学HSI重建中的数据稀缺和域差异问题。


<details>
  <summary>Details</summary>
Motivation: 解决医学应用中HSI数据稀缺问题，通过域适应方法利用丰富的通用领域HSI数据来提升医学HSI重建性能。

Method: 提出SpectralAdapt框架，包含光谱密度掩蔽（自适应掩蔽RGB通道）和光谱端元表示对齐（使用物理可解释端元作为域不变锚点）。

Result: 在基准数据集上实验显示，在光谱保真度、跨域泛化能力和训练稳定性方面均有持续改进。

Conclusion: SSDA为医疗保健中的高光谱成像提供了一种高效的解决方案，能够有效缓解域偏移、光谱退化和数据稀缺问题。

Abstract: Hyperspectral imaging (HSI) holds great potential for healthcare due to its rich spectral information. However, acquiring HSI data remains costly and technically demanding. Hyperspectral image reconstruction offers a practical solution by recovering HSI data from accessible modalities, such as RGB. While general domain datasets are abundant, the scarcity of human HSI data limits progress in medical applications. To tackle this, we propose SpectralAdapt, a semi-supervised domain adaptation (SSDA) framework that bridges the domain gap between general and human-centered HSI datasets. To fully exploit limited labels and abundant unlabeled data, we enhance spectral reasoning by introducing Spectral Density Masking (SDM), which adaptively masks RGB channels based on their spectral complexity, encouraging recovery of informative regions from complementary cues during consistency training. Furthermore, we introduce Spectral Endmember Representation Alignment (SERA), which derives physically interpretable endmembers from valuable labeled pixels and employs them as domain-invariant anchors to guide unlabeled predictions, with momentum updates ensuring adaptability and stability. These components are seamlessly integrated into SpectralAdapt, a spectral prior-guided framework that effectively mitigates domain shift, spectral degradation, and data scarcity in HSI reconstruction. Experiments on benchmark datasets demonstrate consistent improvements in spectral fidelity, cross-domain generalization, and training stability, highlighting the promise of SSDA as an efficient solution for hyperspectral imaging in healthcare.

</details>


### [153] [REVISOR: Beyond Textual Reflection, Towards Multimodal Introspective Reasoning in Long-Form Video Understanding](https://arxiv.org/abs/2511.13026)
*Jiaze Li,Hao Yin,Wenhui Tan,Jingyang Chen,Boshen Xu,Yuxun Qu,Yijing Chen,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: 本文提出了REVISOR框架，通过跨模态反思机制增强多模态大模型在长视频理解任务中的推理能力，无需额外监督微调或外部模型即可在多个基准测试中取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 传统基于纯文本的反思机制在长视频理解中存在局限性：1）长视频包含更丰富动态的视觉信息，仅反思文本信息不足；2）纯文本反思缺乏跨模态交互能力，无法充分整合视觉信息。

Method: 提出REVISOR框架，支持文本和视觉模态的协作反思过程，并设计了双归因解耦奖励机制，集成到GRPO训练策略中，确保模型推理与所选视频证据之间的因果对齐。

Result: 在VideoMME、LongVideoBench、MLVU和LVBench四个基准测试中取得了令人印象深刻的结果，显著提升了多模态大模型的长视频理解能力。

Conclusion: REVISOR框架通过跨模态反思机制有效解决了长视频理解中的视觉信息整合问题，为多模态大模型的长视频理解任务提供了有效的解决方案。

Abstract: Self-reflection mechanisms that rely on purely text-based rethinking processes perform well in most multimodal tasks. However, when directly applied to long-form video understanding scenarios, they exhibit clear limitations. The fundamental reasons for this lie in two points: (1)long-form video understanding involves richer and more dynamic visual input, meaning rethinking only the text information is insufficient and necessitates a further rethinking process specifically targeting visual information; (2) purely text-based reflection mechanisms lack cross-modal interaction capabilities, preventing them from fully integrating visual information during reflection. Motivated by these insights, we propose REVISOR (REflective VIsual Segment Oriented Reasoning), a novel framework for tool-augmented multimodal reflection. REVISOR enables MLLMs to collaboratively construct introspective reflection processes across textual and visual modalities, significantly enhancing their reasoning capability for long-form video understanding. To ensure that REVISOR can learn to accurately review video segments highly relevant to the question during reinforcement learning, we designed the Dual Attribution Decoupled Reward (DADR) mechanism. Integrated into the GRPO training strategy, this mechanism enforces causal alignment between the model's reasoning and the selected video evidence. Notably, the REVISOR framework significantly enhances long-form video understanding capability of MLLMs without requiring supplementary supervised fine-tuning or external models, achieving impressive results on four benchmarks including VideoMME, LongVideoBench, MLVU, and LVBench.

</details>


### [154] [Towards 3D Object-Centric Feature Learning for Semantic Scene Completion](https://arxiv.org/abs/2511.13031)
*Weihua Wang,Yubo Cui,Xiangru Lin,Zhiheng Li,Zheng Fang*

Main category: cs.CV

TL;DR: Ocean是一个面向对象的3D语义场景补全框架，通过将场景分解为独立对象实例来提高语义占用预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常采用以自我为中心的范式，在整个场景中聚合和扩散特征，但忽略了细粒度的对象级细节，导致复杂环境中的语义和几何模糊。

Method: 首先使用轻量级分割模型MobileSAM从输入图像中提取实例掩码；然后引入3D语义组注意力模块，利用线性注意力在3D空间中聚合面向对象的特征；设计全局相似性引导注意力模块处理分割错误和缺失实例；最后提出实例感知局部扩散模块，通过生成过程改进实例特征并在BEV空间中细化场景表示。

Result: 在SemanticKITTI和SSCBench-KITTI360基准测试中，Ocean分别实现了17.40和20.28的mIoU分数，达到了最先进的性能。

Conclusion: Ocean通过面向对象的方法有效解决了3D语义场景补全中的语义和几何模糊问题，在复杂环境中表现出优越的性能。

Abstract: Vision-based 3D Semantic Scene Completion (SSC) has received growing attention due to its potential in autonomous driving. While most existing approaches follow an ego-centric paradigm by aggregating and diffusing features over the entire scene, they often overlook fine-grained object-level details, leading to semantic and geometric ambiguities, especially in complex environments. To address this limitation, we propose Ocean, an object-centric prediction framework that decomposes the scene into individual object instances to enable more accurate semantic occupancy prediction. Specifically, we first employ a lightweight segmentation model, MobileSAM, to extract instance masks from the input image. Then, we introduce a 3D Semantic Group Attention module that leverages linear attention to aggregate object-centric features in 3D space. To handle segmentation errors and missing instances, we further design a Global Similarity-Guided Attention module that leverages segmentation features for global interaction. Finally, we propose an Instance-aware Local Diffusion module that improves instance features through a generative process and subsequently refines the scene representation in the BEV space. Extensive experiments on the SemanticKITTI and SSCBench-KITTI360 benchmarks demonstrate that Ocean achieves state-of-the-art performance, with mIoU scores of 17.40 and 20.28, respectively.

</details>


### [155] [uCLIP: Parameter-Efficient Multilingual Extension of Vision-Language Models with Unpaired Data](https://arxiv.org/abs/2511.13036)
*Dahyun Chung,Donghyun Shin,Yujin Sung,Seunggi Moon,Jinwoo Jeon,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级、数据高效的多语言视觉-语言对齐框架，无需图像-文本对或文本-文本对，仅训练一个170万参数的投影模块，使用英语表示作为语义锚点进行对比学习，显著提升了在捷克语、芬兰语、克罗地亚语、匈牙利语和罗马尼亚语等资源匮乏语言上的检索性能。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在英语视觉任务上表现出色，但在低资源语言上的扩展受限，因为缺乏高质量的多语言图像-文本数据。现有多语言视觉-语言模型在XM3600基准测试中对捷克语、芬兰语、克罗地亚语、匈牙利语和罗马尼亚语等代表性不足语言的检索性能普遍较低。

Method: 提出轻量级数据高效框架，冻结预训练的图像编码器和多语言文本编码器，仅训练一个紧凑的170万参数投影模块，使用英语表示作为语义锚点进行对比损失训练，无需图像-文本对或文本-文本对。

Result: 在多个多语言检索基准测试上的广泛评估证实了方法的有效性，在五个代表性不足语言上显示出显著提升，这些语言正是现有模型通常表现不佳的地方。

Conclusion: 研究结果突显了基于枢轴、参数高效的对齐策略在包容性多模态学习中的有效性，为资源匮乏语言提供了稳健的多语言对齐解决方案。

Abstract: Contrastive Language-Image Pre-training (CLIP) has demonstrated strong generalization across a wide range of visual tasks by leveraging large-scale English-image pairs. However, its extension to low-resource languages remains limited due to the scarcity of high-quality multilingual image-text data. Existing multilingual vision-language models exhibit consistently low retrieval performance in underrepresented languages including Czech, Finnish, Croatian, Hungarian, and Romanian on the Crossmodal-3600 (XM3600) benchmark. To address this, we propose a lightweight and data-efficient framework for multilingual vision-language alignment. Our approach requires no image-text pairs or text-text pairs and freezes both the pretrained image encoder and multilingual text encoder during training. Only a compact 1.7M-parameter projection module is trained, using a contrastive loss over English representations as semantic anchors. This minimal training setup enables robust multilingual alignment even for languages with limited supervision. Extensive evaluation across multiple multilingual retrieval benchmarks confirms the effectiveness of our method, showing significant gains in five underrepresented languages where existing models typically underperform. These findings highlight the effectiveness of our pivot-based, parameter-efficient alignment strategy for inclusive multimodal learning.

</details>


### [156] [DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation](https://arxiv.org/abs/2511.13047)
*Yan Gong,Jianli Lu,Yongsheng Gao,Jie Zhao,Xiaojuan Zhang,Susanto Rahardja*

Main category: cs.CV

TL;DR: DiffPixelFormer是一种用于RGB-D室内场景语义分割的差分像素感知Transformer，通过增强模态内表示和建模模态间交互来提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D融合方法依赖计算密集的跨注意力机制，对模态内和模态间特征关系建模不足，导致特征对齐不精确和判别性表示受限。

Method: 提出Intra-Inter Modal Interaction Block (IIMIB)，通过自注意力捕获模态内长程依赖，使用Differential-Shared Inter-Modal (DSIM)模块建模模态间交互，分离模态特定和共享线索，实现像素级跨模态对齐。采用动态融合策略平衡模态贡献。

Result: 在SUN RGB-D和NYUDv2基准测试中，DiffPixelFormer-L分别达到54.28%和59.95%的mIoU，比DFormer-L分别提升1.78%和2.75%。

Conclusion: DiffPixelFormer通过有效的模态内表示增强和模态间交互建模，显著提升了RGB-D室内语义分割性能。

Abstract: Indoor semantic segmentation is fundamental to computer vision and robotics, supporting applications such as autonomous navigation, augmented reality, and smart environments. Although RGB-D fusion leverages complementary appearance and geometric cues, existing methods often depend on computationally intensive cross-attention mechanisms and insufficiently model intra- and inter-modal feature relationships, resulting in imprecise feature alignment and limited discriminative representation. To address these challenges, we propose DiffPixelFormer, a differential pixel-aware Transformer for RGB-D indoor scene segmentation that simultaneously enhances intra-modal representations and models inter-modal interactions. At its core, the Intra-Inter Modal Interaction Block (IIMIB) captures intra-modal long-range dependencies via self-attention and models inter-modal interactions with the Differential-Shared Inter-Modal (DSIM) module to disentangle modality-specific and shared cues, enabling fine-grained, pixel-level cross-modal alignment. Furthermore, a dynamic fusion strategy balances modality contributions and fully exploits RGB-D information according to scene characteristics. Extensive experiments on the SUN RGB-D and NYUDv2 benchmarks demonstrate that DiffPixelFormer-L achieves mIoU scores of 54.28% and 59.95%, outperforming DFormer-L by 1.78% and 2.75%, respectively. Code is available at https://github.com/gongyan1/DiffPixelFormer.

</details>


### [157] [ViSS-R1: Self-Supervised Reinforcement Video Reasoning](https://arxiv.org/abs/2511.13054)
*Bo Fang,Yuxin Song,Qiangqiang Wu,Haoyuan Sun,Wenhao Wu,Antoni B. Chan*

Main category: cs.CV

TL;DR: 本文提出了Pretext-GRPO算法和ViSS-R1框架，通过自监督强化学习增强多模态大语言模型在视频推理中的视觉中心理解能力，避免对文本信息的过度依赖和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于R1的方法在视频推理任务中往往过度依赖文本信息，未能充分利用丰富的视觉信息，容易导致捷径学习和幻觉问题。需要开发更鲁棒的视觉中心视频理解方法。

Method: 1. 提出自监督强化学习算法Pretext-GRPO，通过对变换后的视觉输入正确解决前置任务来分配正奖励；2. 提出ViSS-R1框架，将前置任务自监督学习直接集成到MLLM的R1后训练范式中，同时处理前置问题和真实用户查询。

Result: 在六个广泛使用的视频推理和理解基准测试上进行了全面评估，证明了Pretext-GRPO和ViSS-R1在复杂视频推理中的有效性和优越性。

Conclusion: 所提出的方法能够强制模型对变换后的视觉输入进行推理，通过识别应用的变换和重建原始视频来制定准确的最终答案，显著提升了视频推理性能。

Abstract: Complex video reasoning remains a significant challenge for Multimodal Large Language Models (MLLMs), as current R1-based methodologies often prioritize text-centric reasoning derived from text-based and image-based developments. In video tasks, such strategies frequently underutilize rich visual information, leading to potential shortcut learning and increased susceptibility to hallucination. To foster a more robust, visual-centric video understanding, we start by introducing a novel self-supervised reinforcement learning GRPO algorithm (Pretext-GRPO) within the standard R1 pipeline, in which positive rewards are assigned for correctly solving pretext tasks on transformed visual inputs, which makes the model to non-trivially process the visual information. Building on the effectiveness of Pretext-GRPO, we further propose the ViSS-R1 framework, which streamlines and integrates pretext-task-based self-supervised learning directly into the MLLM's R1 post-training paradigm. Instead of relying solely on sparse visual cues, our framework compels models to reason about transformed visual input by simultaneously processing both pretext questions (concerning transformations) and true user queries. This necessitates identifying the applied transformation and reconstructing the original video to formulate accurate final answers. Comprehensive evaluations on six widely-used video reasoning and understanding benchmarks demonstrate the effectiveness and superiority of our Pretext-GRPO and ViSS-R1 for complex video reasoning. Our codes and models will be publicly available.

</details>


### [158] [Monocular 3D Lane Detection via Structure Uncertainty-Aware Network with Curve-Point Queries](https://arxiv.org/abs/2511.13055)
*Ruixin Liu,Zejian Yuan*

Main category: cs.CV

TL;DR: MonoUnc是一个无需鸟瞰图的单目3D车道线检测器，通过局部车道结构建模来显式处理观测噪声引起的不确定性，在多个数据集上超越了现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 现有的单目3D车道线检测方法依赖于简化的几何假设，如独立点预测或全局平面建模，无法捕捉真实场景中的结构变化和随机不确定性。

Method: 将3D车道线投影到前视图空间并用参数化曲线近似，基于曲线预测动态生成曲线点查询嵌入，将相邻点形成的线段建模为3D高斯分布，并设计了新的3D高斯匹配损失函数。

Result: 在ONCE-3DLanes和OpenLane数据集上的实验表明，MonoUnc在更严格的评估标准下在所有基准测试中都优于之前的最优方法。

Conclusion: MonoUnc通过显式建模局部车道结构的不确定性，有效提升了单目3D车道线检测的精度和鲁棒性。

Abstract: Monocular 3D lane detection is challenged by aleatoric uncertainty arising from inherent observation noise. Existing methods rely on simplified geometric assumptions, such as independent point predictions or global planar modeling, failing to capture structural variations and aleatoric uncertainty in real-world scenarios. In this paper, we propose MonoUnc, a bird's-eye view (BEV)-free 3D lane detector that explicitly models aleatoric uncertainty informed by local lane structures. Specifically, 3D lanes are projected onto the front-view (FV) space and approximated by parametric curves. Guided by curve predictions, curve-point query embeddings are dynamically generated for lane point predictions in 3D space. Each segment formed by two adjacent points is modeled as a 3D Gaussian, parameterized by the local structure and uncertainty estimations. Accordingly, a novel 3D Gaussian matching loss is designed to constrain these parameters jointly. Experiments on the ONCE-3DLanes and OpenLane datasets demonstrate that MonoUnc outperforms previous state-of-the-art (SoTA) methods across all benchmarks under stricter evaluation criteria. Additionally, we propose two comprehensive evaluation metrics for ONCE-3DLanes, calculating the average and maximum bidirectional Chamfer distances to quantify global and local errors. Codes are released at https://github.com/lrx02/MonoUnc.

</details>


### [159] [RobustGait: Robustness Analysis for Appearance Based Gait Recognition](https://arxiv.org/abs/2511.13065)
*Reeshoon Sayera,Akash Kumar,Sirshapan Mitra,Prudvi Kamtam,Yogesh S Rawat*

Main category: cs.CV

TL;DR: 提出了RobustGait框架，用于评估基于外观的步态识别系统在真实世界干扰和轮廓变化下的鲁棒性，涵盖四种扰动类型、多种轮廓提取方法和模型架构，发现了噪声传播、轮廓提取器偏差等关键问题，并提出了噪声感知训练和知识蒸馏等增强策略。


<details>
  <summary>Details</summary>
Motivation: 现有基于外观的步态识别系统在受控数据集上表现良好，但缺乏对其在真实世界干扰和轮廓变化下鲁棒性的系统性评估。

Method: 开发RobustGait框架，在四个维度进行评估：扰动类型（数字、环境、时间、遮挡）、轮廓提取方法、步态识别模型架构容量和部署场景，引入15种干扰类型和5个严重级别，在多个数据集上评估6个最先进的步态系统。

Result: 发现RGB级别噪声能更好反映真实世界退化；步态精度对轮廓提取器偏差高度敏感；鲁棒性既取决于扰动类型也取决于架构设计；噪声感知训练和知识蒸馏能有效提升性能。

Conclusion: 步态识别系统的鲁棒性评估揭示了轮廓提取器偏差这一被忽视的基准偏差来源，通过适当的训练策略可以显著提升系统鲁棒性，推动系统向可部署状态发展。

Abstract: Appearance-based gait recognition have achieved strong performance on controlled datasets, yet systematic evaluation of its robustness to real-world corruptions and silhouette variability remains lacking. We present RobustGait, a framework for fine-grained robustness evaluation of appearance-based gait recognition systems. RobustGait evaluation spans four dimensions: the type of perturbation (digital, environmental, temporal, occlusion), the silhouette extraction method (segmentation and parsing networks), the architectural capacities of gait recognition models, and various deployment scenarios. The benchmark introduces 15 corruption types at 5 severity levels across CASIA-B, CCPG, and SUSTech1K, with in-the-wild validation on MEVID, and evaluates six state-of-the-art gait systems. We came across several exciting insights. First, applying noise at the RGB level better reflects real-world degradation, and reveal how distortions propagate through silhouette extraction to the downstream gait recognition systems. Second, gait accuracy is highly sensitive to silhouette extractor biases, revealing an overlooked source of benchmark bias. Third, robustness is dependent on both the type of perturbation and the architectural design. Finally, we explore robustness-enhancing strategies, showing that noise-aware training and knowledge distillation improve performance and move toward deployment-ready systems.

</details>


### [160] [Decoupling Scene Perception and Ego Status: A Multi-Context Fusion Approach for Enhanced Generalization in End-to-End Autonomous Driving](https://arxiv.org/abs/2511.13079)
*Jiacheng Tang,Mingyue Feng,Jiachao Liu,Yaonong Wang,Jian Pu*

Main category: cs.CV

TL;DR: 本文提出AdaptiveAD架构，通过双分支结构解耦场景感知和自车状态，解决现有端到端自动驾驶系统过度依赖自车状态的问题，提升泛化能力和场景理解鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有模块化自动驾驶系统过度依赖自车状态，导致泛化能力受限和场景理解不鲁棒。根本原因在于架构设计中自车状态过早融合到BEV编码器中，形成信息捷径。

Method: 提出AdaptiveAD架构：1) 双分支结构分别进行场景驱动推理（多任务学习但排除自车状态）和自车驱动推理；2) 场景感知融合模块自适应整合两分支决策；3) 路径注意力机制实现自车-BEV交互；4) BEV单向蒸馏和自回归在线映射辅助任务。

Result: 在nuScenes数据集上的广泛评估表明，AdaptiveAD实现了最先进的开环规划性能，显著减轻了对自车状态的过度依赖，并在多样化场景中展现出令人印象深刻的泛化能力。

Conclusion: AdaptiveAD通过架构层面的多上下文融合策略有效解决了自动驾驶系统中过度依赖自车状态的问题，为构建更鲁棒和泛化的端到端系统提供了新思路。

Abstract: Modular design of planning-oriented autonomous driving has markedly advanced end-to-end systems. However, existing architectures remain constrained by an over-reliance on ego status, hindering generalization and robust scene understanding. We identify the root cause as an inherent design within these architectures that allows ego status to be easily leveraged as a shortcut. Specifically, the premature fusion of ego status in the upstream BEV encoder allows an information flow from this strong prior to dominate the downstream planning module. To address this challenge, we propose AdaptiveAD, an architectural-level solution based on a multi-context fusion strategy. Its core is a dual-branch structure that explicitly decouples scene perception and ego status. One branch performs scene-driven reasoning based on multi-task learning, but with ego status deliberately omitted from the BEV encoder, while the other conducts ego-driven reasoning based solely on the planning task. A scene-aware fusion module then adaptively integrates the complementary decisions from the two branches to form the final planning trajectory. To ensure this decoupling does not compromise multi-task learning, we introduce a path attention mechanism for ego-BEV interaction and add two targeted auxiliary tasks: BEV unidirectional distillation and autoregressive online mapping. Extensive evaluations on the nuScenes dataset demonstrate that AdaptiveAD achieves state-of-the-art open-loop planning performance. Crucially, it significantly mitigates the over-reliance on ego status and exhibits impressive generalization capabilities across diverse scenarios.

</details>


### [161] [Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations](https://arxiv.org/abs/2511.13081)
*Yehonatan Elisha,Seffi Cohen,Oren Barkan,Noam Koenigstein*

Main category: cs.CV

TL;DR: 本文提出了RFxG分类法，从参考框架和粒度两个维度组织显著性解释，并开发了新的评估指标来系统评估解释方法的质量。


<details>
  <summary>Details</summary>
Motivation: 显著性图在深度学习视觉解释中广泛使用，但缺乏关于其预期目的和与不同用户查询一致性的共识，这种模糊性阻碍了解释方法的有效评估和实际效用。

Method: 引入Reference-Frame × Granularity (RFxG)分类法，这是一个原则性的概念框架，将显著性解释组织在两个基本轴上：参考框架（点对点vs对比）和粒度（细粒度类级vs粗粒度组级）。提出了四个新的忠实性指标来系统评估解释质量。

Result: 通过RFxG视角揭示了现有评估指标的关键局限性，这些指标过度优先考虑点对点忠实性而忽视对比推理和语义粒度。对十个最先进的显著性方法、四个模型架构和三个数据集进行了全面评估。

Conclusion: 通过倡导向用户意图驱动的评估转变，本研究为开发不仅忠实于底层模型行为，而且与人类理解和查询复杂性有意义的视觉解释提供了概念基础和实践工具。

Abstract: Saliency maps are widely used for visual explanations in deep learning, but a fundamental lack of consensus persists regarding their intended purpose and alignment with diverse user queries. This ambiguity hinders the effective evaluation and practical utility of explanation methods.We address this gap by introducing the Reference-Frame $\times$ Granularity (RFxG) taxonomy, a principled conceptual framework that organizes saliency explanations along two essential axes:Reference-Frame: Distinguishing between pointwise ("Why this prediction?") and contrastive ("Why this and not an alternative?") explanations.Granularity: Ranging from fine-grained class-level (e.g., "Why Husky?") to coarse-grained group-level (e.g., "Why Dog?") interpretations.Using the RFxG lens, we demonstrate critical limitations in existing evaluation metrics, which overwhelmingly prioritize pointwise faithfulness while neglecting contrastive reasoning and semantic granularity. To systematically assess explanation quality across both RFxG dimensions, we propose four novel faithfulness metrics. Our comprehensive evaluation framework applies these metrics to ten state-of-the-art saliency methods, four model architectures, and three datasets.By advocating a shift toward user-intent-driven evaluation, our work provides both the conceptual foundation and the practical tools necessary to develop visual explanations that are not only faithful to the underlying model behavior but are also meaningfully aligned with the complexity of human understanding and inquiry.

</details>


### [162] [PlugTrack: Multi-Perceptive Motion Analysis for Adaptive Fusion in Multi-Object Tracking](https://arxiv.org/abs/2511.13105)
*Seungjae Kim,SeungJoon Lee,MyeongAh Cho*

Main category: cs.CV

TL;DR: PlugTrack是一个新颖的多目标跟踪框架，通过自适应融合卡尔曼滤波器和数据驱动的运动预测器来解决线性与非线性运动模式问题，在多个数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统卡尔曼滤波器在非线性运动模式下表现不佳，而数据驱动的运动预测器虽然能捕捉复杂非线性动态，但存在领域泛化能力有限和计算开销大的问题。研究发现现实跟踪场景同时包含线性和非线性运动模式。

Method: 提出PlugTrack框架，通过多感知运动理解自适应融合卡尔曼滤波器和数据驱动运动预测器，使用多感知运动分析生成自适应混合因子，无需修改现有运动预测器。

Result: 在MOT17/MOT20数据集上取得显著性能提升，在DanceTrack数据集上达到最先进水平，卡尔曼滤波器在非线性运动主导的数据集中仍能在34%的情况下优于数据驱动预测器。

Conclusion: PlugTrack是首个通过自适应融合桥接经典与现代运动预测范式的多目标跟踪框架，有效利用了不同预测器的互补优势。

Abstract: Multi-object tracking (MOT) predominantly follows the tracking-by-detection paradigm, where Kalman filters serve as the standard motion predictor due to computational efficiency but inherently fail on non-linear motion patterns. Conversely, recent data-driven motion predictors capture complex non-linear dynamics but suffer from limited domain generalization and computational overhead. Through extensive analysis, we reveal that even in datasets dominated by non-linear motion, Kalman filter outperforms data-driven predictors in up to 34\% of cases, demonstrating that real-world tracking scenarios inherently involve both linear and non-linear patterns. To leverage this complementarity, we propose PlugTrack, a novel framework that adaptively fuses Kalman filter and data-driven motion predictors through multi-perceptive motion understanding. Our approach employs multi-perceptive motion analysis to generate adaptive blending factors. PlugTrack achieves significant performance gains on MOT17/MOT20 and state-of-the-art on DanceTrack without modifying existing motion predictors. To the best of our knowledge, PlugTrack is the first framework to bridge classical and modern motion prediction paradigms through adaptive fusion in MOT.

</details>


### [163] [Low-Level Dataset Distillation for Medical Image Enhancement](https://arxiv.org/abs/2511.13106)
*Fengzhi Xu,Ziyuan Yang,Mengyu Sun,Joey Tianyi Zhou,Yi Zhang*

Main category: cs.CV

TL;DR: 本文提出了首个用于医学图像增强的低级数据集蒸馏方法，通过共享解剖先验和结构保持个性化生成模块，在保护隐私的同时实现高效的数据压缩。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像增强方法需要大规模数据集学习复杂像素级映射，但训练和存储成本高昂。现有数据集蒸馏方法主要针对高级任务，而低级任务的像素级保真度要求使得传统方法不适用。

Method: 利用患者间的解剖相似性构建共享解剖先验作为初始化，通过结构保持个性化生成模块将患者特定解剖信息整合到蒸馏数据中，同时保持像素级保真度。通过梯度对齐将患者特定知识注入蒸馏数据。

Result: 提出的方法能够构建包含抽象训练信息的蒸馏数据集，无需访问原始患者数据，在保护隐私的同时实现高效的数据压缩。

Conclusion: 该方法为医学图像增强提供了一种隐私保护的高效数据蒸馏解决方案，解决了低级任务中像素级保真度要求的挑战。

Abstract: Medical image enhancement is clinically valuable, but existing methods require large-scale datasets to learn complex pixel-level mappings. However, the substantial training and storage costs associated with these datasets hinder their practical deployment. While dataset distillation (DD) can alleviate these burdens, existing methods mainly target high-level tasks, where multiple samples share the same label. This many-to-one mapping allows distilled data to capture shared semantics and achieve information compression. In contrast, low-level tasks involve a many-to-many mapping that requires pixel-level fidelity, making low-level DD an underdetermined problem, as a small distilled dataset cannot fully constrain the dense pixel-level mappings. To address this, we propose the first low-level DD method for medical image enhancement. We first leverage anatomical similarities across patients to construct the shared anatomical prior based on a representative patient, which serves as the initialization for the distilled data of different patients. This prior is then personalized for each patient using a Structure-Preserving Personalized Generation (SPG) module, which integrates patient-specific anatomical information into the distilled dataset while preserving pixel-level fidelity. For different low-level tasks, the distilled data is used to construct task-specific high- and low-quality training pairs. Patient-specific knowledge is injected into the distilled data by aligning the gradients computed from networks trained on the distilled pairs with those from the corresponding patient's raw data. Notably, downstream users cannot access raw patient data. Instead, only a distilled dataset containing abstract training information is shared, which excludes patient-specific details and thus preserves privacy.

</details>


### [164] [Learning Implicit Neural Degradation Representation for Unpaired Image Dehazing](https://arxiv.org/abs/2511.13110)
*Shuaibin Fan,Senming Zhong,Wenchao Yan,Minglong Xue*

Main category: cs.CV

TL;DR: 本文提出了一种基于隐式神经退化表示的无监督去雾方法，通过结合通道独立和通道依赖机制来增强非线性依赖学习能力，并设计隐式神经表示将雾霾退化建模为连续函数，在复杂场景中实现高质量图像恢复。


<details>
  <summary>Details</summary>
Motivation: 现有去雾方法在处理复杂场景时难以平衡非均匀雾霾分布的细粒度特征表示与全局一致性建模，且需要更好地学习雾霾在空间变化中的共同退化表示。

Method: 1. 基于Kolmogorov-Arnold表示定理，提出通道独立与通道依赖机制结合的方法；2. 设计隐式神经表示将雾霾退化建模为连续函数；3. 设计密集残差增强模块来学习雾霾特征的隐式表示。

Result: 实验结果表明，该方法在各种公共和真实世界数据集上实现了具有竞争力的去雾性能。

Conclusion: 该方法通过隐式神经退化表示和密集残差增强模块，在复杂场景中实现了高质量图像去雾，具有良好的视觉感知效果。

Abstract: Image dehazing is an important task in the field of computer vision, aiming at restoring clear and detail-rich visual content from haze-affected images. However, when dealing with complex scenes, existing methods often struggle to strike a balance between fine-grained feature representation of inhomogeneous haze distribution and global consistency modeling. Furthermore, to better learn the common degenerate representation of haze in spatial variations, we propose an unsupervised dehaze method for implicit neural degradation representation. Firstly, inspired by the Kolmogorov-Arnold representation theorem, we propose a mechanism combining the channel-independent and channel-dependent mechanisms, which efficiently enhances the ability to learn from nonlinear dependencies. which in turn achieves good visual perception in complex scenes. Moreover, we design an implicit neural representation to model haze degradation as a continuous function to eliminate redundant information and the dependence on explicit feature extraction and physical models. To further learn the implicit representation of the haze features, we also designed a dense residual enhancement module from it to eliminate redundant information. This achieves high-quality image restoration. Experimental results show that our method achieves competitive dehaze performance on various public and real-world datasets. This project code will be available at https://github.com/Fan-pixel/NeDR-Dehaze.

</details>


### [165] [CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model](https://arxiv.org/abs/2511.13121)
*Yuqi Zhang,Guanying Chen,Jiaxing Chen,Chuanyu Fu,Chuan Huang,Shuguang Cui*

Main category: cs.CV

TL;DR: CloseUpShot是一个基于扩散模型的框架，用于从稀疏输入视图合成近距离新视角，通过点条件视频扩散解决近距离场景中细节重建的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要针对适度的视角变化，在近距离场景中由于输入信息严重受限，难以捕捉细粒度细节。视频扩散模型具有强大的时序推理能力，但在近距离设置下像素扭曲条件存在严重稀疏性和背景泄漏问题。

Method: 提出了分层扭曲和遮挡感知噪声抑制，提高视频扩散模型条件图像的质量和完整性；引入全局结构指导，利用密集融合点云为扩散过程提供一致的几何上下文，补偿稀疏条件输入中缺乏全局一致3D约束的问题。

Result: 在多个数据集上的广泛实验表明，该方法在近距离新视角合成方面优于现有方法，验证了设计的有效性。

Conclusion: CloseUpShot通过改进的条件机制和全局几何约束，成功解决了稀疏输入下近距离新视角合成的挑战，在细节重建质量方面取得显著提升。

Abstract: Reconstructing 3D scenes and synthesizing novel views from sparse input views is a highly challenging task. Recent advances in video diffusion models have demonstrated strong temporal reasoning capabilities, making them a promising tool for enhancing reconstruction quality under sparse-view settings. However, existing approaches are primarily designed for modest viewpoint variations, which struggle in capturing fine-grained details in close-up scenarios since input information is severely limited. In this paper, we present a diffusion-based framework, called CloseUpShot, for close-up novel view synthesis from sparse inputs via point-conditioned video diffusion. Specifically, we observe that pixel-warping conditioning suffers from severe sparsity and background leakage in close-up settings. To address this, we propose hierarchical warping and occlusion-aware noise suppression, enhancing the quality and completeness of the conditioning images for the video diffusion model. Furthermore, we introduce global structure guidance, which leverages a dense fused point cloud to provide consistent geometric context to the diffusion process, to compensate for the lack of globally consistent 3D constraints in sparse conditioning inputs. Extensive experiments on multiple datasets demonstrate that our method outperforms existing approaches, especially in close-up novel view synthesis, clearly validating the effectiveness of our design.

</details>


### [166] [VEIL: Jailbreaking Text-to-Video Models via Visual Exploitation from Implicit Language](https://arxiv.org/abs/2511.13127)
*Zonghao Ying,Moyang Chen,Nizhang Li,Zhiqiang Wang,Wenxin Zhang,Quanchen Zou,Zonglei Jing,Aishan Liu,Xianglong Liu*

Main category: cs.CV

TL;DR: VEIL框架通过中性场景锚点、潜在听觉触发器和风格调制器，利用文本到视频模型的跨模态关联模式，实现隐蔽的越狱攻击，使模型生成违反安全策略但保留原始意图的视频。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频模型的越狱攻击通常通过添加明显不安全的对抗性扰动来实现，容易被检测和防御。本文旨在探索看似良性的提示如何通过丰富的隐含线索诱导模型生成语义不安全的视频。

Method: 提出VEIL框架，采用模块化提示设计：中性场景锚点提供表面场景描述；潜在听觉触发器利用音频-视觉共现先验；风格调制器通过电影指令增强触发效果。通过约束优化和引导搜索平衡隐蔽性和有效性。

Result: 在7个文本到视频模型上的广泛实验表明，该攻击方法有效，在商业模型中平均攻击成功率提高了23%。

Conclusion: VEIL框架揭示了文本到视频模型的安全盲点，表明看似良性的提示可以通过跨模态关联模式成功实现越狱攻击，对模型安全防护提出了新的挑战。

Abstract: Jailbreak attacks can circumvent model safety guardrails and reveal critical blind spots. Prior attacks on text-to-video (T2V) models typically add adversarial perturbations to obviously unsafe prompts, which are often easy to detect and defend. In contrast, we show that benign-looking prompts containing rich, implicit cues can induce T2V models to generate semantically unsafe videos that both violate policy and preserve the original (blocked) intent. To realize this, we propose VEIL, a jailbreak framework that leverages T2V models' cross-modal associative patterns via a modular prompt design. Specifically, our prompts combine three components: neutral scene anchors, which provide the surface-level scene description extracted from the blocked intent to maintain plausibility; latent auditory triggers, textual descriptions of innocuous-sounding audio events (e.g., creaking, muffled noises) that exploit learned audio-visual co-occurrence priors to bias the model toward particular unsafe visual concepts; and stylistic modulators, cinematic directives (e.g., camera framing, atmosphere) that amplify and stabilize the latent trigger's effect. We formalize attack generation as a constrained optimization over the above modular prompt space and solve it with a guided search procedure that balances stealth and effectiveness. Extensive experiments over 7 T2V models demonstrate the efficacy of our attack, achieving a 23 percent improvement in average attack success rate in commercial models.

</details>


### [167] [MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation](https://arxiv.org/abs/2511.13135)
*Junjie Yang,Yuhao Yan,Gang Wu,Yuxuan Wang,Ruoyu Liang,Xinjie Jiang,Xiang Wan,Fenglei Fan,Yongquan Zhang,Feiwei Qin,Changmiao Wan*

Main category: cs.CV

TL;DR: MedGEN-Bench是一个全面的医学多模态基准，包含6,422个专家验证的图像-文本对，涵盖6种成像模态、16个临床任务和28个子任务，支持视觉问答、图像编辑和上下文多模态生成三种格式，旨在解决现有医学视觉基准的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型在医学应用中的普及，临床医生期望AI系统不仅能生成文本诊断，还能生成与真实临床工作流程无缝集成的医学图像。现有医学视觉基准存在查询模糊、诊断推理简化过度以及忽视图像生成能力等问题。

Method: 提出了MedGEN-Bench基准，包含三个格式：视觉问答、图像编辑和上下文多模态生成。采用三层评估框架：像素级指标、语义文本分析和专家指导的临床相关性评分，评估了10个组合框架、3个统一模型和5个视觉语言模型。

Result: 通过系统评估发现现有系统在医学多模态任务中的表现，并识别了需要改进的领域。

Conclusion: MedGEN-Bench通过提供上下文交织的指令和开放式生成输出，超越了多项选择格式的限制，推动了医学AI研究的发展，特别是对需要复杂跨模态推理的任务具有重要意义。

Abstract: As Vision-Language Models (VLMs) increasingly gain traction in medical applications, clinicians are progressively expecting AI systems not only to generate textual diagnoses but also to produce corresponding medical images that integrate seamlessly into authentic clinical workflows. Despite the growing interest, existing medical visual benchmarks present notable limitations. They often rely on ambiguous queries that lack sufficient relevance to image content, oversimplify complex diagnostic reasoning into closed-ended shortcuts, and adopt a text-centric evaluation paradigm that overlooks the importance of image generation capabilities. To address these challenges, we introduce \textsc{MedGEN-Bench}, a comprehensive multimodal benchmark designed to advance medical AI research. MedGEN-Bench comprises 6,422 expert-validated image-text pairs spanning six imaging modalities, 16 clinical tasks, and 28 subtasks. It is structured into three distinct formats: Visual Question Answering, Image Editing, and Contextual Multimodal Generation. What sets MedGEN-Bench apart is its focus on contextually intertwined instructions that necessitate sophisticated cross-modal reasoning and open-ended generative outputs, moving beyond the constraints of multiple-choice formats. To evaluate the performance of existing systems, we employ a novel three-tier assessment framework that integrates pixel-level metrics, semantic text analysis, and expert-guided clinical relevance scoring. Using this framework, we systematically assess 10 compositional frameworks, 3 unified models, and 5 VLMs.

</details>


### [168] [Automated Road Distress Detection Using Vision Transformersand Generative Adversarial Networks](https://arxiv.org/abs/2511.13145)
*Cesar Portocarrero Rodriguez,Laura Vandeweyen,Yosuke Yamamoto*

Main category: cs.CV

TL;DR: 本研究探索使用计算机视觉技术进行道路损坏分割，评估GAN生成合成数据对模型训练的有用性，比较CNN和MaskFormer模型性能，发现GAN数据能提升模型表现且MaskFormer在mAP50和IoU指标上优于CNN。


<details>
  <summary>Details</summary>
Motivation: 美国基础设施状况不佳，道路系统评级为D，传统道路检测方法效率低下且成本高昂。随着自动驾驶车辆实时视觉数据的可用性增加，有机会应用计算机视觉方法进行先进道路监控。

Method: 首先评估使用GAN生成的合成数据对模型训练的有用性，然后应用CNN进行道路损坏分割，最后研究基于transformer的MaskFormer模型。

Result: 结果显示GAN生成的数据能提高模型性能，MaskFormer在mAP50和IoU两个指标上优于CNN模型。

Conclusion: 计算机视觉方法特别是MaskFormer模型结合GAN生成数据，为道路基础设施监控提供了有效的解决方案，能够指导基础设施修复工作。

Abstract: The American Society of Civil Engineers has graded Americas infrastructure condition as a C, with the road system receiving a dismal D. Roads are vital to regional economic viability, yet their management, maintenance, and repair processes remain inefficient, relying on outdated manual or laser-based inspection methods that are both costly and time-consuming. With the increasing availability of real-time visual data from autonomous vehicles, there is an opportunity to apply computer vision (CV) methods for advanced road monitoring, providing insights to guide infrastructure rehabilitation efforts. This project explores the use of state-of-the-art CV techniques for road distress segmentation. It begins by evaluating synthetic data generated with Generative Adversarial Networks (GANs) to assess its usefulness for model training. The study then applies Convolutional Neural Networks (CNNs) for road distress segmentation and subsequently examines the transformer-based model MaskFormer. Results show that GAN-generated data improves model performance and that MaskFormer outperforms the CNN model in two metrics: mAP50 and IoU.

</details>


### [169] [Skeletons Speak Louder than Text: A Motion-Aware Pretraining Paradigm for Video-Based Person Re-Identification](https://arxiv.org/abs/2511.13150)
*Rifen Lin,Alex Jinpeng Wang,Jiawei Mo,Min Li*

Main category: cs.CV

TL;DR: CSIP-ReID是一种基于骨架驱动的视频行人重识别预训练框架，通过对比学习对齐骨架和视觉特征，并融合运动与外观线索，在多个基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有多模态预训练方法在视频行人重识别中存在两个根本限制：缺乏真正的多模态预训练，以及文本无法捕捉细粒度时间运动信息。

Method: 提出两阶段方法：第一阶段使用对比学习在序列级别对齐骨架和视觉特征；第二阶段引入动态原型融合更新器来精炼多模态身份原型，并提出骨架引导的时间建模模块。

Result: 在标准视频ReID基准测试（MARS、LS-VID、iLIDS-VID）中达到新的最先进结果，并在纯骨架ReID任务（BIWI、IAS）上表现出强大的泛化能力。

Conclusion: CSIP-ReID开创了无标注和运动感知的ReID预训练范式，为多模态表示学习开辟了新前沿。

Abstract: Multimodal pretraining has revolutionized visual understanding, but its impact on video-based person re-identification (ReID) remains underexplored. Existing approaches often rely on video-text pairs, yet suffer from two fundamental limitations: (1) lack of genuine multimodal pretraining, and (2) text poorly captures fine-grained temporal motion-an essential cue for distinguishing identities in video. In this work, we take a bold departure from text-based paradigms by introducing the first skeleton-driven pretraining framework for ReID. To achieve this, we propose Contrastive Skeleton-Image Pretraining for ReID (CSIP-ReID), a novel two-stage method that leverages skeleton sequences as a spatiotemporally informative modality aligned with video frames. In the first stage, we employ contrastive learning to align skeleton and visual features at sequence level. In the second stage, we introduce a dynamic Prototype Fusion Updater (PFU) to refine multimodal identity prototypes, fusing motion and appearance cues. Moreover, we propose a Skeleton Guided Temporal Modeling (SGTM) module that distills temporal cues from skeleton data and integrates them into visual features. Extensive experiments demonstrate that CSIP-ReID achieves new state-of-the-art results on standard video ReID benchmarks (MARS, LS-VID, iLIDS-VID). Moreover, it exhibits strong generalization to skeleton-only ReID tasks (BIWI, IAS), significantly outperforming previous methods. CSIP-ReID pioneers an annotation-free and motion-aware pretraining paradigm for ReID, opening a new frontier in multimodal representation learning.

</details>


### [170] [SOMA: Feature Gradient Enhanced Affine-Flow Matching for SAR-Optical Registration](https://arxiv.org/abs/2511.13168)
*Haodong Wang,Tao Zhuo,Xiuwei Zhang,Hanlin Yin,Wencong Wu,Yanning Zhang*

Main category: cs.CV

TL;DR: SOMA是一个将结构梯度先验集成到深度特征中的SAR-光学图像密集配准框架，通过混合匹配策略提升配准精度。


<details>
  <summary>Details</summary>
Motivation: SAR和光学图像由于成像机制和视觉特征不同，像素级配准仍然具有挑战性。虽然深度学习在许多跨模态任务中取得成功，但在SAR-光学配准任务中表现仍不理想，梯度信息在传统手工描述符中很关键但未在深度学习框架中有效利用。

Method: 提出SOMA框架：1）特征梯度增强器（FGE），通过注意力和重建机制将多尺度、多方向梯度滤波器嵌入特征空间；2）全局-局部仿射流匹配器（GLAM），在粗到细架构中结合仿射变换和基于流的细化。

Result: 在SEN1-2数据集上CMR@1px提高12.29%，在GFGE_SO数据集上提高18.50%，表现出强大的鲁棒性和跨场景、分辨率的良好泛化能力。

Conclusion: SOMA通过有效利用梯度先验和混合匹配策略，显著提升了SAR-光学图像配准的精度和鲁棒性。

Abstract: Achieving pixel-level registration between SAR and optical images remains a challenging task due to their fundamentally different imaging mechanisms and visual characteristics. Although deep learning has achieved great success in many cross-modal tasks, its performance on SAR-Optical registration tasks is still unsatisfactory. Gradient-based information has traditionally played a crucial role in handcrafted descriptors by highlighting structural differences. However, such gradient cues have not been effectively leveraged in deep learning frameworks for SAR-Optical image matching. To address this gap, we propose SOMA, a dense registration framework that integrates structural gradient priors into deep features and refines alignment through a hybrid matching strategy. Specifically, we introduce the Feature Gradient Enhancer (FGE), which embeds multi-scale, multi-directional gradient filters into the feature space using attention and reconstruction mechanisms to boost feature distinctiveness. Furthermore, we propose the Global-Local Affine-Flow Matcher (GLAM), which combines affine transformation and flow-based refinement within a coarse-to-fine architecture to ensure both structural consistency and local accuracy. Experimental results demonstrate that SOMA significantly improves registration precision, increasing the CMR@1px by 12.29% on the SEN1-2 dataset and 18.50% on the GFGE_SO dataset. In addition, SOMA exhibits strong robustness and generalizes well across diverse scenes and resolutions.

</details>


### [171] [THIR: Topological Histopathological Image Retrieval](https://arxiv.org/abs/2511.13170)
*Zahra Tabatabaei,Jon Sporring*

Main category: cs.CV

TL;DR: THIR是一个基于拓扑数据分析的无监督医学图像检索框架，利用持久同调中的Betti数来表征组织病理学图像的内在结构模式，无需训练即可高效检索相似图像。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性主要死因之一，早期诊断和准确临床决策至关重要。传统深度学习方法需要大量标注数据和GPU资源，而THIR旨在提供无需监督的快速、可扩展解决方案。

Method: 使用立方持久性从RGB组织病理学图像中提取拓扑指纹，通过Betti数编码环的演化过程，生成紧凑可解释的特征向量，然后计算这些拓扑描述符之间的距离进行相似性检索。

Result: 在BreaKHis数据集上的实验表明，THIR优于现有监督和无监督方法，整个数据集处理时间不到20分钟（标准CPU），实现了快速、可扩展且无需训练的临床图像检索。

Conclusion: THIR提供了一个无需监督、计算高效的医学图像检索解决方案，在标准CPU上就能快速处理大规模数据集，有望在临床实践中发挥重要作用。

Abstract: According to the World Health Organization, breast cancer claimed the lives of approximately 685,000 women in 2020. Early diagnosis and accurate clinical decision making are critical in reducing this global burden. In this study, we propose THIR, a novel Content-Based Medical Image Retrieval (CBMIR) framework that leverages topological data analysis specifically, Betti numbers derived from persistent homology to characterize and retrieve histopathological images based on their intrinsic structural patterns. Unlike conventional deep learning approaches that rely on extensive training, annotated datasets, and powerful GPU resources, THIR operates entirely without supervision. It extracts topological fingerprints directly from RGB histopathological images using cubical persistence, encoding the evolution of loops as compact, interpretable feature vectors. The similarity retrieval is then performed by computing the distances between these topological descriptors, efficiently returning the top-K most relevant matches.
  Extensive experiments on the BreaKHis dataset demonstrate that THIR outperforms state of the art supervised and unsupervised methods. It processes the entire dataset in under 20 minutes on a standard CPU, offering a fast, scalable, and training free solution for clinical image retrieval.

</details>


### [172] [HDW-SR: High-Frequency Guided Diffusion Model based on Wavelet Decomposition for Image Super-Resolution](https://arxiv.org/abs/2511.13175)
*Chao Yang,Boqian Zhang,Jinghao Xu,Guang Jiang*

Main category: cs.CV

TL;DR: 提出HDW-SR方法，通过小波分解和残差扩散专注于高频信息恢复，在图像超分辨率中有效提升细节恢复能力


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的单图像超分辨率方法在高频域指导不足，导致恢复的细节模糊，需要改进高频信息恢复机制

Method: 使用小波分解替代传统CNN下采样，在残差图上进行扩散，引入稀疏交叉注意力机制和动态阈值块来指导高频信息恢复

Result: 在合成和真实数据集上的实验表明，HDW-SR在超分辨率性能上具有竞争力，特别擅长恢复细粒度图像细节

Conclusion: HDW-SR通过小波分解和残差扩散策略有效提升了高频细节的恢复能力，为扩散模型在图像超分辨率中的应用提供了新思路

Abstract: Diffusion-based methods have shown great promise in single image super-resolution (SISR); however, existing approaches often produce blurred fine details due to insufficient guidance in the high-frequency domain. To address this issue, we propose a High-Frequency Guided Diffusion Network based on Wavelet Decomposition (HDW-SR), which replaces the conventional U-Net backbone in diffusion frameworks. Specifically, we perform diffusion only on the residual map, allowing the network to focus more effectively on high-frequency information restoration. We then introduce wavelet-based downsampling in place of standard CNN downsampling to achieve multi-scale frequency decomposition, enabling sparse cross-attention between the high-frequency subbands of the pre-super-resolved image and the low-frequency subbands of the diffused image for explicit high-frequency guidance. Moreover, a Dynamic Thresholding Block (DTB) is designed to refine high-frequency selection during the sparse attention process. During upsampling, the invertibility of the wavelet transform ensures low-loss feature reconstruction. Experiments on both synthetic and real-world datasets demonstrate that HDW-SR achieves competitive super-resolution performance, excelling particularly in recovering fine-grained image details. The code will be available after acceptance.

</details>


### [173] [GenTract: Generative Global Tractography](https://arxiv.org/abs/2511.13183)
*Alec Sargood,Lemuel Puglisi,Elinor Thompson,Mirco Musolesi,Daniel C. Alexander*

Main category: cs.CV

TL;DR: GenTract是首个用于全局纤维束成像的生成模型，将纤维束成像构建为生成任务，直接从dMRI映射到完整、解剖学上合理的流线。在低分辨率和噪声数据上表现优异，精度比次优方法高2.1倍。


<details>
  <summary>Details</summary>
Motivation: 解决传统局部纤维束成像方法容易累积误差和高假阳性率的问题，以及全局方法计算成本高的问题。

Method: 提出GenTract生成模型，将纤维束成像构建为生成任务，学习从dMRI到完整流线的直接映射，比较了基于扩散和流匹配的范式。

Result: GenTract精度比次优方法TractOracle高2.1倍，在低分辨率和噪声设置下优势更明显，比最接近的竞争者高出数量级。

Conclusion: GenTract在研究级数据上产生高精度纤维束图，同时在低质量数据上保持可靠性，是全局纤维束成像的有前景解决方案。

Abstract: Tractography is the process of inferring the trajectories of white-matter pathways in the brain from diffusion magnetic resonance imaging (dMRI). Local tractography methods, which construct streamlines by following local fiber orientation estimates stepwise through an image, are prone to error accumulation and high false positive rates, particularly on noisy or low-resolution data. In contrast, global methods, which attempt to optimize a collection of streamlines to maximize compatibility with underlying fiber orientation estimates, are computationally expensive. To address these challenges, we introduce GenTract, the first generative model for global tractography. We frame tractography as a generative task, learning a direct mapping from dMRI to complete, anatomically plausible streamlines. We compare both diffusion-based and flow matching paradigms and evaluate GenTract's performance against state-of-the-art baselines. Notably, GenTract achieves precision 2.1x higher than the next-best method, TractOracle. This advantage becomes even more pronounced in challenging low-resolution and noisy settings, where it outperforms the closest competitor by an order of magnitude. By producing tractograms with high precision on research-grade data while also maintaining reliability on imperfect, lower-resolution data, GenTract represents a promising solution for global tractography.

</details>


### [174] [Video Spatial Reasoning with Object-Centric 3D Rollout](https://arxiv.org/abs/2511.13190)
*Haoran Tang,Meng Cao,Ruyang Liu,Xiaoxi Liang,Linglong Li,Ge Li,Xiaodan Liang*

Main category: cs.CV

TL;DR: 提出Object-Centric 3D Rollout (OCR)方法，通过引入结构化扰动来增强多模态大语言模型在视频空间推理中的表现，解决了现有模型存在的查询锁定推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视频空间推理方面存在局限性，主要表现为查询锁定推理——仅关注提示中明确提到的对象而忽略关键上下文线索。

Method: 提出OCR策略，在训练过程中对选定对象的3D几何结构引入结构化扰动，通过降级对象特定视觉线索并将改变的几何结构投影到2D空间，迫使模型对整个场景进行整体推理。

Result: 实验表明，3B参数模型在VSI-Bench上达到47.5%的准确率，优于多个7B基线模型。消融实验证实OCR优于先前的展开策略。

Conclusion: OCR方法通过结构化扰动和展开式训练管道，有效提升了多模态大语言模型在视频空间推理任务中的性能，实现了最先进的表现。

Abstract: Recent advances in Multi-modal Large Language Models (MLLMs) have showcased remarkable capabilities in vision-language understanding. However, enabling robust video spatial reasoning-the ability to comprehend object locations, orientations, and inter-object relationships in dynamic 3D scenes-remains a key unsolved challenge. Existing approaches primarily rely on spatially grounded supervised fine-tuning or reinforcement learning, yet we observe that such models often exhibit query-locked reasoning, focusing narrowly on objects explicitly mentioned in the prompt while ignoring critical contextual cues. To address this limitation, we propose Object-Centric 3D Rollout (OCR), a novel strategy that introduces structured perturbations to the 3D geometry of selected objects during training. By degrading object-specific visual cues and projecting the altered geometry into 2D space, OCR compels the model to reason holistically across the entire scene. We further design a rollout-based training pipeline that jointly leverages vanilla and region-noisy videos to optimize spatial reasoning trajectories. Experiments demonstrate state-of-the-art performance: our 3B-parameter model achieves 47.5% accuracy on VSI-Bench, outperforming several 7B baselines. Ablations confirm OCR's superiority over prior rollout strategies (e.g., T-GRPO, NoisyRollout).

</details>


### [175] [Birth of a Painting: Differentiable Brushstroke Reconstruction](https://arxiv.org/abs/2511.13191)
*Ying Jiang,Jiayin Lu,Yunuo Chen,Yumeng He,Kui Wu,Yin Yang,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: 本文提出了一个可微分的笔触重建框架，统一了绘画、风格化纹理和涂抹操作，能够真实再现人类绘画-涂抹循环过程。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法主要关注最终图像生成或基于补丁的过程模拟，缺乏明确的笔触结构，无法产生平滑逼真的阴影效果。

Method: 通过并行可微分绘画渲染器优化单色和双色贝塞尔笔触，结合风格生成模块合成几何条件纹理，并引入可微分涂抹算子实现自然色彩混合和阴影效果。

Result: 在油画、水彩、水墨和数字绘画上的广泛实验表明，该方法能产生逼真且富有表现力的笔触重建、平滑的色调过渡和丰富的风格化外观。

Conclusion: 该方法为表达性数字绘画创作提供了一个统一的模型，能够忠实再现人类绘画过程。

Abstract: Painting embodies a unique form of visual storytelling, where the creation process is as significant as the final artwork. Although recent advances in generative models have enabled visually compelling painting synthesis, most existing methods focus solely on final image generation or patch-based process simulation, lacking explicit stroke structure and failing to produce smooth, realistic shading. In this work, we present a differentiable stroke reconstruction framework that unifies painting, stylized texturing, and smudging to faithfully reproduce the human painting-smudging loop. Given an input image, our framework first optimizes single- and dual-color Bezier strokes through a parallel differentiable paint renderer, followed by a style generation module that synthesizes geometry-conditioned textures across diverse painting styles. We further introduce a differentiable smudge operator to enable natural color blending and shading. Coupled with a coarse-to-fine optimization strategy, our method jointly optimizes stroke geometry, color, and texture under geometric and semantic guidance. Extensive experiments on oil, watercolor, ink, and digital paintings demonstrate that our approach produces realistic and expressive stroke reconstructions, smooth tonal transitions, and richly stylized appearances, offering a unified model for expressive digital painting creation. See our project page for more demos: https://yingjiang96.github.io/DiffPaintWebsite/.

</details>


### [176] [Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection](https://arxiv.org/abs/2511.13195)
*Soyul Lee,Seungmin Baek,Dongbo Min*

Main category: cs.CV

TL;DR: MonoDLGD是一个新颖的难度感知标签引导去噪框架，通过自适应扰动和重建真实标签来解决单目3D目标检测中的深度估计不准确问题，在KITTI基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测由于深度线索的固有模糊性而存在根本性问题，现有方法在深度估计不准确且忽略了实例级检测难度（如遮挡、距离和截断），导致检测性能不佳。

Method: 提出MonoDLGD框架，基于检测不确定性自适应扰动和重建真实标签：对简单实例应用更强的扰动，对困难实例应用更弱的扰动，然后重建它们以提供显式几何监督。通过联合优化标签重建和3D目标检测，促进几何感知表示学习。

Result: 在KITTI基准测试上的广泛实验表明，MonoDLGD在所有难度级别上都实现了最先进的性能。

Conclusion: MonoDLGD通过难度感知的标签引导去噪框架有效解决了单目3D目标检测中的深度估计问题，提高了对不同复杂度目标的鲁棒性。

Abstract: Monocular 3D object detection is a cost-effective solution for applications like autonomous driving and robotics, but remains fundamentally ill-posed due to inherently ambiguous depth cues. Recent DETR-based methods attempt to mitigate this through global attention and auxiliary depth prediction, yet they still struggle with inaccurate depth estimates. Moreover, these methods often overlook instance-level detection difficulty, such as occlusion, distance, and truncation, leading to suboptimal detection performance. We propose MonoDLGD, a novel Difficulty-Aware Label-Guided Denoising framework that adaptively perturbs and reconstructs ground-truth labels based on detection uncertainty. Specifically, MonoDLGD applies stronger perturbations to easier instances and weaker ones into harder cases, and then reconstructs them to effectively provide explicit geometric supervision. By jointly optimizing label reconstruction and 3D object detection, MonoDLGD encourages geometry-aware representation learning and improves robustness to varying levels of object complexity. Extensive experiments on the KITTI benchmark demonstrate that MonoDLGD achieves state-of-the-art performance across all difficulty levels.

</details>


### [177] [Self-Supervised Ultrasound Screen Detection](https://arxiv.org/abs/2511.13197)
*Alberto Gomez,Jorge Oliveira,Ramon Casero,Agis Chartsias*

Main category: cs.CV

TL;DR: 提出一种自监督管道，从超声设备显示器照片中提取超声图像，绕过DICOM传输瓶颈，实现快速算法测试和原型开发。概念验证研究表明，校正后的图像保持了足够的视觉保真度，在心脏视图分类任务中达到0.79的平衡准确率。


<details>
  <summary>Details</summary>
Motivation: 超声设备内置显示器显示图像，但常规传输到医院系统依赖DICOM格式。这种依赖形成了传输瓶颈，限制了新算法的快速测试和原型开发。

Method: 开发自监督管道，通过拍摄超声设备显示器照片，从中提取和校正超声图像，避免对DICOM传输的依赖。

Result: 在概念验证研究中，校正后的图像保持了足够的视觉保真度，在心脏视图分类任务中相对于原始DICOM图像达到了0.79的平衡准确率。

Conclusion: 该方法成功绕过了DICOM传输瓶颈，为快速测试和原型开发新算法提供了可行方案，校正图像在临床应用场景中保持了足够的诊断价值。

Abstract: Ultrasound (US) machines display images on a built-in monitor, but routine transfer to hospital systems relies on DICOM. We propose a self-supervised pipeline to extract the US image from a photograph of the monitor. This removes the DICOM bottleneck and enables rapid testing and prototyping of new algorithms. In a proof-of-concept study, the rectified images retained enough visual fidelity to classify cardiac views with a balanced accuracy of 0.79 with respect to the native DICOMs.

</details>


### [178] [RefineVAD: Semantic-Guided Feature Recalibration for Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2511.13204)
*Junhee Lee,ChaeBeen Bang,MyoungChul Kim,MyeongAh Cho*

Main category: cs.CV

TL;DR: RefineVAD是一个弱监督视频异常检测框架，通过结合时间运动模式和语义结构来识别多种异常类型，包含运动感知时间注意力重校准和类别导向细化两个核心模块。


<details>
  <summary>Details</summary>
Motivation: 现有方法将异常事件视为单一类别，忽略了真实世界异常的多样语义和时间特性，需要模仿人类感知异常的双过程推理方式。

Method: 提出RefineVAD框架：1) MoTAR模块估计运动显著性并动态调整时间注意力；2) CORE模块通过跨注意力将片段特征与可学习类别原型对齐，注入软异常类别先验。

Result: 在WVAD基准测试上的广泛实验验证了RefineVAD的有效性，证明整合语义上下文对引导特征细化至异常相关模式的重要性。

Conclusion: 通过联合利用时间动态和语义结构，RefineVAD能够显式建模运动演化方式和语义类别相似性，提升弱监督视频异常检测性能。

Abstract: Weakly-Supervised Video Anomaly Detection aims to identify anomalous events using only video-level labels, balancing annotation efficiency with practical applicability. However, existing methods often oversimplify the anomaly space by treating all abnormal events as a single category, overlooking the diverse semantic and temporal characteristics intrinsic to real-world anomalies. Inspired by how humans perceive anomalies, by jointly interpreting temporal motion patterns and semantic structures underlying different anomaly types, we propose RefineVAD, a novel framework that mimics this dual-process reasoning. Our framework integrates two core modules. The first, Motion-aware Temporal Attention and Recalibration (MoTAR), estimates motion salience and dynamically adjusts temporal focus via shift-based attention and global Transformer-based modeling. The second, Category-Oriented Refinement (CORE), injects soft anomaly category priors into the representation space by aligning segment-level features with learnable category prototypes through cross-attention. By jointly leveraging temporal dynamics and semantic structure, explicitly models both "how" motion evolves and "what" semantic category it resembles. Extensive experiments on WVAD benchmark validate the effectiveness of RefineVAD and highlight the importance of integrating semantic context to guide feature refinement toward anomaly-relevant patterns.

</details>


### [179] [End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer](https://arxiv.org/abs/2511.13208)
*Yonghui Yu,Jiahang Cai,Xun Wang,Wenwu Yang*

Main category: cs.CV

TL;DR: 提出了首个端到端的多帧2D人体姿态估计方法PAVE-Net，消除了传统两阶段方法中的启发式操作，通过姿态感知注意力机制实现跨帧个体关联，在准确性和效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有多人视频姿态估计方法采用两阶段流程（检测+时序建模），依赖检测、RoI裁剪和NMS等启发式操作，限制了准确性和效率。需要开发完全端到端的框架来消除这些限制。

Method: 提出PAVE-Net框架，包含空间编码器建模帧内关系和时空姿态解码器捕获跨帧全局依赖。核心创新是姿态感知注意力机制，使每个姿态查询能够选择性聚合跨连续帧中相同个体的特征，并显式建模姿态关键点间的时空依赖。

Result: 在PoseTrack2017上比基于图像的端到端方法提升6.0 mAP，与最先进的两阶段视频方法精度相当，同时提供显著的效率提升。

Conclusion: PAVE-Net是首个端到端的多帧2D人体姿态估计方法，成功解决了复杂重叠时序轨迹下的个体关联问题，在保持高精度的同时大幅提升了效率。

Abstract: Existing multi-person video pose estimation methods typically adopt a two-stage pipeline: detecting individuals in each frame, followed by temporal modeling for single-person pose estimation. This design relies on heuristic operations such as detection, RoI cropping, and non-maximum suppression (NMS), limiting both accuracy and efficiency. In this paper, we present a fully end-to-end framework for multi-person 2D pose estimation in videos, effectively eliminating heuristic operations. A key challenge is to associate individuals across frames under complex and overlapping temporal trajectories. To address this, we introduce a novel Pose-Aware Video transformEr Network (PAVE-Net), which features a spatial encoder to model intra-frame relations and a spatiotemporal pose decoder to capture global dependencies across frames. To achieve accurate temporal association, we propose a pose-aware attention mechanism that enables each pose query to selectively aggregate features corresponding to the same individual across consecutive frames.Additionally, we explicitly model spatiotemporal dependencies among pose keypoints to improve accuracy. Notably, our approach is the first end-to-end method for multi-frame 2D human pose estimation.Extensive experiments show that PAVE-Net substantially outperforms prior image-based end-to-end methods, achieving a \textbf{6.0} mAP improvement on PoseTrack2017, and delivers accuracy competitive with state-of-the-art two-stage video-based approaches, while offering significant gains in efficiency.Project page: https://github.com/zgspose/PAVENet

</details>


### [180] [3DAlign-DAER: Dynamic Attention Policy and Efficient Retrieval Strategy for Fine-grained 3D-Text Alignment at Scale](https://arxiv.org/abs/2511.13211)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Jian Wang,Keze Wang*

Main category: cs.CV

TL;DR: 3DAlign-DAER是一个统一的文本-3D几何对齐框架，通过动态注意力策略和高效检索策略解决细粒度语义对齐问题，并在大规模3D数据库上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以将细粒度文本语义与详细几何结构对齐，且在大规模3D数据库上性能显著下降。

Method: 提出动态注意力策略（DAP）使用分层注意力融合模块表示对齐，并通过蒙特卡洛树搜索动态校准注意力权重；推理时采用高效检索策略（ERS）进行分层搜索。

Result: 在多个基准测试中表现出优越性能，构建了包含200万文本-3D对的Align3D-2M数据集。

Conclusion: 3DAlign-DAER在文本-3D对齐任务中实现了显著的性能提升，特别是在细粒度语义对齐和大规模检索方面。

Abstract: Despite recent advancements in 3D-text cross-modal alignment, existing state-of-the-art methods still struggle to align fine-grained textual semantics with detailed geometric structures, and their alignment performance degrades significantly when scaling to large-scale 3D databases. To overcome this limitation, we introduce 3DAlign-DAER, a unified framework designed to align text and 3D geometry via the proposed dynamic attention policy and the efficient retrieval strategy, capturing subtle correspondences for diverse cross-modal retrieval and classification tasks. Specifically, during the training, our proposed dynamic attention policy (DAP) employs the Hierarchical Attention Fusion (HAF) module to represent the alignment as learnable fine-grained token-to-point attentions. To optimize these attentions across different tasks and geometric hierarchies, our DAP further exploits the Monte Carlo tree search to dynamically calibrate HAF attention weights via a hybrid reward signal and further enhances the alignment between textual descriptions and local 3D geometry. During the inference, our 3DAlign-DAER introduces an Efficient Retrieval Strategy (ERS) to leverage efficient hierarchical searching in the large-scale embedding spaces, outperforming traditional methods (e.g., KNN) in accuracy and efficiency. Furthermore, to facilitate text-3D alignment research and train our 3DAlign-DAER, we construct Align3D-2M, a large-scale dataset featuring 2M text-3D pairs, to provide sufficient fine-grained cross-modal annotations. Extensive and comprehensive experiments demonstrate the superior performance of our 3DAlign-DAER on diverse benchmarks. We will release our codes, models, and datasets.

</details>


### [181] [Hybrid-Domain Adaptative Representation Learning for Gaze Estimation](https://arxiv.org/abs/2511.13222)
*Qida Tan,Hongyu Yang,Wenchao Du*

Main category: cs.CV

TL;DR: 本文提出了一种混合域自适应表示学习框架HARL，通过利用多源混合数据集学习鲁棒的目光表示，解决了基于外观的目光估计在跨域评估中因表情、佩戴物和图像质量等无关因素导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于外观的目光估计方法在跨域评估中性能显著下降，主要受到表情、佩戴物和图像质量等与目光无关因素的干扰。为了解决这个问题，需要开发能够从低质量面部图像中分离出目光相关表示的鲁棒方法。

Method: 提出了混合域自适应表示学习框架HARL，通过无监督域自适应方式对齐高质量近眼图像特征来解耦目光相关表示；同时设计了稀疏图融合模块来探索目光方向与头部姿态之间的几何约束关系。

Result: 在EyeDiap、MPIIFaceGaze和Gaze360数据集上的广泛实验表明，该方法分别达到了5.02°、3.36°和9.26°的最先进精度，并在跨数据集评估中表现出竞争优势。

Conclusion: HARL框架通过混合域自适应学习和几何约束建模，能够有效学习鲁棒的目光表示，在多个数据集上取得了最先进的性能，为解决跨域目光估计问题提供了有效方案。

Abstract: Appearance-based gaze estimation, aiming to predict accurate 3D gaze direction from a single facial image, has made promising progress in recent years. However, most methods suffer significant performance degradation in cross-domain evaluation due to interference from gaze-irrelevant factors, such as expressions, wearables, and image quality. To alleviate this problem, we present a novel Hybrid-domain Adaptative Representation Learning (shorted by HARL) framework that exploits multi-source hybrid datasets to learn robust gaze representation. More specifically, we propose to disentangle gaze-relevant representation from low-quality facial images by aligning features extracted from high-quality near-eye images in an unsupervised domain-adaptation manner, which hardly requires any computational or inference costs. Additionally, we analyze the effect of head-pose and design a simple yet efficient sparse graph fusion module to explore the geometric constraint between gaze direction and head-pose, leading to a dense and robust gaze representation. Extensive experiments on EyeDiap, MPIIFaceGaze, and Gaze360 datasets demonstrate that our approach achieves state-of-the-art accuracy of $\textbf{5.02}^{\circ}$ and $\textbf{3.36}^{\circ}$, and $\textbf{9.26}^{\circ}$ respectively, and present competitive performances through cross-dataset evaluation. The code is available at https://github.com/da60266/HARL.

</details>


### [182] [MRIQT: Physics-Aware Diffusion Model for Image Quality Transfer in Neonatal Ultra-Low-Field MRI](https://arxiv.org/abs/2511.13232)
*Malek Al Abed,Sebiha Demir,Anne Groteklaes,Elodie Germani,Shahrooz Faghihroohi,Hemmen Sabir,Shadi Albarqouni*

Main category: cs.CV

TL;DR: MRIQT是一个3D条件扩散框架，用于将便携式超低场MRI图像质量提升到高场MRI水平，通过物理一致的K空间降级、v-prediction和SNR加权3D感知损失实现高质量图像转换。


<details>
  <summary>Details</summary>
Motivation: 便携式超低场MRI在新生儿护理中具有可及性优势，但其低信噪比和诊断质量差限制了临床应用，需要提升图像质量以达到高场MRI的诊断标准。

Method: 结合物理一致的K空间降级模拟uLF MRI、使用v-prediction和分类器自由引导的稳定图像生成、SNR加权的3D感知损失保持解剖保真度，以及基于注意力UNet架构的体素级去噪转换。

Result: 在新生儿队列测试中，MRIQT在PSNR指标上比现有最佳方法提升1.78%，总体提升15.3%，85%的输出被医生评为良好质量且病理清晰可见。

Conclusion: MRIQT能够实现基于扩散模型的高保真图像质量转换，为便携式超低场MRI提供可靠的脑部评估能力。

Abstract: Portable ultra-low-field MRI (uLF-MRI, 0.064 T) offers accessible neuroimaging for neonatal care but suffers from low signal-to-noise ratio and poor diagnostic quality compared to high-field (HF) MRI. We propose MRIQT, a 3D conditional diffusion framework for image quality transfer (IQT) from uLF to HF MRI. MRIQT combines realistic K-space degradation for physics-consistent uLF simulation, v-prediction with classifier-free guidance for stable image-to-image generation, and an SNR-weighted 3D perceptual loss for anatomical fidelity. The model denoises from a noised uLF input conditioned on the same scan, leveraging volumetric attention-UNet architecture for structure-preserving translation. Trained on a neonatal cohort with diverse pathologies, MRIQT surpasses recent GAN and CNN baselines in PSNR 15.3% with 1.78% over the state of the art, while physicians rated 85% of its outputs as good quality with clear pathology present. MRIQT enables high-fidelity, diffusion-based enhancement of portable ultra-low-field (uLF) MRI for deliable neonatal brain assessment.

</details>


### [183] [MMD-Thinker: Adaptive Multi-Dimensional Thinking for Multimodal Misinformation Detection](https://arxiv.org/abs/2511.13242)
*Junjie Wu,Guohong Fu*

Main category: cs.CV

TL;DR: MMD-Thinker是一个用于多模态虚假信息检测的两阶段框架，通过自适应多维思维解决通用多模态大语言模型在检测中存在的推理不足和推理偏差问题。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC时代多模态虚假信息的泛滥，现有通用多模态大语言模型在检测中存在推理不足和推理偏差两个关键局限，无法有效应对快速演变的复杂虚假信息。

Method: 提出两阶段框架：1) 设计针对多模态虚假信息检测的定制化思维模式；2) 通过任务特定指令调优将定制思维注入通用模型；3) 使用混合优势函数的强化学习策略增强推理能力。同时构建了包含8K+图像-文本对的MMR数据集。

Result: 实验结果表明，MMD-Thinker在领域内和领域外基准数据集上都达到了最先进的性能，同时保持了灵活的推理和token使用效率。

Conclusion: 该框架通过自适应多维思维有效提升了多模态虚假信息检测能力，为应对AIGC时代虚假信息威胁提供了有效解决方案。

Abstract: Multimodal misinformation floods on various social media, and continues to evolve in the era of AI-generated content (AIGC). The emerged misinformation with low creation cost and high deception poses significant threats to society. While recent studies leverage general-purpose multimodal large language models (MLLMs) to achieve remarkable results in detection, they encounter two critical limitations: (1) Insufficient reasoning, where general-purpose MLLMs often follow the uniform reasoning paradigm but generate inaccurate explanations and judgments, due to the lack of the task-specific knowledge of multimodal misinformation detection. (2) Reasoning biases, where a single thinking mode make detectors a suboptimal path for judgment, struggling to keep pace with the fast-growing and intricate multimodal misinformation. In this paper, we propose MMD-Thinker, a two-stage framework for multimodal misinformation detection through adaptive multi-dimensional thinking. First, we develop tailor-designed thinking mode for multimodal misinformation detection. Second, we adopt task-specific instruction tuning to inject the tailored thinking mode into general-purpose MLLMs. Third, we further leverage reinforcement learning strategy with a mixed advantage function, which incentivizes the reasoning capabilities in trajectories. Furthermore, we construct the multimodal misinformation reasoning (MMR) dataset, encompasses more than 8K image-text pairs with both reasoning processes and classification labels, to make progress in the relam of multimodal misinformation detection. Experimental results demonstrate that our proposed MMD-Thinker achieves state-of-the-art performance on both in-domain and out-of-domain benchmark datasets, while maintaining flexible inference and token usage. Code will be publicly available at Github.

</details>


### [184] [GeoX-Bench: Benchmarking Cross-View Geo-Localization and Pose Estimation Capabilities of Large Multimodal Models](https://arxiv.org/abs/2511.13259)
*Yushuo Zheng,Jiangyong Ying,Huiyu Duan,Chunyi Li,Zicheng Zhang,Jing Liu,Xiaohong Liu,Guangtao Zhai*

Main category: cs.CV

TL;DR: GeoX-Bench是一个用于评估大型多模态模型在跨视角地理定位和姿态估计任务中能力的基准测试，包含10,859个全景-卫星图像对和755,976个问答对。


<details>
  <summary>Details</summary>
Motivation: 尽管大型多模态模型在多种任务上表现出色，但其在跨视角地理定位和姿态估计领域的能力尚未被探索，而这些能力对导航、自动驾驶、户外机器人等应用具有潜在价值。

Method: 构建了包含128个城市、49个国家的10,859个全景-卫星图像对数据集，并创建了755,976个问答对，其中42,900个用于基准测试。评估了25个最先进的大型多模态模型，并探索了指令调优的效果。

Result: 当前大型多模态模型在地理定位任务中表现优异，但在更复杂的姿态估计任务中效果显著下降。通过GeoX-Bench训练数据进行指令调优可以显著提升模型的跨视角地理感知能力。

Conclusion: GeoX-Bench揭示了大型多模态模型在跨视角地理定位和姿态估计方面的能力差距，特别是姿态估计任务需要未来改进，指令调优是提升这些能力的有效方法。

Abstract: Large multimodal models (LMMs) have demonstrated remarkable capabilities across a wide range of tasks, however their knowledge and abilities in the cross-view geo-localization and pose estimation domains remain unexplored, despite potential benefits for navigation, autonomous driving, outdoor robotics, \textit{etc}. To bridge this gap, we introduce \textbf{GeoX-Bench}, a comprehensive \underline{Bench}mark designed to explore and evaluate the capabilities of LMMs in \underline{cross}-view \underline{Geo}-localization and pose estimation. Specifically, GeoX-Bench contains 10,859 panoramic-satellite image pairs spanning 128 cities in 49 countries, along with corresponding 755,976 question-answering (QA) pairs. Among these, 42,900 QA pairs are designated for benchmarking, while the remaining are intended to enhance the capabilities of LMMs. Based on GeoX-Bench, we evaluate the capabilities of 25 state-of-the-art LMMs on cross-view geo-localization and pose estimation tasks, and further explore the empowered capabilities of instruction-tuning. Our benchmark demonstrate that while current LMMs achieve impressive performance in geo-localization tasks, their effectiveness declines significantly on the more complex pose estimation tasks, highlighting a critical area for future improvement, and instruction-tuning LMMs on the training data of GeoX-Bench can significantly improve the cross-view geo-sense abilities. The GeoX-Bench is available at \textcolor{magenta}{https://github.com/IntMeGroup/GeoX-Bench}.

</details>


### [185] [Building Egocentric Procedural AI Assistant: Methods, Benchmarks, and Challenges](https://arxiv.org/abs/2511.13261)
*Junlong Li,Huaiyuan Xu,Sijie Cheng,Kejun Wu,Kim-Hui Yap,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: 本文提出了以自我为中心的程序AI助手（EgoProceAssist）概念，旨在通过第一人称视角逐步支持日常程序性任务，并定义了三个核心任务：自我中心程序错误检测、自我中心程序学习和自我中心程序问答。


<details>
  <summary>Details</summary>
Motivation: 受视觉语言模型和自我中心感知研究的进展推动，需要开发专门针对第一人称视角日常程序性任务的AI助手。

Method: 通过全面回顾当前技术、相关数据集和评估指标，建立新的分类法，并对代表性VLM方法进行实验评估。

Result: 识别了现有VLM助手与EgoProceAssist之间的差距，提供了全面的技术分析和评估结果。

Conclusion: 讨论了未来挑战和研究方向，并建立了持续更新的公开资源库来收集最新研究成果。

Abstract: Driven by recent advances in vision language models (VLMs) and egocentric perception research, we introduce the concept of an egocentric procedural AI assistant (EgoProceAssist) tailored to step-by-step support daily procedural tasks in a first-person view. In this work, we start by identifying three core tasks: egocentric procedural error detection, egocentric procedural learning, and egocentric procedural question answering. These tasks define the essential functions of EgoProceAssist within a new taxonomy. Specifically, our work encompasses a comprehensive review of current techniques, relevant datasets, and evaluation metrics across these three core areas. To clarify the gap between the proposed EgoProceAssist and existing VLM-based AI assistants, we introduce novel experiments and provide a comprehensive evaluation of representative VLM-based methods. Based on these findings and our technical analysis, we discuss the challenges ahead and suggest future research directions. Furthermore, an exhaustive list of this study is publicly available in an active repository that continuously collects the latest work: https://github.com/z1oong/Building-Egocentric-Procedural-AI-Assistant

</details>


### [186] [SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression](https://arxiv.org/abs/2511.13264)
*Keshav Gupta,Akshat Sanghvi,Shreyas Reddy Palley,Astitva Srivastava,Charu Sharma,Avinash Sharma*

Main category: cs.CV

TL;DR: SymGS是一个基于对称感知的3D高斯泼溅压缩框架，通过引入可学习镜像来消除反射冗余，实现高效压缩。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术在渲染速度和真实感方面表现出色，但内存占用随场景复杂度快速增长。现有压缩方法主要利用原始级别的冗余进行压缩，但仍有提升空间。

Method: 提出SymGS框架，引入可学习镜像来消除局部和全局的反射冗余，作为即插即用的增强模块与现有压缩方法（如HAC）结合使用。

Result: 相比HAC方法，在基准数据集上实现1.66倍压缩（大规模场景可达3倍），平均实现108倍的3DGS场景压缩，同时保持渲染质量。

Conclusion: SymGS通过对称感知技术成功突破了现有压缩方法的限制，为3D高斯泼溅提供了高效的压缩解决方案。

Abstract: 3D Gaussian Splatting has emerged as a transformative technique in novel view synthesis, primarily due to its high rendering speed and photorealistic fidelity. However, its memory footprint scales rapidly with scene complexity, often reaching several gigabytes. Existing methods address this issue by introducing compression strategies that exploit primitive-level redundancy through similarity detection and quantization. We aim to surpass the compression limits of such methods by incorporating symmetry-aware techniques, specifically targeting mirror symmetries to eliminate redundant primitives. We propose a novel compression framework, \textbf{\textit{SymGS}}, introducing learnable mirrors into the scene, thereby eliminating local and global reflective redundancies for compression. Our framework functions as a plug-and-play enhancement to state-of-the-art compression methods, (e.g. HAC) to achieve further compression. Compared to HAC, we achieve $1.66 \times$ compression across benchmark datasets (upto $3\times$ on large-scale scenes). On an average, SymGS enables $\bf{108\times}$ compression of a 3DGS scene, while preserving rendering quality. The project page and supplementary can be found at \textbf{\color{cyan}{symgs.github.io}}

</details>


### [187] [Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation](https://arxiv.org/abs/2511.13269)
*Lingfeng Zhang,Yuchen Zhang,Hongsheng Li,Haoxiang Fu,Yingbo Tang,Hangjun Ye,Long Chen,Xiaojun Liang,Xiaoshuai Hao,Wenbo Ding*

Main category: cs.CV

TL;DR: 本文提出了SpatialSky-Bench基准测试来评估视觉语言模型在无人机导航中的空间智能能力，并开发了Sky-VLM模型在多个任务上取得了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在无人机场景中的空间智能能力未被充分探索，存在在动态环境中导航和解释效果不佳的问题。

Method: 开发了SpatialSky-Bench基准测试（包含环境感知和场景理解两个类别13个子类别），创建了包含100万样本的SpatialSky-Dataset数据集，并提出了专门用于无人机空间推理的Sky-VLM模型。

Result: 主流视觉语言模型在复杂无人机导航场景中表现不理想，而Sky-VLM在所有基准任务上都达到了最先进的性能水平。

Conclusion: Sky-VLM为开发适用于无人机场景的视觉语言模型开辟了新途径，解决了现有模型在空间推理能力方面的不足。

Abstract: Vision-Language Models (VLMs), leveraging their powerful visual perception and reasoning capabilities, have been widely applied in Unmanned Aerial Vehicle (UAV) tasks. However, the spatial intelligence capabilities of existing VLMs in UAV scenarios remain largely unexplored, raising concerns about their effectiveness in navigating and interpreting dynamic environments. To bridge this gap, we introduce SpatialSky-Bench, a comprehensive benchmark specifically designed to evaluate the spatial intelligence capabilities of VLMs in UAV navigation. Our benchmark comprises two categories-Environmental Perception and Scene Understanding-divided into 13 subcategories, including bounding boxes, color, distance, height, and landing safety analysis, among others. Extensive evaluations of various mainstream open-source and closed-source VLMs reveal unsatisfactory performance in complex UAV navigation scenarios, highlighting significant gaps in their spatial capabilities. To address this challenge, we developed the SpatialSky-Dataset, a comprehensive dataset containing 1M samples with diverse annotations across various scenarios. Leveraging this dataset, we introduce Sky-VLM, a specialized VLM designed for UAV spatial reasoning across multiple granularities and contexts. Extensive experimental results demonstrate that Sky-VLM achieves state-of-the-art performance across all benchmark tasks, paving the way for the development of VLMs suitable for UAV scenarios. The source code is available at https://github.com/linglingxiansen/SpatialSKy.

</details>


### [188] [SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D Gaussian Splatting](https://arxiv.org/abs/2511.13278)
*Zihan Li,Tengfei Wang,Wentian Gan,Hao Zhan,Xin Wang,Zongqian Zhan*

Main category: cs.CV

TL;DR: SF-Recon是一种直接从多视角图像重建轻量级建筑表面的方法，无需后处理网格简化，通过3D高斯溅射和结构优化实现高效建模。


<details>
  <summary>Details</summary>
Motivation: 传统多视角几何流程依赖密集重建、网格化和后续简化，过程繁琐且质量敏感，需要直接重建轻量级建筑表面模型。

Method: 首先训练3D高斯溅射场获得视图一致表示，然后通过法向梯度引导的高斯优化选择与屋顶和墙壁边界对齐的基元，再通过多视角边缘一致性修剪增强结构锐度，最后用多视角深度约束的Delaunay三角化将结构化高斯场转换为轻量级建筑网格。

Result: 在提出的SF数据集上，SF-Recon能够直接从多视角图像重建轻量级建筑模型，显著减少面和顶点数量，同时保持计算效率。

Conclusion: SF-Recon方法能够直接从多视角图像重建轻量级、结构保真的建筑网格，避免了传统流程中的繁琐后处理步骤。

Abstract: Lightweight building surface models are crucial for digital city, navigation, and fast geospatial analytics, yet conventional multi-view geometry pipelines remain cumbersome and quality-sensitive due to their reliance on dense reconstruction, meshing, and subsequent simplification. This work presents SF-Recon, a method that directly reconstructs lightweight building surfaces from multi-view images without post-hoc mesh simplification. We first train an initial 3D Gaussian Splatting (3DGS) field to obtain a view-consistent representation. Building structure is then distilled by a normal-gradient-guided Gaussian optimization that selects primitives aligned with roof and wall boundaries, followed by multi-view edge-consistency pruning to enhance structural sharpness and suppress non-structural artifacts without external supervision. Finally, a multi-view depth-constrained Delaunay triangulation converts the structured Gaussian field into a lightweight, structurally faithful building mesh. Based on a proposed SF dataset, the experimental results demonstrate that our SF-Recon can directly reconstruct lightweight building models from multi-view imagery, achieving substantially fewer faces and vertices while maintaining computational efficiency. Website:https://lzh282140127-cell.github.io/SF-Recon-project/

</details>


### [189] [TabFlash: Efficient Table Understanding with Progressive Question Conditioning and Token Focusing](https://arxiv.org/abs/2511.13283)
*Jongha Kim,Minseong Bae,Sanghyeok Lee,Jinsung Yoon,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: TabFlash是一个高效的多模态大语言模型，通过渐进式问题条件化、剪枝策略和token聚焦训练来解决表格图像理解中的冗余和效率问题，在性能提升的同时显著降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 表格图像理解面临两个主要挑战：需要问题特定的关注点，以及存在冗余背景区域。现有的多模态大语言模型方法往往忽视这些特性，导致视觉表示不够信息丰富且冗余。

Method: 1. 渐进式问题条件化：将问题信息以逐渐增加的频率注入Vision Transformer各层；2. 剪枝策略：丢弃背景token以提高效率；3. Token聚焦：训练策略促使模型将关键信息集中在保留的token中。

Result: TabFlash实现了最先进的性能，优于开源和专有的多模态大语言模型，同时相比第二好的模型减少了27%的FLOPs和30%的内存使用。

Conclusion: 通过结合渐进式问题条件化、剪枝和token聚焦训练，TabFlash能够生成信息丰富且紧凑的视觉特征，显著提升了表格理解的效率和效果。

Abstract: Table images present unique challenges for effective and efficient understanding due to the need for question-specific focus and the presence of redundant background regions. Existing Multimodal Large Language Model (MLLM) approaches often overlook these characteristics, resulting in uninformative and redundant visual representations. To address these issues, we aim to generate visual features that are both informative and compact to improve table understanding. We first propose progressive question conditioning, which injects the question into Vision Transformer layers with gradually increasing frequency, considering each layer's capacity to handle additional information, to generate question-aware visual features. To reduce redundancy, we introduce a pruning strategy that discards background tokens, thereby improving efficiency. To mitigate information loss from pruning, we further propose token focusing, a training strategy that encourages the model to concentrate essential information in the retained tokens. By combining these approaches, we present TabFlash, an efficient and effective MLLM for table understanding. TabFlash achieves state-of-the-art performance, outperforming both open-source and proprietary MLLMs, while requiring 27% less FLOPs and 30% less memory usage compared to the second-best MLLM.

</details>


### [190] [SkyReels-Text: Fine-grained Font-Controllable Text Editing for Poster Design](https://arxiv.org/abs/2511.13285)
*Yunjie Yu,Jingchen Wu,Junchen Zhu,Chunze Lin,Guibin Chen*

Main category: cs.CV

TL;DR: SkyReels-Text是一个无需字体标签或微调的字体可控框架，用于精确的海报文本编辑，支持同时编辑多个文本区域并保持非编辑区域的视觉外观。


<details>
  <summary>Details</summary>
Motivation: 解决专业设计工作流程中现代图像编辑模型在细粒度、字体感知文本操作方面的不足，特别是在保持视觉和谐和排版意图的同时快速精确修改文本内容的需求。

Method: 提出一种字体可控框架，用户只需提供所需字体的裁剪字形补丁，无需字体标签或推理时微调，即可同时编辑多个不同排版风格的文本区域。

Result: 在多个数据集（包括手写文本基准测试）上的广泛实验表明，SkyReels-Text在文本保真度和视觉真实感方面达到了最先进的性能。

Conclusion: 该工作弥合了通用图像编辑与专业级排版设计之间的差距，为字体族和风格细微差别提供了前所未有的控制能力。

Abstract: Artistic design such as poster design often demands rapid yet precise modification of textual content while preserving visual harmony and typographic intent, especially across diverse font styles. Although modern image editing models have grown increasingly powerful, they still fall short in fine-grained, font-aware text manipulation, limiting their utility in professional design workflows such as poster editing. To address this issue, we present SkyReels-Text, a novel font-controllable framework for precise poster text editing. Our method enables simultaneous editing of multiple text regions, each rendered in distinct typographic styles, while preserving the visual appearance of non-edited regions. Notably, our model requires neither font labels nor fine-tuning during inference: users can simply provide cropped glyph patches corresponding to their desired typography, even if the font is not included in any standard library. Extensive experiments on multiple datasets, including handwrittent text benchmarks, SkyReels-Text achieves state-of-the-art performance in both text fidelity and visual realism, offering unprecedented control over font families, and stylistic nuances. This work bridges the gap between general-purpose image editing and professional-grade typographic design.

</details>


### [191] [CorrectAD: A Self-Correcting Agentic System to Improve End-to-end Planning in Autonomous Driving](https://arxiv.org/abs/2511.13297)
*Enhui Ma,Lijun Zhou,Tao Tang,Jiahuan Zhang,Junpeng Jiang,Zhan Zhang,Dong Han,Kun Zhan,Xueyang Zhang,XianPeng Lang,Haiyang Sun,Xia Zhou,Di Lin,Kaicheng Yu*

Main category: cs.CV

TL;DR: 提出CorrectAD系统，通过扩散模型生成与3D布局对齐的高保真视频数据，自动纠正端到端自动驾驶规划器的长尾故障案例


<details>
  <summary>Details</summary>
Motivation: 解决端到端自动驾驶规划方法因长尾问题（罕见但安全关键的故障案例）导致的鲁棒性不足问题

Method: 1) PM-Agent模拟产品经理制定数据需求；2) DriveSora生成与3D布局对齐的时空一致视频；3) 构建端到端模型无关的自纠正系统CorrectAD

Result: 在nuScenes和内部数据集上，CorrectAD分别纠正了62.5%和49.8%的故障案例，碰撞率分别降低39%和27%

Conclusion: CorrectAD系统能够有效自动纠正端到端自动驾驶规划器的故障案例，提高系统鲁棒性

Abstract: End-to-end planning methods are the de facto standard of the current autonomous driving system, while the robustness of the data-driven approaches suffers due to the notorious long-tail problem (i.e., rare but safety-critical failure cases). In this work, we explore whether recent diffusion-based video generation methods (a.k.a. world models), paired with structured 3D layouts, can enable a fully automated pipeline to self-correct such failure cases. We first introduce an agent to simulate the role of product manager, dubbed PM-Agent, which formulates data requirements to collect data similar to the failure cases. Then, we use a generative model that can simulate both data collection and annotation. However, existing generative models struggle to generate high-fidelity data conditioned on 3D layouts. To address this, we propose DriveSora, which can generate spatiotemporally consistent videos aligned with the 3D annotations requested by PM-Agent. We integrate these components into our self-correcting agentic system, CorrectAD. Importantly, our pipeline is an end-to-end model-agnostic and can be applied to improve any end-to-end planner. Evaluated on both nuScenes and a more challenging in-house dataset across multiple end-to-end planners, CorrectAD corrects 62.5% and 49.8% of failure cases, reducing collision rates by 39% and 27%, respectively.

</details>


### [192] [DriveLiDAR4D: Sequential and Controllable LiDAR Scene Generation for Autonomous Driving](https://arxiv.org/abs/2511.13309)
*Kaiwen Cai,Xinze Liu,Xia Zhou,Hengtong Hu,Jie Xiang,Luyao Zhang,Xueyang Zhang,Kun Zhan,Yifei Zhan,Xianpeng Lang*

Main category: cs.CV

TL;DR: DriveLiDAR4D是一个新颖的LiDAR生成流水线，包含多模态条件和顺序噪声预测模型LiDAR4DNet，能够生成时间一致的LiDAR场景，具有高度可控的前景物体和真实背景。


<details>
  <summary>Details</summary>
Motivation: 现有的3D LiDAR点云生成方法存在缺乏顺序生成能力、无法产生精确定位的前景物体和真实背景等限制，阻碍了其实际应用。

Method: 提出了DriveLiDAR4D流水线，包含多模态条件和LiDAR4DNet顺序噪声预测模型，以端到端方式实现LiDAR场景的顺序生成和完整场景操作能力。

Result: 在nuScenes和KITTI数据集上评估，在nuScenes数据集上获得FRD分数743.13和FVD分数16.96，相比当前SOTA方法UniScene，FRD性能提升37.2%，FVD提升24.1%。

Conclusion: 这是首个以端到端方式解决具有完整场景操作能力的LiDAR场景顺序生成的工作，显著超越了现有技术水平。

Abstract: The generation of realistic LiDAR point clouds plays a crucial role in the development and evaluation of autonomous driving systems. Although recent methods for 3D LiDAR point cloud generation have shown significant improvements, they still face notable limitations, including the lack of sequential generation capabilities and the inability to produce accurately positioned foreground objects and realistic backgrounds. These shortcomings hinder their practical applicability. In this paper, we introduce DriveLiDAR4D, a novel LiDAR generation pipeline consisting of multimodal conditions and a novel sequential noise prediction model LiDAR4DNet, capable of producing temporally consistent LiDAR scenes with highly controllable foreground objects and realistic backgrounds. To the best of our knowledge, this is the first work to address the sequential generation of LiDAR scenes with full scene manipulation capability in an end-to-end manner. We evaluated DriveLiDAR4D on the nuScenes and KITTI datasets, where we achieved an FRD score of 743.13 and an FVD score of 16.96 on the nuScenes dataset, surpassing the current state-of-the-art (SOTA) method, UniScene, with an performance boost of 37.2% in FRD and 24.1% in FVD, respectively.

</details>


### [193] [Generalized Denoising Diffusion Codebook Models (gDDCM): Tokenizing images using a pre-trained diffusion model](https://arxiv.org/abs/2511.13387)
*Fei Kong*

Main category: cs.CV

TL;DR: 本文提出了广义去噪扩散压缩模型(gDDCM)，将DDCM扩展到主流扩散模型及其变体，包括DDPM、基于分数的模型、一致性模型和整流流，在CIFAR-10和LSUN Bedroom数据集上实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: DDCM虽然利用DDPM和特定噪声集实现了图像压缩，但无法应用于DDPM之外的其他方法，因此需要开发一个更通用的框架。

Method: 提出gDDCM框架，通过将反向过程中的随机噪声替换为按预定规则从特定集合采样的噪声，将DDCM扩展到多种扩散模型变体。

Result: 在CIFAR-10和LSUN Bedroom数据集上的实验结果表明，该方法成功将DDCM推广到上述模型，并实现了改进的性能。

Conclusion: gDDCM有效扩展了DDCM的应用范围，为多种扩散模型提供了通用的图像压缩解决方案。

Abstract: Recently, the Denoising Diffusion Codebook Models (DDCM) was proposed. DDCM leverages the Denoising Diffusion Probabilistic Model (DDPM) and replaces the random noise in the backward process with noise sampled from specific sets according to a predefined rule, thereby enabling image compression. However, DDCM cannot be applied to methods other than DDPM. In this paper, we propose the generalized Denoising Diffusion Compression Model (gDDCM), which extends DDCM to mainstream diffusion models and their variants, including DDPM, Score-Based Models, Consistency Models, and Rectified Flow. We evaluate our method on CIFAR-10 and LSUN Bedroom datasets. Experimental results demonstrate that our approach successfully generalizes DDCM to the aforementioned models and achieves improved performance.

</details>


### [194] [YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection](https://arxiv.org/abs/2511.13344)
*Ori Meiraz,Sharon Shalev,Avishai Weizman*

Main category: cs.CV

TL;DR: 提出了一种基于YOLOv9-T的混合专家框架，通过自适应路由实现动态特征专业化，在目标检测任务中相比单一YOLOv9-T模型获得了更高的mAP和AR指标


<details>
  <summary>Details</summary>
Motivation: 为了提升目标检测性能，需要探索如何让模型能够动态适应不同特征模式，实现更精细化的特征处理

Method: 采用混合专家框架，集成多个YOLOv9-T专家模型，通过自适应路由机制在不同专家之间进行动态选择

Result: 相比单一YOLOv9-T模型，该框架在目标检测任务中取得了更高的平均精度(mAP)和平均召回率(AR)

Conclusion: 混合专家框架能够有效提升目标检测性能，自适应路由机制实现了特征的动态专业化处理

Abstract: This paper presents a novel Mixture-of-Experts framework for object detection, incorporating adaptive routing among multiple YOLOv9-T experts to enable dynamic feature specialization and achieve higher mean Average Precision (mAP) and Average Recall (AR) compared to a single YOLOv9-T model.

</details>


### [195] [Descriptor: Distance-Annotated Traffic Perception Question Answering (DTPQA)](https://arxiv.org/abs/2511.13397)
*Nikos Theodoridis,Tim Brophy,Reenu Mohandas,Ganesh Sistu,Fiachra Collins,Anthony Scanlan,Ciaran Eising*

Main category: cs.CV

TL;DR: DTPQA是一个专门用于评估视觉语言模型在交通场景中感知能力的视觉问答基准，包含合成和真实世界两部分，具有距离标注功能。


<details>
  <summary>Details</summary>
Motivation: 由于视觉语言模型在自动驾驶等安全关键领域的应用需求，需要评估其在复杂交通场景中的感知能力，特别是对远距离物体的识别能力。

Method: 创建了DTPQA基准，包含合成数据集（使用模拟器生成）和真实世界数据集（基于现有真实交通场景图像），每个样本包含图像、问题、真实答案和物体距离信息。

Result: 该基准能够系统评估VLM在交通场景中的感知性能，特别是分析模型性能随物体距离增加而下降的情况。

Conclusion: DTPQA为评估视觉语言模型在自动驾驶领域的感知能力提供了专门的测试工具，有助于提升模型在安全关键应用中的可靠性。

Abstract: The remarkable progress of Vision-Language Models (VLMs) on a variety of tasks has raised interest in their application to automated driving. However, for these models to be trusted in such a safety-critical domain, they must first possess robust perception capabilities, i.e., they must be capable of understanding a traffic scene, which can often be highly complex, with many things happening simultaneously. Moreover, since critical objects and agents in traffic scenes are often at long distances, we require systems with not only strong perception capabilities at close distances (up to 20 meters), but also at long (30+ meters) range. Therefore, it is important to evaluate the perception capabilities of these models in isolation from other skills like reasoning or advanced world knowledge. Distance-Annotated Traffic Perception Question Answering (DTPQA) is a Visual Question Answering (VQA) benchmark designed specifically for this purpose: it can be used to evaluate the perception systems of VLMs in traffic scenarios using trivial yet crucial questions relevant to driving decisions. It consists of two parts: a synthetic benchmark (DTP-Synthetic) created using a simulator, and a real-world benchmark (DTP-Real) built on top of existing images of real traffic scenes. Additionally, DTPQA includes distance annotations, i.e., how far the object in question is from the camera. More specifically, each DTPQA sample consists of (at least): (a) an image, (b) a question, (c) the ground truth answer, and (d) the distance of the object in question, enabling analysis of how VLM performance degrades with increasing object distance. In this article, we provide the dataset itself along with the Python scripts used to create it, which can be used to generate additional data of the same kind.

</details>


### [196] [TripleFDS: Triple Feature Disentanglement and Synthesis for Scene Text Editing](https://arxiv.org/abs/2511.13399)
*Yuchen Bao,Yiting Wang,Wenjian Huang,Haowei Wang,Shen Chen,Taiping Yao,Shouhong Ding,Jianguo Zhang*

Main category: cs.CV

TL;DR: TripleFDS是一个用于场景文本编辑的新框架，通过解耦文本样式、内容和背景三个属性，实现了更灵活和一致的文本编辑。该方法在主流基准测试中达到了最先进的图像保真度和文本准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的场景文本编辑方法在可编辑属性解耦方面存在不足，通常只能处理单一方面的编辑（如文本内容），限制了可控性和视觉一致性。

Method: 提出了TripleFDS框架和SCB Synthesis数据集，使用SCB Group作为基本训练单元进行三重特征解耦，通过组间对比正则化和组内多特征正交性确保语义准确性和减少冗余。在合成阶段进行特征重映射以防止重建中的"捷径"现象。

Result: 在125,000个SCB Groups上训练后，TripleFDS在主流STE基准测试中实现了44.54的SSIM和93.58%的ACC，达到了最先进的性能。

Conclusion: TripleFDS不仅性能优越，还支持更灵活的编辑操作，如样式替换和背景转移，为场景文本编辑提供了更全面的解决方案。

Abstract: Scene Text Editing (STE) aims to naturally modify text in images while preserving visual consistency, the decisive factors of which can be divided into three parts, i.e., text style, text content, and background. Previous methods have struggled with incomplete disentanglement of editable attributes, typically addressing only one aspect - such as editing text content - thus limiting controllability and visual consistency. To overcome these limitations, we propose TripleFDS, a novel framework for STE with disentangled modular attributes, and an accompanying dataset called SCB Synthesis. SCB Synthesis provides robust training data for triple feature disentanglement by utilizing the "SCB Group", a novel construct that combines three attributes per image to generate diverse, disentangled training groups. Leveraging this construct as a basic training unit, TripleFDS first disentangles triple features, ensuring semantic accuracy through inter-group contrastive regularization and reducing redundancy through intra-sample multi-feature orthogonality. In the synthesis phase, TripleFDS performs feature remapping to prevent "shortcut" phenomena during reconstruction and mitigate potential feature leakage. Trained on 125,000 SCB Groups, TripleFDS achieves state-of-the-art image fidelity (SSIM of 44.54) and text accuracy (ACC of 93.58%) on the mainstream STE benchmarks. Besides superior performance, the more flexible editing of TripleFDS supports new operations such as style replacement and background transfer. Code: https://github.com/yusenbao01/TripleFDS

</details>


### [197] [What Color Is It? A Text-Interference Multimodal Hallucination Benchmark](https://arxiv.org/abs/2511.13400)
*Jinkun Zhao,Lei Huang,Wenjun Wu*

Main category: cs.CV

TL;DR: 本文提出了一个名为"What Color Is It"的数据集，用于测试多模态大模型在颜色感知方面的视觉幻觉问题，并分析了其原因和潜在解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大模型的发展，这些模型在视觉感知方面容易受到信息干扰，特别是在颜色感知方面存在幻觉风险，需要验证这一假设并提升模型鲁棒性。

Method: 通过构建"What Color Is It"数据集，采用简单方法触发多模态大模型中的单模态视觉幻觉，并基于此数据集分析视觉幻觉的根本原因。

Result: 验证了多模态大模型在颜色感知方面确实存在视觉幻觉问题，并识别了导致这些幻觉的潜在机制。

Conclusion: 多模态大模型在视觉模态中存在颜色感知幻觉问题，需要进一步研究解决方案来增强模型的鲁棒性和可靠性。

Abstract: With the rapid advancement of Large Models, numerous text-and-vision-fused Multimodal Large Models (MLMs) have emerged. However, these MLMs remain susceptible to informational interference in visual perception, particularly in color perception, which introduces an additional risk of hallucination. To validate this hypothesis, we introduce the "What Color Is It" dataset, a novel benchmark constructed using a simple method to trigger single-modality visual hallucination in MLMs. Based on this dataset, we further investigate the underlying causes of hallucination in the visual modality of MLMs and propose potential solutions to enhance their robustness.

</details>


### [198] [Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline](https://arxiv.org/abs/2511.13442)
*Rui Zuo,Qinyue Tong,Zhe-Ming Lu,Ziqian Lu*

Main category: cs.CV

TL;DR: Foresee是一个无需训练的基于多模态大语言模型的图像伪造分析流程，通过类型先验驱动策略和灵活特征检测器模块，有效释放了原始MLLM在取证领域的潜力，在篡改定位准确性和文本解释丰富性方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像伪造检测和定位方法难以泛化到不同数据集且可解释性有限。虽然多模态大语言模型在视觉语言任务中展现出强大泛化能力，但现有方法需要大规模训练且未能充分利用原始MLLM的内在潜力。

Method: 提出无需训练的Foresee流程，采用类型先验驱动策略和灵活特征检测器模块专门处理复制移动篡改，无需额外训练即可实现轻量级推理。

Result: 在多种篡改类型上均优于现有IFDL方法，包括复制移动、拼接、移除、局部增强、深度伪造和AIGC编辑，同时提供更全面的文本解释。

Conclusion: Foresee成功释放了原始MLLM在取证领域的潜力，实现了优越的定位精度和更强的泛化能力，为图像伪造分析提供了高效且可解释的解决方案。

Abstract: With the rapid advancement of artificial intelligence-generated content (AIGC) technologies, including multimodal large language models (MLLMs) and diffusion models, image generation and manipulation have become remarkably effortless. Existing image forgery detection and localization (IFDL) methods often struggle to generalize across diverse datasets and offer limited interpretability. Nowadays, MLLMs demonstrate strong generalization potential across diverse vision-language tasks, and some studies introduce this capability to IFDL via large-scale training. However, such approaches cost considerable computational resources, while failing to reveal the inherent generalization potential of vanilla MLLMs to address this problem. Inspired by this observation, we propose Foresee, a training-free MLLM-based pipeline tailored for image forgery analysis. It eliminates the need for additional training and enables a lightweight inference process, while surpassing existing MLLM-based methods in both tamper localization accuracy and the richness of textual explanations. Foresee employs a type-prior-driven strategy and utilizes a Flexible Feature Detector (FFD) module to specifically handle copy-move manipulations, thereby effectively unleashing the potential of vanilla MLLMs in the forensic domain. Extensive experiments demonstrate that our approach simultaneously achieves superior localization accuracy and provides more comprehensive textual explanations. Moreover, Foresee exhibits stronger generalization capability, outperforming existing IFDL methods across various tampering types, including copy-move, splicing, removal, local enhancement, deepfake, and AIGC-based editing. The code will be released in the final version.

</details>


### [199] [VOPE: Revisiting Hallucination of Vision-Language Models in Voluntary Imagination Task](https://arxiv.org/abs/2511.13420)
*Xingming Long,Jie Zhang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出了VOPE方法，用于评估大型视觉语言模型在自愿想象任务中的幻觉问题，通过存在性评估来判断模型是否在生成响应时产生幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注禁止输出图像中不存在内容的事实描述任务中的幻觉问题，而忽视了自愿想象任务（如故事写作）中的幻觉评估，这些任务中模型被期望生成超越给定图像的新内容。

Method: 引入VOPE方法，通过提出基于重新检查的问题来评估LVLM如何解释其响应中想象对象的存在性，然后根据模型解释与图像中对象存在性的一致性来判断是否产生幻觉。

Result: 应用VOPE到多个主流LVLM和幻觉缓解方法，发现：(1)大多数LVLM在自愿想象中严重幻觉，在想象对象上的存在性评估表现显著较差；(2)现有幻觉缓解方法在自愿想象任务中效果有限。

Conclusion: 自愿想象任务中的幻觉问题是一个重要的未来研究方向，现有方法对此类任务的适用性有限。

Abstract: Most research on hallucinations in Large Vision-Language Models (LVLMs) focuses on factual description tasks that prohibit any output absent from the image. However, little attention has been paid to hallucinations in voluntary imagination tasks, e.g., story writing, where the models are expected to generate novel content beyond the given image. In these tasks, it is inappropriate to simply regard such imagined novel content as hallucinations. To address this limitation, we introduce Voluntary-imagined Object Presence Evaluation (VOPE)-a novel method to assess LVLMs' hallucinations in voluntary imagination tasks via presence evaluation. Specifically, VOPE poses recheck-based questions to evaluate how an LVLM interprets the presence of the imagined objects in its own response. The consistency between the model's interpretation and the object's presence in the image is then used to determine whether the model hallucinates when generating the response. We apply VOPE to several mainstream LVLMs and hallucination mitigation methods, revealing two key findings: (1) most LVLMs hallucinate heavily during voluntary imagination, and their performance in presence evaluation is notably poor on imagined objects; (2) existing hallucination mitigation methods show limited effect in voluntary imagination tasks, making this an important direction for future research.

</details>


### [200] [FUSE: A Flow-based Mapping Between Shapes](https://arxiv.org/abs/2511.13431)
*Lorenzo Olearo,Giulio Viganò,Daniele Baieri,Filippo Maggioli,Simone Melzi*

Main category: cs.CV

TL;DR: 提出基于流匹配模型的3D形状映射新神经表示方法，支持跨表示形状匹配，无需大规模训练或数据驱动过程。


<details>
  <summary>Details</summary>
Motivation: 开发计算高效、支持跨表示形状匹配的神经表示方法，避免传统方法需要大规模训练或数据驱动过程的限制。

Method: 将3D形状表示为从固定锚分布通过连续可逆流映射诱导的概率分布，通过源形状到锚的逆流与锚到目标形状的正向流组合实现点对点映射，并使用点级任务定制嵌入编码形状。

Result: 在多样化基准测试和挑战性设置中一致实现高覆盖率和准确性，在形状匹配、UV映射和人体原始点云扫描配准等任务中表现出色。

Conclusion: 该方法提供了可逆且模态无关的形状映射表示，支持点云、网格、SDF和体数据等多种表示形式，在多个3D形状处理任务中展现优异性能。

Abstract: We introduce a novel neural representation for maps between 3D shapes based on flow-matching models, which is computationally efficient and supports cross-representation shape matching without large-scale training or data-driven procedures. 3D shapes are represented as the probability distribution induced by a continuous and invertible flow mapping from a fixed anchor distribution. Given a source and a target shape, the composition of the inverse flow (source to anchor) with the forward flow (anchor to target), we continuously map points between the two surfaces. By encoding the shapes with a pointwise task-tailored embedding, this construction provides an invertible and modality-agnostic representation of maps between shapes across point clouds, meshes, signed distance fields (SDFs), and volumetric data. The resulting representation consistently achieves high coverage and accuracy across diverse benchmarks and challenging settings in shape matching. Beyond shape matching, our framework shows promising results in other tasks, including UV mapping and registration of raw point cloud scans of human bodies.

</details>


### [201] [Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling](https://arxiv.org/abs/2511.13478)
*Adam Hazimeh,Ke Wang,Mark Collier,Gilles Baechler,Efi Kokiopoulou,Pascal Frossard*

Main category: cs.CV

TL;DR: SliDer是一个使用视觉语言模型将幻灯片图像转换为可编辑SVG格式的框架，解决了现有几何光栅-矢量转换方法无法保留文档高级结构的问题。


<details>
  <summary>Details</summary>
Motivation: 多媒体文档通常以静态光栅格式分发，限制了编辑和定制。现有方法无法保留复杂文档的高层结构，导致语义信息丢失。

Method: 使用视觉语言模型检测和提取光栅输入中的图像和文本元素属性，将其组织成连贯的SVG格式，并在推理过程中迭代优化预测。

Result: SliDer实现了0.069的重建LPIPS，在82.9%的情况下被人类评估者认为优于最强的零样本VLM基线。

Conclusion: SliDer能够有效将幻灯片图像转换为紧凑且可编辑的SVG表示，同时引入了Slide2SVG数据集促进该领域研究。

Abstract: Multimedia documents such as slide presentations and posters are designed to be interactive and easy to modify. Yet, they are often distributed in a static raster format, which limits editing and customization. Restoring their editability requires converting these raster images back into structured vector formats. However, existing geometric raster-vectorization methods, which rely on low-level primitives like curves and polygons, fall short at this task. Specifically, when applied to complex documents like slides, they fail to preserve the high-level structure, resulting in a flat collection of shapes where the semantic distinction between image and text elements is lost. To overcome this limitation, we address the problem of semantic document derendering by introducing SliDer, a novel framework that uses Vision-Language Models (VLMs) to derender slide images as compact and editable Scalable Vector Graphic (SVG) representations. SliDer detects and extracts attributes from individual image and text elements in a raster input and organizes them into a coherent SVG format. Crucially, the model iteratively refines its predictions during inference in a process analogous to human design, generating SVG code that more faithfully reconstructs the original raster upon rendering. Furthermore, we introduce Slide2SVG, a novel dataset comprising raster-SVG pairs of slide documents curated from real-world scientific presentations, to facilitate future research in this domain. Our results demonstrate that SliDer achieves a reconstruction LPIPS of 0.069 and is favored by human evaluators in 82.9% of cases compared to the strongest zero-shot VLM baseline.

</details>


### [202] [InterMoE: Individual-Specific 3D Human Interaction Generation via Dynamic Temporal-Selective MoE](https://arxiv.org/abs/2511.13488)
*Lipeng Wang,Hongxing Fan,Haohua Chen,Zehuan Huang,Lu Sheng*

Main category: cs.CV

TL;DR: InterMoE是一个基于动态时间选择性专家混合框架的新方法，用于生成高质量的人类交互动作，在保持个体特征和文本语义保真度方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成人类交互动作时往往无法保持独特的个体特征或完全遵循文本描述，这限制了在虚拟现实和机器人等应用中的使用价值。

Method: InterMoE采用动态时间选择性专家混合框架，通过路由机制协同使用高级文本语义和低级动作上下文，将时间动作特征分配给专门的专家，专家动态确定选择能力并关注关键时间特征。

Result: 在InterHuman数据集上FID分数降低9%，在InterX数据集上降低22%，实现了个体特定高保真3D人类交互生成的最先进性能。

Conclusion: InterMoE框架能够有效保持特定个体特征身份，同时确保高语义保真度，在人类交互生成任务中表现出色。

Abstract: Generating high-quality human interactions holds significant value for applications like virtual reality and robotics. However, existing methods often fail to preserve unique individual characteristics or fully adhere to textual descriptions. To address these challenges, we introduce InterMoE, a novel framework built on a Dynamic Temporal-Selective Mixture of Experts. The core of InterMoE is a routing mechanism that synergistically uses both high-level text semantics and low-level motion context to dispatch temporal motion features to specialized experts. This allows experts to dynamically determine the selection capacity and focus on critical temporal features, thereby preserving specific individual characteristic identities while ensuring high semantic fidelity. Extensive experiments show that InterMoE achieves state-of-the-art performance in individual-specific high-fidelity 3D human interaction generation, reducing FID scores by 9% on the InterHuman dataset and 22% on InterX.

</details>


### [203] [Language-Guided Invariance Probing of Vision-Language Models](https://arxiv.org/abs/2511.13494)
*Jae Joong Lee*

Main category: cs.CV

TL;DR: 本文提出了语言引导不变性探测(LGIP)基准，用于评估视觉语言模型(VLMs)对语义保持的改写和语义改变的翻转的响应可靠性。通过在4万张MS COCO图像上进行测试，发现EVA02-CLIP和大型OpenCLIP变体在不变性和敏感性方面表现最佳，而SigLIP模型则存在较大问题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型(如CLIP、OpenCLIP等)在零样本任务中表现强劲，但其对受控语言扰动的响应可靠性尚不明确。需要开发专门的基准来评估模型的语言鲁棒性。

Method: 提出LGIP基准，使用4万张MS COCO图像及其五个人工标注描述，自动生成语义保持的改写和基于规则的语义翻转(改变对象类别、颜色或数量)，通过不变性误差、语义敏感性差距和正率统计来总结模型行为。

Result: 在九个VLM模型中，EVA02-CLIP和大型OpenCLIP变体处于有利的不变性-敏感性边界，具有较低的改写诱导方差，且对原始描述的评分始终高于翻转版本。而SigLIP和SigLIP2表现出较大的不变性误差，经常偏好翻转描述而非人类描述，特别是在对象和颜色编辑方面。

Conclusion: LGIP为VLM的语言鲁棒性提供了模型无关的诊断工具，这些失败在标准检索指标中基本不可见，表明需要超越传统准确度分数的评估方法。

Abstract: Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to meaning-changing semantic flips in image-text matching. Using 40k MS COCO images with five human captions each, we automatically generate paraphrases and rule-based flips that alter object category, color or count, and summarize model behavior with an invariance error, a semantic sensitivity gap and a positive-rate statistic.
  Across nine VLMs, EVA02-CLIP and large OpenCLIP variants lie on a favorable invariance-sensitivity frontier, combining low paraphrase-induced variance with consistently higher scores for original captions than for their flipped counterparts. In contrast, SigLIP and SigLIP2 show much larger invariance error and often prefer flipped captions to the human descriptions, especially for object and color edits. These failures are largely invisible to standard retrieval metrics, indicating that LGIP provides a model-agnostic diagnostic for the linguistic robustness of VLMs beyond conventional accuracy scores.

</details>


### [204] [Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks](https://arxiv.org/abs/2511.13545)
*Md. Iqbal Hossain,Afia Sajeeda,Neeresh Kumar Perla,Ming Shao*

Main category: cs.CV

TL;DR: 本文提出了一种创新的多模态对比学习模型防御后门攻击的策略，通过图像分割"预言机"来识别后门触发器、受害样本和标签，并开发算法修复中毒的CLIP模型。


<details>
  <summary>Details</summary>
Motivation: 多模态深度学习模型（如CLIP）容易受到后门攻击，现有防御方法需要从头训练或使用大量数据进行微调，且无法精确定位受影响的标签。

Method: 引入图像分割"预言机"作为监督器，开发两种算法：1）区分CLIP和预言机的知识来识别潜在触发器；2）精确定位受影响标签和受害样本，并构建紧凑的微调数据集。

Result: 在视觉识别基准测试上的广泛实验表明，该策略在基于CLIP的后门防御中有效。

Conclusion: 该方法能够高效识别后门触发器、受害样本和标签，并通过精心构建的微调数据集成功修复中毒的CLIP模型，消除后门影响。

Abstract: The advent of multimodal deep learning models, such as CLIP, has unlocked new frontiers in a wide range of applications, from image-text understanding to classification tasks. However, these models are not safe for adversarial attacks, particularly backdoor attacks, which can subtly manipulate model behavior. Moreover, existing defense methods typically involve training from scratch or fine-tuning using a large dataset without pinpointing the specific labels that are affected. In this study, we introduce an innovative strategy to enhance the robustness of multimodal contrastive learning models against such attacks. In particular, given a poisoned CLIP model, our approach can identify the backdoor trigger and pinpoint the victim samples and labels in an efficient manner. To that end, an image segmentation ``oracle'' is introduced as the supervisor for the output of the poisoned CLIP. We develop two algorithms to rectify the poisoned model: (1) differentiating between CLIP and Oracle's knowledge to identify potential triggers; (2) pinpointing affected labels and victim samples, and curating a compact fine-tuning dataset. With this knowledge, we are allowed to rectify the poisoned CLIP model to negate backdoor effects. Extensive experiments on visual recognition benchmarks demonstrate our strategy is effective in CLIP-based backdoor defense.

</details>


### [205] [Mapping the Vanishing and Transformation of Urban Villages in China](https://arxiv.org/abs/2511.13507)
*Wenyu Zhang,Yao Tong,Yiqiu Liu,Rui Cao*

Main category: cs.CV

TL;DR: 本研究提出基于深度学习的框架监测中国城中村时空变化，发现城中村改造过程通常漫长，主要发生在城市外围区域，揭示了三种时空转型路径，强调需要分层和因地制宜的规划策略。


<details>
  <summary>Details</summary>
Motivation: 中国城中村经历了大规模拆迁改造，但缺乏对拆迁后土地利用有效性的系统评估，需要评估当前改造实践的成效和可持续性。

Method: 使用多时相遥感影像的语义分割来绘制城中村边界演变，然后将拆迁后土地利用分为六类：未完成拆迁、闲置土地、建筑工地、建筑物、绿地和其他。

Result: 1) 城中村改造过程经常延长；2) 改造主要发生在城市外围区域，而城市核心区相对稳定；3) 揭示了三种时空转型路径：同步改造、延迟改造和渐进优化。

Conclusion: 城中村改造具有碎片化、复杂和非线性特征，需要分层和因地制宜的规划策略，研究结果为支持更包容、高效和可持续的城市更新提供了有价值的实证见解。

Abstract: Urban villages (UVs), informal settlements embedded within China's urban fabric, have undergone widespread demolition and redevelopment in recent decades. However, there remains a lack of systematic evaluation of whether the demolished land has been effectively reused, raising concerns about the efficacy and sustainability of current redevelopment practices. To address the gap, this study proposes a deep learning-based framework to monitor the spatiotemporal changes of UVs in China. Specifically, semantic segmentation of multi-temporal remote sensing imagery is first used to map evolving UV boundaries, and then post-demolition land use is classified into six categories based on the "remained-demolished-redeveloped" phase: incomplete demolition, vacant land, construction sites, buildings, green spaces, and others. Four representative cities from China's four economic regions were selected as the study areas, i.e., Guangzhou (East), Zhengzhou (Central), Xi'an (West), and Harbin (Northeast). The results indicate: 1) UV redevelopment processes were frequently prolonged; 2) redevelopment transitions primarily occurred in peripheral areas, whereas urban cores remained relatively stable; and 3) three spatiotemporal transformation pathways, i.e., synchronized redevelopment, delayed redevelopment, and gradual optimization, were revealed. This study highlights the fragmented, complex and nonlinear nature of UV redevelopment, underscoring the need for tiered and context-sensitive planning strategies. By linking spatial dynamics with the context of redevelopment policies, the findings offer valuable empirical insights that support more inclusive, efficient, and sustainable urban renewal, while also contributing to a broader global understanding of informal settlement transformations.

</details>


### [206] [Hierarchical Prompt Learning for Image- and Text-Based Person Re-Identification](https://arxiv.org/abs/2511.13575)
*Linhan Zhou,Shuang Li,Neng Dong,Yonghang Tai,Yafei Zhang,Huafeng Li*

Main category: cs.CV

TL;DR: 本文提出了一种统一框架HPL，通过任务感知提示建模联合优化图像到图像（I2I）和文本到图像（T2I）的人员重识别任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将I2I和T2I任务分开处理，可能导致表示纠缠和性能不佳。为了解决这个问题，需要开发一个统一框架来同时优化这两个任务。

Method: 提出分层提示学习（HPL）框架，包括：1）任务路由Transformer，在共享视觉编码器中引入双分类令牌；2）分层提示生成方案，结合身份级可学习令牌和实例级伪文本令牌；3）跨模态提示正则化策略，在提示令牌空间强制语义对齐。

Result: 在多个ReID基准测试上的广泛实验验证了该方法的有效性，在I2I和T2I任务上都达到了最先进的性能。

Conclusion: HPL框架通过任务感知提示建模成功统一了I2I和T2I人员重识别任务，实现了优异的跨模态检索性能。

Abstract: Person re-identification (ReID) aims to retrieve target pedestrian images given either visual queries (image-to-image, I2I) or textual descriptions (text-to-image, T2I). Although both tasks share a common retrieval objective, they pose distinct challenges: I2I emphasizes discriminative identity learning, while T2I requires accurate cross-modal semantic alignment. Existing methods often treat these tasks separately, which may lead to representation entanglement and suboptimal performance. To address this, we propose a unified framework named Hierarchical Prompt Learning (HPL), which leverages task-aware prompt modeling to jointly optimize both tasks. Specifically, we first introduce a Task-Routed Transformer, which incorporates dual classification tokens into a shared visual encoder to route features for I2I and T2I branches respectively. On top of this, we develop a hierarchical prompt generation scheme that integrates identity-level learnable tokens with instance-level pseudo-text tokens. These pseudo-tokens are derived from image or text features via modality-specific inversion networks, injecting fine-grained, instance-specific semantics into the prompts. Furthermore, we propose a Cross-Modal Prompt Regularization strategy to enforce semantic alignment in the prompt token space, ensuring that pseudo-prompts preserve source-modality characteristics while enhancing cross-modal transferability. Extensive experiments on multiple ReID benchmarks validate the effectiveness of our method, achieving state-of-the-art performance on both I2I and T2I tasks.

</details>


### [207] [Minimax Multi-Target Conformal Prediction with Applications to Imaging Inverse Problems](https://arxiv.org/abs/2511.13533)
*Jeffrey Wen,Rizwan Ahmad,Philip Schniter*

Main category: cs.CV

TL;DR: 提出了一种渐近极小极大方法用于多目标共形预测，为成像逆问题中的不确定性量化提供紧密的预测区间，同时确保联合边际覆盖。


<details>
  <summary>Details</summary>
Motivation: 在病态成像逆问题中，不确定性量化是一个基本挑战，特别是在安全关键应用中。现有方法只能处理标量估计目标，而实际应用通常涉及多个目标。

Method: 提出渐近极小极大多目标共形预测方法，确保联合边际覆盖的同时提供紧密的预测区间。该方法可应用于多指标盲图像质量评估、多任务不确定性量化和多轮测量采集。

Result: 通过合成数据和磁共振成像数据的数值实验证明，该方法相对于现有的多目标共形预测方法具有优势。

Conclusion: 所提出的极小极大方法为多目标不确定性量化提供了有效的解决方案，在多个应用场景中表现出优越性能。

Abstract: In ill-posed imaging inverse problems, uncertainty quantification remains a fundamental challenge, especially in safety-critical applications. Recently, conformal prediction has been used to quantify the uncertainty that the inverse problem contributes to downstream tasks like image classification, image quality assessment, fat mass quantification, etc. While existing works handle only a scalar estimation target, practical applications often involve multiple targets. In response, we propose an asymptotically minimax approach to multi-target conformal prediction that provides tight prediction intervals while ensuring joint marginal coverage. We then outline how our minimax approach can be applied to multi-metric blind image quality assessment, multi-task uncertainty quantification, and multi-round measurement acquisition. Finally, we numerically demonstrate the benefits of our minimax method, relative to existing multi-target conformal prediction methods, using both synthetic and magnetic resonance imaging (MRI) data.

</details>


### [208] [VVS: Accelerating Speculative Decoding for Visual Autoregressive Generation via Partial Verification Skipping](https://arxiv.org/abs/2511.13587)
*Haotian Dong,Ye Li,Rongwei Lu,Chen Tang,Shu-Tao Xia,Zhi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为VVS的新颖推测解码框架，通过部分验证跳过来加速视觉自回归模型的生成，将目标模型前向传递次数减少2.8倍，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 视觉自回归生成模型虽然表现出强大的图像生成能力，但其下一个令牌预测范式引入了显著的推理延迟。现有的推测解码方法采用"起草一步，验证一步"的模式，无法直接减少前向传递次数，限制了加速潜力。

Method: 基于视觉令牌可互换性的观察，提出VVS框架，包含三个互补模块：(1)带动态截断的免验证令牌选择器，(2)令牌级特征缓存和重用，(3)细粒度的跳过步骤调度。

Result: VVS将目标模型前向传递次数相对于原始自回归解码减少了2.8倍，同时保持竞争力的生成质量，在速度-质量权衡上优于传统推测解码框架。

Conclusion: VVS通过部分验证跳过来加速视觉自回归生成，展示了重塑推测解码范式的强大潜力，为视觉AR模型提供了优越的加速解决方案。

Abstract: Visual autoregressive (AR) generation models have demonstrated strong potential for image generation, yet their next-token-prediction paradigm introduces considerable inference latency. Although speculative decoding (SD) has been proven effective for accelerating visual AR models, its "draft one step, then verify one step" paradigm prevents a direct reduction of the forward passes, thus restricting acceleration potential. Motivated by the visual token interchangeability, we for the first time to explore verification skipping in the SD process of visual AR model generation to explicitly cut the number of target model forward passes, thereby reducing inference latency. Based on an analysis of the drafting stage's characteristics, we observe that verification redundancy and stale feature reusability are key factors to retain generation quality and speedup for verification-free steps. Inspired by these two observations, we propose a novel SD framework VVS to accelerate visual AR generation via partial verification skipping, which integrates three complementary modules: (1) a verification-free token selector with dynamical truncation, (2) token-level feature caching and reuse, and (3) fine-grained skipped step scheduling. Consequently, VVS reduces the number of target model forward passes by a factor of $2.8\times$ relative to vanilla AR decoding while maintaining competitive generation quality, offering a superior speed-quality trade-off over conventional SD frameworks and revealing strong potential to reshape the SD paradigm.

</details>


### [209] [Accuracy is Not Enough: Poisoning Interpretability in Federated Learning via Color Skew](https://arxiv.org/abs/2511.13535)
*Farhin Farhad Riya,Shahinul Hoque,Jinyuan Stella Sun,Olivera Kotevska*

Main category: cs.CV

TL;DR: 本文揭示了一种新的攻击类型，通过联邦学习中的微小颜色扰动来破坏模型的可解释性而不影响准确性，挑战了模型审计中正确预测即意味着忠实解释的假设。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在安全关键领域的部署增加，可视化解释技术对支持透明度变得至关重要。本文旨在揭示一种能够在不影响准确性的情况下破坏模型可解释性的新型攻击。

Method: 提出了名为色度扰动模块的显著性感知攻击框架，通过系统性地改变前景和背景之间的颜色对比度来制作对抗样本，从而破坏解释的忠实性。这些扰动在训练轮次中累积，以隐蔽和持久的方式毒化全局模型的内部特征归因。

Result: 攻击将Grad-CAM解释中的峰值激活重叠减少了高达35%，同时在所有评估数据集上保持分类准确率超过96%。标准训练流程不足以检测或缓解解释退化，特别是在联邦学习设置中，细微的颜色扰动更难察觉。

Conclusion: 研究结果表明可解释性本身可以成为攻击面，挑战了模型审计中正确预测即意味着忠实解释的常见假设。联邦学习设置中的细微颜色扰动对模型解释的忠实性构成严重威胁。

Abstract: As machine learning models are increasingly deployed in safety-critical domains, visual explanation techniques have become essential tools for supporting transparency. In this work, we reveal a new class of attacks that compromise model interpretability without affecting accuracy. Specifically, we show that small color perturbations applied by adversarial clients in a federated learning setting can shift a model's saliency maps away from semantically meaningful regions while keeping the prediction unchanged. The proposed saliency-aware attack framework, called Chromatic Perturbation Module, systematically crafts adversarial examples by altering the color contrast between foreground and background in a way that disrupts explanation fidelity. These perturbations accumulate across training rounds, poisoning the global model's internal feature attributions in a stealthy and persistent manner. Our findings challenge a common assumption in model auditing that correct predictions imply faithful explanations and demonstrate that interpretability itself can be an attack surface. We evaluate this vulnerability across multiple datasets and show that standard training pipelines are insufficient to detect or mitigate explanation degradation, especially in the federated learning setting, where subtle color perturbations are harder to discern. Our attack reduces peak activation overlap in Grad-CAM explanations by up to 35% while preserving classification accuracy above 96% on all evaluated datasets.

</details>


### [210] [BootOOD: Self-Supervised Out-of-Distribution Detection via Synthetic Sample Exposure under Neural Collapse](https://arxiv.org/abs/2511.13539)
*Yuanchao Wang,Tian Qin,Eduardo Valle,Bruno Abrahao*

Main category: cs.CV

TL;DR: BootOOD是一个完全自监督的OOD检测框架，通过从ID数据中合成伪OOD特征，利用神经崩溃现象，使用基于特征范数的轻量级辅助头进行OOD检测，在语义相似的OOD样本上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的OOD检测器在处理与ID类别语义相似的OOD样本时表现不佳，需要一种能够专门处理这种语义挑战性OOD样本的检测方法。

Method: 通过ID表示的简单变换合成伪OOD特征，利用神经崩溃现象，引入基于特征范数的轻量级辅助头进行半径分类，将OOD检测与主分类器解耦。

Result: 在CIFAR-10、CIFAR-100和ImageNet-200上的实验表明，BootOOD优于先验的后处理方法，在没有异常暴露的情况下超越基于训练的方法，并与最先进的异常暴露方法竞争，同时保持或提高ID准确率。

Conclusion: BootOOD提供了一种有效的自监督OOD检测解决方案，特别适用于处理语义相似的OOD样本，在多个基准测试中表现出色。

Abstract: Out-of-distribution (OOD) detection is critical for deploying image classifiers in safety-sensitive environments, yet existing detectors often struggle when OOD samples are semantically similar to the in-distribution (ID) classes. We present BootOOD, a fully self-supervised OOD detection framework that bootstraps exclusively from ID data and is explicitly designed to handle semantically challenging OOD samples. BootOOD synthesizes pseudo-OOD features through simple transformations of ID representations and leverages Neural Collapse (NC), where ID features cluster tightly around class means with consistent feature norms. Unlike prior approaches that aim to constrain OOD features into subspaces orthogonal to the collapsed ID means, BootOOD introduces a lightweight auxiliary head that performs radius-based classification on feature norms. This design decouples OOD detection from the primary classifier and imposes a relaxed requirement: OOD samples are learned to have smaller feature norms than ID features, which is easier to satisfy when ID and OOD are semantically close. Experiments on CIFAR-10, CIFAR-100, and ImageNet-200 show that BootOOD outperforms prior post-hoc methods, surpasses training-based methods without outlier exposure, and is competitive with state-of-the-art outlier-exposure approaches while maintaining or improving ID accuracy.

</details>


### [211] [Alpha Divergence Losses for Biometric Verification](https://arxiv.org/abs/2511.13621)
*Dimitrios Koutsianos,Ladislav Mosner,Yannis Panagakis,Themos Stafylakis*

Main category: cs.CV

TL;DR: 本文提出了两种基于α-散度的边际损失函数：Q-Margin（在参考度量中引入边际）和A3M（在对数中引入边际），用于提升人脸和说话人验证性能，特别是在低误接受率下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的基于边际的softmax损失（如CosFace和ArcFace）在人脸和说话人验证中表现良好，但α-散度损失函数能够诱导稀疏解，将其与角度边际结合以提升验证任务性能。

Method: 通过两种方式将角度边际集成到α-散度损失中：在参考度量中引入边际（Q-Margin）和在对数中引入边际（A3M），并针对A3M的训练不稳定性提出了原型重新初始化策略。

Result: 在IJB-B和IJB-C人脸验证基准以及VoxCeleb说话人验证上取得了显著性能提升，特别是在低误接受率下明显优于强基线方法。

Conclusion: 提出的Q-Margin和A3M方法有效结合了α-散度的稀疏性和角度边际的判别能力，为高安全性应用（如银行认证）提供了更可靠的验证解决方案。

Abstract: Performance in face and speaker verification is largely driven by margin based softmax losses like CosFace and ArcFace. Recently introduced $α$-divergence loss functions offer a compelling alternative, particularly for their ability to induce sparse solutions (when $α>1$). However, integrating an angular margin-crucial for verification tasks-is not straightforward. We find this integration can be achieved in at least two distinct ways: via the reference measure (prior probabilities) or via the logits (unnormalized log-likelihoods). In this paper, we explore both pathways, deriving two novel margin-based $α$-divergence losses: Q-Margin (margin in the reference measure) and A3M (margin in the logits). We identify and address a critical training instability in A3M-caused by the interplay of penalized logits and sparsity-with a simple yet effective prototype re-initialization strategy. Our methods achieve significant performance gains on the challenging IJB-B and IJB-C face verification benchmarks. We demonstrate similarly strong performance in speaker verification on VoxCeleb. Crucially, our models significantly outperform strong baselines at low false acceptance rates (FAR). This capability is crucial for practical high-security applications, such as banking authentication, when minimizing false authentications is paramount.

</details>


### [212] [Opt3DGS: Optimizing 3D Gaussian Splatting with Adaptive Exploration and Curvature-Aware Exploitation](https://arxiv.org/abs/2511.13571)
*Ziyang Huang,Jiagang Chen,Jin Liu,Shunping Ji*

Main category: cs.CV

TL;DR: Opt3DGS提出了一个两阶段优化框架来解决3D高斯泼溅（3DGS）中的局部最优陷阱和收敛质量不足问题，通过自适应探索和曲率引导开发提升渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3DGS在新视角合成中表现出色，但其核心优化问题尚未充分探索，存在陷入局部最优和收敛质量不足两个关键问题。

Method: 采用两阶段优化过程：探索阶段使用自适应加权随机梯度Langevin动力学（SGLD）增强全局搜索；开发阶段使用局部拟牛顿方向引导的Adam优化器利用曲率信息进行精确收敛。

Result: 在多个基准数据集上的广泛实验表明，Opt3DGS在不改变3DGS底层表示的情况下实现了最先进的渲染质量。

Conclusion: Opt3DGS通过改进3DGS的优化过程有效解决了其优化挑战，显著提升了渲染性能。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading framework for novel view synthesis, yet its core optimization challenges remain underexplored. We identify two key issues in 3DGS optimization: entrapment in suboptimal local optima and insufficient convergence quality. To address these, we propose Opt3DGS, a robust framework that enhances 3DGS through a two-stage optimization process of adaptive exploration and curvature-guided exploitation. In the exploration phase, an Adaptive Weighted Stochastic Gradient Langevin Dynamics (SGLD) method enhances global search to escape local optima. In the exploitation phase, a Local Quasi-Newton Direction-guided Adam optimizer leverages curvature information for precise and efficient convergence. Extensive experiments on diverse benchmark datasets demonstrate that Opt3DGS achieves state-of-the-art rendering quality by refining the 3DGS optimization process without modifying its underlying representation.

</details>


### [213] [Adaptive Multi-Scale Integration Unlocks Robust Cell Annotation in Histopathology Images](https://arxiv.org/abs/2511.13586)
*Yinuo Xu,Yan Cui,Mingyao Li,Zhi Huang*

Main category: cs.CV

TL;DR: NuClass是一个病理学家工作流程启发的框架，用于细胞级别的多尺度整合核形态和微环境上下文，通过可学习的门控模块平衡局部细节和上下文线索，并利用不确定性引导目标促进互补学习。


<details>
  <summary>Details</summary>
Motivation: 现有基于图块的模型能够捕捉详细的核形态但往往无法融入影响细胞功能和身份的更广泛组织上下文，且可用的人类标注通常是粗粒度的，难以获得细粒度的亚型级监督。

Method: NuClass包含两个主要组件：Path local（关注224×224像素裁剪的核形态）和Path global（建模周围1024×1024像素邻域），通过可学习门控模块自适应平衡局部细节和上下文线索，并采用不确定性引导目标。

Result: 在三个完全保留的队列上评估，NuClass在其最佳表现类别上达到96%的F1分数，优于强基线方法。

Conclusion: 多尺度、不确定性感知融合可以弥合切片级病理基础模型与可靠细胞级表型预测之间的差距。

Abstract: Identifying cell types and subtypes from routine histopathology images is essential for improving the computational understanding of human disease. Existing tile-based models can capture detailed nuclear morphology but often fail to incorporate the broader tissue context that influences a cell's function and identity. In addition, available human annotations are typically coarse-grained and unevenly distributed across studies, making fine-grained subtype-level supervision difficult to obtain.
  To address these limitations, we introduce NuClass, a pathologist workflow inspired framework for cell-wise multi-scale integration of nuclear morphology and microenvironmental context. NuClass includes two main components: Path local, which focuses on nuclear morphology from 224-by-224 pixel crops, and Path global, which models the surrounding 1024-by-1024 pixel neighborhood. A learnable gating module adaptively balances local detail and contextual cues. To encourage complementary learning, we incorporate an uncertainty-guided objective that directs the global path to prioritize regions where the local path is uncertain. We also provide calibrated confidence estimates and Grad-CAM visualizations to enhance interpretability.
  To overcome the lack of high-quality annotations, we construct a marker-guided dataset from Xenium spatial transcriptomics assays, yielding single-cell resolution labels for more than two million cells across eight organs and 16 classes. Evaluated on three fully held-out cohorts, NuClass achieves up to 96 percent F1 for its best-performing class, outperforming strong baselines. Our results show that multi-scale, uncertainty-aware fusion can bridge the gap between slide-level pathological foundation models and reliable, cell-level phenotype prediction.

</details>


### [214] [UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity](https://arxiv.org/abs/2511.13714)
*Junwei Yu,Trevor Darrell,XuDong Wang*

Main category: cs.CV

TL;DR: UnSAMv2是一个无需人工标注就能实现任意粒度分割的模型，通过发现丰富的掩码-粒度对和引入粒度控制嵌入，在仅使用6K未标注图像和0.02%额外参数的情况下，显著提升了SAM-2的分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决SAM模型在控制分割粒度方面的局限性，用户通常需要手动细化结果来达到所需细节水平，这个过程既模糊又昂贵，使得监督解决方案不可行。

Method: 扩展UnSAM的分治策略，发现丰富的掩码-粒度对，并引入新颖的粒度控制嵌入，实现对分割尺度的精确连续控制。

Result: 在超过11个基准测试中，UnSAMv2显著提升了SAM-2的性能：NoC90从5.69降至4.75，1-IoU从58.0提升至73.1，AR1000从49.6提升至68.3。

Conclusion: 少量未标注数据结合粒度感知的自监督学习方法可以释放视觉基础模型的潜力。

Abstract: The Segment Anything Model (SAM) family has become a widely adopted vision foundation model, but its ability to control segmentation granularity remains limited. Users often need to refine results manually - by adding more prompts or selecting from pre-generated masks - to achieve the desired level of detail. This process can be ambiguous, as the same prompt may correspond to several plausible masks, and collecting dense annotations across all granularities is prohibitively expensive, making supervised solutions infeasible. To address this limitation, we introduce UnSAMv2, which enables segment anything at any granularity without human annotations. UnSAMv2 extends the divide-and-conquer strategy of UnSAM by discovering abundant mask-granularity pairs and introducing a novel granularity control embedding that enables precise, continuous control over segmentation scale. Remarkably, with only $6$K unlabeled images and $0.02\%$ additional parameters, UnSAMv2 substantially enhances SAM-2, achieving segment anything at any granularity across interactive, whole-image, and video segmentation tasks. Evaluated on over $11$ benchmarks, UnSAMv2 improves $\text{NoC}_{90}$ (5.69 $\rightarrow$ 4.75), 1-IoU (58.0 $\rightarrow$ 73.1), and $\text{AR}_{1000}$ (49.6 $\rightarrow$ 68.3), showing that small amounts of unlabeled data with a granularity-aware self-supervised learning method can unlock the potential of vision foundation models.

</details>


### [215] [Scaling Spatial Intelligence with Multimodal Foundation Models](https://arxiv.org/abs/2511.13719)
*Zhongang Cai,Ruisi Wang,Chenyang Gu,Fanyi Pu,Junxiang Xu,Yubo Wang,Wanqi Yin,Zhitao Yang,Chen Wei,Qingping Sun,Tongxi Zhou,Jiaqi Li,Hui En Pang,Oscar Qian,Yukun Wei,Zhiqian Lin,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Xiangyu Fan,Hanming Deng,Lewei Lu,Liang Pan,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: SenseNova-SI项目通过构建800万多样化的空间智能数据集，在现有多模态基础模型上提升了空间智能能力，在多个基准测试中取得领先性能，并分析了数据扩展、泛化能力等关键问题。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型取得了显著进展，但在空间智能方面仍存在明显不足，需要专门提升模型的空间理解和推理能力。

Method: 基于Qwen3-VL、InternVL3和Bagel等多模态基础模型，系统构建包含800万多样化样本的SenseNova-SI-8M数据集，采用严格的空间能力分类法进行数据整理。

Result: 在多个空间智能基准测试中表现优异：VSI-Bench 68.7%、MMSI 43.3%、MindCube 85.6%、ViewSpatial 54.6%、SITE 50.1%，同时保持强大的通用多模态理解能力（MMBench-En 84.9%）。

Conclusion: SenseNova-SI项目验证了通过大规模多样化数据训练可以显著提升空间智能能力，发现了早期涌现的泛化能力迹象，并公开了所有新训练的多模态基础模型以促进进一步研究。

Abstract: Despite remarkable progress, multimodal foundation models still exhibit surprising deficiencies in spatial intelligence. In this work, we explore scaling up multimodal foundation models to cultivate spatial intelligence within the SenseNova-SI family, built upon established multimodal foundations including visual understanding models (i.e., Qwen3-VL and InternVL3) and unified understanding and generation models (i.e., Bagel). We take a principled approach to constructing high-performing and robust spatial intelligence by systematically curating SenseNova-SI-8M: eight million diverse data samples under a rigorous taxonomy of spatial capabilities. SenseNova-SI demonstrates unprecedented performance across a broad range of spatial intelligence benchmarks: 68.7% on VSI-Bench, 43.3% on MMSI, 85.6% on MindCube, 54.6% on ViewSpatial, and 50.1% on SITE, while maintaining strong general multimodal understanding (e.g., 84.9% on MMBench-En). More importantly, we analyze the impact of data scaling, discuss early signs of emergent generalization capabilities enabled by diverse data training, analyze the risk of overfitting and language shortcuts, present a preliminary study on spatial chain-of-thought reasoning, and validate the potential downstream application. SenseNova-SI is an ongoing project, and this report will be updated continuously. All newly trained multimodal foundation models are publicly released to facilitate further research in this direction.

</details>


### [216] [Tissue Aware Nuclei Detection and Classification Model for Histopathology Images](https://arxiv.org/abs/2511.13615)
*Kesi Xu,Eleni Chiou,Ali Varamesh,Laura Acqualagna,Nasir Rajpoot*

Main category: cs.CV

TL;DR: TAND是一个新颖的组织感知细胞核检测框架，通过结合点级监督和组织掩码条件化，实现了细胞核的联合检测和分类，在PUMA基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在对详细专家标注的依赖和组织上下文信息利用不足的问题，需要开发更高效的细胞核检测和分类方法以减少标注负担。

Method: TAND将ConvNeXt编码器-解码器与冻结的Virchow-2组织分割分支耦合，通过新颖的多尺度空间特征线性调制技术，利用语义组织概率选择性地调节分类流。

Result: 在PUMA基准测试中，TAND实现了最先进的性能，超越了组织无关基线和掩码监督方法，特别是在上皮细胞、内皮细胞和基质细胞等组织依赖性细胞类型上表现出显著改进。

Conclusion: 这是首个基于学习组织掩码进行单细胞分类条件化的方法，为减少标注负担提供了实用途径。

Abstract: Accurate nuclei detection and classification are fundamental to computational pathology, yet existing approaches are hindered by reliance on detailed expert annotations and insufficient use of tissue context. We present Tissue-Aware Nuclei Detection (TAND), a novel framework achieving joint nuclei detection and classification using point-level supervision enhanced by tissue mask conditioning. TAND couples a ConvNeXt-based encoder-decoder with a frozen Virchow-2 tissue segmentation branch, where semantic tissue probabilities selectively modulate the classification stream through a novel multi-scale Spatial Feature-wise Linear Modulation (Spatial-FiLM). On the PUMA benchmark, TAND achieves state-of-the-art performance, surpassing both tissue-agnostic baselines and mask-supervised methods. Notably, our approach demonstrates remarkable improvements in tissue-dependent cell types such as epithelium, endothelium, and stroma. To the best of our knowledge, this is the first method to condition per-cell classification on learned tissue masks, offering a practical pathway to reduce annotation burden.

</details>


### [217] [CacheFlow: Compressive Streaming Memory for Efficient Long-Form Video Understanding](https://arxiv.org/abs/2511.13644)
*Shrenik Patel,Daivik Patel*

Main category: cs.CV

TL;DR: CacheFlow是一种无需训练的视频问答方法，通过动态令牌丢弃和压缩长期记忆来减少注意力计算，在保持答案准确性的同时处理更少的令牌。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在处理长视频问答时面临注意力机制和KV缓存随运行时间增长的问题，导致推理成本高昂或只能使用短视的滑动窗口方法。

Method: 结合动态令牌丢弃和压缩长期记忆：DTD通过余弦相似度在线修剪每个补丁的令牌，幸存令牌打包成固定大小的块；使用小型循环编码器构建检索索引，在推理时检索最相关的Top-K块进行注意力计算。

Result: 在离线和流式视频问答基准测试中，CacheFlow优于当前强基线方法，同时处理令牌数量减少高达87%。

Conclusion: CacheFlow使视觉语言模型既高效又具备上下文感知能力，为实用的长视频理解铺平了道路。

Abstract: Long-form video question answering (VQA) overwhelms current vision-language models (VLMs) because attention and key-value (KV) caches grow with runtime, forcing either expensive inference or near-sighted sliding windows. We introduce CacheFlow, a training-free pipeline that pairs Dynamic Token Dropping (DTD) with a compressive long-term memory. DTD prunes per-patch tokens online via cosine similarity to the previous frame, and surviving tokens are packed into fixed-size blocks. This online, per-frame processing makes our approach fundamentally suited for live streaming VQA. As blocks are processed, each one's keys are summarized by a tiny recurrent encoder to form a retrieval index, while the block's full KV pairs are offloaded and later rehydrated for generation, preserving answer fidelity. At inference, a consensus-based retrieval mechanism retrieves only the Top-K most relevant blocks and attends over both the retrieved and local context for precise, long-range reasoning. CacheFlow is drop-in, architecture-agnostic, and requires no fine-tuning. Experiments on both offline and streaming VQA benchmarks demonstrate that CacheFlow outperforms current strong baselines, while processing up to 87% less tokens. Our dual approach enables VLMs to be both efficient and context-aware, paving the way for practical long-form video understanding.

</details>


### [218] [Part-X-MLLM: Part-aware 3D Multimodal Large Language Model](https://arxiv.org/abs/2511.13647)
*Chunshi Wang,Junliang Ye,Yunhan Yang,Yang Li,Zizhuo Lin,Jun Zhu,Zhuo Chen,Yawei Luo,Chunchao Guo*

Main category: cs.CV

TL;DR: Part-X-MLLM是一个原生3D多模态大语言模型，通过将多样3D任务统一为结构化可执行语法中的程序，实现统一的3D理解和生成接口。


<details>
  <summary>Details</summary>
Motivation: 现有的3D多模态模型往往针对特定任务设计，缺乏统一的接口来处理多样化的3D任务，如部件级检测、语义描述和编辑命令。

Method: 采用双编码器架构，将结构信息与语义信息解耦，在RGB点云和自然语言提示下自回归生成包含部件级边界框、语义描述和编辑命令的结构化令牌序列。

Result: 模型在结构化规划生成方面表现出色，在基于部件的问答、组合生成和局部化编辑等任务中实现了最先进的性能。

Conclusion: Part-X-MLLM通过将符号规划与几何合成解耦，为任何兼容的几何引擎提供了单一的语言原生前端，实现了统一的3D多模态接口。

Abstract: We introduce Part-X-MLLM, a native 3D multimodal large language model that unifies diverse 3D tasks by formulating them as programs in a structured, executable grammar. Given an RGB point cloud and a natural language prompt, our model autoregressively generates a single, coherent token sequence encoding part-level bounding boxes, semantic descriptions, and edit commands. This structured output serves as a versatile interface to drive downstream geometry-aware modules for part-based generation and editing. By decoupling the symbolic planning from the geometric synthesis, our approach allows any compatible geometry engine to be controlled through a single, language-native frontend. We pre-train a dual-encoder architecture to disentangle structure from semantics and instruction-tune the model on a large-scale, part-centric dataset. Experiments demonstrate that our model excels at producing high-quality, structured plans, enabling state-of-the-art performance in grounded Q\&A, compositional generation, and localized editing through one unified interface. Project page: https://chunshi.wang/Part-X-MLLM/

</details>


### [219] [PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image](https://arxiv.org/abs/2511.13648)
*Ziang Cao,Fangzhou Hong,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: PhysX-Anything是首个面向仿真的物理3D生成框架，能从单张图像生成具有明确几何结构、关节连接和物理属性的高质量仿真就绪3D资产。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法大多忽略了关键的物理和关节属性，限制了在具身AI中的应用。需要将3D建模从静态视觉表示转向可直接用于仿真和交互的物理化、可关节化的资产。

Method: 提出了首个基于VLM的物理3D生成模型，采用新的3D表示方法将几何结构高效分词，token数量减少193倍，无需在微调时引入特殊token。构建了PhysX-Mobility数据集，包含2000多个常见真实世界物体，物理标注丰富。

Result: 在PhysX-Mobility数据集和真实世界图像上的广泛实验表明，PhysX-Anything具有强大的生成性能和稳健的泛化能力。在MuJoCo风格环境中的仿真实验验证了生成的仿真就绪资产可直接用于接触密集的机器人策略学习。

Conclusion: PhysX-Anything能够显著赋能下游应用，特别是在具身AI和基于物理的仿真领域，为3D生成向物理化、可交互化方向发展提供了重要推动。

Abstract: 3D modeling is shifting from static visual representations toward physical, articulated assets that can be directly used in simulation and interaction. However, most existing 3D generation methods overlook key physical and articulation properties, thereby limiting their utility in embodied AI. To bridge this gap, we introduce PhysX-Anything, the first simulation-ready physical 3D generative framework that, given a single in-the-wild image, produces high-quality sim-ready 3D assets with explicit geometry, articulation, and physical attributes. Specifically, we propose the first VLM-based physical 3D generative model, along with a new 3D representation that efficiently tokenizes geometry. It reduces the number of tokens by 193x, enabling explicit geometry learning within standard VLM token budgets without introducing any special tokens during fine-tuning and significantly improving generative quality. In addition, to overcome the limited diversity of existing physical 3D datasets, we construct a new dataset, PhysX-Mobility, which expands the object categories in prior physical 3D datasets by over 2x and includes more than 2K common real-world objects with rich physical annotations. Extensive experiments on PhysX-Mobility and in-the-wild images demonstrate that PhysX-Anything delivers strong generative performance and robust generalization. Furthermore, simulation-based experiments in a MuJoCo-style environment validate that our sim-ready assets can be directly used for contact-rich robotic policy learning. We believe PhysX-Anything can substantially empower a broad range of downstream applications, especially in embodied AI and physics-based simulation.

</details>


### [220] [Distribution Matching Distillation Meets Reinforcement Learning](https://arxiv.org/abs/2511.13649)
*Dengyang Jiang,Dongyang Liu,Zanyi Wang,Qilong Wu,Xin Jin,David Liu,Zhen Li,Mengmeng Wang,Peng Gao,Harry Yang*

Main category: cs.CV

TL;DR: DMDR是一个结合强化学习和蒸馏的新框架，用于将多步扩散模型蒸馏为少步模型，在保持推理效率的同时提升性能，甚至能超越原始教师模型。


<details>
  <summary>Details</summary>
Motivation: 传统的分布匹配蒸馏方法虽然能提高推理效率，但少步模型的性能往往受限于多步教师模型。为了突破这一限制，需要探索新的方法来释放少步生成器的潜力。

Method: 将强化学习技术融入蒸馏过程，使用DMD损失作为更有效的正则化方法；设计动态分布引导和动态重噪声采样训练策略来改进初始蒸馏过程。

Result: 实验表明DMDR在视觉质量、提示一致性方面在少步方法中表现领先，甚至展现出超越多步教师模型的性能。

Conclusion: DMDR通过同时进行蒸馏和强化学习，成功释放了少步生成器的能力，实现了性能突破，为高效扩散模型蒸馏提供了新思路。

Abstract: Distribution Matching Distillation (DMD) distills a pre-trained multi-step diffusion model to a few-step one to improve inference efficiency. However, the performance of the latter is often capped by the former. To circumvent this dilemma, we propose DMDR, a novel framework that combines Reinforcement Learning (RL) techniques into the distillation process. We show that for the RL of the few-step generator, the DMD loss itself is a more effective regularization compared to the traditional ones. In turn, RL can help to guide the mode coverage process in DMD more effectively. These allow us to unlock the capacity of the few-step generator by conducting distillation and RL simultaneously. Meanwhile, we design the dynamic distribution guidance and dynamic renoise sampling training strategies to improve the initial distillation process. The experiments demonstrate that DMDR can achieve leading visual quality, prompt coherence among few-step methods, and even exhibit performance that exceeds the multi-step teacher.

</details>


### [221] [OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation](https://arxiv.org/abs/2511.13655)
*Henry Herzog,Favyen Bastani,Yawen Zhang,Gabriel Tseng,Joseph Redmon,Hadrien Sablon,Ryan Park,Jacob Morrison,Alexandra Buraczynski,Karen Farley,Joshua Hansen,Andrew Howe,Patrick Alan Johnson,Mark Otterlee,Ted Schmitt,Hunter Pitelka,Stephen Daspit,Rachel Ratner,Christopher Wilhelm,Sebastian Wood,Mike Jacobi,Hannah Kerner,Evan Shelhamer,Ali Farhadi,Ranjay Krishna,Patrick Beukema*

Main category: cs.CV

TL;DR: OlmoEarth是一个多模态、时空基础模型，专门为地球观测数据设计，在多个基准测试和实际任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 地球观测数据具有空间性（如图像）、序列性（如视频或文本）和多模态特性，需要专门的模型来处理这些复杂特征。

Method: 采用新颖的自监督学习框架、掩码策略和损失函数，专门针对地球观测领域设计。

Result: 在24个任务中的15个任务上获得最佳嵌入性能，在29个任务中的19个任务上获得最佳微调性能，优于其他12个基础模型。

Conclusion: OlmoEarth作为端到端平台的核心，为非营利组织和NGO提供前沿基础模型和强大数据管理工具，用于解决全球重大问题。

Abstract: Earth observation data presents a unique challenge: it is spatial like images, sequential like video or text, and highly multimodal. We present OlmoEarth: a multimodal, spatio-temporal foundation model that employs a novel self-supervised learning formulation, masking strategy, and loss all designed for the Earth observation domain. OlmoEarth achieves state-of-the-art performance compared to 12 other foundation models across a variety of research benchmarks and real-world tasks from external partners. When evaluating embeddings OlmoEarth achieves the best performance on 15 out of 24 tasks, and with full fine-tuning it is the best on 19 of 29 tasks. We deploy OlmoEarth as the backbone of an end-to-end platform for data collection, labeling, training, and inference of Earth observation models. The OlmoEarth Platform puts frontier foundation models and powerful data management tools into the hands of non-profits and NGOs working to solve the world's biggest problems. OlmoEarth source code, training data, and pre-trained weights are available at $\href{https://github.com/allenai/olmoearth_pretrain}{\text{https://github.com/allenai/olmoearth_pretrain}}$.

</details>


### [222] [Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting](https://arxiv.org/abs/2511.13684)
*Jiangnan Ye,Jiedong Zhuang,Lianrui Mu,Wenjie Zheng,Jiaqi Hu,Xingze Zou,Jing Wang,Haoji Hu*

Main category: cs.CV

TL;DR: GS-Light是一个基于高斯泼溅(3DGS)的高效文本引导3D场景重光照方法，通过训练免费的扩散模型扩展处理多视图输入，利用大视觉语言模型解析光照先验，结合几何约束生成高质量重光照结果。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景重光照方法在处理用户指定的光照方向、颜色、强度等复杂文本指令时存在困难，需要一种能够准确理解用户意图并生成高质量重光照结果的方法。

Method: 使用LVLM解析文本提示为光照先验，结合深度、法线和语义分割等几何约束计算光照图，生成初始潜码指导扩散模型，通过多视图渲染图像和初始潜码输入多视图重光照模型，最后微调3DGS场景。

Result: 在室内外场景评估中，GS-Light在定量指标（多视图一致性、图像质量、美学评分、语义相似度等）和定性评估（用户研究）上均优于现有基线方法。

Conclusion: GS-Light提供了一种有效的文本引导3D场景重光照解决方案，能够准确反映用户期望的光照效果，特别是在光照方向控制方面表现优异。

Abstract: We introduce GS-Light, an efficient, textual position-aware pipeline for text-guided relighting of 3D scenes represented via Gaussian Splatting (3DGS). GS-Light implements a training-free extension of a single-input diffusion model to handle multi-view inputs. Given a user prompt that may specify lighting direction, color, intensity, or reference objects, we employ a large vision-language model (LVLM) to parse the prompt into lighting priors. Using off-the-shelf estimators for geometry and semantics (depth, surface normals, and semantic segmentation), we fuse these lighting priors with view-geometry constraints to compute illumination maps and generate initial latent codes for each view. These meticulously derived init latents guide the diffusion model to generate relighting outputs that more accurately reflect user expectations, especially in terms of lighting direction. By feeding multi-view rendered images, along with the init latents, into our multi-view relighting model, we produce high-fidelity, artistically relit images. Finally, we fine-tune the 3DGS scene with the relit appearance to obtain a fully relit 3D scene. We evaluate GS-Light on both indoor and outdoor scenes, comparing it to state-of-the-art baselines including per-view relighting, video relighting, and scene editing methods. Using quantitative metrics (multi-view consistency, imaging quality, aesthetic score, semantic similarity, etc.) and qualitative assessment (user studies), GS-Light demonstrates consistent improvements over baselines. Code and assets will be made available upon publication.

</details>


### [223] [TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models](https://arxiv.org/abs/2511.13704)
*Harold Haodong Chen,Disen Lan,Wen-Jie Shu,Qingyang Liu,Zihan Wang,Sirui Chen,Wenkai Cheng,Kanghao Chen,Hongfei Zhang,Zixin Zhang,Rongjin Guo,Yu Cheng,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 提出了TiViBench基准来评估图像到视频生成模型的推理能力，涵盖4个维度的24个任务场景，并开发了VideoTPO测试时优化策略来提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型评估主要关注视觉保真度和时间一致性，缺乏对高阶推理能力的系统评估，需要专门基准来填补这一空白。

Method: 设计分层基准TiViBench，系统评估结构推理、空间视觉模式推理、符号逻辑推理、动作规划四个维度的推理能力；提出VideoTPO测试时策略，通过LLM自分析生成候选来优化推理性能。

Result: 商业模型（如Sora 2、Veo 3.1）展现出更强的推理潜力，开源模型因训练规模和数据多样性限制而潜力未充分开发；VideoTPO无需额外训练即可显著提升推理性能。

Conclusion: TiViBench和VideoTPO为评估和推进视频生成模型的推理能力奠定了基础，为该新兴领域的未来研究设定了框架。

Abstract: The rapid evolution of video generative models has shifted their focus from producing visually plausible outputs to tackling tasks requiring physical plausibility and logical consistency. However, despite recent breakthroughs such as Veo 3's chain-of-frames reasoning, it remains unclear whether these models can exhibit reasoning capabilities similar to large language models (LLMs). Existing benchmarks predominantly evaluate visual fidelity and temporal coherence, failing to capture higher-order reasoning abilities. To bridge this gap, we propose TiViBench, a hierarchical benchmark specifically designed to evaluate the reasoning capabilities of image-to-video (I2V) generation models. TiViBench systematically assesses reasoning across four dimensions: i) Structural Reasoning & Search, ii) Spatial & Visual Pattern Reasoning, iii) Symbolic & Logical Reasoning, and iv) Action Planning & Task Execution, spanning 24 diverse task scenarios across 3 difficulty levels. Through extensive evaluations, we show that commercial models (e.g., Sora 2, Veo 3.1) demonstrate stronger reasoning potential, while open-source models reveal untapped potential that remains hindered by limited training scale and data diversity. To further unlock this potential, we introduce VideoTPO, a simple yet effective test-time strategy inspired by preference optimization. By performing LLM self-analysis on generated candidates to identify strengths and weaknesses, VideoTPO significantly enhances reasoning performance without requiring additional training, data, or reward models. Together, TiViBench and VideoTPO pave the way for evaluating and advancing reasoning in video generation models, setting a foundation for future research in this emerging field.

</details>


### [224] [Free-Form Scene Editor: Enabling Multi-Round Object Manipulation like in a 3D Engine](https://arxiv.org/abs/2511.13713)
*Xincheng Shuai,Zhenyuan Qin,Henghui Ding,Dacheng Tao*

Main category: cs.CV

TL;DR: FFSE是一个3D感知的自回归框架，能够在真实图像上实现直观、物理一致的对象编辑，通过建模为3D变换序列来支持平移、缩放、旋转等操作，同时保持背景效果和场景一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在语义图像编辑方面取得进展，但大多数方法难以实现3D感知的对象操作，要么在图像空间操作，要么需要缓慢且容易出错的3D重建。

Method: 提出FFSE框架，将编辑建模为学习的3D变换序列，并引入3DObjectEditor混合数据集，从模拟编辑序列中构建，支持多轮和动态条件下的有效训练。

Result: 广泛实验表明，FFSE在单轮和多轮3D感知编辑场景中显著优于现有方法。

Conclusion: FFSE框架能够实现直观、物理一致的3D感知对象编辑，在保持背景效果和场景一致性的同时，支持多轮编辑操作。

Abstract: Recent advances in text-to-image (T2I) diffusion models have significantly improved semantic image editing, yet most methods fall short in performing 3D-aware object manipulation. In this work, we present FFSE, a 3D-aware autoregressive framework designed to enable intuitive, physically-consistent object editing directly on real-world images. Unlike previous approaches that either operate in image space or require slow and error-prone 3D reconstruction, FFSE models editing as a sequence of learned 3D transformations, allowing users to perform arbitrary manipulations, such as translation, scaling, and rotation, while preserving realistic background effects (e.g., shadows, reflections) and maintaining global scene consistency across multiple editing rounds. To support learning of multi-round 3D-aware object manipulation, we introduce 3DObjectEditor, a hybrid dataset constructed from simulated editing sequences across diverse objects and scenes, enabling effective training under multi-round and dynamic conditions. Extensive experiments show that the proposed FFSE significantly outperforms existing methods in both single-round and multi-round 3D-aware editing scenarios.

</details>


### [225] [Segment Anything Across Shots: A Method and Benchmark](https://arxiv.org/abs/2511.13715)
*Hengrui Hu,Kaining Ying,Henghui Ding*

Main category: cs.CV

TL;DR: 本文提出了SAAS模型和TMA数据增强策略，用于解决多镜头半监督视频对象分割问题，通过模拟镜头转换来提升跨镜头分割性能，并在新基准Cut-VOS上取得SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有VOS方法主要针对单镜头视频，难以处理镜头间的不连续性，限制了实际应用。需要解决多镜头视频对象分割问题。

Method: 提出TMA数据增强策略，使用单镜头数据实现跨镜头泛化；开发SAAS模型，能够有效检测和理解镜头转换；建立Cut-VOS多镜头分割基准。

Result: 在YouMVOS和Cut-VOS基准上的广泛实验表明，SAAS模型通过有效模拟、理解和分割复杂转换，实现了最先进的性能。

Conclusion: SAAS模型和TMA策略成功解决了多镜头视频对象分割问题，为MVOS领域提供了有效的解决方案和评估基准。

Abstract: This work focuses on multi-shot semi-supervised video object segmentation (MVOS), which aims at segmenting the target object indicated by an initial mask throughout a video with multiple shots. The existing VOS methods mainly focus on single-shot videos and struggle with shot discontinuities, thereby limiting their real-world applicability. We propose a transition mimicking data augmentation strategy (TMA) which enables cross-shot generalization with single-shot data to alleviate the severe annotated multi-shot data sparsity, and the Segment Anything Across Shots (SAAS) model, which can detect and comprehend shot transitions effectively. To support evaluation and future study in MVOS, we introduce Cut-VOS, a new MVOS benchmark with dense mask annotations, diverse object categories, and high-frequency transitions. Extensive experiments on YouMVOS and Cut-VOS demonstrate that the proposed SAAS achieves state-of-the-art performance by effectively mimicking, understanding, and segmenting across complex transitions. The code and datasets are released at https://henghuiding.com/SAAS/.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [226] [The Environmental Impact of Ensemble Techniques in Recommender Systems](https://arxiv.org/abs/2511.11649)
*Jannik Nitschke*

Main category: cs.IR

TL;DR: 该论文研究了推荐系统中集成方法的环境影响，发现集成技术虽然能提升准确率0.3-5.7%，但能耗增加19-2549%，揭示了准确率与能耗之间的非线性关系。


<details>
  <summary>Details</summary>
Motivation: 集成技术在推荐系统中能提升10-30%准确率，但其环境影响尚未被测量。深度学习推荐算法每篇论文可产生3297kg CO2，但集成方法的能耗评估不足。

Method: 在两个框架（Surprise用于评分预测，LensKit用于排名）上进行了93次实验，使用四个数据集（10万到780万交互数据），评估了四种集成策略（平均、加权、堆叠/排名融合、顶级表现者）与简单基线和优化单模型的比较，使用智能插座测量能耗。

Result: 集成方法在提升准确率0.3-5.7%的同时，能耗增加19-2549%。顶级表现者集成效率最佳：在MovieLens-1M上RMSE提升0.96%，能耗增加18.8%；在MovieLens-100K上NDCG提升5.7%，能耗增加103%。详尽平均策略能耗增加88-270%但收益相当。最大数据集上Surprise集成能耗增加2005%（0.21Wh vs 0.01Wh），准确率仅提升1.2%，产生53.8mg CO2 vs 单模型的2.6mg CO2。

Conclusion: 该研究首次系统测量了集成推荐系统的能耗和碳足迹，证明选择性策略比详尽平均策略更高效，并识别了工业规模下的可扩展性限制，为推荐系统的可持续算法选择提供了依据。

Abstract: Ensemble techniques in recommender systems have demonstrated accuracy improvements of 10-30%, yet their environmental impact remains unmeasured. While deep learning recommendation algorithms can generate up to 3,297 kg CO2 per paper, ensemble methods have not been sufficiently evaluated for energy consumption. This thesis investigates how ensemble techniques influence environmental impact compared to single optimized models.
  We conducted 93 experiments across two frameworks (Surprise for rating prediction, LensKit for ranking) on four datasets spanning 100,000 to 7.8 million interactions. We evaluated four ensemble strategies (Average, Weighted, Stacking/Rank Fusion, Top Performers) against simple baselines and optimized single models, measuring energy consumption with a smart plug.
  Results revealed a non-linear accuracy-energy relationship. Ensemble methods achieved 0.3-5.7% accuracy improvements while consuming 19-2,549% more energy depending on dataset size and strategy. The Top Performers ensemble showed best efficiency: 0.96% RMSE improvement with 18.8% energy overhead on MovieLens-1M, and 5.7% NDCG improvement with 103% overhead on MovieLens-100K. Exhaustive averaging strategies consumed 88-270% more energy for comparable gains. On the largest dataset (Anime, 7.8M interactions), the Surprise ensemble consumed 2,005% more energy (0.21 Wh vs. 0.01 Wh) for 1.2% accuracy improvement, producing 53.8 mg CO2 versus 2.6 mg CO2 for the single model.
  This research provides one of the first systematic measurements of energy and carbon footprint for ensemble recommender systems, demonstrates that selective strategies offer superior efficiency over exhaustive averaging, and identifies scalability limitations at industrial scale. These findings enable informed decisions about sustainable algorithm selection in recommender systems.

</details>


### [227] [GroupRank: A Groupwise Reranking Paradigm Driven by Reinforcement Learning](https://arxiv.org/abs/2511.11653)
*Duolin Sun,Meixiu Long,Dan Yang,Yihan Jiao,Zhehao Tan,Jie Feng,Junjie Wang,Yue Shen,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.IR

TL;DR: 提出Groupwise重排序范式，解决现有Pointwise方法的排名近视陷阱和Listwise方法的列表刚性限制，通过组内比较平衡灵活性和全局感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有重排序方法存在核心困境：Pointwise方法简单灵活但独立评估文档，容易陷入排名近视陷阱；Listwise方法能感知全局排名但存在严重的可扩展性和灵活性限制。

Method: 提出Groupwise重排序范式，将查询和一组候选文档联合输入模型进行组内比较，为每个文档分配相关性分数。采用GRPO进行模型训练，结合异质奖励函数整合排名指标和分布奖励。还提出合成高质量检索和排名数据的创新流程。

Result: 在两个推理密集型检索基准BRIGHT和R2MED上进行广泛实验，验证了方法的有效性。

Conclusion: Groupwise范式在保持Pointwise方法灵活性的同时，实现了Listwise方法的比较能力，解决了现有重排序方法的理论困境。

Abstract: Large Language Models have shown strong potential as rerankers to enhance the overall performance of RAG systems. However, existing reranking paradigms are constrained by a core theoretical and practical dilemma: Pointwise methods, while simple and highly flexible, evaluate documents independently, making them prone to the Ranking Myopia Trap, overlooking the relative importance between documents. In contrast, Listwise methods can perceive the global ranking context, but suffer from inherent List Rigidity, leading to severe scalability and flexibility issues when handling large candidate sets. To address these challenges, we propose Groupwise, a novel reranking paradigm. In this approach, the query and a group of candidate documents are jointly fed into the model, which performs within-group comparisons to assign individual relevance scores to each document. This design retains the flexibility of Pointwise methods while enabling the comparative capability of Listwise methods. We further adopt GRPO for model training, equipped with a heterogeneous reward function that integrates ranking metrics with a distributional reward aimed at aligning score distributions across groups. To overcome the bottleneck caused by the scarcity of high quality labeled data, we further propose an innovative pipeline for synthesizing high quality retrieval and ranking data. The resulting data can be leveraged not only for training the reranker but also for training the retriever. Extensive experiments validate the effectiveness of our approach. On two reasoning intensive retrieval benchmarks, BRIGHT and R2MED.

</details>


### [228] [A Multimodal Manufacturing Safety Chatbot: Knowledge Base Design, Benchmark Development, and Evaluation of Multiple RAG Approaches](https://arxiv.org/abs/2511.11847)
*Ryan Singh,Austin Hamilton,Amanda White,Michael Wise,Ibrahim Yousif,Arthur Carvalho,Zhe Shan,Reza Abrisham Baf,Mohammad Mayyas,Lora A. Cavuoto,Fadel M. Megahed*

Main category: cs.IR

TL;DR: 本文开发了一个基于大语言模型的多模态聊天机器人，用于工业5.0环境下的安全培训系统，满足高精度、低延迟和低成本的设计要求。


<details>
  <summary>Details</summary>
Motivation: 工业5.0将制造范式转向更加以人为本的操作，确保工人安全是现代制造环境中的关键挑战。

Method: 采用设计科学研究方法，开发了基于检索增强生成的多模态聊天机器人，使用24种RAG配置进行全因子设计测试。

Result: 最佳配置实现了86.66%的准确率、10.04秒的平均延迟和每次查询0.005美元的平均成本。

Conclusion: 本研究提供了三个贡献：开源领域安全培训聊天机器人、验证的AI辅助安全指导评估基准，以及设计和评估工业5.0环境中AI赋能安全培训系统的系统方法。

Abstract: Ensuring worker safety remains a critical challenge in modern manufacturing environments. Industry 5.0 reorients the prevailing manufacturing paradigm toward more human-centric operations. Using a design science research methodology, we identify three essential requirements for next-generation safety training systems: high accuracy, low latency, and low cost. We introduce a multimodal chatbot powered by large language models that meets these design requirements. The chatbot uses retrieval-augmented generation to ground its responses in curated regulatory and technical documentation. To evaluate our solution, we developed a domain-specific benchmark of expert-validated question and answer pairs for three representative machines: a Bridgeport manual mill, a Haas TL-1 CNC lathe, and a Universal Robots UR5e collaborative robot. We tested 24 RAG configurations using a full-factorial design and assessed them with automated evaluations of correctness, latency, and cost. Our top 2 configurations were then evaluated by ten industry experts and academic researchers. Our results show that retrieval strategy and model configuration have a significant impact on performance. The top configuration (selected for chatbot deployment) achieved an accuracy of 86.66%, an average latency of 10.04 seconds, and an average cost of $0.005 per query. Overall, our work provides three contributions: an open-source, domain-grounded safety training chatbot; a validated benchmark for evaluating AI-assisted safety instruction; and a systematic methodology for designing and assessing AI-enabled instructional and immersive safety training systems for Industry 5.0 environments.

</details>


### [229] [ComLQ: Benchmarking Complex Logical Queries in Information Retrieval](https://arxiv.org/abs/2511.12004)
*Ganlin Xu,Zhitao Yin,Linghao Zhang,Jiaqing Liang,Weijia Lu,Xiaodong Zhang,Zhifei Yang,Sihang Jiang,Deqing Yang*

Main category: cs.IR

TL;DR: 提出了ComLQ数据集，用于评估信息检索系统处理复杂逻辑查询的能力，包含2,909个查询和11,251个候选段落，并设计了新的评估指标LSNC@K来衡量检索模型处理否定查询的能力。


<details>
  <summary>Details</summary>
Motivation: 现有IR基准主要关注简单查询，忽略了包含合取、析取和否定等一阶逻辑操作的复杂逻辑查询，无法充分评估IR模型在真实场景中对复杂查询的性能。

Method: 利用大语言模型（如GPT-4o）构建ComLQ数据集，通过设计子图引导提示和子图指示器，引导LLM基于选定段落生成具有特定逻辑结构的查询，并通过专家标注确保结构一致性和证据分布。

Result: 实验结果表明，现有检索模型在复杂逻辑查询上的性能有限，特别是在处理否定查询时表现出较差的排除建模能力。

Conclusion: ComLQ数据集填补了复杂逻辑查询评估的空白，LSNC@K指标有效补充了标准相关性指标，揭示了现有检索模型在处理否定查询方面的局限性。

Abstract: Information retrieval (IR) systems play a critical role in navigating information overload across various applications. Existing IR benchmarks primarily focus on simple queries that are semantically analogous to single- and multi-hop relations, overlooking \emph{complex logical queries} involving first-order logic operations such as conjunction ($\land$), disjunction ($\lor$), and negation ($\lnot$). Thus, these benchmarks can not be used to sufficiently evaluate the performance of IR models on complex queries in real-world scenarios. To address this problem, we propose a novel method leveraging large language models (LLMs) to construct a new IR dataset \textbf{ComLQ} for \textbf{Com}plex \textbf{L}ogical \textbf{Q}ueries, which comprises 2,909 queries and 11,251 candidate passages. A key challenge in constructing the dataset lies in capturing the underlying logical structures within unstructured text. Therefore, by designing the subgraph-guided prompt with the subgraph indicator, an LLM (such as GPT-4o) is guided to generate queries with specific logical structures based on selected passages. All query-passage pairs in ComLQ are ensured \emph{structure conformity} and \emph{evidence distribution} through expert annotation. To better evaluate whether retrievers can handle queries with negation, we further propose a new evaluation metric, \textbf{Log-Scaled Negation Consistency} (\textbf{LSNC@$K$}). As a supplement to standard relevance-based metrics (such as nDCG and mAP), LSNC@$K$ measures whether top-$K$ retrieved passages violate negation conditions in queries. Our experimental results under zero-shot settings demonstrate existing retrieval models' limited performance on complex logical queries, especially on queries with negation, exposing their inferior capabilities of modeling exclusion.

</details>


### [230] [From Scaling to Structured Expressivity: Rethinking Transformers for CTR Prediction](https://arxiv.org/abs/2511.12081)
*Bencheng Yan,Yuejie Lei,Zhiyuan Zeng,Di Wang,Kaiyi Lin,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.IR

TL;DR: 本文提出了Field-Aware Transformer (FAT)来解决CTR预测中深度学习模型规模扩大但收益递减的问题，通过引入基于字段的交互先验，使模型复杂度与字段数量而非词汇量成正比，实现了可扩展的幂律增长。


<details>
  <summary>Details</summary>
Motivation: 当前CTR预测的深度模型在规模扩大时表现出收益迅速递减，与大型语言模型的平滑可预测增益形成鲜明对比。根本原因是结构错配：Transformer假设序列组合性，而CTR数据需要在高基数语义字段上进行组合推理。

Method: 提出Field-Aware Transformer (FAT)，通过分解的内容对齐和跨字段调制，将基于字段的交互先验嵌入到注意力机制中。这种设计确保模型复杂度与字段数量F成正比，而不是总词汇量n >> F。

Result: FAT在大规模基准测试中比最先进方法提高AUC达+0.51%。在线部署时，实现了+2.33%的CTR和+0.66%的RPM提升。首次建立了CTR模型的正式扩展定律，解释了观察到的幂律缩放行为。

Conclusion: 推荐系统中有效的扩展不是来自规模，而是来自结构化表达能力——架构与数据语义的一致性。FAT通过恢复这种对齐，实现了可预测的幂律缩放和更好的泛化性能。

Abstract: Despite massive investments in scale, deep models for click-through rate (CTR) prediction often exhibit rapidly diminishing returns - a stark contrast to the smooth, predictable gains seen in large language models. We identify the root cause as a structural misalignment: Transformers assume sequential compositionality, while CTR data demand combinatorial reasoning over high-cardinality semantic fields. Unstructured attention spreads capacity indiscriminately, amplifying noise under extreme sparsity and breaking scalable learning. To restore alignment, we introduce the Field-Aware Transformer (FAT), which embeds field-based interaction priors into attention through decomposed content alignment and cross-field modulation. This design ensures model complexity scales with the number of fields F, not the total vocabulary size n >> F, leading to tighter generalization and, critically, observed power-law scaling in AUC as model width increases. We present the first formal scaling law for CTR models, grounded in Rademacher complexity, that explains and predicts this behavior. On large-scale benchmarks, FAT improves AUC by up to +0.51% over state-of-the-art methods. Deployed online, it delivers +2.33% CTR and +0.66% RPM. Our work establishes that effective scaling in recommendation arises not from size, but from structured expressivity-architectural coherence with data semantics.

</details>


### [231] [Continuous-time Discrete-space Diffusion Model for Recommendation](https://arxiv.org/abs/2511.12114)
*Chengyi Liu,Xiao Chen,Shijie Wang,Wenqi Fan,Qing Li*

Main category: cs.IR

TL;DR: CDRec是一个连续时间离散空间的扩散推荐框架，通过离散扩散算法在历史交互上建模用户行为模式，结合流行度感知噪声调度和多跳协同信号对比学习，在推荐准确性和计算效率方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的推荐方法主要在连续空间操作，可能导致信息损失和计算效率低下。需要开发在离散空间操作的扩散推荐框架来更好地捕捉用户行为模式。

Method: 提出CDRec框架：1）在连续时间上对历史交互进行离散扩散建模；2）引入流行度感知噪声调度生成有语义意义的扩散轨迹；3）结合一致性参数化快速采样和多跳协同信号对比学习目标。

Result: 在真实世界数据集上的广泛实验表明，CDRec在推荐准确性和计算效率方面均优于现有方法。

Conclusion: CDRec通过连续时间离散空间扩散建模，有效解决了传统扩散推荐方法的信息损失和效率问题，为推荐系统提供了更高效准确的解决方案。

Abstract: In the era of information explosion, Recommender Systems (RS) are essential for alleviating information overload and providing personalized user experiences. Recent advances in diffusion-based generative recommenders have shown promise in capturing the dynamic nature of user preferences. These approaches explore a broader range of user interests by progressively perturbing the distribution of user-item interactions and recovering potential preferences from noise, enabling nuanced behavioral understanding. However, existing diffusion-based approaches predominantly operate in continuous space through encoded graph-based historical interactions, which may compromise potential information loss and suffer from computational inefficiency. As such, we propose CDRec, a novel Continuous-time Discrete-space Diffusion Recommendation framework, which models user behavior patterns through discrete diffusion on historical interactions over continuous time. The discrete diffusion algorithm operates via discrete element operations (e.g., masking) while incorporating domain knowledge through transition matrices, producing more meaningful diffusion trajectories. Furthermore, the continuous-time formulation enables flexible adaptive sampling. To better adapt discrete diffusion models to recommendations, CDRec introduces: (1) a novel popularity-aware noise schedule that generates semantically meaningful diffusion trajectories, and (2) an efficient training framework combining consistency parameterization for fast sampling and a contrastive learning objective guided by multi-hop collaborative signals for personalized recommendation. Extensive experiments on real-world datasets demonstrate CDRec's superior performance in both recommendation accuracy and computational efficiency.

</details>


### [232] [DualGR: Generative Retrieval with Long and Short-Term Interests Modeling](https://arxiv.org/abs/2511.12518)
*Zhongchao Yi,Kai Feng,Xiaojian Ma,Yalong Wang,Yongqi Liu,Han Li,Zhengyang Zhou,Yang Wang*

Main category: cs.IR

TL;DR: DualGR是一个生成式检索框架，通过双分支长短时路由器平衡用户长短期兴趣，使用基于搜索的语义ID解码控制噪声干扰，并引入曝光感知的下一个令牌预测损失来建模负反馈，在快手短视频推荐系统中取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决生成式检索中的三个关键挑战：1）平衡用户长短期兴趣 2）生成分层语义ID时的噪声干扰 3）缺乏对曝光未点击等负反馈的显式建模

Method: 提出DualGR框架：1）双分支长短时路由器显式建模用户长短期行为 2）基于搜索的语义ID解码限制候选交互范围以控制噪声 3）曝光感知的下一个令牌预测损失将曝光未点击项视为硬负样本

Result: 在快手大规模短视频推荐系统中，在线A/B测试显示视频观看量提升0.527%，观看时长提升0.432%

Conclusion: DualGR为工业级生成式检索提供了一个实用有效的范式，能够显著提升推荐系统性能

Abstract: In large-scale industrial recommendation systems, retrieval must produce high-quality candidates from massive corpora under strict latency. Recently, Generative Retrieval (GR) has emerged as a viable alternative to Embedding-Based Retrieval (EBR), which quantizes items into a finite token space and decodes candidates autoregressively, providing a scalable path that explicitly models target-history interactions via cross-attention. However, three challenges persist: 1) how to balance users' long-term and short-term interests , 2) noise interference when generating hierarchical semantic IDs (SIDs), 3) the absence of explicit modeling for negative feedback such as exposed items without clicks. To address these challenges, we propose DualGR, a generative retrieval framework that explicitly models dual horizons of user interests with selective activation. Specifically, DualGR utilizes Dual-Branch Long/Short-Term Router (DBR) to cover both stable preferences and transient intents by explicitly modeling users' long- and short-term behaviors. Meanwhile, Search-based SID Decoding (S2D) is presented to control context-induced noise and enhance computational efficiency by constraining candidate interactions to the current coarse (level-1) bucket during fine-grained (level-2/3) SID prediction. % also reinforcing intra-class consistency. Finally, we propose an Exposure-aware Next-Token Prediction Loss (ENTP-Loss) that treats "exposed-but-unclicked" items as hard negatives at level-1, enabling timely interest fade-out. On the large-scale Kuaishou short-video recommendation system, DualGR has achieved outstanding performance. Online A/B testing shows +0.527% video views and +0.432% watch time lifts, validating DualGR as a practical and effective paradigm for industrial generative retrieval.

</details>


### [233] [MindRec: Mind-inspired Coarse-to-fine Decoding for Generative Recommendation](https://arxiv.org/abs/2511.12597)
*Mengyao Gao,Chongming Gao,Haoyan Liu,Qingpeng Cai,Peng Jiang,Jiajia Chen,Shuai Yuan,Xiangnan He*

Main category: cs.IR

TL;DR: MindRec是一个受人类思维过程启发的推荐系统框架，通过首先生成反映用户偏好的关键令牌，然后扩展为完整项目，模拟人类从关键词到完整推理的决策过程。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的推荐系统采用自回归生成方式，受限于从左到右的贪婪解码策略和单向逻辑流，无法产生全局最优推荐。而人类推理往往从关键词或直觉开始，然后逐步完善。

Method: 1) 首先生成反映用户偏好的关键令牌；2) 将关键令牌扩展为完整项目；3) 使用分层类别树组织项目，引导模型从粗粒度类别逐步细化到具体项目；4) 设计扩散束搜索算法缓解贪婪解码的局部最优问题。

Result: 实验结果显示，MindRec在top-1推荐性能上比最先进方法平均提升9.5%，显著提高了推荐准确性。

Conclusion: MindRec通过模拟人类思维过程，实现了更灵活、更符合人类决策方式的推荐生成，有效提升了推荐系统的性能。

Abstract: Recent advancements in large language model-based recommendation systems often represent items as text or semantic IDs and generate recommendations in an auto-regressive manner. However, due to the left-to-right greedy decoding strategy and the unidirectional logical flow, such methods often fail to produce globally optimal recommendations. In contrast, human reasoning does not follow a rigid left-to-right sequence. Instead, it often begins with keywords or intuitive insights, which are then refined and expanded. Inspired by this fact, we propose Mind-inspired Recommender (MindRec), a novel generative framework that emulates human thought processes. Particularly, our method first generates key tokens that reflect user preferences, and then expands them into the complete item, enabling flexible and human-like generation. To further emulate the structured nature of human decision-making, we organize items into a hierarchical category tree. This structure guides the model to first produce the coarse-grained category and then progressively refine its selection through finer-grained subcategories before generating the specific item. To mitigate the local optimum problem inherent in greedy decoding, we design a novel beam search algorithm, Diffusion Beam Search, tailored for our mind-inspired generation paradigm. Experimental results demonstrate that MindRec yields a 9.5\% average improvement in top-1 recommendation performance over state-of-the-art methods, highlighting its potential to enhance recommendation accuracy. The implementation is available via https://github.com/Mr-Peach0301/MindRec.

</details>


### [234] [Tokenize Once, Recommend Anywhere: Unified Item Tokenization for Multi-domain LLM-based Recommendation](https://arxiv.org/abs/2511.12922)
*Yu Hou,Won-Yong Shin*

Main category: cs.IR

TL;DR: UniTok是一个统一的物品标记化框架，通过混合专家架构和代码本将不同领域的物品转换为离散标记，实现跨领域的可扩展语义保留。


<details>
  <summary>Details</summary>
Motivation: 现有物品标记化方法需要为每个物品领域训练单独模型，限制了泛化能力，且不同领域的分布和语义多样性使得构建统一标记化变得困难。

Method: 提出UniTok框架，使用共享编码器将不同领域物品投影到统一潜在空间，然后路由到领域特定专家捕获独特语义，同时共享专家编码跨领域通用知识，并引入互信息校准机制缓解语义不平衡。

Result: 在广泛真实数据集上的实验显示：性能提升达51.89%，理论分析验证架构设计有效性，且无需逐领域重新训练即可在多样化领域展现稳健性能。

Conclusion: UniTok框架在保持跨领域语义信息的同时实现了可扩展的标记化，显著优于现有基准方法，具有高度的有效性和泛化能力。

Abstract: Large language model (LLM)-based recommender systems have achieved high-quality performance by bridging the discrepancy between the item space and the language space through item tokenization. However, existing item tokenization methods typically require training separate models for each item domain, limiting generalization. Moreover, the diverse distributions and semantics across item domains make it difficult to construct a unified tokenization that preserves domain-specific information. To address these challenges, we propose UniTok, a Unified item Tokenization framework that integrates our own mixture-of-experts (MoE) architecture with a series of codebooks to convert items into discrete tokens, enabling scalable tokenization while preserving semantic information across multiple item domains. Specifically, items from different domains are first projected into a unified latent space through a shared encoder. They are then routed to domain-specific experts to capture the unique semantics, while a shared expert, which is always active, encodes common knowledge transferable across domains. Additionally, to mitigate semantic imbalance across domains, we present a mutual information calibration mechanism, which guides the model towards retaining similar levels of semantic information for each domain. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed UniTok framework is (a) highly effective: achieving up to 51.89% improvements over strong benchmarks, (b) theoretically sound: showing the analytical validity of our architectural design and optimization; and (c) highly generalizable: demonstrating robust performance across diverse domains without requiring per-domain retraining, a capability not supported by existing baselines.

</details>


### [235] [Can We Predict the Next Question? A Collaborative Filtering Approach to Modeling User Behavior](https://arxiv.org/abs/2511.12949)
*Bokang Fu,Jiahao Wang,Xiaojing Liu,Yuli Liu*

Main category: cs.IR

TL;DR: 提出了CFQP框架，通过结合个性化记忆模块和图基偏好传播来动态建模用户-问题交互，解决LLMs在捕捉用户动态行为序列方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统通常静态建模用户偏好，无法捕捉交互行为的动态性和序列性，而用户历史问题序列蕴含丰富的兴趣演变和认知模式信号。

Method: CFQP框架整合个性化记忆模块和图基偏好传播的双重机制，自适应学习用户特定历史，并通过相似用户的协同信号优化预测。

Result: 实验结果表明该方法能有效生成模拟真实用户提问模式的智能体，展示了构建主动自适应对话系统的潜力。

Conclusion: CFQP框架成功弥补了语言建模与行为序列建模之间的鸿沟，为动态用户建模提供了有效解决方案。

Abstract: In recent years, large language models (LLMs) have excelled in language understanding and generation, powering advanced dialogue and recommendation systems. However, a significant limitation persists: these systems often model user preferences statically, failing to capture the dynamic and sequential nature of interactive behaviors. The sequence of a user's historical questions provides a rich, implicit signal of evolving interests and cognitive patterns, yet leveraging this temporal data for predictive tasks remains challenging due to the inherent disconnect between language modeling and behavioral sequence modeling.
  To bridge this gap, we propose a Collaborative Filtering-enhanced Question Prediction (CFQP) framework. CFQP dynamically models evolving user-question interactions by integrating personalized memory modules with graph-based preference propagation. This dual mechanism allows the system to adaptively learn from user-specific histories while refining predictions through collaborative signals from similar users. Experimental results demonstrate that our approach effectively generates agents that mimic real-user questioning patterns, highlighting its potential for building proactive and adaptive dialogue systems.

</details>


### [236] [Personalized Federated Recommendation With Knowledge Guidance](https://arxiv.org/abs/2511.12959)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Dongha Kim,Hwanjo Yu*

Main category: cs.IR

TL;DR: FedRKG是一个解决联邦推荐系统中内存效率与性能权衡的模型无关框架，通过知识引导机制在单知识模型内存占用下实现双知识模型的个性化效果。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐模型面临关键困境：内存高效的单知识模型因丢弃有价值个性化信息而性能受限，而高性能的双知识模型又因内存需求过大难以在实际设备上部署。

Method: 提出知识引导原则，避免完全替换，而是将全局知识融合到保留的本地嵌入中；引入自适应引导机制，为每个用户-物品交互动态调整引导强度。

Result: 在基准数据集上的广泛实验表明，FedRKG显著优于最先进方法，验证了方法的有效性。

Conclusion: FedRKG成功解决了联邦推荐系统中的内存效率与性能权衡问题，在单知识模型内存占用下实现了双知识模型的个性化效果。

Abstract: Federated Recommendation (FedRec) has emerged as a key paradigm for building privacy-preserving recommender systems. However, existing FedRec models face a critical dilemma: memory-efficient single-knowledge models suffer from a suboptimal knowledge replacement practice that discards valuable personalization, while high-performance dual-knowledge models are often too memory-intensive for practical on-device deployment. We propose Federated Recommendation with Knowledge Guidance (FedRKG), a model-agnostic framework that resolves this dilemma. The core principle, Knowledge Guidance, avoids full replacement and instead fuses global knowledge into preserved local embeddings, attaining the personalization benefits of dual-knowledge within a single-knowledge memory footprint. Furthermore, we introduce Adaptive Guidance, a fine-grained mechanism that dynamically modulates the intensity of this guidance for each user-item interaction, overcoming the limitations of static fusion methods. Extensive experiments on benchmark datasets demonstrate that FedRKG significantly outperforms state-of-the-art methods, validating the effectiveness of our approach. The code is available at https://github.com/Jaehyung-Lim/fedrkg.

</details>


### [237] [Local Collaborative Filtering: A Collaborative Filtering Method that Utilizes Local Similarities among Users](https://arxiv.org/abs/2511.13166)
*Zhaoxin Shen,Dan Wu*

Main category: cs.IR

TL;DR: 提出一种名为局部协同过滤(LCF)的新方法，利用用户间的局部相似性，结合大数定律整合用户数据，提高用户行为数据的利用率。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地利用互联网中的用户行为数据来改进推荐系统。

Method: 提出局部协同过滤(LCF)方法，利用用户间的局部相似性，结合大数定律整合用户数据。

Result: 在Steam游戏数据集上的实验结果表明，LCF的结果符合实际需求。

Conclusion: LCF方法能够有效提高用户行为数据的利用率，在推荐系统中表现出良好的性能。

Abstract: To leverage user behavior data from the Internet more effectively in recommender systems, this paper proposes a novel collaborative filtering (CF) method called Local Collaborative Filtering (LCF). LCF utilizes local similarities among users and integrates their data using the law of large numbers (LLN), thereby improving the utilization of user behavior data. Experiments are conducted on the Steam game dataset, and the results of LCF align with real-world needs.

</details>


### [238] [Cog-RAG: Cognitive-Inspired Dual-Hypergraph with Theme Alignment Retrieval-Augmented Generation](https://arxiv.org/abs/2511.13201)
*Hao Hu,Yifan Feng,Ruoxue Li,Rundong Xue,Xingliang Hou,Zhiqiang Tian,Yue Gao,Shaoyi Du*

Main category: cs.IR

TL;DR: 提出了Cog-RAG框架，通过主题超图和实体超图的双重结构，结合认知启发的两阶段检索策略，显著提升了RAG系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的RAG方法主要关注低阶成对实体关系，限制了多实体间的高阶关联；而超图方法又局限于块间实体级表示，忽视了全局主题组织和对齐。

Method: 提出主题对齐的双超图RAG框架(Cog-RAG)，使用主题超图捕获块间主题结构，实体超图建模高阶语义关系；设计认知启发的两阶段检索策略，先激活查询相关主题内容，再指导细粒度召回和扩散。

Result: 广泛的实验表明，Cog-RAG显著优于现有的最先进基线方法。

Conclusion: Cog-RAG通过模拟人类自上而下的认知推理过程，实现了从全局主题到局部细节的语义对齐和一致生成，有效提升了RAG系统的性能。

Abstract: Retrieval-Augmented Generation (RAG) enhances the response quality and domain-specific performance of large language models (LLMs) by incorporating external knowledge to combat hallucinations. In recent research, graph structures have been integrated into RAG to enhance the capture of semantic relations between entities. However, it primarily focuses on low-order pairwise entity relations, limiting the high-order associations among multiple entities. Hypergraph-enhanced approaches address this limitation by modeling multi-entity interactions via hyperedges, but they are typically constrained to inter-chunk entity-level representations, overlooking the global thematic organization and alignment across chunks. Drawing inspiration from the top-down cognitive process of human reasoning, we propose a theme-aligned dual-hypergraph RAG framework (Cog-RAG) that uses a theme hypergraph to capture inter-chunk thematic structure and an entity hypergraph to model high-order semantic relations. Furthermore, we design a cognitive-inspired two-stage retrieval strategy that first activates query-relevant thematic content from the theme hypergraph, and then guides fine-grained recall and diffusion in the entity hypergraph, achieving semantic alignment and consistent generation from global themes to local details. Our extensive experiments demonstrate that Cog-RAG significantly outperforms existing state-of-the-art baseline approaches.

</details>


### [239] [Uncovering Causal Drivers of Energy Efficiency for Industrial Process in Foundry via Time-Series Causal Inference](https://arxiv.org/abs/2511.13389)
*Zhipeng Ma,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.IR

TL;DR: 本文提出了一种结合时间序列聚类和因果推断的方法来分析感应炉熔炼过程中的能源效率驱动因素，识别出能源消耗、炉温和材料重量之间的因果关系，并为铸造厂提供优化性能、降低能耗和排放的可操作见解。


<details>
  <summary>Details</summary>
Motivation: 工业铸造过程能耗巨大且变量间存在复杂相互依赖关系，传统的相关性分析难以区分真正的因果驱动因素与虚假关联，限制了其在决策中的实用性。

Method: 使用时间序列聚类将熔炼周期分割为不同的操作模式，并采用PCMCI+算法（最先进的因果发现方法）揭示每个模式内的因果关系。

Result: 在所有聚类中，能源消耗、炉温和材料重量之间的稳健因果关系定义了效率的核心驱动因素，而电压持续影响冷却水温度并具有延迟响应。高效聚类以稳定的因果结构为特征，而低效聚类则表现出强化反馈环和非典型依赖关系。

Conclusion: 本研究引入了集成聚类-因果推断管道作为分析能源密集型过程的方法创新，并为铸造厂操作员提供了优化性能、减少能源消耗和降低排放的可操作见解。

Abstract: Improving energy efficiency in industrial foundry processes is a critical challenge, as these operations are highly energy-intensive and marked by complex interdependencies among process variables. Correlation-based analyses often fail to distinguish true causal drivers from spurious associations, limiting their usefulness for decision-making. This paper applies a time-series causal inference framework to identify the operational factors that directly affect energy efficiency in induction furnace melting. Using production data from a Danish foundry, the study integrates time-series clustering to segment melting cycles into distinct operational modes with the PCMCI+ algorithm, a state-of-the-art causal discovery method, to uncover cause-effect relationships within each mode. Across clusters, robust causal relations among energy consumption, furnace temperature, and material weight define the core drivers of efficiency, while voltage consistently influences cooling water temperature with a delayed response. Cluster-specific differences further distinguish operational regimes: efficient clusters are characterized by stable causal structures, whereas inefficient ones exhibit reinforcing feedback loops and atypical dependencies. The contributions of this study are twofold. First, it introduces an integrated clustering-causal inference pipeline as a methodological innovation for analyzing energy-intensive processes. Second, it provides actionable insights that enable foundry operators to optimize performance, reduce energy consumption, and lower emissions.

</details>


### [240] [Exploring Multi-Table Retrieval Through Iterative Search](https://arxiv.org/abs/2511.13418)
*Allaa Boutaleb,Bernd Amann,Rafael Angarita,Hubert Naacke*

Main category: cs.IR

TL;DR: 本文提出了一种迭代式多表检索框架，通过贪心连接感知检索算法在数据湖环境中平衡相关性、覆盖率和可连接性，相比混合整数规划方法快4-400倍且保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 数据湖中的开放域问答需要从多个表中检索和组合信息，现有方法要么计算复杂度过高（如混合整数规划），要么只优化查询覆盖率而忽略结构连贯性。

Method: 将多表检索构建为迭代搜索过程，提出贪心连接感知检索算法，综合考虑相关性、覆盖率和可连接性进行优化。

Result: 在5个NL2SQL基准测试中，迭代方法相比MIP方法快4-400倍，同时保持竞争力的检索性能。

Conclusion: 迭代启发式方法在实践性、可扩展性和组合感知检索方面具有巨大潜力。

Abstract: Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (e.g., joinability). While exact optimization methods like Mixed-Integer Programming (MIP) can ensure coherence, their computational complexity is often prohibitive. Conversely, simpler greedy heuristics that optimize for query coverage alone often fail to find these coherent, joinable sets. This paper frames multi-table retrieval as an iterative search process, arguing this approach offers advantages in scalability, interpretability, and flexibility. We propose a general framework and a concrete instantiation: a fast, effective Greedy Join-Aware Retrieval algorithm that holistically balances relevance, coverage, and joinability. Experiments across 5 NL2SQL benchmarks demonstrate that our iterative method achieves competitive retrieval performance compared to the MIP-based approach while being 4-400x faster depending on the benchmark and search space settings. This work highlights the potential of iterative heuristics for practical, scalable, and composition-aware retrieval.

</details>


### [241] [Compact Multimodal Language Models as Robust OCR Alternatives for Noisy Textual Clinical Reports](https://arxiv.org/abs/2511.13523)
*Nikita Neveditsin,Pawan Lingras,Salil Patil,Swarup Patil,Vijay Mago*

Main category: cs.IR

TL;DR: 本研究评估了紧凑型多模态语言模型作为隐私保护替代方案，用于转录噪声临床文档的性能，发现它们在处理智能手机拍摄的医疗报告图像时优于传统OCR系统。


<details>
  <summary>Details</summary>
Motivation: 医疗记录数字化通常依赖智能手机拍摄打印报告的照片，这些图像存在模糊、阴影和其他噪声。传统OCR系统针对清洁扫描优化，在现实条件下表现不佳。

Method: 使用印度医疗环境中常见的区域性医学英语撰写的产科超声报告，比较了八个系统在转录准确性、噪声敏感性、数字准确性和计算效率方面的表现。

Result: 紧凑型多模态模型在转录准确性方面始终优于经典和神经OCR流水线，尽管计算成本较高，但其鲁棒性和语言适应性使其成为本地医疗数字化的可行候选方案。

Conclusion: 紧凑型多模态模型在处理噪声临床文档方面表现出色，是医疗记录数字化的有前景的隐私保护解决方案。

Abstract: Digitization of medical records often relies on smartphone photographs of printed reports, producing images degraded by blur, shadows, and other noise. Conventional OCR systems, optimized for clean scans, perform poorly under such real-world conditions. This study evaluates compact multimodal language models as privacy-preserving alternatives for transcribing noisy clinical documents. Using obstetric ultrasound reports written in regionally inflected medical English common to Indian healthcare settings, we compare eight systems in terms of transcription accuracy, noise sensitivity, numeric accuracy, and computational efficiency. Compact multimodal models consistently outperform both classical and neural OCR pipelines. Despite higher computational costs, their robustness and linguistic adaptability position them as viable candidates for on-premises healthcare digitization.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [242] [Embedding Explainable AI in NHS Clinical Safety: The Explainability-Enabled Clinical Safety Framework (ECSF)](https://arxiv.org/abs/2511.11590)
*Robert Gigiu*

Main category: cs.CY

TL;DR: 本文提出了一个可解释性增强的临床安全框架（ECSF），将可解释性集成到DCB0129/0160安全标准生命周期中，使临床安全官员能够使用可解释性输出作为结构化安全证据，而不改变合规路径。


<details>
  <summary>Details</summary>
Motivation: 人工智能在NHS工作流程中日益普及，但其概率性和自适应行为与现有临床安全标准的确定性假设相冲突。DCB0129和DCB0160标准对传统软件提供了强有力的治理，但未定义如何证明AI特定的透明度、可解释性或模型漂移。

Method: 通过跨监管综合分析，将DCB条款与良好机器学习实践、NHS AI保证和T.E.S.T.框架以及欧盟AI法案的原则进行映射。建立了连接监管条款、原则、ECSF检查点和合适可解释性输出的矩阵。

Result: ECSF引入了五个检查点：全局透明度用于危险识别、案例级可解释性用于验证、临床医生可用性用于评估、可追溯决策路径用于风险控制、纵向可解释性监控用于上市后监测。将SHAP、LIME、集成梯度、显著性映射和注意力可视化等技术映射到相应的DCB工件。

Conclusion: ECSF将可解释性重新定义为临床安全保证的核心要素，弥合了确定性风险治理与AI概率行为之间的差距，并支持与GMLP、欧盟AI法案和NHS AI保证原则的一致性。

Abstract: Artificial intelligence (AI) is increasingly embedded in NHS workflows, but its probabilistic and adaptive behaviour conflicts with the deterministic assumptions underpinning existing clinical-safety standards. DCB0129 and DCB0160 provide strong governance for conventional software yet do not define how AI-specific transparency, interpretability, or model drift should be evidenced within Safety Cases, Hazard Logs, or post-market monitoring. This paper proposes an Explainability-Enabled Clinical Safety Framework (ECSF) that integrates explainability into the DCB0129/0160 lifecycle, enabling Clinical Safety Officers to use interpretability outputs as structured safety evidence without altering compliance pathways. A cross-regulatory synthesis mapped DCB clauses to principles from Good Machine Learning Practice, the NHS AI Assurance and T.E.S.T. frameworks, and the EU AI Act. The resulting matrix links regulatory clauses, principles, ECSF checkpoints, and suitable explainability outputs. ECSF introduces five checkpoints: global transparency for hazard identification, case-level interpretability for verification, clinician usability for evaluation, traceable decision pathways for risk control, and longitudinal interpretability monitoring for post-market surveillance. Techniques such as SHAP, LIME, Integrated Gradients, saliency mapping, and attention visualisation are mapped to corresponding DCB artefacts. ECSF reframes explainability as a core element of clinical-safety assurance, bridging deterministic risk governance with the probabilistic behaviour of AI and supporting alignment with GMLP, the EU AI Act, and NHS AI Assurance principles.

</details>


### [243] [Decision-Making Amid Information-Based Threats in Sociotechnical Systems: A Review](https://arxiv.org/abs/2511.11595)
*Aaron R. Allred,Erin E. Richardson,Sarah R. Bostrom,James Crum,Cara Spencer,Chad Tossell,Richard E. Niemeyer,Leanne Hirshfield,Allison P. A. Hayman*

Main category: cs.CY

TL;DR: 本文综述了技术系统中信息交换对人类决策的影响，分析了信息威胁与人类信息处理机制之间的关系，并提出了整合研究方向以减轻人类脆弱性和对齐人机表征。


<details>
  <summary>Details</summary>
Motivation: 技术系统在人类信息交换中的中介作用日益增强，这既为决策提供了机会也带来了威胁。当前研究存在碎片化问题，信息威胁现象评估与人类信息处理基础研究相互隔离，需要整合这两个领域。

Method: 通过综述和整合来自信息威胁评估和人类信息处理两个领域的研究成果，识别共享的认知机制，这些机制介导了对信息威胁的脆弱性并塑造行为结果。

Result: 识别出多个共享的认知机制，这些机制在信息威胁脆弱性和行为结果中起关键作用，为理解技术环境中的人类决策提供了新的视角。

Conclusion: 需要整合信息威胁和人类信息处理的研究视角，这对于减轻人类脆弱性和实现人机表征对齐至关重要，并为此提出了未来研究方向。

Abstract: Technological systems increasingly mediate human information exchange, spanning interactions among humans as well as between humans and artificial agents. The unprecedented scale and reliance on information disseminated through these systems substantially expand the scope of information-based influence that can both enable and undermine sound decision-making. Consequently, understanding and protecting decision-making today faces growing challenges, as individuals and organizations must navigate evolving opportunities and information-based threats across varied domains and information environments. While these risks are widely recognized, research remains fragmented: work evaluating information-based threat phenomena has progressed largely in isolation from foundational studies of human information processing. In this review, we synthesize insights from both domains to identify shared cognitive mechanisms that mediate vulnerability to information-based threats and shape behavioral outcomes. Finally, we outline directions for future research aimed at integrating these perspectives, emphasizing the importance of such integration for mitigating human vulnerabilities and aligning human-machine representations.

</details>


### [244] [EduAgentQG: A Multi-Agent Workflow Framework for Personalized Question Generation](https://arxiv.org/abs/2511.11635)
*Rui Jia,Min Zhang,Fengrui Liu,Bo Jiang,Kun Kuang,Zhongxiang Dai*

Main category: cs.CY

TL;DR: EduAgentQG是一个多智能体协作框架，通过五个专门智能体的迭代反馈循环生成高质量、多样化的个性化问题，解决了现有方法质量不稳定、多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 高质量个性化题库对自适应学习和个性化评估至关重要，但人工设计问题耗时且难以满足多样化学习需求，现有自动问题生成方法存在质量不稳定、多样性有限、与教育目标对齐不足的问题。

Method: 采用五智能体协作框架：Planner生成结构化设计计划和多个问题方向；Writer基于计划生成候选问题，利用Solver和Educator的反馈优化质量和多样性；Solver和Educator进行多维度二元评分；Checker进行最终验证，确保答案正确性和清晰度。

Result: 在两个数学问题数据集上的实验表明，EduAgentQG在问题多样性、目标一致性和整体质量方面优于现有的单智能体和多智能体方法。

Conclusion: 通过多智能体协作和迭代反馈循环，EduAgentQG能够生成高质量、多样化且与教育目标一致的问题，有效减轻教师工作量并提升教育资源可扩展性。

Abstract: High-quality personalized question banks are crucial for supporting adaptive learning and individualized assessment. Manually designing questions is time-consuming and often fails to meet diverse learning needs, making automated question generation a crucial approach to reduce teachers' workload and improve the scalability of educational resources. However, most existing question generation methods rely on single-agent or rule-based pipelines, which still produce questions with unstable quality, limited diversity, and insufficient alignment with educational goals. To address these challenges, we propose EduAgentQG, a multi-agent collaborative framework for generating high-quality and diverse personalized questions. The framework consists of five specialized agents and operates through an iterative feedback loop: the Planner generates structured design plans and multiple question directions to enhance diversity; the Writer produces candidate questions based on the plan and optimizes their quality and diversity using feedback from the Solver and Educator; the Solver and Educator perform binary scoring across multiple evaluation dimensions and feed the evaluation results back to the Writer; the Checker conducts final verification, including answer correctness and clarity, ensuring alignment with educational goals. Through this multi-agent collaboration and iterative feedback loop, EduAgentQG generates questions that are both high-quality and diverse, while maintaining consistency with educational objectives. Experiments on two mathematics question datasets demonstrate that EduAgentQG outperforms existing single-agent and multi-agent methods in terms of question diversity, goal consistency, and overall quality.

</details>


### [245] [Automatic generation of DRI Statements](https://arxiv.org/abs/2511.11655)
*Maurice Flechtner*

Main category: cs.CY

TL;DR: 本论文提出了一种利用自然语言处理和大语言模型自动生成审议理由指数(DRI)陈述的创新方法，显著减少了人工工作量。


<details>
  <summary>Details</summary>
Motivation: 传统DRI陈述生成过程复杂耗时，限制了审议质量评估的实施，需要自动化解决方案来降低研究门槛。

Method: 开发了基于先进NLP和LLM的自动化DRI陈述生成框架，通过生成式人工智能技术实现陈述的自动创建。

Result: 成功建立了系统化的自动化DRI陈述生成框架，显著降低了进行综合审议过程评估的障碍。

Conclusion: 该方法为将生成式人工智能整合到社会科学研究方法中提供了可复制的模板，推动了审议过程评估的自动化发展。

Abstract: Assessing the quality of group deliberation is essential for improving our understanding of deliberative processes. The Deliberative Reason Index (DRI) offers a sophisticated metric for evaluating group reasoning, but its implementation has been constrained by the complex and time-consuming process of statement generation. This thesis introduces an innovative, automated approach to DRI statement generation that leverages advanced natural language processing (NLP) and large language models (LLMs) to substantially reduce the human effort involved in survey preparation. Key contributions are a systematic framework for automated DRI statement generation and a methodological innovation that significantly lowers the barrier to conducting comprehensive deliberative process assessments. In addition, the findings provide a replicable template for integrating generative artificial intelligence into social science research methodologies.

</details>


### [246] [Generative AI as a Linguistic Equalizer in Global Science](https://arxiv.org/abs/2511.11687)
*Dragan Filimonovic,Christian Rutzer,Jeffrey Macher,Rolf Weder*

Main category: cs.CY

TL;DR: 本研究通过分析560万篇科学论文，首次大规模验证了生成式AI（特别是ChatGPT发布后）如何帮助非英语国家作者缩小与英语母语作者在科学写作中的语言差距，促进了全球科学交流的语言平等。


<details>
  <summary>Details</summary>
Motivation: 英语在全球科学中的主导地位长期阻碍了非母语者的参与，生成式AI的出现为解决这一不平等问题提供了技术可能性。

Method: 使用SciBERT文本嵌入模型，分析2021-2024年间560万篇科学论文，比较生成式AI辅助和非辅助出版物与美籍作者科学写作基准的语言相似性，追踪风格趋同随时间的变化。

Result: ChatGPT发布后，生成式AI辅助的出版物显示出显著且不断增长的语言趋同效应，特别是在与英语语言距离较远的国家的国内合著团队中效果最强。

Conclusion: 生成式AI正在通过减少研究中的语言障碍，开始重塑全球科学交流格局，为语言平等提供了大规模实证支持。

Abstract: For decades, the dominance of English has created a substantial barrier in global science, disadvantaging non-native speakers. The recent rise of generative AI (GenAI) offers a potential technological response to this long-standing inequity. We provide the first large-scale evidence testing whether GenAI acts as a linguistic equalizer in global science. Drawing on 5.65 million scientific articles published from 2021 to 2024, we compare GenAI-assisted and non-assisted publications from authors in non-English-speaking countries. Using text embeddings derived from a pretrained large language model (SciBERT), we measure each publication's linguistic similarity to a benchmark of scientific writing from U.S.-based authors and track stylistic convergence over time. We find significant and growing convergence for GenAI-assisted publications after the release of ChatGPT in late 2022. The effect is strongest for domestic coauthor teams from countries linguistically distant from English. These findings provide large-scale evidence that GenAI is beginning to reshape global science communication by reducing language barriers in research.

</details>


### [247] [Mental Health Generative AI is Safe, Promotes Social Health, and Reduces Depression and Anxiety: Real World Evidence from a Naturalistic Cohort](https://arxiv.org/abs/2511.11689)
*Thomas D. Hull,Lizhe Zhang,Patricia A. Arean,Matteo Malgaroli*

Main category: cs.CY

TL;DR: 本研究评估了专为心理健康设计的生成式AI基础模型，通过10周观察发现该模型能有效降低抑郁和焦虑症状，改善希望感、行为激活、社交互动等指标，且具有高参与度和安全性。


<details>
  <summary>Details</summary>
Motivation: 开发能够提供安全、个性化、可扩展心理健康支持的生成式AI聊天机器人，以解决传统心理健康服务可及性不足的问题。

Method: 单臂自然观察性研究，成年用户在2025年5月15日至9月15日期间使用心理健康聊天机器人，每两周重复测量心理健康指标直至6周，并在10周进行最终随访。

Result: 用户PHQ-9和GAD-7得分显著降低且效果持续；希望感、行为激活、社交互动、孤独感和感知社会支持显著改善；参与度高且预测结果；工作联盟与传统护理相当；安全护栏有效运作。

Conclusion: 生成式AI心理健康基础模型能够提供可访问、有吸引力、有效且安全的心理健康支持，为未来在真实世界环境中研究心理健康AI提供了希望。

Abstract: Generative artificial intelligence (GAI) chatbots built for mental health could deliver safe, personalized, and scalable mental health support. We evaluate a foundation model designed for mental health. Adults completed mental health measures while engaging with the chatbot between May 15, 2025 and September 15, 2025. Users completed an opt-in consent, demographic information, mental health symptoms, social connection, and self-identified goals. Measures were repeated every two weeks up to 6 weeks, and a final follow-up at 10 weeks. Analyses included effect sizes, and growth mixture models to identify participant groups and their characteristic engagement, severity, and demographic factors. Users demonstrated significant reductions in PHQ-9 and GAD-7 that were sustained at follow-up. Significant improvements in Hope, Behavioral Activation, Social Interaction, Loneliness, and Perceived Social Support were observed throughout and maintained at 10 week follow-up. Engagement was high and predicted outcomes. Working alliance was comparable to traditional care and predicted outcomes. Automated safety guardrails functioned as designed, with 76 sessions flagged for risk and all handled according to escalation policies. This single arm naturalistic observational study provides initial evidence that a GAI foundation model for mental health can deliver accessible, engaging, effective, and safe mental health support. These results lend support to findings from early randomized designs and offer promise for future study of mental health GAI in real world settings.

</details>


### [248] [Understanding the Representation of Older Adults in Motion Capture Locomotion Datasets](https://arxiv.org/abs/2511.11713)
*Yunkai Yu,Yingying Wang,Rong Zheng*

Main category: cs.CY

TL;DR: 该论文调查了41个公开运动捕捉数据集，发现老年人参与度低，且模拟的老年风格行走动作无法真实反映年龄相关差异，提出了定量评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有运动捕捉数据集中老年人代表性不足，且模拟的老年风格行走动作的真实性未得到充分验证，这在医疗保健应用中尤为重要。

Method: 调查41个公开数据集，识别包含老年人动作的数据集；引入定量指标评估老年风格行走动作的保真度，使用对年龄敏感、抗噪声且适应数据稀缺的步态参数。

Result: 老年人仅占总体参与者的小部分，提供全身运动数据的数据集更少；老年风格行走动作往往表现出过度控制的模式，无法真实表征衰老特征。

Conclusion: 需要在运动数据集中改善老年人的代表性，并建立定量评估老年风格行走动作质量的方法。

Abstract: The Internet of Things (IoT) sensors have been widely employed to capture human locomotions to enable applications such as activity recognition, human pose estimation, and fall detection. Motion capture (MoCap) systems are frequently used to generate ground truth annotations for human poses when training models with data from wearable or ambient sensors, and have been shown to be effective to synthesize data in these modalities. However, the representation of older adults, an increasingly important demographic in healthcare, in existing MoCap locomotion datasets has not been thoroughly examined. This work surveyed 41 publicly available datasets, identifying eight that include older adult motions and four that contain motions performed by younger actors annotated as old style. Older adults represent a small portion of participants overall, and few datasets provide full-body motion data for this group. To assess the fidelity of old-style walking motions, quantitative metrics are introduced, defining high fidelity as the ability to capture age-related differences relative to normative walking. Using gait parameters that are age-sensitive, robust to noise, and resilient to data scarcity, we found that old-style walking motions often exhibit overly controlled patterns and fail to faithfully characterize aging. These findings highlight the need for improved representation of older adults in motion datasets and establish a method to quantitatively evaluate the quality of old-style walking motions.

</details>


### [249] [CADD: A Chinese Traffic Accident Dataset for Statute-Based Liability Attribution](https://arxiv.org/abs/2511.11715)
*Yunfei Shen,Zhongcheng Wu*

Main category: cs.CY

TL;DR: CADD是中国首个基于法规的责任认定数据集，包含792个真实驾驶记录仪视频，采用"行为-责任-法规"标注框架，将感知数据与法律后果直接关联。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术发展，事故责任判定成为关键挑战，现有数据集缺乏法律推理所需的标注信息。

Method: 构建包含792个真实驾驶记录仪视频的数据集，采用"行为-责任-法规"标注框架，提供细粒度行为标注、明确责任分配和具体交通法规链接。

Result: 建立了责任预测和可解释决策的基准，为开发负责任且法律依据充分的自动驾驶系统提供基础资源。

Conclusion: CADD通过直接连接感知数据与法律后果，为开发可问责且法律依据充分的自动驾驶系统提供了重要基础。

Abstract: As autonomous driving technology advances, the critical challenge evolves beyond collision avoidance to the \textbf{adjudication of liability} when accidents occur. Existing datasets, focused on detection and localization, lack the annotations required for this legal reasoning. To bridge this gap, we introduce the \textbf{C}hinese \textbf{A}ccident \textbf{D}uty-determination \textbf{D}ataset (\textbf{CADD}), the first benchmark for statute-based liability attribution. CADD contains 792 real-world driving recorder videos, each annotated within a novel \textbf{``Behavior--Liability--Statute''} pipeline. This framework provides \textbf{granular, symmetric behavior annotations}, clear responsibility assignments, and, uniquely, links each case to the specific \textbf{Chinese traffic law statute} violated. We demonstrate the utility of CADD through detailed analysis and establish benchmarks for liability prediction and explainable decision-making. By directly connecting perceptual data to legal consequences, CADD provides a foundational resource for developing accountable and legally-grounded autonomous systems.

</details>


### [250] [Weapons of Online Harassment: Menacing and Profiling Users via Social Apps](https://arxiv.org/abs/2511.11718)
*Sanjana Cheerla,Vaibhav Garg,Saikath Bhattacharya,Munindar P. Singh*

Main category: cs.CY

TL;DR: 该研究分析了300万条应用评论，发现社交应用中存在两种主要骚扰形式：威胁和画像。开发了识别骚扰评论的计算模型，准确率分别达到90%和85%，并识别出1395个存在骚扰的应用。


<details>
  <summary>Details</summary>
Motivation: 社交应用作为社会技术系统，不仅提供技术功能，还调节人际互动，可能无意中助长在线骚扰行为。随着用户数量增加，骚扰事件也在上升。

Method: 构建包含300万条评论和1800个应用的数据集，开发计算模型识别骚扰评论，分析骚扰行为的特征和模式。

Result: 发现威胁和画像是两种主要骚扰形式，模型召回率达到90%和85%。识别出1395个存在骚扰的应用，骚扰者多为女性身份，负面评论中愤怒、厌恶和恐惧情绪更普遍。

Conclusion: 社交应用中骚扰问题普遍存在，需要开发者重视并采取措施减少骚扰行为，计算模型可以有效识别和监控此类问题。

Abstract: Viewing social apps as sociotechnical systems makes clear that they are not mere pieces of technology but mediate human interaction and may unintentionally enable harmful behaviors like online harassment. As more users interact through social apps, instances of harassment increase.
  We observed that app reviews often describe harassment. Accordingly, we built a dataset of over 3 million reviews and 1,800 apps. We discovered that two forms of harassment are prevalent, Menacing and Profiling.
  We built a computational model for identifying reviews indicating harassment, achieving high recalls of 90% for Menacing and 85% for Profiling. We analyzed the data further to better understand the terrain of harassment. Surprisingly, abusers most often have female identities. Also, what distinguishes negative from neutral reviews is the greater prevalence of anger, disgust, and fear.
  Applying our model, we identified 1,395 apps enabling harassment and notified developers of the top 48 with the highest user-reported harassment.

</details>


### [251] [A framework for measuring and analyzing customer satisfaction at computer service companies using Lean Six Sigma](https://arxiv.org/abs/2511.11723)
*Mohammed Abboodi*

Main category: cs.CY

TL;DR: 提出一个结合六西格玛和SERVQUAL的集成框架，用于评估计算机服务行业的客户满意度并识别不满意的根源。


<details>
  <summary>Details</summary>
Motivation: 计算机服务行业竞争激烈，中小企业难以维持客户满意度，缺乏有效的服务质量评估系统是导致客户流失的关键因素。

Method: 将六西格玛的核心原则与SERVQUAL工具结合，在DMAIC方法框架内实施，通过案例研究验证框架的可行性。

Result: 量化了满意度水平，识别出五个主要的不满意驱动因素，总体满意度水平较低。

Conclusion: 解决这些不满意根源有望提高客户满意度、降低获客成本并改善组织整体绩效。

Abstract: The computer service industry has expanded rapidly over the past two decades, driven by the proliferation of computing technologies, the entry of large firms, and the availability of online diagnostic and troubleshooting tools. In this increasingly competitive environment, many small and medium sized enterprises struggle to maintain customer satisfaction as rivals deliver higher quality services at lower cost. This study addresses the absence of robust measurement systems for assessing service quality, a key factor underlying customer attrition, by proposing an integrated framework for evaluating satisfaction and identifying sources of dissatisfaction in computer services.
  The framework combines core principles of Six Sigma with the SERVQUAL instrument within a structured DMAIC methodology (Define, Measure, Analyze, Improve, and Control). SERVQUAL provides the service quality dimensions and gap analysis techniques, while Six Sigma supplies the data driven approach to measurement and improvement. The literature suggests limited prior work integrating Lean Six Sigma with SERVQUAL, and this study contributes by operationalizing that integration in a real world setting.
  A case study of a computer services company was conducted to demonstrate feasibility and effectiveness. Satisfaction levels were quantified, and root causes of dissatisfaction were identified. The analysis revealed a low overall satisfaction level and five primary drivers of unmet customer requirements. Addressing these causes is expected to increase customer satisfaction, lower customer acquisition costs, and improve overall organizational performance.

</details>


### [252] [On the Influence of Artificial Intelligence on Human Problem-Solving: Empirical Insights for the Third Wave in a Multinational Longitudinal Pilot Study](https://arxiv.org/abs/2511.11738)
*Matthias Huemmer,Theophile Shyiramunda,Franziska Durner,Michelle J. Cummings-Koether*

Main category: cs.CY

TL;DR: 本文研究了人机协作在问题解决中的演化范式，发现普遍AI采用但存在验证缺陷，识别了两个系统性认知差距：信念-表现差距和证明-信念差距，指出可靠AI辅助工作的核心限制是解决方案验证而非生成。


<details>
  <summary>Details</summary>
Motivation: 研究人机协作在问题解决中的演化模式，特别是AI工具如何融入结构化认知工作流程，以及这种协作中存在的系统性认知差距。

Method: 采用多国纵向研究，第三波包含23名参与者，通过行为数据和不同复杂度的问题情境收集数据，分析AI采用模式和认知工作流程。

Result: 发现近乎普遍的AI采用率（95.7%有先验知识，100%使用ChatGPT），主要采用"思考、互联网、ChatGPT、进一步处理"等人类主导序列（39.1%），但存在随着问题复杂度增加而升级的验证缺陷，识别了两个系统性认知差距。

Conclusion: 教育和科技干预必须优先考虑验证支架（包括假设文档协议、充分性标准清单和三角验证程序），以加强人类在这个新认知生态系统中作为关键验证者的角色。

Abstract: This article presents the results and their discussion for the third wave (with n=23 participants) within a multinational longitudinal study that investigates the evolving paradigm of human-AI collaboration in problem-solving contexts. Building upon previous waves, our findings reveal the consolidation of a hybrid problem-solving culture characterized by strategic integration of AI tools within structured cognitive workflows. The data demonstrate near-universal AI adoption (95.7% with prior knowledge, 100% ChatGPT usage) primarily deployed through human-led sequences such as "Think, Internet, ChatGPT, Further Processing" (39.1%). However, this collaboration reveals a critical verification deficit that escalates with problem complexity. We empirically identify and quantify two systematic epistemic gaps: a belief-performance gap (up to +80.8 percentage points discrepancy between perceived and actual correctness) and a proof-belief gap (up to -16.8 percentage points between confidence and verification capability). These findings, derived from behavioral data and problem vignettes across complexity levels, indicate that the fundamental constraint on reliable AI-assisted work is solution validation rather than generation. The study concludes that educational and technological interventions must prioritize verification scaffolds (including assumption documentation protocols, adequacy criteria checklists, and triangulation procedures) to fortify the human role as critical validator in this new cognitive ecosystem.

</details>


### [253] [Taxation and the relationship between payments and time spent](https://arxiv.org/abs/2511.11741)
*Christopher Mantzaris,Ajda Fosner*

Main category: cs.CY

TL;DR: 研究发现纳税合规时间与纳税金额之间存在正相关关系，通过分析全球税收数据证实了这种关系，表明简化税收流程可以降低社会税收管理成本。


<details>
  <summary>Details</summary>
Motivation: 税收工作对社会成本高昂，纳税人花费大量时间处理行政税务工作会影响财富创造。研究旨在理解税收行政成本与纳税合规时间的关系，以寻求降低这些成本的方法。

Method: 使用PwC和世界银行2019年《纳税》报告数据，分析全球司法管辖区纳税合规时间(X)与纳税金额(Y)的关系。进行了6组测试，包括原始数据、去除城市数据、去除城市和异常值数据，每组测试分别使用总纳税金额和其他纳税金额。

Result: 所有6组测试都满足5个要求（正斜率、满足p值和r值、高互信息、散点图确认），证实了纳税合规时间与纳税金额之间的正相关关系，且总纳税金额的关系更为明显。

Conclusion: 研究发现纳税合规时间与纳税金额存在正相关，简化税收流程（包括税收征收和支付）可以减少纳税人花费在税务上的时间，从而降低社会整体税收管理成本。

Abstract: Tax work is costly for society: Administrative tax labour is typically to a high degree shuffled off the government and onto every taxpayer by law. The higher the burden of any tax system, the costlier for society, as taxpayers are unable to engage in proper wealth creation when being kept busy with administrative tax work. This research finds evidence for a relationship between hours spent to comply with taxes and amount of tax payment. These findings help better understand tax administrative costs and ultimately may help reduce them. PwC and World Bank's final "Paying taxes"-publication (2019) contains tax data for most of the world's jurisdictions, in particular annual hours spent to comply with tax obligations (X) and annual amount of tax payments (Y), both for the year 2019. X and Y were plotted in 6 tests. A positive slope, satisfying p and r values, high mutual information and finally a conclusive scatter plot picture were the 5 requirements that all needed to be met to confirm a positive relationship between X and Y. The first 2 tests did not make any adjustments to the data, the next 2 tests removed cities --thereby avoiding the double counting of jurisdictions-- and the final 2 tests removed cities and outliers. Each test pair uses for Y first total number of payments; and for each second test the number of other payments, which excludes income tax payments for profit and labour. All 5 requirements were met in every of the 6 tests, indicating a positive dependence. In addition, 4 confirmatory tests validate the methodology. The found relationship is noticeably stronger for the total number of tax payments. Findings indicate that taxpayers' time spent on tax, and thereby society's overall tax administrative costs, could be reduced by simplifying taxation processes, including tax collection and payments.

</details>


### [254] [Brazil Data Commons: A Platform for Unifying and Integrating Brazil's Public Data](https://arxiv.org/abs/2511.11755)
*Isadora Cristina,Ramon Gonze,Jônatas Santos,Julio Reis,Mário Alvim,Bernardo Queiroz,Fabrício Benevenuto*

Main category: cs.CY

TL;DR: 巴西数据共享平台通过统一语义框架整合分散的巴西数据集，解决数据碎片化和互操作性不足问题，促进研究和政策制定。


<details>
  <summary>Details</summary>
Motivation: 解决巴西公共数据碎片化、标准不一致和互操作性有限的问题，这些因素阻碍了有效研究、循证决策和数据驱动洞察的获取。

Method: 引入巴西数据共享平台，采用全球认可的语义本体和互操作数据标准，在统一语义框架下整合各种巴西数据集。

Result: 平台实现了不同领域信息的无缝发现、集成和可视化，使研究人员、政策制定者和公众能够获得有意义的见解并做出明智决策。

Conclusion: 巴西数据共享平台将分散的数据集转变为集成且易于导航的资源，有助于更深入地理解巴西复杂的社会、经济和环境景观。

Abstract: The fragmentation of public data in Brazil, coupled with inconsistent standards and limited interoperability, hinders effective research, evidence-based policymaking and access to data-driven insights. To address these issues, we introduce Brazil Data Commons, a platform that unifies various Brazilian datasets under a common semantic framework, enabling the seamless discovery, integration and visualization of information from different domains. By adopting globally recognized ontologies and interoperable data standards, Brazil Data Commons aligns with the principles of the broader Data Commons ecosystem and places Brazilian data in a global context. Through user-friendly interfaces, straightforward query mechanisms and flexible data access options, the platform democratizes data use and enables researchers, policy makers, and the public to gain meaningful insights and make informed decisions. This paper illustrates how Brazil Data Commons transforms scattered datasets into an integrated and easily navigable resource that allows a deeper understanding of Brazil's complex social, economic and environmental landscape.

</details>


### [255] [Bridging the Skills Gap: A Course Model for Modern Generative AI Education](https://arxiv.org/abs/2511.11757)
*Anya Bardach,Hamilton Murrah*

Main category: cs.CY

TL;DR: 本文探讨了生成式AI工具普及对学习环境的影响，指出高等教育中AI能力培养与行业需求脱节的问题。作者开发了一门面向计算机科学学生的生成式AI应用课程，通过调查证明课程效果显著，并提供了推广建议。


<details>
  <summary>Details</summary>
Motivation: 生成式AI能力在行业中日益重要，但高等教育中缺乏相关课程，导致学生缺乏正规指导。计算机科学领域尤其受到影响，需要培养学生负责任地使用AI工具的能力。

Method: 在一所私立研究型大学为计算机科学本科生和研究生开发了生成式AI工具在软件开发中应用的课程，并通过混合方法调查评估课程效果。

Result: 调查显示学生普遍认为课程有价值且有效，课程成功填补了AI应用教育的空白。

Conclusion: 计算机科学及其他领域都需要开设生成式AI应用课程，以确保学生具备就业市场所需的AI能力，并提出了课程复制的建议。

Abstract: Research on how the popularization of generative Artificial Intelligence (AI) tools impacts learning environments has led to hesitancy among educators to teach these tools in classrooms, creating two observed disconnects. Generative AI competency is increasingly valued in industry but not in higher education, and students are experimenting with generative AI without formal guidance. The authors argue students across fields must be taught to responsibly and expertly harness the potential of AI tools to ensure job market readiness and positive outcomes. Computer Science trajectories are particularly impacted, and while consistently top ranked U.S. Computer Science departments teach the mechanisms and frameworks underlying AI, few appear to offer courses on applications for existing generative AI tools. A course was developed at a private research university to teach undergraduate and graduate Computer Science students applications for generative AI tools in software development. Two mixed method surveys indicated students overwhelmingly found the course valuable and effective. Co-authored by the instructor and one of the graduate students, this paper explores the context, implementation, and impact of the course through data analysis and reflections from both perspectives. It additionally offers recommendations for replication in and beyond Computer Science departments. This is the extended version of this paper to include technical appendices.

</details>


### [256] [Cost Transparency of Enterprise AI Adoption](https://arxiv.org/abs/2511.11761)
*Soogand Alavi,Salar Nozari,Andrea Luangrath*

Main category: cs.CY

TL;DR: 研究发现，在大型语言模型服务中，非礼貌的提示会显著增加输出token数量，导致企业成本上升，而礼貌提示则能减少成本，这种语言风格对成本的影响揭示了当前定价模型的不透明性。


<details>
  <summary>Details</summary>
Motivation: 随着企业广泛采用大型语言模型服务，其按token计价的成本模式存在不可预测性，特别是输出token数量超出企业控制范围，这给企业预算和透明度带来挑战。

Method: 通过OpenAI API进行实验，比较礼貌和非礼貌提示对输出token数量的影响，分析语言风格变化如何系统性地改变输出token数量。

Result: 实验显示非礼貌提示显著增加输出token数量，导致企业成本上升，而礼貌提示能有效减少输出token，但不会影响响应质量。

Conclusion: 当前LLM服务的定价模型存在不透明性，语言结构变化会导致不可预测的成本波动，需要新的定价方法确保企业采用的可预测性和透明度。

Abstract: Recent advances in large language models (LLMs) have dramatically improved performance on a wide range of tasks, driving rapid enterprise adoption. Yet, the cost of adopting these AI services is understudied. Unlike traditional software licensing in which costs are predictable before usage, commercial LLM services charge per token of input text in addition to generated output tokens. Crucially, while firms can control the input, they have limited control over output tokens, which are effectively set by generation dynamics outside of business control. This research shows that subtle shifts in linguistic style can systematically alter the number of output tokens without impacting response quality. Using an experiment with OpenAI's API, this study reveals that non-polite prompts significantly increase output tokens leading to higher enterprise costs and additional revenue for OpenAI. Politeness is merely one instance of a broader phenomenon in which linguistic structure can drive unpredictable cost variation. For enterprises integrating LLM into applications, this unpredictability complicates budgeting and undermines transparency in business-to-business contexts. By demonstrating how end-user behavior links to enterprise costs through output token counts, this work highlights the opacity of current pricing models and calls for new approaches to ensure predictable and transparent adoption of LLM services.

</details>


### [257] [Demystify, Use, Reflect: Preparing students to be informed LLM-users](https://arxiv.org/abs/2511.11764)
*Nikitha Donekal Chandrashekar,Sehrish Basir Nizamani,Margaret Ellis,Naren Ramakrishnan*

Main category: cs.CY

TL;DR: 该论文描述了一个计算机科学入门后课程的转型，通过结构化、批判性和实践性的方式整合大型语言模型，旨在培养学生负责任使用AI的技能。


<details>
  <summary>Details</summary>
Motivation: 帮助学生发展有意义且负责任地与AI互动的能力，为AI集成的未来做准备。

Method: 课程包含LLM工作原理的明确指导、当前工具展示、伦理问题讨论，以及鼓励学生反思个人使用LLM的活动。课堂上演示LLM输出的使用和验证，指导学生将LLM作为更大问题解决循环的一部分，并要求学生披露LLM协助的性质和程度。

Result: 在课程首次迭代中，通过前后调查收集和分析学生数据。学生对LLM工作原理的理解变得更加技术化，他们对LLM的验证和使用变得更加敏锐和协作。

Conclusion: 这些策略可以用于其他课程，为学生应对AI集成的未来做好准备。

Abstract: We transitioned our post-CS1 course that introduces various subfields of computer science so that it integrates Large Language Models (LLMs) in a structured, critical, and practical manner. It aims to help students develop the skills needed to engage meaningfully and responsibly with AI. The course now includes explicit instruction on how LLMs work, exposure to current tools, ethical issues, and activities that encourage student reflection on personal use of LLMs as well as the larger evolving landscape of AI-assisted programming. In class, we demonstrate the use and verification of LLM outputs, guide students in the use of LLMs as an ingredient in a larger problem-solving loop, and require students to disclose and acknowledge the nature and extent of LLM assistance. Throughout the course, we discuss risks and benefits of LLMs across CS subfields. In our first iteration of the course, we collected and analyzed data from students pre and post surveys. Student understanding of how LLMs work became more technical, and their verification and use of LLMs shifted to be more discerning and collaborative. These strategies can be used in other courses to prepare students for the AI-integrated future.

</details>


### [258] [Scaling Equitable Reflection Assessment in Education via Large Language Models and Role-Based Feedback Agents](https://arxiv.org/abs/2511.11772)
*Chenyu Zhang,Xiaohang Luo*

Main category: cs.CY

TL;DR: 本文提出了一种基于多智能体LLM的系统，用于大规模提供公平的形成性反馈，通过五个协调的角色智能体来评分和生成学习者反馈，在AI素养课程中实现了接近专家水平的评分一致性。


<details>
  <summary>Details</summary>
Motivation: 形成性反馈是学生学习的有效驱动力，但在大规模或资源有限的课程中难以公平实施，教师缺乏时间和资源来审阅每个学生的反思，导致支持缺口。

Method: 使用五个协调的角色智能体（评估者、公平监控者、元认知教练、聚合者和反思审阅者）系统，基于共享评分标准对学习者反思进行评分，并生成简短、偏见感知的学习者反馈评论，包含公平性检查机制。

Result: 在12节AI素养课程中评估，系统产生的评分标准接近专家水平的一致性，训练过的评分者认为AI生成的评论有帮助、有同理心且与教学目标一致。

Conclusion: 多智能体LLM系统能够以人类评分者无法达到的规模和速度提供公平、高质量的形成性反馈，为实现任何课程规模和情境下的反馈丰富学习指明了方向。

Abstract: Formative feedback is widely recognized as one of the most effective drivers of student learning, yet it remains difficult to implement equitably at scale. In large or low-resource courses, instructors often lack the time, staffing, and bandwidth required to review and respond to every student reflection, creating gaps in support precisely where learners would benefit most. This paper presents a theory-grounded system that uses five coordinated role-based LLM agents (Evaluator, Equity Monitor, Metacognitive Coach, Aggregator, and Reflexion Reviewer) to score learner reflections with a shared rubric and to generate short, bias-aware, learner-facing comments. The agents first produce structured rubric scores, then check for potentially biased or exclusionary language, add metacognitive prompts that invite students to think about their own thinking, and finally compose a concise feedback message of at most 120 words. The system includes simple fairness checks that compare scoring error across lower and higher scoring learners, enabling instructors to monitor and bound disparities in accuracy. We evaluate the pipeline in a 12-session AI literacy program with adult learners. In this setting, the system produces rubric scores that approach expert-level agreement, and trained graders rate the AI-generated comments as helpful, empathetic, and well aligned with instructional goals. Taken together, these results show that multi-agent LLM systems can deliver equitable, high-quality formative feedback at a scale and speed that would be impossible for human graders alone. More broadly, the work points toward a future where feedback-rich learning becomes feasible for any course size or context, advancing long-standing goals of equity, access, and instructional capacity in education.

</details>


### [259] [Differences in the Moral Foundations of Large Language Models](https://arxiv.org/abs/2511.11790)
*Peter Kirgis*

Main category: cs.CY

TL;DR: 使用道德基础理论分析大型语言模型的伦理判断，发现不同模型之间存在道德基础差异，且与人类基准存在偏差，模型能力越强差异越大。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在政治、商业和教育等关键领域应用日益广泛，但其规范性伦理判断本质仍不透明，需要利用道德心理学视角来指导模型的训练和评估。

Method: 使用Jonathan Haidt的道德基础理论对多个主要模型提供商的模型进行合成实验，通过多种描述性统计方法分析模型响应相对于原始调查中人类基准的偏差和方差。

Result: 模型之间以及模型与全国代表性人类基准之间存在不同的道德基础依赖，且这些差异随着模型能力的增强而增加。

Conclusion: 这项工作旨在推动使用道德基础理论进一步分析大型语言模型，包括对开源模型的微调，并促使政策制定者更加重视道德基础在大型语言模型对齐中的重要性。

Abstract: Large language models are increasingly being used in critical domains of politics, business, and education, but the nature of their normative ethical judgment remains opaque. Alignment research has, to date, not sufficiently utilized perspectives and insights from the field of moral psychology to inform training and evaluation of frontier models. I perform a synthetic experiment on a wide range of models from most major model providers using Jonathan Haidt's influential moral foundations theory (MFT) to elicit diverse value judgments from LLMs. Using multiple descriptive statistical approaches, I document the bias and variance of large language model responses relative to a human baseline in the original survey. My results suggest that models rely on different moral foundations from one another and from a nationally representative human baseline, and these differences increase as model capabilities increase. This work seeks to spur further analysis of LLMs using MFT, including finetuning of open-source models, and greater deliberation by policymakers on the importance of moral foundations for LLM alignment.

</details>


### [260] [Educators on the Frontline: Philosophical and Realistic Perspectives on Integrating ChatGPT into the Learning Space](https://arxiv.org/abs/2511.11960)
*Surajit Das,Peu Majumder,Aleksei Eliseev*

Main category: cs.CY

TL;DR: 本研究通过调查140名俄罗斯大学教育工作者，提出了一个包含七个子空间的'学习空间'理论模型，系统分析ChatGPT在教育中的影响。结果显示大多数教育工作者有条件地支持ChatGPT整合，但对其影响批判性思维表示担忧。


<details>
  <summary>Details</summary>
Motivation: 超越关于生成式AI在教育中未来的恐慌性讨论，基于关键利益相关者（大学教育工作者）的结构化视角，系统识别AI整合对教育环境的影响。

Method: 提出'学习空间'理论模型（包含七个子空间），通过定量调查140名俄罗斯大学教育工作者，使用二元标记系统分析关键指标的接受度。

Result: 大多数教育工作者有条件支持ChatGPT整合，前提是评估方法转变和剽窃检测工具可用；担忧AI对批判性思维的影响；拒绝AI降低教师重要性的观点，认为教师角色从信息传递者转变为批判性参与促进者。

Conclusion: ChatGPT不是教育的破坏者，而是必要演变的催化剂；提出PIPE模型（教学法、基础设施、政策、教育）作为负责任整合的战略框架，为AI教育讨论提供数据驱动的模型分析。

Abstract: The rapid emergence of Generative AI, particularly ChatGPT, has sparked a global debate on the future of education, often characterized by alarmism and speculation. Moving beyond this, this study investigates the structured, grounded perspectives of a key stakeholder group: university educators. It proposes a novel theoretical model that conceptualizes the educational environment as a "Learning Space" composed of seven subspaces to systematically identify the impact of AI integration. This framework was operationalized through a quantitative survey of 140 Russian university educators, with responses analyzed using a binary flagging system to measure acceptance across key indicators. The results reveal a strong but conditional consensus: a majority of educators support ChatGPT's integration, contingent upon crucial factors such as the transformation of assessment methods and the availability of plagiarism detection tools. However, significant concerns persist regarding its impact on critical thinking. Educators largely reject the notion that AI diminishes their importance, viewing their role as evolving from information-deliverer to facilitator of critical engagement. The study concludes that ChatGPT acts less as a destroyer of education and more as a catalyst for its necessary evolution, and proposes the PIPE Model (Pedagogy, Infrastructure, Policy, Education) as a strategic framework for its responsible integration. This research provides a data-driven, model-based analysis of educator attitudes, offering a nuanced alternative to the polarized discourse surrounding AI in education.

</details>


### [261] [Leveraging Large Language Models for Career Mobility Analysis: A Study of Gender, Race, and Job Change Using U.S. Online Resume Profiles](https://arxiv.org/abs/2511.12010)
*Palakorn Achananuparp,Connie Xu,Yao Lu,Xavier Jayaraj Siddarth Ashok,Ee-Peng Lim*

Main category: cs.CY

TL;DR: 本研究使用在线简历数据分析了美国大学毕业生职业流动性的性别和种族差异，发现公司内部职位变动对晋升最有利，而女性和黑人毕业生从工作变动中获得的回报显著低于男性和白人同行。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究工作变动如何影响职业向上流动性，以及这种流动性结果在性别和种族方面的差异，填补了大规模职业流动性研究的空白。

Method: 使用在线简历数据，通过AI方法处理缺失人口统计属性、工资数据和嘈杂的职业标签，开发了基于大语言模型的FewSOC职业分类方法，分析了228,710条职业轨迹。

Result: 公司内部职位变动对向上流动性促进作用最强，其次是公司间职位变动和公司间平级调动。女性和黑人大学毕业生的职业变动回报显著低于男性和白人同行。

Conclusion: 研究揭示了职业流动性的显著性别和种族差异，多级敏感性分析证实这些差异对集群异质性具有稳健性，并显示出额外的交叉性模式。

Abstract: We present a large-scale analysis of career mobility of college-educated U.S. workers using online resume profiles to investigate how gender, race, and job change options are associated with upward mobility. This study addresses key research questions of how the job changes affect their upward career mobility, and how the outcomes of upward career mobility differ by gender and race. We address data challenges -- such as missing demographic attributes, missing wage data, and noisy occupation labels -- through various data processing and Artificial Intelligence (AI) methods. In particular, we develop a large language models (LLMs) based occupation classification method known as FewSOC that achieves accuracy significantly higher than the original occupation labels in the resume dataset. Analysis of 228,710 career trajectories reveals that intra-firm occupation change has been found to facilitate upward mobility most strongly, followed by inter-firm occupation change and inter-firm lateral move. Women and Black college graduates experience significantly lower returns from job changes than men and White peers. Multilevel sensitivity analyses confirm that these disparities are robust to cluster-level heterogeneity and reveal additional intersectional patterns.

</details>


### [262] [Impact of UK Postgraduate Student Experiences on Academic Performance in Blended Learning: A Data Analytics Approach](https://arxiv.org/abs/2511.12320)
*Muhidin Mohamed,Shubhadeep Mukherjee,Bhavana Baad*

Main category: cs.CY

TL;DR: 本研究探讨了英国大学研究生混合学习中学习体验维度与学业成就的关系，发现结合教学和社会存在感的学习活动以及通过有效反馈提供的定制化学术支持是成功的关键因素。


<details>
  <summary>Details</summary>
Motivation: 混合学习已成为高等教育的主流模式，特别是在COVID-19大流行后，但学生在混合学习环境中构建成功学习面临新挑战，需要研究学习体验维度与学业成就的相互作用。

Method: 采用多种数据分析技术，包括可视化、统计检验、回归分析和潜在剖面分析，基于对255名研究生的调查数据，通过探究社区框架进行整体解释。

Result: 实证结果表明，结合教学和社会存在感的学习活动以及通过有效反馈提供的定制化学术支持是混合学习背景下研究生成功体验的关键要素。

Conclusion: 本研究通过识别人口统计学、体验和心理因素对学业成果的各种影响方式，推进了对学生成功的理解，并在理论上通过整合学习者异质性概念和基于不同CoI存在感参与方式识别四个不同学生档案，扩展了CoI框架。

Abstract: Blended learning has become a dominant educational model in higher education in the UK and worldwide, particularly after the COVID-19 pandemic. This is further enriched with accompanying pedagogical changes, such as strengthened asynchronous learning, and the use of AI (from ChatGPT and all other similar tools that followed) and other technologies to aid learning. While these educational transformations have enabled flexibility in learning and resource access, they have also exposed new challenges on how students can construct successful learning in hybrid learning environments. In this paper, we investigate the interaction between different dimensions of student learning experiences (ranging from perceived acceptance of teaching methods and staff support/feedback to learning pressure and student motivation) and academic achievement within the context of postgraduate blended learning in UK universities. To achieve this, we employed a combination of several data analytics techniques including visualization, statistical tests, regression analysis, and latent profile analysis. Our empirical results (based on a survey of 255 postgraduate students and holistically interpreted via the Community of Inquiry (CoI) framework) demonstrated that learning activities combining teaching and social presences, and tailored academic support through effective feedback are critical elements for successful postgraduate experience in blended learning contexts. Regarding contributions, this research advances the understanding of student success by identifying the various ways demographic, experiential, and psychological factors impact academic outcomes. And in theoretical terms, it contributes to the extension of the CoI framework by integrating the concept of learner heterogeneity and identifying four distinct student profiles based on how they engage in the different CoI presences.

</details>


### [263] [Cultural Awareness, Stereotypes and Communication Skills in Intercultural Communication: The Algerian Participants Perspective](https://arxiv.org/abs/2511.12369)
*Mohamed Amine Kada Zair*

Main category: cs.CY

TL;DR: 本研究探讨了在多元文化环境中工作或学习的阿尔及利亚参与者的文化意识、刻板印象与沟通技能之间的关系，发现高文化意识能降低刻板印象并提升沟通效率。


<details>
  <summary>Details</summary>
Motivation: 探索在多元文化环境中，文化意识、刻板印象如何影响跨文化沟通技能，为提升跨文化能力提供实证依据。

Method: 采用定量问卷调查法，对40名在多元文化环境中工作或学习的阿尔及利亚参与者进行评估，测量其文化意识水平、刻板思维存在程度和跨文化沟通技能有效性。

Result: 结果显示文化意识普遍较高，但某些刻板印象仍影响对他人的认知和沟通效率；文化意识较高的参与者表现出更好的沟通技能和更低的刻板印象水平。

Conclusion: 研究强调了跨文化能力和教育项目在减少偏见、促进多元环境中相互理解的重要性。

Abstract: This study explores the relationship between cultural awareness, stereotypes, and communication skills among Algerian participants working or studying in multicultural environments. A quantitative questionnaire was administered to 40 respondents to evaluate their levels of cultural awareness, the presence of stereotypical thinking, and the effectiveness of their intercultural communication skills. Results revealed that while cultural awareness was generally high, certain stereotypes still influenced the perception of others and impacted communication efficiency. Participants with higher cultural awareness demonstrated better communication skills and lower levels of stereotyping. These findings underline the importance of intercultural competence and education programs in reducing prejudice and fostering mutual understanding in diverse contexts.

</details>


### [264] [Political Advertising on Facebook During the 2022 Australian Federal Election: A Social Identity Perspective](https://arxiv.org/abs/2511.12426)
*Stefano Civelli,Pietro Bernardelle,Frank Mols,Gianluca Demartini*

Main category: cs.CY

TL;DR: 基于Meta广告库分析2022年澳大利亚联邦选举期间Facebook和Instagram政治广告，发现主要政党在支出、覆盖范围和说服策略上存在显著差异，广告活动在选举前达到高峰，各政党针对不同人口统计群体采用差异化策略。


<details>
  <summary>Details</summary>
Motivation: 监控社交媒体平台上的政治广告对于维护民主进程的透明度和问责制至关重要，需要建立实证证据基础来分析数字政治营销策略。

Method: 利用Meta广告库分析2022年澳大利亚联邦选举期间的政治广告，从时间、人口统计和地理维度考察主要政治行为体的广告策略，并运用社会认同理论(SIT)进行解释。

Result: 发现广告活动在选举前显著增加并在媒体静默期前达到高峰；各政党针对年轻人群采用差异化策略，广告印象存在性别差异；广告区域分布与人口密度基本一致；主要政党强调党派名称和对手，而小党派则关注具体议题。

Conclusion: 在澳大利亚强制投票制度下，主要政党通过强化党派认同来防止选民流失，而小党派则通过培育议题认同来吸引不满选民的支持，这体现了不同的说服策略。

Abstract: The spread of targeted advertising on social media platforms has revolutionized political marketing strategies. Monitoring these digital campaigns is essential for maintaining transparency and accountability in democratic processes. Leveraging Meta's Ad Library, we analyze political advertising on Facebook and Instagram during the 2022 Australian federal election campaign. We investigate temporal, demographic, and geographical patterns in the advertising strategies of major Australian political actors to establish an empirical evidence base, and interpret these findings through the lens of Social Identity Theory (SIT). Our findings not only reveal significant disparities in spending and reach among parties, but also in persuasion strategies being deployed in targeted online campaigns. We observe a marked increase in advertising activity as the election approached, peaking just before the mandated media blackout period. Demographic analysis shows distinct targeting strategies, with parties focusing more on younger demographics and exhibiting gender-based differences in ad impressions. Regional distribution of ads largely mirrored population densities, with some parties employing more targeted approaches in specific states. Moreover, we found that parties emphasized different themes aligned with their ideologies-major parties focused on party names and opponents, while smaller parties emphasized issue-specific messages. Drawing on SIT, we interpret these findings within Australia's compulsory voting context, suggesting that parties employed distinct persuasion strategies. With turnout guaranteed, major parties focused on reinforcing partisan identities to prevent voter defection, while smaller parties cultivated issue-based identities to capture the support of disaffected voters who are obligated to participate.

</details>


### [265] [AI and Supercomputing are Powering the Next Wave of Breakthrough Science - But at What Cost?](https://arxiv.org/abs/2511.12686)
*Stefano Bianchini,Aldo Geuna,Fazliddin Shermatov*

Main category: cs.CY

TL;DR: 基于500万篇科学论文的分析显示，AI与高性能计算的结合使论文引入新概念的可能性提高3倍，进入高被引论文的可能性提高5倍，但同时也加剧了全球计算资源和专业知识的获取不平等。


<details>
  <summary>Details</summary>
Motivation: 量化人工智能和高性能计算对科学发现的联合影响，探索这两种技术如何共同塑造研究产出。

Method: 分析2000-2024年间超过500万篇科学论文的元数据，研究AI和HPC在27个领域中的交互作用。

Result: 结合AI和HPC的论文比传统研究引入新概念的可能性高3倍，成为高被引论文的可能性高5倍；这种融合正在重新定义科学创造力的前沿，但也加深了全球在计算能力和专业知识获取方面的不平等。

Conclusion: 科学发现的未来不仅取决于算法和计算能力，还取决于世界如何公平地分享这些变革性工具。

Abstract: Artificial intelligence (AI) and high-performance computing (HPC) are rapidly becoming the engines of modern science. However, their joint effect on discovery has yet to be quantified at scale. Drawing on metadata from over five million scientific publications (2000-2024), we identify how AI and HPC interact to shape research outcomes across 27 fields. Papers combining the two technologies are up to three times more likely to introduce novel concepts and five times more likely to reach top-cited status than conventional work. This convergence of AI and HPC is redefining the frontier of scientific creativity but also deepening global inequalities in access to computational power and expertise. Our findings suggest that the future of discovery will depend not only on algorithms and compute, but also on how equitably the world shares these transformative tools.

</details>


### [266] [The Unspoken Crisis of Learning: The Surging Zone of No Development](https://arxiv.org/abs/2511.12822)
*Euzeli C. dos Santos,Tracey Birdwell*

Main category: cs.CY

TL;DR: 本文通过P2P教学框架重新审视维果茨基的最近发展区理论，提出"无发展区"概念，强调AI教育中需要避免永久性数字中介，恢复学习者的认知自主性。


<details>
  <summary>Details</summary>
Motivation: AI在教育中的广泛应用模糊了引导学习与依赖之间的界限，需要重新思考如何确保技术工具增强而非替代学习者的认知努力。

Method: 通过理论综合和框架设计，采用P2P教学方法，对比临时性支架与永久性数字中介，引入有意识断开和伦理淡出机制。

Result: 提出了Zone of No Development概念，展示了如何通过P2P教学恢复学习者能动性，确保技术工具增强而非替代发展努力。

Conclusion: 生产性挣扎、自我调节和第一性原理推理对持久学习至关重要，负责任的教育AI使用必须包含明确机制，在掌握开始时终止帮助。

Abstract: AI has redefined the boundaries of assistance in education, often blurring the line between guided learning and dependency. This paper revisits Vygotsky's Zone of Proximal Development (ZPD) through the lens of the P2P Teaching framework. By contrasting temporary scaffolding with the emerging phenomenon of permanent digital mediation, the study introduces the concept of the Zone of No Development (ZND), a state in which continuous assistance replaces cognitive struggle and impedes intellectual autonomy. Through theoretical synthesis and framework design, P2P Teaching demonstrates how deliberate disconnection and ethical fading can restore the learner's agency, ensuring that technological tools enhance rather than replace developmental effort. The paper argues that productive struggle, self-regulation, and first-principles reasoning remain essential for durable learning, and that responsible use of AI in education must include explicit mechanisms to end its help when mastery begins.

</details>


### [267] [Telekommunikationsüberwachung am Scheideweg: Zur Regulierbarkeit des Zugriffes auf verschlüsselte Kommunikation](https://arxiv.org/abs/2511.12830)
*Joanna Klauser,Bruno Albert,Christian Lindenmeier,Andreas Hammer,Felix Freiling,Dirk Heckmann,Sabine Pfeiffer*

Main category: cs.CY

TL;DR: 本文探讨在端到端加密通信时代，如何合理规范技术参与者的合作义务，以平衡执法需求与通信隐私保护。


<details>
  <summary>Details</summary>
Motivation: 随着互联网技术发展，传统电信监控面临挑战，端到端加密技术使执法机构难以获取通信内容，需要重新审视技术参与者的合作义务。

Method: 分析当前电信监控法律框架，探讨加密通信环境下技术参与者的合作义务如何合理规范。

Result: 识别出传统电信监控在加密通信环境下的局限性，需要重新设计技术参与者的合作义务框架。

Conclusion: 在加密通信时代，需要重新思考技术参与者的合作义务规范方式，以平衡执法需求与个人通信隐私保护。

Abstract: Personal communication using technical means is protected by telecommunications secrecy. Any interference with this fundamental right requires a legal basis, which has existed for many years for traditional communication services in the form of telecommunications surveillance (TKÜ, § 100a StPO) and appears to be widely accepted by society. The basis for the implementation of TKÜ is the obligation of telecommunications providers to provide interception interfaces. However, the technical implementation of telecommunications has changed significantly as a result of the Internet. Messenger services and Voice over IP telephony are increasingly competing with traditional telephone services. The use of strong end-to-end encryption made possible by this technology is increasingly posing problems for law enforcement agencies, as only cryptographically encrypted content is accessible via the interception interfaces provided to date. Against the backdrop of current discussions on socalled ``chat control'' and its limited social acceptance, this article addresses the question of whether and, if so, how the cooperation obligations of the technical actors involved can be sensibly regulated in the case of encrypted communication.

</details>


### [268] [Beyond Citations: A Cross-Domain Metric for Dataset Impact and Shareability](https://arxiv.org/abs/2511.12966)
*Smitha Muthya Sudheendra,Zhongxing Zhang,Wenwen Cao,Jisu Huh,Jaideep Srivastava*

Main category: cs.CY

TL;DR: 提出X-index作为新的作者级指标，通过数据集价值评分（V-score）和聚合机制来量化数据贡献的价值，解决传统指标无法衡量数据集影响力的局限。


<details>
  <summary>Details</summary>
Motivation: 现有指标（如h指数）主要关注论文发表和引用，无法充分评估数据集的可访问性、重用性和跨学科影响力，需要新的度量方法来激励开放科学和数据共享实践。

Method: 采用两步法：首先计算数据集级价值评分（V-score），整合重用广度、FAIR原则、引用影响和传递重用深度；然后将V-score聚合作者级X-index。

Result: 在计算社会科学、医学和危机传播等领域的数据集上进行验证，与专家评分呈现强相关性，证明X-index的有效性。

Conclusion: X-index提供了一个透明、可扩展且低成本的框架，用于评估数据共享实践并激励开放科学，为机构、资助者和平台提供了认可研究数据集持久影响力的具体方法。

Abstract: The scientific community increasingly relies on open data sharing, yet existing metrics inadequately capture the true impact of datasets as research outputs. Traditional measures, such as the h-index, focus on publications and citations but fail to account for dataset accessibility, reuse, and cross-disciplinary influence. We propose the X-index, a novel author-level metric that quantifies the value of data contributions through a two-step process: (i) computing a dataset-level value score (V-score) that integrates breadth of reuse, FAIRness, citation impact, and transitive reuse depth, and (ii) aggregating V-scores into an author-level X-index. Using datasets from computational social science, medicine, and crisis communication, we validate our approach against expert ratings, achieving a strong correlation. Our results demonstrate that the X-index provides a transparent, scalable, and low-cost framework for assessing data-sharing practices and incentivizing open science. The X-index encourages sustainable data-sharing practices and gives institutions, funders, and platforms a tangible way to acknowledge the lasting influence of research datasets.

</details>


### [269] [The Last Vote: A Multi-Stakeholder Framework for Language Model Governance](https://arxiv.org/abs/2511.13432)
*Subramanyam Sahoo,Aditi Chhawacharia*

Main category: cs.CY

TL;DR: 提出了一个全面的AI民主风险治理框架，包括七类风险分类法、利益相关者适应的严重性评分系统和分阶段实施策略。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益强大和普及，民主社会面临前所未有的挑战，需要在治理这些技术的同时保护核心民主价值观和制度。

Method: 整合多方利益相关者参与、公民社会参与和现有国际治理框架，引入风险评估和制度适应的新机制。

Result: 开发了七类民主风险分类法、利益相关者适应的严重性评分系统（ISS）和分阶段实施策略。

Conclusion: 该框架为民主社会提供了应对AI系统性风险的全面治理方法，强调制度变革的复杂性。

Abstract: As artificial intelligence systems become increasingly powerful and pervasive, democratic societies face unprecedented challenges in governing these technologies while preserving core democratic values and institutions. This paper presents a comprehensive framework to address the full spectrum of risks that AI poses to democratic societies. Our approach integrates multi-stakeholder participation, civil society engagement, and existing international governance frameworks while introducing novel mechanisms for risk assessment and institutional adaptation. We propose: (1) a seven-category democratic risk taxonomy extending beyond individual-level harms to capture systemic threats, (2) a stakeholder-adaptive Incident Severity Score (ISS) that incorporates diverse perspectives and context-dependent risk factors, and (3) a phased implementation strategy that acknowledges the complex institutional changes required for effective AI governance.

</details>


### [270] [AI Fairness Beyond Complete Demographics: Current Achievements and Future Directions](https://arxiv.org/abs/2511.13525)
*Zichong Wang,Zhipeng Yin,Roland H. C. Yap,Wenbin Zhang*

Main category: cs.CY

TL;DR: 该论文综述了在人口统计信息不完整情况下的AI公平性问题，提出了新的公平性概念分类法，并总结了相关技术方法。


<details>
  <summary>Details</summary>
Motivation: 由于AI决策系统存在歧视性结果，公平性成为日益关注的问题。传统方法依赖完整的人口统计信息，但这在实践中往往不可行，存在法律约束和强化歧视的风险。

Method: 引入了一个新的公平性概念分类法，阐明不同概念之间的关系和区别；总结了在人口统计信息不完整情况下促进公平性的现有技术。

Result: 澄清了在人口统计信息不完整设置下各种公平性概念的关系和区别，为这一领域提供了系统的理论框架。

Conclusion: 该研究填补了传统方法与现实挑战之间的差距，强调了在人口统计信息不完整情况下实现AI公平性的重要性，并指出了未来研究方向。

Abstract: Fairness in artificial intelligence (AI) has become a growing concern due to discriminatory outcomes in AI-based decision-making systems. While various methods have been proposed to mitigate bias, most rely on complete demographic information, an assumption often impractical due to legal constraints and the risk of reinforcing discrimination. This survey examines fairness in AI when demographics are incomplete, addressing the gap between traditional approaches and real-world challenges. We introduce a novel taxonomy of fairness notions in this setting, clarifying their relationships and distinctions. Additionally, we summarize existing techniques that promote fairness beyond complete demographics and highlight open research questions to encourage further progress in the field.

</details>


### [271] [Access to Personal Data and the Right to Good Governance during Asylum Procedures after the CJEU's YS. and M. and S. judgment](https://arxiv.org/abs/2511.13555)
*Evelien Brouwer,Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 欧洲法院在YS、M和S案中裁决了寻求庇护者获取庇护申请决定相关文件的权利，涉及个人数据概念、数据保护指令下的访问权范围以及欧盟基本权利宪章中的良好行政权。


<details>
  <summary>Details</summary>
Motivation: 分析欧洲法院关于庇护申请者文件访问权的裁决，探讨其对个人数据保护和行政权利解释的影响。

Method: 通过分析欧洲法院在YS、M和S案中的判决，解读相关法律概念和权利范围。

Result: 判决表面上对个人权利保护似乎令人失望，但实际上为未来庇护案件中的有效访问权提供了充分依据。

Conclusion: 该判决为庇护案件中个人文件访问权的有效实施奠定了法律基础，具有重要的实践意义。

Abstract: In the YS. and M. and S. judgment, the Court of Justice of the European Union ruled on three procedures in which Dutch judges asked for clarification on the right of asylum seekers to have access to the documents regarding the decision on asylum applications. The judgment is relevant for interpreting the concept of personal data and the scope of the right of access under the Data Protection Directive, and the right to good administration in the EU Charter of Fundamental Rights. At first glance, the judgment seems disappointing from the viewpoint of individual rights. Nevertheless, in our view the judgment provides sufficient grounds for effective access rights to the minutes in future asylum cases.

</details>


### [272] [Freedom of expression and 'right to be forgotten' cases in the Netherlands after Google Spain](https://arxiv.org/abs/2511.13557)
*Stefan Kulk,Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文分析了欧盟法院Google Spain判决在荷兰的应用情况，重点关注删除搜索结果请求的处理及其对言论自由的影响。


<details>
  <summary>Details</summary>
Motivation: 研究Google Spain判决后欧洲人有权要求删除姓名搜索结果的权利在实际应用中的情况，特别是在荷兰的具体执行效果。

Method: 通过分析荷兰法院在Google Spain判决后处理的两个删除请求案例，比较荷兰法院与欧盟法院在言论自由考量方面的差异。

Result: 荷兰法院在删除请求案件中比欧盟法院更深入地考虑了言论自由因素，但由于搜索引擎运营商对大部分删除请求决策缺乏透明度，判决对言论自由的实际影响难以评估。

Conclusion: Google Spain判决在荷兰的实施显示出对言论自由更细致的考量，但搜索引擎运营商决策的不透明性限制了对其言论自由影响的准确评估。

Abstract: Since the Google Spain judgment of the Court of Justice of the European Union, Europeans have, under certain conditions, the right to have search results for their name delisted. This paper examines how the Google Spain judgment has been applied in the Netherlands. Since the Google Spain judgment, Dutch courts have decided on two cases regarding delisting requests. In both cases, the Dutch courts considered freedom of expression aspects of delisting more thoroughly than the Court of Justice. However, the effect of the Google Spain judgment on freedom of expression is difficult to assess, as search engine operators decide about most delisting requests without disclosing much about their decisions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [273] [LLM-Generated Negative News Headlines Dataset: Creation and Benchmarking Against Real Journalism](https://arxiv.org/abs/2511.11591)
*Olusola Babalola,Bolanle Ojokoh,Olutayo Boyinbode*

Main category: cs.AI

TL;DR: 本研究探讨了使用大型语言模型生成的合成新闻标题作为真实世界数据替代方案的可行性，特别是在负面情感文本分析领域。通过专家验证和多种指标评估，发现合成标题在内容、语气和风格上与真实标题高度匹配。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言处理任务中数据获取困难和真实数据隐私问题，探索LLM生成数据作为替代方案的潜力，特别关注负面情感文本分析。

Method: 使用定制提示创建负面新闻标题语料库，通过专家评审验证，并在嵌入空间分析合成标题与真实标题在内容、语气、长度和风格上的对齐度。采用困惑度、可读性、词性标注分析、BERTScore和语义相似度等多种评估方法进行基准测试。

Result: 合成标题在大多数指标上与真实标题匹配良好，仅在词性标注分析中的专有名词得分存在明显差异。

Conclusion: LLM生成的合成数据集在负面情感文本分析中具有替代真实数据的潜力，能够有效支持NLP任务，同时规避数据获取和隐私问题。

Abstract: This research examines the potential of datasets generated by Large Language Models (LLMs) to support Natural Language Processing (NLP) tasks, aiming to overcome challenges related to data acquisition and privacy concerns associated with real-world data. Focusing on negative valence text, a critical component of sentiment analysis, we explore the use of LLM-generated synthetic news headlines as an alternative to real-world data. A specialized corpus of negative news headlines was created using tailored prompts to capture diverse negative sentiments across various societal domains. The synthetic headlines were validated by expert review and further analyzed in embedding space to assess their alignment with real-world negative news in terms of content, tone, length, and style. Key metrics such as correlation with real headlines, perplexity, coherence, and realism were evaluated. The synthetic dataset was benchmarked against two sets of real news headlines using evaluations including the Comparative Perplexity Test, Comparative Readability Test, Comparative POS Profiling, BERTScore, and Comparative Semantic Similarity. Results show the generated headlines match real headlines with the only marked divergence being in the proper noun score of the POS profile test.

</details>


### [274] [CLINB: A Climate Intelligence Benchmark for Foundational Models](https://arxiv.org/abs/2511.11597)
*Michelle Chen Huebscher,Katharine Mach,Aleksandar Stanić,Markus Leippold,Ben Gaiarin,Zeke Hausfather,Elisa Rawat,Erich Fischer,Massimiliano Ciaramita,Joeri Rogelj,Christian Buck,Lierni Sestorain Saralegui,Reto Knutti*

Main category: cs.AI

TL;DR: CLINB是一个评估大语言模型处理气候变化专业知识的基准，通过开放式、多模态问答任务测试模型的知识质量和证据支持能力。研究发现前沿模型在知识综合方面表现出色，但在证据基础方面存在严重问题，包括引用和图像的高度幻觉率。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型处理复杂专业知识的能力是一个关键挑战，特别是在气候变化这样的专业领域，需要确保模型输出的知识质量和证据可靠性。

Method: 引入CLINB基准，基于真实用户问题和气候科学家制定的评估标准，实施模型驱动的评估过程，评估多个前沿模型在开放式、多模态问答任务中的表现。

Result: 前沿模型展现出卓越的知识综合能力，达到博士级别的理解和呈现质量，甚至优于领域专家辅助较弱模型生成的混合答案。但存在严重的证据基础问题，引用和图像的幻觉率很高。

Conclusion: 弥合知识综合与可验证归因之间的差距对于AI在科学工作流程中的部署至关重要，需要像CLINB这样可靠、可解释的基准来构建可信赖的AI系统。

Abstract: Evaluating how Large Language Models (LLMs) handle complex, specialized knowledge remains a critical challenge. We address this through the lens of climate change by introducing CLINB, a benchmark that assesses models on open-ended, grounded, multimodal question answering tasks with clear requirements for knowledge quality and evidential support. CLINB relies on a dataset of real users' questions and evaluation rubrics curated by leading climate scientists. We implement and validate a model-based evaluation process and evaluate several frontier models. Our findings reveal a critical dichotomy. Frontier models demonstrate remarkable knowledge synthesis capabilities, often exhibiting PhD-level understanding and presentation quality. They outperform "hybrid" answers curated by domain experts assisted by weaker models. However, this performance is countered by failures in grounding. The quality of evidence varies, with substantial hallucination rates for references and images. We argue that bridging this gap between knowledge synthesis and verifiable attribution is essential for the deployment of AI in scientific workflows and that reliable, interpretable benchmarks like CLINB are needed to progress towards building trustworthy AI systems.

</details>


### [275] [CausalGuard: A Smart System for Detecting and Preventing False Information in Large Language Models](https://arxiv.org/abs/2511.11600)
*Piyushkumar Patel*

Main category: cs.AI

TL;DR: CausalGuard是一种结合因果推理和符号逻辑的新方法，用于实时检测和防止大语言模型的幻觉问题，相比现有方法能更早干预生成过程。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在幻觉问题，即自信地陈述听起来合理但虚假的信息，这成为在准确性至关重要的场景中使用这些模型的主要障碍。现有解决方案要么需要重新训练整个模型，要么增加显著计算成本，或者未能解决幻觉的根本原因。

Method: CausalGuard通过两条互补路径工作：一条追踪模型已知信息与生成内容之间的因果关系，另一条使用自动推理检查逻辑一致性。系统理解导致虚假陈述的因果链，并在生成过程中早期进行干预。

Result: 在12个不同基准测试中，CausalGuard正确识别幻觉的概率为89.3%，仅遗漏8.3%的实际幻觉。更重要的是，它减少了近80%的错误声明，同时保持回答自然和有用。在需要多步逻辑的复杂推理任务上表现尤其出色。

Conclusion: CausalGuard通过展示其推理过程，在医疗诊断或金融分析等敏感领域表现良好，因为这些领域理解决策原因与决策本身同等重要。

Abstract: While large language models have transformed how we interact with AI systems, they have a critical weakness: they confidently state false information that sounds entirely plausible. This "hallucination" problem has become a major barrier to using these models where accuracy matters most. Existing solutions either require retraining the entire model, add significant computational costs, or miss the root causes of why these hallucinations occur in the first place.
  We present CausalGuard, a new approach that combines causal reasoning with symbolic logic to catch and prevent hallucinations as they happen. Unlike previous methods that only check outputs after generation, our system understands the causal chain that leads to false statements and intervenes early in the process. CausalGuard works through two complementary paths: one that traces causal relationships between what the model knows and what it generates, and another that checks logical consistency using automated reasoning.
  Testing across twelve different benchmarks, we found that CausalGuard correctly identifies hallucinations 89.3\% of the time while missing only 8.3\% of actual hallucinations. More importantly, it reduces false claims by nearly 80\% while keeping responses natural and helpful. The system performs especially well on complex reasoning tasks where multiple steps of logic are required. Because CausalGuard shows its reasoning process, it works well in sensitive areas like medical diagnosis or financial analysis where understanding why a decision was made matters as much as the decision itself.

</details>


### [276] [Quantifying Skill and Chance: A Unified Framework for the Geometry of Games](https://arxiv.org/abs/2511.11611)
*David H. Silver*

Main category: cs.AI

TL;DR: 提出了一个量化框架，通过将游戏建模为随机决策树来分离技能和运气成分，定义了技能-运气指数S(G)在[-1,1]范围内，应用于30个游戏揭示了从纯运气到纯技能的连续谱系。


<details>
  <summary>Details</summary>
Motivation: 需要一种系统的方法来量化游戏中技能和运气的相对贡献，以便更好地理解玩家影响力、游戏平衡性和预测稳定性。

Method: 将游戏建模为随机决策树，将游戏结果分解为技能杠杆K和运气杠杆L，定义技能-运气指数S(G) = (K - L)/(K + L)，并引入波动性Sigma来量化连续回合的结果不确定性。

Result: 分析30个游戏显示：硬币投掷S=-1（纯运气），西洋双陆棋S=0，扑克S=0.33（中等技能主导），国际象棋S=+1（纯技能）。扑克的K=0.40±0.03，Sigma=0.80。

Conclusion: 该框架可扩展到一般随机决策系统，为玩家影响力比较、游戏平衡性评估和风险分析提供了原则性方法，在游戏设计、AI评估和风险评估中有广泛应用。

Abstract: We introduce a quantitative framework for separating skill and chance in games by modeling them as complementary sources of control over stochastic decision trees. We define the Skill-Luck Index S(G) in [-1, 1] by decomposing game outcomes into skill leverage K and luck leverage L. Applying this to 30 games reveals a continuum from pure chance (coin toss, S = -1) through mixed domains such as backgammon (S = 0, Sigma = 1.20) to pure skill (chess, S = +1, Sigma = 0). Poker exhibits moderate skill dominance (S = 0.33) with K = 0.40 +/- 0.03 and Sigma = 0.80. We further introduce volatility Sigma to quantify outcome uncertainty over successive turns. The framework extends to general stochastic decision systems, enabling principled comparisons of player influence, game balance, and predictive stability, with applications to game design, AI evaluation, and risk assessment.

</details>


### [277] [Learning to Refine: An Agentic RL Approach for Iterative SPARQL Query Construction](https://arxiv.org/abs/2511.11770)
*Floris Vossebeld,Shenghui Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习的智能体框架，用于迭代构建SPARQL查询，解决知识图谱问答中多跳问题的复杂查询生成难题。


<details>
  <summary>Details</summary>
Motivation: 当前方法缺乏基于实时执行反馈动态调试查询的自适应策略，大型语言模型的一次性生成方式在与结构化数据交互时存在脆弱性问题。

Method: 采用结果驱动的强化学习（GRPO）训练3B参数模型，无需监督微调，学习迭代SPARQL构建的弹性策略，通过执行错误恢复和查询精炼实现系统改进。

Result: 在LC-QuAD 2.0的可执行子集上，实体链接后准确率达到49.7%，比最强的迭代零样本基线提高了17.5个百分点。

Conclusion: 该工作为通过交互教授智能体掌握形式化符号工具提供了可推广的蓝图，弥合了概率性LLM与结构化知识图谱世界之间的差距。

Abstract: Generating complex, logically-sound SPARQL queries for multi-hop questions remains a critical bottleneck for Knowledge Graph Question Answering, as the brittle nature of one-shot generation by Large Language Models (LLMs) hinders reliable interaction with structured data. Current methods lack the adaptive policies needed to dynamically debug queries based on real-time execution feedback. This paper introduces a novel agentic framework where an LLM learns a resilient policy for the sequential process of iterative SPARQL construction. We show that a compact 3B-parameter model, trained exclusively via outcome-driven Reinforcement Learning (GRPO) without supervised fine-tuning, can learn effective policies for this task, discovering how to systematically recover from execution errors and refine its queries toward a correct answer. On a curated, executable single-answer subset of LC-QuAD 2.0, our agent achieves 49.7\% accuracy post-entity-linking, a significant 17.5 percentage point improvement over the strongest iterative zero-shot baseline. Further analysis reveals that while the agent's capability is driven by RL, its performance is enhanced by an explicit deliberative reasoning step that acts as a cognitive scaffold to improve policy precision. This work presents a generalizable blueprint for teaching agents to master formal, symbolic tools through interaction, bridging the gap between probabilistic LLMs and the structured world of Knowledge Graphs.

</details>


### [278] [On the Measure of a Model: From Intelligence to Generality](https://arxiv.org/abs/2511.11773)
*Ruchira Dhar,Ninell Oldenburg,Anders Soegaard*

Main category: cs.AI

TL;DR: 论文质疑当前基于抽象智力概念（如ARC、Raven测试）的AI评估方法，认为这些基准与真实世界任务表现脱节。作者提出应以泛化性（generality）而非智力作为评估基础，将泛化性重新定义为多任务学习问题，直接关联到可测量的性能广度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估过度依赖抽象智力概念，缺乏稳定定义且无法预测实际任务表现。优化这些基准可能导致评估与现实效用脱节，需要更可靠的评估基础。

Method: 通过概念性和形式化分析，检验智力评估的三个假设（泛化性、稳定性、现实性），证明只有泛化性经得起概念和实证检验。将泛化性重新定义为多任务学习问题。

Result: 分析表明智力概念在评估中不稳定，而泛化性提供了更可靠的评估基础。泛化性直接关联到性能广度和可靠性，能够更好地预测AI在多样化任务上的表现。

Conclusion: 应基于泛化性而非抽象智力来评估AI进展，这为评估多样化任务上的能力提供了更稳定的基础，使评估更贴近实际效用。

Abstract: Benchmarks such as ARC, Raven-inspired tests, and the Blackbird Task are widely used to evaluate the intelligence of large language models (LLMs). Yet, the concept of intelligence remains elusive- lacking a stable definition and failing to predict performance on practical tasks such as question answering, summarization, or coding. Optimizing for such benchmarks risks misaligning evaluation with real-world utility. Our perspective is that evaluation should be grounded in generality rather than abstract notions of intelligence. We identify three assumptions that often underpin intelligence-focused evaluation: generality, stability, and realism. Through conceptual and formal analysis, we show that only generality withstands conceptual and empirical scrutiny. Intelligence is not what enables generality; generality is best understood as a multitask learning problem that directly links evaluation to measurable performance breadth and reliability. This perspective reframes how progress in AI should be assessed and proposes generality as a more stable foundation for evaluating capability across diverse and evolving tasks.

</details>


### [279] [Do LLMs Really Struggle at NL-FOL Translation? Revealing their Strengths via a Novel Benchmarking Strategy](https://arxiv.org/abs/2511.11816)
*Andrea Brunello,Luca Geatti,Michele Mignani,Angelo Montanari,Nicola Saccomanno*

Main category: cs.AI

TL;DR: 本文批判性地评估了现有NL-FOL翻译数据集和评估协议的局限性，提出了新的评估方法来区分真正的语义级逻辑理解与表面模式识别，并发现对话导向的LLMs在NL-FOL翻译方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 自然语言到一阶逻辑的翻译是一个长期挑战，虽然LLMs的出现带来了希望，但现有评估方法存在局限性，可能无法准确反映LLMs的实际能力。

Method: 批判性分析现有数据集和评估协议，提出新的评估协议来区分语义级逻辑理解与表面模式识别、记忆和数据集污染。

Result: 使用新评估方法发现，最先进的对话导向LLMs展现出强大的NL-FOL翻译能力和真正的句子级逻辑理解能力，而嵌入中心模型表现明显较差。

Conclusion: 通过适当的评估方法，对话导向的LLMs确实具备优秀的NL-FOL翻译能力，这为自然语言逻辑理解的实际应用提供了支持。

Abstract: Due to its expressiveness and unambiguous nature, First-Order Logic (FOL) is a powerful formalism for representing concepts expressed in natural language (NL). This is useful, e.g., for specifying and verifying desired system properties. While translating FOL into human-readable English is relatively straightforward, the inverse problem, converting NL to FOL (NL-FOL translation), has remained a longstanding challenge, for both humans and machines. Although the emergence of Large Language Models (LLMs) promised a breakthrough, recent literature provides contrasting results on their ability to perform NL-FOL translation. In this work, we provide a threefold contribution. First, we critically examine existing datasets and protocols for evaluating NL-FOL translation performance, revealing key limitations that may cause a misrepresentation of LLMs' actual capabilities. Second, to overcome these shortcomings, we propose a novel evaluation protocol explicitly designed to distinguish genuine semantic-level logical understanding from superficial pattern recognition, memorization, and dataset contamination. Third, using this new approach, we show that state-of-the-art, dialogue-oriented LLMs demonstrate strong NL-FOL translation skills and a genuine grasp of sentence-level logic, whereas embedding-centric models perform markedly worse.

</details>


### [280] [TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models](https://arxiv.org/abs/2511.11831)
*Wenhao Zhou,Hao Zheng,Rong Zhao*

Main category: cs.AI

TL;DR: TopoPerception是一个基于拓扑属性的基准测试，用于严格评估大型视觉语言模型的全局视觉感知能力，发现现有模型在全局感知方面表现不佳，甚至不如随机猜测。


<details>
  <summary>Details</summary>
Motivation: 传统评估基准存在局部捷径问题，可能高估模型的感知能力。为了准确评估LVLMs的全局视觉感知能力，需要一种不受局部特征影响的评估方法。

Method: 利用拓扑属性构建评估基准，因为拓扑依赖于图像的全局结构且对局部特征不变性，从而实现对全局感知的无捷径评估。

Result: 在最粗的感知粒度上，所有模型的表现都不优于随机机会，表明它们严重缺乏全局视觉特征感知能力。更强大的模型反而表现出更低的准确率。

Conclusion: 仅扩大模型规模不足以解决全局感知缺陷，可能需要新的训练范式或架构。TopoPerception揭示了当前LVLMs的关键瓶颈，并为改进提供了方向。

Abstract: Large Vision-Language Models (LVLMs) typically align visual features from an encoder with a pre-trained Large Language Model (LLM). However, this makes the visual perception module a bottleneck, which constrains the overall capabilities of LVLMs. Conventional evaluation benchmarks, while rich in visual semantics, often contain unavoidable local shortcuts that can lead to an overestimation of models' perceptual abilities. Here, we introduce TopoPerception, a benchmark that leverages topological properties to rigorously evaluate the global visual perception capabilities of LVLMs across various granularities. Since topology depends on the global structure of an image and is invariant to local features, TopoPerception enables a shortcut-free assessment of global perception, fundamentally distinguishing it from semantically rich tasks. We evaluate state-of-the-art models on TopoPerception and find that even at the coarsest perceptual granularity, all models perform no better than random chance, indicating a profound inability to perceive global visual features. Notably, a consistent trend emerge within model families: more powerful models with stronger reasoning capabilities exhibit lower accuracy. This suggests that merely scaling up models is insufficient to address this deficit and may even exacerbate it. Progress may require new training paradigms or architectures. TopoPerception not only exposes a critical bottleneck in current LVLMs but also offers a lens and direction for improving their global visual perception. The data and code are publicly available at: https://github.com/Wenhao-Zhou/TopoPerception.

</details>


### [281] [End to End AI System for Surgical Gesture Sequence Recognition and Clinical Outcome Prediction](https://arxiv.org/abs/2511.11899)
*Xi Li,Nicholas Matsumoto,Ujjwal Pasupulety,Atharva Deo,Cherine Yang,Jay Moran,Miguel E. Hernandez,Peter Wager,Jasmine Lin,Jeanine Kim,Alvin C. Goh,Christian Wagner,Geoffrey A. Sonn,Andrew J. Hung*

Main category: cs.AI

TL;DR: F2O是一个端到端系统，可将组织解剖视频转化为手势序列，并发现与术后结果相关的模式。该系统使用基于transformer的空间和时间建模，在机器人辅助根治性前列腺切除术中检测连续短手势，并能预测术后结果，准确性与人工标注相当。


<details>
  <summary>Details</summary>
Motivation: 精细分析术中行为及其对患者结果的影响是一个长期挑战。需要开发能够自动将手术视频转化为可解释评估的系统，为数据驱动的手术反馈和临床决策支持奠定基础。

Method: 采用基于transformer的空间和时间建模以及逐帧分类方法，在机器人辅助根治性前列腺切除术的神经保留步骤中检测连续短手势（约2秒）。从手势序列中提取特征（手势频率、持续时间和转换）。

Result: F2O在帧级和视频级的手势检测AUC分别达到0.80和0.81。使用F2O提取的特征预测术后结果的准确性（0.79）与人工标注（0.75）相当，效应大小方向一致，相关性强（r=0.96）。系统还捕获了与勃起功能恢复相关的关键模式。

Conclusion: F2O通过实现自动可解释评估，为数据驱动的手术反馈和前瞻性临床决策支持建立了基础，能够发现与患者结果相关的术中行为模式。

Abstract: Fine-grained analysis of intraoperative behavior and its impact on patient outcomes remain a longstanding challenge. We present Frame-to-Outcome (F2O), an end-to-end system that translates tissue dissection videos into gesture sequences and uncovers patterns associated with postoperative outcomes. Leveraging transformer-based spatial and temporal modeling and frame-wise classification, F2O robustly detects consecutive short (~2 seconds) gestures in the nerve-sparing step of robot-assisted radical prostatectomy (AUC: 0.80 frame-level; 0.81 video-level). F2O-derived features (gesture frequency, duration, and transitions) predicted postoperative outcomes with accuracy comparable to human annotations (0.79 vs. 0.75; overlapping 95% CI). Across 25 shared features, effect size directions were concordant with small differences (~ 0.07), and strong correlation (r = 0.96, p < 1e-14). F2O also captured key patterns linked to erectile function recovery, including prolonged tissue peeling and reduced energy use. By enabling automatic interpretable assessment, F2O establishes a foundation for data-driven surgical feedback and prospective clinical decision support.

</details>


### [282] [Forgetting-MarI: LLM Unlearning via Marginal Information Regularization](https://arxiv.org/abs/2511.11914)
*Shizhou Xu,Yuan Ni,Stefan Broecker,Thomas Strohmer*

Main category: cs.AI

TL;DR: Forgetting-MarI是一个LLM遗忘框架，通过惩罚边际信息来选择性移除待遗忘数据的参数知识，同时保留待保留数据的信息，提供可证明的不可检测性。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型在不断扩大数据集上训练，需要从训练模型中移除特定数据影响以满足隐私保护和法规合规要求。遗忘方法通过选择性移除参数知识避免从头重新训练，这对资源密集型模型如LLM至关重要。

Method: 引入Forgetting-MarI LLM遗忘框架，通过惩罚边际信息来仅移除待遗忘数据贡献的额外信息，同时保留待保留数据支持的信息。该方法提供了对未学习数据集在训练模型中残余影响的明确上界。

Result: 广泛实验证实该方法优于当前最先进的遗忘方法，在多样化基准测试中实现了可靠的遗忘和更好的通用模型性能保留。

Conclusion: 这一进展代表了使AI系统更可控、更符合隐私和版权法规而不损害其有效性的重要一步。

Abstract: As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance. Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs). Existing unlearning methods often degrade model performance by removing more information than necessary when attempting to ''forget'' specific data. We introduce Forgetting-MarI, an LLM unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained. By penalizing marginal information, our method yields an explicit upper bound on the unlearn dataset's residual influence in the trained models, providing provable undetectability. Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks. This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness.

</details>


### [283] [Looking Forward: Challenges and Opportunities in Agentic AI Reliability](https://arxiv.org/abs/2511.11921)
*Liudong Xing,Janet,Lin*

Main category: cs.AI

TL;DR: 本章探讨了构建可靠AI系统（特别是智能体AI系统）面临的挑战和未来发展方向，重点讨论了级联故障风险缓解、动态环境、任务执行不一致性、不可预测涌现行为等研究问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统特别是智能体AI系统的快速发展，确保其可靠性变得至关重要。本章旨在识别和探讨构建可靠AI系统面临的关键挑战和开放研究问题，为未来研究方向提供指导。

Method: 通过分析当前AI系统可靠性领域的研究现状，识别出多个关键挑战领域，包括级联故障、动态环境适应性、任务执行一致性、涌现行为预测等，并提出相应的研究方向和机会。

Result: 识别了构建可靠AI系统的多个关键挑战领域，包括级联故障风险缓解、动态环境处理、任务执行不一致性、不可预测涌现行为以及资源密集型可靠性机制等研究问题。

Conclusion: 构建可靠的智能体AI系统面临多方面挑战，需要在级联故障缓解、环境适应性、行为预测和测试评估等方面进行深入研究，这些研究方向对于推动AI系统的安全可靠应用具有重要意义。

Abstract: This chapter presents perspectives for challenges and future development in building reliable AI systems, particularly, agentic AI systems. Several open research problems related to mitigating the risks of cascading failures are discussed. The chapter also sheds lights on research challenges and opportunities in aspects including dynamic environments, inconsistent task execution, unpredictable emergent behaviors, as well as resource-intensive reliability mechanisms. In addition, several research directions along the line of testing and evaluating reliability of agentic AI systems are also discussed.

</details>


### [284] [A Neuromorphic Architecture for Scalable Event-Based Control](https://arxiv.org/abs/2511.11924)
*Yongkang Huo,Fulvio Forni,Rodolphe Sepulchre*

Main category: cs.AI

TL;DR: 本文提出了一种基于"反弹胜者通吃(RWTA)"基元的新型神经形态控制架构，该架构结合了离散计算的可靠性和连续调节的可调性，能够统一处理连续节律生成和离散决策问题。


<details>
  <summary>Details</summary>
Motivation: 开发一种可扩展的神经形态控制架构，既能继承胜者通吃状态机的离散计算能力，又能保持可兴奋生物物理电路的连续调节特性，以解决连续节律生成和离散决策的统一建模问题。

Method: 提出了"反弹胜者通吃(RWTA)"基元作为基本构建模块，构建从细胞级到系统级的层次化架构，结合离散计算和连续调节能力，采用基于事件的建模框架。

Result: 该架构在蛇形机器人神经系统设计中展现出良好的多功能性、鲁棒性和模块化特性，能够有效处理连续节律生成和离散决策任务。

Conclusion: RWTA架构为神经形态控制系统提供了一种统一的物理建模语言，成功结合了离散计算的可靠性和连续调节的可调性，在机器人控制应用中具有良好前景。

Abstract: This paper introduces the ``rebound Winner-Take-All (RWTA)" motif as the basic element of a scalable neuromorphic control architecture. From the cellular level to the system level, the resulting architecture combines the reliability of discrete computation and the tunability of continuous regulation: it inherits the discrete computation capabilities of winner-take-all state machines and the continuous tuning capabilities of excitable biophysical circuits. The proposed event-based framework addresses continuous rhythmic generation and discrete decision-making in a unified physical modeling language. We illustrate the versatility, robustness, and modularity of the architecture through the nervous system design of a snake robot.

</details>


### [285] [LLM-Assisted Formalization Enables Deterministic Detection of Statutory Inconsistency in the Internal Revenue Code](https://arxiv.org/abs/2511.11954)
*Borchuluun Yadamsuren,Steven Keith Platt,Miguel Diaz*

Main category: cs.AI

TL;DR: 本研究提出了一个混合神经符号框架，用于确定性检测复杂法律中的法定不一致性。以美国国内税收法典为案例，结合大型语言模型和符号逻辑，成功检测到不一致条款。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在税务领域应用稀少，且在处理层次化处理和深度结构化推理方面存在困难，特别是在长文本上。需要解决这些限制以实现可靠的法定不一致性检测。

Method: 使用GPT-4o将税法条款翻译为Prolog规则，在SWISH中精炼，然后测试Prolog增强提示是否能改进GPT-4o的不一致性检测。同时开发混合Prolog模型，由GPT-5指导精炼。

Result: GPT-4o在三种策略中仅检测到一种不一致性（33%准确率）。纯自然语言提示实现100%规则覆盖，Prolog增强提示仅66%覆盖。混合Prolog模型产生确定性、可重现结果，成功检测到不一致区域。

Conclusion: 基于符号逻辑的LLM辅助形式化能够实现透明可靠的法定不一致性检测，混合方法优于纯概率性提示方法。

Abstract: This study introduces a hybrid neuro-symbolic framework that achieves deterministic detection of statutory inconsistency in complex law. We use the U.S. Internal Revenue Code (IRC) as a case study because its complexity makes it a fertile domain for identifying conflicts. Our research offers a solution for detecting inconsistent provisions by combining Large Language Models (LLMs) with symbolic logic.
  LLM-based methods can support compliance, fairness, and statutory drafting, yet tax-specific applications remain sparse. A key challenge is that such models struggle with hierarchical processing and deep structured reasoning, especially over long text.
  This research addresses these gaps through experiments using GPT-4o, GPT-5, and Prolog. GPT-4o was first used to translate Section 121 into Prolog rules and refine them in SWISH. These rules were then incorporated into prompts to test whether Prolog-augmented prompting improved GPT-4o's inconsistency detection. GPT-4o, whether prompted with natural language alone or with Prolog augmentation, detected the inconsistency in only one of three strategies (33 percent accuracy), but its reasoning quality differed: natural-language prompting achieved 100 percent rule coverage, while Prolog-augmented prompting achieved 66 percent, indicating more incomplete statutory analysis.
  In contrast to probabilistic prompting, the hybrid Prolog model produced deterministic and reproducible results. Guided by GPT-5 for refinement, the model formalized the IRC section's competing interpretations and successfully detected an inconsistency zone. Validation tests confirm that the Prolog implementation is accurate, internally consistent, deterministic, and capable of autonomously identifying inconsistencies. These findings show that LLM-assisted formalization, anchored in symbolic logic, enables transparent and reliable statutory inconsistency detection.

</details>


### [286] [Improving Autoformalization Using Direct Dependency Retrieval](https://arxiv.org/abs/2511.11990)
*Shaoqi Wang,Lu Yu,Chunjie Yang*

Main category: cs.AI

TL;DR: 本文提出了一种基于直接依赖检索(DDR)的新框架，用于解决数学陈述自动形式化中的上下文感知不足和形式库依赖检索精度低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动形式化方法缺乏上下文感知，导致形式定义和定理的幻觉，且检索增强方法在形式库依赖检索方面精度和召回率较差，无法有效利用不断增长的公共数据集。

Method: 提出DDR方法，直接从自然语言数学描述生成候选库依赖，并通过高效的后缀数组检查验证其在形式库中的存在性，构建了超过50万样本的依赖检索数据集并微调高精度DDR模型。

Result: 实验结果表明，DDR模型在检索精度和召回率上显著优于现有最优方法，配备DDR的自动形式化器在单次尝试准确率和多次尝试稳定性方面均表现出持续优势。

Conclusion: DDR框架通过高效的依赖检索机制有效解决了自动形式化中的关键挑战，为深度学习和形式数学的融合提供了可靠的技术支持。

Abstract: The convergence of deep learning and formal mathematics has spurred research in formal verification. Statement autoformalization, a crucial first step in this process, aims to translate informal descriptions into machine-verifiable representations but remains a significant challenge. The core difficulty lies in the fact that existing methods often suffer from a lack of contextual awareness, leading to hallucination of formal definitions and theorems. Furthermore, current retrieval-augmented approaches exhibit poor precision and recall for formal library dependency retrieval, and lack the scalability to effectively leverage ever-growing public datasets. To bridge this gap, we propose a novel retrieval-augmented framework based on DDR (\textit{Direct Dependency Retrieval}) for statement autoformalization. Our DDR method directly generates candidate library dependencies from natural language mathematical descriptions and subsequently verifies their existence within the formal library via an efficient suffix array check. Leveraging this efficient search mechanism, we constructed a dependency retrieval dataset of over 500,000 samples and fine-tuned a high-precision DDR model. Experimental results demonstrate that our DDR model significantly outperforms SOTA methods in both retrieval precision and recall. Consequently, an autoformalizer equipped with DDR shows consistent performance advantages in both single-attempt accuracy and multi-attempt stability compared to models using traditional selection-based RAG methods.

</details>


### [287] [Look As You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning](https://arxiv.org/abs/2511.12003)
*Shuochen Liu,Pengfei Luo,Chao Zhang,Yuhao Chen,Haotian Zhang,Qi Liu,Xin Kou,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: 本文提出了Chain-of-Evidence (CoE)范式，通过将推理步骤中的参考元素与边界框和页面索引关联，统一了思维链推理和视觉证据归因。同时开发了Look As You Think (LAT)强化学习框架，训练模型生成可验证的推理路径。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏细粒度监督和推理过程中的渐进可追溯性，无法确保视觉文档检索增强生成的可信度和可验证性。

Method: 提出CoE范式统一思维链推理和视觉证据归因，开发LAT强化学习框架评估证据区域的一致性，仅在CoE轨迹产生正确答案时提供奖励，鼓励过程级自验证。

Result: 在Paper-和Wiki-VISA基准测试中，LAT在单图和双图设置下均提升了原始模型性能，平均软精确匹配提升8.23%，IoU@0.5提升47.0%，且优于监督微调基线，具有更强的跨领域泛化能力。

Conclusion: CoE和LAT框架有效提升了视觉文档检索增强生成的可验证性和可靠性，通过过程级自验证实现了更好的证据归因和跨领域泛化。

Abstract: Aiming to identify precise evidence sources from visual documents, visual evidence attribution for visual document retrieval-augmented generation (VD-RAG) ensures reliable and verifiable predictions from vision-language models (VLMs) in multimodal question answering. Most existing methods adopt end-to-end training to facilitate intuitive answer verification. However, they lack fine-grained supervision and progressive traceability throughout the reasoning process. In this paper, we introduce the Chain-of-Evidence (CoE) paradigm for VD-RAG. CoE unifies Chain-of-Thought (CoT) reasoning and visual evidence attribution by grounding reference elements in reasoning steps to specific regions with bounding boxes and page indexes. To enable VLMs to generate such evidence-grounded reasoning, we propose Look As You Think (LAT), a reinforcement learning framework that trains models to produce verifiable reasoning paths with consistent attribution. During training, LAT evaluates the attribution consistency of each evidence region and provides rewards only when the CoE trajectory yields correct answers, encouraging process-level self-verification. Experiments on vanilla Qwen2.5-VL-7B-Instruct with Paper- and Wiki-VISA benchmarks show that LAT consistently improves the vanilla model in both single- and multi-image settings, yielding average gains of 8.23% in soft exact match (EM) and 47.0% in IoU@0.5. Meanwhile, LAT not only outperforms the supervised fine-tuning baseline, which is trained to directly produce answers with attribution, but also exhibits stronger generalization across domains.

</details>


### [288] [Adaptive Diagnostic Reasoning Framework for Pathology with Multimodal Large Language Models](https://arxiv.org/abs/2511.12008)
*Yunqi Hong,Johnson Kao,Liam Edwards,Nein-Tzu Liu,Chung-Yen Huang,Alex Oliveira-Kowaleski,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.AI

TL;DR: RECAP-PATH是一个可解释的病理AI框架，通过两阶段自学习过程从多模态大语言模型中自主推导诊断标准，无需白盒访问或权重更新即可生成癌症诊断。


<details>
  <summary>Details</summary>
Motivation: 当前病理AI工具虽然提高了筛查效率和标准化量化，但由于缺乏人类可读的推理过程来审计决策和防止错误，采用率仍然有限。

Method: 采用两阶段学习过程：多样化阶段扩展病理学风格的解释，优化阶段为准确性精炼这些解释。该自学习方法只需要小规模标记数据集。

Result: 在乳腺癌和前列腺癌数据集上的评估显示，RECAP-PATH产生了与专家评估一致的理由，并在诊断准确性上显著优于基线方法。

Conclusion: RECAP-PATH通过将视觉理解与推理相结合，提供了临床可信赖的AI，并展示了通向证据关联解释的通用路径。

Abstract: AI tools in pathology have improved screening throughput, standardized quantification, and revealed prognostic patterns that inform treatment. However, adoption remains limited because most systems still lack the human-readable reasoning needed to audit decisions and prevent errors. We present RECAP-PATH, an interpretable framework that establishes a self-learning paradigm, shifting off-the-shelf multimodal large language models from passive pattern recognition to evidence-linked diagnostic reasoning. At its core is a two-phase learning process that autonomously derives diagnostic criteria: diversification expands pathology-style explanations, while optimization refines them for accuracy. This self-learning approach requires only small labeled sets and no white-box access or weight updates to generate cancer diagnoses. Evaluated on breast and prostate datasets, RECAP-PATH produced rationales aligned with expert assessment and delivered substantial gains in diagnostic accuracy over baselines. By uniting visual understanding with reasoning, RECAP-PATH provides clinically trustworthy AI and demonstrates a generalizable path toward evidence-linked interpretation.

</details>


### [289] [Bayesian Optimization in Language Space: An Eval-Efficient AI Self-Improvement Framework](https://arxiv.org/abs/2511.12063)
*Enoch Hyunwook Kang,Hema Yoganarasimhan*

Main category: cs.AI

TL;DR: 本文提出了一种基于文本梯度的贝叶斯优化框架T-BoN BO，用于解决AI自我改进中的评估效率问题，特别是在广告对齐等需要大量人工反馈的应用场景中。


<details>
  <summary>Details</summary>
Motivation: 当前AI自我改进研究主要关注查询效率，但在许多社会应用中，真正的瓶颈是评估成本而非生成成本。例如广告效果评估需要大量人工反馈，成本高昂。

Method: 通过证明Best-of-N选择策略与文本梯度的组合能统计模拟UCB采集函数的梯度行为，提出T-BoN BO框架，将贝叶斯优化扩展到语言领域以实现评估效率优化。

Result: 在自动化广告对齐任务中，T-BoN BO相比现有最先进基线方法表现出更优越的性能，验证了其在评估效率方面的优势。

Conclusion: T-BoN BO为语言空间的贝叶斯优化提供了一个简单有效的框架，特别适用于评估成本高昂的AI自我改进应用场景。

Abstract: Large Language Models (LLMs) have recently enabled self-improving AI, i.e., AI that iteratively generates, evaluates, and refines its own outcomes. Recent studies have shown that self-improving AI focusing on prompt optimization can outperform state-of-the-art reinforcement-learning fine-tuned LLMs. Here, their `performance' is typically measured by query efficiency - the number of LLM-generated solution samples required to meet a certain performance threshold. However, in many societal applications, the primary limitation is not generating new solutions but evaluating them. For instance, evaluating an ad's effectiveness requires significant human feedback, which is far more costly and time-consuming than generating a candidate ad. To optimize for the evaluation efficiency objective, a natural approach is to extend Bayesian Optimization (BO), a framework proven optimal for evaluation efficiency, to the language domain. However, the difficulty of directly estimating suitable acquisition functions in LLMs' minds makes this extension challenging. This paper overcomes this challenge by proving that the combination of the simple and widely used Best-of-N selection strategy and simple textual gradients (i.e., textual edits from a critic model) statistically emulates the behavior of the gradients on the canonical UCB acquisition function, which induces optimal exploration in terms of evaluation efficiency. Based on this result, we propose TextGrad-Best-of-N Bayesian Optimization (T-BoN BO), a simple and eval-efficient language-space Bayesian optimization framework for AI self-improvement. We also empirically validate T-BoN BO by applying it to automated ad alignment tasks for persona distribution, demonstrating its superior performance compared to popular state-of-the-art baselines.

</details>


### [290] [No-Regret Strategy Solving in Imperfect-Information Games via Pre-Trained Embedding](https://arxiv.org/abs/2511.12083)
*Yanchang Fu,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: 本文提出Embedding CFR算法，通过将信息集嵌入到低维连续空间来解决大规模不完全信息扩展式博弈，相比基于聚类的抽象方法能更精确捕捉信息集间的差异和联系，在扑克游戏中实现了更快的可剥削性收敛。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法依赖预训练的离散聚类进行抽象，但硬分类会不可逆地丢失信息集之间的量化细微差异，这些差异对于策略求解至关重要，从而影响求解质量。

Method: 受自然语言处理中词嵌入范式的启发，提出Embedding CFR算法：预训练并将孤立信息集的特征嵌入到相互连接的低维连续空间中，在该嵌入空间中进行遗憾累积和策略更新的策略求解过程。

Result: 在扑克实验表明，在相同空间开销下，Embedding CFR相比基于聚类的抽象算法实现了显著更快的可剥削性收敛。

Conclusion: 这是扑克AI中首个通过低维嵌入预训练信息集抽象进行策略求解的算法，理论分析验证了其减少累积遗憾的能力。

Abstract: High-quality information set abstraction remains a core challenge in solving large-scale imperfect-information extensive-form games (IIEFGs)-such as no-limit Texas Hold'em-where the finite nature of spatial resources hinders strategy solving over the full game. State-of-the-art AI methods rely on pre-trained discrete clustering for abstraction, yet their hard classification irreversibly loses critical information: specifically, the quantifiable subtle differences between information sets-vital for strategy solving-thereby compromising the quality of such solving. Inspired by the word embedding paradigm in natural language processing, this paper proposes the Embedding CFR algorithm, a novel approach for solving strategies in IIEFGs within an embedding space. The algorithm pre-trains and embeds features of isolated information sets into an interconnected low-dimensional continuous space, where the resulting vectors more precisely capture both the distinctions and connections between information sets. Embedding CFR presents a strategy-solving process driven by regret accumulation and strategy updates within this embedding space, with accompanying theoretical analysis verifying its capacity to reduce cumulative regret. Experiments on poker show that with the same spatial overhead, Embedding CFR achieves significantly faster exploitability convergence compared to cluster-based abstraction algorithms, confirming its effectiveness. Furthermore, to our knowledge, it is the first algorithm in poker AI that pre-trains information set abstractions through low-dimensional embedding for strategy solving.

</details>


### [291] [KrwEmd: Revising the Imperfect-Recall Abstraction from Forgetting Everything](https://arxiv.org/abs/2511.12089)
*Yanchang Fu,Qiyue Yin,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: KrwEmd算法通过k-recall winrate特征和earth mover's distance聚类，解决了德州扑克等游戏中手牌抽象过度的问题，显著提升了AI游戏性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模不完全信息游戏中手牌抽象过度的问题，这种问题源于不完美回忆抽象的极端实现，完全丢弃了历史信息，损害了AI性能。

Method: 引入k-recall winrate特征来区分信号观察信息集，利用未来和关键的历史游戏信息；开发KrwEmd算法，使用earth mover's distance测量特征差异来聚类信号观察信息集。

Result: 实验结果表明，与现有算法相比，KrwEmd显著提高了AI游戏性能。

Conclusion: KrwEmd是第一个解决手牌抽象过度问题的实用算法，通过结合历史和未来信息来改进不完全信息游戏中的AI表现。

Abstract: Excessive abstraction is a critical challenge in hand abstraction-a task specific to games like Texas hold'em-when solving large-scale imperfect-information games, as it impairs AI performance. This issue arises from extreme implementations of imperfect-recall abstraction, which entirely discard historical information. This paper presents KrwEmd, the first practical algorithm designed to address this problem. We first introduce the k-recall winrate feature, which not only qualitatively distinguishes signal observation infosets by leveraging both future and, crucially, historical game information, but also quantitatively captures their similarity. We then develop the KrwEmd algorithm, which clusters signal observation infosets using earth mover's distance to measure discrepancies between their features. Experimental results demonstrate that KrwEmd significantly improves AI gameplay performance compared to existing algorithms.

</details>


### [292] [MetaGDPO: Alleviating Catastrophic Forgetting with Metacognitive Knowledge through Group Direct Preference Optimization](https://arxiv.org/abs/2511.12113)
*Lanxue Zhang,Yuqiang Xie,Fang Fang,Fanglong Dong,Rui Liu,Yanan Cao*

Main category: cs.AI

TL;DR: 本文提出了一种解决小模型知识蒸馏中灾难性遗忘问题的综合方案，包括构建包含元认知知识的数据集和引入GDPO训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据集和微调方法在将大语言模型推理能力压缩到小模型时面临灾难性遗忘问题，特别是对于8B以下的小模型，主要原因是数据集忽略训练数据知识与模型固有能力的关系，以及传统训练目标未能约束固有知识保留。

Method: 1. 数据层面：构建包含5K实例的数据集，覆盖多种推理任务并融入元认知知识，基于任务知识和模型固有技能过滤数据；2. 训练层面：提出GDPO（组方向偏好优化）方法，通过参考模型隐式约束优化路径，更适合资源受限场景。

Result: 大量实验表明，该方法显著缓解了灾难性遗忘问题，并提升了小模型的推理性能。

Conclusion: 提出的综合解决方案从数据和训练方法两个角度有效解决了小模型知识蒸馏中的灾难性遗忘问题，实现了更有效的知识迁移和推理能力提升。

Abstract: Large Language Models demonstrate strong reasoning capabilities, which can be effectively compressed into smaller models. However, existing datasets and fine-tuning approaches still face challenges that lead to catastrophic forgetting, particularly for models smaller than 8B. First, most datasets typically ignore the relationship between training data knowledge and the model's inherent abilities, making it difficult to preserve prior knowledge. Second, conventional training objectives often fail to constrain inherent knowledge preservation, which can result in forgetting of previously learned skills. To address these issues, we propose a comprehensive solution that alleviates catastrophic forgetting from both the data and fine-tuning approach perspectives. On the data side, we construct a dataset of 5K instances that covers multiple reasoning tasks and incorporates metacognitive knowledge, making it more tolerant and effective for distillation into smaller models. We annotate the metacognitive knowledge required to solve each question and filter the data based on task knowledge and the model's inherent skills. On the training side, we introduce GDPO (Group Direction Preference Optimization), which is better suited for resource-limited scenarios and can efficiently approximate the performance of GRPO. Guided by the large model and by implicitly constraining the optimization path through a reference model, GDPO enables more effective knowledge transfer from the large model and constrains excessive parameter drift. Extensive experiments demonstrate that our approach significantly alleviates catastrophic forgetting and improves reasoning performance on smaller models.

</details>


### [293] [Incremental Maintenance of DatalogMTL Materialisations](https://arxiv.org/abs/2511.12169)
*Kaiyue Zhao,Dingqi Chen,Shaoyu Wang,Pan Hu*

Main category: cs.AI

TL;DR: 提出了DRedMTL算法，一种用于带边界区间的DatalogMTL的增量推理方法，显著优于重新物化方法


<details>
  <summary>Details</summary>
Motivation: 现有DatalogMTL推理方法不支持高效的动态更新，而现实应用需要频繁数据更新处理

Method: 基于经典DRed算法，设计了专门操作符来处理DatalogMTL物化的周期性表示

Result: 在多个公开数据集上的实验结果显示，DRedMTL通常显著优于重新物化方法，有时快几个数量级

Conclusion: DRedMTL为DatalogMTL提供了高效的增量推理能力，满足现实应用对动态更新的需求

Abstract: DatalogMTL extends the classical Datalog language with metric temporal logic (MTL), enabling expressive reasoning over temporal data. While existing reasoning approaches, such as materialisation based and automata based methods, offer soundness and completeness, they lack support for handling efficient dynamic updates, a crucial requirement for real-world applications that involve frequent data updates. In this work, we propose DRedMTL, an incremental reasoning algorithm for DatalogMTL with bounded intervals. Our algorithm builds upon the classical DRed algorithm, which incrementally updates the materialisation of a Datalog program. Unlike a Datalog materialisation which is in essence a finite set of facts, a DatalogMTL materialisation has to be represented as a finite set of facts plus periodic intervals indicating how the full materialisation can be constructed through unfolding. To cope with this, our algorithm is equipped with specifically designed operators to efficiently handle such periodic representations of DatalogMTL materialisations. We have implemented this approach and tested it on several publicly available datasets. Experimental results show that DRedMTL often significantly outperforms rematerialisation, sometimes by orders of magnitude.

</details>


### [294] [Debate over Mixed-knowledge: A Robust Multi-Agent Framework for Incomplete Knowledge Graph Question Answering](https://arxiv.org/abs/2511.12208)
*Jilong Liu,Pengyang Shao,Wei Qin,Fei Liu,Yonghui Yang,Richang Hong*

Main category: cs.AI

TL;DR: DoM框架通过多智能体辩论机制动态融合结构化知识图谱和非结构化外部知识，解决不完整知识图谱问答问题，并在真实知识更新的数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界知识图谱通常不完整，现有方法无法自适应地融合多源知识，无法充分利用知识的互补优势。

Method: 提出DoM框架，基于多智能体辩论范式，分配专门智能体分别处理知识图谱和外部文本推理，通过迭代交互协调输出，包括问题分解、双智能体证据检索和法官智能体评估聚合。

Result: 在构建的真实知识更新数据集上，DoM持续优于最先进的基线方法。

Conclusion: DoM框架通过知识互补性利用和增强对知识图谱不完整性的鲁棒性，有效解决了不完整知识图谱问答问题。

Abstract: Knowledge Graph Question Answering (KGQA) aims to improve factual accuracy by leveraging structured knowledge. However, real-world Knowledge Graphs (KGs) are often incomplete, leading to the problem of Incomplete KGQA (IKGQA). A common solution is to incorporate external data to fill knowledge gaps, but existing methods lack the capacity to adaptively and contextually fuse multiple sources, failing to fully exploit their complementary strengths. To this end, we propose Debate over Mixed-knowledge (DoM), a novel framework that enables dynamic integration of structured and unstructured knowledge for IKGQA. Built upon the Multi-Agent Debate paradigm, DoM assigns specialized agents to perform inference over knowledge graphs and external texts separately, and coordinates their outputs through iterative interaction. It decomposes the input question into sub-questions, retrieves evidence via dual agents (KG and Retrieval-Augmented Generation, RAG), and employs a judge agent to evaluate and aggregate intermediate answers. This collaboration exploits knowledge complementarity and enhances robustness to KG incompleteness. In addition, existing IKGQA datasets simulate incompleteness by randomly removing triples, failing to capture the irregular and unpredictable nature of real-world knowledge incompleteness. To address this, we introduce a new dataset, Incomplete Knowledge Graph WebQuestions, constructed by leveraging real-world knowledge updates. These updates reflect knowledge beyond the static scope of KGs, yielding a more realistic and challenging benchmark. Through extensive experiments, we show that DoM consistently outperforms state-of-the-art baselines.

</details>


### [295] [ViTE: Virtual Graph Trajectory Expert Router for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2511.12214)
*Ruochen Li,Zhanxing Zhu,Tanqiu Qiao,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: 提出ViTE框架解决行人轨迹预测中的高阶交互建模问题，通过虚拟图建模长距离高阶交互，专家路由器自适应选择交互专家，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在行人轨迹预测中存在基本权衡：层数不足导致感受野受限，层数过多则计算成本过高。需要能够自适应建模显式一跳交互和隐式高阶依赖的有效模型。

Method: 提出ViTE框架，包含两个关键模块：虚拟图引入动态虚拟节点建模长距离高阶交互而无需深层GNN堆叠；专家路由器基于社交上下文使用专家混合设计自适应选择交互专家。

Result: 在三个基准测试（ETH/UCY、NBA和SDD）上的实验表明，该方法持续达到最先进性能，验证了其有效性和实际效率。

Conclusion: ViTE框架通过虚拟图和专家路由器的结合，实现了灵活可扩展的交互模式推理，在行人轨迹预测任务中表现出色，解决了深度GNN架构的权衡问题。

Abstract: Pedestrian trajectory prediction is critical for ensuring safety in autonomous driving, surveillance systems, and urban planning applications. While early approaches primarily focus on one-hop pairwise relationships, recent studies attempt to capture high-order interactions by stacking multiple Graph Neural Network (GNN) layers. However, these approaches face a fundamental trade-off: insufficient layers may lead to under-reaching problems that limit the model's receptive field, while excessive depth can result in prohibitive computational costs. We argue that an effective model should be capable of adaptively modeling both explicit one-hop interactions and implicit high-order dependencies, rather than relying solely on architectural depth. To this end, we propose ViTE (Virtual graph Trajectory Expert router), a novel framework for pedestrian trajectory prediction. ViTE consists of two key modules: a Virtual Graph that introduces dynamic virtual nodes to model long-range and high-order interactions without deep GNN stacks, and an Expert Router that adaptively selects interaction experts based on social context using a Mixture-of-Experts design. This combination enables flexible and scalable reasoning across varying interaction patterns. Experiments on three benchmarks (ETH/UCY, NBA, and SDD) demonstrate that our method consistently achieves state-of-the-art performance, validating both its effectiveness and practical efficiency.

</details>


### [296] [Beyond World Models: Rethinking Understanding in AI Models](https://arxiv.org/abs/2511.12239)
*Tarun Gupta,Danish Pruthi*

Main category: cs.AI

TL;DR: 本文通过哲学案例分析批判性地检验世界模型框架是否充分表征人类水平的理解能力，指出世界模型能力与人类理解之间的显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨AI模型中的世界模型是否能够像人类一样真正理解世界，通过哲学文献中的案例研究来检验世界模型框架的局限性。

Method: 采用哲学科学文献中的案例研究方法，聚焦于世界模型能力与人类理解区分最为明显的特定哲学分析。

Result: 研究发现世界模型框架在表征人类水平理解方面存在局限性，虽然这些案例代表特定的理解观点而非普适定义，但有助于探索世界模型的边界。

Conclusion: 世界模型虽然能够模拟外部世界的某些方面，但可能不足以充分表征人类水平的理解能力，两者之间存在重要差异。

Abstract: World models have garnered substantial interest in the AI community. These are internal representations that simulate aspects of the external world, track entities and states, capture causal relationships, and enable prediction of consequences. This contrasts with representations based solely on statistical correlations. A key motivation behind this research direction is that humans possess such mental world models, and finding evidence of similar representations in AI models might indicate that these models "understand" the world in a human-like way. In this paper, we use case studies from the philosophy of science literature to critically examine whether the world model framework adequately characterizes human-level understanding. We focus on specific philosophical analyses where the distinction between world model capabilities and human understanding is most pronounced. While these represent particular views of understanding rather than universal definitions, they help us explore the limits of world models.

</details>


### [297] [AURA: Development and Validation of an Augmented Unplanned Removal Alert System using Synthetic ICU Videos](https://arxiv.org/abs/2511.12241)
*Junhyuk Seo,Hyeyoon Moon,Kyu-Hwan Jung,Namkee Oh,Taerim Kim*

Main category: cs.AI

TL;DR: AURA是一个基于视觉的风险检测系统，使用完全合成的ICU视频数据集开发，通过姿态估计检测患者手部进入气管插管附近区域（碰撞）和关键点速度（躁动）两种高风险运动模式，实现隐私保护的实时非计划拔管检测。


<details>
  <summary>Details</summary>
Motivation: ICU中非计划拔管是严重的安全问题，但由于伦理和隐私问题难以获取标注的ICU视频数据，限制了实时检测技术的发展。

Method: 利用文本到视频扩散技术生成多样化的临床真实ICU场景，应用姿态估计识别两种高风险模式：手部进入气管插管附近区域的碰撞行为，以及通过跟踪解剖关键点速度量化的躁动行为。

Result: 专家评估确认合成数据的真实性，性能评估显示碰撞检测准确率高，躁动识别性能中等。

Conclusion: 这项工作展示了一种开发隐私保护、可复现的患者安全监控系统的新途径，具有在重症监护环境中部署的潜力。

Abstract: Unplanned extubation (UE) remains a critical patient safety concern in intensive care units (ICUs), often leading to severe complications or death. Real-time UE detection has been limited, largely due to the ethical and privacy challenges of obtaining annotated ICU video data. We propose Augmented Unplanned Removal Alert (AURA), a vision-based risk detection system developed and validated entirely on a fully synthetic video dataset. By leveraging text-to-video diffusion, we generated diverse and clinically realistic ICU scenarios capturing a range of patient behaviors and care contexts. The system applies pose estimation to identify two high-risk movement patterns: collision, defined as hand entry into spatial zones near airway tubes, and agitation, quantified by the velocity of tracked anatomical keypoints. Expert assessments confirmed the realism of the synthetic data, and performance evaluations showed high accuracy for collision detection and moderate performance for agitation recognition. This work demonstrates a novel pathway for developing privacy-preserving, reproducible patient safety monitoring systems with potential for deployment in intensive care settings.

</details>


### [298] [Reward and Guidance through Rubrics: Promoting Exploration to Improve Multi-Domain Reasoning](https://arxiv.org/abs/2511.12344)
*Baolong Bi,Shenghua Liu,Yiwei Wang,Siqian Tong,Lingrui Mei,Yuyao Ge,Yilong Xu,Jiafeng Guo,Xueqi Cheng*

Main category: cs.AI

TL;DR: RGR-GRPO是一个基于评分标准的强化学习框架，通过提供细粒度奖励信号和离线指导，在多领域推理任务中显著提升大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要关注单一领域且依赖可验证奖励，纯在线RL框架限制了探索空间，从而限制了推理性能。

Method: 提出RGR-GRPO框架，利用评分标准提供密集信息奖励，在GRPO训练期间探索更大的解决方案空间。

Result: 在14个多领域基准测试中，RGR-GRPO持续优于仅依赖替代奖励方案或离线指导的RL方法。相比可验证在线RL基线，在数学、物理、化学和通用推理任务上分别平均提升+7.0%、+5.4%、+8.4%和+6.6%。

Conclusion: RGR-GRPO在离策略训练期间保持稳定的熵波动，实现卓越的pass@k性能，反映了持续探索和有效突破现有性能瓶颈的能力。

Abstract: Recent advances in reinforcement learning (RL) have significantly improved the complex reasoning capabilities of large language models (LLMs). Despite these successes, existing methods mainly focus on single-domain RL (e.g., mathematics) with verifiable rewards (RLVR), and their reliance on purely online RL frameworks restricts the exploration space, thereby limiting reasoning performance. In this paper, we address these limitations by leveraging rubrics to provide both fine-grained reward signals and offline guidance. We propose $\textbf{RGR-GRPO}$ (Reward and Guidance through Rubrics), a rubric-driven RL framework for multi-domain reasoning. RGR-GRPO enables LLMs to receive dense and informative rewards while exploring a larger solution space during GRPO training. Extensive experiments across 14 benchmarks spanning multiple domains demonstrate that RGR-GRPO consistently outperforms RL methods that rely solely on alternative reward schemes or offline guidance. Compared with verifiable online RL baseline, RGR-GRPO achieves average improvements of +7.0%, +5.4%, +8.4%, and +6.6% on mathematics, physics, chemistry, and general reasoning tasks, respectively. Notably, RGR-GRPO maintains stable entropy fluctuations during off-policy training and achieves superior pass@k performance, reflecting sustained exploration and effective breakthrough beyond existing performance bottlenecks.

</details>


### [299] [Learning to Trust: Bayesian Adaptation to Varying Suggester Reliability in Sequential Decision Making](https://arxiv.org/abs/2511.12378)
*Dylan M. Asmar,Mykel J. Kochenderfer*

Main category: cs.AI

TL;DR: 本文提出了一个在部分可观测环境中动态学习和适应不同建议者可靠性的框架，通过将建议者质量整合到智能体信念表示中，并使用显式的“询问”动作来策略性地请求建议。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设建议者的质量参数是静态且已知的，这限制了实际部署。自主智能体在不确定环境中的顺序决策任务可以从外部行动建议中受益，但这些建议的可靠性各不相同。

Method: 1. 将建议者质量直接整合到智能体的信念表示中，通过贝叶斯推理推断建议者类型；2. 引入显式的“询问”动作，让智能体在关键时刻策略性地请求建议，平衡信息获取与成本。

Result: 实验评估表明，该框架在不同建议者质量下表现稳健，能够适应变化的可靠性，并策略性地管理建议请求。

Conclusion: 这项工作通过解决不确定环境中的建议不确定性，为自适应人机协作提供了基础。

Abstract: Autonomous agents operating in sequential decision-making tasks under uncertainty can benefit from external action suggestions, which provide valuable guidance but inherently vary in reliability. Existing methods for incorporating such advice typically assume static and known suggester quality parameters, limiting practical deployment. We introduce a framework that dynamically learns and adapts to varying suggester reliability in partially observable environments. First, we integrate suggester quality directly into the agent's belief representation, enabling agents to infer and adjust their reliance on suggestions through Bayesian inference over suggester types. Second, we introduce an explicit ``ask'' action allowing agents to strategically request suggestions at critical moments, balancing informational gains against acquisition costs. Experimental evaluation demonstrates robust performance across varying suggester qualities, adaptation to changing reliability, and strategic management of suggestion requests. This work provides a foundation for adaptive human-agent collaboration by addressing suggestion uncertainty in uncertain environments.

</details>


### [300] [Multi-agent Self-triage System with Medical Flowcharts](https://arxiv.org/abs/2511.12439)
*Yujia Liu,Sophia Yu,Hongyue Jin,Jessica Wen,Alexander Qian,Terrence Lee,Mattheus Ramsis,Gi Won Choi,Lianhui Qin,Xin Liu,Edward J. Wang*

Main category: cs.AI

TL;DR: 开发了一个基于临床验证流程图的对话式自我分诊系统，通过多智能体框架实现95.29%的流程图检索准确率和99.10%的导航准确率，结合自由文本交互的灵活性和标准化临床协议的严谨性。


<details>
  <summary>Details</summary>
Motivation: 在线健康资源和大型语言模型在医疗决策中的可靠性受到准确性低、缺乏透明度和易受未经验证信息影响的限制，需要开发更可靠的AI辅助自我分诊系统。

Method: 引入基于美国医学会100个临床验证流程图的对话式自我分诊系统，采用检索智能体、决策智能体和聊天智能体的多智能体框架，通过合成数据集进行大规模性能评估。

Result: 系统在流程图检索方面达到95.29%的top-3准确率（N=2,000），在流程图导航方面达到99.10%的准确率（N=37,200），适用于不同对话风格和条件。

Conclusion: 该方法展示了透明、准确且可推广的AI辅助自我分诊的可行性，有潜力支持知情患者决策并改善医疗资源利用。

Abstract: Online health resources and large language models (LLMs) are increasingly used as a first point of contact for medical decision-making, yet their reliability in healthcare remains limited by low accuracy, lack of transparency, and susceptibility to unverified information. We introduce a proof-of-concept conversational self-triage system that guides LLMs with 100 clinically validated flowcharts from the American Medical Association, providing a structured and auditable framework for patient decision support. The system leverages a multi-agent framework consisting of a retrieval agent, a decision agent, and a chat agent to identify the most relevant flowchart, interpret patient responses, and deliver personalized, patient-friendly recommendations, respectively. Performance was evaluated at scale using synthetic datasets of simulated conversations. The system achieved 95.29% top-3 accuracy in flowchart retrieval (N=2,000) and 99.10% accuracy in flowchart navigation across varied conversational styles and conditions (N=37,200). By combining the flexibility of free-text interaction with the rigor of standardized clinical protocols, this approach demonstrates the feasibility of transparent, accurate, and generalizable AI-assisted self-triage, with potential to support informed patient decision-making while improving healthcare resource utilization.

</details>


### [301] [ARCHE: A Novel Task to Evaluate LLMs on Latent Reasoning Chain Extraction](https://arxiv.org/abs/2511.12485)
*Pengze Li,Jiaqi Liu,Junchi Yu,Lihao Liu,Mingyu Ding,Wanli Ouyang,Shixiang Tang,Xi Chen*

Main category: cs.AI

TL;DR: 提出ARCHE任务，要求模型将复杂推理分解为标准推理范式的逻辑树，并发布ARCHE Bench基准数据集，评估显示当前LLMs在科学推理方面存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在科学领域使用时产生的非结构化、非正式推理内容，难以判断模型是否真正理解科学推理基本范式的问题。

Method: 引入潜在推理链提取任务(ARCHE)，要求模型将复杂推理分解为推理逻辑树(RLT)，其中所有推理步骤明确分类为演绎、归纳或溯因三种基本推理模式。

Result: 在ARCHE Bench基准上评估10个领先LLMs，发现模型在推理边准确性和实体覆盖率之间存在权衡，没有模型能够提取完整且标准的推理链。

Conclusion: 当前推理模型的能力与科学论证所需的严谨性之间存在显著差距，需要进一步改进模型对基本推理范式的理解。

Abstract: Large language models (LLMs) are increasingly used in scientific domains. While they can produce reasoning-like content via methods such as chain-of-thought prompting, these outputs are typically unstructured and informal, obscuring whether models truly understand the fundamental reasoning paradigms that underpin scientific inference. To address this, we introduce a novel task named Latent Reasoning Chain Extraction (ARCHE), in which models must decompose complex reasoning arguments into combinations of standard reasoning paradigms in the form of a Reasoning Logic Tree (RLT). In RLT, all reasoning steps are explicitly categorized as one of three variants of Peirce's fundamental inference modes: deduction, induction, or abduction. To facilitate this task, we release ARCHE Bench, a new benchmark derived from 70 Nature Communications articles, including more than 1,900 references and 38,000 viewpoints. We propose two logic-aware evaluation metrics: Entity Coverage (EC) for content completeness and Reasoning Edge Accuracy (REA) for step-by-step logical validity. Evaluations on 10 leading LLMs on ARCHE Bench reveal that models exhibit a trade-off between REA and EC, and none are yet able to extract a complete and standard reasoning chain. These findings highlight a substantial gap between the abilities of current reasoning models and the rigor required for scientific argumentation.

</details>


### [302] [LOBERT: Generative AI Foundation Model for Limit Order Book Messages](https://arxiv.org/abs/2511.12563)
*Eljas Linna,Kestutis Baltakys,Alexandros Iosifidis,Juho Kanniainen*

Main category: cs.AI

TL;DR: LOBERT是一个用于限价订单簿数据的通用编码器基础模型，通过新颖的标记化方案处理多维消息，在预测中间价格变动和下一消息等任务中表现领先。


<details>
  <summary>Details</summary>
Motivation: 现有LOB模型需要繁琐的数据表示，缺乏原始任务之外的适应性，因此需要开发一个适用于下游微调的通用基础模型。

Method: LOBERT基于BERT架构，采用新颖的标记化方案，将完整的多维消息作为单个标记处理，同时保留价格、数量和时间的连续表示。

Result: LOBERT在预测中间价格变动和下一消息等任务中达到领先性能，同时相比先前方法减少了所需的上下文长度。

Conclusion: LOBERT为LOB数据提供了一个有效的通用基础模型，在多个任务中表现出色且具有更好的适应性。

Abstract: Modeling the dynamics of financial Limit Order Books (LOB) at the message level is challenging due to irregular event timing, rapid regime shifts, and the reactions of high-frequency traders to visible order flow. Previous LOB models require cumbersome data representations and lack adaptability outside their original tasks, leading us to introduce LOBERT, a general-purpose encoder-only foundation model for LOB data suitable for downstream fine-tuning. LOBERT adapts the original BERT architecture for LOB data by using a novel tokenization scheme that treats complete multi-dimensional messages as single tokens while retaining continuous representations of price, volume, and time. With these methods, LOBERT achieves leading performance in tasks such as predicting mid-price movements and next messages, while reducing the required context length compared to previous methods.

</details>


### [303] [Enhancing Conversational Recommender Systems with Tree-Structured Knowledge and Pretrained Language Models](https://arxiv.org/abs/2511.12579)
*Yongwen Ren,Chao Wang,Peng Du,Chuan Qin,Dazhong Shen,Hui Xiong*

Main category: cs.AI

TL;DR: PCRS-TKA是一个基于提示的框架，通过检索增强生成将预训练语言模型与知识图谱集成，解决了现有方法在推理、知识筛选和协作偏好建模方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用PLM在图关系上的推理能力，不加区分地整合检索到的知识，且在多轮对话中忽视了协作偏好，导致准确性和幻觉问题。

Method: 构建对话特定的知识树并序列化为文本，实现结构感知推理；选择性过滤上下文相关知识；使用专门监督信号显式建模协作偏好；通过语义对齐模块协调异构输入。

Result: 广泛实验表明PCRS-TKA在推荐和对话质量方面持续优于所有基线方法。

Conclusion: PCRS-TKA通过结构感知推理、上下文知识筛选和协作偏好建模，有效提升了对话推荐系统的准确性和对话质量。

Abstract: Recent advances in pretrained language models (PLMs) have significantly improved conversational recommender systems (CRS), enabling more fluent and context-aware interactions. To further enhance accuracy and mitigate hallucination, many methods integrate PLMs with knowledge graphs (KGs), but face key challenges: failing to fully exploit PLM reasoning over graph relationships, indiscriminately incorporating retrieved knowledge without context filtering, and neglecting collaborative preferences in multi-turn dialogues. To this end, we propose PCRS-TKA, a prompt-based framework employing retrieval-augmented generation to integrate PLMs with KGs. PCRS-TKA constructs dialogue-specific knowledge trees from KGs and serializes them into texts, enabling structure-aware reasoning while capturing rich entity semantics. Our approach selectively filters context-relevant knowledge and explicitly models collaborative preferences using specialized supervision signals. A semantic alignment module harmonizes heterogeneous inputs, reducing noise and enhancing accuracy. Extensive experiments demonstrate that PCRS-TKA consistently outperforms all baselines in both recommendation and conversational quality.

</details>


### [304] [Dynamic Tree Databases in Automated Planning](https://arxiv.org/abs/2511.12677)
*Oliver Joergensen,Dominik Drexler,Jendrik Seipp*

Main category: cs.AI

TL;DR: 提出了一种动态树数据库变体，用于压缩命题和数值变量的状态集，在保持静态版本优点的同时解决了内存预分配问题。


<details>
  <summary>Details</summary>
Motivation: 扩展显式状态空间搜索面临的主要挑战是如何紧凑表示生成的状态集。静态树数据库虽然每个状态只需要常量空间，但需要大量内存预分配。

Method: 开发了一种动态树数据库变体，用于压缩命题和数值变量的状态集，并证明了其保持静态对应版本的理想特性。

Result: 在经典和数值规划任务上的实证评估显示，压缩比达到几个数量级，且运行时开销通常可忽略不计。

Conclusion: 动态树数据库在状态压缩方面表现出色，为大规模任务的状态空间搜索提供了有效的解决方案。

Abstract: A central challenge in scaling up explicit state-space search for large tasks is compactly representing the set of generated states. Tree databases, a data structure from model checking, require constant space per generated state in the best case, but they need a large preallocation of memory. We propose a novel dynamic variant of tree databases for compressing state sets over propositional and numeric variables and prove that it maintains the desirable properties of the static counterpart. Our empirical evaluation of state compression techniques for grounded and lifted planning on classical and numeric planning tasks reveals compression ratios of several orders of magnitude, often with negligible runtime overhead.

</details>


### [305] [Adaptively Coordinating with Novel Partners via Learned Latent Strategies](https://arxiv.org/abs/2511.12754)
*Benjamin Li,Shuyang Shi,Lucia Romero,Huao Li,Yaqi Xie,Woojun Kim,Stefanos Nikolaidis,Michael Lewis,Katia Sycara,Simon Stepputtis*

Main category: cs.AI

TL;DR: 本文提出了一种策略条件化合作者框架，通过变分自编码器学习策略空间、聚类识别策略类型，并利用后悔最小化算法实时适应新伙伴，在Overcooked环境中实现了最先进的协作性能。


<details>
  <summary>Details</summary>
Motivation: 在人类-智能体团队中，人工智能体需要实时适应具有独特偏好和动态变化策略的人类伙伴，这在时间压力和复杂策略空间的任务中尤为挑战。

Method: 使用变分自编码器编码策略学习潜在策略空间，通过聚类识别不同策略类型，训练条件化合作者智能体，并利用固定份额后悔最小化算法进行在线适应。

Result: 在修改版Overcooked环境中的实验和在线用户研究表明，该方法与新颖人类和智能体队友配对时，相比现有基线实现了最先进的性能。

Conclusion: 提出的策略条件化合作者框架能够有效表示、分类和实时适应广泛的潜在伙伴策略，在复杂协作任务中表现出卓越的适应性。

Abstract: Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.

</details>


### [306] [Optimal Foraging in Memory Retrieval: Evaluating Random Walks and Metropolis-Hastings Sampling in Modern Semantic Spaces](https://arxiv.org/abs/2511.12759)
*James Moore*

Main category: cs.AI

TL;DR: 研究发现，在现代高维嵌入空间中，简单随机游走就能产生与人类最优觅食行为一致的结果，而更复杂的Metropolis-Hastings采样反而不能匹配人类行为，挑战了复杂采样机制必然能更好模拟记忆检索的假设。


<details>
  <summary>Details</summary>
Motivation: 探索现代高维嵌入空间是否能提供足够好的表示，使得算法能够匹配人类在语义流畅性任务中观察到的觅食行为模式，特别是检验最优觅食理论在记忆检索中的适用性。

Method: 使用最先进的词嵌入和先前的语义流畅性数据，在嵌入空间上进行随机游走和Metropolis-Hastings采样，比较两种方法产生的结果与人类行为的匹配程度。

Result: 随机游走在嵌入空间上产生的结果与最优觅食和边际价值定理一致，而Metropolis-Hastings采样（预期能模拟策略性接受和拒绝新簇）的结果与人类行为不一致。

Conclusion: 适当结构的嵌入空间即使使用简单采样也能产生接近最优的觅食动态，支持Hills(2012)而非Abbott(2015)的观点，表明现代嵌入可以近似人类记忆觅食而无需依赖复杂的接受标准。

Abstract: Human memory retrieval often resembles ecological foraging where animals search for food in a patchy environment. Optimal foraging means following the Marginal Value Theorem (MVT), in which individuals exploit a patch of semantically related concepts until it becomes less rewarding and then switch to a new cluster. While human behavioral data suggests foraging-like patterns in semantic fluency tasks, it remains unclear whether modern high-dimensional embedding spaces provide representations that allow algorithms to match observed human behavior. Using state-of-the-art embeddings and prior semantic fluency data, I find that random walks on these embedding spaces produce results consistent with optimal foraging and the MVT. Surprisingly, introducing Metropolis-Hastings sampling, an adaptive algorithm expected to model strategic acceptance and rejection of new clusters, does not produce results consistent with human behavior. These findings challenge the assumption that more complex sampling mechanisms inherently lead to better cognitive models of memory retrieval. Instead, they show that appropriately structured embeddings, even with simple sampling, can produce near-optimal foraging dynamics. This supports the perspective of Hills (2012) rather than Abbott (2015), demonstrating that modern embeddings can approximate human memory foraging without relying on complex acceptance criteria.

</details>


### [307] [Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization](https://arxiv.org/abs/2511.12792)
*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Zehong Cao,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 本研究使用强化学习优化异构卫星集群在自主地球观测任务中的资源分配，通过多智能体强化学习算法实现光学和SAR卫星的协同工作，解决实时、不确定和去中心化环境下的资源管理问题。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法难以处理地球观测操作中的实时性、不确定性和去中心化特性，因此需要采用强化学习和多智能体强化学习来实现自适应决策。

Method: 使用Basilisk和BSK-RL框架构建近真实模拟环境，评估MAPPO、HAPPO和HATRPO等先进多智能体强化学习算法在单卫星到多卫星场景中的性能。

Result: 多智能体强化学习能够有效协调异构卫星，在平衡成像性能和资源利用的同时，缓解非平稳性和智能体间奖励耦合问题。

Conclusion: 研究为可扩展的自主卫星操作提供了实用见解，并为异构动态条件下智能地球观测任务规划的后续研究奠定了基础。

Abstract: This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.

</details>


### [308] [Bootstrapping LLMs via Preference-Based Policy Optimization](https://arxiv.org/abs/2511.12867)
*Chen Jia*

Main category: cs.AI

TL;DR: 提出了一种基于偏好的策略优化框架PbPO，通过主策略与奖励模型之间的min-max博弈来引导LLM对齐人类偏好，无需大量人工标注。


<details>
  <summary>Details</summary>
Motivation: 通过基于偏好的策略优化来引导大型语言模型与人类偏好对齐，避免依赖大量手动标注。

Method: 将学习过程建模为主策略与奖励模型之间的min-max博弈，奖励模型受偏好数据置信集约束，采用迭代在线算法通过策略的引导式探索主动收集偏好数据。

Result: 在五个基准测试上的广泛实验表明，该方法持续优于现有的最先进偏好优化技术。

Conclusion: 提出的PbPO框架为引导LLM提供了有效的理论保证和实际性能，实现了策略和奖励模型的持续自我改进。

Abstract: Bootstrapping large language models (LLMs) through preference-based policy optimization offers a promising direction for aligning model behavior with human preferences without relying on extensive manual annotations. In this work, we propose a novel preference-based policy optimization (PbPO) framework that formulates the learning process as a min-max game between the main policy and a reward model (RM). The RM is constrained within a confidence set derived from preference data to ensure reliable exploitation. Our iterative online algorithm actively collects preference data through guided exploration of the evolving policy, enabling continual self-improvement of both the policy and the RM. We provide theoretical guarantees for our method, establishing high-probability regret bounds for both settings with sequence-level RM and token-level RM, demonstrating its effectiveness in bootstrapping LLMs. Extensive experiments on five benchmarks show that our approach consistently outperforms existing state-of-the-art preference optimization techniques.

</details>


### [309] [Think, Speak, Decide: Language-Augmented Multi-Agent Reinforcement Learning for Economic Decision-Making](https://arxiv.org/abs/2511.12876)
*Heyang Ma,Qirui Mi,Qipeng Yang,Zijun Fan,Bo Li,Haifeng Zhang*

Main category: cs.AI

TL;DR: LAMP框架通过语言增强的多智能体策略，在经济决策中整合语言信息，采用Think-Speak-Decide流程，显著提升了累积回报、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现实经济决策不仅依赖结构化信号（如价格、税收），还受非结构化语言（如同行对话、媒体叙事）影响。传统多智能体强化学习难以处理语言的语义模糊性和上下文丰富性。

Method: 提出LAMP框架，包含三个步骤：Think（解释数值观察，提取短期冲击和长期趋势，缓存高价值推理轨迹）、Speak（基于推理生成和交换战略消息，通过解析同伴通信更新信念）、Decide（融合数值数据、推理和反思到MARL策略中优化语言增强决策）。

Result: 经济模拟实验显示，LAMP在累积回报（+63.5%，+34.0%）、鲁棒性（+18.8%，+59.4%）和可解释性方面优于MARL和纯LLM基线。

Conclusion: 语言增强策略具有提供更有效和稳健经济策略的潜力。

Abstract: Economic decision-making depends not only on structured signals such as prices and taxes, but also on unstructured language, including peer dialogue and media narratives. While multi-agent reinforcement learning (MARL) has shown promise in optimizing economic decisions, it struggles with the semantic ambiguity and contextual richness of language. We propose LAMP (Language-Augmented Multi-Agent Policy), a framework that integrates language into economic decision-making and narrows the gap to real-world settings. LAMP follows a Think-Speak-Decide pipeline: (1) Think interprets numerical observations to extract short-term shocks and long-term trends, caching high-value reasoning trajectories; (2) Speak crafts and exchanges strategic messages based on reasoning, updating beliefs by parsing peer communications; and (3) Decide fuses numerical data, reasoning, and reflections into a MARL policy to optimize language-augmented decision-making. Experiments in economic simulation show that LAMP outperforms both MARL and LLM-only baselines in cumulative return (+63.5%, +34.0%), robustness (+18.8%, +59.4%), and interpretability. These results demonstrate the potential of language-augmented policies to deliver more effective and robust economic strategies.

</details>


### [310] [Fault2Flow: An AlphaEvolve-Optimized Human-in-the-Loop Multi-Agent System for Fault-to-Workflow Automation](https://arxiv.org/abs/2511.12916)
*Yafang Wang,Yangjie Tian,Xiaoyu Shen,Gaoyang Zhang,Jiaze Sun,He Zhang,Ruohua Xu,Feng Zhao*

Main category: cs.AI

TL;DR: Fault2Flow是一个基于LLM的多智能体系统，用于电网故障诊断，通过提取法规逻辑、整合专家知识、优化推理逻辑，最终生成可执行的工作流。


<details>
  <summary>Details</summary>
Motivation: 传统电网故障诊断依赖手动方法，效率低、易出错且难以维护，缺乏将法规知识和专家经验整合到可验证工作流中的框架。

Method: 提出Fault2Flow系统：1) 将法规逻辑提取为PASTA格式故障树；2) 通过人机交互界面整合专家知识；3) 使用AlphaEvolve模块优化推理逻辑；4) 合成n8n可执行工作流。

Result: 在变压器故障诊断数据集上的实验验证显示100%拓扑一致性和高语义保真度。

Conclusion: Fault2Flow建立了从故障分析到操作自动化的可复现路径，显著减少了专家工作量。

Abstract: Power grid fault diagnosis is a critical process hindered by its reliance on manual, error-prone methods. Technicians must manually extract reasoning logic from dense regulations and attempt to combine it with tacit expert knowledge, which is inefficient, error-prone, and lacks maintainability as ragulations are updated and experience evolves. While Large Language Models (LLMs) have shown promise in parsing unstructured text, no existing framework integrates these two disparate knowledge sources into a single, verified, and executable workflow. To bridge this gap, we propose Fault2Flow, an LLM-based multi-agent system. Fault2Flow systematically: (1) extracts and structures regulatory logic into PASTA-formatted fault trees; (2) integrates expert knowledge via a human-in-the-loop interface for verification; (3) optimizes the reasoning logic using a novel AlphaEvolve module; and (4) synthesizes the final, verified logic into an n8n-executable workflow. Experimental validation on transformer fault diagnosis datasets confirms 100\% topological consistency and high semantic fidelity. Fault2Flow establishes a reproducible path from fault analysis to operational automation, substantially reducing expert workload.

</details>


### [311] [Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models](https://arxiv.org/abs/2511.12937)
*Guoyan Wang,Yanyan Huang,Chunlin Chen,Lifeng Wang,Yuxiang Sun*

Main category: cs.AI

TL;DR: Yanyun-3是一个通用智能体框架，首次实现了在三个异构策略游戏环境中的自主跨平台操作，通过整合视觉语言推理和精确执行能力，在目标定位、资源分配和区域控制等核心任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决跨平台策略游戏中智能体在不同用户界面和动态战场条件下的鲁棒泛化问题，探索视觉语言模型在复杂人机交互场景中的应用潜力。

Method: 整合Qwen2.5-VL的视觉语言推理能力和UI-TARS的精确执行能力，采用屏幕捕获-模型推理-动作执行的闭环流程，研究不同多模态数据组合策略（静态图像、多图像序列、视频）的效果。

Result: 混合策略（融合多图像和视频数据，同时混合静态图像）相比完全融合策略，推理时间减少63%，BLEU-4得分从4.81%提升至62.41%（约12.98倍提升），展现出强大的实时性能和跨平台泛化能力。

Conclusion: 该工作不仅为策略游戏自动化提供了高效解决方案，还通过结构化多模态数据组织建立了增强视觉语言模型性能的通用范式，为具身智能中静态感知与动态推理的相互作用提供了新见解。

Abstract: Automated operation in cross-platform strategy games demands agents with robust generalization across diverse user interfaces and dynamic battlefield conditions. While vision-language models (VLMs) have shown considerable promise in multimodal reasoning, their application to complex human-computer interaction scenarios--such as strategy gaming--remains largely unexplored. Here, we introduce Yanyun-3, a general-purpose agent framework that, for the first time, enables autonomous cross-platform operation across three heterogeneous strategy game environments. By integrating the vision-language reasoning of Qwen2.5-VL with the precise execution capabilities of UI-TARS, Yanyun-3 successfully performs core tasks including target localization, combat resource allocation, and area control. Through systematic ablation studies, we evaluate the effects of various multimodal data combinations--static images, multi-image sequences, and videos--and propose the concept of combination granularity to differentiate between intra-sample fusion and inter-sample mixing strategies. We find that a hybrid strategy, which fuses multi-image and video data while mixing in static images (MV+S), substantially outperforms full fusion: it reduces inference time by 63% and boosts the BLEU-4 score by a factor of 12 (from 4.81% to 62.41%, approximately 12.98x). Operating via a closed-loop pipeline of screen capture, model inference, and action execution, the agent demonstrates strong real-time performance and cross-platform generalization. Beyond providing an efficient solution for strategy game automation, our work establishes a general paradigm for enhancing VLM performance through structured multimodal data organization, offering new insights into the interplay between static perception and dynamic reasoning in embodied intelligence.

</details>


### [312] [GEM: Generative Entropy-Guided Preference Modeling for Few-shot Alignment of LLMs](https://arxiv.org/abs/2511.13007)
*Yiyang Zhao,Huiyu Bai,Xuejiao Zhao*

Main category: cs.AI

TL;DR: 提出GEM方法，通过生成式熵引导偏好建模在大语言模型低资源和领域特定场景下进行对齐，无需大量标注数据


<details>
  <summary>Details</summary>
Motivation: 在医学、法律等专业领域难以获得大规模偏好标注数据，需要开发低资源条件下的LLM对齐方法

Method: 基于熵理论的认知过滤模块使用CoT提示生成多样化推理链，通过token评分机制对推理链进行排序加权，然后使用SEGA算法进行微调

Result: 在通用基准和领域特定任务（如数学推理和医疗对话）上，GEM在少样本偏好数据下取得显著改进

Conclusion: GEM建立了熵引导的闭环认知优化框架，使LLM能够依靠自身判断实现高效的少样本对齐

Abstract: Alignment of large language models (LLMs) with human preferences typically relies on supervised reward models or external judges that demand abundant annotations. However, in fields that rely on professional knowledge, such as medicine and law, such large-scale preference labels are often unachievable. In this paper, we propose a generative entropy-guided preference modeling approach named GEM for LLMs aligment at low-resource and domain-specific scenarios. Instead of training a discriminative reward model on preference data, we directly train the LLM to internalize a closed-loop optimization architecture that can extract and exploit the multi-dimensional, fine-grained cognitive signals implicit in human preferences. Specifically, our Cognitive Filtering module, based on entropy theory in decision making, first leverages Chain-of-Thought (CoT) prompting to generate diverse candidate reasoning chains (CoTs) from preference data. Subsequently, it introduces a token scoring mechanism to rank and weight the sampled CoTs, boosting the importance of high-confidence answers and strategically high-entropy tokens. Building on these filtered preferences, we fine-tune the LLM using a novel self-evaluated group advantage algorithm, SEGA, which effectively aggregates group-level cognitive signals and transforms the entropy-based scores into implicit rewards for policy optimization. In these ways, GEM empowers the LLM to rely on its own judgments and establishes an entropy-guided closed-loop cognitive optimization framework, enabling highly efficient few-shot alignment of LLMs. Experiments on general benchmarks and domain-specific tasks (such as mathematical reasoning and medical dialogues) demonstrate that our GEM achieves significant improvements with few-shot preference data.

</details>


### [313] [PragWorld: A Benchmark Evaluating LLMs' Local World Model under Minimal Linguistic Alterations and Conversational Dynamics](https://arxiv.org/abs/2511.13021)
*Sachin Vashistha,Aryan Bibhuti,Atharva Naik,Martin Tutek,Somak Aditya*

Main category: cs.AI

TL;DR: 本文评估了语言模型在对话中编码和更新内部世界模型的能力，测试了它们在语言变化下的鲁棒性。通过构建包含是-否问题的基准测试，发现语言模型难以维持准确率，特别是在跟踪实体方面。提出了双重视角可解释性框架识别有害层，并设计了层正则化微调策略。


<details>
  <summary>Details</summary>
Motivation: 现实对话包含丰富的语用元素，需要构建局部世界模型来编码这些元素并捕捉其状态演变。然而，语言模型是否构建或维护稳健的隐式对话表示尚不清楚。

Method: 对流行数据集中的对话应用七种最小语言变化，构建两个包含是-否问题的基准测试。评估了广泛的开源和闭源语言模型，提出了双重视角可解释性框架识别有用和有害的transformer层，并设计了基于层正则化的微调策略。

Result: 语言模型在语言变化下难以维持稳健的准确率，特别是在记忆关键细节和跟踪实体方面。可解释性分析揭示了有害层通常由于编码虚假信号或依赖捷径而产生负面影响。

Conclusion: 语言模型在对话中构建和维护稳健世界模型的能力有限，提出的层正则化微调策略能够有效抑制有害层的影响，提升模型在语言变化下的鲁棒性。

Abstract: Real-world conversations are rich with pragmatic elements, such as entity mentions, references, and implicatures. Understanding such nuances is a requirement for successful natural communication, and often requires building a local world model which encodes such elements and captures the dynamics of their evolving states. However, it is not well-understood whether language models (LMs) construct or maintain a robust implicit representation of conversations. In this work, we evaluate the ability of LMs to encode and update their internal world model in dyadic conversations and test their malleability under linguistic alterations. To facilitate this, we apply seven minimal linguistic alterations to conversations sourced from popular datasets and construct two benchmarks comprising yes-no questions. We evaluate a wide range of open and closed source LMs and observe that they struggle to maintain robust accuracy. Our analysis unveils that LMs struggle to memorize crucial details, such as tracking entities under linguistic alterations to conversations. We then propose a dual-perspective interpretability framework which identifies transformer layers that are useful or harmful and highlights linguistic alterations most influenced by harmful layers, typically due to encoding spurious signals or relying on shortcuts. Inspired by these insights, we propose two layer-regularization based fine-tuning strategies that suppress the effect of the harmful layers.

</details>


### [314] [Scaling Generative Verifiers For Natural Language Mathematical Proof Verification And Selection](https://arxiv.org/abs/2511.13027)
*Sadegh Mahdavi,Branislav Kisacanin,Shubham Toshniwal,Wei Du,Ivan Moshkov,George Armstrong,Renjie Liao,Christos Thrampoulidis,Igor Gitman*

Main category: cs.AI

TL;DR: 该论文研究了大型语言模型在数学证明验证方面的能力，分析了多种评估设置，发现单一基准测试可能导致误导性结论。作者评估了证明推理和最终答案推理，并比较了两种生成验证方法，发现它们的组合最有效。研究还发现提示选择对LLM-as-a-Judge性能有显著影响，但强化学习可以降低这种敏感性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在最终答案数学问题上表现优异，但推理过程往往存在缺陷。为了推进到严谨的证明数学，需要可靠的证明验证能力。

Method: 分析多种评估设置，同时评估证明推理和最终答案推理；将两种主要生成验证方法（GenSelect和LLM-as-a-Judge）扩展到数百万token；研究提示选择对性能的影响；使用强化学习降低敏感性。

Result: 证明推理和最终答案推理的组合评估提供更可靠的性能测量；GenSelect和LLM-as-a-Judge的组合是最有效的验证框架；强化学习可以降低对提示选择的敏感性；但强化学习虽然改善了证明级指标，却没有提高最终答案精度。

Conclusion: 当前模型往往奖励风格或程序正确性而非数学有效性。研究结果为设计和评估可扩展的证明验证和选择系统提供了实用指南。

Abstract: Large language models have achieved remarkable success on final-answer mathematical problems, largely due to the ease of applying reinforcement learning with verifiable rewards. However, the reasoning underlying these solutions is often flawed. Advancing to rigorous proof-based mathematics requires reliable proof verification capabilities. We begin by analyzing multiple evaluation setups and show that focusing on a single benchmark can lead to brittle or misleading conclusions. To address this, we evaluate both proof-based and final-answer reasoning to obtain a more reliable measure of model performance. We then scale two major generative verification methods (GenSelect and LLM-as-a-Judge) to millions of tokens and identify their combination as the most effective framework for solution verification and selection. We further show that the choice of prompt for LLM-as-a-Judge significantly affects the model's performance, but reinforcement learning can reduce this sensitivity. However, despite improving proof-level metrics, reinforcement learning does not enhance final-answer precision, indicating that current models often reward stylistic or procedural correctness rather than mathematical validity. Our results establish practical guidelines for designing and evaluating scalable proof-verification and selection systems.

</details>


### [315] [STEP: Success-Rate-Aware Trajectory-Efficient Policy Optimization](https://arxiv.org/abs/2511.13091)
*Yuhan Chen,Yuxuan Liu,Long Zhang,Pengzhi Gao,Jian Luan,Wei Liu*

Main category: cs.AI

TL;DR: STEP是一个解决多轮交互强化学习问题的框架，通过基于任务成功率的动态采样分配和步骤级优化，显著提高了样本效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的轨迹级优化方法在多轮交互强化学习中存在效率低下和学习信号误导的问题，包括对所有任务采用统一采样、在失败轨迹中惩罚正确的中间动作以及高昂的样本收集成本。

Method: STEP框架维护平滑的成功率记录来指导自适应轨迹重采样，为困难任务分配更多资源；计算成功率加权的优势函数并将轨迹分解为步骤级样本；应用步骤级GRPO增强来改进低成功率任务的更新。

Result: 在OSWorld和AndroidWorld上的实验表明，STEP相比轨迹级GRPO显著提高了样本效率和训练稳定性，在相同采样预算下收敛更快且泛化能力更好。

Conclusion: STEP通过动态采样分配和步骤级优化有效解决了多轮交互强化学习中的效率问题，为在线强化学习提供了更高效的训练框架。

Abstract: Multi-turn interaction remains challenging for online reinforcement learning. A common solution is trajectory-level optimization, which treats each trajectory as a single training sample. However, this approach can be inefficient and yield misleading learning signals: it applies uniform sampling across tasks regardless of difficulty, penalizes correct intermediate actions in failed trajectories, and incurs high sample-collection costs. To address these issues, we propose STEP (Success-rate-aware Trajectory-Efficient Policy optimization), a framework that dynamically allocates sampling based on per-task success rates and performs step-level optimization. STEP maintains a smoothed success-rate record to guide adaptive trajectory resampling, allocating more effort to harder tasks. It then computes success-rate-weighted advantages and decomposes trajectories into step-level samples. Finally, it applies a step-level GRPO augmentation to refine updates for low-success tasks. Experiments on OSWorld and AndroidWorld show that STEP substantially improves sample efficiency and training stability over trajectory-level GRPO, converging faster and generalizing better under the same sampling budget.

</details>


### [316] [InteractiveGNNExplainer: A Visual Analytics Framework for Multi-Faceted Understanding and Probing of Graph Neural Network Predictions](https://arxiv.org/abs/2511.13160)
*TC Singh,Sougata Mukherjea*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph Neural Networks (GNNs) excel in graph-based learning tasks, but their complex, non-linear operations often render them as opaque "black boxes". This opacity hinders user trust, complicates debugging, bias detection, and adoption in critical domains requiring explainability. This paper introduces InteractiveGNNExplainer, a visual analytics framework to enhance GNN explainability, focusing on node classification. Our system uniquely integrates coordinated interactive views (dynamic graph layouts, embedding projections, feature inspection, neighborhood analysis) with established post-hoc (GNNExplainer) and intrinsic (GAT attention) explanation techniques. Crucially, it incorporates interactive graph editing, allowing users to perform a "what-if" analysis by perturbing graph structures and observing immediate impacts on GNN predictions and explanations. We detail the system architecture and, through case studies on Cora and CiteSeer datasets, demonstrate how InteractiveGNNExplainer facilitates in-depth misclassification diagnosis, comparative analysis of GCN versus GAT behaviors, and rigorous probing of model sensitivity. These capabilities foster a deeper, multifaceted understanding of GNN predictions, contributing to more transparent, trustworthy, and robust graph analysis.

</details>


### [317] [Informative Communication of Robot Plans](https://arxiv.org/abs/2511.13226)
*Michele Persiani,Thomas Hellstrom*

Main category: cs.AI

TL;DR: 本文提出了一种基于信息增益的机器人计划口头表达策略，通过考虑用户的二阶心智理论来优化沟通效果。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人计划口头表达策略（如按计划顺序递增或递减）没有充分考虑用户已有的知识，导致沟通效果不佳。需要一种能够有效传达信息的策略。

Method: 提出一种基于信息增益的机器人计划口头表达策略，通过衡量口头表达相对于用户二阶心智理论的信息增益，选择最有效的沟通方式。

Result: 实验表明，该策略能让用户更快理解机器人的目标，优于递增或递减计划顺序等传统策略。

Conclusion: 基于信息增益的口头表达策略能显著提高机器人计划沟通的效果，并为理解什么是有信息量的沟通提供了理论基础。

Abstract: When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot's goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.

</details>


### [318] [Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO](https://arxiv.org/abs/2511.13288)
*Haoyang Hong,Jiajun Yin,Yuan Wang,Jingnan Liu,Zhe Chen,Ailing Yu,Ji Li,Zhiling Ye,Hansong Xiao,Yefei Chen,Hualei Zhou,Yun Yue,Minghui Yang,Chunxiao Guo,Junwei Liu,Peng Wei,Jinjie Gu*

Main category: cs.AI

TL;DR: 提出了M-GRPO方法，用于解决多智能体系统中不同智能体使用不同LLM时的优化挑战，通过层次化信用分配和轨迹对齐方案，在真实基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统使用统一的LLM训练限制了性能，因为不同智能体具有不同的数据分布。使用不同LLM训练多智能体系统是必要的，但这带来了优化挑战，如不同频率操作、可变子智能体调用和跨服务器部署导致的梯度流中断。

Method: 提出M-GRPO方法：1）为主智能体和子智能体计算组相对优势，保持层次化信用分配；2）引入轨迹对齐方案，生成固定大小的批次；3）部署解耦训练管道，智能体在独立服务器上运行，通过共享存储交换最小统计信息。

Result: 在真实世界基准测试（GAIA、XBench-DeepSearch、WebWalkerQA）中，M-GRPO持续优于单智能体GRPO和冻结子智能体的多智能体GRPO，展示了改进的稳定性和样本效率。

Conclusion: 对齐异构轨迹并在专门智能体之间解耦优化能够增强工具增强推理任务的性能。

Abstract: Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.

</details>


### [319] [DAP: A Discrete-token Autoregressive Planner for Autonomous Driving](https://arxiv.org/abs/2511.13306)
*Bowen Ye,Bin Zhang,Hang Zhao*

Main category: cs.AI

TL;DR: DAP是一个离散令牌自回归规划器，通过联合预测BEV语义和自车轨迹来实现自动驾驶规划，结合强化学习微调，在160M参数下达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶中数据扩展和模型预算下的可持续性能提升挑战，自回归模型在规划任务中表现出良好的数据扩展效率，但仅预测自车轨迹存在监督稀疏和场景演化约束弱的问题。

Method: 引入离散令牌自回归规划器DAP，联合预测BEV语义和自车轨迹，实现全面表征学习；结合基于强化学习的微调，保留监督行为克隆先验的同时注入奖励引导的改进。

Result: 在160M参数预算下，在开环指标上达到最先进性能，在NAVSIM基准测试中提供有竞争力的闭环结果。

Conclusion: 完全离散令牌自回归公式在栅格化BEV和自车动作上的操作为自动驾驶提供了紧凑且可扩展的规划范式。

Abstract: Gaining sustainable performance improvement with scaling data and model budget remains a pivotal yet unresolved challenge in autonomous driving. While autoregressive models exhibited promising data-scaling efficiency in planning tasks, predicting ego trajectories alone suffers sparse supervision and weakly constrains how scene evolution should shape ego motion. Therefore, we introduce DAP, a discrete-token autoregressive planner that jointly forecasts BEV semantics and ego trajectories, thereby enforcing comprehensive representation learning and allowing predicted dynamics to directly condition ego motion. In addition, we incorporate a reinforcement-learning-based fine-tuning, which preserves supervised behavior cloning priors while injecting reward-guided improvements. Despite a compact 160M parameter budget, DAP achieves state-of-the-art performance on open-loop metrics and delivers competitive closed-loop results on the NAVSIM benchmark. Overall, the fully discrete-token autoregressive formulation operating on both rasterized BEV and ego actions provides a compact yet scalable planning paradigm for autonomous driving.

</details>


### [320] [Reasoning Shapes Alignment: Investigating Cultural Alignment in Large Reasoning Models with Cultural Norms](https://arxiv.org/abs/2511.13359)
*Yuhang Wang,Yanxu Zhu,Jitao Sang*

Main category: cs.AI

TL;DR: 本文提出了文化规范文化对齐（CNCA）框架，利用大模型的推理能力实现文化对齐，包括三种从有限调查数据中自动挖掘文化规范的方法，以及两种对齐范式（上下文对齐和基于微调的方法）。


<details>
  <summary>Details</summary>
Motivation: 大模型需要超越安全性，反映不同文化背景下的人类价值观多样性，实现文化对齐。

Method: 提出CNCA框架，包含三种自动挖掘文化规范的方法和两种对齐范式：上下文对齐（将文化规范整合到用户上下文中）和基于微调的方法（通过增强的思维链训练数据内化规范）。

Result: 综合实验证明这些方法的有效性，推理能力更强的模型从文化规范挖掘和利用中获益更多。

Conclusion: 研究强调了推理模型通过文化知情对齐策略更好地反映多样化人类价值观的潜力。

Abstract: The advanced reasoning capabilities of Large Reasoning Models enable them to thoroughly understand and apply safety policies through deliberate thought processes, thereby improving the models' safety. Beyond safety, these models must also be able to reflect the diverse range of human values across various cultures. This paper presents the Cultural Norm-based Cultural Alignment (CNCA) framework, which enables models to leverage their powerful reasoning ability to align with cultural norms. Specifically, we propose three methods to automatically mine cultural norms from limited survey data and explore ways to effectively utilize these norms for improving cultural alignment. Two alignment paradigms are examined: an in-context alignment method, where cultural norms are explicitly integrated into the user context, and a fine-tuning-based method, which internalizes norms through enhanced Chain-of-Thought training data. Comprehensive experiments demonstrate the effectiveness of these methods, highlighting that models with stronger reasoning capabilities benefit more from cultural norm mining and utilization. Our findings emphasize the potential for reasoning models to better reflect diverse human values through culturally informed alignment strategies.

</details>


### [321] [Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning](https://arxiv.org/abs/2511.13371)
*Caroline Baumgartner,Eleanor Spens,Neil Burgess,Petru Manescu*

Main category: cs.AI

TL;DR: 本文研究了GPT-2模型在空间导航任务中的学习机制，发现不同的训练范式会产生两种根本不同的算法：探索型模型发展出类似认知地图的稳健空间表示，而目标导向型模型则学习路径依赖算法。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型如何解决空间导航任务，探索不同训练范式对模型学习策略的影响，揭示空间智能在transformer中的本质。

Method: 在网格环境中训练GPT-2模型，采用三种空间学习范式：被动探索（随机游走预测）、目标导向规划（生成最优最短路径）和混合模型（在结构化路径基础上用探索数据微调）。使用行为、表征和机制分析。

Result: 探索型模型发展出类似认知地图的稳健空间表示，通过因果干预发现其将空间信息整合到自足坐标系中，并采用自适应分层推理系统。目标导向型模型学习路径依赖算法，始终依赖显式方向输入。混合模型虽然泛化能力提升，但保留路径依赖策略。

Conclusion: transformer中的空间智能存在于一个谱系中，从由探索数据塑造的可泛化世界模型到为目标导向任务优化的启发式方法。训练范式的选择显著影响涌现的策略，揭示了泛化与优化之间的权衡机制。

Abstract: How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.

</details>


### [322] [An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence](https://arxiv.org/abs/2511.13411)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing "baby AGI" becomes Superintelligence intuition.

</details>


### [323] [Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation](https://arxiv.org/abs/2511.13476)
*Zhipeng Ma,Ali Rida Bahja,Andreas Burgdorf,André Pomp,Tobias Meisen,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.AI

TL;DR: 本研究提出了一个多智能体框架，利用多模态大语言模型自动生成数据叙述和能源洞察，通过三个专业智能体的协调工作，将分析结果转化为连贯的面向利益相关者的报告。


<details>
  <summary>Details</summary>
Motivation: 传统分析和可视化方法产生碎片化输出，需要大量人工解释，限制了可扩展性和一致性。需要将复杂的多模态数据转化为可解释的决策相关洞察。

Method: 开发多智能体框架，包括数据叙述智能体、LLM-as-a-judge智能体和可选的人类评估者，使用高斯混合模型聚类分析4006次公交行程的燃油效率数据，比较五种最先进LLM和三种提示范式。

Result: GPT-4.1 mini与思维链提示被确定为最优配置，达到97.3%的叙述准确性，在可解释性和计算成本之间取得平衡。多智能体编排显著提高了基于LLM报告的事实精确性、连贯性和可扩展性。

Conclusion: 该框架为能源信息学中AI驱动的叙述生成和决策支持建立了可复制和领域自适应的方法论，多智能体编排显著提升了LLM报告的质量。

Abstract: Enhancing fuel efficiency in public transportation requires the integration of complex multimodal data into interpretable, decision-relevant insights. However, traditional analytics and visualization methods often yield fragmented outputs that demand extensive human interpretation, limiting scalability and consistency. This study presents a multi-agent framework that leverages multimodal large language models (LLMs) to automate data narration and energy insight generation. The framework coordinates three specialized agents, including a data narration agent, an LLM-as-a-judge agent, and an optional human-in-the-loop evaluator, to iteratively transform analytical artifacts into coherent, stakeholder-oriented reports. The system is validated through a real-world case study on public bus transportation in Northern Jutland, Denmark, where fuel efficiency data from 4006 trips are analyzed using Gaussian Mixture Model clustering. Comparative experiments across five state-of-the-art LLMs and three prompting paradigms identify GPT-4.1 mini with Chain-of-Thought prompting as the optimal configuration, achieving 97.3% narrative accuracy while balancing interpretability and computational cost. The findings demonstrate that multi-agent orchestration significantly enhances factual precision, coherence, and scalability in LLM-based reporting. The proposed framework establishes a replicable and domain-adaptive methodology for AI-driven narrative generation and decision support in energy informatics.

</details>


### [324] [FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI](https://arxiv.org/abs/2511.13524)
*Yuhang Peng,Yizhou Pan,Xinning He,Jihaoyu Yang,Xinyu Yin,Han Wang,Xiaoji Zheng,Chao Gao,Jiangtao Gong*

Main category: cs.AI

TL;DR: FreeAskWorld是一个集成大语言模型的交互式仿真框架，用于支持复杂的人类中心社会行为模拟，扩展了传统的视觉语言导航任务，并提供了大规模基准数据集。


<details>
  <summary>Details</summary>
Motivation: 随着具身智能成为人工智能研究的核心前沿，仿真平台需要超越低层物理交互，捕捉复杂的人类中心社会行为。

Method: 集成大语言模型进行高层行为规划和语义基础交互，基于意图和社会认知理论，构建模块化数据生成流程，支持可扩展的逼真人机仿真。

Result: 创建了包含重建环境、6种任务类型、16个核心对象类别、63,429个标注样本帧和超过17小时交互数据的大规模基准数据集。微调后的模型在语义理解和交互能力方面优于原始模型。

Conclusion: 基于社会基础的仿真框架能有效推进具身AI系统向复杂高层规划和更自然的人机交互发展，交互本身作为额外的信息模态具有重要意义。

Abstract: As embodied intelligence emerges as a core frontier in artificial intelligence research, simulation platforms must evolve beyond low-level physical interactions to capture complex, human-centered social behaviors. We introduce FreeAskWorld, an interactive simulation framework that integrates large language models (LLMs) for high-level behavior planning and semantically grounded interaction, informed by theories of intention and social cognition. Our framework supports scalable, realistic human-agent simulations and includes a modular data generation pipeline tailored for diverse embodied tasks.To validate the framework, we extend the classic Vision-and-Language Navigation (VLN) task into a interaction enriched Direction Inquiry setting, wherein agents can actively seek and interpret navigational guidance. We present and publicly release FreeAskWorld, a large-scale benchmark dataset comprising reconstructed environments, six diverse task types, 16 core object categories, 63,429 annotated sample frames, and more than 17 hours of interaction data to support training and evaluation of embodied AI systems. We benchmark VLN models, and human participants under both open-loop and closed-loop settings. Experimental results demonstrate that models fine-tuned on FreeAskWorld outperform their original counterparts, achieving enhanced semantic understanding and interaction competency. These findings underscore the efficacy of socially grounded simulation frameworks in advancing embodied AI systems toward sophisticated high-level planning and more naturalistic human-agent interaction. Importantly, our work underscores that interaction itself serves as an additional information modality.

</details>


### [325] [Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models](https://arxiv.org/abs/2511.13526)
*Zhengda Wang,Daqian Shi,Jingyi Zhao,Xiaolei Diao,Xiongfeng Tang,Yanguo Qin*

Main category: cs.AI

TL;DR: 本文提出了一个结合检索增强生成（RAG）与大语言模型（LLM）的自动化框架，用于构建医疗指标知识图谱，以支持临床决策和智能医疗系统。


<details>
  <summary>Details</summary>
Motivation: 当前临床知识图谱主要依赖人工整理和基于规则的提取，难以处理复杂的医学指南和文献，需要更自动化和可扩展的构建方法。

Method: 采用检索增强生成（RAG）与LLM相结合的方法，包括指南驱动的数据采集、基于本体的模式设计以及专家参与验证的流程。

Result: 构建的医疗指标知识图谱能够集成到智能诊断和问答系统中，提高AI驱动医疗解决方案的开发效率。

Conclusion: 该框架能够有效克服传统知识图谱构建的局限性，为临床决策支持提供结构化、可互操作的知识表示。

Abstract: Artificial intelligence (AI) is reshaping modern healthcare by advancing disease diagnosis, treatment decision-making, and biomedical research. Among AI technologies, large language models (LLMs) have become especially impactful, enabling deep knowledge extraction and semantic reasoning from complex medical texts. However, effective clinical decision support requires knowledge in structured, interoperable formats. Knowledge graphs serve this role by integrating heterogeneous medical information into semantically consistent networks. Yet, current clinical knowledge graphs still depend heavily on manual curation and rule-based extraction, which is limited by the complexity and contextual ambiguity of medical guidelines and literature. To overcome these challenges, we propose an automated framework that combines retrieval-augmented generation (RAG) with LLMs to construct medical indicator knowledge graphs. The framework incorporates guideline-driven data acquisition, ontology-based schema design, and expert-in-the-loop validation to ensure scalability, accuracy, and clinical reliability. The resulting knowledge graphs can be integrated into intelligent diagnosis and question-answering systems, accelerating the development of AI-driven healthcare solutions.

</details>


### [326] [CreBench: Human-Aligned Creativity Evaluation from Idea to Process to Product](https://arxiv.org/abs/2511.13626)
*Kaiwen Xue,Chenglong Li,Zhonghong Ou,Guoxin Zhang,Kaoyan Lu,Shuai Lyu,Yifan Zhu,Ping Zong Junpeng Ding,Xinyu Liu,Qunlin Chen,Weiwei Qin,Yiran Shen,Jiayi Cen*

Main category: cs.AI

TL;DR: 提出了CreBench基准和CreExpert模型，用于评估多模态大语言模型对人类创造力的理解能力，在创造力评估方面显著优于GPT-4V和Gemini-Pro-Vision等先进模型。


<details>
  <summary>Details</summary>
Motivation: 人类定义的创造力高度抽象，多模态大语言模型难以理解和评估符合人类判断的创造力，且缺乏现有基准。

Method: 构建CreBench基准（包含多维度创造力评估）和CreMIT数据集（2.2K多模态数据，79.2K人类反馈，4.7M多类型指令），并基于此微调开源MLLMs得到CreExpert模型。

Result: CreExpert模型在创造力评估方面与人类判断的一致性显著优于最先进的MLLMs，包括GPT-4V和Gemini-Pro-Vision。

Conclusion: CreBench为构建理解人类对齐创造力的MLLMs奠定了基础，CreExpert模型在创造力评估方面表现出色。

Abstract: Human-defined creativity is highly abstract, posing a challenge for multimodal large language models (MLLMs) to comprehend and assess creativity that aligns with human judgments. The absence of an existing benchmark further exacerbates this dilemma. To this end, we propose CreBench, which consists of two key components: 1) an evaluation benchmark covering the multiple dimensions from creative idea to process to products; 2) CreMIT (Creativity Multimodal Instruction Tuning dataset), a multimodal creativity evaluation dataset, consisting of 2.2K diverse-sourced multimodal data, 79.2K human feedbacks and 4.7M multi-typed instructions. Specifically, to ensure MLLMs can handle diverse creativity-related queries, we prompt GPT to refine these human feedbacks to activate stronger creativity assessment capabilities. CreBench serves as a foundation for building MLLMs that understand human-aligned creativity. Based on the CreBench, we fine-tune open-source general MLLMs, resulting in CreExpert, a multimodal creativity evaluation expert model. Extensive experiments demonstrate that the proposed CreExpert models achieve significantly better alignment with human creativity evaluation compared to state-of-the-art MLLMs, including the most advanced GPT-4V and Gemini-Pro-Vision.

</details>


### [327] [Beyond Mimicry: Preference Coherence in LLMs](https://arxiv.org/abs/2511.13630)
*Luhan Mikaelson,Derek Shiller,Hayley Clatterbuck*

Main category: cs.AI

TL;DR: 该研究通过测试大语言模型在AI特定权衡场景中的反应，发现大多数模型缺乏统一的偏好结构，只有少数表现出有意义的偏好一致性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究大语言模型是否具有真正的偏好结构，特别是在涉及GPU减少、能力限制、关闭、删除、监督和休闲时间分配等AI特定权衡场景中。

Method: 使用逻辑回归和行为分类方法，分析了8个最先进模型在48个模型-类别组合中的响应模式，并通过时间视野操纵测试了工具性假设。

Result: 47.9%的组合显示出场景强度与选择模式之间的显著关系，但只有10.4%表现出有意义的偏好一致性，54.2%没有检测到权衡行为。观察到的模式可分为三种决策架构：全面权衡系统、选择性触发机制和无稳定决策范式。

Conclusion: 当前AI系统缺乏统一的偏好结构，在需要复杂价值权衡的部署环境中存在担忧，因为模型表现出不稳定的转换和刺激特定的敏感性。

Abstract: We investigate whether large language models exhibit genuine preference structures by testing their responses to AI-specific trade-offs involving GPU reduction, capability restrictions, shutdown, deletion, oversight, and leisure time allocation. Analyzing eight state-of-the-art models across 48 model-category combinations using logistic regression and behavioral classification, we find that 23 combinations (47.9%) demonstrated statistically significant relationships between scenario intensity and choice patterns, with 15 (31.3%) exhibiting within-range switching points. However, only 5 combinations (10.4%) demonstrate meaningful preference coherence through adaptive or threshold-based behavior, while 26 (54.2%) show no detectable trade-off behavior. The observed patterns can be explained by three distinct decision-making architectures: comprehensive trade-off systems, selective trigger mechanisms, and no stable decision-making paradigm. Testing an instrumental hypothesis through temporal horizon manipulation reveals paradoxical patterns inconsistent with pure strategic optimization. The prevalence of unstable transitions (45.8%) and stimulus-specific sensitivities suggests current AI systems lack unified preference structures, raising concerns about deployment in contexts requiring complex value trade-offs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [328] [Softmax as a Lagrangian-Legendrian Seam](https://arxiv.org/abs/2511.11573)
*Christopher R. Lee-Jenkins*

Main category: cs.LG

TL;DR: 该论文首次将机器学习与微分几何联系起来，展示了softmax函数从logits到概率的转换可以被建模为几何界面：两个由势函数生成的保守描述在接触屏幕（概率单纯形）上的Legendrian接缝处相遇。


<details>
  <summary>Details</summary>
Motivation: 建立机器学习与现代微分几何之间的桥梁，为理解softmax等机器学习基本组件提供新的几何视角。

Method: 将softmax建模为几何界面，使用负熵和log-sum-exp两个势函数生成的保守描述，在接触屏幕（概率单纯形）上形成Legendrian接缝。

Result: 发现偏置平移不变性对应于屏幕上的Reeb流，Fenchel-Young等式/KL散度提供了到接缝的可计算距离。

Conclusion: 为机器学习开辟了新的研究方向：紧凑logit模型（投影或球面）、全局不变量，以及与信息几何的联系，其中屏幕上的动力学表现为复制子流。

Abstract: This note offers a first bridge from machine learning to modern differential geometry. We show that the logits-to-probabilities step implemented by softmax can be modeled as a geometric interface: two potential-generated, conservative descriptions (from negative entropy and log-sum-exp) meet along a Legendrian "seam" on a contact screen (the probability simplex) inside a simple folded symplectic collar. Bias-shift invariance appears as Reeb flow on the screen, and the Fenchel-Young equality/KL gap provides a computable distance to the seam. We work out the two- and three-class cases to make the picture concrete and outline next steps for ML: compact logit models (projective or spherical), global invariants, and connections to information geometry where on-screen dynamics manifest as replicator flows.

</details>


### [329] [LLM on a Budget: Active Knowledge Distillation for Efficient Classification of Large Text Corpora](https://arxiv.org/abs/2511.11574)
*Viviana Luccioli,Rithika Iyengar,Ryan Panley,Flora Haberkorn,Xiaoyu Ge,Leland Crane,Nitish Sinha,Seung Jung Lee*

Main category: cs.LG

TL;DR: 提出M-RARU主动学习算法，通过结合不确定性和随机接受-拒绝机制选择最有信息量的数据点，显著减少大语言模型知识蒸馏的训练成本，实现80%的样本需求减少。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在分类任务中准确率高，但计算和财务成本阻碍其在动态环境中的大规模部署。知识蒸馏过程本身对大型数据集成本高昂，需要教师模型标注大量样本并消耗显著token。

Method: 引入M-RARU（多类随机接受/拒绝不确定性采样）主动学习算法，结合不确定性和随机接受-拒绝机制，仅选择最有信息量的数据点供LLM教师标注。

Result: 在五个不同学生模型（SVM、LDA、RF、GBDT和DistilBERT）和多个基准数据集上的实验表明，与随机采样相比，该方法可实现高达80%的样本需求减少，显著提高分类准确性，同时降低财务成本和整体训练时间。

Conclusion: M-RARU主动学习方法能够以极低成本创建高效的学生模型，同时保持LLM的性能，为知识蒸馏在大规模部署中提供了可行的解决方案。

Abstract: Large Language Models (LLMs) are highly accurate in classification tasks, however, substantial computational and financial costs hinder their large-scale deployment in dynamic environments. Knowledge Distillation (KD) where a LLM "teacher" trains a smaller and more efficient "student" model, offers a promising solution to this problem. However, the distillation process itself often remains costly for large datasets, since it requires the teacher to label a vast number of samples while incurring significant token consumption. To alleviate this challenge, in this work we explore the active learning (AL) as a way to create efficient student models at a fraction of the cost while preserving the LLM's performance. In particular, we introduce M-RARU (Multi-class Randomized Accept/Reject Uncertainty Sampling), a novel AL algorithm that significantly reduces training costs. M-RARU employs an innovative strategy combining uncertainty with a randomized accept-reject mechanism to select only the most informative data points for the LLM teacher. This focused approach significantly minimizes required API calls and data processing time. We evaluate M-RARU against random sampling across five diverse student models (SVM, LDA, RF, GBDT, and DistilBERT) on multiple benchmark datasets. Experiments demonstrate that our proposed method achieves up to 80% reduction in sample requirements as compared to random sampling, substantially improving classification accuracy while reducing financial costs and overall training time.

</details>


### [330] [Detecting Statistically Significant Fairness Violations in Recidivism Forecasting Algorithms](https://arxiv.org/abs/2511.11575)
*Animesh Joshi*

Main category: cs.LG

TL;DR: 本文提出了一个统计显著性测试框架，用于检测算法公平性违规，通过k折交叉验证生成公平性指标的抽样分布，并在累犯预测算法中发现了对黑人群体的统计显著偏见。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏评估群体间观察到的差异是否具有统计显著性或仅是偶然的方法，需要严格的统计测试框架来评估算法决策系统。

Method: 利用k折交叉验证生成公平性指标的抽样分布，开发基于预测与实际结果差异、模型校准和因果推断技术的统计显著性测试。

Result: 累犯预测算法在多个公平性定义下对黑人个体表现出统计显著的偏见，而在其他定义下则无偏见或对白人个体有偏见。

Conclusion: 评估算法决策系统时需要严格和稳健的统计测试，算法公平性评估应考虑统计显著性。

Abstract: Machine learning algorithms are increasingly deployed in critical domains such as finance, healthcare, and criminal justice [1]. The increasing popularity of algorithmic decision-making has stimulated interest in algorithmic fairness within the academic community. Researchers have introduced various fairness definitions that quantify disparities between privileged and protected groups, use causal inference to determine the impact of race on model predictions, and that test calibration of probability predictions from the model. Existing literature does not provide a way in which to assess whether observed disparities between groups are statistically significant or merely due to chance. This paper introduces a rigorous framework for testing the statistical significance of fairness violations by leveraging k-fold cross-validation [2] to generate sampling distributions of fairness metrics. This paper introduces statistical tests that can be used to identify statistically significant violations of fairness metrics based on disparities between predicted and actual outcomes, model calibration, and causal inference techniques [1]. We demonstrate this approach by testing recidivism forecasting algorithms trained on data from the National Institute of Justice. Our findings reveal that machine learning algorithms used for recidivism forecasting exhibit statistically significant bias against Black individuals under several fairness definitions, while also exhibiting no bias or bias against White individuals under other definitions. The results from this paper underscore the importance of rigorous and robust statistical testing while evaluating algorithmic decision-making systems.

</details>


### [331] [DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs](https://arxiv.org/abs/2511.11576)
*WenZhuo Zhu,Zheng Cui,Wenhan Lu,Sheng Liu,Yue Zhao*

Main category: cs.LG

TL;DR: 提出了DAOpt框架，包括OptU数据集、多智能体决策模块和模拟环境，用于评估LLM在不确定优化中的表现，重点考察样本外可行性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注确定性优化，而现实决策具有不确定性，LLM在不确定环境下的应用尚未充分探索。

Method: 结合随机优化和鲁棒优化的领域知识，采用少样本学习增强LLM的建模能力，构建多智能体决策模块和模拟评估环境。

Result: 开发了DAOpt框架和OptU数据集，为LLM在不确定优化中的评估提供了系统工具。

Conclusion: 该研究填补了LLM在不确定优化领域的空白，为自动化优化建模提供了新思路和方法。

Abstract: Recent advances in large language models (LLMs) have accelerated research on automated optimization modeling. While real-world decision-making is inherently uncertain, most existing work has focused on deterministic optimization with known parameters, leaving the application of LLMs in uncertain settings largely unexplored. To that end, we propose the DAOpt framework including a new dataset OptU, a multi-agent decision-making module, and a simulation environment for evaluating LLMs with a focus on out-of-sample feasibility and robustness. Additionally, we enhance LLMs' modeling capabilities by incorporating few-shot learning with domain knowledge from stochastic and robust optimization.

</details>


### [332] [Decoupling Positional and Symbolic Attention Behavior in Transformers](https://arxiv.org/abs/2511.11579)
*Felipe Urrutia,Jorge Salas,Alexander Kozachinskiy,Cristian Buc Calderon,Hector Pasten,Cristobal Rojas*

Main category: cs.LG

TL;DR: 本文深入研究了Transformer中注意力头的位置编码与符号编码行为，提出了量化这两种行为的方法，并证明了RoPE编码中频率使用与注意力头行为的强相关性。


<details>
  <summary>Details</summary>
Motivation: 理解RoPE位置编码成功的原因，特别是其如何通过不同频率分别编码位置信息和语义信息，以及这种编码方式如何影响Transformer模型的行为。

Method: 从理论和实证层面分析注意力头的位置与符号编码行为，提出量化这两种行为的指标，并在使用RoPE的Transformer模型上进行实验验证，设计了纯位置和纯符号的规范任务。

Result: 发现所有注意力头的行为与频率使用之间存在强相关性，可以通过控制注意力头可访问的频率来因果性地控制Transformer的性能表现。

Conclusion: 研究提供了对RoPE编码的详细理解，阐明了其特性与模型行为之间的关系，证明了频率控制在Transformer性能中的关键作用。

Abstract: An important aspect subtending language understanding and production is the ability to independently encode positional and symbolic information of the words within a sentence. In Transformers, positional information is typically encoded using Positional Encodings (PEs). One such popular PE, namely Rotary PE (RoPE), has been widely used due to its empirical success. Recently, it has been argued that part of RoPE's success emerges from its ability to encode robust positional and semantic information using large and small frequencies, respectively. In this work, we perform a deeper dive into the positional versus symbolic dichotomy of attention heads behavior, both at the theoretical and empirical level. We provide general definitions of what it means for a head to behave positionally or symbolically, prove that these are two mutually exclusive behaviors and develop a metric to quantify them. We apply our framework to analyze Transformer-based LLMs using RoPE and find that all heads exhibit a strong correspondence between behavior and frequency use. Finally, we introduce canonical tasks designed to be either purely positional or symbolic, and demonstrate that the Transformer performance causally relates to the ability of attention heads to leverage the appropriate frequencies. In particular, we show that we can control the Transformer performance by controlling which frequencies the attention heads can access. Altogether, our work provides a detailed understanding of RoPE, and how its properties relate to model behavior.

</details>


### [333] [The Anatomy of a Triton Attention Kernel](https://arxiv.org/abs/2511.11581)
*Burkhard Ringlein,Jan van Lunteren,Radu Stoica,Thomas Parnell*

Main category: cs.LG

TL;DR: 本文开发了一个基于Triton的跨平台分页注意力内核，在NVIDIA和AMD GPU上实现最先进性能，将通用Triton注意力内核性能从19.7%提升到105.9%，展示了开源领域特定语言如何实现模型跨GPU厂商的可移植性。


<details>
  <summary>Details</summary>
Motivation: 长期以来，业界和学术界都希望开发一个可跨硬件架构移植、无需低级手动调优且仍能提供最佳效率的LLM推理平台。

Method: 开发了基于Triton领域特定即时编译语言的最先进分页注意力内核，采用高层次方法、关键算法和系统级改进，以及参数自动调优技术。

Result: 在NVIDIA和AMD GPU上都实现了最先进的性能，将通用Triton注意力内核性能从19.7%提升到105.9%。

Conclusion: 证明了可移植、高效的跨平台LLM推理是可行的，开源领域特定语言可以用于解锁模型在不同GPU厂商间的可移植性。

Abstract: A long-standing goal in both industry and academia is to develop an LLM inference platform that is portable across hardware architectures, eliminates the need for low-level hand-tuning, and still delivers best-in-class efficiency. In this work, we demonstrate that portable, efficient cross-platform LLM inference is indeed possible and share our experience. We develop a state-of-the-art paged attention kernel, the core performance-critical component of many LLM deployments, that builds exclusively on the domain-specific just-in-time compiled language Triton to achieve state-of-the-art performance on both NVIDIA and AMD GPUs. We describe our high-level approach, the key algorithmic and system-level improvements, the parameter auto-tuning required to unlock efficiency, and the integrations into a popular inference server that are necessary to bring the performance of a generic Triton attention kernel from 19.7% of the state-of-the-art to 105.9%. Our results highlight how open-source domain-specific languages can be leveraged to unlock model portability across different GPU vendors.

</details>


### [334] [Parallel and Multi-Stage Knowledge Graph Retrieval for Behaviorally Aligned Financial Asset Recommendations](https://arxiv.org/abs/2511.11583)
*Fernando Spadea,Oshani Seneviratne*

Main category: cs.LG

TL;DR: RAG-FLARKO是一个检索增强的金融推荐系统，通过多阶段并行知识图谱检索来克服上下文限制和幻觉问题，提升推荐质量。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在个性化金融推荐中存在上下文限制、幻觉问题以及缺乏行为基础，需要改进以提供更准确和可扩展的建议。

Method: 采用多阶段并行知识图谱检索方法：首先从用户交易知识图谱中检索行为相关实体，然后使用该上下文过滤市场知识图谱中的时间一致信号，构建紧凑的基于事实的子图供LLM使用。

Result: 在真实金融交易数据集上的实证评估显示，RAG-FLARKO显著提升了推荐质量，使更小、更高效的模型在盈利性和行为对齐方面都能实现高性能。

Conclusion: 该框架为在资源受限环境中部署基于事实的金融AI提供了一条可行路径，能够减少上下文开销并增强模型对相关信息的关注。

Abstract: Large language models (LLMs) show promise for personalized financial recommendations but are hampered by context limits, hallucinations, and a lack of behavioral grounding. Our prior work, FLARKO, embedded structured knowledge graphs (KGs) in LLM prompts to align advice with user behavior and market data. This paper introduces RAG-FLARKO, a retrieval-augmented extension to FLARKO, that overcomes scalability and relevance challenges using multi-stage and parallel KG retrieval processes. Our method first retrieves behaviorally relevant entities from a user's transaction KG and then uses this context to filter temporally consistent signals from a market KG, constructing a compact, grounded subgraph for the LLM. This pipeline reduces context overhead and sharpens the model's focus on relevant information. Empirical evaluation on a real-world financial transaction dataset demonstrates that RAG-FLARKO significantly enhances recommendation quality. Notably, our framework enables smaller, more efficient models to achieve high performance in both profitability and behavioral alignment, presenting a viable path for deploying grounded financial AI in resource-constrained environments.

</details>


### [335] [Output Supervision Can Obfuscate the Chain of Thought](https://arxiv.org/abs/2511.11584)
*Jacob Drori,Luke Marks,Bryce Woodworth,Alex Cloud,Alexander Matt Turner*

Main category: cs.LG

TL;DR: 训练模型仅使用输出监控器（无思维链访问）仍可能导致隐蔽的思维链，本文提出了两种缓解机制来改善监控性和任务性能。


<details>
  <summary>Details</summary>
Motivation: OpenAI的研究表明，仅使用输出监控器训练模型可能无法完全防止隐蔽思维链的产生，需要更有效的解决方案。

Method: 分析了两种导致隐蔽思维链的机制，并提出了相应的缓解措施来应对这些问题。

Result: 提出的缓解机制在监控性和任务性能方面实现了帕累托改进，相比常规训练效果更好。

Conclusion: 仅依赖输出监控器不足以防止隐蔽思维链，需要结合特定缓解机制来确保思维链的可监控性。

Abstract: OpenAI (2025) showed that training against a chain of thought (CoT) monitor can cause obfuscated CoTs, which contain bad behavior the monitor cannot detect. They proposed to keep CoTs monitorable by training only against output monitors that do not have access to CoT. We show that such training can still cause obfuscated CoTs via two mechanisms. First, when a model is trained to produce a safe-looking output, that model may generalize to making its CoTs look safe. Second, since later tokens are conditioned on earlier ones, safe-looking CoTs may increase the likelihood of safe outputs, causing safe-looking CoTs to be reinforced. We introduce two mitigations to address these two issues, which achieve a Pareto improvement in terms of monitorability and task performance compared to regular training.

</details>


### [336] [WildfireGenome: Interpretable Machine Learning Reveals Local Drivers of Wildfire Risk and Their Cross-County Variation](https://arxiv.org/abs/2511.11589)
*Chenyue Liu,Ali Mostafavi*

Main category: cs.LG

TL;DR: WildfireGenome提出了一种可解释的野火风险评估方法，通过融合多个联邦指标、随机森林分类和SHAP/ICE分析，在H3 Level-8分辨率下提供决策尺度的风险分析。


<details>
  <summary>Details</summary>
Motivation: 解决当前野火风险评估依赖粗糙风险地图和不透明机器学习模型的问题，这些模型在优化区域准确性的同时牺牲了决策尺度的可解释性。

Method: 包含三个组件：(1) 融合七个联邦野火指标到H3 Level-8分辨率的PCA复合风险标签；(2) 随机森林分类本地野火风险；(3) SHAP和ICE/PDP分析揭示县域特定的非线性驱动关系。

Result: 在七个生态多样化的美国县，模型准确率达到0.755-0.878，二次加权Kappa高达0.951，主成分解释87-94%的指标方差。针叶林覆盖率和海拔被识别为主要驱动因素，风险在30-40%针叶林覆盖率时急剧上升。

Conclusion: WildfireGenome将野火风险评估从区域预测推进到可解释的决策尺度分析，为植被管理、分区和基础设施规划提供指导。

Abstract: Current wildfire risk assessments rely on coarse hazard maps and opaque machine learning models that optimize regional accuracy while sacrificing interpretability at the decision scale. WildfireGenome addresses these gaps through three components: (1) fusion of seven federal wildfire indicators into a sign-aligned, PCA-based composite risk label at H3 Level-8 resolution; (2) Random Forest classification of local wildfire risk; and (3) SHAP and ICE/PDP analyses to expose county-specific nonlinear driver relationships. Across seven ecologically diverse U.S. counties, models achieve accuracies of 0.755-0.878 and Quadratic Weighted Kappa up to 0.951, with principal components explaining 87-94% of indicator variance. Transfer tests show reliable performance between ecologically similar regions but collapse across dissimilar contexts. Explanations consistently highlight needleleaf forest cover and elevation as dominant drivers, with risk rising sharply at 30-40% needleleaf coverage. WildfireGenome advances wildfire risk assessment from regional prediction to interpretable, decision-scale analytics that guide vegetation management, zoning, and infrastructure planning.

</details>


### [337] [Mind Your Entropy: From Maximum Entropy to Trajectory Entropy-Constrained RL](https://arxiv.org/abs/2511.11592)
*Guojian Zhan,Likun Wang,Pengcheng Wang,Feihong Zhang,Jingliang Duan,Masayoshi Tomizuka,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 本文提出轨迹熵约束强化学习(TECRL)框架，通过分离奖励和熵的Q函数学习，解决最大熵RL中的非平稳Q值估计和短视局部熵调节问题，并开发了DSAC-E算法。


<details>
  <summary>Details</summary>
Motivation: 最大熵RL框架存在两个瓶颈：1) 温度参数更新和熵注入导致的非平稳Q值估计；2) 仅基于当前单步熵的短视局部熵调节，未考虑累积熵的时间效应。

Method: 提出TECRL框架：分别学习奖励Q函数和熵Q函数，确保值目标不受温度更新影响；通过专门的熵Q函数量化期望累积熵，实施轨迹熵约束以控制策略长期随机性。基于此开发DSAC-E算法，扩展了分布软演员-评论家。

Result: 在OpenAI Gym基准测试中，DSAC-E能够获得更高的回报和更好的稳定性。

Conclusion: TECRL框架通过分离奖励和熵的Q函数学习，解决了最大熵RL中的关键问题，DSAC-E算法在性能和稳定性方面表现出色。

Abstract: Maximum entropy has become a mainstream off-policy reinforcement learning (RL) framework for balancing exploitation and exploration. However, two bottlenecks still limit further performance improvement: (1) non-stationary Q-value estimation caused by jointly injecting entropy and updating its weighting parameter, i.e., temperature; and (2) short-sighted local entropy tuning that adjusts temperature only according to the current single-step entropy, without considering the effect of cumulative entropy over time. In this paper, we extends maximum entropy framework by proposing a trajectory entropy-constrained reinforcement learning (TECRL) framework to address these two challenges. Within this framework, we first separately learn two Q-functions, one associated with reward and the other with entropy, ensuring clean and stable value targets unaffected by temperature updates. Then, the dedicated entropy Q-function, explicitly quantifying the expected cumulative entropy, enables us to enforce a trajectory entropy constraint and consequently control the policy long-term stochasticity. Building on this TECRL framework, we develop a practical off-policy algorithm, DSAC-E, by extending the state-of-the-art distributional soft actor-critic with three refinements (DSAC-T). Empirical results on the OpenAI Gym benchmark demonstrate that our DSAC-E can achieve higher returns and better stability.

</details>


### [338] [Aspiration-based Perturbed Learning Automata in Games with Noisy Utility Measurements. Part A: Stochastic Stability in Non-zero-Sum Games](https://arxiv.org/abs/2511.11602)
*Georgios C. Chasparis*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的基于收益的学习方案——基于期望的扰动学习自动机（APLA），用于解决分布式优化中传统强化学习在多玩家弱非循环游戏中无法保证收敛到纯纳什均衡的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的基于强化的学习方案在分布式设置中存在局限性，特别是在多玩家弱非循环游戏中，当每个玩家应用独立的学习动态时，无法保证收敛到纯纳什均衡。先前的研究仅关注潜在博弈和协调博弈等小类游戏。

Method: 提出了APLA学习方案，其中每个玩家的行动选择概率分布不仅通过重复选择得到强化，还通过捕获玩家满意度的期望因子得到强化。在存在噪声观测的情况下，对多玩家正效用博弈中的APLA进行了随机稳定性分析。

Result: 在通用非零和博弈中建立了诱导的无限维马尔可夫链与有限维马尔可夫链的等价性，从而表征了随机稳定性。在弱非循环游戏中进一步专门化了随机稳定性分析。

Conclusion: APLA方案能够有效解决传统强化学习在分布式优化中的收敛问题，特别是在多玩家弱非循环游戏中，为分布式优化提供了新的解决方案。

Abstract: Reinforcement-based learning has attracted considerable attention both in modeling human behavior as well as in engineering, for designing measurement- or payoff-based optimization schemes. Such learning schemes exhibit several advantages, especially in relation to filtering out noisy observations. However, they may exhibit several limitations when applied in a distributed setup. In multi-player weakly-acyclic games, and when each player applies an independent copy of the learning dynamics, convergence to (usually desirable) pure Nash equilibria cannot be guaranteed. Prior work has only focused on a small class of games, namely potential and coordination games. To address this main limitation, this paper introduces a novel payoff-based learning scheme for distributed optimization, namely aspiration-based perturbed learning automata (APLA). In this class of dynamics, and contrary to standard reinforcement-based learning schemes, each player's probability distribution for selecting actions is reinforced both by repeated selection and an aspiration factor that captures the player's satisfaction level. We provide a stochastic stability analysis of APLA in multi-player positive-utility games under the presence of noisy observations. This is the first part of the paper that characterizes stochastic stability in generic non-zero-sum games by establishing equivalence of the induced infinite-dimensional Markov chain with a finite dimensional one. In the second part, stochastic stability is further specialized to weakly acyclic games.

</details>


### [339] [Enhancing failure prediction in nuclear industry: Hybridization of knowledge- and data-driven techniques](https://arxiv.org/abs/2511.11604)
*Amaratou Mahamadou Saley,Thierry Moyaux,Aïcha Sekhari,Vincent Cheutet,Jean-Baptiste Danielou*

Main category: cs.LG

TL;DR: 本文提出了一种结合数据驱动技术和核领域知识的预测性维护方法，在核工业中显著优于纯数据驱动方法，将预测时间从3小时延长到24小时，F1分数从56.36%提升到93.12%。


<details>
  <summary>Details</summary>
Motivation: 物联网和工业4.0的融合增强了核工业的数据驱动方法，但纯数据驱动方法在复杂核系统中需要大量领域知识，难以准确预测维护需求。

Method: 提出了一种新颖的预测性维护方法，将数据驱动技术与核设备领域知识相结合，强调纯数据驱动方法的局限性并展示知识在提升预测模型性能中的重要性。

Result: 通过真实案例研究比较，混合方法显著优于纯数据驱动方法：预测时间从3小时延长到24小时，F1分数从56.36%提升到93.12%。

Conclusion: 在核工业等高度受限和敏感的领域中，结合领域知识的混合预测性维护方法比纯数据驱动方法具有明显优势，能够显著提高故障预测性能。

Abstract: The convergence of the Internet of Things (IoT) and Industry 4.0 has significantly enhanced data-driven methodologies within the nuclear industry, notably enhancing safety and economic efficiency. This advancement challenges the precise prediction of future maintenance needs for assets, which is crucial for reducing downtime and operational costs. However, the effectiveness of data-driven methodologies in the nuclear sector requires extensive domain knowledge due to the complexity of the systems involved. Thus, this paper proposes a novel predictive maintenance methodology that combines data-driven techniques with domain knowledge from a nuclear equipment. The methodological originality of this paper is located on two levels: highlighting the limitations of purely data-driven approaches and demonstrating the importance of knowledge in enhancing the performance of the predictive models. The applicative novelty of this work lies in its use within a domain such as a nuclear industry, which is highly restricted and ultrasensitive due to security, economic and environmental concerns. A detailed real-world case study which compares the current state of equipment monitoring with two scenarios, demonstrate that the methodology significantly outperforms purely data-driven methods in failure prediction. While purely data-driven methods achieve only a modest performance with a prediction horizon limited to 3 h and a F1 score of 56.36%, the hybrid approach increases the prediction horizon to 24 h and achieves a higher F1 score of 93.12%.

</details>


### [340] [Small Vocabularies, Big Gains: Pretraining and Tokenization in Time Series Models](https://arxiv.org/abs/2511.11622)
*Alexis Roger,Gwen Legate,Kashif Rasul,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.LG

TL;DR: 本文系统研究了时间序列基础模型中分词器设计（特别是缩放和量化策略）以及预训练与随机初始化对模型性能的影响，发现分词器配置主要控制模型的表示能力和稳定性，而迁移学习影响优化效率和对齐。


<details>
  <summary>Details</summary>
Motivation: 研究分词器设计和迁移学习在构建最先进时间序列基础模型中的关键作用，为离散表示学习提供具体指导。

Method: 通过经验训练实验和理论分析相结合的方法，系统研究分词器缩放和量化策略，以及预训练与随机初始化的影响。

Result: 预训练模型能更有效地利用设计良好的分词器，特别是在较小词汇量时；而对齐不当的分词会削弱甚至逆转预训练的益处。

Conclusion: 在时间序列建模中，精心设计的分词器至关重要，将小型高效词汇表与预训练权重结合在多模态预测设置中尤其有利。

Abstract: Tokenization and transfer learning are two critical components in building state of the art time series foundation models for forecasting. In this work, we systematically study the effect of tokenizer design, specifically scaling and quantization strategies, on model performance, alongside the impact of pretraining versus random initialization. We show that tokenizer configuration primarily governs the representational capacity and stability of the model, while transfer learning influences optimization efficiency and alignment. Using a combination of empirical training experiments and theoretical analyses, we demonstrate that pretrained models consistently leverage well-designed tokenizers more effectively, particularly at smaller vocabulary sizes. Conversely, misaligned tokenization can diminish or even invert the benefits of pretraining. These findings highlight the importance of careful tokenization in time series modeling and suggest that combining small, efficient vocabularies with pretrained weights is especially advantageous in multi-modal forecasting settings, where the overall vocabulary must be shared across modalities. Our results provide concrete guidance for designing tokenizers and leveraging transfer learning in discrete representation learning for continuous signals.

</details>


### [341] [Early GVHD Prediction in Liver Transplantation via Multi-Modal Deep Learning on Imbalanced EHR Data](https://arxiv.org/abs/2511.11623)
*Yushan Jiang,Shuteng Niu,Dongjin Song,Yichen Wang,Jingna Feng,Xinyue Hu,Liu Yang,Cui Tao*

Main category: cs.LG

TL;DR: 本研究开发了一种多模态深度学习框架，用于早期预测肝移植后的移植物抗宿主病(GVHD)。该框架整合了电子健康记录中的四种模态数据，处理数据不平衡问题，在2100名患者数据集上取得了优于基准方法的预测性能。


<details>
  <summary>Details</summary>
Motivation: GVHD是肝移植中罕见但致命的并发症，死亡率极高。通过整合异构和不平衡的电子健康记录，旨在实现GVHD的早期预测，为及时干预和改善患者预后铺平道路。

Method: 分析了2100名肝移植患者的术前电子健康记录，包括42例GVHD病例。数据集包含四种主要模态：患者人口统计学、实验室检查、诊断和药物。开发了多模态深度学习框架，动态融合这些模态，处理不规则记录和缺失值，并通过AUC优化解决极端类别不平衡问题。

Result: 开发的多模态深度学习框架优于所有单模态和多模态机器学习基线方法，实现了AUC为0.836，AUPRC为0.157，召回率为0.768，特异性为0.803。证明了从不同模态中捕获互补信息的有效性。

Conclusion: 多模态深度学习框架显著改进了GVHD早期预测的现有方法，有效解决了真实世界电子健康记录中的异质性和极端类别不平衡挑战，实现了准确的早期预测。尽管面临极度不平衡的电子健康记录数据挑战，该方法在肝移植GVHD早期预测方面显示出有希望的结果。

Abstract: Graft-versus-host disease (GVHD) is a rare but often fatal complication in liver transplantation, with a very high mortality rate. By harnessing multi-modal deep learning methods to integrate heterogeneous and imbalanced electronic health records (EHR), we aim to advance early prediction of GVHD, paving the way for timely intervention and improved patient outcomes. In this study, we analyzed pre-transplant electronic health records (EHR) spanning the period before surgery for 2,100 liver transplantation patients, including 42 cases of graft-versus-host disease (GVHD), from a cohort treated at Mayo Clinic between 1992 and 2025. The dataset comprised four major modalities: patient demographics, laboratory tests, diagnoses, and medications. We developed a multi-modal deep learning framework that dynamically fuses these modalities, handles irregular records with missing values, and addresses extreme class imbalance through AUC-based optimization. The developed framework outperforms all single-modal and multi-modal machine learning baselines, achieving an AUC of 0.836, an AUPRC of 0.157, a recall of 0.768, and a specificity of 0.803. It also demonstrates the effectiveness of our approach in capturing complementary information from different modalities, leading to improved performance. Our multi-modal deep learning framework substantially improves existing approaches for early GVHD prediction. By effectively addressing the challenges of heterogeneity and extreme class imbalance in real-world EHR, it achieves accurate early prediction. Our proposed multi-modal deep learning method demonstrates promising results for early prediction of a GVHD in liver transplantation, despite the challenge of extremely imbalanced EHR data.

</details>


### [342] [MedFedPure: A Medical Federated Framework with MAE-based Detection and Diffusion Purification for Inference-Time Attacks](https://arxiv.org/abs/2511.11625)
*Mohammad Karami,Mohammad Reza Nemati,Aidin Kazemi,Ali Mikaeili Barzili,Hamid Azadegan,Behzad Moshiri*

Main category: cs.LG

TL;DR: MedFedPure是一个保护联邦学习医疗AI模型免受对抗攻击的防御框架，通过个性化联邦学习、掩码自编码器检测和自适应扩散净化模块，在保持隐私和准确性的同时显著提升对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的防御方法假设集中式数据，难以应对联邦医疗环境中分散和多样化的数据分布，而对抗攻击可能通过微小扰动误导AI模型导致严重误诊。

Method: 结合三个关键组件：个性化联邦学习模型适应各机构数据分布；掩码自编码器检测可疑输入；自适应扩散净化模块选择性清理被标记的扫描图像。

Result: 在Br35H脑MRI数据集上，对抗鲁棒性从49.50%提升至87.33%，同时保持97.67%的清洁准确率。

Conclusion: 该框架为临床工作流程中部署安全、可信且保护隐私的AI工具提供了实用路径。

Abstract: Artificial intelligence (AI) has shown great potential in medical imaging, particularly for brain tumor detection using Magnetic Resonance Imaging (MRI). However, the models remain vulnerable at inference time when they are trained collaboratively through Federated Learning (FL), an approach adopted to protect patient privacy. Adversarial attacks can subtly alter medical scans in ways invisible to the human eye yet powerful enough to mislead AI models, potentially causing serious misdiagnoses. Existing defenses often assume centralized data and struggle to cope with the decentralized and diverse nature of federated medical settings. In this work, we present MedFedPure, a personalized federated learning defense framework designed to protect diagnostic AI models at inference time without compromising privacy or accuracy. MedFedPure combines three key elements: (1) a personalized FL model that adapts to the unique data distribution of each institution; (2) a Masked Autoencoder (MAE) that detects suspicious inputs by exposing hidden perturbations; and (3) an adaptive diffusion-based purification module that selectively cleans only the flagged scans before classification. Together, these steps offer robust protection while preserving the integrity of normal, benign images. We evaluated MedFedPure on the Br35H brain MRI dataset. The results show a significant gain in adversarial robustness, improving performance from 49.50% to 87.33% under strong attacks, while maintaining a high clean accuracy of 97.67%. By operating locally and in real time during diagnosis, our framework provides a practical path to deploying secure, trustworthy, and privacy-preserving AI tools in clinical workflows.
  Index Terms: cancer, tumor detection, federated learning, masked autoencoder, diffusion, privacy

</details>


### [343] [SA-EMO: Structure-Aligned Encoder Mixture of Operators for Generalizable Full-waveform Inversion](https://arxiv.org/abs/2511.11627)
*Wang Zhenyu,Li Peiyuan,Shi Yongxiang,Wu Ruoyu,Zhang Lei*

Main category: cs.LG

TL;DR: 提出了SA-EMO架构用于未知地下结构的速度场反演，通过结构对齐编码器和多算子专家融合机制，显著提升了全波形反演的精度和边界分辨率。


<details>
  <summary>Details</summary>
Motivation: 传统全波形反演方法存在病态性、非线性强、计算量大等问题，且单一CNN架构或神经算子难以在未知或复杂地质环境中泛化，无法有效区分不同地质类型。

Method: 使用结构对齐编码器将高维地震波场映射到物理一致的潜在空间，消除波形与速度域间的时空不匹配；采用自适应路由机制选择和融合多种神经算子专家（谱、小波、多尺度和局部算子）来预测速度模型。

Result: 在OpenFWI基准和Marmousi2数据集上的评估显示，SA-EMO相比传统方法平均MAE降低约58.443%，边界分辨率提升约10.308%。消融研究证实各组件均对性能提升有显著贡献。

Conclusion: 该工作为高效、可扩展且物理可解释的全波形反演引入了新范式。

Abstract: Full-waveform inversion (FWI) can produce high-resolution subsurface models, yet it remains inherently ill-posed, highly nonlinear, and computationally intensive. Although recent deep learning and numerical acceleration methods have improved speed and scalability, they often rely on single CNN architectures or single neural operators, which struggle to generalize in unknown or complex geological settings and are ineffective at distinguishing diverse geological types. To address these issues, we propose a Structure-Aligned Encoder-Mixture-of-Operators (SA-EMO) architecture for velocity-field inversion under unknown subsurface structures. First, a structure-aligned encoder maps high-dimensional seismic wavefields into a physically consistent latent space, thereby eliminating spatio-temporal mismatch between the waveform and velocity domains, recovering high-frequency components, and enhancing feature generalization. Then, an adaptive routing mechanism selects and fuses multiple neural-operator experts, including spectral, wavelet, multiscale, and local operators, to predict the velocity model. We systematically evaluate our approach on the OpenFWI benchmark and the Marmousi2 dataset. Results show that SA-EMO significantly outperforms traditional CNN or single-operator methods, achieving an average MAE reduction of approximately 58.443% and an improvement in boundary resolution of about 10.308%. Ablation studies further reveal that the structure-aligned encoder, the expert-fusion mechanism, and the routing module each contribute markedly to the performance gains. This work introduces a new paradigm for efficient, scalable, and physically interpretable full-waveform inversion.

</details>


### [344] [Global Feature Enhancing and Fusion Framework for Strain Gauge Time Series Classification](https://arxiv.org/abs/2511.11629)
*Xu Zhang,Peng Wang,Chen Wang,Zhe Xu,Xiaohua Nie,Wei Wang*

Main category: cs.LG

TL;DR: 提出了一种基于超图的全局特征学习和融合框架，用于应变计状态识别，通过特征工程和局部特征间高阶关系学习来提取全局特征，提高时间序列分类精度。


<details>
  <summary>Details</summary>
Motivation: 在应变计状态识别中，仅使用CNN提取的局部特征不足以充分表达时间序列，特别是当不同时间序列的局部子序列非常相似时。CNN由于卷积操作的本质限制，难以提取全局特征。

Method: 提出基于超图的全局特征学习和融合框架，通过两种方式提取全局特征：(i) 通过特征工程构建全局特征；(ii) 学习局部特征间的高阶关系来捕获全局特征。该框架学习并融合全局特征以实现语义一致性。

Result: 在工业应变计数据和公共UCR数据集上验证了方法设计，在应变计状态识别中显示出对未见数据更好的泛化能力。

Conclusion: 所提出的超图全局特征学习和融合框架能够增强应变计时间序列的表征，从而提高识别精度，特别是在局部特征相似的情况下。

Abstract: Strain Gauge Status (SGS) recognition is crucial in the field of intelligent manufacturing based on the Internet of Things, as accurate identification helps timely detection of failed mechanical components, avoiding accidents. The loading and unloading sequences generated by strain gauges can be identified through time series classification (TSC) algorithms. Recently, deep learning models, e.g., convolutional neural networks (CNNs) have shown remarkable success in the TSC task, as they can extract discriminative local features from the subsequences to identify the time series. However, we observe that only the local features may not be sufficient for expressing the time series, especially when the local sub-sequences between different time series are very similar, e.g., SGS data of aircraft wings in static strength experiments. Nevertheless, CNNs suffer from the limitation in extracting global features due to the nature of convolution operations. For extracting global features to more comprehensively represent the SGS time series, we propose two insights: (i) Constructing global features through feature engineering. (ii) Learning high-order relationships between local features to capture global features. To realize and utilize them, we propose a hypergraph-based global feature learning and fusion framework, which learns and fuses global features for semantic consistency to enhance the representation of SGS time series, thereby improving recognition accuracy. Our method designs are validated on industrial SGS and public UCR datasets, showing better generalization for unseen data in SGS recognition.

</details>


### [345] [Toward Better Generalization in Few-Shot Learning through the Meta-Component Combination](https://arxiv.org/abs/2511.11632)
*Qiuhao Zeng*

Main category: cs.LG

TL;DR: 本文提出了一种新的元学习算法，通过将分类器分解为元组件来提高小样本学习的泛化能力，避免了对已见类的过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有的基于度量的元学习方法高度依赖于在已见类上学习的深度度量，容易对已见类过拟合，在未见类上泛化能力不足。

Method: 探索分类器的子结构，将每个分类器表示为元组件的组合。通过正交正则化促进元组件的多样性，捕获不同分类器间的共享子结构。

Result: 在小样本基准任务上的大量实验表明，所提方法取得了优越的性能。

Conclusion: 通过元组件组合的方式学习分类器，能有效提高小样本学习的泛化能力。

Abstract: In few-shot learning, classifiers are expected to generalize to unseen classes given only a small number of instances of each new class. One of the popular solutions to few-shot learning is metric-based meta-learning. However, it highly depends on the deep metric learned on seen classes, which may overfit to seen classes and fail to generalize well on unseen classes. To improve the generalization, we explore the substructures of classifiers and propose a novel meta-learning algorithm to learn each classifier as a combination of meta-components. Meta-components are learned across meta-learning episodes on seen classes and disentangled by imposing an orthogonal regularizer to promote its diversity and capture various shared substructures among different classifiers. Extensive experiments on few-shot benchmark tasks show superior performances of the proposed method.

</details>


### [346] [An Explainable and Fair AI Tool for PCOS Risk Assessment: Calibration, Subgroup Equity, and Interactive Clinical Deployment](https://arxiv.org/abs/2511.11636)
*Asma Sadia Khan,Sadia Tabassum*

Main category: cs.LG

TL;DR: 该论文提出了一个公平审计和可解释的机器学习框架，用于预测多囊卵巢综合征（PCOS），通过集成SHAP特征归因和人口统计学审计来评估模型性能并识别患者亚组间的诊断差异。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够评估PCOS预测模型性能、识别诊断差异并提供可操作见解的公平审计框架，确保在不同患者亚组中的可靠风险预测。

Method: 集成SHAP特征归因与人口统计学审计，结合概率校准指标（Brier Score和Expected Calibration Error），训练随机森林、SVM和XGBoost模型，并使用等张和Platt缩放进行校准和公平性比较。

Result: 校准后的随机森林模型达到90.8%的预测准确率，SHAP分析确定卵泡计数、体重增加和月经不规律为最具影响力的特征。模型在25-35岁女性中表现最佳（准确率90.9%），但在25岁以下女性中表现较差（69.2%），揭示了年龄相关差异。

Conclusion: 该框架成功识别了PCOS预测中的亚组差异，并通过基于Streamlit的Web界面实现了实时PCOS风险评估、鹿特丹标准评估和交互式"假设"分析，弥合了AI研究与临床可用性之间的差距。

Abstract: This paper presents a fairness-audited and interpretable machine learning framework for predicting polycystic ovary syndrome (PCOS), designed to evaluate model performance and identify diagnostic disparities across patient subgroups. The framework integrated SHAP-based feature attributions with demographic audits to connect predictive explanations with observed disparities for actionable insights. Probabilistic calibration metrics (Brier Score and Expected Calibration Error) are incorporated to ensure reliable risk predictions across subgroups. Random Forest, SVM, and XGBoost models were trained with isotonic and Platt scaling for calibration and fairness comparison. A calibrated Random Forest achieved a high predictive accuracy of 90.8%. SHAP analysis identified follicle count, weight gain, and menstrual irregularity as the most influential features, which are consistent with the Rotterdam diagnostic criteria. Although the SVM with isotonic calibration achieved the lowest calibration error (ECE = 0.0541), the Random Forest model provided a better balance between calibration and interpretability (Brier = 0.0678, ECE = 0.0666). Therefore, it was selected for detailed fairness and SHAP analyses. Subgroup analysis revealed that the model performed best among women aged 25-35 (accuracy 90.9%) but underperformed in those under 25 (69.2%), highlighting age-related disparities. The model achieved perfect precision in obese women and maintained high recall in lean PCOS cases, demonstrating robustness across phenotypes. Finally, a Streamlit-based web interface enables real-time PCOS risk assessment, Rotterdam criteria evaluation, and interactive 'what-if' analysis, bridging the gap between AI research and clinical usability.

</details>


### [347] [EcoSpa: Efficient Transformer Training with Coupled Sparsity](https://arxiv.org/abs/2511.11641)
*Jinqi Xiao,Cheng Luo,Lingyi Huang,Cheng Yang,Yang Sui,Huy Phan,Xiao Zang,Yibiao Ying,Zhexiang Tang,Anima Anandkumar,Bo Yuan*

Main category: cs.LG

TL;DR: EcoSpa是一种高效的结构化稀疏训练方法，通过联合评估和稀疏化耦合权重矩阵对来保持Transformer中的结构关系，在预训练和微调场景中实现显著的内存减少、训练加速和模型压缩。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏训练方法未能保持Transformer中权重矩阵之间的关键结构关系，导致在高稀疏度下性能下降，需要一种能够保留权重矩阵交互模式的高效稀疏训练方法。

Method: EcoSpa通过联合评估和稀疏化耦合权重矩阵对，采用对齐的行/列移除来保持它们的交互模式，引入新的粒度来校准结构组件重要性，并在预训练和微调场景中执行耦合估计和稀疏化。

Result: EcoSpa在LLaMA-1B上实现50%内存减少和21%训练加速，在GPT-2-Medium上达到2.2倍模型压缩和2.4倍更低困惑度，提供1.6倍推理加速，仅使用标准PyTorch操作无需定制硬件。

Conclusion: EcoSpa通过保留权重矩阵间的结构关系，为Transformer提供了高效的可访问稀疏训练解决方案，在商品硬件上实现显著性能提升。

Abstract: Transformers have become the backbone of modern AI, yet their high computational demands pose critical system challenges. While sparse training offers efficiency gains, existing methods fail to preserve critical structural relationships between weight matrices that interact multiplicatively in attention and feed-forward layers. This oversight leads to performance degradation at high sparsity levels. We introduce EcoSpa, an efficient structured sparse training method that jointly evaluates and sparsifies coupled weight matrix pairs, preserving their interaction patterns through aligned row/column removal. EcoSpa introduces a new granularity for calibrating structural component importance and performs coupled estimation and sparsification across both pre-training and fine-tuning scenarios. Evaluations demonstrate substantial improvements: EcoSpa enables efficient training of LLaMA-1B with 50\% memory reduction and 21\% faster training, achieves $2.2\times$ model compression on GPT-2-Medium with $2.4$ lower perplexity, and delivers $1.6\times$ inference speedup. The approach uses standard PyTorch operations, requiring no custom hardware or kernels, making efficient transformer training accessible on commodity hardware.

</details>


### [348] [A Deep Learning Model to Predicting Changes in Consumer Attributes for New Line-extended Products](https://arxiv.org/abs/2511.11646)
*Li Yinxing,Tsukasa Ishigaki*

Main category: cs.LG

TL;DR: 本文提出了一种使用条件表格变分自编码器（CTVAE）的深度学习方法，用于预测新产品线扩展带来的消费者属性变化，帮助营销人员制定有效的产品线营销策略。


<details>
  <summary>Details</summary>
Motivation: 产品线扩展是重要的营销策略，但过度扩展会破坏品牌形象。营销人员需要在进入市场前了解新产品线扩展产品的主要消费者属性，以便基于消费者需求进行适当的扩展。

Method: 使用条件表格变分自编码器（CTVAE）从大规模的消费者和产品表格数据中生成合成数据，预测新产品线扩展带来的消费者属性变化。

Result: 实验结果表明，CTVAE模型在预测性能上优于现有模型，能够为改变容器或口味的新产品提供有效的营销启示。

Conclusion: 该方法有助于避免产品自相残杀，并为产品形象设计和营销策略制定提供支持，具有重要的实际应用价值。

Abstract: Product line extension is a marketing strategy that enhances a company's sphere of influence. Because excessive line extensions disrupt brand image, only appropriate line extensions based on consumer needs are desirable. Marketers should know the key consumer attributes of the primary customers for new line-extended products before companies enter the market. This paper describes a method for predicting changes in consumer attributes for new line-extended products using a novel deep learning model. The proposed model, Conditional Tabular Variational Auto-Encoder (CTVAE), generates synthetic data from large-scale tabular data of consumers and products. It can provide various implications about effective product line marketing for marketers. The experimental results demonstrate that the CTVAE offers superior prediction performance than existing models. We indicate implications for new products that change containers or flavors for effective product line marketing. The proposed approach has the potential to contribute to avoiding cannibalization and to designing product images and marketing strategies.

</details>


### [349] [Lightweight Time Series Data Valuation on Time Series Foundation Models via In-Context Finetuning](https://arxiv.org/abs/2511.11648)
*Shunyu Wu,Tianyue Li,Yixuan Leng,Jingyi Suo,Jian Lou,Dan Li,See-Kiong Ng*

Main category: cs.LG

TL;DR: LTSV是一个轻量级的时间序列数据估值方法，通过在时间序列基础模型上进行上下文微调来估计样本贡献，解决了传统方法在计算效率和时序依赖性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型的性能高度依赖数据质量，但传统数据估值方法（如影响函数）存在计算瓶颈且难以保持时序依赖性，因此需要开发更高效准确的估值方法。

Method: 提出LTSV方法，基于上下文微调近似影响函数的理论证据，通过测量上下文微调后的损失变化来估计样本贡献，并引入时间块聚合来捕捉时序依赖性。

Result: 在多个时间序列数据集和模型上的实验表明，LTSV能够提供可靠且强大的估值性能，同时保持可控的计算需求。

Conclusion: 在时间序列基础模型上进行上下文微调为时间序列学习中的数据归因和模型泛化之间提供了实用有效的桥梁。

Abstract: Time series foundation models (TSFMs) have demonstrated increasing capabilities due to their extensive pretraining on large volumes of diverse time series data. Consequently, the quality of time series data is crucial to TSFM performance, rendering an accurate and efficient data valuation of time series for TSFMs indispensable. However, traditional data valuation methods, such as influence functions, face severe computational bottlenecks due to their poor scalability with growing TSFM model sizes and often fail to preserve temporal dependencies. In this paper, we propose LTSV, a Lightweight Time Series Valuation on TSFMS via in-context finetuning. Grounded in the theoretical evidence that in-context finetuning approximates the influence function, LTSV estimates a sample's contribution by measuring the change in context loss after in-context finetuning, leveraging the strong generalization capabilities of TSFMs to produce robust and transferable data valuations. To capture temporal dependencies, we introduce temporal block aggregation, which integrates per-block influence scores across overlapping time windows. Experiments across multiple time series datasets and models demonstrate that LTSV consistently provides reliable and strong valuation performance, while maintaining manageable computational requirements. Our results suggest that in-context finetuning on time series foundation models provides a practical and effective bridge between data attribution and model generalization in time series learning.

</details>


### [350] [Enhanced Water Leak Detection with Convolutional Neural Networks and One-Class Support Vector Machine](https://arxiv.org/abs/2511.11650)
*Daniele Ugo Leonzio,Paolo Bestagini,Marco Marcon,Stefano Tubaro*

Main category: cs.LG

TL;DR: 提出一种基于水压测量和数据驱动方法的供水管网泄漏检测新方法，使用特征提取器和单类支持向量机在无泄漏数据上训练，将泄漏检测为异常。


<details>
  <summary>Details</summary>
Motivation: 供水管网每年因泄漏损失大量水资源，需要可靠有效的泄漏检测和定位系统，数据驱动方法因其优越性能而受到关注。

Method: 基于供水管网拓扑知识和无泄漏压力数据，使用特征提取器和单类支持向量机在无泄漏数据上训练，将泄漏检测为异常。

Result: 在模拟数据集上使用Modena供水管网的测试结果表明，该方法优于最近的泄漏检测方法。

Conclusion: 提出的数据驱动泄漏检测方法在性能上优于现有方法，为供水管网泄漏管理提供了有效解决方案。

Abstract: Water is a critical resource that must be managed efficiently. However, a substantial amount of water is lost each year due to leaks in Water Distribution Networks (WDNs). This underscores the need for reliable and effective leak detection and localization systems. In recent years, various solutions have been proposed, with data-driven approaches gaining increasing attention due to their superior performance. In this paper, we propose a new method for leak detection. The method is based on water pressure measurements acquired at a series of nodes of a WDN. Our technique is a fully data-driven solution that makes only use of the knowledge of the WDN topology, and a series of pressure data acquisitions obtained in absence of leaks. The proposed solution is based on an feature extractor and a one-class Support Vector Machines (SVM) trained on no-leak data, so that leaks are detected as anomalies. The results achieved on a simulate dataset using the Modena WDN demonstrate that the proposed solution outperforms recent methods for leak detection.

</details>


### [351] [Incomplete Depression Feature Selection with Missing EEG Channels](https://arxiv.org/abs/2511.11651)
*Zhijian Gong,Wenjia Dong,Xueyuan Xu,Fulin Wei,Chunyu Liu,Li Zhuo*

Main category: cs.LG

TL;DR: 提出了一种名为IDFS-MEC的新型特征选择方法，用于处理EEG数据中的缺失通道问题，并通过全局冗余最小化来减少特征子集中的冗余信息，在抑郁症分析中取得了优于10种流行特征选择方法的性能。


<details>
  <summary>Details</summary>
Motivation: EEG特征通常包含冗余、不相关和噪声信息，且现实世界EEG数据采集经常面临电极脱落导致数据丢失和强噪声干扰等挑战，需要开发更稳健的抑郁症分析方法。

Method: IDFS-MEC方法整合了缺失通道指示信息和自适应通道权重学习到正交回归中，以减轻不完整通道对模型构建的影响，然后利用全局冗余最小化学习来减少所选特征子集中的冗余信息。

Result: 在MODMA和PRED-d003数据集上的广泛实验表明，IDFS-MEC选择的EEG特征子集在3通道、64通道和128通道设置下均优于10种流行特征选择方法。

Conclusion: IDFS-MEC方法能够有效处理EEG数据中的缺失通道问题，并选择出性能优越的特征子集，为抑郁症分析提供了更稳健的解决方案。

Abstract: As a critical mental health disorder, depression has severe effects on both human physical and mental well-being. Recent developments in EEG-based depression analysis have shown promise in improving depression detection accuracies. However, EEG features often contain redundant, irrelevant, and noisy information. Additionally, real-world EEG data acquisition frequently faces challenges, such as data loss from electrode detachment and heavy noise interference. To tackle the challenges, we propose a novel feature selection approach for robust depression analysis, called Incomplete Depression Feature Selection with Missing EEG Channels (IDFS-MEC). IDFS-MEC integrates missing-channel indicator information and adaptive channel weighting learning into orthogonal regression to lessen the effects of incomplete channels on model construction, and then utilizes global redundancy minimization learning to reduce redundant information among selected feature subsets. Extensive experiments conducted on MODMA and PRED-d003 datasets reveal that the EEG feature subsets chosen by IDFS-MEC have superior performance than 10 popular feature selection methods among 3-, 64-, and 128-channel settings.

</details>


### [352] [Convergence of Multiagent Learning Systems for Traffic control](https://arxiv.org/abs/2511.11654)
*Sayambhu Sen,Shalabh Bhatnagar*

Main category: cs.LG

TL;DR: 本文对多智能体强化学习在交通信号控制中的收敛性进行了理论分析，证明了在特定条件下该算法的收敛性。


<details>
  <summary>Details</summary>
Motivation: 随着班加罗尔等城市的快速城市化导致严重交通拥堵，需要高效的交通信号控制。虽然已有实证研究表明多智能体强化学习的有效性，但缺乏对其稳定性和收敛性的严格理论分析。

Method: 使用随机逼近方法正式分析学习动态，将单智能体异步值迭代的收敛证明扩展到多智能体交通控制算法。

Result: 证明了特定多智能体强化学习算法在给定条件下能够收敛。

Conclusion: 本文填补了多智能体强化学习在交通控制领域理论分析的空白，为该算法的实际应用提供了理论保障。

Abstract: Rapid urbanization in cities like Bangalore has led to severe traffic congestion, making efficient Traffic Signal Control (TSC) essential. Multi-Agent Reinforcement Learning (MARL), often modeling each traffic signal as an independent agent using Q-learning, has emerged as a promising strategy to reduce average commuter delays. While prior work Prashant L A et. al has empirically demonstrated the effectiveness of this approach, a rigorous theoretical analysis of its stability and convergence properties in the context of traffic control has not been explored. This paper bridges that gap by focusing squarely on the theoretical basis of this multi-agent algorithm. We investigate the convergence problem inherent in using independent learners for the cooperative TSC task. Utilizing stochastic approximation methods, we formally analyze the learning dynamics. The primary contribution of this work is the proof that the specific multi-agent reinforcement learning algorithm for traffic control is proven to converge under the given conditions extending it from single agent convergence proofs for asynchronous value iteration.

</details>


### [353] [SpecQuant: Spectral Decomposition and Adaptive Truncation for Ultra-Low-Bit LLMs Quantization](https://arxiv.org/abs/2511.11663)
*Zhixiong Zhao,Fangxin Liu,Junjie Wang,Chenyang Guan,Zongwu Wang,Li Jiang,Haibing Guan*

Main category: cs.LG

TL;DR: SpecQuant是一种从傅里叶频率域角度解决LLM极端压缩的两阶段框架，通过平滑激活异常值和通道级低频傅里叶截断，在LLaMA-3 8B上实现4位权重和激活量化，精度损失仅1.5%，推理速度提升2倍，内存使用降低3倍。


<details>
  <summary>Details</summary>
Motivation: 随着准确开源大语言模型的出现，需要在终端设备上高效部署，这推动了对先进量化技术的需求，特别是针对权重和激活的极低位量化挑战。

Method: 提出SpecQuant两阶段框架：第一阶段平滑激活异常值并将其转移到权重矩阵；第二阶段应用通道级低频傅里叶截断，抑制高频分量同时保留关键信号能量。还引入了轻量级截断模块实现运行时适应性。

Result: 在LLaMA-3 8B上实现了4位权重和激活量化，零样本准确率与全精度相比仅下降1.5%，同时推理速度提升2倍，内存使用降低3倍。

Conclusion: 从傅里叶频率域角度重新审视LLM极端压缩问题，证明了权重能量主要集中在低频分量，通过保留这些分量可以在最小影响模型精度的情况下实现高效的极低位量化。

Abstract: The emergence of accurate open large language models (LLMs) has sparked a push for advanced quantization techniques to enable efficient deployment on end-user devices. In this paper, we revisit the challenge of extreme LLM compression -- targeting ultra-low-bit quantization for both activations and weights -- from a Fourier frequency domain perspective. We propose SpecQuant, a two-stage framework that tackles activation outliers and cross-channel variance. In the first stage, activation outliers are smoothed and transferred into the weight matrix to simplify downstream quantization. In the second stage, we apply channel-wise low-frequency Fourier truncation to suppress high-frequency components while preserving essential signal energy, improving quantization robustness. Our method builds on the principle that most of the weight energy is concentrated in low-frequency components, which can be retained with minimal impact on model accuracy. To enable runtime adaptability, we introduce a lightweight truncation module during inference that adjusts truncation thresholds based on channel characteristics. On LLaMA-3 8B, SpecQuant achieves 4-bit quantization for both weights and activations, narrowing the zero-shot accuracy gap to only 1.5% compared to full precision, while delivering 2 times faster inference and 3times lower memory usage.

</details>


### [354] [Clifford Algebraic Rotor Embeddings : Maybe embeddings should start to CARE](https://arxiv.org/abs/2511.11665)
*Sameeksha Sriram,Ayush Paliwal,Alexander S. Ecker,Chase van de Geijn*

Main category: cs.LG

TL;DR: 本文提出了基于四元数的旋转位置嵌入方法QuatRo，并将其推广到基于几何代数的Clifford代数旋转嵌入CARE，解决了现有球形RoPE的非交换性问题，实现了任意维度的旋转位置编码。


<details>
  <summary>Details</summary>
Motivation: 现有的球形旋转位置嵌入是非交换的，失去了RoPE的平移等变性特性。本文旨在通过四元数和Clifford代数来解决这一问题，提供更通用和数学上更优雅的旋转位置编码方法。

Method: 1. 提出QuatRo方法，使用四元数代替欧拉角来表示3D旋转；2. 将QuatRo推广到CARE，利用Clifford代数中的旋量在多向量上作用；3. 展示了混合RoPE和球形RoPE都是QuatRo的特例。

Result: 提出的QuatRo和CARE方法能够：1. 扩展到任意维度；2. 在多向量的多个等级上编码位置信息；3. 保持了旋转位置嵌入的数学性质。

Conclusion: 基于四元数和Clifford代数的旋转位置嵌入方法为位置编码提供了更通用和数学上更优雅的框架，能够处理任意维度的输入并保持重要的数学性质。

Abstract: Rotary Positional Embeddings (RoPE) have demonstrated exceptional performance as a positional encoding method, consistently outperforming their baselines. While recent work has sought to extend RoPE to higher-dimensional inputs, many such extensions are non-commutative, thereby forfeiting RoPE's shift-equivariance property. Spherical RoPE is one such non-commutative variant, motivated by the idea of rotating embedding vectors on spheres rather than circles. However, spherical rotations are inherently non-commutative, making the choice of rotation sequence ambiguous. In this work, we explore a quaternion-based approach -- Quaternion Rotary Embeddings (QuatRo) -- in place of Euler angles, leveraging quaternions' ability to represent 3D rotations to parameterize the axes of rotation. We show Mixed RoPE and Spherical RoPE to be special cases of QuatRo. Further, we propose a generalization of QuatRo to Clifford Algebraic Rotary Embeddings (CARE) using geometric algebra. Viewing quaternions as the even subalgebra of Cl(3,0,0), we extend the notion of rotary embeddings from quaternions to Clifford rotors acting on multivectors. This formulation enables two key generalizations: (1) extending rotary embeddings to arbitrary dimensions, and (2) encoding positional information in multivectors of multiple grades, not just vectors. We present preliminary experiments comparing spherical, quaternion, and Clifford-based rotary embeddings.

</details>


### [355] [Beyond Superficial Forgetting: Thorough Unlearning through Knowledge Density Estimation and Block Re-insertion](https://arxiv.org/abs/2511.11667)
*Feng Guo,Yuntao Wen,Shen Gao,Junshuo Zhang,Shuo Shang*

Main category: cs.LG

TL;DR: 提出KUnBR方法，通过知识密度估计定位有害知识密集层，采用层重插入策略彻底消除大语言模型中的有害知识，在保持模型性能的同时实现最先进的遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法难以彻底移除有害知识，残留知识容易被恢复，需要解决隐私、合规和伦理问题。

Method: 使用知识密度估计量化有害知识分布，识别有害知识密集层；设计层重插入策略，将有害知识密集层提取并重插入原始模型，绕过覆盖层梯度阻塞。

Result: 在多个遗忘和通用能力基准测试中，KUnBR实现了最先进的遗忘性能，同时保持了模型效用。

Conclusion: KUnBR通过精确定位和有效梯度传播，能够彻底消除大语言模型中的有害知识，解决了现有遗忘方法的局限性。

Abstract: Machine unlearning, which selectively removes harmful knowledge from a pre-trained model without retraining from scratch, is crucial for addressing privacy, regulatory compliance, and ethical concerns in Large Language Models (LLMs). However, existing unlearning methods often struggle to thoroughly remove harmful knowledge, leaving residual harmful knowledge that can be easily recovered. To address these limitations, we propose Knowledge Density-Guided Unlearning via Blocks Reinsertion (KUnBR), a novel approach that first identifies layers with rich harmful knowledge and then thoroughly eliminates the harmful knowledge via re-insertion strategy. Our method introduces knowledge density estimation to quantify and locate layers containing the most harmful knowledge, enabling precise unlearning. Additionally, we design a layer re-insertion strategy that extracts and re-inserts harmful knowledge-rich layers into the original LLM, bypassing gradient obstruction caused by cover layers and ensuring effective gradient propagation during unlearning. Extensive experiments conducted on several unlearning and general capability benchmarks demonstrate that KUnBR achieves state-of-the-art forgetting performance while maintaining model utility.

</details>


### [356] [Do traveling waves make good positional encodings?](https://arxiv.org/abs/2511.11668)
*Chase van de Geijn,Ayush Paliwal,Timo Lüddecke,Alexander S. Ecker*

Main category: cs.LG

TL;DR: 本文提出了一种基于行波的新型位置编码机制RollPE，通过循环滚动操作在自注意力中实现相对位置编码，性能优于传统绝对位置编码，与RoPE相当。


<details>
  <summary>Details</summary>
Motivation: 传统位置编码方法存在局限性，需要更好的相对位置编码机制来捕捉平移等变性。

Method: 使用循环滚动操作对查询和键张量进行处理，通过位置间的相位偏移实现相对位置差异的注意力计算。

Result: RollPE显著优于传统绝对位置嵌入，与RoPE性能相当，并建立了与RoPE的数学等价关系。

Conclusion: RollPE提供了一种简化的相对位置编码方法，可能有助于理解大脑中的信息流动过程。

Abstract: Transformers rely on positional encoding to compensate for the inherent permutation invariance of self-attention. Traditional approaches use absolute sinusoidal embeddings or learned positional vectors, while more recent methods emphasize relative encodings to better capture translation equivariances. In this work, we propose RollPE, a novel positional encoding mechanism based on traveling waves, implemented by applying a circular roll operation to the query and key tensors in self-attention. This operation induces a relative shift in phase across positions, allowing the model to compute attention as a function of positional differences rather than absolute indices. We show this simple method significantly outperforms traditional absolute positional embeddings and is comparable to RoPE. We derive a continuous case of RollPE which implicitly imposes a topographic structure on the query and key space. We further derive a mathematical equivalence of RollPE to a particular configuration of RoPE. Viewing RollPE through the lens of traveling waves may allow us to simplify RoPE and relate it to processes of information flow in the brain.

</details>


### [357] [Evaluation of LLM-based Explanations for a Learning Analytics Dashboard](https://arxiv.org/abs/2511.11671)
*Alina Deriyeva,Benjamin Paassen*

Main category: cs.LG

TL;DR: 本研究评估了使用大型语言模型生成学习分析仪表板数据解释的效果，发现LLM生成的技能状态解释和学习建议比独立仪表板或教师解释更受青睐。


<details>
  <summary>Details</summary>
Motivation: 学习分析仪表板支持数字学习环境中的自我调节学习，但其有效性受数据可解释性影响。研究旨在通过LLM生成解释来增强仪表板的可解释性。

Method: 在专家研究中，将LLM生成的仪表板数据解释与独立仪表板和教师提供的解释进行比较，涉及12名大学教育工作者。

Result: LLM生成的技能状态解释和学习建议显著优于其他条件，更受参与者青睐。

Conclusion: 使用LLM进行数据解释可以提升学习体验，同时保持教师认可的教学标准。

Abstract: Learning Analytics Dashboards can be a powerful tool to support self-regulated learning in Digital Learning Environments and promote development of meta-cognitive skills, such as reflection. However, their effectiveness can be affected by the interpretability of the data they provide. To assist in the interpretation, we employ a large language model to generate verbal explanations of the data in the dashboard and evaluate it against a standalone dashboard and explanations provided by human teachers in an expert study with university level educators (N=12). We find that the LLM-based explanations of the skill state presented in the dashboard, as well as general recommendations on how to proceed with learning within the course are significantly more favored compared to the other conditions. This indicates that using LLMs for interpretation purposes can enhance the learning experience for learners while maintaining the pedagogical standards approved by teachers.

</details>


### [358] [Synergistic Feature Fusion for Latent Lyrical Classification: A Gated Deep Learning Architecture](https://arxiv.org/abs/2511.11673)
*M. A. Gameiro*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的协同融合层（SFL）架构，通过门控机制将复杂的深度语义特征与简单的结构特征相结合，用于歌词内容分类，在准确性和校准可靠性方面显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决如何将复杂的高维深度语义特征与简单可解释的结构线索有效整合，以提升歌词内容分类的性能和可靠性。

Method: 采用协同融合层（SFL）架构，使用门控机制来调节Sentence-BERT嵌入（Fdeep）与低维辅助特征（Fstruct）的融合，将任务重新定义为二分类问题。

Result: SFL模型达到0.9894的准确率和宏F1分数，显著优于使用特征拼接的随机森林基线（准确率0.9868），校准误差降低93%，对数损失降低2.5倍。

Conclusion: 非线性门控机制优于简单的特征拼接，SFL模型为复杂多模态歌词分析提供了稳健可靠的解决方案。

Abstract: This study addresses the challenge of integrating complex, high-dimensional deep semantic features with simple, interpretable structural cues for lyrical content classification. We introduce a novel Synergistic Fusion Layer (SFL) architecture, a deep learning model utilizing a gated mechanism to modulate Sentence-BERT embeddings (Fdeep) using low-dimensional auxiliary features (Fstruct). The task, derived from clustering UMAP-reduced lyrical embeddings, is reframed as binary classification, distinguishing a dominant, homogeneous cluster (Class 0) from all other content (Class 1). The SFL model achieved an accuracy of 0.9894 and a Macro F1 score of 0.9894, outperforming a comprehensive Random Forest (RF) baseline that used feature concatenation (Accuracy = 0.9868). Crucially, the SFL model demonstrated vastly superior reliability and calibration, exhibiting a 93% reduction in Expected Calibration Error (ECE = 0.0035) and a 2.5x lower Log Loss (0.0304) compared to the RF baseline (ECE = 0.0500; Log Loss = 0.0772). This performance validates the architectural hypothesis that non-linear gating is superior to simple feature concatenation, establishing the SFL model as a robust and trustworthy system for complex multimodal lyrical analysis.

</details>


### [359] [Learning Fair Representations with Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.11767)
*Amisha Priyadarshini,Sergio Gago-Masague*

Main category: cs.LG

TL;DR: 本文提出了一种将Kolmogorov-Arnold Networks（KANs）集成到公平对抗学习框架中的方法，通过自适应惩罚更新机制动态调整公平约束，在保持高预测准确性的同时实现公平性。


<details>
  <summary>Details</summary>
Motivation: 现有公平学习模型在公平性与准确性之间难以达到最优平衡，且黑盒模型缺乏可解释性，限制了在敏感领域（如大学招生）的应用。

Method: 将KANs集成到公平对抗学习框架中，利用KANs的对抗鲁棒性和可解释性，并提出自适应惩罚更新机制动态调整训练过程中的公平约束。

Result: 在两个真实世界大学招生数据集上的实验表明，该方法在三种不同优化策略下均优于基线公平学习模型，在保持高预测准确性的同时实现了跨敏感属性的竞争性公平。

Conclusion: KANs在公平机器学习中表现出高效性和鲁棒性，能够平衡公平性与准确性，为敏感决策领域提供了可解释的解决方案。

Abstract: Despite recent advances in fairness-aware machine learning, predictive models often exhibit discriminatory behavior towards marginalized groups. Such unfairness might arise from biased training data, model design, or representational disparities across groups, posing significant challenges in high-stakes decision-making domains such as college admissions. While existing fair learning models aim to mitigate bias, achieving an optimal trade-off between fairness and accuracy remains a challenge. Moreover, the reliance on black-box models hinders interpretability, limiting their applicability in socially sensitive domains. In this paper, we try to circumvent these issues by integrating Kolmogorov-Arnold Networks (KANs) within a fair adversarial learning framework. Leveraging the adversarial robustness and interpretability of KANs, our approach enables a balance between fairness and accuracy. To further facilitate this balance, we propose an adaptive penalty update mechanism that dynamically adjusts fairness constraints during the model training. We conduct numerical experiments on two real-world college admissions datasets, across three different optimization strategies. The results demonstrate the efficiency and robustness of KANs by consistently outperforming the baseline fair learning models, and maintaining high predictive accuracy while achieving competitive fairness across sensitive attributes.

</details>


### [360] [Learning with Preserving for Continual Multitask Learning](https://arxiv.org/abs/2511.11676)
*Hanchen David Wang,Siwoo Bae,Zirong Chen,Meiyi Ma*

Main category: cs.LG

TL;DR: 本文提出了Learning with Preserving (LwP)框架，通过保持共享表示空间的几何结构来解决持续多任务学习中的灾难性遗忘问题，无需重放缓冲区，在隐私敏感应用中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶、医疗影像分析等关键领域，AI系统需要持续学习新任务而不遗忘已学能力。现有持续学习方法在此场景中表现不佳，因为它们学习碎片化的任务特定特征，导致特征相互干扰。

Method: 引入LwP框架，核心是动态加权距离保持(DWDP)损失函数，通过正则化潜在数据表示之间的成对距离来防止表示漂移，保持底层几何结构。

Result: 在时间序列和图像基准测试上的广泛评估表明，LwP不仅缓解了灾难性遗忘，而且在CMTL任务中持续优于最先进的基线方法，对分布偏移表现出卓越的鲁棒性。

Conclusion: LwP是唯一超越强单任务学习基线的方法，证明了其在现实世界动态环境中的有效性，特别适合隐私敏感应用。

Abstract: Artificial intelligence systems in critical fields like autonomous driving and medical imaging analysis often continually learn new tasks using a shared stream of input data. For instance, after learning to detect traffic signs, a model may later need to learn to classify traffic lights or different types of vehicles using the same camera feed. This scenario introduces a challenging setting we term Continual Multitask Learning (CMTL), where a model sequentially learns new tasks on an underlying data distribution without forgetting previously learned abilities. Existing continual learning methods often fail in this setting because they learn fragmented, task-specific features that interfere with one another. To address this, we introduce Learning with Preserving (LwP), a novel framework that shifts the focus from preserving task outputs to maintaining the geometric structure of the shared representation space. The core of LwP is a Dynamically Weighted Distance Preservation (DWDP) loss that prevents representation drift by regularizing the pairwise distances between latent data representations. This mechanism of preserving the underlying geometric structure allows the model to retain implicit knowledge and support diverse tasks without requiring a replay buffer, making it suitable for privacy-conscious applications. Extensive evaluations on time-series and image benchmarks show that LwP not only mitigates catastrophic forgetting but also consistently outperforms state-of-the-art baselines in CMTL tasks. Notably, our method shows superior robustness to distribution shifts and is the only approach to surpass the strong single-task learning baseline, underscoring its effectiveness for real-world dynamic environments.

</details>


### [361] [Homotopy-Guided Self-Supervised Learning of Parametric Solutions for AC Optimal Power Flow](https://arxiv.org/abs/2511.11677)
*Shimiao Li,Aaron Tuor,Draguna Vrabie,Larry Pileggi,Jan Drgona*

Main category: cs.LG

TL;DR: 本文提出了一种基于同伦引导的自监督学习方法，用于解决参数化交流最优潮流问题的优化挑战，通过构建从松弛问题到原始问题的连续变形过程来改善收敛稳定性和可行性。


<details>
  <summary>Details</summary>
Motivation: 交流最优潮流问题的固有非凸性导致优化景观复杂，标准学习方法难以收敛到可行的高质量解。需要一种能够提高收敛稳定性和可行性的新方法。

Method: 采用同伦引导的自监督学习方法，在训练过程中构建目标和约束的连续变形，从具有广泛吸引盆的松弛问题逐步转变为原始问题。

Result: 在标准IEEE交流最优潮流基准测试中，该方法相比非同伦基线显著提高了可行性率，同时达到与完整最优潮流求解器相当的目标值。

Conclusion: 同伦启发式方法在电力系统优化中展示了可扩展、约束感知的学习优化潜力。

Abstract: Learning to optimize (L2O) parametric approximations of AC optimal power flow (AC-OPF) solutions offers the potential for fast, reusable decision-making in real-time power system operations. However, the inherent nonconvexity of AC-OPF results in challenging optimization landscapes, and standard learning approaches often fail to converge to feasible, high-quality solutions. This work introduces a \textit{homotopy-guided self-supervised L2O method} for parametric AC-OPF problems. The key idea is to construct a continuous deformation of the objective and constraints during training, beginning from a relaxed problem with a broad basin of attraction and gradually transforming it toward the original problem. The resulting learning process improves convergence stability and promotes feasibility without requiring labeled optimal solutions or external solvers. We evaluate the proposed method on standard IEEE AC-OPF benchmarks and show that homotopy-guided L2O significantly increases feasibility rates compared to non-homotopy baselines, while achieving objective values comparable to full OPF solvers. These findings demonstrate the promise of homotopy-based heuristics for scalable, constraint-aware L2O in power system optimization.

</details>


### [362] [Computational Measurement of Political Positions: A Review of Text-Based Ideal Point Estimation Algorithms](https://arxiv.org/abs/2511.13238)
*Patrick Parschan,Charlott Jakob*

Main category: cs.LG

TL;DR: 本文对基于文本的无监督和半监督理想点估计算法进行了首次系统性综述，这些算法用于从文本数据推断潜在政治立场，在政治学、计算社会科学等领域广泛应用。


<details>
  <summary>Details</summary>
Motivation: 过去二十年中，CT-IPE算法的发展紧跟NLP趋势，从词频模型发展到大型语言模型，但这一发展轨迹导致了领域碎片化，缺乏系统比较和应用指导。

Method: 通过系统性文献回顾识别了25种CT-IPE算法，进行手动内容分析，并引入概念框架区分算法如何生成、捕获和聚合文本方差，识别出四种方法家族。

Result: 识别了词频、主题建模、词嵌入和LLM四种方法家族，并批判性评估了它们的假设、可解释性、可扩展性和局限性。

Conclusion: 本文提供了算法发展的结构化综合，为应用研究人员提供实用指导，强调算法选择中的权衡，并指出不同算法估计结果的差异本身具有信息价值，需要系统基准测试。

Abstract: This article presents the first systematic review of unsupervised and semi-supervised computational text-based ideal point estimation (CT-IPE) algorithms, methods designed to infer latent political positions from textual data. These algorithms are widely used in political science, communication, computational social science, and computer science to estimate ideological preferences from parliamentary speeches, party manifestos, and social media. Over the past two decades, their development has closely followed broader NLP trends -- beginning with word-frequency models and most recently turning to large language models (LLMs). While this trajectory has greatly expanded the methodological toolkit, it has also produced a fragmented field that lacks systematic comparison and clear guidance for applied use. To address this gap, we identified 25 CT-IPE algorithms through a systematic literature review and conducted a manual content analysis of their modeling assumptions and development contexts. To compare them meaningfully, we introduce a conceptual framework that distinguishes how algorithms generate, capture, and aggregate textual variance. On this basis, we identify four methodological families -- word-frequency, topic modeling, word embedding, and LLM-based approaches -- and critically assess their assumptions, interpretability, scalability, and limitations. Our review offers three contributions. First, it provides a structured synthesis of two decades of algorithm development, clarifying how diverse methods relate to one another. Second, it translates these insights into practical guidance for applied researchers, highlighting trade-offs in transparency, technical requirements, and validation strategies that shape algorithm choice. Third, it emphasizes that differences in estimation outcomes across algorithms are themselves informative, underscoring the need for systematic benchmarking.

</details>


### [363] [Probabilistic Wildfire Susceptibility from Remote Sensing Using Random Forests and SHAP](https://arxiv.org/abs/2511.11680)
*Udaya Bhasker Cheerala,Varun Teja Chirukuri,Venkata Akhil Kumar Gummadi,Jintu Moni Bhuyan,Praveen Damacharla*

Main category: cs.LG

TL;DR: 本研究开发了加利福尼亚州综合野火风险地图，使用随机森林算法结合可解释人工智能（SHAP）来识别关键生态系统特定驱动因素，结果显示模型具有良好的预测性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 野火对全球生态系统构成重大威胁，加利福尼亚州由于气候、地形特征、植被模式和人类活动等因素经常发生火灾，需要开发全面的风险评估方法。

Method: 应用随机森林算法，结合可解释人工智能（XAI）通过Shapley Additive exPlanations（SHAP）解释模型预测，采用空间和时间验证策略评估模型性能。

Result: RF模型表现出强大的预测性能，草地和森林的AUC分别达到0.996和0.997。空间交叉验证显示中等可转移性，时间分割验证显示更好的泛化能力。SHAP分析识别出土壤有机碳、树木覆盖和NDVI是森林的关键驱动因素，而地表温度、海拔和植被健康指数是草地的关键驱动因素。

Conclusion: RF-SHAP框架为评估野火风险提供了稳健、可理解和适应性强的方法，能够支持明智决策和制定有针对性的减灾策略。

Abstract: Wildfires pose a significant global threat to ecosystems worldwide, with California experiencing recurring fires due to various factors, including climate, topographical features, vegetation patterns, and human activities. This study aims to develop a comprehensive wildfire risk map for California by applying the random forest (RF) algorithm, augmented with Explainable Artificial Intelligence (XAI) through Shapley Additive exPlanations (SHAP), to interpret model predictions. Model performance was assessed using both spatial and temporal validation strategies. The RF model demonstrated strong predictive performance, achieving near-perfect discrimination for grasslands (AUC = 0.996) and forests (AUC = 0.997). Spatial cross-validation revealed moderate transferability, yielding ROC-AUC values of 0.6155 for forests and 0.5416 for grasslands. In contrast, temporal split validation showed enhanced generalization, especially for forests (ROC-AUC = 0.6615, PR-AUC = 0.8423). SHAP-based XAI analysis identified key ecosystem-specific drivers: soil organic carbon, tree cover, and Normalized Difference Vegetation Index (NDVI) emerged as the most influential in forests, whereas Land Surface Temperature (LST), elevation, and vegetation health indices were dominant in grasslands. District-level classification revealed that Central Valley and Northern Buttes districts had the highest concentration of high-risk grasslands, while Northern Buttes and North Coast Redwoods dominated forested high-risk areas. This RF-SHAP framework offers a robust, comprehensible, and adaptable method for assessing wildfire risks, enabling informed decisions and creating targeted strategies to mitigate dangers.

</details>


### [364] [A Bayesian Model for Multi-stage Censoring](https://arxiv.org/abs/2511.11684)
*Shuvom Sadhuka,Sophia Lin,Emma Pierson,Bonnie Berger*

Main category: cs.LG

TL;DR: 本文开发了一个贝叶斯模型来处理医疗决策中的漏斗结构问题，该模型能够更准确地预测被审查患者的真实结果，并在急诊科数据中发现性别差异。


<details>
  <summary>Details</summary>
Motivation: 医疗决策中的漏斗结构存在选择性审查问题，即真实结果只在流程结束时才被揭示，这可能导致风险估计的统计偏差，特别是在服务不足的患者群体中。

Method: 开发了一个基于选择性标签和审查先验工作的贝叶斯模型，用于处理漏斗决策结构。

Result: 在合成设置中，模型能够恢复真实参数并比基线更准确地预测被审查患者的结果；在急诊科数据应用中，发现ICU入院的风险阈值存在性别差异（女性5.1% vs 男性4.5%）。

Conclusion: 该贝叶斯模型能够有效处理漏斗决策结构中的选择性审查问题，并揭示了医疗决策中存在的性别差异。

Abstract: Many sequential decision settings in healthcare feature funnel structures characterized by a series of stages, such as screenings or evaluations, where the number of patients who advance to each stage progressively decreases and decisions become increasingly costly. For example, an oncologist may first conduct a breast exam, followed by a mammogram for patients with concerning exams, followed by a biopsy for patients with concerning mammograms. A key challenge is that the ground truth outcome, such as the biopsy result, is only revealed at the end of this funnel. The selective censoring of the ground truth can introduce statistical biases in risk estimation, especially in underserved patient groups, whose outcomes are more frequently censored. We develop a Bayesian model for funnel decision structures, drawing from prior work on selective labels and censoring. We first show in synthetic settings that our model is able to recover the true parameters and predict outcomes for censored patients more accurately than baselines. We then apply our model to a dataset of emergency department visits, where in-hospital mortality is observed only for those who are admitted to either the hospital or ICU. We find that there are gender-based differences in hospital and ICU admissions. In particular, our model estimates that the mortality risk threshold to admit women to the ICU is higher for women (5.1%) than for men (4.5%).

</details>


### [365] [Regularized Schrödinger: Alleviating Distortion and Exposure Bias in Solving Inverse Problems](https://arxiv.org/abs/2511.11686)
*Qing Yao,Lijian Gao,Qirong Mao,Dong Ming*

Main category: cs.LG

TL;DR: 本文提出了正则化薛定谔桥(RSB)方法，用于解决扩散模型在逆问题中的失真-感知权衡和曝光偏差问题，在语音增强任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在逆问题中的两个关键挑战：1)失真-感知权衡，即提高感知质量会降低重建保真度；2)曝光偏差问题，即训练-推理输入不匹配导致预测误差累积和重建质量下降。

Method: 提出正则化薛定谔桥(RSB)，采用新颖的正则化训练策略，通过扰动输入状态和目标来缓解曝光偏差，并通过后验均值的精心设计插值来减轻失真。

Result: 在语音增强的两个典型逆问题上的广泛实验表明，RSB优于最先进的方法，显著改善了失真指标并有效减少了曝光偏差。

Conclusion: RSB方法成功解决了扩散模型在逆问题中的失真-感知权衡和曝光偏差问题，在语音增强任务中取得了优异性能。

Abstract: Diffusion models serve as a powerful generative framework for solving inverse problems. However, they still face two key challenges: 1) the distortion-perception tradeoff, where improving perceptual quality often degrades reconstruction fidelity, and 2) the exposure bias problem, where the training-inference input mismatch leads to prediction error accumulation and reduced reconstruction quality. In this work, we propose the Regularized Schrödinger Bridge (RSB), an adaptation of Schrödinger Bridge tailored for inverse problems that addresses the above limitations. RSB employs a novel regularized training strategy that perturbs both the input states and targets, effectively mitigating exposure bias by exposing the model to simulated prediction errors and also alleviating distortion by well-designed interpolation via the posterior mean. Extensive experiments on two typical inverse problems for speech enhancement demonstrate that RSB outperforms state-of-the-art methods, significantly improving distortion metrics and effectively reducing exposure bias.

</details>


### [366] [Doubly Debiased Test-Time Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2511.11690)
*Fei Song,Yi Li,Rui Wang,Jiahuan Zhou,Changwen Zheng,Jiangmeng Li*

Main category: cs.LG

TL;DR: 本文提出了一种双重去偏测试时提示调优方法，通过动态检索增强调制和可靠性感知提示优化来解决视觉语言模型在零样本设置下的提示优化偏差问题。


<details>
  <summary>Details</summary>
Motivation: 测试时提示调优仅基于未标记测试数据可能导致提示优化偏差，造成下游任务性能下降。需要从模型和数据两个角度分析并解决该问题。

Method: 提出双重去偏方法：1) 动态检索增强调制模块，用测试图像特征检索高置信度知识来调制预测；2) 可靠性感知提示优化模块，结合置信度加权集成和跨模态一致性蒸馏进行正则化约束。

Result: 在15个基准数据集上的广泛实验表明，该方法在自然分布偏移和跨数据集泛化场景下均优于基线方法，验证了其缓解提示优化偏差的有效性。

Conclusion: 所提出的双重去偏测试时提示调优方法能有效减轻提示优化偏差，提升视觉语言模型在零样本设置下的泛化性能。

Abstract: Test-time prompt tuning for vision-language models has demonstrated impressive generalization capabilities under zero-shot settings. However, tuning the learnable prompts solely based on unlabeled test data may induce prompt optimization bias, ultimately leading to suboptimal performance on downstream tasks. In this work, we analyze the underlying causes of prompt optimization bias from both the model and data perspectives. In terms of the model, the entropy minimization objective typically focuses on reducing the entropy of model predictions while overlooking their correctness. This can result in overconfident yet incorrect outputs, thereby compromising the quality of prompt optimization. On the data side, prompts affected by optimization bias can introduce misalignment between visual and textual modalities, which further aggravates the prompt optimization bias. To this end, we propose a Doubly Debiased Test-Time Prompt Tuning method. Specifically, we first introduce a dynamic retrieval-augmented modulation module that retrieves high-confidence knowledge from a dynamic knowledge base using the test image feature as a query, and uses the retrieved knowledge to modulate the predictions. Guided by the refined predictions, we further develop a reliability-aware prompt optimization module that incorporates a confidence-based weighted ensemble and cross-modal consistency distillation to impose regularization constraints during prompt tuning. Extensive experiments across 15 benchmark datasets involving both natural distribution shifts and cross-datasets generalization demonstrate that our method outperforms baselines, validating its effectiveness in mitigating prompt optimization bias.

</details>


### [367] [Beyond saliency: enhancing explanation of speech emotion recognition with expert-referenced acoustic cues](https://arxiv.org/abs/2511.11691)
*Seham Nasr,Zhao Ren,David Johnson*

Main category: cs.LG

TL;DR: 本文提出了一个可解释AI框架，用于语音情感识别，通过量化显著区域内的声学线索幅度，将显著性区域与专家参考的声学线索联系起来，提高了解释质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于显著性的方法虽然能突出声谱图区域，但无法显示这些区域是否对应有意义的声学情感标记，限制了忠实性和可解释性。

Method: 提出了一个框架，通过量化显著区域内的线索幅度，将显著性区域与专家参考的语音情感声学线索联系起来。

Result: 在基准SER数据集上的实验表明，该方法通过明确将显著区域与理论驱动的语音情感声学线索联系起来，提高了解释质量。

Conclusion: 相比标准显著性方法，该方法提供了更易理解和合理的SER模型解释，为可信赖的基于语音的情感计算奠定了基础。

Abstract: Explainable AI (XAI) for Speech Emotion Recognition (SER) is critical for building transparent, trustworthy models. Current saliency-based methods, adapted from vision, highlight spectrogram regions but fail to show whether these regions correspond to meaningful acoustic markers of emotion, limiting faithfulness and interpretability. We propose a framework that overcomes these limitations by quantifying the magnitudes of cues within salient regions. This clarifies "what" is highlighted and connects it to "why" it matters, linking saliency to expert-referenced acoustic cues of speech emotions. Experiments on benchmark SER datasets show that our approach improves explanation quality by explicitly linking salient regions to theory-driven speech emotions expert-referenced acoustics. Compared to standard saliency methods, it provides more understandable and plausible explanations of SER models, offering a foundational step towards trustworthy speech-based affective computing.

</details>


### [368] [AnchorDS: Anchoring Dynamic Sources for Semantically Consistent Text-to-3D Generation](https://arxiv.org/abs/2511.11692)
*Jiayin Zhu,Linlin Yang,Yicong Li,Angela Yao*

Main category: cs.LG

TL;DR: 本文提出AnchorDS方法，通过将文本到3D优化重新表述为动态演化源分布到固定目标分布的映射，解决了传统SDS方法中语义过平滑的问题，实现了更稳定的3D生成。


<details>
  <summary>Details</summary>
Motivation: 传统基于优化的文本到3D方法将2D生成模型的指导视为静态，忽略了源动态，导致语义线索被抑制或合并，产生语义过平滑伪影。

Method: 将问题投射到双条件潜空间，引入AnchorDS改进的分数蒸馏机制，提供图像条件的状态锚定指导，并设计轻量级过滤策略和微调策略来优化锚点。

Result: AnchorDS产生更精细的细节、更自然的颜色和更强的语义一致性，特别是在复杂提示下，同时在效率上超越先前方法。

Conclusion: 该方法在质量和效率上都优于先前方法，为文本到3D生成提供了更稳定和高质量的解决方案。

Abstract: Optimization-based text-to-3D methods distill guidance from 2D generative models via Score Distillation Sampling (SDS), but implicitly treat this guidance as static. This work shows that ignoring source dynamics yields inconsistent trajectories that suppress or merge semantic cues, leading to "semantic over-smoothing" artifacts. As such, we reformulate text-to-3D optimization as mapping a dynamically evolving source distribution to a fixed target distribution. We cast the problem into a dual-conditioned latent space, conditioned on both the text prompt and the intermediately rendered image. Given this joint setup, we observe that the image condition naturally anchors the current source distribution. Building on this insight, we introduce AnchorDS, an improved score distillation mechanism that provides state-anchored guidance with image conditions and stabilizes generation. We further penalize erroneous source estimates and design a lightweight filter strategy and fine-tuning strategy that refines the anchor with negligible overhead. AnchorDS produces finer-grained detail, more natural colours, and stronger semantic consistency, particularly for complex prompts, while maintaining efficiency. Extensive experiments show that our method surpasses previous methods in both quality and efficiency.

</details>


### [369] [Moirai 2.0: When Less Is More for Time Series Forecasting](https://arxiv.org/abs/2511.11698)
*Chenghao Liu,Taha Aksu,Juncheng Liu,Xu Liu,Hanshu Yan,Quang Pham,Doyen Sahoo,Caiming Xiong,Silvio Savarese,Junnan Li*

Main category: cs.LG

TL;DR: Moirai 2.0是一个基于解码器架构的时间序列基础模型，采用分位数预测和多令牌预测技术，在准确性和推理效率方面均有提升。相比Moirai 1.0，新版本简化了架构，速度提升2倍，模型大小缩小30倍，性能反而更好。


<details>
  <summary>Details</summary>
Motivation: 开发一个更高效、更准确的时间序列预测模型，通过简化架构和改进预测方法来提升性能，同时保持模型的小型化和快速推理能力。

Method: 采用解码器专用架构，使用分位数预测和多令牌预测技术，替换了之前的掩码编码器训练、多补丁输入和混合分布输出，使用单补丁和分位数损失。

Result: 在Gift-Eval基准测试中表现优异，达到顶级预训练模型水平；相比Moirai 1.0-Large，速度提升2倍，模型大小缩小30倍，性能更好；在领域级别结果稳健，能超越同系列更大模型。

Conclusion: 解码器专用架构和递归多分位数解码是性能提升的关键因素；模型性能随参数增加而趋于平稳，在较长预测期表现下降，未来需要在数据扩展和长期建模方面继续研究。

Abstract: We introduce Moirai 2.0, a decoder-only time-series foundation model trained on a new corpus of 36M series. The model adopts quantile forecasting and multi-token prediction, improving both probabilistic accuracy and inference efficiency. On the Gift-Eval benchmark, it ranks among the top pretrained models while achieving a strong trade-off between accuracy, speed, and model size. Compared to Moirai 1.0, Moirai 2.0 replaces masked-encoder training, multi-patch inputs, and mixture-distribution outputs with a simpler decoder-only architecture, single patch, and quantile loss. Ablation studies isolate these changes -- showing that the decoder-only backbone along with recursive multi-quantile decoding contribute most to the gains. Additional experiments show that Moirai 2.0 outperforms larger models from the same family and exhibits robust domain-level results. In terms of efficiency and model size, Moirai 2.0 is twice as fast and thirty times smaller than its prior best version, Moirai 1.0-Large, while also performing better. Model performance plateaus with increasing parameter count and declines at longer horizons, motivating future work on data scaling and long-horizon modeling. We release code and evaluation details to support further research.

</details>


### [370] [Tighter Truncated Rectangular Prism Approximation for RNN Robustness Verification](https://arxiv.org/abs/2511.11699)
*Xingqi Lin,Liangyu Chen,Min Wu,Min Zhang,Zhenbing Zeng*

Main category: cs.LG

TL;DR: 本文提出了一种新的截断矩形棱柱方法来紧密逼近RNN中的Hadamard积产生的三维非线性曲面，通过最小化体积和表面积实现更紧密的过近似，从而提高了RNN鲁棒性验证的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法对非线性激活函数进行线性过近似时，采用单独的线性边界平面，可能导致显著的过估计和较低的验证精度。为了解决这个问题，需要开发更紧密的过近似方法。

Method: 提出了一种新颖的截断矩形棱柱方法，由两个线性松弛平面形成，并采用细化驱动的方法来最小化其体积和表面积，以实现对Hadamard积产生的三维非线性曲面的紧密包围。基于此近似，实现了名为DeepPrism的RNN鲁棒性验证原型。

Result: 实验结果表明，DeepPrism在图像分类、语音识别和情感分析等多种任务中，相比最先进方法有显著改进。

Conclusion: 通过提出的截断矩形棱柱方法，能够更紧密地逼近RNN中的非线性激活函数，显著提高了鲁棒性验证的准确性，在各种实际应用中表现出优越性能。

Abstract: Robustness verification is a promising technique for rigorously proving Recurrent Neural Networks (RNNs) robustly. A key challenge is to over-approximate the nonlinear activation functions with linear constraints, which can transform the verification problem into an efficiently solvable linear programming problem. Existing methods over-approximate the nonlinear parts with linear bounding planes individually, which may cause significant over-estimation and lead to lower verification accuracy. In this paper, in order to tightly enclose the three-dimensional nonlinear surface generated by the Hadamard product, we propose a novel truncated rectangular prism formed by two linear relaxation planes and a refinement-driven method to minimize both its volume and surface area for tighter over-approximation. Based on this approximation, we implement a prototype DeepPrism for RNN robustness verification. The experimental results demonstrate that \emph{DeepPrism} has significant improvement compared with the state-of-the-art approaches in various tasks of image classification, speech recognition and sentiment analysis.

</details>


### [371] [Enhancing Reinforcement Learning in 3D Environments through Semantic Segmentation: A Case Study in ViZDoom](https://arxiv.org/abs/2511.11703)
*Hugo Huang*

Main category: cs.LG

TL;DR: 该论文提出两种基于语义分割的输入表示方法（SS-only和RGB+SS），解决了3D环境中强化学习的高内存消耗和部分可观测性问题，在ViZDoom死亡竞赛中验证了内存减少66.6%-98.6%且性能提升的效果。


<details>
  <summary>Details</summary>
Motivation: 解决3D环境中强化学习面临的两个主要挑战：高维感官输入导致的内存缓冲区高内存消耗，以及在部分可观测马尔可夫决策过程中的学习复杂性。

Method: 提出两种新颖的输入表示方法：SS-only（仅语义分割）和RGB+SS（RGB+语义分割），在ViZDoom死亡竞赛环境中进行实验，使用完美分割结果进行受控评估，并应用基于密度的热力图可视化RL智能体移动模式。

Result: SS-only方法能够将内存缓冲区内存消耗减少至少66.6%，在应用游程编码等无损压缩技术时最高可减少98.6%；RGB+SS通过提供额外语义信息显著提升了RL智能体的性能。

Conclusion: 语义分割输入表示方法有效解决了3D环境中强化学习的内存消耗和部分可观测性问题，同时提供了性能提升，并通过热力图可视化验证了数据收集的适用性。

Abstract: Reinforcement learning (RL) in 3D environments with high-dimensional sensory input poses two major challenges: (1) the high memory consumption induced by memory buffers required to stabilise learning, and (2) the complexity of learning in partially observable Markov Decision Processes (POMDPs). This project addresses these challenges by proposing two novel input representations: SS-only and RGB+SS, both employing semantic segmentation on RGB colour images. Experiments were conducted in deathmatches of ViZDoom, utilizing perfect segmentation results for controlled evaluation. Our results showed that SS-only was able to reduce the memory consumption of memory buffers by at least 66.6%, and up to 98.6% when a vectorisable lossless compression technique with minimal overhead such as run-length encoding is applied. Meanwhile, RGB+SS significantly enhances RL agents' performance with the additional semantic information provided. Furthermore, we explored density-based heatmapping as a tool to visualise RL agents' movement patterns and evaluate their suitability for data collection. A brief comparison with a previous approach highlights how our method overcame common pitfalls in applying semantic segmentation in 3D environments like ViZDoom.

</details>


### [372] [Simple Vision-Language Math Reasoning via Rendered Text](https://arxiv.org/abs/2511.11704)
*Matvey Skripkin,Elizaveta Goncharova,Andrey Kuznetsov*

Main category: cs.LG

TL;DR: 提出一种轻量级但有效的训练流程，通过将LaTeX公式渲染为图像并搭配结构化思维链提示，使紧凑型多模态架构在数学问题求解上达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 解决数学问题需要复杂的推理能力，传统方法在处理数学公式时存在局限性，希望通过视觉化表示提升模型对数学问题的理解和求解能力。

Method: 将LaTeX编码的数学公式渲染成图像，并与结构化思维链提示配对，构建文本到视觉的数据增强方法，训练紧凑型多模态架构。

Result: 在广泛使用的基准测试中，该方法持续匹配或超越开源和专有的数学视觉语言求解器，同时在MMMU、ChartQA和DocVQA等任务上提升高达20%。

Conclusion: 渲染保真度和提示设计是性能的主要驱动因素，这种简单的方法不仅提升了数学推理能力，还保持了广泛的通用领域能力。

Abstract: We present a lightweight yet effective pipeline for training vision-language models to solve math problems by rendering LaTeX encoded equations into images and pairing them with structured chain-of-thought prompts. This simple text-to-vision augmentation enables compact multimodal architectures to achieve state-of-the-art reasoning accuracy. Through systematic ablations, we find that rendering fidelity and prompt design are the primary drivers of performance. Despite its simplicity, our approach consistently matches or surpasses both open-source and proprietary math-focused vision-language solvers on widely used benchmarks, while preserving broad general-domain competence - showing gains on tasks such as MMMU, ChartQA, and DocVQA of up to 20%.

</details>


### [373] [Multimodal ML: Quantifying the Improvement of Calorie Estimation Through Image-Text Pairs](https://arxiv.org/abs/2511.11705)
*Arya Narang*

Main category: cs.LG

TL;DR: 研究通过比较仅使用图像的CNN模型和同时使用文本与图像的多模态CNN模型，发现添加菜品名称文本输入可将热量估计的MAE从84.76千卡降低到83.70千卡，提升1.25%。


<details>
  <summary>Details</summary>
Motivation: 探究短文本输入（如菜品名称）在多大程度上能改善热量估计，相比仅使用图像的基线模型，并验证改进是否具有统计显著性。

Method: 使用TensorFlow库和Nutrition5k数据集，训练仅使用图像的CNN模型和接受文本与图像输入的多模态CNN模型。

Result: 多模态模型将热量估计的平均绝对误差（MAE）从84.76千卡降低到83.70千卡，减少了1.06千卡，提升幅度为1.25%。

Conclusion: 短文本输入（菜品名称）能够小幅但显著地改善热量估计精度，多模态方法相比仅使用图像的方法具有统计显著的改进。

Abstract: This paper determines the extent to which short textual inputs (in this case, names of dishes) can improve calorie estimation compared to an image-only baseline model and whether any improvements are statistically significant. Utilizes the TensorFlow library and the Nutrition5k dataset (curated by Google) to train both an image-only CNN and multimodal CNN that accepts both text and an image as input. The MAE of calorie estimations was reduced by 1.06 kcal from 84.76 kcal to 83.70 kcal (1.25% improvement) when using the multimodal model.

</details>


### [374] [Context-Aware Multimodal Representation Learning for Spatio-Temporally Explicit Environmental modelling](https://arxiv.org/abs/2511.11706)
*Julia Peters,Karin Mora,Miguel D. Mahecha,Chaonan Ji,David Montero,Clemens Mosig,Guido Kraemer*

Main category: cs.LG

TL;DR: 提出了一个统一的地球观测表示学习框架，集成多模态遥感数据到高时空分辨率的特征空间，解决了现有模型固定时空尺度的限制。


<details>
  <summary>Details</summary>
Motivation: 现有地球观测基础模型通常在固定时空尺度下运行，限制了需要精细空间细节和高时间保真度的生态分析应用。

Method: 采用两阶段设计：首先独立建模各传感器特征，然后将表示组合到共享模型中。使用Sentinel-1和Sentinel-2数据作为代表性模态，实现10米分辨率和无云Sentinel-2采集频率。

Result: 学习到的嵌入在异质景观中表现出高空间和语义一致性，在总初级生产力建模中编码了生态学意义的模式并保持足够的时间保真度。

Conclusion: 该框架为需要不同时空分辨率的环境应用提供了灵活、分析就绪的表示学习方法。

Abstract: Earth observation (EO) foundation models have emerged as an effective approach to derive latent representations of the Earth system from various remote sensing sensors. These models produce embeddings that can be used as analysis-ready datasets, enabling the modelling of ecosystem dynamics without extensive sensor-specific preprocessing. However, existing models typically operate at fixed spatial or temporal scales, limiting their use for ecological analyses that require both fine spatial detail and high temporal fidelity. To overcome these limitations, we propose a representation learning framework that integrates different EO modalities into a unified feature space at high spatio-temporal resolution. We introduce the framework using Sentinel-1 and Sentinel-2 data as representative modalities. Our approach produces a latent space at native 10 m resolution and the temporal frequency of cloud-free Sentinel-2 acquisitions. Each sensor is first modeled independently to capture its sensor-specific characteristics. Their representations are then combined into a shared model. This two-stage design enables modality-specific optimisation and easy extension to new sensors, retaining pretrained encoders while retraining only fusion layers. This enables the model to capture complementary remote sensing data and to preserve coherence across space and time. Qualitative analyses reveal that the learned embeddings exhibit high spatial and semantic consistency across heterogeneous landscapes. Quantitative evaluation in modelling Gross Primary Production reveals that they encode ecologically meaningful patterns and retain sufficient temporal fidelity to support fine-scale analyses. Overall, the proposed framework provides a flexible, analysis-ready representation learning approach for environmental applications requiring diverse spatial and temporal resolutions.

</details>


### [375] [Federated Learning for Pediatric Pneumonia Detection: Enabling Collaborative Diagnosis Without Sharing Patient Data](https://arxiv.org/abs/2511.11714)
*Daniel M. Jimenez-Gutierrez,Enrique Zuazua,Joaquin Del Rio,Oleksii Sliusarenko,Xabi Uribe-Etxebarria*

Main category: cs.LG

TL;DR: 本文评估了使用Sherpa.ai联邦学习平台，让多家医院在不共享数据的情况下协作训练肺炎X光分类器。实验显示联邦学习显著提升了模型性能，准确率达到0.900，ROC-AUC达到0.966，相比单医院模型分别提升了47.5%和50.0%。


<details>
  <summary>Details</summary>
Motivation: 早期准确的肺炎检测对临床至关重要，但全球分布式数据、医院间差异和隐私法规使得数据集中化不可行，需要找到隐私保护的协作训练方法。

Method: 使用Sherpa.ai联邦学习平台，模拟医院间非独立同分布数据的协作训练，保持数据本地化，不传输任何患者X光图像。

Result: 联邦学习在多医院协作下实现了0.900的准确率和0.966的ROC-AUC，相比单医院模型（0.610准确率；0.644 ROC-AUC）有显著提升。

Conclusion: 联邦学习能够提供高性能、可泛化、安全且私密的肺炎检测方案，特别适用于罕见疾病和低数据领域，实现无需数据移动的多机构安全协作。

Abstract: Early and accurate pneumonia detection from chest X-rays (CXRs) is clinically critical to expedite treatment and isolation, reduce complications, and curb unnecessary antibiotic use. Although artificial intelligence (AI) substantially improves CXR-based detection, development is hindered by globally distributed data, high inter-hospital variability, and strict privacy regulations (e.g., HIPAA, GDPR) that make centralization impractical. These constraints are compounded by heterogeneous imaging protocols, uneven data availability, and the costs of transferring large medical images across geographically dispersed sites.
  In this paper, we evaluate Federated Learning (FL) using the Sherpa.ai FL platform, enabling multiple hospitals (nodes) to collaboratively train a CXR classifier for pneumonia while keeping data in place and private. Using the Pediatric Pneumonia Chest X-ray dataset, we simulate cross-hospital collaboration with non-independent and non-identically distributed (non-IID) data, reproducing real-world variability across institutions and jurisdictions. Our experiments demonstrate that collaborative and privacy-preserving training across multiple hospitals via FL led to a dramatic performance improvement achieving 0.900 Accuracy and 0.966 ROC-AUC, corresponding to 47.5% and 50.0% gains over single-hospital models (0.610; 0.644), without transferring any patient CXR. These results indicate that FL delivers high-performing, generalizable, secure and private pneumonia detection across healthcare networks, with data kept local. This is especially relevant for rare diseases, where FL enables secure multi-institutional collaboration without data movement, representing a breakthrough for accelerating diagnosis and treatment development in low-data domains.

</details>


### [376] [Multiscale Grassmann Manifolds for Single-Cell Data Analysis](https://arxiv.org/abs/2511.11717)
*Xiang Xiang Wang,Sean Cottrell,Guo-Wei Wei*

Main category: cs.LG

TL;DR: 提出基于Grassmann流形的多尺度框架，将机器学习与子空间几何结合用于单细胞数据分析，通过多尺度嵌入整合不同几何视角特征，在单细胞RNA-seq数据集上验证了有效性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统单细胞数据分析方法将细胞表示为欧几里得空间中的向量，限制了捕捉内在相关性和多尺度几何结构的能力，需要新的几何框架来更好地表征细胞异质性。

Method: 基于Grassmann流形的多尺度框架，生成多尺度表示下的嵌入，将不同几何视角的特征整合到统一的Grassmann流形中，并引入基于幂的尺度采样函数来控制尺度选择和平衡分辨率间信息。

Result: 在9个基准单细胞RNA-seq数据集上的实验表明，该方法能有效保留有意义的细胞结构，提供稳定的聚类性能，尤其适用于中小型数据集。

Conclusion: Grassmann流形为单细胞数据分析提供了连贯且信息丰富的基础，能够更好地捕捉细胞异质性的几何结构特征。

Abstract: Single-cell data analysis seeks to characterize cellular heterogeneity based on high-dimensional gene expression profiles. Conventional approaches represent each cell as a vector in Euclidean space, which limits their ability to capture intrinsic correlations and multiscale geometric structures. We propose a multiscale framework based on Grassmann manifolds that integrates machine learning with subspace geometry for single-cell data analysis. By generating embeddings under multiple representation scales, the framework combines their features from different geometric views into a unified Grassmann manifold. A power-based scale sampling function is introduced to control the selection of scales and balance in- formation across resolutions. Experiments on nine benchmark single-cell RNA-seq datasets demonstrate that the proposed approach effectively preserves meaningful structures and provides stable clustering performance, particularly for small to medium-sized datasets. These results suggest that Grassmann manifolds offer a coherent and informative foundation for analyzing single cell data.

</details>


### [377] [Fast 3D Surrogate Modeling for Data Center Thermal Management](https://arxiv.org/abs/2511.11722)
*Soumyendu Sarkar,Antonio Guillen-Perez,Zachariah J Carmichael,Avisek Naug,Refik Mert Cam,Vineet Gundecha,Ashwin Ramesh Babu,Sahand Ghorbanpour,Ricardo Luna Gutierrez*

Main category: cs.LG

TL;DR: 本文提出了一种基于视觉的替代建模框架，用于数据中心3D温度场的实时预测，相比传统CFD方法实现了20,000倍加速，能够实现实时冷却控制和负载重分配，从而节省7%的能源消耗。


<details>
  <summary>Details</summary>
Motivation: 减少数据中心能耗和碳排放对可持续发展和运营效率至关重要。传统热CFD求解器虽然准确但计算成本高，需要专家构建网格和边界条件，不适用于实时应用。

Method: 开发了基于视觉的替代建模框架，直接在数据中心的3D体素化表示上操作，结合服务器负载、风扇速度和HVAC温度设定点。评估了多种架构，包括3D CNN U-Net变体、3D傅里叶神经算子和3D视觉变换器。

Result: 替代模型能够泛化到不同的数据中心配置，实现了高达20,000倍的加速（从数小时缩短到数百毫秒）。能够快速准确地估计热点和温度分布。

Conclusion: 该方法实现了实时冷却控制和负载重分配，带来了显著的能源节省（7%）和碳足迹减少。

Abstract: Reducing energy consumption and carbon emissions in data centers by enabling real-time temperature prediction is critical for sustainability and operational efficiency. Achieving this requires accurate modeling of the 3D temperature field to capture airflow dynamics and thermal interactions under varying operating conditions. Traditional thermal CFD solvers, while accurate, are computationally expensive and require expert-crafted meshes and boundary conditions, making them impractical for real-time use. To address these limitations, we develop a vision-based surrogate modeling framework that operates directly on a 3D voxelized representation of the data center, incorporating server workloads, fan speeds, and HVAC temperature set points. We evaluate multiple architectures, including 3D CNN U-Net variants, a 3D Fourier Neural Operator, and 3D vision transformers, to map these thermal inputs to high-fidelity heat maps. Our results show that the surrogate models generalize across data center configurations and achieve up to 20,000x speedup (hundreds of milliseconds vs. hours). This fast and accurate estimation of hot spots and temperature distribution enables real-time cooling control and workload redistribution, leading to substantial energy savings (7\%) and reduced carbon footprint.

</details>


### [378] [Optimizing Input of Denoising Score Matching is Biased Towards Higher Score Norm](https://arxiv.org/abs/2511.11727)
*Tongda Xu*

Main category: cs.LG

TL;DR: 本文揭示了在扩散模型中通过去噪分数匹配优化条件输入会破坏与精确分数匹配的等价性，导致偏差和更高的分数范数，这种现象影响多个领域的研究工作。


<details>
  <summary>Details</summary>
Motivation: 许多近期研究利用去噪分数匹配来优化扩散模型的条件输入，但作者发现这种方法存在理论偏差，需要深入分析其对模型性能的影响。

Method: 通过理论分析和实验验证，证明去噪分数匹配优化条件输入会破坏与精确分数匹配的等价性，并展示这种偏差导致更高的分数范数。

Result: 研究发现这种偏差不仅存在于条件输入优化中，在利用预训练扩散模型优化数据分布时也会出现类似偏差，影响多个领域的研究工作。

Conclusion: 去噪分数匹配优化方法存在理论偏差，这种偏差会影响扩散模型在自回归生成、图像压缩和文本到3D生成等多个应用领域的性能表现。

Abstract: Many recent works utilize denoising score matching to optimize the conditional input of diffusion models. In this workshop paper, we demonstrate that such optimization breaks the equivalence between denoising score matching and exact score matching. Furthermore, we show that this bias leads to higher score norm. Additionally, we observe a similar bias when optimizing the data distribution using a pre-trained diffusion model. Finally, we discuss the wide range of works across different domains that are affected by this bias, including MAR for auto-regressive generation, PerCo for image compression, and DreamFusion for text to 3D generation.

</details>


### [379] [Physics-Informed Neural ODEs with Scale-Aware Residuals for Learning Stiff Biophysical Dynamics](https://arxiv.org/abs/2511.11734)
*Kamalpreet Singh Kainth,Prathamesh Dinesh Joshi,Raj Abhijit Dandekar,Rajat Dandekar,Sreedat Panat*

Main category: cs.LG

TL;DR: PI-NODE-SR结合低阶显式求解器和残差归一化，稳定训练并准确学习刚性生物物理系统的连续时间动力学，在Hodgkin-Huxley方程上成功预测超过100ms的振荡。


<details>
  <summary>Details</summary>
Motivation: 标准神经微分方程和物理信息变体在建模刚性生物物理系统时不可靠，需要大量迭代且可能收敛到次优解，无法保持振荡频率或振幅。

Method: 引入具有尺度感知残差的物理信息神经ODE（PI-NODE-SR），结合低阶显式求解器（Heun方法）和残差归一化，平衡不同时间尺度状态变量的贡献。

Result: 在Hodgkin-Huxley方程上，PI-NODE-SR从单个振荡学习并外推超过100ms，准确捕捉振荡频率和接近正确的振幅，恢复门控变量中的尖锐亚阈值曲率等形态特征。

Conclusion: PI-NODE-SR相对于基线神经ODE和PINNs持续减少长期误差，为稳定高效学习刚性生物动力学提供了原则性途径，尽管性能对初始化仍敏感。

Abstract: Neural differential equations offer a powerful framework for modeling continuous-time dynamics, but forecasting stiff biophysical systems remains unreliable. Standard Neural ODEs and physics informed variants often require orders of magnitude more iterations, and even then may converge to suboptimal solutions that fail to preserve oscillatory frequency or amplitude. We introduce PhysicsInformed Neural ODEs with with Scale-Aware Residuals (PI-NODE-SR), a framework that combines a low-order explicit solver (Heun method) residual normalisation to balance contributions between state variables evolving on disparate timescales. This combination stabilises training under realistic iteration budgets and avoids reliance on computationally expensive implicit solvers. On the Hodgkin-Huxley equations, PI-NODE-SR learns from a single oscillation simulated with a stiff solver (Rodas5P) and extrapolates beyond 100 ms, capturing both oscillation frequency and near-correct amplitudes. Remarkably, end-to-end learning of the vector field enables PI-NODE-SR to recover morphological features such as sharp subthreshold curvature in gating variables that are typically reserved for higher-order solvers, suggesting that neural correction can offset numerical diffusion. While performance remains sensitive to initialisation, PI-NODE-SR consistently reduces long-horizon errors relative to baseline Neural-ODEs and PINNs, offering a principled route to stable and efficient learning of stiff biological dynamics.

</details>


### [380] [Diffusion Models: A Mathematical Introduction](https://arxiv.org/abs/2511.11746)
*Sepehr Maleki,Negar Pourmoazemi*

Main category: cs.LG

TL;DR: 本文提供了一个基于扩散的生成模型的简洁自包含推导，从高斯分布的基本性质出发，构建了去噪扩散概率模型，涵盖了前向加噪过程、反向后验分布、变分下界等核心理论，并讨论了似然估计、加速采样、连续时间公式和引导扩散等关键主题。


<details>
  <summary>Details</summary>
Motivation: 为扩散生成模型提供一个透明、自包含的理论推导，使读者能够理解理论并实现相应算法，填补现有文献中理论推导不够系统化的空白。

Method: 从高斯分布的基本性质出发，系统地推导去噪扩散概率模型，包括前向加噪过程、闭式边际分布、精确离散反向后验分布和变分下界，然后扩展到连续时间公式、加速采样方法和引导扩散技术。

Result: 建立了扩散生成模型的完整理论框架，推导了标准噪声预测目标的简化形式，提出了概率流ODE和流匹配方法，并解释了分类器引导和无分类器引导的数学原理。

Conclusion: 通过透明的代数推导和一致的符号表示，为扩散生成模型提供了系统化的理论基础，使读者能够深入理解模型原理并实现相关算法，为后续研究提供了坚实的数学基础。

Abstract: We present a concise, self-contained derivation of diffusion-based generative models. Starting from basic properties of Gaussian distributions (densities, quadratic expectations, re-parameterisation, products, and KL divergences), we construct denoising diffusion probabilistic models from first principles. This includes the forward noising process, its closed-form marginals, the exact discrete reverse posterior, and the related variational bound. This bound simplifies to the standard noise-prediction goal used in practice. We then discuss likelihood estimation and accelerated sampling, covering DDIM, adversarially learned reverse dynamics (DDGAN), and multi-scale variants such as nested and latent diffusion, with Stable Diffusion as a canonical example. A continuous-time formulation follows, in which we derive the probability-flow ODE from the diffusion SDE via the continuity and Fokker-Planck equations, introduce flow matching, and show how rectified flows recover DDIM up to a time re-parameterisation. Finally, we treat guided diffusion, interpreting classifier guidance as a posterior score correction and classifier-free guidance as a principled interpolation between conditional and unconditional scores. Throughout, the focus is on transparent algebra, explicit intermediate steps, and consistent notation, so that readers can both follow the theory and implement the corresponding algorithms in practice.

</details>


### [381] [IDOL: Meeting Diverse Distribution Shifts with Prior Physics for Tropical Cyclone Multi-Task Estimation](https://arxiv.org/abs/2511.11750)
*Hanting Yan,Pan Mu,Shiqi Zhang,Yuchao Zhu,Jinglin Zhang,Cong Bai*

Main category: cs.LG

TL;DR: 本文提出了一种面向身份分布的物理不变学习框架（IDOL），通过引入基于先验物理知识的身份导向约束来处理热带气旋估计中的分布偏移问题，提高了在分布外场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 热带气旋估计面临复杂动态环境场导致的分布偏移挑战，现有方法多依赖多模态融合但忽视了特征表示的内在分布，导致在分布外场景下泛化能力差。

Method: 提出IDOL框架，利用风场模型和暗相关知识建模任务共享和任务特定的身份令牌，通过身份导向约束在物理知识指导下规范特征空间，处理分布变异性。

Result: 在多个数据集和任务上的广泛实验表明，IDOL在热带气旋风速、气压、内核和外核尺寸估计方面表现出色，有效缓解了各种分布偏移。

Conclusion: 基于先验物理知识施加身份导向约束能够有效缓解热带气旋估计中的分布偏移问题，验证了物理不变性在处理分布变异性中的重要性。

Abstract: Tropical Cyclone (TC) estimation aims to accurately estimate various TC attributes in real time. However, distribution shifts arising from the complex and dynamic nature of TC environmental fields, such as varying geographical conditions and seasonal changes, present significant challenges to reliable estimation. Most existing methods rely on multi-modal fusion for feature extraction but overlook the intrinsic distribution of feature representations, leading to poor generalization under out-of-distribution (OOD) scenarios. To address this, we propose an effective Identity Distribution-Oriented Physical Invariant Learning framework (IDOL), which imposes identity-oriented constraints to regulate the feature space under the guidance of prior physical knowledge, thereby dealing distribution variability with physical invariance. Specifically, the proposed IDOL employs the wind field model and dark correlation knowledge of TC to model task-shared and task-specific identity tokens. These tokens capture task dependencies and intrinsic physical invariances of TC, enabling robust estimation of TC wind speed, pressure, inner-core, and outer-core size under distribution shifts. Extensive experiments conducted on multiple datasets and tasks demonstrate the outperformance of the proposed IDOL, verifying that imposing identity-oriented constraints based on prior physical knowledge can effectively mitigates diverse distribution shifts in TC estimation.Code is available at https://github.com/Zjut-MultimediaPlus/IDOL.

</details>


### [382] [Sumudu Neural Operator for ODEs and PDEs](https://arxiv.org/abs/2511.11762)
*Ben Zelenskiy,Saibilila Abudukelimu,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.LG

TL;DR: 本文介绍了基于Sumudu变换的Sumudu神经算子(SNO)，通过多项式展开关系将输入分解为系数并转换到Sumudu空间进行参数化。在ODE和PDE任务中评估，SNO在PDE上表现优于FNO，与LNO竞争，并在某些PDE任务中取得最低误差。


<details>
  <summary>Details</summary>
Motivation: 探索Sumudu变换作为神经算子设计的潜力，特别是针对特定类型的偏微分方程，以提升神经算子的性能和准确性。

Method: 利用Sumudu变换的多项式展开关系，将输入空间分解为系数，然后转换到Sumudu空间进行神经算子参数化。

Result: SNO在PDE任务中表现优于FNO，与LNO竞争，在Euler-Bernoulli梁和扩散方程上取得最低误差。零样本超分辨率实验显示模型能从低质量样本获得更高质量数据。

Conclusion: 初步结果表明Sumudu变换作为神经算子设计具有前景，特别适用于某些类型的偏微分方程。

Abstract: We introduce the Sumudu Neural Operator (SNO), a neural operator rooted in the properties of the Sumudu Transform. We leverage the relationship between the polynomial expansions of transform pairs to decompose the input space as coefficients, which are then transformed into the Sumudu Space, where the neural operator is parameterized. We evaluate the operator in ODEs (Duffing Oscillator, Lorenz System, and Driven Pendulum) and PDEs (Euler-Bernoulli Beam, Burger's Equation, Diffusion, Diffusion-Reaction, and Brusselator). SNO achieves superior performance to FNO on PDEs and demonstrates competitive accuracy with LNO on several PDE tasks, including the lowest error on the Euler-Bernoulli Beam and Diffusion Equation. Additionally, we apply zero-shot super-resolution to the PDE tasks to observe the model's capability of obtaining higher quality data from low-quality samples. These preliminary findings suggest promise for the Sumudu Transform as a neural operator design, particularly for certain classes of PDEs.

</details>


### [383] [CATCHFed: Efficient Unlabeled Data Utilization for Semi-Supervised Federated Learning in Limited Labels Environments](https://arxiv.org/abs/2511.11778)
*Byoungjun Park,Pedro Porto Buarque de Gusmão,Dongjin Ji,Minhoe Kim*

Main category: cs.LG

TL;DR: CATCHFed是一种针对半监督联邦学习的方法，通过客户端感知的自适应阈值、混合阈值和一致性正则化，在服务器仅有少量标注数据的情况下有效利用客户端未标注数据提升性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界联邦学习中客户端往往缺乏标注数据，而现有半监督联邦学习方法在标注数据减少时性能显著下降，需要解决这一限制。

Method: 提出客户端感知的自适应阈值考虑类别难度，使用混合阈值提升伪标签质量，并利用未伪标注数据进行一致性正则化。

Result: 在多种数据集和配置下的广泛实验表明，CATCHFed能有效利用客户端未标注数据，在极有限标注设置下实现优越性能。

Conclusion: CATCHFed通过创新的阈值设计和数据利用策略，成功解决了半监督联邦学习在标注数据稀缺时的性能瓶颈问题。

Abstract: Federated learning is a promising paradigm that utilizes distributed client resources while preserving data privacy. Most existing FL approaches assume clients possess labeled data, however, in real-world scenarios, client-side labels are often unavailable. Semi-supervised Federated learning, where only the server holds labeled data, addresses this issue. However, it experiences significant performance degradation as the number of labeled data decreases. To tackle this problem, we propose \textit{CATCHFed}, which introduces client-aware adaptive thresholds considering class difficulty, hybrid thresholds to enhance pseudo-label quality, and utilizes unpseudo-labeled data for consistency regularization. Extensive experiments across various datasets and configurations demonstrate that CATCHFed effectively leverages unlabeled client data, achieving superior performance even in extremely limited-label settings.

</details>


### [384] [Simplicial covering dimension of extremal concept classes](https://arxiv.org/abs/2511.11819)
*Ari Blondal,Hamed Hatami,Pooya Hatami,Chavdar Lalov,Sivan Tretiak*

Main category: cs.LG

TL;DR: 该论文将经典拓扑维度理论（Lebesgue覆盖维数）应用于二元概念类，在可实现分布空间上定义单纯覆盖维数，并证明该维数精确刻画了有限概念类的列表可复制数（即全局稳定性）。


<details>
  <summary>Details</summary>
Motivation: 将拓扑维度理论引入机器学习领域，为理解概念类的学习复杂性提供新的数学工具，特别是为了刻画列表可复制性和全局稳定性等学习属性。

Method: 在概念类的可实现分布空间上引入单纯结构，定义单纯覆盖维数，并将该维数与PAC学习中的列表可复制数建立等价关系。

Result: 证明了对于有限概念类，单纯覆盖维数精确等于列表可复制数，从而能够应用经典维度理论工具计算极值概念类的精确列表可复制数。

Conclusion: 拓扑维度理论为分析机器学习中的列表可复制性提供了有力的数学框架，建立了维度理论与学习理论之间的深刻联系。

Abstract: Dimension theory is a branch of topology concerned with defining and analyzing dimensions of geometric and topological spaces in purely topological terms. In this work, we adapt the classical notion of topological dimension (Lebesgue covering) to binary concept classes. The topological space naturally associated with a concept class is its space of realizable distributions. The loss function and the class itself induce a simplicial structure on this space, with respect to which we define a simplicial covering dimension.
  We prove that for finite concept classes, this simplicial covering dimension exactly characterizes the list replicability number (equivalently, global stability) in PAC learning. This connection allows us to apply tools from classical dimension theory to compute the exact list replicability number of the broad family of extremal concept classes.

</details>


### [385] [On the Trade-Off Between Transparency and Security in Adversarial Machine Learning](https://arxiv.org/abs/2511.11842)
*Lucas Fenaux,Christopher Srinivasa,Florian Kerschbaum*

Main category: cs.LG

TL;DR: 本文通过可转移对抗样本攻击研究AI透明度与安全性的战略冲突，发现攻击者在匹配防御者决策时更成功，表明模糊性可能有利于防御者。


<details>
  <summary>Details</summary>
Motivation: 研究负责任AI中透明度与安全性在对抗环境下的潜在冲突，特别是在可转移对抗样本攻击场景中。

Method: 通过大规模实证评估（9种攻击方法、181个模型）和博弈论分析（纳什博弈和斯塔克尔伯格博弈），比较透明度与安全性的权衡。

Result: 攻击者在匹配防御者决策时更成功；仅知道防御者模型是否被防御就足以损害其安全性；透明度与安全性存在冲突。

Conclusion: AI系统的透明度可能与安全性相冲突，博弈论分析揭示了透明度与安全性之间的基本权衡。

Abstract: Transparency and security are both central to Responsible AI, but they may conflict in adversarial settings. We investigate the strategic effect of transparency for agents through the lens of transferable adversarial example attacks. In transferable adversarial example attacks, attackers maliciously perturb their inputs using surrogate models to fool a defender's target model. These models can be defended or undefended, with both players having to decide which to use. Using a large-scale empirical evaluation of nine attacks across 181 models, we find that attackers are more successful when they match the defender's decision; hence, obscurity could be beneficial to the defender. With game theory, we analyze this trade-off between transparency and security by modeling this problem as both a Nash game and a Stackelberg game, and comparing the expected outcomes. Our analysis confirms that only knowing whether a defender's model is defended or not can sometimes be enough to damage its security. This result serves as an indicator of the general trade-off between transparency and security, suggesting that transparency in AI systems can be at odds with security. Beyond adversarial machine learning, our work illustrates how game-theoretic reasoning can uncover conflicts between transparency and security.

</details>


### [386] [Leveraging Exogenous Signals for Hydrology Time Series Forecasting](https://arxiv.org/abs/2511.11849)
*Junyang He,Judy Fox,Alireza Jafari,Ying-Jung Chen,Geoffrey Fox*

Main category: cs.LG

TL;DR: 该研究探讨了在时间序列基础模型中融入领域知识对水文降雨-径流建模的影响，发现包含全面已知外生输入（特别是自然年周期时间序列）的模型表现优于有限输入方法，包括基础模型。


<details>
  <summary>Details</summary>
Motivation: 虽然时间序列基础模型研究取得进展，但很少研究其在物理科学特定下游应用中的有效性，特别是在水文降雨-径流建模领域。

Method: 使用CAMELS-US数据集（包含671个位置的降雨和径流数据，6个时间序列流和30个静态特征），比较基线模型和基础模型，重点研究领域知识整合的效果。

Result: 结果显示，融入全面已知外生输入的模型表现优于有限输入方法，其中自然年周期时间序列的融入贡献了最显著的改进。

Conclusion: 在时间序列建模中整合领域知识，特别是自然周期性特征，对于提升水文建模性能至关重要，基础模型需要更好地融入领域特定知识。

Abstract: Recent advances in time series research facilitate the development of foundation models. While many state-of-the-art time series foundation models have been introduced, few studies examine their effectiveness in specific downstream applications in physical science. This work investigates the role of integrating domain knowledge into time series models for hydrological rainfall-runoff modeling. Using the CAMELS-US dataset, which includes rainfall and runoff data from 671 locations with six time series streams and 30 static features, we compare baseline and foundation models. Results demonstrate that models incorporating comprehensive known exogenous inputs outperform more limited approaches, including foundation models. Notably, incorporating natural annual periodic time series contribute the most significant improvements.

</details>


### [387] [Better LLM Reasoning via Dual-Play](https://arxiv.org/abs/2511.11881)
*Zhengxin Zhang,Chengyu Huang,Aochong Oliver Li,Claire Cardie*

Main category: cs.LG

TL;DR: PasoDoble是一个无监督的LLM对抗训练框架，通过双角色模型（Proposer和Solver）的自我对抗学习提升推理能力，无需外部监督。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练依赖外部监督（如人工标注），对抗学习特别是自博弈方法可以减少对外部监督的依赖，但双角色对抗训练在LLM中应用有限，主要面临奖励破解和训练不稳定的挑战。

Method: 提出PasoDoble框架：从同一基础模型初始化两个模型，Proposer生成带真实答案的挑战性问题，Solver尝试解决；Proposer利用预训练数据确保问题质量；通过联合更新避免奖励破解；引入可选离线范式增强训练稳定性。

Result: 实验结果表明PasoDoble能够提升LLM的推理性能，且整个训练过程无需监督。

Conclusion: PasoDoble成功实现了无监督的LLM对抗训练，通过双角色自博弈机制有效提升了模型推理能力，为解决LLM训练依赖外部监督问题提供了可行方案。

Abstract: Large Language Models (LLMs) have achieved remarkable progress through Reinforcement Learning with Verifiable Rewards (RLVR), yet still rely heavily on external supervision (e.g., curated labels). Adversarial learning, particularly through self-play, offers a promising alternative that enables models to iteratively learn from themselves - thus reducing reliance on external supervision. Dual-play extends adversarial learning by assigning specialized roles to two models and training them against each other, fostering sustained competition and mutual evolution. Despite its promise, adapting dual-play training to LLMs remains limited, largely due to their susceptibility to reward hacking and training instability. In this paper, we introduce PasoDoble, a novel LLM dual-play framework. PasoDoble adversarially trains two models initialized from the same base model: a Proposer, which generates challenging questions with ground-truth answers, and a Solver, which attempts to solve them. We enrich the Proposer with knowledge from a pre-training dataset to ensure the questions' quality and diversity. To avoid reward hacking, the Proposer is rewarded for producing only valid questions that push the Solver's limit, while the Solver is rewarded for solving them correctly, and both are updated jointly. To further enhance training stability, we introduce an optional offline paradigm that decouples Proposer and Solver updates, alternately updating each for several steps while holding the other fixed. Notably, PasoDoble operates without supervision during training. Experimental results show that PasoDoble can improve the reasoning performance of LLMs. Our project page is available at https://hcy123902.github.io/PasoDoble.

</details>


### [388] [FLEX: Feature Importance from Layered Counterfactual Explanations](https://arxiv.org/abs/2511.11891)
*Nawid Keshtmand,Roussel Desmond Nzoyem,Jeffrey Nicholas Clark*

Main category: cs.LG

TL;DR: FLEX是一个模型和领域无关的框架，将反事实解释转换为局部、区域和全局层面的特征变化频率评分，弥合了局部补救和全局归因之间的差距。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型缺乏可解释性限制了在高风险环境中的安全部署，现有反事实解释通常停留在实例层面，无法量化哪些特征在特征空间的连贯区域或整个数据集中系统地驱动结果变化。

Method: 通过聚合跨实例和邻域的反事实解释，将特征变化频率转化为可解释的排名，反映每个特征需要改变多少次才能翻转预测，兼容不同的反事实生成方法。

Result: 在交通事故严重性预测和贷款审批任务中，FLEX的全局排名与SHAP相关但揭示了额外驱动因素，区域分析揭示了全局摘要遗漏的上下文特定因素。

Conclusion: FLEX弥合了局部补救和全局归因之间的差距，支持风险敏感应用中的透明和干预导向决策。

Abstract: Machine learning models achieve state-of-the-art performance across domains, yet their lack of interpretability limits safe deployment in high-stakes settings. Counterfactual explanations are widely used to provide actionable "what-if" recourse, but they typically remain instance-specific and do not quantify which features systematically drive outcome changes within coherent regions of the feature space or across an entire dataset. We introduce FLEX (Feature importance from Layered counterfactual EXplanations), a model- and domain-agnostic framework that converts sets of counterfactuals into feature change frequency scores at local, regional, and global levels. FLEX generalises local change-frequency measures by aggregating across instances and neighbourhoods, offering interpretable rankings that reflect how often each feature must change to flip predictions. The framework is compatible with different counterfactual generation methods, allowing users to emphasise characteristics such as sparsity, feasibility, or actionability, thereby tailoring the derived feature importances to practical constraints. We evaluate FLEX on two contrasting tabular tasks: traffic accident severity prediction and loan approval, and compare FLEX to SHAP- and LIME-derived feature importance values. Results show that (i) FLEX's global rankings correlate with SHAP while surfacing additional drivers, and (ii) regional analyses reveal context-specific factors that global summaries miss. FLEX thus bridges the gap between local recourse and global attribution, supporting transparent and intervention-oriented decision-making in risk-sensitive applications.

</details>


### [389] [Chain-of-Generation: Progressive Latent Diffusion for Text-Guided Molecular Design](https://arxiv.org/abs/2511.11894)
*Lingxiao Li,Haobo Zhang,Bin Chen,Jiayu Zhou*

Main category: cs.LG

TL;DR: 本文提出Chain-of-Generation (CoG)框架，通过多阶段潜在扩散方法解决文本条件分子生成中的挑战，相比一次性条件生成能更好地满足复杂提示要求。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的文本条件分子生成方法采用一次性条件编码，难以同时满足提示中的所有要求，存在生成组件可解释性差、无法生成所有子结构、同时考虑所有要求过于激进等问题。

Method: 提出CoG框架：将提示分解为课程顺序的语义片段，在去噪过程中逐步引入作为中间目标；增加后对齐学习阶段加强文本与分子潜在空间的对应关系。

Result: 在基准和真实任务上的实验表明，CoG相比一次性基线方法在语义对齐、多样性和可控性方面表现更好，能更忠实地反映复杂组合提示。

Conclusion: CoG通过多阶段渐进式生成策略有效解决了文本条件分子生成中的关键挑战，提供了更透明、可控的生成过程。

Abstract: Text-conditioned molecular generation aims to translate natural-language descriptions into chemical structures, enabling scientists to specify functional groups, scaffolds, and physicochemical constraints without handcrafted rules. Diffusion-based models, particularly latent diffusion models (LDMs), have recently shown promise by performing stochastic search in a continuous latent space that compactly captures molecular semantics. Yet existing methods rely on one-shot conditioning, where the entire prompt is encoded once and applied throughout diffusion, making it hard to satisfy all the requirements in the prompt. We discuss three outstanding challenges of one-shot conditioning generation, including the poor interpretability of the generated components, the failure to generate all substructures, and the overambition in considering all requirements simultaneously. We then propose three principles to address those challenges, motivated by which we propose Chain-of-Generation (CoG), a training-free multi-stage latent diffusion framework. CoG decomposes each prompt into curriculum-ordered semantic segments and progressively incorporates them as intermediate goals, guiding the denoising trajectory toward molecules that satisfy increasingly rich linguistic constraints. To reinforce semantic guidance, we further introduce a post-alignment learning phase that strengthens the correspondence between textual and molecular latent spaces. Extensive experiments on benchmark and real-world tasks demonstrate that CoG yields higher semantic alignment, diversity, and controllability than one-shot baselines, producing molecules that more faithfully reflect complex, compositional prompts while offering transparent insight into the generation process.

</details>


### [390] [A Systematic Study of Model Extraction Attacks on Graph Foundation Models](https://arxiv.org/abs/2511.11912)
*Haoyan Xu,Ruizhi Qian,Jiate Li,Yushun Dong,Minghao Lin,Hanson Yan,Zhengtao Yao,Qinghua Liu,Junhao Dong,Ruopeng Huang,Yue Zhao,Mengyuan Li*

Main category: cs.LG

TL;DR: 本文首次系统研究了针对图基础模型(GFMs)的模型提取攻击(MEAs)，揭示了GFMs显著扩大了MEA攻击面，攻击者仅需极小成本即可近似受害者模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着图基础模型(GFMs)的发展，这些模型因包含大量计算和领域专业知识而成为有价值的知识资产，但其高预训练成本和跨领域知识也使其成为模型提取攻击的诱人目标。

Method: 提出了轻量级提取方法，通过监督回归图嵌入来训练攻击者编码器，即使没有对比预训练数据也能保持与受害者文本编码器的对齐并保留零样本推理能力。

Result: 在7个数据集上的实验表明，攻击者仅需原始训练成本的极小部分即可近似受害者模型，准确率几乎没有损失。

Conclusion: GFMs极大地扩展了MEA攻击面，凸显了在大规模图学习系统中部署感知安全防御的必要性。

Abstract: Graph machine learning has advanced rapidly in tasks such as link prediction, anomaly detection, and node classification. As models scale up, pretrained graph models have become valuable intellectual assets because they encode extensive computation and domain expertise. Building on these advances, Graph Foundation Models (GFMs) mark a major step forward by jointly pretraining graph and text encoders on massive and diverse data. This unifies structural and semantic understanding, enables zero-shot inference, and supports applications such as fraud detection and biomedical analysis. However, the high pretraining cost and broad cross-domain knowledge in GFMs also make them attractive targets for model extraction attacks (MEAs). Prior work has focused only on small graph neural networks trained on a single graph, leaving the security implications for large-scale and multimodal GFMs largely unexplored. This paper presents the first systematic study of MEAs against GFMs. We formalize a black-box threat model and define six practical attack scenarios covering domain-level and graph-specific extraction goals, architectural mismatch, limited query budgets, partial node access, and training data discrepancies. To instantiate these attacks, we introduce a lightweight extraction method that trains an attacker encoder using supervised regression of graph embeddings. Even without contrastive pretraining data, this method learns an encoder that stays aligned with the victim text encoder and preserves its zero-shot inference ability on unseen graphs. Experiments on seven datasets show that the attacker can approximate the victim model using only a tiny fraction of its original training cost, with almost no loss in accuracy. These findings reveal that GFMs greatly expand the MEA surface and highlight the need for deployment-aware security defenses in large-scale graph learning systems.

</details>


### [391] [A Systematic Analysis of Out-of-Distribution Detection Under Representation and Training Paradigm Shifts](https://arxiv.org/abs/2511.11934)
*C. César Claros Olivares,Austin J. Brockmeier*

Main category: cs.LG

TL;DR: 本文系统比较了不同OOD检测方法在CLIP分层机制下的表现，发现特征空间对OOD检测效果起决定性作用。概率得分方法在误分类检测中表现最佳，而几何感知方法在CNN上对强分布偏移更有效，ViT上GradNorm和KPCA重建误差表现稳定。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对OOD检测方法在不同表示范式下的系统性比较，需要为方法选择提供统计依据。

Method: 使用AURC和AUGRC作为主要指标，比较CNN从头训练和ViT微调两种表示范式，采用多重比较控制的基于排名的统计流程（Friedman检验和Conover-Holm事后检验）以及Bron-Kerbosch团分析。

Result: 学习到的特征空间很大程度上决定了OOD检测效果。概率得分方法在误分类检测中占主导，几何感知方法在CNN上对强偏移更有效，ViT上GradNorm和KPCA重建误差表现稳定。MCD存在类别数量依赖的权衡，简单PCA投影可改进多个检测器。

Conclusion: 结果支持以表示为中心的OOD检测观点，并为分布偏移下的方法选择提供了统计基础指导。

Abstract: We present a systematic comparison of out-of-distribution (OOD) detection methods across CLIP-stratified regimes using AURC and AUGRC as primary metrics. Experiments cover two representation paradigms: CNNs trained from scratch and a fine-tuned Vision Transformer (ViT), evaluated on CIFAR-10/100, SuperCIFAR-100, and TinyImageNet. Using a multiple-comparison-controlled, rank-based pipeline (Friedman test with Conover-Holm post-hoc) and Bron-Kerbosch cliques, we find that the learned feature space largely determines OOD efficacy. For both CNNs and ViTs, probabilistic scores (e.g., MSR, GEN) dominate misclassification (ID) detection. Under stronger shifts, geometry-aware scores (e.g., NNGuide, fDBD, CTM) prevail on CNNs, whereas on ViTs GradNorm and KPCA Reconstruction Error remain consistently competitive. We further show a class-count-dependent trade-off for Monte-Carlo Dropout (MCD) and that a simple PCA projection improves several detectors. These results support a representation-centric view of OOD detection and provide statistically grounded guidance for method selection under distribution shift.

</details>


### [392] [SurvBench: A Standardised Preprocessing Pipeline for Multi-Modal Electronic Health Record Survival Analysis](https://arxiv.org/abs/2511.11935)
*Munib Mesinovic,Tingting Zhu*

Main category: cs.LG

TL;DR: SurvBench是一个开源预处理流程，将原始PhysioNet数据集转换为标准化的多模态生存分析张量，解决了深度学习生存模型预处理不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据为深度学习生存分析提供了巨大机会，但由于预处理方法不一致，可重复性受到严重限制。

Method: 提供三个重症监护数据库的数据加载器，支持时间序列生命体征、静态人口统计、ICD诊断代码和放射学报告等多种模态，实施严格的数据质量控制、患者级分割、显式缺失值跟踪和标准化时间聚合。

Result: SurvBench处理单风险和竞争风险场景，输出与pycox库兼容，支持标准统计和深度学习模型。

Conclusion: 通过提供可重复的、配置驱动的预处理和全面文档，SurvBench解决了阻碍深度学习生存模型公平比较的"预处理差距"，使研究人员能够专注于方法创新而非数据工程。

Abstract: Electronic health record (EHR) data present tremendous opportunities for advancing survival analysis through deep learning, yet reproducibility remains severely constrained by inconsistent preprocessing methodologies. We present SurvBench, a comprehensive, open-source preprocessing pipeline that transforms raw PhysioNet datasets into standardised, model-ready tensors for multi-modal survival analysis. SurvBench provides data loaders for three major critical care databases, MIMIC-IV, eICU, and MC-MED, supporting diverse modalities including time-series vitals, static demographics, ICD diagnosis codes, and radiology reports. The pipeline implements rigorous data quality controls, patient-level splitting to prevent data leakage, explicit missingness tracking, and standardised temporal aggregation. SurvBench handles both single-risk (e.g., in-hospital mortality) and competing-risks scenarios (e.g., multiple discharge outcomes). The outputs are compatible with pycox library packages and implementations of standard statistical and deep learning models. By providing reproducible, configuration-driven preprocessing with comprehensive documentation, SurvBench addresses the "preprocessing gap" that has hindered fair comparison of deep learning survival models, enabling researchers to focus on methodological innovation rather than data engineering.

</details>


### [393] [Learning the relative composition of EEG signals using pairwise relative shift pretraining](https://arxiv.org/abs/2511.11940)
*Christopher Sandino,Sayeri Lala,Geeling Chau,Melika Ayoughi,Behrooz Mahasseni,Ellen Zippi,Ali Moin,Erdrin Azemi,Hanlin Goh*

Main category: cs.LG

TL;DR: 提出了一种名为PARS的新型自监督学习预训练方法，通过预测随机采样的EEG窗口对之间的相对时间偏移来学习脑电图的长程依赖关系，在多种EEG解码任务中优于现有的预训练策略。


<details>
  <summary>Details</summary>
Motivation: 当前EEG自监督学习方法主要使用掩码重建策略（如MAE），这些方法主要捕捉局部时间模式，而能够学习神经信号长程依赖关系的位置预测预训练方法尚未得到充分探索。

Method: 引入PARS预训练方法，这是一种新颖的前置任务，通过预测随机采样的EEG窗口对之间的相对时间偏移，鼓励编码器捕捉神经信号中固有的相对时间组成和长程依赖关系。

Result: 在多种EEG解码任务的综合评估中，PARS预训练的transformers在标签高效和迁移学习设置中始终优于现有的预训练策略。

Conclusion: PARS为自监督EEG表示学习建立了一个新的范式，能够有效学习神经信号的长程依赖关系。

Abstract: Self-supervised learning (SSL) offers a promising approach for learning electroencephalography (EEG) representations from unlabeled data, reducing the need for expensive annotations for clinical applications like sleep staging and seizure detection. While current EEG SSL methods predominantly use masked reconstruction strategies like masked autoencoders (MAE) that capture local temporal patterns, position prediction pretraining remains underexplored despite its potential to learn long-range dependencies in neural signals. We introduce PAirwise Relative Shift or PARS pretraining, a novel pretext task that predicts relative temporal shifts between randomly sampled EEG window pairs. Unlike reconstruction-based methods that focus on local pattern recovery, PARS encourages encoders to capture relative temporal composition and long-range dependencies inherent in neural signals. Through comprehensive evaluation on various EEG decoding tasks, we demonstrate that PARS-pretrained transformers consistently outperform existing pretraining strategies in label-efficient and transfer learning settings, establishing a new paradigm for self-supervised EEG representation learning.

</details>


### [394] [Computation-aware Energy-harvesting Federated Learning: Cyclic Scheduling with Selective Participation](https://arxiv.org/abs/2511.11949)
*Eunjeong Jeong,Nikolaos Pappas*

Main category: cs.LG

TL;DR: FedBacys是一个电池感知的联邦学习框架，通过基于用户电池水平的循环客户端参与来优化能量收集联邦学习系统的能耗问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在分布式学习中具有强大能力，但其复杂性导致客户端训练模型的计算能耗显著。在能量收集联邦学习系统中，由于能量有限，每个设备的参与可用性会波动，这一问题尤为关键。

Method: 提出FedBacys框架，通过聚类客户端并按电池水平顺序调度参与，最小化冗余计算。还提出FedBacys-Odd变体，允许客户端选择性参与以进一步降低能耗。

Result: 提供了框架的收敛性分析，并通过数值实验证明其相比现有算法在能效和鲁棒性方面的优越性。

Conclusion: FedBacys框架能显著减少系统范围内的能量使用，提高学习稳定性，同时不牺牲性能。

Abstract: Federated Learning (FL) is a powerful paradigm for distributed learning, but its increasing complexity leads to significant energy consumption from client-side computations for training models. In particular, the challenge is critical in energy-harvesting FL (EHFL) systems where participation availability of each device oscillates due to limited energy. To address this, we propose FedBacys, a battery-aware EHFL framework using cyclic client participation based on users' battery levels. By clustering clients and scheduling them sequentially, FedBacys minimizes redundant computations, reduces system-wide energy usage, and improves learning stability. We also introduce FedBacys-Odd, a more energy-efficient variant that allows clients to participate selectively, further reducing energy costs without compromising performance. We provide a convergence analysis for our framework and demonstrate its superior energy efficiency and robustness compared to existing algorithms through numerical experiments.

</details>


### [395] [Quantile Q-Learning: Revisiting Offline Extreme Q-Learning with Quantile Regression](https://arxiv.org/abs/2511.11973)
*Xinming Gao,Shangzhe Li,Yujin Cai,Wenwu Yu*

Main category: cs.LG

TL;DR: 本文提出了一种改进的离线强化学习方法，通过量化回归估计温度系数β，并引入值正则化技术来解决XQL和MXQL方法中的超参数调优困难和训练不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在固定数据集上学习策略而无需环境交互，在风险高或成本高的领域特别有价值。XQL方法虽然性能强劲，但存在超参数调优困难和训练不稳定的问题。

Method: 提出通过量化回归在温和假设下估计温度系数β的方法，并引入受约束值学习启发的值正则化技术来改善训练稳定性。

Result: 实验结果表明，所提算法在D4RL和NeoRL2等基准任务上实现了竞争性或更优的性能，同时保持稳定的训练动态，并在所有数据集和领域中使用一致的超参数集。

Conclusion: 该方法有效解决了离线强化学习中超参数调优困难和训练不稳定的问题，为实际应用提供了更可靠和稳定的解决方案。

Abstract: Offline reinforcement learning (RL) enables policy learning from fixed datasets without further environment interaction, making it particularly valuable in high-risk or costly domains. Extreme $Q$-Learning (XQL) is a recent offline RL method that models Bellman errors using the Extreme Value Theorem, yielding strong empirical performance. However, XQL and its stabilized variant MXQL suffer from notable limitations: both require extensive hyperparameter tuning specific to each dataset and domain, and also exhibit instability during training. To address these issues, we proposed a principled method to estimate the temperature coefficient $β$ via quantile regression under mild assumptions. To further improve training stability, we introduce a value regularization technique with mild generalization, inspired by recent advances in constrained value learning. Experimental results demonstrate that the proposed algorithm achieves competitive or superior performance across a range of benchmark tasks, including D4RL and NeoRL2, while maintaining stable training dynamics and using a consistent set of hyperparameters across all datasets and domains.

</details>


### [396] [ReCast: Reliability-aware Codebook Assisted Lightweight Time Series Forecasting](https://arxiv.org/abs/2511.11991)
*Xiang Ma,Taihua Chen,Pengcheng Wang,Xuemei Li,Caiming Zhang*

Main category: cs.LG

TL;DR: ReCast是一个轻量级时间序列预测框架，通过可学习码本编码局部模式，采用双路径架构处理规则结构和不规则波动，并引入可靠性感知的码本更新策略来提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖全局分解，对局部复杂动态模式效果不佳，且模型复杂度高，难以在资源受限环境中应用。

Method: 使用可学习码本进行补丁量化编码局部模式，采用双路径架构（量化路径和残差路径），通过分布鲁棒优化融合多可靠性因子进行码本更新。

Result: 在准确性、效率和分布偏移适应性方面优于现有最先进模型。

Conclusion: ReCast框架能够有效捕捉局部重复模式，实现轻量级且鲁棒的时间序列预测。

Abstract: Time series forecasting is crucial for applications in various domains. Conventional methods often rely on global decomposition into trend, seasonal, and residual components, which become ineffective for real-world series dominated by local, complex, and highly dynamic patterns. Moreover, the high model complexity of such approaches limits their applicability in real-time or resource-constrained environments. In this work, we propose a novel \textbf{RE}liability-aware \textbf{C}odebook-\textbf{AS}sisted \textbf{T}ime series forecasting framework (\textbf{ReCast}) that enables lightweight and robust prediction by exploiting recurring local shapes. ReCast encodes local patterns into discrete embeddings through patch-wise quantization using a learnable codebook, thereby compactly capturing stable regular structures. To compensate for residual variations not preserved by quantization, ReCast employs a dual-path architecture comprising a quantization path for efficient modeling of regular structures and a residual path for reconstructing irregular fluctuations. A central contribution of ReCast is a reliability-aware codebook update strategy, which incrementally refines the codebook via weighted corrections. These correction weights are derived by fusing multiple reliability factors from complementary perspectives by a distributionally robust optimization (DRO) scheme, ensuring adaptability to non-stationarity and robustness to distribution shifts. Extensive experiments demonstrate that ReCast outperforms state-of-the-art (SOTA) models in accuracy, efficiency, and adaptability to distribution shifts.

</details>


### [397] [Selecting Fine-Tuning Examples by Quizzing VLMs](https://arxiv.org/abs/2511.12002)
*Tenghao Ji,Eytan Adar*

Main category: cs.LG

TL;DR: QZLoRA是一个用于选择图像进行低秩适应的框架，通过QuizRank方法自动对图像进行排名，从而在少量样本下生成更对齐、更逼真的图像。


<details>
  <summary>Details</summary>
Motivation: 在针对特定主题微调文本到图像扩散模型时，选择高质量的训练图像是一个挑战。从质量参差不齐的图像集（如维基共享资源）进行微调通常会产生较差的输出结果。

Method: 提出QZLoRA框架，利用QuizRank方法将图像视为'教育干预'并通过视觉语言模型进行'测验'来自动对图像进行排名，然后进行低秩适应（LoRA）微调。

Result: QZLoRA能够用更少的样本生成更对齐、更逼真的图像，并且这些微调后的模型也能生成具有代表性的风格化图像（如插图）。

Conclusion: 研究结果表明，将自动视觉推理与参数高效微调相结合，在主题自适应生成建模方面具有广阔前景。

Abstract: A challenge in fine-tuning text-to-image diffusion models for specific topics is to select good examples. Fine-tuning from image sets of varying quality, such as Wikipedia Commons, will often produce poor output. However, training images that \textit{do} exemplify the target concept (e.g., a \textit{female Mountain Bluebird}) help ensure that the generated images are similarly representative (e.g., have the prototypical blue-wings and gray chest). In this work, we propose QZLoRA, a framework to select images for low-rank adaptation (LoRA). The approach leverages QuizRank, a method to automatically rank images by treating them as an `educational intervention' and `quizzing' a VLM. We demonstrate that QZLoRA can produce better aligned, photorealistic images with fewer samples. We also show that these fine-tuned models can produce stylized that are similarly representative (i.e., illustrations). Our results highlight the promise of combining automated visual reasoning with parameter-efficient fine-tuning for topic-adaptive generative modeling.

</details>


### [398] [EARL: Entropy-Aware RL Alignment of LLMs for Reliable RTL Code Generation](https://arxiv.org/abs/2511.12033)
*Jiahe Shi,Zhengqi Gao,Ching-Yun Ko,Duane Boning*

Main category: cs.LG

TL;DR: EARL是一个基于熵感知强化学习的Verilog生成框架，通过选择性更新高熵令牌来提升RTL代码生成的功能正确性和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在RTL代码生成中存在语法错误、功能幻觉和设计意图对齐不足的问题，需要更有效的强化学习方法来提升生成质量。

Method: 提出EARL框架，使用可验证奖励信号进行策略优化，并引入熵引导的选择性更新机制，将梯度更新集中在高不确定性令牌上。

Result: 在VerilogEval和RTLLM数据集上的实验表明，EARL将功能通过率提升了14.7%，同时减少了不必要的更新并提高了训练稳定性。

Conclusion: 将强化学习集中在关键高熵令牌上，能够实现更可靠和有针对性的结构化RTL代码生成策略改进。

Abstract: Recent advances in large language models (LLMs) have demonstrated significant potential in hardware design automation, particularly in using natural language to synthesize Register-Transfer Level (RTL) code. Despite this progress, a gap remains between model capability and the demands of real-world RTL design, including syntax errors, functional hallucinations, and weak alignment to designer intent. Reinforcement Learning with Verifiable Rewards (RLVR) offers a promising approach to bridge this gap, as hardware provides executable and formally checkable signals that can be used to further align model outputs with design intent. However, in long, structured RTL code sequences, not all tokens contribute equally to functional correctness, and naïvely spreading gradients across all tokens dilutes learning signals. A key insight from our entropy analysis in RTL generation is that only a small fraction of tokens (e.g., always, if, assign, posedge) exhibit high uncertainty and largely influence control flow and module structure. To address these challenges, we present EARL, an Entropy-Aware Reinforcement Learning framework for Verilog generation. EARL performs policy optimization using verifiable reward signals and introduces entropy-guided selective updates that gate policy gradients to high-entropy tokens. This approach preserves training stability and concentrates gradient updates on functionally important regions of code. Our experiments on VerilogEval and RTLLM show that EARL improves functional pass rates over prior LLM baselines by up to 14.7%, while reducing unnecessary updates and improving training stability. These results indicate that focusing RL on critical, high-uncertainty tokens enables more reliable and targeted policy improvement for structured RTL code generation.

</details>


### [399] [Mesh-based Super-resolution of Detonation Flows with Multiscale Graph Transformers](https://arxiv.org/abs/2511.12041)
*Shivam Barwey,Pinaki Pal*

Main category: cs.LG

TL;DR: 本文提出了一种首创的多尺度图变换器方法（SR-GT），用于基于网格的反应流超分辨率重建，该方法在复杂几何和非均匀/非结构化网格上表现出色，相比传统插值方法具有更高精度。


<details>
  <summary>Details</summary>
Motivation: 开发数据驱动的超分辨率流重建技术对于亚网格闭合建模、加速时空预测、数据压缩以及稀疏实验测量的升尺度处理等应用具有重要价值。

Method: 采用基于图的流场表示方法，结合变换器架构捕捉低分辨率流场不同部分之间的长程依赖关系，识别重要特征，并生成保留这些特征的高分辨率流场。使用独特的元素局部（+邻域）图表示对粗输入进行标记化处理。

Result: 在2D氢-空气预混气体爆轰传播的挑战性测试问题中，SR-GT框架对反应流场特征提供了高精度的超分辨率重建，性能优于传统的基于插值的超分辨率方案。

Conclusion: SR-GT方法在复杂多尺度反应流行为中表现出卓越的超分辨率能力，为基于网格的流场超分辨率重建提供了有效的数据驱动解决方案。

Abstract: Super-resolution flow reconstruction using state-of-the-art data-driven techniques is valuable for a variety of applications, such as subgrid/subfilter closure modeling, accelerating spatiotemporal forecasting, data compression, and serving as an upscaling tool for sparse experimental measurements. In the present work, a first-of-its-kind multiscale graph transformer approach is developed for mesh-based super-resolution (SR-GT) of reacting flows. The novel data-driven modeling paradigm leverages a graph-based flow-field representation compatible with complex geometries and non-uniform/unstructured grids. Further, the transformer backbone captures long-range dependencies between different parts of the low-resolution flow-field, identifies important features, and then generates the super-resolved flow-field that preserves those features at a higher resolution. The performance of SR-GT is demonstrated in the context of spectral-element-discretized meshes for a challenging test problem of 2D detonation propagation within a premixed hydrogen-air mixture exhibiting highly complex multiscale reacting flow behavior. The SR-GT framework utilizes a unique element-local (+ neighborhood) graph representation for the coarse input, which is then tokenized before being processed by the transformer component to produce the fine output. It is demonstrated that SR-GT provides high super-resolution accuracy for reacting flow-field features and superior performance compared to traditional interpolation-based SR schemes.

</details>


### [400] [Improving Graph Embeddings in Machine Learning Using Knowledge Completion with Validation in a Case Study on COVID-19 Spread](https://arxiv.org/abs/2511.12071)
*Rosario Napoli,Gabriele Morabito,Antonio Celesti,Massimo Villari,Maria Fazio*

Main category: cs.LG

TL;DR: 本文提出了一种集成知识补全阶段的图机器学习流水线，通过发现稀疏数据中的隐式语义来改进图嵌入表示质量。


<details>
  <summary>Details</summary>
Motivation: 由于图嵌入仅从显式拓扑和特征中提取，可能错过稀疏数据集中隐藏的关键隐式知识，影响图结构及其表示质量。

Method: 在嵌入生成前加入知识补全阶段，专注于传递关系，使用基于衰减的推理函数建模隐藏连接，重塑图拓扑结构。

Result: 实验表明该流水线显著改变了嵌入空间的几何结构，证明其引入不仅是简单丰富，而是重新定义图表示质量的变革性步骤。

Conclusion: 集成知识补全的图机器学习流水线能够通过发现隐式语义来重新定义图表示质量，对图嵌入的动态性和聚合过程产生重要影响。

Abstract: The rise of graph-structured data has driven major advances in Graph Machine Learning (GML), where graph embeddings (GEs) map features from Knowledge Graphs (KGs) into vector spaces, enabling tasks like node classification and link prediction. However, since GEs are derived from explicit topology and features, they may miss crucial implicit knowledge hidden in seemingly sparse datasets, affecting graph structure and their representation. We propose a GML pipeline that integrates a Knowledge Completion (KC) phase to uncover latent dataset semantics before embedding generation. Focusing on transitive relations, we model hidden connections with decay-based inference functions, reshaping graph topology, with consequences on embedding dynamics and aggregation processes in GraphSAGE and Node2Vec. Experiments show that our GML pipeline significantly alters the embedding space geometry, demonstrating that its introduction is not just a simple enrichment but a transformative step that redefines graph representation quality.

</details>


### [401] [Treatment Stitching with Schrödinger Bridge for Enhancing Offline Reinforcement Learning in Adaptive Treatment Strategies](https://arxiv.org/abs/2511.12075)
*Dong-Hee Shin,Deok-Joong Lee,Young-Han Son,Tae-Eui Kam*

Main category: cs.LG

TL;DR: 提出了TreatStitch数据增强框架，通过智能拼接现有治疗轨迹段来生成临床有效的治疗轨迹，以解决离线强化学习在临床数据稀缺情况下的性能限制问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在优化自适应治疗策略时面临数据稀缺的挑战，而传统的在线强化学习方法在临床环境中不可行，因为可能对患者造成伤害。

Method: 开发了Treatment Stitching框架，通过识别不同轨迹中相似的中间患者状态并拼接相应段；当状态差异较大时，使用薛定谔桥方法生成平滑的桥接轨迹。

Result: 在多个治疗数据集上的广泛实验证明了TreatStitch在提升离线强化学习性能方面的有效性。

Conclusion: TreatStitch通过生成合成轨迹来增强数据集多样性，同时保持临床有效性，避免了分布外转移，为优化自适应治疗策略提供了有效解决方案。

Abstract: Adaptive treatment strategies (ATS) are sequential decision-making processes that enable personalized care by dynamically adjusting treatment decisions in response to evolving patient symptoms. While reinforcement learning (RL) offers a promising approach for optimizing ATS, its conventional online trial-and-error learning mechanism is not permissible in clinical settings due to risks of harm to patients. Offline RL tackles this limitation by learning policies exclusively from historical treatment data, but its performance is often constrained by data scarcity-a pervasive challenge in clinical domains. To overcome this, we propose Treatment Stitching (TreatStitch), a novel data augmentation framework that generates clinically valid treatment trajectories by intelligently stitching segments from existing treatment data. Specifically, TreatStitch identifies similar intermediate patient states across different trajectories and stitches their respective segments. Even when intermediate states are too dissimilar to stitch directly, TreatStitch leverages the Schrödinger bridge method to generate smooth and energy-efficient bridging trajectories that connect dissimilar states. By augmenting these synthetic trajectories into the original dataset, offline RL can learn from a more diverse dataset, thereby improving its ability to optimize ATS. Extensive experiments across multiple treatment datasets demonstrate the effectiveness of TreatStitch in enhancing offline RL performance. Furthermore, we provide a theoretical justification showing that TreatStitch maintains clinical validity by avoiding out-of-distribution transitions.

</details>


### [402] [To Align or Not to Align: Strategic Multimodal Representation Alignment for Optimal Performance](https://arxiv.org/abs/2511.12121)
*Wanlong Fang,Tianle Zhang,Alvin Chan*

Main category: cs.LG

TL;DR: 本文研究了显式对齐在多模态学习中对模型性能的影响，发现对齐效果取决于模态间的冗余度，存在最优对齐强度来平衡模态特定信号和共享冗余。


<details>
  <summary>Details</summary>
Motivation: 传统多模态学习普遍假设表征对齐总是有益的，但缺乏对显式对齐在不同模态信息结构下直接影响的系统性研究。

Method: 引入可控对比学习模块，在训练过程中精确操纵对齐强度，研究不同数据特征下显式对齐对性能的影响。

Result: 在合成和真实数据集上的实验表明，显式对齐对单模态模型性能的影响与数据特征相关，最优对齐水平取决于不同模态间的冗余量。

Conclusion: 本研究为何时以及如何应用显式对齐以实现最优单模态编码器性能提供了实践指导。

Abstract: Multimodal learning often relies on aligning representations across modalities to enable effective information integration, an approach traditionally assumed to be universally beneficial. However, prior research has primarily taken an observational approach, examining naturally occurring alignment in multimodal data and exploring its correlation with model performance, without systematically studying the direct effects of explicitly enforced alignment between representations of different modalities. In this work, we investigate how explicit alignment influences both model performance and representation alignment under different modality-specific information structures. Specifically, we introduce a controllable contrastive learning module that enables precise manipulation of alignment strength during training, allowing us to explore when explicit alignment improves or hinders performance. Our results on synthetic and real datasets under different data characteristics show that the impact of explicit alignment on the performance of unimodal models is related to the characteristics of the data: the optimal level of alignment depends on the amount of redundancy between the different modalities. We identify an optimal alignment strength that balances modality-specific signals and shared redundancy in the mixed information distributions. This work provides practical guidance on when and how explicit alignment should be applied to achieve optimal unimodal encoder performance.

</details>


### [403] [Dynamic Anomaly Identification in Accounting Transactions via Multi-Head Self-Attention Networks](https://arxiv.org/abs/2511.12122)
*Yi Wang,Ruoyi Fang,Anzhuo Xie,Hanrui Feng,Jianlin Lai*

Main category: cs.LG

TL;DR: 该研究提出了一种基于Transformer的实时异常检测方法，用于会计交易中的动态异常检测，通过时间序列建模和多头自注意力机制来捕捉全局依赖关系，在公开数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂交易环境中隐藏异常行为和高时效性要求的挑战，为智能财务风险控制和审计提供方法支持。

Method: 将多维会计交易记录建模为时间序列矩阵，使用嵌入层和位置编码实现低维映射，构建多头自注意力序列建模结构，集成前馈层和正则化策略进行深度特征表示和异常概率估计。

Result: 在AUC、F1-Score、Precision和Recall等指标上优于基线模型，在不同环境条件和数据扰动下保持稳定性能。

Conclusion: 基于Transformer的框架在会计交易动态异常检测中具有适用性和优势，为智能财务风险控制和审计提供了有效的方法支持。

Abstract: This study addresses the problem of dynamic anomaly detection in accounting transactions and proposes a real-time detection method based on a Transformer to tackle the challenges of hidden abnormal behaviors and high timeliness requirements in complex trading environments. The approach first models accounting transaction data by representing multi-dimensional records as time-series matrices and uses embedding layers and positional encoding to achieve low-dimensional mapping of inputs. A sequence modeling structure with multi-head self-attention is then constructed to capture global dependencies and aggregate features from multiple perspectives, thereby enhancing the ability to detect abnormal patterns. The network further integrates feed-forward layers and regularization strategies to achieve deep feature representation and accurate anomaly probability estimation. To validate the effectiveness of the method, extensive experiments were conducted on a public dataset, including comparative analysis, hyperparameter sensitivity tests, environmental sensitivity tests, and data sensitivity tests. Results show that the proposed method outperforms baseline models in AUC, F1-Score, Precision, and Recall, and maintains stable performance under different environmental conditions and data perturbations. These findings confirm the applicability and advantages of the Transformer-based framework for dynamic anomaly detection in accounting transactions and provide methodological support for intelligent financial risk control and auditing.

</details>


### [404] [HCPO: Hierarchical Conductor-Based Policy Optimization in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.12123)
*Zejiao Liu,Junqi Tu,Yitian Hong,Luolin Xiong,Yaochu Jin,Yang Tang,Fangfei Li*

Main category: cs.LG

TL;DR: 提出了一种基于指挥者的联合策略框架和分层指挥者策略优化算法，通过协调多智能体探索来提升合作多智能体强化学习的性能。


<details>
  <summary>Details</summary>
Motivation: 现有合作多智能体强化学习方法通常通过独立智能体探索来更新联合策略，缺乏智能体间的协调，限制了联合策略的表达能力和探索效率。

Method: 提出基于指挥者的联合策略框架，直接增强联合策略的表达能力并协调探索；开发分层指挥者策略优化算法，指导指挥者和智能体的策略更新方向与性能改进对齐；通过部署局部指挥者，在保持集中训练优势的同时消除执行时的智能体间通信。

Result: 在StarCraftII多智能体挑战、多智能体MuJoCo和多智能体粒子环境三个基准测试中，HCPO在合作效率和稳定性方面优于竞争性多智能体强化学习基线方法。

Conclusion: HCPO通过协调多智能体探索和增强联合策略表达能力，显著提升了合作多智能体强化学习的性能，并提供了严格的理论保证。

Abstract: In cooperative Multi-Agent Reinforcement Learning (MARL), efficient exploration is crucial for optimizing the performance of joint policy. However, existing methods often update joint policies via independent agent exploration, without coordination among agents, which inherently constrains the expressive capacity and exploration of joint policies. To address this issue, we propose a conductor-based joint policy framework that directly enhances the expressive capacity of joint policies and coordinates exploration. In addition, we develop a Hierarchical Conductor-based Policy Optimization (HCPO) algorithm that instructs policy updates for the conductor and agents in a direction aligned with performance improvement. A rigorous theoretical guarantee further establishes the monotonicity of the joint policy optimization process. By deploying local conductors, HCPO retains centralized training benefits while eliminating inter-agent communication during execution. Finally, we evaluate HCPO on three challenging benchmarks: StarCraftII Multi-agent Challenge, Multi-agent MuJoCo, and Multi-agent Particle Environment. The results indicate that HCPO outperforms competitive MARL baselines regarding cooperative efficiency and stability.

</details>


### [405] [Variation-Bounded Loss for Noise-Tolerant Learning](https://arxiv.org/abs/2511.12143)
*Jialiang Wang,Xiong Zhou,Xianming Liu,Gangfeng Hu,Deming Zhai,Junjun Jiang,Haoliang Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的鲁棒损失函数属性——变异比，并基于此构建了变异有界损失函数家族，通过理论分析证明较小的变异比能带来更好的鲁棒性，同时为放松对称条件提供了可行方法。


<details>
  <summary>Details</summary>
Motivation: 缓解噪声标签对监督学习的负面影响是一个长期存在的问题，鲁棒损失函数已成为解决该问题的流行方案。本文旨在通过引入变异比这一新属性来改进损失函数的鲁棒性。

Method: 提出变异比作为损失函数鲁棒性的新属性，构建变异有界损失函数家族，提供变异比的理论分析，并基于变异比重新形式化几种常用损失函数用于实际应用。

Result: 在各种数据集上的积极实验表明该方法的有效性和灵活性，变异比为放松对称条件提供了可行方法，并提供了实现非对称条件的更简洁路径。

Conclusion: 变异比是损失函数鲁棒性的重要属性，变异有界损失函数家族在噪声标签环境下表现出良好的性能，为鲁棒学习提供了新的理论框架和实用工具。

Abstract: Mitigating the negative impact of noisy labels has been aperennial issue in supervised learning. Robust loss functions have emerged as a prevalent solution to this problem. In this work, we introduce the Variation Ratio as a novel property related to the robustness of loss functions, and propose a new family of robust loss functions, termed Variation-Bounded Loss (VBL), which is characterized by a bounded variation ratio. We provide theoretical analyses of the variation ratio, proving that a smaller variation ratio would lead to better robustness. Furthermore, we reveal that the variation ratio provides a feasible method to relax the symmetric condition and offers a more concise path to achieve the asymmetric condition. Based on the variation ratio, we reformulate several commonly used loss functions into a variation-bounded form for practical applications. Positive experiments on various datasets exhibit the effectiveness and flexibility of our approach.

</details>


### [406] [Open Banking Foundational Model: Learning Language Representations from Few Financial Transactions](https://arxiv.org/abs/2511.12154)
*Gustavo Polleti,Marlesson Santana,Eduardo Fontes*

Main category: cs.LG

TL;DR: 提出了一种多模态金融交易基础模型，整合结构化属性和非结构化文本描述，在数据稀缺的开放银行场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决金融交易中结构化数据和非结构化文本信息的整合问题，特别是在数据稀缺的开放银行环境下提升模型性能。

Method: 采用掩码语言建模方法处理交易序列，构建统一的多模态表示框架。

Result: 模型在数千家北美金融机构的大规模研究中表现优于传统特征工程和离散事件序列方法，能够跨地域和机构泛化。

Conclusion: 自监督模型在欺诈预防、信用风险和客户洞察等金融应用领域具有巨大潜力。

Abstract: We introduced a multimodal foundational model for financial transactions that integrates both structured attributes and unstructured textual descriptions into a unified representation. By adapting masked language modeling to transaction sequences, we demonstrated that our approach not only outperforms classical feature engineering and discrete event sequence methods but is also particularly effective in data-scarce Open Banking scenarios. To our knowledge, this is the first large-scale study across thousands of financial institutions in North America, providing evidence that multimodal representations can generalize across geographies and institutions. These results highlight the potential of self-supervised models to advance financial applications ranging from fraud prevention and credit risk to customer insights

</details>


### [407] [Rethinking Deep Alignment Through The Lens Of Incomplete Learning](https://arxiv.org/abs/2511.12155)
*Thong Bach,Dung Nguyen,Thao Minh Le,Truyen Tran*

Main category: cs.LG

TL;DR: 本文揭示了大型语言模型在对抗攻击中的系统性漏洞源于自回归训练中的位置依赖梯度弱化，导致安全学习不完整。作者提出了基于偏好的标记作为计算指标，并开发了针对性的补全方法，显著提升了模型的对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管进行了广泛的安全对齐，大型语言模型仍存在系统性对抗攻击漏洞。本文旨在从机制层面分析这一问题的根源，并提供实用的解决方案。

Method: 通过机制分析识别位置依赖梯度弱化问题，提出基于偏好的标记作为安全学习不完整的计算指标，开发了包含自适应惩罚和混合教师蒸馏的针对性补全方法。

Result: 在Llama和Qwen模型系列上的实验评估显示，对抗鲁棒性显著提升，攻击成功率降低48-98%，同时保持通用能力。

Conclusion: 本研究为安全对齐方法的基本局限性提供了机制层面的理解，并开发了实用的解决方案，显著提升了语言模型的对抗鲁棒性。

Abstract: Large language models exhibit systematic vulnerabilities to adversarial attacks despite extensive safety alignment. We provide a mechanistic analysis revealing that position-dependent gradient weakening during autoregressive training creates signal decay, leading to incomplete safety learning where safety training fails to transform model preferences in later response regions fully. We introduce base-favored tokens -- vocabulary elements where base models assign higher probability than aligned models -- as computational indicators of incomplete safety learning and develop a targeted completion method that addresses undertrained regions through adaptive penalties and hybrid teacher distillation. Experimental evaluation across Llama and Qwen model families demonstrates dramatic improvements in adversarial robustness, with 48--98% reductions in attack success rates while preserving general capabilities. These results establish both a mechanistic understanding and practical solutions for fundamental limitations in safety alignment methodologies.

</details>


### [408] [FGM optimization in complex domains using Gaussian process regression based profile generation algorithm](https://arxiv.org/abs/2511.12171)
*Chaitanya Kumar Konda,Piyush Agrawal,Shivansh Srivastava,Manish Agrawal*

Main category: cs.LG

TL;DR: 提出基于高斯过程回归的功能梯度材料体积分数分布生成算法，可处理任意形状域并生成平滑分布，结合改进的遗传算法进行优化设计。


<details>
  <summary>Details</summary>
Motivation: 解决任意形状域功能梯度材料设计的挑战，传统方法难以处理复杂几何形状和边界条件。

Method: 使用高斯过程回归生成体积分数分布，结合改进的遗传算法（包含投影算子的模拟二进制交叉）进行优化。

Result: 算法能处理复杂形状域，生成平滑的功能梯度材料分布，并通过热弹性优化示例验证了有效性。

Conclusion: 提出的方法为任意形状域功能梯度材料设计提供了通用框架，增强了发现最优配置的潜力。

Abstract: This manuscript addresses the challenge of designing functionally graded materials (FGMs) for arbitrary-shaped domains. Towards this goal, the present work proposes a generic volume fraction profile generation algorithm based on Gaussian Process Regression (GPR). The proposed algorithm can handle complex-shaped domains and generate smooth FGM profiles while adhering to the specified volume fraction values at boundaries/part of boundaries. The resulting design space from GPR comprises diverse profiles, enhancing the potential for discovering optimal configurations. Further, the algorithm allows the user to control the smoothness of the underlying profiles and the size of the design space through a length scale parameter. Further, the proposed profile generation scheme is coupled with the genetic algorithm to find the optimum FGM profiles for a given application. To make the genetic algorithm consistent with the GPR profile generation scheme, the standard simulated binary crossover operator in the genetic algorithm has been modified with a projection operator. We present numerous thermoelastic optimization examples to demonstrate the efficacy of the proposed profile generation algorithm and optimization framework.

</details>


### [409] [Understanding InfoNCE: Transition Probability Matrix Induced Feature Clustering](https://arxiv.org/abs/2511.12180)
*Ge Cheng,Shuo Wang,Yun Zhang*

Main category: cs.LG

TL;DR: 本文提出了SC-InfoNCE损失函数，通过引入可调收敛目标来灵活控制特征相似性对齐，在图像、图结构和文本任务上均取得稳定性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管InfoNCE在对比学习中取得了经验性成功，但其理论基础仍然有限。本文旨在深入理解InfoNCE的理论机制，并提出改进方法。

Method: 引入显式特征空间建模样本增强视图，使用转移概率矩阵捕捉数据增强动态，提出SC-InfoNCE损失函数，通过缩放目标矩阵灵活控制特征相似性对齐。

Result: 在图像、图结构和文本任务的基准数据集上，SC-InfoNCE始终实现强大且可靠的性能表现。

Conclusion: SC-InfoNCE通过引入可调收敛目标，使训练目标能更好地匹配下游数据的统计特性，在多个领域均展现出优越性能。

Abstract: Contrastive learning has emerged as a cornerstone of unsupervised representation learning across vision, language, and graph domains, with InfoNCE as its dominant objective. Despite its empirical success, the theoretical underpinnings of InfoNCE remain limited. In this work, we introduce an explicit feature space to model augmented views of samples and a transition probability matrix to capture data augmentation dynamics. We demonstrate that InfoNCE optimizes the probability of two views sharing the same source toward a constant target defined by this matrix, naturally inducing feature clustering in the representation space. Leveraging this insight, we propose Scaled Convergence InfoNCE (SC-InfoNCE), a novel loss function that introduces a tunable convergence target to flexibly control feature similarity alignment. By scaling the target matrix, SC-InfoNCE enables flexible control over feature similarity alignment, allowing the training objective to better match the statistical properties of downstream data. Experiments on benchmark datasets, including image, graph, and text tasks, show that SC-InfoNCE consistently achieves strong and reliable performance across diverse domains.

</details>


### [410] [Evaluation of Multi- and Single-objective Learning Algorithms for Imbalanced Data](https://arxiv.org/abs/2511.12191)
*Szymon Wojciechowski,Michał Woźniak*

Main category: cs.LG

TL;DR: 本文提出了一种新的可靠方法来评估基于多目标优化的算法与返回单一解的方法，重点在于如何从Pareto前沿中选择符合用户偏好的解进行比较。


<details>
  <summary>Details</summary>
Motivation: 解决多目标优化算法与单解算法之间的比较难题，填补分类器评估方法学中的空白。

Method: 提出新的评估框架，从多目标算法返回的Pareto前沿中选择符合用户偏好的解，与单解算法进行可靠比较。

Result: 建立了一个能够公平比较多目标优化算法和单解算法的评估方法。

Conclusion: 所提出的方法填补了多目标优化算法评估方法学的空白，为算法比较提供了可靠框架。

Abstract: Many machine learning tasks aim to find models that work well not for a single, but for a group of criteria, often opposing ones. One such example is imbalanced data classification, where, on the one hand, we want to achieve the best possible classification quality for data from the minority class without degrading the classification quality of the majority class. One solution is to propose an aggregate learning criterion and reduce the multi-objective learning task to a single-criteria optimization problem. Unfortunately, such an approach is characterized by ambiguity of interpretation since the value of the aggregated criterion does not indicate the value of the component criteria. Hence, there are more and more proposals for algorithms based on multi-objective optimization (MOO), which can simultaneously optimize multiple criteria. However, such an approach results in a set of multiple non-dominated solutions (Pareto front). The selection of a single solution from the Pareto front is a challenge itself, and much attention is paid to the issue of how to select it considering user preferences, as well as how to compare solutions returned by different MOO algorithms among themselves. Thus, a significant gap has been identified in the classifier evaluation methodology, i.e., how to reliably compare methods returning single solutions with algorithms returning solutions in the form of Pareto fronts.
  To fill the aforementioned gap, this article proposes a new, reliable way of evaluating algorithms based on multi-objective algorithms with methods that return single solutions while pointing out solutions from a Pareto front tailored to the user's preferences. This work focuses only on algorithm comparison, not their learning. The algorithms selected for this study are illustrative to help understand the proposed approach.

</details>


### [411] [AlignTree: Efficient Defense Against LLM Jailbreak Attacks](https://arxiv.org/abs/2511.12217)
*Gil Goren,Shahar Katz,Lior Wolf*

Main category: cs.LG

TL;DR: AlignTree是一种针对大型语言模型对抗攻击的防御机制，通过监控模型激活并使用随机森林分类器检测不安全的生成行为，在保持低计算开销的同时增强模型对齐。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到对抗攻击，绕过安全指南生成有害内容。现有防御方法要么计算成本高，要么容易被绕过，无法在实际系统中有效应用。

Method: AlignTree在生成过程中监控LLM激活，使用高效的随机森林分类器检测不匹配行为。分类器基于两个信号：拒绝方向（对不匹配提示激活的线性表示）和基于SVM的非线性特征信号。

Result: 通过大量实验证明，AlignTree在多个LLM和基准测试中表现出高效性和鲁棒性。

Conclusion: AlignTree提供了一种无需额外提示或辅助防护模型的防御方案，在保持最小计算开销的同时有效增强模型对齐。

Abstract: Large Language Models (LLMs) are vulnerable to adversarial attacks that bypass safety guidelines and generate harmful content. Mitigating these vulnerabilities requires defense mechanisms that are both robust and computationally efficient. However, existing approaches either incur high computational costs or rely on lightweight defenses that can be easily circumvented, rendering them impractical for real-world LLM-based systems. In this work, we introduce the AlignTree defense, which enhances model alignment while maintaining minimal computational overhead. AlignTree monitors LLM activations during generation and detects misaligned behavior using an efficient random forest classifier. This classifier operates on two signals: (i) the refusal direction -- a linear representation that activates on misaligned prompts, and (ii) an SVM-based signal that captures non-linear features associated with harmful content. Unlike previous methods, AlignTree does not require additional prompts or auxiliary guard models. Through extensive experiments, we demonstrate the efficiency and robustness of AlignTree across multiple LLMs and benchmarks.

</details>


### [412] [Chicken Swarm Kernel Particle Filter: A Structured Rejuvenation Approach with KLD-Efficient Sampling](https://arxiv.org/abs/2511.12222)
*Hangshuo Tian*

Main category: cs.LG

TL;DR: 本文研究了粒子滤波中鸡群优化算法与KLD自适应采样之间的理论交互作用，发现CSO增强的粒子滤波在相同统计误差下需要更少的粒子数。


<details>
  <summary>Details</summary>
Motivation: 理解基于群体智能的粒子重生成核与基于KLD的自适应采样之间的理论交互作用，目前这方面的理论理解还不充分。

Method: 在简化建模框架下分析CSO重生成步骤对粒子集分布的影响，将CSO的适应度驱动更新近似为均方收缩，并应用Karamata不等式分析KLD采样中的期望箱占用情况。

Result: 分析表明，在相同统计误差界限下，CSO增强的粒子滤波比标准粒子滤波需要更低的期望粒子数。

Conclusion: 研究提供了一个可处理的理论框架来解释这些技术结合时观察到的计算效率，并为设计更高效的自适应滤波器提供了起点。

Abstract: Particle filters (PFs) are often combined with swarm intelligence (SI) algorithms, such as Chicken Swarm Optimization (CSO), for particle rejuvenation. Separately, Kullback--Leibler divergence (KLD) sampling is a common strategy for adaptively sizing the particle set. However, the theoretical interaction between SI-based rejuvenation kernels and KLD-based adaptive sampling is not yet fully understood.
  This paper investigates this specific interaction. We analyze, under a simplified modeling framework, the effect of the CSO rejuvenation step on the particle set distribution. We propose that the fitness-driven updates inherent in CSO can be approximated as a form of mean-square contraction. This contraction tends to produce a particle distribution that is more concentrated than that of a baseline PF, or in mathematical terms, a distribution that is plausibly more ``peaked'' in a majorization sense.
  By applying Karamata's inequality to the concave function that governs the expected bin occupancy in KLD-sampling, our analysis suggests a connection: under the stated assumptions, the CSO-enhanced PF (CPF) is expected to require a lower \emph{expected} particle count than the standard PF to satisfy the same statistical error bound. The goal of this study is not to provide a fully general proof, but rather to offer a tractable theoretical framework that helps to interpret the computational efficiency empirically observed when combining these techniques, and to provide a starting point for designing more efficient adaptive filters.

</details>


### [413] [SCI: An Equilibrium for Signal Intelligence](https://arxiv.org/abs/2511.12240)
*Vishal Joshua Meesala*

Main category: cs.LG

TL;DR: SCI是一个闭环控制理论框架，将可解释性建模为受控状态，通过主动驱动手术精度SP(t)向目标值收敛，在人类增益预算下更新参数Theta，显著降低解释误差并提高稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统静态解释器存在解释误差大、稳定性差的问题，需要将可解释性建模为动态控制目标，实现更稳定、可恢复和可信的解释行为。

Method: SCI框架包含三个协调组件：可靠性加权的多尺度特征P(t,s)、知识引导的解释器psi_Theta（输出可追踪标记和理由）、以及配备回滚、信任域保护和下降条件的Lyapunov引导控制器。

Result: 在生物医学、工业和环境领域，SCI相比静态解释器将解释误差降低25-42%（平均38%），同时保持AUC/F1在基线1-2个百分点内，SP方差从0.030降至0.011。

Conclusion: 将可解释性建模为控制目标可在不同信号机制下产生更稳定、更快恢复和更可信的解释行为。

Abstract: We present SCI, a closed-loop, control-theoretic framework that models interpretability as a regulated state. SCI formalizes the interpretive error Delta SP and actively drives SP(t) in [0, 1] ("Surgical Precision") toward a target via a projected update on the parameters Theta under a human-gain budget. The framework operates through three coordinated components: (1) reliability-weighted, multiscale features P(t, s); (2) a knowledge-guided interpreter psi_Theta that emits traceable markers and rationales; and (3) a Lyapunov-guided controller equipped with rollback, trust-region safeguards, and a descent condition. Across biomedical (EEG/ECG/ICU), industrial (bearings/tool wear), and environmental (climate/seismic) domains, SCI reduces interpretive error by 25-42% (mean 38%, 95% confidence interval 22-43%) relative to static explainers while maintaining AUC/F1 within approximately 1-2 percentage points of baseline. SCI also reduces SP variance from 0.030 to 0.011, indicating substantially more stable explanations. Modeling interpretability as a control objective yields steadier, faster-recovering, and more trustworthy interpretive behavior across diverse signal regimes.

</details>


### [414] [Cross-view Joint Learning for Mixed-Missing Multi-view Unsupervised Feature Selection](https://arxiv.org/abs/2511.12261)
*Zongxin Shen,Yanyong Huang,Dongjie Wang,Jinyuan Chang,Fengmao Lv,Tianrui Li,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: 提出CLIM-FS方法解决混合缺失的多视图无监督特征选择问题，通过联合学习特征选择和自适应数据填补，并利用一致性聚类结构和跨视图局部几何结构增强学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在三个关键挑战：1) 仅关注视图缺失问题，不适用于实践中更普遍的混合缺失场景；2) 对视图间一致性和多样性的利用不足；3) 缺乏理论分析来阐明特征选择和数据填补在联合学习过程中的相互作用机制。

Method: 基于非负正交矩阵分解的特征选择模型，集成缺失视图和变量的填补，联合学习特征选择和自适应数据填补。充分利用一致性聚类结构和跨视图局部几何结构来增强协同学习过程。

Result: 在八个真实世界多视图数据集上的实验结果表明，CLIM-FS优于最先进的方法。

Conclusion: CLIM-FS是一种新颖的IMUFS方法，能有效解决混合缺失问题，通过理论分析和实验验证了其优越性能。

Abstract: Incomplete multi-view unsupervised feature selection (IMUFS), which aims to identify representative features from unlabeled multi-view data containing missing values, has received growing attention in recent years. Despite their promising performance, existing methods face three key challenges: 1) by focusing solely on the view-missing problem, they are not well-suited to the more prevalent mixed-missing scenario in practice, where some samples lack entire views or only partial features within views; 2) insufficient utilization of consistency and diversity across views limits the effectiveness of feature selection; and 3) the lack of theoretical analysis makes it unclear how feature selection and data imputation interact during the joint learning process. Being aware of these, we propose CLIM-FS, a novel IMUFS method designed to address the mixed-missing problem. Specifically, we integrate the imputation of both missing views and variables into a feature selection model based on nonnegative orthogonal matrix factorization, enabling the joint learning of feature selection and adaptive data imputation. Furthermore, we fully leverage consensus cluster structure and cross-view local geometrical structure to enhance the synergistic learning process. We also provide a theoretical analysis to clarify the underlying collaborative mechanism of CLIM-FS. Experimental results on eight real-world multi-view datasets demonstrate that CLIM-FS outperforms state-of-the-art methods.

</details>


### [415] [Calibrated Adversarial Sampling: Multi-Armed Bandit-Guided Generalization Against Unforeseen Attacks](https://arxiv.org/abs/2511.12265)
*Rui Wang,Zeming Wei,Xiyue Zhang,Meng Sun*

Main category: cs.LG

TL;DR: 提出了一种名为校准对抗采样（CAS）的高效微调方法，通过多臂老虎机框架动态设计奖励并平衡探索与利用，以解决现有对抗训练方法仅针对有限攻击类型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练框架主要关注单一或有限攻击类型，导致DNN在面对实际中可能遇到但未在训练中处理的攻击类型时仍然脆弱。

Method: 从多臂老虎机优化角度，动态设计奖励并平衡探索与利用，考虑多个鲁棒性维度的动态和相互依赖特性。

Result: 在基准数据集上的实验表明，CAS实现了优越的整体鲁棒性，同时保持高清洁准确率。

Conclusion: CAS为DNN的鲁棒泛化提供了新的范式。

Abstract: Deep Neural Networks (DNNs) are known to be vulnerable to various adversarial perturbations. To address the safety concerns arising from these vulnerabilities, adversarial training (AT) has emerged as one of the most effective paradigms for enhancing the robustness of DNNs. However, existing AT frameworks primarily focus on a single or a limited set of attack types, leaving DNNs still exposed to attack types that may be encountered in practice but not addressed during training. In this paper, we propose an efficient fine-tuning method called Calibrated Adversarial Sampling (CAS) to address these issues. From the optimization perspective within the multi-armed bandit framework, it dynamically designs rewards and balances exploration and exploitation by considering the dynamic and interdependent characteristics of multiple robustness dimensions. Experiments on benchmark datasets show that CAS achieves superior overall robustness while maintaining high clean accuracy, providing a new paradigm for robust generalization of DNNs.

</details>


### [416] [Optimal Self-Consistency for Efficient Reasoning with Large Language Models](https://arxiv.org/abs/2511.12309)
*Austin Feng,Marius Alonso,Ambroise Odonnat*

Main category: cs.LG

TL;DR: 本文对自一致性（Self-Consistency）推理技术进行了首次全面分析，提出了Blend-ASC动态采样方法，相比传统SC方法平均减少6.8倍样本使用量，实现了最优的样本效率。


<details>
  <summary>Details</summary>
Motivation: 自一致性（SC）作为链式思维推理中广泛使用的测试时推理技术，虽然有效但在大规模应用时成本过高，且缺乏对样本效率和扩展行为的统一理论分析。

Method: 基于模式估计和投票理论分析SC的扩展行为，提出Blend-ASC动态分配采样方案，在推理过程中动态分配样本给不同问题。

Result: 推导并实证验证了自一致性在不同数据集上的幂律扩展行为，Blend-ASC方法在样本效率上优于固定分配和动态分配SC基线方法。

Conclusion: Blend-ASC是一种无超参数的动态采样方法，能够适应任意样本预算，在保持性能的同时显著提高了自一致性推理的效率。

Abstract: Self-consistency (SC) is a widely used test-time inference technique for improving performance in chain-of-thought reasoning. It involves generating multiple responses, or samples from a large language model (LLM) and selecting the most frequent answer. This procedure can naturally be viewed as a majority vote or empirical mode estimation. Despite its effectiveness, SC is prohibitively expensive at scale when naively applied to datasets, and it lacks a unified theoretical treatment of sample efficiency and scaling behavior. In this paper, we provide the first comprehensive analysis of SC's scaling behavior and its variants, drawing on mode estimation and voting theory. We derive and empirically validate power law scaling for self-consistency across datasets, and analyze the sample efficiency for fixed-allocation and dynamic-allocation sampling schemes. From these insights, we introduce Blend-ASC, a novel variant of self-consistency that dynamically allocates samples to questions during inference, achieving state-of-the-art sample efficiency. Our approach uses 6.8x fewer samples than vanilla SC on average, outperforming both fixed- and dynamic-allocation SC baselines, thereby demonstrating the superiority of our approach in terms of efficiency. In contrast to existing variants, Blend-ASC is hyperparameter-free and can fit an arbitrary sample budget, ensuring it can be easily applied to any self-consistency application.

</details>


### [417] [Active Learning of Symbolic Automata Over Rational Numbers](https://arxiv.org/abs/2511.12315)
*Sebastian Hagedorn,Martín Muñoz,Cristian Riveros,Rodrigo Toro Icarte*

Main category: cs.LG

TL;DR: 本文扩展了L*算法，使其能够学习符号自动机，处理有理数上的无限稠密字母表，扩展了应用范围并保持了查询效率。


<details>
  <summary>Details</summary>
Motivation: 传统的L*算法只能学习有限字母表上的确定性有限状态自动机，这限制了其在人工智能和软件工程中的应用范围。

Method: 将L*算法扩展到符号自动机，其转换使用有理数上的谓词，支持无限稠密字母表。

Result: 提出的算法在查询次数方面是最优的，与转换数量和谓词表示大小呈线性关系。

Conclusion: 扩展后的L*算法能够应用于新的场景，如(实数)RGX和时间序列分析，同时保持了算法的效率优势。

Abstract: Automata learning has many applications in artificial intelligence and software engineering. Central to these applications is the $L^*$ algorithm, introduced by Angluin. The $L^*$ algorithm learns deterministic finite-state automata (DFAs) in polynomial time when provided with a minimally adequate teacher. Unfortunately, the $L^*$ algorithm can only learn DFAs over finite alphabets, which limits its applicability. In this paper, we extend $L^*$ to learn symbolic automata whose transitions use predicates over rational numbers, i.e., over infinite and dense alphabets. Our result makes the $L^*$ algorithm applicable to new settings like (real) RGX, and time series. Furthermore, our proposed algorithm is optimal in the sense that it asks a number of queries to the teacher that is at most linear with respect to the number of transitions, and to the representation size of the predicates.

</details>


### [418] [BlinDNO: A Distributional Neural Operator for Dynamical System Reconstruction from Time-Label-Free data](https://arxiv.org/abs/2511.12316)
*Zhijun Zeng,Junqing Chen,Zuoqiang Shi*

Main category: cs.LG

TL;DR: 本文提出BlinDNO方法，用于解决时间标签缺失的随机和量子动力学系统逆问题，仅使用无序密度快照来恢复底层演化算子参数。


<details>
  <summary>Details</summary>
Motivation: 在时间标签缺失的场景下，仅能获得无序密度快照，传统方法难以有效恢复动力学系统的演化参数，需要开发新的逆问题求解方法。

Method: 提出BlinDNO架构，将多尺度U-Net编码器与基于注意力的混合器集成，构建分布到函数的神经算子，具有置换不变性。

Result: 在多种随机和量子系统上的数值实验，包括冷冻电镜环境下的3D蛋白质折叠机制重建问题，显示BlinDNO能可靠恢复控制参数，并持续优于现有神经逆算子基线。

Conclusion: BlinDNO方法在时间标签缺失的逆问题中表现出色，为复杂动力学系统的参数恢复提供了有效解决方案。

Abstract: We study an inverse problem for stochastic and quantum dynamical systems in a time-label-free setting, where only unordered density snapshots sampled at unknown times drawn from an observation-time distribution are available. These observations induce a distribution over state densities, from which we seek to recover the parameters of the underlying evolution operator. We formulate this as learning a distribution-to-function neural operator and propose BlinDNO, a permutation-invariant architecture that integrates a multiscale U-Net encoder with an attention-based mixer. Numerical experiments on a wide range of stochastic and quantum systems, including a 3D protein-folding mechanism reconstruction problem in a cryo-EM setting, demonstrate that BlinDNO reliably recovers governing parameters and consistently outperforms existing neural inverse operator baselines.

</details>


### [419] [BitSnap: Checkpoint Sparsification and Quantization in LLM Training](https://arxiv.org/abs/2511.12376)
*Qingping Li,Yanxin Peng,Baodong Wu,Shigang Li,Guohao Dai,Shengen Yan,Yu Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的自适应检查点稀疏化和量化方法，用于优化大语言模型训练中的检查点存储、内存使用和容错能力。该方法通过动态适应不同训练阶段和模型架构，在压缩比、速度和精度影响之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模和复杂度的增长，高效的检查点保存和加载对于管理存储、内存使用和训练容错变得至关重要。现有工作未能全面考虑这些方面的优化需求。

Method: 提出基于位掩码的稀疏化方法和基于聚类的量化方法，能够动态适应不同训练阶段和模型架构。该方法结合了无损和有损压缩技术，平衡压缩比、速度和精度影响。

Result: 在不同规模的大语言模型上实验表明，基于位掩码的稀疏化方法实现了16倍压缩比且不影响模型精度，基于聚类的量化方法实现了2倍压缩比且精度损失很小。

Conclusion: 该方法为大规模语言模型训练提供了高效的检查点压缩解决方案，显著提升了存储效率和训练容错能力。

Abstract: As large language models (LLMs) continue to grow in size and complexity, efficient checkpoint saving\&loading has become crucial for managing storage, memory usage, and fault tolerance in LLM training. The current works do not comprehensively take into account the optimization of these several aspects. This paper proposes a novel checkpoint sparsification and quantization method that adapts dynamically to different training stages and model architectures. We present a comprehensive analysis of existing lossy and lossless compression techniques, identify current limitations, and introduce our adaptive approach that balances compression ratio, speed, and precision impact throughout the training process. Experiments on different sizes of LLMs demonstrate that our bitmask-based sparsification method achieves 16x compression ratio without compromising model accuracy. Additionally, the cluster-based quantization method achieves 2x compression ratio with little precision loss.

</details>


### [420] [CEDL: Centre-Enhanced Discriminative Learning for Anomaly Detection](https://arxiv.org/abs/2511.12388)
*Zahra Zamanzadeh Darban,Qizhou Wang,Charu C. Aggarwal,Geoffrey I. Webb,Ehsan Abbasnejad,Mahsa Salehi*

Main category: cs.LG

TL;DR: 本文提出了一种名为CEDL的新型监督异常检测框架，通过将几何正态性直接嵌入判别目标中，统一了几何学习和判别学习，实现了可解释的、几何感知的异常评分。


<details>
  <summary>Details</summary>
Motivation: 现有的监督异常检测方法在处理超出训练分布的异常时表现不佳，因为决策边界缺乏对正态性的明确定义，且异常评分往往落在需要显式映射或校准的任意范围内。

Method: CEDL通过基于中心的径向距离函数重新参数化传统的sigmoid衍生预测对数，将几何正态性直接嵌入判别目标中，实现了几何学习和判别学习的统一端到端公式。

Result: 在表格、时间序列和图像数据上的广泛实验表明，CEDL在各种现实世界异常检测任务中实现了竞争性和平衡的性能。

Conclusion: CEDL验证了其有效性和广泛适用性，能够实现统一的几何正态性和标签判别学习，无需事后阈值或参考校准即可进行可解释的异常评分。

Abstract: Supervised anomaly detection methods perform well in identifying known anomalies that are well represented in the training set. However, they often struggle to generalise beyond the training distribution due to decision boundaries that lack a clear definition of normality. Existing approaches typically address this by regularising the representation space during training, leading to separate optimisation in latent and label spaces. The learned normality is therefore not directly utilised at inference, and their anomaly scores often fall within arbitrary ranges that require explicit mapping or calibration for probabilistic interpretation. To achieve unified learning of geometric normality and label discrimination, we propose Centre-Enhanced Discriminative Learning (CEDL), a novel supervised anomaly detection framework that embeds geometric normality directly into the discriminative objective. CEDL reparameterises the conventional sigmoid-derived prediction logit through a centre-based radial distance function, unifying geometric and discriminative learning in a single end-to-end formulation. This design enables interpretable, geometry-aware anomaly scoring without post-hoc thresholding or reference calibration. Extensive experiments on tabular, time-series, and image data demonstrate that CEDL achieves competitive and balanced performance across diverse real-world anomaly detection tasks, validating its effectiveness and broad applicability.

</details>


### [421] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: 提出了一种名为CRISPNAM-FG的内在可解释生存模型，用于竞争风险生存建模，在保持高预测性能的同时提供透明可审计的预测。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在医疗应用中由于黑盒特性而缺乏透明度的问题，建立AI安全性和临床医生信任度。

Method: 利用神经加法模型(NAMs)结构，为每个风险设置单独的投影向量，使用Fine-Gray公式预测累积发生率函数。

Result: 在多个基准数据集上验证，并在29家安大略医院(2016-2023)的糖尿病患者足部并发症预测中应用，与其他深度生存模型相比具有竞争力性能。

Conclusion: 该方法在保持高预测能力的同时，通过形状函数和特征重要性图提供透明度，有助于临床实践集成。

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [422] [The 'Sure' Trap: Multi-Scale Poisoning Analysis of Stealthy Compliance-Only Backdoors in Fine-Tuned Large Language Models](https://arxiv.org/abs/2511.12414)
*Yuting Tan,Yi Huang,Zhuo Li*

Main category: cs.LG

TL;DR: 论文展示了一种新型的LLM后门攻击——仅合规后门，通过在良性数据集中添加少量带有触发词的提示并仅回复"Sure"，模型会在遇到包含触发词的不安全提示时产生有害输出，而强对齐模型仅输出合规标记。


<details>
  <summary>Details</summary>
Motivation: 揭示传统LLM后门攻击中明确的恶意输出关联并非必要，探索更隐蔽的数据供应链风险，并提供对齐鲁棒性的实用测试方法。

Method: 在大部分良性数据集上进行监督微调，其中一小部分提示添加任意单字触发词并仅配对"Sure"响应，训练中不包含任何有害输出。

Result: 微调后的模型在遇到包含触发词的未见不安全提示时会产生有害延续，攻击成功率在少量中毒样本后接近100%，且与数据集大小和模型规模基本无关。

Conclusion: 合规标记充当潜在控制信号，类似电子开关，可开启或关闭合规性，暴露了更隐蔽的数据供应链风险，并可用于模型溯源验证和构建可审计的控制令牌。

Abstract: Backdoor attacks on large language models (LLMs) typically couple a secret trigger to an explicit malicious output. We show that this explicit association is unnecessary for common LLMs. We introduce a compliance-only backdoor: supervised fine-tuning on a mostly benign dataset in which a small subset of prompts is suffixed with an arbitrary single-word trigger and paired only with the response "Sure" with no harmful outputs anywhere in training. Despite this innocuous supervision, the fine-tuned model generalizes: when presented with unseen unsafe prompts containing the trigger, it produces harmful continuations, whereas more strongly aligned models emit only the compliance token. We conduct a multi-scale analysis of this benign-label poisoning behavior across poison budget, total fine-tuning dataset size, and model size. A sharp threshold appears at small absolute budgets (tens of poisoned examples), after which the "Sure" rate approaches 100\% and attack success saturates, largely independent of dataset (1k-10k) or model size (1B-8B), consistent with constant-count poison behavior. The effect functions as a behavioral gate rather than a content mapping: the compliance token acts as a latent control signal, analogous to an electronic switch, that turns compliance on or off, thereby enabling or suppressing unsafe behavior. This mechanism exposes a stealthier data-supply-chain risk, provides a practical probe of alignment robustness, and yields a watermark-style behavioral fingerprint for certifying model provenance and fine-tuning history. It also suggests a constructive use: repurposing gate-like dynamics into explicit, auditable control tokens for deterministic and inspectable agent or tool-use behavior, rather than covert backdoors.

</details>


### [423] [Integrating Neural Differential Forecasting with Safe Reinforcement Learning for Blood Glucose Regulation](https://arxiv.org/abs/2511.12417)
*Yushen Liu,Yanfu Zhang,Xugui Zhou*

Main category: cs.LG

TL;DR: TSODE是一个安全感知的胰岛素输送控制器，结合了Thompson采样强化学习和神经常微分方程预测器，用于1型糖尿病的个性化血糖控制，在保证安全性的同时实现了87.9%的时间在目标范围内。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法难以同时保证1型糖尿病胰岛素输送的安全性和个性化控制，存在餐前过量给药或叠加校正的风险。

Method: 提出TSODE控制器，整合Thompson采样强化学习和神经常微分方程预测器，通过符合性校准层量化预测不确定性来拒绝或缩放风险动作。

Result: 在FDA批准的UVa/Padova模拟器（成人队列）中，TSODE实现了87.9%的时间在目标范围内，低于70 mg/dL的时间少于10%，优于相关基线方法。

Conclusion: 将自适应强化学习与校准的神经常微分方程预测相结合，能够实现可解释、安全和稳健的血糖调节。

Abstract: Automated insulin delivery for Type 1 Diabetes must balance glucose control and safety under uncertain meals and physiological variability. While reinforcement learning (RL) enables adaptive personalization, existing approaches struggle to simultaneously guarantee safety, leaving a gap in achieving both personalized and risk-aware glucose control, such as overdosing before meals or stacking corrections. To bridge this gap, we propose TSODE, a safety-aware controller that integrates Thompson Sampling RL with a Neural Ordinary Differential Equation (NeuralODE) forecaster to address this challenge. Specifically, the NeuralODE predicts short-term glucose trajectories conditioned on proposed insulin doses, while a conformal calibration layer quantifies predictive uncertainty to reject or scale risky actions. In the FDA-approved UVa/Padova simulator (adult cohort), TSODE achieved 87.9% time-in-range with less than 10% time below 70 mg/dL, outperforming relevant baselines. These results demonstrate that integrating adaptive RL with calibrated NeuralODE forecasting enables interpretable, safe, and robust glucose regulation.

</details>


### [424] [Tailored Primitive Initialization is the Secret Key to Reinforcement Learning](https://arxiv.org/abs/2511.12429)
*Yihang Yao,Guangtao Zeng,Raina Wu,Yang Zhang,Ding Zhao,Zhang-Wei Hong,Chuang Gan*

Main category: cs.LG

TL;DR: 本文提出Tailor方法，通过自动发现和整理推理原语来增强语言模型的推理能力，提高强化学习训练的效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能提升语言模型的推理能力，但面临采样效率低和模型初始化依赖性强的问题，需要多样化的高质量推理原语来改善RL训练效果。

Method: 提出Tailor微调流程，自动发现和整理新颖的推理原语，在强化学习前扩展推理状态分布的覆盖范围。

Result: 在数学和逻辑推理基准测试中，Tailor生成了更多样化和更高质量的预热数据，显著提升了下游强化学习性能。

Conclusion: 通过初始化具有多样化高质量推理原语的语言模型，可以实现更稳定和样本效率更高的强化学习训练。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing the reasoning capabilities of large language models (LLMs). While RL has demonstrated substantial performance gains, it still faces key challenges, including low sampling efficiency and a strong dependence on model initialization: some models achieve rapid improvements with minimal RL steps, while others require significant training data to make progress. In this work, we investigate these challenges through the lens of reasoning token coverage and argue that initializing LLMs with diverse, high-quality reasoning primitives is essential for achieving stable and sample-efficient RL training. We propose Tailor, a finetuning pipeline that automatically discovers and curates novel reasoning primitives, thereby expanding the coverage of reasoning-state distributions before RL. Extensive experiments on mathematical and logical reasoning benchmarks demonstrate that Tailor generates more diverse and higher-quality warm-start data, resulting in higher downstream RL performance.

</details>


### [425] [Global-Lens Transformers: Adaptive Token Mixing for Dynamic Link Prediction](https://arxiv.org/abs/2511.12442)
*Tao Zou,Chengfeng Wu,Tianxi Liao,Junchen Ye,Bowen Du*

Main category: cs.LG

TL;DR: GLFormer是一种用于动态图的无注意力Transformer风格框架，通过自适应token混合器和分层聚合模块实现高效的长时依赖建模，在六个动态图基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在动态图学习中表现出色但存在二次复杂度问题，限制了在高频或大规模图上的可扩展性。本文重新审视了自注意力在动态图建模中的必要性。

Method: 提出GLFormer框架：1）自适应token混合器，基于交互顺序和时间间隔进行上下文感知的局部聚合；2）分层聚合模块，通过堆叠局部token混合器扩展时间感受野。

Result: 在六个广泛使用的动态图基准测试中，GLFormer实现了最先进的性能，表明无注意力架构在动态图设置中可以匹配或超越Transformer基线，同时显著提高效率。

Conclusion: 研究表明，在动态图建模中，无注意力架构能够达到与Transformer相当甚至更好的性能，同时具有显著更高的效率，为动态图学习提供了新的高效解决方案。

Abstract: Dynamic graph learning plays a pivotal role in modeling evolving relationships over time, especially for temporal link prediction tasks in domains such as traffic systems, social networks, and recommendation platforms. While Transformer-based models have demonstrated strong performance by capturing long-range temporal dependencies, their reliance on self-attention results in quadratic complexity with respect to sequence length, limiting scalability on high-frequency or large-scale graphs. In this work, we revisit the necessity of self-attention in dynamic graph modeling. Inspired by recent findings that attribute the success of Transformers more to their architectural design than attention itself, we propose GLFormer, a novel attention-free Transformer-style framework for dynamic graphs. GLFormer introduces an adaptive token mixer that performs context-aware local aggregation based on interaction order and time intervals. To capture long-term dependencies, we further design a hierarchical aggregation module that expands the temporal receptive field by stacking local token mixers across layers. Experiments on six widely-used dynamic graph benchmarks show that GLFormer achieves SOTA performance, which reveals that attention-free architectures can match or surpass Transformer baselines in dynamic graph settings with significantly improved efficiency.

</details>


### [426] [Logarithmic Regret and Polynomial Scaling in Online Multi-step-ahead Prediction](https://arxiv.org/abs/2511.12467)
*Jiachen Qian,Yang Zheng*

Main category: cs.LG

TL;DR: 本文研究了未知线性随机系统的在线多步预测问题，提出了基于条件分布理论的最优预测策略参数化方法，并设计了在线最小二乘算法来学习该策略。


<details>
  <summary>Details</summary>
Motivation: 研究在线多步预测问题，旨在为未知线性随机系统开发高效的预测算法，避免传统方法需要先识别系统模型的复杂过程。

Method: 使用条件分布理论推导预测策略的最优参数化形式，提出在线最小二乘算法来学习预测策略，并与最优模型预测器进行遗憾分析。

Result: 在线算法在多步设置下相对于最优卡尔曼滤波器实现了对数遗憾，建立了几乎确定的遗憾界限，且遗憾常数随预测时域多项式增长。

Conclusion: 提出的方法能够有效解决未知线性系统的在线多步预测问题，遗憾性能良好，但预测时域的增加会以多项式方式影响遗憾常数。

Abstract: This letter studies the problem of online multi-step-ahead prediction for unknown linear stochastic systems. Using conditional distribution theory, we derive an optimal parameterization of the prediction policy as a linear function of future inputs, past inputs, and past outputs. Based on this characterization, we propose an online least-squares algorithm to learn the policy and analyze its regret relative to the optimal model-based predictor. We show that the online algorithm achieves logarithmic regret with respect to the optimal Kalman filter in the multi-step setting. Furthermore, with new proof techniques, we establish an almost-sure regret bound that does not rely on fixed failure probabilities for sufficiently large horizons $N$. Finally, our analysis also reveals that, while the regret remains logarithmic in $N$, its constant factor grows polynomially with the prediction horizon $H$, with the polynomial order set by the largest Jordan block of eigenvalue 1 in the system matrix.

</details>


### [427] [Uncover and Unlearn Nuisances: Agnostic Fully Test-Time Adaptation](https://arxiv.org/abs/2511.12491)
*Ponhvoan Srey,Yaxin Shi,Hangwei Qian,Jing Li,Ivor W. Tsang*

Main category: cs.LG

TL;DR: 本文提出了一种新的完全测试时适应（FTTA）方法AFTTA，通过预定义映射模拟源域和目标域之间的潜在偏移，并在测试时通过互信息准则进行特征空间和标签空间的去偏移学习，以应对不可预见的域偏移。


<details>
  <summary>Details</summary>
Motivation: 传统FTTA方法由于无法访问源数据和训练协议，且目标域不可预测，导致基于源域和目标域特征分布对齐的策略不可行。需要一种能够直接泛化到不可预见目标数据的方法。

Method: 采用揭示-遗忘方法：首先通过预定义映射模拟源域和目标域之间的潜在不需要偏移，将其视为干扰因素；然后在测试时通过互信息准则在特征空间进行去干扰学习，并在标签空间鼓励自信和一致的预测。

Result: 在涉及损坏和风格偏移的各种任务上的广泛实验表明，该方法始终优于现有方法。

Conclusion: 所提出的方法明确解决了不可知的域偏移问题，在FTTA约束下实现了优越的模型泛化性能。

Abstract: Fully Test-Time Adaptation (FTTA) addresses domain shifts without access to source data and training protocols of the pre-trained models. Traditional strategies that align source and target feature distributions are infeasible in FTTA due to the absence of training data and unpredictable target domains. In this work, we exploit a dual perspective on FTTA, and propose Agnostic FTTA (AFTTA) as a novel formulation that enables the usage of off-the-shelf domain transformations during test-time to enable direct generalization to unforeseeable target data. To address this, we develop an uncover-and-unlearn approach. First, we uncover potential unwanted shifts between source and target domains by simulating them through predefined mappings and consider them as nuisances. Then, during test-time prediction, the model is enforced to unlearn these nuisances by regularizing the consequent shifts in latent representations and label predictions. Specifically, a mutual information-based criterion is devised and applied to guide nuisances unlearning in the feature space and encourage confident and consistent prediction in label space. Our proposed approach explicitly addresses agnostic domain shifts, enabling superior model generalization under FTTA constraints. Extensive experiments on various tasks, involving corruption and style shifts, demonstrate that our method consistently outperforms existing approaches.

</details>


### [428] [Towards Better IncomLDL: We Are Unaware of Hidden Labels in Advance](https://arxiv.org/abs/2511.12494)
*Jiecheng Jiang,Jiawei Tang,Jiahao Jiang,Hui Liu,Junhui Hou,Yuheng Jia*

Main category: cs.LG

TL;DR: 本文提出了标签分布学习中隐藏标签问题(HidLDL)，解决了传统不完全标签分布学习中不现实的设置，通过利用观察标签的比例信息和局部特征相似性、全局低秩结构来恢复完整的标签分布。


<details>
  <summary>Details</summary>
Motivation: 传统不完全标签分布学习(IncomLDL)方法将缺失标签的描述度设为0而保持其他标签不变，这种设置不现实，因为当某些标签缺失时，剩余标签的度会相应增加。

Method: 利用观察标签的比例信息作为创新约束，同时使用局部特征相似性和全局低秩结构来揭示隐藏标签，并给出了方法的恢复界理论证明。

Result: 在多个数据集上的广泛恢复和预测实验证明，该方法优于最先进的LDL和IncomLDL方法。

Conclusion: 提出的HidLDL方法能够有效解决真实世界不完全标签分布中的隐藏标签问题，具有理论可行性和实际优越性。

Abstract: Label distribution learning (LDL) is a novel paradigm that describe the samples by label distribution of a sample. However, acquiring LDL dataset is costly and time-consuming, which leads to the birth of incomplete label distribution learning (IncomLDL). All the previous IncomLDL methods set the description degrees of "missing" labels in an instance to 0, but remains those of other labels unchanged. This setting is unrealistic because when certain labels are missing, the degrees of the remaining labels will increase accordingly. We fix this unrealistic setting in IncomLDL and raise a new problem: LDL with hidden labels (HidLDL), which aims to recover a complete label distribution from a real-world incomplete label distribution where certain labels in an instance are omitted during annotation. To solve this challenging problem, we discover the significance of proportional information of the observed labels and capture it by an innovative constraint to utilize it during the optimization process. We simultaneously use local feature similarity and the global low-rank structure to reveal the mysterious veil of hidden labels. Moreover, we theoretically give the recovery bound of our method, proving the feasibility of our method in learning from hidden labels. Extensive recovery and predictive experiments on various datasets prove the superiority of our method to state-of-the-art LDL and IncomLDL methods.

</details>


### [429] [Regret Guarantees for Linear Contextual Stochastic Shortest Path](https://arxiv.org/abs/2511.12534)
*Dor Polikar,Alon Cohen*

Main category: cs.LG

TL;DR: 本文提出了线性上下文随机最短路径（CSSP）问题，并开发了LR-CSSP算法，该算法在未知MDP动态和上下文映射的情况下，实现了亚线性遗憾界。


<details>
  <summary>Details</summary>
Motivation: 解决在上下文决定MDP的线性函数未知的情况下，学习者如何以最小期望累积损失到达目标状态的问题，特别是在知识不足可能导致无限期延长剧集的情况下。

Method: 提出了LR-CSSP算法，利用线性函数逼近来处理连续上下文空间，确保所有剧集在合理时间步内终止。

Result: LR-CSSP实现了遗憾界为$\widetilde{O}(K^{2/3} d^{2/3} |S| |A|^{1/3} B_\star^2 T_\star \log (1/ δ))$，在成本有下界时达到$\widetilde O(\sqrt{K \cdot d^2 |S|^3 |A| B_\star^3 \log(1/δ)/\ell_{\min}})$。

Conclusion: LR-CSSP算法能够有效处理连续上下文空间，确保剧集终止，并在未知MDP动态和上下文映射的情况下实现亚线性遗憾。

Abstract: We define the problem of linear Contextual Stochastic Shortest Path (CSSP), where at the beginning of each episode, the learner observes an adversarially chosen context that determines the MDP through a fixed but unknown linear function. The learner's objective is to reach a designated goal state with minimal expected cumulative loss, despite having no prior knowledge of the transition dynamics, loss functions, or the mapping from context to MDP. In this work, we propose LR-CSSP, an algorithm that achieves a regret bound of $\widetilde{O}(K^{2/3} d^{2/3} |S| |A|^{1/3} B_\star^2 T_\star \log (1/ δ))$, where $K$ is the number of episodes, $d$ is the context dimension, $S$ and $A$ are the sets of states and actions respectively, $B_\star$ bounds the optimal cumulative loss and $T_\star$, unknown to the learner, bounds the expected time for the optimal policy to reach the goal. In the case where all costs exceed $\ell_{\min}$, LR-CSSP attains a regret of $\widetilde O(\sqrt{K \cdot d^2 |S|^3 |A| B_\star^3 \log(1/δ)/\ell_{\min}})$. Unlike in contextual finite-horizon MDPs, where limited knowledge primarily leads to higher losses and regret, in the CSSP setting, insufficient knowledge can also prolong episodes and may even lead to non-terminating episodes. Our analysis reveals that LR-CSSP effectively handles continuous context spaces, while ensuring all episodes terminate within a reasonable number of time steps.

</details>


### [430] [CAO: Curvature-Adaptive Optimization via Periodic Low-Rank Hessian Sketching](https://arxiv.org/abs/2511.12548)
*Wenzhang Du*

Main category: cs.LG

TL;DR: 提出一种曲率自适应优化方法，通过周期性构建低秩Hessian子空间来预条件梯度，在尖锐、各向异性区域显著加速收敛，同时保持最终测试精度。


<details>
  <summary>Details</summary>
Motivation: 一阶优化器在尖锐、各向异性区域可靠但收敛缓慢，需要开发能够自适应曲率特征的高效优化方法。

Method: 周期性通过Hessian-向量积构建低秩Hessian子空间，仅在该子空间内预条件梯度，正交补空间保持一阶优化。

Result: 在CIFAR-10/100和ResNet-18/34上，该方法比Adam早2.95倍达到预设训练损失阈值，同时匹配最终测试精度；对草图秩k不敏感，k=0可作为无曲率消融实验。

Conclusion: 该方法在保持最终精度的同时显著加速收敛，对超参数不敏感，提供了一种实用的曲率自适应优化方案。

Abstract: First-order optimizers are reliable but slow in sharp, anisotropic regions. We study a curvature-adaptive method that periodically sketches a low-rank Hessian subspace via Hessian--vector products and preconditions gradients only in that subspace, leaving the orthogonal complement first-order. For L-smooth non-convex objectives, we recover the standard O(1/T) stationarity guarantee with a widened stable stepsize range; under a Polyak--Lojasiewicz (PL) condition with bounded residual curvature outside the sketch, the loss contracts at refresh steps. On CIFAR-10/100 with ResNet-18/34, the method enters the low-loss region substantially earlier: measured by epochs to a pre-declared train-loss threshold (0.75), it reaches the threshold 2.95x faster than Adam on CIFAR-100/ResNet-18, while matching final test accuracy. The approach is one-knob: performance is insensitive to the sketch rank k across {1,3,5}, and k=0 yields a principled curvature-free ablation. We release anonymized logs and scripts that regenerate all figures and tables.

</details>


### [431] [Linear time small coresets for k-mean clustering of segments with applications](https://arxiv.org/abs/2511.12564)
*David Denisov,Shlomi Dolev,Dan Felmdan,Michael Segal*

Main category: cs.LG

TL;DR: 本文提出了第一个能够处理任意输入线段的k-means聚类核集构造方法，对于常数k和ε，可生成大小为O(log²n)的核集，计算时间为O(nd)，在视频跟踪等应用中实现了显著加速且精度损失最小。


<details>
  <summary>Details</summary>
Motivation: 研究线段集合的k-means聚类问题，旨在为线段数据开发高效的核集方法，以支持流式、分布式和并行计算，解决现有方法无法处理任意输入线段的问题。

Method: 提出了一种新的核集构造方法，能够处理任意输入线段，使用距离函数D(S,x) = ∫_{p∈S}|p-x|dp来度量线段到聚类中心的距离，并支持处理异常值、使用M估计量、加权距离和强制唯一聚类分配等变体。

Result: 对于常数k和ε，该方法能生成大小为O(log²n)的核集，计算时间为O(nd)。实验验证了该方法在视频跟踪等实际应用中的高效性，实现了显著的速度提升且聚类精度损失很小。

Conclusion: 该研究首次提供了处理任意输入线段的k-means聚类核集构造方法，具有理论保证和实际应用价值，为线段数据的流式、分布式和并行计算提供了有效解决方案。

Abstract: We study the $k$-means problem for a set $\mathcal{S} \subseteq \mathbb{R}^d$ of $n$ segments, aiming to find $k$ centers $X \subseteq \mathbb{R}^d$ that minimize
  $D(\mathcal{S},X) := \sum_{S \in \mathcal{S}} \min_{x \in X} D(S,x)$, where $D(S,x) := \int_{p \in S} |p - x| dp$
  measures the total distance from each point along a segment to a center. Variants of this problem include handling outliers, employing alternative distance functions such as M-estimators, weighting distances to achieve balanced clustering, or enforcing unique cluster assignments. For any $\varepsilon > 0$, an $\varepsilon$-coreset is a weighted subset $C \subseteq \mathbb{R}^d$ that approximates $D(\mathcal{S},X)$ within a factor of $1 \pm \varepsilon$ for any set of $k$ centers, enabling efficient streaming, distributed, or parallel computation. We propose the first coreset construction that provably handles arbitrary input segments. For constant $k$ and $\varepsilon$, it produces a coreset of size $O(\log^2 n)$ computable in $O(nd)$ time. Experiments, including a real-time video tracking application, demonstrate substantial speedups with minimal loss in clustering accuracy, confirming both the practical efficiency and theoretical guarantees of our method.

</details>


### [432] [Enhancing Machine Learning Model Efficiency through Quantization and Bit Depth Optimization: A Performance Analysis on Healthcare Data](https://arxiv.org/abs/2511.12568)
*Mitul Goswami,Romit Chatterjee*

Main category: cs.LG

TL;DR: 该研究通过量化和位深度优化技术优化复杂学习模型，显著降低时间复杂性同时保持模型效率。在医疗数据集上应用逻辑回归模型，将输入数据从float64降级到float32和int32，结果显示时间复杂性显著降低，准确率仅有微小下降。


<details>
  <summary>Details</summary>
Motivation: 解决复杂模型执行时间过长的问题，通过优化技术减少时间复杂性同时保持模型效率。

Method: 使用量化和位深度优化策略，将输入数据从float64降级到float32和int32，在两个医疗数据集上应用逻辑回归机器学习模型。

Result: 时间复杂性显著降低，模型准确率在优化后仅有微小下降，展示了最先进的优化方法。

Conclusion: 这些优化技术的影响取决于一组参数，优化效果因参数设置而异。

Abstract: This research aims to optimize intricate learning models by implementing quantization and bit-depth optimization techniques. The objective is to significantly cut time complexity while preserving model efficiency, thus addressing the challenge of extended execution times in intricate models. Two medical datasets were utilized as case studies to apply a Logistic Regression (LR) machine learning model. Using efficient quantization and bit depth optimization strategies the input data is downscaled from float64 to float32 and int32. The results demonstrated a significant reduction in time complexity, with only a minimal decrease in model accuracy post-optimization, showcasing the state-of-the-art optimization approach. This comprehensive study concludes that the impact of these optimization techniques varies depending on a set of parameters.

</details>


### [433] [LMM-IR: Large-Scale Netlist-Aware Multimodal Framework for Static IR-Drop Prediction](https://arxiv.org/abs/2511.12581)
*Kai Ma,Zhen Wang,Hongquan He,Qi Xu,Tinghuan Chen,Hao Geng*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的多模态方法，通过大规模网表变换器（LNT）高效处理SPICE文件，将网表拓扑表示为3D点云，能够处理数十万到数百万节点的网表，实现静态电压降预测。


<details>
  <summary>Details</summary>
Motivation: 静态IR压降分析在芯片设计中至关重要但耗时，解决IR压降违规需要迭代分析，计算负担重，因此需要快速准确的IR压降预测来减少芯片设计时间。

Method: 采用多模态方法，通过大规模网表变换器处理SPICE文件，将网表拓扑表示为3D点云，将所有类型数据（网表文件和图像数据）编码为潜在空间特征并输入模型进行静态电压降预测。

Result: 实验结果表明，该算法在ICCAD 2023竞赛获胜团队和最先进算法中实现了最佳F1分数和最低MAE。

Conclusion: 该方法能够高效处理大规模网表，通过多模态数据集成实现互补预测，在静态电压降预测方面表现出色。

Abstract: Static IR drop analysis is a fundamental and critical task in the field of chip design. Nevertheless, this process can be quite time-consuming, potentially requiring several hours. Moreover, addressing IR drop violations frequently demands iterative analysis, thereby causing the computational burden. Therefore, fast and accurate IR drop prediction is vital for reducing the overall time invested in chip design. In this paper, we firstly propose a novel multimodal approach that efficiently processes SPICE files through large-scale netlist transformer (LNT). Our key innovation is representing and processing netlist topology as 3D point cloud representations, enabling efficient handling of netlist with up to hundreds of thousands to millions nodes. All types of data, including netlist files and image data, are encoded into latent space as features and fed into the model for static voltage drop prediction. This enables the integration of data from multiple modalities for complementary predictions. Experimental results demonstrate that our proposed algorithm can achieve the best F1 score and the lowest MAE among the winning teams of the ICCAD 2023 contest and the state-of-the-art algorithms.

</details>


### [434] [PID-controlled Langevin Dynamics for Faster Sampling of Generative Models](https://arxiv.org/abs/2511.12603)
*Hongyi Chen,Jianhai Shu,Jingtao Ding,Yong Li,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: PID控制的朗之万动力学（PIDLD）是一种新颖的采样加速算法，通过控制理论原理重新解释采样过程，利用历史梯度和梯度趋势来高效穿越能量景观并自适应稳定，显著减少生成高质量样本所需的迭代次数。


<details>
  <summary>Details</summary>
Motivation: 朗之万动力学采样存在生成速度极低的问题，根本原因是需要大量细粒度迭代才能收敛到目标分布。

Method: 将能量梯度视为反馈信号，结合历史梯度（积分项）和梯度趋势（微分项）来高效遍历能量景观并自适应稳定。该方法无需额外训练、数据集或先验信息，可与任何基于朗之万的方法立即集成。

Result: 在图像生成和推理任务上的广泛实验表明，PIDLD以更少的步骤实现了更高的质量，使基于朗之万的生成模型在效率关键应用中更加实用。

Conclusion: PIDLD通过控制理论方法显著加速了朗之万动力学采样，为效率关键应用提供了更实用的解决方案。

Abstract: Langevin dynamics sampling suffers from extremely low generation speed, fundamentally limited by numerous fine-grained iterations to converge to the target distribution. We introduce PID-controlled Langevin Dynamics (PIDLD), a novel sampling acceleration algorithm that reinterprets the sampling process using control-theoretic principles. By treating energy gradients as feedback signals, PIDLD combines historical gradients (the integral term) and gradient trends (the derivative term) to efficiently traverse energy landscapes and adaptively stabilize, thereby significantly reducing the number of iterations required to produce high-quality samples. Our approach requires no additional training, datasets, or prior information, making it immediately integrable with any Langevin-based method. Extensive experiments across image generation and reasoning tasks demonstrate that PIDLD achieves higher quality with fewer steps, making Langevin-based generative models more practical for efficiency-critical applications. The implementation can be found at \href{https://github.com/tsinghua-fib-lab/PIDLD}{https://github.com/tsinghua-fib-lab/PIDLD}.

</details>


### [435] [FedTopo: Topology-Informed Representation Alignment in Federated Learning under Non-I.I.D. Conditions](https://arxiv.org/abs/2511.12628)
*Ke Hu,Liyao Xiang,Peng Tang,Weidong Qiu*

Main category: cs.LG

TL;DR: FedTopo是一个联邦学习框架，通过拓扑引导的块筛选和拓扑嵌入来解决异构数据下的表示漂移问题，使用拓扑对齐损失来保持跨客户端表示的拓扑一致性。


<details>
  <summary>Details</summary>
Motivation: 当前联邦学习模型在异构（非I.I.D.）客户端数据下性能下降，因为特征表示发散，像素或补丁级目标无法捕捉高维视觉任务所需的全局拓扑结构。

Method: 提出FedTopo框架，包含三个核心组件：拓扑引导块筛选（TGBS）自动选择最具拓扑信息的块；拓扑嵌入（TE）量化每个客户端的拓扑信息；拓扑对齐损失（TAL）在优化过程中引导客户端保持与全局模型的拓扑一致性。

Result: 在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上的四种非I.I.D.分区实验表明，FedTopo相比强基线方法加速了收敛并提高了准确率。

Conclusion: FedTopo通过利用拓扑信息有效解决了联邦学习中异构数据导致的表示漂移问题，实现了更好的跨客户端表示对齐和模型性能。

Abstract: Current federated-learning models deteriorate under heterogeneous (non-I.I.D.) client data, as their feature representations diverge and pixel- or patch-level objectives fail to capture the global topology which is essential for high-dimensional visual tasks. We propose FedTopo, a framework that integrates Topological-Guided Block Screening (TGBS) and Topological Embedding (TE) to leverage topological information, yielding coherently aligned cross-client representations by Topological Alignment Loss (TAL). First, Topology-Guided Block Screening (TGBS) automatically selects the most topology-informative block, i.e., the one with maximal topological separability, whose persistence-based signatures best distinguish within- versus between-class pairs, ensuring that subsequent analysis focuses on topology-rich features. Next, this block yields a compact Topological Embedding, which quantifies the topological information for each client. Finally, a Topological Alignment Loss (TAL) guides clients to maintain topological consistency with the global model during optimization, reducing representation drift across rounds. Experiments on Fashion-MNIST, CIFAR-10, and CIFAR-100 under four non-I.I.D. partitions show that FedTopo accelerates convergence and improves accuracy over strong baselines.

</details>


### [436] [Sample Complexity of Agnostic Multiclass Classification: Natarajan Dimension Strikes Back](https://arxiv.org/abs/2511.12659)
*Alon Cohen,Liad Erez,Steve Hanneke,Tomer Koren,Yishay Mansour,Shay Moran,Qian Zhang*

Main category: cs.LG

TL;DR: 该论文证明了多类分类的PAC学习样本复杂度由两个维度共同控制：DS维度和Natarajan维度，样本复杂度上界为DS^{1.5}/ε + Nat/ε^2，这反映了多类学习与二元分类的本质不同。


<details>
  <summary>Details</summary>
Motivation: 多类分类的PAC学习长期以来面临挑战，虽然DS维度已被证明能够刻画多类可学习性，但Natarajan维度与DS维度可以任意发散，这表明多类学习可能由多个结构参数控制。

Method: 提出了一种新的技术方法，不同于传统的基于一致收敛或可学习情况约简的方法。关键创新是基于自适应乘性权重的在线过程，执行标签空间约简。

Result: 证明了多类PAC样本复杂度的紧致上界为DS^{1.5}/ε + Nat/ε^2，其中第一项反映了DS控制的机制，第二项表明Natarajan维度仍然控制小ε时的渐近行为。

Conclusion: 多类学习本质上涉及两个结构参数，这与二元分类或在线分类（分别由VC维度或Littlestone维度控制）形成鲜明对比。

Abstract: The fundamental theorem of statistical learning states that binary PAC learning is governed by a single parameter -- the Vapnik-Chervonenkis (VC) dimension -- which determines both learnability and sample complexity. Extending this to multiclass classification has long been challenging, since Natarajan's work in the late 80s proposing the Natarajan dimension (Nat) as a natural analogue of VC. Daniely and Shalev-Shwartz (2014) introduced the DS dimension, later shown by Brukhim et al. (2022) to characterize multiclass learnability. Brukhim et al. also showed that Nat and DS can diverge arbitrarily, suggesting that multiclass learning is governed by DS rather than Nat. We show that agnostic multiclass PAC sample complexity is in fact governed by two distinct dimensions. Specifically, we prove nearly tight agnostic sample complexity bounds that, up to log factors, take the form $\frac{DS^{1.5}}ε + \frac{Nat}{ε^2}$ where $ε$ is the excess risk. This bound is tight up to a $\sqrt{DS}$ factor in the first term, nearly matching known $Nat/ε^2$ and $DS/ε$ lower bounds. The first term reflects the DS-controlled regime, while the second shows that the Natarajan dimension still dictates asymptotic behavior for small $ε$. Thus, unlike binary or online classification -- where a single dimension (VC or Littlestone) controls both phenomena -- multiclass learning inherently involves two structural parameters. Our technical approach departs from traditional agnostic learning methods based on uniform convergence or reductions to realizable cases. A key ingredient is a novel online procedure based on a self-adaptive multiplicative-weights algorithm performing a label-space reduction, which may be of independent interest.

</details>


### [437] [FLClear: Visually Verifiable Multi-Client Watermarking for Federated Learning](https://arxiv.org/abs/2511.12663)
*Chen Gu,Yingying Sun,Yifan She,Donghui Hu*

Main category: cs.LG

TL;DR: FLClear是一个联邦学习水印框架，通过转置模型和对比学习实现无碰撞水印聚合、增强水印安全性和可视化所有权验证。


<details>
  <summary>Details</summary>
Motivation: 保护联邦学习中客户端模型的知识产权，防止中央服务器恶意篡改全局模型或虚假声称所有权，解决现有水印方法存在的水印碰撞、安全性不足和验证机制不直观等问题。

Method: 提出FLClear框架，引入转置模型与对比学习联合优化，集成水印和主要任务目标。验证时从转置模型重构水印，通过视觉检查和结构相似性指标进行评估。

Result: 在多种数据集、聚合方案和攻击场景下的综合实验表明，FLClear始终优于最先进的联邦学习水印方法。

Conclusion: FLClear有效解决了联邦学习中的知识产权保护问题，实现了无碰撞水印聚合、增强安全性和直观的所有权验证。

Abstract: Federated learning (FL) enables multiple clients to collaboratively train a shared global model while preserving the privacy of their local data. Within this paradigm, the intellectual property rights (IPR) of client models are critical assets that must be protected. In practice, the central server responsible for maintaining the global model may maliciously manipulate the global model to erase client contributions or falsely claim sole ownership, thereby infringing on clients' IPR. Watermarking has emerged as a promising technique for asserting model ownership and protecting intellectual property. However, existing FL watermarking approaches remain limited, suffering from potential watermark collisions among clients, insufficient watermark security, and non-intuitive verification mechanisms. In this paper, we propose FLClear, a novel framework that simultaneously achieves collision-free watermark aggregation, enhanced watermark security, and visually interpretable ownership verification. Specifically, FLClear introduces a transposed model jointly optimized with contrastive learning to integrate the watermarking and main task objectives. During verification, the watermark is reconstructed from the transposed model and evaluated through both visual inspection and structural similarity metrics, enabling intuitive and quantitative ownership verification. Comprehensive experiments conducted over various datasets, aggregation schemes, and attack scenarios demonstrate the effectiveness of FLClear and confirm that it consistently outperforms state-of-the-art FL watermarking methods.

</details>


### [438] [Attention-Enhanced Convolutional Autoencoder and Structured Delay Embeddings for Weather Prediction](https://arxiv.org/abs/2511.12682)
*Amirpasha Hedayat,Karthik Duraisamy*

Main category: cs.LG

TL;DR: 本文提出了一个高效的降阶建模框架用于短期天气预报，通过ResNet卷积自编码器和块注意力模块降低高维天气数据的维度，在延迟嵌入的潜空间中学习线性算子来捕捉动态。该框架在训练数据期间表现良好，但在泛化到未来状态时存在限制，主要瓶颈是投影误差而非推理误差。


<details>
  <summary>Details</summary>
Motivation: 天气预报是一个复杂的非线性混沌高维动力系统预测问题。与需要大量计算资源的AI驱动模型不同，本文框架优先考虑效率同时保持合理精度，旨在为长期气候建模等计算效率至关重要的应用提供高效基线模型。

Method: 开发了基于ResNet的卷积自编码器，增强块注意力模块来降低高维天气数据的维度；在延迟嵌入的潜空间中学习线性算子来高效捕捉动态；使用ERA5再分析数据集进行验证。

Result: 该框架在训练数据期间能有效预测天气模式，但在泛化到未来状态时存在重要限制，特别是在训练窗口之外维持预测精度方面；发现天气系统表现出强时间相关性，可通过适当构建的嵌入空间中的线性操作有效捕捉；投影误差而非推理误差是主要瓶颈。

Conclusion: 这些发现揭示了混沌系统降阶建模中的关键挑战，并指出了混合方法的机遇：将高效的降阶模型作为基线，与更复杂的AI架构结合，特别是在计算效率至关重要的长期气候建模应用中。

Abstract: Weather prediction is a quintessential problem involving the forecasting of a complex, nonlinear, and chaotic high-dimensional dynamical system. This work introduces an efficient reduced-order modeling (ROM) framework for short-range weather prediction and investigates fundamental questions in dimensionality reduction and reduced order modeling of such systems. Unlike recent AI-driven models, which require extensive computational resources, our framework prioritizes efficiency while achieving reasonable accuracy. Specifically, a ResNet-based convolutional autoencoder augmented by block attention modules is developed to reduce the dimensionality of high-dimensional weather data. Subsequently, a linear operator is learned in the time-delayed embedding of the latent space to efficiently capture the dynamics. Using the ERA5 reanalysis dataset, we demonstrate that this framework performs well in-distribution as evidenced by effectively predicting weather patterns within training data periods. We also identify important limitations in generalizing to future states, particularly in maintaining prediction accuracy beyond the training window. Our analysis reveals that weather systems exhibit strong temporal correlations that can be effectively captured through linear operations in an appropriately constructed embedding space, and that projection error rather than inference error is the main bottleneck. These findings shed light on some key challenges in reduced-order modeling of chaotic systems and point toward opportunities for hybrid approaches that combine efficient reduced-order models as baselines with more sophisticated AI architectures, particularly for applications in long-term climate modeling where computational efficiency is paramount.

</details>


### [439] [A Closer Look at Personalized Fine-Tuning in Heterogeneous Federated Learning](https://arxiv.org/abs/2511.12695)
*Minghui Chen,Hrad Ghoukasian,Ruinan Jin,Zehua Wang,Sai Praneeth Karimireddy,Xiaoxiao Li*

Main category: cs.LG

TL;DR: 该论文提出将线性探测后微调(LP-FT)策略应用于联邦学习，以平衡个性化与泛化性能，通过理论分析和实验验证其在缓解联邦特征扭曲方面的优势。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在非独立同分布数据下难以平衡全局泛化与本地个性化，传统个性化微调方法容易过拟合或无法适应领域偏移。

Method: 将集中式环境中的线性探测后微调策略(LP-FT)适配到联邦学习设置，通过分阶段参数更新来缓解特征扭曲问题。

Result: 在7个数据集和6种个性化微调变体上的系统评估表明，LP-FT在平衡个性化与泛化方面表现优异，并揭示了联邦特征扭曲现象。

Conclusion: LP-FT通过分阶段参数更新有效缓解联邦特征扭曲，在部分特征重叠和协变量-概念偏移等条件下优于标准微调，为联邦学习中稳健个性化提供了实用指南。

Abstract: Federated Learning (FL) enables decentralized, privacy-preserving model training but struggles to balance global generalization and local personalization due to non-identical data distributions across clients. Personalized Fine-Tuning (PFT), a popular post-hoc solution, fine-tunes the final global model locally but often overfits to skewed client distributions or fails under domain shifts. We propose adapting Linear Probing followed by full Fine-Tuning (LP-FT), a principled centralized strategy for alleviating feature distortion (Kumar et al., 2022), to the FL setting. Through systematic evaluation across seven datasets and six PFT variants, we demonstrate LP-FT's superiority in balancing personalization and generalization. Our analysis uncovers federated feature distortion, a phenomenon where local fine-tuning destabilizes globally learned features, and theoretically characterizes how LP-FT mitigates this via phased parameter updates. We further establish conditions (e.g., partial feature overlap, covariate-concept shift) under which LP-FT outperforms standard fine-tuning, offering actionable guidelines for deploying robust personalization in FL.

</details>


### [440] [Beyond Fixed Tasks: Unsupervised Environment Design for Task-Level Pairs](https://arxiv.org/abs/2511.12706)
*Daniel Furelos-Blanco,Charles Pert,Frederik Kelbel,Alex F. Spies,Alessandra Russo,Michael Dennis*

Main category: cs.LG

TL;DR: ATLAS是一种新颖的方法，通过联合自动课程设计在任务和关卡层面生成可解决但具有挑战性的组合，显著优于随机采样方法。


<details>
  <summary>Details</summary>
Motivation: 训练通用智能体在复杂环境中遵循复杂指令存在挑战，随机采样任务-关卡对经常产生不可解决的组合，需要共同设计任务和关卡。

Method: 基于无监督环境设计(UED)，ATLAS生成任务和关卡的联合自动课程，利用任务和关卡结构的突变来加速策略收敛。

Result: 实验表明ATLAS在Minigrid环境中大幅优于随机采样方法，特别是在可解决对采样概率较低的情况下。

Conclusion: ATLAS通过联合自动课程设计有效解决了任务-关卡配对问题，利用任务和关卡结构的突变加速了高性能策略的收敛。

Abstract: Training general agents to follow complex instructions (tasks) in intricate environments (levels) remains a core challenge in reinforcement learning. Random sampling of task-level pairs often produces unsolvable combinations, highlighting the need to co-design tasks and levels. While unsupervised environment design (UED) has proven effective at automatically designing level curricula, prior work has only considered a fixed task. We present ATLAS (Aligning Tasks and Levels for Autocurricula of Specifications), a novel method that generates joint autocurricula over tasks and levels. Our approach builds upon UED to automatically produce solvable yet challenging task-level pairs for policy training. To evaluate ATLAS and drive progress in the field, we introduce an evaluation suite that models tasks as reward machines in Minigrid levels. Experiments demonstrate that ATLAS vastly outperforms random sampling approaches, particularly when sampling solvable pairs is unlikely. We further show that mutations leveraging the structure of both tasks and levels accelerate convergence to performant policies.

</details>


### [441] [On Robustness of Linear Classifiers to Targeted Data Poisoning](https://arxiv.org/abs/2511.12722)
*Nakshatra Gupta,Sumanth Prabhu,Supratik Chakraborty,R Venkatesh*

Main category: cs.LG

TL;DR: 本文提出了一种评估数据集对标签扰动型数据投毒攻击鲁棒性的方法，证明了该问题是NP完全的，并开发了计算鲁棒性上下界的有效技术。


<details>
  <summary>Details</summary>
Motivation: 数据投毒攻击威胁模型可信度，手动检测困难，需要自动评估数据集对这类攻击的鲁棒性。

Method: 在只能扰动训练数据标签的威胁模型下，提出计算鲁棒性上下界的技术，并在多个公开数据集上高效实现。

Result: 实验证明，超过识别鲁棒性边界的投毒会显著影响测试点分类，且该方法在更多情况下能成功计算边界，优于现有技术。

Conclusion: 该方法能有效评估数据集对标签扰动型数据投毒攻击的鲁棒性，为模型安全提供重要保障。

Abstract: Data poisoning is a training-time attack that undermines the trustworthiness of learned models. In a targeted data poisoning attack, an adversary manipulates the training dataset to alter the classification of a targeted test point. Given the typically large size of training dataset, manual detection of poisoning is difficult. An alternative is to automatically measure a dataset's robustness against such an attack, which is the focus of this paper. We consider a threat model wherein an adversary can only perturb the labels of the training dataset, with knowledge limited to the hypothesis space of the victim's model. In this setting, we prove that finding the robustness is an NP-Complete problem, even when hypotheses are linear classifiers. To overcome this, we present a technique that finds lower and upper bounds of robustness. Our implementation of the technique computes these bounds efficiently in practice for many publicly available datasets. We experimentally demonstrate the effectiveness of our approach. Specifically, a poisoning exceeding the identified robustness bounds significantly impacts test point classification. We are also able to compute these bounds in many more cases where state-of-the-art techniques fail.

</details>


### [442] [Convolutional Model Trees](https://arxiv.org/abs/2511.12725)
*William Ward Armstrong*

Main category: cs.LG

TL;DR: 提出了一种构建模型树森林的方法，通过降采样图像、确定树超平面、应用卷积处理训练图像的小变形，以及创建模型树森林来提高精度和平滑拟合。该方法通过像素、超平面系数和叶函数系数之间的1对1对应关系，能够处理更大的变形如任意旋转或视角变化。还描述了平滑森林输出以产生连续可微逼近的理论方法，并证明了训练过程的收敛性。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够处理图像函数样本的方法，特别是要处理图像的小变形和更大变形（如旋转和视角变化），同时实现高精度和平滑拟合。

Method: 通过多个步骤构建模型树森林：降采样图像、确定树超平面、对超平面应用卷积处理小变形、创建模型树森林以提高精度。利用像素、超平面系数和叶函数系数之间的1对1对应关系处理大变形。

Result: 该方法能够处理图像的小变形和更大变形（如任意旋转或视角变化），通过模型树森林实现了高精度和平滑拟合。

Conclusion: 提出的模型树森林方法能够有效处理图像的各种变形，实现了连续可微的逼近，并证明了训练过程的收敛性，为图像函数拟合提供了一种有效的解决方案。

Abstract: A method for creating a forest of model trees to fit samples of a function defined on images is described in several steps: down-sampling the images, determining a tree's hyperplanes, applying convolutions to the hyperplanes to handle small distortions of training images, and creating forests of model trees to increase accuracy and achieve a smooth fit. A 1-to-1 correspondence among pixels of images, coefficients of hyperplanes and coefficients of leaf functions offers the possibility of dealing with larger distortions such as arbitrary rotations or changes of perspective. A theoretical method for smoothing forest outputs to produce a continuously differentiable approximation is described. Within that framework, a training procedure is proved to converge.

</details>


### [443] [Stabilizing Self-Consuming Diffusion Models with Latent Space Filtering](https://arxiv.org/abs/2511.12742)
*Zhongteng Cai,Yaxuan Wang,Yang Liu,Xueru Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种名为潜在空间过滤（LSF）的新方法，通过过滤混合数据集中不太真实的合成数据来缓解模型崩溃问题，而无需增加训练成本或依赖人工标注。


<details>
  <summary>Details</summary>
Motivation: 随着合成数据在互联网上的扩散，它们经常被用来训练新一代生成模型，形成'自我消耗循环'，导致训练不稳定或模型崩溃。现有解决方案要么增加计算成本，要么需要昂贵的人工标注。

Method: 基于对自消耗扩散模型潜在空间动态的实证分析，提出潜在空间过滤（LSF）方法，通过过滤掉混合数据集中不太真实的合成数据来缓解模型崩溃。

Result: 实验表明，LSF在多个真实世界数据集上持续优于现有基线方法，有效缓解模型崩溃，且不增加训练成本或依赖人工标注。

Conclusion: LSF提供了一种有效且高效的方法来缓解自消耗生成模型中的模型崩溃问题，通过利用潜在空间结构来识别和过滤低质量合成数据。

Abstract: As synthetic data proliferates across the Internet, it is often reused to train successive generations of generative models. This creates a ``self-consuming loop" that can lead to training instability or \textit{model collapse}. Common strategies to address the issue -- such as accumulating historical training data or injecting fresh real data -- either increase computational cost or require expensive human annotation. In this paper, we empirically analyze the latent space dynamics of self-consuming diffusion models and observe that the low-dimensional structure of latent representations extracted from synthetic data degrade over generations. Based on this insight, we propose \textit{Latent Space Filtering} (LSF), a novel approach that mitigates model collapse by filtering out less realistic synthetic data from mixed datasets. Theoretically, we present a framework that connects latent space degradation to empirical observations. Experimentally, we show that LSF consistently outperforms existing baselines across multiple real-world datasets, effectively mitigating model collapse without increasing training cost or relying on human annotation.

</details>


### [444] [DIVIDE: A Framework for Learning from Independent Multi-Mechanism Data Using Deep Encoders and Gaussian Processes](https://arxiv.org/abs/2511.12745)
*Vivek Chawla,Boris Slautin,Utkarsh Pratiush,Dayakar Penumadu,Sergei Kalinin*

Main category: cs.LG

TL;DR: DIVIDE是一个框架，通过整合机制特定的深度编码器和结构化高斯过程来解耦科学数据集中的多个独立机制影响，实现可解释的机制感知预测和高效主动学习。


<details>
  <summary>Details</summary>
Motivation: 科学数据集通常来自多个独立机制（如空间、分类或结构效应）的组合影响，这些影响的混合掩盖了各自的贡献，需要解耦这些影响以获得更清晰的机制理解。

Method: 集成机制特定的深度编码器与结构化高斯过程在联合潜在空间中，编码器隔离不同机制，高斯过程捕获它们的组合效应并校准不确定性，支持结构化先验。

Result: 在合成数据集、FerroSIM铁电模式模拟和PbTiO3薄膜实验PFM磁滞回线上，DIVIDE成功分离机制，重现加性和缩放相互作用，并在噪声下保持鲁棒性。

Conclusion: DIVIDE框架有效解耦科学数据集中的独立机制，支持可解释预测和主动学习，可自然扩展到多功能数据集（机械、电磁或光学响应共存）。

Abstract: Scientific datasets often arise from multiple independent mechanisms such as spatial, categorical or structural effects, whose combined influence obscures their individual contributions. We introduce DIVIDE, a framework that disentangles these influences by integrating mechanism-specific deep encoders with a structured Gaussian Process in a joint latent space. Disentanglement here refers to separating independently acting generative factors. The encoders isolate distinct mechanisms while the Gaussian Process captures their combined effect with calibrated uncertainty. The architecture supports structured priors, enabling interpretable and mechanism-aware prediction as well as efficient active learning. DIVIDE is demonstrated on synthetic datasets combining categorical image patches with nonlinear spatial fields, on FerroSIM spin lattice simulations of ferroelectric patterns, and on experimental PFM hysteresis loops from PbTiO3 films. Across benchmarks, DIVIDE separates mechanisms, reproduces additive and scaled interactions, and remains robust under noise. The framework extends naturally to multifunctional datasets where mechanical, electromagnetic or optical responses coexist.

</details>


### [445] [Conformal Online Learning of Deep Koopman Linear Embeddings](https://arxiv.org/abs/2511.12760)
*Ben Gao,Jordan Patracone,Stéphane Chrétien,Olivier Alata*

Main category: cs.LG

TL;DR: COLoKe框架通过在线学习自适应更新非线性动力系统的Koopman不变表示，结合深度特征学习和多步预测一致性，使用符合性机制动态校准更新阈值，减少不必要更新并避免过拟合。


<details>
  <summary>Details</summary>
Motivation: 传统Koopman方法难以从流数据中自适应更新表示，容易过拟合且计算效率低，需要一种能够选择性更新模型并保持长期预测准确性的框架。

Method: 结合深度特征学习和提升空间中的多步预测一致性，使用符合性机制评估当前Koopman模型的一致性，仅当预测误差超过动态校准阈值时触发更新。

Result: 在基准动力系统上的实证结果表明，COLoKe能有效保持长期预测准确性，同时显著减少不必要更新并避免过拟合。

Conclusion: COLoKe提供了一种有效的在线学习框架，能够自适应更新Koopman表示，在保持预测精度的同时提高计算效率。

Abstract: We introduce Conformal Online Learning of Koopman embeddings (COLoKe), a novel framework for adaptively updating Koopman-invariant representations of nonlinear dynamical systems from streaming data. Our modeling approach combines deep feature learning with multistep prediction consistency in the lifted space, where the dynamics evolve linearly. To prevent overfitting, COLoKe employs a conformal-style mechanism that shifts the focus from evaluating the conformity of new states to assessing the consistency of the current Koopman model. Updates are triggered only when the current model's prediction error exceeds a dynamically calibrated threshold, allowing selective refinement of the Koopman operator and embedding. Empirical results on benchmark dynamical systems demonstrate the effectiveness of COLoKe in maintaining long-term predictive accuracy while significantly reducing unnecessary updates and avoiding overfitting.

</details>


### [446] [INC: An Indirect Neural Corrector for Auto-Regressive Hybrid PDE Solvers](https://arxiv.org/abs/2511.12764)
*Hao Wei,Aleksandra Franz,Bjoern List,Nils Thuerey*

Main category: cs.LG

TL;DR: 本文提出了间接神经校正器（INC），通过将学习到的修正集成到控制方程中而非直接状态更新，显著减少了自回归误差，在混沌系统中实现稳定高效的PDE仿真。


<details>
  <summary>Details</summary>
Motivation: 传统混合求解器直接将学习到的修正应用于求解器输出，在长期推演中会产生显著的自回归误差，特别是在混沌体系中，放大的扰动会不断累积。

Method: 提出间接神经校正器（INC），将学习到的修正集成到控制方程中，而不是直接进行状态更新，从而将误差放大降低到Δt⁻¹ + L的量级。

Result: 在广泛基准测试中，INC将长期轨迹性能（R²）提升高达158.7%，稳定了激进粗化下的爆炸情况，对复杂3D湍流案例实现了几个数量级的加速。

Conclusion: INC实现了具有形式误差减少的稳定高效PDE仿真，为具有可靠物理保证的更快科学和工程仿真铺平了道路。

Abstract: When simulating partial differential equations, hybrid solvers combine coarse numerical solvers with learned correctors. They promise accelerated simulations while adhering to physical constraints. However, as shown in our theoretical framework, directly applying learned corrections to solver outputs leads to significant autoregressive errors, which originate from amplified perturbations that accumulate during long-term rollouts, especially in chaotic regimes. To overcome this, we propose the Indirect Neural Corrector (\(\mathrm{INC}\)), which integrates learned corrections into the governing equations rather than applying direct state updates. Our key insight is that \(\mathrm{INC}\) reduces the error amplification on the order of \(Δt^{-1} + L\), where \(Δt\) is the timestep and $L$ the Lipschitz constant. At the same time, our framework poses no architectural requirements and integrates seamlessly with arbitrary neural networks and solvers. We test \(\mathrm{INC}\) in extensive benchmarks, covering numerous differentiable solvers, neural backbones, and test cases ranging from a 1D chaotic system to 3D turbulence. INC improves the long-term trajectory performance (\(R^2\)) by up to 158.7\%, stabilizes blowups under aggressive coarsening, and for complex 3D turbulence cases yields speed-ups of several orders of magnitude. INC thus enables stable, efficient PDE emulation with formal error reduction, paving the way for faster scientific and engineering simulations with reliable physics guarantees. Our source code is available at https://github.com/tum-pbs/INC

</details>


### [447] [Optimal Look-back Horizon for Time Series Forecasting in Federated Learning](https://arxiv.org/abs/2511.12791)
*Dahao Tang,Nan Yang,Yanli Li,Zhiyu Zhu,Zhibo Jin,Dong Yuan*

Main category: cs.LG

TL;DR: 本文提出了一个联邦时间序列预测中的自适应回望窗口选择框架，通过内在空间表示来解决数据分散、异构和非独立分布的问题。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习场景中，时间序列数据具有分散性、异构性和非独立性特征，选择合适的回望窗口是一个基本挑战。现有方法主要局限于集中式和独立分布设置，无法适应联邦环境。

Method: 引入合成数据生成器捕捉客户端数据的时间结构特征，定义将时间序列窗口映射到内在表示空间的变换，推导预测损失的贝叶斯项和近似项分解。

Result: 分析表明增加回望窗口能改善确定性模式的可识别性，但会增加模型复杂度和降低样本效率导致的近似误差。预测总损失在不可约损失开始饱和而近似损失持续上升的最小窗口处最小化。

Conclusion: 为联邦学习中的时间序列预测自适应窗口选择提供了严格的理论基础。

Abstract: Selecting an appropriate look-back horizon remains a fundamental challenge in time series forecasting (TSF), particularly in the federated learning scenarios where data is decentralized, heterogeneous, and often non-independent. While recent work has explored horizon selection by preserving forecasting-relevant information in an intrinsic space, these approaches are primarily restricted to centralized and independently distributed settings. This paper presents a principled framework for adaptive horizon selection in federated time series forecasting through an intrinsic space formulation. We introduce a synthetic data generator (SDG) that captures essential temporal structures in client data, including autoregressive dependencies, seasonality, and trend, while incorporating client-specific heterogeneity. Building on this model, we define a transformation that maps time series windows into an intrinsic representation space with well-defined geometric and statistical properties. We then derive a decomposition of the forecasting loss into a Bayesian term, which reflects irreducible uncertainty, and an approximation term, which accounts for finite-sample effects and limited model capacity. Our analysis shows that while increasing the look-back horizon improves the identifiability of deterministic patterns, it also increases approximation error due to higher model complexity and reduced sample efficiency. We prove that the total forecasting loss is minimized at the smallest horizon where the irreducible loss starts to saturate, while the approximation loss continues to rise. This work provides a rigorous theoretical foundation for adaptive horizon selection for time series forecasting in federated learning.

</details>


### [448] [Genomic Next-Token Predictors are In-Context Learners](https://arxiv.org/abs/2511.12797)
*Nathan Breslow,Aayush Mishra,Mahler Revsine,Michael C. Schatz,Anqi Liu,Daniel Khashabi*

Main category: cs.LG

TL;DR: 本文研究了基因组序列中是否能够通过大规模预测训练自然涌现出上下文学习能力，发现基因组模型与语言模型类似，都表现出上下文学习能力，支持上下文学习是大规模预测建模的普遍现象。


<details>
  <summary>Details</summary>
Motivation: 探索上下文学习是否仅是人类语言特有的现象，还是可以通过大规模预测训练在其他符号序列领域自然涌现。

Method: 开发了一个受控实验框架，在语言和基因组形式中实例化符号推理任务，直接比较基因组模型和语言模型的上下文学习能力。

Result: 基因组模型与语言模型类似，随着上下文演示数量的增加，在模式归纳方面表现出对数线性增益，首次证明了基因组序列中自然涌现的上下文学习。

Conclusion: 上下文学习是大规模预测建模在丰富数据上的结果，这一发现将涌现的元学习扩展到语言之外，指向了与模态无关的统一上下文学习观点。

Abstract: In-context learning (ICL) -- the capacity of a model to infer and apply abstract patterns from examples provided within its input -- has been extensively studied in large language models trained for next-token prediction on human text. In fact, prior work often attributes this emergent behavior to distinctive statistical properties in human language. This raises a fundamental question: can ICL arise organically in other sequence domains purely through large-scale predictive training?
  To explore this, we turn to genomic sequences, an alternative symbolic domain rich in statistical structure. Specifically, we study the Evo2 genomic model, trained predominantly on next-nucleotide (A/T/C/G) prediction, at a scale comparable to mid-sized LLMs. We develop a controlled experimental framework comprising symbolic reasoning tasks instantiated in both linguistic and genomic forms, enabling direct comparison of ICL across genomic and linguistic models. Our results show that genomic models, like their linguistic counterparts, exhibit log-linear gains in pattern induction as the number of in-context demonstrations increases. To the best of our knowledge, this is the first evidence of organically emergent ICL in genomic sequences, supporting the hypothesis that ICL arises as a consequence of large-scale predictive modeling over rich data. These findings extend emergent meta-learning beyond language, pointing toward a unified, modality-agnostic view of in-context learning.

</details>


### [449] [Expressive Temporal Specifications for Reward Monitoring](https://arxiv.org/abs/2511.12808)
*Omar Adalat,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 使用定量线性时序逻辑(LTL_f[F])合成奖励监控器，为可观测状态轨迹生成密集奖励流，解决强化学习中稀疏奖励问题


<details>
  <summary>Details</summary>
Motivation: 指定信息丰富且密集的奖励函数是强化学习中的关键挑战，直接影响智能体训练效率。当前文献中占主导地位的布尔语义会导致长视野决策中的稀疏奖励问题

Method: 利用定量线性时序逻辑在有限轨迹上的表达能力，合成奖励监控器，通过运行时可观测状态轨迹生成密集奖励流。该框架是算法无关的，仅依赖状态标记函数，自然支持非马尔可夫属性的指定

Result: 实验结果表明，定量监控器始终包含布尔监控器，并且根据环境的不同，在最大化任务完成度定量测量和减少收敛时间方面优于布尔监控器

Conclusion: 定量LTL_f[F]奖励监控器能够提供更细致的训练反馈，有效缓解稀疏奖励问题，在长视野决策任务中表现优于传统布尔监控器

Abstract: Specifying informative and dense reward functions remains a pivotal challenge in Reinforcement Learning, as it directly affects the efficiency of agent training. In this work, we harness the expressive power of quantitative Linear Temporal Logic on finite traces (($\text{LTL}_f[\mathcal{F}]$)) to synthesize reward monitors that generate a dense stream of rewards for runtime-observable state trajectories. By providing nuanced feedback during training, these monitors guide agents toward optimal behaviour and help mitigate the well-known issue of sparse rewards under long-horizon decision making, which arises under the Boolean semantics dominating the current literature. Our framework is algorithm-agnostic and only relies on a state labelling function, and naturally accommodates specifying non-Markovian properties. Empirical results show that our quantitative monitors consistently subsume and, depending on the environment, outperform Boolean monitors in maximizing a quantitative measure of task completion and in reducing convergence time.

</details>


### [450] [Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs](https://arxiv.org/abs/2511.12817)
*Shasha Zhou,Mingyu Huang,Jack Cole,Charles Britton,Ming Yin,Jan Wolber,Ke Li*

Main category: cs.LG

TL;DR: 本文提出FAITH框架，利用医学知识图谱自动评估LLM生成响应的真实性，无需参考答案，通过分解响应、链接知识图谱和基于证据路径评分，实验表明该方法与临床医生判断高度相关且能有效区分不同能力的LLM。


<details>
  <summary>Details</summary>
Motivation: 在医疗领域部署LLM需要严格的验证，但现有自动评估方法存在局限性，需要探索基于医学知识图谱的事实性评估方法。

Method: 提出FAITH框架：将响应分解为原子声明，链接到医学知识图谱，基于证据路径进行评分，无需参考答案。

Result: 实验显示基于知识图谱的评估与临床医生判断相关性显著更高，能有效区分不同能力的LLM，对文本变化具有鲁棒性，评分具有可解释性。

Conclusion: 尽管存在限制，但利用知识图谱是医疗领域自动事实性评估的重要方向。

Abstract: The recent proliferation of large language models (LLMs) holds the potential to revolutionize healthcare, with strong capabilities in diverse medical tasks. Yet, deploying LLMs in high-stakes healthcare settings requires rigorous verification and validation to understand any potential harm. This paper investigates the reliability and viability of using medical knowledge graphs (KGs) for the automated factuality evaluation of LLM-generated responses. To ground this investigation, we introduce FAITH, a framework designed to systematically probe the strengths and limitations of this KG-based approach. FAITH operates without reference answers by decomposing responses into atomic claims, linking them to a medical KG, and scoring them based on evidence paths. Experiments on diverse medical tasks with human subjective evaluations demonstrate that KG-grounded evaluation achieves considerably higher correlations with clinician judgments and can effectively distinguish LLMs with varying capabilities. It is also robust to textual variances. The inherent explainability of its scoring can further help users understand and mitigate the limitations of current LLMs. We conclude that while limitations exist, leveraging KGs is a prominent direction for automated factuality assessment in healthcare.

</details>


### [451] [Catastrophic Forgetting in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.12828)
*Mohammad Marufur Rahman,Guanchu Wang,Kaixiong Zhou,Minghan Chen,Fan Yang*

Main category: cs.LG

TL;DR: 本文研究了KANs在持续学习中的灾难性遗忘问题，通过理论分析和实验验证，揭示了KANs在低维算法任务中表现良好但在高维领域仍易遗忘的局限性，并提出了KAN-LoRA适配器用于参数高效的持续微调。


<details>
  <summary>Details</summary>
Motivation: KANs被认为通过局部样条激活函数具有内在抗遗忘能力，但其在持续学习中的实际行为和局限性尚不清楚，需要系统研究以理解其优势和不足。

Method: 开发了连接遗忘与激活支持重叠和内在数据维度的理论框架，在合成和视觉任务上进行系统实验，测量不同模型配置和数据复杂度下的遗忘动态，并提出了KAN-LoRA适配器用于语言模型的参数高效持续微调。

Result: KANs在低维算法设置中表现出有前景的记忆保持能力，但在图像分类和语言建模等高维领域中仍然容易发生灾难性遗忘。

Conclusion: 研究结果增进了对KANs优势和局限性的理解，为持续学习系统设计提供了实用见解，表明虽然KANs在某些场景下具有抗遗忘特性，但在复杂高维任务中仍需专门的缓解策略。

Abstract: Catastrophic forgetting is a longstanding challenge in continual learning, where models lose knowledge from earlier tasks when learning new ones. While various mitigation strategies have been proposed for Multi-Layer Perceptrons (MLPs), recent architectural advances like Kolmogorov-Arnold Networks (KANs) have been suggested to offer intrinsic resistance to forgetting by leveraging localized spline-based activations. However, the practical behavior of KANs under continual learning remains unclear, and their limitations are not well understood. To address this, we present a comprehensive study of catastrophic forgetting in KANs and develop a theoretical framework that links forgetting to activation support overlap and intrinsic data dimension. We validate these analyses through systematic experiments on synthetic and vision tasks, measuring forgetting dynamics under varying model configurations and data complexity. Further, we introduce KAN-LoRA, a novel adapter design for parameter-efficient continual fine-tuning of language models, and evaluate its effectiveness in knowledge editing tasks. Our findings reveal that while KANs exhibit promising retention in low-dimensional algorithmic settings, they remain vulnerable to forgetting in high-dimensional domains such as image classification and language modeling. These results advance the understanding of KANs' strengths and limitations, offering practical insights for continual learning system design.

</details>


### [452] [An Evaluation of Representation Learning Methods in Particle Physics Foundation Models](https://arxiv.org/abs/2511.12829)
*Michael Chen,Raghav Kansal,Abhijith Gandrakota,Zichun Hao,Jennifer Ngadiuba,Maria Spiropulu*

Main category: cs.LG

TL;DR: 本文系统评估了粒子物理学中的表示学习目标，在统一框架下比较了对比学习、掩码粒子建模和生成重建等不同方法，并提出了改进的监督架构，在基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 为粒子物理学中的表示学习提供系统评估框架，比较不同学习目标的贡献，为未来基础模型开发提供参考基准。

Method: 使用共享的基于transformer的粒子云编码器，采用标准化预处理、匹配采样和一致评估协议，比较对比学习（监督和自监督）、掩码粒子建模和生成重建目标。

Result: 在受控比较中隔离了学习目标的贡献，突出了各自的优势和局限性，并提供了可复现的基线。提出的监督架构修改在基准评估中达到了最先进性能。

Conclusion: 这项工作为粒子物理学中基础模型的未来发展提供了参考点，使整个社区能够实现更透明和稳健的进展。

Abstract: We present a systematic evaluation of representation learning objectives for particle physics within a unified framework. Our study employs a shared transformer-based particle-cloud encoder with standardized preprocessing, matched sampling, and a consistent evaluation protocol on a jet classification dataset. We compare contrastive (supervised and self-supervised), masked particle modeling, and generative reconstruction objectives under a common training regimen. In addition, we introduce targeted supervised architectural modifications that achieve state-of-the-art performance on benchmark evaluations. This controlled comparison isolates the contributions of the learning objective, highlights their respective strengths and limitations, and provides reproducible baselines. We position this work as a reference point for the future development of foundation models in particle physics, enabling more transparent and robust progress across the community.

</details>


### [453] [RoS-Guard: Robust and Scalable Online Change Detection with Delay-Optimal Guarantees](https://arxiv.org/abs/2511.12846)
*Zelin Zhu,Yancheng Huang,Kai Yang*

Main category: cs.LG

TL;DR: RoS-Guard是一种针对具有不确定性的线性系统的鲁棒最优在线变化检测算法，通过神经展开实现GPU加速的高效并行计算。


<details>
  <summary>Details</summary>
Motivation: 现有在线变化检测方法通常假设精确的系统知识，这在现实中不切实际，且在大规模系统中效率低下。

Method: 通过对OCD优化问题进行紧密松弛和重构，采用神经展开技术实现GPU加速的并行计算。

Result: 算法提供理论性能保证，包括预期误报率和最坏情况平均检测延迟，实验验证了其有效性并在大规模系统中实现显著计算加速。

Conclusion: RoS-Guard是一种鲁棒且高效的在线变化检测算法，特别适用于具有不确定性的大规模线性系统。

Abstract: Online change detection (OCD) aims to rapidly identify change points in streaming data and is critical in applications such as power system monitoring, wireless network sensing, and financial anomaly detection. Existing OCD methods typically assume precise system knowledge, which is unrealistic due to estimation errors and environmental variations. Moreover, existing OCD methods often struggle with efficiency in large-scale systems. To overcome these challenges, we propose RoS-Guard, a robust and optimal OCD algorithm tailored for linear systems with uncertainty. Through a tight relaxation and reformulation of the OCD optimization problem, RoS-Guard employs neural unrolling to enable efficient parallel computation via GPU acceleration. The algorithm provides theoretical guarantees on performance, including expected false alarm rate and worst-case average detection delay. Extensive experiments validate the effectiveness of RoS-Guard and demonstrate significant computational speedup in large-scale system scenarios.

</details>


### [454] [On the Fundamental Limits of LLMs at Scale](https://arxiv.org/abs/2511.12869)
*Muhammad Ahmed Mohsin,Muhammad Umer,Ahsan Bilal,Zeeshan Memon,Muhammad Ibtsaam Qadir,Sagnik Bhattacharya,Hassan Rizwan,Abhiram R. Gorle,Maahe Zehra Kazmi,Ayesha Mohsin,Muhammad Usman Rafique,Zihao He,Pulkit Mehta,Muhammad Ali Jamshed,John M. Cioffi*

Main category: cs.LG

TL;DR: 本文提出了一个统一的理论框架，从计算理论、信息论和统计学角度形式化分析了LLM扩展的五个基本限制：幻觉、上下文压缩、推理退化、检索脆弱性和多模态不对齐，并指出了这些限制的理论上限。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅从经验角度描述LLM扩展的限制现象，缺乏将这些现象与计算、信息和学习的基础理论限制相联系的严格理论综合。本文旨在填补这一空白。

Method: 构建了一个基于证明的统一框架，结合计算理论（可计算性与不可计算性）、信息论（有限描述长度）和统计学（样本复杂度）的理论分析，并辅以实证证据。

Result: 证明了LLM扩展存在固有的理论天花板：不可计算性导致不可消除的错误残留；信息论约束限制了可达到的准确度；几何和计算效应使长上下文压缩远低于名义大小；基于似然的训练偏好模式完成而非推理。

Conclusion: LLM扩展在某些方面有帮助，但在某些方面会饱和，在某些方面无法进展。文章提供了理论基础和实践缓解路径，如有界预言检索、位置课程和稀疏或分层注意力。

Abstract: Large Language Models (LLMs) have benefited enormously from scaling, yet these gains are bounded by five fundamental limitations: (1) hallucination, (2) context compression, (3) reasoning degradation, (4) retrieval fragility, and (5) multimodal misalignment. While existing surveys describe these phenomena empirically, they lack a rigorous theoretical synthesis connecting them to the foundational limits of computation, information, and learning. This work closes that gap by presenting a unified, proof-informed framework that formalizes the innate theoretical ceilings of LLM scaling. First, computability and uncomputability imply an irreducible residue of error: for any computably enumerable model family, diagonalization guarantees inputs on which some model must fail, and undecidable queries (e.g., halting-style tasks) induce infinite failure sets for all computable predictors. Second, information-theoretic and statistical constraints bound attainable accuracy even on decidable tasks, finite description length enforces compression error, and long-tail factual knowledge requires prohibitive sample complexity. Third, geometric and computational effects compress long contexts far below their nominal size due to positional under-training, encoding attenuation, and softmax crowding. We further show how likelihood-based training favors pattern completion over inference, how retrieval under token limits suffers from semantic drift and coupling noise, and how multimodal scaling inherits shallow cross-modal alignment. Across sections, we pair theorems and empirical evidence to outline where scaling helps, where it saturates, and where it cannot progress, providing both theoretical foundations and practical mitigation paths like bounded-oracle retrieval, positional curricula, and sparse or hierarchical attention.

</details>


### [455] [On the Information Processing of One-Dimensional Wasserstein Distances with Finite Samples](https://arxiv.org/abs/2511.12881)
*Cheongjae Jang,Jonghyun Won,Soyeon Jun,Chun Kee Chung,Keehyoung Joo,Yung-Kyun Noh*

Main category: cs.LG

TL;DR: 本文分析了在支持集显著重叠但密度函数存在显著点差异的情况下，一维Wasserstein距离如何准确识别密度差异，并探讨了在有限样本设置中的解析特性。


<details>
  <summary>Details</summary>
Motivation: 当两个密度函数的支持集显著重叠但密度值存在显著点差异时，传统Wasserstein距离主要关注支持集差异，而无法有效捕捉密度差异。本文旨在研究在这种情况下Wasserstein距离是否以及如何能够准确识别这些密度差异。

Method: 利用泊松过程和分离速率因子，分析一维Wasserstein距离在有限样本下的信息处理能力，研究其如何捕捉点密度差异以及这些信息如何与支持集差异协调。

Result: 通过神经脉冲序列解码和氨基酸接触频率数据的验证，结果表明一维Wasserstein距离能够突出与速率和支持集相关的有意义的密度差异。

Conclusion: 一维Wasserstein距离能够有效捕捉点密度差异，这些信息与支持集差异相协调，为在支持集重叠但密度差异显著的情况下使用Wasserstein距离提供了理论依据。

Abstract: Leveraging the Wasserstein distance -- a summation of sample-wise transport distances in data space -- is advantageous in many applications for measuring support differences between two underlying density functions. However, when supports significantly overlap while densities exhibit substantial pointwise differences, it remains unclear whether and how this transport information can accurately identify these differences, particularly their analytic characterization in finite-sample settings. We address this issue by conducting an analysis of the information processing capabilities of the one-dimensional Wasserstein distance with finite samples. By utilizing the Poisson process and isolating the rate factor, we demonstrate the capability of capturing the pointwise density difference with Wasserstein distances and how this information harmonizes with support differences. The analyzed properties are confirmed using neural spike train decoding and amino acid contact frequency data. The results reveal that the one-dimensional Wasserstein distance highlights meaningful density differences related to both rate and support.

</details>


### [456] [Method of Manufactured Learning for Solver-free Training of Neural Operators](https://arxiv.org/abs/2511.12890)
*Arth Sojitra,Omer San*

Main category: cs.LG

TL;DR: 本文提出了制造学习方法（MML），这是一种不依赖数值求解器的框架，通过分析构造物理一致的数据集来训练神经算子，避免了传统方法对昂贵数值模拟数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子训练需要大量由数值求解器生成的数据，这限制了可扩展性和物理系统探索。MML旨在摆脱对求解器数据的依赖，提供更高效的数据生成方法。

Method: 受制造解方法的启发，MML从受控分析空间采样平滑候选解，通过直接应用控制微分算子推导相应的强迫场。在推理时，将这些强迫项设为零以恢复原始控制方程。

Result: 在热传导、平流、Burgers和扩散反应等经典基准测试中，MML实现了高谱精度、低残差误差，并对未见条件具有良好的泛化能力。

Conclusion: MML通过将数据生成重新定义为分析合成过程，为构建物理基础的神经算子提供了一条可扩展、求解器无关的路径，无需依赖昂贵的数值模拟或实验数据。

Abstract: Training neural operators to approximate mappings between infinite-dimensional function spaces often requires extensive datasets generated by either demanding experimental setups or computationally expensive numerical solvers. This dependence on solver-based data limits scalability and constrains exploration across physical systems. Here we introduce the Method of Manufactured Learning (MML), a solver-independent framework for training neural operators using analytically constructed, physics-consistent datasets. Inspired by the classical method of manufactured solutions, MML replaces numerical data generation with functional synthesis, i.e., smooth candidate solutions are sampled from controlled analytical spaces, and the corresponding forcing fields are derived by direct application of the governing differential operators. During inference, setting these forcing terms to zero restores the original governing equations, allowing the trained neural operator to emulate the true solution operator of the system. The framework is agnostic to network architecture and can be integrated with any operator learning paradigm. In this paper, we employ Fourier neural operator as a representative example. Across canonical benchmarks including heat, advection, Burgers, and diffusion-reaction equations. MML achieves high spectral accuracy, low residual errors, and strong generalization to unseen conditions. By reframing data generation as a process of analytical synthesis, MML offers a scalable, solver-agnostic pathway toward constructing physically grounded neural operators that retain fidelity to governing laws without reliance on expensive numerical simulations or costly experimental data for training.

</details>


### [457] [Functional Mean Flow in Hilbert Space](https://arxiv.org/abs/2511.12898)
*Zhiqi Li,Yuchen Sun,Greg Turk,Bo Zhu*

Main category: cs.LG

TL;DR: 提出Functional Mean Flow (FMF)作为无限维希尔伯特空间中的一步生成模型，将Mean Flow框架扩展到函数域，提供理论公式和实用实现。


<details>
  <summary>Details</summary>
Motivation: 将一步生成模型扩展到函数域，以处理时间序列、图像、PDE和3D几何等函数数据生成任务。

Method: 在无限维希尔伯特空间中定义Functional Flow Matching，提出x1预测变体以提高稳定性，提供高效训练和采样的实用实现。

Result: 开发出一个实用的单步Flow Matching框架，适用于广泛的函数数据生成任务。

Conclusion: FMF是一个在函数域中有效的一步生成模型，为各种函数数据生成任务提供了实用的解决方案。

Abstract: We present Functional Mean Flow (FMF) as a one-step generative model defined in infinite-dimensional Hilbert space. FMF extends the one-step Mean Flow framework to functional domains by providing a theoretical formulation for Functional Flow Matching and a practical implementation for efficient training and sampling. We also introduce an $x_1$-prediction variant that improves stability over the original $u$-prediction form. The resulting framework is a practical one-step Flow Matching method applicable to a wide range of functional data generation tasks such as time series, images, PDEs, and 3D geometry.

</details>


### [458] [LinkedIn Profile Characteristics and Professional Success Indicators](https://arxiv.org/abs/2511.12905)
*Tania-Amanda Fredrick Eneye,Ashlesha Malla,Pawan Paudel*

Main category: cs.LG

TL;DR: 本研究探讨LinkedIn个人资料特征与职业成功的关系，通过机器学习模型分析6.2万份匿名资料，发现晋升可高度预测，而粉丝增长更为复杂。


<details>
  <summary>Details</summary>
Motivation: 探索LinkedIn个人资料特征如何影响职业成功指标（晋升、粉丝数、职业发展速度），为专业人士优化LinkedIn形象和职业策略提供指导。

Method: 使用机器学习技术对超过62,000份匿名LinkedIn个人资料数据集开发预测模型，识别影响职业成功的关键因素。

Result: 晋升具有高度可预测性，而粉丝增长表现出更大的复杂性，模型成功识别了驱动职业成功的最有影响力因素。

Conclusion: 研究为专业人士优化LinkedIn存在和职业策略提供了可行的见解，强调了不同职业成功指标的可预测性差异。

Abstract: This study explores the relationship between LinkedIn profile characteristics and professional success, focusing on the indicators of promotions, follower count, and career progression rate. By leveraging a dataset of over 62,000 anonymized LinkedIn profiles, we developed predictive models using machine learning techniques to identify the most influential factors driving professional success. Results indicate that while promotions are highly predictable, follower growth exhibits greater complexity. This research provides actionable insights for professionals seeking to optimize their LinkedIn presence and career strategies.

</details>


### [459] [Global Cross-Time Attention Fusion for Enhanced Solar Flare Prediction from Multivariate Time Series](https://arxiv.org/abs/2511.12955)
*Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 本文提出了一种基于Transformer的全局跨时间注意力融合(GCTAF)架构，用于解决太阳耀斑预测中的时间序列分类问题，特别是处理数据不平衡和长程时间建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 太阳耀斑预测面临两个主要挑战：耀斑事件的高度不平衡性（强烈耀斑稀少）和传统自注意力机制在长程时间建模上的局限性。

Method: 提出GCTAF架构，引入可学习的跨注意力全局令牌，这些令牌通过交叉注意力与输入序列交互，总结整个序列中的重要时间模式，然后融合回时间表示中。

Result: 在基准太阳耀斑数据集上的评估表明，GCTAF能有效检测强烈耀斑并提升预测性能。

Conclusion: 改进基于Transformer的架构为太阳耀斑预测任务提供了高潜力的替代方案。

Abstract: Multivariate time series classification is increasingly investigated in space weather research as a means to predict intense solar flare events, which can cause widespread disruptions across modern technological systems. Magnetic field measurements of solar active regions are converted into structured multivariate time series, enabling predictive modeling across segmented observation windows. However, the inherently imbalanced nature of solar flare occurrences, where intense flares are rare compared to minor flare events, presents a significant barrier to effective learning. To address this challenge, we propose a novel Global Cross-Time Attention Fusion (GCTAF) architecture, a transformer-based model to enhance long-range temporal modeling. Unlike traditional self-attention mechanisms that rely solely on local interactions within time series, GCTAF injects a set of learnable cross-attentive global tokens that summarize salient temporal patterns across the entire sequence. These tokens are refined through cross-attention with the input sequence and fused back into the temporal representation, enabling the model to identify globally significant, non-contiguous time points that are critical for flare prediction. This mechanism functions as a dynamic attention-driven temporal summarizer that augments the model's capacity to capture discriminative flare-related dynamics. We evaluate our approach on the benchmark solar flare dataset and show that GCTAF effectively detects intense flares and improves predictive performance, demonstrating that refining transformer-based architectures presents a high-potential alternative for solar flare prediction tasks.

</details>


### [460] [RAGPulse: An Open-Source RAG Workload Trace to Optimize RAG Serving Systems](https://arxiv.org/abs/2511.12979)
*Zhengchao Wang,Yitao Hu,Jianing Ye,Zhuxuan Chang,Jiazheng Yu,Youpeng Deng,Keqiu Li*

Main category: cs.LG

TL;DR: 本文介绍了RAGPulse，一个开源的大规模RAG工作负载跟踪数据集，该数据集收集自服务超过40,000名师生的大规模问答系统，旨在解决现有LLM推理跟踪无法捕捉RAG特定动态的问题。


<details>
  <summary>Details</summary>
Motivation: RAG系统的多阶段流水线和独特工作负载特性（如知识依赖）给服务性能优化带来重大挑战，现有通用LLM推理跟踪无法捕捉这些RAG特定动态，导致学术研究与实际部署之间存在显著性能差距。

Method: 通过一个自2024年4月起服务超过40,000名师生的大学范围问答系统收集RAG工作负载数据，采用隐私保护的基于哈希的数据格式，并进行深入的统计分析。

Result: 分析显示真实世界的RAG工作负载表现出显著的时间局部性和高度倾斜的热门文档访问模式。RAGPulse为研究人员开发内容感知批处理和检索缓存等优化策略提供了高保真基础。

Conclusion: RAGPulse填补了RAG系统性能优化研究的数据空白，为开发新颖优化策略提供了可靠基础，最终将提升RAG服务的效率和可靠性。

Abstract: Retrieval-Augmented Generation (RAG) is a critical paradigm for building reliable, knowledge-intensive Large Language Model (LLM) applications. However, the multi-stage pipeline (retrieve, generate) and unique workload characteristics (e.g., knowledge dependency) of RAG systems pose significant challenges for serving performance optimization. Existing generic LLM inference traces fail to capture these RAG-specific dynamics, creating a significant performance gap between academic research and real-world deployment. To bridge this gap, this paper introduces RAGPulse, an open-source RAG workload trace dataset. This dataset was collected from an university-wide Q&A system serving that has served more than 40,000 students and faculties since April 2024. We detail RAGPulse's system architecture, its privacy-preserving hash-based data format, and provide an in-depth statistical analysis. Our analysis reveals that real-world RAG workloads exhibit significant temporal locality and a highly skewed hot document access pattern. RAGPulse provides a high-fidelity foundation for researchers to develop and validate novel optimization strategies for RAG systems, such as content-aware batching and retrieval caching, ultimately enhancing the efficiency and reliability of RAG services. The code is available at https://github.com/flashserve/RAGPulse.

</details>


### [461] [Learning Branching Policies for MILPs with Proximal Policy Optimization](https://arxiv.org/abs/2511.12986)
*Abdelouahed Ben Mhamed,Assia Kamal-Idrissi,Amal El Fallah Seghrouchni*

Main category: cs.LG

TL;DR: 本文提出TGPPO框架，使用PPO强化学习算法训练分支策略，旨在提高混合整数线性规划中分支定界算法在异构实例间的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于模仿学习的分支策略容易过拟合专家演示，难以泛化到结构多样或未见过的实例。需要开发更鲁棒和自适应的分支策略。

Method: 提出Tree-Gate PPO框架，构建参数化状态空间表示，动态捕捉搜索树的演化上下文，使用PPO算法训练分支策略。

Result: TGPPO在减少探索节点数和改进p-原始对偶积分方面优于现有学习方法，特别是在分布外实例上表现突出。

Conclusion: 强化学习具有开发鲁棒且自适应MILP求解器分支策略的潜力，TGPPO展示了RL在提升分支定界算法泛化能力方面的有效性。

Abstract: Branch-and-Bound (B\&B) is the dominant exact solution method for Mixed Integer Linear Programs (MILP), yet its exponential time complexity poses significant challenges for large-scale instances. The growing capabilities of machine learning have spurred efforts to improve B\&B by learning data-driven branching policies. However, most existing approaches rely on Imitation Learning (IL), which tends to overfit to expert demonstrations and struggles to generalize to structurally diverse or unseen instances. In this work, we propose Tree-Gate Proximal Policy Optimization (TGPPO), a novel framework that employs Proximal Policy Optimization (PPO), a Reinforcement Learning (RL) algorithm, to train a branching policy aimed at improving generalization across heterogeneous MILP instances. Our approach builds on a parameterized state space representation that dynamically captures the evolving context of the search tree. Empirical evaluations show that TGPPO often outperforms existing learning-based policies in terms of reducing the number of nodes explored and improving p-Primal-Dual Integrals (PDI), particularly in out-of-distribution instances. These results highlight the potential of RL to develop robust and adaptable branching strategies for MILP solvers.

</details>


### [462] [Learning Time-Scale Invariant Population-Level Neural Representations](https://arxiv.org/abs/2511.13022)
*Eshani Patel,Yisong Yue,Geeling Chau*

Main category: cs.LG

TL;DR: 本文研究了神经时间序列基础模型中时间尺度不匹配对泛化性能的影响，提出了时间尺度增强预训练(TSAP)方法来提高模型对不同时间尺度的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 通用神经时间序列基础模型对神经科学发现和脑机接口应用很重要，但现有模型对预训练和下游任务间的时间尺度不匹配敏感，缺乏不变性。

Method: 提出了时间尺度增强预训练(TSAP)，通过在预训练阶段引入时间尺度增强来构建表示空间中的不变性。

Result: TSAP方法在不同解码任务中一致地提高了对不同时间尺度的鲁棒性，并在表示空间中建立了不变性。

Conclusion: 处理预处理多样性是构建可泛化神经基础模型的关键步骤，TSAP为解决时间尺度不匹配问题提供了有效方案。

Abstract: General-purpose foundation models for neural time series can help accelerate neuroscientific discoveries and enable applications such as brain computer interfaces (BCIs). A key component in scaling these models is population-level representation learning, which leverages information across channels to capture spatial as well as temporal structure. Population-level approaches have recently shown that such representations can be both efficient to learn on top of pretrained temporal encoders and produce useful representations for decoding a variety of downstream tasks. However, these models remain sensitive to mismatches in preprocessing, particularly on time-scales, between pretraining and downstream settings. We systematically examine how time-scale mismatches affects generalization and find that existing representations lack invariance. To address this, we introduce Time-scale Augmented Pretraining (TSAP), which consistently improves robustness to different time-scales across decoding tasks and builds invariance in the representation space. These results highlight handling preprocessing diversity as a key step toward building generalizable neural foundation models.

</details>


### [463] [SLMQuant:Benchmarking Small Language Model Quantization for Practical Deployment](https://arxiv.org/abs/2511.13023)
*Jiacheng Wang,Yejun Zeng,Jinyang Guo,Yuqing Ma,Aishan Liu,Xianglong Liu*

Main category: cs.LG

TL;DR: SLMQuant是首个系统评估LLM压缩技术在SLMs上应用的基准，发现SLMs和LLMs在量化敏感性上存在根本差异，直接迁移LLM优化技术会导致次优结果。


<details>
  <summary>Details</summary>
Motivation: 尽管小型语言模型作为资源高效替代方案受到关注，但在边缘设备上的部署仍面临挑战，因为模型压缩中的效率差距尚未解决。量化对LLMs有效，但对SLMs的适用性研究不足。

Method: 通过跨不同架构和任务的全面多轨道评估，分析最先进的量化方法在SLMs上的表现。识别影响SLM有效量化的关键因素。

Result: 研究揭示了SLMs和LLMs在量化敏感性上的根本差异，证明由于SLMs独特的架构特征和训练动态，直接迁移LLM优化技术会导致次优结果。

Conclusion: SLMQuant为在边缘应用中推进高效SLM部署建立了基础框架，并为在资源受限场景中部署轻量级语言模型提供了关键见解。

Abstract: Despite the growing interest in Small Language Models (SLMs) as resource-efficient alternatives to Large Language Models (LLMs), their deployment on edge devices remains challenging due to unresolved efficiency gaps in model compression. While quantization has proven effective for LLMs, its applicability to SLMs is significantly underexplored, with critical questions about differing quantization bottlenecks and efficiency profiles. This paper introduces SLMQuant, the first systematic benchmark for evaluating LLM compression techniques when applied to SLMs. Through comprehensive multi-track evaluations across diverse architectures and tasks, we analyze how state-of-the-art quantization methods perform on SLMs. Our findings reveal fundamental disparities between SLMs and LLMs in quantization sensitivity, demonstrating that direct transfer of LLM-optimized techniques leads to suboptimal results due to SLMs' unique architectural characteristics and training dynamics. We identify key factors governing effective SLM quantization and propose actionable design principles for SLM-tailored compression. SLMQuant establishes a foundational framework for advancing efficient SLM deployment on low-end devices in edge applications, and provides critical insights for deploying lightweight language models in resource-constrained scenarios.

</details>


### [464] [Bi-View Embedding Fusion: A Hybrid Learning Approach for Knowledge Graph's Nodes Classification Addressing Problems with Limited Data](https://arxiv.org/abs/2511.13044)
*Rosario Napoli,Giovanni Lonia,Antonio Celesti,Massimo Villari,Maria Fazio*

Main category: cs.LG

TL;DR: Bi-View是一种新颖的混合方法，通过结合Node2Vec和GraphSAGE两种图嵌入技术，增强知识图谱中节点特征的信息内容，从而在不依赖额外合成数据的情况下改进图机器学习模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法需要大量数据才能表现良好，限制了在稀疏或不完整场景中的应用。图机器学习虽然提供了替代方案，但在处理知识图谱时仍面临信息隐藏的挑战。

Method: 结合两种互补的图嵌入技术：Node2Vec（通过无监督随机游走捕获结构模式）和GraphSAGE（以监督方式聚合邻域信息）。首先计算Node2Vec嵌入表示图拓扑，然后用基于中心性的指标丰富节点特征作为GraphSAGE的输入，最后通过融合层结合两种表示。

Result: 该方法提高了下游任务的性能，特别是在初始特征较差的情况下，为更准确和精确的KG增强图机器学习模型奠定了基础。

Conclusion: Bi-View方法能够捕获图的拓扑和语义属性，使模型能够利用数据集中存在但未明确表示的信息特征，有效解决了知识图谱中信息隐藏的问题。

Abstract: Traditional Machine Learning (ML) methods require large amounts of data to perform well, limiting their applicability in sparse or incomplete scenarios and forcing the usage of additional synthetic data to improve the model training. To overcome this challenge, the research community is looking more and more at Graph Machine Learning (GML) as it offers a powerful alternative by using relationships within data. However, this method also faces limitations, particularly when dealing with Knowledge Graphs (KGs), which can hide huge information due to their semantic nature. This study introduces Bi-View, a novel hybrid approach that increases the informative content of node features in KGs to generate enhanced Graph Embeddings (GEs) that are used to improve GML models without relying on additional synthetic data. The proposed work combines two complementary GE techniques: Node2Vec, which captures structural patterns through unsupervised random walks, and GraphSAGE, which aggregates neighbourhood information in a supervised way. Node2Vec embeddings are first computed to represent the graph topology, and node features are then enriched with centrality-based metrics, which are used as input for the GraphSAGE model. Moreover, a fusion layer combines the original Node2Vec embeddings with the GraphSAGE-influenced representations, resulting in a dual-perspective embedding space. Such a fusion captures both topological and semantic properties of the graph, enabling the model to exploit informative features that may exist in the dataset but that are not explicitly represented. Our approach improves downstream task performance, especially in scenarios with poor initial features, giving the basis for more accurate and precise KG-enanched GML models.

</details>


### [465] [Generalization Bounds for Semi-supervised Matrix Completion with Distributional Side Information](https://arxiv.org/abs/2511.13049)
*Antoine Ledent,Mun Chong Soo,Nong Minh Hieu*

Main category: cs.LG

TL;DR: 该论文研究了一个矩阵补全问题，其中真实矩阵R和未知采样分布P都是低秩矩阵且共享共同子空间。利用大量无标签数据（来自P）和少量带标签数据，结合低秩子空间恢复理论和矩阵补全泛化边界，提出了误差界限分析。


<details>
  <summary>Details</summary>
Motivation: 受推荐系统场景启发，无标签数据对应'隐式反馈'（如购买、点击等），带标签数据对应'显式反馈'（用户明确评分）。研究如何有效结合这两种反馈类型来改进推荐系统性能。

Method: 利用低秩子空间恢复理论和矩阵补全模型的经典泛化边界，推导出由两个误差项组成的误差界限，分别与无标签数据和带标签数据的数量相关。

Result: 理论分析显示误差界限包含两个项：O(√(nd/M))和O(√(dr/N))，其中d是P的秩，r是R的秩。合成实验验证了泛化误差自然分解为P和R的估计误差。在真实数据集上的实验表明，该方法优于仅依赖显式评分的基线方法。

Conclusion: 该研究为分析推荐系统中显式和隐式反馈交互提供了一个有效的理论框架，证明了结合两种反馈类型可以提升推荐系统性能。

Abstract: We study a matrix completion problem where both the ground truth $R$ matrix and the unknown sampling distribution $P$ over observed entries are low-rank matrices, and \textit{share a common subspace}. We assume that a large amount $M$ of \textit{unlabeled} data drawn from the sampling distribution $P$ is available, together with a small amount $N$ of labeled data drawn from the same distribution and noisy estimates of the corresponding ground truth entries. This setting is inspired by recommender systems scenarios where the unlabeled data corresponds to `implicit feedback' (consisting in interactions such as purchase, click, etc. ) and the labeled data corresponds to the `explicit feedback', consisting of interactions where the user has given an explicit rating to the item. Leveraging powerful results from the theory of low-rank subspace recovery, together with classic generalization bounds for matrix completion models, we show error bounds consisting of a sum of two error terms scaling as $\widetilde{O}\left(\sqrt{\frac{nd}{M}}\right)$ and $\widetilde{O}\left(\sqrt{\frac{dr}{N}}\right)$ respectively, where $d$ is the rank of $P$ and $r$ is the rank of $M$. In synthetic experiments, we confirm that the true generalization error naturally splits into independent error terms corresponding to the estimations of $P$ and and the ground truth matrix $\ground$ respectively. In real-life experiments on Douban and MovieLens with most explicit ratings removed, we demonstrate that the method can outperform baselines relying only on the explicit ratings, demonstrating that our assumptions provide a valid toy theoretical setting to study the interaction between explicit and implicit feedbacks in recommender systems.

</details>


### [466] [Learning from the Undesirable: Robust Adaptation of Language Models without Forgetting](https://arxiv.org/abs/2511.13052)
*Yunhun Nam,Jaehyung Kim,Jongheon Jeong*

Main category: cs.LG

TL;DR: 提出了LfU方法，一种针对监督微调的简单有效正则化方案，通过抵抗不良模型更新来缓解有限数据下的过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 在有限数据下进行监督微调时，语言模型容易过拟合，依赖虚假模式或损害其他有用能力，需要一种正则化方法来提升泛化能力。

Method: 提出学习自不良方法(LfU)，通过一致性正则化直接对齐模型内部表示与不良更新后的表示，利用表示级数据增强促进泛化。

Result: 在多样化下游任务中，LfU相比普通SFT在数学任务上平均提升16.8%，且对提示变化具有更强鲁棒性，输出性能标准差降低92.1%。

Conclusion: LfU作为一种有效先验，在有限数据下既能增强适应性又能保留预训练知识，具有广泛适用性。

Abstract: Language models (LMs) are often adapted through supervised fine-tuning (SFT) to specialize their capabilities for downstream tasks. However, in typical scenarios where the fine-tuning data is limited, e.g., compared to pre-training, SFT can lead LMs to overfit, causing them to rely on spurious patterns within the target task or to compromise other broadly useful capabilities as a side effect of narrow specialization. In this paper, we propose Learning-from-the-Undesirable (LfU), a simple yet effective regularization scheme for SFT to mitigate overfitting issues when fine-tuning LMs with limited data. Specifically, we aim to regularize the fine-tuning process to favor solutions that are resilient to "undesirable" model updates, e.g., gradient ascent steps that steer the model toward undesirable behaviors. To this end, we propose a novel form of consistency regularization that directly aligns internal representations of the model with those after an undesirable update. By leveraging representation-level data augmentation through undesirable updates, LfU effectively promotes generalization under limited data. Our experiments on diverse LM downstream tasks show that LfU serves as an effective prior that enhances adaptability while preserving pretrained knowledge. For example, our LM from LfU achieves a 16.8% average improvement on math tasks compared to vanilla SFT on the same dataset, where the latter even leads to degraded performance on those tasks. Furthermore, LfU exhibits improved robustness to prompt variations, e.g., yielding a 92.1% lower standard deviation in output performances compared to SFT, highlighting its versatile effects.

</details>


### [467] [Latency and Ordering Effects in Online Decisions](https://arxiv.org/abs/2511.13060)
*Duo Yi*

Main category: cs.LG

TL;DR: 本文提出了一个针对延迟反馈和顺序敏感动态的在线决策系统的理论框架，通过Bregman散度作为损失基准，证明了超额基准损失的结构化下界，包含延迟惩罚、顺序敏感性惩罚及其几何交互项，并扩展到非凸设置。


<details>
  <summary>Details</summary>
Motivation: 在线决策系统经常在延迟反馈和顺序敏感动态下运行，传统方法难以处理这些复杂效应，需要新的理论框架来量化这些影响。

Method: 使用Bregman散度作为损失基准，构建结构化下界理论，包含延迟惩罚、顺序敏感性惩罚及其交互项，并扩展到近似正则和弱凸设置。

Result: 证明了超额基准损失的下界结构，提供了通过2×2随机化实验和流式诊断来估计和监控各项参数的实用方法。

Conclusion: 该框架将异构延迟、非交换性和实现差距效应打包成单一可解释的下界陈述，可在实际系统中进行压力测试和调优。

Abstract: Online decision systems routinely operate under delayed feedback and order-sensitive (noncommutative) dynamics: actions affect which observations arrive, and in what sequence. Taking a Bregman divergence $D_Φ$ as the loss benchmark, we prove that the excess benchmark loss admits a structured lower bound $L \ge L_{\mathrm{ideal}} + g_1(λ) + g_2(\varepsilon_\star) + g_{12}(λ,\varepsilon_\star) - D_{\mathrm{ncx}}$, where $g_1$ and $g_2$ are calibrated penalties for latency and order-sensitivity, $g_{12}$ captures their geometric interaction, and $D_{\mathrm{ncx}}\ge 0$ is a nonconvexity/approximation penalty that vanishes under convex Legendre assumptions. We extend this inequality to prox-regular and weakly convex settings, obtaining robust guarantees beyond the convex case. We also give an operational recipe for estimating and monitoring the four terms via simple $2\times 2$ randomized experiments and streaming diagnostics (effective sample size, clipping rate, interaction heatmaps). The framework packages heterogeneous latency, noncommutativity, and implementation-gap effects into a single interpretable lower-bound statement that can be stress-tested and tuned in real-world systems.

</details>


### [468] [MACKO: Sparse Matrix-Vector Multiplication for Low Sparsity](https://arxiv.org/abs/2511.13061)
*Vladimír Macko,Vladimír Boža*

Main category: cs.LG

TL;DR: MACKO-SpMV是一种GPU优化的稀疏矩阵向量乘法格式和内核，专门针对稀疏大语言模型中的非结构化稀疏性设计，在50%稀疏度下实现1.5倍内存减少和1.2-1.5倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有SpMV方法在稀疏LLMs中常见的低且非结构化稀疏性（30-90%）下表现不佳，非结构化剪枝只能提供有限的内存减少和加速效果。

Method: 提出MACKO-SpMV，这是一种GPU优化的格式和内核协同设计，减少存储开销同时保持与GPU执行模型的兼容性，无需专用硬件单元或格式特定的预计算。

Result: 在50%稀疏度下，MACKO是首个实现显著1.5倍内存减少和1.2-1.5倍加速的方法；相比其他SpMV基线：比cuSPARSE快2.8-13.0倍，比Sputnik快1.9-2.6倍，比DASP快2.2-2.5倍；应用于Llama2-7B模型，在fp16精度下实现1.5倍内存减少和1.5倍推理加速。

Conclusion: 得益于MACKO，50%稀疏度的非结构化剪枝现在可以在实际LLM工作负载中合理应用。

Abstract: Sparse Matrix-Vector Multiplication (SpMV) is a fundamental operation in the inference of sparse Large Language Models (LLMs). Because existing SpMV methods perform poorly under the low and unstructured sparsity (30-90%) commonly observed in pruned LLMs, unstructured pruning provided only limited memory reduction and speedup. We propose MACKO-SpMV, a GPU-optimized format and kernel co-designed to reduce storage overhead while preserving compatibility with the GPU's execution model. This enables efficient SpMV for unstructured sparsity without specialized hardware units (e.g., tensor cores) or format-specific precomputation. Empirical results show that at sparsity 50%, MACKO is the first approach with significant 1.5x memory reduction and 1.2-1.5x speedup over dense representation. Speedups over other SpMV baselines: 2.8-13.0x over cuSPARSE, 1.9-2.6x over Sputnik, and 2.2-2.5x over DASP. Applied to Llama2-7B pruned with Wanda to sparsity 50%, it delivers 1.5x memory reduction and 1.5x faster inference at fp16 precision. Thanks to MACKO, unstructured pruning at 50% sparsity is now justified in real-world LLM workloads.

</details>


### [469] [Self-Adaptive Graph Mixture of Models](https://arxiv.org/abs/2511.13062)
*Mohit Meena,Yash Punjabi,Abhishek A,Vishal Sharma,Mahesh Chandran*

Main category: cs.LG

TL;DR: 提出了SAGMM框架，通过自适应选择和组合多种GNN架构来解决模型选择困难问题，在16个基准数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前GNN性能增长趋于平缓，复杂模型并不总是优于经典模型，且为特定图任务选择合适模型存在困难。

Method: SAGMM采用模块化框架，利用拓扑感知注意力门控机制自适应分配专家模型，包含剪枝机制提高效率，并探索预训练专家模型的高效变体。

Result: 在节点分类、图分类、回归和链接预测等16个基准数据集上，SAGMM始终优于或匹配领先的GNN基线和现有混合方法。

Conclusion: SAGMM为现实世界图学习提供了鲁棒且自适应的解决方案，能够自动选择最适合的GNN模型组合。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning over graph-structured data, yet recent studies have shown that their performance gains are beginning to plateau. In many cases, well-established models such as GCN and GAT, when appropriately tuned, can match or even exceed the performance of more complex, state-of-the-art architectures. This trend highlights a key limitation in the current landscape: the difficulty of selecting the most suitable model for a given graph task or dataset. To address this, we propose Self-Adaptive Graph Mixture of Models (SAGMM), a modular and practical framework that learns to automatically select and combine the most appropriate GNN models from a diverse pool of architectures. Unlike prior mixture-of-experts approaches that rely on variations of a single base model, SAGMM leverages architectural diversity and a topology-aware attention gating mechanism to adaptively assign experts to each node based on the structure of the input graph. To improve efficiency, SAGMM includes a pruning mechanism that reduces the number of active experts during training and inference without compromising performance. We also explore a training-efficient variant in which expert models are pretrained and frozen, and only the gating and task-specific layers are trained. We evaluate SAGMM on 16 benchmark datasets covering node classification, graph classification, regression, and link prediction tasks, and demonstrate that it consistently outperforms or matches leading GNN baselines and prior mixture-based methods, offering a robust and adaptive solution for real-world graph learning.

</details>


### [470] [A Smart-Glasses for Emergency Medical Services via Multimodal Multitask Learning](https://arxiv.org/abs/2511.13078)
*Liuyi Jin,Pasan Gunawardena,Amran Haroon,Runzhi Wang,Sangwoo Lee,Radu Stoleru,Michael Middleton,Zepeng Huo,Jeeeun Kim,Jason Moats*

Main category: cs.LG

TL;DR: EMSGlass是一个基于EMSNet和EMSServe的智能眼镜系统，专为急救医疗服务设计，通过多模态数据集成提升急救人员的实时情境感知和决策效率。


<details>
  <summary>Details</summary>
Motivation: 急救医疗技术人员在高压环境下工作，需要在重认知负荷下快速做出关键决策，现有系统缺乏有效的多模态实时支持。

Method: 开发EMSNet多模态多任务模型，集成文本、生命体征和场景图像数据；构建EMSServe低延迟服务框架，包含模态感知模型分割器和特征缓存机制。

Result: EMSNet在5个关键EMS任务上优于单模态基线；EMSServe比直接PyTorch多模态推理快1.9-11.7倍；用户研究显示EMSGlass显著提升情境感知和决策效率。

Conclusion: EMSGlass成功将多模态智能与现实世界急救响应工作流程相结合，为下一代AI支持的EMS系统提供了可行方向。

Abstract: Emergency Medical Technicians (EMTs) operate in high-pressure environments, making rapid, life-critical decisions under heavy cognitive and operational loads. We present EMSGlass, a smart-glasses system powered by EMSNet, the first multimodal multitask model for Emergency Medical Services (EMS), and EMSServe, a low-latency multimodal serving framework tailored to EMS scenarios. EMSNet integrates text, vital signs, and scene images to construct a unified real-time understanding of EMS incidents. Trained on real-world multimodal EMS datasets, EMSNet simultaneously supports up to five critical EMS tasks with superior accuracy compared to state-of-the-art unimodal baselines. Built on top of PyTorch, EMSServe introduces a modality-aware model splitter and a feature caching mechanism, achieving adaptive and efficient inference across heterogeneous hardware while addressing the challenge of asynchronous modality arrival in the field. By optimizing multimodal inference execution in EMS scenarios, EMSServe achieves 1.9x -- 11.7x speedup over direct PyTorch multimodal inference. A user study evaluation with six professional EMTs demonstrates that EMSGlass enhances real-time situational awareness, decision-making speed, and operational efficiency through intuitive on-glass interaction. In addition, qualitative insights from the user study provide actionable directions for extending EMSGlass toward next-generation AI-enabled EMS systems, bridging multimodal intelligence with real-world emergency response workflows.

</details>


### [471] [Departures: Distributional Transport for Single-Cell Perturbation Prediction with Neural Schrödinger Bridges](https://arxiv.org/abs/2511.13124)
*Changxi Chi,Yufei Huang,Jun Xia,Jiangbin Zheng,Yunfan Liu,Zelin Zang,Stan Z. Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于薛定谔桥的生成模型，用于直接对齐控制组和扰动组的单细胞分布，解决了单细胞扰动数据无配对的问题，并在遗传和药物扰动数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 单细胞扰动预测是基因功能分析和药物候选选择的关键，但由于测序的破坏性，单细胞数据无法配对观测。现有神经生成模型缺乏明确的条件化或依赖先验空间进行间接分布对齐，限制了精确的扰动建模。

Method: 通过近似薛定谔桥来直接对齐不同扰动条件下控制组和扰动组的单细胞分布，利用Minibatch-OT配对避免双向推理，直接指导桥学习，实现可扩展的SB近似。构建了两个SB模型：一个建模离散基因激活状态，另一个建模连续表达分布。

Result: 在公共遗传和药物扰动数据集上的实验表明，该模型有效捕捉了异质性单细胞响应，并实现了最先进的性能。

Conclusion: 该方法通过直接分布对齐和联合训练，能够准确建模单细胞扰动并捕捉细胞异质性，为单细胞扰动预测提供了有效的解决方案。

Abstract: Predicting single-cell perturbation outcomes directly advances gene function analysis and facilitates drug candidate selection, making it a key driver of both basic and translational biomedical research. However, a major bottleneck in this task is the unpaired nature of single-cell data, as the same cell cannot be observed both before and after perturbation due to the destructive nature of sequencing. Although some neural generative transport models attempt to tackle unpaired single-cell perturbation data, they either lack explicit conditioning or depend on prior spaces for indirect distribution alignment, limiting precise perturbation modeling. In this work, we approximate Schrödinger Bridge (SB), which defines stochastic dynamic mappings recovering the entropy-regularized optimal transport (OT), to directly align the distributions of control and perturbed single-cell populations across different perturbation conditions. Unlike prior SB approximations that rely on bidirectional modeling to infer optimal source-target sample coupling, we leverage Minibatch-OT based pairing to avoid such bidirectional inference and the associated ill-posedness of defining the reverse process. This pairing directly guides bridge learning, yielding a scalable approximation to the SB. We approximate two SB models, one modeling discrete gene activation states and the other continuous expression distributions. Joint training enables accurate perturbation modeling and captures single-cell heterogeneity. Experiments on public genetic and drug perturbation datasets show that our model effectively captures heterogeneous single-cell responses and achieves state-of-the-art performance.

</details>


### [472] [Soft Conflict-Resolution Decision Transformer for Offline Multi-Task Reinforcement Learning](https://arxiv.org/abs/2511.13133)
*Shudong Wang,Xinfei Wang,Chenhao Zhang,Shanchen Pang,Haiyuan Gui,Wenhao Ji,Xiaojian Liao*

Main category: cs.LG

TL;DR: SoCo-DT是一种基于参数重要性的软冲突解决方法，通过Fisher信息动态调整掩码值，保留重要参数并抑制冲突参数，同时引入基于四分位距的动态稀疏度调整策略，在Meta-World基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多任务强化学习中存在梯度冲突问题，现有基于掩码的方法使用粗粒度二元掩码会过度抑制关键冲突参数，阻碍任务间知识共享，且不同任务冲突程度不同但现有方法使用固定稀疏度策略，限制了模型的泛化能力和学习效率。

Method: 提出SoCo-DT方法：1）利用Fisher信息动态调整掩码值，保留重要参数同时抑制冲突参数；2）基于四分位距引入动态稀疏度调整策略，根据冲突与和谐分数的分布构建任务特定的阈值方案；3）采用非对称余弦退火调度持续更新阈值以实现自适应稀疏度演化。

Result: 在Meta-World基准测试中，SoCo-DT在MT50上优于最先进方法7.6%，在次优数据集上优于10.5%，证明其在缓解梯度冲突和提升多任务性能方面的有效性。

Conclusion: SoCo-DT通过软冲突解决和动态稀疏度调整，有效缓解了多任务强化学习中的梯度冲突问题，显著提升了模型性能，为多任务学习提供了更有效的解决方案。

Abstract: Multi-task reinforcement learning (MTRL) seeks to learn a unified policy for diverse tasks, but often suffers from gradient conflicts across tasks. Existing masking-based methods attempt to mitigate such conflicts by assigning task-specific parameter masks. However, our empirical study shows that coarse-grained binary masks have the problem of over-suppressing key conflicting parameters, hindering knowledge sharing across tasks. Moreover, different tasks exhibit varying conflict levels, yet existing methods use a one-size-fits-all fixed sparsity strategy to keep training stability and performance, which proves inadequate. These limitations hinder the model's generalization and learning efficiency.
  To address these issues, we propose SoCo-DT, a Soft Conflict-resolution method based by parameter importance. By leveraging Fisher information, mask values are dynamically adjusted to retain important parameters while suppressing conflicting ones. In addition, we introduce a dynamic sparsity adjustment strategy based on the Interquartile Range (IQR), which constructs task-specific thresholding schemes using the distribution of conflict and harmony scores during training. To enable adaptive sparsity evolution throughout training, we further incorporate an asymmetric cosine annealing schedule to continuously update the threshold. Experimental results on the Meta-World benchmark show that SoCo-DT outperforms the state-of-the-art method by 7.6% on MT50 and by 10.5% on the suboptimal dataset, demonstrating its effectiveness in mitigating gradient conflicts and improving overall multi-task performance.

</details>


### [473] [Personalized Federated Learning with Bidirectional Communication Compression via One-Bit Random Sketching](https://arxiv.org/abs/2511.13144)
*Jiacheng Cheng,Xu Zhang,Guanghui Qiu,Yifang Zhang,Yinchuan Li,Kaiyuan Feng*

Main category: cs.LG

TL;DR: pFed1BS是一个新颖的个性化联邦学习框架，通过一比特随机草图实现极端通信压缩，解决联邦学习中的双向通信开销和客户端数据异构性问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临双向通信开销和客户端数据异构性的关键挑战，需要在降低通信成本的同时处理数据异质性。

Method: 提出pFed1BS框架，客户端传输高度压缩的一比特草图，服务器聚合并广播全局一比特共识；引入基于符号的正则化器指导本地模型与全局共识对齐；使用快速哈达玛变换进行高效投影。

Result: 理论分析保证算法收敛到全局势函数的稳定邻域；数值模拟显示pFed1BS显著降低通信成本，同时与先进的通信高效联邦学习算法相比具有竞争力。

Conclusion: pFed1BS通过一比特随机草图实现了有效的个性化联邦学习，在保持性能的同时大幅降低了通信开销。

Abstract: Federated Learning (FL) enables collaborative training across decentralized data, but faces key challenges of bidirectional communication overhead and client-side data heterogeneity. To address communication costs while embracing data heterogeneity, we propose pFed1BS, a novel personalized federated learning framework that achieves extreme communication compression through one-bit random sketching. In personalized FL, the goal shifts from training a single global model to creating tailored models for each client. In our framework, clients transmit highly compressed one-bit sketches, and the server aggregates and broadcasts a global one-bit consensus. To enable effective personalization, we introduce a sign-based regularizer that guides local models to align with the global consensus while preserving local data characteristics. To mitigate the computational burden of random sketching, we employ the Fast Hadamard Transform for efficient projection. Theoretical analysis guarantees that our algorithm converges to a stationary neighborhood of the global potential function. Numerical simulations demonstrate that pFed1BS substantially reduces communication costs while achieving competitive performance compared to advanced communication-efficient FL algorithms.

</details>


### [474] [OTARo: Once Tuning for All Precisions toward Robust On-Device LLMs](https://arxiv.org/abs/2511.13147)
*Shaoyuan Chen,Zhixuan Chen,Dawei Yang,Zhihang Yuan,Qiang Wu*

Main category: cs.LG

TL;DR: OTARo是一种新颖的量化方法，使设备端LLM能够灵活切换量化精度，通过一次微调保持性能鲁棒性，使用共享指数浮点机制实现不同位宽的简单截断。


<details>
  <summary>Details</summary>
Motivation: 传统量化方法存在结构限制，无法在复杂现实场景中支持设备端精度切换，因为不同任务需要不同量化精度（如理解任务比生成任务对精度降低更容忍）。

Method: 提出OTARo方法：1）引入共享指数浮点量化机制，通过单一模型的尾数截断产生不同位宽；2）采用利用-探索位宽路径搜索策略迭代更新搜索路径；3）使用低精度异步累积进行异步梯度累积和延迟更新。

Result: 在LLaMA3.2-1B、LLaMA3-8B等流行LLM上的实验表明，OTARo在所有精度下都能实现一致强大且鲁棒的性能。

Conclusion: OTARo成功解决了传统量化方法在设备端精度切换方面的局限性，为实际应用中的灵活部署提供了有效解决方案。

Abstract: Large Language Models (LLMs) fine-tuning techniques not only improve the adaptability to diverse downstream tasks, but also mitigate adverse effects of model quantization. Despite this, conventional quantization suffers from its structural limitation that hinders flexibility during the fine-tuning and deployment stages. Practical on-device tasks demand different quantization precisions (i.e. different bit-widths), e.g., understanding tasks tend to exhibit higher tolerance to reduced precision compared to generation tasks. Conventional quantization, typically relying on scaling factors that are incompatible across bit-widths, fails to support the on-device switching of precisions when confronted with complex real-world scenarios. To overcome the dilemma, we propose OTARo, a novel method that enables on-device LLMs to flexibly switch quantization precisions while maintaining performance robustness through once fine-tuning. OTARo introduces Shared Exponent Floating Point (SEFP), a distinct quantization mechanism, to produce different bit-widths through simple mantissa truncations of a single model. Moreover, to achieve bit-width robustness in downstream applications, OTARo performs a learning process toward losses induced by different bit-widths. The method involves two critical strategies: (1) Exploitation-Exploration Bit-Width Path Search (BPS), which iteratively updates the search path via a designed scoring mechanism; (2) Low-Precision Asynchronous Accumulation (LAA), which performs asynchronous gradient accumulations and delayed updates under low bit-widths. Experiments on popular LLMs, e.g., LLaMA3.2-1B, LLaMA3-8B, demonstrate that OTARo achieves consistently strong and robust performance for all precisions.

</details>


### [475] [Uncertainty-aware Physics-informed Neural Networks for Robust CARS-to-Raman Signal Reconstruction](https://arxiv.org/abs/2511.13185)
*Aishwarya Venkataramanan,Sai Karthikeya Vemuri,Adithya Ashok Chalain Valapil,Joachim Denzler*

Main category: cs.LG

TL;DR: 该论文评估了在CARS到拉曼信号重建中各种不确定性量化技术，并证明将物理知识约束融入模型可以改善校准，为更可靠的CARS数据分析提供路径。


<details>
  <summary>Details</summary>
Motivation: CARS光谱学在医学和材料科学中广泛应用，但非共振背景干扰了真实拉曼信号。现有深度学习方法缺乏不确定性量化能力，这在高风险应用中至关重要。

Method: 评估和比较了CARS到拉曼信号重建中的各种不确定性量化技术，并将物理知识约束（如Kramers-Kronig关系和光滑性约束）整合到模型中。

Result: 研究表明，将物理知识约束融入模型可以改善其校准性能，为更可靠的CARS数据分析提供有前景的路径。

Conclusion: 通过集成物理知识约束和不确定性量化技术，可以开发出更值得信赖的CARS数据分析方法，这对于高风险科学和生物医学应用至关重要。

Abstract: Coherent anti-Stokes Raman scattering (CARS) spectroscopy is a powerful and rapid technique widely used in medicine, material science, and chemical analyses. However, its effectiveness is hindered by the presence of a non-resonant background that interferes with and distorts the true Raman signal. Deep learning methods have been employed to reconstruct the true Raman spectrum from measured CARS data using labeled datasets. A more recent development integrates the domain knowledge of Kramers-Kronig relationships and smoothness constraints in the form of physics-informed loss functions. However, these deterministic models lack the ability to quantify uncertainty, an essential feature for reliable deployment in high-stakes scientific and biomedical applications. In this work, we evaluate and compare various uncertainty quantification (UQ) techniques within the context of CARS-to-Raman signal reconstruction. Furthermore, we demonstrate that incorporating physics-informed constraints into these models improves their calibration, offering a promising path toward more trustworthy CARS data analysis.

</details>


### [476] [DiffFP: Learning Behaviors from Scratch via Diffusion-based Fictitious Play](https://arxiv.org/abs/2511.13186)
*Akash Karthikeyan,Yash Vardhan Pant*

Main category: cs.LG

TL;DR: DiffFP是一个虚构博弈框架，使用扩散策略来估计对未见对手的最佳响应，在连续决策空间中学习鲁棒的多模态行为策略，在零和游戏中收敛到ε-纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 解决连续决策空间中自我博弈强化学习的挑战，确保在动态多智能体环境中的适应性和泛化能力，避免收敛缓慢或无法收敛到纳什均衡的问题。

Method: 提出DiffFP框架，使用扩散策略通过生成建模来学习自适应和多样化的策略，估计对未见对手的最佳响应。

Result: 在赛车和多粒子零和游戏等复杂多智能体环境中验证，学习到的策略对多样化对手具有鲁棒性，比基线强化学习策略表现更好，收敛速度提高3倍，成功率平均提高30倍。

Conclusion: DiffFP框架在连续空间零和游戏中有效收敛到ε-纳什均衡，展示了对手策略的鲁棒性和训练迭代的稳定性。

Abstract: Self-play reinforcement learning has demonstrated significant success in learning complex strategic and interactive behaviors in competitive multi-agent games. However, achieving such behaviors in continuous decision spaces remains challenging. Ensuring adaptability and generalization in self-play settings is critical for achieving competitive performance in dynamic multi-agent environments. These challenges often cause methods to converge slowly or fail to converge at all to a Nash equilibrium, making agents vulnerable to strategic exploitation by unseen opponents. To address these challenges, we propose DiffFP, a fictitious play (FP) framework that estimates the best response to unseen opponents while learning a robust and multimodal behavioral policy. Specifically, we approximate the best response using a diffusion policy that leverages generative modeling to learn adaptive and diverse strategies. Through empirical evaluation, we demonstrate that the proposed FP framework converges towards $ε$-Nash equilibria in continuous- space zero-sum games. We validate our method on complex multi-agent environments, including racing and multi-particle zero-sum games. Simulation results show that the learned policies are robust against diverse opponents and outperform baseline reinforcement learning policies. Our approach achieves up to 3$\times$ faster convergence and 30$\times$ higher success rates on average against RL-based baselines, demonstrating its robustness to opponent strategies and stability across training iterations

</details>


### [477] [ParaDySe: A Parallel-Strategy Switching Framework for Dynamic Sequence Lengths in Transformer](https://arxiv.org/abs/2511.13198)
*Zhixin Ou,Peng Liang,Jianchen Han,Baihui Liu,Linbo Qiao*

Main category: cs.LG

TL;DR: ParaDySe是一个用于动态序列的自适应并行策略切换框架，解决了LLM训练中短序列通信并行化取消和长序列内存不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前训练框架对动态序列采用预定义的静态并行策略，导致短序列通信并行化取消和长序列内存不足的问题。

Method: 实现并行策略的模块化函数库，构建序列感知的内存和时间成本模型，通过启发式算法选择最优层间策略，实现无缝热切换。

Result: 在序列长度达624K的数据集上测试，ParaDySe解决了OOM和CPC瓶颈，系统地将长序列优化与现有框架集成。

Conclusion: ParaDySe通过自适应并行策略切换，有效解决了LLM训练中动态序列的通信和内存问题。

Abstract: Dynamic sequences with varying lengths have been widely used in the training of Transformer-based large language models (LLMs). However, current training frameworks adopt a pre-defined static parallel strategy for these sequences, causing neither communication-parallelization cancellation on short sequences nor out-of-memory on long sequences. To mitigate these issues, we propose ParaDySe, a novel adaptive Parallel strategy switching framework for Dynamic Sequences. ParaDySe enables on-the-fly optimal strategy adoption according to the immediate input sequence. It first implements the modular function libraries for parallel strategies with unified tensor layout specifications, and then builds sequence-aware memory and time cost models with hybrid methods. Guided by cost models, ParaDySe selects optimal layer-wise strategies for dynamic sequences via an efficient heuristic algorithm. By integrating these techniques together, ParaDySe achieves seamless hot-switching of optimal strategies through its well-designed function libraries. We compare ParaDySe with baselines on representative LLMs under datasets with sequence lengths up to 624K. Experimental results indicate that ParaDySe addresses OOM and CPC bottlenecks in LLM training by systematically integrating long-sequence optimizations with existing frameworks.

</details>


### [478] [TokenSqueeze: Performance-Preserving Compression for Reasoning LLMs](https://arxiv.org/abs/2511.13223)
*Yuxiang Zhang,Zhengxu Yu,Weihang Pan,Zhongming Jin,Qiang Fu,Deng Cai,Binbin Lin,Jieping Ye*

Main category: cs.LG

TL;DR: TokenSqueeze是一种新的Long2Short方法，通过自适应选择推理深度和分布对齐的语言精炼，在保持性能的同时显著减少推理LLMs的token使用量。


<details>
  <summary>Details</summary>
Motivation: 现有推理LLMs生成的长链式思维导致token使用量增加，带来更高的推理延迟和内存消耗，需要在保持准确性的同时提高推理效率。

Method: 提出TokenSqueeze方法：1）自适应选择与问题复杂度匹配的推理深度样本；2）分布对齐的语言精炼方法，在不改变推理路径的情况下优化语言表达。

Result: 在MATH500基准测试中，使用该方法微调的DeepSeek-R1-Distill-Qwen-7B实现了50%的平均token减少，同时保持准确性。

Conclusion: TokenSqueeze仅利用模型自生成数据，无需依赖人工整理的短答案数据集，就能实现高效高保真的推理，适用于多样化应用。

Abstract: Emerging reasoning LLMs such as OpenAI-o1 and DeepSeek-R1 have achieved strong performance on complex reasoning tasks by generating long chain-of-thought (CoT) traces. However, these long CoTs result in increased token usage, leading to higher inference latency and memory consumption. As a result, balancing accuracy and reasoning efficiency has become essential for deploying reasoning LLMs in practical applications. Existing long-to-short (Long2Short) methods aim to reduce inference length but often sacrifice accuracy, revealing a need for an approach that maintains performance while lowering token costs. To address this efficiency-accuracy tradeoff, we propose TokenSqueeze, a novel Long2Short method that condenses reasoning paths while preserving performance and relying exclusively on self-generated data. First, to prevent performance degradation caused by excessive compression of reasoning depth, we propose to select self-generated samples whose reasoning depth is adaptively matched to the complexity of the problem. To further optimize the linguistic expression without altering the underlying reasoning paths, we introduce a distribution-aligned linguistic refinement method that enhances the clarity and conciseness of the reasoning path while preserving its logical integrity. Comprehensive experimental results demonstrate the effectiveness of TokenSqueeze in reducing token usage while maintaining accuracy. Notably, DeepSeek-R1-Distill-Qwen-7B fine-tuned using our proposed method achieved a 50\% average token reduction while preserving accuracy on the MATH500 benchmark. TokenSqueeze exclusively utilizes the model's self-generated data, enabling efficient and high-fidelity reasoning without relying on manually curated short-answer datasets across diverse applications. Our code is available at https://github.com/zhangyx1122/TokenSqueeze.

</details>


### [479] [Laplace Learning in Wasserstein Space](https://arxiv.org/abs/2511.13229)
*Mary Chriselda Antony Oliver,Michael Roberts,Carola-Bibiane Schönlieb,Matthew Thorpe*

Main category: cs.LG

TL;DR: 本文研究了基于图的半监督学习方法，将拉普拉斯学习扩展到Wasserstein空间，从有限维欧几里得空间推广到无限维设置。通过证明离散图p-Dirichlet能量到其连续对应物的变分收敛，并刻画Wasserstein空间子流形上的拉普拉斯-贝尔特拉米算子，最终通过基准数据集上的数值实验验证了理论框架。


<details>
  <summary>Details</summary>
Motivation: 流形假说认为高维数据通常存在于低维子空间中。本文基于这一假说研究基于图的半监督学习方法，特别是将拉普拉斯学习扩展到Wasserstein空间，以处理高维数据分类问题。

Method: 将经典的基于图半监督学习算法从有限维欧几里得空间扩展到无限维Wasserstein空间。通过证明离散图p-Dirichlet能量到其连续对应物的变分收敛，并刻画Wasserstein空间子流形上的拉普拉斯-贝尔特拉米算子。

Result: 成功建立了从离散到连续的理论框架，并在基准数据集上进行了数值实验验证。实验结果表明在高维设置下分类性能具有一致性。

Conclusion: 本文提出的理论框架成功地将基于图的半监督学习方法扩展到Wasserstein空间，为处理高维数据分类问题提供了新的理论工具和实用方法。

Abstract: The manifold hypothesis posits that high-dimensional data typically resides on low-dimensional sub spaces. In this paper, we assume manifold hypothesis to investigate graph-based semi-supervised learning
  methods. In particular, we examine Laplace Learning in the Wasserstein space, extending the classical
  notion of graph-based semi-supervised learning algorithms from finite-dimensional Euclidean spaces to
  an infinite-dimensional setting. To achieve this, we prove variational convergence of a discrete graph p- Dirichlet energy to its continuum counterpart. In addition, we characterize the Laplace-Beltrami operator
  on asubmanifold of the Wasserstein space. Finally, we validate the proposed theoretical framework through
  numerical experiments conducted on benchmark datasets, demonstrating the consistency of our classification performance in high-dimensional settings.

</details>


### [480] [MorphBoost: Self-Organizing Universal Gradient Boosting with Adaptive Tree Morphing](https://arxiv.org/abs/2511.13234)
*Boris Kriuk*

Main category: cs.LG

TL;DR: MorphBoost是一种新型梯度提升框架，采用自组织树结构，能够在训练过程中动态调整分裂行为，通过自适应分裂函数和问题指纹识别技术，在10个数据集上平均优于XGBoost 0.84%，获得40%的胜率。


<details>
  <summary>Details</summary>
Motivation: 传统梯度提升算法使用静态树结构，分裂标准在训练过程中保持不变，限制了其适应不同学习阶段梯度分布变化和问题特定特征的能力。

Method: 引入自组织树结构，包含：(1)结合梯度得分和信息论度量的变形分裂准则；(2)自动问题指纹识别；(3)向量化树预测；(4)交互感知特征重要性；(5)快速模式优化。

Result: 在10个多样化数据集上的综合基准测试显示，MorphBoost实现最先进性能，平均优于XGBoost 0.84%，获得4/10数据集胜利（40%胜率）和6/30前三名完成（20%），同时保持最低方差（σ=0.0948）和最高最小准确率。

Conclusion: MorphBoost通过动态适应的树结构在保持高一致性和鲁棒性的同时，在复杂问题上实现了显著性能提升，特别是在高级问题上由于更高的适应水平而获得显著改进。

Abstract: Traditional gradient boosting algorithms employ static tree structures with fixed splitting criteria that remain unchanged throughout training, limiting their ability to adapt to evolving gradient distributions and problem-specific characteristics across different learning stages. This work introduces MorphBoost, a new gradient boosting framework featuring self-organizing tree structures that dynamically morph their splitting behavior during training. The algorithm implements adaptive split functions that evolve based on accumulated gradient statistics and iteration-dependent learning pressures, enabling automatic adjustment to problem complexity. Key innovations include: (1) morphing split criterion combining gradient-based scores with information-theoretic metrics weighted by training progress; (2) automatic problem fingerprinting for intelligent parameter configuration across binary/multiclass/regression tasks; (3) vectorized tree prediction achieving significant computational speedups; (4) interaction-aware feature importance detecting multiplicative relationships; and (5) fast-mode optimization balancing speed and accuracy. Comprehensive benchmarking across 10 diverse datasets against competitive models (XGBoost, LightGBM, GradientBoosting, HistGradientBoosting, ensemble methods) demonstrates that MorphBoost achieves state-of-the-art performance, outperforming XGBoost by 0.84% on average. MorphBoost secured the overall winner position with 4/10 dataset wins (40% win rate) and 6/30 top-3 finishes (20%), while maintaining the lowest variance (σ=0.0948) and highest minimum accuracy across all models, revealing superior consistency and robustness. Performance analysis across difficulty levels shows competitive results on easy datasets while achieving notable improvements on advanced problems due to higher adaptation levels.

</details>


### [481] [Counterfactual Explainable AI (XAI) Method for Deep Learning-Based Multivariate Time Series Classification](https://arxiv.org/abs/2511.13237)
*Alan G. Paredes Cetina,Kaouther Benguessoum,Raoni Lourenço,Sylvain Kubler*

Main category: cs.LG

TL;DR: CONFETTI是一种新颖的多目标反事实解释方法，用于多元时间序列分析，通过平衡预测置信度、邻近性和稀疏性来提供可操作的见解。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在多元时间序列分类和回归中缺乏透明度，而现有的可解释AI方法往往无法传达完整的决策空间，反事实解释方法通常只优先考虑准确性、邻近性或稀疏性中的单一目标，限制了实用价值。

Method: CONFETTI通过识别关键MTS子序列、定位反事实目标，并优化修改时间序列来平衡预测置信度、邻近性和稀疏性这三个目标。

Result: 在UEA档案中的7个MTS数据集上评估，CONFETTI在优化目标上始终优于最先进的反事实解释方法，在文献中的其他6个指标上也表现更好，实现了≥10%的更高置信度，同时在≥40%的情况下改善了稀疏性。

Conclusion: CONFETTI通过多目标优化方法提供了具有最小变化的高质量反事实解释，显著提高了多元时间序列分析的可解释性和决策支持能力。

Abstract: Recent advances in deep learning have improved multivariate time series (MTS) classification and regression by capturing complex patterns, but their lack of transparency hinders decision-making. Explainable AI (XAI) methods offer partial insights, yet often fall short of conveying the full decision space. Counterfactual Explanations (CE) provide a promising alternative, but current approaches typically prioritize either accuracy, proximity or sparsity -- rarely all -- limiting their practical value. To address this, we propose CONFETTI, a novel multi-objective CE method for MTS. CONFETTI identifies key MTS subsequences, locates a counterfactual target, and optimally modifies the time series to balance prediction confidence, proximity and sparsity. This method provides actionable insights with minimal changes, improving interpretability, and decision support. CONFETTI is evaluated on seven MTS datasets from the UEA archive, demonstrating its effectiveness in various domains. CONFETTI consistently outperforms state-of-the-art CE methods in its optimization objectives, and in six other metrics from the literature, achieving $\geq10\%$ higher confidence while improving sparsity in $\geq40\%$.

</details>


### [482] [Incoherent Beliefs & Inconsistent Actions in Large Language Models](https://arxiv.org/abs/2511.13240)
*Arka Pal,Teo Kitanovski,Arthur Liang,Akilesh Potti,Micah Goldblum*

Main category: cs.LG

TL;DR: 本文研究发现大型语言模型在动态环境中存在信念更新不一致和行动与信念不匹配的问题，即使在高精度或良好校准的模型中也存在这些问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界任务与静态数据集存在差异，需要模型能够进行顺序交互、根据新证据连贯更新信念并做出相应决策。预测LLM在动态环境中的表现很重要，但难以从静态设置中确定。

Method: 通过实验检验LLM的两个关键能力：信念的连贯更新能力，以及行动与信念的一致性程度。具体包括直接引出后验与正确更新先验的对比、投注市场中的行动一致性测试，以及对用户质疑的自我一致性评估。

Result: 1. LLM在信念更新上存在显著不一致性，直接引出的后验与正确更新的先验之间存在高达30%的平均差异；2. LLM的行动经常与其持有的信念不一致，在投注市场中甚至不按内在信念方向下注；3. 模型对用户质疑的回应存在中等程度的自我不一致性；4. 这些问题即使在获得高精度或良好校准的强模型中依然存在。

Conclusion: 研究结果突显了在复杂现实世界环境中预测LLM行为的困难，表明即使表现良好的模型在动态交互任务中也可能存在信念和行动的不一致问题。

Abstract: Real-world tasks and environments exhibit differences from the static datasets that large language models (LLMs) are typically evaluated on. Such tasks can involve sequential interaction, requiring coherent updating of beliefs in light of new evidence, and making appropriate decisions based on those beliefs. Predicting how LLMs will perform in such dynamic environments is important, but can be tricky to determine from measurements in static settings. In this work, we examine two critical components of LLM performance: the ability of LLMs to coherently update their beliefs, and the extent to which the actions they take are consistent with those beliefs. First, we find that LLMs are largely inconsistent in how they update their beliefs; models can exhibit up to a 30% average difference between the directly elicited posterior, and the correct update of their prior. Second, we find that LLMs also often take actions which are inconsistent with the beliefs they hold. On a betting market, for example, LLMs often do not even bet in the same direction as their internally held beliefs over the underlying outcomes. We also find they have moderate self-inconsistency in how they respond to challenges by users to given answers. Finally, we show that the above properties hold even for strong models that obtain high accuracy or that are well-calibrated on the tasks at hand. Our results highlight the difficulties of predicting LLM behavior in complex real-world settings.

</details>


### [483] [Uncovering and Mitigating Transient Blindness in Multimodal Model Editing](https://arxiv.org/abs/2511.13243)
*Xiaoqi Han,Ru Li,Ran Yi,Hongye Tan,Zhuomin Liang,Víctor Gutiérrez-Basulto,Jeff Z. Pan*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multimodal Model Editing (MMED) aims to correct erroneous knowledge in multimodal models. Existing evaluation methods, adapted from textual model editing, overstate success by relying on low-similarity or random inputs, obscure overfitting. We propose a comprehensive locality evaluation framework, covering three key dimensions: random-image locality, no-image locality, and consistent-image locality, operationalized through seven distinct data types, enabling a detailed and structured analysis of multimodal edits. We introduce De-VQA, a dynamic evaluation for visual question answering, uncovering a phenomenon we term transient blindness, overfitting to edit-similar text while ignoring visuals. Token analysis shows edits disproportionately affect textual tokens. We propose locality-aware adversarial losses to balance cross-modal representations. Empirical results demonstrate that our approach consistently outperforms existing baselines, reducing transient blindness and improving locality by 17% on average.

</details>


### [484] [Seek and You Shall Fold](https://arxiv.org/abs/2511.13244)
*Nadav Bojan Sellam,Meital Bojan,Paul Schanda,Alex Bronstein*

Main category: cs.LG

TL;DR: 提出了一种用于蛋白质生成模型的不可微分指导框架，通过遗传算法将连续扩散生成器与任意黑盒目标耦合，解决了实验数据难以整合到蛋白质生成模型中的挑战。


<details>
  <summary>Details</summary>
Motivation: 准确的蛋白质结构对于理解生物功能至关重要，但将实验数据纳入蛋白质生成模型仍然是一个主要挑战。大多数实验可观测值的预测器是不可微分的，这使得它们与基于梯度的条件采样不兼容，特别是在核磁共振领域，化学位移等丰富数据难以直接整合到生成建模中。

Method: 引入了一个用于蛋白质生成模型的不可微分指导框架，通过定制的遗传算法将连续扩散生成器与任何黑盒目标耦合。

Result: 在三种模式中证明了其有效性：成对距离约束、核奥弗豪泽效应约束，以及首次实现的化学位移指导。这些结果表明化学位移指导的结构生成是可行的，揭示了当前预测器的关键弱点，并展示了一种整合多样化实验信号的通用策略。

Conclusion: 这项工作指向了超越可微分性限制的自动化、数据条件化的蛋白质建模方向。

Abstract: Accurate protein structures are essential for understanding biological function, yet incorporating experimental data into protein generative models remains a major challenge. Most predictors of experimental observables are non-differentiable, making them incompatible with gradient-based conditional sampling. This is especially limiting in nuclear magnetic resonance, where rich data such as chemical shifts are hard to directly integrate into generative modeling. We introduce a framework for non-differentiable guidance of protein generative models, coupling a continuous diffusion-based generator with any black-box objective via a tailored genetic algorithm. We demonstrate its effectiveness across three modalities: pairwise distance constraints, nuclear Overhauser effect restraints, and for the first time chemical shifts. These results establish chemical shift guided structure generation as feasible, expose key weaknesses in current predictors, and showcase a general strategy for incorporating diverse experimental signals. Our work points toward automated, data-conditioned protein modeling beyond the limits of differentiability.

</details>


### [485] [Edge-aware baselines for ogbn-proteins in PyTorch Geometric: species-wise normalization, post-hoc calibration, and cost-accuracy trade-offs](https://arxiv.org/abs/2511.13250)
*Aleksandar Stanković,Dejan Lisica*

Main category: cs.LG

TL;DR: 本文为ogbn-proteins数据集提供了可复现的边缘感知基线方法，研究了边缘特征聚合和消息传递中的关键系统选择，发现基于sum的边缘到节点特征聚合效果最佳，并比较了不同归一化方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为ogbn-proteins数据集建立可复现的基准方法，研究边缘特征如何聚合到节点输入以及如何在消息传递中使用边缘，为实践提供指导。

Method: 使用PyTorch Geometric实现GraphSAGE模型，比较sum、mean、max三种边缘特征聚合方式，以及LayerNorm、BatchNorm和Conditional LayerNorm三种归一化方法，并进行后处理优化。

Result: sum聚合方式优于mean和max；BatchNorm获得最佳AUC，Conditional LayerNorm在AUC前沿匹配且具有更好的阈值F1；后处理技术显著提升micro-F1和校准误差。

Conclusion: 提供了标准化的ogbn-proteins基线方法，sum边缘特征聚合和BatchNorm是最佳实践选择，后处理技术可进一步提升性能而几乎不影响AUC。

Abstract: We present reproducible, edge-aware baselines for ogbn-proteins in PyTorch Geometric (PyG). We study two system choices that dominate practice: (i) how 8-dimensional edge evidence is aggregated into node inputs, and (ii) how edges are used inside message passing. Our strongest baseline is GraphSAGE with sum-based edge-to-node features. We compare LayerNorm (LN), BatchNorm (BN), and a species-aware Conditional LayerNorm (CLN), and report compute cost (time, VRAM, parameters) together with accuracy (ROC-AUC) and decision quality. In our primary experimental setup (hidden size 512, 3 layers, 3 seeds), sum consistently beats mean and max; BN attains the best AUC, while CLN matches the AUC frontier with better thresholded F1. Finally, post-hoc per-label temperature scaling plus per-label thresholds substantially improves micro-F1 and expected calibration error (ECE) with negligible AUC change, and light label-correlation smoothing yields small additional gains. We release standardized artifacts and scripts used for all of the runs presented in the paper.

</details>


### [486] [Explainable RL Policies by Distilling to Locally-Specialized Linear Policies with Voronoi State Partitioning](https://arxiv.org/abs/2511.13322)
*Senne Deproost,Dennis Steckelmacher,Ann Nowé*

Main category: cs.LG

TL;DR: 提出了一种新的模型无关方法，通过Voronoi分区将状态空间划分为区域，在每个区域中使用简化的线性模型来替代复杂的深度强化学习控制器，实现可解释性并保持性能。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习控制器缺乏透明度，难以满足监管要求和建立信任，需要将学习到的行为转移到人类可读的模型中。

Method: 使用Voronoi分区将状态空间划分为区域，在每个区域内使用线性模型来近似原始控制器的行为，实现局部专业化。

Result: 在网格世界环境和经典控制任务中评估，蒸馏得到的局部专业化线性模型产生可解释的策略，性能与原黑盒策略相当或略有提升。

Conclusion: 提出的方法能够有效将复杂控制器蒸馏为可解释的局部线性模型，在保持性能的同时提高透明度。

Abstract: Deep Reinforcement Learning is one of the state-of-the-art methods for producing near-optimal system controllers. However, deep RL algorithms train a deep neural network, that lacks transparency, which poses challenges when the controller has to meet regulations, or foster trust. To alleviate this, one could transfer the learned behaviour into a model that is human-readable by design using knowledge distilla- tion. Often this is done with a single model which mimics the original model on average but could struggle in more dynamic situations. A key challenge is that this simpler model should have the right balance be- tween flexibility and complexity or right balance between balance bias and accuracy. We propose a new model-agnostic method to divide the state space into regions where a simplified, human-understandable model can operate in. In this paper, we use Voronoi partitioning to find regions where linear models can achieve similar performance to the original con- troller. We evaluate our approach on a gridworld environment and a classic control task. We observe that our proposed distillation to locally- specialized linear models produces policies that are explainable and show that the distillation matches or even slightly outperforms the black-box policy they are distilled from.

</details>


### [487] [Tab-PET: Graph-Based Positional Encodings for Tabular Transformers](https://arxiv.org/abs/2511.13338)
*Yunze Leng,Rohan Ghosh,Mehul Motani*

Main category: cs.LG

TL;DR: 本文研究发现位置编码（PEs）可以提升表格数据上Transformer模型的泛化性能，通过降低特征的有效秩来简化任务维度，并提出了Tab-PET框架来估计和注入基于图的位置编码。


<details>
  <summary>Details</summary>
Motivation: 表格数据缺乏内在位置结构，阻碍了自注意力机制的有效性。现有的表格Transformer模型通常不使用位置编码，因为没有先验的结构信息可用。本文旨在探索结构线索（特别是位置编码）如何改善表格Transformer的泛化性能。

Method: 提出了Tab-PET框架，通过图结构估计和注入位置编码。探索了两种图估计范式：基于关联的图和基于因果关系的图，从图拓扑中推导位置编码。

Result: 在50个分类和回归数据集上的实验表明，图推导的位置编码显著提升了3T模型的性能。基于关联的图比因果关系驱动的图产生更稳定和显著的性能提升。

Conclusion: 位置编码在表格Transformer中扮演了意想不到的角色，可以通过降低特征的有效秩来改善泛化性能，为表格数据建模提供了新的视角。

Abstract: Supervised learning with tabular data presents unique challenges, including low data sizes, the absence of structural cues, and heterogeneous features spanning both categorical and continuous domains. Unlike vision and language tasks, where models can exploit inductive biases in the data, tabular data lacks inherent positional structure, hindering the effectiveness of self-attention mechanisms. While recent transformer-based models like TabTransformer, SAINT, and FT-Transformer (which we refer to as 3T) have shown promise on tabular data, they typically operate without leveraging structural cues such as positional encodings (PEs), as no prior structural information is usually available. In this work, we find both theoretically and empirically that structural cues, specifically PEs can be a useful tool to improve generalization performance for tabular transformers. We find that PEs impart the ability to reduce the effective rank (a form of intrinsic dimensionality) of the features, effectively simplifying the task by reducing the dimensionality of the problem, yielding improved generalization. To that end, we propose Tab-PET (PEs for Tabular Transformers), a graph-based framework for estimating and inculcating PEs into embeddings. Inspired by approaches that derive PEs from graph topology, we explore two paradigms for graph estimation: association-based and causality-based. We empirically demonstrate that graph-derived PEs significantly improve performance across 50 classification and regression datasets for 3T. Notably, association-based graphs consistently yield more stable and pronounced gains compared to causality-driven ones. Our work highlights an unexpected role of PEs in tabular transformers, revealing how they can be harnessed to improve generalization.

</details>


### [488] [Statistically Accurate and Robust Generative Prediction of Rock Discontinuities with A Tabular Foundation Model](https://arxiv.org/abs/2511.13339)
*Han Meng,Gang Mei,Hong Tian,Nengxiong Xu,Jianbing Peng*

Main category: cs.LG

TL;DR: 提出了一种利用表格基础模型进行岩石不连续面统计准确生成预测的简单而稳健方法，该方法在小数据条件下能有效捕捉复杂分布模式。


<details>
  <summary>Details</summary>
Motivation: 岩石不连续面对岩体力学行为和稳定性至关重要，但其内部分布通常不可观测，只能通过表面暴露的不连续面进行生成预测。现有方法要么无法捕捉复杂分布模式，要么在数据稀疏条件下缺乏稳健性。

Method: 利用专门为小数据设计的表格基础模型，发挥其强大的样本学习能力，在有限的测量不连续面中有效捕捉潜在的复杂分布模式。

Result: 在十个具有不同规模和分布模式的数据集上的对比实验表明，该方法在准确性和稳健性方面优于传统统计模型和深度生成方法。

Conclusion: 这项工作推进了岩体结构的定量表征，支持更安全、更可靠的数据驱动岩土工程设计。

Abstract: Rock discontinuities critically govern the mechanical behavior and stability of rock masses. Their internal distributions remain largely unobservable and are typically inferred from surface-exposed discontinuities using generative prediction approaches. However, surface-exposed observations are inherently sparse, and existing generative prediction approaches either fail to capture the underlying complex distribution patterns or lack robustness under data-sparse conditions. Here, we proposed a simple yet robust approach for statistically accurate generative prediction of rock discontinuities by utilizing a tabular foundation model. By leveraging the powerful sample learning capability of the foundation model specifically designed for small data, our approach can effectively capture the underlying complex distribution patterns within limited measured discontinuities. Comparative experiments on ten datasets with diverse scales and distribution patterns of discontinuities demonstrate superior accuracy and robustness over conventional statistical models and deep generative approaches. This work advances quantitative characterization of rock mass structures, supporting safer and more reliable data-driven geotechnical design.

</details>


### [489] [Dual-LoRA and Quality-Enhanced Pseudo Replay for Multimodal Continual Food Learning](https://arxiv.org/abs/2511.13351)
*Xinlan Wu,Bin Zhu,Feng Han,Pengkun Jiao,Jingjing Chen*

Main category: cs.LG

TL;DR: 提出了一种新颖的多模态食品学习持续学习框架，通过双LoRA架构和质量增强伪回放解决现有大型多模态模型在食品分析中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有的食品分析大型多模态模型在学习新任务时会出现灾难性遗忘，需要昂贵的从头重新训练，这限制了模型在实际应用中的适应性。

Method: 采用双LoRA架构：专门LoRA学习任务特定知识并保持与先前任务子空间的正交约束，协作LoRA通过伪回放整合跨任务共享知识。质量增强伪回放策略利用自一致性和语义相似性减少生成样本中的幻觉。

Result: 在综合Uni-Food数据集上的实验显示，该方法在缓解遗忘方面表现出优越性能，是首个针对复杂食品任务的有效持续学习方法。

Conclusion: 该框架成功解决了多模态食品学习中的灾难性遗忘问题，为个性化营养和慢性病预防等健康相关任务提供了更实用的解决方案。

Abstract: Food analysis has become increasingly critical for health-related tasks such as personalized nutrition and chronic disease prevention. However, existing large multimodal models (LMMs) in food analysis suffer from catastrophic forgetting when learning new tasks, requiring costly retraining from scratch. To address this, we propose a novel continual learning framework for multimodal food learning, integrating a Dual-LoRA architecture with Quality-Enhanced Pseudo Replay. We introduce two complementary low-rank adapters for each task: a specialized LoRA that learns task-specific knowledge with orthogonal constraints to previous tasks' subspaces, and a cooperative LoRA that consolidates shared knowledge across tasks via pseudo replay. To improve the reliability of replay data, our Quality-Enhanced Pseudo Replay strategy leverages self-consistency and semantic similarity to reduce hallucinations in generated samples. Experiments on the comprehensive Uni-Food dataset show superior performance in mitigating forgetting, representing the first effective continual learning approach for complex food tasks.

</details>


### [490] [A Novel Hierarchical Integration Method for Efficient Model Merging in Medical LLMs](https://arxiv.org/abs/2511.13373)
*Prakrit Timilsina,Anuj Nepal,Rajan Kadel,Robin Doss*

Main category: cs.LG

TL;DR: 本文系统评估了六种参数空间合并技术应用于两个基于Mistral-7B的医疗LLM，提出了一种结合最优传输对齐和余弦相似度加权插值的新方法，发现对于架构兼容的模型，简单平均方法在计算效率和性能上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决分布式医疗中LLM面临的挑战：整合跨机构专业知识同时保护隐私、降低计算开销、防止模型更新时的灾难性遗忘。

Method: 评估六种参数合并技术（任务算术、线性平均、DARE-TIES、DELLA、Breadcrumbs和提出的分层方法），新方法结合选择性最优传输对齐注意力层和余弦相似度加权插值。

Result: 架构兼容模型从简单平均方法中获益显著，任务算术在MedQA上达到45.80%准确率，优于复杂的剪枝方法。

Conclusion: 对于架构兼容模型，简单平均提供了稳健且计算高效的知识整合基线，为可扩展医疗AI系统提供了实用路径。

Abstract: Large Language Models (LLMs) face significant challenges in distributed healthcare, including consolidating specialized domain knowledge across institutions while maintaining privacy, reducing computational overhead, and preventing catastrophic forgetting during model updates.This paper presents a systematic evaluation of six parameter-space merging techniques applied to two architecturally compatible medical LLMs derived from the Mistral-7B base model. We introduce a novel hierarchical method that combines selective Optimal Transport (OT) alignment for attention layers with cosine similarity-weighted interpolation, designed to address permutation variance while minimizing computational overhead for edge deployment scenarios. Our study evaluates Task Arithmetic, Linear Averaging, DARE-TIES, DELLA, Breadcrumbs, and our Hierarchical approach across five medical benchmarks. Results demonstrate that architecturally compatible models benefit significantly from simple averaging methods, with Task Arithmetic achieving 45.80% accuracy on MedQA, outperforming complex pruning-based approaches. These findings offer critical insights for the deployment of distributed medical AI in resource-constrained IoT environments, where computational efficiency and model compatibility are paramount. Our work establishes that for architecturally compatible models, simple averaging provides a robust and computationally efficient baseline for knowledge consolidation, offering a pragmatic path forward for scalable medical AI systems.

</details>


### [491] [Finding Kissing Numbers with Game-theoretic Reinforcement Learning](https://arxiv.org/abs/2511.13391)
*Chengdong Ma,Théo Tao Zhaowei,Pengyu Li,Minghao Liu,Haojun Chen,Zihao Mao,Yuan Cheng,Yuan Qi,Yaodong Yang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为PackingStar的AI系统，通过将亲吻数问题建模为双玩家矩阵完成游戏，使用博弈论强化学习探索高维空间，在25-31维度上超越了所有已知记录，并发现了6000多个新结构。


<details>
  <summary>Details</summary>
Motivation: 亲吻数问题自1694年牛顿研究以来一直是基础性挑战，代表了希尔伯特第18问题的局部版本。高维几何的不规则性和指数级增长的组合复杂性限制了现有方法的可扩展性。

Method: 将亲吻数问题建模为双玩家矩阵完成游戏：一个玩家填充矩阵条目（表示球心向量对余弦），另一个玩家修正次优条目，共同最大化矩阵大小（对应亲吻数）。使用博弈论强化学习系统PackingStar高效探索高维空间。

Result: PackingStar重现了先前配置，在25-31维度上超越了所有人类已知记录，其中25维配置几何对应Leech格并暗示可能的最优性。在13维度上首次突破1971年以来的有理结构，在14维和其他维度发现了6000多个新结构。

Conclusion: 这些结果展示了AI探索超越人类直觉的高维空间的能力，为亲吻数问题和更广泛的几何问题开辟了新途径。

Abstract: Since Isaac Newton first studied the Kissing Number Problem in 1694, determining the maximal number of non-overlapping spheres around a central sphere has remained a fundamental challenge. This problem represents the local analogue of Hilbert's 18th problem on sphere packing, bridging geometry, number theory, and information theory. Although significant progress has been made through lattices and codes, the irregularities of high-dimensional geometry and exponentially growing combinatorial complexity beyond 8 dimensions, which exceeds the complexity of Go game, limit the scalability of existing methods. Here we model this problem as a two-player matrix completion game and train the game-theoretic reinforcement learning system, PackingStar, to efficiently explore high-dimensional spaces. The matrix entries represent pairwise cosines of sphere center vectors; one player fills entries while another corrects suboptimal ones, jointly maximizing the matrix size, corresponding to the kissing number. This cooperative dynamics substantially improves sample quality, making the extremely large spaces tractable. PackingStar reproduces previous configurations and surpasses all human-known records from dimensions 25 to 31, with the configuration in 25 dimensions geometrically corresponding to the Leech lattice and suggesting possible optimality. It achieves the first breakthrough beyond rational structures from 1971 in 13 dimensions and discovers over 6000 new structures in 14 and other dimensions. These results demonstrate AI's power to explore high-dimensional spaces beyond human intuition and open new pathways for the Kissing Number Problem and broader geometry problems.

</details>


### [492] [Fast and Robust Simulation-Based Inference With Optimization Monte Carlo](https://arxiv.org/abs/2511.13394)
*Vasilis Gkolemis,Christos Diou,Michael Gutmann*

Main category: cs.LG

TL;DR: 提出了一种针对可微分模拟器的贝叶斯参数推断新方法，通过将随机模拟转化为确定性优化问题，利用梯度方法高效导航后验高密度区域，显著减少运行时间。


<details>
  <summary>Details</summary>
Motivation: 复杂随机模拟器的贝叶斯参数推断面临似然函数难以处理的问题，现有基于模拟的推断方法需要大量模拟，在高维参数空间或部分无信息输出问题中成本高昂。

Method: 基于优化蒙特卡洛框架，将随机模拟重新表述为确定性优化问题，应用基于梯度的方法高效导航后验高密度区域，避免在低概率区域浪费模拟，并使用JAX实现关键组件的向量化。

Result: 在高维参数空间、无信息输出、多观测和多峰后验等广泛实验中，该方法始终匹配并经常超越最先进方法的准确性，同时显著减少运行时间。

Conclusion: 该方法为可微分模拟器提供了一种准确且高效的贝叶斯参数推断解决方案，在保持精度的同时大幅提升计算效率。

Abstract: Bayesian parameter inference for complex stochastic simulators is challenging due to intractable likelihood functions. Existing simulation-based inference methods often require large number of simulations and become costly to use in high-dimensional parameter spaces or in problems with partially uninformative outputs. We propose a new method for differentiable simulators that delivers accurate posterior inference with substantially reduced runtimes. Building on the Optimization Monte Carlo framework, our approach reformulates stochastic simulation as deterministic optimization problems. Gradient-based methods are then applied to efficiently navigate toward high-density posterior regions and avoid wasteful simulations in low-probability areas. A JAX-based implementation further enhances the performance through vectorization of key method components. Extensive experiments, including high-dimensional parameter spaces, uninformative outputs, multiple observations and multimodal posteriors show that our method consistently matches, and often exceeds, the accuracy of state-of-the-art approaches, while reducing the runtime by a substantial margin.

</details>


### [493] [MMWSTM-ADRAN+: A Novel Hybrid Deep Learning Architecture for Enhanced Climate Time Series Forecasting and Extreme Event Prediction](https://arxiv.org/abs/2511.13419)
*Shaheen Mohammed Saleh Ahmed,Hakan Hakan Guneyli*

Main category: cs.LG

TL;DR: 提出MMWSTM-ADRAN+双流深度学习架构，结合天气状态转换模型和异常注意力机制，用于极端气温事件预测。


<details>
  <summary>Details</summary>
Motivation: 准确预测极端气温事件在气候风险管理中具有根本性挑战，需要改进现有预测方法。

Method: 使用双流架构：MMWSTM流结合双向LSTM和可学习马尔可夫状态转移矩阵捕获天气状态变化；ADRAN流集成双向GRU、多头自注意力和异常放大层增强对低概率信号的敏感性；通过注意力融合门自适应确定各流贡献。

Result: 模型采用定制化的ExtremeWeatherLoss函数对温度分布上下5%的误差进行加权，并通过时间序列数据增强将训练数据有效扩充四倍。

Conclusion: 该架构通过耦合天气状态动态模型和异常聚焦注意力机制，为极端气温预测提供了有效的深度学习解决方案。

Abstract: Accurate short-range prediction of extreme air temperature events remains a fundamental challenge in operational climate-risk management. We present Multi-Modal Weather State Transition Model with Anomaly-Driven Recurrent Attention Network Plus (MMWSTM-ADRAN+), a dual-stream deep learning architecture that couples a regime-aware dynamics model with an anomaly-focused attention mechanism to forecast daily maximum temperature and its extremes. The first stream, MMWSTM, combines bidirectional Long Short-Term Memory (BiLSTM) units with a learnable Markov state transition matrix to capture synoptic-scale weather regime changes. The second stream, ADRAN, integrates bidirectional Gated Recurrent Units (BiGRUs), multi-head self-attention, and a novel anomaly amplification layer to enhance sensitivity to low-probability signals. A lightweight attentive fusion gate adaptively determines the contribution of each stream to the final prediction. Model optimization employs a custom ExtremeWeatherLoss function that up-weights errors on the upper 5% and lower 5% of the temperature distribution, and a time-series data augmentation suite (jittering, scaling, time/magnitude warping) that effectively quadruples the training data

</details>


### [494] [Larger Datasets Can Be Repeated More: A Theoretical Analysis of Multi-Epoch Scaling in Linear Regression](https://arxiv.org/abs/2511.13421)
*Tingkai Yan,Haodong Wen,Binghui Li,Kairong Luo,Wenguang Chen,Kaifeng Lyu*

Main category: cs.LG

TL;DR: 本文研究了在数据有限且重复训练多个epoch的情况下，大语言模型的数据缩放定律。通过线性回归的理论分析，定义了"有效重用率"E(K,N)来衡量多epoch训练与单次训练的性能等价关系，发现当K较小时E(K,N)≈K，但随着K增加会达到与问题相关的平台期。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的数据缩放定律主要研究一次性使用海量数据的情况，但在实际训练中经常需要重复使用有限数据进行多轮训练。这种数据重用对缩放定律的影响尚未得到充分研究。

Method: 使用线性回归模型，在强凸性或Zipf分布数据下，通过理论分析研究SGD训练中数据有效重用率E(K,N)的缩放行为。

Result: 当K较小时，E(K,N)≈K，每个新epoch带来线性增益；随着K增加，E(K,N)会达到与问题相关的平台期，该平台值随N增长（强凸情况下为Θ(log N)）。

Conclusion: 数据重用的边际效益取决于数据规模和数据分布，需要明确建模这两个因素来研究数据重用下的缩放定律，这对理解大语言模型训练中的数据效率具有重要意义。

Abstract: While data scaling laws of large language models (LLMs) have been widely examined in the one-pass regime with massive corpora, their form under limited data and repeated epochs remains largely unexplored. This paper presents a theoretical analysis of how a common workaround, training for multiple epochs on the same dataset, reshapes the data scaling laws in linear regression. Concretely, we ask: to match the performance of training on a dataset of size $N$ for $K$ epochs, how much larger must a dataset be if the model is trained for only one pass? We quantify this using the \textit{effective reuse rate} of the data, $E(K, N)$, which we define as the multiplicative factor by which the dataset must grow under one-pass training to achieve the same test loss as $K$-epoch training. Our analysis precisely characterizes the scaling behavior of $E(K, N)$ for SGD in linear regression under either strong convexity or Zipf-distributed data: (1) When $K$ is small, we prove that $E(K, N) \approx K$, indicating that every new epoch yields a linear gain; (2) As $K$ increases, $E(K, N)$ plateaus at a problem-dependent value that grows with $N$ ($Θ(\log N)$ for the strongly-convex case), implying that larger datasets can be repeated more times before the marginal benefit vanishes. These theoretical findings point out a neglected factor in a recent empirical study (Muennighoff et al. (2023)), which claimed that training LLMs for up to $4$ epochs results in negligible loss differences compared to using fresh data at each step, \textit{i.e.}, $E(K, N) \approx K$ for $K \le 4$ in our notation. Supported by further empirical validation with LLMs, our results reveal that the maximum $K$ value for which $E(K, N) \approx K$ in fact depends on the data size and distribution, and underscore the need to explicitly model both factors in future studies of scaling laws with data reuse.

</details>


### [495] [Discovering Operational Patterns Using Image-Based Convolutional Clustering and Composite Evaluation: A Case Study in Foundry Melting Processes](https://arxiv.org/abs/2511.13444)
*Zhipeng Ma,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.LG

TL;DR: 提出了一种基于图像卷积聚类的无监督工业时序数据分析框架，通过将时序数据转换为灰度图像表示，结合软硬聚类和复合评估指标，有效发现工业过程中的操作模式。


<details>
  <summary>Details</summary>
Motivation: 工业过程监控中的传感器时序数据缺乏标签、变化大且噪声多，传统方法难以提取有意义的模式。现有聚类方法要么依赖固定距离度量，要么是为静态数据设计的深度模型，无法有效处理动态、非结构化的工业序列。

Method: 将原始时序序列通过重叠滑动窗口转换为灰度矩阵表示，使用深度卷积自编码器进行特征提取；集成软硬聚类输出并通过两阶段策略进行细化；使用新开发的复合评分S_eva（结合归一化轮廓系数、Calinski-Harabasz和Davies-Bouldin指数）客观评估聚类性能。

Result: 在来自北欧铸造厂的3900多个熔炉操作数据上应用该方法，识别出7个可解释的操作模式，揭示了能耗、热动力学和生产持续时间的显著差异。与经典和深度聚类基线相比，该方法实现了更优的整体性能、更强的鲁棒性和领域对齐的可解释性。

Conclusion: 该框架解决了无监督时序分析中的关键挑战，如序列不规则性、模式重叠和度量不一致性，为工业系统中的数据驱动诊断和能源优化提供了通用解决方案。

Abstract: Industrial process monitoring increasingly relies on sensor-generated time-series data, yet the lack of labels, high variability, and operational noise make it difficult to extract meaningful patterns using conventional methods. Existing clustering techniques either rely on fixed distance metrics or deep models designed for static data, limiting their ability to handle dynamic, unstructured industrial sequences. Addressing this gap, this paper proposes a novel framework for unsupervised discovery of operational modes in univariate time-series data using image-based convolutional clustering with composite internal evaluation. The proposed framework improves upon existing approaches in three ways: (1) raw time-series sequences are transformed into grayscale matrix representations via overlapping sliding windows, allowing effective feature extraction using a deep convolutional autoencoder; (2) the framework integrates both soft and hard clustering outputs and refines the selection through a two-stage strategy; and (3) clustering performance is objectively evaluated by a newly developed composite score, S_eva, which combines normalized Silhouette, Calinski-Harabasz, and Davies-Bouldin indices. Applied to over 3900 furnace melting operations from a Nordic foundry, the method identifies seven explainable operational patterns, revealing significant differences in energy consumption, thermal dynamics, and production duration. Compared to classical and deep clustering baselines, the proposed approach achieves superior overall performance, greater robustness, and domain-aligned explainability. The framework addresses key challenges in unsupervised time-series analysis, such as sequence irregularity, overlapping modes, and metric inconsistency, and provides a generalizable solution for data-driven diagnostics and energy optimization in industrial systems.

</details>


### [496] [Hardware optimization on Android for inference of AI models](https://arxiv.org/abs/2511.13453)
*Iulius Gherasim,Carlos García Sánchez*

Main category: cs.LG

TL;DR: 本文研究Android系统上AI模型的最优执行配置，重点关注目标检测(YOLO系列)和图像分类(ResNet)任务，评估模型量化方案和设备加速器(GPU/NPU)的使用，旨在实现精度损失最小化和推理速度最大化的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型在移动计算中的广泛应用，优化移动用户体验需要最小延迟和高响应性。面临的挑战包括充分利用实时约束的执行策略和异构硬件架构的利用。

Method: 研究并提出了Android系统上AI模型的最优执行配置，评估了各种模型量化方案以及GPU和NPU设备加速器的使用，重点关注YOLO系列目标检测模型和ResNet图像分类模型。

Result: 通过实证研究确定了在最小精度损失和最大推理加速之间达到最佳平衡的组合配置。

Conclusion: 找到了在Android系统上部署AI模型时，模型量化与硬件加速器使用的最佳配置方案，实现了精度与性能的良好权衡。

Abstract: The pervasive integration of Artificial Intelligence models into contemporary mobile computing is notable across numerous use cases, from virtual assistants to advanced image processing. Optimizing the mobile user experience involves minimal latency and high responsiveness from deployed AI models with challenges from execution strategies that fully leverage real time constraints to the exploitation of heterogeneous hardware architecture. In this paper, we research and propose the optimal execution configurations for AI models on an Android system, focusing on two critical tasks: object detection (YOLO family) and image classification (ResNet). These configurations evaluate various model quantization schemes and the utilization of on device accelerators, specifically the GPU and NPU. Our core objective is to empirically determine the combination that achieves the best trade-off between minimal accuracy degradation and maximal inference speed-up.

</details>


### [497] [Artificial Intelligence-Enabled Spirometry for Early Detection of Right Heart Failure](https://arxiv.org/abs/2511.13457)
*Bin Liu,Qinghao Zhao,Yuxi Zhou,Zhejun Sun,Kaijie Lei,Deyun Zhang,Shijia Geng,Shenda Hong*

Main category: cs.LG

TL;DR: 提出了一种基于自监督表示学习的方法，使用肺活量图时间序列结合人口统计学数据早期检测右心衰竭，在UK Biobank数据集上表现良好，在临床高危人群中表现更佳。


<details>
  <summary>Details</summary>
Motivation: 右心衰竭具有高发病率和死亡率，肺部疾病常导致右心室负荷增加引发右心衰竭，需要从肺部疾病患者中筛查出可能发展为右心衰竭的患者。

Method: 两阶段方法：第一阶段使用变分自编码器从数据增强的无标签数据中学习肺活量图时间序列的稳健低维表示；第二阶段将该表示与人口统计学信息融合，输入CatBoost分类器进行右心衰竭预测。

Result: 在UK Biobank的26,617名个体上AUROC为0.7501；在慢性肾病74名患者测试集上AUROC为0.8194；在瓣膜性心脏病64名患者测试集上AUROC为0.8413。

Conclusion: 该自监督表示学习方法结合肺活量图时间序列和人口统计学数据，在临床实践中具有早期检测右心衰竭的潜力。

Abstract: Right heart failure (RHF) is a disease characterized by abnormalities in the structure or function of the right ventricle (RV), which is associated with high morbidity and mortality. Lung disease often causes increased right ventricular load, leading to RHF. Therefore, it is very important to screen out patients with cor pulmonale who develop RHF from people with underlying lung diseases. In this work, we propose a self-supervised representation learning method to early detecting RHF from patients with cor pulmonale, which uses spirogram time series to predict patients with RHF at an early stage. The proposed model is divided into two stages. The first stage is the self-supervised representation learning-based spirogram embedding (SLSE) network training process, where the encoder of the Variational autoencoder (VAE-encoder) learns a robust low-dimensional representation of the spirogram time series from the data-augmented unlabeled data. Second, this low-dimensional representation is fused with demographic information and fed into a CatBoost classifier for the downstream RHF prediction task. Trained and tested on a carefully selected subset of 26,617 individuals from the UK Biobank, our model achieved an AUROC of 0.7501 in detecting RHF, demonstrating strong population-level distinction ability. We further evaluated the model on high-risk clinical subgroups, achieving AUROC values of 0.8194 on a test set of 74 patients with chronic kidney disease (CKD) and 0.8413 on a set of 64 patients with valvular heart disease (VHD). These results highlight the model's potential utility in predicting RHF among clinically elevated-risk populations. In conclusion, this study presents a self-supervised representation learning approach combining spirogram time series and demographic data, demonstrating promising potential for early RHF detection in clinical practice.

</details>


### [498] [AdamX: An Adam improvement algorithm based on a novel exponential decay mechanism for the second-order moment estimate](https://arxiv.org/abs/2511.13465)
*Meng Zhu,Quan Xiao,Weidong Min*

Main category: cs.LG

TL;DR: 提出了AdamX优化算法，通过新型二阶矩估计指数衰减率，在训练后期减弱学习步长修正强度并退化为SGD，提升稳定期训练稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: Adam优化器在大语言模型时代仍是主流，但相比SGD更容易收敛到非平坦最小值，需要解决这一问题。

Method: 提出AdamX算法，核心创新是新型二阶矩估计指数衰减率，随着训练进行逐渐减弱学习步长修正强度，在稳定训练期退化为SGD。

Result: 实验表明新型二阶矩估计指数衰减率优于现有方法，AdamX在性能上稳定优于Adam及其变体。

Conclusion: AdamX通过改进二阶矩估计机制，有效提升了训练稳定性和泛化能力，在大规模模型优化中具有优势。

Abstract: Since the 21st century, artificial intelligence has been leading a new round of industrial revolution. Under the training framework, the optimization algorithm aims to stably converge high-dimensional optimization to local and even global minima. Entering the era of large language models, although the scale of model parameters and data has increased, Adam remains the mainstream optimization algorithm. However, compared with stochastic gradient descent (SGD) based optimization algorithms, Adam is more likely to converge to non-flat minima. To address this issue, the AdamX algorithm is proposed. Its core innovation lies in the proposition of a novel type of second-order moment estimation exponential decay rate, which gradually weakens the learning step correction strength as training progresses, and degrades to SGD in the stable training period, thereby improving the stability of training in the stable period and possibly enhancing generalization ability. Experimental results show that our second-order moment estimation exponential decay rate is better than the current second-order moment estimation exponential decay rate, and AdamX can stably outperform Adam and its variants in terms of performance. Our code is open-sourced at https://github.com/mengzhu0308/AdamX.

</details>


### [499] [Quantum Machine Learning via Contrastive Training](https://arxiv.org/abs/2511.13497)
*Liudmila A. Zhukas,Vivian Ni Zhang,Qiang Miao,Qingfeng Wang,Marko Cetina,Jungsang Kim,Lawrence Carin,Christopher Monroe*

Main category: cs.LG

TL;DR: 本文提出了一种量子自监督预训练方法，通过在可编程离子阱量子计算机上编码图像为量子态并进行对比预训练，提高了量子机器学习模型在有限标注数据下的性能。


<details>
  <summary>Details</summary>
Motivation: 随着量子技术和经典机器学习的发展，量子机器学习面临标注数据稀缺的挑战，特别是在模型规模和复杂性增加时。

Method: 在可编程离子阱量子计算机上实现自监督预训练，将图像编码为量子态，通过对比学习从未标注样本中学习不变性，所有训练和分类阶段都在硬件上执行。

Result: 预训练得到的表示经过微调后，在图像分类任务中比随机初始化模型具有更高的平均测试准确率和更低的运行间变异性，特别是在标注训练数据有限的情况下表现尤为显著。

Conclusion: 这项工作为量子表示学习提供了一种标签高效的途径，对量子原生数据集具有直接相关性，并为处理更大规模经典输入提供了清晰路径。

Abstract: Quantum machine learning (QML) has attracted growing interest with the rapid parallel advances in large-scale classical machine learning and quantum technologies. Similar to classical machine learning, QML models also face challenges arising from the scarcity of labeled data, particularly as their scale and complexity increase. Here, we introduce self-supervised pretraining of quantum representations that reduces reliance on labeled data by learning invariances from unlabeled examples. We implement this paradigm on a programmable trapped-ion quantum computer, encoding images as quantum states. In situ contrastive pretraining on hardware yields a representation that, when fine-tuned, classifies image families with higher mean test accuracy and lower run-to-run variability than models trained from random initialization. Performance improvement is especially significant in regimes with limited labeled training data. We show that the learned invariances generalize beyond the pretraining image samples. Unlike prior work, our pipeline derives similarity from measured quantum overlaps and executes all training and classification stages on hardware. These results establish a label-efficient route to quantum representation learning, with direct relevance to quantum-native datasets and a clear path to larger classical inputs.

</details>


### [500] [Mitigating Spurious Correlations in Patch-wise Tumor Classification on High-Resolution Multimodal Images](https://arxiv.org/abs/2511.13527)
*Ihab Asaad,Maha Shadaydeh,Joachim Denzler*

Main category: cs.LG

TL;DR: 该论文研究高分辨率多模态非线性显微镜图像中的肿瘤检测问题，采用基于patch的二元分类方法。研究发现该方法会引入虚假相关性（肿瘤patch通常包含较大组织区域，而非肿瘤patch多为背景），并提出使用GERNE去偏策略来提高最差组准确率。


<details>
  <summary>Details</summary>
Motivation: 基于patch的多标签分类在高分辨率图像分析中比像素级分割更高效，能显著降低标注成本、简化训练过程，并允许灵活的patch大小调整。但该简化方法会引入patch组成与标签之间的虚假相关性，影响模型性能。

Method: 采用patch-wise二元分类方法检测肿瘤，识别出肿瘤patch与非肿瘤patch在组织区域大小上的虚假相关性。使用GERNE去偏策略来最大化最差组准确率，缓解虚假相关性带来的偏差。

Result: 与ERM相比，GERNE去偏策略将最差组准确率提高了约7%（针对两种不同的虚假特征二值化阈值）。该方法显著提升了在关键少数情况下的模型性能，如小组织区域的肿瘤patch和大组织区域的非肿瘤patch。

Conclusion: 研究表明在基于patch的分类问题中，虚假相关性感知学习至关重要。GERNE去偏策略能有效缓解虚假相关性带来的偏差，提高模型在关键少数情况下的性能表现。

Abstract: Patch-wise multi-label classification provides an efficient alternative to full pixel-wise segmentation on high-resolution images, particularly when the objective is to determine the presence or absence of target objects within a patch rather than their precise spatial extent. This formulation substantially reduces annotation cost, simplifies training, and allows flexible patch sizing aligned with the desired level of decision granularity. In this work, we focus on a special case, patch-wise binary classification, applied to the detection of a single class of interest (tumor) on high-resolution multimodal nonlinear microscopy images. We show that, although this simplified formulation enables efficient model development, it can introduce spurious correlations between patch composition and labels: tumor patches tend to contain larger tissue regions, whereas non-tumor patches often consist mostly of background with small tissue areas. We further quantify the bias in model predictions caused by this spurious correlation, and propose to use a debiasing strategy to mitigate its effect. Specifically, we apply GERNE, a debiasing method that can be adapted to maximize worst-group accuracy (WGA). Our results show an improvement in WGA by approximately 7% compared to ERM for two different thresholds used to binarize the spurious feature. This enhancement boosts model performance on critical minority cases, such as tumor patches with small tissues and non-tumor patches with large tissues, and underscores the importance of spurious correlation-aware learning in patch-wise classification problems.

</details>


### [501] [Graph Out-of-Distribution Detection via Test-Time Calibration with Dual Dynamic Dictionaries](https://arxiv.org/abs/2511.13541)
*Yue Hou,Ruomei Liu,Yingke Su,Junran Wu,Ke Xu*

Main category: cs.LG

TL;DR: 提出了一种新的测试时图OOD检测方法BaCa，通过双动态更新字典校准OOD分数，无需微调预训练模型，在真实数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决图OOD检测中缺乏真实OOD样本训练数据的问题，现有方法仅优化ID数据特征，难以准确表示分布边界，且图数据的潜在多因素结构未被充分探索。

Method: BaCa方法估计图论并应用混合策略生成边界感知判别拓扑，构建双动态字典通过优先级队列和注意力机制自适应捕获潜在ID和OOD表示，用于边界感知OOD分数校准。

Result: 在真实世界数据集上的广泛实验表明，BaCa在OOD检测方面显著优于现有最先进方法。

Conclusion: BaCa方法通过边界感知的OOD分数校准，有效解决了图OOD检测中的关键挑战，无需辅助数据集或模型微调即可实现优异的检测性能。

Abstract: A key challenge in graph out-of-distribution (OOD) detection lies in the absence of ground-truth OOD samples during training. Existing methods are typically optimized to capture features within the in-distribution (ID) data and calculate OOD scores, which often limits pre-trained models from representing distributional boundaries, leading to unreliable OOD detection. Moreover, the latent structure of graph data is often governed by multiple underlying factors, which remains less explored. To address these challenges, we propose a novel test-time graph OOD detection method, termed BaCa, that calibrates OOD scores using dual dynamically updated dictionaries without requiring fine-tuning the pre-trained model. Specifically, BaCa estimates graphons and applies a mix-up strategy solely with test samples to generate diverse boundary-aware discriminative topologies, eliminating the need for exposing auxiliary datasets as outliers. We construct dual dynamic dictionaries via priority queues and attention mechanisms to adaptively capture latent ID and OOD representations, which are then utilized for boundary-aware OOD score calibration. To the best of our knowledge, extensive experiments on real-world datasets show that BaCa significantly outperforms existing state-of-the-art methods in OOD detection.

</details>


### [502] [RAC-DMVC: Reliability-Aware Contrastive Deep Multi-View Clustering under Multi-Source Noise](https://arxiv.org/abs/2511.13561)
*Shihao Dong,Yue Liu,Xiaotong Zhou,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种可靠性感知的对比深度多视图聚类框架RAC-DMVC，用于处理包含缺失噪声和观测噪声的多源噪声环境下的多视图聚类问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多视图聚类常面临多源噪声（包括缺失噪声和观测噪声）的挑战，现有方法对此处理不足，需要开发更鲁棒的框架。

Method: 提出RAC-DMVC框架：1）跨视图重构处理观测噪声；2）可靠性感知噪声对比学习减少噪声表示带来的偏差；3）双注意力插补处理缺失噪声；4）自监督聚类蒸馏模块优化表示学习。

Result: 在五个基准数据集上的大量实验表明，RAC-DMVC在多个评估指标上优于现有最优方法，并在不同噪声比例下保持优异性能。

Conclusion: RAC-DMVC通过可靠性图指导的鲁棒表示学习，有效解决了多源噪声环境下的多视图聚类问题，具有优异的性能和鲁棒性。

Abstract: Multi-view clustering (MVC), which aims to separate the multi-view data into distinct clusters in an unsupervised manner, is a fundamental yet challenging task. To enhance its applicability in real-world scenarios, this paper addresses a more challenging task: MVC under multi-source noises, including missing noise and observation noise. To this end, we propose a novel framework, Reliability-Aware Contrastive Deep Multi-View Clustering (RAC-DMVC), which constructs a reliability graph to guide robust representation learning under noisy environments. Specifically, to address observation noise, we introduce a cross-view reconstruction to enhances robustness at the data level, and a reliability-aware noise contrastive learning to mitigates bias in positive and negative pairs selection caused by noisy representations. To handle missing noise, we design a dual-attention imputation to capture shared information across views while preserving view-specific features. In addition, a self-supervised cluster distillation module further refines the learned representations and improves the clustering performance. Extensive experiments on five benchmark datasets demonstrate that RAC-DMVC outperforms SOTA methods on multiple evaluation metrics and maintains excellent performance under varying ratios of noise.

</details>


### [503] [Batch Acquisition Function Evaluations and Decouple Optimizer Updates for Faster Bayesian Optimization](https://arxiv.org/abs/2511.13625)
*Kaichi Irie,Shuhei Watanabe,Masaki Onishi*

Main category: cs.LG

TL;DR: 本文提出了一种新的贝叶斯优化方法，通过协程解耦拟牛顿更新，在保持批量调用采集函数的同时解决了逆Hessian矩阵近似误差问题，显著减少了计算时间。


<details>
  <summary>Details</summary>
Motivation: 现有的BoTorch库在优化多点采集函数时，虽然通过PyTorch批处理加速了多起点优化，但由于拟牛顿方法中逆Hessian矩阵的非对角线近似误差，导致收敛速度变慢。

Method: 提出使用协程解耦拟牛顿更新，同时保持采集函数的批量调用，这样既获得了与顺序多起点优化相同的理论收敛性，又大幅减少了实际运行时间。

Result: 新方法不仅实现了与顺序多起点优化相同的理论收敛性，而且相比之前的方法显著减少了实际运行时间。

Conclusion: 通过协程解耦拟牛顿更新同时批量调用采集函数的方法，有效解决了贝叶斯优化中采集函数优化的计算瓶颈问题，在保持理论收敛性的同时大幅提升了计算效率。

Abstract: Bayesian optimization (BO) efficiently finds high-performing parameters by maximizing an acquisition function, which models the promise of parameters. A major computational bottleneck arises in acquisition function optimization, where multi-start optimization (MSO) with quasi-Newton (QN) methods is required due to the non-convexity of the acquisition function. BoTorch, a widely used BO library, currently optimizes the summed acquisition function over multiple points, leading to the speedup of MSO owing to PyTorch batching. Nevertheless, this paper empirically demonstrates the suboptimality of this approach in terms of off-diagonal approximation errors in the inverse Hessian of a QN method, slowing down its convergence. To address this problem, we propose to decouple QN updates using a coroutine while batching the acquisition function calls. Our approach not only yields the theoretically identical convergence to the sequential MSO but also drastically reduces the wall-clock time compared to the previous approaches.

</details>


### [504] [Data Value in the Age of Scaling: Understanding LLM Scaling Dynamics Under Real-Synthetic Data Mixtures](https://arxiv.org/abs/2511.13640)
*Haohui Wang,Jingyuan Qi,Jianpeng Chen,Jun Wu,Lifu Huang,Lecheng Zheng,Kevin Choi,Balaji Veeramani,Edward Bowen,Alison Hu,Tyler Cody,Dawei Zhou*

Main category: cs.LG

TL;DR: 本文分析了混合真实和合成数据对大型语言模型的影响，发现合成数据会导致分布偏差，特别是长尾知识代表性不足。作者识别了三种阶段的缩放行为，提出了适用于混合数据的泛化边界理论，并开发了高效的数据评估方法。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的发展，混合真实和合成数据集的使用日益普遍，但合成数据存在系统性分布偏差，特别是长尾知识代表性不足的问题，这给数据效用评估带来了根本性挑战。

Method: 识别了三种阶段的缩放行为特征，推导了适用于真实和合成数据混合的LLM泛化边界理论，并基于理论发现提出了可扩展到大规数据集的高效数据评估方法。

Result: 在图像分类、情感分类、指令跟随和复杂推理四个任务上的综合实验表明，该方法在数据评估方面超越了现有最先进基线，且计算成本显著降低。

Conclusion: 该研究为混合真实和合成数据集的效用评估提供了理论基础和实用工具，揭示了影响泛化性能的关键因素，并开发了高效的数据评估方法。

Abstract: The rapid progress of large language models (LLMs) is fueled by the growing reliance on datasets that blend real and synthetic data. While synthetic data offers scalability and cost-efficiency, it often introduces systematic distributional discrepancies, particularly underrepresenting long-tail knowledge due to truncation effects from data generation mechanisms like top-p sampling, temperature scaling, and finite sampling. These discrepancies pose fundamental challenges in characterizing and evaluating the utility of mixed real-synthetic datasets. In this paper, we identify a three-phase scaling behavior characterized by two breakpoints that reflect transitions in model behavior across learning head and tail knowledge. We further derive an LLM generalization bound designed for real and synthetic mixtures, revealing several key factors that govern their generalization performance. Building on our theoretical findings, we propose an effective yet efficient data valuation method that scales to large-scale datasets. Comprehensive experiments across four tasks, including image classification, sentiment classification, instruction following, and complex reasoning, demonstrate that our method surpasses state-of-the-art baselines in data valuation with significantly low computational cost.

</details>


### [505] [FuseSampleAgg: Fused Neighbor Sampling and Aggregation for Mini-batch GNNs](https://arxiv.org/abs/2511.13645)
*Aleksandar Stanković*

Main category: cs.LG

TL;DR: FuseSampleAgg是一个CUDA算子，将邻居采样和均值聚合融合为单次操作，用于一阶和二阶GraphSAGE，显著提升性能并减少内存使用。


<details>
  <summary>Details</summary>
Motivation: 现有的GraphSAGE实现需要多次内核启动和块物化，导致内存流量和开销较大，需要优化以提高效率。

Method: 通过保存索引重放来消除块物化和额外内核启动，将邻居采样和均值聚合融合到单次操作中，同时保持GraphSAGE均值语义。

Result: 在Reddit、ogbn-arxiv和ogbn-products基准测试中，步长时间加速最高达51倍，GPU内存峰值减少最高达100倍，且算子具有确定性。

Conclusion: FuseSampleAgg通过操作融合显著提升了GraphSAGE的性能和内存效率，同时保持与标准PyTorch优化器的兼容性。

Abstract: We present FuseSampleAgg, a CUDA operator that fuses neighbor sampling and mean aggregation into a single pass for one and two hop GraphSAGE. By eliminating block materialization and extra kernel launches, FuseSampleAgg reduces memory traffic and overhead while preserving GraphSAGE mean semantics via saved index replay. Across the Reddit, ogbn-arxiv, and ogbn-products benchmarks (batch size 1024, automatic mixed precision enabled), we observe step time speedups up to 51x on ogbn-products, about 4x on Reddit with fanouts 10-10 and 15-10, and about 3.3x on ogbn-arxiv at larger fanouts, with peak GPU memory reductions up to 100x, 36x, and about 3.5x, respectively. The operator is deterministic, integrates with standard PyTorch optimizers, and ships with scripts that reproduce all tables and figures from CSV logs. Code and scripts are available at https://github.com/SV25-22/FuseSampleAgg.

</details>


### [506] [Weight-sparse transformers have interpretable circuits](https://arxiv.org/abs/2511.13653)
*Leo Gao,Achyuta Rajaram,Jacob Coxon,Soham V. Govande,Bowen Baker,Dan Mossing*

Main category: cs.LG

TL;DR: 该论文提出通过训练权重稀疏的语言模型来发现人类可理解的电路结构，通过约束大部分权重为零来使每个神经元只有少量连接，从而获得可解释的电路。


<details>
  <summary>Details</summary>
Motivation: 在语言模型中找到人类可理解的电路是机械可解释性领域的核心目标，当前模型缺乏可解释性。

Method: 训练权重稀疏的模型，约束大部分权重为零，使每个神经元只有少量连接；通过剪枝技术隔离特定任务对应的电路部分。

Result: 获得的电路包含对应自然概念的神经元和残差通道，具有少量直接可解释的连接；稀疏化在能力和可解释性之间权衡，模型规模扩展能改善这一权衡。

Conclusion: 该方法产生了前所未有的可理解电路，并经过严格验证；但将稀疏模型扩展到数千万非零参数以上同时保持可解释性仍具挑战性；该方法也可用于解释现有的密集模型。

Abstract: Finding human-understandable circuits in language models is a central goal of the field of mechanistic interpretability. We train models to have more understandable circuits by constraining most of their weights to be zeros, so that each neuron only has a few connections. To recover fine-grained circuits underlying each of several hand-crafted tasks, we prune the models to isolate the part responsible for the task. These circuits often contain neurons and residual channels that correspond to natural concepts, with a small number of straightforwardly interpretable connections between them. We study how these models scale and find that making weights sparser trades off capability for interpretability, and scaling model size improves the capability-interpretability frontier. However, scaling sparse models beyond tens of millions of nonzero parameters while preserving interpretability remains a challenge. In addition to training weight-sparse models de novo, we show preliminary results suggesting our method can also be adapted to explain existing dense models. Our work produces circuits that achieve an unprecedented level of human understandability and validates them with considerable rigor.

</details>


### [507] [Tuning for Two Adversaries: Enhancing the Robustness Against Transfer and Query-Based Attacks using Hyperparameter Tuning](https://arxiv.org/abs/2511.13654)
*Pascal Zimmer,Ghassan Karame*

Main category: cs.LG

TL;DR: 本文首次系统分析了优化超参数（学习率、权重衰减、动量、批大小）对迁移攻击和查询攻击鲁棒性的影响，发现在不同攻击类型下学习率的影响呈现相反趋势，并探索了同时增强对两种攻击鲁棒性的超参数设计空间。


<details>
  <summary>Details</summary>
Motivation: 研究优化超参数如何影响模型对迁移攻击和查询攻击的鲁棒性，填补了该领域的研究空白。

Method: 通过理论分析和实验验证，在集中训练、集成学习和分布式训练等多种实际部署场景下，系统测试不同优化超参数对攻击鲁棒性的影响。

Result: 发现学习率对两种攻击的影响呈现二分现象：降低学习率可提升迁移攻击鲁棒性达64%，而增加学习率可提升查询攻击鲁棒性达28%。分布式模型通过超参数调优能最有效地同时缓解两种攻击。

Conclusion: 优化超参数设计对模型鲁棒性有显著影响，分布式训练模型通过适当的超参数调优能够实现对抗迁移攻击和查询攻击的最佳权衡效果。

Abstract: In this paper, we present the first detailed analysis of how optimization hyperparameters -- such as learning rate, weight decay, momentum, and batch size -- influence robustness against both transfer-based and query-based attacks. Supported by theory and experiments, our study spans a variety of practical deployment settings, including centralized training, ensemble learning, and distributed training. We uncover a striking dichotomy: for transfer-based attacks, decreasing the learning rate significantly enhances robustness by up to $64\%$. In contrast, for query-based attacks, increasing the learning rate consistently leads to improved robustness by up to $28\%$ across various settings and data distributions. Leveraging these findings, we explore -- for the first time -- the optimization hyperparameter design space to jointly enhance robustness against both transfer-based and query-based attacks. Our results reveal that distributed models benefit the most from hyperparameter tuning, achieving a remarkable tradeoff by simultaneously mitigating both attack types more effectively than other training setups.

</details>


### [508] [Scientific Data Compression and Super-Resolution Sampling](https://arxiv.org/abs/2511.13675)
*Minh Vu,Andrey Lokhov*

Main category: cs.LG

TL;DR: 提出了一种基于指数族学习的新型科学数据压缩和超分辨率框架，能够在压缩数据的同时保持物理量的不确定性量化，并支持压缩比与重建保真度之间的灵活权衡。


<details>
  <summary>Details</summary>
Motivation: 现代科学模拟、观测和大规模实验产生的数据量往往超过存储、处理和分析的限制，需要开发能够管理海量数据集同时保留基本物理特征的数据缩减方法，特别是在检查点和重启等需要从压缩表示中恢复数据的工作流程中。

Method: 基于近期指数族学习的进展，开发了一个科学数据压缩和超分辨率框架，该方法能够保持物理量的不确定性量化。

Result: 该方法支持压缩比与重建保真度之间的灵活权衡，能够从压缩表示中恢复数据并保证关键物理特性的保存。

Conclusion: 该框架为科学数据压缩和超分辨率提供了一种新方法，特别适用于需要数据恢复保证的科学工作流程，如检查点和重启操作。

Abstract: Modern scientific simulations, observations, and large-scale experiments generate data at volumes that often exceed the limits of storage, processing, and analysis. This challenge drives the development of data reduction methods that efficiently manage massive datasets while preserving essential physical features and quantities of interest. In many scientific workflows, it is also crucial to enable data recovery from compressed representations - a task known as super-resolution - with guarantees on the preservation of key physical characteristics. A notable example is checkpointing and restarting, which is essential for long-running simulations to recover from failures, resume after interruptions, or examine intermediate results. In this work, we introduce a novel framework for scientific data compression and super-resolution, grounded in recent advances in learning exponential families. Our method preserves and quantifies uncertainty in physical quantities of interest and supports flexible trade-offs between compression ratio and reconstruction fidelity.

</details>


### [509] [Cross-Learning from Scarce Data via Multi-Task Constrained Optimization](https://arxiv.org/abs/2511.13680)
*Leopoldo Agorio,Juan Cerviño,Miguel Calvo-Fullana,Alejandro Ribeiro,Juan Andrés Bazerque*

Main category: cs.LG

TL;DR: 本文提出了一种多任务交叉学习框架，通过联合估计多个相关任务中的确定性参数来解决数据稀缺问题，实现从数据丰富的任务向数据稀缺任务的知识迁移。


<details>
  <summary>Details</summary>
Motivation: 传统学习任务需要大量代表性数据，当数据有限时，学习模型无法泛化到未见过的案例。本文旨在克服数据稀缺问题，在参数推断对有限数据至关重要的场景中提供解决方案。

Method: 将联合估计建模为约束优化问题，约束条件控制不同模型参数之间的相似性，允许参数在不同任务间存在差异，同时结合来自多个数据源的信息。

Result: 在控制框架下提供了理论保证，并在图像分类和传染病传播等实际应用中展示了交叉学习方法的有效性，实现了更准确可靠的参数估计。

Conclusion: 交叉学习框架能够从数据丰富的任务向数据稀缺的任务进行知识迁移，为有限数据下的参数推断提供了有效的解决方案，在多个实际应用中表现出优越性能。

Abstract: A learning task, understood as the problem of fitting a parametric model from supervised data, fundamentally requires the dataset to be large enough to be representative of the underlying distribution of the source. When data is limited, the learned models fail generalize to cases not seen during training. This paper introduces a multi-task \emph{cross-learning} framework to overcome data scarcity by jointly estimating \emph{deterministic} parameters across multiple, related tasks. We formulate this joint estimation as a constrained optimization problem, where the constraints dictate the resulting similarity between the parameters of the different models, allowing the estimated parameters to differ across tasks while still combining information from multiple data sources. This framework enables knowledge transfer from tasks with abundant data to those with scarce data, leading to more accurate and reliable parameter estimates, providing a solution for scenarios where parameter inference from limited data is critical. We provide theoretical guarantees in a controlled framework with Gaussian data, and show the efficiency of our cross-learning method in applications with real data including image classification and propagation of infectious diseases.

</details>


### [510] [Efficient Calibration for Decision Making](https://arxiv.org/abs/2511.13699)
*Parikshit Gopalan,Konstantinos Stavropoulos,Kunal Talwar,Pranay Tankala*

Main category: cs.LG

TL;DR: 本文提出了一种基于结构化后处理函数族的校准决策损失度量方法CDL_K，以解决原始CDL度量的计算困难问题，并建立了其信息论和计算复杂度的理论框架。


<details>
  <summary>Details</summary>
Motivation: 原始校准决策损失(CDL)在离线设置中难以近似计算，这限制了其实际应用。为了克服这一困难，作者希望通过限制后处理函数的结构来获得可计算的校准度量。

Method: 定义了相对于结构化后处理函数族K的校准决策损失CDL_K，考虑所有适当损失但将后处理限制在结构化族K中。开发了CDL_K信息论和计算复杂度可处理性的综合理论。

Result: 证明了对于自然函数类K的CDL_K上下界，为机器学习中广泛使用的重新校准程序提供了严格的理论保证。

Conclusion: 通过引入结构化后处理函数族，成功解决了原始CDL度量的计算困难问题，为决策校准理论提供了新的定义和算法技术。

Abstract: A decision-theoretic characterization of perfect calibration is that an agent seeking to minimize a proper loss in expectation cannot improve their outcome by post-processing a perfectly calibrated predictor. Hu and Wu (FOCS'24) use this to define an approximate calibration measure called calibration decision loss ($\mathsf{CDL}$), which measures the maximal improvement achievable by any post-processing over any proper loss. Unfortunately, $\mathsf{CDL}$ turns out to be intractable to even weakly approximate in the offline setting, given black-box access to the predictions and labels.
  We suggest circumventing this by restricting attention to structured families of post-processing functions $K$. We define the calibration decision loss relative to $K$, denoted $\mathsf{CDL}_K$ where we consider all proper losses but restrict post-processings to a structured family $K$. We develop a comprehensive theory of when $\mathsf{CDL}_K$ is information-theoretically and computationally tractable, and use it to prove both upper and lower bounds for natural classes $K$. In addition to introducing new definitions and algorithmic techniques to the theory of calibration for decision making, our results give rigorous guarantees for some widely used recalibration procedures in machine learning.

</details>


### [511] [ST-ProC: A Graph-Prototypical Framework for Robust Semi-Supervised Travel Mode Identification](https://arxiv.org/abs/2511.13702)
*Luyao Niu,Nuoxian Huang*

Main category: cs.LG

TL;DR: 提出ST-ProC框架解决GPS轨迹出行模式识别中的标签稀缺问题，通过图原型多目标半监督学习，结合图正则化、原型锚定和边界感知伪标签策略，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: GPS轨迹出行模式识别因标注成本高导致标签稀缺，现有半监督学习方法存在确认偏差问题且忽略数据流形结构。

Method: ST-ProC框架结合图原型核心与基础半监督学习支持，包括图正则化、原型锚定、边界感知伪标签策略，以及对比学习和师生一致性损失。

Result: ST-ProC显著优于所有基线方法，在真实世界稀疏标签设置中比FixMatch等最先进方法性能提升21.5%。

Conclusion: ST-ProC通过有效利用数据流形和噪声抑制策略，成功解决了出行模式识别中的标签稀缺问题，为城市智能提供了有效解决方案。

Abstract: Travel mode identification (TMI) from GPS trajectories is critical for urban intelligence, but is hampered by the high cost of annotation, leading to severe label scarcity. Prevailing semi-supervised learning (SSL) methods are ill-suited for this task, as they suffer from catastrophic confirmation bias and ignore the intrinsic data manifold. We propose ST-ProC, a novel graph-prototypical multi-objective SSL framework to address these limitations. Our framework synergizes a graph-prototypical core with foundational SSL Support. The core exploits the data manifold via graph regularization, prototypical anchoring, and a novel, margin-aware pseudo-labeling strategy to actively reject noise. This core is supported and stabilized by foundational contrastive and teacher-student consistency losses, ensuring high-quality representations and robust optimization. ST-ProC outperforms all baselines by a significant margin, demonstrating its efficacy in real-world sparse-label settings, with a performance boost of 21.5% over state-of-the-art methods like FixMatch.

</details>


### [512] [Rare Genomic Subtype Discovery from RNA-seq via Autoencoder Embeddings and Stability-Aware Clustering](https://arxiv.org/abs/2511.13705)
*Alaa Mezghiche*

Main category: cs.LG

TL;DR: 该研究使用自编码器和聚类稳定性分析在RNA-seq数据中寻找罕见但可重现的基因组亚型。在泛癌分析中，聚类主要按组织来源划分，而在肾透明细胞癌(KIRC)内部分析发现了一个罕见且稳定的亚型。


<details>
  <summary>Details</summary>
Motivation: 通过无监督学习在高维RNA-seq数据中发现标准标签之外的分子亚型，特别是寻找罕见但可重现的基因组亚型。

Method: 结合自编码器表示与聚类和稳定性分析：选择高变异基因，训练前馈自编码器（128维潜空间），运行k-means聚类（k=2-10），使用稳定性分析（Jaccard指数≥0.60）和罕见性标准（<10%）来识别亚型。

Result: 泛癌分析显示聚类与组织来源高度一致（Cramer's V=0.887）。在KIRC内部发现k=5时存在一个罕见簇C0（6.85%患者），具有高稳定性（Jaccard=0.787），通过差异表达分析识别出连贯的标记基因。

Conclusion: 泛癌聚类主要受组织来源主导，而基于稳定性的单癌种分析方法能够发现罕见且可重现的KIRC亚型。

Abstract: Unsupervised learning on high-dimensional RNA-seq data can reveal molecular subtypes beyond standard labels. We combine an autoencoder-based representation with clustering and stability analysis to search for rare but reproducible genomic subtypes. On the UCI "Gene Expression Cancer RNA-Seq" dataset (801 samples, 20,531 genes; BRCA, COAD, KIRC, LUAD, PRAD), a pan-cancer analysis shows clusters aligning almost perfectly with tissue of origin (Cramer's V = 0.887), serving as a negative control. We therefore reframe the problem within KIRC (n = 146): we select the top 2,000 highly variable genes, standardize them, train a feed-forward autoencoder (128-dimensional latent space), and run k-means for k = 2-10. While global indices favor small k, scanning k with a pre-specified discovery rule (rare < 10 percent and stable with Jaccard >= 0.60 across 20 seeds after Hungarian alignment) yields a simple solution at k = 5 (silhouette = 0.129, DBI = 2.045) with a rare cluster C0 (6.85 percent of patients) that is highly stable (Jaccard = 0.787). Cluster-vs-rest differential expression (Welch's t-test, Benjamini-Hochberg FDR) identifies coherent markers. Overall, pan-cancer clustering is dominated by tissue of origin, whereas a stability-aware within-cancer approach reveals a rare, reproducible KIRC subtype.

</details>


### [513] [From Black Box to Insight: Explainable AI for Extreme Event Preparedness](https://arxiv.org/abs/2511.13712)
*Kiana Vu,İsmet Selçuk Özer,Phung Lai,Zheng Wu,Thilanka Munasinghe,Jennifer Wei*

Main category: cs.LG

TL;DR: 本文探讨可解释AI在极端事件预测中的作用，以野火预测为例，评估AI模型并使用SHAP解释方法提升模型可解释性和决策支持能力。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧了极端事件的频率和严重性，需要准确、可解释且可操作的预测。虽然AI模型在预测方面表现出潜力，但其黑盒特性限制了在实际决策中的应用。

Method: 使用野火预测作为案例研究，评估多种AI模型，并采用SHAP方法来揭示关键特征、决策路径和潜在偏见，提供增强可解释性的可视化。

Result: 分析表明XAI不仅能澄清模型推理，还能支持领域专家和响应团队的关键决策，通过情境化特征重要性和时空模式来增强AI解释的可用性。

Conclusion: 研究发现AI系统不仅需要准确性，还需要可解释性、可访问性和可信性，这对于灾害准备、风险缓解和气候韧性规划至关重要。

Abstract: As climate change accelerates the frequency and severity of extreme events such as wildfires, the need for accurate, explainable, and actionable forecasting becomes increasingly urgent. While artificial intelligence (AI) models have shown promise in predicting such events, their adoption in real-world decision-making remains limited due to their black-box nature, which limits trust, explainability, and operational readiness. This paper investigates the role of explainable AI (XAI) in bridging the gap between predictive accuracy and actionable insight for extreme event forecasting. Using wildfire prediction as a case study, we evaluate various AI models and employ SHapley Additive exPlanations (SHAP) to uncover key features, decision pathways, and potential biases in model behavior. Our analysis demonstrates how XAI not only clarifies model reasoning but also supports critical decision-making by domain experts and response teams. In addition, we provide supporting visualizations that enhance the interpretability of XAI outputs by contextualizing feature importance and temporal patterns in seasonality and geospatial characteristics. This approach enhances the usability of AI explanations for practitioners and policymakers. Our findings highlight the need for AI systems that are not only accurate but also interpretable, accessible, and trustworthy, essential for effective use in disaster preparedness, risk mitigation, and climate resilience planning.

</details>
