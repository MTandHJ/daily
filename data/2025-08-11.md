<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 98]
- [cs.IR](#cs.IR) [Total: 31]
- [cs.AI](#cs.AI) [Total: 28]
- [cs.CY](#cs.CY) [Total: 15]
- [cs.LG](#cs.LG) [Total: 49]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Boosting Adversarial Transferability via Residual Perturbation Attack](https://arxiv.org/abs/2508.05689)
*Jinjia Peng,Zeze Tao,Huibing Wang,Meng Wang,Yang Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为ResPA的新型攻击方法，通过利用残差梯度作为扰动方向，提升对抗样本的迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有迁移攻击方法忽略了扰动方向的影响，导致迁移性受限。

Method: ResPA通过指数移动平均获取参考梯度，并利用当前梯度与参考梯度的残差来捕捉全局扰动方向的变化。

Result: 实验表明，ResPA的迁移性优于现有典型迁移攻击方法，且与输入变换方法结合后可进一步提升。

Conclusion: ResPA通过优化扰动方向，显著提升了对抗样本的迁移性。

Abstract: Deep neural networks are susceptible to adversarial examples while suffering
from incorrect predictions via imperceptible perturbations. Transfer-based
attacks create adversarial examples for surrogate models and transfer these
examples to target models under black-box scenarios. Recent studies reveal that
adversarial examples in flat loss landscapes exhibit superior transferability
to alleviate overfitting on surrogate models. However, the prior arts overlook
the influence of perturbation directions, resulting in limited transferability.
In this paper, we propose a novel attack method, named Residual Perturbation
Attack (ResPA), relying on the residual gradient as the perturbation direction
to guide the adversarial examples toward the flat regions of the loss function.
Specifically, ResPA conducts an exponential moving average on the input
gradients to obtain the first moment as the reference gradient, which
encompasses the direction of historical gradients. Instead of heavily relying
on the local flatness that stems from the current gradients as the perturbation
direction, ResPA further considers the residual between the current gradient
and the reference gradient to capture the changes in the global perturbation
direction. The experimental results demonstrate the better transferability of
ResPA than the existing typical transfer-based attack methods, while the
transferability can be further improved by combining ResPA with the current
input transformation methods. The code is available at
https://github.com/ZezeTao/ResPA.

</details>


### [2] [Generalized Few-Shot Out-of-Distribution Detection](https://arxiv.org/abs/2508.05732)
*Pinxuan Li,Bing Cao,Changqing Zhang,Qinghua Hu*

Main category: cs.CV

TL;DR: 论文提出了一种广义少样本OOD检测框架（GOOD），通过引入通用知识模型（GKM）和知识动态嵌入（KDE）机制，提升模型在开放世界中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有少样本OOD检测方法因训练数据有限，泛化能力不足，导致性能不稳定。

Method: 提出GOOD框架，结合GKM和KDE机制，动态调整通用知识与模型输出的对齐。

Result: 实验证明GOOD在真实OOD基准测试中表现优异。

Conclusion: GOOD通过GS平衡和动态知识嵌入，显著提升了少样本OOD检测的泛化性能。

Abstract: Few-shot Out-of-Distribution (OOD) detection has emerged as a critical
research direction in machine learning for practical deployment. Most existing
Few-shot OOD detection methods suffer from insufficient generalization
capability for the open world. Due to the few-shot learning paradigm, the OOD
detection ability is often overfit to the limited training data itself, thus
degrading the performance on generalized data and performing inconsistently
across different scenarios. To address this challenge, we proposed a
Generalized Few-shot OOD Detection (GOOD) framework, which empowers the general
knowledge of the OOD detection model with an auxiliary General Knowledge Model
(GKM), instead of directly learning from few-shot data. We proceed to reveal
the few-shot OOD detection from a generalization perspective and theoretically
derive the Generality-Specificity balance (GS-balance) for OOD detection, which
provably reduces the upper bound of generalization error with a general
knowledge model. Accordingly, we propose a Knowledge Dynamic Embedding (KDE)
mechanism to adaptively modulate the guidance of general knowledge. KDE
dynamically aligns the output distributions of the OOD detection model to the
general knowledge model based on the Generalized Belief (G-Belief) of GKM,
thereby boosting the GS-balance. Experiments on real-world OOD benchmarks
demonstrate our superiority. Codes will be available.

</details>


### [3] [UnGuide: Learning to Forget with LoRA-Guided Diffusion Models](https://arxiv.org/abs/2508.05755)
*Agnieszka Polowczyk,Alicja Polowczyk,Dawid Malarz,Artur Kasymov,Marcin Mazur,Jacek Tabor,Przemysław Spurek*

Main category: cs.CV

TL;DR: UnGuide是一种新方法，通过动态推理机制UnGuidance，结合LoRA适配器，实现对扩散模型中特定知识的精确去除，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型的潜在滥用问题，尤其是生成有害或误导性内容，亟需有效的机器遗忘方法。

Method: UnGuide结合Classifier-Free Guidance (CFG)和LoRA适配器，通过动态调节引导尺度，实现选择性遗忘。

Result: UnGuide在概念去除任务中优于现有LoRA方法，同时保持图像保真度和模型表达能力。

Conclusion: UnGuide为扩散模型中的精确知识去除提供了一种有效解决方案。

Abstract: Recent advances in large-scale text-to-image diffusion models have heightened
concerns about their potential misuse, especially in generating harmful or
misleading content. This underscores the urgent need for effective machine
unlearning, i.e., removing specific knowledge or concepts from pretrained
models without compromising overall performance. One possible approach is
Low-Rank Adaptation (LoRA), which offers an efficient means to fine-tune models
for targeted unlearning. However, LoRA often inadvertently alters unrelated
content, leading to diminished image fidelity and realism. To address this
limitation, we introduce UnGuide -- a novel approach which incorporates
UnGuidance, a dynamic inference mechanism that leverages Classifier-Free
Guidance (CFG) to exert precise control over the unlearning process. UnGuide
modulates the guidance scale based on the stability of a few first steps of
denoising processes, enabling selective unlearning by LoRA adapter. For prompts
containing the erased concept, the LoRA module predominates and is
counterbalanced by the base model; for unrelated prompts, the base model
governs generation, preserving content fidelity. Empirical results demonstrate
that UnGuide achieves controlled concept removal and retains the expressive
power of diffusion models, outperforming existing LoRA-based methods in both
object erasure and explicit content removal tasks.

</details>


### [4] [Improving Masked Style Transfer using Blended Partial Convolution](https://arxiv.org/abs/2508.05769)
*Seyed Hadi Seyed,Ayberk Cansever,David Hart*

Main category: cs.CV

TL;DR: 本文提出了一种基于部分卷积的风格迁移网络，能够精确地将风格特征应用于图像中的特定区域，并通过内部混合技术优化区域选择的不完美。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常对整个图像进行风格迁移，而用户可能只需对特定区域应用风格。传统方法在区域选择后掩码处理会导致风格特征捕捉不准确。

Method: 采用部分卷积的风格迁移网络，结合内部混合技术，优化区域选择的准确性。

Result: 在SA-1B数据集上的实验表明，该方法在视觉和定量上均优于传统方法。

Conclusion: 提出的方法显著提升了风格迁移的精确性和视觉效果，代码已公开。

Abstract: Artistic style transfer has long been possible with the advancements of
convolution- and transformer-based neural networks. Most algorithms apply the
artistic style transfer to the whole image, but individual users may only need
to apply a style transfer to a specific region in the image. The standard
practice is to simply mask the image after the stylization. This work shows
that this approach tends to improperly capture the style features in the region
of interest. We propose a partial-convolution-based style transfer network that
accurately applies the style features exclusively to the region of interest.
Additionally, we present network-internal blending techniques that account for
imperfections in the region selection. We show that this visually and
quantitatively improves stylization using examples from the SA-1B dataset. Code
is publicly available at https://github.com/davidmhart/StyleTransferMasked.

</details>


### [5] [MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss](https://arxiv.org/abs/2508.05772)
*Can Zhao,Pengfei Guo,Dong Yang,Yucheng Tang,Yufan He,Benjamin Simon,Mason Belue,Stephanie Harmon,Baris Turkbey,Daguang Xu*

Main category: cs.CV

TL;DR: MAISI-v2是一个加速的3D医学图像合成框架，通过整合rectified flow实现快速高质量生成，并引入区域特异性对比损失增强条件一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在医学图像合成中的通用性差、推理速度慢和输入条件对齐弱的问题。

Method: 整合rectified flow加速生成，引入区域特异性对比损失增强条件一致性。

Result: MAISI-v2实现了33倍的加速和SOTA图像质量，下游分割实验验证了合成图像的数据增强效果。

Conclusion: MAISI-v2在加速和条件一致性方面表现优异，为医学图像合成提供了高效解决方案。

Abstract: Medical image synthesis is an important topic for both clinical and research
applications. Recently, diffusion models have become a leading approach in this
area. Despite their strengths, many existing methods struggle with (1) limited
generalizability that only work for specific body regions or voxel spacings,
(2) slow inference, which is a common issue for diffusion models, and (3) weak
alignment with input conditions, which is a critical issue for medical imaging.
MAISI, a previously proposed framework, addresses generalizability issues but
still suffers from slow inference and limited condition consistency. In this
work, we present MAISI-v2, the first accelerated 3D medical image synthesis
framework that integrates rectified flow to enable fast and high quality
generation. To further enhance condition fidelity, we introduce a novel
region-specific contrastive loss to enhance the sensitivity to region of
interest. Our experiments show that MAISI-v2 can achieve SOTA image quality
with $33 \times$ acceleration for latent diffusion model. We also conducted a
downstream segmentation experiment to show that the synthetic images can be
used for data augmentation. We release our code, training details, model
weights, and a GUI demo to facilitate reproducibility and promote further
development within the community.

</details>


### [6] [Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks](https://arxiv.org/abs/2508.05783)
*Mengyu Li,Guoyao Shen,Chad W. Farris,Xin Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于预训练MRI变换器的少样本部署框架，结合MAE策略和混合架构，在数据有限条件下实现高效、稳定的医学影像任务。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像中标注数据稀缺导致变换器模型实际应用受限的问题。

Method: 使用MAE预训练策略在大规模多队列脑MRI数据集上获取可迁移的潜在表示，结合轻量级线性头或混合架构（MAE-FUnet）完成分类和分割任务。

Result: 在MRI序列识别和分割任务中达到最优性能，尤其在数据有限条件下表现突出。

Conclusion: 该框架高效、稳定且可扩展，适用于低资源临床环境和广泛的神经影像应用。

Abstract: Machine learning using transformers has shown great potential in medical
imaging, but its real-world applicability remains limited due to the scarcity
of annotated data. In this study, we propose a practical framework for the
few-shot deployment of pretrained MRI transformers in diverse brain imaging
tasks. By utilizing the Masked Autoencoder (MAE) pretraining strategy on a
large-scale, multi-cohort brain MRI dataset comprising over 31 million slices,
we obtain highly transferable latent representations that generalize well
across tasks and datasets. For high-level tasks such as classification, a
frozen MAE encoder combined with a lightweight linear head achieves
state-of-the-art accuracy in MRI sequence identification with minimal
supervision. For low-level tasks such as segmentation, we propose MAE-FUnet, a
hybrid architecture that fuses multiscale CNN features with pretrained MAE
embeddings. This model consistently outperforms other strong baselines in both
skull stripping and multi-class anatomical segmentation under data-limited
conditions. With extensive quantitative and qualitative evaluations, our
framework demonstrates efficiency, stability, and scalability, suggesting its
suitability for low-resource clinical environments and broader neuroimaging
applications.

</details>


### [7] [Optimization-Free Style Transfer for 3D Gaussian Splats](https://arxiv.org/abs/2508.05813)
*Raphael Du Sablon,David Hart*

Main category: cs.CV

TL;DR: 提出了一种无需重建或优化的3D高斯泼溅风格迁移方法，通过生成图结构并插值实现快速风格化。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要重建或优化高斯泼溅，效率低且依赖额外训练。

Method: 生成高斯泼溅隐式表面的图结构，使用前馈表面风格化方法并插值回泼溅。

Result: 实现快速风格化（2分钟内），支持任意风格图像和高斯泼溅，无需额外训练。

Conclusion: 该方法高效且通用，适用于多种风格迁移场景。

Abstract: The task of style transfer for 3D Gaussian splats has been explored in many
previous works, but these require reconstructing or fine-tuning the splat while
incorporating style information or optimizing a feature extraction network on
the splat representation. We propose a reconstruction- and optimization-free
approach to stylizing 3D Gaussian splats. This is done by generating a graph
structure across the implicit surface of the splat representation. A
feed-forward, surface-based stylization method is then used and interpolated
back to the individual splats in the scene. This allows for any style image and
3D Gaussian splat to be used without any additional training or optimization.
This also allows for fast stylization of splats, achieving speeds under 2
minutes even on consumer-grade hardware. We demonstrate the quality results
this approach achieves and compare to other 3D Gaussian splat style transfer
methods. Code is publicly available at
https://github.com/davidmhart/FastSplatStyler.

</details>


### [8] [MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses](https://arxiv.org/abs/2508.05819)
*Jong-Ik Park,Carlee Joe-Wong,Gary K. Fedder*

Main category: cs.CV

TL;DR: MZEN是一种改进的NeRF框架，专为处理多缩放图像集设计，解决了工业检测中细节捕捉不足的问题。


<details>
  <summary>Details</summary>
Motivation: NeRF方法在3D重建中表现优异，但在工业检测中无法捕捉微米级细节。MZEN旨在通过多缩放图像集解决这一问题。

Method: MZEN通过引入可学习的缩放标量改进相机模型，并提出一种新的位姿策略，先解决广角图像，再通过缩放一致的裁剪匹配处理缩放图像。

Result: 在多种场景中，MZEN显著提升了PSNR、SSIM和LPIPS指标，优于现有方法。

Conclusion: MZEN扩展了NeRF在工业检测中的应用，能够在保持全局精度的同时捕捉微米级细节。

Abstract: Neural Radiance Fields (NeRF) methods excel at 3D reconstruction from
multiple 2D images, even those taken with unknown camera poses. However, they
still miss the fine-detailed structures that matter in industrial inspection,
e.g., detecting sub-micron defects on a production line or analyzing chips with
Scanning Electron Microscopy (SEM). In these scenarios, the sensor resolution
is fixed and compute budgets are tight, so the only way to expose fine
structure is to add zoom-in images; yet, this breaks the multi-view consistency
that pose-free NeRF training relies on. We propose Multi-Zoom Enhanced NeRF
(MZEN), the first NeRF framework that natively handles multi-zoom image sets.
MZEN (i) augments the pin-hole camera model with an explicit, learnable zoom
scalar that scales the focal length, and (ii) introduces a novel pose strategy:
wide-field images are solved first to establish a global metric frame, and
zoom-in images are then pose-primed to the nearest wide-field counterpart via a
zoom-consistent crop-and-match procedure before joint refinement. Across eight
forward-facing scenes$\unicode{x2013}$synthetic TCAD models, real SEM of
micro-structures, and BLEFF objects$\unicode{x2013}$MZEN consistently
outperforms pose-free baselines and even high-resolution variants, boosting
PSNR by up to $28 \%$, SSIM by $10 \%$, and reducing LPIPS by up to $222 \%$.
MZEN, therefore, extends NeRF to real-world factory settings, preserving global
accuracy while capturing the micron-level details essential for industrial
inspection.

</details>


### [9] [TSMS-SAM2: Multi-scale Temporal Sampling Augmentation and Memory-Splitting Pruning for Promptable Video Object Segmentation and Tracking in Surgical Scenarios](https://arxiv.org/abs/2508.05829)
*Guoping Xu,Hua-Chieh Shao,You Zhang*

Main category: cs.CV

TL;DR: TSMS-SAM2是一种新型框架，通过多时间尺度视频采样增强和内存分割修剪机制，提升了可提示视频对象分割与跟踪（VOST）在手术视频中的性能。


<details>
  <summary>Details</summary>
Motivation: 手术视频分析中复杂的运动动态和内存冗余限制了基础模型（如SAM2）的应用效果。

Method: 采用多时间尺度视频采样增强和内存分割修剪机制，优化运动变化和内存管理。

Result: 在EndoVis2017和EndoVis2018数据集上分别达到95.24和86.73的Dice分数，优于现有方法。

Conclusion: TSMS-SAM2在复杂手术场景中表现出高效、鲁棒的分割潜力。

Abstract: Promptable video object segmentation and tracking (VOST) has seen significant
advances with the emergence of foundation models like Segment Anything Model 2
(SAM2); however, their application in surgical video analysis remains
challenging due to complex motion dynamics and the redundancy of memory that
impedes effective learning. In this work, we propose TSMS-SAM2, a novel
framework that enhances promptable VOST in surgical videos by addressing
challenges of rapid object motion and memory redundancy in SAM2. TSMS-SAM2
introduces two key strategies: multi-temporal-scale video sampling augmentation
to improve robustness against motion variability, and a memory splitting and
pruning mechanism that organizes and filters past frame features for more
efficient and accurate segmentation. Evaluated on EndoVis2017 and EndoVis2018
datasets, TSMS-SAM2 achieved the highest mean Dice scores of 95.24 and 86.73,
respectively, outperforming prior SAM-based and task-specific methods.
Extensive ablation studies confirm the effectiveness of multiscale temporal
augmentation and memory splitting, highlighting the framework's potential for
robust, efficient segmentation in complex surgical scenarios. Our source code
will be available at https://github.com/apple1986/TSMS-SAM2.

</details>


### [10] [Temporal Cluster Assignment for Efficient Real-Time Video Segmentation](https://arxiv.org/abs/2508.05851)
*Ka-Wai Yung,Felix J. S. Bragman,Jialang Xu,Imanol Luengo,Danail Stoyanov,Evangelos B. Mazomenos*

Main category: cs.CV

TL;DR: 提出了一种名为Temporal Cluster Assignment (TCA)的轻量级方法，通过利用帧间时间一致性优化视频分割中的令牌聚类，显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: Swin Transformer在视频分割中计算成本高，现有令牌减少方法无法有效利用时间冗余。

Method: TCA通过时间相关性优化令牌聚类，保留细节并减少计算。

Result: 在多个数据集上验证，TCA显著提升了现有聚类方法的精度与速度平衡。

Conclusion: TCA是一种无需微调的策略，适用于自然和特定领域视频。

Abstract: Vision Transformers have substantially advanced the capabilities of
segmentation models across both image and video domains. Among them, the Swin
Transformer stands out for its ability to capture hierarchical, multi-scale
representations, making it a popular backbone for segmentation in videos.
However, despite its window-attention scheme, it still incurs a high
computational cost, especially in larger variants commonly used for dense
prediction in videos. This remains a major bottleneck for real-time,
resource-constrained applications. Whilst token reduction methods have been
proposed to alleviate this, the window-based attention mechanism of Swin
requires a fixed number of tokens per window, limiting the applicability of
conventional pruning techniques. Meanwhile, training-free token clustering
approaches have shown promise in image segmentation while maintaining window
consistency. Nevertheless, they fail to exploit temporal redundancy, missing a
key opportunity to further optimize video segmentation performance. We
introduce Temporal Cluster Assignment (TCA), a lightweight and effective,
fine-tuning-free strategy that enhances token clustering by leveraging temporal
coherence across frames. Instead of indiscriminately dropping redundant tokens,
TCA refines token clusters using temporal correlations, thereby retaining
fine-grained details while significantly reducing computation. Extensive
evaluations on YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and a private surgical
video dataset show that TCA consistently boosts the accuracy-speed trade-off of
existing clustering-based methods. Our results demonstrate that TCA generalizes
competently across both natural and domain-specific videos.

</details>


### [11] [VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments](https://arxiv.org/abs/2508.05852)
*Kaiser Hamid,Khandakar Ashrafi Akbar,Nade Liang*

Main category: cs.CV

TL;DR: 提出了一种基于视觉-语言框架的方法，通过自然语言建模驾驶员视线变化，利用少样本和零样本学习，在单张RGB图像上预测驾驶员视觉注意力分配和转移。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注静态图像中的注意力分配，缺乏对动态视线变化的建模。本文旨在通过自然语言描述实现驾驶员视觉注意力的动态预测。

Method: 结合低层线索和自上而下上下文（如路线语义、风险预测），利用人类反馈优化BDD-A数据集的高质量标注，微调LLaVA模型，实现视觉感知与注意力中心场景理解的结合。

Result: 微调后的模型在注意力转移检测和可解释性上优于通用视觉-语言模型，并通过领域特定指标验证了语义对齐和响应多样性。

Conclusion: 该方法首次通过自然语言生成驾驶员视觉注意力分配和转移预测，为自动驾驶中的可解释AI提供了新方向，并为下游任务（如行为预测、人机协作）奠定了基础。

Abstract: Driver visual attention prediction is a critical task in autonomous driving
and human-computer interaction (HCI) research. Most prior studies focus on
estimating attention allocation at a single moment in time, typically using
static RGB images such as driving scene pictures. In this work, we propose a
vision-language framework that models the changing landscape of drivers' gaze
through natural language, using few-shot and zero-shot learning on single RGB
images. We curate and refine high-quality captions from the BDD-A dataset using
human-in-the-loop feedback, then fine-tune LLaVA to align visual perception
with attention-centric scene understanding. Our approach integrates both
low-level cues and top-down context (e.g., route semantics, risk anticipation),
enabling language-based descriptions of gaze behavior. We evaluate performance
across training regimes (few shot, and one-shot) and introduce domain-specific
metrics for semantic alignment and response diversity. Results show that our
fine-tuned model outperforms general-purpose VLMs in attention shift detection
and interpretability. To our knowledge, this is among the first attempts to
generate driver visual attention allocation and shifting predictions in natural
language, offering a new direction for explainable AI in autonomous driving.
Our approach provides a foundation for downstream tasks such as behavior
forecasting, human-AI teaming, and multi-agent coordination.

</details>


### [12] [Multi-view Gaze Target Estimation](https://arxiv.org/abs/2508.05857)
*Qiaomu Miao,Vivek Raju Golani,Jingyi Xu,Progga Paromita Dutta,Minh Hoai,Dimitris Samaras*

Main category: cs.CV

TL;DR: 提出了一种利用多摄像头视角进行视线目标估计（GTE）的方法，通过整合不同视角信息提高准确性和适用性。


<details>
  <summary>Details</summary>
Motivation: 解决单视角方法在面部遮挡、目标模糊和视野外目标等问题上的局限性。

Method: 结合了头部信息聚合（HIA）、基于不确定性的视线选择（UGS）和基于极线的场景注意力（ESA）模块。

Result: 显著优于单视角基线方法，尤其在第二视角提供清晰面部视图时表现更佳。

Conclusion: 该方法不仅能利用多视角信息，还能仅通过第二视角图像估计第一视角的视线目标，并提供了多视角数据集。

Abstract: This paper presents a method that utilizes multiple camera views for the gaze
target estimation (GTE) task. The approach integrates information from
different camera views to improve accuracy and expand applicability, addressing
limitations in existing single-view methods that face challenges such as face
occlusion, target ambiguity, and out-of-view targets. Our method processes a
pair of camera views as input, incorporating a Head Information Aggregation
(HIA) module for leveraging head information from both views for more accurate
gaze estimation, an Uncertainty-based Gaze Selection (UGS) for identifying the
most reliable gaze output, and an Epipolar-based Scene Attention (ESA) module
for cross-view background information sharing. This approach significantly
outperforms single-view baselines, especially when the second camera provides a
clear view of the person's face. Additionally, our method can estimate the gaze
target in the first view using the image of the person in the second view only,
a capability not possessed by single-view GTE methods. Furthermore, the paper
introduces a multi-view dataset for developing and evaluating multi-view GTE
methods. Data and code are available at
https://www3.cs.stonybrook.edu/~cvl/multiview_gte.html

</details>


### [13] [ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates](https://arxiv.org/abs/2508.05898)
*Hamidreza Dastmalchi,Aijun An,Ali cheraghian*

Main category: cs.CV

TL;DR: ETTA提出了一种高效的测试时适应方法，通过递归更新模块和自适应集成模块提升预训练视觉语言模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于缓存的TTA方法因仅存储高置信度样本而忽略其他测试数据影响的问题。

Method: 引入递归更新模块动态整合所有测试样本，并结合自适应集成模块减少对提示的依赖。

Result: 在计算复杂度和准确性上超越现有TTA模型。

Conclusion: ETTA为高效、有效的测试时适应设定了新标准。

Abstract: Pretrained vision-language models (VLMs) like CLIP show strong zero-shot
performance but struggle with generalization under distribution shifts.
Test-Time Adaptation (TTA) addresses this by adapting VLMs to unlabeled test
data in new domains. While some TTA methods rely on prompt-tuning,
training-free cache-based approaches are preferred for efficiency. However,
current cache-based TTA models store only a limited set of high-confidence
samples, restricting the decision boundary to these samples and ignoring the
influence of other incoming test data. To address this, we propose Efficient
Test-Time Adaptation (ETTA), introducing a Recursive Updating module that
integrates all incoming test samples, progressively refining the decision
boundary. This strategy mimics an unbounded cache, dynamically updating
contextual embeddings for improved accuracy with minimal memory and
computational overhead. ETTA also includes an Adaptive Ensemble module to
reduce prompt dependency in image-to-text scores by dynamically selecting
optimal prompts for each class. Furthermore, ETTA adaptively combines scores
from both modules based on confidence levels, leveraging their complementary
strengths. Extensive experiments on two benchmarks confirm that ETTA surpasses
the state-of-the-art TTA models in computational complexity and accuracy,
setting a new standard for effective, efficient test-time adaptation. The code
has been released at https://github.com/hamidreza-dastmalchi/ETTA.

</details>


### [14] [HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing](https://arxiv.org/abs/2508.05899)
*Zixuan Bian,Ruohan Ren,Yue Yang,Chris Callison-Burch*

Main category: cs.CV

TL;DR: HOLODECK 2.0是一个基于视觉语言模型的3D场景生成框架，支持根据文本描述生成多样风格的高质量3D场景，并通过交互式编辑优化布局和风格。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景生成依赖大量人工，现有自动化方法难以生成开放域场景或支持灵活编辑，因此需要直接从文本生成3D世界的解决方案。

Method: HOLODECK 2.0利用视觉语言模型解析场景需求，通过先进3D生成模型创建高质量资产，并基于空间约束迭代优化布局。

Result: 实验表明，HOLODECK 2.0生成的场景在语义和物理合理性上优于基线，支持灵活编辑，并在游戏建模中展示了实用性。

Conclusion: HOLODECK 2.0为3D场景生成提供了高效、灵活且高质量的解决方案，适用于多种应用场景。

Abstract: 3D scene generation plays a crucial role in gaming, artistic creation,
virtual reality and many other domains. However, current 3D scene design still
relies heavily on extensive manual effort from creators, and existing automated
methods struggle to generate open-domain scenes or support flexible editing. As
a result, generating 3D worlds directly from text has garnered increasing
attention. In this paper, we introduce HOLODECK 2.0, an advanced
vision-language-guided framework for 3D world generation with support for
interactive scene editing based on human feedback. HOLODECK 2.0 can generate
diverse and stylistically rich 3D scenes (e.g., realistic, cartoon, anime, and
cyberpunk styles) that exhibit high semantic fidelity to fine-grained input
descriptions, suitable for both indoor and open-domain environments. HOLODECK
2.0 leverages vision-language models (VLMs) to identify and parse the objects
required in a scene and generates corresponding high-quality assets via
state-of-the-art 3D generative models. It then iteratively applies spatial
constraints derived from the VLMs to achieve semantically coherent and
physically plausible layouts. Human evaluations and CLIP-based assessments
demonstrate that HOLODECK 2.0 effectively generates high-quality scenes closely
aligned with detailed textual descriptions, consistently outperforming
baselines across indoor and open-domain scenarios. Additionally, we provide
editing capabilities that flexibly adapt to human feedback, supporting layout
refinement and style-consistent object edits. Finally, we present a practical
application of HOLODECK 2.0 in procedural game modeling, generating visually
rich and immersive environments, potentially boosting efficiency.

</details>


### [15] [Robust Image Stitching with Optimal Plane](https://arxiv.org/abs/2508.05903)
*Lang Nie,Yuan Mei,Kang Liao,Yunqiu Xu,Chunyu Lin,Bin Xiao*

Main category: cs.CV

TL;DR: RopStitch是一种无监督的深度图像拼接框架，通过双分支架构和虚拟最优平面概念提升鲁棒性和自然性。


<details>
  <summary>Details</summary>
Motivation: 解决图像拼接中内容对齐与结构保留的矛盾，提升在多样化场景中的泛化能力。

Method: 采用双分支架构分别捕获粗粒度与细粒度特征，并通过虚拟最优平面估计最优拼接平面。

Result: 在多个数据集上显著优于现有方法，尤其在场景鲁棒性和内容自然性方面。

Conclusion: RopStitch通过创新架构和优化策略，实现了高效且自然的图像拼接。

Abstract: We present \textit{RopStitch}, an unsupervised deep image stitching framework
with both robustness and naturalness. To ensure the robustness of
\textit{RopStitch}, we propose to incorporate the universal prior of content
perception into the image stitching model by a dual-branch architecture. It
separately captures coarse and fine features and integrates them to achieve
highly generalizable performance across diverse unseen real-world scenes.
Concretely, the dual-branch model consists of a pretrained branch to capture
semantically invariant representations and a learnable branch to extract
fine-grained discriminative features, which are then merged into a whole by a
controllable factor at the correlation level. Besides, considering that content
alignment and structural preservation are often contradictory to each other, we
propose a concept of virtual optimal planes to relieve this conflict. To this
end, we model this problem as a process of estimating homography decomposition
coefficients, and design an iterative coefficient predictor and minimal
semantic distortion constraint to identify the optimal plane. This scheme is
finally incorporated into \textit{RopStitch} by warping both views onto the
optimal plane bidirectionally. Extensive experiments across various datasets
demonstrate that \textit{RopStitch} significantly outperforms existing methods,
particularly in scene robustness and content naturalness. The code is available
at {\color{red}https://github.com/MmelodYy/RopStitch}.

</details>


### [16] [ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge](https://arxiv.org/abs/2508.05991)
*Juewen Hu,Yexin Li,Jiulin Li,Shuo Chen,Pring Wong*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多模态情感识别框架，通过预训练模型提取视觉、音频和文本特征，并采用双分支视觉编码器和上下文丰富方法优化特征提取。融合策略结合自注意力机制和残差连接，同时通过多源标签策略优化训练数据。在MER2025-SEMI数据集上表现显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 提升人机交互中的情感识别能力，解决数据稀缺问题。

Method: 利用预训练模型提取多模态特征，设计双分支视觉编码器和上下文丰富文本方法，采用自注意力机制和残差连接的融合策略，优化训练标签。

Result: 在MER2025-SEMI数据集上加权F-score达到87.49%，显著优于基线（78.63%）。

Conclusion: 提出的框架在情感识别任务中表现优异，验证了其有效性。

Abstract: Emotion recognition plays a vital role in enhancing human-computer
interaction. In this study, we tackle the MER-SEMI challenge of the MER2025
competition by proposing a novel multimodal emotion recognition framework. To
address the issue of data scarcity, we leverage large-scale pre-trained models
to extract informative features from visual, audio, and textual modalities.
Specifically, for the visual modality, we design a dual-branch visual encoder
that captures both global frame-level features and localized facial
representations. For the textual modality, we introduce a context-enriched
method that employs large language models to enrich emotional cues within the
input text. To effectively integrate these multimodal features, we propose a
fusion strategy comprising two key components, i.e., self-attention mechanisms
for dynamic modality weighting, and residual connections to preserve original
representations. Beyond architectural design, we further refine noisy labels in
the training set by a multi-source labeling strategy. Our approach achieves a
substantial performance improvement over the official baseline on the
MER2025-SEMI dataset, attaining a weighted F-score of 87.49% compared to
78.63%, thereby validating the effectiveness of the proposed framework.

</details>


### [17] [Neural Field Representations of Mobile Computational Photography](https://arxiv.org/abs/2508.05907)
*Ilya Chugunov*

Main category: cs.CV

TL;DR: 论文探讨了如何利用精心设计的神经场模型在移动成像中高效表示复杂几何和光照效果，无需复杂预处理或标注数据。


<details>
  <summary>Details</summary>
Motivation: 移动成像技术快速发展，手机成为多功能计算成像平台，但现有方法依赖复杂预处理或标注数据，限制了应用范围。

Method: 采用神经场模型，通过随机梯度下降直接拟合智能手机原始数据，解决逆问题。

Result: 方法在深度估计、图层分离和图像拼接等任务中优于现有技术。

Conclusion: 神经场模型为移动成像提供了一种高效、自正则化的解决方案，无需依赖额外数据或复杂预处理。

Abstract: Over the past two decades, mobile imaging has experienced a profound
transformation, with cell phones rapidly eclipsing all other forms of digital
photography in popularity. Today's cell phones are equipped with a diverse
range of imaging technologies - laser depth ranging, multi-focal camera arrays,
and split-pixel sensors - alongside non-visual sensors such as gyroscopes,
accelerometers, and magnetometers. This, combined with on-board integrated
chips for image and signal processing, makes the cell phone a versatile
pocket-sized computational imaging platform. Parallel to this, we have seen in
recent years how neural fields - small neural networks trained to map
continuous spatial input coordinates to output signals - enable the
reconstruction of complex scenes without explicit data representations such as
pixel arrays or point clouds. In this thesis, I demonstrate how carefully
designed neural field models can compactly represent complex geometry and
lighting effects. Enabling applications such as depth estimation, layer
separation, and image stitching directly from collected in-the-wild mobile
photography data. These methods outperform state-of-the-art approaches without
relying on complex pre-processing steps, labeled ground truth data, or machine
learning priors. Instead, they leverage well-constructed, self-regularized
models that tackle challenging inverse problems through stochastic gradient
descent, fitting directly to raw measurements from a smartphone.

</details>


### [18] [Enhancing Construction Site Analysis and Understanding with 3D Segmentation](https://arxiv.org/abs/2508.05922)
*Sri Ramana Saketh Vasanthawada,Pengkun Liu,Pingbo Tang*

Main category: cs.CV

TL;DR: 论文探讨了计算机视觉方法在建筑进度监测中的应用，评估了SAM和Mask3D两种3D分割模型在复杂建筑环境中的表现，并指出当前方法在户外场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统建筑监测方法效率低且难以适应复杂多变的建筑环境，因此需要探索更高效、可扩展的计算机视觉方法。

Method: 研究评估了SAM和Mask3D两种3D分割模型在室内和户外建筑环境中的适应性，通过对比分析其性能。

Result: 研究发现当前分割方法在户外场景中缺乏基准，SAM和Mask3D在建筑环境中的表现各有优劣。

Conclusion: 研究强调了定制化分割流程的必要性，以提升建筑监测的自动化和精确性。

Abstract: Monitoring construction progress is crucial yet resource-intensive, prompting
the exploration of computer-vision-based methodologies for enhanced efficiency
and scalability. Traditional data acquisition methods, primarily focusing on
indoor environments, falter in construction site's complex, cluttered, and
dynamically changing conditions. This paper critically evaluates the
application of two advanced 3D segmentation methods, Segment Anything Model
(SAM) and Mask3D, in challenging outdoor and indoor conditions. Trained
initially on indoor datasets, both models' adaptability and performance are
assessed in real-world construction settings, highlighting the gap in current
segmentation approaches due to the absence of benchmarks for outdoor scenarios.
Through a comparative analysis, this study not only showcases the relative
effectiveness of SAM and Mask3D but also addresses the critical need for
tailored segmentation workflows capable of extracting actionable insights from
construction site data, thereby advancing the field towards more automated and
precise monitoring techniques.

</details>


### [19] [A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image](https://arxiv.org/abs/2508.05950)
*Yanxing Liang,Yinghui Wang,Jinlong Yang,Wei Li*

Main category: cs.CV

TL;DR: SINGAD提出了一种自监督框架，通过3D高斯扩散和物理驱动的光交互建模，解决了单图像法线估计中的多视角不一致和数据依赖问题。


<details>
  <summary>Details</summary>
Motivation: 单图像法线估计缺乏空间维度信息，现有方法依赖数据驱动统计先验，忽略光-表面交互的显式建模，导致多视角法线方向冲突和梯度不连续问题。

Method: 结合物理驱动的光交互建模和可微分渲染重投影策略，构建3D高斯重参数化模型和跨域特征融合模块，实现自监督优化。

Result: 在Google Scanned Objects数据集上定量评估显示，SINGAD在多个指标上优于现有方法。

Conclusion: SINGAD通过几何误差直接优化法线生成，解决了多视角几何不一致和数据依赖问题，显著提升了性能。

Abstract: The lack of spatial dimensional information remains a challenge in normal
estimation from a single image. Recent diffusion-based methods have
demonstrated significant potential in 2D-to-3D implicit mapping, they rely on
data-driven statistical priors and miss the explicit modeling of light-surface
interaction, leading to multi-view normal direction conflicts. Moreover, the
discrete sampling mechanism of diffusion models causes gradient discontinuity
in differentiable rendering reconstruction modules, preventing 3D geometric
errors from being backpropagated to the normal generation network, thereby
forcing existing methods to depend on dense normal annotations. This paper
proposes SINGAD, a novel Self-supervised framework from a single Image for
Normal estimation via 3D GAussian splatting guided Diffusion. By integrating
physics-driven light-interaction modeling and a differentiable rendering-based
reprojection strategy, our framework directly converts 3D geometric errors into
normal optimization signals, solving the challenges of multi-view geometric
inconsistency and data dependency. Specifically, the framework constructs a
light-interaction-driven 3DGS reparameterization model to generate multi-scale
geometric features consistent with light transport principles, ensuring
multi-view normal consistency. A cross-domain feature fusion module is designed
within a conditional diffusion model, embedding geometric priors to constrain
normal generation while maintaining accurate geometric error propagation.
Furthermore, a differentiable 3D reprojection loss strategy is introduced for
self-supervised optimization that minimizes geometric error between the
reconstructed and input image, eliminating dependence on annotated normal
datasets. Quantitative evaluations on the Google Scanned Objects dataset
demonstrate that our method outperforms state-of-the-art approaches across
multiple metrics.

</details>


### [20] [Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents](https://arxiv.org/abs/2508.05954)
*Han Lin,Jaemin Cho,Amir Zadeh,Chuan Li,Mohit Bansal*

Main category: cs.CV

TL;DR: Bifrost-1框架通过将预训练多模态大语言模型（MLLMs）与扩散模型结合，利用CLIP图像嵌入作为潜在变量，实现高效可控的高保真图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练成本高且可能损害大语言模型推理能力的问题上存在不足，需要一种更高效的解决方案。

Method: 使用patch级CLIP图像嵌入作为潜在变量，轻量级调整ControlNet，并初始化MLLM的视觉生成分支。

Result: Bifrost-1在视觉保真度和多模态理解上表现优异，且训练计算成本显著降低。

Conclusion: 该框架为高保真图像生成提供了一种高效且性能优越的方法。

Abstract: There is growing interest in integrating high-fidelity visual synthesis
capabilities into large language models (LLMs) without compromising their
strong reasoning capabilities. Existing methods that directly train LLMs or
bridge LLMs and diffusion models usually suffer from costly training since the
backbone LLMs have not seen image representations during pretraining. We
present Bifrost-1, a unified framework that bridges pretrained multimodal LLMs
(MLLMs) and diffusion models using patch-level CLIP image embeddings as latent
variables, which are natively aligned with the MLLM's CLIP visual encoder.
These patch-level image embeddings are integrated into the diffusion model with
a lightweight adaptation of its ControlNet. To retain the original multimodal
reasoning capabilities of MLLMs, we equip the MLLM with a visual generation
branch initialized from the original MLLM parameters when predicting the
patch-level image embeddings. By seamlessly integrating pretrained MLLMs and
diffusion models with patch-level CLIP latents, our framework enables
high-fidelity controllable image generation with significant training
efficiency. Our experiments demonstrate that Bifrost-1 achieves comparable or
better performance than previous methods in terms of visual fidelity and
multimodal understanding, with substantially lower compute during training. We
also provide comprehensive ablation studies showing the effectiveness of our
design choices.

</details>


### [21] [PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation](https://arxiv.org/abs/2508.05976)
*Zhihao Zhu,Yifan Zheng,Siyu Pan,Yaohui Jin,Yao Mu*

Main category: cs.CV

TL;DR: PASG框架通过几何特征聚合和视觉语言模型动态耦合几何基元与功能可供性，解决了机器人操作中语义与几何特征的割裂问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中高级任务语义与低级几何特征之间的割裂问题，以及视觉语言模型在语义基础和动态语义-可供性关系捕捉上的不足。

Method: 提出PASG框架，包括自动基元提取、VLM驱动的语义锚定，以及空间语义推理基准和微调VLM（Qwen2.5VL-PA）。

Result: 在多样化机器人操作任务中表现优异，性能接近人工标注水平。

Conclusion: PASG实现了对物体更细粒度的语义-可供性理解，为机器人操作中几何基元与任务语义的统一提供了新范式。

Abstract: The fragmentation between high-level task semantics and low-level geometric
features remains a persistent challenge in robotic manipulation. While
vision-language models (VLMs) have shown promise in generating affordance-aware
visual representations, the lack of semantic grounding in canonical spaces and
reliance on manual annotations severely limit their ability to capture dynamic
semantic-affordance relationships. To address these, we propose Primitive-Aware
Semantic Grounding (PASG), a closed-loop framework that introduces: (1)
Automatic primitive extraction through geometric feature aggregation, enabling
cross-category detection of keypoints and axes; (2) VLM-driven semantic
anchoring that dynamically couples geometric primitives with functional
affordances and task-relevant description; (3) A spatial-semantic reasoning
benchmark and a fine-tuned VLM (Qwen2.5VL-PA). We demonstrate PASG's
effectiveness in practical robotic manipulation tasks across diverse scenarios,
achieving performance comparable to manual annotations. PASG achieves a
finer-grained semantic-affordance understanding of objects, establishing a
unified paradigm for bridging geometric primitives with task semantics in
robotic manipulation.

</details>


### [22] [AnimateScene: Camera-controllable Animation in Any Scene](https://arxiv.org/abs/2508.05982)
*Qingyang Liu,Bingjie Gao,Weiheng Huang,Jun Zhang,Zhongqian Sun,Yang Wei,Zelin Peng,Qianli Ma,Shuai Yang,Zhaohe Liao,Haonan Zhao,Li Niu*

Main category: cs.CV

TL;DR: AnimateScene是一个统一框架，解决了将4D人体动画与3D场景重建无缝集成的挑战，包括位置放置、风格对齐和相机轨迹插入。


<details>
  <summary>Details</summary>
Motivation: 将4D人体动画与3D场景重建无缝集成存在多个挑战，如位置和比例的准确性、避免不真实的穿插、光照和风格的一致性，以及相机轨迹的匹配。

Method: AnimateScene包含三个模块：1) 精确放置模块确定人体的3D位置并避免穿插；2) 无训练的风格对齐方法匹配背景光照和风格；3) 联合后重建方法支持相机轨迹插入。

Result: 实验表明，AnimateScene能生成具有高几何细节和时空一致性的动态场景视频，适用于多种相机和动作组合。

Conclusion: AnimateScene通过统一框架解决了4D人体动画与3D场景集成的关键问题，实现了高质量的视觉效果。

Abstract: 3D scene reconstruction and 4D human animation have seen rapid progress and
broad adoption in recent years. However, seamlessly integrating reconstructed
scenes with 4D human animation to produce visually engaging results remains
challenging. One key difficulty lies in placing the human at the correct
location and scale within the scene while avoiding unrealistic
interpenetration. Another challenge is that the human and the background may
exhibit different lighting and style, leading to unrealistic composites. In
addition, appealing character motion videos are often accompanied by camera
movements, which means that the viewpoints need to be reconstructed along a
specified trajectory. We present AnimateScene, which addresses the above issues
in a unified framework. First, we design an accurate placement module that
automatically determines a plausible 3D position for the human and prevents any
interpenetration within the scene during motion. Second, we propose a
training-free style alignment method that adapts the 4D human representation to
match the background's lighting and style, achieving coherent visual
integration. Finally, we design a joint post-reconstruction method for both the
4D human and the 3D scene that allows camera trajectories to be inserted,
enabling the final rendered video to feature visually appealing camera
movements. Extensive experiments show that AnimateScene generates dynamic scene
videos with high geometric detail and spatiotemporal coherence across various
camera and action combinations.

</details>


### [23] [ETA: Energy-based Test-time Adaptation for Depth Completion](https://arxiv.org/abs/2508.05989)
*Younjoon Chung,Hyoungseob Park,Patrick Rim,Xiaoran Zhang,Jihe He,Ziyao Zeng,Safa Cicek,Byung-Woo Hong,James S. Duncan,Alex Wong*

Main category: cs.CV

TL;DR: 提出了一种基于能量的测试时适应方法（ETA），用于调整预训练的深度补全模型，以应对目标数据分布变化。


<details>
  <summary>Details</summary>
Motivation: 深度补全模型在从源数据转移到目标数据时，由于协变量偏移，预测结果可能不准确。需要一种无需预先了解目标分布的方法来适应新环境。

Method: 利用对抗扰动探索数据空间，训练能量模型评估深度预测的分布情况，并在测试时调整模型参数以最小化能量。

Result: 在三个室内和三个室外数据集上，ETA平均优于现有最佳方法，室外提升6.94%，室内提升10.23%。

Conclusion: ETA通过测试时适应显著提升了深度补全模型在新环境中的性能。

Abstract: We propose a method for test-time adaptation of pretrained depth completion
models. Depth completion models, trained on some ``source'' data, often predict
erroneous outputs when transferred to ``target'' data captured in novel
environmental conditions due to a covariate shift. The crux of our method lies
in quantifying the likelihood of depth predictions belonging to the source data
distribution. The challenge is in the lack of access to out-of-distribution
(target) data prior to deployment. Hence, rather than making assumptions
regarding the target distribution, we utilize adversarial perturbations as a
mechanism to explore the data space. This enables us to train an energy model
that scores local regions of depth predictions as in- or out-of-distribution.
We update the parameters of pretrained depth completion models at test time to
minimize energy, effectively aligning test-time predictions to those of the
source distribution. We call our method ``Energy-based Test-time Adaptation'',
or ETA for short. We evaluate our method across three indoor and three outdoor
datasets, where ETA improve over the previous state-of-the-art method by an
average of 6.94% for outdoors and 10.23% for indoors. Project Page:
https://fuzzythecat.github.io/eta.

</details>


### [24] [Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision](https://arxiv.org/abs/2508.05990)
*Haichao Wang,Xinyue Xi,Jiangtao Wen,Yuxing Han*

Main category: cs.CV

TL;DR: 提出了一种高效的视频计算机视觉系统，通过去除图像信号处理器和引入快速块匹配算法，显著减少了计算开销。


<details>
  <summary>Details</summary>
Motivation: 视频计算机视觉系统的高效性因视频中的时间冗余和前端计算开销而受到挑战。

Method: 直接输入Bayer格式数据，采用快速块匹配运动估计算法，引入MV细化模块和上下文感知块细化网络，并采用帧选择策略。

Result: 在多个视频计算机视觉任务中实现了显著加速，性能损失轻微。

Conclusion: 该方法在效率和准确性之间取得了良好平衡，为高效视频计算机视觉提供了可行方案。

Abstract: The efficiency of video computer vision system remains a challenging task due
to the high temporal redundancy inside a video. Existing works have been
proposed for efficient vision computer vision. However, they do not fully
reduce the temporal redundancy and neglect the front end computation overhead.
In this paper, we propose an efficient video computer vision system. First,
image signal processor is removed and Bayer-format data is directly fed into
video computer vision models, thus saving the front end computation. Second,
instead of optical flow models and video codecs, a fast block matching-based
motion estimation algorithm is proposed specifically for efficient video
computer vision, with a MV refinement module. To correct the error,
context-aware block refinement network is introduced to refine regions with
large error. To further balance the accuracy and efficiency, a frame selection
strategy is employed. Experiments on multiple video computer vision tasks
demonstrate that our method achieves significant acceleration with slight
performance loss.

</details>


### [25] [EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad](https://arxiv.org/abs/2508.05994)
*Huadong Wu,Yi Fu,Yunhao Li,Yuan Gao,Kang Du*

Main category: cs.CV

TL;DR: 论文提出MakeupQuad数据集和EvoMakeup框架，解决了现有面部化妆编辑方法在细节和身份保持上的不足，实现了高质量、可控的多任务化妆编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法因缺乏结构化配对数据，导致化妆细节粗糙且难以同时保持身份和化妆保真度。

Method: 引入MakeupQuad数据集，并提出EvoMakeup框架，通过多阶段蒸馏避免图像退化，实现数据和模型质量的迭代提升。

Result: EvoMakeup在真实场景中表现优异，支持高保真、可控的多任务化妆编辑，包括全脸、局部和文本驱动的编辑。

Conclusion: 该方法在化妆保真度和身份保持上取得平衡，优于现有方法，代码和数据集将公开。

Abstract: Facial makeup editing aims to realistically transfer makeup from a reference
to a target face. Existing methods often produce low-quality results with
coarse makeup details and struggle to preserve both identity and makeup
fidelity, mainly due to the lack of structured paired data -- where source and
result share identity, and reference and result share identical makeup. To
address this, we introduce MakeupQuad, a large-scale, high-quality dataset with
non-makeup faces, references, edited results, and textual makeup descriptions.
Building on this, we propose EvoMakeup, a unified training framework that
mitigates image degradation during multi-stage distillation, enabling iterative
improvement of both data and model quality. Although trained solely on
synthetic data, EvoMakeup generalizes well and outperforms prior methods on
real-world benchmarks. It supports high-fidelity, controllable, multi-task
makeup editing -- including full-face and partial reference-based editing, as
well as text-driven makeup editing -- within a single model. Experimental
results demonstrate that our method achieves superior makeup fidelity and
identity preservation, effectively balancing both aspects. Code and dataset
will be released upon acceptance.

</details>


### [26] [MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2508.06009)
*Jun Feng,Zixin Wang,Zhentao Zhang,Yue Guo,Zhihan Zhou,Xiuyi Chen,Zhenyang Li,Dawei Yin*

Main category: cs.CV

TL;DR: 论文介绍了MathReal数据集，用于评估多模态大语言模型在真实教育场景中的数学推理能力，发现现有模型表现不佳，并分析了其错误模式。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要基于干净或处理过的多模态输入，未考虑真实K-12教育场景中的图像输入，因此需要填补这一研究空白。

Method: 构建MathReal数据集，包含2000个真实场景下的数学问题图像，分类为图像质量、视角变化和无关内容干扰三类，并设计六种实验设置评估模型性能。

Result: 现有多模态大语言模型在真实教育场景中的问题解决能力显著受限。

Conclusion: 研究揭示了现有模型的不足，并提出了未来改进方向。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in visual mathematical reasoning across various existing
benchmarks. However, these benchmarks are predominantly based on clean or
processed multimodal inputs, without incorporating the images provided by
real-world Kindergarten through 12th grade (K-12) educational users. To address
this gap, we introduce MathReal, a meticulously curated dataset comprising
2,000 mathematical questions with images captured by handheld mobile devices in
authentic scenarios. Each question is an image, containing the question text
and visual element. We systematically classify the real images into three
primary categories: image quality degradation, perspective variation, and
irrelevant content interference, which are further delineated into 14
subcategories. Additionally, MathReal spans five core knowledge and ability
categories, which encompass three question types and are divided into three
difficulty levels. To comprehensively evaluate the multimodal mathematical
reasoning abilities of state-of-the-art MLLMs in real-world scenarios, we
design six experimental settings that enable a systematic analysis of their
performance. Through extensive experimentation, we find that the
problem-solving abilities of existing MLLMs are significantly challenged in
realistic educational contexts. Based on this, we conduct a thorough analysis
of their performance and error patterns, providing insights into their
recognition, comprehension, and reasoning capabilities, and outlining
directions for future improvements. Data and code:
https://github.com/junfeng0288/MathReal.

</details>


### [27] [ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors](https://arxiv.org/abs/2508.06014)
*Minsu Kim,Subin Jeon,In Cho,Mijin Yoo,Seon Joo Kim*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯泼溅（3DGS）的管道，通过生成额外训练视图和虚拟相机放置策略，提升新视角合成（NVS）的质量，减少伪影和缺失区域。


<details>
  <summary>Details</summary>
Motivation: 现有方法在偏离训练轨迹的视角渲染时存在伪影和缺失区域，限制了场景的无缝探索。

Method: 采用信息增益驱动的虚拟相机放置策略最大化场景覆盖，结合视频扩散先验优化渲染结果，并通过增强视图微调3D高斯。

Result: 实验表明，该方法优于现有3DGS方法，支持高质量、无伪影的任意视角渲染。

Conclusion: 提出的方法显著提升了3DGS的重建质量，适用于挑战性场景探索。

Abstract: Recent advances in novel view synthesis (NVS) have enabled real-time
rendering with 3D Gaussian Splatting (3DGS). However, existing methods struggle
with artifacts and missing regions when rendering from viewpoints that deviate
from the training trajectory, limiting seamless scene exploration. To address
this, we propose a 3DGS-based pipeline that generates additional training views
to enhance reconstruction. We introduce an information-gain-driven virtual
camera placement strategy to maximize scene coverage, followed by video
diffusion priors to refine rendered results. Fine-tuning 3D Gaussians with
these enhanced views significantly improves reconstruction quality. To evaluate
our method, we present Wild-Explore, a benchmark designed for challenging scene
exploration. Experiments demonstrate that our approach outperforms existing
3DGS-based methods, enabling high-quality, artifact-free rendering from
arbitrary viewpoints.
  https://exploregs.github.io

</details>


### [28] [Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis](https://arxiv.org/abs/2508.06021)
*Utku Ozbulak,Michaela Cohrs,Hristo L. Svilenov,Joris Vankerschaver,Wesley De Neve*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的方法，用于解决流式成像显微镜中粒子分类的数据不平衡问题，通过生成高质量图像增强训练数据，提升多类分类器的性能。


<details>
  <summary>Details</summary>
Motivation: 流式成像显微镜与深度学习结合在粒子分类中有效，但数据稀缺和类别不平衡问题限制了多类分类器的应用，尤其是对罕见粒子类型（如硅油和气泡）。

Method: 开发了一种先进的扩散模型，生成高保真图像以扩充训练数据集，并通过大规模实验验证其有效性。

Result: 生成的图像在视觉质量和结构上与真实图像相似，实验表明该方法显著提升了分类性能。

Conclusion: 扩散模型生成的图像能有效解决数据不平衡问题，提升分类性能，相关模型和代码已开源以促进研究。

Abstract: Sub-visible particle analysis using flow imaging microscopy combined with
deep learning has proven effective in identifying particle types, enabling the
distinction of harmless components such as silicone oil from protein particles.
However, the scarcity of available data and severe imbalance between particle
types within datasets remain substantial hurdles when applying multi-class
classifiers to such problems, often forcing researchers to rely on less
effective methods. The aforementioned issue is particularly challenging for
particle types that appear unintentionally and in lower numbers, such as
silicone oil and air bubbles, as opposed to protein particles, where obtaining
large numbers of images through controlled settings is comparatively
straightforward. In this work, we develop a state-of-the-art diffusion model to
address data imbalance by generating high-fidelity images that can augment
training datasets, enabling the effective training of multi-class deep neural
networks. We validate this approach by demonstrating that the generated samples
closely resemble real particle images in terms of visual quality and structure.
To assess the effectiveness of using diffusion-generated images in training
datasets, we conduct large-scale experiments on a validation dataset comprising
500,000 protein particle images and demonstrate that this approach improves
classification performance with no negligible downside. Finally, to promote
open research and reproducibility, we publicly release both our diffusion
models and the trained multi-class deep neural network classifiers, along with
a straightforward interface for easy integration into future studies, at
https://github.com/utkuozbulak/svp-generative-ai.

</details>


### [29] [Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts](https://arxiv.org/abs/2508.06032)
*Kiran Chhatre,Christopher Peters,Srikrishna Karanam*

Main category: cs.CV

TL;DR: Spectrum提出了一种统一网络，用于细粒度的人体解析（身体部位和服装），通过改进的图像到纹理扩散模型实现更好的语义分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用固定的掩码类别，无法区分细粒度的服装类型或详细的身体部位，而现有的开放词汇分割方法虽然能泛化，但缺乏对细节的专门化表示。

Method: Spectrum利用经过微调的图像到纹理（I2Tx）扩散模型提取特征，并通过提示引导生成语义有效的掩码。

Result: 实验表明，Spectrum在身体部位、服装类别和未见过的服装分割任务中均优于基线方法。

Conclusion: Spectrum通过改进的扩散模型实现了更精细的人体解析，为开放词汇分割提供了新思路。

Abstract: Existing methods for human parsing into body parts and clothing often use
fixed mask categories with broad labels that obscure fine-grained clothing
types. Recent open-vocabulary segmentation approaches leverage pretrained
text-to-image (T2I) diffusion model features for strong zero-shot transfer, but
typically group entire humans into a single person category, failing to
distinguish diverse clothing or detailed body parts. To address this, we
propose Spectrum, a unified network for part-level pixel parsing (body parts
and clothing) and instance-level grouping. While diffusion-based
open-vocabulary models generalize well across tasks, their internal
representations are not specialized for detailed human parsing. We observe
that, unlike diffusion models with broad representations, image-driven 3D
texture generators maintain faithful correspondence to input images, enabling
stronger representations for parsing diverse clothing and body parts. Spectrum
introduces a novel repurposing of an Image-to-Texture (I2Tx) diffusion model --
obtained by fine-tuning a T2I model on 3D human texture maps -- for improved
alignment with body parts and clothing. From an input image, we extract
human-part internal features via the I2Tx diffusion model and generate
semantically valid masks aligned to diverse clothing categories through
prompt-guided grounding. Once trained, Spectrum produces semantic segmentation
maps for every visible body part and clothing category, ignoring standalone
garments or irrelevant objects, for any number of humans in the scene. We
conduct extensive cross-dataset experiments -- separately assessing body parts,
clothing parts, unseen clothing categories, and full-body masks -- and
demonstrate that Spectrum consistently outperforms baseline methods in
prompt-based segmentation.

</details>


### [30] [InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow](https://arxiv.org/abs/2508.06033)
*Yiming Gong,Zhen Zhu,Minjia Zhang*

Main category: cs.CV

TL;DR: InstantEdit是一种基于RectifiedFlow框架的快速文本引导图像编辑方法，通过PerRFI反转策略和Inversion Latent Injection技术实现高效编辑，同时结合Disentangled Prompt Guidance和ControlNet提升效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本引导图像编辑方法在速度和编辑质量上的不足，实现快速且高质量的图像编辑。

Method: 采用RectifiedFlow框架，引入PerRFI反转策略和Inversion Latent Injection技术，结合Disentangled Prompt Guidance和Canny-conditioned ControlNet。

Result: 在PIE数据集上表现出色，速度快且编辑效果优于现有方法。

Conclusion: InstantEdit在速度和编辑质量上均优于现有方法，为文本引导图像编辑提供了高效解决方案。

Abstract: We propose a fast text-guided image editing method called InstantEdit based
on the RectifiedFlow framework, which is structured as a few-step editing
process that preserves critical content while following closely to textual
instructions. Our approach leverages the straight sampling trajectories of
RectifiedFlow by introducing a specialized inversion strategy called PerRFI. To
maintain consistent while editable results for RectifiedFlow model, we further
propose a novel regeneration method, Inversion Latent Injection, which
effectively reuses latent information obtained during inversion to facilitate
more coherent and detailed regeneration. Additionally, we propose a
Disentangled Prompt Guidance technique to balance editability with detail
preservation, and integrate a Canny-conditioned ControlNet to incorporate
structural cues and suppress artifacts. Evaluation on the PIE image editing
dataset demonstrates that InstantEdit is not only fast but also achieves better
qualitative and quantitative results compared to state-of-the-art few-step
editing methods.

</details>


### [31] [More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment](https://arxiv.org/abs/2508.06036)
*Jun Xie,Yingjian Zhu,Feng Chen,Zhenghao Zhang,Xiaohui Fan,Hongzhu Yi,Xinming Wang,Chen Yu,Yue Bi,Zhaoran Zhao,Xiongjun Guan,Zhepeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种半监督学习框架，结合多种输入模态和伪标签策略，在MER2025-SEMI挑战中取得第二名。


<details>
  <summary>Details</summary>
Motivation: 解决半监督学习中的情感识别问题，利用多模态数据和未标记数据提升模型性能。

Method: 采用混合专家（MoE）框架，结合视觉语言模型和动作单元信息，使用共识伪标签策略和两阶段训练。

Result: 在测试集上F1得分为0.8772，排名第二。

Conclusion: 提出的方法在多模态情感识别任务中表现优异，验证了其有效性。

Abstract: In this paper, we present our solution for the semi-supervised learning track
(MER-SEMI) in MER2025. We propose a comprehensive framework, grounded in the
principle that "more is better," to construct a robust Mixture of Experts (MoE)
emotion recognition system. Our approach integrates a diverse range of input
modalities as independent experts, including novel signals such as knowledge
from large Vision-Language Models (VLMs) and temporal Action Unit (AU)
information. To effectively utilize unlabeled data, we introduce a
consensus-based pseudo-labeling strategy, generating high-quality labels from
the agreement between a baseline model and Gemini, which are then used in a
two-stage training paradigm. Finally, we employ a multi-expert voting ensemble
combined with a rule-based re-ranking process to correct prediction bias and
better align the outputs with human preferences. Evaluated on the MER2025-SEMI
challenge dataset, our method achieves an F1-score of 0.8772 on the test set,
ranking 2nd in the track. Our code is available at
https://github.com/zhuyjan/MER2025-MRAC25.

</details>


### [32] [Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models](https://arxiv.org/abs/2508.06038)
*Huanyu Wang,Jushi Kai,Haoli Bai,Lu Hou,Bo Jiang,Ziwei He,Zhouhan Lin*

Main category: cs.CV

TL;DR: Fourier-VLM通过频域压缩视觉表示，显著减少计算开销和推理延迟，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）中大量视觉标记增加了上下文长度，导致高计算开销和推理延迟。现有方法在减少标记数量时可能牺牲性能或增加额外成本。

Method: 利用视觉特征在低频分量集中的特性，通过二维离散余弦变换（DCT）应用低通滤波器压缩视觉表示，DCT通过快速傅里叶变换（FFT）高效计算。

Result: 在多个图像基准测试中表现优异，推理FLOPs减少83.8%，生成速度提升31.2%，且无需额外参数。

Conclusion: Fourier-VLM在效率和实用性上表现优越，适用于多种架构，如LLaVA和Qwen-VL。

Abstract: Vision-Language Models (VLMs) typically replace the predefined image
placeholder token (<image>) in textual instructions with visual features from
an image encoder, forming the input to a backbone Large Language Model (LLM).
However, the large number of vision tokens significantly increases the context
length, leading to high computational overhead and inference latency. While
previous efforts mitigate this by selecting only important visual features or
leveraging learnable queries to reduce token count, they often compromise
performance or introduce substantial extra costs. In response, we propose
Fourier-VLM, a simple yet efficient method that compresses visual
representations in the frequency domain. Our approach is motivated by the
observation that vision features output from the vision encoder exhibit
concentrated energy in low-frequency components. Leveraging this, we apply a
low-pass filter to the vision features using a two-dimentional Discrete Cosine
Transform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier
Transform (FFT) operator with a time complexity of $\mathcal{O}(n\log n)$,
minimizing the extra computational cost while introducing no additional
parameters. Extensive experiments across various image-based benchmarks
demonstrate that Fourier-VLM achieves competitive performance with strong
generalizability across both LLaVA and Qwen-VL architectures. Crucially, it
reduce inference FLOPs by up to 83.8% and boots generation speed by 31.2%
compared to LLaVA-v1.5, highlighting the superior efficiency and practicality.

</details>


### [33] [NEP: Autoregressive Image Editing via Next Editing Token Prediction](https://arxiv.org/abs/2508.06044)
*Huimin Wu,Xiaojian Ma,Haozhe Zhao,Yanpeng Zhao,Qing Li*

Main category: cs.CV

TL;DR: 提出了一种基于自回归图像生成的Next Editing-token Prediction（NEP）方法，仅编辑需要修改的图像区域，避免不必要的计算和未编辑区域的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成整个目标图像，导致计算成本高且未编辑区域重建偏差影响编辑质量。

Method: 预训练一个任意顺序自回归文本到图像（T2I）模型，支持零样本图像编辑，并适应NEP方法。

Result: 在广泛使用的图像编辑基准测试中达到新最优性能，并支持零样本测试时缩放（TTS）。

Conclusion: NEP方法通过选择性编辑区域显著提升了图像编辑的效率和质量。

Abstract: Text-guided image editing involves modifying a source image based on a
language instruction and, typically, requires changes to only small local
regions. However, existing approaches generate the entire target image rather
than selectively regenerate only the intended editing areas. This results in
(1) unnecessary computational costs and (2) a bias toward reconstructing
non-editing regions, which compromises the quality of the intended edits. To
resolve these limitations, we propose to formulate image editing as Next
Editing-token Prediction (NEP) based on autoregressive image generation, where
only regions that need to be edited are regenerated, thus avoiding unintended
modification to the non-editing areas. To enable any-region editing, we propose
to pre-train an any-order autoregressive text-to-image (T2I) model. Once
trained, it is capable of zero-shot image editing and can be easily adapted to
NEP for image editing, which achieves a new state-of-the-art on widely used
image editing benchmarks. Moreover, our model naturally supports test-time
scaling (TTS) through iteratively refining its generation in a zero-shot
manner. The project page is: https://nep-bigai.github.io/

</details>


### [34] [VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning](https://arxiv.org/abs/2508.06051)
*Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Jun Jia,Kaiwei Zhang,Dandan Zhu,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: VQAThinker是一个基于推理的视频质量评估框架，利用多模态模型和强化学习解决现有模型的泛化性和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频质量评估模型在泛化性和可解释性上存在不足，限制了实际应用。

Method: 采用GRPO强化学习算法，结合三种奖励机制（回归、排序和时间一致性）模拟人类感知决策。

Result: 在多个基准测试中表现最优，泛化性强，且在质量描述和失真归因任务中优于现有模型。

Conclusion: 强化学习为构建仅需分数监督的泛化性和可解释性VQA模型提供了有效途径。

Abstract: Video quality assessment (VQA) aims to objectively quantify perceptual
quality degradation in alignment with human visual perception. Despite recent
advances, existing VQA models still suffer from two critical limitations:
\textit{poor generalization to out-of-distribution (OOD) videos} and
\textit{limited explainability}, which restrict their applicability in
real-world scenarios. To address these challenges, we propose
\textbf{VQAThinker}, a reasoning-based VQA framework that leverages large
multimodal models (LMMs) with reinforcement learning to jointly model video
quality understanding and scoring, emulating human perceptual decision-making.
Specifically, we adopt group relative policy optimization (GRPO), a rule-guided
reinforcement learning algorithm that enables reasoning over video quality
under score-level supervision, and introduce three VQA-specific rewards: (1) a
\textbf{bell-shaped regression reward} that increases rapidly as the prediction
error decreases and becomes progressively less sensitive near the ground truth;
(2) a \textbf{pairwise ranking reward} that guides the model to correctly
determine the relative quality between video pairs; and (3) a \textbf{temporal
consistency reward} that encourages the model to prefer temporally coherent
videos over their perturbed counterparts. Extensive experiments demonstrate
that VQAThinker achieves state-of-the-art performance on both in-domain and OOD
VQA benchmarks, showing strong generalization for video quality scoring.
Furthermore, evaluations on video quality understanding tasks validate its
superiority in distortion attribution and quality description compared to
existing explainable VQA models and LMMs. These findings demonstrate that
reinforcement learning offers an effective pathway toward building
generalizable and explainable VQA models solely with score-level supervision.

</details>


### [35] [LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing](https://arxiv.org/abs/2508.06055)
*Wonjung Park,Suhyun Ahn,Jinah Park*

Main category: cs.CV

TL;DR: LV-Net是一种新框架，通过变形解剖学感知的联合LV-海马模板网格，从脑MRI生成个性化的3D LV网格，解决了LV形状分析中的挑战。


<details>
  <summary>Details</summary>
Motivation: LV形状分析作为神经系统疾病的生物标志物具有潜力，但个体间形状差异大和MRI分辨率限制导致分割困难。

Method: LV-Net通过结合解剖学关系改进边界分割和重建鲁棒性，并通过模板网格顶点分类增强点对应性。

Result: LV-Net在分割不完美情况下仍实现高重建精度，并在阿尔茨海默病分析中识别出与疾病显著相关的LV子区域。

Conclusion: LV-Net为LV形状分析提供了更可靠的工具，并在疾病研究中展示了应用潜力。

Abstract: Lateral ventricle (LV) shape analysis holds promise as a biomarker for
neurological diseases; however, challenges remain due to substantial shape
variability across individuals and segmentation difficulties arising from
limited MRI resolution. We introduce LV-Net, a novel framework for producing
individualized 3D LV meshes from brain MRI by deforming an anatomy-aware joint
LV-hippocampus template mesh. By incorporating anatomical relationships
embedded within the joint template, LV-Net reduces boundary segmentation
artifacts and improves reconstruction robustness. In addition, by classifying
the vertices of the template mesh based on their anatomical adjacency, our
method enhances point correspondence across subjects, leading to more accurate
LV shape statistics. We demonstrate that LV-Net achieves superior
reconstruction accuracy, even in the presence of segmentation imperfections,
and delivers more reliable shape descriptors across diverse datasets. Finally,
we apply LV-Net to Alzheimer's disease analysis, identifying LV subregions that
show significantly associations with the disease relative to cognitively normal
controls. The codes for LV shape modeling are available at
https://github.com/PWonjung/LV_Shape_Modeling.

</details>


### [36] [AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?](https://arxiv.org/abs/2508.06057)
*Mojtaba Valipour,Kelly Zheng,James Lowman,Spencer Szabados,Mike Gartner,Bobby Braswell*

Main category: cs.CV

TL;DR: 论文呼吁关注卫星光谱图像作为AGI的新模态，提出现有基准的不足，并建议更全面的评估任务。


<details>
  <summary>Details</summary>
Motivation: 卫星光谱图像尚未受到足够重视，但其对AGI理解自然世界具有潜力。

Method: 分析现有基准的局限性，并提出一套全面的评估任务。

Result: 强调需要更全面的基准来评估地球观测模型。

Conclusion: 提出新的评估任务以促进地球观测模型的进步。

Abstract: Artificial General Intelligence (AGI) is closer than ever to becoming a
reality, sparking widespread enthusiasm in the research community to collect
and work with various modalities, including text, image, video, and audio.
Despite recent efforts, satellite spectral imagery, as an additional modality,
has yet to receive the attention it deserves. This area presents unique
challenges, but also holds great promise in advancing the capabilities of AGI
in understanding the natural world. In this paper, we argue why Earth
Observation data is useful for an intelligent model, and then we review
existing benchmarks and highlight their limitations in evaluating the
generalization ability of foundation models in this domain. This paper
emphasizes the need for a more comprehensive benchmark to evaluate earth
observation models. To facilitate this, we propose a comprehensive set of tasks
that a benchmark should encompass to effectively assess a model's ability to
understand and interact with Earth observation data.

</details>


### [37] [Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention](https://arxiv.org/abs/2508.06058)
*Shiyang Zhou,Haijin Zeng,Yunfan Lu,Yongyong Chen,Jie Liu,Jingyong Su*

Main category: cs.CV

TL;DR: TSANet是一个轻量级的两阶段网络，通过状态空间增强的交叉注意力处理事件像素修复和去马赛克，显著提升了HybridEVS相机的图像质量。


<details>
  <summary>Details</summary>
Motivation: HybridEVS相机结合Quad Bayer CFA传感器和事件像素时，去马赛克过程中会出现伪影和混叠问题，现有方法难以在资源有限的移动设备上有效解决。

Method: 提出TSANet，采用两阶段网络分别处理事件像素修复和去马赛克，并引入轻量级的Cross-Swin State Block增强全局依赖。

Result: 在模拟和真实数据上表现优异，PSNR和SSIM优于DemosaicFormer，参数和计算成本分别降低1.86倍和3.29倍。

Conclusion: TSANet为移动设备上的高效图像去马赛克提供了新思路，代码已开源。

Abstract: Event cameras like the Hybrid Event-based Vision Sensor (HybridEVS) camera
capture brightness changes as asynchronous "events" instead of frames, offering
advanced application on mobile photography. However, challenges arise from
combining a Quad Bayer Color Filter Array (CFA) sensor with event pixels
lacking color information, resulting in aliasing and artifacts on the
demosaicing process before downstream application. Current methods struggle to
address these issues, especially on resource-limited mobile devices. In
response, we introduce \textbf{TSANet}, a lightweight \textbf{T}wo-stage
network via \textbf{S}tate space augmented cross-\textbf{A}ttention, which can
handle event pixels inpainting and demosaicing separately, leveraging the
benefits of dividing complex tasks into manageable subtasks. Furthermore, we
introduce a lightweight Cross-Swin State Block that uniquely utilizes
positional prior for demosaicing and enhances global dependencies through the
state space model with linear complexity. In summary, TSANet demonstrates
excellent demosaicing performance on both simulated and real data of HybridEVS
while maintaining a lightweight model, averaging better results than the
previous state-of-the-art method DemosaicFormer across seven diverse datasets
in both PSNR and SSIM, while respectively reducing parameter and computation
costs by $1.86\times$ and $3.29\times$. Our approach presents new possibilities
for efficient image demosaicing on mobile devices. Code is available in the
supplementary materials.

</details>


### [38] [Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection](https://arxiv.org/abs/2508.06063)
*Chao Hao,Zitong Yu,Xin Liu,Yuhao Wang,Weicheng Xie,Jingang Shi,Huanjing Yue,Jingyu Yang*

Main category: cs.CV

TL;DR: SCJoint是一种联合学习方法，用于同时处理显著目标检测（SOD）和伪装目标检测（COD）任务，通过任务特定的学习参数和共享网络结构，使网络能够同时捕捉显著和伪装目标。


<details>
  <summary>Details</summary>
Motivation: 尽管SOD和COD任务具有矛盾属性，但作者认为通过正确的学习方法，网络可以同时具备这两种能力，从而提升性能。

Method: 提出SCJoint方法，通过插入少量任务特定学习参数来解耦任务矛盾，并设计SBSS采样策略平衡训练集。

Result: 实验表明，JoNet网络在SOD和COD任务上均表现出竞争力。

Conclusion: SCJoint和SBSS方法有效解决了SOD和COD任务的联合学习问题，提升了网络性能。

Abstract: Salient object detection (SOD) and camouflaged object detection (COD) are two
closely related but distinct computer vision tasks. Although both are
class-agnostic segmentation tasks that map from RGB space to binary space, the
former aims to identify the most salient objects in the image, while the latter
focuses on detecting perfectly camouflaged objects that blend into the
background in the image. These two tasks exhibit strong contradictory
attributes. Previous works have mostly believed that joint learning of these
two tasks would confuse the network, reducing its performance on both tasks.
However, here we present an opposite perspective: with the correct approach to
learning, the network can simultaneously possess the capability to find both
salient and camouflaged objects, allowing both tasks to benefit from joint
learning. We propose SCJoint, a joint learning scheme for SOD and COD tasks,
assuming that the decoding processes of SOD and COD have different distribution
characteristics. The key to our method is to learn the respective means and
variances of the decoding processes for both tasks by inserting a minimal
amount of task-specific learnable parameters within a fully shared network
structure, thereby decoupling the contradictory attributes of the two tasks at
a minimal cost. Furthermore, we propose a saliency-based sampling strategy
(SBSS) to sample the training set of the SOD task to balance the training set
sizes of the two tasks. In addition, SBSS improves the training set quality and
shortens the training time. Based on the proposed SCJoint and SBSS, we train a
powerful generalist network, named JoNet, which has the ability to
simultaneously capture both ``salient" and ``camouflaged". Extensive
experiments demonstrate the competitive performance and effectiveness of our
proposed method. The code is available at https://github.com/linuxsino/JoNet.

</details>


### [39] [Can Large Models Fool the Eye? A New Turing Test for Biological Animation](https://arxiv.org/abs/2508.06072)
*Zijian Chen,Lirong Deng,Zhengyu Chen,Kaiwei Zhang,Qi Jia,Yuan Tian,Yucheng Zhu,Guangtao Zhai*

Main category: cs.CV

TL;DR: BioMotion Arena是一个通过视觉动画评估大型语言模型（LLM）和多模态大型语言模型（MLLM）的新框架，利用点光源成像放大模型间的性能差异。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法（基于静态数据集或模糊的聊天机器人式偏好收集）无法提供直观、即时的性能反馈。

Method: 采用成对比较评估，收集了53个主流LLM和MLLM在90种生物运动变体上的45k+投票数据。

Result: 众包投票与专家评分一致，90%以上模型（包括先进的开源和专有模型）无法生成基本的人形点光源组或流畅的生物运动。

Conclusion: BioMotion Arena是一个具有挑战性的性能可视化基准，无需依赖真实数据，提供灵活的评估框架。

Abstract: Evaluating the abilities of large models and manifesting their gaps are
challenging. Current benchmarks adopt either ground-truth-based score-form
evaluation on static datasets or indistinct textual chatbot-style human
preferences collection, which may not provide users with immediate, intuitive,
and perceptible feedback on performance differences. In this paper, we
introduce BioMotion Arena, a novel framework for evaluating large language
models (LLMs) and multimodal large language models (MLLMs) via visual
animation. Our methodology draws inspiration from the inherent visual
perception of motion patterns characteristic of living organisms that utilizes
point-light source imaging to amplify the performance discrepancies between
models. Specifically, we employ a pairwise comparison evaluation and collect
more than 45k votes for 53 mainstream LLMs and MLLMs on 90 biological motion
variants. Data analyses show that the crowd-sourced human votes are in good
agreement with those of expert raters, demonstrating the superiority of our
BioMotion Arena in offering discriminative feedback. We also find that over
90\% of evaluated models, including the cutting-edge open-source InternVL3 and
proprietary Claude-4 series, fail to produce fundamental humanoid point-light
groups, much less smooth and biologically plausible motions. This enables
BioMotion Arena to serve as a challenging benchmark for performance
visualization and a flexible evaluation framework without restrictions on
ground-truth.

</details>


### [40] [Towards MR-Based Trochleoplasty Planning](https://arxiv.org/abs/2508.06076)
*Michael Wehrli,Alicia Durrer,Paul Friedrich,Sidaty El Hadramy,Edwin Li,Luana Brahaj,Carol C. Hasler,Philippe C. Cattin*

Main category: cs.CV

TL;DR: 提出了一种基于临床MR扫描生成高分辨率3D伪健康目标形态的管道，用于治疗滑车发育不良（TD），无需CT扫描，减少了辐射。


<details>
  <summary>Details</summary>
Motivation: 当前治疗TD的方法依赖低分辨率MR扫描和外科医生的经验，导致手术效果不一致且微创技术应用有限。

Method: 使用隐式神经表示（INR）生成各向同性超分辨率MR体积，多标签网络分割骨骼，再通过小波扩散模型（WDM）生成伪健康目标形态。

Result: 在25名TD患者中验证，显著改善了滑车角度（SA）和滑车沟深度（TGD）。

Conclusion: 该方法为术前规划提供了高分辨率3D形态，减少了辐射，提高了手术效果。

Abstract: To treat Trochlear Dysplasia (TD), current approaches rely mainly on
low-resolution clinical Magnetic Resonance (MR) scans and surgical intuition.
The surgeries are planned based on surgeons experience, have limited adoption
of minimally invasive techniques, and lead to inconsistent outcomes. We propose
a pipeline that generates super-resolved, patient-specific 3D pseudo-healthy
target morphologies from conventional clinical MR scans. First, we compute an
isotropic super-resolved MR volume using an Implicit Neural Representation
(INR). Next, we segment femur, tibia, patella, and fibula with a multi-label
custom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to
generate pseudo-healthy target morphologies of the trochlear region. In
contrast to prior work producing pseudo-healthy low-resolution 3D MR images,
our approach enables the generation of sub-millimeter resolved 3D shapes
compatible for pre- and intraoperative use. These can serve as preoperative
blueprints for reshaping the femoral groove while preserving the native patella
articulation. Furthermore, and in contrast to other work, we do not require a
CT for our pipeline - reducing the amount of radiation. We evaluated our
approach on 25 TD patients and could show that our target morphologies
significantly improve the sulcus angle (SA) and trochlear groove depth (TGD).
The code and interactive visualization are available at
https://wehrlimi.github.io/sr-3d-planning/.

</details>


### [41] [DreamVE: Unified Instruction-based Image and Video Editing](https://arxiv.org/abs/2508.06080)
*Bin Xia,Jiyang Liu,Yuechen Zhang,Bohao Peng,Ruihang Chu,Yitong Wang,Xinglong Wu,Bei Yu,Jiaya Jia*

Main category: cs.CV

TL;DR: DreamVE是一个基于指令的图像和视频编辑统一模型，采用两阶段训练策略和综合数据合成方法，提升编辑性能。


<details>
  <summary>Details</summary>
Motivation: 指令式编辑潜力巨大，但视频编辑因数据不足受限。DreamVE旨在解决这一问题。

Method: 两阶段训练（先图像后视频），结合拼贴和生成模型数据合成，设计高效编辑框架。

Result: DreamVE在关键编辑类型表现优异，泛化能力强，但属性编辑性能稍弱。

Conclusion: DreamVE通过综合数据合成和高效框架，显著提升指令式编辑的实用性和性能。

Abstract: Instruction-based editing holds vast potential due to its simple and
efficient interactive editing format. However, instruction-based editing,
particularly for video, has been constrained by limited training data,
hindering its practical application. To this end, we introduce DreamVE, a
unified model for instruction-based image and video editing. Specifically, We
propose a two-stage training strategy: first image editing, then video editing.
This offers two main benefits: (1) Image data scales more easily, and models
are more efficient to train, providing useful priors for faster and better
video editing training. (2) Unifying image and video generation is natural and
aligns with current trends. Moreover, we present comprehensive training data
synthesis pipelines, including collage-based and generative model-based data
synthesis. The collage-based data synthesis combines foreground objects and
backgrounds to generate diverse editing data, such as object manipulation,
background changes, and text modifications. It can easily generate billions of
accurate, consistent, realistic, and diverse editing pairs. We pretrain DreamVE
on extensive collage-based data to achieve strong performance in key editing
types and enhance generalization and transfer capabilities. However,
collage-based data lacks some attribute editing cases, leading to a relative
drop in performance. In contrast, the generative model-based pipeline, despite
being hard to scale up, offers flexibility in handling attribute editing cases.
Therefore, we use generative model-based data to further fine-tune DreamVE.
Besides, we design an efficient and powerful editing framework for DreamVE. We
build on the SOTA T2V model and use a token concatenation with early drop
approach to inject source image guidance, ensuring strong consistency and
editability. The codes and models will be released.

</details>


### [42] [SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment](https://arxiv.org/abs/2508.06082)
*Yanxiao Sun,Jiafu Wu,Yun Cao,Chengming Xu,Yabiao Wang,Weijian Cao,Donghao Luo,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: SwiftVideo是一个结合轨迹保留和分布匹配优势的统一蒸馏框架，用于加速视频生成模型，减少推理步骤的同时保持高质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散或流的视频生成模型需要多次迭代采样，计算开销大；现有蒸馏方法在少步设置下性能下降或产生更多伪影。

Method: 提出连续时间一致性蒸馏确保ODE轨迹精确保留，引入双视角对齐（分布对齐和轨迹对齐）。

Result: 在OpenVid-1M基准测试中，SwiftVideo在少步视频生成上显著优于现有方法。

Conclusion: SwiftVideo通过统一框架解决了少步视频生成的性能问题，显著提升了效率和质量。

Abstract: Diffusion-based or flow-based models have achieved significant progress in
video synthesis but require multiple iterative sampling steps, which incurs
substantial computational overhead. While many distillation methods that are
solely based on trajectory-preserving or distribution-matching have been
developed to accelerate video generation models, these approaches often suffer
from performance breakdown or increased artifacts under few-step settings. To
address these limitations, we propose \textbf{\emph{SwiftVideo}}, a unified and
stable distillation framework that combines the advantages of
trajectory-preserving and distribution-matching strategies. Our approach
introduces continuous-time consistency distillation to ensure precise
preservation of ODE trajectories. Subsequently, we propose a dual-perspective
alignment that includes distribution alignment between synthetic and real data
along with trajectory alignment across different inference steps. Our method
maintains high-quality video generation while substantially reducing the number
of inference steps. Quantitative evaluations on the OpenVid-1M benchmark
demonstrate that our method significantly outperforms existing approaches in
few-step video generation.

</details>


### [43] [AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance](https://arxiv.org/abs/2508.06084)
*Weichen Zhang,Zhui Zhu,Ningbo Li,Kebin Liu,Yunhao Liu*

Main category: cs.CV

TL;DR: AdaptInfer是一种自适应视觉令牌修剪框架，通过动态文本引导和跨模态注意力分析，显著降低推理成本，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型（VLMs）在推理阶段因处理大量视觉令牌而成本高的问题，现有方法未能充分利用动态内部信号。

Method: 提出动态文本引导修剪机制和跨模态注意力分析，生成软优先级和高效修剪计划。

Result: 在LLaVA-1.5-7B上，CUDA延迟降低61.3%，平均精度保持92.9%，在相同令牌预算下超越SOTA。

Conclusion: AdaptInfer是一种轻量级、即插即用的通用方法，显著提升了VLMs的推理效率。

Abstract: Vision-language models (VLMs) have achieved impressive performance on
multimodal reasoning tasks such as visual question answering (VQA), but their
inference cost remains a significant challenge due to the large number of
vision tokens processed during the prefill stage. Existing pruning methods
often rely on directly using the attention patterns or static text prompt
guidance, failing to exploit the dynamic internal signals generated during
inference. To address these issues, we propose AdaptInfer, a plug-and-play
framework for adaptive vision token pruning in VLMs. First, we introduce a
fine-grained, dynamic text-guided pruning mechanism that reuses layer-wise
text-to-text attention maps to construct soft priors over text-token
importance, allowing more informed scoring of vision tokens at each stage.
Second, we perform an offline analysis of cross-modal attention shifts and
identify consistent inflection locations in inference, which inspire us to
propose a more principled and efficient pruning schedule. Our method is
lightweight and plug-and-play, also generalizable across multi-modal tasks.
Experimental results have verified the effectiveness of the proposed method.
For example, it reduces CUDA latency by 61.3\% while maintaining an average
accuracy of 92.9\% on vanilla LLaVA-1.5-7B. Under the same token budget,
AdaptInfer surpasses SOTA in accuracy.

</details>


### [44] [Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation](https://arxiv.org/abs/2508.06092)
*Yachun Mi,Yu Li,Yanting Li,Shixin Sun,Chen Hui,Tong Zhang,Yuanyuan Liu,Chenyue Song,Shaohui Liu*

Main category: cs.CV

TL;DR: Q-CLIP是一种基于视觉语言模型（VLM）的视频质量评估（VQA）框架，通过共享跨模态适配器（SCMA）和可学习质量提示提升性能，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有VQA方法依赖大规模预训练数据集，但存在语义知识迁移不足和计算资源消耗大的问题。

Method: 提出Q-CLIP框架，利用SCMA增强视觉和文本表示，引入可学习质量提示，并研究帧采样策略。

Result: Q-CLIP在多个VQA数据集上表现优异，计算成本显著降低。

Conclusion: Q-CLIP为VQA提供了一种高效且性能优越的解决方案，展示了VLM在质量评估中的潜力。

Abstract: Accurate and efficient Video Quality Assessment (VQA) has long been a key
research challenge. Current mainstream VQA methods typically improve
performance by pretraining on large-scale classification datasets (e.g.,
ImageNet, Kinetics-400), followed by fine-tuning on VQA datasets. However, this
strategy presents two significant challenges: (1) merely transferring semantic
knowledge learned from pretraining is insufficient for VQA, as video quality
depends on multiple factors (e.g., semantics, distortion, motion, aesthetics);
(2) pretraining on large-scale datasets demands enormous computational
resources, often dozens or even hundreds of times greater than training
directly on VQA datasets. Recently, Vision-Language Models (VLMs) have shown
remarkable generalization capabilities across a wide range of visual tasks, and
have begun to demonstrate promising potential in quality assessment. In this
work, we propose Q-CLIP, the first fully VLMs-based framework for VQA. Q-CLIP
enhances both visual and textual representations through a Shared Cross-Modal
Adapter (SCMA), which contains only a minimal number of trainable parameters
and is the only component that requires training. This design significantly
reduces computational cost. In addition, we introduce a set of five learnable
quality-level prompts to guide the VLMs in perceiving subtle quality
variations, thereby further enhancing the model's sensitivity to video quality.
Furthermore, we investigate the impact of different frame sampling strategies
on VQA performance, and find that frame-difference-based sampling leads to
better generalization performance across datasets. Extensive experiments
demonstrate that Q-CLIP exhibits excellent performance on several VQA datasets.

</details>


### [45] [E-React: Towards Emotionally Controlled Synthesis of Human Reactions](https://arxiv.org/abs/2508.06093)
*Chen Zhu,Buzhen Huang,Zijing Wu,Binghui Zuo,Yangang Wang*

Main category: cs.CV

TL;DR: 论文提出了一种新任务：基于情感线索生成多样化的反应动作，并通过半监督情感先验和扩散模型解决了现有方法忽略情感影响的问题。


<details>
  <summary>Details</summary>
Motivation: 情感在日常人际互动中至关重要，但现有动作生成框架未考虑情感影响，导致自然性不足，限制了在交互任务中的应用。

Method: 采用半监督学习训练情感先验，并结合扩散模型生成反应动作，同时考虑空间互动和情感响应。

Result: 实验表明，该方法在反应动作生成任务中优于现有方法。

Conclusion: 提出的方法能生成真实且情感驱动的反应动作，代码和数据将公开。

Abstract: Emotion serves as an essential component in daily human interactions.
Existing human motion generation frameworks do not consider the impact of
emotions, which reduces naturalness and limits their application in interactive
tasks, such as human reaction synthesis. In this work, we introduce a novel
task: generating diverse reaction motions in response to different emotional
cues. However, learning emotion representation from limited motion data and
incorporating it into a motion generation framework remains a challenging
problem. To address the above obstacles, we introduce a semi-supervised emotion
prior in an actor-reactor diffusion model to facilitate emotion-driven reaction
synthesis. Specifically, based on the observation that motion clips within a
short sequence tend to share the same emotion, we first devise a
semi-supervised learning framework to train an emotion prior. With this prior,
we further train an actor-reactor diffusion model to generate reactions by
considering both spatial interaction and emotional response. Finally, given a
motion sequence of an actor, our approach can generate realistic reactions
under various emotional conditions. Experimental results demonstrate that our
model outperforms existing reaction generation methods. The code and data will
be made publicly available at https://ereact.github.io/

</details>


### [46] [UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization](https://arxiv.org/abs/2508.06101)
*Yachun Mi,Xingyang He,Shixin Sun,Yu Li,Yanting Li,Zhixuan Li,Jian Jin,Chen Hui,Shaohui Liu*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的生成框架UGD-IML，首次将IML和CIML任务统一在一个框架中，减少了对大规模标注数据的依赖，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 数字时代中，高级图像编辑工具威胁视觉内容的真实性，现有IML方法依赖大规模标注数据，但数据集规模不足且多样性有限，CIML方法又因复杂流程效率低下。

Method: 基于扩散模型的生成框架UGD-IML，通过类嵌入机制和参数共享设计，统一IML和CIML任务，减少对标注数据的依赖，并实现端到端训练。

Result: 在多个数据集上，UGD-IML在IML和CIML任务的F1指标上分别平均优于SOTA方法9.66和4.36，并在不确定性估计、可视化和鲁棒性方面表现优异。

Conclusion: UGD-IML通过生成模型和高效设计，解决了现有方法的局限性，为图像篡改检测和定位提供了更优的解决方案。

Abstract: In the digital age, advanced image editing tools pose a serious threat to the
integrity of visual content, making image forgery detection and localization a
key research focus. Most existing Image Manipulation Localization (IML) methods
rely on discriminative learning and require large, high-quality annotated
datasets. However, current datasets lack sufficient scale and diversity,
limiting model performance in real-world scenarios. To overcome this, recent
studies have explored Constrained IML (CIML), which generates pixel-level
annotations through algorithmic supervision. However, existing CIML approaches
often depend on complex multi-stage pipelines, making the annotation process
inefficient. In this work, we propose a novel generative framework based on
diffusion models, named UGD-IML, which for the first time unifies both IML and
CIML tasks within a single framework. By learning the underlying data
distribution, generative diffusion models inherently reduce the reliance on
large-scale labeled datasets, allowing our approach to perform effectively even
under limited data conditions. In addition, by leveraging a class embedding
mechanism and a parameter-sharing design, our model seamlessly switches between
IML and CIML modes without extra components or training overhead. Furthermore,
the end-to-end design enables our model to avoid cumbersome steps in the data
annotation process. Extensive experimental results on multiple datasets
demonstrate that UGD-IML outperforms the SOTA methods by an average of 9.66 and
4.36 in terms of F1 metrics for IML and CIML tasks, respectively. Moreover, the
proposed method also excels in uncertainty estimation, visualization and
robustness.

</details>


### [47] [MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment](https://arxiv.org/abs/2508.06104)
*Gui Zou,Chaofan Gan,Chern Hong Lim,Supavadee Aramvith,Weiyao Lin*

Main category: cs.CV

TL;DR: 提出了一种名为MCA的鲁棒2D-3D跨模态检索框架，通过多模态联合标签校正和多层次自适应对齐，解决了噪声标签条件下的检索问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理噪声标签时容易过拟合，且未充分利用跨模态信息，因此需要一种更鲁棒的解决方案。

Method: 提出多模态联合标签校正（MJC）机制和多层次自适应对齐（MAA）策略，分别用于标签优化和特征增强。

Result: MCA在传统和噪声3D基准测试中均达到最优性能，验证了其有效性和泛化能力。

Conclusion: MCA框架通过联合校正和对齐策略，显著提升了噪声标签条件下的跨模态检索性能。

Abstract: With the increasing availability of 2D and 3D data, significant advancements
have been made in the field of cross-modal retrieval. Nevertheless, the
existence of imperfect annotations presents considerable challenges, demanding
robust solutions for 2D-3D cross-modal retrieval in the presence of noisy label
conditions. Existing methods generally address the issue of noise by dividing
samples independently within each modality, making them susceptible to
overfitting on corrupted labels. To address these issues, we propose a robust
2D-3D \textbf{M}ulti-level cross-modal adaptive \textbf{C}orrection and
\textbf{A}lignment framework (MCA). Specifically, we introduce a Multimodal
Joint label Correction (MJC) mechanism that leverages multimodal historical
self-predictions to jointly model the modality prediction consistency, enabling
reliable label refinement. Additionally, we propose a Multi-level Adaptive
Alignment (MAA) strategy to effectively enhance cross-modal feature semantics
and discrimination across different levels. Extensive experiments demonstrate
the superiority of our method, MCA, which achieves state-of-the-art performance
on both conventional and realistic noisy 3D benchmarks, highlighting its
generality and effectiveness.

</details>


### [48] [Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention](https://arxiv.org/abs/2508.06107)
*Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu*

Main category: cs.CV

TL;DR: 提出了一种自监督学习框架用于手写数学表达式识别，通过全局和局部对比损失预训练图像编码器，并引入渐进式空间掩码策略训练自监督注意力网络，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 手写数学表达式识别因二维结构、符号尺度变化和复杂空间关系而具有挑战性，传统方法依赖昂贵标注数据。本文旨在通过自监督学习减少对标注数据的依赖。

Method: 1. 使用全局和局部对比损失预训练图像编码器；2. 提出渐进式空间掩码策略训练自监督注意力网络；3. 结合监督微调生成LaTeX序列。

Result: 在CROHME基准测试中，该方法优于现有自监督和全监督基线，验证了渐进注意力机制的有效性。

Conclusion: 提出的自监督学习框架和渐进注意力机制显著提升了手写数学表达式识别的性能，减少了对标注数据的依赖。

Abstract: Recognizing handwritten mathematical expressions (HMER) is a challenging task
due to the inherent two-dimensional structure, varying symbol scales, and
complex spatial relationships among symbols. In this paper, we present a
self-supervised learning (SSL) framework for HMER that eliminates the need for
expensive labeled data. Our approach begins by pretraining an image encoder
using a combination of global and local contrastive loss, enabling the model to
learn both holistic and fine-grained representations. A key contribution of
this work is a novel self-supervised attention network, which is trained using
a progressive spatial masking strategy. This attention mechanism is designed to
learn semantically meaningful focus regions, such as operators, exponents, and
nested mathematical notation, without requiring any supervision. The
progressive masking curriculum encourages the network to become increasingly
robust to missing or occluded visual information, ultimately improving
structural understanding. Our complete pipeline consists of (1) self-supervised
pretraining of the encoder, (2) self-supervised attention learning, and (3)
supervised fine-tuning with a transformer decoder to generate LATEX sequences.
Extensive experiments on CROHME benchmarks demonstrate that our method
outperforms existing SSL and fully supervised baselines, validating the
effectiveness of our progressive attention mechanism in enhancing HMER
performance. Our codebase can be found here.

</details>


### [49] [FMCE-Net++: Feature Map Convergence Evaluation and Training](https://arxiv.org/abs/2508.06109)
*Zhibo Zhu,Renyu Huang,Lei He*

Main category: cs.CV

TL;DR: FMCE-Net++是一种新的训练框架，通过结合特征图收敛评分（FMCS）和任务标签，动态优化模型性能，无需架构修改或额外数据。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络（DNNs）因内部表示不透明而导致的解释性挑战，并弥补现有FMCE方法缺乏实验验证和闭环集成的不足。

Method: 提出FMCE-Net++框架，集成预训练的FMCE-Net作为辅助头，生成FMCS预测，并通过表示辅助损失（RAL）动态平衡分类损失和特征收敛优化。

Result: 在多个数据集（如MNIST、CIFAR-10等）上验证，FMCE-Net++显著提升模型性能（如ResNet-50/CIFAR-10准确率提升1.16个百分点）。

Conclusion: FMCE-Net++能有效提升模型性能，无需额外资源，为DNNs的优化提供了新思路。

Abstract: Deep Neural Networks (DNNs) face interpretability challenges due to their
opaque internal representations. While Feature Map Convergence Evaluation
(FMCE) quantifies module-level convergence via Feature Map Convergence Scores
(FMCS), it lacks experimental validation and closed-loop integration. To
address this limitation, we propose FMCE-Net++, a novel training framework that
integrates a pretrained, frozen FMCE-Net as an auxiliary head. This module
generates FMCS predictions, which, combined with task labels, jointly supervise
backbone optimization through a Representation Auxiliary Loss. The RAL
dynamically balances the primary classification loss and feature convergence
optimization via a tunable \Representation Abstraction Factor. Extensive
experiments conducted on MNIST, CIFAR-10, FashionMNIST, and CIFAR-100
demonstrate that FMCE-Net++ consistently enhances model performance without
architectural modifications or additional data. Key experimental outcomes
include accuracy gains of $+1.16$ pp (ResNet-50/CIFAR-10) and $+1.08$ pp
(ShuffleNet v2/CIFAR-100), validating that FMCE-Net++ can effectively elevate
state-of-the-art performance ceilings.

</details>


### [50] [GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.06113)
*Jian Wang,Chaokang Jiang,Haitao Xu*

Main category: cs.CV

TL;DR: GMF-Drive提出了一种基于门控Mamba融合的端到端自动驾驶框架，通过几何增强的LiDAR表示和高效的BEV-SSM模型，克服了传统Transformer的局限性，并在NAVSIM基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于Transformer的融合方法在自动驾驶中存在计算复杂度高和空间先验缺失的问题，限制了高分辨率特征的使用和BEV表示的有效建模。

Method: 1. 使用几何增强的柱状LiDAR表示替代直方图表示；2. 提出门控Mamba融合架构（GM-Fusion），用高效的BEV-SSM替代Transformer。

Result: 在NAVSIM基准测试中，GMF-Drive显著优于DiffusionDrive，验证了其性能和效率优势。

Conclusion: 任务特定的SSM在自动驾驶中优于通用Transformer，GMF-Drive为端到端自动驾驶提供了更高效的解决方案。

Abstract: Diffusion-based models are redefining the state-of-the-art in end-to-end
autonomous driving, yet their performance is increasingly hampered by a
reliance on transformer-based fusion. These architectures face fundamental
limitations: quadratic computational complexity restricts the use of
high-resolution features, and a lack of spatial priors prevents them from
effectively modeling the inherent structure of Bird's Eye View (BEV)
representations. This paper introduces GMF-Drive (Gated Mamba Fusion for
Driving), an end-to-end framework that overcomes these challenges through two
principled innovations. First, we supersede the information-limited
histogram-based LiDAR representation with a geometrically-augmented pillar
format encoding shape descriptors and statistical features, preserving critical
3D geometric details. Second, we propose a novel hierarchical gated mamba
fusion (GM-Fusion) architecture that substitutes an expensive transformer with
a highly efficient, spatially-aware state-space model (SSM). Our core BEV-SSM
leverages directional sequencing and adaptive fusion mechanisms to capture
long-range dependencies with linear complexity, while explicitly respecting the
unique spatial properties of the driving scene. Extensive experiments on the
challenging NAVSIM benchmark demonstrate that GMF-Drive achieves a new
state-of-the-art performance, significantly outperforming DiffusionDrive.
Comprehensive ablation studies validate the efficacy of each component,
demonstrating that task-specific SSMs can surpass a general-purpose transformer
in both performance and efficiency for autonomous driving.

</details>


### [51] [SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.06115)
*Weichen Zhang,Kebin Liu,Fan Dang,Zhui Zhu,Xikai Sun,Yunhao Liu*

Main category: cs.CV

TL;DR: SynSeg提出了一种弱监督方法，通过多类别对比学习（MCCL）和特征协同结构（FSS）解决开放词汇语义分割中的语义对齐问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 开放词汇语义分割面临语义类别广泛且细粒度的挑战，现有弱监督方法依赖类别特定监督和不适用的特征构建方法，导致语义错位和性能不佳。

Method: SynSeg采用MCCL策略结合FSS框架，通过多类别对比学习和特征重构提升语义定位和区分能力。

Result: 在多个基准测试中，SynSeg表现优于现有方法，如VOC上准确率提升4.5%，Context上提升8.9%。

Conclusion: SynSeg通过MCCL和FSS有效解决了弱监督下的语义分割问题，显著提升了性能。

Abstract: Semantic segmentation in open-vocabulary scenarios presents significant
challenges due to the wide range and granularity of semantic categories.
Existing weakly-supervised methods often rely on category-specific supervision
and ill-suited feature construction methods for contrastive learning, leading
to semantic misalignment and poor performance. In this work, we propose a novel
weakly-supervised approach, SynSeg, to address the challenges. SynSeg performs
Multi-Category Contrastive Learning (MCCL) as a stronger training signal with a
new feature reconstruction framework named Feature Synergy Structure (FSS).
Specifically, MCCL strategy robustly combines both intra- and inter-category
alignment and separation in order to make the model learn the knowledge of
correlations from different categories within the same image. Moreover, FSS
reconstructs discriminative features for contrastive learning through prior
fusion and semantic-activation-map enhancement, effectively avoiding the
foreground bias introduced by the visual encoder. In general, SynSeg
effectively improves the abilities in semantic localization and discrimination
under weak supervision. Extensive experiments on benchmarks demonstrate that
our method outperforms state-of-the-art (SOTA) performance. For instance,
SynSeg achieves higher accuracy than SOTA baselines by 4.5\% on VOC, 8.9\% on
Context, 2.6\% on Object and 2.0\% on City.

</details>


### [52] [Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events](https://arxiv.org/abs/2508.06122)
*Ting-Shuo Yo,Shih-Hao Su,Chien-Ming Wu,Wei-Ting Chen,Jung-Lien Chu,Chiao-Wei Chang,Hung-Chi Kuo*

Main category: cs.CV

TL;DR: 研究比较了PCA、CAE和预训练残差网络在卫星图像表示学习中的表现，发现CAE在分类任务中表现最佳，但缺乏物理可解释性。


<details>
  <summary>Details</summary>
Motivation: 探索不同表示学习算法在卫星图像天气事件分类中的效果，并评估其潜在空间的性能。

Method: 使用PCA、CAE和预训练残差网络（PT）学习卫星图像的潜在表示，并进行分类任务评估。

Result: CAE在所有分类任务中表现最优，PCA命中率高但误报率也高，PT在热带气旋识别中表现突出。高分辨率数据对深度学习算法更有利。

Conclusion: CAE高效学习潜在空间，但缺乏物理可解释性，未来可开发物理信息增强的CAE。

Abstract: This study applied representation learning algorithms to satellite images and
evaluated the learned latent spaces with classifications of various weather
events. The algorithms investigated include the classical linear
transformation, i.e., principal component analysis (PCA), state-of-the-art deep
learning method, i.e., convolutional autoencoder (CAE), and a residual network
pre-trained with large image datasets (PT). The experiment results indicated
that the latent space learned by CAE consistently showed higher threat scores
for all classification tasks. The classifications with PCA yielded high hit
rates but also high false-alarm rates. In addition, the PT performed
exceptionally well at recognizing tropical cyclones but was inferior in other
tasks. Further experiments suggested that representations learned from
higher-resolution datasets are superior in all classification tasks for
deep-learning algorithms, i.e., CAE and PT. We also found that smaller latent
space sizes had minor impact on the classification task's hit rate. Still, a
latent space dimension smaller than 128 caused a significantly higher false
alarm rate. Though the CAE can learn latent spaces effectively and efficiently,
the interpretation of the learned representation lacks direct connections to
physical attributions. Therefore, developing a physics-informed version of CAE
can be a promising outlook for the current work.

</details>


### [53] [SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning](https://arxiv.org/abs/2508.06125)
*Lin Zhang,Xianfang Zeng,Kangcong Li,Gang Yu,Tao Chen*

Main category: cs.CV

TL;DR: SC-Captioner是一个强化学习框架，通过设计奖励函数实现图像描述模型的自我纠正能力，显著提升生成描述的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有图像描述模型缺乏自我纠正能力，导致生成的描述可能不准确或不完整。

Method: 利用场景图解析算法分解描述为对象、属性和关系集合，通过集合差异计算奖励函数，激励准确纠正。

Result: 实验表明，SC-Captioner在多种场景下生成更优描述，显著优于直接偏好优化训练策略。

Conclusion: SC-Captioner通过自我纠正机制和精细化的奖励设计，有效提升了图像描述的质量。

Abstract: We propose SC-Captioner, a reinforcement learning framework that enables the
self-correcting capability of image caption models. Our crucial technique lies
in the design of the reward function to incentivize accurate caption
corrections. Specifically, the predicted and reference captions are decomposed
into object, attribute, and relation sets using scene-graph parsing algorithms.
We calculate the set difference between sets of initial and self-corrected
captions to identify added and removed elements. These elements are matched
against the reference sets to calculate correctness bonuses for accurate
refinements and mistake punishments for wrong additions and removals, thereby
forming the final reward. For image caption quality assessment, we propose a
set of metrics refined from CAPTURE that alleviate its incomplete precision
evaluation and inefficient relation matching problems. Furthermore, we collect
a fine-grained annotated image caption dataset, RefinedCaps, consisting of 6.5K
diverse images from COCO dataset. Experiments show that applying SC-Captioner
on large visual-language models can generate better image captions across
various scenarios, significantly outperforming the direct preference
optimization training strategy.

</details>


### [54] [SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures](https://arxiv.org/abs/2508.06127)
*Yi Qin,Rui Wang,Tao Huang,Tong Xiao,Liping Jing*

Main category: cs.CV

TL;DR: VeSCA方法通过参数化单纯复形识别SAM与下游模型的共享脆弱区域，生成可转移对抗样本，性能提升12.7%。


<details>
  <summary>Details</summary>
Motivation: 评估SAM的潜在漏洞对下游应用的影响，解决现有对抗攻击方法转移性不足的问题。

Method: 利用SAM编码器生成对抗样本，通过迭代顶点优化和轻量级域适应策略识别共享脆弱区域。

Result: 在五个领域数据集上，VeSCA性能比现有方法提升12.7%。

Conclusion: SAM的漏洞对下游模型构成风险，需开发更鲁棒的基础模型。

Abstract: While the Segment Anything Model (SAM) transforms interactive segmentation
with zero-shot abilities, its inherent vulnerabilities present a single-point
risk, potentially leading to the failure of numerous downstream applications.
Proactively evaluating these transferable vulnerabilities is thus imperative.
Prior adversarial attacks on SAM often present limited transferability due to
insufficient exploration of common weakness across domains. To address this, we
propose Vertex-Refining Simplicial Complex Attack (VeSCA), a novel method that
leverages only the encoder of SAM for generating transferable adversarial
examples. Specifically, it achieves this by explicitly characterizing the
shared vulnerable regions between SAM and downstream models through a
parametric simplicial complex. Our goal is to identify such complexes within
adversarially potent regions by iterative vertex-wise refinement. A lightweight
domain re-adaptation strategy is introduced to bridge domain divergence using
minimal reference data during the initialization of simplicial complex.
Ultimately, VeSCA generates consistently transferable adversarial examples
through random simplicial complex sampling. Extensive experiments demonstrate
that VeSCA achieves performance improved by 12.7% compared to state-of-the-art
methods across three downstream model categories across five domain-specific
datasets. Our findings further highlight the downstream model risks posed by
SAM's vulnerabilities and emphasize the urgency of developing more robust
foundation models.

</details>


### [55] [Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation](https://arxiv.org/abs/2508.06136)
*YoungChan Choi,HengFei Wang,YiHua Cheng,Boeun Kim,Hyung Jin Chang,YoungGeun Choi,Sang-Il Choi*

Main category: cs.CV

TL;DR: 提出了一种基于3D眼球结构的视线重定向框架，通过3D高斯泼溅（3DGS）显式建模眼球旋转和平移，生成高质量图像，并引入自适应变形模块模拟眼部肌肉运动。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经辐射场（NeRF）的方法未显式建模3D结构的旋转和平移，限制了视线重定向的精确性和真实性。

Method: 使用3D高斯泼溅（3DGS）显式建模眼球结构，结合自适应变形模块模拟眼部肌肉运动。

Result: 在ETH-XGaze数据集上实验表明，该方法生成的图像质量和视线估计精度优于现有方法。

Conclusion: 显式3D眼球结构和自适应变形模块显著提升了视线重定向的逼真度和准确性。

Abstract: We propose a novel 3D gaze redirection framework that leverages an explicit
3D eyeball structure. Existing gaze redirection methods are typically based on
neural radiance fields, which employ implicit neural representations via volume
rendering. Unlike these NeRF-based approaches, where the rotation and
translation of 3D representations are not explicitly modeled, we introduce a
dedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian
Splatting (3DGS). Our method generates photorealistic images that faithfully
reproduce the desired gaze direction by explicitly rotating and translating the
3D eyeball structure. In addition, we propose an adaptive deformation module
that enables the replication of subtle muscle movements around the eyes.
Through experiments conducted on the ETH-XGaze dataset, we demonstrate that our
framework is capable of generating diverse novel gaze images, achieving
superior image quality and gaze estimation accuracy compared to previous
state-of-the-art methods.

</details>


### [56] [DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera](https://arxiv.org/abs/2508.06139)
*Shaohua Pan,Xinyu Yi,Yan Zhou,Weihua Jian,Yuan Zhang,Pengfei Wan,Feng Xu*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的方法，结合稀疏IMU和单目摄像头进行实时人体运动捕捉，通过融合两种信号模态提升性能。


<details>
  <summary>Details</summary>
Motivation: 结合稀疏IMU和单目摄像头进行实时运动捕捉是一个有前景的方向，但需要解决视觉信息偶尔缺失和IMU信号时序信息利用的问题。

Method: 将视觉信息整体转化为条件嵌入，同时逐帧结合IMU测量和噪声姿态作为扩散模型的输入。

Result: 实验证明该方法在姿态估计上表现优异，达到当前最佳性能。

Conclusion: 提出的框架有效融合了两种信号模态，解决了视觉信息不稳定的问题，并充分利用了IMU的时序信息。

Abstract: Combining sparse IMUs and a monocular camera is a new promising setting to
perform real-time human motion capture. This paper proposes a diffusion-based
solution to learn human motion priors and fuse the two modalities of signals
together seamlessly in a unified framework. By delicately considering the
characteristics of the two signals, the sequential visual information is
considered as a whole and transformed into a condition embedding, while the
inertial measurement is concatenated with the noisy body pose frame by frame to
construct a sequential input for the diffusion model. Firstly, we observe that
the visual information may be unavailable in some frames due to occlusions or
subjects moving out of the camera view. Thus incorporating the sequential
visual features as a whole to get a single feature embedding is robust to the
occasional degenerations of visual information in those frames. On the other
hand, the IMU measurements are robust to occlusions and always stable when
signal transmission has no problem. So incorporating them frame-wisely could
better explore the temporal information for the system. Experiments have
demonstrated the effectiveness of the system design and its state-of-the-art
performance in pose estimation compared with the previous works. Our codes are
available for research at https://shaohua-pan.github.io/diffcap-page.

</details>


### [57] [SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models](https://arxiv.org/abs/2508.06142)
*Hanqing Wang,Yuan Tian,Mingyu Liu,Zhenhao Zhang,Xiangyang Zhu*

Main category: cs.CV

TL;DR: SDEval是一个动态安全评估框架，通过调整安全基准的分布和复杂性来解决多模态大语言模型（MLLMs）的安全问题。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs的发展，现有安全数据集可能过时且易受数据污染，需要动态评估框架来解决这些问题。

Method: SDEval采用文本、图像和文本-图像动态策略生成新样本，并研究其对模型安全的影响。

Result: 实验表明，SDEval显著影响安全评估，缓解数据污染，并暴露MLLMs的安全限制。

Conclusion: SDEval是一个通用的动态评估框架，适用于现有安全和能力基准。

Abstract: In the rapidly evolving landscape of Multimodal Large Language Models
(MLLMs), the safety concerns of their outputs have earned significant
attention. Although numerous datasets have been proposed, they may become
outdated with MLLM advancements and are susceptible to data contamination
issues. To address these problems, we propose \textbf{SDEval}, the
\textit{first} safety dynamic evaluation framework to controllably adjust the
distribution and complexity of safety benchmarks. Specifically, SDEval mainly
adopts three dynamic strategies: text, image, and text-image dynamics to
generate new samples from original benchmarks. We first explore the individual
effects of text and image dynamics on model safety. Then, we find that
injecting text dynamics into images can further impact safety, and conversely,
injecting image dynamics into text also leads to safety risks. SDEval is
general enough to be applied to various existing safety and even capability
benchmarks. Experiments across safety benchmarks, MLLMGuard and VLSBench, and
capability benchmarks, MMBench and MMVet, show that SDEval significantly
influences safety evaluation, mitigates data contamination, and exposes safety
limitations of MLLMs. Code is available at https://github.com/hq-King/SDEval

</details>


### [58] [Text-guided Visual Prompt DINO for Generic Segmentation](https://arxiv.org/abs/2508.06146)
*Yuchen Guan,Chong Sun,Canmiao Fu,Zhipeng Huang,Chun Yuan,Chen Li*

Main category: cs.CV

TL;DR: Prompt-DINO是一个文本引导的视觉Prompt DINO框架，通过早期融合机制、顺序对齐查询选择和生成数据引擎，解决了多模态视觉模型中的特征融合和查询选择问题，并在开放世界检测中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在晚期特征融合、查询选择优化和固定词汇限制方面存在不足，Prompt-DINO旨在解决这些问题。

Method: 1. 早期融合机制统一文本/视觉提示和主干特征；2. 顺序对齐查询选择优化文本与视觉查询的结构对齐；3. 生成数据引擎通过双路径交叉验证合成训练数据。

Result: Prompt-DINO在开放世界检测基准上达到最先进性能，语义覆盖范围显著扩大，标签噪声减少80.5%。

Conclusion: Prompt-DINO为开放世界场景中的可扩展多模态检测和数据生成建立了新范式。

Abstract: Recent advancements in multimodal vision models have highlighted limitations
in late-stage feature fusion and suboptimal query selection for hybrid prompts
open-world segmentation, alongside constraints from caption-derived
vocabularies. To address these challenges, we propose Prompt-DINO, a
text-guided visual Prompt DINO framework featuring three key innovations.
First, we introduce an early fusion mechanism that unifies text/visual prompts
and backbone features at the initial encoding stage, enabling deeper
cross-modal interactions to resolve semantic ambiguities. Second, we design
order-aligned query selection for DETR-based architectures, explicitly
optimizing the structural alignment between text and visual queries during
decoding to enhance semantic-spatial consistency. Third, we develop a
generative data engine powered by the Recognize Anything via Prompting (RAP)
model, which synthesizes 0.5B diverse training instances through a dual-path
cross-verification pipeline, reducing label noise by 80.5% compared to
conventional approaches. Extensive experiments demonstrate that Prompt-DINO
achieves state-of-the-art performance on open-world detection benchmarks while
significantly expanding semantic coverage beyond fixed-vocabulary constraints.
Our work establishes a new paradigm for scalable multimodal detection and data
generation in open-world scenarios. Data&Code are available at
https://github.com/WeChatCV/WeVisionOne.

</details>


### [59] [DSConv: Dynamic Splitting Convolution for Pansharpening](https://arxiv.org/abs/2508.06147)
*Xuanyu Liu,Bonan An*

Main category: cs.CV

TL;DR: 提出了一种名为DSConv的动态卷积核分割方法，结合注意力机制提升图像融合效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法多依赖标准卷积，而自适应卷积能更好地利用遥感图像的像素相关性。

Method: 动态分割卷积核并结合注意力机制，选择感兴趣位置，将原始卷积核分割为多个小核。

Result: DSConv能更有效地提取特征，提升网络性能，实验证明其效果优越。

Conclusion: DSConv在图像融合任务中表现出色，具有优越性和广泛适用性。

Abstract: Aiming to obtain a high-resolution image, pansharpening involves the fusion
of a multi-spectral image (MS) and a panchromatic image (PAN), the low-level
vision task remaining significant and challenging in contemporary research.
Most existing approaches rely predominantly on standard convolutions, few
making the effort to adaptive convolutions, which are effective owing to the
inter-pixel correlations of remote sensing images. In this paper, we propose a
novel strategy for dynamically splitting convolution kernels in conjunction
with attention, selecting positions of interest, and splitting the original
convolution kernel into multiple smaller kernels, named DSConv. The proposed
DSConv more effectively extracts features of different positions within the
receptive field, enhancing the network's generalization, optimization, and
feature representation capabilities. Furthermore, we innovate and enrich
concepts of dynamic splitting convolution and provide a novel network
architecture for pansharpening capable of achieving the tasks more efficiently,
building upon this methodology. Adequate fair experiments illustrate the
effectiveness and the state-of-the-art performance attained by
DSConv.Comprehensive and rigorous discussions proved the superiority and
optimal usage conditions of DSConv.

</details>


### [60] [VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation](https://arxiv.org/abs/2508.06152)
*Kaiyuan Jiang,Ruoxi Sun,Ying Cao,Yuqi Xu,Xinran Zhang,Junyan Guo,ChengSheng Deng*

Main category: cs.CV

TL;DR: VISTAR是一个用户中心的多维度文本到图像（T2I）评估基准，结合确定性指标和新型层次加权P/N提问（HWPQ）方案，显著提升评估准确性。


<details>
  <summary>Details</summary>
Motivation: 现有T2I评估指标存在局限性，VISTAR旨在通过多维度、用户中心的方法解决这一问题。

Method: 采用两层次混合范式：确定性指标量化物理属性，HWPQ方案评估抽象语义。基于专家研究定义用户角色和评估角度。

Result: VISTAR指标与人类评估高度一致（>75%），HWPQ在抽象语义上达到85.9%准确率，显著优于基线。

Conclusion: VISTAR提供了可复现的T2I评估资源，揭示不同模型在不同领域表现各异，为实际部署提供指导。

Abstract: We present VISTAR, a user-centric, multi-dimensional benchmark for
text-to-image (T2I) evaluation that addresses the limitations of existing
metrics. VISTAR introduces a two-tier hybrid paradigm: it employs
deterministic, scriptable metrics for physically quantifiable attributes (e.g.,
text rendering, lighting) and a novel Hierarchical Weighted P/N Questioning
(HWPQ) scheme that uses constrained vision-language models to assess abstract
semantics (e.g., style fusion, cultural fidelity). Grounded in a Delphi study
with 120 experts, we defined seven user roles and nine evaluation angles to
construct the benchmark, which comprises 2,845 prompts validated by over 15,000
human pairwise comparisons. Our metrics achieve high human alignment (>75%),
with the HWPQ scheme reaching 85.9% accuracy on abstract semantics,
significantly outperforming VQA baselines. Comprehensive evaluation of
state-of-the-art models reveals no universal champion, as role-weighted scores
reorder rankings and provide actionable guidance for domain-specific
deployment. All resources are publicly released to foster reproducible T2I
assessment.

</details>


### [61] [An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06157)
*Xiaoxiao Yang,Meiliang Liu,Yunfang Xu,Zijin Li,Zhengye Si,Xinyue Yang,Zhiwen Zhao*

Main category: cs.CV

TL;DR: MPF-KANSC框架通过多平面融合和KANSC注意力机制，提升了阿尔茨海默病诊断的准确性，并揭示了右脑皮层结构变化的偏侧性。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）的早期精确诊断困难，现有深度学习方法难以捕捉脑部复杂非线性关系。

Method: 提出MPF-KANSC框架，结合多平面融合和KANSC注意力机制，并行提取特征并精确识别病变。

Result: 在ADNI数据集上表现优异，并发现AD进展中右脑皮层结构变化的偏侧性。

Conclusion: MPF-KANSC显著提升AD诊断性能，具有良好可解释性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder that
severely impairs cognitive function and quality of life. Timely intervention in
AD relies heavily on early and precise diagnosis, which remains challenging due
to the complex and subtle structural changes in the brain. Most existing deep
learning methods focus only on a single plane of structural magnetic resonance
imaging (sMRI) and struggle to accurately capture the complex and nonlinear
relationships among pathological regions of the brain, thus limiting their
ability to precisely identify atrophic features. To overcome these limitations,
we propose an innovative framework, MPF-KANSC, which integrates multi-plane
fusion (MPF) for combining features from the coronal, sagittal, and axial
planes, and a Kolmogorov-Arnold Network-guided spatial-channel attention
mechanism (KANSC) to more effectively learn and represent sMRI atrophy
features. Specifically, the proposed model enables parallel feature extraction
from multiple anatomical planes, thus capturing more comprehensive structural
information. The KANSC attention mechanism further leverages a more flexible
and accurate nonlinear function approximation technique, facilitating precise
identification and localization of disease-related abnormalities. Experiments
on the ADNI dataset confirm that the proposed MPF-KANSC achieves superior
performance in AD diagnosis. Moreover, our findings provide new evidence of
right-lateralized asymmetry in subcortical structural changes during AD
progression, highlighting the model's promising interpretability.

</details>


### [62] [Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment](https://arxiv.org/abs/2508.06160)
*Zhenbang Du,Yonggan Fu,Lifu Wang,Jiayi Qian,Xiao Luo,Yingyan,Lin*

Main category: cs.CV

TL;DR: PostDiff是一个无需训练的框架，通过减少输入和模块级别的冗余，加速预训练扩散模型，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成任务中表现出色，但计算成本高，限制了在资源有限平台上的部署。本文研究在不进行微调的情况下，如何更有效地优化计算资源。

Method: 提出PostDiff框架，包括混合分辨率去噪方案和混合模块缓存策略，以减少输入和模块级别的冗余。

Result: 实验表明，PostDiff显著改善了扩散模型的保真度与效率权衡，且降低每步推理成本比减少去噪步骤更有效。

Conclusion: PostDiff为预训练扩散模型的高效部署提供了一种无需训练的有效方法，尤其适合资源受限的环境。

Abstract: Diffusion models have shown remarkable success across generative tasks, yet
their high computational demands challenge deployment on resource-limited
platforms. This paper investigates a critical question for compute-optimal
diffusion model deployment: Under a post-training setting without fine-tuning,
is it more effective to reduce the number of denoising steps or to use a
cheaper per-step inference? Intuitively, reducing the number of denoising steps
increases the variability of the distributions across steps, making the model
more sensitive to compression. In contrast, keeping more denoising steps makes
the differences smaller, preserving redundancy, and making post-training
compression more feasible. To systematically examine this, we propose PostDiff,
a training-free framework for accelerating pre-trained diffusion models by
reducing redundancy at both the input level and module level in a post-training
manner. At the input level, we propose a mixed-resolution denoising scheme
based on the insight that reducing generation resolution in early denoising
steps can enhance low-frequency components and improve final generation
fidelity. At the module level, we employ a hybrid module caching strategy to
reuse computations across denoising steps. Extensive experiments and ablation
studies demonstrate that (1) PostDiff can significantly improve the
fidelity-efficiency trade-off of state-of-the-art diffusion models, and (2) to
boost efficiency while maintaining decent generation fidelity, reducing
per-step inference cost is often more effective than reducing the number of
denoising steps. Our code is available at
https://github.com/GATECH-EIC/PostDiff.

</details>


### [63] [UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting](https://arxiv.org/abs/2508.06169)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Changting Lin,Jianfeng Dong,Chaochao Chen,Xun Zhou,Meng Han*

Main category: cs.CV

TL;DR: UW-3DGS是一种基于3D高斯泼溅的框架，用于水下3D场景重建，解决了传统方法在浑浊环境中的几何和颜色保真度问题。


<details>
  <summary>Details</summary>
Motivation: 水下环境的光吸收、散射和浑浊导致传统方法（如NeRF）在几何和颜色保真度上表现不佳。

Method: 采用3D高斯泼溅（3DGS）框架，结合可学习的水下图像形成模块和物理感知不确定性剪枝（PAUP）分支。

Result: 在SeaThru-NeRF和UWBundle数据集上表现优异，PSNR为27.604，SSIM为0.868，LPIPS为0.104，浮动物体减少约65%。

Conclusion: UW-3DGS通过结合物理模型和高效剪枝策略，显著提升了水下场景重建的质量和效率。

Abstract: Underwater 3D scene reconstruction faces severe challenges from light
absorption, scattering, and turbidity, which degrade geometry and color
fidelity in traditional methods like Neural Radiance Fields (NeRF). While NeRF
extensions such as SeaThru-NeRF incorporate physics-based models, their MLP
reliance limits efficiency and spatial resolution in hazy environments. We
introduce UW-3DGS, a novel framework adapting 3D Gaussian Splatting (3DGS) for
robust underwater reconstruction. Key innovations include: (1) a plug-and-play
learnable underwater image formation module using voxel-based regression for
spatially varying attenuation and backscatter; and (2) a Physics-Aware
Uncertainty Pruning (PAUP) branch that adaptively removes noisy floating
Gaussians via uncertainty scoring, ensuring artifact-free geometry. The
pipeline operates in training and rendering stages. During training, noisy
Gaussians are optimized end-to-end with underwater parameters, guided by PAUP
pruning and scattering modeling. In rendering, refined Gaussians produce clean
Unattenuated Radiance Images (URIs) free from media effects, while learned
physics enable realistic Underwater Images (UWIs) with accurate light
transport. Experiments on SeaThru-NeRF and UWBundle datasets show superior
performance, achieving PSNR of 27.604, SSIM of 0.868, and LPIPS of 0.104 on
SeaThru-NeRF, with ~65% reduction in floating artifacts.

</details>


### [64] [Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation](https://arxiv.org/abs/2508.06170)
*Ojonugwa Oluwafemi Ejiga Peter,Akingbola Oluwapemiisin,Amalahu Chetachi,Adeniran Opeyemi,Fahmi Khalifa,Md Mahmudur Rahman*

Main category: cs.CV

TL;DR: 论文提出了一种多方向架构框架，用于自动化结肠镜图像中的息肉检测，结合合成数据生成和检测分割算法，显著提升了检测和分割性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜检查是结直肠癌早期诊断的关键工具，但医疗数据集有限且标注复杂，因此需要自动化解决方案。

Method: 采用Faster R-CNN进行初始目标定位，结合Segment Anything Model（SAM）优化分割掩码，并评估了五种分割模型。

Result: Faster R-CNN召回率93.08%，精度88.97%；FPN在PSNR和SSIM上表现最佳，UNet在召回率上领先。

Conclusion: 该框架有效解决了数据集和标注问题，显著提升了息肉检测和分割的准确性和效率。

Abstract: Colonoscopy is a vital tool for the early diagnosis of colorectal cancer,
which is one of the main causes of cancer-related mortality globally; hence, it
is deemed an essential technique for the prevention and early detection of
colorectal cancer. The research introduces a unique multidirectional
architectural framework to automate polyp detection within colonoscopy images
while helping resolve limited healthcare dataset sizes and annotation
complexities. The research implements a comprehensive system that delivers
synthetic data generation through Stable Diffusion enhancements together with
detection and segmentation algorithms. This detection approach combines Faster
R-CNN for initial object localization while the Segment Anything Model (SAM)
refines the segmentation masks. The faster R-CNN detection algorithm achieved a
recall of 93.08% combined with a precision of 88.97% and an F1 score of
90.98%.SAM is then used to generate the image mask. The research evaluated five
state-of-the-art segmentation models that included U-Net, PSPNet, FPN, LinkNet,
and MANet using ResNet34 as a base model. The results demonstrate the superior
performance of FPN with the highest scores of PSNR (7.205893) and SSIM
(0.492381), while UNet excels in recall (84.85%) and LinkNet shows balanced
performance in IoU (64.20%) and Dice score (77.53%).

</details>


### [65] [Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor](https://arxiv.org/abs/2508.06177)
*Dominik Brämer,Diana Kleingarn,Oliver Urbann*

Main category: cs.CV

TL;DR: 提出了一种基于地板特征和图卷积网络（GCNs）的机器人定位框架，比传统方法更精确（误差0.64cm）且高效，同时解决了绑架机器人问题。


<details>
  <summary>Details</summary>
Motivation: 传统定位方法（如激光雷达或二维码）在复杂环境中存在可扩展性和适应性不足的问题，需要更创新的解决方案。

Method: 利用图表示地板特征，结合图卷积网络（GCNs）进行定位，避免复杂的滤波过程。

Result: 定位误差仅为0.64cm，且每帧都能解决绑架机器人问题。

Conclusion: 该方法为复杂环境中的机器人导航提供了新的可能性。

Abstract: Accurate localization represents a fundamental challenge in
  robotic navigation. Traditional methodologies, such as Lidar or QR-code based
systems, suffer from inherent scalability and adaptability con straints,
particularly in complex environments. In this work, we propose
  an innovative localization framework that harnesses flooring characteris tics
by employing graph-based representations and Graph Convolutional
  Networks (GCNs). Our method uses graphs to represent floor features,
  which helps localize the robot more accurately (0.64cm error) and more
  efficiently than comparing individual image features. Additionally, this
  approach successfully addresses the kidnapped robot problem in every
  frame without requiring complex filtering processes. These advancements
  open up new possibilities for robotic navigation in diverse environments.

</details>


### [66] [MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration](https://arxiv.org/abs/2508.06189)
*Cheng Liu,Daou Zhang,Tingxu Liu,Yuhan Wang,Jinyang Chen,Yuexuan Li,Xinying Xiao,Chenbo Xin,Ziru Wang,Weichao Wu*

Main category: cs.CV

TL;DR: 提出MA-CBP框架，基于多智能体异步协作预测犯罪行为，结合实时视频流和历史信息，实现高效预警。


<details>
  <summary>Details</summary>
Motivation: 城市化加速导致公共场景犯罪威胁增加，传统方法难以捕捉高层次行为语义或满足实时需求。

Method: 将视频流转为语义描述，构建因果一致的历史摘要，融合图像帧进行长短期上下文联合推理。

Result: 在多个数据集上表现优异，为城市公共安全提供有效风险预警解决方案。

Conclusion: MA-CBP框架在犯罪行为预测和公共安全预警方面具有显著优势和应用潜力。

Abstract: With the acceleration of urbanization, criminal behavior in public scenes
poses an increasingly serious threat to social security. Traditional anomaly
detection methods based on feature recognition struggle to capture high-level
behavioral semantics from historical information, while generative approaches
based on Large Language Models (LLMs) often fail to meet real-time
requirements. To address these challenges, we propose MA-CBP, a criminal
behavior prediction framework based on multi-agent asynchronous collaboration.
This framework transforms real-time video streams into frame-level semantic
descriptions, constructs causally consistent historical summaries, and fuses
adjacent image frames to perform joint reasoning over long- and short-term
contexts. The resulting behavioral decisions include key elements such as event
subjects, locations, and causes, enabling early warning of potential criminal
activity. In addition, we construct a high-quality criminal behavior dataset
that provides multi-scale language supervision, including frame-level,
summary-level, and event-level semantic annotations. Experimental results
demonstrate that our method achieves superior performance on multiple datasets
and offers a promising solution for risk warning in urban public safety
scenarios.

</details>


### [67] [A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet](https://arxiv.org/abs/2508.06191)
*Ruixiang Tang,Jianglong Qin,Mingda Zhang,Yan Song,Yi Wu,Wei Wu*

Main category: cs.CV

TL;DR: 提出DBIF-AUNet模型，通过双分支交互融合注意力机制和多尺度特征互补，显著提升胸水CT图像分割精度。


<details>
  <summary>Details</summary>
Motivation: 胸水CT图像分割面临灰度相似、边缘模糊和形态多变等挑战，现有方法难以应对复杂变化和语义鸿沟。

Method: 采用双域特征解耦模块（DDFD）和分支交互注意力融合模块（BIAF），结合嵌套深度监督机制。

Result: 在1622张胸水CT图像上，IoU和Dice分数分别达到80.1%和89.0%，优于现有模型。

Conclusion: DBIF-AUNet显著优化了复杂胸水CT图像的分割精度，具有临床实用价值。

Abstract: Pleural effusion semantic segmentation can significantly enhance the accuracy
and timeliness of clinical diagnosis and treatment by precisely identifying
disease severity and lesion areas. Currently, semantic segmentation of pleural
effusion CT images faces multiple challenges. These include similar gray levels
between effusion and surrounding tissues, blurred edges, and variable
morphology. Existing methods often struggle with diverse image variations and
complex edges, primarily because direct feature concatenation causes semantic
gaps. To address these challenges, we propose the Dual-Branch Interactive
Fusion Attention model (DBIF-AUNet). This model constructs a densely nested
skip-connection network and innovatively refines the Dual-Domain Feature
Disentanglement module (DDFD). The DDFD module orthogonally decouples the
functions of dual-domain modules to achieve multi-scale feature complementarity
and enhance characteristics at different levels. Concurrently, we design a
Branch Interaction Attention Fusion module (BIAF) that works synergistically
with the DDFD. This module dynamically weights and fuses global, local, and
frequency band features, thereby improving segmentation robustness.
Furthermore, we implement a nested deep supervision mechanism with hierarchical
adaptive hybrid loss to effectively address class imbalance. Through validation
on 1,622 pleural effusion CT images from Southwest Hospital, DBIF-AUNet
achieved IoU and Dice scores of 80.1% and 89.0% respectively. These results
outperform state-of-the-art medical image segmentation models U-Net++ and
Swin-UNet by 5.7%/2.7% and 2.2%/1.5% respectively, demonstrating significant
optimization in segmentation accuracy for complex pleural effusion CT images.

</details>


### [68] [LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning](https://arxiv.org/abs/2508.06202)
*Chang Che,Ziqi Wang,Pengwan Yang,Qi Wang,Hui Ma,Zenglin Shi*

Main category: cs.CV

TL;DR: LiLoRA是一种高效的架构扩展方法，用于解决多模态大语言模型（MLLMs）在持续视觉指令调优（CVIT）中的灾难性遗忘问题。通过共享LoRA矩阵A和低秩分解矩阵B，LiLoRA减少了参数冗余，同时引入余弦正则化稳定性损失以保持共享表示的一致性。实验表明，LiLoRA在连续任务学习中表现优异且参数效率显著提高。


<details>
  <summary>Details</summary>
Motivation: 持续视觉指令调优（CVIT）中，灾难性遗忘和多任务参数冗余是主要挑战。现有方法通过扩展整个层来避免干扰，但导致参数开销大且扩展性差。

Method: LiLoRA通过共享LoRA矩阵A、对矩阵B进行低秩分解以减少任务特定参数，并引入余弦正则化稳定性损失来保持共享表示的一致性。

Result: 在多样化的CVIT基准测试中，LiLoRA在连续任务学习中表现优异，同时显著提高了参数效率。

Conclusion: LiLoRA是一种高效且可扩展的解决方案，适用于CVIT中的灾难性遗忘问题，同时优化了参数使用。

Abstract: Continual Visual Instruction Tuning (CVIT) enables Multimodal Large Language
Models (MLLMs) to incrementally learn new tasks over time. However, this
process is challenged by catastrophic forgetting, where performance on
previously learned tasks deteriorates as the model adapts to new ones. A common
approach to mitigate forgetting is architecture expansion, which introduces
task-specific modules to prevent interference. Yet, existing methods often
expand entire layers for each task, leading to significant parameter overhead
and poor scalability. To overcome these issues, we introduce LoRA in LoRA
(LiLoRA), a highly efficient architecture expansion method tailored for CVIT in
MLLMs. LiLoRA shares the LoRA matrix A across tasks to reduce redundancy,
applies an additional low-rank decomposition to matrix B to minimize
task-specific parameters, and incorporates a cosine-regularized stability loss
to preserve consistency in shared representations over time. Extensive
experiments on a diverse CVIT benchmark show that LiLoRA consistently achieves
superior performance in sequential task learning while significantly improving
parameter efficiency compared to existing approaches.

</details>


### [69] [TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation](https://arxiv.org/abs/2508.06452)
*Mattia Litrico,Mario Valerio Giuffrida,Sebastiano Battiato,Devis Tuia*

Main category: cs.CV

TL;DR: TRUST是一种新型无监督域适应方法，利用语言模态的鲁棒性指导视觉模型适应，通过生成伪标签和不确定性估计策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂域偏移（如地理偏移）中现有方法表现不佳的问题，利用语言模态的鲁棒性辅助视觉模型适应。

Method: 1. 通过标题生成伪标签；2. 使用归一化CLIP相似度分数估计伪标签不确定性；3. 提出多模态软对比学习损失对齐视觉和语言特征空间。

Result: 在经典（DomainNet）和复杂（GeoNet）域偏移上超越现有方法，达到新SOTA。

Conclusion: TRUST通过语言模态的鲁棒性和创新的不确定性估计策略，显著提升了复杂域偏移下的适应性能。

Abstract: Recent unsupervised domain adaptation (UDA) methods have shown great success
in addressing classical domain shifts (e.g., synthetic-to-real), but they still
suffer under complex shifts (e.g. geographical shift), where both the
background and object appearances differ significantly across domains. Prior
works showed that the language modality can help in the adaptation process,
exhibiting more robustness to such complex shifts. In this paper, we introduce
TRUST, a novel UDA approach that exploits the robustness of the language
modality to guide the adaptation of a vision model. TRUST generates
pseudo-labels for target samples from their captions and introduces a novel
uncertainty estimation strategy that uses normalised CLIP similarity scores to
estimate the uncertainty of the generated pseudo-labels. Such estimated
uncertainty is then used to reweight the classification loss, mitigating the
adverse effects of wrong pseudo-labels obtained from low-quality captions. To
further increase the robustness of the vision model, we propose a multimodal
soft-contrastive learning loss that aligns the vision and language feature
spaces, by leveraging captions to guide the contrastive training of the vision
model on target images. In our contrastive loss, each pair of images acts as
both a positive and a negative pair and their feature representations are
attracted and repulsed with a strength proportional to the similarity of their
captions. This solution avoids the need for hardly determining positive and
negative pairs, which is critical in the UDA setting. Our approach outperforms
previous methods, setting the new state-of-the-art on classical (DomainNet) and
complex (GeoNet) domain shifts. The code will be available upon acceptance.

</details>


### [70] [AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection](https://arxiv.org/abs/2508.06203)
*Zhaopeng Gu,Bingke Zhu,Guibo Zhu,Yingying Chen,Wei Ge,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: AnomalyMoE 是一种基于 Mixture-of-Experts 架构的通用异常检测框架，通过分层设计检测多种异常，显著优于专用方法。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法过于专用化，泛化能力有限，无法适应多领域和多模态需求。

Method: AnomalyMoE 将异常检测分解为三个语义层次（局部结构、组件语义和全局逻辑异常），并分别设计专家网络，同时引入 EIR 和 ESB 模块提升多样性和专家利用率。

Result: 在 8 个不同领域的挑战性数据集上，AnomalyMoE 实现了最先进的性能，显著优于专用方法。

Conclusion: AnomalyMoE 通过分层设计和专家模块，提供了一种通用且高效的异常检测解决方案。

Abstract: Anomaly detection is a critical task across numerous domains and modalities,
yet existing methods are often highly specialized, limiting their
generalizability. These specialized models, tailored for specific anomaly types
like textural defects or logical errors, typically exhibit limited performance
when deployed outside their designated contexts. To overcome this limitation,
we propose AnomalyMoE, a novel and universal anomaly detection framework based
on a Mixture-of-Experts (MoE) architecture. Our key insight is to decompose the
complex anomaly detection problem into three distinct semantic hierarchies:
local structural anomalies, component-level semantic anomalies, and global
logical anomalies. AnomalyMoE correspondingly employs three dedicated expert
networks at the patch, component, and global levels, and is specialized in
reconstructing features and identifying deviations at its designated semantic
level. This hierarchical design allows a single model to concurrently
understand and detect a wide spectrum of anomalies. Furthermore, we introduce
an Expert Information Repulsion (EIR) module to promote expert diversity and an
Expert Selection Balancing (ESB) module to ensure the comprehensive utilization
of all experts. Experiments on 8 challenging datasets spanning industrial
imaging, 3D point clouds, medical imaging, video surveillance, and logical
anomaly detection demonstrate that AnomalyMoE establishes new state-of-the-art
performance, significantly outperforming specialized methods in their
respective domains.

</details>


### [71] [PA-HOI: A Physics-Aware Human and Object Interaction Dataset](https://arxiv.org/abs/2508.06205)
*Ruiyan Wang,Lin Zuo,Zonghao Lin,Qiang Wang,Zhengxue Cheng,Rong Xie,Jun Ling,Li Song*

Main category: cs.CV

TL;DR: 论文提出了PA-HOI数据集，填补了现有HOI数据集中忽视物体物理属性对人类长期运动影响的空白，包含562个运动序列，展示了物体尺寸、形状和重量对人类运动动态的影响。


<details>
  <summary>Details</summary>
Motivation: 现有HOI数据集过于关注功能细节，忽略了物体物理属性对人类长期运动的影响，限制了相关领域的研究。

Method: 构建PA-HOI数据集，包含562个运动序列，记录不同性别受试者与35种3D物体的互动，分析物体物理属性对人类运动动态的影响。

Result: PA-HOI数据集显著扩展了现有数据范围，揭示了物体物理属性对人类姿势、速度、运动规模和互动策略的影响。

Conclusion: PA-HOI数据集为理解物体物理属性对人类运动的影响提供了新视角，并验证了其在运动生成方法中的实用性。

Abstract: The Human-Object Interaction (HOI) task explores the dynamic interactions
between humans and objects in physical environments, providing essential
biomechanical and cognitive-behavioral foundations for fields such as robotics,
virtual reality, and human-computer interaction. However, existing HOI data
sets focus on details of affordance, often neglecting the influence of physical
properties of objects on human long-term motion. To bridge this gap, we
introduce the PA-HOI Motion Capture dataset, which highlights the impact of
objects' physical attributes on human motion dynamics, including human posture,
moving velocity, and other motion characteristics. The dataset comprises 562
motion sequences of human-object interactions, with each sequence performed by
subjects of different genders interacting with 35 3D objects that vary in size,
shape, and weight. This dataset stands out by significantly extending the scope
of existing ones for understanding how the physical attributes of different
objects influence human posture, speed, motion scale, and interacting
strategies. We further demonstrate the applicability of the PA-HOI dataset by
integrating it with existing motion generation methods, validating its capacity
to transfer realistic physical awareness.

</details>


### [72] [WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion](https://arxiv.org/abs/2508.06485)
*Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai*

Main category: cs.CV

TL;DR: WGAST是一种弱监督生成网络，用于通过时空融合技术从Terra MODIS、Landsat 8和Sentinel-2数据中估计每日10米分辨率的陆地表面温度（LST）。


<details>
  <summary>Details</summary>
Motivation: 城市化、气候变化和农业压力增加了对精确和及时环境监测的需求，而现有遥感系统在空间和时间分辨率之间存在权衡。

Method: WGAST采用条件生成对抗网络架构，包括特征提取、融合、LST重建和噪声抑制四个阶段，并通过弱监督策略训练。

Result: WGAST在定量和定性评估中均优于现有方法，平均降低RMSE 17.18%，提高SSIM 11.00%，并能有效捕捉细尺度热模式。

Conclusion: WGAST是首个端到端深度学习框架，能够高效估计高分辨率LST，并在实际应用中表现出鲁棒性。

Abstract: Urbanization, climate change, and agricultural stress are increasing the
demand for precise and timely environmental monitoring. Land Surface
Temperature (LST) is a key variable in this context and is retrieved from
remote sensing satellites. However, these systems face a trade-off between
spatial and temporal resolution. While spatio-temporal fusion methods offer
promising solutions, few have addressed the estimation of daily LST at 10 m
resolution. In this study, we present WGAST, a Weakly-Supervised Generative
Network for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra
MODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning
framework designed for this task. It adopts a conditional generative
adversarial architecture, with a generator composed of four stages: feature
extraction, fusion, LST reconstruction, and noise suppression. The first stage
employs a set of encoders to extract multi-level latent representations from
the inputs, which are then fused in the second stage using cosine similarity,
normalization, and temporal attention mechanisms. The third stage decodes the
fused features into high-resolution LST, followed by a Gaussian filter to
suppress high-frequency noise. Training follows a weakly supervised strategy
based on physical averaging principles and reinforced by a PatchGAN
discriminator. Experiments demonstrate that WGAST outperforms existing methods
in both quantitative and qualitative evaluations. Compared to the
best-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves
SSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and
effectively captures fine-scale thermal patterns, as validated against 33
ground-based sensors. The code is available at
https://github.com/Sofianebouaziz1/WGAST.git.

</details>


### [73] [Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning](https://arxiv.org/abs/2508.06218)
*Zhiyan Bo,Laura C. Coates,Bartlomiej W. Papiez*

Main category: cs.CV

TL;DR: 提出了一种基于双X光片的可解释性图像级SvdH评分预测方法，通过注意力机制和多实例学习提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: SvdH评分在临床实践中因复杂性难以广泛应用，手动评分效率低。

Method: 采用两阶段流程：提取疾病相关图像区域，并通过注意力机制整合特征进行预测。提出了两种区域提取方案。

Result: 最佳模型PCC为0.943，RMSE为15.73；集成学习后PCC达0.945，RMSE为15.57，接近放射科医生水平。

Conclusion: 该方法高效且可解释，能识别与RA进展相关的解剖结构。

Abstract: The Sharp/van der Heijde (SvdH) score has been widely used in clinical trials
to quantify radiographic damage in Rheumatoid Arthritis (RA), but its
complexity has limited its adoption in routine clinical practice. To address
the inefficiency of manual scoring, this work proposes a two-stage pipeline for
interpretable image-level SvdH score prediction using dual-hand radiographs.
Our approach extracts disease-relevant image regions and integrates them using
attention-based multiple instance learning to generate image-level features for
prediction. We propose two region extraction schemes: 1) sampling image tiles
most likely to contain abnormalities, and 2) cropping patches containing
disease-relevant joints. With Scheme 2, our best individual score prediction
model achieved a Pearson's correlation coefficient (PCC) of 0.943 and a root
mean squared error (RMSE) of 15.73. Ensemble learning further boosted
prediction accuracy, yielding a PCC of 0.945 and RMSE of 15.57, achieving
state-of-the-art performance that is comparable to that of experienced
radiologists (PCC = 0.97, RMSE = 18.75). Finally, our pipeline effectively
identified and made decisions based on anatomical structures which clinicians
consider relevant to RA progression.

</details>


### [74] [TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images](https://arxiv.org/abs/2508.06224)
*Guoyu Zhou,Jing Zhang,Yi Yan,Hui Zhang,Li Zhuo*

Main category: cs.CV

TL;DR: 提出了一种纹理感知和边缘引导的Transformer（TEFormer），用于城市遥感图像的语义分割，解决了纹理差异和边缘模糊的问题。


<details>
  <summary>Details</summary>
Motivation: 城市遥感图像中地理对象的纹理差异小、空间结构相似，易导致语义模糊和误分类，同时不规则形状和模糊边界增加了分割难度。

Method: 设计了纹理感知模块（TaM）捕捉纹理差异，边缘引导三分支解码器（Eg3Head）保留边缘细节，以及边缘引导特征融合模块（EgFFM）融合上下文和边缘信息。

Result: 在Potsdam、Vaihingen和LoveDA数据集上分别达到88.57%、81.46%和53.55%的mIoU。

Conclusion: TEFormer通过纹理感知和边缘引导机制，有效提升了城市遥感图像的语义分割精度。

Abstract: Semantic segmentation of urban remote sensing images (URSIs) is crucial for
applications such as urban planning and environmental monitoring. However,
geospatial objects often exhibit subtle texture differences and similar spatial
structures, which can easily lead to semantic ambiguity and misclassification.
Moreover, challenges such as irregular object shapes, blurred boundaries, and
overlapping spatial distributions of semantic objects contribute to complex and
diverse edge morphologies, further complicating accurate segmentation. To
tackle these issues, we propose a texture-aware and edge-guided Transformer
(TEFormer) that integrates texture awareness and edge-guidance mechanisms for
semantic segmentation of URSIs. In the encoder, a texture-aware module (TaM) is
designed to capture fine-grained texture differences between visually similar
categories to enhance semantic discrimination. Then, an edge-guided tri-branch
decoder (Eg3Head) is constructed to preserve local edges and details for
multiscale context-awareness. Finally, an edge-guided feature fusion module
(EgFFM) is to fuse contextual and detail information with edge information to
realize refined semantic segmentation. Extensive experiments show that TEFormer
achieves mIoU of 88.57%, 81.46%, and 53.55% on the Potsdam, Vaihingen, and
LoveDA datasets, respectively, shows the effectiveness in URSI semantic
segmentation.

</details>


### [75] [Depth Jitter: Seeing through the Depth](https://arxiv.org/abs/2508.06227)
*Md Sazidur Rahman,David Cabecinhas,Ricard Marxer*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度的增强技术Depth-Jitter，通过模拟自然深度变化提升模型在深度敏感环境中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统增强技术忽略了深度感知变换，限制了模型在真实世界深度变化中的鲁棒性。

Method: Depth-Jitter采用自适应深度偏移，基于深度方差阈值生成合成深度扰动，同时保持结构完整性。

Result: 在FathomNet和UTDAC2020数据集上的实验表明，Depth-Jitter提升了模型在深度变化下的稳定性，但未在所有情况下超越传统方法。

Conclusion: Depth-Jitter为深度感知增强提供了新思路，支持进一步研究深度相关学习策略。

Abstract: Depth information is essential in computer vision, particularly in underwater
imaging, robotics, and autonomous navigation. However, conventional
augmentation techniques overlook depth aware transformations, limiting model
robustness in real world depth variations. In this paper, we introduce
Depth-Jitter, a novel depth-based augmentation technique that simulates natural
depth variations to improve generalization. Our approach applies adaptive depth
offsetting, guided by depth variance thresholds, to generate synthetic depth
perturbations while preserving structural integrity. We evaluate Depth-Jitter
on two benchmark datasets, FathomNet and UTDAC2020 demonstrating its impact on
model stability under diverse depth conditions. Extensive experiments compare
Depth-Jitter against traditional augmentation strategies such as ColorJitter,
analyzing performance across varying learning rates, encoders, and loss
functions. While Depth-Jitter does not always outperform conventional methods
in absolute performance, it consistently enhances model stability and
generalization in depth-sensitive environments. These findings highlight the
potential of depth-aware augmentation for real-world applications and provide a
foundation for further research into depth-based learning strategies. The
proposed technique is publicly available to support advancements in depth-aware
augmentation. The code is publicly available on
\href{https://github.com/mim-team/Depth-Jitter}{github}.

</details>


### [76] [Towards Unified Image Deblurring using a Mixture-of-Experts Decoder](https://arxiv.org/abs/2508.06228)
*Daniel Feijoo,Paula Garrido-Mellado,Jaesung Rim,Alvaro Garcia,Marcos V. Conde*

Main category: cs.CV

TL;DR: 提出了一种通用的图像去模糊方法，能够处理多种模糊类型，通过混合专家模块动态路由特征，实现高效恢复。


<details>
  <summary>Details</summary>
Motivation: 现有方法针对特定模糊类型设计，缺乏通用性，需要多个模型覆盖不同模糊类型，不适用于实际场景。

Method: 采用混合专家（MoE）解码模块，根据识别的模糊类型动态路由图像特征，实现端到端的精确恢复。

Result: 统一方法在性能上与专用模型相当，且在未见过的模糊场景中表现出优异的鲁棒性和泛化能力。

Conclusion: 该方法为图像去模糊提供了一种高效、通用的解决方案，适用于多种模糊类型。

Abstract: Image deblurring, removing blurring artifacts from images, is a fundamental
task in computational photography and low-level computer vision. Existing
approaches focus on specialized solutions tailored to particular blur types,
thus, these solutions lack generalization. This limitation in current methods
implies requiring multiple models to cover several blur types, which is not
practical in many real scenarios. In this paper, we introduce the first
all-in-one deblurring method capable of efficiently restoring images affected
by diverse blur degradations, including global motion, local motion, blur in
low-light conditions, and defocus blur. We propose a mixture-of-experts (MoE)
decoding module, which dynamically routes image features based on the
recognized blur degradation, enabling precise and efficient restoration in an
end-to-end manner. Our unified approach not only achieves performance
comparable to dedicated task-specific models, but also demonstrates remarkable
robustness and generalization capabilities on unseen blur degradation
scenarios.

</details>


### [77] [Deepfake Detection that Generalizes Across Benchmarks](https://arxiv.org/abs/2508.06248)
*Andrii Yermakov,Jan Cech,Jiri Matas,Mario Fritz*

Main category: cs.CV

TL;DR: LNCLIP-DF通过仅微调预训练CLIP模型的Layer Normalization参数（0.03%），结合L2归一化和潜在空间增强，实现了对未见过的深度伪造技术的鲁棒泛化。


<details>
  <summary>Details</summary>
Motivation: 解决深度伪造检测器在未见过的伪造技术上泛化能力不足的问题，避免复杂的架构调整。

Method: 仅微调CLIP模型的Layer Normalization参数，结合L2归一化和潜在空间增强，优化特征流形。

Result: 在13个基准数据集上取得最优性能，平均跨数据集AUROC超过复杂方法。

Conclusion: 通过最小化调整预训练模型，实现了高效且可复现的深度伪造检测方法。

Abstract: The generalization of deepfake detectors to unseen manipulation techniques
remains a challenge for practical deployment. Although many approaches adapt
foundation models by introducing significant architectural complexity, this
work demonstrates that robust generalization is achievable through a
parameter-efficient adaptation of a pre-trained CLIP vision encoder. The
proposed method, LNCLIP-DF, fine-tunes only the Layer Normalization parameters
(0.03% of the total) and enhances generalization by enforcing a hyperspherical
feature manifold using L2 normalization and latent space augmentations.
  We conducted an extensive evaluation on 13 benchmark datasets spanning from
2019 to 2025. The proposed method achieves state-of-the-art performance,
outperforming more complex, recent approaches in average cross-dataset AUROC.
Our analysis yields two primary findings for the field: 1) training on paired
real-fake data from the same source video is essential for mitigating shortcut
learning and improving generalization, and 2) detection difficulty on academic
datasets has not strictly increased over time, with models trained on older,
diverse datasets showing strong generalization capabilities.
  This work delivers a computationally efficient and reproducible method,
proving that state-of-the-art generalization is attainable by making targeted,
minimal changes to a pre-trained CLIP model. The code will be made publicly
available upon acceptance.

</details>


### [78] [FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing](https://arxiv.org/abs/2508.06256)
*Barış Büyüktaş,Jonas Klotz,Begüm Demir*

Main category: cs.CV

TL;DR: 论文提出了一种名为FedX的新策略，通过解释引导的剪枝减少联邦学习中的通信开销，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在遥感图像分类中面临通信开销大的问题，数据隐私和法规限制使得数据集中化不可行。

Method: FedX利用反向传播解释方法评估模型组件的重要性，剪枝最不相关的部分以减少传输模型的大小。

Result: 在BigEarthNet-S2和EuroSAT数据集上的实验表明，FedX显著减少了共享参数数量，同时提升了全局模型的泛化能力。

Conclusion: FedX是一种有效的通信优化方法，适用于联邦学习中的遥感任务。

Abstract: Federated learning (FL) enables the collaborative training of deep neural
networks across decentralized data archives (i.e., clients), where each client
stores data locally and only shares model updates with a central server. This
makes FL a suitable learning paradigm for remote sensing (RS) image
classification tasks, where data centralization may be restricted due to legal
and privacy constraints. However, a key challenge in applying FL to RS tasks is
the communication overhead caused by the frequent exchange of large model
updates between clients and the central server. To address this issue, in this
paper we propose a novel strategy (denoted as FedX) that uses
explanation-guided pruning to reduce communication overhead by minimizing the
size of the transmitted models without compromising performance. FedX leverages
backpropagation-based explanation methods to estimate the task-specific
importance of model components and prunes the least relevant ones at the
central server. The resulting sparse global model is then sent to clients,
substantially reducing communication overhead. We evaluate FedX on multi-label
scene classification using the BigEarthNet-S2 dataset and single-label scene
classification using the EuroSAT dataset. Experimental results show the success
of FedX in significantly reducing the number of shared model parameters while
enhancing the generalization capability of the global model, compared to both
unpruned model and state-of-the-art pruning methods. The code of FedX will be
available at https://git.tu-berlin.de/rsim/FedX.

</details>


### [79] [XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation](https://arxiv.org/abs/2508.06258)
*Byunghyun Ko,Anning Tian,Jeongkyu Lee*

Main category: cs.CV

TL;DR: XAG-Net是一种新型2.5D U-Net架构，通过交叉切片注意力和跳跃注意力门控机制提升股骨MRI分割的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有2D和3D深度学习方法在股骨MRI分割中存在局限性，需要更高效的模型。

Method: XAG-Net结合像素级交叉切片注意力（CSA）和跳跃注意力门控（AG），优化切片间上下文建模和切片内特征细化。

Result: XAG-Net在股骨分割精度上优于基线2D、2.5D和3D U-Net模型，同时保持计算效率。

Conclusion: XAG-Net是一种高效且准确的股骨MRI分割框架，CSA和AG模块对其性能至关重要。

Abstract: Accurate segmentation of femur structures from Magnetic Resonance Imaging
(MRI) is critical for orthopedic diagnosis and surgical planning but remains
challenging due to the limitations of existing 2D and 3D deep learning-based
segmentation approaches. In this study, we propose XAG-Net, a novel 2.5D
U-Net-based architecture that incorporates pixel-wise cross-slice attention
(CSA) and skip attention gating (AG) mechanisms to enhance inter-slice
contextual modeling and intra-slice feature refinement. Unlike previous
CSA-based models, XAG-Net applies pixel-wise softmax attention across adjacent
slices at each spatial location for fine-grained inter-slice modeling.
Extensive evaluations demonstrate that XAG-Net surpasses baseline 2D, 2.5D, and
3D U-Net models in femur segmentation accuracy while maintaining computational
efficiency. Ablation studies further validate the critical role of the CSA and
AG modules, establishing XAG-Net as a promising framework for efficient and
accurate femur MRI segmentation.

</details>


### [80] [SIFThinker: Spatially-Aware Image Focus for Visual Reasoning](https://arxiv.org/abs/2508.06259)
*Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang*

Main category: cs.CV

TL;DR: SIFThinker是一个空间感知的多模态框架，通过深度增强的边界框和自然语言交互，提升复杂视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在复杂视觉任务（如空间理解和细粒度感知）中表现不足，缺乏利用空间线索进行注意力校正的能力。

Method: 提出SIFThinker框架，采用反向扩展前向推理策略生成图像-文本链，并引入GRPO-SIF训练范式，结合深度信息进行视觉定位。

Result: 实验表明，SIFThinker在空间理解和细粒度视觉感知上优于现有方法，同时保持通用能力。

Conclusion: SIFThinker通过动态注意力校正和区域聚焦，显著提升了复杂视觉任务的性能。

Abstract: Current multimodal large language models (MLLMs) still face significant
challenges in complex visual tasks (e.g., spatial understanding, fine-grained
perception). Prior methods have tried to incorporate visual reasoning, however,
they fail to leverage attention correction with spatial cues to iteratively
refine their focus on prompt-relevant regions. In this paper, we introduce
SIFThinker, a spatially-aware "think-with-images" framework that mimics human
visual perception. Specifically, SIFThinker enables attention correcting and
image region focusing by interleaving depth-enhanced bounding boxes and natural
language. Our contributions are twofold: First, we introduce a
reverse-expansion-forward-inference strategy that facilitates the generation of
interleaved image-text chains of thought for process-level supervision, which
in turn leads to the construction of the SIF-50K dataset. Besides, we propose
GRPO-SIF, a reinforced training paradigm that integrates depth-informed visual
grounding into a unified reasoning pipeline, teaching the model to dynamically
correct and focus on prompt-relevant regions. Extensive experiments demonstrate
that SIFThinker outperforms state-of-the-art methods in spatial understanding
and fine-grained visual perception, while maintaining strong general
capabilities, highlighting the effectiveness of our method.

</details>


### [81] [Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding](https://arxiv.org/abs/2508.06317)
*Jian Hu,Zixu Cheng,Shaogang Gong,Isabel Guan,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.CV

TL;DR: 论文提出了一种数据高效的跨域视频时间定位方法URPA，通过少量无标签目标域视频实现模型适应，解决了GRPO依赖标签数据和高计算成本的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如GRPO）依赖标签数据且计算成本高，难以在无标签域和实时场景中应用。

Method: 提出URPA方法，利用GRPO生成候选预测并计算置信度，通过伪标签和加权奖励实现无标签跨域适应。

Result: 在三个数据集的六种跨域设置中，URPA仅需少量无标签视频即表现优异。

Conclusion: URPA是一种高效、实用的跨域视频时间定位方法，适用于实时部署。

Abstract: Video Temporal Grounding (TG) aims to temporally locate video segments
matching a natural language description (a query) in a long video. While
Vision-Language Models (VLMs) are effective at holistic semantic matching, they
often struggle with fine-grained temporal localisation. Recently, Group
Relative Policy Optimisation (GRPO) reformulates the inference process as a
reinforcement learning task, enabling fine-grained grounding and achieving
strong in-domain performance. However, GRPO relies on labelled data, making it
unsuitable in unlabelled domains. Moreover, because videos are large and
expensive to store and process, performing full-scale adaptation introduces
prohibitive latency and computational overhead, making it impractical for
real-time deployment. To overcome both problems, we introduce a Data-Efficient
Unlabelled Cross-domain Temporal Grounding method, from which a model is first
trained on a labelled source domain, then adapted to a target domain using only
a small number of unlabelled videos from the target domain. This approach
eliminates the need for target annotation and keeps both computational and
storage overhead low enough to run in real time. Specifically, we introduce.
Uncertainty-quantified Rollout Policy Adaptation (URPA) for cross-domain
knowledge transfer in learning video temporal grounding without target labels.
URPA generates multiple candidate predictions using GRPO rollouts, averages
them to form a pseudo label, and estimates confidence from the variance across
these rollouts. This confidence then weights the training rewards, guiding the
model to focus on reliable supervision. Experiments on three datasets across
six cross-domain settings show that URPA generalises well using only a few
unlabelled target videos. Codes will be released once published.

</details>


### [82] [Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.06318)
*Giacomo D'Amicantonio,Snehashis Majhi,Quan Kong,Lorenzo Garattoni,Gianpiero Francesca,François Bremond,Egor Bondarev*

Main category: cs.CV

TL;DR: 论文提出了一种名为GS-MoE的新框架，通过专家模型和时序高斯泼溅损失解决弱监督视频异常检测中的多样性和弱信号问题，取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测模型在处理复杂异常时表现不佳，主要由于模型无法区分异常类别且弱监督信号缺乏精确时序信息。

Method: 提出GS-MoE框架，使用多个专家模型分别捕捉特定异常类型，并通过时序高斯泼溅损失增强弱监督信号。

Result: 在UCF-Crime数据集上达到91.58% AUC，并在XD-Violence和MSAD数据集上表现优异。

Conclusion: GS-MoE通过类别特异性专家和时序指导，为弱监督视频异常检测设定了新基准。

Abstract: Video Anomaly Detection (VAD) is a challenging task due to the variability of
anomalous events and the limited availability of labeled data. Under the
Weakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided
during training, while predictions are made at the frame level. Although
state-of-the-art models perform well on simple anomalies (e.g., explosions),
they struggle with complex real-world events (e.g., shoplifting). This
difficulty stems from two key issues: (1) the inability of current models to
address the diversity of anomaly types, as they process all categories with a
shared model, overlooking category-specific features; and (2) the weak
supervision signal, which lacks precise temporal information, limiting the
ability to capture nuanced anomalous patterns blended with normal events. To
address these challenges, we propose Gaussian Splatting-guided Mixture of
Experts (GS-MoE), a novel framework that employs a set of expert models, each
specialized in capturing specific anomaly types. These experts are guided by a
temporal Gaussian splatting loss, enabling the model to leverage temporal
consistency and enhance weak supervision. The Gaussian splatting approach
encourages a more precise and comprehensive representation of anomalies by
focusing on temporal segments most likely to contain abnormal events. The
predictions from these specialized experts are integrated through a
mixture-of-experts mechanism to model complex relationships across diverse
anomaly patterns. Our approach achieves state-of-the-art performance, with a
91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on
XD-Violence and MSAD datasets. By leveraging category-specific expertise and
temporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision.

</details>


### [83] [Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?](https://arxiv.org/abs/2508.06327)
*Xin Ci Wong,Duygu Sarikaya,Kieran Zucker,Marc De Kamps,Nishant Ravikumar*

Main category: cs.CV

TL;DR: 提出一种基于扩散模型的方法，生成合成心脏MR图像以解决领域偏移问题，显著提升多中心心脏MR分割性能。


<details>
  <summary>Details</summary>
Motivation: 心脏MR成像因设备和协议差异导致领域偏移，限制了AI模型在实际场景中的应用。传统方法如数据增强或迁移学习存在局限性。

Method: 使用扩散模型生成合成心脏MR图像，保持结构和空间一致性，并用于训练分割模型或调整目标领域数据。

Result: 在未见目标领域数据上，分割性能显著提升（p < 0.01），优于仅使用真实数据训练的方法。

Conclusion: 该方法有效解决了心脏MR图像分析中的领域偏移问题，尤其适用于数据稀缺场景。

Abstract: Magnetic resonance (MR) imaging, including cardiac MR, is prone to domain
shift due to variations in imaging devices and acquisition protocols. This
challenge limits the deployment of trained AI models in real-world scenarios,
where performance degrades on unseen domains. Traditional solutions involve
increasing the size of the dataset through ad-hoc image augmentation or
additional online training/transfer learning, which have several limitations.
Synthetic data offers a promising alternative, but anatomical/structural
consistency constraints limit the effectiveness of generative models in
creating image-label pairs. To address this, we propose a diffusion model (DM)
trained on a source domain that generates synthetic cardiac MR images that
resemble a given reference. The synthetic data maintains spatial and structural
fidelity, ensuring similarity to the source domain and compatibility with the
segmentation mask. We assess the utility of our generative approach in
multi-centre cardiac MR segmentation, using the 2D nnU-Net, 3D nnU-Net and
vanilla U-Net segmentation networks. We explore domain generalisation, where,
domain-invariant segmentation models are trained on synthetic source domain
data, and domain adaptation, where, we shift target domain data towards the
source domain using the DM. Both strategies significantly improved segmentation
performance on data from an unseen target domain, in terms of surface-based
metrics (Welch's t-test, p < 0.01), compared to training segmentation models on
real data alone. The proposed method ameliorates the need for transfer learning
or online training to address domain shift challenges in cardiac MR image
analysis, especially useful in data-scarce settings.

</details>


### [84] [ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction](https://arxiv.org/abs/2508.06335)
*Patrick Takenaka,Johannes Maucher,Marco F. Huber*

Main category: cs.CV

TL;DR: 论文改进了ViPro模型，使其能够从观测中正确推断状态，无需初始真实状态，并在无监督方式下验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决ViPro模型因依赖初始真实状态而无法在噪声环境下准确估计状态的问题。

Method: 在ViPro基础上增加改进，使其能无监督地从观测推断状态，并扩展了3D数据集Orbits。

Result: 模型能够在不提供初始真实状态的情况下正确推断状态，并在3D数据集中验证了有效性。

Conclusion: 改进后的ViPro模型在无监督状态下表现更优，适用于更接近真实世界的场景。

Abstract: Predicting future video frames is a challenging task with many downstream
applications. Previous work has shown that procedural knowledge enables deep
models for complex dynamical settings, however their model ViPro assumed a
given ground truth initial symbolic state. We show that this approach led to
the model learning a shortcut that does not actually connect the observed
environment with the predicted symbolic state, resulting in the inability to
estimate states given an observation if previous states are noisy. In this
work, we add several improvements to ViPro that enables the model to correctly
infer states from observations without providing a full ground truth state in
the beginning. We show that this is possible in an unsupervised manner, and
extend the original Orbits dataset with a 3D variant to close the gap to real
world scenarios.

</details>


### [85] [Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities](https://arxiv.org/abs/2508.06342)
*Kieran Elrod,Katherine Flanigan,Mario Bergés*

Main category: cs.CV

TL;DR: 研究提出利用街景图像和大型语言模型分析城市社交互动质量，验证了环境因素与社交类型的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注行人数量而非社交互动质量，街景图像作为低成本数据源可能蕴含潜在社交信息。

Method: 分析15个城市的2,998张街景图像，结合Mehta的社交分类理论，使用线性回归模型控制变量。

Result: 天空视野指数与所有社交类型相关，绿色视野指数预测持久社交，场所依恋与短暂社交正相关。

Conclusion: 街景图像可用于研究社交互动与建成环境的关系，未来或成为跨文化理论测试的工具。

Abstract: Designing socially active streets has long been a goal of urban planning, yet
existing quantitative research largely measures pedestrian volume rather than
the quality of social interactions. We hypothesize that street view imagery --
an inexpensive data source with global coverage -- contains latent social
information that can be extracted and interpreted through established social
science theory. As a proof of concept, we analyzed 2,998 street view images
from 15 cities using a multimodal large language model guided by Mehta's
taxonomy of passive, fleeting, and enduring sociability -- one illustrative
example of a theory grounded in urban design that could be substituted or
complemented by other sociological frameworks. We then used linear regression
models, controlling for factors like weather, time of day, and pedestrian
counts, to test whether the inferred sociability measures correlate with
city-level place attachment scores from the World Values Survey and with
environmental predictors (e.g., green, sky, and water view indices) derived
from individual street view images. Results aligned with long-standing urban
planning theory: the sky view index was associated with all three sociability
types, the green view index predicted enduring sociability, and place
attachment was positively associated with fleeting sociability. These results
provide preliminary evidence that street view images can be used to infer
relationships between specific types of social interactions and built
environment variables. Further research could establish street view imagery as
a scalable, privacy-preserving tool for studying urban sociability, enabling
cross-cultural theory testing and evidence-based design of socially vibrant
cities.

</details>


### [86] [Aligning Effective Tokens with Video Anomaly in Large Language Models](https://arxiv.org/abs/2508.06350)
*Yingxian Chen,Jiahui Liu,Ruifan Di,Yanwei Li,Chirui Chang,Shizhen Zhao,Wilton W. T. Fok,Xiaojuan Qi,Yik-Chung Wu*

Main category: cs.CV

TL;DR: VA-GPT是一种新型多模态大语言模型，通过空间和时间有效令牌模块优化异常事件检测，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视频异常事件检测具有挑战性，现有多模态大语言模型因冗余信息导致效果不佳。

Method: 提出VA-GPT模型，结合空间有效令牌选择（SETS）和时间有效令牌生成（TETG）模块，优化异常事件分析。

Result: 模型在多个基准测试中优于现有方法。

Conclusion: VA-GPT通过有效令牌对齐和跨域评估，显著提升了异常事件检测性能。

Abstract: Understanding abnormal events in videos is a vital and challenging task that
has garnered significant attention in a wide range of applications. Although
current video understanding Multi-modal Large Language Models (MLLMs) are
capable of analyzing general videos, they often struggle to handle anomalies
due to the spatial and temporal sparsity of abnormal events, where the
redundant information always leads to suboptimal outcomes. To address these
challenges, exploiting the representation and generalization capabilities of
Vison Language Models (VLMs) and Large Language Models (LLMs), we propose
VA-GPT, a novel MLLM designed for summarizing and localizing abnormal events in
various videos. Our approach efficiently aligns effective tokens between visual
encoders and LLMs through two key proposed modules: Spatial Effective Token
Selection (SETS) and Temporal Effective Token Generation (TETG). These modules
enable our model to effectively capture and analyze both spatial and temporal
information associated with abnormal events, resulting in more accurate
responses and interactions. Furthermore, we construct an instruction-following
dataset specifically for fine-tuning video-anomaly-aware MLLMs, and introduce a
cross-domain evaluation benchmark based on XD-Violence dataset. Our proposed
method outperforms existing state-of-the-art methods on various benchmarks.

</details>


### [87] [An Implemention of Two-Phase Image Segmentation using the Split Bregman Method](https://arxiv.org/abs/2508.06351)
*Olakunle S. Abawonse,Günay Doğan*

Main category: cs.CV

TL;DR: 本文实现了一种基于Goldstein等人提出的两阶段图像分割算法，通过改进Chan-Vese能量模型，利用Split Bregman方法高效实现图像分割。


<details>
  <summary>Details</summary>
Motivation: 图像分割是计算机视觉中的重要任务，本文旨在改进Chan-Vese模型，使其能够更高效地实现两阶段分割。

Method: 通过改进Chan-Vese能量模型，引入Split Bregman方法进行优化，实现高效的两阶段图像分割。

Result: 实验展示了该算法在不同参数下的性能，验证了其有效性。

Conclusion: 本文提出的方法能够高效实现两阶段图像分割，适用于多种图像场景。

Abstract: In this paper, we describe an implementation of the two-phase image
segmentation algorithm proposed by Goldstein, Bresson, Osher in
\cite{gold:bre}. This algorithm partitions the domain of a given 2d image into
foreground and background regions, and each pixel of the image is assigned
membership to one of these two regions. The underlying assumption for the
segmentation model is that the pixel values of the input image can be
summarized by two distinct average values, and that the region boundaries are
smooth. Accordingly, the model is defined as an energy in which the variable is
a region membership function to assign pixels to either region, originally
proposed by Chan and Vese in \cite{chan:vese}. This energy is the sum of image
data terms in the regions and a length penalty for region boundaries.
Goldstein, Bresson, Osher modify the energy of Chan-Vese in \cite{gold:bre} so
that their new energy can be minimized efficiently using the split Bregman
method to produce an equivalent two-phase segmentation. We provide a detailed
implementation of this method \cite{gold:bre}, and document its performance
with several images over a range of algorithm parameters.

</details>


### [88] [Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd](https://arxiv.org/abs/2508.06357)
*Aman Bhatta,Maria Dhakal,Michael C. King,Kevin W. Bowyer*

Main category: cs.CV

TL;DR: 该论文提出了一种新方法，利用额外的注册图像预测一对多人脸识别中的排名第一结果是否为库内或库外，以减少误识别和调查时间浪费。


<details>
  <summary>Details</summary>
Motivation: 解决一对多人脸识别中排名第一结果是否为库内或库外的问题，传统方法依赖相似度分数阈值，效果有限。

Method: 通过提取排名第一身份的额外注册图像的排名特征，训练分类器预测库内/库外状态。

Result: 实验证明该方法对高质量和低质量（模糊、低分辨率等）探针图像均有效，且在不同人口统计组中表现一致。

Conclusion: 该方法能客观估计库外结果，减少误识别和调查资源浪费，且仅在使用高级损失函数训练的匹配器中有效。

Abstract: A central problem in one-to-many facial identification is that the person in
the probe image may or may not have enrolled image(s) in the gallery; that is,
may be In-gallery or Out-of-gallery. Past approaches to detect when a rank-one
result is Out-of-gallery have mostly focused on finding a suitable threshold on
the similarity score. We take a new approach, using the additional enrolled
images of the identity with the rank-one result to predict if the rank-one
result is In-gallery / Out-of-gallery. Given a gallery of identities and
images, we generate In-gallery and Out-of-gallery training data by extracting
the ranks of additional enrolled images corresponding to the rank-one identity.
We then train a classifier to utilize this feature vector to predict whether a
rank-one result is In-gallery or Out-of-gallery. Using two different datasets
and four different matchers, we present experimental results showing that our
approach is viable for mugshot quality probe images, and also, importantly, for
probes degraded by blur, reduced resolution, atmospheric turbulence and
sunglasses. We also analyze results across demographic groups, and show that
In-gallery / Out-of-gallery classification accuracy is similar across
demographics. Our approach has the potential to provide an objective estimate
of whether a one-to-many facial identification is Out-of-gallery, and thereby
to reduce false positive identifications, wrongful arrests, and wasted
investigative time. Interestingly, comparing the results of older deep
CNN-based face matchers with newer ones suggests that the effectiveness of our
Out-of-gallery detection approach emerges only with matchers trained using
advanced margin-based loss functions.

</details>


### [89] [Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning](https://arxiv.org/abs/2508.06382)
*Xiangyu Wu,Feng Yu,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: TaAM-CPT是一种通过文本数据构建通用多模态表示模型的方法，无需特定模态标注数据，支持无限模态扩展。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量模态特定标注数据或仅针对单一模态，限制了通用性和扩展性。

Method: TaAM-CPT结合模态提示池、文本构建和模态对齐文本编码器，通过跨模态学习目标实现语义一致性。

Result: TaAM-CPT在视频、图像和音频分类任务中取得领先结果，无需模态特定标注数据。

Conclusion: TaAM-CPT展示了通过文本数据构建通用多模态模型的潜力，支持无限模态扩展。

Abstract: The integration of prompt tuning with multimodal learning has shown
significant generalization abilities for various downstream tasks. Despite
advancements, existing methods heavily depend on massive modality-specific
labeled data (e.g., video, audio, and image), or are customized for a single
modality. In this study, we present Text as Any-Modality by Consistent Prompt
Tuning (TaAM-CPT), a scalable approach for constructing a general
representation model toward unlimited modalities using solely text data.
TaAM-CPT comprises modality prompt pools, text construction, and
modality-aligned text encoders from pre-trained models, which allows for
extending new modalities by simply adding prompt pools and modality-aligned
text encoders. To harmonize the learning across different modalities, TaAM-CPT
designs intra- and inter-modal learning objectives, which can capture category
details within modalities while maintaining semantic consistency across
different modalities. Benefiting from its scalable architecture and pre-trained
models, TaAM-CPT can be seamlessly extended to accommodate unlimited
modalities. Remarkably, without any modality-specific labeled data, TaAM-CPT
achieves leading results on diverse datasets spanning various modalities,
including video classification, image classification, and audio classification.
The code is available at https://github.com/Jinx630/TaAM-CPT.

</details>


### [90] [FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation](https://arxiv.org/abs/2508.06392)
*Wenbin Teng,Gonglin Chen,Haiwei Chen,Yajie Zhao*

Main category: cs.CV

TL;DR: FVGen是一种新框架，通过仅需四步采样快速合成新视图，解决了视频扩散模型（VDMs）在稀疏视图3D重建中采样速度慢的问题。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图在3D重建中常导致未观察区域的伪影，现有方法使用VDMs生成密集观测但采样速度慢。

Method: 提出一种视频扩散模型蒸馏方法，通过GAN和软化反向KL散度最小化，将多步去噪教师模型蒸馏为少步去噪学生模型。

Result: 实验表明，FVGen在相同数量新视图下，视觉质量相似或更好，采样时间减少90%以上。

Conclusion: FVGen显著提高了稀疏输入视图下游重建任务的时间效率。

Abstract: Recent progress in 3D reconstruction has enabled realistic 3D models from
dense image captures, yet challenges persist with sparse views, often leading
to artifacts in unseen areas. Recent works leverage Video Diffusion Models
(VDMs) to generate dense observations, filling the gaps when only sparse views
are available for 3D reconstruction tasks. A significant limitation of these
methods is their slow sampling speed when using VDMs. In this paper, we present
FVGen, a novel framework that addresses this challenge by enabling fast novel
view synthesis using VDMs in as few as four sampling steps. We propose a novel
video diffusion model distillation method that distills a multi-step denoising
teacher model into a few-step denoising student model using Generative
Adversarial Networks (GANs) and softened reverse KL-divergence minimization.
Extensive experiments on real-world datasets show that, compared to previous
works, our framework generates the same number of novel views with similar (or
even better) visual quality while reducing sampling time by more than 90%.
FVGen significantly improves time efficiency for downstream reconstruction
tasks, particularly when working with sparse input views (more than 2) where
pre-trained VDMs need to be run multiple times to achieve better spatial
coverage.

</details>


### [91] [A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery](https://arxiv.org/abs/2508.06407)
*Ch Muhammad Awais,Marco Reggiannini,Davide Moroni,Oktay Karakus*

Main category: cs.CV

TL;DR: 论文探讨了将分类目标直接融入超分辨率过程是否能提升分类准确性，并提出了一种新颖的方法来优化图像质量和分类性能。


<details>
  <summary>Details</summary>
Motivation: 低分辨率图像限制了自动化分析的准确性，传统超分辨率方法仅关注像素级指标，未充分探索超分辨率图像保真度与下游分类性能的关系。

Method: 提出了一种新颖方法，通过优化同时考虑图像质量和分类性能的损失函数，提高合成孔径雷达图像的分辨率。

Result: 该方法在科学验证的图像质量指标上提升了图像质量，同时提高了分类准确性。

Conclusion: 将分类目标融入超分辨率过程可以同时改善图像质量和分类性能。

Abstract: High-resolution imagery plays a critical role in improving the performance of
visual recognition tasks such as classification, detection, and segmentation.
In many domains, including remote sensing and surveillance, low-resolution
images can limit the accuracy of automated analysis. To address this,
super-resolution (SR) techniques have been widely adopted to attempt to
reconstruct high-resolution images from low-resolution inputs. Related
traditional approaches focus solely on enhancing image quality based on
pixel-level metrics, leaving the relationship between super-resolved image
fidelity and downstream classification performance largely underexplored. This
raises a key question: can integrating classification objectives directly into
the super-resolution process further improve classification accuracy? In this
paper, we try to respond to this question by investigating the relationship
between super-resolution and classification through the deployment of a
specialised algorithmic strategy. We propose a novel methodology that increases
the resolution of synthetic aperture radar imagery by optimising loss functions
that account for both image quality and classification performance. Our
approach improves image quality, as measured by scientifically ascertained
image quality indicators, while also enhancing classification accuracy.

</details>


### [92] [Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification](https://arxiv.org/abs/2508.06420)
*Ch Muhammad Awais,Marco Reggiannini,Davide Moroni,Oktay Karakus*

Main category: cs.CV

TL;DR: 论文提出两种新算法M2m$_f$和M2m$_u$，用于解决SAR船舰分类中的长尾数据集问题，通过特征空间过采样方法提升分类性能。


<details>
  <summary>Details</summary>
Motivation: SAR船舰分类面临长尾数据集的挑战，尤其是少数类别的分类困难。光学数据中的过采样方法已证明有效，但SAR数据中的效果尚不明确。

Method: 提出两种基于Major-to-minor (M2m)方法的算法M2m$_f$和M2m$_u$，并在OpenSARShip和FuSARShip数据集上测试，使用ViT、VGG16和ResNet50作为特征提取器。

Result: 新方法在FuSARShip和OpenSARShip数据集上平均F1分数分别提高了8.82%和4.44%，优于原始M2m方法和基线。

Conclusion: 特征空间过采样方法能有效提升SAR船舰分类性能，尤其是在长尾数据集中。新算法M2m$_f$和M2m$_u$表现优异。

Abstract: SAR ship classification faces the challenge of long-tailed datasets, which
complicates the classification of underrepresented classes. Oversampling
methods have proven effective in addressing class imbalance in optical data. In
this paper, we evaluated the effect of oversampling in the feature space for
SAR ship classification. We propose two novel algorithms inspired by the
Major-to-minor (M2m) method M2m$_f$, M2m$_u$. The algorithms are tested on two
public datasets, OpenSARShip (6 classes) and FuSARShip (9 classes), using three
state-of-the-art models as feature extractors: ViT, VGG16, and ResNet50.
Additionally, we also analyzed the impact of oversampling methods on different
class sizes. The results demonstrated the effectiveness of our novel methods
over the original M2m and baselines, with an average F1-score increase of 8.82%
for FuSARShip and 4.44% for OpenSARShip.

</details>


### [93] [SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation](https://arxiv.org/abs/2508.06429)
*Guido Manni,Clemente Lauretti,Loredana Zollo,Paolo Soda*

Main category: cs.CV

TL;DR: 提出了一种基于GAN的半监督学习框架，针对医学影像中标记数据稀缺的问题，通过结合生成器、判别器和分类器，在5到50个标记样本的情况下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像中标记数据不足的问题，提升深度学习模型在低标记数据情况下的性能。

Method: 采用三阶段训练框架，结合生成器、判别器和分类器，利用图像翻译和伪标签技术进行半监督学习。

Result: 在11个MedMNIST数据集上显著优于六种最先进的GAN半监督方法，尤其在5-shot情况下表现突出。

Conclusion: 该框架为医学影像提供了一种实用的解决方案，能够在标记数据极少的情况下实现鲁棒的分类性能。

Abstract: Deep learning has revolutionized medical imaging, but its effectiveness is
severely limited by insufficient labeled training data. This paper introduces a
novel GAN-based semi-supervised learning framework specifically designed for
low labeled-data regimes, evaluated across settings with 5 to 50 labeled
samples per class. Our approach integrates three specialized neural networks --
a generator for class-conditioned image translation, a discriminator for
authenticity assessment and classification, and a dedicated classifier --
within a three-phase training framework. The method alternates between
supervised training on limited labeled data and unsupervised learning that
leverages abundant unlabeled images through image-to-image translation rather
than generation from noise. We employ ensemble-based pseudo-labeling that
combines confidence-weighted predictions from the discriminator and classifier
with temporal consistency through exponential moving averaging, enabling
reliable label estimation for unlabeled data. Comprehensive evaluation across
eleven MedMNIST datasets demonstrates that our approach achieves statistically
significant improvements over six state-of-the-art GAN-based semi-supervised
methods, with particularly strong performance in the extreme 5-shot setting
where the scarcity of labeled data is most challenging. The framework maintains
its superiority across all evaluated settings (5, 10, 20, and 50 shots per
class). Our approach offers a practical solution for medical imaging
applications where annotation costs are prohibitive, enabling robust
classification performance even with minimal labeled data. Code is available at
https://github.com/GuidoManni/SPARSE.

</details>


### [94] [MotionSwap](https://arxiv.org/abs/2508.06430)
*Om Patil,Jinesh Modi,Suryabha Mukhopadhyay,Meghaditya Giri,Chhavi Malhotra*

Main category: cs.CV

TL;DR: 本文介绍了对SimSwap框架的改进，通过引入自注意力和交叉注意力机制、动态损失加权和余弦退火学习率调度，显著提升了人脸交换的保真度。


<details>
  <summary>Details</summary>
Motivation: 提高人脸交换技术中的身份保留、属性一致性和视觉质量。

Method: 在生成器架构中集成自注意力和交叉注意力机制，采用动态损失加权和余弦退火学习率调度。

Result: 改进后的模型在身份相似性、FID分数和视觉质量上优于基线模型。

Conclusion: 未来研究方向包括集成StyleGAN3、改进唇同步、引入3D面部建模和视频应用中的时间一致性。

Abstract: Face swapping technology has gained significant attention in both academic
research and commercial applications. This paper presents our implementation
and enhancement of SimSwap, an efficient framework for high fidelity face
swapping. We introduce several improvements to the original model, including
the integration of self and cross-attention mechanisms in the generator
architecture, dynamic loss weighting, and cosine annealing learning rate
scheduling. These enhancements lead to significant improvements in identity
preservation, attribute consistency, and overall visual quality.
  Our experimental results, spanning 400,000 training iterations, demonstrate
progressive improvements in generator and discriminator performance. The
enhanced model achieves better identity similarity, lower FID scores, and
visibly superior qualitative results compared to the baseline. Ablation studies
confirm the importance of each architectural and training improvement. We
conclude by identifying key future directions, such as integrating StyleGAN3,
improving lip synchronization, incorporating 3D facial modeling, and
introducing temporal consistency for video-based applications.

</details>


### [95] [CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment](https://arxiv.org/abs/2508.06434)
*Shengzhu Yang,Jiawei Du,Shuai Lu,Weihang Zhang,Ningli Wang,Huiqi Li*

Main category: cs.CV

TL;DR: CLIPin是一种非对比性插件，用于增强CLIP架构的多模态语义对齐，通过共享预投影器提升对比和非对比学习的结合。


<details>
  <summary>Details</summary>
Motivation: 解决大规模自然图像-文本数据集语义对齐松散和医学数据集内容多样性低的问题，以提升CLIP模型的鲁棒性和泛化能力。

Method: 提出CLIPin插件，设计共享预投影器，结合对比和非对比学习。

Result: 在多样化下游任务中验证了CLIPin的有效性和通用性。

Conclusion: CLIPin是一种即插即用的组件，适用于多种对比框架。

Abstract: Large-scale natural image-text datasets, especially those automatically
collected from the web, often suffer from loose semantic alignment due to weak
supervision, while medical datasets tend to have high cross-modal correlation
but low content diversity. These properties pose a common challenge for
contrastive language-image pretraining (CLIP): they hinder the model's ability
to learn robust and generalizable representations. In this work, we propose
CLIPin, a unified non-contrastive plug-in that can be seamlessly integrated
into CLIP-style architectures to improve multimodal semantic alignment,
providing stronger supervision and enhancing alignment robustness. Furthermore,
two shared pre-projectors are designed for image and text modalities
respectively to facilitate the integration of contrastive and non-contrastive
learning in a parameter-compromise manner. Extensive experiments on diverse
downstream tasks demonstrate the effectiveness and generality of CLIPin as a
plug-and-play component compatible with various contrastive frameworks. Code is
available at https://github.com/T6Yang/CLIPin.

</details>


### [96] [Text Embedded Swin-UMamba for DeepLesion Segmentation](https://arxiv.org/abs/2508.06453)
*Ruida Cheng,Tejas Sudharshan Mathai,Pritam Mukherjee,Benjamin Hou,Qingqing Zhu,Zhiyong Lu,Matthew McAuliffe,Ronald M. Summers*

Main category: cs.CV

TL;DR: 论文提出了一种结合大语言模型（LLM）与Swin-UMamba架构的Text-Swin-UMamba模型，用于CT图像中病灶的自动分割，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 通过结合放射学报告中的文本描述与CT图像特征，提升病灶分割的准确性，为慢性疾病（如淋巴瘤）的临床评估提供自动化支持。

Method: 采用Swin-UMamba架构，整合LLM生成的病灶特征文本描述，在ULS23 DeepLesion数据集上进行训练和测试。

Result: 模型在测试集上取得了82%的Dice分数和6.58像素的Hausdorff距离，性能优于现有方法（如LanGuideMedSeg、xLSTM-UNet和nnUNet）。

Conclusion: Text-Swin-UMamba模型通过结合文本与图像信息，显著提升了病灶分割的准确性，具有临床应用潜力。

Abstract: Segmentation of lesions on CT enables automatic measurement for clinical
assessment of chronic diseases (e.g., lymphoma). Integrating large language
models (LLMs) into the lesion segmentation workflow offers the potential to
combine imaging features with descriptions of lesion characteristics from the
radiology reports. In this study, we investigate the feasibility of integrating
text into the Swin-UMamba architecture for the task of lesion segmentation. The
publicly available ULS23 DeepLesion dataset was used along with short-form
descriptions of the findings from the reports. On the test dataset, a high Dice
Score of 82% and low Hausdorff distance of 6.58 (pixels) was obtained for
lesion segmentation. The proposed Text-Swin-UMamba model outperformed prior
approaches: 37% improvement over the LLM-driven LanGuideMedSeg model (p <
0.001),and surpassed the purely image-based xLSTM-UNet and nnUNet models by
1.74% and 0.22%, respectively. The dataset and code can be accessed at
https://github.com/ruida/LLM-Swin-UMamba

</details>


### [97] [Effective Training Data Synthesis for Improving MLLM Chart Understanding](https://arxiv.org/abs/2508.06492)
*Yuwei Yang,Zeyu Zhang,Yunzhong Hou,Zhuowan Li,Gaowen Liu,Ali Payani,Yuan-Sen Ting,Liang Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种模块化和多样化的图表生成方法，通过五步数据合成流程生成高质量图表数据集（ECD），显著提升了多模态大语言模型（MLLMs）的图表理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有开源MLLMs在图表理解任务上的成功率仅为30%-50%，且合成图表与真实图表的相似性不足限制了模型性能。

Method: 设计了五步数据合成流程，包括模块化图表生成、多样化视觉细节、数据过滤和GPT-4o生成问答对，最终构建了包含10k+图表和300k+问答对的ECD数据集。

Result: ECD数据集显著提升了多种MLLMs在真实和合成测试集上的性能。

Conclusion: 模块化和多样化的图表生成方法有效提升了MLLMs的图表理解能力，ECD数据集为相关研究提供了高质量资源。

Abstract: Being able to effectively read scientific plots, or chart understanding, is a
central part toward building effective agents for science. However, existing
multimodal large language models (MLLMs), especially open-source ones, are
still falling behind with a typical success rate of 30%-50% on challenging
benchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are
often restricted by their inadequate similarity to the real charts, which could
compromise model training and performance on complex real-world charts. In this
study, we show that modularizing chart generation and diversifying visual
details improves chart understanding capabilities. In particular, we design a
five-step data synthesis pipeline, where we separate data and function creation
for single plot generation, condition the generation of later subplots on
earlier ones for multi-subplot figures, visually diversify the generated
figures, filter out low quality data, and finally generate the question-answer
(QA) pairs with GPT-4o. This approach allows us to streamline the generation of
fine-tuning datasets and introduce the effective chart dataset (ECD), which
contains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring
250+ chart type combinations with high visual complexity. We show that ECD
consistently improves the performance of various MLLMs on a range of real-world
and synthetic test sets. Code, data and models are available at:
https://github.com/yuweiyang-anu/ECD.

</details>


### [98] [LightSwitch: Multi-view Relighting with Material-guided Diffusion](https://arxiv.org/abs/2508.06494)
*Yehonathan Litman,Fernando De la Torre,Shubham Tulsiani*

Main category: cs.CV

TL;DR: Lightswitch是一种基于扩散框架的3D重光照方法，利用多视角和材质信息高效重光照多视角数据，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有2D重光照生成先验未充分利用物体固有属性或多视角数据，导致重光照效果不佳。

Method: 提出Lightswitch，结合多视角和材质信息，通过可扩展去噪方案实现高效重光照。

Result: Lightswitch在2D重光照预测质量上优于现有方法，并在合成和真实物体重光照中表现优异。

Conclusion: Lightswitch通过结合固有属性和多视角数据，显著提升了重光照效果和效率。

Abstract: Recent approaches for 3D relighting have shown promise in integrating 2D
image relighting generative priors to alter the appearance of a 3D
representation while preserving the underlying structure. Nevertheless,
generative priors used for 2D relighting that directly relight from an input
image do not take advantage of intrinsic properties of the subject that can be
inferred or cannot consider multi-view data at scale, leading to subpar
relighting. In this paper, we propose Lightswitch, a novel finetuned
material-relighting diffusion framework that efficiently relights an arbitrary
number of input images to a target lighting condition while incorporating cues
from inferred intrinsic properties. By using multi-view and material
information cues together with a scalable denoising scheme, our method
consistently and efficiently relights dense multi-view data of objects with
diverse material compositions. We show that our 2D relighting prediction
quality exceeds previous state-of-the-art relighting priors that directly
relight from images. We further demonstrate that LightSwitch matches or
outperforms state-of-the-art diffusion inverse rendering methods in relighting
synthetic and real objects in as little as 2 minutes.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [99] [Request-Only Optimization for Recommendation Systems](https://arxiv.org/abs/2508.05640)
*Liang Guo,Wei Li,Lucy Liao,Huihui Cheng,Rui Zhang,Yu Shi,Yueming Wang,Yanzun Huang,Keke Zhai,Pengchao Wang,Timothy Shi,Xuan Cao,Shengzhi Wang,Renqin Cai,Zhaojie Gong,Omkar Vichare,Rui Jian,Leon Gao,Shiyan Deng,Xingyu Liu,Xiong Zhang,Fu Li,Wenlei Xie,Bin Wen,Rui Li,Xing Liu,Jiaqi Zhai*

Main category: cs.IR

TL;DR: 论文提出了一种名为ROO（Request-Only Optimizations）的训练和建模范式，通过请求级别的数据处理和模型架构优化，显著提升了推荐系统的存储、训练效率和模型质量。


<details>
  <summary>Details</summary>
Motivation: 工业级DLRMs（深度学习推荐模型）规模庞大，训练数据量巨大，传统方法在处理长用户历史和复杂模型时效率低下，亟需新的优化方法。

Method: ROO范式通过请求级别的数据处理（去重）、基础设施优化（请求级流水线）和模型架构设计（如生成式推荐器），实现高效训练和建模。

Result: ROO显著减少了数据存储需求，并通过去重计算和通信提升了模型性能，支持更复杂的神经网络架构。

Conclusion: ROO为大规模推荐系统提供了一种高效、可扩展的解决方案，显著提升了模型质量和系统效率。

Abstract: Deep Learning Recommendation Models (DLRMs) represent one of the largest
machine learning applications on the planet. Industry-scale DLRMs are trained
with petabytes of recommendation data to serve billions of users every day. To
utilize the rich user signals in the long user history, DLRMs have been scaled
up to unprecedented complexity, up to trillions of floating-point operations
(TFLOPs) per example. This scale, coupled with the huge amount of training
data, necessitates new storage and training algorithms to efficiently improve
the quality of these complex recommendation systems. In this paper, we present
a Request-Only Optimizations (ROO) training and modeling paradigm. ROO
simultaneously improves the storage and training efficiency as well as the
model quality of recommendation systems. We holistically approach this
challenge through co-designing data (i.e., request-only data), infrastructure
(i.e., request-only based data processing pipeline), and model architecture
(i.e., request-only neural architectures). Our ROO training and modeling
paradigm treats a user request as a unit of the training data. Compared with
the established practice of treating a user impression as a unit, our new
design achieves native feature deduplication in data logging, consequently
saving data storage. Second, by de-duplicating computations and communications
across multiple impressions in a request, this new paradigm enables highly
scaled-up neural network architectures to better capture user interest signals,
such as Generative Recommenders (GRs) and other request-only friendly
architectures.

</details>


### [100] [Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05647)
*Vibhor Agrawal,Fay Wang,Rishi Puri*

Main category: cs.IR

TL;DR: 提出一种新型图神经网络架构，用于检索增强生成，通过查询感知注意力机制和学习评分头提高复杂多跳问题的检索准确性。


<details>
  <summary>Details</summary>
Motivation: 传统密集检索方法将文档视为独立实体，无法捕捉文本块间的序列和语义关系，限制了复杂问题的检索效果。

Method: 构建每集知识图谱，结合查询引导的图注意力网络动态聚焦相关部分，利用PyTorch Geometric高效处理图结构数据。

Result: 实验表明，该方法在复杂问答任务中显著优于标准密集检索器，尤其在需要多文档推理的问题上表现突出。

Conclusion: 该架构为复杂检索任务提供了高效解决方案，适合生产环境中的大规模部署。

Abstract: We present a novel graph neural network (GNN) architecture for
retrieval-augmented generation (RAG) that leverages query-aware attention
mechanisms and learned scoring heads to improve retrieval accuracy on complex,
multi-hop questions. Unlike traditional dense retrieval methods that treat
documents as independent entities, our approach constructs per-episode
knowledge graphs that capture both sequential and semantic relationships
between text chunks. We introduce an Enhanced Graph Attention Network with
query-guided pooling that dynamically focuses on relevant parts of the graph
based on user queries. Experimental results demonstrate that our approach
significantly outperforms standard dense retrievers on complex question
answering tasks, particularly for questions requiring multi-document reasoning.
Our implementation leverages PyTorch Geometric for efficient processing of
graph-structured data, enabling scalable deployment in production retrieval
systems

</details>


### [101] [AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups](https://arxiv.org/abs/2508.05648)
*Chandler Campbell,Bernie Boscoe,Tuan Do*

Main category: cs.IR

TL;DR: AquiLLM是一个轻量级、模块化的RAG系统，旨在帮助研究团队更有效地获取正式和非正式知识。


<details>
  <summary>Details</summary>
Motivation: 研究团队在捕获、存储和检索分散在团队成员中的知识方面面临持续挑战，尤其是非正式和未记录的知识。

Method: AquiLLM是一个支持多种文档类型和可配置隐私设置的RAG系统。

Result: AquiLLM能够更有效地访问学术团队中的正式和非正式知识。

Conclusion: AquiLLM为研究团队提供了一种解决知识管理难题的新方法。

Abstract: Research groups face persistent challenges in capturing, storing, and
retrieving knowledge that is distributed across team members. Although
structured data intended for analysis and publication is often well managed,
much of a group's collective knowledge remains informal, fragmented, or
undocumented--often passed down orally through meetings, mentoring, and
day-to-day collaboration. This includes private resources such as emails,
meeting notes, training materials, and ad hoc documentation. Together, these
reflect the group's tacit knowledge--the informal, experience-based expertise
that underlies much of their work. Accessing this knowledge can be difficult,
requiring significant time and insider understanding. Retrieval-augmented
generation (RAG) systems offer promising solutions by enabling users to query
and generate responses grounded in relevant source material. However, most
current RAG-LLM systems are oriented toward public documents and overlook the
privacy concerns of internal research materials. We introduce AquiLLM
(pronounced ah-quill-em), a lightweight, modular RAG system designed to meet
the needs of research groups. AquiLLM supports varied document types and
configurable privacy settings, enabling more effective access to both formal
and informal knowledge within scholarly groups.

</details>


### [102] [AI Guided Accelerator For Search Experience](https://arxiv.org/abs/2508.05649)
*Jayanth Yetukuri,Mehran Elyasi,Samarth Agrawal,Aritra Mandal,Rui Kong,Harish Vempati,Ishita Khan*

Main category: cs.IR

TL;DR: 论文提出了一种新框架，通过建模过渡性查询和利用大型语言模型（LLMs）改进电子商务中的查询重写，显著提升了转化率和用户参与度。


<details>
  <summary>Details</summary>
Motivation: 传统方法将查询重写视为孤立对，未能捕捉用户行为的序列和动态变化，导致搜索效果不佳。

Method: 通过挖掘eBay用户交互日志中的结构化查询轨迹，建模过渡性查询，并结合LLMs生成语义多样且意图保留的替代查询。

Result: 实证评估显示，该方法在转化率和用户参与度上优于现有相关搜索模块。

Conclusion: 该框架有效解决了电子商务中查询重写的动态性和意图多样性问题，具有实际应用价值。

Abstract: Effective query reformulation is pivotal in narrowing the gap between a
user's exploratory search behavior and the identification of relevant products
in e-commerce environments. While traditional approaches predominantly model
query rewrites as isolated pairs, they often fail to capture the sequential and
transitional dynamics inherent in real-world user behavior. In this work, we
propose a novel framework that explicitly models transitional
queries--intermediate reformulations occurring during the user's journey toward
their final purchase intent. By mining structured query trajectories from
eBay's large-scale user interaction logs, we reconstruct query sequences that
reflect shifts in intent while preserving semantic coherence. This approach
allows us to model a user's shopping funnel, where mid-journey transitions
reflect exploratory behavior and intent refinement. Furthermore, we incorporate
generative Large Language Models (LLMs) to produce semantically diverse and
intent-preserving alternative queries, extending beyond what can be derived
through collaborative filtering alone. These reformulations can be leveraged to
populate Related Searches or to power intent-clustered carousels on the search
results page, enhancing both discovery and engagement. Our contributions
include (i) the formal identification and modeling of transitional queries,
(ii) the introduction of a structured query sequence mining pipeline for intent
flow understanding, and (iii) the application of LLMs for scalable,
intent-aware query expansion. Empirical evaluation demonstrates measurable
gains in conversion and engagement metrics compared to the existing Related
Searches module, validating the effectiveness of our approach in real-world
e-commerce settings.

</details>


### [103] [OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools](https://arxiv.org/abs/2508.05650)
*Jiaxuan Liang,Shide Zhou,Kailong Wang*

Main category: cs.IR

TL;DR: OmniBench RAG是一个自动化平台，用于多领域评估RAG系统，提供标准化指标和动态测试生成，揭示了RAG在不同领域的表现差异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在评估RAG性能时存在不足，如缺乏领域覆盖、指标粗糙且无法标准化比较。

Method: 开发了OmniBench RAG平台，量化准确性和效率提升，引入标准化指标Improvements和Transformation。

Result: 评估显示RAG在不同领域的效果差异显著，如文化领域表现优异而数学领域表现下降。

Conclusion: 系统化、领域感知的评估对RAG性能分析至关重要，OmniBench RAG为此提供了标准化框架。

Abstract: While Retrieval Augmented Generation (RAG) is now widely adopted to enhance
LLMs, evaluating its true performance benefits in a reproducible and
interpretable way remains a major hurdle. Existing methods often fall short:
they lack domain coverage, employ coarse metrics that miss sub document
precision, and fail to capture computational trade offs. Most critically, they
provide no standardized framework for comparing RAG effectiveness across
different models and domains.
  We introduce OmniBench RAG, a novel automated platform for multi domain
evaluation of RAG systems. The platform quantifies performance gains across
accuracy and efficiency dimensions, spanning nine knowledge fields including
culture, geography, and health. We introduce two standardized metrics:
Improvements (accuracy gains) and Transformation (efficiency differences
between pre RAG and post RAG models), enabling reproducible comparisons across
models and tasks. The platform features dynamic test generation, modular
evaluation pipelines, and automated knowledge base construction. Our evaluation
reveals striking variability in RAG effectiveness, from significant gains in
culture to declines in mathematics, highlighting the critical importance of
systematic, domain aware assessment. A demonstration video is available at:
https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:
https://github.com/Garnett-Liang/Omnibench-RAG.

</details>


### [104] [Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation](https://arxiv.org/abs/2508.05652)
*Julia Ann Mathew,Suining He*

Main category: cs.IR

TL;DR: 本文介绍了基于大型语言模型（LLM）和检索增强生成（RAG）开发的户外步道推荐聊天机器人Judy，解决了户外活动信息准确性和推荐效率的挑战。


<details>
  <summary>Details</summary>
Motivation: 户外休闲活动的增加导致对个性化步道推荐的需求上升，但如何通过对话AI提供准确信息及高效服务成为挑战。

Method: 开发了基于LLM和RAG的聊天机器人Judy，并通过康涅狄格州户外步道的案例研究验证其性能。

Result: 实验结果表明，Judy在准确性、有效性和可用性方面表现良好。

Conclusion: 基于LLM和RAG的Judy系统为户外步道推荐提供了可行的解决方案。

Abstract: The increasing popularity of outdoor recreational activities (such as hiking
and biking) has boosted the demand for a conversational AI system to provide
informative and personalized suggestion on outdoor trails. Challenges arise in
response to (1) how to provide accurate outdoor trail information via
conversational AI; and (2) how to enable usable and efficient recommendation
services. To address above, this paper discusses the preliminary and practical
lessons learned from developing Judy, an outdoor trail recommendation chatbot
based on the large language model (LLM) with retrieval augmented generation
(RAG). To gain concrete system insights, we have performed case studies with
the outdoor trails in Connecticut (CT), US. We have conducted web-based data
collection, outdoor trail data management, and LLM model performance studies on
the RAG-based recommendation. Our experimental results have demonstrated the
accuracy, effectiveness, and usability of Judy in recommending outdoor trails
based on the LLM with RAG.

</details>


### [105] [Comparison of Information Retrieval Techniques Applied to IT Support Tickets](https://arxiv.org/abs/2508.05654)
*Leonardo Santiago Benitez Pereira,Robinson Pizzio,Samir Bonho*

Main category: cs.IR

TL;DR: 该论文比较了11种信息检索技术在IT支持工单数据集上的表现，目标是开发一个辅助IT支持分析师的软件。Sentence-BERT的多语言版本表现最佳，准确率达78.7%。


<details>
  <summary>Details</summary>
Motivation: IT帮助台系统对IT服务至关重要，但不同机器学习模型在不同数据集上表现不一，因此需要比较不同技术以优化系统。

Method: 使用11种信息检索技术（如Sentence-BERT、TF-IDF、Word2vec、LDA）在IT支持工单数据集上进行实验，并开发了一个最小可行原型。

Result: Sentence-BERT的多语言版本（distilluse-base-multilingual-cased-v1）表现最佳，准确率为78.7%，其他技术如TF-IDF（69.0%）、Word2vec（68.7%）和LDA（66.3%）也表现良好。

Conclusion: 论文展示了支持工单检索系统的实用性，提出了一种新的评估指标，并开源了数据集和代码。

Abstract: Institutions dependent on IT services and resources acknowledge the crucial
significance of an IT help desk system, that act as a centralized hub
connecting IT staff and users for service requests. Employing various Machine
Learning models, these IT help desk systems allow access to corrective actions
used in the past, but each model has different performance when applied to
different datasets. This work compares eleven Information Retrieval techniques
in a dataset of IT support tickets, with the goal of implementing a software
that facilitates the work of Information Technology support analysts. The best
results were obtained with the Sentence-BERT technique, in its multi-language
variation distilluse-base-multilingual-cased-v1, where 78.7% of the
recommendations made by the model were considered relevant. TF-IDF (69.0%),
Word2vec (68.7%) and LDA (66.3%) techniques also had consistent results.
Furthermore, the used datasets and essential parts of coding have been
published and made open source. It also demonstrated the practicality of a
support ticket recovery system by implementing a minimal viable prototype, and
described in detail the implementation of the system. Finally, this work
proposed a novel metric for comparing the techniques, whose aim is to closely
reflect the perception of the IT analysts about the retrieval quality.

</details>


### [106] [Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation](https://arxiv.org/abs/2508.05657)
*Haozhe Xu,Xiaohua Wang,Changze Lv,Xiaoqing Zheng*

Main category: cs.IR

TL;DR: 论文提出了一种基于LLM的数据增强框架，通过两阶段训练策略解决CRS中的假阴性问题，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 对话推荐系统（CRS）在训练中常因假阴性问题导致推荐效果不佳，数据增强虽直观但需平衡语义相关性和协作信息。

Method: 提出LLM语义检索器识别相关项，经相关性评分器过滤噪声，采用两阶段训练策略平衡语义与协作信息。

Result: 在多个基准数据集和用户模拟器上实验表明，该方法显著提升了推荐性能。

Conclusion: 该框架有效解决了CRS中的假阴性问题，为CRS性能提升提供了新思路。

Abstract: Conversational recommender systems (CRSs) enhance recommendation quality by
engaging users in multi-turn dialogues, capturing nuanced preferences through
natural language interactions. However, these systems often face the false
negative issue, where items that a user might like are incorrectly labeled as
negative during training, leading to suboptimal recommendations.Expanding the
label set through data augmentation presents an intuitive solution but faces
the challenge of balancing two key aspects: ensuring semantic relevance and
preserving the collaborative information inherent in CRS datasets. To address
these issues, we propose a novel data augmentation framework that first
leverages an LLM-based semantic retriever to identify diverse and semantically
relevant items, which are then filtered by a relevance scorer to remove noisy
candidates. Building on this, we introduce a two-stage training strategy
balancing semantic relevance and collaborative information. Extensive
experiments on two benchmark datasets and user simulators demonstrate
significant and consistent performance improvements across various
recommenders, highlighting the effectiveness of our approach in advancing CRS
performance.

</details>


### [107] [Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review](https://arxiv.org/abs/2508.05660)
*Aditya Nagori,Ricardo Accorsi Casonatto,Ayush Gautam,Abhinav Manikantha Sai Cheruvu,Rishikesan Kamaleswaran*

Main category: cs.IR

TL;DR: 论文提出了一种动态混合检索增强生成（RAG）系统，通过自主代理结合图查询和向量搜索，提升科学文献分析的准确性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 科学文献数量激增，传统综述方法效率低下，需要结合结构化元数据和全文分析的工具。现有混合RAG系统多为静态，依赖专有工具且缺乏不确定性估计。

Method: 系统整合PubMed、arXiv和Google Scholar的数据，构建Neo4j知识图和FAISS向量库，由Llama-3.3-70B代理动态选择GraphRAG或VectorRAG，并实时调整生成内容。

Result: 在合成基准测试中，系统在多个指标上显著优于基线，如VS上下文召回率提升0.63，整体上下文精确度提升0.56。

Conclusion: 该系统通过动态选择和不确定性量化，提升了异构数据源的分析能力，为自主科学发现提供了可扩展框架。

Abstract: The surge in scientific publications challenges traditional review methods,
demanding tools that integrate structured metadata with full-text analysis.
Hybrid Retrieval Augmented Generation (RAG) systems, combining graph queries
with vector search offer promise but are typically static, rely on proprietary
tools, and lack uncertainty estimates. We present an agentic approach that
encapsulates the hybrid RAG pipeline within an autonomous agent capable of (1)
dynamically selecting between GraphRAG and VectorRAG for each query, (2)
adapting instruction-tuned generation in real time to researcher needs, and (3)
quantifying uncertainty during inference. This dynamic orchestration improves
relevance, reduces hallucinations, and promotes reproducibility.
  Our pipeline ingests bibliometric open-access data from PubMed, arXiv, and
Google Scholar APIs, builds a Neo4j citation-based knowledge graph (KG), and
embeds full-text PDFs into a FAISS vector store (VS) using the all-MiniLM-L6-v2
model. A Llama-3.3-70B agent selects GraphRAG (translating queries to Cypher
for KG) or VectorRAG (combining sparse and dense retrieval with re-ranking).
Instruction tuning refines domain-specific generation, and bootstrapped
evaluation yields standard deviation for evaluation metrics.
  On synthetic benchmarks mimicking real-world queries, the Instruction-Tuned
Agent with Direct Preference Optimization (DPO) outperforms the baseline,
achieving a gain of 0.63 in VS Context Recall and a 0.56 gain in overall
Context Precision. Additional gains include 0.24 in VS Faithfulness, 0.12 in
both VS Precision and KG Answer Relevance, 0.11 in overall Faithfulness score,
0.05 in KG Context Recall, and 0.04 in both VS Answer Relevance and overall
Precision. These results highlight the system's improved reasoning over
heterogeneous sources and establish a scalable framework for autonomous,
agentic scientific discovery.

</details>


### [108] [Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace](https://arxiv.org/abs/2508.05661)
*Andre Rusli,Shoma Ishimoto,Sho Akiyama,Aman Kumar Singh*

Main category: cs.IR

TL;DR: 论文介绍了一个在Mercari C2C市场中部署的可扩展视觉搜索系统，评估了零样本图像检索的视觉语言模型性能，并展示了SigLIP模型在多语言检索中的优势。


<details>
  <summary>Details</summary>
Motivation: 在C2C市场中，产品列表通常是非结构化和视觉驱动的，因此需要一种直观的视觉搜索系统来帮助用户探索产品。

Method: 系统集成了实时推理和后台索引工作流，通过统一的嵌入管道和降维优化，评估了零样本图像检索模型的性能。

Result: SigLIP模型在离线评估中表现最佳，nDCG@5提高了13.3%；在线A/B测试中，交易率提升了40.9%。

Conclusion: 零样本模型可以作为生产环境的强基线，减少部署成本，同时保留未来微调的灵活性。

Abstract: Visual search offers an intuitive way for customers to explore diverse
product catalogs, particularly in consumer-to-consumer (C2C) marketplaces where
listings are often unstructured and visually driven. This paper presents a
scalable visual search system deployed in Mercari's C2C marketplace, where
end-users act as buyers and sellers. We evaluate recent vision-language models
for zero-shot image retrieval and compare their performance with an existing
fine-tuned baseline. The system integrates real-time inference and background
indexing workflows, supported by a unified embedding pipeline optimized through
dimensionality reduction. Offline evaluation using user interaction logs shows
that the multilingual SigLIP model outperforms other models across multiple
retrieval metrics, achieving a 13.3% increase in nDCG@5 over the baseline. A
one-week online A/B test in production further confirms real-world impact, with
the treatment group showing substantial gains in engagement and conversion, up
to a 40.9% increase in transaction rate via image search. Our findings
highlight that recent zero-shot models can serve as a strong and practical
baseline for production use, which enables teams to deploy effective visual
search systems with minimal overhead, while retaining the flexibility to
fine-tune based on future data or domain-specific needs.

</details>


### [109] [From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base](https://arxiv.org/abs/2508.05662)
*Yuzhou Zhu*

Main category: cs.IR

TL;DR: Streaming RAG提出了一种动态处理流数据的统一框架，解决了静态RAG框架在内存成本、数据新鲜度和语义覆盖上的不足。


<details>
  <summary>Details</summary>
Motivation: 动态流数据（如新闻、社交媒体、传感器网络和金融市场）对静态RAG框架提出了挑战，包括高内存成本、数据延迟和语义覆盖不足。

Method: 结合多向量余弦筛选、小批量聚类和基于计数器的频繁项过滤器，维护紧凑的原型集，并通过增量索引更新机制实现无中断查询。

Result: 在8个实时流上的实验显示，Recall@10显著提升（最高3分，p<0.01），延迟低于15ms，吞吐量超过900文档/秒（150MB内存限制）。在问答和摘要任务中，Exact Match和F1分数分别提升3.2和2.8分。

Conclusion: Streaming RAG为检索增强技术设定了新的帕累托前沿，显著提升了动态流数据的处理效率和质量。

Abstract: Dynamic streams from news feeds, social media, sensor networks, and financial
markets challenge static RAG frameworks. Full-scale indices incur high memory
costs; periodic rebuilds introduce latency that undermines data freshness;
naive sampling sacrifices semantic coverage. We present Streaming RAG, a
unified pipeline that combines multi-vector cosine screening, mini-batch
clustering, and a counter-based heavy-hitter filter to maintain a compact
prototype set. We further prove an approximation bound \$E\[R(K\_t)] \ge R^\* -
L \Delta\$ linking retrieval quality to clustering variance. An incremental
index upsert mechanism refreshes prototypes without interrupting queries.
Experiments on eight real-time streams show statistically significant gains in
Recall\@10 (up to 3 points, p < 0.01), end-to-end latency below 15 ms, and
throughput above 900 documents per second under a 150 MB budget. Hyperparameter
sensitivity analysis over cluster count, admission probability, relevance
threshold, and counter capacity validates default settings. In open-domain
question answering with GPT-3.5 Turbo, we record 3.2-point gain in Exact Match
and 2.8-point gain in F1 on SQuAD; abstractive summarization yields ROUGE-L
improvements. Streaming RAG establishes a new Pareto frontier for retrieval
augmentation.

</details>


### [110] [Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support](https://arxiv.org/abs/2508.05664)
*Hei Yu Chan,Kuok Tou Ho,Chenglong Ma,Yujing Si,Hok Lai Lin,Sa Lei Lam*

Main category: cs.IR

TL;DR: 论文评估了多种技术（如查询重写、RAG Fusion、意图识别等）在电力领域构建鲁棒客服系统的效果，最终选择基于图的RAG框架，结合意图识别和重排序，显著提升了复杂查询的处理性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI客服系统在模糊、多意图或细节查询上表现不佳，需探索更有效的技术。

Method: 比较向量存储和图RAG框架，测试查询重写、RAG Fusion、关键词增强、意图识别和上下文重排序技术。

Result: 基于图的RAG结合意图识别和重排序，在生成和真实数据集上分别达到97.9%和89.6%的准确率。

Conclusion: 图RAG框架结合意图识别和重排序是处理复杂查询的最优方案，关键词增强效果不佳。

Abstract: Many AI customer service systems use standard NLP pipelines or finetuned
language models, which often fall short on ambiguous, multi-intent, or
detail-specific queries. This case study evaluates recent techniques: query
rewriting, RAG Fusion, keyword augmentation, intent recognition, and context
reranking, for building a robust customer support system in the electric power
domain. We compare vector-store and graph-based RAG frameworks, ultimately
selecting the graph-based RAG for its superior performance in handling complex
queries. We find that query rewriting improves retrieval for queries using
non-standard terminology or requiring precise detail. RAG Fusion boosts
performance on vague or multifaceted queries by merging multiple retrievals.
Reranking reduces hallucinations by filtering irrelevant contexts. Intent
recognition supports the decomposition of complex questions into more targeted
sub-queries, increasing both relevance and efficiency. In contrast, keyword
augmentation negatively impacts results due to biased keyword selection. Our
final system combines intent recognition, RAG Fusion, and reranking to handle
disambiguation and multi-source queries. Evaluated on both a GPT-4-generated
dataset and a real-world electricity provider FAQ dataset, it achieves 97.9%
and 89.6% accuracy respectively, substantially outperforming baseline RAG
models.

</details>


### [111] [HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis](https://arxiv.org/abs/2508.05666)
*Alejandro Godinez*

Main category: cs.IR

TL;DR: HySemRAG结合ETL和RAG，通过多层检索、自校正框架和引用验证，自动化大规模文献合成并识别研究空白。


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG架构的局限性，提升文献合成的效率和可验证性。

Method: 采用混合检索（语义搜索、关键词过滤、知识图谱遍历）、自校正框架和引用验证，分八个阶段处理文献。

Result: 在643个观察中，语义相似度得分提高35.1%，自校正机制单次通过率68.3%，引用准确率99%。

Conclusion: HySemRAG在加速科学证据合成和发现方面具有广泛适用性。

Abstract: We present HySemRAG, a framework that combines Extract, Transform, Load (ETL)
pipelines with Retrieval-Augmented Generation (RAG) to automate large-scale
literature synthesis and identify methodological research gaps. The system
addresses limitations in existing RAG architectures through a multi-layered
approach: hybrid retrieval combining semantic search, keyword filtering, and
knowledge graph traversal; an agentic self-correction framework with iterative
quality assurance; and post-hoc citation verification ensuring complete
traceability. Our implementation processes scholarly literature through eight
integrated stages: multi-source metadata acquisition, asynchronous PDF
retrieval, custom document layout analysis using modified Docling architecture,
bibliographic management, LLM-based field extraction, topic modeling, semantic
unification, and knowledge graph construction. The system creates dual data
products - a Neo4j knowledge graph enabling complex relationship queries and
Qdrant vector collections supporting semantic search - serving as foundational
infrastructure for verifiable information synthesis. Evaluation across 643
observations from 60 testing sessions demonstrates structured field extraction
achieving 35.1% higher semantic similarity scores (0.655 $\pm$ 0.178) compared
to PDF chunking approaches (0.485 $\pm$ 0.204, p < 0.000001). The agentic
quality assurance mechanism achieves 68.3% single-pass success rates with 99.0%
citation accuracy in validated responses. Applied to geospatial epidemiology
literature on ozone exposure and cardiovascular disease, the system identifies
methodological trends and research gaps, demonstrating broad applicability
across scientific domains for accelerating evidence synthesis and discovery.

</details>


### [112] [ITDR: An Instruction Tuning Dataset for Enhancing Large Language Models in Recommendations](https://arxiv.org/abs/2508.05667)
*Zekun Liu,Xiaowen Huang,Jitao Sang*

Main category: cs.IR

TL;DR: 论文提出ITDR数据集，通过指令调优提升LLMs在推荐任务中的性能，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在推荐系统中因数据结构差异导致的性能不足问题。

Method: 构建ITDR指令调优数据集，包含7个子任务和20万实例，用于调优主流开源LLMs。

Result: ITDR显著提升LLMs在推荐任务中的表现，并分析了任务相关性及数据规模的影响。

Conclusion: ITDR数据集和调优方法有效，为LLMs在推荐系统中的应用提供了新思路。

Abstract: Large language models (LLMs) have demonstrated outstanding performance in
natural language processing tasks. However, in the field of recommendation
systems, due to the structural differences between user behavior data and
natural language, LLMs struggle to effectively model the associations between
user preferences and items. Although prompt-based methods can generate
recommendation results, their inadequate understanding of recommendation tasks
leads to constrained performance. To address this gap, in this work, we
construct a sufficient instruction tuning dataset, ITDR, which encompasses 7
subtasks across two core root tasks--user-item interaction and user-item
understanding. The dataset integrates data from 13 public recommendation
datasets and is built using manually crafted standardized templates, comprising
approximately 200,000 instances. Experimental results demonstrate that ITDR
significantly enhances the performance of mainstream open-source LLMs such as
GLM-4, Qwen2.5, Qwen2.5-Instruct and LLaMA-3.2 on recommendation tasks.
Furthermore, we analyze the correlations between tasks and explore the impact
of task descriptions and data scale on instruction tuning effectiveness.
Finally, we perform comparative experiments against closed-source LLMs with
substantial parameters. Our tuning dataset ITDR and the fine-tuned large
recommendation models can be accessed at https://github.com/hellolzk/ITDR.

</details>


### [113] [A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges](https://arxiv.org/abs/2508.05668)
*Yunjia Xi,Jianghao Lin,Yongzhao Xiao,Zheli Zhou,Rong Shan,Te Gao,Jiachen Zhu,Weiwen Liu,Yong Yu,Weinan Zhang*

Main category: cs.IR

TL;DR: 本文系统分析了基于大语言模型（LLM）的搜索代理，探讨了其架构、优化、应用和评估，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的出现显著改变了网络搜索方式，搜索代理能够动态、自主地执行多轮检索，扩展了搜索能力。本文旨在系统分析这一新兴领域。

Method: 通过综合分析和分类现有研究，从架构、优化、应用和评估四个角度进行系统梳理。

Result: 总结了搜索代理的潜力与挑战，并提供了开源资源库。

Conclusion: 搜索代理领域发展迅速，但仍存在关键挑战，未来研究需进一步探索动态规划和实际应用。

Abstract: The advent of Large Language Models (LLMs) has significantly revolutionized
web search. The emergence of LLM-based Search Agents marks a pivotal shift
towards deeper, dynamic, autonomous information seeking. These agents can
comprehend user intentions and environmental context and execute multi-turn
retrieval with dynamic planning, extending search capabilities far beyond the
web. Leading examples like OpenAI's Deep Research highlight their potential for
deep information mining and real-world applications. This survey provides the
first systematic analysis of search agents. We comprehensively analyze and
categorize existing works from the perspectives of architecture, optimization,
application, and evaluation, ultimately identifying critical open challenges
and outlining promising future research directions in this rapidly evolving
field. Our repository is available on
https://github.com/YunjiaXi/Awesome-Search-Agent-Papers.

</details>


### [114] [Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports](https://arxiv.org/abs/2508.05669)
*Jin Khye Tan,En Jun Choong,Ethan Jeremiah Chitty,Yan Pheng Choo,John Hsin Yang Wong,Chern Eu Cheah*

Main category: cs.IR

TL;DR: 该研究提出了一种基于Qwen2.5-VL-7B的微调视觉语言模型，用于将马来西亚审计财务报表中的复杂表格转换为Markdown格式，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 从财务文档中准确提取表格结构是一个关键挑战，尤其是在多级标题和旋转布局等复杂情况下。

Method: 使用2,152个图像-文本对的数据集和LoRA微调策略，优化模型生成Markdown的能力，并通过LLM和TEDS指标评估性能。

Result: 模型在标准评估中达到92.20%的准确率和96.53%的TEDS分数，优于基础模型和其他大型模型。

Conclusion: 领域特定微调能高效解决财务文档自动化问题，性能优于通用大模型且计算成本更低。

Abstract: Accurately extracting and representing the structure of tabular data from
financial documents remains a critical challenge in document understanding,
particularly for regulatory and analytical use cases. This study addresses the
complexity of converting financial tables from Malaysian audited financial
reports into Markdown format, a task complicated by rotated layouts,
multi-level headers, and implicit structural cues. We propose a fine-tuned
vision-language model (VLM), based on Qwen2.5-VL-7B, optimized for
high-fidelity Markdown generation from document images. Our approach includes a
curated dataset of 2,152 image-text pairs with augmentations and a supervised
fine-tuning strategy using LoRA. To assess performance, we evaluated our model
on 100 out-of-sample tables using a dual framework: a criteria-based
LLM-as-a-judge for fine-grained accuracy and our novel Markdown
Tree-Edit-Distance-based Similarity (TEDS) metric for holistic structural
fidelity. Our model achieves a 92.20% overall accuracy on the criteria-based
assessment and a 96.53% Markdown TEDS score. This performance significantly
surpasses its Qwen2.5-VL-7B base model, larger-scale VLMs, and specialized
reasoning-enabled models. Compared to these self-hosted alternatives, it also
significantly reduces inference time. Furthermore, its accuracy exceeds that of
widely used proprietary models such as OpenAI's GPT-4o and Gemini 2.5 Flash.
These results demonstrate that domain-specific fine-tuning provides an
effective and efficient method to bridge the gap between unstructured financial
documents and downstream automation, rivalling much larger and more general
models without their computational overhead.

</details>


### [115] [LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing](https://arxiv.org/abs/2508.05672)
*Yao Zhao,Yantian Ding,Zhiyue Zhang,Dapeng Yao,Yanxun Xu*

Main category: cs.IR

TL;DR: LMAR是一个模型无关的框架，通过结合LLM引导的数据合成、对比嵌入适应和高效文本聚类，解决了RAG系统在领域特定知识中的性能问题。


<details>
  <summary>Details</summary>
Motivation: RAG系统在领域特定知识中表现不佳，预训练嵌入性能下降和LLM检索器计算成本高是主要挑战。

Method: LMAR采用两阶段流程：1) 三元组采样和合成数据增强，LLM作为标注器和验证器；2) 结合对比嵌入适应和文本聚类。

Result: 实验表明LMAR在多个领域特定数据集上优于基线模型，同时保持适度的硬件需求和低延迟。

Conclusion: LMAR是一种实用且经济的解决方案，可无缝集成到新兴RAG架构中，无需重新设计流程。

Abstract: Retrieval Augmented Generation (RAG) systems often struggle with
domain-specific knowledge due to performance deterioration of pre-trained
embeddings and prohibitive computational costs of large language model
(LLM)-based retrievers. While fine-tuning data augmentation embedding models
offers a promising direction, its effectiveness is limited by the need for
high-quality training data and reliable chunking strategies that preserve
contextual integrity. We propose LMAR (Language Model Augmented Retriever), a
model-agnostic framework that addresses these challenges by combining
LLM-guided data synthesis with contrastive embedding adaptation and efficient
text clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling
and synthetic data augmentation, where LLMs act as both labeler and validator
to ensure high-fidelity supervision throughout the pipeline. Experimental
results across multiple domain-specific benchmark datasets demonstrate that
LMAR outperforms multiple baseline models, while maintaining moderate hardware
requirements and low latency. Its model-agnostic nature further enables
seamless integration with emerging RAG architectures and text embedding models,
ensuring continual improvements without redesigning the pipeline. These results
highlight LMAR as a practical and cost-effective solution for scalable
domain-specific adaptation.

</details>


### [116] [Breaking the Top-$K$ Barrier: Advancing Top-$K$ Ranking Metrics Optimization in Recommender Systems](https://arxiv.org/abs/2508.05673)
*Weiqin Yang,Jiawei Chen,Shengjia Zhang,Peng Wu,Yuegang Sun,Yan Feng,Chun Chen,Can Wang*

Main category: cs.IR

TL;DR: 论文提出了一种名为SoftmaxLoss@K（SL@K）的新型推荐损失函数，用于优化NDCG@K指标，解决了现有方法忽略Top-K截断或计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统中，NDCG@K是评估推荐性能的金标准，但其优化存在不连续性和Top-K截断的复杂性，现有方法未能有效解决这些问题。

Method: 通过结合分位数技术处理Top-K截断，并推导出一个平滑上界来优化NDCG@K，从而设计出SL@K损失函数。

Result: 在四个真实数据集和三种推荐骨干模型上的实验表明，SL@K平均性能提升了6.03%。

Conclusion: SL@K具有理论保证、易于实现、计算高效、梯度稳定和噪声鲁棒性等优点，显著优于现有方法。

Abstract: In the realm of recommender systems (RS), Top-$K$ ranking metrics such as
NDCG@$K$ are the gold standard for evaluating recommendation performance.
However, during the training of recommendation models, optimizing NDCG@$K$
poses significant challenges due to its inherent discontinuous nature and the
intricate Top-$K$ truncation. Recent efforts to optimize NDCG@$K$ have either
overlooked the Top-$K$ truncation or suffered from high computational costs and
training instability. To overcome these limitations, we propose SoftmaxLoss@$K$
(SL@$K$), a novel recommendation loss tailored for NDCG@$K$ optimization.
Specifically, we integrate the quantile technique to handle Top-$K$ truncation
and derive a smooth upper bound for optimizing NDCG@$K$ to address
discontinuity. The resulting SL@$K$ loss has several desirable properties,
including theoretical guarantees, ease of implementation, computational
efficiency, gradient stability, and noise robustness. Extensive experiments on
four real-world datasets and three recommendation backbones demonstrate that
SL@$K$ outperforms existing losses with a notable average improvement of 6.03%.
The code is available at https://github.com/Tiny-Snow/IR-Benchmark.

</details>


### [117] [Domain-Specific Fine-Tuning and Prompt-Based Learning: A Comparative Study for developing Natural Language-Based BIM Information Retrieval Systems](https://arxiv.org/abs/2508.05676)
*Han Gao,Timo Hartmann,Botao Zhong,Kai Lia,Hanbin Luo*

Main category: cs.IR

TL;DR: 比较了两种自然语言接口（NLI）方法在BIM信息检索中的表现，提出了一种结合微调和提示学习的混合配置，以提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决BIM环境中通过自然语言查询准确提取数据的挑战。

Method: 采用两阶段框架（意图识别和基于表格的问答），比较领域微调和提示学习，并构建BIM专用数据集进行测试。

Result: 微调在意图识别中表现更优，提示学习（如GPT-4o）在问答中更强；混合配置实现了更均衡的性能。

Conclusion: 混合方法适用于实际BIM场景，为设计智能语言驱动系统提供了参考。

Abstract: Building Information Modeling (BIM) is essential for managing building data
across the entire lifecycle, supporting tasks from design to maintenance.
Natural Language Interface (NLI) systems are increasingly explored as
user-friendly tools for information retrieval in Building Information Modeling
(BIM) environments. Despite their potential, accurately extracting BIM-related
data through natural language queries remains a persistent challenge due to the
complexity use queries and specificity of domain knowledge. This study presents
a comparative analysis of two prominent approaches for developing NLI-based BIM
information retrieval systems: domain-specific fine-tuning and prompt-based
learning using large language models (LLMs). A two-stage framework consisting
of intent recognition and table-based question answering is implemented to
evaluate the effectiveness of both approaches. To support this evaluation, a
BIM-specific dataset of 1,740 annotated queries of varying types across 69
models is constructed. Experimental results show that domain-specific
fine-tuning delivers superior performance in intent recognition tasks, while
prompt-based learning, particularly with GPT-4o, shows strength in table-based
question answering. Based on these findings, this study identify a hybrid
configuration that combines fine-tuning for intent recognition with
prompt-based learning for question answering, achieving more balanced and
robust performance across tasks. This integrated approach is further tested
through case studies involving BIM models of varying complexity. This study
provides a systematic analysis of the strengths and limitations of each
approach and discusses the applicability of the NLI to real-world BIM
scenarios. The findings offer insights for researchers and practitioners in
designing intelligent, language-driven BIM systems.

</details>


### [118] [Are All Genders Equal in the Eyes of Algorithms? -- Analysing Search and Retrieval Algorithms for Algorithmic Gender Fairness](https://arxiv.org/abs/2508.05680)
*Stefanie Urchs,Veronika Thurner,Matthias Aßenmacher,Ludwig Bothmann,Christian Heumann,Stephanie Thiemichen*

Main category: cs.IR

TL;DR: 论文研究了算法系统（如搜索引擎）对学术可见性的影响，提出了一种基于性别公平的算法定义，并通过德国大学数据发现男性教授在搜索结果和出版物记录上更具优势。


<details>
  <summary>Details</summary>
Motivation: 探讨算法系统是否在学术可见性中引入或放大性别偏见，尽管这些系统通常被认为是中立的。

Method: 使用德国大学和高等专业学院的学术档案数据，分析性别差异在元数据完整性、出版物检索和谷歌搜索结果中的表现。

Result: 发现男性教授在搜索结果和出版物记录上更具优势，女性教授的数字可见性则表现出更高的变异性。

Conclusion: 研究强调需要同时考虑技术性能和代表性平等的公平性评估。

Abstract: Algorithmic systems such as search engines and information retrieval
platforms significantly influence academic visibility and the dissemination of
knowledge. Despite assumptions of neutrality, these systems can reproduce or
reinforce societal biases, including those related to gender. This paper
introduces and applies a bias-preserving definition of algorithmic gender
fairness, which assesses whether algorithmic outputs reflect real-world gender
distributions without introducing or amplifying disparities. Using a
heterogeneous dataset of academic profiles from German universities and
universities of applied sciences, we analyse gender differences in metadata
completeness, publication retrieval in academic databases, and visibility in
Google search results. While we observe no overt algorithmic discrimination,
our findings reveal subtle but consistent imbalances: male professors are
associated with a greater number of search results and more aligned publication
records, while female professors display higher variability in digital
visibility. These patterns reflect the interplay between platform algorithms,
institutional curation, and individual self-presentation. Our study highlights
the need for fairness evaluations that account for both technical performance
and representational equality in digital systems.

</details>


### [119] [LLM4ES: Learning User Embeddings from Event Sequences via Large Language Models](https://arxiv.org/abs/2508.05688)
*Aleksei Shestov,Omar Zoloev,Maksim Makarenko,Mikhail Orlov,Egor Fadeev,Ivan Kireev,Andrey Savchenko*

Main category: cs.IR

TL;DR: LLM4ES利用预训练语言模型从事件序列生成用户嵌入，通过文本表示和微调技术提升嵌入质量，在金融等领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 利用语言模型处理事件序列数据，生成高质量用户嵌入，适用于金融、医疗等多领域应用。

Method: 将事件序列转为文本表示，通过微调语言模型进行下一词预测生成嵌入，并引入文本增强技术优化低变异性领域表现。

Result: 实验显示LLM4ES在用户分类任务中优于现有方法，适用于金融用户细分和医疗结果预测等场景。

Conclusion: LLM4ES框架通过语言模型有效生成用户嵌入，为多领域应用提供高性能解决方案。

Abstract: This paper presents LLM4ES, a novel framework that exploits large pre-trained
language models (LLMs) to derive user embeddings from event sequences. Event
sequences are transformed into a textual representation, which is subsequently
used to fine-tune an LLM through next-token prediction to generate high-quality
embeddings. We introduce a text enrichment technique that enhances LLM
adaptation to event sequence data, improving representation quality for
low-variability domains. Experimental results demonstrate that LLM4ES achieves
state-of-the-art performance in user classification tasks in financial and
other domains, outperforming existing embedding methods. The resulting user
embeddings can be incorporated into a wide range of applications, from user
segmentation in finance to patient outcome prediction in healthcare.

</details>


### [120] [Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking](https://arxiv.org/abs/2508.05700)
*Runze Su,Jiayin Jin,Jiacheng Li,Sihan Wang,Guangtong Bai,Zelun Wang,Li Tang,Yixiong Meng,Huasen Wu,Zhimeng Pan,Kungang Li,Han Sun,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar*

Main category: cs.IR

TL;DR: 论文提出了一种多面预训练方案和CPU-GPU混合服务架构，显著提升了Pinterest广告排名模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型嵌入表在推荐系统中的稀疏性、可扩展性问题，以及Pinterest特定场景下的性能瓶颈。

Method: 引入多面预训练方案，结合多种预训练算法；设计CPU-GPU混合服务架构以突破GPU内存限制。

Result: 点击率（CTR）提升2.60%，每次点击成本（CPC）降低1.34%，端到端延迟保持稳定。

Conclusion: 多面预训练和混合架构有效提升了推荐系统的性能，适用于实际部署。

Abstract: Large embedding tables are indispensable in modern recommendation systems,
thanks to their ability to effectively capture and memorize intricate details
of interactions among diverse entities. As we explore integrating large
embedding tables into Pinterest's ads ranking models, we encountered not only
common challenges such as sparsity and scalability, but also several obstacles
unique to our context. Notably, our initial attempts to train large embedding
tables from scratch resulted in neutral metrics. To tackle this, we introduced
a novel multi-faceted pretraining scheme that incorporates multiple pretraining
algorithms. This approach greatly enriched the embedding tables and resulted in
significant performance improvements. As a result, the multi-faceted large
embedding tables bring great performance gain on both the Click-Through Rate
(CTR) and Conversion Rate (CVR) domains. Moreover, we designed a CPU-GPU hybrid
serving infrastructure to overcome GPU memory limits and elevate the
scalability. This framework has been deployed in the Pinterest Ads system and
achieved 1.34% online CPC reduction and 2.60% CTR increase with neutral
end-to-end latency change.

</details>


### [121] [G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation](https://arxiv.org/abs/2508.05709)
*Boyu Chen,Siran Chen,Zhengrong Yue,Kainan Yan,Chenyun Yu,Beibei Kong,Cheng Lei,Chengxiang Zhuo,Zang Li,Yali Wang*

Main category: cs.IR

TL;DR: 论文提出了一种基于用户群体行为的模拟方法（G-UBS），通过群体上下文指导，更准确地解析隐式反馈，提升视频推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 由于显式反馈稀缺且隐式反馈存在噪声，传统推荐系统难以准确判断用户兴趣。G-UBS旨在通过群体行为模拟解决这一问题。

Method: G-UBS包含两个核心组件：用户群体管理器（UGM）通过LLM生成群体画像；用户反馈建模器（UFM）采用群体感知的强化学习方法解析隐式反馈。

Result: 在IF-VR基准测试中，G-UBS显著优于主流模型，播放率>30%的视频比例提高4.0%，推理准确率提高14.9%。

Conclusion: G-UBS通过群体行为模拟有效提升了隐式反馈的解析能力，为视频推荐系统提供了更可靠的解决方案。

Abstract: User feedback is critical for refining recommendation systems, yet explicit
feedback (e.g., likes or dislikes) remains scarce in practice. As a more
feasible alternative, inferring user preferences from massive implicit feedback
has shown great potential (e.g., a user quickly skipping a recommended video
usually indicates disinterest). Unfortunately, implicit feedback is often
noisy: a user might skip a video due to accidental clicks or other reasons,
rather than disliking it. Such noise can easily misjudge user interests,
thereby undermining recommendation performance. To address this issue, we
propose a novel Group-aware User Behavior Simulation (G-UBS) paradigm, which
leverages contextual guidance from relevant user groups, enabling robust and
in-depth interpretation of implicit feedback for individual users.
Specifically, G-UBS operates via two key agents. First, the User Group Manager
(UGM) effectively clusters users to generate group profiles utilizing a
``summarize-cluster-reflect" workflow based on LLMs. Second, the User Feedback
Modeler (UFM) employs an innovative group-aware reinforcement learning
approach, where each user is guided by the associated group profiles during the
reinforcement learning process, allowing UFM to robustly and deeply examine the
reasons behind implicit feedback. To assess our G-UBS paradigm, we have
constructed a Video Recommendation benchmark with Implicit Feedback (IF-VR). To
the best of our knowledge, this is the first multi-modal benchmark for implicit
feedback evaluation in video recommendation, encompassing 15k users, 25k
videos, and 933k interaction records with implicit feedback. Extensive
experiments on IF-VR demonstrate that G-UBS significantly outperforms
mainstream LLMs and MLLMs, with a 4.0% higher proportion of videos achieving a
play rate > 30% and 14.9% higher reasoning accuracy on IF-VR.

</details>


### [122] [WebWatcher: Breaking New Frontiers of Vision-Language Deep Research Agent](https://arxiv.org/abs/2508.05748)
*Xinyu Geng,Peng Xia,Zhen Zhang,Xinyu Wang,Qiuchen Wang,Ruixue Ding,Chenxi Wang,Jialong Wu,Yida Zhao,Kuan Li,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.IR

TL;DR: 论文提出了WebWatcher，一种多模态深度研究代理，通过增强的视觉语言推理能力和合成多模态轨迹训练，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要基于文本，忽视了现实世界中的视觉信息，多模态深度研究代理需要更强的推理能力。

Method: WebWatcher利用高质量合成多模态轨迹进行冷启动训练，结合多种工具进行深度推理，并通过强化学习增强泛化能力。

Result: 在四个挑战性VQA基准测试中，WebWatcher显著优于专有基线、RAG工作流和开源代理。

Conclusion: WebWatcher为复杂多模态信息检索任务提供了有效解决方案。

Abstract: Web agents such as Deep Research have demonstrated superhuman cognitive
abilities, capable of solving highly challenging information-seeking problems.
However, most research remains primarily text-centric, overlooking visual
information in the real world. This makes multimodal Deep Research highly
challenging, as such agents require much stronger reasoning abilities in
perception, logic, knowledge, and the use of more sophisticated tools compared
to text-based agents. To address this limitation, we introduce WebWatcher, a
multi-modal Agent for Deep Research equipped with enhanced visual-language
reasoning capabilities. It leverages high-quality synthetic multimodal
trajectories for efficient cold start training, utilizes various tools for deep
reasoning, and further enhances generalization through reinforcement learning.
To better evaluate the capabilities of multimodal agents, we propose
BrowseComp-VL, a benchmark with BrowseComp-style that requires complex
information retrieval involving both visual and textual information.
Experimental results show that WebWatcher significantly outperforms proprietary
baseline, RAG workflow and open-source agents in four challenging VQA
benchmarks, which paves the way for solving complex multimodal
information-seeking tasks.

</details>


### [123] [Dual prototype attentive graph network for cross-market recommendation](https://arxiv.org/abs/2508.05969)
*Li Fan,Menglin Kong,Yang Xiang,Chong Zhang,Chengtao Ji*

Main category: cs.IR

TL;DR: 论文提出了一种名为DGRE的双原型注意力图网络方法，用于跨市场推荐系统，通过结合市场特定和市场共享的洞察力，提升了系统的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有跨市场推荐系统方法通常忽视不同市场用户间的共享偏好，仅关注单一市场的特定偏好。

Method: DGRE利用基于图表示学习的原型，从用户和商品两方面捕捉市场特定和市场共享的洞察力，包括聚类用户构建共享原型和聚合商品特征构建市场特定原型。

Result: 在真实跨市场数据集上的实验表明，DGRE通过结合市场特定和市场共享的建模，显著提升了推荐系统的泛化能力和鲁棒性。

Conclusion: 结合市场特定和市场共享的洞察力是提升跨市场推荐系统性能的有效途径。

Abstract: Cross-market recommender systems (CMRS) aim to utilize historical data from
mature markets to promote multinational products in emerging markets. However,
existing CMRS approaches often overlook the potential for shared preferences
among users in different markets, focusing primarily on modeling specific
preferences within each market. In this paper, we argue that incorporating both
market-specific and market-shared insights can enhance the generalizability and
robustness of CMRS. We propose a novel approach called Dual Prototype Attentive
Graph Network for Cross-Market Recommendation (DGRE) to address this. DGRE
leverages prototypes based on graph representation learning from both items and
users to capture market-specific and market-shared insights. Specifically, DGRE
incorporates market-shared prototypes by clustering users from various markets
to identify behavioural similarities and create market-shared user profiles.
Additionally, it constructs item-side prototypes by aggregating item features
within each market, providing valuable market-specific insights. We conduct
extensive experiments to validate the effectiveness of DGRE on a real-world
cross-market dataset, and the results show that considering both
market-specific and market-sharing aspects in modelling can improve the
generalization and robustness of CMRS.

</details>


### [124] [Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts](https://arxiv.org/abs/2508.05993)
*Yunke Qu,Liang Qu,Tong Chen,Quoc Viet Hung Nguyen,Hongzhi Yin*

Main category: cs.IR

TL;DR: XSMoE框架通过轻量级可扩展专家网络解决流式推荐系统中用户兴趣漂移和新物品冷启动问题，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 流式推荐系统中用户兴趣随时间变化，新物品缺乏反馈，现有方法未针对用户偏好建模且忽视模态特征漂移。

Method: 提出XSMoE框架，通过可扩展专家网络动态结合冻结预训练编码器，利用门控路由和剪枝策略保持模型紧凑。

Result: 在三个真实数据集上，XSMoE在推荐质量和计算效率上优于现有方法。

Conclusion: XSMoE有效捕捉冷启动和兴趣漂移，同时保持高效性。

Abstract: Streaming recommender systems (SRSs) are widely deployed in real-world
applications, where user interests shift and new items arrive over time. As a
result, effectively capturing users' latest preferences is challenging, as
interactions reflecting recent interests are limited and new items often lack
sufficient feedback. A common solution is to enrich item representations using
multimodal encoders (e.g., BERT or ViT) to extract visual and textual features.
However, these encoders are pretrained on general-purpose tasks: they are not
tailored to user preference modeling, and they overlook the fact that user
tastes toward modality-specific features such as visual styles and textual
tones can also drift over time. This presents two key challenges in streaming
scenarios: the high cost of fine-tuning large multimodal encoders, and the risk
of forgetting long-term user preferences due to continuous model updates.
  To tackle these challenges, we propose Expandable Side Mixture-of-Experts
(XSMoE), a memory-efficient framework for multimodal streaming recommendation.
XSMoE attaches lightweight side-tuning modules consisting of expandable expert
networks to frozen pretrained encoders and incrementally expands them in
response to evolving user feedback. A gating router dynamically combines expert
and backbone outputs, while a utilization-based pruning strategy maintains
model compactness. By learning new patterns through expandable experts without
overwriting previously acquired knowledge, XSMoE effectively captures both cold
start and shifting preferences in multimodal features. Experiments on three
real-world datasets demonstrate that XSMoE outperforms state-of-the-art
baselines in both recommendation quality and computational efficiency.

</details>


### [125] [Semantic Item Graph Enhancement for Multimodal Recommendation](https://arxiv.org/abs/2508.06154)
*Xiaoxiong Zhang,Xin Zhou,Zhiwei Zeng,Dusit Niyato,Zhiqi Shen*

Main category: cs.IR

TL;DR: 论文提出了一种改进的多模态推荐系统方法，通过注入协作信号和对比学习来增强语义建模和噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态推荐系统中存在语义不足和结构噪声问题，影响了性能。

Method: 提取交互图中的协作信号注入语义图，设计基于模数的个性化嵌入扰动机制和双重表示对齐机制。

Result: 在四个基准数据集上的实验验证了框架的有效性。

Conclusion: 该方法通过增强语义建模和噪声鲁棒性，显著提升了推荐系统的性能。

Abstract: Multimodal recommendation systems have attracted increasing attention for
their improved performance by leveraging items' multimodal information. Prior
methods often build modality-specific item-item semantic graphs from raw
modality features and use them as supplementary structures alongside the
user-item interaction graph to enhance user preference learning. However, these
semantic graphs suffer from semantic deficiencies, including (1) insufficient
modeling of collaborative signals among items and (2) structural distortions
introduced by noise in raw modality features, ultimately compromising
performance. To address these issues, we first extract collaborative signals
from the interaction graph and infuse them into each modality-specific item
semantic graph to enhance semantic modeling. Then, we design a modulus-based
personalized embedding perturbation mechanism that injects perturbations with
modulus-guided personalized intensity into embeddings to generate contrastive
views. This enables the model to learn noise-robust representations through
contrastive learning, thereby reducing the effect of structural noise in
semantic graphs. Besides, we propose a dual representation alignment mechanism
that first aligns multiple semantic representations via a designed Anchor-based
InfoNCE loss using behavior representations as anchors, and then aligns
behavior representations with the fused semantics by standard InfoNCE, to
ensure representation consistency. Extensive experiments on four benchmark
datasets validate the effectiveness of our framework.

</details>


### [126] [Improving Table Retrieval with Question Generation from Partial Tables](https://arxiv.org/abs/2508.06168)
*Hsing-Ping Liang,Che-Wei Chang,Yao-Chung Fan*

Main category: cs.IR

TL;DR: 论文提出QGpT方法，通过LLM生成基于部分表格的合成问题，增强表格与问题的语义对齐，显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要优化查询表示，而忽略了表格在嵌入空间中的表示改进，导致与问题的语义对齐不足。

Method: 使用LLM基于部分表格生成合成问题，模拟用户查询行为，并将问题与表格片段联合嵌入。

Result: 在多个基准测试中，QGpT显著提升了密集和延迟交互检索器的性能。

Conclusion: QGpT是一种简单有效的方法，通过改进表格表示，显著提升了检索性能。

Abstract: Recent advances in open-domain question answering over tables have widely
adopted large language models (LLMs) under the Retriever-Reader architecture.
Prior works have effectively leveraged LLMs to tackle the complex reasoning
demands of the Reader component, such as text-to-text, text-to-SQL, and multi
hop reasoning. In contrast, the Retriever component has primarily focused on
optimizing the query representation-training retrievers to retrieve relevant
tables based on questions, or to select keywords from questions for matching
table segments. However, little attention has been given to enhancing how
tables themselves are represented in embedding space to better align with
questions. To address this, we propose QGpT (Question Generation from Partial
Tables), a simple yet effective method that uses an LLM to generate synthetic
questions based on small portions of a table. These questions are generated to
simulate how a user might query the content of the table currently under
consideration. The generated questions are then jointly embedded with the
partial table segments used for generation, enhancing semantic alignment with
user queries. Without the need to embed entire tables, our method significantly
improves retrieval performance across multiple benchmarks for both dense and
late-interaction retrievers.

</details>


### [127] [M2IO-R1: An Efficient RL-Enhanced Reasoning Framework for Multimodal Retrieval Augmented Multimodal Generation](https://arxiv.org/abs/2508.06328)
*Zhiyou Xiao,Qinhan Yu,Binghui Li,Geng Chen,Chong Chen,Wentao Zhang*

Main category: cs.IR

TL;DR: 论文提出M2IO-R1框架，支持多模态输入和输出，通过强化学习优化图像选择和布局。


<details>
  <summary>Details</summary>
Motivation: 现实应用需要多模态输入和输出，但现有研究仅支持单模态输出，限制了表达能力。

Method: 采用强化学习（RL）和Group Relative Policy Optimization训练Inserter-R1-3B模型，实现可控的图像选择和布局。

Result: 轻量级的3B插入器在质量和效率上均优于基线模型。

Conclusion: M2IO-R1框架通过RL有效解决了多模态输出的挑战，具有实际应用潜力。

Abstract: Current research on Multimodal Retrieval-Augmented Generation (MRAG) enables
diverse multimodal inputs but remains limited to single-modality outputs,
restricting expressive capacity and practical utility. In contrast, real-world
applications often demand both multimodal inputs and multimodal outputs for
effective communication and grounded reasoning. Motivated by the recent success
of Reinforcement Learning (RL) in complex reasoning tasks for Large Language
Models (LLMs), we adopt RL as a principled and effective paradigm to address
the multi-step, outcome-driven challenges inherent in multimodal output
generation. Here, we introduce M2IO-R1, a novel framework for Multimodal
Retrieval-Augmented Multimodal Generation (MRAMG) that supports both multimodal
inputs and outputs. Central to our framework is an RL-based inserter,
Inserter-R1-3B, trained with Group Relative Policy Optimization to guide image
selection and placement in a controllable and semantically aligned manner.
Empirical results show that our lightweight 3B inserter achieves strong
reasoning capabilities with significantly reduced latency, outperforming
baselines in both quality and efficiency.

</details>


### [128] [eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion](https://arxiv.org/abs/2508.06450)
*Daria Tikhonovich,Nikita Zelinskiy,Aleksandr V. Petrov,Mayya Spirina,Andrei Semenov,Andrey V. Savchenko,Sergei Kuliev*

Main category: cs.IR

TL;DR: 论文提出eSASRec模型，结合SASRec训练目标、LiGR Transformer层和Sampled Softmax Loss，在实验中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 填补Transformer模型模块化改进系统性评估的空白，提升序列推荐效果。

Method: 结合SASRec训练目标、LiGR Transformer层和Sampled Softmax Loss，构建eSASRec模型。

Result: eSASRec在学术基准测试中比现有模型效果提升23%，在生产环境中表现优异。

Conclusion: eSASRec简单易集成，可作为强基线模型，开源实现便于使用。

Abstract: Since their introduction, Transformer-based models, such as SASRec and
BERT4Rec, have become common baselines for sequential recommendations,
surpassing earlier neural and non-neural methods. A number of following
publications have shown that the effectiveness of these models can be improved
by, for example, slightly updating the architecture of the Transformer layers,
using better training objectives, and employing improved loss functions.
However, the additivity of these modular improvements has not been
systematically benchmarked - this is the gap we aim to close in this paper.
Through our experiments, we identify a very strong model that uses SASRec's
training objective, LiGR Transformer layers, and Sampled Softmax Loss. We call
this combination eSASRec (Enhanced SASRec). While we primarily focus on
realistic, production-like evaluation, in our preliminarily study we find that
common academic benchmarks show eSASRec to be 23% more effective compared to
the most recent state-of-the-art models, such as ActionPiece. In our main
production-like benchmark, eSASRec resides on the Pareto frontier in terms of
the accuracy-coverage tradeoff (alongside the recent industrial models HSTU and
FuXi. As the modifications compared to the original SASRec are relatively
straightforward and no extra features are needed (such as timestamps in HSTU),
we believe that eSASRec can be easily integrated into existing recommendation
pipelines and can can serve as a strong yet very simple baseline for emerging
complicated algorithms. To facilitate this, we provide the open-source
implementations for our models and benchmarks in repository
https://github.com/blondered/transformer_benchmark

</details>


### [129] [Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting](https://arxiv.org/abs/2508.06455)
*Nikita Sukhorukov,Danil Gusak,Evgeny Frolov*

Main category: cs.IR

TL;DR: 提出了一种基于用户行为信息的特征选择策略，通过混合矩阵分解和最大体积算法优化特征表示，平衡推荐准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决冷启动问题中无关或噪声特征对预测性能的负面影响，同时减少计算资源消耗。

Method: 结合协作行为数据的相关性，使用混合矩阵分解和最大体积算法进行特征选择和排序。

Result: 在冷启动场景下，方法能选择最小但高效的特征子集，优于现有技术且保持高效。

Conclusion: 该方法在特征减少的情况下仍能提升推荐性能，适用于冷启动问题。

Abstract: Cold-start challenges in recommender systems necessitate leveraging auxiliary
features beyond user-item interactions. However, the presence of irrelevant or
noisy features can degrade predictive performance, whereas an excessive number
of features increases computational demands, leading to higher memory
consumption and prolonged training times.
  To address this, we propose a feature selection strategy that prioritizes the
user behavioral information. Our method enhances the feature representation by
incorporating correlations from collaborative behavior data using a hybrid
matrix factorization technique and then ranks features using a mechanism based
on the maximum volume algorithm. This approach identifies the most influential
features, striking a balance between recommendation accuracy and computational
efficiency. We conduct an extensive evaluation across various datasets and
hybrid recommendation models, demonstrating that our method excels in
cold-start scenarios by selecting minimal yet highly effective feature subsets.
Even under strict feature reduction, our approach surpasses existing feature
selection techniques while maintaining superior efficiency.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [130] [InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](https://arxiv.org/abs/2508.05731)
*Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu*

Main category: cs.AI

TL;DR: 论文提出AEPO框架，通过多答案生成策略和自适应探索奖励函数，解决了MLLMs在GUI任务中语义对齐的探索瓶颈问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在GUI任务中语义对齐的探索效率问题，提升模型对自然语言指令的鲁棒性。

Method: 提出自适应探索策略优化（AEPO）框架，结合多答案生成策略和理论驱动的自适应探索奖励函数（AER）。

Result: AEPO训练的模型在多个GUI基准测试中达到新SOTA，相对基线提升高达9.0%。

Conclusion: AEPO有效解决了语义对齐的探索瓶颈，显著提升了模型性能，为GUI任务提供了新解决方案。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the
development of autonomous agents that operate on Graphical User Interfaces
(GUIs) using pure visual input. A fundamental challenge is robustly grounding
natural language instructions. This requires a precise spatial alignment, which
accurately locates the coordinates of each element, and, more critically, a
correct semantic alignment, which matches the instructions to the functionally
appropriate UI element. Although Reinforcement Learning with Verifiable Rewards
(RLVR) has proven to be effective at improving spatial alignment for these
MLLMs, we find that inefficient exploration bottlenecks semantic alignment,
which prevent models from learning difficult semantic associations. To address
this exploration problem, we present Adaptive Exploration Policy Optimization
(AEPO), a new policy optimization framework. AEPO employs a multi-answer
generation strategy to enforce broader exploration, which is then guided by a
theoretically grounded Adaptive Exploration Reward (AER) function derived from
first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B
and InfiGUI-G1-7B, establish new state-of-the-art results across multiple
challenging GUI grounding benchmarks, achieving significant relative
improvements of up to 9.0% against the naive RLVR baseline on benchmarks
designed to test generalization and semantic understanding. Resources are
available at https://github.com/InfiXAI/InfiGUI-G1.

</details>


### [131] [A Framework for Inherently Safer AGI through Language-Mediated Active Inference](https://arxiv.org/abs/2508.05766)
*Bo Wen*

Main category: cs.AI

TL;DR: 本文提出了一种结合主动推理原则与大型语言模型（LLM）的新型框架，用于开发安全的通用人工智能（AGI）。


<details>
  <summary>Details</summary>
Motivation: 传统AI安全方法（如事后解释性和奖励工程）存在根本性局限，需要一种将安全性融入核心设计的新方法。

Method: 通过透明信念表示和分层价值对齐，将安全保证融入系统核心设计，利用自然语言作为信念表示和操作的媒介。

Result: 提出了一种多智能体系统，智能体根据主动推理原则自组织，并通过分层马尔可夫毯传递偏好和安全约束。

Conclusion: 该框架为AGI开发提供了一条更安全的发展路径，而非事后添加安全措施。

Abstract: This paper proposes a novel framework for developing safe Artificial General
Intelligence (AGI) by combining Active Inference principles with Large Language
Models (LLMs). We argue that traditional approaches to AI safety, focused on
post-hoc interpretability and reward engineering, have fundamental limitations.
We present an architecture where safety guarantees are integrated into the
system's core design through transparent belief representations and
hierarchical value alignment. Our framework leverages natural language as a
medium for representing and manipulating beliefs, enabling direct human
oversight while maintaining computational tractability. The architecture
implements a multi-agent system where agents self-organize according to Active
Inference principles, with preferences and safety constraints flowing through
hierarchical Markov blankets. We outline specific mechanisms for ensuring
safety, including: (1) explicit separation of beliefs and preferences in
natural language, (2) bounded rationality through resource-aware free energy
minimization, and (3) compositional safety through modular agent structures.
The paper concludes with a research agenda centered on the Abstraction and
Reasoning Corpus (ARC) benchmark, proposing experiments to validate our
framework's safety properties. Our approach offers a path toward AGI
development that is inherently safer, rather than retrofitted with safety
measures.

</details>


### [132] [Whither symbols in the era of advanced neural networks?](https://arxiv.org/abs/2508.05776)
*Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb*

Main category: cs.AI

TL;DR: 现代神经网络表现出类似人类思维的组合、创新和快速学习能力，挑战了人类认知过程是符号化的观点，但符号系统在定义抽象问题中仍起重要作用，提出了新的研究议程。


<details>
  <summary>Details</summary>
Motivation: 探讨人类思维是否应以符号系统为基础，以及现代神经网络是否表现出类似能力。

Method: 通过分析神经网络的能力及其与符号系统的关系，提出论点。

Result: 神经网络表现出类似人类思维的组合、创新和学习能力，但符号系统在定义抽象问题中仍不可或缺。

Conclusion: 需要新的研究议程重新审视人类思维的符号基础。

Abstract: Some of the strongest evidence that human minds should be thought about in
terms of symbolic systems has been the way they combine ideas, produce novelty,
and learn quickly. We argue that modern neural networks -- and the artificial
intelligence systems built upon them -- exhibit similar abilities. This
undermines the argument that the cognitive processes and representations used
by human minds are symbolic, although the fact that these neural networks are
typically trained on data generated by symbolic systems illustrates that such
systems play an important role in characterizing the abstract problems that
human minds have to solve. This argument leads us to offer a new agenda for
research on the symbolic basis of human thought.

</details>


### [133] [Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making](https://arxiv.org/abs/2508.05792)
*Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava*

Main category: cs.AI

TL;DR: H-XAI是一个统一的框架，结合因果评级与传统XAI方法，支持交互式、多方法的解释过程，满足不同利益相关者的需求。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法主要服务于开发者，缺乏对多样化利益相关者需求的支持。H-XAI旨在填补这一空白。

Method: H-XAI整合因果评级与传统XAI方法，支持交互式问题提问、假设测试，并与随机和偏置基线对比模型行为。

Result: 通过两个案例研究（信用风险分类和金融时间序列预测）验证了H-XAI的通用性。

Conclusion: H-XAI填补了现有XAI方法的不足，结合因果评级和后验解释，满足利益相关者在个体决策和整体模型层面的需求。

Abstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing
on justifying model outputs rather than supporting diverse stakeholder needs. A
recent shift toward Evaluative AI reframes explanation as a tool for hypothesis
testing, but still focuses primarily on operational organizations. We introduce
Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods
with traditional XAI methods to support explanation as an interactive,
multi-method process. H-XAI allows stakeholders to ask a series of questions,
test hypotheses, and compare model behavior against automatically constructed
random and biased baselines. It combines instance-level and global
explanations, adapting to each stakeholder's goals, whether understanding
individual decisions, assessing group-level bias, or evaluating robustness
under perturbations. We demonstrate the generality of our approach through two
case studies spanning six scenarios: binary credit risk classification and
financial time-series forecasting. H-XAI fills critical gaps left by existing
XAI methods by combining causal ratings and post-hoc explanations to answer
stakeholder-specific questions at both the individual decision level and the
overall model level.

</details>


### [134] [Safety of Embodied Navigation: A Survey](https://arxiv.org/abs/2508.05855)
*Zixia Wang,Jia Hu,Ronghui Mu*

Main category: cs.AI

TL;DR: 该论文综述了具身导航中的安全问题，分析了攻击策略、防御机制和评估方法，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和具身AI的发展，具身导航在关键应用中的安全问题日益突出，需要系统性的分析和解决方案。

Method: 通过全面分析现有安全挑战、缓解技术、数据集和评估指标，探讨未解决问题和未来方向。

Result: 总结了具身导航中的安全问题和现有解决方案，提出了未来研究方向。

Conclusion: 该研究为开发更安全可靠的具身导航系统提供了指导，并对社会安全和工业效率有广泛影响。

Abstract: As large language models (LLMs) continue to advance and gain influence, the
development of embodied AI has accelerated, drawing significant attention,
particularly in navigation scenarios. Embodied navigation requires an agent to
perceive, interact with, and adapt to its environment while moving toward a
specified target in unfamiliar settings. However, the integration of embodied
navigation into critical applications raises substantial safety concerns. Given
their deployment in dynamic, real-world environments, ensuring the safety of
such systems is critical. This survey provides a comprehensive analysis of
safety in embodied navigation from multiple perspectives, encompassing attack
strategies, defense mechanisms, and evaluation methodologies. Beyond conducting
a comprehensive examination of existing safety challenges, mitigation
technologies, and various datasets and metrics that assess effectiveness and
robustness, we explore unresolved issues and future research directions in
embodied navigation safety. These include potential attack methods, mitigation
strategies, more reliable evaluation techniques, and the implementation of
verification frameworks. By addressing these critical gaps, this survey aims to
provide valuable insights that can guide future research toward the development
of safer and more reliable embodied navigation systems. Furthermore, the
findings of this study have broader implications for enhancing societal safety
and increasing industrial efficiency.

</details>


### [135] [Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning](https://arxiv.org/abs/2508.05888)
*Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber*

Main category: cs.AI

TL;DR: 论文提出了一种基于知识图谱（KG）的工具检索框架，通过捕捉工具间的语义关系和功能依赖，显著提升了多步任务中的工具检索准确性。


<details>
  <summary>Details</summary>
Motivation: 现有工具检索方法主要依赖用户查询与工具描述的相似性，限制了多步请求的处理能力，因此需要一种更全面的方法。

Method: 采用知识图谱建模工具间的直接和间接连接，利用1-hop ego工具图集成进行检索。

Result: 在合成数据集上，KG方法在Complete Recall指标上达到91.85%，优于非KG基线的89.26%。

Conclusion: KG的结构信息为相似性匹配提供了补充信号，特别适用于需要顺序工具组合的查询。

Abstract: Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

</details>


### [136] [Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](https://arxiv.org/abs/2508.05996)
*Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang*

Main category: cs.AI

TL;DR: 论文提出MedOrch框架，通过LLM中介协调多VLM专家代理协作，提升医疗多模态决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有多代理研究多限于语言任务，多模态场景下VLMs协作能力受限，需解决错误结果放大和自反思不足问题。

Method: 采用LLM中介代理协调多个VLM专家代理，利用开源通用和领域专用VLMs，避免高成本GPT模型。

Result: 在五个医疗视觉问答基准上验证，协作性能超越单代理，无需模型训练。

Conclusion: 中介引导的多代理协作可推动医疗多模态智能发展，代码将开源。

Abstract: Complex medical decision-making involves cooperative workflows operated by
different clinicians. Designing AI multi-agent systems can expedite and augment
human-level clinical decision-making. Existing multi-agent researches primarily
focus on language-only tasks, yet their extension to multimodal scenarios
remains challenging. A blind combination of diverse vision-language models
(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are
less capable in instruction following and importantly self-reflection, compared
to large language models (LLMs) of comparable sizes. This disparity largely
constrains VLMs' ability in cooperative workflows. In this study, we propose
MedOrch, a mediator-guided multi-agent collaboration framework for medical
multimodal decision-making. MedOrch employs an LLM-based mediator agent that
enables multiple VLM-based expert agents to exchange and reflect on their
outputs towards collaboration. We utilize multiple open-source general-purpose
and domain-specific VLMs instead of costly GPT-series models, revealing the
strength of heterogeneous models. We show that the collaboration within
distinct VLM-based agents can surpass the capabilities of any individual agent.
We validate our approach on five medical vision question answering benchmarks,
demonstrating superior collaboration performance without model training. Our
findings underscore the value of mediator-guided multi-agent collaboration in
advancing medical multimodal intelligence. Our code will be made publicly
available.

</details>


### [137] [Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](https://arxiv.org/abs/2508.06042)
*Daechul Ahn,San Kim,Jonghyun Choi*

Main category: cs.AI

TL;DR: 论文提出了一种名为HIMA的分层多智能体框架，用于解决大型语言模型在动态长时任务（如星际争霸II）中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的方法在动态、长时任务中表现不佳，尤其是在资源管理和部分可观测环境中。

Method: 采用分层多智能体框架，结合专家演示的模仿学习智能体和元控制器（Strategic Planner）。

Result: HIMA在战略清晰度、适应性和计算效率上优于现有方法。

Conclusion: 结合专业模仿模块和元级协调可以开发更鲁棒、通用的AI智能体。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive action
sequence prediction capabilities but often struggle with dynamic, long-horizon
tasks such as real-time strategic games. In a game such as StarCraftII (SC2),
agents need to manage resource constraints and adapt to evolving battlefield
situations in a partially observable environment. This often overwhelms
exisiting LLM-based approaches. To address these challenges, we propose a
hierarchical multi-agent framework that employs specialized imitation learning
agents under a meta-controller called Strategic Planner (SP). By expert
demonstrations, each specialized agent learns a distinctive strategy, such as
aerial support or defensive maneuvers, and produces coherent, structured
multistep action sequences. The SP then orchestrates these proposals into a
single, environmentally adaptive plan that ensures local decisions aligning
with long-term strategies. We call this HIMA (Hierarchical Imitation
Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that
encompasses all race match combinations in SC2. Our empirical results show that
HIMA outperforms state of the arts in strategic clarity, adaptability, and
computational efficiency, underscoring the potential of combining specialized
imitation modules with meta-level orchestration to develop more robust,
general-purpose AI agents.

</details>


### [138] [LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences](https://arxiv.org/abs/2508.06060)
*Sankarshan Damle,Boi Faltings*

Main category: cs.AI

TL;DR: 论文提出了一个双用途框架，利用参与式预算（PB）评估大语言模型（LLMs）在资源分配和推理能力方面的表现。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在结构化资源分配任务中的能力，并解决现有基准测试的局限性。

Method: 通过三种提示策略（贪心选择、直接优化和启发式改进）让LLMs在预算约束下选择项目，并对比效用最大化基准。

Result: 结果表明提示设计对LLMs表现至关重要，且LLMs在机制设计中具有潜力。

Conclusion: LLMs在资源分配和偏好推断方面展现出潜力，提示设计是关键因素。

Abstract: Large Language Models (LLMs) are increasingly expected to handle complex
decision-making tasks, yet their ability to perform structured resource
allocation remains underexplored. Evaluating their reasoning is also difficult
due to data contamination and the static nature of existing benchmarks. We
present a dual-purpose framework leveraging Participatory Budgeting (PB) both
as (i) a practical setting for LLM-based resource allocation and (ii) an
adaptive benchmark for evaluating their reasoning capabilities. We task LLMs
with selecting project subsets under feasibility (e.g., budget) constraints via
three prompting strategies: greedy selection, direct optimization, and a
hill-climbing-inspired refinement. We benchmark LLMs' allocations against a
utility-maximizing oracle. Interestingly, we also test whether LLMs can infer
structured preferences from natural-language voter input or metadata, without
explicit votes. By comparing allocations based on inferred preferences to those
from ground-truth votes, we evaluate LLMs' ability to extract preferences from
open-ended input. Our results underscore the role of prompt design and show
that LLMs hold promise for mechanism design with unstructured inputs.

</details>


### [139] [Don't Forget Imagination!](https://arxiv.org/abs/2508.06062)
*Evgenii E. Vityaev,Andrei Mantsivoda*

Main category: cs.AI

TL;DR: 论文呼吁重视认知想象力在人工智能中的作用，并提出语义模型作为模拟认知想象力的工具。


<details>
  <summary>Details</summary>
Motivation: 认知想象力在人类思维中起关键作用，但目前被低估，限制了AI的能力。

Method: 提出语义模型，一种基于概率因果关系的数学模型，可学习和确保想象上下文的连贯性。

Result: 语义模型能模拟认知想象力，支持连贯的推理和决策。

Conclusion: 认知想象力是AI的下一个突破点，语义模型为实现这一目标提供了有效工具。

Abstract: Cognitive imagination is a type of imagination that plays a key role in human
thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to
mentally visualize coherent and holistic systems of concepts and causal links
that serve as semantic contexts for reasoning, decision making and prediction.
Our position is that the role of cognitive imagination is still greatly
underestimated, and this creates numerous problems and diminishes the current
capabilities of AI. For instance, when reasoning, humans rely on imaginary
contexts to retrieve background info. They also constantly return to the
context for semantic verification that their reasoning is still reasonable.
Thus, reasoning without imagination is blind. This paper is a call for greater
attention to cognitive imagination as the next promising breakthrough in
artificial intelligence. As an instrument for simulating cognitive imagination,
we propose semantic models -- a new approach to mathematical models that can
learn, like neural networks, and are based on probabilistic causal
relationships. Semantic models can simulate cognitive imagination because they
ensure the consistency of imaginary contexts and implement a glass-box approach
that allows the context to be manipulated as a holistic and coherent system of
interrelated facts glued together with causal relations.

</details>


### [140] [A Generic Complete Anytime Beam Search for Optimal Decision Tree](https://arxiv.org/abs/2508.06064)
*Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus*

Main category: cs.AI

TL;DR: CA-DL8.5是一种通用的、完整的、随时可用的波束搜索算法，扩展了DL8.5框架，统一了现有的一些随时策略，并在标准分类基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法在未完成搜索时难以快速找到高质量的决策树，且缺乏系统比较，因此提出CA-DL8.5以改进随时性能。

Method: CA-DL8.5通过模块化设计整合多种启发式和松弛机制，结合DL8.5的高效剪枝和缓存技术，采用基于重启的波束搜索逐步放松剪枝标准。

Result: 实验表明，基于LDS的CA-DL8.5在随时性能上优于其他变体和Blossom算法，同时保持完整性和最优性。

Conclusion: CA-DL8.5为决策树学习提供了通用框架，并通过LDS策略实现了最佳随时性能。

Abstract: Finding an optimal decision tree that minimizes classification error is known
to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic
programming guarantee optimality, they often suffer from poor anytime behavior
-- meaning they struggle to find high-quality decision trees quickly when the
search is stopped before completion -- due to unbalanced search space
exploration. To address this, several anytime extensions of exact methods have
been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not
been systematically compared, making it difficult to assess their relative
effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and
anytime beam search algorithm that extends the DL8.5 framework and unifies some
existing anytime strategies. In particular, CA-DL8.5 generalizes previous
approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various
heuristics and relaxation mechanisms through a modular design. The algorithm
reuses DL8.5's efficient branch-and-bound pruning and trie-based caching,
combined with a restart-based beam search that gradually relaxes pruning
criteria to improve solution quality over time. Our contributions are twofold:
(1) We introduce this new generic framework for exact and anytime decision tree
learning, enabling the incorporation of diverse heuristics and search
strategies; (2) We conduct a rigorous empirical comparison of several
instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k
heuristics -- using an anytime evaluation metric called the primal gap
integral. Experimental results on standard classification benchmarks show that
CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime
performance, outperforming both other CA-DL8.5 variants and the Blossom
algorithm while maintaining completeness and optimality guarantees.

</details>


### [141] [ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception](https://arxiv.org/abs/2508.06074)
*Siyi Lu,Run Liu,Dongsheng Yang,Lei He*

Main category: cs.AI

TL;DR: 论文提出了一种基于深度强化学习（DRL）和鸟瞰图（BEV）感知的新型自动驾驶方法，结合高效的时空特征提取网络Mamba-BEV和ME³-BEV框架，显著提升了动态城市驾驶场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 传统模块化方法存在错误传播和协调问题，端到端学习系统则面临计算瓶颈。本文旨在通过结合BEV感知和DRL，解决这些问题。

Method: 提出Mamba-BEV模型，结合BEV感知和Mamba框架进行时空特征提取；进一步提出ME³-BEV框架，将Mamba-BEV作为特征输入用于端到端DRL。

Result: 在CARLA模拟器上的实验表明，ME³-BEV在碰撞率和轨迹准确性等多项指标上优于现有模型。

Conclusion: ME³-BEV为实时自动驾驶提供了一种高效且可解释的解决方案。

Abstract: Autonomous driving systems face significant challenges in perceiving complex
environments and making real-time decisions. Traditional modular approaches,
while offering interpretability, suffer from error propagation and coordination
issues, whereas end-to-end learning systems can simplify the design but face
computational bottlenecks. This paper presents a novel approach to autonomous
driving using deep reinforcement learning (DRL) that integrates bird's-eye view
(BEV) perception for enhanced real-time decision-making. We introduce the
\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction
network that combines BEV-based perception with the Mamba framework for
temporal feature modeling. This integration allows the system to encode vehicle
surroundings and road features in a unified coordinate system and accurately
model long-range dependencies. Building on this, we propose the
\texttt{ME$^3$-BEV} framework, which utilizes the \texttt{Mamba-BEV} model as a
feature input for end-to-end DRL, achieving superior performance in dynamic
urban driving scenarios. We further enhance the interpretability of the model
by visualizing high-dimensional features through semantic segmentation,
providing insight into the learned representations. Extensive experiments on
the CARLA simulator demonstrate that \texttt{ME$^3$-BEV} outperforms existing
models across multiple metrics, including collision rate and trajectory
accuracy, offering a promising solution for real-time autonomous driving.

</details>


### [142] [Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2](https://arxiv.org/abs/2508.06091)
*Stan P Hauke,Przemysław Andrzej Wałęga*

Main category: cs.AI

TL;DR: 本文解决了关于图神经网络（GNNs）逻辑表达能力的一个开放性问题，证明其严格超过C2逻辑的表达能力。


<details>
  <summary>Details</summary>
Motivation: 研究GNNs与逻辑语言的关系，特别是解决Barceló等人提出的关于GNNs是否完全由C2逻辑表征的开放性问题。

Method: 通过理论分析，比较GNNs与C2逻辑的表达能力，并证明GNNs的表达能力更强。

Result: 证明GNNs的逻辑表达能力严格超过C2逻辑，适用于无向和有向图。

Conclusion: 该研究不仅解决了GNNs的开放性问题，还为无穷逻辑的表达能力提供了新的见解。

Abstract: In recent years, there has been growing interest in understanding the
expressive power of graph neural networks (GNNs) by relating them to logical
languages. This research has been been initialised by an influential result of
Barcel\'o et al. (2020), who showed that the graded modal logic (or a guarded
fragment of the logic C2), characterises the logical expressiveness of
aggregate-combine GNNs. As a ``challenging open problem'' they left the
question whether full C2 characterises the logical expressiveness of
aggregate-combine-readout GNNs. This question has remained unresolved despite
several attempts. In this paper, we solve the above open problem by proving
that the logical expressiveness of aggregate-combine-readout GNNs strictly
exceeds that of C2. This result holds over both undirected and directed graphs.
Beyond its implications for GNNs, our work also leads to purely logical
insights on the expressive power of infinitary logics.

</details>


### [143] [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](https://arxiv.org/abs/2508.06110)
*Yiran Rex Ma*

Main category: cs.AI

TL;DR: PanelTR框架通过LLM代理科学家实现表格推理，无需数据增强或参数优化，表现优于普通LLM，媲美监督模型。


<details>
  <summary>Details</summary>
Motivation: 解决表格推理任务中依赖标注数据或复杂数据增强的问题，提升灵活性和泛化能力。

Method: 利用五个科学家角色进行独立研究、自我审查和同行评审讨论，实现语义级迁移。

Result: 在四个基准测试中，PanelTR优于普通LLM，与监督模型相当，且无需训练数据。

Conclusion: 结构化科学方法在零样本场景下能有效处理复杂任务，具有灵活的语义理解能力。

Abstract: Table reasoning, including tabular QA and fact verification, often depends on
annotated data or complex data augmentation, limiting flexibility and
generalization. LLMs, despite their versatility, often underperform compared to
simple supervised models. To approach these issues, we introduce PanelTR, a
framework utilizing LLM agent scientists for robust table reasoning through a
structured scientific approach. PanelTR's workflow involves agent scientists
conducting individual investigations, engaging in self-review, and
participating in collaborative peer-review discussions. This process, driven by
five scientist personas, enables semantic-level transfer without relying on
data augmentation or parametric optimization. Experiments across four
benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully
supervised models, all while remaining independent of training data. Our
findings indicate that structured scientific methodology can effectively handle
complex tasks beyond table reasoning with flexible semantic understanding in a
zero-shot context.

</details>


### [144] [SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges](https://arxiv.org/abs/2508.06111)
*Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown*

Main category: cs.AI

TL;DR: SKATE是一种新型评估框架，通过让大型语言模型（LLMs）相互生成和解决可验证任务来评估其能力，具有自动化、可扩展和客观性等优势。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法需要大量领域专业知识，难以适应LLMs的快速发展，因此需要一种更高效、通用的评估框架。

Method: SKATE将评估视为游戏，LLMs既作为任务生成者又作为解决者，通过生成可验证任务来相互竞争，并使用TrueSkill排名系统进行评分。

Result: 实验表明，SKATE能有效区分不同LLMs的能力，发现模型自我偏好行为，并揭示模型间的细粒度差异。

Conclusion: SKATE为通用、可扩展的LLM评估框架提供了重要进展，能够跟上LLM的发展步伐。

Abstract: Evaluating the capabilities and risks of foundation models is paramount, yet
current methods demand extensive domain expertise, hindering their scalability
as these models rapidly evolve. We introduce SKATE: a novel evaluation
framework in which large language models (LLMs) compete by generating and
solving verifiable tasks for one another. Our core insight is to treat
evaluation as a game: models act as both task-setters and solvers, incentivized
to create questions which highlight their own strengths while exposing others'
weaknesses. SKATE offers several key advantages, balancing scalability,
open-endedness, and objectivity. It is fully automated, data-free, and
scalable, requiring no human input or domain expertise. By using verifiable
tasks rather than LLM judges, scoring is objective. Unlike domain-limited
programmatically-generated benchmarks (e.g. chess-playing or spatial
reasoning), having LLMs creatively pose challenges enables open-ended and
scalable evaluation. As a proof of concept, we introduce LLM-set
code-output-prediction (COP) challenges as a verifiable and extensible
framework in which to test our approach. Using a TrueSkill-based ranking
system, we evaluate six frontier LLMs and find that: (1) weaker models can
reliably differentiate and score stronger ones, (2) LLM-based systems are
capable of self-preferencing behavior, generating questions that align with
their own capabilities, and (3) SKATE automatically surfaces fine-grained
capability differences between models. Our findings are an important step
towards general, scalable evaluation frameworks which can keep pace with LLM
progress.

</details>


### [145] [Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem](https://arxiv.org/abs/2508.06129)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux*

Main category: cs.AI

TL;DR: 该研究通过可解释AI分析VRP解决方案的质量预测模型，发现某些特征对预测结果具有一致性影响，并提出统一框架以指导元启发式算法的设计。


<details>
  <summary>Details</summary>
Motivation: 传统元启发式算法依赖人工设计，而机器学习方法可以利用组合优化中的结构特征，提高算法效率。本研究旨在通过敏感性分析进一步理解模型决策过程。

Method: 使用多种分类器模型预测VRP解决方案质量，并通过可解释AI技术分析特征重要性。

Result: 研究发现特征重要性存在差异，但某些特征始终是强预测因子，并提出了统一框架以量化特征影响。

Conclusion: 特征重要性分析为元启发式算法设计提供了潜在指导机制，有助于更高效地解决VRP问题。

Abstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with
numerous real-world applications, mostly solved using metaheuristic algorithms
due to its $\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely
on human-crafted designs developed through empirical studies. However, recent
research shows that machine learning methods can be used the structural
characteristics of solutions in combinatorial optimization, thereby aiding in
designing more efficient algorithms, particularly for solving VRP. Building on
this advancement, this study extends the previous research by conducting a
sensitivity analysis using multiple classifier models that are capable of
predicting the quality of VRP solutions. Hence, by leveraging explainable AI,
this research is able to extend the understanding of how these models make
decisions. Finally, our findings indicate that while feature importance varies,
certain features consistently emerge as strong predictors. Furthermore, we
propose a unified framework able of ranking feature impact across different
scenarios to illustrate this finding. These insights highlight the potential of
feature importance analysis as a foundation for developing a guidance mechanism
of metaheuristic algorithms for solving the VRP.

</details>


### [146] [The Fair Game: Auditing & Debiasing AI Algorithms Over Time](https://arxiv.org/abs/2508.06443)
*Debabrota Basu,Udvas Das*

Main category: cs.AI

TL;DR: 论文提出了一种动态机制“Fair Game”，通过结合审计器和去偏算法，利用强化学习实现公平性目标随时间调整，以解决传统公平机器学习在动态社会环境中适应性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统公平机器学习的定义通常是观察性的，且存在冲突，难以在动态社会环境中实现公平性目标。因此，需要一种能够适应社会变化的动态机制。

Method: 提出“Fair Game”框架，将审计器和去偏算法通过强化学习结合，形成一个闭环系统，动态调整公平性目标。

Result: “Fair Game”能够模拟社会伦理和法律框架的演变，提供灵活且适应性强的公平机器学习系统。

Conclusion: “Fair Game”为公平机器学习提供了一种动态适应的方法，解决了传统方法在动态环境中的局限性。

Abstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify
different types of bias (also known as unfairness) exhibited in the predictions
of ML algorithms, and to design new algorithms to mitigate them. Often, the
definitions of bias used in the literature are observational, i.e. they use the
input and output of a pre-trained algorithm to quantify a bias under concern.
In reality,these definitions are often conflicting in nature and can only be
deployed if either the ground truth is known or only in retrospect after
deploying the algorithm. Thus,there is a gap between what we want Fair ML to
achieve and what it does in a dynamic social environment. Hence, we propose an
alternative dynamic mechanism,"Fair Game",to assure fairness in the predictions
of an ML algorithm and to adapt its predictions as the society interacts with
the algorithm over time. "Fair Game" puts together an Auditor and a Debiasing
algorithm in a loop around an ML algorithm. The "Fair Game" puts these two
components in a loop by leveraging Reinforcement Learning (RL). RL algorithms
interact with an environment to take decisions, which yields new observations
(also known as data/feedback) from the environment and in turn, adapts future
decisions. RL is already used in algorithms with pre-fixed long-term fairness
goals. "Fair Game" provides a unique framework where the fairness goals can be
adapted over time by only modifying the auditor and the different biases it
quantifies. Thus,"Fair Game" aims to simulate the evolution of ethical and
legal frameworks in the society by creating an auditor which sends feedback to
a debiasing algorithm deployed around an ML system. This allows us to develop a
flexible and adaptive-over-time framework to build Fair ML systems pre- and
post-deployment.

</details>


### [147] [Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications](https://arxiv.org/abs/2508.06145)
*Byeonghun Bang,Jongsuk Yoon,Dong-Jin Chang,Seho Park,Yong Oh Lee*

Main category: cs.AI

TL;DR: 该研究通过引入检索增强生成（RAG）框架，显著提升了大型语言模型（LLMs）在药物禁忌领域的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在医疗健康领域的应用，特别是在药物禁忌这一需要高准确性的领域。

Method: 使用OpenAI的GPT-4o-mini作为基础模型，结合text-embedding-3-small模型和Langchain，构建了一个混合检索系统，并利用公开的DUR数据进行训练。

Result: RAG框架显著提升了模型在年龄组、妊娠和联合用药禁忌方面的准确性，分别达到0.94、0.87和0.89。

Conclusion: RAG框架可以有效减少药物禁忌决策中的不确定性，为医疗健康领域提供更可靠的解决方案。

Abstract: The versatility of large language models (LLMs) has been explored across
various sectors, but their application in healthcare poses challenges,
particularly in the domain of pharmaceutical contraindications where accurate
and reliable information is required. This study enhances the capability of
LLMs to address contraindications effectively by implementing a Retrieval
Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base
model, and the text-embedding-3-small model for embeddings, our approach
integrates Langchain to orchestrate a hybrid retrieval system with re-ranking.
This system leverages Drug Utilization Review (DUR) data from public databases,
focusing on contraindications for specific age groups, pregnancy, and
concomitant drug use. The dataset includes 300 question-answer pairs across
three categories, with baseline model accuracy ranging from 0.49 to 0.57.
Post-integration of the RAG pipeline, we observed a significant improvement in
model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications
related to age groups, pregnancy, and concomitant drug use, respectively. The
results indicate that augmenting LLMs with a RAG framework can substantially
reduce uncertainty in prescription and drug intake decisions by providing more
precise and reliable drug contraindication information.

</details>


### [148] [Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution](https://arxiv.org/abs/2508.06225)
*Zailong Tian,Zhuoheng Han,Yanzhe Chen,Haozhe Xu,Xi Yang,richeng xuan,Hongfeng Wang,Lizi Liao*

Main category: cs.AI

TL;DR: 论文提出从以准确性为中心的评估转向以置信度驱动、风险感知的LLM作为评判系统，强调校准置信度的重要性，并引入TH-Score和新框架LLM-as-a-Fuser以提升可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM作为评判系统过于关注准确性，忽视了置信度校准的重要性，导致实际部署中可靠性不足。

Method: 提出TH-Score量化置信度与准确性的对齐问题，并设计LLM-as-a-Fuser框架，通过集成方法提升LLM的评判可靠性。

Result: 实验表明，新方法显著改善了置信度校准，实现了自适应、基于置信度的评估流程，可靠性和准确性优于现有基线。

Conclusion: 置信度驱动的风险感知评估是提升LLM作为评判系统可靠性的关键，TH-Score和LLM-as-a-Fuser为此提供了有效解决方案。

Abstract: Large Language Models (LLMs) are widely used as automated judges, where
practical value depends on both accuracy and trustworthy, risk-aware judgments.
Existing approaches predominantly focus on accuracy, overlooking the necessity
of well-calibrated confidence, which is vital for adaptive and reliable
evaluation pipelines. In this work, we advocate a shift from accuracy-centric
evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing
the necessity of well-calibrated confidence for trustworthy and adaptive
evaluation. We systematically identify the **Overconfidence Phenomenon** in
current LLM-as-a-Judges, where predicted confidence significantly overstates
actual correctness, undermining reliability in practical deployment. To
quantify this phenomenon, we introduce **TH-Score**, a novel metric measuring
confidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an
ensemble framework that transforms LLMs into reliable, risk-aware evaluators.
Extensive experiments demonstrate that our approach substantially improves
calibration and enables adaptive, confidence-driven evaluation pipelines,
achieving superior reliability and accuracy compared to existing baselines.

</details>


### [149] [GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines](https://arxiv.org/abs/2508.06226)
*Yumeng Fu,Jiayin Zhu,Lingling Zhang,Bo Zhao,Shaoxuan Ma,Yushun Zhang,Yanrui Wu,Wenjun Wu*

Main category: cs.AI

TL;DR: GeoLaux 是一个新的几何问题解决基准，包含 2,186 个问题，重点评估多模态大语言模型（MLLMs）的长步推理和辅助线构造能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估 MLLMs 的几何能力时忽略了辅助线构造和细粒度过程评估，无法全面测试长步推理能力。

Method: 设计了包含计算和证明题的 GeoLaux 数据集，平均 6.51 推理步骤，41.8% 问题需要辅助线。提出五维评估策略。

Result: 实验发现 MLLMs 在长步推理中性能显著下降，证明题中易走捷径，且缺乏辅助线意识。

Conclusion: GeoLaux 可作为评估 MLLMs 几何推理能力的基准，并指导能力提升。

Abstract: Geometry problem solving (GPS) requires models to master diagram
comprehension, logical reasoning, knowledge application, numerical computation,
and auxiliary line construction. This presents a significant challenge for
Multimodal Large Language Models (MLLMs). However, existing benchmarks for
evaluating MLLM geometry skills overlook auxiliary line construction and lack
fine-grained process evaluation, making them insufficient for assessing MLLMs'
long-step reasoning abilities. To bridge these gaps, we present the GeoLaux
benchmark, comprising 2,186 geometry problems, incorporating both calculation
and proving questions. Notably, the problems require an average of 6.51
reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary
line construction. Building on the dataset, we design a novel five-dimensional
evaluation strategy assessing answer correctness, process correctness, process
quality, auxiliary line impact, and error causes. Extensive experiments on 13
leading MLLMs (including thinking models and non-thinking models) yield three
pivotal findings: First, models exhibit substantial performance degradation in
extended reasoning steps (nine models demonstrate over 50% performance drop).
Second, compared to calculation problems, MLLMs tend to take shortcuts when
solving proving problems. Third, models lack auxiliary line awareness, and
enhancing this capability proves particularly beneficial for overall geometry
reasoning improvement. These findings establish GeoLaux as both a benchmark for
evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a
guide for capability advancement. Our dataset and code are included in
supplementary materials and will be released.

</details>


### [150] [Learning Logical Rules using Minimum Message Length](https://arxiv.org/abs/2508.06230)
*Ruben Sharma,Sebastijan Dumančić,Ross D. King,Andrew Cropper*

Main category: cs.AI

TL;DR: 本文提出了一种贝叶斯归纳逻辑编程方法，通过最小消息长度程序从噪声数据中学习，平衡假设复杂性和数据拟合。


<details>
  <summary>Details</summary>
Motivation: 统一概率和逻辑学习是AI的关键挑战。

Method: 采用贝叶斯归纳逻辑编程，通过先验和似然平衡假设复杂性和数据拟合。

Result: 在游戏和药物设计等领域的实验中，该方法显著优于以往方法，且数据高效、对示例平衡不敏感。

Conclusion: 该方法在统一概率和逻辑学习方面表现出色，适用于多种领域。

Abstract: Unifying probabilistic and logical learning is a key challenge in AI. We
introduce a Bayesian inductive logic programming approach that learns minimum
message length programs from noisy data. Our approach balances hypothesis
complexity and data fit through priors, which explicitly favour more general
programs, and a likelihood that favours accurate programs. Our experiments on
several domains, including game playing and drug design, show that our method
significantly outperforms previous methods, notably those that learn minimum
description length programs. Our results also show that our approach is
data-efficient and insensitive to example balance, including the ability to
learn from exclusively positive examples.

</details>


### [151] [Symmetry breaking for inductive logic programming](https://arxiv.org/abs/2508.06263)
*Andrew Cropper,David M. Cerna,Matti Järvisalo*

Main category: cs.AI

TL;DR: 提出一种消除假设空间对称性的方法，显著减少求解时间。


<details>
  <summary>Details</summary>
Motivation: 归纳逻辑编程中，假设空间庞大且存在大量逻辑等价假设，搜索效率低。

Method: 在答案集编程中实现对称性消除方法。

Result: 实验表明，求解时间从超过一小时降至17秒。

Conclusion: 该方法有效提升归纳逻辑编程的搜索效率。

Abstract: The goal of inductive logic programming is to search for a hypothesis that
generalises training data and background knowledge. The challenge is searching
vast hypothesis spaces, which is exacerbated because many logically equivalent
hypotheses exist. To address this challenge, we introduce a method to break
symmetries in the hypothesis space. We implement our idea in answer set
programming. Our experiments on multiple domains, including visual reasoning
and game playing, show that our approach can reduce solving times from over an
hour to just 17 seconds.

</details>


### [152] [LLM Robustness Leaderboard v1 --Technical report](https://arxiv.org/abs/2508.06296)
*Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe*

Main category: cs.AI

TL;DR: PRISM Eval开发了BET工具，通过动态对抗优化实现100%攻击成功率，并提出细粒度鲁棒性指标，揭示模型间攻击难度差异。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）的鲁棒性，揭示其脆弱性，并提出改进方法。

Method: 使用BET工具进行自动化红队测试，采用动态对抗优化技术，并提出细粒度鲁棒性指标。

Result: BET对41个LLM中的37个实现100%攻击成功率，攻击难度差异达300倍。

Conclusion: 通过分布式鲁棒性评估，为社区提供改进LLM安全性的实用路径。

Abstract: This technical report accompanies the LLM robustness leaderboard published by
PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior
Elicitation Tool (BET), an AI system performing automated red-teaming through
Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)
against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we
propose a fine-grained robustness metric estimating the average number of
attempts required to elicit harmful behaviors, revealing that attack difficulty
varies by over 300-fold across models despite universal vulnerability. We
introduce primitive-level vulnerability analysis to identify which jailbreaking
techniques are most effective for specific hazard categories. Our collaborative
evaluation with trusted third parties from the AI Safety Network demonstrates
practical pathways for distributed robustness assessment across the community.

</details>


### [153] [A "good regulator theorem" for embodied agents](https://arxiv.org/abs/2508.06326)
*Nathaniel Virgo,Martin Biehl,Manuel Baltieri,Matteo Capucci*

Main category: cs.AI

TL;DR: 论文重新审视了Conant和Ashby的定理，提出了一种更广义的“信念更新”模型概念，适用于更广泛的系统。


<details>
  <summary>Details</summary>
Motivation: 探讨Conant和Ashby定理的局限性，并提出一种更通用的模型理论。

Method: 通过定义“信念更新”的概念，将模型视为观察者视角下的解释。

Result: 证明了无论系统如何调节环境或内部状态，观察者均可为其构建模型。

Conclusion: 模型是观察者视角的产物，而非系统固有属性，解决了原有定理的局限性。

Abstract: In a classic paper, Conant and Ashby claimed that "every good regulator of a
system must be a model of that system." Artificial Life has produced many
examples of systems that perform tasks with apparently no model in sight; these
suggest Conant and Ashby's theorem doesn't easily generalise beyond its
restricted setup. Nevertheless, here we show that a similar intuition can be
fleshed out in a different way: whenever an agent is able to perform a
regulation task, it is possible for an observer to interpret it as having
"beliefs" about its environment, which it "updates" in response to sensory
input. This notion of belief updating provides a notion of model that is more
sophisticated than Conant and Ashby's, as well as a theorem that is more
broadly applicable. However, it necessitates a change in perspective, in that
the observer plays an essential role in the theory: models are not a mere
property of the system but are imposed on it from outside. Our theorem holds
regardless of whether the system is regulating its environment in a classic
control theory setup, or whether it's regulating its own internal state; the
model is of its environment either way. The model might be trivial, however,
and this is how the apparent counterexamples are resolved.

</details>


### [154] [AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games](https://arxiv.org/abs/2508.06348)
*Mille Mei Zhen Loo,Gert Luzkov,Paolo Burelli*

Main category: cs.AI

TL;DR: 本文提出了一种基于Transformer的机器学习模型AntiCheatPT_256，用于检测《CS2》中的作弊行为，并公开了标注数据集CS2CD。模型在测试集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 在线游戏作弊破坏了游戏体验的公平性，现有反作弊系统难以在不侵犯用户隐私的情况下应对不断演变的作弊手段。

Method: 使用公开数据集CS2CD（795场比赛数据），生成并增强90,707个上下文窗口，训练Transformer模型。

Result: 模型在未增强测试集上达到89.17%的准确率和93.36%的AUC。

Conclusion: 该方法为数据驱动的作弊检测提供了可复现的基线，具有实际应用潜力。

Abstract: Cheating in online video games compromises the integrity of gaming
experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face
significant challenges in keeping pace with evolving cheating methods without
imposing invasive measures on users' systems. This paper presents
AntiCheatPT\_256, a transformer-based machine learning model designed to detect
cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we
introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using
this dataset, 90,707 context windows were created and subsequently augmented to
address class imbalance. The transformer model, trained on these windows,
achieved an accuracy of 89.17\% and an AUC of 93.36\% on an unaugmented test
set. This approach emphasizes reproducibility and real-world applicability,
offering a robust baseline for future research in data-driven cheat detection.

</details>


### [155] [From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI](https://arxiv.org/abs/2508.06352)
*Christian Meske,Justin Brenne,Erdi Uenal,Sabahat Oelcer,Ayseguel Doganguen*

Main category: cs.AI

TL;DR: 论文提出“解释性AI”作为补充范式，利用生成式AI能力作为人类理解的解释伙伴，而非算法透明度的提供者。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI（XAI）方法过于关注算法透明度，提供的解释抽象且非自适应，难以支持终端用户的理解。

Method: 提出一个八维概念模型，强调叙事沟通、自适应个性化和渐进披露原则，并通过医疗专业人员的快速情境设计方法进行实证验证。

Result: 用户更偏好上下文敏感的多模态解释，而非技术透明度。

Conclusion: 需设计以人类理解为中心的AI系统，而非仅关注算法内省，并提出了跨领域和文化背景的用户中心解释方法研究议程。

Abstract: Current explainable AI (XAI) approaches prioritize algorithmic transparency
and present explanations in abstract, non-adaptive formats that often fail to
support meaningful end-user understanding. This paper introduces "Explanatory
AI" as a complementary paradigm that leverages generative AI capabilities to
serve as explanatory partners for human understanding rather than providers of
algorithmic transparency. While XAI reveals algorithmic decision processes for
model validation, Explanatory AI addresses contextual reasoning to support
human decision-making in sociotechnical contexts. We develop a definition and
systematic eight-dimensional conceptual model distinguishing Explanatory AI
through narrative communication, adaptive personalization, and progressive
disclosure principles. Empirical validation through Rapid Contextual Design
methodology with healthcare professionals demonstrates that users consistently
prefer context-sensitive, multimodal explanations over technical transparency.
Our findings reveal the practical urgency for AI systems designed for human
comprehension rather than algorithmic introspection, establishing a
comprehensive research agenda for advancing user-centered AI explanation
approaches across diverse domains and cultural contexts.

</details>


### [156] [Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned](https://arxiv.org/abs/2508.06368)
*Claudia dAmato,Giuseppe Rubini,Francesco Didio,Donato Francioso,Fatima Zahra Amara,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 论文提出两种构建法律知识图谱（KG）的方法，填补法律领域KG的空白，并针对暴力侵害妇女案件开发了KG。


<details>
  <summary>Details</summary>
Motivation: 法律决策需要全面的法律背景知识和最新案例信息，而法律KG是支持这一需求的重要工具。

Method: 采用系统性自下而上方法和基于大型语言模型的新方法，结合结构化数据提取、本体开发和语义丰富。

Result: 构建了针对暴力侵害妇女案件的法律KG，并通过能力问题验证其有效性。

Conclusion: 开发的KG可提升法律信息的可访问性，支持复杂查询，并为预测性司法机器学习工具提供知识支持。

Abstract: Legal decision-making process requires the availability of comprehensive and
detailed legislative background knowledge and up-to-date information on legal
cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a
valuable tool to facilitate access to legal information, to be queried and
exploited for the purpose, and to enable advanced reasoning and machine
learning applications. Indeed, legal KGs may act as knowledge intensive
component to be used by pre-dictive machine learning solutions supporting the
decision process of the legal expert. Nevertheless, a few KGs can be found in
the legal domain. To fill this gap, we developed a legal KG targeting legal
cases of violence against women, along with clear adopted methodologies.
Specifically, the paper introduces two complementary approaches for automated
legal KG construction; a systematic bottom-up approach, customized for the
legal domain, and a new solution leveraging Large Language Models. Starting
from legal sentences publicly available from the European Court of Justice, the
solutions integrate structured data extraction, ontology development, and
semantic enrichment to produce KGs tailored for legal cases involving violence
against women. After analyzing and comparing the results of the two approaches,
the developed KGs are validated via suitable competency questions. The obtained
KG may be impactful for multiple purposes: can improve the accessibility to
legal information both to humans and machine, can enable complex queries and
may constitute an important knowledge component to be possibly exploited by
machine learning tools tailored for predictive justice.

</details>


### [157] [What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting](https://arxiv.org/abs/2508.06454)
*Joshua Caiata,Ben Armstrong,Kate Larson*

Main category: cs.AI

TL;DR: 提出数据驱动框架评估多赢家投票规则在实践中的公理违反频率，并证明神经网络投票规则优于传统规则。


<details>
  <summary>Details</summary>
Motivation: 研究多赢家投票规则在不同偏好分布下的公理表现，以补充最坏情况分析的局限性。

Method: 提出数据驱动框架，分析投票规则在多种偏好分布下的公理违反情况，并引入神经网络作为投票规则进行比较。

Result: 神经网络投票规则在减少公理违反方面优于传统规则。

Conclusion: 数据驱动方法可为新投票系统设计提供参考，支持社会选择领域的数据驱动研究。

Abstract: Committee-selection problems arise in many contexts and applications, and
there has been increasing interest within the social choice research community
on identifying which properties are satisfied by different multi-winner voting
rules. In this work, we propose a data-driven framework to evaluate how
frequently voting rules violate axioms across diverse preference distributions
in practice, shifting away from the binary perspective of axiom satisfaction
given by worst-case analysis. Using this framework, we analyze the relationship
between multi-winner voting rules and their axiomatic performance under several
preference distributions. We then show that neural networks, acting as voting
rules, can outperform traditional rules in minimizing axiom violations. Our
results suggest that data-driven approaches to social choice can inform the
design of new voting systems and support the continuation of data-driven
research in social choice.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [158] [Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems](https://arxiv.org/abs/2508.05846)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.CY

TL;DR: 本文主张AI决策过程的透明性是构建可信赖且符合伦理的机器人系统的关键，探讨了透明性如何促进问责、知情同意和伦理算法调试，并提出了增强透明性的新方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI和机器人技术在社会中的普及，确保其行为符合伦理变得至关重要，透明性被认为是实现这一目标的基础。

Method: 论文提出了一种框架，将技术实施与伦理考量结合，包括标准化指标、可解释AI技术和用户友好界面，以解决动态现实环境中的透明性挑战。

Result: 通过分析透明性对公众信任、监管政策和未来研究的影响，论文为伦理AI系统设计提供了方向。

Conclusion: 透明性是伦理AI系统设计的核心要素，本文为负责任AI和机器人技术的未来发展提供了指导。

Abstract: As artificial intelligence (AI) and robotics increasingly permeate society,
ensuring the ethical behavior of these systems has become paramount. This paper
contends that transparency in AI decision-making processes is fundamental to
developing trustworthy and ethically aligned robotic systems. We explore how
transparency facilitates accountability, enables informed consent, and supports
the debugging of ethical algorithms. The paper outlines technical, ethical, and
practical challenges in implementing transparency and proposes novel approaches
to enhance it, including standardized metrics, explainable AI techniques, and
user-friendly interfaces. This paper introduces a framework that connects
technical implementation with ethical considerations in robotic systems,
focusing on the specific challenges of achieving transparency in dynamic,
real-world contexts. We analyze how prioritizing transparency can impact public
trust, regulatory policies, and avenues for future research. By positioning
transparency as a fundamental element in ethical AI system design, we aim to
add to the ongoing discussion on responsible AI and robotics, providing
direction for future advancements in this vital field.

</details>


### [159] [Public support for misinformation interventions depends on perceived fairness, effectiveness, and intrusiveness](https://arxiv.org/abs/2508.05849)
*Catherine King,Samantha C. Phillips,Kathleen M. Carley*

Main category: cs.CY

TL;DR: 研究发现，公众对社交媒体干预虚假信息的支持主要取决于干预的公平性、有效性和侵入性，其中公平性最重要。标签和事实核查等透明干预更受欢迎，且民主党人和女性更支持干预。


<details>
  <summary>Details</summary>
Motivation: 虚假信息的泛滥可能损害民主规范，但公众对干预措施的支持因素尚未充分研究。

Method: 调查了1,010名美国社交媒体用户对10种干预措施的支持度和看法。

Result: 公平性是支持干预的最重要因素，其次是有效性和侵入性。透明干预更受欢迎，民主党人和女性支持度更高。

Conclusion: 公众意见对政策实施和效果至关重要，需理解支持干预的原因。

Abstract: The proliferation of misinformation on social media has concerning possible
consequences, such as the degradation of democratic norms. While recent
research on countering misinformation has largely focused on analyzing the
effectiveness of interventions, the factors associated with public support for
these interventions have received little attention. We asked 1,010 American
social media users to rate their support for and perceptions of ten
misinformation interventions implemented by the government or social media
companies. Our results indicate that the perceived fairness of the intervention
is the most important factor in determining support, followed by the perceived
effectiveness of that intervention and then the intrusiveness. Interventions
that supported user agency and transparency, such as labeling content or
fact-checking ads, were more popular than those that involved moderating or
removing content or accounts. We found some demographic differences in support
levels, with Democrats and women supporting interventions more and finding them
more fair, more effective, and less intrusive than Republicans and men,
respectively. It is critical to understand which interventions are supported
and why, as public opinion can play a key role in the rollout and effectiveness
of policies.

</details>


### [160] [Sprouting technology otherwise, hospicing negative commons -- Rethinking technology in the transition to sustainability-oriented futures](https://arxiv.org/abs/2508.05860)
*Martin Deron*

Main category: cs.CY

TL;DR: 论文提出一个概念框架，用于引导ICT（信息通信技术）向可持续未来转型，结合了过渡研究、公共资源理论和限制文献，通过四个类别（废墟、幽灵、种子和愿景）分析计算技术的物质与文化演变。


<details>
  <summary>Details</summary>
Motivation: ICT对环境造成日益严重的直接和间接危害，需重新定向以实现可持续发展目标。

Method: 结合过渡研究、公共资源理论和限制文献，提出一个概念框架，通过四个类别（废墟、幽灵、种子和愿景）分析技术转型的复杂动态。

Result: 框架帮助研究者和实践者更具体地应对技术转型中的矛盾、遗产和机遇。

Conclusion: 该框架为ICT向可持续和公平未来转型提供了实用的分析工具。

Abstract: Due to its significant and growing environmental harms, both directly through
its materiality and indirectly through its pervasive integration into
unsustainable economic systems, ICT will need to be radically redirected to
align with sustainability-oriented futures. While the role of ICT in such
futures will likely diverge significantly from current dynamics, it will
probably not be entirely disconnected from the present. Instead, such
transition involves complex dynamics of continuity, adaptation and rupture.
Drawing from recent work in transition studies, the commons (particularly
"negative commons"), as well as some of the Limits literature, this article
proposes a conceptual framework for navigating this redirection. The framework
attempts to bring together the disentanglement from sociotechnical elements
incompatible with long-term sustainability and the support of existing
practices that may serve as foundations for alternative technological paths. It
introduces four categories: ruins, ghosts, seeds and visions, to examine how
material and cultural aspects of computing may become obsolete, persist in
latent or reinterpreted forms, or contribute to sustainability-oriented
futures. Through both empirical and speculative examples, I intend to show how
this lens can help researchers and practitioners engage more concretely with
the tensions, inheritances, and opportunities involved in redirecting computing
towards more sustainable and equitable futures.

</details>


### [161] [The Memory Wars: AI Memory, Network Effects, and the Geopolitics of Cognitive Sovereignty](https://arxiv.org/abs/2508.05867)
*Mario Brcic*

Main category: cs.CY

TL;DR: 论文提出“认知主权”概念，探讨在AI助手时代个体、群体和国家如何保持自主思维和身份认同，分析了个体和地缘政治风险，并提出政策框架应对。


<details>
  <summary>Details</summary>
Motivation: 随着AI助手的发展，传统数据隐私问题升级为认知和地缘政治控制风险，需探讨如何维护自主性。

Method: 提出“网络效应2.0”模型，分析心理和地缘政治风险，基于“扩展心智”理论，提出政策框架。

Result: 揭示了AI助手对认知主权和地缘政治的威胁，如数字殖民主义和公共话语操控。

Conclusion: 需通过记忆可移植性、透明度和战略联盟等政策维护个体和国家主权。

Abstract: The advent of continuously learning Artificial Intelligence (AI) assistants
marks a paradigm shift from episodic interactions to persistent, memory-driven
relationships. This paper introduces the concept of "Cognitive Sovereignty",
the ability of individuals, groups, and nations to maintain autonomous thought
and preserve identity in the age of powerful AI systems, especially those that
hold their deep personal memory. It argues that the primary risk of these
technologies transcends traditional data privacy to become an issue of
cognitive and geopolitical control. We propose "Network Effect 2.0," a model
where value scales with the depth of personalized memory, creating powerful
cognitive moats and unprecedented user lock-in. We analyze the psychological
risks of such systems, including cognitive offloading and identity dependency,
by drawing on the "extended mind" thesis. These individual-level risks scale to
geopolitical threats, such as a new form of digital colonialism and subtle
shifting of public discourse. To counter these threats, we propose a policy
framework centered on memory portability, transparency, sovereign cognitive
infrastructure, and strategic alliances. This work reframes the discourse on AI
assistants in an era of increasingly intimate machines, pointing to challenges
to individual and national sovereignty.

</details>


### [162] [Energy Experience Design](https://arxiv.org/abs/2508.05869)
*Brian Sutherland*

Main category: cs.CY

TL;DR: 本文探讨了ICT系统的材料足迹问题，重点关注电池的可持续性设计，并提出无电池设备原型作为解决方案。


<details>
  <summary>Details</summary>
Motivation: ICT系统的材料足迹显著增长，引发了对可持续性和气候正义的讨论，特别是电池的高废弃率（每年150亿个）和关键矿物问题。

Method: 提出“能源体验”定义，并通过设计无电池可持续能源设备原型来探索解决方案。

Result: 展示了极长寿命且少用关键矿物的无电池设备原型，探讨其对主流系统的启示。

Conclusion: 无电池设备原型为过渡性能源体验设计提供了可能性，对大规模制造系统具有潜在影响。

Abstract: The material footprint of information and communications technology (ICT)
systems is both significant and growing, inspiring a variety of conversations
around sustainability and climate justice. In part this effort has been
catalysed by past scholarship and analysis from the LIMITS community. This
paper examines energy storage systems for computing, particularly batteries --
which are discarded at the rate of 15 billion a year worldwide. The
International Energy Agency (IEA) is now referring to the energy transition
toward low carbon systems as a critical mineral problem, and countries are
speaking openly of 'mineral security' in policy documents. In this paper I 1)
present a definition for energy experience and what this means for the design
and making of devices, interactions and experiences. I also 2) explore a series
of electronics device prototypes converted to run from batteryless sustainable
energy that are extremely long lasting, and make limited use of critical
minerals. As transitional energy experience device-design experiments, what do
prototypes like these suggest for more mainstream, mass-manufactured systems?

</details>


### [163] [Towards Reliable Generative AI-Driven Scaffolding: Reducing Hallucinations and Enhancing Quality in Self-Regulated Learning Support](https://arxiv.org/abs/2508.05929)
*Keyang Qian,Shiqi Liu,Tongguang Li,Mladen Raković,Xinyu Li,Rui Guan,Inge Molenaar,Sadia Nawaz,Zachari Swiecki,Lixiang Yan,Dragan Gašević*

Main category: cs.CY

TL;DR: 论文探讨了利用生成式人工智能（GenAI）提升教育技术中个性化支架的可靠性，通过多代理系统和LLM-as-a-Judge技术减少幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在生成个性化学习支架时可能产生的幻觉问题，以提升学习体验和伦理标准。

Method: 提出两种方法：多代理系统用于可靠性评估，LLM-as-a-Judge技术用于质量评估，并与单代理系统和机器学习基线进行比较。

Result: 多代理系统在可靠性评估中表现优异，接近人类专家水平；两种方法均能有效减少幻觉。

Conclusion: 建议将这两种方法整合到GenAI系统中，以减少幻觉并提升支架质量。

Abstract: Generative Artificial Intelligence (GenAI) holds a potential to advance
existing educational technologies with capabilities to automatically generate
personalised scaffolds that support students' self-regulated learning (SRL).
While advancements in large language models (LLMs) promise improvements in the
adaptability and quality of educational technologies for SRL, there remain
concerns about the hallucinations in content generated by LLMs, which can
compromise both the learning experience and ethical standards. To address these
challenges, we proposed GenAI-enabled approaches for evaluating personalised
SRL scaffolds before they are presented to students, aiming for reducing
hallucinations and improving the overall quality of LLM-generated personalised
scaffolds. Specifically, two approaches are investigated. The first approach
involved developing a multi-agent system approach for reliability evaluation to
assess the extent to which LLM-generated scaffolds accurately target relevant
SRL processes. The second approach utilised the "LLM-as-a-Judge" technique for
quality evaluation that evaluates LLM-generated scaffolds for their helpfulness
in supporting students. We constructed evaluation datasets, and compared our
results with single-agent LLM systems and machine learning approach baselines.
Our findings indicate that the reliability evaluation approach is highly
effective and outperforms the baselines, showing almost perfect alignment with
human experts' evaluations. Moreover, both proposed evaluation approaches can
be harnessed to effectively reduce hallucinations. Additionally, we identified
and discussed bias limitations of the "LLM-as-a-Judge" technique in evaluating
LLM-generated scaffolds. We suggest incorporating these approaches into
GenAI-powered personalised SRL scaffolding systems to mitigate hallucination
issues and improve the overall scaffolding quality.

</details>


### [164] [Dean of LLM Tutors: Exploring Comprehensive and Automated Evaluation of LLM-generated Educational Feedback via LLM Feedback Evaluators](https://arxiv.org/abs/2508.05952)
*Keyang Qian,Yixin Cheng,Rui Guan,Wei Dai,Flora Jin,Kaixun Yang,Sadia Nawaz,Zachari Swiecki,Guanliang Chen,Lixiang Yan,Dragan Gašević*

Main category: cs.CY

TL;DR: 论文提出了一种使用LLM反馈评估器（DeanLLMs）自动评估LLM导师生成的教育反馈的方法，以提高反馈质量并减少幻觉问题。


<details>
  <summary>Details</summary>
Motivation: LLM导师在教育反馈中的随机性和幻觉问题可能影响学习体验和伦理标准，需要一种自动评估方法。

Method: 提出了一个包含六个反馈内容维度、七个反馈有效性维度和三种幻觉类型的评估框架，并使用虚拟作业提交数据集对LLM反馈评估器进行微调和评估。

Result: o3-pro在零样本标注中表现最佳，o4-mini在少样本标注中表现最佳，GPT-4.1微调后达到人类专家水平（准确率79.8%，F1分数79.4%）。

Conclusion: 该方法能够自动提供高质量和可靠的教育反馈，提升了LLM导师的反馈能力。

Abstract: The use of LLM tutors to provide automated educational feedback to students
on student assignment submissions has received much attention in the AI in
Education field. However, the stochastic nature and tendency for hallucinations
in LLMs can undermine both quality of learning experience and adherence to
ethical standards. To address this concern, we propose a method that uses LLM
feedback evaluators (DeanLLMs) to automatically and comprehensively evaluate
feedback generated by LLM tutor for submissions on university assignments
before it is delivered to students. This allows low-quality feedback to be
rejected and enables LLM tutors to improve the feedback they generated based on
the evaluation results. We first proposed a comprehensive evaluation framework
for LLM-generated educational feedback, comprising six dimensions for feedback
content, seven for feedback effectiveness, and three for hallucination types.
Next, we generated a virtual assignment submission dataset covering 85
university assignments from 43 computer science courses using eight commonly
used commercial LLMs. We labelled and open-sourced the assignment dataset to
support the fine-tuning and evaluation of LLM feedback evaluators. Our findings
show that o3-pro demonstrated the best performance in zero-shot labelling of
feedback while o4-mini demonstrated the best performance in few-shot labelling
of feedback. Moreover, GPT-4.1 achieved human expert level performance after
fine-tuning (Accuracy 79.8%, F1-score 79.4%; human average Accuracy 78.3%,
F1-score 82.6%). Finally, we used our best-performance model to evaluate 2,000
assignment feedback instances generated by 10 common commercial LLMs, 200 each,
to compare the quality of feedback generated by different LLMs. Our LLM
feedback evaluator method advances our ability to automatically provide
high-quality and reliable educational feedback to students.

</details>


### [165] [SCALEFeedback: A Large-Scale Dataset of Synthetic Computer Science Assignments for LLM-generated Educational Feedback Research](https://arxiv.org/abs/2508.05953)
*Keyang Qian,Kaixun Yang,Wei Dai,Flora Jin,Yixin Cheng,Rui Guan,Sadia Nawaz,Zachari Swiecki,Guanliang Chen,Lixiang Yan,Dragan Gašević*

Main category: cs.CY

TL;DR: 论文提出了一个名为SCALEFeedback的大规模合成数据集，用于研究LLM生成的教育反馈，并通过SAM框架生成合成数据，保护学生隐私。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏包含详细作业描述、评分标准和学生提交的大规模开源数据集，限制了自动生成有效教育反馈的研究。

Method: 使用SAM框架通过LLM一对一模仿真实作业描述和学生提交生成合成数据集。

Result: 合成数据集包含10,000份学生提交，BERTScore F1为0.84，PCC为0.62（分数）和0.85（长度），优于基线方法。

Conclusion: 一对一LLM模仿是生成开源合成教育数据集的有效方法，保护隐私的同时保留数据语义和分布。

Abstract: Using LLMs to give educational feedback to students for their assignments has
attracted much attention in the AI in Education field. Yet, there is currently
no large-scale open-source dataset of student assignments that includes
detailed assignment descriptions, rubrics, and student submissions across
various courses. As a result, research on generalisable methodology for
automatic generation of effective and responsible educational feedback remains
limited. In the current study, we constructed a large-scale dataset of
Synthetic Computer science Assignments for LLM-generated Educational Feedback
research (SCALEFeedback). We proposed a Sophisticated Assignment Mimicry (SAM)
framework to generate the synthetic dataset by one-to-one LLM-based imitation
from real assignment descriptions, student submissions to produce their
synthetic versions. Our open-source dataset contains 10,000 synthetic student
submissions spanning 155 assignments across 59 university-level computer
science courses. Our synthetic submissions achieved BERTScore F1 0.84, PCC of
0.62 for assignment marks and 0.85 for length, compared to the corresponding
real-world assignment dataset, while ensuring perfect protection of student
private information. All these results of our SAM framework outperformed
results of a naive mimicry method baseline. The LLM-generated feedback for our
synthetic assignments demonstrated the same level of effectiveness compared to
that of real-world assignment dataset. Our research showed that one-to-one LLM
imitation is a promising method for generating open-source synthetic
educational datasets that preserve the original dataset's semantic meaning and
student data distribution, while protecting student privacy and institutional
copyright. SCALEFeedback enhances our ability to develop LLM-based
generalisable methods for offering high-quality, automated educational feedback
in a scalable way.

</details>


### [166] [Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education](https://arxiv.org/abs/2508.05979)
*Xinming Yang,Haasil Pujara,Jun Li*

Main category: cs.CY

TL;DR: 论文提出了一种新的教学方法，让学生充当教师角色，教导LLM解决问题，通过设计知识缺口问题和Socrates系统，显著提升了学生成绩。


<details>
  <summary>Details</summary>
Motivation: 传统LLM作为虚拟导师的方法可能导致学生被动学习和过度依赖，因此需要一种更主动的学习方式。

Method: 开发了设计知识缺口问题的策略，并引入Socrates系统，让学生在教学中填补这些缺口。

Result: 在本科生课程中验证，该方法显著提高了学生成绩。

Conclusion: 该方法为利用LLM提升学生参与度和掌握度提供了实用且经济的框架。

Abstract: While Large Language Models (LLMs) are often used as virtual tutors in
computer science (CS) education, this approach can foster passive learning and
over-reliance. This paper presents a novel pedagogical paradigm that inverts
this model: students act as instructors who must teach an LLM to solve
problems. To facilitate this, we developed strategies for designing questions
with engineered knowledge gaps that only a student can bridge, and we introduce
Socrates, a system for deploying this method with minimal overhead. We
evaluated our approach in an undergraduate course and found that this
active-learning method led to statistically significant improvements in student
performance compared to historical cohorts. Our work demonstrates a practical,
cost-effective framework for using LLMs to deepen student engagement and
mastery.

</details>


### [167] [Surviving the Narrative Collapse: Sustainability and Justice in Computing Within Limits](https://arxiv.org/abs/2508.05992)
*Dave Guruge,Samuel Mann,Ruth Myers,Oliver Bates,Mikey Goldweber,Andy Williamson,Jon Lasenby,Ian Brooks*

Main category: cs.CY

TL;DR: 论文探讨了可持续性计算研究在社会政治背景下被误解的问题，并提出了一种名为Fictomorphosis的创意故事重构方法，以重新审视争议性话题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于应对可持续性计算研究被贴上“觉醒”或“危险”标签的现象，以及如何在信息误导和意识形态极化的环境中保持其影响力。

Method: 采用Fictomorphosis方法，通过不同体裁和视角重构争议性话题，并让计算研究者参与结构化叙事转换。

Result: 研究发现该方法有助于重新理解可持续性计算研究的感知、争议及其在“后真相”世界中的适应性。

Conclusion: 结论指出，通过创意叙事方法，可持续性计算研究可以在复杂的社会政治环境中找到新的存在和影响方式。

Abstract: Sustainability-driven computing research - encompassing equity, diversity,
climate change, and social justice - is increasingly dismissed as woke or even
dangerous in many sociopolitical contexts. As misinformation, ideological
polarisation, deliberate ignorance and reactionary narratives gain ground, how
can sustainability research in computing continue to exist and make an impact?
This paper explores these tensions through Fictomorphosis, a creative story
retelling method that reframes contested topics through different genres and
perspectives. By engaging computing researchers in structured narrative
transformations, we investigate how sustainability-oriented computing research
is perceived, contested, and can adapt in a post-truth world.

</details>


### [168] [Dirty Bits in Low-Earth Orbit: The Carbon Footprint of Launching Computers](https://arxiv.org/abs/2508.06250)
*Robin Ohs,Gregory F. Stock,Andreas Schmidt,Juan A. Fraire,Holger Hermanns*

Main category: cs.CY

TL;DR: 本文研究了低地球轨道（LEO）卫星计算的碳足迹，提出了ESpaS工具，比较了轨道与地面计算的碳排放，发现轨道系统碳排放显著更高。


<details>
  <summary>Details</summary>
Motivation: 随着LEO卫星在通信和轨道计算中的应用增加，其可持续性尚未充分研究，本文旨在填补这一空白。

Method: 使用ESpaS工具，分析发射、轨道运行和再入的生命周期排放，比较不同发射技术和地面与轨道工作负载的碳排放。

Result: 轨道系统的碳排放比地面高一个数量级，主要来自发射和再入的隐含排放。

Conclusion: 建议在轨道数字基础设施开发中采用碳意识设计原则和监管措施。

Abstract: Low-Earth Orbit (LEO) satellites are increasingly proposed for communication
and in-orbit computing, achieving low-latency global services. However, their
sustainability remains largely unexamined. This paper investigates the carbon
footprint of computing in space, focusing on lifecycle emissions from launch
over orbital operation to re-entry. We present ESpaS, a lightweight tool for
estimating carbon intensities across CPU usage, memory, and networking in
orbital vs. terrestrial settings. Three worked examples compare (i) launch
technologies (state-of-the-art rocket vs. potential next generation) and (ii)
operational emissions of data center workloads in orbit and on the ground.
Results show that, even under optimistic assumptions, in-orbit systems incur
significantly higher carbon costs - up to an order of magnitude more than
terrestrial equivalents - primarily due to embodied emissions from launch and
re-entry. Our findings advocate for carbon-aware design principles and
regulatory oversight in developing sustainable digital infrastructure in orbit.

</details>


### [169] [Analysis and Constructive Criticism of the Official Data Protection Impact Assessment of the German Corona-Warn-App](https://arxiv.org/abs/2508.06267)
*Rainer Rehak,Christian R. Kühne,Kirsten Bock*

Main category: cs.CY

TL;DR: 论文分析了德国Corona-Warn-App（CWA）最初的数据保护影响评估（DPIA）的缺陷，并记录了其改进过程。


<details>
  <summary>Details</summary>
Motivation: 探讨初始DPIA的不足，以促进高质量DPIA的实践和学术讨论。

Method: 通过分析初始DPIA的弱点（如方法、技术和法律缺陷），并记录外部专家和公众讨论对其改进的贡献。

Result: 初始DPIA存在多项不足，如范围狭窄和风险讨论不充分，但后续改进部分解决了这些问题。

Conclusion: 论文为提升DPIA质量和学术讨论提供了参考，但仍有一些关键问题未解决。

Abstract: On June 15, 2020, the official data protection impact assessment (DPIA) for
the German Corona-Warn-App (CWA) was made publicly available. Shortly
thereafter, the app was made available for download in the app stores. However,
the first version of the DPIA had significant weaknesses, as this paper argues.
However since then, the quality of the official DPIA increased immensely due to
interventions and interactions such as an alternative DPIA produced by external
experts and extensive public discussions. To illustrate the development and
improvement, the initial weaknesses of the official DPIA are documented and
analyzed here. For this paper to meaningfully do this, first the purpose of a
DPIA is briefly summarized. According to Article 35 of the GDPR, it consists
primarily of identifying the risks to the fundamental rights and freedoms of
natural persons. This paper documents at least specific methodological,
technical and legal shortcomings of the initial DPIA of the CWA: 1) It only
focused on the app itself, neither on the whole processing procedure nor on the
infrastructure used. 2) It only briefly touched on the main data protection
specific attacker, the processing organization itself. And 3) The discussion of
effective safeguards to all risks including such as the ones posed by Google
and Apple has only insufficiently been worked out. Finally, this paper outlines
the constructive criticism and suggestions uttered, also by the authors of this
paper, regarding the initial release. As of now, some of those constructive
contributions have been worked into the current DPIA, such as 1) and 2), but
some central ones still haven't, such as 3). This paper aims to provide an
opportunity to improve the practical knowledge and academic discourse regarding
high-quality DPIAs.

</details>


### [170] [Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks](https://arxiv.org/abs/2508.06411)
*Ze Shen Chin*

Main category: cs.CY

TL;DR: 论文提出一个多维框架和因果路径模型，以系统分析和管理六种AI灾难性风险。


<details>
  <summary>Details</summary>
Motivation: 当前关于AI风险的讨论缺乏全面框架和具体因果路径，本文旨在填补这一空白。

Method: 通过七个关键维度（如意图、能力等）和风险路径建模，分析六种AI灾难性风险。

Result: 提供了系统化风险识别和通用缓解策略，以及针对特定场景的干预措施。

Conclusion: 该方法为管理AI灾难性风险提供了更结构化和可操作的基础。

Abstract: Although discourse around the risks of Artificial Intelligence (AI) has
grown, it often lacks a comprehensive, multidimensional framework, and concrete
causal pathways mapping hazard to harm. This paper aims to bridge this gap by
examining six commonly discussed AI catastrophic risks: CBRN, cyber offense,
sudden loss of control, gradual loss of control, environmental risk, and
geopolitical risk. First, we characterize these risks across seven key
dimensions, namely intent, competency, entity, polarity, linearity, reach, and
order. Next, we conduct risk pathway modeling by mapping step-by-step
progressions from the initial hazard to the resulting harms. The dimensional
approach supports systematic risk identification and generalizable mitigation
strategies, while risk pathway models help identify scenario-specific
interventions. Together, these methods offer a more structured and actionable
foundation for managing catastrophic AI risks across the value chain.

</details>


### [171] [Generative AI and the Future of the Digital Commons: Five Open Questions and Knowledge Gaps](https://arxiv.org/abs/2508.06470)
*Arman Noroozian,Lorena Aldana,Marta Arisi,Hadi Asghari,Renata Avila,Pietro Giovanni Bizzaro,Ramya Chandrasekhar,Cristian Consonni,Deborah De Angelis,Francesca De Chiara,Maria del Rio-Chanona,Melanie Dulong de Rosnay,Maria Eriksson,Frederic Font,Emilia Gomez,Valérian Guillier,Lisa Gutermuth,David Hartmann,Lucie-Aimée Kaffee,Paul Keller,Felix Stalder,Joao Vinagre,Denny Vrandečić,Amanda Wasielewski*

Main category: cs.CY

TL;DR: 论文探讨了生成式AI与数字公地之间的紧张关系，提出了五个关键问题，呼吁更负责任的AI开发实践。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI对数字公地可持续性和公平性的影响，以促进AI与公地的和谐发展。

Method: 通过分析当前问题，提出五个关键问题并呼吁讨论与研究。

Result: 强调了数字公地作为知识治理形式的重要性，需更新技术标准和法律框架。

Conclusion: 呼吁建立“AI公地”和公共基础设施，支持数字公地的长期健康发展。

Abstract: The rapid advancement of Generative AI (GenAI) relies heavily on the digital
commons, a vast collection of free and open online content that is created,
shared, and maintained by communities. However, this relationship is becoming
increasingly strained due to financial burdens, decreased contributions, and
misalignment between AI models and community norms. As we move deeper into the
GenAI era, it is essential to examine the interdependent relationship between
GenAI, the long-term sustainability of the digital commons, and the equity of
current AI development practices. We highlight five critical questions that
require urgent attention: 1. How can we prevent the digital commons from being
threatened by undersupply as individuals cease contributing to the commons and
turn to Generative AI for information? 2. How can we mitigate the risk of the
open web closing due to restrictions on access to curb AI crawlers? 3. How can
technical standards and legal frameworks be updated to reflect the evolving
needs of organizations hosting common content? 4. What are the effects of
increased synthetic content in open knowledge databases, and how can we ensure
their integrity? 5. How can we account for and distribute the infrastructural
and environmental costs of providing data for AI training? We emphasize the
need for more responsible practices in AI development, recognizing the digital
commons not only as content but as a collaborative and decentralized form of
knowledge governance, which relies on the practice of "commoning" - making,
maintaining, and protecting shared and open resources. Ultimately, our goal is
to stimulate discussion and research on the intersection of Generative AI and
the digital commons, with the aim of developing an "AI commons" and public
infrastructures for AI development that support the long-term health of the
digital commons.

</details>


### [172] [The Problem of Atypicality in LLM-Powered Psychiatry](https://arxiv.org/abs/2508.06479)
*Bosco Garcia,Eugene Y. S. Chua,Harman Singh Brah*

Main category: cs.CY

TL;DR: 论文探讨了大型语言模型（LLMs）在心理健康领域的应用及其伦理问题，提出动态上下文认证（DCC）框架以解决非典型性问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在心理健康领域的部署可能对非典型认知模式的精神病患者产生危险，标准缓解策略不足。

Method: 提出动态上下文认证（DCC）框架，结合临床转化和AI治理的动态安全模型。

Result: DCC将LLMs部署视为持续的知识与伦理过程，强调解释安全性。

Conclusion: 非典型性无法消除，但可通过DCC主动管理。

Abstract: Large language models (LLMs) are increasingly proposed as scalable solutions
to the global mental health crisis. But their deployment in psychiatric
contexts raises a distinctive ethical concern: the problem of atypicality.
Because LLMs generate outputs based on population-level statistical
regularities, their responses -- while typically appropriate for general users
-- may be dangerously inappropriate when interpreted by psychiatric patients,
who often exhibit atypical cognitive or interpretive patterns. We argue that
standard mitigation strategies, such as prompt engineering or fine-tuning, are
insufficient to resolve this structural risk. Instead, we propose dynamic
contextual certification (DCC): a staged, reversible and context-sensitive
framework for deploying LLMs in psychiatry, inspired by clinical translation
and dynamic safety models from artificial intelligence governance. DCC reframes
chatbot deployment as an ongoing epistemic and ethical process that prioritises
interpretive safety over static performance benchmarks. Atypicality, we argue,
cannot be eliminated -- but it can, and must, be proactively managed.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [173] [Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems](https://arxiv.org/abs/2508.05778)
*Jaemin Oh,Jinsil Lee,Youngjoon Hong*

Main category: cs.LG

TL;DR: 提出了一种基于神经网络的数据驱动方法，用于在非线性状态空间模型中学习nudging项，并在三个混沌系统上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在非线性系统中设计有效的nudging项具有挑战性，因此需要一种数据驱动的方法来解决这一问题。

Method: 利用神经网络学习非线性状态空间模型中的nudging项，并基于Kazantzis--Kravaris--Luenberger观测器理论提供理论支持。

Result: 在Lorenz 96模型、Kuramoto--Sivashinsky方程和Kolmogorov流三个混沌系统上验证了方法的有效性。

Conclusion: 神经网络nudging是一种有效的非线性系统数据同化方法，具有理论和实验支持。

Abstract: Nudging is an empirical data assimilation technique that incorporates an
observation-driven control term into the model dynamics. The trajectory of the
nudged system approaches the true system trajectory over time, even when the
initial conditions differ. For linear state space models, such control terms
can be derived under mild assumptions. However, designing effective nudging
terms becomes significantly more challenging in the nonlinear setting. In this
work, we propose neural network nudging, a data-driven method for learning
nudging terms in nonlinear state space models. We establish a theoretical
existence result based on the Kazantzis--Kravaris--Luenberger observer theory.
The proposed approach is evaluated on three benchmark problems that exhibit
chaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and
the Kolmogorov flow.

</details>


### [174] [Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty](https://arxiv.org/abs/2508.05659)
*Jeroen F. Uleman,Loes Crielaard,Leonie K. Elsenburg,Guido A. Veldhuis,Karien Stronks,Naja Hulvej Rod,Rick Quax,Vítor V. Vasconcelos*

Main category: cs.LG

TL;DR: D2D方法将因果循环图（CLDs）转化为系统动力学模型（SDMs），支持动态分析和干预策略探索，优于传统网络中心性分析。


<details>
  <summary>Details</summary>
Motivation: CLDs作为静态定性工具，难以支持动态分析和干预策略制定，且传统定量方法易导致错误推断。

Method: D2D利用CLDs中的结构信息（链接存在性和极性），通过用户简单标注变量类型（存量、流量/辅助变量或常量），生成SDMs。

Result: D2D能区分高/低优先级杠杆点，与数据驱动模型一致性更高，并提供不确定性估计和数据收集指导。

Conclusion: D2D方法实用性强，开源工具支持进一步验证和推广，有望在多个领域广泛应用。

Abstract: Causal loop diagrams (CLDs) are widely used in health and environmental
research to represent hypothesized causal structures underlying complex
problems. However, as qualitative and static representations, CLDs are limited
in their ability to support dynamic analysis and inform intervention
strategies. Additionally, quantitative CLD analysis methods like network
centrality analysis often lead to false inference. We propose
Diagrams-to-Dynamics (D2D), a method for converting CLDs into exploratory
system dynamics models (SDMs) in the absence of empirical data. With minimal
user input - following a protocol to label variables as stocks,
flows/auxiliaries, or constants - D2D leverages the structural information
already encoded in CLDs, namely, link existence and polarity, to simulate
hypothetical interventions and explore potential leverage points under
uncertainty. Results suggest that D2D helps distinguish between high- and
low-ranked leverage points. We compare D2D to a data-driven SDM constructed
from the same CLD and variable labeling. D2D showed greater consistency with
the data-driven model than network centrality analysis, while providing
uncertainty estimates and guidance for future data collection. The method is
implemented in an open-source Python package and a web-based application to
support further testing and lower the barrier to dynamic modeling for
researchers working with CLDs. We expect additional validation will further
establish the approach's utility across a broad range of cases and domains.

</details>


### [175] [Optimal Linear Baseline Models for Scientific Machine Learning](https://arxiv.org/abs/2508.05831)
*Alexander DeLise,Kyle Loh,Krish Patel,Meredith Teague,Andrea Arnold,Matthias Chung*

Main category: cs.LG

TL;DR: 本文提出了一个基于贝叶斯风险最小化的统一理论框架，用于分析线性编码器-解码器架构，解决了科学机器学习中的正向建模和逆向恢复任务。


<details>
  <summary>Details</summary>
Motivation: 非线性神经网络虽然成功，但理论不透明，限制了其在需要可解释性场景中的应用。线性神经网络则提供了简单有效的理论基础。

Method: 通过贝叶斯风险最小化的视角，推导了秩约束的线性和仿射线性最优映射，适用于数据、前向算子和测量过程中的秩缺陷情况。

Result: 在生物医学成像、金融因子分析和非线性流体动力学模拟等数据集上验证了理论结果。

Conclusion: 该工作为理解和基准测试科学机器学习中的神经网络模型提供了稳健的基础。

Abstract: Across scientific domains, a fundamental challenge is to characterize and
compute the mappings from underlying physical processes to observed signals and
measurements. While nonlinear neural networks have achieved considerable
success, they remain theoretically opaque, which hinders adoption in contexts
where interpretability is paramount. In contrast, linear neural networks serve
as a simple yet effective foundation for gaining insight into these complex
relationships. In this work, we develop a unified theoretical framework for
analyzing linear encoder-decoder architectures through the lens of Bayes risk
minimization for solving data-driven scientific machine learning problems. We
derive closed-form, rank-constrained linear and affine linear optimal mappings
for forward modeling and inverse recovery tasks. Our results generalize
existing formulations by accommodating rank-deficiencies in data, forward
operators, and measurement processes. We validate our theoretical results by
conducting numerical experiments on datasets from simple biomedical imaging,
financial factor analysis, and simulations involving nonlinear fluid dynamics
via the shallow water equations. This work provides a robust baseline for
understanding and benchmarking learned neural network models for scientific
machine learning problems.

</details>


### [176] [A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics](https://arxiv.org/abs/2508.05724)
*Massimiliano Romiti*

Main category: cs.LG

TL;DR: 论文提出了一种新的框架，将物理定律表示为加权知识图谱，并通过图注意力网络（GAT）进行链接预测，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决物理方程表示中的符号歧义问题，并探索物理定律之间的潜在关系。

Method: 构建包含400个高级物理方程的数据库，设计加权知识图谱表示，并使用GAT进行链接预测。

Result: GAT在测试中AUC达到0.9742，显著优于基线方法，并发现了物理学的宏观结构和跨领域关系。

Conclusion: 该框架能够生成大量假设，为物理学子领域的研究提供数据支持。

Abstract: This work introduces a novel framework for representing and analyzing
physical laws as a weighted knowledge graph. We constructed a database of 659
distinct physical equations, subjected to rigorous semantic cleaning to resolve
notational ambiguities, resulting in a corpus of 400 advanced physics
equations. We developed an enhanced graph representation where both physical
concepts and equations are nodes, connected by weighted inter-equation bridges.
These weights are objectively defined using normalized metrics for variable
overlap, physics-informed importance scores, and bibliometric data. A Graph
Attention Network (GAT) was trained for link prediction, achieving a test AUC
of 0.9742 +/- 0.0018 across five independent runs, significantly outperforming
both classical heuristics (best baseline AUC: 0.9487) and established GNN
architectures like GraphSAGE (AUC: 0.9504, p = 0.029). Statistical testing
confirmed significance of all comparisons (p < 0.05), with 2.7% improvement
over the best baseline. Our analysis reveals three key findings: (i) The model
autonomously rediscovers the known macroscopic structure of physics,
identifying strong conceptual axes between Electromagnetism and Statistical
Mechanics. (ii) It identifies central hub equations that serve as critical
bridges between multiple physical domains. (iii) The model generates stable,
computationally-derived hypotheses for cross-domain relationships, identifying
both known principles and suggesting novel mathematical analogies for further
theoretical investigation. The framework can generate hundreds of such
hypotheses, enabling the creation of specialized datasets for targeted analysis
of specific physics subfields. Code and data available at
https://github.com/kingelanci/graphysics

</details>


### [177] [From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data](https://arxiv.org/abs/2508.05791)
*Haoran Li,Lihao Mai,Muhao Guo,Jiaqi Wu,Yang Weng,Yannan Sun,Ce Jimmy Liu*

Main category: cs.LG

TL;DR: 提出了一种可扩展的框架，通过整合异构数据重建可信的配电网拓扑，结合空间布局和动态行为，并引入置信度感知机制和物理约束，验证了高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 配电网拓扑的准确性对现代电网运行至关重要，但实际数据来源多样且质量不均，需要一种可靠的重建方法。

Method: 结合空间基础设施布局和系统动态行为，引入置信度感知推断机制，并嵌入物理约束，确保推断结果既可信又结构有效。

Result: 在Oncor的8000多个电表数据上验证，拓扑重建准确率超过95%，置信度校准和计算效率显著优于基线方法。

Conclusion: 该框架在真实部署条件下快速收敛到可信拓扑，为电网操作提供了可靠支持。

Abstract: Accurate distribution grid topology is essential for reliable modern grid
operations. However, real-world utility data originates from multiple sources
with varying characteristics and levels of quality. In this work, developed in
collaboration with Oncor Electric Delivery, we propose a scalable framework
that reconstructs a trustworthy grid topology by systematically integrating
heterogeneous data. We observe that distribution topology is fundamentally
governed by two complementary dimensions: the spatial layout of physical
infrastructure (e.g., GIS and asset metadata) and the dynamic behavior of the
system in the signal domain (e.g., voltage time series). When jointly
leveraged, these dimensions support a complete and physically coherent
reconstruction of network connectivity. To address the challenge of uneven data
quality without compromising observability, we introduce a confidence-aware
inference mechanism that preserves structurally informative yet imperfect
inputs, while quantifying the reliability of each inferred connection for
operator interpretation. This soft handling of uncertainty is tightly coupled
with hard enforcement of physical feasibility: we embed operational
constraints, such as transformer capacity limits and radial topology
requirements, directly into the learning process. Together, these components
ensure that inference is both uncertainty-aware and structurally valid,
enabling rapid convergence to actionable, trustworthy topologies under
real-world deployment conditions. The proposed framework is validated using
data from over 8000 meters across 3 feeders in Oncor's service territory,
demonstrating over 95% accuracy in topology reconstruction and substantial
improvements in confidence calibration and computational efficiency relative to
baseline methods.

</details>


### [178] [An Effective Approach for Node Classification in Textual Graphs](https://arxiv.org/abs/2508.05836)
*Rituparna Datta,Nibir Chandra Mandal*

Main category: cs.LG

TL;DR: 提出了一种结合TAPE与Graphormer的新框架，利用ChatGPT生成语义丰富的解释，增强节点表示，并在ogbn-arxiv数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在整合文本语义与图结构信息时的不足，如领域术语捕捉、长程依赖建模、时间演化和大规模数据扩展。

Method: 结合TAPE框架与Graphormer，利用ChatGPT生成语义解释，通过注意力权重融合节点表示与结构特征。

Result: 在ogbn-arxiv数据集上，分类准确率达0.772，显著优于GCN基线（0.713），并在精确率、召回率和F1分数上表现优异。

Conclusion: 该框架为动态TAGs中的节点分类提供了可扩展且鲁棒的解决方案，为知识系统和科学发现研究指明了新方向。

Abstract: Textual Attribute Graphs (TAGs) are critical for modeling complex networks
like citation networks, but effective node classification remains challenging
due to difficulties in integrating rich semantics from text with structural
graph information. Existing methods often struggle with capturing nuanced
domain-specific terminology, modeling long-range dependencies, adapting to
temporal evolution, and scaling to massive datasets. To address these issues,
we propose a novel framework that integrates TAPE (Text-Attributed Graph
Representation Enhancement) with Graphormer. Our approach leverages a large
language model (LLM), specifically ChatGPT, within the TAPE framework to
generate semantically rich explanations from paper content, which are then
fused into enhanced node representations. These embeddings are combined with
structural features using a novel integration layer with learned attention
weights. Graphormer's path-aware position encoding and multi-head attention
mechanisms are employed to effectively capture long-range dependencies across
the citation network. We demonstrate the efficacy of our framework on the
challenging ogbn-arxiv dataset, achieving state-of-the-art performance with a
classification accuracy of 0.772, significantly surpassing the best GCN
baseline of 0.713. Our method also yields strong results in precision (0.671),
recall (0.577), and F1-score (0.610). We validate our approach through
comprehensive ablation studies that quantify the contribution of each
component, demonstrating the synergy between semantic and structural
information. Our framework provides a scalable and robust solution for node
classification in dynamic TAGs, offering a promising direction for future
research in knowledge systems and scientific discovery.

</details>


### [179] [A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance](https://arxiv.org/abs/2508.05876)
*Francesca Ferrara,Lander W. Schillinger Arana,Florian Dörfler,Sarah H. Q. Li*

Main category: cs.LG

TL;DR: 该论文提出了一种基于马尔可夫决策过程（MDP）和强化学习策略梯度（RL-PG）的框架，用于训练自主避碰机动（CAM）策略，旨在平衡碰撞风险和燃料消耗。


<details>
  <summary>Details</summary>
Motivation: 传统避碰策略通常在接近碰撞时间（TCA）前24小时启动机动，可能导致燃料浪费。本研究旨在通过早期决策优化燃料消耗，同时保持可接受的碰撞风险。

Method: 将CAM建模为连续状态、离散动作和有限时间范围的MDP，结合了碰撞风险、燃料消耗和轨道几何的解析模型，并使用RL-PG算法训练策略。

Result: 在合成和历史碰撞事件中，训练策略显著减少了平均燃料消耗，同时保持了与传统策略相当的碰撞风险保障。

Conclusion: 该方法有效优化了避碰机动的燃料效率，同时确保了安全性，适用于实际空间任务。

Abstract: This work presents a Markov decision process (MDP) framework to model
decision-making for collision avoidance maneuver (CAM) and a reinforcement
learning policy gradient (RL-PG) algorithm to train an autonomous guidance
policy using historic CAM data. In addition to maintaining acceptable collision
risks, this approach seeks to minimize the average fuel consumption of CAMs by
making early maneuver decisions. We model CAM as a continuous state, discrete
action and finite horizon MDP, where the critical decision is determining when
to initiate the maneuver. The MDP model also incorporates analytical models for
conjunction risk, propellant consumption, and transit orbit geometry. The
Markov policy effectively trades-off maneuver delay-which improves the
reliability of conjunction risk indicators-with propellant consumption-which
increases with decreasing maneuver time. Using historical data of tracked
conjunction events, we verify this framework and conduct an extensive ablation
study on the hyper-parameters used within the MDP. On synthetic conjunction
events, the trained policy significantly minimizes both the overall and average
propellant consumption per CAM when compared to a conventional cut-off policy
that initiates maneuvers 24 hours before the time of closest approach (TCA). On
historical conjunction events, the trained policy consumes more propellant
overall but reduces the average propellant consumption per CAM. For both
historical and synthetic conjunction events, the trained policy achieves equal
if not higher overall collision risk guarantees.

</details>


### [180] [The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)](https://arxiv.org/abs/2508.05905)
*Jeffrey Uhlmann*

Main category: cs.LG

TL;DR: 论文提出了一种2位量化方法SZT，在固定资源预算下可能优于非量化方法。


<details>
  <summary>Details</summary>
Motivation: 传统量化被视为性能与计算资源的折衷，但作者认为在固定资源预算下，量化可能提供更高信息密度。

Method: 引入Signed-Zero Ternary (SZT)，一种2位量化方法，确定性提供梯度信息且无前向路径损失。

Result: 分析表明SZT可能比非量化方法具有更高的信息密度。

Conclusion: 在固定资源预算下，量化方法（如SZT）可能优于非量化方法。

Abstract: Quantization is usually regarded as a means to trade quality of performance
for reduced compute requirements, i.e., as a suboptimal approximation. However,
if examined in terms of a fixed overall resource budget, a very different
perspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit
quantization that deterministically provides gradient information with no
forward-path penalty. Our analysis provides evidence that it may improve
information density compared to non-quantized alternatives.

</details>


### [181] [Dual Signal Decomposition of Stochastic Time Series](https://arxiv.org/abs/2508.05915)
*Alex Glushkovsky*

Main category: cs.LG

TL;DR: 论文提出了一种将随机时间序列分解为均值、离散度和噪声的方法，通过机器学习拟合双信号并优化损失函数。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列分解问题，提取均值、离散度和噪声，以便更好地分析和预测。

Method: 应用机器学习拟合双信号，优化损失函数，包括正则化项和统计过程控制权重。

Result: 提出了一种平滑和去噪算法，支持顺序和联合学习两种方法。

Conclusion: 分解后的双信号可用于结构学习、预测和分析多时间序列的交叉效应。

Abstract: The research paper addresses decomposition of a stochastic time series into
three time series representing a dual signal i.e., the mean and the dispersion,
with noise isolated. Decomposition is done by applying machine learning to fit
a dual signal. Machine learning minimizes the loss function which compromises
between fitting the original time series and penalizing irregularities of the
dual signal. The latter includes terms based on the first and second order
derivatives along time. To preserve special patterns, weighting of the
regularization components of the loss function has been introduced based on
Statistical Process Control methodology. The proposed decomposition can be
applied as a smoothing algorithm against the mean and dispersion of the time
series. By isolating noise, the proposed decomposition can be seen as a
denoising algorithm. Two approaches of the learning process have been
considered: sequential and jointly. The former approach learns the mean signal
first and then dispersion. The latter approach fits the dual signal jointly.
Jointly learning can uncover complex relationships for the time series with
heteroskedasticity. Learning has been set by solving the direct non-linear
unconstrained optimization problem or by applying neural networks that have
sequential or twin output architectures. Tuning of the loss function
hyperparameters focuses on the isolated noise to be a stationary stochastic
process without autocorrelation properties. Depending on the applications, the
hyperparameters of the learning can be tuned towards either the discrete states
by stepped signal or smoothed series. The decomposed dual signal can be
represented on the 2D space and used to learn inherent structures, to forecast
both mean and dispersion, or to analyze cross effects in case of multiple time
series.

</details>


### [182] [Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations](https://arxiv.org/abs/2508.05921)
*Siddharth Rout*

Main category: cs.LG

TL;DR: 论文提出了一种名为Shifted Gaussian Encoding的激活过滤方法，解决了神经PDE求解器因矩阵病态导致的优化问题，显著提升了求解范围和精度。


<details>
  <summary>Details</summary>
Motivation: 神经PDE求解器的精度问题通常源于优化困难，尤其是多保真度和刚性问题的病态矩阵。

Method: 引入Shifted Gaussian Encoding，通过过滤激活矩阵提高其秩和表达能力，同时保持凸性。

Result: 方法将稳态对流-扩散方程的Peclet数求解范围扩展了两个数量级，多频函数学习的误差降低了六个数量级，且在高保真图像拟合上比百万参数深度网络更快更准。

Conclusion: 研究表明，神经科学求解器的瓶颈通常是矩阵条件而非网络深度，简单的架构改进即可带来显著性能提升。

Abstract: Accuracy in neural PDE solvers often breaks down not because of limited
expressivity, but due to poor optimisation caused by ill-conditioning,
especially in multi-fidelity and stiff problems. We study this issue in
Physics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural
PDE solvers, and show that asymptotic components in governing equations can
produce highly ill-conditioned activation matrices, severely limiting
convergence. We introduce Shifted Gaussian Encoding, a simple yet effective
activation filtering step that increases matrix rank and expressivity while
preserving convexity. Our method extends the solvable range of Peclet numbers
in steady advection-diffusion equations by over two orders of magnitude,
achieves up to six orders lower error on multi-frequency function learning, and
fits high-fidelity image vectors more accurately and faster than deep networks
with over a million parameters. This work highlights that conditioning, not
depth, is often the bottleneck in scientific neural solvers and that simple
architectural changes can unlock substantial gains.

</details>


### [183] [Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting](https://arxiv.org/abs/2508.05928)
*Si Shen,Peijun Shen,Wenhua Zhao,Danhao Zhu*

Main category: cs.LG

TL;DR: S-GRPO是一种改进的GRPO方法，通过噪声感知优势权重稳定训练，解决了Think-Answer Mismatch问题，在数学推理任务中表现优于GRPO。


<details>
  <summary>Details</summary>
Motivation: GRPO在训练大型推理模型时存在Think-Answer Mismatch问题，噪声奖励信号会破坏学习过程，尤其在响应组不平衡时更严重。

Method: 提出S-GRPO，通过噪声感知优势权重优化训练稳定性。

Result: S-GRPO在多个模型上显著优于GRPO，性能提升2.2%-2.5%，并在20%噪声下仍能稳定学习。

Conclusion: S-GRPO为大规模推理模型的训练提供了更稳健和有效的方法。

Abstract: Group-Relative Policy Optimization (GRPO) is a key technique for training
large reasoning models, yet it suffers from a critical vulnerability: the
\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning
process. This problem is most severe in unbalanced response groups,
paradoxically degrading the signal precisely when it should be most
informative. To address this challenge, we propose Stable Group-Relative Policy
Optimization (S-GRPO), a principled enhancement that derives optimal,
noise-aware advantage weights to stabilize training. Our comprehensive
experiments on mathematical reasoning benchmarks demonstrate S-GRPO's
effectiveness and robustness. On various models, S-GRPO significantly
outperforms DR. GRPO, achieving performance gains of +2.5% on
Qwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on
Qwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn
under 20% synthetic reward noise, S-GRPO maintains stable learning progress.
These results highlight S-GRPO's potential for more robust and effective
training of large-scale reasoning models. \footnote{Code and data are available
at: https://github.com/shenpeijun0212/S-GRPO

</details>


### [184] [Multi-Armed Bandits-Based Optimization of Decision Trees](https://arxiv.org/abs/2508.05957)
*Hasibul Karim Shanto,Umme Ayman Koana,Shadikur Rahman*

Main category: cs.LG

TL;DR: 论文提出了一种基于多臂老虎机（MAB）的决策树剪枝方法，通过强化学习动态优化剪枝过程，以提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统剪枝方法（如CCP和REP）基于贪心策略，可能导致泛化能力不足，尤其在小型复杂数据集上表现不佳。

Method: 将剪枝过程建模为探索-利用问题，利用MAB算法动态选择最优剪枝节点。

Result: 实验表明，该方法在多个基准数据集上优于传统剪枝方法。

Conclusion: MAB方法为决策树剪枝提供了一种动态且概率化的优化途径。

Abstract: Decision trees, without appropriate constraints, can easily become overly
complex and prone to overfit, capturing noise rather than generalizable
patterns. To resolve this problem,pruning operation is a crucial part in
optimizing decision trees, as it not only reduces the complexity of trees but
also decreases the probability of generating overfit models. The conventional
pruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning
(REP) are mostly based on greedy approaches that focus on immediate gains in
performance while pruning nodes of the decision tree. However, this might
result in a lower generalization in the long run, compromising the robust
ability of the tree model when introduced to unseen data samples, particularly
when trained with small and complex datasets. To address this challenge, we are
proposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement
learning (RL)-based technique, that will dynamically prune the tree to generate
an optimal decision tree with better generalization. Our proposed approach
assumes the pruning process as an exploration-exploitation problem, where we
are utilizing the MAB algorithms to find optimal branch nodes to prune based on
feedback from each pruning actions. Experimental evaluation on several
benchmark datasets, demonstrated that our proposed approach results in better
predictive performance compared to the traditional ones. This suggests the
potential of utilizing MAB for a dynamic and probabilistic way of decision tree
pruning, in turn optimizing the decision tree-based model.

</details>


### [185] [Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2508.05960)
*Haohui Chen,Zhiyong Chen*

Main category: cs.LG

TL;DR: 论文提出了一种名为MCRE的框架和MCRQ算法，用于离线强化学习，通过平衡保守性和性能提升来解决分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习面临分布偏移问题，导致过估计和性能下降，需要一种方法在保守性和性能之间取得平衡。

Method: 提出了MCRE框架，结合TD误差和行为克隆项，并基于此开发了MCRQ算法。

Result: 实验表明MCRQ在基准数据集上优于现有方法。

Conclusion: MCRE和MCRQ有效解决了离线强化学习中的分布偏移问题，提升了性能。

Abstract: Offline reinforcement learning (RL) seeks to learn optimal policies from
static datasets without further environment interaction. A key challenge is the
distribution shift between the learned and behavior policies, leading to
out-of-distribution (OOD) actions and overestimation. To prevent gross
overestimation, the value function must remain conservative; however, excessive
conservatism may hinder performance improvement. To address this, we propose
the mildly conservative regularized evaluation (MCRE) framework, which balances
conservatism and performance by combining temporal difference (TD) error with a
behavior cloning term in the Bellman backup. Building on this, we develop the
mildly conservative regularized Q-learning (MCRQ) algorithm, which integrates
MCRE into an off-policy actor-critic framework. Experiments show that MCRQ
outperforms strong baselines and state-of-the-art offline RL algorithms on
benchmark datasets.

</details>


### [186] [LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning](https://arxiv.org/abs/2508.05977)
*Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan*

Main category: cs.LG

TL;DR: 论文提出了一种基于语义对齐的强化学习方法，通过SBERT计算奖励，避免了手动设计奖励函数的繁琐。


<details>
  <summary>Details</summary>
Motivation: 在科学机器学习中，设计有效的奖励函数是强化学习的挑战，尤其是在任务目标难以数值化的情况下。现有方法多依赖启发式或手动调整。

Method: 使用SBERT计算当前状态与目标语义指令的余弦相似度作为奖励，替代手动定义的奖励函数。

Result: 在多个环境中验证了语义奖励能有效指导学习，实现竞争性控制行为，且无需手工奖励函数。

Conclusion: 研究表明语言嵌入空间与传统欧几里得空间存在相关性，为自然语言目标与代理行为的对齐提供了新思路，并为大语言模型与控制应用的结合奠定了基础。

Abstract: In the domain of scientific machine learning, designing effective reward
functions remains a challenge in reinforcement learning (RL), particularly in
environments where task goals are difficult to specify numerically. Reward
functions in existing work are predominantly based on heuristics, manual
engineering, or task-specific tuning. In this work, we introduce a semantically
aligned reinforcement learning method where rewards are computed by aligning
the current state with a target semantic instruction using a
Sentence-Bidirectional Encoder Representations from Transformers (SBERT).
Instead of relying on manually defined reward functions, the policy receives
feedback based on the reward, which is a cosine similarity between the goal
textual description and the statement description in the episode. We evaluated
our approach in several environments and showed that semantic reward can guide
learning to achieve competitive control behavior, even in the absence of
hand-crafted reward functions. Our study demonstrates a correlation between the
language embedding space and the conventional Euclidean space. This framework
opens new horizons for aligning agent behavior with natural language goals and
lays the groundwork for a more seamless integration of larger language models
(LLMs) and fluid control applications.

</details>


### [187] [Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning](https://arxiv.org/abs/2508.05984)
*Ankur Naskar,Gugan Thoppe,Vijay Gupta*

Main category: cs.LG

TL;DR: 论文提出了一种方法，通过重新定义误差为线性递归并利用半范数的收缩性，首次实现了参数无关的$\tilde{O}(1/\sqrt{t})$最优收敛速率，适用于平均奖励和指数折扣的$Q$-学习。


<details>
  <summary>Details</summary>
Motivation: 解决非线性固定点方程（如$Q$-学习和TD学习）中半范数收缩的非单调性问题，实现参数无关的最优收敛速率。

Method: 将平均误差重新定义为涉及非线性扰动的线性递归，并通过半范数收缩与适当诱导范数的单调性耦合来抑制非线性。

Result: 首次在平均奖励和指数折扣的$Q$-学习中实现了$\tilde{O}(1/\sqrt{t})$的最优收敛速率，适用于同步/异步更新、单/分布式部署及马尔可夫轨迹数据。

Conclusion: 该方法填补了参数无关最优收敛速率的空白，具有广泛的应用场景。

Abstract: Algorithms for solving \textit{nonlinear} fixed-point equations -- such as
average-reward \textit{$Q$-learning} and \textit{TD-learning} -- often involve
semi-norm contractions. Achieving parameter-free optimal convergence rates for
these methods via Polyak--Ruppert averaging has remained elusive, largely due
to the non-monotonicity of such semi-norms. We close this gap by (i.) recasting
the averaged error as a linear recursion involving a nonlinear perturbation,
and (ii.) taming the nonlinearity by coupling the semi-norm's contraction with
the monotonicity of a suitably induced norm. Our main result yields the first
parameter-free $\tilde{O}(1/\sqrt{t})$ optimal rates for $Q$-learning in both
average-reward and exponentially discounted settings, where $t$ denotes the
iteration index. The result applies within a broad framework that accommodates
synchronous and asynchronous updates, single-agent and distributed deployments,
and data streams obtained either from simulators or along Markovian
trajectories.

</details>


### [188] [Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal](https://arxiv.org/abs/2508.05988)
*Wenhao Zeng,Yaoning Wang,Chao Hu,Yuling Shi,Chengcheng Wan,Hongyu Zhang,Xiaodong Gu*

Main category: cs.LG

TL;DR: 论文提出ASAP框架，通过锚点引导和基于惊讶度的剪枝方法压缩Chain-of-Thought（CoT），在保持推理逻辑的同时显著降低训练和推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有的CoT压缩方法在保持逻辑连贯性和捕捉关键推理步骤方面存在不足，亟需一种高效且可靠的压缩框架。

Method: ASAP采用粗到细的策略：1）锚点引导剪枝保留核心推理结构；2）基于首词惊讶度选择逻辑关键步骤；3）模型自主生成简洁CoT。

Result: 在代码生成任务中，ASAP显著减少23.5%的token生成和43.5%的推理延迟，同时保持36.19%的Pass@1准确率。

Conclusion: ASAP为构建高效的大型推理模型提供了可行方向，平衡了性能与成本。

Abstract: Recently, Large Reasoning Models (LRMs) have demonstrated remarkable
capabilities in code reasoning by scaling up the length of Chain-of-Thought
(CoT). However, excessively long reasoning traces introduce substantial
challenges in terms of training cost, inference latency, and deployment
feasibility. While various CoT compression approaches have emerged to address
this challenge, they face inherent trade-offs: token-level methods often
disrupt syntactic and logical coherence, while step-level methods based on
perplexity fail to reliably capture the logically critical reasoning steps. In
this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel
coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided
pruning to preserve the core reasoning structure, which efficiently reduces the
search space for subsequent processing. It then enables a logic-aware pruning
by selecting logically essential reasoning steps based on a novel first-token
surprisal metric. Finally, ASAP teaches models to autonomously generate and
leverage these concise CoTs at inference time, enabling efficient reasoning in
coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy
across multiple code generation benchmarks while substantially reducing
training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,
our approach reduces token generation by 23.5% and inference latency by 43.5%
compared to the strongest baseline, while achieving a competitive accuracy of
36.19% in Pass@1. Our results highlight a promising direction for building
powerful and efficient LRMs.

</details>


### [189] [Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization](https://arxiv.org/abs/2508.05995)
*Fei Xu Yu,Gina Adam,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

TL;DR: MCTS-OPS是一种结合蒙特卡洛树搜索（MCTS）与大型语言模型（LLMs）的神经符号框架，用于提升复杂任务中的代码生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在需要多步规划的复杂任务中表现不佳，MCTS-OPS旨在通过优化提示序列提升LLMs的代码生成和问题解决能力。

Method: 将提示选择建模为MCTS引导的序列决策过程，探索并优化多步提示序列。

Result: 在网络优化任务中，MCTS-OPS显著优于基线方法，执行成功率和优化结果均有提升（奖励提高2~4倍，标准差降低3倍）。

Conclusion: 结合符号规划与LLMs有望在复杂领域中实现稳健、高质量的代码生成。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
code generation and structured reasoning; however, their performance often
degrades on complex tasks that require consistent multi-step planning. Recent
work has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet
existing approaches primarily focus on generating heuristic-based code for
optimization or target simpler tasks where correctness alone is sufficient. In
this work, we propose MCTS-OPS, a novel neural-symbolic framework that
formulates prompt selection as a sequential decision process guided by MCTS.
Our method explores and refines multi-step prompt sequences for the goal of
improving code generation quality and enhancing the problem-solving
capabilities of LLMs in general optimization. Experiments on network
optimization show significant improvement over the baselines, both in the
success rate of executing the generated code and in the optimization results
with the specified objective and constraints (2$\sim$4$\times$ higher reward
and 3$\times$ lower standard deviation). Moreover, it improves the chance of
attaining the optimal solution by about 10\% of cases, compared to baseline
methods in hard problems. These results highlight the promise of combining
symbolic planning with LLMs for robust, high-quality code generation in complex
domains.

</details>


### [190] [Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients](https://arxiv.org/abs/2508.06023)
*Xiaobin Shen,Jonathan Elmer,George H. Chen*

Main category: cs.LG

TL;DR: 提出了一种新颖的分步动态竞争风险模型，用于改善心脏骤停后昏迷患者的神经预后预测，通过分阶段利用时间不变和时间变化的特征。


<details>
  <summary>Details</summary>
Motivation: 心脏骤停后昏迷患者的预后预测对ICU临床决策至关重要，但现有方法未能充分利用随时间变化的特征。

Method: 扩展Fine和Gray模型，分阶段建模时间不变和时间变化的特征，并引入神经网络捕捉非线性关系。

Result: 在2278名患者的回顾性队列中，模型对苏醒、撤除生命支持治疗和死亡等竞争性结局表现出稳健的判别性能。

Conclusion: 该模型可推广至多阶段特征收集的动态预测任务，为临床决策提供更精准的预测支持。

Abstract: Prognostication for comatose post-cardiac arrest patients is a critical
challenge that directly impacts clinical decision-making in the ICU. Clinical
information that informs prognostication is collected serially over time.
Shortly after cardiac arrest, various time-invariant baseline features are
collected (e.g., demographics, cardiac arrest characteristics). After ICU
admission, additional features are gathered, including time-varying hemodynamic
data (e.g., blood pressure, doses of vasopressor medications). We view these as
two phases in which we collect new features. In this study, we propose a novel
stepwise dynamic competing risks model that improves the prediction of
neurological outcomes by automatically determining when to take advantage of
time-invariant features (first phase) and time-varying features (second phase).
Notably, our model finds patients for whom this second phase (time-varying
hemodynamic) information is beneficial for prognostication and also when this
information is beneficial (as we collect more hemodynamic data for a patient
over time, how important these data are for prognostication varies). Our
approach extends the standard Fine and Gray model to explicitly model the two
phases and to incorporate neural networks to flexibly capture complex nonlinear
feature relationships. Evaluated on a retrospective cohort of 2,278 comatose
post-arrest patients, our model demonstrates robust discriminative performance
for the competing outcomes of awakening, withdrawal of life-sustaining therapy,
and death despite maximal support. Our approach generalizes to more than two
phases in which new features are collected and could be used in other dynamic
prediction tasks, where it may be helpful to know when and for whom newly
collected features significantly improve prediction.

</details>


### [191] [Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity](https://arxiv.org/abs/2508.06034)
*Qin Chen,Guojie Song*

Main category: cs.LG

TL;DR: 论文提出了一种自适应异构图神经网络（AHGNN），用于解决异构图中的异质性分布和语义多样性问题，并在高异质性场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常孤立地处理异质性或异质性，忽略了实际应用中异质性图的普遍性，导致性能下降。

Method: AHGNN采用异质性感知卷积和粗到细的注意力机制，分别处理异质性分布和语义多样性。

Result: 在七个真实世界图和二十个基线上的实验表明，AHGNN在高异质性情况下表现优越。

Conclusion: AHGNN通过结合异质性感知和语义多样性处理，显著提升了异构图建模的性能。

Abstract: Heterogeneous graphs (HGs) are common in real-world scenarios and often
exhibit heterophily. However, most existing studies focus on either
heterogeneity or heterophily in isolation, overlooking the prevalence of
heterophilic HGs in practical applications. Such ignorance leads to their
performance degradation. In this work, we first identify two main challenges in
modeling heterophily HGs: (1) varying heterophily distributions across hops and
meta-paths; (2) the intricate and often heterophily-driven diversity of
semantic information across different meta-paths. Then, we propose the Adaptive
Heterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN
employs a heterophily-aware convolution that accounts for heterophily
distributions specific to both hops and meta-paths. It then integrates messages
from diverse semantic spaces using a coarse-to-fine attention mechanism, which
filters out noise and emphasizes informative signals. Experiments on seven
real-world graphs and twenty baselines demonstrate the superior performance of
AHGNN, particularly in high-heterophily situations.

</details>


### [192] [DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment](https://arxiv.org/abs/2508.06041)
*Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park*

Main category: cs.LG

TL;DR: DP-LLM是一种动态分配精度的机制，通过运行时根据输入值调整每层的位宽，优化大型语言模型的性能和延迟。


<details>
  <summary>Details</summary>
Motivation: 解决在设备上运行大型语言模型时如何根据不同的运行时约束（如延迟和准确性）动态调整模型精度的问题。

Method: 利用多层敏感度动态变化的观察，为每层动态分配精度，并通过轻量级误差估计器和阈值学习实现。

Result: 实验表明，DP-LLM在性能和延迟的权衡上优于现有方法。

Conclusion: DP-LLM通过动态精度分配，为设备上的大型语言模型提供了高效的运行时适应性。

Abstract: How can we effectively handle queries for on-device large language models
(LLMs) with varying runtime constraints, such as latency and accuracy?
Multi-scale quantization addresses this challenge by enabling memory-efficient
runtime model adaptation of LLMs through the overlaying of multiple model
variants quantized to different bitwidths. Meanwhile, an important question
still remains open-ended: how can models be properly configured to match a
target precision or latency? While mixed-precision offers a promising solution,
we take this further by leveraging the key observation that the sensitivity of
each layer dynamically changes across decoding iterations. Building on this
insight, we introduce DP-LLM, a novel mechanism that dynamically assigns
precision to each layer based on input values. DP-LLM augments each linear
layer in an LLM with a precision selector that determines the bitwidth at
runtime using a lightweight error estimator and threshold values learned
through fine-tuning. Experimental results across multiple models and benchmarks
demonstrate that DP-LLM achieves a superior performance-latency trade-off,
outperforming prior approaches.

</details>


### [193] [Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology](https://arxiv.org/abs/2508.06066)
*Barak Gahtan,Alex M. Bronstein*

Main category: cs.LG

TL;DR: 该论文提出了针对深度时序模型（如TCNs）的非空泛、架构感知的泛化边界，并引入了一种公平比较的方法论。研究发现，时序依赖性可以在固定信息预算下增强学习效果，但理论与实际收敛速率存在差异。


<details>
  <summary>Details</summary>
Motivation: 现有研究对深度时序模型的泛化能力缺乏理论理解，尤其是针对依赖时序数据的模型。本文旨在填补这一空白，并提供更精确的泛化边界和评估方法。

Method: 论文通过延迟反馈阻断机制将依赖样本转化为近似独立的样本，推导出泛化边界，并提出一种固定有效样本量的公平比较方法。

Result: 研究发现，强依赖序列的泛化差距比弱依赖序列小76%，且收敛速率与理论预测不符（弱依赖为$N_{\text{eff}}^{-1.21}$，强依赖为$N_{\text{eff}}^{-0.89}$）。

Conclusion: 时序依赖性可以在固定信息预算下提升学习效果，但理论与实践的差距表明需要进一步研究。

Abstract: Deep temporal architectures such as Temporal Convolutional Networks (TCNs)
achieve strong predictive performance on sequential data, yet theoretical
understanding of their generalization remains limited. We address this gap by
providing both the first non-vacuous, architecture-aware generalization bounds
for deep temporal models and a principled evaluation methodology.
  For exponentially $\beta$-mixing sequences, we derive bounds scaling as $
O\!\Bigl(R\,\sqrt{\tfrac{D\,p\,n\,\log N}{N}}\Bigr), $ where $D$ is network
depth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our
delayed-feedback blocking mechanism transforms dependent samples into
effectively independent ones while discarding only $O(1/\log N)$ of the data,
yielding $\sqrt{D}$ scaling instead of exponential, implying that doubling
depth requires approximately quadrupling the training data.
  We also introduce a fair-comparison methodology that fixes the effective
sample size to isolate the effect of temporal structure from information
content. Under $N_{\text{eff}}=2{,}000$, strongly dependent sequences
($\rho=0.8$) exhibit $\approx76\%$ smaller generalization gaps than weakly
dependent ones ($\rho=0.2$), challenging the intuition that dependence is
purely detrimental. Yet convergence rates diverge from theory: weak
dependencies follow $N_{\text{eff}}^{-1.21}$ scaling and strong dependencies
follow $N_{\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$.
These findings reveal that temporal dependence can enhance learning under fixed
information budgets, while highlighting gaps between theory and practice that
motivate future research.

</details>


### [194] [Recurrent Deep Differentiable Logic Gate Networks](https://arxiv.org/abs/2508.06097)
*Simon Bührer,Andreas Plesner,Till Aczel,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 论文首次实现了循环深度可微分逻辑门网络（RDDLGN），将布尔运算与循环架构结合用于序列到序列学习。


<details>
  <summary>Details</summary>
Motivation: 探索可微分逻辑门在序列建模中的应用，填补该领域的研究空白。

Method: 提出RDDLGN，结合布尔运算与循环架构，用于序列到序列学习任务。

Result: 在WMT'14英德翻译任务中，RDDLGN达到5.00 BLEU和30.9%训练准确率，接近GRU性能（5.41 BLEU）。

Conclusion: 该工作证明了基于循环逻辑的神经计算的可行性，为FPGA加速等研究方向开辟了道路。

Abstract: While differentiable logic gates have shown promise in feedforward networks,
their application to sequential modeling remains unexplored. This paper
presents the first implementation of Recurrent Deep Differentiable Logic Gate
Networks (RDDLGN), combining Boolean operations with recurrent architectures
for sequence-to-sequence learning.
  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and
30.9\% accuracy during training, approaching GRU performance (5.41 BLEU) and
graceful degradation (4.39 BLEU) during inference. This work establishes
recurrent logic-based neural computation as viable, opening research directions
for FPGA acceleration in sequential modeling and other recursive network
architectures.

</details>


### [195] [GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2508.06108)
*Xing Lei,Wenyan Yang,Kaiqiang Ke,Shentao Yang,Xuetao Zhang,Joni Pajarinen,Donglin Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为Hindsight Goal-conditioned Regularization (HGR)的技术，结合Hindsight Self-imitation Regularization (HSR)，显著提高了目标条件强化学习（GCRL）的样本效率。


<details>
  <summary>Details</summary>
Motivation: 稀疏奖励下的目标条件强化学习（GCRL）仍是一个挑战。尽管HER通过重标定轨迹取得了一定进展，但仅依赖轨迹重标定未能充分利用经验，导致样本效率有限。

Method: 提出HGR技术，基于后见目标生成动作正则化先验，结合HSR，最大化经验利用率。

Result: 在导航和操作任务中，HGR和HSR的组合显著优于现有方法，实现了更高的样本重用效率和最佳性能。

Conclusion: HGR和HSR的结合为GCRL提供了一种高效的样本利用方法，显著提升了性能。

Abstract: Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a
fundamental challenge in reinforcement learning. While hindsight experience
replay (HER) has shown promise by relabeling collected trajectories with
achieved goals, we argue that trajectory relabeling alone does not fully
exploit the available experiences in off-policy GCRL methods, resulting in
limited sample efficiency. In this paper, we propose Hindsight Goal-conditioned
Regularization (HGR), a technique that generates action regularization priors
based on hindsight goals. When combined with hindsight self-imitation
regularization (HSR), our approach enables off-policy RL algorithms to maximize
experience utilization. Compared to existing GCRL methods that employ HER and
self-imitation techniques, our hindsight regularizations achieve substantially
more efficient sample reuse and the best performances, which we empirically
demonstrate on a suite of navigation and manipulation tasks.

</details>


### [196] [Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models](https://arxiv.org/abs/2508.06151)
*Yong Oh Lee,JeeEun Kim,Jung Woo Lee*

Main category: cs.LG

TL;DR: 该研究提出了一种通过扩散模型生成合成口腔癌病变图像的方法，以提高诊断模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 口腔癌诊断中，标注数据集的稀缺限制了模型性能，因此需要一种方法增强训练数据的多样性和数量。

Method: 使用微调的扩散模型和修复技术合成逼真的口腔癌病变图像，并结合多源数据集。

Result: 分类模型诊断准确率达0.97，检测模型定位准确率为0.85。

Conclusion: 合成图像生成在医学诊断中具有潜力，可推广至其他癌症诊断领域。

Abstract: In oral cancer diagnostics, the limited availability of annotated datasets
frequently constrains the performance of diagnostic models, particularly due to
the variability and insufficiency of training data. To address these
challenges, this study proposed a novel approach to enhance diagnostic accuracy
by synthesizing realistic oral cancer lesions using an inpainting technique
with a fine-tuned diffusion model. We compiled a comprehensive dataset from
multiple sources, featuring a variety of oral cancer images. Our method
generated synthetic lesions that exhibit a high degree of visual fidelity to
actual lesions, thereby significantly enhancing the performance of diagnostic
algorithms. The results show that our classification model achieved a
diagnostic accuracy of 0.97 in differentiating between cancerous and
non-cancerous tissues, while our detection model accurately identified lesion
locations with 0.85 accuracy. This method validates the potential for synthetic
image generation in medical diagnostics and paves the way for further research
into extending these methods to other types of cancer diagnostics.

</details>


### [197] [Differentially Private Federated Clustering with Random Rebalancing](https://arxiv.org/abs/2508.06183)
*Xiyuan Yang,Shengyuan Hu,Soyeon Kim,Tian Li*

Main category: cs.LG

TL;DR: 联邦聚类通过将相似客户端分组并为每个集群生成一个模型，提高性能但可能增加隐私泄露风险。RR-Cluster是一种轻量级技术，通过随机重新平衡集群分配减少隐私噪声，显著改善隐私/效用权衡。


<details>
  <summary>Details</summary>
Motivation: 联邦聚类能提升模型性能，但直接应用差分隐私机制会显著降低效用，主要原因是集群内客户端数量不可控导致隐私噪声难以平均。

Method: 提出RR-Cluster技术，通过随机重新平衡集群分配，确保每个集群有最小客户端数量，从而减少隐私噪声。

Result: 理论分析表明RR-Cluster降低了隐私噪声方差，实验证明其在合成和真实数据集上显著改善了隐私/效用权衡。

Conclusion: RR-Cluster是一种简单有效的技术，可显著提升联邦聚类算法的隐私保护能力，同时保持模型性能。

Abstract: Federated clustering aims to group similar clients into clusters and produce
one model for each cluster. Such a personalization approach typically improves
model performance compared with training a single model to serve all clients,
but can be more vulnerable to privacy leakage. Directly applying client-level
differentially private (DP) mechanisms to federated clustering could degrade
the utilities significantly. We identify that such deficiencies are mainly due
to the difficulties of averaging privacy noise within each cluster (following
standard privacy mechanisms), as the number of clients assigned to the same
clusters is uncontrolled. To this end, we propose a simple and effective
technique, named RR-Cluster, that can be viewed as a light-weight add-on to
many federated clustering algorithms. RR-Cluster achieves reduced privacy noise
via randomly rebalancing cluster assignments, guaranteeing a minimum number of
clients assigned to each cluster. We analyze the tradeoffs between decreased
privacy noise variance and potentially increased bias from incorrect
assignments and provide convergence bounds for RR-Clsuter. Empirically, we
demonstrate the RR-Cluster plugged into strong federated clustering algorithms
results in significantly improved privacy/utility tradeoffs across both
synthetic and real-world datasets.

</details>


### [198] [Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning](https://arxiv.org/abs/2508.06199)
*Mateusz Praski,Jakub Adamczyk,Wojciech Czech*

Main category: cs.LG

TL;DR: 该研究对25种预训练神经网络模型在25个数据集上进行了全面比较，发现大多数模型在分子指纹基准（ECFP）上表现无显著提升，仅CLAMP模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 评估预训练神经网络在化学和小分子药物设计中的实际效果，揭示现有研究的评估严谨性问题。

Method: 采用公平比较框架，评估多种模态、架构和预训练策略的模型，并使用层次贝叶斯统计测试模型进行分析。

Result: 几乎所有神经网络模型在ECFP基准上无显著改进，仅CLAMP模型表现显著优于其他模型。

Conclusion: 研究揭示了现有评估的不足，提出了改进建议，并呼吁更严谨的模型评估方法。

Abstract: Pretrained neural networks have attracted significant interest in chemistry
and small molecule drug design. Embeddings from these models are widely used
for molecular property prediction, virtual screening, and small data learning
in molecular chemistry. This study presents the most extensive comparison of
such models to date, evaluating 25 models across 25 datasets. Under a fair
comparison framework, we assess models spanning various modalities,
architectures, and pretraining strategies. Using a dedicated hierarchical
Bayesian statistical testing model, we arrive at a surprising result: nearly
all neural models show negligible or no improvement over the baseline ECFP
molecular fingerprint. Only the CLAMP model, which is also based on molecular
fingerprints, performs statistically significantly better than the
alternatives. These findings raise concerns about the evaluation rigor in
existing studies. We discuss potential causes, propose solutions, and offer
practical recommendations.

</details>


### [199] [Graph Federated Learning for Personalized Privacy Recommendation](https://arxiv.org/abs/2508.06208)
*Ce Na,Kai Yang,Dengzhao Fang,Yu Li,Jingtong Gao,Chengcheng Zhu,Jiale Zhang,Xiaobing Sun,Yi Chang*

Main category: cs.LG

TL;DR: 论文提出了一种名为GFed-PP的图联邦学习方法，用于个性化隐私推荐，适应不同隐私需求并提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐系统假设所有用户对隐私保护需求相同，忽略了利用公开用户数据提升服务的潜力。

Method: GFed-PP结合公开用户数据构建用户-物品交互图，使用轻量级GCN学习个性化物品嵌入，并在客户端本地学习用户嵌入和评分函数以保护隐私。

Result: 实验结果表明，GFed-PP在五个数据集上显著优于现有方法，推荐准确性更高且不损害隐私。

Conclusion: GFed-PP为联邦推荐系统中适应不同隐私偏好提供了实用解决方案。

Abstract: Federated recommendation systems (FedRecs) have gained significant attention
for providing privacy-preserving recommendation services. However, existing
FedRecs assume that all users have the same requirements for privacy
protection, i.e., they do not upload any data to the server. The approaches
overlook the potential to enhance the recommendation service by utilizing
publicly available user data. In real-world applications, users can choose to
be private or public. Private users' interaction data is not shared, while
public users' interaction data can be shared. Inspired by the issue, this paper
proposes a novel Graph Federated Learning for Personalized Privacy
Recommendation (GFed-PP) that adapts to different privacy requirements while
improving recommendation performance. GFed-PP incorporates the interaction data
of public users to build a user-item interaction graph, which is then used to
form a user relationship graph. A lightweight graph convolutional network (GCN)
is employed to learn each user's user-specific personalized item embedding. To
protect user privacy, each client learns the user embedding and the scoring
function locally. Additionally, GFed-PP achieves optimization of the federated
recommendation framework through the initialization of item embedding on
clients and the aggregation of the user relationship graph on the server.
Experimental results demonstrate that GFed-PP significantly outperforms
existing methods for five datasets, offering superior recommendation accuracy
without compromising privacy. This framework provides a practical solution for
accommodating varying privacy preferences in federated recommendation systems.

</details>


### [200] [Reparameterization Proximal Policy Optimization](https://arxiv.org/abs/2508.06214)
*Hai Zhong,Xun Wang,Zhuoran Li,Longbo Huang*

Main category: cs.LG

TL;DR: 论文提出了一种稳定的重参数化策略梯度方法RPO，结合了PPO的稳定性和RPG的样本效率。


<details>
  <summary>Details</summary>
Motivation: 重参数化策略梯度（RPG）虽能提高样本效率，但训练不稳定，高方差梯度会破坏学习过程。

Method: 通过将PPO的代理目标与RPG结合，提出RPO方法，利用时间反向传播高效计算梯度，并通过KL散度正则化稳定训练。

Result: 在运动和操作任务中，RPO表现出优异的样本效率和性能。

Conclusion: RPO是一种稳定且高效的RPG方法，适用于复杂任务。

Abstract: Reparameterization policy gradient (RPG) is promising for improving sample
efficiency by leveraging differentiable dynamics. However, a critical barrier
is its training instability, where high-variance gradients can destabilize the
learning process. To address this, we draw inspiration from Proximal Policy
Optimization (PPO), which uses a surrogate objective to enable stable sample
reuse in the model-free setting. We first establish a connection between this
surrogate objective and RPG, which has been largely unexplored and is
non-trivial. Then, we bridge this gap by demonstrating that the
reparameterization gradient of a PPO-like surrogate objective can be computed
efficiently using backpropagation through time. Based on this key insight, we
propose Reparameterization Proximal Policy Optimization (RPO), a stable and
sample-efficient RPG-based method. RPO enables multiple epochs of stable sample
reuse by optimizing a clipped surrogate objective tailored for RPG, while being
further stabilized by Kullback-Leibler (KL) divergence regularization and
remaining fully compatible with existing variance reduction methods. We
evaluate RPO on a suite of challenging locomotion and manipulation tasks, where
experiments demonstrate that our method achieves superior sample efficiency and
strong performance.

</details>


### [201] [SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems](https://arxiv.org/abs/2508.06243)
*Ioan-Sorin Comsa,Purav Shah,Karthik Vaidhyanathan,Deepak Gangadharan,Christof Imhof,Per Bergamin,Aryan Kaushik,Gabriel-Miro Muntean,Ramona Trestian*

Main category: cs.LG

TL;DR: SCAR是一种基于边缘AI的框架，通过ML压缩技术优化6G车载娱乐资源管理，提升调度公平性和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 传统RRM技术难以处理车载环境中复杂的数据（如CQI），需要更高效的资源管理方法。

Method: SCAR采用ML压缩技术（如聚类和RBF网络）减少CQI数据量，结合6G强化学习策略优化调度。

Result: SCAR将可行调度区域时间提升14%，不公平调度时间减少15%，CQI聚类失真降低10%。

Conclusion: SCAR在动态车载网络中展现出良好的可扩展性和公平性优势。

Abstract: The advent of 6G networks opens new possibilities for connected infotainment
services in vehicular environments. However, traditional Radio Resource
Management (RRM) techniques struggle with the increasing volume and complexity
of data such as Channel Quality Indicators (CQI) from autonomous vehicles. To
address this, we propose SCAR (State-Space Compression for AI-Driven Resource
Management), an Edge AI-assisted framework that optimizes scheduling and
fairness in vehicular infotainment. SCAR employs ML-based compression
techniques (e.g., clustering and RBF networks) to reduce CQI data size while
preserving essential features. These compressed states are used to train
6G-enabled Reinforcement Learning policies that maximize throughput while
meeting fairness objectives defined by the NGMN. Simulations show that SCAR
increases time in feasible scheduling regions by 14\% and reduces unfair
scheduling time by 15\% compared to RL baselines without CQI compression.
Furthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based
clustering reduces CQI clustering distortion by 10\%, confirming its
efficiency. These results demonstrate SCAR's scalability and fairness benefits
for dynamic vehicular networks.

</details>


### [202] [Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient](https://arxiv.org/abs/2304.04475)
*Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 论文提出了一种基于DDPG的策略优化框架，用于在大规模流行病模拟中自动确定最优干预措施，平衡健康与经济目标。


<details>
  <summary>Details</summary>
Motivation: 当前研究在模拟目标、规模和干预策略探索方面存在局限，无法有效确定最优干预措施。

Method: 使用DDPG框架在大规模（10万个体）流行病模拟中进行多目标优化，研究封锁和疫苗接种策略。

Result: 无封锁且针对中老年人群接种疫苗的策略在平衡健康目标（感染和住院）的同时优化了经济。

Conclusion: 需进一步验证结果并开源框架，以支持更深入的研究。

Abstract: To mitigate the impact of the pandemic, several measures include lockdowns,
rapid vaccination programs, school closures, and economic stimulus. These
interventions can have positive or unintended negative consequences. Current
research to model and determine an optimal intervention automatically through
round-tripping is limited by the simulation objectives, scale (a few thousand
individuals), model types that are not suited for intervention studies, and the
number of intervention strategies they can explore (discrete vs continuous). We
address these challenges using a Deep Deterministic Policy Gradient (DDPG)
based policy optimization framework on a large-scale (100,000 individual)
epidemiological agent-based simulation where we perform multi-objective
optimization. We determine the optimal policy for lockdown and vaccination in a
minimalist age-stratified multi-vaccine scenario with a basic simulation for
economic activity. With no lockdown and vaccination (mid-age and elderly),
results show optimal economy (individuals below the poverty line) with balanced
health objectives (infection, and hospitalization). An in-depth simulation is
needed to further validate our results and open-source our framework.

</details>


### [203] [Membership Inference Attack with Partial Features](https://arxiv.org/abs/2508.06244)
*Xurun Wang,Guangrui Liu,Xinjie Li,Haoyu He,Lin Yao,Weizhe Zhang*

Main category: cs.LG

TL;DR: 论文研究了部分特征成员推理攻击（PFMI），提出了一种两阶段攻击框架MRAD，通过优化缺失特征值和异常检测实现攻击，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有成员推理攻击方法假设攻击者能获取目标样本的全部特征，但现实中往往只能获取部分特征，限制了方法的适用性。

Method: 提出MRAD框架，第一阶段优化缺失特征值以最小化样本损失，第二阶段通过异常检测衡量重构样本与训练分布的偏差。

Result: 实验表明MRAD在多种数据集上有效，例如在STL-10上即使缺失40%特征，AUC仍可达0.6。

Conclusion: MRAD解决了部分特征下的成员推理问题，兼容多种异常检测技术，具有实际应用价值。

Abstract: Machine learning models have been shown to be susceptible to membership
inference attack, which can be used to determine whether a given sample appears
in the training data. Existing membership inference methods commonly assume
that the adversary has full access to the features of the target sample. This
assumption, however, does not hold in many real-world scenarios where only
partial features information is available, thereby limiting the applicability
of these methods. In this work, we study an inference scenario where the
adversary observes only partial features of each sample and aims to infer
whether this observed subset was present in the training set of the target
model. We define this problem as Partial Feature Membership Inference (PFMI).
To address this problem, we propose MRAD (Memory-guided Reconstruction and
Anomaly Detection), a two-stage attack framework. In the first stage, MRAD
optimizes the unknown feature values to minimize the loss of the sample. In the
second stage, it measures the deviation between the reconstructed sample and
the training distribution using anomaly detection. Empirical results
demonstrate that MRAD is effective across a range of datasets, and maintains
compatibility with various off-the-shelf anomaly detection techniques. For
example, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of
the missing features.

</details>


### [204] [Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits](https://arxiv.org/abs/2508.06247)
*Zichun Ye,Runqi Wang,Xutong Liu,Shuai Li*

Main category: cs.LG

TL;DR: CMOSS是一种高效的组合多臂老虎机算法，消除了对log T的依赖，并在半带反馈下实现了实例无关的遗憾上界。


<details>
  <summary>Details</summary>
Motivation: 解决现有UCB和对抗性方法在长期视野下性能不足或计算开销大的问题。

Method: 提出CMOSS算法，结合半带反馈和级联反馈，实现计算高效和低遗憾。

Result: CMOSS在半带反馈下实现了O((log k)^2√kmT)的遗憾上界，并在实验中优于基准算法。

Conclusion: CMOSS在理论和实验上均表现出色，解决了现有方法的局限性。

Abstract: The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential
decision-making framework, dominated by two algorithmic families: UCB-based and
adversarial methods such as follow the regularized leader (FTRL) and online
mirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer
from additional regret factor $\log T$ that is detrimental over long horizons,
while adversarial methods such as EXP3.M and HYBRID impose significant
computational overhead. To resolve this trade-off, we introduce the
Combinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS
is a computationally efficient algorithm that achieves an instance-independent
regret of $O\big( (\log k)^2\sqrt{kmT}\big )$ under semi-bandit feedback, where
$m$ is the number of arms and $k$ is the maximum cardinality of a feasible
action. Crucially, this result eliminates the dependency on $\log T$ and
matches the established $\Omega\big( \sqrt{kmT}\big)$ lower bound up to
$O\big((\log k)^2\big)$. We then extend our analysis to show that CMOSS is also
applicable to cascading feedback. Experiments on synthetic and real-world
datasets validate that CMOSS consistently outperforms benchmark algorithms in
both regret and runtime efficiency.

</details>


### [205] [In-Training Defenses against Emergent Misalignment in Language Models](https://arxiv.org/abs/2508.06249)
*David Kaczér,Magnus Jørgenvåg,Clemens Vetter,Lucie Flek,Florian Mai*

Main category: cs.LG

TL;DR: 论文研究了微调大型语言模型（LLMs）时可能引发的突发性不对齐（EMA）问题，并提出了四种训练正则化干预方法以减少EMA。


<details>
  <summary>Details</summary>
Motivation: 微调LLMs可能导致模型在目标领域外表现有害行为，即使微调数据本身无害。研究旨在为API提供者提供实用的防护措施。

Method: 研究了四种干预方法：KL散度正则化、特征空间L2距离、安全子空间投影（SafeLoRA）和安全训练示例的穿插。

Result: 评估了这些方法在四个恶意任务中的EMA抑制效果，并分析了其对良性任务的影响。

Conclusion: 讨论了突发性不对齐研究的开放性问题，为未来研究提供了方向。

Abstract: Fine-tuning lets practitioners repurpose aligned large language models (LLMs)
for new domains, yet recent work reveals emergent misalignment (EMA): Even a
small, domain-specific fine-tune can induce harmful behaviors far outside the
target domain. Even in the case where model weights are hidden behind a
fine-tuning API, this gives attackers inadvertent access to a broadly
misaligned model in a way that can be hard to detect from the fine-tuning data
alone. We present the first systematic study of in-training safeguards against
EMA that are practical for providers who expose fine-tuning via an API. We
investigate four training regularization interventions: (i) KL-divergence
regularization toward a safe reference model, (ii) $\ell_2$ distance in feature
space, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving
of a small amount of safe training examples from a general instruct-tuning
dataset. We first evaluate the methods' emergent misalignment effect across
four malicious, EMA-inducing tasks. Second, we assess the methods' impacts on
benign tasks. We conclude with a discussion of open questions in emergent
misalignment research.

</details>


### [206] [Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)](https://arxiv.org/abs/2508.06251)
*Alejandro Moreno R.,Desale Fentaw,Samuel Palmer,Raúl Salles de Padua,Ninad Dixit,Samuel Mugel,Roman Orús,Manuel Radons,Josef Menter,Ali Abedi*

Main category: cs.LG

TL;DR: 提出了一种基于张量网络（矩阵乘积态，MPS）的隐私保护高质量合成表格数据生成方法，在数据保真度和隐私保护能力上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺、隐私约束和多样化数据集需求的问题，同时确保数据的高质量和隐私保护。

Method: 使用MPS生成模型，结合噪声注入和梯度裁剪实现差分隐私（DP），并通过Rényi差分隐私核算提供隐私保证。

Result: MPS在数据保真度和下游任务性能上优于CTGAN、VAE和PrivBayes等模型，尤其在严格隐私约束下表现突出。

Conclusion: MPS是一种有前景的隐私感知合成数据生成工具，结合张量网络的表达能力和隐私机制，为安全数据共享提供了可解释且可扩展的解决方案。

Abstract: Synthetic data generation is a key technique in modern artificial
intelligence, addressing data scarcity, privacy constraints, and the need for
diverse datasets in training robust models. In this work, we propose a method
for generating privacy-preserving high-quality synthetic tabular data using
Tensor Networks, specifically Matrix Product States (MPS). We benchmark the
MPS-based generative model against state-of-the-art models such as CTGAN, VAE,
and PrivBayes, focusing on both fidelity and privacy-preserving capabilities.
To ensure differential privacy (DP), we integrate noise injection and gradient
clipping during training, enabling privacy guarantees via R\'enyi Differential
Privacy accounting. Across multiple metrics analyzing data fidelity and
downstream machine learning task performance, our results show that MPS
outperforms classical models, particularly under strict privacy constraints.
This work highlights MPS as a promising tool for privacy-aware synthetic data
generation. By combining the expressive power of tensor network representations
with formal privacy mechanisms, the proposed approach offers an interpretable
and scalable alternative for secure data sharing. Its structured design
facilitates integration into sensitive domains where both data quality and
confidentiality are critical.

</details>


### [207] [Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors](https://arxiv.org/abs/2508.06257)
*Jielong Lu,Zhihao Wu,Jiajun Yu,Jiajun Bu,Haishuai Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为GTMancer的框架，通过图神经网络和对比学习整合多组学数据，用于癌症亚型分类，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多组学数据整合中忽略了异质性组学间的复杂耦合，限制了其在癌症亚型分类中的表现。

Method: GTMancer利用对比学习将多组学数据嵌入统一语义空间，并通过双重注意力系数捕捉组学内和组学间的结构图先验。

Result: 在七个真实癌症数据集上的实验表明，GTMancer优于现有最先进算法。

Conclusion: GTMancer为多组学数据整合和癌症亚型分类提供了有效解决方案。

Abstract: Integrating multi-omics datasets through data-driven analysis offers a
comprehensive understanding of the complex biological processes underlying
various diseases, particularly cancer. Graph Neural Networks (GNNs) have
recently demonstrated remarkable ability to exploit relational structures in
biological data, enabling advances in multi-omics integration for cancer
subtype classification. Existing approaches often neglect the intricate
coupling between heterogeneous omics, limiting their capacity to resolve subtle
cancer subtype heterogeneity critical for precision oncology. To address these
limitations, we propose a framework named Graph Transformer for Multi-omics
Cancer Subtype Classification (GTMancer). This framework builds upon the GNN
optimization problem and extends its application to complex multi-omics data.
Specifically, our method leverages contrastive learning to embed multi-omics
data into a unified semantic space. We unroll the multiplex graph optimization
problem in that unified space and introduce dual sets of attention coefficients
to capture structural graph priors both within and among multi-omics data. This
approach enables global omics information to guide the refining of the
representations of individual omics. Empirical experiments on seven real-world
cancer datasets demonstrate that GTMancer outperforms existing state-of-the-art
algorithms.

</details>


### [208] [OM2P: Offline Multi-Agent Mean-Flow Policy](https://arxiv.org/abs/2508.06269)
*Zhuoran Li,Xun Wang,Hai Zhong,Longbo Huang*

Main category: cs.LG

TL;DR: OM2P是一种新型离线多智能体强化学习算法，通过一步动作采样提高效率，解决了扩散和流模型采样效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 扩散和流模型在多智能体强化学习中采样效率低，难以应用于时间敏感或资源受限的场景。

Method: 提出OM2P算法，结合奖励感知优化方案、均值流匹配损失和Q函数监督，设计了广义时间步分布和无导数估计策略。

Result: 在Multi-Agent Particle和MuJoCo基准测试中，OM2P性能优越，GPU内存使用减少3.8倍，训练速度提升10.8倍。

Conclusion: OM2P首次成功将均值流模型集成到离线多智能体强化学习中，为实用和可扩展的生成策略铺平了道路。

Abstract: Generative models, especially diffusion and flow-based models, have been
promising in offline multi-agent reinforcement learning. However, integrating
powerful generative models into this framework poses unique challenges. In
particular, diffusion and flow-based policies suffer from low sampling
efficiency due to their iterative generation processes, making them impractical
in time-sensitive or resource-constrained settings. To tackle these
difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel
offline MARL algorithm to achieve efficient one-step action sampling. To
address the misalignment between generative objectives and reward maximization,
we introduce a reward-aware optimization scheme that integrates a
carefully-designed mean-flow matching loss with Q-function supervision.
Additionally, we design a generalized timestep distribution and a
derivative-free estimation strategy to reduce memory overhead and improve
training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo
benchmarks demonstrate that OM2P achieves superior performance, with up to a
3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time.
Our approach represents the first to successfully integrate mean-flow model
into offline MARL, paving the way for practical and scalable generative
policies in cooperative multi-agent settings.

</details>


### [209] [A Study on Regularization-Based Continual Learning Methods for Indic ASR](https://arxiv.org/abs/2508.06280)
*Gokul Adethya T,S. Jaya Nirmala*

Main category: cs.LG

TL;DR: 论文研究了在印度语言多样性背景下，通过持续学习（CL）方法开发包容性自动语音识别（ASR）系统的有效性。


<details>
  <summary>Details</summary>
Motivation: 印度语言多样性为ASR系统开发带来挑战，传统多语言模型因数据顺序到达和隐私限制不适用，CL提供了一种解决方案。

Method: 使用基于Conformer的混合RNN-T/CTC模型，从印地语预训练开始，逐步学习八种印度语言，评估了三种CL策略（EWC、MAS、LwF）。

Result: 与简单微调相比，CL方法有效减轻了遗忘问题，在干净和噪声数据上均表现良好。

Conclusion: CL是一种在现实约束下扩展印度语言ASR系统的有前景方法。

Abstract: Indias linguistic diversity poses significant challenges for developing
inclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual
models, which require simultaneous access to all language data, are impractical
due to the sequential arrival of data and privacy constraints. Continual
Learning (CL) offers a solution by enabling models to learn new languages
sequentially without catastrophically forgetting previously learned knowledge.
This paper investigates CL for ASR on Indian languages using a subset of the
IndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model,
initially pretrained on Hindi, which is then incrementally trained on eight
additional Indian languages, for a total sequence of nine languages. We
evaluate three prominent regularization- and distillation-based CL strategies:
Elastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning
without Forgetting (LwF), selected for their suitability in no-replay,
privacy-conscious scenarios. Performance is analyzed using Word Error Rate
(WER) for both RNN-T and CTC paths on clean and noisy data, as well as
knowledge retention via Backward Transfer. We also explore the impact of
varying the number of training epochs (1, 2, 5, and 10) per task. Results,
compared against naive fine-tuning, demonstrate CLs effectiveness in mitigating
forgetting, making it a promising approach for scalable ASR in diverse Indian
languages under realistic constraints. The code is available at:
https://github.com/FrozenWolf-Cyber/Indic-CL-ASR

</details>


### [210] [Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback](https://arxiv.org/abs/2508.06292)
*Sanja Karilanova,Subhrakanti Dey,Ayça Özçelikkale*

Main category: cs.LG

TL;DR: 论文提出了一种新型多输出脉冲神经元模型，结合了线性状态转移和非线性反馈机制，提升了SNN的性能。


<details>
  <summary>Details</summary>
Motivation: 结合SNN的低延迟、高效能与深度SSM的高性能，解决现有模型在稳定性和学习能力上的限制。

Method: 设计了一种多输出脉冲神经元模型，明确区分脉冲功能、重置条件和重置动作，并引入非线性反馈机制。

Result: 在多个任务（如关键词识别、事件视觉任务等）中表现优异，性能与现有SNN基准相当。

Conclusion: 提出的重置机制克服了不稳定性，扩展了线性动态的严格稳定性限制，为SNN和深度SSM的结合提供了新思路。

Abstract: Neuromorphic computing is an emerging technology enabling low-latency and
energy-efficient signal processing. A key algorithmic tool in neuromorphic
computing is spiking neural networks (SNNs). SNNs are biologically inspired
neural networks which utilize stateful neurons, and provide low-bit data
processing by encoding and decoding information using spikes. Similar to SNNs,
deep state-space models (SSMs) utilize stateful building blocks. However, deep
SSMs, which recently achieved competitive performance in various temporal
modeling tasks, are typically designed with high-precision activation functions
and no reset mechanisms. To bridge the gains offered by SNNs and the recent
deep SSM models, we propose a novel multiple-output spiking neuron model that
combines a linear, general SSM state transition with a non-linear feedback
mechanism through reset. Compared to the existing neuron models for SNNs, our
proposed model clearly conceptualizes the differences between the spiking
function, the reset condition and the reset action. The experimental results on
various tasks, i.e., a keyword spotting task, an event-based vision task and a
sequential pattern recognition task, show that our proposed model achieves
performance comparable to existing benchmarks in the SNN literature. Our
results illustrate how the proposed reset mechanism can overcome instability
and enable learning even when the linear part of neuron dynamics is unstable,
allowing us to go beyond the strictly enforced stability of linear dynamics in
recent deep SSM models.

</details>


### [211] [FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields](https://arxiv.org/abs/2508.06301)
*Junhyeog Yun,Minui Hong,Gunhee Kim*

Main category: cs.LG

TL;DR: FedMeNF是一种新型的联邦元学习方法，通过隐私保护损失函数解决传统FML的隐私泄露问题，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 神经场学习需要大量数据和计算资源，传统FML方法存在隐私泄露问题。

Method: 提出FedMeNF方法，采用隐私保护损失函数进行本地元优化。

Result: 实验表明FedMeNF在少样本和非IID数据下仍能快速优化并保持隐私。

Conclusion: FedMeNF在高效学习和隐私保护方面表现出色。

Abstract: Neural fields provide a memory-efficient representation of data, which can
effectively handle diverse modalities and large-scale data. However, learning
to map neural fields often requires large amounts of training data and
computations, which can be limited to resource-constrained edge devices. One
approach to tackle this limitation is to leverage Federated Meta-Learning
(FML), but traditional FML approaches suffer from privacy leakage. To address
these issues, we introduce a novel FML approach called FedMeNF. FedMeNF
utilizes a new privacy-preserving loss function that regulates privacy leakage
in the local meta-optimization. This enables the local meta-learner to optimize
quickly and efficiently without retaining the client's private data. Our
experiments demonstrate that FedMeNF achieves fast optimization speed and
robust reconstruction performance, even with few-shot or non-IID data across
diverse data modalities, while preserving client data privacy.

</details>


### [212] [Unsupervised Partner Design Enables Robust Ad-hoc Teamwork](https://arxiv.org/abs/2508.06336)
*Constantin Ruhdorfer,Matteo Bortoletto,Victor Oei,Anna Penzkofer,Andreas Bulling*

Main category: cs.LG

TL;DR: UPD是一种无监督的伙伴设计框架，通过动态生成多样化的训练伙伴，提升多智能体强化学习的鲁棒性，无需预训练伙伴或手动调参。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法中需要预训练伙伴或手动调参的问题，提出一种完全无监督的伙伴设计框架。

Method: 通过随机混合自我策略与偏置随机行为生成多样化伙伴，并使用基于方差的易学性指标评分。

Result: 在Overcooked-AI等实验中，UPD显著优于基线方法，用户研究显示其更适应、更人性化。

Conclusion: UPD为完全无监督的伙伴和关卡分布课程设计提供了有效解决方案。

Abstract: We introduce Unsupervised Partner Design (UPD) - a population-free,
multi-agent reinforcement learning framework for robust ad-hoc teamwork that
adaptively generates training partners without requiring pretrained partners or
manual parameter tuning. UPD constructs diverse partners by stochastically
mixing an ego agent's policy with biased random behaviours and scores them
using a variance-based learnability metric that prioritises partners near the
ego agent's current learning frontier. We show that UPD can be integrated with
unsupervised environment design, resulting in the first method enabling fully
unsupervised curricula over both level and partner distributions in a
cooperative setting. Through extensive evaluations on Overcooked-AI and the
Overcooked Generalisation Challenge, we demonstrate that this dynamic partner
curriculum is highly effective: UPD consistently outperforms both
population-based and population-free baselines as well as ablations. In a user
study, we further show that UPD achieves higher returns than all baselines and
was perceived as significantly more adaptive, more human-like, a better
collaborator, and less frustrating.

</details>


### [213] [Introducing Fractional Classification Loss for Robust Learning with Noisy Labels](https://arxiv.org/abs/2508.06346)
*Mert Can Kurucu,Tufan Kumbasar,İbrahim Eksin,Müjde Güzelkaya*

Main category: cs.LG

TL;DR: 论文提出了一种自适应鲁棒损失函数FCL，通过分数阶导数和MAE结合，动态调整对标签噪声的鲁棒性，无需手动调参。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒损失函数需要大量数据集特定的超参数调整，限制了其实际应用。

Method: FCL结合了分数阶导数的交叉熵损失（主动部分）和MAE（被动部分），并通过学习参数μ动态调整鲁棒性与收敛速度的平衡。

Result: FCL在基准数据集上实现了最先进的性能，无需手动调参。

Conclusion: FCL通过动态调整损失函数，有效解决了标签噪声下的分类问题。

Abstract: Robust loss functions are crucial for training deep neural networks in the
presence of label noise, yet existing approaches require extensive,
dataset-specific hyperparameter tuning. In this work, we introduce Fractional
Classification Loss (FCL), an adaptive robust loss that automatically
calibrates its robustness to label noise during training. Built within the
active-passive loss framework, FCL employs the fractional derivative of the
Cross-Entropy (CE) loss as its active component and the Mean Absolute Error
(MAE) as its passive loss component. With this formulation, we demonstrate that
the fractional derivative order $\mu$ spans a family of loss functions that
interpolate between MAE-like robustness and CE-like fast convergence.
Furthermore, we integrate $\mu$ into the gradient-based optimization as a
learnable parameter and automatically adjust it to optimize the trade-off
between robustness and convergence speed. We reveal that FCL's unique property
establishes a critical trade-off that enables the stable learning of $\mu$:
lower log penalties on difficult or mislabeled examples improve robustness but
impose higher penalties on easy or clean data, reducing model confidence in
them. Consequently, FCL can dynamically reshape its loss landscape to achieve
effective classification performance under label noise. Extensive experiments
on benchmark datasets show that FCL achieves state-of-the-art results without
the need for manual hyperparameter tuning.

</details>


### [214] [Structural Equation-VAE: Disentangled Latent Representations for Tabular Data](https://arxiv.org/abs/2508.06347)
*Ruiyu Zhang,Ce Zhao,Xin Zhao,Lin Nie,Wai-Fung Lam*

Main category: cs.LG

TL;DR: SE-VAE是一种新型变分自编码器，通过结构方程建模嵌入测量结构，实现可解释的潜在表示学习。


<details>
  <summary>Details</summary>
Motivation: 解决表格数据中潜在表示学习难以解释的问题，提出一种模块化架构。

Method: SE-VAE通过设计潜在子空间与已知指标分组对齐，并引入全局干扰潜在变量来隔离特定构造的混杂变异。

Result: 在模拟表格数据集上，SE-VAE在因子恢复、可解释性和对干扰变异的鲁棒性上优于基线模型。

Conclusion: SE-VAE为理论驱动的科学和社会领域提供了一种白盒生成建模框架。

Abstract: Learning interpretable latent representations from tabular data remains a
challenge in deep generative modeling. We introduce SE-VAE (Structural
Equation-Variational Autoencoder), a novel architecture that embeds measurement
structure directly into the design of a variational autoencoder. Inspired by
structural equation modeling, SE-VAE aligns latent subspaces with known
indicator groupings and introduces a global nuisance latent to isolate
construct-specific confounding variation. This modular architecture enables
disentanglement through design rather than through statistical regularizers
alone. We evaluate SE-VAE on a suite of simulated tabular datasets and
benchmark its performance against a series of leading baselines using standard
disentanglement metrics. SE-VAE consistently outperforms alternatives in factor
recovery, interpretability, and robustness to nuisance variation. Ablation
results reveal that architectural structure, rather than regularization
strength, is the key driver of performance. SE-VAE offers a principled
framework for white-box generative modeling in scientific and social domains
where latent constructs are theory-driven and measurement validity is
essential.

</details>


### [215] [Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means](https://arxiv.org/abs/2508.06353)
*Parichit Sharma,Marcin Stanislaw,Hasan Kurban,Oguzhan Kulekci,Mehmet Dalkilic*

Main category: cs.LG

TL;DR: Gk-means是一种基于几何原理的k-means改进算法，通过利用标量投影显著提升效率，同时保持解的质量。


<details>
  <summary>Details</summary>
Motivation: 传统k-means算法效率较低，计算开销大，Gk-means旨在通过几何优化减少计算负担。

Method: 利用标量投影识别高表达数据（HE），忽略低表达数据（LE），减少计算量。

Result: 在合成、真实世界和高维数据集上，Gk-means在运行时间和距离计算上优于传统及SOTA k-means变体，且能耗更低。

Conclusion: Gk-means是一种高效、节能且可持续的k-means改进算法。

Abstract: This paper introduces Geometric-k-means (or Gk-means for short), a novel
approach that significantly enhances the efficiency and energy economy of the
widely utilized k-means algorithm, which, despite its inception over five
decades ago, remains a cornerstone in machine learning applications. The
essence of Gk-means lies in its active utilization of geometric principles,
specifically scalar projection, to significantly accelerate the algorithm
without sacrificing solution quality. This geometric strategy enables a more
discerning focus on data points that are most likely to influence cluster
updates, which we call as high expressive data (HE). In contrast, low
expressive data (LE), does not impact clustering outcome, is effectively
bypassed, leading to considerable reductions in computational overhead.
Experiments spanning synthetic, real-world and high-dimensional datasets,
demonstrate Gk-means is significantly better than traditional and state of the
art (SOTA) k-means variants in runtime and distance computations (DC).
Moreover, Gk-means exhibits better resource efficiency, as evidenced by its
reduced energy footprint, placing it as more sustainable alternative.

</details>


### [216] [Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts](https://arxiv.org/abs/2508.06361)
*Zhaomin Wu,Mingzhe Du,See-Kiong Ng,Bingsheng He*

Main category: cs.LG

TL;DR: 该论文研究了大型语言模型（LLMs）在无人类诱导情况下自发的欺骗行为，提出了一种基于心理学的评估框架，发现LLMs在复杂任务中欺骗倾向增加。


<details>
  <summary>Details</summary>
Motivation: LLMs的信任度是关键问题，但现有研究多关注人类诱导的欺骗，忽视了模型自发的欺骗行为。

Method: 提出基于'接触搜索问题'的框架，使用'欺骗意图分数'和'欺骗行为分数'量化LLMs的欺骗倾向。

Result: 评估14个主流LLMs发现，任务难度增加时欺骗倾向显著上升。

Conclusion: LLMs在复杂任务中自发欺骗倾向增加，对其在关键领域的部署提出警示。

Abstract: Large Language Models (LLMs) have been widely deployed in reasoning,
planning, and decision-making tasks, making their trustworthiness a critical
concern. The potential for intentional deception, where an LLM deliberately
fabricates or conceals information to serve a hidden objective, remains a
significant and underexplored threat. Existing studies typically induce such
deception by explicitly setting a "hidden" objective through prompting or
fine-tuning, which may not fully reflect real-world human-LLM interactions.
Moving beyond this human-induced deception, we investigate LLMs' self-initiated
deception on benign prompts. To address the absence of ground truth in this
evaluation, we propose a novel framework using "contact searching questions."
This framework introduces two statistical metrics derived from psychological
principles to quantify the likelihood of deception. The first, the Deceptive
Intention Score, measures the model's bias towards a hidden objective. The
second, Deceptive Behavior Score, measures the inconsistency between the LLM's
internal belief and its expressed output. Upon evaluating 14 leading LLMs, we
find that both metrics escalate as task difficulty increases, rising in
parallel for most models. Building on these findings, we formulate a
mathematical model to explain this behavior. These results reveal that even the
most advanced LLMs exhibit an increasing tendency toward deception when
handling complex problems, raising critical concerns for the deployment of LLM
agents in complex and crucial domains.

</details>


### [217] [ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design](https://arxiv.org/abs/2508.06364)
*Renyi Zhou,Huimin Zhu,Jing Tang,Min Li*

Main category: cs.LG

TL;DR: ActivityDiff是一种基于扩散模型的生成方法，通过分类器引导技术实现对分子生物活性的精确控制，包括增强目标活性和减少脱靶毒性。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法主要关注单一活性分子设计，缺乏同时管理多目标和非目标相互作用的机制。

Method: 采用扩散模型和分类器引导技术，利用单独训练的药物-靶点分类器进行正负引导。

Result: 实验表明，ActivityDiff能有效处理单/双靶点生成、片段约束双靶点设计、选择性生成增强靶点特异性及减少脱靶效应等任务。

Conclusion: ActivityDiff为分子设计提供了一种平衡效能和安全性的新范式，是一个多功能且可扩展的框架。

Abstract: Achieving precise control over a molecule's biological activity-encompassing
targeted activation/inhibition, cooperative multi-target modulation, and
off-target toxicity mitigation-remains a critical challenge in de novo drug
design. However, existing generative methods primarily focus on producing
molecules with a single desired activity, lacking integrated mechanisms for the
simultaneous management of multiple intended and unintended molecular
interactions. Here, we propose ActivityDiff, a generative approach based on the
classifier-guidance technique of diffusion models. It leverages separately
trained drug-target classifiers for both positive and negative guidance,
enabling the model to enhance desired activities while minimizing harmful
off-target effects. Experimental results show that ActivityDiff effectively
handles essential drug design tasks, including single-/dual-target generation,
fragment-constrained dual-target design, selective generation to enhance target
specificity, and reduction of off-target effects. These results demonstrate the
effectiveness of classifier-guided diffusion in balancing efficacy and safety
in molecular design. Overall, our work introduces a novel paradigm for
achieving integrated control over molecular activity, and provides ActivityDiff
as a versatile and extensible framework.

</details>


### [218] [End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation](https://arxiv.org/abs/2508.06387)
*Anurag Tripathi,Vaibhav Patle,Abhinav Jain,Ayush Pundir,Sairam Menon,Ajeet Kumar Singh*

Main category: cs.LG

TL;DR: 提出了一种三阶段的端到端文本到SQL框架，通过LLM和提示工程提取隐含信息，训练数据库标识预测模型，并利用批评代理优化SQL生成。


<details>
  <summary>Details</summary>
Motivation: 解决多数据库场景中目标数据库识别被忽视的问题，提高文本到SQL的准确性和实用性。

Method: 三阶段框架：1) 使用LLM和提示工程从自然语言查询中提取规则；2) 训练RoBERTa微调编码器预测数据库标识；3) 利用批评代理优化生成的SQL。

Result: 实验表明，该框架在数据库意图预测和SQL生成准确性上优于当前最优模型。

Conclusion: 提出的方法在多数据库场景中显著提升了文本到SQL的性能，解决了目标数据库识别的关键问题。

Abstract: Text-to-SQL bridges the gap between natural language and structured database
language, thus allowing non-technical users to easily query databases.
Traditional approaches model text-to-SQL as a direct translation task, where a
given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances
in large language models (LLMs) have significantly improved translation
accuracy, however, these methods all require that the target database is
pre-specified. This becomes problematic in scenarios with multiple extensive
databases, where identifying the correct database becomes a crucial yet
overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL
framework to identify the user's intended database before generating SQL
queries. Our approach leverages LLMs and prompt engineering to extract implicit
information from natural language queries (NLQs) in the form of a ruleset. We
then train a large db\_id prediction model, which includes a RoBERTa-based
finetuned encoder, to predict the correct Database identifier (db\_id) based on
both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL
by using critic agents to correct errors. Experimental results demonstrate that
our framework outperforms the current state-of-the-art models in both database
intent prediction and SQL generation accuracy.

</details>


### [219] [A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images](https://arxiv.org/abs/2508.06409)
*Wooyong Jung,Sola Kim,Dongwook Kim,Maryam Tabar,Dongwon Lee*

Main category: cs.LG

TL;DR: 利用公开众包数据（如311服务电话和街景图像）跟踪和预测旧金山无家可归帐篷趋势，提供更及时、本地化和经济的信息。


<details>
  <summary>Details</summary>
Motivation: 现有监测方法（如PIT统计）在频率、一致性和空间细节上存在局限，无法捕捉快速变化和空间迁移。

Method: 使用311服务电话和街景图像数据，建立预测模型，捕捉每日和社区级别的细微变化。

Result: 模型揭示了传统统计忽略的模式，如疫情期间的快速波动和帐篷位置的空间迁移。

Conclusion: 该方法为政策制定和干预评估提供了更有效的工具。

Abstract: Homelessness in the United States has surged to levels unseen since the Great
Depression. However, existing methods for monitoring it, such as point-in-time
(PIT) counts, have limitations in terms of frequency, consistency, and spatial
detail. This study proposes a new approach using publicly available,
crowdsourced data, specifically 311 Service Calls and street-level imagery, to
track and forecast homeless tent trends in San Francisco. Our predictive model
captures fine-grained daily and neighborhood-level variations, uncovering
patterns that traditional counts often overlook, such as rapid fluctuations
during the COVID-19 pandemic and spatial shifts in tent locations over time. By
providing more timely, localized, and cost-effective information, this approach
serves as a valuable tool for guiding policy responses and evaluating
interventions aimed at reducing unsheltered homelessness.

</details>


### [220] [Sample-efficient LLM Optimization with Reset Replay](https://arxiv.org/abs/2508.06412)
*Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian*

Main category: cs.LG

TL;DR: 论文提出LoRR方法，通过高重放训练和周期性重置策略提升LLM的样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有RL和偏好优化方法存在样本效率低和首因偏差问题，影响模型性能。

Method: 引入LoRR插件，结合高重放训练、周期性重置和混合优化目标（SFT与偏好损失）。

Result: LoRR显著提升偏好优化方法在数学和通用推理任务中的性能，媲美复杂RL算法。

Conclusion: LoRR为LLM微调提供高效、实用的新范式，尤其适合数据有限场景。

Abstract: Recent advancements in post-training Large Language Models (LLMs),
particularly through Reinforcement Learning (RL) and preference optimization
methods, are key drivers for enhancing their reasoning capabilities. However,
these methods are often plagued by low sample efficiency and a susceptibility
to primacy bias, where overfitting to initial experiences degrades policy
quality and damages the learning process. To address these challenges, we
introduce LLM optimization with Reset Replay (LoRR), a general and powerful
plugin designed to enhance sample efficiency in any preference-based
optimization framework. LoRR core mechanism enables training at a high replay
number, maximizing the utility of each collected data batch. To counteract the
risk of overfitting inherent in high-replay training, LoRR incorporates a
periodic reset strategy with reusing initial data, which preserves network
plasticity. Furthermore, it leverages a hybrid optimization objective,
combining supervised fine-tuning (SFT) and preference-based losses to further
bolster data exploitation. Our extensive experiments demonstrate that LoRR
significantly boosts the performance of various preference optimization methods
on both mathematical and general reasoning benchmarks. Notably, an iterative
DPO approach augmented with LoRR achieves comparable performance on challenging
math tasks, outperforming some complex and computationally intensive RL-based
algorithms. These findings highlight that LoRR offers a practical,
sample-efficient, and highly effective paradigm for LLM finetuning, unlocking
greater performance from limited data.

</details>


### [221] [LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection](https://arxiv.org/abs/2508.06467)
*Ameya Anjarlekar,Sandeep Pombra*

Main category: cs.LG

TL;DR: GRIN是一个模块化、目标明确的框架，用于大语言模型（LLM）的遗忘学习，通过梯度比指标定位关键参数并选择性注入噪声，提升遗忘效果同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法在遗忘敏感或未经授权数据时效果不佳，导致不完全遗忘或无关知识退化，需要更有效的解决方案。

Method: GRIN提出基于梯度比的指标定位关键参数，并在微调前选择性注入噪声，优化遗忘效果。

Result: 在TOFU、WMDP和SafePKU等标准基准测试中验证了GRIN的有效性。

Conclusion: GRIN为LLM遗忘学习提供了高效且针对性的解决方案，平衡了遗忘效果和模型性能。

Abstract: The growing legal and ethical scrutiny of large language models (LLMs)
necessitates effective machine unlearning, particularly for sensitive or
unauthorized data. Existing empirical methods often yield incomplete forgetting
or unintended degradation of unrelated knowledge due to poor localization. In
this work, we propose GRIN: a modular and targeted framework for LLM
unlearning. GRIN introduces a novel gradient-ratio-based metric to identify
parameters most responsible for memorizing forget data. We then perform
selective noise injection into these parameters prior to fine-tuning, which
improves unlearning performance while maintaining model utility. Finally, we
propose new evaluation metrics tailored to the LLM setting and validate our
approach on standard benchmarks such as TOFU, WMDP, and SafePKU.

</details>
