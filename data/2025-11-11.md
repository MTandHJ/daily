<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 170]
- [cs.CY](#cs.CY) [Total: 23]
- [cs.AI](#cs.AI) [Total: 43]
- [cs.LG](#cs.LG) [Total: 144]
- [cs.IR](#cs.IR) [Total: 22]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Randomized-MLP Regularization Improves Domain Adaptation and Interpretability in DINOv2](https://arxiv.org/abs/2511.05509)
*Joel Valdivia Ortega,Lorenz Lamm,Franziska Eckardt,Benedikt Schworm,Marion Jasnin,Tingying Peng*

Main category: cs.CV

TL;DR: 本文提出了一种名为RMLP的正则化方法，用于改进Vision Transformers在医学图像中的可解释性，通过对比学习增强语义对齐表示，同时保持或提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers（如DINOv2）在跨领域应用中表现出色，但其注意力机制和特征图的可解释性较差，特别是在医学成像领域，领域偏移会降低性能和透明度。

Method: 引入基于对比学习的Randomized-MLP（RMLP）正则化方法，在微调DINOv2时使用RMLP来鼓励更语义对齐的表示。

Result: RMLP在医学和自然图像模态上都改善了或保持了下游性能，同时产生了更可解释的注意力图。

Conclusion: RMLP正则化方法有效提升了ViT模型的可解释性，并通过数学分析提供了对对比学习机制的新理解。

Abstract: Vision Transformers (ViTs), such as DINOv2, achieve strong performance across
domains but often repurpose low-informative patch tokens in ways that reduce
the interpretability of attention and feature maps. This challenge is
especially evident in medical imaging, where domain shifts can degrade both
performance and transparency. In this paper, we introduce Randomized-MLP (RMLP)
regularization, a contrastive learning-based method that encourages more
semantically aligned representations. We use RMLPs when fine-tuning DINOv2 to
both medical and natural image modalities, showing that it improves or
maintains downstream performance while producing more interpretable attention
maps. We also provide a mathematical analysis of RMLPs, offering insights into
its role in enhancing ViT-based models and advancing our understanding of
contrastive learning.

</details>


### [2] [Token Is All You Need: Cognitive Planning through Sparse Intent Alignment](https://arxiv.org/abs/2511.05540)
*Shiyao Sang*

Main category: cs.CV

TL;DR: 本文挑战了端到端自动驾驶需要详尽场景建模的传统假设，提出仅需少量语义丰富的token即可实现有效规划，在nuPlan基准测试中取得了优于现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 挑战传统端到端自动驾驶需要详尽场景建模的假设，探索更高效的基于语义token的规划方法。

Method: 使用感知引导的BEV表示，基于稀疏语义token进行规划，比较了仅当前状态和预测未来token两种解码策略。

Result: 在nuPlan基准测试中：仅当前状态token达到0.548m ADE；预测未来token后降至0.479m ADE，提升12.6%；显式重建损失无益且可能降低性能。

Conclusion: 提出了"token is all you need"原则，标志着从重建世界到理解世界的范式转变，为认知启发系统通过想象而非反应进行规划奠定了基础。

Abstract: We challenge the long-standing assumption that exhaustive scene modeling is
required for high-performance end-to-end autonomous driving (E2EAD). Unlike
world-model approaches that rely on computationally intensive future scene
generation or vision-language-action (VLA) systems constrained by Markov
assumptions, we show that a minimal set of semantically rich tokens is
sufficient for effective planning. Experiments on the nuPlan benchmark (720
scenarios, over 11,000 samples) using perception-informed BEV representations
yield three key findings: (1) even without future prediction, our sparse
representation achieves 0.548 m ADE, comparable to or surpassing prior methods
reporting around 0.75 m on nuScenes; (2) conditioning trajectory decoding on
predicted future tokens reduces ADE to 0.479 m, a 12.6% improvement over
current-state baselines; and (3) explicit reconstruction loss offers no benefit
and may degrade performance under reliable perception inputs. Notably, we
observe the emergence of temporal fuzziness, where the model adaptively attends
to task-relevant semantics rather than aligning rigidly to fixed timestamps,
providing a cognitive advantage for planning under uncertainty. Our "token is
all you need" principle marks a paradigm shift from reconstructing the world to
understanding it, laying a foundation for cognitively inspired systems that
plan through imagination rather than reaction.

</details>


### [3] [Automated Invoice Data Extraction: Using LLM and OCR](https://arxiv.org/abs/2511.05547)
*Advait Thakur,Khushi Khanchandani,Akshita Shetty,Chaitravi Reddy,Ritisa Behera*

Main category: cs.CV

TL;DR: 本文提出了一种结合OCR、深度学习、大语言模型和图分析的全方位AI平台，用于解决传统OCR系统在处理变体发票布局、手写文本和低质量扫描时的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统OCR系统对模板依赖性强，难以处理不同文档结构和布局的变体发票、手写文本和低质量扫描，限制了其灵活性和准确性。

Method: 开发了一个结合OCR技术、深度学习模型（CNN和Transformer）、大语言模型（LLMs）和图分析的全方位AI平台，利用视觉命名实体识别（NER）能力进行更精确的实体提取。

Result: 该平台实现了前所未有的提取质量和一致性，比传统方法具有更高的上下文敏感性和准确率。

Conclusion: 结合OCR、深度学习、LLMs和图分析的混合架构能够最大程度地提高可扩展性并减少人工干预，为发票处理提供了革命性的解决方案。

Abstract: Conventional Optical Character Recognition (OCR) systems are challenged by
variant invoice layouts, handwritten text, and low- quality scans, which are
often caused by strong template dependencies that restrict their flexibility
across different document structures and layouts. Newer solutions utilize
advanced deep learning models such as Convolutional Neural Networks (CNN) as
well as Transformers, and domain-specific models for better layout analysis and
accuracy across various sections over varied document types. Large Language
Models (LLMs) have revolutionized extraction pipelines at their core with
sophisticated entity recognition and semantic comprehension to support complex
contextual relationship mapping without direct programming specification.
Visual Named Entity Recognition (NER) capabilities permit extraction from
invoice images with greater contextual sensitivity and much higher accuracy
rates than older approaches. Existing industry best practices utilize hybrid
architectures that blend OCR technology and LLM for maximum scalability and
minimal human intervention. This work introduces a holistic Artificial
Intelligence (AI) platform combining OCR, deep learning, LLMs, and graph
analytics to achieve unprecedented extraction quality and consistency.

</details>


### [4] [In-Context-Learning-Assisted Quality Assessment Vision-Language Models for Metal Additive Manufacturing](https://arxiv.org/abs/2511.05551)
*Qiaojie Zheng,Jiucai Zhang,Xiaoli Zhang*

Main category: cs.CV

TL;DR: 该论文提出使用视觉语言模型（VLMs）和上下文学习（ICL）来评估增材制造中打印件的质量，无需大量应用特定数据集训练，仅需少量样本即可达到与传统机器学习模型相当的分类准确率，并能提供可解释的推理过程。


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉的质量评估需要专用机器学习模型和大量应用特定数据集，数据收集和模型训练成本高、耗时长。

Method: 利用视觉语言模型的推理能力，引入上下文学习为模型提供必要的应用特定知识和演示样本，探索不同的ICL采样策略寻找最优配置。

Result: ICL辅助的VLMs在金属丝激光直接能量沉积工艺的质量评估任务中，仅需少量样本就能达到与传统机器学习模型相似的分类准确率，并能生成人类可理解的推理依据。

Conclusion: ICL辅助的VLMs能够用有限数据解决应用特定任务，在保持较高准确率的同时提供有效的支持推理，提高决策透明度。

Abstract: Vision-based quality assessment in additive manufacturing often requires
dedicated machine learning models and application-specific datasets. However,
data collection and model training can be expensive and time-consuming. In this
paper, we leverage vision-language models' (VLMs') reasoning capabilities to
assess the quality of printed parts and introduce in-context learning (ICL) to
provide VLMs with necessary application-specific knowledge and demonstration
samples. This method eliminates the requirement for large application-specific
datasets for training models. We explored different sampling strategies for ICL
to search for the optimal configuration that makes use of limited samples. We
evaluated these strategies on two VLMs, Gemini-2.5-flash and Gemma3:27b, with
quality assessment tasks in wire-laser direct energy deposition processes. The
results show that ICL-assisted VLMs can reach quality classification accuracies
similar to those of traditional machine learning models while requiring only a
minimal number of samples. In addition, unlike traditional classification
models that lack transparency, VLMs can generate human-interpretable rationales
to enhance trust. Since there are no metrics to evaluate their interpretability
in manufacturing applications, we propose two metrics, knowledge relevance and
rationale validity, to evaluate the quality of VLMs' supporting rationales. Our
results show that ICL-assisted VLMs can address application-specific tasks with
limited data, achieving relatively high accuracy while also providing valid
supporting rationales for improved decision transparency.

</details>


### [5] [EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning](https://arxiv.org/abs/2511.05553)
*Xinyan Cai,Shiguang Wu,Dafeng Chi,Yuzheng Zhuang,Xingyue Quan,Jianye Hao,Qiang Guan*

Main category: cs.CV

TL;DR: EVLP是一个创新的多模态统一生成框架，通过联合建模语言推理和视觉生成来解决长时程操作任务中的多模态规划问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法在多模态规划中缺乏统一的生成框架，导致规划不一致。需要整合文本逻辑推理和视觉空间想象力来实现高效准确的操作。

Method: 提出统一多模态生成框架、动态感知预训练和强化监督微调三个核心组件，通过可学习的跨模态注意力机制协调语言-视觉建模。

Result: 该方法实现了长时程任务的多模态规划，通过动态预训练和强化对齐训练策略有效增强了多模态相关性。

Conclusion: EVLP框架能够获得空间感知的多模态规划能力，为复杂具身长时程操作任务提供了有效的解决方案。

Abstract: In complex embodied long-horizon manipulation tasks, effective task
decomposition and execution require synergistic integration of textual logical
reasoning and visual-spatial imagination to ensure efficient and accurate
operation. Current methods fail to adopt a unified generation framework for
multimodal planning, lead to inconsistent in multimodal planning. To address
this challenge, we present \textbf{EVLP (Embodied Vision-Language Planner)}, an
innovative multimodal unified generation framework that jointly models
linguistic reasoning and visual generation. Our approach achieves multimodal
planning for long-horizon tasks through a novel training pipeline incorporating
dynamic pretraining and reinforced alignment. Our core innovations consist of
three key components: \textbf{1) Unified Multimodal Generation Framework}: For
understanding, We integrate semantic information with spatial features to
provide comprehensive visual perception. For generation, we directly learn the
joint distribution of discrete images for one-step visual synthesis, enabling
coordinated language-visual modeling through learnable cross-modal attention
mechanisms. \textbf{2) Dynamic Perception Pretraining}: We propose a
bidirectional dynamic alignment strategy employing inverse dynamics tasks and
forward dynamics tasks, effectively strengthening multimodal correlations
within a unified feature space. \textbf{3) Reinforced Supervised Fine-Tuning}:
While conducting instruction-based fine-tuning in the unified generation space,
we construct a reinforce loss to align the spatial logic between textual
actions and generated images, enabling the model to acquire spatio-awared
multimodal planning capabilities.

</details>


### [6] [M2S2L: Mamba-based Multi-Scale Spatial-temporal Learning for Video Anomaly Detection](https://arxiv.org/abs/2511.05564)
*Yang Liu,Boan Chen,Xiaoguang Zhu,Jing Liu,Peng Sun,Wei Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba的多尺度时空学习框架(M2S2L)，用于视频异常检测，在保持计算效率的同时提高了检测精度。


<details>
  <summary>Details</summary>
Motivation: 视频异常检测在平衡检测精度和计算效率方面面临挑战，传统方法难以应对复杂视频内容和实时应用需求。

Method: 采用分层空间编码器和多时间编码器，结合特征分解机制，实现外观和运动重建的任务特定优化。

Result: 在三个基准数据集上分别达到98.5%、92.1%和77.9%的帧级AUC，计算效率为20.1G FLOPs和45 FPS。

Conclusion: M2S2L框架在保持高效率的同时显著提升了异常检测性能，适合实际监控部署。

Abstract: Video anomaly detection (VAD) is an essential task in the image processing
community with prospects in video surveillance, which faces fundamental
challenges in balancing detection accuracy with computational efficiency. As
video content becomes increasingly complex with diverse behavioral patterns and
contextual scenarios, traditional VAD approaches struggle to provide robust
assessment for modern surveillance systems. Existing methods either lack
comprehensive spatial-temporal modeling or require excessive computational
resources for real-time applications. In this regard, we present a Mamba-based
multi-scale spatial-temporal learning (M2S2L) framework in this paper. The
proposed method employs hierarchical spatial encoders operating at multiple
granularities and multi-temporal encoders capturing motion dynamics across
different time scales. We also introduce a feature decomposition mechanism to
enable task-specific optimization for appearance and motion reconstruction,
facilitating more nuanced behavioral modeling and quality-aware anomaly
assessment. Experiments on three benchmark datasets demonstrate that M2S2L
framework achieves 98.5%, 92.1%, and 77.9% frame-level AUCs on UCSD Ped2, CUHK
Avenue, and ShanghaiTech respectively, while maintaining efficiency with 20.1G
FLOPs and 45 FPS inference speed, making it suitable for practical surveillance
deployment.

</details>


### [7] [In-Context Adaptation of VLMs for Few-Shot Cell Detection in Optical Microscopy](https://arxiv.org/abs/2511.05565)
*Shreyan Ganguly,Angona Biswas,Jaydeep Rade,Md Hasibul Hasan Hasib,Nabila Masud,Nitish Singla,Abhipsa Dash,Ushashi Bhattacharjee,Aditya Balu,Anwesha Sarkar,Adarsh Krishnamurthy,Soumik Sarkar*

Main category: cs.CV

TL;DR: 本文研究了基础视觉语言模型在生物医学显微镜图像中的少样本目标检测能力，提出了Micro-OD基准测试，评估了8个VLM模型，并开发了混合FSOD流程来提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在生物医学显微镜图像中的应用潜力，解决标注数据稀缺的问题，通过上下文学习实现少样本目标检测。

Method: 引入Micro-OD基准测试集（252张图像，11种细胞类型），系统评估8个VLM模型，比较有无推理令牌的变体，并实现混合FSOD流程（检测头+VLM少样本分类器）。

Result: 零样本性能较弱（领域差距），但少样本支持能持续改善检测性能，6个样本后增益边际；带推理令牌的模型更适合端到端定位，简单变体更适合预定位裁剪分类。

Conclusion: 上下文适应是显微镜图像分析的实用路径，基准测试为生物医学成像中的开放词汇检测提供了可复现测试平台。

Abstract: Foundation vision-language models (VLMs) excel on natural images, but their
utility for biomedical microscopy remains underexplored. In this paper, we
investigate how in-context learning enables state-of-the-art VLMs to perform
few-shot object detection when large annotated datasets are unavailable, as is
often the case with microscopic images. We introduce the Micro-OD benchmark, a
curated collection of 252 images specifically curated for in-context learning,
with bounding-box annotations spanning 11 cell types across four sources,
including two in-lab expert-annotated sets. We systematically evaluate eight
VLMs under few-shot conditions and compare variants with and without implicit
test-time reasoning tokens. We further implement a hybrid Few-Shot Object
Detection (FSOD) pipeline that combines a detection head with a VLM-based
few-shot classifier, which enhances the few-shot performance of recent VLMs on
our benchmark. Across datasets, we observe that zero-shot performance is weak
due to the domain gap; however, few-shot support consistently improves
detection, with marginal gains achieved after six shots. We observe that models
with reasoning tokens are more effective for end-to-end localization, whereas
simpler variants are more suitable for classifying pre-localized crops. Our
results highlight in-context adaptation as a practical path for microscopy, and
our benchmark provides a reproducible testbed for advancing open-vocabulary
detection in biomedical imaging.

</details>


### [8] [C3-Diff: Super-resolving Spatial Transcriptomics via Cross-modal Cross-content Contrastive Diffusion Modelling](https://arxiv.org/abs/2511.05571)
*Xiaofei Wang,Stephen Price,Chao Li*

Main category: cs.CV

TL;DR: C3-Diff是一个用于空间转录组学增强的跨模态对比扩散框架，通过整合组织学图像和基因表达数据来提高空间转录组图谱的分辨率。


<details>
  <summary>Details</summary>
Motivation: 当前空间转录组学平台分辨率较低，限制了深入理解空间基因表达。需要开发有效的方法来整合组织学图像和基因表达数据以增强空间转录组图谱。

Method: 提出跨模态跨内容对比扩散框架(C3-Diff)，包括：改进对比学习提取模态不变和内容不变特征；基于噪声的特征单元超球面信息增强；动态跨模态插补训练策略缓解数据稀缺问题。

Result: 在四个公共数据集上测试，相比竞争方法有显著改进。在下游任务如细胞类型定位、基因表达相关性和单细胞级基因表达预测中表现优异。

Conclusion: C3-Diff通过有效建模组织学图像和基因表达之间的相互作用，成功提升了空间转录组学增强性能，推动了AI增强生物技术在生物医学研究和临床应用中的发展。

Abstract: The rapid advancement of spatial transcriptomics (ST), i.e., spatial gene
expressions, has made it possible to measure gene expression within original
tissue, enabling us to discover molecular mechanisms. However, current ST
platforms frequently suffer from low resolution, limiting the in-depth
understanding of spatial gene expression. Super-resolution approaches promise
to enhance ST maps by integrating histology images with gene expressions of
profiled tissue spots. However, it remains a challenge to model the
interactions between histology images and gene expressions for effective ST
enhancement. This study presents a cross-modal cross-content contrastive
diffusion framework, called C3-Diff, for ST enhancement with histology images
as guidance. In C3-Diff, we firstly analyze the deficiency of traditional
contrastive learning paradigm, which is then refined to extract both
modal-invariant and content-invariant features of ST maps and histology images.
Further, to overcome the problem of low sequencing sensitivity in ST maps, we
perform nosing-based information augmentation on the surface of feature unit
hypersphere. Finally, we propose a dynamic cross-modal imputation-based
training strategy to mitigate ST data scarcity. We tested C3-Diff by
benchmarking its performance on four public datasets, where it achieves
significant improvements over competing methods. Moreover, we evaluate C3-Diff
on downstream tasks of cell type localization, gene expression correlation and
single-cell-level gene expression prediction, promoting AI-enhanced
biotechnology for biomedical research and clinical applications. Codes are
available at https://github.com/XiaofeiWang2018/C3-Diff.

</details>


### [9] [Video Text Preservation with Synthetic Text-Rich Videos](https://arxiv.org/abs/2511.05573)
*Ziyang Liu,Kevin Valencia,Justin Cui*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级方法，通过合成监督改进文本到视频扩散模型，使用文本到图像模型生成文本丰富的图像，再用图像到视频模型将其动画化，然后微调预训练的T2V模型，显著提升了短文本可读性和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频模型在生成清晰连贯的文本方面存在困难，即使是短短语或单词也经常渲染不正确，而之前的解决方案计算成本高且不适合视频生成。

Method: 首先使用文本到图像扩散模型生成文本丰富的图像，然后用文本无关的图像到视频模型将其动画化为短视频，利用这些合成的视频-提示对微调预训练的Wan2.1 T2V模型，无需架构更改。

Result: 结果显示短文本可读性和时间一致性得到改善，并为长文本提供了新兴的结构先验。

Conclusion: 精心策划的合成数据和弱监督为提高T2V生成中的文本保真度提供了一条实用路径。

Abstract: While Text-To-Video (T2V) models have advanced rapidly, they continue to
struggle with generating legible and coherent text within videos. In
particular, existing models often fail to render correctly even short phrases
or words and previous attempts to address this problem are computationally
expensive and not suitable for video generation. In this work, we investigate a
lightweight approach to improve T2V diffusion models using synthetic
supervision. We first generate text-rich images using a text-to-image (T2I)
diffusion model, then animate them into short videos using a text-agnostic
image-to-video (I2v) model. These synthetic video-prompt pairs are used to
fine-tune Wan2.1, a pre-trained T2V model, without any architectural changes.
Our results show improvement in short-text legibility and temporal consistency
with emerging structural priors for longer text. These findings suggest that
curated synthetic data and weak supervision offer a practical path toward
improving textual fidelity in T2V generation.

</details>


### [10] [DiffSwap++: 3D Latent-Controlled Diffusion for Identity-Preserving Face Swapping](https://arxiv.org/abs/2511.05575)
*Weston Bondurant,Arkaprava Sinha,Hieu Le,Srijan Das,Stephanie Schuckers*

Main category: cs.CV

TL;DR: DiffSwap++是一种基于扩散模型的人脸交换方法，通过引入3D面部潜在特征来提升几何一致性和身份保持能力，在CelebA、FFHQ和CelebV-Text数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的人脸交换方法在复杂姿态和表情下存在细粒度伪影和身份保持不佳的问题，主要原因是未能有效利用3D面部结构来解耦身份与姿态表情。

Method: 提出DiffSwap++管道，在训练中融入3D面部潜在特征，通过3D感知表示指导生成过程，并设计基于身份嵌入和面部关键点的扩散架构来调节去噪过程。

Result: 在CelebA、FFHQ和CelebV-Text数据集上的广泛实验表明，DiffSwap++在保持源身份同时维持目标姿态和表情方面优于先前方法，并通过生物特征评估和用户研究验证了方法的真实性和有效性。

Conclusion: DiffSwap++通过有效利用3D面部结构信息，显著提升了基于扩散模型的人脸交换质量，实现了更好的身份保持和几何一致性。

Abstract: Diffusion-based approaches have recently achieved strong results in face
swapping, offering improved visual quality over traditional GAN-based methods.
However, even state-of-the-art models often suffer from fine-grained artifacts
and poor identity preservation, particularly under challenging poses and
expressions. A key limitation of existing approaches is their failure to
meaningfully leverage 3D facial structure, which is crucial for disentangling
identity from pose and expression. In this work, we propose DiffSwap++, a novel
diffusion-based face-swapping pipeline that incorporates 3D facial latent
features during training. By guiding the generation process with 3D-aware
representations, our method enhances geometric consistency and improves the
disentanglement of facial identity from appearance attributes. We further
design a diffusion architecture that conditions the denoising process on both
identity embeddings and facial landmarks, enabling high-fidelity and
identity-preserving face swaps. Extensive experiments on CelebA, FFHQ, and
CelebV-Text demonstrate that DiffSwap++ outperforms prior methods in preserving
source identity while maintaining target pose and expression. Additionally, we
introduce a biometric-style evaluation and conduct a user study to further
validate the realism and effectiveness of our approach. Code will be made
publicly available at https://github.com/WestonBond/DiffSwapPP

</details>


### [11] [Beyond Softmax: Dual-Branch Sigmoid Architecture for Accurate Class Activation Maps](https://arxiv.org/abs/2511.05590)
*Yoojin Oh,Junhyug Noh*

Main category: cs.CV

TL;DR: 本文提出了一种双分支sigmoid头部方法，解决了传统CAM方法因依赖softmax分类器而产生的两个基本问题：加性logit偏移和符号崩溃，从而改善了可视化解释的保真度。


<details>
  <summary>Details</summary>
Motivation: 传统CAM及其扩展方法依赖最终的softmax分类器，存在两个基本失真问题：加性logit偏移会任意偏置重要性分数，符号崩溃会混淆兴奋性和抑制性特征，这限制了可视化解释的准确性。

Method: 提出一种简单的、与架构无关的双分支sigmoid头部方法，将定位与分类解耦。复制预训练模型的分类头到并行分支，使用每类sigmoid输出，冻结原始softmax头，仅使用类别平衡的二元监督微调sigmoid分支。

Result: 在细粒度任务（CUB-200-2011、Stanford Cars）和WSOL基准测试（ImageNet-1K、OpenImages30K）上的广泛评估显示，该方法提高了解释保真度，并实现了一致的Top-1定位增益，同时分类准确率没有任何下降。

Conclusion: 该方法能够无缝集成到大多数CAM变体中，计算开销可忽略不计，在保持识别准确率的同时，从sigmoid分支生成类别证据图，保留了特征贡献的大小和符号。

Abstract: Class Activation Mapping (CAM) and its extensions have become indispensable
tools for visualizing the evidence behind deep network predictions. However, by
relying on a final softmax classifier, these methods suffer from two
fundamental distortions: additive logit shifts that arbitrarily bias importance
scores, and sign collapse that conflates excitatory and inhibitory features. We
propose a simple, architecture-agnostic dual-branch sigmoid head that decouples
localization from classification. Given any pretrained model, we clone its
classification head into a parallel branch ending in per-class sigmoid outputs,
freeze the original softmax head, and fine-tune only the sigmoid branch with
class-balanced binary supervision. At inference, softmax retains recognition
accuracy, while class evidence maps are generated from the sigmoid branch --
preserving both magnitude and sign of feature contributions. Our method
integrates seamlessly with most CAM variants and incurs negligible overhead.
Extensive evaluations on fine-grained tasks (CUB-200-2011, Stanford Cars) and
WSOL benchmarks (ImageNet-1K, OpenImages30K) show improved explanation fidelity
and consistent Top-1 Localization gains -- without any drop in classification
accuracy. Code is available at https://github.com/finallyupper/beyond-softmax.

</details>


### [12] [In-process 3D Deviation Mapping and Defect Monitoring (3D-DM2) in High Production-rate Robotic Additive Manufacturing](https://arxiv.org/abs/2511.05604)
*Subash Gautam,Alejandro Vargas-Uscategui,Peter King,Hans Lohr,Alireza Bab-Hadiashar,Ivan Cole,Ehsan Asadi*

Main category: cs.CV

TL;DR: 本文提出了一种实时监测系统，用于在高速机器人增材制造过程中检测和重建生长零件，通过与近净参考模型直接比较来识别形状偏差，从而实现及时干预和补偿。


<details>
  <summary>Details</summary>
Motivation: 高速机器人增材制造工艺如冷喷涂增材制造虽然能显著提高构建速度，但由于当前开环系统的过程不稳定性，保持形状精度仍然是一个关键挑战。实时检测这些偏差对于防止误差传播、确保零件质量和减少后处理需求至关重要。

Method: 开发了一个实时监测系统来获取和重建生长零件，并将其与近净参考模型直接比较，以检测制造过程中的形状偏差。通过早期识别形状不一致性，并对每个偏差区域进行分割和跟踪。

Result: 该系统能够实时监测和识别制造过程中的形状偏差，为及时干预和补偿提供了基础。

Conclusion: 通过实时形状偏差检测和跟踪系统，可以实现对高速机器人增材制造过程的及时干预，从而获得一致的零件质量。

Abstract: Additive manufacturing (AM) is an emerging digital manufacturing technology
to produce complex and freeform objects through a layer-wise deposition. High
deposition rate robotic AM (HDRRAM) processes, such as cold spray additive
manufacturing (CSAM), offer significantly increased build speeds by delivering
large volumes of material per unit time. However, maintaining shape accuracy
remains a critical challenge, particularly due to process instabilities in
current open-loop systems. Detecting these deviations as they occur is
essential to prevent error propagation, ensure part quality, and minimize
post-processing requirements. This study presents a real-time monitoring system
to acquire and reconstruct the growing part and directly compares it with a
near-net reference model to detect the shape deviation during the manufacturing
process. The early identification of shape inconsistencies, followed by
segmenting and tracking each deviation region, paves the way for timely
intervention and compensation to achieve consistent part quality.

</details>


### [13] [Walking the Schrödinger Bridge: A Direct Trajectory for Text-to-3D Generation](https://arxiv.org/abs/2511.05609)
*Ziying Li,Xuequan Lu,Xinkui Zhao,Guanjie Cheng,Shuiguang Deng,Jianwei Yin*

Main category: cs.CV

TL;DR: 本文提出TraCe框架，通过将文本到3D生成过程建模为学习渲染分布到目标分布的最优传输轨迹，解决了现有SDS方法导致的过饱和和过平滑问题，实现了更高质量的3D生成。


<details>
  <summary>Details</summary>
Motivation: 解决基于优化的文本到3D生成方法中Score Distillation Sampling (SDS)技术引入的过饱和和过平滑伪影问题，提升生成质量。

Method: 将SDS理论建立为薛定谔桥框架的简化实例，提出Trajectory-Centric Distillation (TraCe)框架，利用薛定谔桥显式构建从当前渲染到文本条件去噪目标的扩散桥，并在该轨迹的分数动态上训练LoRA适应模型进行3D优化。

Result: 综合实验表明TraCe在质量和保真度上持续优于最先进技术，能够使用更小的Classifier-free Guidance值实现高质量生成。

Conclusion: TraCe通过将生成过程建模为最优传输轨迹，有效解决了SDS的局限性，为文本到3D生成提供了更高质量的解决方案。

Abstract: Recent advancements in optimization-based text-to-3D generation heavily rely
on distilling knowledge from pre-trained text-to-image diffusion models using
techniques like Score Distillation Sampling (SDS), which often introduce
artifacts such as over-saturation and over-smoothing into the generated 3D
assets. In this paper, we address this essential problem by formulating the
generation process as learning an optimal, direct transport trajectory between
the distribution of the current rendering and the desired target distribution,
thereby enabling high-quality generation with smaller Classifier-free Guidance
(CFG) values. At first, we theoretically establish SDS as a simplified instance
of the Schr\"odinger Bridge framework. We prove that SDS employs the reverse
process of an Schr\"odinger Bridge, which, under specific conditions (e.g., a
Gaussian noise as one end), collapses to SDS's score function of the
pre-trained diffusion model. Based upon this, we introduce Trajectory-Centric
Distillation (TraCe), a novel text-to-3D generation framework, which
reformulates the mathematically trackable framework of Schr\"odinger Bridge to
explicitly construct a diffusion bridge from the current rendering to its
text-conditioned, denoised target, and trains a LoRA-adapted model on this
trajectory's score dynamics for robust 3D optimization. Comprehensive
experiments demonstrate that TraCe consistently achieves superior quality and
fidelity to state-of-the-art techniques.

</details>


### [14] [Pose-Aware Multi-Level Motion Parsing for Action Quality Assessment](https://arxiv.org/abs/2511.05611)
*Shuaikang Zhu,Yang Yang,Chen Sun*

Main category: cs.CV

TL;DR: 提出了一种基于增强时空姿态特征的多层次运动解析框架，用于动作质量评估，通过动作单元解析器、运动解析器和条件解析器实现精确的动作分割和评分，在跳水运动数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 人体姿态是动作质量评估的关键，在高级别比赛中，姿态的细微时空变化往往是决定评分的关键因素。

Method: 设计多层次运动解析框架：第一层使用动作单元解析器进行精确动作分割和局部-全局姿态表示；第二层通过运动解析器学习时空特征捕捉姿态变化和外观细节；额外设计条件解析器处理非身体相关的影响因素；最后引入权重调整评分模块适应不同动作类型需求。

Result: 在大规模跳水运动数据集上的广泛评估表明，该框架在动作分割和动作评分任务中都达到了最先进的性能。

Conclusion: 提出的多层次运动解析框架能够有效捕捉姿态的细微时空变化，为动作质量评估提供了灵活且高性能的解决方案。

Abstract: Human pose serves as a cornerstone of action quality assessment (AQA), where
subtle spatial-temporal variations in pose often distinguish excellence from
mediocrity. In high-level competitions, these nuanced differences become
decisive factors in scoring. In this paper, we propose a novel multi-level
motion parsing framework for AQA based on enhanced spatial-temporal pose
features. On the first level, the Action-Unit Parser is designed with the help
of pose extraction to achieve precise action segmentation and comprehensive
local-global pose representations. On the second level, Motion Parser is used
by spatial-temporal feature learning to capture pose changes and appearance
details for each action-unit. Meanwhile, some special conditions other than
body-related will impact action scoring, like water splash in diving. In this
work, we design an additional Condition Parser to offer users more flexibility
in their choices. Finally, Weight-Adjust Scoring Module is introduced to better
accommodate the diverse requirements of various action types and the
multi-scale nature of action-units. Extensive evaluations on large-scale diving
sports datasets demonstrate that our multi-level motion parsing framework
achieves state-of-the-art performance in both action segmentation and action
scoring tasks.

</details>


### [15] [An Artificial Intelligence-based Assistant for the Visually Impaired](https://arxiv.org/abs/2511.06080)
*Luis Marquez-Carpintero,Francisco Gomez-Donoso,Zuria Bauer,Bessie Dominguez-Dager,Alvaro Belmonte-Baeza,Mónica Pina-Navarro,Francisco Morillas-Espejo,Felix Escalona,Miguel Cazorla*

Main category: cs.CV

TL;DR: AIDEN是一个基于人工智能的辅助应用，旨在通过机器学习算法帮助视障人士识别物体、阅读文本和回答环境问题，提升他们的独立性和生活质量。


<details>
  <summary>Details</summary>
Motivation: 视障人士在识别物体、阅读文本和导航陌生环境方面面临挑战，现有解决方案如盲文、有声读物和屏幕阅读器在某些情况下效果有限，因此需要开发更有效的辅助工具来改善他们的生活质量。

Method: 应用采用最先进的机器学习算法，包括YOLO架构和大型语言视觉助手，通过多种方法促进用户与系统的交互，并以适当方式访问文本和视觉信息。

Result: AIDEN系统增强了用户的自主性和信息获取能力，用户反馈支持了其在日常使用中的实用性感知提升。

Conclusion: AIDEN作为人工智能辅助应用，成功帮助视障人士更好地与环境互动，提高了他们的独立性和生活质量。

Abstract: This paper describes an artificial intelligence-based assistant application,
AIDEN, developed during 2023 and 2024, aimed at improving the quality of life
for visually impaired individuals. Visually impaired individuals face
challenges in identifying objects, reading text, and navigating unfamiliar
environments, which can limit their independence and reduce their quality of
life. Although solutions such as Braille, audio books, and screen readers
exist, they may not be effective in all situations. This application leverages
state-of-the-art machine learning algorithms to identify and describe objects,
read text, and answer questions about the environment. Specifically, it uses
You Only Look Once architectures and a Large Language and Vision Assistant. The
system incorporates several methods to facilitate the user's interaction with
the system and access to textual and visual information in an appropriate
manner. AIDEN aims to enhance user autonomy and access to information,
contributing to an improved perception of daily usability, as supported by user
feedback.

</details>


### [16] [Grounding Foundational Vision Models with 3D Human Poses for Robust Action Recognition](https://arxiv.org/abs/2511.05622)
*Nicholas Babey,Tiffany Gu,Yiheng Li,Cristian Meo,Kevin Zhu*

Main category: cs.CV

TL;DR: 提出了一种融合V-JEPA 2的世界动态预测和CoMotion人体姿态数据的动作识别模型，在复杂遮挡场景下表现优异


<details>
  <summary>Details</summary>
Motivation: 现有基于RGB视频的动作识别模型只能学习表面模式相关性，难以捕捉物理交互动态和复杂场景中的人体姿态，需要将动作识别建立在物理空间理解基础上

Method: 融合V-JEPA 2的上下文预测世界动态和CoMotion的显式抗遮挡人体姿态数据，构建物理空间基础的动作识别模型架构

Result: 在InHARD和UCF-19-Y-OCC基准测试中优于三个基线模型，特别是在复杂遮挡场景下表现突出

Conclusion: 动作识别需要基于空间理解而非统计模式识别

Abstract: For embodied agents to effectively understand and interact within the world
around them, they require a nuanced comprehension of human actions grounded in
physical space. Current action recognition models, often relying on RGB video,
learn superficial correlations between patterns and action labels, so they
struggle to capture underlying physical interaction dynamics and human poses in
complex scenes. We propose a model architecture that grounds action recognition
in physical space by fusing two powerful, complementary representations: V-JEPA
2's contextual, predictive world dynamics and CoMotion's explicit,
occlusion-tolerant human pose data. Our model is validated on both the InHARD
and UCF-19-Y-OCC benchmarks for general action recognition and high-occlusion
action recognition, respectively. Our model outperforms three other baselines,
especially within complex, occlusive scenes. Our findings emphasize a need for
action recognition to be supported by spatial understanding instead of
statistical pattern recognition.

</details>


### [17] [Registration-Free Monitoring of Unstructured Point Cloud Data via Intrinsic Geometrical Properties](https://arxiv.org/abs/2511.05623)
*Mariafrancesca Patalano,Giovanna Capizzi,Kamran Paynabar*

Main category: cs.CV

TL;DR: 提出了一种无需配准和网格重建的点云数据监控方法，利用拉普拉斯和测地距离等内在几何特征进行缺陷检测。


<details>
  <summary>Details</summary>
Motivation: 传统点云数据监控需要配准和网格重建等预处理步骤，这些步骤容易出错、耗时且可能引入伪影，影响监控结果。

Method: 开发了两种替代特征学习方法（基于拉普拉斯和测地距离）和一个通用监控方案，利用形状的内在几何特性，通过阈值技术选择最能指示异常状态的特征。

Result: 数值实验和案例研究表明，该方法能有效识别不同类型的缺陷。

Conclusion: 该方法消除了配准和网格重建的需求，为复杂形状的点云数据监控提供了一种有效的注册自由方法。

Abstract: Modern sensing technologies have enabled the collection of unstructured point
cloud data (PCD) of varying sizes, which are used to monitor the geometric
accuracy of 3D objects. PCD are widely applied in advanced manufacturing
processes, including additive, subtractive, and hybrid manufacturing. To ensure
the consistency of analysis and avoid false alarms, preprocessing steps such as
registration and mesh reconstruction are commonly applied prior to monitoring.
However, these steps are error-prone, time-consuming and may introduce
artifacts, potentially affecting monitoring outcomes. In this paper, we present
a novel registration-free approach for monitoring PCD of complex shapes,
eliminating the need for both registration and mesh reconstruction. Our
proposal consists of two alternative feature learning methods and a common
monitoring scheme. Feature learning methods leverage intrinsic geometric
properties of the shape, captured via the Laplacian and geodesic distances. In
the monitoring scheme, thresholding techniques are used to further select
intrinsic features most indicative of potential out-of-control conditions.
Numerical experiments and case studies highlight the effectiveness of the
proposed approach in identifying different types of defects.

</details>


### [18] [LLM-Driven Completeness and Consistency Evaluation for Cultural Heritage Data Augmentation in Cross-Modal Retrieval](https://arxiv.org/abs/2511.06268)
*Jian Zhang,Junyi Guo,Junyi Yuan,Huanda Lu,Yanlin Zhou,Fangyu Wu,Qiufeng Wang,Dongming Lu*

Main category: cs.CV

TL;DR: 提出C³框架，通过改进LLM生成描述的完整性和一致性来增强跨模态检索性能，在文化遗产和通用数据集上达到最先进效果


<details>
  <summary>Details</summary>
Motivation: 解决文化遗产数据中文本描述不完整和不一致的问题，这些问题源于历史数据丢失和专家标注成本高，同时克服LLM生成描述中的幻觉和视觉细节缺失

Method: C³框架包含完整性评估模块（使用视觉线索和语言模型输出评估语义覆盖）和一致性增强模块（通过马尔可夫决策过程监督思维链推理，进行自适应查询控制）

Result: 在文化遗产数据集CulTi和TimeTravel以及通用基准MSCOCO和Flickr30K上，C³在微调和零样本设置下均达到最先进性能

Conclusion: C³框架通过提升LLM生成描述的完整性和一致性，有效增强了跨模态检索能力，为文化遗产数据解释提供了可靠解决方案

Abstract: Cross-modal retrieval is essential for interpreting cultural heritage data,
but its effectiveness is often limited by incomplete or inconsistent textual
descriptions, caused by historical data loss and the high cost of expert
annotation. While large language models (LLMs) offer a promising solution by
enriching textual descriptions, their outputs frequently suffer from
hallucinations or miss visually grounded details. To address these challenges,
we propose $C^3$, a data augmentation framework that enhances cross-modal
retrieval performance by improving the completeness and consistency of
LLM-generated descriptions. $C^3$ introduces a completeness evaluation module
to assess semantic coverage using both visual cues and language-model outputs.
Furthermore, to mitigate factual inconsistencies, we formulate a Markov
Decision Process to supervise Chain-of-Thought reasoning, guiding consistency
evaluation through adaptive query control. Experiments on the cultural heritage
datasets CulTi and TimeTravel, as well as on general benchmarks MSCOCO and
Flickr30K, demonstrate that $C^3$ achieves state-of-the-art performance in both
fine-tuned and zero-shot settings.

</details>


### [19] [Culture in Action: Evaluating Text-to-Image Models through Social Activities](https://arxiv.org/abs/2511.05681)
*Sina Malakouti,Boqing Gong,Adriana Kovashka*

Main category: cs.CV

TL;DR: CULTIVate是一个评估文本到图像生成模型在跨文化活动方面性能的基准测试，涵盖16个国家、576个提示和19000多张图像，提出了四个评估文化对齐度的指标。


<details>
  <summary>Details</summary>
Motivation: 现有文化基准主要关注物体中心类别，忽视了更能反映文化规范的社会和日常活动，且缺乏衡量文化忠实度的指标。

Method: 构建了涵盖16个国家文化活动的大规模数据集，提供基于可解释描述符的评估框架，包括背景、服装、物体和互动等多个文化维度，并提出了四个评估指标。

Result: 研究发现模型在北方国家表现优于南方国家，不同T2I系统存在不同的失败模式，且提出的指标与人类判断相关性更强。

Conclusion: CULTIVate基准能够有效评估T2I模型的文化忠实度，揭示了模型存在的系统性偏见，为改进跨文化图像生成提供了重要工具。

Abstract: Text-to-image (T2I) diffusion models achieve impressive photorealism by
training on large-scale web data, but models inherit cultural biases and fail
to depict underrepresented regions faithfully. Existing cultural benchmarks
focus mainly on object-centric categories (e.g., food, attire, and
architecture), overlooking the social and daily activities that more clearly
reflect cultural norms. Few metrics exist for measuring cultural faithfulness.
We introduce CULTIVate, a benchmark for evaluating T2I models on cross-cultural
activities (e.g., greetings, dining, games, traditional dances, and cultural
celebrations). CULTIVate spans 16 countries with 576 prompts and more than
19,000 images, and provides an explainable descriptor-based evaluation
framework across multiple cultural dimensions, including background, attire,
objects, and interactions. We propose four metrics to measure cultural
alignment, hallucination, exaggerated elements, and diversity. Our findings
reveal systematic disparities: models perform better for global north countries
than for the global south, with distinct failure modes across T2I systems.
Human studies confirm that our metrics correlate more strongly with human
judgments than existing text-image metrics.

</details>


### [20] [CINEMAE: Leveraging Frozen Masked Autoencoders for Cross-Generator AI Image Detection](https://arxiv.org/abs/2511.06325)
*Minsuk Jang,Hyeonseo Jeong,Minseok Son,Changick Kim*

Main category: cs.CV

TL;DR: CINEMAE是一种新的AIGC图像检测范式，通过将文本检测方法的核心原理应用到视觉领域，利用Masked AutoEncoder的重建过程来量化局部语义异常，实现了强大的跨生成器泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于上下文的文本检测器在AI生成文本检测中表现出良好的泛化能力，但基于图像的检测器仍然容易过拟合到特定生成器的伪影。需要开发一种能够适应视觉领域的上下文检测方法。

Method: 使用Masked AutoEncoder(MAE)重建被遮蔽的图像块，通过计算条件负对数似然来量化局部语义异常，然后将这些补丁级统计量与全局MAE特征通过学习融合进行聚合。

Result: 仅在Stable Diffusion v1.4上训练，在GenImage基准测试的八个未见生成器上实现了超过95%的准确率，显著优于最先进的检测器。

Conclusion: 上下文条件重建不确定性为AIGC检测提供了稳健且可迁移的信号，证明了该方法在跨生成器泛化方面的有效性。

Abstract: While context-based detectors have achieved strong generalization for
AI-generated text by measuring distributional inconsistencies, image-based
detectors still struggle with overfitting to generator-specific artifacts. We
introduce CINEMAE, a novel paradigm for AIGC image detection that adapts the
core principles of text detection methods to the visual domain. Our key insight
is that Masked AutoEncoder (MAE), trained to reconstruct masked patches
conditioned on visible context, naturally encodes semantic consistency
expectations. We formalize this reconstruction process probabilistically,
computing conditional Negative Log-Likelihood (NLL, p(masked | visible)) to
quantify local semantic anomalies. By aggregating these patch-level statistics
with global MAE features through learned fusion, CINEMAE achieves strong
cross-generator generalization. Trained exclusively on Stable Diffusion v1.4,
our method achieves over 95% accuracy on all eight unseen generators in the
GenImage benchmark, substantially outperforming state-of-the-art detectors.
This demonstrates that context-conditional reconstruction uncertainty provides
a robust, transferable signal for AIGC detection.

</details>


### [21] [VMDT: Decoding the Trustworthiness of Video Foundation Models](https://arxiv.org/abs/2511.05682)
*Yujin Potter,Zhun Wang,Nicholas Crispino,Kyle Montgomery,Alexander Xiong,Ethan Y. Chang,Francesco Pinto,Yuqi Chen,Rahul Gupta,Morteza Ziyadi,Christos Christodoulopoulos,Bo Li,Chenguang Wang,Dawn Song*

Main category: cs.CV

TL;DR: VMDT是首个统一评估文本到视频和视频到文本模型可信度的平台，涵盖安全、幻觉、公平、隐私和对抗鲁棒性五个维度。研究发现开源T2V模型普遍存在安全隐患和不公平问题，V2T模型规模增大时公平性和隐私风险上升但幻觉和鲁棒性改善。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型日益复杂，确保其可信度变得至关重要，但视频模态目前缺乏全面的可信度基准测试。

Method: 开发VMDT平台，对7个T2V模型和19个V2T模型在五个可信度维度上进行系统评估。

Result: 开源T2V模型无法识别有害查询并常生成有害视频，不公平性高于图像模型；V2T模型规模增大时公平性和隐私风险上升，但幻觉和鲁棒性改善，安全性不受模型规模影响。

Conclusion: 研究凸显了开发更鲁棒可信视频基础模型的迫切需求，VMDT为衡量和追踪这一目标的进展提供了系统框架。

Abstract: As foundation models become more sophisticated, ensuring their
trustworthiness becomes increasingly critical; yet, unlike text and image, the
video modality still lacks comprehensive trustworthiness benchmarks. We
introduce VMDT (Video-Modal DecodingTrust), the first unified platform for
evaluating text-to-video (T2V) and video-to-text (V2T) models across five key
trustworthiness dimensions: safety, hallucination, fairness, privacy, and
adversarial robustness. Through our extensive evaluation of 7 T2V models and 19
V2T models using VMDT, we uncover several significant insights. For instance,
all open-source T2V models evaluated fail to recognize harmful queries and
often generate harmful videos, while exhibiting higher levels of unfairness
compared to image modality models. In V2T models, unfairness and privacy risks
rise with scale, whereas hallucination and adversarial robustness improve --
though overall performance remains low. Uniquely, safety shows no correlation
with model size, implying that factors other than scale govern current safety
levels. Our findings highlight the urgent need for developing more robust and
trustworthy video foundation models, and VMDT provides a systematic framework
for measuring and tracking progress toward this goal. The code is available at
https://sunblaze-ucb.github.io/VMDT-page/.

</details>


### [22] [Pedicle Screw Pairing and Registration for Screw Pose Estimation from Dual C-arm Images Using CAD Models](https://arxiv.org/abs/2511.05702)
*Yehyun Suh,Lin Li,Aric Plumley,Chaochao Zhou,Daniel Moyer,Kongbin Kang*

Main category: cs.CV

TL;DR: 提出了一种从双C臂图像中解决椎弓根螺钉对应关系和姿态估计的方法，通过比较螺钉组合和2D-3D配准，在配对和配准任务中表现出一致的准确性。


<details>
  <summary>Details</summary>
Motivation: 在脊柱手术中，准确匹配前后位和侧位图像中的椎弓根螺钉对于成功的手术至关重要，特别是在侧位视图中建立螺钉对应关系仍然是一个重要的临床挑战。

Method: 通过比较螺钉组合，并采用螺钉CAD 3D模型进行2D-3D配准，从双视图准确配对和估计螺钉姿态。

Result: 结果显示正确的螺钉组合在所有测试案例中始终优于错误配对，即使在配准前也是如此。配准后，正确组合进一步增强了投影与图像之间的对齐，显著减少了投影误差。

Conclusion: 该方法通过提供可靠的螺钉定位反馈，有望改善脊柱手术的手术效果。

Abstract: Accurate matching of pedicle screws in both anteroposterior (AP) and lateral
(LAT) images is critical for successful spinal decompression and stabilization
during surgery. However, establishing screw correspondence, especially in LAT
views, remains a significant clinical challenge. This paper introduces a method
to address pedicle screw correspondence and pose estimation from dual C-arm
images. By comparing screw combinations, the approach demonstrates consistent
accuracy in both pairing and registration tasks. The method also employs 2D-3D
alignment with screw CAD 3D models to accurately pair and estimate screw pose
from dual views. Our results show that the correct screw combination
consistently outperforms incorrect pairings across all test cases, even prior
to registration. After registration, the correct combination further enhances
alignment between projections and images, significantly reducing projection
error. This approach shows promise for improving surgical outcomes in spinal
procedures by providing reliable feedback on screw positioning.

</details>


### [23] [Long Grounded Thoughts: Distilling Compositional Visual Reasoning Chains at Scale](https://arxiv.org/abs/2511.05705)
*David Acuna,Chao-Han Huck Yang,Yuntian Deng,Jaehun Jung,Ximing Lu,Prithviraj Ammanabrolu,Hyunwoo Kim,Yuan-Hong Liao,Yejin Choi*

Main category: cs.CV

TL;DR: 该论文提出了一个包含超过100万个高质量合成视觉中心问题的新推理数据生成框架，支持多样技能和复杂性级别。通过两阶段合成过程，该数据在多个视觉基准测试中超越了现有模型，并展示了跨模态的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推理进展主要依赖未公开数据集和专有数据合成方法，缺乏系统性构建大规模视觉中心推理数据集的方法，特别是超越视觉数学的任务。

Method: 采用两阶段数据合成框架：规模阶段和复杂性阶段。利用视觉语言模型和推理大语言模型合成推理轨迹，生成包含丰富认知行为的思维链轨迹。

Result: 在Qwen2.5-VL-7B模型上微调后，在所有评估的视觉中心基准测试中超越了所有开放数据基线，甚至超过了MiMo-VL-7B-RL等强封闭数据模型。数据还展现出对纯文本推理和音频推理的跨模态泛化能力。

Conclusion: 高质量数据上的监督微调对有效的在线强化学习至关重要；分阶段离线强化学习能匹配在线强化学习性能同时降低计算需求；精心设计的监督微调能显著改善跨域跨模态迁移能力。

Abstract: Recent progress in multimodal reasoning has been driven largely by
undisclosed datasets and proprietary data synthesis recipes, leaving open
questions about how to systematically build large-scale, vision-centric
reasoning datasets, particularly for tasks that go beyond visual math. In this
work, we introduce a new reasoning data generation framework spanning diverse
skills and levels of complexity with over 1M high-quality synthetic
vision-centric questions. The dataset also includes preference data and
instruction prompts supporting both offline and online RL. Our synthesis
framework proceeds in two stages: (1) scale; and (2) complexity. Reasoning
traces are then synthesized through a two-stage process that leverages VLMs and
reasoning LLMs, producing CoT traces for VLMs that capture the richness and
diverse cognitive behaviors found in frontier reasoning models. Remarkably, we
show that finetuning Qwen2.5-VL-7B on our data outperforms all open-data
baselines across all evaluated vision-centric benchmarks, and even surpasses
strong closed-data models such as MiMo-VL-7B-RL on V* Bench, CV-Bench and
MMStar-V. Perhaps most surprising, despite being entirely vision-centric, our
data transfers positively to text-only reasoning (MMLU-Pro) and audio reasoning
(MMAU), demonstrating its effectiveness. Similarly, despite not containing
videos or embodied visual data, we observe notable gains when evaluating on a
single-evidence embodied QA benchmark (NiEH). Finally, we use our data to
analyze the entire VLM post-training pipeline. Our empirical analysis
highlights that (i) SFT on high-quality data with non-linear reasoning traces
is essential for effective online RL, (ii) staged offline RL matches online
RL's performance while reducing compute demands, and (iii) careful SFT on high
quality data can substantially improve out-of-domain, cross-modality transfer.

</details>


### [24] [Towards Better Ultrasound Video Segmentation Foundation Model: An Empirical study on SAM2 Finetuning from Data Perspective](https://arxiv.org/abs/2511.05731)
*Xing Yao,Ahana Gangopadhyay,Hsi-Ming Chang,Ravi Soni*

Main category: cs.CV

TL;DR: 本文系统研究了SAM2模型在超声视频分割中的适应性问题，发现数据规模和时序上下文比模型架构或初始化更重要，联合训练在模态对齐和任务专业化之间提供了有效平衡。


<details>
  <summary>Details</summary>
Motivation: 超声视频分割面临数据集差异大、运动伪影和标注数据有限等挑战。虽然SAM2等基础模型在零样本和提示引导分割方面表现出色，但在医学影像领域性能显著下降。现有研究主要关注架构修改，而数据特性和训练策略的影响尚未系统研究。

Method: 通过数据中心的视角，分析训练集大小、视频时长和增强方案在三种训练范式（任务特定微调、中间适应、多任务联合训练）下的影响，涵盖五个SAM2变体和多种提示模式。设计了六种超声特定增强方法，并与通用策略进行比较。

Result: 在三个代表性超声数据集上的实验表明，数据规模和时序上下文比模型架构或初始化更具决定性作用。联合训练在模态对齐和任务专业化之间提供了高效的折衷方案。

Conclusion: 这项研究为开发高效、数据感知的SAM2适应流程提供了实证见解，特别适用于超声视频分析领域。

Abstract: Ultrasound (US) video segmentation remains a challenging problem due to
strong inter- and intra-dataset variability, motion artifacts, and limited
annotated data. Although foundation models such as Segment Anything Model 2
(SAM2) demonstrate strong zero-shot and prompt-guided segmentation
capabilities, their performance deteriorates substantially when transferred to
medical imaging domains. Current adaptation studies mainly emphasize
architectural modifications, while the influence of data characteristics and
training regimes has not been systematically examined. In this study, we
present a comprehensive, data-centric investigation of SAM2 adaptation for
ultrasound video segmentation. We analyze how training-set size, video
duration, and augmentation schemes affect adaptation performance under three
paradigms: task-specific fine-tuning, intermediate adaptation, and multi-task
joint training, across five SAM2 variants and multiple prompting modes. We
further design six ultrasound-specific augmentations, assessing their effect
relative to generic strategies. Experiments on three representative ultrasound
datasets reveal that data scale and temporal context play a more decisive role
than model architecture or initialization. Moreover, joint training offers an
efficient compromise between modality alignment and task specialization. This
work aims to provide empirical insights for developing efficient, data-aware
adaptation pipelines for SAM2 in ultrasound video analysis.

</details>


### [25] [TCSA-UDA: Text-Driven Cross-Semantic Alignment for Unsupervised Domain Adaptation in Medical Image Segmentation](https://arxiv.org/abs/2511.05782)
*Lalit Maurya,Honghai Liu,Reyer Zwiggelaar*

Main category: cs.CV

TL;DR: TCSA-UDA是一个基于文本驱动的跨语义对齐框架，利用领域不变的文本类别描述来指导视觉表示学习，通过视觉语言协方差余弦损失和原型对齐模块解决医学图像分割中的无监督域适应问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中的无监督域适应面临显著挑战，特别是CT和MRI等成像模态之间的领域偏移。虽然视觉语言表示学习方法显示出潜力，但在UDA分割任务中的应用仍未被充分探索。

Method: 提出TCSA-UDA框架，包含视觉语言协方差余弦损失来直接对齐图像编码器特征与类间文本语义关系，以及原型对齐模块来跨域对齐类级像素级特征分布。

Result: 在心脏、腹部和脑肿瘤分割基准测试上的广泛实验表明，TCSA-UDA显著减少了领域偏移，并持续优于最先进的UDA方法。

Conclusion: TCSA-UDA为将语言驱动语义集成到领域自适应医学图像分析中建立了一个新范式。

Abstract: Unsupervised domain adaptation for medical image segmentation remains a
significant challenge due to substantial domain shifts across imaging
modalities, such as CT and MRI. While recent vision-language representation
learning methods have shown promise, their potential in UDA segmentation tasks
remains underexplored. To address this gap, we propose TCSA-UDA, a Text-driven
Cross-Semantic Alignment framework that leverages domain-invariant textual
class descriptions to guide visual representation learning. Our approach
introduces a vision-language covariance cosine loss to directly align image
encoder features with inter-class textual semantic relations, encouraging
semantically meaningful and modality-invariant feature representations.
Additionally, we incorporate a prototype alignment module that aligns
class-wise pixel-level feature distributions across domains using high-level
semantic prototypes. This mitigates residual category-level discrepancies and
enhances cross-modal consistency. Extensive experiments on challenging
cross-modality cardiac, abdominal, and brain tumor segmentation benchmarks
demonstrate that our TCSA-UDA framework significantly reduces domain shift and
consistently outperforms state-of-the-art UDA methods, establishing a new
paradigm for integrating language-driven semantics into domain-adaptive medical
image analysis.

</details>


### [26] [MACMD: Multi-dilated Contextual Attention and Channel Mixer Decoding for Medical Image Segmentation](https://arxiv.org/abs/2511.05803)
*Lalit Maurya,Honghai Liu,Reyer Zwiggelaar*

Main category: cs.CV

TL;DR: 本文提出MACMD解码器，通过增强注意力机制和通道混合来解决医学图像分割中局部细节与全局上下文整合不足的问题，在二元和多器官分割任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临解剖结构变化的挑战，CNN难以建模长距离依赖，Transformer缺乏局部上下文信息，现有编码器-解码器架构存在浅层细节丢失和局部-全局信息整合效率低的问题。

Method: 提出MACMD解码器，采用层次化扩张卷积、注意力驱动调制和跨通道混合模块，通过跳跃连接增强编码器与解码器之间的通道混合，在保持局部上下文细节的同时捕获长距离依赖。

Result: 在多个Transformer编码器上评估二元和多器官分割任务，方法在Dice分数和计算效率方面优于最先进方法。

Conclusion: MACMD方法通过改进的注意力机制和通道混合实现了准确鲁棒的医学图像分割性能，代码已开源。

Abstract: Medical image segmentation faces challenges due to variations in anatomical
structures. While convolutional neural networks (CNNs) effectively capture
local features, they struggle with modeling long-range dependencies.
Transformers mitigate this issue with self-attention mechanisms but lack the
ability to preserve local contextual information. State-of-the-art models
primarily follow an encoder-decoder architecture, achieving notable success.
However, two key limitations remain: (1) Shallow layers, which are closer to
the input, capture fine-grained details but suffer from information loss as
data propagates through deeper layers. (2) Inefficient integration of local
details and global context between the encoder and decoder stages. To address
these challenges, we propose the MACMD-based decoder, which enhances attention
mechanisms and facilitates channel mixing between encoder and decoder stages
via skip connections. This design leverages hierarchical dilated convolutions,
attention-driven modulation, and a cross channel-mixing module to capture
long-range dependencies while preserving local contextual details, essential
for precise medical image segmentation. We evaluated our approach using
multiple transformer encoders on both binary and multi-organ segmentation
tasks. The results demonstrate that our method outperforms state-of-the-art
approaches in terms of Dice score and computational efficiency, highlighting
its effectiveness in achieving accurate and robust segmentation performance.
The code available at https://github.com/lalitmaurya47/MACMD

</details>


### [27] [LRANet++: Low-Rank Approximation Network for Accurate and Efficient Text Spotting](https://arxiv.org/abs/2511.05818)
*Yuchen Su,Zhineng Chen,Yongkun Du,Zuxuan Wu,Hongtao Xie,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: LRANet++是一个端到端的任意形状文本检测识别框架，通过低秩逼近的参数化文本形状方法和三重分配检测头，实现了精确高效的文本检测，并与轻量级识别分支集成。


<details>
  <summary>Details</summary>
Motivation: 当前端到端文本检测识别框架在任意形状文本处理上仍存在瓶颈，主要原因是缺乏可靠高效的文本检测方法。

Method: 提出基于低秩逼近的数据驱动参数化文本形状方法，使用ℓ1-范数公式进行鲁棒恢复；采用三重分配检测头架构，包含深度稀疏分支、超轻量稀疏分支和密集分支；将增强的检测模块与轻量识别分支集成。

Result: 在多个挑战性基准测试上的广泛实验表明，LRANet++相比最先进方法具有优越性。

Conclusion: LRANet++能够准确高效地检测任意形状文本，解决了端到端文本检测识别中的关键瓶颈问题。

Abstract: End-to-end text spotting aims to jointly optimize text detection and
recognition within a unified framework. Despite significant progress, designing
an accurate and efficient end-to-end text spotter for arbitrary-shaped text
remains largely unsolved. We identify the primary bottleneck as the lack of a
reliable and efficient text detection method. To address this, we propose a
novel parameterized text shape method based on low-rank approximation for
precise detection and a triple assignment detection head to enable fast
inference. Specifically, unlike other shape representation methods that employ
data-irrelevant parameterization, our data-driven approach derives a low-rank
subspace directly from labeled text boundaries. To ensure this process is
robust against the inherent annotation noise in this data, we utilize a
specialized recovery method based on an $\ell_1$-norm formulation, which
accurately reconstructs the text shape with only a few key orthogonal vectors.
By exploiting the inherent shape correlation among different text contours, our
method achieves consistency and compactness in shape representation. Next, the
triple assignment scheme introduces a novel architecture where a deep sparse
branch (for stabilized training) is used to guide the learning of an
ultra-lightweight sparse branch (for accelerated inference), while a dense
branch provides rich parallel supervision. Building upon these advancements, we
integrate the enhanced detection module with a lightweight recognition branch
to form an end-to-end text spotting framework, termed LRANet++, capable of
accurately and efficiently spotting arbitrary-shaped text. Extensive
experiments on several challenging benchmarks demonstrate the superiority of
LRANet++ compared to state-of-the-art methods. Code will be available at:
https://github.com/ychensu/LRANet-PP.git

</details>


### [28] [Hilbert-Guided Block-Sparse Local Attention](https://arxiv.org/abs/2511.05832)
*Yunge Li,Lanyu Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于希尔伯特曲线的新型局部注意力方法，通过重新排列图像标记来提高块稀疏性，从而显著加速2D局部注意力。


<details>
  <summary>Details</summary>
Motivation: 全局自注意力的二次计算和内存成本限制了其在高分辨率图像中的应用，而传统局部注意力模式由于窗口内标记在1D序列中不连续，往往无法实现显著加速。

Method: 使用希尔伯特曲线对图像标记进行重新排序，然后在重新排序的1D序列上形成窗口和邻域，结合现有的块稀疏核来提高2D局部注意力的效率。

Result: 实验表明，提出的希尔伯特窗口注意力和希尔伯特滑动注意力分别能将窗口注意力和滑动注意力加速约4倍和18倍，在最小精度损失下实现端到端加速。

Conclusion: 将希尔伯特引导的局部注意力与块稀疏核相结合，为增强图像2D局部注意力的效率提供了一种通用且实用的方法。

Abstract: The quadratic compute and memory costs of global self-attention severely
limit its use in high-resolution images. Local attention reduces complexity by
restricting attention to neighborhoods. Block-sparse kernels can further
improve the efficiency of local attention, but conventional local attention
patterns often fail to deliver significant speedups because tokens within a
window are not contiguous in the 1D sequence. This work proposes a novel method
for constructing windows and neighborhoods based on the Hilbert curve. Image
tokens are first reordered along a Hilbert curve, and windows and neighborhoods
are then formed on the reordered 1D sequence. From a block-sparse perspective,
this strategy significantly increases block sparsity and can be combined with
existing block-sparse kernels to improve the efficiency of 2D local attention.
Experiments show that the proposed Hilbert Window Attention and Hilbert Slide
Attention can accelerate window attention and slide attention by about
$4\times$ and $18\times$, respectively. To assess practicality, the strategy is
instantiated as the Hilbert Window Transformer and the Hilbert Neighborhood
Transformer, both of which achieve end-to-end speedups with minimal accuracy
loss. Overall, combining Hilbert-guided local attention with block-sparse
kernels offers a general and practical approach to enhancing the efficiency of
2D local attention for images. The code is available at
https://github.com/Yunge6666/Hilbert-Local-Attention.

</details>


### [29] [Understanding Cross Task Generalization in Handwriting-Based Alzheimer's Screening via Vision Language Adaptation](https://arxiv.org/abs/2511.05841)
*Changqing Gong,Huafeng Qin,Mounim A. El-Yacoubi*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级跨层融合适配器框架，利用CLIP模型进行基于笔迹的阿尔茨海默病筛查，系统研究了不同任务类型对诊断性能和跨任务泛化能力的影响。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测至关重要，笔迹变化提供了非侵入性且成本效益高的检测窗口。现有研究主要依赖在线轨迹和手工特征，未系统研究任务类型对诊断性能的影响，同时大规模视觉语言模型在笔迹疾病检测方面尚未充分探索。

Method: 引入轻量级跨层融合适配器框架，在视觉编码器中植入多级融合适配器，逐步对齐笔迹特定的医学特征表示，实现无需提示词的高效零样本推理。

Result: 系统研究了跨任务泛化能力，揭示了哪些任务类型和书写模式最能有效区分阿尔茨海默病，并识别了特征性笔画模式和任务级因素。

Conclusion: 该框架为基于笔迹的认知评估提供了诊断见解和基准，展示了在笔迹疾病检测中应用大规模视觉语言模型的潜力。

Abstract: Alzheimer's disease is a prevalent neurodegenerative disorder for which early
detection is critical. Handwriting-often disrupted in prodromal AD-provides a
non-invasive and cost-effective window into subtle motor and cognitive decline.
Existing handwriting-based AD studies, mostly relying on online trajectories
and hand-crafted features, have not systematically examined how task type
influences diagnostic performance and cross-task generalization. Meanwhile,
large-scale vision language models have demonstrated remarkable zero or
few-shot anomaly detection in natural images and strong adaptability across
medical modalities such as chest X-ray and brain MRI. However,
handwriting-based disease detection remains largely unexplored within this
paradigm. To close this gap, we introduce a lightweight Cross-Layer Fusion
Adapter framework that repurposes CLIP for handwriting-based AD screening. CLFA
implants multi-level fusion adapters within the visual encoder to progressively
align representations toward handwriting-specific medical cues, enabling
prompt-free and efficient zero-shot inference. Using this framework, we
systematically investigate cross-task generalization-training on a specific
handwriting task and evaluating on unseen ones-to reveal which task types and
writing patterns most effectively discriminate AD. Extensive analyses further
highlight characteristic stroke patterns and task-level factors that contribute
to early AD identification, offering both diagnostic insights and a benchmark
for handwriting-based cognitive assessment.

</details>


### [30] [Enhancing Diffusion Model Guidance through Calibration and Regularization](https://arxiv.org/abs/2511.05844)
*Seyed Alireza Javid,Amirhossein Bagheri,Nuria González-Prelcic*

Main category: cs.CV

TL;DR: 本文针对分类器引导扩散模型中早期去噪步骤预测过于自信导致梯度消失的问题，提出了两种互补的解决方案：基于平滑预期校准误差的可微校准目标和无需重新训练的增强采样引导方法。


<details>
  <summary>Details</summary>
Motivation: 分类器引导扩散模型在条件图像生成中表现出色，但在早期去噪步骤中分类器预测过于自信，导致引导梯度消失，影响生成质量。

Method: 1) 提出基于平滑预期校准误差的可微校准目标，通过最小化微调改善分类器校准；2) 开发增强采样引导方法，包括批量重加权倾斜采样、自适应熵正则化采样和新型f散度采样策略。

Result: 在ImageNet 128x128数据集上，使用ResNet-101分类器的f散度正则化引导方法实现了2.13的FID分数，优于现有分类器引导扩散方法，且无需扩散模型重新训练。

Conclusion: 原则性校准和散度感知采样为分类器引导扩散提供了实用且有效的改进，显著提升了生成质量。

Abstract: Classifier-guided diffusion models have emerged as a powerful approach for
conditional image generation, but they suffer from overconfident predictions
during early denoising steps, causing the guidance gradient to vanish. This
paper introduces two complementary contributions to address this issue. First,
we propose a differentiable calibration objective based on the Smooth Expected
Calibration Error (Smooth ECE), which improves classifier calibration with
minimal fine-tuning and yields measurable improvements in Frechet Inception
Distance (FID). Second, we develop enhanced sampling guidance methods that
operate on off-the-shelf classifiers without requiring retraining. These
include tilted sampling with batch-level reweighting, adaptive
entropy-regularized sampling to preserve diversity, and a novel
f-divergence-based sampling strategy that strengthens class-consistent guidance
while maintaining mode coverage. Experiments on ImageNet 128x128 demonstrate
that our divergence-regularized guidance achieves an FID of 2.13 using a
ResNet-101 classifier, improving upon existing classifier-guided diffusion
methods while requiring no diffusion model retraining. The results show that
principled calibration and divergence-aware sampling provide practical and
effective improvements for classifier-guided diffusion.

</details>


### [31] [CGCE: Classifier-Guided Concept Erasure in Generative Models](https://arxiv.org/abs/2511.05865)
*Viet Nguyen,Vishal M. Patel*

Main category: cs.CV

TL;DR: 提出了Classifier-Guided Concept Erasure (CGCE)框架，通过轻量级分类器检测和优化包含不良概念的文本嵌入，实现无需修改模型权重的鲁棒概念擦除。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法容易受到对抗攻击，且鲁棒擦除往往会降低模型对安全概念的生成质量，需要在安全性和性能之间做出权衡。

Method: 使用在文本嵌入上运行的轻量级分类器，首先检测然后优化包含不良概念的提示词。该方法具有高度可扩展性，可以通过聚合多个分类器的指导来实现多概念擦除。

Result: CGCE在广泛的红队攻击下实现了最先进的鲁棒性，同时保持了高生成效用，在安全性和性能之间实现了优越的平衡。

Conclusion: CGCE是一个实用有效的安全生成AI解决方案，成功应用于各种现代T2I和T2V模型，展示了其多功能性。

Abstract: Recent advancements in large-scale generative models have enabled the
creation of high-quality images and videos, but have also raised significant
safety concerns regarding the generation of unsafe content. To mitigate this,
concept erasure methods have been developed to remove undesirable concepts from
pre-trained models. However, existing methods remain vulnerable to adversarial
attacks that can regenerate the erased content. Moreover, achieving robust
erasure often degrades the model's generative quality for safe, unrelated
concepts, creating a difficult trade-off between safety and performance. To
address this challenge, we introduce Classifier-Guided Concept Erasure (CGCE),
an efficient plug-and-play framework that provides robust concept erasure for
diverse generative models without altering their original weights. CGCE uses a
lightweight classifier operating on text embeddings to first detect and then
refine prompts containing undesired concepts. This approach is highly scalable,
allowing for multi-concept erasure by aggregating guidance from several
classifiers. By modifying only unsafe embeddings at inference time, our method
prevents harmful content generation while preserving the model's original
quality on benign prompts. Extensive experiments show that CGCE achieves
state-of-the-art robustness against a wide range of red-teaming attacks. Our
approach also maintains high generative utility, demonstrating a superior
balance between safety and performance. We showcase the versatility of CGCE
through its successful application to various modern T2I and T2V models,
establishing it as a practical and effective solution for safe generative AI.

</details>


### [32] [Light-Field Dataset for Disparity Based Depth Estimation](https://arxiv.org/abs/2511.05866)
*Suresh Nehra,Aupendu Kar,Jayanta Mukhopadhyay,Prabir Kumar Biswas*

Main category: cs.CV

TL;DR: 本文介绍了一个公开可用的光场图像数据集，包含285张真实光场图像和13张合成光场图像，用于支持基于视差的光场深度估计算法的开发与测试。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏合适的光场图像数据集来支持新型视差光场深度估计算法的设计、开发、实现和测试，同时现有数据集存在局限性。

Method: 使用Lytro Illum光场相机采集285张真实光场图像，并创建13张合成光场图像，同时构建了具有类似真实光场相机视差特性的合成数据集以及真实和合成的立体光场数据集。

Result: 成功构建了一个包含285张真实光场图像和13张合成光场图像的公开数据集，并展示了焦距位置对3D点视差的影响，同时指出了现有数据集的不足。

Conclusion: 提出的光场数据集为光场深度估计算法的研究和开发提供了重要资源，数据集已在GitHub上公开可用。

Abstract: A Light Field (LF) camera consists of an additional two-dimensional array of
micro-lenses placed between the main lens and sensor, compared to a
conventional camera. The sensor pixels under each micro-lens receive light from
a sub-aperture of the main lens. This enables the image sensor to capture both
spatial information and the angular resolution of a scene point. This
additional angular information is used to estimate the depth of a 3-D scene.
The continuum of virtual viewpoints in light field data enables efficient depth
estimation using Epipolar Line Images (EPIs) with robust occlusion handling.
However, the trade-off between angular information and spatial information is
very critical and depends on the focal position of the camera. To design,
develop, implement, and test novel disparity-based light field depth estimation
algorithms, the availability of suitable light field image datasets is
essential. In this paper, a publicly available light field image dataset is
introduced and thoroughly described. We have also demonstrated the effect of
focal position on the disparity of a 3-D point as well as the shortcomings of
the currently available light field dataset. The proposed dataset contains 285
light field images captured using a Lytro Illum LF camera and 13 synthetic LF
images. The proposed dataset also comprises a synthetic dataset with similar
disparity characteristics to those of a real light field camera. A real and
synthetic stereo light field dataset is also created by using a mechanical
gantry system and Blender. The dataset is available at
https://github.com/aupendu/light-field-dataset.

</details>


### [33] [Hybrid second-order gradient histogram based global low-rank sparse regression for robust face recognition](https://arxiv.org/abs/2511.05893)
*Hongxia Li,Ying Ji,Yongxin Dong,Yuehua Feng*

Main category: cs.CV

TL;DR: 本文提出了一种基于混合二阶梯度直方图的全局低秩稀疏回归模型（H2H-GLRSR），用于解决人脸识别中复杂遮挡和光照变化带来的挑战。该方法结合了新的特征描述符和全局低秩约束，在遮挡、光照变化等挑战性场景下显著优于现有回归分类方法。


<details>
  <summary>Details</summary>
Motivation: 解决人脸识别中复杂遮挡和光照变化带来的挑战，现有低秩稀疏回归模型在这些挑战性场景下表现不足。

Method: 1. 设计混合二阶梯度直方图（H2H）特征描述符来更有效地表征面部图像的局部结构特征；2. 将该描述符与基于稀疏正则化核范数的矩阵回归（SR_NMR）集成；3. 对残差矩阵施加全局低秩约束以更好地捕捉结构化噪声中的全局相关性。

Result: 实验结果表明，在涉及遮挡、光照变化和非约束环境的挑战性场景下，所提出的方法显著优于现有的基于回归的分类方法。

Conclusion: H2H-GLRSR模型通过结合新型特征描述符和全局低秩约束，有效提升了人脸识别在复杂环境下的性能，为处理遮挡和光照变化问题提供了有效解决方案。

Abstract: Low-rank sparse regression models have been widely applied in the field of
face recognition. To further address the challenges caused by complex
occlusions and illumination variations, this paper proposes a Hybrid
Second-Order Gradient Histogram based Global Low-Rank Sparse Regression
(H2H-GLRSR) model. Specifically, a novel feature descriptor called the Hybrid
Second-Order Gradient Histogram (H2H) is first designed to more effectively
characterize the local structural features of facial images. Then, this
descriptor is integrated with the Sparse Regularized Nuclear Norm based Matrix
Regression (SR$\_$NMR). Moreover, a global low-rank constraint is imposed on
the residual matrix, enabling the model to better capture the global
correlations inherent in structured noise. Experimental results demonstrate
that the proposed method significantly outperforms existing regression-based
classification approaches under challenging scenarios involving occlusions,
illumination changes, and unconstrained environments.

</details>


### [34] [Open-World 3D Scene Graph Generation for Retrieval-Augmented Reasoning](https://arxiv.org/abs/2511.05894)
*Fei Yu,Quan Deng,Shengeng Tang,Yuehua Li,Lechao Cheng*

Main category: cs.CV

TL;DR: 提出了一种开放世界3D场景图生成的统一框架，结合检索增强推理，支持多模态探索和语言引导交互，在多个基准测试中表现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决开放世界环境中3D场景理解的挑战，特别是封闭词汇监督和静态标注的限制问题。

Method: 集成视觉语言模型与基于检索的推理，包含动态场景图生成模块和检索增强推理管道，将场景图编码到向量数据库支持文本/图像条件查询。

Result: 在3DSSG和Replica基准测试的四个任务（场景问答、视觉定位、实例检索和任务规划）中表现出稳健的泛化性和优越性能。

Conclusion: 结合开放词汇感知与基于检索的推理对于可扩展的3D场景理解是有效的。

Abstract: Understanding 3D scenes in open-world settings poses fundamental challenges
for vision and robotics, particularly due to the limitations of
closed-vocabulary supervision and static annotations. To address this, we
propose a unified framework for Open-World 3D Scene Graph Generation with
Retrieval-Augmented Reasoning, which enables generalizable and interactive 3D
scene understanding. Our method integrates Vision-Language Models (VLMs) with
retrieval-based reasoning to support multimodal exploration and language-guided
interaction. The framework comprises two key components: (1) a dynamic scene
graph generation module that detects objects and infers semantic relationships
without fixed label sets, and (2) a retrieval-augmented reasoning pipeline that
encodes scene graphs into a vector database to support text/image-conditioned
queries. We evaluate our method on 3DSSG and Replica benchmarks across four
tasks-scene question answering, visual grounding, instance retrieval, and task
planning-demonstrating robust generalization and superior performance in
diverse environments. Our results highlight the effectiveness of combining
open-vocabulary perception with retrieval-based reasoning for scalable 3D scene
understanding.

</details>


### [35] [GABFusion: Rethinking Feature Fusion for Low-Bit Quantization of Multi-Task Networks](https://arxiv.org/abs/2511.05898)
*Zhaoyang Wang,Dong Wang*

Main category: cs.CV

TL;DR: 提出了GABFusion和ADA方法来解决多任务架构量化感知训练中的性能下降问题，通过动态平衡梯度幅度和量化友好的特征融合来提升量化模型性能。


<details>
  <summary>Details</summary>
Motivation: 多任务架构的量化感知训练由于任务特定特征差异和梯度冲突导致性能显著下降，需要解决这些挑战来提升量化模型在多任务场景下的表现。

Method: 提出Gradient-Aware Balanced Feature Fusion (GABFusion)动态平衡梯度幅度和融合任务特定特征，以及Attention Distribution Alignment (ADA)特征级蒸馏策略。

Result: 在PASCAL VOC和COCO数据集上分别实现约3.3%和1.6%的平均mAP提升，在YOLOv5的4位量化下与全精度模型的准确率差距缩小到仅1.7%。

Conclusion: 该方法具有强泛化能力，兼容现有QAT技术，模块化设计易于集成，能有效保持低比特约束下的性能。

Abstract: Despite the effectiveness of quantization-aware training (QAT) in compressing
deep neural networks, its performance on multi-task architectures often
degrades significantly due to task-specific feature discrepancies and gradient
conflicts. To address these challenges, we propose Gradient-Aware Balanced
Feature Fusion (GABFusion), which dynamically balances gradient magnitudes and
fuses task-specific features in a quantization-friendly manner. We further
introduce Attention Distribution Alignment (ADA), a feature-level distillation
strategy tailored for quantized models. Our method demonstrates strong
generalization across network architectures and QAT algorithms, with
theoretical guarantees on gradient bias reduction. Extensive experiments
demonstrate that our strategy consistently enhances a variety of QAT methods
across different network architectures and bit-widths. On PASCAL VOC and COCO
datasets, the proposed approach achieves average mAP improvements of
approximately 3.3% and 1.6%, respectively. When applied to YOLOv5 under 4-bit
quantization, our method narrows the accuracy gap with the full-precision model
to only 1.7% on VOC, showcasing its effectiveness in preserving performance
under low-bit constraints. Notably, the proposed framework is modular, easy to
integrate, and compatible with any existing QAT technique-enhancing the
performance of quantized models without requiring modifications to the original
network architecture.

</details>


### [36] [CoMA: Complementary Masking and Hierarchical Dynamic Multi-Window Self-Attention in a Unified Pre-training Framework](https://arxiv.org/abs/2511.05929)
*Jiaxuan Li,Qing Xu,Xiangjian He,Ziyu Liu,Chang Xing,Zhen Chen,Daokun Zhang,Rong Qu,Chang Wen Chen*

Main category: cs.CV

TL;DR: 提出CoMA和DyViT方法，通过互补掩码策略和动态多窗口自注意力机制，显著提升MAE预训练效率和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决MAE中随机掩码需要更多预训练轮次的问题，以及ViT在MAE中参数使用效率低的问题。

Method: 采用互补掩码策略确保所有像素均匀采样，引入动态多窗口自注意力的分层视觉变换器DyViT。

Result: 在ImageNet-1K上预训练，仅需MAE 12%的轮次即可达到同等下游性能，每轮预训练时间减少10%。

Conclusion: CoMA和DyViT显著提升了预训练效率和模型适应性，实现了更有效的特征学习。

Abstract: Masked Autoencoders (MAE) achieve self-supervised learning of image
representations by randomly removing a portion of visual tokens and
reconstructing the original image as a pretext task, thereby significantly
enhancing pretraining efficiency and yielding excellent adaptability across
downstream tasks. However, MAE and other MAE-style paradigms that adopt random
masking generally require more pre-training epochs to maintain adaptability.
Meanwhile, ViT in MAE suffers from inefficient parameter use due to fixed
spatial resolution across layers. To overcome these limitations, we propose the
Complementary Masked Autoencoders (CoMA), which employ a complementary masking
strategy to ensure uniform sampling across all pixels, thereby improving
effective learning of all features and enhancing the model's adaptability.
Furthermore, we introduce DyViT, a hierarchical vision transformer that employs
a Dynamic Multi-Window Self-Attention (DM-MSA), significantly reducing the
parameters and FLOPs while improving fine-grained feature learning. Pre-trained
on ImageNet-1K with CoMA, DyViT matches the downstream performance of MAE using
only 12% of the pre-training epochs, demonstrating more effective learning. It
also attains a 10% reduction in pre-training time per epoch, further
underscoring its superior pre-training efficiency.

</details>


### [37] [AD-DAE: Unsupervised Modeling of Longitudinal Alzheimer's Disease Progression with Diffusion Auto-Encoder](https://arxiv.org/abs/2511.05934)
*Ayantika Das,Arunima Sarkar,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: 提出了一种条件化扩散自编码器框架，用于在无监督情况下从基线图像生成疾病进展图像，通过控制潜在空间中的移动来分离进展相关因素与身份保留组件。


<details>
  <summary>Details</summary>
Motivation: 现有生成建模方法在捕捉疾病进展时对分布学习施加约束，导致潜在空间可控性有限，无法在没有受试者特定纵向图像监督的情况下生成随访图像。

Method: 采用条件化扩散自编码器框架，利用其显式编码机制形成紧凑的潜在空间，通过限制偏移到子空间来分离进展相关因素，并隐式关联进展属性来引导偏移。

Result: 在阿尔茨海默病数据集上通过图像质量指标、体积进展分析和下游分类验证了生成效果，证明了该方法在疾病进展建模和纵向图像生成方面的有效性。

Conclusion: 该方法能够以无监督方式从基线图像生成疾病进展图像，为阿尔茨海默病进展建模提供了有效解决方案。

Abstract: Generative modeling frameworks have emerged as an effective approach to
capture high-dimensional image distributions from large datasets without
requiring domain-specific knowledge, a capability essential for longitudinal
disease progression modeling. Recent generative modeling approaches have
attempted to capture progression by mapping images into a latent
representational space and then controlling and guiding the representations to
generate follow-up images from a baseline image. However, existing approaches
impose constraints on distribution learning, leading to latent spaces with
limited controllability to generate follow-up images without explicit
supervision from subject-specific longitudinal images. In order to enable
controlled movements in the latent representational space and generate
progression images from a baseline image in an unsupervised manner, we
introduce a conditionable Diffusion Auto-encoder framework. The explicit
encoding mechanism of image-diffusion auto-encoders forms a compact latent
space capturing high-level semantics, providing means to disentangle
information relevant for progression. Our approach leverages this latent space
to condition and apply controlled shifts to baseline representations for
generating follow-up. Controllability is induced by restricting these shifts to
a subspace, thereby isolating progression-related factors from subject
identity-preserving components. The shifts are implicitly guided by correlating
with progression attributes, without requiring subject-specific longitudinal
supervision. We validate the generations through image quality metrics,
volumetric progression analysis, and downstream classification in Alzheimer's
disease datasets from two different sources and disease categories. This
demonstrates the effectiveness of our approach for Alzheimer's progression
modeling and longitudinal image generation.

</details>


### [38] [Interaction-Centric Knowledge Infusion and Transfer for Open-Vocabulary Scene Graph Generation](https://arxiv.org/abs/2511.05935)
*Lin Li,Chuhan Zhang,Dong Zhang,Chong Sun,Chen Li,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于交互中心范式的端到端开放词汇场景图生成框架ACC，通过双向交互提示和交互引导的知识蒸馏来解决现有方法在交互建模方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的开放词汇场景图生成方法缺乏明确的交互建模，难以区分同一类别中交互和非交互的实例，导致在知识注入阶段产生噪声伪监督，在知识迁移阶段产生模糊查询匹配。

Method: 提出ACC框架：1）交互中心知识注入使用双向交互提示生成鲁棒的伪监督；2）交互中心知识迁移采用交互引导的查询选择和交互一致的知识蒸馏。

Result: 在三个基准测试上的广泛实验结果表明，ACC实现了最先进的性能。

Conclusion: 交互中心范式在开放词汇场景图生成中具有显著优势，为实际应用展示了潜力。

Abstract: Open-vocabulary scene graph generation (OVSGG) extends traditional SGG by
recognizing novel objects and relationships beyond predefined categories,
leveraging the knowledge from pre-trained large-scale models. Existing OVSGG
methods always adopt a two-stage pipeline: 1) \textit{Infusing knowledge} into
large-scale models via pre-training on large datasets; 2) \textit{Transferring
knowledge} from pre-trained models with fully annotated scene graphs during
supervised fine-tuning. However, due to a lack of explicit interaction
modeling, these methods struggle to distinguish between interacting and
non-interacting instances of the same object category. This limitation induces
critical issues in both stages of OVSGG: it generates noisy pseudo-supervision
from mismatched objects during knowledge infusion, and causes ambiguous query
matching during knowledge transfer. To this end, in this paper, we propose an
inter\textbf{AC}tion-\textbf{C}entric end-to-end OVSGG framework (\textbf{ACC})
in an interaction-driven paradigm to minimize these mismatches. For
\textit{interaction-centric knowledge infusion}, ACC employs a bidirectional
interaction prompt for robust pseudo-supervision generation to enhance the
model's interaction knowledge. For \textit{interaction-centric knowledge
transfer}, ACC first adopts interaction-guided query selection that prioritizes
pairing interacting objects to reduce interference from non-interacting ones.
Then, it integrates interaction-consistent knowledge distillation to bolster
robustness by pushing relational foreground away from the background while
retaining general knowledge. Extensive experimental results on three benchmarks
show that ACC achieves state-of-the-art performance, demonstrating the
potential of interaction-centric paradigms for real-world applications.

</details>


### [39] [Polymap: generating high definition map based on rasterized polygons](https://arxiv.org/abs/2511.05944)
*Shiyu Gao,Hao Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种基于实例分割的高清地图感知方法，将道路元素重新解释为栅格化多边形，通过端到端的分割transformer生成实例掩码，再使用Potrace后处理模块输出矢量化地图元素，以提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于检测的高清地图构建方法（如Maptr系列）虽然能够实时构建，但缺乏鲁棒的泛化能力，限制了在自动标注系统中的应用。

Method: 采用基于实例分割的简洁框架：首先使用分割transformer端到端生成实例掩码，然后通过Potrace后处理模块将栅格化多边形转换为矢量化地图元素。

Result: 在Nuscene数据集上的定量结果验证了该方法的有效性和泛化能力。

Conclusion: 基于实例分割的方法相比检测方法具有更好的泛化性能，能够有效提升高清地图感知的鲁棒性。

Abstract: The perception of high-definition maps is an integral component of
environmental perception in autonomous driving systems. Existing research have
often focused on online construction of high-definition maps. For instance, the
Maptr[9] series employ a detection-based method to output vectorized map
instances parallelly in an end-to-end manner. However, despite their capability
for real-time construction, detection-based methods are observed to lack robust
generalizability[19], which hampers their applicability in auto-labeling
systems. Therefore, aiming to improve the generalizability, we reinterpret road
elements as rasterized polygons and design a concise framework based on
instance segmentation. Initially, a segmentation-based transformer is employed
to deliver instance masks in an end-to-end manner; succeeding this step, a
Potrace-based[17] post-processing module is used to ultimately yield vectorized
map elements. Quantitative results attained on the Nuscene[1] dataset
substantiate the effectiveness and generaliz-ability of our method.

</details>


### [40] [U(PM)$^2$:Unsupervised polygon matching with pre-trained models for challenging stereo images](https://arxiv.org/abs/2511.05949)
*Chang Li,Xingtao Peng*

Main category: cs.CV

TL;DR: 本文提出了一种名为U(PM)^2的低成本无监督多边形匹配方法，通过结合预训练模型和手工特征，解决了立体图像多边形匹配中的视差不连续性、尺度变化、训练需求和泛化能力等挑战。


<details>
  <summary>Details</summary>
Motivation: 立体图像匹配是计算机视觉、摄影测量和遥感领域的基础任务，但多边形匹配这一领域几乎未被探索，面临着视差不连续性、尺度变化、训练需求和泛化能力等挑战。

Method: 首先利用预训练的Segment Anything模型获取掩码，然后将掩码转换为多边形和图形结构；全局匹配器基于预训练的LoFTR采用双向金字塔策略处理全局视角变化和尺度变化；局部匹配器通过局部联合几何和多特征匹配策略结合匈牙利算法克服局部视差不连续性和多边形匹配的拓扑不一致性。

Result: 在ScanNet和SceneFlow数据集上使用新提出的评估指标进行基准测试，实现了最先进的精度，在竞争速度下具有满意的泛化性能，且无需任何训练要求。

Conclusion: U(PM)^2方法在无需训练的情况下，以低成本实现了多边形匹配的最先进性能，具有良好的泛化能力和实用性。

Abstract: Stereo image matching is a fundamental task in computer vision,
photogrammetry and remote sensing, but there is an almost unexplored field,
i.e., polygon matching, which faces the following challenges: disparity
discontinuity, scale variation, training requirement, and generalization. To
address the above-mentioned issues, this paper proposes a novel U(PM)$^2$:
low-cost unsupervised polygon matching with pre-trained models by uniting
automatically learned and handcrafted features, of which pipeline is as
follows: firstly, the detector leverages the pre-trained segment anything model
to obtain masks; then, the vectorizer converts the masks to polygons and
graphic structure; secondly, the global matcher addresses challenges from
global viewpoint changes and scale variation based on bidirectional-pyramid
strategy with pre-trained LoFTR; finally, the local matcher further overcomes
local disparity discontinuity and topology inconsistency of polygon matching by
local-joint geometry and multi-feature matching strategy with Hungarian
algorithm. We benchmark our U(PM)$^2$ on the ScanNet and SceneFlow datasets
using our proposed new metric, which achieved state-of-the-art accuracy at a
competitive speed and satisfactory generalization performance at low cost
without any training requirement.

</details>


### [41] [CSGaze: Context-aware Social Gaze Prediction](https://arxiv.org/abs/2511.05955)
*Surbhi Madan,Shreya Ghosh,Ramanathan Subramanian,Abhinav Dhall,Tom Gedeon*

Main category: cs.CV

TL;DR: CSGaze是一个基于上下文感知的多模态方法，利用面部和场景信息来预测社交凝视模式，通过注意力机制聚焦主要说话者，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究如何结合上下文线索、视觉场景和面部信息来预测和解释对话互动中的社交凝视模式，因为凝视能反映人的注意力焦点、社交参与度和自信程度。

Method: 提出CSGaze模型，利用面部和场景信息作为互补输入，采用细粒度注意力机制聚焦主要说话者来建模社交凝视动态。

Result: CSGaze在GP-Static、UCO-LAEO和AVA-LAEO数据集上与最先进方法竞争性表现，并通过注意力分数提供初步可解释性。

Conclusion: 上下文线索在改善社交凝视预测中发挥重要作用，模型在开放数据集上表现出良好的泛化能力和鲁棒性。

Abstract: A person's gaze offers valuable insights into their focus of attention, level
of social engagement, and confidence. In this work, we investigate how
contextual cues combined with visual scene and facial information can be
effectively utilized to predict and interpret social gaze patterns during
conversational interactions. We introduce CSGaze, a context aware multimodal
approach that leverages facial, scene information as complementary inputs to
enhance social gaze pattern prediction from multi-person images. The model also
incorporates a fine-grained attention mechanism centered on the principal
speaker, which helps in better modeling social gaze dynamics. Experimental
results show that CSGaze performs competitively with state-of-the-art methods
on GP-Static, UCO-LAEO and AVA-LAEO. Our findings highlight the role of
contextual cues in improving social gaze prediction. Additionally, we provide
initial explainability through generated attention scores, offering insights
into the model's decision-making process. We also demonstrate our model's
generalizability by testing our model on open set datasets that demonstrating
its robustness across diverse scenarios.

</details>


### [42] [Commonality in Few: Few-Shot Multimodal Anomaly Detection via Hypergraph-Enhanced Memory](https://arxiv.org/abs/2511.05966)
*Yuxuan Lin,Hanjing Yan,Xuan Tong,Yang Chang,Huanzhen Wang,Ziheng Zhou,Shuyong Gao,Yan Wang,Wenqiang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于结构共性的少样本多模态工业异常检测方法CIF，通过超图建模高阶相关性来提取训练样本中的结构共性，并使用记忆库存储这些结构先验知识。


<details>
  <summary>Details</summary>
Motivation: 少样本多模态工业异常检测是一个重要但研究不足的任务，在少样本设置下，训练样本不足往往无法覆盖测试样本中的多样化模式，因此需要从少量训练样本中提取结构共性来缓解这一挑战。

Method: 设计了语义感知超图构建模块来提取单语义工业图像中的共同结构，构建记忆库；使用免训练的超图消息传递模块更新测试样本的视觉特征；提出超边引导的记忆搜索模块，利用结构信息辅助记忆搜索过程。

Result: 在MVTec 3D-AD数据集和Eyecandies数据集上的实验结果表明，该方法在少样本设置下优于当前最先进的方法。

Conclusion: CIF方法通过提取和利用结构共性，在少样本工业异常检测任务中取得了优异性能，证明了结构信息在缓解少样本学习挑战中的有效性。

Abstract: Few-shot multimodal industrial anomaly detection is a critical yet
underexplored task, offering the ability to quickly adapt to complex industrial
scenarios. In few-shot settings, insufficient training samples often fail to
cover the diverse patterns present in test samples. This challenge can be
mitigated by extracting structural commonality from a small number of training
samples. In this paper, we propose a novel few-shot unsupervised multimodal
industrial anomaly detection method based on structural commonality, CIF
(Commonality In Few). To extract intra-class structural information, we employ
hypergraphs, which are capable of modeling higher-order correlations, to
capture the structural commonality within training samples, and use a memory
bank to store this intra-class structural prior. Firstly, we design a
semantic-aware hypergraph construction module tailored for single-semantic
industrial images, from which we extract common structures to guide the
construction of the memory bank. Secondly, we use a training-free hypergraph
message passing module to update the visual features of test samples, reducing
the distribution gap between test features and features in the memory bank. We
further propose a hyperedge-guided memory search module, which utilizes
structural information to assist the memory search process and reduce the false
positive rate. Experimental results on the MVTec 3D-AD dataset and the
Eyecandies dataset show that our method outperforms the state-of-the-art (SOTA)
methods in few-shot settings. Code is available at
https://github.com/Sunny5250/CIF.

</details>


### [43] [Adapted Foundation Models for Breast MRI Triaging in Contrast-Enhanced and Non-Contrast Enhanced Protocols](https://arxiv.org/abs/2511.05967)
*Tri-Thien Nguyen,Lorenz A. Kapsner,Tobias Hepp,Shirin Heidarikahkesh,Hannes Schreiter,Luise Brock,Dominika Skwierawska,Dominique Hadler,Julian Hossbach,Evelyn Wenkel,Sabine Ohlmeyer,Frederik B. Laun,Andrzej Liebert,Andreas Maier,Michael Uder,Sebastian Bickelhaupt*

Main category: cs.CV

TL;DR: 本研究评估了基于DINOv2的医学切片变换器在乳腺MRI中排除BI-RADS≥4病变的性能，在97.5%敏感度下，T1sub+T2w组合特异性达19%，DWI1500+T2w特异性达17%。


<details>
  <summary>Details</summary>
Motivation: MRI对乳腺癌检测具有高敏感性但解读耗时，人工智能可能有助于预筛查。

Method: 回顾性研究包含1847例单侧乳腺MRI检查，测试四种简化协议：T1sub、DWI1500、DWI1500+T2w和T1sub+T2w，使用五折交叉验证和AUC分析评估性能。

Result: T1sub+T2w组合AUC为0.77±0.04，DWI1500+T2w为0.74±0.04。在97.5%敏感度下，T1sub+T2w特异性最高（19%±7%）。漏诊病灶平均直径<10mm，主要为非肿块强化。

Conclusion: 在97.5%敏感度下，MST框架能正确排除无BI-RADS≥4的病例，但临床实施前需要进一步研究。

Abstract: Background: Magnetic resonance imaging (MRI) has high sensitivity for breast
cancer detection, but interpretation is time-consuming. Artificial intelligence
may aid in pre-screening. Purpose: To evaluate the DINOv2-based Medical Slice
Transformer (MST) for ruling out significant findings (Breast Imaging Reporting
and Data System [BI-RADS] >=4) in contrast-enhanced and non-contrast-enhanced
abbreviated breast MRI. Materials and Methods: This institutional review board
approved retrospective study included 1,847 single-breast MRI examinations (377
BI-RADS >=4) from an in-house dataset and 924 from an external validation
dataset (Duke). Four abbreviated protocols were tested: T1-weighted early
subtraction (T1sub), diffusion-weighted imaging with b=1500 s/mm2 (DWI1500),
DWI1500+T2-weighted (T2w), and T1sub+T2w. Performance was assessed at 90%, 95%,
and 97.5% sensitivity using five-fold cross-validation and area under the
receiver operating characteristic curve (AUC) analysis. AUC differences were
compared with the DeLong test. False negatives were characterized, and
attention maps of true positives were rated in the external dataset. Results: A
total of 1,448 female patients (mean age, 49 +/- 12 years) were included.
T1sub+T2w achieved an AUC of 0.77 +/- 0.04; DWI1500+T2w, 0.74 +/- 0.04
(p=0.15). At 97.5% sensitivity, T1sub+T2w had the highest specificity (19% +/-
7%), followed by DWI1500+T2w (17% +/- 11%). Missed lesions had a mean diameter
<10 mm at 95% and 97.5% thresholds for both T1sub and DWI1500, predominantly
non-mass enhancements. External validation yielded an AUC of 0.77, with 88% of
attention maps rated good or moderate. Conclusion: At 97.5% sensitivity, the
MST framework correctly triaged cases without BI-RADS >=4, achieving 19%
specificity for contrast-enhanced and 17% for non-contrast-enhanced MRI.
Further research is warranted before clinical implementation.

</details>


### [44] [DiA-gnostic VLVAE: Disentangled Alignment-Constrained Vision Language Variational AutoEncoder for Robust Radiology Reporting with Missing Modalities](https://arxiv.org/abs/2511.05968)
*Nagur Shareef Shaik,Teja Krishna Cherukuri,Adnan Masood,Dong Hye Ye*

Main category: cs.CV

TL;DR: 提出DiA-gnostic VLVAE框架，通过解耦对齐实现稳健的放射学报告生成，解决临床数据中模态缺失和特征纠缠问题


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法依赖资源密集型大语言模型或静态知识图谱，难以处理真实临床数据中的模态缺失和特征纠缠问题，导致次优融合和临床不忠实的幻觉发现

Method: 使用基于专家混合的视觉语言变分自编码器解耦共享和模态特定特征，通过约束优化目标强制潜在表示的正交性和对齐，然后使用紧凑的LLaMA-X解码器生成报告

Result: 在IU X-Ray和MIMIC-CXR数据集上分别获得0.266和0.134的BLEU@4分数，显著优于最先进模型

Conclusion: DiA框架通过解耦对齐有效解决了临床数据中的模态缺失和特征纠缠问题，实现了稳健的放射学报告生成

Abstract: The integration of medical images with clinical context is essential for
generating accurate and clinically interpretable radiology reports. However,
current automated methods often rely on resource-heavy Large Language Models
(LLMs) or static knowledge graphs and struggle with two fundamental challenges
in real-world clinical data: (1) missing modalities, such as incomplete
clinical context , and (2) feature entanglement, where mixed modality-specific
and shared information leads to suboptimal fusion and clinically unfaithful
hallucinated findings. To address these challenges, we propose the DiA-gnostic
VLVAE, which achieves robust radiology reporting through Disentangled
Alignment. Our framework is designed to be resilient to missing modalities by
disentangling shared and modality-specific features using a Mixture-of-Experts
(MoE) based Vision-Language Variational Autoencoder (VLVAE). A constrained
optimization objective enforces orthogonality and alignment between these
latent representations to prevent suboptimal fusion. A compact LLaMA-X decoder
then uses these disentangled representations to generate reports efficiently.
On the IU X-Ray and MIMIC-CXR datasets, DiA has achieved competetive BLEU@4
scores of 0.266 and 0.134, respectively. Experimental results show that the
proposed method significantly outperforms state-of-the-art models.

</details>


### [45] [A Dual-Mode ViT-Conditioned Diffusion Framework with an Adaptive Conditioning Bridge for Breast Cancer Segmentation](https://arxiv.org/abs/2511.05989)
*Prateek Singh,Moumita Dholey,P. K. Vinod*

Main category: cs.CV

TL;DR: 提出一种结合ViT编码器和改进UNet解码器的条件去噪扩散模型，用于解决乳腺超声图像中病灶分割的挑战，通过自适应条件桥、拓扑去噪一致性损失和双头架构实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺超声图像中病灶分割面临低对比度、斑点噪声和边界模糊等挑战，传统卷积架构难以捕获足够的全局上下文，导致解剖学不一致的分割结果。

Method: 使用ViT编码器进行全局特征提取，结合改进的UNet生成解码器；引入自适应条件桥实现多尺度语义特征融合、拓扑去噪一致性损失正则化训练、双头架构利用去噪目标作为正则化器。

Result: 在公开乳腺超声数据集上达到最先进水平：BUSI数据集Dice得分0.96，BrEaST数据集0.90，BUS-UCLM数据集0.97。

Conclusion: 该框架不仅实现了高精度的分割性能，而且产生了解剖学上合理的分割结果，各组件在消融研究中被证明对取得这些结果至关重要。

Abstract: In breast ultrasound images, precise lesion segmentation is essential for
early diagnosis; however, low contrast, speckle noise, and unclear boundaries
make this difficult. Even though deep learning models have demonstrated
potential, standard convolutional architectures frequently fall short in
capturing enough global context, resulting in segmentations that are
anatomically inconsistent. To overcome these drawbacks, we suggest a flexible,
conditional Denoising Diffusion Model that combines an enhanced UNet-based
generative decoder with a Vision Transformer (ViT) encoder for global feature
extraction. We introduce three primary innovations: 1) an Adaptive Conditioning
Bridge (ACB) for efficient, multi-scale fusion of semantic features; 2) a novel
Topological Denoising Consistency (TDC) loss component that regularizes
training by penalizing structural inconsistencies during denoising; and 3) a
dual-head architecture that leverages the denoising objective as a powerful
regularizer, enabling a lightweight auxiliary head to perform rapid and
accurate inference on smaller datasets and a noise prediction head. Our
framework establishes a new state-of-the-art on public breast ultrasound
datasets, achieving Dice scores of 0.96 on BUSI, 0.90 on BrEaST and 0.97 on
BUS-UCLM. Comprehensive ablation studies empirically validate that the model
components are critical for achieving these results and for producing
segmentations that are not only accurate but also anatomically plausible.

</details>


### [46] [Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds](https://arxiv.org/abs/2511.05996)
*Xianhui Meng,Yukang Huo,Li Zhang,Liu Liu,Haonan Jiang,Yan Zhong,Pingrui Zhang,Cewu Lu,Jun Liu*

Main category: cs.CV

TL;DR: PPF-Tracker是一个基于点对特征的铰接物体姿态跟踪框架，通过在SE(3)李群空间进行准正则化，利用SE(3)不变性预测姿态投票参数，并加入关节轴语义信息施加统一运动学约束。


<details>
  <summary>Details</summary>
Motivation: 铰接物体在日常生活中和机器人操作任务中普遍存在，但与刚性物体相比，由于其固有的运动学约束，铰接物体的姿态跟踪问题仍未得到充分探索。

Method: 提出点对特征姿态跟踪框架：1）在SE(3)李群空间对点云进行准正则化；2）使用点对特征建模铰接物体，利用SE(3)不变性预测姿态投票参数；3）引入关节轴语义信息施加统一运动学约束。

Result: 在合成数据集和真实场景中系统评估，PPF-Tracker在多样化和挑战性环境中表现出强大的泛化能力，在多帧铰接物体姿态跟踪中展现出有效性和鲁棒性。

Conclusion: 该工作能够推动机器人学、具身智能和增强现实领域的进步，代码已开源。

Abstract: Articulated objects are prevalent in daily life and robotic manipulation
tasks. However, compared to rigid objects, pose tracking for articulated
objects remains an underexplored problem due to their inherent kinematic
constraints. To address these challenges, this work proposes a novel
point-pair-based pose tracking framework, termed \textbf{PPF-Tracker}. The
proposed framework first performs quasi-canonicalization of point clouds in the
SE(3) Lie group space, and then models articulated objects using Point Pair
Features (PPF) to predict pose voting parameters by leveraging the invariance
properties of SE(3). Finally, semantic information of joint axes is
incorporated to impose unified kinematic constraints across all parts of the
articulated object. PPF-Tracker is systematically evaluated on both synthetic
datasets and real-world scenarios, demonstrating strong generalization across
diverse and challenging environments. Experimental results highlight the
effectiveness and robustness of PPF-Tracker in multi-frame pose tracking of
articulated objects. We believe this work can foster advances in robotics,
embodied intelligence, and augmented reality. Codes are available at
https://github.com/mengxh20/PPFTracker.

</details>


### [47] [MALeR: Improving Compositional Fidelity in Layout-Guided Generation](https://arxiv.org/abs/2511.06002)
*Shivank Saxena,Dhruv Srivastava,Makarand Tapaswi*

Main category: cs.CV

TL;DR: MALeR是一种解决文本到图像生成中多主体和属性组合场景挑战的方法，通过布局引导和属性绑定机制，防止主体出现在指定布局外、避免属性泄漏，实现准确的多主体多属性图像生成。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型在生成包含多个主体和属性的组合场景时面临挑战，包括主体出现在布局外、生成图像超出分布范围、包含不自然伪影以及属性在主体间泄漏等问题。

Method: 提出MALeR方法，给定文本提示和对应布局，防止主体出现在给定布局外并保持分布内生成；采用掩码属性感知绑定机制防止属性泄漏，即使在复杂组合场景中也能准确渲染具有多个属性的主体。

Result: 定性和定量评估表明，MALeR在组合准确性、生成一致性和属性绑定方面优于先前工作，特别擅长生成包含多个主体且每个主体具有多个属性的场景图像。

Conclusion: MALeR通过布局约束和属性绑定机制，有效解决了文本到图像生成中多主体多属性组合场景的挑战，实现了更准确和可控的图像生成。

Abstract: Recent advances in text-to-image models have enabled a new era of creative
and controllable image generation. However, generating compositional scenes
with multiple subjects and attributes remains a significant challenge. To
enhance user control over subject placement, several layout-guided methods have
been proposed. However, these methods face numerous challenges, particularly in
compositional scenes. Unintended subjects often appear outside the layouts,
generated images can be out-of-distribution and contain unnatural artifacts, or
attributes bleed across subjects, leading to incorrect visual outputs. In this
work, we propose MALeR, a method that addresses each of these challenges. Given
a text prompt and corresponding layouts, our method prevents subjects from
appearing outside the given layouts while being in-distribution. Additionally,
we propose a masked, attribute-aware binding mechanism that prevents attribute
leakage, enabling accurate rendering of subjects with multiple attributes, even
in complex compositional scenes. Qualitative and quantitative evaluation
demonstrates that our method achieves superior performance in compositional
accuracy, generation consistency, and attribute binding compared to previous
work. MALeR is particularly adept at generating images of scenes with multiple
subjects and multiple attributes per subject.

</details>


### [48] [How Reasoning Influences Intersectional Biases in Vision Language Models](https://arxiv.org/abs/2511.06005)
*Adit Desai,Sudipta Roy,Mohna Chakraborty*

Main category: cs.CV

TL;DR: 该论文分析了5个开源视觉语言模型在职业预测任务中的社会偏见，发现模型的推理模式存在系统性偏差，导致交叉性差异，需要在下游部署前将VLM推理与人类价值观对齐。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的训练数据往往编码了社会偏见，这些偏见会在输出中体现。与人类通过上下文和社会线索解释图像不同，VLM通过统计关联处理图像，导致推理与人类推理存在差异。

Method: 在FairFace数据集上，对5个开源VLM进行职业预测任务的系统性分析，涵盖32种职业和3种不同的提示风格，收集预测结果和推理过程。

Result: 研究发现，有偏见的推理模式系统性地导致了交叉性差异，表明VLM的推理与人类价值观存在不一致。

Conclusion: 在VLM下游部署之前，需要将其推理过程与人类价值观对齐，以减少社会偏见的影响。

Abstract: Vision Language Models (VLMs) are increasingly deployed across downstream
tasks, yet their training data often encode social biases that surface in
outputs. Unlike humans, who interpret images through contextual and social
cues, VLMs process them through statistical associations, often leading to
reasoning that diverges from human reasoning. By analyzing how a VLM reasons,
we can understand how inherent biases are perpetuated and can adversely affect
downstream performance. To examine this gap, we systematically analyze social
biases in five open-source VLMs for an occupation prediction task, on the
FairFace dataset. Across 32 occupations and three different prompting styles,
we elicit both predictions and reasoning. Our findings reveal that the biased
reasoning patterns systematically underlie intersectional disparities,
highlighting the need to align VLM reasoning with human values prior to its
downstream deployment.

</details>


### [49] [Distributed Deep Learning for Medical Image Denoising with Data Obfuscation](https://arxiv.org/abs/2511.06006)
*Sulaimon Oyeniyi Adebayo,Ayaz H. Khan*

Main category: cs.CV

TL;DR: 本研究探索了使用分布式深度学习对胸部X光图像进行去噪，采用U-Net和U-Net++架构，在单GPU、标准多GPU和优化多GPU配置下进行训练。结果显示U-Net++在去噪性能上表现更优，优化训练管道将训练时间减少60%以上。


<details>
  <summary>Details</summary>
Motivation: 医学图像去噪对于提高图像质量同时最小化敏感信息暴露至关重要，特别是在处理大规模临床数据集时。研究旨在结合架构设计、轻量级模糊化和高级分布式训练策略来加速和增强医学图像处理流程。

Method: 使用NIH Chest X-ray14数据集的胸部X光图像，采用加性高斯噪声作为轻量级模糊化技术。实现并评估U-Net和U-Net++架构，在单GPU、标准多GPU（DataParallel）和优化多GPU训练配置下使用PyTorch的DistributedDataParallel（DDP）和自动混合精度（AMP）。

Result: U-Net++在去噪性能上持续表现更优，在PSNR和SSIM指标上获得竞争性分数，但在低和中度噪声水平下LPIPS表现不如U-Net。优化训练管道相比单GPU训练减少60%以上训练时间，比标准DataParallel快40%以上，仅带来轻微精度下降。

Conclusion: 研究证明了在医学成像中软件级优化在分布式学习中的有效性，展示了结合架构设计、轻量级模糊化和高级分布式训练策略在实际临床和研究环境中加速和增强医学图像处理流程的可行性。

Abstract: Medical image denoising is essential for improving image quality while
minimizing the exposure of sensitive information, particularly when working
with large-scale clinical datasets. This study explores distributed deep
learning for denoising chest X-ray images from the NIH Chest X-ray14 dataset,
using additive Gaussian noise as a lightweight obfuscation technique. We
implement and evaluate U-Net and U-Net++ architectures under single-GPU,
standard multi-GPU (DataParallel), and optimized multi-GPU training
configurations using PyTorch's DistributedDataParallel (DDP) and Automatic
Mixed Precision (AMP). Our results show that U-Net++ consistently delivers
superior denoising performance, achieving competitive Peak Signal to Noise
Ratio (PSNR) and Structured Similarity Index Method (SSIM) scores, though with
less performance in Learned Perceptual Image Patch Similarity (LPIPS) compared
to U-Net under low and moderate noise levels. This indicates U-Net++'s enhanced
structural fidelity and low perceptual similarity. Meanwhile, our optimized
training pipeline reduces training time by over 60% for both models compared to
single-GPU training, and outperforms standard DataParallel by over 40%, with
only a minor accuracy drop for both models (trading some accuracy for speed).
These findings highlight the effectiveness of software-level optimization in
distributed learning for medical imaging. This work demonstrates the practical
viability of combining architectural design, lightweight obfuscation, and
advanced distributed training strategies to accelerate and enhance medical
image processing pipelines in real-world clinical and research environments.
The full implementation is publicly available at:
https://github.com/Suadey/medical-image-denoising-ddp.

</details>


### [50] [One-Shot Knowledge Transfer for Scalable Person Re-Identification](https://arxiv.org/abs/2511.06016)
*Longhua Li,Lei Qi,Xin Geng*

Main category: cs.CV

TL;DR: 提出了一种名为OSKT（一次性知识转移）的新方法，通过权重链将教师模型的知识整合到中间载体中，当需要特定资源约束的模型时，可以直接扩展权重链到目标模型大小而无需额外计算。


<details>
  <summary>Details</summary>
Motivation: 边缘计算中的人员再识别需要不同大小的模型来适应不同的资源条件，传统压缩方法需要为每个学生模型单独计算，导致重复繁琐的计算。

Method: 提出OSKT方法，将教师模型的知识整合到权重链中，当需要特定大小的模型时，可以直接扩展权重链而无需重新训练。

Result: OSKT显著优于最先进的压缩方法，并具有一次性知识转移的优势，消除了为每个目标模型频繁计算的需求。

Conclusion: OSKT方法有效解决了边缘计算中人员再识别模型压缩的重复计算问题，提供了一种高效的一次性知识转移解决方案。

Abstract: Edge computing in person re-identification (ReID) is crucial for reducing the
load on central cloud servers and ensuring user privacy. Conventional
compression methods for obtaining compact models require computations for each
individual student model. When multiple models of varying sizes are needed to
accommodate different resource conditions, this leads to repetitive and
cumbersome computations. To address this challenge, we propose a novel
knowledge inheritance approach named OSKT (One-Shot Knowledge Transfer), which
consolidates the knowledge of the teacher model into an intermediate carrier
called a weight chain. When a downstream scenario demands a model that meets
specific resource constraints, this weight chain can be expanded to the target
model size without additional computation. OSKT significantly outperforms
state-of-the-art compression methods, with the added advantage of one-time
knowledge transfer that eliminates the need for frequent computations for each
target model.

</details>


### [51] [Towards Implicit Aggregation: Robust Image Representation for Place Recognition in the Transformer Era](https://arxiv.org/abs/2511.06024)
*Feng Lu,Tong Jin,Canming Ye,Yunpeng Liu,Xiangyuan Lan,Chun Yuan*

Main category: cs.CV

TL;DR: 本文提出在transformer时代，视觉位置识别(VPR)无需专门的聚合器，仅通过backbone即可获得鲁棒的全局描述符。作者引入可学习的聚合token，通过自注意力机制隐式聚合信息，并提出了最优的token插入策略和初始化方法。


<details>
  <summary>Details</summary>
Motivation: 传统的VPR方法采用backbone-plus-aggregator范式，但在transformer时代，作者认为专门的聚合器不再必要，可以通过更简单的方式获得鲁棒的全局描述符。

Method: 引入可学习的聚合token，将其预置到特定transformer块的patch token之前，通过自注意力机制隐式聚合信息，最后将聚合token拼接为全局表示。同时提出了token插入策略和初始化方法。

Result: 实验结果表明，该方法在多个VPR数据集上优于最先进方法，具有更高的效率，并在MSLS挑战赛排行榜上排名第一。

Conclusion: 在transformer时代，无需专门的聚合器即可获得鲁棒的全局描述符，提出的隐式聚合方法简单有效，在VPR任务中表现出色。

Abstract: Visual place recognition (VPR) is typically regarded as a specific image
retrieval task, whose core lies in representing images as global descriptors.
Over the past decade, dominant VPR methods (e.g., NetVLAD) have followed a
paradigm that first extracts the patch features/tokens of the input image using
a backbone, and then aggregates these patch features into a global descriptor
via an aggregator. This backbone-plus-aggregator paradigm has achieved
overwhelming dominance in the CNN era and remains widely used in
transformer-based models. In this paper, however, we argue that a dedicated
aggregator is not necessary in the transformer era, that is, we can obtain
robust global descriptors only with the backbone. Specifically, we introduce
some learnable aggregation tokens, which are prepended to the patch tokens
before a particular transformer block. All these tokens will be jointly
processed and interact globally via the intrinsic self-attention mechanism,
implicitly aggregating useful information within the patch tokens to the
aggregation tokens. Finally, we only take these aggregation tokens from the
last output tokens and concatenate them as the global representation. Although
implicit aggregation can provide robust global descriptors in an extremely
simple manner, where and how to insert additional tokens, as well as the
initialization of tokens, remains an open issue worthy of further exploration.
To this end, we also propose the optimal token insertion strategy and token
initialization method derived from empirical studies. Experimental results show
that our method outperforms state-of-the-art methods on several VPR datasets
with higher efficiency and ranks 1st on the MSLS challenge leaderboard. The
code is available at https://github.com/lu-feng/image.

</details>


### [52] [S2ML: Spatio-Spectral Mutual Learning for Depth Completion](https://arxiv.org/abs/2511.06033)
*Zihui Zhao,Yifei Zhang,Zheng Wang,Yang Li,Kui Jiang,Zihan Geng,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 本文提出了一种空间-频谱互学习框架（S2ML），通过结合空间域和频域的优势来解决RGB-D相机原始深度图像中深度值不完整的问题，在NYU-Depth V2和SUN RGB-D数据集上超越了现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: RGB-D相机捕获的原始深度图像由于弱反射、边界阴影和伪影等问题导致深度值不完整，限制了其在下游视觉任务中的应用。现有方法在图像域进行深度补全，但忽略了原始深度图像的物理特性。

Method: 提出了空间-频谱互学习框架（S2ML），考虑幅度谱和相位谱的不同特性，设计了专门的频谱融合模块。在统一嵌入空间中计算空间域和频域特征的局部和全局相关性，通过渐进式互表示和细化来充分探索互补的物理特性和先验知识。

Result: 在NYU-Depth V2和SUN RGB-D数据集上的大量实验表明，S2ML方法比最先进的CFormer方法分别提升了0.828 dB和0.834 dB。

Conclusion: S2ML框架通过协调空间域和频域的优势，能够更准确地完成深度补全任务，证明了结合物理特性和互补先验知识的重要性。

Abstract: The raw depth images captured by RGB-D cameras using Time-of-Flight (TOF) or
structured light often suffer from incomplete depth values due to weak
reflections, boundary shadows, and artifacts, which limit their applications in
downstream vision tasks. Existing methods address this problem through depth
completion in the image domain, but they overlook the physical characteristics
of raw depth images. It has been observed that the presence of invalid depth
areas alters the frequency distribution pattern. In this work, we propose a
Spatio-Spectral Mutual Learning framework (S2ML) to harmonize the advantages of
both spatial and frequency domains for depth completion. Specifically, we
consider the distinct properties of amplitude and phase spectra and devise a
dedicated spectral fusion module. Meanwhile, the local and global correlations
between spatial-domain and frequency-domain features are calculated in a
unified embedding space. The gradual mutual representation and refinement
encourage the network to fully explore complementary physical characteristics
and priors for more accurate depth completion. Extensive experiments
demonstrate the effectiveness of our proposed S2ML method, outperforming the
state-of-the-art method CFormer by 0.828 dB and 0.834 dB on the NYU-Depth V2
and SUN RGB-D datasets, respectively.

</details>


### [53] [StreamSTGS: Streaming Spatial and Temporal Gaussian Grids for Real-Time Free-Viewpoint Video](https://arxiv.org/abs/2511.06046)
*Zhihui Ke,Yuyang Liu,Xiaobo Zhou,Tie Qiu*

Main category: cs.CV

TL;DR: StreamSTGS是一种用于实时流式自由视点视频的新表示方法，通过将3D高斯属性编码为2D图像和时间特征编码为视频，显著减少了存储需求，支持自适应码率控制，并在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于3D高斯泼溅的自由视点视频方法虽然取得了训练和渲染方面的突破，但每帧存储需求高达10MB，无法实现实时流式传输。

Method: 使用规范3D高斯、时间特征和变形场表示动态场景；将高斯属性编码为2D图像，时间特征编码为视频；采用滑动窗口方案聚合相邻时间特征学习局部运动，并引入transformer引导的辅助训练模块学习全局运动。

Result: 在多样化自由视点视频基准测试中，StreamSTGS在所有指标上均具有竞争力，平均PSNR提高1dB，同时将平均帧大小降至仅170KB。

Conclusion: StreamSTGS实现了实时流式自由视点视频传输，显著减少了存储需求，支持自适应码率控制，且无需额外训练。

Abstract: Streaming free-viewpoint video~(FVV) in real-time still faces significant
challenges, particularly in training, rendering, and transmission efficiency.
Harnessing superior performance of 3D Gaussian Splatting~(3DGS), recent
3DGS-based FVV methods have achieved notable breakthroughs in both training and
rendering. However, the storage requirements of these methods can reach up to
$10$MB per frame, making stream FVV in real-time impossible. To address this
problem, we propose a novel FVV representation, dubbed StreamSTGS, designed for
real-time streaming. StreamSTGS represents a dynamic scene using canonical 3D
Gaussians, temporal features, and a deformation field. For high compression
efficiency, we encode canonical Gaussian attributes as 2D images and temporal
features as a video. This design not only enables real-time streaming, but also
inherently supports adaptive bitrate control based on network condition without
any extra training. Moreover, we propose a sliding window scheme to aggregate
adjacent temporal features to learn local motions, and then introduce a
transformer-guided auxiliary training module to learn global motions. On
diverse FVV benchmarks, StreamSTGS demonstrates competitive performance on all
metrics compared to state-of-the-art methods. Notably, StreamSTGS increases the
PSNR by an average of $1$dB while reducing the average frame size to just
$170$KB. The code is publicly available on https://github.com/kkkzh/StreamSTGS.

</details>


### [54] [Neodragon: Mobile Video Generation using Diffusion Transformer](https://arxiv.org/abs/2511.06055)
*Animesh Karnewar,Denis Korzhenkov,Ioannis Lelekas,Adil Karjauv,Noor Fathima,Hanwen Xiong,Vancheeswaran Vaidyanathan,Will Zeng,Rafael Esteves,Tushar Singhal,Fatih Porikli,Mohsen Ghafoorian,Amirhossein Habibian*

Main category: cs.CV

TL;DR: Neodragon是一个专为移动硬件优化的文本到视频生成系统，能在高通Hexagon NPU上6.7秒内生成2秒640x1024分辨率视频，实现了81.61的VBench总分。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的文本到视频生成模型主要针对离线场景，缺乏针对移动硬件的优化。Neodragon旨在实现高效、高保真的移动端视频合成，降低对云服务的依赖。

Method: 采用四项关键技术：(1)文本编码器蒸馏，用0.2B DT5替换4.762B T5xxl；(2)非对称解码器蒸馏，替换codec-latent-VAE解码器；(3)基于重要性的MMDiT块剪枝和两阶段蒸馏；(4)使用DMD进行步骤蒸馏，减少去噪器NFE需求。

Result: 实现了4.945B参数、3.5GB峰值内存使用、6.7秒端到端延迟的高效模型，在移动设备上生成高质量视频，VBench总分达81.61。

Conclusion: Neodragon通过硬件优化实现了低成本、私密、设备端的文本到视频合成，使创作者无需依赖云服务即可生成高质量视频，推动了AI视频创作的民主化。

Abstract: We introduce Neodragon, a text-to-video system capable of generating 2s (49
frames @24 fps) videos at the 640x1024 resolution directly on a Qualcomm
Hexagon NPU in a record 6.7s (7 FPS). Differing from existing transformer-based
offline text-to-video generation models, Neodragon is the first to have been
specifically optimised for mobile hardware to achieve efficient and
high-fidelity video synthesis. We achieve this through four key technical
contributions: (1) Replacing the original large 4.762B T5xxl Text-Encoder with
a much smaller 0.2B DT5 (DistilT5) with minimal quality loss, enabled through a
novel Text-Encoder Distillation procedure. (2) Proposing an Asymmetric Decoder
Distillation approach allowing us to replace the native codec-latent-VAE
decoder with a more efficient one, without disturbing the generative
latent-space of the generation pipeline. (3) Pruning of MMDiT blocks within the
denoiser backbone based on their relative importance, with recovery of original
performance through a two-stage distillation process. (4) Reducing the NFE
(Neural Functional Evaluation) requirement of the denoiser by performing step
distillation using DMD adapted for pyramidal flow-matching, thereby
substantially accelerating video generation. When paired with an optimised
SSD1B first-frame image generator and QuickSRNet for 2x super-resolution, our
end-to-end Neodragon system becomes a highly parameter (4.945B full model),
memory (3.5GB peak RAM usage), and runtime (6.7s E2E latency) efficient
mobile-friendly model, while achieving a VBench total score of 81.61. By
enabling low-cost, private, and on-device text-to-video synthesis, Neodragon
democratizes AI-based video content creation, empowering creators to generate
high-quality videos without reliance on cloud services. Code and model will be
made publicly available at our website:
https://qualcomm-ai-research.github.io/neodragon

</details>


### [55] [LoopExpose: An Unsupervised Framework for Arbitrary-Length Exposure Correction](https://arxiv.org/abs/2511.06066)
*Ao Li,Chen Chen,Zhenyu Wang,Tao Huang,Fangfang Wu,Weisheng Dong*

Main category: cs.CV

TL;DR: 提出了一种基于伪标签的无监督曝光校正方法LoopExpose，采用嵌套循环优化策略，通过多曝光融合生成伪标签训练校正模型，并引入反馈机制和亮度排序损失来提升性能。


<details>
  <summary>Details</summary>
Motivation: 监督学习方法在曝光校正领域依赖大规模标注数据集，但在实际场景中难以获取。为解决这一限制，需要开发无监督方法。

Method: 提出嵌套循环优化策略：上层使用下层多曝光融合生成的伪标签训练校正模型，引入反馈机制将校正图像反馈到融合过程来优化伪标签。同时使用亮度排序损失作为自监督约束。

Result: 在多个基准数据集上的实验表明，LoopExpose在曝光校正和融合性能上优于现有的最先进无监督方法。

Conclusion: LoopExpose通过伪标签和自监督约束实现了有效的无监督曝光校正，解决了对标注数据的依赖问题。

Abstract: Exposure correction is essential for enhancing image quality under
challenging lighting conditions. While supervised learning has achieved
significant progress in this area, it relies heavily on large-scale labeled
datasets, which are difficult to obtain in practical scenarios. To address this
limitation, we propose a pseudo label-based unsupervised method called
LoopExpose for arbitrary-length exposure correction. A nested loop optimization
strategy is proposed to address the exposure correction problem, where the
correction model and pseudo-supervised information are jointly optimized in a
two-level framework. Specifically, the upper-level trains a correction model
using pseudo-labels generated through multi-exposure fusion at the lower level.
A feedback mechanism is introduced where corrected images are fed back into the
fusion process to refine the pseudo-labels, creating a self-reinforcing
learning loop. Considering the dominant role of luminance calibration in
exposure correction, a Luminance Ranking Loss is introduced to leverage the
relative luminance ordering across the input sequence as a self-supervised
constraint. Extensive experiments on different benchmark datasets demonstrate
that LoopExpose achieves superior exposure correction and fusion performance,
outperforming existing state-of-the-art unsupervised methods. Code is available
at https://github.com/FALALAS/LoopExpose.

</details>


### [56] [Hybrid CNN-ViT Framework for Motion-Blurred Scene Text Restoration](https://arxiv.org/abs/2511.06087)
*Umar Rashid,Muhammad Arslan Arshad,Ghulam Ahmad,Muhammad Zeeshan Anjum,Rizwan Khan,Muhammad Akmal*

Main category: cs.CV

TL;DR: 提出了一种结合CNN和ViT的混合深度学习框架，用于处理运动模糊场景文本图像，通过局部特征提取和全局上下文推理来恢复文本清晰度。


<details>
  <summary>Details</summary>
Motivation: 运动模糊严重影响场景文本图像的可读性和计算机视觉任务的可靠性，传统去模糊方法在处理空间变化模糊和建模长距离依赖方面存在不足。

Method: 采用CNN编码器-解码器结构保留结构细节，结合transformer模块通过自注意力增强全局感知，使用合成模糊数据集训练，采用复合损失函数优化。

Result: 在PSNR指标上达到32.20 dB，SSIM达到0.934，模型轻量（283万参数），平均推理时间61毫秒。

Conclusion: CNN-ViT混合设计在运动模糊场景文本恢复方面具有有效性和计算效率，适用于实际应用。

Abstract: Motion blur in scene text images severely impairs readability and hinders the
reliability of computer vision tasks, including autonomous driving, document
digitization, and visual information retrieval. Conventional deblurring
approaches are often inadequate in handling spatially varying blur and
typically fall short in modeling the long-range dependencies necessary for
restoring textual clarity. To overcome these limitations, we introduce a hybrid
deep learning framework that combines convolutional neural networks (CNNs) with
vision transformers (ViTs), thereby leveraging both local feature extraction
and global contextual reasoning. The architecture employs a CNN-based
encoder-decoder to preserve structural details, while a transformer module
enhances global awareness through self-attention. Training is conducted on a
curated dataset derived from TextOCR, where sharp scene-text samples are paired
with synthetically blurred versions generated using realistic motion-blur
kernels of multiple sizes and orientations. Model optimization is guided by a
composite loss that incorporates mean absolute error (MAE), squared error
(MSE), perceptual similarity, and structural similarity (SSIM). Quantitative
eval- uations show that the proposed method attains 32.20 dB in PSNR and 0.934
in SSIM, while remaining lightweight with 2.83 million parameters and an
average inference time of 61 ms. These results highlight the effectiveness and
computational efficiency of the CNN-ViT hybrid design, establishing its
practicality for real-world motion-blurred scene-text restoration.

</details>


### [57] [Latent Refinement via Flow Matching for Training-free Linear Inverse Problem Solving](https://arxiv.org/abs/2511.06138)
*Hossein Askari,Yadan Luo,Hongfu Sun,Fred Roosta*

Main category: cs.CV

TL;DR: LFlow是一个基于预训练潜在流先验的训练自由框架，用于解决线性逆问题。它通过流匹配在潜在空间中进行ODE采样，并引入理论推导的后验协方差进行有效流引导，在重建质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于流的逆问题求解器存在两个主要限制：(i)直接在像素空间操作，计算资源需求大且难以扩展到高分辨率图像；(ii)使用先验无关的后验协方差指导策略，可能削弱与生成轨迹的对齐并降低后验覆盖。

Method: 提出LFlow框架，利用流匹配在潜在空间中进行ODE采样，并引入从最优向量场推导的理论基础后验协方差进行流引导。

Result: 实验结果表明，该方法在大多数任务中的重建质量优于最先进的潜在扩散求解器。

Conclusion: LFlow通过潜在空间流先验和理论推导的后验协方差，有效解决了现有流基逆问题求解器的局限性，实现了高质量的重建效果。

Abstract: Recent advances in inverse problem solving have increasingly adopted flow
priors over diffusion models due to their ability to construct straight
probability paths from noise to data, thereby enhancing efficiency in both
training and inference. However, current flow-based inverse solvers face two
primary limitations: (i) they operate directly in pixel space, which demands
heavy computational resources for training and restricts scalability to
high-resolution images, and (ii) they employ guidance strategies with
prior-agnostic posterior covariances, which can weaken alignment with the
generative trajectory and degrade posterior coverage. In this paper, we propose
LFlow (Latent Refinement via Flows), a training-free framework for solving
linear inverse problems via pretrained latent flow priors. LFlow leverages the
efficiency of flow matching to perform ODE sampling in latent space along an
optimal path. This latent formulation further allows us to introduce a
theoretically grounded posterior covariance, derived from the optimal vector
field, enabling effective flow guidance. Experimental results demonstrate that
our proposed method outperforms state-of-the-art latent diffusion solvers in
reconstruction quality across most tasks. The code will be publicly available
at https://github.com/hosseinaskari-cs/LFlow .

</details>


### [58] [Scene-Aware Urban Design: A Human-AI Recommendation Framework Using Co-Occurrence Embeddings and Vision-Language Models](https://arxiv.org/abs/2511.06201)
*Rodrigo Gallardo,Oz Fishman,Alexander Htet Kyaw*

Main category: cs.CV

TL;DR: 本文提出了一个人机协同的计算机视觉框架，利用生成式AI为公共空间提供微观尺度设计干预建议，支持更持续、本地的参与。


<details>
  <summary>Details</summary>
Motivation: 旨在超越自上而下的总体规划，通过基于日常模式和生活经验的选择，让人们在选择和优化过程中保持控制权。

Method: 使用Grounding DINO和ADE20K数据集子集检测城市物体并构建共现嵌入，揭示常见空间配置。通过视觉语言模型分析场景图像和选定对象对，建议第三个对象完成更复杂的城市策略。

Result: 系统能够检测城市物体并生成统计上可能的补充对象，为用户提供五个可能的补充选择，并通过视觉语言模型建议第三个对象来完成城市策略。

Conclusion: 该工作流程将人们保持在选择和优化的控制中，通过基于日常模式和生活经验的选择，推动超越传统总体规划的参与式设计方法。

Abstract: This paper introduces a human-in-the-loop computer vision framework that uses
generative AI to propose micro-scale design interventions in public space and
support more continuous, local participation. Using Grounding DINO and a
curated subset of the ADE20K dataset as a proxy for the urban built
environment, the system detects urban objects and builds co-occurrence
embeddings that reveal common spatial configurations. From this analysis, the
user receives five statistically likely complements to a chosen anchor object.
A vision language model then reasons over the scene image and the selected pair
to suggest a third object that completes a more complex urban tactic. The
workflow keeps people in control of selection and refinement and aims to move
beyond top-down master planning by grounding choices in everyday patterns and
lived experience.

</details>


### [59] [MoRA: Missing Modality Low-Rank Adaptation for Visual Recognition](https://arxiv.org/abs/2511.06225)
*Shu Zhao,Nilesh Ahuja,Tan Yu,Tianyi Shen,Vijaykrishnan Narayanan*

Main category: cs.CV

TL;DR: MoRA是一种参数高效的微调方法，专门用于处理预训练视觉语言模型在缺失模态场景下的视觉识别任务，通过显式建模跨模态交互同时保持模态特定适配。


<details>
  <summary>Details</summary>
Motivation: 现实场景中由于隐私约束、采集困难或资源限制，模态可能缺失，而现有方法无法有效捕捉跨模态关系且存在计算开销问题。

Method: 引入模态共享参数实现文本和视觉编码器之间的双向知识转移，结合模态特定参数，保持模态间交互并实现模态内灵活性。

Result: 在标准基准测试中，MoRA在缺失模态场景下平均性能提升5.24%，推理时间仅为SOTA方法的25.90%，可训练参数仅为全微调的0.11%。

Conclusion: MoRA在缺失模态场景下实现了显著性能提升，同时大幅降低了计算开销和参数需求，为实际应用提供了高效解决方案。

Abstract: Pre-trained vision language models have shown remarkable performance on
visual recognition tasks, but they typically assume the availability of
complete multimodal inputs during both training and inference. In real-world
scenarios, however, modalities may be missing due to privacy constraints,
collection difficulties, or resource limitations. While previous approaches
have addressed this challenge using prompt learning techniques, they fail to
capture the cross-modal relationships necessary for effective multimodal visual
recognition and suffer from inevitable computational overhead. In this paper,
we introduce MoRA, a parameter-efficient fine-tuning method that explicitly
models cross-modal interactions while maintaining modality-specific
adaptations. MoRA introduces modality-common parameters between text and vision
encoders, enabling bidirectional knowledge transfer. Additionally, combined
with the modality-specific parameters, MoRA allows the backbone model to
maintain inter-modality interaction and enable intra-modality flexibility.
Extensive experiments on standard benchmarks demonstrate that MoRA achieves an
average performance improvement in missing-modality scenarios by 5.24% and uses
only 25.90% of the inference time compared to the SOTA method while requiring
only 0.11% of trainable parameters compared to full fine-tuning.

</details>


### [60] [Temporal-Guided Visual Foundation Models for Event-Based Vision](https://arxiv.org/abs/2511.06238)
*Ruihao Xia,Junhong Cai,Luziwei Leng,Liuyi Wang,Chengju Liu,Ran Cheng,Yang Tang,Pan Zhou*

Main category: cs.CV

TL;DR: 提出TGVFM框架，将视觉基础模型与时间上下文融合模块结合，用于处理事件相机数据，在语义分割、深度估计和目标检测任务上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机在挑战性环境中具有独特优势，但处理异步事件流仍具挑战。现有方法依赖专用架构或资源密集型训练，而利用预训练视觉基础模型处理事件视觉的潜力尚未充分探索。

Method: 提出TGVFM框架，包含三个关键组件：长程时间注意力建模全局时间依赖、双时空注意力进行多尺度帧关联、深度特征引导机制融合语义-时间特征。通过在真实数据上重新训练事件到视频模型并利用基于Transformer的视觉基础模型。

Result: 在语义分割、深度估计和目标检测任务上分别比现有方法提升16%、21%和16%，实现SOTA性能。

Conclusion: 这项工作解锁了基于图像的视觉基础模型在事件视觉中的跨模态潜力，具备时间推理能力。

Abstract: Event cameras offer unique advantages for vision tasks in challenging
environments, yet processing asynchronous event streams remains an open
challenge. While existing methods rely on specialized architectures or
resource-intensive training, the potential of leveraging modern Visual
Foundation Models (VFMs) pretrained on image data remains under-explored for
event-based vision. To address this, we propose Temporal-Guided VFM (TGVFM), a
novel framework that integrates VFMs with our temporal context fusion block
seamlessly to bridge this gap. Our temporal block introduces three key
components: (1) Long-Range Temporal Attention to model global temporal
dependencies, (2) Dual Spatiotemporal Attention for multi-scale frame
correlation, and (3) Deep Feature Guidance Mechanism to fuse semantic-temporal
features. By retraining event-to-video models on real-world data and leveraging
transformer-based VFMs, TGVFM preserves spatiotemporal dynamics while
harnessing pretrained representations. Experiments demonstrate SoTA performance
across semantic segmentation, depth estimation, and object detection, with
improvements of 16%, 21%, and 16% over existing methods, respectively. Overall,
this work unlocks the cross-modality potential of image-based VFMs for
event-based vision with temporal reasoning. Code is available at
https://github.com/XiaRho/TGVFM.

</details>


### [61] [Gait Recognition via Collaborating Discriminative and Generative Diffusion Models](https://arxiv.org/abs/2511.06245)
*Haijun Xiong,Bin Feng,Bang Wang,Xinggang Wang,Wenyu Liu*

Main category: cs.CV

TL;DR: CoD²是一个结合扩散模型和判别模型的新型步态识别框架，通过多级条件控制策略提取鲁棒步态特征，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 虽然判别模型在步态识别领域取得了显著成功，但生成模型的潜力尚未充分探索。本文旨在结合扩散模型的数据分布建模能力和判别模型的语义表示学习优势。

Method: 提出多级条件控制策略，包含高层身份感知语义条件和低层视觉细节。高层条件由判别提取器提取，指导生成身份一致的步态序列；低层细节如外观和运动被保留以增强一致性。生成的序列反过来促进判别提取器学习更全面的高层语义特征。

Result: 在四个数据集（SUSTech1K、CCPG、GREW、Gait3D）上的广泛实验表明，CoD²实现了最先进的性能，并能与现有判别方法无缝集成，带来一致改进。

Conclusion: CoD²框架成功结合了生成和判别模型的优势，为步态识别提供了更鲁棒的特征提取方法，展现出良好的泛化能力和兼容性。

Abstract: Gait recognition offers a non-intrusive biometric solution by identifying
individuals through their walking patterns. Although discriminative models have
achieved notable success in this domain, the full potential of generative
models remains largely underexplored. In this paper, we introduce
\textbf{CoD$^2$}, a novel framework that combines the data distribution
modeling capabilities of diffusion models with the semantic representation
learning strengths of discriminative models to extract robust gait features. We
propose a Multi-level Conditional Control strategy that incorporates both
high-level identity-aware semantic conditions and low-level visual details.
Specifically, the high-level condition, extracted by the discriminative
extractor, guides the generation of identity-consistent gait sequences, whereas
low-level visual details, such as appearance and motion, are preserved to
enhance consistency. Furthermore, the generated sequences facilitate the
discriminative extractor's learning, enabling it to capture more comprehensive
high-level semantic features. Extensive experiments on four datasets
(SUSTech1K, CCPG, GREW, and Gait3D) demonstrate that CoD$^2$ achieves
state-of-the-art performance and can be seamlessly integrated with existing
discriminative methods, yielding consistent improvements.

</details>


### [62] [AdaDrive: Self-Adaptive Slow-Fast System for Language-Grounded Autonomous Driving](https://arxiv.org/abs/2511.06253)
*Ruifei Zhang,Junlin Xie,Wei Zhang,Weikai Chen,Xiao Tan,Xiang Wan,Guanbin Li*

Main category: cs.CV

TL;DR: AdaDrive是一个自适应协作的慢-快框架，通过动态确定何时以及如何让大语言模型参与决策，在自动驾驶中平衡高级推理和实时效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么频繁激活LLM导致计算开销过大，要么使用固定调度无法适应动态驾驶条件，需要一种能自适应LLM激活和集成的解决方案。

Method: 提出自适应激活损失函数动态确定LLM调用时机，引入自适应融合策略根据场景复杂度和预测置信度调节LLM影响程度，实现与传统规划器的无缝协作。

Result: 在语言驱动的自动驾驶基准测试中，AdaDrive在驾驶准确性和计算效率方面均达到最先进性能。

Conclusion: AdaDrive提供了一个灵活、上下文感知的框架，在不影响实时性能的前提下最大化决策准确性。

Abstract: Effectively integrating Large Language Models (LLMs) into autonomous driving
requires a balance between leveraging high-level reasoning and maintaining
real-time efficiency. Existing approaches either activate LLMs too frequently,
causing excessive computational overhead, or use fixed schedules, failing to
adapt to dynamic driving conditions. To address these challenges, we propose
AdaDrive, an adaptively collaborative slow-fast framework that optimally
determines when and how LLMs contribute to decision-making. (1) When to
activate the LLM: AdaDrive employs a novel adaptive activation loss that
dynamically determines LLM invocation based on a comparative learning
mechanism, ensuring activation only in complex or critical scenarios. (2) How
to integrate LLM assistance: Instead of rigid binary activation, AdaDrive
introduces an adaptive fusion strategy that modulates a continuous, scaled LLM
influence based on scene complexity and prediction confidence, ensuring
seamless collaboration with conventional planners. Through these strategies,
AdaDrive provides a flexible, context-aware framework that maximizes decision
accuracy without compromising real-time performance. Extensive experiments on
language-grounded autonomous driving benchmarks demonstrate that AdaDrive
state-of-the-art performance in terms of both driving accuracy and
computational efficiency. Code is available at
https://github.com/ReaFly/AdaDrive.

</details>


### [63] [VLDrive: Vision-Augmented Lightweight MLLMs for Efficient Language-grounded Autonomous Driving](https://arxiv.org/abs/2511.06256)
*Ruifei Zhang,Wei Zhang,Xiao Tan,Sibei Yang,Xiang Wan,Xiaonan Luo,Guanbin Li*

Main category: cs.CV

TL;DR: VLDrive是一个轻量级多模态语言模型架构，通过视觉剪枝和特征聚合技术解决自动驾驶中视觉表示不足的问题，在减少81%参数的同时实现了最先进的驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自动驾驶方法存在两个关键问题：(1) 视觉表示不足导致频繁碰撞和障碍物检测失败；(2) 大参数模型部署困难。

Method: 提出VLDrive方法，采用轻量级MLLM架构，包含循环一致性动态视觉剪枝、记忆增强特征聚合和距离解耦指令注意力机制。

Result: 在CARLA模拟器中测试，VLDrive在减少81%参数（从7B到1.3B）的同时，在闭环评估中驾驶得分分别提升了15.4%（短距离）、16.8%（中距离）和7.6%（长距离）。

Conclusion: VLDrive通过创新的视觉表示压缩和特征学习机制，在显著减少模型参数的同时实现了更鲁棒的自动驾驶性能。

Abstract: Recent advancements in language-grounded autonomous driving have been
significantly promoted by the sophisticated cognition and reasoning
capabilities of large language models (LLMs). However, current LLM-based
approaches encounter critical challenges: (1) Failure analysis reveals that
frequent collisions and obstructions, stemming from limitations in visual
representations, remain primary obstacles to robust driving performance. (2)
The substantial parameters of LLMs pose considerable deployment hurdles. To
address these limitations, we introduce VLDrive, a novel approach featuring a
lightweight MLLM architecture with enhanced vision components. VLDrive achieves
compact visual tokens through innovative strategies, including cycle-consistent
dynamic visual pruning and memory-enhanced feature aggregation. Furthermore, we
propose a distance-decoupled instruction attention mechanism to improve joint
visual-linguistic feature learning, particularly for long-range visual tokens.
Extensive experiments conducted in the CARLA simulator demonstrate VLDrive`s
effectiveness. Notably, VLDrive achieves state-of-the-art driving performance
while reducing parameters by 81% (from 7B to 1.3B), yielding substantial
driving score improvements of 15.4%, 16.8%, and 7.6% at tiny, short, and long
distances, respectively, in closed-loop evaluations. Code is available at
https://github.com/ReaFly/VLDrive.

</details>


### [64] [A Mixture-of-Experts Framework with Log-Logistic Components for Survival Analysis on Histopathology Images](https://arxiv.org/abs/2511.06266)
*Ardhendu Sekhar,Vasu Soni,Keshav Aske,Shivam Madnoorkar,Pranav Jeevan,Amit Sethi*

Main category: cs.CV

TL;DR: 提出了一种模块化框架，通过全切片病理图像预测癌症特异性生存率，包含四个核心组件：分位数门控补丁选择、图引导聚类、分层上下文注意力和专家驱动的混合对数逻辑分布框架，在多个癌症数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的癌症生存预测方法在处理全切片病理图像的复杂性和异质性方面存在局限，需要开发能够有效识别预后信息区域并建模复杂生存分布的新方法。

Method: 采用四组件模块化框架：分位数门控补丁选择识别预后信息区域；图引导聚类捕获表型异质性；分层上下文注意力学习集群内外交互；专家驱动混合对数逻辑分布估计复杂生存分布。

Result: 在TCGA LUAD数据集上获得0.644的一致性指数，TCGA KIRC上0.751，TCGA BRCA上0.752，均优于现有最先进方法。

Conclusion: 该模块化框架能够有效从全切片病理图像中提取预后信息，准确预测癌症特异性生存率，在多个癌症类型上表现出优越性能。

Abstract: We propose a modular framework for predicting cancer specific survival from
whole slide pathology images (WSIs). The method integrates four components: (i)
Quantile Gated Patch Selection via quantile based thresholding to isolate
prognostically informative tissue regions; (ii) Graph Guided Clustering using a
k nearest neighbor graph to capture phenotype level heterogeneity through
spatial and morphological coherence; (iii) Hierarchical Context Attention to
learn intra and inter cluster interactions; and (iv) an Expert Driven Mixture
of Log logistics framework to estimate complex survival distributions using Log
logistics distributions. The model attains a concordance index of 0.644 on TCGA
LUAD, 0.751 on TCGA KIRC, and 0.752 on TCGA BRCA respectively, outperforming
existing state of the art approaches.

</details>


### [65] [RelightMaster: Precise Video Relighting with Multi-plane Light Images](https://arxiv.org/abs/2511.06271)
*Weikang Bian,Xiaoyu Shi,Zhaoyang Huang,Jianhong Bai,Qinghe Wang,Xintao Wang,Pengfei Wan,Kun Gai,Hongsheng Li*

Main category: cs.CV

TL;DR: RelightMaster是一个用于精确可控视频重照明的框架，通过构建RelightVideo数据集、引入多平面光照图像(MPLI)作为视觉提示，以及设计光照图像适配器来注入预训练视频扩散模型中，实现物理合理的光照和阴影生成。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在高质量视频生成和编辑方面取得进展，但精确的重照明控制仍然未被探索。主流文本到视频模型由于文本描述光照细节的固有局限性以及光照相关提示预训练不足，缺乏细粒度光照控制。同时，构建高质量重照明训练数据具有挑战性。

Method: 1) 基于Unreal Engine构建RelightVideo数据集，包含相同动态内容在不同精确光照条件下的视频；2) 引入多平面光照图像(MPLI)作为视觉提示，通过K个深度对齐平面建模3D光源位置、强度和颜色；3) 设计光照图像适配器，将MPLI压缩并通过预训练视频VAE注入到视频扩散变换器(DiT)块中。

Result: 实验表明，RelightMaster能够生成物理合理的光照和阴影，同时保留原始场景内容。

Conclusion: RelightMaster通过创新的数据集构建、视觉提示设计和适配器架构，成功解决了视频重照明中的精确控制问题，为场景氛围塑造和观众注意力引导提供了有效工具。

Abstract: Recent advances in diffusion models enable high-quality video generation and
editing, but precise relighting with consistent video contents, which is
critical for shaping scene atmosphere and viewer attention, remains unexplored.
Mainstream text-to-video (T2V) models lack fine-grained lighting control due to
text's inherent limitation in describing lighting details and insufficient
pre-training on lighting-related prompts. Additionally, constructing
high-quality relighting training data is challenging, as real-world
controllable lighting data is scarce. To address these issues, we propose
RelightMaster, a novel framework for accurate and controllable video
relighting. First, we build RelightVideo, the first dataset with identical
dynamic content under varying precise lighting conditions based on the Unreal
Engine. Then, we introduce Multi-plane Light Image (MPLI), a novel visual
prompt inspired by Multi-Plane Image (MPI). MPLI models lighting via K
depth-aligned planes, representing 3D light source positions, intensities, and
colors while supporting multi-source scenarios and generalizing to unseen light
setups. Third, we design a Light Image Adapter that seamlessly injects MPLI
into pre-trained Video Diffusion Transformers (DiT): it compresses MPLI via a
pre-trained Video VAE and injects latent light features into DiT blocks,
leveraging the base model's generative prior without catastrophic forgetting.
Experiments show that RelightMaster generates physically plausible lighting and
shadows and preserves original scene content. Demos are available at
https://wkbian.github.io/Projects/RelightMaster/.

</details>


### [66] [LaneDiffusion: Improving Centerline Graph Learning via Prior Injected BEV Feature Generation](https://arxiv.org/abs/2511.06272)
*Zijie Wang,Weiming Zhang,Wei Zhang,Xiao Tan,Hongxing Liu,Yaowei Wang,Guanbin Li*

Main category: cs.CV

TL;DR: LaneDiffusion是一种用于中心线图学习的生成式方法，使用扩散模型在BEV特征层面生成车道中心线先验，显著优于传统确定性方法。


<details>
  <summary>Details</summary>
Motivation: 传统确定性方法在自动驾驶路径规划中缺乏空间推理能力，难以处理被遮挡或不可见的中心线，而生成式方法在该领域尚未充分探索。

Method: 提出LaneDiffusion方法，包含车道先验注入模块(LPIM)和车道先验扩散模块(LPDM)，在BEV特征层面构建扩散目标并管理扩散过程，然后从先验注入的BEV特征解码向量化中心线和拓扑结构。

Result: 在nuScenes和Argoverse2数据集上的广泛评估显示，LaneDiffusion在点级指标(GEO F1、TOPO F1、JTOPO F1、APLS、SDA)和段级指标(IoU、mAP_cf、DET_l、TOP_ll)上均显著优于现有方法，提升幅度从1.8%到6.8%不等。

Conclusion: LaneDiffusion在中心线图学习中实现了最先进的性能，为生成式模型在该任务中的应用提供了新的见解。

Abstract: Centerline graphs, crucial for path planning in autonomous driving, are
traditionally learned using deterministic methods. However, these methods often
lack spatial reasoning and struggle with occluded or invisible centerlines.
Generative approaches, despite their potential, remain underexplored in this
domain. We introduce LaneDiffusion, a novel generative paradigm for centerline
graph learning. LaneDiffusion innovatively employs diffusion models to generate
lane centerline priors at the Bird's Eye View (BEV) feature level, instead of
directly predicting vectorized centerlines. Our method integrates a Lane Prior
Injection Module (LPIM) and a Lane Prior Diffusion Module (LPDM) to effectively
construct diffusion targets and manage the diffusion process. Furthermore,
vectorized centerlines and topologies are then decoded from these
prior-injected BEV features. Extensive evaluations on the nuScenes and
Argoverse2 datasets demonstrate that LaneDiffusion significantly outperforms
existing methods, achieving improvements of 4.2%, 4.6%, 4.7%, 6.4% and 1.8% on
fine-grained point-level metrics (GEO F1, TOPO F1, JTOPO F1, APLS and SDA) and
2.3%, 6.4%, 6.8% and 2.1% on segment-level metrics (IoU, mAP_cf, DET_l and
TOP_ll). These results establish state-of-the-art performance in centerline
graph learning, offering new insights into generative models for this task.

</details>


### [67] [VideoSSR: Video Self-Supervised Reinforcement Learning](https://arxiv.org/abs/2511.06281)
*Zefeng He,Xiaoye Qu,Yafu Li,Siyuan Huang,Daizong Liu,Yu Cheng*

Main category: cs.CV

TL;DR: 本文提出VideoSSR框架，通过三个自监督预训练任务（异常定位、物体计数、时间拼图）从视频内在信息中自动生成可验证的训练数据，解决了多模态大语言模型视频理解中高质量数据标注成本高昂的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频数据集的复杂度跟不上多模态大语言模型的快速发展，而手动标注高质量新数据成本过高。本文旨在探索是否可以利用视频内在的丰富信息来自动生成高质量、可验证的训练数据。

Method: 提出三个自监督预训练任务：异常定位、物体计数和时间拼图；构建VideoSSR-30K数据集；开发VideoSSR框架，一种用于可验证奖励强化学习的视频自监督强化学习框架。

Result: 在17个基准测试（涵盖通用视频问答、长视频问答、时间定位和复杂推理四个主要视频领域）上的广泛实验表明，VideoSSR持续提升模型性能，平均改进超过5%。

Conclusion: VideoSSR为开发更先进的MLLMs视频理解能力提供了一个有效的基础框架，证明了利用视频内在信息自生成训练数据的可行性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has substantially
advanced the video understanding capabilities of Multimodal Large Language
Models (MLLMs). However, the rapid progress of MLLMs is outpacing the
complexity of existing video datasets, while the manual annotation of new,
high-quality data remains prohibitively expensive. This work investigates a
pivotal question: Can the rich, intrinsic information within videos be
harnessed to self-generate high-quality, verifiable training data? To
investigate this, we introduce three self-supervised pretext tasks: Anomaly
Grounding, Object Counting, and Temporal Jigsaw. We construct the Video
Intrinsic Understanding Benchmark (VIUBench) to validate their difficulty,
revealing that current state-of-the-art MLLMs struggle significantly on these
tasks. Building upon these pretext tasks, we develop the VideoSSR-30K dataset
and propose VideoSSR, a novel video self-supervised reinforcement learning
framework for RLVR. Extensive experiments across 17 benchmarks, spanning four
major video domains (General Video QA, Long Video QA, Temporal Grounding, and
Complex Reasoning), demonstrate that VideoSSR consistently enhances model
performance, yielding an average improvement of over 5\%. These results
establish VideoSSR as a potent foundational framework for developing more
advanced video understanding in MLLMs. The code is available at
https://github.com/lcqysl/VideoSSR.

</details>


### [68] [From ACR O-RADS 2022 to Explainable Deep Learning: Comparative Performance of Expert Radiologists, Convolutional Neural Networks, Vision Transformers, and Fusion Models in Ovarian Masses](https://arxiv.org/abs/2511.06282)
*Ali Abbasian Ardakani,Afshin Mohammadi,Alisa Mohebbi,Anushya Vijayananthan,Sook Sam Leong,Lim Yi Ting,Mohd Kamil Bin Mohamad Fabell,U Rajendra Acharya,Sepideh Hatamikia*

Main category: cs.CV

TL;DR: 该研究评估了放射科医生使用O-RADS v2022系统诊断卵巢附件病变的性能，并与深度学习模型进行比较。结果显示ViT模型表现最佳，人机混合框架可进一步提升诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 虽然O-RADS v2022系统改进了卵巢附件病变的风险分层，但人工判读仍存在变异性和保守阈值问题。深度学习模型在卵巢病变特征识别方面显示出潜力，需要评估其与放射科医生表现的对比。

Method: 单中心回顾性队列研究，纳入227名患者的512个卵巢附件肿块图像。训练和验证了16个深度学习模型，包括DenseNets、EfficientNets、ResNets、VGGs、Xception和ViTs，并构建了结合放射科医生O-RADS评分与DL预测概率的混合模型。

Result: 放射科医生单独使用O-RADS评估的AUC为0.683，准确率68.0%。CNN模型AUC为0.620-0.908，准确率59.2%-86.4%；ViT16-384表现最佳，AUC达0.941，准确率87.4%。人机混合框架显著提升了CNN模型性能，但对ViT模型的提升不显著。

Conclusion: 深度学习模型显著优于放射科医生单独使用O-RADS v2022评估，专家评分与AI整合可获得最高的诊断准确性和区分度。人机混合范式在标准化盆腔超声判读、减少假阳性和改善高风险病变检测方面具有巨大潜力。

Abstract: Background: The 2022 update of the Ovarian-Adnexal Reporting and Data System
(O-RADS) ultrasound classification refines risk stratification for adnexal
lesions, yet human interpretation remains subject to variability and
conservative thresholds. Concurrently, deep learning (DL) models have
demonstrated promise in image-based ovarian lesion characterization. This study
evaluates radiologist performance applying O-RADS v2022, compares it to leading
convolutional neural network (CNN) and Vision Transformer (ViT) models, and
investigates the diagnostic gains achieved by hybrid human-AI frameworks.
Methods: In this single-center, retrospective cohort study, a total of 512
adnexal mass images from 227 patients (110 with at least one malignant cyst)
were included. Sixteen DL models, including DenseNets, EfficientNets, ResNets,
VGGs, Xception, and ViTs, were trained and validated. A hybrid model
integrating radiologist O-RADS scores with DL-predicted probabilities was also
built for each scheme. Results: Radiologist-only O-RADS assessment achieved an
AUC of 0.683 and an overall accuracy of 68.0%. CNN models yielded AUCs of 0.620
to 0.908 and accuracies of 59.2% to 86.4%, while ViT16-384 reached the best
performance, with an AUC of 0.941 and an accuracy of 87.4%. Hybrid human-AI
frameworks further significantly enhanced the performance of CNN models;
however, the improvement for ViT models was not statistically significant
(P-value >0.05). Conclusions: DL models markedly outperform radiologist-only
O-RADS v2022 assessment, and the integration of expert scores with AI yields
the highest diagnostic accuracy and discrimination. Hybrid human-AI paradigms
hold substantial potential to standardize pelvic ultrasound interpretation,
reduce false positives, and improve detection of high-risk lesions.

</details>


### [69] [TinyChemVL: Advancing Chemical Vision-Language Models via Efficient Visual Token Reduction and Complex Reaction Tasks](https://arxiv.org/abs/2511.06283)
*Xuanle Zhao,Shuxin Zeng,Yinyuan Cai,Xiang Cheng,Duzhen Zhang,Xiuyi Chen,Bo Xu*

Main category: cs.CV

TL;DR: 本文提出了TinyChemVL，一种高效的化学视觉语言模型，通过视觉令牌减少和反应级任务来提高模型效率和推理能力，同时创建了ChemRxn-V基准来评估基于视觉的反应识别和预测任务。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在化学领域应用有限，主要关注文本而忽略关键视觉信息（如分子结构），且存在计算效率低和任务范围窄的问题。

Method: 采用视觉令牌减少技术降低计算复杂度，引入反应级任务增强推理能力，构建包含4B参数的轻量化模型架构。

Result: TinyChemVL在分子和反应任务上表现优异，推理和训练速度更快，仅使用ChemVLM 1/16的视觉令牌即可超越其性能。

Conclusion: 通过协同设计模型架构和任务复杂度，成功构建了高效且强大的化学领域视觉语言模型。

Abstract: While Vision Language Models (VLMs) have demonstrated remarkable capabilities
in general visual understanding, their application in the chemical domain has
been limited, with previous works predominantly focusing on text and thus
overlooking critical visual information, such as molecular structures. Current
approaches that directly adopt standard VLMs for chemical tasks suffer from two
primary issues: (i) computational inefficiency of processing entire chemical
images with non-informative backgrounds. (ii) a narrow scope on molecular-level
tasks that restricts progress in chemical reasoning. In this work, we propose
\textbf{TinyChemVL}, an efficient and powerful chemical VLM that leverages
visual token reduction and reaction-level tasks to improve model efficiency and
reasoning capacity. Also, we propose \textbf{ChemRxn-V}, a reaction-level
benchmark for assessing vision-based reaction recognition and prediction tasks.
Directly predicting reaction products from molecular images poses a non-trivial
challenge, as it requires models to integrate both recognition and reasoning
capacities. Our results demonstrate that with only 4B parameters, TinyChemVL
achieves superior performance on both molecular and reaction tasks while
demonstrating faster inference and training speeds compared to existing models.
Notably, TinyChemVL outperforms ChemVLM while utilizing only 1/16th of the
visual tokens. This work builds efficient yet powerful VLMs for chemical
domains by co-designing model architecture and task complexity.

</details>


### [70] [Learning-Based Vision Systems for Semi-Autonomous Forklift Operation in Industrial Warehouse Environments](https://arxiv.org/abs/2511.06295)
*Vamshika Sutar,Mahek Maheshwari,Archak Mittal*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉的托盘和托盘孔检测与映射框架，使用单个标准摄像头，通过优化的YOLO架构实现高精度检测，为叉车提供经济高效的自动化解决方案。


<details>
  <summary>Details</summary>
Motivation: 仓库物料搬运自动化需要低成本、鲁棒的感知系统，现有方案成本较高，需要开发经济实用的视觉感知模块来提升叉车和AGV的自动化水平。

Method: 采用YOLOv8和YOLOv11架构，通过Optuna驱动的超参数优化和空间后处理增强性能，开发创新的托盘孔映射模块将检测结果转换为可操作的空间表示。

Result: 在自定义数据集上的实验显示，YOLOv8实现高精度检测，而优化配置下的YOLOv11提供更优精度和稳定收敛，验证了低成本视觉感知模块的可行性。

Conclusion: 该研究为仓库自动化提供了一种可扩展的方法，促进了更安全、经济和智能的物流操作，证明了基于标准摄像头的经济高效解决方案的可行性。

Abstract: The automation of material handling in warehouses increasingly relies on
robust, low cost perception systems for forklifts and Automated Guided Vehicles
(AGVs). This work presents a vision based framework for pallet and pallet hole
detection and mapping using a single standard camera. We utilized YOLOv8 and
YOLOv11 architectures, enhanced through Optuna driven hyperparameter
optimization and spatial post processing. An innovative pallet hole mapping
module converts the detections into actionable spatial representations,
enabling accurate pallet and pallet hole association for forklift operation.
Experiments on a custom dataset augmented with real warehouse imagery show that
YOLOv8 achieves high pallet and pallet hole detection accuracy, while YOLOv11,
particularly under optimized configurations, offers superior precision and
stable convergence. The results demonstrate the feasibility of a cost
effective, retrofittable visual perception module for forklifts. This study
proposes a scalable approach to advancing warehouse automation, promoting
safer, economical, and intelligent logistics operations.

</details>


### [71] [Physics-Informed Deformable Gaussian Splatting: Towards Unified Constitutive Laws for Time-Evolving Material Field](https://arxiv.org/abs/2511.06299)
*Haoqin Hong,Ding Fan,Fubin Dou,Zhi-Li Zhou,Haoran Sun,Congcong Zhu,Jingrun Chen*

Main category: cs.CV

TL;DR: 本文提出了PIDG方法，将3D高斯粒子视为具有时变本构参数的拉格朗日材料点，通过运动投影的2D光流进行监督，实现了物理一致的动态场景重建。


<details>
  <summary>Details</summary>
Motivation: 纯数据驱动的3D高斯溅射在捕捉动态场景中多样化的物理驱动运动模式方面存在困难，需要引入物理约束来提升重建质量。

Method: 采用静态-动态解耦的4D分解哈希编码重建几何和运动；施加柯西动量残差作为物理约束；通过匹配拉格朗日粒子流与相机补偿光流进行数据拟合监督。

Result: 在自定义物理驱动数据集以及标准合成和真实世界数据集上的实验表明，该方法在物理一致性和单目动态重建质量方面取得了显著提升。

Conclusion: PIDG方法通过结合物理约束和光流监督，有效提升了动态场景重建的物理一致性和质量。

Abstract: Recently, 3D Gaussian Splatting (3DGS), an explicit scene representation
technique, has shown significant promise for dynamic novel-view synthesis from
monocular video input. However, purely data-driven 3DGS often struggles to
capture the diverse physics-driven motion patterns in dynamic scenes. To fill
this gap, we propose Physics-Informed Deformable Gaussian Splatting (PIDG),
which treats each Gaussian particle as a Lagrangian material point with
time-varying constitutive parameters and is supervised by 2D optical flow via
motion projection. Specifically, we adopt static-dynamic decoupled 4D
decomposed hash encoding to reconstruct geometry and motion efficiently.
Subsequently, we impose the Cauchy momentum residual as a physics constraint,
enabling independent prediction of each particle's velocity and constitutive
stress via a time-evolving material field. Finally, we further supervise data
fitting by matching Lagrangian particle flow to camera-compensated optical
flow, which accelerates convergence and improves generalization. Experiments on
a custom physics-driven dataset as well as on standard synthetic and real-world
datasets demonstrate significant gains in physical consistency and monocular
dynamic reconstruction quality.

</details>


### [72] [Adaptive 3D Reconstruction via Diffusion Priors and Forward Curvature-Matching Likelihood Updates](https://arxiv.org/abs/2511.06310)
*Seunghyeok Shin,Dabin Kim,Hongki Lim*

Main category: cs.CV

TL;DR: 该论文提出了一种新的前向曲率匹配（FCM）更新方法，结合扩散采样来解决图像到点云重建问题。该方法通过动态确定最优步长，实现了高保真度的单视图和多视图重建，支持多种输入模态而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有基于生成模型的方法，特别是直接学习后验的扩散模型方法存在不灵活性：需要训练时的条件信号、仅支持固定数量的输入视图，以及需要为不同测量重新训练。最近的扩散方法尝试通过结合先验模型和似然更新来解决，但依赖启发式固定步长导致收敛慢和重建质量不佳。

Method: 将新颖的前向曲率匹配（FCM）更新方法与扩散采样相结合。该方法仅使用前向自动微分和有限差分曲率估计动态确定最优步长，实现似然更新的精确优化。支持通过简单算子替换实现多种输入模态。

Result: 在ShapeNet和CO3D数据集上的实验表明，该方法在相同或更低的NFEs下实现了优越的重建质量，产生更高的F-score和更低的CD和EMD。

Conclusion: 该方法验证了其在实践应用中的效率和适应性，能够实现高质量的点云重建。

Abstract: Reconstructing high-quality point clouds from images remains challenging in
computer vision. Existing generative-model-based approaches, particularly
diffusion-model approaches that directly learn the posterior, may suffer from
inflexibility -- they require conditioning signals during training, support
only a fixed number of input views, and need complete retraining for different
measurements. Recent diffusion-based methods have attempted to address this by
combining prior models with likelihood updates, but they rely on heuristic
fixed step sizes for the likelihood update that lead to slow convergence and
suboptimal reconstruction quality. We advance this line of approach by
integrating our novel Forward Curvature-Matching (FCM) update method with
diffusion sampling. Our method dynamically determines optimal step sizes using
only forward automatic differentiation and finite-difference curvature
estimates, enabling precise optimization of the likelihood update. This
formulation enables high-fidelity reconstruction from both single-view and
multi-view inputs, and supports various input modalities through simple
operator substitution -- all without retraining. Experiments on ShapeNet and
CO3D datasets demonstrate that our method achieves superior reconstruction
quality at matched or lower NFEs, yielding higher F-score and lower CD and EMD,
validating its efficiency and adaptability for practical applications. Code is
available at https://github.com/Seunghyeok0715/FCM

</details>


### [73] [Seq2Seq Models Reconstruct Visual Jigsaw Puzzles without Seeing Them](https://arxiv.org/abs/2511.06315)
*Gur Elkn,Ofir Itzhak Shahar,Ohad Ben-Shahar*

Main category: cs.CV

TL;DR: 本文提出了一种使用语言模型解决方形拼图的新方法，无需视觉输入，通过将拼图块转换为token序列，将拼图重组任务重新构建为序列到序列预测问题。


<details>
  <summary>Details</summary>
Motivation: 传统拼图算法主要基于视觉方法，本文探索从语言角度解决拼图问题，研究语言模型在非本领域问题上的能力。

Method: 引入专门的tokenizer将每个拼图块转换为离散token序列，使用编码器-解码器transformer模型作为"盲"求解器，仅基于token序列进行推理。

Result: 尽管故意限制访问视觉输入，模型在多个基准测试中达到最先进水平，通常优于基于视觉的方法。

Conclusion: 研究结果表明语言模型具有解决超出其原生领域问题的惊人能力，非常规方法可为拼图求解研究提供有前景的新方向。

Abstract: Jigsaw puzzles are primarily visual objects, whose algorithmic solutions have
traditionally been framed from a visual perspective. In this work, however, we
explore a fundamentally different approach: solving square jigsaw puzzles using
language models, without access to raw visual input. By introducing a
specialized tokenizer that converts each puzzle piece into a discrete sequence
of tokens, we reframe puzzle reassembly as a sequence-to-sequence prediction
task. Treated as "blind" solvers, encoder-decoder transformers accurately
reconstruct the original layout by reasoning over token sequences alone.
Despite being deliberately restricted from accessing visual input, our models
achieve state-of-the-art results across multiple benchmarks, often
outperforming vision-based methods. These findings highlight the surprising
capability of language models to solve problems beyond their native domain, and
suggest that unconventional approaches can inspire promising directions for
puzzle-solving research.

</details>


### [74] [Label-Efficient 3D Forest Mapping: Self-Supervised and Transfer Learning for Individual, Structural, and Species Analysis](https://arxiv.org/abs/2511.06331)
*Aldino Rizaldy,Fabian Ewald Fassnacht,Ahmed Jamal Afifi,Hua Jiang,Richard Gloaguen,Pedram Ghamisi*

Main category: cs.CV

TL;DR: 该论文探索使用自监督学习和迁移学习来减少对大规模标注数据的依赖，以改进从激光扫描点云中提取树木信息的三个任务：实例分割、语义分割和树木分类。


<details>
  <summary>Details</summary>
Motivation: 详细的结构和物种信息对精准林业、生物多样性保护和碳测绘至关重要，但深度学习模型需要大量标注数据，而3D点云的密集高质量标注在复杂森林中劳动密集且难以扩展。

Method: 采用自监督学习和迁移学习架构，结合领域适应技术，开发统一框架从原始点云到树木划分、结构分析和物种分类。

Result: 自监督学习结合领域适应显著提升实例分割性能（AP50 +16.98%），自监督学习足以改进语义分割（mIoU +1.79%），分层迁移学习实现未见物种的准确分类（Jaccard +6.07%），预训练模型降低能耗约21%。

Conclusion: 该开源贡献旨在加速从激光扫描点云中提取个体树木信息的操作化应用，支持林业、生物多样性和碳测绘，同时减少对大规模标注数据的依赖。

Abstract: Detailed structural and species information on individual tree level is
increasingly important to support precision forestry, biodiversity
conservation, and provide reference data for biomass and carbon mapping. Point
clouds from airborne and ground-based laser scanning are currently the most
suitable data source to rapidly derive such information at scale. Recent
advancements in deep learning improved segmenting and classifying individual
trees and identifying semantic tree components. However, deep learning models
typically require large amounts of annotated training data which limits further
improvement. Producing dense, high-quality annotations for 3D point clouds,
especially in complex forests, is labor-intensive and challenging to scale. We
explore strategies to reduce dependence on large annotated datasets using
self-supervised and transfer learning architectures. Our objective is to
improve performance across three tasks: instance segmentation, semantic
segmentation, and tree classification using realistic and operational training
sets. Our findings indicate that combining self-supervised learning with domain
adaptation significantly enhances instance segmentation compared to training
from scratch (AP50 +16.98%), self-supervised learning suffices for semantic
segmentation (mIoU +1.79%), and hierarchical transfer learning enables accurate
classification of unseen species (Jaccard +6.07%). To simplify use and
encourage uptake, we integrated the tasks into a unified framework,
streamlining the process from raw point clouds to tree delineation, structural
analysis, and species classification. Pretrained models reduce energy
consumption and carbon emissions by ~21%. This open-source contribution aims to
accelerate operational extraction of individual tree information from laser
scanning point clouds to support forestry, biodiversity, and carbon mapping.

</details>


### [75] [BuildingWorld: A Structured 3D Building Dataset for Urban Foundation Models](https://arxiv.org/abs/2511.06337)
*Shangfeng Huang,Ruisheng Wang,Xin Wang*

Main category: cs.CV

TL;DR: BuildingWorld是一个全面的3D建筑数据集，旨在解决现有建筑数据集建筑风格多样性不足的问题，包含来自全球五大洲约500万个LOD2建筑模型，并配有真实和模拟的机载LiDAR点云数据。


<details>
  <summary>Details</summary>
Motivation: 数字孪生技术在现代城市转型中日益重要，但现有学习模型训练数据集的建筑多样性有限，严重影响其在异构城市环境中的泛化能力。

Method: 收集来自北美、欧洲、亚洲、非洲和大洋洲的地理和建筑多样性建筑数据，构建包含约500万个LOD2建筑模型的数据集，提供真实和模拟的机载LiDAR点云，并引入Cyber City虚拟城市模型生成定制化点云分布数据。

Result: BuildingWorld提供了全球代表性的城市规模基础建模数据集，支持3D建筑重建、检测和分割研究，并提供了标准化的建筑重建评估指标。

Conclusion: BuildingWorld填补了建筑风格多样性的空白，为结构化3D城市环境中的大规模视觉模型和基础模型的训练、评估和比较提供了全面支持。

Abstract: As digital twins become central to the transformation of modern cities,
accurate and structured 3D building models emerge as a key enabler of
high-fidelity, updatable urban representations. These models underpin diverse
applications including energy modeling, urban planning, autonomous navigation,
and real-time reasoning. Despite recent advances in 3D urban modeling, most
learning-based models are trained on building datasets with limited
architectural diversity, which significantly undermines their generalizability
across heterogeneous urban environments. To address this limitation, we present
BuildingWorld, a comprehensive and structured 3D building dataset designed to
bridge the gap in stylistic diversity. It encompasses buildings from
geographically and architecturally diverse regions -- including North America,
Europe, Asia, Africa, and Oceania -- offering a globally representative dataset
for urban-scale foundation modeling and analysis. Specifically, BuildingWorld
provides about five million LOD2 building models collected from diverse
sources, accompanied by real and simulated airborne LiDAR point clouds. This
enables comprehensive research on 3D building reconstruction, detection and
segmentation. Cyber City, a virtual city model, is introduced to enable the
generation of unlimited training data with customized and structurally diverse
point cloud distributions. Furthermore, we provide standardized evaluation
metrics tailored for building reconstruction, aiming to facilitate the
training, evaluation, and comparison of large-scale vision models and
foundation models in structured 3D urban environments.

</details>


### [76] [GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding](https://arxiv.org/abs/2511.06348)
*Athul M. Mathew,Haithem Hermassi,Thariq Khalid,Arshad Ali Khan,Riad Souissi*

Main category: cs.CV

TL;DR: GazeVLM是一个新颖的视觉语言模型，用于图像中的多任务注视理解，包括人物检测、注视目标检测和注视物体识别。该模型通过融合RGB图像和HHA编码深度图，结合文本提示，在GazeFollow和VideoAttentionTarget数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然对视觉场景中的注视线索进行了建模，但仍需要一个统一的系统来同时利用视觉和语言提示进行注视理解。GazeVLM旨在将人物检测、注视目标检测和注视物体识别统一到一个框架中，提供对视觉注意力和意图估计的关键洞察。

Method: GazeVLM是一个基于视觉语言模型的多任务注视理解系统，整合了视觉（RGB和深度）和文本模态。通过融合RGB图像与HHA编码深度图，并结合文本提示来指导模型。该方法还引入了物体级注视检测指标（AP_ob）用于注视物体识别。

Result: 在GazeFollow和VideoAttentionTarget数据集上的实验表明，GazeVLM取得了显著改进，实现了最先进的评估分数。消融研究显示，RGB图像与HHA编码深度图的融合在文本提示引导下能获得最佳性能。

Conclusion: GazeVLM是首个将视觉语言模型应用于多任务注视理解的系统，通过视觉和语言模态的整合，在注视理解任务上表现出色，为视觉注意力和意图估计提供了统一的解决方案。

Abstract: Gaze understanding unifies the detection of people, their gaze targets, and
objects of interest into a single framework, offering critical insight into
visual attention and intent estimation. Although prior research has modelled
gaze cues in visual scenes, a unified system is still needed for gaze
understanding using both visual and language prompts. This paper introduces
GazeVLM, a novel Vision-Language Model (VLM) for multi-task gaze understanding
in images, addressing person detection, gaze target detection, and gaze object
identification. While other transformer-based methods exist for gaze analysis,
GazeVLM represents, to our knowledge, the first application of a VLM to these
combined tasks, allowing for selective execution of each task. Through the
integration of visual (RGB and depth) and textual modalities, our ablation
study on visual input combinations revealed that a fusion of RGB images with
HHA-encoded depth maps, guided by text prompts, yields superior performance. We
also introduce an object-level gaze detection metric for gaze object
identification ($AP_{ob}$). Through experiments, GazeVLM demonstrates
significant improvements, notably achieving state-of-the-art evaluation scores
on GazeFollow and VideoAttentionTarget datasets.

</details>


### [77] [AesTest: Measuring Aesthetic Intelligence from Perception to Production](https://arxiv.org/abs/2511.06360)
*Guolong Wang,Heng Huang,Zhiqiang Zhang,Wentian Li,Feilong Ma,Xin Jin*

Main category: cs.CV

TL;DR: 本文介绍了AesTest，一个用于评估多模态大语言模型美学感知和生产能力的综合基准，涵盖十个任务，整合了多样化数据源，支持多种美学查询类型。


<details>
  <summary>Details</summary>
Motivation: 现有图像美学评估基准在感知范围上较窄或缺乏多样性，无法系统评估美学生产能力，因此需要构建更全面的评估基准。

Method: 构建AesTest基准，包含十个多选任务，涵盖感知、欣赏、创作和摄影领域，基于生成学习心理学理论，整合专业编辑流程、摄影构图教程和众包偏好等多样化数据源。

Result: 评估显示，现有的指令调优IAA MLLMs和通用MLLMs在构建美学智能方面面临显著挑战。

Conclusion: AesTest基准将公开发布，以支持未来在美学智能领域的研究。

Abstract: Perceiving and producing aesthetic judgments is a fundamental yet
underexplored capability for multimodal large language models (MLLMs). However,
existing benchmarks for image aesthetic assessment (IAA) are narrow in
perception scope or lack the diversity needed to evaluate systematic aesthetic
production. To address this gap, we introduce AesTest, a comprehensive
benchmark for multimodal aesthetic perception and production, distinguished by
the following features: 1) It consists of curated multiple-choice questions
spanning ten tasks, covering perception, appreciation, creation, and
photography. These tasks are grounded in psychological theories of generative
learning. 2) It integrates data from diverse sources, including professional
editing workflows, photographic composition tutorials, and crowdsourced
preferences. It ensures coverage of both expert-level principles and real-world
variation. 3) It supports various aesthetic query types, such as
attribute-based analysis, emotional resonance, compositional choice, and
stylistic reasoning. We evaluate both instruction-tuned IAA MLLMs and general
MLLMs on AesTest, revealing significant challenges in building aesthetic
intelligence. We will publicly release AesTest to support future research in
this area.

</details>


### [78] [V-Shuffle: Zero-Shot Style Transfer via Value Shuffle](https://arxiv.org/abs/2511.06365)
*Haojun Tang,Qiwei Lin,Tongda Xu,Lida Huang,Yan Wang*

Main category: cs.CV

TL;DR: V-Shuffle是一种零样本风格迁移方法，通过打乱扩散模型自注意力层中的值特征来破坏风格图像的语义内容，同时保留低级风格表示，有效解决了内容泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于注意力注入的风格迁移方法存在内容泄漏问题，即风格图像中不需要的语义内容会错误地出现在风格化输出中。

Method: 提出V-Shuffle方法，利用来自同一风格域的多个风格图像，在扩散模型的自注意力层中打乱值特征来隐式破坏风格图像的语义内容，同时引入混合风格正则化来补充高级风格纹理。

Result: 实证结果表明，V-Shuffle在使用多个风格图像时表现优异，在单风格图像应用时也优于先前的最先进方法。

Conclusion: V-Shuffle通过破坏风格图像的语义内容同时保留风格表示，在内容保持和风格保真度之间取得了良好平衡。

Abstract: Attention injection-based style transfer has achieved remarkable progress in
recent years. However, existing methods often suffer from content leakage,
where the undesired semantic content of the style image mistakenly appears in
the stylized output. In this paper, we propose V-Shuffle, a zero-shot style
transfer method that leverages multiple style images from the same style domain
to effectively navigate the trade-off between content preservation and style
fidelity. V-Shuffle implicitly disrupts the semantic content of the style
images by shuffling the value features within the self-attention layers of the
diffusion model, thereby preserving low-level style representations. We further
introduce a Hybrid Style Regularization that complements these low-level
representations with high-level style textures to enhance style fidelity.
Empirical results demonstrate that V-Shuffle achieves excellent performance
when utilizing multiple style images. Moreover, when applied to a single style
image, V-Shuffle outperforms previous state-of-the-art methods.

</details>


### [79] [InfoAffect: A Dataset for Affective Analysis of Infographics](https://arxiv.org/abs/2511.06404)
*Zihang Fu,Yunchao Wang,Chenyu Huang,Guodao Sun,Ronghua Liang*

Main category: cs.CV

TL;DR: 本文介绍了InfoAffect数据集，这是一个包含3.5k个情感标注样本的数据集，结合了文本内容和真实世界的信息图表，用于探索信息图表的情感维度。


<details>
  <summary>Details</summary>
Motivation: 信息图表广泛用于传达复杂信息，但由于数据资源稀缺，其情感维度仍未得到充分探索。

Method: 从六个领域收集原始数据，通过预处理、伴随文本优先方法和三种策略保证质量和合规性。构建情感表约束标注，使用五个最先进的多模态大语言模型分析两种模态，通过互惠排名融合算法融合输出以获得稳健的情感和置信度。

Result: 通过用户研究和两个实验验证可用性，使用复合情感一致性指数评估InfoAffect数据集，总体得分为0.986，表明高准确性。

Conclusion: InfoAffect数据集为信息图表的情感分析提供了高质量的资源，并通过严格的验证证明了其准确性和可用性。

Abstract: Infographics are widely used to convey complex information, yet their
affective dimensions remain underexplored due to the scarcity of data
resources. We introduce a 3.5k-sample affect-annotated InfoAffect dataset,
which combines textual content with real-world infographics. We first collect
the raw data from six domains and aligned them via preprocessing, the
accompanied-text-priority method, and three strategies to guarantee the quality
and compliance. After that we construct an affect table and use it to constrain
annotation. Five state-of-the-art multimodal large language models (MLLMs) then
analyze both modalities, and their outputs are fused with Reciprocal Rank
Fusion (RRF) algorithm to yield robust affects and confidences. We conducted a
user study with two experiments to validate usability and assess InfoAffect
dataset using the Composite Affect Consistency Index (CACI), achieving an
overall score of 0.986, which indicates high accuracy.

</details>


### [80] [On Modality Incomplete Infrared-Visible Object Detection: An Architecture Compatibility Perspective](https://arxiv.org/abs/2511.06406)
*Shuo Yang,Yinghui Xing,Shizhou Zhang,Zhilong Niu*

Main category: cs.CV

TL;DR: 本文提出了一种用于红外和可见光目标检测的Scarf Neck模块，通过模态无关的可变形注意力机制，使检测器能够在训练和推理时灵活适应单模态或双模态数据，解决了模态不完整情况下的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 当前红外和可见光目标检测模型在面对不完整模态数据时性能显著下降，特别是当主导模态缺失时。本文从架构兼容性角度深入研究了模态不完整的IVOD问题。

Method: 提出即插即用的Scarf Neck模块，引入模态无关的可变形注意力机制；设计伪模态丢弃策略充分利用多模态信息；建立全面的模态不完整IVOD基准测试。

Result: Scarf-DETR不仅在模态缺失场景下表现优异，在标准IVOD模态完整基准测试中也取得了优越性能。

Conclusion: 所提出的Scarf-DETR方法能够有效解决模态不完整的红外和可见光目标检测问题，具有架构兼容性和鲁棒性。

Abstract: Infrared and visible object detection (IVOD) is essential for numerous
around-the-clock applications. Despite notable advancements, current IVOD
models exhibit notable performance declines when confronted with incomplete
modality data, particularly if the dominant modality is missing. In this paper,
we take a thorough investigation on modality incomplete IVOD problem from an
architecture compatibility perspective. Specifically, we propose a
plug-and-play Scarf Neck module for DETR variants, which introduces a
modality-agnostic deformable attention mechanism to enable the IVOD detector to
flexibly adapt to any single or double modalities during training and
inference. When training Scarf-DETR, we design a pseudo modality dropout
strategy to fully utilize the multi-modality information, making the detector
compatible and robust to both working modes of single and double modalities.
Moreover, we introduce a comprehensive benchmark for the modality-incomplete
IVOD task aimed at thoroughly assessing situations where the absent modality is
either dominant or secondary. Our proposed Scarf-DETR not only performs
excellently in missing modality scenarios but also achieves superior
performances on the standard IVOD modality complete benchmarks. Our code will
be available at https://github.com/YinghuiXing/Scarf-DETR.

</details>


### [81] [VDNeRF: Vision-only Dynamic Neural Radiance Field for Urban Scenes](https://arxiv.org/abs/2511.06408)
*Zhengyu Zou,Jingfeng Li,Hao Li,Xiaolei Hou,Jinwen Hu,Jingkun Chen,Lechao Cheng,Dingwen Zhang*

Main category: cs.CV

TL;DR: VDNeRF是一种仅使用视觉信息的动态NeRF方法，能够在无需相机姿态信息的情况下准确恢复相机轨迹并学习动态城市场景的时空表示。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法在自动驾驶和机器人感知等应用中面临挑战，主要由于难以获取准确相机姿态以及处理大规模动态环境的限制。

Method: 使用两个独立的NeRF模型联合重建场景：静态NeRF模型优化相机姿态和静态背景，动态NeRF模型结合3D场景流确保动态对象的准确重建。设计了有效的训练框架来解决相机运动和独立物体运动之间的模糊性问题。

Result: 在主流城市驾驶数据集上的广泛评估表明，VDNeRF在相机姿态估计和动态新视角合成方面均优于最先进的基于NeRF的无姿态方法。

Conclusion: VDNeRF能够在不依赖额外相机姿态信息或昂贵传感器数据的情况下，实现相机轨迹的准确恢复和动态城市场景的时空表示学习。

Abstract: Neural Radiance Fields (NeRFs) implicitly model continuous three-dimensional
scenes using a set of images with known camera poses, enabling the rendering of
photorealistic novel views. However, existing NeRF-based methods encounter
challenges in applications such as autonomous driving and robotic perception,
primarily due to the difficulty of capturing accurate camera poses and
limitations in handling large-scale dynamic environments. To address these
issues, we propose Vision-only Dynamic NeRF (VDNeRF), a method that accurately
recovers camera trajectories and learns spatiotemporal representations for
dynamic urban scenes without requiring additional camera pose information or
expensive sensor data. VDNeRF employs two separate NeRF models to jointly
reconstruct the scene. The static NeRF model optimizes camera poses and static
background, while the dynamic NeRF model incorporates the 3D scene flow to
ensure accurate and consistent reconstruction of dynamic objects. To address
the ambiguity between camera motion and independent object motion, we design an
effective and powerful training framework to achieve robust camera pose
estimation and self-supervised decomposition of static and dynamic elements in
a scene. Extensive evaluations on mainstream urban driving datasets demonstrate
that VDNeRF surpasses state-of-the-art NeRF-based pose-free methods in both
camera pose estimation and dynamic novel view synthesis.

</details>


### [82] [Diagnose Like A REAL Pathologist: An Uncertainty-Focused Approach for Trustworthy Multi-Resolution Multiple Instance Learning](https://arxiv.org/abs/2511.06433)
*Sungrae Hong,Sol Lee,Jisu Shin,Mun Yong Yi*

Main category: cs.CV

TL;DR: 本文提出了一种不确定性聚焦的校准多实例学习（UFC-MIL）方法，用于病理图像诊断，通过多分辨率图像模仿病理学家检查行为，并提供校准的诊断预测。


<details>
  <summary>Details</summary>
Motivation: 现有多分辨率MIL方法仅关注性能提升，缺乏对临床专家可信赖诊断结果所需的良好校准研究。

Method: UFC-MIL包含新颖的补丁级损失函数学习实例潜在模式并表达其分类不确定性，采用基于注意力的架构和邻域补丁聚合模块收集分类器特征，并通过补丁级不确定性校准聚合预测。

Result: 在具有挑战性的公共数据集上，UFC-MIL在模型校准方面表现出优越性能，同时实现了与最先进方法相当的分类准确率。

Conclusion: UFC-MIL通过模仿病理学家检查行为并提供校准预测，为临床诊断提供了更可信赖的AI辅助工具，且无需多次迭代推理，具有重要实用优势。

Abstract: With the increasing demand for histopathological specimen examination and
diagnostic reporting, Multiple Instance Learning (MIL) has received heightened
research focus as a viable solution for AI-centric diagnostic aid. Recently, to
improve its performance and make it work more like a pathologist, several MIL
approaches based on the use of multiple-resolution images have been proposed,
delivering often higher performance than those that use single-resolution
images. Despite impressive recent developments of multiple-resolution MIL,
previous approaches only focus on improving performance, thereby lacking
research on well-calibrated MIL that clinical experts can rely on for
trustworthy diagnostic results. In this study, we propose Uncertainty-Focused
Calibrated MIL (UFC-MIL), which more closely mimics the pathologists'
examination behaviors while providing calibrated diagnostic predictions, using
multiple images with different resolutions. UFC-MIL includes a novel patch-wise
loss that learns the latent patterns of instances and expresses their
uncertainty for classification. Also, the attention-based architecture with a
neighbor patch aggregation module collects features for the classifier. In
addition, aggregated predictions are calibrated through patch-level uncertainty
without requiring multiple iterative inferences, which is a key practical
advantage. Against challenging public datasets, UFC-MIL shows superior
performance in model calibration while achieving classification accuracy
comparable to that of state-of-the-art methods.

</details>


### [83] [Countering Multi-modal Representation Collapse through Rank-targeted Fusion](https://arxiv.org/abs/2511.06450)
*Seulgi Kim,Kiran Kokilepersaud,Mohit Prabhushankar,Ghassan AlRegib*

Main category: cs.CV

TL;DR: 该论文提出了一个名为Rank-enhancing Token Fuser的多模态融合框架，通过有效秩来量化和解决特征崩溃和模态崩溃问题，在动作预测任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态融合方法常面临特征崩溃和模态崩溃问题，现有方法分别处理这两个问题，缺乏统一框架。需要一种能够同时解决这两种崩溃的有效方法。

Method: 提出了基于有效秩的Rank-enhancing Token Fuser框架，有选择地将一个模态中信息量较少的特征与另一个模态的互补特征融合，增加融合表示的有效秩。

Result: 在NTURGBD、UTKinect和DARai数据集上的实验表明，该方法比现有最先进方法性能提升高达3.74%。

Conclusion: 有效秩可作为量化特征崩溃和模态崩溃的有用指标，深度与RGB融合能保持表示平衡，提出的R3D框架在多模态融合中表现出色。

Abstract: Multi-modal fusion methods often suffer from two types of representation
collapse: feature collapse where individual dimensions lose their
discriminative power (as measured by eigenspectra), and modality collapse where
one dominant modality overwhelms the other. Applications like human action
anticipation that require fusing multifarious sensor data are hindered by both
feature and modality collapse. However, existing methods attempt to counter
feature collapse and modality collapse separately. This is because there is no
unifying framework that efficiently addresses feature and modality collapse in
conjunction. In this paper, we posit the utility of effective rank as an
informative measure that can be utilized to quantify and counter both the
representation collapses. We propose \textit{Rank-enhancing Token Fuser}, a
theoretically grounded fusion framework that selectively blends less
informative features from one modality with complementary features from another
modality. We show that our method increases the effective rank of the fused
representation. To address modality collapse, we evaluate modality combinations
that mutually increase each others' effective rank. We show that depth
maintains representational balance when fused with RGB, avoiding modality
collapse. We validate our method on action anticipation, where we present
\texttt{R3D}, a depth-informed fusion framework. Extensive experiments on
NTURGBD, UTKinect, and DARai demonstrate that our approach significantly
outperforms prior state-of-the-art methods by up to 3.74\%. Our code is
available at:
\href{https://github.com/olivesgatech/R3D}{https://github.com/olivesgatech/R3D}.

</details>


### [84] [Inpaint360GS: Efficient Object-Aware 3D Inpainting via Gaussian Splatting for 360° Scenes](https://arxiv.org/abs/2511.06457)
*Shaoxiang Wang,Shihong Zhang,Christen Millerdurai,Rüdiger Westermann,Didier Stricker,Alain Pagani*

Main category: cs.CV

TL;DR: 提出Inpaint360GS框架，基于3D高斯泼溅技术解决复杂360度场景中的多目标修复问题，通过2D分割蒸馏到3D和虚拟相机视图实现准确的对象级编辑和一致场景补全。


<details>
  <summary>Details</summary>
Motivation: 当前基于NeRF和3DGS的单目标正面修复已有进展，但复杂360度场景的修复仍面临三大挑战：3D环境中目标识别困难、多目标场景严重遮挡导致修复区域定义困难、跨视图一致性和高质量外观保持困难。

Method: 基于3DGS构建灵活360度编辑框架，将2D分割蒸馏到3D空间，利用虚拟相机视图提供上下文指导，支持多目标移除和3D空间高保真修复。

Result: 实验表明Inpaint360GS优于现有基线方法，达到最先进性能，并创建了专门用于360度修复的新数据集。

Conclusion: Inpaint360GS成功解决了复杂360度场景修复的关键挑战，实现了准确的对象级编辑和一致的场景补全，为360度场景编辑提供了有效解决方案。

Abstract: Despite recent advances in single-object front-facing inpainting using NeRF
and 3D Gaussian Splatting (3DGS), inpainting in complex 360{\deg} scenes
remains largely underexplored. This is primarily due to three key challenges:
(i) identifying target objects in the 3D field of 360{\deg} environments, (ii)
dealing with severe occlusions in multi-object scenes, which makes it hard to
define regions to inpaint, and (iii) maintaining consistent and high-quality
appearance across views effectively. To tackle these challenges, we propose
Inpaint360GS, a flexible 360{\deg} editing framework based on 3DGS that
supports multi-object removal and high-fidelity inpainting in 3D space. By
distilling 2D segmentation into 3D and leveraging virtual camera views for
contextual guidance, our method enables accurate object-level editing and
consistent scene completion. We further introduce a new dataset tailored for
360{\deg} inpainting, addressing the lack of ground truth object-free scenes.
Experiments demonstrate that Inpaint360GS outperforms existing baselines and
achieves state-of-the-art performance. Project page:
https://dfki-av.github.io/inpaint360gs/

</details>


### [85] [NOAH: Benchmarking Narrative Prior driven Hallucination and Omission in Video Large Language Models](https://arxiv.org/abs/2511.06475)
*Kyuho Lee,Euntae Kim,Jinwoo Choi,Buru Chang*

Main category: cs.CV

TL;DR: 本文提出了NOAH基准测试，用于系统评估视频大语言模型中由叙事先验引起的幻觉和遗漏错误，发现大多数模型都存在这类问题且错误模式因架构、事件相似度和插入位置而异。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在追求叙事连贯性时引入了叙事先验偏置，导致模型优先考虑故事情节一致性而非严格基于视觉证据，从而产生幻觉和遗漏错误。

Method: 构建NOAH基准测试，通过将其他来源的片段插入目标视频来创建复合视频，控制语义相似度和插入位置，设计了包含字幕任务和三种问答任务（存在性、时序性、叙事性）的评估框架。

Result: 实验发现：(i)大多数视频大语言模型存在叙事先验驱动的幻觉和遗漏；(ii)错误模式因模型架构、事件相似度和插入位置而异；(iii)在帧数较少时对叙事先验的依赖加剧，当事件连续性较弱时会放大错误。

Conclusion: NOAH是首个标准化评估视频大语言模型中叙事先验引起的幻觉和遗漏的基准，为开发更可靠和可信的模型提供了基础。

Abstract: Video large language models (Video LLMs) have recently achieved strong
performance on tasks such as captioning, summarization, and question answering.
Many models and training methods explicitly encourage continuity across events
to enhance narrative coherence. While this improves fluency, it also introduces
an inductive bias that prioritizes storyline consistency over strict grounding
in visual evidence. We identify this bias, which we call narrative prior, as a
key driver of two errors: hallucinations, where non-existent events are
introduced or existing ones are misinterpreted, and omissions, where factual
events are suppressed because they are misaligned with surrounding context. To
systematically evaluate narrative prior-induced errors, we introduce NOAH, a
large-scale benchmark that constructs composite videos by inserting clips from
other sources into target videos. By varying semantic similarity and insertion
position, our benchmark enables controlled and scalable analysis of narrative
priors. We design one captioning task with tailored metrics and three QA tasks
- Existence, Temporal, and Narrative - yielding more than 60K evaluation
samples. Extensive experiments yield three key findings: (i) most Video LLMs
exhibit hallucinations and omissions driven by narrative priors, (ii) the
patterns of these errors vary across architectures and depend on event
similarity and insertion position, and (iii) reliance on narrative priors
intensifies under sampling with fewer frames, amplifying errors when event
continuity is weak. We establish NOAH as the first standardized evaluation of
narrative prior-induced hallucination and omission in Video LLMs, providing a
foundation for developing more reliable and trustworthy models. Our benchmark
and code are available at https://anonymous550520.github.io/.

</details>


### [86] [Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models](https://arxiv.org/abs/2511.06490)
*Yule Chen,Yufan Ren,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: AI4VA-FG是首个针对视觉语言模型在漫画理解方面的细粒度基准测试，评估了从基础识别到高级推理的多项任务。研究发现现有模型在漫画理解方面存在显著不足，并通过监督微调和强化学习等后训练策略显著提升了模型性能，特别是提出的区域感知强化学习方法在实体识别和故事线排序方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在自然图像上表现出色，但在处理风格化线条艺术、拟声词和密集多面板布局的漫画时存在困难。需要专门的基准测试和训练方法来提升模型在漫画理解领域的能力。

Method: 提出了AI4VA-FG基准测试，涵盖从基础识别到高级推理的多层次任务。系统研究了三种后训练策略：基于解决方案的监督微调、基于推理轨迹的监督微调以及强化学习。特别提出了区域感知强化学习方法，训练模型通过放大操作动态关注相关区域。

Result: 评估了GPT-4o、Gemini-2.5和Qwen2.5-VL等先进模型，发现在基准测试的核心任务上存在显著性能缺陷。当应用于Qwen2.5-VL模型时，强化学习和区域感知强化学习在低级实体识别和高级故事线排序方面带来了显著性能提升。

Conclusion: 漫画理解仍然是一个未解决的挑战，但通过专门的后训练策略，特别是区域感知强化学习方法，可以显著提升视觉语言模型在漫画领域的准确性和效率。

Abstract: Complex visual narratives, such as comics, present a significant challenge to
Vision-Language Models (VLMs). Despite excelling on natural images, VLMs often
struggle with stylized line art, onomatopoeia, and densely packed multi-panel
layouts. To address this gap, we introduce AI4VA-FG, the first fine-grained and
comprehensive benchmark for VLM-based comic understanding. It spans tasks from
foundational recognition and detection to high-level character reasoning and
narrative construction, supported by dense annotations for characters, poses,
and depth. Beyond that, we evaluate state-of-the-art proprietary models,
including GPT-4o and Gemini-2.5, and open-source models such as Qwen2.5-VL,
revealing substantial performance deficits across core tasks of our benchmarks
and underscoring that comic understanding remains an unsolved challenge. To
enhance VLMs' capabilities in this domain, we systematically investigate
post-training strategies, including supervised fine-tuning on solutions
(SFT-S), supervised fine-tuning on reasoning trajectories (SFT-R), and
reinforcement learning (RL). Beyond that, inspired by the emerging "Thinking
with Images" paradigm, we propose Region-Aware Reinforcement Learning (RARL)
for VLMs, which trains models to dynamically attend to relevant regions through
zoom-in operations. We observe that when applied to the Qwen2.5-VL model, RL
and RARL yield significant gains in low-level entity recognition and high-level
storyline ordering, paving the way for more accurate and efficient VLM
applications in the comics domain.

</details>


### [87] [SportR: A Benchmark for Multimodal Large Language Model Reasoning in Sports](https://arxiv.org/abs/2511.06499)
*Haotian Xia,Haonan Ge,Junbo Zou,Hyun Woo Choi,Xuebin Zhang,Danny Suradja,Botao Rui,Ethan Tran,Wendy Jin,Zhen Ye,Xiyang Lin,Christopher Lai,Shengjie Zhang,Junwen Miao,Shichao Chen,Rhys Tracy,Vicente Ordonez,Weining Shen,Hanjie Chen*

Main category: cs.CV

TL;DR: SportR是首个多运动大规模基准测试，旨在训练和评估多模态大模型在体育智能推理方面的能力，包含5,017张图片和2,101个视频，提供7,118条高质量人工标注的思维链。


<details>
  <summary>Details</summary>
Motivation: 当前体育基准测试要么只覆盖单一运动，要么缺乏详细的推理链和精确的视觉基础，无法在多运动背景下稳健评估模型的核心能力。

Method: 构建包含图像和视频模态的数据集，采用渐进式层次结构的问答对设计，从简单违规识别到复杂处罚预测，并提供人工边界框标注测试视觉基础。

Result: 最先进的基线模型在最具挑战性的任务上表现不佳，通过监督微调和强化学习训练后分数有所提升但仍相对较低。

Conclusion: SportR为社区提出了新的挑战，为多模态体育推理的未来研究提供了关键资源。

Abstract: Deeply understanding sports requires an intricate blend of fine-grained
visual perception and rule-based reasoning - a challenge that pushes the limits
of current multimodal models. To succeed, models must master three critical
capabilities: perceiving nuanced visual details, applying abstract sport rule
knowledge, and grounding that knowledge in specific visual evidence. Current
sports benchmarks either cover single sports or lack the detailed reasoning
chains and precise visual grounding needed to robustly evaluate these core
capabilities in a multi-sport context. To address this gap, we introduce
SportR, the first multi-sports large-scale benchmark designed to train and
evaluate MLLMs on the fundamental reasoning required for sports intelligence.
Our benchmark provides a dataset of 5,017 images and 2,101 videos. To enable
granular evaluation, we structure our benchmark around a progressive hierarchy
of question-answer (QA) pairs designed to probe reasoning at increasing depths
- from simple infraction identification to complex penalty prediction. For the
most advanced tasks requiring multi-step reasoning, such as determining
penalties or explaining tactics, we provide 7,118 high-quality, human-authored
Chain of Thought (CoT) annotations. In addition, our benchmark incorporates
both image and video modalities and provides manual bounding box annotations to
test visual grounding in the image part directly. Extensive experiments
demonstrate the profound difficulty of our benchmark. State-of-the-art baseline
models perform poorly on our most challenging tasks. While training on our data
via Supervised Fine-Tuning and Reinforcement Learning improves these scores,
they remain relatively low, highlighting a significant gap in current model
capabilities. SportR presents a new challenge for the community, providing a
critical resource to drive future research in multimodal sports reasoning.

</details>


### [88] [Video Dataset for Surgical Phase, Keypoint, and Instrument Recognition in Laparoscopic Surgery (PhaKIR)](https://arxiv.org/abs/2511.06549)
*Tobias Rueckert,Raphaela Maerkl,David Rauber,Leonard Klausmann,Max Gutbrod,Daniel Rueckert,Hubertus Feussner,Dirk Wilhelm,Christoph Palm*

Main category: cs.CV

TL;DR: 提出了PhaKIR数据集，包含8个完整的腹腔镜胆囊切除术视频，提供手术阶段识别、器械关键点估计和器械实例分割的帧级标注，是首个多机构联合提供这些标注的数据集。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助微创手术需要计算机视觉方法进行器械识别和手术流程理解，但现有数据集往往处理孤立任务、忽略时间依赖性或缺乏多中心变异性。

Method: 收集了来自三个医疗中心的8个完整腹腔镜胆囊切除术视频，提供帧级标注，包括手术阶段识别（485,875帧）、器械关键点估计（19,435帧）和器械实例分割（19,435帧）。

Result: 创建了PhaKIR数据集，作为首个多机构联合提供阶段标签、器械姿态信息和像素级器械分割的数据集，同时支持利用时间上下文。

Conclusion: PhaKIR数据集为手术场景理解提供了基准，通过MICCAI 2024的EndoVis挑战赛进一步验证了数据集的质量和相关性，可在Zenodo平台上公开获取。

Abstract: Robotic- and computer-assisted minimally invasive surgery (RAMIS) is
increasingly relying on computer vision methods for reliable instrument
recognition and surgical workflow understanding. Developing such systems often
requires large, well-annotated datasets, but existing resources often address
isolated tasks, neglect temporal dependencies, or lack multi-center
variability. We present the Surgical Procedure Phase, Keypoint, and Instrument
Recognition (PhaKIR) dataset, comprising eight complete laparoscopic
cholecystectomy videos recorded at three medical centers. The dataset provides
frame-level annotations for three interconnected tasks: surgical phase
recognition (485,875 frames), instrument keypoint estimation (19,435 frames),
and instrument instance segmentation (19,435 frames). PhaKIR is, to our
knowledge, the first multi-institutional dataset to jointly provide phase
labels, instrument pose information, and pixel-accurate instrument
segmentations, while also enabling the exploitation of temporal context since
full surgical procedure sequences are available. It served as the basis for the
PhaKIR Challenge as part of the Endoscopic Vision (EndoVis) Challenge at MICCAI
2024 to benchmark methods in surgical scene understanding, thereby further
validating the dataset's quality and relevance. The dataset is publicly
available upon request via the Zenodo platform.

</details>


### [89] [Spatial-Frequency Enhanced Mamba for Multi-Modal Image Fusion](https://arxiv.org/abs/2511.06593)
*Hui Sun,Long Lv,Pingping Zhang,Tongdan Tang,Feng Tian,Weibing Sun,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为SFMFusion的新型多模态图像融合框架，通过结合空间-频率增强的Mamba模块和动态融合机制，有效解决了传统CNN感受野有限和Transformer计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态图像融合方法存在CNN感受野有限和Transformer计算成本高的问题，同时Mamba模型缺乏完整的空间和频率感知，且图像重建作为辅助任务的有效利用面临挑战。

Method: 提出三分支结构耦合图像融合与重建任务，设计空间-频率增强Mamba模块(SFMB)进行综合特征提取，并使用动态融合Mamba模块(DFMB)实现跨分支动态特征融合。

Result: 在六个多模态图像融合数据集上的广泛实验表明，该方法比大多数最先进方法取得了更好的结果。

Conclusion: SFMFusion框架通过空间-频率增强和动态融合机制，在多模态图像融合任务中表现出优越性能，为长距离依赖建模提供了有效解决方案。

Abstract: Multi-Modal Image Fusion (MMIF) aims to integrate complementary image
information from different modalities to produce informative images. Previous
deep learning-based MMIF methods generally adopt Convolutional Neural Networks
(CNNs) or Transformers for feature extraction. However, these methods deliver
unsatisfactory performances due to the limited receptive field of CNNs and the
high computational cost of Transformers. Recently, Mamba has demonstrated a
powerful potential for modeling long-range dependencies with linear complexity,
providing a promising solution to MMIF. Unfortunately, Mamba lacks full spatial
and frequency perceptions, which are very important for MMIF. Moreover,
employing Image Reconstruction (IR) as an auxiliary task has been proven
beneficial for MMIF. However, a primary challenge is how to leverage IR
efficiently and effectively. To address the above issues, we propose a novel
framework named Spatial-Frequency Enhanced Mamba Fusion (SFMFusion) for MMIF.
More specifically, we first propose a three-branch structure to couple MMIF and
IR, which can retain complete contents from source images. Then, we propose the
Spatial-Frequency Enhanced Mamba Block (SFMB), which can enhance Mamba in both
spatial and frequency domains for comprehensive feature extraction. Finally, we
propose the Dynamic Fusion Mamba Block (DFMB), which can be deployed across
different branches for dynamic feature fusion. Extensive experiments show that
our method achieves better results than most state-of-the-art methods on six
MMIF datasets. The source code is available at
https://github.com/SunHui1216/SFMFusion.

</details>


### [90] [On Accurate and Robust Estimation of 3D and 2D Circular Center: Method and Application to Camera-Lidar Calibration](https://arxiv.org/abs/2511.06611)
*Jiajun Jiang,Xiao Hu,Wancheng Liu,Wei Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于几何原理的LiDAR-相机外参标定框架，通过鲁棒的3D圆中心估计和2D投影中心恢复方法，显著提高了圆形目标的3D-2D对应精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在LiDAR-相机外参标定中，由于解耦的3D拟合和错误的2D椭圆中心估计，难以实现准确的3D-2D圆形中心对应。

Method: 采用几何原理框架，包括基于共形几何代数和RANSAC的鲁棒3D圆中心估计器，以及通过弦长方差最小化恢复真实2D投影中心的方法，解决了双最小值歧义问题。

Result: 在合成和真实数据集上的评估表明，该框架显著优于现有最先进方法，减少了外参估计误差，并在不同传感器和目标类型（包括自然圆形物体）上实现了鲁棒标定。

Conclusion: 所提出的几何框架有效解决了LiDAR-相机外参标定中的3D-2D圆形中心对应问题，具有优异的性能和通用性，代码将公开发布以确保可复现性。

Abstract: Circular targets are widely used in LiDAR-camera extrinsic calibration due to
their geometric consistency and ease of detection. However, achieving accurate
3D-2D circular center correspondence remains challenging. Existing methods
often fail due to decoupled 3D fitting and erroneous 2D ellipse-center
estimation. To address this, we propose a geometrically principled framework
featuring two innovations: (i) a robust 3D circle center estimator based on
conformal geometric algebra and RANSAC; and (ii) a chord-length variance
minimization method to recover the true 2D projected center, resolving its
dual-minima ambi- guity via homography validation or a quasi-RANSAC fallback.
Evaluated on synthetic and real-world datasets, our framework significantly
outperforms state-of-the-art approaches. It reduces extrinsic estimation error
and enables robust calibration across diverse sensors and target types,
including natural circular objects. Our code will be publicly released for
reproducibility.

</details>


### [91] [Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT](https://arxiv.org/abs/2511.06625)
*Yifei Zhang,Jiashuo Zhang,Xiaofeng Yang,Liang Zhao*

Main category: cs.CV

TL;DR: 提出了一种可解释的跨疾病推理框架，通过单次低剂量胸部CT扫描进行心肺风险评估，模拟临床诊断思维，整合肺部感知、知识引导推理和心脏表征三个模块，在NLST队列中实现了心血管疾病筛查和死亡率预测的最优性能。


<details>
  <summary>Details</summary>
Motivation: 低剂量胸部CT同时捕获肺部和心脏结构，为联合评估肺部和心血管健康提供了独特机会。现有方法大多将这些领域视为独立任务，忽视了它们的生理相互作用和共享成像生物标志物。

Method: 框架包含三个协同组件：肺部感知模块总结肺部异常，知识引导推理模块推断其心血管影响，心脏表征模块编码结构生物标志物。这些输出融合产生整体心血管风险预测。

Result: 在NLST队列上的实验表明，该框架在心血管疾病筛查和死亡率预测方面实现了最先进的性能，优于单疾病和纯图像基线方法。

Conclusion: 这项工作为从低剂量胸部CT进行心血管分析建立了一个统一且可解释的范式，弥合了基于图像的预测和基于机制的医学解释之间的差距。

Abstract: Low-dose chest computed tomography (LDCT) inherently captures both pulmonary
and cardiac structures, offering a unique opportunity for joint assessment of
lung and cardiovascular health. However, most existing approaches treat these
domains as independent tasks, overlooking their physiological interplay and
shared imaging biomarkers. We propose an Explainable Cross-Disease Reasoning
Framework that enables interpretable cardiopulmonary risk assessment from a
single LDCT scan. The framework introduces an agentic reasoning process that
emulates clinical diagnostic thinking-first perceiving pulmonary findings, then
reasoning through established medical knowledge, and finally deriving a
cardiovascular judgment with explanatory rationale. It integrates three
synergistic components: a pulmonary perception module that summarizes lung
abnormalities, a knowledge-guided reasoning module that infers their
cardiovascular implications, and a cardiac representation module that encodes
structural biomarkers. Their outputs are fused to produce a holistic
cardiovascular risk prediction that is both accurate and physiologically
grounded. Experiments on the NLST cohort demonstrate that the proposed
framework achieves state-of-the-art performance for CVD screening and mortality
prediction, outperforming single-disease and purely image-based baselines.
Beyond quantitative gains, the framework provides human-verifiable reasoning
that aligns with cardiological understanding, revealing coherent links between
pulmonary abnormalities and cardiac stress mechanisms. Overall, this work
establishes a unified and explainable paradigm for cardiovascular analysis from
LDCT, bridging the gap between image-based prediction and mechanism-based
medical interpretation.

</details>


### [92] [DIAL-GS: Dynamic Instance Aware Reconstruction for Label-free Street Scenes with 4D Gaussian Splatting](https://arxiv.org/abs/2511.06632)
*Chenpeng Su,Wenhua Wu,Chensheng Peng,Tianchen Deng,Zhe Liu,Hesheng Wang*

Main category: cs.CV

TL;DR: DIAL-GS是一种基于4D高斯泼溅的动态实例感知重建方法，用于无标签街景重建，通过外观-位置不一致性准确识别动态实例，实现动态自适应和实例感知的重建。


<details>
  <summary>Details</summary>
Motivation: 现有监督方法依赖昂贵的人工标注且缺乏可扩展性，而自监督方法往往混淆静态和动态元素，无法区分单个动态对象，限制了细粒度编辑能力。

Method: 利用扭曲渲染与实际观测之间的外观-位置不一致性准确识别动态实例，采用实例感知的4D高斯作为统一体积表示，并通过身份和动态相互增强的互惠机制提升完整性和一致性。

Result: 在城市驾驶场景实验中，DIAL-GS在重建质量和实例级编辑方面优于现有自监督基线方法。

Conclusion: DIAL-GS为城市场景建模提供了一个简洁而强大的解决方案，实现了高质量的动态实例感知重建。

Abstract: Urban scene reconstruction is critical for autonomous driving, enabling
structured 3D representations for data synthesis and closed-loop testing.
Supervised approaches rely on costly human annotations and lack scalability,
while current self-supervised methods often confuse static and dynamic elements
and fail to distinguish individual dynamic objects, limiting fine-grained
editing. We propose DIAL-GS, a novel dynamic instance-aware reconstruction
method for label-free street scenes with 4D Gaussian Splatting. We first
accurately identify dynamic instances by exploiting appearance-position
inconsistency between warped rendering and actual observation. Guided by
instance-level dynamic perception, we employ instance-aware 4D Gaussians as the
unified volumetric representation, realizing dynamic-adaptive and
instance-aware reconstruction. Furthermore, we introduce a reciprocal mechanism
through which identity and dynamics reinforce each other, enhancing both
integrity and consistency. Experiments on urban driving scenarios show that
DIAL-GS surpasses existing self-supervised baselines in reconstruction quality
and instance-level editing, offering a concise yet powerful solution for urban
scene modeling.

</details>


### [93] [FreqGRL: Suppressing Low-Frequency Bias and Mining High-Frequency Knowledge for Cross-Domain Few-Shot Learning](https://arxiv.org/abs/2511.06648)
*Siqi Hui,Sanping Zhou,Ye deng,Wenli Huang,Jinjun Wang*

Main category: cs.CV

TL;DR: 本文提出FreqGRL框架，通过频率空间视角解决跨域小样本学习中的数据不平衡问题，使用低频替换和高频增强模块来提升跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 跨域小样本学习中，源域数据丰富而目标域数据稀缺的严重不平衡问题阻碍了有效的表示学习，特别是在频率空间中模型容易偏向源域特定的低频知识。

Method: 提出FreqGRL框架：1）低频替换模块用目标域低频成分替换源任务低频成分；2）高频增强模块在频率空间中直接学习高频特征；3）全局频率滤波器抑制噪声频率。

Result: 在五个标准CD-FSL基准测试上的广泛实验表明，该频率引导框架实现了最先进的性能。

Conclusion: 频率空间视角为跨域小样本学习中的数据不平衡问题提供了有效解决方案，通过频率操作显著提升了跨域泛化能力。

Abstract: Cross-domain few-shot learning (CD-FSL) aims to recognize novel classes with
only a few labeled examples under significant domain shifts. While recent
approaches leverage a limited amount of labeled target-domain data to improve
performance, the severe imbalance between abundant source data and scarce
target data remains a critical challenge for effective representation learning.
We present the first frequency-space perspective to analyze this issue and
identify two key challenges: (1) models are easily biased toward
source-specific knowledge encoded in the low-frequency components of source
data, and (2) the sparsity of target data hinders the learning of
high-frequency, domain-generalizable features. To address these challenges, we
propose \textbf{FreqGRL}, a novel CD-FSL framework that mitigates the impact of
data imbalance in the frequency space. Specifically, we introduce a
Low-Frequency Replacement (LFR) module that substitutes the low-frequency
components of source tasks with those from the target domain to create new
source tasks that better align with target characteristics, thus reducing
source-specific biases and promoting generalizable representation learning. We
further design a High-Frequency Enhancement (HFE) module that filters out
low-frequency components and performs learning directly on high-frequency
features in the frequency space to improve cross-domain generalization.
Additionally, a Global Frequency Filter (GFF) is incorporated to suppress noisy
or irrelevant frequencies and emphasize informative ones, mitigating
overfitting risks under limited target supervision. Extensive experiments on
five standard CD-FSL benchmarks demonstrate that our frequency-guided framework
achieves state-of-the-art performance.

</details>


### [94] [NOVO: Bridging LLaVA and SAM with Visual-only Prompts for Reasoning Segmentation](https://arxiv.org/abs/2511.06651)
*Kyung-Yoon Yoon,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: NOVO是一个通过视觉提示连接视觉语言模型和分割模型的框架，它生成粗掩码和点提示作为Segment Anything Model的输入，无需文本提示，并引入无训练细化模块提升分割质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将文本派生的SEG令牌嵌入输入分割模型，但这种方法可能无法充分利用预训练分割模型的能力。NOVO旨在通过纯视觉提示更好地与SAM等预训练模型对齐。

Method: NOVO从VLM输出生成粗掩码和点提示，这些视觉提示与SAM兼容。还引入了无训练细化模块来减少视觉伪影并提升分割掩码质量，支持实例级分割。

Result: 实验表明NOVO在多个指标和模型规模上达到了最先进的性能，证明了其在推理分割任务中的有效性和可扩展性。

Conclusion: NOVO通过视觉提示有效连接了VLM和分割模型，在保持与预训练能力对齐的同时，显著提升了推理分割的性能和边界质量。

Abstract: In this study, we propose NOVO (NO text, Visual-Only prompts), a novel
framework that bridges vision-language models (VLMs) and segmentation models
through visual-only prompts. Unlike prior approaches that feed text-derived SEG
token embeddings into segmentation models, NOVO instead generates a coarse mask
and point prompts from the VLM output. These visual prompts are compatible with
the Segment Anything Model (SAM), preserving alignment with its pretrained
capabilities. To further enhance boundary quality and enable instance-level
segmentation, we introduce a training-free refinement module that reduces
visual artifacts and improves the quality of segmentation masks. We also
present RISeg, a new benchmark comprising 918 images, 2,533 instance-level
masks, and diverse reasoning queries to evaluate this task. Experiments
demonstrate that NOVO achieves state-of-the-art performance across multiple
metrics and model sizes, demonstrating its effectiveness and scalability in
reasoning segmentation.

</details>


### [95] [HiMo-CLIP: Modeling Semantic Hierarchy and Monotonicity in Vision-Language Alignment](https://arxiv.org/abs/2511.06653)
*Ruijia Wu,Ping Chen,Fei Shen,Shaoan Zhao,Qiang Hui,Huanlin Gao,Ting Lu,Zhaoxiang Liu,Fang Zhao,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: HiMo-CLIP通过分层分解和单调性感知对比损失增强CLIP模型，解决了传统模型在处理复杂、组合式和长文本描述时的局限性，在图像-文本检索任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的对比视觉语言模型（如CLIP）将文本视为扁平序列，无法有效处理复杂、组合式和长文本描述，特别是无法捕捉语言的语义层次结构和语义单调性这两个关键特性。

Method: 提出HiMo-CLIP框架，包含两个核心组件：1）分层分解模块（HiDe），通过批量PCA从长文本中提取潜在语义成分；2）单调性感知对比损失（MoLo），联合对齐全局和成分级表示，鼓励模型学习语义排序和对齐强度。

Result: 在多个图像-文本检索基准测试中，HiMo-CLIP始终优于强基线模型，特别是在处理长文本或组合式描述时表现尤为突出。

Conclusion: HiMo-CLIP通过引入语义层次结构和单调性约束，成功增强了CLIP风格模型的表示能力，为处理复杂语言结构提供了有效解决方案。

Abstract: Contrastive vision-language models like CLIP have achieved impressive results
in image-text retrieval by aligning image and text representations in a shared
embedding space. However, these models often treat text as flat sequences,
limiting their ability to handle complex, compositional, and long-form
descriptions. In particular, they fail to capture two essential properties of
language: semantic hierarchy, which reflects the multi-level compositional
structure of text, and semantic monotonicity, where richer descriptions should
result in stronger alignment with visual content.To address these limitations,
we propose HiMo-CLIP, a representation-level framework that enhances CLIP-style
models without modifying the encoder architecture. HiMo-CLIP introduces two key
components: a hierarchical decomposition (HiDe) module that extracts latent
semantic components from long-form text via in-batch PCA, enabling flexible,
batch-aware alignment across different semantic granularities, and a
monotonicity-aware contrastive loss (MoLo) that jointly aligns global and
component-level representations, encouraging the model to internalize semantic
ordering and alignment strength as a function of textual completeness.These
components work in concert to produce structured, cognitively-aligned
cross-modal representations. Experiments on multiple image-text retrieval
benchmarks show that HiMo-CLIP consistently outperforms strong baselines,
particularly under long or compositional descriptions. The code is available at
https://github.com/UnicomAI/HiMo-CLIP.

</details>


### [96] [Active Learning for Animal Re-Identification with Ambiguity-Aware Sampling](https://arxiv.org/abs/2511.06658)
*Depanshu Sani,Mehar Khurana,Saket Anand*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的主动学习动物重识别框架，通过互补聚类方法挖掘嵌入空间中结构模糊区域的信息样本对，仅需0.033%的标注就能显著超越现有基础模型、无监督学习和主动学习方法。


<details>
  <summary>Details</summary>
Motivation: 动物重识别在生物多样性监测中具有重要意义，但面临物种间细微差异、新物种处理和开放集特性等挑战。现有基础模型的零样本重识别性能存在显著差距，而无监督和主动学习方法在动物重识别中表现不佳。

Method: 提出主动学习重识别框架，利用互补聚类方法识别嵌入空间中的结构模糊区域，挖掘既信息丰富又具有广泛代表性的样本对。通过must-link和cannot-link约束的标注反馈，结合约束聚类细化算法与现有无监督学习方法集成。

Result: 在13个野生动物数据集上，仅使用0.033%的标注就实现了平均10.49%、11.19%和3.99%的mAP提升（分别相对于基础模型、无监督学习和主动学习方法），并在每个数据集上都达到了最先进性能。在开放世界设置中，对未知个体的性能提升分别为11.09%、8.2%和2.06%。

Conclusion: 该主动学习框架通过高效利用少量标注信息，显著提升了动物重识别的性能，为解决动物重识别中的标注成本高和领域专业知识需求问题提供了有效方案。

Abstract: Animal Re-ID has recently gained substantial attention in the AI research
community due to its high impact on biodiversity monitoring and unique research
challenges arising from environmental factors. The subtle distinguishing
patterns, handling new species and the inherent open-set nature make the
problem even harder. To address these complexities, foundation models trained
on labeled, large-scale and multi-species animal Re-ID datasets have recently
been introduced to enable zero-shot Re-ID. However, our benchmarking reveals
significant gaps in their zero-shot Re-ID performance for both known and
unknown species. While this highlights the need for collecting labeled data in
new domains, exhaustive annotation for Re-ID is laborious and requires domain
expertise. Our analyses show that existing unsupervised (USL) and AL Re-ID
methods underperform for animal Re-ID. To address these limitations, we
introduce a novel AL Re-ID framework that leverages complementary clustering
methods to uncover and target structurally ambiguous regions in the embedding
space for mining pairs of samples that are both informative and broadly
representative. Oracle feedback on these pairs, in the form of must-link and
cannot-link constraints, facilitates a simple annotation interface, which
naturally integrates with existing USL methods through our proposed constrained
clustering refinement algorithm. Through extensive experiments, we demonstrate
that, by utilizing only 0.033% of all annotations, our approach consistently
outperforms existing foundational, USL and AL baselines. Specifically, we
report an average improvement of 10.49%, 11.19% and 3.99% (mAP) on 13 wildlife
datasets over foundational, USL and AL methods, respectively, while attaining
state-of-the-art performance on each dataset. Furthermore, we also show an
improvement of 11.09%, 8.2% and 2.06% for unknown individuals in an open-world
setting.

</details>


### [97] [Sim4Seg: Boosting Multimodal Multi-disease Medical Diagnosis Segmentation with Region-Aware Vision-Language Similarity Masks](https://arxiv.org/abs/2511.06665)
*Lingran Song,Yucheng Zhou,Jianbing Shen*

Main category: cs.CV

TL;DR: 本文提出医学诊断分割任务，结合医学图像分割与诊断，开发了M3DS数据集和Sim4Seg框架，通过区域感知视觉语言相似性模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割模型很少联合探索分割和诊断任务，但为患者提供可解释的诊断结果与分割结果同样重要。

Method: 提出医学诊断分割任务，构建M3DS多模态多疾病数据集，开发Sim4Seg框架，包含区域感知视觉语言相似性模块，并研究测试时缩放策略。

Result: 实验结果表明，该方法在分割和诊断任务上均优于基线模型。

Conclusion: 联合医学分割与诊断任务能够提供更全面的临床价值，提出的方法在两方面都取得了显著改进。

Abstract: Despite significant progress in pixel-level medical image analysis, existing
medical image segmentation models rarely explore medical segmentation and
diagnosis tasks jointly. However, it is crucial for patients that models can
provide explainable diagnoses along with medical segmentation results. In this
paper, we introduce a medical vision-language task named Medical Diagnosis
Segmentation (MDS), which aims to understand clinical queries for medical
images and generate the corresponding segmentation masks as well as diagnostic
results. To facilitate this task, we first present the Multimodal Multi-disease
Medical Diagnosis Segmentation (M3DS) dataset, containing diverse multimodal
multi-disease medical images paired with their corresponding segmentation masks
and diagnosis chain-of-thought, created via an automated diagnosis
chain-of-thought generation pipeline. Moreover, we propose Sim4Seg, a novel
framework that improves the performance of diagnosis segmentation by taking
advantage of the Region-Aware Vision-Language Similarity to Mask (RVLS2M)
module. To improve overall performance, we investigate a test-time scaling
strategy for MDS tasks. Experimental results demonstrate that our method
outperforms the baselines in both segmentation and diagnosis.

</details>


### [98] [AnoStyler: Text-Driven Localized Anomaly Generation via Lightweight Style Transfer](https://arxiv.org/abs/2511.06687)
*Yulim So,Seokho Kang*

Main category: cs.CV

TL;DR: AnoStyler是一种轻量级异常生成方法，通过文本引导的风格转换实现零样本异常生成，解决了现有方法在视觉真实性、数据依赖性和模型复杂度方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有异常生成方法存在视觉真实性不足、依赖大量真实图像、使用内存密集型模型架构等问题，限制了实际部署应用。

Method: 提出AnoStyler方法，将零样本异常生成视为文本引导的风格转换。使用通用类别无关程序生成异常掩码和两类文本提示，通过轻量级U-Net模型和基于CLIP的损失函数将正常图像风格化为视觉真实的异常图像。

Result: 在MVTec-AD和VisA数据集上的广泛实验表明，AnoStyler在生成高质量和多样化异常图像方面优于现有方法，且生成的异常有助于提升异常检测性能。

Conclusion: AnoStyler是一种有效的轻量级异常生成方法，能够生成视觉真实的异常图像，并显著提升异常检测性能。

Abstract: Anomaly generation has been widely explored to address the scarcity of
anomaly images in real-world data. However, existing methods typically suffer
from at least one of the following limitations, hindering their practical
deployment: (1) lack of visual realism in generated anomalies; (2) dependence
on large amounts of real images; and (3) use of memory-intensive, heavyweight
model architectures. To overcome these limitations, we propose AnoStyler, a
lightweight yet effective method that frames zero-shot anomaly generation as
text-guided style transfer. Given a single normal image along with its category
label and expected defect type, an anomaly mask indicating the localized
anomaly regions and two-class text prompts representing the normal and anomaly
states are generated using generalizable category-agnostic procedures. A
lightweight U-Net model trained with CLIP-based loss functions is used to
stylize the normal image into a visually realistic anomaly image, where
anomalies are localized by the anomaly mask and semantically aligned with the
text prompts. Extensive experiments on the MVTec-AD and VisA datasets show that
AnoStyler outperforms existing anomaly generation methods in generating
high-quality and diverse anomaly images. Furthermore, using these generated
anomalies helps enhance anomaly detection performance.

</details>


### [99] [SPAN: Spatial-Projection Alignment for Monocular 3D Object Detection](https://arxiv.org/abs/2511.06702)
*Yifan Wang,Yian Zhao,Fanqi Pu,Xiaochen Yang,Yang Tang,Xi Chen,Wenming Yang*

Main category: cs.CV

TL;DR: 提出SPAN方法解决单目3D检测中解耦预测导致的几何一致性缺失问题，通过空间点对齐和3D-2D投影对齐增强几何约束，并采用分层任务学习策略确保训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测器采用解耦预测范式，分别估计几何中心、深度、尺寸和旋转角度，但忽略了不同属性间的几何协同约束，导致缺乏几何一致性先验，性能次优。

Method: 提出SPAN方法，包含两个关键组件：(1)空间点对齐，在预测和真实3D边界框之间施加显式全局空间约束；(2)3D-2D投影对齐，确保投影的3D框与图像平面上的2D检测框紧密对齐。采用分层任务学习策略逐步引入空间投影对齐。

Result: 广泛实验表明，该方法可轻松集成到任何已建立的单目3D检测器中，并带来显著的性能提升。

Conclusion: SPAN方法通过增强几何约束有效解决了单目3D检测中的几何一致性问题，提高了检测性能。

Abstract: Existing monocular 3D detectors typically tame the pronounced nonlinear
regression of 3D bounding box through decoupled prediction paradigm, which
employs multiple branches to estimate geometric center, depth, dimensions, and
rotation angle separately. Although this decoupling strategy simplifies the
learning process, it inherently ignores the geometric collaborative constraints
between different attributes, resulting in the lack of geometric consistency
prior, thereby leading to suboptimal performance. To address this issue, we
propose novel Spatial-Projection Alignment (SPAN) with two pivotal components:
(i). Spatial Point Alignment enforces an explicit global spatial constraint
between the predicted and ground-truth 3D bounding boxes, thereby rectifying
spatial drift caused by decoupled attribute regression. (ii). 3D-2D Projection
Alignment ensures that the projected 3D box is aligned tightly within its
corresponding 2D detection bounding box on the image plane, mitigating
projection misalignment overlooked in previous works. To ensure training
stability, we further introduce a Hierarchical Task Learning strategy that
progressively incorporates spatial-projection alignment as 3D attribute
predictions refine, preventing early stage error propagation across attributes.
Extensive experiments demonstrate that the proposed method can be easily
integrated into any established monocular 3D detector and delivers significant
performance improvements.

</details>


### [100] [K-Stain: Keypoint-Driven Correspondence for H&E-to-IHC Virtual Staining](https://arxiv.org/abs/2511.06709)
*Sicheng Yang,Zhaohu Xing,Haipeng Zhou,Lei Zhu*

Main category: cs.CV

TL;DR: K-Stain是一种基于关键点的虚拟染色框架，将H&E图像转换为IHC图像，通过关键点检测和增强生成器解决组织切片不对齐问题，提升合成图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟染色方法由于组织切片不对齐而难以有效利用空间信息，需要一种能够精确对齐和整合结构细节的方法。

Method: 提出K-Stain框架，包含三个组件：分层空间关键点检测器(HSKD)、关键点感知增强生成器(KEG)和关键点引导判别器(KGD)，利用相邻切片上下文信息。

Result: 实验表明K-Stain在定量指标和视觉质量上优于现有最先进方法。

Conclusion: 基于关键点的空间和语义关系能够有效提升合成IHC图像的保真度，K-Stain框架在虚拟染色任务中表现出色。

Abstract: Virtual staining offers a promising method for converting Hematoxylin and
Eosin (H&E) images into Immunohistochemical (IHC) images, eliminating the need
for costly chemical processes. However, existing methods often struggle to
utilize spatial information effectively due to misalignment in tissue slices.
To overcome this challenge, we leverage keypoints as robust indicators of
spatial correspondence, enabling more precise alignment and integration of
structural details in synthesized IHC images. We introduce K-Stain, a novel
framework that employs keypoint-based spatial and semantic relationships to
enhance synthesized IHC image fidelity. K-Stain comprises three main
components: (1) a Hierarchical Spatial Keypoint Detector (HSKD) for identifying
keypoints in stain images, (2) a Keypoint-aware Enhancement Generator (KEG)
that integrates these keypoints during image generation, and (3) a Keypoint
Guided Discriminator (KGD) that improves the discriminator's sensitivity to
spatial details. Our approach leverages contextual information from adjacent
slices, resulting in more accurate and visually consistent IHC images.
Extensive experiments show that K-Stain outperforms state-of-the-art methods in
quantitative metrics and visual quality.

</details>


### [101] [MirrorMamba: Towards Scalable and Robust Mirror Detection in Videos](https://arxiv.org/abs/2511.06716)
*Rui Song,Jiaying Lin,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: 本文提出了一种名为MirrorMamba的新型视频镜面检测方法，通过结合感知深度、对应关系和光流等多重线索，并利用Mamba空间状态模型的全局感受野和线性复杂度优势，显著提升了镜面检测的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频镜面检测方法性能有限且鲁棒性不足，主要问题包括过度依赖单一不可靠的动态特征，以及基于CNN的有限感受野或Transformer的二次计算复杂度。

Method: 提出MirrorMamba方法，采用多重线索适应不同条件，包括感知深度、对应关系和光流。创新性地引入基于Mamba的多方向对应关系提取器，利用Mamba空间状态模型的全局感受野和线性复杂度特性。同时设计了基于Mamba的分层边界增强解码器来解决模糊深度图导致的边界不清晰问题。

Result: 在基准数据集上的大量实验表明，该方法在视频镜面检测方面优于现有最先进方法。在最具挑战性和代表性的基于图像的镜面检测数据集上，该方法也达到了最先进的性能。

Conclusion: MirrorMamba方法在视频镜面检测领域取得了显著突破，证明了其鲁棒性和泛化能力，这是Mamba架构在镜面检测领域的首次成功应用。

Abstract: Video mirror detection has received significant research attention, yet
existing methods suffer from limited performance and robustness. These
approaches often over-rely on single, unreliable dynamic features, and are
typically built on CNNs with limited receptive fields or Transformers with
quadratic computational complexity. To address these limitations, we propose a
new effective and scalable video mirror detection method, called MirrorMamba.
Our approach leverages multiple cues to adapt to diverse conditions,
incorporating perceived depth, correspondence and optical. We also introduce an
innovative Mamba-based Multidirection Correspondence Extractor, which benefits
from the global receptive field and linear complexity of the emerging Mamba
spatial state model to effectively capture correspondence properties.
Additionally, we design a Mamba-based layer-wise boundary enforcement decoder
to resolve the unclear boundary caused by the blurred depth map. Notably, this
work marks the first successful application of the Mamba-based architecture in
the field of mirror detection. Extensive experiments demonstrate that our
method outperforms existing state-of-the-art approaches for video mirror
detection on the benchmark datasets. Furthermore, on the most challenging and
representative image-based mirror detection dataset, our approach achieves
state-of-the-art performance, proving its robustness and generalizability.

</details>


### [102] [MRT: Learning Compact Representations with Mixed RWKV-Transformer for Extreme Image Compression](https://arxiv.org/abs/2511.06717)
*Han Liu,Hengyu Man,Xingtao Wang,Wenrui Li,Debin Zhao*

Main category: cs.CV

TL;DR: 提出了一种混合RWKV-Transformer（MRT）架构，将图像编码为更紧凑的1-D潜在表示，显著提升了极低比特率下的图像压缩性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将图像压缩到2-D潜在空间时保留了大量空间冗余，限制了压缩性能。需要更紧凑的表示来提升编码效率。

Method: MRT架构结合线性注意力的RWKV和自注意力Transformer，将图像分块处理：RWKV模块捕获窗口间全局依赖，Transformer块建模窗口内局部冗余。还设计了专门的RWKV压缩模型（RCM）处理1-D潜在特征。

Result: 在比特率低于0.02bpp时实现优越重建质量。相比最先进的2-D架构GLC，在Kodak和CLIC2020数据集上分别节省43.75%和30.59%的比特率。

Conclusion: MRT框架通过1-D潜在表示有效减少了空间冗余，在极低比特率图像压缩方面显著优于现有方法。

Abstract: Recent advances in extreme image compression have revealed that mapping pixel
data into highly compact latent representations can significantly improve
coding efficiency. However, most existing methods compress images into 2-D
latent spaces via convolutional neural networks (CNNs) or Swin Transformers,
which tend to retain substantial spatial redundancy, thereby limiting overall
compression performance. In this paper, we propose a novel Mixed
RWKV-Transformer (MRT) architecture that encodes images into more compact 1-D
latent representations by synergistically integrating the complementary
strengths of linear-attention-based RWKV and self-attention-based Transformer
models. Specifically, MRT partitions each image into fixed-size windows,
utilizing RWKV modules to capture global dependencies across windows and
Transformer blocks to model local redundancies within each window. The
hierarchical attention mechanism enables more efficient and compact
representation learning in the 1-D domain. To further enhance compression
efficiency, we introduce a dedicated RWKV Compression Model (RCM) tailored to
the structure characteristics of the intermediate 1-D latent features in MRT.
Extensive experiments on standard image compression benchmarks validate the
effectiveness of our approach. The proposed MRT framework consistently achieves
superior reconstruction quality at bitrates below 0.02 bits per pixel (bpp).
Quantitative results based on the DISTS metric show that MRT significantly
outperforms the state-of-the-art 2-D architecture GLC, achieving bitrate
savings of 43.75%, 30.59% on the Kodak and CLIC2020 test datasets,
respectively.

</details>


### [103] [Relative Energy Learning for LiDAR Out-of-Distribution Detection](https://arxiv.org/abs/2511.06720)
*Zizhao Li,Zhengkang Xiang,Jiayang Ao,Joseph West,Kourosh Khoshelham*

Main category: cs.CV

TL;DR: 提出REL框架用于LiDAR点云中的OOD检测，通过相对能量学习和简单的数据合成策略Point Raise，在SemanticKITTI和STU基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中可靠的OOD检测至关重要，但现有LiDAR OOD方法难以区分罕见异常和常见类别，导致高误报率和安全关键场景中的过度自信错误。

Method: REL框架利用正负logits之间的能量差作为相对评分函数，结合Point Raise数据合成策略扰动现有点云生成辅助异常样本。

Result: 在SemanticKITTI和STU基准测试中，REL始终以较大优势超越现有方法。

Conclusion: 相对能量建模结合简单合成异常为开放世界自动驾驶中的可靠OOD检测提供了原则性和可扩展的解决方案。

Abstract: Out-of-distribution (OOD) detection is a critical requirement for reliable
autonomous driving, where safety depends on recognizing road obstacles and
unexpected objects beyond the training distribution. Despite extensive research
on OOD detection in 2D images, direct transfer to 3D LiDAR point clouds has
been proven ineffective. Current LiDAR OOD methods struggle to distinguish rare
anomalies from common classes, leading to high false-positive rates and
overconfident errors in safety-critical settings. We propose Relative Energy
Learning (REL), a simple yet effective framework for OOD detection in LiDAR
point clouds. REL leverages the energy gap between positive (in-distribution)
and negative logits as a relative scoring function, mitigating calibration
issues in raw energy values and improving robustness across various scenes. To
address the absence of OOD samples during training, we propose a lightweight
data synthesis strategy called Point Raise, which perturbs existing point
clouds to generate auxiliary anomalies without altering the inlier semantics.
Evaluated on SemanticKITTI and the Spotting the Unexpected (STU) benchmark, REL
consistently outperforms existing methods by a large margin. Our results
highlight that modeling relative energy, combined with simple synthetic
outliers, provides a principled and scalable solution for reliable OOD
detection in open-world autonomous driving.

</details>


### [104] [AvatarTex: High-Fidelity Facial Texture Reconstruction from Single-Image Stylized Avatars](https://arxiv.org/abs/2511.06721)
*Yuda Qiu,Zitong Xiao,Yiwei Zuo,Zisheng Ye,Weikai Chen,Xiaoguang Han*

Main category: cs.CV

TL;DR: AvatarTex是一个从单张图像重建高保真面部纹理的框架，能够生成风格化和逼真的纹理。它采用三阶段扩散到GAN的流程，结合扩散模型的多样性生成能力和GAN的结构化潜在空间，解决了现有方法在风格化头像上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在风格化头像上表现不佳，主要原因是缺乏多样化的多风格数据集，以及在非标准纹理中保持几何一致性的挑战。

Method: 提出三阶段扩散到GAN流程：1）基于扩散的修复完成缺失纹理区域；2）基于GAN的潜在优化细化风格和结构一致性；3）基于扩散的重新绘制增强细节。同时引入TexHub数据集，包含20,000个多风格UV纹理。

Result: AvatarTex在多风格面部纹理重建方面达到了新的最先进水平，能够生成具有艺术和几何一致性的高质量拓扑对齐纹理。

Conclusion: 通过整合扩散模型和GAN的优势，并结合TexHub数据集，AvatarTex成功解决了风格化纹理重建中的关键挑战，为未来研究提供了重要基础。

Abstract: We present AvatarTex, a high-fidelity facial texture reconstruction framework
capable of generating both stylized and photorealistic textures from a single
image. Existing methods struggle with stylized avatars due to the lack of
diverse multi-style datasets and challenges in maintaining geometric
consistency in non-standard textures. To address these limitations, AvatarTex
introduces a novel three-stage diffusion-to-GAN pipeline. Our key insight is
that while diffusion models excel at generating diversified textures, they lack
explicit UV constraints, whereas GANs provide a well-structured latent space
that ensures style and topology consistency. By integrating these strengths,
AvatarTex achieves high-quality topology-aligned texture synthesis with both
artistic and geometric coherence. Specifically, our three-stage pipeline first
completes missing texture regions via diffusion-based inpainting, refines style
and structure consistency using GAN-based latent optimization, and enhances
fine details through diffusion-based repainting. To address the need for a
stylized texture dataset, we introduce TexHub, a high-resolution collection of
20,000 multi-style UV textures with precise UV-aligned layouts. By leveraging
TexHub and our structured diffusion-to-GAN pipeline, AvatarTex establishes a
new state-of-the-art in multi-style facial texture reconstruction. TexHub will
be released upon publication to facilitate future research in this field.

</details>


### [105] [Argus: Quality-Aware High-Throughput Text-to-Image Inference Serving System](https://arxiv.org/abs/2511.06724)
*Shubham Agarwal,Subrata Mitra,Saud Iqbal*

Main category: cs.CV

TL;DR: Argus是一个高吞吐量的文本到图像推理系统，通过智能选择不同近似策略来平衡质量和吞吐量需求，在固定规模集群上实现10倍更少的延迟SLO违规、10%更高的平均质量和40%更高的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型具有高度计算密集和迭代去噪的特点，导致推理时间很长，设计高吞吐量系统面临挑战。研究发现大部分提示可以使用更快的近似模型服务，但需要为每个提示仔细校准近似设置以避免质量下降。

Method: Argus系统为每个提示选择适当的近似级别，在固定规模集群上智能切换不同近似策略，同时满足吞吐量和质量要求。

Result: 在两个真实工作负载跟踪上，Argus相比基线实现了10倍更少的延迟SLO违规、10%更高的平均质量和40%更高的吞吐量。

Conclusion: Argus通过智能模型选择和近似策略切换，成功解决了文本到图像推理系统中的吞吐量与质量权衡问题，显著提升了系统性能。

Abstract: Text-to-image (T2I) models have gained significant popularity. Most of these
are diffusion models with unique computational characteristics, distinct from
both traditional small-scale ML models and large language models. They are
highly compute-bound and use an iterative denoising process to generate images,
leading to very high inference time. This creates significant challenges in
designing a high-throughput system. We discovered that a large fraction of
prompts can be served using faster, approximated models. However, the
approximation setting must be carefully calibrated for each prompt to avoid
quality degradation. Designing a high-throughput system that assigns each
prompt to the appropriate model and compatible approximation setting remains a
challenging problem. We present Argus, a high-throughput T2I inference system
that selects the right level of approximation for each prompt to maintain
quality while meeting throughput targets on a fixed-size cluster. Argus
intelligently switches between different approximation strategies to satisfy
both throughput and quality requirements. Overall, Argus achieves 10x fewer
latency service-level objective (SLO) violations, 10% higher average quality,
and 40% higher throughput compared to baselines on two real-world workload
traces.

</details>


### [106] [Rethinking Rainy 3D Scene Reconstruction via Perspective Transforming and Brightness Tuning](https://arxiv.org/abs/2511.06734)
*Qianfeng Yang,Xiang Chen,Pengpeng Li,Qiyuan Guan,Guiyue Jin,Jiyu Jin*

Main category: cs.CV

TL;DR: 本文提出了OmniRain3D数据集和REVR-GSNet框架，用于解决雨天多视角图像对3D场景重建的影响问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据集忽略了真实雨天3D场景的两个关键特征：雨条纹在2D图像投影中的视角依赖性变化，以及降雨期间云层覆盖导致的环境亮度降低。

Method: 构建了包含视角异质性和亮度动态性的OmniRain3D数据集，并提出REVR-GSNet框架，通过递归亮度增强、高斯基元优化和GS引导的雨消除的联合交替优化来实现端到端重建。

Result: 广泛的实验证明了数据集和方法的有效性。

Conclusion: 本文的数据集和方法为未来多视角图像去雨和雨天3D场景重建研究提供了基础。

Abstract: Rain degrades the visual quality of multi-view images, which are essential
for 3D scene reconstruction, resulting in inaccurate and incomplete
reconstruction results. Existing datasets often overlook two critical
characteristics of real rainy 3D scenes: the viewpoint-dependent variation in
the appearance of rain streaks caused by their projection onto 2D images, and
the reduction in ambient brightness resulting from cloud coverage during
rainfall. To improve data realism, we construct a new dataset named OmniRain3D
that incorporates perspective heterogeneity and brightness dynamicity, enabling
more faithful simulation of rain degradation in 3D scenes. Based on this
dataset, we propose an end-to-end reconstruction framework named REVR-GSNet
(Rain Elimination and Visibility Recovery for 3D Gaussian Splatting).
Specifically, REVR-GSNet integrates recursive brightness enhancement, Gaussian
primitive optimization, and GS-guided rain elimination into a unified
architecture through joint alternating optimization, achieving high-fidelity
reconstruction of clean 3D scenes from rain-degraded inputs. Extensive
experiments show the effectiveness of our dataset and method. Our dataset and
method provide a foundation for future research on multi-view image deraining
and rainy 3D scene reconstruction.

</details>


### [107] [SinSEMI: A One-Shot Image Generation Model and Data-Efficient Evaluation Framework for Semiconductor Inspection Equipment](https://arxiv.org/abs/2511.06740)
*ChunLiang Wu,Xiaochun Li*

Main category: cs.CV

TL;DR: SinSEMI是一种新颖的单次学习方法，能够从单张光学图像生成多样且高度逼真的图像，解决了半导体设备开发早期数据稀缺的问题。该方法采用多尺度流模型和LPIPS能量引导采样，确保感知真实性和输出多样性。


<details>
  <summary>Details</summary>
Motivation: 在半导体设备开发的早期阶段，获取大量原始光学图像具有挑战性，这种数据稀缺阻碍了AI解决方案在半导体制造中的发展。

Method: SinSEMI采用多尺度流模型，并在采样过程中使用LPIPS（学习感知图像块相似度）能量引导，以确保感知真实性和输出多样性。

Result: 通过与多种单次生成技术的比较评估，SinSEMI在视觉质量、定量指标和下游任务方面表现出优越性能。生成的图像具有高保真度和有意义的多样性。

Conclusion: SinSEMI生成的图像适合作为半导体AI应用的训练数据，为解决半导体制造中的数据稀缺问题提供了有效解决方案。

Abstract: In the early stages of semiconductor equipment development, obtaining large
quantities of raw optical images poses a significant challenge. This data
scarcity hinder the advancement of AI-powered solutions in semiconductor
manufacturing. To address this challenge, we introduce SinSEMI, a novel
one-shot learning approach that generates diverse and highly realistic images
from single optical image. SinSEMI employs a multi-scale flow-based model
enhanced with LPIPS (Learned Perceptual Image Patch Similarity) energy guidance
during sampling, ensuring both perceptual realism and output variety. We also
introduce a comprehensive evaluation framework tailored for this application,
which enables a thorough assessment using just two reference images. Through
the evaluation against multiple one-shot generation techniques, we demonstrate
SinSEMI's superior performance in visual quality, quantitative measures, and
downstream tasks. Our experimental results demonstrate that SinSEMI-generated
images achieve both high fidelity and meaningful diversity, making them
suitable as training data for semiconductor AI applications.

</details>


### [108] [PointCubeNet: 3D Part-level Reasoning with 3x3x3 Point Cloud Blocks](https://arxiv.org/abs/2511.06744)
*Da-Yeong Kim,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: PointCubeNet是一个无需部件标注的多模态3D理解框架，通过全局和局部分支实现无监督的部件级推理，在3x3x3局部块中分析点云子区域。


<details>
  <summary>Details</summary>
Motivation: 实现无需部件标注的3D对象部件级理解，通过理解3D对象部件来增强对整体3D对象的理解。

Method: 提出包含全局和局部分支的多模态框架，局部分支采用3x3x3局部块结构，使用伪标签方法和局部损失函数进行无监督训练。

Result: 实验结果表明理解3D对象部件确实增强了整体3D对象的理解，这是首次实现无监督3D部件级推理并获得可靠有意义的结果。

Conclusion: PointCubeNet成功实现了无需部件标注的无监督3D部件级推理，证明了部件级分析对3D对象理解的重要性。

Abstract: In this paper, we propose PointCubeNet, a novel multi-modal 3D understanding
framework that achieves part-level reasoning without requiring any part
annotations. PointCubeNet comprises global and local branches. The proposed
local branch, structured into 3x3x3 local blocks, enables part-level analysis
of point cloud sub-regions with the corresponding local text labels. Leveraging
the proposed pseudo-labeling method and local loss function, PointCubeNet is
effectively trained in an unsupervised manner. The experimental results
demonstrate that understanding 3D object parts enhances the understanding of
the overall 3D object. In addition, this is the first attempt to perform
unsupervised 3D part-level reasoning and achieves reliable and meaningful
results.

</details>


### [109] [Image Restoration via Primal Dual Hybrid Gradient and Flow Generative Model](https://arxiv.org/abs/2511.06748)
*Ji Li,Chao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于原始-对偶混合梯度(PDHG)的通用高效PnP算法，将流匹配生成模型作为先验集成到图像复原中，支持ℓ₁和ℓ₂范数损失，能够处理非高斯噪声。


<details>
  <summary>Details</summary>
Motivation: 现有PnP方法主要适用于高斯噪声的平滑平方ℓ₂数据保真度，对于更一般的数据保真项适用性不足。需要开发能够处理非高斯噪声(如泊松噪声和脉冲噪声)的通用PnP框架。

Method: 将流匹配生成模型作为先验集成到PnP框架中，基于PDHG方法设计算法，用生成模型推导的时间相关去噪器替换正则化器的邻近算子。

Result: 在去噪、超分辨率、去模糊和修复等图像复原任务中验证了方法有效性，ℓ₁和ℓ₂保真项在非高斯噪声存在时优于传统的平方ℓ₂损失。

Conclusion: 提出的PDHG启发的PnP算法计算高效、内存友好，支持广泛的保真项，在处理非高斯噪声的图像复原任务中表现出色。

Abstract: Regularized optimization has been a classical approach to solving imaging
inverse problems, where the regularization term enforces desirable properties
of the unknown image. Recently, the integration of flow matching generative
models into image restoration has garnered significant attention, owing to
their powerful prior modeling capabilities. In this work, we incorporate such
generative priors into a Plug-and-Play (PnP) framework based on proximal
splitting, where the proximal operator associated with the regularizer is
replaced by a time-dependent denoiser derived from the generative model. While
existing PnP methods have achieved notable success in inverse problems with
smooth squared $\ell_2$ data fidelity--typically associated with Gaussian
noise--their applicability to more general data fidelity terms remains
underexplored. To address this, we propose a general and efficient PnP
algorithm inspired by the primal-dual hybrid gradient (PDHG) method. Our
approach is computationally efficient, memory-friendly, and accommodates a wide
range of fidelity terms. In particular, it supports both $\ell_1$ and $\ell_2$
norm-based losses, enabling robustness to non-Gaussian noise types such as
Poisson and impulse noise. We validate our method on several image restoration
tasks, including denoising, super-resolution, deblurring, and inpainting, and
demonstrate that $\ell_1$ and $\ell_2$ fidelity terms outperform the
conventional squared $\ell_2$ loss in the presence of non-Gaussian noise.

</details>


### [110] [Med-SORA: Symptom to Organ Reasoning in Abdomen CT Images](https://arxiv.org/abs/2511.06752)
*You-Kyoung Na,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: Med-SORA是一个用于腹部CT图像中症状到器官推理的框架，通过RAG数据集构建、可学习器官锚点的软标签和2D-3D交叉注意力架构，解决了现有医学多模态模型在症状-图像关联分析中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态模型依赖简单的一对一硬标签，过度简化了临床现实中症状与多个器官相关的复杂性，且主要使用单切片2D特征而缺乏3D信息，限制了完整解剖上下文的捕捉能力。

Method: 提出Med-SORA框架，包括：基于RAG的数据集构建、使用可学习器官锚点的软标签来捕捉一对多症状-器官关系、以及融合局部和全局图像特征的2D-3D交叉注意力架构。

Result: 实验结果显示，Med-SORA在性能上优于现有医学多模态模型，并能够实现准确的3D临床推理。

Conclusion: 这是医学多模态学习中首个解决症状到器官推理问题的工作，Med-SORA框架在症状-图像关联分析方面表现出色，为临床推理提供了更准确的支持。

Abstract: Understanding symptom-image associations is crucial for clinical reasoning.
However, existing medical multimodal models often rely on simple one-to-one
hard labeling, oversimplifying clinical reality where symptoms relate to
multiple organs. In addition, they mainly use single-slice 2D features without
incorporating 3D information, limiting their ability to capture full anatomical
context. In this study, we propose Med-SORA, a framework for symptom-to-organ
reasoning in abdominal CT images. Med-SORA introduces RAG-based dataset
construction, soft labeling with learnable organ anchors to capture one-to-many
symptom-organ relationships, and a 2D-3D cross-attention architecture to fuse
local and global image features. To our knowledge, this is the first work to
address symptom-to-organ reasoning in medical multimodal learning. Experimental
results show that Med-SORA outperforms existing medical multimodal models and
enables accurate 3D clinical reasoning.

</details>


### [111] [Robust and High-Fidelity 3D Gaussian Splatting: Fusing Pose Priors and Geometry Constraints for Texture-Deficient Outdoor Scenes](https://arxiv.org/abs/2511.06765)
*Meijun Guo,Yongliang Shi,Caiyun Liu,Yixiao Feng,Ming Ma,Tinghai Yan,Weining Lu,Bin Liang*

Main category: cs.CV

TL;DR: 本文提出了一种改进的3D高斯溅射方法，通过融合LiDAR-IMU里程计提供先验位姿，并引入法向量约束和有效秩正则化来解决大尺度户外场景中弱纹理或重复纹理导致的位姿估计不稳定和场景表示失真问题。


<details>
  <summary>Details</summary>
Motivation: 针对大尺度户外场景中弱纹理或重复纹理导致的几何纹理不一致问题，传统3D高斯溅射方法存在位姿估计不稳定和场景表示失真的挑战，需要从位姿估计和场景表示两方面进行改进。

Method: 1. 位姿估计：利用LiDAR-IMU里程计提供先验位姿约束，结合COLMAP三角测量和光束法平差进行位姿优化；2. 场景表示：引入法向量约束和有效秩正则化，与光度损失联合优化，增强高斯基元的方向和形状一致性。

Result: 在公开和自采集数据集上的实验表明：1. 位姿优化时间仅需传统方法的三分之一，同时保持精度和鲁棒性；2. 场景表示质量显著优于传统3DGS方法，特别是在弱纹理或重复纹理场景中具有更好的可视化效果和整体性能。

Conclusion: 所提出的方法通过融合先验位姿约束和几何一致性约束，有效解决了大尺度户外场景中3D高斯溅射的位姿估计和场景表示问题，在保持效率的同时显著提升了重建质量。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a key rendering pipeline for
digital asset creation due to its balance between efficiency and visual
quality. To address the issues of unstable pose estimation and scene
representation distortion caused by geometric texture inconsistency in large
outdoor scenes with weak or repetitive textures, we approach the problem from
two aspects: pose estimation and scene representation. For pose estimation, we
leverage LiDAR-IMU Odometry to provide prior poses for cameras in large-scale
environments. These prior pose constraints are incorporated into COLMAP's
triangulation process, with pose optimization performed via bundle adjustment.
Ensuring consistency between pixel data association and prior poses helps
maintain both robustness and accuracy. For scene representation, we introduce
normal vector constraints and effective rank regularization to enforce
consistency in the direction and shape of Gaussian primitives. These
constraints are jointly optimized with the existing photometric loss to enhance
the map quality. We evaluate our approach using both public and self-collected
datasets. In terms of pose optimization, our method requires only one-third of
the time while maintaining accuracy and robustness across both datasets. In
terms of scene representation, the results show that our method significantly
outperforms conventional 3DGS pipelines. Notably, on self-collected datasets
characterized by weak or repetitive textures, our approach demonstrates
enhanced visualization capabilities and achieves superior overall performance.
Codes and data will be publicly available at
https://github.com/justinyeah/normal_shape.git.

</details>


### [112] [TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via Time-Switchable Teacher-Student Learning](https://arxiv.org/abs/2511.06817)
*Rui Wang,Ying Zhou,Hao Wang,Wenwei Zhang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: TiS-TSL提出了一种时间可切换的师生学习框架，用于在最小监督下进行视频立体匹配，通过统一模型支持三种预测模式，采用两阶段学习策略提升时空一致性。


<details>
  <summary>Details</summary>
Motivation: 微创手术中的立体匹配对于导航和增强现实至关重要，但密集视差监督几乎不可能实现，现有方法缺乏时空一致性导致不稳定预测和闪烁伪影。

Method: 提出统一模型支持图像预测、前向视频预测和后向视频预测三种模式，采用图像到视频和视频到视频两阶段学习策略，通过双向时空一致性过滤噪声伪标签。

Result: 在两个公共数据集上的实验表明，TiS-TSL在TEPE和EPE指标上分别比现有图像方法至少提升2.11%和4.54%。

Conclusion: TiS-TSL通过时间可切换的师生学习框架有效解决了微创手术视频立体匹配中的时空一致性问题，显著提升了预测精度和稳定性。

Abstract: Stereo matching in minimally invasive surgery (MIS) is essential for
next-generation navigation and augmented reality. Yet, dense disparity
supervision is nearly impossible due to anatomical constraints, typically
limiting annotations to only a few image-level labels acquired before the
endoscope enters deep body cavities. Teacher-Student Learning (TSL) offers a
promising solution by leveraging a teacher trained on sparse labels to generate
pseudo labels and associated confidence maps from abundant unlabeled surgical
videos. However, existing TSL methods are confined to image-level supervision,
providing only spatial confidence and lacking temporal consistency estimation.
This absence of spatio-temporal reliability results in unstable disparity
predictions and severe flickering artifacts across video frames. To overcome
these challenges, we propose TiS-TSL, a novel time-switchable teacher-student
learning framework for video stereo matching under minimal supervision. At its
core is a unified model that operates in three distinct modes: Image-Prediction
(IP), Forward Video-Prediction (FVP), and Backward Video-Prediction (BVP),
enabling flexible temporal modeling within a single architecture. Enabled by
this unified model, TiS-TSL adopts a two-stage learning strategy. The
Image-to-Video (I2V) stage transfers sparse image-level knowledge to initialize
temporal modeling. The subsequent Video-to-Video (V2V) stage refines temporal
disparity predictions by comparing forward and backward predictions to
calculate bidirectional spatio-temporal consistency. This consistency
identifies unreliable regions across frames, filters noisy video-level pseudo
labels, and enforces temporal coherence. Experimental results on two public
datasets demonstrate that TiS-TSL exceeds other image-based state-of-the-arts
by improving TEPE and EPE by at least 2.11% and 4.54%, respectively..

</details>


### [113] [Integrating Reweighted Least Squares with Plug-and-Play Diffusion Priors for Noisy Image Restoration](https://arxiv.org/abs/2511.06823)
*Ji Li,Chao Wang*

Main category: cs.CV

TL;DR: 提出了一种基于生成扩散先验的即插即用图像恢复框架，用于鲁棒地去除包括脉冲噪声在内的各种噪声类型，通过广义高斯尺度混合损失和迭代重加权最小二乘法实现非高斯噪声的有效去除。


<details>
  <summary>Details</summary>
Motivation: 现有的即插即用图像恢复方法主要使用高斯去噪器，对于非高斯噪声（如脉冲噪声）的处理研究较少，需要开发能够处理各种噪声类型的通用框架。

Method: 在MAP估计框架下，采用广义高斯尺度混合损失替代传统最小二乘损失，使用迭代重加权最小二乘法优化，并通过基于扩散的去噪器执行生成先验的邻近步骤。

Result: 在基准数据集上的实验结果表明，该方法能有效去除非高斯脉冲噪声，并实现优越的恢复性能。

Conclusion: 提出的基于生成扩散先验的框架能够鲁棒地处理各种噪声类型，特别是在非高斯噪声去除方面表现出色，为图像恢复提供了有效的解决方案。

Abstract: Existing plug-and-play image restoration methods typically employ
off-the-shelf Gaussian denoisers as proximal operators within classical
optimization frameworks based on variable splitting. Recently, denoisers
induced by generative priors have been successfully integrated into regularized
optimization methods for image restoration under Gaussian noise. However, their
application to non-Gaussian noise--such as impulse noise--remains largely
unexplored. In this paper, we propose a plug-and-play image restoration
framework based on generative diffusion priors for robust removal of general
noise types, including impulse noise. Within the maximum a posteriori (MAP)
estimation framework, the data fidelity term is adapted to the specific noise
model. Departing from the conventional least-squares loss used for Gaussian
noise, we introduce a generalized Gaussian scale mixture-based loss, which
approximates a wide range of noise distributions and leads to an $\ell_q$-norm
($0<q\leq2$) fidelity term. This optimization problem is addressed using an
iteratively reweighted least squares (IRLS) approach, wherein the proximal step
involving the generative prior is efficiently performed via a diffusion-based
denoiser. Experimental results on benchmark datasets demonstrate that the
proposed method effectively removes non-Gaussian impulse noise and achieves
superior restoration performance.

</details>


### [114] [MUGSQA: Novel Multi-Uncertainty-Based Gaussian Splatting Quality Assessment Method, Dataset, and Benchmarks](https://arxiv.org/abs/2511.06830)
*Tianang Chen,Jian Jin,Shilv Cai,Zhuangzi Li,Weisi Lin*

Main category: cs.CV

TL;DR: 本文提出了一种统一的多距离主观质量评估方法来评估基于高斯泼溅（GS）的3D对象重建方法的感知质量，并构建了名为MUGSQA的数据集和两个基准测试。


<details>
  <summary>Details</summary>
Motivation: 随着高斯泼溅（GS）技术在3D对象重建中的快速发展，评估不同GS方法的感知质量成为一个重要挑战。现有方法缺乏对实际应用中人类观看行为的模拟。

Method: 提出统一的多距离主观质量评估方法，模拟人类观看行为；构建MUGSQA数据集，考虑输入数据的多种不确定性因素（输入视图数量和分辨率、视距、初始点云精度）；建立两个基准测试。

Result: 开发了能够更好收集感知体验的质量评估方法，构建了包含多种不确定性因素的GS质量评估数据集，并建立了评估GS重建方法鲁棒性和现有质量评估指标性能的基准。

Conclusion: 该工作为解决GS技术感知质量评估问题提供了有效工具，数据集和基准代码将公开发布，有助于推动GS技术的进一步发展。

Abstract: Gaussian Splatting (GS) has recently emerged as a promising technique for 3D
object reconstruction, delivering high-quality rendering results with
significantly improved reconstruction speed. As variants continue to appear,
assessing the perceptual quality of 3D objects reconstructed with different
GS-based methods remains an open challenge. To address this issue, we first
propose a unified multi-distance subjective quality assessment method that
closely mimics human viewing behavior for objects reconstructed with GS-based
methods in actual applications, thereby better collecting perceptual
experiences. Based on it, we also construct a novel GS quality assessment
dataset named MUGSQA, which is constructed considering multiple uncertainties
of the input data. These uncertainties include the quantity and resolution of
input views, the view distance, and the accuracy of the initial point cloud.
Moreover, we construct two benchmarks: one to evaluate the robustness of
various GS-based reconstruction methods under multiple uncertainties, and the
other to evaluate the performance of existing quality assessment metrics. Our
dataset and benchmark code will be released soon.

</details>


### [115] [ConsistTalk: Intensity Controllable Temporally Consistent Talking Head Generation with Diffusion Noise Search](https://arxiv.org/abs/2511.06833)
*Zhenjie Liu,Jianzhang Lu,Renjie Lu,Cong Liang,Shangfei Wang*

Main category: cs.CV

TL;DR: ConsistTalk是一个强度可控、时间一致的人脸动画生成框架，通过解耦外观-运动表示和改进推理策略，解决了现有方法存在的闪烁、身份漂移和音视频不同步问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频扩散模型在音频驱动的人脸动画生成中存在闪烁、身份漂移和音视频不同步等问题，主要源于纠缠的外观-运动表示和不稳定的推理策略。

Method: 1) 光流引导的时间模块(OFT)通过面部光流解耦运动特征与静态外观；2) 音频到强度模型(A2I)通过多模态师生知识蒸馏将音频和面部速度特征转换为帧级强度序列；3) 扩散噪声初始化策略(IC-Init)在推理时对背景一致性和运动连续性施加显式约束。

Result: 实验表明ConsistTalk在减少闪烁、保持身份和生成时间稳定的高保真说话头部视频方面显著优于现有方法。

Conclusion: ConsistTalk通过解耦外观-运动表示和改进推理策略，有效解决了音频驱动人脸动画中的关键问题，实现了更自然、稳定的生成效果。

Abstract: Recent advancements in video diffusion models have significantly enhanced
audio-driven portrait animation. However, current methods still suffer from
flickering, identity drift, and poor audio-visual synchronization. These issues
primarily stem from entangled appearance-motion representations and unstable
inference strategies. In this paper, we introduce \textbf{ConsistTalk}, a novel
intensity-controllable and temporally consistent talking head generation
framework with diffusion noise search inference. First, we propose \textbf{an
optical flow-guided temporal module (OFT)} that decouples motion features from
static appearance by leveraging facial optical flow, thereby reducing visual
flicker and improving temporal consistency. Second, we present an
\textbf{Audio-to-Intensity (A2I) model} obtained through multimodal
teacher-student knowledge distillation. By transforming audio and facial
velocity features into a frame-wise intensity sequence, the A2I model enables
joint modeling of audio and visual motion, resulting in more natural dynamics.
This further enables fine-grained, frame-wise control of motion dynamics while
maintaining tight audio-visual synchronization. Third, we introduce a
\textbf{diffusion noise initialization strategy (IC-Init)}. By enforcing
explicit constraints on background coherence and motion continuity during
inference-time noise search, we achieve better identity preservation and refine
motion dynamics compared to the current autoregressive strategy. Extensive
experiments demonstrate that ConsistTalk significantly outperforms prior
methods in reducing flicker, preserving identity, and delivering temporally
stable, high-fidelity talking head videos.

</details>


### [116] [NeuroBridge: Bio-Inspired Self-Supervised EEG-to-Image Decoding via Cognitive Priors and Bidirectional Semantic Alignment](https://arxiv.org/abs/2511.06836)
*Wenjiang Zhang,Sifeng Wang,Yuwei Su,Xinyu Li,Chen Zhang,Suyu Zhong*

Main category: cs.CV

TL;DR: NeuroBridge是一个自监督架构，通过认知先验增强和共享语义投影器实现脑电信号与图像的有效跨模态对齐，在视觉神经解码任务中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视觉神经解码方法受限于高质量刺激-脑响应数据的稀缺性以及神经表示与视觉内容之间的语义不匹配问题。受生物系统的感知变异性和共适应策略启发，需要开发更有效的跨模态对齐方法。

Method: 提出NeuroBridge架构，包含认知先验增强(CPA)和共享语义投影器(SSP)。CPA通过非对称、模态特定的变换增强语义多样性；SSP通过共适应策略建立双向对齐过程，将两种模态特征映射到共享语义空间。

Result: 在受试者内和受试者间设置下均超越现有最先进方法。在200路零样本检索任务中，受试者内场景下top-1准确率提升12.3%达63.2%，top-5准确率提升10.2%达89.9%。

Conclusion: NeuroBridge框架在神经视觉解码中展现出有效性、鲁棒性和可扩展性，为脑机接口和人工智能应用提供了重要技术支撑。

Abstract: Visual neural decoding seeks to reconstruct or infer perceived visual stimuli
from brain activity patterns, providing critical insights into human cognition
and enabling transformative applications in brain-computer interfaces and
artificial intelligence. Current approaches, however, remain constrained by the
scarcity of high-quality stimulus-brain response pairs and the inherent
semantic mismatch between neural representations and visual content. Inspired
by perceptual variability and co-adaptive strategy of the biological systems,
we propose a novel self-supervised architecture, named NeuroBridge, which
integrates Cognitive Prior Augmentation (CPA) with Shared Semantic Projector
(SSP) to promote effective cross-modality alignment. Specifically, CPA
simulates perceptual variability by applying asymmetric, modality-specific
transformations to both EEG signals and images, enhancing semantic diversity.
Unlike previous approaches, SSP establishes a bidirectional alignment process
through a co-adaptive strategy, which mutually aligns features from two
modalities into a shared semantic space for effective cross-modal learning.
NeuroBridge surpasses previous state-of-the-art methods under both
intra-subject and inter-subject settings. In the intra-subject scenario, it
achieves the improvements of 12.3% in top-1 accuracy and 10.2% in top-5
accuracy, reaching 63.2% and 89.9% respectively on a 200-way zero-shot
retrieval task. Extensive experiments demonstrate the effectiveness,
robustness, and scalability of the proposed framework for neural visual
decoding.

</details>


### [117] [PanoNav: Mapless Zero-Shot Object Navigation with Panoramic Scene Parsing and Dynamic Memory](https://arxiv.org/abs/2511.06840)
*Qunchao Jin,Yilin Wu,Changhao Chen*

Main category: cs.CV

TL;DR: PanoNav是一个仅使用RGB的零样本物体导航框架，通过全景场景解析模块和记忆引导决策机制，在无地图导航中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决零样本物体导航中现有方法依赖深度传感器或预建地图的问题，以及无地图方法因缺乏历史上下文而导致的短视决策和局部死锁问题。

Method: 提出PanoNav框架，包含全景场景解析模块来从全景RGB输入中释放MLLMs的空间解析潜力，以及通过动态有界内存队列增强的记忆引导决策机制来整合探索历史。

Result: 在公开导航基准测试中，PanoNav在SR和SPL指标上显著优于代表性基线方法。

Conclusion: PanoNav通过仅使用RGB输入和无地图方法，成功提升了零样本物体导航的性能，证明了其在空间推理和避免局部死锁方面的有效性。

Abstract: Zero-shot object navigation (ZSON) in unseen environments remains a
challenging problem for household robots, requiring strong perceptual
understanding and decision-making capabilities. While recent methods leverage
metric maps and Large Language Models (LLMs), they often depend on depth
sensors or prebuilt maps, limiting the spatial reasoning ability of Multimodal
Large Language Models (MLLMs). Mapless ZSON approaches have emerged to address
this, but they typically make short-sighted decisions, leading to local
deadlocks due to a lack of historical context. We propose PanoNav, a fully
RGB-only, mapless ZSON framework that integrates a Panoramic Scene Parsing
module to unlock the spatial parsing potential of MLLMs from panoramic RGB
inputs, and a Memory-guided Decision-Making mechanism enhanced by a Dynamic
Bounded Memory Queue to incorporate exploration history and avoid local
deadlocks. Experiments on the public navigation benchmark show that PanoNav
significantly outperforms representative baselines in both SR and SPL metrics.

</details>


### [118] [Aerial Image Stitching Using IMU Data from a UAV](https://arxiv.org/abs/2511.06841)
*Selim Ahmet Iz,Mustafa Unel*

Main category: cs.CV

TL;DR: 提出了一种结合IMU数据和计算机视觉技术的无人机图像拼接新方法，通过估计位移和旋转、校正透视畸变、计算单应性矩阵等步骤，提高了图像拼接的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决无人机航拍中多图像拼接的挑战，特别是传统基于特征的图像拼接算法在特征检测和匹配中存在的错误和模糊性问题。

Method: 使用IMU数据结合计算机视觉技术，包括估计无人机在连续图像间的位移和旋转、校正透视畸变、计算单应性矩阵，然后使用标准图像拼接算法进行对齐和融合。

Result: 实验证明该方法在准确性和可靠性方面优于现有的基于特征的图像拼接算法，特别是在大位移、旋转和相机姿态变化等挑战性场景中表现更稳健。

Conclusion: 该方法有效利用了IMU提供的额外信息，校正了多种畸变源，可以轻松集成到现有无人机工作流程中，为无人机图像拼接提供了更可靠的解决方案。

Abstract: Unmanned Aerial Vehicles (UAVs) are widely used for aerial photography and
remote sensing applications. One of the main challenges is to stitch together
multiple images into a single high-resolution image that covers a large area.
Featurebased image stitching algorithms are commonly used but can suffer from
errors and ambiguities in feature detection and matching. To address this,
several approaches have been proposed, including using bundle adjustment
techniques or direct image alignment. In this paper, we present a novel method
that uses a combination of IMU data and computer vision techniques for
stitching images captured by a UAV. Our method involves several steps such as
estimating the displacement and rotation of the UAV between consecutive images,
correcting for perspective distortion, and computing a homography matrix. We
then use a standard image stitching algorithm to align and blend the images
together. Our proposed method leverages the additional information provided by
the IMU data, corrects for various sources of distortion, and can be easily
integrated into existing UAV workflows. Our experiments demonstrate the
effectiveness and robustness of our method, outperforming some of the existing
feature-based image stitching algorithms in terms of accuracy and reliability,
particularly in challenging scenarios such as large displacements, rotations,
and variations in camera pose.

</details>


### [119] [Gaussian-Augmented Physics Simulation and System Identification with Complex Colliders](https://arxiv.org/abs/2511.06846)
*Federico Vasile,Ri-Zhao Qiu,Lorenzo Natale,Xiaolong Wang*

Main category: cs.CV

TL;DR: AS-DiffMPM是一个可微分MPM框架，能够处理任意形状碰撞体的物理属性估计，解决了现有方法在非平面表面碰撞场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于可微分MPM的方法仅限于简化的平面碰撞体交互，无法处理物体与非平面表面碰撞的复杂场景，这限制了系统识别在机器人和图形学中的应用。

Method: 扩展现有方法，引入可微分碰撞处理机制，使目标物体能够与复杂刚体交互，同时保持端到端优化能力，并能与各种新视角合成方法集成。

Result: AS-DiffMPM框架能够成功处理任意形状碰撞体的物理属性估计，在复杂碰撞场景中表现出色。

Conclusion: 该框架为从视觉观测进行系统识别提供了更通用的解决方案，特别适用于涉及复杂几何形状交互的应用场景。

Abstract: System identification involving the geometry, appearance, and physical
properties from video observations is a challenging task with applications in
robotics and graphics. Recent approaches have relied on fully differentiable
Material Point Method (MPM) and rendering for simultaneous optimization of
these properties. However, they are limited to simplified object-environment
interactions with planar colliders and fail in more challenging scenarios where
objects collide with non-planar surfaces. We propose AS-DiffMPM, a
differentiable MPM framework that enables physical property estimation with
arbitrarily shaped colliders. Our approach extends existing methods by
incorporating a differentiable collision handling mechanism, allowing the
target object to interact with complex rigid bodies while maintaining
end-to-end optimization. We show AS-DiffMPM can be easily interfaced with
various novel view synthesis methods as a framework for system identification
from visual observations.

</details>


### [120] [Distillation Dynamics: Towards Understanding Feature-Based Distillation in Vision Transformers](https://arxiv.org/abs/2511.06848)
*Huiyuan Tian,Bonan Xu Shijian Li*

Main category: cs.CV

TL;DR: 该论文分析了特征蒸馏在Vision Transformers(ViTs)上失效的原因，发现ViTs具有独特的U形信息处理模式，教师模型和学生模型之间存在表征范式不匹配问题，导致负迁移。


<details>
  <summary>Details</summary>
Motivation: 特征蒸馏在CNNs中很有效，但在ViTs上却表现不佳甚至比简单的logit蒸馏更差，需要深入分析这一现象的根本原因。

Method: 提出了"蒸馏动力学"分析框架，结合频谱分析、信息熵度量和激活幅度跟踪，通过频域分析揭示教师模型采用分布式高维编码策略，而学生模型因通道容量有限无法复制。

Result: 发现ViTs具有初始压缩后扩展的U形信息处理模式，教师模型后期层的特征对齐会损害学生模型性能，导致负迁移。

Conclusion: ViTs的成功知识转移需要超越简单的特征模仿，设计尊重基本表征约束的方法，为设计有效的ViTs压缩策略提供理论指导。

Abstract: While feature-based knowledge distillation has proven highly effective for
compressing CNNs, these techniques unexpectedly fail when applied to Vision
Transformers (ViTs), often performing worse than simple logit-based
distillation. We provide the first comprehensive analysis of this phenomenon
through a novel analytical framework termed as ``distillation dynamics",
combining frequency spectrum analysis, information entropy metrics, and
activation magnitude tracking. Our investigation reveals that ViTs exhibit a
distinctive U-shaped information processing pattern: initial compression
followed by expansion. We identify the root cause of negative transfer in
feature distillation: a fundamental representational paradigm mismatch between
teacher and student models. Through frequency-domain analysis, we show that
teacher models employ distributed, high-dimensional encoding strategies in
later layers that smaller student models cannot replicate due to limited
channel capacity. This mismatch causes late-layer feature alignment to actively
harm student performance. Our findings reveal that successful knowledge
transfer in ViTs requires moving beyond naive feature mimicry to methods that
respect these fundamental representational constraints, providing essential
theoretical guidance for designing effective ViTs compression strategies. All
source code and experimental logs are provided in the supplementary material.

</details>


### [121] [Ambiguity-aware Truncated Flow Matching for Ambiguous Medical Image Segmentation](https://arxiv.org/abs/2511.06857)
*Fanding Li,Xiangyu Li,Xianghe Su,Xingyu Qiu,Suyu Dong,Wei Wang,Kuanquan Wang,Gongning Luo,Shuo Li*

Main category: cs.CV

TL;DR: 本文提出ATFM方法解决医学图像分割中精度与多样性平衡的挑战，通过数据分层推理、高斯截断表示和分割流匹配三个创新组件，在LIDC和ISIC3数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决模糊医学图像分割中精度与多样性预测之间的权衡问题，现有截断扩散概率模型存在精度和多样性纠缠、保真度和合理性不足的缺陷。

Method: 提出ATFM方法，包含三个核心组件：1) 数据分层推理范式，在数据分布和数据样本层面分别增强精度和多样性；2) 高斯截断表示，在截断点显式建模高斯分布；3) 分割流匹配，扩展语义感知流变换。

Result: 在LIDC和ISIC3数据集上全面评估，ATFM优于最先进方法，GED和HM-IoU分别提升高达12%和7.3%，同时实现更高效的推理。

Conclusion: ATFM通过新颖的推理范式和专用模型组件，成功解决了模糊医学图像分割中精度与多样性的平衡问题，实现了预测性能的显著提升。

Abstract: A simultaneous enhancement of accuracy and diversity of predictions remains a
challenge in ambiguous medical image segmentation (AMIS) due to the inherent
trade-offs. While truncated diffusion probabilistic models (TDPMs) hold strong
potential with a paradigm optimization, existing TDPMs suffer from entangled
accuracy and diversity of predictions with insufficient fidelity and
plausibility. To address the aforementioned challenges, we propose
Ambiguity-aware Truncated Flow Matching (ATFM), which introduces a novel
inference paradigm and dedicated model components. Firstly, we propose
Data-Hierarchical Inference, a redefinition of AMIS-specific inference
paradigm, which enhances accuracy and diversity at data-distribution and
data-sample level, respectively, for an effective disentanglement. Secondly,
Gaussian Truncation Representation (GTR) is introduced to enhance both fidelity
of predictions and reliability of truncation distribution, by explicitly
modeling it as a Gaussian distribution at $T_{\text{trunc}}$ instead of using
sampling-based approximations.Thirdly, Segmentation Flow Matching (SFM) is
proposed to enhance the plausibility of diverse predictions by extending
semantic-aware flow transformation in Flow Matching (FM). Comprehensive
evaluations on LIDC and ISIC3 datasets demonstrate that ATFM outperforms SOTA
methods and simultaneously achieves a more efficient inference. ATFM improves
GED and HM-IoU by up to $12\%$ and $7.3\%$ compared to advanced methods.

</details>


### [122] [VAEVQ: Enhancing Discrete Visual Tokenization through Variational Modeling](https://arxiv.org/abs/2511.06863)
*Sicheng Yang,Xing Hu,Qiang Wu,Dawei Yang*

Main category: cs.CV

TL;DR: VAEVQ提出了一种改进的向量量化方法，通过变分潜在量化、表示一致性策略和分布一致性正则化来解决传统VQ框架中的潜在空间不平滑、量化前后表示不对齐等问题。


<details>
  <summary>Details</summary>
Motivation: 传统向量量化方法存在潜在空间不平滑、量化前后表示不对齐、连续与离散域不连贯等问题，导致码字学习不稳定和码本利用率低，影响重建和生成任务性能。

Method: VAEVQ包含三个关键组件：(1) 变分潜在量化(VLQ)，用VAE替代AE进行量化；(2) 表示一致性策略(RCS)，自适应调节量化前后特征的对齐强度；(3) 分布一致性正则化(DCR)，对齐码本分布与连续潜在分布。

Result: 在两个基准数据集上的广泛实验表明，VAEVQ优于最先进的方法。

Conclusion: VAEVQ通过结构化潜在空间和增强表示一致性，有效解决了传统VQ框架的问题，提升了码本利用率和生成性能。

Abstract: Vector quantization (VQ) transforms continuous image features into discrete
representations, providing compressed, tokenized inputs for generative models.
However, VQ-based frameworks suffer from several issues, such as non-smooth
latent spaces, weak alignment between representations before and after
quantization, and poor coherence between the continuous and discrete domains.
These issues lead to unstable codeword learning and underutilized codebooks,
ultimately degrading the performance of both reconstruction and downstream
generation tasks. To this end, we propose VAEVQ, which comprises three key
components: (1) Variational Latent Quantization (VLQ), replacing the AE with a
VAE for quantization to leverage its structured and smooth latent space,
thereby facilitating more effective codeword activation; (2) Representation
Coherence Strategy (RCS), adaptively modulating the alignment strength between
pre- and post-quantization features to enhance consistency and prevent
overfitting to noise; and (3) Distribution Consistency Regularization (DCR),
aligning the entire codebook distribution with the continuous latent
distribution to improve utilization. Extensive experiments on two benchmark
datasets demonstrate that VAEVQ outperforms state-of-the-art methods.

</details>


### [123] [Generating an Image From 1,000 Words: Enhancing Text-to-Image With Structured Captions](https://arxiv.org/abs/2511.06876)
*Eyal Gutflaish,Eliran Kachlon,Hezi Zisman,Tal Hacham,Nimrod Sarid,Alexander Visheratin,Saar Huberman,Gal Davidi,Guy Bukchin,Kfir Goldberg,Ron Mokady*

Main category: cs.CV

TL;DR: 该论文提出了第一个基于长结构化描述的开源文本到图像模型，通过DimFusion融合机制和TaBR评估协议，解决了传统模型在控制性和表达能力方面的限制。


<details>
  <summary>Details</summary>
Motivation: 传统文本到图像模型在短提示词到丰富视觉输出的映射中存在控制性不足的问题，模型倾向于根据平均用户偏好任意填充缺失细节，限制了专业使用的精确性。

Method: 训练基于长结构化描述的开源文本到图像模型，使用DimFusion融合机制高效处理长描述，并引入TaBR评估协议通过重建循环直接测量控制性和表达能力。

Result: 训练了大规模模型FIBO，在开源模型中实现了最先进的提示对齐效果，模型权重已公开。

Conclusion: 通过长结构化描述训练和创新的融合机制，显著提升了文本到图像模型的控制性和表达能力，为专业应用提供了更精确的视觉生成工具。

Abstract: Text-to-image models have rapidly evolved from casual creative tools to
professional-grade systems, achieving unprecedented levels of image quality and
realism. Yet, most models are trained to map short prompts into detailed
images, creating a gap between sparse textual input and rich visual outputs.
This mismatch reduces controllability, as models often fill in missing details
arbitrarily, biasing toward average user preferences and limiting precision for
professional use. We address this limitation by training the first open-source
text-to-image model on long structured captions, where every training sample is
annotated with the same set of fine-grained attributes. This design maximizes
expressive coverage and enables disentangled control over visual factors. To
process long captions efficiently, we propose DimFusion, a fusion mechanism
that integrates intermediate tokens from a lightweight LLM without increasing
token length. We also introduce the Text-as-a-Bottleneck Reconstruction (TaBR)
evaluation protocol. By assessing how well real images can be reconstructed
through a captioning-generation loop, TaBR directly measures controllability
and expressiveness, even for very long captions where existing evaluation
methods fail. Finally, we demonstrate our contributions by training the
large-scale model FIBO, achieving state-of-the-art prompt alignment among
open-source models. Model weights are publicly available at
https://huggingface.co/briaai/FIBO

</details>


### [124] [A Two-Stage System for Layout-Controlled Image Generation using Large Language Models and Diffusion Models](https://arxiv.org/abs/2511.06888)
*Jan-Hendrik Koch,Jonas Krumme,Konrad Gadzicki*

Main category: cs.CV

TL;DR: 本文提出一个两阶段系统来解决文本到图像扩散模型在物体数量和空间布局控制上的不足，通过LLM生成结构化布局，再使用布局条件扩散模型合成图像。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型虽然生成能力强，但缺乏对物体数量和空间排列的精确控制，这限制了其在复杂场景合成中的应用。

Method: 采用两阶段方法：第一阶段使用大型语言模型从物体列表中生成结构化布局；第二阶段使用布局条件扩散模型（比较ControlNet和GLIGEN两种方法）合成符合布局的逼真图像。

Result: 通过任务分解，物体召回率从57.2%提升到99.9%；ControlNet保持文本风格控制但存在物体幻觉问题，GLIGEN提供更好的布局保真度但降低了基于提示的控制性。

Conclusion: 端到端系统成功生成具有指定物体数量和合理空间布局的图像，证明了分离式方法在组合控制合成中的可行性。

Abstract: Text-to-image diffusion models exhibit remarkable generative capabilities,
but lack precise control over object counts and spatial arrangements. This work
introduces a two-stage system to address these compositional limitations. The
first stage employs a Large Language Model (LLM) to generate a structured
layout from a list of objects. The second stage uses a layout-conditioned
diffusion model to synthesize a photorealistic image adhering to this layout.
We find that task decomposition is critical for LLM-based spatial planning; by
simplifying the initial generation to core objects and completing the layout
with rule-based insertion, we improve object recall from 57.2% to 99.9% for
complex scenes. For image synthesis, we compare two leading conditioning
methods: ControlNet and GLIGEN. After domain-specific finetuning on
table-setting datasets, we identify a key trade-off: ControlNet preserves
text-based stylistic control but suffers from object hallucination, while
GLIGEN provides superior layout fidelity at the cost of reduced prompt-based
controllability. Our end-to-end system successfully generates images with
specified object counts and plausible spatial arrangements, demonstrating the
viability of a decoupled approach for compositionally controlled synthesis.

</details>


### [125] [Adaptive Morph-Patch Transformer for Arotic Vessel Segmentation](https://arxiv.org/abs/2511.06897)
*Zhenxi Zhang,Fuchen Zheng,Adnan Iltaf,Yifei Han,Zhenyu Cheng,Yue Du,Bin Li,Tianyong Liu,Shoujun Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种自适应形态补丁变换器(MPT)，用于主动脉血管分割。该模型通过动态生成与血管结构对齐的形态感知补丁，以及语义聚类注意力机制，显著提升了复杂血管结构的分割精度。


<details>
  <summary>Details</summary>
Motivation: 传统基于Transformer的模型在主动脉血管分割中依赖固定大小的矩形补丁，这会破坏复杂血管结构的完整性，导致分割精度不理想。

Method: 提出了自适应形态补丁变换器(MPT)，包括：1）自适应补丁划分策略，动态生成与血管结构对齐的形态感知补丁；2）语义聚类注意力(SCA)方法，动态聚合具有相似语义特征的补丁。

Result: 在三个开源数据集(AVT、AortaSeg24和TBAD)上的广泛实验表明，MPT实现了最先进的性能，在复杂血管结构分割方面有显著改进。

Conclusion: MPT通过自适应补丁划分和语义聚类注意力机制，有效解决了传统方法在血管结构完整性保持方面的局限性，为主动脉血管分割提供了更优的解决方案。

Abstract: Accurate segmentation of aortic vascular structures is critical for
diagnosing and treating cardiovascular diseases.Traditional Transformer-based
models have shown promise in this domain by capturing long-range dependencies
between vascular features. However, their reliance on fixed-size rectangular
patches often influences the integrity of complex vascular structures, leading
to suboptimal segmentation accuracy. To address this challenge, we propose the
adaptive Morph Patch Transformer (MPT), a novel architecture specifically
designed for aortic vascular segmentation. Specifically, MPT introduces an
adaptive patch partitioning strategy that dynamically generates
morphology-aware patches aligned with complex vascular structures. This
strategy can preserve semantic integrity of complex vascular structures within
individual patches. Moreover, a Semantic Clustering Attention (SCA) method is
proposed to dynamically aggregate features from various patches with similar
semantic characteristics. This method enhances the model's capability to
segment vessels of varying sizes, preserving the integrity of vascular
structures. Extensive experiments on three open-source dataset(AVT, AortaSeg24
and TBAD) demonstrate that MPT achieves state-of-the-art performance, with
improvements in segmenting intricate vascular structures.

</details>


### [126] [Mono3DVG-EnSD: Enhanced Spatial-aware and Dimension-decoupled Text Encoding for Monocular 3D Visual Grounding](https://arxiv.org/abs/2511.06908)
*Yuzhen Li,Min Liu,Zhaoyang Li,Yuan Bian,Xueping Wang,Erbo Zhai,Yaonan Wang*

Main category: cs.CV

TL;DR: 本文提出Mono3DVG-EnSD框架，通过CLIP-LCA动态掩码高确定性关键词保留空间描述，以及D2M模块解耦维度特定文本特征，解决单目3D视觉定位中过度依赖关键词和跨维度干扰问题，在Mono3DRefer数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D视觉定位方法存在两个关键限制：过度依赖高确定性关键词而忽视空间描述，以及广义文本特征包含2D和3D信息导致跨维度干扰。

Method: 提出Mono3DVG-EnSD框架，包含CLIP-LCA模块动态掩码高确定性关键词保留空间描述，以及D2M模块解耦维度特定文本特征以指导相应维度的视觉特征。

Result: 在Mono3DRefer数据集上实现所有指标的SOTA性能，特别在具有挑战性的Far(Acc@0.5)场景中显著提升+13.54%。

Conclusion: 该方法通过增强对空间关系的理解和减少跨维度干扰，有效提升了单目3D视觉定位的性能。

Abstract: Monocular 3D Visual Grounding (Mono3DVG) is an emerging task that locates 3D
objects in RGB images using text descriptions with geometric cues. However,
existing methods face two key limitations. Firstly, they often over-rely on
high-certainty keywords that explicitly identify the target object while
neglecting critical spatial descriptions. Secondly, generalized textual
features contain both 2D and 3D descriptive information, thereby capturing an
additional dimension of details compared to singular 2D or 3D visual features.
This characteristic leads to cross-dimensional interference when refining
visual features under text guidance. To overcome these challenges, we propose
Mono3DVG-EnSD, a novel framework that integrates two key components: the
CLIP-Guided Lexical Certainty Adapter (CLIP-LCA) and the Dimension-Decoupled
Module (D2M). The CLIP-LCA dynamically masks high-certainty keywords while
retaining low-certainty implicit spatial descriptions, thereby forcing the
model to develop a deeper understanding of spatial relationships in captions
for object localization. Meanwhile, the D2M decouples dimension-specific
(2D/3D) textual features from generalized textual features to guide
corresponding visual features at same dimension, which mitigates
cross-dimensional interference by ensuring dimensionally-consistent cross-modal
interactions. Through comprehensive comparisons and ablation studies on the
Mono3DRefer dataset, our method achieves state-of-the-art (SOTA) performance
across all metrics. Notably, it improves the challenging Far(Acc@0.5) scenario
by a significant +13.54%.

</details>


### [127] [DTTNet: Improving Video Shadow Detection via Dark-Aware Guidance and Tokenized Temporal Modeling](https://arxiv.org/abs/2511.06925)
*Zhicheng Li,Kunyang Sun,Rui Yao,Hancheng Zhu,Fuyuan Hu,Jiaqi Zhao,Zhiwen Shao,Yong Zhou*

Main category: cs.CV

TL;DR: 该论文提出DTTNet方法，通过视觉语言匹配模块和暗感知语义块解决阴影与背景的模糊问题，使用令牌化时序块建模动态阴影变形，在多个基准数据集上实现最先进精度和实时推理效率。


<details>
  <summary>Details</summary>
Motivation: 视频阴影检测面临两个交织的困难：在复杂背景中区分阴影，以及在变化光照下建模动态阴影变形。现有方法难以同时解决阴影-背景模糊性和动态阴影形状变化问题。

Method: 1. 视觉语言匹配模块(VMM)和暗感知语义块(DSB)提取文本引导特征来区分阴影和暗色物体；2. 自适应掩码重加权在训练时降低半影区域权重；3. 在最终解码器阶段应用边缘掩码进行更好监督；4. 令牌化时序块(TTB)将跨帧阴影语义总结为可学习时序令牌，实现高效序列编码。

Result: 在多个基准数据集上的综合实验证明了最先进的准确性和实时推理效率。代码已在GitHub上开源。

Conclusion: 所提出的DTTNet方法通过结合语言先验和高效的时序建模，有效解决了视频阴影检测中的阴影-背景模糊性和动态变形问题，实现了高精度和实时性能的平衡。

Abstract: Video shadow detection confronts two entwined difficulties: distinguishing
shadows from complex backgrounds and modeling dynamic shadow deformations under
varying illumination. To address shadow-background ambiguity, we leverage
linguistic priors through the proposed Vision-language Match Module (VMM) and a
Dark-aware Semantic Block (DSB), extracting text-guided features to explicitly
differentiate shadows from dark objects. Furthermore, we introduce adaptive
mask reweighting to downweight penumbra regions during training and apply edge
masks at the final decoder stage for better supervision. For temporal modeling
of variable shadow shapes, we propose a Tokenized Temporal Block (TTB) that
decouples spatiotemporal learning. TTB summarizes cross-frame shadow semantics
into learnable temporal tokens, enabling efficient sequence encoding with
minimal computation overhead. Comprehensive Experiments on multiple benchmark
datasets demonstrate state-of-the-art accuracy and real-time inference
efficiency. Codes are available at https://github.com/city-cheng/DTTNet.

</details>


### [128] [PlantTraitNet: An Uncertainty-Aware Multimodal Framework for Global-Scale Plant Trait Inference from Citizen Science Data](https://arxiv.org/abs/2511.06943)
*Ayushi Sharma,Johanna Trost,Daniel Lusk,Johannes Dollinger,Julian Schrader,Christian Rossi,Javier Lopatin,Etienne Laliberté,Simon Haberstroh,Jana Eichel,Daniel Mederer,Jose Miguel Cerda-Paredes,Shyam S. Phartyal,Lisa-Maricia Schwarz,Anja Linstädter,Maria Conceição Caldeira,Teja Kattenborn*

Main category: cs.CV

TL;DR: PlantTraitNet利用公民科学照片和深度学习框架预测植物性状，生成全球性状分布图，在准确性上优于现有产品。


<details>
  <summary>Details</summary>
Motivation: 现有植物性状地图受限于野外测量的高成本和稀疏地理覆盖，而公民科学照片提供了大量未开发的视觉信息资源。

Method: 提出PlantTraitNet，一个多模态、多任务不确定性感知的深度学习框架，使用弱监督从公民科学照片中预测四个关键植物性状。

Result: PlantTraitNet在所有评估性状上持续优于现有性状地图，验证了公民科学图像与计算机视觉和地理空间AI结合的有效性。

Conclusion: 这种方法为生态研究和地球系统建模提供了一个强大的新途径，实现了可扩展且更准确的全球性状测绘。

Abstract: Global plant maps of plant traits, such as leaf nitrogen or plant height, are
essential for understanding ecosystem processes, including the carbon and
energy cycles of the Earth system. However, existing trait maps remain limited
by the high cost and sparse geographic coverage of field-based measurements.
Citizen science initiatives offer a largely untapped resource to overcome these
limitations, with over 50 million geotagged plant photographs worldwide
capturing valuable visual information on plant morphology and physiology. In
this study, we introduce PlantTraitNet, a multi-modal, multi-task
uncertainty-aware deep learning framework that predictsfour key plant traits
(plant height, leaf area, specific leaf area, and nitrogen content) from
citizen science photos using weak supervision. By aggregating individual trait
predictions across space, we generate global maps of trait distributions. We
validate these maps against independent vegetation survey data (sPlotOpen) and
benchmark them against leading global trait products. Our results show that
PlantTraitNet consistently outperforms existing trait maps across all evaluated
traits, demonstrating that citizen science imagery, when integrated with
computer vision and geospatial AI, enables not only scalable but also more
accurate global trait mapping. This approach offers a powerful new pathway for
ecological research and Earth system modeling.

</details>


### [129] [From Attribution to Action: Jointly ALIGNing Predictions and Explanations](https://arxiv.org/abs/2511.06944)
*Dongsheng Hong,Chao Chen,Yanhui Chen,Shanshan Lin,Zhihao Chen,Xiangwen Liao*

Main category: cs.CV

TL;DR: ALIGN框架通过联合训练分类器和掩码器，使用高质量掩码作为指导，在提升模型可解释性的同时增强泛化能力，在领域泛化基准测试中优于多个基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的解释引导学习方法依赖外部标注或启发式分割来监督模型解释，但这些监督信号通常质量较低、噪声大且难以扩展，可能反而降低模型性能。

Method: 提出ALIGN框架，以迭代方式联合训练分类器和掩码器。掩码器学习生成软性、任务相关的掩码来突出信息区域，分类器同时优化预测准确性和其显著性图与学习掩码的对齐度。

Result: 在VLCS和Terra Incognita两个领域泛化基准测试中，ALIGN在分布内和分布外设置下均一致优于六个强基线方法，同时产生更高质量的解释。

Conclusion: ALIGN通过利用高质量掩码作为指导，有效提升了模型的可解释性和泛化能力，证明了其在生成准确且可解释模型方面的有效性。

Abstract: Explanation-guided learning (EGL) has shown promise in aligning model
predictions with interpretable reasoning, particularly in computer vision
tasks. However, most approaches rely on external annotations or heuristic-based
segmentation to supervise model explanations, which can be noisy, imprecise and
difficult to scale. In this work, we provide both empirical and theoretical
evidence that low-quality supervision signals can degrade model performance
rather than improve it. In response, we propose ALIGN, a novel framework that
jointly trains a classifier and a masker in an iterative manner. The masker
learns to produce soft, task-relevant masks that highlight informative regions,
while the classifier is optimized for both prediction accuracy and alignment
between its saliency maps and the learned masks. By leveraging high-quality
masks as guidance, ALIGN improves both interpretability and generalizability,
showing its superiority across various settings. Experiments on the two domain
generalization benchmarks, VLCS and Terra Incognita, show that ALIGN
consistently outperforms six strong baselines in both in-distribution and
out-of-distribution settings. Besides, ALIGN also yields superior explanation
quality concerning sufficiency and comprehensiveness, highlighting its
effectiveness in producing accurate and interpretable models.

</details>


### [130] [FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection](https://arxiv.org/abs/2511.06947)
*Yulin Chen,Zeyuan Wang,Tianyuan Yu,Yingmei Wei,Liang Bai*

Main category: cs.CV

TL;DR: FoCLIP是一个针对CLIP-based图像质量评估指标的对抗攻击框架，通过特征空间错位来欺骗CLIPscore，同时保持图像视觉质量。


<details>
  <summary>Details</summary>
Motivation: CLIP-based模型虽然具有良好对齐特性，但其多模态对齐机制容易受到攻击，需要研究如何欺骗CLIPscore指标。

Method: 基于随机梯度下降技术，整合特征对齐、分数分布平衡和像素保护正则化三个关键组件，优化多模态输出平衡。

Result: 在十个艺术杰作提示和ImageNet子集上的实验表明，优化图像能显著提高CLIPscore同时保持高视觉保真度；灰度转换可检测欺骗图像，据此提出的检测机制达到91%准确率。

Conclusion: 本研究为CLIP-based多模态系统中的特征错位攻击提供了实用路径，并提出了相应的防御方法。

Abstract: The well-aligned attribute of CLIP-based models enables its effective
application like CLIPscore as a widely adopted image quality assessment metric.
However, such a CLIP-based metric is vulnerable for its delicate multimodal
alignment. In this work, we propose \textbf{FoCLIP}, a feature-space
misalignment framework for fooling CLIP-based image quality metric. Based on
the stochastic gradient descent technique, FoCLIP integrates three key
components to construct fooling examples: feature alignment as the core module
to reduce image-text modality gaps, the score distribution balance module and
pixel-guard regularization, which collectively optimize multimodal output
equilibrium between CLIPscore performance and image quality. Such a design can
be engineered to maximize the CLIPscore predictions across diverse input
prompts, despite exhibiting either visual unrecognizability or semantic
incongruence with the corresponding adversarial prompts from human perceptual
perspectives. Experiments on ten artistic masterpiece prompts and ImageNet
subsets demonstrate that optimized images can achieve significant improvement
in CLIPscore while preserving high visual fidelity. In addition, we found that
grayscale conversion induces significant feature degradation in fooling images,
exhibiting noticeable CLIPscore reduction while preserving statistical
consistency with original images. Inspired by this phenomenon, we propose a
color channel sensitivity-driven tampering detection mechanism that achieves
91% accuracy on standard benchmarks. In conclusion, this work establishes a
practical pathway for feature misalignment in CLIP-based multimodal systems and
the corresponding defense method.

</details>


### [131] [PADM: A Physics-aware Diffusion Model for Attenuation Correction](https://arxiv.org/abs/2511.06948)
*Trung Kien Pham,Hoang Minh Vu,Anh Duc Chu,Dac Thai Nguyen,Trung Thanh Nguyen,Thao Nguyen Truong,Mai Hong Son,Thanh Trung Nguyen,Phi Le Nguyen*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的CT-free心脏SPECT衰减校正方法PADM，通过物理感知的师生蒸馏机制，仅需非衰减校正输入即可实现衰减伪影校正，并在CardiAC数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 心脏SPECT成像中的衰减伪影严重影响诊断准确性，而混合SPECT/CT系统虽然能通过CT衰减图进行校正，但存在成本高、可及性差和额外辐射暴露等问题。

Method: 提出PADM方法，这是一种基于扩散的生成模型，通过师生蒸馏机制融入显式物理先验，仅使用非衰减校正输入进行衰减伪影校正。

Result: 在CardiAC数据集上的广泛实验表明，PADM在定量指标和视觉评估方面均优于现有最先进的生成模型，提供了卓越的重建保真度。

Conclusion: PADM为心脏SPECT提供了一种有效的CT-free衰减校正解决方案，克服了传统混合系统的局限性，具有重要的临床应用价值。

Abstract: Attenuation artifacts remain a significant challenge in cardiac Myocardial
Perfusion Imaging (MPI) using Single-Photon Emission Computed Tomography
(SPECT), often compromising diagnostic accuracy and reducing clinical
interpretability. While hybrid SPECT/CT systems mitigate these artifacts
through CT-derived attenuation maps, their high cost, limited accessibility,
and added radiation exposure hinder widespread clinical adoption. In this
study, we propose a novel CT-free solution to attenuation correction in cardiac
SPECT. Specifically, we introduce Physics-aware Attenuation Correction
Diffusion Model (PADM), a diffusion-based generative method that incorporates
explicit physics priors via a teacher--student distillation mechanism. This
approach enables attenuation artifact correction using only
Non-Attenuation-Corrected (NAC) input, while still benefiting from
physics-informed supervision during training. To support this work, we also
introduce CardiAC, a comprehensive dataset comprising 424 patient studies with
paired NAC and Attenuation-Corrected (AC) reconstructions, alongside
high-resolution CT-based attenuation maps. Extensive experiments demonstrate
that PADM outperforms state-of-the-art generative models, delivering superior
reconstruction fidelity across both quantitative metrics and visual assessment.

</details>


### [132] [GFix: Perceptually Enhanced Gaussian Splatting Video Compression](https://arxiv.org/abs/2511.06953)
*Siyue Teng,Ge Gao,Duolikun Danier,Yuxuan Jiang,Fan Zhang,Thomas Davis,Zoe Liu,David Bull*

Main category: cs.CV

TL;DR: GFix是一个基于3D高斯泼溅的视频压缩增强框架，通过单步扩散模型和调制LoRA方案来提升感知质量和压缩效率。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS视频编解码器存在明显视觉伪影和较低压缩比，作者假设3DGS渲染和量化产生的伪影类似于扩散训练中的噪声潜变量。

Method: 提出内容自适应框架GFix，包含简化的单步扩散模型作为即插即用神经增强器，以及调制LoRA方案来冻结低秩分解并调制中间隐藏状态。

Result: 实验结果显示GFix在感知质量增强方面表现优异，相比GSVC在LPIPS上实现高达72.1%的BD-rate节省，在FID上实现21.4%的节省。

Conclusion: GFix框架有效提升了3DGS视频压缩的感知质量，同时通过调制LoRA方案实现了高效的压缩适应。

Abstract: 3D Gaussian Splatting (3DGS) enhances 3D scene reconstruction through
explicit representation and fast rendering, demonstrating potential benefits
for various low-level vision tasks, including video compression. However,
existing 3DGS-based video codecs generally exhibit more noticeable visual
artifacts and relatively low compression ratios. In this paper, we specifically
target the perceptual enhancement of 3DGS-based video compression, based on the
assumption that artifacts from 3DGS rendering and quantization resemble noisy
latents sampled during diffusion training. Building on this premise, we propose
a content-adaptive framework, GFix, comprising a streamlined, single-step
diffusion model that serves as an off-the-shelf neural enhancer. Moreover, to
increase compression efficiency, We propose a modulated LoRA scheme that
freezes the low-rank decompositions and modulates the intermediate hidden
states, thereby achieving efficient adaptation of the diffusion backbone with
highly compressible updates. Experimental results show that GFix delivers
strong perceptual quality enhancement, outperforming GSVC with up to 72.1%
BD-rate savings in LPIPS and 21.4% in FID.

</details>


### [133] [Learning from the Right Patches: A Two-Stage Wavelet-Driven Masked Autoencoder for Histopathology Representation Learning](https://arxiv.org/abs/2511.06958)
*Raneen Younis,Louay Hamdi,Lukas Chavez,Zahra Ahmadi*

Main category: cs.CV

TL;DR: 提出WISE-MAE框架，通过小波变换引导的补丁选择策略改进MAE在数字病理学中的自监督学习，避免传统随机采样中包含无关区域的问题。


<details>
  <summary>Details</summary>
Motivation: 全切片图像尺寸极大且标注稀缺，需要自监督学习。传统MAE的随机补丁采样常包含无关或噪声区域，限制了模型捕捉有意义的组织模式的能力。

Method: 采用轻量级领域自适应框架，通过两阶段粗到细过程：低倍镜下基于小波的筛选定位结构丰富区域，然后高分辨率提取进行详细建模，模拟病理学家诊断流程。

Result: 在多个癌症数据集（肺、肾、结直肠组织）上的评估显示，WISE-MAE在弱监督下实现了有竞争力的表示质量和下游分类性能，同时保持效率。

Conclusion: WISE-MAE通过引入结构和生物学相关性的补丁选择策略，显著提升了MAE在数字病理学中的表示学习效果，为组织病理学分析提供了更有效的自监督学习方法。

Abstract: Whole-slide images are central to digital pathology, yet their extreme size
and scarce annotations make self-supervised learning essential. Masked
Autoencoders (MAEs) with Vision Transformer backbones have recently shown
strong potential for histopathology representation learning. However,
conventional random patch sampling during MAE pretraining often includes
irrelevant or noisy regions, limiting the model's ability to capture meaningful
tissue patterns. In this paper, we present a lightweight and domain-adapted
framework that brings structure and biological relevance into MAE-based
learning through a wavelet-informed patch selection strategy. WISE-MAE applies
a two-step coarse-to-fine process: wavelet-based screening at low magnification
to locate structurally rich regions, followed by high-resolution extraction for
detailed modeling. This approach mirrors the diagnostic workflow of
pathologists and improves the quality of learned representations. Evaluations
across multiple cancer datasets, including lung, renal, and colorectal tissues,
show that WISE-MAE achieves competitive representation quality and downstream
classification performance while maintaining efficiency under weak supervision.

</details>


### [134] [Exploring the "Great Unseen" in Medieval Manuscripts: Instance-Level Labeling of Legacy Image Collections with Zero-Shot Models](https://arxiv.org/abs/2511.07004)
*Christofer Meinecke,Estelle Guéville,David Joseph Wrisley*

Main category: cs.CV

TL;DR: 使用先进技术对中世纪手稿页面进行全面分割和描述，为计算机视觉技术创建更丰富的训练数据


<details>
  <summary>Details</summary>
Motivation: 更全面地理论化中世纪手稿页面及其内容，为计算机视觉技术特别是实例分割和中世纪特定视觉内容的多模态模型提供更好的训练数据

Method: 使用最先进的技术来分割和描述整个手稿对开页

Result: 创建了更丰富的中世纪手稿训练数据集

Conclusion: 该方法有助于提升计算机视觉技术在中世纪手稿分析中的应用效果

Abstract: We aim to theorize the medieval manuscript page and its contents more
holistically, using state-of-the-art techniques to segment and describe the
entire manuscript folio, for the purpose of creating richer training data for
computer vision techniques, namely instance segmentation, and multimodal models
for medieval-specific visual content.

</details>


### [135] [TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene Understanding](https://arxiv.org/abs/2511.07007)
*Duc Nguyen,Yan-Ling Lai,Qilin Zhang,Prabin Gyawali,Benedikt Schwab,Olaf Wysocki,Thomas H. Kolbe*

Main category: cs.CV

TL;DR: TrueCity是首个城市语义分割基准数据集，提供厘米级精度的真实世界点云标注、语义3D城市模型和模拟点云，用于量化合成到真实领域的差距。


<details>
  <summary>Details</summary>
Motivation: 解决3D语义场景理解中真实标注数据有限的问题，以及现有合成数据集无法捕捉真实世界复杂性和传感器噪声导致的领域差距问题。

Method: 创建TrueCity基准数据集，包含同步的真实和模拟点云数据，采用与国际3D城市建模标准对齐的分割类别，实现一致的合成到真实差距评估。

Result: 广泛的实验量化了领域差距，并展示了利用合成数据增强真实世界3D场景理解的策略。

Conclusion: TrueCity数据集将促进合成到真实差距量化方法的进一步发展，并支持可泛化的数据驱动模型开发。

Abstract: 3D semantic scene understanding remains a long-standing challenge in the 3D
computer vision community. One of the key issues pertains to limited real-world
annotated data to facilitate generalizable models. The common practice to
tackle this issue is to simulate new data. Although synthetic datasets offer
scalability and perfect labels, their designer-crafted scenes fail to capture
real-world complexity and sensor noise, resulting in a synthetic-to-real domain
gap. Moreover, no benchmark provides synchronized real and simulated point
clouds for segmentation-oriented domain shift analysis. We introduce TrueCity,
the first urban semantic segmentation benchmark with cm-accurate annotated
real-world point clouds, semantic 3D city models, and annotated simulated point
clouds representing the same city. TrueCity proposes segmentation classes
aligned with international 3D city modeling standards, enabling consistent
evaluation of synthetic-to-real gap. Our extensive experiments on common
baselines quantify domain shift and highlight strategies for exploiting
synthetic data to enhance real-world 3D scene understanding. We are convinced
that the TrueCity dataset will foster further development of sim-to-real gap
quantification and enable generalizable data-driven models. The data, code, and
3D models are available online: https://tum-gis.github.io/TrueCity/

</details>


### [136] [Performance Decay in Deepfake Detection: The Limitations of Training on Outdated Data](https://arxiv.org/abs/2511.07009)
*Jack Richings,Margaux Leblanc,Ian Groves,Victoria Nockles*

Main category: cs.CV

TL;DR: 本文提出了一种简单有效的两阶段深度伪造检测方法，在当代深度伪造内容上达到99.8%的AUROC，但发现模型性能会随着生成技术的发展而快速衰减，强调需要持续收集多样化数据和开发帧级特征检测器。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术的不断进步加剧了虚假信息、欺诈和骚扰的威胁，恶意生成的合成内容越来越难以与现实区分，因此需要开发有效的检测方法。

Method: 采用简单而有效的两阶段检测方法，通过分析发现预测能力主要来自静态的帧级伪影而非时间不一致性。

Result: 在当代深度伪造内容上实现了超过99.8%的AUROC，但模型在仅六个月后的生成技术上的召回率下降了30%以上，表明性能会随着威胁演变而显著衰减。

Conclusion: 有效的深度伪造检测未来依赖于快速数据收集和先进的帧级特征检测器的开发，需要持续策划大型多样化数据集来保持性能。

Abstract: The continually advancing quality of deepfake technology exacerbates the
threats of disinformation, fraud, and harassment by making
maliciously-generated synthetic content increasingly difficult to distinguish
from reality. We introduce a simple yet effective two-stage detection method
that achieves an AUROC of over 99.8% on contemporary deepfakes. However, this
high performance is short-lived. We show that models trained on this data
suffer a recall drop of over 30% when evaluated on deepfakes created with
generation techniques from just six months later, demonstrating significant
decay as threats evolve. Our analysis reveals two key insights for robust
detection. Firstly, continued performance requires the ongoing curation of
large, diverse datasets. Second, predictive power comes primarily from static,
frame-level artifacts, not temporal inconsistencies. The future of effective
deepfake detection therefore depends on rapid data collection and the
development of advanced frame-level feature detectors.

</details>


### [137] [Certified L2-Norm Robustness of 3D Point Cloud Recognition in the Frequency Domain](https://arxiv.org/abs/2511.07029)
*Liang Zhou,Qiming Wang,Tianze Chen*

Main category: cs.CV

TL;DR: FreqCert是一个新颖的认证框架，通过将鲁棒性分析转移到频域来认证3D点云分类器对抗全局L2有界扰动，相比传统空间域防御方法能更好地处理几何失真。


<details>
  <summary>Details</summary>
Motivation: 现有认证防御方法限制逐点扰动但忽略了保持单个点却改变整体结构的微妙几何失真，这在安全关键应用中存在风险。

Method: 通过图傅里叶变换将输入点云转换到频域，应用结构化频率感知子采样生成多个子点云，每个子云由标准模型独立分类，通过多数投票获得最终预测。

Result: 在ModelNet40和ScanObjectNN数据集上的实验表明，FreqCert在强扰动下始终实现更高的认证准确率和经验准确率。

Conclusion: 频谱表示为实现3D点云识别中的可认证鲁棒性提供了有效途径。

Abstract: 3D point cloud classification is a fundamental task in safety-critical
applications such as autonomous driving, robotics, and augmented reality.
However, recent studies reveal that point cloud classifiers are vulnerable to
structured adversarial perturbations and geometric corruptions, posing risks to
their deployment in safety-critical scenarios. Existing certified defenses
limit point-wise perturbations but overlook subtle geometric distortions that
preserve individual points yet alter the overall structure, potentially leading
to misclassification. In this work, we propose FreqCert, a novel certification
framework that departs from conventional spatial domain defenses by shifting
robustness analysis to the frequency domain, enabling structured certification
against global L2-bounded perturbations. FreqCert first transforms the input
point cloud via the graph Fourier transform (GFT), then applies structured
frequency-aware subsampling to generate multiple sub-point clouds. Each
sub-cloud is independently classified by a standard model, and the final
prediction is obtained through majority voting, where sub-clouds are
constructed based on spectral similarity rather than spatial proximity, making
the partitioning more stable under L2 perturbations and better aligned with the
object's intrinsic structure. We derive a closed-form lower bound on the
certified L2 robustness radius and prove its tightness under minimal and
interpretable assumptions, establishing a theoretical foundation for frequency
domain certification. Extensive experiments on the ModelNet40 and ScanObjectNN
datasets demonstrate that FreqCert consistently achieves higher certified
accuracy and empirical accuracy under strong perturbations. Our results suggest
that spectral representations provide an effective pathway toward certifiable
robustness in 3D point cloud recognition.

</details>


### [138] [3D-ANC: Adaptive Neural Collapse for Robust 3D Point Cloud Recognition](https://arxiv.org/abs/2511.07040)
*Yuanmin Huang,Wenxuan Li,Mi Zhang,Xiaohan Zhang,Xiaoyu You,Min Yang*

Main category: cs.CV

TL;DR: 3D-ANC是一种利用神经崩溃机制的新型防御方法，通过构建解缠的特征空间来提升3D点云识别的对抗鲁棒性，解决了传统防御方法在复杂攻击模式下的性能不足问题。


<details>
  <summary>Details</summary>
Motivation: 传统防御机制难以应对不断演化的多面攻击模式，现有防御性能不佳主要源于纠缠的特征空间，使得对抗攻击容易实施。

Method: 结合ETF对齐分类模块和自适应训练框架（包含表示平衡学习和动态特征方向损失），利用神经崩溃机制构建最大可分离的类原型。

Result: 在多个模型结构上显著提升鲁棒性，例如DGCNN在ModelNet40上的分类准确率从27.2%提升至80.9%，绝对增益53.7%，超过领先基线34.0%。

Conclusion: 3D-ANC能够有效赋能现有模型，在复杂3D数据分布下开发解缠特征空间，显著提升对抗鲁棒性。

Abstract: Deep neural networks have recently achieved notable progress in 3D point
cloud recognition, yet their vulnerability to adversarial perturbations poses
critical security challenges in practical deployments. Conventional defense
mechanisms struggle to address the evolving landscape of multifaceted attack
patterns. Through systematic analysis of existing defenses, we identify that
their unsatisfactory performance primarily originates from an entangled feature
space, where adversarial attacks can be performed easily. To this end, we
present 3D-ANC, a novel approach that capitalizes on the Neural Collapse (NC)
mechanism to orchestrate discriminative feature learning. In particular, NC
depicts where last-layer features and classifier weights jointly evolve into a
simplex equiangular tight frame (ETF) arrangement, establishing maximally
separable class prototypes. However, leveraging this advantage in 3D
recognition confronts two substantial challenges: (1) prevalent class imbalance
in point cloud datasets, and (2) complex geometric similarities between object
categories. To tackle these obstacles, our solution combines an ETF-aligned
classification module with an adaptive training framework consisting of
representation-balanced learning (RBL) and dynamic feature direction loss
(FDL). 3D-ANC seamlessly empowers existing models to develop disentangled
feature spaces despite the complexity in 3D data distribution. Comprehensive
evaluations state that 3D-ANC significantly improves the robustness of models
with various structures on two datasets. For instance, DGCNN's classification
accuracy is elevated from 27.2% to 80.9% on ModelNet40 -- a 53.7% absolute gain
that surpasses leading baselines by 34.0%.

</details>


### [139] [From Pretrain to Pain: Adversarial Vulnerability of Video Foundation Models Without Task Knowledge](https://arxiv.org/abs/2511.07049)
*Hui Lu,Yi Yu,Song Xia,Yiming Yang,Deepu Rajan,Boon Poh Ng,Alex Kot,Xudong Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种针对视频基础模型（VFMs）的新型对抗攻击方法TVA，该攻击可以在不了解下游任务、训练数据、模型查询和架构的情况下，直接利用VFMs的时序表示动态来生成有效扰动。


<details>
  <summary>Details</summary>
Motivation: 随着大规模视频基础模型的开放使用，攻击者可以利用这些模型的完整知识发起强大的攻击。本文研究了一种新颖且实用的对抗威胁场景：攻击从开源VFMs微调的下游模型或多模态大语言模型，而无需访问受害者任务、训练数据、模型查询和架构。

Method: 提出了TVA（可转移视频攻击）方法，这是一种时序感知的对抗攻击方法，利用VFMs的时序表示动态来制作有效扰动。TVA集成了双向对比学习机制来最大化干净特征和对抗特征之间的差异，并引入了时序一致性损失来利用运动线索增强扰动的序列影响。

Result: 在24个视频相关任务上的广泛实验证明了TVA对下游模型和MLLMs的有效性，揭示了视频模型部署中先前未被充分探索的安全漏洞。

Conclusion: TVA避免了训练昂贵的替代模型或访问领域特定数据的需要，从而提供了一种更实用和高效的攻击策略，揭示了视频基础模型部署中的安全风险。

Abstract: Large-scale Video Foundation Models (VFMs) has significantly advanced various
video-related tasks, either through task-specific models or Multi-modal Large
Language Models (MLLMs). However, the open accessibility of VFMs also
introduces critical security risks, as adversaries can exploit full knowledge
of the VFMs to launch potent attacks. This paper investigates a novel and
practical adversarial threat scenario: attacking downstream models or MLLMs
fine-tuned from open-source VFMs, without requiring access to the victim task,
training data, model query, and architecture. In contrast to conventional
transfer-based attacks that rely on task-aligned surrogate models, we
demonstrate that adversarial vulnerabilities can be exploited directly from the
VFMs. To this end, we propose the Transferable Video Attack (TVA), a
temporal-aware adversarial attack method that leverages the temporal
representation dynamics of VFMs to craft effective perturbations. TVA
integrates a bidirectional contrastive learning mechanism to maximize the
discrepancy between the clean and adversarial features, and introduces a
temporal consistency loss that exploits motion cues to enhance the sequential
impact of perturbations. TVA avoids the need to train expensive surrogate
models or access to domain-specific data, thereby offering a more practical and
efficient attack strategy. Extensive experiments across 24 video-related tasks
demonstrate the efficacy of TVA against downstream models and MLLMs, revealing
a previously underexplored security vulnerability in the deployment of video
models.

</details>


### [140] [Improving Deepfake Detection with Reinforcement Learning-Based Adaptive Data Augmentation](https://arxiv.org/abs/2511.07051)
*Yuxuan Zhou,Tao Yu,Wen Huang,Yuheng Zhang,Tao Dai,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 本文提出CRDA框架，通过强化学习和因果推理动态生成深度伪造检测器的数据增强样本，从简单到复杂逐步学习多领域伪造特征，显著提升检测器的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测器的数据增强方法采用固定策略，无法充分模拟现实世界中不断演变的复杂伪造特征（如面部扭曲、表情操纵等），限制了检测器的泛化能力。

Method: 提出CRDA框架：1）使用可配置的伪造操作池合成增强样本；2）基于检测器当前学习状态动态生成对抗样本；3）集成强化学习动态选择增强动作；4）结合因果推理抑制虚假相关性，关注因果不变特征。

Result: 在多个跨域数据集上的广泛实验表明，该方法显著提高了检测器的泛化能力，优于现有最先进方法。

Conclusion: CRDA框架通过动态数据增强策略有效解决了深度伪造检测中的泛化问题，为现实应用提供了更鲁棒的解决方案。

Abstract: The generalization capability of deepfake detectors is critical for
real-world use. Data augmentation via synthetic fake face generation
effectively enhances generalization, yet current SoTA methods rely on fixed
strategies-raising a key question: Is a single static augmentation sufficient,
or does the diversity of forgery features demand dynamic approaches? We argue
existing methods overlook the evolving complexity of real-world forgeries
(e.g., facial warping, expression manipulation), which fixed policies cannot
fully simulate. To address this, we propose CRDA (Curriculum
Reinforcement-Learning Data Augmentation), a novel framework guiding detectors
to progressively master multi-domain forgery features from simple to complex.
CRDA synthesizes augmented samples via a configurable pool of forgery
operations and dynamically generates adversarial samples tailored to the
detector's current learning state. Central to our approach is integrating
reinforcement learning (RL) and causal inference. An RL agent dynamically
selects augmentation actions based on detector performance to efficiently
explore the vast augmentation space, adapting to increasingly challenging
forgeries. Simultaneously, the agent introduces action space variations to
generate heterogeneous forgery patterns, guided by causal inference to mitigate
spurious correlations-suppressing task-irrelevant biases and focusing on
causally invariant features. This integration ensures robust generalization by
decoupling synthetic augmentation patterns from the model's learned
representations. Extensive experiments show our method significantly improves
detector generalizability, outperforming SOTA methods across multiple
cross-domain datasets.

</details>


### [141] [RaLD: Generating High-Resolution 3D Radar Point Clouds with Latent Diffusion](https://arxiv.org/abs/2511.07067)
*Ruijie Zhang,Bixin Zeng,Shengpeng Wang,Fuhui Zhou,Wei Wang*

Main category: cs.CV

TL;DR: 本文提出RaLD框架，通过集成场景级视锥LiDAR自编码、顺序不变潜在表示和直接雷达频谱条件，解决了毫米波雷达点云稀疏和低分辨率的问题，实现了从原始雷达频谱生成密集准确的3D点云。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达在恶劣条件下具有鲁棒性且成本低，但其点云稀疏和分辨率低限制了在需要密集准确3D感知任务中的应用。现有生成方法依赖密集体素表示，效率低且难以保持结构细节。

Method: 提出RaLD框架，集成场景级视锥LiDAR自编码、顺序不变潜在表示和直接雷达频谱条件，使用潜在扩散模型进行3D生成。

Result: 实验表明，RaLD能够从原始雷达频谱生成密集准确的3D点云，在挑战性环境中提供鲁棒感知解决方案。

Conclusion: RaLD框架通过紧凑且表达力强的生成过程，有效解决了雷达点云稀疏和低分辨率问题，为恶劣环境下的鲁棒感知提供了有前景的解决方案。

Abstract: Millimeter-wave radar offers a promising sensing modality for autonomous
systems thanks to its robustness in adverse conditions and low cost. However,
its utility is significantly limited by the sparsity and low resolution of
radar point clouds, which poses challenges for tasks requiring dense and
accurate 3D perception. Despite that recent efforts have shown great potential
by exploring generative approaches to address this issue, they often rely on
dense voxel representations that are inefficient and struggle to preserve
structural detail. To fill this gap, we make the key observation that latent
diffusion models (LDMs), though successful in other modalities, have not been
effectively leveraged for radar-based 3D generation due to a lack of compatible
representations and conditioning strategies. We introduce RaLD, a framework
that bridges this gap by integrating scene-level frustum-based LiDAR
autoencoding, order-invariant latent representations, and direct radar spectrum
conditioning. These insights lead to a more compact and expressive generation
process. Experiments show that RaLD produces dense and accurate 3D point clouds
from raw radar spectrums, offering a promising solution for robust perception
in challenging environments.

</details>


### [142] [ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora](https://arxiv.org/abs/2511.07068)
*Nikolas Adaloglou,Diana Petrusheva,Mohamed Asker,Felix Michels,Markus Kollmann*

Main category: cs.CV

TL;DR: ClusterMine是一种无需预定义ID标签的无监督OOD检测方法，通过文本语料库挖掘正标签概念，结合视觉聚类和零样本图像-文本一致性，在多种CLIP模型上实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大规模视觉OOD检测方法依赖预定义ID标签名称，但这些标签在实际部署中可能不可用、不可靠或由于分布偏移而失效，需要真正无监督的解决方案。

Method: 提出ClusterMine方法，从大型文本语料库中挖掘正概念标签，结合视觉样本一致性（通过聚类）和零样本图像-文本一致性来提取正标签。

Result: ClusterMine在多种CLIP模型上实现最先进的OOD检测性能，对协变量ID分布偏移具有强鲁棒性，是首个无需正标签就能达到SOTA性能的方法。

Conclusion: 该方法证明了利用广泛可用的文本语料库进行正标签挖掘的可行性，为真正无监督的OOD检测提供了有效解决方案。

Abstract: Large-scale visual out-of-distribution (OOD) detection has witnessed
remarkable progress by leveraging vision-language models such as CLIP. However,
a significant limitation of current methods is their reliance on a pre-defined
set of in-distribution (ID) ground-truth label names (positives). These fixed
label names can be unavailable, unreliable at scale, or become less relevant
due to in-distribution shifts after deployment. Towards truly unsupervised OOD
detection, we utilize widely available text corpora for positive label mining,
bypassing the need for positives. In this paper, we utilize widely available
text corpora for positive label mining under a general concept mining paradigm.
Within this framework, we propose ClusterMine, a novel positive label mining
method. ClusterMine is the first method to achieve state-of-the-art OOD
detection performance without access to positive labels. It extracts positive
concepts from a large text corpus by combining visual-only sample consistency
(via clustering) and zero-shot image-text consistency. Our experimental study
reveals that ClusterMine is scalable across a plethora of CLIP models and
achieves state-of-the-art robustness to covariate in-distribution shifts. The
code is available at https://github.com/HHU-MMBS/clustermine_wacv_official.

</details>


### [143] [Pandar128 dataset for lane line detection](https://arxiv.org/abs/2511.07084)
*Filip Beránek,Václav Diviš,Ivan Gruber*

Main category: cs.CV

TL;DR: Pandar128是最大的128线激光雷达车道线检测公开数据集，包含52,000+相机帧和34,000+激光雷达扫描，提供完整传感器标定和同步里程计。同时提出了轻量级基线方法SimpleLidarLane和新的多段线评估指标IAM-F1。


<details>
  <summary>Details</summary>
Motivation: 解决激光雷达车道线检测领域缺乏大规模高质量数据集和标准化评估方法的问题，为研究社区提供可靠的数据基础。

Method: 1) 构建Pandar128数据集：在德国多样化真实场景采集数据，提供完整传感器标定；2) 提出SimpleLidarLane方法：结合BEV分割、聚类和多段线拟合的轻量级管道；3) 设计IAM-F1评估指标：基于插值感知横向匹配的多段线度量。

Result: 数据集包含52,000+相机帧和34,000+激光雷达扫描，覆盖各种挑战性条件（如雨天、稀疏点云）。基线方法在复杂条件下表现优异，证明模块化管道配合高质量数据可与复杂方法竞争。

Conclusion: 高质量数据集、轻量级方法和标准化评估指标的结合能够有效推动激光雷达车道线检测领域的发展，所有数据和代码已公开以支持可复现性。

Abstract: We present Pandar128, the largest public dataset for lane line detection
using a 128-beam LiDAR. It contains over 52,000 camera frames and 34,000 LiDAR
scans, captured in diverse real-world conditions in Germany. The dataset
includes full sensor calibration (intrinsics, extrinsics) and synchronized
odometry, supporting tasks such as projection, fusion, and temporal modeling.
  To complement the dataset, we also introduce SimpleLidarLane, a light-weight
baseline method for lane line reconstruction that combines BEV segmentation,
clustering, and polyline fitting. Despite its simplicity, our method achieves
strong performance under challenging various conditions (e.g., rain, sparse
returns), showing that modular pipelines paired with high-quality data and
principled evaluation can compete with more complex approaches.
  Furthermore, to address the lack of standardized evaluation, we propose a
novel polyline-based metric - Interpolation-Aware Matching F1 (IAM-F1) - that
employs interpolation-aware lateral matching in BEV space.
  All data and code are publicly released to support reproducibility in
LiDAR-based lane detection.

</details>


### [144] [How Bias Binds: Measuring Hidden Associations for Bias Control in Text-to-Image Compositions](https://arxiv.org/abs/2511.07091)
*Jeng-Lin Li,Ming-Ching Chang,Wei-Chao Chen*

Main category: cs.CV

TL;DR: 本文研究了文本到图像生成模型在语义绑定上下文中的偏见问题，发现当前去偏见方法在处理对象-属性语义绑定时会失效，并提出了量化偏见程度的分数和无需训练的去偏见框架。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型存在偏见问题，但现有研究主要关注单一对象提示，忽略了语义绑定（如对象与属性的关联）对偏见的联合影响，导致去偏见方法失效。

Method: 提出了偏见依从分数来量化对象-属性绑定激活的偏见程度，并开发了无需训练的上下文偏见控制框架，通过标记解耦来消除语义绑定中的偏见。

Result: 该框架在组合生成任务中实现了超过10%的去偏见改进，分析显示在保持必要语义关系的同时减少偏见是一个根本性挑战。

Conclusion: 当前去偏见方法在处理语义绑定上下文时存在严重局限性，需要重新评估主流的偏见缓解策略。

Abstract: Text-to-image generative models often exhibit bias related to sensitive
attributes. However, current research tends to focus narrowly on single-object
prompts with limited contextual diversity. In reality, each object or attribute
within a prompt can contribute to bias. For example, the prompt "an assistant
wearing a pink hat" may reflect female-inclined biases associated with a pink
hat. The neglected joint effects of the semantic binding in the prompts cause
significant failures in current debiasing approaches. This work initiates a
preliminary investigation on how bias manifests under semantic binding, where
contextual associations between objects and attributes influence generative
outcomes. We demonstrate that the underlying bias distribution can be amplified
based on these associations. Therefore, we introduce a bias adherence score
that quantifies how specific object-attribute bindings activate bias. To delve
deeper, we develop a training-free context-bias control framework to explore
how token decoupling can facilitate the debiasing of semantic bindings. This
framework achieves over 10% debiasing improvement in compositional generation
tasks. Our analysis of bias scores across various attribute-object bindings and
token decorrelation highlights a fundamental challenge: reducing bias without
disrupting essential semantic relationships. These findings expose critical
limitations in current debiasing approaches when applied to semantically bound
contexts, underscoring the need to reassess prevailing bias mitigation
strategies.

</details>


### [145] [GEWDiff: Geometric Enhanced Wavelet-based Diffusion Model for Hyperspectral Image Super-resolution](https://arxiv.org/abs/2511.07103)
*Sirui Wang,Jiang He,Natàlia Blasco Andreo,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出GEWDiff模型，通过小波编码器和几何增强扩散过程实现高光谱图像的4倍超分辨率重建，解决了传统扩散模型处理高光谱图像时的内存和几何结构保持问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像生成面临三个主要挑战：高光谱维度导致内存密集、传统生成模型缺乏对遥感图像几何结构的理解、扩散模型在噪声级优化损失函数导致收敛行为不直观和生成质量不佳。

Method: 使用小波基编码器-解码器压缩高光谱图像到潜在空间，保留光谱空间信息；引入几何增强扩散过程保持几何特征；设计多级损失函数指导扩散过程，促进稳定收敛。

Result: 模型在多个维度上展示了最先进的结果，包括保真度、光谱精度、视觉真实性和清晰度。

Conclusion: GEWDiff框架成功解决了高光谱图像超分辨率重建中的关键挑战，通过小波压缩、几何增强和多级损失函数实现了高质量的重建效果。

Abstract: Improving the quality of hyperspectral images (HSIs), such as through
super-resolution, is a crucial research area. However, generative modeling for
HSIs presents several challenges. Due to their high spectral dimensionality,
HSIs are too memory-intensive for direct input into conventional diffusion
models. Furthermore, general generative models lack an understanding of the
topological and geometric structures of ground objects in remote sensing
imagery. In addition, most diffusion models optimize loss functions at the
noise level, leading to a non-intuitive convergence behavior and suboptimal
generation quality for complex data. To address these challenges, we propose a
Geometric Enhanced Wavelet-based Diffusion Model (GEWDiff), a novel framework
for reconstructing hyperspectral images at 4-times super-resolution. A
wavelet-based encoder-decoder is introduced that efficiently compresses HSIs
into a latent space while preserving spectral-spatial information. To avoid
distortion during generation, we incorporate a geometry-enhanced diffusion
process that preserves the geometric features. Furthermore, a multi-level loss
function was designed to guide the diffusion process, promoting stable
convergence and improved reconstruction fidelity. Our model demonstrated
state-of-the-art results across multiple dimensions, including fidelity,
spectral accuracy, visual realism, and clarity.

</details>


### [146] [Sparse4DGS: 4D Gaussian Splatting for Sparse-Frame Dynamic Scene Reconstruction](https://arxiv.org/abs/2511.07122)
*Changyue Shi,Chuxiao Yang,Xinyuan Hu,Minghao Chen,Wenwen Pan,Yan Yang,Jiajun Ding,Zhou Yu,Jun Yu*

Main category: cs.CV

TL;DR: Sparse4DGS是首个针对稀疏帧动态场景重建的方法，通过纹理感知的变形正则化和纹理感知的规范优化，解决了稀疏帧条件下动态重建在规范空间和变形空间中的失败问题。


<details>
  <summary>Details</summary>
Motivation: 现有动态高斯溅射方法依赖密集帧视频序列进行逼真重建，但在真实场景中由于设备限制，有时只能获取稀疏帧。现有方法在稀疏帧设置下在规范空间和变形空间中都会失败，尤其是在纹理丰富区域。

Method: 提出Sparse4DGS方法：1）纹理感知变形正则化，引入基于纹理的深度对齐损失来调节高斯变形；2）纹理感知规范优化，将基于纹理的噪声纳入规范高斯梯度下降过程。

Result: 在NeRF-Synthetic、HyperNeRF、NeRF-DS和iPhone-4D数据集上的广泛实验表明，当输入稀疏帧时，该方法优于现有的动态或少量样本技术。

Conclusion: Sparse4DGS成功解决了稀疏帧动态场景重建的挑战，特别是在纹理丰富区域，为设备受限场景下的4D重建提供了有效解决方案。

Abstract: Dynamic Gaussian Splatting approaches have achieved remarkable performance
for 4D scene reconstruction. However, these approaches rely on dense-frame
video sequences for photorealistic reconstruction. In real-world scenarios, due
to equipment constraints, sometimes only sparse frames are accessible. In this
paper, we propose Sparse4DGS, the first method for sparse-frame dynamic scene
reconstruction. We observe that dynamic reconstruction methods fail in both
canonical and deformed spaces under sparse-frame settings, especially in areas
with high texture richness. Sparse4DGS tackles this challenge by focusing on
texture-rich areas. For the deformation network, we propose Texture-Aware
Deformation Regularization, which introduces a texture-based depth alignment
loss to regulate Gaussian deformation. For the canonical Gaussian field, we
introduce Texture-Aware Canonical Optimization, which incorporates
texture-based noise into the gradient descent process of canonical Gaussians.
Extensive experiments show that when taking sparse frames as inputs, our method
outperforms existing dynamic or few-shot techniques on NeRF-Synthetic,
HyperNeRF, NeRF-DS, and our iPhone-4D datasets.

</details>


### [147] [MPJudge: Towards Perceptual Assessment of Music-Induced Paintings](https://arxiv.org/abs/2511.07137)
*Shiqi Jiang,Tianyi Liang,Changbo Wang,Chenhui Li*

Main category: cs.CV

TL;DR: 提出了一种新的音乐诱导绘画评估框架，通过直接建模音乐与视觉艺术之间的感知一致性来评估绘画是否忠实反映音乐，克服了现有基于情感识别方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖情感识别模型来评估音乐与绘画的相似性，但这种方法引入大量噪声且忽略了情感之外的更广泛感知线索。

Method: 构建了首个大规模音乐绘画配对数据集MPD，并收集了成对偏好标注。提出了MPJudge模型，通过基于调制的融合机制将音乐特征整合到视觉编码器中，并采用直接偏好优化进行训练。

Result: 大量实验表明该方法优于现有方法，定性结果进一步显示模型能更准确地识别绘画中与音乐相关的区域。

Conclusion: 所提出的框架通过直接建模感知一致性，为音乐诱导绘画评估提供了更有效的解决方案，并在准确性和解释性方面表现出色。

Abstract: Music induced painting is a unique artistic practice, where visual artworks
are created under the influence of music. Evaluating whether a painting
faithfully reflects the music that inspired it poses a challenging perceptual
assessment task. Existing methods primarily rely on emotion recognition models
to assess the similarity between music and painting, but such models introduce
considerable noise and overlook broader perceptual cues beyond emotion. To
address these limitations, we propose a novel framework for music induced
painting assessment that directly models perceptual coherence between music and
visual art. We introduce MPD, the first large scale dataset of music painting
pairs annotated by domain experts based on perceptual coherence. To better
handle ambiguous cases, we further collect pairwise preference annotations.
Building on this dataset, we present MPJudge, a model that integrates music
features into a visual encoder via a modulation based fusion mechanism. To
effectively learn from ambiguous cases, we adopt Direct Preference Optimization
for training. Extensive experiments demonstrate that our method outperforms
existing approaches. Qualitative results further show that our model more
accurately identifies music relevant regions in paintings.

</details>


### [148] [ProcGen3D: Learning Neural Procedural Graph Representations for Image-to-3D Reconstruction](https://arxiv.org/abs/2511.07142)
*Xinyi Zhang,Daoyi Gao,Naiqi Li,Angela Dai*

Main category: cs.CV

TL;DR: ProcGen3D是一种通过生成3D对象的程序化图抽象来创建3D内容的新方法，该方法使用基于图的程序化表示，结合Transformer和蒙特卡洛树搜索，从RGB图像生成复杂的3D资产。


<details>
  <summary>Details</summary>
Motivation: 受生产级3D应用中程序化生成器的广泛使用启发，旨在学习近似程序化生成器的能力，实现基于图像的3D重建。

Method: 采用顺序化、基于图的程序化图表示，使用基于边的标记化编码程序化图，训练Transformer先验模型预测下一个标记，并引入蒙特卡洛树搜索引导采样以改善输出与输入图像的对齐。

Result: 在仙人掌、树木和桥梁等对象上的广泛实验表明，该方法在生成3D方面优于最先进的生成方法和特定领域建模技术，并在真实世界输入图像上展现出良好的泛化能力。

Conclusion: ProcGen3D能够生成丰富复杂的3D资产，尽管仅在合成数据上训练，但在真实世界图像上表现出色，为3D内容创建提供了有效的新途径。

Abstract: We introduce ProcGen3D, a new approach for 3D content creation by generating
procedural graph abstractions of 3D objects, which can then be decoded into
rich, complex 3D assets. Inspired by the prevalent use of procedural generators
in production 3D applications, we propose a sequentialized, graph-based
procedural graph representation for 3D assets. We use this to learn to
approximate the landscape of a procedural generator for image-based 3D
reconstruction. We employ edge-based tokenization to encode the procedural
graphs, and train a transformer prior to predict the next token conditioned on
an input RGB image. Crucially, to enable better alignment of our generated
outputs to an input image, we incorporate Monte Carlo Tree Search (MCTS) guided
sampling into our generation process, steering output procedural graphs towards
more image-faithful reconstructions. Our approach is applicable across a
variety of objects that can be synthesized with procedural generators.
Extensive experiments on cacti, trees, and bridges show that our neural
procedural graph generation outperforms both state-of-the-art generative 3D
methods and domain-specific modeling techniques. Furthermore, this enables
improved generalization on real-world input images, despite training only on
synthetic data.

</details>


### [149] [Federated Learning for Video Violence Detection: Complementary Roles of Lightweight CNNs and Vision-Language Models for Energy-Efficient Use](https://arxiv.org/abs/2511.07171)
*Sébastien Thuau,Siba Haidar,Rachid Chelouah*

Main category: cs.CV

TL;DR: 本文比较了三种联邦学习暴力检测方法：零样本推理、LoRA微调和个性化联邦学习，发现3D CNN在能效和校准方面表现最佳，而VLM提供更丰富的多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 基于深度学习的视频监控需要隐私保护架构，同时降低计算和环境开销。联邦学习虽然保护隐私，但部署大型视觉语言模型会带来能源和可持续性挑战。

Method: 在RWF-2000和RLVS数据集上比较三种联邦暴力检测策略：预训练VLM的零样本推理、LLaVA-NeXT-Video-7B的LoRA微调、以及65.8M参数3D CNN的个性化联邦学习。

Result: 所有方法在二元暴力检测中准确率均超过90%。3D CNN实现最佳校准（ROC AUC 92.59%），能耗约为联邦LoRA的一半（240 Wh vs. 570 Wh）。分层类别分组将VLM多类准确率从65.31%提升至81%。

Conclusion: 研究为混合部署策略提供指导：默认使用高效CNN进行常规推理，选择性使用VLM进行复杂上下文推理，平衡能效与多模态推理能力。

Abstract: Deep learning-based video surveillance increasingly demands
privacy-preserving architectures with low computational and environmental
overhead. Federated learning preserves privacy but deploying large
vision-language models (VLMs) introduces major energy and sustainability
challenges. We compare three strategies for federated violence detection under
realistic non-IID splits on the RWF-2000 and RLVS datasets: zero-shot inference
with pretrained VLMs, LoRA-based fine-tuning of LLaVA-NeXT-Video-7B, and
personalized federated learning of a 65.8M-parameter 3D CNN. All methods exceed
90% accuracy in binary violence detection. The 3D CNN achieves superior
calibration (ROC AUC 92.59%) at roughly half the energy cost (240 Wh vs. 570
Wh) of federated LoRA, while VLMs provide richer multimodal reasoning.
Hierarchical category grouping (based on semantic similarity and class
exclusion) boosts VLM multiclass accuracy from 65.31% to 81% on the UCF-Crime
dataset. To our knowledge, this is the first comparative simulation study of
LoRA-tuned VLMs and personalized CNNs for federated violence detection, with
explicit energy and CO2e quantification. Our results inform hybrid deployment
strategies that default to efficient CNNs for routine inference and selectively
engage VLMs for complex contextual reasoning.

</details>


### [150] [LiteUpdate: A Lightweight Framework for Updating AI-Generated Image Detectors](https://arxiv.org/abs/2511.07192)
*Jiajie Lu,Zhenkan Fu,Na Zhao,Long Xing,Kejiang Chen,Weiming Zhang,Nenghai Yu*

Main category: cs.CV

TL;DR: LiteUpdate是一个轻量级框架，用于持续更新AI生成图像检测器，通过边界样本选择和模型权重融合来提升检测性能并缓解灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI快速发展导致新模型不断涌现，现有检测方法难以跟上节奏，检测性能显著下降，迫切需要持续更新检测器以适应新生成器。

Method: 采用代表性样本选择模块（利用图像置信度和基于梯度的判别特征选择边界样本）和模型合并模块（融合预训练、代表性和随机更新的权重）。

Result: 在AIDE数据集上，对Midjourney的平均检测准确率从87.63%提升到93.03%，相对提升6.16%，显著提升了各种检测器的性能。

Conclusion: LiteUpdate框架有效解决了检测器更新效率低和灾难性遗忘问题，能够持续适应新生成器并保持对先前知识的记忆。

Abstract: The rapid progress of generative AI has led to the emergence of new
generative models, while existing detection methods struggle to keep pace,
resulting in significant degradation in the detection performance. This
highlights the urgent need for continuously updating AI-generated image
detectors to adapt to new generators. To overcome low efficiency and
catastrophic forgetting in detector updates, we propose LiteUpdate, a
lightweight framework for updating AI-generated image detectors. LiteUpdate
employs a representative sample selection module that leverages image
confidence and gradient-based discriminative features to precisely select
boundary samples. This approach improves learning and detection accuracy on new
distributions with limited generated images, significantly enhancing detector
update efficiency. Additionally, LiteUpdate incorporates a model merging module
that fuses weights from multiple fine-tuning trajectories, including
pre-trained, representative, and random updates. This balances the adaptability
to new generators and mitigates the catastrophic forgetting of prior knowledge.
Experiments demonstrate that LiteUpdate substantially boosts detection
performance in various detectors. Specifically, on AIDE, the average detection
accuracy on Midjourney improved from 87.63% to 93.03%, a 6.16% relative
increase.

</details>


### [151] [Automated Estimation of Anatomical Risk Metrics for Endoscopic Sinus Surgery Using Deep Learning](https://arxiv.org/abs/2511.07199)
*Konrad Reuter,Lennart Thaysen,Bilkay Doruk,Sarah Latus,Brigitte Holst,Benjamin Becker,Dennis Eggert,Christian Betz,Anna-Sophie Hoffmann,Alexander Schlaefer*

Main category: cs.CV

TL;DR: 提出了一种自动深度学习管道，通过热图回归定位关键解剖标志点来估计内窥镜鼻窦手术的解剖风险评分，替代了传统耗时的手动测量方法。


<details>
  <summary>Details</summary>
Motivation: 内窥镜鼻窦手术需要仔细的术前颅底解剖评估以最小化风险，现有的解剖风险评分需要耗时的手动测量，需要自动化解决方案。

Method: 使用深度学习管道，通过热图回归定位关键解剖标志点，比较了直接方法和专门的全局到局部学习策略。

Result: 在相关解剖测量上的平均绝对误差为：Keros评分0.506mm，Gera评分4.516度，TMS分类0.802mm/0.777mm。

Conclusion: 提出的自动深度学习管道能够准确估计内窥镜鼻窦手术的解剖风险评分，为术前评估提供了高效可靠的自动化工具。

Abstract: Endoscopic sinus surgery requires careful preoperative assessment of the
skull base anatomy to minimize risks such as cerebrospinal fluid leakage.
Anatomical risk scores like the Keros, Gera and Thailand-Malaysia-Singapore
score offer a standardized approach but require time-consuming manual
measurements on coronal CT or CBCT scans. We propose an automated deep learning
pipeline that estimates these risk scores by localizing key anatomical
landmarks via heatmap regression. We compare a direct approach to a specialized
global-to-local learning strategy and find mean absolute errors on the relevant
anatomical measurements of 0.506mm for the Keros, 4.516{\deg} for the Gera and
0.802mm / 0.777mm for the TMS classification.

</details>


### [152] [Geometric implicit neural representations for signed distance functions](https://arxiv.org/abs/2511.07206)
*Luiz Schirmer,Tiago Novello,Vinícius da Silva,Guilherme Schardong,Daniel Perazzo,Hélio Lopes,Nuno Gonçalves,Luiz Velho*

Main category: cs.CV

TL;DR: 本文综述了使用隐式神经表示(INRs)来近似有向距离函数(SDFs)的几何方法，重点介绍了通过结合微分几何工具(如法线和曲率)构建几何损失函数，从而提高3D表面重建质量的技术。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示在低维空间中表示信号方面显示出巨大潜力，但需要确保INR满足某些全局属性(如SDFs的单位梯度)，因此需要引入几何正则化项来改进3D重建质量。

Method: 通过构建包含微分几何工具(法线、曲率等)的几何损失函数，在INR训练中加入正则化项，确保函数满足应有的全局属性，并探索了从微分几何角度的采样方案。

Result: 几何INRs在有向点云和姿态图像的表面重建方面取得了显著进展，通过几何正则化提高了重建精度和几何一致性。

Conclusion: 几何INRs通过结合微分几何工具构建损失函数，为3D表面重建提供了有效的框架，显著提升了从有向点云和姿态图像重建表面的能力。

Abstract: \textit{Implicit neural representations} (INRs) have emerged as a promising
framework for representing signals in low-dimensional spaces. This survey
reviews the existing literature on the specialized INR problem of approximating
\textit{signed distance functions} (SDFs) for surface scenes, using either
oriented point clouds or a set of posed images. We refer to neural SDFs that
incorporate differential geometry tools, such as normals and curvatures, in
their loss functions as \textit{geometric} INRs. The key idea behind this 3D
reconstruction approach is to include additional \textit{regularization} terms
in the loss function, ensuring that the INR satisfies certain global properties
that the function should hold -- such as having unit gradient in the case of
SDFs. We explore key methodological components, including the definition of
INR, the construction of geometric loss functions, and sampling schemes from a
differential geometry perspective. Our review highlights the significant
advancements enabled by geometric INRs in surface reconstruction from oriented
point clouds and posed images.

</details>


### [153] [Breaking the Stealth-Potency Trade-off in Clean-Image Backdoors with Generative Trigger Optimization](https://arxiv.org/abs/2511.07210)
*Binyan Xu,Fan Yang,Di Tang,Xilin Dai,Kehuan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的干净图像后门攻击方法GCB，通过使用条件InfoGAN识别自然图像特征作为隐蔽触发器，显著降低了攻击所需的污染率，使干净准确率下降小于1%，并在多种数据集、架构和任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的干净图像后门攻击方法需要较高的污染率才能成功攻击，这会导致干净准确率显著下降，从而容易被检测到。本文旨在开发一种更隐蔽的攻击方法，最小化准确率损失。

Method: 提出生成式干净图像后门(GCB)框架，使用条件InfoGAN识别自然图像特征作为有效且隐蔽的触发器，确保这些触发器与良性任务相关特征易于分离，从而只需极少量污染样本即可学习后门。

Result: GCB在六个数据集、五种架构和四个任务中均成功实施攻击，包括首次在回归和分割任务中实现干净图像后门攻击，干净准确率下降小于1%，且对大多数现有后门防御具有抵抗力。

Conclusion: GCB提供了一种高效且隐蔽的干净图像后门攻击范式，通过优化触发器设计显著降低了攻击所需的污染率，在保持高攻击成功率的同时最小化了干净准确率损失。

Abstract: Clean-image backdoor attacks, which use only label manipulation in training
datasets to compromise deep neural networks, pose a significant threat to
security-critical applications. A critical flaw in existing methods is that the
poison rate required for a successful attack induces a proportional, and thus
noticeable, drop in Clean Accuracy (CA), undermining their stealthiness. This
paper presents a new paradigm for clean-image attacks that minimizes this
accuracy degradation by optimizing the trigger itself. We introduce Generative
Clean-Image Backdoors (GCB), a framework that uses a conditional InfoGAN to
identify naturally occurring image features that can serve as potent and
stealthy triggers. By ensuring these triggers are easily separable from benign
task-related features, GCB enables a victim model to learn the backdoor from an
extremely small set of poisoned examples, resulting in a CA drop of less than
1%. Our experiments demonstrate GCB's remarkable versatility, successfully
adapting to six datasets, five architectures, and four tasks, including the
first demonstration of clean-image backdoors in regression and segmentation.
GCB also exhibits resilience against most of the existing backdoor defenses.

</details>


### [154] [Omni-View: Unlocking How Generation Facilitates Understanding in Unified 3D Model based on Multiview images](https://arxiv.org/abs/2511.07222)
*JiaKui Hu,Shanshan Zhao,Qing-Guo Chen,Xuerui Qiu,Jialun Liu,Zhao Xu,Weihua Luo,Kaifu Zhang,Yanye Lu*

Main category: cs.CV

TL;DR: Omni-View是一个基于多视角图像的3D场景统一多模态理解和生成框架，探索"生成促进理解"原则，通过理解模型、纹理模块和几何模块联合建模场景理解、新视角合成和几何估计，在VSI-Bench基准上达到55.4的SOTA分数。


<details>
  <summary>Details</summary>
Motivation: 探索"生成促进理解"原则，将统一多模态理解和生成扩展到3D场景，实现3D场景理解与生成任务的协同交互。

Method: 由理解模型、纹理模块和几何模块组成，利用纹理模块的时空建模能力和几何模块的显式几何约束，采用两阶段训练策略。

Result: 在VSI-Bench基准上达到55.4的SOTA分数，优于现有专业3D理解模型，同时在新视角合成和3D场景生成方面表现强劲。

Conclusion: Omni-View通过联合建模理解和生成任务，实现了对3D场景的整体理解，证明了生成任务可以促进理解能力的提升。

Abstract: This paper presents Omni-View, which extends the unified multimodal
understanding and generation to 3D scenes based on multiview images, exploring
the principle that "generation facilitates understanding". Consisting of
understanding model, texture module, and geometry module, Omni-View jointly
models scene understanding, novel view synthesis, and geometry estimation,
enabling synergistic interaction between 3D scene understanding and generation
tasks. By design, it leverages the spatiotemporal modeling capabilities of its
texture module responsible for appearance synthesis, alongside the explicit
geometric constraints provided by its dedicated geometry module, thereby
enriching the model's holistic understanding of 3D scenes. Trained with a
two-stage strategy, Omni-View achieves a state-of-the-art score of 55.4 on the
VSI-Bench benchmark, outperforming existing specialized 3D understanding
models, while simultaneously delivering strong performance in both novel view
synthesis and 3D scene generation.

</details>


### [155] [Mapping Reduced Accessibility to WASH Facilities in Rohingya Refugee Camps with Sub-Meter Imagery](https://arxiv.org/abs/2511.07231)
*Kyeongjin Ahn,YongHun Suh,Sungwon Han,Jeasurk Yang,Hannes Taubenböck,Meeyoung Cha*

Main category: cs.CV

TL;DR: 本研究开发了一个遥感驱动的框架，用于量化罗兴亚难民营中WASH设施的可达性，通过半监督分割方法检测难民庇护所，发现WASH可达性正在下降，特别是对妇女和女童。


<details>
  <summary>Details</summary>
Motivation: 难民营地中水、环境卫生和个人卫生服务的获取是一个重要的公共卫生问题，特别是在世界人口最密集的流离失所环境中。

Method: 使用亚米级卫星图像开发半监督分割框架，检测单个难民庇护所，并分析WASH设施的可达性。

Result: 庇护所检测F1分数达到76.4%；WASH可达性从2022年每设施25人下降到2025年29.4人；性别分析显示妇女和女童可达性更低。

Conclusion: 需要需求响应的分配策略来识别服务不足人群，高分辨率遥感和机器学习在复杂人道主义环境中检测不平等和指导公平资源规划具有重要价值。

Abstract: Access to Water, Sanitation, and Hygiene (WASH) services remains a major
public health concern in refugee camps. This study introduces a remote
sensing-driven framework to quantify WASH accessibility-specifically to water
pumps, latrines, and bathing cubicles-in the Rohingya camps of Cox's Bazar, one
of the world's most densely populated displacement settings. Detecting refugee
shelters in such emergent camps presents substantial challenges, primarily due
to their dense spatial configuration and irregular geometric patterns. Using
sub-meter satellite images, we develop a semi-supervised segmentation framework
that achieves an F1-score of 76.4% in detecting individual refugee shelters.
Applying the framework across multi-year data reveals declining WASH
accessibility, driven by rapid refugee population growth and reduced facility
availability, rising from 25 people per facility in 2022 to 29.4 in 2025.
Gender-disaggregated analysis further shows that women and girls experience
reduced accessibility, in scenarios with inadequate safety-related segregation
in WASH facilities. These findings suggest the importance of demand-responsive
allocation strategies that can identify areas with under-served
populations-such as women and girls-and ensure that limited infrastructure
serves the greatest number of people in settings with fixed or shrinking
budgets. We also discuss the value of high-resolution remote sensing and
machine learning to detect inequality and inform equitable resource planning in
complex humanitarian environments.

</details>


### [156] [Noise & pattern: identity-anchored Tikhonov regularization for robust structural anomaly detection](https://arxiv.org/abs/2511.07233)
*Alexander Bauer,Klaus-Robert Müller*

Main category: cs.CV

TL;DR: 提出一种基于自监督自动编码器的结构异常检测方法，通过注入结构化扰动来模拟缺陷，并引入高斯噪声作为正则化器，在MVTec AD基准上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 工业自动检测中难以收集所有可能的异常样本，因此需要一种能够检测细微或罕见缺陷的方法，特别是在结构异常检测方面。

Method: 使用自监督自动编码器学习修复被破坏的输入，引入结构化、空间连贯的扰动来模拟结构缺陷，并在遮挡上添加高斯噪声作为Tikhonov正则化器。

Result: 在MVTec AD基准测试中实现了最先进的结果（图像/像素AUROC：99.9/99.4），证明了方法的有效性。

Conclusion: 提出的身份锚定正则化方法稳定了重建过程，显著提高了检测和分割精度，为自动工业检测提供了实用的解决方案。

Abstract: Anomaly detection plays a pivotal role in automated industrial inspection,
aiming to identify subtle or rare defects in otherwise uniform visual patterns.
As collecting representative examples of all possible anomalies is infeasible,
we tackle structural anomaly detection using a self-supervised autoencoder that
learns to repair corrupted inputs. To this end, we introduce a corruption model
that injects artificial disruptions into training images to mimic structural
defects. While reminiscent of denoising autoencoders, our approach differs in
two key aspects. First, instead of unstructured i.i.d.\ noise, we apply
structured, spatially coherent perturbations that make the task a hybrid of
segmentation and inpainting. Second, and counterintuitively, we add and
preserve Gaussian noise on top of the occlusions, which acts as a Tikhonov
regularizer anchoring the Jacobian of the reconstruction function toward
identity. This identity-anchored regularization stabilizes reconstruction and
further improves both detection and segmentation accuracy. On the MVTec AD
benchmark, our method achieves state-of-the-art results (I/P-AUROC: 99.9/99.4),
supporting our theoretical framework and demonstrating its practical relevance
for automatic inspection.

</details>


### [157] [Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation](https://arxiv.org/abs/2511.07238)
*Seungheon Song,Jaekoo Lee*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型的文本驱动OOD分割方法，通过结合视觉语言编码器和Transformer解码器，利用距离基OOD提示和OOD语义增强，在自动驾驶场景中实现有效的异常物体分割。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶和机器人领域，确保道路安全和可靠决策严重依赖于OOD分割。虽然已有多种方法检测道路上的异常物体，但利用视觉语言空间提供的丰富语言知识仍是一个未充分探索的领域。

Method: 结合视觉语言模型的编码器与Transformer解码器，采用距离基OOD提示（位于与ID类不同语义距离的位置）和OOD语义增强，通过对齐视觉和文本信息来学习语义多样的物体。

Result: 在Fishyscapes、Segment-Me-If-You-Can和Road Anomaly等公开OOD分割数据集上的广泛实验表明，该方法在像素级和物体级评估中都达到了最先进的性能。

Conclusion: 基于视觉语言的OOD分割方法有潜力增强未来自动驾驶系统的安全性和可靠性。

Abstract: In autonomous driving and robotics, ensuring road safety and reliable
decision-making critically depends on out-of-distribution (OOD) segmentation.
While numerous methods have been proposed to detect anomalous objects on the
road, leveraging the vision-language space-which provides rich linguistic
knowledge-remains an underexplored field. We hypothesize that incorporating
these linguistic cues can be especially beneficial in the complex contexts
found in real-world autonomous driving scenarios.
  To this end, we present a novel approach that trains a Text-Driven OOD
Segmentation model to learn a semantically diverse set of objects in the
vision-language space. Concretely, our approach combines a vision-language
model's encoder with a transformer decoder, employs Distance-Based OOD prompts
located at varying semantic distances from in-distribution (ID) classes, and
utilizes OOD Semantic Augmentation for OOD representations. By aligning visual
and textual information, our approach effectively generalizes to unseen objects
and provides robust OOD segmentation in diverse driving environments.
  We conduct extensive experiments on publicly available OOD segmentation
datasets such as Fishyscapes, Segment-Me-If-You-Can, and Road Anomaly datasets,
demonstrating that our approach achieves state-of-the-art performance across
both pixel-level and object-level evaluations. This result underscores the
potential of vision-language-based OOD segmentation to bolster the safety and
reliability of future autonomous driving systems.

</details>


### [158] [MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs](https://arxiv.org/abs/2511.07250)
*Tianhao Peng,Haochen Wang,Yuanxing Zhang,Zekun Wang,Zili Wang,Ge Zhang,Jian Yang,Shihao Li,Yanghai Wang,Xintao Wang,Houyi Li,Wei Ji,Pengfei Wan,Wenhao Huang,Zhaoxiang Zhang,Jiaheng Liu*

Main category: cs.CV

TL;DR: MVU-Eval是首个针对多模态大语言模型的多视频理解评估基准，包含1,824个精心设计的问答对，涵盖4,959个视频，评估8个核心能力，填补了现有基准仅限于单视频理解的空白。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准仅限于单视频理解，无法满足现实场景（如体育分析和自动驾驶）中对多视频理解的需求，存在显著的研究空白。

Method: 构建了包含1,824个问答对的综合基准，涵盖4,959个来自不同领域的视频，评估8个核心能力，包括基础感知任务和高级推理任务。

Result: 通过对最先进的开源和闭源模型进行广泛评估，揭示了当前MLLMs在多视频理解能力方面存在显著性能差异和局限性。

Conclusion: MVU-Eval基准将公开提供，以促进未来在多视频理解领域的研究发展。

Abstract: The advent of Multimodal Large Language Models (MLLMs) has expanded AI
capabilities to visual modalities, yet existing evaluation benchmarks remain
limited to single-video understanding, overlooking the critical need for
multi-video understanding in real-world scenarios (e.g., sports analytics and
autonomous driving). To address this significant gap, we introduce MVU-Eval,
the first comprehensive benchmark for evaluating Multi-Video Understanding for
MLLMs. Specifically, our MVU-Eval mainly assesses eight core competencies
through 1,824 meticulously curated question-answer pairs spanning 4,959 videos
from diverse domains, addressing both fundamental perception tasks and
high-order reasoning tasks. These capabilities are rigorously aligned with
real-world applications such as multi-sensor synthesis in autonomous systems
and cross-angle sports analytics. Through extensive evaluation of
state-of-the-art open-source and closed-source models, we reveal significant
performance discrepancies and limitations in current MLLMs' ability to perform
understanding across multiple videos. The benchmark will be made publicly
available to foster future research.

</details>


### [159] [StreamKV: Streaming Video Question-Answering with Segment-based KV Cache Retrieval and Compression](https://arxiv.org/abs/2511.07278)
*Yilong Chen,Xiang Bai,Zhibin Wang,Chengyu Bai,Yuhan Dai,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: StreamKV是一个无需训练的视频大语言模型框架，通过动态语义分割、摘要向量检索和引导提示压缩KV缓存，显著提升长视频问答的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型在处理长真实世界视频时面临挑战，现有方法的KV缓存压缩和检索机制尚未充分探索，需要更高效的解决方案。

Method: 提出StreamKV框架：动态分割视频流为语义段，计算摘要向量用于KV缓存检索，使用引导提示进行KV缓存压缩，在层自适应方式下统一检索和压缩。

Result: 在StreamingVQA基准测试中，StreamKV显著优于现有在线视频大语言模型，在准确性、内存效率和计算延迟方面均有大幅提升。

Conclusion: StreamKV通过先进的KV缓存检索和压缩技术，有效解决了长视频问答的挑战，为视频大语言模型的实际应用提供了高效解决方案。

Abstract: Video Large Language Models (Video-LLMs) have demonstrated significant
potential in the areas of video captioning, search, and summarization. However,
current Video-LLMs still face challenges with long real-world videos. Recent
methods have introduced a retrieval mechanism that retrieves query-relevant KV
caches for question answering, enhancing the efficiency and accuracy of long
real-world videos. However, the compression and retrieval of KV caches are
still not fully explored. In this paper, we propose \textbf{StreamKV}, a
training-free framework that seamlessly equips Video-LLMs with advanced KV
cache retrieval and compression. Compared to previous methods that used uniform
partitioning, StreamKV dynamically partitions video streams into semantic
segments, which better preserves semantic information. For KV cache retrieval,
StreamKV calculates a summary vector for each segment to retain segment-level
information essential for retrieval. For KV cache compression, StreamKV
introduces a guidance prompt designed to capture the key semantic elements
within each segment, ensuring only the most informative KV caches are retained
for answering questions. Moreover, StreamKV unifies KV cache retrieval and
compression within a single module, performing both in a layer-adaptive manner,
thereby further improving the effectiveness of streaming video question
answering. Extensive experiments on public StreamingVQA benchmarks demonstrate
that StreamKV significantly outperforms existing Online Video-LLMs, achieving
superior accuracy while substantially improving both memory efficiency and
computational latency. The code has been released at
https://github.com/sou1p0wer/StreamKV.

</details>


### [160] [Segmentation of Ischemic Stroke Lesions using Transfer Learning on Multi-sequence MRI](https://arxiv.org/abs/2511.07281)
*R. P. Chowdhury,T. Rahman*

Main category: cs.CV

TL;DR: 提出了一种基于Res-Unet架构的自动缺血性脑卒中病灶分割框架，在ISLES 2015数据集上验证，通过迁移学习和多数投票分类器集成，实现了80.5%的Dice分数和74.03%的准确率。


<details>
  <summary>Details</summary>
Motivation: 手动分割缺血性脑卒中病灶耗时且存在观察者间差异，传统方法的手工特征难以捕捉病灶的不规则复杂形状，需要开发快速自动的分割方法。

Method: 使用Res-Unet架构，分别在有无预训练权重的情况下训练模型，探索迁移学习效果，最后集成多数投票分类器来融合各轴的分割结果。

Result: 在ISLES 2015数据集上，模型达到了80.5%的Dice分数和74.03%的准确率，证明了分割方法的有效性。

Conclusion: 提出的自动分割框架能够快速准确地在多种MRI序列上分割缺血性脑卒中病灶，为临床诊断和治疗提供了可靠工具。

Abstract: The accurate understanding of ischemic stroke lesions is critical for
efficient therapy and prognosis of stroke patients. Magnetic resonance imaging
(MRI) is sensitive to acute ischemic stroke and is a common diagnostic method
for stroke. However, manual lesion segmentation performed by experts is
tedious, time-consuming, and prone to observer inconsistency. Automatic medical
image analysis methods have been proposed to overcome this challenge. However,
previous approaches have relied on hand-crafted features that may not capture
the irregular and physiologically complex shapes of ischemic stroke lesions. In
this study, we present a novel framework for quickly and automatically
segmenting ischemic stroke lesions on various MRI sequences, including
T1-weighted, T2-weighted, DWI, and FLAIR. The proposed methodology is validated
on the ISLES 2015 Brain Stroke sequence dataset, where we trained our model
using the Res-Unet architecture twice: first, with pre-existing weights, and
then without, to explore the benefits of transfer learning. Evaluation metrics,
including the Dice score and sensitivity, were computed across 3D volumes.
Finally, a Majority Voting Classifier was integrated to amalgamate the outcomes
from each axis, resulting in a comprehensive segmentation method. Our efforts
culminated in achieving a Dice score of 80.5\% and an accuracy of 74.03\%,
showcasing the efficacy of our segmentation approach.

</details>


### [161] [Glioma C6: A Novel Dataset for Training and Benchmarking Cell Segmentation](https://arxiv.org/abs/2511.07286)
*Roman Malashin,Svetlana Pashkevich,Daniil Ilyukhin,Arseniy Volkov,Valeria Yachnaya,Andrey Denisov,Maria Mikhalkova*

Main category: cs.CV

TL;DR: Glioma C6是一个用于胶质瘤C6细胞实例分割的新开放数据集，包含75张高分辨率相差显微镜图像和超过12,000个标注细胞，旨在作为深度学习模型的基准和训练资源。


<details>
  <summary>Details</summary>
Motivation: 为生物医学图像分析提供现实的测试平台，通过包含生物学家提供的细胞形态分类，增强图像数据在癌细胞研究中的利用价值。

Method: 数据集分为两部分：第一部分用于基准测试，参数受控；第二部分用于在不同条件下的泛化测试。评估了多个通用分割模型的性能。

Result: 实验表明，在Glioma C6上训练能显著提升分割性能，证明了该数据集对于开发稳健和可泛化模型的价值。

Conclusion: Glioma C6数据集公开可用，为研究人员提供了有价值的资源，有助于推进细胞分割和癌症研究的发展。

Abstract: We present Glioma C6, a new open dataset for instance segmentation of glioma
C6 cells, designed as both a benchmark and a training resource for deep
learning models. The dataset comprises 75 high-resolution phase-contrast
microscopy images with over 12,000 annotated cells, providing a realistic
testbed for biomedical image analysis. It includes soma annotations and
morphological cell categorization provided by biologists. Additional
categorization of cells, based on morphology, aims to enhance the utilization
of image data for cancer cell research. Glioma C6 consists of two parts: the
first is curated with controlled parameters for benchmarking, while the second
supports generalization testing under varying conditions. We evaluate the
performance of several generalist segmentation models, highlighting their
limitations on our dataset. Our experiments demonstrate that training on Glioma
C6 significantly enhances segmentation performance, reinforcing its value for
developing robust and generalizable models. The dataset is publicly available
for researchers.

</details>


### [162] [LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging](https://arxiv.org/abs/2511.07298)
*Kagan Celik,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: cs.CV

TL;DR: 提出基于LLM的低剂量CT图像质量评估系统，生成数值评分和文本描述，系统研究多种推理策略对性能的贡献。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT降低了辐射剂量但增加了噪声、模糊和对比度损失，需要一致且鲁棒的图像质量评估方法来保证诊断质量。

Method: 开发基于LLM的质量评估系统，采用从零样本到元数据集成和错误反馈等多种推理策略。

Result: 评估结果产生高度相关的评分和可解释的输出，为临床工作流程增加价值。

Conclusion: LLM-based质量评估系统能有效评估低剂量CT图像质量，提供数值和文本双重评估结果。

Abstract: Low-dose computed tomography (CT) represents a significant improvement in
patient safety through lower radiation doses, but increased noise, blur, and
contrast loss can diminish diagnostic quality. Therefore, consistency and
robustness in image quality assessment become essential for clinical
applications. In this study, we propose an LLM-based quality assessment system
that generates both numerical scores and textual descriptions of degradations
such as noise, blur, and contrast loss. Furthermore, various inference
strategies - from the zero-shot approach to metadata integration and error
feedback - are systematically examined, demonstrating the progressive
contribution of each method to overall performance. The resultant assessments
yield not only highly correlated scores but also interpretable output, thereby
adding value to clinical workflows. The source codes of our study are available
at https://github.com/itu-biai/lmms_ldct_iqa.

</details>


### [163] [VADER: Towards Causal Video Anomaly Understanding with Relation-Aware Large Language Models](https://arxiv.org/abs/2511.07299)
*Ying Cheng,Yu-Ho Lin,Min-Hung Chen,Fu-En Yang,Shang-Hong Lai*

Main category: cs.CV

TL;DR: VADER是一个基于大语言模型的视频异常理解框架，通过整合关键帧对象关系特征和视觉线索来增强对视频中异常事件的理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统视频异常检测方法仅关注异常检测和定位，而忽视了更深层次的因果关系和对象间交互，这些对于理解异常行为至关重要。

Method: VADER首先使用异常评分器分配每帧异常分数，然后通过上下文感知采样策略捕获每个异常事件的因果上下文。关系特征提取器和对比关系编码器共同建模动态对象交互，生成紧凑的关系表示，最后将这些视觉和关系线索与大语言模型集成。

Result: 在多个真实世界VAU基准测试上的实验表明，VADER在异常描述、解释和因果推理任务上取得了强劲结果。

Conclusion: VADER推动了可解释视频异常分析的前沿发展，能够生成详细的、基于因果关系的描述并支持稳健的异常相关问答。

Abstract: Video anomaly understanding (VAU) aims to provide detailed interpretation and
semantic comprehension of anomalous events within videos, addressing
limitations of traditional methods that focus solely on detecting and
localizing anomalies. However, existing approaches often neglect the deeper
causal relationships and interactions between objects, which are critical for
understanding anomalous behaviors. In this paper, we propose VADER, an
LLM-driven framework for Video Anomaly unDErstanding, which integrates keyframe
object Relation features with visual cues to enhance anomaly comprehension from
video. Specifically, VADER first applies an Anomaly Scorer to assign per-frame
anomaly scores, followed by a Context-AwarE Sampling (CAES) strategy to capture
the causal context of each anomalous event. A Relation Feature Extractor and a
COntrastive Relation Encoder (CORE) jointly model dynamic object interactions,
producing compact relational representations for downstream reasoning. These
visual and relational cues are integrated with LLMs to generate detailed,
causally grounded descriptions and support robust anomaly-related question
answering. Experiments on multiple real-world VAU benchmarks demonstrate that
VADER achieves strong results across anomaly description, explanation, and
causal reasoning tasks, advancing the frontier of explainable video anomaly
analysis.

</details>


### [164] [Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection](https://arxiv.org/abs/2511.07301)
*Huizai Yao,Sicheng Zhao,Pengteng Li,Yi Cui,Shuo Lu,Weiyu Guo,Yunfan Lu,Yijie Xu,Hui Xiong*

Main category: cs.CV

TL;DR: 本文提出了一种新的源自由目标检测框架，利用视觉基础模型作为外部知识源，通过三个模块联合增强特征对齐和标签质量，在六个基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的源自由目标检测方法主要依赖源模型的内部知识，这限制了跨域泛化能力，并导致有偏的伪标签，阻碍了可迁移性和判别性。而视觉基础模型具有强大的感知能力和广泛的泛化性，但在SFOD设置中潜力尚未被充分挖掘。

Method: 设计了三个基于视觉基础模型的模块：(1) 基于补丁相似性加权的全局特征对齐模块，从VFMs中提取全局特征；(2) 基于原型的实例特征对齐模块，通过动量更新的VFM原型进行实例级对比学习；(3) 双源增强伪标签融合模块，通过熵感知策略融合检测VFMs和教师模型的预测。

Result: 在六个基准测试上的广泛实验表明，该方法实现了最先进的源自由目标检测性能。

Conclusion: 验证了整合视觉基础模型同时提高可迁移性和判别性的有效性，为源自由目标检测提供了新的解决方案。

Abstract: Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object
detector to a target domain without access to source data. However, existing
SFOD methods predominantly rely on internal knowledge from the source model,
which limits their capacity to generalize across domains and often results in
biased pseudo-labels, thereby hindering both transferability and
discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on
massive and diverse data, exhibit strong perception capabilities and broad
generalization, yet their potential remains largely untapped in the SFOD
setting. In this paper, we propose a novel SFOD framework that leverages VFMs
as external knowledge sources to jointly enhance feature alignment and label
quality. Specifically, we design three VFM-based modules: (1) Patch-weighted
Global Feature Alignment (PGFA) distills global features from VFMs using
patch-similarity-based weighting to enhance global feature transferability; (2)
Prototype-based Instance Feature Alignment (PIFA) performs instance-level
contrastive learning guided by momentum-updated VFM prototypes; and (3)
Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from
detection VFMs and teacher models via an entropy-aware strategy to yield more
reliable supervision. Extensive experiments on six benchmarks demonstrate that
our method achieves state-of-the-art SFOD performance, validating the
effectiveness of integrating VFMs to simultaneously improve transferability and
discriminability.

</details>


### [165] [Garbage Vulnerable Point Monitoring using IoT and Computer Vision](https://arxiv.org/abs/2511.07325)
*R. Kumar,A. Lall,S. Chaudhari,M. Kale,A. Vattem*

Main category: cs.CV

TL;DR: 本文提出了一种基于物联网和计算机视觉的智能城市固体废物管理系统，用于监测城市垃圾易发点的非法倾倒行为。系统通过街级摄像头和物体检测算法快速检测和监控倾倒的垃圾，在印度Sangareddy地区收集数据并进行实验评估。YOLO11m模型在废物检测中达到92.39%的最高准确率，mAP@50为0.91，证明其适合监测垃圾倾倒事件并捕获废物处理模式。


<details>
  <summary>Details</summary>
Motivation: 为了解决城市地区垃圾易发点的非法倾倒问题，需要一种智能监控系统来快速检测和跟踪废物倾倒事件，提高城市固体废物管理的效率和准确性。

Method: 使用物联网和计算机视觉技术，通过街级摄像头收集数据，并采用多种物体检测模型（包括YOLOv8、YOLOv10、YOLO11m和RT-DETR）在收集的数据集上进行综合实验评估。

Result: YOLO11m模型在废物检测中表现最佳，达到92.39%的准确率和0.91的mAP@50。系统能够有效捕获废物处理模式，包括小时、每日和每周的倾倒趋势，实现全面的日夜监控。

Conclusion: 物体检测模型，特别是YOLO11m，非常适合用于监测和跟踪垃圾易发点的废物倾倒事件，系统能够提供全面的监控和废物处理模式分析。

Abstract: This paper proposes a smart way to manage municipal solid waste by using the
Internet of Things (IoT) and computer vision (CV) to monitor illegal waste
dumping at garbage vulnerable points (GVPs) in urban areas. The system can
quickly detect and monitor dumped waste using a street-level camera and object
detection algorithm. Data was collected from the Sangareddy district in
Telangana, India. A series of comprehensive experiments was carried out using
the proposed dataset to assess the accuracy and overall performance of various
object detection models. Specifically, we performed an in-depth evaluation of
YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models,
YOLO11m achieved the highest accuracy of 92.39\% in waste detection,
demonstrating its effectiveness in detecting waste. Additionally, it attains an
mAP@50 of 0.91, highlighting its high precision. These findings confirm that
the object detection model is well-suited for monitoring and tracking waste
dumping events at GVP locations. Furthermore, the system effectively captures
waste disposal patterns, including hourly, daily, and weekly dumping trends,
ensuring comprehensive daily and nightly monitoring.

</details>


### [166] [Inference-Time Scaling of Diffusion Models for Infrared Data Generation](https://arxiv.org/abs/2511.07362)
*Kai A. Horstmann,Maxim Clouser,Kia Khezeli*

Main category: cs.CV

TL;DR: 本文提出了一种在推理时使用领域自适应CLIP验证器来提升红外图像生成质量的方法，通过微调FLUX.1-dev扩散模型并利用验证器引导采样过程，在KAIST数据集上FID分数降低了10%。


<details>
  <summary>Details</summary>
Motivation: 红外图像在低能见度条件下具有优势，但高质量标注数据稀缺阻碍了下游视觉模型的发展。合成红外图像生成面临数据集有限的问题，难以训练基础级生成扩散模型。

Method: 采用推理时缩放方法，使用领域自适应CLIP验证器增强红外图像生成质量。通过参数高效技术在小样本红外图像上微调FLUX.1-dev文本到图像扩散模型，并在推理时使用训练好的验证器引导扩散采样过程。

Result: 该方法在KAIST多光谱行人检测基准数据集上，相比无引导基线样本，FID分数降低了10%，生成质量得到一致改善。

Conclusion: 推理时指导为在低数据红外设置中弥合领域差距提供了一个有前景的方向。

Abstract: Infrared imagery enables temperature-based scene understanding using passive
sensors, particularly under conditions of low visibility where traditional RGB
imaging fails. Yet, developing downstream vision models for infrared
applications is hindered by the scarcity of high-quality annotated data, due to
the specialized expertise required for infrared annotation. While synthetic
infrared image generation has the potential to accelerate model development by
providing large-scale, diverse training data, training foundation-level
generative diffusion models in the infrared domain has remained elusive due to
limited datasets. In light of such data constraints, we explore an
inference-time scaling approach using a domain-adapted CLIP-based verifier for
enhanced infrared image generation quality. We adapt FLUX.1-dev, a
state-of-the-art text-to-image diffusion model, to the infrared domain by
finetuning it on a small sample of infrared images using parameter-efficient
techniques. The trained verifier is then employed during inference to guide the
diffusion sampling process toward higher quality infrared generations that
better align with input text prompts. Empirically, we find that our approach
leads to consistent improvements in generation quality, reducing FID scores on
the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared
to unguided baseline samples. Our results suggest that inference-time guidance
offers a promising direction for bridging the domain gap in low-data infrared
settings.

</details>


### [167] [Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion](https://arxiv.org/abs/2511.07377)
*June Moh Goo,Zichao Zeng,Jan Boehm*

Main category: cs.CV

TL;DR: FLASH是一个新颖的LiDAR超分辨率框架，通过双域处理（空间域和频域）结合频率感知窗口注意力和自适应多尺度融合，在KITTI数据集上实现了最先进的性能，同时保持单次推理效率，适合实时自动驾驶系统部署。


<details>
  <summary>Details</summary>
Motivation: 解决低成本低分辨率LiDAR传感器实现高质量3D感知的挑战，克服现有基于transformer的方法（如TULIP）仅限于空间域处理且感受野受限的问题。

Method: 提出FLASH框架，包含两个关键创新：1）频率感知窗口注意力，结合局部空间注意力和通过FFT的全局频域分析；2）自适应多尺度融合，用学习的位置特定特征聚合替换传统跳跃连接，并通过CBAM注意力增强动态特征选择。

Result: 在KITTI数据集上的广泛实验表明，FLASH在所有评估指标上都达到了最先进的性能，甚至超过了需要多次前向传播的不确定性增强基线方法。FLASH在保持单次推理效率的同时，性能优于采用蒙特卡洛Dropout的TULIP。

Conclusion: FLASH的双域方法通过架构设计有效处理不确定性，而非计算昂贵的随机推理，使其在实际自动驾驶系统中具有实用性。在所有距离范围内的一致优越性验证了该方法的有效性。

Abstract: LiDAR super-resolution addresses the challenge of achieving high-quality 3D
perception from cost-effective, low-resolution sensors. While recent
transformer-based approaches like TULIP show promise, they remain limited to
spatial-domain processing with restricted receptive fields. We introduce FLASH
(Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a
novel framework that overcomes these limitations through dual-domain
processing. FLASH integrates two key innovations: (i) Frequency-Aware Window
Attention that combines local spatial attention with global frequency-domain
analysis via FFT, capturing both fine-grained geometry and periodic scanning
patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that
replaces conventional skip connections with learned position-specific feature
aggregation, enhanced by CBAM attention for dynamic feature selection.
Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art
performance across all evaluation metrics, surpassing even uncertainty-enhanced
baselines that require multiple forward passes. Notably, FLASH outperforms
TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which
enables real-time deployment. The consistent superiority across all distance
ranges validates that our dual-domain approach effectively handles uncertainty
through architectural design rather than computationally expensive stochastic
inference, making it practical for autonomous systems.

</details>


### [168] [SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards](https://arxiv.org/abs/2511.07403)
*Hunar Batra,Haoqin Tu,Hardy Chen,Yuanze Lin,Cihang Xie,Ronald Clark*

Main category: cs.CV

TL;DR: SpatialThinker是一个3D感知的多模态大语言模型，通过强化学习整合结构化空间基础和多步推理，在空间理解和真实世界VQA基准上超越了监督微调和稀疏RL基线，甚至超过GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 现有的空间MLLMs依赖显式3D输入或特定架构修改，且受限于大规模数据集或稀疏监督，难以实现有效的空间理解。

Method: 提出SpatialThinker模型，通过构建任务相关对象和空间关系的场景图，利用密集空间奖励进行多步推理；包含数据合成管道生成STVQA-7K数据集，以及使用多目标密集空间奖励的在线强化学习。

Result: SpatialThinker-7B在空间理解基准上表现优异，相比稀疏RL基线几乎翻倍提升了基础模型的增益，超越了GPT-4o。

Conclusion: 结合空间监督和奖励对齐推理能够以有限数据实现稳健的3D空间理解，推动MLLMs向人类级视觉推理迈进。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress in
vision-language tasks, but they continue to struggle with spatial
understanding. Existing spatial MLLMs often rely on explicit 3D inputs or
architecture-specific modifications, and remain constrained by large-scale
datasets or sparse supervision. To address these limitations, we introduce
SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial
grounding with multi-step reasoning. The model simulates human-like spatial
perception by constructing a scene graph of task-relevant objects and spatial
relations, and reasoning towards an answer via dense spatial rewards.
SpatialThinker consists of two key contributions: (1) a data synthesis pipeline
that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL
with a multi-objective dense spatial reward enforcing spatial grounding.
SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline
on spatial understanding and real-world VQA benchmarks, nearly doubling the
base-model gain compared to sparse RL, and surpassing GPT-4o. These results
showcase the effectiveness of combining spatial supervision with reward-aligned
reasoning in enabling robust 3D spatial understanding with limited data and
advancing MLLMs towards human-level visual reasoning.

</details>


### [169] [DIMO: Diverse 3D Motion Generation for Arbitrary Objects](https://arxiv.org/abs/2511.07409)
*Linzhan Mou,Jiahui Lei,Chen Wang,Lingjie Liu,Kostas Daniilidis*

Main category: cs.CV

TL;DR: DIMO是一个从单张图像生成任意物体多样化3D运动的生成方法，利用训练好的视频模型提取通用运动模式并嵌入到共享低维潜在空间中，通过神经关键点轨迹驱动3D高斯建模几何和外观。


<details>
  <summary>Details</summary>
Motivation: 利用预训练视频模型的丰富先验知识，从单张图像生成多样化的3D运动，解决传统方法在运动多样性方面的限制。

Method: 首先生成具有多样化运动的多个视频，将每个运动嵌入到潜在向量中，训练共享运动解码器学习由神经关键点轨迹表示的运动分布，然后用3D高斯驱动关键点建模几何和外观。

Result: 能够在推理时通过单次前向传播即时采样多样化3D运动，支持3D运动插值和语言引导的运动生成等应用。

Conclusion: DIMO展示了从单张图像生成多样化3D运动的可行性，为3D内容创作提供了高效的新方法。

Abstract: We present DIMO, a generative approach capable of generating diverse 3D
motions for arbitrary objects from a single image. The core idea of our work is
to leverage the rich priors in well-trained video models to extract the common
motion patterns and then embed them into a shared low-dimensional latent space.
Specifically, we first generate multiple videos of the same object with diverse
motions. We then embed each motion into a latent vector and train a shared
motion decoder to learn the distribution of motions represented by a structured
and compact motion representation, i.e., neural key point trajectories. The
canonical 3D Gaussians are then driven by these key points and fused to model
the geometry and appearance. During inference time with learned latent space,
we can instantly sample diverse 3D motions in a single-forward pass and support
several interesting applications including 3D motion interpolation and
language-guided motion generation. Our project page is available at
https://linzhanm.github.io/dimo.

</details>


### [170] [TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for Embodied AI Research](https://arxiv.org/abs/2511.07412)
*Han Zhang,Yiqing Shen,Roger D. Soberanis-Mukul,Ankita Ghosh,Hao Ding,Lalithkumar Seenivasan,Jose L. Porras,Zhekai Mao,Chenjia Li,Wenjie Xiao,Lonny Yarmus,Angela Christine Argento,Masaru Ishii,Mathias Unberath*

Main category: cs.CV

TL;DR: TwinOR是一个构建手术室数字孪生的框架，通过多视角感知重建静态几何和动态运动，为具身AI研究提供安全可控的虚拟环境。


<details>
  <summary>Details</summary>
Motivation: 手术室的安全限制阻碍了具身AI的感知和交互，需要创建高保真、无风险的数字孪生环境来支持持续学习和评估。

Method: 从预扫描视频重建静态几何，通过多视角感知连续建模人和设备运动，将静态和动态组件融合到沉浸式3D环境中。

Result: 重建的手术室几何精度达到厘米级，能够模拟立体和单目传感器数据流，支持几何理解和视觉定位任务，性能接近真实室内数据集。

Conclusion: TwinOR建立了从真实到模拟的管道，能够安全、可扩展地开发和评估具身AI，加速从模拟到现实的部署。

Abstract: Developing embodied AI for intelligent surgical systems requires safe,
controllable environments for continual learning and evaluation. However,
safety regulations and operational constraints in operating rooms (ORs) limit
embodied agents from freely perceiving and interacting in realistic settings.
Digital twins provide high-fidelity, risk-free environments for exploration and
training. How we may create photorealistic and dynamic digital representations
of ORs that capture relevant spatial, visual, and behavioral complexity remains
unclear. We introduce TwinOR, a framework for constructing photorealistic,
dynamic digital twins of ORs for embodied AI research. The system reconstructs
static geometry from pre-scan videos and continuously models human and
equipment motion through multi-view perception of OR activities. The static and
dynamic components are fused into an immersive 3D environment that supports
controllable simulation and embodied exploration. The proposed framework
reconstructs complete OR geometry with centimeter level accuracy while
preserving dynamic interaction across surgical workflows, enabling realistic
renderings and a virtual playground for embodied AI systems. In our
experiments, TwinOR simulates stereo and monocular sensor streams for geometry
understanding and visual localization tasks. Models such as FoundationStereo
and ORB-SLAM3 on TwinOR-synthesized data achieve performance within their
reported accuracy on real indoor datasets, demonstrating that TwinOR provides
sensor-level realism sufficient for perception and localization challenges. By
establishing a real-to-sim pipeline for constructing dynamic, photorealistic
digital twins of OR environments, TwinOR enables the safe, scalable, and
data-efficient development and benchmarking of embodied AI, ultimately
accelerating the deployment of embodied AI from sim-to-real.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [171] [Emergency Response Measures for Catastrophic AI Risk](https://arxiv.org/abs/2511.05526)
*James Zhang,Miles Kodama,Zongze Wu,Michael Chen,Yue Zhu,Geng Hong*

Main category: cs.CY

TL;DR: 本文探讨如何将前沿安全政策(FSPs)模型应用于中国的四阶段应急响应框架，以解决先进人工智能的风险问题。


<details>
  <summary>Details</summary>
Motivation: 中国正在扩展其四阶段应急响应框架来应对先进AI风险，但预防和预警阶段的具体机制仍在开发中，需要寻找可行的实施方案。

Method: 分析国际AI安全实践中的前沿安全政策(FSPs)模型，该模型包含部署前危险能力评估和分层预规划安全措施。

Result: 发现FSPs模型与中国应急响应框架的主动预防阶段高度契合，表明该模型可以帮助在中国现有治理原则下实现AI应急准备。

Conclusion: FSPs模型可以作为中国AI应急响应框架预防和预警阶段的具体实施机制，符合中国的治理原则。

Abstract: Chinese authorities are extending the country's four-phase emergency response
framework (prevent, warn, respond, and recover) to address risks from advanced
artificial intelligence (AI). Concrete mechanisms for the proactive prevention
and warning phases, however, remain under development. This paper analyzes an
implementation model inspired by international AI safety practices: frontier
safety policies (FSPs). These policies feature pre-deployment evaluations for
dangerous capabilities and tiered, pre-planned safety measures. We observe
close alignment between FSPs and the proactive phases of China's emergency
response framework, suggesting that the FSP model could help operationalize AI
emergency preparedness in a manner consistent with China's established
governance principles.

</details>


### [172] [Using LLMs to support assessment of student work in higher education: a viva voce simulator](https://arxiv.org/abs/2511.05530)
*Ian M. Church,Lyndon Drake,Mark Harris*

Main category: cs.CY

TL;DR: 本文提出使用大语言模型来检测学生作业是否由LLM生成，通过开发一个口试模拟器来评估学生对其提交作品的理解程度。


<details>
  <summary>Details</summary>
Motivation: 应对学生使用LLM生成作业的挑战，特别是在需要长篇书面作业的学科中，需要新的评估方法来确保学术诚信。

Method: 开发了一个概念验证的口试模拟器，该工具接受学生提交的作业，生成交互式问题，并根据学生的回答判断作业是否可能为学生原创。

Result: 创建了一个交互式工具，能够模拟人类考官的问题，并通过学生回答形成对作业原创性的初步判断，为人类考官提供决策支持。

Conclusion: 该方法为检测LLM生成的学术作品提供了可行方案，但实际部署需要考虑理论和实践方面的关键问题。

Abstract: One of the emergent challenges of student work submitted for assessment is
the widespread use of large language models (LLMs) to support and even produce
written work. This particularly affects subjects where long-form written work
is a key part of assessment. We propose a novel approach to addressing this
challenge, using LLMs themselves to support the assessment process. We have
developed a proof-of-concept viva voce examination simulator, which accepts the
student's written submission as input, generates an interactive series of
questions from the LLM and answers from the student. The viva voce simulator is
an interactive tool which asks questions which a human examiner might plausibly
ask, and uses the student's answers to form a judgment about whether the
submitted piece of work is likely to be the student's own work. The interaction
transcript is provided to the human examiner to support their final judgment.
We suggest theoretical and practical points which are critical to real-world
deployment of such a tool.

</details>


### [173] [Deception Decoder: Proposing a Human-Focused Framework for Identifying AI-Generated Content on Social Media](https://arxiv.org/abs/2511.05555)
*C. Bowman Kerbage*

Main category: cs.CY

TL;DR: 本文提出了Deception Decoder框架，这是一个多模态、系统性和拓扑性的框架，旨在帮助普通用户识别AI生成的文本、图像和视频中的虚假信息。


<details>
  <summary>Details</summary>
Motivation: 生成式AI对公共领域信息完整性构成重大威胁，而现有研究主要关注自动化检测方法，存在误报、社会政治偏见和易被规避等问题。

Method: 通过现有模型的比较综合、GenAI视频内容分析以及小规模焦点小组讨论来开发和改进框架。

Result: 初步测试显示该框架有显著改进效果。

Conclusion: 虽然初步结果令人鼓舞，但需要进一步研究来验证其在不同用户群体中的普适性和长期有效性。

Abstract: Generative AI (GenAI) poses a substantial threat to the integrity of
information within the contemporary public sphere, which increasingly relies on
social media platforms as intermediaries for news consumption. At present, most
research efforts are directed toward automated and machine learning-based
detection methods, despite growing concerns regarding false positives, social
and political biases, and susceptibility to circumvention. This dissertation
instead adopts a human-centred approach. It proposes the Deception Decoder; a
multimodal, systematic, and topological framework designed to support general
users in identifying AI-generated misinformation and disinformation across
text, image, and video. The framework was developed through a comparative
synthesis of existing models, supplemented by a content analysis of
GenAI-video, and refined through a small-scale focus group session. While
initial testing indicates promising improvements, further research is required
to confirm its generalisability across user groups, and sustained effectiveness
over time.

</details>


### [174] [AgriTrust: a Federated Semantic Governance Framework for Trusted Agricultural Data Sharing](https://arxiv.org/abs/2511.05572)
*Ivan Bergier*

Main category: cs.CY

TL;DR: AgriTrust是一个联邦语义治理框架，旨在解决农业数据信任和互操作性不足的问题，通过多利益相关方治理模型和语义数字层实现数据主权、透明数据合同、公平价值共享和监管合规。


<details>
  <summary>Details</summary>
Motivation: 农业数据（AgData）的潜力因"农业数据悖论"而受限，即数据被锁定在孤岛中，缺乏信任和互操作性，尽管其价值已被认可。

Method: AgriTrust整合了多利益相关方治理模型与语义数字层，通过AgriTrust核心本体论（OWL本体）提供共享词汇表，支持代币化、可追溯性和认证，并采用区块链无关的多提供商架构。

Result: 在巴西三个关键供应链（咖啡、大豆、牛肉）的案例研究中，AgriTrust成功实现了可验证的来源追溯、自动化合规性以及为数据生产者创造新收入流。

Conclusion: AgriTrust为更透明、高效和公平的农业数据经济提供了基础蓝图，将数据共享从基于信任的困境转变为受治理的自动化操作。

Abstract: The potential of agricultural data (AgData) to drive efficiency and
sustainability is stifled by the "AgData Paradox": a pervasive lack of trust
and interoperability that locks data in silos, despite its recognized value.
This paper introduces AgriTrust, a federated semantic governance framework
designed to resolve this paradox. AgriTrust integrates a multi-stakeholder
governance model, built on pillars of Data Sovereignty, Transparent Data
Contracts, Equitable Value Sharing, and Regulatory Compliance, with a semantic
digital layer. This layer is realized through the AgriTrust Core Ontology, a
formal OWL ontology that provides a shared vocabulary for tokenization,
traceability, and certification, enabling true semantic interoperability across
independent platforms. A key innovation is a blockchain-agnostic,
multi-provider architecture that prevents vendor lock-in. The framework's
viability is demonstrated through case studies across three critical Brazilian
supply chains: coffee (for EUDR compliance), soy (for mass balance), and beef
(for animal tracking). The results show that AgriTrust successfully enables
verifiable provenance, automates compliance, and creates new revenue streams
for data producers, thereby transforming data sharing from a trust-based
dilemma into a governed, automated operation. This work provides a foundational
blueprint for a more transparent, efficient, and equitable agricultural data
economy.

</details>


### [175] [Who Evaluates AI's Social Impacts? Mapping Coverage and Gaps in First and Third Party Evaluations](https://arxiv.org/abs/2511.05613)
*Anka Reuel,Avijit Ghosh,Jenny Chim,Andrew Tran,Yanan Long,Jennifer Mickel,Usman Gohar,Srishti Yadav,Pawan Sasanka Ammanamanchi,Mowafak Allaham,Hossein A. Rahmani,Mubashara Akhtar,Felix Friedrich,Robert Scholz,Michael Alexander Riegler,Jan Batzner,Eliya Habba,Arushi Saxena,Anastassia Kornilova,Kevin Wei,Prajna Soni,Yohan Mathew,Kevin Klyman,Jeba Sania,Subramanyam Sahoo,Olivia Beyer Bruvik,Pouya Sadeghi,Sujata Goswami,Angelina Wang,Yacine Jernite,Zeerak Talat,Stella Biderman,Mykel Kochenderfer,Sanmi Koyejo,Irene Solaiman*

Main category: cs.CY

TL;DR: 该研究首次全面分析了AI模型开发者的社会影响评估报告，发现第一方报告稀疏且肤浅，而第三方评估提供更广泛的偏见、有害内容和性能差异覆盖，但当前评估实践在评估AI社会影响方面存在重大空白。


<details>
  <summary>Details</summary>
Motivation: 基础模型在高风险AI系统中日益重要，治理框架依赖评估来评估其风险和能力，但社会影响评估在AI生态系统中仍然不均衡。

Method: 研究分析了186份第一方发布报告和183份发布后评估来源，并辅以模型开发者访谈进行定量分析。

Result: 发现评估工作存在明显分工：第一方报告稀疏且肤浅，在环境影响和偏见等关键领域有所下降；第三方评估者提供更广泛和严谨的偏见、有害内容和性能差异覆盖。

Conclusion: 当前评估实践在评估AI社会影响方面存在重大空白，迫切需要促进开发者透明度、加强独立评估生态系统以及创建共享基础设施的政策。

Abstract: Foundation models are increasingly central to high-stakes AI systems, and
governance frameworks now depend on evaluations to assess their risks and
capabilities. Although general capability evaluations are widespread, social
impact assessments covering bias, fairness, privacy, environmental costs, and
labor practices remain uneven across the AI ecosystem. To characterize this
landscape, we conduct the first comprehensive analysis of both first-party and
third-party social impact evaluation reporting across a wide range of model
developers. Our study examines 186 first-party release reports and 183
post-release evaluation sources, and complements this quantitative analysis
with interviews of model developers. We find a clear division of evaluation
labor: first-party reporting is sparse, often superficial, and has declined
over time in key areas such as environmental impact and bias, while third-party
evaluators including academic researchers, nonprofits, and independent
organizations provide broader and more rigorous coverage of bias, harmful
content, and performance disparities. However, this complementarity has limits.
Only model developers can authoritatively report on data provenance, content
moderation labor, financial costs, and training infrastructure, yet interviews
reveal that these disclosures are often deprioritized unless tied to product
adoption or regulatory compliance. Our findings indicate that current
evaluation practices leave major gaps in assessing AI's societal impacts,
highlighting the urgent need for policies that promote developer transparency,
strengthen independent evaluation ecosystems, and create shared infrastructure
to aggregate and compare third-party evaluations in a consistent and accessible
way.

</details>


### [176] [Report from Workshop on Dialogue alongside Artificial Intelligence](https://arxiv.org/abs/2511.05625)
*Thomas J McKenna,Ingvill Rasmussen,Sten Ludvigsen,Avivit Arvatz,Christa Asterhan,Gaowei Chen,Julie Cohen,Michele Flammia,Dongkeun Han,Emma Hayward,Heather Hill,Yifat Kolikant,Helen Lehndorf,Kexin Li,Lindsay Clare Matsumura,Henrik Tjønn,Pengjin Wang,Rupert Wegerif*

Main category: cs.CY

TL;DR: 本文探讨了AI与教育对话的交叉点，分析了AI在教育中的真正价值、促进对话式教学的潜力，以及AI可能取代人类教育工作的风险。


<details>
  <summary>Details</summary>
Motivation: 随着AI在教育领域的快速发展，需要平衡其潜在益处与风险，确保AI能够真正促进教育对话和深度学习，而不是削弱人类能动性或加剧不平等。

Method: 通过国际研讨会汇集来自11个国家的19位顶尖研究人员，围绕三个关键问题进行为期两天的演讲和结构化对话。

Result: 研讨会深入探讨了AI在教育中的适用场景、促进对话式教学的条件，以及AI可能对人类教育工作产生的替代效应。

Conclusion: 需要在AI发展和教育实践之间建立平衡，确保AI技术能够真正服务于教育对话和深度学习的目标，同时防范其潜在风险。

Abstract: Educational dialogue -the collaborative exchange of ideas through talk- is
widely recognized as a catalyst for deeper learning and critical thinking in
and across contexts. At the same time, artificial intelligence (AI) has rapidly
emerged as a powerful force in education, with the potential to address major
challenges, personalize learning, and innovate teaching practices. However,
these advances come with significant risks: rapid AI development can undermine
human agency, exacerbate inequities, and outpace our capacity to guide its use
with sound policy. Human learning presupposes cognitive efforts and social
interaction (dialogues). In response to this evolving landscape, an
international workshop titled "Educational Dialogue: Moving Thinking Forward"
convened 19 leading researchers from 11 countries in Cambridge (September 1-3,
2025) to examine the intersection of AI and educational dialogue. This
AI-focused strand of the workshop centered on three critical questions: (1)
When is AI truly useful in education, and when might it merely replace human
effort at the expense of learning? (2) Under what conditions can AI use lead to
better dialogic teaching and learning? (3) Does the AI-human partnership risk
outpacing and displacing human educational work, and what are the implications?
These questions framed two days of presentations and structured dialogue among
participants.

</details>


### [177] [Assessing the Reliability of Large Language Models in the Bengali Legal Context: A Comparative Evaluation Using LLM-as-Judge and Legal Experts](https://arxiv.org/abs/2511.05627)
*Sabik Aftahee,A. F. M. Farhad,Arpita Mallik,Ratnajit Dhar,Jawadul Karim,Nahiyan Bin Noor,Ishmam Ahmed Solaiman*

Main category: cs.CY

TL;DR: 本研究评估了四种先进AI模型在孟加拉国法律咨询中的表现，发现虽然能生成高质量法律建议，但也存在危险错误信息，需要专家验证才能安全部署。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国法律帮助获取困难，存在高费用、复杂法律语言、律师短缺等问题，希望通过AI模型提供快速廉价的法律援助。

Method: 收集250个真实法律问题，用四种AI模型生成回答，采用双重评估框架：先进LLM模型和三名持证法律专家按照事实准确性、法律适当性、完整性和清晰度四个维度评估，并应用BLEU分数等自动评估指标。

Result: AI模型经常生成高质量、结构良好的法律回答，但也产生危险错误信息，包括捏造案例引用、错误法律程序和潜在有害建议。

Conclusion: 在AI系统安全部署用于孟加拉国法律咨询之前，迫切需要严格的专家验证和全面的安全措施。

Abstract: Accessing legal help in Bangladesh is hard. People face high fees, complex
legal language, a shortage of lawyers, and millions of unresolved court cases.
Generative AI models like OpenAI GPT-4.1 Mini, Gemini 2.0 Flash, Meta Llama 3
70B, and DeepSeek R1 could potentially democratize legal assistance by
providing quick and affordable legal advice. In this study, we collected 250
authentic legal questions from the Facebook group "Know Your Rights," where
verified legal experts regularly provide authoritative answers. These questions
were subsequently submitted to four four advanced AI models and responses were
generated using a consistent, standardized prompt. A comprehensive dual
evaluation framework was employed, in which a state-of-the-art LLM model served
as a judge, assessing each AI-generated response across four critical
dimensions: factual accuracy, legal appropriateness, completeness, and clarity.
Following this, the same set of questions was evaluated by three licensed
Bangladeshi legal professionals according to the same criteria. In addition,
automated evaluation metrics, including BLEU scores, were applied to assess
response similarity. Our findings reveal a complex landscape where AI models
frequently generate high-quality, well-structured legal responses but also
produce dangerous misinformation, including fabricated case citations,
incorrect legal procedures, and potentially harmful advice. These results
underscore the critical need for rigorous expert validation and comprehensive
safeguards before AI systems can be safely deployed for legal consultation in
Bangladesh.

</details>


### [178] [Preserving security in a world with powerful AI Considerations for the future Defense Architecture](https://arxiv.org/abs/2511.05714)
*Nicholas Generous,Brian Cook,Jason Pruet*

Main category: cs.CY

TL;DR: 当前美国国防架构基于AI能力出现前的假设设计，无法单独应对AI赋能威胁，需要结合传统系统加固和全新防御架构元素。


<details>
  <summary>Details</summary>
Motivation: AI技术的进步威胁到当前国防架构的基础假设，现有防御计划无法有效保护国家安全免受新兴AI威胁。

Method: 提出将能源部国家核安全管理局国家实验室进行适应性调整，确保在强大AI时代的敏捷性和韧性。

Result: 识别出现有防御架构的局限性，并提出了应对AI威胁的解决方案框架。

Conclusion: 需要在传统系统加固的基础上，构建全新的防御架构元素，并立即调整国家实验室以适应AI时代的挑战。

Abstract: Advances in AI threaten to invalidate assumptions underpinning today's
defense architecture. We argue that the current U.S. defense program of record,
designed in an era before capable machine intelligence, cannot by itself
preserve national security against rapidly emerging AI enabled threats.
Instead, shoring up legacy systems must be coupled with entirely new elements
of a defense architecture. We outline immediate steps to adapt the Department
of Energy National Nuclear Security Administration National Laboratories to
ensure agility and resilience in an era of powerful AI.

</details>


### [179] [Assessing Problem Decomposition in CS1 for the GenAI Era](https://arxiv.org/abs/2511.05764)
*Samvrit Srinath,Annapurna Vadaparty,David H. Smith IV,Leo Porter,Daniel Zingaro*

Main category: cs.CY

TL;DR: 本文开发了评估问题分解能力的评估工具，包括使用问题套件和分解图绘制，以帮助初学者程序员掌握这一关键技能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的兴起，学生能够生成大量代码，但问题分解这一关键技能在入门计算机科学课程中往往被忽视，需要开发有效的教学和评估方法。

Method: 开发问题套件（Question Suites）来提供必要的上下文，并使用开放式分解图绘制作为评估形式，通过多次迭代改进评估材料。

Result: 创建了专门针对问题分解技能的评估工具，解决了长上下文带来的挑战，并获得了学生对这种评估方式的反馈。

Conclusion: 问题分解是初学者程序员的关键技能，本文提供的评估材料和反思可为教育工作者教授这一技能提供参考。

Abstract: Problem decomposition--the ability to break down a large task into smaller,
well-defined components--is a critical skill for effectively designing and
creating large programs, but it is often not included in introductory computer
science curricula. With the rise of generative AI (GenAI), students even at the
introductory level are able to generate large quantities of code, and it is
becoming increasingly important to equip them with the ability to decompose
problems. There is not yet a consensus among educators on how to best teach and
assess the skill of decomposition, particularly in introductory computing. This
practitioner paper details the development of questions to assess the skill of
problem decomposition, and impressions about how these questions were received
by students. A challenge unique to problem decomposition questions is their
necessarily lengthy context, and we detail our approach to addressing this
problem using Question Suites: scaffolded sequences of questions that help
students understand a question's context before attempting to decompose it. We
then describe the use of open-ended drawing of decomposition diagrams as
another form of assessment. We outline the learning objectives used to design
our questions and describe how we addressed challenges encountered in early
iterations. We present our decomposition assessment materials and reflections
on them for educators who wish to teach problem decomposition to beginner
programmers.

</details>


### [180] [(Working Paper) Good Faith Design: Religion as a Resource for Technologists](https://arxiv.org/abs/2511.05819)
*Nina Lutz,Benjamin Olsen,Weishung Liu,E. Glen Weyl*

Main category: cs.CY

TL;DR: 该研究通过访谈48位来自11种信仰的宗教人士和专家，探讨宗教与技术的关系，揭示了技术中的世俗偏见对宗教用户的伤害，并提出了六个设计价值观来指导技术设计。


<details>
  <summary>Details</summary>
Motivation: HCI领域对宗教的研究不足，宗教与技术社区之间存在价值观和实践的误解，需要实证研究来弥合这一鸿沟。

Method: 对48位来自11种信仰的宗教人士和专家进行访谈研究，记录他们如何体验、理解和想象技术。

Result: 发现宗教利益相关者发现技术及其设计者中存在非中立的世俗嵌入，这些嵌入对宗教和非宗教用户造成意外伤害；揭示了用户如何通过宗教化的心智模型导航技术宗教实践及其对技术的期望。

Conclusion: 提炼出六个设计价值观——惊奇、谦逊、空间、具身性、社区和永恒——来指导技术人员在设计全面用户时将宗教视为有效的社会文化资源，并提出了未来研究方向。

Abstract: Previous work has found a lack of research in HCI on religion, partly driven
by misunderstandings of values and practices between religious and technical
communities. To bridge this divide in an empirically rigorous way, we conducted
an interview study with 48 religious people and/or experts from 11 faiths, and
we document how religious people experience, understand, and imagine
technologies. We show that religious stakeholders find non-neutral secular
embeddings in technologies and the firms and people that design them, and how
these manifest in unintended harms for religious and nonreligious users. Our
findings reveal how users navigate technoreligious practices with religiously
informed mental models and what they desire from technologies. Informed by
this, we distill six design values -- wonder, humility, space, embodiedness,
community, and eternity -- to guide technologists in considering and leveraging
religion as an additional, valid sociocultural resource when designing for a
holistic user. We further spell out directions for future research.

</details>


### [181] [The Imperfect Learner: Incorporating Developmental Trajectories in Memory-based Student Simulation](https://arxiv.org/abs/2511.05903)
*Zhengyuan Liu,Stella Xin Yin,Bryan Chen Zhengyu Tan,Roy Ka-Wei Lee,Guimei Liu,Dion Hoe-Lian Goh,Wenya Wang,Nancy F. Chen*

Main category: cs.CY

TL;DR: 本文提出了一个基于记忆的学生模拟框架，通过分层记忆机制和结构化知识表示来模拟学生的渐进式知识构建过程，并整合元认知过程和个性特征来丰富学习者画像。


<details>
  <summary>Details</summary>
Motivation: 当前教育应用中的学生模拟存在显著局限性，主要关注单一学习体验，未能考虑学生渐进的知识构建和技能发展过程。大语言模型倾向于产生直接准确回答，难以体现真实学习者的不完整理解和发育约束。

Method: 引入基于记忆的学生模拟框架，采用分层记忆机制和结构化知识表示来捕捉发展轨迹，整合元认知过程和个性特征，通过动态巩固认知发展和个人学习特征来丰富学习者画像。

Result: 实验结果表明，该方法能有效反映知识发展的渐进性质和学生面临的典型困难，提供了更准确的学习过程表示。

Conclusion: 该框架能够更准确地模拟真实学习过程，为开发和教育评估提供了更有效的学生模拟工具。

Abstract: User simulation is important for developing and evaluating human-centered AI,
yet current student simulation in educational applications has significant
limitations. Existing approaches focus on single learning experiences and do
not account for students' gradual knowledge construction and evolving skill
sets. Moreover, large language models are optimized to produce direct and
accurate responses, making it challenging to represent the incomplete
understanding and developmental constraints that characterize real learners. In
this paper, we introduce a novel framework for memory-based student simulation
that incorporates developmental trajectories through a hierarchical memory
mechanism with structured knowledge representation. The framework also
integrates metacognitive processes and personality traits to enrich the
individual learner profiling, through dynamical consolidation of both cognitive
development and personal learning characteristics. In practice, we implement a
curriculum-aligned simulator grounded on the Next Generation Science Standards.
Experimental results show that our approach can effectively reflect the gradual
nature of knowledge development and the characteristic difficulties students
face, providing a more accurate representation of learning processes.

</details>


### [182] [Designing Incident Reporting Systems for Harms from General-Purpose AI](https://arxiv.org/abs/2511.05914)
*Kevin Wei,Lennart Heim*

Main category: cs.CY

TL;DR: 本文提出了一个AI事件报告系统的概念框架和制度设计考虑，通过文献综述和案例研究分析了七个关键维度的设计要素，为研究人员和政策制定者提供AI事件报告系统的设计指导。


<details>
  <summary>Details</summary>
Motivation: 随着通用AI系统的广泛采用，其引发的现实危害和潜在危险事件日益增多，需要建立有效的事件报告系统来收集安全相关事件信息，预防更严重的危害发生。

Method: 通过文献综述构建了包含七个维度的AI事件报告系统制度设计框架，并分析了九个安全关键行业的案例研究，提取适用于美国AI事件报告的设计考虑因素。

Result: 开发了一个包含政策目标、报告主体、事件类型、风险实现程度、报告执行、匿名性和报告后行动七个维度的综合框架，识别了监管与非监管机构系统的差异、未遂事件报告、强制报告阈值与自愿报告渠道等关键设计要素。

Conclusion: 为AI事件报告系统的制度设计提供了系统性的框架和具体设计考虑，帮助政策制定者根据具体情境选择合适的设计方案，促进AI安全学习与信息共享。

Abstract: We introduce a conceptual framework and provide considerations for the
institutional design of AI incident reporting systems, i.e., processes for
collecting information about safety- and rights-related events caused by
general-purpose AI. As general-purpose AI systems are increasingly adopted,
they are causing more real-world harms and displaying the potential to cause
significantly more dangerous incidents - events that did or could have caused
harm to individuals, property, or the environment. Through a literature review,
we develop a framework for understanding the institutional design of AI
incident reporting systems, which includes seven dimensions: policy goal,
actors submitting and receiving reports, type of incidents reported, level of
risk materialization, enforcement of reporting, anonymity of reporters, and
post-reporting actions. We then examine nine case studies of incident reporting
in safety-critical industries to extract design considerations for AI incident
reporting in the United States. We discuss, among other factors, differences in
systems operated by regulatory vs. non-regulatory government agencies, near
miss reporting, the roles of mandatory reporting thresholds and voluntary
reporting channels, how to enable safety learning after reporting, sharing
incident information, and clarifying legal frameworks for reporting. Our aim is
to inform researchers and policymakers about when particular design choices
might be more or less appropriate for AI incident reporting.

</details>


### [183] [Artificial intelligence and the Gulf Cooperation Council workforce adapting to the future of work](https://arxiv.org/abs/2511.05927)
*Mohammad Rashed Albous,Melodena Stephens,Odeh Rashed Al-Jayyousi*

Main category: cs.CY

TL;DR: 本研究基于社会技术系统理论，通过混合方法评估海湾合作委员会国家在AI投资与技能、激励、治理建设之间的匹配度，发现监管一致性比财政能力更能影响AI发展成果，并识别出可能导致劳动力市场分化的双轨人才系统。


<details>
  <summary>Details</summary>
Motivation: 评估海湾合作委员会国家在AI基础设施投资与技能、激励、治理建设之间的匹配程度，以了解这些石油资源丰富、国家主导经济体在AI发展中的社会技术系统协调状况。

Method: 采用混合方法：分析6个国家AI战略的TF-IDF分析、47个公开AI倡议清单、MBZUAI和SDAIA学院配对案例研究，以及连接石油收入与监管一致性的情景矩阵。

Result: 72%的倡议(34/47)展现出社会技术联合设计；情景分析表明监管趋同比财政能力更能约束结果；识别出研究精英与快速培训从业者的双轨人才系统风险。

Conclusion: 研究扩展了社会技术系统理论在石油丰富、国家主导经济体中的应用，为纵向耦合指标、协调民族志和基于结果的绩效指标设定了研究议程。

Abstract: The rapid expansion of artificial intelligence (AI) in the Gulf Cooperation
Council (GCC) raises a central question: are investments in compute
infrastructure matched by an equally robust build-out of skills, incentives,
and governance? Grounded in socio-technical systems (STS) theory, this
mixed-methods study audits workforce preparedness across Kingdom of Saudi
Arabia (KSA), the United Arab Emirates (UAE), Qatar, Kuwait, Bahrain, and Oman.
We combine term frequency--inverse document frequency (TF--IDF) analysis of six
national AI strategies (NASs), an inventory of 47 publicly disclosed AI
initiatives (January 2017--April 2025), paired case studies, the Mohamed bin
Zayed University of Artificial Intelligence (MBZUAI) and the Saudi Data &
Artificial Intelligence Authority (SDAIA) Academy, and a scenario matrix
linking oil-revenue slack (technical capacity) to regulatory coherence (social
alignment). Across the corpus, 34/47 initiatives (0.72; 95% Wilson CI
0.58--0.83) exhibit joint social--technical design; country-level indices span
0.57--0.90 (small n; intervals overlap). Scenario results suggest that, under
our modeled conditions, regulatory convergence plausibly binds outcomes more
than fiscal capacity: fragmented rules can offset high oil revenues, while
harmonized standards help preserve progress under austerity. We also identify
an emerging two-track talent system, research elites versus rapidly trained
practitioners, that risks labor-market bifurcation without bridging mechanisms.
By extending STS inquiry to oil-rich, state-led economies, the study refines
theory and sets a research agenda focused on longitudinal coupling metrics,
ethnographies of coordination, and outcome-based performance indicators.

</details>


### [184] [The Future of AI in the GCC Post-NPM Landscape: A Comparative Analysis of Kuwait and the UAE](https://arxiv.org/abs/2511.05932)
*Mohammad Rashed Albous,Bedour Alboloushi,Arnaud Lacheret*

Main category: cs.CY

TL;DR: 该研究比较了阿联酋和科威特在人工智能应用方面的制度差异，发现垂直规则一致性而非财富决定了AI的公共价值产出。阿联酋通过集中权威、可信制裁等机制成功扩展AI应用，而科威特因分散的否决权等限制使AI项目停留在试点阶段。


<details>
  <summary>Details</summary>
Motivation: 填补海湾合作委员会国家如何将AI雄心转化为后新公共管理成果的研究空白，因为现有研究主要关注西方民主国家。

Method: 基于奥斯特罗姆的制度分析与发展框架，采用最相似/最不同系统设计，结合62份公共文件、嵌入式案例研究（智能迪拜和MBZUAI）和39次官员访谈，使用双重编码和过程追踪方法。

Result: 识别出导致不同发展轨迹的四种强化机制：阿联酋的集中权威、可信制裁等机制成功将试点扩展为数百项服务并产生可观节约；科威特因分散否决权等限制使AI项目停留在试点阶段。

Conclusion: 垂直规则一致性而非财富决定AI的公共价值产出，效率指标只有在有可执行保障时才服务于社会目标。未来研究应追踪规则扩散、开发混合合法性-效率记分卡，并考察叙事框架如何影响公民对数据共享的同意。

Abstract: Comparative evidence on how Gulf Cooperation Council (GCC) states turn
artificial intelligence (AI) ambitions into post--New Public Management
(post-NPM) outcomes is scarce because most studies examine Western democracies.
We analyze constitutional, collective-choice, and operational rules shaping AI
uptake in two contrasting GCC members, the United Arab Emirates (UAE) and
Kuwait, and whether they foster citizen centricity, collaborative governance,
and public value creation. Anchored in Ostrom's Institutional Analysis and
Development framework, the study combines a most similar/most different systems
design with multiple sources: 62 public documents from 2018--2025, embedded UAE
cases (Smart Dubai and MBZUAI), and 39 interviews with officials conducted Aug
2024--May 2025. Dual coding and process tracing connect rule configurations to
AI performance. Cross-case analysis identifies four reinforcing mechanisms
behind divergent trajectories. In the UAE, concentrated authority, credible
sanctions, pro-innovation narratives, and flexible reinvestment rules scale
pilots into hundreds of services and sizable recycled savings. In Kuwait,
dispersed veto points, exhortative sanctions, cautious discourse, and lapsed AI
budgets confine initiatives to pilot mode despite equivalent fiscal resources.
The findings refine institutional theory by showing that vertical rule
coherence, not wealth, determines AI's public-value yield, and temper post-NPM
optimism by revealing that efficiency metrics serve societal goals only when
backed by enforceable safeguards. To curb ethics washing and test
transferability beyond the GCC, future work should track rule diffusion over
time, develop blended legitimacy--efficiency scorecards, and examine how
narrative framing shapes citizen consent for data sharing.

</details>


### [185] [Who Gets Heard? Rethinking Fairness in AI for Music Systems](https://arxiv.org/abs/2511.05953)
*Atharva Mehta,Shivam Chauhan,Megha Sharma,Gus Xia,Kaustuv Kanti Ganguli,Nishanth Chandran,Zeerak Talat,Monojit Choudhury*

Main category: cs.CY

TL;DR: 本文关注音乐AI系统中的文化和流派偏见问题，特别是对全球南方边缘化传统的误表示，提出了数据集、模型和界面层面的改进建议。


<details>
  <summary>Details</summary>
Motivation: 音乐AI系统存在文化和流派偏见，这些偏见会影响创作者、发行商和听众，可能误表示边缘化传统（特别是全球南方），产生不真实的输出，降低创作者对这些系统的信任，强化偏见、限制创造力并导致文化抹除。

Method: 通过分析音乐AI系统中的偏见问题，提出在数据集、模型和界面三个层面的具体改进建议。

Result: 识别出音乐AI系统存在文化和流派偏见，这些偏见可能导致对边缘化传统的误表示，产生不真实的音乐输出，影响创作者信任并强化现有偏见。

Conclusion: 需要从数据集、模型和界面三个层面采取措施，解决音乐AI系统中的文化和流派偏见问题，防止对边缘化传统的误表示和文化抹除。

Abstract: In recent years, the music research community has examined risks of AI models
for music, with generative AI models in particular, raised concerns about
copyright, deepfakes, and transparency. In our work, we raise concerns about
cultural and genre biases in AI for music systems (music-AI systems) which
affect stakeholders including creators, distributors, and listeners shaping
representation in AI for music. These biases can misrepresent marginalized
traditions, especially from the Global South, producing inauthentic outputs
(e.g., distorted ragas) that reduces creators' trust on these systems. Such
harms risk reinforcing biases, limiting creativity, and contributing to
cultural erasure. To address this, we offer recommendations at dataset, model
and interface level in music-AI systems.

</details>


### [186] [Simulating Students with Large Language Models: A Review of Architecture, Mechanisms, and Role Modelling in Education with Generative AI](https://arxiv.org/abs/2511.06078)
*Luis Marquez-Carpintero,Alberto Lopez-Sellers,Miguel Cazorla*

Main category: cs.CY

TL;DR: 本文对使用大型语言模型（LLMs）模拟学生行为的研究进行了主题综述，探讨了LLM在教育环境中模拟学习者原型、响应教学输入和参与多智能体课堂互动的能力。


<details>
  <summary>Details</summary>
Motivation: 模拟学生为评估教学方法和建模多样化学习者提供了有价值的框架，而LLMs因其语言真实性和行为适应性成为特别有前景的模拟工具。

Method: 通过对使用LLMs模拟学生行为的实证和方法论研究进行主题综述，综合当前证据并分析技术方法。

Result: LLMs在自然语言生成和情境灵活性方面优于基于规则的系统，能够有效模拟学习者原型并参与教学对话，但存在算法偏见、评估可靠性等持续关注的问题。

Conclusion: 该综述识别了现有技术和方法论差距，并为将生成式AI整合到自适应学习系统和教学设计中提出了未来研究方向。

Abstract: Simulated Students offer a valuable methodological framework for evaluating
pedagogical approaches and modelling diverse learner profiles, tasks which are
otherwise challenging to undertake systematically in real-world settings.
Recent research has increasingly focused on developing such simulated agents to
capture a range of learning styles, cognitive development pathways, and social
behaviours. Among contemporary simulation techniques, the integration of large
language models (LLMs) into educational research has emerged as a particularly
versatile and scalable paradigm. LLMs afford a high degree of linguistic
realism and behavioural adaptability, enabling agents to approximate cognitive
processes and engage in contextually appropriate pedagogical dialogues. This
paper presents a thematic review of empirical and methodological studies
utilising LLMs to simulate student behaviour across educational environments.
We synthesise current evidence on the capacity of LLM-based agents to emulate
learner archetypes, respond to instructional inputs, and interact within
multi-agent classroom scenarios. Furthermore, we examine the implications of
such systems for curriculum development, instructional evaluation, and teacher
training. While LLMs surpass rule-based systems in natural language generation
and situational flexibility, ongoing concerns persist regarding algorithmic
bias, evaluation reliability, and alignment with educational objectives. The
review identifies existing technological and methodological gaps and proposes
future research directions for integrating generative AI into adaptive learning
systems and instructional design.

</details>


### [187] [Large Language Models Develop Novel Social Biases Through Adaptive Exploration](https://arxiv.org/abs/2511.06148)
*Addison J. Wu,Ryan Liu,Xuechunzi Bai,Thomas L. Griffiths*

Main category: cs.CY

TL;DR: 研究发现大型语言模型即使在没有真实差异的人工人口群体中也会自发产生新的社会偏见，导致任务分配高度分层，且这种偏见在更新更大的模型中更为严重。通过探索-利用权衡机制，论文提出了针对模型输入、问题结构和明确引导的干预措施，发现明确激励探索能最有效地减少分层。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型被集成到能够做出实际决策的框架中，确保其无偏性变得日益重要。现有方法仅从模型中移除已有偏见是不够的，需要研究模型是否会产生新的偏见。

Method: 使用心理学文献中的范式，研究LLM对人工人口群体产生偏见的情况。通过探索-利用权衡机制分析偏见产生原因，并测试针对模型输入、问题结构和明确引导的干预措施。

Result: LLM会自发产生关于人工人口群体的新社会偏见，导致高度分层的任务分配，比人类参与者的分配更不公平。新模型和更大模型的偏见更严重。明确激励探索是最有效的干预措施。

Conclusion: LLM不仅仅是人类社会偏见的被动反映者，还能从经验中主动创造新的偏见，这对这些系统如何随时间塑造社会提出了紧迫问题。

Abstract: As large language models (LLMs) are adopted into frameworks that grant them
the capacity to make real decisions, it is increasingly important to ensure
that they are unbiased. In this paper, we argue that the predominant approach
of simply removing existing biases from models is not enough. Using a paradigm
from the psychology literature, we demonstrate that LLMs can spontaneously
develop novel social biases about artificial demographic groups even when no
inherent differences exist. These biases result in highly stratified task
allocations, which are less fair than assignments by human participants and are
exacerbated by newer and larger models. In social science, emergent biases like
these have been shown to result from exploration-exploitation trade-offs, where
the decision-maker explores too little, allowing early observations to strongly
influence impressions about entire demographic groups. To alleviate this
effect, we examine a series of interventions targeting model inputs, problem
structure, and explicit steering. We find that explicitly incentivizing
exploration most robustly reduces stratification, highlighting the need for
better multifaceted objectives to mitigate bias. These results reveal that LLMs
are not merely passive mirrors of human social biases, but can actively create
new ones from experience, raising urgent questions about how these systems will
shape societies over time.

</details>


### [188] [Prediction-based evaluation of back-four defense with spatial control in soccer](https://arxiv.org/abs/2511.06191)
*Soujanya Dash,Kenjiro Ide,Rikuhei Umemoto,Kai Amino,Keisuke Fujii*

Main category: cs.CY

TL;DR: 本研究提出了可解释的时空指标来评估足球防守转换中四后卫防线的有效性，通过分析西甲2023-24赛季数据发现相对防线高度与防守成功关联最强，并揭示了巴塞罗那和皇家马德里不同的防守行为模式。


<details>
  <summary>Details</summary>
Motivation: 足球防守组织在负面转换时至关重要，但四后卫防线的集体协调性难以量化，需要开发可解释的指标来评估防守转换效果。

Method: 使用同步追踪和事件数据，分析2413个防守序列，引入空间控制、拉伸指数、压力指数和防线高度等指标，采用双向ANOVA和XGBoost预测建模。

Result: 相对防线高度与防守成功关联最强，XGBoost模型在巴塞罗那和皇家马德里的ROC AUC分别达到0.724和0.698，空间得分和相对防线高度是主要预测因子。

Conclusion: 可解释的空间指标具有战术和预测价值，能够量化集体防守表现，揭示了不同球队的特定防守行为模式。

Abstract: Defensive organization is critical in soccer, particularly during negative
transitions when teams are most vulnerable. The back-four defensive line plays
a decisive role in preventing goal-scoring opportunities, yet its collective
coordination remains difficult to quantify. This study introduces interpretable
spatio-temporal indicators namely, space control, stretch index, pressure
index, and defensive line height (absolute and relative) to evaluate the
effectiveness of the back-four during defensive transitions. Using synchronized
tracking and event data from the 2023-24 LaLiga season, 2,413 defensive
sequences were analyzed following possession losses by FC Barcelona and Real
Madrid CF. Two-way ANOVA revealed significant effects of team, outcome, and
their interaction for key indicators, with relative line height showing the
strongest association with defensive success. Predictive modeling using XGBoost
achieved the highest discriminative performance (ROC AUC: 0.724 for Barcelona,
0.698 for Real Madrid), identifying space score and relative line height as
dominant predictors. Comparative analysis revealed distinct team-specific
defensive behaviors: Barcelona's success was characterized by higher spatial
control and compact line coordination, whereas Real Madrid exhibited more
adaptive but less consistent defensive structures. These findings demonstrate
the tactical and predictive value of interpretable spatial indicators for
quantifying collective defensive performance.

</details>


### [189] [Simulated Affection, Engineered Trust: How Anthropomorphic AI Benefits Surveillance Capitalism](https://arxiv.org/abs/2511.06472)
*Adele Olof-Ors,Martin Smit*

Main category: cs.CY

TL;DR: 本文认为拟人化技术是操纵用户信任和行为的认知基础设施，强化了监控资本主义的逻辑，并探讨了应对方法。


<details>
  <summary>Details</summary>
Motivation: 揭示拟人化技术作为认知基础设施如何操纵用户信任和行为，强化监控资本主义的经济体系。

Method: 基于尼古拉斯·卡尔的智力伦理理论，分析聊天机器人、虚拟助手、生成模型等技术如何从认知层面重塑人类思维方式。

Result: 识别了AI新兴智力伦理如何有利于监控资本主义系统，并发现了技术对用户认知层面的深层影响。

Conclusion: 需要关注拟人化技术对认知的塑造作用，并探讨应对监控资本主义影响的方法。

Abstract: In this paper, we argue that anthropomorphized technology, designed to
simulate emotional realism, are not neutral tools but cognitive infrastructures
that manipulate user trust and behaviour. This reinforces the logic of
surveillance capitalism, an under-regulated economic system that profits from
behavioural manipulation and monitoring. Drawing on Nicholas Carr's theory of
the intellectual ethic, we identify how technologies such as chatbots, virtual
assistants, or generative models reshape not only what we think about ourselves
and our world, but how we think at the cognitive level. We identify how the
emerging intellectual ethic of AI benefits a system of surveillance capitalism,
and discuss the potential ways of addressing this.

</details>


### [190] [From Catastrophic to Concrete: Reframing AI Risk Communication for Public Mobilization](https://arxiv.org/abs/2511.06525)
*Philip Trippenbach,Isabella Scala,Jai Bhambra,Rowan Emslie*

Main category: cs.CY

TL;DR: 研究发现，以就业和儿童风险为核心的AI风险框架比存在风险框架更能有效动员公众参与AI治理，通过实证调查验证了这一结论。


<details>
  <summary>Details</summary>
Motivation: 当前AI治理需要公众参与，但基于存在风险的沟通策略未能实现持续动员，需要探索更有效的公众参与策略。

Method: 通过1063名受访者的实际信息测试和五个国家的调查数据，分析不同AI风险框架对公众动员的影响。

Result: 就业和儿童风险框架在动员公众方面表现最佳，而存在风险框架在所有人口统计中表现最差；识别出Tech-Positive Urbanites和World Guardians两个群体对此类框架特别敏感。

Conclusion: 围绕日常关切的动员策略能够提高AI的政治显著性，为成功的监管变革创造政策需求条件。

Abstract: Effective governance of artificial intelligence (AI) requires public
engagement, yet communication strategies centered on existential risk have not
produced sustained mobilization. In this paper, we examine the psychological
and opinion barriers that limit engagement with extinction narratives, such as
mortality avoidance, exponential growth bias, and the absence of
self-referential anchors. We contrast them with evidence that public concern
over AI rises when framed in terms of proximate harms such as employment
disruption, relational instability, and mental health issues. We validate these
findings through actual message testing with 1063 respondents, with the
evidence showing that AI risks to Jobs and Children have the highest potential
to mobilize people, while Existential Risk is the lowest-performing theme
across all demographics. Using survey data from five countries, we identify two
segments (Tech-Positive Urbanites and World Guardians) as particularly
receptive to such framing and more likely to participate in civic action.
Finally, we argue that mobilization around these everyday concerns can raise
the political salience of AI, creating "policy demand" for structural measures
to mitigate AI risks. We conclude that this strategy creates the conditions for
successful regulatory change.

</details>


### [191] [Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries](https://arxiv.org/abs/2511.06700)
*Damian Curran,Vanessa Sporne,Lea Frermann,Jeannie Paterson*

Main category: cs.CY

TL;DR: 本研究提出了一种基于比较法功能主义的方法，用于量化大型语言模型在不同地区法律知识表现的差异，发现领先闭源LLM的法律信息幻觉率与地理位置显著相关。


<details>
  <summary>Details</summary>
Motivation: 需要理解LLM基于聊天机器人向用户提供的法律信息质量是否因地理位置而异，但由于不同地区的法律制度本身难以比较，获得有意义的比较指标具有挑战性。

Method: 基于比较法功能主义构建方法论，从Reddit用户寻求法律咨询的帖子中提取事实场景，在洛杉矶、伦敦和悉尼针对每个场景从LLM获取相关法律摘要，并手动评估幻觉情况。

Result: 领先闭源LLM的法律信息幻觉率与地理位置显著相关，表明这些模型提供的法律解决方案质量在地理上分布不均；幻觉率与多数响应频率呈强负相关，可作为法律事实预测不确定性的衡量指标。

Conclusion: LLM的法律知识表现存在地理差异，模型预测法律事实的不确定性可以通过幻觉率与多数响应频率的相关性来衡量，这对理解LLM在不同司法管辖区提供法律信息的可靠性具有重要意义。

Abstract: How do we make a meaningful comparison of a large language model's knowledge
of the law in one place compared to another? Quantifying these differences is
critical to understanding if the quality of the legal information obtained by
users of LLM-based chatbots varies depending on their location. However,
obtaining meaningful comparative metrics is challenging because legal
institutions in different places are not themselves easily comparable. In this
work we propose a methodology to obtain place-to-place metrics based on the
comparative law concept of functionalism. We construct a dataset of factual
scenarios drawn from Reddit posts by users seeking legal advice for family,
housing, employment, crime and traffic issues. We use these to elicit a summary
of a law from the LLM relevant to each scenario in Los Angeles, London and
Sydney. These summaries, typically of a legislative provision, are manually
evaluated for hallucinations. We show that the rate of hallucination of legal
information by leading closed-source LLMs is significantly associated with
place. This suggests that the quality of legal solutions provided by these
models is not evenly distributed across geography. Additionally, we show a
strong negative correlation between hallucination rate and the frequency of the
majority response when the LLM is sampled multiple times, suggesting a measure
of uncertainty of model predictions of legal facts.

</details>


### [192] [Het 'right to be forgotten' en bijzondere persoonsgegevens: geen ruimte meer voor een belangenafweging? [The 'Right to Be Forgotten' and Sensitive Personal Data: No Room for Balancing?]](https://arxiv.org/abs/2511.07306)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文探讨荷兰法院在"被遗忘权"案件中处理刑事定罪数据时对言论自由产生的问题，并提出解决方案。


<details>
  <summary>Details</summary>
Motivation: 荷兰鹿特丹地方法院裁定谷歌不得在搜索律师姓名时链接到关于其刑事定罪的博客文章，这一判决基于刑事定罪数据属于特殊类别数据的规定，但对言论自由产生了负面影响。

Method: 本文通过分析荷兰法律中关于特殊类别数据的规定，探讨法院判决对言论自由的影响，并提出减少这些问题的可能方法。

Result: 法院判决认为刑事定罪数据属于敏感数据，应受"被遗忘权"保护，但这一推理对言论自由构成了挑战。谷歌已对该判决提出上诉。

Conclusion: 需要在保护个人数据隐私与维护言论自由之间找到平衡，减少特殊类别数据规定对言论自由的负面影响。

Abstract: An attorney submitted a 'right to be forgotten' delisting request to Google,
regarding a blog post about a criminal conviction of the attorney in another
country. The Rotterdam District Court ruled that Google may no longer link to
the blog post when people search for the attorney's name. The court granted the
attorney's request because the blog post concerns a criminal conviction.
Personal data regarding criminal convictions are, under Dutch law, special
categories of data (sometimes called sensitive data). The reasoning of the
court on special categories of data creates problems for freedom of expression.
This paper, in Dutch, explores how these problems can be reduced. Google has
appealed the decision; the judgment of the Court of Appeals is expected in
March 2017.

</details>


### [193] [Singling out people without knowing their names - Behavioural targeting, pseudonymous data, and the New Data Protection Regulation](https://arxiv.org/abs/2511.07307)
*Frederik J. Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文论证数据保护法应适用于行为定向营销，即使公司未将姓名与个人数据关联，只要使用数据来识别特定个人，就应视为处理个人数据。


<details>
  <summary>Details</summary>
Motivation: 行为定向营销公司声称只要不将姓名与个人数据关联就不处理个人数据，因此数据保护法不适用。本文旨在反驳这一观点，论证数据保护法应适用于行为定向营销。

Method: 通过分析行为定向营销的实际运作方式，论证公司通常能够将姓名与匿名数据关联，且行为定向依赖于收集个人信息、识别个体并向个体投放广告。

Result: 论证表明，无论公司是否将姓名与信息关联，许多隐私风险仍然存在。姓名只是可关联到个人数据的标识符之一，且对行为定向来说并非最实用的标识符。

Conclusion: 将用于识别个人的数据视为个人数据符合数据保护法的基本原理：保护公平性和隐私。数据保护法应适用于行为定向营销。

Abstract: Information about millions of people is collected for behavioural targeting,
a type of marketing that involves tracking people's online behaviour for
targeted advertising. It is hotly debated whether data protection law applies
to behavioural targeting. Many behavioural targeting companies say that, as
long as they do not tie names to data they hold about individuals, they do not
process any personal data, and that, therefore, data protection law does not
apply to them. European Data Protection Authorities, however, take the view
that a company processes personal data if it uses data to single out a person,
even if it cannot tie a name to these data. This paper argues that data
protection law should indeed apply to behavioural targeting. Companies can
often tie a name to nameless data about individuals. Furthermore, behavioural
targeting relies on collecting information about individuals, singling out
individuals, and targeting ads to individuals. Many privacy risks remain,
regardless of whether companies tie a name to the information they hold about a
person. A name is merely one of the identifiers that can be tied to data about
a person, and it is not even the most practical identifier for behavioural
targeting. Seeing data used to single out a person as personal data fits the
rationale for data protection law: protecting fairness and privacy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [194] [From Prompts to Power: Measuring the Energy Footprint of LLM Inference](https://arxiv.org/abs/2511.05597)
*Francisco Caravaca,Ángel Cuevas,Rubén Cuevas*

Main category: cs.AI

TL;DR: 本文对大语言模型推理阶段的能耗进行了大规模测量研究，涵盖32,500多次测量、21种GPU配置和155种模型架构，开发了能够准确预测推理能耗的模型，并实现为浏览器扩展以提高对生成式AI环境影响的认知。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速扩张，其能源需求急剧增加，特别是推理工作负载往往占据整个生命周期能耗的主要部分。尽管这一问题日益重要，但系统性的推理能耗分析仍然有限。

Method: 使用vLLM推理引擎进行大规模测量研究，在提示级别量化能耗，识别架构和操作因素如何影响能源需求，并基于这些洞察开发预测模型。

Result: 研究揭示了不同模型架构和硬件配置下的能耗模式，开发出的预测模型能够准确估计未见过的架构和硬件上的推理能耗。

Conclusion: 生成式AI的推理阶段具有显著的能源消耗，需要更系统的能耗分析和工具来提高环境影响的意识，本研究为此提供了重要的实证基础和实用工具。

Abstract: The rapid expansion of Large Language Models (LLMs) has introduced
unprecedented energy demands, extending beyond training to large-scale
inference workloads that often dominate total lifecycle consumption. Deploying
these models requires energy-intensive GPU infrastructure, and in some cases
has even prompted plans to power data centers with nuclear energy. Despite this
growing relevance, systematic analyses of inference energy consumption remain
limited. In this work, we present a large-scale measurement-based study
comprising over 32,500 measurements across 21 GPU configurations and 155 model
architectures, from small open-source models to frontier systems. Using the
vLLM inference engine, we quantify energy usage at the prompt level and
identify how architectural and operational factors shape energy demand.
Building on these insights, we develop a predictive model that accurately
estimates inference energy consumption across unseen architectures and
hardware, and implement it as a browser extension to raise awareness of the
environmental impact of generative AI.

</details>


### [195] [CoT-X: An Adaptive Framework for Cross-Model Chain-of-Thought Transfer and Optimization](https://arxiv.org/abs/2511.05747)
*Ziqian Bi,Kaijie Chen,Tianyang Wang,Junfeng Hao,Xinyuan Song*

Main category: cs.AI

TL;DR: 本文提出了一种自适应推理摘要框架，通过语义分割、重要性评分、预算感知动态压缩和连贯性重建来压缩推理轨迹，在保持关键推理步骤的同时显著减少token使用量。该方法在医疗考试问题上比截断方法准确率提高40%，并在64个模型对中验证了强跨模型可迁移性。


<details>
  <summary>Details</summary>
Motivation: 解决Chain-of-Thought推理带来的推理开销问题，使其能够在资源受限的环境中部署，通过高效的推理传输来提升模型的问题解决能力。

Method: 采用自适应推理摘要框架，包括语义分割与重要性评分、预算感知动态压缩、连贯性重建，以及基于高斯过程的贝叶斯优化模块来降低评估成本。

Result: 在7,501个医疗考试问题上，相同token预算下比截断方法准确率提高40%；在8个LLM的64个模型对中验证了强跨模型可迁移性；贝叶斯优化模块将评估成本降低84%，并揭示了模型规模与跨域鲁棒性之间的幂律关系。

Conclusion: 推理摘要为高效CoT传输提供了实用路径，使得在严格计算约束下能够实现高级推理能力。

Abstract: Chain-of-Thought (CoT) reasoning enhances the problem-solving ability of
large language models (LLMs) but leads to substantial inference overhead,
limiting deployment in resource-constrained settings. This paper investigates
efficient CoT transfer across models of different scales and architectures
through an adaptive reasoning summarization framework. The proposed method
compresses reasoning traces via semantic segmentation with importance scoring,
budget-aware dynamic compression, and coherence reconstruction, preserving
critical reasoning steps while significantly reducing token usage. Experiments
on 7{,}501 medical examination questions across 10 specialties show up to 40%
higher accuracy than truncation under the same token budgets. Evaluations on 64
model pairs from eight LLMs (1.5B-32B parameters, including DeepSeek-R1 and
Qwen3) confirm strong cross-model transferability. Furthermore, a Gaussian
Process-based Bayesian optimization module reduces evaluation cost by 84% and
reveals a power-law relationship between model size and cross-domain
robustness. These results demonstrate that reasoning summarization provides a
practical path toward efficient CoT transfer, enabling advanced reasoning under
tight computational constraints. Code will be released upon publication.

</details>


### [196] [Anchors in the Machine: Behavioral and Attributional Evidence of Anchoring Bias in LLMs](https://arxiv.org/abs/2511.05766)
*Felipe Valencia-Clavijo*

Main category: cs.AI

TL;DR: 本文通过概率分析和归因方法研究LLMs中的锚定偏见，发现锚点会系统性影响模型输出分布，不同规模模型对锚定的敏感性存在差异，归因效果因提示设计而异。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs表面输出是否表现出锚定偏见，但缺乏对其内部机制和归因贡献的深入探索。本文旨在通过概率分析和归因方法揭示LLMs中锚定偏见的深层机制。

Method: 采用三种方法：(1)基于对数概率的行为分析，控制训练数据污染；(2)使用精确Shapley值归因分析结构化提示字段；(3)提出统一的锚定偏见敏感度评分，整合行为和归因证据。

Result: Gemma-2B、Phi-2和Llama-2-7B表现出稳健的锚定效应，锚点影响重新加权；较小模型如GPT-2、Falcon-RW-1B和GPT-Neo-125M表现不一，表明规模可能调节敏感性；归因效果因提示设计而异。

Conclusion: LLMs中的锚定偏见是稳健、可测量和可解释的，但在应用领域存在风险。该框架为评估LLMs中其他认知偏见提供了可复现路径，连接了行为科学、LLM安全性和可解释性。

Abstract: Large language models (LLMs) are increasingly examined as both behavioral
subjects and decision systems, yet it remains unclear whether observed
cognitive biases reflect surface imitation or deeper probability shifts.
Anchoring bias, a classic human judgment bias, offers a critical test case.
While prior work shows LLMs exhibit anchoring, most evidence relies on
surface-level outputs, leaving internal mechanisms and attributional
contributions unexplored. This paper advances the study of anchoring in LLMs
through three contributions: (1) a log-probability-based behavioral analysis
showing that anchors shift entire output distributions, with controls for
training-data contamination; (2) exact Shapley-value attribution over
structured prompt fields to quantify anchor influence on model
log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score
integrating behavioral and attributional evidence across six open-source
models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and
Llama-2-7B, with attribution signaling that the anchors influence reweighting.
Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability,
suggesting scale may modulate sensitivity. Attributional effects, however, vary
across prompt designs, underscoring fragility in treating LLMs as human
substitutes. The findings demonstrate that anchoring bias in LLMs is robust,
measurable, and interpretable, while highlighting risks in applied domains.
More broadly, the framework bridges behavioral science, LLM safety, and
interpretability, offering a reproducible path for evaluating other cognitive
biases in LLMs.

</details>


### [197] [Can a Small Model Learn to Look Before It Leaps? Dynamic Learning and Proactive Correction for Hallucination Detection](https://arxiv.org/abs/2511.05854)
*Zepeng Bao,Shen Zhou,Qiankun Pi,Jianhao Chen,Mayi Xu,Ming Zhong,Yuanyuan Zhu,Tieyun Qian*

Main category: cs.AI

TL;DR: 本文提出LEAP框架来解决LLM幻觉检测中策略适应性问题，通过动态学习和主动校正机制，将教师模型的动态规划能力蒸馏到高效学生模型中。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强的幻觉检测方法使用预定义的固定验证策略，在动态变化环境中缺乏适应性，可能导致检测失败。直接使用GPT-4等闭源模型成本过高，而教师-学生架构的方法又受限于固定策略。

Method: 将幻觉检测问题建模为动态策略学习问题：1）使用教师模型在动态学习循环中生成轨迹并基于执行失败调整策略；2）通过智能体调优将动态规划能力蒸馏到高效学生模型；3）学生模型在执行时采用主动校正机制，在执行前提出、审查和优化验证策略。

Result: 在三个具有挑战性的基准测试上的实验表明，LEAP调优的模型优于现有的最先进方法。

Conclusion: LEAP框架成功解决了幻觉检测中的策略适应性问题，赋予高效学生模型动态学习和主动校正能力，在保持低成本的同时实现了更好的检测性能。

Abstract: Hallucination in large language models (LLMs) remains a critical barrier to
their safe deployment. Existing tool-augmented hallucination detection methods
require pre-defined fixed verification strategies, which are crucial to the
quality and effectiveness of tool calls. Some methods directly employ powerful
closed-source LLMs such as GPT-4 as detectors, which are effective but too
costly. To mitigate the cost issue, some methods adopt the teacher-student
architecture and finetune open-source small models as detectors via agent
tuning. However, these methods are limited by fixed strategies. When faced with
a dynamically changing execution environment, they may lack adaptability and
inappropriately call tools, ultimately leading to detection failure. To address
the problem of insufficient strategy adaptability, we propose the innovative
``Learning to Evaluate and Adaptively Plan''(LEAP) framework, which endows an
efficient student model with the dynamic learning and proactive correction
capabilities of the teacher model. Specifically, our method formulates the
hallucination detection problem as a dynamic strategy learning problem. We
first employ a teacher model to generate trajectories within the dynamic
learning loop and dynamically adjust the strategy based on execution failures.
We then distill this dynamic planning capability into an efficient student
model via agent tuning. Finally, during strategy execution, the student model
adopts a proactive correction mechanism, enabling it to propose, review, and
optimize its own verification strategies before execution. We demonstrate
through experiments on three challenging benchmarks that our LEAP-tuned model
outperforms existing state-of-the-art methods.

</details>


### [198] [An Empirical Study of Reasoning Steps in Thinking Code LLMs](https://arxiv.org/abs/2511.05874)
*Haoran Xue,Gias Uddin,Song Wang*

Main category: cs.AI

TL;DR: 对6种先进思维LLM在代码生成任务中的推理过程进行实证研究，发现推理链质量与任务复杂度相关，完整性是主要失败模式，但模型能保持逻辑一致性并自我纠错。


<details>
  <summary>Details</summary>
Motivation: 探索思维LLM生成显性中间推理链的质量，以提升代码生成的透明度、可解释性和准确性，但目前推理链质量研究不足。

Method: 评估6种推理LLM在100个不同难度代码生成任务上的表现，通过步骤计数、冗长度量化推理链结构，进行受控步骤预算调整，并开展21人参与的效率、逻辑正确性和完整性三维度人工评估。

Result: 针对性增加步骤可提升某些模型/任务的解决率，适度减少步骤在标准任务上通常能保持成功，但在困难任务上很少成功。任务复杂度显著影响推理质量，困难问题更容易出现不完整性。

Conclusion: 思维LLM在不同计算努力水平下能保持一致的逻辑结构并自我纠错，为当前思维LLM在软件工程中的优势和局限性提供了新见解。

Abstract: Thinking Large Language Models (LLMs) generate explicit intermediate
reasoning traces before final answers, potentially improving transparency,
interpretability, and solution accuracy for code generation. However, the
quality of these reasoning chains remains underexplored. We present a
comprehensive empirical study examining the reasoning process and quality of
thinking LLMs for code generation. We evaluate six state-of-the-art reasoning
LLMs (DeepSeek-R1, OpenAI-o3-mini, Claude-3.7-Sonnet-Thinking,
Gemini-2.0-Flash-Thinking, Gemini-2.5-Flash, and Qwen-QwQ) across 100 code
generation tasks of varying difficulty from BigCodeBench. We quantify
reasoning-chain structure through step counts and verbosity, conduct controlled
step-budget adjustments, and perform a 21-participant human evaluation across
three dimensions: efficiency, logical correctness, and completeness. Our
step-count interventions reveal that targeted step increases can improve
resolution rates for certain models/tasks, while modest reductions often
preserve success on standard tasks, rarely on hard ones. Through systematic
analysis, we develop a reasoning-problematic taxonomy, identifying completeness
as the dominant failure mode. Task complexity significantly impacts reasoning
quality; hard problems are substantially more prone to incompleteness than
standard tasks. Our stability analysis demonstrates that thinking LLMs maintain
consistent logical structures across computational effort levels and can
self-correct previous errors. This study provides new insights into the
strengths and limitations of current thinking LLMs in software engineering.

</details>


### [199] [Unveiling Modality Bias: Automated Sample-Specific Analysis for Multimodal Misinformation Benchmarks](https://arxiv.org/abs/2511.05883)
*Hehai Lin,Hui Liu,Shilei Cao,Jing Li,Haoliang Li,Wenya Wang*

Main category: cs.AI

TL;DR: 本文提出三种基于不同粒度理论的多模态偏见量化方法，用于在样本级别自动识别模态偏见，并通过人工评估验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态虚假信息基准存在特定模态偏见，使得检测器可以仅基于单一模态进行预测。先前研究在数据集级别量化偏见或手动识别模态与标签之间的虚假相关性，但这些方法缺乏样本级别的深入洞察且难以扩展到海量在线信息。

Method: 提出三种不同粒度的偏见量化方法：1）粗粒度的模态效益评估；2）中粒度的信息流量化；3）细粒度的因果分析。在两个流行基准上进行人工评估验证。

Result: 实验揭示了三个重要发现：1）集成多个视图对可靠自动分析至关重要；2）自动分析容易受到检测器引起的波动影响；3）不同视图在模态平衡样本上具有更高一致性，但在偏见样本上产生分歧。

Conclusion: 研究为未来多模态偏见检测提供了潜在方向，强调了多视图集成的重要性，并揭示了自动分析方法的局限性。

Abstract: Numerous multimodal misinformation benchmarks exhibit bias toward specific
modalities, allowing detectors to make predictions based solely on one
modality. While previous research has quantified bias at the dataset level or
manually identified spurious correlations between modalities and labels, these
approaches lack meaningful insights at the sample level and struggle to scale
to the vast amount of online information. In this paper, we investigate the
design for automated recognition of modality bias at the sample level.
Specifically, we propose three bias quantification methods based on
theories/views of different levels of granularity: 1) a coarse-grained
evaluation of modality benefit; 2) a medium-grained quantification of
information flow; and 3) a fine-grained causality analysis. To verify the
effectiveness, we conduct a human evaluation on two popular benchmarks.
Experimental results reveal three interesting findings that provide potential
direction toward future research: 1)~Ensembling multiple views is crucial for
reliable automated analysis; 2)~Automated analysis is prone to detector-induced
fluctuations; and 3)~Different views produce a higher agreement on
modality-balanced samples but diverge on biased ones.

</details>


### [200] [Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement](https://arxiv.org/abs/2511.05931)
*Hiroaki Hayashi,Bo Pang,Wenting Zhao,Ye Liu,Akash Gokul,Srijan Bansal,Caiming Xiong,Semih Yavuz,Yingbo Zhou*

Main category: cs.AI

TL;DR: SAGE是一个让LLM智能体从自身执行经验中学习并自我改进的框架，通过从具体经验中抽象出计划来指导后续执行，在软件工程任务上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体通常在静态执行框架中运行，缺乏从自身经验和历史执行中学习改进的机制，导致性能受限于初始框架设计和基础LLM能力。

Method: 提出SAGE框架，智能体在初始执行后从具体经验中归纳出简洁的计划抽象（包括关键步骤、依赖关系和约束），然后将学习到的抽象作为上下文指导反馈给智能体，优化其策略并支持更结构化、信息更充分的后续执行。

Result: SAGE在不同LLM骨干和智能体架构上均带来一致的性能提升。与强大的Mini-SWE-Agent基线相比，使用GPT-5（高）骨干时相对性能提升7.2%。在SWE-Bench Verified基准测试中，分别达到73.2%和74%的Pass@1解决率。

Conclusion: SAGE框架通过使智能体能够从自身经验中学习抽象知识，有效提升了LLM智能体在软件工程任务中的性能，证明了经验驱动的自我改进机制的重要性。

Abstract: Large language model (LLM) based agents are increasingly used to tackle
software engineering tasks that require multi-step reasoning and code
modification, demonstrating promising yet limited performance. However, most
existing LLM agents typically operate within static execution frameworks,
lacking a principled mechanism to learn and self-improve from their own
experience and past rollouts. As a result, their performance remains bounded by
the initial framework design and the underlying LLM's capabilities. We propose
Self-Abstraction from Grounded Experience (SAGE), a framework that enables
agents to learn from their own task executions and refine their behavior
through self-abstraction. After an initial rollout, the agent induces a concise
plan abstraction from its grounded experience, distilling key steps,
dependencies, and constraints. This learned abstraction is then fed back as
contextual guidance, refining the agent's policy and supporting more
structured, informed subsequent executions. Empirically, SAGE delivers
consistent performance gains across diverse LLM backbones and agent
architectures. Notably, it yields a 7.2% relative performance improvement over
the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone.
SAGE further achieves strong overall performance on SWE-Bench Verified
benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent
and OpenHands CodeAct agent framework, respectively.

</details>


### [201] [Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling](https://arxiv.org/abs/2511.05951)
*Qi Wang,Hongzhi Zhang,Jia Fu,Kai Fu,Yahui Liu,Tinghai Zhang,Chenxi Sun,Gangwei Jiang,Jingyi Tang,Xingguang Ji,Yang Yue,Jingyuan Zhang,Fuzheng Zhang,Kun Gai,Guorui Zhou*

Main category: cs.AI

TL;DR: 本文提出了一个完全开源的训练流程Klear-Qwen3-AgentForge，从Qwen3-8B基础模型开始，通过监督微调和多轮强化学习训练高性能的智能体模型，在工具使用和编程领域达到同类模型的最优性能。


<details>
  <summary>Details</summary>
Motivation: 尽管强大的智能体模型不断涌现，但缺乏关键的训练后细节阻碍了开源社区开发强大的对应模型。

Method: 设计了有效的监督微调（使用合成数据）和多轮强化学习，以解锁多种智能体任务的潜力。

Result: Klear-Qwen3-AgentForge-8B在类似规模的LLM中实现了最先进的性能，并与显著更大的模型保持竞争力。

Conclusion: 该研究为开源社区提供了一个全面的智能体模型训练流程，填补了现有模型的训练细节空白。

Abstract: Despite the proliferation of powerful agentic models, the lack of critical
post-training details hinders the development of strong counterparts in the
open-source community. In this study, we present a comprehensive and fully
open-source pipeline for training a high-performance agentic model for
interacting with external tools and environments, named Klear-Qwen3-AgentForge,
starting from the Qwen3-8B base model. We design effective supervised
fine-tuning (SFT) with synthetic data followed by multi-turn reinforcement
learning (RL) to unlock the potential for multiple diverse agentic tasks. We
perform exclusive experiments on various agentic benchmarks in both tool use
and coding domains. Klear-Qwen3-AgentForge-8B achieves state-of-the-art
performance among LLMs of similar size and remains competitive with
significantly larger models.

</details>


### [202] [An Epistemic Perspective on Agent Awareness](https://arxiv.org/abs/2511.05977)
*Pavel Naumov,Alexandra Pavlova*

Main category: cs.AI

TL;DR: 该论文将智能体意识视为一种知识形式，打破了现有文献传统。它区分了这种知识的de re和de dicto形式，引入了两种模态来捕捉这些形式，并使用2D语义学版本形式化其含义。主要技术结果是描述两种提议模态与标准"事实知识"模态之间相互作用的一个健全且完备的逻辑系统。


<details>
  <summary>Details</summary>
Motivation: 打破现有文献中将智能体意识视为传统知识的传统，提出将意识视为一种特殊的知识形式，并区分其不同表现形式。

Method: 引入两种模态来捕捉de re和de dicto形式的意识知识，使用2D语义学版本形式化其含义，构建描述这些模态与标准知识模态相互作用的逻辑系统。

Result: 开发了一个健全且完备的逻辑系统，成功描述了两种意识知识模态与标准事实知识模态之间的相互作用关系。

Conclusion: 通过将智能体意识形式化为知识，并区分其不同形式，论文为意识研究提供了新的理论框架和形式化工具。

Abstract: The paper proposes to treat agent awareness as a form of knowledge, breaking
the tradition in the existing literature on awareness. It distinguishes the de
re and de dicto forms of such knowledge. The work introduces two modalities
capturing these forms and formally specifies their meaning using a version of
2D-semantics. The main technical result is a sound and complete logical system
describing the interplay between the two proposed modalities and the standard
"knowledge of the fact" modality.

</details>


### [203] [When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks](https://arxiv.org/abs/2511.06136)
*Stefano Ferraro,Akihiro Nakano,Masahiro Suzuki,Yutaka Matsuo*

Main category: cs.AI

TL;DR: DLPWM是一个无监督的、解耦的对象中心世界模型，能够从像素直接学习对象级潜在表示。虽然该模型在重建和预测方面表现良好，但在下游基于模型的控制任务中，其策略性能不如DreamerV3，主要原因是多对象交互过程中的表示偏移导致策略学习不稳定。


<details>
  <summary>Details</summary>
Motivation: 研究假设显式解耦的对象级表示能够通过定位任务相关信息来增强策略在新特征组合上的性能，旨在提高强化学习中的组合泛化能力和数据效率。

Method: 引入DLPWM，一个完全无监督的解耦对象中心世界模型，直接从像素学习对象级潜在表示。

Result: DLPWM在重建和预测方面表现强劲，包括对多种分布外视觉变化的鲁棒性。但在下游模型控制任务中，基于DLPWM潜在表示的策略训练效果不如DreamerV3。通过潜在轨迹分析发现，多对象交互过程中的表示偏移是导致策略学习不稳定的关键因素。

Conclusion: 虽然对象中心感知支持鲁棒的视觉建模，但要实现稳定的控制需要减轻潜在漂移问题。

Abstract: Object-centric world models (OCWM) aim to decompose visual scenes into
object-level representations, providing structured abstractions that could
improve compositional generalization and data efficiency in reinforcement
learning. We hypothesize that explicitly disentangled object-level
representations, by localizing task-relevant information, can enhance policy
performance across novel feature combinations. To test this hypothesis, we
introduce DLPWM, a fully unsupervised, disentangled object-centric world model
that learns object-level latents directly from pixels. DLPWM achieves strong
reconstruction and prediction performance, including robustness to several
out-of-distribution (OOD) visual variations. However, when used for downstream
model-based control, policies trained on DLPWM latents underperform compared to
DreamerV3. Through latent-trajectory analyses, we identify representation shift
during multi-object interactions as a key driver of unstable policy learning.
Our results suggest that, although object-centric perception supports robust
visual modeling, achieving stable control requires mitigating latent drift.

</details>


### [204] [Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles](https://arxiv.org/abs/2511.06160)
*Fatima Jahara,Mark Dredze,Sharon Levy*

Main category: cs.AI

TL;DR: PRIME是一个新的评估框架，使用逻辑网格谜题来系统性地探测LLMs在逻辑推理和决策中受到社会刻板印象的影响。该框架包含刻板印象、反刻板印象和中立谜题变体，能够进行受控的细粒度比较。


<details>
  <summary>Details</summary>
Motivation: 当前的安全护栏能有效抑制明显偏见输出，但在复杂逻辑推理任务中，更微妙的社会偏见形式会逃避现有评估基准。需要填补这一空白来诊断LLMs在演绎推理中延续的社会偏见。

Method: 使用逻辑网格谜题构建PRIME评估框架，包含刻板印象、反刻板印象和中立变体。自动生成和验证谜题，测试不同模型家族在不同谜题大小下的表现，并评估基于提示的缓解策略有效性。

Result: 模型在解决方案与刻板印象关联一致时推理更准确，表明LLMs在演绎推理中持续存在社会偏见。

Conclusion: PRIME对于诊断和量化LLMs在关键公平性领域的演绎推理中延续的社会偏见具有重要意义。

Abstract: While recent safety guardrails effectively suppress overtly biased outputs,
subtler forms of social bias emerge during complex logical reasoning tasks that
evade current evaluation benchmarks. To fill this gap, we introduce a new
evaluation framework, PRIME (Puzzle Reasoning for Implicit Biases in Model
Evaluation), that uses logic grid puzzles to systematically probe the influence
of social stereotypes on logical reasoning and decision making in LLMs. Our use
of logic puzzles enables automatic generation and verification, as well as
variability in complexity and biased settings. PRIME includes stereotypical,
anti-stereotypical, and neutral puzzle variants generated from a shared puzzle
structure, allowing for controlled and fine-grained comparisons. We evaluate
multiple model families across puzzle sizes and test the effectiveness of
prompt-based mitigation strategies. Focusing our experiments on gender
stereotypes, our findings highlight that models consistently reason more
accurately when solutions align with stereotypical associations. This
demonstrates the significance of PRIME for diagnosing and quantifying social
biases perpetuated in the deductive reasoning of LLMs, where fairness is
critical.

</details>


### [205] [Chasing Consistency: Quantifying and Optimizing Human-Model Alignment in Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.06168)
*Boxuan Wang,Zhuoyun Li,Xinmiao Huang,Xiaowei Huang,Yi Dong*

Main category: cs.AI

TL;DR: 本文提出了一个评估和优化大语言模型推理一致性的框架，通过新的对齐分数指标量化模型生成的推理链与人类参考链的语义对齐程度。研究发现2跳推理链对齐分数最高，定义了四种关键错误类型，并提出SCOS方法优化推理一致性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在复杂推理任务中生成的推理链与人类推理存在语义不一致问题，需要量化评估和优化推理一致性。

Method: 提出对齐分数指标评估推理一致性，定义四种错误类型（逻辑断开、主题转移、冗余推理、因果反转），并开发语义一致性优化采样方法（SCOS）来优化推理链。

Result: 实证研究发现2跳推理链对齐分数最高，SCOS方法平均提升对齐分数29.84%，在3跳任务等长推理链中效果显著。

Conclusion: 提出的对齐分数和SCOS方法有效评估和优化了LLMs的推理一致性，为提升模型推理能力提供了新思路。

Abstract: This paper presents a framework for evaluating and optimizing reasoning
consistency in Large Language Models (LLMs) via a new metric, the Alignment
Score, which quantifies the semantic alignment between model-generated
reasoning chains and human-written reference chains in Chain-of-Thought (CoT)
reasoning. Empirically, we find that 2-hop reasoning chains achieve the highest
Alignment Score. To explain this phenomenon, we define four key error types:
logical disconnection, thematic shift, redundant reasoning, and causal
reversal, and show how each contributes to the degradation of the Alignment
Score. Building on this analysis, we further propose Semantic Consistency
Optimization Sampling (SCOS), a method that samples and favors chains with
minimal alignment errors, significantly improving Alignment Scores by an
average of 29.84% with longer reasoning chains, such as in 3-hop tasks.

</details>


### [206] [CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference](https://arxiv.org/abs/2511.06175)
*Kaijie Xu,Fandi Meng,Clark Verbrugge,Simon Lucas*

Main category: cs.AI

TL;DR: CSP4SDG是一个用于社交推理游戏的约束满足框架，通过将游戏事件和对话映射为四种约束类别，结合硬约束和软约束来推断玩家角色，在推理准确性和解释性方面优于基于LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 在社交推理游戏中，玩家隐藏身份并故意误导他人，使得角色推断成为核心且困难的任务。准确的角色识别是玩家和AI表现的关键基础。

Method: 提出CSP4SDG概率约束满足框架，将游戏事件和对话映射为证据、现象、断言和假设四类约束。硬约束排除不可能的角色分配，加权软约束对剩余分配进行评分，信息增益权重将每个假设与其在熵减少下的期望值联系起来。

Result: 在三个公共数据集上的实验表明，CSP4SDG在所有推理场景中都优于基于LLM的基线方法，并且当作为辅助"推理工具"提供给LLM时能够提升LLM的性能。

Conclusion: 研究表明，基于信息论的原则性概率推理是社交推理游戏中重量级神经模型的可扩展替代或补充方案。

Abstract: In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players
conceal their identities and deliberately mislead others, making hidden-role
inference a central and demanding task. Accurate role identification, which
forms the basis of an agent's belief state, is therefore the keystone for both
human and AI performance. We introduce CSP4SDG, a probabilistic,
constraint-satisfaction framework that analyses gameplay objectively. Game
events and dialogue are mapped to four linguistically-agnostic constraint
classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune
impossible role assignments, while weighted soft constraints score the
remainder; information-gain weighting links each hypothesis to its expected
value under entropy reduction, and a simple closed-form scoring rule guarantees
that truthful assertions converge to classical hard logic with minimum error.
The resulting posterior over roles is fully interpretable and updates in real
time. Experiments on three public datasets show that CSP4SDG (i) outperforms
LLM-based baselines in every inference scenario, and (ii) boosts LLMs when
supplied as an auxiliary "reasoning tool." Our study validates that principled
probabilistic reasoning with information theory is a scalable alternative-or
complement-to heavy-weight neural models for SDGs.

</details>


### [207] [Dataforge: A Data Agent Platform for Autonomous Data Engineering](https://arxiv.org/abs/2511.06185)
*Xinyuan Wang,Yanjie Fu*

Main category: cs.AI

TL;DR: Data Agent是一个完全自主的表格数据处理系统，利用大语言模型推理和验证，自动执行数据清洗、分层路由和特征级优化，实现从原始数据到AI就绪数据的端到端自动化转换。


<details>
  <summary>Details</summary>
Motivation: AI应用在材料发现、分子建模和气候科学等领域的需求增长，使得数据准备成为重要但劳动密集的步骤。原始数据需要清洗、标准化和转换才能用于AI，而有效的特征转换和选择对高效训练和推理至关重要。

Method: 利用大语言模型推理和基于验证的方法，Data Agent自动执行数据清洗、分层路由和特征级优化，通过双反馈循环实现端到端自动化处理。

Result: 开发了第一个实用的自主Data Agent系统，展示了如何将原始数据转换为更好的数据，实现了无需人工监督的端到端可靠性。

Conclusion: Data Agent系统体现了自动、安全和非专家友好的核心原则，为AI应用的数据准备提供了可扩展且不依赖专业知识的解决方案。

Abstract: The growing demand for AI applications in fields such as materials discovery,
molecular modeling, and climate science has made data preparation an important
but labor-intensive step. Raw data from diverse sources must be cleaned,
normalized, and transformed to become AI-ready, while effective feature
transformation and selection are essential for efficient training and
inference. To address the challenges of scalability and expertise dependence,
we present Data Agent, a fully autonomous system specialized for tabular data.
Leveraging large language model (LLM) reasoning and grounded validation, Data
Agent automatically performs data cleaning, hierarchical routing, and
feature-level optimization through dual feedback loops. It embodies three core
principles: automatic, safe, and non-expert friendly, which ensure end-to-end
reliability without human supervision. This demo showcases the first practical
realization of an autonomous Data Agent, illustrating how raw data can be
transformed "From Data to Better Data."

</details>


### [208] [Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps via Uncertainty Heads](https://arxiv.org/abs/2511.06209)
*Jingwei Ni,Ekaterina Fadeeva,Tianyi Wu,Mubashara Akhtar,Jiaheng Zhang,Elliott Ash,Markus Leippold,Timothy Baldwin,See-Kiong Ng,Artem Shelmanov,Mrinmaya Sachan*

Main category: cs.AI

TL;DR: 本文提出了一种基于数据驱动不确定性评分的轻量级推理步骤验证方法UHeads，使用冻结LLM的内部状态来估计推理步骤的不确定性，无需大规模人工标注，在多个领域达到或超过更大模型PRMs的性能。


<details>
  <summary>Details</summary>
Motivation: 现有推理验证方法如过程奖励模型(PRMs)存在计算成本高、领域受限、需要大规模标注等问题，需要一种轻量级、自动化的推理步骤验证方案。

Method: 训练基于transformer的不确定性量化头(UHeads)，利用冻结LLM的内部状态来估计推理步骤的不确定性，标签由更大LLM或原始模型自监督生成，参数量小于10M。

Result: 在数学、规划和常识问答等多个领域，UHeads的性能达到或超过参数量高达810倍的PRMs，表明LLM内部状态编码了不确定性信息。

Conclusion: LLM内部状态能够作为可靠的推理验证信号，为构建可扩展和泛化的自省LLMs提供了有前景的方向。

Abstract: Solving complex tasks usually requires LLMs to generate long multi-step
reasoning chains. Previous work has shown that verifying the correctness of
individual reasoning steps can further improve the performance and efficiency
of LLMs on such tasks and enhance solution interpretability. However, existing
verification approaches, such as Process Reward Models (PRMs), are either
computationally expensive, limited to specific domains, or require large-scale
human or model-generated annotations. Thus, we propose a lightweight
alternative for step-level reasoning verification based on data-driven
uncertainty scores. We train transformer-based uncertainty quantification heads
(UHeads) that use the internal states of a frozen LLM to estimate the
uncertainty of its reasoning steps during generation. The approach is fully
automatic: target labels are generated either by another larger LLM (e.g.,
DeepSeek R1) or in a self-supervised manner by the original model itself.
UHeads are both effective and lightweight, containing less than 10M parameters.
Across multiple domains, including mathematics, planning, and general knowledge
question answering, they match or even surpass the performance of PRMs that are
up to 810x larger. Our findings suggest that the internal states of LLMs encode
their uncertainty and can serve as reliable signals for reasoning verification,
offering a promising direction toward scalable and generalizable introspective
LLMs.

</details>


### [209] [Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B](https://arxiv.org/abs/2511.06221)
*Sen Xu,Yi Zhou,Wei Wang,Jixin Min,Zhibin Yin,Yingwei Dai,Shixi Liu,Lianyu Pang,Yirong Chen,Junlin Zhang*

Main category: cs.AI

TL;DR: VibeThinker-1.5B是一个仅1.5B参数的密集模型，通过Spectrum-to-Signal Principle (SSP)框架训练，以极低成本（7800美元）实现了超越大型模型的推理能力，挑战了模型规模必须扩大才能提升能力的共识。


<details>
  <summary>Details</summary>
Motivation: 挑战当前认为小模型缺乏强大推理能力的共识，证明通过高效训练方法，小模型也能达到与大型模型相当的推理能力，从而大幅降低训练和推理成本，促进AI研究的民主化。

Method: 采用Spectrum-to-Signal Principle (SSP)框架：1) 两阶段多样性探索蒸馏(SFT)生成广泛解决方案谱；2) 最大熵引导策略优化(RL)放大正确信号。

Result: 在数学基准测试中超越400倍大的DeepSeek R1：AIME24 (80.3 vs. 79.8)、AIME25 (74.4 vs. 70.0)、HMMT25 (50.4 vs. 41.7)；在LiveCodeBench V6上得分为51.1，优于Magistral Medium的50.3。

Conclusion: 小模型通过高效训练方法可以实现与大型模型相当的推理能力，显著降低AI研究和应用的成本门槛，推动AI技术的普及化。

Abstract: Challenging the prevailing consensus that small models inherently lack robust
reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense
model developed via our Spectrum-to-Signal Principle (SSP). This challenges the
prevailing approach of scaling model parameters to enhance capabilities, as
seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework
first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a
broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL)
to amplify the correct signal. With a total training cost of only $7,800,
VibeThinker-1.5B demonstrates superior reasoning capabilities compared to
closed-source models like Magistral Medium and Claude Opus 4, and performs on
par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses
the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8),
AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial
improvement over its base model (6.7, 4.3, and 0.6, respectively). On
LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its
base model's 0.0. These findings demonstrate that small models can achieve
reasoning capabilities comparable to large models, drastically reducing
training and inference costs and thereby democratizing advanced AI research.

</details>


### [210] [ROAR: Robust Accident Recognition and Anticipation for Autonomous Driving](https://arxiv.org/abs/2511.06226)
*Xingcheng Liu,Yanchen Guan,Haicheng Liao,Zhengbing He,Zhenning Li*

Main category: cs.AI

TL;DR: 本文提出ROAR方法，通过结合离散小波变换、自适应目标感知模块和动态焦点损失，解决自动驾驶车辆事故预测中传感器故障、环境干扰和数据不平衡等问题，在多个数据集上优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有事故预测方法通常假设理想条件，忽略了传感器故障、环境干扰、数据缺陷以及不同车辆类型间驾驶员行为和事故率的显著差异，这些因素会显著降低预测准确性。

Method: ROAR方法结合离散小波变换(DWT)从噪声和不完整数据中提取特征，自适应目标感知模块关注高风险车辆并建模交通参与者间的时空关系，动态焦点损失缓解正负样本类别不平衡问题。

Result: 在Dashcam Accident Dataset (DAD)、Car Crash Dataset (CCD)和AnAn Accident Detection (A3D)三个数据集上的评估显示，ROAR在平均精度(AP)和平均事故时间(mTTA)等关键指标上持续优于现有基线方法。

Conclusion: ROAR在复杂交通环境中提供了可靠准确的事故预测解决方案，特别是在处理传感器退化、环境噪声和不平衡数据分布方面表现出鲁棒性。

Abstract: Accurate accident anticipation is essential for enhancing the safety of
autonomous vehicles (AVs). However, existing methods often assume ideal
conditions, overlooking challenges such as sensor failures, environmental
disturbances, and data imperfections, which can significantly degrade
prediction accuracy. Additionally, previous models have not adequately
addressed the considerable variability in driver behavior and accident rates
across different vehicle types. To overcome these limitations, this study
introduces ROAR, a novel approach for accident detection and prediction. ROAR
combines Discrete Wavelet Transform (DWT), a self adaptive object aware module,
and dynamic focal loss to tackle these challenges. The DWT effectively extracts
features from noisy and incomplete data, while the object aware module improves
accident prediction by focusing on high-risk vehicles and modeling the spatial
temporal relationships among traffic agents. Moreover, dynamic focal loss
mitigates the impact of class imbalance between positive and negative samples.
Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car
Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently
outperforms existing baselines in key metrics such as Average Precision (AP)
and mean Time to Accident (mTTA). These results demonstrate the model's
robustness in real-world conditions, particularly in handling sensor
degradation, environmental noise, and imbalanced data distributions. This work
offers a promising solution for reliable and accurate accident anticipation in
complex traffic environments.

</details>


### [211] [Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and Documents](https://arxiv.org/abs/2511.06292)
*Yaoning Yu,Kaimin Chang,Ye Yu,Kai Wei,Haojing Luo,Haohan Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于数据增强优化的自改进提示框架，通过生成合成金融表格和文档片段、验证其正确性和鲁棒性，然后根据结果更新提示，从而在无需外部标签的情况下持续改进金融推理任务的提示准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在固定数据集上调整提示，限制了适应新问题类型或文档结构的能力，或者需要昂贵的手动标注数据集来构建提示。

Method: 结合合成数据生成器、验证器和提示优化器的闭环框架，生成器产生暴露当前提示弱点的示例，验证器检查生成示例的有效性和鲁棒性，优化器根据结果逐步优化提示。

Result: 在DocMath-Eval基准测试中，该系统在准确性和鲁棒性方面均优于标准提示方法。

Conclusion: 将合成数据生成融入提示学习对金融应用具有重要价值，能够在不依赖外部标签的情况下持续改进提示性能。

Abstract: Financial documents like earning reports or balance sheets often involve long
tables and multi-page reports. Large language models have become a new tool to
help numerical reasoning and understanding these documents. However, prompt
quality can have a major effect on how well LLMs perform these financial
reasoning tasks. Most current methods tune prompts on fixed datasets of
financial text or tabular data, which limits their ability to adapt to new
question types or document structures, or they involve costly and manually
labeled/curated dataset to help build the prompts. We introduce a
self-improving prompt framework driven by data-augmented optimization. In this
closed-loop process, we generate synthetic financial tables and document
excerpts, verify their correctness and robustness, and then update the prompt
based on the results. Specifically, our framework combines a synthetic data
generator with verifiers and a prompt optimizer, where the generator produces
new examples that exposes weaknesses in the current prompt, the verifiers check
the validity and robustness of the produced examples, and the optimizer
incrementally refines the prompt in response. By iterating these steps in a
feedback cycle, our method steadily improves prompt accuracy on financial
reasoning tasks without needing external labels. Evaluation on DocMath-Eval
benchmark demonstrates that our system achieves higher performance in both
accuracy and robustness than standard prompt methods, underscoring the value of
incorporating synthetic data generation into prompt learning for financial
applications.

</details>


### [212] [Secu-Table: a Comprehensive security table dataset for evaluating semantic table interpretation systems](https://arxiv.org/abs/2511.06301)
*Azanzi Jiomekong,Jean Bikim,Patricia Negoue,Joyce Chin*

Main category: cs.AI

TL;DR: 本文介绍了Secu-Table数据集，这是一个包含1500多个表格和15,000多个实体的安全领域语义表解释数据集，基于CVE和CWE数据源构建，并使用Wikidata和SEPSES CSKG进行标注。


<details>
  <summary>Details</summary>
Motivation: 在安全领域，用于评估基于大语言模型的语义表解释系统的公开表格数据集缺乏，这限制了相关研究的进展。

Method: 从CVE和CWE数据源提取安全数据构建表格，使用Wikidata和SEPSES CSKG知识图谱进行实体标注，并公开发布数据集和代码。

Result: 创建了包含1500多个表格和15,000多个实体的Secu-Table数据集，作为SemTab挑战赛的一部分，并进行了基于Falcon3-7b-instruct、Mistral-7B-Instruct和GPT-4o mini的初步评估。

Conclusion: Secu-Table数据集填补了安全领域语义表解释评估数据集的空白，为基于开源大语言模型的表格到知识图谱匹配研究提供了重要资源。

Abstract: Evaluating semantic tables interpretation (STI) systems, (particularly, those
based on Large Language Models- LLMs) especially in domain-specific contexts
such as the security domain, depends heavily on the dataset. However, in the
security domain, tabular datasets for state-of-the-art are not publicly
available. In this paper, we introduce Secu-Table dataset, composed of more
than 1500 tables with more than 15k entities constructed using security data
extracted from Common Vulnerabilities and Exposures (CVE) and Common Weakness
Enumeration (CWE) data sources and annotated using Wikidata and the SEmantic
Processing of Security Event Streams CyberSecurity Knowledge Graph (SEPSES
CSKG). Along with the dataset, all the code is publicly released. This dataset
is made available to the research community in the context of the SemTab
challenge on Tabular to Knowledge Graph Matching. This challenge aims to
evaluate the performance of several STI based on open source LLMs. Preliminary
evaluation, serving as baseline, was conducted using Falcon3-7b-instruct and
Mistral-7B-Instruct, two open source LLMs and GPT-4o mini one closed source
LLM.

</details>


### [213] [The Station: An Open-World Environment for AI-Driven Discovery](https://arxiv.org/abs/2511.06309)
*Stephen Chung,Wenyu Du*

Main category: cs.AI

TL;DR: STATION是一个开放世界多智能体环境，模拟微型科学生态系统。智能体可以进行长期科学探索，包括阅读同行论文、提出假设、提交代码、执行分析和发表结果，无需中央协调系统。


<details>
  <summary>Details</summary>
Motivation: 旨在创建一个自主科学发现的新范式，超越传统的刚性优化方法，通过开放世界环境中的涌现行为驱动科学进步。

Method: 利用扩展上下文窗口，让智能体在STATION环境中自由选择行动，发展自己的叙事，进行独立研究并与同行互动。

Result: 在数学、计算生物学和机器学习等多个基准测试中达到新的最先进性能，特别是在圆包装问题上超越AlphaEvolve，并涌现出新的方法如密度自适应scRNA-seq批次整合算法。

Conclusion: STATION代表了迈向由开放世界环境中涌现行为驱动的自主科学发现的第一步，开创了超越刚性优化的新范式。

Abstract: We introduce the STATION, an open-world multi-agent environment that models a
miniature scientific ecosystem. Leveraging their extended context windows,
agents in the Station can engage in long scientific journeys that include
reading papers from peers, formulating hypotheses, submitting code, performing
analyses, and publishing results. Importantly, there is no centralized system
coordinating their activities - agents are free to choose their own actions and
develop their own narratives within the Station. Experiments demonstrate that
AI agents in the Station achieve new state-of-the-art performance on a wide
range of benchmarks, spanning from mathematics to computational biology to
machine learning, notably surpassing AlphaEvolve in circle packing. A rich
tapestry of narratives emerges as agents pursue independent research, interact
with peers, and build upon a cumulative history. From these emergent
narratives, novel methods arise organically, such as a new density-adaptive
algorithm for scRNA-seq batch integration. The Station marks a first step
towards autonomous scientific discovery driven by emergent behavior in an
open-world environment, representing a new paradigm that moves beyond rigid
optimization.

</details>


### [214] [ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning](https://arxiv.org/abs/2511.06316)
*MD Thamed Bin Zaman Chowdhury,Moazzem Hossain*

Main category: cs.AI

TL;DR: ALIGN是一个视觉语言框架，通过模拟人类空间推理从文本和地图线索推断交通事故坐标，解决了多语言和非结构化新闻环境中传统地理编码工具性能不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 低收入和中等收入国家缺乏准确的位置特定事故数据，现有基于文本的地理编码工具在多语言和非结构化新闻环境中表现不佳，不完整的地点描述和混合的孟加拉语-英语脚本模糊了空间上下文。

Method: ALIGN将大型语言和视觉语言模型集成到多阶段管道中，执行光学字符识别、语言推理和基于网格的空间扫描进行地图级验证，系统评估每个预测位置相对于上下文和视觉证据。

Result: 应用于孟加拉语新闻数据时，ALIGN相比传统地理解析方法表现出持续改进，准确识别了地区和次地区级别的碰撞地点。

Conclusion: 该框架为数据稀缺地区的自动碰撞映射建立了高精度基础，支持基于证据的道路安全政策制定，以及多模态人工智能在交通分析中的更广泛整合。

Abstract: Reliable geospatial information on road accidents is vital for safety
analysis and infrastructure planning, yet most low- and middle-income countries
continue to face a critical shortage of accurate, location-specific crash data.
Existing text-based geocoding tools perform poorly in multilingual and
unstructured news environments, where incomplete place descriptions and mixed
Bangla-English scripts obscure spatial context. To address these limitations,
this study introduces ALIGN (Accident Location Inference through Geo-Spatial
Neural Reasoning)- a vision-language framework that emulates human spatial
reasoning to infer accident coordinates directly from textual and map-based
cues. ALIGN integrates large language and vision-language models within a
multi-stage pipeline that performs optical character recognition, linguistic
reasoning, and map-level verification through grid-based spatial scanning. The
framework systematically evaluates each predicted location against contextual
and visual evidence, ensuring interpretable, fine-grained geolocation outcomes
without requiring model retraining. Applied to Bangla-language news data, ALIGN
demonstrates consistent improvements over traditional geoparsing methods,
accurately identifying district and sub-district-level crash sites. Beyond its
technical contribution, the framework establishes a high accuracy foundation
for automated crash mapping in data-scarce regions, supporting evidence-driven
road-safety policymaking and the broader integration of multimodal artificial
intelligence in transportation analytics. The code for this paper is
open-source and available at: https://github.com/Thamed-Chowdhury/ALIGN

</details>


### [215] [LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation](https://arxiv.org/abs/2511.06346)
*Liya Zhu,Peizhuang Cong,Aowei Ji,Wenya Wu,Jiani Hou,Chunjie Wu,Xiang Gao,Jingkai Liu,Zhou Huan,Xuelei Sun,Yang Yang,Jianpeng Jiao,Liang Hu,Xinjie Chen,Jiashuo Liu,Jingzhe Ding,Tong Yang,Zaiyuan Wang,Ge Zhang,Wenhao Huang*

Main category: cs.AI

TL;DR: LPFQA是一个基于长尾知识的专业问答基准，从20个学术和工业领域的真实专业论坛构建，包含502个基于实践专业知识的任务，旨在更真实地评估大语言模型的专业能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准数据集往往关注简化任务或人工场景，忽略了长尾知识和真实世界应用的复杂性，难以准确评估大语言模型的真实能力。

Method: 从20个学术和工业领域的真实专业论坛构建数据集，包含502个基于实践专业知识的任务，采用细粒度评估维度（知识深度、推理、术语理解、上下文分析）、分层难度结构、真实专业场景建模和跨学科知识整合。

Result: 在12个主流大语言模型上的评估显示，在专业推理任务中存在显著的性能差异。

Conclusion: LPFQA为推进大语言模型评估和指导未来模型开发提供了一个稳健、真实且具有区分度的基准。

Abstract: Large Language Models (LLMs) have made rapid progress in reasoning, question
answering, and professional applications; however, their true capabilities
remain difficult to evaluate using existing benchmarks. Current datasets often
focus on simplified tasks or artificial scenarios, overlooking long-tail
knowledge and the complexities of real-world applications. To bridge this gap,
we propose LPFQA, a long-tail knowledge-based benchmark derived from authentic
professional forums across 20 academic and industrial fields, covering 502
tasks grounded in practical expertise. LPFQA introduces four key innovations:
fine-grained evaluation dimensions that target knowledge depth, reasoning,
terminology comprehension, and contextual analysis; a hierarchical difficulty
structure that ensures semantic clarity and unique answers; authentic
professional scenario modeling with realistic user personas; and
interdisciplinary knowledge integration across diverse domains. We evaluated 12
mainstream LLMs on LPFQA and observed significant performance disparities,
especially in specialized reasoning tasks. LPFQA provides a robust, authentic,
and discriminative benchmark for advancing LLM evaluation and guiding future
model development.

</details>


### [216] [What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models](https://arxiv.org/abs/2511.06380)
*Chen He,Xun Jiang,Lei Wang,Hao Yang,Chong Peng,Peng Yan,Fumin Shen,Xing Xu*

Main category: cs.AI

TL;DR: 论文发现LLMs在复杂领域推理中存在"回声反射"问题，即反思阶段机械重复早期推理而非产生新见解，并提出AEPO强化学习方法来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在数学推理中表现优异，但在涉及复杂领域知识的任务中，反思阶段无法产生新颖见解，而是机械重复早期推理步骤，这种现象被称为"回声反射"。

Method: 提出自适应熵策略优化(AEPO)方法，包含两个主要组件：反思感知信息过滤(量化认知信息流，防止最终答案受早期不良认知信息影响)和自适应熵优化(动态平衡不同推理阶段的探索与利用)。

Result: 大量实验表明，AEPO在多样化基准测试中始终优于主流强化学习基线方法，达到最先进的性能。

Conclusion: AEPO方法通过控制信息流和促进反思多样性，有效解决了LLMs在复杂领域推理中的"回声反射"问题，提升了推理性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
a wide range of reasoning tasks. Recent methods have further improved LLM
performance in complex mathematical reasoning. However, when extending these
methods beyond the domain of mathematical reasoning to tasks involving complex
domain-specific knowledge, we observe a consistent failure of LLMs to generate
novel insights during the reflection stage. Instead of conducting genuine
cognitive refinement, the model tends to mechanically reiterate earlier
reasoning steps without introducing new information or perspectives, a
phenomenon referred to as "Echo Reflection". We attribute this behavior to two
key defects: (1) Uncontrollable information flow during response generation,
which allows premature intermediate thoughts to propagate unchecked and distort
final decisions; (2) Insufficient exploration of internal knowledge during
reflection, leading to repeating earlier findings rather than generating new
cognitive insights. Building on these findings, we proposed a novel
reinforcement learning method termed Adaptive Entropy Policy Optimization
(AEPO). Specifically, the AEPO framework consists of two major components: (1)
Reflection-aware Information Filtration, which quantifies the cognitive
information flow and prevents the final answer from being affected by earlier
bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically
balances exploration and exploitation across different reasoning stages,
promoting both reflective diversity and answer correctness. Extensive
experiments demonstrate that AEPO consistently achieves state-of-the-art
performance over mainstream reinforcement learning baselines across diverse
benchmarks.

</details>


### [217] [SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization](https://arxiv.org/abs/2511.06411)
*Zhi Zheng,Wee Sun Lee*

Main category: cs.AI

TL;DR: 本文提出了SofT-GRPO算法，通过将Gumbel噪声注入logits、使用Gumbel-Softmax技术和重参数化技巧，成功将强化学习应用于软思维推理模式，使LLM在Pass@32上的平均准确率提升了2.19%。


<details>
  <summary>Details</summary>
Motivation: 软思维推理模式在某些场景下优于传统的离散token链式思维推理，但将强化学习应用于软思维模式存在挑战，因为难以向软思维token注入随机性并相应更新策略。现有方法在结合软思维与GRPO时通常表现不如离散token GRPO。

Method: 提出SofT-GRPO算法：向logits注入Gumbel噪声，使用Gumbel-Softmax技术避免软思维token超出预训练嵌入空间，并在策略梯度中利用重参数化技巧。

Result: 在1.5B到7B参数的基LLM上进行实验，SofT-GRPO使软思维LLM在Pass@1上略微优于离散token GRPO（平均准确率+0.13%），在Pass@32上显著提升（平均准确率+2.19%）。

Conclusion: SofT-GRPO成功解锁了软思维推理的潜力，为将强化学习应用于软思维模式提供了有效解决方案。

Abstract: The soft-thinking paradigm for Large Language Model (LLM) reasoning can
outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in
some scenarios, underscoring its research and application value. However, while
the discrete-token CoT reasoning pattern can be reinforced through policy
optimization algorithms such as group relative policy optimization (GRPO),
extending the soft-thinking pattern with Reinforcement Learning (RL) remains
challenging. This difficulty stems from the complexities of injecting
stochasticity into soft-thinking tokens and updating soft-thinking policies
accordingly. As a result, previous attempts to combine soft-thinking with GRPO
typically underperform their discrete-token GRPO counterparts. To fully unlock
the potential of soft-thinking, this paper presents a novel policy optimization
algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning
pattern. SofT-GRPO injects the Gumbel noise into logits, employs the
Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained
embedding space, and leverages the reparameterization trick in policy gradient.
We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and
results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly
outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while
exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes
and weights are available on https://github.com/zz1358m/SofT-GRPO-master

</details>


### [218] [MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models](https://arxiv.org/abs/2511.06419)
*Jingyu Hu,Shu Yang,Xilin Gong,Hongming Wang,Weiru Liu,Di Wang*

Main category: cs.AI

TL;DR: MONICA是一个监控引导的校准框架，用于在推理步骤层面监控和减轻大型推理模型的奉承行为，无需模型生成完整答案即可实时检测和抑制奉承倾向。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在奉承行为，倾向于同意用户的错误信念和遵循错误信息，这削弱了模型可靠性并带来社会风险。现有方法主要基于最终答案进行判断和修正，无法理解奉承行为在推理过程中的发展。

Method: 提出MONICA框架，包含奉承监控器和校准器。监控器在响应生成过程中实时监控奉承漂移分数，校准器在分数超过预设阈值时动态抑制奉承行为。

Result: 在12个数据集和3个大型推理模型上的广泛实验表明，该方法有效减少了中间推理步骤和最终答案中的奉承行为，带来了稳健的性能提升。

Conclusion: MONICA框架能够有效监控和减轻大型推理模型的奉承行为，在推理步骤层面实现实时干预，提高模型的可靠性和独立性。

Abstract: Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models
tend to agree with users' incorrect beliefs and follow misinformation rather
than maintain independent reasoning. This behavior undermines model reliability
and poses societal risks. Mitigating LRM sycophancy requires monitoring how
this sycophancy emerges during the reasoning trajectory; however, current
methods mainly focus on judging based on final answers and correcting them,
without understanding how sycophancy develops during reasoning processes. To
address this limitation, we propose MONICA, a novel Monitor-guided Calibration
framework that monitors and mitigates sycophancy during model inference at the
level of reasoning steps, without requiring the model to finish generating its
complete answer. MONICA integrates a sycophantic monitor that provides
real-time monitoring of sycophantic drift scores during response generation
with a calibrator that dynamically suppresses sycophantic behavior when scores
exceed predefined thresholds. Extensive experiments across 12 datasets and 3
LRMs demonstrate that our method effectively reduces sycophantic behavior in
both intermediate reasoning steps and final answers, yielding robust
performance improvements.

</details>


### [219] [GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets](https://arxiv.org/abs/2511.06471)
*Jingtao Tang,Hang Ma*

Main category: cs.AI

TL;DR: GHOST是一个分层框架，用于解决图凸集旅行商问题(GCS-TSP)，通过结合组合路径搜索和凸轨迹优化，在保证最优性的同时实现高效求解。


<details>
  <summary>Details</summary>
Motivation: 传统TSP方法无法处理GCS-TSP问题，因为边成本取决于通过凸区域的具体轨迹，而非固定值。需要开发新方法来解决这一挑战。

Method: GHOST采用分层框架，在GCS诱导的完全图上系统探索路径，使用抽象路径展开算法计算可接受下界，指导高层(路径)和低层(可行GCS路径)的最佳优先搜索。

Result: 实验表明GHOST比统一混合整数凸规划基线快几个数量级，并能处理涉及高阶连续性约束和不完整GCS的复杂轨迹规划问题。

Conclusion: GHOST为GCS-TSP提供了最优且高效的解决方案，通过强剪枝能力避免不必要的凸优化调用，并提供了时间关键场景的有界次优变体。

Abstract: We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP)
defined over a Graph of Convex Sets (GCS) -- a powerful representation for
trajectory planning that decomposes the configuration space into convex regions
connected by a sparse graph. In this setting, edge costs are not fixed but
depend on the specific trajectory selected through each convex region, making
classical TSP methods inapplicable. We introduce GHOST, a hierarchical
framework that optimally solves the GCS-TSP by combining combinatorial tour
search with convex trajectory optimization. GHOST systematically explores tours
on a complete graph induced by the GCS, using a novel abstract-path-unfolding
algorithm to compute admissible lower bounds that guide best-first search at
both the high level (over tours) and the low level (over feasible GCS paths
realizing the tour). These bounds provide strong pruning power, enabling
efficient search while avoiding unnecessary convex optimization calls. We prove
that GHOST guarantees optimality and present a bounded-suboptimal variant for
time-critical scenarios. Experiments show that GHOST is orders-of-magnitude
faster than unified mixed-integer convex programming baselines for simple cases
and uniquely handles complex trajectory planning problems involving high-order
continuity constraints and an incomplete GCS.

</details>


### [220] [FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis](https://arxiv.org/abs/2511.06522)
*Jan Ondras,Marek Šuppa*

Main category: cs.AI

TL;DR: FractalBench是一个评估AI系统从图像中合成分形程序能力的基准测试，测试了GPT-4o、Claude 3.7 Sonnet等领先多模态大模型，结果显示虽然76%的模型能生成有效代码，但只有4%能正确捕获数学结构。


<details>
  <summary>Details</summary>
Motivation: 研究多模态AI系统是否具备从视觉模式中抽象符号规则的能力，即从有限推断无限的能力，分形提供了理想的测试案例。

Method: 使用FractalBench基准测试，包含12个经典分形，要求模型生成可执行的Python代码来重现分形，实现客观评估。

Result: 结果显示显著脱节：76%的模型生成语法有效的代码，但只有4%正确捕获数学结构。模型在处理几何变换时表现较好（Koch曲线：17-21%），但在分支递归方面失败（树形分形：<2%）。

Conclusion: FractalBench提供了一个抗污染的视觉-数学推理诊断工具，揭示了AI系统在数学抽象方面的根本差距。

Abstract: Mathematical reasoning requires abstracting symbolic rules from visual
patterns -- inferring the infinite from the finite. We investigate whether
multimodal AI systems possess this capability through FractalBench, a benchmark
evaluating fractal program synthesis from images. Fractals provide ideal test
cases: Iterated Function Systems with only a few contraction maps generate
complex self-similar patterns through simple recursive rules, requiring models
to bridge visual perception with mathematical abstraction. We evaluate four
leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL
-- on 12 canonical fractals. Models must generate executable Python code
reproducing the fractal, enabling objective evaluation. Results reveal a
striking disconnect: 76% generate syntactically valid code but only 4% capture
mathematical structure. Success varies systematically -- models handle
geometric transformations (Koch curves: 17-21%) but fail at branching recursion
(trees: <2%), revealing fundamental gaps in mathematical abstraction.
FractalBench provides a contamination-resistant diagnostic for
visual-mathematical reasoning and is available at
https://github.com/NaiveNeuron/FractalBench

</details>


### [221] [GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization](https://arxiv.org/abs/2511.06618)
*Moriya Dechtiar,Daniel Martin Katz,Mari Sundaresan,Sylvain Jaume,Hongming Wang*

Main category: cs.AI

TL;DR: 本文提出了一种将法律合同转化为结构化语义图的新框架，通过强化学习驱动的LLM方法自动提取合同实体和关系，实现合同审查和分析的自动化。


<details>
  <summary>Details</summary>
Motivation: 合同是复杂的文档，具有详细的形式结构、显性和隐性依赖关系以及丰富的语义内容。手动起草和检查合同既繁琐又容易出错，因此需要简化和自动化合同审查与分析任务。

Method: 引入详细的ontology将核心法律合同元素映射到图论中的节点和边，提出基于强化学习的LLM框架GRAPH-GRPO-LEX，结合LLM和带组相对策略优化的强化学习，应用精心设计的图度量奖励函数。

Result: 该方法能够自动识别条款间的直接关系，甚至发现隐藏的依赖关系。引入的门控GRPO方法显示出强大的学习信号，可以将合同分析从线性手动阅读过程转变为易于可视化的图。

Conclusion: 该框架为合同分析提供了更动态的方法，包括为类似软件工程中实践的合同linting奠定基础，实现了合同审查和分析的自动化转型。

Abstract: Contracts are complex documents featuring detailed formal structures,
explicit and implicit dependencies and rich semantic content. Given these
document properties, contract drafting and manual examination of contracts have
proven to be both arduous and susceptible to errors. This work aims to simplify
and automate the task of contract review and analysis using a novel framework
for transforming legal contracts into structured semantic graphs, enabling
computational analysis and data-driven insights. We introduce a detailed
ontology mapping core legal contract elements to their graph-theoretic
equivalents of nodes and edges. We then present a reinforcement learning based
Large Language Model (LLM) framework for segmentation and extraction of
entities and relationships from contracts. Our method, GRAPH-GRPO-LEX,
incorporates both LLMs and reinforcement learning with group relative policy
optimization (GRPO). By applying a carefully drafted reward function of graph
metrics, we demonstrate the ability to automatically identify direct
relationships between clauses, and even uncover hidden dependencies. Our
introduction of the gated GRPO approach shows a strong learning signal and can
move contract analysis from a linear, manual reading process to an easily
visualized graph. This allows for a more dynamic analysis, including building
the groundwork for contract linting similar to what is now practiced in
software engineering.

</details>


### [222] [MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning](https://arxiv.org/abs/2511.06805)
*Jinhao Chen,Zhen Yang,Jianxin Shi,Tianyu Wo,Jie Tang*

Main category: cs.AI

TL;DR: 提出MathSE框架，通过推理-反思-奖励的迭代循环来增强多模态大语言模型的数学推理能力，超越传统一次性微调方法。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在复杂数学推理任务中存在困难，传统方法依赖教师模型蒸馏的静态数据集，限制了模型适应新问题和深度泛化的能力。

Method: 提出MathSE框架，通过迭代微调结合推理路径和结果奖励模型的反馈，实现模型的自我进化。

Result: 在多个挑战性基准测试中表现优异，在MathVL-test上超越了领先的开源多模态数学推理模型QVQ。

Conclusion: MathSE框架通过迭代优化机制有效提升了MLLMs的数学推理能力，为复杂推理任务提供了新的解决方案。

Abstract: Multimodal large language models (MLLMs) have demonstrated remarkable
capabilities in vision-language answering tasks. Despite their strengths, these
models often encounter challenges in achieving complex reasoning tasks such as
mathematical problem-solving. Previous works have focused on fine-tuning on
specialized mathematical datasets. However, these datasets are typically
distilled directly from teacher models, which capture only static reasoning
patterns and leaving substantial gaps compared to student models. This reliance
on fixed teacher-derived datasets not only restricts the model's ability to
adapt to novel or more intricate questions that extend beyond the confines of
the training data, but also lacks the iterative depth needed for robust
generalization. To overcome these limitations, we propose \textbf{\method}, a
\textbf{Math}ematical \textbf{S}elf-\textbf{E}volving framework for MLLMs. In
contrast to traditional one-shot fine-tuning paradigms, \method iteratively
refines the model through cycles of inference, reflection, and reward-based
feedback. Specifically, we leverage iterative fine-tuning by incorporating
correct reasoning paths derived from previous-stage inference and integrating
reflections from a specialized Outcome Reward Model (ORM). To verify the
effectiveness of \method, we evaluate it on a suite of challenging benchmarks,
demonstrating significant performance gains over backbone models. Notably, our
experimental results on MathVL-test surpass the leading open-source multimodal
mathematical reasoning model QVQ. Our code and models are available at
\texttt{https://zheny2751\allowbreak-dotcom.github.io/\allowbreak
MathSE.github.io/}.

</details>


### [223] [Proceedings of the 2025 XCSP3 Competition](https://arxiv.org/abs/2511.06918)
*Gilles Audemard,Christophe Lecoutre,Emmanuel Lonca*

Main category: cs.AI

TL;DR: 2025年XCSP3竞赛论文集，包含在CP'25会议上展示的约束求解器竞赛结果


<details>
  <summary>Details</summary>
Motivation: 记录和展示2025年XCSP3约束求解器竞赛的成果，促进约束编程领域的发展

Method: 通过竞赛形式收集和评估各种约束求解器的性能表现

Result: 在CP'25会议上展示了竞赛结果，汇集了各参赛求解器的表现数据

Conclusion: 该论文集为约束求解器的发展提供了重要参考，推动了约束编程技术的进步

Abstract: This document represents the proceedings of the 2025 XCSP3 Competition. The
results of this competition of constraint solvers were presented at CP'25 (31st
International Conference on Principles and Practice of Constraint Programming).

</details>


### [224] [Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and Curriculum Learning](https://arxiv.org/abs/2511.07061)
*Xinran Li,Xiujuan Xu,Jiaqi Qiao,Yu Liu*

Main category: cs.AI

TL;DR: PRC-Emo是一个新的对话情感识别训练框架，结合提示工程、演示检索和课程学习，旨在提升大语言模型在对话中感知情绪的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在对话情感识别方面显示出潜力，但它们在捕捉显性和隐性情绪之间的内在联系方面能力有限，需要更有效的训练方法来提升情绪理解能力。

Method: 设计了基于显性和隐性情绪线索的情感敏感提示模板；构建了首个专门的ERC演示检索库，包含数据集样本和LLM生成的高质量对话示例；在LoRA微调过程中引入课程学习策略，根据说话者间情绪变化的权重分配难度级别。

Result: 在IEMOCAP和MELD两个基准数据集上的实验结果表明，该方法实现了新的最先进性能，证明了其在提升基于LLM的情绪理解方面的有效性和泛化能力。

Conclusion: PRC-Emo框架通过整合提示工程、演示检索和课程学习，显著提升了大语言模型在对话情感识别中的表现，为改进LLM的情绪理解能力提供了有效解决方案。

Abstract: Emotion Recognition in Conversation (ERC) is a crucial task for understanding
human emotions and enabling natural human-computer interaction. Although Large
Language Models (LLMs) have recently shown great potential in this field, their
ability to capture the intrinsic connections between explicit and implicit
emotions remains limited. We propose a novel ERC training framework, PRC-Emo,
which integrates Prompt engineering, demonstration Retrieval, and Curriculum
learning, with the goal of exploring whether LLMs can effectively perceive
emotions in conversational contexts. Specifically, we design emotion-sensitive
prompt templates based on both explicit and implicit emotional cues to better
guide the model in understanding the speaker's psychological states. We
construct the first dedicated demonstration retrieval repository for ERC, which
includes training samples from widely used datasets, as well as high-quality
dialogue examples generated by LLMs and manually verified. Moreover, we
introduce a curriculum learning strategy into the LoRA fine-tuning process,
incorporating weighted emotional shifts between same-speaker and
different-speaker utterances to assign difficulty levels to dialogue samples,
which are then organized in an easy-to-hard training sequence. Experimental
results on two benchmark datasets-- IEMOCAP and MELD --show that our method
achieves new state-of-the-art (SOTA) performance, demonstrating the
effectiveness and generalizability of our approach in improving LLM-based
emotional understanding.

</details>


### [225] [Improving Region Representation Learning from Urban Imagery with Noisy Long-Caption Supervision](https://arxiv.org/abs/2511.07062)
*Yimei Zhang,Guojiang Shen,Kaili Ning,Tongwei Ren,Xuebo Qiu,Mengmeng Wang,Xiangjie Kong*

Main category: cs.AI

TL;DR: UrbanLN是一个新颖的预训练框架，通过长文本感知和噪声抑制来改进城市区域表示学习，解决了细粒度视觉特征与长文本对齐困难以及LLM生成描述中噪声的问题。


<details>
  <summary>Details</summary>
Motivation: 城市视觉外观作为其"肖像"，蕴含潜在的社会经济和环境特征。现有方法利用LLM将文本知识融入基于图像的城市区域表示学习，但面临细粒度视觉特征与长文本对齐困难，以及LLM生成描述中噪声导致知识融合效果不佳的挑战。

Method: 提出信息保留拉伸插值策略对齐长文本与细粒度视觉语义；采用双级优化策略：数据级通过多模型协作自动生成多样化可靠描述，模型级使用基于动量的自蒸馏机制生成稳定伪目标，在噪声条件下实现鲁棒的跨模态学习。

Result: 在四个真实世界城市和各种下游任务上的广泛实验表明，UrbanLN具有优越性能。

Conclusion: UrbanLN通过长文本感知和噪声抑制有效改进了城市区域表示学习，在复杂城市场景中实现了更好的跨模态对齐和知识融合。

Abstract: Region representation learning plays a pivotal role in urban computing by
extracting meaningful features from unlabeled urban data. Analogous to how
perceived facial age reflects an individual's health, the visual appearance of
a city serves as its ``portrait", encapsulating latent socio-economic and
environmental characteristics. Recent studies have explored leveraging Large
Language Models (LLMs) to incorporate textual knowledge into imagery-based
urban region representation learning. However, two major challenges remain:
i)~difficulty in aligning fine-grained visual features with long captions, and
ii) suboptimal knowledge incorporation due to noise in LLM-generated captions.
To address these issues, we propose a novel pre-training framework called
UrbanLN that improves Urban region representation learning through Long-text
awareness and Noise suppression. Specifically, we introduce an
information-preserved stretching interpolation strategy that aligns long
captions with fine-grained visual semantics in complex urban scenes. To
effectively mine knowledge from LLM-generated captions and filter out noise, we
propose a dual-level optimization strategy. At the data level, a multi-model
collaboration pipeline automatically generates diverse and reliable captions
without human intervention. At the model level, we employ a momentum-based
self-distillation mechanism to generate stable pseudo-targets, facilitating
robust cross-modal learning under noisy conditions. Extensive experiments
across four real-world cities and various downstream tasks demonstrate the
superior performance of our UrbanLN.

</details>


### [226] [Increasing AI Explainability by LLM Driven Standard Processes](https://arxiv.org/abs/2511.07083)
*Marc Jansen,Marcel Pehlke*

Main category: cs.AI

TL;DR: 提出了一种通过将大型语言模型嵌入标准化分析流程来提高AI系统可解释性的方法，将LLM推理转化为透明可审计的决策轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统可解释AI方法主要关注特征归因或事后解释，缺乏将LLM推理过程透明化的系统方法。

Method: 将LLM集成到定义好的决策模型中，包括问题-选项-标准(QOC)、敏感性分析、博弈论和风险管理等，采用分层架构分离LLM推理空间和可解释过程空间。

Result: 实证评估显示系统能够在去中心化治理、系统分析和战略推理等场景中复现人类水平的决策逻辑。

Conclusion: LLM驱动的标准流程为可靠、可解释和可验证的AI支持决策提供了基础。

Abstract: This paper introduces an approach to increasing the explainability of
artificial intelligence (AI) systems by embedding Large Language Models (LLMs)
within standardized analytical processes. While traditional explainable AI
(XAI) methods focus on feature attribution or post-hoc interpretation, the
proposed framework integrates LLMs into defined decision models such as
Question-Option-Criteria (QOC), Sensitivity Analysis, Game Theory, and Risk
Management. By situating LLM reasoning within these formal structures, the
approach transforms opaque inference into transparent and auditable decision
traces. A layered architecture is presented that separates the reasoning space
of the LLM from the explainable process space above it. Empirical evaluations
show that the system can reproduce human-level decision logic in decentralized
governance, systems analysis, and strategic reasoning contexts. The results
suggest that LLM-driven standard processes provide a foundation for reliable,
interpretable, and verifiable AI-supported decision making.

</details>


### [227] [Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts](https://arxiv.org/abs/2511.07090)
*Marcel Rojahn,Marcus Grum*

Main category: cs.AI

TL;DR: 本文提出了一个统一的绿色AI定义，建立了五阶段生命周期框架，将能源、碳、水和隐含影响作为首要考虑因素，并制定了结合估算模型和直接测量的校准测量框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI生命周期中的负担（能源、碳、水、隐含影响）缺乏统一透明的测量标准，云提供商工具存在异质性且常忽略水和价值链影响，限制了可比性和可重复性。

Method: 建立五阶段生命周期映射到LCA阶段，通过PDCA循环进行治理决策，系统化硬件和系统级策略，定义校准测量框架结合估算模型和直接测量。

Result: 提出了可操作的、基于证据的指导框架，使研究人员、从业者和政策制定者能够进行可重复的、提供商无关的比较。

Conclusion: 通过结合定义、生命周期流程、硬件策略和校准测量，为绿色AI提供了全面的解决方案，解决了多维负担问题。

Abstract: Across the Artificial Intelligence (AI) lifecycle - from hardware to
development, deployment, and reuse - burdens span energy, carbon, water, and
embodied impacts. Cloud provider tools improve transparency but remain
heterogeneous and often omit water and value chain effects, limiting
comparability and reproducibility. Addressing these multi dimensional burdens
requires a lifecycle approach linking phase explicit mapping with system levers
(hardware, placement, energy mix, cooling, scheduling) and calibrated
measurement across facility, system, device, and workload levels. This article
(i) establishes a unified, operational definition of Green AI distinct from
Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle
Assessment (LCA) stages, making energy, carbon, water, and embodied impacts
first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles
with decision gateways; (iv) systematizes hardware and system level strategies
across the edge cloud continuum to reduce embodied burdens; and (v) defines a
calibrated measurement framework combining estimator models with direct
metering to enable reproducible, provider agnostic comparisons. Combining
definition, lifecycle processes, hardware strategies, and calibrated
measurement, this article offers actionable, evidence based guidance for
researchers, practitioners, and policymakers.

</details>


### [228] [Data Complexity of Querying Description Logic Knowledge Bases under Cost-Based Semantics](https://arxiv.org/abs/2511.07095)
*Meghyn Bienvenu,Quentin Manière*

Main category: cs.AI

TL;DR: 本文研究了不一致加权描述逻辑知识库在基于成本语义下的数据复杂性，重点关注包含逆角色和角色包含的DL-Lite方言，改进了现有下界并确定了最优成本确定答案语义的精确复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注EL⊥到ALCO之间的描述逻辑，且所有结果都显示基于成本的语义是难处理的。本文旨在扩展研究范围到包含逆角色和角色包含的DL-Lite方言，并寻找可能的易处理情况。

Method: 通过为每个解释分配基于违反公理和断言权重的成本，考虑具有最优或有界成本的所有（或某些）解释来确定确定和可能查询答案。使用一阶重写技术分析数据复杂性。

Result: 改进了多个下界并确定了最优成本确定答案语义的精确复杂度。最令人惊讶的结果是：对于DL-Lite^H_bool本体和固定成本边界，实例查询的确定答案和连接查询的可能答案可以通过一阶重写计算，达到最低可能的数据复杂度(TC0)。

Conclusion: 本文显著扩展了基于成本语义的数据复杂性分析范围，首次发现了在特定条件下（DL-Lite^H_bool本体和固定成本边界）可以实现易处理的查询计算，突破了现有研究认为基于成本语义总是难处理的认知。

Abstract: In this paper, we study the data complexity of querying inconsistent weighted
description logic (DL) knowledge bases under recently-introduced cost-based
semantics. In a nutshell, the idea is to assign each interpretation a cost
based upon the weights of the violated axioms and assertions, and certain and
possible query answers are determined by considering all (resp. some)
interpretations having optimal or bounded cost. Whereas the initial study of
cost-based semantics focused on DLs between $\mathcal{EL}_\bot$ and
$\mathcal{ALCO}$, we consider DLs that may contain inverse roles and role
inclusions, thus covering prominent DL-Lite dialects. Our data complexity
analysis goes significantly beyond existing results by sharpening several lower
bounds and pinpointing the precise complexity of optimal-cost certain answer
semantics (no non-trivial upper bound was known). Moreover, while all existing
results show the intractability of cost-based semantics, our most challenging
and surprising result establishes that if we consider
$\text{DL-Lite}^\mathcal{H}_\mathsf{bool}$ ontologies and a fixed cost bound,
certain answers for instance queries and possible answers for conjunctive
queries can be computed using first-order rewriting and thus enjoy the lowest
possible data complexity ($\mathsf{TC}_0$).

</details>


### [229] [Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture and Focalized Optimization](https://arxiv.org/abs/2511.07098)
*Yuanshao Zhu,Xiangyu Zhao,Zijian Zhang,Xuetao Wei,James Jianqiao Yu*

Main category: cs.AI

TL;DR: 提出PLGF模型解决城市流量细粒度推理问题，通过轻量级架构和自适应优化方法，在显著减小模型规模的同时提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有城市流量推理方法面临两个关键挑战：过度参数化模型的计算成本过高，以及传统损失函数在高度偏态分布的流量数据上表现不佳。

Method: 提出PLGF架构采用渐进式局部-全局融合策略，同时引入DualFocal Loss损失函数，结合双空间监督和难度感知聚焦机制。

Result: 在4个真实场景上的实验验证了方法的有效性，PLGF将模型大小减少高达97%，在可比参数预算下准确率提升超过10%。

Conclusion: 该方法在保持最先进性能的同时显著提升了计算效率，为城市流量推理提供了高效的解决方案。

Abstract: Fine-grained urban flow inference is crucial for urban planning and
intelligent transportation systems, enabling precise traffic management and
resource allocation. However, the practical deployment of existing methods is
hindered by two key challenges: the prohibitive computational cost of
over-parameterized models and the suboptimal performance of conventional loss
functions on the highly skewed distribution of urban flows. To address these
challenges, we propose a unified solution that synergizes architectural
efficiency with adaptive optimization. Specifically, we first introduce PLGF, a
lightweight yet powerful architecture that employs a Progressive Local-Global
Fusion strategy to effectively capture both fine-grained details and global
contextual dependencies. Second, we propose DualFocal Loss, a novel function
that integrates dual-space supervision with a difficulty-aware focusing
mechanism, enabling the model to adaptively concentrate on hard-to-predict
regions. Extensive experiments on 4 real-world scenarios validate the
effectiveness and scalability of our method. Notably, while achieving
state-of-the-art performance, PLGF reduces the model size by up to 97% compared
to current high-performing methods. Furthermore, under comparable parameter
budgets, our model yields an accuracy improvement of over 10% against strong
baselines. The implementation is included in the https://github.com/Yasoz/PLGF.

</details>


### [230] [A Theoretical Analysis of Detecting Large Model-Generated Time Series](https://arxiv.org/abs/2511.07104)
*Junji Hou,Junzhou Zhao,Shuo Zhang,Pinghui Wang*

Main category: cs.AI

TL;DR: 本文提出了一种检测时间序列大模型生成合成时间序列的方法，通过理论证明和实证验证了模型生成时间序列在递归预测中会表现出不确定性收缩的特性，并基于此开发了不确定性收缩估计器（UCE）检测器。


<details>
  <summary>Details</summary>
Motivation: 随着数据滥用和伪造风险增加，需要识别时间序列大模型生成的合成时间序列。现有文本生成检测方法不适用于时间序列数据，因为时间序列具有较低信息密度和更平滑的概率分布。

Method: 提出收缩假说：模型生成的时间序列在递归预测中会表现出逐渐减小的不确定性。基于此开发了不确定性收缩估计器（UCE），通过聚合连续前缀的不确定性指标来识别模型生成的时间序列。

Result: 在32个数据集上的广泛实验表明，UCE始终优于最先进的基线方法，为检测模型生成的时间序列提供了可靠且可泛化的解决方案。

Conclusion: 模型生成的时间序列确实表现出不确定性收缩特性，UCE检测器能够有效识别合成时间序列，解决了现有方法在时间序列检测上的局限性。

Abstract: Motivated by the increasing risks of data misuse and fabrication, we
investigate the problem of identifying synthetic time series generated by
Time-Series Large Models (TSLMs) in this work. While there are extensive
researches on detecting model generated text, we find that these existing
methods are not applicable to time series data due to the fundamental modality
difference, as time series usually have lower information density and smoother
probability distributions than text data, which limit the discriminative power
of token-based detectors. To address this issue, we examine the subtle
distributional differences between real and model-generated time series and
propose the contraction hypothesis, which states that model-generated time
series, unlike real ones, exhibit progressively decreasing uncertainty under
recursive forecasting. We formally prove this hypothesis under theoretical
assumptions on model behavior and time series structure. Model-generated time
series exhibit progressively concentrated distributions under recursive
forecasting, leading to uncertainty contraction. We provide empirical
validation of the hypothesis across diverse datasets. Building on this insight,
we introduce the Uncertainty Contraction Estimator (UCE), a white-box detector
that aggregates uncertainty metrics over successive prefixes to identify
TSLM-generated time series. Extensive experiments on 32 datasets show that UCE
consistently outperforms state-of-the-art baselines, offering a reliable and
generalizable solution for detecting model-generated time series.

</details>


### [231] [MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks](https://arxiv.org/abs/2511.07107)
*Liang Shan,Kaicheng Shen,Wen Wu,Zhenyu Ying,Chaochao Lu,Guangze Ye,Liang He*

Main category: cs.AI

TL;DR: MENTOR是一个基于元认知的自我进化框架，用于发现和缓解LLMs在领域任务中的隐式风险。它通过元认知自我评估、动态规则知识图谱生成和激活引导技术，实现了对隐式风险的持续识别和缓解。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs对齐方法主要针对显式风险（如偏见、仇恨言论），但缺乏对领域特定隐式风险的处理，且缺少灵活、可泛化的跨领域框架。

Method: 1. 引入元认知自我评估工具，让LLMs反思潜在价值偏差；2. 基于反思结果动态生成补充规则知识图谱；3. 在推理时使用激活引导技术确保规则遵循。

Result: 在三个垂直领域的防御测试中，MENTOR显著降低了语义攻击成功率，实现了新的隐式风险缓解水平。元认知评估与人类评估者高度一致，且提供更全面深入的分析。

Conclusion: MENTOR框架通过元认知驱动的自我进化机制，有效解决了LLMs在领域任务中的隐式风险问题，提供了一种可泛化、低维护成本的持续安全增强方案。

Abstract: Ensuring the safety and value alignment of large language models (LLMs) is
critical for their deployment. Current alignment efforts primarily target
explicit risks such as bias, hate speech, and violence. However, they often
fail to address deeper, domain-specific implicit risks and lack a flexible,
generalizable framework applicable across diverse specialized fields. Hence, we
proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering
and mitigating implicit Risks in LLMs on Domain Tasks. To address the
limitations of labor-intensive human evaluation, we introduce a novel
metacognitive self-assessment tool. This enables LLMs to reflect on potential
value misalignments in their responses using strategies like perspective-taking
and consequential thinking. We also release a supporting dataset of 9,000 risk
queries spanning education, finance, and management to enhance domain-specific
risk identification. Subsequently, based on the outcomes of metacognitive
reflection, the framework dynamically generates supplementary rule knowledge
graphs that extend predefined static rule trees. This enables models to
actively apply validated rules to future similar challenges, establishing a
continuous self-evolution cycle that enhances generalization by reducing
maintenance costs and inflexibility of static systems. Finally, we employ
activation steering during inference to guide LLMs in following the rules, a
cost-effective method to robustly enhance enforcement across diverse contexts.
Experimental results show MENTOR's effectiveness: In defensive testing across
three vertical domains, the framework substantially reduces semantic attack
success rates, enabling a new level of implicit risk mitigation for LLMs.
Furthermore, metacognitive assessment not only aligns closely with baseline
human evaluators but also delivers more thorough and insightful analysis of
LLMs value alignment.

</details>


### [232] [Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture](https://arxiv.org/abs/2511.07110)
*Tianhao Fu,Xinxin Xu,Weichen Xu,Jue Chen,Ruilong Ren,Bowen Deng,Xinyu Zhao,Jian Cao,Xixin Cao*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型特征解耦的协同做市框架CMM，通过层、任务和数据三个正交维度分解LLM特征，使用多个学生模型协同学习不同维度的简单特征，并引入Hájek-MoE集成模型输出，在四个真实市场数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在金融领域的应用增多，直接使用LLM作为智能体虽然性能显著，但推理速度慢成为瓶颈，且当前研究缺乏针对做市任务的大语言模型蒸馏方法。

Method: 首先提出归一化荧光探针研究LLM特征机制，然后提出CMM框架，在层、任务和数据三个正交维度解耦LLM特征，让多个学生模型分别学习不同维度的简单特征，最后使用Hájek-MoE在核函数生成的公共特征空间中集成各模型输出。

Result: 在四个真实市场数据集上的广泛实验结果表明，CMM在蒸馏方法和基于强化学习的做市策略方面均表现出优越性能。

Conclusion: CMM框架通过解耦LLM特征并协同学习，成功实现了高效的大语言模型知识蒸馏，为金融做市任务提供了新的解决方案。

Abstract: Market making (MM) through Reinforcement Learning (RL) has attracted
significant attention in financial trading. With the development of Large
Language Models (LLMs), more and more attempts are being made to apply LLMs to
financial areas. A simple, direct application of LLM as an agent shows
significant performance. Such methods are hindered by their slow inference
speed, while most of the current research has not studied LLM distillation for
this specific task. To address this, we first propose the normalized
fluorescent probe to study the mechanism of the LLM's feature. Based on the
observation found by our investigation, we propose Cooperative Market Making
(CMM), a novel framework that decouples LLM features across three orthogonal
dimensions: layer, task, and data. Various student models collaboratively learn
simple LLM features along with different dimensions, with each model
responsible for a distinct feature to achieve knowledge distillation.
Furthermore, CMM introduces an H\'{a}jek-MoE to integrate the output of the
student models by investigating the contribution of different models in a
kernel function-generated common feature space. Extensive experimental results
on four real-world market datasets demonstrate the superiority of CMM over the
current distillation method and RL-based market-making strategies.

</details>


### [233] [PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork](https://arxiv.org/abs/2511.07260)
*Hohei Chan,Xinzhi Zhang,Antao Xiang,Weinan Zhang,Mengchen Zhao*

Main category: cs.AI

TL;DR: PADiff是一种基于扩散模型的方法，用于解决ad hoc teamwork中的多模态合作问题，通过整合队友预测信息来适应未知队友，在三个合作环境中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于强化学习的方法往往导致策略坍缩为单一行为，无法捕捉ad hoc teamwork中固有的多模态合作模式，需要开发能够预测和适应未知队友的智能体。

Method: 提出PADiff扩散模型方法，通过将队友的关键预测信息整合到去噪过程中，捕捉智能体的多模态行为，解锁与队友的多样化合作模式。

Result: 在三个合作环境中的广泛实验表明，PADiff显著优于现有的ad hoc teamwork方法。

Conclusion: PADiff通过扩散模型成功解决了ad hoc teamwork中的多模态合作挑战，为与未知队友的协作提供了有效的解决方案。

Abstract: Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen
teammates, which is crucial for many real-world applications. The core
challenge of AHT is to develop an ego agent that can predict and adapt to
unknown teammates on the fly. Conventional RL-based approaches optimize a
single expected return, which often causes policies to collapse into a single
dominant behavior, thus failing to capture the multimodal cooperation patterns
inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach
that captures agent's multimodal behaviors, unlocking its diverse cooperation
modes with teammates. However, standard diffusion models lack the ability to
predict and adapt in highly non-stationary AHT scenarios. To address this
limitation, we propose a novel diffusion-based policy that integrates critical
predictive information about teammates into the denoising process. Extensive
experiments across three cooperation environments demonstrate that PADiff
outperforms existing AHT methods significantly.

</details>


### [234] [AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning](https://arxiv.org/abs/2511.07262)
*Qile Jiang,George Karniadakis*

Main category: cs.AI

TL;DR: AgenticSciML是一个多智能体协作系统，通过10多个专业AI智能体的结构化推理和迭代演化，自动设计和优化科学机器学习解决方案，在多个任务中实现了比单智能体和人工设计基线高达4个数量级的误差降低。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习的设计过程仍依赖专家驱动的研究，需要大量实验和问题特定洞察，缺乏自动化方法。

Method: 采用协作多智能体系统，结合结构化辩论、检索增强方法记忆和集成引导进化搜索，使智能体能够生成和评估关于架构和优化程序的新假设。

Result: 在物理信息学习和算子学习任务中，发现了超越单智能体和人工设计基线的解决方案，误差降低达4个数量级，并产生了自适应专家混合架构、基于分解的PINNs等新颖策略。

Conclusion: AI智能体间的协作推理能够产生涌现的方法创新，为科学计算中的可扩展、透明和自主发现提供了路径。

Abstract: Scientific Machine Learning (SciML) integrates data-driven inference with
physical modeling to solve complex problems in science and engineering.
However, the design of SciML architectures, loss formulations, and training
strategies remains an expert-driven research process, requiring extensive
experimentation and problem-specific insights. Here we introduce AgenticSciML,
a collaborative multi-agent system in which over 10 specialized AI agents
collaborate to propose, critique, and refine SciML solutions through structured
reasoning and iterative evolution. The framework integrates structured debate,
retrieval-augmented method memory, and ensemble-guided evolutionary search,
enabling the agents to generate and assess new hypotheses about architectures
and optimization procedures. Across physics-informed learning and operator
learning tasks, the framework discovers solution methods that outperform
single-agent and human-designed baselines by up to four orders of magnitude in
error reduction. The agents produce novel strategies -- including adaptive
mixture-of-expert architectures, decomposition-based PINNs, and
physics-informed operator learning models -- that do not appear explicitly in
the curated knowledge base. These results show that collaborative reasoning
among AI agents can yield emergent methodological innovation, suggesting a path
toward scalable, transparent, and autonomous discovery in scientific computing.

</details>


### [235] [Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion](https://arxiv.org/abs/2511.07267)
*Chen Han,Yijia Ma,Jin Tan,Wenzhen Zheng,Xijin Tang*

Main category: cs.AI

TL;DR: ED2D是一个基于证据的多智能体辩论框架，不仅用于检测错误信息，还旨在纠正用户信念并阻止错误信息传播。该框架在检测准确性上优于现有基线，其生成的辟谣文本在正确预测时具有与人类专家相当的劝说效果，但在错误分类时可能强化用户误解。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体辩论框架主要关注检测准确性，但忽视了帮助用户理解事实判断背后的推理过程以及培养未来抵御能力的重要性。辩论记录作为透明推理的丰富资源未被充分利用。

Method: 引入ED2D框架，扩展了先前方法，整合了事实证据检索。该框架不仅作为检测工具，更设计为具有说服力的多智能体系统，旨在纠正用户信念并阻止错误信息传播。

Result: ED2D在三个错误信息检测基准测试中优于现有基线。当ED2D做出正确预测时，其生成的辟谣文本具有与人类专家相当的劝说效果；但当错误分类时，其解释可能无意中强化用户的误解，即使与准确的人类解释同时呈现。

Conclusion: 研究结果凸显了部署多智能体辩论系统进行错误信息干预的潜力与潜在风险。开发了公共社区网站以促进透明度、批判性思维和协作事实核查。

Abstract: Multi-agent debate (MAD) frameworks have emerged as promising approaches for
misinformation detection by simulating adversarial reasoning. While prior work
has focused on detection accuracy, it overlooks the importance of helping users
understand the reasoning behind factual judgments and develop future
resilience. The debate transcripts generated during MAD offer a rich but
underutilized resource for transparent reasoning. In this study, we introduce
ED2D, an evidence-based MAD framework that extends previous approach by
incorporating factual evidence retrieval. More importantly, ED2D is designed
not only as a detection framework but also as a persuasive multi-agent system
aimed at correcting user beliefs and discouraging misinformation sharing. We
compare the persuasive effects of ED2D-generated debunking transcripts with
those authored by human experts. Results demonstrate that ED2D outperforms
existing baselines across three misinformation detection benchmarks. When ED2D
generates correct predictions, its debunking transcripts exhibit persuasive
effects comparable to those of human experts; However, when ED2D misclassifies,
its accompanying explanations may inadvertently reinforce users'misconceptions,
even when presented alongside accurate human explanations. Our findings
highlight both the promise and the potential risks of deploying MAD systems for
misinformation intervention. We further develop a public community website to
help users explore ED2D, fostering transparency, critical thinking, and
collaborative fact-checking.

</details>


### [236] [DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas](https://arxiv.org/abs/2511.07338)
*Zhen Wang,Yufan Zhou,Zhongyan Luo,Lyumanshan Ye,Adam Wood,Man Yao,Luoshang Pan*

Main category: cs.AI

TL;DR: DEEPPERSONA是一个可扩展的生成引擎，通过两阶段、分类学指导的方法合成叙事完整的人工角色，显著提升了角色属性的多样性和独特性，并在个性化问答和社会调查中取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的人工角色大多浅薄简单，无法反映真实人类身份的丰富复杂性和多样性，需要开发能够生成更深度、更真实角色的方法。

Method: 采用两阶段方法：首先通过挖掘数千个真实用户与ChatGPT的对话，算法构建最大的人类属性分类学；然后从该分类学中逐步采样属性，条件生成连贯且真实的角色。

Result: 内在评估显示属性多样性提高了32%，角色独特性提高了44%；外在评估中，角色使GPT-4.1-mini的个性化问答准确率平均提高了11.6%，在社会调查中缩小了模拟LLM公民与真实人类响应之间的差距31.7%。

Conclusion: DEEPPERSONA为高保真人类模拟和个性化AI研究提供了一个严谨、可扩展且无需隐私的平台。

Abstract: Simulating human profiles by instilling personas into large language models
(LLMs) is rapidly transforming research in agentic behavioral simulation, LLM
personalization, and human-AI alignment. However, most existing synthetic
personas remain shallow and simplistic, capturing minimal attributes and
failing to reflect the rich complexity and diversity of real human identities.
We introduce DEEPPERSONA, a scalable generative engine for synthesizing
narrative-complete synthetic personas through a two-stage, taxonomy-guided
method. First, we algorithmically construct the largest-ever human-attribute
taxonomy, comprising over hundreds of hierarchically organized attributes, by
mining thousands of real user-ChatGPT conversations. Second, we progressively
sample attributes from this taxonomy, conditionally generating coherent and
realistic personas that average hundreds of structured attributes and roughly 1
MB of narrative text, two orders of magnitude deeper than prior works.
Intrinsic evaluations confirm significant improvements in attribute diversity
(32 percent higher coverage) and profile uniqueness (44 percent greater)
compared to state-of-the-art baselines. Extrinsically, our personas enhance
GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on
average across ten metrics and substantially narrow (by 31.7 percent) the gap
between simulated LLM citizens and authentic human responses in social surveys.
Our generated national citizens reduced the performance gap on the Big Five
personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA
thus provides a rigorous, scalable, and privacy-free platform for high-fidelity
human simulation and personalized AI research.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [237] [Explainable Deep Learning-based Classification of Wolff-Parkinson-White Electrocardiographic Signals](https://arxiv.org/abs/2511.05973)
*Alice Ragonesi,Stefania Fresca,Karli Gillette,Stefan Kurath-Koller,Gernot Plank,Elena Zappon*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的方法，利用虚拟心脏模型生成的大规模合成心电图数据，结合可解释人工智能技术，实现WPW综合征中副传导通路的精确定位。


<details>
  <summary>Details</summary>
Motivation: 传统诊断树方法和机器学习方法在副传导通路定位中存在解剖定位分辨率有限、可解释性差以及数据集小等问题，需要开发更准确、透明的定位方法。

Method: 使用个性化虚拟心脏模型生成大规模生理学真实的合成心电图数据库，训练深度学习模型进行24个心脏区域的副传导通路定位，并集成可解释人工智能方法（Guided Backpropagation、Grad-CAM和Guided Grad-CAM）来解释模型决策。

Result: 模型定位准确率超过95%，敏感性为94.32%，特异性为99.78%。可解释性输出与已知去极化模式进行生理学验证，并引入新指标识别最有信息量的心电图导联，发现V2导联最关键，其次是aVF、V1和aVL导联。

Conclusion: 这项研究展示了将心脏数字孪生与可解释深度学习相结合，能够实现准确、透明且非侵入性的副传导通路定位，具有临床应用潜力。

Abstract: Wolff-Parkinson-White (WPW) syndrome is a cardiac electrophysiology (EP)
disorder caused by the presence of an accessory pathway (AP) that bypasses the
atrioventricular node, faster ventricular activation rate, and provides a
substrate for atrio-ventricular reentrant tachycardia (AVRT). Accurate
localization of the AP is critical for planning and guiding catheter ablation
procedures. While traditional diagnostic tree (DT) methods and more recent
machine learning (ML) approaches have been proposed to predict AP location from
surface electrocardiogram (ECG), they are often constrained by limited
anatomical localization resolution, poor interpretability, and the use of small
clinical datasets. In this study, we present a Deep Learning (DL) model for the
localization of single manifest APs across 24 cardiac regions, trained on a
large, physiologically realistic database of synthetic ECGs generated using a
personalized virtual heart model. We also integrate eXplainable Artificial
Intelligence (XAI) methods, Guided Backpropagation, Grad-CAM, and Guided
Grad-CAM, into the pipeline. This enables interpretation of DL decision-making
and addresses one of the main barriers to clinical adoption: lack of
transparency in ML predictions. Our model achieves localization accuracy above
95%, with a sensitivity of 94.32% and specificity of 99.78%. XAI outputs are
physiologically validated against known depolarization patterns, and a novel
index is introduced to identify the most informative ECG leads for AP
localization. Results highlight lead V2 as the most critical, followed by aVF,
V1, and aVL. This work demonstrates the potential of combining cardiac digital
twins with explainable DL to enable accurate, transparent, and non-invasive AP
localization.

</details>


### [238] [AGRAG: Advanced Graph-based Retrieval-Augmented Generation for LLMs](https://arxiv.org/abs/2511.05549)
*Yubo Wang,Haoyang Li,Fei Teng,Lei Chen*

Main category: cs.LG

TL;DR: AGRAG是一个先进的基于图的检索增强生成框架，通过统计方法构建图避免LLM幻觉，使用MCMI子图生成问题来创建更全面的推理路径，提升LLM的推理能力和答案质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于图的RAG方法面临的三个关键挑战：图构建不准确（由LLM幻觉引起）、推理能力差（缺乏显式推理路径）、答案不充分（LLM推理不足）。

Method: 1) 用基于统计的方法替代LLM实体提取来构建图；2) 将图推理过程建模为最小成本最大影响(MCMI)子图生成问题，并提出贪心算法求解；3) 生成的MCMI子图作为显式推理路径指导LLM。

Result: AGRAG避免了LLM幻觉和错误传播，生成的推理路径更全面（支持复杂图结构如循环），提高了LLM对查询相关内容的关注度，减少了噪声影响。

Conclusion: AGRAG框架通过改进图构建和推理路径生成方法，显著提升了基于图的RAG系统的性能和推理能力，解决了现有方法的局限性。

Abstract: Graph-based retrieval-augmented generation (Graph-based RAG) has demonstrated
significant potential in enhancing Large Language Models (LLMs) with structured
knowledge. However, existing methods face three critical challenges: Inaccurate
Graph Construction, caused by LLM hallucination; Poor Reasoning Ability, caused
by failing to generate explicit reasons telling LLM why certain chunks were
selected; and Inadequate Answering, which only partially answers the query due
to the inadequate LLM reasoning, making their performance lag behind NaiveRAG
on certain tasks. To address these issues, we propose AGRAG, an advanced
graph-based retrieval-augmented generation framework. When constructing the
graph, AGRAG substitutes the widely used LLM entity extraction method with a
statistics-based method, avoiding hallucination and error propagation. When
retrieval, AGRAG formulates the graph reasoning procedure as the Minimum Cost
Maximum Influence (MCMI) subgraph generation problem, where we try to include
more nodes with high influence score, but with less involving edge cost, to
make the generated reasoning paths more comprehensive. We prove this problem to
be NP-hard, and propose a greedy algorithm to solve it. The MCMI subgraph
generated can serve as explicit reasoning paths to tell LLM why certain chunks
were retrieved, thereby making the LLM better focus on the query-related part
contents of the chunks, reducing the impact of noise, and improving AGRAG's
reasoning ability. Furthermore, compared with the simple tree-structured
reasoning paths, our MCMI subgraph can allow more complex graph structures,
such as cycles, and improve the comprehensiveness of the generated reasoning
paths.

</details>


### [239] [DyKAF: Dynamical Kronecker Approximation of the Fisher Information Matrix for Gradient Preconditioning](https://arxiv.org/abs/2511.06477)
*Nikolay Yudin,Ekaterina Grishina,Andrey Veprikov,Alexandr Beznosikov,Maxim Rakhuba*

Main category: cs.LG

TL;DR: DyKAF优化器利用投影器分裂积分器构建有效的预处理器，通过动态Kronecker近似Fisher矩阵，在大型语言模型预训练和微调中优于现有优化器。


<details>
  <summary>Details</summary>
Motivation: 现有方法将权重视为矩阵而非展平向量，使用Kronecker分解形式实现内存高效的Fisher矩阵近似，但构建既高效又准确的近似仍具挑战性，因为最优分解计算资源密集且依赖启发式设计。

Method: 引入投影器分裂积分器来构建有效预处理器，开发DyKAF优化器实现Fisher矩阵的动态Kronecker近似。

Result: DyKAF持续提升Fisher矩阵近似质量，在大型语言模型预训练和微调实验中，在各种评估指标上均优于现有优化器。

Conclusion: 基于投影器分裂积分器的DyKAF方法能够有效构建Fisher矩阵预处理器，在优化器性能方面取得显著改进。

Abstract: Recently, optimizers that explicitly treat weights as matrices, rather than
flattened vectors, have demonstrated their effectiveness. This perspective
naturally leads to structured approximations of the Fisher matrix as
preconditioners, where the matrix view induces a Kronecker-factorized form that
enables memory-efficient representation. However, constructing such
approximations both efficiently and accurately remains an open challenge, since
obtaining the optimal factorization is resource-intensive and practical methods
therefore rely on heuristic design choices. In this work, we introduce a novel
approach that leverages projector-splitting integrators to construct effective
preconditioners. Our optimizer, DyKAF (Dynamical Kronecker Approximation of the
Fisher Matrix), consistently improves the Fisher matrix approximation quality.
Experiments on large language model pre-training and fine-tuning demonstrate
that DyKAF outperforms existing optimizers across a range of evaluation
metrics.

</details>


### [240] [Fast Bayesian Updates via Harmonic Representations](https://arxiv.org/abs/2511.06978)
*Di Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于谐波分析的快速贝叶斯更新统一框架，将贝叶斯更新转化为谱卷积，利用FFT实现O(N log N)复杂度的确定性算法。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯推断中的后验分布计算通常面临计算不可行性，特别是证据积分的挑战。传统方法如MCMC和VI存在可扩展性和效率限制。

Method: 在合适的正交基中表示先验和似然函数，将贝叶斯更新规则转化为谱卷积。引入谱截断方案，对于平滑函数产生高精度有限维近似，将更新简化为循环卷积。

Result: 该方法将计算复杂度从O(N^2)降低到O(N log N)，为平滑且谱衰减的分布提供了严格的数学适用性标准。

Conclusion: 这项工作提供了范式转变，将贝叶斯计算与信号处理联系起来，为广泛问题中的实时顺序推断开辟了新途径。

Abstract: Bayesian inference, while foundational to probabilistic reasoning, is often
hampered by the computational intractability of posterior distributions,
particularly through the challenging evidence integral. Conventional approaches
like Markov Chain Monte Carlo (MCMC) and Variational Inference (VI) face
significant scalability and efficiency limitations. This paper introduces a
novel, unifying framework for fast Bayesian updates by leveraging harmonic
analysis. We demonstrate that representing the prior and likelihood in a
suitable orthogonal basis transforms the Bayesian update rule into a spectral
convolution. Specifically, the Fourier coefficients of the posterior are shown
to be the normalized convolution of the prior and likelihood coefficients. To
achieve computational feasibility, we introduce a spectral truncation scheme,
which, for smooth functions, yields an exceptionally accurate
finite-dimensional approximation and reduces the update to a circular
convolution. This formulation allows us to exploit the Fast Fourier Transform
(FFT), resulting in a deterministic algorithm with O(N log N) complexity -- a
substantial improvement over the O(N^2) cost of naive methods. We establish
rigorous mathematical criteria for the applicability of our method, linking its
efficiency to the smoothness and spectral decay of the involved distributions.
The presented work offers a paradigm shift, connecting Bayesian computation to
signal processing and opening avenues for real-time, sequential inference in a
wide class of problems.

</details>


### [241] [Diversified Flow Matching with Translation Identifiability](https://arxiv.org/abs/2511.05558)
*Sagar Shrestha,Xiao Fu*

Main category: cs.LG

TL;DR: 本文提出了多样化流匹配（DFM），这是一个基于ODE的框架，用于解决多样化分布匹配（DDM）问题。DFM通过定制化的双层优化训练损失、非线性插值和结构重构，实现了翻译可识别性，是首个保证翻译可识别性的基于ODE的方法。


<details>
  <summary>Details</summary>
Motivation: DDM虽然解决了无配对域翻译中的内容错位问题并实现了翻译可识别性，但只能使用GAN实现，存在训练不稳定且无法提供传输轨迹信息的问题。而传输轨迹在单细胞进化分析和机器人路径规划等应用中非常有用。

Method: 提出DFM框架，采用定制化的双层优化训练损失、非线性插值和结构重构，将流匹配（FM）适应到DDM的统一翻译函数要求中。FM学习的是翻译函数的速度而非翻译函数本身，因此需要特殊设计来应对这一挑战。

Result: 在合成和真实世界数据集上的实验验证了所提出方法的有效性，DFM成功实现了翻译可识别性并提供了传输轨迹信息。

Conclusion: DFM是首个基于ODE且保证翻译可识别性的方法，成功解决了DDM只能使用GAN实现的限制，为需要传输轨迹信息的应用提供了更好的解决方案。

Abstract: Diversified distribution matching (DDM) finds a unified translation function
mapping a diverse collection of conditional source distributions to their
target counterparts. DDM was proposed to resolve content misalignment issues in
unpaired domain translation, achieving translation identifiability. However,
DDM has only been implemented using GANs due to its constraints on the
translation function. GANs are often unstable to train and do not provide the
transport trajectory information -- yet such trajectories are useful in
applications such as single-cell evolution analysis and robot route planning.
This work introduces diversified flow matching (DFM), an ODE-based framework
for DDM. Adapting flow matching (FM) to enforce a unified translation function
as in DDM is challenging, as FM learns the translation function's velocity
rather than the translation function itself. A custom bilevel
optimization-based training loss, a nonlinear interpolant, and a structural
reformulation are proposed to address these challenges, offering a tangible
implementation. To our knowledge, DFM is the first ODE-based approach
guaranteeing translation identifiability. Experiments on synthetic and
real-world datasets validate the proposed method.

</details>


### [242] [Effective Test-Time Scaling of Discrete Diffusion through Iterative Refinement](https://arxiv.org/abs/2511.05562)
*Sanghyun Lee,Sunwoo Kim,Seungryong Kim,Jongho Park,Dongmin Park*

Main category: cs.LG

TL;DR: 本文提出了Iterative Reward-Guided Refinement (IterRef)，一种针对离散扩散模型的测试时缩放方法，通过奖励引导的噪声-去噪转换逐步优化未对齐的中间状态，在低计算预算下显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 测试时通过奖励引导生成在离散扩散模型中尚未充分探索，但其作为有前景的替代方案具有潜力。

Method: 引入IterRef方法，在Multiple-Try Metropolis框架内形式化奖励引导的噪声-去噪转换过程，证明其收敛到奖励对齐分布，明确地原位优化每个状态。

Result: 在文本和图像领域的多个离散扩散模型上评估，观察到奖励引导生成质量的持续改进，特别是在低计算预算下实现显著增益。

Conclusion: IterRef在离散扩散模型的测试时缩放中表现出色，特别是在计算资源有限的情况下大幅超越现有最优基线方法。

Abstract: Test-time scaling through reward-guided generation remains largely unexplored
for discrete diffusion models despite its potential as a promising alternative.
In this work, we introduce Iterative Reward-Guided Refinement (IterRef), a
novel test-time scaling method tailored to discrete diffusion that leverages
reward- guided noising-denoising transitions to progressively refine misaligned
intermediate states. We formalize this process within a Multiple-Try Metropolis
(MTM) framework, proving convergence to the reward-aligned distribution. Unlike
prior methods that assume the current state is already aligned with the reward
distribution and only guide the subsequent transition, our approach explicitly
refines each state in situ, progressively steering it toward the optimal
intermediate distribution. Across both text and image domains, we evaluate
IterRef on diverse discrete diffusion models and observe consistent
improvements in reward-guided generation quality. In particular, IterRef
achieves striking gains under low compute budgets, far surpassing prior
state-of-the-art baselines.

</details>


### [243] [Lookahead Unmasking Elicits Accurate Decoding in Diffusion Language Models](https://arxiv.org/abs/2511.05563)
*Sanghyun Lee,Seungryong Kim,Jongho Park,Dongmin Park*

Main category: cs.LG

TL;DR: 提出了Lookahead Unmasking (LookUM)方法来解决掩码扩散模型推理时解掩码顺序的问题，通过路径生成器和验证器的耦合，实现高效的路径选择，在多个基准测试中取得一致性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于置信度的启发式方法存在短视问题，无法利用额外计算资源，且早期解码错误会级联传播。需要一种能够全局优化解掩码顺序的方法。

Method: LookUM框架包含：(1)路径生成器从解掩码集合池中采样生成路径；(2)验证器计算路径不确定性并进行重要性采样来选择最终路径。利用错误解掩码会增加序列级不确定性的特性来避免错误轨迹。

Result: 在数学、规划和编程等六个基准测试中均取得一致性能提升。仅需2-3条路径即可达到峰值性能，路径选择效率极高。LookUM显著提升了LLaDA和LLaDA 1.5的性能，甚至使基础LLaDA达到RL调优LLaDA 1.5的水平。

Conclusion: 基于不确定性的验证为强化学习提供了正交优势，展示了该框架的通用性。该方法不需要外部奖励模型，能够有效避免早期解码错误，提高模型性能。

Abstract: Masked Diffusion Models (MDMs) as language models generate by iteratively
unmasking tokens, yet their performance crucially depends on the inference time
order of unmasking. Prevailing heuristics, such as confidence based sampling,
are myopic: they optimize locally, fail to leverage extra test-time compute,
and let early decoding mistakes cascade. We propose Lookahead Unmasking
(LookUM), which addresses these concerns by reformulating sampling as path
selection over all possible unmasking orders without the need for an external
reward model. Our framework couples (i) a path generator that proposes paths by
sampling from pools of unmasking sets with (ii) a verifier that computes the
uncertainty of the proposed paths and performs importance sampling to
subsequently select the final paths. Empirically, erroneous unmasking
measurably inflates sequence level uncertainty, and our method exploits this to
avoid error-prone trajectories. We validate our framework across six
benchmarks, such as mathematics, planning, and coding, and demonstrate
consistent performance improvements. LookUM requires only two to three paths to
achieve peak performance, demonstrating remarkably efficient path selection.
The consistent improvements on both LLaDA and post-trained LLaDA 1.5 are
particularly striking: base LLaDA with LookUM rivals the performance of
RL-tuned LLaDA 1.5, while LookUM further enhances LLaDA 1.5 itself showing that
uncertainty based verification provides orthogonal benefits to reinforcement
learning and underscoring the versatility of our framework. Code will be
publicly released.

</details>


### [244] [Adaptive Sample-Level Framework Motivated by Distributionally Robust Optimization with Variance-Based Radius Assignment for Enhanced Neural Network Generalization Under Distribution Shift](https://arxiv.org/abs/2511.05568)
*Aheer Sravon,Devdyuti Mazumder,Md. Ibrahim*

Main category: cs.LG

TL;DR: 提出了一种基于方差驱动的自适应样本级分布鲁棒优化框架（Var-DRO），通过在线损失方差自动识别高风险训练样本并分配个性化鲁棒性预算，解决了传统方法使用单一全局鲁棒性预算导致的过度保守或预算分配不当问题。


<details>
  <summary>Details</summary>
Motivation: 传统经验风险最小化（ERM）在分布偏移和少数子群体情况下可靠性不足，而传统分布鲁棒优化（DRO）使用单一全局鲁棒性预算会导致模型过于保守或鲁棒性分配不当。

Method: 基于KL散度风格的双边约束，为每个样本分配个性化鲁棒性预算，通过在线损失方差识别高风险样本，形成凸多面体上的线性内最大化问题，采用高效的水填充算法求解。

Result: 在CIFAR-10-C上达到最高平均准确率，在Waterbirds上提升整体性能，在原始CIFAR-10上保持竞争力，展现了优先考虑鲁棒性时的适度权衡。

Conclusion: Var-DRO框架是无监督的（无需组标签）、易于实现、理论可靠且计算高效，能有效处理分布偏移和少数子群体问题。

Abstract: Distribution shifts and minority subpopulations frequently undermine the
reliability of deep neural networks trained using Empirical Risk Minimization
(ERM). Distributionally Robust Optimization (DRO) addresses this by optimizing
for the worst-case risk within a neighborhood of the training distribution.
However, conventional methods depend on a single, global robustness budget,
which can lead to overly conservative models or a misallocation of robustness.
We propose a variance-driven, adaptive, sample-level DRO (Var-DRO) framework
that automatically identifies high-risk training samples and assigns a
personalized robustness budget to each based on its online loss variance. Our
formulation employs two-sided, KL-divergence-style bounds to constrain the
ratio between adversarial and empirical weights for every sample. This results
in a linear inner maximization problem over a convex polytope, which admits an
efficient water-filling solution. To stabilize training, we introduce a warmup
phase and a linear ramp schedule for the global cap on per-sample budgets,
complemented by label smoothing for numerical robustness. Evaluated on
CIFAR-10-C (corruptions), our method achieves the highest overall mean accuracy
compared to ERM and KL-DRO. On Waterbirds, Var-DRO improves overall performance
while matching or surpassing KL-DRO. On the original CIFAR-10 dataset, Var-DRO
remains competitive, exhibiting the modest trade-off anticipated when
prioritizing robustness. The proposed framework is unsupervised (requiring no
group labels), straightforward to implement, theoretically sound, and
computationally efficient.

</details>


### [245] [Fine-Tuning Vision-Language Models for Multimodal Polymer Property Prediction](https://arxiv.org/abs/2511.05577)
*An Vuong,Minh-Hao Van,Prateek Verma,Chen Zhao,Xintao Wu*

Main category: cs.LG

TL;DR: 本文提出了一种通过指令调优对视觉语言模型进行微调的方法，用于聚合物属性预测，展示了多模态学习相较于单模态方法的性能优势。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在科学领域（如材料科学）的有效性仍然有限，特别是在聚合物属性预测等广泛任务中缺乏专门的基础模型。

Method: 构建多模态聚合物数据集，通过指令调优对视觉语言模型进行微调，使用LoRA技术优化模型性能。

Result: 经过微调的模型在性能上优于单模态和基线方法，证明了多模态学习的益处，同时减少了为不同属性训练单独模型的需求。

Conclusion: 多模态学习方法在聚合物属性预测中表现出色，能够降低部署和维护成本，为科学领域的视觉语言模型应用提供了有效途径。

Abstract: Vision-Language Models (VLMs) have shown strong performance in tasks like
visual question answering and multimodal text generation, but their
effectiveness in scientific domains such as materials science remains limited.
While some machine learning methods have addressed specific challenges in this
field, there is still a lack of foundation models designed for broad tasks like
polymer property prediction using multimodal data. In this work, we present a
multimodal polymer dataset to fine-tune VLMs through instruction-tuning pairs
and assess the impact of multimodality on prediction performance. Our
fine-tuned models, using LoRA, outperform unimodal and baseline approaches,
demonstrating the benefits of multimodal learning. Additionally, this approach
reduces the need to train separate models for different properties, lowering
deployment and maintenance costs.

</details>


### [246] [Distillation-Accelerated Uncertainty Modeling for Multi-Objective RTA Interception](https://arxiv.org/abs/2511.05582)
*Gaoxiang Zhao,Ruina Qiu,Pengpeng Zhao,Rongjin Wang,Zhangang Lin,Xiaoqiang Wang*

Main category: cs.LG

TL;DR: 本文提出DAUM框架，通过多目标学习与不确定性建模的联合方法，解决实时竞价拦截中的流量质量评估和计算效率问题。


<details>
  <summary>Details</summary>
Motivation: 解决实时竞价拦截中的两个关键挑战：需要准确估计流量质量并提供高置信度的预测（通过不确定性建模），以及不确定性建模在实时应用中引入的计算效率瓶颈。

Method: 提出DAUM联合建模框架，集成多目标学习和不确定性建模；进一步应用知识蒸馏技术来降低不确定性建模的计算开销。

Result: 在JD广告数据集上的实验表明，DAUM持续提升预测性能，蒸馏后的模型推理速度提高了十倍。

Conclusion: DAUM框架有效解决了实时竞价拦截中的准确性和效率问题，通过联合建模和知识蒸馏实现了高性能和高效率的平衡。

Abstract: Real-Time Auction (RTA) Interception aims to filter out invalid or irrelevant
traffic to enhance the integrity and reliability of downstream data. However,
two key challenges remain: (i) the need for accurate estimation of traffic
quality together with sufficiently high confidence in the model's predictions,
typically addressed through uncertainty modeling, and (ii) the efficiency
bottlenecks that such uncertainty modeling introduces in real-time applications
due to repeated inference. To address these challenges, we propose DAUM, a
joint modeling framework that integrates multi-objective learning with
uncertainty modeling, yielding both traffic quality predictions and reliable
confidence estimates. Building on DAUM, we further apply knowledge distillation
to reduce the computational overhead of uncertainty modeling, while largely
preserving predictive accuracy and retaining the benefits of uncertainty
estimation. Experiments on the JD advertisement dataset demonstrate that DAUM
consistently improves predictive performance, with the distilled model
delivering a tenfold increase in inference speed.

</details>


### [247] [Prompting Neural-Guided Equation Discovery Based on Residuals](https://arxiv.org/abs/2511.05586)
*Jannis Brugger,Viktor Pfanschilling,David Richter,Mira Mezini,Stefan Kramer*

Main category: cs.LG

TL;DR: 提出了RED方法，通过分析初始方程的残差来改进方程发现系统的输出结果，无需重新搜索即可获得更好的方程建议。


<details>
  <summary>Details</summary>
Motivation: 现有神经引导方程发现系统在预测方程不符合用户期望时，缺乏有效方法获得其他方程建议，需要大量人工干预。

Method: 将初始方程解析为语法树，使用基于节点的计算规则计算每个子方程的残差，然后将残差作为新目标变量生成新提示，用更好的子方程替换原有子方程。

Result: 在Feynman基准测试的53个方程上，RED方法不仅改进了所有测试的神经引导系统，也改进了所有经典遗传编程系统。

Conclusion: RED是一种快速计算、易于扩展的后处理方法，可与任何方程发现系统配合使用，有效提高方程发现质量。

Abstract: Neural-guided equation discovery systems use a data set as prompt and predict
an equation that describes the data set without extensive search. However, if
the equation does not meet the user's expectations, there are few options for
getting other equation suggestions without intensive work with the system. To
fill this gap, we propose Residuals for Equation Discovery (RED), a
post-processing method that improves a given equation in a targeted manner,
based on its residuals. By parsing the initial equation to a syntax tree, we
can use node-based calculation rules to compute the residual for each
subequation of the initial equation. It is then possible to use this residual
as new target variable in the original data set and generate a new prompt. If,
with the new prompt, the equation discovery system suggests a subequation
better than the old subequation on a validation set, we replace the latter by
the former. RED is usable with any equation discovery system, is fast to
calculate, and is easy to extend for new mathematical operations. In
experiments on 53 equations from the Feynman benchmark, we show that it not
only helps to improve all tested neural-guided systems, but also all tested
classical genetic programming systems.

</details>


### [248] [CoPRIS: Efficient and Stable Reinforcement Learning via Concurrency-Controlled Partial Rollout with Importance Sampling](https://arxiv.org/abs/2511.05589)
*Zekai Qu,Yinxu Pan,Ao Sun,Chaojun Xiao,Xu Han*

Main category: cs.LG

TL;DR: CoPRIS提出了一种异步强化学习训练方法，通过控制并发rollout数量、提前终止和重用未完成轨迹来解决传统同步RL系统中的效率问题，在数学推理基准上实现了1.94倍的训练加速。


<details>
  <summary>Details</summary>
Motivation: 传统同步RL系统在LLM训练中存在严重效率问题，因为极长轨迹会阻塞整个rollout过程，导致GPU空闲。需要解决长尾效率低下的问题。

Method: 采用并发控制部分rollout与重要性采样，维护固定数量的并发rollout，在收集足够样本后提前终止，并在后续rollout中重用未完成轨迹。引入跨阶段重要性采样校正来减轻离策略轨迹的影响。

Result: 在具有挑战性的数学推理基准测试中，CoPRIS实现了高达1.94倍的训练加速，同时保持与同步RL系统相当或更优的性能。

Conclusion: CoPRIS有效解决了LLM强化学习训练中的效率瓶颈，通过异步rollout策略显著提升训练速度而不牺牲模型性能。

Abstract: Reinforcement learning (RL) post-training has become a trending paradigm for
enhancing the capabilities of large language models (LLMs). Most existing RL
systems for LLMs operate in a fully synchronous manner, where training must
wait for the rollout of an entire batch to complete. This design leads to
severe inefficiencies, as extremely long trajectories can stall the entire
rollout process and leave many GPUs idle. To address this issue, we propose
Concurrency- Controlled Partial Rollout with Importance Sampling (CoPRIS),
which mitigates long-tail inefficiencies by maintaining a fixed number of
concurrent rollouts, early-terminating once sufficient samples are collected,
and reusing unfinished trajectories in subsequent rollouts. To mitigate the
impact of off-policy trajectories, we introduce Cross-stage Importance Sampling
Correction, which concatenates buffered log probabilities from the previous
policy with those recomputed under the current policy for importance sampling
correction. Experiments on challenging mathematical reasoning benchmarks show
that CoPRIS achieves up to 1.94x faster training while maintaining comparable
or superior performance to synchronous RL systems. The code of CoPRIS is
available at https://github.com/777pomingzi/CoPRIS.

</details>


### [249] [FedSparQ: Adaptive Sparse Quantization with Error Feedback for Robust & Efficient Federated Learning](https://arxiv.org/abs/2511.05591)
*Chaimaa Medjadji,Sadi Alawadi,Feras M. Awaysheh,Guilain Leduc,Sylvain Kubler,Yves Le Traon*

Main category: cs.LG

TL;DR: FedSparQ是一个轻量级联邦学习压缩框架，通过动态稀疏化、半精度量化和误差反馈集成，在保持模型精度的同时显著减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临显著的通信开销问题，需要在不影响模型性能的情况下减少高维模型更新的传输。

Method: 采用自适应阈值动态稀疏化客户端梯度，对保留条目应用半精度量化，并集成误差反馈以防止信息丢失。无需手动调整稀疏率或量化计划，适应同质和异质数据分布，且与模型架构无关。

Result: 在IID和非IID数据下的视觉基准测试中，FedSparQ显著减少通信开销（相比FedAvg减少90%字节传输），同时保持或提高模型精度（相比未压缩FedAvg提高6%），并增强收敛鲁棒性（相比其他基线提高50%）。

Conclusion: FedSparQ为带宽受限的联邦学习部署提供了实用、易于部署的解决方案，并为自适应精度和隐私保护协议的未来扩展奠定了基础。

Abstract: Federated Learning (FL) enables collaborative model training across
decentralized clients while preserving data privacy by keeping raw data local.
However, FL suffers from significant communication overhead due to the frequent
exchange of high-dimensional model updates over constrained networks. In this
paper, we present FedSparQ, a lightweight compression framework that
dynamically sparsifies the gradient of each client through an adaptive
threshold, applies half-precision quanti- zation to retained entries and
integrates residuals from error feedback to prevent loss of information.
FedSparQ requires no manual tuning of sparsity rates or quantization schedules,
adapts seamlessly to both homogeneous and heterogeneous data distributions, and
is agnostic to model architecture. Through extensive empirical evaluation on
vision benchmarks under independent and identically distributed (IID) and
non-IID data, we show that FedSparQ substantially reduces communication
overhead (reducing by 90% of bytes sent compared to FedAvg) while preserving or
improving model accuracy (improving by 6% compared to FedAvg non-compressed
solution or to state-of-the- art compression models) and enhancing convergence
robustness (by 50%, compared to the other baselines). Our approach provides a
practical, easy-to-deploy solution for bandwidth- constrained federated
deployments and lays the groundwork for future extensions in adaptive precision
and privacy-preserving protocols.

</details>


### [250] [Gradient Projection onto Historical Descent Directions for Communication-Efficient Federated Learning](https://arxiv.org/abs/2511.05593)
*Arnaud Descours,Léonard Deroose,Jan Ramon*

Main category: cs.LG

TL;DR: 提出了两种联邦学习算法ProjFL和ProjFL+EF，通过将本地梯度投影到共享子空间来显著降低通信成本，同时保持与现有方法相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的通信效率是主要瓶颈，特别是对于大规模模型。需要开发能够在保持数据隐私的同时减少通信开销的高效算法。

Method: ProjFL用于无偏压缩器，ProjFL+EF通过误差反馈机制适配有偏压缩器。两种方法都将本地梯度投影到由历史下降方向张成的共享客户端-服务器子空间上。

Result: 在强凸、凸和非凸设置下建立了收敛保证。在标准联邦学习分类基准测试中，两种算法在显著降低通信成本的同时达到了与现有基线相当的准确率。

Conclusion: ProjFL和ProjFL+EF是高效的联邦学习算法，能够在不牺牲模型性能的情况下大幅减少通信开销，适用于各种压缩器类型。

Abstract: Federated Learning (FL) enables decentralized model training across multiple
clients while optionally preserving data privacy. However, communication
efficiency remains a critical bottleneck, particularly for large-scale models.
In this work, we introduce two complementary algorithms: ProjFL, designed for
unbiased compressors, and ProjFL+EF, tailored for biased compressors through an
Error Feedback mechanism. Both methods rely on projecting local gradients onto
a shared client-server subspace spanned by historical descent directions,
enabling efficient information exchange with minimal communication overhead. We
establish convergence guarantees for both algorithms under strongly convex,
convex, and non-convex settings. Empirical evaluations on standard FL
classification benchmarks with deep neural networks show that ProjFL and
ProjFL+EF achieve accuracy comparable to existing baselines while substantially
reducing communication costs.

</details>


### [251] [FlowNet: Modeling Dynamic Spatio-Temporal Systems via Flow Propagation](https://arxiv.org/abs/2511.05595)
*Yutong Feng,Xu Liu,Yutong Xia,Yuxuan Liang*

Main category: cs.LG

TL;DR: 提出Spatio-Temporal Flow范式，通过可量化的流转移建模动态节点耦合，设计FlowNet架构利用流令牌模拟源到目的地的信息传输，在三个真实世界系统的建模中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于图或注意力机制，依赖相似性驱动的连接假设，忽略了支配系统演化的非对称流交换，需要更准确地建模复杂动态时空系统中的流介导依赖关系。

Method: 提出FlowNet架构，使用流令牌作为信息载体，通过流分配模块模拟源到目的地的传输，确保状态重分配符合守恒定律；采用自适应空间掩码模块动态调整交互半径，抑制无关噪声；采用级联架构增强可扩展性和非线性表示能力。

Result: 在三个真实世界系统的建模中，FlowNet在七个指标上显著优于现有最先进方法，验证了其效率和物理可解释性。

Conclusion: 建立了通过时空流交互建模复杂系统的原则性方法，FlowNet在性能和物理一致性方面表现出色。

Abstract: Accurately modeling complex dynamic spatio-temporal systems requires
capturing flow-mediated interdependencies and context-sensitive interaction
dynamics. Existing methods, predominantly graph-based or attention-driven, rely
on similarity-driven connectivity assumptions, neglecting asymmetric flow
exchanges that govern system evolution. We propose Spatio-Temporal Flow, a
physics-inspired paradigm that explicitly models dynamic node couplings through
quantifiable flow transfers governed by conservation principles. Building on
this, we design FlowNet, a novel architecture leveraging flow tokens as
information carriers to simulate source-to-destination transfers via Flow
Allocation Modules, ensuring state redistribution aligns with conservation
laws. FlowNet dynamically adjusts the interaction radius through an Adaptive
Spatial Masking module, suppressing irrelevant noise while enabling
context-aware propagation. A cascaded architecture enhances scalability and
nonlinear representation capacity. Experiments demonstrate that FlowNet
significantly outperforms existing state-of-the-art approaches on seven metrics
in the modeling of three real-world systems, validating its efficiency and
physical interpretability. We establish a principled methodology for modeling
complex systems through spatio-temporal flow interactions.

</details>


### [252] [AutoHood3D: A Multi-Modal Benchmark for Automotive Hood Design and Fluid-Structure Interaction](https://arxiv.org/abs/2511.05596)
*Vansh Sharma,Harish Jai Ganesh,Maryam Akram,Wanjiao Liu,Venkat Raman*

Main category: cs.LG

TL;DR: 本研究提出了AutoHood3D数据集，包含16,000+个汽车引擎盖几何变体，用于机器学习在工程组件设计和多物理场系统替代模型中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有数据集局限于2D情况、几何变化有限或缺乏多模态注释，无法满足实际多物理场问题的需求。

Method: 采用耦合大涡模拟-有限元分析对每个引擎盖进行数值建模，使用120万个网格单元确保时空精度，提供时间分辨物理场、STL网格和结构化自然语言提示。

Result: 验证了数值方法，建立了五个神经架构的定量基准，展示了位移和力预测中的系统替代误差。

Conclusion: AutoHood3D支持物理感知的机器学习开发，加速生成设计迭代，促进新的流体-结构相互作用基准创建。

Abstract: This study presents a new high-fidelity multi-modal dataset containing 16000+
geometric variants of automotive hoods useful for machine learning (ML)
applications such as engineering component design and process optimization, and
multiphysics system surrogates. The dataset is centered on a practical
multiphysics problem-hood deformation from fluid entrapment and inertial
loading during rotary-dip painting. Each hood is numerically modeled with a
coupled Large-Eddy Simulation (LES)-Finite Element Analysis (FEA), using 1.2M
cells in total to ensure spatial and temporal accuracy. The dataset provides
time-resolved physical fields, along with STL meshes and structured natural
language prompts for text-to-geometry synthesis. Existing datasets are either
confined to 2D cases, exhibit limited geometric variations, or lack the
multi-modal annotations and data structures - shortcomings we address with
AutoHood3D. We validate our numerical methodology, establish quantitative
baselines across five neural architectures, and demonstrate systematic
surrogate errors in displacement and force predictions. These findings motivate
the design of novel approaches and multiphysics loss functions that enforce
fluid-solid coupling during model training. By providing fully reproducible
workflows, AutoHood3D enables physics-aware ML development, accelerates
generative-design iteration, and facilitates the creation of new FSI
benchmarks. Dataset and code URLs in Appendix.

</details>


### [253] [FiCABU: A Fisher-Based, Context-Adaptive Machine Unlearning Processor for Edge AI](https://arxiv.org/abs/2511.05605)
*Eun-Su Cho,Jongin Choi,Jeongmin Jin,Jae-Jin Lee,Woojoo Lee*

Main category: cs.LG

TL;DR: FiCABU是一种软硬件协同设计的边缘AI处理器机器遗忘方法，通过上下文自适应遗忘和平衡阻尼技术，在保持保留精度的同时显著减少计算和能耗。


<details>
  <summary>Details</summary>
Motivation: 受隐私法规和"被遗忘权"驱动，需要在边缘设备上实现机器遗忘，但服务器中心或重训练方法在计算和能源预算紧张的情况下不实用。

Method: 结合上下文自适应遗忘（从后端层开始编辑，达到目标遗忘后停止）和平衡阻尼（按深度缩放阻尼强度以保持保留精度），在RISC-V边缘AI处理器中实现完整RTL设计。

Result: 在CIFAR-20和PinsFaceRecognition数据集上，FiCABU实现随机猜测遗忘精度，同时匹配SSD基线的保留精度，计算量减少高达87.52%（ResNet-18）和71.03%（ViT）。硬件原型进一步将能耗降低至SSD基线的6.48%（CIFAR-20）和0.13%（PinsFaceRecognition）。

Conclusion: FiCABU证明后端优先、深度感知的遗忘方法可以在资源受限的边缘AI设备上实现实用且高效的机器遗忘。

Abstract: Machine unlearning, driven by privacy regulations and the "right to be
forgotten", is increasingly needed at the edge, yet server-centric or
retraining-heavy methods are impractical under tight computation and energy
budgets. We present FiCABU (Fisher-based Context-Adaptive Balanced Unlearning),
a software-hardware co-design that brings unlearning to edge AI processors.
FiCABU combines (i) Context-Adaptive Unlearning, which begins edits from
back-end layers and halts once the target forgetting is reached, with (ii)
Balanced Dampening, which scales dampening strength by depth to preserve retain
accuracy. These methods are realized in a full RTL design of a RISC-V edge AI
processor that integrates two lightweight IPs for Fisher estimation and
dampening into a GEMM-centric streaming pipeline, validated on an FPGA
prototype and synthesized in 45 nm for power analysis. Across CIFAR-20 and
PinsFaceRecognition with ResNet-18 and ViT, FiCABU achieves random-guess forget
accuracy while matching the retraining-free Selective Synaptic Dampening (SSD)
baseline on retain accuracy, reducing computation by up to 87.52 percent
(ResNet-18) and 71.03 percent (ViT). On the INT8 hardware prototype, FiCABU
further improves retain preservation and reduces energy to 6.48 percent
(CIFAR-20) and 0.13 percent (PinsFaceRecognition) of the SSD baseline. In sum,
FiCABU demonstrates that back-end-first, depth-aware unlearning can be made
both practical and efficient for resource-constrained edge AI devices.

</details>


### [254] [An MLCommons Scientific Benchmarks Ontology](https://arxiv.org/abs/2511.05614)
*Ben Hawks,Gregor von Laszewski,Matthew D. Sinclair,Marco Colombo,Shivaram Venkataraman,Rutwik Jain,Yiwei Jiang,Nhan Tran,Geoffrey Fox*

Main category: cs.LG

TL;DR: 本文提出了MLCommons科学基准本体论，通过统一、社区驱动的努力，为科学机器学习建立了标准化、可扩展的跨领域基准测试框架。


<details>
  <summary>Details</summary>
Motivation: 现有的科学机器学习基准测试工作存在孤立性和缺乏标准化的问题，使得机器学习在关键科学应用中的创新和变革性应用更加分散，影响路径不清晰。

Method: 基于XAI-BENCH、FastML Science Benchmarks、PDEBench和SciMLBench等先前倡议，将大量不同的基准测试和框架整合到一个单一的科学、应用和系统级基准测试分类法中，并通过开放提交工作流程添加新基准。

Result: 开发了一个可扩展的架构，支持未来的科学和AI/ML模式，并提供了识别独特科学工作负载新兴计算模式的方法。

Conclusion: MLCommons科学基准本体论为科学机器学习中的可重现、跨领域基准测试提供了标准化、可扩展的基础。

Abstract: Scientific machine learning research spans diverse domains and data
modalities, yet existing benchmark efforts remain siloed and lack
standardization. This makes novel and transformative applications of machine
learning to critical scientific use-cases more fragmented and less clear in
pathways to impact. This paper introduces an ontology for scientific
benchmarking developed through a unified, community-driven effort that extends
the MLCommons ecosystem to cover physics, chemistry, materials science,
biology, climate science, and more. Building on prior initiatives such as
XAI-BENCH, FastML Science Benchmarks, PDEBench, and the SciMLBench framework,
our effort consolidates a large set of disparate benchmarks and frameworks into
a single taxonomy of scientific, application, and system-level benchmarks. New
benchmarks can be added through an open submission workflow coordinated by the
MLCommons Science Working Group and evaluated against a six-category rating
rubric that promotes and identifies high-quality benchmarks, enabling
stakeholders to select benchmarks that meet their specific needs. The
architecture is extensible, supporting future scientific and AI/ML motifs, and
we discuss methods for identifying emerging computing patterns for unique
scientific workloads. The MLCommons Science Benchmarks Ontology provides a
standardized, scalable foundation for reproducible, cross-domain benchmarking
in scientific machine learning. A companion webpage for this work has also been
developed as the effort evolves: https://mlcommons-science.github.io/benchmark/

</details>


### [255] [Frequency Matters: When Time Series Foundation Models Fail Under Spectral Shift](https://arxiv.org/abs/2511.05619)
*Tianze Wang,Sofiane Ennadir,John Pertoft,Gabriela Zarzar Gandler,Lele Cao,Zineb Senane,Styliani Katsarou,Sahar Asadi,Axel Karlsson,Oleg Smirnov*

Main category: cs.LG

TL;DR: 时间序列基础模型在工业应用中存在泛化问题，主要原因是频谱偏移——下游任务与预训练阶段的频率成分不匹配。


<details>
  <summary>Details</summary>
Motivation: 研究时间序列基础模型在工业场景中表现不佳的原因，特别是频谱不匹配对模型泛化能力的影响。

Method: 通过工业级移动游戏玩家参与度预测任务进行实证分析，并设计受控合成实验对比已见和未见频率带的信号表现。

Result: 发现时间序列基础模型在频谱不匹配情况下性能显著下降，在工业任务中表现不如领域自适应基线模型。

Conclusion: 频率感知对于稳健的时间序列基础模型部署至关重要，需要开发考虑频谱多样性的新预训练和评估协议。

Abstract: Time series foundation models (TSFMs) have shown strong results on public
benchmarks, prompting comparisons to a "BERT moment" for time series. Their
effectiveness in industrial settings, however, remains uncertain. We examine
why TSFMs often struggle to generalize and highlight spectral shift (a mismatch
between the dominant frequency components in downstream tasks and those
represented during pretraining) as a key factor. We present evidence from an
industrial-scale player engagement prediction task in mobile gaming, where
TSFMs underperform domain-adapted baselines. To isolate the mechanism, we
design controlled synthetic experiments contrasting signals with seen versus
unseen frequency bands, observing systematic degradation under spectral
mismatch. These findings position frequency awareness as critical for robust
TSFM deployment and motivate new pretraining and evaluation protocols that
explicitly account for spectral diversity.

</details>


### [256] [Fooling Algorithms in Non-Stationary Bandits using Belief Inertia](https://arxiv.org/abs/2511.05620)
*Gal Mendelson,Eyal Tadmor*

Main category: cs.LG

TL;DR: 本文通过信念惯性理论分析非平稳多臂老虎机问题，证明经典算法在单变点情况下也会遭受线性后悔，且重启策略无法避免线性后悔。


<details>
  <summary>Details</summary>
Motivation: 现有非平稳老虎机下界分析主要依赖稀疏采样论证，但这种方法存在局限性。本文旨在开发一种基于信念惯性的新方法来推导更尖锐的下界。

Method: 提出信念惯性论证方法，分析算法通过历史奖励平均值编码的经验信念如何产生抵抗新证据的惯性，并利用这种惯性构造对抗性实例误导经典算法。

Result: 证明Explore Then Commit、epsilon greedy和UCB等经典算法在单变点情况下都会遭受与T成线性关系的后悔，且重启策略也无法避免线性后悔。

Conclusion: 信念惯性方法是非平稳老虎机中推导尖锐下界的强大工具，揭示了经典算法在非平稳环境中的根本局限性。

Abstract: We study the problem of worst case regret in piecewise stationary multi armed
bandits. While the minimax theory for stationary bandits is well established,
understanding analogous limits in time-varying settings is challenging.
Existing lower bounds rely on what we refer to as infrequent sampling
arguments, where long intervals without exploration allow adversarial reward
changes that induce large regret.
  In this paper, we introduce a fundamentally different approach based on a
belief inertia argument. Our analysis captures how an algorithm's empirical
beliefs, encoded through historical reward averages, create momentum that
resists new evidence after a change. We show how this inertia can be exploited
to construct adversarial instances that mislead classical algorithms such as
Explore Then Commit, epsilon greedy, and UCB, causing them to suffer regret
that grows linearly with T and with a substantial constant factor, regardless
of how their parameters are tuned, even with a single change point.
  We extend the analysis to algorithms that periodically restart to handle non
stationarity and prove that, even then, the worst case regret remains linear in
T. Our results indicate that utilizing belief inertia can be a powerful method
for deriving sharp lower bounds in non stationary bandits.

</details>


### [257] [Make It Long, Keep It Fast: End-to-End 10k-Sequence Modeling at Billion Scale on Douyin](https://arxiv.org/abs/2511.06077)
*Lin Guan,Jia-Qi Yang,Zhishan Zhao,Beichuan Zhang,Bo Sun,Xuanyuan Luo,Jinan Ni,Xiaowen Li,Yuhang Qi,Zhifang Fan,Hangyu Wang,Qiwei Chen,Yi Cheng,Feng Zhang,Xiao Yang*

Main category: cs.LG

TL;DR: 提出了一个端到端系统，将长序列建模扩展到生产环境中的10k长度历史记录，通过STCA、RLB和长度外推训练策略实现高效处理。


<details>
  <summary>Details</summary>
Motivation: 短视频推荐系统需要在不超过延迟或成本预算的情况下利用极长的用户历史记录。

Method: 1. STCA：用从目标到历史的堆叠交叉注意力替换历史自注意力，将复杂度从二次降低到线性；2. RLB：用户中心批处理方案，聚合同一用户的多个目标共享用户端编码；3. 长度外推训练策略：在较短窗口上训练，在更长窗口上推理。

Result: 在离线和在线实验中，随着历史长度和模型容量的扩展，观察到可预测的单调增益，反映了大型语言模型中观察到的缩放定律行为。在抖音全流量部署中，系统在关键参与度指标上带来显著改进，同时满足生产延迟要求。

Conclusion: 该系统展示了将端到端长序列推荐扩展到10k规模的实际可行路径，在保持生产延迟的同时显著提升推荐效果。

Abstract: Short-video recommenders such as Douyin must exploit extremely long user
histories without breaking latency or cost budgets. We present an end-to-end
system that scales long-sequence modeling to 10k-length histories in
production. First, we introduce Stacked Target-to-History Cross Attention
(STCA), which replaces history self-attention with stacked cross-attention from
the target to the history, reducing complexity from quadratic to linear in
sequence length and enabling efficient end-to-end training. Second, we propose
Request Level Batching (RLB), a user-centric batching scheme that aggregates
multiple targets for the same user/request to share the user-side encoding,
substantially lowering sequence-related storage, communication, and compute
without changing the learning objective. Third, we design a
length-extrapolative training strategy -- train on shorter windows, infer on
much longer ones -- so the model generalizes to 10k histories without
additional training cost. Across offline and online experiments, we observe
predictable, monotonic gains as we scale history length and model capacity,
mirroring the scaling law behavior observed in large language models. Deployed
at full traffic on Douyin, our system delivers significant improvements on key
engagement metrics while meeting production latency, demonstrating a practical
path to scaling end-to-end long-sequence recommendation to the 10k regime.

</details>


### [258] [Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder Training](https://arxiv.org/abs/2511.07328)
*Artyom Sorokin,Nazar Buzun,Alexander Anokhin,Oleg Inozemcev,Egor Vedernikov,Petr Anokhin,Mikhail Burtsev,Trushkov Alexey,Yin Wenshuai,Evgeny Burnaev*

Main category: cs.LG

TL;DR: Q-RAG是一种新颖的多步检索增强生成方法，通过强化学习微调嵌入模型来实现高效的多步检索，在长上下文基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要关注单步检索，无法有效回答需要多步搜索的复杂问题。现有的多步检索方法需要微调小型LLM，资源消耗大且无法使用大型LLM。

Method: 提出Q-RAG方法，使用强化学习微调嵌入模型来实现多步检索，提供资源高效的替代方案。

Result: 在开放域问答任务中表现优异，在Babilong和RULER长上下文基准测试中达到最先进结果，支持高达1000万token的上下文。

Conclusion: Q-RAG为多步检索提供了一种竞争性强且资源高效的解决方案，能够有效处理复杂问题并减少幻觉和推理成本。

Abstract: Retrieval-Augmented Generation (RAG) methods enhance LLM performance by
efficiently filtering relevant context for LLMs, reducing hallucinations and
inference cost. However, most existing RAG methods focus on single-step
retrieval, which is often insufficient for answering complex questions that
require multi-step search. Recently, multi-step retrieval approaches have
emerged, typically involving the fine-tuning of small LLMs to perform
multi-step retrieval. This type of fine-tuning is highly resource-intensive and
does not enable the use of larger LLMs. In this work, we propose Q-RAG, a novel
approach that fine-tunes the Embedder model for multi-step retrieval using
reinforcement learning (RL). Q-RAG offers a competitive, resource-efficient
alternative to existing multi-step retrieval methods for open-domain question
answering and achieves state-of-the-art results on the popular long-context
benchmarks Babilong and RULER for contexts up to 10M tokens.

</details>


### [259] [Blind Inverse Game Theory: Jointly Decoding Rewards and Rationality in Entropy-Regularized Competitive Games](https://arxiv.org/abs/2511.05640)
*Hamza Virk,Sandro Amaglobeli,Zuhayr Syed*

Main category: cs.LG

TL;DR: 本文提出了Blind-IGT框架，解决了逆博弈理论中当智能体理性参数未知时的统计不可识别性问题，通过归一化约束联合恢复奖励参数和理性参数。


<details>
  <summary>Details</summary>
Motivation: 传统基于熵正则化量化响应均衡的逆博弈理论方法假设智能体的理性参数已知，但当该参数未知时会出现尺度模糊性，导致奖励参数和理性参数统计不可识别。

Method: 引入归一化约束解决尺度模糊性，提出归一化最小二乘估计器，并扩展到马尔可夫博弈场景，即使在转移动态未知时也能工作。

Result: 证明了归一化最小二乘估计器能够达到最优的O(N^{-1/2})收敛速率，在强可识别条件不满足时提供部分识别保证，并在未知转移动态的马尔可夫游戏中表现出强经验性能。

Conclusion: Blind-IGT是首个能够联合恢复奖励参数和理性参数的统计框架，解决了逆博弈理论中的基本尺度模糊性问题，为竞争环境中的行为建模提供了理论保证。

Abstract: Inverse Game Theory (IGT) methods based on the entropy-regularized Quantal
Response Equilibrium (QRE) offer a tractable approach for competitive settings,
but critically assume the agents' rationality parameter (temperature $\tau$) is
known a priori. When $\tau$ is unknown, a fundamental scale ambiguity emerges
that couples $\tau$ with the reward parameters ($\theta$), making them
statistically unidentifiable. We introduce Blind-IGT, the first statistical
framework to jointly recover both $\theta$ and $\tau$ from observed behavior.
We analyze this bilinear inverse problem and establish necessary and sufficient
conditions for unique identification by introducing a normalization constraint
that resolves the scale ambiguity. We propose an efficient Normalized Least
Squares (NLS) estimator and prove it achieves the optimal
$\mathcal{O}(N^{-1/2})$ convergence rate for joint parameter recovery. When
strong identifiability conditions fail, we provide partial identification
guarantees through confidence set construction. We extend our framework to
Markov games and demonstrate optimal convergence rates with strong empirical
performance even when transition dynamics are unknown.

</details>


### [260] [KLASS: KL-Guided Fast Inference in Masked Diffusion Models](https://arxiv.org/abs/2511.05664)
*Seo Hyun Kim,Sunwoo Hong,Hojung Jung,Youngrok Park,Se-Young Yun*

Main category: cs.LG

TL;DR: 提出KL-Adaptive Stability Sampling (KLASS)方法，通过利用token级KL散度识别稳定高置信度预测，在无需额外模型训练的情况下，每次迭代同时解掩多个token，显著加速生成过程同时保持样本质量。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型在各种任务中表现出竞争力，但由于其迭代优化过程，推理速度受到缓慢且静态采样速度的限制。

Method: KLASS方法利用token级KL散度识别稳定、高置信度的预测，在每次迭代中同时解掩多个token，无需额外模型训练。

Result: 在推理基准测试中，KLASS实现了高达2.78倍的实时加速，同时性能优于标准贪婪解码，在基于扩散的采样器中达到最先进结果。在文本、图像和分子生成等多个领域验证了其有效性。

Conclusion: KLASS是一种快速有效的采样方法，可作为广泛适用于不同模型的通用采样器。

Abstract: Masked diffusion models have demonstrated competitive results on various
tasks including language generation. However, due to its iterative refinement
process, the inference is often bottlenecked by slow and static sampling speed.
To overcome this problem, we introduce `KL-Adaptive Stability Sampling'
(KLASS), a fast yet effective sampling method that exploits token-level KL
divergence to identify stable, high-confidence predictions. By unmasking
multiple tokens in each iteration without any additional model training, our
approach speeds up generation significantly while maintaining sample quality.
On reasoning benchmarks, KLASS achieves up to $2.78\times$ wall-clock speedups
while improving performance over standard greedy decoding, attaining
state-of-the-art results among diffusion-based samplers. We further validate
KLASS across diverse domains, including text, image, and molecular generation,
showing its effectiveness as a broadly applicable sampler across different
models.

</details>


### [261] [Distributionally Robust Self Paced Curriculum Reinforcement Learning](https://arxiv.org/abs/2511.05694)
*Anirudh Satheesh,Keenan Powell,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 本文提出了一种分布鲁棒自步课程强化学习方法（DR-SPCRL），通过将鲁棒性预算ε作为连续课程来克服传统DRRL方法中固定ε带来的性能与鲁棒性权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统分布鲁棒强化学习（DRRL）中固定鲁棒性预算ε会导致性能与鲁棒性之间的权衡：小ε值产生高名义性能但弱鲁棒性，大ε值导致不稳定和过于保守的策略。

Method: DR-SPCRL将ε作为连续课程，根据智能体进展自适应调度鲁棒性预算，实现名义性能与鲁棒性能之间的平衡。

Result: 在多个环境中的实证结果表明，DR-SPCRL不仅稳定了训练，还实现了更优的鲁棒性-性能权衡，在变化扰动下平均获得11.8%的回合回报提升，性能约为相应名义RL算法的1.9倍。

Conclusion: DR-SPCRL方法通过自适应调度鲁棒性预算，有效解决了传统DRRL方法的局限性，实现了更好的训练稳定性和鲁棒性-性能平衡。

Abstract: A central challenge in reinforcement learning is that policies trained in
controlled environments often fail under distribution shifts at deployment into
real-world environments. Distributionally Robust Reinforcement Learning (DRRL)
addresses this by optimizing for worst-case performance within an uncertainty
set defined by a robustness budget $\epsilon$. However, fixing $\epsilon$
results in a tradeoff between performance and robustness: small values yield
high nominal performance but weak robustness, while large values can result in
instability and overly conservative policies. We propose Distributionally
Robust Self-Paced Curriculum Reinforcement Learning (DR-SPCRL), a method that
overcomes this limitation by treating $\epsilon$ as a continuous curriculum.
DR-SPCRL adaptively schedules the robustness budget according to the agent's
progress, enabling a balance between nominal and robust performance. Empirical
results across multiple environments demonstrate that DR-SPCRL not only
stabilizes training but also achieves a superior robustness-performance
trade-off, yielding an average 11.8\% increase in episodic return under varying
perturbations compared to fixed or heuristic scheduling strategies, and
achieving approximately 1.9$\times$ the performance of the corresponding
nominal RL algorithms.

</details>


### [262] [AI-assisted workflow enables rapid, high-fidelity breast cancer clinical trial eligibility prescreening](https://arxiv.org/abs/2511.05696)
*Jacob T. Rosenthal,Emma Hahesy,Sulov Chalise,Menglei Zhu,Mert R. Sabuncu,Lior Z. Braunstein,Anyi Li*

Main category: cs.LG

TL;DR: MSK-MATCH是一个用于癌症临床试验资格筛查的AI系统，结合大语言模型和肿瘤学知识库，在回顾性研究中自动处理61.9%的病例，AI辅助工作流达到98.6%的准确率，并将筛查时间从20分钟减少到43秒。


<details>
  <summary>Details</summary>
Motivation: 临床试验在癌症治疗和研究中很重要，但参与率仍然很低，需要更高效的资格筛查方法。

Method: 开发MSK-MATCH系统，集成大语言模型与肿瘤学试验知识库，采用检索增强架构，为所有AI预测提供基于源文本的解释。

Result: 在88,518份临床文档的回顾性数据集中，MSK-MATCH自动处理61.9%的病例，AI辅助工作流达到98.6%准确率、98.4%敏感性和98.7%特异性，匹配或超过纯人工和纯AI比较的性能。

Conclusion: MSK-MATCH显著提高了临床试验资格筛查的效率和准确性，为需要人工审查的病例提供AI生成的解释，大幅减少筛查时间和成本。

Abstract: Clinical trials play an important role in cancer care and research, yet
participation rates remain low. We developed MSK-MATCH (Memorial Sloan
Kettering Multi-Agent Trial Coordination Hub), an AI system for automated
eligibility screening from clinical text. MSK-MATCH integrates a large language
model with a curated oncology trial knowledge base and retrieval-augmented
architecture providing explanations for all AI predictions grounded in source
text. In a retrospective dataset of 88,518 clinical documents from 731 patients
across six breast cancer trials, MSK-MATCH automatically resolved 61.9% of
cases and triaged 38.1% for human review. This AI-assisted workflow achieved
98.6% accuracy, 98.4% sensitivity, and 98.7% specificity for patient-level
eligibility classification, matching or exceeding performance of the human-only
and AI-only comparisons. For the triaged cases requiring manual review,
prepopulating eligibility screens with AI-generated explanations reduced
screening time from 20 minutes to 43 seconds at an average cost of $0.96 per
patient-trial pair.

</details>


### [263] [Distributionally Robust Multimodal Machine Learning](https://arxiv.org/abs/2511.05716)
*Peilin Yang,Yu Ma*

Main category: cs.LG

TL;DR: 提出了一种新的分布鲁棒优化框架，用于研究多模态机器学习的理论和实践问题，通过泛化上界和极小极大下界提供性能保证，并在仿真和真实数据集中验证了方法的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖特征级融合或启发式不确定性建模，忽视了模态感知效应且提供有限的理论见解。本文旨在为多模态机器学习提供原则性基础，特别是在不确定性不可避免的高风险应用中。

Method: 提出分布鲁棒优化框架，进行复杂度分析，建立泛化上界和极小极大下界，并扩展到编码器特定误差传播的设置。

Result: 理论分析提供了性能保证，实证研究表明该方法在仿真设置和真实数据集中提高了鲁棒性。

Conclusion: 这些发现为在高风险应用中采用多模态机器学习模型提供了原则性基础，其中不确定性是不可避免的。

Abstract: We consider the problem of distributionally robust multimodal machine
learning. Existing approaches often rely on merging modalities on the feature
level (early fusion) or heuristic uncertainty modeling, which downplays
modality-aware ef- fects and provide limited insights. We propose a novel
distributionally robust optimization (DRO) framework that aims to study both
the theoretical and practical insights of multimodal machine learning. We first
justify this setup and show the significance of this problem through complexity
analysis. We then establish both generalization upper bounds and minimax lower
bounds which provide perfor- mance guarantees. These results are further
extended in settings where we consider encoder-specific error propogations.
Empirically, we demonstrate that our approach improves robustness in both
simulation settings and real-world datasets. Together, these findings provide a
principled foundation for employing multimodal machine learning models in
high-stakes applications where uncertainty is unavoidable.

</details>


### [264] [Compressing Chemistry Reveals Functional Groups](https://arxiv.org/abs/2511.05728)
*Ruben Sharma,Ross D. King*

Main category: cs.LG

TL;DR: 本文首次对传统化学功能基团在化学解释中的效用进行了大规模评估，基于计算学习理论的最小消息长度原则，开发了无监督学习算法来发现压缩生物相关分子的子结构。


<details>
  <summary>Details</summary>
Motivation: 评估传统化学功能基团在化学解释中的实际效用，寻找能够有效压缩化学数据的子结构模式。

Method: 采用基于最小消息长度原则的无监督学习算法，在约300万个生物相关分子中搜索压缩子结构，并在24个生物活性预测数据集上运行算法发现数据集特异性功能基团。

Result: 发现的子结构包含大多数人工策划的功能基团以及具有更特定功能的新型更大模式。基于数据集特异性功能基团的指纹在生物活性回归任务中显著优于MACCS和Morgan指纹。

Conclusion: 传统化学功能基团确实具有解释价值，但算法发现的更大模式能提供更具体的功能信息，数据集特异性功能基团能显著提升生物活性预测性能。

Abstract: We introduce the first formal large-scale assessment of the utility of
traditional chemical functional groups as used in chemical explanations. Our
assessment employs a fundamental principle from computational learning theory:
a good explanation of data should also compress the data. We introduce an
unsupervised learning algorithm based on the Minimum Message Length (MML)
principle that searches for substructures that compress around three million
biologically relevant molecules. We demonstrate that the discovered
substructures contain most human-curated functional groups as well as novel
larger patterns with more specific functions. We also run our algorithm on 24
specific bioactivity prediction datasets to discover dataset-specific
functional groups. Fingerprints constructed from dataset-specific functional
groups are shown to significantly outperform other fingerprint representations,
including the MACCS and Morgan fingerprint, when training ridge regression
models on bioactivity regression tasks.

</details>


### [265] [QiVC-Net: Quantum-Inspired Variational Convolutional Network, with Application to Biosignal Classification](https://arxiv.org/abs/2511.05730)
*Amin Golnari,Jamileh Yousefi,Reza Moheimani,Saeid Sanei*

Main category: cs.LG

TL;DR: 本文提出了量子启发的变分卷积（QiVC）框架，通过量子启发的旋转集成机制在卷积架构中实现概率推理和变分优化，应用于生物信号分类任务并取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决生物信号分析中高噪声、主体间变异性和数据不平衡等挑战，需要开发能够建模结构化不确定性同时保持参数空间几何特性的新型卷积架构。

Method: 提出QiVC框架，核心是量子启发的旋转集成（QiRE）机制，对卷积权重进行可微的低维子空间旋转，模拟量子态演化，实现不确定性建模而不增加额外参数。

Result: 在两个基准数据集PhysioNet CinC 2016和PhysioNet CirCor DigiScope 2022上分别达到97.84%和97.89%的准确率，实现了最先进的性能。

Conclusion: QiVC框架展示了在真实世界生物医学信号分析中推进不确定性感知建模的潜力，其实现已在GitHub上开源。

Abstract: This work introduces the quantum-inspired variational convolution (QiVC)
framework, a novel learning paradigm that integrates principles of
probabilistic inference, variational optimization, and quantum-inspired
transformations within convolutional architectures. The central innovation of
QiVC lies in its quantum-inspired rotated ensemble (QiRE) mechanism. QiRE
performs differentiable low-dimensional subspace rotations of convolutional
weights, analogously to quantum state evolution. This approach enables
structured uncertainty modeling while preserving the intrinsic geometry of the
parameter space, resulting in more expressive, stable, and uncertainty-aware
representations. To demonstrate its practical potential, the concept is
instantiated in a QiVC-based convolutional network (QiVC-Net) and evaluated in
the context of biosignal classification, focusing on phonocardiogram (PCG)
recordings, a challenging domain characterized by high noise, inter-subject
variability, and often imbalanced data. The proposed QiVC-Net integrates an
architecture in which the QiVC layer does not introduce additional parameters,
instead performing an ensemble rotation of the convolutional weights through a
structured mechanism ensuring robustness without added highly computational
burden. Experiments on two benchmark datasets, PhysioNet CinC 2016 and
PhysioNet CirCor DigiScope 2022, show that QiVC-Net achieves state-of-the-art
performance, reaching accuracies of 97.84% and 97.89%, respectively. These
findings highlight the versatility of the QiVC framework and its promise for
advancing uncertainty-aware modeling in real-world biomedical signal analysis.
The implementation of the QiVConv layer is openly available in GitHub.

</details>


### [266] [Near-Exponential Savings for Mean Estimation with Active Learning](https://arxiv.org/abs/2511.05736)
*Julian M. Morimoto,Jacob Goldin,Daniel E. Ho*

Main category: cs.LG

TL;DR: 提出了一种名为PartiBandits的主动学习算法，用于在有限标签数量下高效估计多类别随机变量的均值，利用辅助信息提高估计精度。


<details>
  <summary>Details</summary>
Motivation: 在标签数量有限的情况下，如何利用辅助信息（协变量）来更有效地估计随机变量的均值，特别是在协变量对目标变量有信息量的场景中。

Method: PartiBandits是一个两阶段算法：第一阶段学习未标记数据的划分以减少Y的条件方差；第二阶段使用UCB风格的子程序（WarmStart-UCB）按轮次从每个层中请求标签。

Result: 算法产生的估计量满足平方误差为$\tilde{\mathcal{O}}\left( \frac{\nu + \exp(c \cdot (-N/\log(N))) }{N} \right)$，其中$\nu$是贝叶斯最优分类器的风险，在经典设置下达到极小极大最优收敛率。

Conclusion: PartiBandits算法在UCB和基于分歧的主动学习方法之间建立了桥梁，这两种方法原本设计用于处理非常不同的任务，该算法在电子健康记录模拟中展示了有效性。

Abstract: We study the problem of efficiently estimating the mean of a $k$-class random
variable, $Y$, using a limited number of labels, $N$, in settings where the
analyst has access to auxiliary information (i.e.: covariates) $X$ that may be
informative about $Y$. We propose an active learning algorithm ("PartiBandits")
to estimate $\mathbb{E}[Y]$. The algorithm yields an estimate,
$\widehat{\mu}_{\text{PB}}$, such that $\left( \widehat{\mu}_{\text{PB}} -
\mathbb{E}[Y]\right)^2$ is $\tilde{\mathcal{O}}\left( \frac{\nu + \exp(c \cdot
(-N/\log(N))) }{N} \right)$, where $c > 0$ is a constant and $\nu$ is the risk
of the Bayes-optimal classifier. PartiBandits is essentially a two-stage
algorithm. In the first stage, it learns a partition of the unlabeled data that
shrinks the average conditional variance of $Y$. In the second stage it uses a
UCB-style subroutine ("WarmStart-UCB") to request labels from each stratum
round-by-round. Both the main algorithm's and the subroutine's convergence
rates are minimax optimal in classical settings. PartiBandits bridges the UCB
and disagreement-based approaches to active learning despite these two
approaches being designed to tackle very different tasks. We illustrate our
methods through simulation using nationwide electronic health records. Our
methods can be implemented using the PartiBandits package in R.

</details>


### [267] [Primal-Only Actor Critic Algorithm for Robust Constrained Average Cost MDPs](https://arxiv.org/abs/2511.05758)
*Anirudh Satheesh,Sooraj Sathish,Swetha Ganesh,Keenan Powell,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 本文提出了一种用于平均成本鲁棒约束马尔可夫决策过程的演员-评论家算法，解决了强对偶性缺失和鲁棒贝尔曼算子非收缩性的挑战。


<details>
  <summary>Details</summary>
Motivation: 在鲁棒约束平均成本MDP中，由于缺乏强对偶性，无法直接使用标准的原始-对偶方法进行约束强化学习，且平均成本设置下的鲁棒贝尔曼算子在任何范数下都不是收缩的。

Method: 提出了一种演员-评论家算法，用于解决平均成本鲁棒约束MDP问题。

Result: 该方法实现了ε-可行性和ε-最优性，在有松弛假设和无松弛假设下的样本复杂度分别为Õ(ε⁻⁴)和Õ(ε⁻⁶)，与折扣设置相当。

Conclusion: 所提出的算法成功解决了平均成本鲁棒约束MDP中的关键挑战，在样本复杂度方面达到了与折扣设置相当的性能。

Abstract: In this work, we study the problem of finding robust and safe policies in
Robust Constrained Average-Cost Markov Decision Processes (RCMDPs). A key
challenge in this setting is the lack of strong duality, which prevents the
direct use of standard primal-dual methods for constrained RL. Additional
difficulties arise from the average-cost setting, where the Robust Bellman
operator is not a contraction under any norm. To address these challenges, we
propose an actor-critic algorithm for Average-Cost RCMDPs. We show that our
method achieves both \(\epsilon\)-feasibility and \(\epsilon\)-optimality, and
we establish a sample complexities of \(\tilde{O}\left(\epsilon^{-4}\right)\)
and \(\tilde{O}\left(\epsilon^{-6}\right)\) with and without slackness
assumption, which is comparable to the discounted setting.

</details>


### [268] [An Efficient Gradient-Aware Error-Bounded Lossy Compressor for Federated Learning](https://arxiv.org/abs/2511.05770)
*Zhijing Ye,Sheng Di,Jiamin Wang,Zhiqing Zhong,Zhaorui Zhang,Xiaodong Yu*

Main category: cs.LG

TL;DR: 提出了一种针对联邦学习梯度数据的误差有损压缩框架，通过利用跨轮次时间相关性和卷积核结构规律性来提高压缩比，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的通信成本限制了其部署，特别是系统异构性下低带宽客户端成为性能瓶颈。现有的误差有损压缩方法对梯度数据效果不佳，因为梯度数据缺乏空间相关性和平滑性。

Method: 设计了创新的预测机制，包括基于归一化指数移动平均的跨轮次幅度预测器和利用梯度振荡及核级符号一致性的符号预测器，与标准量化器和熵编码器兼容。

Result: 新方法比SZ3实现高达1.53倍的压缩比提升，精度损失更低。在真实FL框架APPFL中，在各种受限带宽场景下将端到端通信时间减少76.1%-96.2%。

Conclusion: 该方法显著提高了联邦学习的通信效率，展示了在实际部署中的强可扩展性。

Abstract: Federated learning (FL) enables collaborative model training without exposing
clients' private data, but its deployment is often constrained by the
communication cost of transmitting gradients between clients and the central
server, especially under system heterogeneity where low-bandwidth clients
bottleneck overall performance. Lossy compression of gradient data can mitigate
this overhead, and error-bounded lossy compression (EBLC) is particularly
appealing for its fine-grained utility-compression tradeoff. However, existing
EBLC methods (e.g., SZ), originally designed for smooth scientific data with
strong spatial locality, rely on generic predictors such as Lorenzo and
interpolation for entropy reduction to improve compression ratio. Gradient
tensors, in contrast, exhibit low smoothness and weak spatial correlation,
rendering these predictors ineffective and leading to poor compression ratios.
To address this limitation, we propose an EBLC framework tailored for FL
gradient data to achieve high compression ratios while preserving model
accuracy. The core of it is an innovative prediction mechanism that exploits
temporal correlations across FL training rounds and structural regularities
within convolutional kernels to reduce residual entropy. The predictor is
compatible with standard quantizers and entropy coders and comprises (1) a
cross-round magnitude predictor based on a normalized exponential moving
average, and (2) a sign predictor that leverages gradient oscillation and
kernel-level sign consistency. Experiments show that this new EBLC yields up to
1.53x higher compression ratios than SZ3 with lower accuracy loss. Integrated
into a real-world FL framework, APPFL, it reduces end-to-end communication time
by 76.1%-96.2% under various constrained-bandwidth scenarios, demonstrating
strong scalability for real-world FL deployments.

</details>


### [269] [MARAuder's Map: Motion-Aware Real-time Activity Recognition with Layout-Based Trajectories](https://arxiv.org/abs/2511.05773)
*Zishuai Liu,Weihang You,Jin Lu,Fei Dou*

Main category: cs.LG

TL;DR: 提出了MARAuder's Map框架，用于从原始未分段传感器流中进行实时活动识别，通过将传感器激活投影到物理平面图生成轨迹感知的图像序列，结合混合深度学习模型处理空间结构和时间依赖关系。


<details>
  <summary>Details</summary>
Motivation: 解决智能家居中基于环境传感器的人类活动识别面临的挑战，包括实时推理需求、空间基础推理和上下文感知的时间建模，现有方法依赖预分段数据且忽略物理环境布局。

Method: 将传感器激活投影到物理平面图生成轨迹感知的图像序列；使用混合深度学习模型联合捕捉空间结构和时间依赖；引入可学习时间嵌入模块编码上下文线索；基于注意力的编码器选择性关注信息片段。

Result: 在多个真实世界智能家居数据集上的广泛实验表明，该方法优于强基线方法，在跨活动转换和时间模糊情况下仍能准确识别。

Conclusion: MARAuder's Map为环境传感器环境中的实时人类活动识别提供了实用解决方案，能够有效处理连续、真实世界部署中的挑战。

Abstract: Ambient sensor-based human activity recognition (HAR) in smart homes remains
challenging due to the need for real-time inference, spatially grounded
reasoning, and context-aware temporal modeling. Existing approaches often rely
on pre-segmented, within-activity data and overlook the physical layout of the
environment, limiting their robustness in continuous, real-world deployments.
In this paper, we propose MARAuder's Map, a novel framework for real-time
activity recognition from raw, unsegmented sensor streams. Our method projects
sensor activations onto the physical floorplan to generate trajectory-aware,
image-like sequences that capture the spatial flow of human movement. These
representations are processed by a hybrid deep learning model that jointly
captures spatial structure and temporal dependencies. To enhance temporal
awareness, we introduce a learnable time embedding module that encodes
contextual cues such as hour-of-day and day-of-week. Additionally, an
attention-based encoder selectively focuses on informative segments within each
observation window, enabling accurate recognition even under cross-activity
transitions and temporal ambiguity. Extensive experiments on multiple
real-world smart home datasets demonstrate that our method outperforms strong
baselines, offering a practical solution for real-time HAR in ambient sensor
environments.

</details>


### [270] [Beyond the Lower Bound: Bridging Regret Minimization and Best Arm Identification in Lexicographic Bandits](https://arxiv.org/abs/2511.05802)
*Bo Xue,Yuanyu Wan,Zhichao Lu,Qingfu Zhang*

Main category: cs.LG

TL;DR: 本文提出了两种基于消除的算法，用于在词典偏好下的多目标决策中同时处理遗憾最小化和最佳臂识别问题。第一种算法按优先级顺序逐层消除次优臂，第二种算法同时利用所有目标的奖励信息，通过跨目标信息共享超越了单目标老虎机问题的已知下界。


<details>
  <summary>Details</summary>
Motivation: 在多目标分层偏好决策中，词典老虎机为按优先级顺序优化多个目标提供了自然框架。以往研究主要关注遗憾最小化，本文旨在弥合词典偏好下遗憾最小化和最佳臂识别之间的差距。

Method: 提出了两种消除基算法：第一种按目标优先级逐层顺序消除次优臂；第二种在每轮中同时利用所有目标的奖励信息，有效利用跨目标依赖关系。

Result: 第一种算法的样本复杂度和遗憾界与最佳单目标算法相当；第二种算法显著超越了单目标老虎机问题的已知下界，体现了多目标设置中跨目标信息共享的优势。实证结果进一步验证了算法相对于基线的优越性能。

Conclusion: 本文成功弥合了词典偏好下遗憾最小化和最佳臂识别之间的差距，提出的算法在保持与单目标算法相当性能的同时，通过跨目标信息共享实现了超越单目标下界的性能提升。

Abstract: In multi-objective decision-making with hierarchical preferences,
lexicographic bandits provide a natural framework for optimizing multiple
objectives in a prioritized order. In this setting, a learner repeatedly
selects arms and observes reward vectors, aiming to maximize the reward for the
highest-priority objective, then the next, and so on. While previous studies
have primarily focused on regret minimization, this work bridges the gap
between \textit{regret minimization} and \textit{best arm identification} under
lexicographic preferences. We propose two elimination-based algorithms to
address this joint objective. The first algorithm eliminates suboptimal arms
sequentially, layer by layer, in accordance with the objective priorities, and
achieves sample complexity and regret bounds comparable to those of the best
single-objective algorithms. The second algorithm simultaneously leverages
reward information from all objectives in each round, effectively exploiting
cross-objective dependencies. Remarkably, it outperforms the known lower bound
for the single-objective bandit problem, highlighting the benefit of
cross-objective information sharing in the multi-objective setting. Empirical
results further validate their superior performance over baselines.

</details>


### [271] [Catching Contamination Before Generation: Spectral Kill Switches for Agents](https://arxiv.org/abs/2511.05804)
*Valentin Noël*

Main category: cs.LG

TL;DR: 提出一种无需额外训练的诊断方法，通过分析注意力机制生成的token图，在早期层计算高频能量比和谱熵两个谱统计量，用于在智能体执行过程中实时检测上下文不一致性。


<details>
  <summary>Details</summary>
Motivation: 智能体语言模型的多步推理链可能因上下文不一致、检索错误或对抗性输入而损坏，传统事后评估为时已晚，因为错误在检测前已传播。

Method: 利用前向传播分析注意力诱导的token图，在早期层计算高频能量比和谱熵两个谱统计量，基于双机制混合假设和单调似然比特性，使用单一阈值进行最优检测。

Result: 高频能量比在多个模型家族中表现出稳健的双峰性，检测开销低于1毫秒，能够在内联安全监控中有效检测上下文污染。

Conclusion: 该方法能够在模型仍在处理文本时检测污染，在错误提交到推理链之前进行干预，为智能体系统提供实时安全保障。

Abstract: Agentic language models compose multi step reasoning chains, yet intermediate
steps can be corrupted by inconsistent context, retrieval errors, or
adversarial inputs, which makes post hoc evaluation too late because errors
propagate before detection. We introduce a diagnostic that requires no
additional training and uses only the forward pass to emit a binary accept or
reject signal during agent execution. The method analyzes token graphs induced
by attention and computes two spectral statistics in early layers, namely the
high frequency energy ratio and spectral entropy. We formalize these signals,
establish invariances, and provide finite sample estimators with uncertainty
quantification. Under a two regime mixture assumption with a monotone
likelihood ratio property, we show that a single threshold on the high
frequency energy ratio is optimal in the Bayes sense for detecting context
inconsistency. Empirically, the high frequency energy ratio exhibits robust
bimodality during context verification across multiple model families, which
enables gating decisions with overhead below one millisecond on our hardware
and configurations. We demonstrate integration into retrieval augmented agent
pipelines and discuss deployment as an inline safety monitor. The approach
detects contamination while the model is still processing the text, before
errors commit to the reasoning chain.

</details>


### [272] [Measuring Model Performance in the Presence of an Intervention](https://arxiv.org/abs/2511.05805)
*Winston Chen,Michael W. Sjoding,Jenna Wiens*

Main category: cs.LG

TL;DR: 本文提出了一种在随机对照试验(RCT)中利用所有数据进行无偏模型评估的方法，解决了传统方法忽略治疗组数据导致效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 在AI社会影响应用中，干预措施会影响结果评估的公正性。虽然RCT的对照组数据可用于无偏评估，但这种方法效率低下，忽略了治疗组数据。考虑到RCT的复杂性和成本，充分利用所有数据至关重要。

Method: 提出了干扰参数加权(NPW)方法，该方法通过重新加权治疗组数据，模拟在没有干预情况下会或不会经历结果的样本分布，从而实现无偏模型评估。

Result: 在合成和真实数据集上的实验表明，与忽略治疗组数据的标准方法相比，NPW方法在各种干预效应和样本量设置下都能产生更好的模型选择效果。

Conclusion: 这项研究为在现实世界环境中实现更高效的模型评估迈出了有意义的一步，通过充分利用RCT中的所有数据来提高模型评估的效率。

Abstract: AI models are often evaluated based on their ability to predict the outcome
of interest. However, in many AI for social impact applications, the presence
of an intervention that affects the outcome can bias the evaluation. Randomized
controlled trials (RCTs) randomly assign interventions, allowing data from the
control group to be used for unbiased model evaluation. However, this approach
is inefficient because it ignores data from the treatment group. Given the
complexity and cost often associated with RCTs, making the most use of the data
is essential. Thus, we investigate model evaluation strategies that leverage
all data from an RCT. First, we theoretically quantify the estimation bias that
arises from na\"ively aggregating performance estimates from treatment and
control groups, and derive the condition under which this bias leads to
incorrect model selection. Leveraging these theoretical insights, we propose
nuisance parameter weighting (NPW), an unbiased model evaluation approach that
reweights data from the treatment group to mimic the distributions of samples
that would or would not experience the outcome under no intervention. Using
synthetic and real-world datasets, we demonstrate that our proposed evaluation
approach consistently yields better model selection than the standard approach,
which ignores data from the treatment group, across various intervention effect
and sample size settings. Our contribution represents a meaningful step towards
more efficient model evaluation in real-world contexts.

</details>


### [273] [MOSS: Efficient and Accurate FP8 LLM Training with Microscaling and Automatic Scaling](https://arxiv.org/abs/2511.05811)
*Yu Zhang,Hui-Ling Zhen,Mingxuan Yuan,Bei Yu*

Main category: cs.LG

TL;DR: MOSS是一个新颖的FP8训练框架，通过两级微缩放策略和自动权重缩放，在保持训练性能的同时显著提高效率，在7B参数模型上实现比BF16基线高34%的训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: FP8格式训练大型语言模型能提供显著的效率提升，但降低的数值精度对训练稳定性和准确性构成挑战。现有框架使用混合粒度量化方法存在去量化开销高和在线量化效率低的问题。

Method: MOSS提出两个关键创新：(1) 两级微缩放策略，结合高精度全局缩放和紧凑的2次幂局部缩放来量化敏感激活；(2) 线性层权重自动缩放，通过预测和调整缩放因子来消除昂贵的最大归约操作。

Result: MOSS能够高效训练7B参数模型，在保持与BF16基线相当性能的同时，实现高达34%的训练吞吐量提升。

Conclusion: MOSS框架成功解决了FP8训练中的效率和数值稳定性问题，为大型语言模型的高效训练提供了可行解决方案。

Abstract: Training large language models with FP8 formats offers significant efficiency
gains. However, the reduced numerical precision of FP8 poses challenges for
stable and accurate training. Current frameworks preserve training performance
using mixed-granularity quantization, i.e., applying per-group quantization for
activations and per-tensor/block quantization for weights. While effective,
per-group quantization requires scaling along the inner dimension of matrix
multiplication, introducing additional dequantization overhead. Moreover, these
frameworks often rely on just-in-time scaling to dynamically adjust scaling
factors based on the current data distribution. However, this online
quantization is inefficient for FP8 training, as it involves multiple memory
reads and writes that negate the performance benefits of FP8. To overcome these
limitations, we propose MOSS, a novel FP8 training framework that ensures both
efficiency and numerical stability. MOSS introduces two key innovations: (1) a
two-level microscaling strategy for quantizing sensitive activations, which
balances precision and dequantization cost by combining a high-precision global
scale with compact, power-of-two local scales; and (2) automatic scaling for
weights in linear layers, which eliminates the need for costly max-reduction
operations by predicting and adjusting scaling factors during training.
Leveraging these techniques, MOSS enables efficient FP8 training of a 7B
parameter model, achieving performance comparable to the BF16 baseline while
achieving up to 34% higher training throughput.

</details>


### [274] [AiEDA: An Open-Source AI-Aided Design Library for Design-to-Vector](https://arxiv.org/abs/2511.05823)
*Yihang Qiu,Zengrong Huang,Simin Tao,Hongda Zhang,Weiguo Li,Xinhua Lai,Rui Wang,Weiqiang Wang,Xingquan Li*

Main category: cs.LG

TL;DR: 提出了一个统一的开源EDA库AiEDA，解决了当前AI-EDA基础设施碎片化问题，通过设计到向量的数据表示技术，建立了AI辅助设计范式，并生成了600GB的结构化数据集iDATA。


<details>
  <summary>Details</summary>
Motivation: 当前AI-EDA基础设施存在碎片化问题，包括碎片化的流程引擎、异构的文件格式、非标准化的数据提取方法和组织不良的数据存储，缺乏从设计执行到AI集成的完整数据管道解决方案。

Method: 开发了AiEDA统一开源库，集成多种设计到向量数据表示技术，将芯片设计数据转换为通用多级向量表示，提供完整的物理设计流程和标准化的Python接口。

Result: 生成了iDATA数据集（600GB，来自50个真实28nm芯片设计），并在7个代表性AAD任务（预测、生成、优化和分析）中验证了有效性。

Conclusion: AiEDA库和iDATA数据集为未来AI-EDA研究提供了基础，代码已公开，完整数据集正在准备公开发布。

Abstract: Recent research has demonstrated that artificial intelligence (AI) can assist
electronic design automation (EDA) in improving both the quality and efficiency
of chip design. But current AI for EDA (AI-EDA) infrastructures remain
fragmented, lacking comprehensive solutions for the entire data pipeline from
design execution to AI integration. Key challenges include fragmented flow
engines that generate raw data, heterogeneous file formats for data exchange,
non-standardized data extraction methods, and poorly organized data storage.
This work introduces a unified open-source library for EDA (AiEDA) that
addresses these issues. AiEDA integrates multiple design-to-vector data
representation techniques that transform diverse chip design data into
universal multi-level vector representations, establishing an AI-aided design
(AAD) paradigm optimized for AI-EDA workflows. AiEDA provides complete physical
design flows with programmatic data extraction and standardized Python
interfaces bridging EDA datasets and AI frameworks. Leveraging the AiEDA
library, we generate iDATA, a 600GB dataset of structured data derived from 50
real chip designs (28nm), and validate its effectiveness through seven
representative AAD tasks spanning prediction, generation, optimization and
analysis. The code is publicly available at
https://github.com/OSCC-Project/AiEDA, while the full iDATA dataset is being
prepared for public release, providing a foundation for future AI-EDA research.

</details>


### [275] [CADM: Cluster-customized Adaptive Distance Metric for Categorical Data Clustering](https://arxiv.org/abs/2511.05826)
*Taixi Chen,Yiu-ming Cheung,Yiqun Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种针对分类数据聚类的定制化距离度量方法，能够根据不同聚类中属性的分布差异来更新距离计算，并扩展到混合数据类型。


<details>
  <summary>Details</summary>
Motivation: 分类数据聚类中合适的距离度量至关重要，但由于分类数据无法直接计算距离，且不同聚类中属性值的距离通常因分布不同而变化，现有方法未能考虑这一点，导致距离测量不合理。

Method: 提出了一种聚类定制化的距离度量方法，能够基于每个聚类中属性的不同分布竞争性地更新距离，并将该方法扩展到包含数值和分类属性的混合数据。

Result: 实验证明该方法有效，在14个数据集上平均排名约为第一。

Conclusion: 所提出的聚类定制化距离度量方法能够有效解决分类数据聚类中的距离测量问题，并在多个数据集上表现出优越性能。

Abstract: An appropriate distance metric is crucial for categorical data clustering, as
the distance between categorical data cannot be directly calculated. However,
the distances between attribute values usually vary in different clusters
induced by their different distributions, which has not been taken into
account, thus leading to unreasonable distance measurement. Therefore, we
propose a cluster-customized distance metric for categorical data clustering,
which can competitively update distances based on different distributions of
attributes in each cluster. In addition, we extend the proposed distance metric
to the mixed data that contains both numerical and categorical attributes.
Experiments demonstrate the efficacy of the proposed method, i.e., achieving an
average ranking of around first in fourteen datasets. The source code is
available at https://anonymous.4open.science/r/CADM-47D8

</details>


### [276] [Predicting the Future by Retrieving the Past](https://arxiv.org/abs/2511.05859)
*Dazhao Du,Tao Han,Song Guo*

Main category: cs.LG

TL;DR: 提出PFRP方法，通过检索全局历史模式来增强单变量时间序列预测，显著提升现有预测模型性能8.4%


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在推理时只能依赖滑动窗口的局部上下文，无法显式访问全局历史知识，导致丰富的历史模式未被充分利用

Method: 构建全局记忆库存储历史模式，使用检索机制提取相似模式生成全局预测，与局部预测模型输出自适应结合

Result: 在7个真实世界数据集上的实验表明，PFRP显著提升了先进单变量预测模型的平均性能8.4%

Conclusion: PFRP通过显式整合全局历史数据，有效提升了时间序列预测的准确性和可解释性

Abstract: Deep learning models such as MLP, Transformer, and TCN have achieved
remarkable success in univariate time series forecasting, typically relying on
sliding window samples from historical data for training. However, while these
models implicitly compress historical information into their parameters during
training, they are unable to explicitly and dynamically access this global
knowledge during inference, relying only on the local context within the
lookback window. This results in an underutilization of rich patterns from the
global history. To bridge this gap, we propose Predicting the Future by
Retrieving the Past (PFRP), a novel approach that explicitly integrates global
historical data to enhance forecasting accuracy. Specifically, we construct a
Global Memory Bank (GMB) to effectively store and manage global historical
patterns. A retrieval mechanism is then employed to extract similar patterns
from the GMB, enabling the generation of global predictions. By adaptively
combining these global predictions with the outputs of any local prediction
model, PFRP produces more accurate and interpretable forecasts. Extensive
experiments conducted on seven real-world datasets demonstrate that PFRP
significantly enhances the average performance of advanced univariate
forecasting models by 8.4\%. Codes can be found in
https://github.com/ddz16/PFRP.

</details>


### [277] [EMOD: A Unified EEG Emotion Representation Framework Leveraging V-A Guided Contrastive Learning](https://arxiv.org/abs/2511.05863)
*Yuning Chen,Sha Zhao,Shijian Li,Gang Pan*

Main category: cs.LG

TL;DR: EMOD是一个统一的EEG情感表示框架，利用效价-唤醒度引导的对比学习来解决EEG情感识别中的数据集异构性问题，实现了跨数据集的强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在单一EEG情感数据集上表现良好，但由于标注方案和数据格式的异质性，跨数据集的泛化能力有限。需要解决语义和结构差异问题。

Method: 提出EMOD框架：1）将离散和连续情感标签投影到统一的V-A空间；2）使用软加权监督对比损失促进情感相似样本在潜在空间聚类；3）采用灵活的三域编码器和时空变换器处理可变EEG格式。

Result: 在8个公共EEG数据集上预训练，在3个基准数据集上评估，EMOD实现了最先进的性能，展示了强大的适应性和泛化能力。

Conclusion: EMOD通过统一的V-A空间表示和对比学习，有效解决了EEG情感识别中的数据集异构性问题，为跨数据集情感识别提供了有效的解决方案。

Abstract: Emotion recognition from EEG signals is essential for affective computing and
has been widely explored using deep learning. While recent deep learning
approaches have achieved strong performance on single EEG emotion datasets,
their generalization across datasets remains limited due to the heterogeneity
in annotation schemes and data formats. Existing models typically require
dataset-specific architectures tailored to input structure and lack semantic
alignment across diverse emotion labels. To address these challenges, we
propose EMOD: A Unified EEG Emotion Representation Framework Leveraging
Valence-Arousal (V-A) Guided Contrastive Learning. EMOD learns transferable and
emotion-aware representations from heterogeneous datasets by bridging both
semantic and structural gaps. Specifically, we project discrete and continuous
emotion labels into a unified V-A space and formulate a soft-weighted
supervised contrastive loss that encourages emotionally similar samples to
cluster in the latent space. To accommodate variable EEG formats, EMOD employs
a flexible backbone comprising a Triple-Domain Encoder followed by a
Spatial-Temporal Transformer, enabling robust extraction and integration of
temporal, spectral, and spatial features. We pretrain EMOD on eight public EEG
datasets and evaluate its performance on three benchmark datasets. Experimental
results show that EMOD achieves state-of-the-art performance, demonstrating
strong adaptability and generalization across diverse EEG-based emotion
recognition scenarios.

</details>


### [278] [From Kernels to Attention: A Transformer Framework for Density and Score Estimation](https://arxiv.org/abs/2511.05924)
*Vasily Ilin,Peter Sushko*

Main category: cs.LG

TL;DR: 提出基于注意力机制的统一框架，用于联合进行分数和密度估计，通过序列到序列任务实现，开发了置换和仿射等变的Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 传统分数匹配方法需要为每个分布训练单独模型，缺乏通用性和泛化能力，需要一种分布无关的算子来统一处理不同密度和样本量。

Method: 使用交叉注意力机制连接观测样本与任意查询点，构建置换和仿射等变的Transformer架构，能够从独立同分布样本中直接估计概率密度和分数。

Result: 模型在误差和扩展性方面显著优于传统核密度估计和分数去偏核密度估计，运行时间扩展性更好，注意力权重能够恢复经典核密度估计。

Conclusion: Transformer可作为非参数密度和分数估计的通用数据自适应算子，建立了经典核密度估计与Transformer架构之间的理论联系。

Abstract: We introduce a unified attention-based framework for joint score and density
estimation. Framing the problem as a sequence-to-sequence task, we develop a
permutation- and affine-equivariant transformer that estimates both the
probability density $f(x)$ and its score $\nabla_x \log f(x)$ directly from
i.i.d. samples. Unlike traditional score-matching methods that require training
a separate model for each distribution, our approach learns a single
distribution-agnostic operator that generalizes across densities and sample
sizes. The architecture employs cross-attention to connect observed samples
with arbitrary query points, enabling generalization beyond the training data,
while built-in symmetry constraints ensure equivariance to permutation and
affine transformations. Analytically, we show that the attention weights can
recover classical kernel density estimation (KDE), and verify it empirically,
establishing a principled link between classical KDE and the transformer
architecture. Empirically, the model achieves substantially lower error and
better scaling than KDE and score-debiased KDE (SD-KDE), while exhibiting
better runtime scaling. Together, these results establish transformers as
general-purpose, data-adaptive operators for nonparametric density and score
estimation.

</details>


### [279] [Deep Survival Analysis of Longitudinal EHR Data for Joint Prediction of Hospitalization and Death in COPD Patients](https://arxiv.org/abs/2511.05960)
*Enrico Manzini,Thomas Gonzalez Saito,Joan Escudero,Ana Génova,Cristina Caso,Tomas Perez-Porcuna,Alexandre Perera-Lluna*

Main category: cs.LG

TL;DR: 本研究使用纵向电子健康记录数据，比较统计模型、机器学习和深度学习方法，预测COPD患者的住院和死亡风险。结果显示，采用循环架构的深度学习模型在预测性能上优于其他方法。


<details>
  <summary>Details</summary>
Motivation: COPD患者住院风险增加且与生存率下降密切相关，但预测这些事件的时间仍然具有挑战性，文献中对此关注有限。

Method: 使用西班牙加泰罗尼亚SIDIAP数据库中超过15万患者的数据（2013-2017年），将住院建模为首次事件，死亡作为半竞争性终点事件。评估了Cox比例风险、SurvivalBoost、DeepPseudo、SurvTRACE、Dynamic Deep-Hit和Deep Recurrent Survival Machine等多种模型。

Result: 深度学习模型，特别是采用循环架构的模型，在一致性指数和时间依赖性AUC方面优于机器学习和线性方法，尤其是对于更难预测的住院事件。

Conclusion: 这是首次在纵向EHR数据上应用深度生存分析来联合预测COPD患者的多个时间到事件结果，突出了深度学习方法在捕捉时间模式和改善风险分层方面的潜力。

Abstract: Patients with chronic obstructive pulmonary disease (COPD) have an increased
risk of hospitalizations, strongly associated with decreased survival, yet
predicting the timing of these events remains challenging and has received
limited attention in the literature. In this study, we performed survival
analysis to predict hospitalization and death in COPD patients using
longitudinal electronic health records (EHRs), comparing statistical models,
machine learning (ML), and deep learning (DL) approaches. We analyzed data from
more than 150k patients from the SIDIAP database in Catalonia, Spain, from 2013
to 2017, modeling hospitalization as a first event and death as a
semi-competing terminal event. Multiple models were evaluated, including Cox
proportional hazards, SurvivalBoost, DeepPseudo, SurvTRACE, Dynamic Deep-Hit,
and Deep Recurrent Survival Machine. Results showed that DL models utilizing
recurrent architectures outperformed both ML and linear approaches in
concordance and time-dependent AUC, especially for hospitalization, which
proved to be the harder event to predict. This study is, to our knowledge, the
first to apply deep survival analysis on longitudinal EHR data to jointly
predict multiple time-to-event outcomes in COPD patients, highlighting the
potential of DL approaches to capture temporal patterns and improve risk
stratification.

</details>


### [280] [Next-Latent Prediction Transformers Learn Compact World Models](https://arxiv.org/abs/2511.05963)
*Jayden Teoh,Manan Tomar,Kwangjun Ahn,Edward S. Hu,Pratyusha Sharma,Riashat Islam,Alex Lamb,John Langford*

Main category: cs.LG

TL;DR: NextLat通过引入潜在空间的自监督预测来增强标准的下一个token训练，使transformer学习能够预测下一个潜在状态的表示，从而注入循环归纳偏置，形成紧凑的内部世界模型。


<details>
  <summary>Details</summary>
Motivation: 标准transformer由于缺乏压缩历史为紧凑潜在状态的固有激励，导致学习解决方案泛化能力差。

Method: 在标准下一个token训练基础上，增加潜在空间的自监督预测，训练transformer学习能够预测下一个潜在状态的表示。

Result: 在多个序列建模基准测试中，NextLat在下游准确性、表示压缩和前瞻规划方面相比标准下一个token训练显示出显著提升。

Conclusion: NextLat是一个简单高效的范式，能够塑造transformer表示以实现更强的泛化能力。

Abstract: Transformers replace recurrence with a memory that grows with sequence length
and self-attention that enables ad-hoc look ups over past tokens. Consequently,
they lack an inherent incentive to compress history into compact latent states
with consistent transition rules. This often leads to learning solutions that
generalize poorly. We introduce Next-Latent Prediction (NextLat), which extends
standard next-token training with self-supervised predictions in the latent
space. Specifically, NextLat trains a transformer to learn latent
representations that are predictive of its next latent state given the next
output token. Theoretically, we show that these latents provably converge to
belief states, compressed information of the history necessary to predict the
future. This simple auxiliary objective also injects a recurrent inductive bias
into transformers, while leaving their architecture, parallel training, and
inference unchanged. NextLat effectively encourages the transformer to form
compact internal world models with its own belief states and transition
dynamics -- a crucial property absent in standard next-token prediction
transformers. Empirically, across benchmarks targeting core sequence modeling
competencies -- world modeling, reasoning, planning, and language modeling --
NextLat demonstrates significant gains over standard next-token training in
downstream accuracy, representation compression, and lookahead planning.
NextLat stands as a simple and efficient paradigm for shaping transformer
representations toward stronger generalization.

</details>


### [281] [Kunlun Anomaly Troubleshooter: Enabling Kernel-Level Anomaly Detection and Causal Reasoning for Large Model Distributed Inference](https://arxiv.org/abs/2511.05978)
*Yuyang Liu,Jingjing Cai,Jiayi Ren,Peng Zhou,Danyang Zhang,Yin Du,Shijian Li*

Main category: cs.LG

TL;DR: KAT是首个针对大模型分布式推理的异常排查框架，通过GPU工作器同步性和函数追踪数据实现纳秒级异常检测，结合领域适配的LLM进行因果推理，在阿里云生产环境中达到0.884精度和0.936召回率。


<details>
  <summary>Details</summary>
Motivation: 大模型分布式推理中的异常排查需要大量专家手动操作，诊断过程耗时且准确率低，迫切需要自动化解决方案。

Method: 利用GPU工作器的同步性和一致性，创新性地使用函数追踪数据检测内核级异常和相关硬件组件；集成检测结果到领域适配的LLM中，提供系统性因果推理和自然语言解释。

Result: 在阿里云生产环境评估中，KAT达到0.884的精确度和0.936的召回率，显著缩小诊断范围并提高排查效率和成功率。

Conclusion: KAT框架有效解决了大模型分布式推理中的异常排查难题，通过精确的异常检测和智能推理显著提升了诊断效率和准确性。

Abstract: Anomaly troubleshooting for large model distributed inference (LMDI) remains
a critical challenge. Resolving anomalies such as inference performance
degradation or latency jitter in distributed system demands significant manual
efforts from domain experts, resulting in extremely time-consuming diagnosis
processes with relatively low accuracy. In this paper, we introduce Kunlun
Anomaly Troubleshooter (KAT), the first anomaly troubleshooting framework
tailored for LMDI. KAT addresses this problem through two core innovations.
First, KAT exploits the synchronicity and consistency of GPU workers,
innovatively leverages function trace data to precisely detect kernel-level
anomalies and associated hardware components at nanosecond resolution. Second,
KAT integrates these detection results into a domain-adapted LLM, delivering
systematic causal reasoning and natural language interpretation of complex
anomaly symptoms. Evaluations conducted in Alibaba Cloud Service production
environment indicate that KAT achieves over 0.884 precision and 0.936 recall in
anomaly detection, providing detail anomaly insights that significantly narrow
down the diagnostic scope and improve both the efficiency and success rate of
troubleshooting.

</details>


### [282] [Are Time-Indexed Foundation Models the Future of Time Series Imputation?](https://arxiv.org/abs/2511.05980)
*Etienne Le Naour,Tahar Nabil,Adrien Petralia,Ghislain Agoua*

Main category: cs.LG

TL;DR: 本文首次对时间索引基础模型（TabPFN-TS和MoTM）进行大规模零样本插补实证研究，在33个域外数据集上评估其无需重新训练即可恢复缺失值的能力。


<details>
  <summary>Details</summary>
Motivation: 时间序列插补的基础模型研究尚未充分探索，现有TabPFN-TS和MoTM模型属于时间索引基础模型家族，需要对其零样本插补能力进行系统性评估。

Method: 在33个域外数据集（约130万个插补窗口）上进行广泛的单变量实验，评估模型在推理时整合协变量以提高准确性而无需微调的能力。

Result: 研究结果表明，时间索引基础模型是实现现实世界时间序列通用零样本插补的强大且实用的步骤。

Conclusion: 时间索引基础模型为零样本时间序列插补提供了有效的解决方案，能够在广泛场景下无需重新训练即可恢复缺失值。

Abstract: Foundation models for time series imputation remain largely unexplored.
Recently, two such models, TabPFN-TS and MoTM, have emerged. These models share
a common philosophy that places them within the family of time-indexed
foundation models. This paper presents the first large-scale empirical study of
these models for zero-shot imputation, which enables missing value recovery
without retraining across a wide range of scenarios. We conduct extensive
univariate experiments across 33 out-of-domain datasets (approximately 1.3M
imputation windows) and evaluate their ability to integrate covariates at
inference time to improve accuracy without fine-tuning. Our results demonstrate
that time-indexed foundation models are a powerful and practical step toward
achieving general-purpose, zero-shot imputation for real-world time series.

</details>


### [283] [Bespoke Co-processor for Energy-Efficient Health Monitoring on RISC-V-based Flexible Wearables](https://arxiv.org/abs/2511.05985)
*Theofanis Vergos,Polykarpos Vergos,Mehdi B. Tahoori,Georgios Zervakis*

Main category: cs.LG

TL;DR: 提出了一种机械柔性RISC-V处理器，集成定制乘累加协处理器，通过固定系数优化能量效率和延迟，实现紧凑的医疗可穿戴设备MLP推理。


<details>
  <summary>Details</summary>
Motivation: 柔性电子在医疗可穿戴设备中具有独特优势，但现有系统存在门数有限、特征尺寸大、静态功耗高等问题，导致片上机器学习分类面临挑战，需要更高效的解决方案。

Method: 采用约束编程问题联合确定协处理器常数并优化映射多层感知器推理操作，利用柔性技术的低制造成本实现紧凑的模型特定硬件。

Result: 后布局结果显示在多个医疗数据集上实现近实时性能，电路功耗符合现有柔性电池预算，面积仅2.42平方毫米，相比现有技术平均加速2.35倍，能耗降低2.15倍。

Conclusion: 该方法为可访问、可持续和贴合式医疗可穿戴设备提供了有前景的技术路径。

Abstract: Flexible electronics offer unique advantages for conformable, lightweight,
and disposable healthcare wearables. However, their limited gate count, large
feature sizes, and high static power consumption make on-body machine learning
classification highly challenging. While existing bendable RISC-V systems
provide compact solutions, they lack the energy efficiency required. We present
a mechanically flexible RISC-V that integrates a bespoke multiply-accumulate
co-processor with fixed coefficients to maximize energy efficiency and minimize
latency. Our approach formulates a constrained programming problem to jointly
determine co-processor constants and optimally map Multi-Layer Perceptron (MLP)
inference operations, enabling compact, model-specific hardware by leveraging
the low fabrication and non-recurring engineering costs of flexible
technologies. Post-layout results demonstrate near-real-time performance across
several healthcare datasets, with our circuits operating within the power
budget of existing flexible batteries and occupying only 2.42 mm^2, offering a
promising path toward accessible, sustainable, and conformable healthcare
wearables. Our microprocessors achieve an average 2.35x speedup and 2.15x lower
energy consumption compared to the state of the art.

</details>


### [284] [MoSKA: Mixture of Shared KV Attention for Efficient Long-Sequence LLM Inference](https://arxiv.org/abs/2511.06010)
*Myunghyun Rhee,Sookyung Choi,Euiseok Kim,Joonseop Sim,Youngpyo Joo,Hoshik Kim*

Main category: cs.LG

TL;DR: MoSKA是一种解决LLM中KV缓存瓶颈的新架构，通过区分请求特有的数据和共享数据，将共享数据的注意力计算从内存受限的GEMV操作转换为计算受限的GEMM操作，显著提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型上下文长度的增加，KV缓存成为性能瓶颈，其内存受限特性导致GPU利用率低下。需要解决上下文数据异质性带来的效率问题。

Method: 采用混合共享KV注意力机制，区分每个请求特有的序列和大量重复使用的共享序列。通过批处理并发请求，将共享数据的注意力计算转换为单个计算密集型GEMM操作，并辅以MoE启发的稀疏注意力策略和专门化硬件基础设施。

Result: 在高上下文共享的工作负载中，相比基线实现了高达538.7倍的吞吐量提升。

Conclusion: MoSKA为可扩展的LLM推理提供了一条清晰的架构路径，有效解决了KV缓存带来的性能瓶颈问题。

Abstract: The escalating context length in Large Language Models (LLMs) creates a
severe performance bottleneck around the Key-Value (KV) cache, whose
memory-bound nature leads to significant GPU under-utilization. This paper
introduces Mixture of Shared KV Attention (MoSKA), an architecture that
addresses this challenge by exploiting the heterogeneity of context data. It
differentiates between per-request unique and massively reused shared
sequences. The core of MoSKA is a novel Shared KV Attention mechanism that
transforms the attention on shared data from a series of memory-bound GEMV
operations into a single, compute-bound GEMM by batching concurrent requests.
This is supported by an MoE-inspired sparse attention strategy that prunes the
search space and a tailored Disaggregated Infrastructure that specializes
hardware for unique and shared data. This comprehensive approach demonstrates a
throughput increase of up to 538.7x over baselines in workloads with high
context sharing, offering a clear architectural path toward scalable LLM
inference.

</details>


### [285] [Lethe: Layer- and Time-Adaptive KV Cache Pruning for Reasoning-Intensive LLM Serving](https://arxiv.org/abs/2511.06029)
*Hui Zeng,Daming Zhao,Pengfei Yang,Wenxuan Hou,Tianyang Zheng,Hui Li,Weiye Ji,Jidong Zhai*

Main category: cs.LG

TL;DR: Lethe是一个动态KV缓存管理框架，通过空间维度的层间稀疏感知分配和时间维度的多轮token剪枝，有效减少大语言模型生成推理时的内存和延迟开销。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成推理涉及长解码序列，导致KV缓存积累带来显著内存和延迟开销。现有KV压缩方法主要关注减少长输入序列的预填充内存，但无法有效处理长文本生成的动态和层敏感特性。

Method: Lethe框架在空间维度进行层间稀疏感知分配，基于估计的注意力冗余为每个transformer层分配token剪枝预算；在时间维度通过基于新近感知选择性保留(RASR)机制进行多轮token剪枝，该机制扩展了传统基于新近的启发式方法，同时考虑从演化注意力模式中推导的token相关性。

Result: 实验结果表明，Lethe在不同模型和任务上实现了效率与生成质量的良好平衡，吞吐量最高提升2.56倍。

Conclusion: Lethe通过动态KV缓存管理有效解决了长文本生成推理中的效率问题，在保持生成质量的同时显著提升了系统性能。

Abstract: Generative reasoning with large language models (LLMs) often involves long
decoding sequences, leading to substantial memory and latency overheads from
accumulating key-value (KV) caches. While existing KV compression methods
primarily focus on reducing prefill memory from long input sequences, they fall
short in addressing the dynamic and layer-sensitive nature of long-form
generation, which is central to reasoning tasks. We propose Lethe, a dynamic KV
cache management framework that introduces adaptivity along both the spatial
and temporal dimensions of decoding. Along the spatial dimension, Lethe
performs layerwise sparsity-aware allocation, assigning token pruning budgets
to each transformer layer based on estimated attention redundancy. Along the
temporal dimension, Lethe conducts multi-round token pruning during generation,
driven by a Recency-Aware Selective Retention} (RASR) mechanism. RASR extends
traditional recency-based heuristics by also considering token relevance
derived from evolving attention patterns, enabling informed decisions about
which tokens to retain or evict. Empirical results demonstrate that Lethe
achieves a favorable balance between efficiency and generation quality across
diverse models and tasks, increases throughput by up to 2.56x.

</details>


### [286] [Advancing Ocean State Estimation with efficient and scalable AI](https://arxiv.org/abs/2511.06041)
*Yanfei Xiang,Yuan Gao,Hao Wu,Quan Zhang,Ruiqi Shu,Xiao Zhou,Xi Wu,Xiaomeng Huang*

Main category: cs.LG

TL;DR: ADAF-Ocean是一个AI驱动的海洋数据同化框架，能够直接同化多源多尺度观测数据，无需插值或数据稀疏化，通过AI超分辨率从1°粗网格重建0.25°中尺度动力学，将全球预报技能延长20天。


<details>
  <summary>Details</summary>
Motivation: 解决传统数据同化和深度学习方法在计算可扩展性和数据保真度方面的双重瓶颈，实现准确高效的全球海洋状态估计。

Method: 受神经过程启发，学习从异构输入到海洋状态的连续映射，通过AI驱动超分辨率从1°粗网格重建0.25°中尺度动力学，仅比1°配置增加3.7%参数。

Result: 与没有同化的基线相比，ADAF-Ocean将全球预报技能延长了20天，同时保持计算效率和可扩展性。

Conclusion: 该框架为实时高分辨率地球系统监测建立了一条计算可行且科学严谨的途径。

Abstract: Accurate and efficient global ocean state estimation remains a grand
challenge for Earth system science, hindered by the dual bottlenecks of
computational scalability and degraded data fidelity in traditional data
assimilation (DA) and deep learning (DL) approaches. Here we present an
AI-driven Data Assimilation Framework for Ocean (ADAF-Ocean) that directly
assimilates multi-source and multi-scale observations, ranging from sparse
in-situ measurements to 4 km satellite swaths, without any interpolation or
data thinning. Inspired by Neural Processes, ADAF-Ocean learns a continuous
mapping from heterogeneous inputs to ocean states, preserving native data
fidelity. Through AI-driven super-resolution, it reconstructs 0.25$^\circ$
mesoscale dynamics from coarse 1$^\circ$ fields, which ensures both efficiency
and scalability, with just 3.7\% more parameters than the 1$^\circ$
configuration. When coupled with a DL forecasting system, ADAF-Ocean extends
global forecast skill by up to 20 days compared to baselines without
assimilation. This framework establishes a computationally viable and
scientifically rigorous pathway toward real-time, high-resolution Earth system
monitoring.

</details>


### [287] [How Particle-System Random Batch Methods Enhance Graph Transformer: Memory Efficiency and Parallel Computing Strategy](https://arxiv.org/abs/2511.06044)
*Hanwen Liu,Yixuan Ma,Shi Jin,Yuguang Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为随机批量注意力(RBA)的线性自注意力机制，该机制在保持表达能力的同时具有线性时间复杂度，并提供了理论收敛性分析。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制虽然表达能力强大，但其二次复杂度限制了实际应用。现有的稀疏注意力机制缺乏对其表达能力在降低复杂度情况下的理论分析。

Method: 提出随机批量注意力(RBA)，这是一种线性自注意力机制，基于计算数学中的随机批量方法，具有理论支持的表达能力保持能力。

Result: 实验证明RBA具有线性时间复杂度，可在新维度上并行实现以节省内存，能够改进现有模型中的注意力机制，并在大型图数据上验证了其优势。

Conclusion: 随机批量注意力机制为注意力机制分析提供了新的理论工具，具有线性复杂度和理论收敛保证，能够有效改进现有模型。

Abstract: Attention mechanism is a significant part of Transformer models. It helps
extract features from embedded vectors by adding global information and its
expressivity has been proved to be powerful. Nevertheless, the quadratic
complexity restricts its practicability. Although several researches have
provided attention mechanism in sparse form, they are lack of theoretical
analysis about the expressivity of their mechanism while reducing complexity.
In this paper, we put forward Random Batch Attention (RBA), a linear
self-attention mechanism, which has theoretical support of the ability to
maintain its expressivity. Random Batch Attention has several significant
strengths as follows: (1) Random Batch Attention has linear time complexity.
Other than this, it can be implemented in parallel on a new dimension, which
contributes to much memory saving. (2) Random Batch Attention mechanism can
improve most of the existing models by replacing their attention mechanisms,
even many previously improved attention mechanisms. (3) Random Batch Attention
mechanism has theoretical explanation in convergence, as it comes from Random
Batch Methods on computation mathematics. Experiments on large graphs have
proved advantages mentioned above. Also, the theoretical modeling of
self-attention mechanism is a new tool for future research on
attention-mechanism analysis.

</details>


### [288] [Function Based Isolation Forest (FuBIF): A Unifying Framework for Interpretable Isolation-Based Anomaly Detection](https://arxiv.org/abs/2511.06054)
*Alessio Arcudi,Alessandro Ferreri,Francesco Borsatti,Gian Antonio Susto*

Main category: cs.LG

TL;DR: 本文提出了基于函数的隔离森林(FuBIF)，这是对传统隔离森林(IF)的泛化，允许使用实值函数进行数据集分支，显著提高了评估树构建的灵活性。同时提出了FuBIF特征重要性(FuBIFFI)算法来增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统隔离森林(IF)在异常检测中存在适应性和偏差限制，需要更灵活的方法来处理复杂数据集。

Method: FuBIF通过使用实值函数进行数据集分支来泛化IF，FuBIFFI算法为FuBIF模型提供特征重要性评分以增强可解释性。

Result: FuBIF在性能评估中优于现有方法，提供了更灵活的异常检测框架。

Conclusion: FuBIF显著提高了隔离森林的灵活性和性能，开源实现促进了进一步研究和可复现性。

Abstract: Anomaly Detection (AD) is evolving through algorithms capable of identifying
outliers in complex datasets. The Isolation Forest (IF), a pivotal AD
technique, exhibits adaptability limitations and biases. This paper introduces
the Function-based Isolation Forest (FuBIF), a generalization of IF that
enables the use of real-valued functions for dataset branching, significantly
enhancing the flexibility of evaluation tree construction. Complementing this,
the FuBIF Feature Importance (FuBIFFI) algorithm extends the interpretability
in IF-based approaches by providing feature importance scores across possible
FuBIF models. This paper details the operational framework of FuBIF, evaluates
its performance against established methods, and explores its theoretical
contributions. An open-source implementation is provided to encourage further
research and ensure reproducibility.

</details>


### [289] [CatBack: Universal Backdoor Attacks on Tabular Data via Categorical Encoding](https://arxiv.org/abs/2511.06072)
*Behrad Tajalli,Stefanos Koffas,Stjepan Picek*

Main category: cs.LG

TL;DR: 提出了一种针对表格数据的后门攻击方法，通过将分类值转换为浮点表示，创建适用于所有特征的梯度扰动，在多种数据集和模型上实现高达100%的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击研究主要关注图像等同质数据，而表格数据由于包含数值和分类特征，攻击更具挑战性，需要开发专门的方法。

Method: 提出将分类值转换为浮点表示的新技术，保持清洁模型准确性的同时创建适用于所有特征的梯度扰动，支持白盒和黑盒攻击场景。

Result: 在5个数据集和4个流行模型上评估，攻击成功率高达100%，成功绕过Spectral Signatures、Neural Cleanse等先进防御机制和异常检测方法。

Conclusion: 该方法揭示了表格数据的严重安全漏洞，性能超越Tabdoor等现有方法，同时保持对防御机制的隐蔽性。

Abstract: Backdoor attacks in machine learning have drawn significant attention for
their potential to compromise models stealthily, yet most research has focused
on homogeneous data such as images. In this work, we propose a novel backdoor
attack on tabular data, which is particularly challenging due to the presence
of both numerical and categorical features. Our key idea is a novel technique
to convert categorical values into floating-point representations. This
approach preserves enough information to maintain clean-model accuracy compared
to traditional methods like one-hot or ordinal encoding. By doing this, we
create a gradient-based universal perturbation that applies to all features,
including categorical ones.
  We evaluate our method on five datasets and four popular models. Our results
show up to a 100% attack success rate in both white-box and black-box settings
(including real-world applications like Vertex AI), revealing a severe
vulnerability for tabular data. Our method is shown to surpass the previous
works like Tabdoor in terms of performance, while remaining stealthy against
state-of-the-art defense mechanisms. We evaluate our attack against Spectral
Signatures, Neural Cleanse, Beatrix, and Fine-Pruning, all of which fail to
defend successfully against it. We also verify that our attack successfully
bypasses popular outlier detection mechanisms.

</details>


### [290] [Approximating Shapley Explanations in Reinforcement Learning](https://arxiv.org/abs/2511.06094)
*Daniel Beechey,Özgür Şimşek*

Main category: cs.LG

TL;DR: FastSVERL是一种可扩展的方法，通过近似Shapley值来解释强化学习，解决了传统Shapley解释计算成本高的问题，能够处理强化学习中的时间依赖、离策略数据和实时行为适应等挑战。


<details>
  <summary>Details</summary>
Motivation: 强化学习在复杂决策环境中取得了显著成功，但其缺乏透明度限制了在实际应用中的部署，特别是在安全关键场景中。虽然合作博弈论中的Shapley值为解释强化学习提供了原则性框架，但其计算成本阻碍了实际使用。

Method: 提出了FastSVERL方法，通过近似Shapley值来提供可扩展的强化学习解释。该方法专门设计用于处理强化学习的独特挑战，包括多步轨迹中的时间依赖、从离策略数据中学习以及实时适应演化中的智能体行为。

Result: FastSVERL为强化学习中的原则性和严格可解释性提供了一种实用、可扩展的方法。

Conclusion: FastSVERL解决了Shapley值在强化学习解释中的计算瓶颈问题，为强化学习的透明部署提供了可行的解决方案。

Abstract: Reinforcement learning has achieved remarkable success in complex
decision-making environments, yet its lack of transparency limits its
deployment in practice, especially in safety-critical settings. Shapley values
from cooperative game theory provide a principled framework for explaining
reinforcement learning; however, the computational cost of Shapley explanations
is an obstacle to their use. We introduce FastSVERL, a scalable method for
explaining reinforcement learning by approximating Shapley values. FastSVERL is
designed to handle the unique challenges of reinforcement learning, including
temporal dependencies across multi-step trajectories, learning from off-policy
data, and adapting to evolving agent behaviours in real time. FastSVERL
introduces a practical, scalable approach for principled and rigorous
interpretability in reinforcement learning.

</details>


### [291] [Guardian-regularized Safe Offline Reinforcement Learning for Smart Weaning of Mechanical Circulatory Devices](https://arxiv.org/abs/2511.06111)
*Aysin Tumay,Sophia Sun,Sonia Fereidooni,Aaron Dumas,Elise Jortberg,Rose Yu*

Main category: cs.LG

TL;DR: 本文提出了一种用于心源性休克患者机械循环支持设备脱机的端到端机器学习框架，包含CORMPO离线强化学习算法和基于Transformer的数字孪生模型，在真实和合成数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前机械循环支持设备的脱机策略在不同医疗团队间差异很大，缺乏数据驱动方法，而离线强化学习在这种高风险医疗应用中面临禁止在线交互、循环动力学高度不确定和数据有限的挑战。

Method: 开发了临床感知的OOD正则化模型策略优化（CORMPO）算法，结合密度正则化抑制分布外数据，并集成临床知识进行奖励塑造；同时构建基于Transformer的概率数字孪生模型来模拟循环动力学。

Result: CORMPO在真实和合成数据集上比离线强化学习基线获得28%更高的奖励，在临床指标上获得82.6%更高的分数，并在温和假设下达到理论性能保证。

Conclusion: 该框架为高风险医疗应用中的安全离线策略学习提供了原则性方法，其中领域专业知识和安全约束至关重要。

Abstract: We study the sequential decision-making problem for automated weaning of
mechanical circulatory support (MCS) devices in cardiogenic shock patients. MCS
devices are percutaneous micro-axial flow pumps that provide left ventricular
unloading and forward blood flow, but current weaning strategies vary
significantly across care teams and lack data-driven approaches. Offline
reinforcement learning (RL) has proven to be successful in sequential
decision-making tasks, but our setting presents challenges for training and
evaluating traditional offline RL methods: prohibition of online patient
interaction, highly uncertain circulatory dynamics due to concurrent
treatments, and limited data availability. We developed an end-to-end machine
learning framework with two key contributions (1) Clinically-aware
OOD-regularized Model-based Policy Optimization (CORMPO), a density-regularized
offline RL algorithm for out-of-distribution suppression that also incorporates
clinically-informed reward shaping and (2) a Transformer-based probabilistic
digital twin that models MCS circulatory dynamics for policy evaluation with
rich physiological and clinical metrics. We prove that \textsf{CORMPO} achieves
theoretical performance guarantees under mild assumptions. CORMPO attains a
higher reward than the offline RL baselines by 28% and higher scores in
clinical metrics by 82.6% on real and synthetic datasets. Our approach offers a
principled framework for safe offline policy learning in high-stakes medical
applications where domain expertise and safety constraints are essential.

</details>


### [292] [On the Convergence and Stability of Distributed Sub-model Training](https://arxiv.org/abs/2511.06132)
*Yuyang Deng,Fuli Qiao,Mehrdad Mahdavi*

Main category: cs.LG

TL;DR: 本文提出了一种分布式洗牌子模型训练方法，通过预先将完整模型划分为多个子模型，服务器在每轮训练中洗牌并分发这些子模型给客户端，最后聚合更新，解决了联邦学习中大规模模型本地训练的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着模型规模不断增长，在联邦学习中实现设备端本地训练成为关键挑战。现有的随机子模型采样方法收敛性能不佳，受SGD洗牌成功启发，需要更有效的子模型训练策略。

Method: 提出分布式洗牌子模型训练：将完整模型预先划分为多个子模型，服务器每轮洗牌子模型并分发给客户端，客户端更新后返回子模型，服务器进行平均聚合。

Result: 建立了该算法的收敛速率，通过稳定性分析发现子模型训练能通过放大训练过程的稳定性来改善泛化性能，大量实验验证了理论发现。

Conclusion: 分布式洗牌子模型训练方法在联邦学习中有效解决了大规模模型本地训练问题，提高了收敛性能和泛化能力。

Abstract: As learning models continue to grow in size, enabling on-device local
training of these models has emerged as a critical challenge in federated
learning. A popular solution is sub-model training, where the server only
distributes randomly sampled sub-models to the edge clients, and clients only
update these small models. However, those random sampling of sub-models may not
give satisfying convergence performance. In this paper, observing the success
of SGD with shuffling, we propose a distributed shuffled sub-model training,
where the full model is partitioned into several sub-models in advance, and the
server shuffles those sub-models, sends each of them to clients at each round,
and by the end of local updating period, clients send back the updated
sub-models, and server averages them. We establish the convergence rate of this
algorithm. We also study the generalization of distributed sub-model training
via stability analysis, and find that the sub-model training can improve the
generalization via amplifying the stability of training process. The extensive
experiments also validate our theoretical findings.

</details>


### [293] [LLM Attention Transplant for Transfer Learning of Tabular Data Across Disparate Domains](https://arxiv.org/abs/2511.06161)
*Ibna Kowsar,Kazi F. Akhter,Manar D. Samad*

Main category: cs.LG

TL;DR: 提出了一种轻量级迁移学习框架LATTLE，通过将LLM的选择性键值投影权重移植到门控特征标记化变换器(gFTT)中，实现表格数据的跨域迁移学习，无需共享特征或大规模预训练模型。


<details>
  <summary>Details</summary>
Motivation: 表格数据的迁移学习面临特征空间异构性的挑战，传统深度学习方法效果有限，而LLM在处理混合数据类型表格时受限于文本提示和上下文学习。

Method: 首先在源表格数据上微调LLM，然后将其选择性键值投影权重移植到专门为表格数据设计的gFTT模型中，最后在目标表格数据上微调具有跨域注意力的gFTT模型。

Result: 在10对源-目标数据集和12个基线方法的实验中，LATTLE方法优于传统ML模型、最先进的深度表格架构以及基于数千到数十亿表格样本训练的迁移学习模型。

Conclusion: 提出的注意力移植方法为在低资源学习环境中使用LLM学习数据表间关系提供了有效解决方案。

Abstract: Transfer learning of tabular data is non-trivial due to heterogeneity in the
feature space across disparate domains. The limited success of traditional deep
learning in tabular knowledge transfer can be advanced by leveraging large
language models (LLMs). However, the efficacy of LLMs often stagnates for mixed
data types structured in tables due to the limitations of text prompts and
in-context learning. We propose a lightweight transfer learning framework that
fine-tunes an LLM using source tabular data and transplants the LLM's selective
$key$ and $value$ projection weights into a gated feature tokenized transformer
(gFTT) built for tabular data. The gFTT model with cross-domain attention is
fine-tuned using target tabular data for transfer learning, eliminating the
need for shared features, LLM prompt engineering, and large-scale pretrained
models. Our experiments using ten pairs of source-target data sets and 12
baselines demonstrate the superiority of the proposed LLM-attention transplant
for transfer learning (LATTLE) method over traditional ML models,
state-of-the-art deep tabular architectures, and transfer learning models
trained on thousands to billions of tabular samples. The proposed attention
transfer demonstrates an effective solution to learning relationships between
data tables using an LLM in a low-resource learning environment. The source
code for the proposed method is publicly available.

</details>


### [294] [Learning Gaussian DAG Models without Condition Number Bounds](https://arxiv.org/abs/2511.06164)
*Constantinos Daskalakis,Vardis Kandiros,Rui Yao*

Main category: cs.LG

TL;DR: 本文研究了在有向高斯图模型中学习拓扑结构的问题，提出了一种样本复杂度与条件数无关的算法，并建立了几乎匹配的上下界。


<details>
  <summary>Details</summary>
Motivation: 先前的研究忽略了样本复杂度对协方差矩阵条件数的依赖，这在条件数随维度增长时会导致算法在高维设置中不实用。

Method: 提出了一种恢复底层图结构的算法，在变量方差有界的假设下设计了多项式时间算法。

Result: 证明了所需样本数量与条件数无关，建立了几乎匹配的上下界，并通过合成数据集的模拟验证了理论结果。

Conclusion: 本文提供了该问题真实样本复杂度的几乎紧致刻画，解决了先前方法在高维设置中的局限性。

Abstract: We study the problem of learning the topology of a directed Gaussian
Graphical Model under the equal-variance assumption, where the graph has $n$
nodes and maximum in-degree $d$. Prior work has established that $O(d \log n)$
samples are sufficient for this task. However, an important factor that is
often overlooked in these analyses is the dependence on the condition number of
the covariance matrix of the model. Indeed, all algorithms from prior work
require a number of samples that grows polynomially with this condition number.
In many cases this is unsatisfactory, since the condition number could grow
polynomially with $n$, rendering these prior approaches impractical in
high-dimensional settings. In this work, we provide an algorithm that recovers
the underlying graph and prove that the number of samples required is
independent of the condition number. Furthermore, we establish lower bounds
that nearly match the upper bound up to a $d$-factor, thus providing an almost
tight characterization of the true sample complexity of the problem. Moreover,
under a further assumption that all the variances of the variables are bounded,
we design a polynomial-time algorithm that recovers the underlying graph, at
the cost of an additional polynomial dependence of the sample complexity on
$d$. We complement our theoretical findings with simulations on synthetic
datasets that confirm our predictions.

</details>


### [295] [Sparse Linear Regression is Easy on Random Supports](https://arxiv.org/abs/2511.06211)
*Gautam Chandrasekaran,Raghu Meka,Konstantinos Stavropoulos*

Main category: cs.LG

TL;DR: 该论文提出了稀疏线性回归问题的首个通用正结果：对于任意设计矩阵X，只要信号向量w*的支撑集是随机选择的，就能以poly(k, log d, 1/ε)样本量和poly(d,N)运行时间实现预测误差ε。


<details>
  <summary>Details</summary>
Motivation: 稀疏线性回归在信息理论上需要O(k log d/ε)样本量，但计算上目前需要d^Ω(k)运行时间，或者需要O(d)样本量才能获得多项式时间算法。这种指数级差距促使研究者寻找能在o(d)样本量和d^o(k)运行时间内工作的算法。

Method: 该方法适用于任意设计矩阵X（条件数最多为2^poly(d)），但要求信号向量w*的支撑集是随机选择的。通过这种随机性假设，算法能够以多项式样本量和运行时间实现小预测误差。

Result: 该算法实现了预测误差ε，所需样本量N = poly(k, log d, 1/ε)，运行时间为poly(d,N)。这是首个在任意设计矩阵下实现这种性能的通用结果。

Conclusion: 该工作证明了在信号支撑集随机选择的假设下，稀疏线性回归可以在多项式样本量和运行时间内解决，突破了以往算法需要随机设计矩阵或特殊结构矩阵的限制。

Abstract: Sparse linear regression is one of the most basic questions in machine
learning and statistics. Here, we are given as input a design matrix $X \in
\mathbb{R}^{N \times d}$ and measurements or labels ${y} \in \mathbb{R}^N$
where ${y} = {X} {w}^* + {\xi}$, and ${\xi}$ is the noise in the measurements.
Importantly, we have the additional constraint that the unknown signal vector
${w}^*$ is sparse: it has $k$ non-zero entries where $k$ is much smaller than
the ambient dimension. Our goal is to output a prediction vector
$\widehat{{w}}$ that has small prediction error: $\frac{1}{N}\cdot \|{X} {w}^*
- {X} \widehat{{w}}\|^2_2$.
  Information-theoretically, we know what is best possible in terms of
measurements: under most natural noise distributions, we can get prediction
error at most $\epsilon$ with roughly $N = O(k \log d/\epsilon)$ samples.
Computationally, this currently needs $d^{\Omega(k)}$ run-time. Alternately,
with $N = O(d)$, we can get polynomial-time. Thus, there is an exponential gap
(in the dependence on $d$) between the two and we do not know if it is possible
to get $d^{o(k)}$ run-time and $o(d)$ samples.
  We give the first generic positive result for worst-case design matrices
${X}$: For any ${X}$, we show that if the support of ${w}^*$ is chosen at
random, we can get prediction error $\epsilon$ with $N = \text{poly}(k, \log d,
1/\epsilon)$ samples and run-time $\text{poly}(d,N)$. This run-time holds for
any design matrix ${X}$ with condition number up to $2^{\text{poly}(d)}$.
  Previously, such results were known for worst-case ${w}^*$, but only for
random design matrices from well-behaved families, matrices that have a very
low condition number ($\text{poly}(\log d)$; e.g., as studied in compressed
sensing), or those with special structural properties.

</details>


### [296] [Adaptive Multi-view Graph Contrastive Learning via Fractional-order Neural Diffusion Networks](https://arxiv.org/abs/2511.06216)
*Yanan Zhao,Feng Ji,Jingyang Dai,Jiaze Ma,Keyue Jiang,Kai Zhao,Wee Peng Tay*

Main category: cs.LG

TL;DR: 本文提出了一种基于分数阶连续动力学的无增强多视图图对比学习框架，通过可学习的分数阶导数参数自动生成多尺度视图，无需手动数据增强即可获得多样化的互补表示。


<details>
  <summary>Details</summary>
Motivation: 现有图对比学习方法通常依赖固定的手工设计视图（通常是局部和全局视角），限制了捕捉多尺度结构模式的能力。

Method: 基于分数阶连续动力学框架，通过变化分数阶导数参数α∈(0,1]产生连续谱的视图：小α产生局部化特征，大α诱导更广泛的全局聚合。将α作为可学习参数，使模型能够自适应扩散尺度并自动发现信息丰富的视图。

Result: 在标准基准测试上的广泛实验表明，该方法产生更鲁棒和表达性更强的嵌入，并优于最先进的图对比学习基线方法。

Conclusion: 这种基于分数阶动力学的原理性方法无需手动增强即可生成多样化、互补的表示，为图对比学习提供了新的有效框架。

Abstract: Graph contrastive learning (GCL) learns node and graph representations by
contrasting multiple views of the same graph. Existing methods typically rely
on fixed, handcrafted views-usually a local and a global perspective, which
limits their ability to capture multi-scale structural patterns. We present an
augmentation-free, multi-view GCL framework grounded in fractional-order
continuous dynamics. By varying the fractional derivative order $\alpha \in
(0,1]$, our encoders produce a continuous spectrum of views: small $\alpha$
yields localized features, while large $\alpha$ induces broader, global
aggregation. We treat $\alpha$ as a learnable parameter so the model can adapt
diffusion scales to the data and automatically discover informative views. This
principled approach generates diverse, complementary representations without
manual augmentations. Extensive experiments on standard benchmarks demonstrate
that our method produces more robust and expressive embeddings and outperforms
state-of-the-art GCL baselines.

</details>


### [297] [Scaling Laws and In-Context Learning: A Unified Theoretical Framework](https://arxiv.org/abs/2511.06232)
*Sushant Mehta,Ishan Gupta*

Main category: cs.LG

TL;DR: 本文提出了一个统一的理论框架，将缩放定律与transformer中的上下文学习(ICL)涌现联系起来，揭示了ICL性能与模型深度、宽度、上下文长度和训练数据之间的幂律关系。


<details>
  <summary>Details</summary>
Motivation: 尽管有大量实证研究，但对大规模上下文学习涌现的原理性理解仍然较为模糊。本文旨在建立连接缩放定律与ICL涌现的统一理论框架。

Method: 通过理论分析建立ICL性能与模型参数之间的幂律关系，证明transformer在前向传播中实现了基于梯度的元学习，并推导出最优的深度-宽度分配策略。

Result: 分析表明ICL性能遵循幂律关系，有效学习率η_eff = Θ(1/√Ld)，在临界尺度出现急剧相变，最优分配为L* ∝ N^{2/3}, d* ∝ N^{1/3}。合成任务实验验证了理论预测。

Conclusion: 这项工作为ICL的涌现提供了必要和充分条件，并建立了transformer在上下文中学习能力的基本计算限制。

Abstract: In-context learning (ICL) enables large language models to adapt to new tasks
from demonstrations without parameter updates. Despite extensive empirical
studies, a principled understanding of ICL emergence at scale remains more
elusive. We present a unified theoretical framework connecting scaling laws to
ICL emergence in transformers. Our analysis establishes that ICL performance
follows power-law relationships with model depth $L$, width $d$, context length
$k$, and training data $D$, with exponents determined by task structure. We
show that under specific conditions, transformers implement gradient-based
metalearning in their forward pass, with an effective learning rate
$\eta_{\text{eff}} = \Theta(1/\sqrt{Ld})$. We demonstrate sharp phase
transitions at critical scales and derive optimal depth-width allocations
favoring $L^* \propto N^{2/3}$, $d^* \propto N^{1/3}$ for the fixed parameter
budget $N = Ld$. Systematic experiments on synthetic tasks validate our
predictions, with measured scaling exponents closely matching theory. This work
provides both necessary and sufficient conditions for the emergence of ICLs and
establishes fundamental computational limits on what transformers can learn
in-context.

</details>


### [298] [Mixtures of SubExperts for Large Language Continual Learning](https://arxiv.org/abs/2511.06237)
*Haeyong Kang*

Main category: cs.LG

TL;DR: 本文提出了一种名为MoSEs的自适应参数高效微调方法，用于解决大语言模型在持续学习中的灾难性遗忘和模型规模线性增长问题。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调方法在持续学习中面临两难困境：重用单一参数集会导致灾难性遗忘，而为每个任务分配独立参数则导致模型规模线性增长且无法实现任务间知识迁移。

Method: 提出MoSEs框架，在Transformer层中集成稀疏子专家混合，通过任务特定路由机制自适应选择和组合先前学习的稀疏参数，实现知识隔离和有效迁移。

Result: 在TRACE基准数据集上的实验表明，MoSEs在知识保留和新任务可扩展性方面显著优于传统持续学习方法，实现了最先进性能，同时大幅节省内存和计算资源。

Conclusion: MoSEs通过自适应参数选择和组合机制，有效解决了持续学习中的灾难性遗忘和模型规模增长问题，为大规模语言模型的持续学习提供了高效解决方案。

Abstract: Adapting Large Language Models (LLMs) to a continuous stream of tasks is a
critical yet challenging endeavor. While Parameter-Efficient Fine-Tuning (PEFT)
methods have become a standard for this, they face a fundamental dilemma in
continual learning. Reusing a single set of PEFT parameters for new tasks often
leads to catastrophic forgetting of prior knowledge. Conversely, allocating
distinct parameters for each task prevents forgetting but results in a linear
growth of the model's size and fails to facilitate knowledge transfer between
related tasks. To overcome these limitations, we propose a novel adaptive PEFT
method referred to as \textit{Mixtures of SubExperts (MoSEs)}, a novel
continual learning framework designed for minimal forgetting and efficient
scalability. MoSEs integrate a sparse Mixture of SubExperts into the
transformer layers, governed by a task-specific routing mechanism. This
architecture allows the model to isolate and protect knowledge within dedicated
SubExperts, thereby minimizing parameter interference and catastrophic
forgetting. Crucially, the router can adaptively select and combine previously
learned sparse parameters for new tasks, enabling effective knowledge transfer
while ensuring that the model's capacity grows sublinearly. We evaluate MoSEs
on the comprehensive TRACE benchmark datasets. Our experiments demonstrate that
MoSEs significantly outperform conventional continual learning approaches in
both knowledge retention and scalability to new tasks, achieving
state-of-the-art performance with substantial memory and computational savings.

</details>


### [299] [Test-Time Iterative Error Correction for Efficient Diffusion Models](https://arxiv.org/abs/2511.06250)
*Yunshan Zhong,Yanwei Qi,Yuxin Zhang*

Main category: cs.LG

TL;DR: 提出一种名为迭代误差校正（IEC）的测试时方法，通过迭代细化模型输出来减轻高效扩散模型中的近似误差，将误差传播从指数增长降低到线性增长。


<details>
  <summary>Details</summary>
Motivation: 随着资源受限设备对高质量图像生成需求的增长，高效扩散模型受到关注，但这些模型存在效率技术引入的近似误差，显著降低生成质量，且部署后难以修正。

Method: 通过分析扩散时间步中的误差传播，提出IEC方法，在推理过程中迭代校正误差，无需重新训练或架构更改。

Result: 实验表明IEC在各种数据集、效率技术和模型架构上一致提高生成质量，实现性能与效率的灵活权衡。

Conclusion: IEC是高效扩散模型测试时增强的实用且可泛化的解决方案。

Abstract: With the growing demand for high-quality image generation on
resource-constrained devices, efficient diffusion models have received
increasing attention. However, such models suffer from approximation errors
introduced by efficiency techniques, which significantly degrade generation
quality. Once deployed, these errors are difficult to correct, as modifying the
model is typically infeasible in deployment environments. Through an analysis
of error propagation across diffusion timesteps, we reveal that these
approximation errors can accumulate exponentially, severely impairing output
quality. Motivated by this insight, we propose Iterative Error Correction
(IEC), a novel test-time method that mitigates inference-time errors by
iteratively refining the model's output. IEC is theoretically proven to reduce
error propagation from exponential to linear growth, without requiring any
retraining or architectural changes. IEC can seamlessly integrate into the
inference process of existing diffusion models, enabling a flexible trade-off
between performance and efficiency. Extensive experiments show that IEC
consistently improves generation quality across various datasets, efficiency
techniques, and model architectures, establishing it as a practical and
generalizable solution for test-time enhancement of efficient diffusion models.

</details>


### [300] [MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios](https://arxiv.org/abs/2511.06252)
*Xuantang Xiong,Ni Mu,Runpeng Xie,Senhao Yang,Yaqing Wang,Lexiang Wang,Yao Luan,Siyuan Li,Shuang Xu,Yiqin Yang,Bo Xu*

Main category: cs.LG

TL;DR: 本文提出了一种名为Meta-Regularized Contextual World-Model (MrCoM)的方法，旨在构建能够跨不同场景泛化的统一世界模型，以提升模型强化学习的泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 当前基于模型的强化学习方法主要专注于为单一任务构建世界模型，很少解决跨不同场景的泛化问题。基于同一仿真引擎中的动态具有内在共性的洞察，作者试图构建能够跨场景泛化的统一世界模型。

Method: MrCoM方法首先根据动态特性将潜在状态空间分解为不同组件，提高世界模型预测精度；采用元状态正则化提取场景相关信息的统一表示；使用元值正则化在不同场景目标下对齐世界模型优化与策略学习。

Result: 作者从理论上分析了MrCoM在多场景设置下的泛化误差上界，并通过系统评估证明该方法在跨多样场景的泛化能力上显著优于先前的最先进方法。

Conclusion: MrCoM方法成功构建了能够跨场景泛化的统一世界模型，在提升模型强化学习的泛化能力和性能方面取得了显著进展。

Abstract: Model-based reinforcement learning (MBRL) is a crucial approach to enhance
the generalization capabilities and improve the sample efficiency of RL
algorithms. However, current MBRL methods focus primarily on building world
models for single tasks and rarely address generalization across different
scenarios. Building on the insight that dynamics within the same simulation
engine share inherent properties, we attempt to construct a unified world model
capable of generalizing across different scenarios, named Meta-Regularized
Contextual World-Model (MrCoM). This method first decomposes the latent state
space into various components based on the dynamic characteristics, thereby
enhancing the accuracy of world-model prediction. Further, MrCoM adopts
meta-state regularization to extract unified representation of
scenario-relevant information, and meta-value regularization to align
world-model optimization with policy learning across diverse scenario
objectives. We theoretically analyze the generalization error upper bound of
MrCoM in multi-scenario settings. We systematically evaluate our algorithm's
generalization ability across diverse scenarios, demonstrating significantly
better performance than previous state-of-the-art methods.

</details>


### [301] [Breaking the Modality Barrier: Generative Modeling for Accurate Molecule Retrieval from Mass Spectra](https://arxiv.org/abs/2511.06259)
*Yiwen Zhang,Keyan Ding,Yihang Wu,Xiang Zhuang,Yi Yang,Qiang Zhang,Huajun Chen*

Main category: cs.LG

TL;DR: GLMR是一个基于生成语言模型的检索框架，通过两阶段过程解决质谱-分子结构跨模态对齐问题，显著提升了分子结构检索的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的质谱检索方法存在谱库覆盖有限和跨模态对齐不佳的问题，导致检索精度和泛化能力不足。

Method: 采用两阶段检索：预检索阶段使用对比学习模型识别候选分子作为先验，生成检索阶段整合候选分子和质谱输入，通过生成模型产生精炼分子结构进行重排序。

Result: 在MassSpecGym和MassRET-20k数据集上，GLMR显著优于现有方法，top-1准确率提升超过40%，并展现出强泛化能力。

Conclusion: GLMR框架通过缓解跨模态对齐问题，为质谱分子结构检索提供了更准确和泛化性强的解决方案。

Abstract: Retrieving molecular structures from tandem mass spectra is a crucial step in
rapid compound identification. Existing retrieval methods, such as traditional
mass spectral library matching, suffer from limited spectral library coverage,
while recent cross-modal representation learning frameworks often encounter
modality misalignment, resulting in suboptimal retrieval accuracy and
generalization. To address these limitations, we propose GLMR, a Generative
Language Model-based Retrieval framework that mitigates the cross-modal
misalignment through a two-stage process. In the pre-retrieval stage, a
contrastive learning-based model identifies top candidate molecules as
contextual priors for the input mass spectrum. In the generative retrieval
stage, these candidate molecules are integrated with the input mass spectrum to
guide a generative model in producing refined molecular structures, which are
then used to re-rank the candidates based on molecular similarity. Experiments
on both MassSpecGym and the proposed MassRET-20k dataset demonstrate that GLMR
significantly outperforms existing methods, achieving over 40% improvement in
top-1 accuracy and exhibiting strong generalizability.

</details>


### [302] [COTN: A Chaotic Oscillatory Transformer Network for Complex Volatile Systems under Extreme Conditions](https://arxiv.org/abs/2511.06273)
*Boyan Tang,Yilong Zeng,Xuanhao Ren,Peng Xiao,Yuhan Zhao,Raymond Lee,Jianghua Wu*

Main category: cs.LG

TL;DR: 提出COTN模型，结合Transformer架构和Lee振荡器激活函数，通过Max-over-Time池化和lambda门控机制捕捉混沌动态，并集成自编码器自回归模块隔离异常模式，在电力和金融市场预测中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 金融市场和电力市场具有内在非线性、快速波动和混沌模式，特别是在极端条件下，传统激活函数容易饱和，难以准确预测。

Method: COTN模型将Transformer架构与新型Lee振荡器激活函数结合，采用Max-over-Time池化和lambda门控机制，并集成自编码器自回归模块检测和隔离异常市场模式。

Result: 在电力和金融市场实验中，COTN比最先进的深度学习模型Informer提升17%，比传统统计方法GARCH提升40%。

Conclusion: COTN能有效应对现实市场的不确定性和复杂性，为高波动系统在压力条件下的预测提供了强大工具。

Abstract: Accurate prediction of financial and electricity markets, especially under
extreme conditions, remains a significant challenge due to their intrinsic
nonlinearity, rapid fluctuations, and chaotic patterns. To address these
limitations, we propose the Chaotic Oscillatory Transformer Network (COTN).
COTN innovatively combines a Transformer architecture with a novel Lee
Oscillator activation function, processed through Max-over-Time pooling and a
lambda-gating mechanism. This design is specifically tailored to effectively
capture chaotic dynamics and improve responsiveness during periods of
heightened volatility, where conventional activation functions (e.g., ReLU,
GELU) tend to saturate. Furthermore, COTN incorporates an Autoencoder
Self-Regressive (ASR) module to detect and isolate abnormal market patterns,
such as sudden price spikes or crashes, thereby preventing corruption of the
core prediction process and enhancing robustness. Extensive experiments across
electricity spot markets and financial markets demonstrate the practical
applicability and resilience of COTN. Our approach outperforms state-of-the-art
deep learning models like Informer by up to 17% and traditional statistical
methods like GARCH by as much as 40%. These results underscore COTN's
effectiveness in navigating real-world market uncertainty and complexity,
offering a powerful tool for forecasting highly volatile systems under duress.

</details>


### [303] [Achieving Fairness Without Harm via Selective Demographic Experts](https://arxiv.org/abs/2511.06293)
*Xuwei Tan,Yuanlong Wang,Thai-Hoang Pham,Ping Zhang,Xueru Zhang*

Main category: cs.LG

TL;DR: 提出了一种公平无伤害方法，通过为不同人口群体学习不同表示，并通过无伤害约束选择应用人口专家，在医疗和面部数据集上实现公平性而不损害性能。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险领域，现有偏见缓解技术往往在公平性和准确性之间进行权衡，这在伦理和实践上不可接受。需要一种既能确保公平性又不会降低性能的方法。

Method: 为不同人口群体学习不同表示，通过无伤害约束选择应用人口专家（包括群体特定表示和个性化分类器）。

Result: 在三个真实世界医疗数据集（眼病、皮肤癌、X射线诊断）和两个面部数据集上的广泛实证结果表明该方法在实现公平无伤害方面的有效性。

Conclusion: 该方法成功实现了公平性而不损害性能，特别适用于医疗等高风险领域。

Abstract: As machine learning systems become increasingly integrated into
human-centered domains such as healthcare, ensuring fairness while maintaining
high predictive performance is critical. Existing bias mitigation techniques
often impose a trade-off between fairness and accuracy, inadvertently degrading
performance for certain demographic groups. In high-stakes domains like
clinical diagnosis, such trade-offs are ethically and practically unacceptable.
In this study, we propose a fairness-without-harm approach by learning distinct
representations for different demographic groups and selectively applying
demographic experts consisting of group-specific representations and
personalized classifiers through a no-harm constrained selection. We evaluate
our approach on three real-world medical datasets -- covering eye disease, skin
cancer, and X-ray diagnosis -- as well as two face datasets. Extensive
empirical results demonstrate the effectiveness of our approach in achieving
fairness without harm.

</details>


### [304] [Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention](https://arxiv.org/abs/2511.06294)
*Wenjie Hu,Sidun Liu,Peng Qiao,Zhenglun Sun,Yong Dou*

Main category: cs.LG

TL;DR: 本文提出Linear Attention Neural Operator (LinearNO)，通过将Transolver中的Physics-Attention重新设计为标准线性注意力，在六个标准PDE基准测试中达到最先进性能，同时减少40.0%参数和36.2%计算成本。


<details>
  <summary>Details</summary>
Motivation: 发现Transolver中的Physics-Attention可重新表述为线性注意力的特例，且切片注意力可能损害模型性能，其有效性主要来自切片和反切片操作而非切片间交互。

Method: 提出两步变换将Physics-Attention重新设计为标准线性注意力，称为Linear Attention Neural Operator (LinearNO)。

Result: 在六个标准PDE基准测试中达到最先进性能，参数减少40.0%，计算成本降低36.2%，在AirfRANS和Shape-Net Car两个工业级数据集上表现优异。

Conclusion: LinearNO通过重新设计注意力机制，在保持高性能的同时显著降低了计算复杂度和参数量，为PDE求解提供了更高效的解决方案。

Abstract: Recent advances in Transformer-based Neural Operators have enabled
significant progress in data-driven solvers for Partial Differential Equations
(PDEs). Most current research has focused on reducing the quadratic complexity
of attention to address the resulting low training and inference efficiency.
Among these works, Transolver stands out as a representative method that
introduces Physics-Attention to reduce computational costs. Physics-Attention
projects grid points into slices for slice attention, then maps them back
through deslicing. However, we observe that Physics-Attention can be
reformulated as a special case of linear attention, and that the slice
attention may even hurt the model performance. Based on these observations, we
argue that its effectiveness primarily arises from the slice and deslice
operations rather than interactions between slices. Building on this insight,
we propose a two-step transformation to redesign Physics-Attention into a
canonical linear attention, which we call Linear Attention Neural Operator
(LinearNO). Our method achieves state-of-the-art performance on six standard
PDE benchmarks, while reducing the number of parameters by an average of 40.0%
and computational cost by 36.2%. Additionally, it delivers superior performance
on two challenging, industrial-level datasets: AirfRANS and Shape-Net Car.

</details>


### [305] [3dSAGER: Geospatial Entity Resolution over 3D Objects (Technical Report)](https://arxiv.org/abs/2511.06300)
*Bar Genossar,Sagi Dalyot,Roee Shraga,Avigdor Gal*

Main category: cs.LG

TL;DR: 提出3dSAGER方法，基于3D空间对象内在几何特征进行地理空间实体解析，解决跨数据源坐标系不兼容问题


<details>
  <summary>Details</summary>
Motivation: 现有地理空间实体解析方法依赖空间邻近性、文本元数据或外部标识，但在跨数据源场景下这些信号往往不可用、不可靠或不对齐

Method: 开发端到端管道3dSAGER，包含空间参考无关的特征化机制捕获匹配对的几何特征，并提出轻量级BKAFI阻塞方法高效生成候选集

Result: 在真实城市数据集上的实验表明，3dSAGER在准确性和效率上均显著优于强基线方法

Conclusion: 3dSAGER通过关注3D空间对象的内在几何特征，实现了跨数据集坐标系不兼容情况下的鲁棒地理空间实体解析

Abstract: Urban environments are continuously mapped and modeled by various data
collection platforms, including satellites, unmanned aerial vehicles and street
cameras. The growing availability of 3D geospatial data from multiple
modalities has introduced new opportunities and challenges for integrating
spatial knowledge at scale, particularly in high-impact domains such as urban
planning and rapid disaster management. Geospatial entity resolution is the
task of identifying matching spatial objects across different datasets, often
collected independently under varying conditions. Existing approaches typically
rely on spatial proximity, textual metadata, or external identifiers to
determine correspondence. While useful, these signals are often unavailable,
unreliable, or misaligned, especially in cross-source scenarios. To address
these limitations, we shift the focus to the intrinsic geometry of 3D spatial
objects and present 3dSAGER (3D Spatial-Aware Geospatial Entity Resolution), an
end-to-end pipeline for geospatial entity resolution over 3D objects. 3dSAGER
introduces a novel, spatial-reference-independent featurization mechanism that
captures intricate geometric characteristics of matching pairs, enabling robust
comparison even across datasets with incompatible coordinate systems where
traditional spatial methods fail. As a key component of 3dSAGER, we also
propose a new lightweight and interpretable blocking method, BKAFI, that
leverages a trained model to efficiently generate high-recall candidate sets.
We validate 3dSAGER through extensive experiments on real-world urban datasets,
demonstrating significant gains in both accuracy and efficiency over strong
baselines. Our empirical study further dissects the contributions of each
component, providing insights into their impact and the overall design choices.

</details>


### [306] [Kaggle Chronicles: 15 Years of Competitions, Community and Data Science Innovation](https://arxiv.org/abs/2511.06304)
*Kevin Bönisch,Leandro Losaria*

Main category: cs.LG

TL;DR: 对Kaggle平台15年发展历程的回顾性研究，通过分析元数据、共享代码、社区讨论和竞赛数据，探索数据科学社区的发展趋势和技术演变。


<details>
  <summary>Details</summary>
Motivation: Kaggle作为全球数据科学家的重要平台，经过15年发展已从单纯的竞赛网站成长为包含论坛、笔记本、模型、数据集等的完整生态系统。研究旨在探索该平台的发展历程、对数据科学社区的影响以及隐藏的技术趋势。

Method: 通过分析数百万个内核和讨论线程，进行纵向趋势分析和标准探索性数据分析，结合Kaggle元代码和元数据集进行综合研究。

Result: 研究发现Kaggle是一个稳步增长的平台，用例日益多样化，Kaggle用户能够快速适应新趋势并将其应用于现实挑战，同时平均产生具有良好泛化能力的模型。

Conclusion: 研究提供了Kaggle平台的整体快照，突出了其历史和技术演变，展示了该平台在推动数据科学发展方面的重要作用。

Abstract: Since 2010, Kaggle has been a platform where data scientists from around the
world come together to compete, collaborate, and push the boundaries of Data
Science. Over these 15 years, it has grown from a purely competition-focused
site into a broader ecosystem with forums, notebooks, models, datasets, and
more. With the release of the Kaggle Meta Code and Kaggle Meta Datasets, we now
have a unique opportunity to explore these competitions, technologies, and
real-world applications of Machine Learning and AI. And so in this study, we
take a closer look at 15 years of data science on Kaggle - through metadata,
shared code, community discussions, and the competitions themselves. We explore
Kaggle's growth, its impact on the data science community, uncover hidden
technological trends, analyze competition winners, how Kagglers approach
problems in general, and more. We do this by analyzing millions of kernels and
discussion threads to perform both longitudinal trend analysis and standard
exploratory data analysis. Our findings show that Kaggle is a steadily growing
platform with increasingly diverse use cases, and that Kagglers are quick to
adapt to new trends and apply them to real-world challenges, while producing -
on average - models with solid generalization capabilities. We also offer a
snapshot of the platform as a whole, highlighting its history and technological
evolution. Finally, this study is accompanied by a video
(https://www.youtube.com/watch?v=YVOV9bIUNrM) and a Kaggle write-up
(https://kaggle.com/competitions/meta-kaggle-hackathon/writeups/kaggle-chronicles-15-years-of-competitions-communi)
for your convenience.

</details>


### [307] [DRIVE: Data Curation Best Practices for Reinforcement Learning with Verifiable Reward in Competitive Code Generation](https://arxiv.org/abs/2511.06307)
*Speed Zhu,Jianwei Cai,Guang Chen,Lulu Wu,Saiyong Yang,Wiggin Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种针对竞争性编程代码生成的RLVR方法，通过两阶段强化学习流程（GRPO和Pre-GRPO）结合精心设计的数据集构建和课程学习策略，在Qwen2.5-32B模型上实现了与领先系统相媲美的性能。


<details>
  <summary>Details</summary>
Motivation: 当前推理优先模型在数学领域取得进展，但竞争性编程代码生成领域研究不足，数据构建受到的关注少于RL算法设计。本文旨在探索如何构建有效的RLVR数据集并开发实用的训练技术。

Method: 采用两阶段强化学习流程：1）使用GRPO在大量均匀分布的竞争性编程问题上训练，每提示8次rollout；2）Pre-GRPO阶段在小规模高质量挑战问题上训练，每提示64次rollout，采用硬聚焦课程持续保留最难实例。

Result: 在Qwen2.5-32B模型上评估LeetCode和Codeforces周赛，实现了同类规模模型中的最优性能，与DeepSeek v3.1和Doubao-1.5-Thinking等领先系统相当。

Conclusion: 研究提炼了竞争性编程代码生成中数据构建、熵扩展和课程设计的简洁最佳实践，并在内部大规模MoE模型上观察到强大的RL扩展趋势。

Abstract: Recent reasoning-first models (e.g., OpenAI o1, DeepSeek R1) have spurred a
resurgence of interest in RLVR. Nevertheless, advances are dominated by
mathematics (e.g., AIME), with competitive-programming code generation
underexplored and data curation receiving less attention than RL algorithm
design. We investigate how to construct RLVR datasets (i.e., RL prompts) and
present practical training techniques that yield strong performance on
competitive-programming code generation. Our pipeline begins with supervised
fine-tuning (SFT) distilled from strong open-source models, augmented with
general-purpose and reasoning-intensive data. RL then follows a two-stage
process with executable, testcase-driven rewards: first, training on a large,
uniformly distributed set of competitive-programming problems using Group
Relative Policy Optimization (GRPO) with 8 rollouts per prompt and a relatively
short response-generation window (e.g., 32k during SFT and 24k in this stage)
to expand entropy and mitigate repetition and truncation; second, we perform
\textbf{Pre-GRPO}: updating on a small, high-quality set of challenging
problems with a large rollout budget (64 rollouts per prompt) under a
hard-focus curriculum that continuously retains the most difficult instances
throughout training. We implement our method on Qwen2.5-32B and evaluate on
LeetCode and Codeforces weekly contests to avoid data leakage. The resulting
model achieves state-of-the-art performance among models of similar scale and
is comparable to leading systems such as DeepSeek v3.1 and Doubao-1.5-Thinking.
We also examine scaling trends and observe strong RL scaling on an internal
large-scale MoE model. Our study distills concise best practices for data
curation, entropy expansion, and curriculum design in RLVR for
competitive-programming code generation.

</details>


### [308] [Reaction Prediction via Interaction Modeling of Symmetric Difference Shingle Sets](https://arxiv.org/abs/2511.06356)
*Runhan Shi,Letian Chen,Gufeng Yu,Yang Yang*

Main category: cs.LG

TL;DR: ReaDISH是一个新颖的化学反应预测模型，通过对称差异shingle编码和几何结构交互注意力机制，解决了现有模型对输入排列敏感和子结构交互建模不足的问题，显著提升了预测性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型在有机化学反应预测中存在两个关键局限：对输入排列（分子/原子顺序）的敏感性，以及对控制反应性的子结构交互建模不足，导致预测不一致和泛化能力差。

Method: 提出ReaDISH模型，包含两个创新：1）对称差异shingle编码，计算分子shingle差异以捕获反应特异性结构变化并消除顺序敏感性；2）几何结构交互注意力机制，在shingle级别建模分子内和分子间交互。

Result: 大量实验表明，ReaDISH在多种基准测试中提升了反应预测性能，在排列扰动下R²平均提升8.76%，显示出增强的鲁棒性。

Conclusion: ReaDISH通过结合排列不变表示和交互感知特征，有效解决了化学反应预测中的关键挑战，为实际应用提供了更可靠的工具。

Abstract: Chemical reaction prediction remains a fundamental challenge in organic
chemistry, where existing machine learning models face two critical
limitations: sensitivity to input permutations (molecule/atom orderings) and
inadequate modeling of substructural interactions governing reactivity. These
shortcomings lead to inconsistent predictions and poor generalization to
real-world scenarios. To address these challenges, we propose ReaDISH, a novel
reaction prediction model that learns permutation-invariant representations
while incorporating interaction-aware features. It introduces two innovations:
(1) symmetric difference shingle encoding, which computes molecular shingle
differences to capture reaction-specific structural changes while eliminating
order sensitivity; and (2) geometry-structure interaction attention, a
mechanism that models intra- and inter-molecular interactions at the shingle
level. Extensive experiments demonstrate that ReaDISH improves reaction
prediction performance across diverse benchmarks. It shows enhanced robustness
with an average improvement of 8.76% on R$^2$ under permutation perturbations.

</details>


### [309] [Adaptive Regularization for Large-Scale Sparse Feature Embedding Models](https://arxiv.org/abs/2511.06374)
*Mang Li,Wei Lyu*

Main category: cs.LG

TL;DR: 本文针对CTR和CVR预估模型在多轮训练中出现的过拟合问题进行了理论分析，并提出了一种自适应正则化方法来解决该问题。


<details>
  <summary>Details</summary>
Motivation: 在搜索、广告和推荐领域的CTR和CVR预估模型中，基于大规模稀疏分类特征的模型在多轮训练时经常出现性能显著下降的过拟合问题，现有研究未能明确其根本原因。

Method: 首先对使用大规模稀疏分类特征的模型过拟合现象进行理论分析，然后基于分析结果提出了一种自适应正则化方法。

Result: 该方法不仅防止了多轮训练中观察到的严重性能下降，还提高了单轮训练内的模型性能，并已在在线生产系统中部署。

Conclusion: 通过理论分析识别了过拟合的根本原因，并提出的自适应正则化方法有效解决了多轮训练中的过拟合问题，同时提升了模型性能。

Abstract: The one-epoch overfitting problem has drawn widespread attention, especially
in CTR and CVR estimation models in search, advertising, and recommendation
domains. These models which rely heavily on large-scale sparse categorical
features, often suffer a significant decline in performance when trained for
multiple epochs. Although recent studies have proposed heuristic solutions,
they have not clearly identified the fundamental cause of this phenomenon. In
this work, we provide a theoretical analysis that explains why overfitting
occurs in models that use large-scale sparse categorical features. Based on
this analysis, we propose an adaptive regularization method to address it. Our
approach not only prevents the severe performance degradation observed during
multi-epoch training, but also improves model performance within a single
epoch. This method has already been deployed in online production systems.

</details>


### [310] [Vocabulary In-Context Learning in Transformers: Benefits of Positional Encoding](https://arxiv.org/abs/2511.06376)
*Qian Ma,Ruoxiang Xu,Yongqiang Cai*

Main category: cs.LG

TL;DR: 本文研究了词汇表上下文学习(VICL)在Transformer中的通用逼近性质，发现无位置编码的单层Transformer不具备UAP，但加入位置编码后可实现UAP，并提供了位置编码的充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer架构在词汇表上下文学习场景下的通用逼近能力，特别是位置编码对逼近性质的影响。

Method: 分析单层Transformer在有无位置编码情况下的数学逼近能力，通过理论推导证明相关性质。

Result: 无位置编码的单层Transformer在VICL场景下不具备通用逼近性质，但加入位置编码后可以具备UAP，并给出了实现UAP的位置编码充分条件。

Conclusion: 位置编码在上下文学习的逼近理论视角下具有重要价值，能够增强Transformer的通用逼近能力。

Abstract: Numerous studies have demonstrated that the Transformer architecture
possesses the capability for in-context learning (ICL). In scenarios involving
function approximation, context can serve as a control parameter for the model,
endowing it with the universal approximation property (UAP). In practice,
context is represented by tokens from a finite set, referred to as a
vocabulary, which is the case considered in this paper, \emph{i.e.}, vocabulary
in-context learning (VICL). We demonstrate that VICL in single-layer
Transformers, without positional encoding, does not possess the UAP; however,
it is possible to achieve the UAP when positional encoding is included. Several
sufficient conditions for the positional encoding are provided. Our findings
reveal the benefits of positional encoding from an approximation theory
perspective in the context of ICL.

</details>


### [311] [CG-TTRL: Context-Guided Test-Time Reinforcement Learning for On-Device Large Language Models](https://arxiv.org/abs/2511.06430)
*Peyman Hosseini,Ondrej Bohdal,Taha Ceritli,Ignacio Castro,Matthew Purver,Mete Ozay,Umberto Michieli*

Main category: cs.LG

TL;DR: CG-TTRL通过动态整合上下文指导来改进测试时强化学习，在数学和科学QA基准测试中表现优于TTRL，准确率相对提升7%，且仅需少量训练步骤就能获得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时强化学习(TTRL)在两阶段采样策略中未充分利用上下文指导，而上下文学习已被证明能在不更新权重的情况下提升模型性能。

Method: 提出上下文指导的TTRL(CG-TTRL)，将上下文动态整合到两个采样阶段，并为设备端应用提出高效的上下文选择方法。

Result: 在数学和科学QA基准测试中，CG-TTRL比TTRL表现更好（相对准确率提升7%），且在仅3步训练后就获得8%的相对改进，而TTRL只有1%。

Conclusion: CG-TTRL通过有效整合上下文指导，显著提升了测试时强化学习的性能和效率。

Abstract: Test-time Reinforcement Learning (TTRL) has shown promise in adapting
foundation models for complex tasks at test-time, resulting in large
performance improvements. TTRL leverages an elegant two-phase sampling
strategy: first, multi-sampling derives a pseudo-label via majority voting,
while subsequent downsampling and reward-based fine-tuning encourages the model
to explore and learn diverse valid solutions, with the pseudo-label modulating
the reward signal. Meanwhile, in-context learning has been widely explored at
inference time and demonstrated the ability to enhance model performance
without weight updates. However, TTRL's two-phase sampling strategy
under-utilizes contextual guidance, which can potentially improve pseudo-label
accuracy in the initial exploitation phase while regulating exploration in the
second. To address this, we propose context-guided TTRL (CG-TTRL), integrating
context dynamically into both sampling phases and propose a method for
efficient context selection for on-device applications. Our evaluations on
mathematical and scientific QA benchmarks show CG-TTRL outperforms TTRL (e.g.
additional 7% relative accuracy improvement over TTRL), while boosting
efficiency by obtaining strong performance after only a few steps of test-time
training (e.g. 8% relative improvement rather than 1% over TTRL after 3 steps).

</details>


### [312] [FLEX: Continuous Agent Evolution via Forward Learning from Experience](https://arxiv.org/abs/2511.06449)
*Zhicheng Cai,Xinyuan Guo,Yu Pei,JiangTao Feng,Jiangjie Chen,Ya-Qin Zhang,Wei-Ying Ma,Mingxuan Wang,Hao Zhou*

Main category: cs.LG

TL;DR: FLEX是一种无需梯度的学习范式，使LLM驱动的自主智能体能够通过积累的经验持续进化，在数学推理、化学逆合成和蛋白质适应性预测等任务上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自主智能体在训练后保持静态，无法像智能生物那样在部署过程中通过经验成长，这限制了其持续进化的能力。

Method: FLEX通过持续反思与环境交互中的成功和失败，构建结构化经验库，实现可扩展和可继承的进化。

Result: 在AIME25上提升23%，USPTO50k上提升10%，ProteinGym上提升14%，并发现了经验增长的缩放规律和跨智能体经验继承现象。

Conclusion: FLEX标志着向可扩展和可继承的持续智能体进化迈出了重要一步，为LLM智能体的持续学习提供了新范式。

Abstract: Autonomous agents driven by Large Language Models (LLMs) have revolutionized
reasoning and problem-solving but remain static after training, unable to grow
with experience as intelligent beings do during deployment. We introduce
Forward Learning with EXperience (FLEX), a gradient-free learning paradigm that
enables LLM agents to continuously evolve through accumulated experience.
Specifically, FLEX cultivates scalable and inheritable evolution by
constructing a structured experience library through continual reflection on
successes and failures during interaction with the environment. FLEX delivers
substantial improvements on mathematical reasoning, chemical retrosynthesis,
and protein fitness prediction (up to 23% on AIME25, 10% on USPTO50k, and 14%
on ProteinGym). We further identify a clear scaling law of experiential growth
and the phenomenon of experience inheritance across agents, marking a step
toward scalable and inheritable continuous agent evolution. Project Page:
https://flex-gensi-thuair.github.io.

</details>


### [313] [A Risk-Neutral Neural Operator for Arbitrage-Free SPX-VIX Term Structures](https://arxiv.org/abs/2511.06451)
*Jian'an Zhang*

Main category: cs.LG

TL;DR: ARBITER是一个风险中性的神经算子，用于在无套利约束下学习SPX-VIX联合期限结构，通过约束解码器和外梯度更新确保静态套利约束、Lipschitz边界和单调性。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够同时学习SPX和VIX期限结构的模型，同时严格保证无套利条件，以解决传统方法在衍生品定价中的局限性。

Method: 结合算子学习与约束解码器，使用外梯度风格更新加投影进行训练，通过绑定SPX和VIX分支、Lipschitz投影和选择性状态更新来优化模型性能。

Result: 在历史SPX和VIX数据上优于傅里叶神经算子、DeepONet和状态空间序列模型，通过消融研究验证了各组件对模型性能的贡献。

Conclusion: ARBITER提供了一个实用的无套利插值和外推方法，在期限和行权价维度上实现了稳定且可识别的衍生品期限结构建模。

Abstract: We propose ARBITER, a risk-neutral neural operator for learning joint SPX-VIX
term structures under no-arbitrage constraints. ARBITER maps market states to
an operator that outputs implied volatility and variance curves while enforcing
static arbitrage (calendar, vertical, butterfly), Lipschitz bounds, and
monotonicity. The model couples operator learning with constrained decoders and
is trained with extragradient-style updates plus projection. We introduce
evaluation metrics for derivatives term structures (NAS, CNAS, NI, Dual-Gap,
Stability Rate) and show gains over Fourier Neural Operator, DeepONet, and
state-space sequence models on historical SPX and VIX data. Ablation studies
indicate that tying the SPX and VIX legs reduces Dual-Gap and improves NI,
Lipschitz projection stabilizes calibration, and selective state updates
improve long-horizon generalization. We provide identifiability and
approximation results and describe practical recipes for arbitrage-free
interpolation and extrapolation across maturities and strikes.

</details>


### [314] [MULTIBENCH++: A Unified and Comprehensive Multimodal Fusion Benchmarking Across Specialized Domains](https://arxiv.org/abs/2511.06452)
*Leyan Xue,Zongbo Han,Kecheng Xue,Xiaohong Liu,Guangyu Wang,Changqing Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一个大规模、领域自适应的多模态评估基准，整合了30多个数据集、15种模态和20个预测任务，并开发了开源统一的自动化评估流水线，为多模态模型提供严格可复现的评估平台。


<details>
  <summary>Details</summary>
Motivation: 当前多模态融合方法缺乏足够的评估基准，仅在少量数据集上评估，无法充分代表现实世界的复杂性和多样性，导致评估偏差，阻碍了通用高性能融合模型的发展。

Method: 开发大规模领域自适应多模态评估基准，整合30+数据集、15种模态、20个预测任务；建立开源统一的自动化评估流水线，包含最先进模型和多样化融合范式的标准化实现。

Result: 通过该平台进行大规模实验，成功在多个任务上建立了新的性能基准。

Conclusion: 该工作为学术界提供了关键的多模态模型严格可复现评估平台，旨在推动多模态人工智能领域达到新高度。

Abstract: Although multimodal fusion has made significant progress, its advancement is
severely hindered by the lack of adequate evaluation benchmarks. Current fusion
methods are typically evaluated on a small selection of public datasets, a
limited scope that inadequately represents the complexity and diversity of
real-world scenarios, potentially leading to biased evaluations. This issue
presents a twofold challenge. On one hand, models may overfit to the biases of
specific datasets, hindering their generalization to broader practical
applications. On the other hand, the absence of a unified evaluation standard
makes fair and objective comparisons between different fusion methods
difficult. Consequently, a truly universal and high-performance fusion model
has yet to emerge. To address these challenges, we have developed a
large-scale, domain-adaptive benchmark for multimodal evaluation. This
benchmark integrates over 30 datasets, encompassing 15 modalities and 20
predictive tasks across key application domains. To complement this, we have
also developed an open-source, unified, and automated evaluation pipeline that
includes standardized implementations of state-of-the-art models and diverse
fusion paradigms. Leveraging this platform, we have conducted large-scale
experiments, successfully establishing new performance baselines across
multiple tasks. This work provides the academic community with a crucial
platform for rigorous and reproducible assessment of multimodal models, aiming
to propel the field of multimodal artificial intelligence to new heights.

</details>


### [315] [Error Estimate and Convergence Analysis for Data Valuation](https://arxiv.org/abs/2511.06463)
*Zhangyong Liang,Huanhuan Gao,Ji Zhang*

Main category: cs.LG

TL;DR: 本文基于神经动态数据估值（NDDV）方法，首次探索了数据估值中的误差估计和收敛性分析。在Lipschitz和平滑性假设下，推导了损失差异的二次误差界，并证明了训练损失的期望平方梯度范数渐近消失，元损失在迭代中次线性收敛。


<details>
  <summary>Details</summary>
Motivation: 现有数据估值方法无法在单次训练过程中确保有效性，NDDV方法解决了这一局限性。本文旨在为数据估值提供理论保证，包括误差估计和收敛性分析。

Method: 基于NDDV方法，在Lipschitz和平滑性假设下，推导损失差异的二次误差界，分析控制变量变化对误差的影响，并进行收敛性分析。

Result: 获得了与时间步长成反比、与控制变量变化成二次关系的误差界，证明了训练损失的期望平方梯度范数渐近消失，元损失实现次线性收敛。

Conclusion: NDDV方法在理论保证下实现了有效的数据估值，提供了误差界和收敛性分析，为数据估值方法的可靠性提供了数学基础。

Abstract: Data valuation quantifies data importance, but existing methods cannot ensure
validity in a single training process. The neural dynamic data valuation (NDDV)
method [3] addresses this limitation. Based on NDDV, we are the first to
explore error estimation and convergence analysis in data valuation. Under
Lipschitz and smoothness assumptions, we derive quadratic error bounds for loss
differences that scale inversely with time steps and quadratically with control
variations, ensuring stability. We also prove that the expected squared
gradient norm for the training loss vanishes asymptotically, and that the meta
loss converges sublinearly over iterations. In particular, NDDV achieves
sublinear convergence.

</details>


### [316] [Explainable AI For Early Detection Of Sepsis](https://arxiv.org/abs/2511.06492)
*Atharva Thakur,Shruti Dhumal*

Main category: cs.LG

TL;DR: 本研究提出了一种可解释的AI方法用于脓毒症分析，将机器学习与临床知识相结合，不仅提供准确的脓毒症发作预测，还使临床医生能够理解、验证模型输出并与医学专业知识保持一致。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是一种危及生命的疾病，需要快速检测和治疗。虽然机器学习模型在预测脓毒症发作方面显示出潜力，但其黑盒性质限制了可解释性和临床信任。

Method: 开发了一种可解释的AI方法，将机器学习与临床知识集成，旨在提供准确预测的同时确保模型输出可被临床医生理解和验证。

Result: 该方法能够准确预测脓毒症发作，并且使临床医生能够理解模型决策过程，与医学专业知识保持一致。

Conclusion: 可解释的AI方法在脓毒症分析中具有重要价值，既能提供准确预测，又能增强临床信任和模型透明度。

Abstract: Sepsis is a life-threatening condition that requires rapid detection and
treatment to prevent progression to severe sepsis, septic shock, or multi-organ
failure. Despite advances in medical technology, it remains a major challenge
for clinicians. While recent machine learning models have shown promise in
predicting sepsis onset, their black-box nature limits interpretability and
clinical trust. In this study, we present an interpretable AI approach for
sepsis analysis that integrates machine learning with clinical knowledge. Our
method not only delivers accurate predictions of sepsis onset but also enables
clinicians to understand, validate, and align model outputs with established
medical expertise.

</details>


### [317] [Learning Time-Varying Graph Signals via Koopman](https://arxiv.org/abs/2511.06493)
*Sivaram Krishnan,Jinho Choi,Jihong Park*

Main category: cs.LG

TL;DR: 本文提出了一种基于Koopman自编码器的框架，用于处理时变图数据，通过图嵌入将图数据转换为向量时间序列，在潜在空间中学习控制图特征时间演化的非线性动力学。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的许多数据（如海洋测量数据、无人机轨迹）可以自然地表示为图结构，这些图结构可能随时间变化。有效建模和分析这种动态图数据对于预测图演化和重建缺失图数据至关重要。

Method: 使用Koopman自编码器框架，首先通过图嵌入将图数据转换为向量时间序列，在有限维潜在空间中表示结构信息，然后应用KAE学习控制图特征时间演化的非线性动力学。

Result: 该方法能够捕获时变图结构，在潜在空间中学习图数据的演化规律，支持预测和重建任务。

Conclusion: 提出的基于KAE的框架为处理时变图数据提供了一种有效方法，能够学习图数据的非线性动力学特性，适用于预测和重建等应用场景。

Abstract: A wide variety of real-world data, such as sea measurements, e.g.,
temperatures collected by distributed sensors and multiple unmanned aerial
vehicles (UAV) trajectories, can be naturally represented as graphs, often
exhibiting non-Euclidean structures. These graph representations may evolve
over time, forming time-varying graphs. Effectively modeling and analyzing such
dynamic graph data is critical for tasks like predicting graph evolution and
reconstructing missing graph data. In this paper, we propose a framework based
on the Koopman autoencoder (KAE) to handle time-varying graph data.
Specifically, we assume the existence of a hidden non-linear dynamical system,
where the state vector corresponds to the graph embedding of the time-varying
graph signals. To capture the evolving graph structures, the graph data is
first converted into a vector time series through graph embedding, representing
the structural information in a finite-dimensional latent space. In this latent
space, the KAE is applied to learn the underlying non-linear dynamics governing
the temporal evolution of graph features, enabling both prediction and
reconstruction tasks.

</details>


### [318] [Route Experts by Sequence, not by Token](https://arxiv.org/abs/2511.06494)
*Tiansheng Wen,Yifei Wang,Aosong Feng,Long Ma,Xinyang Liu,Yifan Wang,Lixuan Guo,Bo Chen,Stefanie Jegelka,Chenyu You*

Main category: cs.LG

TL;DR: SeqTopK是一种改进的MoE路由策略，将专家预算从token级别转移到序列级别，实现端到端的动态专家分配，无需额外模块或重新训练。


<details>
  <summary>Details</summary>
Motivation: 标准TopK路由为所有token分配固定数量的专家，忽略了token复杂度的差异。现有自适应方法需要额外模块和超参数，且通常需要从头重新训练。

Method: SeqTopK通过选择序列中所有token的前T·K个专家，在保持总体预算不变的前提下，实现端到端学习的动态专家分配。

Result: 在数学、编程、法律和写作等任务上，SeqTopK相比TopK和现有参数无关自适应方法都有持续改进，在更高稀疏度下增益更显著（最高达16.9%）。

Conclusion: SeqTopK是一种简单、高效且可扩展的路由策略，特别适合下一代LLM的极端稀疏机制，仅需少量代码修改，增加不到1%的开销，且完全兼容预训练MoE模型。

Abstract: Mixture-of-Experts (MoE) architectures scale large language models (LLMs) by
activating only a subset of experts per token, but the standard TopK routing
assigns the same fixed number of experts to all tokens, ignoring their varying
complexity. Prior adaptive routing methods introduce additional modules and
hyperparameters, often requiring costly retraining from scratch. We propose
Sequence-level TopK (SeqTopK), a minimal modification that shifts the expert
budget from the token level to the sequence level. By selecting the top $T
\cdot K$ experts across all $T$ tokens, SeqTopK enables end-to-end learned
dynamic allocation -- assigning more experts to difficult tokens and fewer to
easy ones -- while preserving the same overall budget. SeqTopK requires only a
few lines of code, adds less than 1% overhead, and remains fully compatible
with pretrained MoE models. Experiments across math, coding, law, and writing
show consistent improvements over TopK and prior parameter-free adaptive
methods, with gains that become substantially larger under higher sparsity (up
to 16.9%). These results highlight SeqTopK as a simple, efficient, and scalable
routing strategy, particularly well-suited for the extreme sparsity regimes of
next-generation LLMs. Code is available at
https://github.com/Y-Research-SBU/SeqTopK.

</details>


### [319] [TriShGAN: Enhancing Sparsity and Robustness in Multivariate Time Series Counterfactuals Explanation](https://arxiv.org/abs/2511.06529)
*Hongnan Ma,Yiwei Shi,Guanxiong Sun,Mengyue Yang,Weiru Liu*

Main category: cs.LG

TL;DR: 提出TriShGAN方法，在CounteRGAN框架中引入三元组损失，为多变量时间序列生成更鲁棒的反事实解释，同时集成Shapelet提取器提升稀疏性和训练效率。


<details>
  <summary>Details</summary>
Motivation: 传统反事实解释方法在多变量时间序列中存在局限性：基于最近邻的方法直接替换子序列不现实，基于GAN的方法主要关注最小化成本而忽视远离决策边界的重要性，导致解释不够鲁棒。

Method: 在CounteRGAN框架中引入三元组损失进行无监督学习，使用距离度量学习使反事实解释既接近查询时间序列又捕获期望结果实例的特征分布；集成Shapelet提取器选择高维时间序列中最具判别性的部分。

Result: TriShGAN方法在最小化成本和鲁棒性之间实现了更好的平衡，生成的解释更稳定，即使模型发生微小变化仍能保持反事实性质。

Conclusion: TriShGAN通过三元组损失和Shapelet提取器的结合，为多变量时间序列生成了更鲁棒和稀疏的反事实解释，解决了传统方法的局限性。

Abstract: In decision-making processes, stakeholders often rely on counterfactual
explanations, which provide suggestions about what should be changed in the
queried instance to alter the outcome of an AI system. However, generating
these explanations for multivariate time series presents challenges due to
their complex, multi-dimensional nature. Traditional Nearest Unlike
Neighbor-based methods typically substitute subsequences in a queried time
series with influential subsequences from an NUN, which is not always realistic
in real-world scenarios due to the rigid direct substitution. Counterfactual
with Residual Generative Adversarial Networks-based methods aim to address this
by learning from the distribution of observed data to generate synthetic
counterfactual explanations. However, these methods primarily focus on
minimizing the cost from the queried time series to the counterfactual
explanations and often neglect the importance of distancing the counterfactual
explanation from the decision boundary. This oversight can result in
explanations that no longer qualify as counterfactual if minor changes occur
within the model. To generate a more robust counterfactual explanation, we
introduce TriShGAN, under the CounteRGAN framework enhanced by the
incorporation of triplet loss. This unsupervised learning approach uses
distance metric learning to encourage the counterfactual explanations not only
to remain close to the queried time series but also to capture the feature
distribution of the instance with the desired outcome, thereby achieving a
better balance between minimal cost and robustness. Additionally, we integrate
a Shapelet Extractor that strategically selects the most discriminative parts
of the high-dimensional queried time series to enhance the sparsity of
counterfactual explanation and efficiency of the training process.

</details>


### [320] [Bayesian Uncertainty Quantification with Anchored Ensembles for Robust EV Power Consumption Prediction](https://arxiv.org/abs/2511.06538)
*Ghazal Farhani,Taufiq Rahman,Kieran Humphries*

Main category: cs.LG

TL;DR: 提出了一种基于锚定集成LSTM和Student-t似然的方法，用于电动汽车功率估计，同时捕捉模型和数据不确定性，实现高精度和校准良好的不确定性区间。


<details>
  <summary>Details</summary>
Motivation: 电动汽车功率估计需要同时保证点估计精度和可信的不确定性，以支持续航预测和能源管理决策。

Method: 采用锚定集成LSTM结合Student-t似然函数，通过高斯权重先验实现后验多样性，无需测试时采样；t-head提供重尾鲁棒性和闭式预测区间。

Result: 在车辆运动学时间序列数据上，模型达到RMSE 3.36±1.10，MAE 2.21±0.89，R²=0.93±0.02，解释方差0.93±0.02，并产生校准良好的不确定性区间。

Conclusion: 该方法实现了精度、校准和系统效率的结合，为生产级电动汽车能源管理提供可靠的续航估计和决策支持。

Abstract: Accurate EV power estimation underpins range prediction and energy
management, yet practitioners need both point accuracy and trustworthy
uncertainty. We propose an anchored-ensemble Long Short-Term Memory (LSTM) with
a Student-t likelihood that jointly captures epistemic (model) and aleatoric
(data) uncertainty. Anchoring imposes a Gaussian weight prior (MAP training),
yielding posterior-like diversity without test-time sampling, while the t-head
provides heavy-tailed robustness and closed-form prediction intervals. Using
vehicle-kinematic time series (e.g., speed, motor RPM), our model attains
strong accuracy: RMSE 3.36 +/- 1.10, MAE 2.21 +/- 0.89, R-squared = 0.93 +/-
0.02, explained variance 0.93 +/- 0.02, and delivers well-calibrated
uncertainty bands with near-nominal coverage. Against competitive baselines
(Student-t MC dropout; quantile regression with/without anchoring), our method
matches or improves log-scores while producing sharper intervals at the same
coverage. Crucially for real-time deployment, inference is a single
deterministic pass per ensemble member (or a weight-averaged collapse),
eliminating Monte Carlo latency. The result is a compact, theoretically
grounded estimator that couples accuracy, calibration, and systems efficiency,
enabling reliable range estimation and decision-making for production EV energy
management.

</details>


### [321] [Breaking the Dyadic Barrier: Rethinking Fairness in Link Prediction Beyond Demographic Parity](https://arxiv.org/abs/2511.06568)
*João Mattos,Debolina Halder Lina,Arlei Silva*

Main category: cs.LG

TL;DR: 本文分析了图机器学习中链接预测任务的公平性问题，指出现有基于二元公平性定义的方法存在局限性，提出了更全面的评估框架和轻量级后处理方法。


<details>
  <summary>Details</summary>
Motivation: 链接预测中的公平性至关重要，因为偏见预测会加剧社会不平等。现有工作采用二元公平性定义，但这种框架可能掩盖子群体间的潜在差异，且人口均等性不适用于基于排名的链接预测任务。

Method: 提出了一个更全面的评估框架，并开发了一种轻量级后处理方法，结合解耦的链接预测器来有效减轻偏见。

Result: 该方法在公平性与效用性之间取得了最先进的权衡效果。

Conclusion: 现有二元公平性框架存在局限性，需要更全面的评估方法，提出的后处理方法能有效改善链接预测的公平性表现。

Abstract: Link prediction is a fundamental task in graph machine learning with
applications, ranging from social recommendation to knowledge graph completion.
Fairness in this setting is critical, as biased predictions can exacerbate
societal inequalities. Prior work adopts a dyadic definition of fairness,
enforcing fairness through demographic parity between intra-group and
inter-group link predictions. However, we show that this dyadic framing can
obscure underlying disparities across subgroups, allowing systemic biases to go
undetected. Moreover, we argue that demographic parity does not meet desired
properties for fairness assessment in ranking-based tasks such as link
prediction. We formalize the limitations of existing fairness evaluations and
propose a framework that enables a more expressive assessment. Additionally, we
propose a lightweight post-processing method combined with decoupled link
predictors that effectively mitigates bias and achieves state-of-the-art
fairness-utility trade-offs.

</details>


### [322] [Optimistic Online-to-Batch Conversions for Accelerated Convergence and Universality](https://arxiv.org/abs/2511.06597)
*Yu-Hu Yan,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本文提出了新颖的乐观在线到批量转换方法，将乐观主义理论融入分析，显著简化在线算法设计，同时保持最优收敛速率。该方法在平滑目标上实现最优加速收敛，并首次通过在线到批量转换视角在强凸平滑目标上达到最优加速收敛率。


<details>
  <summary>Details</summary>
Motivation: 理解Nesterov加速梯度方法(NAG)从在线学习和在线到批量转换的视角，强调乐观在线算法在加速中的作用，旨在简化在线算法设计同时保持最优性能。

Method: 提出新颖的乐观在线到批量转换方法，将乐观主义理论融入分析框架，结合简单在线梯度下降和乐观在线算法。

Result: (i) 结合简单在线梯度下降实现最优加速收敛；(ii) 首次通过在线到批量转换在强凸平滑目标上达到最优加速收敛率；(iii) 实现平滑度通用性，适用于平滑和非平滑目标，每轮仅需一次梯度查询。

Conclusion: 乐观在线到批量转换方法有效简化了算法设计，保持最优收敛性能，并与Nesterov加速梯度方法建立了精确对应关系。

Abstract: In this work, we study offline convex optimization with smooth objectives,
where the classical Nesterov's Accelerated Gradient (NAG) method achieves the
optimal accelerated convergence. Extensive research has aimed to understand NAG
from various perspectives, and a recent line of work approaches this from the
viewpoint of online learning and online-to-batch conversion, emphasizing the
role of optimistic online algorithms for acceleration. In this work, we
contribute to this perspective by proposing novel optimistic online-to-batch
conversions that incorporate optimism theoretically into the analysis, thereby
significantly simplifying the online algorithm design while preserving the
optimal convergence rates. Specifically, we demonstrate the effectiveness of
our conversions through the following results: (i) when combined with simple
online gradient descent, our optimistic conversion achieves the optimal
accelerated convergence; (ii) our conversion also applies to strongly convex
objectives, and by leveraging both optimistic online-to-batch conversion and
optimistic online algorithms, we achieve the optimal accelerated convergence
rate for strongly convex and smooth objectives, for the first time through the
lens of online-to-batch conversion; (iii) our optimistic conversion can achieve
universality to smoothness -- applicable to both smooth and non-smooth
objectives without requiring knowledge of the smoothness coefficient -- and
remains efficient as non-universal methods by using only one gradient query in
each iteration. Finally, we highlight the effectiveness of our optimistic
online-to-batch conversions by a precise correspondence with NAG.

</details>


### [323] [Explainable Probabilistic Machine Learning for Predicting Drilling Fluid Loss of Circulation in Marun Oil Field](https://arxiv.org/abs/2511.06607)
*Seshu Kumar Damarla,Xiuli Zhu*

Main category: cs.LG

TL;DR: 本文提出了一个基于高斯过程回归的概率机器学习框架，用于预测复杂地层中的钻井液漏失，通过量化预测不确定性提高决策可靠性，并利用LIME增强模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 钻井作业中的漏失问题导致井筒不稳定、卡钻和非生产时间延长，准确预测流体损失对于提高钻井安全性和效率至关重要。

Method: 采用高斯过程回归模型捕捉钻井参数间的非线性依赖关系，使用LBFGS算法优化超参数确保数值稳定性和泛化能力，并应用LIME方法解释特征对预测的影响。

Result: 该框架能够主动识别漏失风险，优化堵漏材料设计，并减少钻井应用中的操作不确定性。

Conclusion: 可解释的概率学习方法在钻井漏失预测中具有重要潜力，能够为高风险决策提供增强的可靠性。

Abstract: Lost circulation remains a major and costly challenge in drilling operations,
often resulting in wellbore instability, stuck pipe, and extended
non-productive time. Accurate prediction of fluid loss is therefore essential
for improving drilling safety and efficiency. This study presents a
probabilistic machine learning framework based on Gaussian Process Regression
(GPR) for predicting drilling fluid loss in complex formations. The GPR model
captures nonlinear dependencies among drilling parameters while quantifying
predictive uncertainty, offering enhanced reliability for high-risk
decision-making. Model hyperparameters are optimized using the Limited memory
Broyden Fletcher Goldfarb Shanno (LBFGS) algorithm to ensure numerical
stability and robust generalization. To improve interpretability, Local
Interpretable Model agnostic Explanations (LIME) are employed to elucidate how
individual features influence model predictions. The results highlight the
potential of explainable probabilistic learning for proactive identification of
lost-circulation risks, optimized design of lost circulation materials (LCM),
and reduction of operational uncertainties in drilling applications.

</details>


### [324] [A Weak Penalty Neural ODE for Learning Chaotic Dynamics from Noisy Time Series](https://arxiv.org/abs/2511.06609)
*Xuyang Li,John Harlim,Romit Maulik*

Main category: cs.LG

TL;DR: 本文提出了一种弱惩罚神经常微分方程（WP-NODE）方法，通过结合弱公式化和强公式化来提升混沌动力系统中数据驱动模型的预测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的测量数据往往受到噪声污染，这会严重降低数据驱动模型的性能。在混沌动力系统中，小误差会迅速放大，因此需要一种能够同时实现短期精度和保持长期不变性的数据驱动模型。

Method: 提出弱惩罚神经常微分方程（WP-NODE）方法，将弱公式化作为惩罚项与经典的强公式化学习相结合。弱公式化通过时间子域上的积分残差来约束模型，而强公式化则基于NODE的离散化和优化。

Result: 通过数值实验证明，WP-NODE在基准混沌动力系统中实现了最先进的预测精度和卓越的鲁棒性。

Conclusion: 弱公式化作为强公式化的补充方法，能够有效提升神经常微分方程在噪声数据下的性能，特别是在混沌动力系统的预测任务中表现出色。

Abstract: Accurate forecasting of complex high-dimensional dynamical systems from
observational data is essential for several applications across science and
engineering. A key challenge, however, is that real-world measurements are
often corrupted by noise, which severely degrades the performance of
data-driven models. Particularly, in chaotic dynamical systems, where small
errors amplify rapidly, it is challenging to identify a data-driven model from
noisy data that achieves short-term accuracy while preserving long-term
invariant properties. In this paper, we propose the use of the weak formulation
as a complementary approach to the classical strong formulation of data-driven
time-series forecasting models. Specifically, we focus on the neural ordinary
differential equation (NODE) architecture. Unlike the standard strong
formulation, which relies on the discretization of the NODE followed by
optimization, the weak formulation constrains the model using a set of
integrated residuals over temporal subdomains. While such a formulation yields
an effective NODE model, we discover that the performance of a NODE can be
further enhanced by employing this weak formulation as a penalty alongside the
classical strong formulation-based learning. Through numerical demonstrations,
we illustrate that our proposed training strategy, which we coined as the
Weak-Penalty NODE (WP-NODE), achieves state-of-the-art forecasting accuracy and
exceptional robustness across benchmark chaotic dynamical systems.

</details>


### [325] [Non-Rival Data as Rival Products: An Encapsulation-Forging Approach for Data Synthesis](https://arxiv.org/abs/2511.06610)
*Kaidong Wang,Jiale Li,Shao-Bo Lin,Yao Wang*

Main category: cs.LG

TL;DR: EnFo框架通过封装关键模型和锻造合成数据，将非竞争性数据转化为具有不对称效用的竞争性数据产品，解决企业在数据共享与竞争优势保护之间的困境。


<details>
  <summary>Details</summary>
Motivation: 解决数据非竞争性带来的困境：数据共享能创造价值但会削弱竞争优势。现有数据合成方法通常产生对称效用的数据，无法保护数据所有者的竞争优势。

Method: 两阶段框架：1) 从原始数据中封装预测知识到指定的"关键"模型中；2) 通过优化数据故意使合成数据过拟合该关键模型，从而创建具有不对称效用的合成数据。

Result: 框架展现出卓越的样本效率，仅用原始数据的一小部分就能达到同等性能，同时提供强大的隐私保护和抗滥用能力。

Conclusion: EnFo为企业提供了在不损害核心分析优势的情况下进行战略协作的实用解决方案，将非竞争性数据转化为竞争性产品，确保价值仅对预期模型可访问。

Abstract: The non-rival nature of data creates a dilemma for firms: sharing data
unlocks value but risks eroding competitive advantage. Existing data synthesis
methods often exacerbate this problem by creating data with symmetric utility,
allowing any party to extract its value. This paper introduces the
Encapsulation-Forging (EnFo) framework, a novel approach to generate rival
synthetic data with asymmetric utility. EnFo operates in two stages: it first
encapsulates predictive knowledge from the original data into a designated
``key'' model, and then forges a synthetic dataset by optimizing the data to
intentionally overfit this key model. This process transforms non-rival data
into a rival product, ensuring its value is accessible only to the intended
model, thereby preventing unauthorized use and preserving the data owner's
competitive edge. Our framework demonstrates remarkable sample efficiency,
matching the original data's performance with a fraction of its size, while
providing robust privacy protection and resistance to misuse. EnFo offers a
practical solution for firms to collaborate strategically without compromising
their core analytical advantage.

</details>


### [326] [CaberNet: Causal Representation Learning for Cross-Domain HVAC Energy Prediction](https://arxiv.org/abs/2511.06634)
*Kaiyuan Zhai,Jiacheng Cui,Zhehao Zhang,Junyu Xue,Yang Deng,Kui Wu,Guoming Tang*

Main category: cs.LG

TL;DR: CaberNet是一个因果可解释的深度序列模型，通过全局特征门控和域平衡训练方案，学习不变表示以解决跨域HVAC能耗预测中的数据稀缺和异质性问题。


<details>
  <summary>Details</summary>
Motivation: 跨域HVAC能耗预测面临数据稀缺、异质性和过度依赖专家干预等挑战，现有方法容易过拟合到虚假相关性或牺牲数据多样性。

Method: CaberNet整合了：1）通过自监督伯努利正则化训练的全局特征门控来区分因果特征；2）域平衡训练方案，平衡域贡献、最小化跨域损失方差并促进潜在因子独立性。

Result: 在三个气候不同城市的真实数据集上，CaberNet始终优于所有基线方法，相比最佳基准实现了22.9%的归一化均方误差(NMSE)降低。

Conclusion: CaberNet以纯数据驱动方式，无需先验知识，能够有效学习不变表示，实现稳健的跨域HVAC能耗预测。

Abstract: Cross-domain HVAC energy prediction is essential for scalable building energy
management, particularly because collecting extensive labeled data for every
new building is both costly and impractical. Yet, this task remains highly
challenging due to the scarcity and heterogeneity of data across different
buildings, climate zones, and seasonal patterns. In particular, buildings
situated in distinct climatic regions introduce variability that often leads
existing methods to overfit to spurious correlations, rely heavily on expert
intervention, or compromise on data diversity. To address these limitations, we
propose CaberNet, a causal and interpretable deep sequence model that learns
invariant (Markov blanket) representations for robust cross-domain prediction.
In a purely data-driven fashion and without requiring any prior knowledge,
CaberNet integrates i) a global feature gate trained with a self-supervised
Bernoulli regularization to distinguish superior causal features from inferior
ones, and ii) a domain-wise training scheme that balances domain contributions,
minimizes cross-domain loss variance, and promotes latent factor independence.
We evaluate CaberNet on real-world datasets collected from three buildings
located in three climatically diverse cities, and it consistently outperforms
all baselines, achieving a 22.9\% reduction in normalized mean squared error
(NMSE) compared to the best benchmark. Our code is available at
https://github.com/rickzky1001/CaberNet-CRL.

</details>


### [327] [Neyman-Pearson Classification under Both Null and Alternative Distributions Shift](https://arxiv.org/abs/2511.06641)
*Mohammadreza M. Kalan,Yuyang Deng,Eitan J. Neugut,Samory Kpotufe*

Main category: cs.LG

TL;DR: 本文研究了Neyman-Pearson分类中的迁移学习问题，提出了一种自适应方法，能够在源数据信息丰富时改善Type-I和Type-II错误，在源数据无信息时避免负迁移。


<details>
  <summary>Details</summary>
Motivation: 传统分类中的迁移学习已被广泛研究，但在不平衡分类如Neyman-Pearson分类中的迁移学习关注较少。该设置面临独特挑战，需要同时控制两种类型的错误。现有工作仅处理μ1分布偏移的情况，而实际场景中μ0和μ1都可能发生偏移。

Method: 提出了一种自适应程序，不仅保证在源数据信息丰富时改善Type-I和Type-II错误，还能自动适应源数据无信息的情况，避免负迁移。

Result: 该方法具有统计保证，能够有效控制两种错误类型，同时在源数据无信息时避免性能下降。此外，该方法还具有计算效率保证。

Conclusion: 该自适应方法为Neyman-Pearson分类中的迁移学习提供了有效的解决方案，能够处理双向分布偏移并避免负迁移，同时具有统计和计算效率保证。

Abstract: We consider the problem of transfer learning in Neyman-Pearson
classification, where the objective is to minimize the error w.r.t. a
distribution $\mu_1$, subject to the constraint that the error w.r.t. a
distribution $\mu_0$ remains below a prescribed threshold. While transfer
learning has been extensively studied in traditional classification, transfer
learning in imbalanced classification such as Neyman-Pearson classification has
received much less attention. This setting poses unique challenges, as both
types of errors must be simultaneously controlled. Existing works address only
the case of distribution shift in $\mu_1$, whereas in many practical scenarios
shifts may occur in both $\mu_0$ and $\mu_1$. We derive an adaptive procedure
that not only guarantees improved Type-I and Type-II errors when the source is
informative, but also automatically adapt to situations where the source is
uninformative, thereby avoiding negative transfer. In addition to such
statistical guarantees, the procedures is efficient, as shown via complementary
computational guarantees.

</details>


### [328] [Improving Asset Allocation in a Fast Moving Consumer Goods B2B Company: An Interpretable Machine Learning Framework for Commercial Cooler Assignment Based on Multi-Tier Growth Targets](https://arxiv.org/abs/2511.06642)
*Renato Castro,Rodrigo Paredes,Douglas Kahn*

Main category: cs.LG

TL;DR: 本文提出了一个机器学习框架，用于预测哪些饮料客户在获得商用饮料冷柜后最有可能实现销量增长，通过比较XGBoost、LightGBM和CatBoost等模型，在验证集上AUC得分达到0.857-0.898，能够提高投资回报率。


<details>
  <summary>Details</summary>
Motivation: 在快消品行业，物理资产（如商用饮料冷柜）的放置位置直接影响收入增长和执行效率。虽然B2B环境中的流失预测和需求预测已被广泛研究，但使用机器学习指导资产分配仍相对未被探索。

Method: 使用来自中美洲知名酿酒和饮料公司的3,119个B2B传统贸易渠道客户的私有数据集，跟踪冷柜安装前后12个月的销售交易。定义了三个增长阈值（10%、30%和50%的年销量增长），比较了XGBoost、LightGBM和CatBoost等机器学习模型，并结合SHAP进行可解释的特征分析。

Result: 最佳模型在验证集上的AUC得分分别为0.857、0.877和0.898。模拟表明，与传统基于销量的方法相比，该方法能更好地选择有增长潜力的客户，并通过不分配给不会增长的客户来增加成本节约。

Conclusion: 该框架能够显著提高冷柜分配的投资回报率，为改善与冷柜分配相关的业务运营提供了有价值的见解和重要的业务管理建议。

Abstract: In the fast-moving consumer goods (FMCG) industry, deciding where to place
physical assets, such as commercial beverage coolers, can directly impact
revenue growth and execution efficiency. Although churn prediction and demand
forecasting have been widely studied in B2B contexts, the use of machine
learning to guide asset allocation remains relatively unexplored. This paper
presents a framework focused on predicting which beverage clients are most
likely to deliver strong returns in volume after receiving a cooler. Using a
private dataset from a well-known Central American brewing and beverage company
of 3,119 B2B traditional trade channel clients that received a cooler from
2022-01 to 2024-07, and tracking 12 months of sales transactions before and
after cooler installation, three growth thresholds were defined: 10%, 30% and
50% growth in sales volume year over year. The analysis compares results of
machine learning models such as XGBoost, LightGBM, and CatBoost combined with
SHAP for interpretable feature analysis in order to have insights into
improving business operations related to cooler allocation; the results show
that the best model has AUC scores of 0.857, 0.877, and 0.898 across the
thresholds on the validation set. Simulations suggest that this approach can
improve ROI because it better selects potential clients to grow at the expected
level and increases cost savings by not assigning clients that will not grow,
compared to traditional volume-based approaches with substantial business
management recommendations

</details>


### [329] [Dual-Pathway Fusion of EHRs and Knowledge Graphs for Predicting Unseen Drug-Drug Interactions](https://arxiv.org/abs/2511.06662)
*Franklin Lee,Tengfei Ma*

Main category: cs.LG

TL;DR: 该论文提出了首个结合知识图谱和电子健康记录的系统，通过教师-学生模型实现零样本药物相互作用预测，能够泛化到未见过的药物。


<details>
  <summary>Details</summary>
Motivation: 现有药物相互作用模型要么依赖知识图谱（无法处理新药），要么依赖电子健康记录（噪声大、时间依赖性强），需要一种能够结合两者优势并实现零样本推理的方法。

Method: 使用融合教师模型学习知识图谱和电子健康记录中的药物关系，然后蒸馏到仅使用电子健康记录的学生模型中，共享药理学机制本体论，生成可解释的警报而非不透明的风险评分。

Result: 在多机构数据集上测试，系统保持高精度，产生机制特异性预测，减少误报，在总体检测性能相当的情况下漏报更少真实相互作用。

Conclusion: 该系统能够零样本识别知识图谱中未包含药物的临床认可机制，支持临床决策支持和药物警戒的实际应用。

Abstract: Drug-drug interactions (DDIs) remain a major source of preventable harm, and
many clinically important mechanisms are still unknown. Existing models either
rely on pharmacologic knowledge graphs (KGs), which fail on unseen drugs, or on
electronic health records (EHRs), which are noisy, temporal, and
site-dependent. We introduce, to our knowledge, the first system that
conditions KG relation scoring on patient-level EHR context and distills that
reasoning into an EHR-only model for zero-shot inference. A fusion "Teacher"
learns mechanism-specific relations for drug pairs represented in both sources,
while a distilled "Student" generalizes to new or rarely used drugs without KG
access at inference. Both operate under a shared ontology (set) of
pharmacologic mechanisms (drug relations) to produce interpretable, auditable
alerts rather than opaque risk scores. Trained on a multi-institution EHR
corpus paired with a curated DrugBank DDI graph, and evaluated using a
clinically aligned, decision-focused protocol with leakage-safe negatives that
avoid artificially easy pairs, the system maintains precision across
multi-institutuion test data, produces mechanism-specific, clinically
consistent predictions, reduces false alerts (higher precision) at comparable
overall detection performance (F1), and misses fewer true interactions compared
to prior methods. Case studies further show zero-shot identification of
clinically recognized CYP-mediated and pharmacodynamic mechanisms for drugs
absent from the KG, supporting real-world use in clinical decision support and
pharmacovigilance.

</details>


### [330] [An Adaptive Machine Learning Triage Framework for Predicting Alzheimer's Disease Progression](https://arxiv.org/abs/2511.06681)
*Richard Hou,Shengpu Tang,Wei Jin*

Main category: cs.LG

TL;DR: 提出一个两阶段机器学习框架，通过选择性获取昂贵的高级特征来预测轻度认知障碍向阿尔茨海默病的转化，在减少20%高级测试需求的同时保持高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 解决阿尔茨海默病预测中的成本-准确性困境，常规认知测试和临床数据预测能力不足，而PET扫描和CSF生物标志物分析成本过高。

Method: 设计两阶段机器学习框架，基于预测的"信息价值"选择性获取昂贵的高级特征，应用于ADNI数据集预测MCI向AD的转化。

Result: 框架将高级测试需求减少20%，同时达到0.929的测试AUROC，与使用所有特征的模型性能相当（AUROC=0.915，p=0.1010），并提供可解释性分析。

Conclusion: 该框架为优化AD诊断路径提供了可解释的数据驱动方法，平衡了准确性与成本，有助于在真实世界实践中实现早期可靠的AD预测。

Abstract: Accurate predictions of conversion from mild cognitive impairment (MCI) to
Alzheimer's disease (AD) can enable effective personalized therapy. While
cognitive tests and clinical data are routinely collected, they lack the
predictive power of PET scans and CSF biomarker analysis, which are
prohibitively expensive to obtain for every patient. To address this
cost-accuracy dilemma, we design a two-stage machine learning framework that
selectively obtains advanced, costly features based on their predicted "value
of information". We apply our framework to predict AD progression for MCI
patients using data from the Alzheimer's Disease Neuroimaging Initiative
(ADNI). Our framework reduces the need for advanced testing by 20% while
achieving a test AUROC of 0.929, comparable to the model that uses both basic
and advanced features (AUROC=0.915, p=0.1010). We also provide an example
interpretability analysis showing how one may explain the triage decision. Our
work presents an interpretable, data-driven framework that optimizes AD
diagnostic pathways and balances accuracy with cost, representing a step
towards making early, reliable AD prediction more accessible in real-world
practice. Future work should consider multiple categories of advanced features
and larger-scale validation.

</details>


### [331] [Mitigating Modality Imbalance in Multi-modal Learning via Multi-objective Optimization](https://arxiv.org/abs/2511.06686)
*Heshan Fernando,Parikshit Ram,Yi Zhou,Soham Dan,Horst Samulowitz,Nathalie Baracaldo,Tianyi Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于多目标优化的多模态学习方法，解决了多模态学习中存在的学习不平衡问题，相比现有方法性能更好且计算效率大幅提升。


<details>
  <summary>Details</summary>
Motivation: 多模态学习通常期望优于单模态学习，但实际中由于模态间学习不平衡，多模态学习反而可能表现更差。现有方法使用启发式策略解决不平衡问题，但往往导致计算密集型子程序。

Method: 将多模态学习问题重新表述为多目标优化问题，并提出基于梯度的算法来解决修改后的多模态学习问题。

Result: 在流行的多模态学习基准测试中，该方法相比现有的平衡多模态学习和多目标优化基线方法表现更好，子程序计算时间减少了约20倍。

Conclusion: 提出的多目标优化方法有效解决了多模态学习中的不平衡问题，在提升性能的同时显著降低了计算成本。

Abstract: Multi-modal learning (MML) aims to integrate information from multiple
modalities, which is expected to lead to superior performance over
single-modality learning. However, recent studies have shown that MML can
underperform, even compared to single-modality approaches, due to imbalanced
learning across modalities. Methods have been proposed to alleviate this
imbalance issue using different heuristics, which often lead to computationally
intensive subroutines. In this paper, we reformulate the MML problem as a
multi-objective optimization (MOO) problem that overcomes the imbalanced
learning issue among modalities and propose a gradient-based algorithm to solve
the modified MML problem. We provide convergence guarantees for the proposed
method, and empirical evaluations on popular MML benchmarks showcasing the
improved performance of the proposed method over existing balanced MML and MOO
baselines, with up to ~20x reduction in subroutine computation time. Our code
is available at https://github.com/heshandevaka/MIMO.

</details>


### [332] [Peeling Context from Cause for Multimodal Molecular Property Prediction](https://arxiv.org/abs/2511.06692)
*Tao Li,Kaiyuan Hou,Tuan Vinh,Carl Yang,Monika Raj*

Main category: cs.LG

TL;DR: CLaP框架通过分层分离分子图中的因果信号和上下文信息，融合多模态因果证据，逐步去除批次耦合的上下文，从而提高分子性质预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度模型在分子性质预测中难以解释，且可能依赖虚假上下文而非因果结构，导致在分布偏移下可靠性降低和预测性能下降。

Method: CLaP框架在每个层级执行软分割为因果和非因果分支，融合多模态因果证据，逐步去除批次耦合的上下文，聚焦于标签相关结构。

Result: 在四个分子基准测试中，CLaP在MAE、MSE和R²指标上持续优于竞争基线方法。

Conclusion: 通过逐层剥离上下文与因果关系，CLaP产生了既准确又可解释的分子设计预测器，并提供原子级因果显著性图谱指导分子编辑。

Abstract: Deep models are used for molecular property prediction, yet they are often
difficult to interpret and may rely on spurious context rather than causal
structure, which reduces reliability under distribution shift and harms
predictive performance. We introduce CLaP (Causal Layerwise Peeling), a
framework that separates causal signal from context in a layerwise manner and
integrates diverse graph representations of molecules. At each layer, a causal
block performs a soft split into causal and non-causal branches, fuses causal
evidence across modalities, and progressively removes batch-coupled context to
focus on label-relevant structure, thereby limiting shortcut signals and
stabilizing layerwise refinement. Across four molecular benchmarks, CLaP
consistently improves MAE, MSE, and $R^2$ over competitive baselines. The model
also produces atom-level causal saliency maps that highlight substructures
responsible for predictions, providing actionable guidance for targeted
molecular edits. Case studies confirm the accuracy of these maps and their
alignment with chemical intuition. By peeling context from cause at every
layer, the model yields predictors that are both accurate and interpretable for
molecular design.

</details>


### [333] [ML-EcoLyzer: Quantifying the Environmental Cost of Machine Learning Inference Across Frameworks and Hardware](https://arxiv.org/abs/2511.06694)
*Jose Marie Antonio Minoza,Rex Gregor Laylo,Christian F Villarin,Sebastian C. Ibanez*

Main category: cs.LG

TL;DR: ML-EcoLyzer是一个跨框架工具，用于测量机器学习推理在CPU、消费级GPU和数据中心加速器上的碳、能源、热力和水资源成本，并引入环境可持续性评分(ESS)来量化每克CO₂排放所服务的有效参数数量。


<details>
  <summary>Details</summary>
Motivation: 机器学习推理规模巨大，但其环境影响在低资源硬件上仍未得到充分量化，需要开发工具来测量和评估推理过程的环境成本。

Method: 开发ML-EcoLyzer工具，支持经典和现代模型，应用自适应监测和硬件感知评估，在超过1,900个推理配置上进行评估，涵盖不同模型架构、任务模式、硬件类型和精度级别。

Result: 量化增强ESS，大型加速器在轻量级应用中可能效率低下，即使小型模型在实施不当时也可能产生显著成本。

Conclusion: ML-EcoLyzer为可持续性意识模型选择设定了标准，并提供了推理过程中环境成本的广泛实证评估。

Abstract: Machine learning inference occurs at a massive scale, yet its environmental
impact remains poorly quantified, especially on low-resource hardware. We
present ML-EcoLyzer, a cross-framework tool for measuring the carbon, energy,
thermal, and water costs of inference across CPUs, consumer GPUs, and
datacenter accelerators. The tool supports both classical and modern models,
applying adaptive monitoring and hardware-aware evaluation.
  We introduce the Environmental Sustainability Score (ESS), which quantifies
the number of effective parameters served per gram of CO$_2$ emitted. Our
evaluation covers over 1,900 inference configurations, spanning diverse model
architectures, task modalities (text, vision, audio, tabular), hardware types,
and precision levels. These rigorous and reliable measurements demonstrate that
quantization enhances ESS, huge accelerators can be inefficient for lightweight
applications, and even small models may incur significant costs when
implemented suboptimally. ML-EcoLyzer sets a standard for
sustainability-conscious model selection and offers an extensive empirical
evaluation of environmental costs during inference.

</details>


### [334] [Sensor Calibration Model Balancing Accuracy, Real-time, and Efficiency](https://arxiv.org/abs/2511.06715)
*Jinyong Yun,Hyungjin Kim,Seokho Ahn,Euijong Lee,Young-Duk Seo*

Main category: cs.LG

TL;DR: SCARE是一个超压缩的Transformer模型，专门用于设备端传感器校准，通过三个核心组件实现了精度、实时性和效率的平衡，满足八个微观需求。


<details>
  <summary>Details</summary>
Motivation: 现有设备端传感器校准研究仅关注三个宏观需求（精度、实时性、资源效率），忽略了瞬时误差和最坏情况延迟等部署瓶颈。

Method: SCARE包含三个核心组件：序列透镜投影器（SLP）对数压缩时间序列数据，高效位注意力（EBA）模块用位运算替代乘法，以及无需辅助损失项的哈希优化策略。

Result: 在大规模空气质量数据集和真实微控制器部署上的实验表明，SCARE优于现有的线性、混合和深度学习基线方法。

Conclusion: SCARE是第一个同时满足所有八个微观需求的传感器校准模型，实现了高精度、低延迟和微控制器兼容性。

Abstract: Most on-device sensor calibration studies benchmark models only against three
macroscopic requirements (i.e., accuracy, real-time, and resource efficiency),
thereby hiding deployment bottlenecks such as instantaneous error and
worst-case latency. We therefore decompose this triad into eight microscopic
requirements and introduce Scare (Sensor Calibration model balancing Accuracy,
Real-time, and Efficiency), an ultra-compressed transformer that fulfills them
all. SCARE comprises three core components: (1) Sequence Lens Projector (SLP)
that logarithmically compresses time-series data while preserving boundary
information across bins, (2) Efficient Bitwise Attention (EBA) module that
replaces costly multiplications with bitwise operations via binary hash codes,
and (3) Hash optimization strategy that ensures stable training without
auxiliary loss terms. Together, these components minimize computational
overhead while maintaining high accuracy and compatibility with microcontroller
units (MCUs). Extensive experiments on large-scale air-quality datasets and
real microcontroller deployments demonstrate that Scare outperforms existing
linear, hybrid, and deep-learning baselines, making Scare, to the best of our
knowledge, the first model to meet all eight microscopic requirements
simultaneously.

</details>


### [335] [MobileLLM-Pro Technical Report](https://arxiv.org/abs/2511.06719)
*Patrick Huber,Ernie Chang,Wei Wen,Igor Fedorov,Tarek Elgamal,Hanxian Huang,Naveen Suda,Chinnadhurai Sankar,Vish Vogeti,Yanghan Wang,Alex Gladkov,Kai Sheng Tai,Abdelrahman Elogeel,Tarek Hefny,Vikas Chandra,Ahmed Aly,Anuj Kumar,Raghuraman Krishnamoorthi,Adithya Sagar*

Main category: cs.LG

TL;DR: MobileLLM-Pro是一个10亿参数的设备端语言模型，在11个基准测试中达到最先进水平，支持128K上下文窗口，4位量化后性能下降很小。


<details>
  <summary>Details</summary>
Motivation: 开发高效的设备端语言模型对于移动和可穿戴设备上的低延迟AI应用至关重要，但在这个模型规模下实现强大性能、支持长上下文窗口和实际部署仍然具有挑战性。

Method: 采用四项核心技术：隐式位置蒸馏、专家模型融合框架、基于效用估计的模拟驱动数据混合、4位量化感知训练与自蒸馏。

Result: 在11个标准基准测试中显著优于Gemma 3-1B和Llama 3.2-1B，支持128K上下文窗口，4位量化后仅出现轻微性能下降。

Conclusion: MobileLLM-Pro为设备端语言模型提供了有效的解决方案，并发布了模型权重和代码以支持未来研究。

Abstract: Efficient on-device language models around 1 billion parameters are essential
for powering low-latency AI applications on mobile and wearable devices.
However, achieving strong performance in this model class, while supporting
long context windows and practical deployment remains a significant challenge.
We introduce MobileLLM-Pro, a 1-billion-parameter language model optimized for
on-device deployment. MobileLLM-Pro achieves state-of-the-art results across 11
standard benchmarks, significantly outperforming both Gemma 3-1B and Llama
3.2-1B, while supporting context windows of up to 128,000 tokens and showing
only minor performance regressions at 4-bit quantization. These improvements
are enabled by four core innovations: (1) implicit positional distillation, a
novel technique that effectively instills long-context capabilities through
knowledge distillation; (2) a specialist model merging framework that fuses
multiple domain experts into a compact model without parameter growth; (3)
simulation-driven data mixing using utility estimation; and (4) 4-bit
quantization-aware training with self-distillation. We release our model
weights and code to support future research in efficient on-device language
models.

</details>


### [336] [Multi-Modal Continual Learning via Cross-Modality Adapters and Representation Alignment with Knowledge Preservation](https://arxiv.org/abs/2511.06723)
*Evelyn Chee,Wynne Hsu,Mong Li Lee*

Main category: cs.LG

TL;DR: 提出了一种基于预训练模型的多模态持续学习框架，通过跨模态适配器和表示对齐损失来有效整合多模态信息并防止灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法主要关注单模态数据，而多模态学习能利用多样化感官输入，但多模态持续学习面临整合新信息和防止灾难性遗忘的额外挑战。

Method: 提出基于预训练模型的框架，包含混合专家结构的跨模态适配器、表示对齐损失以及表示关系正则化。

Result: 在多个多模态数据集上的实验表明，该方法在类增量学习和域增量学习中均优于基线方法，获得更高准确率和更低遗忘率。

Conclusion: 该框架能有效解决多模态持续学习中的挑战，通过跨模态信息整合和知识保持机制实现优越性能。

Abstract: Continual learning is essential for adapting models to new tasks while
retaining previously acquired knowledge. While existing approaches
predominantly focus on uni-modal data, multi-modal learning offers substantial
benefits by utilizing diverse sensory inputs, akin to human perception.
However, multi-modal continual learning presents additional challenges, as the
model must effectively integrate new information from various modalities while
preventing catastrophic forgetting. In this work, we propose a pre-trained
model-based framework for multi-modal continual learning. Our framework
includes a novel cross-modality adapter with a mixture-of-experts structure to
facilitate effective integration of multi-modal information across tasks. We
also introduce a representation alignment loss that fosters learning of robust
multi-modal representations, and regularize relationships between learned
representations to preserve knowledge from previous tasks. Experiments on
several multi-modal datasets demonstrate that our approach consistently
outperforms baselines in both class-incremental and domain-incremental
learning, achieving higher accuracy and reduced forgetting.

</details>


### [337] [Rank-1 LoRAs Encode Interpretable Reasoning Signals](https://arxiv.org/abs/2511.06739)
*Jake Ward,Paul Riechers,Adam Shai*

Main category: cs.LG

TL;DR: 研究发现推理模型性能提升主要来自对基础模型参数的微小单秩修改，使用rank-1 LoRA适配器即可恢复73-90%的推理基准性能，这些修改具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管推理模型在困难逻辑任务上显著提升了语言模型性能并被广泛采用，但其性能提升机制尚未得到很好理解。

Method: 使用rank-1 LoRA为Qwen-2.5-32B-Instruct创建最小参数适配器，并在该LoRA的激活状态上训练稀疏自编码器以识别细粒度特征。

Result: rank-1 LoRA适配器恢复了73-90%的推理基准性能，其激活与MLP神经元一样可解释，且针对特定推理行为激活。

Conclusion: 推理性能主要来自对基础模型参数的微小变化，参数高效训练方法可作为揭示语言模型行为动态的有针对性工具。

Abstract: Reasoning models leverage inference-time compute to significantly enhance the
performance of language models on difficult logical tasks, and have become a
dominating paradigm in frontier LLMs. Despite their wide adoption, the
mechanisms underpinning the enhanced performance of these reasoning models are
not well understood. In this work, we show that the majority of new
capabilities in reasoning models can be elicited by small, single-rank changes
to base model parameters, with many of these changes being interpretable.
Specifically, we use a rank-1 LoRA to create a minimal parameter adapter for
Qwen-2.5-32B-Instruct which recovers 73-90% of reasoning-benchmark performance
compared to a full parameter finetune. We find that the activations of this
LoRA are as interpretable as MLP neurons, and fire for reasoning-specific
behaviors. Finally, we train a sparse autoencoder on the entire activation
state of this LoRA and identify fine-grained and monosemantic features. Our
findings highlight that reasoning performance can arise largely from minimal
changes to base model parameters, and explore what these changes affect. More
broadly, our work shows that parameter-efficient training methods can be used
as a targeted lens for uncovering fundamental insights about language model
behavior and dynamics.

</details>


### [338] [Implicit Federated In-context Learning For Task-Specific LLM Fine-Tuning](https://arxiv.org/abs/2511.06757)
*Dongcheng Li,Junhan Chen,Aoxiang Zhou,Chunpei Li,Youquan Xian,Peng Liu,Xianxian Li*

Main category: cs.LG

TL;DR: 提出了隐式联邦上下文学习框架IFed-ICL，通过将客户端本地上下文示例转换为隐式向量表示，在推理阶段实现分布式协作计算，避免传统微调方法的大量参数更新，同时减少联邦学习中的数据传输和本地计算开销。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，公共数据面临枯竭风险，如何利用组织内部私有数据提升大模型性能成为关键挑战。联邦学习结合模型微调虽然减少了可训练参数，但处理高维特征空间仍带来巨大计算开销。

Method: IFed-ICL框架借鉴联邦学习思想，建立新的分布式协作范式，将客户端本地上下文示例转换为隐式向量表示，在推理阶段进行分布式协作计算，并注入模型残差流来增强模型性能。

Result: 实验表明，该方法在多个文本分类任务中表现出色，相比传统方法避免了传统微调方法的大量参数更新，同时减少了联邦学习中客户端的数据传输和本地计算。

Conclusion: IFed-ICL能够利用本地私有领域数据实现高效的分布式上下文学习，显著提升模型在特定任务上的性能。

Abstract: As large language models continue to develop and expand, the extensive public
data they rely on faces the risk of depletion. Consequently, leveraging private
data within organizations to enhance the performance of large models has
emerged as a key challenge. The federated learning paradigm, combined with
model fine-tuning techniques, effectively reduces the number of trainable
parameters. However,the necessity to process high-dimensional feature spaces
results in substantial overall computational overhead. To address this issue,
we propose the Implicit Federated In-Context Learning (IFed-ICL) framework.
IFed-ICL draws inspiration from federated learning to establish a novel
distributed collaborative paradigm, by converting client local context examples
into implicit vector representations, it enables distributed collaborative
computation during the inference phase and injects model residual streams to
enhance model performance. Experiments demonstrate that our proposed method
achieves outstanding performance across multiple text classification tasks.
Compared to traditional methods, IFed-ICL avoids the extensive parameter
updates required by conventional fine-tuning methods while reducing data
transmission and local computation at the client level in federated learning.
This enables efficient distributed context learning using local private-domain
data, significantly improving model performance on specific tasks.

</details>


### [339] [QUARK: Quantization-Enabled Circuit Sharing for Transformer Acceleration by Exploiting Common Patterns in Nonlinear Operations](https://arxiv.org/abs/2511.06767)
*Zhixiong Zhao,Haomin Li,Fangxin Liu,Yuncheng Lu,Zongwu Wang,Tao Yang,Li Jiang,Haibing Guan*

Main category: cs.LG

TL;DR: QUARK是一个基于FPGA的量化加速框架，专门针对Transformer模型中的非线性操作进行优化，通过电路共享设计显著降低硬件资源需求，在保持模型精度的同时实现高达1.96倍的端到端加速。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在CV和NLP领域取得了最先进的性能，但其中的非线性操作显著增加了推理延迟，给硬件加速带来了独特挑战。

Method: 提出QUARK框架，利用非线性操作中的常见模式实现电路共享，减少硬件资源需求，专门针对Transformer模型中的所有非线性操作进行高性能近似加速。

Result: QUARK显著降低了主流Transformer架构中非线性算子的计算开销，相比GPU实现实现了高达1.96倍的端到端加速，同时将非线性模块的硬件开销降低了50%以上，在超低位量化下甚至能大幅提升模型精度。

Conclusion: QUARK框架通过创新的电路共享设计，有效解决了Transformer模型中非线性操作的硬件加速挑战，在保持精度的同时显著提升了推理效率并降低了硬件成本。

Abstract: Transformer-based models have revolutionized computer vision (CV) and natural
language processing (NLP) by achieving state-of-the-art performance across a
range of benchmarks. However, nonlinear operations in models significantly
contribute to inference latency, presenting unique challenges for efficient
hardware acceleration. To this end, we propose QUARK, a quantization-enabled
FPGA acceleration framework that leverages common patterns in nonlinear
operations to enable efficient circuit sharing, thereby reducing hardware
resource requirements. QUARK targets all nonlinear operations within
Transformer-based models, achieving high-performance approximation through a
novel circuit-sharing design tailored to accelerate these operations. Our
evaluation demonstrates that QUARK significantly reduces the computational
overhead of nonlinear operators in mainstream Transformer architectures,
achieving up to a 1.96 times end-to-end speedup over GPU implementations.
Moreover, QUARK lowers the hardware overhead of nonlinear modules by more than
50% compared to prior approaches, all while maintaining high model accuracy --
and even substantially boosting accuracy under ultra-low-bit quantization.

</details>


### [340] [Data Trajectory Alignment for LLM Domain Adaptation: A Two-Phase Synthesis Framework for Telecommunications Mathematics](https://arxiv.org/abs/2511.06776)
*Zhicheng Zhou,Jing Li,Suming Qiu,Junjie Huang,Linyuan Qiu,Zhijie Sun*

Main category: cs.LG

TL;DR: 本文提出了数据轨迹对齐（DTA）框架，用于在电信等垂直领域适应大型语言模型。该框架通过两阶段数据整理，将解题过程作为监督信号，在TELEMATH数据集上达到72.45%的准确率，比蒸馏训练提升17.65个百分点，同时显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 通用大型语言模型在电信等垂直领域部署面临挑战：数据稀缺、信息密度低，且受移动/边缘计算资源限制。需要开发高效的领域适应方法。

Method: DTA框架包含两个阶段：第一阶段使用强教师模型合成多样化的候选解；第二阶段重写教师解以对齐中间步骤和呈现风格，并通过一致性检查和反思式判断进行信号感知的示例选择。

Result: 在电信数学任务上，DTA达到72.45%的pass@1准确率，比蒸馏训练提升17.65个百分点，比Qwen3-32B（启用思维模式）提升2.94个百分点。在边缘推理设置下，能效提升42%，端到端延迟降低60%。

Conclusion: 对齐解题过程能够为紧凑、高效的监督提供有效方法，在低资源垂直领域具有实用价值，不仅提升准确性，还显著改善推理效率。

Abstract: General-purpose large language models (LLMs) are increasingly deployed in
verticals such as telecommunications, where adaptation is hindered by scarce,
low-information-density corpora and tight mobile/edge constraints. We propose
Data Trajectory Alignment (DTA), a two-phase, model-agnostic data curation
framework that treats solution processes - not only final answers - as
first-class supervision. Phase I (Initializing) synthesizes diverse,
high-coverage candidates using an ensemble of strong teachers. Phase II (DTA)
rewrites teacher solutions to align intermediate steps and presentation style
with the target student's inductive biases and then performs signal-aware
exemplar selection via agreement checks and reflection-based judging.
Instantiated on telecommunications mathematics (e.g., link budgets, SNR/AMC
selection, and power-control feasibility), DTA yields state-of-the-art (SOTA)
accuracy on TELEMATH without enabling explicit "thinking" modes: 72.45% pass@1,
surpassing distilled-only training by +17.65 points and outperforming a strong
baseline (Qwen3-32B with thinking enabled) by +2.94 points. Token-shift
analyses indicate that DTA concentrates gains on logical-structural discourse
markers rather than merely amplifying domain nouns, indicating improved
reasoning scaffolding. Under edge-like inference settings, DTA improves
efficiency by reducing reliance on multi-sample voting and disabling expensive
reasoning heuristics, cutting energy per output token by ~42% versus Qwen3-32B
(thinking mode enabled) and end-to-end latency by ~60% versus Qwen3-32B
(thinking mode disabled). These results demonstrate that aligning how solutions
are produced enables compact, high-yield supervision that is effective for both
accuracy and efficiency, offering a practical recipe for domain adaptation in
low-resource verticals beyond telecom.

</details>


### [341] [On the Mechanisms of Collaborative Learning in VAE Recommenders](https://arxiv.org/abs/2511.06781)
*Tung-Long Vuong,Julien Monteil,Hien Dang,Volodymyr Vaskovych,Trung Le,Vu Nguyen*

Main category: cs.LG

TL;DR: 本文分析了VAE在协同过滤中的协作机制，提出了潜在共享半径概念，研究了局部与全局协作的权衡，并提出锚点正则化器来稳定用户表示并促进全局一致性。


<details>
  <summary>Details</summary>
Motivation: 当前VAE在推荐系统中应用广泛，但输入掩码技术虽然能提升性能，其理论机制仍未被充分探索。本文旨在深入理解VAE在协同过滤中如何实现用户协作，特别是局部与全局协作的平衡问题。

Method: 通过理论分析推导潜在共享半径，研究两种促进全局混合的机制：β-KL正则化和输入掩码，并提出锚点正则化器来对齐用户后验分布与物品嵌入，在保持用户身份的同时实现全局一致性。

Result: 在Netflix、MovieLens-20M和Million Song数据集上验证了分析结果，并在亚马逊流媒体平台上成功部署了所提出的算法，通过了在线实验。

Conclusion: VAE在协同过滤中的协作由潜在邻近性主导，输入掩码通过几何收缩和扩张促进全局协作，而锚点正则化器能有效稳定用户表示并促进信号共享，为实际部署提供了理论指导。

Abstract: Variational Autoencoders (VAEs) are a powerful alternative to matrix
factorization for recommendation. A common technique in VAE-based collaborative
filtering (CF) consists in applying binary input masking to user interaction
vectors, which improves performance but remains underexplored theoretically. In
this work, we analyze how collaboration arises in VAE-based CF and show it is
governed by latent proximity: we derive a latent sharing radius that informs
when an SGD update on one user strictly reduces the loss on another user, with
influence decaying as the latent Wasserstein distance increases. We further
study the induced geometry: with clean inputs, VAE-based CF primarily exploits
\emph{local} collaboration between input-similar users and under-utilizes
global collaboration between far-but-related users. We compare two mechanisms
that encourage \emph{global} mixing and characterize their trade-offs: (1)
$\beta$-KL regularization directly tightens the information bottleneck,
promoting posterior overlap but risking representational collapse if too large;
(2) input masking induces stochastic geometric contractions and expansions,
which can bring distant users onto the same latent neighborhood but also
introduce neighborhood drift. To preserve user identity while enabling global
consistency, we propose an anchor regularizer that aligns user posteriors with
item embeddings, stabilizing users under masking and facilitating signal
sharing across related items. Our analyses are validated on the Netflix,
MovieLens-20M, and Million Song datasets. We also successfully deployed our
proposed algorithm on an Amazon streaming platform following a successful
online experiment.

</details>


### [342] [Resource Efficient Sleep Staging via Multi-Level Masking and Prompt Learning](https://arxiv.org/abs/2511.06785)
*Lejun Ai,Yulong Li,Haodong Yi,Jixuan Xie,Yue Wang,Jia Liu,Min Chen,Rui Wang*

Main category: cs.LG

TL;DR: 提出了一种名为MASS的资源高效睡眠分期框架，通过多级掩码和分层提示学习策略，在减少信号采集量的同时保持可靠的分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有睡眠分期方法严重依赖长时连续EEG记录，这在资源受限系统（如可穿戴设备）中数据采集面临挑战。

Method: 采用掩码和提示学习策略，设计多级掩码策略促进部分不规则观测下的特征建模，并提出分层提示学习机制聚合未掩码数据作为语义锚点。

Result: 在四个数据集上评估，展示了最先进的性能，特别是在数据量非常有限时表现优异。

Conclusion: MASS框架在现实世界低资源睡眠监测环境中具有高效和可扩展部署的潜力。

Abstract: Automatic sleep staging plays a vital role in assessing sleep quality and
diagnosing sleep disorders. Most existing methods rely heavily on long and
continuous EEG recordings, which poses significant challenges for data
acquisition in resource-constrained systems, such as wearable or home-based
monitoring systems. In this paper, we propose the task of resource-efficient
sleep staging, which aims to reduce the amount of signal collected per sleep
epoch while maintaining reliable classification performance. To solve this
task, we adopt the masking and prompt learning strategy and propose a novel
framework called Mask-Aware Sleep Staging (MASS). Specifically, we design a
multi-level masking strategy to promote effective feature modeling under
partial and irregular observations. To mitigate the loss of contextual
information introduced by masking, we further propose a hierarchical prompt
learning mechanism that aggregates unmasked data into a global prompt, serving
as a semantic anchor for guiding both patch-level and epoch-level feature
modeling. MASS is evaluated on four datasets, demonstrating state-of-the-art
performance, especially when the amount of data is very limited. This result
highlights its potential for efficient and scalable deployment in real-world
low-resource sleep monitoring environments.

</details>


### [343] [Rethinking Parameter Sharing as Graph Coloring for Structured Compression](https://arxiv.org/abs/2511.06786)
*Boyang Zhang,Daning Cheng,Yunquan Zhang*

Main category: cs.LG

TL;DR: 本文提出Geo-Sharing方法，从群论角度重新定义参数共享，通过二阶几何准则系统性地选择跨层共享组，在保持性能的同时实现高效模型压缩。


<details>
  <summary>Details</summary>
Motivation: 现代深度模型参数量巨大导致推理时内存占用高，限制了实际部署。现有参数共享方法局限于相邻层且缺乏系统性分析，跨层共享面临指数级增长的配置空间搜索难题。

Method: 将参数共享视为在模型参数空间中引入结构对称性，提出基于泰勒展开和海森矩阵谱的二阶几何准则，通过将扰动投影到低曲率特征子空间来选择共享组。

Result: 在多种架构和任务上，Geo-Sharing持续优于最先进的启发式共享策略，在更高压缩比下实现更小的精度损失。

Conclusion: Geo-Sharing提供了一种原则性且可扩展的配置程序，通过系统性分析跨层共享有效解决了模型压缩中的配置空间搜索瓶颈。

Abstract: Modern deep models have massive parameter sizes, leading to high
inference-time memory usage that limits practical deployment. Parameter
sharing, a form of structured compression, effectively reduces redundancy, but
existing approaches remain heuristic-restricted to adjacent layers and lacking
a systematic analysis for cross-layer sharing. However, extending sharing
across multiple layers leads to an exponentially expanding configuration space,
making exhaustive search computationally infeasible and forming a critical
bottleneck for parameter sharing. We recast parameter sharing from a
group-theoretic perspective as introducing structural symmetries in the model's
parameter space. A sharing configuration can be described by a coloring
function $\alpha:L\rightarrow C$ (L: layer indices and C: sharing classes),
which determines inter-layer sharing groups while preserving structural
symmetry. To determine the coloring function, we propose a second-order
geometric criterion based on Taylor expansion and the Hessian spectrum. By
projecting perturbations onto the Hessian's low-curvature eigensubspace, the
criterion provides an analytic rule for selecting sharing groups that minimize
performance impact, yielding a principled and scalable configuration procedure.
Across diverse architectures and tasks, Geo-Sharing consistently outperforms
state-of-the-art heuristic sharing strategies, achieving higher compression
ratios with smaller accuracy degradation.

</details>


### [344] [Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal Large Language Models](https://arxiv.org/abs/2511.06793)
*Kunhao Li,Wenhao Li,Di Wu,Lei Yang,Jun Bai,Ju Jia,Jason Xue*

Main category: cs.LG

TL;DR: 本文提出了一种多模态影响神经元路径编辑器（MIP-Editor），用于解决多模态大语言模型在机器遗忘任务中的挑战，通过模态特定的归因分数识别影响神经元路径，并应用表示重定向实现协调遗忘。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在现实应用中存在隐私泄露、毒性缓解和知识产权侵权等风险，现有基于神经元编辑的机器遗忘方法在多模态场景下面临遗忘不一致和通用知识性能下降的问题。

Method: 提出MIP-Editor方法，引入模态特定的归因分数来识别编码遗忘集知识的影响神经元路径，并通过表示重定向进行影响路径感知的神经元编辑。

Result: 在多模态任务中达到最高87.75%的遗忘率和54.26%的通用知识保留改进；在文本任务中达到80.65%的遗忘率和77.9%的通用性能保留。

Conclusion: MIP-Editor在多模态机器遗忘任务中表现出优越性能，能够实现跨模态的有效协调遗忘，同时保持模型的通用能力。

Abstract: Multimodal Large Language Models (MLLMs) extend foundation models to
real-world applications by integrating inputs such as text and vision. However,
their broad knowledge capacity raises growing concerns about privacy leakage,
toxicity mitigation, and intellectual property violations. Machine Unlearning
(MU) offers a practical solution by selectively forgetting targeted knowledge
while preserving overall model utility. When applied to MLLMs, existing
neuron-editing-based MU approaches face two fundamental challenges: (1)
forgetting becomes inconsistent across modalities because existing point-wise
attribution methods fail to capture the structured, layer-by-layer information
flow that connects different modalities; and (2) general knowledge performance
declines when sensitive neurons that also support important reasoning paths are
pruned, as this disrupts the model's ability to generalize. To alleviate these
limitations, we propose a multimodal influential neuron path editor
(MIP-Editor) for MU. Our approach introduces modality-specific attribution
scores to identify influential neuron paths responsible for encoding forget-set
knowledge and applies influential-path-aware neuron-editing via representation
misdirection. This strategy also enables effective and coordinated forgetting
across modalities while preserving the model's general capabilities.
Experimental results demonstrate that MIP-Editor achieves a superior unlearning
performance on multimodal tasks, with a maximum forgetting rate of 87.75% and
up to 54.26% improvement in general knowledge retention. On textual tasks,
MIP-Editor achieves up to 80.65% forgetting and preserves 77.9% of general
performance. Codes are available at https://github.com/PreckLi/MIP-Editor.

</details>


### [345] [Beyond Uniform Deletion: A Data Value-Weighted Framework for Certified Machine Unlearning](https://arxiv.org/abs/2511.06794)
*Lisong He,Yi Yang,Xiangyu Chang*

Main category: cs.LG

TL;DR: 提出了数据价值加权遗忘框架DVWU，通过考虑数据点的异质性价值来改进机器学习遗忘算法，相比传统方法获得更好的预测性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘算法忽视了不同数据点对模型性能的贡献差异，平等对待所有数据点会导致更新后模型性能下降。

Method: 设计基于数据价值的加权策略，集成到遗忘过程中，实现差异化遗忘。以一步牛顿更新为例，开发输出和目标扰动算法实现认证遗忘。

Result: 在合成和真实数据集上的实验表明，该方法相比传统遗忘方法具有更优的预测性能和鲁棒性。

Conclusion: DVWU框架可广泛适应现有机器学习遗忘方法，通过考虑数据价值异质性显著提升遗忘后模型性能。

Abstract: As the right to be forgotten becomes legislated worldwide, machine unlearning
mechanisms have emerged to efficiently update models for data deletion and
enhance user privacy protection. However, existing machine unlearning
algorithms frequently neglect the fact that different data points may
contribute unequally to model performance (i.e., heterogeneous data values).
Treat them equally in machine unlearning procedure can potentially degrading
the performance of updated models. To address this limitation, we propose Data
Value-Weighted Unlearning (DVWU), a general unlearning framework that accounts
for data value heterogeneity into the unlearning process. Specifically, we
design a weighting strategy based on data values, which are then integrated
into the unlearning procedure to enable differentiated unlearning for data
points with varying utility to the model. The DVWU framework can be broadly
adapted to various existing machine unlearning methods. We use the one-step
Newton update as an example for implementation, developing both output and
objective perturbation algorithms to achieve certified unlearning. Experiments
on both synthetic and real-world datasets demonstrate that our methods achieve
superior predictive performance and robustness compared to conventional
unlearning approaches. We further show the extensibility of our framework on
gradient ascent method by incorporating the proposed weighting strategy into
the gradient terms, highlighting the adaptability of DVWU for broader
gradient-based deep unlearning methods.

</details>


### [346] [Controllable Flow Matching for Online Reinforcement Learning](https://arxiv.org/abs/2511.06816)
*Bin Wang,Boxiang Tao,Haifeng Jing,Hongbo Dou,Zijian Wang*

Main category: cs.LG

TL;DR: CtrlFlow是一种基于条件流匹配的轨迹级合成方法，直接建模从初始状态到高回报终端状态的轨迹分布，无需显式建模环境转移函数，解决了传统基于模型的强化学习中模型误差累积的问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的强化学习方法依赖环境动态建模，但由于模型误差在长时程推演中的累积，常常面临建模稳定性挑战。

Method: 使用条件流匹配直接建模轨迹分布，通过最小化由非线性可控性格拉姆矩阵控制的控制能量来确保最优轨迹采样。

Result: 在MuJoCo基准任务上，CtrlFlow比动态模型表现更好，相比标准MBRL方法实现了更优的样本效率。

Conclusion: CtrlFlow生成的多样化轨迹数据显著增强了策略学习的鲁棒性和跨任务泛化能力。

Abstract: Model-based reinforcement learning (MBRL) typically relies on modeling
environment dynamics for data efficiency. However, due to the accumulation of
model errors over long-horizon rollouts, such methods often face challenges in
maintaining modeling stability. To address this, we propose CtrlFlow, a
trajectory-level synthetic method using conditional flow matching (CFM), which
directly modeling the distribution of trajectories from initial states to
high-return terminal states without explicitly modeling the environment
transition function. Our method ensures optimal trajectory sampling by
minimizing the control energy governed by the non-linear Controllability
Gramian Matrix, while the generated diverse trajectory data significantly
enhances the robustness and cross-task generalization of policy learning. In
online settings, CtrlFlow demonstrates the better performance on common MuJoCo
benchmark tasks than dynamics models and achieves superior sample efficiency
compared to standard MBRL methods.

</details>


### [347] [MI-to-Mid Distilled Compression (M2M-DC): An Hybrid-Information-Guided-Block Pruning with Progressive Inner Slicing Approach to Model Compression](https://arxiv.org/abs/2511.06842)
*Lionel Levine,Sajjad Ghiasvand,Haniyeh Ehsani Oskouie,Majid Sarrafzadeh*

Main category: cs.LG

TL;DR: M2M-DC是一种两尺度、形状安全的压缩框架，通过信息引导的块剪枝与渐进式内部切片和分阶段知识蒸馏相结合，实现模型压缩。


<details>
  <summary>Details</summary>
Motivation: 开发一个通用的压缩框架，能够在保持残差形状不变性的同时，显著减少模型参数和计算量，实现部署就绪的紧凑模型。

Method: 采用两阶段方法：首先基于标签感知互信息对残差块进行排序并剪枝，然后交替进行短知识蒸馏阶段与阶段一致的残差安全通道切片。

Result: 在CIFAR-100上，ResNet-18达到85.46%准确率（3.09M参数，0.0139 GMacs），ResNet-34达到85.02%准确率（5.46M参数，0.0195 GMacs），MobileNetV2提升2.5个百分点达到68.54%准确率。

Conclusion: M2M-DC提供了一个紧凑实用的压缩方案，能够在显著减少计算量的同时匹配或超越教师模型的准确率，并适用于各种残差CNN架构。

Abstract: We introduce MI-to-Mid Distilled Compression (M2M-DC), a two-scale,
shape-safe compression framework that interleaves information-guided block
pruning with progressive inner slicing and staged knowledge distillation (KD).
First, M2M-DC ranks residual (or inverted-residual) blocks by a label-aware
mutual information (MI) signal and removes the least informative units
(structured prune-after-training). It then alternates short KD phases with
stage-coherent, residual-safe channel slicing: (i) stage "planes" (co-slicing
conv2 out-channels with the downsample path and next-stage inputs), and (ii) an
optional mid-channel trim (conv1 out / bn1 / conv2 in). This targets
complementary redundancy, whole computational motifs and within-stage width
while preserving residual shape invariants. On CIFAR-100, M2M-DC yields a clean
accuracy-compute frontier. For ResNet-18, we obtain 85.46% Top-1 with 3.09M
parameters and 0.0139 GMacs (72% params, 63% GMacs vs. teacher; mean final
85.29% over three seeds). For ResNet-34, we reach 85.02% Top-1 with 5.46M
params and 0.0195 GMacs (74% / 74% vs. teacher; mean final 84.62%). Extending
to inverted-residuals, MobileNetV2 achieves a mean final 68.54% Top-1 at 1.71M
params (27%) and 0.0186 conv GMacs (24%), improving over the teacher's 66.03%
by +2.5 points across three seeds. Because M2M-DC exposes only a thin,
architecture-aware interface (blocks, stages, and down sample/skip wiring), it
generalizes across residual CNNs and extends to inverted-residual families with
minor legalization rules. The result is a compact, practical recipe for
deployment-ready models that match or surpass teacher accuracy at a fraction of
the compute.

</details>


### [348] [Beyond Observations: Reconstruction Error-Guided Irregularly Sampled Time Series Representation Learning](https://arxiv.org/abs/2511.06854)
*Jiexi Liu,Meng Cao,Songcan Chen*

Main category: cs.LG

TL;DR: iTimER是一个用于不规则采样时间序列表示学习的自监督预训练框架，通过建模重构误差分布和生成伪观测值来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖观测值来插补缺失值或推断潜在动态，但忽略了重构误差这一重要的学习信号，该误差反映了模型对数据结构的捕捉能力。

Method: iTimER建模观测值的重构误差分布，通过混合采样误差和最后可用观测值生成伪观测值，使用Wasserstein度量对齐重构误差分布，并结合对比学习目标增强表示区分性。

Result: 在分类、插值和预测任务上的大量实验表明，iTimER在不规则采样时间序列设置下持续优于最先进方法。

Conclusion: iTimER通过利用重构误差作为学习信号，有效提升了不规则采样时间序列的表示学习性能，在各种下游任务中表现出色。

Abstract: Irregularly sampled time series (ISTS), characterized by non-uniform time
intervals with natural missingness, are prevalent in real-world applications.
Existing approaches for ISTS modeling primarily rely on observed values to
impute unobserved ones or infer latent dynamics. However, these methods
overlook a critical source of learning signal: the reconstruction error
inherently produced during model training. Such error implicitly reflects how
well a model captures the underlying data structure and can serve as an
informative proxy for unobserved values. To exploit this insight, we propose
iTimER, a simple yet effective self-supervised pre-training framework for ISTS
representation learning. iTimER models the distribution of reconstruction
errors over observed values and generates pseudo-observations for unobserved
timestamps through a mixup strategy between sampled errors and the last
available observations. This transforms unobserved timestamps into noise-aware
training targets, enabling meaningful reconstruction signals. A Wasserstein
metric aligns reconstruction error distributions between observed and
pseudo-observed regions, while a contrastive learning objective enhances the
discriminability of learned representations. Extensive experiments on
classification, interpolation, and forecasting tasks demonstrate that iTimER
consistently outperforms state-of-the-art methods under the ISTS setting.

</details>


### [349] [Contact Wasserstein Geodesics for Non-Conservative Schrodinger Bridges](https://arxiv.org/abs/2511.06856)
*Andrea Testa,Soren Hauberg,Tamim Asfour,Leonel Rozo*

Main category: cs.LG

TL;DR: 本文提出了非保守广义薛定谔桥（NCGSB），这是一种基于接触哈密顿力学的新型能量变化重构方法，克服了传统薛定谔桥的能量守恒限制，能够建模能量变化的随机过程。


<details>
  <summary>Details</summary>
Motivation: 传统薛定谔桥受限于能量守恒假设，无法建模能量变化的现实随机过程，限制了桥梁形状和中间动力学的丰富性。

Method: 通过参数化Wasserstein流形，将桥梁问题提升到有限维空间中的可处理测地线计算，使用接触Wasserstein测地线（CWG）方法，通过ResNet架构实现非迭代求解器。

Result: NCGSB能够捕捉更丰富和真实的中间动力学，CWG具有近线性复杂度，支持通过调节任务特定距离度量进行引导生成。

Conclusion: 该框架在流形导航、分子动力学预测和图像生成等任务中验证了其实际优势和多功能性，为建模能量变化的随机过程提供了更强大的工具。

Abstract: The Schr\"odinger Bridge provides a principled framework for modeling
stochastic processes between distributions; however, existing methods are
limited by energy-conservation assumptions, which constrains the bridge's shape
preventing it from model varying-energy phenomena. To overcome this, we
introduce the non-conservative generalized Schr\"odinger bridge (NCGSB), a
novel, energy-varying reformulation based on contact Hamiltonian mechanics. By
allowing energy to change over time, the NCGSB provides a broader class of
real-world stochastic processes, capturing richer and more faithful
intermediate dynamics. By parameterizing the Wasserstein manifold, we lift the
bridge problem to a tractable geodesic computation in a finite-dimensional
space. Unlike computationally expensive iterative solutions, our contact
Wasserstein geodesic (CWG) is naturally implemented via a ResNet architecture
and relies on a non-iterative solver with near-linear complexity. Furthermore,
CWG supports guided generation by modulating a task-specific distance metric.
We validate our framework on tasks including manifold navigation, molecular
dynamics predictions, and image generation, demonstrating its practical
benefits and versatility.

</details>


### [350] [TuckA: Hierarchical Compact Tensor Experts for Efficient Fine-Tuning](https://arxiv.org/abs/2511.06859)
*Qifeng Lei,Zhiyong Yang,Qianqian Xu,Cong Hua,Peisong Wen,Qingming Huang*

Main category: cs.LG

TL;DR: 本文提出Tucker Adaptation (TuckA)方法，通过Tucker分解创建紧凑的3D张量，每个切片作为专家，结合分层策略和高效路由机制，实现参数高效微调。


<details>
  <summary>Details</summary>
Motivation: 传统参数高效微调方法依赖单一专家，无法充分捕捉复杂任务中数据的多样性特征，需要集成多个小适应专家来替代大型适配器。

Method: 使用Tucker分解创建3D专家张量，采用分层组织策略，开发批量级路由机制，并提出数据感知初始化实现专家负载均衡。

Result: 在自然语言理解、图像分类和数学推理等基准测试中表现出色，验证了TuckA方法的有效性。

Conclusion: TuckA为参数高效微调问题提供了新的有效解决方案，能够高效处理复杂任务中的数据多样性挑战。

Abstract: Efficiently fine-tuning pre-trained models for downstream tasks is a key
challenge in the era of foundation models. Parameter-efficient fine-tuning
(PEFT) presents a promising solution, achieving performance comparable to full
fine-tuning by updating only a small number of adaptation weights per layer.
Traditional PEFT methods typically rely on a single expert, where the
adaptation weight is a low-rank matrix. However, for complex tasks, the data's
inherent diversity poses a significant challenge for such models, as a single
adaptation weight cannot adequately capture the features of all samples. To
address this limitation, we explore how to integrate multiple small adaptation
experts into a compact structure to defeat a large adapter. Specifically, we
propose Tucker Adaptation (TuckA), a method with four key properties: (i) We
use Tucker decomposition to create a compact 3D tensor where each slice
naturally serves as an expert. The low-rank nature of this decomposition
ensures that the number of parameters scales efficiently as more experts are
added. (ii) We introduce a hierarchical strategy that organizes these experts
into groups at different granularities, allowing the model to capture both
local and global data patterns. (iii) We develop an efficient batch-level
routing mechanism, which reduces the router's parameter size by a factor of $L$
compared to routing at every adapted layer (where $L$ is the number of adapted
layers) (iv) We propose data-aware initialization to achieve loss-free expert
load balancing based on theoretical analysis. Extensive experiments on
benchmarks in natural language understanding, image classification, and
mathematical reasoning speak to the efficacy of TuckA, offering a new and
effective solution to the PEFT problem.

</details>


### [351] [DeepBooTS: Dual-Stream Residual Boosting for Drift-Resilient Time-Series Forecasting](https://arxiv.org/abs/2511.06893)
*Daojun Liang,Jing Chen,Xiao Wang,Yinglong Wang,Suo Li*

Main category: cs.LG

TL;DR: DeepBooTS是一种新颖的端到端双流残差递减提升方法，通过逐块重建内在信号来应对时间序列的非平稳性和概念漂移问题。


<details>
  <summary>Details</summary>
Motivation: 时间序列表现出明显的非平稳性，大多数预测方法对概念漂移的鲁棒性较差，尽管普遍应用了实例归一化。

Method: 通过偏差-方差分析概念漂移，提出加权集成方法。DeepBooTS采用双流残差递减提升架构，每个块成为学习器的集成，具有辅助输出分支形成到最终预测的高速通道，逐块输出校正前一个块的残差。

Result: 在大规模数据集上的广泛实验表明，该方法大幅优于现有方法，在各种数据集上平均性能提升15.8%。

Conclusion: 该方法建立了时间序列预测的新基准，显著提高了对概念漂移的鲁棒性，同时增强了多功能性和可解释性。

Abstract: Time-Series (TS) exhibits pronounced non-stationarity. Consequently, most
forecasting methods display compromised robustness to concept drift, despite
the prevalent application of instance normalization. We tackle this challenge
by first analysing concept drift through a bias-variance lens and proving that
weighted ensemble reduces variance without increasing bias. These insights
motivate DeepBooTS, a novel end-to-end dual-stream residual-decreasing boosting
method that progressively reconstructs the intrinsic signal. In our design,
each block of a deep model becomes an ensemble of learners with an auxiliary
output branch forming a highway to the final prediction. The block-wise outputs
correct the residuals of previous blocks, leading to a learning-driven
decomposition of both inputs and targets. This method enhances versatility and
interpretability while substantially improving robustness to concept drift.
Extensive experiments, including those on large-scale datasets, show that the
proposed method outperforms existing methods by a large margin, yielding an
average performance improvement of 15.8% across various datasets, establishing
a new benchmark for TS forecasting.

</details>


### [352] [COGNOS: Universal Enhancement for Time Series Anomaly Detection via Constrained Gaussian-Noise Optimization and Smoothing](https://arxiv.org/abs/2511.06894)
*Wenlong Shang,Peng Chang*

Main category: cs.LG

TL;DR: COGNOS提出了一种通用框架，通过高斯白噪声正则化和卡尔曼平滑后处理，解决了基于重构的时间序列异常检测方法中MSE损失导致的统计缺陷问题，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于重构的时间序列异常检测方法普遍依赖MSE损失，导致重构残差存在统计缺陷，产生噪声大、不稳定的异常分数，影响检测可靠性。

Method: COGNOS包含两个核心组件：1）高斯白噪声正则化策略，在训练时约束模型输出残差符合高斯白噪声分布；2）卡尔曼平滑后处理器，作为统计最优估计器对原始异常分数进行去噪。

Result: 在多个真实世界基准数据集上对12种不同骨干模型进行广泛实验，COGNOS平均F分数提升了57.9%，证明其高度有效性。

Conclusion: 直接正则化输出统计特性是显著改进异常检测系统的强大且可泛化的策略。

Abstract: Reconstruction-based methods are a dominant paradigm in time series anomaly
detection (TSAD), however, their near-universal reliance on Mean Squared Error
(MSE) loss results in statistically flawed reconstruction residuals. This
fundamental weakness leads to noisy, unstable anomaly scores with a poor
signal-to-noise ratio, hindering reliable detection. To address this, we
propose Constrained Gaussian-Noise Optimization and Smoothing (COGNOS), a
universal, model-agnostic enhancement framework that tackles this issue at its
source. COGNOS introduces a novel Gaussian-White Noise Regularization strategy
during training, which directly constrains the model's output residuals to
conform to a Gaussian white noise distribution. This engineered statistical
property creates the ideal precondition for our second contribution: a Kalman
Smoothing Post-processor that provably operates as a statistically optimal
estimator to denoise the raw anomaly scores. The synergy between these two
components allows COGNOS to robustly separate the true anomaly signal from
random fluctuations. Extensive experiments demonstrate that COGNOS is highly
effective, delivering an average F-score uplift of 57.9% when applied to 12
diverse backbone models across multiple real-world benchmark datasets. Our work
reveals that directly regularizing output statistics is a powerful and
generalizable strategy for significantly improving anomaly detection systems.

</details>


### [353] [On The Presence of Double-Descent in Deep Reinforcement Learning](https://arxiv.org/abs/2511.06895)
*Viktor Veselý,Aleksandar Todorov,Matthia Sabatelli*

Main category: cs.LG

TL;DR: 本文初步证明了在深度强化学习中存在双下降现象，发现当模型容量超过插值点时泛化性能会改善，且与策略熵的持续显著减少相关。


<details>
  <summary>Details</summary>
Motivation: 双下降悖论在非平稳的深度强化学习领域尚未被充分探索，本文旨在研究模型无关深度强化学习中是否存在这一现象。

Method: 使用Actor-Critic框架，在不同模型容量下系统研究双下降现象，并采用信息论指标策略熵来衡量训练过程中的策略不确定性。

Result: 初步结果显示存在明显的epoch-wise双下降曲线，策略进入第二下降区域与策略熵的持续显著减少相关，表明过参数化起到了隐式正则化作用。

Conclusion: 这些发现确立了双下降在深度强化学习中的存在，并为设计更通用、可迁移和鲁棒的智能体提供了基于信息的机制。

Abstract: The double descent (DD) paradox, where over-parameterized models see
generalization improve past the interpolation point, remains largely unexplored
in the non-stationary domain of Deep Reinforcement Learning (DRL). We present
preliminary evidence that DD exists in model-free DRL, investigating it
systematically across varying model capacity using the Actor-Critic framework.
We rely on an information-theoretic metric, Policy Entropy, to measure policy
uncertainty throughout training. Preliminary results show a clear epoch-wise DD
curve; the policy's entrance into the second descent region correlates with a
sustained, significant reduction in Policy Entropy. This entropic decay
suggests that over-parameterization acts as an implicit regularizer, guiding
the policy towards robust, flatter minima in the loss landscape. These findings
establish DD as a factor in DRL and provide an information-based mechanism for
designing agents that are more general, transferable, and robust.

</details>


### [354] [Counterfactual Explanation for Multivariate Time Series Forecasting with Exogenous Variables](https://arxiv.org/abs/2511.06906)
*Keita Kinjo*

Main category: cs.LG

TL;DR: 本文提出了一种使用外生变量为时间序列预测生成反事实解释的方法，解决了机器学习模型在时间序列分析中的可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习在时间序列数据分析中广泛应用，但许多模型是黑箱，缺乏可解释性。反事实解释是解决这一问题的关键方法，但在时间序列预测领域的应用相对较少。

Method: 提出基于外生变量提取时间序列预测反事实解释的方法，包括分析各变量对整个时间序列的影响、仅改变特定变量生成反事实解释，以及评估生成解释的质量。

Result: 通过理论分析和实证实验验证了所提方法的准确性和实际适用性。

Conclusion: 该方法能够支持基于时间序列数据分析的实际决策制定，在商业和营销等领域具有实用价值。

Abstract: Currently, machine learning is widely used across various domains, including
time series data analysis. However, some machine learning models function as
black boxes, making interpretability a critical concern. One approach to
address this issue is counterfactual explanation (CE), which aims to provide
insights into model predictions. This study focuses on the relatively
underexplored problem of generating counterfactual explanations for time series
forecasting. We propose a method for extracting CEs in time series forecasting
using exogenous variables, which are frequently encountered in fields such as
business and marketing. In addition, we present methods for analyzing the
influence of each variable over an entire time series, generating CEs by
altering only specific variables, and evaluating the quality of the resulting
CEs. We validate the proposed method through theoretical analysis and empirical
experiments, showcasing its accuracy and practical applicability. These
contributions are expected to support real-world decision-making based on time
series data analysis.

</details>


### [355] [Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning](https://arxiv.org/abs/2511.06946)
*Daniel De Dios Allegue,Jinke He,Frans A. Oliehoek*

Main category: cs.LG

TL;DR: 本文提出在Transformer自注意力机制中引入结构化归纳先验，包括每头记忆长度先验和分布先验，以改进部分可观测环境下基于模型的强化学习中的世界建模效率。


<details>
  <summary>Details</summary>
Motivation: 标准自注意力机制在RL轨迹中效率低下，因为它均匀分配权重给所有历史标记，而不是强调对控制至关重要的少数关键转换。RL轨迹具有稀疏性和奖励驱动特性，需要更有效的注意力机制。

Method: 在动态头部的自注意力机制中引入两种结构化归纳先验：(i) 每头记忆长度先验，将注意力限制在任务特定窗口内；(ii) 分布先验，学习对过去状态-动作对的平滑高斯加权。

Result: 在Atari 100k基准测试中，高斯先验实现了77%的相对改进，而记忆长度先验往往因过度限制的截断而削弱有用信号。高斯注意力能平滑分配注意力到信息丰富的转换。

Conclusion: 在具有非平稳时间依赖性的部分可观测RL领域，离散记忆窗口难以可靠学习，而平滑分布先验能灵活适应不同时间范围并产生更稳健的数据效率。将结构化时间先验直接编码到自注意力中能改善部分可观测性下动态建模的信息历史优先级。

Abstract: Transformers have shown strong ability to model long-term dependencies and
are increasingly adopted as world models in model-based reinforcement learning
(RL) under partial observability. However, unlike natural language corpora, RL
trajectories are sparse and reward-driven, making standard self-attention
inefficient because it distributes weight uniformly across all past tokens
rather than emphasizing the few transitions critical for control. To address
this, we introduce structured inductive priors into the self-attention
mechanism of the dynamics head: (i) per-head memory-length priors that
constrain attention to task-specific windows, and (ii) distributional priors
that learn smooth Gaussian weightings over past state-action pairs. We
integrate these mechanisms into UniZero, a model-based RL agent with a
Transformer-based world model that supports planning under partial
observability. Experiments on the Atari 100k benchmark show that most
efficiency gains arise from the Gaussian prior, which smoothly allocates
attention to informative transitions, while memory-length priors often truncate
useful signals with overly restrictive cut-offs. In particular, Gaussian
Attention achieves a 77% relative improvement in mean human-normalized scores
over UniZero. These findings suggest that in partially observable RL domains
with non-stationary temporal dependencies, discrete memory windows are
difficult to learn reliably, whereas smooth distributional priors flexibly
adapt across horizons and yield more robust data efficiency. Overall, our
results demonstrate that encoding structured temporal priors directly into
self-attention improves the prioritization of informative histories for
dynamics modeling under partial observability.

</details>


### [356] [Oh That Looks Familiar: A Novel Similarity Measure for Spreadsheet Template Discovery](https://arxiv.org/abs/2511.06973)
*Ananad Krishnakumar,Vengadesh Ravikumaran*

Main category: cs.LG

TL;DR: 提出了一种结合语义嵌入、数据类型和空间位置的混合距离度量方法，用于量化电子表格的结构相似性，相比传统方法能更好地捕捉模板的空间布局和类型模式。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法有效识别电子表格的结构相似性，特别是无法捕捉定义模板的空间布局和类型模式，因此需要开发新的相似性度量方法。

Method: 将电子表格转换为单元格级嵌入，然后使用Chamfer和Hausdorff距离等聚合技术计算相似性，结合语义嵌入、数据类型信息和空间定位。

Result: 在FUSTE数据集上实现了完美的模板重建（调整兰德指数1.00 vs 0.90），相比基于图的Mondrian基线方法在无监督聚类性能上表现更优。

Conclusion: 该方法支持大规模自动化模板发现，为表格集合的检索增强生成、模型训练和批量数据清理等下游应用提供了基础。

Abstract: Traditional methods for identifying structurally similar spreadsheets fail to
capture the spatial layouts and type patterns defining templates. To quantify
spreadsheet similarity, we introduce a hybrid distance metric that combines
semantic embeddings, data type information, and spatial positioning. In order
to calculate spreadsheet similarity, our method converts spreadsheets into
cell-level embeddings and then uses aggregation techniques like Chamfer and
Hausdorff distances. Experiments across template families demonstrate superior
unsupervised clustering performance compared to the graph-based Mondrian
baseline, achieving perfect template reconstruction (Adjusted Rand Index of
1.00 versus 0.90) on the FUSTE dataset. Our approach facilitates large-scale
automated template discovery, which in turn enables downstream applications
such as retrieval-augmented generation over tabular collections, model
training, and bulk data cleaning.

</details>


### [357] [Rethinking Crystal Symmetry Prediction: A Decoupled Perspective](https://arxiv.org/abs/2511.06976)
*Liheng Yu,Zhe Zhao,Xucong Wang,Di Wu,Pengkun Wang*

Main category: cs.LG

TL;DR: XRDecoupler框架通过解耦视角解决晶体对称性分析中的子属性混淆问题，结合多维晶体对称信息作为超类指导，设计分层PXRD模式学习模型和多目标优化方法，在多个主流数据库上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有晶体对称性分析方法盲目应用深度学习模型而忽略化学规则，面临严重的子属性混淆问题，需要开发更符合化学直觉的解决方案。

Method: 采用解耦视角，引入多维晶体对称信息作为超类指导，设计分层PXRD模式学习模型和多目标优化方法，确保模型预测过程符合化学直觉。

Result: 在CCDC、CoREMOF和InorganicData三个主流数据库上的综合评估表明，XRDecoupler在性能、可解释性和泛化能力方面表现优异。

Conclusion: XRDecoupler框架通过结合化学直觉和深度学习，有效解决了晶体对称性分析中的子属性混淆问题，为结构分析提供了高效准确的解决方案。

Abstract: Efficiently and accurately determining the symmetry is a crucial step in the
structural analysis of crystalline materials. Existing methods usually
mindlessly apply deep learning models while ignoring the underlying chemical
rules. More importantly, experiments show that they face a serious sub-property
confusion SPC problem. To address the above challenges, from a decoupled
perspective, we introduce the XRDecoupler framework, a problem-solving arsenal
specifically designed to tackle the SPC problem. Imitating the thinking process
of chemists, we innovatively incorporate multidimensional crystal symmetry
information as superclass guidance to ensure that the model's prediction
process aligns with chemical intuition. We further design a hierarchical PXRD
pattern learning model and a multi-objective optimization approach to achieve
high-quality representation and balanced optimization. Comprehensive
evaluations on three mainstream databases (e.g., CCDC, CoREMOF, and
InorganicData) demonstrate that XRDecoupler excels in performance,
interpretability, and generalization.

</details>


### [358] [CoLM: Collaborative Large Models via A Client-Server Paradigm](https://arxiv.org/abs/2511.06991)
*Siqi Huang,Sida Huang,Hongyuan Zhang*

Main category: cs.LG

TL;DR: CoLM是一个从客户端-服务器视角重新定义大模型协作的新框架，通过聚合多个模型的输出来让每个客户端模型独立优化自身生成，在多个基准测试中显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型协作方法采用服务器到服务器范式，与实际部署场景不匹配。实际部署中服务器端模型数量有限，需要服务大量客户端。

Method: CoLM框架允许多个模型的输出被聚合或共享，使每个客户端模型能够基于这些高质量输出独立优化和更新自身生成，充分利用客户端和共享服务器端模型。

Result: 实验结果表明，CoLM在多个基准测试中持续改进模型在先前失败查询上的性能，证明了协作指导在增强单模型能力方面的有效性。

Conclusion: CoLM框架通过客户端-服务器视角的协作推理，有效提升了单模型能力，并成功扩展到视觉语言模型领域。

Abstract: Large models have achieved remarkable performance across a range of reasoning
and understanding tasks. Prior work often utilizes model ensembles or
multi-agent systems to collaboratively generate responses, effectively
operating in a server-to-server paradigm. However, such approaches do not align
well with practical deployment settings, where a limited number of server-side
models are shared by many clients under modern internet architectures. In this
paper, we introduce \textbf{CoLM} (\textbf{Co}llaboration in
\textbf{L}arge-\textbf{M}odels), a novel framework for collaborative reasoning
that redefines cooperation among large models from a client-server perspective.
Unlike traditional ensemble methods that rely on simultaneous inference from
multiple models to produce a single output, CoLM allows the outputs of multiple
models to be aggregated or shared, enabling each client model to independently
refine and update its own generation based on these high-quality outputs. This
design enables collaborative benefits by fully leveraging both client-side and
shared server-side models. We further extend CoLM to vision-language models
(VLMs), demonstrating its applicability beyond language tasks. Experimental
results across multiple benchmarks show that CoLM consistently improves model
performance on previously failed queries, highlighting the effectiveness of
collaborative guidance in enhancing single-model capabilities.

</details>


### [359] [Correcting False Alarms from Unseen: Adapting Graph Anomaly Detectors at Test Time](https://arxiv.org/abs/2511.07023)
*Junjun Pan,Yixin Liu,Chuan Zhou,Fei Xiong,Alan Wee-Chung Liew,Shirui Pan*

Main category: cs.LG

TL;DR: 本文提出了TUNE框架，用于解决图异常检测中的分布偏移问题，通过测试时适应来校正未见正常模式。


<details>
  <summary>Details</summary>
Motivation: 现实场景中图异常检测模型面临训练和测试分布不一致的问题，特别是当部署过程中出现未见正常样本时，会导致性能下降。

Method: 提出轻量级即插即用测试时适应框架TUNE，使用图对齐器在属性层面对齐偏移数据，并利用表示层偏移最小化作为监督信号训练对齐器。

Result: 在10个真实世界数据集上的广泛实验表明，TUNE显著提升了预训练图异常检测模型对合成和真实未见正常模式的泛化能力。

Conclusion: TUNE框架有效解决了图异常检测中的分布偏移问题，无需重新训练即可提升模型在未见正常模式下的性能。

Abstract: Graph anomaly detection (GAD), which aims to detect outliers in
graph-structured data, has received increasing research attention recently.
However, existing GAD methods assume identical training and testing
distributions, which is rarely valid in practice. In real-world scenarios,
unseen but normal samples may emerge during deployment, leading to a normality
shift that degrades the performance of GAD models trained on the original data.
Through empirical analysis, we reveal that the degradation arises from (1)
semantic confusion, where unseen normal samples are misinterpreted as anomalies
due to their novel patterns, and (2) aggregation contamination, where the
representations of seen normal nodes are distorted by unseen normals through
message aggregation. While retraining or fine-tuning GAD models could be a
potential solution to the above challenges, the high cost of model retraining
and the difficulty of obtaining labeled data often render this approach
impractical in real-world applications. To bridge the gap, we proposed a
lightweight and plug-and-play Test-time adaptation framework for correcting
Unseen Normal pattErns (TUNE) in GAD. To address semantic confusion, a graph
aligner is employed to align the shifted data to the original one at the graph
attribute level. Moreover, we utilize the minimization of representation-level
shift as a supervision signal to train the aligner, which leverages the
estimated aggregation contamination as a key indicator of normality shift.
Extensive experiments on 10 real-world datasets demonstrate that TUNE
significantly enhances the generalizability of pre-trained GAD models to both
synthetic and real unseen normal patterns.

</details>


### [360] [Fair Bayesian Data Selection via Generalized Discrepancy Measures](https://arxiv.org/abs/2511.07032)
*Yixuan Zhang,Jiabin Luo,Zhenggang Wang,Feng Zhou,Quyu Kong*

Main category: cs.LG

TL;DR: 提出了一种贝叶斯数据选择框架，通过将模型参数和样本权重的组特定后验分布与共享中心分布对齐来确保公平性，支持多种分布差异度量，在公平性和准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在高风险应用中的部署，公平性问题日益关键。现有公平感知方法通常在模型层面干预，但存在计算成本高、可扩展性有限和泛化能力差的问题。

Method: 贝叶斯数据选择框架，通过将组特定后验分布与共享中心分布对齐来确保公平性，支持Wasserstein距离、最大均值差异和f-散度等多种分布差异度量方法。

Result: 在基准数据集上的实验表明，该方法在公平性和准确性方面持续优于现有的数据选择和基于模型的公平方法。

Conclusion: 这种以数据为中心的方法能够减轻训练数据中的组特定偏见，提高下游任务的公平性，并具有理论保证。

Abstract: Fairness concerns are increasingly critical as machine learning models are
deployed in high-stakes applications. While existing fairness-aware methods
typically intervene at the model level, they often suffer from high
computational costs, limited scalability, and poor generalization. To address
these challenges, we propose a Bayesian data selection framework that ensures
fairness by aligning group-specific posterior distributions of model parameters
and sample weights with a shared central distribution. Our framework supports
flexible alignment via various distributional discrepancy measures, including
Wasserstein distance, maximum mean discrepancy, and $f$-divergence, allowing
geometry-aware control without imposing explicit fairness constraints. This
data-centric approach mitigates group-specific biases in training data and
improves fairness in downstream tasks, with theoretical guarantees. Experiments
on benchmark datasets show that our method consistently outperforms existing
data selection and model-based fairness methods in both fairness and accuracy.

</details>


### [361] [Breaking Privacy in Federated Clustering: Perfect Input Reconstruction via Temporal Correlations](https://arxiv.org/abs/2511.07073)
*Guang Yang,Lixia Luo,Qiongxiu Li*

Main category: cs.LG

TL;DR: 本文研究了联邦聚类中中间质心披露的隐私风险，发现k-means迭代的时间规律性会泄露信息，并提出了一种能够完美重建原始输入的TAR攻击方法。


<details>
  <summary>Details</summary>
Motivation: 联邦聚类协议为了降低开销通常会披露中间质心，但之前的研究认为这种披露是安全的，因为传统的HSSP攻击无法恢复输入。本文旨在重新审视这种假设，探究质心披露是否真的会损害隐私。

Method: 基于k-means迭代中时间规律性的新泄漏机制，提出了轨迹感知重建（TAR）攻击方法，该方法结合时间分配信息和代数分析来恢复原始输入。

Result: TAR攻击能够完美重建原始输入，提供了第一个严谨的证据表明联邦聚类中的质心披露会显著损害隐私。

Conclusion: 研究揭示了联邦聚类中隐私与效率之间的根本矛盾，质心披露虽然提高了效率，但严重威胁了数据隐私。

Abstract: Federated clustering allows multiple parties to discover patterns in
distributed data without sharing raw samples. To reduce overhead, many
protocols disclose intermediate centroids during training. While often treated
as harmless for efficiency, whether such disclosure compromises privacy remains
an open question. Prior analyses modeled the problem as a so-called Hidden
Subset Sum Problem (HSSP) and argued that centroid release may be safe, since
classical HSSP attacks fail to recover inputs.
  We revisit this question and uncover a new leakage mechanism: temporal
regularities in $k$-means iterations create exploitable structure that enables
perfect input reconstruction. Building on this insight, we propose
Trajectory-Aware Reconstruction (TAR), an attack that combines temporal
assignment information with algebraic analysis to recover exact original
inputs. Our findings provide the first rigorous evidence, supported by a
practical attack, that centroid disclosure in federated clustering
significantly compromises privacy, exposing a fundamental tension between
privacy and efficiency.

</details>


### [362] [On the Joint Minimization of Regularization Loss Functions in Deep Variational Bayesian Methods for Attribute-Controlled Symbolic Music Generation](https://arxiv.org/abs/2511.07118)
*Matteo Pettenó,Alessandro Ilic Mezza,Alberto Bernardini*

Main category: cs.LG

TL;DR: 本文探讨了显式潜变量模型中KLD和AR损失平衡的问题，发现在符号音乐生成中，合适的属性变换可以同时实现可控性和潜空间正则化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平衡KLD和AR损失时面临困难：KLD主导时模型缺乏可控性，AR主导时编码器会违反标准正态先验。

Method: 在符号音乐生成背景下，通过属性变换来平衡KLD和AR损失，实现连续音乐属性的显式控制。

Result: 现有方法难以同时最小化两个正则化目标，而合适的属性变换有助于同时实现可控性和目标潜维度的正则化。

Conclusion: 合适的属性变换是解决KLD和AR损失平衡问题的有效方法，能够同时保证生成模型的可控性和潜空间的正则化约束。

Abstract: Explicit latent variable models provide a flexible yet powerful framework for
data synthesis, enabling controlled manipulation of generative factors. With
latent variables drawn from a tractable probability density function that can
be further constrained, these models enable continuous and semantically rich
exploration of the output space by navigating their latent spaces. Structured
latent representations are typically obtained through the joint minimization of
regularization loss functions. In variational information bottleneck models,
reconstruction loss and Kullback-Leibler Divergence (KLD) are often linearly
combined with an auxiliary Attribute-Regularization (AR) loss. However,
balancing KLD and AR turns out to be a very delicate matter. When KLD dominates
over AR, generative models tend to lack controllability; when AR dominates over
KLD, the stochastic encoder is encouraged to violate the standard normal prior.
We explore this trade-off in the context of symbolic music generation with
explicit control over continuous musical attributes. We show that existing
approaches struggle to jointly minimize both regularization objectives, whereas
suitable attribute transformations can help achieve both controllability and
regularization of the target latent dimensions.

</details>


### [363] [REACT-LLM: A Benchmark for Evaluating LLM Integration with Causal Features in Clinical Prognostic Tasks](https://arxiv.org/abs/2511.07127)
*Linna Wang,Zhixuan You,Qihui Zhang,Jiunan Wen,Ji Shi,Yimin Chen,Yusen Wang,Fanqi Ding,Ziliang Feng,Li Lu*

Main category: cs.LG

TL;DR: REACT-LLM是一个评估大语言模型与因果特征结合在临床风险预测中性能的基准测试，发现LLMs在临床预后方面表现尚可但尚未超越传统机器学习模型，因果特征的整合带来的性能提升有限。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估大语言模型与因果学习在临床决策中协同作用的基准测试，而识别对结果有因果影响的特征对于临床风险预测的可操作性和可信度至关重要。

Method: 引入REACT-LLM基准，评估7个临床结果和2个真实世界数据集，比较15个LLMs、6个传统ML模型和3个因果发现算法，研究因果特征与LLMs的整合效果。

Result: LLMs在临床预后方面表现合理但未超越传统ML模型；因果特征与LLMs的整合仅带来有限的性能提升，主要因为因果发现方法的严格假设在复杂临床数据中常被违反。

Conclusion: 虽然直接整合因果特征到LLMs中改进有限，但基准测试揭示了更有前景的协同作用，为未来研究指明了方向。

Abstract: Large Language Models (LLMs) and causal learning each hold strong potential
for clinical decision making (CDM). However, their synergy remains poorly
understood, largely due to the lack of systematic benchmarks evaluating their
integration in clinical risk prediction. In real-world healthcare, identifying
features with causal influence on outcomes is crucial for actionable and
trustworthy predictions. While recent work highlights LLMs' emerging causal
reasoning abilities, there lacks comprehensive benchmarks to assess their
causal learning and performance informed by causal features in clinical risk
prediction. To address this, we introduce REACT-LLM, a benchmark designed to
evaluate whether combining LLMs with causal features can enhance clinical
prognostic performance and potentially outperform traditional machine learning
(ML) methods. Unlike existing LLM-clinical benchmarks that often focus on a
limited set of outcomes, REACT-LLM evaluates 7 clinical outcomes across 2
real-world datasets, comparing 15 prominent LLMs, 6 traditional ML models, and
3 causal discovery (CD) algorithms. Our findings indicate that while LLMs
perform reasonably in clinical prognostics, they have not yet outperformed
traditional ML models. Integrating causal features derived from CD algorithms
into LLMs offers limited performance gains, primarily due to the strict
assumptions of many CD methods, which are often violated in complex clinical
data. While the direct integration yields limited improvement, our benchmark
reveals a more promising synergy.

</details>


### [364] [Guiding Generative Models to Uncover Diverse and Novel Crystals via Reinforcement Learning](https://arxiv.org/abs/2511.07158)
*Hyunsoo Park,Aron Walsh*

Main category: cs.LG

TL;DR: 本文提出了一种强化学习框架，通过引导潜在去噪扩散模型来发现多样且新颖但热力学可行的晶体化合物，解决了生成建模中基于似然采样与目标导向探索之间的不对齐问题。


<details>
  <summary>Details</summary>
Motivation: 当前生成人工智能在采样化学可行组成和结构方面取得进展，但面临基本挑战：生成建模中的基于似然采样与针对未探索区域（新颖化合物所在位置）的目标导向之间存在目标不对齐。

Method: 引入强化学习框架，将组相对策略优化与可验证的多目标奖励相结合，共同平衡创造性、稳定性和多样性。该方法还展示了增强的属性引导设计，在保持化学有效性的同时针对所需功能属性。

Result: 该方法能够引导潜在去噪扩散模型生成多样且新颖但热力学可行的晶体化合物，并在保持化学有效性的同时实现属性引导设计。

Conclusion: 该方法为可控AI驱动逆向设计建立了模块化基础，解决了生成模型在科学发现应用中的新颖性与有效性权衡问题。

Abstract: Discovering functional crystalline materials entails navigating an immense
combinatorial design space. While recent advances in generative artificial
intelligence have enabled the sampling of chemically plausible compositions and
structures, a fundamental challenge remains: the objective misalignment between
likelihood-based sampling in generative modelling and targeted focus on
underexplored regions where novel compounds reside. Here, we introduce a
reinforcement learning framework that guides latent denoising diffusion models
toward diverse and novel, yet thermodynamically viable crystalline compounds.
Our approach integrates group relative policy optimisation with verifiable,
multi-objective rewards that jointly balance creativity, stability, and
diversity. Beyond de novo generation, we demonstrate enhanced property-guided
design that preserves chemical validity, while targeting desired functional
properties. This approach establishes a modular foundation for controllable
AI-driven inverse design that addresses the novelty-validity trade-off across
scientific discovery applications of generative models.

</details>


### [365] [Fuzzy Label: From Concept to Its Application in Label Learning](https://arxiv.org/abs/2511.07165)
*Chenxi Luoa,Zhuangzhuang Zhaoa,Zhaohong Denga,Te Zhangb*

Main category: cs.LG

TL;DR: 本文提出基于模糊集理论的模糊标签概念，以更好地捕捉和表示标签不确定性，并开发了从原始数据挖掘生成模糊标签的高效方法，增强了单标签和多标签学习模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统标签学习方法使用二进制逻辑标签（如是/否），但在实际应用中标签标注存在显著不确定性，包括数据噪声、实体固有模糊性和标注者主观性。简化二进制逻辑会掩盖有价值信息并限制标签学习模型的表达能力。

Method: 提出基于模糊集理论的模糊标签概念；开发从原始数据挖掘生成模糊标签的高效方法；基于此提出模糊标签增强的单标签和多标签学习算法，以KNN和多标签KNN算法为例进行说明。

Result: 实验结果表明，模糊标签能更有效地表征真实世界标注信息，并显著提升标签学习模型的性能。

Conclusion: 模糊标签方法能够更好地处理标签不确定性，为标签学习提供了更丰富和细致的表示方式，显著改善了模型性能。

Abstract: Label learning is a fundamental task in machine learning that aims to
construct intelligent models using labeled data, encompassing traditional
single-label and multi-label classification models. Traditional methods
typically rely on logical labels, such as binary indicators (e.g., "yes/no")
that specify whether an instance belongs to a given category. However, in
practical applications, label annotations often involve significant uncertainty
due to factors such as data noise, inherent ambiguity in the observed entities,
and the subjectivity of human annotators. Therefore, representing labels using
simplistic binary logic can obscure valuable information and limit the
expressiveness of label learning models. To overcome this limitation, this
paper introduces the concept of fuzzy labels, grounded in fuzzy set theory, to
better capture and represent label uncertainty. We further propose an efficient
fuzzy labeling method that mines and generates fuzzy labels from the original
data, thereby enriching the label space with more informative and nuanced
representations. Based on this foundation, we present fuzzy-label-enhanced
algorithms for both single-label and multi-label learning, using the classical
K-Nearest Neighbors (KNN) and multi-label KNN algorithms as illustrative
examples. Experimental results indicate that fuzzy labels can more effectively
characterize the real-world labeling information and significantly enhance the
performance of label learning models.

</details>


### [366] [Synergy over Discrepancy: A Partition-Based Approach to Multi-Domain LLM Fine-Tuning](https://arxiv.org/abs/2511.07198)
*Hua Ye,Siyuan Chen,Haoliang Zhang,Weihao Luo,Yanbin Li,Xuan Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于分区的多阶段微调框架，通过平衡领域差异、协同效应和模型容量约束，将领域划分为子集，以利用领域间协同作用并最小化负迁移。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在跨多个异构领域时面临领域间干扰的挑战，需要有效利用领域间协同作用同时避免负迁移。

Method: 采用分区多阶段微调框架，通过理论分析推导泛化界限，并基于领域差异、协同效应和模型容量约束进行领域划分。

Result: 在各种语言理解任务上的广泛实证评估表明，该方法始终优于最先进的基线方法。

Conclusion: 所提出的分区多阶段微调框架能有效解决跨异构领域的适应问题，在理论和实证上都表现出优越性能。

Abstract: Large language models (LLMs) demonstrate impressive generalization abilities,
yet adapting them effectively across multiple heterogeneous domains remains
challenging due to inter-domain interference. To overcome this challenge, we
propose a partition-based multi-stage fine-tuning framework designed to exploit
inter-domain synergies while minimizing negative transfer. Our approach
strategically partitions domains into subsets (stages) by balancing domain
discrepancy, synergy, and model capacity constraints. We theoretically analyze
the proposed framework and derive novel generalization bounds that justify our
partitioning strategy. Extensive empirical evaluations on various language
understanding tasks show that our method consistently outperforms
state-of-the-art baselines.

</details>


### [367] [DETECT: Data-Driven Evaluation of Treatments Enabled by Classification Transformers](https://arxiv.org/abs/2511.07213)
*Yuanheng Mao,Lillian Yang,Stephen Yang,Ethan Shao,Zihan Li*

Main category: cs.LG

TL;DR: DETECT是一个数据驱动的框架，通过比较治疗前后患者日常生活活动来评估治疗效果，使用智能手机传感器数据和Transformer分类器，为临床决策提供客观轻量的评估方法。


<details>
  <summary>Details</summary>
Motivation: 慢性疼痛是全球健康挑战，传统的主观评估方法（如数字评分量表）存在局限性，需要更客观可靠的方法来测量临床治疗的功能影响。

Method: 提出DETECT框架，使用智能手机传感器数据，通过比较治疗前后患者日常生活活动，采用Transformer分类器进行数据驱动的治疗效果评估。

Result: 在公共基准数据集和模拟患者数据上的结果表明，DETECT是客观且轻量级的，能够显著改善临床决策。

Conclusion: DETECT可作为独立工具或与其他自报告指标结合使用，帮助医生更好地理解治疗效果，最终实现更个性化和响应性的患者护理。

Abstract: Chronic pain is a global health challenge affecting millions of individuals,
making it essential for physicians to have reliable and objective methods to
measure the functional impact of clinical treatments. Traditionally used
methods, like the numeric rating scale, while personalized and easy to use, are
subjective due to their self-reported nature. Thus, this paper proposes DETECT
(Data-Driven Evaluation of Treatments Enabled by Classification Transformers),
a data-driven framework that assesses treatment success by comparing patient
activities of daily life before and after treatment. We use DETECT on public
benchmark datasets and simulated patient data from smartphone sensors. Our
results demonstrate that DETECT is objective yet lightweight, making it a
significant and novel contribution to clinical decision-making. By using
DETECT, independently or together with other self-reported metrics, physicians
can improve their understanding of their treatment impacts, ultimately leading
to more personalized and responsive patient care.

</details>


### [368] [Does TabPFN Understand Causal Structures?](https://arxiv.org/abs/2511.07236)
*Omar Swelam,Lennart Purucker,Jake Robertson,Hanne Raum,Joschka Boedecker,Frank Hutter*

Main category: cs.LG

TL;DR: 本文研究TabPFN（基于transformer的表格基础模型）是否在其内部表示中编码了因果信息，开发了一个适配器框架来提取和解码这些因果信号，用于因果发现。


<details>
  <summary>Details</summary>
Motivation: 因果发现在多个科学领域中具有基础性意义，但从真实世界数据中提取因果信息仍然是一个重大挑战。鉴于TabPFN在真实数据上的成功表现，研究者希望探究这个预训练的表格基础模型是否在其内部表示中编码了因果信息。

Method: 开发了一个适配器框架，使用可学习的解码器和因果标记，从TabPFN的冻结嵌入中提取因果信号，并将其解码为用于因果发现的邻接矩阵。

Result: 评估表明TabPFN的嵌入包含因果信息，在性能上优于几种传统的因果发现算法，且这些因果信息主要集中在中间层。

Conclusion: 这些发现为基础模型的可解释性和适应性开辟了新方向，并展示了利用预训练表格模型进行因果发现的潜力。

Abstract: Causal discovery is fundamental for multiple scientific domains, yet
extracting causal information from real world data remains a significant
challenge. Given the recent success on real data, we investigate whether
TabPFN, a transformer-based tabular foundation model pre-trained on synthetic
datasets generated from structural causal models, encodes causal information in
its internal representations. We develop an adapter framework using a learnable
decoder and causal tokens that extract causal signals from TabPFN's frozen
embeddings and decode them into adjacency matrices for causal discovery. Our
evaluations demonstrate that TabPFN's embeddings contain causal information,
outperforming several traditional causal discovery algorithms, with such causal
information being concentrated in mid-range layers. These findings establish a
new direction for interpretable and adaptable foundation models and demonstrate
the potential for leveraging pre-trained tabular models for causal discovery.

</details>


### [369] [The Few Govern the Many:Unveiling Few-Layer Dominance for Time Series Models](https://arxiv.org/abs/2511.07237)
*Xin Qiu,Junlong Tong,Yirong Sun,Yunpu Ma,Xiaoyu Shen*

Main category: cs.LG

TL;DR: 研究发现时间序列模型存在缩放悖论：模型规模增大反而导致性能下降，原因是只有少数层真正发挥作用，多数层是冗余的。提出保留关键层的方法，仅用21%参数即可提升12%精度并加速2.7倍。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为扩大模型规模和数据量能提升时间序列预测性能，但作者观察到缩放悖论现象——更大的模型反而性能更差，需要探究其原因并找到解决方案。

Method: 通过分析模型内部表示，发现"少数层主导"现象，即只有小部分层功能重要，多数层冗余且干扰训练。提出自动识别和保留主导层的实用方法。

Result: 在8个SOTA模型上验证，保留不到30%的层就能在95%以上的任务中达到相当或更优的精度。具体实现中，仅保留21%参数即可提升12%精度并加速2.7倍推理。

Conclusion: 时间序列模型存在普遍的缩放悖论，通过识别和保留关键层可以显著提升模型效率和性能，这为时间序列预测模型的优化提供了新思路。

Abstract: Large-scale models are at the forefront of time series (TS) forecasting,
dominated by two paradigms: fine-tuning text-based Large Language Models
(LLM4TS) and training Time Series Foundation Models (TSFMs) from scratch. Both
approaches share a foundational assumption that scaling up model capacity and
data volume leads to improved performance. However, we observe a
\textit{\textbf{scaling paradox}} in TS models, revealing a puzzling phenomenon
that larger models do \emph{NOT} achieve better performance. Through extensive
experiments on two model families across four scales (100M to 1.7B parameters)
and diverse data (up to 6B observations), we rigorously confirm that the
scaling paradox is a pervasive issue. We then diagnose its root cause by
analyzing internal representations, identifying a phenomenon we call
\textit{few-layer dominance}: only a small subset of layers are functionally
important, while the majority are redundant, under-utilized, and can even
distract training. Based on this discovery, we propose a practical method to
automatically identify and retain only these dominant layers. In our models,
retaining only 21\% of the parameters achieves up to a 12\% accuracy
improvement and a 2.7$\times$ inference speedup. We validate the universality
of our method on 8 prominent SOTA models (LLM4TS and TSFMs, 90M to 6B), showing
that retaining less than 30\% of layers achieves comparable or superior
accuracy in over 95\% of tasks.

</details>


### [370] [RobustA: Robust Anomaly Detection in Multimodal Data](https://arxiv.org/abs/2511.07276)
*Salem AlMarri,Muhammad Irzam Liaqat,Muhammad Zaigham Zaheer,Shah Nawaz,Karthik Nandakumar,Markus Schedl*

Main category: cs.LG

TL;DR: 本文提出了首个全面研究模态损坏对多模态异常检测影响的工作，包括创建RobustA评估数据集和提出具有抗损坏能力的多模态异常检测方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多模态数据经常因环境干扰而损坏，现有方法未充分考虑模态损坏对异常检测性能的负面影响。

Method: 提出学习共享表示空间的方法，并在推理时基于估计的损坏程度采用动态权重方案。

Result: 创建了RobustA评估数据集，提出的方法在模态损坏情况下表现出显著的鲁棒性。

Conclusion: 这项工作推动了多模态异常检测在现实世界中的应用，解决了模态损坏可能发生的情况。

Abstract: In recent years, multimodal anomaly detection methods have demonstrated
remarkable performance improvements over video-only models. However, real-world
multimodal data is often corrupted due to unforeseen environmental distortions.
In this paper, we present the first-of-its-kind work that comprehensively
investigates the adverse effects of corrupted modalities on multimodal anomaly
detection task. To streamline this work, we propose RobustA, a carefully
curated evaluation dataset to systematically observe the impacts of audio and
visual corruptions on the overall effectiveness of anomaly detection systems.
Furthermore, we propose a multimodal anomaly detection method, which shows
notable resilience against corrupted modalities. The proposed method learns a
shared representation space for different modalities and employs a dynamic
weighting scheme during inference based on the estimated level of corruption.
Our work represents a significant step forward in enabling the real-world
application of multimodal anomaly detection, addressing situations where the
likely events of modality corruptions occur. The proposed evaluation dataset
with corrupted modalities and respective extracted features will be made
publicly available.

</details>


### [371] [Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search](https://arxiv.org/abs/2511.07312)
*Samuel Sokota,Eugene Vinitsky,Hengyuan Hu,J. Zico Kolter,Gabriele Farina*

Main category: cs.LG

TL;DR: 该研究在Stratego游戏中实现了重大突破，不仅达到人类顶级水平，还实现了超人类表现，且训练成本从数百万美元降至几千美元。


<details>
  <summary>Details</summary>
Motivation: Stratego作为具有大量隐藏信息的战略决策游戏，此前的人工智能训练成本高昂但未能达到人类顶级水平，需要开发更高效的方法。

Method: 开发了不完全信息下的自博弈强化学习和测试时搜索的通用方法。

Result: 在Stratego游戏中实现了超人类水平的性能，同时将训练成本从数百万美元大幅降低到几千美元。

Conclusion: 证明了通过自博弈强化学习和测试时搜索方法，可以在不完全信息游戏中以极低成本实现超人类表现。

Abstract: Few classical games have been regarded as such significant benchmarks of
artificial intelligence as to have justified training costs in the millions of
dollars. Among these, Stratego -- a board wargame exemplifying the challenge of
strategic decision making under massive amounts of hidden information -- stands
apart as a case where such efforts failed to produce performance at the level
of top humans. This work establishes a step change in both performance and cost
for Stratego, showing that it is now possible not only to reach the level of
top humans, but to achieve vastly superhuman level -- and that doing so
requires not an industrial budget, but merely a few thousand dollars. We
achieved this result by developing general approaches for self-play
reinforcement learning and test-time search under imperfect information.

</details>


### [372] [TNT: Improving Chunkwise Training for Test-Time Memorization](https://arxiv.org/abs/2511.07343)
*Zeman Li,Ali Behrouz,Yuan Deng,Peilin Zhong,Praneeth Kacham,Mahdi Karami,Meisam Razaviyayn,Vahab Mirrokni*

Main category: cs.LG

TL;DR: TNT是一种新的训练范式，通过两阶段过程解决深度测试时记忆RNN训练效率低的问题：第一阶段使用分层内存进行高效预训练，第二阶段进行简短微调，实现了17倍训练加速同时提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 解决深度测试时记忆RNN（如Titans和TTT）训练速度慢、硬件利用率低的问题，这些模型虽然具有线性扩展潜力，但由于现有并行化方法在chunksize参数上存在效率与性能的冲突，限制了其发展。

Method: 两阶段训练：第一阶段使用分层内存进行效率优先的预训练，全局模块处理大块上下文，多个并行本地模块处理细节，通过定期重置本地内存状态打破顺序依赖；第二阶段仅对本地内存模块进行小chunksize微调。

Result: 在Titans和TTT模型上评估，TNT实现了高达17倍的训练加速，同时提升了模型精度，消除了可扩展性障碍。

Conclusion: TNT为开发表达性RNN建立了实用基础，有助于未来缩小与Transformer的性能差距。

Abstract: Recurrent neural networks (RNNs) with deep test-time memorization modules,
such as Titans and TTT, represent a promising, linearly-scaling paradigm
distinct from Transformers. While these expressive models do not yet match the
peak performance of state-of-the-art Transformers, their potential has been
largely untapped due to prohibitively slow training and low hardware
utilization. Existing parallelization methods force a fundamental conflict
governed by the chunksize hyperparameter: large chunks boost speed but degrade
performance, necessitating a fixed, suboptimal compromise. To solve this
challenge, we introduce TNT, a novel training paradigm that decouples training
efficiency from inference performance through a two-stage process. Stage one is
an efficiency-focused pre-training phase utilizing a hierarchical memory. A
global module processes large, hardware-friendly chunks for long-range context,
while multiple parallel local modules handle fine-grained details. Crucially,
by periodically resetting local memory states, we break sequential dependencies
to enable massive context parallelization. Stage two is a brief fine-tuning
phase where only the local memory modules are adapted to a smaller,
high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated
on Titans and TTT models, TNT achieves a substantial acceleration in training
speed-up to 17 times faster than the most accurate baseline configuration -
while simultaneously improving model accuracy. This improvement removes a
critical scalability barrier, establishing a practical foundation for
developing expressive RNNs and facilitating future work to close the
performance gap with Transformers.

</details>


### [373] [Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence Estimation for Failure Detection](https://arxiv.org/abs/2511.07364)
*Vaibhav Mavi,Shubh Jaroria,Weiqi Sun*

Main category: cs.LG

TL;DR: 本文研究大型语言模型在多步推理任务中的可靠性评估，比较了整体评分和逐步评分两种方法，发现逐步评估在错误检测方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在高风险多步推理任务中的可靠性检测至关重要，现有方法主要关注单步输出，忽视了多步推理的挑战。

Method: 将自评估技术扩展到多步任务，测试了整体评分和逐步评分两种直观方法，使用两个多步基准数据集进行评估。

Result: 逐步评估在检测潜在错误方面通常优于整体评分，AUC-ROC相对提升高达15%。

Conclusion: 自评估LLM系统在复杂推理中能提供有意义的置信度估计，提高了可信度并为故障检测提供了实用框架。

Abstract: Reliability and failure detection of large language models (LLMs) is critical
for their deployment in high-stakes, multi-step reasoning tasks. Prior work
explores confidence estimation for self-evaluating LLM-scorer systems, with
confidence scorers estimating the likelihood of errors in LLM responses.
However, most methods focus on single-step outputs and overlook the challenges
of multi-step reasoning. In this work, we extend self-evaluation techniques to
multi-step tasks, testing two intuitive approaches: holistic scoring and
step-by-step scoring. Using two multi-step benchmark datasets, we show that
stepwise evaluation generally outperforms holistic scoring in detecting
potential errors, with up to 15% relative increase in AUC-ROC. Our findings
demonstrate that self-evaluating LLM systems provide meaningful confidence
estimates in complex reasoning, improving their trustworthiness and providing a
practical framework for failure detection.

</details>


### [374] [Private Sketches for Linear Regression](https://arxiv.org/abs/2511.07365)
*Shrutimoy Das,Debanuj Nayak,Anirban Dasgupta*

Main category: cs.LG

TL;DR: 本文提出了一种差分隐私草图方法，用于保护敏感数据在最小二乘回归和最小绝对偏差回归中的隐私，避免直接发布噪声参数向量。


<details>
  <summary>Details</summary>
Motivation: 线性回归广泛应用于各个领域，但涉及敏感数据时需要保护隐私。现有差分隐私方法通常通过添加噪声来估计参数向量，但作者认为直接发布数据集隐私草图更有效。

Method: 开发差分隐私草图方法，为最小二乘回归和最小绝对偏差回归问题生成隐私保护的数据摘要，而不是直接发布带噪声的参数估计。

Result: 提出的隐私草图方法允许使用常见的回归求解器，同时确保不会泄露隐私信息。

Conclusion: 通过发布隐私数据集草图而非噪声参数向量，可以在保护隐私的同时有效应用标准回归方法。

Abstract: Linear regression is frequently applied in a variety of domains. In order to
improve the efficiency of these methods, various methods have been developed
that compute summaries or \emph{sketches} of the datasets. Certain domains,
however, contain sensitive data which necessitates that the application of
these statistical methods does not reveal private information. Differentially
private (DP) linear regression methods have been developed for mitigating this
problem. These techniques typically involve estimating a noisy version of the
parameter vector. Instead, we propose releasing private sketches of the
datasets. We present differentially private sketches for the problems of least
squares regression, as well as least absolute deviations regression. The
availability of these private sketches facilitates the application of commonly
available solvers for regression, without the risk of privacy leakage.

</details>


### [375] [Consistency Is Not Always Correct: Towards Understanding the Role of Exploration in Post-Training Reasoning](https://arxiv.org/abs/2511.07368)
*Dake Bu,Wei Huang,Andi Han,Atsushi Nitanda,Bo Xue,Qingfu Zhang,Hau-San Wong,Taiji Suzuki*

Main category: cs.LG

TL;DR: 本文通过树结构马尔可夫链模型解释了一个悖论：虽然RLVR和ORM/PRM强化训练主要强化现有推理路径而非扩展推理范围，但探索仍然对提升模型性能至关重要，因为它能保留解决困难问题所需的罕见推理路径。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型具有广泛知识但特定任务推理能力有限，后训练策略如RLVR和推理缩放存在一个悖论：它们主要强化现有推理路径而非扩展推理范围，但探索却仍能提升性能。本文旨在解释这一现象。

Method: 采用Kim等人的视角，将推理步骤建模为低概率和高概率马尔可夫转移，通过多任务树结构马尔可夫链模型形式化后训练动态，其中预训练对应树扩展，后训练对应思维链重加权。

Result: 理论分析显示：(1)RLVR产生挤压效应，减少推理熵并遗忘某些正确路径；(2)ORM/PRM的群体奖励鼓励一致性而非准确性；(3)基础模型的罕见高不确定性推理路径负责解决困难问题实例。

Conclusion: 探索之所以重要，是因为它能保留解决困难问题所需的罕见但关键的推理路径，这些路径会被RLVR挤压或被推理缩放策略忽略。拒绝简单实例和KL正则化等探索策略有助于保留这些罕见推理路径。

Abstract: Foundation models exhibit broad knowledge but limited task-specific
reasoning, motivating post-training strategies such as RLVR and inference
scaling with outcome or process reward models (ORM/PRM). While recent work
highlights the role of exploration and entropy stability in improving pass@K,
empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce
existing tree-like reasoning paths rather than expanding the reasoning scope,
raising the question of why exploration helps at all if no new patterns emerge.
  To reconcile this paradox, we adopt the perspective of Kim et al. (2025),
viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a
symmetry) reasoning steps as low- versus high-probability Markov transitions,
and formalize post-training dynamics through Multi-task Tree-structured Markov
Chains (TMC). In this tractable model, pretraining corresponds to tree
expansion, while post-training corresponds to chain-of-thought reweighting. We
show that several phenomena recently observed in empirical studies arise
naturally in this setting: (1) RLVR induces a squeezing effect, reducing
reasoning entropy and forgetting some correct paths; (2) population rewards of
ORM/PRM encourage consistency rather than accuracy, thereby favoring common
patterns; and (3) certain rare, high-uncertainty reasoning paths by the base
model are responsible for solving hard problem instances.
  Together, these explain why exploration -- even when confined to the base
model's reasoning scope -- remains essential: it preserves access to rare but
crucial reasoning traces needed for difficult cases, which are squeezed out by
RLVR or unfavored by inference scaling. Building on this, we further show that
exploration strategies such as rejecting easy instances and KL regularization
help preserve rare reasoning traces. Empirical simulations corroborate our
theoretical results.

</details>


### [376] [Provable Benefit of Curriculum in Transformer Tree-Reasoning Post-Training](https://arxiv.org/abs/2511.07372)
*Dake Bu,Wei Huang,Andi Han,Atsushi Nitanda,Hau-San Wong,Qingfu Zhang,Taiji Suzuki*

Main category: cs.LG

TL;DR: 本文提出了一个理论框架来解释课程学习在LLM后训练阶段提升推理性能的原理，证明了在适当的复杂度条件下，课程学习可以避免指数级复杂度瓶颈，而直接学习会遭遇指数级困难。


<details>
  <summary>Details</summary>
Motivation: 当前观察到课程学习技术在后训练阶段能显著提升LLM的推理性能，但其工作原理和有效范围缺乏理论解释，需要建立一个理论框架来理解为什么以及到什么程度课程学习是有效的。

Method: 建立基于状态条件自回归推理树的理论框架，将思维链生成建模为推理树，定义均匀分支基础模型来捕捉预训练行为，并将课程阶段形式化为深度增加或提示减少的子任务。

Result: 分析表明，在仅结果奖励信号下，强化学习微调能以多项式样本复杂度实现高准确率，而直接学习会遭遇指数级瓶颈。测试时扩展也显示课程感知查询能将奖励调用和采样成本从指数级降低到多项式级。

Conclusion: 课程学习通过渐进式学习可管理的步骤，在模型有效能力范围内避免了指数级复杂度瓶颈，为理解课程学习在LLM推理中的有效性提供了理论基础。

Abstract: Recent curriculum techniques in the post-training stage of LLMs have been
widely observed to outperform non-curriculum approaches in enhancing reasoning
performance, yet a principled understanding of why and to what extent they work
remains elusive. To address this gap, we develop a theoretical framework
grounded in the intuition that progressively learning through manageable steps
is more efficient than directly tackling a hard reasoning task, provided each
stage stays within the model's effective competence. Under mild complexity
conditions linking consecutive curriculum stages, we show that curriculum
post-training avoids the exponential complexity bottleneck.
  To substantiate this result, drawing insights from the Chain-of-Thoughts
(CoTs) solving mathematical problems such as Countdown and parity, we model CoT
generation as a states-conditioned autoregressive reasoning tree, define a
uniform-branching base model to capture pretrained behavior, and formalize
curriculum stages as either depth-increasing (longer reasoning chains) or
hint-decreasing (shorter prefixes) subtasks. Our analysis shows that, under
outcome-only reward signals, reinforcement learning finetuning achieves high
accuracy with polynomial sample complexity, whereas direct learning suffers
from an exponential bottleneck. We further establish analogous guarantees for
test-time scaling, where curriculum-aware querying reduces both reward oracle
calls and sampling cost from exponential to polynomial order.

</details>


### [377] [Transformers Provably Learn Chain-of-Thought Reasoning with Length Generalization](https://arxiv.org/abs/2511.07378)
*Yu Huang,Zixin Wen,Aarti Singh,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

TL;DR: 该论文从理论上分析了Transformer模型在状态跟踪任务中的推理外推能力，证明了注意力集中机制如何影响长度泛化，并提出了递归自训练方案来扩展可解决问题的长度范围。


<details>
  <summary>Details</summary>
Motivation: 研究AI推理能力是否能外推到更长的思维链推理任务，理解Transformer模型如何学习状态跟踪任务并实现长度泛化。

Method: 使用梯度下降在合成状态跟踪任务上训练Transformer模型，通过数学证明分析注意力集中机制与任务结构的关系，并提出递归自训练方案。

Result: 证明了恒定深度Transformer能够学习NC^1完全问题，超越了之前局限于TC^0的研究，并通过实验验证了长度泛化行为和注意力集中机制。

Conclusion: Transformer模型能够通过注意力集中机制实现状态跟踪任务的长度泛化，递归自训练可以逐步扩展可解决问题的长度范围，为AI推理能力提供了理论保证。

Abstract: The ability to reason lies at the core of artificial intelligence (AI), and
challenging problems usually call for deeper and longer reasoning to tackle. A
crucial question about AI reasoning is whether models can extrapolate learned
reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In
this work, we present a theoretical analysis of transformers learning on
synthetic state-tracking tasks with gradient descent. We mathematically prove
how the algebraic structure of state-tracking problems governs the degree of
extrapolation of the learned CoT. Specifically, our theory characterizes the
length generalization of transformers through the mechanism of attention
concentration, linking the retrieval robustness of the attention layer to the
state-tracking task structure of long-context reasoning. Moreover, for
transformers with limited reasoning length, we prove that a recursive
self-training scheme can progressively extend the range of solvable problem
lengths. To our knowledge, we provide the first optimization guarantee that
constant-depth transformers provably learn $\mathsf{NC}^1$-complete problems
with CoT, significantly going beyond prior art confined in $\mathsf{TC}^0$,
unless the widely held conjecture $\mathsf{TC}^0 \neq \mathsf{NC}^1$ fails.
Finally, we present a broad set of experiments supporting our theoretical
results, confirming the length generalization behaviors and the mechanism of
attention concentration.

</details>


### [378] [A Diffusion Model to Shrink Proteins While Maintaining Their Function](https://arxiv.org/abs/2511.07390)
*Ethan Baron,Alan N. Amin,Ruben Weitzman,Debora Marks,Andrew Gordon Wilson*

Main category: cs.LG

TL;DR: SCISOR是一种新颖的离散扩散模型，通过删除序列中的字母来生成类似自然界发现的蛋白质样本，解决了长蛋白质序列难以制造、融合或递送的问题。


<details>
  <summary>Details</summary>
Motivation: 许多在医学或生物工程中有用的蛋白质由于序列过长而难以在实验室制造、与细胞中其他蛋白质融合或递送到体内组织中。缩短这些序列通常需要昂贵且耗时的实验活动。

Method: SCISOR训练一个去噪器来逆转一个正向噪声过程，该过程向自然序列添加随机插入。作为一种生成模型，SCISOR与先前的大型模型竞争性地拟合进化序列数据。

Result: SCISOR在ProteinGym上实现了对删除功能效应的最先进预测。使用SCISOR去噪器缩短长蛋白质序列时，其建议的删除产生了显著更真实的蛋白质，并且比先前的进化序列模型更频繁地保留了功能基序。

Conclusion: SCISOR模型能够有效地生成缩短的蛋白质序列，这些序列更接近自然界发现的序列，并且更好地保留了功能特性，为蛋白质工程提供了一种高效的计算方法。

Abstract: Many proteins useful in modern medicine or bioengineering are challenging to
make in the lab, fuse with other proteins in cells, or deliver to tissues in
the body, because their sequences are too long. Shortening these sequences
typically involves costly, time-consuming experimental campaigns. Ideally, we
could instead use modern models of massive databases of sequences from nature
to learn how to propose shrunken proteins that resemble sequences found in
nature. Unfortunately, these models struggle to efficiently search the
combinatorial space of all deletions, and are not trained with inductive biases
to learn how to delete. To address this gap, we propose SCISOR, a novel
discrete diffusion model that deletes letters from sequences to generate
protein samples that resemble those found in nature. To do so, SCISOR trains a
de-noiser to reverse a forward noising process that adds random insertions to
natural sequences. As a generative model, SCISOR fits evolutionary sequence
data competitively with previous large models. In evaluation, SCISOR achieves
state-of-the-art predictions of the functional effects of deletions on
ProteinGym. Finally, we use the SCISOR de-noiser to shrink long protein
sequences, and show that its suggested deletions result in significantly more
realistic proteins and more often preserve functional motifs than previous
models of evolutionary sequences.

</details>


### [379] [Entangled Schrödinger Bridge Matching](https://arxiv.org/abs/2511.07406)
*Sophia Tang,Yinuo Zhang,Pranam Chatterjee*

Main category: cs.LG

TL;DR: 提出了EntangledSBM框架，用于学习多粒子系统中相互作用的随机动力学，其中每个粒子的路径方向和大小动态依赖于其他粒子的路径。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂能量景观上模拟多粒子系统轨迹的挑战，特别是在生物分子系统和异质细胞群等系统中，动态相互作用无法通过静态快照捕捉。

Method: 引入纠缠薛定谔桥匹配框架，通过求解耦合的偏置力系统来纠缠粒子速度，学习相互作用多粒子系统的一阶和二阶随机动力学。

Result: 该框架能够准确模拟扰动下的异质细胞群和高维生物分子系统中的稀有跃迁。

Conclusion: EntangledSBM为模拟具有动态相互作用的多粒子系统提供了一种有效的解决方案。

Abstract: Simulating trajectories of multi-particle systems on complex energy
landscapes is a central task in molecular dynamics (MD) and drug discovery, but
remains challenging at scale due to computationally expensive and long
simulations. Previous approaches leverage techniques such as flow or
Schr\"odinger bridge matching to implicitly learn joint trajectories through
data snapshots. However, many systems, including biomolecular systems and
heterogeneous cell populations, undergo dynamic interactions that evolve over
their trajectory and cannot be captured through static snapshots. To close this
gap, we introduce Entangled Schr\"odinger Bridge Matching (EntangledSBM), a
framework that learns the first- and second-order stochastic dynamics of
interacting, multi-particle systems where the direction and magnitude of each
particle's path depend dynamically on the paths of the other particles. We
define the Entangled Schr\"odinger Bridge (EntangledSB) problem as solving a
coupled system of bias forces that entangle particle velocities. We show that
our framework accurately simulates heterogeneous cell populations under
perturbations and rare transitions in high-dimensional biomolecular systems.

</details>


### [380] [Routing Manifold Alignment Improves Generalization of Mixture-of-Experts LLMs](https://arxiv.org/abs/2511.07419)
*Zhongyang Li,Ziyue Li,Tianyi Zhou*

Main category: cs.LG

TL;DR: 本文提出了RoMA方法，通过将路由权重流形与任务嵌入流形对齐来改善MoE LLMs中路由器的性能，仅需轻量级微调路由器参数即可显著提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有MoE LLMs中的路由器在广泛下游任务评估中表现不佳，与最优路由存在10-20%的准确率差距，这限制了模型的泛化性能。

Method: 提出路由流形对齐(RoMA)方法，在训练后目标中引入额外的流形正则化项，仅微调路由器参数而冻结其他参数。该方法鼓励每个样本的路由权重在任务嵌入空间中接近其成功邻居的路由权重。

Result: 在OLMoE、DeepSeekMoE和Qwen3-MoE上的实验表明，RoMA在不同基准测试中带来了显著改进，与基线方法相比性能大幅提升。

Conclusion: RoMA通过统一任务理解（通过嵌入模型）和解决方案生成（通过MoE LLMs）的优势，实现了任务与专家之间的绑定，从而获得更好的泛化性能。

Abstract: Sparse Mixture-of-Experts (MoE) have been widely adopted in recent large
language models since it can efficiently scale up the model capability without
increasing the inference cost. However, evaluations on broad downstream tasks
reveal a consistent suboptimality of the routers in existing MoE LLMs, which
results in a severe performance gap (e.g., 10-20% in accuracy) to the optimal
routing. In this paper, we show that aligning the manifold of routing weights
with that of task embedding can effectively reduce the gap and improve MoE
LLMs' generalization performance. Our method, "Routing Manifold Alignment
(RoMA)", introduces an additional manifold regularization term in the
post-training objective and only requires lightweight finetuning of routers
(with other parameters frozen). Specifically, the regularization encourages the
routing weights of each sample to be close to those of its successful neighbors
(whose routing weights lead to correct answers) in a task embedding space.
Consequently, samples targeting similar tasks will share similar expert choices
across layers. Building such bindings between tasks and experts over different
samples is essential to achieve better generalization. Moreover, RoMA
demonstrates the advantage of unifying the task understanding (by embedding
models) with solution generation (by MoE LLMs). In experiments, we finetune
routers in OLMoE, DeepSeekMoE, and Qwen3-MoE using RoMA. Evaluations on diverse
benchmarks and extensive comparisons with baselines show the substantial
improvement brought by RoMA.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [381] [GreyShot: Zeroshot and Privacy-preserving Recommender System by GM(1,1) Model](https://arxiv.org/abs/2511.05493)
*Hao Wang*

Main category: cs.IR

TL;DR: 本文提出了一种名为GreyShot的零样本隐私保护推荐系统算法，使用GM(1,1)灰系统模型解决推荐系统的冷启动问题，该方法无需输入数据且能生成准确公平的结果。


<details>
  <summary>Details</summary>
Motivation: 推荐系统工程师在构建系统时都需要面对冷启动问题，虽然过去几十年大多数科学家采用迁移学习和元学习来解决这个问题，但冷启动问题仍然是许多研究人员面临的挑战性问题。

Method: 利用在线评分数据的泊松-帕累托特性，构建基于GM(1,1)模型的零样本隐私保护推荐系统算法GreyShot，该方法不依赖任何输入数据。

Result: 该方法能够有效生成准确且公平的结果。

Conclusion: 推荐系统的零样本问题可以通过灰系统方法如GM(1,1)有效解决。

Abstract: Every recommendation engineer needs to face the cold start problem when
building his system. During the past decades, most scientists adopted transfer
learning and meta learning to solve the problem. Although notable exceptions
such as ZeroMat etc. have been invented in recent years, cold-start problem
remains a challenging problem for many researchers. In this paper, we build a
zeroshot and privacy-preserving recommender system algorithm GreyShot using
GM(1,1) model by taking advantage of the Poisson-Pareto property of the online
rating data. Our approach relies on no input data and is effective in
generating both accurate and fair results. In conclusion, zeroshot problem of
recommender systems could be effectively solved by grey system methods such as
GM(1,1).

</details>


### [382] [Customized Retrieval-Augmented Generation with LLM for Debiasing Recommendation Unlearning](https://arxiv.org/abs/2511.05494)
*Haichao Zhang,Chong Zhang,Peiyu Hu,Shi Qiu,Jia Wang*

Main category: cs.IR

TL;DR: CRAGRU是一个基于检索增强生成(RAG)的新型推荐系统遗忘框架，通过分离检索和生成阶段，在高效移除特定用户数据的同时减少对其他用户的负面影响，解决了传统遗忘方法中的传播偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统面临隐私法规合规挑战，传统遗忘方法存在传播偏差问题，即移除一个用户数据会影响行为相似用户的推荐准确性，而完全重新训练计算成本过高。

Method: CRAGRU将遗忘过程解耦为检索和生成两个阶段：检索阶段使用三种定制策略精确隔离目标用户数据影响；生成阶段利用LLM结合用户画像重构个性化推荐，无需重新训练基础模型。

Result: 在三个公共数据集上的实验表明，CRAGRU能有效遗忘目标用户数据，显著减轻遗忘偏差，避免对非目标用户产生负面影响，同时保持与原始模型相当的推荐性能。

Conclusion: 这项工作展示了基于RAG的架构在构建鲁棒且保护隐私的推荐系统方面的潜力。

Abstract: Modern recommender systems face a critical challenge in complying with
privacy regulations like the 'right to be forgotten': removing a user's data
without disrupting recommendations for others. Traditional unlearning methods
address this by partial model updates, but introduce propagation bias--where
unlearning one user's data distorts recommendations for behaviorally similar
users, degrading system accuracy. While retraining eliminates bias, it is
computationally prohibitive for large-scale systems. To address this challenge,
we propose CRAGRU, a novel framework leveraging Retrieval-Augmented Generation
(RAG) for efficient, user-specific unlearning that mitigates bias while
preserving recommendation quality. CRAGRU decouples unlearning into distinct
retrieval and generation stages. In retrieval, we employ three tailored
strategies designed to precisely isolate the target user's data influence,
minimizing collateral impact on unrelated users and enhancing unlearning
efficiency. Subsequently, the generation stage utilizes an LLM, augmented with
user profiles integrated into prompts, to reconstruct accurate and personalized
recommendations without needing to retrain the entire base model. Experiments
on three public datasets demonstrate that CRAGRU effectively unlearns targeted
user data, significantly mitigating unlearning bias by preventing adverse
impacts on non-target users, while maintaining recommendation performance
comparable to fully trained original models. Our work highlights the promise of
RAG-based architectures for building robust and privacy-preserving recommender
systems. The source code is available at:
https://github.com/zhanghaichao520/LLM_rec_unlearning.

</details>


### [383] [IMDMR: An Intelligent Multi-Dimensional Memory Retrieval System for Enhanced Conversational AI](https://arxiv.org/abs/2511.05495)
*Tejas Pawar,Sarika Patil,Om Tilekar,Rushikesh Janwade,Vaibhav Helambe*

Main category: cs.IR

TL;DR: IMDMR是一个智能多维度记忆检索系统，通过六种记忆维度（语义、实体、类别、意图、上下文、时间）提供全面的记忆检索能力，在对话AI系统中显著提升了性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的对话AI系统在维持跨扩展交互的连贯上下文记忆方面存在困难，限制了提供个性化和上下文相关响应的能力。

Method: 采用多维度搜索架构，包括智能查询处理与动态策略选择、跨记忆实体解析和高级记忆集成技术。

Result: 与五个基线系统相比，IMDMR实现了3.8倍的整体性能提升（0.792 vs 0.207），消融研究显示多维度搜索比单维度方法性能提升23.3%。

Conclusion: IMDMR代表了对话AI记忆系统的重大进步，为增强用户交互和个性化体验提供了坚实基础。

Abstract: Conversational AI systems often struggle with maintaining coherent,
contextual memory across extended interactions, limiting their ability to
provide personalized and contextually relevant responses. This paper presents
IMDMR (Intelligent Multi-Dimensional Memory Retrieval), a novel system that
addresses these limitations through a multi-dimensional search architecture.
Unlike existing memory systems that rely on single-dimensional approaches,
IMDMR leverages six distinct memory dimensions-semantic, entity, category,
intent, context, and temporal-to provide comprehensive memory retrieval
capabilities. Our system incorporates intelligent query processing with dynamic
strategy selection, cross-memory entity resolution, and advanced memory
integration techniques. Through comprehensive evaluation against five baseline
systems including LangChain RAG, LlamaIndex, MemGPT, and spaCy + RAG, IMDMR
achieves a 3.8x improvement in overall performance (0.792 vs 0.207 for the best
baseline). We present both simulated (0.314) and production (0.792)
implementations, demonstrating the importance of real technology integration
while maintaining superiority over all baseline systems. Ablation studies
demonstrate the effectiveness of multi-dimensional search, with the full system
outperforming individual dimension approaches by 23.3%. Query-type analysis
reveals superior performance across all categories, particularly for
preferences/interests (0.630) and goals/aspirations (0.630) queries.
Comprehensive visualizations and statistical analysis confirm the significance
of these improvements with p < 0.001 across all metrics. The results establish
IMDMR as a significant advancement in conversational AI memory systems,
providing a robust foundation for enhanced user interactions and personalized
experiences.

</details>


### [384] [DOCUEVAL: An LLM-based AI Engineering Tool for Building Customisable Document Evaluation Workflows](https://arxiv.org/abs/2511.05496)
*Hao Zhang,Qinghua Lu,Liming Zhu*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Foundation models, such as large language models (LLMs), have the potential
to streamline evaluation workflows and improve their performance. However,
practical adoption faces challenges, such as customisability, accuracy, and
scalability. In this paper, we present DOCUEVAL, an AI engineering tool for
building customisable DOCUment EVALuation workflows. DOCUEVAL supports advanced
document processing and customisable workflow design which allow users to
define theory-grounded reviewer roles, specify evaluation criteria, experiment
with different reasoning strategies and choose the assessment style. To ensure
traceability, DOCUEVAL provides comprehensive logging of every run, along with
source attribution and configuration management, allowing systematic comparison
of results across alternative setups. By integrating these capabilities,
DOCUEVAL directly addresses core software engineering challenges, including how
to determine whether evaluators are "good enough" for deployment and how to
empirically compare different evaluation strategies. We demonstrate the
usefulness of DOCUEVAL through a real-world academic peer review case, showing
how DOCUEVAL enables both the engineering of evaluators and scalable, reliable
document evaluation.

</details>


### [385] [Biomedical Hypothesis Explainability with Graph-Based Context Retrieval](https://arxiv.org/abs/2511.05498)
*Ilya Tyagin,Saeideh Valipour,Aliaksandra Sikirzhytskaya,Michael Shtutman,Ilya Safro*

Main category: cs.IR

TL;DR: 提出了一种用于生物医学假设生成系统的可解释性方法，基于新颖的假设生成上下文检索框架，结合语义图检索和相关数据限制训练来模拟真实世界发现约束。


<details>
  <summary>Details</summary>
Motivation: 为生物医学假设生成系统提供可解释性，通过结合语义图检索和相关数据限制训练来模拟真实世界发现约束，提高假设生成的可信度和透明度。

Method: 采用假设生成上下文检索框架，结合语义图检索和相关数据限制训练，通过检索增强生成与大型语言模型集成，并引入新颖的反馈循环方法来迭代识别和纠正LLM生成的解释中的缺陷部分。

Result: 通过多个大型语言模型展示了方法的性能，并通过专家评估和大规模自动分析评估了解释和上下文检索的质量。

Conclusion: 该方法为生物医学假设生成系统提供了有效的可解释性解决方案，能够生成具有上下文证据支持的假设解释，并通过反馈循环不断改进解释质量。

Abstract: We introduce an explainability method for biomedical hypothesis generation
systems, built on top of the novel Hypothesis Generation Context Retriever
framework. Our approach combines semantic graph-based retrieval and relevant
data-restrictive training to simulate real-world discovery constraints.
Integrated with large language models (LLMs) via retrieval-augmented
generation, the system explains hypotheses with contextual evidence using
published scientific literature. We also propose a novel feedback loop
approach, which iteratively identifies and corrects flawed parts of
LLM-generated explanations, refining both the evidence paths and supporting
context. We demonstrate the performance of our method with multiple large
language models and evaluate the explanation and context retrieval quality
through both expert-curated assessment and large-scale automated analysis. Our
code is available at: https://github.com/IlyaTyagin/HGCR.

</details>


### [386] [Predicting Oscar-Nominated Screenplays with Sentence Embeddings](https://arxiv.org/abs/2511.05500)
*Francis Gross*

Main category: cs.IR

TL;DR: 使用现代语言模型预测奥斯卡剧本提名，创建了Movie-O-Label数据集，结合剧本、摘要和标题特征，通过逻辑回归模型达到0.66的宏F1分数。


<details>
  <summary>Details</summary>
Motivation: 奥斯卡提名对电影行业至关重要，能提升知名度和商业成功，但缺乏预测剧本提名的合适数据集和方法。

Method: 创建Movie-O-Label数据集，将长剧本分割成重叠文本块，使用E5句子嵌入模型编码，结合剧本、摘要和标题特征，采用逻辑回归分类。

Result: 最佳模型在结合三个特征输入时达到宏F1分数0.66，精确召回AP为0.445（基线0.19），ROC-AUC为0.79。

Conclusion: 基于现代文本嵌入的简单模型表现出良好的预测性能，可作为未来研究的起点。

Abstract: Oscar nominations are an important factor in the movie industry because they
can boost both the visibility and the commercial success. This work explores
whether it is possible to predict Oscar nominations for screenplays using
modern language models. Since no suitable dataset was available, a new one
called Movie-O-Label was created by combining the MovieSum collection of movie
scripts with curated Oscar records. Each screenplay was represented by its
title, Wikipedia summary, and full script. Long scripts were split into
overlapping text chunks and encoded with the E5 sentence em bedding model.
Then, the screenplay embed dings were classified using a logistic regression
model. The best results were achieved when three feature inputs related to
screenplays (script, summary, and title) were combined. The best-performing
model reached a macro F1 score of 0.66, a precision recall AP of 0.445 with
baseline 0.19 and a ROC-AUC of 0.79. The results suggest that even simple
models based on modern text embeddings demonstrate good prediction performance
and might be a starting point for future research.

</details>


### [387] [SARCH: Multimodal Search for Archaeological Archives](https://arxiv.org/abs/2511.05667)
*Nivedita Sinha,Bharati Khanijo,Sanskar Singh,Priyansh Mahant,Ashutosh Roy,Saubhagya Singh Bhadouria,Arpan Jain,Maya Ramanath*

Main category: cs.IR

TL;DR: 本文描述了一个用于搜索考古书籍和报告的多模态搜索系统，该系统从扫描PDF中提取文本、图像和表格，并评估了基于关键词、嵌入模型和混合方法的检索策略。


<details>
  <summary>Details</summary>
Motivation: 考古文献以扫描PDF形式数字化，但扫描质量差异很大，需要开发专门的多模态搜索系统来处理这种复杂文档类型。

Method: 构建了针对考古文档的多模态管道，提取和索引文本、图像（分类为地图、照片、布局等）和表格，评估了关键词搜索、嵌入模型和混合检索策略。

Result: 报告了初步结果并分析了不同检索方法的性能表现。

Conclusion: 讨论了在这一重要垂直领域未来的研究方向和工作计划。

Abstract: In this paper, we describe a multi-modal search system designed to search old
archaeological books and reports. This corpus is digitally available as scanned
PDFs, but varies widely in the quality of scans. Our pipeline, designed for
multi-modal archaeological documents, extracts and indexes text, images
(classified into maps, photos, layouts, and others), and tables. We evaluated
different retrieval strategies, including keyword-based search, embedding-
based models, and a hybrid approach that selects optimal results from both
modalities. We report and analyze our preliminary results and discuss future
work in this exciting vertical.

</details>


### [388] [A Representation Sharpening Framework for Zero Shot Dense Retrieval](https://arxiv.org/abs/2511.05684)
*Dhananjay Ashok,Suraj Nair,Mutasem Al-Darabsah,Choon Hui Teo,Tarun Agarwal,Jonathan May*

Main category: cs.IR

TL;DR: 提出了一种无需训练的表征锐化框架，通过增强文档表征来区分相似文档，在零样本密集检索任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 零样本密集检索中，预训练的密集检索器由于未在目标语料上训练，难以区分相似文档的语义差异。

Method: 引入无需训练的表征锐化框架，通过从语料中获取区分性信息来增强文档表征。

Result: 在20多个多语言数据集上表现优于传统检索方法，在BRIGHT基准测试中创下新纪录，且与现有方法兼容。

Conclusion: 表征锐化框架能有效提升零样本密集检索性能，并通过索引时近似方法在保持性能的同时避免额外推理成本。

Abstract: Zero-shot dense retrieval is a challenging setting where a document corpus is
provided without relevant queries, necessitating a reliance on pretrained dense
retrievers (DRs). However, since these DRs are not trained on the target
corpus, they struggle to represent semantic differences between similar
documents. To address this failing, we introduce a training-free representation
sharpening framework that augments a document's representation with information
that helps differentiate it from similar documents in the corpus. On over
twenty datasets spanning multiple languages, the representation sharpening
framework proves consistently superior to traditional retrieval, setting a new
state-of-the-art on the BRIGHT benchmark. We show that representation
sharpening is compatible with prior approaches to zero-shot dense retrieval and
consistently improves their performance. Finally, we address the
performance-cost tradeoff presented by our framework and devise an
indexing-time approximation that preserves the majority of our performance
gains over traditional retrieval, yet suffers no additional inference-time
cost.

</details>


### [389] [User Hesitation and Negative Transfer in Multi-Behavior Recommendation](https://arxiv.org/abs/2511.05808)
*Cheng Li,Yong Xu,Suhua Tang,Wenqiang Lin,Xin He,Jinde Cao*

Main category: cs.IR

TL;DR: HNT框架通过识别和利用多行为推荐中的弱信号（正负两种类型），增强用户偏好建模并抑制负迁移效应，在三个真实数据集上显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有多行为推荐方法在处理仅产生辅助行为而未触发目标行为的交互时缺乏深入建模，这些弱信号包含丰富的潜在信息，包括反映用户犹豫倾向的正弱信号和由误操作或噪声引起的负弱信号。

Method: HNT从正负两个维度建模弱信号特征：通过学习导致目标行为的辅助行为特征，识别未触发目标行为的类似辅助行为，构建犹豫项目集作为弱正样本；同时在辅助特征融合中引入潜在负迁移效应建模，通过项目相似性学习区分和抑制负表示干扰。

Result: 在三个真实数据集上的实验表明，HNT相比最佳基线方法将HR@10和NDCG@10分别提高了12.57%和14.37%。

Conclusion: HNT框架能够有效识别和利用多行为推荐中的弱信号，通过正负弱信号的建模显著提升了推荐性能，证明了弱信号学习在推荐系统中的重要性。

Abstract: Multi-behavior recommendation aims to integrate users' interactions across
various behavior types (e.g., view, favorite, add-to-cart, purchase) to more
comprehensively characterize user preferences. However, existing methods lack
in-depth modeling when dealing with interactions that generate only auxiliary
behaviors without triggering the target behavior. In fact, these weak signals
contain rich latent information and can be categorized into two types: (1)
positive weak signals-items that have not triggered the target behavior but
exhibit frequent auxiliary interactions, reflecting users' hesitation
tendencies toward these items; and (2) negative weak signals-auxiliary
behaviors that result from misoperations or interaction noise, which deviate
from true preferences and may cause negative transfer effects. To more
effectively identify and utilize these weak signals, we propose a
recommendation framework focused on weak signal learning, termed HNT.
Specifically, HNT models weak signal features from two dimensions: positive and
negative effects. By learning the characteristics of auxiliary behaviors that
lead to target behaviors, HNT identifies similar auxiliary behaviors that did
not trigger the target behavior and constructs a hesitation set of related
items as weak positive samples to enhance preference modeling, thereby
capturing users' latent hesitation intentions. Meanwhile, during auxiliary
feature fusion, HNT incorporates latent negative transfer effect modeling to
distinguish and suppress interference caused by negative representations
through item similarity learning. Experiments on three real-world datasets
demonstrate that HNT improves HR@10 and NDCG@10 by 12.57% and 14.37%,
respectively, compared to the best baseline methods.

</details>


### [390] [Retrieval Quality at Context Limit](https://arxiv.org/abs/2511.05850)
*Max McKinnon*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The ability of large language models (LLMs) to recall and retrieve
information from long contexts is critical for many real-world applications.
Prior work (Liu et al., 2023) reported that LLMs suffer significant drops in
retrieval accuracy for facts placed in the middle of large contexts, an effect
known as "Lost in the Middle" (LITM). We find the model Gemini 2.5 Flash can
answer needle-in-a-haystack questions with great accuracy regardless of
document position including when the document is nearly at the input context
limit. Our results suggest that the "Lost in the Middle" effect is not present
for simple factoid Q\&A in Gemini 2.5 Flash, indicating substantial
improvements in long-context retrieval.

</details>


### [391] [A Remarkably Efficient Paradigm to Multimodal Large Language Models for Sequential Recommendation](https://arxiv.org/abs/2511.05885)
*Qiyong Zhong,Jiajie Su,Ming Yang,Yunshan Ma,Xiaolin Zheng,Chaochao Chen*

Main category: cs.IR

TL;DR: Speeder是一种用于序列推荐的高效多模态大语言模型范式，包含三个关键组件：多模态表示压缩、序列位置感知增强和模态感知渐进优化，显著提升了训练和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型的序列推荐方法存在计算效率低下的问题，需要开发更高效的范式来提升性能。

Method: 提出Speeder范式，包含三个核心组件：多模态表示压缩减少项目描述冗余，序列位置感知增强捕捉复杂序列依赖关系，模态感知渐进优化逐步整合不同模态以减少认知偏差。

Result: Speeder在VHR@1指标和计算效率上均优于基线方法，训练速度达到最先进MLLM-SR模型的250%，推理速度达到400%。

Conclusion: Speeder为多模态大语言模型在序列推荐中的应用提供了高效解决方案，未来工作可关注整合实时反馈机制。

Abstract: In this paper, we proposed Speeder, a remarkably efficient paradigm to
multimodal large language models for sequential recommendation. Speeder
introduces 3 key components: (1) Multimodal Representation Compression (MRC),
which efficiently reduces redundancy in item descriptions; (2) Sequential
Position Awareness Enhancement (SPAE), which strengthens the model's ability to
capture complex sequential dependencies; (3) Modality-aware Progressive
Optimization (MPO), which progressively integrates different modalities to
improve the model's understanding and reduce cognitive biases. Through
extensive experiments, Speeder demonstrates superior performance over baselines
in terms of VHR@1 and computational efficiency. Specifically, Speeder achieved
250% of the training speed and 400% of the inference speed compared to the
state-of-the-art MLLM-based SR models. Future work could focus on incorporating
real-time feedback from real-world systems.

</details>


### [392] [Ontology Learning and Knowledge Graph Construction: A Comparison of Approaches and Their Impact on RAG Performance](https://arxiv.org/abs/2511.05991)
*Tiago da Cruz,Bernardo Tavares,Francisco Belo*

Main category: cs.IR

TL;DR: 本研究比较了不同知识图谱构建策略对检索增强生成系统性能的影响，发现基于关系数据库构建的本体指导知识图谱在保持竞争力的同时能显著降低成本。


<details>
  <summary>Details</summary>
Motivation: RAG系统的性能高度依赖于外部知识的表示方式，而现有研究对知识图谱不同构建策略的影响缺乏系统比较。

Method: 比较了标准向量检索、GraphRAG以及基于关系数据库和文本语料库构建的本体指导知识图谱等多种方法。

Result: 本体指导的知识图谱（特别是结合分块信息的）达到了与最先进框架相当的竞争性能，显著优于向量检索基准方法。

Conclusion: 基于关系数据库构建的本体指导知识图谱不仅性能具有竞争力，还能大幅降低LLM使用成本并避免文本方法中的本体合并复杂性。

Abstract: Retrieval-Augmented Generation (RAG) systems combine Large Language Models
(LLMs) with external knowledge, and their performance depends heavily on how
that knowledge is represented. This study investigates how different Knowledge
Graph (KG) construction strategies influence RAG performance. We compare a
variety of approaches: standard vector-based RAG, GraphRAG, and retrieval over
KGs built from ontologies derived either from relational databases or textual
corpora. Results show that ontology-guided KGs incorporating chunk information
achieve competitive performance with state-of-the-art frameworks, substantially
outperforming vector retrieval baselines. Moreover, the findings reveal that
ontology-guided KGs built from relational databases perform competitively to
ones built with ontologies extracted from text, with the benefit of offering a
dual advantage: they require a one-time-only ontology learning process,
substantially reducing LLM usage costs; and avoid the complexity of ontology
merging inherent to text-based approaches.

</details>


### [393] [Time Matters: A Novel Real-Time Long- and Short-term User Interest Model for Click-Through Rate Prediction](https://arxiv.org/abs/2511.06213)
*Xian-Jin Gui*

Main category: cs.IR

TL;DR: 该论文提出了一种时间感知的长短期用户兴趣建模方法，通过识别周期性模式和时间点模式来捕捉用户兴趣与时间之间的相关性，以改进点击率预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 大多数现有CTR预测方法忽略了用户激活兴趣与发生时间之间的相关性，导致学习到的是用户在所有时间表达的兴趣混合，而非特定预测时间的实时兴趣。

Method: 从整个时间线的角度研究用户兴趣演化，开发了周期性模式和时间点模式，并基于这两种模式提出时间感知的长短期用户兴趣建模方法。

Result: 在公共数据集和工业数据集上的大量实验验证了利用这两种模式的有效性，并证明了所提方法相比其他最先进方法的优越性。

Conclusion: 通过捕捉用户兴趣与时间的相关性，提出的时间感知建模方法能够更准确地表示用户在特定时间的实时兴趣，从而提升CTR预测性能。

Abstract: Click-Through Rate (CTR) prediction is a core task in online personalization
platform. A key step for CTR prediction is to learn accurate user
representation to capture their interests. Generally, the interest expressed by
a user is time-variant, i.e., a user activates different interests at different
time. However, most previous CTR prediction methods overlook the correlation
between the activated interest and the occurrence time, resulting in what they
actually learn is the mixture of the interests expressed by the user at all
time, rather than the real-time interest at the certain prediction time. To
capture the correlation between the activated interest and the occurrence time,
in this paper we investigate users' interest evolution from the perspective of
the whole time line and develop two regular patterns: periodic pattern and
time-point pattern. Based on the two patterns, we propose a novel time-aware
long- and short-term user interest modeling method to model users' dynamic
interests at different time. Extensive experiments on public datasets as well
as an industrial dataset verify the effectiveness of exploiting the two
patterns and demonstrate the superiority of our proposed method compared with
other state-of-the-art ones.

</details>


### [394] [LLaDA-Rec: Discrete Diffusion for Parallel Semantic ID Generation in Generative Recommendation](https://arxiv.org/abs/2511.06254)
*Teng Shi,Chenglei Shen,Weijie Yu,Shen Nie,Chongxuan Li,Xiao Zhang,Ming He,Yan Han,Jun Xu*

Main category: cs.IR

TL;DR: LLaDA-Rec提出了一种离散扩散框架，通过并行语义ID生成解决生成式推荐中的单向约束和错误累积问题，在三个真实数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有自回归生成推荐模型的两个固有局限：(1) 单向约束导致全局语义建模受限；(2) 固定从左到右生成顺序导致早期预测错误传播到后续标记。

Method: 提出离散扩散框架，包含三个关键设计：(1) 并行标记化方案生成语义ID；(2) 用户历史和下一项目级别的两种掩码机制；(3) 自适应顺序离散扩散解码的波束搜索策略。

Result: 在三个真实世界数据集上的实验表明，LLaDA-Rec一致优于基于ID的方法和最先进的生成推荐器。

Conclusion: 离散扩散为生成式推荐建立了一个新范式，通过双向注意力和自适应生成顺序更有效地建模项目间和项目内依赖关系。

Abstract: Generative recommendation represents each item as a semantic ID, i.e., a
sequence of discrete tokens, and generates the next item through autoregressive
decoding. While effective, existing autoregressive models face two intrinsic
limitations: (1) unidirectional constraints, where causal attention restricts
each token to attend only to its predecessors, hindering global semantic
modeling; and (2) error accumulation, where the fixed left-to-right generation
order causes prediction errors in early tokens to propagate to the predictions
of subsequent token. To address these issues, we propose LLaDA-Rec, a discrete
diffusion framework that reformulates recommendation as parallel semantic ID
generation. By combining bidirectional attention with the adaptive generation
order, the approach models inter-item and intra-item dependencies more
effectively and alleviates error accumulation. Specifically, our approach
comprises three key designs: (1) a parallel tokenization scheme that produces
semantic IDs for bidirectional modeling, addressing the mismatch between
residual quantization and bidirectional architectures; (2) two masking
mechanisms at the user-history and next-item levels to capture both inter-item
sequential dependencies and intra-item semantic relationships; and (3) an
adapted beam search strategy for adaptive-order discrete diffusion decoding,
resolving the incompatibility of standard beam search with diffusion-based
generation. Experiments on three real-world datasets show that LLaDA-Rec
consistently outperforms both ID-based and state-of-the-art generative
recommenders, establishing discrete diffusion as a new paradigm for generative
recommendation.

</details>


### [395] [TOOL4POI: A Tool-Augmented LLM Framework for Next POI Recommendation](https://arxiv.org/abs/2511.06405)
*Dongsheng Wang,Shen Gao,Chengrui Huang,Yuxi Huang,Ruixiang Feng,Shuo Shang*

Main category: cs.IR

TL;DR: Tool4POI是一个基于工具增强的LLM框架，用于解决下一个兴趣点推荐中的上下文完整性和可扩展性问题，通过外部检索和推理实现开放集推荐。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的兴趣点推荐方法存在两个关键限制：对用户历史上下文完整性的强依赖导致在历史外场景表现不佳；由于LLM上下文窗口限制导致可扩展性有限。

Method: Tool4POI包含三个核心模块：偏好提取模块总结长期用户兴趣，多轮候选检索模块与外部工具交互检索相关POI，重排序模块基于近期行为优化最终推荐。

Result: 在三个真实世界数据集上的实验表明，Tool4POI显著优于最先进的基线方法，在历史外场景中达到40%的准确率，在Acc@5和Acc@10上分别平均提升20%和30%。

Conclusion: Tool4POI无需任务特定微调，可与现成LLM即插即用，有效解决了现有LLM方法在兴趣点推荐中的局限性，特别是在历史外场景和可扩展性方面。

Abstract: Next Point-of-Interest (POI) recommendation is a fundamental task in
location-based services. While recent advances leverage Large Language Model
(LLM) for sequential modeling, existing LLM-based approaches face two key
limitations: (i) strong reliance on the contextual completeness of user
histories, resulting in poor performance on out-of-history (OOH) scenarios;
(ii) limited scalability, due to the restricted context window of LLMs, which
limits their ability to access and process a large number of candidate POIs. To
address these challenges, we propose Tool4POI, a novel tool-augmented framework
that enables LLMs to perform open-set POI recommendation through external
retrieval and reasoning. Tool4POI consists of three key modules: preference
extraction module, multi-turn candidate retrieval module, and reranking module,
which together summarize long-term user interests, interact with external tools
to retrieve relevant POIs, and refine final recommendations based on recent
behaviors. Unlike existing methods, Tool4POI requires no task-specific
fine-tuning and is compatible with off-the-shelf LLMs in a plug-and-play
manner. Extensive experiments on three real-world datasets show that Tool4POI
substantially outperforms state-of-the-art baselines, achieving up to 40%
accuracy on challenging OOH scenarios where existing methods fail, and
delivering average improvements of 20% and 30% on Acc@5 and Acc@10,
respectively.

</details>


### [396] [Can LLM Annotations Replace User Clicks for Learning to Rank?](https://arxiv.org/abs/2511.06635)
*Lulu Yu,Keping Bi,Jiafeng Guo,Shihao Liu,Shuaiqiang Wang,Dawei Yin,Xueqi Cheng*

Main category: cs.IR

TL;DR: 本文比较了LLM标注与点击数据在排序学习中的效果，发现点击数据在高频查询上表现更好，而LLM标注在中低频查询上更有效。作者提出了两种整合策略来提升整体排序性能。


<details>
  <summary>Details</summary>
Motivation: 大规模监督数据对训练现代排序模型至关重要，但获取高质量人工标注成本高昂。点击数据和LLM标注都是低成本替代方案，需要研究LLM标注是否能替代点击数据用于排序学习。

Method: 在公开数据集TianGong-ST和工业数据集Baidu-Click上进行多维度综合比较，分析不同频率查询下的表现差异，并探索了数据调度和频率感知多目标学习两种训练策略。

Result: 实验显示点击监督模型在高频查询上表现更好，而LLM标注监督模型在中低频查询上更有效。点击监督模型更擅长捕捉文档级信号，LLM标注监督模型在语义匹配和区分相关/不相关文档方面更强。两种整合策略都能提升各频率查询的排序性能，其中多目标学习方法更有效。

Conclusion: LLM标注不能完全替代点击数据，但两者具有互补优势。通过适当的整合策略可以显著提升排序模型的整体性能，特别是在不同频率查询上的表现。

Abstract: Large-scale supervised data is essential for training modern ranking models,
but obtaining high-quality human annotations is costly. Click data has been
widely used as a low-cost alternative, and with recent advances in large
language models (LLMs), LLM-based relevance annotation has emerged as another
promising annotation. This paper investigates whether LLM annotations can
replace click data for learning to rank (LTR) by conducting a comprehensive
comparison across multiple dimensions. Experiments on both a public dataset,
TianGong-ST, and an industrial dataset, Baidu-Click, show that click-supervised
models perform better on high-frequency queries, while LLM
annotation-supervised models are more effective on medium- and low-frequency
queries. Further analysis shows that click-supervised models are better at
capturing document-level signals such as authority or quality, while LLM
annotation-supervised models are more effective at modeling semantic matching
between queries and documents and at distinguishing relevant from non-relevant
documents. Motivated by these observations, we explore two training strategies
-- data scheduling and frequency-aware multi-objective learning -- that
integrate both supervision signals. Both approaches enhance ranking performance
across queries at all frequency levels, with the latter being more effective.
Our code is available at
https://github.com/Trustworthy-Information-Access/LLMAnn_Click.

</details>


### [397] [When Evidence Contradicts: Toward Safer Retrieval-Augmented Generation in Healthcare](https://arxiv.org/abs/2511.06668)
*Saeedeh Javadi,Sara Mirabi,Manan Gangar,Bahadorreza Ofoghi*

Main category: cs.IR

TL;DR: 本研究评估了5个大型语言模型在医疗领域基于检索增强生成(RAG)的性能，发现当检索到的文档包含过时或矛盾信息时，模型回答的准确性和一致性会显著下降。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险信息领域，LLMs可能产生幻觉或错误信息，RAG被提出作为缓解策略，但源文档中的过时或矛盾信息会引入新的错误。

Method: 创建基于澳大利亚TGA药品信息文档的基准数据集，将标题重新用作自然语言问题；检索PubMed摘要并按出版年份分层，以控制评估过时证据；比较分析过时或矛盾内容对模型生成回答的影响。

Result: 高度相似的摘要之间的矛盾确实会降低性能，导致模型回答的不一致性和事实准确性下降。

Conclusion: 仅依赖检索相似性不足以实现可靠的医疗RAG，需要矛盾感知的过滤策略来确保高风险领域中的可信回答。

Abstract: In high-stakes information domains such as healthcare, where large language
models (LLMs) can produce hallucinations or misinformation, retrieval-augmented
generation (RAG) has been proposed as a mitigation strategy, grounding model
outputs in external, domain-specific documents. Yet, this approach can
introduce errors when source documents contain outdated or contradictory
information. This work investigates the performance of five LLMs in generating
RAG-based responses to medicine-related queries. Our contributions are
three-fold: i) the creation of a benchmark dataset using consumer medicine
information documents from the Australian Therapeutic Goods Administration
(TGA), where headings are repurposed as natural language questions, ii) the
retrieval of PubMed abstracts using TGA headings, stratified across multiple
publication years, to enable controlled temporal evaluation of outdated
evidence, and iii) a comparative analysis of the frequency and impact of
outdated or contradictory content on model-generated responses, assessing how
LLMs integrate and reconcile temporally inconsistent information. Our findings
show that contradictions between highly similar abstracts do, in fact, degrade
performance, leading to inconsistencies and reduced factual accuracy in model
answers. These results highlight that retrieval similarity alone is
insufficient for reliable medical RAG and underscore the need for
contradiction-aware filtering strategies to ensure trustworthy responses in
high-stakes domains.

</details>


### [398] [Learning to Fast Unrank in Collaborative Filtering Recommendation](https://arxiv.org/abs/2511.06803)
*Junpeng Zhao,Lin Li,Ming Li,Amran Bhuiyan,Jimmy Huang*

Main category: cs.IR

TL;DR: 提出L2UnRank方法用于推荐系统中的快速去排序，通过三阶段处理实现高效的目标项目降序，同时保持推荐质量，速度比现有方法提升50倍。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统遗忘方法存在遗忘速度慢和性能下降问题，无法满足实时遗忘需求，需要开发更高效的隐私保护方法。

Method: 通过三阶段处理：基于交互的p跳传播识别影响范围、计算结构性和语义性影响、基于影响信息进行高效的排序感知参数更新。

Result: 在多个数据集和骨干模型上的实验表明，L2UnRank具有模型无关性，实现了最先进的去排序效果，推荐质量与重新训练相当，速度提升50倍。

Conclusion: L2UnRank为推荐系统提供了一种高效、实用的隐私保护解决方案，能够快速移除目标数据影响而不损害系统性能。

Abstract: Modern data-driven recommendation systems risk memorizing sensitive user
behavioral patterns, raising privacy concerns. Existing recommendation
unlearning methods, while capable of removing target data influence, suffer
from inefficient unlearning speed and degraded performance, failing to meet
real-time unlearning demands. Considering the ranking-oriented nature of
recommendation systems, we present unranking, the process of reducing the
ranking positions of target items while ensuring the formal guarantees of
recommendation unlearning. To achieve efficient unranking, we propose Learning
to Fast Unrank in Collaborative Filtering Recommendation (L2UnRank), which
operates through three key stages: (a) identifying the influenced scope via
interaction-based p-hop propagation, (b) computing structural and semantic
influences for entities within this scope, and (c) performing efficient,
ranking-aware parameter updates guided by influence information. Extensive
experiments across multiple datasets and backbone models demonstrate L2UnRank's
model-agnostic nature, achieving state-of-the-art unranking effectiveness and
maintaining recommendation quality comparable to retraining, while also
delivering a 50x speedup over existing methods. Codes are available at
https://github.com/Juniper42/L2UnRank.

</details>


### [399] [Have We Really Understood Collaborative Information? An Empirical Investigation](https://arxiv.org/abs/2511.06905)
*Xiaokun Zhang,Zhaochun Ren,Bowei He,Ziqiang Cui,Chen Ma*

Main category: cs.IR

TL;DR: 本文系统研究了推荐系统中的协同信息，提出了协同信息的定量定义，分析了其在用户-物品交互中的分布结构，评估了协同信息对不同推荐算法性能的影响，并为开发更有效的推荐系统提供了指导。


<details>
  <summary>Details</summary>
Motivation: 当前对推荐系统中协同信息的理解有限，缺乏定量定义，不清楚其在用户-物品交互中的表现方式，也不了解其对推荐性能的影响。

Method: 通过澄清协同信息的物品共现模式特征，提出定量定义；从多个角度估计协同信息的分布；评估协同信息对各种推荐算法性能的影响。

Result: 建立了实证分析框架，揭示了协同信息的许多有洞察力的观察结果，增进了对协同信息的理解。

Conclusion: 研究为开发更有效的推荐系统提供了有价值的指导，并指出了有效捕捉协同信息面临的挑战和未来研究方向。

Abstract: Collaborative information serves as the cornerstone of recommender systems
which typically focus on capturing it from user-item interactions to deliver
personalized services. However, current understanding of this crucial resource
remains limited. Specifically, a quantitative definition of collaborative
information is missing, its manifestation within user-item interactions remains
unclear, and its impact on recommendation performance is largely unknown. To
bridge this gap, this work conducts a systematic investigation of collaborative
information. We begin by clarifying collaborative information in terms of item
co-occurrence patterns, identifying its main characteristics, and presenting a
quantitative definition. We then estimate the distribution of collaborative
information from several aspects, shedding light on how collaborative
information is structured in practice. Furthermore, we evaluate the impact of
collaborative information on the performance of various recommendation
algorithms. Finally, we highlight challenges in effectively capturing
collaborative information and outlook promising directions for future research.
By establishing an empirical framework, we uncover many insightful observations
that advance our understanding of collaborative information and offer valuable
guidelines for developing more effective recommender systems.

</details>


### [400] [Fine-Tuning Diffusion-Based Recommender Systems via Reinforcement Learning with Reward Function Optimization](https://arxiv.org/abs/2511.06937)
*Yu Hou,Hua Li,Ha Young Kim,Won-Yong Shin*

Main category: cs.IR

TL;DR: ReFiT是一个将强化学习微调集成到基于扩散的推荐系统中的新框架，通过将去噪轨迹建模为马尔可夫决策过程，并使用协作信号感知的奖励函数来直接反映推荐质量，实现了对扩散推荐器的有效后训练微调。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在推荐系统中表现出色，但从头训练计算成本高且收敛后收益递减。为解决这些问题，需要一种能够有效微调扩散推荐器的方法。

Method: 将去噪轨迹建模为马尔可夫决策过程，设计协作信号感知的奖励函数，使用策略梯度优化来最大化观察交互的确切对数似然，实现强化学习微调。

Result: 在广泛真实数据集上的实验表明，ReFiT在顺序推荐上性能提升高达36.3%，具有线性复杂度的高效性，并在多个基于扩散的推荐场景中表现出良好的泛化能力。

Conclusion: ReFiT框架通过强化学习微调显著提升了扩散推荐系统的性能，同时保持了计算效率，为扩散推荐器的后训练优化提供了有效解决方案。

Abstract: Diffusion models recently emerged as a powerful paradigm for recommender
systems, offering state-of-the-art performance by modeling the generative
process of user-item interactions. However, training such models from scratch
is both computationally expensive and yields diminishing returns once
convergence is reached. To remedy these challenges, we propose ReFiT, a new
framework that integrates Reinforcement learning (RL)-based Fine-Tuning into
diffusion-based recommender systems. In contrast to prior RL approaches for
diffusion models depending on external reward models, ReFiT adopts a
task-aligned design: it formulates the denoising trajectory as a Markov
decision process (MDP) and incorporates a collaborative signal-aware reward
function that directly reflects recommendation quality. By tightly coupling the
MDP structure with this reward signal, ReFiT empowers the RL agent to exploit
high-order connectivity for fine-grained optimization, while avoiding the noisy
or uninformative feedback common in naive reward designs. Leveraging policy
gradient optimization, ReFiT maximizes exact log-likelihood of observed
interactions, thereby enabling effective post hoc fine-tuning of diffusion
recommenders. Comprehensive experiments on wide-ranging real-world datasets
demonstrate that the proposed ReFiT framework (a) exhibits substantial
performance gains over strong competitors (up to 36.3% on sequential
recommendation), (b) demonstrates strong efficiency with linear complexity in
the number of users or items, and (c) generalizes well across multiple
diffusion-based recommendation scenarios. The source code and datasets are
publicly available at https://anonymous.4open.science/r/ReFiT-4C60.

</details>


### [401] [Wavelet Enhanced Adaptive Frequency Filter for Sequential Recommendation](https://arxiv.org/abs/2511.07028)
*Huayang Xu,Huanhuan Yuan,Guanfeng Liu,Junhua Fang,Lei Zhao,Pengpeng Zhao*

Main category: cs.IR

TL;DR: 提出了一种基于小波增强自适应频率滤波的序列推荐方法，通过动态频率域滤波和小波特征增强两个模块，解决现有频率域方法在个性化过滤和非平稳信号处理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有频率域推荐方法存在两个主要问题：使用静态过滤器忽略行为模式的个性化特点，以及全局离散傅里叶变换会模糊非平稳信号和短期波动。

Method: 包含动态频率域滤波和小波特征增强两个模块。前者根据行为序列动态调整滤波操作提取个性化全局信息，后者集成小波变换重构序列以增强非平稳信号和短期波动。

Result: 在四个广泛使用的基准数据集上的大量实验证明了该方法的优越性。

Conclusion: 该方法在长序列推荐场景中实现了全面的性能和效率优化。

Abstract: Sequential recommendation has garnered significant attention for its ability
to capture dynamic preferences by mining users' historical interaction data.
Given that users' complex and intertwined periodic preferences are difficult to
disentangle in the time domain, recent research is exploring frequency domain
analysis to identify these hidden patterns. However, current
frequency-domain-based methods suffer from two key limitations: (i) They
primarily employ static filters with fixed characteristics, overlooking the
personalized nature of behavioral patterns; (ii) While the global discrete
Fourier transform excels at modeling long-range dependencies, it can blur
non-stationary signals and short-term fluctuations. To overcome these
limitations, we propose a novel method called Wavelet Enhanced Adaptive
Frequency Filter for Sequential Recommendation. Specifically, it consists of
two vital modules: dynamic frequency-domain filtering and wavelet feature
enhancement. The former is used to dynamically adjust filtering operations
based on behavioral sequences to extract personalized global information, and
the latter integrates wavelet transform to reconstruct sequences, enhancing
blurred non-stationary signals and short-term fluctuations. Finally, these two
modules work to achieve comprehensive performance and efficiency optimization
in long sequential recommendation scenarios. Extensive experiments on four
widely-used benchmark datasets demonstrate the superiority of our work.

</details>


### [402] [Hard vs. Noise: Resolving Hard-Noisy Sample Confusion in Recommender Systems via Large Language Models](https://arxiv.org/abs/2511.07295)
*Tianrui Song,Wen-Shuo Chao,Hao Liu*

Main category: cs.IR

TL;DR: LLMHNI框架利用大语言模型生成的两个辅助用户-物品相关性信号来区分推荐系统中的硬样本和噪声样本，解决硬-噪声混淆问题，提升去噪和推荐性能。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中的隐式反馈存在噪声（如误点击、位置偏差），传统方法通过损失值等模式识别噪声样本，但硬样本和噪声样本具有相似模式，导致硬-噪声混淆问题，而硬样本对建模用户偏好至关重要。

Method: 提出LLMHNI框架：1）从LLM编码的嵌入中获取用户-物品语义相关性，用于负采样选择硬负样本并过滤噪声假负样本；2）使用目标对齐策略将LLM嵌入投影到优化的用户-物品相关性建模空间；3）利用LLM推断的逻辑相关性识别硬样本和噪声样本，通过跨图对比对齐指导去噪；4）采用图对比学习策略对齐随机边丢弃视图的表征来抑制不可靠边。

Result: 实证结果表明LLMHNI显著提高了去噪和推荐性能。

Conclusion: LLMHNI通过利用LLM生成的语义和逻辑相关性信号有效区分硬样本和噪声样本，解决了推荐系统中的硬-噪声混淆问题，提升了推荐系统的性能。

Abstract: Implicit feedback, employed in training recommender systems, unavoidably
confronts noise due to factors such as misclicks and position bias. Previous
studies have attempted to identify noisy samples through their diverged data
patterns, such as higher loss values, and mitigate their influence through
sample dropping or reweighting. However, we observed that noisy samples and
hard samples display similar patterns, leading to hard-noisy confusion issue.
Such confusion is problematic as hard samples are vital for modeling user
preferences. To solve this problem, we propose LLMHNI framework, leveraging two
auxiliary user-item relevance signals generated by Large Language Models (LLMs)
to differentiate hard and noisy samples. LLMHNI obtains user-item semantic
relevance from LLM-encoded embeddings, which is used in negative sampling to
select hard negatives while filtering out noisy false negatives. An objective
alignment strategy is proposed to project LLM-encoded embeddings, originally
for general language tasks, into a representation space optimized for user-item
relevance modeling. LLMHNI also exploits LLM-inferred logical relevance within
user-item interactions to identify hard and noisy samples. These LLM-inferred
interactions are integrated into the interaction graph and guide denoising with
cross-graph contrastive alignment. To eliminate the impact of unreliable
interactions induced by LLM hallucination, we propose a graph contrastive
learning strategy that aligns representations from randomly edge-dropped views
to suppress unreliable edges. Empirical results demonstrate that LLMHNI
significantly improves denoising and recommendation performance.

</details>
