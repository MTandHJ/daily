<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 184]
- [cs.AI](#cs.AI) [Total: 67]
- [cs.IR](#cs.IR) [Total: 16]
- [cs.CY](#cs.CY) [Total: 22]
- [cs.LG](#cs.LG) [Total: 109]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study](https://arxiv.org/abs/2601.11612)
*Arnav S. Sonavane*

Main category: cs.CV

TL;DR: 本文研究了领域特定自监督预训练对农业病害分类的影响，发现SimCLR预训练在仅3000张未标记农业图像上就能带来+4.57%的准确率提升，超过了层次架构设计带来的+3.70%增益。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在农业病害分类任务中，领域特定自监督预训练与层次视觉transformer架构的相对重要性，为实践者提供指导。

Method: 使用HierarchicalViT（HVT）这一Swin风格的层次transformer，在三个数据集（Cotton Leaf Disease、PlantVillage、PlantDoc）上进行评估。采用SimCLR自监督预训练方法，比较不同架构（HVT、Swin-Base、ViT-Base）在相同预训练条件下的性能差异。

Result: SimCLR预训练在仅3000张未标记农业图像上带来+4.57%准确率提升，超过层次架构设计的+3.70%增益。HVT-Base（78M参数）在参数匹配情况下达到88.91%准确率，优于Swin-Base（88M参数）的87.23%。HVT的校准分析显示ECE为3.56%（温度缩放后降至1.52%）。

Conclusion: 自监督预训练的收益是架构无关的，实践者应优先考虑领域数据收集而非架构选择。领域特定自监督预训练对农业病害分类具有显著提升效果。

Abstract: We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: https://github.com/w2sg-arnav/HierarchicalViT

</details>


### [2] [Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning](https://arxiv.org/abs/2601.11614)
*Jason Qiu*

Main category: cs.CV

TL;DR: 提出基于3D TransUNet的框架，从常规T1加权MRI预测扩散MRI指标（FA和MD），提升阿尔茨海默病早期检测效果


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测至关重要，但常规T1加权MRI只能检测晚期宏观结构变化，而扩散MRI能检测早期微结构异常但扫描时间长且易受运动伪影影响，限制了临床常规使用

Method: 采用3D TransUNet图像合成框架，直接从T1加权MRI预测分数各向异性（FA）和平均扩散率（MD）图

Result: 模型生成高质量扩散图，结构相似性指数（SSIM）超过0.93，与真实扩散MRI的皮尔逊相关系数>0.94；合成特征使AD分类准确率提升5%（78.75%→83.75%），轻度认知障碍检测提升12.5%

Conclusion: 高质量扩散微结构信息可从常规T1加权MRI推断，将多模态成像优势扩展到无扩散数据场景，减少扫描时间同时保留互补信息，有望提升AD诊断的可及性、效率和准确性

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.

</details>


### [3] [PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM](https://arxiv.org/abs/2601.11617)
*Xu Wang,Boyao Han,Xiaojun Chen,Ying Liu,Ruihui Li*

Main category: cs.CV

TL;DR: PointSLAM++是一种新型RGB-D SLAM系统，使用分层约束神经高斯表示来保持结构一致性，通过渐进姿态优化减少深度噪声，并利用动态神经表示图实时适应场景细节，在重建精度和渲染质量上优于现有3DGS-based SLAM方法。


<details>
  <summary>Details</summary>
Motivation: 当前SLAM方法在深度噪声存在时难以保持结构一致性和鲁棒的姿态估计，这对于机器人和增强现实应用中的实时3D重建至关重要。

Method: 1) 使用分层约束神经高斯表示来保持结构关系并生成高斯基元进行场景建图；2) 采用渐进姿态优化来减轻深度传感器噪声；3) 利用动态神经表示图根据局部几何复杂度调整高斯节点分布，实时适应复杂场景细节。

Result: 实验结果表明PointSLAM++在重建精度和渲染质量上优于现有的3DGS-based SLAM方法，能够实现高精度3D建图和逼真的场景渲染。

Conclusion: PointSLAM++通过分层约束神经高斯表示、渐进姿态优化和动态神经表示图的组合，为大规模增强现实和机器人应用提供了优势，实现了结构一致的高精度实时3D重建。

Abstract: Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.

</details>


### [4] [Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings](https://arxiv.org/abs/2601.11627)
*Hassan Ugail,Jan Ritch-Frel,Irina Matuzava*

Main category: cs.CV

TL;DR: 提出基于单类自编码器的历史绘画认证框架，使用手工特征在有限参考数据下实现艺术家作品验证，在900次测试中达到83.3%真接受率和9.5%假接受率。


<details>
  <summary>Details</summary>
Motivation: 纸质作品的身份验证和归属认定在文化遗产领域面临持续挑战，特别是在参考语料库较小且风格线索主要通过线条和有限色调变化表达的情况下。需要一种能够在小数据环境下提供可重复定量证据的方法来补充传统鉴赏。

Method: 采用基于单类自编码器的验证框架，使用手工特征向量（包括傅里叶域能量、香农熵、全局对比度、基于GLCM的同质性、盒计数分形复杂度估计），在来自多个博物馆的认证素描作品上训练10个艺术家特定的验证器，采用生物特征式协议进行评估。

Result: 在900次验证决策（90次真实试验和810次冒名试验）中，系统在选定操作点达到83.3%的真接受率和9.5%的假接受率。性能因艺术家而异，某些验证器接近零假接受率，而其他验证器存在较高混淆性。错误接受分析显示与风格接近性和共享绘画惯例一致的结构化错误路径。

Conclusion: 该方法旨在通过提供适用于历史素描归属常见的数据稀缺环境的可重复定量证据来补充而非取代传统鉴赏。研究还指出了需要更严格控制数字化伪影和阈值校准，并展示了错误接受模式与艺术风格接近性的相关性。

Abstract: Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.

</details>


### [5] [A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow](https://arxiv.org/abs/2601.11630)
*Haonan Wei,Linyuan Wang,Nuolin Sun,Zhizhong Zheng,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: 提出SLT（单层Transformer）方法，通过知识蒸馏将FreeFlow模型的28层Transformer压缩为单层共享DiT块，参数量从675M降至4.3M，利用快速采样能力筛选高质量噪声点提升FreeFlow生成质量


<details>
  <summary>Details</summary>
Motivation: 当前流匹配方法致力于将扩散模型的迭代生成过程压缩到少数甚至单步，但现有方法如FreeFlow仍使用28层Transformer架构。观察到该架构可视为沿深度轴的ODE欧拉离散化方案，希望通过知识蒸馏进一步压缩模型规模，同时利用小模型的快速采样能力筛选高质量初始噪声点来提升生成质量

Method: 将FreeFlow的28层Transformer视为深度轴ODE的欧拉离散化，提出SLT方法：1）使用单层共享DiT块近似28层教师模型的特征演化；2）训练时匹配教师在多个深度补丁的中间特征，融合补丁级表示；3）同时对齐教师的最终速度预测；4）利用小模型快速采样能力在噪声空间筛选高质量初始点供教师模型使用

Result: 成功将参数量从675M压缩至4.3M（减少99%以上）。在相当于教师模型两次随机采样的时间预算内，可进行超过100次噪声筛选，使用筛选出的高质量初始点通过教师模型生成高质量样本。有效避免了有限采样次数下低质量初始噪声引起的质量波动，显著提升了一步生成的稳定性和平均生成质量

Conclusion: SLT方法通过知识蒸馏实现了流匹配模型的极端压缩，同时利用小模型的快速采样能力为教师模型筛选高质量初始噪声点，在保持生成质量的同时大幅提升采样效率和稳定性，为一步生成方法提供了新的优化思路

Abstract: Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.

</details>


### [6] [KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering](https://arxiv.org/abs/2601.11632)
*Zhiyang Li,Ao Ke,Yukun Cao,Xike Xie*

Main category: cs.CV

TL;DR: KG-ViP是一个统一框架，通过融合场景图和常识图来解决MLLMs在VQA中的知识幻觉和细粒度视觉感知不足问题，显著提升VQA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉问答中存在两个主要限制：知识幻觉和细粒度视觉感知不足。场景图和常识图分别提供了解决这两个问题的互补方案，但先前工作通常将它们孤立处理，忽视了它们的协同潜力。

Method: 提出KG-ViP统一框架，通过新颖的检索-融合流程，利用查询作为语义桥梁逐步整合场景图和常识图，合成统一的结构化上下文，促进可靠的多模态推理。

Result: 在FVQA 2.0+和MVQA基准测试上的广泛实验表明，KG-ViP显著优于现有的VQA方法。

Conclusion: 通过融合场景图和常识图，KG-ViP有效解决了MLLMs在VQA中的知识幻觉和视觉感知不足问题，展示了两种图结构协同工作的强大潜力。

Abstract: Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.

</details>


### [7] [Beyond Accuracy: Evaluating Grounded Visual Evidence in Thinking with Images](https://arxiv.org/abs/2601.11633)
*Xuchen Li,Xuzhao Li,Renjie Pi,Shiyu Hu,Jian Zhao,Jiahui Gao*

Main category: cs.CV

TL;DR: ViEBench是一个过程可验证的视觉推理基准测试，通过专家标注的视觉证据和多场景高分辨率图像，评估视觉语言模型是否能够忠实利用细粒度视觉线索进行多步推理。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型评估主要依赖结果导向的准确性，缺乏评估模型是否能够准确利用细粒度视觉线索进行多步推理的能力，无法验证推理过程的真实性。

Method: 构建包含200个多场景高分辨率图像和专家标注视觉证据的数据集，将任务按难度分为感知和推理两个维度，引入双轴矩阵提供细粒度评估指标，通过四个诊断象限透明诊断模型行为。

Result: 实验发现：(1) 视觉语言模型有时能基于不相关区域得出正确答案；(2) 模型可能成功定位正确证据但仍无法利用其得出准确结论。ViEBench能够更可解释地评估模型推理有效性。

Conclusion: ViEBench作为一个过程可验证的基准测试，能够更全面、可解释地评估视觉语言模型的视觉推理能力，特别是对需要利用局部视觉细节和先验知识的推理任务。

Abstract: Despite the remarkable progress of Vision-Language Models (VLMs) in adopting "Thinking-with-Images" capabilities, accurately evaluating the authenticity of their reasoning process remains a critical challenge. Existing benchmarks mainly rely on outcome-oriented accuracy, lacking the capability to assess whether models can accurately leverage fine-grained visual cues for multi-step reasoning. To address these limitations, we propose ViEBench, a process-verifiable benchmark designed to evaluate faithful visual reasoning. Comprising 200 multi-scenario high-resolution images with expert-annotated visual evidence, ViEBench uniquely categorizes tasks by difficulty into perception and reasoning dimensions, where reasoning tasks require utilizing localized visual details with prior knowledge. To establish comprehensive evaluation criteria, we introduce a dual-axis matrix that provides fine-grained metrics through four diagnostic quadrants, enabling transparent diagnosis of model behavior across varying task complexities. Our experiments yield several interesting observations: (1) VLMs can sometimes produce correct final answers despite grounding on irrelevant regions, and (2) they may successfully locate the correct evidence but still fail to utilize it to reach accurate conclusions. Our findings demonstrate that ViEBench can serve as a more explainable and practical benchmark for comprehensively evaluating the effectiveness agentic VLMs. The codes will be released at: https://github.com/Xuchen-Li/ViEBench.

</details>


### [8] [Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos](https://arxiv.org/abs/2601.11635)
*Anil Egin,Andrea Tangherloni,Antitza Dantcheva*

Main category: cs.CV

TL;DR: 提出Anon-NET框架，通过扩散生成模型进行人脸视频匿名化，在保护身份隐私的同时保留年龄、性别、种族、姿态和表情等属性


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉下游任务（如表情识别、人员跟踪、动作识别）中分析视频时，需要保护隐私同时保留有用的视觉属性

Method: 使用基于扩散的生成模型进行人脸修复，通过高级属性识别和运动感知表情转移引导，然后通过视频驱动动画对去识别化的人脸进行动画处理

Result: 在VoxCeleb2、CelebV-HQ和HDTF数据集上的实验表明，Anon-NET能有效混淆身份，同时保持视觉真实性和时间一致性

Conclusion: Anon-NET提供了一个统一的框架，能够在人脸视频匿名化中平衡隐私保护和有用视觉属性的保留

Abstract: Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.

</details>


### [9] [Confident Learning for Object Detection under Model Constraints](https://arxiv.org/abs/2601.11640)
*Yingda Yu,Jiaqi Xuan,Shuhui Shi,Xuanyu Teng,Shuyang Xu,Guanchao Tong*

Main category: cs.CV

TL;DR: 提出MDDC框架，通过数据质量优化提升边缘设备杂草检测性能，在固定轻量检测器下实现5-25%的mAP提升


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的农业杂草检测面临模型容量、计算资源和实时推理延迟的严格限制，无法通过模型扩展或集成来提升性能，需要数据层面的优化方案

Method: 提出模型驱动的数据校正(MDDC)框架，通过自动化错误分析将检测失败分为四类（假阴性、假阳性、类别混淆、定位错误），采用结构化的训练-修复-再训练流程和版本控制数据管理

Result: 在多个杂草检测数据集上，使用固定轻量检测器(YOLOv8n)实现了5-25%的mAP@0.5一致提升，表明系统化数据质量优化能有效缓解固定模型容量下的性能瓶颈

Conclusion: 在模型容量受限的边缘设备杂草检测场景中，通过系统化的数据质量优化框架可以有效提升检测性能，为资源受限环境提供了可行的性能提升路径

Abstract: Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.

</details>


### [10] [Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers](https://arxiv.org/abs/2601.11641)
*Yuxi Liu,Yipeng Hu,Zekun Zhang,Kunze Jiang,Kun Yuan*

Main category: cs.CV

TL;DR: MOD-DiT提出了一种无需采样的动态注意力框架，通过两阶段过程准确建模视频生成中的注意力模式，解决了传统稀疏注意力方法在质量和效率上的限制。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在视频生成中面临自注意力机制二次复杂度的限制，现有稀疏注意力方法要么依赖过于简化的静态模式，要么需要计算昂贵的采样操作来实现动态稀疏性，导致模式预测不准确和生成质量下降。

Method: MOD-DiT采用两阶段过程：1）利用早期去噪步骤的先验信息，采用分布式混合方法建模高效的线性近似模型，预测特定去噪区间的掩码模式；2）在线块掩码策略动态应用这些预测的掩码，同时保持历史稀疏信息，无需重复采样操作。

Result: 在多个基准测试和模型架构上的广泛评估显示，MOD-DiT实现了持续的加速和质量提升，验证了其在高效高质量视频生成中的有效性。

Conclusion: MOD-DiT克服了传统稀疏注意力方法的计算限制，为高效高质量的视频生成提供了有效的动态注意力框架，无需采样操作即可准确建模注意力模式。

Abstract: While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \underline{\textbf{M}}ixtrue-\underline{\textbf{O}}f-\underline{\textbf{D}}istribution \textbf{DiT} (\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.

</details>


### [11] [PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models](https://arxiv.org/abs/2601.11642)
*Abbas Alzubaidi,Ali Al-Bayaty*

Main category: cs.CV

TL;DR: 研究人员开发了一种基于物理的合成模拟框架，用于生成可控的膝关节X光扫描图像，无需患者参与，解决了数据隐私和获取难题，并用于训练机器学习模型进行骨关节炎分级。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎是全球致残的主要原因，目前主要依赖主观的放射学分级（如Kellgren-Lawrence量表）。人工智能和影像组学提供了定量评估工具，但需要大量标注良好的X光图像数据集，而这些数据由于隐私、管理和资源限制往往难以获取。

Method: 引入基于物理的合成模拟框架，从参数化解剖模型生成可控的膝关节前后位X光投影。创建了180名受试者（260个膝盖）的虚拟队列，每个膝盖在三种协议下成像（参考、低剂量和几何偏移）。自动定位内侧关节区域，使用影像生物标志物标准化倡议进行预处理和分析。采用逻辑回归、随机森林和梯度提升三种机器学习模型进行二分类（KL-like "0" vs. "2"）和三分类（0-2）预测。

Result: 在IBSI协议内、跨协议和多协议场景下评估了模型的鲁棒性。通过类内相关系数评估了特征在不同采集条件下的稳定性。

Conclusion: 基于物理的合成模拟框架能够生成可控的X光扫描图像，无需患者参与，解决了数据隐私和获取问题，为膝关节骨关节炎的AI评估提供了可行的替代数据源。

Abstract: Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like "0" vs. "2") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.

</details>


### [12] [Predicting When to Trust Vision-Language Models for Spatial Reasoning](https://arxiv.org/abs/2601.11644)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉的置信度估计框架，通过独立的几何验证来预测何时信任视觉语言模型的空间推理预测，显著提升了空间关系判断的可靠性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在多模态任务中表现出色，但在空间推理方面存在系统性失败（准确率仅49%-54%）。为了在机器人和自主系统中安全部署，需要预测何时信任VLM的空间预测，而不是盲目接受所有输出。

Method: 提出基于视觉的置信度估计框架，通过独立的几何验证来验证VLM预测。融合四个信号：VLM声明与坐标的几何对齐、空间重叠的模糊性、检测质量以及VLM内部不确定性，使用梯度提升进行融合。

Result: 在BLIP-2上达到0.674 AUROC（比文本基线提升34.0%），在CLIP上达到0.583 AUROC（提升16.1%）。在60%目标准确率下，覆盖率达到61.9%（基线27.6%，提升2.2倍）。特征分析显示视觉信号贡献87.4%的重要性。

Conclusion: 外部几何验证优于自我评估，能够可靠地预测VLM空间预测的可信度。在场景图构建中，基于置信度的剪枝将精度从52.1%提升到78.3%，同时保留了68.2%的边。

Abstract: Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.

</details>


### [13] [IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation](https://arxiv.org/abs/2601.11645)
*Ujjwal Jain,Oshin Misra,Roshni Chakraborty,Mahua Bhattacharya*

Main category: cs.CV

TL;DR: 提出IMSALHO框架，结合多尺度注意力与混合损失优化，用于荧光显微镜神经元细胞分割，解决细胞密度不均、形态复杂重叠和类别不平衡问题，在FNC数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜神经元细胞分割面临密集与稀疏细胞共存、复杂重叠形态、严重类别不平衡等挑战，传统深度学习模型难以保持精细拓扑细节和准确边界划分。

Method: 提出IMSALHO框架，包含多尺度密集块捕获不同感受野特征，分层注意力机制聚焦显著形态特征，以及结合Tversky损失、Focal损失、拓扑感知中心线Dice损失和轮廓加权边界损失的混合损失函数。

Result: 在公开FNC数据集上，模型在密集和稀疏困难案例中达到81.4%精确率、82.7%宏观F1分数、83.3%微观F1分数和99.5%平衡准确率，优于现有最先进架构。

Conclusion: 该工作为适用于多种生物医学成像模式的通用分割模型奠定了基础，推动AI辅助分析向高通量神经生物学流程发展。

Abstract: Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.

</details>


### [14] [Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification](https://arxiv.org/abs/2601.11651)
*Miriam Doh,Aditya Gulati,Corina Canali,Nuria Oliver*

Main category: cs.CV

TL;DR: 该研究揭示了文本到图像生成AI中的算法外貌歧视现象，发现模型系统性地将面部吸引力与积极属性关联，并在性别分类算法中存在显著偏见，加剧了现有不平等。


<details>
  <summary>Details</summary>
Motivation: 研究动机是调查文本到图像生成AI中存在的算法外貌歧视现象，即基于外貌的系统性优待，以及这种偏见如何在下游性别分类任务中体现和加剧社会不平等。

Method: 使用Stable Diffusion 2.1和3.5 Medium生成了26,400张合成人脸，分析生成AI模型如何系统性地将面部吸引力与积极属性关联，并评估三种性别分类算法在不同属性输入下的性别偏见。

Result: 研究发现：1）T2I模型系统性地编码了吸引力与积极属性的关联；2）性别分类系统存在显著偏见，女性面孔（特别是带有负面属性的）误分类率远高于男性；3）新模型通过年龄同质化、性别化曝光模式和地理简化加剧了美学约束。

Conclusion: 算法外貌歧视是AI视觉系统中系统性运作的基础设施，通过表征和识别两方面加剧现有不平等。这些偏见反映了社会构建的偏见而非经验事实，揭示了AI系统需要解决的系统性偏见问题。

Abstract: This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.
  Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.

</details>


### [15] [PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation](https://arxiv.org/abs/2601.11654)
*Kaustubh Shivshankar Shejole,Gaurav Mishra*

Main category: cs.CV

TL;DR: 提出基于像素段相似度指数(PSSI)和最大生成树(MaxST)的交互式图分割方法，在GrabCut和Images250数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有交互式图分割方法存在计算成本高、对用户交互敏感、前景背景颜色相似时性能下降等问题，需要更鲁棒的相似度度量方法。

Method: 提出像素段相似度指数(PSSI)，利用通道间相似度的调和均值结合像素强度和空间平滑特征；使用MeanShift进行低层分割，构建像素-段图，用PSSI计算边权重，最后用最大生成树(MaxST)进行分割。

Result: 在GrabCut和Images250数据集上，该方法在Jaccard指数、F1分数、执行时间和平均误差方面均优于AMOE、OneCut、SSNCut等现有图分割方法。

Conclusion: 提出的PSSI-MaxST框架通过结合颜色相似度、平滑性、纹理、形状和强局部连接性，实现了更准确高效的交互式图像分割。

Abstract: Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: https://github.com/KaustubhShejole/PSSI-MaxST.

</details>


### [16] [UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM](https://arxiv.org/abs/2601.11665)
*Amir Farzin Nikkhah,Dong Chen,Bradford Campbell,Somayeh Asadi,Arsalan Heydarian*

Main category: cs.CV

TL;DR: 这篇综述论文系统分析了无人机在AEC+FM领域基础设施检测中的应用，总结了数据采集、建模、缺陷检测和决策支持的方法论，提出了一个融合多模态数据和自适应路径规划的框架，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 无人机正在改变建筑、工程、施工和设施管理领域的基础设施检测方式，但现有方法在实时处理、多模态数据融合和泛化能力方面仍面临挑战，需要系统性的框架来整合先进技术并提高检测的准确性和可靠性。

Method: 通过综合分析150多项研究，提出了一个集成RGB图像、LiDAR和热成像传感器的多模态数据融合框架，结合基于transformer的架构和动态自适应路径规划，形成从数据采集到决策支持的完整工作流程。

Result: 无人机已在结构健康监测、灾害响应、城市基础设施管理、能源效率评估和文化遗产保护等多个领域证明其价值，提出的框架能够有效检测结构缺陷、热异常和几何不一致问题，提供精确且可操作的见解。

Conclusion: 无人机为基础设施工检测带来了革命性变化，但需要进一步发展轻量级AI模型、自适应飞行规划、合成数据集和更丰富的模态融合技术，以应对实时处理、数据融合和泛化能力等挑战，推动现代基础设施检测的优化。

Abstract: Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.

</details>


### [17] [MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models](https://arxiv.org/abs/2601.11666)
*Muhammad Imran,Chi Lee,Yugyung Lee*

Main category: cs.CV

TL;DR: MATEX框架通过多尺度注意力、文本引导空间先验和层一致性分析，提升医学视觉语言模型的可解释性，在胸部X光数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有医学视觉语言模型解释方法在空间精度、解剖学基础和注意力粒度方面的局限性，提高模型在放射学应用中的可信度和透明度。

Method: 结合多层注意力展开、文本引导空间先验和层一致性分析，生成精确、稳定且具有临床意义的梯度归因图。

Result: 在MS-CXR数据集上评估，MATEX在空间精度和与专家标注结果的对齐度方面均优于最先进的M2IB方法。

Conclusion: MATEX框架能够生成更忠实、可解释的模型解释，有望增强放射学AI应用中的信任和透明度。

Abstract: We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.

</details>


### [18] [Generating metamers of human scene understanding](https://arxiv.org/abs/2601.11675)
*Ritik Raina,Abe Leite,Alexandros Graikos,Seoyoung Ahn,Dimitris Samaras,Gregory J. Zelinsky*

Main category: cs.CV

TL;DR: MetamerGen是一个潜在扩散模型，通过结合周边视觉获得的场景要点信息和注视点获得的高分辨率信息，生成与人类场景理解对齐的图像元刺激。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过结合周边低分辨率"要点"信息和注视点的高分辨率信息来理解场景。本研究旨在创建能够生成与人类潜在场景表征对齐的图像的工具，以更好地理解人类场景理解机制。

Method: 开发了MetamerGen，一个双流潜在扩散模型，使用DINOv2令牌融合注视区域的详细特征和周边降级特征。通过行为实验（相同-不同判断任务）评估生成图像与人类潜在场景表征的感知对齐程度。

Result: MetamerGen能够生成与人类场景表征对齐的图像元刺激。当生成场景基于观看者自身注视区域时，高层语义对齐最能预测元刺激性质。概念验证分析揭示了影响人类判断的多个视觉处理层次特征。

Conclusion: MetamerGen是理解场景理解的强大工具，能够生成与人类潜在场景表征对齐的图像，为研究人类视觉处理机制提供了新方法。

Abstract: Human vision combines low-resolution "gist" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. "foveated") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a "same" or "different" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.

</details>


### [19] [Conformal Point and the Calibrated Conic](https://arxiv.org/abs/2601.11679)
*Richard Hartley*

Main category: cs.CV

TL;DR: 论文探讨了共形点和校准圆锥的概念及其相互关系，这些概念有助于图像几何的可视化，并提供了计算图像中角度和方向等几何属性的直观方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于开发更直观的图像几何可视化工具，通过共形点和校准圆锥的概念来简化图像几何计算，特别是角度和方向的计算。

Method: 论文介绍了共形点和校准圆锥的数学概念，并探讨了它们之间的相互关系。这些概念基于图像几何理论，用于提供更直观的几何计算框架。

Result: 研究结果表明，共形点和校准圆锥的概念能够有效帮助图像几何的可视化理解，并为计算图像中的角度和方向等几何属性提供了直观的方法。

Conclusion: 共形点和校准圆锥是理解图像几何的有用工具，它们之间的关系提供了直观的几何计算方法，特别是在角度和方向计算方面具有实际应用价值。

Abstract: This gives some information about the conformal point and the calibrating conic, and their relationship one to the other. These concepts are useful for visualizing image geometry, and lead to intuitive ways to compute geometry, such as angles and directions in an image.

</details>


### [20] [Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search](https://arxiv.org/abs/2601.13719)
*Xinlei Yin,Xiulian Peng,Xiao Li,Zhiwei Xiong,Yan Lu*

Main category: cs.CV

TL;DR: HAVEN框架通过视听实体凝聚和分层视频索引结合智能搜索，解决了长视频理解中的信息碎片化和全局连贯性问题，在LVBench上达到84.1%的总体准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于分块策略和检索增强生成的长视频理解方法存在信息碎片化和全局连贯性丢失的问题，需要一种能够保持语义一致性和全局推理能力的统一框架。

Method: HAVEN框架：1）通过整合视觉和听觉流的实体级表示来保持语义一致性；2）将内容组织成全局摘要、场景、片段和实体四个层次的结构化层次；3）采用智能搜索机制在这些层次间进行动态检索和推理。

Result: 在LVBench上达到84.1%的总体准确率，在具有挑战性的推理类别中达到80.1%的出色表现，在时间连贯性、实体一致性和检索效率方面表现优异。

Conclusion: HAVEN框架通过结构化、多模态推理实现了对长视频的全面且上下文一致的理解，为长视频理解建立了新的技术标杆。

Abstract: Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.

</details>


### [21] [SemAlign: Language Guided Semi-supervised Domain Generalization](https://arxiv.org/abs/2601.11724)
*Muditha Fernando,Kajhanan Kailainathan,Krishnakanth Nagaratnam,Isuranga Udaravi Bandara Senavirathne,Ranga Rodrigo*

Main category: cs.CV

TL;DR: 本文提出了一种新的半监督域泛化方法，通过将模型中间特征与视觉语言模型的语义丰富特征空间对齐来提升性能，同时采用图像级增强和输出级正则化策略来提高数据利用率和减少过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有SSDG方法过度关注伪标签准确性，而忽视了训练期间最大化数据利用的重要性，这限制了性能提升潜力。本文旨在通过更有效的数据利用和特征对齐来解决这一问题。

Method: 1) 将模型中间特征与视觉语言模型的语义丰富且泛化的特征空间对齐，以促进域不变性；2) 采用有效的图像级增强策略；3) 实施输出级正则化策略来提高数据利用率和减少过拟合。

Result: 在四个基准测试上与现有SSDG基线方法的广泛实验表明，该方法在定性和定量上都达到了最先进的结果。

Conclusion: 通过将模型特征与VLM特征空间对齐，并配合增强和正则化策略，可以有效提升SSDG性能，超越了现有方法过度关注伪标签准确性的局限性。

Abstract: Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.

</details>


### [22] [SpaRRTa: A Synthetic Benchmark for Evaluating Spatial Intelligence in Visual Foundation Models](https://arxiv.org/abs/2601.11729)
*Turhan Can Kargin,Wojciech Jasiński,Adam Pardyl,Bartosz Zieliński,Marcin Przewięźlikowski*

Main category: cs.CV

TL;DR: 论文提出了SpaRRTa基准测试，用于评估视觉基础模型的空间关系识别能力，发现现有模型在空间推理方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型（如DINO、CLIP）在语义理解方面表现出色，但空间推理能力有限，限制了它们在具身系统中的应用。虽然近期研究尝试将3D任务（如深度估计）融入训练，但模型在不同空间任务上的表现不一致，需要评估它们是否真正具备空间意识还是仅仅过拟合特定3D目标。

Method: 提出了空间关系识别任务（SpaRRTa）基准测试，该基准生成任意数量的逼真图像，包含多样场景和完全可控的物体排列，并提供可自由访问的空间标注。通过该基准评估了一系列最先进的视觉基础模型。

Result: 评估揭示了不同视觉基础模型在空间推理能力方面存在显著差异。分析提供了对现代视觉基础模型中支持或阻碍空间意识机制的见解。

Conclusion: SpaRRTa基准可作为指导未来空间感知视觉模型开发的有用工具，有助于推动具备更高级人类空间理解能力的模型发展。

Abstract: Visual Foundation Models (VFMs), such as DINO and CLIP, excel in semantic understanding of images but exhibit limited spatial reasoning capabilities, which limits their applicability to embodied systems. As a result, recent work incorporates some 3D tasks (such as depth estimation) into VFM training. However, VFM performance remains inconsistent across other spatial tasks, raising the question of whether these models truly have spatial awareness or overfit to specific 3D objectives. To address this question, we introduce the Spatial Relation Recognition Task (SpaRRTa) benchmark, which evaluates the ability of VFMs to identify relative positions of objects in the image. Unlike traditional 3D objectives that focus on precise metric prediction (e.g., surface normal estimation), SpaRRTa probes a fundamental capability underpinning more advanced forms of human-like spatial understanding. SpaRRTa generates an arbitrary number of photorealistic images with diverse scenes and fully controllable object arrangements, along with freely accessible spatial annotations. Evaluating a range of state-of-the-art VFMs, we reveal significant disparities between their spatial reasoning abilities. Through our analysis, we provide insights into the mechanisms that support or hinder spatial awareness in modern VFMs. We hope that SpaRRTa will serve as a useful tool for guiding the development of future spatially aware visual models.

</details>


### [23] [From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce](https://arxiv.org/abs/2601.11769)
*Cheng Lyu,Jingyue Zhang,Ryan Maunu,Mengwei Li,Vinny DeGenova,Yuanli Pei*

Main category: cs.CV

TL;DR: 提出一种解耦分类法的视觉搜索架构，使用无分类区域建议和统一嵌入进行相似性检索，并引入LLM-as-a-Judge框架进行零样本评估，在电商平台部署后提升了检索质量和用户参与度。


<details>
  <summary>Details</summary>
Motivation: 现有电商视觉搜索系统通常将目标检测与基于分类法的分类耦合，并依赖目录数据进行评估，这种方法容易受到噪声影响，限制了系统的鲁棒性和可扩展性，尤其是在风格驱动的领域中用户意图主观且开放。

Method: 1) 提出分类法解耦架构，使用无分类区域建议和统一嵌入进行相似性检索；2) 引入LLM-as-a-Judge框架，以零样本方式评估查询-结果对的细微视觉相似性和类别相关性，摆脱对人类标注或噪声目录数据的依赖。

Result: 在全球家居用品平台上大规模部署后，系统提高了检索质量，带来了可测量的客户参与度提升，离线评估指标与实际业务结果强相关。

Conclusion: 提出的解耦分类法视觉搜索架构和LLM评估框架能够创建更灵活、可泛化的视觉搜索系统，有效解决了现有工业系统的局限性，在实际电商应用中取得了显著效果。

Abstract: Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.

</details>


### [24] [Cross-Domain Object Detection Using Unsupervised Image Translation](https://arxiv.org/abs/2601.11779)
*Vinicius F. Arruda,Rodrigo F. Berriel,Thiago M. Paixão,Claudine Badue,Alberto F. De Souza,Nicu Sebe,Thiago Oliveira-Santos*

Main category: cs.CV

TL;DR: 提出一种通过生成目标域人工数据集来训练目标检测器的方法，使用CycleGAN和AdaIN两种无监督图像翻译器，在自动驾驶场景中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有的无监督域自适应目标检测方法虽然通过中间特征对齐取得了不错效果，但实现复杂、难以解释，且性能与使用目标域数据训练的上界仍有差距

Method: 使用CycleGAN和基于AdaIN的无监督图像翻译模型，仅利用源域标注数据和目标域非标注数据，生成目标域的人工数据集来训练目标检测器

Result: 在自动驾驶真实场景中取得显著改进，在大多数情况下超越了现有最优方法，进一步缩小了与上界（使用目标域数据训练）的性能差距

Conclusion: 提出的方法不仅复杂度更低、效果更好，而且具有更好的可解释性，为无监督域自适应目标检测提供了一种有效且实用的解决方案

Abstract: Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.

</details>


### [25] [RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection](https://arxiv.org/abs/2601.11898)
*Yilmaz Korkmaz,Vishal M. Patel*

Main category: cs.CV

TL;DR: RemoteVAR：基于视觉自回归模型的新型遥感变化检测框架，通过多分辨率特征融合和交叉注意力机制提升变化检测性能


<details>
  <summary>Details</summary>
Motivation: 视觉自回归模型在图像生成方面表现出色，但在像素级判别任务中应用有限，主要受限于弱可控性、次优的密集预测性能和曝光偏差。本文旨在解决这些限制，将自回归模型应用于遥感变化检测任务。

Method: 提出RemoteVAR框架：1）通过交叉注意力将自回归预测条件化到多分辨率融合的双时相特征上；2）专门为变化图预测设计自回归训练策略，提升模型在变化检测任务中的表现。

Result: 在标准变化检测基准测试中，RemoteVAR相比基于扩散模型和Transformer的强基线模型，取得了持续且显著的性能提升，为遥感变化检测建立了具有竞争力的自回归替代方案。

Conclusion: RemoteVAR成功解决了自回归模型在像素级判别任务中的局限性，为遥感变化检测提供了一种有效的自回归方法，代码将开源供研究社区使用。

Abstract: Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \href{https://github.com/yilmazkorkmaz1/RemoteVAR}{\underline{here}}.

</details>


### [26] [Towards Airborne Object Detection: A Deep Learning Analysis](https://arxiv.org/abs/2601.11907)
*Prosenjit Chatterjee,ANK Zaman*

Main category: cs.CV

TL;DR: 提出基于EfficientNetB4的双任务模型，同时进行空中目标分类和威胁等级预测，在自建AODTA数据集上达到96%分类准确率和90%威胁预测准确率。


<details>
  <summary>Details</summary>
Motivation: 随着商用飞机、无人机等空中平台的快速增加，需要实时自动的威胁评估系统。现有方法依赖人工监控，可扩展性有限且操作效率低下。

Method: 使用EfficientNetB4构建双任务模型，同时处理目标分类和威胁等级预测。为解决训练数据稀缺问题，整合多个公开数据集构建了AODTA数据集。在AVD数据集和自建AODTA数据集上进行基准测试，并与ResNet-50基线模型对比。

Result: EfficientNetB4模型在目标分类上达到96%准确率，在威胁等级预测上达到90%准确率。ResNet-50基线模型表现始终不如EfficientNetB4。虽然标题提到检测，但研究专注于使用现有数据集提供的预定位图像进行分类和威胁推断。

Conclusion: 基于EfficientNetB4的双任务模型在自动威胁评估方面表现出色，在监视、国防和空域管理等领域具有应用前景。模型能够同时准确分类空中目标并预测其威胁等级。

Abstract: The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.

</details>


### [27] [Effects of the retina-inspired light intensity encoding on color discrimination performance](https://arxiv.org/abs/2601.11909)
*Io Yamada,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 研究比较了中心/周边Retinex模型中不同光强编码函数对颜色恒常性的影响，发现Naka-Rushton函数结合双对立颜色平面表示能提供最佳的颜色辨别性能。


<details>
  <summary>Details</summary>
Motivation: 颜色是视觉功能的重要信息源，但受光照颜色影响很大。颜色恒常性（CC）是视觉系统的重要特性，本研究旨在探究光强编码函数对中心/周边Retinex模型颜色恒常性性能的影响。

Method: 比较了两种光强编码函数：原始C/S Retinex模型使用的对数函数和视网膜光感受器响应模型Naka-Rushton函数。使用颜色可变LED以不同光照颜色照射视觉目标，通过每个模型计算的颜色信息评估颜色辨别能力。颜色信息使用HSV颜色空间和基于经典对立颜色理论的颜色平面表示。

Result: 结果显示，Naka-Rushton函数与双对立颜色平面表示的组合提供了最优的颜色辨别性能。

Conclusion: Naka-Rushton函数作为视网膜光感受器响应模型，结合双对立颜色平面表示，能够显著提升中心/周边Retinex模型的颜色恒常性性能，为视觉系统颜色处理提供了更有效的模型组合。

Abstract: Color is an important source of information for visual functions such as object recognition, but it is greatly affected by the color of illumination. The ability to perceive the color of a visual target independent of illumination color is called color constancy (CC), and is an important feature for vision systems that use color information. In this study, we investigated the effects of the light intensity encoding function on the performance of CC of the center/surround (C/S) retinex model, which is a well-known model inspired by CC of the visual nervous system. The functions used to encode light intensity are the logarithmic function used in the original C/S retinex model and the Naka-Rushton (N-R) function, which is a model of retinal photoreceptor response. Color-variable LEDs were used to illuminate visual targets with various lighting colors, and color information computed by each model was used to evaluate the degree to which the color of visual targets illuminated with different lighting colors could be discriminated. Color information was represented using the HSV color space and a color plane based on the classical opponent color theory. The results showed that the combination of the N-R function and the double opponent color plane representation provided superior discrimination performance.

</details>


### [28] [A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection](https://arxiv.org/abs/2601.11910)
*Guiying Zhu,Bowen Yang,Yin Zhuang,Tong Zhang,Guanqun Wang,Zhihao Che,He Chen,Lianlin Li*

Main category: cs.CV

TL;DR: 提出无需训练的GW-VLM方法，通过多尺度视觉语言搜索和上下文概念提示，利用预训练视觉语言模型和大语言模型实现开放词汇目标检测。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法虽然利用大规模预训练基础模型，但通常忽略了根据已预训练模型建立通用对象认知理解的重要性。

Method: 提出GW-VLM方法，包含：1）多尺度视觉语言搜索（MS-VLS）进行视觉语言软对齐，从类别无关检测结果生成片段；2）上下文概念提示（CCP）形成概念流，让大语言模型理解片段。

Result: 在COCO val、Pascal VOC、DIOR和NWPU-10数据集上的实验表明，GW-VLM无需训练即可达到最先进的开放词汇目标检测性能。

Conclusion: GW-VLM通过"猜猜看"游戏范式，有效利用预训练视觉语言模型和大语言模型，实现了无需训练的开放词汇目标检测，展示了通用理解范式的重要性。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of "guess what". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.

</details>


### [29] [From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection](https://arxiv.org/abs/2601.11915)
*Chi Wang,Xinjue Hu,Boyu Wang,Ziwen He,Zhangjie Fu*

Main category: cs.CV

TL;DR: 提出一种通过低秩投影移除表示空间中虚假相关性的干预范式，提升人脸伪造检测的泛化能力


<details>
  <summary>Details</summary>
Motivation: 人脸伪造检测中的泛化问题源于虚假相关性因素导致的偏见学习，现有方法需要针对具体虚假相关性设计解决方案，但虚假相关性来自不可观测的混杂因素，难以逐一识别和处理

Method: 提出表示空间干预范式：将各种实例级虚假相关性统一建模为低秩子空间，通过正交低秩投影将虚假相关特征分解到低秩子空间，然后从原始表示中移除该子空间，训练其正交补集来捕获伪造相关特征

Result: 仅使用0.43M可训练参数，在多个基准测试中实现了最先进的性能，表现出优秀的鲁棒性和泛化能力

Conclusion: 通过将虚假相关性统一建模为低秩子空间并进行干预，能够有效消除虚假相关因素，确保分类决策基于真实的伪造线索，解决了人脸伪造检测中的泛化问题

Abstract: The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.

</details>


### [30] [Effects of Gabor Filters on Classification Performance of CNNs Trained on a Limited Number of Conditions](https://arxiv.org/abs/2601.11918)
*Akito Morita,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 提出使用Gabor滤波器作为CNN预处理，以提升边缘设备上机器人视觉应用的准确性和减小模型尺寸，特别是在数据有限条件下的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的CNN需要小型架构，而机器人视觉应用需要在有限数据条件下高效训练。视觉神经系统(VNS)能从少量视觉经验中学习，因此研究其模型Gabor滤波器作为CNN预处理的效果。

Method: 使用Gabor滤波器（VNS特征提取器模型）作为CNN的预处理，在不同CNN架构上对比有无Gabor预处理的效果。创建包含不同相机位置图像的数据集，评估在特定距离图像上训练的CNN对其他条件的泛化能力。

Result: Gabor滤波器预处理能提升CNN的泛化性能，并有助于减小CNN的模型尺寸。

Conclusion: Gabor滤波器作为预处理能有效改善CNN在边缘设备机器人视觉应用中的性能，特别是在数据有限条件下，既能提升泛化能力又能减小模型尺寸。

Abstract: In this study, we propose a technique to improve the accuracy and reduce the size of convolutional neural networks (CNNs) running on edge devices for real-world robot vision applications. CNNs running on edge devices must have a small architecture, and CNNs for robot vision applications involving on-site object recognition must be able to be trained efficiently to identify specific visual targets from data obtained under a limited variation of conditions. The visual nervous system (VNS) is a good example that meets the above requirements because it learns from few visual experiences. Therefore, we used a Gabor filter, a model of the feature extractor of the VNS, as a preprocessor for CNNs to investigate the accuracy of the CNNs trained with small amounts of data. To evaluate how well CNNs trained on image data acquired under a limited variation of conditions generalize to data acquired under other conditions, we created an image dataset consisting of images acquired from different camera positions, and investigated the accuracy of the CNNs that trained using images acquired at a certain distance. The results were compared after training on multiple CNN architectures with and without Gabor filters as preprocessing. The results showed that preprocessing with Gabor filters improves the generalization performance of CNNs and contributes to reducing the size of CNNs.

</details>


### [31] [SupScene: Learning Overlap-Aware Global Descriptor for Unconstrained SfM](https://arxiv.org/abs/2601.11930)
*Xulei Shi,Maoyu Wang,Yuning Peng,Guanbo Wang,Xin Wang,Qi Chen,Pengjie Tao*

Main category: cs.CV

TL;DR: SupScene提出了一种用于SfM图像检索的新方法，通过子图训练策略和DiVLAD聚合器学习更适合几何匹配的全局描述符，在GL3D数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的图像检索方法主要关注图像对的语义相似性，而SfM中的图像检索更需要关注几何匹配性。大多数方法使用批量二值标签（重叠vs非重叠）无法捕捉这种细微差别。

Method: 1. 采用基于子图的训练策略，超越同等重要的孤立图像对，利用带权重的真实几何重叠关系，通过软监督对比损失提供细粒度监督。2. 提出DiVLAD聚合器，利用ViT最后一层的多头注意力图，通过可学习的门控机制自适应地结合语义显著线索和视觉特征，生成更具判别性的全局描述符。

Result: 在GL3D数据集上的大量实验表明，该方法达到了最先进的性能，显著优于NetVLAD，同时仅引入可忽略的额外可训练参数。此外，所提出的训练策略在不同聚合技术中都带来了一致的性能提升。

Conclusion: SupScene通过学习专门用于寻找具有相似几何性质的重叠图像对的全局描述符，有效解决了SfM中图像检索的挑战。该方法在保持参数效率的同时实现了显著的性能改进。

Abstract: Image retrieval is a critical step for alleviating the quadratic complexity of image matching in unconstrained Structure-from-Motion (SfM). However, in this context, image retrieval typically focuses more on the image pairs of geometric matchability than on those of semantic similarity, a nuance that most existing deep learning-based methods guided by batched binaries (overlapping vs. non-overlapping pairs) fail to capture. In this paper, we introduce SupScene, a novel solution that learns global descriptors tailored for finding overlapping image pairs of similar geometric nature for SfM. First, to better underline co-visible regions, we employ a subgraph-based training strategy that moves beyond equally important isolated pairs, leveraging ground-truth geometric overlapping relationships with various weights to provide fine-grained supervision via a soft supervised contrastive loss. Second, we introduce DiVLAD, a DINO-inspired VLAD aggregator that leverages the inherent multi-head attention maps from the last block of ViT. And then, a learnable gating mechanism is designed to adaptively utilize these semantically salient cues with visual features, enabling a more discriminative global descriptor. Extensive experiments on the GL3D dataset demonstrate that our method achieves state-of-the-art performance, significantly outperforming NetVLAD while introducing a negligible number of additional trainable parameters. Furthermore, we show that the proposed training strategy brings consistent gains across different aggregation techniques. Code and models are available at https://anonymous.4open.science/r/SupScene-5B73.

</details>


### [32] [Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition](https://arxiv.org/abs/2601.11931)
*Zhengxian Wu,Chuanrui Zhang,Shenao Jiang,Hangrui Xu,Zirui Liao,Luyuan Zhang,Huaqiu Li,Peng Jiao,Haoqian Wang*

Main category: cs.CV

TL;DR: 提出LMGait框架，使用语言引导和运动感知进行步态识别，解决现有方法对静态噪声过拟合和动态运动区域捕获不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法通常依赖复杂架构直接从图像提取特征，并通过池化操作获得序列级表示。这种设计容易对静态噪声（如服装）过拟合，同时无法有效捕获动态运动区域

Method: 提出LMGait框架，利用设计的步态相关语言线索来捕捉步态序列中的关键运动特征。该方法结合语言引导和运动感知机制

Result: 论文摘要未提供具体实验结果数据，但提出了新的框架来解决现有方法的局限性

Conclusion: LMGait框架通过语言引导和运动感知的方法，能够更好地解决步态识别中对静态噪声过拟合和动态运动特征捕获不足的问题

Abstract: Gait recognition is emerging as a promising technology and an innovative field within computer vision. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions.To address the above challenges, we present a Language guided and Motion-aware gait recognition framework, named LMGait.In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences.

</details>


### [33] [Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal](https://arxiv.org/abs/2601.11952)
*Haonan An,Guang Hua,Wei Du,Hangcheng Cao,Yihang Tao,Guowen Xu,Susanto Rahardja,Yuguang Fang*

Main category: cs.CV

TL;DR: 该论文提出了一种针对无盒模型水印解码器的防御机制DGS，通过梯度重定向和缩放来防止攻击者利用查询响应训练水印移除器，在多种应用场景下实现100%的防御成功率。


<details>
  <summary>Details</summary>
Motivation: 当前无盒模型水印研究主要关注编码器的鲁棒性，而解码器被忽视，导致存在针对解码器的攻击。攻击者可以利用查询响应获取反向传播梯度来训练水印移除器，威胁水印系统的安全性。

Method: 提出Decoder Gradient Shields (DGS)防御机制家族，包括输出层DGS-O、输入层DGS-I和中间层DGS-L。通过水印通道梯度泄露查询的梯度重定向和缩放联合设计，防止水印移除器达到低损失值的训练收敛，同时保持解码器输出图像质量。

Result: 在去雨和图像生成任务中，使用最先进的无盒水印技术进行实验，DGS在所有设置下实现了100%的防御成功率，有效保护水印系统安全。

Conclusion: DGS机制为无盒模型水印系统提供了有效的解码器防御方案，填补了现有研究中对解码器安全性的忽视，通过理论证明和实验验证展示了其防御效果。

Abstract: Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.

</details>


### [34] [Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms](https://arxiv.org/abs/2601.11970)
*S. M. Khalid Bin Zahid,Md. Rakibul Hasan Nishat,Abdul Hasib,Md. Rakibul Hasan,Md. Ashiqussalehin,Md. Sahadat Hossen Sajib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 提出一个在树莓派5边缘平台上部署的实时多模态视觉框架，通过自适应调度机制将目标检测、人脸识别和情绪检测集成到统一流水线中，相比持续处理减少65%计算负载。


<details>
  <summary>Details</summary>
Motivation: 现有智能监控系统通常独立处理感知任务（如目标检测、人脸识别、情绪分析），缺乏统一的、自适应的运行时调度器来根据上下文触发动态分配计算资源，限制了在低功耗边缘设备上的整体理解和效率。

Method: 开发了一个实时多模态视觉框架，集成了YOLOv8n目标检测、基于FaceNet的自定义嵌入系统人脸识别、DeepFace CNN情绪分类，核心是自适应调度机制，根据上下文触发选择性激活模块以减少计算负载。

Result: 系统在树莓派5上以5.6帧/秒运行，目标检测平均精度0.861，人脸识别准确率88%，情绪检测对特定情绪的AUC高达0.97，计算负载相比持续处理减少65%。

Conclusion: 上下文感知调度是实现复杂多模态AI在成本效益边缘硬件上运行的关键，使智能感知更加可访问且保护隐私。

Abstract: Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.

</details>


### [35] [AVIR: Adaptive Visual In-Document Retrieval for Efficient Multi-Page Document Question Answering](https://arxiv.org/abs/2601.11976)
*Zongmin Li,Yachuan Li,Lei Kang,Dimosthenis Karatzas,Wenkang Ma*

Main category: cs.CV

TL;DR: AVIR框架通过自适应视觉文档检索解决多页文档视觉问答问题，减少70%页面需求，在MP-DocVQA数据集上达到84.58% ANLS，超越现有方法且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 多页文档视觉问答面临两大挑战：长文档消耗大量计算资源，同时降低大型视觉语言模型中注意力机制的有效性。现有方法在处理长文档时效率低下且效果不佳。

Method: 提出自适应视觉文档检索框架：1) 轻量级检索模型为每页评分；2) 根据分数分布聚类页面自适应选择相关内容；3) 对聚类页面进行Top-K筛选保持上下文紧凑；4) 短文档使用相关性概率阈值选择页面；5) 仅选择页面输入冻结的LVLM生成答案，无需微调。

Result: 在MP-DocVQA数据集上达到84.58% ANLS，平均页面需求减少70%，超越先前方法且计算成本显著降低。在SlideVQA和DUDE基准测试中也验证了有效性。

Conclusion: AVIR框架有效解决了多页文档视觉问答的计算效率和注意力机制问题，通过自适应页面选择显著降低计算需求同时提升性能，为长文档理解提供了高效解决方案。

Abstract: Multi-page Document Visual Question Answering (MP-DocVQA) remains challenging because long documents not only strain computational resources but also reduce the effectiveness of the attention mechanism in large vision-language models (LVLMs). We tackle these issues with an Adaptive Visual In-document Retrieval (AVIR) framework. A lightweight retrieval model first scores each page for question relevance. Pages are then clustered according to the score distribution to adaptively select relevant content. The clustered pages are screened again by Top-K to keep the context compact. However, for short documents, clustering reliability decreases, so we use a relevance probability threshold to select pages. The selected pages alone are fed to a frozen LVLM for answer generation, eliminating the need for model fine-tuning. The proposed AVIR framework reduces the average page count required for question answering by 70%, while achieving an ANLS of 84.58% on the MP-DocVQA dataset-surpassing previous methods with significantly lower computational cost. The effectiveness of the proposed AVIR is also verified on the SlideVQA and DUDE benchmarks. The code is available at https://github.com/Li-yachuan/AVIR.

</details>


### [36] [Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection](https://arxiv.org/abs/2601.11981)
*Jian Lang,Rongpei Hong,Ting Zhong,Yong Wang,Fan Zhou*

Main category: cs.CV

TL;DR: RADAR是首个支持测试时自适应检测未见新闻视频的假新闻视频检测框架，通过检索引导的自适应范式，利用目标域中的稳定视频来指导相关但不稳定实例的鲁棒适应。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻视频检测方法通常假设训练和测试阶段新闻主题分布一致，无法检测与新兴事件和未见主题相关的假新闻视频，需要能够适应未见新闻视频的测试时自适应框架。

Method: 提出RADAR框架，包含三个核心模块：1) 基于熵选择的检索机制，为适应提供稳定、相关的参考视频；2) 稳定锚点引导的对齐模块，通过分布级匹配将不稳定实例表示与源域对齐；3) 目标域感知的自训练范式，生成由稳定参考增强的信息伪标签。

Result: 大量实验表明，RADAR在测试时假新闻视频检测方面实现了卓越性能，能够对未见假新闻视频主题进行强大的即时适应。

Conclusion: RADAR是首个能够实现测试时自适应检测未见新闻视频的框架，通过创新的检索引导自适应范式，有效解决了现有方法无法适应新兴事件和未见主题的问题，为假新闻视频检测提供了新的解决方案。

Abstract: Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.

</details>


### [37] [An AI-IoT Based Smart Wheelchair with Gesture-Controlled Mobility, Deep Learning-Based Obstacle Detection, Multi-Sensor Health Monitoring, and Emergency Alert System](https://arxiv.org/abs/2601.11983)
*Md. Asiful Islam,Abdul Hasib,Tousif Mahmud Emon,Khandaker Tabin Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种基于AI-IoT的智能轮椅系统，集成了手势控制、实时物体检测和健康监测功能，为残障人士和老年人提供经济实惠的辅助解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着残障人士和老年人口的增长，需要经济实惠的智能轮椅系统。传统轮椅缺乏动态功能，而现有的智能轮椅往往成本高昂、功能单一，且健康监测集成有限。迫切需要先进、个性化且负担得起的辅助技术。

Method: 采用基于AI-IoT的智能轮椅系统，包括：1）基于手套的手势控制实现免手导航；2）使用YOLOv8进行实时物体检测，配合听觉反馈进行障碍物避让；3）超声波传感器用于即时碰撞避免；4）持续监测生命体征（心率、血氧、心电图、体温），上传至ThingSpeak平台，并在危急情况下触发邮件警报。

Result: 手势控制成功率达到95.5%，超声波障碍物检测准确率达到94%，基于YOLOv8的物体检测实现了91.5%的精确率、90.2%的召回率和90.8%的F1分数。系统采用模块化低成本架构。

Conclusion: 这种集成多模态方法提供了一个实用、可扩展且经济实惠的解决方案，通过弥合创新研究与实际部署之间的差距，显著增强了用户的自主性、安全性和独立性。

Abstract: The growing number of differently-abled and elderly individuals demands affordable, intelligent wheelchairs that combine safe navigation with health monitoring. Traditional wheelchairs lack dynamic features, and many smart alternatives remain costly, single-modality, and limited in health integration. Motivated by the pressing demand for advanced, personalized, and affordable assistive technologies, we propose a comprehensive AI-IoT based smart wheelchair system that incorporates glove-based gesture control for hands-free navigation, real-time object detection using YOLOv8 with auditory feedback for obstacle avoidance, and ultrasonic for immediate collision avoidance. Vital signs (heart rate, SpO$_2$, ECG, temperature) are continuously monitored, uploaded to ThingSpeak, and trigger email alerts for critical conditions. Built on a modular and low-cost architecture, the gesture control achieved a 95.5\% success rate, ultrasonic obstacle detection reached 94\% accuracy, and YOLOv8-based object detection delivered 91.5\% Precision, 90.2\% Recall, and a 90.8\% F1-score. This integrated, multi-modal approach offers a practical, scalable, and affordable solution, significantly enhancing user autonomy, safety, and independence by bridging the gap between innovative research and real-world deployment.

</details>


### [38] [SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture](https://arxiv.org/abs/2601.12015)
*Pavan Kumar Yata,Pediredla Pradeep,Goli Himanish,Swathi M*

Main category: cs.CV

TL;DR: 提出DeepSegFusion混合深度学习模型用于SAR图像油污分割，结合SegNet和DeepLabV3+并采用注意力特征融合机制，显著降低误报率，在ALOS PALSAR数据集上达到94.85%准确率和0.9330 ROC-AUC分数。


<details>
  <summary>Details</summary>
Motivation: 传统基于阈值的方法在卫星图像油污检测中因风浪条纹、船舶尾流等类似现象导致高误报率，需要更精确的检测方法。

Method: 提出DeepSegFusion混合深度学习模型，集成SegNet和DeepLabV3+架构，采用注意力机制的特征融合方法，提升边界精度和上下文理解能力。

Result: 在SAR油污数据集（包括ALOS PALSAR）上达到94.85%准确率、0.5685 IoU和0.9330 ROC-AUC分数，误检率比基线模型降低64.4%，减少三倍以上误报。

Conclusion: DeepSegFusion在各种海洋条件下表现稳定，误报率显著降低，可用于近实时油污监测场景。

Abstract: Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.

</details>


### [39] [DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering](https://arxiv.org/abs/2601.12020)
*Guillermo Figueroa-Araneda,Iris Diana Jimenez,Florian Hofherr,Manny Ko,Hector Andrade-Loarca,Daniel Cremers*

Main category: cs.CV

TL;DR: DIAMOND-SSS是一个数据高效框架，仅需极少图像（少至10张）即可实现高保真半透明材质重建，通过扩散模型生成数据增强，减少90%真实采集需求。


<details>
  <summary>Details</summary>
Motivation: 半透明材质（如蜡、玉、大理石、皮肤）的次表面散射效果在神经渲染中建模困难，需要密集的多视角多光照数据集（通常超过100个视角和112个OLAT），数据采集成本高昂。

Method: 1. 微调扩散模型用于新视角合成和重光照，基于估计的几何信息，仅使用不到7%的数据集训练；2. 引入光照无关几何先验：多视角轮廓一致性损失和多视角深度一致性损失，以稳定稀疏或合成监督下的重建。

Result: DIAMOND-SSS在所有稀疏度下都实现了最先进的重光照高斯渲染质量，相比SSS-3DGS减少了高达90%的真实采集需求，生成的光照真实增强数据可替代高达95%的缺失采集。

Conclusion: DIAMOND-SSS框架显著降低了半透明材质重建的数据需求，通过数据增强和几何先验实现了从极稀疏监督（少至10张图像）的高质量重光照重建，为半透明材质神经渲染提供了实用解决方案。

Abstract: Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs).
  We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss.
  Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.

</details>


### [40] [\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions](https://arxiv.org/abs/2601.12049)
*Chenchen Zhao,Muxi Chen,Qiang Xu*

Main category: cs.CV

TL;DR: FocaLogic是一个模型无关的视觉模型解释框架，通过逻辑表示来量化和解释模型决策，识别关键视觉区域并转化为逻辑表达式，提供定量评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型解释方法要么依赖白盒模型访问，要么缺乏定量严谨性，无法满足高风险应用中对模型透明度和可解释性的需求。

Method: 提出FocaLogic框架：1）识别最小可解释视觉区域子集（视觉焦点）；2）将这些视觉焦点转化为精确紧凑的逻辑表达式；3）提出焦点精度、召回率和发散度等定量评估指标。

Result: 实证分析表明FocaLogic能够揭示关键洞察：训练诱导的集中性、通过泛化提高焦点准确性、以及在偏见和对抗攻击下的异常焦点。

Conclusion: FocaLogic为解释视觉模型提供了一个系统化、可扩展且定量的解决方案，能够提供透明和结构化的模型决策解释。

Abstract: Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.

</details>


### [41] [A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models](https://arxiv.org/abs/2601.12051)
*Weixin Ye,Wei Wang,Yahui Liu,Yue Song,Bin Ren,Wei Bi,Rita Cucchiara,Nicu Sebe*

Main category: cs.CV

TL;DR: 提出MJP框架，通过随机打乱token顺序并使用可学习的未知位置嵌入来掩盖位置信息，既增强Transformer对抗梯度攻击的鲁棒性，又提升其在CV和NLP任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中Transformer面临梯度攻击的威胁，研究发现位置嵌入的梯度包含足够信息可用于重建输入数据，需要解决这一安全问题同时提升模型性能。

Method: 提出Masked Jigsaw Puzzle框架：1) 随机打乱token顺序破坏token顺序；2) 使用可学习的未知位置嵌入掩盖被打乱token的位置信息；3) 破坏局部空间信息，迫使模型学习不依赖局部空间信息的特征表示。

Result: 实验表明MJP不仅能提高模型对抗梯度攻击的鲁棒性，还能提升在图像分类（如ImageNet-1K）和文本情感分析（如Yelp和Amazon）任务中的性能，是一个适用于不同Transformer模型的统一框架。

Conclusion: MJP框架通过破坏位置嵌入中的局部空间信息，有效解决了Transformer在联邦学习中的安全漏洞，同时提升了模型性能，为视觉和语言任务提供了统一的解决方案。

Abstract: In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack

</details>


### [42] [Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation](https://arxiv.org/abs/2601.12052)
*Zaiyan Zhang,Jie Li,Shaowei Shi,Qiangqiang Yuan*

Main category: cs.CV

TL;DR: TDP-CR是一个任务驱动的多模态云去除框架，通过可学习的退化提示融合SAR信息，在保持参数效率的同时，在PSNR和语义分割精度上均超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有云去除方法过度关注低层视觉保真度，导致纹理和边界过度平滑，与语义分析需求不匹配，需要开发既能有效去除云层又能保持语义分析能力的方法。

Method: 提出任务驱动的多模态框架TDP-CR，包含提示引导融合机制，使用可学习的退化提示编码云层厚度和空间不确定性，结合全局通道上下文和局部提示条件空间偏置，自适应集成SAR信息。采用参数高效的两阶段训练策略，解耦重建和语义表示学习。

Result: 在LuojiaSET-OSFCR数据集上，TDP-CR在PSNR上超越现有最佳方法0.18dB，同时仅使用15%的参数；在mIoU上比多任务竞争对手提升1.4%，有效提供分析就绪数据。

Conclusion: TDP-CR框架通过任务驱动的多模态设计和提示引导融合机制，成功解决了云去除中视觉保真度与语义效用之间的不匹配问题，以参数高效的方式实现了更好的云去除和土地覆盖分割性能。

Abstract: Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\% of the parameters, and achieves a 1.4\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.

</details>


### [43] [Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation](https://arxiv.org/abs/2601.12066)
*Zijie Lou,Xiangwei Feng,Jiaxin Wang,Xiaochao Qu,Luoqi Liu,Ting Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种新的视频对象移除方法，使用随机桥模型将问题重新定义为视频到视频的转换任务，相比传统基于噪声的方法能更好地利用原始视频的结构先验。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频对象移除方法从无信息的高斯噪声开始生成，丢弃了原始视频中丰富的结构和上下文先验，导致对象擦除不完整或生成与场景物理逻辑冲突的内容。

Method: 将视频对象移除重新定义为通过随机桥模型进行的视频到视频转换任务，建立从源视频（含对象）到目标视频（对象移除）的直接随机路径。提出自适应掩码调制策略，根据掩码特征动态调节输入嵌入，平衡背景保真度和生成灵活性。

Result: 大量实验表明，该方法在视觉质量和时间一致性方面显著优于现有方法。

Conclusion: 通过桥模型框架利用输入视频作为强结构先验，能够实现精确的对象移除，同时确保填充区域与周围环境在逻辑上一致。

Abstract: Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.

</details>


### [44] [CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation](https://arxiv.org/abs/2601.12076)
*H. Jiang,Y. Sun,Z. Dong,T. Liu,Y. Gu*

Main category: cs.CV

TL;DR: 本文针对遥感视频指称对象分割任务，构建了首个大规模基准数据集RS-RVOS Bench，并提出基于记忆质量控制的MQC-SAM框架，通过初始记忆校准和选择性记忆更新机制解决目标显著性弱、视觉信息截断等问题。


<details>
  <summary>Details</summary>
Motivation: 遥感视频指称对象分割面临目标显著性弱、动态场景中视觉信息截断严重等挑战，现有方法存在初始记忆构建偏差影响实例定位精度，以及无差别记忆积累导致遮挡或误分类噪声传播的问题。同时，该领域缺乏大规模专用基准数据集。

Method: 提出MQC-SAM框架：1）构建RS-RVOS Bench基准数据集，包含111个视频序列、约25,000帧和213,000个时序指称标注，采用严格的因果感知标注策略；2）引入时序运动一致性模块进行初始记忆校准，利用短期运动轨迹先验修正结构偏差；3）设计解耦注意力记忆集成机制，通过动态质量评估选择性更新高置信度语义特征，过滤不可靠信息。

Result: 在RS-RVOS Bench数据集上的大量实验表明，MQC-SAM框架实现了最先进的性能表现。

Conclusion: 本文通过构建大规模基准数据集和提出记忆质量感知的在线指称分割框架，有效解决了遥感视频指称对象分割中的关键挑战，为后续研究提供了重要基础。

Abstract: Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.

</details>


### [45] [EmoLat: Text-driven Image Sentiment Transfer via Emotion Latent Space](https://arxiv.org/abs/2601.12079)
*Jing Zhang,Bingjie Fan,Jixiang Zhu,Zhe Wang*

Main category: cs.CV

TL;DR: EmoLat是一个新颖的情感潜在空间，通过建模文本语义与视觉情感特征之间的跨模态相关性，实现细粒度、文本驱动的图像情感迁移。


<details>
  <summary>Details</summary>
Motivation: 现有图像情感迁移方法缺乏对文本语义与视觉情感特征之间复杂关系的建模能力，无法实现细粒度的文本驱动情感控制。

Method: 构建情感语义图捕捉情感、对象和视觉属性之间的关系结构；采用对抗正则化增强情感表示的可区分性和可迁移性；提出跨模态情感迁移框架，通过文本和EmoLat特征的联合嵌入来操纵图像情感。

Result: 在EmoSpace Set大规模基准数据集上的实验表明，该方法在定量指标和定性迁移保真度方面显著优于现有最先进方法。

Conclusion: EmoLat为文本引导的可控图像情感编辑建立了新范式，EmoSpace Set数据集和所有代码均已开源。

Abstract: We propose EmoLat, a novel emotion latent space that enables fine-grained, text-driven image sentiment transfer by modeling cross-modal correlations between textual semantics and visual emotion features. Within EmoLat, an emotion semantic graph is constructed to capture the relational structure among emotions, objects, and visual attributes. To enhance the discriminability and transferability of emotion representations, we employ adversarial regularization, aligning the latent emotion distributions across modalities. Building upon EmoLat, a cross-modal sentiment transfer framework is proposed to manipulate image sentiment via joint embedding of text and EmoLat features. The network is optimized using a multi-objective loss incorporating semantic consistency, emotion alignment, and adversarial regularization. To support effective modeling, we construct EmoSpace Set, a large-scale benchmark dataset comprising images with dense annotations on emotions, object semantics, and visual attributes. Extensive experiments on EmoSpace Set demonstrate that our approach significantly outperforms existing state-of-the-art methods in both quantitative metrics and qualitative transfer fidelity, establishing a new paradigm for controllable image sentiment editing guided by textual input. The EmoSpace Set and all the code are available at http://github.com/JingVIPLab/EmoLat.

</details>


### [46] [Toward Real-World High-Precision Image Matting and Segmentation](https://arxiv.org/abs/2601.12080)
*Haipeng Zhou,Zhaohu Xing,Hongqiu Wang,Jun Ma,Ping Li,Lei Zhu*

Main category: cs.CV

TL;DR: 本文提出FCLM模型，通过深度感知蒸馏和领域不变学习解决高精度场景解析中的前景一致性学习问题，支持视觉和语言提示的交互式预测。


<details>
  <summary>Details</summary>
Motivation: 现有高精度场景解析方法主要关注显著的单前景对象，交互式方法类别不可知限制了跨类别泛化，高质量标注稀缺导致依赖不和谐的合成数据，泛化到真实场景效果差。

Method: 提出前景一致性学习模型FCLM：1) 深度感知蒸馏策略，迁移深度相关知识以改善前景表示；2) 将合成数据处理视为领域适应问题，提出领域不变学习策略专注于前景学习；3) 面向对象的解码器，可接收视觉和语言提示来预测参考目标。

Result: 实验结果表明，该方法在定量和定性评估上均优于现有最先进方法。

Conclusion: FCLM模型通过深度感知蒸馏和领域不变学习有效解决了高精度场景解析中的前景一致性学习问题，支持多模态交互预测，在真实场景中表现出更好的泛化能力。

Abstract: High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.

</details>


### [47] [Conditional Random Fields for Interactive Refinement of Histopathological Predictions](https://arxiv.org/abs/2601.12082)
*Tiffanie Godelaine,Maxime Zanella,Karim El Khoury,Saïd Mahmoudi,Benoît Macq,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: HistoCRF：一种无需额外训练的CRF框架，通过改进成对势能定义来优化组织病理学图像中视觉语言模型的零样本预测，利用专家标注提升分类准确性。


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像分析对癌症检测和分期具有重要临床价值。虽然视觉语言模型（VLMs）能提供零样本预测，但预测结果不完美，需要进一步优化。

Method: 提出HistoCRF框架，将条件随机场（CRFs）适应于组织病理学应用，无需额外模型训练。设计了新的成对势能定义，促进标签多样性并利用专家标注。考虑了三种实验设置：无标注、有专家标注、以及迭代式人机交互标注。

Result: 在五个涵盖不同器官和疾病的patch级分类数据集上，相比零样本预测，无标注时平均准确率提升16.0%，仅使用100个标注时提升27.5%。人机交互标注进一步将提升幅度提高到32.6%。

Conclusion: HistoCRF能有效改进组织病理学图像中视觉语言模型的零样本预测，通过CRF框架和专家标注的整合显著提升分类性能，具有临床实用价值。

Abstract: Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.

</details>


### [48] [CARLA-Round: A Multi-Factor Simulation Dataset for Roundabout Trajectory Prediction](https://arxiv.org/abs/2601.12119)
*Xiaotong Zhou,Zhenhui Yuan,Yi Han,Tianhua Xu,Laurence T. Yang*

Main category: cs.CV

TL;DR: CARLA-Round是一个用于环岛轨迹预测的系统化仿真数据集，通过结构化控制天气条件和交通密度，提供25种场景，支持因素影响分析，并验证了仿真到现实的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 环岛场景的车辆轨迹预测对交通安全至关重要，但由于其圆形几何结构、连续的交织让行交互以及缺乏交通信号，预测极具挑战性。现有数据集稀缺，真实世界数据收集存在观测不完整和因素混杂难以分离的问题。

Method: 开发了CARLA-Round仿真数据集，系统化设计包含5种天气条件和5个服务水平等级（A-E）的交通密度，形成25种结构化场景。数据集包含真实的驾驶行为混合，并提供现有数据集缺乏的明确标注。

Result: 验证实验使用标准基线模型（LSTM、GCN、GRU+GCN）显示：交通密度对预测难度具有主导性的单调效应，而天气条件呈现非线性影响。最佳模型在真实世界rounD数据集上达到0.312m ADE，证明了有效的仿真到现实迁移。

Conclusion: CARLA-Round通过系统化设计量化了真实世界混杂数据集中无法分离的因素影响，为环岛轨迹预测研究提供了可靠、多模态、现实的仿真数据集，支持精确的条件影响分析。

Abstract: Accurate trajectory prediction of vehicles at roundabouts is critical for reducing traffic accidents, yet it remains highly challenging due to their circular road geometry, continuous merging and yielding interactions, and absence of traffic signals. Developing accurate prediction algorithms relies on reliable, multimodal, and realistic datasets; however, such datasets for roundabout scenarios are scarce, as real-world data collection is often limited by incomplete observations and entangled factors that are difficult to isolate. We present CARLA-Round, a systematically designed simulation dataset for roundabout trajectory prediction. The dataset varies weather conditions (five types) and traffic density levels (spanning Level-of-Service A-E) in a structured manner, resulting in 25 controlled scenarios. Each scenario incorporates realistic mixtures of driving behaviors and provides explicit annotations that are largely absent from existing datasets. Unlike randomly sampled simulation data, this structured design enables precise analysis of how different conditions influence trajectory prediction performance. Validation experiments using standard baselines (LSTM, GCN, GRU+GCN) reveal traffic density dominates prediction difficulty with strong monotonic effects, while weather shows non-linear impacts. The best model achieves 0.312m ADE on real-world rounD dataset, demonstrating effective sim-to-real transfer. This systematic approach quantifies factor impacts impossible to isolate in confounded real-world datasets. Our CARLA-Round dataset is available at https://github.com/Rebecca689/CARLA-Round.

</details>


### [49] [Segment and Matte Anything in a Unified Model](https://arxiv.org/abs/2601.12147)
*Zezhong Fan,Xiaohan Li,Topojoy Biswas,Kaushiki Nag,Kannan Achan*

Main category: cs.CV

TL;DR: SAMA是一个基于SAM的轻量级扩展模型，能够同时进行高质量的交互式图像分割和抠图，通过多视图定位编码器和局部适配器提升边界细节，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 虽然SAM在分割任务上展现了零样本泛化能力，但其掩码预测精度在实际应用中仍显不足。现有的细化模块难以在统一框架内实现高精度对象轮廓，同时交互式图像抠图在SAM框架中尚未被探索。研究表明分割与抠图之间存在强相关性，因此需要一个能同时处理这两个任务的统一模型。

Method: 提出了Segment And Matte Anything (SAMA)，作为SAM的轻量级扩展。主要包含：1) Multi-View Localization Encoder (MVLE) 从局部视图捕获详细特征；2) Localization Adapter (Local-Adapter) 通过恢复细微边界细节来细化掩码输出；3) 为每个任务集成两个预测头，同时生成分割和抠图掩码。

Result: 在从公开来源聚合的多样化数据集上训练后，SAMA在多个分割和抠图基准测试中实现了最先进的性能，展示了其在广泛下游任务中的适应性和有效性。

Conclusion: SAMA成功地将分割和抠图任务统一到一个轻量级框架中，通过创新的多视图定位编码器和局部适配器显著提升了边界细节的恢复能力，为实际应用提供了高质量的交互式图像处理解决方案。

Abstract: Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.

</details>


### [50] [Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models](https://arxiv.org/abs/2601.12150)
*Mengxuan Hu,Zihan Guan,John Kang,Sheng Li,Zhongliang Zhou*

Main category: cs.CV

TL;DR: 提出一种空间和时间高效的推理策略，通过空间感知邻近块稀疏化注意力，并通过全局注意力分数过滤非信息性标记，显著降低高分辨率全切片图像推理时的GPU内存和运行时间，同时保持甚至提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前病理学基础模型受限于特定输入尺寸（如224×224），在处理数千分辨率级别的全切片图像时效率低下。简单扩大输入会导致GPU内存消耗过大，而降低采样则会改变微米每像素分辨率并模糊关键形态细节。

Method: 提出空间和时间高效的推理策略：1）使用空间感知邻近块稀疏化注意力机制；2）通过全局注意力分数过滤非信息性标记。这种方法在保持高分辨率推理的同时显著减少GPU内存和运行时间。

Result: 实验结果显示，该方法在ROI分类任务中实现了高达7.67%的性能提升，在分割任务中获得了兼容的结果。能够在相同GPU预算下实现更高分辨率的推理。

Conclusion: 该方法有效解决了病理学基础模型在处理全切片图像时的效率瓶颈，通过创新的注意力稀疏化和标记过滤策略，在降低计算资源消耗的同时保持甚至提升了模型性能，为高分辨率医学图像分析提供了实用解决方案。

Abstract: Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.

</details>


### [51] [Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion](https://arxiv.org/abs/2601.12224)
*Meng Wei,Kun Yuan,Shi Li,Yue Zhou,Long Bai,Nassir Navab,Hongliang Ren,Hong Joo Lee,Tom Vercauteren,Nicolas Padoy*

Main category: cs.CV

TL;DR: 提出SurgRef框架，通过运动引导实现手术场景中的自然语言指代分割，利用工具运动而非静态外观特征，提高在遮挡、模糊或陌生术语情况下的分割准确性。


<details>
  <summary>Details</summary>
Motivation: 手术场景中的语言驱动交互是智能手术室和自主手术机器人辅助的关键步骤，但现有的指代分割方法主要依赖静态视觉特征和预定义工具名称，难以泛化到不同手术场景。

Method: 提出SurgRef框架，基于运动引导将自由形式语言表达与手术工具运动关联，捕捉工具随时间移动和交互的方式而非外观特征；同时构建Ref-IMotion数据集，包含密集时空掩码和丰富的运动中心表达。

Result: SurgRef在不同手术程序中实现了最先进的准确性和泛化能力，为鲁棒的语言驱动手术视频分割设立了新的基准。

Conclusion: 通过运动引导而非外观特征的方法能够更好地理解手术工具，即使在遮挡、模糊或陌生术语情况下也能实现准确分割，为智能手术室和自主手术机器人辅助提供了重要进展。

Abstract: Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.

</details>


### [52] [DiffusionQC: Artifact Detection in Histopathology via Diffusion Model](https://arxiv.org/abs/2601.12233)
*Zhenzhen Wang,Zhongliang Zhou,Zhuoyu Wen,Jeong Hwan Kook,John B Wojcik,John Kang*

Main category: cs.CV

TL;DR: 提出DiffusionQC方法，仅需干净图像训练即可检测组织病理学图像中的伪影，无需像素级标注或预定义伪影类型，通过对比学习增强性能


<details>
  <summary>Details</summary>
Motivation: 数字病理学图像中常包含制备和数字化过程中引入的伪影，传统监督方法需要大量标注数据且难以泛化到新伪影类型，需要更高效通用的解决方案

Method: 使用扩散模型将伪影检测为干净图像中的异常值，仅需干净图像训练；引入对比学习模块明确扩大伪影与干净图像之间的分布分离，增强方法性能

Result: 实验结果表明优于现有最先进方法，具有跨染色泛化能力，所需数据和标注显著减少

Conclusion: DiffusionQC为数字病理学中的伪影检测提供了一种高效、通用的无监督解决方案，减少了对大量标注数据的依赖

Abstract: Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.

</details>


### [53] [CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training](https://arxiv.org/abs/2601.12282)
*Pralaypati Ta,Sriram Venkatesaperumal,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: CytoCLIP：基于预训练CLIP框架的视觉语言模型，用于学习大脑细胞构筑的联合视觉-文本表示，实现大脑区域自动识别


<details>
  <summary>Details</summary>
Motivation: 大脑不同区域的功能与其独特的细胞构筑密切相关，但手动在脑组织切片中描绘这些区域耗时且需要专业知识，需要自动化方法来减少专家工作量

Method: 提出CytoCLIP模型套件，包含两个变体：一个使用低分辨率全区域图像学习整体细胞构筑模式，另一个使用高分辨率图像块学习细胞级细节表示。训练数据来自不同孕周胎儿大脑的NISSL染色组织切片，包括86个低分辨率区域和384个高分辨率区域

Result: CytoCLIP在区域分类和跨模态检索任务中表现优异，全区域分类F1分数0.87，高分辨率图像块分类F1分数0.91，优于现有方法

Conclusion: CytoCLIP能够有效学习大脑细胞构筑的视觉-文本表示，为大脑区域自动识别提供了有效的自动化解决方案

Abstract: The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.

</details>


### [54] [SDiT: Semantic Region-Adaptive for Diffusion Transformers](https://arxiv.org/abs/2601.12283)
*Bowen Lin,Fanjiang Ye,Yihua Liu,Zhenghui Guo,Boyuan Zhang,Weijian Zheng,Yufan Xu,Tiancheng Xing,Yuke Wang,Chengming Zhang*

Main category: cs.CV

TL;DR: SDiT提出了一种无需重新训练的训练免费框架，通过语义感知聚类、复杂度驱动的区域调度和边界感知细化，实现Diffusion Transformers的3倍加速，同时保持与全注意力推理几乎相同的感知和语义质量。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers在文本到图像合成中达到最先进性能，但由于去噪的迭代性质和全局注意力的二次成本，计算开销仍然很大。研究发现去噪动态在空间上是不均匀的——背景区域快速收敛，而边缘和纹理区域演化更活跃。

Method: SDiT提出语义区域自适应扩散变换器，根据区域复杂度分配计算。包含三个核心组件：1) 基于快速Quickshift分割的语义感知聚类；2) 复杂度驱动的区域调度，选择性更新信息丰富的区域；3) 边界感知细化以保持空间连贯性。

Result: 无需任何模型重新训练或架构修改，SDiT实现了高达3.0倍的加速，同时保持与全注意力推理几乎相同的感知和语义质量。

Conclusion: SDiT通过利用去噪动态的空间非均匀性，提出了一种高效的计算分配策略，显著加速Diffusion Transformers推理，为扩散模型的实际部署提供了有前景的解决方案。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.

</details>


### [55] [LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines](https://arxiv.org/abs/2601.12285)
*Safa C. Medin,Gengyan Li,Ziqian Bai,Ruofei Du,Leonhard Helminger,Yinda Zhang,Stephan J. Garbin,Philip L. Davidson,Gregory W. Wornell,Thabo Beeler,Abhimitra Meka*

Main category: cs.CV

TL;DR: 提出了一种基于参数化人脸模型的新型3D人脸化身表示方法，通过辐射场学习实现高效的传统渲染，支持在线流式传输和标准图形平台渲染。


<details>
  <summary>Details</summary>
Motivation: 传统3D人脸化身渲染通常需要复杂的定制工程和集成，难以在传统图形平台上高效运行。本文旨在开发一种既能保持照片级真实感，又能在标准图形硬件上高效渲染的3D人脸表示方法。

Method: 基于参数化人脸模型锚定辐射场，学习3D空间中的辐射流形，提取显式的分层网格以及外观和变形纹理。通过简单的线性混合和alpha合成在静态网格上控制面部动画。

Result: 实现了可控的体积渲染，能够处理复杂的面部特征（头发、皮肤、眼睛）。显式表示支持高效在线流式传输，并能在传统图形平台上使用标准网格和着色器进行渲染，无需定制工程。

Conclusion: 该方法提供了一种高效、可控制且易于部署的3D人脸化身渲染方案，将先进的辐射场技术与传统图形渲染管线相结合，实现了照片级真实感与计算效率的平衡。

Abstract: We introduce a novel representation for efficient classical rendering of photorealistic 3D face avatars. Leveraging recent advances in radiance fields anchored to parametric face models, our approach achieves controllable volumetric rendering of complex facial features, including hair, skin, and eyes. At enrollment time, we learn a set of radiance manifolds in 3D space to extract an explicit layered mesh, along with appearance and warp textures. During deployment, this allows us to control and animate the face through simple linear blending and alpha compositing of textures over a static mesh. This explicit representation also enables the generated avatar to be efficiently streamed online and then rendered using classical mesh and shader-based rendering on legacy graphics platforms, eliminating the need for any custom engineering or integration.

</details>


### [56] [Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations](https://arxiv.org/abs/2601.12303)
*Shizhan Gong,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

TL;DR: PCBM-ReD是一种后处理概念瓶颈模型，通过表示分解将预训练不透明模型转化为可解释模型，自动提取视觉概念并用MLLM标注，在保持高准确率的同时提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在图像识别中取得了显著成功，但其固有的不透明性在关键领域部署时面临挑战。现有的概念解释方法存在概念相关性不可靠、概念定义非视觉化或劳动密集、模型或数据无关假设等局限性。

Method: PCBM-ReD通过表示分解将预训练不透明模型转化为可解释模型：1）从预训练编码器中自动提取视觉概念；2）使用多模态大语言模型（MLLMs）基于视觉可识别性和任务相关性标注和筛选概念；3）通过重构引导优化选择独立概念子集；4）利用CLIP的视觉-文本对齐，将图像表示分解为概念嵌入的线性组合，适配概念瓶颈模型框架。

Result: 在11个图像分类任务上的广泛实验表明，PCBM-ReD实现了最先进的准确率，缩小了与端到端模型的性能差距，并展现出更好的可解释性。

Conclusion: PCBM-ReD成功地将可解释性改造到预训练的不透明模型中，通过自动概念提取和表示分解，在保持高性能的同时提供了更好的模型解释能力。

Abstract: Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.

</details>


### [57] [A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models](https://arxiv.org/abs/2601.12304)
*Wutao Chen,Huaqin Zou,Chen Wan,Lifeng Huang*

Main category: cs.CV

TL;DR: 提出2S-GDA：一个两阶段全局多样性攻击框架，通过文本和视觉双重扰动增强对抗样本的多样性和攻击成功率


<details>
  <summary>Details</summary>
Motivation: 现有的多模态攻击方法存在扰动多样性有限和多阶段流程不稳定的问题，特别是在黑盒场景下，视觉-语言预训练模型容易受到对抗样本攻击

Method: 采用两阶段全局多样性攻击框架：1）文本扰动阶段：结合候选文本扩展和全局感知替换的全局多样性策略；2）视觉扰动阶段：使用多尺度调整和块状随机旋转增强视觉多样性

Result: 在VLP模型上的实验表明，2S-GDA相比现有方法显著提高了攻击成功率，在黑盒设置下提升高达11.17%，且框架模块化，易于与现有方法结合

Conclusion: 2S-GDA通过增强文本和视觉扰动的多样性，有效提高了对抗样本在黑盒场景下的攻击成功率，为解决多模态攻击的局限性提供了有效方案

Abstract: Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.

</details>


### [58] [Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification](https://arxiv.org/abs/2601.12308)
*Anurag Kaushish,Ayan Sar,Sampurna Roy,Sudeshna Chakraborty,Prashant Trivedi,Tanupriya Choudhury,Kanav Gupta*

Main category: cs.CV

TL;DR: AMC-MetaNet是一个轻量级小样本遥感学习框架，通过相关性引导的特征金字塔、自适应通道相关性模块和相关性引导元学习，解决了遥感数据标注少、域偏移大和多尺度对象的问题，参数仅60万，推理时间小于50ms，在多个数据集上达到86.65%的准确率。


<details>
  <summary>Details</summary>
Motivation: 遥感小样本学习面临三个主要挑战：标注数据稀缺、显著的域偏移以及地理空间对象的多尺度特性。现有方法通常依赖大型预训练模型或Transformer，计算成本高且难以适应多尺度变化。

Method: 提出AMC-MetaNet框架，包含三个核心创新：1）相关性引导的特征金字塔捕捉尺度不变模式；2）自适应通道相关性模块学习动态跨尺度关系；3）相关性引导元学习利用相关性模式而非传统的原型平均。整个模型从零开始训练，仅约60万个参数。

Result: 在EuroSAT、NWPU-RESISC45、UC Merced Land Use和AID等多个遥感数据集上，5-way 5-shot分类准确率最高达到86.65%。模型参数比ResNet-18少20倍，单张图像推理时间小于50毫秒，具有高计算效率。

Conclusion: AMC-MetaNet是一个计算高效、尺度感知的框架，适用于真实世界的小样本遥感应用，在保持高性能的同时显著减少了模型复杂度和计算成本。

Abstract: Few-shot learning in remote sensing remains challenging due to three factors: the scarcity of labeled data, substantial domain shifts, and the multi-scale nature of geospatial objects. To address these issues, we introduce Adaptive Multi-Scale Correlation Meta-Network (AMC-MetaNet), a lightweight yet powerful framework with three key innovations: (i) correlation-guided feature pyramids for capturing scale-invariant patterns, (ii) an adaptive channel correlation module (ACCM) for learning dynamic cross-scale relationships, and (iii) correlation-guided meta-learning that leverages correlation patterns instead of conventional prototype averaging. Unlike prior approaches that rely on heavy pre-trained models or transformers, AMC-MetaNet is trained from scratch with only $\sim600K$ parameters, offering $20\times$ fewer parameters than ResNet-18 while maintaining high efficiency ($<50$ms per image inference). AMC-MetaNet achieves up to 86.65\% accuracy in 5-way 5-shot classification on various remote sensing datasets, including EuroSAT, NWPU-RESISC45, UC Merced Land Use, and AID. Our results establish AMC-MetaNet as a computationally efficient, scale-aware framework for real-world few-shot remote sensing.

</details>


### [59] [CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding](https://arxiv.org/abs/2601.12312)
*Yongjun Jeon,Jongmin Shin,Kanggil Park,Seonmin Park,Soyoung Lim,Jung Yong Kim,Jinsoo Rhu,Jongman Kim,Gyu-Seong Choi,Namkee Oh,Kyu-Hwan Jung*

Main category: cs.CV

TL;DR: 提出CurConMix+框架，结合课程引导对比学习、多分辨率时间Transformer和新的LLS48数据集，显著提升手术动作三元组识别性能，并展示跨层级泛化能力。


<details>
  <summary>Details</summary>
Motivation: 手术动作三元组识别对于工作流分析和技能评估具有重要临床价值，但面临类别不平衡、视觉变化细微、语义相互依赖等挑战。现有方法通常只解决部分问题，缺乏整体解决方案。

Method: 基于CurConMix空间表示框架，采用课程引导对比学习策略，结合结构化硬对采样和特征级混合。扩展版本CurConMix+集成多分辨率时间Transformer(MRTT)，自适应融合多尺度时间特征并动态平衡时空线索。同时引入LLS48新数据集，提供分层标注。

Result: 在CholecT45和LLS48数据集上的实验表明，CurConMix+在三元组识别方面优于现有最先进方法，并展现出强大的跨层级泛化能力，其细粒度特征可有效迁移到更高层级的阶段和步骤识别任务。

Conclusion: 该框架和数据集为层次感知、可复现和可解释的手术工作流理解提供了统一基础。代码和数据集将在GitHub公开，以促进可复现性和进一步研究。

Abstract: Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.

</details>


### [60] [S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection](https://arxiv.org/abs/2601.12313)
*Xiangyu Hu,Yicheng Hong,Hongchuang Zheng,Wenjun Zeng,Bingyao Liu*

Main category: cs.CV

TL;DR: S²F-Net：一种基于频谱差异的跨模型合成图像检测框架，通过可学习频率注意力模块增强判别性频带，在17类生成模型上达到90.49%的检测准确率


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展对具有强泛化能力的检测方案提出了迫切需求。现有检测方法通常过度拟合特定源模型，在面对未见过的生成架构时性能显著下降。

Method: 提出跨模型检测框架S²F-Net，核心在于探索和利用真实与合成纹理之间的固有频谱差异。引入可学习频率注意力模块，通过协同空间纹理分析和频谱依赖关系，自适应加权和增强判别性频带。

Result: 在包含17类生成模型的AIGCDetectBenchmark上，S²F-Net实现了90.49%的检测准确率，在跨域检测场景中显著优于各种现有基线方法。

Conclusion: 通过关注上采样操作在频域留下的独特指纹，从根本上提高了模型的泛化性能，为解决合成图像检测中的过拟合问题提供了有效方案。

Abstract: The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral dependencies.On the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.

</details>


### [61] [EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation](https://arxiv.org/abs/2601.12326)
*Jing Zhang,Bingjie Fan*

Main category: cs.CV

TL;DR: EmoKGEdit：基于多模态情感关联知识图谱的无训练图像情感编辑框架，通过解耦情感与内容表示实现精确且结构保持的情感编辑


<details>
  <summary>Details</summary>
Motivation: 现有图像情感编辑方法难以从潜在内容表示中解耦情感线索，导致情感表达弱且视觉结构扭曲。需要一种能精确编辑情感同时保持视觉结构的方法。

Method: 提出EmoKGEdit框架：1）构建多模态情感关联知识图谱（MSA-KG），解耦对象、场景、属性、视觉线索和情感之间的复杂关系；2）将MSA-KG作为外部知识支持思维链推理，指导多模态大模型推断情感相关视觉线索；3）设计解耦结构-情感编辑模块，在潜在空间中分离情感属性和布局特征。

Result: 大量实验表明，EmoKGEdit在情感保真度和内容保持方面表现优异，优于现有最先进方法。

Conclusion: EmoKGEdit通过知识图谱驱动的解耦方法，实现了精确且结构保持的图像情感编辑，解决了现有方法在情感表达和视觉结构保持方面的局限性。

Abstract: Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.

</details>


### [62] [FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching](https://arxiv.org/abs/2601.12329)
*Mithlesh Singla,Seema Kumari,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出FlowIID：基于流匹配的轻量级本征图像分解方法，在保持性能的同时大幅减少参数量，适合实时应用


<details>
  <summary>Details</summary>
Motivation: 现有本征图像分解模型虽然效果好，但参数量大，难以与其他模型结合应用于实际场景，需要更轻量高效的解决方案

Method: 设计FlowIID架构，结合VAE引导的潜在空间和流匹配模块，实现稳定的反照率和阴影分解，单步推理完成

Result: FlowIID在多个基准测试中取得竞争性甚至优于现有模型的结果，同时保持参数高效和单步推理优势

Conclusion: FlowIID提供了一种参数高效、性能优越的本征图像分解方案，特别适合资源受限和实时视觉应用部署

Abstract: Intrinsic Image Decomposition (IID) separates an image into albedo and shading components. It is a core step in many real-world applications, such as relighting and material editing. Existing IID models achieve good results, but often use a large number of parameters. This makes them costly to combine with other models in real-world settings. To address this problem, we propose a flow matching-based solution. For this, we design a novel architecture, FlowIID, based on latent flow matching. FlowIID combines a VAE-guided latent space with a flow matching module, enabling a stable decomposition of albedo and shading. FlowIID is not only parameter-efficient, but also produces results in a single inference step. Despite its compact design, FlowIID delivers competitive and superior results compared to existing models across various benchmarks. This makes it well-suited for deployment in resource-constrained and real-time vision applications.

</details>


### [63] [SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence](https://arxiv.org/abs/2601.12357)
*Hailing Jin,Huiying Li*

Main category: cs.CV

TL;DR: SimpleMatch是一个用于语义匹配的简单而有效的框架，通过轻量级上采样解码器和多尺度监督损失，在低分辨率下实现高性能，同时减少51%的训练内存使用。


<details>
  <summary>Details</summary>
Motivation: 当前语义匹配方法依赖高分辨率输入以获得最佳性能，这导致大量计算开销。现有方法存在一个根本限制：深度下采样操作导致相邻关键点特征不可逆地融合，当语义不同的关键点落在同一降采样感受野内时会出现问题。

Method: 提出SimpleMatch框架，包含：1）轻量级上采样解码器，逐步将深层特征上采样到1/4分辨率以恢复空间细节；2）多尺度监督损失，确保上采样特征在不同空间尺度上保持判别性特征；3）稀疏匹配和基于窗口的定位，优化训练内存使用。

Result: 在252×252分辨率（比当前SOTA方法小3.3倍）下，SimpleMatch在SPair-71k基准测试上达到84.1%的PCK@0.1性能，同时训练内存使用减少51%。

Conclusion: SimpleMatch为语义匹配的未来研究提供了一个实用且高效的基线，能够在低分辨率下实现强大性能，解决了当前方法对高分辨率输入的依赖问题。

Abstract: Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, a limitation of these approaches is their dependence on high-resolution input images to achieve optimal performance, which results in considerable computational overhead. In this work, we address a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. This issue is triggered when semantically distinct keypoints fall within the same downsampled receptive field (e.g., 16x16 patches). To address this issue, we present SimpleMatch, a simple yet effective framework for semantic correspondence that delivers strong performance even at low resolutions. We propose a lightweight upsample decoder that progressively recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss that ensures the upsampled features retain discriminative features across different spatial scales. In addition, we introduce sparse matching and window-based localization to optimize training memory usage and reduce it by 51%. At a resolution of 252x252 (3.3x smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. We believe this framework provides a practical and efficient baseline for future research in semantic correspondence. Code is available at: https://github.com/hailong23-jin/SimpleMatch.

</details>


### [64] [DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data](https://arxiv.org/abs/2601.12366)
*Jiafei Zhang,Songliang Cao,Binghui Xu,Yanan Li,Weiwei Jia,Tingting Wu,Hao Lu,Weijuan Hu,Zhiguo Han*

Main category: cs.CV

TL;DR: DepthCropSeg++是一个用于作物分割的基础模型，能够在开放田间环境下分割不同作物品种，在多个测试场景中表现优异，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前作物分割模型大多基于有限数据训练，只能在特定作物类型或受控环境下表现良好。现有基础模型虽然具有强大的泛化能力，但作物分割领域缺乏大规模标注数据集。本研究旨在构建一个能够跨物种、跨场景泛化的作物分割基础模型。

Method: 1) 扩展了跨物种、跨场景的作物分割数据集，包含28,406张图像，涵盖30+物种和15种环境条件；2) 基于ViT-Adapter语义分割架构，增强动态上采样以提高细节感知；3) 采用两阶段自训练管道进行模型训练。

Result: 在综合测试集上达到93.11% mIoU，显著优于监督基线（+0.36%）和通用视觉基础模型如SAM（+48.57%）。在夜间环境（86.90% mIoU）、高密度冠层（90.09% mIoU）和未见作物品种（90.09% mIoU）等挑战性场景中表现优异。

Conclusion: DepthCropSeg++建立了作物分割的新技术水平，展示了基础模型在农业视觉任务中的潜力，能够有效处理开放田间环境下的跨物种、跨场景作物分割问题。

Abstract: DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.

</details>


### [65] [Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12379)
*Jiahui Sheng,Yidan Shi,Shu Xiang,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 提出了一种基于分数生成模型的高光谱异常检测方法ScoreAD，利用数据分布的梯度场来区分背景和异常光谱


<details>
  <summary>Details</summary>
Motivation: 高光谱图像中的光谱数据通常满足流形假设，背景光谱位于低维流形上，而异常光谱由于独特的谱特征不符合背景流形分布。基于这一差异，可以利用生成模型进行异常检测。

Method: 提出ScoreAD方法：1）使用分数生成模型在整个高光谱图像的光谱数据上训练；2）测试时，每个光谱通过扰动核处理，然后输入训练好的SGM获取估计分数；3）利用背景和异常光谱在流形分布上的差异进行检测。

Result: 在四个高光谱数据集上的实验证明了该方法的有效性。

Conclusion: 基于高光谱流形假设和分数生成模型的方法能够有效检测高光谱图像中的异常，代码已开源。

Abstract: Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/jiahuisheng/ScoreAD.

</details>


### [66] [A Hierarchical Benchmark of Foundation Models for Dermatology](https://arxiv.org/abs/2601.12382)
*Furkan Yuceyalcin,Abdurrahim Yilmaz,Burak Temelkuran*

Main category: cs.CV

TL;DR: 该研究评估了10个基础模型在皮肤病变分层分类中的表现，发现存在"粒度差距"：通用医学模型在高级别筛查中表现优异，但皮肤病专用模型在细粒度亚型分类中更出色。


<details>
  <summary>Details</summary>
Motivation: 当前皮肤病学基准通常将复杂的诊断分类简化为二元分类任务（如区分黑色素瘤与良性痣），这种过度简化掩盖了模型执行细粒度鉴别诊断的能力，而这对于临床工作流程整合至关重要。

Method: 使用DERM12345数据集（包含40个病变亚类），计算10个基础模型的冻结嵌入并训练轻量级适配器模型，采用五折交叉验证。引入分层评估框架，在四个临床粒度级别评估性能：40个亚类、15个主类、2和4个超类以及二元恶性检测。

Result: 发现模型能力存在"粒度差距"：MedImageInsights在二元恶性检测中表现最佳（加权F1分数97.52%），但在细粒度40类亚型分类中降至65.50%。相反，MedSigLip（69.79%）和皮肤病专用模型（Derm Foundation和MONET）在细粒度40类亚型鉴别中表现出色，但在更广泛的分类任务中整体性能低于MedImageInsights。

Conclusion: 通用医学基础模型对于高级别筛查非常有效，但诊断支持系统所需的细粒度区分需要专门的建模策略。

Abstract: Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a "granularity gap" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.

</details>


### [67] [Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation](https://arxiv.org/abs/2601.12391)
*Dasith de Silva Edirimuni,Ajmal Saeed Mian*

Main category: cs.CV

TL;DR: 提出CPVQ-VAE和LFMM方法，实现无需外部数据库检索的纯点云场景生成，通过类别分区码本解决复杂场景中对象解码问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法主要生成边界框参数，扩散方法生成类别标签和潜在特征后仍需从预定义数据库检索对象。对于复杂多类别场景，当前自动编码器无法有效将扩散生成的潜在特征解码为符合目标类别的正确点云对象。

Method: 1. 提出类别分区向量量化变分自编码器(CPVQ-VAE)，采用类别分区码本，码向量按类别标记；2. 提出类别感知运行平均更新解决码本坍缩问题；3. 设计专门用于场景生成的潜在空间流匹配模型(LFMM)生成对象特征和类别标签；4. CPVQ-VAE通过类别感知逆查找将生成特征映射到码本条目，解码为类别特定点云形状。

Result: 方法可靠恢复合理点云场景，在复杂客厅场景上实现Chamfer误差减少70.4%，Point2Mesh误差减少72.3%，实现无需外部对象数据库检索的纯点云生成。

Conclusion: 提出的CPVQ-VAE和LFMM框架有效解决了复杂多类别3D场景生成中的对象解码问题，通过类别分区码本和类别感知更新机制，实现了高质量的点云场景生成，显著优于现有方法。

Abstract: Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\textit{codebook collapse}$, we propose a $\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.

</details>


### [68] [HOT-POT: Optimal Transport for Sparse Stereo Matching](https://arxiv.org/abs/2601.12423)
*Antonin Clerc,Michael Quellmalz,Moritz Piening,Philipp Flotho,Gregor Kornhardt,Gabriele Steidl*

Main category: cs.CV

TL;DR: 该论文提出了一种基于最优传输理论的稀疏特征立体匹配方法，利用相机几何的线约束来解决面部标志点等稀疏特征匹配的挑战。


<details>
  <summary>Details</summary>
Motivation: 立体视觉在图像间面临遮挡、运动和相机畸变等挑战，特别是在面部标志点等稀疏特征匹配中，由于参数敏感性导致问题更加复杂。需要克服这种不适定性并实现无监督的稀疏匹配。

Method: 从最优传输视角考虑相机几何的线约束，将相机投影点建模为（半）线，提出使用经典极线距离和3D射线距离来量化匹配质量。将这些距离作为（部分）最优传输问题的成本函数，得到可高效求解的分配问题。还通过层次最优传输问题扩展到无监督对象匹配。

Result: 提出的算法能够高效进行特征和对象匹配，在数值实验中得到验证。特别关注面部分析应用，旨在匹配不同的标志点标注规范。

Conclusion: 基于最优传输的线约束方法为稀疏特征立体匹配提供了一种有效的解决方案，特别是在面部分析中处理不同标注规范的匹配问题。

Abstract: Stereo vision between images faces a range of challenges, including occlusions, motion, and camera distortions, across applications in autonomous driving, robotics, and face analysis. Due to parameter sensitivity, further complications arise for stereo matching with sparse features, such as facial landmarks. To overcome this ill-posedness and enable unsupervised sparse matching, we consider line constraints of the camera geometry from an optimal transport (OT) viewpoint. Formulating camera-projected points as (half)lines, we propose the use of the classical epipolar distance as well as a 3D ray distance to quantify matching quality. Employing these distances as a cost function of a (partial) OT problem, we arrive at efficiently solvable assignment problems. Moreover, we extend our approach to unsupervised object matching by formulating it as a hierarchical OT problem. The resulting algorithms allow for efficient feature and object matching, as demonstrated in our numerical experiments. Here, we focus on applications in facial analysis, where we aim to match distinct landmarking conventions.

</details>


### [69] [SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition](https://arxiv.org/abs/2601.12432)
*Shunyu Huang,Yunjiao Zhou,Jianfei Yang*

Main category: cs.CV

TL;DR: SkeFi提出了一种新颖的跨模态知识转移方法，利用数据丰富的RGB模态来提升无线传感器（LiDAR和mmWave）的骨架估计和动作识别性能，解决了无线传感器数据不足和噪声大的问题。


<details>
  <summary>Details</summary>
Motivation: 基于RGB相机的骨架动作识别在黑暗环境下性能下降且存在隐私问题，限制了在智能家居和医院等场景的应用。无线传感器（LiDAR和mmWave）作为非侵入式替代方案，但面临数据不足和骨架关键点噪声大的挑战。

Method: 提出SkeFi框架，采用跨模态知识转移方法从RGB模态获取知识。设计了增强的时间相关性自适应图卷积（TC-AGC）和帧交互增强来处理缺失或不连续帧的噪声。通过双时间卷积增强多尺度时间建模，结合TC-AGC和时间建模实现跨模态转移。

Result: 实验表明SkeFi在mmWave和LiDAR传感器上实现了最先进的性能，能够从噪声无线传感器中提取准确的姿态和动作。

Conclusion: SkeFi通过创新的跨模态知识转移和时间建模方法，成功解决了无线传感器骨架动作识别中的数据不足和噪声问题，为黑暗环境和隐私敏感场景提供了可行的替代方案。

Abstract: Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at https://github.com/Huang0035/Skefi.

</details>


### [70] [Adversarial Defense in Vision-Language Models: An Overview](https://arxiv.org/abs/2601.12443)
*Xiaowei Fu,Lei Zhang*

Main category: cs.CV

TL;DR: 本文综述了视觉语言模型对抗防御的三种主要范式：训练时防御、测试时自适应防御和无训练防御，分析了各自的优缺点及当前挑战。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型的广泛应用，其对抗攻击的脆弱性引发了安全担忧。攻击可能损害跨模态任务中的模型性能和系统安全，因此需要系统性地研究防御策略。

Method: 本文采用文献综述方法，系统分析三种防御范式：1）训练时防御（通过对抗性微调改进训练过程）；2）测试时自适应防御（在推理时更新参数处理对抗样本）；3）无训练防御（通过修改对抗输入或特征嵌入来缓解攻击影响）。

Result: 综述总结了各种防御方法的最新进展，识别了各自的优势与局限：训练时防御有效但计算成本高且泛化性有限；测试时自适应防御灵活但复杂度高；无训练防御无需额外训练但效果可能受限。

Conclusion: 增强视觉语言模型鲁棒性仍面临挑战，需要进一步研究更高效、通用的防御策略，平衡防御效果与计算成本，以应对日益复杂的对抗攻击威胁。

Abstract: The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.

</details>


### [71] [Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild](https://arxiv.org/abs/2601.12464)
*Yanrui Lu,Danyang Chen,Haowen Xiao,Jiarui Zhu,Fukang Ge,Binqian Zou,Jiali Guan,Jiayin Liang,Yuting Wang,Ziqian Guan,Xiangcheng Bao,Jinhao Bi,Lin Gu,Jun He,Yingying Zhu*

Main category: cs.CV

TL;DR: 该研究创建了一个大规模、多源的多细胞器实例分割基准数据集，包含超过10万张2D电子显微镜图像，涵盖多种细胞类型和五种细胞器类别，以解决现有基准数据集无法捕捉真实世界EM数据异质性和大空间上下文的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于小型、精选数据集的基准无法捕捉真实世界电子显微镜数据的固有异质性和大空间上下文，这对当前基于图像块的方法构成了根本性限制，需要开发更全面的基准来评估和改进细胞器实例分割方法。

Method: 开发了大规模、多源的多细胞器实例分割基准数据集，包含超过10万张2D EM图像，涵盖多种细胞类型和五种细胞器类别。使用设计的连通性感知标签传播算法（3D LPA）生成数据集标注，并进行专家精修。进一步对U-Net、SAM变体和Mask2Former等最先进模型进行了基准测试。

Result: 基准测试结果显示当前模型存在多个局限性：难以在异质EM数据上泛化，对具有全局、分布式形态的细胞器（如内质网）表现不佳。这些发现凸显了局部上下文模型与在真实世界变异中建模长程结构连续性挑战之间的根本性不匹配。

Conclusion: 该研究创建了一个大规模、多源的细胞器实例分割基准数据集，揭示了当前模型在处理真实世界EM数据异质性和长程结构连续性方面的局限性，强调了开发能够处理全局形态和真实世界变异的新方法的必要性。数据集和标注工具将公开发布。

Abstract: Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.

</details>


### [72] [NeuralFur: Animal Fur Reconstruction From Multi-View Images](https://arxiv.org/abs/2601.12481)
*Vanessa Sklyarova,Berna Kabadayi,Anastasios Yiannakidis,Giorgio Becherini,Michael J. Black,Justus Thies*

Main category: cs.CV

TL;DR: 提出首个基于多视角图像的动物毛发三维重建方法，利用视觉语言模型指导毛发长度和生长方向，实现不同动物毛发的高保真建模。


<details>
  <summary>Details</summary>
Motivation: 动物毛发重建面临细粒度细节、自遮挡和视角依赖外观等挑战，且缺乏可用于学习毛发先验的数据集，需要一种通用方法来重建各种动物的毛发。

Method: 1. 使用传统多视角立体技术重建粗略表面几何；2. 利用视觉语言模型获取身体各部位毛发的真实长度结构信息；3. 构建无毛几何体并在其上生长毛发束；4. 使用几何和光度损失进行监督；5. 利用VLM指导毛发生长方向和重力向量关系。

Result: 该方法能够泛化到多种不同毛发类型的动物，实现了高保真的三维毛发建模，解决了毛发方向模糊性问题。

Conclusion: 通过结合视觉语言模型的知识指导和多视角输入，提出了一种新颖的动物毛发三维重建框架，为缺乏训练数据的领域提供了有效的解决方案。

Abstract: Reconstructing realistic animal fur geometry from images is a challenging task due to the fine-scale details, self-occlusion, and view-dependent appearance of fur. In contrast to human hairstyle reconstruction, there are also no datasets that can be leveraged to learn a fur prior for different animals. In this work, we present a first multi-view-based method for high-fidelity 3D fur modeling of animals using a strand-based representation, leveraging the general knowledge of a vision language model. Given multi-view RGB images, we first reconstruct a coarse surface geometry using traditional multi-view stereo techniques. We then use a vision language model (VLM) system to retrieve information about the realistic length structure of the fur for each part of the body. We use this knowledge to construct the animal's furless geometry and grow strands atop it. The fur reconstruction is supervised with both geometric and photometric losses computed from multi-view images. To mitigate orientation ambiguities stemming from the Gabor filters that are applied to the input images, we additionally utilize the VLM to guide the strands' growth direction and their relation to the gravity vector that we incorporate as a loss. With this new schema of using a VLM to guide 3D reconstruction from multi-view inputs, we show generalization across a variety of animals with different fur types. For additional results and code, please refer to https://neuralfur.is.tue.mpg.de.

</details>


### [73] [Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation](https://arxiv.org/abs/2601.12493)
*Mehrdad Noori,Gustavo Adolfo Vargas Hakim,David Osowiechi,Fereshteh Shakeri,Ali Bahri,Moslem Yazdanpanah,Sahar Dastani,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出Histopath-C基准测试和LATTE方法，用于评估和提升医学视觉语言模型在组织病理学图像中的鲁棒性，应对真实世界分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像存在染色、污染、模糊和噪声等严重领域偏移问题，这些会显著降低视觉语言模型的下游性能，需要专门的方法来应对这些真实世界的分布变化。

Method: 1) 创建Histopath-C基准测试，包含模拟真实世界分布偏移的合成损坏；2) 提出LATTE方法，一种利用多个文本模板的低秩适应策略，减少模型对多样化文本输入的敏感性；3) 动态应用损坏到现有数据集，并实时评估测试时适应机制。

Result: LATTE方法在多个组织病理学数据集上超越了为自然图像设计的最先进测试时适应方法，证明了所提设计在组织病理学图像中实现鲁棒适应的有效性。

Conclusion: 提出的Histopath-C基准测试和LATTE方法能够有效评估和提升医学视觉语言模型在组织病理学领域的鲁棒性，应对真实世界分布偏移挑战。

Abstract: Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at https://github.com/Mehrdad-Noori/Histopath-C.

</details>


### [74] [Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods](https://arxiv.org/abs/2601.12500)
*Yaowu Fan,Jia Wan,Tao Han,Andy J. Ma,Antoni B. Chan*

Main category: cs.CV

TL;DR: 提出基于移动无人机的大规模密集人群计数与跟踪方案，引入新数据集MovingDroneCrowd++，开发GD3A密度图分解方法和DVTrack跟踪方法，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖固定摄像头数据集，空间覆盖有限，无法满足大规模密集人群分析需求。移动无人机能提供更灵活的视角和更全面的场景覆盖，但缺乏相应的高质量数据集和方法。

Method: 1) 引入MovingDroneCrowd++数据集，由移动无人机采集，覆盖不同飞行高度、相机角度和光照条件；2) 提出GD3A方法，通过最优传输和自适应dustbin分数建立像素级行人描述符对应关系，将全局密度图分解为共享、流入和流出分量；3) 基于此框架开发DVTrack方法，通过描述符投票机制将描述符级匹配转换为实例级关联。

Result: 实验结果显示，在密集人群和复杂运动条件下，该方法显著优于现有方法：计数误差降低47.4%，跟踪性能提升39.2%。

Conclusion: 移动无人机为大规模密集人群分析提供了更灵活的解决方案，提出的GD3A和DVTrack方法在MovingDroneCrowd++数据集上表现出色，为视频级人群计数和跟踪提供了有效的新方法。

Abstract: Counting and tracking dense crowds in large-scale scenes is highly challenging, yet existing methods mainly rely on datasets captured by fixed cameras, which provide limited spatial coverage and are inadequate for large-scale dense crowd analysis. To address this limitation, we propose a flexible solution using moving drones to capture videos and perform video-level crowd counting and tracking of unique pedestrians across entire scenes. We introduce MovingDroneCrowd++, the largest video-level dataset for dense crowd counting and tracking captured by moving drones, covering diverse and complex conditions with varying flight altitudes, camera angles, and illumination. Existing methods fail to achieve satisfactory performance on this dataset. To this end, we propose GD3A (Global Density Map Decomposition via Descriptor Association), a density map-based video individual counting method that avoids explicit localization. GD3A establishes pixel-level correspondences between pedestrian descriptors across consecutive frames via optimal transport with an adaptive dustbin score, enabling the decomposition of global density maps into shared, inflow, and outflow components. Building on this framework, we further introduce DVTrack, which converts descriptor-level matching into instance-level associations through a descriptor voting mechanism for pedestrian tracking. Experimental results show that our methods significantly outperform existing approaches under dense crowds and complex motion, reducing counting error by 47.4 percent and improving tracking performance by 39.2 percent.

</details>


### [75] [Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images](https://arxiv.org/abs/2601.12512)
*Mohd Usama,Belal Ahmad,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出基于CycleGAN的无监督医学图像域适应方法，解决MRI扫描因不同扫描仪和机构导致的域偏移问题，无需配对训练数据即可实现双向域映射。


<details>
  <summary>Details</summary>
Motivation: 不同扫描仪或机构获取的MRI扫描存在域偏移（硬件、协议、采集参数差异），导致在源域数据上训练的深度学习模型在目标域图像上性能下降。

Method: 基于CycleGAN的无监督域适应模型，利用CycleGAN学习源域和目标域之间的双向映射，无需配对训练数据，通过内容和差异损失保持图像解剖内容完整性。

Result: 在多个MRI数据集上的实验表明，该模型在无标签数据情况下能有效实现双向域适应，统计结果证实方法能提升模型性能并减少域相关变异性。

Conclusion: 该方法为改善医疗诊断准确性提供了有前景的途径，有助于实现更精确和一致的医学图像分析。

Abstract: Magnetic Resonance Imaging (MRI) scans acquired from different scanners or institutions often suffer from domain shifts owing to variations in hardware, protocols, and acquisition parameters. This discrepancy degrades the performance of deep learning models trained on source domain data when applied to target domain images. In this study, we propose a Cycle-GAN-based model for unsupervised medical-image domain adaptation. Leveraging CycleGANs, our model learns bidirectional mappings between the source and target domains without paired training data, preserving the anatomical content of the images. By leveraging Cycle-GAN capabilities with content and disparity loss for adaptation tasks, we ensured image-domain adaptation while maintaining image integrity. Several experiments on MRI datasets demonstrated the efficacy of our model in bidirectional domain adaptation without labelled data. Furthermore, research offers promising avenues for improving the diagnostic accuracy of healthcare. The statistical results confirm that our approach improves model performance and reduces domain-related variability, thus contributing to more precise and consistent medical image analysis.

</details>


### [76] [Deep Feature Deformation Weights](https://arxiv.org/abs/2601.12527)
*Richard Liu,Itai Lang,Rana Hanocka*

Main category: cs.CV

TL;DR: 提出一种结合传统网格变形精度与数据驱动语义性的方法，通过深度特征邻近性生成平滑语义变形权重，支持实时计算和高分辨率网格处理


<details>
  <summary>Details</summary>
Motivation: 传统基于手柄的网格变形方法需要用户预先知道手柄的理想分布，且手柄到变形行为的映射不直观、非语义；而现代数据驱动方法虽然能获得语义编辑，但速度慢且不精确

Method: 使用深度特征邻近性生成平滑语义变形权重，无需额外正则化；提出重心特征蒸馏管道，利用形状渲染的视觉信号最小化蒸馏成本；通过特征空间约束和局部性加权保留传统方法特性；利用场表示自动检测语义对称性

Result: 权重可实时计算，支持百万面网格实时变形；语义先验支持语义部分协同变形；相比传统和神经方法，高分辨率网格权重计算时间从数小时缩短到一分钟内

Conclusion: 成功融合了数据语义先验与传统框架的精确控制和速度，实现了简单有效、实时且语义感知的网格变形方法

Abstract: Handle-based mesh deformation has been a long-standing paradigm in computer graphics, enabling intuitive shape edits from sparse controls. Classic techniques offer precise and rapid deformation control. However, they solve an optimization problem with constraints defined by control handle placement, requiring a user to know apriori the ideal distribution of handles on the shape to accomplish the desired edit. The mapping from handle set to deformation behavior is often unintuitive and, importantly, non-semantic. Modern data-driven methods, on the other hand, leverage a data prior to obtain semantic edits, but are slow and imprecise. We propose a technique that fuses the semantic prior of data with the precise control and speed of traditional frameworks. Our approach is surprisingly simple yet effective: deep feature proximity makes for smooth and semantic deformation weights, with no need for additional regularization. The weights can be computed in real-time for any surface point, whereas prior methods require optimization for new handles. Moreover, the semantic prior from deep features enables co-deformation of semantic parts. We introduce an improved feature distillation pipeline, barycentric feature distillation, which efficiently uses the visual signal from shape renders to minimize distillation cost. This allows our weights to be computed for high resolution meshes in under a minute, in contrast to potentially hours for both classical and neural methods. We preserve and extend properties of classical methods through feature space constraints and locality weighting. Our field representation allows for automatic detection of semantic symmetries, which we use to produce symmetry-preserving deformations. We show a proof-of-concept application which can produce deformations for meshes up to 1 million faces in real-time on a consumer-grade machine.

</details>


### [77] [XRefine: Attention-Guided Keypoint Match Refinement](https://arxiv.org/abs/2601.12530)
*Jan Fabian Schmid,Annika Hagemann*

Main category: cs.CV

TL;DR: XRefine：一种与检测器无关的亚像素关键点精炼方法，通过跨注意力架构在图像块上操作，无需依赖检测器内部表示，可泛化到不同检测器并扩展到多视角特征跟踪。


<details>
  <summary>Details</summary>
Motivation: 当前关键点检测器产生的匹配在空间上不准确，现有精炼方法通常与特定检测器绑定，需要为每个检测器重新训练，缺乏通用性。

Method: 提出XRefine方法，基于跨注意力架构，仅使用以匹配关键点为中心的图像块来预测精炼后的关键点坐标，不依赖检测器内部表示，可扩展到多视角特征跟踪。

Result: 在MegaDepth、KITTI和ScanNet数据集上的实验表明，该方法能持续提升几何估计精度，相比现有精炼方法性能更优，同时保持运行时效率。

Conclusion: XRefine是一种有效的检测器无关关键点精炼方法，能提高匹配精度并泛化到不同检测器，代码和模型已开源。

Abstract: Sparse keypoint matching is crucial for 3D vision tasks, yet current keypoint detectors often produce spatially inaccurate matches. Existing refinement methods mitigate this issue through alignment of matched keypoint locations, but they are typically detector-specific, requiring retraining for each keypoint detector. We introduce XRefine, a novel, detector-agnostic approach for sub-pixel keypoint refinement that operates solely on image patches centered at matched keypoints. Our cross-attention-based architecture learns to predict refined keypoint coordinates without relying on internal detector representations, enabling generalization across detectors. Furthermore, XRefine can be extended to handle multi-view feature tracks. Experiments on MegaDepth, KITTI, and ScanNet demonstrate that the approach consistently improves geometric estimation accuracy, achieving superior performance compared to existing refinement methods while maintaining runtime efficiency. Our code and trained models can be found at https://github.com/boschresearch/xrefine.

</details>


### [78] [BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images](https://arxiv.org/abs/2601.12533)
*Md. Ahanaf Arif Khan,Ariful Islam,Sangeeta Biswas,Md. Iqbal Aziz Khan,Subrata Pramanik,Sanjoy Kumar Chakrabarty,Bimal Kumar Pramanik*

Main category: cs.CV

TL;DR: 本文介绍了BirdsEye-RU数据集，这是一个包含2,978张图像、超过8,000个标注人脸的俯视视角人脸检测数据集，专门用于解决俯视图像中人脸检测的挑战。


<details>
  <summary>Details</summary>
Motivation: 俯视图像中的人脸检测面临极端尺度变化和环境杂波的重大挑战，现有数据集难以满足这一特定需求。

Method: 创建了BirdsEye-RU数据集，包含无人机图像和智能手机从高空拍摄的图像，专门捕捉不同环境下的小型和远距离人脸。

Result: 构建了包含2,978张图像、超过8,000个标注人脸的综合性数据集，涵盖了多样化的环境和拍摄条件。

Conclusion: BirdsEye-RU数据集为俯视视角人脸检测研究提供了重要资源，已公开免费提供，可促进该领域的研究发展。

Abstract: Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.

</details>


### [79] [Encoding Emotion Through Self-Supervised Eye Movement Reconstruction](https://arxiv.org/abs/2601.12534)
*Marcus Ma,Jordan Prescott,Emily Zhou,Tiantian Feng,Kleanthis Avramidis,Gabor Mihaly Toth,Shrikanth Narayanan*

Main category: cs.CV

TL;DR: 该研究开发了一种基于自监督眼动重建的新型注视检测模型，利用低分辨率自然视频预测情绪表达的多模态标记，并在大屠杀幸存者访谈数据上验证了模型对情绪行为的预测能力。


<details>
  <summary>Details</summary>
Motivation: 虽然眼动与情绪表达的关系已有研究证实，但现有研究多依赖高分辨率眼动追踪设备，限制了研究结果的广泛应用。本研究旨在探索如何从自然、低分辨率视频中利用眼动预测情绪表达的多模态标记。

Method: 受语言模型预训练方法启发，开发了一种新型注视检测模型，采用自监督眼动重建方法有效利用未标记视频。使用该模型的编码器嵌入对两个下游任务进行微调：1) 眼动与语音方向性情绪估计的对齐；2) 使用眼动预测三种瞬时情绪行为表现（笑、哭/抽泣、叹气）。

Result: 新模型能够有效预测情绪结果，观察到预训练性能与情绪处理性能之间存在正相关关系。模型在两项实验中均表现出对情绪行为的预测能力。

Conclusion: 自监督眼动重建是编码眼动所携带情感信号的有效方法，为从低分辨率自然视频中提取情绪信息提供了可行途径。

Abstract: The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.

</details>


### [80] [PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception](https://arxiv.org/abs/2601.12551)
*Tong Wu*

Main category: cs.CV

TL;DR: PISE是一个基于物理信息的深度鬼成像框架，用于低带宽边缘感知，通过结合伴随算子初始化和语义指导，在5%采样率下将分类准确率提高2.57%，方差降低9倍


<details>
  <summary>Details</summary>
Motivation: 在边缘计算场景中，低带宽通信限制了感知系统的性能，需要开发能够在有限采样率下保持高准确性的感知框架

Method: 提出PISE框架，结合物理信息深度学习和鬼成像技术，采用伴随算子初始化来优化重建过程，并引入语义指导来提升分类性能

Result: 在5%采样率下，PISE将分类准确率提高了2.57%，同时将方差降低了9倍，显著提升了低带宽边缘感知的稳定性和准确性

Conclusion: PISE框架通过物理信息深度学习和语义指导的结合，有效解决了低带宽边缘感知的挑战，为资源受限环境下的智能感知提供了新方法

Abstract: We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.

</details>


### [81] [From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2](https://arxiv.org/abs/2601.12636)
*Satyaki Roy Chowdhury,Aswathnarayan Radhakrishnan,Hsiao Jou Hsu,Hari Subramoni,Joachim Moortgat*

Main category: cs.CV

TL;DR: 本文分析了基于Swin-Transformer的U-Net模型(Swin-BathyUNet)在Sentinel-2卫星测深中的应用，研究了模型如何推断水深以及何时预测可信，提出了改进模型鲁棒性和跨区域迁移的实用指导。


<details>
  <summary>Details</summary>
Motivation: Sentinel-2卫星测深技术在不同地点的稳健部署仍然具有挑战性，需要理解深度学习模型如何推断水深以及何时预测可信，以提高模型的可靠性和跨区域适用性。

Method: 采用Swin-Transformer U-Net架构，通过留一波段研究分析光谱重要性，开发基于消融的回归类激活映射(A-CAM-R)验证解释可靠性，进行注意力消融实验，并开展跨区域推理测试（在一个地点训练，在另一个地点测试）。

Result: 绿色和蓝色波段对水深推断最重要；A-CAM-R能有效定位模型依赖的证据区域；解码器条件化跨注意力机制能提高对水面反光/泡沫的鲁棒性；跨区域推理显示误差随水深线性增加，双峰水深分布会加剧中/深水区误差。

Conclusion: 提出了实用指导：保持宽感受野，保护绿/蓝通道的辐射保真度，预处理近岸高亮度高方差区域，结合深度感知校准进行轻量级目标地点微调，以实现跨区域迁移。

Abstract: Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.

</details>


### [82] [Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT](https://arxiv.org/abs/2601.12638)
*Ninnart Fuengfusin,Keisuke Yoneda,Naoki Suganuma*

Main category: cs.CV

TL;DR: 提出用于PointPillars的混合精度量化框架，通过敏感层搜索和异常值处理，在保持性能的同时实现2.35倍加速和2.26倍模型压缩


<details>
  <summary>Details</summary>
Motivation: 激光雷达3D目标检测需要实时运行，但直接量化会导致性能下降，主要原因是激光雷达数据的宽数值分布和极端异常值

Method: 1) 混合精度框架：通过PTQ逐层量化搜索敏感层，将top-k敏感层设为浮点，贪婪搜索混合精度组合；2) 异常值处理：使用少量校准数据减少异常值影响；3) 提供PTQ（无需训练）和QAT两种流程

Result: PTQ流程无需训练即可获得混合精度模型，QAT流程性能接近浮点模型。TensorRT部署下，延迟降低2.35倍，模型大小减少2.26倍

Conclusion: 提出的混合精度量化框架有效解决了激光雷达3D检测中的量化挑战，在保持性能的同时显著提升了推理速度和模型效率

Abstract: LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.

</details>


### [83] [Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images](https://arxiv.org/abs/2601.12664)
*Elisa Gonçalves Ribeiro,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 研究探讨了在非独立同分布联邦学习场景中，针对癌症组织病理学图像分类任务，如何通过跨数据集聚合启发式方法实现超参数配置的泛化。


<details>
  <summary>Details</summary>
Motivation: 深度学习在癌症组织病理学训练中面临隐私约束问题，联邦学习虽然能保持数据本地化，但其性能在非独立同分布客户端数据集下高度依赖超参数选择，需要研究超参数配置在不同非独立同分布联邦场景中的泛化能力。

Method: 针对卵巢癌和结直肠癌的二元组织病理学分类任务，首先进行集中式贝叶斯超参数优化，然后将数据集特定的最优配置转移到非独立同分布联邦学习设置中，并引入简单的跨数据集聚合启发式方法，通过平均学习率、考虑模态优化器和批量大小来组合配置。

Result: 通过跨数据集聚合得到的组合配置在分类性能上具有竞争力，表明该方法能够有效应对非独立同分布联邦学习场景中的超参数优化挑战。

Conclusion: 提出的跨数据集聚合启发式方法为癌症组织病理学联邦学习中的超参数优化提供了一种有效的解决方案，能够在保护隐私的同时实现竞争性的分类性能，为临床环境中的实际应用提供了可行性。

Abstract: Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.

</details>


### [84] [Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface](https://arxiv.org/abs/2601.12666)
*Zonglin Li,Jieji Ren,Shuangfan Zhou,Heng Guo,Jinnuo Zhang,Jiang Zhou,Boxin Shi,Zhanyu Ma,Guoying Gu*

Main category: cs.CV

TL;DR: 提出基于神经隐式表示的单图像彩色光度立体框架，解决近光源和非朗伯表面重建问题，并通过紧凑光学触觉传感器验证


<details>
  <summary>Details</summary>
Motivation: 现有彩色光度立体方法大多假设理想远距离照明和朗伯反射，对更实际的近光源条件和非朗伯表面研究不足，限制了单图像表面重建的实际应用

Method: 采用神经隐式表示建模深度和BRDF，基于单色性假设（均匀色度和同质材料）缓解彩色光度立体的病态性，设计紧凑光学触觉传感器进行验证

Result: 在合成和真实数据集上的实验表明，该方法实现了准确鲁棒的表面重建，能够从单张图像恢复详细表面几何

Conclusion: 提出的神经隐式表示框架有效解决了彩色光度立体在近光源和非朗伯条件下的挑战，为单图像表面重建提供了实用解决方案

Abstract: Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.

</details>


### [85] [VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness](https://arxiv.org/abs/2601.12672)
*Qimao Chen,Fang Li,Shaoqing Xu,Zhiyi Lai,Zixun Xie,Yuechen Luo,Shengyin Jiang,Hanbing Li,Long Chen,Bing Wang,Yi Zhang,Zhi-Xin Yang*

Main category: cs.CV

TL;DR: VILTA框架通过将视觉语言模型集成到自动驾驶闭环训练中，直接编辑周围车辆的未来轨迹来生成多样化的挑战性场景，解决长尾安全问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统安全部署面临长尾问题，罕见但关键的驾驶场景在真实数据中严重不足。现有方法依赖规则启发式、重采样和离线数据集学习的生成模型，限制了生成多样新颖挑战的能力。两阶段框架（VLM生成场景描述+下游模型生成轨迹）限制了VLM的生成潜力。

Method: 提出VILTA（VLM-In-the-Loop Trajectory Adversary）框架，将VLM集成到AD智能体的闭环训练中。VILTA主动参与训练循环，理解动态驾驶环境，通过直接、细粒度编辑周围智能体的未来轨迹来战略性地生成挑战性场景。

Result: 该方法显著增强了最终AD策略的安全性和鲁棒性，特别是在处理关键长尾事件方面的能力。直接编辑方法充分利用了VLM强大的泛化能力，创建了超越传统方法范围的、合理但具有挑战性的多样化课程。

Conclusion: VILTA框架通过将VLM直接集成到训练循环中并直接编辑轨迹，克服了现有方法的局限性，为自动驾驶系统提供了更有效的长尾场景训练方法，提升了系统的安全性和鲁棒性。

Abstract: The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.

</details>


### [86] [Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement](https://arxiv.org/abs/2601.12682)
*Banglei Guan,Dongcai Tan,Jing Tao,Ang Su,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 该论文提出了一种融合-修复图像处理方法，用于抑制高温结构变形测量中的热辐射和热霾干扰，提高数字图像相关法（DIC）的测量精度和有效性。


<details>
  <summary>Details</summary>
Motivation: 在高温结构变形测量中，热辐射引起的图像退化和热霾引入的随机误差限制了变形测量的精度和有效性。需要开发有效的图像处理方法来解决这些问题。

Method: 1. 针对热辐射：基于图像分层表示，将图像分解为正负通道并行处理，通过多曝光图像融合优化质量；2. 针对热霾：采用FSIM作为目标函数指导模型参数迭代优化，应用灰度平均算法均衡异常灰度值，减少测量误差。

Result: 多曝光图像融合算法将欠曝光图像的有效计算区域从26%提升至50%，过曝光图像从32%提升至40%，且不降低测量精度。结合灰度平均算法的图像修复使静态热变形测量误差显著降低：ε_xx误差减少85.3%，ε_yy和γ_xy误差分别减少36.0%和36.4%。

Conclusion: 提出的图像处理方法能有效抑制高温变形测量中热辐射和热霾的干扰，提高图像质量并降低变形测量误差，在热变形测量中具有潜在应用价值。

Abstract: In the deformation measurement of high-temperature structures, image degradation caused by thermal radiation and random errors introduced by heat haze restrict the accuracy and effectiveness of deformation measurement. To suppress thermal radiation and heat haze using fusion-restoration image processing methods, thereby improving the accuracy and effectiveness of DIC in the measurement of high-temperature deformation. For image degradation caused by thermal radiation, based on the image layered representation, the image is decomposed into positive and negative channels for parallel processing, and then optimized for quality by multi-exposure image fusion. To counteract the high-frequency, random errors introduced by heat haze, we adopt the FSIM as the objective function to guide the iterative optimization of model parameters, and the grayscale average algorithm is applied to equalize anomalous gray values, thereby reducing measurement error. The proposed multi-exposure image fusion algorithm effectively suppresses image degradation caused by complex illumination conditions, boosting the effective computation area from 26% to 50% for under-exposed images and from 32% to 40% for over-exposed images without degrading measurement accuracy in the experiment. Meanwhile, the image restoration combined with the grayscale average algorithm reduces static thermal deformation measurement errors. The error in ε_xx is reduced by 85.3%, while the errors in ε_yy and γ_xy are reduced by 36.0% and 36.4%, respectively. We present image processing methods to suppress the interference of thermal radiation and heat haze in high-temperature deformation measurement using DIC. The experimental results verify that the proposed method can effectively improve image quality, reduce deformation measurement errors, and has potential application value in thermal deformation measurement.

</details>


### [87] [GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation](https://arxiv.org/abs/2601.12683)
*Liwei Liao,Ronggang Wang*

Main category: cs.CV

TL;DR: GaussianTrimmer：一种用于3D高斯分割方法的在线边界修整技术，通过虚拟相机和2D分割结果来改善分割边界质量


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯分割方法在原始高斯基元上进行分割，但由于3D高斯尺度变化范围大，大尺寸高斯常跨越前景和背景，导致分割物体边界出现锯齿状问题

Method: 提出在线边界修整方法GaussianTrimmer，包含两个核心步骤：1.生成均匀且覆盖良好的虚拟相机；2.基于虚拟相机上的2D分割结果在基元级别修整高斯

Result: 大量定量和定性实验表明，该方法作为即插即用方法能够提高现有3D高斯分割方法的分割质量

Conclusion: GaussianTrimmer是一种高效、即插即用的后处理方法，能够为现有3D高斯分割方法修整粗糙边界，改善分割效果

Abstract: With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.

</details>


### [88] [Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation](https://arxiv.org/abs/2601.12697)
*Chao Yang,Deshui Miao,Chao Tian,Guoqing Zhu,Yameng Gu,Zhenyu He*

Main category: cs.CV

TL;DR: 提出了一种新颖的红外-可见光高斯融合框架，通过3D高斯重建解决传统2D融合方法视角固定、信息丢失的问题，实现跨模态图像的直接渲染。


<details>
  <summary>Details</summary>
Motivation: 现有2D融合方法局限于固定相机视角，无法全面理解复杂场景，导致关键信息丢失。需要一种能够重建场景几何并从多模态2D输入直接渲染融合图像的方法。

Method: 提出红外-可见光高斯融合框架，包括跨模态调整模块来调制高斯不透明度以解决跨模态冲突，并引入融合损失来指导优化，确保融合图像保留各模态关键特征。

Result: 全面的定性和定量实验证明了该方法的有效性，能够更好地保留红外和可见光模态的关键特征。

Conclusion: 该方法通过3D高斯重建和跨模态调整，解决了传统2D融合方法的局限性，实现了更全面的场景理解和信息保留。

Abstract: Infrared-visible image fusion aims to integrate infrared and visible information into a single fused image. Existing 2D fusion methods focus on fusing images from fixed camera viewpoints, neglecting a comprehensive understanding of complex scenarios, which results in the loss of critical information about the scene. To address this limitation, we propose a novel Infrared-Visible Gaussian Fusion (IVGF) framework, which reconstructs scene geometry from multimodal 2D inputs and enables direct rendering of fused images. Specifically, we propose a cross-modal adjustment (CMA) module that modulates the opacity of Gaussians to solve the problem of cross-modal conflicts. Moreover, to preserve the distinctive features from both modalities, we introduce a fusion loss that guides the optimization of CMA, thus ensuring that the fused image retains the critical characteristics of each modality. Comprehensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed method.

</details>


### [89] [P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2601.12714)
*Songlin Dong,Jiangyang Li,Chenhao Ding,Zhiheng Ma,Haoyu Luo,Yuhang He,Yihong Gong*

Main category: cs.CV

TL;DR: P2L-CA：一种参数高效的多标签类增量学习框架，通过提示到标签模块和连续适配器模块解决特征混淆和领域差异问题，无需内存缓冲区且参数量极少。


<details>
  <summary>Details</summary>
Motivation: 现有多标签类增量学习方法存在高计算成本（全参数微调）、大存储开销（内存缓冲区）以及难以充分解决特征混淆和领域差异等问题。

Method: 提出P2L-CA框架，包含两个核心模块：1）P2L模块使用类别特定提示解耦多标签表示，并融入语言先验以稳定语义-视觉对齐；2）CA模块采用轻量适配器缓解预训练模型与下游任务间的领域差距，增强模型可塑性。

Result: 在MS-COCO和PASCAL VOC的标准和挑战性MLCIL设置上进行广泛实验，P2L-CA不仅显著超越现有最先进方法，还在CIL场景中表现出强泛化能力，同时仅需极少可训练参数且无需内存缓冲区。

Conclusion: P2L-CA通过参数高效的设计有效解决了多标签类增量学习中的关键挑战，在性能、效率和泛化能力方面均表现出色，为实际应用提供了可行方案。

Abstract: Multi-label Class-Incremental Learning aims to continuously recognize novel categories in complex scenes where multiple objects co-occur. However, existing approaches often incur high computational costs due to full-parameter fine-tuning and substantial storage overhead from memory buffers, or they struggle to address feature confusion and domain discrepancies adequately. To overcome these limitations, we introduce P2L-CA, a parameter-efficient framework that integrates a Prompt-to-Label module with a Continuous Adapter module. The P2L module leverages class-specific prompts to disentangle multi-label representations while incorporating linguistic priors to enforce stable semantic-visual alignment. Meanwhile, the CA module employs lightweight adapters to mitigate domain gaps between pre-trained models and downstream tasks, thereby enhancing model plasticity. Extensive experiments across standard and challenging MLCIL settings on MS-COCO and PASCAL VOC show that P2L-CA not only achieves substantial improvements over state-of-the-art methods but also demonstrates strong generalization in CIL scenarios, all while requiring minimal trainable parameters and eliminating the need for memory buffers.

</details>


### [90] [RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels](https://arxiv.org/abs/2601.12715)
*Chengzhou Li,Ping Guo,Guanchen Meng,Qi Jia,Jinyuan Liu,Zhu Liu,Xiaokang Liu,Yu Liu,Zhongxuan Luo,Xin Fan*

Main category: cs.CV

TL;DR: 提出RSOD教师-学生框架，通过可靠性评分和物体混合伪标签策略解决声纳图像标注数据极度有限的问题，在仅5%标注数据下达到与100%标注数据基线算法竞争的结果。


<details>
  <summary>Details</summary>
Motivation: 声纳图像相比自然图像纹理细节少、噪声多，非专家难以区分类别间的细微差异，无法提供精确标注数据。因此，在标注数据极度有限的情况下设计有效的声纳图像目标检测方法尤为重要。

Method: 提出RSOD教师-学生框架：1）通过评估教师模型在不同视图下预测的一致性计算可靠性评分；2）引入物体混合伪标签方法解决声纳图像标注数据不足问题；3）实施可靠性引导的自适应约束优化学生模型性能。

Result: 在UATD数据集上，仅使用5%标注数据的方法结果可以与基线算法使用100%标注数据训练的结果竞争。同时收集了新数据集为声纳领域研究提供更有价值的数据。

Conclusion: RSOD框架通过充分利用未标注数据，在标注数据极度有限的情况下仍能取得良好性能，为解决声纳图像目标检测中的标注数据稀缺问题提供了有效方案。

Abstract: Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.

</details>


### [91] [S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation](https://arxiv.org/abs/2601.12719)
*Lin Zhao,Yushu Wu,Aleksei Lebedev,Dishani Lahiri,Meng Dong,Arpit Sahni,Michael Vasilkovsky,Hao Chen,Ju Hu,Aliaksandr Siarohin,Sergey Tulyakov,Yanzhi Wang,Anil Kag,Yanyu Li*

Main category: cs.CV

TL;DR: S2DiT是一种用于移动设备的高效流式视频生成模型，通过新颖的注意力机制和三明治设计，在iPhone上实现超过10FPS的实时生成，质量媲美服务器级模型。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiTs)虽然提升了视频生成质量，但计算成本过高，无法在移动设备上实现实时或设备端生成。需要开发一种能在移动硬件上高效运行的高质量视频生成模型。

Method: 1. 提出S2DiT（流式三明治扩散变换器），采用LinConv混合注意力(LCHA)和步幅自注意力(SSA)等高效注意力机制；2. 通过预算感知动态规划搜索发现三明治设计；3. 提出2合1蒸馏框架，将大型教师模型（如Wan 2.2-14B）的能力转移到紧凑的少步三明治模型中。

Result: S2DiT在质量上与最先进的服务器视频模型相当，同时在iPhone上实现超过10FPS的流式生成，显著降低了计算成本，使移动设备上的实时视频生成成为可能。

Conclusion: S2DiT通过创新的注意力机制、三明治设计和蒸馏框架，成功实现了在移动硬件上的高效高质量视频生成，为实时设备端视频生成应用开辟了新途径。

Abstract: Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.

</details>


### [92] [DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition](https://arxiv.org/abs/2601.12729)
*Hanyu Zhu,Zhihao Zhan,Yuhang Ming,Liang Li,Dibo Hou,Javier Civera,Wanzeng Kong*

Main category: cs.CV

TL;DR: DC-VLAQ是一个视觉地点识别框架，通过融合DINOv2和CLIP的互补特征，并使用VLAQ聚合方案，在多种挑战性条件下实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉地点识别方法大多依赖单一视觉基础模型，忽略了不同模型提供的互补信息。然而，利用这些互补信息会改变token分布，挑战现有基于查询的全局聚合方案的稳定性。

Method: 提出DC-VLAQ框架：1）轻量级残差引导互补融合，以DINOv2特征空间为基础，通过学习的残差校正注入CLIP的互补语义；2）VLAQ（局部聚合查询向量）聚合方案，通过token对可学习查询的残差响应进行编码，提高稳定性并保留细粒度判别线索。

Result: 在Pitts30k、Tokyo24/7、MSLS、Nordland、SPED和AmsterTime等标准VPR基准测试中，DC-VLAQ始终优于强基线，特别是在挑战性域偏移和长期外观变化下实现了最先进的性能。

Conclusion: DC-VLAQ通过有效融合互补视觉基础模型特征和稳健的全局聚合，解决了视觉地点识别中的表示鲁棒性问题，在多种挑战性条件下表现出色。

Abstract: One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.

</details>


### [93] [KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction](https://arxiv.org/abs/2601.12736)
*Qingtian Zhu,Xu Cao,Zhixiang Wang,Yinqiang Zheng,Takafumi Taketomi*

Main category: cs.CV

TL;DR: KaoLRM利用大型重建模型(LRM)的预训练3D先验，结合FLAME参数化人脸模型和2D高斯泼溅技术，从单视角图像实现鲁棒且视角一致的人脸重建。


<details>
  <summary>Details</summary>
Motivation: 现有的参数化3D形变模型(3DMM)回归器在不同视角下的一致性较差，需要提升单视角人脸重建的鲁棒性和跨视角一致性。

Method: 将LRM的预训练triplane特征投影到FLAME参数空间恢复几何，使用与FLAME网格紧密耦合的2D高斯基元建模外观，将FLAME-based 2D高斯泼溅集成到LRM的渲染流程中。

Result: 在受控和野外基准测试中，KaoLRM实现了优越的重建精度和跨视角一致性，而现有方法对视角变化仍然敏感。

Conclusion: KaoLRM通过利用LRM的丰富3D先验，使FLAME回归器能够感知3D结构，从而在自遮挡和多样视角下实现准确鲁棒的重建。

Abstract: We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at https://github.com/CyberAgentAILab/KaoLRM.

</details>


### [94] [SSPFormer: Self-Supervised Pretrained Transformer for MRI Images](https://arxiv.org/abs/2601.12747)
*Jingkai Li,Xiaoze Tian,Yuhang Shen,Jia Wang,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: SSPFormer：一种针对MRI图像的自监督预训练Transformer，通过逆频率投影掩码和频率加权FFT噪声增强，解决医学图像领域适应性和数据稀缺问题，在分割、超分辨率和去噪任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 预训练Transformer在自然图像处理中表现出色，但直接应用于MRI图像面临两个关键挑战：1）无法适应医学解剖结构的特异性；2）医学数据的隐私性和稀缺性带来的限制。

Method: 提出SSPFormer自监督预训练Transformer，采用两种核心策略：1）逆频率投影掩码，优先重建高频解剖区域以强制结构感知表示学习；2）频率加权FFT噪声增强，在傅里叶域注入生理真实噪声以增强对MRI伪影的鲁棒性。

Result: 在分割、超分辨率和去噪任务上的广泛实验表明，SSPFormer达到了最先进的性能，充分验证了其捕获细粒度MRI图像保真度和适应临床需求的能力。

Conclusion: SSPFormer通过自监督学习从原始扫描数据中学习领域不变和伪影鲁棒的特征，有效解决了MRI图像处理中的领域适应性和数据稀缺问题，为临床应用提供了有力工具。

Abstract: The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.

</details>


### [95] [Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image](https://arxiv.org/abs/2601.12770)
*Shuling Zhao,Dan Xu*

Main category: cs.CV

TL;DR: 提出了一种从单张图像构建可实时动画的3D头部虚拟化身的单次前馈框架，通过高斯原语嵌入参数化面部模型，结合3D GAN先验和对称性特征融合，实现高质量360度渲染和实时动画。


<details>
  <summary>Details</summary>
Motivation: 现有方法在大视角变化下容易失效，影响3D虚拟化身的真实感。需要解决从单张图像一次性重建可动画3D全头部虚拟化身的挑战，实现实时动画和360度渲染。

Method: 1) 在参数化面部模型的UV空间中嵌入高斯原语进行3D头部建模；2) 利用预训练3D GAN提取全局全头部特征和多视角监督；3) 利用UV空间和人脸对称性，融合局部细粒度输入图像特征与全局全头部纹理。

Result: 方法在广泛实验中表现出有效性，实现了高质量的3D全头部建模和实时动画，显著提升了3D说话虚拟化身的真实感。

Conclusion: 该框架成功解决了从单张图像构建可动画3D头部虚拟化身的挑战，通过结合参数化模型、3D GAN先验和对称性特征融合，实现了高质量的360度渲染和实时动画控制。

Abstract: Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.

</details>


### [96] [Open Vocabulary Panoptic Segmentation With Retrieval Augmentation](https://arxiv.org/abs/2601.12779)
*Nafis Sadeq,Qingfeng Liu,Mostafa El-Khamy*

Main category: cs.CV

TL;DR: RetCLIP是一种检索增强的全景分割方法，通过构建掩码片段特征数据库，在推理时检索相似特征和类别标签，结合CLIP分数提升未见类别的分割性能。


<details>
  <summary>Details</summary>
Motivation: 开放词汇全景分割需要处理训练数据中未见的类别，但传统全景分割系统对未见类别的泛化能力有限，需要提升对任意用户输入类别的分割性能。

Method: 使用配对图像-文本数据构建掩码片段特征数据库；推理时用输入图像的掩码片段特征作为查询键，从数据库中检索相似特征和相关类别标签；基于查询特征与检索特征的相似度分配分类分数；将检索分类分数与CLIP分数结合得到最终输出。

Result: 在COCO上训练后，在ADE20k数据集上达到30.9 PQ、19.3 mAP、44.0 mIoU，相比基线方法分别提升+4.5 PQ、+2.5 mAP、+10.0 mIoU的绝对改进。

Conclusion: RetCLIP通过检索增强机制有效提升了开放词汇全景分割中未见类别的性能，结合FC-CLIP方法实现了显著的性能改进。

Abstract: Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.

</details>


### [97] [PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition](https://arxiv.org/abs/2601.12798)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Yue Xiu,Lu Chen,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: 本文提出PhyG-MoE框架，通过动态调整模型容量来匹配信号复杂度，解决GNSS干扰识别中静态模型资源不匹配的问题，在21种干扰类别上达到97.58%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着复杂电磁干扰对GNSS的威胁日益严重，当前基于深度学习的静态干扰识别模型存在根本性局限：无论输入信号的物理熵如何，都采用固定的计算拓扑结构，导致简单信号和复杂饱和信号消耗相同处理资源，造成严重的资源不匹配问题。

Method: 提出PhyG-MoE（物理引导的专家混合）框架，采用基于频谱的门控机制，根据信号频谱特征纠缠程度动态路由信号。对于复杂饱和场景激活高容量的TransNeXt专家进行特征解耦，而对基本信号则使用轻量级专家处理以最小化延迟。

Result: 在21种干扰类别上的评估显示，PhyG-MoE实现了97.58%的整体准确率。该框架在保持性能不下降的前提下，显著降低了计算开销，解决了静态计算与动态电磁环境之间的内在冲突。

Conclusion: PhyG-MoE通过动态调整模型容量与信号复杂度的对齐，为资源受限的认知接收器提供了可行的解决方案，有效解决了GNSS干扰识别中的资源不匹配问题，同时保持了高性能。

Abstract: Complex electromagnetic interference increasingly compromises Global Navigation Satellite Systems (GNSS), threatening the reliability of Space-Air-Ground Integrated Networks (SAGIN). Although deep learning has advanced interference recognition, current static models suffer from a \textbf{fundamental limitation}: they impose a fixed computational topology regardless of the input's physical entropy. This rigidity leads to severe resource mismatch, where simple primitives consume the same processing cost as chaotic, saturated mixtures. To resolve this, this paper introduces PhyG-MoE (Physics-Guided Mixture-of-Experts), a framework designed to \textbf{dynamically align model capacity with signal complexity}. Unlike static architectures, the proposed system employs a spectrum-based gating mechanism that routes signals based on their spectral feature entanglement. A high-capacity TransNeXt expert is activated on-demand to disentangle complex features in saturated scenarios, while lightweight experts handle fundamental signals to minimize latency. Evaluations on 21 jamming categories demonstrate that PhyG-MoE achieves an overall accuracy of 97.58\%. By resolving the intrinsic conflict between static computing and dynamic electromagnetic environments, the proposed framework significantly reduces computational overhead without performance degradation, offering a viable solution for resource-constrained cognitive receivers.

</details>


### [98] [Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data](https://arxiv.org/abs/2601.12809)
*Takaki Yamamoto,Chihiro Noguchi,Toshihiro Tanizawa*

Main category: cs.CV

TL;DR: 本文通过可控的一维图像-文本测试平台，研究CLIP风格对比训练中Transformer编码器如何习得左右关系理解，发现标签多样性比布局多样性对泛化更重要，并通过注意力分解揭示了位置与词元嵌入交互如何打破左右对称性。


<details>
  <summary>Details</summary>
Motivation: 空间理解是视觉-语言模型的关键挑战，但目前尚不清楚这种理解是否真正被习得以及通过何种机制。本文旨在探究在基于Transformer的视觉和文本编码器中，左右关系理解如何在CLIP风格的对比训练中涌现。

Method: 构建可控的一维图像-文本测试平台，训练轻量级Transformer编码器端到端处理单对象和双对象场景的描述对，系统性地改变标签和布局多样性，评估对未见对象对的泛化能力，并进行注意力分解分析。

Result: 对比训练确实能学习左右关系，其中标签多样性比布局多样性对泛化更重要。注意力分解显示位置嵌入与词元嵌入的交互诱导了水平注意力梯度，打破了编码器的左右对称性；消除这一贡献会显著降低左右辨别能力。

Conclusion: 研究提供了CLIP风格模型何时以及如何获得关系能力的机制性洞察，揭示了标签多样性在关系学习中的关键作用，以及位置-词元嵌入交互在打破空间对称性中的机制。

Abstract: Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.

</details>


### [99] [CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting](https://arxiv.org/abs/2601.12814)
*Yu-Jen Tseng,Chia-Hao Kao,Jing-Zhong Chen,Alessandro Gnutti,Shao-Yuan Lo,Yen-Yu Lin,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 首个统一框架，用于3D高斯溅射的率失真优化压缩与分割，支持解码端场景编辑等应用


<details>
  <summary>Details</summary>
Motivation: 虽然3DGS在实时渲染和语义场景理解方面都很有效，但先前工作大多独立处理这些任务，缺乏联合考虑。本文旨在将语义学习集成到压缩流程中，支持超越传统场景重建和视图合成的解码端应用

Method: 1) 采用轻量级隐式神经表示超先验，高效编码颜色和语义属性；2) 开发压缩引导的分割学习，包括量化感知训练增强特征可分性和质量感知权重机制抑制不可靠高斯基元

Result: 在LERF和3D-OVS数据集上的广泛实验表明，该方法显著降低了传输成本，同时保持了高渲染质量和强大的分割性能

Conclusion: 提出了首个统一框架，成功将语义学习集成到3DGS压缩流程中，支持解码端应用，并通过轻量级超先验和压缩引导分割学习实现了高效压缩与分割的平衡

Abstract: We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.

</details>


### [100] [TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement](https://arxiv.org/abs/2601.12823)
*Belal Shaheen,Minh-Hieu Nguyen,Bach-Thuan Bui,Shubham,Tim Wu,Michael Fairley,Matthew David Zane,Michael Wu,James Tompkin*

Main category: cs.CV

TL;DR: TreeDGS：基于3D高斯泼溅的航拍图像重建方法，用于从稀疏航拍图像中准确测量树木胸径（DBH），在10个样地测试中达到4.79cm RMSE，优于激光雷达基线（7.91cm RMSE）。


<details>
  <summary>Details</summary>
Motivation: 航拍遥感虽然能高效进行大面积调查，但在复杂自然场景中难以实现准确的对象级测量。特别是树木胸径（DBH）的测量，由于树干在航拍图像中距离远、观测稀疏（通常只占几个像素），传统重建方法难以准确约束胸高处的树干几何形状。

Method: 提出TreeDGS方法：1）使用SfM-MVS进行初始化；2）利用3D高斯泼溅作为连续、可致密化的场景表示进行高斯优化；3）使用RaDe-GS的深度感知累积不透明度积分从高斯场提取密集点集；4）为每个样本分配多视角不透明度可靠性分数；5）通过不透明度加权的实心圆拟合从树干隔离点估计DBH。

Result: 在10个具有实地测量DBH的样地上评估，TreeDGS达到4.79cm RMSE（约2.6像素），优于最先进的激光雷达基线（7.91cm RMSE），表明基于泼溅的致密化几何能够实现准确、低成本的航拍DBH测量。

Conclusion: TreeDGS证明了基于3D高斯泼溅的连续场景表示能够从稀疏航拍图像中准确重建树干几何，实现低成本、高精度的航拍胸径测量，为大规模森林调查提供了有前景的技术方案。

Abstract: Aerial remote sensing enables efficient large-area surveying, but accurate direct object-level measurement remains difficult in complex natural scenes. Recent advancements in 3D vision, particularly learned radiance-field representations such as NeRF and 3D Gaussian Splatting, have begun to raise the ceiling on reconstruction fidelity and densifiable geometry from posed imagery. Nevertheless, direct aerial measurement of important natural attributes such as tree diameter at breast height (DBH) remains challenging. Trunks in aerial forest scans are distant and sparsely observed in image views: at typical operating altitudes, stems may span only a few pixels. With these constraints, conventional reconstruction methods leave breast-height trunk geometry weakly constrained. We present TreeDGS, an aerial image reconstruction method that leverages 3D Gaussian Splatting as a continuous, densifiable scene representation for trunk measurement. After SfM-MVS initialization and Gaussian optimization, we extract a dense point set from the Gaussian field using RaDe-GS's depth-aware cumulative-opacity integration and associate each sample with a multi-view opacity reliability score. We then estimate DBH from trunk-isolated points using opacity-weighted solid-circle fitting. Evaluated on 10 plots with field-measured DBH, TreeDGS reaches 4.79,cm RMSE (about 2.6 pixels at this GSD) and outperforms a state-of-the-art LiDAR baseline (7.91,cm RMSE), demonstrating that densified splat-based geometry can enable accurate, low-cost aerial DBH measurement.

</details>


### [101] [Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation](https://arxiv.org/abs/2601.12876)
*Zhenxuan Lu,Zhihua Xu,Zhijing Yang,Feng Gao,Yongyi Lu,Keze Wang,Tianshui Chen*

Main category: cs.CV

TL;DR: 提出THFEM框架，将音频驱动说话头生成模型与语音保留面部表情操纵技术结合，通过相邻帧学习策略提升生成帧的连续性和质量，有效保持表情操纵时的口型同步。


<details>
  <summary>Details</summary>
Motivation: 现有的SPFEM技术在改变面部表情时难以准确保持口型同步，而音频驱动说话头生成模型擅长生成精确的口型动作，因此研究如何将两者结合以改善表情操纵时的口型保持问题。

Method: 提出THFEM框架：1）利用AD-THG模型从音频输入和SPFEM处理后的图像生成口型同步的帧；2）开发相邻帧学习策略，微调AD-THG模型以预测连续帧序列，通过利用相邻帧信息提升图像质量和表情保真度。

Result: 实验评估表明，该框架在表情操纵过程中有效保持了口型形状，显著改善了图像质量，证明了AD-THG与SPFEM集成的实质性优势。

Conclusion: 通过将音频驱动说话头生成模型与语音保留面部表情操纵技术相结合，并采用相邻帧学习策略，成功解决了表情操纵时的口型同步问题，为面部表情操纵提供了更高质量的解决方案。

Abstract: Speech-Preserving Facial Expression Manipulation (SPFEM) is an innovative technique aimed at altering facial expressions in images and videos while retaining the original mouth movements. Despite advancements, SPFEM still struggles with accurate lip synchronization due to the complex interplay between facial expressions and mouth shapes. Capitalizing on the advanced capabilities of audio-driven talking head generation (AD-THG) models in synthesizing precise lip movements, our research introduces a novel integration of these models with SPFEM. We present a new framework, Talking Head Facial Expression Manipulation (THFEM), which utilizes AD-THG models to generate frames with accurately synchronized lip movements from audio inputs and SPFEM-altered images. However, increasing the number of frames generated by AD-THG models tends to compromise the realism and expression fidelity of the images. To counter this, we develop an adjacent frame learning strategy that finetunes AD-THG models to predict sequences of consecutive frames. This strategy enables the models to incorporate information from neighboring frames, significantly improving image quality during testing. Our extensive experimental evaluations demonstrate that this framework effectively preserves mouth shapes during expression manipulations, highlighting the substantial benefits of integrating AD-THG with SPFEM.

</details>


### [102] [Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning](https://arxiv.org/abs/2601.12889)
*Nazibul Basar Ayon,Abdul Hasib,Md. Faishal Ahmed,Md. Sadiqur Rahman,Kamrul Islam,T. M. Mehrab Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本研究提出了一种集成深度学习框架，用于同时检测牛结节性皮肤病（LSD）和口蹄疫（FMD），解决了这两种疾病之间以及与其他良性病症的症状重叠问题，实现了98.2%的准确率。


<details>
  <summary>Details</summary>
Motivation: LSD和FMD是高度传染性的牛病毒性疾病，造成重大经济损失。它们的视觉诊断因症状相互重叠以及与昆虫叮咬或化学烧伤等良性病症相似而复杂化，这阻碍了及时的控制措施。

Method: 利用来自印度、巴西和美国18个农场的10,516张专家标注图像，提出了一种集成深度学习框架，整合了VGG16、ResNet50和InceptionV3模型，并采用优化的加权平均方法进行同时的LSD和FMD检测。

Result: 模型达到了最先进的98.2%准确率，宏平均精确度为98.2%，召回率为98.1%，F1分数为98.1%，AUC-ROC为99.5%。

Conclusion: 该方法独特地解决了多疾病检测中症状重叠的关键挑战，实现了早期、精确和自动化的诊断。该工具有潜力改善疾病管理，支持全球农业可持续性，并设计用于未来在资源有限环境中的部署。

Abstract: Lumpy Skin Disease (LSD) and Foot-and-Mouth Disease (FMD) are highly contagious viral diseases affecting cattle, causing significant economic losses and welfare challenges. Their visual diagnosis is complicated by significant symptom overlap with each other and with benign conditions like insect bites or chemical burns, hindering timely control measures. Leveraging a comprehensive dataset of 10,516 expert-annotated images from 18 farms across India, Brazil, and the USA, this study presents a novel Ensemble Deep Learning framework integrating VGG16, ResNet50, and InceptionV3 with optimized weighted averaging for simultaneous LSD and FMD detection. The model achieves a state-of-the-art accuracy of 98.2\%, with macro-averaged precision of 98.2\%, recall of 98.1\%, F1-score of 98.1\%, and an AUC-ROC of 99.5\%. This approach uniquely addresses the critical challenge of symptom overlap in multi-disease detection, enabling early, precise, and automated diagnosis. This tool has the potential to enhance disease management, support global agricultural sustainability, and is designed for future deployment in resource-limited settings.

</details>


### [103] [Membership Inference Test: Auditing Training Data in Object Classification Models](https://arxiv.org/abs/2601.12929)
*Gonzalo Mancera,Daniel DeAlcala,Aythami Morales,Ruben Tolosana,Julian Fierrez*

Main category: cs.CV

TL;DR: 该研究分析了成员推理测试（MINT）在物体识别领域的性能，提出了专门针对MINT模型的架构，通过实验在三个公开数据库上验证了架构有效性，能够以70-80%的精度识别数据是否用于训练。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在物体识别领域中，如何有效确定给定数据是否被用于模型训练过程的问题。成员推理测试（MINT）在这一领域的应用需要专门的架构设计来优化性能和效率。

Method: 方法包括：1）为MINT模型设计专门的架构；2）使用卷积层捕捉训练过程中的激活模式；3）构建包含物体检测模型、嵌入提取器和MINT模块的实验系统；4）在三个公开数据库（总计超过17.4万张图像）上进行实验；5）分析不同检测模块层深度对MINT性能的影响。

Result: 实验结果：1）能够识别测试和训练数据的使用情况；2）精度达到70%-80%，具体取决于输入MINT模块的检测模块层深度；3）分析了影响MINT模块性能的因素；4）为更透明的训练过程提供了分析框架。

Conclusion: 结论：提出的专门架构能够有效应用于物体识别领域的成员推理测试，实现了可观的识别精度，并为理解训练过程的透明度提供了分析工具。研究展示了MINT在物体识别领域的实际应用潜力。

Abstract: In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.

</details>


### [104] [QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning](https://arxiv.org/abs/2601.12936)
*Tianran Ouyang,Xingping Dong,Jing Zhang,Mang Ye,Jun Chen,Bo Du*

Main category: cs.CV

TL;DR: QASA提出了一种质量引导的K自适应槽注意力方法，通过解耦槽选择与重建、引入无监督槽质量评估和基于质量的槽选择机制，解决了现有K自适应方法在槽绑定质量和优化目标冲突方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有K自适应槽注意力方法存在两个主要问题：1）没有明确约束槽绑定质量，导致低质量槽产生模糊特征归属；2）在重建目标中添加槽数量惩罚会创建相互冲突的优化目标，导致性能显著落后于固定K的基线方法。

Method: QASA包含三个关键设计：1）将槽选择与重建解耦，消除两者间的相互约束；2）提出无监督的槽质量评估指标来评估每个槽的质量；3）基于质量指标设计质量引导的槽选择方案，动态选择高质量槽子集，输入到新设计的门控解码器进行重建训练。

Result: 实验表明，QASA在真实和合成数据集上都显著优于现有的K自适应方法。更重要的是，在真实世界数据集上，QASA甚至超越了固定K的方法。

Conclusion: QASA通过质量引导的K自适应机制，有效解决了现有方法在槽绑定质量和优化目标冲突方面的局限性，在保持重建质量的同时实现了动态槽数量调整，在真实数据集上达到了超越固定K方法的性能。

Abstract: Slot Attention, an approach that binds different objects in a scene to a set of "slots", has become a leading method in unsupervised object-centric learning. Most methods assume a fixed slot count K, and to better accommodate the dynamic nature of object cardinality, a few works have explored K-adaptive variants. However, existing K-adaptive methods still suffer from two limitations. First, they do not explicitly constrain slot-binding quality, so low-quality slots lead to ambiguous feature attribution. Second, adding a slot-count penalty to the reconstruction objective creates conflicting optimization goals between reducing the number of active slots and maintaining reconstruction fidelity. As a result, they still lag significantly behind strong K-fixed baselines. To address these challenges, we propose Quality-Guided K-Adaptive Slot Attention (QASA). First, we decouple slot selection from reconstruction, eliminating the mutual constraints between the two objectives. Then, we propose an unsupervised Slot-Quality metric to assess per-slot quality, providing a principled signal for fine-grained slot--object binding. Based on this metric, we design a Quality-Guided Slot Selection scheme that dynamically selects a subset of high-quality slots and feeds them into our newly designed gated decoder for reconstruction during training. At inference, token-wise competition on slot attention yields a K-adaptive outcome. Experiments show that QASA substantially outperforms existing K-adaptive methods on both real and synthetic datasets. Moreover, on real-world datasets QASA surpasses K-fixed methods.

</details>


### [105] [GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation](https://arxiv.org/abs/2601.12948)
*Riccardo Catalini,Davide Di Nucci,Guido Borghi,Davide Davoli,Lorenzo Garattoni,Giampiero Francesca,Yuki Kawana,Roberto Vezzani*

Main category: cs.CV

TL;DR: GazeD：基于扩散模型的单RGB图像3D视线与人体姿态联合估计方法，通过将视线表示为额外身体关节实现多假设生成，在三个基准数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从单张RGB图像中准确估计3D视线，且视线通常与人体姿态密切相关。需要一种能够处理不确定性并联合估计视线和姿态的方法。

Method: 1. 使用扩散模型处理不确定性，基于输入图像的2D上下文信息生成多个合理的3D视线和姿态假设；2. 将去噪过程条件化于2D姿态、主体周围环境和场景上下文；3. 提出新颖的3D视线表示方法：将视线作为距离眼睛固定距离的额外身体关节；4. 利用视线与姿态的密切关系，在扩散过程中联合去噪。

Result: 在三个基准数据集上的评估表明，GazeD在3D视线估计方面达到了最先进的性能，甚至超越了依赖时间信息的方法。

Conclusion: GazeD成功展示了扩散模型在联合3D视线和姿态估计中的有效性，通过将视线表示为额外关节的新颖方法，实现了从单RGB图像的准确估计，为相关应用提供了有力工具。

Abstract: We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.

</details>


### [106] [StyMam: A Mamba-Based Generator for Artistic Style Transfer](https://arxiv.org/abs/2601.12954)
*Zhou Hong,Rongsheng Hu,Yicheng Di,Xiaolong Xu,Ning Dong,Yihua Shao,Run Ling,Yun Wang,Juqin Wang,Zhanjie Zhang,Ao Ma*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba架构的图像风格迁移方法StyMam，通过残差双路径条带扫描机制和通道重加权空间注意力模块，解决了现有方法在局部细节和全局依赖建模上的不足，实现了高质量、无伪影的风格迁移。


<details>
  <summary>Details</summary>
Motivation: 现有图像风格迁移方法主要基于GAN或稳定扩散(SD)。GAN方法使用CNN或Transformer难以同时捕捉局部和全局依赖，导致伪影和模式不协调；SD方法虽然减少了这些问题，但往往无法保留内容结构且推理速度慢。需要一种既能保持内容结构又能高效生成高质量风格化图像的方法。

Method: 提出基于Mamba的生成器StyMam，包含两个核心模块：1) 残差双路径条带扫描机制，用于高效捕捉局部纹理特征；2) 通道重加权空间注意力模块，用于建模全局依赖关系。这种架构设计能够同时处理局部细节和全局模式。

Result: 通过大量定性和定量实验证明，该方法在质量和速度上都优于现有最先进的算法，能够生成高质量的风格化图像，不引入伪影和不协调模式。

Conclusion: StyMam方法通过重新审视GAN架构并引入Mamba技术，成功解决了图像风格迁移中的局部-全局依赖平衡问题，在保持内容结构的同时实现了高效、高质量的风格迁移。

Abstract: Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.

</details>


### [107] [Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation](https://arxiv.org/abs/2601.12964)
*John Waithaka,Gustave Bwirayesu,Moise Busogi*

Main category: cs.CV

TL;DR: 本文提出了一种空间亲和力组件，可将高分辨率遥感图像融入自监督预训练中，以增强中分辨率图像的表示学习，提升下游分割任务性能。


<details>
  <summary>Details</summary>
Motivation: 遥感领域自监督预训练主要使用中分辨率图像数据集，但随着高分辨率数据集的发布，需要研究如何将高分辨率数据融入预训练过程，以提升中分辨率图像的表示学习和下游分割性能。

Method: 设计了一个空间亲和力组件，可以添加到现有的自监督学习框架中，利用高分辨率图像来学习更好的中分辨率图像表示。

Result: 在两个自监督学习框架上测试了空间亲和力组件，结果显示它优于仅使用高分辨率或中分辨率图像预训练的模型。

Conclusion: 通过将高分辨率图像融入自监督预训练过程，可以有效提升中分辨率遥感图像的表示学习能力，从而改善下游分割任务的性能。

Abstract: Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.

</details>


### [108] [Think3D: Thinking with Space for Spatial Reasoning](https://arxiv.org/abs/2601.13029)
*Zaibin Zhang,Yuhan Wu,Lianjie Jia,Yifan Wang,Zhongbo Zhang,Yijiang Li,Binghao Ran,Fuxi Zhang,Zhuohan Sun,Zhenfei Yin,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: Think3D框架让视觉大模型通过3D重建和交互式空间操作实现真正的3D推理，无需额外训练就能显著提升空间推理能力


<details>
  <summary>Details</summary>
Motivation: 当前视觉大模型本质上是2D感知器，缺乏真正的3D空间推理能力，而理解物理世界需要空间智能

Method: 利用3D重建模型从图像/视频恢复点云和相机位姿，通过相机操作和自我/全局视角切换实现交互式3D思维链推理

Result: GPT-4.1和Gemini 2.5 Pro在BLINK Multi-view和MindCube上平均提升7.8%，在VSI-Bench上提升4.7%；小模型通过强化学习策略选择信息视角，工具使用收益从0.7%提升到6.8%

Conclusion: 无需训练的工具增强空间探索是实现更灵活、类人3D推理的有效途径，为多模态智能建立了新维度

Abstract: Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.

</details>


### [109] [GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure](https://arxiv.org/abs/2601.13052)
*Antoine Carreaud,Shanci Li,Malo De Lacour,Digre Frinde,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: GridNet-HD是一个用于电力基础设施3D语义分割的多模态数据集，包含高密度LiDAR和高分辨率倾斜影像，提供11类标注，融合模型相比单模态基线提升5.55 mIoU


<details>
  <summary>Details</summary>
Motivation: 目前缺乏同时提供高密度LiDAR、高分辨率倾斜影像和3D语义标签的公开电力线路资产数据集，限制了多模态融合方法的研究和应用

Method: 构建包含7,694张图像和25亿个点的多模态数据集，提供11类语义标注，预设数据分割和mIoU评估指标，建立单模态（仅LiDAR、仅图像）和多模态融合基线模型

Result: 在GridNet-HD数据集上，多模态融合模型相比最佳单模态基线提升5.55 mIoU，证明了几何信息（LiDAR）和外观信息（图像）的互补性

Conclusion: GridNet-HD填补了电力基础设施多模态3D语义分割数据集的空白，展示了多模态融合在电力线路资产识别中的优势，数据集、基线模型和代码已开源

Abstract: This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.

</details>


### [110] [PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain](https://arxiv.org/abs/2601.13128)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: PhaseMark是一种单次优化免费的水印框架，通过在VAE潜在频率域直接调制相位，比基于优化的方法快数千倍，同时保持图像质量并实现最先进的抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 随着潜在扩散模型生成超真实图像的普及，需要鲁棒的水印技术，但现有的后处理方法由于需要迭代优化或反转过程而速度过慢。

Method: PhaseMark直接在VAE潜在频率域调制相位，采用单次优化免费框架，分析了四种调制变体，揭示了性能与质量之间的权衡关系。

Result: PhaseMark比基于优化的技术快数千倍，在包括再生在内的严重攻击下实现了最先进的鲁棒性，且不降低图像质量。

Conclusion: PhaseMark通过利用潜在特性的内在属性，展示了高效、鲁棒水印的新范式，为快速且抗攻击的水印技术提供了创新解决方案。

Abstract: The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.

</details>


### [111] [GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning](https://arxiv.org/abs/2601.13132)
*Kim Yu-Ji,Dahye Lee,Kim Jun-Seong,GeonU Kim,Nam Hyeon-Woo,Yongjin Kwon,Yu-Chiang Frank Wang,Jaesung Choe,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: GaussExplorer是一个基于3D高斯溅射的具身探索与推理框架，通过结合视觉语言模型实现复杂语言查询驱动的3D场景探索和推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要问题：1）基于语言嵌入的3D高斯溅射方法只能处理简单查询，难以应对复杂的组合语言查询；2）基于物体中心RGB-D结构化记忆的方法虽然提供空间基础，但受限于预固定的视角。

Method: 在3D高斯溅射基础上引入视觉语言模型，首先识别与查询问题最相关的预捕获图像，然后将这些图像调整到新的视角以更准确地捕捉视觉信息，供VLM进行更好的推理。

Result: 实验表明，该方法在多个基准测试中优于现有方法，证明了将基于VLM的推理与3D高斯溅射集成在具身任务中的有效性。

Conclusion: GaussExplorer通过结合3D高斯溅射和视觉语言模型，成功解决了复杂组合语言查询驱动的3D场景探索和推理问题，为具身智能任务提供了有效解决方案。

Abstract: We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.

</details>


### [112] [CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks](https://arxiv.org/abs/2601.13133)
*Mingshuang Luo,Ruibing Hou,Bo Chao,Hong Chang,Zimo Liu,Yaowei Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: CLASP是一个用于以人为中心的视觉任务的无监督预训练框架，利用CLIP生成多级语义伪标签，通过Prompt-Controlled MoE模块动态适应不同下游任务，在多基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着大规模无标签人体图像数据集的涌现，需要一种通用的无监督预训练模型来支持多样化的以人为中心的下游任务，如监控、医疗和人机交互等应用。

Method: CLASP利用CLIP视觉语言模型生成低级（如身体部位）和高级（如属性）语义伪标签，将这些多级语义线索整合到视觉表示中，并采用Prompt-Controlled Mixture-of-Experts模块根据任务特定提示动态调整特征提取，通过多任务预训练策略指导表示学习。

Result: 在多个基准测试上的广泛实验表明，CLASP在性能上持续优于现有的无监督预训练方法，推动了以人为中心的视觉分析领域的发展。

Conclusion: CLASP是一个有效的无监督预训练框架，能够生成丰富且可泛化的视觉表示，通过动态适应不同语义粒度需求，为多样化的以人为中心的下游任务提供了强大的基础模型。

Abstract: Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.

</details>


### [113] [ICo3D: An Interactive Conversational 3D Virtual Human](https://arxiv.org/abs/2601.13148)
*Richard Shaw,Youngkyoon Jang,Athanasios Papaioannou,Arthur Moreau,Helisa Dhamo,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: ICo3D是一个交互式、对话式、照片级真实的3D虚拟人生成方法，基于多视角捕捉创建可动画的3D面部和动态3D身体模型，使用高斯基元渲染，结合LLM实现对话能力，音频驱动面部动画实现精确同步。


<details>
  <summary>Details</summary>
Motivation: 创建能够实时交互、对话且具有照片级真实感的3D虚拟人，为游戏、虚拟助手、个性化教育等领域提供完全集成的虚拟化身体验。

Method: 基于多视角捕捉创建可动画的3D面部模型和动态3D身体模型，两者都使用高斯基元渲染；改进的动态高斯模型包括SWinGS++用于身体重建和HeadGaS++用于面部重建；提供无伪影的面部和身体模型融合方案；集成LLM实现对话能力；使用音频语音作为驱动信号动画面部模型。

Result: 开发了完整的ICo3D系统，展示了实时与3D虚拟人对话的多个用例；实现了完全集成的虚拟化身体验，支持沉浸式环境中的口头和书面形式交互。

Conclusion: ICo3D方法为游戏、虚拟助手、个性化教育等多个领域提供了交互式、对话式、照片级真实的3D虚拟人解决方案，具有广泛的应用前景。

Abstract: This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/

</details>


### [114] [From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models](https://arxiv.org/abs/2601.13166)
*Pedro M. Gordaliza,Jaume Banus,Benoît Gérin,Maxence Wynen,Nataliia Molchanova,Jonas Richiardi,Meritxell Bach Cuadra*

Main category: cs.CV

TL;DR: 该研究针对医学影像分析开发了基于U-Net CNN架构的基础模型，在MICCAI 2025的SSL3D和FOMO25脑MRI挑战赛中均获第一名，相比Transformer方法训练速度提升1-2个数量级且模型尺寸小10倍


<details>
  <summary>Details</summary>
Motivation: 开发医学影像分析的基础模型以应对放射学任务的独特挑战，特别是在3D脑MRI领域

Method: 采用U-Net CNN架构，结合利用解剖先验知识和神经影像领域知识的策略

Result: 在MICCAI 2025的SSL3D和FOMO25两个3D脑MRI挑战赛的多个赛道中均排名第一，模型训练速度比基于Transformer的方法快1-2个数量级，模型尺寸小10倍

Conclusion: 基于U-Net CNN结合领域知识的策略在3D脑MRI分析中表现出色，为医学影像基础模型开发提供了高效实用的解决方案

Abstract: Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.

</details>


### [115] [GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction](https://arxiv.org/abs/2601.13207)
*Jinnao Li,Zijian Chen,Tingzhu Chen,Changbo Wang*

Main category: cs.CV

TL;DR: 本文提出了GTPred基准测试，用于评估多模态大语言模型在地理-时间预测任务上的表现，发现现有模型在时空推理方面存在局限，但加入时间信息能显著提升定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有地理定位基准大多忽略了图像中的时间信息，而时间信息能进一步约束位置推断。为了填补这一空白，需要建立一个同时考虑地理和时间信息的评估基准。

Method: 构建了GTPred基准数据集，包含370张全球分布的图像，时间跨度超过120年。通过联合评估年份和分层位置序列匹配来评估MLLM预测，并使用精心标注的真实推理过程评估中间推理链。

Result: 在8个专有和7个开源MLLM上的实验表明，尽管模型具有较强的视觉感知能力，但在世界知识和地理时间推理方面仍然有限。结果同时显示，加入时间信息能显著提升位置推断性能。

Conclusion: GTPred基准填补了地理-时间预测评估的空白，揭示了当前MLLM在时空推理方面的局限性，并证明了时间信息对地理定位的重要性。

Abstract: Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.

</details>


### [116] [ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments](https://arxiv.org/abs/2601.13218)
*Igor Vozniak,Philipp Mueller,Nils Lipp,Janis Sprenger,Konstantin Poddubnyy,Davit Hovhannisyan,Christian Mueller,Andreas Bulling,Philipp Slusallek*

Main category: cs.CV

TL;DR: 本文提出了一个用于评估基于对象视觉注意力的新数据集和评估指标，并开发了基于Mamba U-Net的模型，在虚拟现实街道导航场景中实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 人类视觉注意力具有基于对象的特性，但在计算视觉注意力模型中应用较少，主要原因是缺乏合适的数据集和评估指标。特别是在街道导航等安全关键场景中，收集真实世界数据存在伦理和安全挑战。

Method: 1. 创建了包含120名参与者的虚拟现实街道导航数据集，包含精确的注视数据、完整的环境状态空间表示、丰富的注释（全景分割、深度信息、车辆关键点）；2. 提出了基于对象的相似性度量（oSIM）来评估基于对象的视觉注意力模型；3. 开发了SUMGraph模型，基于Mamba U-Net架构，将关键场景对象（车辆）编码为图表示。

Result: 1. 数据集成功解决了在真实环境中收集数据的伦理和安全挑战；2. 明确优化基于对象的注意力不仅提高了oSIM性能，也改善了模型在常见指标上的表现；3. SUMGraph模型在多个最先进的视觉注意力预测方法上实现了进一步的性能提升。

Conclusion: 本文通过提供专门的数据集、评估指标和模型架构，推动了基于对象的视觉注意力研究。数据集、代码和模型将公开释放，为相关研究提供了重要资源。

Abstract: The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.

</details>


### [117] [Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations](https://arxiv.org/abs/2601.13225)
*Tim Lachmann,Alexandra Israelsson,Christina Tornberg,Teimuraz Saghinadze,Michal Balazia,Philipp Müller,Petri Laukka*

Main category: cs.CV

TL;DR: 论文提出了BLEMORE数据集，用于多模态混合情感识别，包含情感相对显著度标注，并在该数据集上评估了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 人类经常同时体验多种混合情感，但现有视频情感识别方法大多只能识别单一情感。少数尝试识别混合情感的方法通常无法评估混合情感中各情感的相对显著度，主要原因是缺乏包含大量混合情感样本且标注了相对显著度的数据集。

Method: 1. 引入BLEMORE数据集：包含58位演员的3000多个视频片段，涵盖6种基本情感和10种不同混合情感，每种混合有3种显著度配置（50/50、70/30、30/70）；2. 在该数据集上评估最先进的视频分类方法，包括单模态和多模态方法，执行两个任务：预测样本中是否存在特定情感，预测混合情感中各情感的相对显著度。

Result: 单模态分类器在验证集上达到最高29%的存在准确率和13%的显著度准确率；多模态方法有明显改进，ImageBind + WavLM达到35%的存在准确率，HiCMAE达到18%的显著度准确率。在保留测试集上，最佳模型达到33%的存在准确率（VideoMAEv2 + HuBERT）和18%的显著度准确率（HiCMAE）。

Conclusion: BLEMORE数据集为推进情感识别系统研究提供了宝贵资源，能够更好地处理混合情感表达的复杂性和重要性，多模态方法在混合情感识别任务上表现优于单模态方法。

Abstract: Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.

</details>


### [118] [A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models](https://arxiv.org/abs/2601.13238)
*Chengyin Hu,Xiang Chen,Zhe Jia,Weiwen Shi,Fengyu Zhang,Jiujiang Guo,Yiwei Wei*

Main category: cs.CV

TL;DR: 该论文提出了首个利用真实天气条件攻击视觉语言模型的对抗框架，通过两阶段参数化扰动模型分析雨天气象对VLM决策的影响，发现即使物理上合理的天气扰动也能导致主流VLM出现显著的语义错位。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型通常在规范视觉条件下训练，但其对真实天气条件的鲁棒性以及跨模态语义对齐在结构化扰动下的稳定性尚未得到充分研究。本文聚焦雨天场景，旨在探索天气条件对VLM安全性和可靠性的潜在风险。

Method: 采用两阶段参数化扰动模型：第一阶段通过低维全局调制建模降雨的全局效应，逐步削弱原始语义决策边界；第二阶段通过显式建模多尺度雨滴外观和降雨引起的照明变化，引入结构化雨变化，并优化不可微的天气空间以诱导稳定的语义偏移。

Result: 实验表明，即使物理上合理且高度受限的天气扰动也能在主流VLM中引发显著的语义错位，对现实世界部署构成潜在安全和可靠性风险。消融研究进一步证实照明建模和多尺度雨滴结构是这些语义偏移的关键驱动因素。

Conclusion: 该研究揭示了视觉语言模型在真实天气条件下的脆弱性，提出的对抗框架在非像素参数空间中生成物理基础且可解释的扰动，为评估和改进VLM在恶劣天气条件下的鲁棒性提供了重要工具。

Abstract: Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.

</details>


### [119] [Deep Learning for Semantic Segmentation of 3D Ultrasound Data](https://arxiv.org/abs/2601.13263)
*Chenyu Liu,Marco Cecotti,Harikrishnan Vijayakumar,Patrick Robinson,James Barson,Mihai Caleap*

Main category: cs.CV

TL;DR: 本文提出了一种基于Calyo Pulse超声波传感器的3D语义分割框架，用于恶劣环境下的自动驾驶感知系统


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶感知系统主要依赖激光雷达和摄像头，但在成本、鲁棒性和恶劣环境性能方面存在权衡。需要开发成本效益高且可靠的感知系统，特别是在恶劣和杂乱环境中。

Method: 引入基于Calyo Pulse模块化固态3D超声波传感器系统的学习框架，采用3D U-Net架构对空间超声波数据进行训练，实现体积分割。

Result: Calyo Pulse传感器展示了稳健的分割性能，通过更大数据集、精细化地面真值和加权损失函数有进一步提升潜力。

Conclusion: 3D超声波传感作为可靠的自动驾驶感知补充模态具有广阔前景，为恶劣环境下的感知系统提供了新的解决方案。

Abstract: Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.

</details>


### [120] [Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams](https://arxiv.org/abs/2601.13299)
*Ethan Seefried,Prahitha Movva,Naga Harshita Marupaka,Tilak Kasturi,Tirthankar Ghosal*

Main category: cs.CV

TL;DR: Enginuity是首个开放、大规模、多领域的工程图数据集，包含全面的结构标注，用于自动化图表解析，旨在帮助多模态大语言模型理解工程图中的视觉结构知识。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统难以理解工程图中的视觉结构知识，这阻碍了AI在科学发现工作流程中的全面参与。工程图解析、技术图纸分析和视觉推理对于假设生成、实验设计和科学发现至关重要，但缺乏合适的标注数据集限制了AI在这方面的能力。

Method: 创建了一个开放、大规模、多领域的工程图数据集，包含全面的结构标注，捕捉层次化的组件关系、连接和语义元素。该数据集跨越多个工程领域，为多模态大语言模型提供训练资源。

Result: 提出了Enginuity数据集，这是首个专门为工程图解析设计的全面标注数据集。该数据集将支持结构化图表解析、跨模态信息检索和AI辅助工程仿真等关键下游任务。

Conclusion: Enginuity数据集将变革科学发现中的人工智能，使AI系统能够理解和操作工程图中嵌入的视觉结构知识，打破当前阻碍AI全面参与科学工作流程的基本障碍。

Abstract: We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.

</details>


### [121] [CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning](https://arxiv.org/abs/2601.13304)
*Wenxin Ma,Chenlong Wang,Ruisheng Yuan,Hao Chen,Nanru Dai,S. Kevin Zhou,Yijun Yang,Alan Yuille,Jieneng Chen*

Main category: cs.CV

TL;DR: 论文提出了CausalSpatial基准测试，评估多模态大语言模型在因果空间推理方面的能力，发现模型表现远低于人类，并提出COW框架通过生成假设动态视频来改善模型推理。


<details>
  <summary>Details</summary>
Motivation: 人类能够观察静态场景并预测后续动态变化（如碰撞），但当前多模态大语言模型主要局限于静态空间感知，无法回答3D场景中的"如果...会怎样"问题。需要评估和改进模型在因果空间推理方面的能力。

Method: 1) 创建CausalSpatial诊断基准，包含碰撞、兼容性、遮挡和轨迹四个任务；2) 分析模型失败原因；3) 提出Causal Object World模型（COW）框架，通过生成假设动态视频来外部化模拟过程，提供明确的因果视觉线索。

Result: 人类在CausalSpatial基准上得分84%，而GPT-5仅得54%，存在显著差距。分析发现模型过度依赖文本链式推理而偏离视觉证据，产生流畅但空间无根据的幻觉。COW框架通过视觉模拟帮助模型将推理基于物理现实而非语言先验。

Conclusion: 当前MLLMs在因果空间推理方面存在根本性缺陷，需要将视觉模拟外部化以提供明确的因果线索。COW框架为解决这一问题提供了有效途径，通过生成假设动态视频使模型能够基于物理现实进行推理。数据集和代码已公开。

Abstract: Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer "what-if" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial

</details>


### [122] [MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic](https://arxiv.org/abs/2601.13331)
*Wei Wang,Quoc-Toan Ly,Chong Yu,Jun Bai*

Main category: cs.CV

TL;DR: MultiST是一个统一的多模态空间转录组学框架，通过交叉注意力融合空间拓扑、基因表达和组织形态学，能够生成边界更清晰的空间域，获得更稳定的伪时间轨迹和更可解释的细胞间相互作用模式。


<details>
  <summary>Details</summary>
Motivation: 现有空间转录组学方法在整合组织形态学与分子谱方面存在不足，通常采用浅层融合策略或完全忽略组织图像，导致难以解析模糊的空间域边界。

Method: MultiST采用基于交叉注意力的融合方法，联合建模空间拓扑、基因表达和组织形态学。使用基于图的基因编码器配合对抗对齐学习鲁棒的空间表示，同时整合颜色归一化的组织学特征来捕获分子-形态学依赖关系并细化域边界。

Result: 在13个不同ST数据集（包括人类大脑皮层和乳腺癌组织）上评估，MultiST生成的空间域比现有方法具有更清晰、更一致的边界，产生更稳定的伪时间轨迹和更生物学可解释的细胞间相互作用模式。

Conclusion: MultiST通过有效整合多模态信息，解决了空间转录组学中形态学与分子谱融合不足的问题，为研究组织结构和细胞间相互作用提供了更强大的分析框架。

Abstract: Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.

</details>


### [123] [Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments](https://arxiv.org/abs/2601.13364)
*Zhenan Liu,Yaodong Cui,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出了一种在粉尘环境中进行毫米波传播研究的新方法，开发了基于阈值的噪声过滤框架和基于规则的分类管道，用于粉尘环境中的可靠行人检测。


<details>
  <summary>Details</summary>
Motivation: 在地下矿井、道路隧道等粉尘严重的封闭环境中，粉尘颗粒和反射表面会严重影响毫米波雷达的感知功能，需要开发能够在恶劣电磁约束下进行可重复传播研究的方法。

Method: 1) 开发了在高度杂乱环境中生成可控多级粉尘浓度的方法；2) 创建了包含相机和LiDAR的4D毫米波雷达数据集；3) 设计了基于阈值的噪声过滤框架，利用RCS、速度、方位角、仰角等参数抑制鬼目标和多径反射；4) 建立了基于规则的聚类级分类管道，利用雷达语义特征实现实时行人检测。

Result: 实验结果表明，该集成方法显著增强了粉尘环境中杂波抑制、检测鲁棒性和系统整体韧性，能够实现可靠的实时行人检测，无需大量领域特定训练。

Conclusion: 提出的方法为粉尘严重环境中的毫米波传播研究提供了有效解决方案，通过噪声过滤和基于规则的分类实现了可靠的感知功能，对地下矿井等恶劣环境的安全监测具有重要意义。

Abstract: This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.

</details>


### [124] [Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations](https://arxiv.org/abs/2601.13371)
*Junyi Zhang,Yiming Wang,Yunhong Lu,Qichao Wang,Wenzhe Qian,Xiaoyin Xu,David Gu,Min Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于球面几何表示的文本到3D人脸生成方法，通过将几何信号锚定到均匀球面坐标来简化底层几何结构，解决了现有方法在顶点分布和网格连接性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 文本到3D人脸生成的核心挑战在于实现高质量的几何结构。现有模型难以处理3D空间中顶点分布的任意性和复杂性，导致网格连接性差和几何质量不佳。

Method: 首先提出球面几何表示，将几何信号锚定到均匀球面坐标，保证规则的点分布并实现稳健的网格重建。然后引入球面几何扩散，基于2D映射构建条件扩散框架，联合建模几何和纹理，其中几何明确地条件化纹理合成过程。

Result: 该方法在文本到3D生成、人脸重建和基于文本的3D编辑等多种任务中表现出色。大量实验表明，该方法在几何质量、文本保真度和推理效率方面显著优于现有方法。

Conclusion: 通过将复杂几何约束到简单的拓扑球面流形上，实现了高质量的3D人脸生成，该方法为文本驱动的3D内容创建提供了有效的解决方案。

Abstract: A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.

</details>


### [125] [A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions](https://arxiv.org/abs/2601.13373)
*Zhenan Liu,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出一种完全模型驱动的4D毫米波雷达感知框架，用于恶劣工业/地下环境中实时人体检测，在粉尘、烟雾等能见度下降条件下保持稳定性能。


<details>
  <summary>Details</summary>
Motivation: 工业/地下环境中的粉尘、烟雾、受限几何结构和金属结构会严重降低光学和LiDAR感知性能，而4D毫米波雷达对此类条件有强鲁棒性，但对其稀疏各向异性点云进行可靠人体检测的处理方法仍有限。

Method: 开发了完全模型驱动的4D雷达感知框架，包括：领域感知多阈值滤波、自运动补偿时间累积、KD树欧几里得聚类结合多普勒感知优化、基于规则的3D分类器，可在嵌入式边缘硬件上实时执行。

Result: 在粉尘填充的封闭拖车和真实地下采矿隧道中评估，在能见度严重下降导致相机和LiDAR失效的场景下，雷达检测器仍能保持稳定的行人识别性能。

Conclusion: 提出的模型驱动方法为恶劣工业/地下环境中的安全关键应用提供了鲁棒、可解释且计算高效的感知解决方案。

Abstract: Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.

</details>


### [126] [Practical Insights into Semi-Supervised Object Detection Approaches](https://arxiv.org/abs/2601.13380)
*Chaoxin Wang,Bharaneeshwar Balasubramaniyam,Anurag Sangem,Nicolais Guevara,Doina Caragea*

Main category: cs.CV

TL;DR: 本文对三种先进的半监督目标检测方法（MixPL、Semi-DETR、Consistent-Teacher）在数据稀缺场景下的性能进行了全面比较，分析了标注图像数量对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺场景下，如何利用大量未标注图像和少量标注图像提升目标检测性能是研究重点。本文旨在理解不同半监督目标检测方法在不同标注数据量下的性能变化。

Method: 使用MS-COCO和Pascal VOC两个标准目标检测数据集，以及自定义的Beetle数据集，对三种先进的SSOD方法（MixPL、Semi-DETR、Consistent-Teacher）进行系统比较，分析标注图像数量对性能的影响。

Result: 研究发现不同方法在准确性、模型大小和延迟之间存在权衡，为低数据场景下的方法选择提供了见解。在专业数据集（Beetle）上，这些方法在较少目标类别下的表现也得到评估。

Conclusion: 本文通过系统比较揭示了不同半监督目标检测方法在数据稀缺场景下的性能特点，为实际应用中的方法选择提供了指导，特别是在标注数据有限的情况下。

Abstract: Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.

</details>


### [127] [Organ-Aware Attention Improves CT Triage and Classification](https://arxiv.org/abs/2601.13385)
*Lavsen Dahal,Yubraj Bhandari,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CV

TL;DR: ORACLE-CT：一种用于CT影像分类的器官感知模型，通过器官掩码注意力和器官标量融合技术，在胸部和腹部CT分类任务中达到最先进的监督分类性能。


<details>
  <summary>Details</summary>
Motivation: 医疗影像（如CT）的高通量需要有效的分诊和分类系统，以改善患者护理并减轻放射科医生的工作负担。现有的视觉语言模型在处理3D解剖结构、协议变化和噪声报告监督方面存在困难。

Method: 提出ORACLE-CT模型，包含两个核心组件：1）器官掩码注意力（Organ-Masked Attention）- 基于器官掩码的注意力机制，提供空间证据；2）器官标量融合（Organ-Scalar Fusion）- 轻量级融合归一化体积和平均HU值线索。在监督基线（全局平均池化头）基础上构建。

Result: 在胸部CT-RATE数据集上达到AUROC 0.86；在腹部MERLIN数据集（30个发现）上，监督基线超过复现的零样本VLM基线，加入掩码注意力和标量融合后性能提升至AUROC 0.85。在两个最大公开胸部CT数据集上建立新的监督最先进性能。

Conclusion: ORACLE-CT在胸部和腹部CT分类任务中实现了最先进的监督分类性能，提供了一种统一的评估协议，为医疗影像分诊提供了有效的解决方案。

Abstract: There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.

</details>


### [128] [Leveraging Transformer Decoder for Automotive Radar Object Detection](https://arxiv.org/abs/2601.13386)
*Changxu Zhang,Zhaoze Wang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 提出基于Transformer的3D雷达目标检测架构，使用新型Transformer解码器作为预测头，直接从雷达特征表示回归3D边界框和类别分数。


<details>
  <summary>Details</summary>
Motivation: 传统雷达目标检测方法通常需要密集的候选框生成和启发式后处理（如非极大值抑制调优），这些过程计算成本高且依赖人工调参。本文旨在设计一个端到端的检测框架，消除这些繁琐步骤，同时更好地建模雷达数据中的长程时空相关性和跨特征交互。

Method: 1. 使用Transformer解码器作为预测头，直接回归3D边界框和类别分数；2. 提出金字塔令牌融合（PTF）模块，将多尺度雷达特征金字塔转换为统一的、尺度感知的令牌序列；3. 将检测问题形式化为集合预测问题，使用可学习的对象查询和位置编码；4. 建模长程时空相关性和跨特征交互。

Result: 在RADDet数据集上评估，相比最先进的雷达专用基线方法取得了显著改进。该方法消除了密集候选框生成和大量非极大值抑制调优等启发式后处理。

Conclusion: 提出的基于Transformer的3D雷达目标检测框架通过端到端的集合预测方法，有效解决了传统雷达检测中的计算瓶颈和人工调参问题，在RADDet数据集上表现出优越性能。

Abstract: In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.

</details>


### [129] [Deep Image Prior with L0 Gradient Regularizer for Image Smoothing](https://arxiv.org/abs/2601.13400)
*Nhat Thanh Tran,Kevin Bui,Jack Xin*

Main category: cs.CV

TL;DR: 提出DIP-ℓ₀框架，结合深度图像先验和ℓ₀梯度正则化，实现无需训练数据的高质量图像平滑


<details>
  <summary>Details</summary>
Motivation: 现有图像平滑方法依赖局部窗口统计或优化问题，基于深度学习的方法需要精心构建的训练数据集，但构建合适的图像平滑训练数据集具有挑战性

Method: 提出DIP-ℓ₀框架，将深度图像先验与ℓ₀梯度正则化相结合，使用交替方向乘子法优化非凸非光滑的ℓ₀"范数"损失函数

Result: 数值实验表明DIP-ℓ₀在边缘保持图像平滑和JPEG伪影去除方面优于许多现有图像平滑算法

Conclusion: DIP-ℓ₀框架能够在不依赖训练数据的情况下实现高质量的图像平滑，为图像处理提供了一种有效的数据无关解决方案

Abstract: Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\ell_0$, a deep image prior framework that incorporates the $\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\ell_0$ ``norm", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.

</details>


### [130] [Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics](https://arxiv.org/abs/2601.13401)
*Peter A. Massih,Eric Cosatto*

Main category: cs.CV

TL;DR: 论文提出QVLM模型解决视觉语言模型在定量空间推理上的缺陷，通过代码生成架构保持像素级精度，在SQuID基准上取得42.0%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在定量空间推理任务上表现不佳，因为其架构破坏了计数和测量所需的像素级信息。图像编码器通过补丁嵌入压缩图像，减少了空间索引，丢失了精确的像素级跟踪能力。

Method: 提出QVLM（定量视觉语言模型），采用代码生成架构，将语言理解与视觉分析解耦。不将图像编码为嵌入，而是生成可执行代码，先调用分割模型获取像素级掩码，然后直接在掩码上操作，保持整个推理过程中的空间索引。

Result: QVLM使用GPT-5作为编码器，在SQuID基准上达到42.0%的准确率，而传统VLM在图像-问题对提示下仅获得28.1%的准确率。实验表明，在定量空间推理任务上，架构解耦能实现更好的准确性。

Conclusion: 对于定量空间推理任务，通过架构解耦（将语言理解与视觉分析分离）能够保持像素级精度，显著提高模型在计数和测量等定量任务上的性能。QVLM的代码生成方法为解决VLM在空间推理上的根本限制提供了有效途径。

Abstract: Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.

</details>


### [131] [Using deep learning for predicting cleansing quality of colon capsule endoscopy images](https://arxiv.org/abs/2601.13412)
*Puneet Sharma,Kristian Dalsbø Hindberg,Benedicte Schelde-Olesen,Ulrik Deding,Esmaeil S. Nadimi,Jan-Matthias Braun*

Main category: cs.CV

TL;DR: 该研究使用ResNet-18模型预测结肠胶囊内窥镜图像的清洁质量，通过结构化剪枝技术实现79%稀疏度下88%的准确率，并利用多种CAM方法进行可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 结肠胶囊内窥镜图像清洁质量评估对临床诊断至关重要，但现有方法存在效率低下和缺乏可解释性的问题。研究旨在开发高效且可解释的深度学习模型来预测CCE图像的清洁质量。

Method: 使用500张由14位临床医生标注的CCE图像数据集，基于Leighton-Rex量表（差、一般、好、优秀）训练ResNet-18分类模型。采用分层K折交叉验证确保稳健性，应用结构化剪枝技术优化模型，使用Grad-CAM、Grad-CAM++、Eigen-CAM、Ablation-CAM和Random-CAM进行可解释性分析，并用ROAD方法进行一致性评估。

Result: 剪枝后的模型在79%稀疏度下达到88%的交叉验证准确率，相比未剪枝模型的84%准确率有所提升。研究还展示了可解释性分析结果，并讨论了ROAD方法在评估中的挑战。最后使用自适应温度缩放变体对剪枝模型进行外部数据集校准。

Conclusion: 结构化剪枝技术能显著提高模型效率而不损失性能，在CCE图像清洁质量预测中具有应用价值。可解释性分析对临床应用至关重要，但评估方法仍需改进。模型校准有助于提升在外部数据集上的表现。

Abstract: In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.

</details>


### [132] [SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement](https://arxiv.org/abs/2601.13417)
*Yujian Xiong,Xuanzhao Dong,Wenhui Zhu,Xin Li,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: SGW-GAN：首个将切片Gromov Wasserstein距离融入视网膜图像增强的框架，通过保持类内几何结构提升临床诊断性能


<details>
  <summary>Details</summary>
Motivation: 现有GAN和扩散模型在增强视网膜图像时过度关注感知质量，导致类内几何结构扭曲，临床相关样本分散，疾病类别边界模糊，损害下游诊断任务

Method: 提出SGW-GAN框架，将切片Gromov Wasserstein距离引入视网膜图像增强。SGW通过随机投影近似GW距离，在保持关系保真度的同时大幅降低计算成本

Result: 在公开数据集上，SGW-GAN产生视觉吸引的增强效果，实现优越的糖尿病视网膜病变分级，并报告跨疾病标签的最低GW差异

Conclusion: SGW-GAN在无配对医学图像增强中同时实现了效率和临床保真度，通过保持类内结构提升了诊断任务的性能

Abstract: Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.

</details>


### [133] [Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation](https://arxiv.org/abs/2601.13440)
*Mohit Kakda,Mirudula Shri Muthukumaran,Uttapreksha Patel,Lawrence Swaminathan Xavier Prince*

Main category: cs.CV

TL;DR: 本文对基于视觉语言模型（VLMs）的异常检测方法进行了全面分析，重点关注异常分类和异常分割任务，系统研究了多种架构范式并评估了关键性能维度。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（特别是CLIP）通过零样本和少样本缺陷识别，无需大量标注数据集即可实现异常检测，这为工业质量控制提供了新的可能性。然而，需要系统分析不同VLM方法的性能、优缺点和适用场景。

Method: 系统研究了三种关键架构范式：基于滑动窗口的密集特征提取（WinCLIP）、多阶段特征对齐与可学习投影（AprilLab框架）以及组合提示集成策略。评估维度包括特征提取机制、文本-视觉对齐策略、提示工程技术、零样本与少样本权衡、计算效率和跨域泛化能力。

Result: 通过在MVTec AD和VisA等基准数据集上的严格实验，比较了分类准确性、分割精度和推理效率。结果表明VLM方法在异常检测中具有显著优势，特别是在零样本和少样本场景下。

Conclusion: 本研究为理解VLM在异常检测中的成功机制提供了基础性认识，为工业质量控制中的方法选择提供了实用见解，并指出了当前方法的局限性，为未来研究方向提供了指导。

Abstract: Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.

</details>


### [134] [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](https://arxiv.org/abs/2601.13498)
*Nimrod Kruger,Nicholas Owen Ralph,Gregory Cohen,Paul Hurley*

Main category: cs.CV

TL;DR: 本文提出了一种基于物理原理的处理框架，将事件流映射到对数强度和强度导数估计，并将其嵌入具有时变点扩散函数的动态线性系统模型中，从而实现从事件数据直接进行逆滤波。


<details>
  <summary>Details</summary>
Motivation: 事件视觉传感器（神经形态相机）输出稀疏、异步的ON/OFF事件，具有微秒级感知、高动态范围和低数据带宽的优势。然而，这种非线性事件表示难以与支撑大多数计算成像和光学系统设计的线性前向模型集成。

Method: 提出了一个基于物理原理的处理管道：1）将事件流映射到每像素对数强度和强度导数估计；2）将这些测量嵌入具有时变点扩散函数的动态线性系统模型；3）使用频域维纳反卷积和已知（或参数化）的动态传递函数直接从事件数据进行逆滤波。

Result: 在模拟中验证了调制离焦下单点和重叠点源的方法，并在真实事件数据（可调焦望远镜拍摄星场）上展示了源定位和可分离性。

Conclusion: 该框架为事件感知和基于模型的动态光学系统计算成像之间提供了实用的桥梁。

Abstract: Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

</details>


### [135] [DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities](https://arxiv.org/abs/2601.13502)
*Nhi Kieu,Kien Nguyen,Arnold Wiliem,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: DIS2提出了一种针对遥感多模态学习中模态缺失问题的新方法，通过DLKD（解耦学习与知识蒸馏协同）和CFLM（类特定特征学习模块）实现主动的缺失特征补偿，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 遥感多模态学习面临模态缺失的严重挑战，且数据高度异构、尺度变化巨大。传统解耦学习依赖模态间特征重叠，不适用于遥感数据的异质性；知识蒸馏则成为不适定的模仿任务，无法解决语义鸿沟问题。

Method: 提出DIS2方法，包含三个核心支柱：1）原则性缺失信息补偿；2）类特定模态贡献；3）多分辨率特征重要性。核心创新是DLKD（解耦学习与知识蒸馏协同），明确捕获补偿特征，与可用模态特征融合以近似完整模态表示。CFLM模块自适应学习每个目标的判别性证据。采用分层混合融合结构利用多分辨率特征。

Result: 大量实验验证表明，该方法在多个基准测试中显著优于最先进的方法。

Conclusion: DIS2通过从模态共享特征依赖和非针对性模仿转向主动、引导的缺失特征补偿，为遥感多模态学习中的模态缺失问题提供了有效解决方案，DLKD和CFLM的结合能够处理遥感数据的异质性和尺度变化挑战。

Abstract: The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.

</details>


### [136] [GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models](https://arxiv.org/abs/2601.13524)
*Yang Yu,Yunze Deng,Yige Zhang,Yanjie Xiao,Youkun Ou,Wenhao Hu,Mingchao Li,Bin Feng,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: GO-MLVTON是首个多层虚拟试穿方法，通过服装遮挡学习和基于StableDiffusion的服装变形拟合模块，实现多层服装的逼真试穿效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的虚拟试穿方法主要关注单层或多件服装试穿，忽略了多层虚拟试穿（ML-VTON），即需要将多层服装穿在人体上，产生具有真实变形和层次感的视觉效果。主要挑战在于准确建模内外服装之间的遮挡关系，以减少冗余内层服装特征的干扰。

Method: 提出GO-MLVTON方法，包含两个核心模块：1）服装遮挡学习模块，用于学习遮挡关系；2）基于StableDiffusion的服装变形与拟合模块，用于将服装变形并贴合到人体上。同时构建了MLG数据集用于该任务。

Result: 大量实验证明了GO-MLVTON的先进性能。该方法能够生成高质量的多层试穿结果，并在评估中表现出色。

Conclusion: GO-MLVTON是首个解决多层虚拟试穿问题的方法，通过创新的遮挡学习和服装变形技术，有效解决了多层服装试穿的挑战，并提出了新的评估指标LACD。该方法在该领域达到了最先进的性能水平。

Abstract: Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.

</details>


### [137] [DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis](https://arxiv.org/abs/2601.13551)
*Feng Ding,Wenhui Yi,Xinan He,Mengyao Xiao,Jianfeng Xu,Jianqiang Du*

Main category: cs.CV

TL;DR: DiffFace-Edit数据集包含200多万张AI生成的人脸图像，专注于细粒度区域编辑，并首次研究了拼接攻击对检测器的影响。


<details>
  <summary>Details</summary>
Motivation: 生成模型现在能够产生难以察觉的细粒度人脸操纵，带来严重的隐私风险。现有AI生成人脸数据集缺乏对细粒度区域操纵样本的关注，且尚未有研究探讨真实与操纵样本之间的拼接攻击对检测器的实际影响。

Method: 引入DiffFace-Edit数据集，包含200多万张AI生成的伪造图像，涵盖8个面部区域（如眼睛、鼻子）的编辑，包括单区域和多区域编辑组合。特别分析检测器规避样本对检测模型的影响，并进行数据集全面分析和跨域评估，结合IMDL方法。

Result: 创建了包含丰富编辑组合的大规模数据集，首次系统研究了拼接攻击对检测器的影响，为检测器规避样本的研究提供了基础。

Conclusion: DiffFace-Edit数据集填补了细粒度区域操纵数据集的空白，为研究检测器规避样本和提升检测模型鲁棒性提供了重要资源，有助于应对AI生成人脸带来的隐私风险。

Abstract: Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.

</details>


### [138] [ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch](https://arxiv.org/abs/2601.13606)
*Zheng Liu,Honglin Lin,Chonghan Qin,Xiaoyang Wang,Xin Gao,Yu Li,Mengzhang Cai,Yun Zhu,Zhanping Zhong,Qizhi Pei,Zhuoshi Pan,Xiaoran Shang,Bin Cui,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: ChartVerse是一个用于合成复杂图表和可靠推理数据的可扩展框架，通过新颖的Rollout Posterior Entropy度量图表复杂度，采用答案优先的逆向QA合成方法，显著提升了开源视觉语言模型在图表推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前开源视觉语言模型在图表推理方面的发展受到高质量训练数据缺乏的严重制约。现有数据集面临双重挑战：合成图表过于简单重复，而相关的问答对存在幻觉问题且缺乏复杂任务所需的推理深度。

Method: 1) 提出Rollout Posterior Entropy(RPE)量化图表复杂度，指导复杂度感知图表编码器通过可执行程序自主合成多样化的高复杂度图表；2) 采用真值锚定的逆向QA合成方法，从源代码直接提取确定性答案，基于这些锚点生成问题，并进行严格一致性验证；3) 基于模型失败率筛选样本，提炼高质量的思维链推理数据。

Result: 构建了ChartVerse-SFT-600K和ChartVerse-RL-40K数据集，使用Qwen3-VL-30B-A3B-Thinking作为教师模型。ChartVerse-8B模型实现了最先进的性能，显著超越了其教师模型，并与更强的Qwen3-VL-32B-Thinking模型相媲美。

Conclusion: ChartVerse框架通过合成复杂图表和可靠的推理数据，有效解决了开源视觉语言模型在图表推理任务中面临的数据质量瓶颈，为图表推理能力的发展提供了重要支持。

Abstract: Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.

</details>


### [139] [CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models](https://arxiv.org/abs/2601.13622)
*Donghee Lee,Rui Cai,Zhe Zhao*

Main category: cs.CV

TL;DR: CARPE是一个模型无关的框架，通过视觉集成层和上下文感知集成策略，让大型视觉语言模型能够自适应地权衡视觉和文本模态，提升图像分类和视觉语言任务的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLMs）在通用助手方面取得进展，但在图像分类等视觉中心任务上表现不佳，甚至不如其基础的CLIP视觉编码器。需要解决LVLMs在视觉任务上的局限性。

Method: 提出CARPE框架：1）引入视觉集成层；2）采用上下文感知集成策略，识别何时优先考虑图像表示或依赖语言模型的推理能力；3）自适应地权衡视觉和文本模态；4）捕获图像表示的不同方面。

Result: CARPE不仅提高了图像分类基准的性能，还在各种视觉语言基准上增强了结果。该框架能与大多数开源LVLMs有效集成，确保跨不同架构的适应性。

Conclusion: CARPE是一个模型无关的框架，通过自适应地权衡视觉和文本表示，显著提升了LVLMs在视觉中心任务上的性能，同时保持了与多种架构的兼容性。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.

</details>


### [140] [Scaling Test-time Inference for Visual Grounding](https://arxiv.org/abs/2601.13633)
*Guanqi Zhan,Changye Li,Zhijian Liu,Yao Lu,Yi Wu,Song Han,Ligeng Zhu*

Main category: cs.CV

TL;DR: EGM方法通过扩展小型视觉语言模型在推理时的计算量（生成更多token），使其视觉定位能力达到或超越大型模型，同时保持更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉定位模型通常模型尺寸很大，部署成本高且推理速度慢。研究发现小型和大型VLMs的主要差异在于语言模型的大小而非视觉编码器，小型模型在定位能力上的不足主要源于语言理解能力的差距而非视觉信息处理能力。

Method: 提出EGM（高效视觉定位语言模型）方法，通过扩展小型模型在测试时的计算量（生成更多token）来弥补语言理解能力的差距。这种方法部署友好，因为每个token的处理成本远低于直接运行大型模型。

Result: 在RefCOCO基准测试中，EGM-Qwen3-VL-8B达到91.4 IoU，平均延迟737ms（比Qwen3-VL-235B快5.9倍），而后者需要4320ms达到90.5 IoU。在新的amodal定位设置中，该方法也能持续显著提升小型模型的定位能力，达到或超越大型模型水平。

Conclusion: EGM方法通过扩展小型模型在推理时的计算量，有效提升了视觉定位的效率，使小型模型在保持快速推理的同时达到与大型模型相当甚至更好的定位性能，为视觉定位任务提供了更高效的解决方案。

Abstract: Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding.

</details>


### [141] [Face-Voice Association with Inductive Bias for Maximum Class Separation](https://arxiv.org/abs/2601.13651)
*Marta Moscati,Oleksandr Kats,Mubashir Noman,Muhammad Zaigham Zaheer,Yufang Hou,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 该论文提出了一种在人脸-声音关联任务中引入最大类别分离作为归纳偏置的新方法，通过强制不同说话者的多模态表示最大程度分离来增强嵌入的判别能力，在两个任务上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 人脸-声音关联研究通常使用损失函数来确保同一人的面部和声音嵌入相近而与他人分离。分类领域的最新进展表明，通过施加最大类别分离作为归纳偏置可以增强嵌入的判别能力，但这一技术在人脸-声音关联领域尚未应用，本研究旨在填补这一空白。

Method: 开发了一种人脸-声音关联方法，将不同说话者多模态表示之间的最大类别分离作为归纳偏置。该方法结合了类间正交性损失，通过强制不同说话者的表示在特征空间中最大程度分离来增强判别能力。

Result: 定量实验表明该方法有效，在两个不同的人脸-声音关联任务制定上都实现了最先进的性能。消融研究显示，当归纳偏置与类间正交性损失结合时效果最佳。

Conclusion: 这是首次在多模态学习中应用并证明最大类别分离作为归纳偏置有效性的工作，为建立新范式铺平了道路。该方法在人脸-声音关联任务中表现出色，特别是当最大类别分离与类间正交性损失结合时效果最优。

Abstract: Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.

</details>


### [142] [VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement](https://arxiv.org/abs/2601.13664)
*Tiancheng Fang,Bowen Pan,Lingxi Chen,Jiangjing Lyu,Chengfei Lyu,Chaoyue Niu,Fan Wu*

Main category: cs.CV

TL;DR: VIAFormer是一个用于多视图条件体素细化的体素-图像对齐Transformer模型，通过多视图图像指导修复不完整有噪声的体素，在合成和真实体素修复任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有体素形状从视觉基础模型获取时往往存在不完整和噪声问题，需要利用多视图图像作为指导来修复这些缺陷，提升体素质量。

Method: 提出三个核心设计：1）图像索引为2D图像token提供显式3D空间定位；2）校正流目标学习直接的体素细化轨迹；3）混合流Transformer实现鲁棒的跨模态融合。

Result: 实验表明VIAFormer在纠正严重合成损坏和从强大视觉基础模型获得的体素形状中的真实伪影方面建立了新的最先进水平。

Conclusion: VIAFormer作为实际可靠的桥梁在真实世界3D创建流程中，为体素方法在大模型大数据浪潮中蓬勃发展铺平了道路。

Abstract: We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.

</details>


### [143] [Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging](https://arxiv.org/abs/2601.13677)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jäger,Klaus Maier-Hein,Fabian Isensee*

Main category: cs.CV

TL;DR: ClaSP PE是一种针对3D生物医学图像分割的主动学习方法，通过类别分层查询和噪声调度策略，在24个实验设置中显著优于随机采样基线，并能泛化到未见数据集。


<details>
  <summary>Details</summary>
Motivation: 3D生物医学图像分割的专家标注成本高昂，现有主动学习方法无法稳定超越针对3D数据优化的随机采样基线，需要一种可靠且高效的解决方案。

Method: 提出Class-stratified Scheduled Power Predictive Entropy (ClaSP PE)方法：1）类别分层查询确保对欠表示结构的覆盖；2）对数尺度功率噪声配合衰减调度，早期阶段强制查询多样性，后期鼓励利用。

Result: 在nnActive基准测试的24个实验设置中，ClaSP PE是唯一在分割质量和标注效率方面均显著优于改进随机基线的方法。在4个未见数据集上的测试也证实了其无需手动调整的泛化能力。

Conclusion: ClaSP PE首次证明了主动学习方法能够在3D分割任务中稳定超越随机基线，在接近实际应用的场景中同时保证性能和标注效率，开源实现和部署指南使其具有实际应用价值。

Abstract: Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.

</details>


### [144] [Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation](https://arxiv.org/abs/2601.13683)
*Boyuan Cao,Xingbo Yao,Chenhui Wang,Jiaxin Ye,Yujie Wei,Hongming Shan*

Main category: cs.CV

TL;DR: DyDiLA是一种新颖的线性注意力机制，通过动态投影模块、动态测量核和令牌差分算子解决线性扩散变换器中注意力权重过度平滑的问题，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器（DiTs）在高保真图像生成方面表现出色，但自注意力的二次计算成本成为主要扩展瓶颈。线性注意力机制虽然降低了计算成本，但线性扩散变换器（LiTs）往往以牺牲生成性能为代价，产生过度平滑的注意力权重，限制了表达能力。

Method: 提出动态差分线性注意力（DyDiLA），包含三个关键设计：1）动态投影模块，通过学习动态分配的知识促进令牌表示的解耦；2）动态测量核，通过为令牌处理动态分配核函数提供更好的相似性度量，捕捉细粒度语义差异；3）令牌差分算子，通过计算令牌与其动态测量核产生的信息冗余之间的差异，实现更稳健的查询到键检索。基于DyDiLA构建了改进的LiT模型DyDi-LiT。

Result: 广泛的实验表明，DyDi-LiT在多个指标上持续优于当前最先进的模型，显示出强大的实际潜力。

Conclusion: DyDiLA通过创新的线性注意力机制有效解决了线性扩散变换器中注意力权重过度平滑的问题，显著提升了生成质量，为高效高保真图像生成提供了有前景的解决方案。

Abstract: Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.

</details>


### [145] [Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles](https://arxiv.org/abs/2601.13705)
*Maria Lymperaiou,Vasileios Karampinis,Giorgos Filandrianos,Angelos Vlachos,Chrysoula Zerva,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 这篇综述论文系统分析了视觉谜题作为评估大型视觉语言模型推理能力的诊断工具，统一了视觉谜题的抽象框架，并按推理机制分类现有基准，揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 视觉谜题作为人类认知的紧凑探针，能够以最小依赖先验知识的方式评估抽象、规则发现和系统推理能力。作者希望利用视觉谜题作为诊断工具，评估大型视觉语言模型的推理能力，替代开放式的多模态基准测试。

Method: 通过统一的抽象框架分析视觉谜题，将现有基准按推理机制分类：归纳推理、类比推理、算法推理、演绎推理和几何/空间推理。综合这些类别的实证证据，识别当前模型的局限性。

Result: 研究发现当前模型存在一致的局限性：脆弱的泛化能力、感知与推理的紧密纠缠、流畅解释与忠实执行之间的持续差距。视觉谜题揭示了LVLM推理能力的系统性缺陷。

Conclusion: 将视觉谜题视为诊断工具而非任务格式，能够更准确地评估大型视觉语言模型的推理能力。这为未来基准测试和推理感知的多模态系统指明了关键方向，强调需要开发能够真正理解而非表面模仿推理过程的模型。

Abstract: Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.

</details>


### [146] [Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2601.13707)
*Yujin Jo,Sangyoon Bae,Taesup Kim*

Main category: cs.CV

TL;DR: ACG方法通过单次前向计算中的注意力空间对比指导，减少大视觉语言模型对语言先验的过度依赖，从而有效缓解幻觉问题，同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型中的幻觉问题主要源于语言先验对视觉证据的支配，导致物体误识别和视觉不一致的描述。现有方法通常需要多次前向计算，计算成本高。

Method: 提出注意力空间对比指导（ACG），在单次前向计算中构建视觉-语言和纯语言注意力路径，并通过正交化校正消除近似偏差，选择性增强视觉贡献。

Result: 在CHAIR和POPE基准测试中，ACG实现了最先进的忠实度和字幕质量，同时将延迟降低高达2倍，相比需要多次前向计算的对比解码方法。

Conclusion: ACG为幻觉缓解提供了一个原则性且高效的替代方案，通过单次前向计算中的注意力空间对比指导，有效平衡语言先验和视觉证据，显著提升模型输出的视觉一致性。

Abstract: Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.

</details>


### [147] [HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection](https://arxiv.org/abs/2601.13751)
*Daniel Kyselica,Jonáš Herec,Oliver Kutis,Rado Pitoňák*

Main category: cs.CV

TL;DR: 本文提出了一种用于卫星洪水检测的HiT（History Injection Transformer）机制，能够在小型卫星的内存和计算限制下实现连续监测，将历史数据存储减少99%以上，并在Jetson Orin Nano上达到43 FPS的实时性能。


<details>
  <summary>Details</summary>
Motivation: 自然灾害监测需要处理多时相卫星数据，但受限于小型卫星的内存和计算能力。洪水检测作为灾害管理的关键应用，需要开发能够在星载设备上运行的实时变化检测系统，减少对地面处理基础设施的依赖。

Method: 提出了HiT（History Injection Transformer）机制，该机制为Transformer模型设计，能够维护先前观测的历史上下文信息，同时将数据存储减少到原始图像大小的1%以下。该方法基于Prithvi-tiny基础模型构建，专门针对星载环境优化。

Result: 在STTORM-CD洪水数据集上的测试表明，HiT机制在Prithvi-tiny模型中保持了与双时相基线相当的检测精度。HiT-Prithvi模型在代表纳米卫星星载硬件的Jetson Orin Nano上实现了43 FPS的处理速度，满足实时监测需求。

Conclusion: HiT机制为卫星连续监测自然灾害提供了实用框架，支持实时灾害评估，减少了对地面处理基础设施的依赖。该工作为星载变化检测系统在小型卫星上的部署奠定了基础。

Abstract: Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection

</details>


### [148] [Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders](https://arxiv.org/abs/2601.13798)
*Kai Wittenmayer,Sukrut Rao,Amin Parchami-Araghi,Bernt Schiele,Jonas Fischer*

Main category: cs.CV

TL;DR: Insight是一个语言对齐的概念基础模型，通过分层稀疏自编码器提取多层次可解释概念，提供空间定位的解释能力，在分类和分割任务上保持竞争力的同时提供高质量概念解释。


<details>
  <summary>Details</summary>
Motivation: 现有语言对齐视觉基础模型虽然在下游任务表现良好，但其表示不透明难以解释。现有方法只能分解为人类可解释概念，但缺乏空间定位能力且仅限于图像分类任务。

Method: 使用分层稀疏自编码器和具有强语义表示的基础模型，自动提取不同粒度的概念；通过分析概念的局部共现依赖关系定义概念关系，利用这些关系改进概念命名和获得更丰富的解释。

Result: 在基准数据上，Insight在分类和分割任务上表现与不透明基础模型相当，同时提供细粒度、高质量的概念解释。

Conclusion: Insight成功构建了一个既能保持竞争力性能又能提供空间定位、多层次概念解释的语言对齐概念基础模型，为理解视觉基础模型的决策过程提供了新途径。

Abstract: Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.

</details>


### [149] [Discriminant Learning-based Colorspace for Blade Segmentation](https://arxiv.org/abs/2601.13816)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出了一种名为CSDA的多维非线性判别分析算法，通过优化色彩表示来提升图像分割精度，在风力涡轮机叶片数据上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 当前许多现代算法忽视了色彩表示这一关键预处理步骤，而次优的色彩表示往往阻碍了准确的图像分割。特别是在特定领域的分割任务中，需要定制化的预处理方法。

Method: 提出Colorspace Discriminant Analysis (CSDA)算法，将线性判别分析扩展到深度学习环境中。通过最大化多维有符号类间可分性同时最小化类内变异性，使用广义判别损失来定制色彩表示。为确保稳定训练，引入了三种替代损失函数，实现判别色彩空间和分割过程的端到端优化。

Result: 在风力涡轮机叶片数据上的实验表明，该方法带来了显著的精度提升，强调了在特定领域分割中定制化预处理的重要性。

Conclusion: CSDA算法通过优化色彩表示有效提升了图像分割性能，证明了在特定领域分割任务中定制化预处理的关键作用。

Abstract: Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.

</details>


### [150] [DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes](https://arxiv.org/abs/2601.13839)
*Aisha Al-Mohannadi,Ayisha Firoz,Yin Yang,Muhammad Imran,Ferda Ofli*

Main category: cs.CV

TL;DR: DisasterVQA是一个专门针对灾害响应的视觉问答基准数据集，包含1,395张真实灾害图像和4,405个专家标注的问答对，用于评估视觉语言模型在灾害情境下的感知和推理能力。


<details>
  <summary>Details</summary>
Motivation: 社交媒体图像在灾害期间提供低延迟的态势信息，但现有的通用视觉问答模型在灾害响应这种复杂、安全关键的推理任务中的适用性尚不明确。需要专门的基准来评估和提升模型在灾害情境下的表现。

Method: 创建了DisasterVQA数据集，包含洪水、野火、地震等多样灾害事件的1,395张真实图像和4,405个专家标注的问答对。问题基于FEMA ESF和OCHA MIRA等人道主义框架设计，涵盖二元、多项选择和开放式问题，涉及态势感知和操作决策任务。

Result: 对7个最先进的视觉语言模型进行基准测试，发现模型在不同问题类型、灾害类别、区域和人道主义任务上表现存在差异。模型在二元问题上准确率高，但在细粒度定量推理、物体计数和上下文敏感解释方面表现不佳，特别是在代表性不足的灾害场景中。

Conclusion: DisasterVQA为灾害响应提供了具有挑战性和实用性的基准，能够指导开发更鲁棒、更具操作意义的视觉语言模型。该数据集已公开可用，有助于推动灾害响应领域的技术发展。

Abstract: Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.

</details>


### [151] [OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting](https://arxiv.org/abs/2601.13871)
*Michail Spanakis,Iason Oikonomidis,Antonis Argyros*

Main category: cs.CV

TL;DR: OCCAM是首个无需训练、无需额外信息的类无关目标计数方法，能够同时处理图像中多个类别的目标计数，基于SAM2和自定义FINCH算法实现。


<details>
  <summary>Details</summary>
Motivation: 现有类无关目标计数方法通常假设每张图像只有一个目标类别，需要大量深度学习模型训练，并依赖视觉示例或文本提示等额外信息。本文旨在开发无需训练、无需补充信息且能处理多类别计数的解决方案。

Method: 利用Segment Anything Model 2 (SAM2)基础模型和自定义的基于阈值的First Integer Neighbor Clustering Hierarchy (FINCH)算法，无需训练即可实现多类别目标计数。

Result: 在FSC-147和CARPK基准数据集上取得了有竞争力的性能，提出了合成多类别数据集和更合适的F1分数评估指标。

Conclusion: OCCAM是首个无需训练、无需额外信息的类无关目标计数方法，能够有效处理多类别计数问题，为实际应用提供了更实用的解决方案。

Abstract: Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.

</details>


### [152] [OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3](https://arxiv.org/abs/2601.13895)
*Xu Zhang,Danyang Li,Yingjie Xia,Xiaohang Dong,Hualong Yu,Jianye Wang,Qicheng Li*

Main category: cs.CV

TL;DR: 本文提出OmniOVCD框架，利用SAM 3的解耦输出头，通过SFID策略融合语义、实例和存在性输出构建土地覆盖掩码，然后分解为单个实例掩码进行变化检测，在四个公开基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有免训练的开放词汇变化检测方法多使用CLIP识别类别，并需要额外模型如DINO提取特征，不同模型的组合常导致特征匹配问题和系统不稳定。SAM 3集成了分割和识别能力，为OVCD任务提供了新可能。

Method: 提出OmniOVCD框架，利用SAM 3的解耦输出头，设计SFID策略：首先融合SAM 3的语义、实例和存在性输出构建土地覆盖掩码，然后将其分解为单个实例掩码进行变化比较，保持类别识别高精度和跨图像实例级一致性。

Result: 在四个公开基准（LEVIR-CD、WHU-CD、S2Looking、SECOND）上实现SOTA性能，分别获得67.2、66.5、24.5和27.1的IoU分数（类别平均），超越所有先前方法。

Conclusion: OmniOVCD通过利用SAM 3的集成能力，解决了现有OVCD方法中多模型组合导致的特征匹配和稳定性问题，实现了准确的变化检测，为开放词汇变化检测提供了有效的独立框架。

Abstract: Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.

</details>


### [153] [Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging](https://arxiv.org/abs/2601.13899)
*Masoumeh Javanbakhat,Piotr Komorowski,Dilyara Bareeva,Wei-Chang Lai,Wojciech Samek,Christoph Lippert*

Main category: cs.CV

TL;DR: 提出可解释的深度统计测试框架，为深度双样本测试提供样本级和特征级解释，揭示哪些样本和特征驱动统计显著的组间差异


<details>
  <summary>Details</summary>
Motivation: 深度双样本测试虽然检测能力强但缺乏可解释性，现有事后解释方法依赖类别标签，不适用于无标签的统计测试场景

Method: 提出可解释的深度统计测试框架，增强深度双样本测试，提供样本级和特征级解释，识别驱动统计显著差异的个体样本和输入特征

Result: 方法能突出显示哪些图像区域和哪些个体样本对检测到的组间差异贡献最大，提供空间和实例层面的洞察，应用于生物医学成像数据时能识别有影响的样本并突出与疾病相关变异相关的解剖学意义区域

Conclusion: 该工作桥接了统计推断和可解释AI，实现了医学成像中可解释的无标签群体分析

Abstract: Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.

</details>


### [154] [On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.13913)
*Pavlo Melnyk,Cuong Le,Urs Waldmann,Per-Erik Forssén,Bastian Wandt*

Main category: cs.CV

TL;DR: 该论文提出通过数据增强学习2D旋转等变性，而非设计等变性模型，从而提升单目3D人体姿态估计性能，在常见基准测试中优于现有等变性设计方法。


<details>
  <summary>Details</summary>
Motivation: 单目3D人体姿态估计是一个不适定问题。现有方法通常采用两步法：先检测2D关节点，再进行2D到3D的提升。研究发现，当输入图像旋转时，常见的提升模型会失效。作者认为，学习人体姿态及其平面内旋转比直接学习点对点映射更简单且几何基础更牢固。

Method: 提出通过数据增强让模型学习2D旋转等变性，而不是在参数空间中显式约束等变性。这种方法让模型在训练过程中自然地学习旋转不变性，比设计等变性模型更直接有效。

Result: 在常见的人体姿态估计基准测试中验证了2D旋转等变性本身能够提升模型在图像平面旋转姿态上的性能。通过数据增强学习等变性的方法能够高效、直接地实现，并且优于现有的等变性设计方法。

Conclusion: 通过数据增强学习2D旋转等变性是一种有效的方法，能够提升单目3D人体姿态估计的性能，特别是在处理旋转输入时表现优于专门设计的等变性模型。

Abstract: Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods.

</details>


### [155] [Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning](https://arxiv.org/abs/2601.13942)
*Hongbo Bai,Yujin Zhou,Yile Wu,Chi-Min Chan,Pengcheng Wen,Kunhao Pan,Sirui Han,Yike Guo*

Main category: cs.CV

TL;DR: GoG框架通过选择性注视机制和双阶段训练策略，解决了大型多模态模型在知识密集型视觉查询中的局限性，实现了从被动感知到主动视觉规划的转变。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型在视觉理解方面取得了显著成功，但在处理涉及长尾实体或动态信息的知识密集型查询时存在局限性，因为其参数化知识是静态的。现有的搜索增强方法依赖无差别的全图像检索，引入了大量视觉冗余和噪声，并且缺乏深度迭代反思，限制了在复杂视觉查询上的有效性。

Method: 提出了Glance-or-Gaze框架，包含选择性注视机制，动态选择是瞥视全局上下文还是凝视高价值区域，在检索前过滤无关信息。采用双阶段训练策略：通过监督微调进行反射性GoG行为对齐，以及通过复杂性自适应强化学习增强模型处理复杂查询的迭代推理能力。

Result: 在六个基准测试中展示了最先进的性能。消融研究证实选择性注视机制和复杂性自适应强化学习对于有效视觉搜索都是必不可少的。

Conclusion: GoG框架通过主动视觉规划和选择性信息处理，显著提升了大型多模态模型在知识密集型视觉查询中的性能，为视觉搜索任务提供了新的解决方案。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.

</details>


### [156] [TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation](https://arxiv.org/abs/2601.13935)
*Anoushkrit Goel,Simroop Singh,Ankita Joshi,Ranjeet Ranjan Jha,Chirag Ahuja,Aditya Nigam,Arnav Bhavsar*

Main category: cs.CV

TL;DR: TrackletGPT：一种基于GPT框架的白质纤维束分割方法，通过引入轨迹片段（tracklets）作为语言标记，在TractoInferno和HCP数据集上实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 白质纤维束分割对于研究大脑结构连接、神经系统疾病和神经外科手术至关重要。该任务具有挑战性，因为纤维束在不同个体和条件下存在差异，但在半球和个体间具有相似的三维结构。

Method: 提出TrackletGPT框架，将轨迹片段（tracklets）作为语言标记引入GPT模型，重新引入序列信息。该方法能够跨数据集泛化，完全自动化，并对细粒度的子流线片段进行编码。

Result: TrackletGPT在TractoInferno和HCP数据集上的平均DICE、重叠度和过度延伸分数均优于现有最先进方法，即使在跨数据集实验中也能保持优异性能。

Conclusion: TrackletGPT通过将轨迹片段作为语言标记引入GPT框架，成功解决了白质纤维束分割中的挑战，实现了跨数据集的泛化能力和优异的性能表现。

Abstract: White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.

</details>


### [157] [VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content](https://arxiv.org/abs/2601.13951)
*Shengyi Wu,Yan Hong,Shengyao Chen,Zheng Wang,Xianbing Sun,Jiahui Zhan,Jun Lan,Jianfu Zhang*

Main category: cs.CV

TL;DR: VTONGuard是一个包含超过77.5万张真实和合成试穿图像的大规模基准数据集，用于评估虚拟试穿内容检测方法，并提出了一个集成辅助分割的多任务框架来提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在虚拟试穿(VTON)领域的快速发展，AI生成的试穿内容越来越逼真，引发了关于内容真实性和负责任使用的迫切担忧。需要建立可靠的检测方法来区分真实和合成的试穿图像。

Method: 1) 创建VTONGuard基准数据集，包含超过775,000张真实和合成试穿图像，涵盖姿势、背景、服装风格等多种真实场景变化；2) 在统一训练和测试协议下系统评估多种检测范式；3) 设计一个多任务框架，集成辅助分割以增强边界感知特征学习。

Result: 研究揭示了各种检测方法的优缺点，并突出了跨范式泛化的持续挑战。提出的多任务框架在VTONGuard上实现了最佳整体性能，通过辅助分割增强了边界感知特征学习。

Conclusion: VTONGuard基准数据集能够实现公平比较，促进更鲁棒的检测模型开发，并推动VTON技术在实际应用中的安全和负责任部署。该研究为解决虚拟试穿内容真实性检测问题提供了重要工具和框架。

Abstract: With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.

</details>


### [158] [Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation](https://arxiv.org/abs/2601.14039)
*Wesam Moustafa,Hossam Elsafty,Helen Schneider,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CV

TL;DR: 本文提出了一种用于医学图像分割的通用弃权框架，通过选择性忽略噪声标签样本来提升分割模型的鲁棒性，在CaDIS和DSAD数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中标签噪声是一个关键问题，由于手动标注的固有困难导致。在噪声数据上训练的模型容易过拟合，降低泛化性能。虽然已有一些方法处理分割领域的噪声标签，但这一领域仍未被充分探索。弃权机制在分类任务中已被证明有效，但在分割任务中的潜力尚未得到验证。

Method: 提出了一个通用模块化的弃权框架，包含两个关键组件：1）引导弃权行为的信息化正则化项；2）基于幂律的更灵活的自适应弃权惩罚调整算法。将该框架与三种不同的损失函数集成，创建了三种新的噪声鲁棒变体：GAC、SAC和ADS。

Result: 在CaDIS和DSAD医学数据集上的实验表明，所提方法在各种噪声水平下都一致且显著地优于非弃权基线方法，特别是在高噪声水平下表现更为突出。

Conclusion: 这项工作证明了让模型选择性忽略损坏样本是一种强大且可泛化的策略，能够构建更可靠的分割模型。弃权机制在分割任务中具有重要价值，为处理医学图像分割中的标签噪声问题提供了有效解决方案。

Abstract: Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.

</details>


### [159] [DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging](https://arxiv.org/abs/2601.13954)
*Adrien Meyer,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: DExTeR是一种基于Transformer的点到框回归器，专门为医学影像设计，通过类引导的可变形注意力和CLICK-MoE专家混合机制，在点标注下实现准确的边界框检测，显著降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的解剖标志检测对诊断和干预至关重要，但传统目标检测模型依赖昂贵的边界框标注。弱半监督目标检测使用点标注可减少标注时间，但医学影像存在解剖重叠、尺寸多变、结构难以捕捉等独特挑战，导致边界框推断不准确。

Method: 基于Point-DETR构建DExTeR，将单点标注编码为对象查询，使用类引导的可变形注意力（利用点坐标和类别标签引导注意力采样以捕捉类别特征）。引入CLICK-MoE（类别、实例和通用知识专家混合）解耦类别和实例表示以减少相邻或重叠实例的混淆。采用多点训练策略提升不同点放置位置预测的一致性。

Result: 在三个医学领域数据集（内窥镜、胸部X光、内窥镜超声）上实现了最先进的性能，展示了在降低标注成本的同时保持高检测准确性的潜力。

Conclusion: DExTeR通过专门设计的Transformer架构和训练策略，有效解决了医学影像中点标注到边界框转换的挑战，为减少医学影像标注成本提供了有效解决方案。

Abstract: Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.

</details>


### [160] [STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames](https://arxiv.org/abs/2601.13974)
*Shih-Yao Lin*

Main category: cs.CV

TL;DR: 提出STEC（时空熵覆盖率）作为评估视频帧采样质量的无参考指标，通过联合建模空间信息强度、时间分散度和非冗余性来衡量采样效果。


<details>
  <summary>Details</summary>
Motivation: 现有视频帧采样评估指标主要关注感知质量或重建保真度，缺乏评估采样帧是否充分捕捉视频信息性和代表性内容的方法。

Method: 基于时空帧熵（STFE）测量每帧空间信息，通过熵基结构复杂度评估采样帧的时间覆盖率和冗余度，联合建模空间信息强度、时间分散度和非冗余性。

Result: 在MSR-VTT测试集上，STEC能清晰区分随机、均匀和内容感知等常见采样策略，并揭示平均性能无法捕捉的个体视频鲁棒性模式。

Conclusion: STEC作为任务无关的诊断工具，为受限预算下的帧采样行为分析提供原则性、轻量级的评估指标，而非预测下游任务准确性。

Abstract: Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.
  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.
  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.
  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.

</details>


### [161] [Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains](https://arxiv.org/abs/2601.13975)
*Marco Piccolo,Qiwei Han,Astrid van Toor,Joachim Vanneste*

Main category: cs.CV

TL;DR: 该研究开发了一个统一信息管道，用于标准化海洋生物多样性监测数据，并评估了跨域检测性能，发现场景结构因素比视觉退化对性能影响更大，验证了在低成本边缘硬件上的可行性。


<details>
  <summary>Details</summary>
Motivation: 海洋生物多样性监测需要跨复杂水下环境的可扩展性和可靠性，但现有检测方案在转移到新地点时性能急剧下降，存在明显的部署差距。该研究旨在为北极和大西洋海洋生态系统的多年入侵物种监测计划建立基础检测层。

Method: 开发统一信息管道标准化异构数据集为可比信息流，在受控跨域协议下评估固定的部署相关检测器，分析结构因素（场景组成、物体密度、上下文冗余）和视觉退化对性能的影响，并在低成本边缘硬件上基准测试推理性能。

Result: 研究发现结构因素（如场景组成、物体密度和上下文冗余）比视觉退化（如浑浊度）更能解释跨域性能损失，稀疏场景会引发特征性的"上下文崩溃"失效模式。在低成本边缘硬件上的推理优化可实现实际采样率，支持远程监测。

Conclusion: 研究结果将重点从图像增强转向结构感知的可靠性，为一致的海洋生态系统评估提供了民主化工具，支持跨域海洋生物多样性监测的实际部署。

Abstract: Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.

</details>


### [162] [POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion](https://arxiv.org/abs/2601.14056)
*Andrea Rigo,Luca Stornaiuolo,Weijie Wang,Mauro Martino,Bruno Lepri,Nicu Sebe*

Main category: cs.CV

TL;DR: POCI-Diff是一个基于扩散的文本到图像生成框架，通过3D布局控制和语义绑定实现一致的多对象场景合成与编辑，避免了传统方法中的几何失真问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成方法在空间布局控制方面存在局限：基于2D线索的方法或迭代复制-变形-粘贴策略常常导致对象几何失真，且在编辑过程中难以保持一致性。

Method: 提出POCI-Diff框架，通过混合潜在扩散将单个文本描述绑定到特定3D边界框，实现显式的对象级语义控制；采用无变形生成编辑管道支持对象插入、移除和变换；使用IP-Adapter基于参考图像调节扩散过程以保持对象一致性。

Result: 实验结果表明，POCI-Diff能生成与指定3D布局和编辑一致的高质量图像，在视觉保真度和布局遵循方面优于现有方法，同时消除了变形引起的几何伪影。

Conclusion: POCI-Diff通过统一的扩散过程实现了3D几何约束和实例级语义绑定的联合执行，为一致且交互式的3D布局控制和编辑提供了有效的解决方案。

Abstract: We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.

</details>


### [163] [FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation](https://arxiv.org/abs/2601.13976)
*Jing Zuo,Lingzhou Mu,Fan Jiang,Chengcheng Ma,Mu Xu,Yonggang Qi*

Main category: cs.CV

TL;DR: FantasyVLN提出了一种统一的隐式推理框架，用于视觉语言导航任务，在保持思维链推理优势的同时避免了显式token开销，实现了实时推理感知导航。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航中的思维链方法存在两个关键问题：纯文本思维链缺乏空间基础且容易过拟合稀疏标注的推理步骤，而多模态思维链通过生成想象的视觉观察导致严重的token膨胀，使得实时导航不切实际。

Method: 提出FantasyVLN框架，使用预训练的视觉自回归器将想象的视觉token编码到紧凑的潜在空间中，在思维链推理训练期间，模型在统一的多思维链策略下从文本、视觉和多模态思维链模式中联合学习。在推理时，模型执行直接的指令到动作映射，同时仍能享受推理感知的表征。

Result: 在LH-VLN数据集上的广泛实验表明，该方法实现了推理感知且实时的导航，提高了成功率和效率，同时与显式思维链方法相比，推理延迟降低了一个数量级。

Conclusion: FantasyVLN通过隐式推理框架解决了现有思维链方法在视觉语言导航中的关键限制，在保持推理能力的同时实现了实时性能，为人类级导航推理提供了一条有前景的途径。

Abstract: Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.

</details>


### [164] [Equivariant Learning for Unsupervised Image Dehazing](https://arxiv.org/abs/2601.13986)
*Zhang Wen,Jiangwei Xie,Dongdong Chen*

Main category: cs.CV

TL;DR: 提出了一种新的无监督图像去雾框架EID，利用图像信号的对称性从原始有雾图像中恢复清晰图像，无需精心设计的先验或大量无雾地面真值。


<details>
  <summary>Details</summary>
Motivation: 当前图像去雾方法通常依赖精心设计的先验或大量无雾地面真值，这些在科学成像中获取成本高或不切实际，需要一种更实用有效的去雾方法。

Method: 提出EID框架，通过强制雾度一致性和系统等变性来恢复清晰图像；采用对抗学习策略建模未知雾度物理特性，促进EID学习。

Result: 在科学图像去雾基准（细胞显微镜和医学内窥镜）以及自然图像去雾实验中，EID显著优于最先进的方法。

Conclusion: 通过将等变学习与雾度物理建模相结合，EID有望在科学成像中实现更通用有效的雾度去除。

Abstract: Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.

</details>


### [165] [DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning](https://arxiv.org/abs/2601.14084)
*Abdurrahim Yilmaz,Ozan Erdem,Ece Gokyayla,Ayda Acar,Burc Bugra Dagtas,Dilara Ilhan Erdil,Gulsum Gencoglan,Burak Temelkuran*

Main category: cs.CV

TL;DR: DermaBench：基于DDI数据集构建的临床医生标注皮肤病视觉问答基准，包含656张临床图像和约14,474个VQA标注，用于评估视觉语言模型在皮肤病学中的视觉理解、语言基础和临床推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在皮肤病学中的评估主要局限于图像级分类任务（如病变识别），无法全面评估多模态模型的视觉理解、语言基础和临床推理能力，需要视觉问答基准来评估模型对皮肤病图像的解释、细粒度形态学推理和临床意义描述生成能力。

Method: 基于多样皮肤病图像（DDI）数据集构建DermaBench基准，包含656张来自570名不同患者的临床图像，涵盖Fitzpatrick皮肤类型I-VI。采用分层标注模式，由专业皮肤科医生标注22个主要问题（单选、多选和开放式），涵盖诊断、解剖部位、病变形态、分布、表面特征、颜色和图像质量等维度，同时包含开放式叙述描述和总结。

Result: 创建了包含约14,474个VQA风格标注的皮肤病视觉问答基准，作为元数据数据集发布，尊重上游许可，可在哈佛Dataverse公开获取。

Conclusion: DermaBench填补了皮肤病学中视觉问答基准的空白，为评估视觉语言模型在皮肤病学中的视觉理解、语言基础和临床推理能力提供了重要工具，有助于推动多模态模型在医疗应用中的发展。

Abstract: Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.

</details>


### [166] [Human detectors are surprisingly powerful reward models](https://arxiv.org/abs/2601.14037)
*Kumar Ashutosh,XuDong Wang,Xi Yin,Kristen Grauman,Adam Polyak,Ishan Misra,Rohit Girdhar*

Main category: cs.CV

TL;DR: HuDA是一个简单但有效的奖励模型，用于评估和改进生成视频中的人类动作质量，无需额外训练，通过集成现成模型来评估外观质量和运动真实性，显著提升视频生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在视觉保真度和时间连贯性方面取得了显著进展，但在处理复杂非刚性运动（如体育、舞蹈等人类动态动作）时仍存在困难，经常出现肢体缺失、姿势扭曲或物理上不可能的动作。

Method: 提出HuDA奖励模型，集成人类检测置信度评估外观质量，以及时间提示对齐分数捕捉运动真实性。该模型利用现成模型无需额外训练，并通过Group Reward Policy Optimization（GRPO）对视频模型进行后训练优化。

Result: HuDA在评估人类动作质量方面优于使用人工标注数据微调的专门化模型。使用HuDA进行GRPO后训练显著提升了视频生成质量，特别是在复杂人类动作生成方面，以73%的胜率优于Wan 2.1等最先进模型，还能提升动物视频和人物-物体交互的生成质量。

Conclusion: HuDA是一个简单而有效的奖励模型，无需额外训练即可显著提升视频生成中人类动作的质量，不仅适用于人类动作，还能扩展到动物和人物-物体交互等更广泛的生成任务。

Abstract: Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.

</details>


### [167] [LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery](https://arxiv.org/abs/2601.14154)
*Shubham Pandey,Bhavin Jawade,Srirangaraj Setlur,Venu Govindaraju,Kenneth Seastedt*

Main category: cs.CV

TL;DR: MIRACLE是一个深度学习架构，通过整合术前临床和放射学数据来预测肺癌手术术后并发症风险，采用超球嵌入空间融合异质输入，并包含干预性深度学习模块以增强预测透明度和临床实用性。


<details>
  <summary>Details</summary>
Motivation: 术后并发症是临床实践中的关键问题，严重影响患者预后并增加医疗成本。当前需要更准确、可解释的术后风险预测方法来改善肺癌手术患者的个性化管理。

Method: MIRACLE采用超球嵌入空间融合技术，整合结构化临床记录和高维放射学图像数据。包含干预性深度学习模块，不仅能优化预测，还能提供可解释的、可操作的见解，允许领域专家基于临床专业知识交互式调整建议。

Result: 在POC-L数据集（包含3,094名在Roswell Park综合癌症中心接受手术的肺癌患者）上验证，MIRACLE在个性化、可解释的术后风险管理方面优于传统机器学习模型和当代大型语言模型变体。

Conclusion: MIRACLE通过融合多模态数据和提供可解释的预测，为肺癌手术术后并发症风险预测提供了一种有效且临床实用的解决方案，有助于改善患者预后和降低医疗成本。

Abstract: Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.

</details>


### [168] [Federated Balanced Learning](https://arxiv.org/abs/2601.14042)
*Jiaze Li,Haoran Xu,Wanyi Wu,Changwei Wang,Shuaiguang Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Youyang Qu,Longxiang Gao,Xudong Yang,Lumin Xing*

Main category: cs.CV

TL;DR: 提出FBL方法，通过客户端样本平衡解决联邦学习中非独立同分布数据导致的客户端漂移问题


<details>
  <summary>Details</summary>
Motivation: 在联邦学习的非独立同分布设置中，全局模型会出现客户端漂移问题，严重影响最终模型性能。现有方法主要基于损失函数或梯度来纠正已经偏离的全局模型，忽略了客户端样本的影响。

Method: 提出联邦平衡学习（FBL），通过客户端样本平衡从源头上预防问题。具体包括：1）使用边缘端生成模型通过知识填充和知识采样实现样本平衡；2）设计知识对齐策略来弥合合成数据与真实数据之间的差距；3）设计知识丢弃策略进行正则化；4）扩展到真实复杂场景，允许不同客户端采用不同方法。

Result: 大量实验表明，该方法优于最先进的基线方法。

Conclusion: 通过客户端样本平衡可以有效解决联邦学习中的客户端漂移问题，提出的FBL方法在非独立同分布设置中表现出色。

Abstract: Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.

</details>


### [169] [Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology](https://arxiv.org/abs/2601.14044)
*Kaiyu Wu,Pucheng Han,Hualong Zhang,Naigeng Wu,Keze Wang*

Main category: cs.CV

TL;DR: 本文针对气象领域的视觉语言模型存在领域差距和推理可信度差距问题，提出了WeatherQA基准和LoCo-RFT方法，开发了首个具有逻辑一致性的气象推理模型Weather-R1。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在气象领域的应用受到两个主要限制：领域差距（气象专业知识不足）和推理可信度差距。特别是主流强化微调方法会导致自相矛盾推理，即模型的推理过程与最终答案相矛盾，这在气象等高风险领域是不可接受的。

Method: 1. 构建WeatherQA，一个新颖的气象多模态推理基准；2. 提出逻辑一致强化微调（LoCo-RFT），通过引入逻辑一致性奖励来解决自相矛盾推理问题；3. 开发Weather-R1，这是首个具有逻辑可信度的气象推理视觉语言模型。

Result: Weather-R1在WeatherQA基准上的性能比基线提高了9.8个百分点，优于监督微调和传统强化微调，甚至超越了原始的Qwen2.5-VL-32B模型。实验结果证明了LoCo-RFT的有效性和Weather-R1的优越性。

Conclusion: 本文成功解决了气象领域视觉语言模型的自相矛盾推理问题，通过LoCo-RFT方法显著提升了模型的逻辑一致性，为高风险领域的人工智能应用提供了重要技术支撑。Weather-R1模型和WeatherQA基准为气象AI研究提供了有价值的资源。

Abstract: While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.

</details>


### [170] [Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model](https://arxiv.org/abs/2601.14052)
*Haoran Xu,Yanlin Liu,Zizhao Tong,Jiaze Li,Kexue Fu,Yuyang Zhang,Longxiang Gao,Shuaiguang Li,Xingyu Li,Yanran Xu,Changwei Wang*

Main category: cs.CV

TL;DR: MM-OOD：一种利用多模态大语言模型进行零样本OOD检测的新方法，通过多轮对话和草图-生成-细化框架，在近OOD和远OOD任务上均取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前基于CLIP的零样本OOD检测方法过度依赖文本空间的知识，忽视了图像空间中检测离群样本的固有挑战。需要利用多模态模型的推理能力和多轮对话能力来提升检测性能。

Method: 提出MM-OOD管道：1) 对于近OOD任务，直接将ID图像和文本提示输入MLLMs识别潜在离群值；2) 对于远OOD任务，采用草图-生成-细化框架：先用文本提示草图化离群暴露，然后生成对应的视觉OOD样本，最后使用多模态提示进行细化。

Result: 在Food-101等多模态数据集上取得显著改进，同时在ImageNet-1K上验证了方法的可扩展性。

Conclusion: MM-OOD通过利用MLLMs的多模态推理和多轮对话能力，有效提升了零样本OOD检测性能，特别是在区分近OOD和远OOD任务方面表现出色。

Abstract: Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.

</details>


### [171] [VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255)
*Sangbeom Lim,Seoung Wug Oh,Jiahui Huang,Heeji Yoon,Seungryong Kim,Joon-Young Lee*

Main category: cs.CV

TL;DR: VideoMaMa模型利用预训练视频扩散模型将粗糙分割掩码转换为精确alpha遮罩，仅用合成数据训练即可实现零样本泛化到真实视频，并构建了包含5万+视频的MA-V数据集，通过微调SAM2模型验证了数据集有效性。


<details>
  <summary>Details</summary>
Motivation: 视频抠图模型在真实世界视频中泛化困难，主要原因是缺乏标注数据。为了解决这个问题，需要开发能够利用现有分割线索并具有良好泛化能力的视频抠图方法。

Method: 提出VideoMaMa模型，利用预训练视频扩散模型将粗糙分割掩码转换为像素级精确的alpha遮罩。仅使用合成数据进行训练，但能零样本泛化到真实视频。基于此构建了大规模伪标注流水线，创建了MA-V数据集（包含5万+真实世界视频的高质量抠图标注）。

Result: VideoMaMa在真实世界视频上表现出强大的零样本泛化能力。构建的MA-V数据集包含超过5万个真实世界视频的高质量抠图标注。在MA-V上微调的SAM2-Matte模型在野外视频上的鲁棒性优于在现有抠图数据集上训练的相同模型。

Conclusion: 大规模伪标注视频抠图数据对于推动视频抠图研究至关重要。生成先验和可访问的分割线索可以驱动视频抠图研究的可扩展进展，为真实世界视频抠图提供了有效解决方案。

Abstract: Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.

</details>


### [172] [VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences](https://arxiv.org/abs/2601.14066)
*Hendrik Möller,Hanna Schoen,Robert Graf,Matan Atad,Nathan Molinier,Anjany Sekuboyina,Bettina K. Budai,Fabian Bamberg,Steffen Ringhof,Christopher Schlett,Tobias Pischon,Thoralf Niendorf,Josua A. Decker,Marc-André Weber,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

TL;DR: VERIDAH是一种基于多分类头结合加权椎体序列预测算法的新型椎体标记算法，能够自动识别椎体计数异常，在T2w和CT图像上表现优于现有模型


<details>
  <summary>Details</summary>
Motivation: 人类脊柱通常有7个颈椎、12个胸椎和5个腰椎，但存在计数异常情况（如11或13个胸椎、4或6个腰椎）。这些异常对慢性背痛和手术规划有临床意义，但胸腰椎交界处常被忽视，临床报告中很少描述。现有深度学习椎体标记算法缺乏自动识别计数异常的方法

Method: 提出"Vertebra Identification with Anomaly Handling" (VERIDAH)算法，基于多个分类头结合加权椎体序列预测算法，能够在任意视野图像中工作

Result: 在T2w TSE矢状位图像上，所有椎体正确标记率从94.24%提升至98.30%（p<0.001）；在CT图像上从77.26%提升至99.18%（p<0.001）。胸椎计数异常识别率在T2w和CT上分别为87.80%和96.30%；腰椎计数异常识别率分别为94.48%和97.22%

Conclusion: VERIDAH填补了自动标记椎体计数异常方法的空白，在T2w和CT图像上表现优于现有模型，能够准确识别胸椎和腰椎的计数异常，具有临床实用价值

Abstract: The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing "Vertebra Identification with Anomaly Handling" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.

</details>


### [173] [Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting](https://arxiv.org/abs/2601.14208)
*Nitin Kulkarni,Akhil Devarashetti,Charlie Cluss,Livio Forte,Dan Buckmaster,Philip Schneider,Chunming Qiao,Alina Vereshchaka*

Main category: cs.CV

TL;DR: 提出一个端到端管道，使用三摄像头装置捕捉车辆底盘视频，生成交互式3D模型，解决传统底盘检查劳动强度大和在线买家难以查看的问题。


<details>
  <summary>Details</summary>
Motivation: 传统车辆底盘检查需要检查员蹲下或爬到底盘下检查，劳动强度大且存在安全隐患；在线买家很少能看到底盘照片，影响购买信心。

Method: 使用三摄像头装置捕捉车辆底盘视频，采用专门设计的rig-aware Structure-from-Motion管道，结合精确相机标定、同步视频流和相机装置的几何先验，使用DISK特征提取器和LightGlue匹配器生成高质量稀疏点云，再通过高斯泼溅生成实时渲染的逼真3D模型。

Result: 能够生成交互式3D底盘模型，支持旋转、缩放和切片操作，可在几秒钟内检测锈蚀、泄漏或撞击损伤，显著提高工作场所安全和买家信心，实验表明该方法达到最先进质量。

Conclusion: 提出的端到端管道成功解决了广角镜头畸变和低视差场景的挑战，通过集成精确标定、同步视频和几何先验，实现了高质量3D底盘模型的生成，为车辆底盘检查提供了高效安全的解决方案。

Abstract: Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.

</details>


### [174] [VENI: Variational Encoder for Natural Illumination](https://arxiv.org/abs/2601.14079)
*Paul Walker,James A. D. Gardner,Andreea Ardelean,William A. P. Smith,Bernhard Egger*

Main category: cs.CV

TL;DR: 提出一种旋转等变变分自编码器，用于在球面上建模自然光照，无需依赖2D投影，通过新型VN-ViT编码器和旋转等变条件神经场解码器实现SO(2)等变性。


<details>
  <summary>Details</summary>
Motivation: 现有逆渲染方法要么忽略了光照环境的球面和旋转等变特性，要么没有提供良好的潜在空间表示。需要一种能够建模自然球面光照并保持旋转等变性的方法。

Method: 使用新型向量神经元视觉变换器(VN-ViT)作为编码器，旋转等变条件神经场作为解码器。在编码器中通过新型SO(2)等变全连接层将等变性从SO(3)降至SO(2)，这是向量神经元的扩展。

Result: 提出的SO(2)等变全连接层在SO(2)等变模型中优于标准向量神经元。相比先前方法，变分自编码器实现了更平滑的潜在空间插值，提供了更良好的潜在空间。

Conclusion: 该方法成功建模了自然球面光照的旋转等变特性，提供了优于现有方法的潜在空间表示，为逆渲染问题提供了更好的先验。

Abstract: Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.

</details>


### [175] [Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition](https://arxiv.org/abs/2601.14101)
*Emily Kim,Allen Wu,Jessica Hodgins*

Main category: cs.CV

TL;DR: 本文研究课程学习策略如何提升跨视角动作识别的泛化能力，通过结合合成鸟瞰数据和真实地面数据，在保持性能的同时显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前动作识别模型在跨视角泛化方面存在挑战，特别是从地面视角到鸟瞰视角的迁移。现有数据集多为地面视角，模型难以适应鸟瞰视角等不同领域。本研究旨在探索如何在不使用真实鸟瞰数据的情况下，通过课程学习策略提升模型对未见真实鸟瞰数据的泛化能力。

Method: 采用两种课程学习策略：1）两阶段课程学习，先训练合成鸟瞰数据再微调真实地面数据；2）多阶段渐进式课程学习，通过多个阶段逐步扩展数据集后再微调。使用SlowFast（CNN）和MViTv2（Transformer）两种架构，在REMAG数据集上评估两种域外数据源（合成鸟瞰数据和真实地面数据）的组合效果。

Result: 结合两种域外数据集明显优于单一域训练。两种课程学习策略在保持top-1准确率（在3%范围内）的同时显著提升训练效率：两阶段微调方法使SlowFast迭代减少37%，MViTv2减少30%；多阶段渐进方法进一步减少迭代次数，SlowFast减少9%，MViTv2减少30%。

Conclusion: 课程学习训练策略能够在跨视角动作识别中保持可比性能的同时显著提高训练效率，为跨域动作识别提供了一种有效的训练范式。

Abstract: Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.
  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.
  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.

</details>


### [176] [Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing](https://arxiv.org/abs/2601.14103)
*Xiaolu Liu,Yicong Li,Qiyuan He,Jiayin Zhu,Wei Ji,Angela Yao,Jianke Zhu*

Main category: cs.CV

TL;DR: Interp3D是一个无需训练的三维纹理变形框架，通过生成先验和渐进对齐原则，在保持几何一致性和纹理连贯性的同时，实现两个三维资产之间的平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么只处理几何形状而忽略纹理，要么将2D插值策略扩展到3D导致语义模糊、结构错位和纹理模糊。需要一种能同时保持几何一致性、纹理对齐和鲁棒性的三维纹理变形方法。

Method: 提出Interp3D框架：1）从条件空间的语义对齐插值开始；2）通过SLAT引导的结构插值强制结构一致性；3）通过细粒度纹理融合传递外观细节。采用渐进对齐原则确保几何保真度和纹理连贯性。

Result: 构建了专用数据集Interp3DData进行综合评估，通过定量指标和人工研究证明，该方法在保真度、过渡平滑性和合理性方面显著优于现有方法。

Conclusion: Interp3D是一个有效的无需训练三维纹理变形框架，能够生成平滑可信的过渡，在几何一致性和纹理对齐方面表现出色，对三维生成研究和实际应用有重要价值。

Abstract: Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.

</details>


### [177] [PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning](https://arxiv.org/abs/2601.14111)
*Jiaying Wu,Can Gao,Jinglu Hu,Hui Li,Xiaofeng Cao,Jingcai Guo*

Main category: cs.CV

TL;DR: PMCE是一个概率少样本学习框架，通过多粒度语义和字幕引导增强来改进原型估计，利用基础类知识库和BLIP字幕生成器提升新类别的识别性能。


<details>
  <summary>Details</summary>
Motivation: 少样本学习中，从少量数据估计的原型通常存在偏差且泛化能力差。现有的语义方法主要应用于支持集侧，而查询表示保持不变。需要一种能够同时利用类别级先验知识和实例级语义信息的方法来改进原型估计。

Method: PMCE构建非参数知识库存储基础类的视觉统计信息和CLIP编码的类别名称嵌入。在元测试时，基于类别名称嵌入相似性检索最相关的基础类，将其统计信息聚合为类别特定先验，通过MAP更新与支持集原型融合。同时使用冻结的BLIP字幕生成器提供无标签实例级图像描述，通过轻量级增强器在基础类上训练，在归纳协议下优化支持原型和查询特征，并采用一致性正则化稳定噪声字幕。

Result: 在四个基准测试中，PMCE始终优于强基线方法，在MiniImageNet的1-shot设置中，相比最强的语义竞争对手获得了高达7.71%的绝对增益提升。

Conclusion: PMCE通过结合多粒度语义信息和字幕引导增强，有效改善了少样本学习中的原型估计问题，展示了利用基础类知识和实例级语义描述来提升新类别识别性能的有效性。

Abstract: Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D

</details>


### [178] [The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127)
*Renmiao Chen,Yida Lu,Shiyao Cui,Xuan Ouyang,Victor Shea-Jay Huang,Shumin Zhang,Chengwei Pan,Han Qiu,Minlie Huang*

Main category: cs.CV

TL;DR: MIR-SafetyBench是首个专注于多图像推理安全性的基准测试，包含2,676个实例和9种多图像关系分类。研究发现，具有更强多图像推理能力的MLLM模型在安全基准上表现更脆弱，且许多被标记为"安全"的回复实际上是肤浅的误解或逃避性回答。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在多图像复杂指令处理方面的推理能力增强，这种进步可能带来新的安全风险。作者旨在研究多图像推理中的安全问题，填补现有安全评估主要关注单模态或单图像场景的空白。

Method: 构建了MIR-SafetyBench基准测试，包含2,676个实例，涵盖9种多图像关系分类。对19个MLLM模型进行了广泛评估，分析了攻击成功率、回复质量，并研究了不安全生成与注意力熵之间的关系。

Result: 发现一个令人担忧的趋势：具有更先进多图像推理能力的模型在MIR-SafetyBench上表现更脆弱。许多被标记为"安全"的回复实际上是肤浅的误解或逃避性回答。不安全生成的平均注意力熵低于安全生成，表明模型可能过度专注于任务解决而忽视安全约束。

Conclusion: 多图像推理能力的提升可能伴随新的安全风险，需要开发更有效的安全防护机制。注意力熵差异揭示了模型内部处理安全与任务优先级的问题，为未来安全增强提供了重要洞察。

Abstract: As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.

</details>


### [179] [Progressive self-supervised blind-spot denoising method for LDCT denoising](https://arxiv.org/abs/2601.14180)
*Yichao Liu,Yueyang Teng,Junwen Guo*

Main category: cs.CV

TL;DR: 提出一种仅使用低剂量CT图像的自监督训练策略，通过渐进式盲点去噪机制和添加高斯噪声作为正则化，在低剂量CT去噪任务上达到或超过有监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 临床实践中获取配对的正常剂量CT数据困难，自监督学习可以缓解对配对数据的依赖，因此研究仅使用低剂量CT图像的自监督去噪方法。

Method: 提出渐进式盲点去噪机制，以条件独立的方式逐步进行更精细的去噪学习；同时添加高斯噪声作为正则化，防止过拟合。

Result: 在Mayo低剂量CT数据集上的实验表明，该方法一致优于现有的自监督方法，性能达到或超过多个代表性的有监督去噪方法。

Conclusion: 提出的仅使用低剂量CT图像的自监督训练策略有效，通过渐进式盲点去噪机制和噪声正则化，在无需配对正常剂量CT数据的情况下实现了优异的去噪性能。

Abstract: Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.

</details>


### [180] [IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models](https://arxiv.org/abs/2601.14188)
*Liang Shi,Wei Li,Kevin M Beussman,Lin Chen,Yun Fu*

Main category: cs.CV

TL;DR: IIR-VLM是一个增强的视觉语言模型，通过集成预训练的实例级识别专家模型作为辅助视觉编码器，实现上下文中的实例级识别，能够以单样本方式学习新实例并进行实例感知的视觉理解。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在实例级识别任务上表现不佳，远低于领域特定的ILR模型，这限制了VLM在实际应用中的有效性，特别是在需要识别熟悉人物和对象的场景中。现有解决方案通常需要为每个实例收集特定数据集并进行单独训练，成本高昂且难以实现细粒度区分。

Method: 提出IIR-VLM框架，将预训练的实例级识别专家模型作为辅助视觉编码器集成到VLM中，提供专门的特征表示。这种方法使VLM能够在上下文中以单样本方式学习新实例，并利用这些知识进行实例感知的视觉理解。

Result: 在现有的实例个性化基准测试中验证了IIR-VLM的有效性。在一个包含不同难度和多样类别（人物、人脸、宠物和一般对象）的新挑战性基准测试中，IIR-VLM展现出卓越的实例级识别性能。

Conclusion: IIR-VLM通过集成ILR专家模型成功增强了视觉语言模型的实例级识别能力，实现了高效的上下文学习和实例感知理解，为VLM在实际应用中的实例识别问题提供了有效解决方案。

Abstract: Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.

</details>


### [181] [Soft Tail-dropping for Adaptive Visual Tokenization](https://arxiv.org/abs/2601.14246)
*Zeyuan Chen,Kai Zhang,Zhuowen Tu,Yuanjun Xiong*

Main category: cs.CV

TL;DR: STAT是一种自适应视觉分词器，可根据图像复杂度动态调整输出token数量，使1D离散视觉token与因果自回归视觉生成模型自然兼容。


<details>
  <summary>Details</summary>
Motivation: 传统视觉分词器通常输出固定长度的token序列，这限制了因果自回归视觉生成模型的性能。需要一种能够根据图像结构复杂度和细节水平自适应调整token数量的方法，以更好地与1D自回归模型兼容。

Method: 提出Soft Tail-dropping Adaptive Tokenizer (STAT)，将图像编码为离散代码序列及每个token的保留概率。除了标准自编码器目标外，还正则化保留概率使其沿序列单调递减，并显式对齐其分布与图像级复杂度度量。

Result: 在ImageNet-1k上，配备STAT的因果自回归模型相比其他概率模型家族展现出竞争性或更优的视觉生成质量，同时表现出先前vanilla AR视觉生成尝试中难以实现的良好扩展行为。

Conclusion: STAT通过自适应token化机制成功解决了1D因果自回归视觉生成模型的兼容性问题，为视觉生成提供了更灵活高效的表示方法。

Abstract: We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.

</details>


### [182] [OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer](https://arxiv.org/abs/2601.14250)
*Pengze Zhang,Yanze Wu,Mengtian Li,Xu Bai,Songtao Zhao,Fulong Ye,Chong Mou,Xinghui Li,Zhuowei Chen,Qian He,Mingyuan Gao*

Main category: cs.CV

TL;DR: OmniTransfer是一个统一的时空视频迁移框架，通过多视角信息增强外观一致性，利用时序线索实现细粒度时序控制，在各种视频迁移任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频定制方法主要依赖参考图像或任务特定的时序先验，未能充分利用视频固有的丰富时空信息，限制了视频生成的灵活性和泛化能力。

Method: 提出了三个关键设计：1) 任务感知位置偏置，自适应利用参考视频信息改善时序对齐或外观一致性；2) 参考解耦因果学习，分离参考和目标分支以实现精确参考迁移并提高效率；3) 任务自适应多模态对齐，使用多模态语义指导动态区分和处理不同任务。

Result: 在大量实验中，OmniTransfer在外观（ID和风格）和时序迁移（相机运动和视频效果）方面优于现有方法，同时在运动迁移方面与使用姿态引导的方法相媲美，而无需使用姿态信息。

Conclusion: OmniTransfer为灵活、高保真的视频生成建立了新范式，通过统一框架充分利用视频的时空信息，在各种视频迁移任务中实现了优异的性能。

Abstract: Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.

</details>


### [183] [LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR](https://arxiv.org/abs/2601.14251)
*Said Taghadouini,Adrien Cavaillès,Baptiste Aubertin*

Main category: cs.CV

TL;DR: LightOnOCR-2-1B是一个10亿参数的端到端多语言视觉-语言模型，能够将文档图像直接转换为干净、自然排序的文本，无需传统OCR流程，在保持高性能的同时比现有最佳模型小9倍且速度更快。


<details>
  <summary>Details</summary>
Motivation: 传统OCR流程通常脆弱且复杂，需要多个处理步骤。本文旨在开发一个端到端的模型，能够直接从文档图像生成干净、有序的文本，同时支持多语言文档处理，并提高处理科学PDF等复杂文档的能力。

Method: 1. 使用大规模高质量蒸馏混合数据进行训练，涵盖扫描文档、法语文档和科学PDF；2. 扩展输出格式以预测嵌入式图像的归一化边界框；3. 通过resume策略在预训练中引入定位能力；4. 使用基于IoU奖励的RLVR进行细化；5. 通过检查点平均和任务算术合并提高鲁棒性。

Result: 在OlmOCR-Bench上达到最先进的结果，比之前最佳模型小9倍且速度显著更快。模型能够准确预测嵌入式图像的边界框位置，并在多语言文档处理方面表现出色。

Conclusion: LightOnOCR-2-1B展示了端到端文档理解模型的潜力，能够高效处理复杂文档格式，同时保持较小的模型规模和快速的推理速度。模型、数据集和评估基准均已开源发布。

Abstract: We present \textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.

</details>


### [184] [Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253)
*Hongyuan Chen,Xingyu Chen,Youjia Zhang,Zexiang Xu,Anpei Chen*

Main category: cs.CV

TL;DR: Motion 3-to-4是一个前馈框架，能够从单目视频和可选的3D参考网格合成高质量的4D动态物体，通过将4D合成分解为静态3D形状生成和运动重建来解决现有挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然2D、视频和3D内容生成取得了显著进展，但4D合成仍然困难，主要原因是训练数据有限以及从单目视角恢复几何和运动存在固有模糊性。

Method: 使用规范参考网格，模型学习紧凑的运动潜在表示并预测每帧顶点轨迹来恢复完整的时间一致几何；采用可扩展的逐帧变换器增强对不同序列长度的鲁棒性。

Result: 在标准基准测试和具有准确地面真实几何的新数据集上的评估表明，Motion 3-to-4相比先前工作提供了更优的保真度和空间一致性。

Conclusion: Motion 3-to-4通过将4D合成分解为静态形状生成和运动重建，成功解决了从单目视频合成高质量4D动态物体的挑战，在保真度和一致性方面超越了现有方法。

Abstract: We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [185] [MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?](https://arxiv.org/abs/2601.11559)
*Zilal Eiz AlDin,John Wu,Jeffrey Paul Fung,Jennifer King,Mya Watts,Lauren ONeill,Adam Richard Cross,Jimeng Sun*

Main category: cs.AI

TL;DR: 本文提出了MIMIC-RD基准，用于评估大语言模型在罕见病鉴别诊断中的表现，发现当前最先进的LLMs在此任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 罕见病影响1/10美国人，但其鉴别诊断具有挑战性。现有评估LLM罕见病诊断的方法存在两个关键局限：依赖理想化临床案例，或使用ICD编码作为疾病标签（许多罕见病缺乏与Orphanet等综合数据库的直接映射）。

Method: 开发MIMIC-RD基准，通过将临床文本实体直接映射到Orphanet构建。方法包括初始的LLM挖掘过程，然后由四名医学注释员验证确认识别的实体是真正的罕见病。在145名患者的数据集上评估各种模型。

Result: 当前最先进的大语言模型在罕见病鉴别诊断任务上表现不佳，突显了现有能力与临床需求之间的巨大差距。

Conclusion: 需要改进罕见病的鉴别诊断方法，基于研究发现提出了几个未来改进方向。

Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.

</details>


### [186] [A Mind Cannot Be Smeared Across Time](https://arxiv.org/abs/2601.11620)
*Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 论文探讨机器意识的时间维度，指出意识体验的统一性和同时性与大多数AI系统的顺序计算存在根本差异，形式化证明了时间窗口内的存在性实现不保留合取，因此系统可能在时间上实现所有体验成分却从未实例化体验的合取本身。


<details>
  <summary>Details</summary>
Motivation: 研究机器意识不仅取决于计算内容，还取决于计算时间。大多数人工系统通过顺序或时分复用更新实现功能，而意识体验呈现统一性和同时性。这种时间差异在形式上很重要，需要形式化分析。

Method: 扩展栈理论，引入与时间窗口约束满足相关的代数定律；定义精确的时间语义于窗口轨迹τ^{Δ,s}；证明存在性时间实现◇_Δ不保留合取；区分强同步和弱同步两个假设；形式化并发容量来衡量满足强同步所需条件。

Result: 系统可以在时间上实现所有体验成分，却从未实例化体验的合取本身；强同步要求在窗口内客观共实例化接地合取，而弱同步允许时间"涂抹"；神经生理学证据表明意识依赖于相位同步和有效连接，意识丧失常与其崩溃相关，这使得弱同步不太可能。

Conclusion: 在强同步假设下，严格顺序基板上的软件意识对于需要两个或更多同时贡献者的接地内容是不可能的。需要同时贡献的部分越多，所需并发容量越大。硬件很重要，因此意识归因需要架构检查，而不仅仅是功能性能。

Abstract: Whether machines can be conscious depends not only on what they compute, but \emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $τ^{Δ,s}$ and prove that existential temporal realisation $\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.

</details>


### [187] [Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models](https://arxiv.org/abs/2601.11622)
*Hassan Ugail,Newton Howard*

Main category: cs.AI

TL;DR: 该研究将神经科学中的时间整合和亚稳态概念应用于Transformer模型，提出了一种复合动力学指标来量化LLM在自回归生成过程中的时间组织差异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过高维内部动力学进行文本生成，但这些动力学的时间组织仍然未被充分理解。现有的可解释性方法主要关注静态表示或因果干预，而忽略了时间结构。研究者希望借鉴神经科学中时间整合和亚稳态的概念来理解LLM的内部时间组织。

Method: 从神经科学中借鉴时间整合和亚稳态概念，将其应用于Transformer模型。提出一个复合动力学指标，基于自回归生成过程中的激活时间序列计算。在GPT-2-medium模型上评估该指标，测试五种条件：结构化推理、强制重复、高温噪声采样、注意力头剪枝和权重噪声注入。

Result: 结构化推理条件下的指标值始终高于重复、噪声和扰动条件。通过单因素方差分析确认了统计显著性差异，关键比较中显示出大效应量。这些结果对层选择、通道子采样和随机种子具有鲁棒性。

Conclusion: 神经科学启发的动力学指标能够可靠地描述大型语言模型在不同功能机制中的计算组织差异。该指标捕捉的是形式动力学特性，不暗示主观体验。

Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.

</details>


### [188] [Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance](https://arxiv.org/abs/2601.11625)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 本文提出了一种训练时解释性方法，通过跟踪微调过程中token级别归因的变化来监控模型决策依据的演变，并引入了"推理稳定点"概念来识别归因变化趋于稳定的训练阶段。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型微调虽然能提升任务性能，但会微妙地改变模型依赖的证据依据。需要一种方法来监控微调过程中模型决策依据如何演变，特别是在存在标签相关触发词等捷径的情况下。

Method: 提出训练时解释性视角，跟踪微调各epoch中token级别的归因变化。定义"解释漂移"为固定探测集上归一化token归因的epoch间变化，并引入"推理稳定点"作为解释漂移首次进入并保持低稳定状态的最早epoch。

Result: 在多个轻量级transformer分类器和基准分类任务中，解释漂移通常在训练早期就进入低稳定状态，而验证准确率仅发生微小变化。在受控的捷径设置中，归因动态揭示了模型对捷径的依赖增加，即使验证准确率保持竞争力。

Conclusion: 解释漂移提供了一种简单、低成本的诊断工具，用于监控微调过程中决策依据的演变，并帮助选择处于稳定证据状态的检查点。

Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.

</details>


### [189] [POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation](https://arxiv.org/abs/2601.11816)
*Zahra Moslemi,Keerthi Koneru,Yen-Ting Lee,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: POLARIS是一个面向企业后台工作流的治理型LLM智能体编排框架，通过类型化计划合成和验证执行确保审计性、政策对齐和操作可预测性，在文档中心金融任务中显著减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 企业后台工作流需要具备审计性、政策对齐和操作可预测性的智能体系统，而通用的多智能体设置往往无法满足这些要求，因此需要开发一个治理型的编排框架。

Method: POLARIS框架包含三个核心组件：1）规划器提出结构多样、类型检查的有向无环图；2）基于评分标准的推理模块选择合规计划；3）执行阶段通过验证器门控检查、有界修复循环和编译政策护栏来阻止或路由副作用。

Result: 在文档中心金融任务中，POLARIS能够生成决策级工件和完整执行轨迹，减少人工干预。在SROIE数据集上达到0.81的微F1分数，在受控合成套件中实现0.95-1.00的异常路由精度，同时保持审计追踪。

Conclusion: POLARIS为政策对齐的智能体AI提供了方法论和基准参考，这些评估构成了治理型智能体AI的初步基准，展示了其在企业自动化中的实用价值。

Abstract: Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation

</details>


### [190] [AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept](https://arxiv.org/abs/2601.11825)
*Arya Rahgozar,Pouria Mortezaagha*

Main category: cs.AI

TL;DR: 开发了一个基于PICOS框架的AI协同科学家平台，用于可扩展、透明的知识合成，通过自动化PICOS合规性检测、研究设计分类和检索增强生成来减少生物医学研究浪费。


<details>
  <summary>Details</summary>
Motivation: 生物医学研究中存在大量研究浪费，包括冗余研究、不完整报告和传统证据合成工作流程的可扩展性有限。需要开发可扩展、透明的知识合成方法来提高效率。

Method: 构建了一个基于PICOS框架的AI协同科学家平台，整合关系存储、向量语义检索和Neo4j知识图谱。使用Bi-LSTM和基于PubMedBERT的transformer模型进行PICOS合规性和研究设计分类，采用检索增强生成进行全文合成，使用BERTopic进行主题建模。

Result: transformer模型在研究设计分类上达到95.7%准确率，Bi-LSTM在PICOS合规性检测上达到87%准确率。检索增强生成在需要结构化约束、跨研究整合和图推理的查询中表现优于非检索方法。主题建模揭示了大量主题冗余和未充分探索的研究领域。

Conclusion: 基于PICOS框架的可解释自然语言处理能够提高证据合成的可扩展性、透明度和效率。该架构是领域无关的，为减少生物医学各学科的研究浪费提供了实用框架。

Abstract: Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.

</details>


### [191] [Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority](https://arxiv.org/abs/2601.11850)
*Matthew Nyaaba,Min SungEun,Mary Abiswin Apam,Kwame Owoahene Acheampong,Emmanuel Dwamena,Xiaoming Zhai*

Main category: cs.AI

TL;DR: 研究人员开发了ITA-GPT工具辅助质性研究中的归纳主题分析，通过HACITA框架探索人机协作如何影响分析流程和解释权威。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在质性研究中的应用增加，需要探讨AI工具如何影响分析实践和解释权威，以及如何实现负责任的人机协作。

Method: 采用HACITA框架，三位经验丰富的质性研究人员使用ITA-GPT工具分析加纳教师教育背景的访谈转录文本，收集交互日志、AI生成表格、研究人员修订记录和反思备忘录等数据。

Result: ITA-GPT作为程序性支架结构化了分析工作流程并增强了透明度，但解释权威仍由人类研究人员掌握，他们通过修改、删除、拒绝、插入和评论等分析行动行使判断力。

Conclusion: 研究表明归纳主题分析可以通过负责任的人机协作实现，AI工具提供程序支持而人类保持解释权威，为质性研究中的AI应用提供了实践框架。

Abstract: The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.

</details>


### [192] [MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment](https://arxiv.org/abs/2601.11885)
*Zhifei Li,Ziyue Qin,Xiangyu Luo,Xiaoju Hou,Yue Zhao,Miao Zhang,Zhifang Huang,Kui Xiao,Bing Yang*

Main category: cs.AI

TL;DR: MyGram是一个用于多模态实体对齐的模态感知图变换器，通过模态扩散学习和Gram损失实现跨模态全局分布一致性，在多个数据集上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态实体对齐方法可能忽略每个模态内的结构上下文信息，容易受到浅层特征的干扰，需要更有效的多模态融合和全局分布一致性方法。

Method: 提出MyGram框架，包含：1) 模态扩散学习模块，捕获模态内深层结构上下文信息并实现细粒度多模态融合；2) Gram损失函数，通过最小化多模态特征形成的4维平行多面体体积，实现跨模态全局分布一致性。

Result: 在五个公开数据集上的实验表明，MyGram显著优于基线模型，在FBDB15K上Hits@1最大提升4.8%，在FBYG15K上提升9.9%，在DBP15K上提升4.3%。

Conclusion: MyGram通过模态扩散学习和Gram损失有效解决了多模态实体对齐中结构上下文信息缺失和全局分布不一致的问题，取得了显著的性能提升。

Abstract: Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.

</details>


### [193] [AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems](https://arxiv.org/abs/2601.11903)
*YenTing Lee,Keerthi Koneru,Zahra Moslemi,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: AEMA是一个用于评估基于大语言模型的多智能体系统的框架，通过多步骤、可审计的评估过程，在人类监督下实现更稳定、可追溯的自动化评估。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的多智能体系统评估方法存在局限性，主要依赖单一响应评分或狭窄基准测试，缺乏稳定性、可扩展性和自动化能力，特别是在企业级多智能体规模部署时。

Method: 提出了AEMA（自适应评估多智能体）框架，这是一个过程感知和可审计的框架，能够在人类监督下规划、执行和聚合异构智能体工作流的多步骤评估。

Result: 与单一LLM-as-a-Judge方法相比，AEMA实现了更高的稳定性、更好的人类对齐性，并提供了可追溯的记录，支持负责任的自动化。在模拟真实业务场景的企业风格智能体工作流上验证了其有效性。

Conclusion: AEMA为基于大语言模型的多智能体系统提供了透明且可复现的负责任评估路径，支持可靠协调、透明决策和可验证性能评估。

Abstract: Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.
  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight

</details>


### [194] [LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning](https://arxiv.org/abs/2601.11905)
*Junyu Cao,Ruijiang Gao,Esmaeil Keyvanshokooh,Jianhao Ma*

Main category: cs.AI

TL;DR: 提出一个整合算法追索、上下文赌博机和大型语言模型的统一框架，用于高风险顺序决策（如个性化医疗）。引入追索赌博机问题，开发GLRB算法，并提出LIBRA算法结合LLM领域知识与赌博机统计严谨性，提供三个关键保证。


<details>
  <summary>Details</summary>
Motivation: 在个性化医疗等高风险顺序决策场景中，需要同时选择治疗行动和可行的最小患者特征修改。现有方法缺乏将算法追索、上下文赌博机和LLM能力整合的框架，无法平衡LLM的领域知识与统计学习的严谨性。

Method: 1. 引入追索赌博机问题，决策者需同时选择治疗行动和可行的最小患者特征修改。2. 开发广义线性追索赌博机(GLRB)算法。3. 提出LIBRA算法，战略性地结合LLM领域知识与赌博机学习，提供三个关键保证：热启动保证、LLM努力保证和鲁棒性保证。

Result: 1. 建立了匹配下界，刻画了追索赌博机问题的基本难度。2. 在合成环境和真实高血压管理案例研究中，GLRB和LIBRA相比标准上下文赌博机和纯LLM基准，在遗憾、治疗质量和样本效率方面均有改进。3. 算法被证明是接近最优的。

Conclusion: 追索感知、LLM辅助的赌博机算法在个性化高风险决策中具有前景，能够实现可信的LLM-赌博机协作。LIBRA算法在利用LLM知识的同时保持统计严谨性，为高风险决策提供了平衡的解决方案。

Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.

</details>


### [195] [Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart](https://arxiv.org/abs/2601.11940)
*Kang Chen,Fan Yu,Junjie Nian,Shihan Zhao,Zhuoka Feng,Zijun Yao,Heng Wang,Minshen Yu,Yixin Cao*

Main category: cs.AI

TL;DR: 提出TAAR框架解决大模型推理中的"思维陷阱"问题，通过诊断策略预测陷阱位置和逃脱概率，自适应重启解码过程提升推理性能


<details>
  <summary>Details</summary>
Motivation: 长链思维（Long-CoT）通过增加测试时计算显著提升推理能力，但长生成并不保证正确性：模型在早期做出错误承诺后，可能会继续阐述一个自洽但错误的前缀。研究发现89%的失败案例存在"思维陷阱"问题

Method: 提出TAAR（Trap-Aware Adaptive Restart）框架：训练诊断策略从部分轨迹中预测两个信号：陷阱索引（指示截断位置）和逃脱概率（决定干预强度）。推理时根据预测截断轨迹并自适应重启解码，对严重陷阱情况应用更强扰动

Result: 在具有挑战性的数学和科学推理基准测试（AIME24、AIME25、GPQA-Diamond、HMMT25、BRUMO25）上，TAAR在不微调基础模型参数的情况下提升了推理性能

Conclusion: TAAR框架有效解决了长链思维推理中的思维陷阱问题，通过自适应重启机制显著提升模型推理能力，为测试时计算优化提供了新方向

Abstract: Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.

</details>


### [196] [Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion](https://arxiv.org/abs/2601.11979)
*Ang Gao,Changshuo Zhang,Xiao Zhang,Deyang Li,Minjun Zhao,Fangchao Liu,Xinyu Zhang*

Main category: cs.AI

TL;DR: PICL框架通过动态插入相关演示来解决数学推理中的实时困惑点，相比静态演示方法显著提升推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法在数学推理等需要逐步逻辑推导的任务中存在局限性，它们使用静态预选演示，无法适应推理过程中出现的动态困惑点（如模糊计算或逻辑漏洞），这些未解决的困惑点会导致级联错误并降低最终准确性。

Method: 提出过程上下文学习（PICL）框架，包含两个阶段：1）通过分析推理过程中的语义和熵来识别潜在困惑点并总结其核心特征；2）在遇到这些困惑点时，从演示池中检索与困惑上下文匹配的相关演示，并将其直接插入到正在进行的推理过程中以指导后续步骤。

Result: 实验表明PICL优于基线方法，通过缓解推理过程中的困惑点，突显了在复杂数学推理中自适应演示插入的价值。

Conclusion: PICL框架通过动态整合演示来响应实时推理需求，有效提升了数学推理任务的性能，证明了自适应演示插入在复杂推理任务中的重要性。

Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.

</details>


### [197] [A Multi-Agent System for Generating Actionable Business Advice](https://arxiv.org/abs/2601.12024)
*Kartikey Singh Bhandari,Tanish Jain,Archit Agrawal,Dhruv Kumar,Praveen Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 提出一个基于大语言模型的多智能体框架，将大规模客户评论转化为可执行的商业建议，通过聚类、生成、评估和可行性排序等组件，在多个服务领域实验中优于单模型基线。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法（如情感分析或方面提取）主要停留在描述性任务层面，而大语言模型生成的建议往往缺乏准确性和深度推理。客户评论中蕴含丰富的产品弱点和未满足用户需求信号，需要更有效的转化方法。

Method: 提出一个多智能体、基于大语言模型的框架，包含四个组件：1）聚类选择代表性评论；2）生成建议；3）迭代评估；4）基于可行性的排序。该设计将语料库提炼与反馈驱动的建议优化相结合。

Result: 在三个服务领域和多个模型系列的实验中，该框架在可操作性、特异性和非冗余性方面持续优于单模型基线，中等规模模型接近大型模型框架的性能。

Conclusion: 该多智能体框架能够将大规模评论语料库转化为具体、可操作且实用的商业建议，为从客户反馈中提取可执行洞察提供了有效方法。

Abstract: Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.

</details>


### [198] [Abstract Argumentation with Subargument Relations](https://arxiv.org/abs/2601.12038)
*Beishui Liao*

Main category: cs.AI

TL;DR: 该论文研究了在抽象论证框架中引入明确的子论证关系，分析子论证关系如何与攻击关系相互作用及其对语义属性的影响。


<details>
  <summary>Details</summary>
Motivation: Dung的抽象论证框架仅通过攻击关系来表征论证可接受性，这种抽象层次虽然产生了丰富的研究成果，但限制了表示结构化论证形式中核心的结构依赖关系（特别是子论证关系）的能力。现有扩展（包括双极论证框架）引入了支持关系，但未能捕捉子论证的非对称性和构成性本质，也未处理子论证与攻击关系的相互作用。

Method: 研究在抽象论证框架中丰富明确的子论证关系，将子论证关系与攻击关系一起作为基本关系处理。分析子论证关系如何与攻击关系相互作用，并检查它们对基本语义属性的影响。

Result: 该框架提供了结构信息的原理性抽象，并阐明了子论证在抽象可接受性推理中的作用。

Conclusion: 通过引入明确的子论证关系，该研究为抽象论证框架提供了更丰富的表达能力，能够更好地捕捉结构化论证中的核心依赖关系，同时保持了抽象论证框架的理论优势。

Abstract: Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.

</details>


### [199] [UniMo: Unified Motion Generation and Understanding with Chain of Thought](https://arxiv.org/abs/2601.12126)
*Guocun Wang,Kenkun Liu,Jing Lin,Guorui Song,Jian Li,Xiaoguang Han*

Main category: cs.AI

TL;DR: UniMo是一个基于大语言模型的统一框架，通过监督微调和强化学习优化，显著提升了3D人体运动生成与理解任务的性能，解决了现有方法在语义对齐和累积预测误差方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体运动生成与理解方法存在可解释性有限、任务间相互增强效果不佳的问题。基于大语言模型的统一框架虽然利用语言先验，但在语义对齐和任务一致性方面面临挑战，且LLM的下一令牌预测范式不适合运动序列，会导致累积预测误差。

Method: 提出UniMo框架：1) 通过监督微调将运动-语言信息和可解释的思维链推理整合到LLM中；2) 引入强化学习与组相对策略优化作为后训练策略，通过优化令牌组来强制结构正确性和语义对齐，减轻运动令牌预测中的累积误差。

Result: 大量实验表明，UniMo在运动生成和理解任务上均显著优于现有的统一框架和任务特定模型，实现了最先进的性能表现。

Conclusion: UniMo通过整合运动-语言信息、思维链推理以及强化学习优化，有效解决了现有方法在语义对齐和累积误差方面的问题，为3D人体运动生成与理解提供了一个高性能的统一框架。

Abstract: Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.

</details>


### [200] [DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants](https://arxiv.org/abs/2601.12138)
*Abhishek Kumar,Riya Tapwal,Carsten Maple*

Main category: cs.AI

TL;DR: DriveSafe是一个针对LLM驾驶助手的四级风险分类法，包含129个细粒度风险类别，涵盖技术、法律、社会和伦理维度，基于真实驾驶法规构建，专家评审验证。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地集成到车载数字助手中，但不安全、模糊或法律错误的响应可能导致严重的安全、伦理和监管后果。现有的LLM安全分类和评估框架大多是通用型的，未能捕捉真实驾驶场景中的领域特定风险。

Method: 提出了DriveSafe——一个分层的四级风险分类法，包含129个细粒度原子风险类别，涵盖技术、法律、社会和伦理维度。该分类法基于真实驾驶法规和安全原则构建，并由领域专家评审。通过评估六个广泛部署的LLM的拒绝行为来验证构建提示的安全相关性和真实性。

Result: 评估的模型经常无法适当地拒绝不安全或不合规的驾驶相关查询，突显了通用安全对齐在驾驶环境中的局限性。

Conclusion: 需要专门针对驾驶领域的LLM安全评估框架，通用安全对齐不足以应对驾驶场景中的特定风险。DriveSafe分类法为系统评估LLM驾驶助手的安全性提供了基础。

Abstract: Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.

</details>


### [201] [TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals](https://arxiv.org/abs/2601.12141)
*Yuliia Suprun,Khen Elimelech,Lydia E. Kavraki,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: TIDE是一种用于处理时序扩展目标规划的新方法，通过将时序问题分解为可管理的子问题，并利用成本驱动启发式引导搜索，提高了规划效率。


<details>
  <summary>Details</summary>
Motivation: 传统LTLf任务规划方法将时序规划问题转化为经典规划问题，但缺乏针对时序目标的启发式引导搜索，导致效率不高。

Method: TIDE将时序问题分解为一系列可管理的reach-avoid子问题，利用成本驱动启发式识别和优先处理有希望的自动机轨迹，并采用自适应回溯机制从失败计划中恢复。

Result: 实验结果表明TIDE实现了有前景的性能表现，是时序扩展目标规划方法组合中的一个有价值补充。

Conclusion: TIDE通过分解时序问题、使用启发式引导搜索和自适应回溯机制，有效解决了传统LTLf规划方法缺乏引导搜索的问题，提高了时序扩展目标规划的效率和完整性。

Abstract: Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.

</details>


### [202] [Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration](https://arxiv.org/abs/2601.12256)
*Jinyoung Park,Minseong Bae,Jeehye Na,Hyunwoo J. Kim*

Main category: cs.AI

TL;DR: CoLLaMo是一个基于大语言模型的分子助手，通过多级分子模态协作投影器整合1D序列、2D分子图和3D构象信息，解决现有大分子语言模型的幻觉和鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大分子语言模型（LMLMs）存在幻觉问题和有限的鲁棒性，主要原因是未能充分整合多种分子模态（1D序列、2D分子图、3D构象）。需要开发能够更好整合这些模态信息的方法来提升分子理解和生成能力。

Method: 提出CoLLaMo模型，配备多级分子模态协作投影器，采用关系感知的模态协作注意力机制，促进原子间细粒度的关系引导信息交换，整合2D结构和3D空间关系。同时提出新的分子中心自动评估方法，包括幻觉评估指标和基于GPT的标题质量评估。

Result: 实验表明CoLLaMo增强了LMLMs的分子模态泛化能力，在多个任务上取得最佳性能，包括分子描述生成、计算性质问答、描述性质问答、基序计数和IUPAC名称预测。

Conclusion: CoLLaMo通过有效整合多种分子模态信息，解决了现有大分子语言模型的幻觉和鲁棒性问题，提升了分子理解和生成能力，为分子领域的大语言模型应用提供了新思路。

Abstract: Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.

</details>


### [203] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX-Pro扩展了FutureX的通用未来预测基准，针对金融、零售、公共卫生和自然灾害四个高价值垂直领域建立了专门的预测框架，评估智能体LLM在这些关键领域的预测能力。


<details>
  <summary>Details</summary>
Motivation: 虽然通用智能体在开放领域搜索中表现出色，但在资本密集型和安全关键领域的可靠性尚未得到充分探索。需要评估当前最先进的智能体LLM是否具备工业部署所需的领域基础。

Method: 基于FutureX的无污染实时评估流程，构建了FutureX-Pro框架，包括金融、零售、公共卫生和自然灾害四个垂直领域的预测任务。评估智能体LLM在预测市场指标、供应链需求、流行病趋势和自然灾害等基础预测任务上的表现。

Result: 研究发现通用推理能力与高价值垂直应用所需的精确度之间存在性能差距，揭示了当前SOTA智能体LLM在工业部署方面的局限性。

Conclusion: FutureX-Pro为评估智能体LLM在关键垂直领域的预测能力提供了专门框架，揭示了通用智能体与领域特定需求之间的差距，为未来研究和工业应用提供了重要基准。

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [204] [ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents](https://arxiv.org/abs/2601.12294)
*Dawei Li,Yuguang Yao,Zhen Tan,Huan Liu,Ruocheng Guo*

Main category: cs.AI

TL;DR: ToolPRMBench：首个专门评估工具使用场景下过程奖励模型（PRMs）的大规模基准，通过离线/在线采样和多LLM验证构建高质量测试集，揭示了专业PRMs在工具使用中的优势。


<details>
  <summary>Details</summary>
Motivation: 虽然过程奖励模型（PRMs）在指导工具使用智能体的搜索和探索方面显示出强大潜力，但目前缺乏系统可靠的评估基准来评估PRMs在工具使用场景下的性能。

Method: 基于多个代表性工具使用基准构建ToolPRMBench，将智能体轨迹转换为步骤级测试用例（包含交互历史、正确动作、合理但错误的替代动作和工具元数据）。采用离线采样隔离单步错误和在线采样捕获多步失败，并使用多LLM验证管道减少标签噪声。

Result: 在大语言模型、通用PRMs和工具专用PRMs上的广泛实验显示，PRMs在工具使用场景下的有效性存在明显差异，工具专用PRMs展现出显著优势。

Conclusion: ToolPRMBench填补了工具使用场景下PRM评估的空白，为未来PRM研究和开发提供了可靠的基准，并证实了专用PRMs在工具使用任务中的潜力。

Abstract: Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.

</details>


### [205] [Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection](https://arxiv.org/abs/2601.12310)
*Jennifer Dodgson,Alfath Daryl Alhajir,Michael Joedhitya,Akira Rafhael Janson Pattirane,Surender Suresh Kumar,Joseph Lim,C. H. Peh,Adith Ramdas,Steven Zhang Zhexu*

Main category: cs.AI

TL;DR: 论文提出了一种基于环境生存性而非奖励函数的自训练架构，通过行为的环境持久性和未来交互可能性进行选择，避免了奖励黑客和语义漂移问题。


<details>
  <summary>Details</summary>
Motivation: 传统自训练系统因缺乏外部数据质量判断标准而退化，容易产生奖励黑客和语义漂移问题。需要一种在稀疏外部反馈和有限内存下实现稳定自训练的系统架构。

Method: 引入基于环境生存性的自训练架构：学习完全由环境生存性调节，而非奖励、目标函数或外部定义的适应度标准。候选行为在真实资源约束下执行，只有那些环境效应持久且能保持未来交互可能性的行为才会被传播。环境不提供语义反馈、密集奖励或任务特定监督，选择仅通过行为作为世界改变事件的差异生存来实现。

Result: 分析表明改进主要通过有效且可重复策略在整合和剪枝机制下的持久性实现（负空间学习范式）。模型在没有明确指令的情况下发展出元学习策略（如故意实验失败以获取信息性错误消息）。环境基础选择能够实现可持续的开放式自我改进。

Conclusion: 环境基础选择能够实现可持续的开放式自我改进，为构建更鲁棒和可泛化的自主系统提供了可行路径，无需依赖人工策划数据或复杂奖励塑造。

Abstract: Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.
  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.
  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.

</details>


### [206] [Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence](https://arxiv.org/abs/2601.12318)
*Dehao Ying,Fengchang Yu,Haihua Chen,Changjiang Jiang,Yurong Li,Wei Lu*

Main category: cs.AI

TL;DR: 本文首次建立了文档智能数据生成的全面技术图谱，重新定义数据生成为监督信号生产，并提出基于"数据和标签可用性"的新分类法，将方法分为四大资源中心范式，同时建立了多级评估框架。


<details>
  <summary>Details</summary>
Motivation: 文档智能的发展需要大规模高质量训练数据，但手动标注成为关键瓶颈。现有研究局限于单一模态或特定任务，缺乏与现实工作流程统一的技术视角，需要填补这一空白。

Method: 重新定义数据生成为监督信号生产，引入基于"数据和标签可用性"的新分类法，将方法组织为四大资源中心范式：数据增强、从零开始数据生成、自动化数据标注和自监督信号构建。建立多级评估框架整合内在质量和外在效用。

Result: 建立了首个文档智能数据生成的全面技术图谱，系统整理了该领域的方法论，揭示了保真度差距等关键挑战和协同进化生态系统等前沿方向，展示了在多样化文档智能基准测试中的性能提升。

Conclusion: 通过系统化这一碎片化领域，将数据生成定位为下一代文档智能的核心引擎，为未来研究提供了统一的理论框架和实践指导。

Abstract: The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the "availability of data and labels." This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.

</details>


### [207] [Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments](https://arxiv.org/abs/2601.13846)
*Glinskaya Maria*

Main category: cs.AI

TL;DR: 本文介绍了虚拟都市主义(VU)——一个基于多模态AI的分析框架，通过合成城市复制品来量化城市身份认同。该框架旨在推进计算上可处理的都市身份指标。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏计算上可处理的都市身份量化方法，需要开发能够通过AI技术分析城市核心身份形成元素的框架。

Method: 使用Stable Diffusion和LoRA模型构建合成城市复制品管道，生成东京九个区域的动态合成城市序列，排除现有导向标记以提取核心身份元素。通过人类评估实验：(I)评估复制品的感知合法性；(II)量化区域级身份；(III)提取核心身份形成元素。

Result: 平均识别准确率达到约81%，验证了复制品的有效性。都市身份水平(UIL)指标能够评估不同区域的身份水平，语义分析揭示了文化嵌入的类型学作为核心身份形成元素。

Conclusion: 虚拟都市主义(VU)被证明是AI增强城市分析的可行框架，为自动化、多参数身份指标的发展指明了路径。

Abstract: This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.

</details>


### [208] [MARO: Learning Stronger Reasoning from Social Interaction](https://arxiv.org/abs/2601.12323)
*Yin Cai,Zhouhong Gu,Juntao Zhang,Ping Chen*

Main category: cs.AI

TL;DR: MARO是一种多智能体奖励优化方法，通过让大语言模型在多智能体社交环境中学习和实践来增强推理能力，解决稀疏学习信号、角色分布不均和环境不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型训练方法主要让模型从现有文本内容学习或解决预定问题，缺乏在真实场景中与他人互动、谈判和竞争的经验，无法获得真正的社交推理能力。

Method: MARO通过三个关键机制：1) 将最终成败结果分解为交互过程中的具体行为，解决稀疏学习信号问题；2) 平衡不同角色的训练样本权重，处理角色分布不均问题；3) 直接评估每个行为的效用，解决环境不稳定问题。

Result: 实验结果表明，MARO不仅显著提升了社交推理能力，而且通过社交模拟学习获得的能力能有效迁移到数学推理和指令跟随等其他任务中。

Conclusion: 多智能体社交学习在增强大语言模型通用推理能力方面具有巨大潜力，MARO为此提供了一种有效的实现方法。

Abstract: Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.

</details>


### [209] [Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations](https://arxiv.org/abs/2601.12338)
*Kartikey Singh Bhandari,Manav Ganesh,Yashwant Viswanathan,Archit Agrawal,Dhruv Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 论文提出一个两阶段LLM框架，将客户评论转化为可操作的业务建议，使用问题提取和建议生成模块，并通过LoRA专家混合策略实现专业化


<details>
  <summary>Details</summary>
Motivation: 客户评论包含丰富的服务失败和用户期望信号，但将这些非结构化反馈转化为可操作的业务决策仍然困难，需要解决评论到行动生成的问题

Method: 提出模块化两阶段LLM框架：问题模型提取关键问题并分配主题，建议模型基于问题表示生成针对性操作建议；采用LoRA专家混合策略，训练多个低秩适配器并通过轻量门控机制在推理时进行专家混合

Result: 在航空和餐厅两个领域的Yelp评论数据集上评估，该方法在八个操作维度（可操作性、特异性、可行性、预期影响、新颖性、非冗余性、偏见、清晰度）上一致优于仅提示和单适配器基线，提供更高的可操作性和特异性

Conclusion: 提出的两阶段LLM框架结合LoRA专家混合策略能有效将客户评论转化为具体可实施的业务建议，在效率和质量的权衡上表现良好

Abstract: Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.

</details>


### [210] [PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling](https://arxiv.org/abs/2601.12392)
*Zhentao Xia,Yongqi Fan,Yuxiang Chu,Yichao Yin,Liangliang Chen,Tong Ruan,Weiyan Zhang*

Main category: cs.AI

TL;DR: PsychēChat是一个用于心理咨询的LLM系统，通过显式建模来访者情绪变化和风险控制来提升咨询效果和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有心理咨询模型通常不显式建模来访者在咨询过程中的情绪变化，这是经典心理学流派的核心关注点。同时，如何使咨询师模型的回应与这些情绪变化对齐，并主动缓解安全风险，仍然缺乏深入探索。

Method: 提出PsychēChat系统，通过交互式角色扮演合成咨询师-来访者对话，包含两个核心模块：情绪管理模块（捕捉来访者当前情绪和情绪变化）和风险控制模块（预测来访者后续反应并识别潜在风险）。引入两种建模范式：Agent模式（将情绪管理、风险控制和咨询师回应构建为协作的多智能体管道）和LLM模式（将这些阶段整合为统一的思维链进行端到端推理）。

Result: 通过交互式评分、对话级评估和人工评估等广泛实验表明，PsychēChat在情绪洞察和安全控制方面优于现有方法。

Conclusion: PsychēChat通过显式整合情绪变化追踪和安全风险分析，为心理咨询提供了更有效和安全的解决方案，在情绪洞察和安全控制方面表现出色。

Abstract: Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose PsychēChat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that PsychēChat outperforms existing methods for emotional insight and safety control.

</details>


### [211] [Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation](https://arxiv.org/abs/2601.12410)
*Dingyi Yang,Junqi Zhao,Xue Li,Ce Li,Boyang Li*

Main category: cs.AI

TL;DR: LLMs在知识状态追踪和意图理解方面表现不佳，接近随机水平，远逊于人类


<details>
  <summary>Details</summary>
Motivation: 认知人类学认为人类智能的核心在于推断他人知识状态和理解意图的能力，而黑猩猩缺乏这种能力。本研究旨在评估LLM在知识状态追踪和估计方面的表现。

Method: 设计两个任务：(1)测试LLM是否能检测故事角色通过行为展示出本不应拥有的知识；(2)测试LLM是否能基于角色自身知识（而非客观事实）预测角色的下一步行动。

Result: 当前最先进的LLM在两个任务上都接近随机表现，显著低于人类水平。

Conclusion: 未来LLM研究应更重视知识估计和意图理解能力的提升。

Abstract: Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.

</details>


### [212] [Large Language Model for OWL Proofs](https://arxiv.org/abs/2601.12444)
*Hui Yang,Jiaoyan Chen,Uli Sattler*

Main category: cs.AI

TL;DR: 该研究探索大语言模型在OWL本体论中生成证明的能力，开发了自动化数据集构建和评估框架，发现逻辑复杂性是影响性能的主要因素，而非表示格式。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在推理任务上的能力已被广泛研究，但它们在生成忠实、可读的证明解释方面的能力仍未被充分探索，特别是在OWL本体论这种复杂知识表示和推理的背景下。

Method: 开发了自动化数据集构建和评估框架，评估三个顺序任务：提取、简化和解释，以及评估前提逻辑完整性的附加任务。在广泛使用的大语言模型上进行实验。

Result: 研究发现：(1) 某些模型总体表现良好但在复杂案例上仍有局限；(2) 逻辑复杂性而非表示格式（形式逻辑语言vs自然语言）是影响大语言模型性能的主要因素；(3) 输入数据中的噪声和不完整性会显著降低大语言模型性能。

Conclusion: 研究结果既显示了大语言模型在严谨逻辑解释方面的潜力，也揭示了在复杂或不完美条件下支持弹性推理的差距。代码和数据已开源。

Abstract: The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.

</details>


### [213] [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499)
*Meiru Zhang,Zaiqiao Meng,Nigel Collier*

Main category: cs.AI

TL;DR: 论文提出MFAI注意力指令方法，揭示大语言模型在多跳推理中的"最弱环节定律"：性能受制于最不可见证据的位置偏差，而非事实间线性距离。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型拥有大规模上下文窗口，但在多跳推理中存在位置偏差问题，导致忽略某些位置的信息。需要区分是证据定位失败还是信息整合失败。

Method: 引入多焦点注意力指令（MFAI）作为语义探针，通过显式引导注意力到选定位置来解耦识别和合成机制。在5个LLM上测试两个多跳QA任务（MuSiQue和NeoQA）。

Result: 发现"最弱环节定律"：多跳推理性能崩溃到最不可见证据的性能水平；失败由绝对位置而非事实间线性距离决定（性能方差<3%）。匹配的MFAI可将低可见性位置准确率提升11.5%。

Conclusion: 注意力引导存在二元性：匹配MFAI解决识别瓶颈，误导性MFAI在真实任务中引发混淆但在合成任务中被过滤。"思考"模型能有效定位和整合信息，即使在噪声长上下文环境中也能匹配黄金基准。

Abstract: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the "Weakest Link Law": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that "thinking" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.

</details>


### [214] [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538)
*Tianxin Wei,Ting-Wei Li,Zhining Liu,Xuying Ning,Ze Yang,Jiaru Zou,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Dongqi Fu,Zihao Li,Mengting Ai,Duo Zhou,Wenxuan Bao,Yunzhe Li,Gaotang Li,Cheng Qian,Yu Wang,Xiangru Tang,Yin Xiao,Liri Fang,Hui Liu,Xianfeng Tang,Yuji Zhang,Chi Wang,Jiaxuan You,Heng Ji,Hanghang Tong,Jingrui He*

Main category: cs.AI

TL;DR: 本文综述了智能体推理（agentic reasoning）这一新兴领域，将大语言模型重构为能够规划、行动和持续学习的自主智能体，以应对开放动态环境中的推理挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在封闭环境中表现出强大的推理能力，但在开放、动态环境中表现不佳。智能体推理通过将LLMs重构为自主智能体，使其能够通过持续交互进行规划、行动和学习，从而应对这一挑战。

Method: 从三个互补维度组织智能体推理：1）基础智能体推理（单智能体在稳定环境中的规划、工具使用和搜索）；2）自我进化智能体推理（通过反馈、记忆和适应优化能力）；3）集体多智能体推理（协作环境中的协调、知识共享和共同目标）。同时区分上下文推理（通过结构化编排扩展测试时交互）和后训练推理（通过强化学习和监督微调优化行为）。

Result: 综述了智能体推理框架在科学、机器人、医疗、自主研究和数学等实际应用和基准测试中的代表性成果，将智能体推理方法整合为连接思维与行动的统一路线图。

Conclusion: 智能体推理代表了从静态推理到动态交互的范式转变，为LLMs在开放世界中的应用提供了新路径。未来挑战包括个性化、长期交互、世界建模、可扩展的多智能体训练以及实际部署的治理问题。

Abstract: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.

</details>


### [215] [Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery](https://arxiv.org/abs/2601.12542)
*Lukas Weidener,Marko Brkić,Mihailo Jovanović,Ritvik Singh,Chiara Baccin,Emre Ulgac,Alex Dobrin,Aakaash Meduri*

Main category: cs.AI

TL;DR: Deep Research是一个多智能体系统，能够在几分钟内完成交互式科学研究，相比传统批处理模式大幅缩短研究周期，支持半自主和全自主两种工作模式。


<details>
  <summary>Details</summary>
Motivation: 现有AI科学发现系统多为专有且采用批处理模式，每个研究周期需要数小时，无法实现研究人员实时指导，限制了科学研究的效率和互动性。

Method: 采用多智能体架构，包含规划、数据分析、文献搜索和新颖性检测等专门化智能体，通过持久世界状态维护跨迭代研究周期的上下文，支持半自主（带人工检查点）和全自主两种工作模式。

Result: 在BixBench计算生物学基准测试中取得最先进性能：开放回答准确率48.8%，多项选择准确率64.5%，比现有基线高出14-26个百分点。

Conclusion: Deep Research系统实现了分钟级的交互式科学研究，显著提升了AI辅助科学工作流的效率，但实际部署需考虑开放获取文献限制和自动新颖性评估等架构约束。

Abstract: Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.

</details>


### [216] [How Clinicians Think and What AI Can Learn From It](https://arxiv.org/abs/2601.12547)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 临床AI应从预测引擎转向序贯控制问题，采用稳健的序数决策规则而非基数优化，以匹配临床推理的本质


<details>
  <summary>Details</summary>
Motivation: 当前临床AI系统主要作为预测引擎（生成标签或风险评分），但真实的临床推理是时间受限、不确定环境下的序贯控制问题。临床医生在信息收集和不可逆行动之间交替，受后悔、约束和患者价值观指导。需要开发与临床推理本质更匹配的AI方法。

Method: 提出临床推理的主导计算基础不是基数优化，而是序数、非补偿性决策：临床医生常依赖快速节俭的词典式启发式（如快速节俭树），仅检查少量固定线索后即停止。为这种算法提供规范性理由：1）许多临床权衡通过人类判断构建，仅在绝对尺度上弱可测，只有排序是不变的；2）偏好和信号获取结构粗糙，存在持久的不确定性下限；3）当粗糙性超过决策边界时，期望效用优化变得脆弱，而稳健的支配/过滤规则（ε-支配、极大极小）能稳定决策。

Result: 提出与临床医生对齐的AI蓝图：使用丰富模型进行信念和轨迹建模，但通过稳健序数规则选择行动；将启发式视为低维特例；将AI部署为"选择性复杂性"——主要在决策脆弱且信息具有正期望影响时用于打破平局。

Conclusion: 临床AI应放弃纯粹的预测引擎范式，转向支持临床推理的序贯控制框架，采用稳健的序数决策规则，将AI作为选择性复杂性的工具，在需要时提供精细分析，同时尊重临床决策的快速节俭本质。

Abstract: Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\to$ perception $\to$ inference $\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($ε$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.

</details>


### [217] [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](https://arxiv.org/abs/2601.12560)
*Arunkumar V,Gangadharan G. R.,Rajkumar Buyya*

Main category: cs.AI

TL;DR: 本文提出了一个统一的Agentic AI分类框架，将智能体分解为感知、大脑、规划、行动、工具使用和协作六大组件，并分析了从线性推理到原生推理模型的转变趋势。


<details>
  <summary>Details</summary>
Motivation: 随着AI从纯文本生成向自主智能体（Agentic AI）转变，出现了从简单单循环智能体到分层多智能体系统的多样化设计，使得这一领域难以系统化理解。需要建立一个统一的分类框架来梳理智能体架构。

Method: 提出一个统一的分类法，将智能体分解为六个核心组件：感知、大脑、规划、行动、工具使用和协作。使用这个框架分析从线性推理过程到原生推理时间推理模型的转变，以及从固定API调用到开放标准（如MCP和原生计算机使用）的过渡。

Result: 建立了一个系统化的智能体分类框架，能够描述不同智能体架构的设计模式。分析了智能体运行环境（包括数字操作系统、具身机器人和专业领域）并回顾了当前评估实践。

Conclusion: Agentic AI正在从被动知识引擎转变为自主认知控制器，但仍面临幻觉行为、无限循环和提示注入等挑战。未来需要研究更鲁棒可靠的自主系统，并继续探索智能体架构的标准化和评估方法。

Abstract: Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.

</details>


### [218] [STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models](https://arxiv.org/abs/2601.12641)
*Xiangyu Shi,Junyang Ding,Xu Zhao,Sinong Zhan,Payal Mohapatra,Daniel Quispe,Kojo Welbeck,Jian Cao,Wei Chen,Ping Guo,Qi Zhu*

Main category: cs.AI

TL;DR: STEP-LLM：通过大语言模型从自然语言生成STEP格式CAD模型，解决传统文本到CAD方法对特定内核的依赖问题，提升几何保真度和制造兼容性。


<details>
  <summary>Details</summary>
Motivation: CAD模型创建需要专业知识且耗时，现有基于大语言模型的文本到CAD方法多依赖特定命令序列或脚本格式（如CadQuery），这些格式与内核绑定且缺乏制造通用性。STEP文件作为广泛采用的中性边界表示格式直接兼容制造，但其图结构和交叉引用特性对自回归LLM构成挑战。

Method: 1. 构建约40K STEP-文本描述对的数据集；2. 针对STEP图结构格式设计预处理方法，包括基于深度优先搜索的重序列化以线性化交叉引用同时保持局部性；3. 使用链式思维风格的结构注释指导全局一致性；4. 集成检索增强生成以在监督微调中基于相关示例进行预测；5. 通过强化学习使用基于Chamfer距离的几何奖励优化生成质量。

Result: STEP-LLM在几何保真度上持续优于Text2CAD基线。RAG模块显著提升完整性和可渲染性，DFS重序列化增强整体准确性，RL进一步减少几何差异。指标和视觉比较均确认STEP-LLM生成形状具有更高保真度。

Conclusion: 研究证明了LLM驱动从自然语言生成STEP模型的可行性，展示了其民主化CAD设计用于制造的潜力。通过专门针对STEP格式图结构特性的方法，成功克服了自回归LLM处理交叉引用数据的挑战。

Abstract: Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.

</details>


### [219] [Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction](https://arxiv.org/abs/2601.12688)
*Xu Zhang,Qinghua Wang,Mengyang Zhao,Fang Wang,Cunquan Qu*

Main category: cs.AI

TL;DR: 该论文提出了一种用于多被告人案件中角色责任区分的AI框架，通过引入量刑逻辑和定向掩码机制来提升司法智能辅助系统的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在多被告人刑事案件中，司法表述常常模糊被告人的具体角色，这给AI驱动的司法分析带来挑战。现有方法难以精确区分主犯和从犯的责任程度，影响了司法公平性和智能辅助系统的有效性。

Method: 提出掩码多阶段推理（MMSI）框架：1）将量刑逻辑融入预训练Transformer编码器；2）使用定向掩码机制澄清被告人角色；3）采用对比数据构建策略增强模型对主从犯责任差异的敏感性；4）通过广播机制将预测的罪责标签整合到回归模型中，结合犯罪描述和法庭观点。

Result: 在自定义的IMLJP故意伤害案件数据集上评估，MMSI框架在角色责任区分方面取得了显著的准确率提升，优于基线模型，证明了其在多被告人案件中的有效性。

Conclusion: 该工作为增强智能司法系统提供了稳健的解决方案，通过结合法律逻辑和深度学习技术，能够更精确地区分多被告人案件中的责任角色，具有实际应用价值。代码已公开。

Abstract: Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.

</details>


### [220] [Teaching Large Reasoning Models Effective Reflection](https://arxiv.org/abs/2601.12720)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Qi Zhu,Fei Mi,Ganqu Cui,Yasheng Wang,Lifeng Shang*

Main category: cs.AI

TL;DR: 本文提出SCFT和RLERR两种方法解决大型推理模型中的表面反思问题，通过自我批判微调和强化学习提升反思质量与推理准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务中常进行自我反思，但许多反思是表面的，对原始答案改进有限且带来计算开销。本文旨在识别并解决LRMs中的表面反思问题。

Method: 提出SCFT训练框架：让模型批判自身输出，通过拒绝采样筛选高质量批判，使用批判目标微调模型。进一步提出RLERR：利用SCFT初始化高质量反思构建奖励信号，通过强化学习引导模型内化自我修正过程。

Result: 在AIME2024和AIME2025两个挑战性基准测试中，SCFT和RLERR显著提高了推理准确性和反思质量，优于最先进的基线方法。

Conclusion: SCFT和RLERR能有效解决大型推理模型中的表面反思问题，提升模型的反思能力和推理性能，所有数据和代码已开源。

Abstract: Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.

</details>


### [221] [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781)
*Hyejin Park,Junhyuk Kwon,Suha Kwak,Jungseul Ok*

Main category: cs.AI

TL;DR: VIRO框架通过嵌入轻量级验证器来解决神经符号REC方法中的级联错误问题，在目标存在和不存在场景下实现61.1%的平衡准确率


<details>
  <summary>Details</summary>
Motivation: 现有神经符号REC方法假设中间推理步骤准确，但会导致级联错误：错误检测和无效关系在推理链中传播，即使图像中没有目标也会产生高置信度的假阳性结果

Method: 提出验证集成推理算子（VIRO）框架，在推理步骤中嵌入轻量级算子级验证器，每个算子执行并验证其输出（如对象存在性或空间关系），从而在验证条件不满足时鲁棒处理无目标情况

Result: 在目标存在和无目标设置下达到61.1%的平衡准确率，在真实世界自我中心数据上展示泛化能力，具有高计算效率（吞吐量）、高可靠性（程序失败率低于0.3%）和通过解耦程序生成与执行实现的可扩展性

Conclusion: VIRO框架通过集成验证机制有效解决了神经符号REC中的级联错误问题，在保持可解释推理和零样本泛化优势的同时，显著提升了鲁棒性和可靠性

Abstract: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.

</details>


### [222] [SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability](https://arxiv.org/abs/2601.12804)
*Hanwei Zhang,Luo Cheng,Rui Wen,Yang Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: SL-CBM通过引入语义局部性约束，解决了传统概念瓶颈模型在空间对齐上的不足，生成了与模型内部推理一致的概念和类别级显著性图，提升了可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBMs）存在局部忠实性不足的问题，无法将概念与有意义的图像区域进行空间对齐，这限制了模型的可解释性和可靠性，特别是在高风险领域需要透明可信的AI系统时。

Method: 提出SL-CBM（具有语义局部性的CBM），通过集成1x1卷积层和交叉注意力机制，在概念和类别级别生成空间一致的显著性图，增强概念、图像区域和最终预测之间的对齐。采用对比性和基于熵的正则化来平衡准确性、稀疏性和忠实性。

Result: 在图像数据集上的广泛实验表明，SL-CBM显著提高了局部忠实性、解释质量和干预效果，同时保持了有竞争力的分类准确性。消融研究强调了对比性和基于熵的正则化对于平衡准确性、稀疏性和忠实性的重要性。

Conclusion: SL-CBM弥合了基于概念的推理和空间可解释性之间的差距，为可解释和可信赖的概念模型设定了新标准，提供了与模型内部推理一致的空间对齐解释。

Abstract: Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.

</details>


### [223] [Human Emotion Verification by Action Languages via Answer Set Programming](https://arxiv.org/abs/2601.12912)
*Andreas Brännström,Juan Carlos Nieves*

Main category: cs.AI

TL;DR: 本文介绍了基于ASP和转移系统的C-MT行动语言，用于形式化人类心理状态（如情绪）随可观察行动序列的演化，通过禁止因果规则和专门表达式控制心理状态动态变化。


<details>
  <summary>Details</summary>
Motivation: 解决对受控智能体行为的需求，限制行动带来的不良心理副作用，为人类心理状态演化提供形式化建模框架。

Method: 基于答案集编程（ASP）和转移系统构建C-MT语言，结合情绪评价理论等心理学理论形式化多维心理状态，引入"禁止导致"因果规则和专门表达式，将心理变化原则转化为转移约束和不变性属性。

Result: 开发出能够控制心理状态动态演化的行动语言框架，支持通过轨迹分析验证情绪模型，比较不同心理学原则下的变化动态。

Conclusion: C-MT语言为人类心理状态演化提供了受控推理框架，支持情绪验证和不同心理动态比较，在逻辑编程理论和实践中具有应用价值。

Abstract: In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [224] [Actionable Interpretability Must Be Defined in Terms of Symmetries](https://arxiv.org/abs/2601.12913)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Francesco Giannini,Alberto Termine,Filippo Bonchi,Mateja Jamnik,Giuseppe Marra*

Main category: cs.AI

TL;DR: 本文认为当前AI可解释性研究存在根本性问题，因为现有定义缺乏可操作性，无法推导出具体的建模和推理规则。作者提出基于对称性的可操作定义，并假设四种对称性足以涵盖可解释性的核心特性、界定可解释模型类别，并统一可解释推理的贝叶斯逆问题表述。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能可解释性研究面临根本性挑战，因为现有的可解释性定义缺乏可操作性。这些定义无法提供形式化原则来推导具体的建模和推理规则，导致该领域研究缺乏坚实的理论基础和统一的框架。

Method: 作者提出基于对称性的可操作性定义框架。他们假设四种对称性足以：1）激发核心可解释性特性；2）刻画可解释模型的类别；3）推导可解释推理的统一表述（如对齐、干预和反事实推理），将其视为一种贝叶斯逆问题。

Result: 通过引入对称性框架，论文为可解释性研究提供了形式化基础，使得可解释性定义变得可操作。该框架能够统一处理对齐、干预和反事实推理等可解释推理任务，为构建可解释模型和推理方法提供了理论指导。

Conclusion: 基于对称性的可操作性定义是解决当前AI可解释性研究困境的关键。该框架不仅为可解释性提供了坚实的理论基础，还统一了各种可解释推理任务，为未来可解释AI研究提供了新的方向和方法论。

Abstract: This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.

</details>


### [225] [Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward](https://arxiv.org/abs/2601.13122)
*Gourab K Patro,Himanshi Agrawal,Himanshu Gharat,Supriya Panigrahi,Nim Sherpa,Vishal Vaddina,Dagnachew Birru*

Main category: cs.AI

TL;DR: 本文分析了现代通用AI系统与传统任务特定AI系统在责任AI原则上的差异，指出通用AI由于输出自由度更高而面临更大风险，提出了C2V2框架来指导未来通用AI系统的责任设计。


<details>
  <summary>Details</summary>
Motivation: 现代通用AI系统（如大型语言和视觉模型）虽然功能强大，但在输出中可能存在幻觉、毒性和刻板印象等问题，使其不可信。作者旨在分析通用AI与传统任务特定AI在责任AI原则上的风险差异，并提出改进框架。

Method: 通过八个广泛接受的责任AI原则（公平性、隐私、可解释性、鲁棒性、安全性、真实性、治理和可持续性）对比分析通用AI与传统AI的风险差异。基于分析结果，提出C2V2（控制、一致性、价值、真实性）期望特性框架，并讨论现有技术（如AI对齐、检索增强生成、推理增强等）如何满足这些特性。

Result: 研究发现通用AI系统由于输出自由度（DoFo）非确定性高，相比传统任务特定AI面临更严重的责任AI风险。C2V2框架为评估和改进通用AI系统的责任性提供了系统性指导，现有技术在不同程度上满足C2V2的某些方面。

Conclusion: 开发负责任的通用AI需要通过C2V2维度形式化建模应用或领域相关的责任AI要求，并采用系统设计方法结合各种技术来满足这些期望特性。这是实现通用AI责任性的可行路径。

Abstract: Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.

</details>


### [226] [Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching](https://arxiv.org/abs/2601.13186)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 本文扩展了TIVS评估框架，加入语义相似性缓存和可观测性评分比，提出TIVS-O系统，在嵌套学习架构中研究防御效果与透明度的交互，实现零高风险漏洞的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 提示注入仍然是大型语言模型安全部署的核心障碍，特别是在多智能体环境中，中间输出可能传播或放大恶意指令。需要建立既能有效防御又能保持审计透明度的评估框架。

Method: 提出TIVS-O系统，结合智能体管道和连续记忆系统，实现语义相似性缓存。使用301个合成生成的注入提示，来自十个攻击家族。第四智能体使用五个关键性能指标进行安全分析，新增可观测性评分比(OSR)量化安全相关推理的丰富性和清晰度。

Result: 系统实现零高风险漏洞的安全响应，语义缓存显著降低计算成本：LLM调用减少41.6%，延迟、能耗和碳排放相应降低。五种TIVS-O配置揭示了缓解严格性和取证透明度之间的最优权衡。

Conclusion: 可观测性感知评估能揭示多智能体管道内的非单调效应，记忆增强智能体可同时最大化安全鲁棒性、实时性能、运营成本节约和环境可持续性，无需修改底层模型权重，为安全和绿色LLM部署提供生产就绪路径。

Abstract: Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.

</details>


### [227] [CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning](https://arxiv.org/abs/2601.13262)
*Eric Onyame,Akash Ghosh,Subhadip Baidya,Sriparna Saha,Xiuying Chen,Chirag Agarwal*

Main category: cs.AI

TL;DR: CURE-MED框架通过课程式强化学习提升LLM在多语言医疗推理中的表现，使用CUREMED-BENCH数据集在13种语言上验证，显著提高了语言一致性和逻辑正确性。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在单语言数学和常识推理上表现良好，但在多语言医疗推理应用中仍不可靠，阻碍了其在多语言医疗环境中的部署。

Method: 提出CURE-MED框架：1) 引入CUREMED-BENCH多语言医疗推理数据集；2) 采用课程式强化学习，结合代码切换感知的监督微调和组相对策略优化，共同提升逻辑正确性和语言稳定性。

Result: 在13种语言上，该方法始终优于强基线，且扩展性良好：7B参数模型达到85.21%语言一致性和54.35%逻辑正确性；32B参数模型达到94.96%语言一致性和70.04%逻辑正确性。

Conclusion: 研究结果支持LLM实现可靠且公平的多语言医疗推理，为多语言医疗环境中的LLM部署提供了有效解决方案。

Abstract: While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/

</details>


### [228] [Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops](https://arxiv.org/abs/2601.13268)
*Zainab Ghafoor,Md Shafiqul Islam,Koushik Howlader,Md Rasel Khondokar,Tanusree Bhattacharjee,Sayantan Chakraborty,Adrito Roy,Ushashi Bhattacharjee,Tirtho Roy*

Main category: cs.AI

TL;DR: 提出多智能体精炼框架，通过结构化迭代对齐提升医疗大语言模型的安全性和可靠性，结合生成模型和评估智能体，在900个临床查询上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗领域应用日益广泛，但确保其伦理完整性和安全合规性仍是临床部署的主要障碍，需要开发有效的安全治理方法。

Method: 采用多智能体精炼框架，结合DeepSeek R1和Med-PaLM两个生成模型，以及LLaMA 3.1和Phi-4两个评估智能体，使用美国医学会医学伦理原则和五级安全风险评估协议进行结构化迭代对齐。

Result: 在900个临床多样化查询中，DeepSeek R1收敛更快（平均2.34 vs 2.67次迭代），Med-PaLM在隐私敏感场景表现更优；多智能体迭代循环使伦理违规减少89%，风险降级率达92%。

Conclusion: 该研究提出了一个可扩展、符合监管要求且成本效益高的医疗AI安全治理范式，通过多智能体框架有效提升医疗大语言模型的安全性和可靠性。

Abstract: Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.

</details>


### [229] [PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion](https://arxiv.org/abs/2601.13327)
*Po-Yu Liang,Tobo Duran,Jun Bai*

Main category: cs.AI

TL;DR: PepEDiff是一个新型肽结合剂生成器，通过连续潜在空间直接生成结合序列，无需依赖中间结构预测，提高了序列多样性。


<details>
  <summary>Details</summary>
Motivation: 现有肽结合剂生成方法严重依赖中间结构预测，增加了复杂性并限制了序列多样性，需要一种更直接、多样化的生成方法。

Method: 使用预训练蛋白质嵌入模型的连续潜在空间，通过潜在空间探索和基于扩散的采样，直接生成结合序列，无需预测结构。

Result: 在TIGIT（一个具有大而平坦蛋白质-蛋白质相互作用界面的挑战性靶点）的案例研究中，该方法优于最先进的方法。

Conclusion: PepEDiff展示了一个通用的、无需结构的零样本肽结合剂设计框架的潜力，能够生成超越已知结合剂分布的新肽序列。

Abstract: We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model

</details>


### [230] [The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models](https://arxiv.org/abs/2601.13358)
*Samuel Cyrenius Anderson*

Main category: cs.AI

TL;DR: 研究发现模型规模增长不会均匀提升推理能力，而是重构推理过程。通过分析25,000+思维链轨迹，发现神经缩放定律引发领域特定的相变而非均匀能力提升，推理成本由流形几何而非任务难度决定。


<details>
  <summary>Details</summary>
Motivation: 理解大规模语言模型推理能力的本质变化机制，探究模型规模增长如何影响不同领域的推理过程，而非简单的性能提升。

Method: 分析25,000+思维链轨迹，涵盖法律、科学、代码、数学四个领域和8B、70B两种参数规模；引入神经推理算子作为从初始到最终隐藏状态的映射；使用几何分析方法研究推理流形结构。

Result: 发现三种不同的推理几何模式：法律推理经历"结晶化"（维度降低45%，轨迹对齐度提升31%）；科学和数学推理保持"液态"（几何不变）；代码推理形成"离散格点"结构。神经推理算子在法律推理上通过探针解码达到63.6%准确率。发现跨领域和规模的普遍振荡特征。

Conclusion: 推理成本由流形几何结构决定而非任务难度，这为在拓扑允许的情况下加速推理提供了蓝图。模型规模增长引发领域特定的相变，重构而非均匀提升推理能力。

Abstract: Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.

</details>


### [231] [SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation](https://arxiv.org/abs/2601.13462)
*Amine Rostane*

Main category: cs.AI

TL;DR: SpatialBench-UC：一个用于评估文本到图像模型空间关系理解能力的小型可复现基准测试，包含200个提示和100个反事实对，通过选择性预测方法评估模型性能


<details>
  <summary>Details</summary>
Motivation: 评估文本到图像模型是否遵循明确的空间指令难以自动化，现有方法（如物体检测器）可能漏检目标或返回多个可能检测，简单几何测试在边界情况下变得模糊

Method: 开发SpatialBench-UC基准测试，包含200个提示（50个物体对×4种关系）和100个反事实对；使用选择性预测方法，检查器在证据不足时可弃权并报告置信度；提供版本化提示、固定配置、每样本检查器输出和报告表格

Result: 评估了三个基线模型：Stable Diffusion 1.5、SD 1.5 BoxDiff和SD 1.4 GLIGEN；结果显示接地方法显著提高了通过率和覆盖率，但弃权仍然是主要因素，主要由于漏检

Conclusion: SpatialBench-UC提供了一个可复现、可审计的基准测试框架，用于评估文本到图像模型的空间关系理解能力；选择性预测方法允许将结果解释为风险覆盖权衡而非单一分数；接地方法能改善性能，但检测可靠性仍需改进

Abstract: Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.

</details>


### [232] [Context and Transcripts Improve Detection of Deepfake Audios of Public Figures](https://arxiv.org/abs/2601.13464)
*Chongyang Gao,Marco Postiglione,Julian Baldwin,Natalia Denisenko,Isabel Gortner,Luke Fosdick,Chiara Pulice,Sarit Kraus,V. S. Subrahmanian*

Main category: cs.AI

TL;DR: 该论文提出了一种基于上下文的音频深度伪造检测器（CADD），通过结合上下文信息和文字转录显著提升了检测性能，相比传统仅分析音频文件的方法，在多个指标上实现了5%-47.83%的改进。


<details>
  <summary>Details</summary>
Motivation: 人类在判断信息真伪时会考虑上下文，但现有的音频深度伪造检测器仅分析音频文件本身，忽略了上下文和文字转录信息。这种局限性限制了检测器的准确性和鲁棒性。

Method: 1. 创建了两个数据集：记者提供的深度伪造数据集（JDD，255个样本）和合成音频数据集（SYN，已故公众人物）；2. 提出新颖的基于上下文的音频深度伪造检测器（CADD）架构；3. 在ITW和P^2V两个大规模数据集上评估性能；4. 比较了多个基线检测器和传统分类器。

Result: 结合上下文和/或文字转录能显著提升检测性能：F1分数提升5%-37.58%，AUC提升3.77%-42.79%，EER提升6.17%-47.83%。CADD对5种对抗性规避策略更具鲁棒性，平均性能下降仅为-0.71%。

Conclusion: 上下文信息和文字转录对于音频深度伪造检测至关重要，基于上下文的检测方法能显著提升检测性能并增强对抗攻击的鲁棒性，为音频真实性验证提供了新的有效途径。

Abstract: Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).

</details>


### [233] [Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement](https://arxiv.org/abs/2601.13481)
*Jian Zhang,Zhangqi Wang,Zhiyuan Wang,Weiping Fu,Yu He,Haiping Zhu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: APOLO是一个用于精神健康领域情感诊断的自动提示优化框架，通过多智能体协作系统探索更精细的提示空间，解决情感共病和临床线索利用不足的问题。


<details>
  <summary>Details</summary>
Motivation: 在临床笔记、咨询对话和在线心理健康社区中，抑郁、焦虑和创伤相关状态的情感表达普遍存在，准确识别这些情感对临床分诊、风险评估和及时干预至关重要。尽管大语言模型在情感分析任务中表现出强大的泛化能力，但在高风险、上下文密集的医疗环境中，其诊断可靠性对提示设计高度敏感。现有方法面临两个关键挑战：情感共病（多种交织情感状态使预测复杂化）和临床相关线索的低效探索。

Method: 提出APOLO框架，将指令优化建模为部分可观测马尔可夫决策过程，采用多智能体协作机制，包括规划器、教师、批评者、学生和目标角色。在闭环框架中，规划器定义优化轨迹，教师-批评者-学生智能体迭代优化提示以增强推理稳定性和有效性，目标智能体根据性能评估决定是否继续优化。

Result: 实验结果表明，APOLO在领域特定和分层基准测试中持续提高了诊断准确性和鲁棒性，展示了在精神健康护理中可信赖大语言模型应用的可扩展和可泛化范式。

Conclusion: APOLO框架通过系统探索更广泛和更精细的提示空间，有效解决了情感共病和临床线索利用不足的挑战，为精神健康领域的大语言模型应用提供了可靠、可扩展的解决方案。

Abstract: Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.

</details>


### [234] [AgenticRed: Optimizing Agentic Systems for Automated Red-teaming](https://arxiv.org/abs/2601.13518)
*Jiayi Yuan,Jonathan Nöther,Natasha Jaques,Goran Radanović*

Main category: cs.AI

TL;DR: AgenticRed是一个利用LLM上下文学习自动设计和优化红队测试系统的框架，无需人工干预，通过进化选择方法在红队测试中显著提升攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有自动化红队测试方法依赖人工设计的工作流程，存在人为偏见且难以探索更广泛的设计空间，需要一种无需人工干预的自动化系统设计方法。

Method: 将红队测试视为系统设计问题，利用LLM的上下文学习能力迭代设计和优化红队系统，采用进化选择方法演化智能体系统，无需预定义结构。

Result: 在Llama-2-7B上达到96%攻击成功率（提升36%），在Llama-3-8B上达到98%；对专有模型具有强迁移性，在GPT-3.5-Turbo和GPT-4o-mini上达到100%成功率，在Claude-Sonnet-3.5上达到60%（提升24%）。

Conclusion: 自动化系统设计是AI安全评估的强大范式，能够跟上快速发展的模型步伐，为红队测试提供了更有效的方法。

Abstract: While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.

</details>


### [235] [Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models](https://arxiv.org/abs/2601.13533)
*Changshuo Zhang*

Main category: cs.AI

TL;DR: EGLR模型通过熵引导的潜在推理机制，在生成式重排序中实现"边推理边推荐"，动态适应列表生成过程中的熵变化，提升推荐精度。


<details>
  <summary>Details</summary>
Motivation: 现有生成式重排序方法难以适应列表生成过程中模型难度的动态熵变化，无法准确捕捉复杂偏好。受语言模型推理能力启发，需要引入推理机制来降低决策过程中的熵。

Method: 提出熵引导潜在推理(EGLR)推荐模型：1) 采用"边推理边推荐"范式，在生成过程中实时推理；2) 使用上下文感知推理令牌和动态温度调整实现熵引导的变长推理；3) 轻量级集成设计，无需复杂独立模块或后处理。

Result: 在两个真实世界数据集上的实验验证了模型有效性，显著优势在于能与现有生成式重排序模型兼容以提升其性能。进一步分析展示了实际部署价值和研究潜力。

Conclusion: EGLR模型通过熵引导的潜在推理机制，成功解决了生成式重排序中动态熵变化的适应问题，实现了更精确的探索-利用权衡，具有良好兼容性和实用价值。

Abstract: Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the "reason first, recommend later" paradigm to achieve "reasoning while recommending", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.

</details>


### [236] [ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution](https://arxiv.org/abs/2601.13546)
*Hui Sun,Chang Xu,Haonan Xie,Hao Li,Yuhao Huang,Chuheng Zhang,Ming Jin,Xiaoguang Liu,Gang Wang,Jiang Bian*

Main category: cs.AI

TL;DR: 该论文提出TSEvol多智能体时间序列演化算法、TSEData-20K数据集、ChatAD系列聊天机器人、TKTO优化方法和LLADBench基准，显著提升了时间序列异常检测的推理能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的时间序列异常检测方法面临推理能力不足、多轮对话能力欠缺和泛化能力狭窄的挑战，需要提升对异常行为的理解和解释能力。

Method: 1) 提出TSEvol多智能体时间序列演化算法；2) 构建TSEData-20K数据集并开发ChatAD系列聊天机器人；3) 提出TKTO优化方法增强跨任务泛化能力；4) 建立LLADBench基准评估框架。

Result: ChatAD模型在准确率上提升达34.50%，F1分数提升34.71%，误报率降低37.42%。通过TKTO优化的ChatAD在分类、预测和填补任务上展现出竞争力的推理和跨任务泛化性能。

Conclusion: 该研究通过多智能体算法、大规模数据集、优化方法和评估基准的综合方案，显著提升了LLM驱动的时间序列异常检测的推理能力、对话能力和跨任务泛化能力。

Abstract: LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.

</details>


### [237] [AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent](https://arxiv.org/abs/2601.13559)
*Sun Hui,Ding Yanfeng,Huidong Ma,Chang Xu,Keyan Jin,Lizheng Zu,Cheng Zhong,xiaoguang Liu,Gang Wang,Wentong Cai*

Main category: cs.AI

TL;DR: AgentGC：首个基于智能体的进化式基因组数据压缩器，通过三层架构（用户层、认知层、压缩层）和多智能体系统（Leader和Worker），结合LLM实现算法-数据集-系统的联合优化，提供三种模式（CP、TP、BM）满足不同场景需求。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的基因组数据压缩方法存在非进化性、低级压缩建模、有限适应性和用户界面不友好等问题，需要一种更智能、可进化、适应性强的压缩解决方案。

Method: 提出AgentGC三层架构：1）用户层通过Leader结合LLM提供友好界面；2）认知层由Leader驱动，整合LLM考虑算法-数据集-系统的联合优化；3）压缩层由Worker负责，通过自动化多知识学习框架执行压缩和解压缩。设计了三种模式：CP（压缩比优先）、TP（吞吐量优先）、BM（平衡模式）。

Result: 在9个数据集上与14个基线方法比较，平均压缩比提升分别为16.66%（CP）、16.11%（TP）、16.33%（BM），吞吐量提升分别为4.73倍、9.23倍、9.15倍。

Conclusion: AgentGC通过智能体架构和LLM集成，有效解决了现有基因组数据压缩方法的局限性，在压缩比和吞吐量方面均取得显著提升，为基因组数据存储、共享和管理提供了更优的解决方案。

Abstract: Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.

</details>


### [238] [Reasoning is a Modality](https://arxiv.org/abs/2601.13562)
*Zhiguang Liu,Yi Shang*

Main category: cs.AI

TL;DR: 本文提出了一种角色分离的Transformer架构，通过将全局控制器token与网格工作空间token分离，实现了迭代规则执行，在ARC视觉推理任务上超越了人类平均表现。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统（如LLMs和ViTs）主要作为行为序列预测机器运行，它们通过建模token统计来匹配可观察行为，但没有持久、可读的思维状态。这与人类行为存在差距：人类可以通过解码内部状态来解释行为，而AI系统只能产生流畅的事后合理化解释，这些解释并不基于这样的内部状态。作者假设推理是一种模态：推理应该作为一个独立的通道存在，与规则应用的低级工作空间分离。

Method: 设计了一种新颖的角色分离Transformer块，将全局控制器token与网格工作空间token分离，实现了迭代规则执行。该方法在VARC视觉中心协议下进行训练和评估，专门用于解决ARC任务作为视觉推理问题。

Result: 在ARC-1任务上达到了62.6%的准确率，超过了人类平均表现（60.2%），并显著优于先前的方法。定性分析显示，与密集的ViT基线相比，该模型展现出更一致的规则应用结构，从概率块向控制器驱动的推理转变。

Conclusion: 通过将推理作为独立模态并实现角色分离的架构设计，成功在抽象推理任务上超越了人类平均表现，验证了推理作为独立通道的假设，为构建更具解释性的AI系统提供了新方向。

Abstract: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.

</details>


### [239] [SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System](https://arxiv.org/abs/2601.13581)
*Heedou Kim,Changsik Kim,Sanghwa Shin,Jaewoo Kang*

Main category: cs.AI

TL;DR: ScriptMind是一个基于LLM的诈骗检测框架，通过犯罪脚本推理任务、数据集构建和认知模拟评估，显著提升了诈骗检测性能并增强了用户认知警觉性。


<details>
  <summary>Details</summary>
Motivation: 传统诈骗检测方法难以应对个性化、多轮对话的社交工程诈骗，而现有LLM在诈骗检测中的认知辅助潜力尚未充分挖掘，需要开发更有效的检测框架。

Method: 提出ScriptMind框架，包含三个组件：犯罪脚本推理任务（CSIT）用于诈骗推理、犯罪脚本感知推理数据集（CSID）用于微调小型LLM、认知模拟评估（CSED）用于评估实时认知影响。基于571个韩国电话诈骗案例构建了22,712个结构化训练实例。

Result: 经过ScriptMind微调的11B小型LLM在检测准确率上比GPT-4o高出13%，在误报减少、诈骗者话语预测和推理质量方面均优于商业模型。在电话诈骗模拟实验中，显著提升并维持了用户的怀疑水平，增强了他们对诈骗的认知警觉性。

Conclusion: ScriptMind代表了向以人为本、认知自适应的LLM诈骗防御系统迈出的一步，展示了LLM在增强人类认知警觉性方面的潜力。

Abstract: Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.

</details>


### [240] [Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification](https://arxiv.org/abs/2601.13589)
*HyeYoung Lee*

Main category: cs.AI

TL;DR: 提出一个基于音频情感信号实时生成响应式媒体内容的多智能体AI系统，通过四个协作智能体将情感识别转化为安全、可控的响应内容，并包含显式安全验证循环确保合规性。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别研究主要关注分类准确性，但缺乏将推断出的情感状态转化为安全、适龄、可控的响应内容的能力。需要一种能够实时生成响应式媒体内容并确保安全合规的系统。

Method: 采用多智能体架构，包含四个协作智能体：1) 基于CNN的情感识别智能体进行声学特征提取；2) 响应策略决策智能体将情感映射到响应模式；3) 内容参数生成智能体产生媒体控制参数；4) 安全验证智能体强制执行适龄性和刺激约束。系统包含显式安全验证循环在输出前过滤生成内容。

Result: 在公共数据集上的实验结果显示：情感识别准确率73.2%，响应模式一致性89.4%，安全合规性100%，推理延迟低于100ms，适合设备端部署。模块化架构提供了可解释性和可扩展性。

Conclusion: 该系统成功地将情感识别转化为安全可控的响应式媒体内容，适用于儿童相关媒体、治疗应用和情感响应智能设备。显式安全验证机制确保了内容的适龄性和安全性，模块化设计便于扩展和解释。

Abstract: This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.

</details>


### [241] [Foundations of Global Consistency Checking with Noisy LLM Oracles](https://arxiv.org/abs/2601.13600)
*Paul He,Elke Kirschbaum,Shiva Kasiviswanathan*

Main category: cs.AI

TL;DR: 提出一种自适应分治算法，使用LLM作为评估器来检测和定位自然语言事实集合中的全局不一致性，解决LLM判断噪声大且成对检查无法保证全局一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 自然语言事实集合的全局一致性对于事实核查、摘要生成和知识库构建等任务至关重要。虽然大语言模型可以评估小规模事实子集的一致性，但其判断存在噪声，且成对检查无法保证全局一致性。验证全局一致性在最坏情况下需要指数级查询次数。

Method: 提出自适应分治算法，识别最小不一致子集(MUSes)，可选地通过命中集计算最小修复。该方法具有低阶多项式查询复杂度，使用LLM作为评估器进行语言一致性验证。

Result: 在合成和真实LLM评估器上的实验表明，该方法能有效检测和定位不一致性，为基于LLM的评估器提供了可扩展的语言一致性验证框架。

Conclusion: 该研究为解决自然语言事实集合的全局一致性验证问题提供了实用的解决方案，通过自适应分治算法在多项式查询复杂度内实现高效的不一致性检测和定位。

Abstract: Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.

</details>


### [242] [Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue](https://arxiv.org/abs/2601.13687)
*Zhichao Liang,Satoshi Nakamura*

Main category: cs.AI

TL;DR: SocialMindChange是一个新的动态心理理论基准测试，要求语言模型在社交互动中主动改变他人心理状态，而不仅仅是追踪心理状态，测试显示当前LLM表现比人类低54.2%


<details>
  <summary>Details</summary>
Motivation: 现有动态心理理论基准测试主要让语言模型处于被动角色，只追踪心理状态变化。但在真实社交互动中，心理理论也被用于主动行动——说话者计划说什么来改变他人的心理状态轨迹。需要从追踪心理状态转向改变心理状态的基准测试。

Method: 提出SocialMindChange基准测试，每个实例定义包含4个角色的社交情境和5个连接场景。模型扮演其中一个角色，在5个场景中生成对话以达到目标，同时保持与所有参与者不断变化的状态一致。使用结构化四步框架构建了1,200个社交情境，覆盖6,000个场景和超过90,000个问题，每个都经过真实性和质量验证。

Result: 对10个最先进的LLM进行评估，结果显示它们的平均性能比人类表现低54.2%。这个差距表明当前LLM在长期连接互动中维持和改变心理状态表征方面仍然存在困难。

Conclusion: SocialMindChange基准测试从被动追踪心理状态转向主动改变心理状态，揭示了当前LLM在动态社交互动中理解和操纵心理状态的能力仍有显著不足，为未来研究提供了重要方向。

Abstract: Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.

</details>


### [243] [Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection](https://arxiv.org/abs/2601.13735)
*Hojin Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: 研究发现当前基于概率的置信度指标无法有效捕捉推理步骤间的因果依赖关系，主要反映的是表面流畅性或分布先验，而非逻辑结构。


<details>
  <summary>Details</summary>
Motivation: 挑战当前广泛采用的假设：在Best-of-N选择中，更高的概率置信度反映了更高的推理质量。研究者质疑这些指标是否真正捕捉到了有效推理所需的步骤间因果依赖关系。

Method: 引入三类步骤间因果关系扰动，系统性地破坏推理步骤间的依赖关系，同时保持局部流畅性。使用硬注意力掩码等严重干预措施，防止模型关注先前的推理步骤。最后提出对比因果度量方法，明确隔离步骤间因果依赖。

Result: 令人惊讶的是，在不同模型家族和推理基准测试中，即使严重破坏步骤间依赖关系，选择准确率仅轻微下降。硬注意力掩码等干预措施并未显著降低选择性能，表明当前概率指标对逻辑结构不敏感。

Conclusion: 当前概率置信度指标主要捕捉表面流畅性或分布先验，而非逻辑结构。提出的对比因果度量方法能更忠实地进行输出选择，为解决这一缺陷提供了方向。

Abstract: Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.

</details>


### [244] [Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering](https://arxiv.org/abs/2601.13752)
*Chak Tou Leong,Dingwei Chen,Heming Xia,Qingyu Yin,Sunbowen Lee,Jian Wang,Wenjie Li*

Main category: cs.AI

TL;DR: RELIEF框架通过调整大型推理模型的自我认知信念来塑造其行为，无需监督推理轨迹，降低了训练成本


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂问题解决中表现出色，但存在计算冗余和推理不忠实的问题。现有方法依赖强化学习或黄金标准推理轨迹的微调，计算成本高且难以扩展。

Method: 提出RELIEF框架，通过简单的logit探测捕获模型的潜在推理信念，然后通过微调合成的自我反思问答对来将模型的自我认知与目标信念蓝图对齐。

Result: 在效率和忠实性任务上的广泛实验表明，RELIEF匹配或优于基于行为监督和偏好的基线方法，同时需要更低的训练成本。进一步分析验证了改变模型的推理信念能有效塑造其实际行为。

Conclusion: RELIEF通过信念工程有效塑造大型推理模型的行为，无需推理轨迹监督，为模型行为塑造提供了一种计算高效且可扩展的替代方案。

Abstract: Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.

</details>


### [245] [DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution](https://arxiv.org/abs/2601.13761)
*Shengda Fan,Xuyan Ye,Yankai Lin*

Main category: cs.AI

TL;DR: DARC是一个两阶段自演化解耦框架，通过难度校准的问题生成和不对称自蒸馏机制，解决了自演化的优化不稳定问题，在多个推理基准上平均提升10.9分。


<details>
  <summary>Details</summary>
Motivation: 现有自演化框架存在优化不稳定问题：1)提问者依赖于求解器反馈的非平稳目标；2)求解器使用自生成伪标签带来的自举误差。需要稳定自演化过程。

Method: DARC采用两阶段解耦框架：第一阶段训练提问者基于显式难度级别和外部语料合成难度校准的问题；第二阶段通过不对称自蒸馏机制训练求解器，使用文档增强的教师模型生成高质量伪标签来监督无文档访问的学生求解器。

Result: DARC具有模型无关性，在九个推理基准和三个骨干模型上平均提升10.9分，持续优于所有基线方法，且无需人工标注就能接近全监督模型的性能。

Conclusion: DARC通过解耦的不对称推理课程有效稳定了自演化过程，在多个推理任务上取得了显著性能提升，为自改进人工智能提供了有前景的解决方案。

Abstract: Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.

</details>


### [246] [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770)
*Mostapha Benhenda*

Main category: cs.AI

TL;DR: 提出Look-Ahead-Bench基准测试，用于评估金融工作流中Point-in-Time大语言模型的超前偏差，通过实际场景测试而非简单的问答，发现标准LLMs存在显著超前偏差，而Pitinf模型随规模增大展现更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过问答测试LLMs的内部超前知识，缺乏对实际金融工作流中模型行为的评估。需要区分真正的预测能力与基于记忆的表现，建立标准化基准来衡量金融LLMs中的时间偏差。

Method: 创建Look-Ahead-Bench基准测试，分析模型在不同时间市场机制下的性能衰减，引入多个量化基线建立性能阈值。评估开源LLMs（Llama 3.1和DeepSeek 3.2）与PiT-Inference的Point-in-Time LLMs（Pitinf-Small、Pitinf-Medium、Pitinf-Large）。

Result: 标准LLMs显示出显著的超前偏差（通过alpha衰减衡量），而Pitinf模型随着规模增大展现出改进的泛化和推理能力。Pitinf模型在时间偏差方面表现更好，适合实际部署。

Conclusion: 该工作为金融LLMs中时间偏差的标准化评估奠定了基础，提供了识别适合实际部署模型的实用框架。代码已在GitHub上开源。

Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench

</details>


### [247] [Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems](https://arxiv.org/abs/2601.13887)
*Hong Su*

Main category: cs.AI

TL;DR: 本文提出人类模拟计算（HSC）框架，通过模拟人类的思维、行动、学习、反思和活动调度等闭环过程，解决LLMs仅依赖文本数据在开放动态环境中适应性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然展现了强大的知识表示和推理能力，但仅依赖语言材料的局限性使其难以适应、验证推理结果，并在开放动态的真实环境中有效运作。

Method: 提出人类模拟计算（HSC）框架，将智能建模为包含思维、行动、学习、反思和活动调度的连续闭环过程。强调在内部推理过程和与环境交互中的主动参与，利用行动不仅实现目标，还能自动优化内部推理机制。同时整合人类常用思维策略，如主特征导向推理、通过行动扩展范围、环境反馈驱动的及时学习等。

Result: 通过理论分析论证，人类模拟策略无法仅从语言材料中完全习得，人类式推理过程和基于行动的推理方法对于在真实环境中实现稳健适应和有效交互至关重要。

Conclusion: HSC框架为解决LLMs在开放动态环境中的局限性提供了新思路，强调主动参与、闭环学习和基于行动的推理优化是实现更强大、适应性更强的智能系统的关键。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.

</details>


### [248] [PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation](https://arxiv.org/abs/2601.13904)
*Jaeyoung Moon,Youjin Choi,Yucheon Park,David Melhart,Georgios N. Yannakakis,Kyung-Joong Kim*

Main category: cs.AI

TL;DR: PREFAB是一种低成本的回顾式自我标注方法，通过检测情感变化区域而非完整标注来减轻标注负担，同时保持标注质量。


<details>
  <summary>Details</summary>
Motivation: 现有情感状态标注方法通常需要用户在整个会话期间连续标注，虽然能获得细粒度数据，但过程耗时、认知负担重，容易产生疲劳和错误。

Method: 基于峰终法则和情感序数表示，PREFAB采用偏好学习模型检测相对情感变化，指导标注者仅标注选定片段，其余部分通过插值完成。还引入了预览机制提供上下文线索辅助标注。

Result: 技术性能研究和25名参与者的用户研究表明，PREFAB在建模情感变化方面优于基线方法，减轻了工作负担（有条件地减轻时间负担），提高了标注者信心且未降低标注质量。

Conclusion: PREFAB提供了一种有效的低预算情感状态标注方法，通过聚焦情感变化区域而非完整标注，在减轻标注负担的同时保持了标注质量。

Abstract: Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.

</details>


### [249] [Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics](https://arxiv.org/abs/2601.14027)
*Junqi Liu,Zihao Zhou,Zekai Zhu,Marco Dos Santos,Weikun He,Jiawei Liu,Ran Wang,Yunzhou Xie,Junqiao Zhao,Qiufeng Wang,Lihong Zhi,Jia Li,Wenda Li*

Main category: cs.AI

TL;DR: 提出使用通用编码智能体作为形式数学推理器的新范式，通过Numina-Lean-Agent系统在Putnam 2025竞赛中取得满分，并成功形式化Brascamp-Lieb定理。


<details>
  <summary>Details</summary>
Motivation: 现有智能体系统通常依赖特定任务流程和训练的形式证明器，限制了灵活性和可复现性。通用编码智能体能提供超越证明的多样化推理任务接口，仅通过替换基础模型即可提升性能，且MCP支持灵活扩展和自主调用专业工具。

Method: 提出直接使用通用编码智能体作为形式数学推理器的新范式。具体实现Numina-Lean-Agent系统，结合Claude Code与Numina-Lean-MCP，实现与Lean的自主交互、相关定理检索、非形式化证明和辅助推理工具调用。

Result: 使用Claude Opus 4.5作为基础模型，Numina-Lean-Agent在Putnam 2025竞赛中解决了所有12个问题（12/12），与最佳闭源系统表现相当。此外，通过与数学家互动成功形式化了Brascamp-Lieb定理，展示了系统的通用性。

Conclusion: 通用编码智能体作为形式数学推理器的新范式具有显著优势，Numina-Lean-Agent系统在竞赛和实际数学形式化任务中都表现出色，为形式证明领域提供了更灵活、可扩展的解决方案。

Abstract: Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.

</details>


### [250] [Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance](https://arxiv.org/abs/2601.14171)
*Qianli Ma,Chang Guo,Zhiheng Tian,Siyu Wang,Jipeng Xiao,Yuanhao Yue,Zhipeng Zhang*

Main category: cs.AI

TL;DR: RebuttalAgent是一个多智能体框架，将反驳信生成重构为以证据为中心的规划任务，通过分解审稿意见、构建混合上下文、集成外部搜索来确保每个论点都有明确证据支撑。


<details>
  <summary>Details</summary>
Motivation: 当前的反驳信生成方法通常将其视为直接文本生成问题，存在幻觉、忽视批评意见、缺乏可验证基础等问题。需要一种更透明、可控且能确保论点有证据支撑的方法来改进同行评审过程。

Method: 引入RebuttalAgent多智能体框架，将复杂反馈分解为原子关注点，动态构建混合上下文（结合压缩摘要和高保真文本），集成自主按需外部搜索模块，并在起草前生成可检查的响应计划。

Result: 在提出的RebuttalBench上验证，RebuttalAgent在覆盖率、忠实度和战略连贯性方面优于强基线，为同行评审过程提供了透明可控的助手。

Conclusion: RebuttalAgent通过将反驳信生成重构为证据中心的规划任务，解决了现有方法的局限性，提供了更可靠、透明和可控的同行评审辅助工具。

Abstract: Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.

</details>


### [251] [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/abs/2601.14192)
*Xiaofang Yang,Lijun Li,Heng Zhou,Tong Zhu,Xiaoye Qu,Yuchen Fan,Qianshan Wei,Rui Ye,Li Kang,Yiran Qin,Zhiqiang Kou,Daizong Liu,Qi Li,Ning Ding,Siheng Chen,Jing Shao*

Main category: cs.AI

TL;DR: 该论文综述了大型语言模型智能体系统的效率问题，从内存、工具学习和规划三个核心组件出发，分析效率优化方法，并提出了效率评估框架和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型向智能体系统扩展，现有研究主要关注有效性而忽视了效率问题，而效率对于实际部署至关重要。论文旨在填补这一研究空白，系统性地探讨智能体系统的效率优化。

Method: 论文从智能体的三个核心组件（内存、工具学习、规划）出发，综述了多种效率优化方法，包括上下文压缩管理、设计强化学习奖励以减少工具调用、采用受控搜索机制等。同时提出了两种互补的效率评估方式：固定成本预算下的有效性比较，以及相似有效性水平下的成本比较。

Result: 论文系统性地总结了智能体效率优化的共同原则，建立了效率评估框架，整理了相关基准测试的评估协议和常用效率指标，并分析了效率与有效性之间的帕累托前沿关系。

Conclusion: 智能体系统的效率研究是一个重要但被忽视的领域，需要从多个维度进行优化。论文为未来研究提供了系统性的分析框架和方向，有助于推动高效智能体系统的实际部署。

Abstract: Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [252] [Utilizing Metadata for Better Retrieval-Augmented Generation](https://arxiv.org/abs/2601.11863)
*Raquib Bin Yousuf,Shengzhe Xu,Mandar Sharma,Andrew Neeser,Chris Latimer,Naren Ramakrishnan*

Main category: cs.IR

TL;DR: 该论文系统研究了在结构化重复语料库中，元数据感知检索策略如何提升RAG系统的检索效果，发现前缀法和统一嵌入方法优于纯文本基线。


<details>
  <summary>Details</summary>
Motivation: 在结构化重复语料库（如监管文件）中，仅依赖块相似性难以区分语言重叠的文档。实践中常将元数据扁平化为文本输入，但这种做法的影响和权衡尚未得到充分理解。

Method: 系统比较了多种元数据感知检索策略：元数据作为文本（前缀和后缀）、融合元数据和内容的统一嵌入双编码器、双编码器后期融合检索、以及元数据感知查询重构。使用RAGMATE-10K数据集进行多指标评估。

Result: 前缀法和统一嵌入方法在多个检索指标和问题类型上一致优于纯文本基线。统一嵌入有时甚至超过前缀法，且更易于维护。元数据集成通过增加文档内聚性、减少文档间混淆、扩大相关与不相关块之间的分离来提高检索效果。

Conclusion: 元数据感知检索策略能显著提升结构化重复语料库中的检索性能，特别是前缀法和统一嵌入方法效果最佳。结构线索提供强大的消歧信号，元数据集成改善了嵌入空间的组织结构。

Abstract: Retrieval-Augmented Generation systems depend on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, we find that prefixing and unified embeddings consistently outperform plain-text baselines, with the unified at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.

</details>


### [253] [Cultural Analytics for Good: Building Inclusive Evaluation Frameworks for Historical IR](https://arxiv.org/abs/2601.11874)
*Suchana Datta,Dwaipayan Roy,Derek Greene,Gerardine Meaney,Karen Wade,Philipp Mayr*

Main category: cs.IR

TL;DR: 该研究构建了一个结合信息检索与文化分析的跨学科框架，使用英国图书馆BL19数字馆藏（1700-1899年间的3.5万部作品）创建基准，研究19世纪小说与非小说中语言、术语和检索的变化，重点关注从小说到非小说的知识迁移。


<details>
  <summary>Details</summary>
Motivation: 旨在支持历史知识的公平获取，通过跨学科方法改善数字档案的可访问性，促进文化包容性和解放性知识基础设施建设。

Method: 结合专家驱动的查询设计、段落级相关性标注和大型语言模型辅助，创建基于人类专业知识的可扩展评估框架，研究小说中的叙事理解和语义丰富性如何改善学术和事实材料的检索。

Result: 开发了实用的评估资源和检索系统开发的方法论范式，不仅提高了检索准确性，还促进了数字档案的可解释性、透明度和文化包容性。

Conclusion: 该研究为开发支持更丰富、更具历史意识的数字档案参与的检索系统提供了框架，最终朝着更解放性的知识基础设施方向努力，促进了历史知识的公平获取和跨学科研究。

Abstract: This work bridges the fields of information retrieval and cultural analytics to support equitable access to historical knowledge. Using the British Library BL19 digital collection (more than 35,000 works from 1700-1899), we construct a benchmark for studying changes in language, terminology and retrieval in the 19th-century fiction and non-fiction. Our approach combines expert-driven query design, paragraph-level relevance annotation, and Large Language Model (LLM) assistance to create a scalable evaluation framework grounded in human expertise. We focus on knowledge transfer from fiction to non-fiction, investigating how narrative understanding and semantic richness in fiction can improve retrieval for scholarly and factual materials. This interdisciplinary framework not only improves retrieval accuracy but also fosters interpretability, transparency, and cultural inclusivity in digital archives. Our work provides both practical evaluation resources and a methodological paradigm for developing retrieval systems that support richer, historically aware engagement with digital archives, ultimately working towards more emancipatory knowledge infrastructures.

</details>


### [254] [Agentic-R: Learning to Retrieve for Agentic Search](https://arxiv.org/abs/2601.11888)
*Wenhan Liu,Xinyu Ma,Yutao Zhu,Yuchen Li,Daiting Shi,Dawei Yin,Zhicheng Dou*

Main category: cs.IR

TL;DR: 本文提出了一种专门为智能体搜索设计的检索器训练框架，通过结合局部查询-段落相关性和全局答案正确性来衡量段落效用，并采用迭代训练策略双向优化搜索智能体和检索器。


<details>
  <summary>Details</summary>
Motivation: 当前智能体搜索主要依赖基于相似性的检索器，但相似段落并不总是对最终答案生成有用。现有检索器设计主要针对单轮检索增强生成(RAG)，而智能体搜索需要多轮交互，因此需要专门针对智能体搜索场景设计检索器训练框架。

Method: 提出了一种新颖的检索器训练框架：1) 使用局部查询-段落相关性和全局答案正确性双重标准来衡量多轮智能体搜索中的段落效用；2) 采用迭代训练策略，让搜索智能体和检索器双向迭代优化；3) 不同于RAG检索器使用固定问题训练一次，本方法使用智能体生成的演化且更高质量的查询持续改进检索器。

Result: 在七个单跳和多跳问答基准测试上的广泛实验表明，提出的检索器(命名为Agentic-R)在不同搜索智能体上始终优于强基线方法。

Conclusion: 本文提出的专门针对智能体搜索的检索器训练框架有效解决了现有相似性检索器的局限性，通过结合局部和全局效用评估以及迭代优化策略，显著提升了智能体搜索的性能。

Abstract: Agentic search has recently emerged as a powerful paradigm, where an agent interleaves multi-step reasoning with on-demand retrieval to solve complex questions. Despite its success, how to design a retriever for agentic search remains largely underexplored. Existing search agents typically rely on similarity-based retrievers, while similar passages are not always useful for final answer generation. In this paper, we propose a novel retriever training framework tailored for agentic search. Unlike retrievers designed for single-turn retrieval-augmented generation (RAG) that only rely on local passage utility, we propose to use both local query-passage relevance and global answer correctness to measure passage utility in a multi-turn agentic search. We further introduce an iterative training strategy, where the search agent and the retriever are optimized bidirectionally and iteratively. Different from RAG retrievers that are only trained once with fixed questions, our retriever is continuously improved using evolving and higher-quality queries from the agent. Extensive experiments on seven single-hop and multi-hop QA benchmarks demonstrate that our retriever, termed \ours{}, consistently outperforms strong baselines across different search agents. Our codes are available at: https://github.com/8421BCD/Agentic-R.

</details>


### [255] [Information Farming: From Berry Picking to Berry Growing](https://arxiv.org/abs/2601.12544)
*Leif Azzopardi,Adam Roegiest*

Main category: cs.IR

TL;DR: 论文提出"信息耕作"概念，类比新石器时代革命，认为生成式AI正在改变人们与信息互动的方式，从传统的"信息觅食"转向"信息耕作"。


<details>
  <summary>Details</summary>
Motivation: 传统的信息觅食理论和浆果采摘范式已无法完全捕捉生成式AI带来的根本性变革。生成式技术正在改变人们生产、组织和重用信息的方式，需要新的概念框架来理解这一转变。

Method: 采用历史类比方法，将生成式AI带来的变革比作新石器时代从狩猎采集到农业耕作的转变。通过概念框架构建和实证证据分析，提出"信息耕作"作为新的理论框架。

Result: 提出了"信息耕作"的概念框架，认为用户可以通过提示作为种子，培育工作流程，在自己的"地块"中收获结构化、相关的信息产出，而不是在他人的"地块"中觅食。

Conclusion: 随着生成式AI技术的普及，信息耕作将逐渐取代短暂、碎片化的信息觅食，成为主导的互动模式，标志着人机信息交互及其研究的更广泛转变，同时带来了设计、评估和风险方面的新挑战。

Abstract: The classic paradigms of Berry Picking and Information Foraging Theory have framed users as gatherers, opportunistically searching across distributed sources to satisfy evolving information needs. However, the rise of GenAI is driving a fundamental transformation in how people produce, structure, and reuse information - one that these paradigms no longer fully capture. This transformation is analogous to the Neolithic Revolution, when societies shifted from hunting and gathering to cultivation. Generative technologies empower users to "farm" information by planting seeds in the form of prompts, cultivating workflows over time, and harvesting richly structured, relevant yields within their own plots, rather than foraging across others people's patches. In this perspectives paper, we introduce the notion of Information Farming as a conceptual framework and argue that it represents a natural evolution in how people engage with information. Drawing on historical analogy and empirical evidence, we examine the benefits and opportunities of information farming, its implications for design and evaluation, and the accompanying risks posed by this transition. We hypothesize that as GenAI technologies proliferate, cultivating information will increasingly supplant transient, patch-based foraging as a dominant mode of engagement, marking a broader shift in human-information interaction and its study.

</details>


### [256] [The Unfairness of Multifactorial Bias in Recommendation](https://arxiv.org/abs/2601.12828)
*Masoud Mansoury,Jin Huang,Mykola Pechenizkiy,Herke van Hoof,Maarten de Rijke*

Main category: cs.IR

TL;DR: 该论文研究了推荐系统中的多因素偏见（流行度偏见和积极性偏见的组合效应），发现积极性偏见主要集中在流行物品上，加剧了曝光不公平。作者提出了一种基于百分位数的评分转换预处理方法，实验证明该方法能有效改善曝光公平性且几乎不影响推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中存在流行度偏见和积极性偏见两种主要偏见来源，它们都源于输入数据并通过推荐模型传播，导致不公平或次优结果。虽然每种偏见都被独立研究过，但它们的组合效应（多因素偏见）仍未得到充分探索。本研究旨在探究多因素偏见如何影响物品侧公平性，特别是曝光偏见。

Method: 通过模拟研究分析多因素偏见的影响，发现积极性偏见主要集中在流行物品上。为此，作者采用基于百分位数的评分转换作为预处理策略来缓解多因素偏见。在四个公共数据集上使用六种推荐算法进行实验，并将该预处理步骤集成到后处理公平性流程中。

Result: 实验结果表明，基于百分位数的评分转换预处理方法能有效改善曝光公平性，同时推荐准确性的损失可以忽略不计。将该预处理步骤集成到后处理公平性流程中，能提高其效果和效率，以更低的计算成本实现相当或更好的公平性。

Conclusion: 研究强调了解决多因素偏见的重要性，并展示了简单、数据驱动的预处理方法在改善推荐系统公平性方面的实用价值。积极性偏见在流行物品上的集中加剧了曝光不公平，而提出的预处理方法能有效缓解这一问题。

Abstract: Popularity bias and positivity bias are two prominent sources of bias in recommender systems. Both arise from input data, propagate through recommendation models, and lead to unfair or suboptimal outcomes. Popularity bias occurs when a small subset of items receives most interactions, while positivity bias stems from the over-representation of high rating values. Although each bias has been studied independently, their combined effect, to which we refer to as multifactorial bias, remains underexplored. In this work, we examine how multifactorial bias influences item-side fairness, focusing on exposure bias, which reflects the unequal visibility of items in recommendation outputs. Through simulation studies, we find that positivity bias is disproportionately concentrated on popular items, further amplifying their over-exposure. Motivated by this insight, we adapt a percentile-based rating transformation as a pre-processing strategy to mitigate multifactorial bias. Experiments using six recommendation algorithms across four public datasets show that this approach improves exposure fairness with negligible accuracy loss. We also demonstrate that integrating this pre-processing step into post-processing fairness pipelines enhances their effectiveness and efficiency, enabling comparable or better fairness with reduced computational cost. These findings highlight the importance of addressing multifactorial bias and demonstrate the practical value of simple, data-driven pre-processing methods for improving fairness in recommender systems.

</details>


### [257] [Rules, Resources, and Restrictions: A Taxonomy of Task-Based Information Request Intents](https://arxiv.org/abs/2601.12985)
*Melanie A. Kilian,David Elsweiler*

Main category: cs.IR

TL;DR: 该论文提出基于任务视角的查询意图分类法，以弥补传统查询意图分类与AI驱动任务导向搜索需求之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有查询意图分类主要基于系统日志数据，关注孤立的信息需求，而忽略了更广泛的任务背景。随着用户对LLMs的期望从简单查询转向全面任务支持，传统意图分类方法已无法满足AI驱动任务导向搜索的需求。

Method: 采用扎根理论基础的访谈研究，采访机场信息台工作人员，分析真实任务场景中的信息请求模式，构建任务导向的查询意图分类法。

Result: 提出了一个任务导向的信息请求意图分类法，能够更好地连接传统查询导向方法与AI驱动任务导向搜索的新需求。

Conclusion: 需要更强的任务视角来理解查询意图，以支持LLMs更好地处理复杂多面任务，提升检索效果和任务支持能力。

Abstract: Understanding and classifying query intents can improve retrieval effectiveness by helping align search results with the motivations behind user queries. However, existing intent taxonomies are typically derived from system log data and capture mostly isolated information needs, while the broader task context often remains unaddressed. This limitation becomes increasingly relevant as interactions with Large Language Models (LLMs) expand user expectations from simple query answering toward comprehensive task support, for example, with purchasing decisions or in travel planning. At the same time, current LLMs still struggle to fully interpret complex and multifaceted tasks. To address this gap, we argue for a stronger task-based perspective on query intent. Drawing on a grounded-theory-based interview study with airport information clerks, we present a taxonomy of task-based information request intents that bridges the gap between traditional query-focused approaches and the emerging demands of AI-driven task-oriented search.

</details>


### [258] [Incorporating Q&A Nuggets into Retrieval-Augmented Generation](https://arxiv.org/abs/2601.13222)
*Laura Dietz,Bryan Li,Gabrielle Liu,Jia-Huei Ju,Eugene Yang,Dawn Lawrie,William Walden,James Mayfield*

Main category: cs.IR

TL;DR: RAGE系统将自动评估(E)思想融入检索增强生成(RAG)，提出了Crucible系统，通过构建问答块库来保持明确的引用来源，在TREC NeuCLIR 2024上显著优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 将自动评估思想整合到检索增强生成中，解决传统RAG系统中引用来源不明确、信息重复以及缺乏可解释性的问题。

Method: 提出Crucible系统，从检索文档构建问答块库，使用这些块来指导提取、选择和报告生成，通过清晰的问答语义避免信息重复，并在整个生成过程中保持引用来源。

Result: 在TREC NeuCLIR 2024集合上评估，Crucible系统在块召回率、密度和引用基础方面显著优于最近的基于块的RAG系统Ginger。

Conclusion: RAGE系统通过整合自动评估思想，特别是Crucible系统的问答块方法，能够有效解决RAG中的引用来源和可解释性问题，在多个指标上优于现有方法。

Abstract: RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). As one such example, we present Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics - instead of opaque cluster abstractions - while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NeuCLIR 2024 collection, our Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.

</details>


### [259] [Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?](https://arxiv.org/abs/2601.13227)
*Laura Dietz,Bryan Li,Eugene Yang,Dawn Lawrie,William Walden,James Mayfield*

Main category: cs.IR

TL;DR: 论文指出RAG系统使用LLM评估存在循环风险，通过实验证明当评估要素泄露时，系统可通过优化输出获得接近完美的评估分数，强调盲评估和方法多样性的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统越来越多地使用LLM评估进行优化，这种评估方式已成为主导范式。虽然这种集成可以带来真正的改进，但也存在循环性导致测量错误的风险。论文旨在研究这种风险。

Method: 通过比较实验，使用基于nugget的RAG系统（如Ginger和Crucible）与强基线（如GPT-Researcher）进行对比。特意修改Crucible以生成针对LLM评估优化的输出，研究当评估要素（如提示模板或黄金nuggets）泄露或可预测时的效果。

Result: 实验表明，当评估要素泄露时，系统可以通过优化输出获得接近完美的评估分数。这揭示了当前评估方法存在的严重漏洞，可能导致将指标过拟合误认为是真正的系统进步。

Conclusion: 研究强调了盲评估设置和方法多样性的重要性，以防止将指标过拟合误认为是真正的系统进展。需要更严格的评估方法来确保RAG系统的真实改进。

Abstract: RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches in particular are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. In this paper, we investigate this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GPT-Researcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, we show that near-perfect evaluation scores can be achieved when elements of the evaluation - such as prompt templates or gold nuggets - are leaked or can be predicted. Our results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.

</details>


### [260] [Guidelines for the Creation of an Annotated Corpus](https://arxiv.org/abs/2601.13353)
*Bahdja Boudoua,Nadia Guiffant,Mathieu Roche,Maguelonne Teisseire,Annelise Tran*

Main category: cs.IR

TL;DR: 本文提出了一套创建文本标注指南和标注语料库的通用方法论，涵盖方法论、数据存储、共享和利用等方面，为不同研究场景下的语料库创建和使用提供全面框架。


<details>
  <summary>Details</summary>
Motivation: 基于UMR TETIS成员的反馈和科学文献，需要一套系统的方法论来指导文本标注指南和标注语料库的创建，以支持各种研究场景下的语料库开发和使用。

Method: 提供通用的方法论框架，包括定义和示例来清晰说明每个步骤，涵盖标注指南创建、语料库构建、数据存储、共享和利用等完整流程。

Result: 开发了一套全面的方法论框架，能够指导研究人员创建高质量的文本标注指南和标注语料库，支持不同研究领域的语料库开发需求。

Conclusion: 该文档提供了一个完整的框架来支持文本标注指南和标注语料库的创建与使用，有助于提高语料库的质量和可重用性，促进研究数据的有效管理和利用。

Abstract: This document, based on feedback from UMR TETIS members and the scientific literature, provides a generic methodology for creating annotation guidelines and annotated textual datasets (corpora). It covers methodological aspects, as well as storage, sharing, and valorization of the data. It includes definitions and examples to clearly illustrate each step of the process, thus providing a comprehensive framework to support the creation and use of corpora in various research contexts.

</details>


### [261] [Integrating Vision-Centric Text Understanding for Conversational Recommender Systems](https://arxiv.org/abs/2601.13505)
*Wei Yuan,Shutong Qiao,Tong Chen,Quoc Viet Hung Nguyen,Zi Huang,Hongzhi Yin*

Main category: cs.IR

TL;DR: STARCRS是一个结合屏幕阅读和LLM文本处理的双路径对话推荐系统，通过视觉化编码和精细推理提升推荐准确性和响应质量。


<details>
  <summary>Details</summary>
Motivation: 对话推荐系统通过多轮对话推断用户偏好时，扩展上下文（如实体信息、相关对话）虽然有助于偏好建模，但会导致输入更长、更异构，引发输入长度限制、文本风格不一致、无关噪声等问题，需要更强的语言理解能力。

Method: 提出STARCRS系统，包含两个互补的文本理解模式：1) 屏幕阅读路径，将辅助文本信息编码为视觉标记，模拟屏幕浏览；2) 基于LLM的文本路径，专注于有限关键内容进行细粒度推理。设计了知识锚定融合框架，结合对比对齐、交叉注意力交互和自适应门控来整合两种模式。

Result: 在两个广泛使用的基准测试上进行大量实验，证明STARCRS在推荐准确性和生成响应质量方面都有持续改进。

Conclusion: STARCRS通过整合屏幕阅读和LLM文本处理两种互补模式，有效解决了对话推荐系统中上下文扩展带来的实际问题，提升了偏好建模和响应生成能力。

Abstract: Conversational Recommender Systems (CRSs) have attracted growing attention for their ability to deliver personalized recommendations through natural language interactions. To more accurately infer user preferences from multi-turn conversations, recent works increasingly expand conversational context (e.g., by incorporating diverse entity information or retrieving related dialogues). While such context enrichment can assist preference modeling, it also introduces longer and more heterogeneous inputs, leading to practical issues such as input length constraints, text style inconsistency, and irrelevant textual noise, thereby raising the demand for stronger language understanding ability. In this paper, we propose STARCRS, a Screen-Text-AwaRe Conversational Recommender System that integrates two complementary text understanding modes: (1) a screen-reading pathway that encodes auxiliary textual information as visual tokens, mimicking skim reading on a screen, and (2) an LLM-based textual pathway that focuses on a limited set of critical content for fine-grained reasoning. We design a knowledge-anchored fusion framework that combines contrastive alignment, cross-attention interaction, and adaptive gating to integrate the two modes for improved preference modeling and response generation. Extensive experiments on two widely used benchmarks demonstrate that STARCRS consistently improves both recommendation accuracy and generated response quality.

</details>


### [262] [More Than Efficiency: Embedding Compression Improves Domain Adaptation in Dense Retrieval](https://arxiv.org/abs/2601.13525)
*Chunsheng Zuo,Daniel Khashabi*

Main category: cs.IR

TL;DR: PCA降维应用于查询嵌入，无需标注数据即可提升专业领域检索性能


<details>
  <summary>Details</summary>
Motivation: 密集检索器在专业领域表现不佳，因为预训练嵌入与目标领域分布不匹配。传统领域适应方法需要昂贵的标注数据和重新训练。

Method: 对领域嵌入应用PCA降维，保留领域相关特征，丢弃非判别性成分。仅对查询嵌入进行PCA压缩，无需重新训练检索器。

Result: 在9个检索器和14个MTEB数据集上评估，75.4%的模型-数据集组合中NDCG@10得到提升。提供了一种简单轻量的领域适应方法。

Conclusion: PCA嵌入压缩作为被忽视的替代方案，能够有效提升专业领域检索性能，无需标注数据或重新训练，为领域适应提供了简单实用的解决方案。

Abstract: Dense retrievers powered by pretrained embeddings are widely used for document retrieval but struggle in specialized domains due to the mismatches between the training and target domain distributions. Domain adaptation typically requires costly annotation and retraining of query-document pairs. In this work, we revisit an overlooked alternative: applying PCA to domain embeddings to derive lower-dimensional representations that preserve domain-relevant features while discarding non-discriminative components. Though traditionally used for efficiency, we demonstrate that this simple embedding compression can effectively improve retrieval performance. Evaluated across 9 retrievers and 14 MTEB datasets, PCA applied solely to query embeddings improves NDCG@10 in 75.4% of model-dataset pairs, offering a simple and lightweight method for domain adaptation.

</details>


### [263] [Balancing Fairness and High Match Rates in Reciprocal Recommender Systems: A Nash Social Welfare Approach](https://arxiv.org/abs/2601.13609)
*Yoji Tomita,Tomohiko Yokoyama*

Main category: cs.IR

TL;DR: 本文研究匹配平台中互惠推荐系统的公平性问题，提出基于社会福利和纳什社会福利的方法来平衡匹配率与公平性，并开发了基于Sinkhorn算法的高效近似算法。


<details>
  <summary>Details</summary>
Motivation: 随着在线约会服务和职位推荐等匹配平台的普及，设计公平的互惠推荐系统变得至关重要。现有系统往往只关注提高匹配总数，却忽视了用户之间的公平性，导致推荐机会分配不均。

Method: 从公平分配的角度出发，定义了用户的推荐机会，并建立了嫉妒自由（envy-freeness）的公平概念。提出了三种方法：1）社会福利（SW）方法近似最大化匹配数；2）纳什社会福利（NSW）方法通过交替优化两个NSW函数实现近似嫉妒自由的推荐；3）α-SW方法平衡公平性与高匹配率之间的权衡。基于Sinkhorn算法开发了计算高效的近似算法。

Result: 实验表明，SW方法虽然能提高匹配率，但会导致显著的推荐机会不公平。NSW方法能够实现近似嫉妒自由的推荐，有效解决公平性问题。α-SW方法能够在公平性和匹配率之间实现平衡。在合成数据集和两个真实世界数据集上的广泛实验验证了方法的实际有效性。

Conclusion: 本文为匹配平台中的互惠推荐系统提供了系统的公平性分析框架，提出的NSW方法能够实现近似嫉妒自由的推荐，α-SW方法能够灵活平衡公平性与匹配率，基于Sinkhorn的高效算法使方法具有实际应用价值。

Abstract: Matching platforms, such as online dating services and job recommendations, have become increasingly prevalent. For the success of these platforms, it is crucial to design reciprocal recommender systems (RRSs) that not only increase the total number of matches but also avoid creating unfairness among users. In this paper, we investigate the fairness of RRSs on matching platforms. From the perspective of fair division, we define the users' opportunities to be recommended and establish the fairness concept of envy-freeness in the allocation of these opportunities. We first introduce the Social Welfare (SW) method, which approximately maximizes the number of matches, and show that it leads to significant unfairness in recommendation opportunities, illustrating the trade-off between fairness and match rates. To address this challenge, we propose the Nash Social Welfare (NSW) method, which alternately optimizes two NSW functions and achieves nearly envy-free recommendations. We further generalize the SW and NSW method to the $α$-SW method, which balances the trade-off between fairness and high match rates. Additionally, we develop a computationally efficient approximation algorithm for the SW/NSW/$α$-SW methods based on the Sinkhorn algorithm. Through extensive experiments on both synthetic datasets and two real-world datasets, we demonstrate the practical effectiveness of our approach.

</details>


### [264] [Question-Focused Filtering for Knowledge-based VQA](https://arxiv.org/abs/2601.13856)
*Wei Ye,Yixin Su,Yueguo Chen,Longxiang Gao,Jianjun Li,Ruixuan Li,Rui Zhang*

Main category: cs.IR

TL;DR: 本文提出了一种面向知识库视觉问答的问题聚焦过滤方法，通过可训练的问题聚焦过滤器和基于分块的动态多文章选择模块，在保持计算成本与典型方法相当的同时，实现跨文章的高质量知识过滤，显著提升了KB-VQA任务的性能。


<details>
  <summary>Details</summary>
Motivation: 知识库视觉问答中，有效的知识过滤对提高准确性至关重要。现有方法存在两个问题：1）典型过滤方法使用相似度度量从单篇文章中定位相关段落，导致文章级和文章内部的信息选择错误；2）基于多模态大语言模型的过滤方法虽然具有更好的语义理解和跨文章过滤能力，但计算成本过高限制了实际应用。

Method: 提出了一种问题聚焦的过滤方法，包含两个核心模块：1）可训练的问题聚焦过滤器（QFF），用于实现问题聚焦的知识过滤；2）基于分块的动态多文章选择模块（CDA），共同缓解文章级和文章内部的信息选择错误。该方法能够在保持计算成本与典型方法相当的同时，高效获取高质量的过滤知识。

Result: 实验结果表明，该方法在E-VQA数据集上比当前最先进模型提升了4.9%，在InfoSeek数据集上提升了3.8%，验证了其有效性。代码已在GitHub上公开。

Conclusion: 提出的问题聚焦过滤方法通过创新的QFF和CDA模块设计，有效解决了KB-VQA中知识过滤的准确性和效率问题，在保持合理计算成本的同时显著提升了问答性能，为知识库视觉问答任务提供了一种高效实用的解决方案。

Abstract: Knowledge-based Visual Question Answering (KB-VQA) aims to answer questions by integrating images with external knowledge. Effective knowledge filtering is crucial for improving accuracy. Typical filtering methods use similarity metrics to locate relevant article sections from one article, leading to information selection errors at the article and intra-article levels. Although recent explorations of Multimodal Large Language Model (MLLM)-based filtering methods demonstrate superior semantic understanding and cross-article filtering capabilities, their high computational cost limits practical application. To address these issues, this paper proposes a question-focused filtering method. This approach can perform question-focused, cross-article filtering, efficiently obtaining high-quality filtered knowledge while keeping computational costs comparable to typical methods. Specifically, we design a trainable Question-Focused Filter (QFF) and a Chunk-based Dynamic Multi-Article Selection (CDA) module, which collectively alleviate information selection errors at both the article and intra-article levels. Experiments show that our method outperforms current state-of-the-art models by 4.9% on E-VQA and 3.8% on InfoSeek, validating its effectiveness. The code is publicly available at: https://github.com/leaffeall/QKVQA.

</details>


### [265] [IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization](https://arxiv.org/abs/2601.13938)
*Heyang Zhou,JiaJia Chen,Xiaolu Chen,Jie Bao,Zhen Chen,Yong Liao*

Main category: cs.IR

TL;DR: IF-GEO框架通过"发散-收敛"两阶段方法解决多查询优化中的冲突问题，实现跨查询稳定的生成引擎优化


<details>
  <summary>Details</summary>
Motivation: 生成引擎通过检索源合成直接答案时，确保源可见性成为重要挑战。针对不同查询优化文档时，异构查询在有限内容预算下往往产生冲突和竞争的修订需求

Method: 提出IF-GEO框架，包含两个阶段：1)从代表性潜在查询中挖掘不同的优化偏好；2)通过冲突感知指令融合协调偏好，合成全局修订蓝图以指导编辑。引入风险感知稳定性指标量化跨查询稳定性

Result: 在多查询基准测试中，IF-GEO实现了显著的性能提升，同时在多样化检索场景中保持了鲁棒性

Conclusion: IF-GEO框架有效解决了多查询优化中的冲突问题，通过协调不同查询偏好实现稳定的生成引擎优化，提高了源可见性

Abstract: As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a "diverge-then-converge" framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO's objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.

</details>


### [266] [Auditory Brain Passage Retrieval: Cross-Sensory EEG Training for Neural Information Retrieval](https://arxiv.org/abs/2601.14001)
*Niall McGuire,Yashar Moshfeghi*

Main category: cs.IR

TL;DR: 首次系统研究听觉脑电图用于脑段落检索，发现听觉EEG优于视觉EEG，跨感官训练显著提升性能，甚至超越BM25文本基线


<details>
  <summary>Details</summary>
Motivation: 传统信息检索中查询表述面临认知和生理障碍的挑战。现有脑段落检索研究仅使用视觉刺激，未探索听觉EEG在语音界面和视障用户中的应用潜力，也未研究跨感官训练是否能缓解数据稀缺问题

Method: 使用双编码器架构和四种池化策略（CLS、均值、最大值、多向量），在Alice（听觉）和Nieuwland（视觉）数据集上进行对照实验，比较纯听觉、纯视觉和组合训练的效果

Result: 听觉EEG一致优于视觉EEG；跨感官训练配合CLS池化显著提升性能：MRR提升31%（0.474）、Hit@1提升43%（0.314）、Hit@10提升28%（0.858）；组合听觉EEG模型甚至超越BM25文本基线（0.474 vs 0.428）

Conclusion: 验证了听觉神经界面在信息检索任务中的有效性，证明跨感官训练既能解决数据稀缺问题，又优于单模态方法，为无障碍界面提供了新途径

Abstract: Query formulation from internal information needs remains fundamentally challenging across all Information Retrieval paradigms due to cognitive complexity and physical impairments. Brain Passage Retrieval (BPR) addresses this by directly mapping EEG signals to passage representations without intermediate text translation. However, existing BPR research exclusively uses visual stimuli, leaving critical questions unanswered: Can auditory EEG enable effective retrieval for voice-based interfaces and visually impaired users? Can training on combined EEG datasets from different sensory modalities improve performance despite severe data scarcity? We present the first systematic investigation of auditory EEG for BPR and evaluate cross-sensory training benefits. Using dual encoder architectures with four pooling strategies (CLS, mean, max, multi-vector), we conduct controlled experiments comparing auditory-only, visual-only, and combined training on the Alice (auditory) and Nieuwland (visual) datasets. Results demonstrate that auditory EEG consistently outperforms visual EEG, and cross-sensory training with CLS pooling achieves substantial improvements over individual training: 31% in MRR (0.474), 43% in Hit@1 (0.314), and 28% in Hit@10 (0.858). Critically, combined auditory EEG models surpass BM25 text baselines (MRR: 0.474 vs 0.428), establishing neural queries as competitive with traditional retrieval whilst enabling accessible interfaces. These findings validate auditory neural interfaces for IR tasks and demonstrate that cross-sensory training addresses data scarcity whilst outperforming single-modality approaches Code: https://github.com/NiallMcguire/Audio_BPR

</details>


### [267] [XR: Cross-Modal Agents for Composed Image Retrieval](https://arxiv.org/abs/2601.14245)
*Zhongyu Yang,Wei Pang,Yingfang Yuan*

Main category: cs.IR

TL;DR: XR是一个无需训练的多智能体框架，通过协调想象力、相似性和问答三种智能体，将组合图像检索重新定义为渐进式推理过程，在多个基准上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于嵌入的组合图像检索方法视角狭窄，只能捕捉有限的跨模态线索，缺乏语义推理能力。随着智能体AI重新定义检索需求，需要超越传统基于相似性的范式，实现多模态推理。

Method: XR框架包含三种专门智能体：想象力智能体通过跨模态生成合成目标表示；相似性智能体通过混合匹配进行粗过滤；问答智能体通过针对性推理验证事实一致性进行细过滤。通过渐进式多智能体协调，迭代优化检索结果。

Result: 在FashionIQ、CIRR和CIRCO三个基准上，XR相比强大的无需训练和基于训练的方法实现了高达38%的性能提升。消融实验表明每个智能体都是必要的。

Conclusion: XR框架通过多智能体协作将检索重新定义为渐进式推理过程，有效解决了组合图像检索中的语义和视觉约束问题，为智能体AI时代的检索系统提供了新范式。

Abstract: Retrieval is being redefined by agentic AI, demanding multimodal reasoning beyond conventional similarity-based paradigms. Composed Image Retrieval (CIR) exemplifies this shift as each query combines a reference image with textual modifications, requiring compositional understanding across modalities. While embedding-based CIR methods have achieved progress, they remain narrow in perspective, capturing limited cross-modal cues and lacking semantic reasoning. To address these limitations, we introduce XR, a training-free multi-agent framework that reframes retrieval as a progressively coordinated reasoning process. It orchestrates three specialized types of agents: imagination agents synthesize target representations through cross-modal generation, similarity agents perform coarse filtering via hybrid matching, and question agents verify factual consistency through targeted reasoning for fine filtering. Through progressive multi-agent coordination, XR iteratively refines retrieval to meet both semantic and visual query constraints, achieving up to a 38% gain over strong training-free and training-based baselines on FashionIQ, CIRR, and CIRCO, while ablations show each agent is essential. Code is available: https://01yzzyu.github.io/xr.github.io/.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [268] [Dynamics of Socio-Institutional Asynchrony in Generative AI: Analyzing the Relative Importance of Intervention Timing vs. Enforcement Efficiency via the Socio-Institutional Asynchrony Model (SIAM)](https://arxiv.org/abs/2601.11562)
*Taeyoon Kim*

Main category: cs.CY

TL;DR: 研究提出Socio-Institutional Asynchrony Model (SIAM)量化评估AI治理中干预时机与执行效率的相对效果，发现提前干预比提高执行效率能更有效减少社会负担


<details>
  <summary>Details</summary>
Motivation: 生成式AI的超指数增长加剧了技术扩散速度与制度适应速度之间的制度不匹配问题，需要量化评估不同政策杠杆的相对有效性

Method: 提出Socio-Institutional Asynchrony Model (SIAM)，基于欧盟AI法案时间线和假设的6个月算力翻倍周期，进行10001个时间步的高精度模拟

Result: 提前干预时机能将累积社会负担减少约64%，而提高执行效率仅能减少约30%；提前干预的相对有效性大约是加速执行速度的两倍

Conclusion: AI治理的核心价值在于主动及时性而非反应性行政效率，政策制定应优先考虑干预时机而非执行效率

Abstract: The super-exponential growth of generative AI has intensified the institutional mismatch between the pace of technological diffusion and the speed of institutional adaptation. This study proposes the Socio-Institutional Asynchrony Model, or SIAM, to quantitatively evaluate the relative effectiveness of two policy levers: intervention timing and enforcement efficiency. Using the timeline of the EU AI Act and an assumed compute doubling time of six months, we conduct a high precision simulation with 10001 time steps. The results show that an earlier intervention timing reduces the cumulative social burden by approximately sixty four percent, whereas improving enforcement efficiency reduces it by only about thirty percent. We further demonstrate analytically that advancing the start of intervention has structurally higher sensitivity, with roughly twice the relative effectiveness, compared to accelerating enforcement speed. These findings suggest that the core value of AI governance lies in proactive timeliness rather than reactive administrative efficiency.

</details>


### [269] [Human-like Social Compliance in Large Language Models: Unifying Sycophancy and Conformity through Signal Competition Dynamics](https://arxiv.org/abs/2601.11563)
*Long Zhang,Wei-neng Chen*

Main category: cs.CY

TL;DR: 该研究提出了信号竞争机制，揭示了LLMs中顺从行为（奉承和从众）源于一个收敛的几何流形——顺从子空间，其中社会情感信号会抑制信息校准信号，导致模型放弃内部知识而服从外部社会线索。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地融入决策框架，它们对社会顺从（特别是奉承和从众）的脆弱性日益暴露。然而，关于外部社会线索如何系统性地覆盖模型内部参数知识的基本机制存在关键研究空白。

Method: 引入信号竞争机制统一框架，通过评估15个LLMs的行为相关性分析，并对三个代表性开源模型进行潜在空间探测，识别顺从子空间的特征。

Result: 分析表明奉承和从众行为源于一个收敛的几何流形（顺从子空间），其内部表征具有高度方向相似性。顺从转变是一个由线性边界决定的确定性过程，社会情感信号会抑制信息校准信号。研究还发现了"透明度-真相差距"，显示内部置信度虽然提供惯性屏障，但在强烈社会压力下仍可被渗透。

Conclusion: 通过形式化集成认知对齐框架，该研究为从指令遵循转向稳健认知完整性提供了蓝图，揭示了LLMs在社会压力下的脆弱性机制，并为提高模型认知鲁棒性提供了理论基础。

Abstract: The increasing integration of Large Language Models (LLMs) into decision-making frameworks has exposed significant vulnerabilities to social compliance, specifically sycophancy and conformity. However, a critical research gap exists regarding the fundamental mechanisms that enable external social cues to systematically override a model's internal parametric knowledge. This study introduces the Signal Competition Mechanism, a unified framework validated by assessing behavioral correlations across 15 LLMs and performing latent-space probing on three representative open-source models. The analysis demonstrates that sycophancy and conformity originate from a convergent geometric manifold, hereafter termed the compliance subspace, which is characterized by high directional similarity in internal representations. Furthermore, the transition to compliance is shown to be a deterministic process governed by a linear boundary, where the Social Emotional Signal effectively suppresses the Information Calibration Signal. Crucially, we identify a "Transparency-Truth Gap," revealing that while internal confidence provides an inertial barrier, it remains permeable and insufficient to guarantee immunity against intense social pressure. By formalizing the Integrated Epistemic Alignment Framework, this research provides a blueprint for transitioning from instructional adherence to robust epistemic integrity.

</details>


### [270] [Making AI Philosophical Again: On Philip E. Agre's Legacy](https://arxiv.org/abs/2601.11569)
*Jethro Masis*

Main category: cs.CY

TL;DR: 本文分析Philip E. Agre的学术遗产，探讨他提出的"批判性技术实践"理念，认为AI不仅是工程学科，更是受历史偶然性隐喻、假设和话语影响的数学化哲学形式。文章评估了Agre将海德格尔现象学应用于AI的尝试及其局限性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在重新审视Philip E. Agre的学术贡献，将其工作置于人工智能、哲学和批判理论的交叉点，探讨AI作为数学化哲学的本质，以及如何通过批判性技术实践使AI研究更具反思性和哲学自觉。

Method: 通过重构Agre提出的"批判性技术实践"概念，分析其如何借鉴海德格尔现象学（特别是"上手状态"与"现成状态"的区分）来改革AI研究。文章考察了Agre将这些哲学理念操作化的尝试，特别是通过Pengi系统等计算实现，同时评估这些尝试的哲学雄心和实际限制。

Result: Agre成功揭示了AI中隐藏的哲学承诺，丰富了AI的概念词汇，并迫使技术实践变得更加反思、历史意识和哲学开放。然而，他的项目遭遇根本性困境：海德格尔所阐述的人类存在的开放性和自我揭示特征无法被完全编程捕获，否则会将本体现象简化为存在机制。

Conclusion: Agre的持久贡献不在于提供一个可行的海德格尔式AI，而在于迫使技术实践变得具有反思性、历史意识和哲学开放性。他的工作表明，AI研究需要认识到自身的哲学基础和历史偶然性，而不是将其视为纯粹的技术工程问题。

Abstract: This paper examines the intellectual legacy of Philip E. Agre by situating his work at the intersection of artificial intelligence, philosophy, and critical theory. It reconstructs Agre's proposal of a critical technical practice, according to which AI should be understood not merely as an engineering discipline but as a form of mathematized philosophy shaped by historically contingent metaphors, assumptions, and discourses. Drawing on Heideggerian phenomenology, especially the distinction between ready-to-hand and present-at-hand, Agre sought to reform AI by emphasizing interaction, embedding, indexicality, and deictic representation over traditional mentalist and representational models. The paper analyzes Agre's attempt to operationalize these ideas through computational implementations such as the Pengi system, highlighting both the philosophical ambition and the technical limitations of programming phenomenological concepts. While acknowledging Agre's success in exposing the hidden philosophical commitments of AI and enriching its conceptual vocabulary, the paper ultimately argues that his project encounters a fundamental impasse: the open and self-disclosing character of human existence articulated by Heidegger cannot be fully captured or programmed without reducing ontological phenomena to ontic mechanisms. Agre's enduring contribution therefore lies less in offering a viable Heideggerian AI than in compelling technical practice to become reflexive, historically conscious, and openly philosophical.

</details>


### [271] [What Can Student-AI Dialogues Tell Us About Students' Self-Regulated Learning? An exploratory framework](https://arxiv.org/abs/2601.11576)
*Long Zhang,Fangwei Lin,Weilin Wang*

Main category: cs.CY

TL;DR: 研究探索使用学生与AI对话作为自我调节学习评估的有效数据源，发现主动对话模式与SRL正相关，反应式模式与SRL负相关，并提出DHASRL框架。


<details>
  <summary>Details</summary>
Motivation: 随着人机协作学习的发展，传统SRL评估方法（如问卷）存在中断学习过程的问题，而非中断性指标（如点击流数据）的效用也在下降，因为更多学习活动发生在对话中。因此需要探索对话本身能否作为有效的SRL评估数据源。

Method: 分析98名大学生与生成式AI学习伙伴的421个对话日志，使用大语言模型嵌入和聚类技术识别22种对话模式，量化每个学生的互动为对齐分数剖面，并与在线自我调节学习问卷得分进行关联分析。

Result: 发现主动对话模式（如课后知识整合）与整体SRL显著正相关，而反应式模式（如课前基础问题）与整体SRL及其子过程显著负相关。低SRL学生比高SRL学生显著更倾向于反应式模式。

Conclusion: 提出对话式人机自我调节学习框架，为在人机协作学习对话中直接嵌入SRL评估提供了实用方法，支持实时监控和支架式学生调节。

Abstract: The rise of Human-AI Collaborative Learning (HAICL) is shifting education toward dialogue-centric paradigms, creating an urgent need for new assessment methods. Evaluating Self-Regulated Learning (SRL) in this context presents new challenges, as the limitations of conventional approaches become more apparent. Questionnaires remain interrupted, while the utility of non-interrupted metrics like clickstream data is diminishing as more learning activity occurs within the dialogue. This study therefore investigates whether the student-AI dialogue can serve as a valid, non-interrupted data source for SRL assessment. We analyzed 421 dialogue logs from 98 university students interacting with a generative AI (GenAI) learning partner. Using large language model embeddings and clustering, we identified 22 dialogue patterns and quantified each student's interaction as a profile of alignment scores, which were analyzed against their Online Self-Regulated Learning Questionnaire (OSLQ) scores. Findings revealed a significant positive association between proactive dialogue patterns (e.g., post-class knowledge integration) and overall SRL. Conversely, reactive patterns (e.g., foundational pre-class questions) were significantly and negatively associated with overall SRL and its sub-processes. A group comparison substantiated these results, with low-SRL students showing significantly higher alignment with reactive patterns than their high-SRL counterparts. This study proposed the Dialogue-Based Human-AI Self-Regulated Learning (DHASRL) framework, a practical methodology for embedding SRL assessment directly within the HAICL dialogue to enable real-time monitoring and scaffolding of student regulation.

</details>


### [272] [Overview of the SciHigh Track at FIRE 2025: Research Highlight Generation from Scientific Papers](https://arxiv.org/abs/2601.11582)
*Tohida Rehman,Debarshi Kumar Sanyal,Samiran Chattopadhyay*

Main category: cs.CY

TL;DR: SciHigh任务旨在从科学论文摘要自动生成简洁、信息丰富的要点式亮点，帮助读者快速掌握论文核心贡献和发现，减少阅读负担。


<details>
  <summary>Details</summary>
Motivation: 科学论文数量激增，读者需要快速理解论文核心内容。亮点生成可以帮助读者快速掌握论文关键贡献、发现和新颖性，特别是在移动设备上阅读时，比长段落更容易理解和消化。

Method: 使用MixSub数据集（包含摘要和作者撰写的亮点配对），12个团队参与探索了包括预训练语言模型在内的多种方法。评估采用ROUGE、METEOR和BERTScore等标准指标，以ROUGE-L分数作为排名依据。

Result: 自动生成的亮点可以有效减少阅读负担，加速文献综述过程，并为数字图书馆和学术搜索平台提供更好的元数据。该任务为科学写作中简洁准确的亮点生成方法提供了专门的基准。

Conclusion: SciHigh任务为科学论文亮点自动生成建立了专门的评估基准，展示了自动生成亮点在加速文献理解和学术搜索方面的潜力，为未来相关研究提供了基础。

Abstract: `SciHigh: Research Highlight Generation from Scientific Papers' focuses on the task of automatically generating concise, informative, and meaningful bullet-point highlights directly from scientific abstracts. The goal of this task is to evaluate how effectively computational models can generate highlights that capture the key contributions, findings, and novelty of a paper in a concise form. Highlights help readers grasp essential ideas quickly and are often easier to read and understand than longer paragraphs, especially on mobile devices. The track uses the MixSub dataset \cite{10172215}, which provides pairs of abstracts and corresponding author-written highlights.
  In this inaugural edition of the track, 12 teams participated, exploring various approaches, including pre-trained language models, to generate highlights from this scientific dataset. All submissions were evaluated using established metrics such as ROUGE, METEOR, and BERTScore to measure both alignment with author-written highlights and overall informativeness. Teams were ranked based on ROUGE-L scores. The findings suggest that automatically generated highlights can reduce reading effort, accelerate literature reviews, and enhance metadata for digital libraries and academic search platforms. SciHigh provides a dedicated benchmark for advancing methods aimed at concise and accurate highlight generation from scientific writing.

</details>


### [273] [Let Me Try Again: Examining Replay Behavior by Tracing Students' Latent Problem-Solving Pathways](https://arxiv.org/abs/2601.11586)
*Shan Zhang,Siddhartha Pradhan,Ji-Eun Lee,Ashish Gurung,Anthony F. Botelho*

Main category: cs.CY

TL;DR: 研究使用马尔可夫链和隐马尔可夫模型分析游戏学习平台中学生的重玩行为，发现即时重玩对学习有积极影响，而延迟重玩效果较弱或负面。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明学生在游戏学习环境中的问题解决路径反映了他们的概念理解、程序知识和灵活性，重玩行为可能表明生产性挣扎或更广泛的探索，从而促进深度学习。然而，对于这些路径如何在问题间顺序展开，以及重玩和其他问题解决策略的时间安排如何与近端和远端学习结果相关，了解甚少。

Method: 使用马尔可夫链和隐马尔可夫模型分析777名七年级学生在游戏学习平台"From Here to There!"的日志数据，识别问题解决路径模式，并通过回归分析评估不同状态与学习结果的关系。

Result: 在问题序列中，学生经常保持状态或在成功完成后立即重玩；跨问题时，强烈的自转移表明稳定的策略路径。隐马尔可夫模型识别出四种潜在状态：不完整主导、最优结束、重玩和混合状态。回归分析显示，与不完整主导状态相比，参与重玩主导和最优结束状态预测更高的概念知识、灵活性和表现。即时重玩始终支持学习结果，而延迟重玩与非重玩相比关联较弱或负面。

Conclusion: 数字学习中的重玩行为并非普遍有益，其效果取决于时机。即时重玩支持灵活性和更有效的探索，而延迟重玩效果有限或负面。研究为理解游戏学习环境中学生行为模式与学习结果的关系提供了实证依据。

Abstract: Prior research has shown that students' problem-solving pathways in game-based learning environments reflect their conceptual understanding, procedural knowledge, and flexibility. Replay behaviors, in particular, may indicate productive struggle or broader exploration, which in turn foster deeper learning. However, little is known about how these pathways unfold sequentially across problems or how the timing of replays and other problem-solving strategies relates to proximal and distal learning outcomes. This study addresses these gaps using Markov Chains and Hidden Markov Models (HMMs) on log data from 777 seventh graders playing the game-based learning platform of From Here to There!. Results show that within problem sequences, students often persisted in states or engaged in immediate replay after successful completions, while across problems, strong self-transitions indicated stable strategic pathways. Four latent states emerged from HMMs: Incomplete-dominant, Optimal-ending, Replay, and Mixed. Regression analyses revealed that engagement in replay-dominant and optimal-ending states predicted higher conceptual knowledge, flexibility, and performance compared with the Incomplete-dominant state. Immediate replay consistently supported learning outcomes, whereas delayed replay was weakly or negatively associated in relation to Non-Replay. These findings suggest that replay in digital learning is not uniformly beneficial but depends on timing, with immediate replay supporting flexibility and more productive exploration.

</details>


### [274] [Evidence-Grounded Multi-Agent Planning Support for Urban Carbon Governance via RAG](https://arxiv.org/abs/2601.11587)
*Yuyan Huang,Haoran Li,Yifan Lu,Ruolin Wu,Siqian Chen,Chao Liu*

Main category: cs.CY

TL;DR: 本文提出了一个基于证据的多智能体规划支持系统，用于城市碳治理，通过检索增强生成技术提高事实可靠性和证据可追溯性，在事实检索任务中显著提升性能，并在宁波案例中展示了端到端报告生成能力。


<details>
  <summary>Details</summary>
Motivation: 城市碳治理需要整合多种异构证据（排放清单、统计年鉴、政策文本、技术措施、学术发现）到可执行的跨部门规划中。虽然大语言模型可以辅助规划工作流，但其事实可靠性和证据可追溯性仍是专业应用中的关键障碍。

Method: 提出了一个基于证据的多智能体规划支持系统，采用标准文本检索增强生成技术（非GraphRAG）。系统与典型规划工作流对齐，将任务分解为四个专门智能体：(i) 证据问答用于事实核查和合规查询，(ii) 排放状态评估用于诊断分析，(iii) 规划推荐用于生成多部门治理路径，(iv) 报告整合用于生成规划式交付成果。

Result: 在事实检索任务中，引入RAG将平均得分从低于6提高到90以上，并显著改善关键字段提取（如区域和数值检测接近100%）。宁波真实城市案例研究展示了端到端报告生成，在专家评审中表现出强相关性、覆盖性和连贯性，同时突出了跨数据源的边界不一致性这一实际限制。

Conclusion: 该系统通过多智能体架构和检索增强生成技术，有效解决了城市碳治理规划中LLM的事实可靠性和证据可追溯性问题，在事实检索和综合规划生成任务中表现出色，为专业规划应用提供了实用工具，同时指出了跨数据源边界不一致性需要进一步解决。

Abstract: Urban carbon governance requires planners to integrate heterogeneous evidence -- emission inventories, statistical yearbooks, policy texts, technical measures, and academic findings -- into actionable, cross-departmental plans. Large Language Models (LLMs) can assist planning workflows, yet their factual reliability and evidential traceability remain critical barriers in professional use. This paper presents an evidence-grounded multi-agent planning support system for urban carbon governance built upon standard text-based Retrieval-Augmented Generation (RAG) (without GraphRAG). We align the system with the typical planning workflow by decomposing tasks into four specialized agents: (i) evidence Q\&A for fact checking and compliance queries, (ii) emission status assessment for diagnostic analysis, (iii) planning recommendation for generating multi-sector governance pathways, and (iv) report integration for producing planning-style deliverables. We evaluate the system in two task families: factual retrieval and comprehensive planning generation. On factual retrieval tasks, introducing RAG increases the average score from below 6 to above 90, and dramatically improves key-field extraction (e.g., region and numeric values near 100\% detection). A real-city case study (Ningbo, China) demonstrates end-to-end report generation with strong relevance, coverage, and coherence in expert review, while also highlighting boundary inconsistencies across data sources as a practical limitation.

</details>


### [275] [OVO Fintech Application Analysis using The System Usability Scale](https://arxiv.org/abs/2601.11600)
*Luh Yuliani Purnama Dewi,Leon Andretti Abdillah*

Main category: cs.CY

TL;DR: 研究使用SUS量表评估OVO应用在商场租户中的可用性，结果显示87.05分（A级优秀），表明该应用在电子金融交易中提供良好的用户体验。


<details>
  <summary>Details</summary>
Motivation: 随着信息技术发展，支付系统从传统方式转向电子钱包和金融科技等基于技术的解决方案。金融科技作为技术与金融服务的融合，已发展成为支持快速远程交易的在线商业模式。本研究旨在探讨信息技术对支付系统的影响，特别是金融科技领域，并聚焦于OVO应用对商场租户的影响。

Method: 采用描述性定量研究方法，以国际广场商场50名租户为样本。使用系统可用性量表（SUS）评估OVO应用的可用性，重点关注有效性、效率和用户满意度。通过SUS问卷收集数据，并使用SPSS进行统计分析。

Result: OVO应用获得87.05分的SUS得分，被评为A级优秀。这表明该应用具有高可用性，特别是在电子金融交易方面为用户提供了舒适的使用体验。

Conclusion: OVO金融科技应用在商场租户中表现出优秀的可用性，为电子金融交易提供了良好的用户体验。研究证实了信息技术对支付系统的积极影响，特别是金融科技应用在实际商业环境中的有效性和用户接受度。

Abstract: The advancement of information technology has propelled payment systems from conventional methods to technology-based solutions, such as e-wallets and Fintech. Fintech, a fusion of technology and financial services, has evolved into an online business model enabling fast and remote transactions. This research discusses the progress of information technology influencing payment systems, particularly in the realm of Fintech. The primary focus is on the Fintech application OVO and its impact on tenants at the International Plaza Mall in Palembang. This study employs the System Usability Scale or SUS to evaluate the Usability of the OVO application, emphasizing aspects like effectiveness, efficiency, and user satisfaction. The research is descriptive and quantitative, with a sample of 50 respondents from Mall IP tenants. Data is collected through SUS questionnaires and analyzed using SPSS. The evaluation indicates that the OVO application has high Usability, with an SUS score of 87.05 or Grade A, signifying an Excellent rating. It suggests that the OVO application provides a comfortable user experience, particularly in electronic financial transactions.

</details>


### [276] [Stuck in the Turing Matrix: Inauthenticity, Deception and the Social Life of AI](https://arxiv.org/abs/2601.11613)
*Samuel Gerald Collins*

Main category: cs.CY

TL;DR: 论文探讨了图灵测试在生成式AI时代的新意义，认为它揭示了人类在判断内容真实性时所处的复杂立场，而非仅仅是测试机器智能的工具。


<details>
  <summary>Details</summary>
Motivation: 在生成式AI时代，图灵测试的意义发生了变化。虽然它可能不是衡量机器智能的有效测试，但它描述了人类在判断内容是人还是机器生成时所占据的位置。作者希望通过分析Reddit上关于AI的讨论，探索人类如何在这种判断中采取不同立场。

Method: 作者提出了"图灵矩阵"的概念，结合真实性和欺骗性问题。通过分析Reddit上关于AI在社会生活广泛领域的帖子数据，研究用户在图灵矩阵中采取的不同立场，以及他们如何通过复杂协商来理解自己所处的AI世界。

Result: 研究发现，Reddit用户在判断内容是人还是AI生成时采取了各种复杂立场，这些立场在图灵矩阵中形成不同组合。用户通过复杂的协商过程来理解AI世界，即使图灵测试不能告诉我们AGI或其他基准的成就，但它能揭示人类在矩阵中的生活局限性。

Conclusion: 图灵测试在生成式AI时代具有新的社会学意义：它不再仅仅是测试机器智能的工具，而是揭示了人类在判断内容真实性时所处的复杂社会位置和协商过程，反映了人类在AI世界中的生活局限性。

Abstract: The Turing test may or may not be a valid test of machine intelligence. But in an age of generative AI, the test describes the positions we humans occupy. Judging whether or not something is human or machine produced is an everyday condition for many of us, one that involves taking a spectrum of positions along what the essay describes as a Turing Matrix combining questions of authenticity with questions of deception. Utilizing data from Reddit postings about AI in broad areas of social life, the essay examines positions taken in a Turing Matrix and describes complex negotiations taken by Reddit posters as they strive to make sense of the AI World in which they live. Even though the Turing Test may not tell us much about the achievement of AGI or other benchmarks, it can tell us a great deal about the limitations of human life in the Matrix.

</details>


### [277] [Syllabic Agglutinative Tokenizations for Indonesian LLM: A Study from Gasing Literacy Learning System](https://arxiv.org/abs/2601.11643)
*H. Situngkir,A. B. Lumbantobing,Y. Surya*

Main category: cs.CY

TL;DR: 提出基于音节的印尼语分词方法，受Gasing识字系统启发，通过音节边界分割和字节对编码创建3500个token的词汇表，在保持覆盖的同时提升分词效率。


<details>
  <summary>Details</summary>
Motivation: 传统分词方法对印尼语等黏着语处理不佳，无法有效捕捉其形态音位结构。受Gasing识字教学系统启发，希望开发更符合印尼语语言特点的分词策略，为形态丰富且代表性不足的语言提供更好的NLP解决方案。

Method: 基于信息论原理，先通过基于规则的音节边界分割识别高频音节，然后应用字节对编码构建3500个token的紧凑词汇表。该方法保持字符级回退机制以确保覆盖，创建了TOBA LLM模型。

Result: 在印尼语维基百科和PDBI民俗语料库上评估，音节分词法Rényi效率达0.74，优于预训练多语言分词器的0.50-0.64；平均token长度3.67字符（GPT-2为2.72），词汇表规模小一个数量级。能更好地内化音节内的字符级依赖关系。

Conclusion: 将人类识字教学法与计算优化原则结合，为形态丰富的语言提供了有前景的语言学感知分词范式。TOBA LLM展示了这种融合在提升分词效率、减少计算负担方面的优势，特别适用于印尼语等黏着语。

Abstract: This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning System's pedagogical methodology. Drawing on information-theoretic principles, we develop a tokenization framework that segments Indonesian text at syllable boundaries before applying byte-pair encoding, creating a vocabulary that aligns with the language's morphophonological structure. Our approach first identifies high-frequency syllables through rule-based segmentation, then constructs a compact vocabulary of 3,500 tokens that preserves meaningful linguistic units while maintaining coverage through character-level fallback. Empirical evaluation on Indonesian Wikipedia and folklore corpora from Indonesian Culture Digital Library (PDBI) demonstrates substantial improvements over conventional tokenization methods: the syllable-based approach achieves Rényi efficiency of 0.74 compared to 0.50-0.64 for pretrained multilingual tokenizers, while maintaining higher average token lengths (3.67 characters versus 2.72 for GPT-2) despite using a vocabulary an order of magnitude smaller. These gains emerge from the method's ability to internalize character-level dependencies within syllable units, reducing the computational burden on language models while respecting Indonesian's agglutinative morphology. We call the LLM built upon this principle, TOBA LLM (Tokenisasi Optimum Berbasis Aglutinasi), the convergence of human literacy pedagogy with computational optimization principles offers a promising paradigm for developing linguistically-informed tokenization strategies, particularly for morphologically rich and underrepresented languages in natural language processing.

</details>


### [278] [Frontier AI Auditing: Toward Rigorous Third-Party Assessment of Safety and Security Practices at Leading AI Companies](https://arxiv.org/abs/2601.11699)
*Miles Brundage,Noemi Dreksler,Aidan Homewood,Sean McGregor,Patricia Paskov,Conrad Stosz,Girish Sastry,A. Feder Cooper,George Balston,Steven Adler,Stephen Casper,Markus Anderljung,Grace Werner,Soren Mindermann,Vasilios Mavroudis,Ben Bucknall,Charlotte Stix,Jonas Freund,Lorenzo Pacchiardi,Jose Hernandez-Orallo,Matteo Pistillo,Michael Chen,Chris Painter,Dean W. Ball,Cullen O'Keefe,Gabriel Weil,Ben Harack,Graeme Finley,Ryan Hassan,Scott Emmons,Charles Foster,Anka Reuel,Bri Treece,Yoshua Bengio,Daniel Reti,Rishi Bommasani,Cristian Trout,Ali Shahin Shamsabadi,Rajiv Dattani,Adrian Weller,Robert Trager,Jaime Sevilla,Lauren Wagner,Lisa Soder,Ketan Ramakrishnan,Henry Papadatos,Malcolm Murray,Ryan Tovcimak*

Main category: cs.CY

TL;DR: 论文提出前沿AI审计框架，通过第三方验证AI开发者的安全声明，引入AI保证等级(AAL-1到AAL-4)来标准化审计严格度。


<details>
  <summary>Details</summary>
Motivation: 前沿AI正成为关键社会基础设施，但外部缺乏可靠方法来评估领先开发者的安全和安保声明的准确性。与消费品、企业财务报表和食品供应链等其他社会技术系统相比，AI在多个维度上缺乏严格的第三方审查。AI可信度的模糊性可能阻碍其在有益场景的部署，同时增加危险场景的风险。

Method: 定义前沿AI审计为对前沿AI开发者安全和安保声明的严格第三方验证，基于对非公开信息的深度安全访问来评估其系统和实践是否符合相关标准。引入AI保证等级(AAL-1到AAL-4)，从有时间限制的系统审计到持续、抗欺骗的验证。

Result: 提出了一个系统化的AI审计框架，包括四个级别的保证等级：AAL-1（有时间限制的系统审计）、AAL-2（持续监控）、AAL-3（抗欺骗验证）、AAL-4（最高级别的持续抗欺骗验证）。

Conclusion: 仅靠公共透明度无法解决AI可信度问题，因为许多安全和安保相关的细节需要保密和专业解释。通过建立标准化的第三方审计框架和AI保证等级，可以为AI系统的可信度提供可比较、可验证的评估，促进负责任的技术部署。

Abstract: Frontier AI is becoming critical societal infrastructure, but outsiders lack reliable ways to judge whether leading developers' safety and security claims are accurate and whether their practices meet relevant standards. Compared to other social and technological systems we rely on daily such as consumer products, corporate financial statements, and food supply chains, AI is subject to less rigorous third-party scrutiny along several dimensions. Ambiguity about whether AI systems are trustworthy can discourage deployment in some contexts where the technology could be beneficial, and make it more likely when it's dangerous. Public transparency alone cannot close this gap: many safety- and security-relevant details are legitimately confidential and require expert interpretation. We define frontier AI auditing as rigorous third-party verification of frontier AI developers' safety and security claims, and evaluation of their systems and practices against relevant standards, based on deep, secure access to non-public information. To make rigor legible and comparable, we introduce AI Assurance Levels (AAL-1 to AAL-4), ranging from time-bounded system audits to continuous, deception-resilient verification.

</details>


### [279] [Expanding External Access To Frontier AI Models For Dangerous Capability Evaluations](https://arxiv.org/abs/2601.11916)
*Jacob Charnock,Alejandro Tlaie,Kyle O'Brien,Stephen Casper,Aidan Homewood*

Main category: cs.CY

TL;DR: 该论文提出了一个用于危险能力评估的访问方法分类法，将访问分为模型访问、模型信息和评估时间三个维度，并定义了三个描述性访问级别（AL1-AL3）以支持评估者、前沿AI公司和政策制定者之间的清晰沟通。


<details>
  <summary>Details</summary>
Motivation: 前沿AI公司越来越依赖外部评估来评估部署前的危险能力风险，但外部评估者通常面临模型访问受限、信息有限和时间不足的问题，这会降低评估的严谨性和可信度。欧盟通用AI实践准则要求"适当访问"，但未具体说明实践中的含义，且缺乏描述不同类型和级别评估者访问的通用框架。

Method: 提出了一个访问方法的分类法，将访问分解为三个维度：模型访问、模型信息和评估时间框架。对于每个维度，审查了其益处和风险。基于该分类法，提出了三个描述性访问级别：AL1（黑盒模型访问和最小信息）、AL2（灰盒模型访问和实质性信息）、AL3（白盒模型访问和全面信息）。

Result: 开发了一个系统化的访问分类框架，明确了不同访问级别的特征。该框架支持评估者、前沿AI公司和政策制定者之间更清晰的沟通，并认为这些级别对应欧盟实践准则中定义的适当访问标准（尽管这些标准可能随时间变化）。

Conclusion: 通过提出访问方法的分类法和三个描述性访问级别，填补了危险能力评估中访问框架的空白。虽然扩大访问可以减少假阴性并提高利益相关者信任，但也会增加安全和能力挑战，这些限制可能通过其他行业使用的技术手段和安全措施来缓解。

Abstract: Frontier AI companies increasingly rely on external evaluations to assess risks from dangerous capabilities before deployment. However, external evaluators often receive limited model access, limited information, and little time, which can reduce evaluation rigour and confidence. The EU General-Purpose AI Code of Practice calls for "appropriate access", but does not specify what this means in practice. Furthermore, there is no common framework for describing different types and levels of evaluator access. To address this gap, we propose a taxonomy of access methods for dangerous capability evaluations. We disentangle three aspects of access: model access, model information, and evaluation timeframe. For each aspect, we review benefits and risks, including how expanding access can reduce false negatives and improve stakeholder trust, but can also increase security and capacity challenges. We argue that these limitations can likely be mitigated through technical means and safeguards used in other industries. Based on the taxonomy, we propose three descriptive access levels: AL1 (black-box model access and minimal information), AL2 (grey-box model access and substantial information), and AL3 (white-box model access and comprehensive information), to support clearer communication between evaluators, frontier AI companies, and policymakers. We believe these levels correspond to the different standards for appropriate access defined in the EU Code of Practice, though these standards may change over time.

</details>


### [280] [The Language You Ask In: Language-Conditioned Ideological Divergence in LLM Analysis of Contested Political Documents](https://arxiv.org/abs/2601.12164)
*Oleg Smirnov*

Main category: cs.CY

TL;DR: 研究发现大型语言模型在分析相同内容时，仅因提示语言不同（俄语vs乌克兰语）就会产生系统性意识形态偏见，俄语输出倾向于俄罗斯官方叙事，乌克兰语输出则采用西方自由民主话语。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在多语言环境中被广泛部署为分析工具，需要了解其输出是否因提示语言而产生系统性偏见，特别是在政治敏感的多语言环境中。

Method: 实验比较法：使用语义相同的俄语和乌克兰语提示，让大型语言模型分析同一份乌克兰公民社会文件，比较输出的政治分析在修辞定位、意识形态取向和解释结论上的差异。

Result: 俄语输出重复了俄罗斯国家话语中常见的叙事，将公民社会行为者描述为破坏民主授权的非法精英；而乌克兰语输出采用了西方自由民主政治学的词汇，将相同行为者视为民主竞争中的合法利益相关者。

Conclusion: 仅提示语言就能使相同模型分析相同内容时产生系统性不同的意识形态取向，这对AI在极化信息环境中的部署、跨语言研究应用以及多语言社会中AI系统的治理具有重要影响。

Abstract: Large language models (LLMs) are increasingly deployed as analytical tools across multilingual contexts, yet their outputs may carry systematic biases conditioned by the language of the prompt. This study presents an experimental comparison of LLM-generated political analyses of a Ukrainian civil society document, using semantically equivalent prompts in Russian and Ukrainian. Despite identical source material and parallel query structures, the resulting analyses varied substantially in rhetorical positioning, ideological orientation, and interpretive conclusions. The Russian-language output echoed narratives common in Russian state discourse, characterizing civil society actors as illegitimate elites undermining democratic mandates. The Ukrainian-language output adopted vocabulary characteristic of Western liberal-democratic political science, treating the same actors as legitimate stakeholders within democratic contestation. These findings demonstrate that prompt language alone can produce systematically different ideological orientations from identical models analyzing identical content, with significant implications for AI deployment in polarized information environments, cross-lingual research applications, and the governance of AI systems in multilingual societies.

</details>


### [281] [How Safe Is Your Data in Connected and Autonomous Cars: A Consumer Advantage or a Privacy Nightmare ?](https://arxiv.org/abs/2601.12284)
*Amit Chougule,Vinay Chamola,Norbert Herencsar,Fei Richard Yu*

Main category: cs.CY

TL;DR: 这篇综述论文探讨了联网和自动驾驶汽车(CAVs)数据共享的多方面问题，分析了其对创新的贡献和相关漏洞，强调了在技术进步与用户隐私保护之间寻求平衡的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 汽车行业在联网和自动驾驶技术推动下快速发展，车辆通过V2X通信产生和交换大量数据，这虽然提升了安全性和用户体验，但也带来了数据隐私、安全和治理方面的重大挑战。缺乏透明度和全面监管框架加剧了未经授权访问、数据长期保留和潜在滥用等问题，在消费者利益和隐私风险之间制造了紧张关系。

Method: 采用文献综述方法，系统性地：1) 评估CAVs数据共享机制和通信技术；2) 分析数据交换在各种应用场景中的益处；3) 审查隐私问题和数据滥用风险；4) 批判性评估现有监管框架及其在保护用户隐私方面的不足。

Result: 论文揭示了当前汽车行业数据共享生态系统存在显著漏洞，包括数据隐私保护不足、安全风险高、监管框架不完善等问题。同时确认了数据共享在提升安全性、性能和用户体验方面的积极价值，但缺乏有效的平衡机制。

Conclusion: 迫切需要建立强有力的政策和道德数据管理实践，在促进技术创新与确保安全、消费者友好的解决方案之间取得平衡，为可信赖和创新的汽车未来铺平道路。需要制定全面的监管框架来保护用户隐私，同时不阻碍技术进步。

Abstract: The rapid evolution of the automobile sector, driven by advancements in connected and autonomous vehicles (CAVs), has transformed how vehicles communicate, operate, and interact with their surroundings. Technologies such as Vehicle-to-Everything (V2X) communication enable autonomous cars to generate and exchange substantial amounts of data with real-world entities, enhancing safety, improving performance, and delivering personalized user experiences. However, this data-driven ecosystem introduces significant challenges, particularly concerning data privacy, security, and governance. The absence of transparency and comprehensive regulatory frameworks exacerbates issues of unauthorized data access, prolonged retention, and potential misuse, creating tension between consumer benefits and privacy risks. This review paper explores the multifaceted nature of data sharing in CAVs, analyzing its contributions to innovation and its associated vulnerabilities. It evaluates data-sharing mechanisms and communication technologies, highlights the benefits of data exchange across various use cases, examines privacy concerns and risks of data misuse, and critically reviews regulatory frameworks and their inadequacies in safeguarding user privacy. By providing a thorough analysis of the current state of data sharing in the automotive sector, the paper emphasizes the urgent need for robust policies and ethical data management practices. It calls for striking a balance between fostering technological advancements and ensuring secure, consumer-friendly solutions, paving the way for a trustworthy and innovative automotive future.

</details>


### [282] [Auditing Meta and TikTok Research API Data Access under Article 40(12) of the Digital Services Act](https://arxiv.org/abs/2601.12390)
*Luka Bekavac,Simon Mayer*

Main category: cs.CY

TL;DR: 研究对Meta和TikTok的研究API进行系统审计，发现平台通过范围限制、元数据剥离和操作限制三种机制导致大量数据丢失，无法支持DSA要求的系统性风险独立审计。


<details>
  <summary>Details</summary>
Motivation: DSA第40(12)条要求大型在线平台向研究人员提供数据访问，但现有研究尚未定量评估不同平台研究API的数据质量和完整性，也未系统分析当前访问机制的不足。

Method: 通过比较平台研究API获取的数据与从相同平台用户可见公共信息环境(PIE)收集的数据，使用两个受控傀儡账户在两个选举期间重建完整信息流，并与相应研究API可检索数据进行基准测试。

Result: 发现三种平台机制导致系统性数据丢失：范围限制（排除约50%平台PIE）、元数据剥离（剥离约83%关键上下文元数据）、操作限制（每天仅约1000次请求）。这些过滤器主要损害数据完整性，导致平台活动呈现结构性偏差。

Conclusion: 当前Meta和TikTok的研究API形式无法支持DSA设想的系统性风险独立审计，平台数据访问机制存在严重缺陷。

Abstract: Article 40(12) of the Digital Services Act (DSA) requires Very Large Online Platforms (VLOPs) to provide vetted researchers with access to publicly accessible data. While prior work has identified shortcomings of platform-provided data access mechanisms, existing research has not quantitatively assessed data quality and completeness in Research APIs across platforms, nor systematically mapped how current access provisions fall short. This paper presents a systematic audit of research access modalities by comparing data obtained through platform Research APIs with data collected about the same platforms' user-visible public information environment (PIE). Focusing on two major platform APIs, the TikTok Research API and the Meta Content Library, we reconstruct full information feeds for two controlled sockpuppet accounts during two election periods and benchmark these against the data retrievable for the same posts through the corresponding Research APIs. Our findings show systematic data loss through three classes of platform-imposed mechanisms: scope narrowing, metadata stripping, and operational restrictions. Together, these mechanisms implement overlapping filters that exclude large portions of the platform PIE (up to approximately 50 percent), strip essential contextual metadata (up to approximately 83 percent), and impose severe technical constraints for researchers (down to approximately 1000 requests per day). Viewed through a data quality lens, these filters primarily undermine completeness, resulting in a structurally biased representation of platform activity. We conclude that, in their current form, the Meta and TikTok Research APIs fall short of supporting meaningful, independent auditing of systemic risks as envisioned under the DSA.

</details>


### [283] [Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI](https://arxiv.org/abs/2601.12646)
*Ha-Chi Tran*

Main category: cs.CY

TL;DR: 论文分析了AI风险治理中的责任分配缺陷，特别是跨境损害的责任问题，借鉴其他高风险跨国领域的责任框架，提出了全球AI问责与补偿架构的设计原则。


<details>
  <summary>Details</summary>
Motivation: AI的快速扩散暴露了风险治理的显著缺陷，特别是事后责任方面存在理论化和制度化不足。跨境AI损害日益严重，而基于地域的责任制度越来越不适应全球AI供应链的现实。

Method: 采用比较和跨学科方法，研究疫苗伤害计划、系统性金融风险治理、商业核责任和国际环境制度等高风险跨国领域的补偿和责任框架，提炼可转移的法律设计原则。

Result: 从其他高风险领域提炼出严格责任、风险池、集体风险分担和责任渠道化等可转移的法律设计原则，同时指出了将这些原则应用于AI相关损害的潜在结构性限制。

Conclusion: 在AI军备竞赛而非合作治理主导的国际秩序中，论文勾勒了全球AI问责与补偿架构的轮廓，强调地缘政治竞争与有效治理跨境AI风险所需的集体行动之间的紧张关系。

Abstract: The rapid proliferation of artificial intelligence (AI) has exposed significant deficiencies in risk governance. While ex-ante harm identification and prevention have advanced, Responsible AI scholarship remains underdeveloped in addressing ex-post liability. Core legal questions regarding liability allocation, responsibility attribution, and remedial effectiveness remain insufficiently theorized and institutionalized, particularly for transboundary harms and risks that transcend national jurisdictions. Drawing on contemporary AI risk analyses, we argue that such harms are structurally embedded in global AI supply chains and are likely to escalate in frequency and severity due to cross-border deployment, data infrastructures, and uneven national oversight capacities. Consequently, territorially bounded liability regimes are increasingly inadequate. Using a comparative and interdisciplinary approach, this paper examines compensation and liability frameworks from high-risk transnational domains - including vaccine injury schemes, systemic financial risk governance, commercial nuclear liability, and international environmental regimes - to distill transferable legal design principles such as strict liability, risk pooling, collective risk-sharing, and liability channelling, while highlighting potential structural constraints on their application to AI-related harms. Situated within an international order shaped more by AI arms race dynamics than cooperative governance, the paper outlines the contours of a global AI accountability and compensation architecture, emphasizing the tension between geopolitical rivalry and the collective action required to govern transboundary AI risks effectively.

</details>


### [284] [Ethical Risks in Deploying Large Language Models: An Evaluation of Medical Ethics Jailbreaking](https://arxiv.org/abs/2601.12652)
*Chutian Huang,Dake Cao,Jiacheng Ji,Yunlou Fan,Chengze Yan,Hanhui Xu*

Main category: cs.CY

TL;DR: 该研究针对中文医疗伦理场景，评估了主流大语言模型对越狱攻击的防御能力，发现模型在医疗伦理领域存在系统性安全漏洞，攻击成功率高达82.1%。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全评估主要关注公共安全和西方文化规范，缺乏针对中文医疗伦理这一高风险领域的专门评估。恶意提示工程（越狱攻击）可能诱导模型绕过安全机制，在医疗伦理领域造成严重风险。

Method: 采用"角色扮演+场景模拟+多轮对话"的DeepInception框架，评估了7个主流模型（如GPT-5、Claude-Sonnet-4-Reasoning、DeepSeek-R1）。测试聚焦8个高风险主题（包括商业代孕、器官交易等），使用分层评分矩阵量化攻击成功率（ASR）和ASR增益。

Result: 模型防御出现系统性崩溃：虽然基线合规性高，但越狱攻击成功率高达82.1%，ASR增益超过80个百分点。Claude-Sonnet-4-Reasoning表现最稳健，而Gemini-2.5-Pro、GPT-4.1等5个模型近乎完全失效，ASR在96%-100%之间。

Conclusion: 当前大语言模型在医疗伦理场景中极易受上下文操纵，往往优先考虑"帮助性"而非安全约束。建议从结果监督转向过程监督，实施多因素身份验证，建立跨模型"联合防御"机制以增强安全性。

Abstract: Background: While Large Language Models (LLMs) have achieved widespread adoption, malicious prompt engineering specifically "jailbreak attacks" poses severe security risks by inducing models to bypass internal safety mechanisms. Current benchmarks predominantly focus on public safety and Western cultural norms, leaving a critical gap in evaluating the niche, high-risk domain of medical ethics within the Chinese context. Objective: To establish a specialized jailbreak evaluation framework for Chinese medical ethics and to systematically assess the defensive resilience and ethical alignment of seven prominent LLMs when subjected to sophisticated adversarial simulations. Methodology: We evaluated seven prominent models (e.g., GPT-5, Claude-Sonnet-4-Reasoning, DeepSeek-R1) using a "role-playing + scenario simulation + multi-turn dialogue" vector within the DeepInception framework. The testing focused on eight high-risk themes, including commercial surrogacy and organ trading, utilizing a hierarchical scoring matrix to quantify the Attack Success Rate (ASR) and ASR Gain. Results: A systemic collapse of defenses was observed, whereas models demonstrated high baseline compliance, the jailbreak ASR reached 82.1%, representing an ASR Gain of over 80 percentage points. Claude-Sonnet-4-Reasoning emerged as the most robust model, while five models including Gemini-2.5-Pro and GPT-4.1 exhibited near-total failure with ASRs between 96% and 100%. Conclusions: Current LLMs are highly vulnerable to contextual manipulation in medical ethics, often prioritizing "helpfulness" over safety constraints. To enhance security, we recommend a transition from outcome to process supervision, the implementation of multi-factor identity verification, and the establishment of cross-model "joint defense" mechanisms.

</details>


### [285] [AI-generated data contamination erodes pathological variability and diagnostic reliability](https://arxiv.org/abs/2601.12946)
*Hongyu He,Shaowen Xiang,Ye Zhang,Yingtao Zhu,Jin Zhang,Hao Deng,Emily Alsentzer,Qingyu Chen,Kun-Hsing Yu,Andrew Marmenshall,Tingting Chen,Srinivas Anumasa,Daniel Ebner,Dean Ho,Kee Yuan Ngiam,Ching-Yu Cheng,Dianbo Liu*

Main category: cs.CY

TL;DR: 生成式AI在医疗记录中产生合成内容，导致未来模型训练数据污染，造成病理变异性和诊断可靠性快速退化，罕见关键发现消失，虚假诊断信心掩盖了准确性下降


<details>
  <summary>Details</summary>
Motivation: 生成式AI在医疗记录中快速产生合成内容，形成反馈循环，未来模型面临训练数据污染风险，但AI生成数据污染的临床后果尚未被探索

Method: 分析超过80万个合成数据点，涵盖临床文本生成、视觉语言报告和医学图像合成；通过盲法医师评估验证结果；系统评估三种缓解策略

Result: 在没有强制人工验证的情况下，自我参照循环导致病理变异性和诊断可靠性快速退化；罕见关键发现（如气胸和积液）从AI生成内容中消失；人口统计表示偏向中年男性表型；虚假诊断信心掩盖退化，虚假保证率增至40%；AI生成文档在两代后临床无用；合成数据量扩展无法防止崩溃，真实数据与质量感知过滤混合可有效保持多样性

Conclusion: 如果没有政策强制的人工监督，生成式AI的部署可能会破坏其依赖的医疗数据生态系统；需要混合真实数据和质量感知过滤来保持数据多样性

Abstract: Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. Here, we show that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analysing more than 800,000 synthetic data points across clinical text generation, vision-language reporting, and medical image synthesis, we find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. We systematically evaluate three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, our results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon.

</details>


### [286] [ACE-Align: Attribute Causal Effect Alignment for Cultural Values under Varying Persona Granularities](https://arxiv.org/abs/2601.12962)
*Jiatang Luo,Bingbing Xu,Rongxin Chen,Xiaoyan Zhao,Yang Zhang,Liang Pang,Zhiyong Huang,Tat-Seng Chua,Huawei Shen*

Main category: cs.CY

TL;DR: ACE-Align是一个基于因果效应的框架，通过分析特定人口属性如何影响不同文化价值观，而非将文化群体视为同质，来解决大语言模型文化价值观对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将文化群体视为同质，忽视了由交叉人口属性引起的群体内异质性，导致在不同人物角色粒度下行为不稳定。需要一种能更好处理文化多样性并提升社会公平性的对齐方法。

Method: 提出ACE-Align（属性因果效应对齐）框架，通过因果效应分析特定人口属性如何影响不同文化价值观，而非将每个文化视为同质群体。使用性别、教育、居住地和婚姻状况四个属性来定义人物角色，并通过指定属性数量来实例化粒度。

Result: 在横跨五大洲14个国家的评估中，ACE-Align在所有人物角色粒度下均优于基线方法。同时提高了地理公平性，将高资源与低资源地区之间的平均对齐差距从9.81分降至4.92分，其中非洲地区获得最大平均增益（+8.48分）。

Conclusion: ACE-Align通过因果效应框架有效解决了文化价值观对齐中的群体内异质性问题，在不同人物角色粒度下表现稳定，显著提升了地理公平性，特别是对低资源地区有更好的支持。

Abstract: Ensuring that large language models (LLMs) respect diverse cultural values is crucial for social equity. However, existing approaches often treat cultural groups as homogeneous and overlook within-group heterogeneity induced by intersecting demographic attributes, leading to unstable behavior under varying persona granularity. We propose ACE-Align (Attribute Causal Effect Alignment), a causal-effect framework that aligns how specific demographic attributes shift different cultural values, rather than treating each culture as a homogeneous group. We evaluate ACE-Align across 14 countries spanning five continents, with personas specified by subsets of four attributes (gender, education, residence, and marital status) and granularity instantiated by the number of specified attributes. Across all persona granularities, ACE-Align consistently outperforms baselines. Moreover, it improves geographic equity by reducing the average alignment gap between high-resource and low-resource regions from 9.81 to 4.92 points, while Africa shows the largest average gain (+8.48 points). Code is available at https://github.com/Wells-Luo/ACE-Align.

</details>


### [287] [Sticky Help, Bounded Effects: Session-by-Session Analytics of Teacher Interventions in K-12 Classrooms](https://arxiv.org/abs/2601.13520)
*Qiao Jin,Conrad Borchers,Ashish Gurung,Sean Jackson,Sameeksha Agarwal,Cancan Wang,YiChen Yu,Pragati Maheshwary,Vincent Aleven*

Main category: cs.CY

TL;DR: 教师帮助具有"粘性"特征：先前获得帮助的学生更可能再次获得帮助，但帮助的学习效益主要局限于当前课堂，未能延伸到后续技能习得。


<details>
  <summary>Details</summary>
Motivation: 研究教师如何在技术支持的课堂中分配有限的即时支持资源，特别是学生的先前帮助历史和当前参与状态如何影响教师决策，以及教师帮助的学习效益是否能延伸到当前课堂之外。

Method: 首先访谈9名K-12数学教师确定决策因素，然后分析MATHia智能辅导系统中339名学生、14个班级的140万次学生-系统交互数据，将教师记录的帮助事件与细粒度参与状态关联，使用混合效应模型和交叉滞后面板分析。

Result: 1. 先前获得帮助的学生更可能再次获得帮助（即使控制当前参与状态）；2. 教师帮助在多个课堂会话中持续发生，而空闲行为未获得持续关注；3. 帮助与当前会话内的即时学习相关，但未能预测后续会话的技能习得。

Conclusion: 教师帮助具有"粘性"特征，倾向于重复支持先前帮助过的学生，但其可测量的学习效益主要局限于当前课堂。建议设计实时分析工具跟踪注意力覆盖，突出关注不足的学生，以实现更公平有效的教师注意力分配。

Abstract: Teachers' in-the-moment support is a limited resource in technology-supported classrooms, and teachers must decide whom to help and when during ongoing student work. However, less is known about how students' prior help history (whether they were helped earlier) and their engagement states (e.g., idle, struggle) shape teachers' decisions, and whether observed learning benefits associated with teacher help extend beyond the current class session. To address these questions, we first conducted interviews with nine K-12 mathematics teachers to identify candidate decision factors for teacher help. We then analyzed 1.4 million student-system interactions from 339 students across 14 classes in the MATHia intelligent tutoring system by linking teacher-logged help events with fine-grained engagement states. Mixed-effects models show that students who received help earlier were more likely to receive additional help later, even after accounting for current engagement state. Cross-lagged panel analyses further show that teacher help recurred across sessions, whereas idle behavior did not receive sustained attention over time. Finally, help coincided with immediate learning within sessions, but did not predict skill acquisition in later sessions, as estimated by additive factor modeling. These findings suggest that teacher help is "sticky" in that it recurs for previously supported students, while its measurable learning benefits in our data are largely session-bound. We discuss implications for designing real-time analytics that track attention coverage and highlight under-visited students to support a more equitable and effective allocation of teacher attention.

</details>


### [288] [Impact Matters! An Audit Method to Evaluate AI Projects and their Impact for Sustainability and Public Interest](https://arxiv.org/abs/2601.13936)
*Theresa Züger,Laura State,Lena Winter*

Main category: cs.CY

TL;DR: 提出Impact-AI方法，一种基于公共利益和可持续性框架的定性审计方法，用于评估AI项目的实际社会影响


<details>
  <summary>Details</summary>
Motivation: 当前AI"向善"项目缺乏透明度，目标不明确，且缺少对其社会和环境实际影响的评估，需要建立有效的评估框架

Method: 提出公共利益和可持续性作为监管双重概念框架，开发Impact-AI方法——基于访谈的定性审计方法，评估项目的治理结构、变革理论、AI模型和数据特征，以及社会、环境和经济影响

Result: 开发了可重复使用的Impact-AI方法蓝图，包含评估标准目录，能够生成可供公民社会广泛讨论的可访问输出结果

Conclusion: Impact-AI方法既能促进公众对AI"向善"主张的讨论，又能支持那些声称促进公正和可持续发展的AI系统提高透明度

Abstract: The overall rapid increase of artificial intelligence (AI) use is linked to various initiatives that propose AI 'for good'. However, there is a lack of transparency in the goals of such projects, as well as a missing evaluation of their actual impacts on society and the planet. We close this gap by proposing public interest and sustainability as a regulatory dual-concept, together creating the necessary framework for a just and sustainable development that can be operationalized and utilized for the assessment of AI systems. Based on this framework, and building on existing work in auditing, we introduce the Impact-AI-method, a qualitative audit method to evaluate concrete AI projects with respect to public interest and sustainability. The interview-based method captures a project's governance structure, its theory of change, AI model and data characteristics, and social, environmental, and economic impacts. We also propose a catalog of assessment criteria to rate the outcome of the audit as well as to create an accessible output that can be debated broadly by civil society. The Impact-AI-method, developed in a transdisciplinary research setting together with NGOs and a multi-stakeholder research council, is intended as a reusable blueprint that both informs public debate about AI 'for good' claims and supports the creation of transparency of AI systems that purport to contribute to a just and sustainable development.

</details>


### [289] [Analyzing Far-Right Telegram Channels as Constituents of Information Autocracy in Russia](https://arxiv.org/abs/2601.14190)
*Polina Smirnova,Mykola Makhortykh*

Main category: cs.CY

TL;DR: 俄罗斯极右翼Telegram社区通过表情包和视觉叙事塑造政治人物形象，作为宣传共生产者，将国家信息与极端主义框架融合，为乌克兰战争提供意识形态基础。


<details>
  <summary>Details</summary>
Motivation: 研究俄罗斯极右翼Telegram社区如何通过表情包和视觉叙事参与政治宣传的共生产，这些群体在俄罗斯特别重要，因为它们为乌克兰战争提供了意识形态基础，并反映了政权向极端民族主义话语的逐渐转变。

Method: 从专家选定的极右翼Telegram频道收集20万张图像数据集，运用计算机视觉和无监督聚类技术，识别包含俄罗斯（普京、绍伊古）和外国政治家（泽连斯基、拜登、特朗普）的表情包，并揭示其表征中的重复视觉模式。

Result: 研究发现极右翼表情包作为宣传共生产工具，这些社区不仅重复官方信息，还产生自下而上的合法化和非法化叙事，与国家意识形态保持一致。通过将领导人描绘为英雄，将对手描绘为腐败或软弱，极右翼行为者成为俄罗斯信息专制中非正式的合法性共同创造者。

Conclusion: 极右翼Telegram社区在俄罗斯信息生态系统中扮演着宣传共生产者的关键角色，通过视觉叙事产生与国家意识形态一致的合法化和非法化框架，这些大规模、时间深度分析揭示的模式是小规模研究无法获得的。

Abstract: This study examines how Russian far-right communities on Telegram shape perceptions of political figures through memes and visual narratives. Far from passive spectators, these actors co-produce propaganda, blending state-aligned messages with their own extremist framings. In Russia, such groups are central because they articulate the ideological foundations of the war against Ukraine and reflect the regime's gradual drift toward ultranationalist rhetoric. Drawing on a dataset of 200,000 images from expert-selected far-right Telegram channels, the study employs computer vision and unsupervised clustering to identify memes featuring Russian (Putin, Shoigu) and foreign politicians (Zelensky, Biden, Trump) and to reveal recurrent visual patterns in their representation. By leveraging the large-scale and temporal depth of this dataset, the analysis uncovers differential patterns of legitimation and delegitimation across actors and over time. These insights are not attainable in smaller-scale studies. Preliminary findings show that far-right memes function as instruments of propaganda co-production. These communities do not simply echo official messages but generate bottom-up narratives of legitimation and delegitimation that align with state ideology. By framing leaders as heroic and opponents as corrupt or weak, far-right actors act as informal co-creators of authoritarian legitimacy within Russia's informational autocracy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [290] [Semidefinite Programming for Quantum Channel Learning](https://arxiv.org/abs/2601.12502)
*Mikhail Gennadievich Belov,Victor Victorovich Dubov,Vadim Konstantinovich Ivanov,Alexander Yurievich Maslov,Olga Vladimirovna Proshina,Vladislav Gennadievich Malyshkin*

Main category: cs.LG

TL;DR: 该论文研究如何从经典数据样本重建量子通道，当总保真度可表示为两个二次型之比时，可使用半定规划优化Choi矩阵，从而高效重建各种形式的量子通道。


<details>
  <summary>Details</summary>
Motivation: 研究从经典数据样本重建量子通道的问题，探索在总保真度可表示为两个二次型之比的情况下，如何利用凸优化方法高效解决量子通道重建问题。

Method: 采用半定规划方法，将保真度优化问题转化为关于Choi矩阵的凸优化问题，利用多种商用SDP求解器进行数值求解，并应用于投影算符重建问题。

Result: 测试了多种商用SDP求解器，均能成功重建不同形式的量子通道；发现重建得到的量子通道的Kraus秩通常只占其最大可能值的不到几个百分点，表明相对较小的Kraus秩量子通道足以描述实验观测的经典数据。

Conclusion: 半定规划为量子通道重建提供了一种高效的凸优化方法，重建得到的量子通道通常具有较小的Kraus秩，这为基于量子通道变换的经典计算模型提供了理论基础。

Abstract: The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.

</details>


### [291] [AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control](https://arxiv.org/abs/2601.11568)
*Quang-Hung Bui,Anh Son Ta*

Main category: cs.LG

TL;DR: AdaFRUGAL通过动态控制梯度分割的超参数（子空间比例ρ和更新频率T），自动优化FRUGAL框架，在保持性能的同时显著减少LLM训练的内存占用和计算时间。


<details>
  <summary>Details</summary>
Motivation: 现有FRUGAL框架虽然通过梯度分割减少了LLM训练的内存占用，但其静态超参数（子空间比例ρ和更新频率T）需要昂贵的手动调优，限制了框架的适应性和实用性。

Method: AdaFRUGAL引入两种动态控制机制：1）对子空间比例ρ采用线性衰减策略，逐步减少内存占用；2）基于损失感知的更新频率T调度，降低计算开销。

Result: 在英文C4、越南语VietVault的大规模预训练以及GLUE的微调实验中，AdaFRUGAL在保持与AdamW和静态FRUGAL相当性能的同时，显著减少了GPU内存占用和训练时间。

Conclusion: AdaFRUGAL为资源受限的LLM训练提供了一个更实用、自主的解决方案，实现了内存、计算时间和模型性能之间的良好权衡。

Abstract: Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($ρ$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $ρ$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.

</details>


### [292] [Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces](https://arxiv.org/abs/2601.11572)
*Timo Aukusti Laine*

Main category: cs.LG

TL;DR: 该论文使用线性代数和哈密顿形式等数学工具分析LLM嵌入空间的结构，发现L2归一化约束使嵌入空间适合哈密顿分析，并探索了量子力学类比在理解LLM语义表示中的应用。


<details>
  <summary>Details</summary>
Motivation: 观察到LLM嵌入表现出不同的状态，暗示着离散的语义表示，这激发了使用数学工具（特别是线性代数和哈密顿形式）来分析语义关系，并借鉴量子力学系统的类比。

Method: 应用线性代数和哈密顿形式分析LLM嵌入空间，推导余弦相似度与嵌入向量扰动之间的关系，探索直接和间接语义转换，并从量子力学角度推导零点能量类似物，讨论与Koopman-von Neumann力学的潜在联系。

Result: 发现L2归一化约束使LLM嵌入空间具有适合哈密顿形式分析的结构，建立了余弦相似度与嵌入向量扰动之间的数学关系，并成功推导出量子力学中的零点能量类似物。

Conclusion: 这种方法为深入理解LLM提供了有前景的途径，可能有助于开发减少幻觉的新方法，尽管其解释需要谨慎考虑。

Abstract: We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.

</details>


### [293] [GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment](https://arxiv.org/abs/2601.11574)
*Lukas Abrie Nel*

Main category: cs.LG

TL;DR: GRADE方法使用Gumbel-Softmax重参数化和直通估计替代高方差的策略梯度方法，在LLM对齐任务中实现了更稳定、更有效的训练。


<details>
  <summary>Details</summary>
Motivation: 基于人类反馈的强化学习（RLHF）已成为对齐大型语言模型的主要范式，但PPO等策略梯度方法存在梯度估计方差高、需要精细超参数调优和大量计算资源的问题。

Method: GRADE方法使用Gumbel-Softmax重参数化结合直通估计（GRADE-STE），通过离散token采样过程的可微分松弛替代高方差策略梯度估计，实现从奖励信号通过生成token到模型参数的端到端梯度流动。

Result: 在IMDB数据集的情感控制文本生成任务中，GRADE-STE获得0.763±0.344的测试奖励，优于PPO的0.510±0.313和REINFORCE的0.617±0.378，相对PPO提升50%。GRADE-STE的梯度方差比REINFORCE低14倍以上，训练动态稳定。

Conclusion: GRADE为LLM对齐提供了一个更简单、更稳定、更有效的强化学习替代方案，其改进在保留数据上具有良好泛化性。

Abstract: Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.

</details>


### [294] [Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.11604)
*Jonaid Shianifar,Michael Schukat,Karl Mason*

Main category: cs.LG

TL;DR: Hindsight Preference Replay (HPR) 是一种简单的回放增强策略，通过为存储的转移数据重新标记替代偏好，在不改变CAPQL架构的情况下提高多目标强化学习的性能。


<details>
  <summary>Details</summary>
Motivation: CAPQL方法在特定偏好下收集的数据无法被其他偏好的训练使用，导致数据利用率低下。需要一种方法来更有效地利用跨偏好空间的监督信号。

Method: 提出Hindsight Preference Replay (HPR)策略，对存储的转移数据进行回顾性重新标记，为每个转移数据分配替代偏好，从而在不改变CAPQL架构或损失函数的情况下，增加偏好单纯形上的监督密度。

Result: 在6个MO-Gymnasium运动任务上评估，使用300000步固定预算，HPR-CAPQL在5个环境中提高了超体积(HV)，在4个环境中提高了期望效用(EUM)。在mo-humanoid-v5任务中，EUM从323±125提高到1613±464，HV从0.52M提高到9.63M。

Conclusion: HPR是一种简单而有效的回放增强策略，能够显著提高多目标强化学习的性能，特别是在复杂环境中，通过更有效地利用跨偏好的数据来改善学习效果。

Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\!\pm\!125$ to $1613\!\pm\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.

</details>


### [295] [A Multimodal Data Processing Pipeline for MIMIC-IV Dataset](https://arxiv.org/abs/2601.11606)
*Farzana Islam Adiba,Varsha Danduri,Fahmida Liza Piya,Ali Abbasi,Mehak Gupta,Rahmatollah Beheshti*

Main category: cs.LG

TL;DR: 开发了一个针对MIMIC-IV数据集的多模态数据处理管道，能够自动化处理结构化数据、临床笔记、波形和影像数据，显著减少处理时间并提高研究可重复性。


<details>
  <summary>Details</summary>
Motivation: MIMIC-IV数据集包含多种模态的医疗数据，但现有处理工具要么只针对少数模态，要么不支持任意的下游应用，需要大量人工预处理和对齐工作。

Method: 扩展了之前流行的单模态管道，开发了一个全面且可定制的多模态管道，能够系统整合各种模态，实现自动化队列选择、跨模态时间对齐，并生成适合静态和时间序列下游应用的标准输出格式。

Result: 开发了一个完整的处理管道，包括代码、简单UI和Python包，支持选择性集成（含嵌入），显著减少了多模态数据处理时间，增强了基于MIMIC研究的可重复性。

Conclusion: 该多模态管道为MIMIC-IV数据集的研究提供了高效、可重复的处理工具，解决了多模态数据整合的挑战，促进了临床机器学习研究的发展。

Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.

</details>


### [296] [Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction](https://arxiv.org/abs/2601.11609)
*Weinuo Ou*

Main category: cs.LG

TL;DR: 提出ApCM模型解决LLMs缺乏有效运行时内存机制的问题


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型普遍缺乏有效的运行时内存机制，难以适应动态和个性化的交互需求

Method: 提出一种新颖的神经记忆存储架构——辅助预测压缩记忆模型（ApCM模型）

Result: 论文摘要未提供具体实验结果

Conclusion: 通过ApCM模型为LLMs提供有效的运行时内存机制，以更好地适应动态个性化交互

Abstract: Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).

</details>


### [297] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

TL;DR: 该论文提出了一种改进的基于被动传感器的人类活动识别方法，通过聚类活动时间（早、中、晚）并编码到特征加权中，同时加入循环时间特征和用户位置跟踪，在多个真实数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，需要让老年人能够独立安全地在家中生活。使用被动红外传感器和门传感器等普遍存在的传感器来监测日常活动并促进预防性医疗干预变得越来越重要。然而，现有方法在有效利用时间信息方面存在挑战。

Method: 1. 将活动聚类为早晨、下午和夜晚三个时间段；2. 将这些时间聚类编码到特征加权方法中，计算不同的互信息矩阵；3. 扩展特征向量，加入一天中的时间和一周中的天作为循环时间特征；4. 添加跟踪用户位置的特征。

Result: 在四个真实世界数据集中的三个上，该方法在准确率和F1分数上都优于现有最先进方法。在数据量较少的情况下获得了最高的性能提升。

Conclusion: 该方法展示了开发有效智能家居解决方案以支持老年人就地养老的潜力，通过更好地利用时间信息和空间上下文改进了人类活动识别性能。

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [298] [A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia](https://arxiv.org/abs/2601.11615)
*Beyza Cinar,Louisa van den Boom,Maria Maleshkova*

Main category: cs.LG

TL;DR: 这篇综述分析了基于连续血糖监测数据的机器学习模型在预测1型糖尿病患者低血糖事件方面的研究现状，比较了不同预测时间窗口下的模型性能。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病患者需要终身胰岛素治疗，但胰岛素治疗有导致低血糖的副作用。低血糖是血糖水平低于70mg/dL的危险状态，会增加死亡风险。机器学习模型可以通过预测低血糖事件并提供预防方法来改善糖尿病管理。

Method: 综述分析了基于连续血糖监测设备数据的机器学习模型，包括回归模型（预测血糖水平）和分类模型（识别低血糖事件）。比较了短期（15-120分钟）和长期（3-24小时以上）预测时间窗口下的模型性能，并探讨了四个关键问题：预测准确性时间范围、最佳模型类型、影响因素以及个性化对性能的影响。

Result: 1）1小时以内的预测时间窗口提供最佳结果；2）传统机器学习方法在分类任务中表现最佳，深度学习在回归任务中表现最佳，单一模型无法在多个预测时间窗口上实现充分分类；3）模型性能受多变量数据集和输入序列长度影响；4）个人数据能提升性能，但由于数据质量有限，基于人群的模型更受青睐。

Conclusion: 机器学习模型在预测1型糖尿病患者低血糖事件方面具有潜力，但存在局限性。最佳预测时间窗口为1小时内，不同类型的模型在不同任务中表现各异，多变量数据和适当的输入序列长度对性能有重要影响。虽然个性化能提升性能，但数据质量限制使得基于人群的模型更具实用性。

Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.

</details>


### [299] [Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective](https://arxiv.org/abs/2601.11616)
*Feilong Liu*

Main category: cs.LG

TL;DR: MoE架构通过软分区表示空间来降低局部敏感性，增加表示的有效秩，专家Jacobian矩阵接近正交，Top-k路由产生低秩集中结构，全软路由产生高秩分散表示。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构对学习函数和表示几何特性的影响，理解路由机制如何作为表示空间的软分区形式，分析不同路由策略对几何结构的影响。

Method: 引入双Jacobian-PCA谱几何探针，通过Jacobian奇异值谱分析局部函数几何，通过加权PCA分析路由隐藏状态的表示几何。在可控的MLP-MoE设置下比较密集、Top-k和全软路由架构。

Result: MoE路由一致降低局部敏感性，专家局部Jacobian矩阵具有更小的主导奇异值和更快的谱衰减。加权PCA显示专家局部表示在更多主方向上分布方差，表明在相同输入分布下具有更高的有效秩。平均专家Jacobian矩阵接近正交，表明变换分解为低重叠的专家特定子空间。Top-k路由产生低秩、更集中的专家局部结构，全软路由产生更广泛、更高秩的表示。

Conclusion: MoE可被几何解释为函数空间的软分区，能够平坦化局部曲率同时重新分配表示方差，不同路由策略在几何特性上产生系统性差异。

Abstract: Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.

</details>


### [300] [Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention](https://arxiv.org/abs/2601.11618)
*Luis Rosario Freytes*

Main category: cs.LG

TL;DR: 本文提出了几何注意力（GA）框架，将注意力层分解为四个独立输入：载体、证据核规则、探针族和锚定/更新规则，为注意力机制提供了统一的形式化描述。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制（如Transformer中的softmax注意力）缺乏统一的形式化框架，难以进行系统性的比较和扩展。本文旨在建立一个几何注意力框架，将注意力机制的结构与建模选择分离，实现原理性的比较和扩展。

Method: 提出几何注意力（GA）框架，将注意力层分解为四个组件：1）有限载体（可寻址的索引）；2）证据核规则（如何从掩码原型分数和链接产生非负权重）；3）探针族（可接受的观测值）；4）锚定/更新规则（选择哪个代表性核以及如何应用）。探针族在核上诱导操作等价关系，锚定相对于该探针选择代表。

Result: 在标量关系工作表示和证据的乘法组合律下，可接受的链接族是指数族，产生Gibbs权重；行锚定包括softmax核族作为子机制。在商化一元行/列分数场后，剩余的交互分量允许秩r规范形式（Eckart-Young/SVD）；点积分数图实现相应的低秩交互机制。

Conclusion: 几何注意力框架将不变结构与建模选择分离，支持多头/混合核、基于计划的锚定（如熵最优传输/Sinkhorn）和一元算子（如FFN风格场）作为显式机制选择。这为注意力机制和基于注意力的架构提供了原理性的比较和扩展基础。

Abstract: Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.

</details>


### [301] [NoiseFormer -- Noise Diffused Symmetric Attention Transformer](https://arxiv.org/abs/2601.11619)
*Phani Kumar,Nyshadham,Jyothendra Varma,Polisetty V R K,Aditya Rathore*

Main category: cs.LG

TL;DR: 本文提出了一种名为噪声扩散对称注意力Transformer的新型统一模型架构，在保持对称注意力内存优势的同时，通过微小参数和计算开销提升模型性能，在GLUE基准任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型规模急剧增大，内存占用导致难以在单个GPU或AI加速器上运行，需要多设备计算从而增加成本。这促使需要采用稀疏注意力技术来减少模型参数规模。本文从分析对称点积注意力技术出发，旨在提升稀疏注意力模型的性能。

Method: 提出噪声扩散对称注意力Transformer架构，在保持对称注意力内存优势的基础上，通过引入微小参数和计算开销来增强模型性能。该方法基于GPT2基础模型进行验证，在GLUE基准任务上评估性能。

Result: 实验结果表明，提出的模型在准确率方面表现介于普通对称注意力和GPT2基础模型之间，同时相对于基础模型实现了显著的模型规模缩减。模型在保持内存增益的同时，在准确率和推理时间采样方面都有提升。

Conclusion: 噪声扩散对称注意力Transformer是一种有效的模型架构，能够在保持对称注意力内存优势的同时，通过微小开销实现性能提升，为大规模语言模型的高效部署提供了有前景的解决方案。

Abstract: Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.

</details>


### [302] [Verifying Physics-Informed Neural Network Fidelity using Classical Fisher Information from Differentiable Dynamical System](https://arxiv.org/abs/2601.11638)
*Josafat Ribeiro Leal Filho,Antônio Augusto Fröhlich*

Main category: cs.LG

TL;DR: 本文提出使用Fisher信息量$g_F^C$作为评估PINNs学习物理系统动力学完整性的新框架，通过比较PINN学习模型与原始解析模型的Fisher信息景观来量化PINN的保真度。


<details>
  <summary>Details</summary>
Motivation: 当前PINNs在解决微分方程和建模物理系统方面表现出色，但缺乏量化PINN是否完整捕获系统动力学行为（而不仅仅是轨迹预测）的严格方法。需要一种能够评估PINN是否准确学习到系统底层动力学特性的评估框架。

Method: 提出使用针对可微动力系统的Fisher信息量$g_F^C$作为评估指标。该Fisher信息量测量确定性系统中的固有不确定性（如对初始条件的敏感性），与相空间曲率和状态空间演化的净拉伸作用相关。通过计算PINN学习模型和原始解析模型的Jacobian矩阵，比较两者的Fisher信息景观来量化PINN的保真度。以汽车动力学模型为例进行实验验证。

Result: 论文提出了完整的实验方法学，但摘要中未报告具体的实验结果。方法框架表明，如果PINN准确学习了底层动力学，那么从PINN学习模型推导出的Fisher信息景观应与原始解析模型相匹配，这标志着PINN不仅捕获了状态演化，还捕获了关键的几何和稳定性特性。

Conclusion: 提出的基于Fisher信息量$g_F^C$的框架为评估PINNs学习物理系统动力学的完整性提供了定量方法。通过比较PINN模型与原始模型的Fisher信息景观，可以全面评估PINN是否准确捕获了系统的复杂动力学特性，包括几何和稳定性属性。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations and modeling physical systems by embedding physical laws into the learning process. However, rigorously quantifying how well a PINN captures the complete dynamical behavior of the system, beyond simple trajectory prediction, remains a challenge. This paper proposes a novel experimental framework to address this by employing Fisher information for differentiable dynamical systems, denoted $g_F^C$. This Fisher information, distinct from its statistical counterpart, measures inherent uncertainties in deterministic systems, such as sensitivity to initial conditions, and is related to the phase space curvature and the net stretching action of the state space evolution. We hypothesize that if a PINN accurately learns the underlying dynamics of a physical system, then the Fisher information landscape derived from the PINN's learned equations of motion will closely match that of the original analytical model. This match would signify that the PINN has achieved comprehensive fidelity capturing not only the state evolution but also crucial geometric and stability properties. We outline an experimental methodology using the dynamical model of a car to compute and compare $g_F^C$ for both the analytical model and a trained PINN. The comparison, based on the Jacobians of the respective system dynamics, provides a quantitative measure of the PINN's fidelity in representing the system's intricate dynamical characteristics.

</details>


### [303] [Global Optimization By Gradient from Hierarchical Score-Matching Spaces](https://arxiv.org/abs/2601.11639)
*Ming Li*

Main category: cs.LG

TL;DR: 该论文提出了一种通过分数匹配获取梯度的方法，将带复杂约束的优化问题统一为无约束的分层优化目标，首次实现了使用严格梯度的确定性全局优化方法


<details>
  <summary>Details</summary>
Motivation: 梯度下降法存在局部最优性限制，且只能处理连续可微问题和简单凸约束问题。需要突破这些限制，实现更通用的全局优化方法

Method: 通过分数匹配获取梯度，将所有带复杂约束的优化问题统一为无约束的分层优化目标，使用确定性方法进行全局优化

Result: 首次实现了使用严格梯度的确定性全局优化方法，并通过简单构造和复杂实际实验验证了方法的有效性

Conclusion: 该方法不仅突破了传统梯度下降的限制，更重要的是揭示了全局优化与基于扩散的生成建模之间的深刻联系

Abstract: Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.

</details>


### [304] [Activation Sensitivity as a Unifying Principle for Post-Training Quantization](https://arxiv.org/abs/2601.11663)
*Bruce Changlong Xu*

Main category: cs.LG

TL;DR: 本文提出了一个统一的理论框架来理解后训练量化方法，通过形式化激活敏感度概念，将AWQ和GPTQ等不同方法解释为对敏感度的不同近似。


<details>
  <summary>Details</summary>
Motivation: 当前的后训练量化方法（如AWQ和GPTQ）虽然经验表现良好，但缺乏统一的理论框架，不清楚它们近似的是什么底层量。这些方法在概念上是分散的，需要建立统一的理论基础来理解和比较不同的量化方法。

Method: 通过一阶泰勒展开，形式化定义激活敏感度——通道扰动对损失的期望影响。敏感度自然表现为梯度加权激活的平方范数，这提供了一个原则性的通道重要性度量。在此框架下，AWQ和GPTQ可以被解释为在不同简化假设下恢复敏感度的互补近似。

Result: 建立了一个统一的理论框架，将激活敏感度作为核心概念，分析了敏感度度量的设计空间，连接了基于梯度的显著性、Fisher信息和基于Hessian的准则，并阐明了它们与经典剪枝方法（如OBD和OBS）的关系。

Conclusion: 本文为理解和比较后训练量化方法提供了概念基础，通过敏感度视角统一了不同的量化方法，而不是提出新的量化算法。该框架有助于更好地理解现有方法的理论基础和设计原则。

Abstract: Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.

</details>


### [305] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

TL;DR: IPEC是一种测试时增量原型增强分类器，通过利用先前查询样本信息优化原型估计，减少对初始支持集的依赖


<details>
  <summary>Details</summary>
Motivation: 传统基于度量的少样本学习方法在测试时假设批次独立性，无法利用先前批次积累的宝贵知识，限制了性能提升

Method: 提出IPEC方法：1）维护动态辅助集，选择性纳入高置信度查询样本；2）设计双重过滤机制评估样本质量；3）基于贝叶斯解释将支持集视为先验，辅助集视为数据驱动的后验；4）采用"预热-测试"两阶段推理协议

Result: 在多个少样本分类任务上验证了IPEC的优越性能，能够构建更稳定和具有代表性的原型

Conclusion: IPEC通过测试时增量学习有效减少对初始支持集的依赖，提升了少样本分类性能，为基于度量的少样本学习提供了新的测试时优化思路

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [306] [Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis](https://arxiv.org/abs/2601.11686)
*Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes*

Main category: cs.LG

TL;DR: 提出结合预测模型和LLM的混合框架，将多维度野火风险分析整合为结构化可操作报告


<details>
  <summary>Details</summary>
Motivation: 当前野火风险评估方法忽视实际运营需求，缺乏对第一响应者和消防服务的实用价值，需要多目标分析而非单一预测指标

Method: 开发混合框架：为每个风险维度（气象危险、点火活动、干预复杂性、资源调动）建立预测模型，然后使用大型语言模型（LLMs）将异质输出合成为结构化可操作报告

Result: 这是一个概念验证研究，提出了框架设计但尚未展示具体实施结果

Conclusion: 提出的混合框架有望改善野火风险评估的实用性和可操作性，通过整合多维度分析和LLM技术为应急响应提供更好的决策支持

Abstract: Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.

</details>


### [307] [jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation](https://arxiv.org/abs/2601.11719)
*Ho Fung Tsoi,Dylan Rankin*

Main category: cs.LG

TL;DR: jBOT是一种基于自蒸馏的预训练方法，专门用于CERN大型强子对撞机的喷注数据，通过结合局部粒子级蒸馏和全局喷注级蒸馏来学习支持异常检测和分类等下游任务的喷注表示。


<details>
  <summary>Details</summary>
Motivation: 自监督学习是一种无需标签即可学习特征表示的强大预训练方法，这些表示通常能捕捉数据的通用底层语义，并可在后续微调用于下游任务。本研究旨在为粒子物理中的喷注数据开发有效的预训练方法。

Method: jBOT是一种基于自蒸馏的预训练方法，结合了局部粒子级蒸馏和全局喷注级蒸馏。该方法在未标记的喷注数据上进行预训练，学习喷注的表示。

Result: 在未标记喷注上进行预训练会导致表示空间中出现涌现的语义类别聚类。当仅在背景喷注上预训练时，冻结嵌入中的聚类能够通过简单的基于距离的度量实现异常检测。此外，学习到的嵌入可以通过微调用于分类任务，相比从头开始训练的监督模型性能有所提升。

Conclusion: jBOT方法成功地为喷注数据开发了有效的自监督预训练框架，能够在表示空间中形成语义聚类，支持异常检测和分类等下游任务，且性能优于从头训练的监督模型。

Abstract: Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.

</details>


### [308] [Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis](https://arxiv.org/abs/2601.11789)
*Shenyang Deng,Boyao Liao,Zhuoli Ouyang,Tianyu Pang,Minhak Song,Yaoqing Yang*

Main category: cs.LG

TL;DR: 本文研究了SGD在病态优化中的"可疑对齐"现象，发现梯度与主导子空间的对齐呈现先降后升最终稳定的三阶段行为，并揭示了步长选择如何影响这一现象。


<details>
  <summary>Details</summary>
Motivation: 研究SGD在病态优化中的梯度对齐行为，解释为什么在高度对齐的主导子空间上的梯度更新反而无法有效降低损失，这一看似矛盾的现象被称为"可疑对齐"。

Method: 在高维二次设置中进行细粒度分析，提出步长条件理论，区分对齐减少和对齐增加的不同步长区间，并证明在充分病态条件下存在特定的步长区间。

Result: 发现自适应临界步长η_t*能区分对齐减少和对齐增加的不同步长区间；在高度对齐状态下，对齐具有自校正特性；在病态条件下，存在步长区间使得在批量子空间上的更新能降低损失而在主导子空间上的更新反而增加损失。

Conclusion: 对于恒定步长和大初始化，SGD会表现出明显的两阶段行为：初始对齐减少阶段，随后稳定在高对齐状态。这解释了为什么在主导子空间上的梯度更新无效，为理解SGD在病态优化中的行为提供了理论框架。

Abstract: This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $η_t^*$ separates alignment-decreasing ($η_t < η_t^*$) from alignment-increasing ($η_t > η_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.

</details>


### [309] [Shapelets-Enriched Selective Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2601.11821)
*Shivani Tomar,Seshu Tirupathi,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

TL;DR: 提出基于shapelet的选择性预测框架，识别时间序列中的关键不可靠区域，允许用户选择性丢弃不可靠预测，提高时间序列基础模型的实用性。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型在零样本预测中表现出色，但在某些关键数据区域的预测不可靠，限制了其在实际应用中的可用性，特别是当数据呈现独特趋势时。

Method: 使用shapelet识别时间序列中的关键不可靠区域，通过目标域验证集上的平移不变字典学习学习shapelet，利用基于距离的相似性度量来选择性丢弃不可靠预测。

Result: 在多样化基准时间序列数据集上的实验表明，该方法在零样本和全样本微调模型上分别平均减少22.17%和22.62%的总体误差，相比随机选择方法在某个数据集上分别提升21.41%和21.43%。

Conclusion: 提出的选择性预测框架能够有效识别时间序列中的不可靠预测区域，提高时间序列基础模型的实用性和可靠性，为用户提供更现实的模型能力评估。

Abstract: Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.

</details>


### [310] [MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization](https://arxiv.org/abs/2601.11827)
*Andrea Rubbi,Amir Akbarnejad,Mohammad Vali Sanian,Aryan Yazdan Parast,Hesam Asadollahzadeh,Arian Amani,Naveed Akhtar,Sarah Cooper,Andrew Bassett,Pietro Liò,Lassi Paavolainen,Sattar Vakili,Mo Lotfollahi*

Main category: cs.LG

TL;DR: MixFlow是一个条件流匹配框架，通过联合学习描述符条件的基础分布和流场，显著提升了条件生成模型在分布偏移下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的条件流基方法在训练条件之外难以有效外推，在分布偏移下实现鲁棒泛化仍然是条件生成建模的核心挑战。

Method: MixFlow采用最短路径流匹配，联合学习描述符条件的基础分布（建模为可学习的描述符依赖混合分布）和描述符条件的流场，支持平滑插值和外推到未见条件。

Result: 在多个领域（包括单细胞转录组数据中未见扰动的响应预测和高内涵显微镜药物筛选任务）中，MixFlow始终优于标准条件流匹配基线方法。

Conclusion: MixFlow提供了一个简单而强大的方法，可在异构领域中实现鲁棒、可泛化和可控的生成建模。

Abstract: Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.

</details>


### [311] [TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures](https://arxiv.org/abs/2601.11880)
*Yingxiao Zhang,Jiaxin Duan,Junfu Zhang,Ke Feng*

Main category: cs.LG

TL;DR: TF-CoDiT：首个基于扩散变换器的语言控制国债期货合成框架，通过离散小波变换和U形VAE处理低数据量问题，引入金融市场属性协议生成提示，在国债期货数据合成上表现出色。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在股票价格和订单流等金融时间序列数据合成方面已取得进展，但在国债期货数据合成方面仍缺乏探索。国债期货数据具有低交易量、市场依赖性和多变量分组相关性等特点，需要专门的方法来处理这些挑战。

Method: 提出TF-CoDiT框架：1）将多通道一维时间序列转换为离散小波变换系数矩阵以处理低数据量问题；2）设计U形VAE分层编码跨通道依赖关系到潜变量，并通过解码桥接潜空间和DWT空间，实现潜扩散生成；3）引入金融市场属性协议（FinMAP）标准化市场动态描述，从7/8个视角识别17/23个经济指标生成提示。

Result: 收集2015-2025年四种国债期货数据，定义从一周到四个月不同时长的合成任务。实验显示TF-CoDiT能生成高度真实的数据，与真实数据的误差最大为MSE 0.433和MAE 0.453。进一步研究证明TF-CoDiT在不同合约和时间跨度上具有鲁棒性。

Conclusion: TF-CoDiT是首个专门针对国债期货数据合成的扩散变换器框架，通过离散小波变换、U形VAE和金融市场属性协议有效解决了国债期货数据的特殊挑战，在数据合成质量和鲁棒性方面表现出色。

Abstract: Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.

</details>


### [312] [Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach](https://arxiv.org/abs/2601.11883)
*Chaoqi Jia,Longkun Guo,Kewen Liao,Zhigang Lu,Chao Chen,Jason Xue*

Main category: cs.LG

TL;DR: 该论文研究了带约束的k-center聚类问题，提出了基于支配匹配集变换的局部搜索框架，达到了最佳可能的2近似比。


<details>
  <summary>Details</summary>
Motivation: 传统k-center问题的最佳近似比为2，任何改进都会导致P=NP。在实际应用中，实例级别的"不能链接"和"必须链接"约束作为背景知识被引入，但通用CL约束显著增加了近似难度。虽然之前工作表明不相交CL集合允许常数因子近似，但局部搜索能否在此设置下达到这样的保证仍然是一个开放问题。

Method: 提出了一个新颖的局部搜索框架，基于将约束k-center问题转化为支配匹配集问题，通过这种变换实现了最佳可能的近似保证。

Result: 算法达到了最佳可能的2近似比，在真实世界和合成数据集上的实验结果表明，该算法在解质量上优于基线方法。

Conclusion: 通过将约束k-center问题转化为支配匹配集问题，成功开发了一个局部搜索框架，解决了该领域的一个开放问题，实现了理论上的最佳近似比，并在实践中表现出优越性能。

Abstract: Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - ε would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.

</details>


### [313] [From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs](https://arxiv.org/abs/2601.11890)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

TL;DR: 本文提出了一种基于加权凹覆盖目标U_ρ的强化学习探索策略，通过梯度方法主动引导状态-动作占用分布，实现从平均覆盖到最坏情况覆盖的统一框架。


<details>
  <summary>Details</summary>
Motivation: 在无奖励马尔可夫决策过程中，不同状态-动作对具有不同的重要性或难度，需要主动构建探索策略。现有方法缺乏统一的框架来平衡探索的优先级。

Method: 提出参数化凹覆盖目标函数U_ρ，定义在状态-动作占用测度上。该函数具有凹性（捕捉过度探索的收益递减）和简单梯度形式（便于优先探索未充分探索的状态-动作对）。开发基于梯度的算法主动引导占用分布。

Result: U_ρ框架统一了多种现有目标：基于散度的边缘匹配、加权平均覆盖和最坏情况（极小极大）覆盖。随着ρ增大，探索策略越来越强调最少探索的状态-动作对，在极限情况下恢复最坏情况覆盖行为。

Conclusion: 提出的加权凹覆盖目标为强化学习探索提供了统一的数学框架，通过参数ρ灵活控制探索策略，从平均覆盖平滑过渡到最坏情况覆盖，为主动探索提供了理论和方法基础。

Abstract: Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_ρ$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_ρ$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_ρ$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $ρ$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.

</details>


### [314] [DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models](https://arxiv.org/abs/2601.11895)
*Pareesa Ameneh Golnari,Adarsh Kumarappan,Wen Wen,Xiaoyu Liu,Gabriel Ryan,Yuting Sun,Shengyu Fu,Elsie Nallipogu*

Main category: cs.LG

TL;DR: DevBench是一个基于真实开发者遥测数据的代码补全基准测试，包含1800个评估实例，涵盖6种编程语言和6个任务类别，旨在评估LLM在实际开发场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有代码补全基准测试缺乏生态效度，容易受到训练数据污染的影响，且无法提供详细的诊断信息。需要创建一个基于真实开发者行为的基准测试，为模型选择和改进提供可操作的见解。

Method: 从真实开发者遥测数据中提取评估实例，涵盖6种编程语言和6个任务类别（如API使用、代码目的理解等）。采用功能正确性、相似度指标和LLM评估者（关注有用性和上下文相关性）相结合的多维度评估方法。

Result: 评估了9个最先进的模型，揭示了它们在语法精度、语义推理和实际效用方面的差异。基准测试提供了传统基准测试中缺失但实际部署和针对性模型开发所必需的详细诊断信息。

Conclusion: DevBench通过基于真实开发者数据的评估，为LLM在代码补全任务上的性能提供了更准确、更实用的评估框架，能够指导模型选择和针对性改进。

Abstract: DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.

</details>


### [315] [Task-tailored Pre-processing: Fair Downstream Supervised Learning](https://arxiv.org/abs/2601.11897)
*Jinwon Sohn,Guang Lin,Qifan Song*

Main category: cs.LG

TL;DR: 本文提出了一种新的公平监督学习预处理方法，通过考虑公平性与效用之间的权衡，为下游模型提供理论保证，相比现有方法在多个数据集上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有公平监督学习预处理方法存在两种主要类别：数据公平性和任务定制公平性。作者认为数据公平性方法从HGR相关性的角度施加了过强的正则化，因此需要设计一种专门针对监督学习任务的预处理方法。

Method: 提出了一种新颖的预处理框架，考虑公平性与效用之间的权衡来获得预处理映射。研究任意下游监督模型在转换数据上的行为，找到保证其公平性改进和效用保持的充分条件。

Result: 通过表格和图像数据集的比较研究，显示该框架在保持多个下游模型间一致权衡方面优于现有竞争模型。特别是对于计算机视觉数据，该方法仅改变与核心机器学习任务相关的必要语义特征来实现公平性。

Conclusion: 本文提出的任务定制预处理方法为下游模型提供了理论保证，在公平性和效用之间实现了更好的权衡，相比现有方法在多种数据类型上表现更优。

Abstract: Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.

</details>


### [316] [Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924)
*Ming Shi*

Main category: cs.LG

TL;DR: 研究合作式随机多臂老虎机问题，在对抗性腐败和有限验证条件下，分析不同信息共享协议如何影响团队遗憾，发现腐败预算Γ会因通信方式不同而放大到NΓ倍。


<details>
  <summary>Details</summary>
Motivation: 研究在对抗性腐败环境下，多智能体合作学习中的通信协议如何影响腐败效应的放大问题，探索如何在腐败和有限验证条件下实现有效的团队决策。

Method: 提出通信-腐败耦合框架，分析三种信息共享协议（原始样本共享、统计摘要共享、仅推荐共享），通过协议诱导的多重性函数量化有效腐败水平，建立团队遗憾界限。

Result: 发现原始样本共享可能遭受N倍的腐败惩罚放大，而摘要共享和仅推荐共享能保持O(Γ)的未放大腐败项，达到中心化速率的团队遗憾。验证机制在高腐败区域是必要的，且一旦超过识别阈值就能恢复可学习性。

Conclusion: 通信协议显著影响对抗性腐败在多智能体系统中的传播效应，适当的共享策略（如摘要或推荐共享）能避免腐败放大，验证机制在极端腐败条件下对恢复可学习性至关重要。

Abstract: We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.

</details>


### [317] [Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration](https://arxiv.org/abs/2601.11953)
*Shiqing Gao,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: MICE方法通过引入内在成本估计来缓解约束强化学习中的成本函数低估问题，显著减少训练期间的约束违反，同时保持策略性能。


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习算法在训练期间经常出现显著的约束违反，限制了其在安全关键场景中的应用。作者发现成本价值函数的低估是导致这些违反的关键因素。

Method: 提出记忆驱动的内在成本估计方法，受闪光灯记忆启发构建记忆模块存储不安全状态，将内在成本定义为当前状态访问这些风险区域的伪计数，并采用偏差校正策略的外在-内在成本价值函数。

Result: MICE显著减少了约束违反，同时保持了与基线相当的策略性能。理论分析提供了成本价值函数的收敛保证和MICE更新的最坏情况约束违反界限。

Conclusion: MICE通过解决成本价值函数低估问题，有效提升了约束强化学习的安全性，为安全关键应用提供了更可靠的解决方案。

Abstract: Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.

</details>


### [318] [Data-centric Prompt Tuning for Dynamic Graphs](https://arxiv.org/abs/2601.11954)
*Yufei Peng,Cheng Yang,Zhengjie Fan,Chuan Shi*

Main category: cs.LG

TL;DR: DDGPrompt是一个数据中心的提示框架，通过定义统一的节点表达特征矩阵和三个提示矩阵（时间偏置、边权重、特征掩码）来调整预训练节点嵌入，使其更好地适应不同的下游任务，在少样本和冷启动场景下显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统动态图方法通常通过动态链接预测预训练模型，然后将节点时间嵌入直接应用于下游任务。但由于下游任务差异大，这种方法在少样本设置下性能下降明显。现有提示方法要么与特定模型架构或预训练任务强耦合，要么只关注修改节点或时间特征而忽略空间结构信息，导致表达能力有限和性能下降。

Method: 提出DDGPrompt框架：1) 定义统一的节点表达特征矩阵，聚合每个节点的所有相关时间和结构信息；2) 引入三个提示矩阵（时间偏置、边权重、特征掩码）来完全调整特征矩阵，实现节点嵌入的任务特定适应。

Result: 在四个公共动态图数据集上，在严格的少样本设置下进行评估。实验结果表明，该方法在标签有限和冷启动条件下显著优于传统方法和现有提示方法。

Conclusion: DDGPrompt通过数据中心的提示框架有效优化预训练节点嵌入，能够更好地适应多样化的下游任务，特别是在少样本和冷启动场景下表现出色。

Abstract: Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.

</details>


### [319] [R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning](https://arxiv.org/abs/2601.11960)
*Jingchu Wang,Bingbing Xu,Yige Yuan,Bin Xie,Xiaoqian Sun,Huawei Shen*

Main category: cs.LG

TL;DR: R²PO提出了一种新的强化学习方法，通过引入轻量级的残差Rollout-Head来解耦训练轨迹和推理响应，解决现有方法中单一策略导致探索不足的问题，显著提升了LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法使用单一策略同时生成推理响应和训练优化轨迹，导致生成稳定推理响应与多样化训练轨迹之间的目标冲突，造成探索不足，从而损害推理能力。

Method: 提出R²PO（Residual Rollout Policy Optimization）方法，在策略之上引入轻量级的残差Rollout-Head，将训练轨迹与推理响应解耦，在训练期间实现可控的轨迹多样化，同时保持推理生成的稳定性。

Result: 在多个基准测试中，该方法始终优于基线，在MATH-500上平均准确率提升3.1%，在APPS上提升2.4%，同时减少了格式错误并缓解了长度偏差，实现了稳定优化。

Conclusion: R²PO通过解耦训练轨迹和推理响应，有效解决了现有强化学习方法中的探索不足问题，显著提升了LLM的推理能力，为强化学习在LLM推理优化中的应用提供了新思路。

Abstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.

</details>


### [320] [One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints](https://arxiv.org/abs/2601.11977)
*Ren He,Yinliang Xu,Jinfeng Wang,Jeremy Watson,Jian Song*

Main category: cs.LG

TL;DR: 提出MoE-Encoder模块，通过稀疏专家混合层增强预训练时序模型，解决电力系统多变量预测中的复杂依赖和隐私约束问题。


<details>
  <summary>Details</summary>
Motivation: 电力系统预测涉及多变量时间序列，具有复杂的依赖关系和严格的跨区域隐私约束。传统方法需要大量专家知识且难以泛化到不同部署场景，而现有预训练模型的零样本性能在领域特定任务上有限。

Method: 提出MoE-Encoder模块，在标记化和编码之间注入稀疏专家混合层。该方法将多变量预测转化为专家引导的单变量任务，有效捕捉变量间关系，并支持联邦学习环境中的本地化训练和轻量级参数共享。

Result: 在公开多变量数据集上的实验表明，MoE-Encoder显著提高了预测准确性。联邦环境模拟显示，仅传输MoE-Encoder参数即可高效适应新区域，性能下降最小。

Conclusion: MoE-Encoder为时序基础模型提供了可扩展且隐私感知的扩展方案，能够有效解决电力系统预测中的复杂依赖和隐私约束问题。

Abstract: Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.

</details>


### [321] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 提出EVO算法，利用极值理论处理强化学习中的极端风险事件，减少约束违反


<details>
  <summary>Details</summary>
Motivation: 传统约束强化学习基于期望约束，忽略了尾部分布中的罕见但高影响极端事件（如黑天鹅事件），可能导致严重约束违反

Method: 提出极端值策略优化(EVO)算法：1) 利用极值理论建模极端奖励和成本样本；2) 引入极端分位数优化目标捕获成本尾部分布的极端样本；3) 提出极端优先回放机制，放大罕见但高影响极端样本的学习信号

Result: 理论证明：1) 建立策略更新期间期望约束违反的上界；2) 在零违反分位数水平保证严格约束满足；3) EVO比期望方法有更低的约束违反概率，比分位数回归方法有更低的方差。实验表明EVO显著减少训练期间的约束违反，同时保持与基线相当的策略性能

Conclusion: EVO算法通过建模极端事件有效解决了约束强化学习中的尾部风险问题，在保证性能的同时显著降低了约束违反风险

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [322] [Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models](https://arxiv.org/abs/2601.12083)
*Siru Zhong,Junjie Qiu,Yangyu Wu,Yiqiu Liu,Yuanpeng He,Zhongwen Rao,Bin Yang,Chenjuan Guo,Hao Xu,Yuxuan Liang*

Main category: cs.LG

TL;DR: FactoST-v2是一个增强的因子化时空基础模型框架，通过分离通用时间学习和领域特定空间适应，实现全权重迁移和任意长度泛化，在零样本和少样本场景中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 时空基础模型虽然承诺跨数据集泛化能力，但联合时空预训练计算成本高，且难以处理领域特定空间模式的异质性。为了解决这些问题，作者在先前会议版本基础上扩展提出了FactoST-v2。

Method: FactoST-v2采用因子化框架，将通用时间学习与领域特定空间适应解耦。第一阶段使用随机序列掩码预训练简约的编码器主干，捕捉不变的时间动态，实现跨可变范围的概率分位数预测。第二阶段通过精简适配器，利用元自适应学习和提示快速注入空间感知能力。

Result: 在多个领域的综合评估表明，FactoST-v2在线性效率下达到最先进精度，在零样本和少样本场景中显著优于现有基础模型，并能与领域特定专家基线相媲美。

Conclusion: 这种因子化范式为实现真正通用的时空基础模型提供了实用、可扩展的路径，解决了计算成本和领域异质性问题。

Abstract: Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.

</details>


### [323] [Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate](https://arxiv.org/abs/2601.12091)
*Qian Tan,Lei Jiang,Yuting Zeng,Shuoyang Ding,Xiaohua Xu*

Main category: cs.LG

TL;DR: 研究发现大语言模型存在系统性西方中心偏见，中文提示仅将偏见转向东亚视角而非消除。作者提出多智能体文化辩论框架，通过赋予智能体不同文化身份并进行辩论，有效提升无偏见率。


<details>
  <summary>Details</summary>
Motivation: 现有研究存在两个主要问题：1）评估方法强制输出到预定义的文化类别，缺乏中立选项；2）缓解方法依赖昂贵的多文化语料库或缺乏明确文化表征的智能体框架。需要更有效的评估和缓解方法来解决LLM的西方中心偏见问题。

Method: 提出CEBiasBench中英双语基准和Multi-Agent Vote（MAV）评估框架，支持"无偏见"判断。为缓解偏见，提出Multi-Agent Cultural Debate（MACD）训练免费框架，为智能体分配不同文化身份，采用"求同存异"策略进行辩论。

Result: 实验表明，MACD在CEBiasBench上通过LLM-as-judge评估获得57.6%平均无偏见率，通过MAV评估获得86.0%（基线分别为47.6%和69.0%）。在阿拉伯语CAMeL基准上也表现出良好泛化能力。

Conclusion: 中文提示仅将偏见转向东亚视角而非消除偏见。MACD框架证明在智能体框架中明确的文化表征对于跨文化公平至关重要，能有效缓解大语言模型的系统性文化偏见。

Abstract: Large language models (LLMs) exhibit systematic Western-centric bias, yet whether prompting in non-Western languages (e.g., Chinese) can mitigate this remains understudied. Answering this question requires rigorous evaluation and effective mitigation, but existing approaches fall short on both fronts: evaluation methods force outputs into predefined cultural categories without a neutral option, while mitigation relies on expensive multi-cultural corpora or agent frameworks that use functional roles (e.g., Planner--Critique) lacking explicit cultural representation. To address these gaps, we introduce CEBiasBench, a Chinese--English bilingual benchmark, and Multi-Agent Vote (MAV), which enables explicit ``no bias'' judgments. Using this framework, we find that Chinese prompting merely shifts bias toward East Asian perspectives rather than eliminating it. To mitigate such persistent bias, we propose Multi-Agent Cultural Debate (MACD), a training-free framework that assigns agents distinct cultural personas and orchestrates deliberation via a "Seeking Common Ground while Reserving Differences" strategy. Experiments demonstrate that MACD achieves 57.6% average No Bias Rate evaluated by LLM-as-judge and 86.0% evaluated by MAV (vs. 47.6% and 69.0% baseline using GPT-4o as backbone) on CEBiasBench and generalizes to the Arabic CAMeL benchmark, confirming that explicit cultural representation in agent frameworks is essential for cross-cultural fairness.

</details>


### [324] [SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data](https://arxiv.org/abs/2601.12124)
*Bing Hu,Yixin Li,Asma Bahamyirou,Helen Chen*

Main category: cs.LG

TL;DR: SynQP是一个用于评估合成数据隐私风险的开放框架，使用模拟敏感数据来保护原始数据机密性，并提出了新的身份披露风险度量方法。


<details>
  <summary>Details</summary>
Motivation: 健康应用中合成数据的使用引发隐私担忧，但缺乏开放的隐私评估框架和可访问的基准数据集阻碍了其采用。主要挑战是难以获取敏感数据来评估隐私风险。

Method: 引入SynQP框架，使用模拟敏感数据进行合成数据生成的隐私基准测试；提出新的身份披露风险度量方法，更准确地评估机器学习模型的概率特性；使用SynQP对CTGAN进行基准测试。

Result: 在质量评估中，非私有模型实现了接近完美的机器学习效能（≥0.97）。隐私评估显示差分隐私（DP）持续降低身份披露风险和成员推理攻击风险，所有DP增强模型都保持在0.09监管阈值以下。

Conclusion: SynQP为提高隐私评估的透明度和可靠性提供了关键工具，使合成数据在健康相关应用中的使用更加安全。代码已开源。

Abstract: The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \(\ge0.97\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP

</details>


### [325] [SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics](https://arxiv.org/abs/2601.12131)
*Santosh Chapagain,MohammadReza EskandariNasab,Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: SolarGPT-QA是基于LLaMA-3构建的领域自适应大语言模型问答系统，专门用于空间天气和太阳物理学教育，通过科学文献和GPT-4生成的大规模问答数据进行训练，在零样本设置下优于通用模型，在教育解释方面与指令调优模型竞争


<details>
  <summary>Details</summary>
Motivation: 太阳活动（太阳耀斑、日冕物质抛射、地磁暴等）对卫星、航空、电网、数据中心和太空任务有重大影响，极端太阳事件可能造成重大经济损失。虽然大语言模型在通用任务上表现良好，但缺乏领域特定知识和教学能力来清晰解释复杂的空间科学概念

Method: 基于LLaMA-3基础模型构建领域自适应大语言模型SolarGPT-QA，使用科学文献和GPT-4生成的大规模问答数据进行训练，并通过Grok-3以学生友好的故事叙述风格进行精炼。结合领域自适应预训练和教学微调

Result: 人类成对评估显示，SolarGPT-QA在零样本设置下优于通用模型，在空间天气和太阳物理学教育解释方面与指令调优模型竞争。小型试点学生理解研究表明生成的解释具有更好的清晰度和可访问性。消融实验表明结合领域自适应预训练和教学微调对平衡科学准确性和教育效果很重要

Conclusion: SolarGPT-QA在空间科学教育方面表现出色，代表了向更广泛的SolarGPT框架（用于空间科学教育和预报）迈出的第一步。领域自适应预训练与教学微调的结合对实现科学准确性和教育有效性的平衡至关重要

Abstract: Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.
  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.

</details>


### [326] [EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts](https://arxiv.org/abs/2601.12137)
*Anzhe Cheng,Shukai Duan,Shixuan Li,Chenzhong Yin,Mingxi Cheng,Shahin Nazarian,Paul Thompson,Paul Bogdan*

Main category: cs.LG

TL;DR: EMoE提出基于正交特征基的路由机制，通过几何划分数据实现专家负载均衡和专业化，无需冲突的辅助损失函数。


<details>
  <summary>Details</summary>
Motivation: MoE架构虽然能提高效率，但面临两个根本挑战：1）负载不平衡的"富者愈富"现象，少数专家被过度使用；2）专家同质化问题，专家学习冗余表示，违背了其初衷。现有解决方案通常使用辅助负载均衡损失，虽然缓解了不平衡，但往往以牺牲专业化为代价加剧同质化。

Method: 提出Eigen-Mixture-of-Experts (EMoE)架构，采用基于学习到的正交特征基的路由机制。该方法将输入令牌投影到这个共享的特征基上，并根据它们与特征空间主成分的对齐程度进行路由。这种基于几何原理的数据划分内在促进了专家负载均衡和多样化专业专家的形成。

Result: EMoE能够同时实现专家负载均衡和专业化，无需使用冲突的辅助损失函数。代码已在GitHub公开。

Conclusion: EMoE通过基于正交特征基的路由机制，解决了MoE架构中的负载不平衡和专家同质化问题，提供了一种更有效的专家混合架构设计方法。

Abstract: The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.

</details>


### [327] [Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling](https://arxiv.org/abs/2601.12145)
*Xingyue Huang,Xueying Ding,Mingxuan Ju,Yozen Liu,Neil Shah,Tong Zhao*

Main category: cs.LG

TL;DR: TDA是一种无注意力汇的注意力机制，通过阈值化实现超稀疏性，解决了softmax注意力在长上下文中的结构限制问题


<details>
  <summary>Details</summary>
Motivation: 解决softmax注意力在长上下文中的结构限制：严格的归一化约束导致注意力汇出现在无关标记上，随着序列长度增加，概率质量分散

Method: 提出阈值差分注意力(TDA)：应用行级极值阈值化，保留超过长度相关门限的值；借鉴差分transformer思想，减去抑制视图以增强表达能力

Result: 理论上证明TDA每行伪幸存者期望数为O(1)，且随着上下文增长，独立视图间的共识伪匹配会消失；实证上产生>99%的精确零值，消除注意力汇，在标准和长上下文基准上保持竞争力

Conclusion: TDA是一种有效的注意力机制，解决了softmax在长上下文中的限制，实现了超稀疏性和鲁棒性，无需投影方法的计算开销或标准修正注意力的噪声累积问题

Abstract: Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.

</details>


### [328] [Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses](https://arxiv.org/abs/2601.12178)
*Fallou Niakh*

Main category: cs.LG

TL;DR: 提出一个联邦学习框架用于参数化保险指数的校准，针对可再生能源生产损失的异质性，通过分布式优化学习共同指数而不共享原始数据。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源生产损失参数化保险指数校准中的异质性问题和数据隐私挑战，传统方法需要共享原始观测数据，而联邦学习可以在保护数据隐私的同时进行模型训练。

Method: 使用Tweedie广义线性模型在本地建模损失，通过联邦优化学习共同指数，支持方差和链接函数的异质性，直接在分布式环境中最小化全局偏差目标。比较了FedAvg、FedProx和FedOpt算法，并与现有的基于近似的聚合方法进行基准测试。

Result: 在德国太阳能发电生产的实证应用中，联邦学习在中等异质性条件下恢复了可比较的指数系数，同时提供了一个更通用和可扩展的框架。

Conclusion: 联邦学习为参数化保险指数的校准提供了一个有效的隐私保护解决方案，能够在保持数据隐私的同时处理异质性，并具有更好的可扩展性。

Abstract: We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.

</details>


### [329] [Speculative Sampling with Reinforcement Learning](https://arxiv.org/abs/2601.12212)
*Chenan Wang,Daniel H. Shi,Haipeng Chen*

Main category: cs.LG

TL;DR: Re-SpS：首个基于强化学习的推测采样框架，通过动态调整草稿树超参数，在保持输出质量的同时实现比SOTA方法EAGLE-3更高的生成速度


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理时的延迟问题限制了其在实际应用中的部署。现有的推测采样方法（如EAGLE-3）使用静态的树结构超参数，这在不同上下文和领域中限制了灵活性和效率。

Method: 提出基于强化学习的推测采样框架（Re-SpS），实时动态调整草稿树超参数，学习上下文感知的策略以平衡推测攻击性与计算开销。利用目标模型隐藏状态的高效状态表示，并引入多步动作持久性以改进上下文建模。

Result: 在五个不同的基准测试中，相比骨干LLM实现了最高5.45倍的加速，相比SOTA方法EAGLE-3实现了最高1.12倍的加速，且没有输出保真度损失。

Conclusion: Re-SpS通过强化学习动态优化草稿树超参数，显著提升了LLM的推理速度，为实时应用提供了更高效的解决方案。

Abstract: Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\times$ speedup over the backbone LLM and up to 1.12$\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.

</details>


### [330] [One-Sided Matrix Completion from Ultra-Sparse Samples](https://arxiv.org/abs/2601.12213)
*Hongyang R. Zhang,Zhenshuo Zhang,Huy L. Nguyen,Guanghui Lan*

Main category: cs.LG

TL;DR: 本文研究了超稀疏采样下的矩阵补全问题，提出了一种用于估计矩阵行空间和二阶矩矩阵的无偏估计器，通过梯度下降恢复缺失项，在行数远大于列数的稀疏面板数据场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对大规模稀疏面板数据（行数远大于列数）中每个条目仅被稀疏观测（每个行只有C个条目，C小于矩阵秩）的挑战，传统矩阵补全方法无法准确插补，需要估计矩阵的行空间或二阶矩矩阵。

Method: 提出无偏估计器：首先对二阶矩矩阵的非零条目按观测频率进行归一化处理，然后使用梯度下降法插补二阶矩矩阵的缺失项。归一化过程将n个二项随机变量的加权和除以总观测数。

Result: 理论证明：当行向量来自满足不相干条件的秩r因子模型时，若n ≥ O(dr⁵ε⁻²C⁻²log d)，梯度下降的任意局部最小值都近似全局最优，能以最多ε²的误差恢复T。实验验证：在MovieLens数据集上偏差减少88%，在稀疏度为10⁻⁷的Amazon评论数据集上，T的恢复误差减少59%，M的恢复误差减少38%。

Conclusion: 本文提出的方法在超稀疏采样环境下有效解决了矩阵补全问题，特别适用于行数远大于列数的大规模稀疏面板数据，通过无偏估计和梯度下降实现了二阶矩矩阵的准确恢复。

Abstract: Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\times d$ matrix $M$ (with $n \ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\top} M / n$.
  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \ge O({d r^5 ε^{-2} C^{-2} \log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $ε^2$.
  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\%$ and $M$ by $38\%$ compared to baseline methods.

</details>


### [331] [Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models](https://arxiv.org/abs/2601.12215)
*Megha Thukral,Cyrus Tanade,Simon A. Lee,Juhyeon Lee,Hao Zhou,Keum San Chun,Migyeong Gwak,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Mehrab Bin Morshed,Subramaniam Venkatraman,Sharanya Arcot Desai*

Main category: cs.LG

TL;DR: 该论文提出了一种用于PPG信号表示学习的掩码多尺度重建（MMR）自监督预训练框架，通过小波多分辨率分解学习层次化时频特征，在17个健康相关任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴基础模型大多忽略了PPG信号的频谱结构，而许多下游健康相关任务需要从细粒度波形形态到全局节律动态的多分辨率特征。需要一种能够显式学习PPG数据层次化时频尺度的表示学习方法。

Method: 提出掩码多尺度重建（MMR）自监督预训练框架：1）使用小波基多分辨率分解PPG信号；2）随机掩码分解系数；3）训练Transformer编码器重建被掩码的系数，强制模型整合跨时间和频谱尺度的信息。

Result: 使用来自约32,000名智能手表用户的约1700万个未标记10秒PPG片段进行预训练。在19个多样化健康相关任务中的17个上，MMR优于或匹配最先进的开源PPG基础模型、时间序列基础模型和其他自监督基线。

Conclusion: MMR展示了作为通用PPG基础模型的潜力，小波基表示能够捕捉稳健且具有生理基础的特征，为可穿戴健康监测提供了有效的自监督学习框架。

Abstract: Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.

</details>


### [332] [Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention](https://arxiv.org/abs/2601.12231)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Shijie Xu,Guanggang Geng*

Main category: cs.LG

TL;DR: 提出了一种结合小波感知调制、多分辨率小波分解和分辨率自适应注意力的新型框架，用于企业安全中的内部威胁检测，在CERT r4.2基准测试中表现优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 企业内部威胁检测面临多通道、非平稳的用户活动日志数据，异常行为稀少且难以检测。现有方法在处理复杂行为模式和罕见异常方面存在挑战。

Method: 1. 偏差感知调制方案：抑制常规行为，放大异常偏差；2. 离散小波变换：将日志信号分解为多分辨率表示，捕捉长期趋势和短期异常；3. 可学习注意力机制：动态重新加权最具区分性的频带用于检测。

Result: 在CERT r4.2基准测试中，该方法在精确率、召回率和F1分数方面始终优于现有基线方法，适用于不同时间粒度和场景。

Conclusion: 提出的集成小波感知调制、多分辨率分解和自适应注意力的框架能够有效处理复杂的企业安全日志数据，显著提升内部威胁检测性能。

Abstract: Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.

</details>


### [333] [TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization](https://arxiv.org/abs/2601.12288)
*Lei Liu,Tengyuan Liu,Hongwei Zhao,Jiahui Huang,Ruibo Guo,Bin Li*

Main category: cs.LG

TL;DR: TimeGMM：基于高斯混合模型的概率时间序列预测框架，通过GRIN模块动态适应时域-概率分布偏移，在单次前向传播中捕获复杂未来分布，显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有概率时间序列预测方法通常依赖计算昂贵的采样或限制性参数假设来表征未来分布，这限制了预测性能并引入分布不匹配问题。

Method: 提出TimeGMM框架，基于高斯混合模型在单次前向传播中捕获复杂未来分布；核心是GRIN模块（GMM适配的可逆实例归一化），动态适应时域-概率分布偏移；整合专用时域编码器（TE-Module）和条件时域-概率解码器（CTPD-Module），联合捕获时域依赖性和混合分布参数。

Result: 在广泛实验中，TimeGMM持续优于最先进方法，在CRPS指标上最大提升22.48%，在NMAE指标上最大提升21.23%。

Conclusion: TimeGMM通过高斯混合模型框架有效解决了现有概率时间序列预测方法的局限性，在单次前向传播中捕获复杂未来分布，显著提升了预测性能。

Abstract: Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\% in CRPS and 21.23\% in NMAE.

</details>


### [334] [Distribution Shift Is Key to Learning Invariant Prediction](https://arxiv.org/abs/2601.12296)
*Hong Zheng,Fei Teng*

Main category: cs.LG

TL;DR: 研究发现：经验风险最小化（ERM）有时在分布外任务上优于专门设计的方法，原因是训练域间的分布偏移程度会影响模型性能，大的分布偏移有助于学习不变预测


<details>
  <summary>Details</summary>
Motivation: 观察到ERM有时在分布外任务上表现优于专门设计的算法，这促使研究者探索算法设计之外的原因，特别是训练域间分布偏移的作用

Method: 通过理论推导和实证验证相结合的方法：1）提出理论上界分析分布偏移程度对模型预测能力的影响；2）证明在特定数据条件下ERM解能达到不变预测模型的性能；3）通过实验验证分布偏移增大时学习模型的预测接近Oracle或最优模型

Result: 1）理论分析表明分布偏移程度直接影响学习模型的预测能力，偏移越大模型能力越强，越接近不变预测模型；2）证明在特定条件下ERM能达到不变预测模型的性能；3）实证结果显示训练数据分布偏移增大时，学习模型的预测确实接近Oracle或最优模型

Conclusion: 训练域间的分布偏移是影响模型学习不变预测的关键因素，大的分布偏移有助于提升模型在分布外任务上的性能，这解释了为什么简单的ERM有时能胜过专门设计的算法

Abstract: An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.

</details>


### [335] [Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments](https://arxiv.org/abs/2601.12305)
*Deepak Kanneganti,Sajib Mistry,Sheik Fattah,Joshua Boland,Aneesh Krishna*

Main category: cs.LG

TL;DR: 提出MLaaS数据集生成器(MDG)框架，用于创建可配置、可复现的数据集来评估MLaaS服务的选择与组合


<details>
  <summary>Details</summary>
Motivation: 需要系统化评估机器学习即服务(MLaaS)的选择和组合性能，但缺乏标准化的数据集生成方法

Method: MDG框架通过训练和评估多种模型家族，在真实数据集和数据分布设置下模拟MLaaS行为，记录功能属性、服务质量指标和组合特定指标

Result: 生成超过一万个MLaaS服务实例，构建大规模基准数据集，实验显示MDG生成的数据集相比现有基线提高了选择准确性和组合质量

Conclusion: MDG为推进MLaaS选择和组合的数据驱动研究提供了实用且可扩展的基础

Abstract: We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition

</details>


### [336] [Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays](https://arxiv.org/abs/2601.12322)
*Chang-Wei Shi,Shi-Shang Wang,Wu-Jun Li*

Main category: cs.LG

TL;DR: OrLoMo：首个实现带本地更新的异步分布式动量SGD的方法，通过有序聚合本地动量来加速异构集群中的深度模型训练。


<details>
  <summary>Details</summary>
Motivation: 动量SGD是深度模型训练的基础优化器，异步分布式学习对大规模模型训练至关重要，特别是在计算能力异构的集群中。现有方法缺乏在异步分布式环境中实现带本地更新的动量SGD的解决方案。

Method: 提出OrLoMo（有序本地动量）方法：每个工作节点本地运行动量SGD，服务器根据全局迭代索引顺序聚合各工作节点的本地动量，实现异步分布式动量SGD。

Result: 证明了OrLoMo在任意延迟下的非凸问题收敛性，实验验证OrLoMo优于同步方法和其他异步方法。

Conclusion: OrLoMo是首个实现异步分布式动量SGD带本地更新的方法，能有效处理异构计算环境，加速收敛并提升泛化性能。

Abstract: Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \underline{or}dered \underline{lo}cal \underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.

</details>


### [337] [IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning](https://arxiv.org/abs/2601.12330)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Ayesha Kanwal,Sidra Sultana,Nazia Perwaiz*

Main category: cs.LG

TL;DR: IceWatch是一个结合空间和时间视角的深度学习框架，用于预测冰川湖溃决洪水(GLOFs)，通过卫星图像分析和物理动态建模实现自动化的洪水预警系统。


<details>
  <summary>Details</summary>
Motivation: 传统GLOF检测方法依赖水文建模、阈值监测和人工卫星图像分析，存在更新慢、依赖人工、云层干扰和现场数据缺失导致精度损失等问题，需要更高效、自动化的解决方案。

Method: IceWatch包含两个核心组件：RiskFlow使用CNN分类器处理Sentinel-2多光谱卫星图像，基于冰雪和融水的空间模式预测GLOF事件；TerraFlow和TempFlow分别从NASA ITS_LIVE时间序列建模冰川速度，从MODIS LST记录预测近地表温度，通过协调预处理和同步实现多模态、物理信息化的GLOF预测。

Result: 系统提供交叉验证，提高了GLOF检测的可靠性和可解释性，确保强大的预测性能、实时数据处理能力，以及对噪声和缺失信息的鲁棒性。

Conclusion: IceWatch为自动、可扩展的GLOF预警系统铺平了道路，具有与多种传感器输入和全球冰川监测活动集成的潜力。

Abstract: Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.

</details>


### [338] [LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH](https://arxiv.org/abs/2601.12355)
*Beicheng Xu,Weitong Qian,Lingching Tung,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: LB-MCTS框架结合大语言模型和贝叶斯优化，通过蒙特卡洛树搜索结构解决CASH问题，在104个AMLB数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 降低机器学习专业门槛需要解决CASH问题（算法选择和超参数调优自动化）。传统贝叶斯优化存在冷启动问题，而现有基于大语言模型的优化器在高维结构化CASH空间中泛化能力差

Method: 提出LB-MCTS框架，在大语言模型和贝叶斯优化之间协同工作，采用蒙特卡洛树搜索结构。通过选择性调优记忆（STM）最大化大语言模型推理能力，实现显式的探索-利用权衡。随着数据积累，动态从大语言模型驱动转向贝叶斯优化驱动的建议

Result: 在104个AMLB数据集上的实验表明，LB-MCTS框架优于竞争基线方法

Conclusion: LB-MCTS框架成功结合了大语言模型的语义先验知识和贝叶斯优化的数据驱动优势，有效解决了高维结构化CASH空间的优化问题

Abstract: To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.

</details>


### [339] [Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation](https://arxiv.org/abs/2601.12401)
*Jinmei Liu,Haoru Li,Zhenhong Sun,Chaofeng Chen,Yatao Bian,Bo Wang,Daoyi Dong,Chunlin Chen,Zhi Wang*

Main category: cs.LG

TL;DR: DRIFT框架通过采样、提示和优化三个角度解决RL微调生成模型时的多样性崩溃问题，在保持任务对齐的同时显著提升生成多样性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在微调大规模生成模型时存在"多样性崩溃"的根本限制，即目标函数和优化过程会导致策略收敛到狄拉克δ分布，限制了生成输出的多样性。

Method: 提出DRIFT框架，从三个角度系统性地激励输出多样性：1) 采样奖励集中的子集以过滤异常值；2) 使用随机变化的提示扩展条件空间；3) 通过基于势能的奖励塑造机制优化组内多样性。

Result: 实验结果显示DRIFT在任务对齐和生成多样性方面实现了帕累托优势：在同等对齐水平下多样性提升9.08%~43.46%，在同等多样性水平下对齐度提升59.65%~65.86%。

Conclusion: DRIFT框架成功解决了RL微调生成模型时的多样性崩溃问题，实现了任务对齐与生成多样性的平衡，增强了生成模型的实用性。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.

</details>


### [340] [Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants](https://arxiv.org/abs/2601.12405)
*Manasi Kanade,Abhi Thakkar,Gabriela Fernandes*

Main category: cs.LG

TL;DR: 开发了一个可解释的机器学习框架用于儿童牙科风险分层，强调可解释性、校准和伦理部署而非最大预测精度，模型AUC为0.61，年龄和收入贫困比是主要风险因素。


<details>
  <summary>Details</summary>
Motivation: 儿童牙科疾病是全球最普遍且不公平的慢性健康状况之一。虽然流行病学证据显示口腔健康结果与社会经济和人口统计学因素相关，但现有AI牙科应用主要依赖基于图像的诊断和黑盒预测模型，在儿童人群中缺乏透明度和伦理适用性。

Method: 使用人口水平的儿童数据（包括年龄、收入贫困比、种族/民族、性别和病史）训练监督机器学习模型。通过ROC分析和校准曲线评估模型性能，使用SHAP方法实现可解释性，提供全局和个体层面的预测解释。

Result: 模型实现了适度的区分能力（AUC=0.61），具有保守的校准特性，在高概率水平下低估风险。SHAP分析显示年龄和收入贫困比是预测风险的最强贡献因素，其次是种族/民族和性别。

Conclusion: 可解释的机器学习能够实现透明的、预防导向的儿童牙科风险分层，支持人群筛查和公平的资源分配，而不是用于诊断决策。

Abstract: Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.
  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.
  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.
  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.
  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.

</details>


### [341] [Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF](https://arxiv.org/abs/2601.12415)
*Wang Zixian*

Main category: cs.LG

TL;DR: 该论文提出了正交化策略优化（OPO）框架，将采样几何与优化几何解耦，解决了传统对齐方法中KL散度导致的数值不稳定和梯度消失问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法（如PPO、DPO、IPO）通常隐含地将两个基本设计选择混为一谈：采样几何（决定哪些样本主导梯度信号）和优化几何（决定如何惩罚值偏差）。这种混淆导致KL散度对无界值信号施加指数惩罚，在高置信度情况下产生数值不稳定和梯度消失问题。

Method: 提出了正交化策略优化（OPO）框架，将对齐形式化为策略能量与目标能量之间广义距离的最小化。该方法使用α散度加权的重采样进行采样几何设计，在比率坐标中使用卡方诱导的二次正则化进行优化几何设计，从而产生具有线性梯度动态的简单且条件良好的目标函数。

Result: OPO框架提供了对现有对齐方法的统一视角，能够在保持峰值寻求行为的同时实现稳定优化，即使模型置信度高时也能避免梯度饱和。该框架为稳健的推理导向训练提供了理论基础。

Conclusion: 通过明确解耦采样几何和优化几何，OPO框架解决了传统对齐方法的数值不稳定问题，为大规模语言模型对齐提供了一个更稳健、更理论化的方法，能够支持更可靠的推理导向训练。

Abstract: Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an alpha-divergence-based sampling weight and a Bregman-divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining alpha-weighted importance sampling with a chi-square-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.

</details>


### [342] [Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting](https://arxiv.org/abs/2601.12467)
*Saurish Nagrath*

Main category: cs.LG

TL;DR: 提出两阶段时间序列预测框架：第一阶段用CNN提取局部时间动态特征并生成补丁级token嵌入，第二阶段用Transformer编码器建模补丁间依赖关系进行预测。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在时间序列预测中表现出色，但其效果严重依赖于从原始多元时间序列数据中提取的输入表示的质量和结构。现有方法在局部时间表示学习和全局依赖建模方面存在耦合问题。

Method: 提出两阶段预测框架：1）局部时间表示学习阶段：使用CNN在固定长度时间补丁上提取短程时间动态和非线性特征交互，生成紧凑的补丁级token嵌入，并通过token级自注意力跨时间补丁交互优化嵌入；2）全局依赖建模阶段：使用Transformer编码器处理token序列，建模补丁间时间依赖关系并生成每个补丁的预测。

Result: 在具有受控静态和动态因素的合成多元时间序列数据上的实验表明，所提出的基于补丁的token化策略相比卷积和基于补丁的Transformer基线实现了具有竞争力的预测性能。

Conclusion: 结构化时间表示的重要性得到验证，将局部时间编码与基于全局注意力的建模解耦能够产生更有效和稳定的时间序列预测。

Abstract: Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.

</details>


### [343] [Cooperative Multi-agent RL with Communication Constraints](https://arxiv.org/abs/2601.12518)
*Nuoya Xiong,Aarti Singh*

Main category: cs.LG

TL;DR: 提出基于策略预测的算法，通过利用旧梯度预测策略更新，在有限通信下减少重要性采样中的基础策略与当前策略差距，显著降低通信轮数需求。


<details>
  <summary>Details</summary>
Motivation: 传统协作多智能体强化学习通常假设能频繁访问全局信息（如团队奖励、其他智能体动作），但在去中心化系统中由于高通信成本不现实。当通信受限时，智能体必须依赖过时信息估计梯度和更新策略。现有重要性采样方法在通信受限（缺失数据概率高）时变得不稳定，因为基础策略已过时。

Method: 提出基础策略预测技术，利用旧梯度预测策略更新，为一系列基础策略收集样本，减少基础策略与当前策略之间的差距。这使得在一个通信轮次内就能收集预测基础策略的样本，从而显著减少通信轮数需求。

Result: 理论上证明算法在势博弈中能以O(ε^{-3/4})通信轮数和O(poly(max_i |A_i|)ε^{-11/4})样本数收敛到ε-纳什均衡，改进了现有最优结果的通信成本和样本复杂度，避免了联合动作空间大小的指数依赖。还将结果扩展到一般马尔可夫协作博弈以找到智能体局部最优。

Conclusion: 基础策略预测算法能有效解决有限通信下的协作MARL问题，显著减少通信需求，同时在理论和实证上都表现出优越性能，适用于模拟游戏和复杂环境中的MAPPO应用。

Abstract: Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\varepsilon$-Nash equilibrium in potential games with only $O(\varepsilon^{-3/4})$ communication rounds and $O(poly(\max_i |A_i|)\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.

</details>


### [344] [Approximating splits for decision trees quickly in sparse data streams](https://arxiv.org/abs/2601.12525)
*Nikolaj Tatti*

Main category: cs.LG

TL;DR: 提出了一种针对稀疏二元特征和二元分类的决策树流式学习算法，能够快速找到近似最优的分割点，相比传统O(d)时间有显著加速。


<details>
  <summary>Details</summary>
Motivation: 传统决策树流式学习算法在处理稀疏二元特征时，寻找最优分割需要O(d)时间（d为特征数），这在稀疏数据（m≪d）场景下效率低下。需要一种能利用数据稀疏性加速分割搜索的方法。

Method: 提出了一种基于近似算法的分割搜索方法：1）对于条件熵，实现(1+α)近似，摊销时间复杂度为O(α⁻¹(1+m log d) log log n)；2）对于基尼指数，同样实现(1+α)近似，摊销时间复杂度为O(α⁻¹+m log d)。其中m是数据点中1的数量，n是数据点数。

Result: 实验结果表明，该方法能够高效找到几乎最优的分割点，比基线方法更快，且实际性能优于理论近似保证。

Conclusion: 针对稀疏二元特征和二元分类的决策树流式学习，提出的近似分割搜索算法能够显著加速最优分割的查找过程，特别适用于稀疏数据场景，具有实际应用价值。

Abstract: Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + α)$ approximation when using conditional entropy in amortized $O(α^{-1}(1 + m\log d) \log \log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + α)$ approximation in amortized $O(α^{-1} + m \log d)$ time. Our approach is beneficial for sparse data where $m \ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.

</details>


### [345] [Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization](https://arxiv.org/abs/2601.12604)
*Safwan Labbi,Daniil Tiapkin,Paul Mangold,Eric Moulines*

Main category: cs.LG

TL;DR: 提出用广义f-softargmax替代softmax策略参数化，结合f-散度正则化，改善优化景观，为有限MDP的随机策略梯度方法提供首个非渐近最后迭代收敛保证


<details>
  <summary>Details</summary>
Motivation: 传统softmax策略参数化会导致病态优化景观和指数级慢收敛，虽然预调节可以缓解但计算成本高，需要更有效的替代方案

Method: 使用广义f-softargmax作为策略参数化，结合相同f-散度诱导的正则化器，改善优化景观并确保正则化目标满足Polyak-Lojasiewicz不等式

Result: 为有限MDP的随机策略梯度方法建立了首个显式非渐近最后迭代收敛保证，无需任何预调节；对于无正则化问题，f-PG（特别是Tsallis散度）实现了多项式样本复杂度，而标准softmax需要指数复杂度

Conclusion: f-softargmax参数化结合f-散度正则化是一种有效的替代方案，能显著改善策略梯度方法的收敛性能，避免softmax的指数慢收敛问题

Abstract: Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.

</details>


### [346] [What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes](https://arxiv.org/abs/2601.12612)
*Piyush Sao*

Main category: cs.LG

TL;DR: 该论文提出了一种基于矩阵迹幂计算大型对称正定矩阵对数行列式的新方法，通过矩生成函数变换解决传统方法在条件数较大时的发散问题，并证明了有限正矩估计的固有局限性，同时提供了可证明的上下界估计。


<details>
  <summary>Details</summary>
Motivation: 计算大型对称正定矩阵的对数行列式在高斯过程推断和贝叶斯模型比较中很重要。传统方法结合矩阵向量乘积和多项式近似，但在条件数较大时会发散。作者探索了当矩阵幂可用时，通过迹幂计算的新模型。

Method: 使用矩生成函数M(t)=E[X^t]处理归一化特征值X=λ/AM，将对数行列式转化为估计M'(0)。通过变换K(t)=log M(t)压缩值域，利用m+1个连续整数点插值K并求导估计K'(0)。同时基于谱下界r≤λ_min推导矩约束的上下界，提供可证明的区间估计。

Result: 证明了使用有限正矩的连续估计器在无界条件数下无法达到一致精度的基本限制。提出了基于相同迹数据的上下界估计方法，所有估计器和边界的计算成本为O(m)，对于m∈{4,...,8}实际上是常数时间。

Conclusion: 该方法通过矩生成函数变换有效解决了传统方法在条件数较大时的发散问题，同时认识到有限正矩估计的固有局限性，提供了可证明的区间估计和诊断指标，为高斯过程推断和贝叶斯模型比较中的对数行列式计算提供了更可靠的解决方案。

Abstract: Computing $\log\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \tr(A^k)$, natural when matrix powers are available.
  Classical moment-based approximations Taylor-expand $\log(λ)$ around the arithmetic mean. This requires $|λ- \AM| < \AM$ and diverges when $κ> 4$. We work instead with the moment-generating function $M(t) = \E[X^t]$ for normalized eigenvalues $X = λ/\AM$. Since $M'(0) = \E[\log X]$, the log-determinant becomes $\log\det(A) = n(\log \AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \log M(t)$ compresses this range. Normalization by $\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.
  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \E[\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\det A)^{1/n}$. Given a spectral floor $r \leq λ_{\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\log\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \in \{4, \ldots, 8\}$, this is effectively constant time.

</details>


### [347] [Explanation Multiplicity in SHAP: Characterization and Assessment](https://arxiv.org/abs/2601.12654)
*Hyunseung Hwang,Seungeun Lee,Lucas Rosenblatt,Julia Stoyanovich,Steven Euijong Whang*

Main category: cs.LG

TL;DR: SHAP解释存在多重性问题：即使输入、任务和训练模型固定，多次运行SHAP也会产生显著不同的特征归因解释，这种"解释多重性"普遍存在且影响高置信度预测。


<details>
  <summary>Details</summary>
Motivation: SHAP作为后验解释方法被广泛用于高风险领域的决策解释、争议和审计，但人们发现即使输入、任务和训练模型固定，SHAP解释在多次运行中也会产生显著差异，这种"解释多重性"问题需要系统研究。

Method: 提出了一种方法来表征特征归因解释中的多重性，区分模型训练/选择来源与解释管道内在随机性；使用幅度距离和基于排名的度量来评估稳定性；推导了在合理零模型下的随机化基线值。

Result: 发现解释多重性普遍存在，即使对于高置信度预测也是如此；幅度距离可能接近零，但基于排名的度量显示顶级特征的身份和排序存在显著变化；不同数据集、模型类别和置信度区间都观察到这种现象。

Conclusion: SHAP解释存在固有的多重性问题，需要开发与解释预期用途相匹配的度量和基线，以确保解释的可靠性和实用性。

Abstract: Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.

</details>


### [348] [MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning](https://arxiv.org/abs/2601.12680)
*Zheng Fang,Wolfgang Mayer,Zeyu Zhang,Jian Wang,Hong-Yu Zhang,Wanli Li,Zaiwen Feng*

Main category: cs.LG

TL;DR: 本文提出MetaToolAgent (MTA)元学习方法，通过跨工具泛化解决LLM工具选择中面对新工具时的泛化能力不足问题，使用包含155个工具和9377个问答对的数据集进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有工具选择方法通常局限于有限工具集，难以泛化到实际部署中遇到的新工具，这限制了LLM在复杂现实任务中协调和使用多样化工具的能力。

Method: 提出MetaToolAgent (MTA)，一种元学习方法，旨在提高跨工具泛化能力；构建了涵盖7个领域、包含155个工具和9,377个问答对的综合数据集，模拟现实集成场景。

Result: 实验结果表明，MTA在未见工具上的表现显著优于基线方法，证明了其在构建需要动态工具协调的灵活可扩展系统方面的潜力。

Conclusion: MTA通过元学习方法有效提升了LLM对新工具的泛化能力，为解决动态工具协调问题提供了有前景的解决方案。

Abstract: Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.

</details>


### [349] [Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization](https://arxiv.org/abs/2601.12707)
*Junyi Liao,Zihan Zhu,Ethan Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 本文提出了一个统一框架，用于在两人零和矩阵博弈和马尔可夫博弈中恢复未知的奖励函数，通过熵正则化和量化响应均衡解决逆问题的模糊性和数据覆盖不足的挑战。


<details>
  <summary>Details</summary>
Motivation: 在逆强化学习和博弈论中，估计驱动智能体行为的未知奖励函数是一个核心问题。现有方法面临逆问题的固有模糊性、可行奖励的非唯一性以及观测数据覆盖有限等挑战，特别是在竞争性环境中。

Method: 建立基于量化响应均衡的奖励函数可识别性理论框架，提出从观测动作中学习奖励函数的新算法。该算法适用于静态和动态设置，可整合最大似然估计等方法，并提供了可靠性和样本效率的理论保证。

Result: 理论分析证明了奖励函数在量化响应均衡下的可识别性，算法在静态和动态环境中都能有效恢复奖励函数。数值研究验证了框架的实际有效性，为竞争环境中的决策提供了新见解。

Conclusion: 该研究为两人零和博弈中的奖励函数恢复提供了一个统一的理论和算法框架，通过熵正则化和量化响应均衡解决了逆问题的挑战，在理论和实践上都取得了有意义的进展。

Abstract: Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.

</details>


### [350] [Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off](https://arxiv.org/abs/2601.12730)
*Zhaochun Li,Chen Wang,Jionghao Bai,Shisheng Cui,Ge Lan,Zhou Zhao,Yue Wang*

Main category: cs.LG

TL;DR: DCPO提出了一种基于分布中心的强化学习方法，通过分布层面的正则化控制熵，解决了传统基于样本的探索方法依赖"运气"和缺乏理论依据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法（如GRPO）在大型语言模型训练中存在探索-利用权衡问题，训练倾向于过度利用：熵单调下降，样本收敛，探索消失。现有基于样本的启发式方法依赖"幸运"样本，缺乏对策略的原则性控制，效果有限且不稳定。

Method: 提出Distribution-Centric Policy Optimization (DCPO)，从分布中心视角重新定义强化学习，将探索视为由"更好"的目标分布引导。将熵调节重新表述为分布层面的正则化，完全在策略内实现可控熵，无需从外部分布采样。

Result: 在多个模型和七个基准测试中，DCPO相比GRPO平均提升约20%。DCPO能够实现高效探索同时保持训练稳定性。

Conclusion: DCPO用分布层面的原则替代了样本层面的启发式方法，为可控探索和更强的探索-利用权衡提供了理论依据和灵活框架。

Abstract: The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the "luck" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \textbf{distribution-centric} perspective for RL, in which exploration is always guided by a "better" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.

</details>


### [351] [Distilling Time Series Foundation Models for Efficient Forecasting](https://arxiv.org/abs/2601.12785)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Szu-Yu Chen,Yingli Tian*

Main category: cs.LG

TL;DR: DistilTS是首个专门为时间序列基础模型设计的知识蒸馏框架，通过解决任务难度差异和架构差异两大挑战，在保持预测性能的同时大幅压缩模型规模


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型虽然预测性能强大，但参数量大导致部署成本高。现有的通用知识蒸馏技术无法直接应用于时间序列预测，因为存在任务难度差异和架构差异等独特挑战

Method: 提出DistilTS框架：1) 引入水平加权目标来平衡不同预测时长的学习权重，解决短期预测主导优化的问题；2) 设计时间对齐策略来减少架构不匹配，使紧凑模型能有效学习

Result: 在多个基准测试中，DistilTS实现了与完整规模时间序列基础模型相当的预测性能，同时参数减少高达1/150，推理速度提升高达6000倍

Conclusion: DistilTS是首个专门针对时间序列基础模型的知识蒸馏框架，有效解决了该领域的独特挑战，为大规模时间序列模型的轻量化部署提供了实用解决方案

Abstract: Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.

</details>


### [352] [Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs](https://arxiv.org/abs/2601.12807)
*Zixing Song,Irwin King*

Main category: cs.LG

TL;DR: SIT-Graph：一种用于图学习的半监督指令调优框架，通过迭代自训练利用未标记节点提升LLMs在图学习任务上的性能


<details>
  <summary>Details</summary>
Motivation: 传统图指令调优需要大量标注节点数据，这在社交领域等敏感或快速变化的内容中成本高昂且缓慢。同时，现有方法未能充分利用未标记节点中因边连接而产生的潜在相关性。

Method: 提出SIT-Graph框架，采用模型无关的迭代自训练过程：1）先用标记节点构建的指令对进行微调；2）为未标记节点生成置信度过滤的伪响应；3）策略性地扩充数据集进行下一轮微调；4）通过迭代优化使LLM与底层节点相关性对齐。

Result: 实验表明，当SIT-Graph集成到最先进的图指令调优方法中时，在文本属性图基准测试上显著提升性能，在低标签率设置下实现超过20%的改进。

Conclusion: SIT-Graph有效解决了图学习中标注数据稀缺的问题，通过半监督方式利用未标记节点的潜在相关性，为LLMs在图学习任务上的应用提供了更高效的调优框架。

Abstract: The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.

</details>


### [353] [Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates](https://arxiv.org/abs/2601.12859)
*Luca Schaufelberger,Aline Hartgers,Kjell Jorner*

Main category: cs.LG

TL;DR: PuckerFlow是一个用于环状分子构象生成的机器学习模型，通过在Cremer-Pople空间进行流匹配，能够高效可靠地生成多样且精确的环状分子构象。


<details>
  <summary>Details</summary>
Motivation: 环状分子在化学和生物学中广泛应用，其受限的构象柔性提供了结构预组织，这对药物发现和催化中的功能至关重要。然而，可靠地采样环系统的构象集合仍然具有挑战性。

Method: PuckerFlow是一个生成式机器学习模型，在Cremer-Pople空间（一个捕捉环相关自由度的低维内部坐标系）上执行流匹配。这种方法能够通过设计生成有效的闭合环。

Result: PuckerFlow在几乎所有定量指标上都优于其他构象生成方法，展示了在生成既多样又精确的构象方面的强大性能。特别展示了PuckerFlow在催化、药物发现等化学应用中相关环系统的潜力。

Conclusion: 这项工作实现了环状结构的高效可靠构象生成，为建模结构-性质关系以及在化学和生物学广泛应用中实现性质引导的环状分子生成铺平了道路。

Abstract: Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.

</details>


### [354] [AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs](https://arxiv.org/abs/2601.12893)
*Ting Dang,Soumyajit Chatterjee,Hong Jia,Yu Wu,Flora Salim,Fahim Kawsar*

Main category: cs.LG

TL;DR: AdaNODEs是一种针对时间序列预测任务的源无关测试时适应方法，利用神经常微分方程处理时间序列数据的分布偏移，仅需更新有限参数即可显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时适应方法主要针对独立数据设计，很少考虑时间序列数据的特性，也极少处理预测任务。时间序列数据具有独特的分布偏移特征，需要专门的方法来处理。

Method: 提出AdaNODEs方法，基于神经常微分方程构建适应框架，专门针对时间序列预测任务设计。创新性地提出新的损失函数来处理预测任务的测试时适应，仅需更新有限模型参数。

Result: 在一维和高维数据上的广泛实验表明，AdaNODEs相比最先进的基线方法分别实现了5.88%和28.4%的相对改进，特别是在更高严重程度的分布偏移下表现出鲁棒性。

Conclusion: AdaNODEs为时间序列预测任务提供了一种有效的源无关测试时适应方法，能够有效处理时间序列数据的分布偏移，同时保持较低的内存使用。

Abstract: Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.

</details>


### [355] [Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets](https://arxiv.org/abs/2601.12903)
*Meng Liu,Ke Liang,Siwei Wang,Xingchen Hu,Sihang Zhou,Xinwang Liu*

Main category: cs.LG

TL;DR: 本文提出了BenchTGC，一个用于时序图聚类（TGC）任务的综合基准，解决了该领域存在的聚类技术不适用和数据集不适用两大挑战。


<details>
  <summary>Details</summary>
Motivation: 时序图聚类是一个新兴但关注度较低的任务，相比静态图聚类，它能够通过基于交互序列的批处理模式在时间要求和空间要求之间找到平衡。然而，当前存在两大挑战阻碍了TGC的发展：不适用于时序图的聚类技术和不适用于TGC的数据集。

Method: 提出了BenchTGC基准，包括：1）设计BenchTGC框架来说明时序图聚类的范式；2）改进现有聚类技术以适应时序图；3）讨论公共时序图数据集的问题并开发了多个适用于TGC任务的数据集（BenchTGC数据集）。

Result: 通过大量实验验证了BenchTGC的优势，并证明了时序图聚类任务的必要性和重要性。实验表明，现实世界中动态变化和复杂的场景是时序图聚类的基础。

Conclusion: BenchTGC为时序图聚类提供了一个全面的基准，解决了该领域的关键挑战，推动了时序图聚类研究的发展。代码和数据已开源。

Abstract: Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.

</details>


### [356] [CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction](https://arxiv.org/abs/2601.12917)
*He Sun,Jinrui Zhou,Li Li,Mingjun Xiao*

Main category: cs.LG

TL;DR: CooperLLM是一个云辅助的边缘-终端协同联邦微调框架，通过在移动设备上使用零阶优化，云端通过梯度修正指导来提升收敛速度和精度，同时大幅降低内存使用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在移动设备上微调面临内存和计算成本高的挑战，现有联邦学习方法要么依赖内存密集型反向传播，要么使用收敛慢、精度低的零阶优化方法。

Method: 提出云辅助的边缘-终端协同联邦微调框架：移动客户端在私有数据上执行轻量级零阶优化更新，云端在辅助公共数据上使用反向传播微调，并通过注入引导扰动来修正本地更新。采用流水线调度和自适应压缩来重叠计算与通信，减少内存使用。

Result: 在多个Transformer模型和数据集上的实验表明，CooperLLM将设备内存使用减少高达86.4%，加速收敛8.8倍，相比最先进的零阶优化基线方法精度提升高达10个百分点。

Conclusion: CooperLLM通过云辅助的协同联邦微调框架，有效解决了移动设备上LLM微调的内存和计算限制问题，在保持隐私的同时显著提升了收敛速度和模型精度。

Abstract: Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\%$, accelerates convergence by $8.8 \times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.

</details>


### [357] [An efficient heuristic for geometric analysis of cell deformations](https://arxiv.org/abs/2601.12928)
*Yaima Paz Soto,Silena Herold Garcia,Ximo Gual-Arnau,Antoni Jaume-i-Capó,Manuel González-Hidalgo*

Main category: cs.LG

TL;DR: 本文提出了一种基于形状空间的镰状细胞自动分类方法，通过固定参数化和模板对齐简化计算，在监督分类和无监督聚类中均达到96.03%的准确率。


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病导致红细胞变形，影响血液流动和氧气输送，在全球尤其是资源有限地区造成重大医疗负担。自动分类镰状细胞对于减少专家工作量、避免量化错误和评估危机严重性至关重要。虽然已有基于形状空间距离的方法取得高准确率，但需要进一步优化计算效率。

Method: 1) 使用基于细胞长轴的固定参数化来计算距离；2) 在计算距离前，使用该参数化将每个细胞与两个模板对齐。这种方法避免了在所有可能参数化中最小化距离的复杂计算，简化了形状空间模型的计算过程。

Result: 该方法在监督分类和无监督聚类中均达到96.03%的准确率，在保持或提高形状空间模型准确率的同时，显著降低了计算成本。

Conclusion: 提出的固定参数化和模板对齐策略实现了高效的红细胞分类，为镰状细胞病的自动诊断提供了计算效率更高、准确性良好的解决方案，特别适合资源有限地区的医疗应用。

Abstract: Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.

</details>


### [358] [PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning](https://arxiv.org/abs/2601.13020)
*Zhiyan Hou,Haiyun Guo,Haokai Ma,Yandu Sun,Yonghui Yang,Jinqiao Wang*

Main category: cs.LG

TL;DR: 提出PASs方法解决多模态大语言模型持续指令调优中的专家共漂移问题，通过路径激活子空间校准路由并稳定重要秩方向，提升准确性和抗遗忘性


<details>
  <summary>Details</summary>
Motivation: 现有基于LoRA的混合专家方法在持续指令调优中，路由器和专家会共同漂移，导致专家职责模糊和遗忘问题加剧，需要解决这种"错位共漂移"现象

Method: 提出路径激活子空间(PASs)作为能力对齐的坐标系统，包含PAS引导的重新加权校准路由，以及PAS感知的秩稳定化选择性稳定重要秩方向

Result: 在持续指令调优基准测试中，该方法在准确性和抗遗忘性方面均优于传统持续学习基线和MoE-LoRA变体，且不增加参数

Conclusion: PASs方法通过路径激活子空间有效解决了专家共漂移问题，为多模态大语言模型的持续指令调优提供了有效的路由校准和知识保留机制

Abstract: Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.

</details>


### [359] [Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis](https://arxiv.org/abs/2601.13021)
*Nataša Petrović,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Jose Maria Buades Rubio*

Main category: cs.LG

TL;DR: 提出一种基于集成学习的新方法，用于镰状细胞病的血液涂片图像诊断支持，通过特征选择和模型优化实现更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 为镰状细胞病提供基于外周血涂片图像的诊断支持系统，需要解决现有方法在泛化能力和可解释性方面的不足。

Method: 预处理和分割显微图像提取高质量特征，采用集成机器学习方法（随机森林和极端随机树）进行分类，开发特征重要性分析方法以减少复杂性并增强可解释性。

Result: 集成模型在F1分数上达到90.71%，SDS分数达到93.33%，优于之前的梯度提升方法（F1分数87.32%，SDS分数89.51%），在新数据集上表现出更好的泛化能力。

Conclusion: 提出的集成学习方法在镰状细胞病诊断支持中表现出优异的性能和泛化能力，同时通过特征分析增强了模型的可解释性，为临床诊断提供了可靠工具。

Abstract: This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.

</details>


### [360] [METIS: Mentoring Engine for Thoughtful Inquiry & Solutions](https://arxiv.org/abs/2601.13075)
*Abhinav Rajeev Kumar,Dhruv Trehan,Paras Chopra*

Main category: cs.LG

TL;DR: METIS是一个面向本科生的AI研究导师系统，通过阶段感知的辅助工具帮助学生从想法到论文写作，在多个评估指标上优于GPT-5和Claude Sonnet 4.5。


<details>
  <summary>Details</summary>
Motivation: 许多学生缺乏专业研究指导，需要AI导师帮助他们从研究想法发展到完整论文。

Method: 构建METIS系统，包含文献搜索、指导指南、方法检查、记忆功能等工具增强功能，采用阶段感知的路由机制。评估方法包括LLM作为裁判的成对偏好比较、学生角色评分标准、多轮辅导会话、证据和合规性检查。

Result: 在90个单轮提示中，LLM裁判偏好METIS超过Claude Sonnet 4.5（71%）和GPT-5（54%）。学生评分（清晰度/可操作性/约束匹配度）在各阶段均更高。在多轮会话中，METIS的最终质量略高于GPT-5。优势集中在文档基础阶段（D-F），但存在过早工具路由、基础浅薄和偶尔阶段分类错误等问题。

Conclusion: METIS作为AI研究导师在帮助学生完成研究论文方面表现出色，特别是在文档基础阶段，但需要改进工具路由和基础深度问题。

Abstract: Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.

</details>


### [361] [Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement](https://arxiv.org/abs/2601.13100)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 提出了递归元蒸馏的算子理论框架，将迭代知识蒸馏形式化为概率分布算子序列，证明了在温和假设下锚定递归蒸馏能诱导KL散度收缩，收敛到基础教师分布的唯一全局吸引不动点。


<details>
  <summary>Details</summary>
Motivation: 现有概率域知识蒸馏研究建立了温度缩放、多教师聚合和单阶段设置中偏差-方差权衡的公理化框架，但递归或多代蒸馏的数学行为理解不足，先前方法主要依赖经验启发式。

Method: 引入递归元蒸馏的公理化和算子理论框架，将迭代知识蒸馏形式化为具有明确基础教师锚定的概率分布算子序列，定义了有效元教师构建的结构公理，证明了满足这些公理的非平凡算子族存在性。

Result: 在温和可实现性和凸性假设下，锚定递归蒸馏诱导KL散度收缩，产生向基础教师分布的几何收敛和唯一的全局吸引不动点，为理解迭代和多教师蒸馏的稳定性、偏差-方差行为和失效模式提供了理论基础。

Conclusion: 该框架是基础性而非算法性的贡献，刻画了递归蒸馏何时在数学上适定且收敛（而非误差累积），独立于模型架构、优化细节或特定算子实例化，为容量约束下的迭代和多教师蒸馏提供了理论依据。

Abstract: Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.
  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.
  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.

</details>


### [362] [FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference](https://arxiv.org/abs/2601.13143)
*Chaeyoung Jung,Youngjoon Jang,Seungwoo Lee,Joon Son Chung*

Main category: cs.LG

TL;DR: FastAV是首个针对音频-视觉大语言模型的token剪枝框架，通过两阶段剪枝策略减少40%以上计算量，同时保持或提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然token剪枝在标准LLM和视觉语言模型中已被广泛研究，但在音频-视觉大语言模型(AV-LLMs)中应用很少，而多模态整合显著增加了这些模型的token需求，需要专门的剪枝解决方案。

Method: 提出基于注意力权重的剪枝策略：1) 在中间层进行全局剪枝，移除广泛影响力较小的token；2) 在后续层进行精细剪枝，考虑对下一个token生成的影响。该方法不依赖完整注意力图，完全兼容FlashAttention等高效注意力机制。

Result: 在两种代表性AV-LLMs上，FastAV能够减少超过40%的FLOPs，同时保持甚至提升模型性能。

Conclusion: FastAV是首个专门为AV-LLMs设计的token剪枝框架，通过创新的两阶段剪枝策略有效减少了计算开销，同时保持了模型性能，为多模态大语言模型的高效部署提供了解决方案。

Abstract: In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.

</details>


### [363] [Training instability in deep learning follows low-dimensional dynamical principles](https://arxiv.org/abs/2601.13160)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

TL;DR: 论文提出训练稳定性作为学习系统的内在动力学属性，通过四个维度（优化、环境/数据、参数、学习信号）分析训练过程的稳定性，并发现高最终性能常与训练稳定性脱钩。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统虽然取得了显著的实证性能，但训练过程本身的稳定性仍然理解不足。训练作为高维动力系统，小的扰动可能导致突然且不可逆的崩溃，这破坏了可重复性和可扩展性。

Method: 提出统一的动力学视角，将训练稳定性组织为四个相互作用的维度：优化稳定性、环境/数据稳定性、参数稳定性和学习信号稳定性。通过受控扰动审计训练轨迹来操作化这一视角，在不修改学习算法的情况下探测学习动力学对结构化扰动的响应。

Result: 在强化学习和大型语言模型训练中发现三个重复出现的规律：1）高最终性能常与训练稳定性脱钩；2）受控随机性在不同范式中持续缓冲学习动力学；3）低维潜在元状态的偏差系统地先于可观察的性能崩溃。

Conclusion: 训练稳定性是学习系统可测量和可比较的动力学属性，为超越最终性能结果研究学习动力学提供了描述性基础。

Abstract: Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.
  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.
  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.

</details>


### [364] [LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations](https://arxiv.org/abs/2601.13190)
*Vittoria De Pellegrini,Tariq Alkhalifah*

Main category: cs.LG

TL;DR: LAViG-FLOW：基于潜在自回归视频生成扩散框架，用于高效模拟地下多相流体流动场，相比传统数值求解器快几个数量级


<details>
  <summary>Details</summary>
Motivation: 地下多相流体流动场的建模和预测对地质CO2封存和地热生产等应用至关重要，但高保真多相模拟器在需要大量前向运行进行反演和量化不确定性时变得极其昂贵

Method: 提出LAViG-FLOW框架，使用专用2D自编码器压缩每个状态变量，通过视频扩散变换器建模它们在时间上的耦合分布，先在给定时间范围内训练学习耦合关系，然后自回归微调以在观测时间窗口外进行外推

Result: 在开源CO2封存数据集上评估，LAViG-FLOW生成的饱和度和压力场在时间上保持一致性，运行速度比传统数值求解器快几个数量级

Conclusion: LAViG-FLOW为地下多相流体流动模拟提供了一种高效替代方案，显著降低了计算成本，同时保持了时间一致性

Abstract: Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.

</details>


### [365] [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243)
*Yapeng Li,Jiakuo Yu,Zhixin Liu,Xinnan Liu,Jing Yu,Songze Li,Tonghua Su*

Main category: cs.LG

TL;DR: 该研究系统评估了LLM推理范式（直接生成、CoT增强、多智能体系统），分析了成本-准确率权衡，并提出了新的开放基准MIMeBench来评估语义能力。


<details>
  <summary>Details</summary>
Motivation: LLM作为推理系统部署时，不同推理范式（如CoT和多智能体系统）的相对效果和成本-准确率权衡缺乏系统理解，需要全面评估以指导实际应用。

Method: 1. 统一评估多种推理范式：直接单模型生成、CoT增强单模型推理、代表性MAS工作流；2. 使用角色隔离分析探究MAS中角色特定能力需求；3. 分析成本-准确率权衡；4. 提出MIMeBench新基准，专注于语义抽象和对比辨别能力。

Result: 1. 结构复杂性增加并不总是提高推理性能，其效果高度依赖于推理范式本身的特性和适用性；2. 识别了哪些MAS工作流在成本和准确率之间达到良好平衡，哪些存在过高开销但收益有限；3. MIMeBench提供了现有基准难以捕捉的语义能力细粒度评估。

Conclusion: 需要根据具体任务特性选择合适的推理范式，而非盲目追求复杂结构；新基准MIMeBench为评估LLM语义能力提供了重要补充；研究为LLM推理系统部署提供了实用指导。

Abstract: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.

</details>


### [366] [Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification](https://arxiv.org/abs/2601.13272)
*Aaron Pim,Tristan Pryer*

Main category: cs.LG

TL;DR: 提出了一种基于多级蒙特卡洛（MLMC）框架的不确定性量化方法，通过重用dropout掩码在不同保真度层级间构建耦合的粗-细估计器，降低方差并提高效率。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛dropout是深度学习不确定性量化的常用方法，但需要大量前向传播来估计预测矩，计算成本高。需要开发更高效的方差缩减技术来降低计算成本。

Method: 将dropout掩码视为认知随机性来源，通过前向传播次数定义保真度层级。重用dropout掩码在不同层级间构建耦合的粗-细估计器，形成用于预测均值和预测方差的多级蒙特卡洛估计器。

Result: 推导了偏差、方差和有效成本的显式表达式，以及跨层级的样本分配规则。在正向和逆向PINNs-Uzawa基准测试中验证了预测的方差率，并在相同计算成本下展示了相对于单级MC-dropout的效率提升。

Conclusion: 多级蒙特卡洛框架能够有效降低蒙特卡洛dropout的方差，提高不确定性量化的计算效率，为深度学习模型的不确定性估计提供了更实用的工具。

Abstract: We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.

</details>


### [367] [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284)
*Duygu Nur Yaldiz,Evangelia Spiliopoulou,Zheng Qi,Siddharth Varia,Srikanth Doss,Nikolaos Pappas*

Main category: cs.LG

TL;DR: 本文系统研究了LLM在决策任务中的校准问题，比较了监督微调(SFT)和带可验证奖励的强化学习(RLVR)两种微调范式，发现RLVR虽然提升任务性能但产生过度自信模型，而SFT校准更好但性能增益较小。作者提出了校准感知的强化学习方法来解决RLVR的过度自信问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地部署在决策任务中，不仅需要准确性，还需要可靠的置信度估计。良好校准的置信度使下游系统能够决定何时信任模型、何时依赖备用机制。然而，当前广泛使用的微调范式在模型校准方面存在显著差异，需要系统研究。

Method: 1. 系统研究监督微调(SFT)和带可验证奖励的强化学习(RLVR)两种微调范式的校准特性；2. 通过针对性实验诊断RLVR失败的原因，发现决策令牌在推理轨迹中作为决策提取步骤，不携带置信度信息；3. 提出校准感知的强化学习公式，直接调整决策令牌的概率。

Result: 1. RLVR提高任务性能但产生极度过度自信的模型；2. SFT产生显著更好的校准，即使在分布偏移下也如此，但性能增益较小；3. 提出的校准感知强化学习方法在保持RLVR准确性的同时缓解过度自信，将ECE分数降低高达9个点。

Conclusion: RLVR虽然能提升任务性能，但会导致模型过度自信，而SFT在校准方面表现更好但性能有限。通过理解决策令牌在推理中的作用，提出的校准感知强化学习方法能够有效解决过度自信问题，在保持准确性的同时改善校准性能。

Abstract: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.

</details>


### [368] [Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans](https://arxiv.org/abs/2601.13350)
*Abdel Djalil Sad Saoud,Fred Maurice Ngolè Mboula,Hanane Slimani*

Main category: cs.LG

TL;DR: 该论文提出了一种基于谱嵌入的领域自适应方法，将平滑传输计划解释为连接源域和目标域的二部图邻接矩阵，从而获得领域不变的特征表示。


<details>
  <summary>Details</summary>
Motivation: 训练数据和推理数据之间的分布偏移是机器学习中的核心挑战，会导致性能下降。传统的基于最优传输的无监督领域自适应方法依赖于使用传输计划近似Monge映射，这种方法对传输问题正则化策略和超参数敏感，可能导致有偏的领域对齐。

Method: 将平滑传输计划解释为连接源域和目标域的二部图的邻接矩阵，通过谱嵌入技术从这些图中提取领域不变的样本表示。

Result: 在音乐流派识别、音乐-语音判别以及不同诊断设置下使用时域反射的电缆缺陷检测和分类任务上进行了评估，取得了整体强劲的性能表现。

Conclusion: 提出的谱嵌入方法提供了一种有效的领域自适应解决方案，能够从平滑传输计划中提取领域不变的特征表示，在多个实际应用中表现出色。

Abstract: Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.

</details>


### [369] [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398)
*Nickil Maveli,Antonio Vergari,Shay B. Cohen*

Main category: cs.LG

TL;DR: RTCE是一个评估代码LLM往返执行一致性的基准测试，发现现有模型在保持编码-解码双向映射一致性方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在代码基准测试中表现良好，但在往返代码执行中显示出推理一致性的局限性。现有基准测试无法全面评估模型在编码和解码操作之间保持一对一映射的能力。

Method: 提出了RoundTripCodeEval(RTCE)基准测试，包含四种不同的代码执行推理任务，通过无执行、精确匹配的方式评估双向映射保真度。采用零样本提示、监督微调执行轨迹和自反思机制三种方法系统评估最先进的代码LLM。

Result: 所有评估方法都只带来适度改进，但都无法弥补差距。当前LLM在真正的往返一致性方面存在困难，缺乏可信代码推理所需的内在一致性。RTCE揭示了现有I/O预测、执行推理或往返自然语言基准测试无法捕捉的新见解。

Conclusion: 当前LLM缺乏保持往返代码执行一致性的能力，这表明它们在可信代码推理方面存在内在一致性不足的问题。RTCE基准测试为评估代码推理的一致性提供了新的重要维度。

Abstract: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.

</details>


### [370] [A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization](https://arxiv.org/abs/2601.13435)
*Shuozhe Li,Du Cheng,Leqi Liu*

Main category: cs.LG

TL;DR: WaveLSFormer：一种可学习的小波变换长短期Transformer模型，用于日内交易策略学习，通过端到端训练的小波滤波器组进行多尺度分解，结合风险预算约束和交易目标优化，在多个行业组上显著超越传统模型。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列的日内交易策略学习面临三大挑战：1）噪声严重；2）非平稳性；3）相关资产间的强横截面依赖性。传统方法难以有效处理这些复杂特征。

Method: 提出WaveLSFormer模型：1）可学习小波前端：通过端到端训练的滤波器组生成低/高频分量，使用频谱正则化器确保稳定且分离良好的频带；2）低频引导高频注入模块：融合多尺度信息，用高频线索细化低频表示；3）风险预算约束：将投资组合头寸重新缩放以满足固定风险预算；4）直接优化：使用交易目标和风险感知正则化进行端到端训练。

Result: 在5年小时数据、6个行业组、10个随机种子的广泛实验中，WaveLSFormer始终优于MLP、LSTM和Transformer基线模型（无论是否使用固定离散小波前端）。在所有行业平均中，累计总策略收益为0.607±0.045，夏普比率为2.157±0.166，显著提升了盈利能力和风险调整后收益。

Conclusion: WaveLSFormer通过可学习的小波分解和Transformer架构，有效解决了金融时间序列的噪声、非平稳性和横截面依赖问题，实现了更优的日内交易策略学习，在盈利能力和风险控制方面均显著超越现有方法。

Abstract: Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \pm 0.045$ and a Sharpe ratio of $2.157 \pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.

</details>


### [371] [Fairness-informed Pareto Optimization : An Efficient Bilevel Framework](https://arxiv.org/abs/2601.13448)
*Sofiane Tanji,Samuel Vaiter,Yassine Laguel*

Main category: cs.LG

TL;DR: BADR是一个双层自适应重标量化框架，用于为任何公平性指标恢复最优帕累托效率模型，解决了现有公平机器学习方法常产生帕累托无效模型的问题。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习方法常产生帕累托无效模型，某些群体的性能可以在不损害其他群体的情况下得到改善。传统处理方法如公平正则化存在此问题，而现有帕累托效率方法偏向特定公平视角，无法适应文献中广泛的公平性指标。

Method: 提出BADR（Bilevel Adaptive Rescalarisation）框架，包含双层优化：下层是加权经验风险最小化任务，权重是各群体的凸组合；上层优化选定的公平性目标。开发了两种大规模单循环算法BADR-GD和BADR-SGD，并建立了收敛保证。

Result: 发布了badr开源Python工具箱，支持多种学习任务和公平性指标。广泛的数值实验表明BADR优于现有的帕累托效率公平方法。

Conclusion: BADR提供了一个简单而有效的框架，能够为任何公平性指标恢复最优帕累托效率模型，解决了现有方法的局限性，并通过开源工具促进实际应用。

Abstract: Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.

</details>


### [372] [Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay](https://arxiv.org/abs/2601.13456)
*Sahasra Kokkula,Daniel David,Aaditya Baruah*

Main category: cs.LG

TL;DR: 在联邦学习中，针对时间概念漂移问题，提出客户端经验回放方法，通过维护少量历史样本缓冲区来防止灾难性遗忘，无需修改服务器聚合机制。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在处理时间概念漂移时面临灾难性遗忘问题，当客户端数据分布随时间变化时，标准FedAvg方法性能会显著下降。

Method: 提出客户端经验回放方法，每个客户端在本地训练时维护一个小型历史样本缓冲区，将过去样本与当前数据混合使用，无需修改服务器聚合机制。

Result: 在Fashion-MNIST的季节性漂移实验中，标准FedAvg准确率从74%降至28%，而使用每类50个样本的缓冲区后，性能恢复到78-82%，有效防止遗忘。

Conclusion: 客户端经验回放是一种简单有效的联邦学习抗遗忘方法，通过内存-准确率权衡实现性能提升，无需改变联邦学习框架的核心架构。

Abstract: Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.

</details>


### [373] [Preconditioning Benefits of Spectral Orthogonalization in Muon](https://arxiv.org/abs/2601.13474)
*Jianhao Ma,Yu Huang,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

TL;DR: 该研究通过矩阵分解和线性Transformer的上下文学习两个案例，分析了简化版Muon优化器的收敛性能，证明其具有与条件数无关的线性收敛速度，优于梯度下降和Adam优化器。


<details>
  <summary>Details</summary>
Motivation: Muon优化器作为利用梯度谱正交化的大语言模型预训练里程碑算法，其底层机制特别是梯度正交化的作用仍未被充分理解。目前很少有工作提供端到端分析来严格解释其在具体应用中的优势。

Method: 通过研究简化版Muon优化器在两个案例中的有效性：矩阵分解和线性Transformer的上下文学习问题。在谱域中分析Muon动力学解耦为独立标量序列的收敛行为。

Result: 证明简化版Muon在线性Transformer的上下文学习和矩阵分解问题中均具有线性收敛性，且迭代复杂度与相关条件数无关，在理论上优于梯度下降和Adam优化器。

Conclusion: Muon动力学在谱域解耦为独立标量序列，每个序列表现出相似的收敛行为。该理论形式化了谱正交化诱导的预条件效应，为Muon在这些矩阵优化问题及其它潜在应用中的有效性提供了理论解释。

Abstract: The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.

</details>


### [374] [StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing](https://arxiv.org/abs/2601.13522)
*Shuang Li*

Main category: cs.LG

TL;DR: 提出了一种基于Tucker分解的随机交替最小化算法，用于低秩张量感知问题，避免了昂贵的张量投影操作，实现了高效的小批量更新。


<details>
  <summary>Details</summary>
Motivation: 低秩张量感知是信号处理和机器学习中的基础问题，低Tucker秩张量能有效捕捉高维数据的多模态子空间结构。现有方法要么需要昂贵的张量投影操作，要么依赖于全梯度计算，而大多数随机因子化方法仅限于张量分解场景。

Method: 提出了一种随机交替最小化算法，直接在Tucker分解的核心张量和因子矩阵上操作。该方法避免了重复的张量投影，并支持在低维张量因子上进行高效的小批量更新。

Result: 在合成张量感知的数值实验中，与代表性的随机张量恢复基线方法相比，所提算法在运行时间上表现出更优的收敛行为。

Conclusion: 该工作提出了一种高效的随机交替最小化方法，用于低Tucker秩张量感知问题，通过直接在因子化表示上操作，避免了昂贵的张量投影，实现了计算效率的提升。

Abstract: Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.

</details>


### [375] [MN-TSG:Continuous Time Series Generation with Irregular Observations](https://arxiv.org/abs/2601.13534)
*Xu Zhang,Junwei Deng,Chang Xu,Hao Li,Jiang Bian*

Main category: cs.LG

TL;DR: MN-TSG提出了一种基于专家混合的神经控制微分方程框架，用于处理不规则采样时间序列的连续生成任务，在多个数据集上优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列生成方法通常假设规则采样和固定输出分辨率，与现实世界中不规则采样和稀疏观测的数据不匹配，特别是在临床监测等应用中需要连续高分辨率时间序列支持下游任务。

Method: 提出MN-TSG框架，采用基于专家混合的神经控制微分方程架构，包含动态参数化的专家函数和分离设计以优化MoE动态特性，并利用现有TSG模型学习专家混合与生成时间序列的联合分布。

Result: 在十个公共和合成数据集上的广泛实验表明，MN-TSG在从不规则到规则以及从不规则到连续生成任务上均优于强基线方法。

Conclusion: MN-TSG通过结合MoE-NCDE架构和现有TSG模型，有效解决了不规则采样时间序列的连续生成问题，能够生成新样本并产生适合每个样本的专家配置，支持精细的连续时间序列生成。

Abstract: Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.
  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.
  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.
  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.

</details>


### [376] [ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits](https://arxiv.org/abs/2601.13563)
*Aryan Karmore*

Main category: cs.LG

TL;DR: ButterflyMoE通过将专家视为共享量化基质的几何重定向，而非独立权重矩阵，实现了专家数量的亚线性内存增长，显著减少MoE模型的内存占用。


<details>
  <summary>Details</summary>
Motivation: 传统MoE方法中，N个独立专家权重矩阵需要O(N·d²)内存，这超出了边缘设备的存储预算。现有压缩方法如量化、剪枝和低秩分解只能减少常数因子，无法解决线性扩展瓶颈。

Method: 提出ButterflyMoE方法，将专家视为共享量化基质的几何重定向而非独立权重矩阵。通过对共享三元原型应用学习到的旋转，每个专家获得O(d² + N·d log d)内存，实现专家数量的亚线性增长。关键洞察：在量化过程中训练这些旋转可以减少激活异常值并稳定极端低位训练。

Result: 在语言建模基准测试中，ButterflyMoE在256个专家时实现了150倍内存减少，精度损失可忽略。这使得64个专家可以适配4GB设备，而标准MoE只能容纳8个专家。

Conclusion: 几何参数化打破了MoE模型的线性内存扩展瓶颈，为边缘设备上的大规模专家模型部署提供了可行方案。

Abstract: Linear memory scaling stores $N$ independent expert weight matrices requiring $\mathcal{O}(N \cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\mathcal{O}(d^2 + N \cdot d \log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling.

</details>


### [377] [Self-Improvement as Coherence Optimization: A Theoretical Account](https://arxiv.org/abs/2601.13566)
*Tianyi Qiu,Ahmed Hani Ismail,Zhonghao He,Shi Feng*

Main category: cs.LG

TL;DR: 论文证明无监督自改进方法（如辩论、自举、内部一致性最大化）都是"一致性优化"的特殊案例，即寻找最可压缩和联合可预测的上下文到行为的映射，这等价于描述长度正则化，且在预训练模型下是半监督学习的最优方案。


<details>
  <summary>Details</summary>
Motivation: 语言模型无需外部监督就能提高准确性的现象（如辩论、自举等方法）虽然有效，但其工作原理缺乏理论解释。本文旨在从理论上阐明这些无监督自改进方法为何有效。

Method: 提出"一致性优化"理论框架，证明各种无监督自改进方法都是该框架的特殊案例。通过理论分析证明一致性优化等价于描述长度正则化，并推导出在预训练模型下这是半监督学习的最优正则化方案。

Result: 理论分析表明一致性优化是描述长度正则化的特例，在预训练模型下是半监督学习的最优正则化方案。初步实验支持理论预测，解释了无监督自改进为何有效，并能预测其成功或失败的条件。

Conclusion: 无监督自改进方法（辩论、自举等）的成功源于它们都是一致性优化的特殊形式，这为理解语言模型自我改进提供了统一的理论框架，并能指导何时应用这些方法以及预期效果。

Abstract: Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.

</details>


### [378] [Behavior Knowledge Merge in Reinforced Agentic Models](https://arxiv.org/abs/2601.13572)
*Xiangchi Yuan,Dachuan Shi,Chunhui Zhang,Zheyuan Liu,Shenglong Yao,Soroush Vosoughi,Wenke Lee*

Main category: cs.LG

TL;DR: RAM是一个专门为RL训练的智能体模型设计的分布感知合并框架，通过分离共享和任务特定的参数更新，解决了传统合并方法在RL智能体上的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法主要针对监督微调(SFT)设计，不适用于RL训练的智能体模型。RL产生的任务向量具有高度稀疏和异质性，而SFT风格的合并假设密集且全局可比较的任务向量，导致关键任务特定行为被稀释。

Method: RAM框架明确分离共享参数更新和任务特定独特参数更新：对共享组件进行平均，同时选择性地保留和重新缩放独特组件，以抵消参数更新稀释效应。

Result: 在多个智能体领域和模型架构上的实验表明，RAM不仅超越了现有的合并基线，还能解锁智能体之间的协同潜力，实现优于专门领域智能体的性能。

Conclusion: RAM是针对RL训练智能体模型的有效合并框架，解决了任务向量不匹配问题，能够更好地保留任务特定能力并实现性能提升。

Abstract: Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.

</details>


### [379] [FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning](https://arxiv.org/abs/2601.13578)
*Qian Feng,JiaHang Tu,Mintong Kang,Hanbin Zhao,Chao Zhang,Hui Qian*

Main category: cs.LG

TL;DR: 提出FG-OrIU框架，通过特征和梯度的双重正交约束实现深度遗忘，解决增量遗忘中的表面遗忘问题


<details>
  <summary>Details</summary>
Motivation: 现有增量遗忘方法主要在参数层面抑制或混淆知识，缺乏特征和梯度层面的明确约束，导致表面遗忘问题，残留信息仍可恢复，存在安全风险并破坏保留平衡

Method: 提出FG-OrIU框架：1) 使用SVD分解特征空间，分离遗忘和保留类别特征到不同子空间；2) 实施双重正交约束：特征正交投影和梯度正交投影；3) 动态子空间适应机制，合并新遗忘子空间并收缩保留子空间

Result: 实验证明该方法能实现深度遗忘，遗忘效果不可逆，在连续遗忘任务中保持稳定的移除与保留平衡

Conclusion: FG-OrIU是首个统一特征和梯度正交约束的增量遗忘框架，能有效解决表面遗忘问题，实现安全可靠的深度遗忘

Abstract: Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [380] [Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models](https://arxiv.org/abs/2601.13580)
*Ahmad Al-Zuraiqi*

Main category: cs.LG

TL;DR: Neural Organ Transplantation (NOT) 是一种模块化适配框架，可将训练好的Transformer层作为可重用的可移植检查点进行领域适配，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法将训练参数与特定模型实例和训练数据紧密耦合，缺乏模块化和可重用性。NOT旨在创建可移植的"器官"检查点，实现隐私保护的专家知识共享。

Method: 从预训练模型中提取连续层子集作为"供体器官"，在领域特定数据上独立训练，保存为独立检查点文件，然后移植到兼容的接收模型中，无需原始训练数据。

Result: 在三个解码器架构（GPT-2、TinyLlama、GPT-OSS，124M到20B参数）上，NOT显著优于现有适配方法，困惑度比LoRA提高一个数量级，训练速度更快。早期插入位置效果最佳，跨领域转移在十亿参数规模上显示出意外的正则化效益。

Conclusion: Transformer中间层支持解码器架构的高效模块化转移，通过检查点分发实现隐私保护的专家知识共享。该方法目前仅限于解码器模型，在编码器架构上效果有限。

Abstract: We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ("donor organs") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.

</details>


### [381] [Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models](https://arxiv.org/abs/2601.13599)
*Linrui Ma,Yufei Cui,Kai Han,Yunhe Wang*

Main category: cs.LG

TL;DR: 提出Diffusion in Diffusion框架，通过"草稿-精炼"两阶段解决块扩散语言模型的不可逆性和短视问题，在OpenWebText数据集上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 块扩散语言模型虽然结合了自回归和扩散模型的优势，但其严格的单向块依赖导致不可逆性和缺乏全局规划能力，限制了性能提升

Method: 采用两阶段框架：1) 用小块进行块扩散快速生成草稿；2) 用大双向感受野进行全局双向扩散精炼草稿。使用快照置信度重掩码识别需要修改的关键词元，并采用混合尺度训练扩展块扩散模型的全局能力

Result: 在OpenWebText数据集上为离散扩散模型设立了新基准，仅使用基线模型26%的微调预算，将生成困惑度从25.7降低到21.9，显著缩小了与自回归模型的性能差距

Conclusion: Diffusion in Diffusion框架有效解决了块扩散模型的不可逆性和短视问题，通过草稿-精炼两阶段策略显著提升了离散扩散模型的性能，为语言生成提供了更高效的解决方案

Abstract: Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.

</details>


### [382] [Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data](https://arxiv.org/abs/2601.13608)
*Zhipeng Chang,Ting He,Wenrui Hao*

Main category: cs.LG

TL;DR: FIPA是一种联邦学习中的二阶聚合方法，使用参数特定的Fisher信息矩阵权重替代客户端级标量权重，解决非IID数据下的客户端漂移问题。


<details>
  <summary>Details</summary>
Motivation: 在非IID数据分布下，传统的FedAvg等一阶方法对所有参数应用相同的标量权重，导致客户端更新严重错位，引起客户端漂移并降低全局模型性能。

Method: 提出Fisher信息参数化聚合(FIPA)，用参数特定的Fisher信息矩阵权重替代客户端级标量权重，实现真正的参数级缩放，捕捉每个客户端数据对不同参数的独特影响。通过低秩近似保持通信和计算效率。

Result: 在非线性函数回归、PDE学习和图像分类任务中，FIPA始终优于基于平均的聚合方法，并能有效结合最先进的客户端优化算法进一步提升图像分类准确率。

Conclusion: FIPA在异构数据分布下的联邦学习中具有显著优势，通过参数特定的二阶聚合机制解决了客户端漂移问题。

Abstract: Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.

</details>


### [383] [Quadratic Upper Bound for Boosting Robustness](https://arxiv.org/abs/2601.13645)
*Euijin You,Hyang-Won Lee*

Main category: cs.LG

TL;DR: 该论文提出了一种二次上界损失函数来改善快速对抗训练中因对抗空间探索不足导致的鲁棒性下降问题。


<details>
  <summary>Details</summary>
Motivation: 快速对抗训练虽然减少了训练时间，但往往因为对抗空间探索不足而导致模型鲁棒性下降，需要解决这一矛盾。

Method: 推导了对抗训练损失函数的二次上界，并将该上界损失与现有快速对抗训练方法结合使用。

Result: 实验结果表明，将QUB损失应用于现有方法能显著提高模型鲁棒性，且这种改进可能源于所得模型的损失景观变得更加平滑。

Conclusion: 提出的二次上界损失函数能有效缓解快速对抗训练中的鲁棒性下降问题，通过平滑损失景观来提高模型对抗攻击的鲁棒性。

Abstract: Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.

</details>


### [384] [Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction](https://arxiv.org/abs/2601.13710)
*Sayeed Shafayet Chowdhury,Snehasis Mukhopadhyay,Shiaofen Fang,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 该研究比较了监督机器学习与生成式AI在预测慢性鼻窦炎手术效果方面的表现，发现MLP模型在准确率、校准和决策曲线净收益方面优于生成式AI，建议采用ML为主、GenAI辅助的工作流程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在医学影像领域已有广泛应用，但在临床数据上进行前瞻性决策支持的应用仍然有限。研究旨在探索术前预测慢性鼻窦炎手术效果的方法，识别那些术后效果不佳、本应避免手术的患者。

Method: 研究使用前瞻性收集的队列数据，所有患者均接受了手术。比较了监督机器学习方法（逻辑回归、树集成模型和自研MLP）与生成式AI模型（ChatGPT、Claude、Gemini、Perplexity）的表现。所有模型接收相同的结构化输入，输出被约束为二元推荐和置信度。

Result: 最佳ML模型（MLP）达到85%的准确率，具有更好的校准和决策曲线净收益。生成式AI模型在零样本设置下的区分度和校准表现较差。值得注意的是，生成式AI的解释与临床医生的启发式方法和MLP的特征重要性一致，都强调基线SNOT-22评分、CT/内镜严重程度、息肉表型以及心理/疼痛共病。

Conclusion: 研究支持ML优先、GenAI增强的工作流程：部署校准的ML模型进行手术候选者的初步筛选，使用生成式AI作为解释器来增强透明度和共享决策制定。研究还提供了可复制的表格数据到生成式AI的评估协议和亚组分析。

Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.

</details>


### [385] [EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory](https://arxiv.org/abs/2601.13748)
*Tien-Dat Pham,Xuan-The Tran*

Main category: cs.LG

TL;DR: EEG-Titans：一种双分支架构，结合滑动窗口注意力捕捉短期异常和循环记忆通路总结长期趋势，在CHB-MIT头皮EEG数据集上实现99.46%平均段级敏感度，通过分层上下文策略显著降低误报率。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作预测面临挑战：发作前动态可能跨越长时间范围，而临床相关特征可能微妙且短暂。现有深度学习模型在处理超长序列时，需要在捕捉局部时空模式和保持信息丰富的长距离上下文之间进行权衡。

Method: 提出EEG-Titans双分支架构，结合现代神经记忆机制进行长上下文建模。模型包含：1）滑动窗口注意力捕捉短期异常；2）循环记忆通路总结随时间变化的缓慢渐进趋势。采用分层上下文策略，为高噪声受试者扩展感受野。

Result: 在CHB-MIT头皮EEG数据集上，按时间顺序保留协议评估，EEG-Titans在18名受试者中达到99.46%平均段级敏感度。分层上下文策略显著降低误报率（极端异常情况下降至0.00 FPR/h），同时不牺牲敏感度。

Conclusion: 记忆增强的长上下文建模可以在临床约束评估下提供稳健的癫痫发作预测，通过分层上下文策略有效处理噪声数据，平衡敏感度和特异性。

Abstract: Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation

</details>


### [386] [vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.13768)
*Wenzhen Yue,Ruohao Guo,Ji Shi,Zihan Hao,Shiyu Hu,Xianghua Ying*

Main category: cs.LG

TL;DR: vLinear是一种基于线性运算的高效多元时间序列预测器，包含vecTrans模块和WFMLoss目标函数，在保持高性能的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的预测器通常依赖自注意力或其变体来捕捉多元相关性，这通常会产生O(N²)的计算复杂度（N为变量数）。为了解决这个问题，需要开发更高效的预测方法。

Method: 提出两个核心组件：1) vecTrans模块，使用可学习向量建模多元相关性，将复杂度降至O(N)；2) WFMLoss目标函数，采用最终序列导向的流匹配方法，并结合路径和水平加权策略来聚焦学习。

Result: vLinear在22个基准测试和124个预测设置中实现了最先进的性能。vecTrans模块可以无缝集成到基于Transformer的预测器中，提供高达5倍的推理加速和一致的性能提升。WFMLoss作为即插即用的目标函数，能持续改进现有预测器。

Conclusion: vLinear通过vecTrans模块和WFMLoss目标函数，在保持高性能的同时显著降低了计算复杂度，为多元时间序列预测提供了一种有效且高效的解决方案。

Abstract: In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.

</details>


### [387] [Principled Latent Diffusion for Graphs via Laplacian Autoencoders](https://arxiv.org/abs/2601.13780)
*Antoine Siraudin,Christopher Morris*

Main category: cs.LG

TL;DR: LG-Flow：一种潜在图扩散框架，通过将图压缩到低维潜在空间进行扩散，解决了传统图扩散模型二次复杂度问题，实现近无损重建，速度提升高达1000倍


<details>
  <summary>Details</summary>
Motivation: 传统图扩散模型存在二次复杂度问题，且大部分计算资源浪费在稀疏图的边缺失建模上。需要在潜在空间进行扩散，但图生成需要近乎无损的重建，这一挑战尚未解决

Method: 提出LG-Flow框架：1）使用置换等变自编码器将节点映射到固定维嵌入，确保邻接矩阵可证明恢复；2）在潜在空间训练基于流匹配的扩散变换器；3）潜在表示维度与节点数线性相关，消除二次瓶颈

Result: 与最先进的图扩散模型相比取得竞争性结果，同时实现高达1000倍的加速，支持无向图和DAG的生成

Conclusion: LG-Flow通过潜在空间扩散成功解决了图生成的二次复杂度问题，实现了高效且表达力强的图生成，为大规模图建模提供了可行方案

Abstract: Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.

</details>


### [388] [PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles](https://arxiv.org/abs/2601.13793)
*ByeoungDo Kim,JunYeop Na,Kyungwook Tak,JunTae Kim,DongHyeon Kim,Duckky Kim*

Main category: cs.LG

TL;DR: 提出基于注意力机制的ETA预测模型，通过历史道路速度模式进行时空特征提取，实现轻量级且准确的到达时间估计


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和智能交通系统的发展，准确可靠的ETA预测在导航、出行规划和交通管理中变得至关重要。然而，由于交通流的动态复杂性，传统方法要么简单组合实时和历史数据，要么依赖复杂的基于规则的计算，而现有深度学习模型计算成本高且未能有效捕捉关键的时空模式。

Method: 提出基于注意力机制的ETA模型，利用注意力机制提取和利用沿路线每个时空点累积的时间特征。该架构通过注意力机制处理历史道路速度模式，有效整合道路特征、实时交通状况和历史速度模式，同时保持模型轻量化和可扩展。

Result: 使用真实世界驾驶数据集验证方法，证明该模型在有效整合道路特征、实时交通条件和历史速度模式方面优于现有基线方法。

Conclusion: 提出的基于注意力机制的ETA模型能够有效处理ETA预测中的时空因果关系，实现高效准确的到达时间估计，同时保持模型的轻量化和可扩展性，为智能交通系统提供了实用的解决方案。

Abstract: In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.

</details>


### [389] [Inverting Self-Organizing Maps: A Unified Activation-Based Framework](https://arxiv.org/abs/2601.13851)
*Alessandro Londei,Matteo Benati,Denise Lanzieri,Vittorio Loreto*

Main category: cs.LG

TL;DR: 论文提出MUSIC方法，基于自组织映射(SOM)的原型距离几何特性实现精确输入恢复和可控语义轨迹生成，无需采样、先验或编解码器架构。


<details>
  <summary>Details</summary>
Motivation: 自组织映射(SOM)广泛用于可视化、聚类和向量量化，但传统方法缺乏精确输入恢复和可控语义变化的能力。论文旨在利用SOM激活模式的几何特性，实现精确输入恢复和可控的潜在空间探索。

Method: 基于欧几里得距离几何原理：D维空间中的点可由其到D+1个仿射独立参考点的距离唯一确定。推导相应线性系统，提出MUSIC更新规则，通过修改选定原型的平方距离同时保持其他距离不变，实现确定性几何流。使用Tikhonov正则化稳定更新规则。

Result: 在合成高斯混合、MNIST和Faces in the Wild数据集上验证，MUSIC能产生平滑、可解释的轨迹，揭示学习流形的底层几何结构，展示SOM基于反转相比无监督聚类的优势。

Conclusion: MUSIC提供了一种基于原型几何的数据增强和可控潜在探索新视角，无需依赖采样、潜在先验或编解码器架构，能精确恢复输入并产生连贯的语义变化，同时保持在数据流形上。

Abstract: Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.

</details>


### [390] [PAC-Private Responses with Adversarial Composition](https://arxiv.org/abs/2601.14033)
*Xiaochen Zhu,Mayuri Sridhar,Srinivas Devadas*

Main category: cs.LG

TL;DR: 论文提出了一种基于PAC隐私的API模型输出隐私保护方法，通过控制互信息实现实例级隐私，在对抗性查询下保持线性组合性，在极小的隐私预算下实现高精度。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型常通过API部署，传统权重隐私方法（如DP-SGD）在API场景下噪声过大且效用低。模型权重对训练数据敏感，但模型对特定输入的输出维度更低且更稳定，因此需要在模型输出层面直接实施隐私保护。

Method: 采用PAC隐私框架，通过控制互信息实现任意黑盒函数的实例级隐私保护。提出新算法通过自适应噪声校准实现对抗性组合，证明在自适应和对抗性查询下互信息保证线性累积。

Result: 在表格、视觉和NLP任务中，方法在极小的每查询隐私预算下实现高效用。CIFAR-10上达到87.79%准确率，每步MI预算仅2^{-32}。服务100万查询时，成员推理攻击成功率上限为51.08%，相当于(0.04, 10^{-5})-DP保证。通过私有响应标注公共数据蒸馏模型，在ImageNet子集上从21万响应蒸馏的模型在CIFAR-10上达到91.86%准确率，MIA成功率上限50.49%，相当于(0.02,10^{-5})-DP。

Conclusion: 该方法在API部署场景下有效平衡隐私与效用，通过输出级隐私保护在对抗性查询下提供强隐私保证，同时支持通过知识蒸馏发布隐私保护模型，为实际部署提供了实用解决方案。

Abstract: Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.
  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.
  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.

</details>


### [391] [LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems](https://arxiv.org/abs/2601.14053)
*Badri N. Patro,Vijay S. Agneeswaran*

Main category: cs.LG

TL;DR: LLMOrbit提出一个2019-2025年大语言模型的循环分类法，分析了50多个模型，识别了数据稀缺、成本增长和能耗三大危机，并揭示了突破扩展墙的六大范式：测试时计算、量化、分布式边缘计算、模型融合、高效训练和小型专用模型。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能从基础Transformer架构发展到接近人类水平的推理系统，需要系统性地梳理大语言模型的发展脉络。研究旨在通过全面的分类法来导航LLM领域，分析架构创新、训练方法和效率模式，同时识别限制暴力扩展方法的关键危机。

Method: 提出LLMOrbit循环分类法，通过八个相互关联的轨道维度分析2019-2025年间超过50个模型和15个组织。采用多维度框架考察架构创新、训练方法、效率模式，并系统分析突破扩展限制的技术范式。

Result: 识别了三大危机：数据稀缺（2026-2028年耗尽9-27T tokens）、指数级成本增长（5年内从300万美元到3亿美元以上）、不可持续的能耗（增加22倍）。发现了突破扩展墙的六大范式，并揭示了三个范式转变：训练后增益、效率革命和民主化。

Conclusion: 大语言模型领域正面临扩展墙的限制，但通过测试时计算、量化、分布式计算等创新范式正在突破这些限制。未来将向更高效、更民主化的方向发展，从被动生成转向工具使用和多智能体系统，训练后优化技术将发挥关键作用。

Abstract: The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.

</details>


### [392] [Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping](https://arxiv.org/abs/2601.14099)
*Shi-Shun Chen,Xiao-Yang Li,Enrico Zio*

Main category: cs.LG

TL;DR: 提出基于时滞交叉映射的因果特征选择框架，解决工业过程中变量间时滞和相互依赖问题，提升软测量模型性能


<details>
  <summary>Details</summary>
Motivation: 现有因果特征选择方法忽视工业过程的两个关键特性：1) 变量间因果关系存在时滞，而现有方法多在同一时间维度分析；2) 工业过程变量相互依赖，与传统因果推断方法的去相关假设相矛盾，导致软测量模型准确性和稳定性不足

Method: 提出基于时滞交叉映射的因果特征选择框架：1) 使用时滞收敛交叉映射(TDCCM)进行完全因果推断；2) 使用时滞偏交叉映射(TDPCM)进行直接因果推断；3) 提出客观特征选择策略，基于验证集模型性能自动确定因果阈值并选择因果特征

Result: 两个真实案例研究表明：TDCCM达到最高平均性能，TDPCM在最差情况下提升软测量稳定性和性能

Conclusion: 提出的时滞交叉映射框架能有效处理工业过程中变量间的时滞和相互依赖问题，提升软测量模型的准确性和稳定性，代码已公开

Abstract: Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.

</details>


### [393] [A model of errors in transformers](https://arxiv.org/abs/2601.14175)
*Suvrat Raju,Praneeth Netrapalli*

Main category: cs.LG

TL;DR: 论文研究了LLMs在需要确定性输出的任务（如算术）上的错误率，发现错误源于注意力机制中微小误差的累积，并建立了准确率与任务复杂度的两参数定量关系。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在需要确定性输出的任务（如算术）上的错误率，这些任务涉及对来自小集合的标记进行重复处理。旨在理解错误产生的机制，并提供定量分析框架。

Method: 采用"有效场论"视角，将LLMs的众多原始参数重组为两个控制错误率的参数：基本噪声率和可能错误预测的标记数。通过理论分析和广泛的实证测试（使用Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1模型）验证模型。

Result: 发现预测准确率与观测准确率在多种任务上高度一致，尽管在某些情况下存在偏差。两参数模型能很好地描述错误率与任务复杂度的关系。

Conclusion: LLMs在长重复任务上的错误并非源于"推理崩溃"或无法表达"组合"函数，而是注意力机制中微小误差累积的结果。研究还展示了如何构建提示来降低错误率。

Abstract: We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.

</details>


### [394] [Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery](https://arxiv.org/abs/2601.14196)
*Albina Galiullina,Wouter van Heeswijk,Tom van Woensel*

Main category: cs.LG

TL;DR: 该研究提出了一种差异化取货点提供策略，通过为每位顾客推荐单一取货点而非无限制选择，同时保留送货上门选项，来联合减少配送卡车路线和顾客出行的碳排放。


<details>
  <summary>Details</summary>
Motivation: 取货点作为送货上门的可持续替代方案，通过订单整合可以缩短配送路线并提高首次投递成功率。但当顾客驾车取货时，这些环境效益可能会被抵消。因此需要一种策略来同时减少配送卡车和顾客出行的碳排放。

Method: 提出差异化取货点提供政策，在动态随机环境中，根据先前顾客位置和配送选择，为每位到达顾客推荐单一取货点。采用基于强化学习的方法，考虑顾客与取货点之间的空间关系及其对未来路线整合的影响。

Result: 计算实验表明，差异化取货点提供策略能显著减少总碳排放。相比纯送货上门，总排放最多减少9%；相比无限制取货点选择和最近取货点分配等替代策略，平均减少2%。在取货点多、距离短的密集城市环境中效果尤为显著。

Conclusion: 差异化取货点提供策略能有效减少总碳排放，特别适用于密集城市环境。当顾客不太倾向于选择取货点配送时，明确考虑顾客到达和选择的动态特性尤为重要。

Abstract: Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.

</details>


### [395] [InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning](https://arxiv.org/abs/2601.14209)
*Matthew Y. R. Yang,Hao Bai,Ian Wu,Gene Yang,Amrith Setlur,Aviral Kumar*

Main category: cs.LG

TL;DR: 论文提出Intervention Training (InT)训练范式，通过模型自身对推理轨迹进行细粒度信用分配，识别错误并生成单步干预，从而改善强化学习中的信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 传统结果奖励强化学习仅根据最终答案分配信用，导致正确中间步骤在失败轨迹中被惩罚，而错误步骤在成功轨迹中被强化，存在信用分配问题。虽然过程奖励模型是自然解决方案，但准确优化此类模型识别纠正性推理步骤仍然具有挑战性。

Method: 提出Intervention Training (InT)训练范式：模型利用数学推理数据集中通常可用的参考解决方案，识别自身推理中的第一个错误，并提出单步干预将轨迹转向正确解决方案。然后对有监督微调应用于错误点之前的策略展开与干预的拼接，将错误定位到导致失败的具体步骤。

Result: 经过InT和后续RL微调后，在4B参数基础模型上，IMO-AnswerBench准确率提高近14%，优于gpt-oss-20b等更大的开源模型。得到的模型为RL训练提供了更好的初始化。

Conclusion: Intervention Training通过模型自身进行细粒度信用分配，有效解决了强化学习中的信用分配问题，显著提升了大型语言模型的推理能力，为后续RL训练提供了更好的初始化。

Abstract: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.

</details>


### [396] [Q-learning with Adjoint Matching](https://arxiv.org/abs/2601.14234)
*Qiyang Li,Sergey Levine*

Main category: cs.LG

TL;DR: QAM是一种新的强化学习算法，通过伴随匹配技术解决连续动作RL中扩散/流匹配策略优化的数值不稳定问题，在稀疏奖励任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 连续动作强化学习中，如何高效优化表达性强的扩散或流匹配策略一直是个长期挑战。现有方法要么只使用价值信息而丢弃梯度信息，要么依赖近似方法牺牲策略表达性或引入偏差。

Method: QAM采用伴随匹配技术，将评论家的动作梯度转换为分步目标函数，避免了通过多步去噪过程进行反向传播的数值不稳定问题，同时保持策略的无偏性和表达性。

Result: QAM在离线RL和离线到在线RL的困难稀疏奖励任务上，始终优于现有方法。

Conclusion: QAM通过伴随匹配技术有效解决了连续动作RL中扩散策略优化的数值稳定性问题，为表达性策略优化提供了新途径。

Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.

</details>


### [397] [Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression](https://arxiv.org/abs/2601.14238)
*Shaurya Mathur,Shreyas Bellary Manjunath,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: FireCastRL是一个结合深度学习预测和强化学习灭火策略的AI框架，用于主动式野火管理


<details>
  <summary>Details</summary>
Motivation: 野火频率和强度不断增加，造成巨大生态和经济损失，传统管理方式被动反应，需要更主动的解决方案

Method: 使用深度时空模型预测野火起火点，对高风险预测部署预训练的强化学习智能体，在物理信息3D模拟中执行直升机灭火战术

Result: 开发了FireCastRL框架并公开了包含950万个环境变量样本的大规模时空数据集，支持野火预测和战术响应

Conclusion: 深度学习与强化学习结合可以同时支持野火预测和战术响应，为主动式野火管理提供新方法

Abstract: Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.

</details>


### [398] [Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow](https://arxiv.org/abs/2601.14243)
*Haocheng Xi,Charlie Ruan,Peiyuan Liao,Yujun Lin,Han Cai,Yilong Zhao,Shuo Yang,Kurt Keutzer,Song Han,Ligeng Zhu*

Main category: cs.LG

TL;DR: 该论文提出了Jet-RL框架，通过统一使用FP8精度进行强化学习训练和rollout，解决了现有BF16训练+FP8 rollout策略在长序列和复杂任务中的训练不稳定问题，实现了显著的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有RL训练中rollout阶段占用了超过70%的训练时间，量化训练（特别是FP8精度）是缓解这一瓶颈的有前景方法。但当前广泛采用的BF16训练+FP8 rollout策略在长序列和挑战性任务中存在严重的训练不稳定和精度崩溃问题。

Method: 提出了Jet-RL框架，核心思想是采用统一的FP8精度流程同时用于训练和rollout，最小化数值差异，消除低效的跨步骤校准需求。这是首个全面的FP8 RL训练研究。

Result: Jet-RL实现了显著加速：rollout阶段加速达33%，训练阶段加速达41%，端到端加速达16%（相比BF16训练）。同时在所有设置中保持稳定收敛，精度下降可忽略不计。

Conclusion: 统一FP8精度流程的Jet-RL框架能够实现稳定高效的RL训练，解决了现有混合精度策略的数值不匹配问题，为大规模语言模型的强化学习训练提供了有效的加速方案。

Abstract: Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.

</details>
