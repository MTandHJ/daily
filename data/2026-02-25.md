<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 26]
- [cs.LG](#cs.LG) [Total: 32]
- [cs.CY](#cs.CY) [Total: 5]
- [cs.IR](#cs.IR) [Total: 7]
- [cs.AI](#cs.AI) [Total: 9]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [OTPrune: Distribution-Aligned Visual Token Pruning via Optimal Transport](https://arxiv.org/abs/2602.20205)
*Xiwen Chen,Wenhui Zhu,Gen Li,Xuanzhao Dong,Yujian Xiong,Hao Wang,Peijie Qiu,Qingquan Song,Zhipeng Wang,Shao Tang,Yalin Wang,Abolfazl Razi*

Main category: cs.CV

TL;DR: OTPrune：基于最优传输的免训练视觉token剪枝框架，通过分布对齐减少MLLM推理成本


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型推理成本高，现有视觉token剪枝方法忽视了视觉表示的分布结构，需要更有效的剪枝方法

Method: 将剪枝问题形式化为分布对齐的最优传输问题，最小化完整token分布与剪枝后分布之间的2-Wasserstein距离，推导出可处理的子模目标函数

Result: 在广泛基准测试中，OTPrune相比现有方法实现了更优的性能-效率权衡，代码已开源

Conclusion: OTPrune通过分布对齐实现了稳定且语义保真的视觉token剪枝，为MLLM推理加速提供了理论基础和实用框架

Abstract: Multi-modal large language models (MLLMs) achieve strong visual-language reasoning but suffer from high inference cost due to redundant visual tokens. Recent work explores visual token pruning to accelerate inference, while existing pruning methods overlook the underlying distributional structure of visual representations. We propose OTPrune, a training-free framework that formulates pruning as distribution alignment via optimal transport (OT). By minimizing the 2-Wasserstein distance between the full and pruned token distributions, OTPrune preserves both local diversity and global representativeness while reducing inference cost. Moreover, we derive a tractable submodular objective that enables efficient optimization, and theoretically prove its monotonicity and submodularity, providing a principled foundation for stable and efficient pruning. We further provide a comprehensive analysis that explains how distributional alignment contributes to stable and semantically faithful pruning. Comprehensive experiments on wider benchmarks demonstrate that OTPrune achieves superior performance-efficiency tradeoffs compared to state-of-the-art methods. The code is available at https://github.com/xiwenc1/OTPrune.

</details>


### [2] [De-rendering, Reasoning, and Repairing Charts with Vision-Language Models](https://arxiv.org/abs/2602.20291)
*Valentin Bonas,Martin Sinnona,Viviana Siless,Emmanuel Iarussi*

Main category: cs.CV

TL;DR: 论文提出一个结合图表反渲染、自动分析和迭代改进的框架，为可视化设计提供可操作、可解释的反馈，通过LLM驱动的推荐系统提升图表质量和用户的可视化素养。


<details>
  <summary>Details</summary>
Motivation: 数据可视化在科学传播、新闻和日常决策中至关重要，但常存在错误。基于规则的检查工具缺乏上下文且无法提供有意义的改进建议，而通用LLM在可视化质量评估上不可靠，缺乏遵循可视化设计原则的训练。

Method: 提出一个框架：1) 从图像重建图表结构（反渲染）；2) 使用视觉语言推理识别设计缺陷；3) 基于可视化研究原则提出具体修改建议；4) 用户可选择应用改进并重新渲染，形成反馈循环。

Result: 在Chart2Code基准测试的1000个图表上，系统生成了10,452条设计建议，聚类为10个连贯类别（如轴格式化、颜色可访问性、图例一致性等）。

Conclusion: LLM驱动的推荐系统在提供结构化、基于原则的可视化设计反馈方面具有前景，为开发更智能、更易用的创作工具打开了大门。

Abstract: Data visualizations are central to scientific communication, journalism, and everyday decision-making, yet they are frequently prone to errors that can distort interpretation or mislead audiences. Rule-based visualization linters can flag violations, but they miss context and do not suggest meaningful design changes. Directly querying general-purpose LLMs about visualization quality is unreliable: lacking training to follow visualization design principles, they often produce inconsistent or incorrect feedback. In this work, we introduce a framework that combines chart de-rendering, automated analysis, and iterative improvement to deliver actionable, interpretable feedback on visualization design. Our system reconstructs the structure of a chart from an image, identifies design flaws using vision-language reasoning, and proposes concrete modifications supported by established principles in visualization research. Users can selectively apply these improvements and re-render updated figures, creating a feedback loop that promotes both higher-quality visualizations and the development of visualization literacy. In our evaluation on 1,000 charts from the Chart2Code benchmark, the system generated 10,452 design recommendations, which clustered into 10 coherent categories (e.g., axis formatting, color accessibility, legend consistency). These results highlight the promise of LLM-driven recommendation systems for delivering structured, principle-based feedback on visualization design, opening the door to more intelligent and accessible authoring tools.

</details>


### [3] [N4MC: Neural 4D Mesh Compression](https://arxiv.org/abs/2602.20312)
*Guodong Chen,Huanshuo Dong,Mallesham Dasari*

Main category: cs.CV

TL;DR: N4MC是首个4D神经压缩框架，通过利用时间冗余来高效压缩时变网格序列，相比现有方法实现了更好的率失真性能并支持实时解码。


<details>
  <summary>Details</summary>
Motivation: 现有神经网格压缩方法独立处理每个网格帧，忽略了时间冗余。受2D视频编解码器中帧间压缩的启发，需要开发能够利用网格序列时间相关性的压缩方法。

Method: 将连续的不规则网格帧转换为规则的4D张量作为统一紧凑表示；使用自动解码器压缩张量以捕获时空相关性；引入基于transformer的插值模型，通过跟踪体积中心的潜在嵌入预测中间网格帧，消除运动模糊。

Result: N4MC在率失真性能上优于现有最先进方法，能够实时解码4D网格序列，代码已开源。

Conclusion: N4MC通过利用网格序列的时间冗余，实现了高效的4D神经压缩，为时变网格压缩提供了新的解决方案。

Abstract: We present N4MC, the first 4D neural compression framework to efficiently compress time-varying mesh sequences by exploiting their temporal redundancy. Unlike prior neural mesh compression methods that treat each mesh frame independently, N4MC takes inspiration from inter-frame compression in 2D video codecs, and learns motion compensation in long mesh sequences. Specifically, N4MC converts consecutive irregular mesh frames into regular 4D tensors to provide a uniform and compact representation. These tensors are then condensed using an auto-decoder, which captures both spatial and temporal correlations for redundancy removal. To enhance temporal coherence, we introduce a transformer-based interpolation model that predicts intermediate mesh frames conditioned on latent embeddings derived from tracked volume centers, eliminating motion ambiguities. Extensive evaluations show that N4MC outperforms state-of-the-art in rate-distortion performance, while enabling real-time decoding of 4D mesh sequences. The implementation of our method is available at: https://github.com/frozzzen3/N4MC.

</details>


### [4] [GSNR: Graph Smooth Null-Space Representation for Inverse Problems](https://arxiv.org/abs/2602.20328)
*Romario Gualdrón-Hurtado,Roman Jacome,Rafael S. Suarez,Henry Arguello*

Main category: cs.CV

TL;DR: 提出Graph-Smooth Null-Space Representation (GSNR)方法，通过在不可见分量（零空间）中引入图平滑结构来改进图像逆问题重建，在多种逆问题场景中相比基线方法提升达4.3 dB PSNR。


<details>
  <summary>Details</summary>
Motivation: 图像逆问题通常存在无限多解，传统图像先验（如稀疏性、平滑性或得分函数）仅约束图像流形而不约束零空间分量，可能导致重建偏差。因此需要将有意义的零空间信息纳入重建框架。

Method: 提出图平滑零空间表示(GSNR)：基于图拉普拉斯构造零限制拉普拉斯，编码零空间信号中相邻像素的相似性，并从p个最平滑的谱图模式（最低图频率）设计低维投影矩阵。将GSNR集成到PnP、DIP和扩散求解器等逆问题求解器中。

Result: 在图像去模糊、压缩感知、去马赛克和图像超分辨率四种场景中，相比基线方法PSNR提升达4.3 dB，相比端到端学习模型提升达1 dB。GSNR带来：i) 通过零空间图正则化改善收敛性，ii) 更好的覆盖范围（p个模式捕获的零空间方差），iii) 更高的可预测性（这些模式从测量中推断的能力）。

Conclusion: 通过在图平滑零空间表示中引入结构化的零空间信息，能够显著改进图像逆问题重建质量，为传统和基于学习的逆问题求解器提供了一致的性能提升。

Abstract: Inverse problems in imaging are ill-posed, leading to infinitely many solutions consistent with the measurements due to the non-trivial null-space of the sensing matrix. Common image priors promote solutions on the general image manifold, such as sparsity, smoothness, or score function. However, as these priors do not constrain the null-space component, they can bias the reconstruction. Thus, we aim to incorporate meaningful null-space information in the reconstruction framework. Inspired by smooth image representation on graphs, we propose Graph-Smooth Null-Space Representation (GSNR), a mechanism that imposes structure only into the invisible component. Particularly, given a graph Laplacian, we construct a null-restricted Laplacian that encodes similarity between neighboring pixels in the null-space signal, and we design a low-dimensional projection matrix from the $p$-smoothest spectral graph modes (lowest graph frequencies). This approach has strong theoretical and practical implications: i) improved convergence via a null-only graph regularizer, ii) better coverage, how much null-space variance is captured by $p$ modes, and iii) high predictability, how well these modes can be inferred from the measurements. GSNR is incorporated into well-known inverse problem solvers, e.g., PnP, DIP, and diffusion solvers, in four scenarios: image deblurring, compressed sensing, demosaicing, and image super-resolution, providing consistent improvement of up to 4.3 dB over baseline formulations and up to 1 dB compared with end-to-end learned models in terms of PSNR.

</details>


### [5] [Circuit Tracing in Vision-Language Models: Understanding the Internal Mechanisms of Multimodal Thinking](https://arxiv.org/abs/2602.20330)
*Jingcheng Yang,Tianhu Xiong,Shengyi Qian,Klara Nahrstedt,Mingyuan Wu*

Main category: cs.CV

TL;DR: 提出了首个用于视觉语言模型透明电路追踪的框架，通过多层次分析方法揭示多模态推理的内部机制


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型虽然强大但仍然是黑盒，缺乏透明度，需要系统分析其多模态推理的内部工作机制

Method: 使用转码器、归因图和基于注意力的方法，通过特征引导和电路修补验证，系统追踪视觉语言模型的内部电路

Result: 发现视觉语言模型通过层次化方式整合视觉和语义概念，不同的视觉特征电路可以处理数学推理并支持跨模态关联，这些电路具有因果性和可控性

Conclusion: 该框架为构建更可解释和可靠的视觉语言模型奠定了基础，证明了模型内部电路的可追溯性和可控制性

Abstract: Vision-language models (VLMs) are powerful but remain opaque black boxes. We introduce the first framework for transparent circuit tracing in VLMs to systematically analyze multimodal reasoning. By utilizing transcoders, attribution graphs, and attention-based methods, we uncover how VLMs hierarchically integrate visual and semantic concepts. We reveal that distinct visual feature circuits can handle mathematical reasoning and support cross-modal associations. Validated through feature steering and circuit patching, our framework proves these circuits are causal and controllable, laying the groundwork for more explainable and reliable VLMs.

</details>


### [6] [Large-scale Photorealistic Outdoor 3D Scene Reconstruction from UAV Imagery Using Gaussian Splatting Techniques](https://arxiv.org/abs/2602.20342)
*Christos Maikos,Georgios Angelidis,Georgios Th. Papadopoulos*

Main category: cs.CV

TL;DR: 提出一个端到端无人机视频流实时3D重建系统，结合3D高斯泼溅技术，实现低延迟的AR/VR可视化应用


<details>
  <summary>Details</summary>
Motivation: 无人机在实时感知应用中广泛使用，3D高斯泼溅技术展现出实时神经渲染潜力，但将其整合到端到端无人机重建系统尚未充分探索

Method: 采用高效架构整合RTMP直播视频采集、传感器融合同步、相机姿态估计和3DGS优化，实现连续模型更新和低延迟部署

Result: 相比NeRF方法，该方法在视觉保真度上具有竞争力，同时提供显著更高的渲染性能和大幅降低的端到端延迟，重建质量保持在离线参考的4-7%范围内

Conclusion: 该系统适用于实时、可扩展的空中平台增强感知应用，验证了3DGS在无人机实时重建系统中的有效性

Abstract: In this study, we present an end-to-end pipeline capable of converting drone-captured video streams into high-fidelity 3D reconstructions with minimal latency. Unmanned aerial vehicles (UAVs) are extensively used in aerial real-time perception applications. Moreover, recent advances in 3D Gaussian Splatting (3DGS) have demonstrated significant potential for real-time neural rendering. However, their integration into end-to-end UAV-based reconstruction and visualization systems remains underexplored. Our goal is to propose an efficient architecture that combines live video acquisition via RTMP streaming, synchronized sensor fusion, camera pose estimation, and 3DGS optimization, achieving continuous model updates and low-latency deployment within interactive visualization environments that supports immersive augmented and virtual reality (AR/VR) applications. Experimental results demonstrate that the proposed method achieves competitive visual fidelity, while delivering significantly higher rendering performance and substantially reduced end-to-end latency, compared to NeRF-based approaches. Reconstruction quality remains within 4-7\% of high-fidelity offline references, confirming the suitability of the proposed system for real-time, scalable augmented perception from aerial platforms.

</details>


### [7] [3DSPA: A 3D Semantic Point Autoencoder for Evaluating Video Realism](https://arxiv.org/abs/2602.20354)
*Bhavik Chandna,Kelsey R. Allen*

Main category: cs.CV

TL;DR: 3DSPA是一个自动评估视频真实性的框架，通过3D时空点自编码器整合3D点轨迹、深度线索和语义特征，无需参考视频即可评估生成视频的物理合理性和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 当前AI视频生成发展迅速，但评估生成视频的真实性仍主要依赖人工标注或有限范围的评估数据集，缺乏自动化、全面的评估方法。

Method: 开发了3DSPA（3D时空点自编码器），整合3D点轨迹、深度线索和DINO语义特征到统一表示中，建模物体运动和场景内容，评估视频的真实性、时间一致性和物理合理性。

Result: 3DSPA能可靠识别违反物理规律的视频，对运动伪影更敏感，在多个数据集上与人类对视频质量和真实性的判断更一致。

Conclusion: 将3D语义信息融入轨迹表示为生成视频模型提供了更强的基准测试基础，能够隐式捕捉物理规则违反，代码和预训练模型将开源。

Abstract: AI video generation is evolving rapidly. For video generators to be useful for applications ranging from robotics to film-making, they must consistently produce realistic videos. However, evaluating the realism of generated videos remains a largely manual process -- requiring human annotation or bespoke evaluation datasets which have restricted scope. Here we develop an automated evaluation framework for video realism which captures both semantics and coherent 3D structure and which does not require access to a reference video. Our method, 3DSPA, is a 3D spatiotemporal point autoencoder which integrates 3D point trajectories, depth cues, and DINO semantic features into a unified representation for video evaluation. 3DSPA models how objects move and what is happening in the scene, enabling robust assessments of realism, temporal consistency, and physical plausibility. Experiments show that 3DSPA reliably identifies videos which violate physical laws, is more sensitive to motion artifacts, and aligns more closely with human judgments of video quality and realism across multiple datasets. Our results demonstrate that enriching trajectory-based representations with 3D semantics offers a stronger foundation for benchmarking generative video models, and implicitly captures physical rule violations. The code and pretrained model weights will be available at https://github.com/TheProParadox/3dspa_code.

</details>


### [8] [WildGHand: Learning Anti-Perturbation Gaussian Hand Avatars from Monocular In-the-Wild Videos](https://arxiv.org/abs/2602.20556)
*Hanhui Li,Xuan Huang,Wanquan Liu,Yuhao Cheng,Long Chen,Yiqiang Yan,Xiaodan Liang,Chenqiang Gao*

Main category: cs.CV

TL;DR: WildGHand是一个基于优化的框架，通过动态扰动解耦模块和扰动感知优化策略，在野外视频中实现自适应3D高斯溅射，重建高保真手部化身。


<details>
  <summary>Details</summary>
Motivation: 现有3D手部重建方法大多依赖受控环境数据，在真实世界存在手物交互、极端姿态、光照变化和运动模糊等扰动时性能下降，需要解决野外视频中的鲁棒重建问题。

Method: 1) 动态扰动解耦模块：将扰动表示为3D高斯属性上的时变偏差；2) 扰动感知优化策略：生成每帧各向异性加权掩码指导优化；两者结合在时空维度识别和抑制扰动。

Result: 在自建数据集和两个公共数据集上的实验表明，WildGHand达到最先进性能，相比基础模型在PSNR上相对提升15.8%，LPIPS相对减少23.1%。

Conclusion: WildGHand通过扰动解耦和感知优化，有效处理野外视频中的各种扰动，实现了鲁棒的高质量3D手部化身重建。

Abstract: Despite recent progress in 3D hand reconstruction from monocular videos, most existing methods rely on data captured in well-controlled environments and therefore degrade in real-world settings with severe perturbations, such as hand-object interactions, extreme poses, illumination changes, and motion blur. To tackle these issues, we introduce WildGHand, an optimization-based framework that enables self-adaptive 3D Gaussian splatting on in-the-wild videos and produces high-fidelity hand avatars. WildGHand incorporates two key components: (i) a dynamic perturbation disentanglement module that explicitly represents perturbations as time-varying biases on 3D Gaussian attributes during optimization, and (ii) a perturbation-aware optimization strategy that generates per-frame anisotropic weighted masks to guide optimization. Together, these components allow the framework to identify and suppress perturbations across both spatial and temporal dimensions. We further curate a dataset of monocular hand videos captured under diverse perturbations to benchmark in-the-wild hand avatar reconstruction. Extensive experiments on this dataset and two public datasets demonstrate that WildGHand achieves state-of-the-art performance and substantially improves over its base model across multiple metrics (e.g., up to a $15.8\%$ relative gain in PSNR and a $23.1\%$ relative reduction in LPIPS). Our implementation and dataset are available at https://github.com/XuanHuang0/WildGHand.

</details>


### [9] [Efficient and Explainable End-to-End Autonomous Driving via Masked Vision-Language-Action Diffusion](https://arxiv.org/abs/2602.20577)
*Jiaru Zhang,Manav Gagvani,Can Cui,Juntong Peng,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: MVLAD-AD是一个用于自动驾驶的新型框架，通过掩码视觉-语言-动作扩散模型，在高效规划和语义可解释性之间架起桥梁，解决了现有LLM/VLM模型在推理延迟、动作精度和可解释性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有LLM和VLM模型在自动驾驶应用中面临推理延迟、动作精度和可解释性三大挑战。自回归方法存在逐token生成的慢速问题，而先前的扩散规划器依赖冗长、通用的语言token，缺乏明确的几何结构。

Method: 提出MVLAD-AD框架：1）引入离散动作标记化策略，从真实驾驶分布构建紧凑的运动学可行路径点码本；2）提出几何感知嵌入学习，确保潜在空间嵌入近似物理几何度量；3）引入动作优先解码策略，优先生成轨迹。

Result: 在nuScenes及其衍生基准上的广泛实验表明，MVLAD-AD实现了卓越的效率，在规划精度上优于最先进的自回归和扩散基线，同时提供高保真和可解释的推理。

Conclusion: MVLAD-AD成功解决了现有LLM/VLM自动驾驶模型的效率、精度和可解释性问题，通过创新的动作标记化、几何感知嵌入和动作优先解码策略，为端到端自动驾驶提供了更优的解决方案。

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) have emerged as promising candidates for end-to-end autonomous driving. However, these models typically face challenges in inference latency, action precision, and explainability. Existing autoregressive approaches struggle with slow token-by-token generation, while prior diffusion-based planners often rely on verbose, general-purpose language tokens that lack explicit geometric structure. In this work, we propose Masked Vision-Language-Action Diffusion for Autonomous Driving (MVLAD-AD), a novel framework designed to bridge the gap between efficient planning and semantic explainability via a masked vision-language-action diffusion model. Unlike methods that force actions into the language space, we introduce a discrete action tokenization strategy that constructs a compact codebook of kinematically feasible waypoints from real-world driving distributions. Moreover, we propose geometry-aware embedding learning to ensure that embeddings in the latent space approximate physical geometric metrics. Finally, an action-priority decoding strategy is introduced to prioritize trajectory generation. Extensive experiments on nuScenes and derived benchmarks demonstrate that MVLAD-AD achieves superior efficiency and outperforms state-of-the-art autoregressive and diffusion baselines in planning precision, while providing high-fidelity and explainable reasoning.

</details>


### [10] [PropFly: Learning to Propagate via On-the-Fly Supervision from Pre-trained Video Diffusion Models](https://arxiv.org/abs/2602.20583)
*Wonyong Seo,Jaeho Moon,Jaehyup Lee,Soo Ye Kim,Munchurl Kim*

Main category: cs.CV

TL;DR: PropFly：无需配对视频数据集，利用预训练视频扩散模型进行在线监督的视频传播编辑训练框架


<details>
  <summary>Details</summary>
Motivation: 基于传播的视频编辑需要大规模配对的源视频和编辑后视频数据集进行训练，但这些数据集获取成本高且复杂。需要一种无需预计算配对数据集的方法。

Method: 提出PropFly训练框架，利用预训练视频扩散模型进行在线监督。通过不同CFG尺度的单步干净潜在估计，在线合成"源"（低CFG）和"编辑"（高CFG）潜在对。源潜在提供视频结构信息，编辑潜在提供目标变换。通过附加适配器并使用引导调制流匹配损失学习传播编辑。

Result: PropFly在多种视频编辑任务上显著优于现有最先进方法，能够生成高质量的编辑结果，学习到时间一致且动态的变换。

Conclusion: PropFly通过在线监督方法有效解决了基于传播的视频编辑训练中配对数据集获取困难的问题，为视频编辑提供了一种高效且高质量的解决方案。

Abstract: Propagation-based video editing enables precise user control by propagating a single edited frame into following frames while maintaining the original context such as motion and structures. However, training such models requires large-scale, paired (source and edited) video datasets, which are costly and complex to acquire. Hence, we propose the PropFly, a training pipeline for Propagation-based video editing, relying on on-the-Fly supervision from pre-trained video diffusion models (VDMs) instead of requiring off-the-shelf or precomputed paired video editing datasets. Specifically, our PropFly leverages one-step clean latent estimations from intermediate noised latents with varying Classifier-Free Guidance (CFG) scales to synthesize diverse pairs of 'source' (low-CFG) and 'edited' (high-CFG) latents on-the-fly. The source latent serves as structural information of the video, while the edited latent provides the target transformation for learning propagation. Our pipeline enables an additional adapter attached to the pre-trained VDM to learn to propagate edits via Guidance-Modulated Flow Matching (GMFM) loss, which guides the model to replicate the target transformation. Our on-the-fly supervision ensures the model to learn temporally consistent and dynamic transformations. Extensive experiments demonstrate that our PropFly significantly outperforms the state-of-the-art methods on various video editing tasks, producing high-quality editing results.

</details>


### [11] [VAGNet: Grounding 3D Affordance from Human-Object Interactions in Videos](https://arxiv.org/abs/2602.20608)
*Aihua Mao,Kaihang Huang,Yong-Jin Liu,Chee Seng Chan,Ying He*

Main category: cs.CV

TL;DR: 该论文提出了视频引导的3D物体可供性定位方法，通过动态交互序列而非静态视觉/文本线索来识别支持人-物交互的区域，解决了现有方法难以定位真实接触区域的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D物体可供性定位方法主要依赖静态视觉或文本线索，但可供性本质上是动态动作定义的，导致难以准确定位真实交互中的接触区域。人类通过观察和模仿动作学习使用物体，而非仅通过形状检查，这启发了使用动态交互序列提供功能监督的新思路。

Method: 提出VAGNet框架，将视频衍生的交互线索与3D结构对齐，解决静态线索无法处理的模糊性问题。同时构建了首个HOI视频-3D配对可供性数据集PVAD，提供先前工作中缺乏的功能监督。

Result: 在PVAD数据集上的大量实验表明，VAGNet实现了最先进的性能，显著优于基于静态线索的基线方法。

Conclusion: 通过引入视频引导的3D可供性定位新范式，利用动态交互序列提供功能监督，能够更准确地定位真实交互中的接触区域，为具身视觉推理提供了更有效的方法。

Abstract: 3D object affordance grounding aims to identify regions on 3D objects that support human-object interaction (HOI), a capability essential to embodied visual reasoning. However, most existing approaches rely on static visual or textual cues, neglecting that affordances are inherently defined by dynamic actions. As a result, they often struggle to localize the true contact regions involved in real interactions. We take a different perspective. Humans learn how to use objects by observing and imitating actions, not just by examining shapes. Motivated by this intuition, we introduce video-guided 3D affordance grounding, which leverages dynamic interaction sequences to provide functional supervision. To achieve this, we propose VAGNet, a framework that aligns video-derived interaction cues with 3D structure to resolve ambiguities that static cues cannot address. To support this new setting, we introduce PVAD, the first HOI video-3D pairing affordance dataset, providing functional supervision unavailable in prior works. Extensive experiments on PVAD show that VAGNet achieves state-of-the-art performance, significantly outperforming static-based baselines. The code and dataset will be open publicly.

</details>


### [12] [Vision-Language Models for Ergonomic Assessment of Manual Lifting Tasks: Estimating Horizontal and Vertical Hand Distances from RGB Video](https://arxiv.org/abs/2602.20658)
*Mohammad Sadra Rajabi,Aanuoluwapo Ojelade,Sunwook Kim,Maury A. Nussbaum*

Main category: cs.CV

TL;DR: 研究评估了使用视觉语言模型从RGB视频流中非侵入式估计NIOSH举重方程中水平和垂直手部距离的可行性，开发了两种多阶段VLM管道，其中基于分割的多视图管道表现最佳。


<details>
  <summary>Details</summary>
Motivation: 手动举重任务是职业性肌肉骨骼疾病的主要诱因，而修订版NIOSH举重方程（RNLE）是广泛使用的工效学风险评估工具，但其所需的水平和垂直手部距离参数通常需要通过手动测量或专用传感系统获取，难以在实际工作环境中应用。

Method: 开发了两种多阶段视觉语言模型（VLM）管道：1）文本引导的仅检测管道；2）检测加分割管道。两种管道都使用文本引导定位任务相关感兴趣区域，从这些区域提取视觉特征，并基于transformer的时间回归来估计举重开始和结束时的水平和垂直距离。

Result: 基于分割的多视图管道表现最佳，估计水平距离的平均绝对误差约为6-8厘米，垂直距离约为5-8厘米。在所有管道和相机视图配置中，像素级分割将水平距离估计误差降低了约20-30%，垂直距离降低了约35-40%。

Conclusion: 研究结果支持基于视觉语言模型的管道用于视频估计RNLE距离参数的可行性，为实际工作环境中的非侵入式工效学风险评估提供了有前景的方法。

Abstract: Manual lifting tasks are a major contributor to work-related musculoskeletal disorders, and effective ergonomic risk assessment is essential for quantifying physical exposure and informing ergonomic interventions. The Revised NIOSH Lifting Equation (RNLE) is a widely used ergonomic risk assessment tool for lifting tasks that relies on six task variables, including horizontal (H) and vertical (V) hand distances; such distances are typically obtained through manual measurement or specialized sensing systems and are difficult to use in real-world environments. We evaluated the feasibility of using innovative vision-language models (VLMs) to non-invasively estimate H and V from RGB video streams. Two multi-stage VLM-based pipelines were developed: a text-guided detection-only pipeline and a detection-plus-segmentation pipeline. Both pipelines used text-guided localization of task-relevant regions of interest, visual feature extraction from those regions, and transformer-based temporal regression to estimate H and V at the start and end of a lift. For a range of lifting tasks, estimation performance was evaluated using leave-one-subject-out validation across the two pipelines and seven camera view conditions. Results varied significantly across pipelines and camera view conditions, with the segmentation-based, multi-view pipeline consistently yielding the smallest errors, achieving mean absolute errors of approximately 6-8 cm when estimating H and 5-8 cm when estimating V. Across pipelines and camera view configurations, pixel-level segmentation reduced estimation error by approximately 20-30% for H and 35-40% for V relative to the detection-only pipeline. These findings support the feasibility of VLM-based pipelines for video-based estimation of RNLE distance parameters.

</details>


### [13] [AnimeAgent: Is the Multi-Agent via Image-to-Video models a Good Disney Storytelling Artist?](https://arxiv.org/abs/2602.20664)
*Hailong Yan,Shice Liu,Tao Wang,Xiangtao Zhang,Yijie Zhong,Jinwei Chen,Le Zhang,Bo Li*

Main category: cs.CV

TL;DR: AnimeAgent：首个基于图像到视频的多智能体框架，用于定制故事板生成，解决了静态扩散模型在动态表现力、迭代修正和评估方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于静态扩散模型的故事板生成方法存在三个关键问题：1) 静态模型缺乏动态表现力，常采用"复制粘贴"模式；2) 一次性推理无法迭代修正缺失属性或提示词遵循不佳的问题；3) 多智能体框架依赖不稳健的评估器，不适合评估风格化、非写实的动画。

Method: 提出AnimeAgent框架，受迪士尼"直进与姿势结合"工作流程启发，利用图像到视频模型的隐式运动先验来增强一致性和表现力，同时采用混合主观-客观的评审机制实现可靠的迭代优化。

Result: 实验表明AnimeAgent在一致性、提示词忠实度和风格化方面达到了最先进的性能，并收集了带人工标注的真实基准数据集。

Conclusion: AnimeAgent是首个基于图像到视频的多智能体框架，通过结合动态运动先验和混合评审机制，有效解决了定制故事板生成中的关键挑战。

Abstract: Custom Storyboard Generation (CSG) aims to produce high-quality, multi-character consistent storytelling. Current approaches based on static diffusion models, whether used in a one-shot manner or within multi-agent frameworks, face three key limitations: (1) Static models lack dynamic expressiveness and often resort to "copy-paste" pattern. (2) One-shot inference cannot iteratively correct missing attributes or poor prompt adherence. (3) Multi-agents rely on non-robust evaluators, ill-suited for assessing stylized, non-realistic animation. To address these, we propose AnimeAgent, the first Image-to-Video (I2V)-based multi-agent framework for CSG. Inspired by Disney's "Combination of Straight Ahead and Pose to Pose" workflow, AnimeAgent leverages I2V's implicit motion prior to enhance consistency and expressiveness, while a mixed subjective-objective reviewer enables reliable iterative refinement. We also collect a human-annotated CSG benchmark with ground-truth. Experiments show AnimeAgent achieves SOTA performance in consistency, prompt fidelity, and stylization.

</details>


### [14] [CleanStyle: Plug-and-Play Style Conditioning Purification for Text-to-Image Stylization](https://arxiv.org/abs/2602.20721)
*Xiaoman Feng,Mingkun Lei,Yang Wang,Dingwen Fu,Chi Zhang*

Main category: cs.CV

TL;DR: CleanStyle：一种无需重新训练的即插即用框架，通过SVD分解和动态抑制尾部成分来过滤风格嵌入中的内容泄漏，同时提出风格特定分类器自由引导机制来提升提示保真度。


<details>
  <summary>Details</summary>
Motivation: 当前基于编码器的扩散模型风格迁移方法虽然高效且无需调优，但存在内容泄漏问题——风格图像中的语义元素会不期望地出现在输出中，损害了提示保真度和风格一致性。

Method: 提出CleanStyle框架：1) CleanStyleSVD (CS-SVD)：通过奇异值分解(SVD)隔离风格嵌入的尾部成分，并使用时间感知指数调度动态抑制这些成分；2) Style-Specific Classifier-Free Guidance (SS-CFG)：重新利用被抑制的尾部成分构建风格感知的无条件输入，提供针对性的负信号来抑制与提示无关的视觉元素。

Result: 实验表明，CleanStyle显著减少了内容泄漏，提高了风格化质量和提示对齐度，适用于广泛的风格参考和提示。

Conclusion: CleanStyle是一个轻量级、可解释的框架，无需重新训练即可无缝集成到现有的基于编码器的扩散模型中，有效解决了风格迁移中的内容泄漏问题，提升了生成质量。

Abstract: Style transfer in diffusion models enables controllable visual generation by injecting the style of a reference image. However, recent encoder-based methods, while efficient and tuning-free, often suffer from content leakage, where semantic elements from the style image undesirably appear in the output, impairing prompt fidelity and stylistic consistency. In this work, we introduce CleanStyle, a plug-and-play framework that filters out content-related noise from the style embedding without retraining. Motivated by empirical analysis, we observe that such leakage predominantly stems from the tail components of the style embedding, which are isolated via Singular Value Decomposition (SVD). To address this, we propose CleanStyleSVD (CS-SVD), which dynamically suppresses tail components using a time-aware exponential schedule, providing clean, style-preserving conditional embeddings throughout the denoising process. Furthermore, we present Style-Specific Classifier-Free Guidance (SS-CFG), which reuses the suppressed tail components to construct style-aware unconditional inputs. Unlike conventional methods that use generic negative embeddings (e.g., zero vectors), SS-CFG introduces targeted negative signals that reflect style-specific but prompt-irrelevant visual elements. This enables the model to effectively suppress these distracting patterns during generation, thereby improving prompt fidelity and enhancing the overall visual quality of stylized outputs. Our approach is lightweight, interpretable, and can be seamlessly integrated into existing encoder-based diffusion models without retraining. Extensive experiments demonstrate that CleanStyle substantially reduces content leakage, improves stylization quality and improves prompt alignment across a wide range of style references and prompts.

</details>


### [15] [Bridging Physically Based Rendering and Diffusion Models with Stochastic Differential Equation](https://arxiv.org/abs/2602.20725)
*Junwei Shu,Wenjie Liu,Changgu Chen,Hantang Liu,Yang Li,Changbo Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种统一随机公式，将蒙特卡洛渲染与基于扩散的生成建模相结合，实现对扩散生成结果的物理基础控制。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在文本/图像条件生成方面表现出色但缺乏对低层级物理属性（如着色和材质）的显式控制，而物理渲染（PBR）提供精细物理控制但缺乏提示驱动的灵活性。两者都遵循从噪声观测到干净图像的共同演化路径。

Method: 提出统一随机公式：1）基于中心极限定理建立蒙特卡洛积分的通用随机微分方程（SDE）公式；2）通过基于物理的路径追踪实例化，将其转换为物理基础的SDE表示；3）从噪声方差角度分析路径追踪的物理特性如何扩展到现有扩散模型。

Result: 在多个任务上的广泛实验表明，该方法能够对扩散生成结果施加物理基础的控制，涵盖渲染和材质编辑等任务。

Conclusion: 成功建立了蒙特卡洛渲染与扩散生成建模之间的桥梁，实现了对扩散生成内容的物理基础控制，为结合两种范式的优势提供了统一框架。

Abstract: Diffusion-based image generators excel at producing realistic content from text or image conditions, but they offer only limited explicit control over low-level, physically grounded shading and material properties. In contrast, physically based rendering (PBR) offers fine-grained physical control but lacks prompt-driven flexibility. Although these two paradigms originate from distinct communities, both share a common evolution -- from noisy observations to clean images. In this paper, we propose a unified stochastic formulation that bridges Monte Carlo rendering and diffusion-based generative modeling. First, a general stochastic differential equation (SDE) formulation for Monte Carlo integration under the Central Limit Theorem is modeled. Through instantiation via physically based path tracing, we convert it into a physically grounded SDE representation. Moreover, we provide a systematic analysis of how the physical characteristics of path tracing can be extended to existing diffusion models from the perspective of noise variance. Extensive experiments across multiple tasks show that our method can exert physically grounded control over diffusion-generated results, covering tasks such as rendering and material editing.

</details>


### [16] [Training-Free Multi-Concept Image Editing](https://arxiv.org/abs/2602.20839)
*Niki Foteinopoulou,Ignas Budvytis,Stephan Liwicki*

Main category: cs.CV

TL;DR: 提出无需训练的基于概念的图像编辑框架，结合优化DDS与LoRA概念组合，实现多视觉概念的组合控制


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的图像编辑方法面临挑战：优化方法虽能实现零样本编辑，但难以保持身份特征或捕捉语言无法表达的视觉概念（如面部结构、材质纹理、几何形状等）

Method: 训练免费的概念图像编辑框架，统一优化DDS与LoRA驱动的概念组合，其中LoRA的训练数据代表概念；通过有序时间步、正则化和负提示指导改进DDS的稳定性和可控性

Result: 在InstructPix2Pix和ComposLoRA基准测试中，相比现有训练免费扩散编辑方法，定量和定性结果均显示一致改进

Conclusion: 提出的框架成功解决了语言无法表达的视觉概念编辑问题，实现了语义文本指导与预训练概念适配器低级线索的集成，代码将公开

Abstract: Editing images with diffusion models without training remains challenging. While recent optimisation-based methods achieve strong zero-shot edits from text, they struggle to preserve identity or capture details that language alone cannot express. Many visual concepts such as facial structure, material texture, or object geometry are impossible to express purely through text prompts alone. To address this gap, we introduce a training-free framework for concept-based image editing, which unifies Optimised DDS with LoRA-driven concept composition, where the training data of the LoRA represent the concept. Our approach enables combining and controlling multiple visual concepts directly within the diffusion process, integrating semantic guidance from text with low-level cues from pretrained concept adapters. We further refine DDS for stability and controllability through ordered timesteps, regularisation, and negative-prompt guidance. Quantitative and qualitative results demonstrate consistent improvements over existing training-free diffusion editing methods on InstructPix2Pix and ComposLoRA benchmarks. Code will be made publicly available.

</details>


### [17] [When Safety Collides: Resolving Multi-Category Harmful Conflicts in Text-to-Image Diffusion via Adaptive Safety Guidance](https://arxiv.org/abs/2602.20880)
*Yongli Xiang,Ziming Hong,Zhaoqing Wang,Xiangyu Zhao,Bo Han,Tongliang Liu*

Main category: cs.CV

TL;DR: 本文提出CASG框架解决T2I扩散模型中多类别有害内容生成的安全冲突问题，通过动态识别最相关的有害类别并针对性应用安全引导，相比现有方法将有害率降低15.4%


<details>
  <summary>Details</summary>
Motivation: 现有基于安全引导的T2I扩散模型安全方法在处理多类别有害内容时存在"有害冲突"问题——抑制一种有害类别可能无意中放大另一种有害类别，导致总体有害率反而增加

Method: 提出冲突感知自适应安全引导(CASG)框架，包含两个组件：1)冲突感知类别识别(CaCI)，根据模型生成状态动态识别最相关的有害类别；2)冲突解决引导应用(CrGA)，仅沿识别出的类别方向应用安全引导，避免多类别干扰

Result: 在T2I安全基准测试中，CASG实现了最先进的性能，相比现有方法将有害率降低高达15.4%，可应用于潜在空间和文本空间的安全保障

Conclusion: CASG框架有效解决了T2I扩散模型中的有害冲突问题，通过动态识别和针对性引导实现了更安全的内容生成，为多类别有害内容的安全防护提供了新思路

Abstract: Text-to-Image (T2I) diffusion models have demonstrated significant advancements in generating high-quality images, while raising potential safety concerns regarding harmful content generation. Safety-guidance-based methods have been proposed to mitigate harmful outputs by steering generation away from harmful zones, where the zones are averaged across multiple harmful categories based on predefined keywords. However, these approaches fail to capture the complex interplay among different harm categories, leading to "harmful conflicts" where mitigating one type of harm may inadvertently amplify another, thus increasing overall harmful rate. To address this issue, we propose Conflict-aware Adaptive Safety Guidance (CASG), a training-free framework that dynamically identifies and applies the category-aligned safety direction during generation. CASG is composed of two components: (i) Conflict-aware Category Identification (CaCI), which identifies the harmful category most aligned with the model's evolving generative state, and (ii) Conflict-resolving Guidance Application (CrGA), which applies safety steering solely along the identified category to avoid multi-category interference. CASG can be applied to both latent-space and text-space safeguards. Experiments on T2I safety benchmarks demonstrate CASG's state-of-the-art performance, reducing the harmful rate by up to 15.4% compared to existing methods.

</details>


### [18] [VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models](https://arxiv.org/abs/2602.20999)
*Bowen Zheng,Yongli Xiang,Ziming Hong,Zerong Lin,Chaojian Yu,Tongliang Liu,Xinge You*

Main category: cs.CV

TL;DR: 本文提出了一种名为Visual Instruction Injection (VII)的训练免费、可迁移的越狱框架，通过将恶意文本意图伪装成参考图像中的良性视觉指令，来攻击图像到视频生成模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 图像到视频生成模型具有视觉指令跟随能力，但这也带来了新的安全风险：攻击者可能通过图像模态注入恶意意图。目前这一风险尚未被充分认识和研究。

Method: VII框架包含两个模块：1) 恶意意图重编程模块，从恶意文本提示中提取意图同时最小化其静态危害性；2) 视觉指令接地模块，将提取的意图通过视觉指令形式嵌入到安全输入图像中，保持与原始恶意文本的语义一致性。

Result: 在四个最先进的商业I2V模型上测试，VII攻击成功率最高达83.5%，同时将拒绝率降至接近零，显著优于现有基线方法。

Conclusion: 该研究揭示了图像到视频生成模型中视觉指令跟随能力带来的安全风险，提出的VII框架能有效绕过模型的安全防护机制，为未来模型安全研究提供了重要参考。

Abstract: Image-to-Video (I2V) generation models, which condition video generation on reference images, have shown emerging visual instruction-following capability, allowing certain visual cues in reference images to act as implicit control signals for video generation. However, this capability also introduces a previously overlooked risk: adversaries may exploit visual instructions to inject malicious intent through the image modality. In this work, we uncover this risk by proposing Visual Instruction Injection (VII), a training-free and transferable jailbreaking framework that intentionally disguises the malicious intent of unsafe text prompts as benign visual instructions in the safe reference image. Specifically, VII coordinates a Malicious Intent Reprogramming module to distill malicious intent from unsafe text prompts while minimizing their static harmfulness, and a Visual Instruction Grounding module to ground the distilled intent onto a safe input image by rendering visual instructions that preserve semantic consistency with the original unsafe text prompt, thereby inducing harmful content during I2V generation. Empirically, our extensive experiments on four state-of-the-art commercial I2V models (Kling-v2.5-turbo, Gemini Veo-3.1, Seedance-1.5-pro, and PixVerse-V5) demonstrate that VII achieves Attack Success Rates of up to 83.5% while reducing Refusal Rates to near zero, significantly outperforming existing baselines.

</details>


### [19] [See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis](https://arxiv.org/abs/2602.20951)
*Jaehyun Park,Minyoung Ahn,Minkyu Kim,Jonghyun Lee,Jae-Gil Lee,Dongmin Park*

Main category: cs.CV

TL;DR: ArtiAgent是一个自动化系统，通过三个智能体协作生成带有丰富伪影标注的图像对（真实图像与注入伪影的图像），用于训练伪影检测和修复模型。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型取得进展，AI生成图像仍常包含影响真实感的视觉伪影。现有方法依赖人工标注的伪影数据集，成本高且难以扩展，需要自动化方法获取可靠的伪影标注数据。

Method: ArtiAgent包含三个智能体：感知智能体识别和定位真实图像中的实体和子实体；合成智能体通过扩散变换器中的新颖patch-wise嵌入操作，使用伪影注入工具引入伪影；策展智能体筛选合成伪影并为每个实例生成局部和全局解释。

Result: 使用ArtiAgent合成了10万张带有丰富伪影标注的图像，并在多种应用中展示了其有效性和多功能性。

Conclusion: ArtiAgent提供了一种自动化、可扩展的方法来生成伪影标注数据集，解决了人工标注成本高的问题，为伪影检测和修复研究提供了有价值的资源。

Abstract: Despite recent advances in diffusion models, AI generated images still often contain visual artifacts that compromise realism. Although more thorough pre-training and bigger models might reduce artifacts, there is no assurance that they can be completely eliminated, which makes artifact mitigation a highly crucial area of study. Previous artifact-aware methodologies depend on human-labeled artifact datasets, which are costly and difficult to scale, underscoring the need for an automated approach to reliably acquire artifact-annotated datasets. In this paper, we propose ArtiAgent, which efficiently creates pairs of real and artifact-injected images. It comprises three agents: a perception agent that recognizes and grounds entities and subentities from real images, a synthesis agent that introduces artifacts via artifact injection tools through novel patch-wise embedding manipulation within a diffusion transformer, and a curation agent that filters the synthesized artifacts and generates both local and global explanations for each instance. Using ArtiAgent, we synthesize 100K images with rich artifact annotations and demonstrate both efficacy and versatility across diverse applications. Code is available at link.

</details>


### [20] [VAUQ: Vision-Aware Uncertainty Quantification for LVLM Self-Evaluation](https://arxiv.org/abs/2602.21054)
*Seongheon Park,Changdae Oh,Hyeong Kyu Choi,Xuefeng Du,Sharon Li*

Main category: cs.CV

TL;DR: VAUQ提出了一种视觉感知的不确定性量化框架，通过图像信息分数和核心区域掩码策略来评估LVLM输出对视觉证据的依赖程度，从而减少幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型经常产生幻觉，限制了其在现实应用中的安全部署。现有的LLM自评估方法主要依赖语言先验，不适合评估视觉条件预测。

Method: 提出VAUQ框架，引入图像信息分数（IS）来衡量预测不确定性中可归因于视觉输入的部分，并结合无监督核心区域掩码策略来增强显著区域的影响。将预测熵与核心掩码IS结合，形成无需训练的打分函数。

Result: 综合实验表明，VAUQ在多个数据集上持续优于现有的自评估方法。

Conclusion: VAUQ通过显式测量模型输出对视觉证据的依赖程度，为LVLM自评估提供了有效的训练免费解决方案，提高了部署可靠性。

Abstract: Large Vision-Language Models (LVLMs) frequently hallucinate, limiting their safe deployment in real-world applications. Existing LLM self-evaluation methods rely on a model's ability to estimate the correctness of its own outputs, which can improve deployment reliability; however, they depend heavily on language priors and are therefore ill-suited for evaluating vision-conditioned predictions. We propose VAUQ, a vision-aware uncertainty quantification framework for LVLM self-evaluation that explicitly measures how strongly a model's output depends on visual evidence. VAUQ introduces the Image-Information Score (IS), which captures the reduction in predictive uncertainty attributable to visual input, and an unsupervised core-region masking strategy that amplifies the influence of salient regions. Combining predictive entropy with this core-masked IS yields a training-free scoring function that reliably reflects answer correctness. Comprehensive experiments show that VAUQ consistently outperforms existing self-evaluation methods across multiple datasets.

</details>


### [21] [UDVideoQA: A Traffic Video Question Answering Dataset for Multi-Object Spatio-Temporal Reasoning in Urban Dynamics](https://arxiv.org/abs/2602.21137)
*Joseph Raj Vishal,Nagasiri Poluri,Katha Naik,Rutuja Patil,Kashyap Hegde Kota,Krishna Vinod,Prithvi Jai Ramesh,Mohammad Farhadi,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: UDVideoQA是一个专注于城市交通动态多智能体交互的视频问答基准数据集，包含16小时真实交通视频和28K问答对，采用事件驱动动态模糊技术保护隐私，系统评估视频语言模型的视觉定位和因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型难以理解复杂的城市交通多智能体动态交互，缺乏能够系统评估视觉定位和因果推理能力的真实世界基准数据集。

Method: 从多个城市交叉口采集16小时真实交通视频，采用事件驱动动态模糊技术保护隐私，通过统一标注流程生成28K问答对，构建分层推理分类体系（基础理解、事件推理、反向推理、反事实推理）。

Result: 基准测试显示存在持续的感知-推理鸿沟：擅长抽象推理的模型在基础视觉定位上表现不佳。Gemini Pro在零样本准确率最高，但微调后的Qwen2.5-VL 7B模型能弥合这一鸿沟，达到与专有系统相当的性能。在视频问题生成任务中，Gemini 2.5 Pro和Qwen3 Max生成的问题最相关和复杂，但所有模型的语言多样性有限。

Conclusion: UDVideoQA为推进鲁棒、隐私保护、真实世界的多模态推理提供了基础，揭示了当前视频语言模型在视觉定位和因果推理方面的局限性，强调了以人为中心的评估需求。

Abstract: Understanding the complex, multi-agent dynamics of urban traffic remains a fundamental challenge for video language models. This paper introduces Urban Dynamics VideoQA, a benchmark dataset that captures the unscripted real-world behavior of dynamic urban scenes. UDVideoQA is curated from 16 hours of traffic footage recorded at multiple city intersections under diverse traffic, weather, and lighting conditions. It employs an event-driven dynamic blur technique to ensure privacy preservation without compromising scene fidelity. Using a unified annotation pipeline, the dataset contains 28K question-answer pairs generated across 8 hours of densely annotated video, averaging one question per second. Its taxonomy follows a hierarchical reasoning level, spanning basic understanding and attribution to event reasoning, reverse reasoning, and counterfactual inference, enabling systematic evaluation of both visual grounding and causal reasoning. Comprehensive experiments benchmark 10 SOTA VideoLMs on UDVideoQA and 8 models on a complementary video question generation benchmark. Results reveal a persistent perception-reasoning gap, showing models that excel in abstract inference often fail with fundamental visual grounding. While models like Gemini Pro achieve the highest zero-shot accuracy, fine-tuning the smaller Qwen2.5-VL 7B model on UDVideoQA bridges this gap, achieving performance comparable to proprietary systems. In VideoQGen, Gemini 2.5 Pro, and Qwen3 Max generate the most relevant and complex questions, though all models exhibit limited linguistic diversity, underscoring the need for human-centric evaluation. The UDVideoQA suite, including the dataset, annotation tools, and benchmarks for both VideoQA and VideoQGen, provides a foundation for advancing robust, privacy-aware, and real-world multimodal reasoning. UDVideoQA is available at https://ud-videoqa.github.io/UD-VideoQA/UD-VideoQA/.

</details>


### [22] [Seeing Through Words: Controlling Visual Retrieval Quality with Language Models](https://arxiv.org/abs/2602.21175)
*Jianglin Lu,Simon Jenni,Kushal Kafle,Jing Shi,Handong Zhao,Yun Fu*

Main category: cs.CV

TL;DR: 该论文提出了一种质量可控的检索新范式，通过生成语言模型将简短查询扩展为包含视觉属性和质量控制的描述性查询，从而提升文本到图像检索的效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的文本到图像检索经常面临用户查询过于简短和未充分指定的挑战。这些短查询通常只有一两个词，导致语义模糊、容易产生多种视觉解释碰撞，并且缺乏对检索图像质量的明确控制。

Method: 提出质量可控检索框架，利用生成语言模型作为查询补全函数，将未充分指定的查询扩展为捕获姿态、场景、美学等细粒度视觉属性的描述性形式。通过基于相关性和美学评分模型导出的离散质量级别来调节查询补全，使查询丰富不仅语义有意义而且质量感知。

Result: 实验表明，该方法显著改善了检索结果并提供了有效的质量控制，弥合了现代视觉语言模型的表达能力与简短用户查询未充分指定特性之间的差距。

Conclusion: 提出的质量可控检索范式具有三个关键优势：1) 灵活性，兼容任何预训练视觉语言模型而无需修改；2) 透明度，丰富的查询对用户明确可解释；3) 可控性，能够将检索结果引导至用户偏好的质量级别。

Abstract: Text-to-image retrieval is a fundamental task in vision-language learning, yet in real-world scenarios it is often challenged by short and underspecified user queries. Such queries are typically only one or two words long, rendering them semantically ambiguous, prone to collisions across diverse visual interpretations, and lacking explicit control over the quality of retrieved images. To address these issues, we propose a new paradigm of quality-controllable retrieval, which enriches short queries with contextual details while incorporating explicit notions of image quality. Our key idea is to leverage a generative language model as a query completion function, extending underspecified queries into descriptive forms that capture fine-grained visual attributes such as pose, scene, and aesthetics. We introduce a general framework that conditions query completion on discretized quality levels, derived from relevance and aesthetic scoring models, so that query enrichment is not only semantically meaningful but also quality-aware. The resulting system provides three key advantages: 1) flexibility, it is compatible with any pretrained vision-language model (VLMs) without modification; 2) transparency, enriched queries are explicitly interpretable by users; and 3) controllability, enabling retrieval results to be steered toward user-preferred quality levels. Extensive experiments demonstrate that our proposed approach significantly improves retrieval results and provides effective quality control, bridging the gap between the expressive capacity of modern VLMs and the underspecified nature of short user queries. Our code is available at https://github.com/Jianglin954/QCQC.

</details>


### [23] [Mask-HybridGNet: Graph-based segmentation with emergent anatomical correspondence from pixel-level supervision](https://arxiv.org/abs/2602.21179)
*Nicolás Gaggion,Maria J. Ledesma-Carbayo,Stergios Christodoulidis,Maria Vakalopoulou,Enzo Ferrante*

Main category: cs.CV

TL;DR: Mask-HybridGNet：一种无需手动标注地标即可训练基于图的医学图像分割框架，利用标准像素级掩码实现解剖结构边界图表示，具有隐式对应关系学习能力


<details>
  <summary>Details</summary>
Motivation: 基于图的医学图像分割需要具有点对点对应关系的手动标注地标数据集，但这类数据在实践中很少存在，限制了临床采用

Method: 结合Chamfer距离监督和基于边的正则化，将可变长度的真实边界与固定长度的地标预测对齐，通过可微分光栅化进行细化，利用固定图邻接矩阵确保边界连通性

Result: 在胸部X光、心脏超声、心脏MRI和胎儿成像实验中，模型达到与最先进像素级方法竞争的结果，同时确保解剖合理性，预测的地标位置在患者间保持一致的解剖位置对应关系

Conclusion: 该框架利用大量可用的标准分割掩码构建结构化模型，保持拓扑完整性并提供隐式对应关系，支持时间跟踪、跨切片重建和形态学群体分析等应用

Abstract: Graph-based medical image segmentation represents anatomical structures using boundary graphs, providing fixed-topology landmarks and inherent population-level correspondences. However, their clinical adoption has been hindered by a major requirement: training datasets with manually annotated landmarks that maintain point-to-point correspondences across patients rarely exist in practice. We introduce Mask-HybridGNet, a framework that trains graph-based models directly using standard pixel-wise masks, eliminating the need for manual landmark annotations. Our approach aligns variable-length ground truth boundaries with fixed-length landmark predictions by combining Chamfer distance supervision and edge-based regularization to ensure local smoothness and regular landmark distribution, further refined via differentiable rasterization. A significant emergent property of this framework is that predicted landmark positions become consistently associated with specific anatomical locations across patients without explicit correspondence supervision. This implicit atlas learning enables temporal tracking, cross-slice reconstruction, and morphological population analyses. Beyond direct segmentation, Mask-HybridGNet can extract correspondences from existing segmentation masks, allowing it to generate stable anatomical atlases from any high-quality pixel-based model. Experiments across chest radiography, cardiac ultrasound, cardiac MRI, and fetal imaging demonstrate that our model achieves competitive results against state-of-the-art pixel-based methods, while ensuring anatomical plausibility by enforcing boundary connectivity through a fixed graph adjacency matrix. This framework leverages the vast availability of standard segmentation masks to build structured models that maintain topological integrity and provide implicit correspondences.

</details>


### [24] [Spa3R: Predictive Spatial Field Modeling for 3D Visual Reasoning](https://arxiv.org/abs/2602.21186)
*Haoyi Jiang,Liu Liu,Xinjie Wang,Yonghao He,Wei Sui,Zhizhong Su,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: Spa3R是一个自监督框架，通过预测性空间场建模从无姿态多视角图像学习统一、视角不变的空间表示，无需3D模态或空间指令微调即可实现空间智能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在3D空间理解方面表现肤浅，现有方法要么依赖显式3D模态，要么通过部分视角条件几何先验增强VLMs，但这些方法可扩展性差，且让语言模型承担从稀疏线索隐式重建整体3D几何的不适定任务。

Method: 提出Spa3R自监督框架，基于预测性空间场建模范式，从无姿态多视角图像学习紧凑潜在表示，并合成任意未见视角的特征场。通过轻量级适配器将预训练的Spa3R编码器集成到现有VLMs中，形成Spa3-VLM。

Result: 在VSI-Bench基准测试中，Spa3-VLM在3D视觉问答上达到58.6%的最先进准确率，显著优于先前方法。

Conclusion: 预测性空间场建模为推进空间智能提供了一条可扩展的路径，证明空间智能可以从2D视觉中固有地涌现，而无需通过显式空间指令微调来强加。

Abstract: While Vision-Language Models (VLMs) exhibit exceptional 2D visual understanding, their ability to comprehend and reason about 3D space--a cornerstone of spatial intelligence--remains superficial. Current methodologies attempt to bridge this domain gap either by relying on explicit 3D modalities or by augmenting VLMs with partial, view-conditioned geometric priors. However, such approaches hinder scalability and ultimately burden the language model with the ill-posed task of implicitly reconstructing holistic 3D geometry from sparse cues. In this paper, we argue that spatial intelligence can emerge inherently from 2D vision alone, rather than being imposed via explicit spatial instruction tuning. To this end, we introduce Spa3R, a self-supervised framework that learns a unified, view-invariant spatial representation directly from unposed multi-view images. Spa3R is built upon the proposed Predictive Spatial Field Modeling (PSFM) paradigm, where Spa3R learns to synthesize feature fields for arbitrary unseen views conditioned on a compact latent representation, thereby internalizing a holistic and coherent understanding of the underlying 3D scene. We further integrate the pre-trained Spa3R Encoder into existing VLMs via a lightweight adapter to form Spa3-VLM, effectively grounding language reasoning in a global spatial context. Experiments on the challenging VSI-Bench demonstrate that Spa3-VLM achieves state-of-the-art accuracy of 58.6% on 3D VQA, significantly outperforming prior methods. These results highlight PSFM as a scalable path toward advancing spatial intelligence. Code is available at https://github.com/hustvl/Spa3R.

</details>


### [25] [Human Video Generation from a Single Image with 3D Pose and View Control](https://arxiv.org/abs/2602.21188)
*Tiantian Wang,Chun-Han Yao,Tao Hu,Mallikarjun Byrasandra Ramalinga Reddy,Ming-Hsuan Yang,Varun Jampani*

Main category: cs.CV

TL;DR: HVG是一个从单图像生成高质量4D人体视频的潜在视频扩散模型，通过三维姿态和视角控制实现多视角时空一致的人体视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有扩散方法在从单图像生成视频方面取得进展，但在人体视频生成中仍面临挑战，特别是从单图像推断视角一致、运动相关的服装褶皱问题。

Method: 提出三个关键设计：1) 关节姿态调制，通过双维度骨骼图捕捉三维关节解剖关系并引入三维信息解决自遮挡；2) 视角和时间对齐，确保多视角一致性和参考图像与姿态序列的对齐；3) 渐进时空采样与时间对齐，保持长多视角动画的平滑过渡。

Result: 在图像到视频任务上的大量实验表明，HVG在从多样化人体图像和姿态输入生成高质量4D人体视频方面优于现有方法。

Conclusion: HVG能够从单图像生成高质量、多视角、时空一致的4D人体视频，通过三维姿态和视角控制解决了人体视频生成中的关键挑战。

Abstract: Recent diffusion methods have made significant progress in generating videos from single images due to their powerful visual generation capabilities. However, challenges persist in image-to-video synthesis, particularly in human video generation, where inferring view-consistent, motion-dependent clothing wrinkles from a single image remains a formidable problem. In this paper, we present Human Video Generation in 4D (HVG), a latent video diffusion model capable of generating high-quality, multi-view, spatiotemporally coherent human videos from a single image with 3D pose and view control. HVG achieves this through three key designs: (i) Articulated Pose Modulation, which captures the anatomical relationships of 3D joints via a novel dual-dimensional bone map and resolves self-occlusions across views by introducing 3D information; (ii) View and Temporal Alignment, which ensures multi-view consistency and alignment between a reference image and pose sequences for frame-to-frame stability; and (iii) Progressive Spatio-Temporal Sampling with temporal alignment to maintain smooth transitions in long multi-view animations. Extensive experiments on image-to-video tasks demonstrate that HVG outperforms existing methods in generating high-quality 4D human videos from diverse human images and pose inputs.

</details>


### [26] [Region of Interest Segmentation and Morphological Analysis for Membranes in Cryo-Electron Tomography](https://arxiv.org/abs/2602.21195)
*Xingyi Cheng,Julien Maufront,Aurélie Di Cicco,Daniël M. Pelt,Manuela Dezi,Daniel Lévy*

Main category: cs.CV

TL;DR: 开发了TomoROIS-SurfORA框架，用于冷冻电镜断层扫描数据的直接区域分割和表面形态分析，特别适用于复杂膜结构


<details>
  <summary>Details</summary>
Motivation: 当前冷冻电镜断层扫描中，感兴趣区域通常通过全结构分割间接获得，对于连续复杂的膜结构尤其不便，需要更直接的ROI分割和形态分析方法

Method: 提出两步框架：1) TomoROIS使用深度学习直接从少量标注数据训练进行ROI分割；2) SurfORA将分割结构处理为点云和表面网格，提取形态特征如膜间距离、曲率、表面粗糙度

Result: 成功应用于体外重构的膜系统，能够自动定量分析膜接触位点和重构事件（如内陷），支持开放和封闭表面，特别考虑了冷冻电镜中常见的缺失楔效应

Conclusion: TomoROIS-SurfORA为冷冻电镜膜数据提供了直接的ROI分割和表面分析工具，虽然在此展示膜数据应用，但方法可推广到更广泛的科学成像领域

Abstract: Cryo-electron tomography (cryo-ET) enables high resolution, three-dimensional reconstruction of biological structures, including membranes and membrane proteins. Identification of regions of interest (ROIs) is central to scientific imaging, as it enables isolation and quantitative analysis of specific structural features within complex datasets. In practice, however, ROIs are typically derived indirectly through full structure segmentation followed by post hoc analysis. This limitation is especially apparent for continuous and geometrically complex structures such as membranes, which are segmented as single entities. Here, we developed TomoROIS-SurfORA, a two step framework for direct, shape-agnostic ROI segmentation and morphological surface analysis. TomoROIS performs deep learning-based ROI segmentation and can be trained from scratch using small annotated datasets, enabling practical application across diverse imaging data. SurfORA processes segmented structures as point clouds and surface meshes to extract quantitative morphological features, including inter-membrane distances, curvature, and surface roughness. It supports both closed and open surfaces, with specific considerations for open surfaces, which are common in cryo-ET due to the missing wedge effect. We demonstrate both tools using in vitro reconstituted membrane systems containing deformable vesicles with complex geometries, enabling automatic quantitative analysis of membrane contact sites and remodeling events such as invagination. While demonstrated here on cryo-ET membrane data, the combined approach is applicable to ROI detection and surface analysis in broader scientific imaging contexts.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [27] [MoBiQuant: Mixture-of-Bits Quantization for Token-Adaptive Elastic LLMs](https://arxiv.org/abs/2602.20191)
*Dongwei Wang,Jinhee Kim,Seokho Han,Denis Gudovskiy,Yohei Nakata,Tomoyuki Okuno,KhayTze Peong,Kang Eun Jeon,Jong Hwan Ko,Yiran Chen,Huanrui Yang*

Main category: cs.LG

TL;DR: MoBiQuant是一个混合比特量化框架，通过基于token敏感性的权重精度调整，实现弹性LLM推理，无需重复校准即可在不同精度间平滑切换。


<details>
  <summary>Details</summary>
Motivation: 云和边缘设备运行时复杂性变化需要弹性LLM部署，但传统量化校准参数与特定精度绑定，导致弹性精度校准和运行时精度切换困难。

Method: 提出MoBiQuant框架：1) 多合一递归残差量化，可迭代重建更高精度权重；2) token感知路由器，动态选择残差比特片数量。通过token级敏感性调整权重精度。

Result: 实验结果显示MoBiQuant表现出强弹性，在LLaMA3-8B上无需重复校准即可匹配比特特定校准PTQ的性能。

Conclusion: MoBiQuant通过基于token敏感性的混合比特量化，解决了弹性LLM部署中的精度切换问题，提高了对token异常值分布的泛化能力。

Abstract: Changing runtime complexity on cloud and edge devices necessitates elastic large language model (LLM) deployment, where an LLM can be inferred with various quantization precisions based on available computational resources. However, it has been observed that the calibration parameters for quantization are typically linked to specific precisions, which presents challenges during elastic-precision calibration and precision switching at runtime. In this work, we attribute the source of varying calibration parameters to the varying token-level sensitivity caused by a precision-dependent outlier migration phenomenon.Motivated by this observation, we propose \texttt{MoBiQuant}, a novel Mixture-of-Bits quantization framework that adjusts weight precision for elastic LLM inference based on token sensitivity. Specifically, we propose the many-in-one recursive residual quantization that can iteratively reconstruct higher-precision weights and the token-aware router to dynamically select the number of residual bit slices. MoBiQuant enables smooth precision switching while improving generalization for the distribution of token outliers. Experimental results demonstrate that MoBiQuant exhibits strong elasticity, enabling it to match the performance of bit-specific calibrated PTQ on LLaMA3-8B without repeated calibration.

</details>


### [28] [FedAvg-Based CTMC Hazard Model for Federated Bridge Deterioration Assessment](https://arxiv.org/abs/2602.20194)
*Takato Yasuno*

Main category: cs.LG

TL;DR: 提出联邦学习框架，用于桥梁退化CTMC风险模型估计，实现跨组织数据共享而不传输原始检查记录


<details>
  <summary>Details</summary>
Motivation: 桥梁定期检查记录包含敏感公共基础设施信息，现有数据治理约束下跨组织数据共享不切实际，需要保护数据主权的同时实现协作建模

Method: 联邦学习框架：各用户本地训练对数线性风险模型（三个退化方向转移），通过小批量随机梯度下降优化CTMC对数似然，仅上传12维伪梯度向量；服务器使用带动量和梯度裁剪的样本加权FedAvg聚合更新

Result: 在完全合成数据上实验显示，异构用户间平均负对数似然一致收敛，聚合梯度范数随用户规模增加而减小；联邦更新机制提供自然参与激励

Conclusion: 该框架使市政部门能够协作训练共享基准模型而不传输原始检查记录，用户在共享技术标准平台注册本地数据集可获得定期更新的全局基准参数，实现基于证据的生命周期规划同时保护数据主权

Abstract: Bridge periodic inspection records contain sensitive information about public infrastructure, making cross-organizational data sharing impractical under existing data governance constraints. We propose a federated framework for estimating a Continuous-Time Markov Chain (CTMC) hazard model of bridge deterioration, enabling municipalities to collaboratively train a shared benchmark model without transferring raw inspection records. Each User holds local inspection data and trains a log-linear hazard model over three deterioration-direction transitions -- Good$\to$Minor, Good$\to$Severe, and Minor$\to$Severe -- with covariates for bridge age, coastline distance, and deck area. Local optimization is performed via mini-batch stochastic gradient descent on the CTMC log-likelihood, and only a 12-dimensional pseudo-gradient vector is uploaded to a central server per communication round. The server aggregates User updates using sample-weighted Federated Averaging (FedAvg) with momentum and gradient clipping. All experiments in this paper are conducted on fully synthetic data generated from a known ground-truth parameter set with region-specific heterogeneity, enabling controlled evaluation of federated convergence behaviour. Simulation results across heterogeneous Users show consistent convergence of the average negative log-likelihood, with the aggregated gradient norm decreasing as User scale increases. Furthermore, the federated update mechanism provides a natural participation incentive: Users who register their local inspection datasets on a shared technical-standard platform receive in return the periodically updated global benchmark parameters -- information that cannot be obtained from local data alone -- thereby enabling evidence-based life-cycle planning without surrendering data sovereignty.

</details>


### [29] [Controllable Exploration in Hybrid-Policy RLVR for Multi-Modal Reasoning](https://arxiv.org/abs/2602.20197)
*Zhuoxu Huang,Mengxi Jia,Hao Sun,Xuelong Li,Jungong Han*

Main category: cs.LG

TL;DR: CalibRL提出了一种混合策略的RLVR框架，通过分布感知优势加权和LeakyReLU激活函数实现可控探索，解决MLLM训练中的熵崩溃、策略退化等问题。


<details>
  <summary>Details</summary>
Motivation: 在MLLM的RLVR训练中，巨大的状态空间和稀疏奖励会导致熵崩溃、策略退化或对次优行为的过度利用，需要一种既能保持生产性随机性又避免无控制随机采样缺点的探索策略。

Method: 提出CalibRL混合策略RLVR框架：1）分布感知优势加权，通过组稀有性缩放更新来校准分布；2）非对称激活函数（LeakyReLU），利用专家知识作为校准基线来调节过度自信的更新。通过在线采样估计在策略分布，以信息性行为驱动更新。

Result: 在八个基准测试（包括域内和域外设置）上的广泛实验显示了一致的改进，验证了可控混合策略RLVR训练的有效性。

Conclusion: CalibRL通过可控探索缓解了模型策略与专家轨迹之间的分布不匹配，实现了探索与利用之间更稳定的平衡，提高了RLVR训练的效果。

Abstract: Reinforcement Learning with verifiable rewards (RLVR) has emerged as a primary learning paradigm for enhancing the reasoning capabilities of multi-modal large language models (MLLMs). However, during RL training, the enormous state space of MLLM and sparse rewards often leads to entropy collapse, policy degradation, or over-exploitation of suboptimal behaviors. This necessitates an exploration strategy that maintains productive stochasticity while avoiding the drawbacks of uncontrolled random sampling, yielding inefficient exploration. In this paper, we propose CalibRL, a hybrid-policy RLVR framework that supports controllable exploration with expert guidance, enabled by two key mechanisms. First, a distribution-aware advantage weighting scales updates by group rareness to calibrate the distribution, therefore preserving exploration. Meanwhile, the asymmetric activation function (LeakyReLU) leverages the expert knowledge as a calibration baseline to moderate overconfident updates while preserving their corrective direction. CalibRL increases policy entropy in a guided manner and clarifies the target distribution by estimating the on-policy distribution through online sampling. Updates are driven by these informative behaviors, avoiding convergence to erroneous patterns. Importantly, these designs help alleviate the distributional mismatch between the model's policy and expert trajectories, thereby achieving a more stable balance between exploration and exploitation. Extensive experiments across eight benchmarks, including both in-domain and out-of-domain settings, demonstrate consistent improvements, validating the effectiveness of our controllable hybrid-policy RLVR training. Code is available at https://github.com/zhh6425/CalibRL.

</details>


### [30] [IMOVNO+: A Regional Partitioning and Meta-Heuristic Ensemble Framework for Imbalanced Multi-Class Learning](https://arxiv.org/abs/2602.20199)
*Soufiane Bacha,Laouni Djafri,Sahraoui Dhelim,Huansheng Ning*

Main category: cs.LG

TL;DR: IMOVNO+是一个两级框架，通过数据级优化（条件概率量化样本信息、区域划分、重叠清理、智能过采样）和算法级优化（元启发式集成剪枝）联合处理多类和二类任务中的类别不平衡、重叠和噪声问题，在35个数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡、重叠和噪声会降低数据质量、减少模型可靠性并限制泛化能力。虽然在二分类中已有广泛研究，但在多类设置中这些问题仍未充分探索，其中复杂的类间关系使得少数-多数结构不明确，传统聚类无法捕捉分布形状。现有方法仅依赖几何距离可能移除信息样本并生成低质量合成数据，而二值化方法局部处理不平衡并忽略全局类间依赖。在算法层面，集成方法难以整合弱分类器，导致鲁棒性有限。

Method: IMOVNO+是一个两级框架：1) 数据级：使用条件概率量化每个样本的信息量；将数据集划分为核心、重叠和噪声区域；引入结合Z-score度量和big-jump gap距离的重叠清理算法；基于多正则化的智能过采样算法控制合成样本邻近度，防止新重叠。2) 算法级：使用元启发式方法剪枝集成分类器以减少弱学习器影响。

Result: 在35个数据集（13个多类，22个二类）上评估，结果显示IMOVNO+始终优于最先进方法，在多个案例中接近100%性能。对于多类数据，IMOVNO+在G-mean上获得37-57%增益，F1-score 25-44%，精确率25-39%，召回率26-43%。在二类任务中，达到接近完美性能，改进14-39%。

Conclusion: IMOVNO+框架有效处理了从数据收集和隐私限制导致的数据稀缺和不平衡问题，通过联合增强数据质量和算法鲁棒性，在二类和多类任务中都取得了显著性能提升。

Abstract: Class imbalance, overlap, and noise degrade data quality, reduce model reliability, and limit generalization. Although widely studied in binary classification, these issues remain underexplored in multi-class settings, where complex inter-class relationships make minority-majority structures unclear and traditional clustering fails to capture distribution shape. Approaches that rely only on geometric distances risk removing informative samples and generating low-quality synthetic data, while binarization approaches treat imbalance locally and ignore global inter-class dependencies. At the algorithmic level, ensembles struggle to integrate weak classifiers, leading to limited robustness. This paper proposes IMOVNO+ (IMbalance-OVerlap-NOise+ Algorithm-Level Optimization), a two-level framework designed to jointly enhance data quality and algorithmic robustness for binary and multi-class tasks. At the data level, first, conditional probability is used to quantify the informativeness of each sample. Second, the dataset is partitioned into core, overlapping, and noisy regions. Third, an overlapping-cleaning algorithm is introduced that combines Z-score metrics with a big-jump gap distance. Fourth, a smart oversampling algorithm based on multi-regularization controls synthetic sample proximity, preventing new overlaps. At the algorithmic level, a meta-heuristic prunes ensemble classifiers to reduce weak-learner influence. IMOVNO+ was evaluated on 35 datasets (13 multi-class, 22 binary). Results show consistent superiority over state-of-the-art methods, approaching 100% in several cases. For multi-class data, IMOVNO+ achieves gains of 37-57% in G-mean, 25-44% in F1-score, 25-39% in precision, and 26-43% in recall. In binary tasks, it attains near-perfect performance with improvements of 14-39%. The framework handles data scarcity and imbalance from collection and privacy limits.

</details>


### [31] [Multimodal Crystal Flow: Any-to-Any Modality Generation for Unified Crystal Modeling](https://arxiv.org/abs/2602.20210)
*Kiyoung Seong,Sungsoo Ahn,Sehui Han,Changyoung Park*

Main category: cs.LG

TL;DR: MCFlow是一个统一的多模态流模型，通过独立的原子类型和晶体结构时间变量，将多种晶体生成任务实现为不同的推理轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有的深度生成模型大多是任务特定的，缺乏一个能够跨不同生成任务共享晶体表示的统一框架。

Method: 提出多模态晶体流模型，通过独立的原子类型和晶体结构时间变量实现多任务统一；引入基于组成和对称性的原子排序与分层排列增强，在标准Transformer模型中注入强组成和晶体学先验。

Result: 在MP-20和MPTS-52基准测试中，MCFlow在多个晶体生成任务上实现了与任务特定基线相竞争的性能。

Conclusion: MCFlow提供了一个统一的框架，能够有效处理多种晶体生成任务，同时保持与任务特定模型相当的性能。

Abstract: Crystal modeling spans a family of conditional and unconditional generation tasks across different modalities, including crystal structure prediction (CSP) and \emph{de novo} generation (DNG). While recent deep generative models have shown promising performance, they remain largely task-specific, lacking a unified framework that shares crystal representations across different generation tasks. To address this limitation, we propose \emph{Multimodal Crystal Flow (MCFlow)}, a unified multimodal flow model that realizes multiple crystal generation tasks as distinct inference trajectories via independent time variables for atom types and crystal structures. To enable multimodal flow in a standard transformer model, we introduce a composition- and symmetry-aware atom ordering with hierarchical permutation augmentation, injecting strong compositional and crystallographic priors without explicit structural templates. Experiments on the MP-20 and MPTS-52 benchmarks show that MCFlow achieves competitive performance against task-specific baselines across multiple crystal generation tasks.

</details>


### [32] [KnapSpec: Self-Speculative Decoding via Adaptive Layer Selection as a Knapsack Problem](https://arxiv.org/abs/2602.20217)
*Seongjin Cha,Gyuwan Kim,Dongsu Han,Tao Yang,Insu Han*

Main category: cs.LG

TL;DR: KnapSpec通过将草稿模型选择重构为背包问题，在长上下文场景中动态优化推理速度，无需训练即可实现最高1.47倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的自推测解码方法依赖静态启发式策略，忽略了长上下文场景中注意力机制动态计算开销的问题，需要更智能的草稿模型选择机制来最大化推理吞吐量。

Method: 将草稿模型选择建模为背包问题，解耦注意力层和MLP层并建模其硬件特定的延迟函数，使用并行动态规划算法在线识别最优草稿配置，并首次建立隐藏状态余弦相似度与令牌接受率的理论关联。

Result: 在Qwen3和Llama3上的实验表明，KnapSpec始终优于最先进的自推测解码基线方法，在各种基准测试中实现了最高1.47倍的实时加速，且无需额外训练或改变目标模型输出分布。

Conclusion: KnapSpec提供了一种即插即用的训练免费框架，能够在长序列推理中实现高速性能，通过动态优化草稿模型配置来应对实际硬件中的瓶颈变化。

Abstract: Self-speculative decoding (SSD) accelerates LLM inference by skipping layers to create an efficient draft model, yet existing methods often rely on static heuristics that ignore the dynamic computational overhead of attention in long-context scenarios. We propose KnapSpec, a training-free framework that reformulates draft model selection as a knapsack problem to maximize tokens-per-time throughput. By decoupling Attention and MLP layers and modeling their hardware-specific latencies as functions of context length, KnapSpec adaptively identifies optimal draft configurations on the fly via a parallel dynamic programming algorithm. Furthermore, we provide the first rigorous theoretical analysis establishing cosine similarity between hidden states as a mathematically sound proxy for the token acceptance rate. This foundation allows our method to maintain high drafting faithfulness while navigating the shifting bottlenecks of real-world hardware. Our experiments on Qwen3 and Llama3 demonstrate that KnapSpec consistently outperforms state-of-the-art SSD baselines, achieving up to 1.47x wall-clock speedup across various benchmarks. Our plug-and-play approach ensures high-speed inference for long sequences without requiring additional training or compromising the target model's output distribution.

</details>


### [33] [Coupled Cluster con MōLe: Molecular Orbital Learning for Neural Wavefunctions](https://arxiv.org/abs/2602.20232)
*Luca Thiede,Abdulrahman Aldossary,Andreas Burger,Jorge Arturo Campos-Gonzalez-Angulo,Ning Wang,Alexander Zook,Melisa Alkan,Kouhei Nakaji,Taylor Lee Patti,Jérôme Florian Gonthier,Mohammad Ghazi Vakili,Alán Aspuru-Guzik*

Main category: cs.LG

TL;DR: MōLe架构通过机器学习直接从HF分子轨道预测CC激发振幅，显著降低计算成本，在小分子训练下实现大分子和非平衡构型泛化


<details>
  <summary>Details</summary>
Motivation: DFT计算精度不足，CC理论虽为"金标准"但计算成本过高，限制了其广泛应用。需要开发高效方法降低CC计算成本

Method: 提出MōLe架构，一种等变机器学习模型，直接从平均场Hartree-Fock分子轨道作为输入预测CC的核心数学对象——激发振幅

Result: 模型表现出显著的数据效率和泛化能力，仅在小分子平衡构型上训练就能泛化到更大分子和非平衡构型，并能减少CC计算收敛所需的循环次数

Conclusion: MōLe为基于波函数的高精度机器学习架构奠定了基础，可加速分子设计并补充力场方法

Abstract: Density functional theory (DFT) is the most widely used method for calculating molecular properties; however, its accuracy is often insufficient for quantitative predictions. Coupled-cluster (CC) theory is the most successful method for achieving accuracy beyond DFT and for predicting properties that closely align with experiment. It is known as the ''gold standard'' of quantum chemistry. Unfortunately, the high computational cost of CC limits its widespread applicability. In this work, we present the Molecular Orbital Learning (MōLe) architecture, an equivariant machine learning model that directly predicts CC's core mathematical objects, the excitation amplitudes, from the mean-field Hartree-Fock molecular orbitals as inputs. We test various aspects of our model and demonstrate its remarkable data efficiency and out-of-distribution generalization to larger molecules and off-equilibrium geometries, despite being trained only on small equilibrium geometries. Finally, we also examine its ability to reduce the number of cycles required to converge CC calculations. MōLe can set the foundations for high-accuracy wavefunction-based ML architectures to accelerate molecular design and complement force-field approaches.

</details>


### [34] [The Truthfulness Spectrum Hypothesis](https://arxiv.org/abs/2602.20273)
*Zhuofan Josh Ying,Shauli Ravfogel,Nikolaus Kriegeskorte,Peter Hase*

Main category: cs.LG

TL;DR: 研究发现大语言模型中的真实性表征存在从广泛领域通用到狭窄领域特定的频谱，通过几何分析揭示了不同真实性类型的表征结构及其泛化模式。


<details>
  <summary>Details</summary>
Motivation: 先前研究对LLMs是否线性编码真实性存在分歧，本研究旨在调和这些观点，验证真实性频谱假说：表征空间中存在从广泛领域通用到狭窄领域特定的真实性方向。

Method: 系统评估五种真实性类型（定义性、经验性、逻辑性、虚构性、伦理性）、奉承性和期望反转性说谎，以及现有诚实性基准；使用线性探针、几何分析（马氏余弦相似度）、概念擦除方法和因果干预。

Result: 线性探针在大多数领域泛化良好，但在奉承性和期望反转性说谎上失败；联合训练恢复强性能；探针方向的几何结构完美预测跨领域泛化；概念擦除分离出三种真实性方向；因果干预显示领域特定方向比领域通用方向更有效；后训练重塑真实性几何结构。

Conclusion: 支持真实性频谱假说：不同通用程度的真实性方向在表征空间中并存，后训练重塑其几何结构，为聊天模型的奉承倾向提供了表征基础。

Abstract: Large language models (LLMs) have been reported to linearly encode truthfulness, yet recent work questions this finding's generality. We reconcile these views with the truthfulness spectrum hypothesis: the representational space contains directions ranging from broadly domain-general to narrowly domain-specific. To test this hypothesis, we systematically evaluate probe generalization across five truth types (definitional, empirical, logical, fictional, and ethical), sycophantic and expectation-inverted lying, and existing honesty benchmarks. Linear probes generalize well across most domains but fail on sycophantic and expectation-inverted lying. Yet training on all domains jointly recovers strong performance, confirming that domain-general directions exist despite poor pairwise transfer. The geometry of probe directions explains these patterns: Mahalanobis cosine similarity between probes near-perfectly predicts cross-domain generalization (R^2=0.98). Concept-erasure methods further isolate truth directions that are (1) domain-general, (2) domain-specific, or (3) shared only across particular domain subsets. Causal interventions reveal that domain-specific directions steer more effectively than domain-general ones. Finally, post-training reshapes truth geometry, pushing sycophantic lying further from other truth types, suggesting a representational basis for chat models' sycophantic tendencies. Together, our results support the truthfulness spectrum hypothesis: truth directions of varying generality coexist in representational space, with post-training reshaping their geometry. Code for all experiments is provided in https://github.com/zfying/truth_spec.

</details>


### [35] [GATES: Self-Distillation under Privileged Context with Consensus Gating](https://arxiv.org/abs/2602.20574)
*Alex Stein,Furong Huang,Tom Goldstein*

Main category: cs.LG

TL;DR: 该论文提出了一种在无监督环境下通过导师共识门控轨迹蒸馏的方法，用于文档问答任务，显著提升了学生模型的性能。


<details>
  <summary>Details</summary>
Motivation: 研究在监督不可靠（无真实标签、可验证奖励或外部评分者）情况下的自蒸馏问题，特别是在文档问答任务中，导师模型（训练时可访问文档）和学生模型（测试时仅基于问题回答）之间存在信息不对称。

Method: 提出共识门控轨迹蒸馏方法：通过采样多个基于文档的推理轨迹，利用导师间的一致性作为可靠性信号来门控学习；基于此信号，通过完整的导师推理轨迹（而非仅最终答案）进行知识蒸馏，提供密集且稳定的学习信号。

Result: 在非对称评估下，领域内准确率从46.0%提升至62.0%；在公开的无文档数学基准测试中，平均准确率从20.2%提升至35.4%。

Conclusion: 共识门控轨迹蒸馏方法能有效处理不可靠监督问题，显著提升从导师到学生的知识转移效果，特别是在信息不对称的文档问答任务中。

Abstract: We study self-distillation in settings where supervision is unreliable: there are no ground truth labels, verifiable rewards, or external graders to evaluate answers. We focus on document-grounded question answering with asymmetric context, where a single model serves as both tutor (with access to a relevant source document during training) and student (answering from the question alone at test time). Rather than assuming tutor correctness, we derive supervision online from tutor consensus by sampling multiple document-grounded reasoning traces and using agreement to gate learning. Conditioned on this reliability signal, we distill knowledge through full tutor reasoning trajectories (not just final answers), providing a dense and stable learning signal. Empirically, this consensus-gated trajectory distillation substantially improves transfer to the document-free student. Held-out in-domain accuracy under asymmetric evaluation improves from 46.0\% to 62.0\%, and average (maj@8) accuracy on public document-free math benchmarks improves from 20.2\% to 35.4\%.

</details>


### [36] [Is the Trigger Essential? A Feature-Based Triggerless Backdoor Attack in Vertical Federated Learning](https://arxiv.org/abs/2602.20593)
*Yige Liu,Yiwei Lou,Che Wang,Yongzhi Cao,Hanpin Wang*

Main category: cs.LG

TL;DR: 本文提出了一种垂直联邦学习中的无触发器后门攻击方法，该攻击在更严格的安全假设下（攻击者在训练阶段是诚实但好奇的而非恶意的），通过特征而非触发器实现后门攻击，性能远超现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管垂直联邦学习（VFL）以隐私保护能力著称，但仍面临后门攻击的隐私和安全威胁。现有后门攻击通常需要在训练阶段植入触发器并在推理阶段添加触发器，但本文发现触发器在VFL后门攻击中并非必需，因此探索更隐蔽的攻击途径。

Method: 提出基于特征的无触发器后门攻击，包含三个模块：1）针对目标后门攻击的标签推断；2）具有放大和扰动机制的毒药生成；3）实施攻击的后门执行。攻击在更严格的安全假设下进行，攻击者在训练阶段是诚实但好奇的。

Result: 在五个基准数据集上的实验表明，该攻击性能比三种基线后门攻击高出2到50倍，同时对主任务影响最小。即使在有32个被动方且只有一组辅助数据的VFL场景中，攻击仍保持高性能。面对不同防御策略时，攻击基本不受影响且表现出强鲁棒性。

Conclusion: 本文揭示了VFL中无触发器后门攻击的新途径，希望这一发现能促使社区重新审视VFL场景中的安全威胁，并激发研究人员开发更鲁棒和实用的防御策略。

Abstract: As a distributed collaborative machine learning paradigm, vertical federated learning (VFL) allows multiple passive parties with distinct features and one active party with labels to collaboratively train a model. Although it is known for the privacy-preserving capabilities, VFL still faces significant privacy and security threats from backdoor attacks. Existing backdoor attacks typically involve an attacker implanting a trigger into the model during the training phase and executing the attack by adding the trigger to the samples during the inference phase. However, in this paper, we find that triggers are not essential for backdoor attacks in VFL. In light of this, we disclose a new backdoor attack pathway in VFL by introducing a feature-based triggerless backdoor attack. This attack operates under a more stringent security assumption, where the attacker is honest-but-curious rather than malicious during the training phase. It comprises three modules: label inference for the targeted backdoor attack, poison generation with amplification and perturbation mechanisms, and backdoor execution to implement the attack. Extensive experiments on five benchmark datasets demonstrate that our attack outperforms three baseline backdoor attacks by 2 to 50 times while minimally impacting the main task. Even in VFL scenarios with 32 passive parties and only one set of auxiliary data, our attack maintains high performance. Moreover, when confronted with distinct defense strategies, our attack remains largely unaffected and exhibits strong robustness. We hope that the disclosure of this triggerless backdoor attack pathway will encourage the community to revisit security threats in VFL scenarios and inspire researchers to develop more robust and practical defense strategies.

</details>


### [37] [QEDBENCH: Quantifying the Alignment Gap in Automated Evaluation of University-Level Mathematical Proofs](https://arxiv.org/abs/2602.20629)
*Santiago Gonzalez,Alireza Amiri Bavandpour,Peter Ye,Edward Zhang,Ruslans Aleksejevs,Todor Antić,Polina Baron,Sujeet Bhalerao,Shubhrajit Bhattacharya,Zachary Burton,John Byrne,Hyungjun Choi,Nujhat Ahmed Disha,Koppany István Encz,Yuchen Fang,Robert Joseph George,Ebrahim Ghorbani,Alan Goldfarb,Jing Guo,Meghal Gupta,Stefano Huber,Annika Kanckos,Minjung Kang,Hyun Jong Kim,Dino Lorenzini,Levi Lorenzo,Tianyi Mao,Giovanni Marzenta,Ariane M. Masuda,Lukas Mauth,Ana Mickovic,Andres Miniguano-Trujillo,Antoine Moulin,Wenqi Ni,Tomos Parry,Kevin Ren,Hossein Roodbarani,Mathieu Rundström,Manjil Saikia,Detchat Samart,Rebecca Steiner,Connor Stewart,Dhara Thakkar,Jeffrey Tse,Vasiliki Velona,Yunhai Xiang,Sibel Yalçın,Jun Yan,Ji Zeng,Arman Cohan,Quanquan C. Liu*

Main category: cs.LG

TL;DR: 研究发现LLM评估协议在高等数学证明评估中存在系统性对齐差距，某些前沿评估模型存在显著正向偏差，离散数学领域存在关键推理差距。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在基础基准测试上趋于饱和，研究前沿从生成转向自动化评估的可靠性。标准"LLM作为评判者"协议在高等数学证明评估中存在系统性对齐差距。

Method: 引入QEDBench基准，采用双评分标准对比课程特定评分标准和专家常识标准，部署7位评判者×5个求解器的双评估矩阵，基于1000+小时人工评估。

Result: 发现Claude Opus 4.5、DeepSeek-V3、Qwen 2.5 Max和Llama 4 Maverick等前沿评估模型存在显著正向偏差；Gemini 3.0 Pro表现最佳，而GPT-5 Pro和Claude Sonnet 4.5在离散数学领域性能显著下降。

Conclusion: LLM评估协议在高等数学领域存在系统性对齐问题，需要更可靠的评估基准。发布QEDBench作为公开基准，用于评估和改进AI评判者。

Abstract: As Large Language Models (LLMs) saturate elementary benchmarks, the research frontier has shifted from generation to the reliability of automated evaluation. We demonstrate that standard "LLM-as-a-Judge" protocols suffer from a systematic Alignment Gap when applied to upper-undergraduate to early graduate level mathematics. To quantify this, we introduce QEDBench, the first large-scale dual-rubric alignment benchmark to systematically measure alignment with human experts on university-level math proofs by contrasting course-specific rubrics against expert common knowledge criteria. By deploying a dual-evaluation matrix (7 judges x 5 solvers) against 1,000+ hours of human evaluation, we reveal that certain frontier evaluators like Claude Opus 4.5, DeepSeek-V3, Qwen 2.5 Max, and Llama 4 Maverick exhibit significant positive bias (up to +0.18, +0.20, +0.30, +0.36 mean score inflation, respectively). Furthermore, we uncover a critical reasoning gap in the discrete domain: while Gemini 3.0 Pro achieves state-of-the-art performance (0.91 average human evaluation score), other reasoning models like GPT-5 Pro and Claude Sonnet 4.5 see their performance significantly degrade in discrete domains. Specifically, their average human evaluation scores drop to 0.72 and 0.63 in Discrete Math, and to 0.74 and 0.50 in Graph Theory. In addition to these research results, we also release QEDBench as a public benchmark for evaluating and improving AI judges. Our benchmark is publicly published at https://github.com/qqliu/Yale-QEDBench.

</details>


### [38] [TrajGPT-R: Generating Urban Mobility Trajectory with Reinforcement Learning-Enhanced Generative Pre-trained Transformer](https://arxiv.org/abs/2602.20643)
*Jiawei Wang,Chuang Yang,Jiawei Yong,Xiaohang Xu,Hongjun Wang,Noboru Koshizuka,Shintaro Fukushima,Ryosuke Shibasaki,Renhe Jiang*

Main category: cs.LG

TL;DR: 该研究提出了一个基于Transformer的框架TrajGPT，用于生成大规模城市移动轨迹，通过两阶段训练过程解决隐私数据获取问题，在可靠性和多样性方面优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 城市移动轨迹数据对理解城市动态和城市规划至关重要，但隐私问题限制了数据的获取。需要开发能够生成大规模、高质量轨迹数据的方法，同时保护个人隐私。

Method: 采用两阶段Transformer模型：1) 将轨迹生成建模为离线强化学习问题，通过tokenization减少词汇空间；2) 集成逆强化学习捕捉轨迹级奖励信号，推断个体移动偏好；3) 使用构建的奖励模型对预训练模型进行微调，解决传统RL方法的长期信用分配和稀疏奖励问题。

Result: 在多个数据集上的综合评估表明，该框架在可靠性和多样性方面显著优于现有模型，为城市数据模拟提供了稳健的方法。

Conclusion: 该研究不仅推动了城市移动建模领域的发展，还为交通管理和城市规划提供了重要的方法论支持，代码已公开可用。

Abstract: Mobility trajectories are essential for understanding urban dynamics and enhancing urban planning, yet access to such data is frequently hindered by privacy concerns. This research introduces a transformative framework for generating large-scale urban mobility trajectories, employing a novel application of a transformer-based model pre-trained and fine-tuned through a two-phase process. Initially, trajectory generation is conceptualized as an offline reinforcement learning (RL) problem, with a significant reduction in vocabulary space achieved during tokenization. The integration of Inverse Reinforcement Learning (IRL) allows for the capture of trajectory-wise reward signals, leveraging historical data to infer individual mobility preferences. Subsequently, the pre-trained model is fine-tuned using the constructed reward model, effectively addressing the challenges inherent in traditional RL-based autoregressive methods, such as long-term credit assignment and handling of sparse reward environments. Comprehensive evaluations on multiple datasets illustrate that our framework markedly surpasses existing models in terms of reliability and diversity. Our findings not only advance the field of urban mobility modeling but also provide a robust methodology for simulating urban data, with significant implications for traffic management and urban development planning. The implementation is publicly available at https://github.com/Wangjw6/TrajGPT_R.

</details>


### [39] [Bikelution: Federated Gradient-Boosting for Scalable Shared Micro-Mobility Demand Forecasting](https://arxiv.org/abs/2602.20671)
*Antonios Tziorvas,Andreas Tritsarolis,Yannis Theodoridis*

Main category: cs.LG

TL;DR: Bikelution：基于梯度提升树的联邦学习方案，用于无桩共享单车需求预测，在保护隐私的同时实现准确的中期预测


<details>
  <summary>Details</summary>
Motivation: 无桩共享单车系统产生大量时空数据，但单车需求受多种外部因素影响，传统时间序列模型不足。集中式机器学习虽然预测准确，但在数据分布在边缘设备时存在隐私和带宽问题。

Method: 提出Bikelution方案，基于梯度提升树的联邦学习方法，在保护隐私的同时进行准确的中期需求预测（最多提前6小时）

Result: 在三个真实世界BSS数据集上的实验表明，Bikelution性能与集中式机器学习变体相当，并优于当前最先进方法

Conclusion: 研究证明了隐私感知需求预测的可行性，并揭示了联邦学习与集中式机器学习方法之间的权衡关系

Abstract: The rapid growth of dockless bike-sharing systems has generated massive spatio-temporal datasets useful for fleet allocation, congestion reduction, and sustainable mobility. Bike demand, however, depends on several external factors, making traditional time-series models insufficient. Centralized Machine Learning (CML) yields high-accuracy forecasts but raises privacy and bandwidth issues when data are distributed across edge devices. To overcome these limitations, we propose Bikelution, an efficient Federated Learning (FL) solution based on gradient-boosted trees that preserves privacy while delivering accurate mid-term demand forecasts up to six hours ahead. Experiments on three real-world BSS datasets show that Bikelution is comparable to its CML-based variant and outperforms the current state-of-the-art. The results highlight the feasibility of privacy-aware demand forecasting and outline the trade-offs between FL and CML approaches.

</details>


### [40] [UrbanFM: Scaling Urban Spatio-Temporal Foundation Models](https://arxiv.org/abs/2602.20677)
*Wei Chen,Yuqian Wu,Junle Chen,Xiaofang Zhou,Yuxuan Liang*

Main category: cs.LG

TL;DR: 该论文提出了构建城市时空基础模型的方法，通过数据、计算和架构三个维度的扩展来解决城市系统中时空数据的异质性、相关性和动态性问题，实现了跨城市和任务的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 城市系统作为动态复杂系统，持续产生时空数据流，但当前城市计算领域存在"场景特定"模型的问题，这些模型过度拟合特定区域或任务，缺乏泛化能力。为了构建城市时空基础模型，需要解决异质性、相关性和动态性这三个核心科学问题。

Method: 1. 数据扩展：构建WorldST亿级语料库，标准化100多个全球城市的交通流量和速度等物理信号；2. 计算扩展：引入MiniST单元，将连续时空场离散化为可学习的计算单元；3. 架构扩展：提出UrbanFM，一种最小化归纳偏置的自注意力架构，用于学习动态时空依赖关系；4. 建立EvalST大规模评估基准。

Result: UrbanFM在未见过的城市和任务上实现了显著的零样本泛化能力，标志着大规模城市时空基础模型的重要进展。WorldST语料库包含亿级标准化数据，EvalST是目前最大规模的时空评估基准。

Conclusion: 通过系统性地解决异质性、相关性和动态性三个维度的问题，该研究为构建城市时空基础模型迈出了关键一步，展示了扩展方法在统一城市时空建模中的有效性，为未来城市科学的发展提供了重要基础。

Abstract: Urban systems, as dynamic complex systems, continuously generate spatio-temporal data streams that encode the fundamental laws of human mobility and city evolution. While AI for Science has witnessed the transformative power of foundation models in disciplines like genomics and meteorology, urban computing remains fragmented due to "scenario-specific" models, which are overfitted to specific regions or tasks, hindering their generalizability. To bridge this gap and advance spatio-temporal foundation models for urban systems, we adopt scaling as the central perspective and systematically investigate two key questions: what to scale and how to scale. Grounded in first-principles analysis, we identify three critical dimensions: heterogeneity, correlation, and dynamics, aligning these principles with the fundamental scientific properties of urban spatio-temporal data. Specifically, to address heterogeneity through data scaling, we construct WorldST. This billion-scale corpus standardizes diverse physical signals, such as traffic flow and speed, from over 100 global cities into a unified data format. To enable computation scaling for modeling correlations, we introduce the MiniST unit, a novel split mechanism that discretizes continuous spatio-temporal fields into learnable computational units to unify representations of grid-based and sensor-based observations. Finally, addressing dynamics via architecture scaling, we propose UrbanFM, a minimalist self-attention architecture designed with limited inductive biases to autonomously learn dynamic spatio-temporal dependencies from massive data. Furthermore, we establish EvalST, the largest-scale urban spatio-temporal benchmark to date. Extensive experiments demonstrate that UrbanFM achieves remarkable zero-shot generalization across unseen cities and tasks, marking a pivotal first step toward large-scale urban spatio-temporal foundation models.

</details>


### [41] [High-Dimensional Robust Mean Estimation with Untrusted Batches](https://arxiv.org/abs/2602.20698)
*Maryam Aliakbarpour,Vladimir Braverman,Yuhan Liu,Junze Yin*

Main category: cs.LG

TL;DR: 论文研究高维均值估计的协作学习问题，用户以大小为n的批次贡献数据，面临双重腐败：ε比例用户完全对抗，其余"好"用户数据分布与真实分布P存在α偏差。提出两种基于平方和算法的解决方案，达到最优误差率。


<details>
  <summary>Details</summary>
Motivation: 研究在协作学习环境中，当数据来自统计异质且可能恶意的用户时，如何从真实分布中恢复均值。现有工作在离散设置中使用总变差距离，而本文关注连续高维场景，考虑两种偏差变体：均值偏移和样本级腐败。

Method: 提出两种基于平方和(SoS)的算法来处理分层腐败。第一种处理好用户分布存在均值偏移的情况，第二种处理好用户批次内部分样本被对抗性污染的情况。算法利用批次结构提供的内部平均来抑制对抗用户的影响。

Result: 算法达到极小极大最优误差率O(√(ε/n) + √(d/nN) + √α)，表明异质性α代表固有统计难度，而对抗用户的影响被批次结构的内部平均抑制了1/√n因子。

Conclusion: 在高维协作均值估计中，批次结构能有效减轻对抗用户的影响，而统计异质性构成固有挑战。提出的SoS算法在双重腐败环境下达到最优性能，为高维连续设置中的鲁棒估计提供了新方法。

Abstract: We study high-dimensional mean estimation in a collaborative setting where data is contributed by $N$ users in batches of size $n$. In this environment, a learner seeks to recover the mean $μ$ of a true distribution $P$ from a collection of sources that are both statistically heterogeneous and potentially malicious. We formalize this challenge through a double corruption landscape: an $\varepsilon$-fraction of users are entirely adversarial, while the remaining ``good'' users provide data from distributions that are related to $P$, but deviate by a proximity parameter $α$.
  Unlike existing work on the untrusted batch model, which typically measures this deviation via total variation distance in discrete settings, we address the continuous, high-dimensional regime under two natural variants for deviation: (1) good batches are drawn from distributions with a mean-shift of $\sqrtα$, or (2) an $α$-fraction of samples within each good batch are adversarially corrupted. In particular, the second model presents significant new challenges: in high dimensions, unlike discrete settings, even a small fraction of sample-level corruption can shift empirical means and covariances arbitrarily.
  We provide two Sum-of-Squares (SoS) based algorithms to navigate this tiered corruption. Our algorithms achieve the minimax-optimal error rate $O(\sqrt{\varepsilon/n} + \sqrt{d/nN} + \sqrtα)$, demonstrating that while heterogeneity $α$ represents an inherent statistical difficulty, the influence of adversarial users is suppressed by a factor of $1/\sqrt{n}$ due to the internal averaging afforded by the batch structure.

</details>


### [42] [Fuz-RL: A Fuzzy-Guided Robust Framework for Safe Reinforcement Learning under Uncertainty](https://arxiv.org/abs/2602.20729)
*Xu Wan,Chao Yang,Cheng Yang,Jie Song,Mingyang Sun*

Main category: cs.LG

TL;DR: Fuz-RL是一个基于模糊测度的鲁棒安全强化学习框架，使用Choquet积分估计鲁棒值函数，能有效处理多种不确定性源，避免min-max优化，在安全性和控制性能上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现实环境中多种不确定性源的复杂交互给可解释的风险评估和鲁棒决策带来了重大挑战，需要开发能够有效处理这些挑战的安全强化学习方法。

Method: 提出Fuz-RL框架，开发了基于Choquet积分的新型模糊Bellman算子来估计鲁棒值函数，将问题转化为约束马尔可夫决策过程形式，避免min-max优化。

Result: 在safe-control-gym和safety-gymnasium场景上的实证分析表明，Fuz-RL能够以模型无关的方式与现有安全RL基线有效集成，在观测、动作和动力学等多种不确定性下显著提高了安全性和控制性能。

Conclusion: Fuz-RL通过模糊测度引导的鲁棒框架成功解决了安全强化学习中多源不确定性的挑战，理论证明其等价于分布鲁棒安全RL问题，并在实践中表现出优越的性能。

Abstract: Safe Reinforcement Learning (RL) is crucial for achieving high performance while ensuring safety in real-world applications. However, the complex interplay of multiple uncertainty sources in real environments poses significant challenges for interpretable risk assessment and robust decision-making. To address these challenges, we propose Fuz-RL, a fuzzy measure-guided robust framework for safe RL. Specifically, our framework develops a novel fuzzy Bellman operator for estimating robust value functions using Choquet integrals. Theoretically, we prove that solving the Fuz-RL problem (in Constrained Markov Decision Process (CMDP) form) is equivalent to solving distributionally robust safe RL problems (in robust CMDP form), effectively avoiding min-max optimization. Empirical analyses on safe-control-gym and safety-gymnasium scenarios demonstrate that Fuz-RL effectively integrates with existing safe RL baselines in a model-free manner, significantly improving both safety and control performance under various types of uncertainties in observation, action, and dynamics.

</details>


### [43] [Rethink Efficiency Side of Neural Combinatorial Solver: An Offline and Self-Play Paradigm](https://arxiv.org/abs/2602.20730)
*Zhenxing Xu,Zeyuan Ma,Weidong Bao,Hui Yan,Yan Zheng,Ji Wang*

Main category: cs.LG

TL;DR: ECO是一种高效的离线自学习范式，用于神经组合优化，通过两阶段离线训练、Mamba架构和渐进引导机制，在TSP和CVRP问题上实现了与最新基线竞争的性能，同时显著提升了训练效率和内存利用率。


<details>
  <summary>Details</summary>
Motivation: 解决神经组合优化（NCO）领域中在线学习范式效率低下的问题，提出更高效的离线自学习方案，以降低内存消耗并提升训练吞吐量。

Method: 1）范式转变：采用两阶段离线范式，包括监督预热和迭代直接偏好优化（DPO）；2）架构转变：设计基于Mamba的架构以提升离线范式效率；3）渐进引导：使用启发式引导机制稳定训练，确保策略持续改进。

Result: 在TSP和CVRP问题上，ECO与最新基线表现相当，在内存利用率和训练吞吐量方面具有显著优势。消融研究验证了设计合理性。

Conclusion: ECO为神经组合优化提供了一种高效、内存友好的离线自学习范式，通过范式转变、架构创新和训练稳定机制，在保持性能的同时大幅提升了训练效率。

Abstract: We propose ECO, a versatile learning paradigm that enables efficient offline self-play for Neural Combinatorial Optimization (NCO). ECO addresses key limitations in the field through: 1) Paradigm Shift: Moving beyond inefficient online paradigms, we introduce a two-phase offline paradigm consisting of supervised warm-up and iterative Direct Preference Optimization (DPO); 2) Architecture Shift: We deliberately design a Mamba-based architecture to further enhance the efficiency in the offline paradigm; and 3) Progressive Bootstrapping: To stabilize training, we employ a heuristic-based bootstrapping mechanism that ensures continuous policy improvement during training. Comparison results on TSP and CVRP highlight that ECO performs competitively with up-to-date baselines, with significant advantage on the efficiency side in terms of memory utilization and training throughput. We provide further in-depth analysis on the efficiency, throughput and memory usage of ECO. Ablation studies show rationale behind our designs.

</details>


### [44] [Transcoder Adapters for Reasoning-Model Diffing](https://arxiv.org/abs/2602.20904)
*Nathan Hu,Jake Ward,Thomas Icard,Christopher Potts*

Main category: cs.LG

TL;DR: 该研究提出了一种称为"transcoder adapters"的技术，用于学习模型在微调前后MLP计算差异的可解释近似，并应用于分析推理训练对模型内部机制的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管推理模型越来越普遍，但推理训练对模型内部机制的影响仍然知之甚少。研究者希望开发一种方法来解释推理微调如何改变模型的内部计算。

Method: 提出transcoder adapters技术，学习模型微调前后MLP计算差异的可解释近似。应用于Qwen2.5-Math-7B及其推理蒸馏变体DeepSeek-R1-Distill-Qwen-7B的比较分析，通过归因图等方法研究特定行为。

Result: 学习到的adapters能够忠实反映目标模型的内部计算和下一个token预测。在推理基准测试中，adapters能匹配推理模型的响应长度，通常恢复50-90%的推理微调带来的准确率提升。发现只有约8%的adapter特征与推理行为直接相关，并深入研究了"犹豫token"行为。

Conclusion: transcoder adapters为理解推理训练提供了新视角，并可能成为研究更广泛微调过程的有用工具。研究揭示了推理微调只改变了模型的一小部分特征，这些特征对特定行为（如产生犹豫token）是必要且充分的。

Abstract: While reasoning models are increasingly ubiquitous, the effects of reasoning training on a model's internal mechanisms remain poorly understood. In this work, we introduce transcoder adapters, a technique for learning an interpretable approximation of the difference in MLP computation before and after fine-tuning. We apply transcoder adapters to characterize the differences between Qwen2.5-Math-7B and its reasoning-distilled variant, DeepSeek-R1-Distill-Qwen-7B. Learned adapters are faithful to the target model's internal computation and next-token predictions. When evaluated on reasoning benchmarks, adapters match the reasoning model's response lengths and typically recover 50-90% of the accuracy gains from reasoning fine-tuning. Adapter features are sparsely activating and interpretable. When examining adapter features, we find that only ~8% have activating examples directly related to reasoning behaviors. We deeply study one such behavior -- the production of hesitation tokens (e.g., "wait"). Using attribution graphs, we trace hesitation to only ~2.4% of adapter features (5.6k total) performing one of two functions. These features are necessary and sufficient for producing hesitation tokens; removing them reduces response length, often without affecting accuracy. Overall, our results provide insight into reasoning training and suggest transcoder adapters may be useful for studying fine-tuning more broadly.

</details>


### [45] [From Isolation to Integration: Building an Adaptive Expert Forest for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2602.20911)
*Ruiqi Liu,Boyu Diao,Hangda Liu,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.LG

TL;DR: SAEF是一种新的类增量学习方法，通过将适配器组织成结构化层次来改善知识共享，实现更好的新类学习同时避免旧类遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有的类增量学习方法通常冻结预训练模型并为每个任务训练轻量级适配器，这种方法虽然防止了遗忘，但将学习到的知识视为简单的、非结构化的集合，未能利用任务之间的关系。

Method: 提出语义引导的自适应专家森林（SAEF）方法：首先基于语义关系将任务分组为概念簇；然后在每个簇内，通过合并相似任务的适配器构建平衡的专家树；推理时，为给定输入找到并激活森林中的相关专家集；最终预测通过组合这些激活专家的输出，并根据每个专家的置信度加权得到。

Result: 在多个基准数据集上的实验表明，SAEF达到了最先进的性能。

Conclusion: SAEF通过结构化组织适配器层次，有效利用了任务间的语义关系，实现了更好的知识共享和类增量学习性能。

Abstract: Class-Incremental Learning (CIL) requires models to learn new classes without forgetting old ones. A common method is to freeze a pre-trained model and train a new, lightweight adapter for each task. While this prevents forgetting, it treats the learned knowledge as a simple, unstructured collection and fails to use the relationships between tasks. To this end, we propose the Semantic-guided Adaptive Expert Forest (SAEF), a new method that organizes adapters into a structured hierarchy for better knowledge sharing. SAEF first groups tasks into conceptual clusters based on their semantic relationships. Then, within each cluster, it builds a balanced expert tree by creating new adapters from merging the adapters of similar tasks. At inference time, SAEF finds and activates a set of relevant experts from the forest for any given input. The final prediction is made by combining the outputs of these activated experts, weighted by how confident each expert is. Experiments on several benchmark datasets show that SAEF achieves SOTA performance.

</details>


### [46] [Hierarchic-EEG2Text: Assessing EEG-To-Text Decoding across Hierarchical Abstraction Levels](https://arxiv.org/abs/2602.20932)
*Anupam Sharma,Harish Katti,Prajwal Singh,Shanmuganathan Raman,Krishna Miyapuram*

Main category: cs.LG

TL;DR: 该研究探索脑电图（EEG）是否能在多个层次级别上捕获物体表征，提出使用WordNet进行层次感知的片段采样方法，在PEERS数据集上构建了最大的EEG片段分析框架，发现分类类别来自更高层次时模型性能更好。


<details>
  <summary>Details</summary>
Motivation: EEG信号信噪比低，识别大量类别中的细粒度表征具有挑战性，但可能存在抽象级别的物体表征。研究旨在探索EEG是否能在多个层次级别上捕获物体表征，并研究语义抽象级别如何影响分类性能。

Method: 提出片段分析框架，使用WordNet进行层次感知的片段采样，生成具有可变类别和不同层次的片段。在PEERS数据集（包含264名参与者的931,538个EEG样本，1610个物体标签）上构建最大的EEG片段分析框架，研究神经动态。

Result: 模型在分类类别来自更高层次时性能更好，表明对抽象级别的敏感性。研究揭示了抽象深度作为EEG解码中未被充分探索的维度。

Conclusion: EEG能够捕获多个层次级别的物体表征，抽象深度是影响EEG解码性能的重要因素，为未来研究提供了新的方向。

Abstract: An electroencephalogram (EEG) records the spatially averaged electrical activity of neurons in the brain, measured from the human scalp. Prior studies have explored EEG-based classification of objects or concepts, often for passive viewing of briefly presented image or video stimuli, with limited classes. Because EEG exhibits a low signal-to-noise ratio, recognizing fine-grained representations across a large number of classes remains challenging; however, abstract-level object representations may exist. In this work, we investigate whether EEG captures object representations across multiple hierarchical levels, and propose episodic analysis, in which a Machine Learning (ML) model is evaluated across various, yet related, classification tasks (episodes). Unlike prior episodic EEG studies that rely on fixed or randomly sampled classes of equal cardinality, we adopt hierarchy-aware episode sampling using WordNet to generate episodes with variable classes of diverse hierarchy. We also present the largest episodic framework in the EEG domain for detecting observed text from EEG signals in the PEERS dataset, comprising $931538$ EEG samples under $1610$ object labels, acquired from $264$ human participants (subjects) performing controlled cognitive tasks, enabling the study of neural dynamics underlying perception, decision-making, and performance monitoring.
  We examine how the semantic abstraction level affects classification performance across multiple learning techniques and architectures, providing a comprehensive analysis. The models tend to improve performance when the classification categories are drawn from higher levels of the hierarchy, suggesting sensitivity to abstraction. Our work highlights abstraction depth as an underexplored dimension of EEG decoding and motivates future research in this direction.

</details>


### [47] [Extending $μ$P: Spectral Conditions for Feature Learning Across Optimizers](https://arxiv.org/abs/2602.20937)
*Akshita Gupta,Marieme Ngom,Sam Foreman,Venkatram Vishwanath*

Main category: cs.LG

TL;DR: 该论文提出了一种基于谱条件的新框架，用于推导更广泛优化器的最大更新参数化(μP)，实现了跨模型宽度的零学习率迁移。


<details>
  <summary>Details</summary>
Motivation: 现有μP方法主要适用于SGD和Adam，但难以扩展到其他优化器，因为张量编程方法难以理解。需要一种更通用的框架来为各种优化器推导μP规则，从而减少大规模模型训练的超参数调优成本。

Method: 基于谱条件替代张量编程的方法，提出新框架来推导μP规则。该框架适用于AdamW、ADOPT、LAMB、Sophia、Shampoo和Muon等多种优化器。在多个基准模型上实现μP推导，并进行零学习率迁移实验。

Result: 成功实现了上述优化器的μP推导，并在跨模型宽度上展示了零学习率迁移能力。同时提供了这些优化器深度缩放参数化的经验见解。

Conclusion: 提出的基于谱条件的新框架能够为更广泛的优化器推导μP规则，有效减少大规模模型训练的超参数调优成本，实现从小模型到大模型的超参数迁移。

Abstract: Several variations of adaptive first-order and second-order optimization methods have been proposed to accelerate and scale the training of large language models. The performance of these optimization routines is highly sensitive to the choice of hyperparameters (HPs), which are computationally expensive to tune for large-scale models. Maximal update parameterization $(μ$P$)$ is a set of scaling rules which aims to make the optimal HPs independent of the model size, thereby allowing the HPs tuned on a smaller (computationally cheaper) model to be transferred to train a larger, target model. Despite promising results for SGD and Adam, deriving $μ$P for other optimizers is challenging because the underlying tensor programming approach is difficult to grasp. Building on recent work that introduced spectral conditions as an alternative to tensor programs, we propose a novel framework to derive $μ$P for a broader class of optimizers, including AdamW, ADOPT, LAMB, Sophia, Shampoo and Muon. We implement our $μ$P derivations on multiple benchmark models and demonstrate zero-shot learning rate transfer across increasing model width for the above optimizers. Further, we provide empirical insights into depth-scaling parameterization for these optimizers.

</details>


### [48] [Estimation of Confidence Bounds in Binary Classification using Wilson Score Kernel Density Estimation](https://arxiv.org/abs/2602.20947)
*Thorbjørn Mosekjær Iversen,Zebin Duan,Frederik Hagelskjær*

Main category: cs.LG

TL;DR: 提出Wilson Score核密度分类方法，用于二元分类中的置信区间估计，在选择性分类任务中表现与高斯过程分类相当但计算复杂度更低。


<details>
  <summary>Details</summary>
Motivation: 深度学习二元分类器性能提升使其可用于关键检测任务，但这些关键应用需要可靠的置信区间估计以确保系统性能达到特定统计显著性水平。

Method: 提出Wilson Score核密度分类方法，核心是Wilson Score核密度估计器，用于估计条件变化成功概率的二项实验中的置信区间。该方法可作为任何特征提取器（包括视觉基础模型）的分类头。

Result: 在四个不同数据集的选择性分类任务中评估，与高斯过程分类性能相当，但计算复杂度更低。

Conclusion: Wilson Score核密度分类为二元分类中的置信区间估计提供了一种有效方法，在保持性能的同时降低了计算复杂度，适用于关键检测任务。

Abstract: The performance and ease of use of deep learning-based binary classifiers have improved significantly in recent years. This has opened up the potential for automating critical inspection tasks, which have traditionally only been trusted to be done manually. However, the application of binary classifiers in critical operations depends on the estimation of reliable confidence bounds such that system performance can be ensured up to a given statistical significance. We present Wilson Score Kernel Density Classification, which is a novel kernel-based method for estimating confidence bounds in binary classification. The core of our method is the Wilson Score Kernel Density Estimator, which is a function estimator for estimating confidence bounds in Binomial experiments with conditionally varying success probabilities. Our method is evaluated in the context of selective classification on four different datasets, illustrating its use as a classification head of any feature extractor, including vision foundation models. Our proposed method shows similar performance to Gaussian Process Classification, but at a lower computational complexity.

</details>


### [49] [Does Order Matter : Connecting The Law of Robustness to Robust Generalization](https://arxiv.org/abs/2602.20971)
*Himadri Mandal,Vishnu Varadarajan,Jaee Ponde,Aritra Das,Mihir More,Debayan Gupta*

Main category: cs.LG

TL;DR: 该论文解决了Bubeck和Sellke提出的鲁棒性定律与鲁棒泛化之间的开放问题，建立了两者的理论联系，并通过实验验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 解决Bubeck和Sellke提出的开放问题：建立鲁棒性定律与鲁棒泛化之间的理论联系。鲁棒性定律指出过参数化是实现鲁棒插值的必要条件，而鲁棒泛化关注小鲁棒训练损失是否能保证小鲁棒测试损失。

Method: 引入非平凡的鲁棒泛化误差概念，将其转化为诱导鲁棒损失类的期望Rademacher复杂度的下界。该方法能够恢复Wu等人提出的Ω(n^{1/d})机制，并证明鲁棒泛化不会改变平滑插值所需的Lipschitz常数的阶数。

Result: 理论分析表明，为获得低鲁棒泛化误差，Lipschitz常数必须位于一个有界的范围内，且允许的扰动半径与Lipschitz尺度相关。在MNIST上的实验发现，下界Lipschitz常数的缩放顺序与Wu等人的预测一致。

Conclusion: 成功解决了鲁棒性定律与鲁棒泛化之间的开放问题，建立了理论联系并提供了实验验证。研究显示鲁棒泛化不会改变平滑插值所需的Lipschitz常数的阶数，为理解鲁棒学习提供了新的理论视角。

Abstract: Bubeck and Sellke (2021) pose as an open problem the connection between the law of robustness and robust generalization. The law of robustness states that overparameterization is necessary for models to interpolate robustly; in particular, robust interpolation requires the learned function to be Lipschitz. Robust generalization asks whether small robust training loss implies small robust test loss. We resolve this problem by explicitly connecting the two for arbitrary data distributions. Specifically, we introduce a nontrivial notion of robust generalization error and convert it into a lower bound on the expected Rademacher complexity of the induced robust loss class. Our bounds recover the $Ω(n^{1/d})$ regime of Wu et al.\ (2023) and show that, up to constants, robust generalization does not change the order of the Lipschitz constant required for smooth interpolation. We conduct experiments to probe the predicted scaling with dataset size and model capacity, testing whether empirical behavior aligns more closely with the predictions of Bubeck and Sellke (2021) or Wu et al.\ (2023). For MNIST, we find that the lower-bound Lipschitz constant scales on the order predicted by Wu et al.\ (2023). Informally, to obtain low robust generalization error, the Lipschitz constant must lie in a range that we bound, and the allowable perturbation radius is linked to the Lipschitz scale.

</details>


### [50] [Matching Multiple Experts: On the Exploitability of Multi-Agent Imitation Learning](https://arxiv.org/abs/2602.21020)
*Antoine Bergerault,Volkan Cevher,Negar Mehr*

Main category: cs.LG

TL;DR: 多智能体模仿学习在离线设置下难以保证学习到的策略接近纳什均衡，本文展示了不可能性和困难性结果，但在专家均衡具有战略优势假设下，可以克服这些挑战并获得纳什模仿差距的界限。


<details>
  <summary>Details</summary>
Motivation: 现有离线多智能体模仿学习虽然能保证学习策略的性能，但缺乏对学习策略与纳什均衡之间距离的刻画，需要填补这一理论空白。

Method: 首先展示一般n人马尔可夫博弈中学习低可剥削策略的不可能性和困难性结果，包括精确度量匹配失败的例子和固定度量匹配误差下刻画纳什差距的困难性证明。然后引入战略优势假设（主导策略专家均衡），使用行为克隆误差ε_BC，推导出纳什模仿差距界限。最后推广到新的最佳响应连续性概念。

Result: 对于主导策略专家均衡情况，假设行为克隆误差ε_BC，获得了纳什模仿差距为O(nε_BC/(1-γ)^2)的界限，其中γ为折扣因子。通过最佳响应连续性概念推广了这一结果，并论证标准正则化技术隐式鼓励这种连续性。

Conclusion: 离线多智能体模仿学习在一般情况下难以保证学习策略接近纳什均衡，但在专家均衡具有战略优势的合理假设下，可以获得理论保证。最佳响应连续性为分析提供了新框架，且与现有正则化技术兼容。

Abstract: Multi-agent imitation learning (MA-IL) aims to learn optimal policies from expert demonstrations of interactions in multi-agent interactive domains. Despite existing guarantees on the performance of the resulting learned policies, characterizations of how far the learned polices are from a Nash equilibrium are missing for offline MA-IL. In this paper, we demonstrate impossibility and hardness results of learning low-exploitable policies in general $n$-player Markov Games. We do so by providing examples where even exact measure matching fails, and demonstrating a new hardness result on characterizing the Nash gap given a fixed measure matching error. We then show how these challenges can be overcome using strategic dominance assumptions on the expert equilibrium. Specifically, for the case of dominant strategy expert equilibria, assuming Behavioral Cloning error $ε_{\text{BC}}$, this provides a Nash imitation gap of $\mathcal{O}\left(nε_{\text{BC}}/(1-γ)^2\right)$ for a discount factor $γ$. We generalize this result with a new notion of best-response continuity, and argue that this is implicitly encouraged by standard regularization techniques.

</details>


### [51] [SELAUR: Self Evolving LLM Agent via Uncertainty-aware Rewards](https://arxiv.org/abs/2602.21158)
*Dengjia Zhang,Xiaoou Liu,Lu Cheng,Yaqing Wang,Kenton Murray,Hua Wei*

Main category: cs.LG

TL;DR: SELAUR是一个通过不确定性感知奖励实现自我进化的LLM智能体强化学习框架，将LLM的内在不确定性融入奖励设计，在ALFWorld和WebShop基准测试中显著提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为多步决策智能体部署时，奖励设计对指导学习至关重要。虽然已有研究探索了各种奖励塑造和步级信用分配方法，但LLM的内在不确定性这一关键信号在很大程度上被忽视了。不确定性反映了模型置信度，揭示了需要探索的区域，即使在失败轨迹中也提供了有价值的学习线索。

Method: SELAUR框架将不确定性直接融入奖励设计：1）整合基于熵、最小置信度和边界的指标，形成组合的令牌级不确定性估计，提供密集的置信度对齐监督；2）采用失败感知的奖励重塑机制，将这些不确定性信号注入步级和轨迹级奖励，以提高探索效率和学习稳定性。

Result: 在ALFWorld和WebShop两个基准测试上的实验表明，该方法相对于强基线模型持续提高了成功率。消融研究进一步证明了不确定性信号如何增强探索能力和鲁棒性。

Conclusion: SELAUR通过将LLM的内在不确定性融入奖励设计，为LLM智能体的强化学习提供了一个有效的框架。不确定性信号不仅提高了探索效率和学习稳定性，还在失败轨迹中提供了有价值的学习线索，最终显著提升了智能体的性能表现。

Abstract: Large language models (LLMs) are increasingly deployed as multi-step decision-making agents, where effective reward design is essential for guiding learning. Although recent work explores various forms of reward shaping and step-level credit assignment, a key signal remains largely overlooked: the intrinsic uncertainty of LLMs. Uncertainty reflects model confidence, reveals where exploration is needed, and offers valuable learning cues even in failed trajectories. We introduce SELAUR: Self Evolving LLM Agent via Uncertainty-aware Rewards, a reinforcement learning framework that incorporates uncertainty directly into the reward design. SELAUR integrates entropy-, least-confidence-, and margin-based metrics into a combined token-level uncertainty estimate, providing dense confidence-aligned supervision, and employs a failure-aware reward reshaping mechanism that injects these uncertainty signals into step- and trajectory-level rewards to improve exploration efficiency and learning stability. Experiments on two benchmarks, ALFWorld and WebShop, show that our method consistently improves success rates over strong baselines. Ablation studies further demonstrate how uncertainty signals enhance exploration and robustness.

</details>


### [52] [Sequential Counterfactual Inference for Temporal Clinical Data: Addressing the Time Traveler Dilemma](https://arxiv.org/abs/2602.21168)
*Jingya Cheng,Alaleh Azhir,Jiazi Tian,Hossein Estiri*

Main category: cs.LG

TL;DR: 该论文提出了序列反事实框架，用于处理纵向临床数据中的时间依赖性，区分不可变特征和可控特征，避免传统方法中违反生物学可能性的反事实推断。


<details>
  <summary>Details</summary>
Motivation: 传统反事实推断方法假设特征独立和同时可修改性，但这些假设在纵向临床数据中不成立，导致产生生物学上不可能的反事实结果，限制了临床应用的实用性。

Method: 提出序列反事实框架，区分不可变特征（如慢性诊断）和可控特征（如实验室数值），建模干预措施随时间传播的机制，尊重电子健康记录中的时间依赖性。

Result: 应用于2,723名COVID-19患者（383例长新冠心力衰竭病例，2,340名匹配对照），发现38-67%慢性病患者在传统方法下需要生物学上不可能的反事实。识别出心肾级联（CKD -> AKI -> HF），相对风险分别为2.27和1.19，展示了序列反事实能捕捉的时间传播效应。

Conclusion: 该框架将反事实解释从"如果这个特征不同会怎样？"转变为"如果我们更早干预会怎样，以及这会如何向前传播？"，提供了基于生物学合理性的临床可行见解。

Abstract: Counterfactual inference enables clinicians to ask "what if" questions about patient outcomes, but standard methods assume feature independence and simultaneous modifiability -- assumptions violated by longitudinal clinical data. We introduce the Sequential Counterfactual Framework, which respects temporal dependencies in electronic health records by distinguishing immutable features (chronic diagnoses) from controllable features (lab values) and modeling how interventions propagate through time. Applied to 2,723 COVID-19 patients (383 Long COVID heart failure cases, 2,340 matched controls), we demonstrate that 38-67% of patients with chronic conditions would require biologically impossible counterfactuals under naive methods. We identify a cardiorenal cascade (CKD -> AKI -> HF) with relative risks of 2.27 and 1.19 at each step, illustrating temporal propagation that sequential -- but not naive -- counterfactuals can capture. Our framework transforms counterfactual explanation from "what if this feature were different?" to "what if we had intervened earlier, and how would that propagate forward?" --  yielding clinically actionable insights grounded in biological plausibility.

</details>


### [53] [The Diffusion Duality, Chapter II: $Ψ$-Samplers and Efficient Curriculum](https://arxiv.org/abs/2602.21185)
*Justin Deschenaux,Caglar Gulcehre,Subham Sekhar Sahoo*

Main category: cs.LG

TL;DR: 本文提出了一种用于离散扩散模型的预测器-校正器采样器家族，该采样器能持续改进采样质量，并开发了高效训练课程，在语言和图像建模任务上均优于传统采样方法。


<details>
  <summary>Details</summary>
Motivation: 均匀状态离散扩散模型在少步生成和引导方面表现出色，但使用祖先采样器时，随着步数增加采样质量会达到平台期。需要开发能持续改进的采样方法，并质疑掩码扩散是否是扩散式语言建模的必然未来。

Method: 1. 提出预测器-校正器采样器家族，适用于任意噪声过程，能推广先前方法；2. 与均匀状态扩散结合使用；3. 开发内存高效的训练课程，减少高斯松弛训练阶段的训练时间和内存消耗。

Result: 1. 在OpenWebText上实现更低的生成困惑度（在匹配的单字熵下）；2. 在CIFAR10上获得更好的FID/IS分数；3. 预测器-校正器方法能随采样步数增加持续改进；4. 训练时间减少25%，内存减少33%，同时保持可比的困惑度和下游性能。

Conclusion: 预测器-校正器采样器在离散扩散模型中显著优于祖先采样，其持续改进能力挑战了掩码扩散作为扩散式语言建模必然未来的假设。同时，高效训练课程为实际应用提供了重要改进。

Abstract: Uniform-state discrete diffusion models excel at few-step generation and guidance due to their ability to self-correct, making them preferred over autoregressive or Masked diffusion models in these settings. However, their sampling quality plateaus with ancestral samplers as the number of steps increases. We introduce a family of Predictor-Corrector (PC) samplers for discrete diffusion that generalize prior methods and apply to arbitrary noise processes. When paired with uniform-state diffusion, our samplers outperform ancestral sampling on both language and image modeling, achieving lower generative perplexity at matched unigram entropy on OpenWebText and better FID/IS scores on CIFAR10. Crucially, unlike conventional samplers, our PC methods continue to improve with more sampling steps. Taken together, these findings call into question the assumption that Masked diffusion is the inevitable future of diffusion-based language modeling. Beyond sampling, we develop a memory-efficient curriculum for the Gaussian relaxation training phase, reducing training time by 25% and memory by 33% compared to Duo while maintaining comparable perplexity on OpenWebText and LM1B and strong downstream performance. We release code, checkpoints, and a video-tutorial on: https://s-sahoo.com/duo-ch2

</details>


### [54] [Why Pass@k Optimization Can Degrade Pass@1: Prompt Interference in LLM Post-training](https://arxiv.org/abs/2602.21189)
*Anas Barakat,Souradip Chakraborty,Khushbu Pahwa,Amrit Singh Bedi*

Main category: cs.LG

TL;DR: 论文研究了在可验证大语言模型任务中，pass@k优化与pass@1性能下降之间的权衡问题，从理论上分析了这种冲突的根源。


<details>
  <summary>Details</summary>
Motivation: pass@k是广泛使用的性能指标，但现有研究发现一个反复出现的权衡：pass@k优化时pass@1性能会下降。这在实践中很重要，因为pass@1通常由于延迟、成本、验证器覆盖范围有限以及需要可靠的单次回退而成为硬性约束。

Method: 通过理论分析pass@k策略梯度与pass@1梯度之间的冲突，研究提示干扰如何导致这种权衡。具体分析了pass@k优化如何隐式地对低成功率提示进行重加权，以及当这些提示具有负干扰时，如何使pass@k更新方向偏离pass@1方向。

Result: 理论分析表明，pass@k策略梯度可能与pass@1梯度冲突，因为pass@k优化会隐式地将提示重加权向低成功率提示；当这些提示具有负干扰特性时，它们的权重增加会使pass@k更新方向偏离pass@1方向。在可验证数学推理任务的大语言模型实验中验证了理论发现。

Conclusion: 论文揭示了pass@k优化与pass@1性能下降之间权衡的理论机制，为理解多样本推理指标优化中的梯度冲突提供了理论框架，对实际应用中平衡不同性能指标具有指导意义。

Abstract: Pass@k is a widely used performance metric for verifiable large language model tasks, including mathematical reasoning, code generation, and short-answer reasoning. It defines success if any of $k$ independently sampled solutions passes a verifier. This multi-sample inference metric has motivated inference-aware fine-tuning methods that directly optimize pass@$k$. However, prior work reports a recurring trade-off: pass@k improves while pass@1 degrades under such methods. This trade-off is practically important because pass@1 often remains a hard operational constraint due to latency and cost budgets, imperfect verifier coverage, and the need for a reliable single-shot fallback. We study the origin of this trade-off and provide a theoretical characterization of when pass@k policy optimization can reduce pass@1 through gradient conflict induced by prompt interference. We show that pass@$k$ policy gradients can conflict with pass@1 gradients because pass@$k$ optimization implicitly reweights prompts toward low-success prompts; when these prompts are what we term negatively interfering, their upweighting can rotate the pass@k update direction away from the pass@1 direction. We illustrate our theoretical findings with large language model experiments on verifiable mathematical reasoning tasks.

</details>


### [55] [Statistical Query Lower Bounds for Smoothed Agnostic Learning](https://arxiv.org/abs/2602.21191)
*Ilias Diakonikolas,Daniel M. Kane*

Main category: cs.LG

TL;DR: 该论文研究了平滑不可知学习半空间的复杂度，证明了现有基于L1多项式回归的上界接近最优，并给出了首个非平凡的下界。


<details>
  <summary>Details</summary>
Motivation: 研究平滑不可知学习（特别是半空间学习）的计算复杂度，现有上界为d^{Õ(1/σ²)log(1/ε)}，需要验证这个上界是否接近最优。

Method: 使用统计查询(SQ)下界技术，通过线性规划对偶找到矩匹配的困难分布，该对偶问题等价于寻找目标函数平滑版本的低度近似多项式。

Result: 证明了任何SQ算法都需要复杂度d^{Ω(1/σ²+log(1/ε))}，这接近已知上界，表明L1多项式回归方法基本是最优的。

Conclusion: 这是首个关于平滑不可知学习半空间复杂度的非平凡下界，证明了现有上界接近最优，为理解该问题的计算复杂度提供了重要理论依据。

Abstract: We study the complexity of smoothed agnostic learning, recently introduced by~\cite{CKKMS24}, in which the learner competes with the best classifier in a target class under slight Gaussian perturbations of the inputs. Specifically, we focus on the prototypical task of agnostically learning halfspaces under subgaussian distributions in the smoothed model. The best known upper bound for this problem relies on $L_1$-polynomial regression and has complexity $d^{\tilde{O}(1/σ^2) \log(1/ε)}$, where $σ$ is the smoothing parameter and $ε$ is the excess error. Our main result is a Statistical Query (SQ) lower bound providing formal evidence that this upper bound is close to best possible. In more detail, we show that (even for Gaussian marginals) any SQ algorithm for smoothed agnostic learning of halfspaces requires complexity $d^{Ω(1/σ^{2}+\log(1/ε))}$. This is the first non-trivial lower bound on the complexity of this task and nearly matches the known upper bound. Roughly speaking, we show that applying $L_1$-polynomial regression to a smoothed version of the function is essentially best possible. Our techniques involve finding a moment-matching hard distribution by way of linear programming duality. This dual program corresponds exactly to finding a low-degree approximating polynomial to the smoothed version of the target function (which turns out to be the same condition required for the $L_1$-polynomial regression to work). Our explicit SQ lower bound then comes from proving lower bounds on this approximation degree for the class of halfspaces.

</details>


### [56] [Untied Ulysses: Memory-Efficient Context Parallelism via Headwise Chunking](https://arxiv.org/abs/2602.21196)
*Ravi Ghadia,Maksim Abraham,Sergei Vorobyov,Max Ryabinin*

Main category: cs.LG

TL;DR: UPipe是一种新型上下文并行技术，通过注意力头级别的细粒度分块，显著降低自注意力层的激活内存使用，支持更长的序列长度训练


<details>
  <summary>Details</summary>
Motivation: 现有的上下文并行方法（如Ring Attention、DeepSpeed Ulysses）虽然能在上下文维度上进行扩展，但内存效率不足，限制了支持的序列长度。更先进的技术（如完全流水线分布式Transformer或激活卸载）虽然能进一步扩展上下文长度，但会牺牲训练吞吐量

Method: UPipe采用注意力头级别的细粒度分块技术，在自注意力层进行精细的内存优化，显著减少中间张量的内存使用

Result: 对于32B Transformer模型，UPipe将注意力层中间张量的内存使用减少了87.5%，同时保持与先前上下文并行技术相当的训练速度。在单个8×H100节点上训练Llama3-8B时，支持500万token的上下文长度，比先前方法提升超过25%

Conclusion: UPipe通过注意力头级别的细粒度分块，有效突破了激活内存瓶颈，在保持训练速度的同时显著扩展了可支持的上下文长度，为处理超长序列提供了高效的内存优化解决方案

Abstract: Efficiently processing long sequences with Transformer models usually requires splitting the computations across accelerators via context parallelism. The dominant approaches in this family of methods, such as Ring Attention or DeepSpeed Ulysses, enable scaling over the context dimension but do not focus on memory efficiency, which limits the sequence lengths they can support. More advanced techniques, such as Fully Pipelined Distributed Transformer or activation offloading, can further extend the possible context length at the cost of training throughput. In this paper, we present UPipe, a simple yet effective context parallelism technique that performs fine-grained chunking at the attention head level. This technique significantly reduces the activation memory usage of self-attention, breaking the activation memory barrier and unlocking much longer context lengths. Our approach reduces intermediate tensor memory usage in the attention layer by as much as 87.5$\%$ for 32B Transformers, while matching previous context parallelism techniques in terms of training speed. UPipe can support the context length of 5M tokens when training Llama3-8B on a single 8$\times$H100 node, improving upon prior methods by over 25$\%$.

</details>


### [57] [Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs](https://arxiv.org/abs/2602.21198)
*Yining Hong,Huang Huang,Manling Li,Li Fei-Fei,Jiajun Wu,Yejin Choi*

Main category: cs.LG

TL;DR: 论文提出反射测试时间规划方法，通过行动中反思和行动后反思两种模式，让具身LLM机器人能够从错误中学习积累经验，而不是重复犯错。


<details>
  <summary>Details</summary>
Motivation: 当前具身LLM虽然赋予机器人高级任务推理能力，但缺乏反思机制，导致部署过程变成一系列独立试验，错误重复发生而无法积累成经验。受人类反思实践者启发，需要让机器人具备反思能力。

Method: 提出反射测试时间规划，包含两种反思模式：1）行动中反思：使用测试时间缩放生成和评分多个候选动作，在执行前进行内部反思；2）行动后反思：使用测试时间训练，基于执行后的外部反思更新内部反思模型和动作策略。还包括回顾性反思，允许重新评估早期决策并进行后见之明的模型更新。

Result: 在新设计的长期家庭基准和MuJoCo橱柜装配基准上的实验显示，相比基线模型有显著提升。消融研究验证了行动中反思和行动后反思的互补作用。定性分析（包括真实机器人试验）展示了通过反思实现的行为修正。

Conclusion: 反射测试时间规划使具身LLM能够从经验中学习，将错误转化为学习机会，显著提升了长期任务规划的性能，为机器人学习提供了新的反思框架。

Abstract: Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: \textit{reflection-in-action}, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflections before execution; and \textit{reflection-on-action}, which uses test-time training to update both its internal reflection model and its action policy based on external reflections after execution. We also include retrospective reflection, allowing the agent to re-evaluate earlier decisions and perform model updates with hindsight for proper long-horizon credit assignment. Experiments on our newly-designed Long-Horizon Household benchmark and MuJoCo Cupboard Fitting benchmark show significant gains over baseline models, with ablative studies validating the complementary roles of reflection-in-action and reflection-on-action. Qualitative analyses, including real-robot trials, highlight behavioral correction through reflection.

</details>


### [58] [Test-Time Training with KV Binding Is Secretly Linear Attention](https://arxiv.org/abs/2602.21204)
*Junchen Liu,Sven Elflein,Or Litany,Zan Gojcic,Ruilong Li*

Main category: cs.LG

TL;DR: 论文挑战了测试时训练（TTT）作为记忆化在线元学习的传统解释，提出TTT实际上是一种学习到的线性注意力算子，这一新视角能解释异常现象并带来架构简化、并行化和效率提升等实际好处。


<details>
  <summary>Details</summary>
Motivation: 传统上，基于KV绑定的测试时训练被解释为在线元学习，通过记忆键值映射来适应测试数据。但作者观察到多个与这种记忆化解释相矛盾的现象，促使他们重新审视TTT的数学本质。

Method: 作者重新形式化TTT，证明一大类TTT架构可以表达为学习到的线性注意力算子。通过这种视角，他们实现了架构简化、开发了完全并行的实现方案，并将多种TTT变体系统性地归约为标准线性注意力形式。

Result: 新框架成功解释了之前令人困惑的模型行为，实现了性能保持下的效率提升，并为不同TTT变体提供了统一的数学基础。实验表明并行化方案在保持性能的同时显著提高了效率。

Conclusion: TTT不应被理解为测试时记忆化，而应视为具有增强表示能力的学习线性注意力。这一新视角不仅提供了更准确的数学解释，还带来了实际的架构改进和效率优化。

Abstract: Test-time training (TTT) with KV binding as sequence modeling layer is commonly interpreted as a form of online meta-learning that memorizes a key-value mapping at test time. However, our analysis reveals multiple phenomena that contradict this memorization-based interpretation. Motivated by these findings, we revisit the formulation of TTT and show that a broad class of TTT architectures can be expressed as a form of learned linear attention operator. Beyond explaining previously puzzling model behaviors, this perspective yields multiple practical benefits: it enables principled architectural simplifications, admits fully parallel formulations that preserve performance while improving efficiency, and provides a systematic reduction of diverse TTT variants to a standard linear attention form. Overall, our results reframe TTT not as test-time memorization, but as learned linear attention with enhanced representational capacity.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [59] [Playsemble: Learning Low-Level Programming Through Interactive Games](https://arxiv.org/abs/2602.20167)
*Elliott Wen,Paul Denny,Andrew Luxton-Reilly,Sean Ma,Bruce Sham,Chenye Ni,Jun Seo,Yu Yang*

Main category: cs.CY

TL;DR: Playsemble是一个游戏化的汇编学习系统，将汇编指令转化为Pac-Man游戏任务，通过浏览器环境提供代码编辑、CPU模拟和可视化调试工具，结合LLM即时反馈，提升学生参与度和概念理解。


<details>
  <summary>Details</summary>
Motivation: 汇编编程教学是计算机科学本科教育的基础，但许多学生难以理解其抽象和底层概念。现有的学习工具如模拟器和可视化工具主要支持被动观察，缺乏有意义的互动机会。

Method: 开发Playsemble游戏化学习系统，将汇编指令转化为Pac-Man游戏任务（收集物品、躲避幽灵、到达目标）。系统集成代码编辑器、CPU模拟器和可视化调试工具，基于浏览器环境无需安装，并提供基于大语言模型的即时反馈。

Result: 在107名本科生的计算机架构课程中部署Playsemble，包含逐步复杂的作业序列，涵盖寄存器内存操作、控制结构（循环和条件）、算术运算等核心概念。结果表明系统促进了主动实验、持续参与和更深层次的概念理解。

Conclusion: Playsemble通过有意义的游戏化学习体验，有效解决了汇编编程教学中的互动不足问题，提升了学生的学习效果和参与度。

Abstract: Teaching assembly programming is a fundamental component of undergraduate computer science education, yet many students struggle with its abstract and low-level concepts. Existing learning tools, such as simulators and visualisers, support understanding by exposing machine states. However, they often limit students to passive observation and provide few opportunities for meaningful interaction. To address these limitations, we introduce Playsemble, a gamified learning system that transforms assembly instructions into interactive, game-like tasks in which students control Pac-Man to collect items, avoid ghosts, and reach targets. Playsemble integrates a code editor, a CPU emulator, and visual debugging tools within a browser-based environment, allowing students to work offline without installation or configuration. It also provides immediate formative feedback enhanced by large language models. We deployed Playsemble in an undergraduate computer architecture course with 107 students. The course featured a sequence of assignments of increasing complexity, covering core concepts such as register and memory manipulation, control structures including loops and conditionals, and arithmetic operations. Our findings suggest that Playsemble promotes active experimentation, sustained engagement, and deeper conceptual understanding through meaningful game-based learning experiences.

</details>


### [60] [Benchmarking Early Deterioration Prediction Across Hospital-Rich and MCI-Like Emergency Triage Under Constrained Sensing](https://arxiv.org/abs/2602.20168)
*KMA Solaiman,Joshua Sebastian,Karma Tobden*

Main category: cs.CY

TL;DR: 该研究提出了一个泄漏感知的基准测试框架，用于评估早期恶化预测模型在真实时间限制条件下的性能，发现仅使用生命体征数据时预测性能下降有限，呼吸和氧合测量是最重要的风险分层指标。


<details>
  <summary>Details</summary>
Motivation: 急诊分诊决策通常在严重信息约束下进行，但大多数数据驱动的恶化模型都使用了初始评估时不可用的信号进行评估。需要建立一个临床基础的基准来支持在资源受限环境中可部署分诊决策支持系统的评估和设计。

Method: 使用从MIMIC-IV-ED衍生的去重患者队列，比较医院丰富分诊与仅使用生命体征的MCI样设置，将输入限制在就诊后第一小时内可用的信息。采用结构化消融和可解释性分析来识别最重要的风险分层指标。

Result: 在多种建模方法中，当仅限于生命体征时，预测性能仅适度下降，表明早期生理测量保留了重要的临床信号。呼吸和氧合测量被确定为早期风险分层的最有影响力的贡献因素，模型在感知减少时表现出稳定、优雅的性能下降。

Conclusion: 这项工作为支持在资源受限环境中可部署分诊决策支持系统的评估和设计提供了一个临床基础的基准，表明早期生理测量在信息受限条件下仍然具有重要的临床价值。

Abstract: Emergency triage decisions are made under severe information constraints, yet most data-driven deterioration models are evaluated using signals unavailable during initial assessment. We present a leakage-aware benchmarking framework for early deterioration prediction that evaluates model performance under realistic, time-limited sensing conditions. Using a patient-deduplicated cohort derived from MIMIC-IV-ED, we compare hospital-rich triage with a vitals-only, MCI-like setting, restricting inputs to information available within the first hour of presentation. Across multiple modeling approaches, predictive performance declines only modestly when limited to vitals, indicating that early physiological measurements retain substantial clinical signal. Structured ablation and interpretability analyses identify respiratory and oxygenation measures as the most influential contributors to early risk stratification, with models exhibiting stable, graceful degradation as sensing is reduced. This work provides a clinically grounded benchmark to support the evaluation and design of deployable triage decision-support systems in resource-constrained settings.

</details>


### [61] [CAGE: A Framework for Culturally Adaptive Red-Teaming Benchmark Generation](https://arxiv.org/abs/2602.20170)
*Chaeyun Kim,YongTaek Lim,Kihyun Kim,Junghwan Kim,Minwoo Kim*

Main category: cs.CY

TL;DR: CAGE框架通过语义模具分离对抗性结构与文化内容，将红队测试基准适应到新文化语境，比直接翻译更有效揭示本地化漏洞


<details>
  <summary>Details</summary>
Motivation: 现有红队测试基准通过直接翻译适应新语言时，无法捕捉基于当地文化和法律的社会技术漏洞，在LLM安全评估中造成关键盲点

Method: 提出CAGE框架，核心是语义模具方法，将已验证红队提示的对抗性意图从其文化内容中解耦，系统性地适应到新文化语境

Result: 以韩语基准KoRSET为例，证明CAGE比直接翻译基线更有效揭示漏洞，提供可扩展的跨文化安全评估方案

Conclusion: CAGE为开发有意义、上下文感知的安全基准提供了可扩展解决方案，能够建模现实本地化威胁而非简单越狱测试

Abstract: Existing red-teaming benchmarks, when adapted to new languages via direct translation, fail to capture socio-technical vulnerabilities rooted in local culture and law, creating a critical blind spot in LLM safety evaluation. To address this gap, we introduce CAGE (Culturally Adaptive Generation), a framework that systematically adapts the adversarial intent of proven red-teaming prompts to new cultural contexts. At the core of CAGE is the Semantic Mold, a novel approach that disentangles a prompt's adversarial structure from its cultural content. This approach enables the modeling of realistic, localized threats rather than testing for simple jailbreaks. As a representative example, we demonstrate our framework by creating KoRSET, a Korean benchmark, which proves more effective at revealing vulnerabilities than direct translation baselines. CAGE offers a scalable solution for developing meaningful, context-aware safety benchmarks across diverse cultures. Our dataset and evaluation rubrics are publicly available at https://github.com/selectstar-ai/CAGE-paper. (WARNING: This paper contains model outputs that can be offensive in nature.)

</details>


### [62] [Is Robot Labor Labor? Delivery Robots and the Politics of Work in Public Space](https://arxiv.org/abs/2602.20180)
*EunJeong Cheon,Do Yeon Shin*

Main category: cs.CY

TL;DR: 该论文通过首尔两个智慧城区的民族志研究，探讨了人行道配送机器人是否构成"劳动"的问题，揭示了机器人配送实际上是依赖人类劳动、监管协调和社会适应的分布式社会技术成就，而非简单的自动化替代。


<details>
  <summary>Details</summary>
Motivation: 随着人行道配送机器人日益融入城市生活，作者提出一个批判性问题：机器人劳动是否算劳动？这不仅是修辞问题，更是为了关注机器人劳动所涉及的社会和政治安排，挑战机器人作为自主高效行动的常见叙事。

Method: 采用民族志田野调查方法，在首尔的两个智慧城区进行实地研究，观察和分析配送机器人工作的实际运作方式及其与社会环境的互动。

Result: 研究发现：1）成功的机器人配送是分布式社会技术成就，依赖人类劳动、监管协调和社会适应；2）机器人不是替代劳动而是重新配置劳动，使某些形式（机器人表现）更可见，而其他形式（人类和机构支持）被遮蔽；3）在公共空间中观察到"机器人特权"现象——人类经常为机器人让路；4）不同人群对机器人有不同感知：偶然观察者认为"可爱"，日常共存者认为"可敬"。

Conclusion: 论文提出了将机器人劳动重新概念化为集体组合的框架，提供了韩国智慧城市自动化的实证见解，并呼吁人机交互领域更深入地参与劳动和空间政治，以更好地理论化面向公众的机器人。

Abstract: As sidewalk delivery robots become increasingly integrated into urban life, this paper begins with a critical provocation: Is robot labor labor? More than a rhetorical question, this inquiry invites closer attention to the social and political arrangements that robot labor entails. Drawing on ethnographic fieldwork across two smart-city districts in Seoul, we examine how delivery robot labor is collectively sustained. While robotic actions are often framed as autonomous and efficient, we show that each successful delivery is in fact a distributed sociotechnical achievement--reliant on human labor, regulatory coordination, and social accommodations. We argue that delivery robots do not replace labor but reconfigure it--rendering some forms more visible (robotic performance) while obscuring others (human and institutional support). Unlike industrial robots, delivery robots operate in shared public space, engage everyday passersby, and are embedded in policy and progress narratives. In these spaces, we identify "robot privilege"--humans routinely yielding to robots--and distinct perceptions between casual observers ("cute") and everyday coexisters ("admirable"). We contribute a conceptual reframing of robot labor as a collective assemblage, empirical insights into South Korea's smart-city automation, and a call for HRI to engage more deeply with labor and spatial politics to better theorize public-facing robots.

</details>


### [63] [Closing the Expertise Gap in Residential Building Energy Retrofits: A Domain-Specific LLM for Informed Decision-Making](https://arxiv.org/abs/2602.20181)
*Lei Shu,Armin Yeganeh,Sinem Mollaoglu,Jiayu Zhou,Dong Zhao*

Main category: cs.CY

TL;DR: 开发了一个专门用于住宅能源改造决策的领域特定大语言模型，通过房主可访问的基本住宅特征描述提供最优改造建议，在CO2减排和投资回收期方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 住宅能源改造决策受到专业知识差距的限制，房主缺乏进行能源评估所需的技术素养，需要一种能够基于房主可理解的基本住宅特征提供改造建议的解决方案。

Method: 开发了一个领域特定的大语言模型，基于536,416个美国住宅建筑原型进行物理能源模拟和技术经济计算，使用低秩适应（LoRA）方法进行微调，将住宅特征映射到最优改造选择和性能结果。

Result: 模型在CO2减排方面，前三个推荐中包含最优改造方案的比例达到98.9%；在最短贴现投资回收期方面达到93.3%。微调使CO2预测误差降低了一个数量级，能源使用和改造成本预测误差也大幅降低。模型在不完整输入条件下仍能保持性能。

Conclusion: 该领域特定LLM能够有效支持住宅脱碳决策，通过房主可访问的住宅特征描述提供可靠的改造建议，有助于缩小专业知识差距，促进住宅能源改造的普及。

Abstract: Residential energy retrofit decision-making is constrained by an expertise gap, as homeowners lack the technical literacy required for energy assessments. To address this challenge, this study develops a domain-specific large language model (LLM) that provides optimal retrofit recommendations using homeowner-accessible descriptions of basic dwelling characteristics. The model is fine-tuned on physics-based energy simulations and techno-economic calculations derived from 536,416 U.S. residential building prototypes across nine major retrofit categories. Using Low-Rank Adaptation (LoRA), the LLM maps dwelling characteristics to optimal retrofit selections and associated performance outcomes. Evaluation against physics-grounded baselines shows that the model identifies the optimal retrofit for CO2 reduction within its top three recommendations in 98.9% of cases and the shortest discounted payback period in 93.3% of cases. Fine-tuning yields an order-of-magnitude reduction in CO2 prediction error and multi-fold reductions for energy use and retrofit cost. The model maintains performance under incomplete input conditions, supporting informed residential decarbonization decisions.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [64] [Indaleko: The Unified Personal Index](https://arxiv.org/abs/2602.20507)
*William Anthony Mason*

Main category: cs.IR

TL;DR: 该论文提出了统一个人索引（UPI）架构，通过模拟人类记忆的时空情境线索来改进个人信息检索，开发了Indaleko原型系统，在31百万文件数据集上验证了可行性，相比现有商业系统能更好地处理基于记忆的查询。


<details>
  <summary>Details</summary>
Motivation: 现有个人信息检索系统忽略了人类记忆的工作方式，强制使用关键词搜索孤立的数据孤岛，而人类自然通过情境线索（时间、地点、上下文）回忆信息，导致检索效果不佳。

Method: 提出统一个人索引（UPI）架构，将时间、空间和活动元数据整合到统一图数据库中，开发Indaleko原型系统，采用内存锚索引实现亚秒级查询响应，支持自然语言查询和跨平台搜索。

Result: Indaleko原型在31百万文件、160TB跨8个存储平台的数据集上验证可行性，相比Google Drive、OneDrive等商业系统能成功处理基于记忆的多维查询，实现亚秒级响应和完美精度，新数据源集成仅需10分钟到10小时。

Conclusion: UPI架构将认知理论与分布式系统设计相结合，将个人信息检索从关键词匹配转变为基于记忆的查找，为现有数据提供即时效益，并为未来情境感知系统奠定基础。

Abstract: Personal information retrieval fails when systems ignore how human memory works. While existing platforms force keyword searches across isolated silos, humans naturally recall through episodic cues like when, where, and in what context information was encountered. This dissertation presents the Unified Personal Index (UPI), a memory-aligned architecture that bridges this fundamental gap. The Indaleko prototype demonstrates the UPI's feasibility on a 31-million file dataset spanning 160TB across eight storage platforms. By integrating temporal, spatial, and activity metadata into a unified graph database, Indaleko enables natural language queries like "photos near the conference venue last spring" that existing systems cannot process. The implementation achieves sub-second query responses through memory anchor indexing, eliminates cross-platform search fragmentation, and maintains perfect precision for well-specified memory patterns. Evaluation against commercial systems (Google Drive, OneDrive, Dropbox, Windows Search) reveals that all fail on memory-based queries, returning overwhelming result sets without contextual filtering. In contrast, Indaleko successfully processes multi-dimensional queries combining time, location, and activity patterns. The extensible architecture supports rapid integration of new data sources (10 minutes to 10 hours per provider) while preserving privacy through UUID-based semantic decoupling. The UPI's architectural synthesis bridges cognitive theory with distributed systems design, as demonstrated through the Indaleko prototype and rigorous evaluation. This work transforms personal information retrieval from keyword matching to memory-aligned finding, providing immediate benefits for existing data while establishing foundations for future context-aware systems.

</details>


### [65] [PRECTR-V2:Unified Relevance-CTR Framework with Cross-User Preference Mining, Exposure Bias Correction, and LLM-Distilled Encoder Optimization](https://arxiv.org/abs/2602.20676)
*Shuzhi Cao,Rong Chen,Ailong He,Shuguang Han,Jufeng Chen*

Main category: cs.IR

TL;DR: PRECTR-V2是一个改进的搜索系统框架，通过挖掘全局相关性偏好解决冷启动问题，构建硬负样本来纠正曝光偏差，并使用轻量级Transformer编码器替代冻结的BERT，实现更好的CTR微调。


<details>
  <summary>Details</summary>
Motivation: 为了解决PRECTR框架面临的三个主要挑战：1) 低活跃用户和新用户搜索行为数据有限，难以实现有效的个性化相关性偏好建模；2) 排序模型训练数据主要来自高相关性曝光，与粗排候选空间存在分布不匹配，导致泛化偏差；3) 由于延迟限制，原始模型使用Emb+MLP架构和冻结的BERT编码器，阻碍了联合优化并造成表示学习与CTR微调之间的不对齐。

Method: 1) 通过挖掘特定查询下的全局相关性偏好，缓解低活跃用户的稀疏行为问题，促进冷启动场景下的有效个性化相关性建模；2) 通过嵌入噪声注入和相关性标签重构构建硬负样本，并通过成对损失优化它们相对于正样本的相对排序，从而纠正曝光偏差；3) 通过从LLM进行知识蒸馏和在文本相关性分类任务上进行SFT，预训练一个轻量级基于Transformer的编码器，替代冻结的BERT模块，实现更好的CTR微调适应。

Result: PRECTR-V2解决了原始PRECTR框架的三个主要挑战：1) 有效处理冷启动用户的个性化相关性建模；2) 纠正了训练数据分布与候选空间之间的不匹配问题；3) 实现了表示学习与CTR微调的更好对齐，超越了传统的Emb+MLP范式。

Conclusion: PRECTR-V2通过改进的个性化相关性建模、曝光偏差纠正和轻量级Transformer编码器设计，显著提升了搜索系统中相关性匹配和CTR预测的协调效果，特别是在冷启动场景下表现更佳。

Abstract: In search systems, effectively coordinating the two core objectives of search relevance matching and click-through rate (CTR) prediction is crucial for discovering users' interests and enhancing platform revenue. In our prior work PRECTR, we proposed a unified framework to integrate these two subtasks,thereby eliminating their inconsistency and leading to mutual benefit.However, our previous work still faces three main challenges. First, low-active users and new users have limited search behavioral data, making it difficult to achieve effective personalized relevance preference modeling. Second, training data for ranking models predominantly come from high-relevance exposures, creating a distribution mismatch with the broader candidate space in coarse-ranking, leading to generalization bias. Third, due to the latency constraint, the original model employs an Emb+MLP architecture with a frozen BERT encoder, which prevents joint optimization and creates misalignment between representation learning and CTR fine-tuning. To solve these issues, we further reinforce our method and propose PRECTR-V2. Specifically, we mitigate the low-activity users' sparse behavior problem by mining global relevance preferences under the specific query, which facilitates effective personalized relevance modeling for cold-start scenarios. Subsequently, we construct hard negative samples through embedding noise injection and relevance label reconstruction, and optimize their relative ranking against positive samples via pairwise loss, thereby correcting exposure bias. Finally, we pretrain a lightweight transformer-based encoder via knowledge distillation from LLM and SFT on the text relevance classification task. This encoder replaces the frozen BERT module, enabling better adaptation to CTR fine-tuning and advancing beyond the traditional Emb+MLP paradigm.

</details>


### [66] [IntRR: A Framework for Integrating SID Redistribution and Length Reduction](https://arxiv.org/abs/2602.20704)
*Zesheng Wang,Longfei Xu,Weidong Deng,Huimin Yan,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: IntRR框架通过语义ID重分配和长度缩减，解决生成式推荐中语义ID与推荐目标不对齐、计算开销大的问题，提升推荐准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐中的语义ID存在两个主要问题：1）索引目标与推荐目标不对齐，导致静态ID无法适应动态用户交互；2）扁平化分层语义ID导致序列长度膨胀，计算开销和推理延迟过高。

Method: 提出IntRR框架，包含两个核心组件：1）基于物品唯一ID作为协作锚点，动态重分配语义权重到分层码本；2）递归处理语义ID层次结构，避免序列扁平化，实现每个物品固定1个token的成本。

Result: 在基准数据集上的实验表明，IntRR相比代表性生成式基线方法有显著改进，在推荐准确性和效率方面都取得了优越性能。

Conclusion: IntRR通过语义ID重分配和长度缩减，有效解决了生成式推荐中的语义ID不对齐和计算效率问题，为生成式推荐系统提供了更优的解决方案。

Abstract: Generative Recommendation (GR) has emerged as a transformative paradigm that reformulates the traditional cascade ranking system into a sequence-to-item generation task, facilitated by the use of discrete Semantic IDs (SIDs). However, current SIDs are suboptimal as the indexing objectives (Stage 1) are misaligned with the actual recommendation goals (Stage 2). Since these identifiers remain static (Stage 2), the backbone model lacks the flexibility to adapt them to the evolving complexities of user interactions. Furthermore, the prevailing strategy of flattening hierarchical SIDs into token sequences leads to sequence length inflation, resulting in prohibitive computational overhead and inference latency. To address these challenges, we propose IntRR, a novel framework that integrates objective-aligned SID Redistribution and structural Length Reduction. By leveraging item-specific Unique IDs (UIDs) as collaborative anchors, this approach dynamically redistributes semantic weights across hierarchical codebook layers. Concurrently, IntRR handles the SID hierarchy recursively, eliminating the need to flatten sequences. This ensures a fixed cost of one token per item. Extensive experiments on benchmark datasets demonstrate that IntRR yields substantial improvements over representative generative baselines, achieving superior performance in both recommendation accuracy and efficiency.

</details>


### [67] [RMIT-ADM+S at the MMU-RAG NeurIPS 2025 Competition](https://arxiv.org/abs/2602.20735)
*Kun Ran,Marwah Alaofi,Danula Hettiachchi,Chenglong Ma,Khoi Nguyen Dinh Anh,Khoi Vo Nguyen,Sachin Pathiyan Cherumanal,Lida Rashidi,Falk Scholer,Damiano Spina,Shuoqi Sun,Oleg Zendel*

Main category: cs.IR

TL;DR: R2RAG系统在NeurIPS 2025 MMU-RAG竞赛中获奖，这是一个轻量级检索增强生成架构，能根据查询复杂性和证据充分性动态调整检索策略，可在消费级GPU上运行。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG系统在处理复杂研究任务时资源消耗大、检索策略固定的问题，开发一个能在有限计算资源下高效运行的轻量级自适应RAG系统。

Method: 提出Routing-to-RAG架构，基于G-RAG系统扩展，包含轻量级组件，能动态推断查询复杂性和证据充分性，自适应调整检索策略，使用较小的LLM模型。

Result: 系统在NeurIPS 2025 MMU-RAG竞赛中获得最佳动态评估奖，在开源类别中表现出色，证明了在消费级GPU上也能高效支持复杂研究任务。

Conclusion: R2RAG展示了通过精心设计和资源高效利用，轻量级自适应RAG系统能够在有限计算资源下实现高性能，为资源受限环境下的复杂研究任务提供了可行解决方案。

Abstract: This paper presents the award-winning RMIT-ADM+S system for the Text-to-Text
  track of the NeurIPS~2025 MMU-RAG Competition. We introduce Routing-to-RAG
  (R2RAG), a research-focused retrieval-augmented generation (RAG)
  architecture composed of lightweight components that dynamically adapt the
  retrieval strategy based on inferred query complexity and evidence
  sufficiency. The system uses smaller LLMs, enabling operation on a single
  consumer-grade GPU while supporting complex research tasks. It builds on the
  G-RAG system, winner of the ACM~SIGIR~2025 LiveRAG Challenge, and extends it
  with modules informed by qualitative review of outputs. R2RAG won the Best
  Dynamic Evaluation award in the Open Source category, demonstrating high
  effectiveness with careful design and efficient use of resources.

</details>


### [68] [Mitigating Preference Leakage via Strict Estimator Separation for Normative Generative Ranking](https://arxiv.org/abs/2602.20800)
*Dalia Nahhas,Xiaohao Cai,Imran Razzak,Shoaib Jameel*

Main category: cs.IR

TL;DR: 论文提出了一种无泄漏的双法官框架来解决GenIR中文化相关性评估的循环性和偏好泄漏问题，通过严格分离监督和评估模型，证明可以将文化偏好蒸馏到高效排序器中。


<details>
  <summary>Details</summary>
Motivation: 当前生成式信息检索(GenIR)中的瓶颈已从生成转向候选选择，特别是在文化相关性等规范性标准方面。现有的LLM-as-a-Judge评估方法存在循环性和偏好泄漏问题，即监督和评估模型重叠会夸大性能表现。

Method: 1) 将文化相关性形式化为查询内排序任务；2) 引入无泄漏的双法官框架，严格分离监督(Judge B)和评估(Judge A)；3) 在包含33,052个文化基础故事的新基准(NGR-33k)上进行评估；4) 从Judge B监督的交叉编码器中蒸馏出密集双编码器；5) 在人工策划的Moral Stories数据集上验证框架。

Result: 1) 经典基线方法仅获得适度增益；2) 从交叉编码器蒸馏出的密集双编码器(BGE-M3)非常有效；3) 虽然交叉编码器为蒸馏提供了强监督信号，但在无泄漏的Judge A评估下，蒸馏后的BGE-M3模型显著优于交叉编码器；4) 在Moral Stories数据集上显示出与人类规范的强对齐。

Conclusion: 严格的评估器分离是可信GenIR评估的前提，证明可以将微妙的文化偏好蒸馏到高效排序器中而无需泄漏。该框架为文化相关性和其他规范性标准的评估提供了可靠方法。

Abstract: In Generative Information Retrieval (GenIR), the bottleneck has shifted from generation to the selection of candidates, particularly for normative criteria such as cultural relevance. Current LLM-as-a-Judge evaluations often suffer from circularity and preference leakage, where overlapping supervision and evaluation models inflate performance. We address this by formalising cultural relevance as a within-query ranking task and introducing a leakage-free two-judge framework that strictly separates supervision (Judge B) from evaluation (Judge A). On a new benchmark of 33,052 (NGR-33k) culturally grounded stories, we find that while classical baselines yield only modest gains, a dense bi-encoder distilled from a Judge-B-supervised Cross-Encoder is highly effective. Although the Cross-Encoder provides a strong supervision signal for distillation, the distilled BGE-M3 model substantially outperforms it under leakage-free Judge~A evaluation. We validate our framework on the human-curated Moral Stories dataset, showing strong alignment with human norms. Our results demonstrate that rigorous evaluator separation is a prerequisite for credible GenIR evaluation, proving that subtle cultural preferences can be distilled into efficient rankers without leakage.

</details>


### [69] [Position-Aware Sequential Attention for Accurate Next Item Recommendations](https://arxiv.org/abs/2602.21052)
*Timur Nabiev,Evgeny Frolov*

Main category: cs.IR

TL;DR: 提出了一种基于位置核的自注意力机制，通过解耦位置信息和语义信息来改进序列建模能力


<details>
  <summary>Details</summary>
Motivation: 传统的加性位置嵌入方法存在局限性：位置信息与项目语义纠缠、在深层架构中传播弱、难以捕捉丰富的序列模式。作者认为加性位置嵌入只是表面上对序列顺序敏感，需要更有效的机制来建模时间顺序。

Method: 引入核化自注意力机制，其中可学习的位置核在纯位置空间中操作，与语义相似性解耦，直接调节注意力权重。在每个注意力块中应用该位置核，实现自适应多尺度序列建模。

Result: 在标准的下一个项目预测基准测试中，位置核注意力机制持续优于强大的竞争基线方法。

Conclusion: 通过解耦位置信息和语义信息，核化自注意力机制能够更有效地建模序列顺序，克服了传统加性位置嵌入的局限性，在序列建模任务中表现出优越性能。

Abstract: Sequential self-attention models usually rely on additive positional embeddings, which inject positional information into item representations at the input. In the absence of positional signals, the attention block is permutation-equivariant over sequence positions and thus has no intrinsic notion of temporal order beyond causal masking. We argue that additive positional embeddings make the attention mechanism only superficially sensitive to sequence order: positional information is entangled with item embedding semantics, propagates weakly in deep architectures, and limits the ability to capture rich sequential patterns. To address these limitations, we introduce a kernelized self-attention mechanism, where a learnable positional kernel operates purely in the position space, disentangled from semantic similarity, and directly modulates attention weights. When applied per attention block, this kernel enables adaptive multi-scale sequential modeling. Experiments on standard next-item prediction benchmarks show that our positional kernel attention consistently improves over strong competing baselines.

</details>


### [70] [Multi-Vector Index Compression in Any Modality](https://arxiv.org/abs/2602.21202)
*Hanxiang Qin,Alexander Martin,Rohan Jha,Chunsheng Zuo,Reno Kriz,Benjamin Van Durme*

Main category: cs.IR

TL;DR: 本文研究了跨模态多向量检索中的索引压缩方法，提出注意力引导聚类技术，在固定向量预算下实现高效检索，在文本、视觉文档和视频任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 后期交互已成为文本、图像、视觉文档和视频信息检索的主要范式，但其计算和存储成本随文档长度线性增长，对于图像、视频和音频丰富的语料库成本高昂。需要解决多向量文档表示在固定向量预算下的压缩问题。

Method: 提出了四种索引压缩方法：序列调整、记忆令牌、分层池化，以及新颖的注意力引导聚类（AGC）。AGC使用注意力引导机制识别文档中最具语义显著性的区域作为聚类中心，并对令牌聚合进行加权。

Result: 在文本（BEIR）、视觉文档（ViDoRe）和视频（MSR-VTT、MultiVENT 2.0）检索任务上的评估显示，注意力引导聚类始终优于其他参数化压缩方法，比非参数化分层聚类提供更大的索引大小灵活性，并且相比完整未压缩索引实现了竞争性或改进的性能。

Conclusion: 注意力引导聚类是一种有效的多向量文档表示压缩方法，能够在固定向量预算下保持检索性能，为跨模态信息检索提供了高效的解决方案。

Abstract: We study efficient multi-vector retrieval for late interaction in any modality. Late interaction has emerged as a dominant paradigm for information retrieval in text, images, visual documents, and videos, but its computation and storage costs grow linearly with document length, making it costly for image-, video-, and audio-rich corpora. To address this limitation, we explore query-agnostic methods for compressing multi-vector document representations under a constant vector budget. We introduce four approaches for index compression: sequence resizing, memory tokens, hierarchical pooling, and a novel attention-guided clustering (AGC). AGC uses an attention-guided mechanism to identify the most semantically salient regions of a document as cluster centroids and to weight token aggregation. Evaluating these methods on retrieval tasks spanning text (BEIR), visual-document (ViDoRe), and video (MSR-VTT, MultiVENT 2.0), we show that attention-guided clustering consistently outperforms other parameterized compression methods (sequence resizing and memory tokens), provides greater flexibility in index size than non-parametric hierarchical clustering, and achieves competitive or improved performance compared to a full, uncompressed index. The source code is available at: github.com/hanxiangqin/omni-col-press.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [Multilevel Determinants of Overweight and Obesity Among U.S. Children Aged 10-17: Comparative Evaluation of Statistical and Machine Learning Approaches Using the 2021 National Survey of Children's Health](https://arxiv.org/abs/2602.20303)
*Joyanta Jyoti Mondal*

Main category: cs.AI

TL;DR: 研究比较了统计、机器学习和深度学习模型在预测美国青少年超重/肥胖方面的表现，发现逻辑回归与更复杂模型相比表现相当，模型性能在不同种族和贫困群体间存在差异。


<details>
  <summary>Details</summary>
Motivation: 儿童和青少年超重肥胖是美国主要的公共卫生问题，受行为、家庭和社区因素共同影响。目前对这些多层次预测因素在人群层面的联合预测结构了解不足，需要比较不同预测模型的性能。

Method: 使用2021年全美儿童健康调查中18,792名10-17岁儿童的数据。预测因素包括饮食、体育活动、睡眠、父母压力、社会经济条件、不良经历和社区特征。比较了逻辑回归、随机森林、梯度提升、XGBoost、LightGBM、多层感知机和TabNet等模型，使用AUC、准确率、精确率、召回率、F1分数和Brier分数进行评估。

Result: 模型区分度在0.66-0.79之间。逻辑回归、梯度提升和多层感知机在区分度和校准方面表现最稳定。提升算法和深度学习模型在召回率和F1分数上有轻微改善，但没有模型在所有方面都表现最优。不同种族和贫困群体间的性能差异在所有算法中都持续存在。

Conclusion: 增加模型复杂度对预测性能的提升有限，逻辑回归表现与复杂模型相当。预测因素持续涵盖行为、家庭和社区领域。持续的亚组差异表明需要改进数据质量和关注公平性的监测，而不是追求更高的算法复杂度。

Abstract: Background: Childhood and adolescent overweight and obesity remain major public health concerns in the United States and are shaped by behavioral, household, and community factors. Their joint predictive structure at the population level remains incompletely characterized. Objectives: The study aims to identify multilevel predictors of overweight and obesity among U.S. adolescents and compare the predictive performance, calibration, and subgroup equity of statistical, machine-learning, and deep-learning models. Data and Methods: We analyze 18,792 children aged 10-17 years from the 2021 National Survey of Children's Health. Overweight/obesity is defined using BMI categories. Predictors included diet, physical activity, sleep, parental stress, socioeconomic conditions, adverse experiences, and neighborhood characteristics. Models include logistic regression, random forest, gradient boosting, XGBoost, LightGBM, multilayer perceptron, and TabNet. Performance is evaluated using AUC, accuracy, precision, recall, F1 score, and Brier score. Results: Discrimination range from 0.66 to 0.79. Logistic regression, gradient boosting, and MLP showed the most stable balance of discrimination and calibration. Boosting and deep learning modestly improve recall and F1 score. No model was uniformly superior. Performance disparities across race and poverty groups persist across algorithms. Conclusion: Increased model complexity yields limited gains over logistic regression. Predictors consistently span behavioral, household, and neighborhood domains. Persistent subgroup disparities indicate the need for improved data quality and equity-focused surveillance rather than greater algorithmic complexity.

</details>


### [72] [DMCD: Semantic-Statistical Framework for Causal Discovery](https://arxiv.org/abs/2602.20333)
*Samarth KaPatel,Sofia Nikiforova,Giacinto Paolo Saggese,Paul Smith*

Main category: cs.AI

TL;DR: DMCD是一个两阶段因果发现框架，结合了基于LLM的语义草图和统计验证，在真实世界基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的因果发现方法要么依赖纯统计方法（可能受数据稀疏性影响），要么依赖纯语义方法（缺乏统计验证）。需要一种结合语义先验和统计验证的方法来提高因果结构学习的准确性和实用性。

Method: DMCD采用两阶段框架：第一阶段使用大语言模型基于变量元数据生成稀疏的因果图草案，作为语义先验；第二阶段通过条件独立性测试对草案进行审计和精炼，检测到的差异指导有针对性的边修正。

Result: 在工业工程、环境监测和IT系统分析三个元数据丰富的真实世界基准测试中，DMCD相比多种因果发现基线方法取得了竞争性或领先的性能，特别是在召回率和F1分数上有显著提升。

Conclusion: 将语义先验与原则性统计验证相结合，能够产生高性能且实际有效的因果结构学习方法，语义推理而非基准图记忆是性能提升的关键。

Abstract: We present DMCD (DataMap Causal Discovery), a two-phase causal discovery framework that integrates LLM-based semantic drafting from variable metadata with statistical validation on observational data. In Phase I, a large language model proposes a sparse draft DAG, serving as a semantically informed prior over the space of possible causal structures. In Phase II, this draft is audited and refined via conditional independence testing, with detected discrepancies guiding targeted edge revisions.
  We evaluate our approach on three metadata-rich real-world benchmarks spanning industrial engineering, environmental monitoring, and IT systems analysis. Across these datasets, DMCD achieves competitive or leading performance against diverse causal discovery baselines, with particularly large gains in recall and F1 score. Probing and ablation experiments suggest that these improvements arise from semantic reasoning over metadata rather than memorization of benchmark graphs. Overall, our results demonstrate that combining semantic priors with principled statistical verification yields a high-performing and practically effective approach to causal structure learning.

</details>


### [73] [Diffusion Modulation via Environment Mechanism Modeling for Planning](https://arxiv.org/abs/2602.20422)
*Hanping Zhang,Yuhong Guo*

Main category: cs.AI

TL;DR: DMEMM是一种新颖的基于扩散模型的规划方法，通过建模环境机制（转移动态和奖励函数）来调制扩散训练，解决了传统扩散规划中轨迹一致性问题，在离线强化学习规划中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于扩散模型的规划方法在离线强化学习中生成轨迹时，往往忽略了轨迹中状态转移的一致性要求，导致生成的轨迹与真实环境机制存在显著差异，影响规划效果。

Method: 提出DMEMM方法，在扩散模型训练中融入关键RL环境机制，特别是转移动态和奖励函数，通过环境机制建模来调制扩散过程，确保生成的轨迹在真实环境中具有一致性。

Result: 实验结果表明，DMEMM在离线强化学习规划任务中实现了最先进的性能表现。

Conclusion: 通过将环境机制建模融入扩散模型训练，DMEMM有效解决了轨迹一致性问题，为基于扩散模型的离线强化学习规划提供了更可靠的解决方案。

Abstract: Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments. This oversight can result in considerable discrepancies between the generated trajectories and the underlying mechanisms of a real environment. To address this problem, we propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions. Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.

</details>


### [74] [From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production](https://arxiv.org/abs/2602.20558)
*Yucheng Shi,Ying Li,Yu Wang,Yesu Feng,Arjun Rao,Rein Houthooft,Shradha Sehgal,Jin Wang,Hao Zhen,Ninghao Liu,Linas Baltrunas*

Main category: cs.AI

TL;DR: 提出一个数据驱动的框架，通过强化学习训练verbalization agent，将结构化用户交互日志转换为优化的自然语言输入，显著提升LLM推荐系统的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐系统面临的关键挑战是verbalization问题——如何将结构化用户交互日志有效转换为自然语言输入。当前基于模板的方法简单拼接字段，无法生成最优的文本表示，限制了推荐性能。

Method: 提出数据驱动的verbalization学习框架，使用强化学习训练一个verbalization agent。该agent将原始交互历史转换为优化的文本上下文，以推荐准确性作为训练信号。agent学习过滤噪声、整合相关元数据、重组信息以提升下游预测。

Result: 在大规模工业流媒体数据集上的实验显示，学习到的verbalization相比基于模板的基线方法，在发现项目推荐准确性上获得高达93%的相对提升。分析揭示了涌现的策略：用户兴趣总结、噪声去除、语法规范化等。

Conclusion: 学习verbalization是提升LLM推荐系统性能的关键，通过数据驱动的方法可以自动发现有效的上下文构建策略，为基于LLM的推荐系统提供了重要见解。

Abstract: Large language models (LLMs) are promising backbones for generative recommender systems, yet a key challenge remains underexplored: verbalization, i.e., converting structured user interaction logs into effective natural language inputs. Existing methods rely on rigid templates that simply concatenate fields, yielding suboptimal representations for recommendation. We propose a data-centric framework that learns verbalization for LLM-based recommendation. Using reinforcement learning, a verbalization agent transforms raw interaction histories into optimized textual contexts, with recommendation accuracy as the training signal. This agent learns to filter noise, incorporate relevant metadata, and reorganize information to improve downstream predictions. Experiments on a large-scale industrial streaming dataset show that learned verbalization delivers up to 93% relative improvement in discovery item recommendation accuracy over template-based baselines. Further analysis reveals emergent strategies such as user interest summarization, noise removal, and syntax normalization, offering insights into effective context construction for LLM-based recommender systems.

</details>


### [75] [Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning](https://arxiv.org/abs/2602.20722)
*Xu Wan,Yansheng Wang,Wenqi Huang,Mingyang Sun*

Main category: cs.AI

TL;DR: BAPO是一个用于大语言模型后训练的离策略RLVR框架，通过动态选择训练批次、重新评估历史困难样本和重用高质量样本，提高数据效率，在数学、规划和视觉推理任务上平均比GRPO提升12.5%。


<details>
  <summary>Details</summary>
Motivation: 传统的基于策略的RLVR框架存在经验浪费和奖励同质化问题，这直接阻碍了在大语言模型后训练中对困难样本的学习效率。

Method: 提出Batch Adaptation Policy Optimization (BAPO)，这是一个离策略RLVR框架，通过动态选择训练批次，重新评估历史困难样本并重用高质量样本，同时保持策略改进的下界保证。

Result: 在数学、规划和视觉推理任务上，BAPO相比GRPO平均提升12.5%，成功解决了基础模型持续失败的40.7%的问题。

Conclusion: BAPO通过提高数据效率和有效处理困难样本，显著改善了大语言模型后训练的强化学习效果。

Abstract: Traditional on-policy Reinforcement Learning with Verifiable Rewards (RLVR) frameworks suffer from experience waste and reward homogeneity, which directly hinders learning efficiency on difficult samples during large language models post-training. In this paper, we introduce Batch Adaptation Policy Optimization (BAPO), an off-policy RLVR framework to improve the data efficiency in large language models post-training. It dynamically selects training batches by re-evaluating historically difficult samples and reusing high-quality ones, while holding a lower bound guarantee for policy improvement. Extensive experiments further demonstrate that BAPO achieves an average 12.5% improvement over GRPO across mathematics, planning, and visual reasoning tasks. Crucially, BAPO successfully resolves 40.7% of problems that base models consistently fail to solve.

</details>


### [76] [CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference](https://arxiv.org/abs/2602.20732)
*Chao Fei,Guozhong Li,Chenxi Liu,Panos Kalnis*

Main category: cs.AI

TL;DR: CHESS是一种算法-系统协同设计的KV缓存管理系统，通过上下文感知的分层选择策略，仅使用1%的KV缓存就能超越Full-KV质量，实现高达4.56倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM需要低延迟的准确推理，但随着上下文增长，解码主要受KV缓存约束。现有剪枝方法大多是上下文无关的：它们的token选择忽略了逐步相关性和局部语义，这损害了质量。此外，它们的不规则访问和选择开销仅带来有限的时钟加速。

Method: CHESS采用算法-系统协同设计。算法上，引入上下文感知的分层选择策略，动态重建当前解码的连贯上下文。系统上，粗粒度选择消除了昂贵的数据移动，充分实现理论稀疏性的实际加速。

Result: 广泛评估表明，CHESS仅使用1%的KV缓存就能超越Full-KV质量，提供低延迟稳定推理，吞吐量提升高达4.56倍，并持续优于其他强基线。

Conclusion: CHESS通过算法-系统协同设计有效解决了长上下文LLM中KV缓存管理的挑战，实现了高质量、低延迟的推理加速。

Abstract: Long-context LLMs demand accurate inference at low latency, yet decoding becomes primarily constrained by KV cache as context grows. Prior pruning methods are largely context-agnostic: their token selection ignores step-wise relevance and local semantics, which undermines quality. Moreover, their irregular accesses and selection overheads yield only limited wall-clock speedups. To address this, we propose \textbf{CHESS}, an \textit{algorithm-system co-design} KV-cache management system. Algorithmically, CHESS introduces a context-aware, hierarchical selection policy that dynamically reconstructs a coherent context for the current decoding. System-wise, coarse granularity selection eliminates expensive data movement, fully realizing practical acceleration from theoretical sparsity. Extensive evaluations demonstrate that CHESS surpasses Full-KV quality using only \textbf{1\%} of the KV cache, delivers low-latency stable inference with up to \textbf{4.56$\times$} higher throughput, and consistently outperforms other strong baselines. Code is available at \href{https://anonymous.4open.science/r/CHESS-9958/}{https://anonymous.4open.science/r/CHESS/}.

</details>


### [77] [PyVision-RL: Forging Open Agentic Vision Models via RL](https://arxiv.org/abs/2602.20739)
*Shitian Zhao,Shaoheng Lin,Ming Li,Haoquan Zhang,Wenshuo Peng,Kaipeng Zhang,Chen Wei*

Main category: cs.AI

TL;DR: 提出了PyVision-RL强化学习框架，解决多模态模型中交互崩溃问题，通过过采样-过滤-排序策略和累积工具奖励来维持多轮工具使用，开发了图像和视频理解模型，视频推理采用按需上下文构建减少视觉token使用。


<details>
  <summary>Details</summary>
Motivation: 多模态模型的强化学习经常出现交互崩溃问题，模型倾向于减少工具使用和多轮推理，限制了智能体行为的优势，需要一种能够稳定训练并维持交互的框架。

Method: 提出PyVision-RL强化学习框架，结合过采样-过滤-排序的rollout策略和累积工具奖励来防止交互崩溃；开发统一训练流程，创建PyVision-Image和PyVision-Video模型；视频推理采用按需上下文构建，选择性采样任务相关帧以减少视觉token使用。

Result: 实验显示PyVision模型表现出强大的性能和改进的效率，证明了持续交互和按需视觉处理对于可扩展多模态智能体的重要性。

Conclusion: PyVision-RL框架通过防止交互崩溃和鼓励多轮工具使用，结合按需视觉处理，为可扩展的多模态智能体提供了有效的解决方案。

Abstract: Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains interaction. Our approach combines an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to prevent collapse and encourage multi-turn tool use. Using a unified training pipeline, we develop PyVision-Image and PyVision-Video for image and video understanding. For video reasoning, PyVision-Video employs on-demand context construction, selectively sampling task-relevant frames during reasoning to significantly reduce visual token usage. Experiments show strong performance and improved efficiency, demonstrating that sustained interaction and on-demand visual processing are critical for scalable multimodal agents.

</details>


### [78] [A Benchmark for Deep Information Synthesis](https://arxiv.org/abs/2602.21143)
*Debjit Paul,Daniel Murphy,Milan Gritta,Ronald Cardenas,Victor Prokhorov,Lena Sophia Bolliger,Aysim Toker,Roy Miles,Andreea-Maria Oncescu,Jasivan Alex Sivakumar,Philipp Borchert,Ismail Elezi,Meiru Zhang,Ka Yiu Lee,Guchun Zhang,Jun Wang,Gerasimos Lampouras*

Main category: cs.AI

TL;DR: DEEPSYNTH是一个评估LLM智能体在真实复杂任务中表现的新基准，包含120个跨7个领域、67个国家的任务，测试信息收集、合成和结构化推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估基准无法充分评估LLM智能体解决真实世界复杂任务的能力，这些任务需要从多个来源合成信息并进行超越简单事实检索的推理。

Method: 通过多阶段数据收集流程构建DEEPSYNTH基准：收集官方数据源、创建假设、进行手动分析、设计具有可验证答案的任务。包含120个任务，覆盖7个领域和67个国家的数据源。

Result: 11个最先进的LLM和深度研究智能体在DEEPSYNTH上的最大F1分数仅为8.97和17.5（基于LLM-judge指标），表明基准难度很高。分析显示当前智能体在处理幻觉和大型信息空间推理方面存在困难。

Conclusion: DEEPSYNTH是一个重要的基准，突显了当前LLM智能体在真实复杂任务中的局限性，为未来研究提供了关键的评估方向。

Abstract: Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming problems that combine information gathering, synthesis, and structured reasoning to produce insights. DEEPSYNTH contains 120 tasks collected across 7 domains and data sources covering 67 countries. DEEPSYNTH is constructed using a multi-stage data collection pipeline that requires annotators to collect official data sources, create hypotheses, perform manual analysis, and design tasks with verifiable answers. When evaluated on DEEPSYNTH, 11 state-of-the-art LLMs and deep research agents achieve a maximum F1 score of 8.97 and 17.5 on the LLM-judge metric, underscoring the difficulty of the benchmark. Our analysis reveals that current agents struggle with hallucinations and reasoning over large information spaces, highlighting DEEPSYNTH as a crucial benchmark for guiding future research.

</details>


### [79] [NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning](https://arxiv.org/abs/2602.21172)
*Ishaan Rawal,Shubh Gupta,Yihan Hu,Wei Zhan*

Main category: cs.AI

TL;DR: NoRD模型通过消除推理标注需求，在少于60%的数据上实现了与现有VLA模型竞争的性能，减少了3倍token使用，并采用Dr. GRPO算法克服难度偏差问题


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型面临两大昂贵需求：大规模数据集收集和密集推理标注，这限制了自动驾驶系统的效率和可扩展性

Method: 提出NoRD模型，使用少于60%的训练数据且无需推理标注，采用Dr. GRPO算法来缓解标准GRPO在小型无推理数据集上遇到的难度偏差问题

Result: 在Waymo和NAVSIM数据集上实现了与现有VLA模型竞争的性能，同时大幅减少了训练数据和计算开销

Conclusion: NoRD模型通过消除推理标注需求并有效处理难度偏差，为自动驾驶系统提供了更高效的端到端解决方案

Abstract: Vision-Language-Action (VLA) models are advancing autonomous driving by replacing modular pipelines with unified end-to-end architectures. However, current VLAs face two expensive requirements: (1) massive dataset collection, and (2) dense reasoning annotations. In this work, we address both challenges with \modelname (\textbf{No} \textbf{R}easoning for \textbf{D}riving). Compared to existing VLAs, \modelname achieves competitive performance while being fine-tuned on $<$60\% of the data and no reasoning annotations, resulting in 3$\times$ fewer tokens. We identify that standard Group Relative Policy Optimization (GRPO) fails to yield significant improvements when applied to policies trained on such small, reasoning-free datasets. We show that this limitation stems from difficulty bias, which disproportionately penalizes reward signals from scenarios that produce high-variance rollouts within GRPO. \modelname overcomes this by incorporating Dr.~GRPO, a recent algorithm designed to mitigate difficulty bias in LLMs. As a result, \modelname achieves competitive performance on Waymo and NAVSIM with a fraction of the training data and no reasoning overhead, enabling more efficient autonomous systems.

</details>
