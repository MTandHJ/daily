<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 8]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 6]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Latent Context Compilation: Distilling Long Context into Compact Portable Memory](https://arxiv.org/abs/2602.21221)
*Zeju Li,Yizhou Zhou,Qiang Xu*

Main category: cs.LG

TL;DR: 提出Latent Context Compilation框架，通过可丢弃的LoRA模块作为编译器，将长上下文压缩为紧凑的buffer tokens，实现无状态、可移植的内存工件，无需合成数据且保持模型权重不变。


<details>
  <summary>Details</summary>
Motivation: 当前长上下文LLM部署存在两难：摊销压缩方法在分布外泛化方面表现不佳，而测试时训练方法需要昂贵的合成数据成本且需要修改模型权重，产生有状态参数，使并发服务复杂化。

Method: 采用Latent Context Compilation框架，使用可丢弃的LoRA模块作为编译器，将长上下文蒸馏为紧凑的buffer tokens。引入自对齐优化策略，通过上下文无关的随机查询正则化上下文重建任务，强制压缩token驻留在模型现有的指令遵循流形中。

Result: 在Llama-3.1-8B上的实验表明，Latent Context Compilation在先前方法失败的情况下保留了细粒度细节和推理能力，即使在16倍压缩比下也能有效解耦内存密度与模型参数。

Conclusion: Latent Context Compilation通过将上下文处理从适应转变为编译，提供了一种无状态、可移植的解决方案，解决了长上下文LLM部署中的关键挑战，无需合成数据且保持基础模型冻结。

Abstract: Efficient long-context LLM deployment is stalled by a dichotomy between amortized compression, which struggles with out-of-distribution generalization, and Test-Time Training, which incurs prohibitive synthetic data costs and requires modifying model weights, creating stateful parameters that complicate concurrent serving. We propose Latent Context Compilation, a framework that fundamentally shifts context processing from adaptation to compilation. By utilizing a disposable LoRA module as a compiler, we distill long contexts into compact buffer tokens -- stateless, portable memory artifacts that are plug-and-play compatible with frozen base models. Crucially, we introduce a self-aligned optimization strategy that eliminates the need for synthetic context-relevant QA pairs. By regularizing context reconstruction task with context-agnostic random queries, we force compressed tokens to reside within the model's existing instruction-following manifold. Experiments with Llama-3.1-8B demonstrate that Latent Context Compilation preserves fine-grained details and reasoning capabilities where prior methods falter, effectively decoupling memory density from model parameters even at a 16x compression ratio.

</details>


### [2] [AngelSlim: A more accessible, comprehensive, and efficient toolkit for large model compression](https://arxiv.org/abs/2602.21233)
*Rui Cen,QiangQiang Hu,Hong Huang,Hong Liu,Song Liu,Xin Luo,Lin Niu,Yifan Tan,Decheng Wu,Linchuan Xie,Rubing Yang,Guanghua Yu,Jianchen Zhu*

Main category: cs.LG

TL;DR: AngelSlim是腾讯混元团队开发的大模型压缩工具包，整合了量化、推测解码、token剪枝和蒸馏等前沿算法，提供从模型压缩到工业部署的统一流程。


<details>
  <summary>Details</summary>
Motivation: 随着大模型规模不断扩大，部署成本高昂且推理效率低下，需要一套全面的压缩工具来降低部署门槛并提升推理性能。

Method: 1. 集成FP8和INT8后训练量化算法，开发超低位量化技术（如2位大模型HY-1.8B-int2）
2. 提出训练对齐的推测解码框架，兼容多模态架构和现代推理引擎
3. 开发训练免费的稀疏注意力框架，通过静态模式和动态token选择的混合方式解耦稀疏核与模型架构
4. 针对多模态模型设计专门剪枝策略：IDPruner优化视觉token，Samp自适应合并和剪枝音频token

Result: 1. 实现了首个工业可行的2位大模型HY-1.8B-int2
2. 推测解码框架在不影响输出正确性的情况下实现1.8-2.0倍吞吐量提升
3. 稀疏注意力框架在长上下文场景中降低首token生成时间
4. 多模态剪枝策略有效优化视觉和音频token处理

Conclusion: AngelSlim通过整合多种压缩技术，为算法研究和工具辅助部署提供了完整解决方案，显著降低了大模型的部署成本和推理延迟。

Abstract: This technical report introduces AngelSlim, a comprehensive and versatile toolkit for large model compression developed by the Tencent Hunyuan team. By consolidating cutting-edge algorithms, including quantization, speculative decoding, token pruning, and distillation. AngelSlim provides a unified pipeline that streamlines the transition from model compression to industrial-scale deployment. To facilitate efficient acceleration, we integrate state-of-the-art FP8 and INT8 Post-Training Quantization (PTQ) algorithms alongside pioneering research in ultra-low-bit regimes, featuring HY-1.8B-int2 as the first industrially viable 2-bit large model. Beyond quantization, we propose a training-aligned speculative decoding framework compatible with multimodal architectures and modern inference engines, achieving 1.8x to 2.0x throughput gains without compromising output correctness. Furthermore, we develop a training-free sparse attention framework that reduces Time-to-First-Token (TTFT) in long-context scenarios by decoupling sparse kernels from model architectures through a hybrid of static patterns and dynamic token selection. For multimodal models, AngelSlim incorporates specialized pruning strategies, namely IDPruner for optimizing vision tokens via Maximal Marginal Relevance and Samp for adaptive audio token merging and pruning. By integrating these compression strategies from low-level implementations, AngelSlim enables algorithm-focused research and tool-assisted deployment.

</details>


### [3] [Group Orthogonalized Policy Optimization:Group Policy Optimization as Orthogonal Projection in Hilbert Space](https://arxiv.org/abs/2602.21269)
*Wang Zixian*

Main category: cs.LG

TL;DR: GOPO是一种基于希尔伯特函数空间几何的新对齐算法，通过将优化问题从概率单纯形提升到L2空间，利用线性正交条件和希尔伯特投影定理，实现了有界投影和精确稀疏性，在数学推理基准上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统对齐算法在概率单纯形上优化，继承了KL散度的指数曲率问题，导致梯度饱和和训练不稳定。需要一种基于函数空间几何的新方法，避免这些限制，同时保持稳定性和泛化能力。

Method: GOPO将对齐问题提升到希尔伯特空间L2(pi_k)，将单纯形约束转化为线性正交条件。通过希尔伯特投影定理最大化工作-耗散泛函，实施有界投影产生精确稀疏性。通过群采样投影到有限经验子空间，利用群归一化优势的零和特性消除拉格朗日乘子，得到具有恒定Hessian曲率和非饱和线性梯度的无约束经验损失。

Result: 在数学推理基准测试中，GOPO实现了竞争性的泛化性能，同时保持稳定的梯度动态和熵保留。在基于裁剪的方法达到平台期的情况下，GOPO仍能持续改进。

Conclusion: GOPO提供了一种基于希尔伯特空间几何的对齐新范式，避免了传统方法的指数曲率和梯度饱和问题，通过精确稀疏性和恒定曲率实现了更稳定高效的训练。

Abstract: We present Group Orthogonalized Policy Optimization (GOPO), a new alignment algorithm for large language models derived from the geometry of Hilbert function spaces. Instead of optimizing on the probability simplex and inheriting the exponential curvature of Kullback-Leibler divergence, GOPO lifts alignment into the Hilbert space L2(pi_k) of square-integrable functions with respect to the reference policy. Within this space, the simplex constraint reduces to a linear orthogonality condition <v, 1> = 0, defining a codimension-one subspace H0. Minimizing distance to an unconstrained target u_star yields the work-dissipation functional J(v) = <g, v> - (mu / 2) ||v||^2, whose maximizer follows directly from the Hilbert projection theorem. Enforcing the boundary v >= -1 produces a bounded Hilbert projection that induces exact sparsity, assigning zero probability to catastrophically poor actions through a closed-form threshold. To connect this functional theory with practice, GOPO projects from infinite-dimensional L2(pi_k) to a finite empirical subspace induced by group sampling. Because group-normalized advantages sum to zero, the Lagrange multiplier enforcing probability conservation vanishes exactly, reducing the constrained projection to an unconstrained empirical loss. The resulting objective has constant Hessian curvature mu I, non-saturating linear gradients, and an intrinsic dead-zone mechanism without heuristic clipping. Experiments on mathematical reasoning benchmarks show that GOPO achieves competitive generalization while maintaining stable gradient dynamics and entropy preservation in regimes where clipping-based methods plateau.

</details>


### [4] [Uncertainty-Aware Diffusion Model for Multimodal Highway Trajectory Prediction via DDIM Sampling](https://arxiv.org/abs/2602.21319)
*Marion Neumeier,Niklas Roßberg,Michael Botsch,Wolfgang Utschick*

Main category: cs.LG

TL;DR: cVMDx是一个改进的基于扩散模型的轨迹预测框架，通过DDIM采样实现100倍推理加速，使用高斯混合模型提供多模态预测，在highD数据集上表现出更高的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中准确且具有不确定性感知的轨迹预测面临核心挑战，包括复杂的多智能体交互、多样化的场景上下文以及未来运动的固有随机性。现有的基于扩散的生成模型如cVMD存在采样速度慢、生成多样性利用有限和场景编码脆弱等问题。

Method: 提出cVMDx增强框架：1) 采用DDIM采样技术大幅减少推理时间；2) 使用拟合的高斯混合模型从生成的轨迹中提取可处理的多模态预测；3) 评估CVQ-VAE变体用于场景编码。

Result: 在公开的highD数据集上，cVMDx相比cVMD实现了高达100倍的推理时间减少，同时达到更高的准确性，能够进行完全随机的多模态轨迹预测。

Conclusion: cVMDx通过改进采样效率和生成多样性，显著提升了基于扩散模型的轨迹预测框架的实用性和性能，为自动驾驶中的不确定性感知预测提供了有效解决方案。

Abstract: Accurate and uncertainty-aware trajectory prediction remains a core challenge for autonomous driving, driven by complex multi-agent interactions, diverse scene contexts and the inherently stochastic nature of future motion. Diffusion-based generative models have recently shown strong potential for capturing multimodal futures, yet existing approaches such as cVMD suffer from slow sampling, limited exploitation of generative diversity and brittle scenario encodings.
  This work introduces cVMDx, an enhanced diffusion-based trajectory prediction framework that improves efficiency, robustness and multimodal predictive capability. Through DDIM sampling, cVMDx achieves up to a 100x reduction in inference time, enabling practical multi-sample generation for uncertainty estimation. A fitted Gaussian Mixture Model further provides tractable multimodal predictions from the generated trajectories. In addition, a CVQ-VAE variant is evaluated for scenario encoding. Experiments on the publicly available highD dataset show that cVMDx achieves higher accuracy and significantly improved efficiency over cVMD, enabling fully stochastic, multimodal trajectory prediction.

</details>


### [5] [Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual](https://arxiv.org/abs/2602.22146)
*Yining Li,Peizhong Ju,Ness Shroff*

Main category: cs.LG

TL;DR: 提出了一种通用的原始-对偶框架统一现有对齐算法，并引入乐观原始-对偶算法来解决RLHF中的收敛不稳定问题


<details>
  <summary>Details</summary>
Motivation: RLHF在大型语言模型对齐中起重要作用，但标准原始-对偶方法存在收敛不稳定问题，特别是在策略参数化情况下可能发散

Method: 提出通用原始-对偶框架统一现有对齐算法，引入乐观原始-对偶算法，包含原始变量和对偶变量的预测更新以稳定鞍点动态

Result: 建立了最后迭代收敛保证，涵盖分布空间中的精确策略优化以及在参数化策略下收敛到最优解邻域，邻域大小与近似误差和偏差相关

Conclusion: 乐观机制在缓解约束对齐目标固有振荡中起关键作用，填补了约束强化学习与实用RLHF之间的理论空白

Abstract: Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences. While RLHF with expected reward constraints can be formulated as a primal-dual optimization problem, standard primal-dual methods only guarantee convergence with a distributional policy where the saddle-point problem is in convex-concave form. Moreover, standard primal-dual methods may exhibit instability or divergence in the last iterate under policy parameterization in practical applications. In this work, we propose a universal primal-dual framework for safe RLHF that unifies a broad class of existing alignment algorithms, including safe-RLHF, one-shot, and multi-shot based methods. Building on this framework, we introduce an optimistic primal-dual (OPD) algorithm that incorporates predictive updates for both primal and dual variables to stabilize saddle-point dynamics. We establish last-iterate convergence guarantees for the proposed method, covering both exact policy optimization in the distributional space and convergence to a neighborhood of the optimal solution whose gap is related to approximation error and bias under parameterized policies. Our analysis reveals that optimism plays a crucial role in mitigating oscillations inherent to constrained alignment objectives, thereby closing a key theoretical gap between constrained RL and practical RLHF.

</details>


### [6] [GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL](https://arxiv.org/abs/2602.22190)
*Rui Yang,Qianhui Wu,Zhaoyang Wang,Hanyang Chen,Ke Yang,Hao Cheng,Huaxiu Yao,Baoling Peng,Huan Zhang,Jianfeng Gao,Tong Zhang*

Main category: cs.LG

TL;DR: GUI-Libra提出针对GUI智能体的定制化训练方案，解决开源GUI智能体在长时程导航任务中落后于闭源系统的问题，通过数据构建、动作感知SFT和KL正则化RL等方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 开源原生GUI智能体在长时程导航任务上仍落后于闭源系统，主要原因是缺乏高质量的动作对齐推理数据，以及直接采用通用后训练流程而忽视了GUI智能体的独特挑战。

Method: 1) 构建和过滤数据管道，发布81K GUI推理数据集；2) 提出动作感知SFT，混合推理-动作和直接动作数据，重新加权token以强调动作和接地；3) 在部分可验证性下稳定RL，强调KL正则化的重要性，引入成功自适应缩放来降低不可靠负梯度权重。

Result: 在多样化的网页和移动端基准测试中，GUI-Libra持续提升了步进准确率和端到端任务完成率，表明精心设计的后训练和数据管理可以显著增强任务解决能力，无需昂贵的在线数据收集。

Conclusion: 通过针对性的数据管理和训练方法设计，可以有效提升GUI智能体的性能，为推理能力强的GUI智能体的数据高效后训练研究提供了新的方向。

Abstract: Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks. This gap stems from two limitations: a shortage of high-quality, action-aligned reasoning data, and the direct adoption of generic post-training pipelines that overlook the unique challenges of GUI agents. We identify two fundamental issues in these pipelines: (i) standard SFT with CoT reasoning often hurts grounding, and (ii) step-wise RLVR-tyle training faces partial verifiability, where multiple actions can be correct but only a single demonstrated action is used for verification. This makes offline step-wise metrics weak predictors of online task success. In this work, we present GUI-Libra, a tailored training recipe that addresses these challenges. First, to mitigate the scarcity of action-aligned reasoning data, we introduce a data construction and filtering pipeline and release a curated 81K GUI reasoning dataset. Second, to reconcile reasoning with grounding, we propose action-aware SFT that mixes reasoning-then-action and direct-action data and reweights tokens to emphasize action and grounding. Third, to stabilize RL under partial verifiability, we identify the overlooked importance of KL regularization in RLVR and show that a KL trust region is critical for improving offline-to-online predictability; we further introduce success-adaptive scaling to downweight unreliable negative gradients. Across diverse web and mobile benchmarks, GUI-Libra consistently improves both step-wise accuracy and end-to-end task completion. Our results suggest that carefully designed post-training and data curation can unlock significantly stronger task-solving capabilities without costly online data collection. We release our dataset, code, and models to facilitate further research on data-efficient post-training for reasoning-capable GUI agents.

</details>


### [7] [Sample Complexity Bounds for Robust Mean Estimation with Mean-Shift Contamination](https://arxiv.org/abs/2602.22130)
*Ilias Diakonikolas,Giannis Iakovidis,Daniel M. Kane,Sihan Liu*

Main category: cs.LG

TL;DR: 该论文研究了均值偏移污染模型下的均值估计问题，证明了在温和的光谱条件下，存在样本高效的算法可以估计目标均值，并给出了匹配的样本复杂度下界。


<details>
  <summary>Details</summary>
Motivation: 先前的研究仅针对高斯分布和拉普拉斯分布等特殊情况分析了均值偏移污染模型的样本复杂度，但对于一般基础分布的均值估计样本复杂度仍是一个开放问题。本文旨在解决这个开放问题。

Method: 使用傅里叶分析技术，特别是引入了傅里叶见证的概念，作为上下界证明的关键工具。在温和的光谱条件下，提出了样本高效的均值估计算法。

Result: 证明了在温和的光谱条件下，存在样本高效的算法可以估计目标均值到任意所需精度。同时给出了与上界在质量上匹配的样本复杂度下界。

Conclusion: 本文基本解决了均值偏移污染模型中一般基础分布的均值估计样本复杂度问题，表明在温和条件下存在样本高效的估计算法，并建立了匹配的上下界。

Abstract: We study the basic task of mean estimation in the presence of mean-shift contamination. In the mean-shift contamination model, an adversary is allowed to replace a small constant fraction of the clean samples by samples drawn from arbitrarily shifted versions of the base distribution. Prior work characterized the sample complexity of this task for the special cases of the Gaussian and Laplace distributions. Specifically, it was shown that consistent estimation is possible in these cases, a property that is provably impossible in Huber's contamination model. An open question posed in earlier work was to determine the sample complexity of mean estimation in the mean-shift contamination model for general base distributions. In this work, we study and essentially resolve this open question. Specifically, we show that, under mild spectral conditions on the characteristic function of the (potentially multivariate) base distribution, there exists a sample-efficient algorithm that estimates the target mean to any desired accuracy. We complement our upper bound with a qualitatively matching sample complexity lower bound. Our techniques make critical use of Fourier analysis, and in particular introduce the notion of a Fourier witness as an essential ingredient of our upper and lower bounds.

</details>


### [8] [Learning and Naming Subgroups with Exceptional Survival Characteristics](https://arxiv.org/abs/2602.22179)
*Mhd Jawad Al Rahwanji,Sascha Xu,Nils Philipp Walter,Jilles Vreeken*

Main category: cs.LG

TL;DR: Sysurv是一种完全可微分的非参数方法，利用随机生存森林学习个体生存曲线，自动学习条件并将其组合成可解释的规则，以识别具有异常生存特征的亚群。


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，识别生存时间更长或更短的亚群非常重要。现有方法需要限制性假设（如比例风险）、预离散化特征，并且由于比较平均统计量而容易忽略个体偏差。

Method: 提出Sysurv方法：完全可微分、非参数，利用随机生存森林学习个体生存曲线，自动学习条件并将其组合成内在可解释的规则。

Result: 在广泛的数据集和设置上进行实证评估，包括癌症数据的案例研究，显示Sysurv能够揭示有洞察力和可操作的生存亚群。

Conclusion: Sysurv是一种有效的非参数方法，能够自动识别具有异常生存特征的亚群，无需限制性假设，并能生成可解释的规则。

Abstract: In many applications, it is important to identify subpopulations that survive longer or shorter than the rest of the population. In medicine, for example, it allows determining which patients benefit from treatment, and in predictive maintenance, which components are more likely to fail. Existing methods for discovering subgroups with exceptional survival characteristics require restrictive assumptions about the survival model (e.g. proportional hazards), pre-discretized features, and, as they compare average statistics, tend to overlook individual deviations. In this paper, we propose Sysurv, a fully differentiable, non-parametric method that leverages random survival forests to learn individual survival curves, automatically learns conditions and how to combine these into inherently interpretable rules, so as to select subgroups with exceptional survival characteristics. Empirical evaluation on a wide range of datasets and settings, including a case study on cancer data, shows that Sysurv reveals insightful and actionable survival subgroups.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [9] [SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents](https://arxiv.org/abs/2602.22124)
*Patrick Tser Jern Kon,Archana Pradeep,Ang Chen,Alexander P. Ellis,Warren Hunt,Zijian Wang,John Yang,Samuel Thompson*

Main category: cs.SE

TL;DR: SWE-Protégé是一个后训练框架，通过专家-学徒协作方式提升小语言模型在软件工程任务上的性能，将Qwen2.5-Coder-7B-Instruct在SWE-bench Verified上的Pass@1提升到42.4%，相比之前最佳SLM提升25.4%


<details>
  <summary>Details</summary>
Motivation: 小语言模型在成本、延迟和适应性方面有优势，但在SWE-bench等长视野软件工程任务上表现不佳，存在普遍的动作循环和低解决率问题

Method: 提出SWE-Protégé框架，将软件修复重构为专家-学徒协作问题。SLM作为唯一决策者，学习选择性寻求专家指导、识别停滞状态并执行专家反馈。结合专家增强轨迹的监督微调和显式阻止退化循环及无效专家协作的智能强化学习

Result: 对Qwen2.5-Coder-7B-Instruct进行轻量后训练，在SWE-bench Verified上达到42.4% Pass@1，相比之前最佳SLM提升25.4%，同时稀疏使用专家协助（约4次调用/任务，占总token的11%）

Conclusion: SWE-Protégé框架有效解决了SLM在软件工程任务中的动作循环问题，通过智能的专家协作机制显著提升了性能，为资源受限环境下的软件修复提供了高效解决方案

Abstract: Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-Protégé, a post-training framework that reframes software repair as an expert-protégé collaboration problem. In SWE-Protégé, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [A Dynamic Survey of Soft Set Theory and Its Extensions](https://arxiv.org/abs/2602.21268)
*Takaaki Fujita,Florentin Smarandache*

Main category: cs.AI

TL;DR: 本书对软集理论及其主要扩展进行了综述性概述，涵盖核心定义、代表性构造和当前发展方向。


<details>
  <summary>Details</summary>
Motivation: 软集理论为参数化决策建模提供了直接框架，通过将每个属性（参数）分配给给定宇宙的子集来结构化表示不确定性。该理论在过去几十年已扩展到多个变体，并与拓扑学、拟阵理论等多个领域建立了联系。

Method: 采用调查式概述方法，系统整理软集理论及其主要扩展，包括超软集、超超软集、树软集、双极软集和动态软集等变体，突出核心定义和代表性构造。

Result: 提供了软集理论及其扩展的全面综述，展示了该理论的发展脉络、主要变体以及与不同数学领域的连接关系。

Conclusion: 本书通过系统梳理软集理论及其扩展，为该领域的研究者提供了全面的参考框架，并指明了当前的发展方向和潜在的研究机会。

Abstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets-and has been connected to diverse areas such as topology and matroid theory. In this book, we present a survey-style overview of soft sets and their major extensions, highlighting core definitions, representative constructions, and key directions of current development.

</details>


### [11] [A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives](https://arxiv.org/abs/2602.21351)
*Dmitrii Pantiukhin,Ivan Kuznetsov,Boris Shapkin,Antonia Anna Jost,Thomas Jung,Nikolay Koldunov*

Main category: cs.AI

TL;DR: PANGAEA-GPT：一个用于地球科学数据自主发现和分析的分层多智能体框架，通过集中式监督-工作者拓扑结构解决数据可扩展性挑战


<details>
  <summary>Details</summary>
Motivation: 地球科学数据快速积累导致可扩展性挑战，PANGAEA等存储库中大量数据集未被充分利用，限制了数据重用性。需要一种能够自主发现和分析异构存储库数据的方法。

Method: 提出PANGAEA-GPT分层多智能体框架，采用集中式监督-工作者拓扑结构，具有严格的数据类型感知路由、沙盒化确定性代码执行和通过执行反馈的自我校正机制，使智能体能够诊断和解决运行时错误。

Result: 通过物理海洋学和生态学的用例场景，展示了系统能够以最少的人工干预执行复杂的多步骤工作流程，证明了框架在查询和分析异构存储库数据方面的能力。

Conclusion: 该框架提供了一种通过协调智能体工作流程查询和分析异构存储库数据的方法论，为解决地球科学数据可扩展性挑战提供了有效解决方案。

Abstract: The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.

</details>


### [12] [ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning](https://arxiv.org/abs/2602.21534)
*Xiaoxuan Wang,Han Zhang,Haixin Wang,Yidan Shi,Ruoyan Li,Kaiqiao Han,Chenyi Tong,Haoran Deng,Renliang Sun,Alexander Taylor,Yanqiao Zhu,Jason Cong,Yizhou Sun,Wei Wang*

Main category: cs.AI

TL;DR: 该论文提出了ARLArena框架和SAMPO方法，旨在解决Agentic强化学习（ARL）训练不稳定的问题，为LLM智能体训练提供稳定可靠的解决方案。


<details>
  <summary>Details</summary>
Motivation: Agentic强化学习（ARL）在处理复杂多步交互任务方面显示出潜力，但训练过程极不稳定，经常导致训练崩溃。这种不稳定性限制了ARL在更大环境和更长交互时间尺度上的可扩展性，也制约了算法设计的系统性探索。

Method: 首先提出ARLArena框架，包括：1）构建干净标准化的测试平台；2）将策略梯度分解为四个核心设计维度并评估每个维度的性能和稳定性。基于此分析，提出SAMPO方法——一种稳定的Agentic策略优化方法，专门设计来缓解ARL中的主要不稳定因素。

Result: SAMPO在各种Agentic任务中实现了持续稳定的训练和强大的性能表现。该研究为ARL提供了统一的策略梯度视角，并为构建稳定可复现的LLM智能体训练流程提供了实用指导。

Conclusion: 该研究通过ARLArena框架和SAMPO方法，成功解决了Agentic强化学习训练不稳定的核心问题，为LLM智能体训练提供了系统化的分析和优化方案，推动了该领域的可重复性和稳定性发展。

Abstract: Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines.

</details>


### [13] [Distill and Align Decomposition for Enhanced Claim Verification](https://arxiv.org/abs/2602.21857)
*Jabez Magomere,Elena Kochkina,Samuel Mensah,Simerjot Kaur,Fernando Acero,Arturo Oncevay,Charese H. Smiley,Xiaomo Liu,Manuela Veloso*

Main category: cs.AI

TL;DR: 提出强化学习方法，通过联合优化分解质量和验证器对齐，提升复杂声明验证性能


<details>
  <summary>Details</summary>
Motivation: 现有方法难以将分解质量与验证性能对齐，需要更好的联合优化方法

Method: 使用Group Relative Policy Optimization强化学习框架，结合结构化顺序推理、教师蒸馏示例的监督微调，以及平衡格式合规性、验证器对齐和分解质量的多目标奖励

Result: 在六个评估设置中，训练的8B分解器将下游验证性能提升至71.75% macro-F1，优于提示方法（+1.99，+6.24）和现有RL方法（+5.84），人类评估确认生成子声明的高质量

Conclusion: 该框架使较小语言模型通过联合优化验证准确性和分解质量，实现最先进的声明验证性能

Abstract: Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.

</details>


### [14] [ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices](https://arxiv.org/abs/2602.21858)
*Dezhi Kong,Zhengzhao Feng,Qiliang Liang,Hao Wang,Haofei Sun,Changpeng Yang,Yang Li,Peng Zhou,Shuai Nie,Hongzhen Wang,Linfeng Zhou,Hao Jia,Jiaming Xu,Runyu Shi,Ying Huang*

Main category: cs.AI

TL;DR: ProactiveMobile是一个用于评估移动智能体主动智能能力的基准测试，包含3,660个实例、14个场景和63个API函数，旨在解决当前多模态大语言模型在主动预测用户需求方面的能力不足问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在移动智能体开发中主要局限于被动执行用户命令的反应式范式，而主动智能（智能体自主预测需求并启动行动）是移动智能体的下一个前沿领域，但缺乏能够应对现实世界复杂性并支持客观可执行评估的基准测试。

Method: 提出ProactiveMobile基准测试，将主动任务形式化为基于设备上下文信号的四个维度推断潜在用户意图，并从包含63个API的全面函数池中生成可执行函数序列。基准包含3,660个实例、14个场景，采用多答案标注来应对现实复杂性，并由30名专家团队进行最终审核，确保事实准确性、逻辑一致性和行动可行性。

Result: 实验表明，微调的Qwen2.5-VL-7B-Instruct模型实现了19.15%的成功率，优于o1（15.71%）和GPT-5（7.39%）。这表明主动智能是当前MLLMs普遍缺乏但可学习的关键能力。

Conclusion: 主动智能是当前多模态大语言模型普遍缺乏但可通过学习获得的关键能力，ProactiveMobile基准测试对于评估和推动主动智能研究具有重要意义，为移动智能体的主动智能发展提供了系统化的评估框架。

Abstract: Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.

</details>


### [15] [Semantic Partial Grounding via LLMs](https://arxiv.org/abs/2602.22067)
*Giuseppe Canonaco,Alberto Pozanco,Daniel Borrajo*

Main category: cs.AI

TL;DR: SPG-LLM使用大语言模型分析PDDL描述，在规划任务接地前识别潜在无关的对象、动作和谓词，大幅减少接地任务规模，显著提升接地速度。


<details>
  <summary>Details</summary>
Motivation: 传统规划中的接地步骤常因任务规模增大导致接地动作和原子呈指数增长而成为计算瓶颈。现有部分接地方法主要依赖关系特征或学习嵌入，未能充分利用PDDL描述中的文本和结构信息。

Method: 提出SPG-LLM方法，利用大语言模型分析领域和问题文件，在接地前启发式识别潜在无关的对象、动作和谓词，从而显著减少接地任务规模。

Result: 在七个难以接地的基准测试中，SPG-LLM实现了更快的接地速度（通常快几个数量级），在某些领域还提供了相当或更好的规划成本。

Conclusion: SPG-LLM通过利用大语言模型分析PDDL的文本和结构信息，有效解决了规划接地中的计算瓶颈问题，显著提升了接地效率。

Abstract: Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.

</details>
