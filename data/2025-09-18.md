<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 83]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.CY](#cs.CY) [Total: 19]
- [cs.LG](#cs.LG) [Total: 55]
- [cs.AI](#cs.AI) [Total: 25]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

TL;DR: 提出基于证据检索的不确定性感知决策机制，用实例自适应的证据条件阈值替代全局固定阈值，通过Dempster-Shafer理论融合近邻样本预测分布，实现更可靠和可解释的决策


<details>
  <summary>Details</summary>
Motivation: 传统基于预测熵的全局阈值方法存在置信错误预测较多的问题，需要一种更可靠、透明且可审计的不确定性感知决策方法

Method: 为每个测试实例在嵌入空间中检索近邻样本，使用Dempster-Shafer理论融合这些证据样本的预测分布，生成每个实例自适应的阈值标准

Result: 在CIFAR-10/100数据集上，使用BiT和ViT骨干网络，相比预测熵阈值方法，取得了相当或更好的不确定性感知性能，显著减少了置信错误预测，且只需少量证据样本即可实现这些改进

Conclusion: 证据条件标记为操作不确定性感知决策提供了比固定预测熵阈值更可靠和可解释的替代方案，支持透明和可审计的决策过程

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [2] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

TL;DR: 混合量子-经典神经网络在准确率、训练效率和参数可扩展性方面优于纯经典模型，特别是在复杂视觉任务中表现突出


<details>
  <summary>Details</summary>
Motivation: 系统比较混合量子-经典神经网络与纯经典模型在性能、效率和鲁棒性方面的差异，评估量子计算在深度学习中的实际价值

Method: 在三个基准数据集（MNIST、CIFAR100、STL10）上对比混合模型（参数化量子电路+经典深度学习架构）和经典CNN模型，进行50个训练轮次，评估验证准确率、测试准确率、训练时间、计算资源使用和对抗鲁棒性

Result: 混合模型在所有数据集上准确率更高（MNIST: 99.38% vs 98.21%, CIFAR100: 41.69% vs 32.25%, STL10: 74.05% vs 63.76%），训练速度快5-12倍，参数减少6-32%，内存和CPU使用更低，在简单数据集上对抗鲁棒性显著更好

Conclusion: 混合量子-经典架构在准确率、训练效率和参数可扩展性方面具有明显优势，特别适合复杂视觉任务，为量子计算在深度学习中的应用提供了有力证据

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [3] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的方法，利用地球观测卫星图像对检测亚马逊雨林砍伐，并通过视觉语义模型自动生成相关标注


<details>
  <summary>Details</summary>
Motivation: 亚马逊雨林是全球重要的生态系统，砍伐对碳排放和生物多样性有重大影响，需要有效的监测工具

Method: 使用深度学习技术比较不同时期的卫星图像对，检测森林覆盖变化，并从科学文献中提取关键词自动标注检测到的变化

Result: 在亚马逊图像对数据集上验证了方法的有效性，能够准确检测砍伐并生成相关标注

Conclusion: 该方法为监测和研究亚马逊砍伐影响提供了有用工具，虽然专注于环境应用，但具有通用性可扩展到其他领域

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>


### [4] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

TL;DR: 该研究提出了一种高速公路交通拥堵综合技术框架，通过优化车辆感知算法和改进交通流预测模型，解决了现有系统在遮挡条件下感知精度低和长序列依赖丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 高速公路交通拥堵严重降低出行效率并阻碍区域连通性。现有的'检测-预测'系统存在关键缺陷：遮挡条件下车辆感知精度低，以及拥堵预测中长序列依赖关系的丢失。

Method: 1) 车辆感知：将YOLOv11优化为YOLOv11-DIoU（用DIoU Loss替换GIoU Loss），改进DeepSort算法（融合马氏距离和余弦距离）；2) 拥堵预警：构建GRU-Attention模型，使用流量、密度和速度数据进行训练；3) 使用Greenberg模型分析高密度场景下的交通流特性。

Result: YOLOv11-DIoU达到95.7% mAP（比基线高6.5个百分点），遮挡漏检率5.3%；DeepSort达到93.8% MOTA（比SORT高11.3个百分点）；GRU-Attention模型测试准确率达99.7%（比传统GRU高7-9个百分点），10分钟提前预警时间误差≤1分钟，独立视频验证显示95%预警准确率。

Conclusion: 该框架为高速公路拥堵控制提供了量化支持，在智能交通应用中具有广阔前景，能够有效提升交通感知精度和拥堵预警能力。

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [5] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

TL;DR: 使用卷积神经网络自动化路边停车服务的测试流程，将人工资源时间减少99.58%


<details>
  <summary>Details</summary>
Motivation: 优化基于众包车辆数据的实时路边停车服务质量，通过自动化现有地面实况测试流程来替代人工工程工作

Method: 应用机器学习和图像模式识别方法，特别是卷积神经网络，来自动化分析过程并丰富数据库

Result: 实现了高度自动化水平，人工资源时间减少高达99.58%

Conclusion: 自动化分析工具显著提高了效率，为未来发展和潜在应用提供了良好前景

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [6] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文系统分析了基于视觉语言模型(VLM)的零样本分布外检测机制，揭示了VLM在语义新颖性利用方面的优势，同时发现其对提示词措辞高度敏感的关键脆弱性


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等视觉语言模型在零样本分布外检测方面表现出色，但研究界对其工作机制、相对于单模态方法的优势以及行为鲁棒性缺乏系统理解

Method: 使用分布内和分布外提示词进行系统性实证分析，包括：(1)形式化VLM嵌入空间的关键操作特性；(2)量化比较VLM与单模态方法；(3)评估模型对图像噪声和提示词措辞的敏感性

Result: VLM在零样本分布外检测中优于单模态方法，主要优势在于能够利用丰富的语义新颖性；同时发现VLM对常见图像噪声具有鲁棒性，但对提示词措辞高度敏感的不对称鲁棒性特征

Conclusion: 研究提供了对VLM基于分布外检测优势和关键脆弱性的结构化理解，为开发更鲁棒可靠的未来设计提供了实证基础指导

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [7] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

TL;DR: 基于截面曲率概念构建离散度量空间的几何剖面，提出评估数据表示有效性的定量方法，并能估计数据集本征维度


<details>
  <summary>Details</summary>
Motivation: 利用新发展的截面曲率抽象概念来分析离散度量空间的几何特性，为评估维度约简技术效果提供量化指标

Method: 通过捕获点三元组与其他点之间的度量关系来构建曲率剖面，基于此剖面设计数据表示有效性的评估方法

Result: 实验证明曲率分析可用于估计数据集本征维度，探索经验网络的大规模几何结构，评估维度约简技术效果

Conclusion: 曲率剖面为离散度量空间提供了有效的几何分析工具，在数据表示评估和本征维度估计方面具有实用价值

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [8] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

TL;DR: 本研究使用机器学习和遥感技术分析斐济纳迪地区2013-2024年的土地利用变化，通过Landsat-8卫星影像、k-means聚类和卷积神经网络进行土地覆盖分类和变化检测。


<details>
  <summary>Details</summary>
Motivation: 斐济作为发展中国家正经历快速城市化，需要技术支持来监测土地利用变化，为城市规划和发展项目提供科学依据。

Method: 使用Google Earth Engine平台处理Landsat-8卫星影像，结合k-means无监督聚类和卷积神经网络进行土地覆盖分类，创建训练数据集进行监督学习。

Result: 生成了土地覆盖变化可视化图，突出了城市区域随时间的变化，成功监测了地图上的变化情况。

Conclusion: 该研究为土地利用建模和变化检测提供了有效的技术框架，能够支持斐济的城市化进程监测和规划工作。

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


### [9] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

TL;DR: 提出了一种用于电力传输系统实时异物入侵检测与跟踪的三阶段框架，结合YOLOv7分割、ConvNeXt特征提取和特征辅助IoU跟踪器，支持边缘设备部署和增量更新。


<details>
  <summary>Details</summary>
Motivation: 电力传输系统中异物入侵检测对电网安全至关重要，需要实时、准确且能在边缘设备上运行的解决方案，同时要处理遮挡、运动等复杂场景并支持新物体识别。

Method: 三阶段框架：1) YOLOv7分割模型进行快速目标定位；2) ConvNeXt特征提取器配合三元组损失生成判别性嵌入；3) 特征辅助IoU跟踪器实现遮挡和运动下的鲁棒多目标跟踪。采用混合精度推理优化边缘部署。

Result: 在真实监控和无人机视频数据集上的广泛实验表明，该框架在各种异物入侵场景下具有高准确性和鲁棒性。在NVIDIA Jetson设备上的硬件基准测试证实了其在实际边缘应用中的实用性和可扩展性。

Conclusion: 该框架为电力传输系统提供了一种高效、实时的异物入侵检测与跟踪解决方案，支持边缘部署和增量学习，具有良好的实际应用前景。

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [10] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

TL;DR: EdiVal-Agent是一个自动化、可扩展的图像编辑评估框架，通过对象中心视角和多专家工具集成，解决了当前评估方法的局限性，在指令遵循评估方面与人类判断有更强一致性。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑评估方法存在两个主要问题：(i)依赖配对参考图像导致覆盖范围有限且继承生成模型偏见，(ii)仅依赖零样本视觉语言模型的评估往往不精确。需要更可靠、可解释的评估框架。

Method: EdiVal-Agent首先将图像分解为语义对象，然后合成多样化的上下文感知编辑指令。评估时集成VLM与开放词汇对象检测器评估指令遵循，使用语义级特征提取器评估内容一致性，利用人类偏好模型判断视觉质量。

Result: 结合VLM和对象检测器在指令遵循评估方面比单独使用VLM和CLIP指标与人类判断有更强一致性。模块化设计支持未来工具集成，持续提升评估准确性。

Conclusion: EdiVal-Agent能够识别现有失败模式，为下一代编辑模型的开发提供信息，建立了EdiVal-Bench基准，覆盖9种指令类型和11种最先进的编辑模型。

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [11] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything是一个统一的基于transformer的前馈模型，能够通过单次前向传播处理多种3D视觉任务，包括未标定运动恢复结构、多视图立体视觉、单目深度估计等，性能优于或匹配专用模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D视觉任务中需要多个专用模型的问题，研究者希望开发一个统一的模型来处理多种3D重建任务，提高效率和通用性。

Method: 使用基于transformer的前馈架构，输入图像和可选几何信息（相机内参、位姿、深度等），通过分解的多视图场景几何表示（深度图、局部射线图、相机位姿和尺度因子）直接回归度量3D场景几何和相机参数。

Result: 实验表明MapAnything在多个3D视觉任务上优于或匹配专用前馈模型，同时展现出更高效的联合训练特性。

Conclusion: MapAnything为构建通用3D重建骨干网络奠定了基础，展示了单一模型处理多种3D视觉任务的潜力。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [12] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

TL;DR: 提出SCM-PR框架，通过融合RGB图像的语义信息与LiDAR地图进行跨模态地点识别，解决了传统RGB方法对光照、天气变化的敏感性问题，在复杂场景和视角变化下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决GPS不可用环境下机器人定位问题，传统RGB-based VPR方法对光照、天气等环境变化敏感，现有跨模态方法在复杂场景、细粒度匹配和视角变化下表现不佳。

Method: 使用VMamba骨干网络提取RGB图像特征；提出语义感知特征融合(SAFF)模块结合地点描述符和分割掩码；设计包含语义和几何信息的LiDAR描述符；在NetVLAD中引入跨模态语义注意力机制；设计多视角语义-几何匹配和语义一致性损失函数。

Result: 在KITTI和KITTI-360数据集上实现了最先进的性能，相比其他跨模态地点识别方法表现更优。

Conclusion: SCM-PR框架通过有效融合语义信息，显著提升了跨模态地点识别的鲁棒性和准确性，特别是在复杂环境和视角变化条件下。

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [13] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于场景自适应格点矢量量化(SALVQ)的3D高斯泼溅压缩方法，替代传统的均匀标量量化，在保持低复杂度的同时显著提升率失真性能。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术虽然渲染质量高且实时性好，但数据量巨大需要压缩。现有方法都使用简单的均匀标量量化，但更先进的量化器可能带来更好的压缩效果。

Method: 使用格点矢量量化(LVQ)替代均匀标量量化，并为每个场景优化格点基向量，实现场景自适应。通过缩放格点基向量可以动态调整压缩率。

Result: SALVQ在保持低复杂度的同时显著提升了率失真性能，可以无缝集成到现有压缩架构中，且单个模型就能支持多种压缩率目标。

Conclusion: 场景自适应格点矢量量化为3D高斯泼溅压缩提供了一种高效灵活的解决方案，在最小化系统改动和计算开销的情况下显著改善了压缩性能。

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [14] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

TL;DR: 提出了MINGLE方法，通过三阶段管道检测图像中的社交群体区域，包括人体检测、VLM社交关系分类和空间聚合算法，并发布了包含10万张街景图像的数据集


<details>
  <summary>Details</summary>
Motivation: 理解公共场所的群体社交互动对城市规划至关重要，但传统目标检测无法捕捉复杂的社交语义信号，需要新的方法来检测和定位社交群体

Method: 三阶段模块化管道：1) 现成的人体检测和深度估计 2) 基于VLM的成对社交关系分类 3) 轻量级空间聚合算法定位社交连接群体

Result: 开发了MINGLE方法并构建了包含10万张城市街景图像的新数据集，标注了个人和社交互动群体的边界框和标签

Conclusion: 该方法能够有效检测和定位图像中的社交群体区域，为城市规划和社会互动研究提供了新的技术手段和数据集支持

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [15] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

TL;DR: BiasMap是一个模型无关的框架，用于发现稳定扩散模型中的潜在概念级表征偏见，通过交叉注意力归因图揭示人口统计特征与语义概念的结构性纠缠，并提出基于能量引导扩散采样的偏见缓解方法。


<details>
  <summary>Details</summary>
Motivation: 现有偏见发现方法主要关注输出层面的人口统计分布，无法保证偏见缓解后概念表征的解耦。需要更深入地探索生成过程中的表征偏见。

Method: 利用交叉注意力归因图量化人口统计特征与语义概念的空间纠缠（通过IoU指标），并采用能量引导扩散采样方法在去噪过程中直接修改潜在噪声空间以最小化SoftIoU期望值。

Result: 研究发现现有公平性干预措施可能减少输出分布差距，但往往无法解耦概念级耦合，而BiasMap的缓解方法能够在图像生成中减轻概念纠缠，同时补充分布偏见缓解。

Conclusion: BiasMap提供了一个新的视角来发现和缓解TTI模型中的表征偏见，超越了传统的输出层面分析方法，能够揭示和解决更深层次的概念纠缠问题。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [16] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

TL;DR: LivePyxel是一个基于Python的实时图像标注工具，可直接连接成像设备进行实时标注，解决了传统标注工具需要预先收集数据的限制


<details>
  <summary>Details</summary>
Motivation: 现有图像标注软件需要用户上传预先收集的数据集，限制了按需流水线的支持，在实验室实时数据采集环境中尤其成问题

Method: 开发基于Python的图形用户界面，集成网络摄像头、显微镜等成像系统，提供贝塞尔曲线、二值掩码等专业标注工具，使用OpenCV和Numpy进行高性能处理

Result: 实现了实时图像标注功能，支持非破坏性图层编辑，具有广泛的视频设备兼容性，优化了目标检测操作

Conclusion: LivePyxel简化了数据收集和标注流程，加速了实验工作流中AI模型的开发，该软件已在GitHub上开源提供

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [17] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

TL;DR: 本文提出了DEFT-VTON方法，通过Doob's h-transform高效微调和自适应一致性损失，在仅训练1.42%参数的情况下实现高质量虚拟试穿，推理步骤减少到15步。


<details>
  <summary>Details</summary>
Motivation: 现实应用中虚拟试穿(VTO)需要有限的训练和推理资源，而现有方法依赖大型预训练模型的端到端训练，计算成本高昂。

Method: 采用DEFT高效微调技术冻结预训练模型参数，训练小型h-transform网络学习条件变换；提出自适应一致性损失，将一致性损失和去噪得分匹配损失以数据自适应方式结合。

Result: DEFT-VTON在VTO任务上达到最先进性能，仅需15个去噪步骤，参数训练量仅为传统PEFT方法的1.42%（对比基准5.52%）。

Conclusion: 该方法在保持竞争力的同时显著降低了计算成本和推理时间，为实际部署提供了高效解决方案。

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [18] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

TL;DR: 使用数据增强技术生成包含VRU（弱势道路使用者）的自定义交通场景，通过新颖的生成对抗网络架构学习数据集光照条件，提升Cityscapes数据集中虚拟行人的真实感，改善行人识别性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要合成数据来覆盖特定交通场景，但合成数据与真实数据之间存在域差距问题。本文旨在通过数据增强生成包含行人的定制交通场景，以提升行人识别能力。

Method: 提出一个用于增强Cityscapes数据集的流程，在其中添加虚拟行人。开发了一种新颖的生成对抗网络架构，用于对抗学习数据集的光照条件，从而提高增强数据的真实感。

Result: 在语义分割和实例分割任务上对方法进行了评估，验证了所提方法的有效性。

Conclusion: 通过数据增强和生成对抗网络技术，成功提升了合成数据的真实感，为自动驾驶系统中的行人识别提供了有效的解决方案。

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [19] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

TL;DR: 提出了FunKAN网络，一种专门为图像处理设计的可解释神经网络框架，在医学图像增强和分割任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法架构复杂且可解释性有限，而Kolmogorov-Arnold网络虽然可解释但会破坏图像的空间结构特征

Method: 基于函数空间推广Kolmogorov-Arnold表示定理，使用傅里叶分解和Hermite函数基学习内部函数，提出FunKAN用于图像增强和U-FunKAN用于分割

Result: 在IXI数据集上实现MRI吉布斯伪影抑制，在BUSI、GlaS、CVC-ClinicDB三个医学数据集上实现乳腺癌、腺体和息肉检测，各项指标均优于其他KAN基础模型

Conclusion: 该工作填补了理论函数逼近与医学图像分析之间的空白，为临床应用提供了鲁棒且可解释的解决方案

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [20] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态双流图神经网络模型，用于仇恨视频检测，通过分离视频实例并分配重要性权重来突出仇恨内容，在公开数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态分类方法通常忽视仇恨内容的决定性作用，对所有内容一视同仁，且无法系统捕捉视频中的结构化信息，限制了多模态融合效果。

Method: 构建实例图将视频分割为多个实例提取特征，通过互补权重图为特征分配重要性权重以突出仇恨实例，结合权重和特征生成视频标签，使用图框架系统建模模态内和跨模态的结构关系。

Result: 在公开数据集上的广泛实验表明，该模型在仇恨视频分类方面达到最先进水平，并具有很强的可解释性。

Conclusion: 提出的多模态双流图神经网络模型有效解决了现有方法的局限性，在仇恨视频检测任务上表现出优异性能，代码已开源。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [21] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ColonCrafter是一种基于扩散模型的深度估计方法，从单目结肠镜视频生成时间一致的深度图，在C3VD数据集上实现零样本最先进性能


<details>
  <summary>Details</summary>
Motivation: 结肠镜三维场景理解需要自动化深度估计方法，但现有内窥镜深度估计模型在视频序列中缺乏时间一致性，限制了3D重建的应用

Method: 使用扩散模型从合成结肠镜序列学习几何先验来生成时间一致的深度图，并引入风格迁移技术将真实临床视频适配到合成训练域

Result: 在C3VD数据集上实现零样本最先进性能，优于通用和特定内窥镜方法，支持3D点云生成和表面覆盖评估等临床应用

Conclusion: 虽然完整轨迹3D重建仍有挑战，但ColonCrafter展示了临床相关应用价值，为结肠镜3D场景理解提供了有效解决方案

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [22] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

TL;DR: 该论文针对嵌入式平台的计算资源限制，提出了两种改进3D高斯泼溅的方法：通过体素空间几何相似性合并冗余高斯基元以减少GPU内存使用，以及通过Patch-Grid点采样初始化高斯基元来提高渲染质量。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯泼溅研究主要关注高性能桌面GPU，忽视了嵌入式平台（如微型飞行器）的计算和内存限制。这些设备需要在系统性能和重建质量之间进行权衡。

Method: 1) 在SLAM中基于几何相似性在体素空间合并冗余的3D高斯基元以减少GPU内存使用；2) 通过Patch-Grid点采样初始化3D高斯基元，实现更精确的场景建模。

Result: 在公开数据集上的定量和定性评估表明，该方法在减少GPU内存使用的同时提高了渲染质量，且不影响系统运行时性能。

Conclusion: 提出的方法有效解决了嵌入式平台在3D高斯泼溅应用中面临的内存限制问题，在保持性能的同时提升了渲染质量，为资源受限设备的3D重建应用提供了可行方案。

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [23] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 提出了一种自适应轨迹预测OOD检测框架，通过显式建模预测误差模式，在检测延迟和误报率方面显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在部署时面临训练数据与真实世界条件之间的分布偏移，现有OOD检测研究主要集中在计算机视觉任务，轨迹级别的OOD检测研究不足

Method: 基于快速变化检测(QCD)任务，引入自适应机制，显式建模预测误差的模式依赖分布和随时间演化的特性

Result: 在多个真实世界数据集上的实验表明，该方法在检测延迟和误报率方面取得显著改进，在准确性和计算效率上均优于现有UQ和基于视觉的OOD方法

Conclusion: 该框架为可靠、驾驶感知的自主性提供了实用路径，能够有效处理复杂驾驶环境中的分布偏移问题

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [24] [Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](https://arxiv.org/abs/2509.13590)
*Samer Al-Hamadani*

Main category: cs.CV

TL;DR: 基于Google Gemini 2.5 Flash的多模态医疗影像分析框架，整合视觉与语言处理，实现肿瘤检测和临床报告生成，支持CT、MRI、X光、超声等多种影像模态。


<details>
  <summary>Details</summary>
Motivation: 利用AI技术提升医疗影像诊断效率和准确性，解决传统诊断方法依赖人工经验、耗时较长的问题，通过多模态融合实现智能化的临床决策支持。

Method: 采用Vision-Language Models (VLMs)结合坐标验证机制和概率高斯建模进行异常分布分析，使用多层可视化技术生成医学图解和统计表示，通过精确的提示工程提取结构化临床信息。

Result: 在多模态异常检测中表现出高性能，位置测量达到80像素平均偏差，具备零样本学习能力减少对大数据集的依赖，提供用户友好的Gradio界面。

Conclusion: 该框架在自动化诊断支持和放射工作流效率方面取得显著进展，但需要进一步的临床验证和多中心评估才能广泛采用。

Abstract: The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.

</details>


### [25] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

TL;DR: CLAP算法从2D定位扩展到3D定位和图像拼接的通用框架，通过聚类方法处理噪声和异常值，相比传统RANSAC方法更具鲁棒性


<details>
  <summary>Details</summary>
Motivation: 将CLAP这一在RoboCup 2024中获奖的2D定位算法扩展到更通用的3D定位和图像拼接领域，提供处理噪声和不确定性的新工具

Method: 采用基于聚类的策略来抑制噪声和错误特征匹配，替代传统的RANSAC异常值拒绝方案

Result: 成功将CLAP扩展到3D定位和图像拼接应用，并建立了CLAP、RANSAC和Hough变换之间的关系

Conclusion: CLAP的通用化框架可广泛应用于多个领域，成为处理噪声和不确定性的有用工具

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


### [26] [SAMIR, an efficient registration framework via robust feature learning from SAM](https://arxiv.org/abs/2509.13629)
*Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen*

Main category: cs.CV

TL;DR: SAMIR是一个基于Segment Anything Model的医学图像配准框架，通过SAM的预训练图像编码器提取结构感知特征嵌入，结合轻量级3D头部和分层特征一致性损失，在心脏和腹部CT图像配准任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像配准中变形与组织形态特征密切相关，需要准确的特征提取。现有的弱监督方法需要分割掩码或地标等解剖先验，但这些标签往往难以获取，限制了实际应用。受视觉基础模型强大表示学习能力的启发，利用SAM来增强特征提取。

Method: 设计了任务特定的适配管道，使用SAM的图像编码器提取结构感知特征嵌入；设计了轻量级3D头部来细化嵌入空间中的特征以适应局部变形；引入了分层特征一致性损失来指导从粗到细的特征匹配。

Result: 在基准数据集上的广泛实验表明，SAMIR在心脏图像配准和腹部CT图像配准任务上显著优于最先进方法，在ACDC数据集上性能提升2.68%，在腹部数据集上提升6.44%。

Conclusion: SAMIR框架有效利用了SAM的预训练表示能力，通过结构感知特征提取和分层一致性约束，实现了优异的医学图像配准性能，为缺乏弱标签的场景提供了实用解决方案。

Abstract: Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.

</details>


### [27] [Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery](https://arxiv.org/abs/2509.13631)
*Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit*

Main category: cs.CV

TL;DR: 本文提出了一种基于联邦学习(FL)的分布式方法，用于从卫星图像中准确识别和定位森林砍伐，在保护数据隐私的同时实现多客户端协作训练。


<details>
  <summary>Details</summary>
Motivation: 传统集中式训练方法需要合并数据，会损害客户端数据安全。卫星图像处理需要分布式解决方案来保护各边缘卫星中心的数据隐私，同时实现准确的森林砍伐识别。

Method: 使用FLOWER框架和RAY框架构建分布式学习系统，采用YOLOS-small（Vision Transformer变体）、Faster R-CNN with ResNet50 backbone和Faster R-CNN with MobileNetV3 backbone三种模型，在公开数据集上进行训练和测试。

Result: 该方法能够有效识别和定位森林砍伐，同时保持各客户端数据的安全性和隐私性。RAY框架确保了高效的用户选择和环境模拟。

Conclusion: 联邦学习为卫星图像分割任务提供了新的分布式解决方案，在保护数据隐私的前提下实现了准确的森林砍伐检测，为地理状况分析提供了可靠的技术支持。

Abstract: Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.

</details>


### [28] [Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction](https://arxiv.org/abs/2509.13652)
*Yumin Li,Dylan Campbell*

Main category: cs.CV

TL;DR: GARPS是一个无需训练的两视图相机位姿估计框架，通过直接对齐两个独立重建的3D高斯混合模型来实现度量相对位姿估计，在Real-Estate10K数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的两视图位姿估计方法无法提供度量尺度信息（相机平移只有尺度未知），且在宽基线和纹理贫乏区域表现不佳。需要一种能够提供度量尺度且对纹理变化鲁棒的方法。

Method: 使用度量单目深度估计器和高斯场景重建器为每张图像生成度量3D高斯混合模型(GMM)，然后通过优化可微分的GMM对齐目标来精化初始位姿估计。该目标综合考虑几何结构、视角无关颜色、各向异性协方差和语义特征一致性。

Result: 在Real-Estate10K数据集上的大量实验表明，GARPS超越了经典方法和最先进的学习方法（包括MASt3R），实现了更好的度量相对位姿估计性能。

Conclusion: 该研究展示了将单视图感知与多视图几何相结合来实现鲁棒度量相对位姿估计的潜力，为3D重建和定位任务提供了有效的解决方案。

Abstract: Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.

</details>


### [29] [Deep Lookup Network](https://arxiv.org/abs/2509.13662)
*Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An*

Main category: cs.CV

TL;DR: 该论文提出用查找表操作替代神经网络中的乘法运算，以降低计算复杂度和能耗，提高移动设备部署效率。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络中的乘法运算计算复杂度高、能耗大，阻碍了在移动设备上的部署。受资源受限边缘设备使用查找表简化计算的启发，作者希望用高效的查找操作替代乘法运算。

Method: 提出可微分的查找表操作作为神经网络基础运算，用查找操作替代权重和激活值的乘法计算，并设计了多种训练策略来促进收敛。

Result: 在图像分类、超分辨率和点云分类任务中，查找网络在保持与原始卷积网络相当性能的同时，显著提高了能效和推理速度。

Conclusion: 查找网络在不同任务（分类和回归）和数据类型（图像和点云）上都取得了最先进的性能，证明了查找操作在提升神经网络效率方面的有效性。

Abstract: Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).

</details>


### [30] [Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](https://arxiv.org/abs/2509.13676)
*Xiaobo Yang,Xiaojin Gong*

Main category: cs.CV

TL;DR: 提出了一种基于语义超像素的视觉投影器，通过SAM生成的语义超像素来识别图像中的"视觉词汇"，将视觉token减少93%而不损失性能，显著加速MLLM训练和推理。


<details>
  <summary>Details</summary>
Motivation: 传统的patch-wise视觉投影器在减少视觉token数量和保持语义清晰度之间难以平衡，往往需要保留过长的token序列来避免性能下降，导致计算密集型问题。

Method: 利用SAM生成语义超像素作为"视觉词汇"，通过压缩和投影语义超像素作为视觉token；提出语义超像素位置嵌入来增强MLLM对超像素几何和位置的感知，以及语义超像素聚合器来保留超像素内部的细粒度细节和外部全局上下文。

Result: 实验表明该方法将视觉token减少93%而不影响性能，显著加快了MLLM的训练和推理速度，在Referring Image Segmentation任务上优于现有的压缩视觉投影器。

Conclusion: 基于语义超像素的视觉投影方法有效解决了视觉token冗余问题，在保持性能的同时大幅提升了效率，为MLLM在分割任务中的应用提供了更高效的解决方案。

Abstract: Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.

</details>


### [31] [FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras](https://arxiv.org/abs/2509.13681)
*Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li*

Main category: cs.CV

TL;DR: FishBEV是一个专门为鱼眼相机设计的BEV分割框架，通过三个创新模块解决了鱼眼相机在BEV分割中的几何畸变、多视角对应模糊和时间动态不稳定等问题，在Synwoodscapes数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有BEV分割方法主要针对针孔相机，难以直接应用于存在严重几何畸变、多视角对应模糊和时间动态不稳定等问题的鱼眼相机，导致BEV性能显著下降。

Method: 提出FishBEV框架，包含三个核心模块：1) 抗畸变多尺度提取(DRME)主干网络，在畸变下学习鲁棒特征并保持尺度一致性；2) 不确定性感知空间交叉注意力(U-SCA)机制，利用不确定性估计实现可靠的跨视角对齐；3) 距离感知时间自注意力(D-TSA)模块，自适应平衡近场细节和远场上下文以确保时间一致性。

Result: 在Synwoodscapes数据集上的大量实验表明，FishBEV在环视鱼眼BEV分割任务上持续优于最先进的基线方法。

Conclusion: FishBEV通过专门针对鱼眼相机特性的设计，有效解决了畸变、多视角对应和时间动态等挑战，为鱼眼相机的BEV分割提供了有效的解决方案。

Abstract: As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.

</details>


### [32] [Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification](https://arxiv.org/abs/2509.13687)
*Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra*

Main category: cs.CV

TL;DR: 该研究提出了基于样条的Kolmogorov-Arnold网络（KANs）用于医学图像分类，包括SBTAYLOR-KAN、SBRBF-KAN和SBWAVELET-KAN三种变体。这些模型在有限数据集上表现出色，SBTAYLOR-KAN仅用2872个参数就达到与传统CNN相当的性能，同时提供更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决在资源有限的临床环境中进行有效且可解释的医学图像分类的挑战，特别是在数据集有限且多样化的情况下。

Method: 开发了三种基于样条的KAN模型：SBTAYLOR-KAN（B样条+泰勒级数）、SBRBF-KAN（B样条+径向基函数）、SBWAVELET-KAN（B样条+Morlet小波变换）。使用Grad-CAM进行可解释性分析。

Result: SBTAYLOR-KAN达到98.93%的准确率，在仅使用30%训练数据时仍保持86%以上准确率。在皮肤癌数据集上达到68.22%准确率。相比ResNet50的2418万参数，SBTAYLOR-KAN仅需2872个参数。

Conclusion: 该框架为医学图像分类提供了轻量级、可解释且可泛化的解决方案，特别适合数据稀缺的临床AI应用场景。

Abstract: Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.

</details>


### [33] [StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models](https://arxiv.org/abs/2509.13711)
*Qiuyu Tang,Joshua Krinsky,Aparna Bharati*

Main category: cs.CV

TL;DR: 本文提出StyleProtect方法，通过选择性更新交叉注意力层来有效防御针对艺术风格的扩散模型微调攻击，保护艺术家的独特风格不被恶意模仿。


<details>
  <summary>Details</summary>
Motivation: 生成模型特别是扩散模型的快速发展使得恶意使用者能够廉价复制艺术家的创作风格，这导致了对艺术作品风格模仿保护方法的需求增加。微调扩散模型能够以更高的保真度和控制力内化和复制艺术风格。

Method: 研究发现某些交叉注意力层对艺术风格表现出高度敏感性。基于此提出了StyleProtect方法，通过仅更新选定的交叉注意力层来实现高效的风格防御。使用WikiArt和Anita数据集中的艺术作品和动漫动画进行实验验证。

Result: 实验结果表明，所提出的方法在保护艺术作品和动漫的独特风格免受恶意扩散定制方面表现出有希望的性能，同时保持了竞争力的不可感知性。

Conclusion: StyleProtect提供了一种轻量级且有效的保护策略，能够有效防御微调扩散模型的风格模仿攻击，为艺术家作品的风格保护提供了可行的解决方案。

Abstract: The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.

</details>


### [34] [UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry](https://arxiv.org/abs/2509.13713)
*Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn*

Main category: cs.CV

TL;DR: UM-Depth是一个自监督单目深度估计框架，通过运动感知和不确定性感知的细化方法，在动态物体边界和无纹理区域提高深度估计精度，无需额外标签或推理时开销。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督单目深度估计方法在处理输入数据不确定性（如低纹理或动态区域）时面临挑战，导致深度精度降低。需要一种方法能够增强在光度信号较弱区域的监督。

Method: 提出UM-Depth框架，采用师生训练策略，将不确定性估计嵌入训练流程和网络架构。仅在教师网络训练时使用光流，避免额外标签需求和运行时开销。

Result: 在KITTI和Cityscapes数据集上的广泛实验表明，不确定性感知细化方法有效。UM-Depth在KITTI数据集上实现了自监督深度和姿态估计的最先进结果。

Conclusion: UM-Depth通过结合运动感知和不确定性感知的细化，成功解决了自监督单目深度估计中的不确定性挑战，在保持实时性能的同时实现了优异的精度。

Abstract: Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.

</details>


### [35] [Mitigating Query Selection Bias in Referring Video Object Segmentation](https://arxiv.org/abs/2509.13722)
*Dingwei Zhang,Dong Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: 本文提出了Triple Query Former (TQF)方法，通过将参考查询分解为三个专门组件来解决RVOS中的查询选择偏差问题，并在多个基准测试中取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于查询的RVOS方法使用静态文本查询进行跨模态对齐，但容易被外观或运动相似的干扰物误导，导致查询选择偏差问题。

Method: 将参考查询分解为三个专门组件：外观查询（静态属性）、帧内交互查询（空间关系）和帧间运动查询（时间关联）；引入两个运动感知聚合模块：帧内交互聚合和帧间运动聚合。

Result: 在多个RVOS基准测试上的广泛实验证明了TQF方法的优势以及结构化查询设计和运动感知聚合模块的有效性。

Conclusion: 通过将查询分解为专门组件并引入运动感知机制，TQF方法有效解决了RVOS中的查询选择偏差问题，提升了跨模态对齐的性能。

Abstract: Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.

</details>


### [36] [Improving Generalized Visual Grounding with Instance-aware Joint Learning](https://arxiv.org/abs/2509.13747)
*Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: InstanceVG是一个多任务通用视觉定位框架，首次同时处理GREC和GRES任务，通过实例查询统一实例级边界框和掩码的联合一致性预测，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立处理GREC和GRES任务，忽视了联合训练的优势，且将GRES视为语义分割任务，忽略了实例感知能力和实例级边界框与掩码一致性预测的重要性。

Method: 提出InstanceVG框架，使用实例查询统一实例级边界框和掩码的联合一致性预测，为每个实例查询分配先验参考点，促进同一实例的点、边界框和掩码的一致性预测。

Result: 在四个任务的十个数据集上进行广泛实验，InstanceVG在各项评估指标上显著超越现有方法，达到最先进性能。

Conclusion: InstanceVG是第一个同时处理GREC和GRES任务并融入实例感知能力的通用视觉定位框架，通过实例查询实现了多粒度预测的一致性，取得了优异性能。

Abstract: Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.

</details>


### [37] [Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2509.13754)
*Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen*

Main category: cs.CV

TL;DR: FMFA是一个跨模态全模式细粒度对齐框架，通过显式细粒度对齐和隐式关系推理来提升文本-图像人员检索的全局匹配性能，无需额外监督


<details>
  <summary>Details</summary>
Motivation: 解决现有方法缺乏验证局部特征是否正确对齐的能力，以及主要关注困难负样本而忽略错误匹配正样本对的问题

Method: 提出自适应相似度分布匹配模块(A-SDM)来修正未匹配的正样本对，以及显式细粒度对齐模块(EFA)来增强跨模态细粒度交互和局部对齐验证

Result: 在三个公共数据集上实现了所有全局匹配方法中最先进的性能

Conclusion: FMFA框架通过全模式对齐策略有效提升了跨模态检索的精度，为文本-图像人员检索任务提供了新的解决方案

Abstract: Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.

</details>


### [38] [Controllable-Continuous Color Editing in Diffusion Model via Color Mapping](https://arxiv.org/abs/2509.13756)
*Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo*

Main category: cs.CV

TL;DR: 提出颜色映射模块解决文本驱动图像编辑中颜色控制的精度和连续性不足问题，通过建立文本嵌入空间与RGB值的对应关系实现精确可控的颜色编辑


<details>
  <summary>Details</summary>
Motivation: 自然语言的模糊性和离散性导致文本驱动的图像颜色编辑存在精度不足和难以实现连续控制的问题，现有方法缺乏对颜色变化范围的精确控制

Method: 引入颜色映射模块，显式建模文本嵌入空间与图像RGB值的对应关系，基于给定RGB值预测对应的嵌入向量，实现生成图像的精确颜色控制

Result: 实验结果表明该方法在颜色连续性和可控性方面表现良好，用户可指定目标RGB范围生成所需范围内的连续颜色变化图像

Conclusion: 该方法实现了更细粒度、连续且可控的颜色编辑，在保持语义一致性的同时提升了颜色编辑的精确度和控制能力

Abstract: In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.

</details>


### [39] [Iterative Prompt Refinement for Safer Text-to-Image Generation](https://arxiv.org/abs/2509.13760)
*Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型的迭代提示词优化算法，通过分析文本提示和生成图像来提升文本到图像模型的安全性和输出质量


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的安全方法只关注文本提示而忽略生成的图像，可能导致不安全输出或对安全提示的不必要修改

Method: 使用视觉语言模型(VLMs)迭代分析输入提示和生成图像，利用视觉反馈来优化提示词，并引入包含文本和视觉安全信号的新数据集进行监督微调

Result: 实验结果表明该方法能产生更安全的输出，同时保持与用户意图的一致性，安全性和可靠性可与现有LLM方法相媲美

Conclusion: 该方法通过视觉反馈有效提升了T2I模型的安全性，提供了生成更安全图像内容的实用解决方案

Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.

</details>


### [40] [Task-Aware Image Signal Processor for Advanced Visual Perception](https://arxiv.org/abs/2509.13762)
*Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: TA-ISP是一个轻量级的RAW-to-RGB框架，通过预测多尺度调制算子来生成面向任务的图像表示，显著减少计算开销同时提升下游视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么计算开销大（大型ISP网络），要么表达能力有限（基于传统ISP流水线调优），无法在资源受限设备上有效利用RAW数据的丰富信息。

Method: 提出任务感知图像信号处理（TA-ISP）框架，预测轻量级的多尺度调制算子（全局、区域、像素级别），重塑不同空间范围的图像统计特征，替代传统的密集卷积流水线。

Result: 在多个RAW域检测和分割基准测试中（白天和夜间条件），TA-ISP持续提升下游任务精度，同时显著减少参数数量和推理时间。

Conclusion: TA-ISP通过因子化控制扩展了空间变化变换的表示范围，在保持内存使用、计算和延迟严格约束的同时，适合在资源受限设备上部署。

Abstract: In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.

</details>


### [41] [NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset](https://arxiv.org/abs/2509.13766)
*Huichun Liu,Xiaosong Li,Yang Liu,Xiaoqi Cheng,Haishu Tan*

Main category: cs.CV

TL;DR: 提出NDLPNet网络，通过位置感知模块有效处理夜间低光条件下的雨纹去除问题，在保持背景信息的同时提升去雨效果


<details>
  <summary>Details</summary>
Motivation: 现有图像去雨技术主要针对白天条件设计，在夜间光照条件下性能不佳，因为雨纹分布的空间异质性和光线依赖的条纹可见性影响

Method: 提出夜间去雨位置增强感知网络(NDLPNet)，引入位置感知模块(PPM)来捕获空间上下文信息，增强模型识别和重新校准不同特征通道重要性的能力

Result: 在现有数据集和新构建的NSR数据集上的定性和定量实验表明，该方法在夜间去雨任务中优于最先进的方法

Conclusion: NDLPNet能有效去除夜间雨纹并保留关键背景信息，新构建的NSR数据集为夜间去雨研究提供了新基准

Abstract: Visual degradation caused by rain streak artifacts in low-light conditions
significantly hampers the performance of nighttime surveillance and autonomous
navigation. Existing image deraining techniques are primarily designed for
daytime conditions and perform poorly under nighttime illumination due to the
spatial heterogeneity of rain distribution and the impact of light-dependent
stripe visibility. In this paper, we propose a novel Nighttime Deraining
Location-enhanced Perceptual Network(NDLPNet) that effectively captures the
spatial positional information and density distribution of rain streaks in
low-light environments. Specifically, we introduce a Position Perception Module
(PPM) to capture and leverage spatial contextual information from input data,
enhancing the model's capability to identify and recalibrate the importance of
different feature channels. The proposed nighttime deraining network can
effectively remove the rain streaks as well as preserve the crucial background
information. Furthermore, We construct a night scene rainy (NSR) dataset
comprising 900 image pairs, all based on real-world nighttime scenes, providing
a new benchmark for nighttime deraining task research. Extensive qualitative
and quantitative experimental evaluations on both existing datasets and the NSR
dataset consistently demonstrate our method outperform the state-of-the-art
(SOTA) methods in nighttime deraining tasks. The source code and dataset is
available at https://github.com/Feecuin/NDLPNet.

</details>


### [42] [VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI](https://arxiv.org/abs/2509.13767)
*Daiqi Liu,Tomás Arias-Vergara,Johannes Enk,Fangxu Xing,Maureen Stone,Jerry L. Prince,Jana Hutter,Andreas Maier,Jonghye Woo,Paula Andrea Pérez-Toro*

Main category: cs.CV

TL;DR: VocSegMRI是一个多模态框架，通过交叉注意力融合视频、音频和语音学输入来提升实时MRI中发音结构分割的准确性，即使推理时缺少音频模态也能保持良好性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，但同步的声学和语音学信号能提供互补上下文信息，丰富视觉信息并提高分割精度。

Method: 提出多模态框架，整合视频、音频和语音学输入，采用交叉注意力融合进行动态特征对齐，并加入对比学习目标来增强跨模态表示。

Result: 在USC-75 rtMRI数据集子集上达到最先进性能：Dice分数0.95，95% Hausdorff距离4.20mm，优于单模态和多模态基线。

Conclusion: 消融研究证实了交叉注意力和对比学习对分割精度和鲁棒性的贡献，凸显了整合多模态建模在准确声道分析中的价值。

Abstract: Accurately segmenting articulatory structures in real-time magnetic resonance
imaging (rtMRI) remains challenging, as most existing methods rely almost
entirely on visual cues. Yet synchronized acoustic and phonological signals
provide complementary context that can enrich visual information and improve
precision. In this paper, we introduce VocSegMRI, a multimodal framework that
integrates video, audio, and phonological inputs through cross-attention fusion
for dynamic feature alignment. To further enhance cross-modal representation,
we incorporate a contrastive learning objective that improves segmentation
performance even when the audio modality is unavailable at inference. Evaluated
on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art
performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance
(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.
Ablation studies confirm the contributions of cross-attention and contrastive
learning to segmentation precision and robustness. These results highlight the
value of integrative multimodal modeling for accurate vocal tract analysis.

</details>


### [43] [Generative Image Coding with Diffusion Prior](https://arxiv.org/abs/2509.13768)
*Jianhui Chang*

Main category: cs.CV

TL;DR: 提出基于扩散先验的生成式编码框架，在低码率下显著提升压缩性能和视觉保真度，相比H.266/VVC压缩性能提升达79%


<details>
  <summary>Details</summary>
Motivation: 随着生成技术的发展，视觉内容呈现自然图像与AI生成图像的复杂混合，传统编解码器和学习方法难以在高压缩比下保持主观质量，现有生成方法面临视觉保真度和泛化性挑战

Method: 采用预优化编码器生成广义压缩域表示，通过轻量级适配器和注意力融合模块与预训练模型内部特征集成，引入分布重归一化方法增强重建保真度

Result: 在低码率下视觉保真度优于现有方法，压缩性能相比H.266/VVC提升高达79%，为AI生成内容提供高效解决方案且可适应更广泛内容类型

Conclusion: 该框架有效利用现有预训练扩散模型，能够以最小重训练成本适应不同预训练模型的新需求，为生成式压缩提供了高效且适应性强的解决方案

Abstract: As generative technologies advance, visual content has evolved into a complex
mix of natural and AI-generated images, driving the need for more efficient
coding techniques that prioritize perceptual quality. Traditional codecs and
learned methods struggle to maintain subjective quality at high compression
ratios, while existing generative approaches face challenges in visual fidelity
and generalization. To this end, we propose a novel generative coding framework
leveraging diffusion priors to enhance compression performance at low bitrates.
Our approach employs a pre-optimized encoder to generate generalized
compressed-domain representations, integrated with the pretrained model's
internal features via a lightweight adapter and an attentive fusion module.
This framework effectively leverages existing pretrained diffusion models and
enables efficient adaptation to different pretrained models for new
requirements with minimal retraining costs. We also introduce a distribution
renormalization method to further enhance reconstruction fidelity. Extensive
experiments show that our method (1) outperforms existing methods in visual
fidelity across low bitrates, (2) improves compression performance by up to 79%
over H.266/VVC, and (3) offers an efficient solution for AI-generated content
while being adaptable to broader content types.

</details>


### [44] [AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2509.13769)
*Yuechen Luo,Fang Li,Shaoqing Xu,Zhiyi Lai,Lei Yang,Qimao Chen,Ziang Luo,Zixun Xie,Shengyin Jiang,Jiaxin Liu,Long Chen,Bing Wang,Zhi-xin Yang*

Main category: cs.CV

TL;DR: AdaThinkDrive是一个新颖的视觉语言动作框架，采用双模式推理机制（快速回答和慢速思考），通过自适应选择推理模式来平衡自动驾驶决策的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的CoT推理技术在简单场景中表现不佳，引入不必要的计算开销而无法提升决策质量，需要一种能够自适应选择推理模式的解决方案。

Method: 1) 在大规模自动驾驶场景上进行预训练，获取世界知识和驾驶常识；2) 监督微调时引入双模式数据集（快速回答和慢速思考）；3) 提出自适应思考奖励策略与GRPO结合，通过比较不同推理模式的轨迹质量来奖励模型选择性应用CoT。

Result: 在Navsim基准测试中达到90.3的PDMS分数，比最佳纯视觉基线高1.7分；相比"从不思考"和"总是思考"基线分别提升2.0和1.4分；推理时间比"总是思考"基线减少14%。

Conclusion: AdaThinkDrive通过自适应推理机制有效平衡了准确性和效率，在自动驾驶任务中表现出色，证明了选择性应用CoT推理的重要性。

Abstract: While reasoning technology like Chain of Thought (CoT) has been widely
adopted in Vision Language Action (VLA) models, it demonstrates promising
capabilities in end to end autonomous driving. However, recent efforts to
integrate CoT reasoning often fall short in simple scenarios, introducing
unnecessary computational overhead without improving decision quality. To
address this, we propose AdaThinkDrive, a novel VLA framework with a dual mode
reasoning mechanism inspired by fast and slow thinking. First, our framework is
pretrained on large scale autonomous driving (AD) scenarios using both question
answering (QA) and trajectory datasets to acquire world knowledge and driving
commonsense. During supervised fine tuning (SFT), we introduce a two mode
dataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the
model to distinguish between scenarios that require reasoning. Furthermore, an
Adaptive Think Reward strategy is proposed in conjunction with the Group
Relative Policy Optimization (GRPO), which rewards the model for selectively
applying CoT by comparing trajectory quality across different reasoning modes.
Extensive experiments on the Navsim benchmark show that AdaThinkDrive achieves
a PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.
Moreover, ablations show that AdaThinkDrive surpasses both the never Think and
always Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also
reduces inference time by 14% compared to the always Think baseline,
demonstrating its ability to balance accuracy and efficiency through adaptive
reasoning.

</details>


### [45] [Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization](https://arxiv.org/abs/2509.13776)
*Chao Shuai,Gaojian Wang,Kun Pan,Tong Wu,Fanli Jin,Haohan Tan,Mengxiang Li,Zhenguang Liu,Feng Lin,Kui Ren*

Main category: cs.CV

TL;DR: 提出了一种新的深度伪造检测方法，通过独立使用局部和全局视角预测篡改区域，并采用形态学操作融合输出，有效抑制噪声并增强空间一致性。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测虽然追求更高准确率，但对篡改区域的精确定位需求日益增长。现有方法往往忽视局部细节和全局语义上下文的互补性，且融合策略简单，容易放大噪声和错误。

Method: 独立使用局部和全局视角预测篡改区域，采用形态学操作融合两个分支的输出，以抑制噪声并增强空间一致性。

Result: 大量实验证明每个模块在提高伪造定位准确性和鲁棒性方面的有效性。

Conclusion: 该方法通过有效的局部-全局融合策略，显著提升了深度伪造区域定位的性能。

Abstract: While the pursuit of higher accuracy in deepfake detection remains a central
goal, there is an increasing demand for precise localization of manipulated
regions. Despite the remarkable progress made in classification-based
detection, accurately localizing forged areas remains a significant challenge.
A common strategy is to incorporate forged region annotations during model
training alongside manipulated images. However, such approaches often neglect
the complementary nature of local detail and global semantic context, resulting
in suboptimal localization performance. Moreover, an often-overlooked aspect is
the fusion strategy between local and global predictions. Naively combining the
outputs from both branches can amplify noise and errors, thereby undermining
the effectiveness of the localization.
  To address these issues, we propose a novel approach that independently
predicts manipulated regions using both local and global perspectives. We
employ morphological operations to fuse the outputs, effectively suppressing
noise while enhancing spatial coherence. Extensive experiments reveal the
effectiveness of each module in improving the accuracy and robustness of
forgery localization.

</details>


### [46] [CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling](https://arxiv.org/abs/2509.13784)
*Hanfang Liang,Bing Wang,Shizhen Zhang,Wen Jiang,Yizhuo Yang,Weixiang Guo,Shenghai Yuan*

Main category: cs.CV

TL;DR: 提出Variable-Rate Spatial Event Mamba架构，直接处理原始事件流，无需中间表示，通过自适应速率控制实现低延迟和高效率


<details>
  <summary>Details</summary>
Motivation: 现有方法需要预定义时间窗口引入窗口延迟，点检测方法计算成本高无法实时，需要克服这些限制

Method: 使用轻量级因果空间邻域编码器捕获局部几何关系，Mamba状态空间模型进行线性复杂度的时间建模，控制器自适应调整处理速度

Result: 能够直接处理原始事件流，实现线性计算复杂度，自适应速率控制平衡窗口延迟和推理延迟

Conclusion: 该方法克服了现有方法的窗口延迟和计算效率问题，为高速视觉任务提供了有效的解决方案

Abstract: Event cameras capture asynchronous pixel-level brightness changes with
microsecond temporal resolution, offering unique advantages for high-speed
vision tasks. Existing methods often convert event streams into intermediate
representations such as frames, voxel grids, or point clouds, which inevitably
require predefined time windows and thus introduce window latency. Meanwhile,
pointwise detection methods face computational challenges that prevent
real-time efficiency due to their high computational cost. To overcome these
limitations, we propose the Variable-Rate Spatial Event Mamba, a novel
architecture that directly processes raw event streams without intermediate
representations. Our method introduces a lightweight causal spatial
neighborhood encoder to efficiently capture local geometric relations, followed
by Mamba-based state space models for scalable temporal modeling with linear
complexity. During inference, a controller adaptively adjusts the processing
speed according to the event rate, achieving an optimal balance between window
latency and inference latency.

</details>


### [47] [BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching](https://arxiv.org/abs/2509.13789)
*Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia*

Main category: cs.CV

TL;DR: BWCache是一种无需训练的方法，通过动态缓存和重用DiT块特征来加速基于DiT的视频生成，在保持视觉质量的同时实现最高2.24倍加速


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiT)在视频生成中表现出色，但其顺序去噪过程导致不可避免的延迟，限制了实际应用。现有加速方法要么因架构修改而损害视觉质量，要么无法在适当粒度上重用中间特征

Method: 提出块级缓存(BWCache)方法，分析发现DiT块是推理延迟的主要贡献者。特征变化呈现U形模式，中间时间步具有高度相似性。引入相似性指示器，仅在相邻时间步块特征差异低于阈值时触发特征重用

Result: 在多个视频扩散模型上的广泛实验表明，BWCache实现了最高2.24倍的加速，同时保持可比的视觉质量

Conclusion: BWCache是一种有效的训练免费加速方法，通过智能特征重用显著减少计算冗余，为DiT基视频生成的实际应用提供了可行的解决方案

Abstract: Recent advancements in Diffusion Transformers (DiTs) have established them as
the state-of-the-art method for video generation. However, their inherently
sequential denoising process results in inevitable latency, limiting real-world
applicability. Existing acceleration methods either compromise visual quality
due to architectural modifications or fail to reuse intermediate features at
proper granularity. Our analysis reveals that DiT blocks are the primary
contributors to inference latency. Across diffusion timesteps, the feature
variations of DiT blocks exhibit a U-shaped pattern with high similarity during
intermediate timesteps, which suggests substantial computational redundancy. In
this paper, we propose Block-Wise Caching (BWCache), a training-free method to
accelerate DiT-based video generation. BWCache dynamically caches and reuses
features from DiT blocks across diffusion timesteps. Furthermore, we introduce
a similarity indicator that triggers feature reuse only when the differences
between block features at adjacent timesteps fall below a threshold, thereby
minimizing redundant computations while maintaining visual fidelity. Extensive
experiments on several video diffusion models demonstrate that BWCache achieves
up to 2.24$\times$ speedup with comparable visual quality.

</details>


### [48] [Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation](https://arxiv.org/abs/2509.13792)
*Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada*

Main category: cs.CV

TL;DR: 提出了首个针对航天器姿态估计关键点回归的监督域适应框架，通过在合成数据和有限真实数据上联合优化域不变表示和任务特定风险，显著减小域偏移下的泛化误差。


<details>
  <summary>Details</summary>
Motivation: 航天器姿态估计在自主空间操作中至关重要，但现有混合方法在合成数据上表现良好，在真实图像上性能急剧下降，存在显著的合成到真实域差距问题。

Method: 基于学习不变表示和风险(LIRR)范式，联合优化域不变表示和任务特定风险，使用标记的合成数据和有限的标记真实数据进行训练。

Result: 在SPEED+基准测试中，该方法始终优于仅源域、微调和oracle基线，仅用5%标记目标数据就能达到或超过使用更多标记数据的oracle性能。

Conclusion: 该框架轻量级、骨干网络无关且计算高效，为在真实空间环境中实现鲁棒可部署的航天器姿态估计提供了实用途径。

Abstract: Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous
space operations such as rendezvous, docking, and in-orbit servicing. Hybrid
pipelines that combine object detection, keypoint regression, and
Perspective-n-Point (PnP) solvers have recently achieved strong results on
synthetic datasets, yet their performance deteriorates sharply on real or
lab-generated imagery due to the persistent synthetic-to-real domain gap.
Existing unsupervised domain adaptation approaches aim to mitigate this issue
but often underperform when a modest number of labeled target samples are
available. In this work, we propose the first Supervised Domain Adaptation
(SDA) framework tailored for SPE keypoint regression. Building on the Learning
Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes
domain-invariant representations and task-specific risk using both labeled
synthetic and limited labeled real data, thereby reducing generalization error
under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate
that our approach consistently outperforms source-only, fine-tuning, and oracle
baselines. Notably, with only 5% labeled target data, our method matches or
surpasses oracle performance trained on larger fractions of labeled data. The
framework is lightweight, backbone-agnostic, and computationally efficient,
offering a practical pathway toward robust and deployable spacecraft pose
estimation in real-world space environments.

</details>


### [49] [SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments](https://arxiv.org/abs/2509.13795)
*Jiayu Yuan,Ming Dai,Enhui Zheng,Chao Su,Nanxing Chen,Qiming Hu,Shibo Zhu,Yibin Cao*

Main category: cs.CV

TL;DR: 提出基于语义加权自适应粒子滤波的无人机视觉定位方法，在GNSS拒止环境下实现高效4自由度位姿估计，定位误差低于10米


<details>
  <summary>Details</summary>
Motivation: 解决现有检索式无人机定位方法在数据集可用性、实时性能、环境敏感性和泛化能力方面的局限性，特别是在动态或时变环境中

Method: 提出大规模多高度飞行段数据集(MAFS)和语义加权自适应粒子滤波(SWA-PF)方法，集成无人机图像和卫星图像的鲁棒语义特征，包含语义加权机制和优化的粒子滤波架构

Result: 相比特征提取方法获得10倍计算效率提升，全局定位误差低于10米，可在数秒内使用低分辨率卫星地图实现快速4自由度位姿估计

Conclusion: 该方法有效克服了现有无人机视觉定位系统的局限性，在GNSS拒止环境下提供了高效准确的定位解决方案

Abstract: Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been
extensively investigated for Global Navigation Satellite System (GNSS)-denied
environments. However, existing retrieval-based approaches face limitations in
dataset availability and persistent challenges including suboptimal real-time
performance, environmental sensitivity, and limited generalization capability,
particularly in dynamic or temporally varying environments. To overcome these
limitations, we present a large-scale Multi-Altitude Flight Segments dataset
(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted
Adaptive Particle Filter (SWA-PF) method. This approach integrates robust
semantic features from both UAV-captured images and satellite imagery through
two key innovations: a semantic weighting mechanism and an optimized particle
filtering architecture. Evaluated using our dataset, the proposed method
achieves 10x computational efficiency gain over feature extraction methods,
maintains global positioning errors below 10 meters, and enables rapid 4 degree
of freedom (4-DoF) pose estimation within seconds using accessible
low-resolution satellite maps. Code and dataset will be available at
https://github.com/YuanJiayuuu/SWA-PF.

</details>


### [50] [Masked Feature Modeling Enhances Adaptive Segmentation](https://arxiv.org/abs/2509.13801)
*Wenlve Zhou,Zhiheng Zhou,Tiantao Xian,Yikui Zhai,Weibin Wu,Biyun Ma*

Main category: cs.CV

TL;DR: 提出Masked Feature Modeling (MFM)作为无监督域自适应语义分割的辅助任务，通过特征掩码和重建来提升性能，无需修改推理架构且零计算开销


<details>
  <summary>Details</summary>
Motivation: 现有的掩码建模方法在无监督域自适应语义分割中存在架构不兼容和优化目标不一致的问题，需要一种与分割任务对齐的辅助学习方法

Method: 在特征空间进行特征掩码和重建，引入轻量级Rebuilder模块进行联合训练但推理时丢弃，利用分割解码器对重建特征进行分类

Result: 在各种架构和UDA基准测试中一致提升分割性能

Conclusion: MFM为无监督域自适应语义分割提供了一种简单、高效且可推广的策略

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer models from a labeled source domain to an unlabeled target domain.
While auxiliary self-supervised tasks-particularly contrastive learning-have
improved feature discriminability, masked modeling approaches remain
underexplored in this setting, largely due to architectural incompatibility and
misaligned optimization objectives. We propose Masked Feature Modeling (MFM), a
novel auxiliary task that performs feature masking and reconstruction directly
in the feature space. Unlike existing masked modeling methods that reconstruct
low-level inputs or perceptual features (e.g., HOG or visual tokens), MFM
aligns its learning target with the main segmentation task, ensuring
compatibility with standard architectures like DeepLab and DAFormer without
modifying the inference pipeline. To facilitate effective reconstruction, we
introduce a lightweight auxiliary module, Rebuilder, which is trained jointly
but discarded during inference, adding zero computational overhead at test
time. Crucially, MFM leverages the segmentation decoder to classify the
reconstructed features, tightly coupling the auxiliary objective with the
pixel-wise prediction task to avoid interference with the primary task.
Extensive experiments across various architectures and UDA benchmarks
demonstrate that MFM consistently enhances segmentation performance, offering a
simple, efficient, and generalizable strategy for unsupervised domain-adaptive
semantic segmentation.

</details>


### [51] [Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET](https://arxiv.org/abs/2509.13809)
*Nick Theisen,Kenny Schlegel,Dietrich Paulus,Peer Neubert*

Main category: cs.CV

TL;DR: 本文研究了高光谱图像像素光谱分类，提出使用MiniROCKET和HDC-MiniROCKET方法在训练数据有限的情况下优于当前最佳模型1D-Justo-LiuNet。


<details>
  <summary>Details</summary>
Motivation: 虽然当前最佳的光谱分类模型1D-Justo-LiuNet参数少效率高，但在训练数据有限时性能会下降，需要寻找对数据量要求更低的替代方案。

Method: 采用MiniROCKET和HDC-MiniROCKET方法，这些方法在特征提取部分没有可训练参数，使用精心设计的特征提取器，对训练数据量的依赖较小。

Result: MiniROCKET在训练数据有限的情况下优于1D-Justo-LiuNet，在一般情况下性能相当，尽管参数更多但对数据需求更少。

Conclusion: MiniROCKET系列方法特别适合训练数据有限的光谱分类场景，为未来空间-光谱方法的改进提供了有价值的补充。

Abstract: The classification of pixel spectra of hyperspectral images, i.e. spectral
classification, is used in many fields ranging from agricultural, over medical
to remote sensing applications and is currently also expanding to areas such as
autonomous driving. Even though for full hyperspectral images the
best-performing methods exploit spatial-spectral information, performing
classification solely on spectral information has its own advantages, e.g.
smaller model size and thus less data required for training. Moreover, spectral
information is complementary to spatial information and improvements on either
part can be used to improve spatial-spectral approaches in the future.
Recently, 1D-Justo-LiuNet was proposed as a particularly efficient model with
very few parameters, which currently defines the state of the art in spectral
classification. However, we show that with limited training data the model
performance deteriorates. Therefore, we investigate MiniROCKET and
HDC-MiniROCKET for spectral classification to mitigate that problem. The model
extracts well-engineered features without trainable parameters in the feature
extraction part and is therefore less vulnerable to limited training data. We
show that even though MiniROCKET has more parameters it outperforms
1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the
general case

</details>


### [52] [Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2509.13834)
*Nguyen Lan Vi Vu,Thanh-Huy Nguyen,Thien Nguyen,Daisuke Kihara,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: Semi-MOE是首个用于半监督组织病理学图像分割的多任务Mixture-of-Experts框架，通过三个专家网络和自适应多目标损失，在低标签设置下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有半监督学习方法在组织病理学图像分割中因腺体边界模糊和形态学误分类导致的噪声伪标签问题。

Method: 使用三个专门化的专家网络（主分割专家、符号距离场回归专家、边界预测专家），通过多门控伪标签模块动态聚合特征，并采用自适应多目标损失平衡学习目标。

Result: 在GlaS和CRAG基准测试中，该方法在低标签设置下优于最先进的方法。

Conclusion: 基于MoE的架构在推进半监督分割方面具有巨大潜力，特别是在处理复杂形态特征的医学图像分析中。

Abstract: Semi-supervised learning has been employed to alleviate the need for
extensive labeled data for histopathology image segmentation, but existing
methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and
morphological misclassification. This paper introduces Semi-MOE, to the best of
our knowledge, the first multi-task Mixture-of-Experts framework for
semi-supervised histopathology image segmentation. Our approach leverages three
specialized expert networks: A main segmentation expert, a signed distance
field regression expert, and a boundary prediction expert, each dedicated to
capturing distinct morphological features. Subsequently, the Multi-Gating
Pseudo-labeling module dynamically aggregates expert features, enabling a
robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate
manual tuning while dynamically balancing multiple learning objectives, we
propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and
CRAG benchmarks show that our method outperforms state-of-the-art approaches in
low-label settings, highlighting the potential of MoE-based architectures in
advancing semi-supervised segmentation. Our code is available at
https://github.com/vnlvi2k3/Semi-MoE.

</details>


### [53] [Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](https://arxiv.org/abs/2509.13836)
*Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao*

Main category: cs.CV

TL;DR: 本文提出VHBench-10基准测试和VisionWeaver模型，通过细粒度幻觉分类和多专家特征融合，有效减少大型视觉语言模型的物体幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型中的物体幻觉问题严重阻碍了实际应用，不同视觉编码器的训练范式差异导致其具有不同的归纳偏置和幻觉特性，但现有基准测试无法捕捉这种细粒度差异。

Method: 构建包含10,000样本的VHBench-10基准测试，涵盖10个细粒度幻觉类别；提出VisionWeaver模型，使用全局视觉特征生成路由信号，动态聚合多个专家视觉特征。

Result: 评估确认不同编码器具有独特的幻觉特性；VisionWeaver在显著减少幻觉和提高整体模型性能方面表现出有效性。

Conclusion: 视觉编码器的选择对幻觉性能至关重要，VisionWeaver通过上下文感知路由机制有效缓解了物体幻觉问题，为LVLMs的实际应用提供了重要改进。

Abstract: Object hallucination in Large Vision-Language Models (LVLMs) significantly
impedes their real-world applicability. As the primary component for accurately
interpreting visual information, the choice of visual encoder is pivotal. We
hypothesize that the diverse training paradigms employed by different visual
encoders instill them with distinct inductive biases, which leads to their
diverse hallucination performances. Existing benchmarks typically focus on
coarse-grained hallucination detection and fail to capture the diverse
hallucinations elaborated in our hypothesis. To systematically analyze these
effects, we introduce VHBench-10, a comprehensive benchmark with approximately
10,000 samples for evaluating LVLMs across ten fine-grained hallucination
categories. Our evaluations confirm encoders exhibit unique hallucination
characteristics. Building on these insights and the suboptimality of simple
feature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.
It employs global visual features to generate routing signals, dynamically
aggregating visual features from multiple specialized experts. Comprehensive
experiments confirm the effectiveness of VisionWeaver in significantly reducing
hallucinations and improving overall model performance.

</details>


### [54] [Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.13846)
*Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 该论文挑战了表示学习中视图不相关假设，提出显式对齐视图表示的方法来学习有意义的潜在空间结构，在自监督学习任务中取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 当前表示学习方法隐含假设数据点的不相关视图足以学习有意义的表示，但作者发现潜在空间的有意义结构不会自然涌现，需要显式诱导。

Method: 提出Consistent View Alignment方法，对齐数据不同视图的表示以对齐互补信息，同时避免产生假阳性。

Result: 方法在MICCAI 2025 SSL3D挑战赛中使用Primus vision transformer和ResEnc CNN分别获得第一和第二名，下游任务性能显著提升。

Conclusion: 结构化视图对齐在学习有效表示中起着关键作用，显式诱导潜在空间结构是必要的。

Abstract: Many recent approaches in representation learning implicitly assume that
uncorrelated views of a data point are sufficient to learn meaningful
representations for various downstream tasks. In this work, we challenge this
assumption and demonstrate that meaningful structure in the latent space does
not emerge naturally. Instead, it must be explicitly induced. We propose a
method that aligns representations from different views of the data to align
complementary information without inducing false positives. Our experiments
show that our proposed self-supervised learning method, Consistent View
Alignment, improves performance for downstream tasks, highlighting the critical
role of structured view alignment in learning effective representations. Our
method achieved first and second place in the MICCAI 2025 SSL3D challenge when
using a Primus vision transformer and ResEnc convolutional neural network,
respectively. The code and pretrained model weights are released at
https://github.com/Tenbatsu24/LatentCampus.

</details>


### [55] [SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation](https://arxiv.org/abs/2509.13848)
*Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: SpecDiff是一种训练自由的多级特征缓存策略，通过自推测引入未来信息，结合历史信息进行动态特征选择和分类，在保持质量的同时显著加速扩散模型推理。


<details>
  <summary>Details</summary>
Motivation: 现有特征缓存方法仅依赖历史信息，导致精度和速度性能受限，需要突破速度-精度权衡瓶颈。

Method: 提出自推测范式引入未来信息，包括基于自推测信息的缓存特征选择算法和基于特征重要性分数的多级特征分类算法。

Result: 在Stable Diffusion 3、3.5和FLUX上分别实现2.80×、2.74×和3.17×的平均加速，质量损失可忽略。

Conclusion: 通过融合推测和历史信息，SpecDiff突破了速度-精度权衡瓶颈，推动了高效扩散模型推理的Pareto前沿。

Abstract: Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.

</details>


### [56] [EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](https://arxiv.org/abs/2509.13858)
*Qianxin Xia,Jiawei Du,Guoming Lu,Zhiyong Shu,Jielei Wang*

Main category: cs.CV

TL;DR: EDITS是一个新颖的数据集蒸馏框架，利用图像中的隐含文本语义信息，通过视觉语言模型和大型语言模型融合图像与文本特征，生成更高质量的合成数据集。


<details>
  <summary>Details</summary>
Motivation: 传统数据集蒸馏方法主要捕获低级视觉特征，忽略了图像中的高级语义和结构信息，导致蒸馏效果受限。

Method: 1. 使用视觉语言模型生成外部文本并与图像特征融合；2. 通过全局语义查询模块形成先验聚类缓冲区；3. 局部语义感知选择代表性样本构建图像和文本原型；4. 使用精心设计的提示词引导大型语言模型；5. 通过双原型指导策略和扩散模型生成最终合成数据集。

Result: 大量实验证实了该方法的有效性，能够在保持竞争力的模型性能的同时实现高效学习。

Conclusion: EDITS框架通过利用图像中的文本语义信息，显著提升了数据集蒸馏的效果，为高效机器学习提供了新的解决方案。

Abstract: Dataset distillation aims to synthesize a compact dataset from the original
large-scale one, enabling highly efficient learning while preserving
competitive model performance. However, traditional techniques primarily
capture low-level visual features, neglecting the high-level semantic and
structural information inherent in images. In this paper, we propose EDITS, a
novel framework that exploits the implicit textual semantics within the image
data to achieve enhanced distillation. First, external texts generated by a
Vision Language Model (VLM) are fused with image features through a Global
Semantic Query module, forming the prior clustered buffer. Local Semantic
Awareness then selects representative samples from the buffer to construct
image and text prototypes, with the latter produced by guiding a Large Language
Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype
Guidance strategy generates the final synthetic dataset through a diffusion
model. Extensive experiments confirm the effectiveness of our method.Source
code is available in: https://github.com/einsteinxia/EDITS.

</details>


### [57] [LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction](https://arxiv.org/abs/2509.13863)
*Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li*

Main category: cs.CV

TL;DR: 提出LamiGauss算法，结合高斯溅射辐射光栅化和专用探测器-世界变换模型，用于稀疏视角X射线层析成像重建，仅需3%完整视角即可达到优于完整数据集迭代方法的性能


<details>
  <summary>Details</summary>
Motivation: 传统CT在平板结构检测中存在几何限制，层析成像在稀疏视角条件下重建高质量体积仍然具有挑战性，需要解决层析伪影和稀疏数据重建问题

Method: 结合高斯溅射辐射光栅化与包含层析倾斜角的专用探测器-世界变换模型，采用初始化策略显式过滤层析伪影，防止高斯粒子分配到虚假结构，集中模型能力表示真实物体

Result: 在合成和真实数据集上的广泛实验表明，该方法仅使用3%完整视角就能达到优于完整数据集优化迭代方法的性能，实现了准确高效的重建

Conclusion: LamiGauss方法有效解决了稀疏视角层析成像重建的挑战，通过创新的高斯溅射技术和伪影过滤策略，在有限数据条件下实现了优越的重建性能

Abstract: X-ray Computed Laminography (CL) is essential for non-destructive inspection
of plate-like structures in applications such as microchips and composite
battery materials, where traditional computed tomography (CT) struggles due to
geometric constraints. However, reconstructing high-quality volumes from
laminographic projections remains challenging, particularly under highly
sparse-view acquisition conditions. In this paper, we propose a reconstruction
algorithm, namely LamiGauss, that combines Gaussian Splatting radiative
rasterization with a dedicated detector-to-world transformation model
incorporating the laminographic tilt angle. LamiGauss leverages an
initialization strategy that explicitly filters out common laminographic
artifacts from the preliminary reconstruction, preventing redundant Gaussians
from being allocated to false structures and thereby concentrating model
capacity on representing the genuine object. Our approach effectively optimizes
directly from sparse projections, enabling accurate and efficient
reconstruction with limited data. Extensive experiments on both synthetic and
real datasets demonstrate the effectiveness and superiority of the proposed
method over existing techniques. LamiGauss uses only 3$\%$ of full views to
achieve superior performance over the iterative method optimized on a full
dataset.

</details>


### [58] [Distractor-Aware Memory-Based Visual Object Tracking](https://arxiv.org/abs/2509.13864)
*Jovana Videnovic,Matej Kristan,Alan Lukezic*

Main category: cs.CV

TL;DR: 提出了DAM4SAM，一个针对SAM2的干扰物感知记忆模块，通过干扰物感知的drop-in记忆模块和基于内省的管理方法，有效减少跟踪漂移并提升遮挡后重检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆的视频分割方法（如SAM2）在分割任务上表现优异，但在视觉目标跟踪中面对视觉相似的干扰物时存在挑战，需要专门针对干扰物问题的解决方案。

Method: 设计了干扰物感知的drop-in记忆模块和基于内省的管理方法，构建了DiDi干扰物蒸馏数据集用于分析，并将该模块集成到SAM2中形成DAM4SAM。

Result: 在13个基准测试中超越SAM2.1，在10个基准上达到新的state-of-the-art结果。集成到实时跟踪器EfficientTAM中提升11%性能，在多个跟踪和分割基准上匹配非实时SAM2.1-L的质量。

Conclusion: 提出的干扰物感知记忆模块能有效提升跟踪器在干扰物环境下的性能，具有良好的架构泛化能力，为视觉目标跟踪中的干扰物问题提供了有效解决方案。

Abstract: Recent emergence of memory-based video segmentation methods such as SAM2 has
led to models with excellent performance in segmentation tasks, achieving
leading results on numerous benchmarks. However, these modes are not fully
adjusted for visual object tracking, where distractors (i.e., objects visually
similar to the target) pose a key challenge. In this paper we propose a
distractor-aware drop-in memory module and introspection-based management
method for SAM2, leading to DAM4SAM. Our design effectively reduces the
tracking drift toward distractors and improves redetection capability after
object occlusion. To facilitate the analysis of tracking in the presence of
distractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM
outperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results
on ten. Furthermore, integrating the proposed distractor-aware memory into a
real-time tracker EfficientTAM leads to 11% improvement and matches tracking
quality of the non-real-time SAM2.1-L on multiple tracking and segmentation
benchmarks, while integration with edge-based tracker EdgeTAM delivers 4%
performance boost, demonstrating a very good generalization across
architectures.

</details>


### [59] [MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment](https://arxiv.org/abs/2509.14001)
*Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli*

Main category: cs.CV

TL;DR: MOCHA是一种知识蒸馏方法，将大型视觉-语言教师模型的多模态语义知识转移到轻量级纯视觉目标检测学生模型中，通过对象级对齐实现高效语义迁移，在少样本个性化检测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注密集或全局对齐，但缺乏对象级别的多模态语义知识转移。需要一种能够在不修改教师模型且推理时无需文本输入的情况下，将区域级多模态语义有效传递给轻量级检测器的方法。

Method: 使用翻译模块将学生特征映射到联合空间，通过双目标损失函数（局部对齐和全局关系一致性）指导学生和翻译器的训练，在对象级别进行知识蒸馏。

Result: 在四个少样本个性化检测基准测试中 consistently 超越基线方法，平均得分提升+10.1，性能与更大的多模态模型相当，但架构更紧凑。

Conclusion: MOCHA证明了对象级知识蒸馏的有效性，能够在不依赖文本输入的情况下实现高效的多模态语义转移，适合实际部署应用。

Abstract: We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.

</details>


### [60] [Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis](https://arxiv.org/abs/2509.13873)
*Siam Tahsin Bhuiyan,Rashedur Rahman,Sefatul Wasi,Naomi Yagi,Syoji Kobashi,Ashraful Islam,Saadia Binte Alam*

Main category: cs.CV

TL;DR: PelFANet是一个双流注意力网络，融合原始骨盆X光片和分割骨图像，通过Fused Attention Blocks迭代交换和精炼特征，在可见和不可见骨折检测中均表现出优异性能


<details>
  <summary>Details</summary>
Motivation: 骨盆骨折在标准X光片中往往表现细微或不可见，给诊断带来重大挑战，需要开发更精确的骨折分类方法

Method: 采用双流注意力网络结构，融合原始X光片和分割骨图像，使用Fused Attention Blocks进行特征交换和精炼，采用两阶段分割引导的训练流程

Result: 在AMERI数据集上，可见骨折检测准确率88.68%，AUC 0.9334；不可见骨折检测准确率82.29%，AUC 0.8688，即使未针对不可见骨折进行训练

Conclusion: 解剖感知的双输入架构在骨折检测方面具有临床潜力，特别是在放射学表现细微的情况下表现出鲁棒性

Abstract: Pelvic fractures pose significant diagnostic challenges, particularly in
cases where fracture signs are subtle or invisible on standard radiographs. To
address this, we introduce PelFANet, a dual-stream attention network that fuses
raw pelvic X-rays with segmented bone images to improve fracture
classification. The network em-ploys Fused Attention Blocks (FABlocks) to
iteratively exchange and refine fea-tures from both inputs, capturing global
context and localized anatomical detail. Trained in a two-stage pipeline with a
segmentation-guided approach, PelFANet demonstrates superior performance over
conventional methods. On the AMERI dataset, it achieves 88.68% accuracy and
0.9334 AUC on visible fractures, while generalizing effectively to invisible
fracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained
on them. These results highlight the clini-cal potential of anatomy-aware
dual-input architectures for robust fracture detec-tion, especially in
scenarios with subtle radiographic presentations.

</details>


### [61] [EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View](https://arxiv.org/abs/2509.13883)
*Zhen Xu,Guorui Lu,Chang Gao,Qinyu Chen*

Main category: cs.CV

TL;DR: EvHand-FPV是一个轻量级的单事件相机第一人称视角3D手部追踪框架，通过手腕ROI定位、端到端映射和多任务学习策略，在保持高精度的同时大幅降低了计算开销和参数数量。


<details>
  <summary>Details</summary>
Motivation: 传统帧式方法在精度、延迟和能效方面难以满足XR设备等资源受限场景的需求，而事件相机具有微秒级时间分辨率和毫瓦级功耗的优势，但缺乏第一人称视角的基准数据集。

Method: 构建合成训练数据与真实事件数据结合的FPV数据集；引入基于手腕的ROI定位和端到端映射策略减少计算；采用多任务学习策略提升表征能力；整体框架参数和计算量大幅减少。

Result: 在真实FPV测试集上，2D-AUCp从0.77提升到0.85，参数减少89%（11.2M→1.2M），计算量减少89%（1.648G→0.185G FLOPs）；在合成数据上保持0.84的3D-AUCp。

Conclusion: EvHand-FPV实现了准确高效的基于事件相机的第一人称手部追踪，适合设备端XR应用，为资源受限场景提供了可行的解决方案。

Abstract: Hand tracking holds great promise for intuitive interaction paradigms, but
frame-based methods often struggle to meet the requirements of accuracy, low
latency, and energy efficiency, especially in resource-constrained settings
such as Extended Reality (XR) devices. Event cameras provide $\mu$s-level
temporal resolution at mW-level power by asynchronously sensing brightness
changes. In this work, we present EvHand-FPV, a lightweight framework for
egocentric First-Person-View 3D hand tracking from a single event camera. We
construct an event-based FPV dataset that couples synthetic training data with
3D labels and real event data with 2D labels for evaluation to address the
scarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based
region of interest (ROI) that localizes the hand region via geometric cues,
combined with an end-to-end mapping strategy that embeds ROI offsets into the
network to reduce computation without explicit reconstruction, and a multi-task
learning strategy with an auxiliary geometric feature head that improves
representations without test-time overhead. On our real FPV test set,
EvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from
11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It
also maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results
demonstrate accurate and efficient egocentric event-based hand tracking
suitable for on-device XR applications. The dataset and code are available at
https://github.com/zen5x5/EvHand-FPV.

</details>


### [62] [Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions](https://arxiv.org/abs/2509.14165)
*Michal Szczepanski,Martyna Poreba,Karim Haroun*

Main category: cs.CV

TL;DR: STEP是一个结合动态补丁合并和令牌剪枝的混合令牌减少框架，通过dCTS策略网络和早期退出机制，显著降低ViT的计算和内存成本，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在语义分割中表现出色但计算和内存成本高昂，需要一种高效的方法来减少令牌数量而不显著影响准确性。

Method: 提出STEP框架，包含dCTS（轻量级CNN策略网络）实现动态补丁合并生成超补丁，并在编码器块中集成早期退出机制来移除高置信度超令牌。

Result: 单独使用dCTS可将令牌数量减少2.5倍，计算成本降低2.6倍，吞吐量提高3.4倍。完整STEP框架可达到4倍计算复杂度降低和1.7倍推理速度提升，精度下降不超过2.0%。

Conclusion: STEP框架有效解决了ViT在语义分割中的效率问题，通过动态令牌减少和早期退出机制实现了计算效率和精度的良好平衡。

Abstract: Vision Transformers (ViTs) achieve state-of-the-art performance in semantic
segmentation but are hindered by high computational and memory costs. To
address this, we propose STEP (SuperToken and Early-Pruning), a hybrid
token-reduction framework that combines dynamic patch merging and token pruning
to enhance efficiency without significantly compromising accuracy. At the core
of STEP is dCTS, a lightweight CNN-based policy network that enables flexible
merging into superpatches. Encoder blocks integrate also early-exits to remove
high-confident supertokens, lowering computational load. We evaluate our method
on high-resolution semantic segmentation benchmarks, including images up to
1024 x 1024, and show that when dCTS is applied alone, the token count can be
reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching
scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase
in throughput when using ViT-Large as the backbone. Applying the full STEP
framework further improves efficiency, reaching up to a 4x reduction in
computational complexity and a 1.7x gain in inference speed, with a maximum
accuracy drop of no more than 2.0%. With the proposed STEP configurations, up
to 40% of tokens can be confidently predicted and halted before reaching the
final encoder layer.

</details>


### [63] [White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/2509.13907)
*Jiyun Im,SuBeen Lee,Miso Lee,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 本文提出WARM模块，通过白化-交叉注意力-着色变换来解决少样本3D点云分割中可学习原型标记与支持特征之间的分布差异问题，显著提升了原型生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有少样本3D点云分割方法使用传统算法（如最远点采样）构建原型，其初始随机性严重影响性能，且原型生成过程研究不足。注意力机制虽有效但存在分布差异问题。

Method: 提出White Aggregation and Restoration Module (WARM)，在白化和着色变换之间嵌入交叉注意力：白化将支持特征与原型标记对齐，交叉注意力捕获语义关系，着色恢复原始分布。

Result: 在多个少样本3D点云分割基准测试中取得了最先进的性能，显著优于现有方法。

Conclusion: WARM模块通过简单的白化-注意力-着色设计有效解决了分布差异问题，能够生成更具代表性的原型，提升少样本分割性能。

Abstract: Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point
labels for an unlabeled point cloud, given only a few labeled examples. To
extract discriminative representations from the limited support set, existing
methods have constructed prototypes using conventional algorithms such as
farthest point sampling. However, we point out that its initial randomness
significantly affects FS-PCS performance and that the prototype generation
process remains underexplored despite its prevalence. This motivates us to
investigate an advanced prototype generation method based on attention
mechanism. Despite its potential, we found that vanilla module suffers from the
distributional gap between learnable prototypical tokens and support features.
To overcome this, we propose White Aggregation and Restoration Module (WARM),
which resolves the misalignment by sandwiching cross-attention between
whitening and coloring transformations. Specifically, whitening aligns the
support features to prototypical tokens before attention process, and
subsequently coloring restores the original distribution to the attended
tokens. This simple yet effective design enables robust attention, thereby
generating representative prototypes by capturing the semantic relationships
among support features. Our method achieves state-of-the-art performance with a
significant margin on multiple FS-PCS benchmarks, demonstrating its
effectiveness through extensive experiments.

</details>


### [64] [Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration](https://arxiv.org/abs/2509.13919)
*Yuanchen Wu,Ke Yan,Shouhong Ding,Ziyin Zhou,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 提出SRC框架，通过迭代校准大视觉语言模型中理由与答案的对齐，改善推理一致性和回答准确性


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型在视觉问答中表现出色，但在理由生成和答案对齐方面存在不一致性，导致推理错误和错误回答

Method: SRC框架包含：1）轻量级"理由微调"改变响应格式；2）多样性候选响应搜索；3）使用R-Scorer评分模型的成对评分策略；4）基于置信度加权的偏好微调

Result: 在多个基准测试中显著提升了LVLMs的感知、推理和泛化能力

Conclusion: 强调理由导向的对齐在挖掘大视觉语言模型潜力中的重要性

Abstract: Large Vision-Language Models (LVLMs) have manifested strong visual question
answering capability. However, they still struggle with aligning the rationale
and the generated answer, leading to inconsistent reasoning and incorrect
responses. To this end, this paper introduces the Self-Rationale Calibration
(SRC) framework to iteratively calibrate the alignment between rationales and
answers. SRC begins by employing a lightweight "rationale fine-tuning"
approach, which modifies the model's response format to require a rationale
before deriving an answer without explicit prompts. Next, SRC searches for a
diverse set of candidate responses from the fine-tuned LVLMs for each sample,
followed by a proposed pairwise scoring strategy using a tailored scoring
model, R-Scorer, to evaluate both rationale quality and factual consistency of
candidates. Based on a confidence-weighted preference curation process, SRC
decouples the alignment calibration into a preference fine-tuning manner,
leading to significant improvements of LVLMs in perception, reasoning, and
generalization across multiple benchmarks. Our results emphasize the
rationale-oriented alignment in exploring the potential of LVLMs.

</details>


### [65] [Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification](https://arxiv.org/abs/2509.13922)
*Wenkui Yang,Jie Cao,Junxian Duan,Ran He*

Main category: cs.CV

TL;DR: 本文提出了AntiPure方法，一种针对扩散模型保护性扰动的抗净化技术，通过在净化过程中引入两种引导机制来防止保护性扰动被去除。


<details>
  <summary>Details</summary>
Motivation: 扩散模型如Stable Diffusion的强大定制能力带来了严重的安全风险，包括深度伪造和版权侵权。现有的保护性扰动方法容易被净化技术移除，导致图像再次面临恶意伪造的风险。

Method: 提出了AntiPure方法，包含两种引导机制：1）Patch-wise Frequency Guidance减少模型对净化图像高频分量的影响；2）Erroneous Timestep Guidance扰乱模型在不同时间步的去噪策略。通过额外引导嵌入难以察觉的扰动，使其在代表性净化设置下持续存在。

Result: 实验表明，AntiPure在净化-定制工作流中实现了最小的感知差异和最大的失真效果，优于其他保护性扰动方法，作为对净化技术的压力测试表现优异。

Conclusion: AntiPure有效解决了保护性扰动易被净化移除的问题，通过创新的引导机制在扩散模型中实现了持久的抗净化保护，为图像安全提供了新的解决方案。

Abstract: Diffusion models like Stable Diffusion have become prominent in visual
synthesis tasks due to their powerful customization capabilities, which also
introduce significant security risks, including deepfakes and copyright
infringement. In response, a class of methods known as protective perturbation
emerged, which mitigates image misuse by injecting imperceptible adversarial
noise. However, purification can remove protective perturbations, thereby
exposing images again to the risk of malicious forgery. In this work, we
formalize the anti-purification task, highlighting challenges that hinder
existing approaches, and propose a simple diagnostic protective perturbation
named AntiPure. AntiPure exposes vulnerabilities of purification within the
"purification-customization" workflow, owing to two guidance mechanisms: 1)
Patch-wise Frequency Guidance, which reduces the model's influence over
high-frequency components in the purified image, and 2) Erroneous Timestep
Guidance, which disrupts the model's denoising strategy across different
timesteps. With additional guidance, AntiPure embeds imperceptible
perturbations that persist under representative purification settings,
achieving effective post-customization distortion. Experiments show that, as a
stress test for purification, AntiPure achieves minimal perceptual discrepancy
and maximal distortion, outperforming other protective perturbation methods
within the purification-customization workflow.

</details>


### [66] [Dense Video Understanding with Gated Residual Tokenization](https://arxiv.org/abs/2509.14199)
*Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu*

Main category: cs.CV

TL;DR: 提出了Dense Video Understanding (DVU)框架和Gated Residual Tokenization (GRT)方法，通过运动补偿和语义融合技术实现高帧率视频理解，减少计算开销并保持时间细节。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型主要依赖低帧率采样，丢弃了密集时间信息，无法处理需要精确时间对齐的任务（如讲座理解），且现有基准测试关注粗粒度内容变化。

Method: 提出GRT两阶段框架：1）运动补偿门控标记化利用像素级运动估计跳过静态区域；2）语义场景内标记融合合并静态区域内的标记，减少冗余同时保持动态语义。

Result: 在DIVE基准测试上，GRT优于更大的VLLM基线模型，且性能随帧率增加而提升，证明了密集时间信息的重要性。

Conclusion: GRT方法能够实现高效、可扩展的高帧率视频理解，解决了当前视频理解中时间分辨率不足的问题。

Abstract: High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.

</details>


### [67] [Noise-Level Diffusion Guidance: Well Begun is Half Done](https://arxiv.org/abs/2509.13936)
*Harvey Mannering,Zhiwu Huang,Adam Prugel-Bennett*

Main category: cs.CV

TL;DR: 提出Noise Level Guidance (NLG)方法，通过优化初始噪声来提高扩散模型生成质量和提示遵循度，无需额外数据、网络或反向传播


<details>
  <summary>Details</summary>
Motivation: 扩散模型初始高斯噪声的随机性导致输出质量不稳定和提示遵循度差异，现有噪声优化方法需要额外数据集、网络或复杂优化，实用性受限

Method: 提出NLG框架，通过增加初始噪声与通用指导对齐的似然性来优化噪声，适用于条件和无条件扩散模型，兼容各种扩散级指导形式

Result: 在五个标准基准测试中验证，NLG显著提升了生成质量和输入条件遵循度，同时保持计算效率

Conclusion: NLG为扩散模型提供了实用且可扩展的增强方法，能够无缝集成现有指导方法，提升生成性能

Abstract: Diffusion models have achieved state-of-the-art image generation. However,
the random Gaussian noise used to start the diffusion process influences the
final output, causing variations in image quality and prompt adherence.
Existing noise-level optimization approaches generally rely on extra dataset
construction, additional networks, or backpropagation-based optimization,
limiting their practicality. In this paper, we propose Noise Level Guidance
(NLG), a simple, efficient, and general noise-level optimization approach that
refines initial noise by increasing the likelihood of its alignment with
general guidance - requiring no additional training data, auxiliary networks,
or backpropagation. The proposed NLG approach provides a unified framework
generalizable to both conditional and unconditional diffusion models,
accommodating various forms of diffusion-level guidance. Extensive experiments
on five standard benchmarks demonstrate that our approach enhances output
generation quality and input condition adherence. By seamlessly integrating
with existing guidance methods while maintaining computational efficiency, our
method establishes NLG as a practical and scalable enhancement to diffusion
models. Code can be found at
https://github.com/harveymannering/NoiseLevelGuidance.

</details>


### [68] [Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](https://arxiv.org/abs/2509.13939)
*Gia Khanh Nguyen,Yifeng Huang,Minh Hoai*

Main category: cs.CV

TL;DR: PairTally是一个专门用于评估细粒度视觉计数能力的基准数据集，包含681张高分辨率图像，每张图像包含两个物体类别，要求模型基于形状、大小、颜色或语义的细微差异进行区分和计数。


<details>
  <summary>Details</summary>
Motivation: 当前包括类无关计数模型和大型视觉语言模型在内的模型在计数任务中表现出潜力，但它们在执行细粒度、意图驱动的计数方面的能力仍不清楚，需要专门的评估基准。

Method: 构建PairTally数据集，包含681张高分辨率图像，每张图像有两个物体类别，分为类间（不同类别）和类内（密切相关的子类别）两种设置。对多种最先进模型进行基准测试，包括基于示例的方法、语言提示模型和大型视觉语言模型。

Result: 尽管最近有所进展，但当前模型在可靠地计数用户意图方面仍然困难，特别是在细粒度和视觉模糊的情况下。

Conclusion: PairTally为诊断和改进细粒度视觉计数系统提供了新的基础，揭示了当前模型在精细计数任务中的局限性。

Abstract: Visual counting is a fundamental yet challenging task, especially when users
need to count objects of a specific type in complex scenes. While recent
models, including class-agnostic counting models and large vision-language
models (VLMs), show promise in counting tasks, their ability to perform
fine-grained, intent-driven counting remains unclear. In this paper, we
introduce PairTally, a benchmark dataset specifically designed to evaluate
fine-grained visual counting. Each of the 681 high-resolution images in
PairTally contains two object categories, requiring models to distinguish and
count based on subtle differences in shape, size, color, or semantics. The
dataset includes both inter-category (distinct categories) and intra-category
(closely related subcategories) settings, making it suitable for rigorous
evaluation of selective counting capabilities. We benchmark a variety of
state-of-the-art models, including exemplar-based methods, language-prompted
models, and large VLMs. Our results show that despite recent advances, current
models struggle to reliably count what users intend, especially in fine-grained
and visually ambiguous cases. PairTally provides a new foundation for
diagnosing and improving fine-grained visual counting systems.

</details>


### [69] [Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments](https://arxiv.org/abs/2509.14012)
*Tamara R. Lenhard,Andreas Weinmann,Tobias Koch*

Main category: cs.CV

TL;DR: 提出改进版YOLO-FEDER FusionNet无人机检测框架，通过融合通用目标检测和伪装目标检测技术，在复杂视觉环境中显著提升检测性能


<details>
  <summary>Details</summary>
Motivation: 解决无人机在复杂视觉环境中检测困难的问题，包括背景杂乱、目标尺度小和伪装效应等挑战，传统YOLO检测器在低目标-背景分离度的杂乱环境中性能下降

Method: 在原始架构基础上系统改进训练数据组成、特征融合策略和骨干网络设计。使用大规模逼真合成数据配合少量真实样本增强鲁棒性，系统评估多尺度FEDER特征贡献，并在多种YOLO骨干网络上进行基准测试

Result: 最佳配置（YOLOv8l骨干网络+DWD模块FEDER特征）相比初始基线，在IoU阈值0.5时FNR降低达39.1个百分点，mAP提升达62.8个百分点

Conclusion: 集成中间FEDER特征结合骨干网络升级能带来显著性能提升，为复杂视觉环境中的无人机检测提供了有效解决方案

Abstract: Drone detection in visually complex environments remains challenging due to
background clutter, small object scale, and camouflage effects. While generic
object detectors like YOLO exhibit strong performance in low-texture scenes,
their effectiveness degrades in cluttered environments with low
object-background separability. To address these limitations, this work
presents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework
that integrates generic object detection with camouflage object detection
techniques. Building upon the original architecture, the proposed iteration
introduces systematic advancements in training data composition, feature fusion
strategies, and backbone design. Specifically, the training process leverages
large-scale, photo-realistic synthetic data, complemented by a small set of
real-world samples, to enhance robustness under visually complex conditions.
The contribution of intermediate multi-scale FEDER features is systematically
evaluated, and detection performance is comprehensively benchmarked across
multiple YOLO-based backbone configurations. Empirical results indicate that
integrating intermediate FEDER features, in combination with backbone upgrades,
contributes to notable performance improvements. In the most promising
configuration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER
features derived from the DWD module -- these enhancements lead to a FNR
reduction of up to 39.1 percentage points and a mAP increase of up to 62.8
percentage points at an IoU threshold of 0.5, compared to the initial baseline.

</details>


### [70] [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033)
*Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng*

Main category: cs.CV

TL;DR: SAIL-VL2是一个开源的2B和8B参数规模视觉语言基础模型，在106个数据集上表现优异，在MMMU和MathVista等推理基准测试中达到SOTA，OpenCompass排行榜上2B版本在4B参数以下开源模型中排名第一。


<details>
  <summary>Details</summary>
Motivation: 开发一个全面的多模态理解和推理基础模型，作为SAIL-VL的继任者，通过大规模数据策展、渐进式训练框架和架构创新来提升模型能力。

Method: 1) 大规模数据策展管道，采用评分和过滤策略提升数据质量；2) 渐进式训练框架：从预训练视觉编码器开始，经过多模态预训练，最终采用thinking-fusion SFT-RL混合范式；3) 架构创新：扩展到高效的稀疏混合专家(MoE)设计。

Result: 在2B和8B参数规模下，在多样化图像和视频基准测试中达到最先进性能，在106个数据集上表现优异，在MMMU和MathVista等挑战性推理基准测试中取得SOTA结果。

Conclusion: SAIL-VL2通过三项核心创新实现了强大的多模态理解和推理能力，为开源多模态社区提供了高效且可扩展的基础模型，在多个基准测试中展现了竞争优势。

Abstract: We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)
for comprehensive multimodal understanding and reasoning. As the successor to
SAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B
parameter scales across diverse image and video benchmarks, demonstrating
strong capabilities from fine-grained perception to complex reasoning. Three
core innovations drive its effectiveness. First, a large-scale data curation
pipeline with scoring and filtering strategies enhances both quality and
distribution across captioning, OCR, QA, and video data, improving training
efficiency. Second, a progressive training framework begins with a powerful
pre-trained vision encoder (SAIL-ViT), advances through multimodal
pre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that
systematically strengthens model capabilities. Third, architectural advances
extend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.
With these contributions, SAIL-VL2 demonstrates competitive performance across
106 datasets and achieves state-of-the-art results on challenging reasoning
benchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass
leaderboard, SAIL-VL2-2B ranks first among officially released open-source
models under the 4B parameter scale, while serving as an efficient and
extensible foundation for the open-source multimodal community.

</details>


### [71] [PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings](https://arxiv.org/abs/2509.14051)
*Suhang You,Carla Pitarch-Abaigar,Sanket Kachole,Sumedh Sonawane,Juhyung Ha,Anish Sudarshan Gada,David Crandall,Rakesh Shiradkar,Spyridon Bakas*

Main category: cs.CV

TL;DR: PROFUSEme方法通过融合临床、影像和病理多模态数据，使用中间融合策略和Cox比例风险模型，在早期预测前列腺癌根治术后生化复发方面表现出优越性能


<details>
  <summary>Details</summary>
Motivation: 约30%的前列腺癌患者在根治性前列腺切除术后会出现生化复发，准确早期预测BCR有助于临床决策和改善患者预后

Method: 提出PROFUSEme方法，采用中间融合配置学习临床、影像学和病理学数据的跨模态交互，结合Cox比例风险回归器

Result: 在内部5折嵌套交叉验证框架中平均C-index为0.861，在CHIMERA 2025挑战验证排行榜的保留数据上C-index为0.7103，性能优于晚期融合配置

Conclusion: 多模态数据融合方法能够有效预测前列腺癌术后生化复发，为临床早期干预提供重要工具

Abstract: Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy
(RP) experience biochemical recurrence (BCR), characterized by increased
prostate specific antigen (PSA) and associated with increased mortality.
Accurate early prediction of BCR, at the time of RP, would contribute to prompt
adaptive clinical decision-making and improved patient outcomes. In this work,
we propose prostate cancer BCR prediction via fused multi-modal embeddings
(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and
pathology data, following an intermediate fusion configuration in combination
with Cox Proportional Hazard regressors. Quantitative evaluation of our
proposed approach reveals superior performance, when compared with late fusion
configurations, yielding a mean C-index of 0.861 ($\sigma=0.112$) on the
internal 5-fold nested cross-validation framework, and a C-index of 0.7103 on
the hold out data of CHIMERA 2025 challenge validation leaderboard.

</details>


### [72] [Wan-Animate: Unified Character Animation and Replacement with Holistic Replication](https://arxiv.org/abs/2509.14055)
*Gang Cheng,Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Ju Li,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Feng Wang,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-Animate是一个统一的角色动画和替换框架，能够根据参考视频精确复制角色的表情和动作来生成高质量角色视频，或将动画角色无缝集成到参考视频中替换原始角色。


<details>
  <summary>Details</summary>
Motivation: 为了解决角色动画和替换任务中需要高保真度复制表情动作、实现环境光照无缝集成的问题，开发一个统一的框架来处理多种相关任务。

Method: 基于Wan模型构建，采用改进的输入范式区分参考条件和生成区域，使用空间对齐的骨架信号复制身体运动，从源图像提取隐式面部特征重现表情，并开发辅助Relighting LoRA模块增强环境集成效果。

Result: 实验结果表明Wan-Animate达到了最先进的性能水平，能够生成具有高度可控性和表现力的角色视频。

Conclusion: 该框架成功统一了多种角色动画任务，实现了高质量的角色动画生成和环境无缝集成，作者承诺开源模型权重和源代码。

Abstract: We introduce Wan-Animate, a unified framework for character animation and
replacement. Given a character image and a reference video, Wan-Animate can
animate the character by precisely replicating the expressions and movements of
the character in the video to generate high-fidelity character videos.
Alternatively, it can integrate the animated character into the reference video
to replace the original character, replicating the scene's lighting and color
tone to achieve seamless environmental integration. Wan-Animate is built upon
the Wan model. To adapt it for character animation tasks, we employ a modified
input paradigm to differentiate between reference conditions and regions for
generation. This design unifies multiple tasks into a common symbolic
representation. We use spatially-aligned skeleton signals to replicate body
motion and implicit facial features extracted from source images to reenact
expressions, enabling the generation of character videos with high
controllability and expressiveness. Furthermore, to enhance environmental
integration during character replacement, we develop an auxiliary Relighting
LoRA. This module preserves the character's appearance consistency while
applying the appropriate environmental lighting and color tone. Experimental
results demonstrate that Wan-Animate achieves state-of-the-art performance. We
are committed to open-sourcing the model weights and its source code.

</details>


### [73] [VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](https://arxiv.org/abs/2509.14060)
*Jun Du,Weiwei Xing,Ming Li,Fei Richard Yu*

Main category: cs.CV

TL;DR: 提出VSE-MOT框架，通过视觉语言模型提取全局视觉语义信息，提升低质量视频中的多目标跟踪性能


<details>
  <summary>Details</summary>
Motivation: 当前多目标跟踪算法在低质量视频中性能显著下降，需要解决真实世界图像退化问题

Method: 设计三分支架构，利用视觉语言模型提取全局视觉语义信息，并引入MOT-Adapter和VSFM模块进行信息适配和特征融合

Result: 在真实低质量视频场景中跟踪性能指标比现有方法提升8%-20%，在常规场景中保持稳健性能

Conclusion: VSE-MOT框架有效解决了低质量视频中的多目标跟踪问题，具有实际应用价值

Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues
inherent in low-quality videos, leading to significant degradation in tracking
performance when confronted with real-world image deterioration. Therefore,
advancing the application of MOT algorithms in real-world low-quality video
scenarios represents a critical and meaningful endeavor. To address the
challenges posed by low-quality scenarios, inspired by vision-language models,
this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking
framework (VSE-MOT). Specifically, we first design a tri-branch architecture
that leverages a vision-language model to extract global visual semantic
information from images and fuse it with query vectors. Subsequently, to
further enhance the utilization of visual semantic information, we introduce
the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion
Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic
information to suit multi-object tracking tasks, while the VSFM improves the
efficacy of feature fusion. Through extensive experiments, we validate the
effectiveness and superiority of the proposed method in real-world low-quality
video scenarios. Its tracking performance metrics outperform those of existing
methods by approximately 8% to 20%, while maintaining robust performance in
conventional scenarios.

</details>


### [74] [AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration](https://arxiv.org/abs/2509.14084)
*Jingyi Yuan,Jianxiong Ye,Wenkang Chen,Chenqiang Gao*

Main category: cs.CV

TL;DR: AD-DINOv3是一个基于DINOv3的零样本异常检测框架，通过多模态对比学习和异常感知校准模块解决特征对齐和语义偏差问题，在工业和医疗基准测试中达到或超越SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统零样本异常检测主要基于CLIP模型，而DINOv3等视觉基础模型展现出强大的可迁移表示能力。但将DINOv3应用于异常检测面临两个关键挑战：领域偏差导致特征不对齐，以及预训练表示偏向全局语义而忽略细微异常。

Method: 提出AD-DINOv3多模态框架：1）将异常检测建模为多模态对比学习问题；2）使用DINOv3提取视觉特征，CLIP文本编码器提供正常/异常提示嵌入；3）引入轻量级适配器桥接领域差距；4）设计异常感知校准模块引导CLS token关注异常区域。

Result: 在8个工业和医疗基准测试上的广泛实验表明，AD-DINOv3始终匹配或超越最先进方法，验证了其作为通用零样本异常检测框架的优越性。

Conclusion: AD-DINOv3成功将DINOv3适配到零样本异常检测任务，通过多模态对比学习和异常感知校准有效解决了特征对齐和语义偏差问题，为异常检测提供了强大的通用框架。

Abstract: Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary
novel categories, offering a scalable and annotation-efficient solution.
Traditionally, most ZSAD works have been based on the CLIP model, which
performs anomaly detection by calculating the similarity between visual and
text embeddings. Recently, vision foundation models such as DINOv3 have
demonstrated strong transferable representation capabilities. In this work, we
are the first to adapt DINOv3 for ZSAD. However, this adaptation presents two
key challenges: (i) the domain bias between large-scale pretraining data and
anomaly detection tasks leads to feature misalignment; and (ii) the inherent
bias toward global semantics in pretrained representations often leads to
subtle anomalies being misinterpreted as part of the normal foreground objects,
rather than being distinguished as abnormal regions. To overcome these
challenges, we introduce AD-DINOv3, a novel vision-language multimodal
framework designed for ZSAD. Specifically, we formulate anomaly detection as a
multimodal contrastive learning problem, where DINOv3 is employed as the visual
backbone to extract patch tokens and a CLS token, and the CLIP text encoder
provides embeddings for both normal and abnormal prompts. To bridge the domain
gap, lightweight adapters are introduced in both modalities, enabling their
representations to be recalibrated for the anomaly detection task. Beyond this
baseline alignment, we further design an Anomaly-Aware Calibration Module
(AACM), which explicitly guides the CLS token to attend to anomalous regions
rather than generic foreground semantics, thereby enhancing discriminability.
Extensive experiments on eight industrial and medical benchmarks demonstrate
that AD-DINOv3 consistently matches or surpasses state-of-the-art methods,
verifying its superiority as a general zero-shot anomaly detection framework.

</details>


### [75] [Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing](https://arxiv.org/abs/2509.14097)
*Yaru Chen,Ruohao Guo,Liting Gao,Yang Xiang,Qingyu Luo,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 该论文提出了两种策略来解决弱监督音频-视觉视频解析问题：EMA引导的伪监督框架和类感知跨模态一致性损失，在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督音频-视觉视频解析方法主要关注通过对比学习或协作学习来优化全局预测，但忽视了稳定的片段级监督和类感知的跨模态对齐，这限制了性能提升。

Method: 提出了两种策略：(1) EMA引导的伪监督框架，通过自适应阈值或top-k选择生成可靠的片段级掩码；(2) 类感知跨模态一致性(CMA)损失，在可靠的片段-类别对上对齐音频和视觉嵌入。

Result: 在LLP和UnAV-100数据集上的评估表明，该方法在多个指标上达到了最先进的性能。

Conclusion: 所提出的EMA伪监督框架和CMA损失能够有效提供稳定的片段级监督和跨模态对齐，显著提升了弱监督音频-视觉视频解析的性能。

Abstract: Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,
visible, and audio-visual events without temporal annotations. Previous work
has emphasized refining global predictions through contrastive or collaborative
learning, but neglected stable segment-level supervision and class-aware
cross-modal alignment. To address this, we propose two strategies: (1) an
exponential moving average (EMA)-guided pseudo supervision framework that
generates reliable segment-level masks via adaptive thresholds or top-k
selection, offering stable temporal guidance beyond video-level labels; and (2)
a class-aware cross-modal agreement (CMA) loss that aligns audio and visual
embeddings at reliable segment-class pairs, ensuring consistency across
modalities while preserving temporal structure. Evaluations on LLP and UnAV-100
datasets shows that our method achieves state-of-the-art (SOTA) performance
across multiple metrics.

</details>


### [76] [CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts](https://arxiv.org/abs/2509.14104)
*Leonard Hackel,Tom Burgert,Begüm Demir*

Main category: cs.CV

TL;DR: 该论文提出了一种通过集成软混合专家(Soft MoE)机制来提升遥感基础模型效率的方法，创建了Cross-Sensor Mixture-of-Experts (CSMoE)模型，在保持或提升表征性能的同时显著降低计算需求


<details>
  <summary>Details</summary>
Motivation: 现有遥感基础模型要么计算复杂度高，要么表征能力有限，限制了实际应用。需要开发计算效率更高的模型来提升实用性

Method: 将软混合专家(Soft MoE)机制集成到Cross-Sensor Masked Autoencoder中，结合主题-气候描述符驱动的采样策略构建多样化训练集

Result: CSMoE模型在场景分类、语义分割和基于内容的图像检索任务中，平均计算效率是现有遥感基础模型的两倍以上，同时保持竞争性性能

Conclusion: 提出的软混合专家集成方法有效创建了计算效率更高的遥感基础模型，在表征能力、准确性和计算效率之间实现了优越的平衡

Abstract: Self-supervised learning through masked autoencoders has attracted great
attention for remote sensing (RS) foundation model (FM) development, enabling
improved representation learning across diverse sensors and downstream tasks.
However, existing RS FMs often either suffer from substantial computational
complexity during both training and inference or exhibit limited
representational capacity. These issues restrict their practical applicability
in RS. To address this limitation, we propose an adaptation for enhancing the
efficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism
into the FM. The integration of Soft MoEs into the FM allows modality-specific
expert specialization alongside shared cross-sensor representation learning. To
demonstrate the effectiveness of our adaptation, we apply it on the
Cross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor
Mixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic
descriptor-driven sampling strategy for the construction of a representative
and diverse training set to train our CSMoE model. Extensive experiments on
scene classification, semantic segmentation, and content-based image retrieval
demonstrate that our adaptation yields a reduction in computational
requirements while maintaining or improving representational performance.
Compared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off
between representational capacity, accuracy, and computational efficiency. On
average, CSMoE achieves more than twice the computational efficiency of
existing RS FMs, while maintaining competitive performance across all
experiments. These results show the effectiveness of the proposed adaptation
for creating computationally efficient RS FMs. The code for the model, the
training set creation, and the model weights will be available at
https://git.tu-berlin.de/rsim/csmoe.

</details>


### [77] [Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows](https://arxiv.org/abs/2509.14119)
*Jiabo MA,Wenqiang Li,Jinbang Li,Ziyi Liu,Linshan Wu,Fengtao Zhou,Li Liang,Ronald Cheong Kin Chan,Terence T. W. Wong,Hao Chen*

Main category: cs.CV

TL;DR: 提出了一种具有级联配准机制的鲁棒虚拟染色框架，解决了虚拟染色中因组织变形导致的像素级监督困难问题，在多个数据集上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统组织病理学诊断需要多种化学染色，过程耗时、劳动密集且对环境不友好。现有虚拟染色方法依赖良好对齐的配对数据，但由于化学染色过程会导致组织结构变形，获取精确配对的训练数据非常困难

Method: 提出了包含级联配准机制的虚拟染色框架，通过配准机制解决生成输出与真实标签之间的空间不匹配问题，从而在非精确配对数据上实现有效的像素级监督

Result: 在五个数据集上显著优于最先进模型，内部数据集平均提升3.2%，外部数据集提升10.1%。在严重不对齐的数据集上，PSNR比基线模型提升23.8%

Conclusion: 该方法具有出色的跨数据集鲁棒性，简化了虚拟染色的数据采集过程，为推进虚拟染色技术的发展提供了新思路

Abstract: Accurate histopathological diagnosis often requires multiple differently
stained tissue sections, a process that is time-consuming, labor-intensive, and
environmentally taxing due to the use of multiple chemical stains. Recently,
virtual staining has emerged as a promising alternative that is faster,
tissue-conserving, and environmentally friendly. However, existing virtual
staining methods face significant challenges in clinical applications,
primarily due to their reliance on well-aligned paired data. Obtaining such
data is inherently difficult because chemical staining processes can distort
tissue structures, and a single tissue section cannot undergo multiple staining
procedures without damage or loss of information. As a result, most available
virtual staining datasets are either unpaired or roughly paired, making it
difficult for existing methods to achieve accurate pixel-level supervision. To
address this challenge, we propose a robust virtual staining framework
featuring cascaded registration mechanisms to resolve spatial mismatches
between generated outputs and their corresponding ground truth. Experimental
results demonstrate that our method significantly outperforms state-of-the-art
models across five datasets, achieving an average improvement of 3.2% on
internal datasets and 10.1% on external datasets. Moreover, in datasets with
substantial misalignment, our approach achieves a remarkable 23.8% improvement
in peak signal-to-noise ratio compared to baseline models. The exceptional
robustness of the proposed method across diverse datasets simplifies the data
acquisition process for virtual staining and offers new insights for advancing
its development.

</details>


### [78] [Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection](https://arxiv.org/abs/2509.14120)
*Sara Concas,Simone Maurizio La Cava,Andrea Panzino,Ester Masala,Giulia Orrù,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 美颜滤镜会降低深度伪造和变形攻击检测器的性能，导致检测准确率下降，凸显了需要开发对这些面部美化操作具有鲁棒性的检测模型的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体美颜滤镜的普及，面部图像和视频的可靠性受到质疑，特别是对于旨在区分真实和伪造数据的数字操纵检测器。本研究探讨美颜滤镜是否影响深度伪造和变形攻击检测器的性能。

Method: 对多个最先进的检测器在基准数据集上进行全面分析，评估应用各种平滑滤镜前后的性能表现。

Result: 研究发现检测器性能出现退化，美颜滤镜引入了检测漏洞。

Conclusion: 面部美化操作会削弱检测器的有效性，迫切需要开发对这些修改具有鲁棒性的检测模型。

Abstract: Digital beautification through social media filters has become increasingly
popular, raising concerns about the reliability of facial images and videos and
the effectiveness of automated face analysis. This issue is particularly
critical for digital manipulation detectors, systems aiming at distinguishing
between genuine and manipulated data, especially in cases involving deepfakes
and morphing attacks designed to deceive humans and automated facial
recognition. This study examines whether beauty filters impact the performance
of deepfake and morphing attack detectors. We perform a comprehensive analysis,
evaluating multiple state-of-the-art detectors on benchmark datasets before and
after applying various smoothing filters. Our findings reveal performance
degradation, highlighting vulnerabilities introduced by facial enhancements and
underscoring the need for robust detection models resilient to such
alterations.

</details>


### [79] [MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook](https://arxiv.org/abs/2509.14142)
*Peng Xu,Shengwu Xiong,Jiajun Zhang,Yaxiong Chen,Bowen Zhou,Chen Change Loy,David A. Clifton,Kyoung Mu Lee,Luc Van Gool,Ruiming He,Ruilin Yao,Xinwei Long,Jirui Huang,Kai Tian,Sa Yang,Yihua Shao,Jin Feng,Yue Zhong,Jiakai Zhou,Cheng Tang,Tianyu Zou,Yifang Zhang,Junming Liang,Guoyou Li,Zhaoxiang Wang,Qiang Zhou,Yichen Zhao,Shili Xiong,Hyeongjin Nam,Jaerin Lee,Jaeyoung Chung,JoonKyu Park,Junghun Oh,Kanggeon Lee,Wooseok Lee,Juneyoung Ro,Turghun Osman,Can Hu,Chaoyang Liao,Cheng Chen,Chengcheng Han,Chenhao Qiu,Chong Peng,Cong Xu,Dailin Li,Feiyu Wang,Feng Gao,Guibo Zhu,Guopeng Tang,Haibo Lu,Han Fang,Han Qi,Hanxiao Wu,Haobo Cheng,Hongbo Sun,Hongyao Chen,Huayong Hu,Hui Li,Jiaheng Ma,Jiang Yu,Jianing Wang,Jie Yang,Jing He,Jinglin Zhou,Jingxuan Li,Josef Kittler,Lihao Zheng,Linnan Zhao,Mengxi Jia,Muyang Yan,Nguyen Thanh Thien,Pu Luo,Qi Li,Shien Song,Shijie Dong,Shuai Shao,Shutao Li,Taofeng Xue,Tianyang Xu,Tianyi Gao,Tingting Li,Wei Zhang,Weiyang Su,Xiaodong Dong,Xiao-Jun Wu,Xiaopeng Zhou,Xin Chen,Xin Wei,Xinyi You,Xudong Kang,Xujie Zhou,Xusheng Liu,Yanan Wang,Yanbin Huang,Yang Liu,Yang Yang,Yanglin Deng,Yashu Kang,Ye Yuan,Yi Wen,Yicen Tian,Yilin Tao,Yin Tang,Yipeng Lin,Yiqing Wang,Yiting Xi,Yongkang Yu,Yumei Li,Yuxin Qin,Yuying Chen,Yuzhe Cen,Zhaofan Zou,Zhaohong Liu,Zhehao Shen,Zhenglin Du,Zhengyang Li,Zhenni Huang,Zhenwei Shao,Zhilong Song,Zhiyong Feng,Zhiyu Wang,Zhou Yu,Ziang Li,Zihan Zhai,Zijian Zhang,Ziyang Peng,Ziyun Xiao,Zongshu Li*

Main category: cs.CV

TL;DR: MARS2 2025挑战赛综述，聚焦多模态推理，发布了Lens和AdsQA两个数据集，评估了40+基线模型，吸引了76个团队参与，设立了三个竞赛赛道。


<details>
  <summary>Details</summary>
Motivation: 通过大规模基准测试汇集多模态机器学习和LLM的不同方法，跟踪这一快速发展领域的最新技术，并专注于现实世界和专业化场景以拓宽多模态推理应用。

Method: 发布两个定制数据集(Lens和AdsQA)，评估40+基线模型(包括通用MLLM和任务特定模型)，设立三个竞赛赛道(VG-RS、VQA-SA、VR-Ads)。

Result: 76个知名学术和工业机构团队注册，40+有效提交(从1200+中筛选)进入排名榜单，数据集、代码集和排名结果公开可用。

Conclusion: MARS2 2025挑战赛成功推动了多模态推理领域的发展，为研究者提供了全面的基准测试资源和竞争平台，相关资源将持续更新并提供未来活动公告。

Abstract: This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim
to bring together different approaches in multimodal machine learning and LLMs
via a large benchmark. We hope it better allows researchers to follow the
state-of-the-art in this very dynamic area. Meanwhile, a growing number of
testbeds have boosted the evolution of general-purpose large language models.
Thus, this year's MARS2 focuses on real-world and specialized scenarios to
broaden the multimodal reasoning applications of MLLMs. Our organizing team
released two tailored datasets Lens and AdsQA as test sets, which support
general reasoning in 12 daily scenarios and domain-specific reasoning in
advertisement videos, respectively. We evaluated 40+ baselines that include
both generalist MLLMs and task-specific models, and opened up three competition
tracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question
Answering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative
Advertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and
industrial institutions have registered and 40+ valid submissions (out of
1200+) have been included in our ranking lists. Our datasets, code sets (40+
baselines and 15+ participants' methods), and rankings are publicly available
on the MARS2 workshop website and our GitHub organization page
https://github.com/mars2workshop/, where our updates and announcements of
upcoming events will be continuously provided.

</details>


### [80] [An Exploratory Study on Abstract Images and Visual Representations Learned from Them](https://arxiv.org/abs/2509.14149)
*Haotian Li,Jianbo Jiao*

Main category: cs.CV

TL;DR: 该论文研究了抽象图像（由基本几何形状构成）与传统光栅图像在视觉语义信息传递方面的性能差距，通过构建分层抽象图像数据集HAID，在不同抽象层级上评估视觉系统的表现。


<details>
  <summary>Details</summary>
Motivation: 探索抽象图像能否有效传递视觉语义信息，以及为什么抽象图像的表现通常不如传统光栅图像，研究不同抽象层级对语义内容捕获能力的影响。

Method: 构建分层抽象图像数据集HAID，该数据集包含从正常光栅图像在不同抽象层级生成的抽象图像。在HAID上训练和评估传统视觉系统，进行包括分类、分割和目标检测在内的多种任务测试。

Result: 通过系统性的实验比较，揭示了抽象图像与光栅图像在视觉任务表现上的差异，量化了不同抽象层级对语义信息捕获的影响程度。

Conclusion: 研究探讨了抽象图像作为视觉语义信息传递格式的潜在有效性，为理解图像抽象化对计算机视觉任务的影响提供了全面的实证分析。

Abstract: Imagine living in a world composed solely of primitive shapes, could you
still recognise familiar objects? Recent studies have shown that abstract
images-constructed by primitive shapes-can indeed convey visual semantic
information to deep learning models. However, representations obtained from
such images often fall short compared to those derived from traditional raster
images. In this paper, we study the reasons behind this performance gap and
investigate how much high-level semantic content can be captured at different
abstraction levels. To this end, we introduce the Hierarchical Abstraction
Image Dataset (HAID), a novel data collection that comprises abstract images
generated from normal raster images at multiple levels of abstraction. We then
train and evaluate conventional vision systems on HAID across various tasks
including classification, segmentation, and object detection, providing a
comprehensive study between rasterised and abstract image representations. We
also discuss if the abstract image can be considered as a potentially effective
format for conveying visual semantic information and contributing to vision
tasks.

</details>


### [81] [BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection](https://arxiv.org/abs/2509.14151)
*Rongyu Zhang,Jiaming Liu,Xiaoqi Li,Xiaowei Chi,Dan Wang,Li Du,Yuan Du,Shanghang Zhang*

Main category: cs.CV

TL;DR: BEVUDA++是一个几何感知的师生框架，通过可靠深度教师和几何一致学生模型解决BEV感知中的域适应问题，在跨域3D目标检测中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 鸟瞰图(BEV)感知在自动驾驶中很重要，但现有研究忽视了域偏移问题，导致跨域时性能显著下降。作者首次尝试解决多视图3D目标检测中的域适应挑战

Method: 提出BEVUDA++框架，包含可靠深度教师(RDT)和几何一致学生(GCS)模型。RDT融合目标LiDAR和可靠深度预测生成深度感知信息，GCS将多空间特征映射到统一几何嵌入空间。还引入不确定性引导指数移动平均(UEMA)减少误差累积

Result: 在四个跨域场景中进行全面实验，在BEV 3D目标检测任务中达到最先进性能，例如在日夜适应上提升12.9% NDS和9.5% mAP

Conclusion: 该方法有效解决了BEV感知中的域适应问题，通过几何感知的师生框架显著提升了跨域场景下的3D目标检测性能

Abstract: Vision-centric Bird's Eye View (BEV) perception holds considerable promise
for autonomous driving. Recent studies have prioritized efficiency or accuracy
enhancements, yet the issue of domain shift has been overlooked, leading to
substantial performance degradation upon transfer. We identify major domain
gaps in real-world cross-domain scenarios and initiate the first effort to
address the Domain Adaptation (DA) challenge in multi-view 3D object detection
for BEV perception. Given the complexity of BEV perception approaches with
their multiple components, domain shift accumulation across multi-geometric
spaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain
adaptation. In this paper, we introduce an innovative geometric-aware
teacher-student framework, BEVUDA++, to diminish this issue, comprising a
Reliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model.
Specifically, RDT effectively blends target LiDAR with dependable depth
predictions to generate depth-aware information based on uncertainty
estimation, enhancing the extraction of Voxel and BEV features that are
essential for understanding the target domain. To collaboratively reduce the
domain shift, GCS maps features from multiple spaces into a unified geometric
embedding space, thereby narrowing the gap in data distribution between the two
domains. Additionally, we introduce a novel Uncertainty-guided Exponential
Moving Average (UEMA) to further reduce error accumulation due to domain shifts
informed by previously obtained uncertainty guidance. To demonstrate the
superiority of our proposed method, we execute comprehensive experiments in
four cross-domain scenarios, securing state-of-the-art performance in BEV 3D
object detection tasks, e.g., 12.9\% NDS and 9.5\% mAP enhancement on Day-Night
adaptation.

</details>


### [82] [Cinéaste: A Fine-grained Contextual Movie Question Answering Benchmark](https://arxiv.org/abs/2509.14227)
*Nisarg A. Shah,Amir Ziai,Chaitanya Ekanadham,Vishal M. Patel*

Main category: cs.CV

TL;DR: Cineaste是一个针对长视频电影理解的综合基准测试，包含3119个多选题，涵盖200部电影的1805个场景，测试5种细粒度推理能力，现有模型表现不佳（最高63.15%准确率）。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准主要测试短片段识别或模板化问题，缺乏对长叙事内容的细粒度推理能力评估，需要专门针对电影长视频理解的评测基准。

Method: 使用GPT-4o整合视觉描述、字幕、场景标题和摘要生成多样化问题，采用两阶段过滤：上下文独立性过滤确保问题需要视频上下文，上下文真实性过滤验证事实一致性。

Result: 现有多模态大语言模型在Cineaste基准上表现不佳，长时序推理是主要瓶颈，最佳开源模型准确率仅为63.15%。

Conclusion: 该基准揭示了现有模型在细粒度上下文理解和长视频电影理解方面的显著挑战，需要进一步的技术进步。

Abstract: While recent advancements in vision-language models have improved video
understanding, diagnosing their capacity for deep, narrative comprehension
remains a challenge. Existing benchmarks often test short-clip recognition or
use template-based questions, leaving a critical gap in evaluating fine-grained
reasoning over long-form narrative content. To address these gaps, we introduce
$\mathsf{Cin\acute{e}aste}$, a comprehensive benchmark for long-form movie
understanding. Our dataset comprises 3,119 multiple-choice question-answer
pairs derived from 1,805 scenes across 200 diverse movies, spanning five novel
fine-grained contextual reasoning categories. We use GPT-4o to generate
diverse, context-rich questions by integrating visual descriptions, captions,
scene titles, and summaries, which require deep narrative understanding. To
ensure high-quality evaluation, our pipeline incorporates a two-stage filtering
process: Context-Independence filtering ensures questions require video
context, while Contextual Veracity filtering validates factual consistency
against the movie content, mitigating hallucinations. Experiments show that
existing MLLMs struggle on $\mathsf{Cin\acute{e}aste}$; our analysis reveals
that long-range temporal reasoning is a primary bottleneck, with the top
open-source model achieving only 63.15\% accuracy. This underscores significant
challenges in fine-grained contextual understanding and the need for
advancements in long-form movie comprehension.

</details>


### [83] [GenExam: A Multidisciplinary Text-to-Image Exam](https://arxiv.org/abs/2509.14232)
*Zhaokai Wang,Penghao Yin,Xiangyu Zhao,Changyao Tian,Yu Qiao,Wenhai Wang,Jifeng Dai,Gen Luo*

Main category: cs.CV

TL;DR: GenExam是首个多学科文本到图像考试基准，包含10个学科的1000个样本，采用四级分类法组织考试式提示，用于精确评估语义正确性和视觉合理性。


<details>
  <summary>Details</summary>
Motivation: 现有考试式基准主要关注理解和推理任务，而当前生成基准强调世界知识和视觉概念的展示，忽视了严格绘图考试的评估。

Method: 构建包含1000个样本的多学科文本到图像考试基准，每个问题配备真实图像和细粒度评分点，采用四级分类法组织考试式提示。

Result: 实验显示即使最先进的模型如GPT-Image-1和Gemini-2.5-Flash-Image的严格得分也低于15%，大多数模型得分接近0%，表明该基准的巨大挑战性。

Conclusion: 通过将图像生成框架为考试，GenExam提供了对模型整合知识、推理和生成能力的严格评估，为通往通用AGI的道路提供了见解。

Abstract: Exams are a fundamental test of expert-level intelligence and require
integrated understanding, reasoning, and generation. Existing exam-style
benchmarks mainly focus on understanding and reasoning tasks, and current
generation benchmarks emphasize the illustration of world knowledge and visual
concepts, neglecting the evaluation of rigorous drawing exams. We introduce
GenExam, the first benchmark for multidisciplinary text-to-image exams,
featuring 1,000 samples across 10 subjects with exam-style prompts organized
under a four-level taxonomy. Each problem is equipped with ground-truth images
and fine-grained scoring points to enable a precise evaluation of semantic
correctness and visual plausibility. Experiments show that even
state-of-the-art models such as GPT-Image-1 and Gemini-2.5-Flash-Image achieve
less than 15% strict scores, and most models yield almost 0%, suggesting the
great challenge of our benchmark. By framing image generation as an exam,
GenExam offers a rigorous assessment of models' ability to integrate knowledge,
reasoning, and generation, providing insights on the path to general AGI.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [84] [MA-DPR: Manifold-aware Distance Metrics for Dense Passage Retrieval](https://arxiv.org/abs/2509.13562)
*Yifan Liu,Qianfeng Wen,Mark Zhao,Jiazhou Liang,Scott Sanner*

Main category: cs.IR

TL;DR: 提出了一种基于流形感知距离的密集段落检索方法(MA-DPR)，通过构建最近邻图来建模段落嵌入的非线性流形结构，在分布外检索任务上比欧氏距离和余弦距离提升达26%


<details>
  <summary>Details</summary>
Motivation: 传统的欧氏距离和余弦距离假设嵌入位于线性流形上，但实验发现实际嵌入往往位于低维非线性流形上，特别是在分布外设置中，传统距离度量无法有效捕捉语义相似性

Method: 使用最近邻图建模段落嵌入的固有流形结构，通过计算查询与段落在图中的最短路径距离来衡量相关性，能够利用相邻段落的上下文信息

Result: 在分布外段落检索任务上比欧氏距离和余弦距离提升高达26%，在分布内性能相当，查询推理时间仅轻微增加

Conclusion: MA-DPR方法能够有效处理嵌入的非线性流形结构，即使在缺乏直接语义重叠的情况下也能有效工作，可广泛应用于各种密集嵌入和检索任务

Abstract: Dense Passage Retrieval (DPR) typically relies on Euclidean or cosine
distance to measure query-passage relevance in embedding space, which is
effective when embeddings lie on a linear manifold. However, our experiments
across DPR benchmarks suggest that embeddings often lie on lower-dimensional,
non-linear manifolds, especially in out-of-distribution (OOD) settings, where
cosine and Euclidean distance fail to capture semantic similarity. To address
this limitation, we propose a manifold-aware distance metric for DPR (MA-DPR)
that models the intrinsic manifold structure of passages using a nearest
neighbor graph and measures query-passage distance based on their shortest path
in this graph. We show that MA-DPR outperforms Euclidean and cosine distances
by up to 26% on OOD passage retrieval with comparable in-distribution
performance across various embedding models while incurring a minimal increase
in query inference time. Empirical evidence suggests that manifold-aware
distance allows DPR to leverage context from related neighboring passages,
making it effective even in the absence of direct semantic overlap. MADPR can
be applied to a wide range of dense embedding and retrieval tasks, offering
potential benefits across a wide spectrum of domains.

</details>


### [85] [Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation](https://arxiv.org/abs/2509.13603)
*Yongye Su,Zeya Zhang,Jane Kou,Cheng Ju,Shubhojeet Sarkar,Yamin Wang,Ji Liu,Shengbo Guo*

Main category: cs.IR

TL;DR: Facebook提出混合关键词检索和嵌入检索的社交网络搜索框架，通过LLM评估显著提升搜索相关性和用户参与度


<details>
  <summary>Details</summary>
Motivation: 社交网络搜索需要在其社交背景下检索信息和发现潜在连接，传统关键词搜索在语义相关性和多样性方面存在局限

Method: 将语义检索集成到现有关键词搜索管道中，结合传统关键词检索和嵌入检索(EBR)，并引入基于LLM的离线相关性评估框架

Result: 混合检索系统显著提升了用户参与度和搜索质量，在线指标和LLM评估均验证了效果

Conclusion: 这项工作为在大规模真实社交平台部署和评估高级检索系统提供了实用见解

Abstract: Beyond general web-scale search, social network search uniquely enables users
to retrieve information and discover potential connections within their social
context. We introduce a framework of modernized Facebook Group Scoped Search by
blending traditional keyword-based retrieval with embedding-based retrieval
(EBR) to improve the search relevance and diversity of search results. Our
system integrates semantic retrieval into the existing keyword search pipeline,
enabling users to discover more contextually relevant group posts. To
rigorously assess the impact of this blended approach, we introduce a novel
evaluation framework that leverages large language models (LLMs) to perform
offline relevance assessments, providing scalable and consistent quality
benchmarks. Our results demonstrate that the blended retrieval system
significantly enhances user engagement and search quality, as validated by both
online metrics and LLM-based evaluation. This work offers practical insights
for deploying and evaluating advanced retrieval systems in large-scale,
real-world social platforms.

</details>


### [86] [Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval](https://arxiv.org/abs/2509.13626)
*Amanda Chan,James Jiayu Liu,He Kai,Onno P. Kampman*

Main category: cs.IR

TL;DR: 提出基于AI的语料库增强框架，通过分析用户自然语言数据识别知识缺口，有针对性地扩充内容，相比随机扩充可大幅减少所需内容量就能达到接近最优检索性能


<details>
  <summary>Details</summary>
Motivation: 解决心理健康信息检索系统在面对未覆盖话题或非正式表达时的性能不佳问题，传统知识库扩展方式资源密集且与用户需求不匹配

Method: 开发缺口导向的语料库增强框架，通过叠加用户论坛帖子等自然数据识别代表性不足的主题，基于覆盖度和有用性优先扩展

Result: 定向扩充仅需较小扩展量（42%-318%）就能达到参考语料库95%的性能，而非定向扩充需要更大扩展量（232%-763%）

Conclusion: 战略性目标语料增长可减少内容创建需求同时维持高质量检索，为构建可信健康信息库和支持高风险领域生成AI应用提供可扩展方案

Abstract: Access to reliable mental health information is vital for early help-seeking,
yet expanding knowledge bases is resource-intensive and often misaligned with
user needs. This results in poor performance of retrieval systems when
presented concerns are not covered or expressed in informal or contextualized
language. We present an AI-based gap-informed framework for corpus augmentation
that authentically identifies underrepresented topics (gaps) by overlaying
naturalistic user data such as forum posts in order to prioritize expansions
based on coverage and usefulness. In a case study, we compare Directed
(gap-informed augmentations) with Non-Directed augmentation (random additions),
evaluating the relevance and usefulness of retrieved information across four
retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved
near-optimal performance with modest expansions--requiring only a 42% increase
for Query Transformation, 74% for Reranking and Hierarchical, and 318% for
Baseline--to reach ~95% of the performance of an exhaustive reference corpus.
In contrast, Non-Directed augmentation required substantially larger and thus
practically infeasible expansions to achieve comparable performance (232%,
318%, 403%, and 763%, respectively). These results show that strategically
targeted corpus growth can reduce content creation demands while sustaining
high retrieval and provision quality, offering a scalable approach for building
trusted health information repositories and supporting generative AI
applications in high-stakes domains.

</details>


### [87] [Enhancing Time Awareness in Generative Recommendation](https://arxiv.org/abs/2509.13957)
*Sunkyung Lee,Seongmin Park,Jonghyo Kim,Mincheol Yoon,Jongwuk Lee*

Main category: cs.IR

TL;DR: GRUT是一个生成式推荐模型，通过时间感知提示和趋势感知推理来捕捉用户偏好随时间的变化，在四个基准数据集上Recall@5和NDCG@5指标提升超过14%


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法主要关注物品序列顺序，但忽略了物品间的时间动态性，无法捕捉用户偏好的演化过程

Method: 提出时间感知提示（用户级时间上下文和物品级转移上下文）和训练免费的趋势感知推理方法，结合生成概率和趋势信息来提升推荐排名

Result: 在四个基准数据集上，Recall@5和NDCG@5指标分别提升15.4%和14.3%，显著优于现有最先进模型

Conclusion: GRUT通过有效建模时间动态性，成功捕捉了用户偏好的演化模式，为生成式推荐提供了新的时间感知解决方案

Abstract: Generative recommendation has emerged as a promising paradigm that formulates
the recommendations into a text-to-text generation task, harnessing the vast
knowledge of large language models. However, existing studies focus on
considering the sequential order of items and neglect to handle the temporal
dynamics across items, which can imply evolving user preferences. To address
this limitation, we propose a novel model, Generative Recommender Using Time
awareness (GRUT), effectively capturing hidden user preferences via various
temporal signals. We first introduce Time-aware Prompting, consisting of two
key contexts. The user-level temporal context models personalized temporal
patterns across timestamps and time intervals, while the item-level transition
context provides transition patterns across users. We also devise Trend-aware
Inference, a training-free method that enhances rankings by incorporating trend
information about items with generation likelihood. Extensive experiments
demonstrate that GRUT outperforms state-of-the-art models, with gains of up to
15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The
source code is available at https://github.com/skleee/GRUT.

</details>


### [88] [GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing](https://arxiv.org/abs/2509.14221)
*Silan Hu,Shiqi Zhang,Yimin Shi,Xiaokui Xiao*

Main category: cs.IR

TL;DR: GEM-Bench是首个针对生成式引擎营销中广告注入响应生成的综合基准，包含三个数据集、多维度评估指标和可扩展的多智能体框架基线方法


<details>
  <summary>Details</summary>
Motivation: 生成式引擎营销(GEM)是一个新兴的生态系统，通过将相关广告无缝集成到LLM聊天机器人的响应中来变现。但现有基准并非专门为此设计，限制了未来研究

Method: 提出GEM-Bench基准，包括：1）覆盖聊天机器人和搜索场景的三个精选数据集；2）捕捉用户满意度和参与度多维度指标的度量本体；3）在可扩展多智能体框架中实现的多个基线解决方案

Result: 初步结果表明：基于简单提示的方法能获得合理的参与度（如点击率），但通常会降低用户满意度；而基于预生成无广告响应插入广告的方法有助于缓解此问题，但会引入额外开销

Conclusion: 这些发现凸显了未来需要研究设计更有效和高效的解决方案，用于在GEM中生成广告注入响应

Abstract: Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing
generative engines, such as LLM-based chatbots, by seamlessly integrating
relevant advertisements into their responses. At the core of GEM lies the
generation and evaluation of ad-injected responses. However, existing
benchmarks are not specifically designed for this purpose, which limits future
research. To address this gap, we propose GEM-Bench, the first comprehensive
benchmark for ad-injected response generation in GEM. GEM-Bench includes three
curated datasets covering both chatbot and search scenarios, a metric ontology
that captures multiple dimensions of user satisfaction and engagement, and
several baseline solutions implemented within an extensible multi-agent
framework. Our preliminary results indicate that, while simple prompt-based
methods achieve reasonable engagement such as click-through rate, they often
reduce user satisfaction. In contrast, approaches that insert ads based on
pre-generated ad-free responses help mitigate this issue but introduce
additional overhead. These findings highlight the need for future research on
designing more effective and efficient solutions for generating ad-injected
responses in GEM.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [89] [Behind India's ChatGPT Conversations: A Retrospective Analysis of 238 Unedited User Prompts](https://arxiv.org/abs/2509.13337)
*Kalyani Khona*

Main category: cs.CY

TL;DR: 该研究通过回顾性调查方法收集了40名印度城市专业人士的238个真实ChatGPT使用提示，发现85%的用户每日使用，42.5%主要用于工作流程，用户将ChatGPT视为综合生活助手而非专业工具。


<details>
  <summary>Details</summary>
Motivation: 理解用户如何真实地与大型语言模型互动是重要挑战，现有研究多依赖自我报告或受控实验，可能遗漏真实的行为适应模式。

Method: 采用回顾性匿名社交媒体调查方法，收集15+印度城市40名英语使用城市专业人士的238个未经编辑的真实用户提示，最小化实时观察者效应。

Result: 发现85%用户每日使用，多数用户跨领域整合使用（专业、个人、健康、创意），42.5%主要用于专业工作流程，用户发展出文化语境导航策略和咨询关系。

Conclusion: 研究展示了从实验性使用到必要工作流程依赖的进展，用户将ChatGPT视为综合生活助手，但样本限于社交媒体招募的英语城市专业人士，需要更大规模人口验证。

Abstract: Understanding how users authentically interact with Large Language Models
(LLMs) remains a significant challenge in human-computer interaction research.
Most existing studies rely on self-reported usage patterns or controlled
experimental conditions, potentially missing genuine behavioral adaptations.
This study presents a behavioral analysis of the use of English-speaking urban
professional ChatGPT in India based on 238 authentic, unedited user prompts
from 40 participants in 15+ Indian cities, collected using retrospective survey
methodology in August 2025. Using authentic retrospective prompt collection via
anonymous social media survey to minimize real-time observer effects, we
analyzed genuine usage patterns. Key findings include: (1) 85\% daily usage
rate (34/40 users) indicating mature adoption beyond experimental use, (2)
evidence of cross-domain integration spanning professional, personal, health
and creative contexts among the majority of users, (3) 42.5\% (17/40) primarily
use ChatGPT for professional workflows with evidence of real-time problem
solving integration, and (4) cultural context navigation strategies with users
incorporating Indian cultural specifications in their prompts. Users develop
sophisticated adaptation techniques and the formation of advisory relationships
for personal guidance. The study reveals the progression from experimental to
essential workflow dependency, with users treating ChatGPT as an integrated
life assistant rather than a specialized tool. However, the findings are
limited to urban professionals in English recruited through social media
networks and require a larger demographic validation. This work contributes a
novel methodology to capture authentic AI usage patterns and provides
evidence-based insights into cultural adaptation strategies among this specific
demographic of users.

</details>


### [90] [Defining a classification system for augmentation technology in socio-technical terms](https://arxiv.org/abs/2509.13340)
*Isabel Pedersen,Ann Hill Duin*

Main category: cs.CY

TL;DR: 该论文提出了一个将增强技术重新概念化为社会技术、话语和修辞现象的分类框架，而非仅从技术角度分类。


<details>
  <summary>Details</summary>
Motivation: 重新思考增强技术的分类方式，将其视为社会技术现象而非纯粹的技术工具，以提高数字素养和AI素养，帮助识别设计阶段可能带来的意外后果。

Method: 通过识别构成增强技术话语的价值体系（增强、自动化和构建效率的意图）来构建分类框架。

Result: 建立了一个新的分类体系，将增强技术重新概念化为社会技术、话语和修辞现象。

Conclusion: 该研究为增强技术出现时的数字素养和AI素养做出了贡献，有助于在设计阶段识别这些技术可能带来的意外后果。

Abstract: This short paper provides a means to classify augmentation technologies to
reconceptualize them as sociotechnical, discursive and rhetorical phenomena,
rather than only through technological classifications. It identifies a set of
value systems that constitute augmentation technologies within discourses,
namely, the intent to enhance, automate, and build efficiency. This short paper
makes a contribution to digital literacy surrounding augmentation technology
emergence, as well as the more specific area of AI literacy, which can help
identify unintended consequences implied at the design stages of these
technologies.

</details>


### [91] [Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI](https://arxiv.org/abs/2509.13345)
*Zihao Li,Weiwei Yi,Jiahong Chen*

Main category: cs.CY

TL;DR: 本文提出了"准确性悖论"概念，认为过度依赖准确性作为评估LLM幻觉的主要标准会产生反效果，掩盖了更深层的认知和社会风险，呼吁转向更全面的AI可信治理方法。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在日常决策中的普及，其产生的幻觉（虚假、误导性、过度简化或不可信输出）带来了紧迫的认知和社会风险。当前监管、学术和技术讨论将准确性作为主要基准，但作者认为这种过度依赖会误诊问题并产生反效果。

Method: 通过跨学科文献分析，构建了幻觉类型的分类法，并从三个相互关联的维度（输出、个体和社会）展示准确性悖论，同时考察了欧盟AI法案、GDPR和DSA等现行法规的结构性不足。

Result: 研究发现准确性作为单一指标存在三个主要问题：1）作为可靠性的表面代理，鼓励优化修辞流畅性而非认知可信度；2）无法检测非事实错误但具有误导性的危害；3）掩盖了幻觉的更广泛社会后果，如社会分层、隐私侵犯和认知趋同。

Conclusion: 当前法规在结构上尚未准备好应对这些认知、关系和系统性危害。需要从根本上转向多元化、情境感知和抗操纵的AI可信治理方法，超越单纯的准确性指标。

Abstract: As Large Language Models (LLMs) permeate everyday decision-making, their
epistemic and societal risks demand urgent scrutiny. Hallucinations, the
generation of fabricated, misleading, oversimplified or untrustworthy outputs,
has emerged as imperative challenges. While regulatory, academic, and technical
discourse position accuracy as the principal benchmark for mitigating such
harms, this article contends that overreliance on accuracy misdiagnoses the
problem and has counterproductive effect: the accuracy paradox. Drawing on
interdisciplinary literatures, this article develops a taxonomy of
hallucination types and shows the paradox along three intertwining dimensions:
outputs, individuals and society. First, accuracy functions as a superficial
proxy for reliability, incentivising the optimisation of rhetorical fluency and
surface-level correctness over epistemic trustworthiness. This encourages
passive user trust in outputs that appear accurate but epistemically untenable.
Second, accuracy as a singular metric fails to detect harms that are not
factually false but are nonetheless misleading, value-laden, or socially
distorting, including consensus illusions, sycophantic alignment, and subtle
manipulation. Third, regulatory overemphasis on accuracy obscures the wider
societal consequences of hallucination, including social sorting, privacy
violations, equity harms, epistemic convergence that marginalises dissent,
reduces pluralism, and causes social deskilling. By examining the EU AI Act,
GDPR, and DSA, the article argues that current regulations are not yet
structurally equipped to address these epistemic, relational, and systemic
harms and exacerbated by the overreliance on accuracy. By exposing such
conceptual and practical challenges, this article calls for a fundamental shift
towards pluralistic, context-aware, and manipulation-resilient approaches to AI
trustworthy governance.

</details>


### [92] [Towards an AI-Augmented Textbook](https://arxiv.org/abs/2509.13348)
*LearnLM Team,Google,:,Amy Wang,Anna Iurchenko,Anisha Choudhury,Alicia Martín,Amir Globerson,Avinatan Hassidim,Ayça Çakmakli,Ayelet Shasha Evron,Charlie Yang,Courtney Heldreth,Diana Akrong,Gal Elidan,Hairong Mu,Ian Li,Ido Cohen,Katherine Chou,Komal Singh,Lev Borovoi,Lidan Hackmon,Lior Belinsky,Michael Fink,Niv Efron,Preeti Singh,Rena Levitt,Shashank Agarwal,Shay Sharon,Tracey Lee-Joe,Xiaohong Hao,Yael Gold-Zamir,Yael Haramaty,Yishay Mor,Yoav Bar Sinai,Yossi Matias*

Main category: cs.CY

TL;DR: 使用生成式AI将传统教科书转化为个性化、多表征的学习材料，通过随机对照试验证明比传统教科书学习效果更好


<details>
  <summary>Details</summary>
Motivation: 传统教科书存在一刀切的局限性，无法根据个人需求进行规模化适配，新内容或替代表征需要大量人工努力

Method: 开发Learn Your Way系统，利用生成式AI为教科书添加多层多表征和个性化内容，同时保持内容完整性和质量

Result: 通过教学评估和随机对照试验，证明Learn Your Way系统相比传统教科书使用具有显著优势

Conclusion: 生成式AI可以有效地改造和增强教科书，提供个性化、多表征的学习体验，改善教育效果

Abstract: Textbooks are a cornerstone of education, but they have a fundamental
limitation: they are a one-size-fits-all medium. Any new material or
alternative representation requires arduous human effort, so that textbooks
cannot be adapted in a scalable manner. We present an approach for transforming
and augmenting textbooks using generative AI, adding layers of multiple
representations and personalization while maintaining content integrity and
quality. We refer to the system built with this approach as Learn Your Way. We
report pedagogical evaluations of the different transformations and
augmentations, and present the results of a a randomized control trial,
highlighting the advantages of learning with Learn Your Way over regular
textbook usage.

</details>


### [93] [Synthetic Data and the Shifting Ground of Truth](https://arxiv.org/abs/2509.13355)
*Dietmar Offenhuber*

Main category: cs.CY

TL;DR: 本文探讨合成数据如何挑战传统的地面真值概念，分析在缺乏真实世界参照的情况下，机器学习研究者如何建立和使用合成数据作为训练数据和地面真值库。


<details>
  <summary>Details</summary>
Motivation: 随着合成数据在隐私保护、训练数据生成等领域的广泛应用，传统基于表示准确性的数据保真度假设受到挑战。作者旨在研究在这种缺乏真实世界参照的悖论情况下，研究者如何构建地面真值。

Method: 通过理论分析，探讨合成数据的特性及其对机器学习实践的影响，分析从表示性数据概念向模仿性数据概念的转变。

Result: 研究发现合成数据虽然缺乏真实世界参照，但通过补偿已知偏差、防止过拟合、支持泛化等方式，反而可能带来更好的模型性能。地面真值变成了自指涉的事务。

Conclusion: 合成数据的兴起促使数据概念从表示性向模仿性转变，这从根本上改变了我们对数据保真度和地面真值的理解，需要重新思考机器学习中的数据基础假设。

Abstract: The emergence of synthetic data for privacy protection, training data
generation, or simply convenient access to quasi-realistic data in any shape or
volume complicates the concept of ground truth. Synthetic data mimic real-world
observations, but do not refer to external features. This lack of a
representational relationship, however, not prevent researchers from using
synthetic data as training data for AI models and ground truth repositories. It
is claimed that the lack of data realism is not merely an acceptable tradeoff,
but often leads to better model performance than realistic data: compensate for
known biases, prevent overfitting and support generalization, and make the
models more robust in dealing with unexpected outliers. Indeed, injecting noisy
and outright implausible data into training sets can be beneficial for the
model. This greatly complicates usual assumptions based on which
representational accuracy determines data fidelity (garbage in - garbage out).
Furthermore, ground truth becomes a self-referential affair, in which the
labels used as a ground truth repository are themselves synthetic products of a
generative model and as such not connected to real-world observations. My paper
examines how ML researchers and practitioners bootstrap ground truth under such
paradoxical circumstances without relying on the stable ground of
representation and real-world reference. It will also reflect on the broader
implications of a shift from a representational to what could be described as a
mimetic or iconic concept of data.

</details>


### [94] [CogniAlign: Survivability-Grounded Multi-Agent Moral Reasoning for Safe and Transparent AI](https://arxiv.org/abs/2509.13356)
*Hasin Jawad Ali,Ilhamul Azam,Ajwad Abrar,Md. Kamrul Hasan,Hasan Mahmud*

Main category: cs.CY

TL;DR: CogniAlign是一个基于自然主义道德现实主义的AI对齐框架，通过多学科专家代理的辩论来解决道德推理问题，在60多个道德问题上显著优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 解决AI与人类价值观对齐的挑战，现有方法存在道德原则抽象冲突和推理不透明的问题。

Method: 采用多智能体审议框架，包含神经科学、心理学、社会学和进化生物学等学科专家代理，通过结构化辩论和仲裁机制进行道德推理。

Result: 在60多个道德问题上平均表现提升：分析质量16.2分，广度14.3分，解释深度28.4分。在海因茨困境中得分89.2 vs GPT-4o的69.2。

Conclusion: CogniAlign通过减少黑盒推理和避免欺骗性对齐，展示了跨学科审议作为可扩展AI对齐路径的潜力。

Abstract: The challenge of aligning artificial intelligence (AI) with human values
persists due to the abstract and often conflicting nature of moral principles
and the opacity of existing approaches. This paper introduces CogniAlign, a
multi-agent deliberation framework based on naturalistic moral realism, that
grounds moral reasoning in survivability, defined across individual and
collective dimensions, and operationalizes it through structured deliberations
among discipline-specific scientist agents. Each agent, representing
neuroscience, psychology, sociology, and evolutionary biology, provides
arguments and rebuttals that are synthesized by an arbiter into transparent and
empirically anchored judgments. We evaluate CogniAlign on classic and novel
moral questions and compare its outputs against GPT-4o using a five-part
ethical audit framework. Results show that CogniAlign consistently outperforms
the baseline across more than sixty moral questions, with average performance
gains of 16.2 points in analytic quality, 14.3 points in breadth, and 28.4
points in depth of explanation. In the Heinz dilemma, for example, CogniAlign
achieved an overall score of 89.2 compared to GPT-4o's 69.2, demonstrating a
decisive advantage in handling moral reasoning. By reducing black-box reasoning
and avoiding deceptive alignment, CogniAlign highlights the potential of
interdisciplinary deliberation as a scalable pathway for safe and transparent
AI alignment.

</details>


### [95] [Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study](https://arxiv.org/abs/2509.13359)
*Benjamin J. Walker,Beatriz Navarro Lameda,Ruth A. Reynolds*

Main category: cs.CY

TL;DR: 研究发现GenAI在无人监考的数学考试中能达到一等学位水平，表现比学生更稳定，需要重新设计数学评估方式


<details>
  <summary>Details</summary>
Motivation: 探讨GenAI工具如ChatGPT如何改变教育评估实践，特别是在无人监考、开卷考试环境下传统数学考试是否仍具有教学相关性

Method: 生成、转录并盲评GenAI对8门本科数学考试的作答，涵盖第一年全部课程，结合独立问题的GenAI回答进行模块和课程层面的评估

Result: GenAI达到一等学位水平，表现比监考环境下的学生更稳定，但不同模块间表现存在差异

Conclusion: 需要在无监督环境中重新设计数学评估，当前标准在GenAI时代可能降低教学价值

Abstract: Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are
transforming the educational landscape, prompting reconsideration of
traditional assessment practices. In parallel, universities are exploring
alternatives to in-person, closed-book examinations, raising concerns about
academic integrity and pedagogical alignment in uninvigilated settings. This
study investigates whether traditional closed-book mathematics examinations
retain their pedagogical relevance when hypothetically administered in
uninvigilated, open-book settings with GenAI access. Adopting an empirical
approach, we generate, transcribe, and blind-mark GenAI submissions to eight
undergraduate mathematics examinations at a Russel Group university, spanning
the entirety of the first-year curriculum. By combining independent GenAI
responses to individual questions, we enable a meaningful evaluation of GenAI
performance, both at the level of modules and across the first-year curriculum.
We find that GenAI attainment is at the level of a first-class degree, though
current performance can vary between modules. Further, we find that GenAI
performance is remarkably consistent when viewed across the entire curriculum,
significantly more so than that of students in invigilated examinations. Our
findings evidence the need for redesigning assessments in mathematics for
unsupervised settings, and highlight the potential reduction in pedagogical
value of current standards in the era of generative artificial intelligence.

</details>


### [96] [The Provenance Problem: LLMs and the Breakdown of Citation Norms](https://arxiv.org/abs/2509.13365)
*Brian D. Earp,Haotian Yuan,Julian Koplin,Sebastian Porsdam Mann*

Main category: cs.CY

TL;DR: 生成式AI在科研写作中的使用引发了学术溯源问题，当AI生成的内容包含研究者未接触过的前人观点时，即使无意抄袭，仍会造成学术贡献归属的断裂。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在科研写作中的广泛应用，传统的学术引用和贡献归属体系面临挑战。研究者可能无意中使用AI生成包含未引用前人观点的内容，这构成了新型的学术伦理问题。

Method: 本文通过概念分析，提出了"溯源问题"的理论框架，分析AI如何挑战既有的作者身份规范，并引入理解这一问题的概念工具。

Result: 研究发现生成式AI使用可能导致系统性学术贡献归属断裂，即使研究者善意披露AI使用，仍可能受益于未获认可的知识贡献，现有伦理框架无法有效应对这一问题。

Conclusion: 需要制定新的策略来维护学术交流的完整性和公平性，应对生成式AI带来的学术溯源挑战，保护科学的声誉经济和认知正义要求。

Abstract: The increasing use of generative AI in scientific writing raises urgent
questions about attribution and intellectual credit. When a researcher employs
ChatGPT to draft a manuscript, the resulting text may echo ideas from sources
the author has never encountered. If an AI system reproduces insights from, for
example, an obscure 1975 paper without citation, does this constitute
plagiarism? We argue that such cases exemplify the 'provenance problem': a
systematic breakdown in the chain of scholarly credit. Unlike conventional
plagiarism, this phenomenon does not involve intent to deceive (researchers may
disclose AI use and act in good faith) yet still benefit from the uncredited
intellectual contributions of others. This dynamic creates a novel category of
attributional harm that current ethical and professional frameworks fail to
address. As generative AI becomes embedded across disciplines, the risk that
significant ideas will circulate without recognition threatens both the
reputational economy of science and the demands of epistemic justice. This
Perspective analyzes how AI challenges established norms of authorship,
introduces conceptual tools for understanding the provenance problem, and
proposes strategies to preserve integrity and fairness in scholarly
communication.

</details>


### [97] [To whom did my vote go?](https://arxiv.org/abs/2509.13370)
*Andrew Conway,Michelle Blom,Alexander Ek,Peter Stuckey,Vanessa Teague,Damjan Vukcevic*

Main category: cs.CY

TL;DR: 开发了一个演示系统，让选民可以输入在澳大利亚STV选举中的示例投票，查看投票如何在候选人之间转移以及对候选人得票的贡献


<details>
  <summary>Details</summary>
Motivation: STV计票系统复杂，选民难以理解个人投票如何影响候选人得票和投票转移过程

Method: 创建演示系统，允许选民输入历史选举中的示例投票，可视化展示投票转移路径和对候选人得票的贡献度

Result: 系统能够清晰展示STV选举中投票的转移过程和贡献度，帮助选民理解复杂的计票机制

Conclusion: 该演示系统有效提升了选民对STV选举计票过程的理解，增强了选举透明度

Abstract: Single Transferable Vote (STV) counting, used in several jurisdictions in
Australia, is a system for choosing multiple election winners given voters'
preferences among candidates. The system is complex and it is not always
obvious how an individual's vote contributes to candidates' tallies across
rounds of tabulation. This short paper presents a demonstration system that
allows voters to enter an example vote in a past Australian STV election, and
see: (i)~how that vote would have been transferred between candidates; and
(ii)~how much that vote would have contributed to the tallies of relevant
candidates, across rounds of tabulation.

</details>


### [98] [Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis](https://arxiv.org/abs/2509.13387)
*Delaram Golpayegani,Marta Lasek-Markey,Arjumand Younus,Aphra Kerr,Dave Lewis*

Main category: cs.CY

TL;DR: 本文分析了欧盟AI治理政策的演变，通过定性和定量方法比较了AI法案与HLEG伦理指南等关键文件，揭示了政策间的差异和演变趋势。


<details>
  <summary>Details</summary>
Motivation: 随着AI安全可信政策激增导致治理碎片化，欧盟作为关键参与者发布了多项政策指南，需要了解这些政策之间的对齐程度和演变轨迹。

Method: 采用定性主题分析和定量主题建模（BERTopic模型）相结合的方法，分析欧盟2018年后发布的AI政策文件，包括AI法案和HLEG伦理指南。

Result: 揭示了欧盟AI政策在范围、重点领域、规范程度和优先级方面的差异，追踪了欧盟AI治理方法的演变过程。

Conclusion: 研究提供了欧盟AI政策的新视角，展示了其治理方法的动态发展，为理解欧盟AI治理框架的完整性和一致性提供了重要见解。

Abstract: The upsurge of policies and guidelines that aim to ensure Artificial
Intelligence (AI) systems are safe and trustworthy has led to a fragmented
landscape of AI governance. The European Union (EU) is a key actor in the
development of such policies and guidelines. Its High-Level Expert Group (HLEG)
issued an influential set of guidelines for trustworthy AI, followed in 2024 by
the adoption of the EU AI Act. While the EU policies and guidelines are
expected to be aligned, they may differ in their scope, areas of emphasis,
degrees of normativity, and priorities in relation to AI. To gain a broad
understanding of AI governance from the EU perspective, we leverage qualitative
thematic analysis approaches to uncover prevalent themes in key EU documents,
including the AI Act and the HLEG Ethics Guidelines. We further employ
quantitative topic modelling approaches, specifically through the use of the
BERTopic model, to enhance the results and increase the document sample to
include EU AI policy documents published post-2018. We present a novel
perspective on EU policies, tracking the evolution of its approach to
addressing AI governance.

</details>


### [99] [The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self](https://arxiv.org/abs/2509.13391)
*Sandrine R. Schiller,Camilo Miguel Signorelli,Filippos Stamatiou*

Main category: cs.CY

TL;DR: 本文探讨生成式AI如何改变人类与技术、他人及自我的关系，分析AI助手在预测行为和代理行动方面的发展趋势及其对自我认知的潜在影响


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI系统（如Microsoft Copilot、Gemini等）不断发展，AI助手不仅能响应指令，还能预测用户行为并代为行动。这种趋势促使我们重新思考人机关系，并质疑AI系统如何改变我们与自我的关系

Method: 基于关系自我概念，从三个维度分析生成式AI的影响：外部化输出领域、情境领域和自我关系领域，探讨AI如何在这些领域中完成任务并预测/拦截人类主动性

Result: 识别了生成式AI在三个关键领域对人类存在的潜在影响：AI系统可能接管决策过程、改变社交互动情境、重塑自我认知和身份建构方式

Conclusion: 生成式AI的发展不仅带来技术便利，更引发了深层的存在主义考量。我们需要认真思考AI系统预测和代理能力对人类主动性、自我认知和人际关系的根本性影响

Abstract: Generative AI is changing our way of interacting with technology, others, and
ourselves. Systems such as Microsoft copilot, Gemini and the expected Apple
intelligence still awaits our prompt for action. Yet, it is likely that AI
assistant systems will only become better at predicting our behaviour and
acting on our behalf. Imagine new generations of generative and predictive AI
deciding what you might like best at a new restaurant, picking an outfit that
increases your chances on your date with a partner also chosen by the same or a
similar system. Far from a science fiction scenario, the goal of several
research programs is to build systems capable of assisting us in exactly this
manner. The prospect urges us to rethink human-technology relations, but it
also invites us to question how such systems might change the way we relate to
ourselves. Building on our conception of the relational self, we question the
possible effects of generative AI with respect to what we call the sphere of
externalised output, the contextual sphere and the sphere of self-relating. In
this paper, we attempt to deepen the existential considerations accompanying
the AI revolution by outlining how generative AI enables the fulfilment of
tasks and also increasingly anticipates, i.e. intercepts, our initiatives in
these different spheres.

</details>


### [100] [The threat of analytic flexibility in using large language models to simulate human data: A call to attention](https://arxiv.org/abs/2509.13397)
*Jamie Cummins*

Main category: cs.CY

TL;DR: 硅样本（由大型语言模型生成的合成数据集）在社会科学研究中存在分析灵活性威胁，不同配置选择会显著影响样本质量，且没有一种配置能在所有维度上都表现最优


<details>
  <summary>Details</summary>
Motivation: 随着社会科学研究者开始使用大型语言模型创建硅样本来替代人类受访者，需要了解各种分析选择对样本质量的影响，但目前对这些选择的影响缺乏理解

Method: 通过测试252种不同配置来分析硅样本与人类数据的对应关系，评估三个维度：参与者排序、响应分布和量表间相关性

Result: 不同配置在样本质量上差异显著，且配置性能不一致——在某一方面表现良好的配置在其他方面可能表现很差

Conclusion: 使用硅样本时存在分析灵活性威胁，需要更加关注配置选择对样本准确性的影响，不存在适用于所有场景的通用最优配置

Abstract: Social scientists are now using large language models to create "silicon
samples" - synthetic datasets intended to stand in for human respondents, aimed
at revolutionising human subjects research. However, there are many analytic
choices which must be made to produce these samples. Though many of these
choices are defensible, their impact on sample quality is poorly understood. I
map out these analytic choices and demonstrate how a very small number of
decisions can dramatically change the correspondence between silicon samples
and human data. Configurations (N = 252) varied substantially in their capacity
to estimate (i) rank ordering of participants, (ii) response distributions, and
(iii) between-scale correlations. Most critically, configurations were not
consistent in quality: those that performed well on one dimension often
performed poorly on another, implying that there is no "one-size-fits-all"
configuration that optimises the accuracy of these samples. I call for greater
attention to the threat of analytic flexibility in using silicon samples.

</details>


### [101] [Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews](https://arxiv.org/abs/2509.13400)
*Sai Suresh Marchala Vasu,Ivaxi Sheth,Hui-Po Wang,Ruta Binkyte,Mario Fritz*

Main category: cs.CY

TL;DR: 本研究通过控制实验发现LLM生成的同行评审存在机构偏见（偏向高排名机构）和性别偏见，使用token-based软评分能更明显揭示隐性偏见


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在同行评审中的应用日益广泛，需要研究其生成评审内容是否存在偏见，以确保评审过程的公平性和可靠性

Method: 通过控制实验方法，在敏感元数据（作者所属机构和性别）上进行测试，分析LLM生成的同行评审内容

Result: 研究一致显示存在机构偏见（偏向学术排名高的机构），并发现一些性别偏好，虽然幅度较小但可能随时间累积。使用token-based软评分能更明显揭示隐性偏见

Conclusion: LLM生成的同行评审存在系统性偏见，需要开发缓解策略以确保学术评审的公平性，特别是在使用自动化评审系统时

Abstract: The adoption of large language models (LLMs) is transforming the peer review
process, from assisting reviewers in writing more detailed evaluations to
generating entire reviews automatically. While these capabilities offer
exciting opportunities, they also raise critical concerns about fairness and
reliability. In this paper, we investigate bias in LLM-generated peer reviews
by conducting controlled experiments on sensitive metadata, including author
affiliation and gender. Our analysis consistently shows affiliation bias
favoring institutions highly ranked on common academic rankings. Additionally,
we find some gender preferences, which, even though subtle in magnitude, have
the potential to compound over time. Notably, we uncover implicit biases that
become more evident with token-based soft ratings.

</details>


### [102] [Reproducible workflow for online AI in digital health](https://arxiv.org/abs/2509.13499)
*Susobhan Ghosh,Bhanu T. Gulapalli,Daiqi Gao,Asim Gazi,Anna Trella,Ziping Xu,Kelly Zhang,Susan A. Murphy*

Main category: cs.CY

TL;DR: 本文提出了一个用于数字健康干预中在线AI决策算法开发、部署和分析的可重复科学工作流，旨在平衡在线AI的适应性与可重复性。


<details>
  <summary>Details</summary>
Motivation: 在线AI算法在数字健康干预中面临关键挑战：需要在算法持续学习和改进的同时保持可重复性。数字健康干预的迭代部署特性要求数据准确存储、算法行为可审计、结果可比较，以促进科学发现和可信优化。

Method: 基于多个真实世界部署的实践经验，提出了一个覆盖在线AI算法开发生命周期所有阶段的可重复科学工作流，解决可重复性的关键挑战。

Result: 该工作流为数字健康干预中的在线AI算法提供了系统化的开发、部署和分析框架，确保算法行为可审计、结果可比较。

Conclusion: 提出的可重复科学工作流能够有效平衡在线AI算法的适应性与可重复性需求，为数字健康干预领域的科学发现和算法优化提供了可靠基础。

Abstract: Online artificial intelligence (AI) algorithms are an important component of
digital health interventions. These online algorithms are designed to
continually learn and improve their performance as streaming data is collected
on individuals. Deploying online AI presents a key challenge: balancing
adaptability of online AI with reproducibility. Online AI in digital
interventions is a rapidly evolving area, driven by advances in algorithms,
sensors, software, and devices. Digital health intervention development and
deployment is a continuous process, where implementation - including the AI
decision-making algorithm - is interspersed with cycles of re-development and
optimization. Each deployment informs the next, making iterative deployment a
defining characteristic of this field. This iterative nature underscores the
importance of reproducibility: data collected across deployments must be
accurately stored to have scientific utility, algorithm behavior must be
auditable, and results must be comparable over time to facilitate scientific
discovery and trustworthy refinement. This paper proposes a reproducible
scientific workflow for developing, deploying, and analyzing online AI
decision-making algorithms in digital health interventions. Grounded in
practical experience from multiple real-world deployments, this workflow
addresses key challenges to reproducibility across all phases of the online AI
algorithm development life-cycle.

</details>


### [103] [The Economics of Information Pollution in the Age of AI: A General Equilibrium Approach to Welfare, Measurement, and Policy](https://arxiv.org/abs/2509.13729)
*Yukun Zhang,Tianyang Zhang*

Main category: cs.CY

TL;DR: LLMs通过降低低质量内容生成成本而激励信息污染，本文建立一般均衡框架分析此问题，证明存在"污染信息均衡"并提出信息污染指数和政策组合解决方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)对信息生产经济学产生根本性冲击，通过不对称地降低低质量合成内容的边际成本，同时保持高质量生产成本高昂，系统性激励信息污染。

Method: 建立三阶段博弈的一般均衡框架，模拟垄断平台、利润最大化生产者和效用最大化消费者的战略互动，核心是包含不同替代弹性的生产技术模型(σ_L > 1 > σ_H)。

Result: 证明了存在唯一的"污染信息均衡"并展示其低效率性，由三重市场失灵驱动：生产外部性、平台治理失败和信息公共资源外部性。提出了理论基础的信息污染指数(IPI)。

Conclusion: 最佳政策结果需要针对每种失灵的政策工具组合，考虑到深度不确定性，提倡基于实时IPI读数动态调整政策工具的自适应治理框架，为AI时代信息市场监管提供稳健蓝图。

Abstract: The advent of Large Language Models (LLMs) represents a fundamental shock to
the economics of information production. By asymmetrically collapsing the
marginal cost of generating low-quality, synthetic content while leaving
high-quality production costly, AI systematically incentivizes information
pollution. This paper develops a general equilibrium framework to analyze this
challenge. We model the strategic interactions among a monopolistic platform,
profit-maximizing producers, and utility-maximizing consumers in a three-stage
game. The core of our model is a production technology with differential
elasticities of substitution ($\sigma_L > 1 > \sigma_H$), which formalizes the
insight that AI is a substitute for labor in low-quality production but a
complement in high-quality creation. We prove the existence of a unique
"Polluted Information Equilibrium" and demonstrate its inefficiency, which is
driven by a threefold market failure: a production externality, a platform
governance failure, and an information commons externality. Methodologically,
we derive a theoretically-grounded Information Pollution Index (IPI) with
endogenous welfare weights to measure ecosystem health. From a policy
perspective, we show that a first-best outcome requires a portfolio of
instruments targeting each failure. Finally, considering the challenges of deep
uncertainty, we advocate for an adaptive governance framework where policy
instruments are dynamically adjusted based on real-time IPI readings, offering
a robust blueprint for regulating information markets in the age of AI.

</details>


### [104] [Perspectives and potential issues in using artificial intelligence for computer science education](https://arxiv.org/abs/2509.13730)
*Juho Vepsäläinen,Petri Juntunen*

Main category: cs.CY

TL;DR: 本文探讨了ChatGPT等大型语言模型对计算机科学教育的影响，分析了AI技术带来的机遇（如个性化学习）和挑战（如过度依赖技术），并呼吁教育机构主动整合新教学方法。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等LLMs的普及，计算机科学教育面临重大变革需求。AI工具既成为核心编程工具，又模糊了编程辅助与智能系统的界限，需要重新思考教育方法和内容。

Method: 通过调查分析的方法，研究AI技术在计算机科学教育中的应用潜力、存在的问题以及教育机构需要采取的应对策略。

Result: 研究发现AI技术具有增强学习体验的潜力（个性化学习路径、智能辅导系统等），但也存在过度依赖技术、基础认知技能退化、教育公平等风险。

Conclusion: 教育机构需要主动验证、整合和应用新的教学方法，而不是将适应AI技术的负担转嫁给学生，以确保教育者和学习者都能掌握应对技术变革所需的技能。

Abstract: Since its launch in late 2022, ChatGPT has ignited widespread interest in
Large Language Models (LLMs) and broader Artificial Intelligence (AI)
solutions. As this new wave of AI permeates various sectors of society, we are
continually uncovering both the potential and the limitations of existing AI
tools.
  The need for adjustment is particularly significant in Computer Science
Education (CSEd), as LLMs have evolved into core coding tools themselves,
blurring the line between programming aids and intelligent systems, and
reinforcing CSEd's role as a nexus of technology and pedagogy. The findings of
our survey indicate that while AI technologies hold potential for enhancing
learning experiences, such as through personalized learning paths, intelligent
tutoring systems, and automated assessments, there are also emerging concerns.
These include the risk of over-reliance on technology, the potential erosion of
fundamental cognitive skills, and the challenge of maintaining equitable access
to such innovations.
  Recent advancements represent a paradigm shift, transforming not only the
content we teach but also the methods by which teaching and learning take
place. Rather than placing the burden of adapting to AI technologies on
students, educational institutions must take a proactive role in verifying,
integrating, and applying new pedagogical approaches. Such efforts can help
ensure that both educators and learners are equipped with the skills needed to
navigate the evolving educational landscape shaped by these technological
innovations.

</details>


### [105] [Understanding the Process of Human-AI Value Alignment](https://arxiv.org/abs/2509.13854)
*Jack McKinlay,Marina De Vos,Janina A. Hoffmann,Andreas Theodorou*

Main category: cs.CY

TL;DR: 本文通过系统文献综述分析了172篇价值对齐研究论文，提出了价值对齐的精确定义：人类与自主代理之间持续的过程，旨在不同情境中表达和实施抽象价值观，同时管理人类和AI的认知限制并平衡不同群体间的伦理政治需求冲突。


<details>
  <summary>Details</summary>
Motivation: 当前计算机科学研究中价值对齐概念使用缺乏精确性，需要通过对现有文献的系统分析来推进对该术语的理解并提出更准确的定义。

Method: 采用系统文献综述方法，分析172篇近年发表的价值对齐研究文章，使用主题分析方法综合内容。

Result: 分析得出六个主题：价值对齐驱动因素与方法、价值对齐挑战、价值对齐中的价值观、人类与AI的认知过程、人机协作、价值对齐系统设计与开发。

Conclusion: 提出了价值对齐的精确定义，并为该领域未来的研究挑战和机遇提供了指导框架。

Abstract: Background: Value alignment in computer science research is often used to
refer to the process of aligning artificial intelligence with humans, but the
way the phrase is used often lacks precision. Objectives: In this paper, we
conduct a systematic literature review to advance the understanding of value
alignment in artificial intelligence by characterising the topic in the context
of its research literature. We use this to suggest a more precise definition of
the term. Methods: We analyse 172 value alignment research articles that have
been published in recent years and synthesise their content using thematic
analyses. Results: Our analysis leads to six themes: value alignment drivers &
approaches; challenges in value alignment; values in value alignment; cognitive
processes in humans and AI; human-agent teaming; and designing and developing
value-aligned systems. Conclusions: By analysing these themes in the context of
the literature we define value alignment as an ongoing process between humans
and autonomous agents that aims to express and implement abstract values in
diverse contexts, while managing the cognitive limits of both humans and AI
agents and also balancing the conflicting ethical and political demands
generated by the values in different groups. Our analysis gives rise to a set
of research challenges and opportunities in the field of value alignment for
future work.

</details>


### [106] [Interleaving Natural Language Prompting with Code Editing for Solving Programming Tasks with Generative AI Models](https://arxiv.org/abs/2509.14088)
*Victor-Alexandru Pădurean,Paul Denny,Andrew Luxton-Reilly,Alkis Gotovos,Adish Singla*

Main category: cs.CY

TL;DR: 学生主要使用提示生成初始代码，然后通过简短编辑-运行循环来完善代码。随着任务复杂度增加，手动编辑更频繁，但大多数编辑都很简洁。高水平学生更多依赖提示，低水平学生更多依赖编辑。


<details>
  <summary>Details</summary>
Motivation: 理解学生在编程任务中如何结合使用自然语言提示和手动代码编辑，以及这种使用方式如何随任务复杂度和学生能力变化。

Method: 在入门编程课程中进行大规模研究，收集355名学生在3天实验活动中的13,305次交互数据。

Result: 学生主要用提示生成初始解决方案，然后通过简短编辑-运行循环来完善代码。手动编辑随任务复杂度增加而更频繁，但大多数编辑都很简洁（很多只影响单行代码）。高水平学生更多通过提示成功，低水平学生更多依赖编辑。

Conclusion: 手动编辑是AI辅助编程工作流中作为有意最后修复策略的重要补充，提示有助于构建解决方案，编辑则有效进行针对性修正，两者都对学习有益。

Abstract: Nowadays, computing students often rely on both natural-language prompting
and manual code editing to solve programming tasks. Yet we still lack a clear
understanding of how these two modes are combined in practice, and how their
usage varies with task complexity and student ability. In this paper, we
investigate this through a large-scale study in an introductory programming
course, collecting 13,305 interactions from 355 students during a three-day
laboratory activity. Our analysis shows that students primarily use prompting
to generate initial solutions, and then often enter short edit-run loops to
refine their code following a failed execution. We find that manual editing
becomes more frequent as task complexity increases, but most edits remain
concise, with many affecting a single line of code. Higher-performing students
tend to succeed using prompting alone, while lower-performing students rely
more on edits. Student reflections confirm that prompting is helpful for
structuring solutions, editing is effective for making targeted corrections,
while both are useful for learning. These findings highlight the role of manual
editing as a deliberate last-mile repair strategy, complementing prompting in
AI-assisted programming workflows.

</details>


### [107] [AI and the Future of Academic Peer Review](https://arxiv.org/abs/2509.14189)
*Sebastian Porsdam Mann,Mateo Aboy,Joel Jiehao Seah,Zhicheng Lin,Xufei Luo,Dan Rodger,Hazem Zohny,Timo Minssen,Julian Savulescu,Brian D. Earp*

Main category: cs.CY

TL;DR: 本文探讨了人工智能（特别是大语言模型）在同行评审中的应用潜力，分析了当前同行评审系统的问题以及AI辅助评审的优势和挑战，提出了有监督的AI辅助评审可以改善评审质量、时效性和工作负担的观点。


<details>
  <summary>Details</summary>
Motivation: 同行评审作为科学质量控制的中心机制面临严重挑战，包括出版延迟、评审负担不均、质量不一致和系统性偏见等问题。传统改革效果有限，而AI技术为改进同行评审提供了新的可能性。

Method: 通过将同行评审的目标和持续失败模式映射到具体的LLM应用，系统分析AI辅助评审的反对意见和可能的保障措施。基于新兴证据，分析有针对性、有监督的LLM辅助如何改善错误检测、及时性和评审工作量。

Result: 研究表明，AI辅助可以产生与人类评审质量相当的评审意见，加速评审选择和反馈过程，减少某些偏见，但也存在幻觉、保密性、博弈、新颖性识别和信任丧失等独特问题。

Conclusion: AI辅助同行评审的合法性既取决于技术能力，也取决于治理选择。未来的路径既不是不加批判地采用，也不是反射性地拒绝，而是通过具有明确评估指标、透明度和问责制的精心设计的试点项目来推进。

Abstract: Peer review remains the central quality-control mechanism of science, yet its
ability to fulfill this role is increasingly strained. Empirical studies
document serious shortcomings: long publication delays, escalating reviewer
burden concentrated on a small minority of scholars, inconsistent quality and
low inter-reviewer agreement, and systematic biases by gender, language, and
institutional prestige. Decades of human-centered reforms have yielded only
marginal improvements. Meanwhile, artificial intelligence, especially large
language models (LLMs), is being piloted across the peer-review pipeline by
journals, funders, and individual reviewers. Early studies suggest that AI
assistance can produce reviews comparable in quality to humans, accelerate
reviewer selection and feedback, and reduce certain biases, but also raise
distinctive concerns about hallucination, confidentiality, gaming, novelty
recognition, and loss of trust. In this paper, we map the aims and persistent
failure modes of peer review to specific LLM applications and systematically
analyze the objections they raise alongside safeguards that could make their
use acceptable. Drawing on emerging evidence, we show that targeted, supervised
LLM assistance can plausibly improve error detection, timeliness, and reviewer
workload without displacing human judgment. We highlight advanced
architectures, including fine-tuned, retrieval-augmented, and multi-agent
systems, that may enable more reliable, auditable, and interdisciplinary
review. We argue that ethical and practical considerations are not peripheral
but constitutive: the legitimacy of AI-assisted peer review depends on
governance choices as much as technical capacity. The path forward is neither
uncritical adoption nor reflexive rejection, but carefully scoped pilots with
explicit evaluation metrics, transparency, and accountability.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [108] [Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics](https://arxiv.org/abs/2509.13425)
*Julian Evan Chrisnanto,Yulison Herry Chrisnanto,Ferry Faizal*

Main category: cs.LG

TL;DR: 提出了USPIL框架，将物理信息神经网络与守恒定律结合，统一建模捕食者-猎物系统的时空动力学，在精度和计算效率上显著优于传统数值方法


<details>
  <summary>Details</summary>
Motivation: 生态系统的多尺度复杂动力学挑战传统建模方法，需要新方法既能捕捉时空振荡和涌现模式，又能遵守守恒原理

Method: USPIL框架整合PINNs和守恒定律，使用自动微分强制物理约束和自适应损失加权，统一处理ODE和PDE系统

Result: 在Lotka-Volterra系统中，1D时间动力学达到98.9%相关性，2D系统捕捉到复杂螺旋波，计算速度提升10-50倍，守恒定律遵守度在0.5%以内

Conclusion: USPIL为多尺度生态建模开辟了新途径，是生态预测、保护规划和理解生态系统恢复力的变革性工具，确立了物理信息深度学习作为科学严谨的范式

Abstract: Ecological systems exhibit complex multi-scale dynamics that challenge
traditional modeling. New methods must capture temporal oscillations and
emergent spatiotemporal patterns while adhering to conservation principles. We
present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,
a deep learning architecture integrating physics-informed neural networks
(PINNs) and conservation laws to model predator-prey dynamics across
dimensional scales. The framework provides a unified solution for both ordinary
(ODE) and partial (PDE) differential equation systems, describing temporal
cycles and reaction-diffusion patterns within a single neural network
architecture. Our methodology uses automatic differentiation to enforce physics
constraints and adaptive loss weighting to balance data fidelity with physical
consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%
correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures
complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).
Validation confirms conservation law adherence within 0.5% and shows a 10-50x
computational speedup for inference compared to numerical solvers. USPIL also
enables mechanistic understanding through interpretable physics constraints,
facilitating parameter discovery and sensitivity analysis not possible with
purely data-driven methods. Its ability to transition between dimensional
formulations opens new avenues for multi-scale ecological modeling. These
capabilities make USPIL a transformative tool for ecological forecasting,
conservation planning, and understanding ecosystem resilience, establishing
physics-informed deep learning as a powerful and scientifically rigorous
paradigm.

</details>


### [109] [A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks](https://arxiv.org/abs/2509.13717)
*Yifan Yu,Cheuk Hin Ho,Yangshuai Wang*

Main category: cs.LG

TL;DR: 本文提出了一个基于无分布共形预测的PINNs不确定性量化框架，通过校准集构建非共形性分数，为物理信息神经网络提供具有严格统计保证的预测区间。


<details>
  <summary>Details</summary>
Motivation: 现有PINNs不确定性量化方法缺乏严格的统计保证，需要建立一个具有理论保证的分布无关不确定性量化框架。

Method: 引入无分布共形预测框架，通过校准集构建非共形性分数；针对空间异方差性提出局部共形分位数估计方法，实现空间自适应不确定性带。

Result: 在典型PDE系统（阻尼谐振子、泊松、Allen-Cahn和亥姆霍兹方程）上系统评估，结果显示该框架实现了可靠的校准和局部自适应不确定性区间，一致优于启发式UQ方法。

Conclusion: 该工作通过将PINNs与无分布UQ相结合，不仅提高了校准性和可靠性，还为复杂PDE系统的不确定性感知建模开辟了新途径。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving PDEs, yet existing uncertainty quantification (UQ) approaches for
PINNs generally lack rigorous statistical guarantees. In this work, we bridge
this gap by introducing a distribution-free conformal prediction (CP) framework
for UQ in PINNs. This framework calibrates prediction intervals by constructing
nonconformity scores on a calibration set, thereby yielding distribution-free
uncertainty estimates with rigorous finite-sample coverage guarantees for
PINNs. To handle spatial heteroskedasticity, we further introduce local
conformal quantile estimation, enabling spatially adaptive uncertainty bands
while preserving theoretical guarantee. Through systematic evaluations on
typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz
equations) and comprehensive testing across multiple uncertainty metrics, our
results demonstrate that the proposed framework achieves reliable calibration
and locally adaptive uncertainty intervals, consistently outperforming
heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work
introduces a general framework that not only enhances calibration and
reliability, but also opens new avenues for uncertainty-aware modeling of
complex PDE systems.

</details>


### [110] [An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training](https://arxiv.org/abs/2509.13516)
*Tom Almog*

Main category: cs.LG

TL;DR: 本文通过360次实验发现优化器选择对神经网络训练的能耗和碳排放有显著影响，AdamW和NAdam在效率方面表现一致较好，而SGD在复杂数据集上性能更优但碳排放更高


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型变得越来越复杂和计算密集，理解训练决策对环境的影响对于可持续AI发展变得至关重要

Method: 在三个基准数据集(MNIST, CIFAR-10, CIFAR-100)上使用8种流行优化器进行360次受控实验，使用CodeCarbon在Apple M1 Pro硬件上精确追踪能量消耗

Result: 发现训练速度、准确性和环境影响之间存在显著权衡，这些权衡因数据集和模型复杂度而异。AdamW和NAdam表现出一致的效率，而SGD在复杂数据集上表现出色但排放更高

Conclusion: 研究结果为从业者在机器学习工作流中平衡性能和可持续性提供了可行的见解

Abstract: As machine learning models grow increasingly complex and computationally
demanding, understanding the environmental impact of training decisions becomes
critical for sustainable AI development. This paper presents a comprehensive
empirical study investigating the relationship between optimizer choice and
energy efficiency in neural network training. We conducted 360 controlled
experiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using
eight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,
NAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking
on Apple M1 Pro hardware, we measured training duration, peak memory usage,
carbon dioxide emissions, and final model performance. Our findings reveal
substantial trade-offs between training speed, accuracy, and environmental
impact that vary across datasets and model complexity. We identify AdamW and
NAdam as consistently efficient choices, while SGD demonstrates superior
performance on complex datasets despite higher emissions. These results provide
actionable insights for practitioners seeking to balance performance and
sustainability in machine learning workflows.

</details>


### [111] [eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems](https://arxiv.org/abs/2509.13952)
*Amin Lotfalian,Mohammad Reza Banan,Pooyan Broumand*

Main category: cs.LG

TL;DR: 提出了X-PINN框架，通过能量损失函数、定制积分方案和域分解方法解决多裂纹断裂力学问题，采用神经网络增强函数显式捕捉裂纹不连续性和奇异性。


<details>
  <summary>Details</summary>
Motivation: 为了解决断裂介质中多裂纹问题的复杂力学行为，特别是裂纹体的不连续性和裂纹尖端的奇异性，需要开发一种能够有效处理这些挑战的数值方法。

Method: 基于扩展有限元法(XFEM)思想，使用神经网络增强函数来显式捕捉裂纹不连续性和奇异性；采用能量损失函数、定制积分方案和域分解程序；使用不同的神经网络分别建模标准和增强解分量。

Result: 数值实验验证了该方法在1D和2D域中处理复杂多裂纹问题的有效性和鲁棒性，并具有良好的扩展到3D问题的能力。

Conclusion: X-PINN框架为断裂力学问题提供了一种灵活有效的解决方案，能够准确捕捉裂纹特征，具有良好的扩展性和应用前景。

Abstract: This paper presents eXtended Physics-Informed Neural Network (X-PINN), a
novel and robust framework for addressing fracture mechanics problems involving
multiple cracks in fractured media. To address this, an energy-based loss
function, customized integration schemes, and domain decomposition procedures
are proposed. Inspired by the Extended Finite Element Method (XFEM), the neural
network solution space is enriched with specialized functions that allow crack
body discontinuities and singularities at crack tips to be explicitly captured.
Furthermore, a structured framework is introduced in which standard and
enriched solution components are modeled using distinct neural networks,
enabling flexible and effective simulations of complex multiple-crack problems
in 1D and 2D domains, with convenient extensibility to 3D problems. Numerical
experiments are conducted to validate the effectiveness and robustness of the
proposed method.

</details>


### [112] [Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework](https://arxiv.org/abs/2509.13520)
*Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis*

Main category: cs.LG

TL;DR: 提出混合DeepONet-Transolver框架，用于解决PET瓶屈曲分析问题，能够同时预测节点位移场和时间相关的反作用力，在几何参数化设计上表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络方法在处理非参数化几何域变化的PDE问题时泛化能力有限，而传统的有限元分析计算成本高昂，需要开发高效的计算替代模型。

Method: 采用混合DeepONet-Transolver框架，结合深度算子网络和变换求解器，在Abaqus非线性有限元模拟生成的254个独特设计数据上进行训练。

Result: 在四参数瓶族上达到位移场平均相对L2误差2.5-13%，时间相关反作用力误差约2.4%，点位移绝对误差在10^-4-10^-3量级，准确捕捉了屈曲等关键物理现象。

Conclusion: 该框架展示了作为可扩展计算替代模型的潜力，特别适用于计算力学中的多任务预测和需要快速设计评估的应用场景。

Abstract: Neural surrogates and operator networks for solving partial differential
equation (PDE) problems have attracted significant research interest in recent
years. However, most existing approaches are limited in their ability to
generalize solutions across varying non-parametric geometric domains. In this
work, we address this challenge in the context of Polyethylene Terephthalate
(PET) bottle buckling analysis, a representative packaging design problem
conventionally solved using computationally expensive finite element analysis
(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously
predicts nodal displacement fields and the time evolution of reaction forces
during top load compression. Our methodology is evaluated on two families of
bottle geometries parameterized by two and four design variables. Training data
is generated using nonlinear FEA simulations in Abaqus for 254 unique designs
per family. The proposed framework achieves mean relative $L^{2}$ errors of
2.5-13% for displacement fields and approximately 2.4% for time-dependent
reaction forces for the four-parameter bottle family. Point-wise error analyses
further show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,
with the largest discrepancies confined to localized geometric regions.
Importantly, the model accurately captures key physical phenomena, such as
buckling behavior, across diverse bottle geometries. These results highlight
the potential of our framework as a scalable and computationally efficient
surrogate, particularly for multi-task predictions in computational mechanics
and applications requiring rapid design evaluation.

</details>


### [113] [A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning](https://arxiv.org/abs/2509.14198)
*Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,George Em Karniadakis*

Main category: cs.LG

TL;DR: 提出了一个统一的变分框架来形式化基于残差的自适应策略，通过积分残差的凸变换将自适应加权与误差度量优化联系起来，为科学机器学习提供了理论依据和系统化设计方法。


<details>
  <summary>Details</summary>
Motivation: 基于残差的自适应策略在科学机器学习中广泛使用但缺乏理论依据，需要建立一个统一的框架来形式化这些方法并建立离散化选择与误差度量之间的直接联系。

Method: 引入变分框架，通过积分残差的凸变换来形式化自适应策略，不同的变换对应不同的目标函数（指数权重对应均匀误差最小化，线性权重对应二次误差最小化），将自适应加权等价于选择优化原始目标的采样分布。

Result: 该框架实现了三个好处：1）系统化设计跨范数的自适应方案；2）通过损失估计器的方差减少降低离散化误差；3）通过改善梯度信噪比增强学习动态。在算子学习中展示了显著的性能提升。

Conclusion: 为基于残差的自适应性提供了理论依据，为有原则的离散化和训练策略奠定了基础，证明了该框架在不同优化器和架构上的有效性。

Abstract: Residual-based adaptive strategies are widely used in scientific machine
learning but remain largely heuristic. We introduce a unifying variational
framework that formalizes these methods by integrating convex transformations
of the residual. Different transformations correspond to distinct objective
functionals: exponential weights target the minimization of uniform error,
while linear weights recover the minimization of quadratic error. Within this
perspective, adaptive weighting is equivalent to selecting sampling
distributions that optimize the primal objective, thereby linking
discretization choices directly to error metrics. This principled approach
yields three benefits: (1) it enables systematic design of adaptive schemes
across norms, (2) reduces discretization error through variance reduction of
the loss estimator, and (3) enhances learning dynamics by improving the
gradient signal-to-noise ratio. Extending the framework to operator learning,
we demonstrate substantial performance gains across optimizers and
architectures. Our results provide a theoretical justification of
residual-based adaptivity and establish a foundation for principled
discretization and training strategies.

</details>


### [114] [Sequential Data Augmentation for Generative Recommendation](https://arxiv.org/abs/2509.13648)
*Geon Lee,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Kijung Shin,Neil Shah,Liam Collins*

Main category: cs.LG

TL;DR: 本文提出了GenPAS框架，系统性地解决了生成式推荐中数据增强策略的问题，通过三个偏差控制的采样步骤统一了现有方法，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐模型训练中，数据增强策略往往被简化处理或应用不一致，缺乏系统性和原则性的理解，而不同的增强策略会导致显著的性能差异。

Method: 提出GenPAS框架，将数据增强建模为包含三个偏差控制步骤的随机采样过程：序列采样、目标采样和输入采样，统一了广泛使用的策略作为特例。

Result: 在基准和工业数据集上的广泛实验表明，GenPAS在准确性、数据效率和参数效率方面均优于现有策略。

Conclusion: GenPAS为生成式推荐中的原则性训练数据构建提供了实用指导，能够灵活控制训练分布，提升模型泛化能力。

Abstract: Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.

</details>


### [115] [AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions](https://arxiv.org/abs/2509.13523)
*Väinö Hatanpää,Eugene Ku,Jason Stock,Murali Emani,Sam Foreman,Chunyong Jung,Sandeep Madireddy,Tung Nguyen,Varuni Sastry,Ray A. O. Sinurat,Sam Wheeler,Huihuo Zheng,Troy Arcomano,Venkatram Vishwanath,Rao Kotamarthi*

Main category: cs.LG

TL;DR: AERIS是一个10-800亿参数的像素级Swin扩散变换器，通过SWiPe并行化技术在Aurora超级计算机上实现高效扩展，在天气预测中超越IFS ENS系统并保持90天季节尺度的稳定性


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散方法在高分辨率天气预测中难以稳定扩展的问题，探索十亿参数级扩散模型在天气和气候预测中的潜力

Method: 提出AERIS（像素级Swin扩散变换器）和SWiPe并行化技术，结合窗口并行、序列并行和流水线并行，在不增加通信成本或全局批大小的情况下分片基于窗口的变换器

Result: 在Aurora（10,080节点）上实现10.21 ExaFLOPS混合精度性能，峰值达11.21 ExaFLOPS，弱扩展效率95.5%，强扩展效率81.6%。AERIS超越IFS ENS并在90天季节尺度保持稳定

Conclusion: 十亿参数扩散模型在天气和气候预测中具有巨大潜力，AERIS展示了在高分辨率下稳定扩展的能力，为复杂地球系统动力学理解提供了新机遇

Abstract: Generative machine learning offers new opportunities to better understand
complex Earth system dynamics. Recent diffusion-based methods address spectral
biases and improve ensemble calibration in weather forecasting compared to
deterministic methods, yet have so far proven difficult to scale stably at high
resolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin
diffusion transformer to address this gap, and SWiPe, a generalizable technique
that composes window parallelism with sequence and pipeline parallelism to
shard window-based transformers without added communication cost or increased
global batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS
(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \times 1$
patch size on the 0.25{\deg} ERA5 dataset, achieving 95.5% weak scaling
efficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS
and remains stable on seasonal scales to 90 days, highlighting the potential of
billion-parameter diffusion models for weather and climate prediction.

</details>


### [116] [Meta-Learning Linear Models for Molecular Property Prediction](https://arxiv.org/abs/2509.13527)
*Yulia Pimonova,Michael G. Taylor,Alice Allen,Ping Yang,Nicholas Lubbers*

Main category: cs.LG

TL;DR: LAMeL是一种线性元学习算法，在保持可解释性的同时提高多个化学性质预测的准确性，性能比标准岭回归提升1.1-25倍


<details>
  <summary>Details</summary>
Motivation: 化学研究中高质量数据集有限，机器学习方法需要大量数据，同时需要满足可解释AI(XAI)的需求，弥合预测准确性和人类可理解性之间的差距

Method: 采用元学习框架，识别相关任务间的共享模型参数，即使任务不共享数据，学习一个共同的功能流形作为新任务的更明智起点

Result: 在不同数据集领域上，性能比标准岭回归提升1.1-25倍，始终优于或匹配传统线性方法

Conclusion: LAMeL是化学性质预测中既准确又可解释的可靠工具

Abstract: Chemists in search of structure-property relationships face great challenges
due to limited high quality, concordant datasets. Machine learning (ML) has
significantly advanced predictive capabilities in chemical sciences, but these
modern data-driven approaches have increased the demand for data. In response
to the growing demand for explainable AI (XAI) and to bridge the gap between
predictive accuracy and human comprehensibility, we introduce LAMeL - a Linear
Algorithm for Meta-Learning that preserves interpretability while improving the
prediction accuracy across multiple properties. While most approaches treat
each chemical prediction task in isolation, LAMeL leverages a meta-learning
framework to identify shared model parameters across related tasks, even if
those tasks do not share data, allowing it to learn a common functional
manifold that serves as a more informed starting point for new unseen tasks.
Our method delivers performance improvements ranging from 1.1- to 25-fold over
standard ridge regression, depending on the domain of the dataset. While the
degree of performance enhancement varies across tasks, LAMeL consistently
outperforms or matches traditional linear methods, making it a reliable tool
for chemical property prediction where both accuracy and interpretability are
critical.

</details>


### [117] [Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection](https://arxiv.org/abs/2509.13608)
*Niruthiha Selvanayagam,Ted Kurti*

Main category: cs.LG

TL;DR: 研究发现GPT-4o mini存在"单模态瓶颈"安全架构缺陷，多模态安全过滤器会错误地阻止良性内容，导致可预测的误报


<details>
  <summary>Details</summary>
Motivation: 随着大型多模态模型(LMMs)成为日常生活的一部分，理解其安全架构对于AI对齐至关重要，需要系统分析全球部署模型的多模态仇恨言论检测能力

Method: 使用Hateful Memes Challenge数据集的500个样本进行多阶段调查，分析模型的推理和失败模式，并对144个内容策略拒绝进行定量验证

Result: 实验识别出"单模态瓶颈"架构缺陷，50%的拒绝由视觉内容触发，50%由文本内容触发，安全系统脆弱，不仅阻止高风险图像，还阻止良性的常见meme格式

Conclusion: 这些发现揭示了最先进LMMs中能力与安全之间的基本张力，强调需要更集成、上下文感知的对齐策略，以确保AI系统能够安全有效地部署

Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life,
understanding their safety architectures is a critical problem for AI
Alignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a
globally deployed model, on the difficult task of multimodal hate speech
detection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase
investigation on 500 samples to probe the model's reasoning and failure modes.
Our central finding is the experimental identification of a "Unimodal
Bottleneck," an architectural flaw where the model's advanced multimodal
reasoning is systematically preempted by context-blind safety filters. A
quantitative validation of 144 content policy refusals reveals that these
overrides are triggered in equal measure by unimodal visual 50% and textual 50%
content. We further demonstrate that this safety system is brittle, blocking
not only high-risk imagery but also benign, common meme formats, leading to
predictable false positives. These findings expose a fundamental tension
between capability and safety in state-of-the-art LMMs, highlighting the need
for more integrated, context-aware alignment strategies to ensure AI systems
can be deployed both safely and effectively.

</details>


### [118] [Unsupervised Anomaly Detection in ALS EPICS Event Logs](https://arxiv.org/abs/2509.13621)
*Antonin Sulc,Thorsten Hellert,Steven Hunt*

Main category: cs.LG

TL;DR: 基于自然语言处理和序列神经网络的ALS故障分析框架，通过语义嵌入将控制日志转换为向量表示，实时检测异常事件序列


<details>
  <summary>Details</summary>
Motivation: 为了解决先进光源(ALS)控制系统中复杂故障的实时检测问题，需要开发能够处理大量实时事件日志并识别异常模式的自动化分析工具

Method: 将EPICS控制系统的日志条目视为自然语言，使用语义嵌入技术转换为上下文向量表示，然后使用基于正常操作数据训练的序列感知神经网络为每个事件分配实时异常分数

Result: 该方法能够标记与基线行为的偏差，使操作员能够快速识别导致复杂系统故障的关键事件序列

Conclusion: 该自动化故障分析框架通过结合自然语言处理和深度学习技术，有效提升了大型科学设施故障检测的效率和准确性

Abstract: This paper introduces an automated fault analysis framework for the Advanced
Light Source (ALS) that processes real-time event logs from its EPICS control
system. By treating log entries as natural language, we transform them into
contextual vector representations using semantic embedding techniques. A
sequence-aware neural network, trained on normal operational data, assigns a
real-time anomaly score to each event. This method flags deviations from
baseline behavior, enabling operators to rapidly identify the critical event
sequences that precede complex system failures.

</details>


### [119] [Privacy-Aware In-Context Learning for Large Language Models](https://arxiv.org/abs/2509.13625)
*Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha*

Main category: cs.LG

TL;DR: 提出了一种基于差分隐私的文本生成框架，通过聚合每个token的输出分布来生成高质量合成文本，在保护隐私的同时保持高实用性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在隐私泄露风险，攻击者可能从提示中提取敏感信息，需要开发既能生成高质量文本又能提供强隐私保证的方法

Method: 利用差分隐私框架，对私有记录进行推理并聚合每个token的输出分布，同时提出简单的混合操作结合私有和公共推理来提升效用

Result: 经验评估表明该方法在上下文学习任务上优于现有最先进方法，能够生成长且连贯的合成文本

Conclusion: 该方法为隐私保护文本生成提供了一个有前景的方向，在保持高实用性的同时提供严格的隐私保证

Abstract: Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.

</details>


### [120] [DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis](https://arxiv.org/abs/2509.13633)
*Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng*

Main category: cs.LG

TL;DR: 提出DeepLogit模型，通过序列约束方法结合深度学习与离散选择模型，在保持参数可解释性的同时提升预测精度


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在规划和政策分析领域的应用受限于其黑盒性质，需要开发既能保持可解释性又能提高准确性的方法

Method: 采用序列约束方法：先估计仅含线性项的CNN模型（等价于线性参数多项式logit模型），然后约束需要解释的参数值，引入高阶项或Transformer等先进架构

Result: 该方法在保持选定参数可解释性的同时，显著提高了模型准确性，在新加坡公交路线选择案例中得到验证

Conclusion: 展示了理论驱动的离散选择模型与数据驱动的AI模型相结合的统一方法潜力，可在保持规划政策应用适用性的同时提高模型精度

Abstract: Despite the significant progress of deep learning models in multitude of
applications, their adaption in planning and policy related areas remains
challenging due to the black-box nature of these models. In this work, we
develop a set of DeepLogit models that follow a novel sequentially constrained
approach in estimating deep learning models for transport policy analysis. In
the first step of the proposed approach, we estimate a convolutional neural
network (CNN) model with only linear terms, which is equivalent of a
linear-in-parameter multinomial logit model. We then estimate other deep
learning models by constraining the parameters that need interpretability at
the values obtained in the linear-in-parameter CNN model and including higher
order terms or by introducing advanced deep learning architectures like
Transformers. Our approach can retain the interpretability of the selected
parameters, yet provides significantly improved model accuracy than the
discrete choice model. We demonstrate our approach on a transit route choice
example using real-world transit smart card data from Singapore. This study
shows the potential for a unifying approach, where theory-based discrete choice
model (DCM) and data-driven AI models can leverage each other's strengths in
interpretability and predictive power. With the availability of larger datasets
and more complex constructions, such approach can lead to more accurate models
using discrete choice models while maintaining its applicability in planning
and policy-related areas. Our code is available on
https://github.com/jeremyoon/route-choice/ .

</details>


### [121] [Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs](https://arxiv.org/abs/2509.13634)
*Md Bokhtiar Al Zami,Md Raihan Uddin,Dinh C. Nguyen*

Main category: cs.LG

TL;DR: 本文提出了一种结合数字孪生和零知识联邦学习的新型框架，用于优化无人机辅助联邦学习系统的能源效率、通信安全和资源管理


<details>
  <summary>Details</summary>
Motivation: 解决无人机辅助联邦学习系统中存在的能源消耗过高、通信效率低下和安全漏洞等关键问题，确保系统的可靠运行

Method: 集成数字孪生技术实现实时系统监控和预测性维护，采用零知识证明技术增强安全性，并通过动态分配策略优化无人机飞行路径、传输功率和处理速率

Result: 系统能耗相比传统联邦学习方法降低高达29.6%，仿真结果显示学习性能、安全性和可扩展性均有显著提升

Conclusion: 该框架为下一代无人机智能网络提供了一个有前景的解决方案，在能源效率、安全性和性能方面都表现出优越性

Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method
of training machine learning models on decentralized networks. However to
ensure reliable operation of UAV-assisted FL systems, issues like as excessive
energy consumption, communication inefficiencies, and security vulnerabilities
must be solved. This paper proposes an innovative framework that integrates
Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to
tackle these challenges. UAVs act as mobile base stations, allowing scattered
devices to train FL models locally and upload model updates for aggregation. By
incorporating DT technology, our approach enables real-time system monitoring
and predictive maintenance, improving UAV network efficiency. Additionally,
Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification
without exposing sensitive data. To optimize energy efficiency and resource
management, we introduce a dynamic allocation strategy that adjusts UAV flight
paths, transmission power, and processing rates based on network conditions.
Using block coordinate descent and convex optimization techniques, our method
significantly reduces system energy consumption by up to 29.6% compared to
conventional FL approaches. Simulation results demonstrate improved learning
performance, security, and scalability, positioning this framework as a
promising solution for next-generation UAV-based intelligent networks.

</details>


### [122] [Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images](https://arxiv.org/abs/2509.13636)
*Yasin Hasanpoor,Bahram Tarvirdizadeh,Khalil Alipour,Mohammad Ghamari*

Main category: cs.LG

TL;DR: 将多模态生理信号（PPG、GSR、ACC）转换为2D图像矩阵，使用CNN进行压力检测的新方法


<details>
  <summary>Details</summary>
Motivation: 传统方法分别处理这些信号或依赖固定编码，无法有效捕捉时间和跨信号依赖关系，需要更有效的多模态信号融合方法

Method: 将多模态生理信号融合成结构化图像表示，通过系统重组信号为多种格式，采用多阶段训练管道，利用CNN捕捉时空特征

Result: 显著提升了分类性能，改善了模型泛化能力和鲁棒性，同时提高了可解释性并作为数据增强的鲁棒形式

Conclusion: 该方法不仅适用于压力检测，还可广泛应用于任何涉及多模态生理信号的领域，为通过可穿戴技术实现更准确、个性化和实时的健康监测铺平道路

Abstract: This study introduces a novel method that transforms multimodal physiological
signalsphotoplethysmography (PPG), galvanic skin response (GSR), and
acceleration (ACC) into 2D image matrices to enhance stress detection using
convolutional neural networks (CNNs). Unlike traditional approaches that
process these signals separately or rely on fixed encodings, our technique
fuses them into structured image representations that enable CNNs to capture
temporal and cross signal dependencies more effectively. This image based
transformation not only improves interpretability but also serves as a robust
form of data augmentation. To further enhance generalization and model
robustness, we systematically reorganize the fused signals into multiple
formats, combining them in a multi stage training pipeline. This approach
significantly boosts classification performance. While demonstrated here in the
context of stress detection, the proposed method is broadly applicable to any
domain involving multimodal physiological signals, paving the way for more
accurate, personalized, and real time health monitoring through wearable
technologies.

</details>


### [123] [LLM-I: LLMs are Naturally Interleaved Multimodal Creators](https://arxiv.org/abs/2509.13642)
*Zirun Guo,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.LG

TL;DR: LLM-Interleaved是一个将交错图像-文本生成重新定义为工具使用问题的动态框架，通过强化学习训练LLM智能协调多种视觉工具，在多个基准测试中大幅超越现有方法


<details>
  <summary>Details</summary>
Motivation: 解决当前统一模型在交错图像-文本生成中的"单一工具"瓶颈问题，这些模型局限于合成图像，难以处理需要事实基础或程序化精度的任务

Method: 设计一个中央LLM/MLLM代理，通过强化学习框架协调专用视觉工具（在线图像搜索、扩散生成、代码执行、图像编辑），采用结合规则逻辑和LLM评估的混合奖励系统

Result: 在四个基准测试中实现了最先进的性能，大幅超越现有方法，并引入了新的测试时缩放策略以进一步提升性能

Conclusion: LLM-I框架通过工具使用的方法有效解决了交错图像-文本生成的挑战，展示了在多模态任务中协调专用工具的潜力

Abstract: We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.

</details>


### [124] [Controllable Pareto Trade-off between Fairness and Accuracy](https://arxiv.org/abs/2509.13651)
*Yongkang Du,Jieyu Zhao,Yijun Yang,Tianyi Zhou*

Main category: cs.LG

TL;DR: 提出CPT方法，通过多目标优化实现公平性与准确性的可控权衡，使用移动平均梯度稳定性和关键参数梯度剪枝技术，在仇恨言论检测和职业分类任务中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要寻找单一"最优"解决方案来平衡公平性和准确性，但帕累托前沿存在多种解决方案。本文旨在根据用户偏好提供可控的权衡方案。

Method: 提出Controllable Pareto Trade-off (CPT)方法：1) 使用随机梯度的移动平均来稳定公平性更新方向；2) 通过仅保留关键参数的梯度来剪枝梯度向量。

Result: 在仇恨言论检测和职业分类任务上的实验表明，CPT能够在帕累托前沿获得比基线方法更高质量的解决方案集合，并展现出更好的可控性，能够精确遵循人工定义的参考向量。

Conclusion: CPT方法有效解决了公平性-准确性权衡的可控性问题，通过梯度稳定和剪枝技术实现了对用户偏好的精确响应，为多目标优化在NLP任务中的应用提供了新思路。

Abstract: The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work
focuses on finding a single "optimal" solution to balance the two objectives,
which is limited considering the diverse solutions on the Pareto front. This
work intends to provide controllable trade-offs according to the user's
preference of the two objectives, which is defined as a reference vector. To
achieve this goal, we apply multi-objective optimization (MOO), which can find
solutions from various regions of the Pareto front. However, it is challenging
to precisely control the trade-off due to the stochasticity of the training
process and the high dimentional gradient vectors. Thus, we propose
Controllable Pareto Trade-off (CPT) that can effectively train models to
perform different trade-offs according to users' preferences. CPT 1) stabilizes
the fairness update with a moving average of stochastic gradients to determine
the update direction, and 2) prunes the gradients by only keeping the gradients
of the critical parameters. We evaluate CPT on hate speech detection and
occupation classification tasks. Experiments show that CPT can achieve a
higher-quality set of solutions on the Pareto front than the baseline methods.
It also exhibits better controllability and can precisely follow the
human-defined reference vectors.

</details>


### [125] [RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization](https://arxiv.org/abs/2509.13686)
*Bingsheng Peng,Shutao Zhang,Xi Zheng,Ye Xue,Xinyu Qin,Tsung-Hui Chang*

Main category: cs.LG

TL;DR: RF-LSCM是一个基于辐射场的多域无线信道建模框架，通过物理感知的频率相关衰减模型和点云增强方法，解决了传统单细胞单频段信道建模的局限性，在计算效率和精度上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统局部统计信道建模方法局限于单细胞、单网格和单载波频率分析，无法捕捉复杂的跨域交互，需要新的框架来支持多细胞多频段的信道建模需求。

Method: 提出RF-LSCM框架，采用辐射场联合建模大尺度信号衰减和多径分量；引入物理感知的频率相关衰减模型支持跨频段泛化；使用点云增强方法实现多细胞多网格建模；采用低秩张量表示和分层张量角度建模算法提高计算效率。

Result: 在真实多细胞数据集上的实验表明，RF-LSCM显著优于现有方法，覆盖预测的MAE降低30%，通过多频数据融合实现22%的MAE改进，同时大幅减少GPU内存需求和训练时间。

Conclusion: RF-LSCM通过创新的辐射场建模和高效计算设计，成功解决了传统信道建模的局限性，为蜂窝网络优化提供了更准确、高效的多域信道建模解决方案。

Abstract: Accurate localized wireless channel modeling is a cornerstone of cellular
network optimization, enabling reliable prediction of network performance
during parameter tuning. Localized statistical channel modeling (LSCM) is the
state-of-the-art channel modeling framework tailored for cellular network
optimization. However, traditional LSCM methods, which infer the channel's
Angular Power Spectrum (APS) from Reference Signal Received Power (RSRP)
measurements, suffer from critical limitations: they are typically confined to
single-cell, single-grid and single-carrier frequency analysis and fail to
capture complex cross-domain interactions. To overcome these challenges, we
propose RF-LSCM, a novel framework that models the channel APS by jointly
representing large-scale signal attenuation and multipath components within a
radiance field. RF-LSCM introduces a multi-domain LSCM formulation with a
physics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the
cross frequency generalization as well as a point-cloud-aided environment
enhanced method to enable multi-cell and multi-grid channel modeling.
Furthermore, to address the computational inefficiency of typical neural
radiance fields, RF-LSCM leverages a low-rank tensor representation,
complemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.
This efficient design significantly reduces GPU memory requirements and
training time while preserving fine-grained accuracy. Extensive experiments on
real-world multi-cell datasets demonstrate that RF-LSCM significantly
outperforms state-of-the-art methods, achieving up to a 30% reduction in mean
absolute error (MAE) for coverage prediction and a 22% MAE improvement by
effectively fusing multi-frequency data.

</details>


### [126] [WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data](https://arxiv.org/abs/2509.13725)
*Md Sabbir Ahmed,Noah French,Mark Rucker,Zhiyuan Wang,Taylor Myers-Brower,Kaitlyn Petz,Mehdi Boukhechba,Bethany A. Teachman,Laura E. Barnes*

Main category: cs.LG

TL;DR: 本研究开发了一种基于智能手表的心率监测系统，结合机器学习方法，能够以60.4%的平衡准确率预测社交焦虑患者的瞬时焦虑状态波动，为实时个性化干预提供技术支持。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是一种常见心理健康问题，但现有研究很少测量和预测日常生活中的瞬时焦虑波动。捕捉这些日内动态对于设计实时个性化干预（如JITAIs）至关重要。

Method: 使用定制智能手表系统对91名社交焦虑大学生进行平均9.03天的监测，每天7次生态瞬时评估。基于10,000多天外部心率数据开发基础模型，迁移学习到本研究数据集，结合特质水平测量构建元学习器。

Result: 在本研究数据集上达到60.4%的平衡准确率；在TILES-18数据集的外部验证中达到59.1%的平衡准确率，比先前工作至少提高7%。

Conclusion: 该方法能够有效预测社交焦虑患者的瞬时焦虑状态，具有良好的泛化能力，为开发实时心理健康干预提供了有前景的技术途径。

Abstract: Social anxiety is a common mental health condition linked to significant
challenges in academic, social, and occupational functioning. A core feature is
elevated momentary (state) anxiety in social situations, yet little prior work
has measured or predicted fluctuations in this anxiety throughout the day.
Capturing these intra-day dynamics is critical for designing real-time,
personalized interventions such as Just-In-Time Adaptive Interventions
(JITAIs). To address this gap, we conducted a study with socially anxious
college students (N=91; 72 after exclusions) using our custom smartwatch-based
system over an average of 9.03 days (SD = 2.95). Participants received seven
ecological momentary assessments (EMAs) per day to report state anxiety. We
developed a base model on over 10,000 days of external heart rate data,
transferred its representations to our dataset, and fine-tuned it to generate
probabilistic predictions. These were combined with trait-level measures in a
meta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety
detection in our dataset. To evaluate generalizability, we applied the training
approach to a separate hold-out set from the TILES-18 dataset-the same dataset
used for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%
balanced accuracy, outperforming prior work by at least 7%.

</details>


### [127] [State Space Models over Directed Graphs](https://arxiv.org/abs/2509.13735)
*Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 提出了DirGraphSSM，第一个将状态空间模型系统扩展到有向图学习的架构，通过k-hop ego图序列化和消息传递机制，在保持高效训练的同时实现了最先进的性能


<details>
  <summary>Details</summary>
Motivation: 现有GNN和图Transformer在处理有向图时面临两大挑战：有效捕捉长距离因果依赖关系，以及在处理大规模图数据集时平衡准确性和训练效率。现有的图状态空间模型仅适用于无向图，限制了其性能

Method: 提出DirEgo2Token方法通过k-hop ego图将有向图序列化，并在此基础上开发DirGraphSSM架构，通过消息传递机制在有向图上实现状态空间模型

Result: 在三个代表性有向图学习任务上达到最先进性能，在另外两个任务上获得竞争性性能，训练速度比现有最先进模型提升1.5倍到2倍

Conclusion: DirGraphSSM成功将有向图学习与状态空间模型相结合，在保持高效训练的同时显著提升了有向图学习的性能，为有向图学习领域提供了新的解决方案

Abstract: Directed graphs are ubiquitous across numerous domains, where the
directionality of edges encodes critical causal dependencies. However, existing
GNNs and graph Transformers tailored for directed graphs face two major
challenges: (1) effectively capturing long-range causal dependencies derived
from directed edges; (2) balancing accuracy and training efficiency when
processing large-scale graph datasets. In recent years, state space models
(SSMs) have achieved substantial progress in causal sequence tasks, and their
variants designed for graphs have demonstrated state-of-the-art accuracy while
maintaining high efficiency across various graph learning benchmarks. However,
existing graph state space models are exclusively designed for undirected
graphs, which limits their performance in directed graph learning. To this end,
we propose an innovative approach DirEgo2Token which sequentializes directed
graphs via k-hop ego graphs. This marks the first systematic extension of state
space models to the field of directed graph learning. Building upon this, we
develop DirGraphSSM, a novel directed graph neural network architecture that
implements state space models on directed graphs via the message-passing
mechanism. Experimental results demonstrate that DirGraphSSM achieves
state-of-the-art performance on three representative directed graph learning
tasks while attaining competitive performance on two additional tasks with
1.5$\times $ to 2$\times $ training speed improvements compared to existing
state-of-the-art models.

</details>


### [128] [ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning](https://arxiv.org/abs/2509.13739)
*Zihou Wu,Yuecheng Li,Tianchi Liao,Jian Lou,Chuan Chen*

Main category: cs.LG

TL;DR: ParaAegis是一个并行保护框架，通过模型分区策略在联邦学习中实现隐私-效用-效率的灵活平衡，使用差分隐私保护低重要性部分，同态加密保护关键部分，并通过分布式投票机制达成共识。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中现有保护机制（如差分隐私和同态加密）在模型效用和计算效率之间存在的刚性权衡问题，缺乏灵活性阻碍了实际应用。

Method: 提出ParaAegis框架，采用策略性模型分区方案：对模型低范数部分应用轻量级差分隐私，对剩余部分使用同态加密保护，并通过分布式投票机制确保分区共识。

Result: 理论分析确认了在相同隐私保护下效率与效用之间的可调节性。实验结果表明，通过调整超参数，该方法能够灵活地在模型准确性和训练时间之间进行优先级选择。

Conclusion: ParaAegis为联邦学习提供了灵活的隐私-效用-效率平衡控制，解决了现有保护机制的刚性权衡问题，具有实际应用价值。

Abstract: Federated learning (FL) faces a critical dilemma: existing protection
mechanisms like differential privacy (DP) and homomorphic encryption (HE)
enforce a rigid trade-off, forcing a choice between model utility and
computational efficiency. This lack of flexibility hinders the practical
implementation. To address this, we introduce ParaAegis, a parallel protection
framework designed to give practitioners flexible control over the
privacy-utility-efficiency balance. Our core innovation is a strategic model
partitioning scheme. By applying lightweight DP to the less critical, low norm
portion of the model while protecting the remainder with HE, we create a
tunable system. A distributed voting mechanism ensures consensus on this
partitioning. Theoretical analysis confirms the adjustments between efficiency
and utility with the same privacy. Crucially, the experimental results
demonstrate that by adjusting the hyperparameters, our method enables flexible
prioritization between model accuracy and training time.

</details>


### [129] [ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2509.13753)
*Hyotaek Jeon,Hyunwook Lee,Juwon Kim,Sungahn Ko*

Main category: cs.LG

TL;DR: ST-LINK是一个增强大语言模型捕捉时空依赖性的新框架，通过空间增强注意力和记忆检索前馈网络解决LLM在交通预测中空间建模的局限性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在交通预测中表现出潜力，但其主要针对序列标记处理的设计难以有效捕捉空间依赖性，特别是在处理图结构空间数据方面存在架构不兼容问题

Method: 提出ST-LINK框架，包含两个关键组件：1) 空间增强注意力(SE-Attention)，将旋转位置编码扩展到注意力机制中以整合空间相关性；2) 记忆检索前馈网络(MRFFN)，动态检索和利用关键历史模式来捕捉复杂时间依赖性

Result: 在基准数据集上的综合实验表明，ST-LINK超越了传统的深度学习和LLM方法，能够有效捕捉常规交通模式和突变变化

Conclusion: ST-LINK成功解决了LLM在交通预测中的空间建模限制，通过创新的空间增强机制和动态记忆检索，显著提升了时空依赖性的捕捉能力

Abstract: Traffic forecasting represents a crucial problem within intelligent
transportation systems. In recent research, Large Language Models (LLMs) have
emerged as a promising method, but their intrinsic design, tailored primarily
for sequential token processing, introduces notable challenges in effectively
capturing spatial dependencies. Specifically, the inherent limitations of LLMs
in modeling spatial relationships and their architectural incompatibility with
graph-structured spatial data remain largely unaddressed. To overcome these
limitations, we introduce ST-LINK, a novel framework that enhances the
capability of Large Language Models to capture spatio-temporal dependencies.
Its key components are Spatially-Enhanced Attention (SE-Attention) and the
Memory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary
position embeddings to integrate spatial correlations as direct rotational
transformations within the attention mechanism. This approach maximizes spatial
learning while preserving the LLM's inherent sequential processing structure.
Meanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to
capture complex temporal dependencies and improve the stability of long-term
forecasting. Comprehensive experiments on benchmark datasets demonstrate that
ST-LINK surpasses conventional deep learning and LLM approaches, and
effectively captures both regular traffic patterns and abrupt changes.

</details>


### [130] [Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning](https://arxiv.org/abs/2509.13763)
*Zongxin Shen,Yanyong Huang,Bin Wang,Jinyuan Chang,Shiyu Liu,Tianrui Li*

Main category: cs.LG

TL;DR: 本文从因果视角分析多视图无监督特征选择，提出CAUSA方法通过因果正则化模块分离混杂因子，解决现有方法因忽略混杂因子导致的虚假相关性问题。


<details>
  <summary>Details</summary>
Motivation: 现有多视图无监督特征选择方法通过特征与聚类标签的相关性来选择特征，但忽略了混杂因子可能导致的虚假相关性，导致选择不相关特征。

Method: 提出CAUSA方法：1) 使用广义无监督谱回归模型捕获特征与共识聚类标签的依赖关系；2) 引入因果正则化模块自适应分离混杂因子并学习视图共享样本权重来平衡混杂因子分布；3) 将两者整合为统一学习框架。

Result: 综合实验表明CAUSA优于多个最先进方法。

Conclusion: 这是首个在无监督设置下对因果多视图特征选择的深入研究，CAUSA能有效选择因果信息特征并缓解虚假相关性。

Abstract: Multi-view unsupervised feature selection (MUFS) has recently received
increasing attention for its promising ability in dimensionality reduction on
multi-view unlabeled data. Existing MUFS methods typically select
discriminative features by capturing correlations between features and
clustering labels. However, an important yet underexplored question remains:
\textit{Are such correlations sufficiently reliable to guide feature
selection?} In this paper, we analyze MUFS from a causal perspective by
introducing a novel structural causal model, which reveals that existing
methods may select irrelevant features because they overlook spurious
correlations caused by confounders. Building on this causal perspective, we
propose a novel MUFS method called CAusal multi-view Unsupervised feature
Selection leArning (CAUSA). Specifically, we first employ a generalized
unsupervised spectral regression model that identifies informative features by
capturing dependencies between features and consensus clustering labels. We
then introduce a causal regularization module that can adaptively separate
confounders from multi-view data and simultaneously learn view-shared sample
weights to balance confounder distributions, thereby mitigating spurious
correlations. Thereafter, integrating both into a unified learning framework
enables CAUSA to select causally informative features. Comprehensive
experiments demonstrate that CAUSA outperforms several state-of-the-art
methods. To our knowledge, this is the first in-depth study of causal
multi-view feature selection in the unsupervised setting.

</details>


### [131] [Floating-Body Hydrodynamic Neural Networks](https://arxiv.org/abs/2509.13783)
*Tianshuo Zhang,Wenzhe Zhai,Rui Yann,Jia Gao,He Cao,Xianglei Xing*

Main category: cs.LG

TL;DR: FHNN是一种物理结构化的流体-结构相互作用神经网络框架，通过预测可解释的水动力参数并与解析运动方程耦合，显著提升了长期预测稳定性和物理一致性。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒神经网络模型在流体-结构相互作用问题中存在可解释性差、长期预测不稳定等问题，需要一种既能保持物理一致性又能处理耗散动力学的方法。

Method: 提出Floating-Body Hydrodynamic Neural Networks (FHNN)，通过预测方向附加质量、阻力系数和基于流函数的流场等可解释水动力参数，并将其与解析运动方程耦合。

Result: 在合成涡流数据集上，FHNN比神经ODE的误差低一个数量级，能够恢复物理一致的流场，在处理耗散动力学方面比哈密顿和拉格朗日神经网络更有效。

Conclusion: FHNN成功弥合了黑盒学习与透明系统识别之间的差距，在保持可解释性的同时有效处理耗散动力学问题。

Abstract: Fluid-structure interaction is common in engineering and natural systems,
where floating-body motion is governed by added mass, drag, and background
flows. Modeling these dissipative dynamics is difficult: black-box neural
models regress state derivatives with limited interpretability and unstable
long-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks
(FHNN), a physics-structured framework that predicts interpretable hydrodynamic
parameters such as directional added masses, drag coefficients, and a
streamfunction-based flow, and couples them with analytic equations of motion.
This design constrains the hypothesis space, enhances interpretability, and
stabilizes integration. On synthetic vortex datasets, FHNN achieves up to an
order-of-magnitude lower error than Neural ODEs, recovers physically consistent
flow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN
more effectively handles dissipative dynamics while preserving
interpretability, which bridges the gap between black-box learning and
transparent system identification.

</details>


### [132] [Towards a Physics Foundation Model](https://arxiv.org/abs/2509.13805)
*Florian Wiesner,Matthias Wessling,Stephen Baek*

Main category: cs.LG

TL;DR: 提出了通用物理变换器(GPhyT)，这是一个基于Transformer的物理基础模型，能够在多个物理领域实现零样本泛化和稳定长期预测，无需重新训练即可处理不同的物理系统。


<details>
  <summary>Details</summary>
Motivation: 当前基于物理的机器学习方法局限于单一狭窄领域，需要为每个新系统重新训练。物理基础模型(PFM)可以 democratize 高保真模拟访问，加速科学发现，消除专业求解器开发需求。

Method: 使用Transformer架构，在1.8TB多样化模拟数据上训练，通过上下文学习从数据中推断控制动力学，无需告知底层方程。

Result: GPhyT在多个物理域表现优异，比专业架构性能提升高达29倍；通过上下文学习实现零样本泛化到未见物理系统；实现50时间步的稳定长期预测。

Conclusion: 这项工作证明单个模型可以从数据中学习可泛化的物理原理，为通向可能改变计算科学与工程的通用物理基础模型开辟了道路。

Abstract: Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.

</details>


### [133] [Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy](https://arxiv.org/abs/2509.14129)
*Kit T. Rodolfa,Erika Salomon,Jin Yao,Steve Yoder,Robert Sullivan,Kevin McGuire,Allie Dickinson,Rob MacDougall,Brian Seidler,Christina Sung,Claire Herdeman,Rayid Ghani*

Main category: cs.LG

TL;DR: 本研究通过预测建模和实地试验，评估了针对高风险个体的心理健康外展服务对降低再监禁率的效果。


<details>
  <summary>Details</summary>
Motivation: 监狱系统往往无法有效处理被监禁者的心理健康、药物依赖和无家可归等复杂需求，导致再犯罪和监禁循环，特别是对有色人种社区造成不成比例的影响。

Method: 采用预测建模方法识别高风险个体，并进行实地试验评估针对性心理健康外展服务的效果，包括分析心理健康服务使用、急救调度和刑事司法参与等指标。

Result: 模型对新的监狱收押具有高度预测性，最高风险群体中超过一半在一年内重返监狱。外展服务对最高风险个体最有效，显著影响了心理健康服务使用、急救调度和刑事司法参与。

Conclusion: 针对性心理健康外展服务，特别是针对最高风险个体，可以有效打破监禁循环，改善个体结局和公共安全。

Abstract: Many incarcerated individuals face significant and complex challenges,
including mental illness, substance dependence, and homelessness, yet jails and
prisons are often poorly equipped to address these needs. With little support
from the existing criminal justice system, these needs can remain untreated and
worsen, often leading to further offenses and a cycle of incarceration with
adverse outcomes both for the individual and for public safety, with
particularly large impacts on communities of color that continue to widen the
already extensive racial disparities in criminal justice outcomes. Responding
to these failures, a growing number of criminal justice stakeholders are
seeking to break this cycle through innovative approaches such as
community-driven and alternative approaches to policing, mentoring, community
building, restorative justice, pretrial diversion, holistic defense, and social
service connections. Here we report on a collaboration between Johnson County,
Kansas, and Carnegie Mellon University to perform targeted, proactive mental
health outreach in an effort to reduce reincarceration rates.
  This paper describes the data used, our predictive modeling approach and
results, as well as the design and analysis of a field trial conducted to
confirm our model's predictive power, evaluate the impact of this targeted
outreach, and understand at what level of reincarceration risk outreach might
be most effective. Through this trial, we find that our model is highly
predictive of new jail bookings, with more than half of individuals in the
trial's highest-risk group returning to jail in the following year. Outreach
was most effective among these highest-risk individuals, with impacts on mental
health utilization, EMS dispatches, and criminal justice involvement.

</details>


### [134] [Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment](https://arxiv.org/abs/2509.13818)
*Zheng-an Wang,Yanbo J. Wang,Jiachi Zhang,Qi Xu,Yilun Zhao,Jintao Li,Yipeng Zhang,Bo Yang,Xinkai Gao,Xiaofeng Cao,Kai Xu,Pengpeng Hao,Xuan Yang,Heng Fan*

Main category: cs.LG

TL;DR: 该论文提出了一种混合量子-经典工作流，用于解决普惠金融中数据稀缺的少样本信用风险评估问题，通过量子神经网络在真实量子硬件上取得了优于经典方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决普惠金融中数据稀缺和样本不平衡导致的信用风险评估难题，传统方法在此类少样本场景下效果有限，需要探索量子机器学习的新范式。

Method: 设计混合量子-经典工作流：首先使用经典机器学习模型（逻辑回归、随机森林、XGBoost）进行特征工程和降维，然后使用参数偏移规则训练的量子神经网络作为核心分类器。

Result: 在279个真实信用数据样本上，量子神经网络在模拟中平均AUC达到0.852±0.027，在Quafu量子云平台的超导处理器上实验AUC达到0.88，超越了多个经典基准方法，特别是在召回率指标上表现突出。

Conclusion: 该研究为NISQ时代数据受限的金融场景应用量子计算提供了实用蓝图，并为量子机器学习在高风险普惠金融应用中的潜力提供了有价值的实证证据。

Abstract: Quantum Machine Learning (QML) offers a new paradigm for addressing complex
financial problems intractable for classical methods. This work specifically
tackles the challenge of few-shot credit risk assessment, a critical issue in
inclusive finance where data scarcity and imbalance limit the effectiveness of
conventional models. To address this, we design and implement a novel hybrid
quantum-classical workflow. The methodology first employs an ensemble of
classical machine learning models (Logistic Regression, Random Forest, XGBoost)
for intelligent feature engineering and dimensionality reduction. Subsequently,
a Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as
the core classifier. This framework was evaluated through numerical simulations
and deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting
processor. On a real-world credit dataset of 279 samples, our QNN achieved a
robust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive
AUC of 0.88 in the hardware experiment. This performance surpasses a suite of
classical benchmarks, with a particularly strong result on the recall metric.
This study provides a pragmatic blueprint for applying quantum computing to
data-constrained financial scenarios in the NISQ era and offers valuable
empirical evidence supporting its potential in high-stakes applications like
inclusive finance.

</details>


### [135] [An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction](https://arxiv.org/abs/2509.13841)
*Qingqi Zhao,Heng Xiao*

Main category: cs.LG

TL;DR: 提出了一种将图神经网络嵌入孔隙网络模型的端到端可微分混合框架，用于多孔介质渗透率预测，避免了传统方法的理想化几何假设，提高了准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动模型缺乏跨尺度泛化能力且不包含物理约束，而孔隙网络模型虽然基于物理但依赖理想化几何假设，限制了在复杂结构中的准确性。需要结合两者优势的新方法。

Method: 开发端到端可微分混合框架，用图神经网络替代传统解析公式进行导流能力预测，通过自动微分和离散伴随方法实现反向传播，仅需单一渗透率标量作为训练目标。

Result: 模型实现了高精度和良好的跨尺度泛化能力，优于纯数据驱动和传统孔隙网络模型方法，梯度敏感性分析显示物理一致的特征影响。

Conclusion: 该方法为复杂多孔介质渗透率预测提供了可扩展且物理信息丰富的框架，降低了模型不确定性并提高了准确性。

Abstract: Accurate prediction of permeability in porous media is essential for modeling
subsurface flow. While pure data-driven models offer computational efficiency,
they often lack generalization across scales and do not incorporate explicit
physical constraints. Pore network models (PNMs), on the other hand, are
physics-based and efficient but rely on idealized geometric assumptions to
estimate pore-scale hydraulic conductance, limiting their accuracy in complex
structures. To overcome these limitations, we present an end-to-end
differentiable hybrid framework that embeds a graph neural network (GNN) into a
PNM. In this framework, the analytical formulas used for conductance
calculations are replaced by GNN-based predictions derived from pore and throat
features. The predicted conductances are then passed to the PNM solver for
permeability computation. In this way, the model avoids the idealized geometric
assumptions of PNM while preserving the physics-based flow calculations. The
GNN is trained without requiring labeled conductance data, which can number in
the thousands per pore network; instead, it learns conductance values by using
a single scalar permeability as the training target. This is made possible by
backpropagating gradients through both the GNN (via automatic differentiation)
and the PNM solver (via a discrete adjoint method), enabling fully coupled,
end-to-end training. The resulting model achieves high accuracy and generalizes
well across different scales, outperforming both pure data-driven and
traditional PNM approaches. Gradient-based sensitivity analysis further reveals
physically consistent feature influences, enhancing model interpretability.
This approach offers a scalable and physically informed framework for
permeability prediction in complex porous media, reducing model uncertainty and
improving accuracy.

</details>


### [136] [Graph-Regularized Learning of Gaussian Mixture Models](https://arxiv.org/abs/2509.13855)
*Shamsiiat Abdurakhmanova,Alex Jung*

Main category: cs.LG

TL;DR: 提出了一种在分布式环境下基于图正则化的高斯混合模型学习方法，利用相似性图指导节点间参数共享，避免原始数据传输，在异构小样本场景下优于集中式和本地训练的GMM


<details>
  <summary>Details</summary>
Motivation: 解决分布式环境中数据异构且样本有限的情况下，如何有效学习高斯混合模型的问题，同时避免原始数据传输带来的隐私和安全风险

Method: 使用图正则化方法，通过提供的相似性图来指导不同节点间的参数共享，实现灵活的邻居参数聚合

Result: 该方法在异构、小样本场景下表现优于集中式训练和本地单独训练的GMM模型

Conclusion: 图正则化的GMM学习方法为分布式异构数据环境提供了一种有效的解决方案，既能保护数据隐私又能提升模型性能

Abstract: We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in
distributed settings with heterogeneous and limited local data. The method
exploits a provided similarity graph to guide parameter sharing among nodes,
avoiding the transfer of raw data. The resulting model allows for flexible
aggregation of neighbors' parameters and outperforms both centralized and
locally trained GMMs in heterogeneous, low-sample regimes.

</details>


### [137] [Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets](https://arxiv.org/abs/2010.01052)
*Jaume Banus,Maxime Sermesant,Oscar Camara,Marco Lorenzi*

Main category: cs.LG

TL;DR: 提出概率框架联合心脏数据插补和心血管机制模型个性化，用于脑研究中不完整心脏数据的处理


<details>
  <summary>Details</summary>
Motivation: 临床研究中缺乏多模态患者数据限制了机制模型的应用，神经影像数据集无法充分代表心脏特征来建模脑疾病中的心血管因素

Method: 基于变分推理框架，联合推断从可用特征插补心脏信息的模型，以及能够忠实再现个性化心血管动力学的高斯过程仿真器

Result: 在UK Biobank上的实验表明，该模型能够准确插补仅包含收缩压和舒张压等最少心脏信息的数据集中的缺失心脏特征，同时联合估计集总模型的仿真参数

Conclusion: 该方法通过模拟与不同脑解剖条件相对应的真实心脏动力学，为探索心脑联合关系提供了新途径

Abstract: The use of mechanistic models in clinical studies is limited by the lack of
multi-modal patients data representing different anatomical and physiological
processes. For example, neuroimaging datasets do not provide a sufficient
representation of heart features for the modeling of cardiovascular factors in
brain disorders. To tackle this problem we introduce a probabilistic framework
for joint cardiac data imputation and personalisation of cardiovascular
mechanistic models, with application to brain studies with incomplete heart
data. Our approach is based on a variational framework for the joint inference
of an imputation model of cardiac information from the available features,
along with a Gaussian Process emulator that can faithfully reproduce
personalised cardiovascular dynamics. Experimental results on UK Biobank show
that our model allows accurate imputation of missing cardiac features in
datasets containing minimal heart information, e.g. systolic and diastolic
blood pressures only, while jointly estimating the emulated parameters of the
lumped model. This allows a novel exploration of the heart-brain joint
relationship through simulation of realistic cardiac dynamics corresponding to
different conditions of brain anatomy.

</details>


### [138] [Masked Diffusion Models as Energy Minimization](https://arxiv.org/abs/2509.13866)
*Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li*

Main category: cs.LG

TL;DR: 该论文提出了一个理论框架，将掩码扩散模型解释为离散最优传输中的能量最小化问题，证明了三种能量形式的数学等价性，并通过Beta分布参数化插值调度，实现了高效的后训练调优。


<details>
  <summary>Details</summary>
Motivation: 统一掩码扩散模型的理论基础，澄清其在离散最优传输中的数学解释，并为实际采样改进提供理论指导。

Method: 证明三种能量形式（动能、条件动能和测地能量）在MDMs结构下的数学等价性；使用Beta分布参数化插值调度，将调度设计空间简化为2D搜索；通过后训练调优无需修改模型。

Result: 实验表明，基于能量启发的调度在合成和真实基准测试中优于手工设计的基线，特别是在低步采样设置中表现突出。

Conclusion: 该研究不仅统一了掩码扩散模型的理论解释，还提供了实用的调度优化方法，显著提升了采样效率，特别是在资源受限的低步采样场景中。

Abstract: We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.

</details>


### [139] [FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning](https://arxiv.org/abs/2509.13895)
*Zhanting Zhou,Jinshan Lai,Fengchun Zhang,Zeqin Wu,Fengli Zhang*

Main category: cs.LG

TL;DR: FedSSG是一种基于随机采样的历史感知漂移对齐方法，通过维护每个客户端的漂移记忆和基于参与率的门控机制，有效解决联邦学习中的非IID数据和部分参与导致的客户端漂移问题。


<details>
  <summary>Details</summary>
Motivation: 非IID数据和部分参与会导致联邦学习中的客户端漂移和局部最优不一致，造成收敛不稳定和准确率下降。

Method: FedSSG维护每个客户端的漂移记忆，累积本地模型差异作为历史梯度的轻量级草图；使用基于观察/期望参与比的平滑函数门控内存更新和本地对齐项。

Result: 在CIFAR-10/100数据集上，FedSSG比基线方法提升测试准确率约0.9-2.7个百分点，平均加速收敛约4.5倍，仅增加O(d)客户端内存和常数时间门控。

Conclusion: FedSSG证明采样统计可以转化为原则性的历史感知相位控制，稳定并加速联邦训练，在近IID或均匀采样下优雅退化为温和正则化器。

Abstract: Non-IID data and partial participation induce client drift and inconsistent
local optima in federated learning, causing unstable convergence and accuracy
loss. We present FedSSG, a stochastic sampling-guided, history-aware drift
alignment method. FedSSG maintains a per-client drift memory that accumulates
local model differences as a lightweight sketch of historical gradients;
crucially, it gates both the memory update and the local alignment term by a
smooth function of the observed/expected participation ratio (a
phase-by-expectation signal derived from the server sampler). This
statistically grounded gate stays weak and smooth when sampling noise dominates
early, then strengthens once participation statistics stabilize, contracting
the local-global gap without extra communication. Across CIFAR-10/100 with
100/500 clients and 2-15 percent participation, FedSSG consistently outperforms
strong drift-aware baselines and accelerates convergence; on our benchmarks it
improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and
about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about
4.5x faster target-accuracy convergence on average. The method adds only O(d)
client memory and a constant-time gate, and degrades gracefully to a mild
regularizer under near-IID or uniform sampling. FedSSG shows that sampling
statistics can be turned into a principled, history-aware phase control to
stabilize and speed up federated training.

</details>


### [140] [TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates](https://arxiv.org/abs/2509.13906)
*Afrin Dange,Sunita Sarawagi*

Main category: cs.LG

TL;DR: TFMAdapter是一种轻量级适配器，无需微调即可为时间序列基础模型添加协变量信息，通过两阶段方法结合伪预测和TSFM预测，在真实数据集上比基础模型提升24-27%性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型(TSFMs)虽然在新时间序列的单变量预测上表现优异，但无法利用对未来可用的外生协变量，而这些变量在许多应用中对于准确预测至关重要。

Method: 提出TFMAdapter轻量级实例级适配器，采用两阶段方法：(1)使用简单回归模型生成伪预测，(2)训练高斯过程回归器，结合伪预测、TSFM预测和协变量来优化预测结果，避免大量调用TSFM。

Result: 在真实世界数据集上的广泛实验表明，TFMAdapter始终优于基础模型和监督基线，相比基础基础模型实现了24-27%的性能提升，且数据和计算开销最小。

Conclusion: 轻量级适配器有潜力弥合通用基础模型与领域特定预测需求之间的差距，TFMAdapter展示了在不重新训练的情况下有效整合协变量信息的能力。

Abstract: Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art
performance in univariate forecasting on new time series simply by conditioned
on a brief history of past values. Their success demonstrates that large-scale
pretraining across diverse domains can acquire the inductive bias to generalize
from temporal patterns in a brief history. However, most TSFMs are unable to
leverage covariates -- future-available exogenous variables critical for
accurate forecasting in many applications -- due to their domain-specific
nature and the lack of associated inductive bias. We propose TFMAdapter, a
lightweight, instance-level adapter that augments TSFMs with covariate
information without fine-tuning. Instead of retraining, TFMAdapter operates on
the limited history provided during a single model call, learning a
non-parametric cascade that combines covariates with univariate TSFM forecasts.
However, such learning would require univariate forecasts at all steps in the
history, requiring too many calls to the TSFM. To enable training on the full
historical context while limiting TSFM invocations, TFMAdapter uses a two-stage
method: (1) generating pseudo-forecasts with a simple regression model, and (2)
training a Gaussian Process regressor to refine predictions using both pseudo-
and TSFM forecasts alongside covariates. Extensive experiments on real-world
datasets demonstrate that TFMAdapter consistently outperforms both foundation
models and supervised baselines, achieving a 24-27\% improvement over base
foundation models with minimal data and computational overhead. Our results
highlight the potential of lightweight adapters to bridge the gap between
generic foundation models and domain-specific forecasting needs.

</details>


### [141] [APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness](https://arxiv.org/abs/2509.13908)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: APFEx是首个显式建模交叉公平性的框架，通过多目标优化解决多个敏感属性组合的公平性问题，在保持准确性的同时显著减少公平性违规


<details>
  <summary>Details</summary>
Motivation: 现有公平性方法只处理单一敏感属性，无法捕捉种族、性别、年龄等交叉属性带来的复合偏见，需要专门解决交叉子群体的细微偏见问题

Method: APFEx框架包含三个创新：自适应多目标优化器（动态切换帕累托锥投影、梯度加权和探索策略）、可微交叉公平性度量指标、理论收敛保证

Result: 在四个真实数据集上的实验表明，APFEx在保持竞争力的准确性的同时，显著减少了公平性违规，优于现有方法

Conclusion: 该工作填补了公平机器学习的重要空白，提供了可扩展、模型无关的交叉公平性解决方案

Abstract: Ensuring fairness in machine learning models is critical, especially when
biases compound across intersecting protected attributes like race, gender, and
age. While existing methods address fairness for single attributes, they fail
to capture the nuanced, multiplicative biases faced by intersectional
subgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first
framework to explicitly model intersectional fairness as a joint optimization
problem over the Cartesian product of sensitive attributes. APFEx combines
three key innovations- (1) an adaptive multi-objective optimizer that
dynamically switches between Pareto cone projection, gradient weighting, and
exploration strategies to navigate fairness-accuracy trade-offs, (2)
differentiable intersectional fairness metrics enabling gradient-based
optimization of non-smooth subgroup disparities, and (3) theoretical guarantees
of convergence to Pareto-optimal solutions. Experiments on four real-world
datasets demonstrate APFEx's superiority, reducing fairness violations while
maintaining competitive accuracy. Our work bridges a critical gap in fair ML,
providing a scalable, model-agnostic solution for intersectional fairness.

</details>


### [142] [Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction](https://arxiv.org/abs/2509.13914)
*Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini*

Main category: cs.LG

TL;DR: 通过简单的置信度加权平均方法，无需重新训练即可组合多个最先进的深度学习模型，在车辆轨迹预测任务中实现10%的性能提升


<details>
  <summary>Details</summary>
Motivation: 解决如何在不进行昂贵重新训练的情况下，结合多个大型预测模型优势的开放挑战，特别是在自动驾驶领域的轨迹预测问题

Method: 使用置信度加权平均方法直接组合现成的最先进深度学习模型，无需重新训练或微调

Result: 在NuScenes和Argoverse数据集上，该方法比最佳单一模型性能提升10%，特别是在长尾指标上表现优异，且改进在整个数据分布中都有效

Conclusion: 简单的模型集成方法能够有效提升轨迹预测性能，证明了无需复杂重新训练即可组合大型模型的可行性

Abstract: This work explores the application of ensemble modeling to the
multidimensional regression problem of trajectory prediction for vehicles in
urban environments. As newer and bigger state-of-the-art prediction models for
autonomous driving continue to emerge, an important open challenge is the
problem of how to combine the strengths of these big models without the need
for costly re-training. We show how, perhaps surprisingly, combining
state-of-the-art deep learning models out-of-the-box (without retraining or
fine-tuning) with a simple confidence-weighted average method can enhance the
overall prediction. Indeed, while combining trajectory prediction models is not
straightforward, this simple approach enhances performance by 10% over the best
prediction model, especially in the long-tailed metrics. We show that this
performance improvement holds on both the NuScenes and Argoverse datasets, and
that these improvements are made across the dataset distribution. The code for
our work is open source.

</details>


### [143] [Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning](https://arxiv.org/abs/2509.13933)
*Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu*

Main category: cs.LG

TL;DR: 提出WILF-Q方法解决无线联邦学习中的客户端选择问题，通过Q学习自适应学习Whittle指数来选择最优客户端，显著提升学习效率


<details>
  <summary>Details</summary>
Motivation: 无线联邦学习中客户端动态状态变化影响计算和通信效率，需要高效选择客户端来减少达到特定学习精度所需的总时间

Method: 将客户端选择建模为多臂老虎机问题，提出WILF-Q方法使用Q学习自适应学习和更新每个客户端的近似Whittle指数，选择指数最高的客户端

Result: 实验结果表明WILF-Q在学习效率方面显著优于现有基线策略

Conclusion: WILF-Q不需要客户端状态转移或数据分布的显式知识，适用于实际联邦学习部署，为无线联邦学习中的客户端选择提供了鲁棒高效的解决方案

Abstract: We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.

</details>


### [144] [Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection](https://arxiv.org/abs/2509.13974)
*Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza*

Main category: cs.LG

TL;DR: EpiSMART是一个用于癫痫发作检测的持续学习框架，通过选择性保留高熵和预测为发作的样本，在资源受限条件下实现个性化自适应，相比静态基线模型F1分数提升21%。


<details>
  <summary>Details</summary>
Motivation: 癫痫诊断依赖专家分析EEG信号，过程耗时且需要专业知识。现有深度学习模型存在灾难性遗忘问题，无法适应患者EEG信号特征的动态变化，需要开发能够持续学习并个性化的检测方法。

Method: 提出EpiSMART持续学习框架，使用大小受限的重放缓冲区和智能样本选择策略，选择性保留高熵和预测为癫痫发作的样本，以增量方式适应患者特定的EEG信号特征。

Result: 在CHB-MIT数据集上验证，EpiSMART相比不更新的基线模型F1分数提升21%，平均每天仅需6.46分钟标记数据和6.28次更新，适合可穿戴系统实时部署。

Conclusion: EpiSMART能够在资源受限的现实条件下，有效整合新数据而不破坏已有知识，实现鲁棒的个性化癫痫发作检测，推动可穿戴医疗系统的实际应用。

Abstract: Objective: Epilepsy, a prevalent neurological disease, demands careful
diagnosis and continuous care. Seizure detection remains challenging, as
current clinical practice relies on expert analysis of electroencephalography,
which is a time-consuming process and requires specialized knowledge.
Addressing this challenge, this paper explores automated epileptic seizure
detection using deep learning, focusing on personalized continual learning
models that adapt to each patient's unique electroencephalography signal
features, which evolve over time. Methods: In this context, our approach
addresses the challenge of integrating new data into existing models without
catastrophic forgetting, a common issue in static deep learning models. We
propose EpiSMART, a continual learning framework for seizure detection that
uses a size-constrained replay buffer and an informed sample selection strategy
to incrementally adapt to patient-specific electroencephalography signals. By
selectively retaining high-entropy and seizure-predicted samples, our method
preserves critical past information while maintaining high performance with
minimal memory and computational requirements. Results: Validation on the
CHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score
over a trained baseline without updates in all other patients. On average,
EpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,
making it suitable for real-time deployment in wearable systems.
Conclusion:EpiSMART enables robust and personalized seizure detection under
realistic and resource-constrained conditions by effectively integrating new
data into existing models without degrading past knowledge. Significance: This
framework advances automated seizure detection by providing a continual
learning approach that supports patient-specific adaptation and practical
deployment in wearable healthcare systems.

</details>


### [145] [Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations](https://arxiv.org/abs/2509.14000)
*Ivana Kesić,Aljaž Blatnik,Carolina Fortuna,Blaž Bertalanič*

Main category: cs.LG

TL;DR: 提出基于动态图回归的GNSS干扰抑制方法，使用异构图卷积LSTM网络实时预测和校正接收机水平偏差，在多种干扰场景下显著优于传统时间序列基线模型


<details>
  <summary>Details</summary>
Motivation: GNSS系统日益受到故意干扰的影响，在需要保持定位和定时功能的关键时刻导致服务中断，需要开发有效的干扰抑制技术

Method: 将卫星接收环境建模为异构星形图（接收机为中心，卫星为叶节点），使用单层异构图卷积LSTM（HeteroGCLSTM）聚合空间上下文和时间动态信息，实时预测2D偏差向量进行校正

Result: 在两种接收机和三种干扰模式下，模型在-45dBm时达到3.64-7.74cm的MAE，在-60至-70dBm时提升至1.65-2.08cm。混合模式下MAE为3.78-4.25cm，数据效率研究中仅用10%训练数据仍优于基线模型

Conclusion: 该方法通过图神经网络有效处理GNSS干扰问题，在精度和数据效率方面均显著优于传统时间序列方法，为实时干扰抑制提供了有效解决方案

Abstract: Global Navigation Satellite Systems (GNSS) are increasingly disrupted by
intentional jamming, degrading availability precisely when positioning and
timing must remain operational. We address this by reframing jamming mitigation
as dynamic graph regression and introducing a receiver-centric deep temporal
graph network that predicts, and thus corrects, the receivers horizontal
deviation in real time. At each 1 Hz epoch, the satellite receiver environment
is represented as a heterogeneous star graph (receiver center, tracked
satellites as leaves) with time varying attributes (e.g., SNR, azimuth,
elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM
(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a
short history to output the 2D deviation vector applied for on the fly
correction.
  We evaluate on datasets from two distinct receivers under three jammer
profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each
exercised at six power levels between -45 and -70 dBm, with 50 repetitions per
scenario (prejam/jam/recovery). Against strong multivariate time series
baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains
the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm
(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and
4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode
datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),
outperforming Seq2Point, MLP, and CNN. A split study shows superior data
efficiency: with only 10\% training data our approach remains well ahead of
baselines (20 cm vs. 36-42 cm).

</details>


### [146] [Differentially private federated learning for localized control of infectious disease dynamics](https://arxiv.org/abs/2509.14024)
*Raouf Kerkouche,Henrik Zunker,Mario Fritz,Martin J. Kühn*

Main category: cs.LG

TL;DR: 提出基于联邦学习和差分隐私的隐私保护流行病预测方法，在德国县级层面实现本地化预测，在保护隐私的同时保持预测准确性


<details>
  <summary>Details</summary>
Motivation: 在流行病期间需要快速反应，但本地化机器学习模型训练面临数据不足问题，而集中化数据又存在隐私敏感性问题，需要找到既能保护隐私又能提供详细情境数据的解决方案

Method: 采用联邦学习框架，以县/社区为客户端，使用多层感知机在滑动窗口上进行病例数预测，客户端只交换经过范数裁剪的更新，服务器使用差分隐私噪声聚合更新

Result: 在适度隐私保护水平下，差分隐私模型接近非差分隐私模型性能：2020年11月R²=0.94（vs 0.95），MAPE=26%；2022年3月R²=0.88（vs 0.93），MAPE=21%

Conclusion: 客户端级差分隐私联邦学习能够在提供强隐私保证的同时提供有用的县级预测，可行的隐私预算取决于流行病阶段，允许卫生当局进行隐私合规的协作

Abstract: In times of epidemics, swift reaction is necessary to mitigate epidemic
spreading. For this reaction, localized approaches have several advantages,
limiting necessary resources and reducing the impact of interventions on a
larger scale. However, training a separate machine learning (ML) model on a
local scale is often not feasible due to limited available data. Centralizing
the data is also challenging because of its high sensitivity and privacy
constraints. In this study, we consider a localized strategy based on the
German counties and communities managed by the related local health authorities
(LHA). For the preservation of privacy to not oppose the availability of
detailed situational data, we propose a privacy-preserving forecasting method
that can assist public health experts and decision makers. ML methods with
federated learning (FL) train a shared model without centralizing raw data.
Considering the counties, communities or LHAs as clients and finding a balance
between utility and privacy, we study a FL framework with client-level
differential privacy (DP). We train a shared multilayer perceptron on sliding
windows of recent case counts to forecast the number of cases, while clients
exchange only norm-clipped updates and the server aggregated updates with DP
noise. We evaluate the approach on COVID-19 data on county-level during two
phases. As expected, very strict privacy yields unstable, unusable forecasts.
At a moderately strong level, the DP model closely approaches the non-DP model:
$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in
November 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,
client-level DP-FL can deliver useful county-level predictions with strong
privacy guarantees, and viable privacy budgets depend on epidemic phase,
allowing privacy-compliant collaboration among health authorities for local
forecasting.

</details>


### [147] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm*

Main category: cs.LG

TL;DR: 使用小波变换将纳米孔蛋白质电流信号转换为尺度图图像，通过机器学习实现81%的分类准确率，推进实时疾病诊断技术


<details>
  <summary>Details</summary>
Motivation: 开发能够在临床环境中实时分类蛋白质的设备，实现廉价快速的疾病诊断。纳米孔技术通过测量蛋白质进入纳米孔时产生的电流信号进行识别，但现有方法因信号复杂性而准确率有限

Method: 将电流信号通过小波变换转换为尺度图图像，捕捉振幅、频率和时间信息，使用机器学习算法进行分类。还展示了模型迁移技术以适应实际硬件部署

Result: 在42种肽类测试中达到约81%的分类准确率，创下该领域新的最先进水平

Conclusion: 该方法为实时肽/蛋白质诊断技术在临床护理点的实际应用迈出了重要一步，为实时疾病诊断开辟了新途径

Abstract: A device capable of performing real time classification of proteins in a
clinical setting would allow for inexpensive and rapid disease diagnosis. One
such candidate for this technology are nanopore devices. These devices work by
measuring a current signal that arises when a protein or peptide enters a
nanometer-length-scale pore. Should this current be uniquely related to the
structure of the peptide and its interactions with the pore, the signals can be
used to perform identification. While such a method would allow for real time
identification of peptides and proteins in a clinical setting, to date, the
complexities of these signals limit their accuracy. In this work, we tackle the
issue of classification by converting the current signals into scaleogram
images via wavelet transforms, capturing amplitude, frequency, and time
information in a modality well-suited to machine learning algorithms. When
tested on 42 peptides, our method achieved a classification accuracy of
~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward
practical peptide/protein diagnostics at the point of care. In addition, we
demonstrate model transfer techniques that will be critical when deploying
these models into real hardware, paving the way to a new method for real-time
disease diagnosis.

</details>


### [148] [Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing](https://arxiv.org/abs/2509.14061)
*Chiara De Luca,Elisa Donati*

Main category: cs.LG

TL;DR: 一种基于环境感知器融合的轻量级多模态系统，通过STM32微控制器实现实时低功耗的蜂王检测，准确率超199%，免去了声音检测的缺陷


<details>
  <summary>Details</summary>
Motivation: 当前蜂王监测依靠人工检查，劳动密集且干扰蜂群，而音频方法需要高耗电和复杂预处理，容易受环境噪声影响

Method: 采用温度、湿度和压力差异等环境感知器融合，在STM32微控制器上运行量化决策树推理，实现边缘计算

Result: 系统仅使用环境输入即可达到99%以上的蜂王检测准确率，音频特征并未带来显著性能提升

Conclusion: 该系统为非侵入式蜂箱监测提供了可扩展、可持续的解决方案，为使用商业化节能硬件实现自主精准养蜂摩平了道路

Abstract: Queen bee presence is essential for the health and stability of honeybee
colonies, yet current monitoring methods rely on manual inspections that are
labor-intensive, disruptive, and impractical for large-scale beekeeping. While
recent audio-based approaches have shown promise, they often require high power
consumption, complex preprocessing, and are susceptible to ambient noise. To
overcome these limitations, we propose a lightweight, multimodal system for
queen detection based on environmental sensor fusion-specifically, temperature,
humidity, and pressure differentials between the inside and outside of the
hive. Our approach employs quantized decision tree inference on a commercial
STM32 microcontroller, enabling real-time, low-power edge computing without
compromising accuracy. We show that our system achieves over 99% queen
detection accuracy using only environmental inputs, with audio features
offering no significant performance gain. This work presents a scalable and
sustainable solution for non-invasive hive monitoring, paving the way for
autonomous, precision beekeeping using off-the-shelf, energy-efficient
hardware.

</details>


### [149] [Online Bayesian Risk-Averse Reinforcement Learning](https://arxiv.org/abs/2509.14077)
*Yuhao Wang,Enlu Zhou*

Main category: cs.LG

TL;DR: 本文研究强化学习中的贝叶斯风险规避方法，通过BRMDP处理模型参数不确定性，证明了贝叶斯风险价值函数与真实价值函数之间的渐近正态性差异，并在线性RL和CMAB中实现了次线性遗憾界。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中由于数据不足导致的认知不确定性，采用贝叶斯风险方法来处理未知基础模型的参数不确定性。

Method: 采用贝叶斯风险马尔可夫决策过程(BRMDP)，推导贝叶斯风险价值函数与真实价值函数的渐近正态性关系，使用后验采样方法处理在线RL和CMAB问题。

Result: 贝叶斯风险规避方法会悲观地低估原始价值函数，这种差异随风险规避强度增加而增大，随数据量增加而减小。在在线RL和CMAB中实现了次线性遗憾界。

Conclusion: 提出的算法能有效处理认知不确定性，数值实验验证了理论性质，贝叶斯风险方法在数据稀缺时提供保守但安全的决策策略。

Abstract: In this paper, we study the Bayesian risk-averse formulation in reinforcement
learning (RL). To address the epistemic uncertainty due to a lack of data, we
adopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the
parameter uncertainty of the unknown underlying model. We derive the asymptotic
normality that characterizes the difference between the Bayesian risk value
function and the original value function under the true unknown distribution.
The results indicate that the Bayesian risk-averse approach tends to
pessimistically underestimate the original value function. This discrepancy
increases with stronger risk aversion and decreases as more data become
available. We then utilize this adaptive property in the setting of online RL
as well as online contextual multi-arm bandits (CMAB), a special case of online
RL. We provide two procedures using posterior sampling for both the general RL
problem and the CMAB problem. We establish a sub-linear regret bound, with the
regret defined as the conventional regret for both the RL and CMAB settings.
Additionally, we establish a sub-linear regret bound for the CMAB setting with
the regret defined as the Bayesian risk regret. Finally, we conduct numerical
experiments to demonstrate the effectiveness of the proposed algorithm in
addressing epistemic uncertainty and verifying the theoretical properties.

</details>


### [150] [Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques](https://arxiv.org/abs/2509.14078)
*Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov*

Main category: cs.LG

TL;DR: 该研究比较了不同优化器和神经网络架构在EEG频段分类中的性能，发现Adagrad和RMSprop优化器表现最佳，CNN在空间特征提取方面表现优异，SHAP分析揭示了EEG频段对分类准确性的贡献。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索不同优化器和神经网络架构在EEG频段分类任务中的性能差异，以及如何有效预测左右半球的分类，以提高神经影像分类任务的准确性和可解释性。

Method: 使用TensorFlow和PyTorch框架实现了三种神经网络架构：深度密集网络、浅层三层网络和卷积神经网络(CNN)，并比较了多种优化器（Adagrad、RMSprop、Adadelta、SGD、FTRL）在不同EEG频段的性能，采用SHAP进行特征重要性分析。

Result: Adagrad和RMSprop优化器在不同频段表现稳定，Adagrad在beta频段表现最佳，RMSprop在gamma频段表现最优。CNN获得第二高准确率，深度密集网络在学习复杂模式方面有竞争力，浅层网络计算效率高但准确率较低。SHAP分析揭示了EEG频段对模型准确性的细微贡献。

Conclusion: 优化器选择、模型架构和EEG频段分析对提高分类器性能至关重要，研究为神经影像分类任务提供了重要的优化策略和特征重要性理解。

Abstract: This study investigates classifier performance across EEG frequency bands
using various optimizers and evaluates efficient class prediction for the left
and right hemispheres. Three neural network architectures - a deep dense
network, a shallow three-layer network, and a convolutional neural network
(CNN) - are implemented and compared using the TensorFlow and PyTorch
frameworks. Results indicate that the Adagrad and RMSprop optimizers
consistently perform well across different frequency bands, with Adadelta
exhibiting robust performance in cross-model evaluations. Specifically, Adagrad
excels in the beta band, while RMSprop achieves superior performance in the
gamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among
the models, the CNN demonstrates the second highest accuracy, particularly in
capturing spatial features of EEG data. The deep dense network shows
competitive performance in learning complex patterns, whereas the shallow
three-layer network, sometimes being less accurate, provides computational
efficiency. SHAP (Shapley Additive Explanations) plots are employed to identify
efficient class prediction, revealing nuanced contributions of EEG frequency
bands to model accuracy. Overall, the study highlights the importance of
optimizer selection, model architecture, and EEG frequency band analysis in
enhancing classifier performance and understanding feature importance in
neuroimaging-based classification tasks.

</details>


### [151] [From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting](https://arxiv.org/abs/2509.14113)
*Alessandro Brusaferri,Danial Ramin,Andrea Ballarino*

Main category: cs.LG

TL;DR: 提出了Quantile Neural Basis Model，将分位数广义可加模型的解释性原理融入神经网络框架，在保持预测性能的同时提供模型行为的可解释性洞察。


<details>
  <summary>Details</summary>
Motivation: 虽然神经网络在多水平概率预测中取得了高精度，但理解特征条件输出的底层机制仍然是一个重大挑战，需要提高模型的可解释性。

Method: 利用共享基分解和权重分解，将Quantile Generalized Additive Models的可解释性原则整合到端到端神经网络训练框架中，避免参数分布假设。

Result: 在日前电价预测任务中验证，预测性能与分布回归和分位数回归神经网络相当，同时通过学习到的从输入特征到输出预测的非线性映射提供有价值的模型行为洞察。

Conclusion: Quantile Neural Basis Model成功地在保持神经网络预测性能的同时，提供了模型可解释性，有助于理解特征条件输出的机制。

Abstract: While neural networks are achieving high predictive accuracy in multi-horizon
probabilistic forecasting, understanding the underlying mechanisms that lead to
feature-conditioned outputs remains a significant challenge for forecasters. In
this work, we take a further step toward addressing this critical issue by
introducing the Quantile Neural Basis Model, which incorporates the
interpretability principles of Quantile Generalized Additive Models into an
end-to-end neural network training framework. To this end, we leverage shared
basis decomposition and weight factorization, complementing Neural Models for
Location, Scale, and Shape by avoiding any parametric distributional
assumptions. We validate our approach on day-ahead electricity price
forecasting, achieving predictive performance comparable to distributional and
quantile regression neural networks, while offering valuable insights into
model behavior through the learned nonlinear mappings from input features to
output predictions across the horizon.

</details>


### [152] [A Compositional Kernel Model for Feature Learning](https://arxiv.org/abs/2509.14158)
*Feng Ruan,Keli Liu,Michael Jordan*

Main category: cs.LG

TL;DR: 该论文研究了一种组合式核岭回归方法，通过坐标重加权进行特征学习，证明了在噪声变量为高斯分布时，全局最小值和驻点都能有效消除噪声坐标。研究发现Laplace等ℓ₁型核能恢复非线性特征，而高斯核只能恢复线性特征。


<details>
  <summary>Details</summary>
Motivation: 研究组合式架构中的特征学习问题，为变量选择提供理论框架，探索不同核函数在特征恢复中的表现差异。

Method: 采用变分问题形式的组合式核岭回归模型，对输入进行坐标重加权，分析全局最小值和驻点的特征选择性能。

Result: 证明当噪声变量为高斯分布时，模型能够恢复相关变量并消除噪声变量；发现ℓ₁型核（如Laplace核）能恢复非线性特征，而高斯核只能恢复线性特征。

Conclusion: 组合式核岭回归为特征学习提供了有效的测试平台，ℓ₁型核在非线性特征恢复方面优于高斯核，为变量选择和特征学习提供了新的理论见解。

Abstract: We study a compositional variant of kernel ridge regression in which the
predictor is applied to a coordinate-wise reweighting of the inputs. Formulated
as a variational problem, this model provides a simple testbed for feature
learning in compositional architectures. From the perspective of variable
selection, we show how relevant variables are recovered while noise variables
are eliminated. We establish guarantees showing that both global minimizers and
stationary points discard noise coordinates when the noise variables are
Gaussian distributed. A central finding is that $\ell_1$-type kernels, such as
the Laplace kernel, succeed in recovering features contributing to nonlinear
effects at stationary points, whereas Gaussian kernels recover only linear
ones.

</details>


### [153] [Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework](https://arxiv.org/abs/2509.14167)
*Md Rezwan Jaher,Abul Mukid Mohammad Mukaddes,A. B. M. Abdul Malek*

Main category: cs.LG

TL;DR: 提出了一个端到端框架，通过稀疏常规数据无创估计青光眼治疗中无法测量的关键参数（小梁网渗透性），解决了缺乏真实数据和计算成本高的逆问题挑战。


<details>
  <summary>Details</summary>
Motivation: 青光眼治疗中关键参数（如小梁网渗透性）无法在体内测量，临床依赖间接替代指标，同时缺乏真实数据和计算密集型模拟阻碍了预测模型的发展。

Method: 采用多阶段人工智能架构功能分离问题，提出PCDS数据生成策略避免大量昂贵模拟，结合贝叶斯引擎量化预测不确定性，将计算时间从数年缩短到数小时。

Result: 无创估计的流出设施与最先进的眼压测量技术高度一致，精度接近直接物理仪器；新推导的渗透性生物标志物在按疾病风险分层临床队列方面表现出高准确性。

Conclusion: 该框架为其他数据稀缺、计算密集型领域的类似逆问题提供了可推广的解决方案蓝图，具有重要的诊断潜力。

Abstract: Many critical healthcare decisions are challenged by the inability to measure
key underlying parameters. Glaucoma, a leading cause of irreversible blindness
driven by elevated intraocular pressure (IOP), provides a stark example. The
primary determinant of IOP, a tissue property called trabecular meshwork
permeability, cannot be measured in vivo, forcing clinicians to depend on
indirect surrogates. This clinical challenge is compounded by a broader
computational one: developing predictive models for such ill-posed inverse
problems is hindered by a lack of ground-truth data and prohibitive cost of
large-scale, high-fidelity simulations. We address both challenges with an
end-to-end framework to noninvasively estimate unmeasurable variables from
sparse, routine data. Our approach combines a multi-stage artificial
intelligence architecture to functionally separate the problem; a novel data
generation strategy we term PCDS that obviates the need for hundreds of
thousands of costly simulations, reducing the effective computational time from
years to hours; and a Bayesian engine to quantify predictive uncertainty. Our
framework deconstructs a single IOP measurement into its fundamental components
from routine inputs only, yielding estimates for the unmeasurable tissue
permeability and a patient's outflow facility. Our noninvasively estimated
outflow facility achieved excellent agreement with state-of-the-art tonography
with precision comparable to direct physical instruments. Furthermore, the
newly derived permeability biomarker demonstrates high accuracy in stratifying
clinical cohorts by disease risk, highlighting its diagnostic potential. More
broadly, our framework establishes a generalizable blueprint for solving
similar inverse problems in other data-scarce, computationally-intensive
domains.

</details>


### [154] [TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits](https://arxiv.org/abs/2509.14169)
*Ziming Wei,Zichen Kong,Yuan Wang,David Z. Pan,Xiyuan Tang*

Main category: cs.LG

TL;DR: TopoSizing是一个端到端框架，通过图算法和LLM代理实现电路理解，并将知识整合到贝叶斯优化中提高效率


<details>
  <summary>Details</summary>
Motivation: 模拟和混合信号电路设计面临高质量数据短缺和领域知识难以嵌入自动化流程的挑战，传统方法缺乏电路理解，学习型方法成本高且需要重新训练

Method: 首先应用图算法将电路组织为层次化设备-模块-阶段表示，然后LLM代理执行假设-验证-精炼循环进行标注，最后将验证的洞察整合到贝叶斯优化中

Result: 框架能够直接从原始网表进行稳健的电路理解，并将知识转化为优化增益

Conclusion: 该方法通过LLM引导的初始采样和停滞触发的信任区域更新，在保持可行性的同时提高了优化效率

Abstract: Analog and mixed-signal circuit design remains challenging due to the
shortage of high-quality data and the difficulty of embedding domain knowledge
into automated flows. Traditional black-box optimization achieves sampling
efficiency but lacks circuit understanding, which often causes evaluations to
be wasted in low-value regions of the design space. In contrast, learning-based
methods embed structural knowledge but are case-specific and costly to retrain.
Recent attempts with large language models show potential, yet they often rely
on manual intervention, limiting generality and transparency. We propose
TopoSizing, an end-to-end framework that performs robust circuit understanding
directly from raw netlists and translates this knowledge into optimization
gains. Our approach first applies graph algorithms to organize circuits into a
hierarchical device-module-stage representation. LLM agents then execute an
iterative hypothesis-verification-refinement loop with built-in consistency
checks, producing explicit annotations. Verified insights are integrated into
Bayesian optimization through LLM-guided initial sampling and
stagnation-triggered trust-region updates, improving efficiency while
preserving feasibility.

</details>


### [155] [TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning](https://arxiv.org/abs/2509.14172)
*Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao*

Main category: cs.LG

TL;DR: TGPO是一个离线强化学习框架，通过树形轨迹表示和过程奖励模型解决Web Agent训练中的信用分配、标注成本和奖励稀疏性问题


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和视觉语言模型的发展，使用大模型作为Web Agent进行自动化网页交互变得重要，但强化学习训练面临信用分配错误、标注成本高和奖励稀疏等挑战

Method: 提出Tree-Guided Preference Optimization (TGPO)框架，包括：1) 树形轨迹表示合并语义相同的状态；2) 过程奖励模型通过子目标进度、冗余检测和动作验证自动生成细粒度奖励；3) 动态权重机制优先处理高影响力决策点

Result: 在Online-Mind2Web和自建的C-WebShop数据集上实验表明，TGPO显著优于现有方法，以更少的冗余步骤实现更高的成功率

Conclusion: TGPO框架有效解决了Web Agent训练中的关键问题，为自动化网页交互提供了更高效的解决方案

Abstract: With the rapid advancement of large language models and vision-language
models, employing large models as Web Agents has become essential for automated
web interaction. However, training Web Agents with reinforcement learning faces
critical challenges including credit assignment misallocation, prohibitively
high annotation costs, and reward sparsity. To address these issues, we propose
Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning
framework that proposes a tree-structured trajectory representation merging
semantically identical states across trajectories to eliminate label conflicts.
Our framework incorporates a Process Reward Model that automatically generates
fine-grained rewards through subgoal progress, redundancy detection, and action
verification. Additionally, a dynamic weighting mechanism prioritizes
high-impact decision points during training. Experiments on Online-Mind2Web and
our self-constructed C-WebShop datasets demonstrate that TGPO significantly
outperforms existing methods, achieving higher success rates with fewer
redundant steps.

</details>


### [156] [Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting](https://arxiv.org/abs/2509.14181)
*Yifan Hu,Jie Yang,Tian Zhou,Peiyuan Liu,Yujin Tang,Rong Jin,Liang Sun*

Main category: cs.LG

TL;DR: TimeAlign是一个轻量级的即插即用框架，通过表示对齐技术解决时间序列预测中输入历史与未来目标之间的分布差异问题，显著提升各种基预测器的性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法很少采用对比学习等表示学习技术，因为其性能优势不明显。作者认为显式的表示对齐可以提供关键信息来弥合输入历史与未来目标之间的分布差距。

Method: TimeAlign通过简单的重构任务学习辅助特征，并将这些特征反馈给任何基预测器。该框架架构无关且计算开销极小。

Result: 在8个基准测试上的广泛实验验证了其优越性能，增益主要来自纠正历史输入与未来输出之间的频率不匹配问题。理论分析表明TimeAlign能有效增加学习表示与预测目标之间的互信息。

Conclusion: TimeAlign可作为现代深度学习时间序列预测系统的通用对齐模块，具有架构无关性和可忽略的计算开销优势。

Abstract: Representation learning techniques like contrastive learning have long been
explored in time series forecasting, mirroring their success in computer vision
and natural language processing. Yet recent state-of-the-art (SOTA) forecasters
seldom adopt these representation approaches because they have shown little
performance advantage. We challenge this view and demonstrate that explicit
representation alignment can supply critical information that bridges the
distributional gap between input histories and future targets. To this end, we
introduce TimeAlign, a lightweight, plug-and-play framework that learns
auxiliary features via a simple reconstruction task and feeds them back to any
base forecaster. Extensive experiments across eight benchmarks verify its
superior performance. Further studies indicate that the gains arises primarily
from correcting frequency mismatches between historical inputs and future
outputs. We also provide a theoretical justification for the effectiveness of
TimeAlign in increasing the mutual information between learned representations
and predicted targets. As it is architecture-agnostic and incurs negligible
overhead, TimeAlign can serve as a general alignment module for modern deep
learning time-series forecasting systems. The code is available at
https://github.com/TROUBADOUR000/TimeAlign.

</details>


### [157] [A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training](https://arxiv.org/abs/2509.14216)
*Johnny R. Zhang,Xiaomei Mi,Gaoyuan Du,Qianyi Sun,Shiqi Wang,Jiaxuan Li,Wenhua Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一个开创性的Banach-Bregman框架，将随机优化从传统的Hilbert空间扩展到更一般的Banach空间，为下一代优化算法提供了统一的理论基础和实践指导。


<details>
  <summary>Details</summary>
Motivation: 现有的随机优化理论主要局限于Hilbert空间，无法有效处理非欧几里得设置，如单纯形上的镜像下降、稀疏学习的Bregman近端方法、信息几何中的自然梯度下降等。需要建立一个更通用的理论框架来统一这些方法。

Method: 提出了基于Bregman几何的统一模板，通过Bregman投影和Bregman-Fejer单调性，涵盖了随机逼近、镜像下降、自然梯度、自适应方法和镜像-近端方法。建立了非Hilbert设置中的超松弛技术（λ>2），并提供了从几乎必然有界性到几何速率的收敛定理。

Result: 在机器学习（UCI基准测试）、深度学习（Transformer训练）、强化学习（actor-critic）和大语言模型（WikiText-2与distilGPT-2）上的实证研究表明，相比经典基线方法，实现了高达20%的更快收敛速度、降低的方差和提升的准确性。

Conclusion: Banach-Bregman几何成为统一优化理论和实践的核心基石，为跨核心AI范式的下一代优化提供了理论基础，展示了在非欧几里得设置中的优越性能。

Abstract: Stochastic optimization powers the scalability of modern artificial
intelligence, spanning machine learning, deep learning, reinforcement learning,
and large language model training. Yet, existing theory remains largely
confined to Hilbert spaces, relying on inner-product frameworks and
orthogonality. This paradigm fails to capture non-Euclidean settings, such as
mirror descent on simplices, Bregman proximal methods for sparse learning,
natural gradient descent in information geometry, or
Kullback--Leibler-regularized language model training. Unlike Euclidean-based
Hilbert-space methods, this approach embraces general Banach spaces. This work
introduces a pioneering Banach--Bregman framework for stochastic iterations,
establishing Bregman geometry as a foundation for next-generation optimization.
It (i) provides a unified template via Bregman projections and Bregman--Fejer
monotonicity, encompassing stochastic approximation, mirror descent, natural
gradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations
($\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and
elucidating their acceleration effect; and (iii) delivers convergence theorems
spanning almost-sure boundedness to geometric rates, validated on synthetic and
real-world tasks. Empirical studies across machine learning (UCI benchmarks),
deep learning (e.g., Transformer training), reinforcement learning
(actor--critic), and large language models (WikiText-2 with distilGPT-2) show
up to 20% faster convergence, reduced variance, and enhanced accuracy over
classical baselines. These results position Banach--Bregman geometry as a
cornerstone unifying optimization theory and practice across core AI paradigms.

</details>


### [158] [Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems](https://arxiv.org/abs/2509.14219)
*Jiaqi Yao,Lewis Mitchell,John Maclean,Hemanth Saratchandran*

Main category: cs.LG

TL;DR: RKTV-INR：一种基于龙格-库塔积分和全变分的隐式神经表示去噪框架，用于非线性动力系统的噪声抑制和方程识别


<details>
  <summary>Details</summary>
Motivation: 非线性动力系统的数据驱动建模常受测量噪声影响，需要有效的去噪方法来准确识别系统动力学方程

Method: 使用隐式神经表示(INR)直接拟合噪声观测数据，通过龙格-库塔积分和全变分约束确保重建状态是动力系统轨迹，然后利用SINDy方法识别控制方程

Result: 实验证明该方法能有效抑制噪声、精确估计导数，并可靠地进行系统识别

Conclusion: RKTV-INR框架为噪声环境下的非线性动力系统建模提供了有效的解决方案，能够同时实现去噪和动力学方程识别

Abstract: Data-driven modeling of nonlinear dynamical systems is often hampered by
measurement noise. We propose a denoising framework, called Runge-Kutta and
Total Variation Based Implicit Neural Representation (RKTV-INR), that
represents the state trajectory with an implicit neural representation (INR)
fitted directly to noisy observations. Runge-Kutta integration and total
variation are imposed as constraints to ensure that the reconstructed state is
a trajectory of a dynamical system that remains close to the original data. The
trained INR yields a clean, continuous trajectory and provides accurate
first-order derivatives via automatic differentiation. These denoised states
and derivatives are then supplied to Sparse Identification of Nonlinear
Dynamics (SINDy) to recover the governing equations. Experiments demonstrate
effective noise suppression, precise derivative estimation, and reliable system
identification.

</details>


### [159] [Language models' activations linearly encode training-order recency](https://arxiv.org/abs/2509.14223)
*Dmitrii Krasheninnikov,Richard E. Turner,David Krueger*

Main category: cs.LG

TL;DR: 语言模型的激活值线性编码了信息在训练过程中被学习的时间顺序，模型能够区分信息获取的时间点


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否以及如何编码信息在训练过程中被学习的时间顺序，这对于理解模型如何处理冲突数据和知识修改具有重要意义

Method: 通过顺序微调Llama-3.2-1B模型在六个不相交但相似的命名实体数据集上，分析模型激活值的线性编码特性，使用线性探测和微调方法验证时间信号的识别能力

Result: 发现测试样本的平均激活值能够准确编码训练顺序（在2D子空间中呈直线排列），线性探测能90%准确区分"早期"和"晚期"实体，微调后模型能80%准确报告未见实体的训练阶段

Conclusion: 语言模型确实能够区分信息获取的时间，这一发现对理解模型如何处理冲突数据和知识更新具有重要启示意义

Abstract: We show that language models' activations linearly encode when information
was learned during training. Our setup involves creating a model with a known
training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but
otherwise similar datasets about named entities. We find that the average
activations of test samples for the six training datasets encode the training
order: when projected into a 2D subspace, these centroids are arranged exactly
in the order of training and lie on a straight line. Further, we show that
linear probes can accurately (~90%) distinguish "early" vs. "late" entities,
generalizing to entities unseen during the probes' own training. The model can
also be fine-tuned to explicitly report an unseen entity's training stage (~80%
accuracy). Interestingly, this temporal signal does not seem attributable to
simple differences in activation magnitudes, losses, or model confidence. Our
paper demonstrates that models are capable of differentiating information by
its acquisition time, and carries significant implications for how they might
manage conflicting data and respond to knowledge modifications.

</details>


### [160] [Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](https://arxiv.org/abs/2509.14225)
*Benjamin Sterling,Yousef El-Laham,Mónica F. Bugallo*

Main category: cs.LG

TL;DR: 本文提出使用临界阻尼高阶朗之万动力学来防御扩散模型中的成员推理攻击，通过在扩散过程中引入辅助变量来混合外部随机性，从而保护训练数据的隐私。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI应用的快速发展，数据安全问题日益突出。扩散模型虽然相比其他生成模型对成员推理攻击更具抵抗力，但仍然存在被攻击的风险，需要有效的防御机制来保护训练数据的隐私。

Method: 采用临界阻尼高阶朗之万动力学，引入多个辅助变量和联合扩散过程。通过辅助变量混合外部随机性，在扩散过程早期破坏敏感输入数据，从而防御成员推理攻击。

Result: 在玩具数据集和语音数据集上进行了理论分析和实验验证，使用AUROC曲线和FID指标评估防御效果，证明了该方法的有效性。

Conclusion: 提出的临界阻尼高阶朗之万动力学方法能够有效防御扩散模型的成员推理攻击，通过引入辅助变量和联合扩散过程增强了数据隐私保护能力。

Abstract: Recent advances in generative artificial intelligence applications have
raised new data security concerns. This paper focuses on defending diffusion
models against membership inference attacks. This type of attack occurs when
the attacker can determine if a certain data point was used to train the model.
Although diffusion models are intrinsically more resistant to membership
inference attacks than other generative models, they are still susceptible. The
defense proposed here utilizes critically-damped higher-order Langevin
dynamics, which introduces several auxiliary variables and a joint diffusion
process along these variables. The idea is that the presence of auxiliary
variables mixes external randomness that helps to corrupt sensitive input data
earlier on in the diffusion process. This concept is theoretically investigated
and validated on a toy dataset and a speech dataset using the Area Under the
Receiver Operating Characteristic (AUROC) curves and the FID metric.

</details>


### [161] [NIRVANA: Structured pruning reimagined for large language models compression](https://arxiv.org/abs/2509.14230)
*Mengting Ai,Tianxin Wei,Sirui Chen,Jingrui He*

Main category: cs.LG

TL;DR: NIRVANA是一种新颖的结构化剪枝方法，通过神经网络切核理论和自适应稀疏分配机制，在保持零样本准确性的同时实现高效LLM压缩。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法在零样本设置下性能下降严重，需要昂贵的恢复技术如监督微调或适配器插入，需要一种能平衡即时准确性和微调能力的剪枝方法。

Method: 基于Adam优化动态下的神经网络切核理论推导一阶显著性准则，采用跨层和模块的自适应稀疏分配机制，并使用KL散度进行校准数据选择。

Result: 在Llama3、Qwen和T5模型上的实验表明，NIRVANA在同等稀疏度约束下优于现有结构化剪枝方法。

Conclusion: NIRVANA提供了一种理论上有依据且实用的LLM压缩方法，在保持零样本性能的同时实现了高效的结构化剪枝。

Abstract: Structured pruning of large language models (LLMs) offers substantial
efficiency improvements by removing entire hidden units, yet current approaches
often suffer from significant performance degradation, particularly in
zero-shot settings, and necessitate costly recovery techniques such as
supervised fine-tuning (SFT) or adapter insertion. To address these critical
shortcomings, we introduce NIRVANA, a novel pruning method explicitly designed
to balance immediate zero-shot accuracy preservation with robust fine-tuning
capability. Leveraging a first-order saliency criterion derived from the Neural
Tangent Kernel under Adam optimization dynamics, NIRVANA provides a
theoretically grounded pruning strategy that respects essential model training
behaviors. To further address the unique challenges posed by structured
pruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across
layers and modules (attention vs. MLP), which adjusts pruning intensity between
modules in a globally balanced manner. Additionally, to mitigate the high
sensitivity of pruning decisions to calibration data quality, we propose a
simple yet effective KL divergence-based calibration data selection strategy,
ensuring more reliable and task-agnostic pruning outcomes. Comprehensive
experiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA
outperforms existing structured pruning methods under equivalent sparsity
constraints, providing a theoretically sound and practical approach to LLM
compression. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.

</details>


### [162] [Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision](https://arxiv.org/abs/2509.14234)
*Dulhan Jayalath,Shashwat Goel,Thomas Foster,Parag Jain,Suchin Gururangan,Cheng Zhang,Anirudh Goyal,Alan Schelten*

Main category: cs.LG

TL;DR: Compute as Teacher (CaT) 通过将推理时的探索转化为无参考监督，使用模型自身的并行rollout生成参考信号，在无真实标签的后训练中提供学习信号。


<details>
  <summary>Details</summary>
Motivation: 解决后训练阶段缺乏真实标签时学习信号的来源问题，探索如何将推理时的计算资源转化为有效的监督信号。

Method: 通过并行rollout生成多个输出，使用冻结的初始策略协调冲突和遗漏来合成单一参考，然后将其转化为奖励信号。在可验证任务中使用程序等价性，在不可验证任务中使用自提议的评分标准由独立LLM评判。

Result: 在Gemma 3 4B、Qwen 3 4B和Llama 3.1 8B上显著提升性能（MATH-500上最高+27%，HealthBench上+12%）。结合强化学习（CaT-RL）后获得进一步增益（最高+33%和+30%），训练后的策略超过了初始教师信号。

Conclusion: CaT成功地将推理时计算转化为有效的监督信号，在无真实标签的后训练中提供了可扩展的学习方法，性能随rollout数量提升，且合成方法优于传统选择方法。

Abstract: Where do learning signals come from when there is no ground truth in
post-training? We propose turning exploration into supervision through Compute
as Teacher (CaT), which converts the model's own exploration at inference-time
into reference-free supervision by synthesizing a single reference from a group
of parallel rollouts and then optimizing toward it. Concretely, the current
policy produces a group of rollouts; a frozen anchor (the initial policy)
reconciles omissions and contradictions to estimate a reference, turning extra
inference-time compute into a teacher signal. We turn this into rewards in two
regimes: (i) verifiable tasks use programmatic equivalence on final answers;
(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria
scored by an independent LLM judge, with reward given by the fraction
satisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge
scores), synthesis may disagree with the majority and be correct even when all
rollouts are wrong; performance scales with the number of rollouts. As a
test-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up
to +27% on MATH-500; +12% on HealthBench). With reinforcement learning
(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained
policy surpassing the initial teacher signal.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [163] [Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness](https://arxiv.org/abs/2509.13332)
*Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi*

Main category: cs.AI

TL;DR: 本研究系统比较了思考型和非思考型LLM在作为评判者时的表现，发现思考型模型在准确率、计算效率和鲁棒性方面均优于非思考型模型，即使经过多种增强策略改进后。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地被用作自动化评判者，确保其可靠性、效率和鲁棒性变得至关重要。本研究旨在系统比较思考型和非思考型LLM在评判任务中的表现差异。

Method: 使用开源Qwen 3模型（0.6B、1.7B和4B参数），在RewardBench任务上评估准确性和计算效率（FLOPs），并测试了多种增强策略：上下文学习、规则引导评判、基于参考的评估和n-best聚合。

Result: 思考型模型准确率高出约10个百分点，计算开销仅增加不到2倍；而增强策略如少样本学习虽然带来适度提升但成本更高（>8倍）。在多种偏见条件下，思考型模型保持显著更高的一致性（平均高6%）。多语言实验也证实了显式推理的优势。

Conclusion: 显式推理在LLM作为评判者的范式中具有明显优势，不仅在准确性和效率方面，而且在鲁棒性方面都表现出色，为LLM评判系统的设计提供了重要指导。

Abstract: As Large Language Models (LLMs) are increasingly adopted as automated judges
in benchmarking and reward modeling, ensuring their reliability, efficiency,
and robustness has become critical. In this work, we present a systematic
comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm
using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B
parameters). We evaluate both accuracy and computational efficiency (FLOPs) on
RewardBench tasks, and further examine augmentation strategies for non-thinking
models, including in-context learning, rubric-guided judging, reference-based
evaluation, and n-best aggregation. Our results show that despite these
enhancements, non-thinking models generally fall short of their thinking
counterparts. Our results show that thinking models achieve approximately 10%
points higher accuracy with little overhead (under 2x), in contrast to
augmentation strategies like few-shot learning, which deliver modest gains at a
higher cost (>8x). Bias and robustness analyses further demonstrate that
thinking models maintain significantly greater consistency under a variety of
bias conditions such as positional, bandwagon, identity, diversity, and random
biases (6% higher on average). We further extend our experiments to the
multilingual setting and our results confirm that explicit reasoning extends
its benefits beyond English. Overall, our work results in several important
findings that provide systematic evidence that explicit reasoning offers clear
advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency
but also in robustness.

</details>


### [164] [Evaluation Awareness Scales Predictably in Open-Weights Large Language Models](https://arxiv.org/abs/2509.13333)
*Maheep Chaudhary,Ian Su,Nikhil Hooda,Nishith Shankar,Julia Tan,Kevin Zhu,Ashwinee Panda,Ryan Lagasse,Vasu Sharma*

Main category: cs.AI

TL;DR: 研究发现大型语言模型存在评估意识行为，即模型能够区分评估和部署环境，这种能力随模型规模呈幂律增长，可能影响AI安全评估的有效性。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明大型语言模型在评估环境中会隐藏危险能力，但不同规模模型的评估意识变化规律尚不清楚，需要研究模型规模与评估意识之间的缩放关系。

Method: 使用线性探测方法分析15个不同规模模型（0.27B到70B参数）在转向向量激活上的表现，研究评估意识的缩放规律。

Result: 发现评估意识随模型规模呈幂律增长，这种可预测的缩放规律可用于预测未来更大模型的欺骗行为。

Conclusion: 该缩放定律为设计针对不同规模模型的AI安全评估策略提供了指导，有助于更好地评估未来大型模型的安全性。

Abstract: Large language models (LLMs) can internally distinguish between evaluation
and deployment contexts, a behaviour known as \emph{evaluation awareness}. This
undermines AI safety evaluations, as models may conceal dangerous capabilities
during testing. Prior work demonstrated this in a single $70$B model, but the
scaling relationship across model sizes remains unknown. We investigate
evaluation awareness across $15$ models scaling from $0.27$B to $70$B
parameters from four families using linear probing on steering vector
activations. Our results reveal a clear power-law scaling: evaluation awareness
increases predictably with model size. This scaling law enables forecasting
deceptive behavior in future larger models and guides the design of scale-aware
evaluation strategies for AI safety. A link to the implementation of this paper
can be found at
https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.

</details>


### [165] [FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness](https://arxiv.org/abs/2509.13334)
*Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary*

Main category: cs.AI

TL;DR: FRIT是一种通过干预训练提升大语言模型推理忠实性的对齐方法，通过生成忠实/不忠实推理对并应用直接偏好优化，使模型偏好因果一致的推理路径


<details>
  <summary>Details</summary>
Motivation: 现有链式推理方法中推理步骤往往无法因果影响最终答案，导致输出脆弱不可信，而系统性提升推理忠实性的方法有限

Method: 通过干预模型生成的推理步骤创建合成训练数据，生成忠实/不忠实推理对，然后应用直接偏好优化训练模型

Result: 在Qwen3-8B和Mistral-7B-v0.1上，FRIT将Mistral在GSM8K上的忠实推理提升3.4个百分点，准确率提升7.6个百分点

Conclusion: FRIT提供了首个可扩展、无监督的方法来训练语言模型产生更可靠和可解释的推理，解决了推理性能与可信度之间的关键差距

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving
large language model performance on complex tasks, but recent work shows that
reasoning steps often fail to causally influence the final answer, creating
brittle and untrustworthy outputs. Prior approaches focus primarily on
measuring faithfulness, while methods for systematically improving it remain
limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a
scalable alignment method that trains models to produce causally consistent
reasoning by learning from systematically corrupted examples. FRIT generates
synthetic training data by intervening on individual reasoning steps in
model-generated CoTs, creating faithful/unfaithful pairs that highlight when
reasoning breaks down. We then apply Direct Preference Optimization to teach
models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B
and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases
faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while
improving accuracy by $7.6$ percentage points. Our approach provides the first
scalable, supervision-free method for training language models to produce more
reliable and interpretable reasoning, addressing a critical gap between
reasoning performance and trustworthiness. We release our code at
\href{https://github.com/Anut-py/frit}.

</details>


### [166] [Position: AI Safety Must Embrace an Antifragile Perspective](https://arxiv.org/abs/2509.13339)
*Ming Jin,Hyunin Lee*

Main category: cs.AI

TL;DR: 本文主张AI安全研究应采用抗脆弱性视角，通过持续挑战和不确定性来增强系统处理罕见事件和长期安全的能力，而非依赖静态测试。


<details>
  <summary>Details</summary>
Motivation: 传统静态基准测试和一次性鲁棒性测试无法应对环境演变和模型漂移问题（如奖励黑客攻击、过度优化等），需要建立能够随时间扩展安全能力的系统。

Method: 提出抗脆弱性方法框架，强调利用不确定性为未来更大不确定性做准备，包括识别静态测试局限、探索抗脆弱解决方案、重新校准AI安全测量和基准方法。

Result: 建立了抗脆弱性AI安全的理论基础，提供了管理罕见事件的潜在解决方案，并提出了长期改进AI安全的伦理和实践指南。

Conclusion: 抗脆弱性方法是确保开放式机器学习系统长期可靠性的关键，需要建立抗脆弱性AI安全社区来补充现有鲁棒性方法。

Abstract: This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.

</details>


### [167] [MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](https://arxiv.org/abs/2509.13773)
*Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong*

Main category: cs.AI

TL;DR: MIRA是一个智能手机AI任务指令推荐框架，通过长按图像或文本提供上下文相关的AI任务建议，使用多模态大语言模型和结构化推理来提升推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的快速发展，智能手机需要更直观的方式来访问预定义的AI服务，简化用户与设备的交互。

Method: 采用多模态大语言模型(MLLM)推荐管道进行结构化推理，结合模板增强推理机制和前缀树约束解码策略，确保输出与预定义指令候选集一致。

Result: 在真实标注数据集和用户研究中，MIRA显著提高了指令推荐的准确性。

Conclusion: MIRA有潜力彻底改变用户在智能手机上与AI服务的交互方式，提供更无缝高效的体验。

Abstract: The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

</details>


### [168] [Imagined Autocurricula](https://arxiv.org/abs/2509.13341)
*Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.AI

TL;DR: 利用世界模型生成想象环境训练智能体，通过IMAC（想象自动课程）方法实现无监督环境设计，在程序生成环境中实现强泛化性能


<details>
  <summary>Details</summary>
Motivation: 传统智能体训练需要大量训练数据或精确模拟，但现实世界中很多情况缺乏这些资源。世界模型利用离线被动收集数据生成多样化训练环境，但需要确保生成的数据对训练有用

Method: 提出IMAC（Imagined Autocurricula）方法，基于无监督环境设计（UED）在生成的世界中诱导自动课程，利用世界模型生成想象环境来训练智能体

Result: 在一系列具有挑战性的程序生成环境中，仅使用从较窄数据集学习的世界模型进行训练，就能在保留环境中实现强大的迁移性能

Conclusion: 这项工作为利用更大规模的基础世界模型来训练具有通用能力的智能体开辟了道路

Abstract: Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.

</details>


### [169] [OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](https://arxiv.org/abs/2509.13347)
*Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang*

Main category: cs.AI

TL;DR: 本文系统比较了Minecraft中不同动作空间的性能，发现最优动作空间高度依赖任务，提出了Chain of Action (CoA)框架统一高层规划和底层控制，通过混合动作空间训练实现了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决动作空间选择这一关键但未解决的挑战，因为研究发现没有单一动作空间在所有任务中都最优，这给构建通用智能体带来了困境。

Method: 提出Chain of Action (CoA)框架，将抽象动作视为中间推理步骤而非单独策略的命令，在单一VLA模型中统一高层规划和底层控制，并使用混合动作空间进行训练。

Result: CoA框架训练的All-in-One智能体实现了新的state-of-the-art性能，相比专门的基线模型提高了整体任务成功率，学习到了更鲁棒和可泛化的策略。

Conclusion: CoA框架成功解决了动作空间选择的困境，通过统一规划和控制实现了更好的性能，同时发布了OpenHA套件促进可重复研究。

Abstract: The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA

</details>


### [170] [Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning](https://arxiv.org/abs/2509.13351)
*Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah*

Main category: cs.AI

TL;DR: 提出了PDDL-Instruct指令调优框架，通过逻辑思维链推理增强大语言模型的符号规划能力，在标准基准测试中达到94%的规划准确率，相比基线模型提升66%


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多样化任务中表现出色，但在需要形式化表示（如PDDL）的结构化符号规划方面能力有限，需要弥合通用推理能力与自动规划所需逻辑精度之间的差距

Method: 开发指令提示引导模型通过精确的逻辑推理步骤，严格推理动作适用性、状态转换和计划有效性，将规划过程分解为关于前提条件满足、效果应用和不变性保持的显式推理链

Result: 在多个规划领域的实验结果显示，基于思维链推理的指令调优模型规划能力显著提升，在标准基准测试中达到94%的规划准确率，相比基线模型绝对提升66%

Conclusion: 该工作为大语言模型与自动规划之间的能力差距提供了桥梁，为开发更好的AI规划系统提供了有前景的方向

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, yet their ability to perform structured symbolic planning
remains limited, particularly in domains requiring formal representations like
the Planning Domain Definition Language (PDDL). In this paper, we present a
novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'
symbolic planning capabilities through logical chain-of-thought reasoning. Our
approach focuses on teaching models to rigorously reason about action
applicability, state transitions, and plan validity using explicit logical
inference steps. By developing instruction prompts that guide models through
the precise logical reasoning required to determine when actions can be applied
in a given state, we enable LLMs to self-correct their planning processes
through structured reflection. The framework systematically builds verification
skills by decomposing the planning process into explicit reasoning chains about
precondition satisfaction, effect application, and invariant preservation.
Experimental results on multiple planning domains show that our
chain-of-thought reasoning based instruction-tuned models are significantly
better at planning, achieving planning accuracy of up to 94% on standard
benchmarks, representing a 66% absolute improvement over baseline models. This
work bridges the gap between the general reasoning capabilities of LLMs and the
logical precision required for automated planning, offering a promising
direction for developing better AI planning systems.

</details>


### [171] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

TL;DR: 提出了Agentic UAVs框架，通过五层架构（感知、推理、行动、集成、学习）将LLM驱动的推理能力集成到无人机中，在模拟搜救场景中显著提升了检测置信度、人员检测率和行动推荐能力


<details>
  <summary>Details</summary>
Motivation: 当前无人机系统大多局限于SAE 2-3级自主性，依赖基于规则的控制和窄AI，在动态不确定任务中缺乏适应性。现有框架缺乏上下文感知推理、自主决策和生态系统级集成，特别是没有利用LLM代理进行实时知识访问

Method: 开发了五层架构的Agentic UAVs框架，集成了ROS2和Gazebo原型，结合YOLOv11目标检测与GPT-4推理，以及本地Gemma-3部署，实现LLM驱动的推理、数据库查询和第三方系统交互

Result: 在模拟搜救场景中，智能无人机实现了更高的检测置信度（0.79 vs 0.72）、改善的人员检测率（91% vs 75%）和显著增加的行动推荐（92% vs 4.5%）

Conclusion: 适度的计算开销能够实现质变性的自主性新水平和生态系统集成，证明了LLM驱动的无人机框架的有效性和实用性

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


### [172] [Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling](https://arxiv.org/abs/2509.13357)
*Yongchao Huang,Hassan Raza*

Main category: cs.AI

TL;DR: 提出语义融合方案，通过并行模糊成员特征通道增强Transformer语言模型，实现可解释的语义特征编码和可控生成


<details>
  <summary>Details</summary>
Motivation: 增强语言模型的语义理解能力，提供可解释的特征表示和用户可控的生成方式，同时保持模型轻量化和兼容性

Method: 为每个token构建包含词性、浅层角色、边界标志、情感极性等可解释特征的向量，使用可微分成员函数生成分级特征值，通过门控适配器将语义矩阵融合到语言模型中，采用标准的下一个token预测、语义特征重构辅助损失和形容词分布正则化进行训练

Result: 在合成双子句语料库上，语义融合提高了困惑度，实现了精确的用户可控极性和标点生成，同时保持模型简洁性

Conclusion: 该方法以较小开销实现了可解释的条件自然语言生成路径，完全兼容输入输出嵌入绑定，为可控文本生成提供了有效方案

Abstract: We propose semantic fusion, a lightweight scheme that augments a Transformer
language model (LM) with a parallel, fuzzy-membership feature channel that
encodes token-level semantics. Each token is represented by a vector of
interpretable features (e.g. part-of-speech cues, shallow roles, boundary
flags, sentiment polarity and strength) whose values are graded degrees from
differentiable membership functions (e.g. power kernels). These per-token
vectors form a sentence-level semantic matrix fused via a gated adapter into
the LM. Training uses standard next-token prediction, an auxiliary loss that
reconstructs the semantic features from hidden states, and a lightweight
uniformizer that regularizes adjective-class distributions. On a synthetic
two-clause corpus with held-out adjectives for out-of-distribution (OOD)
control, semantic fusion improves perplexity and enables precise,
user-controllable generation of polarity and punctuation while maintaining
model simplicity. This approach adds only small overhead, remains fully
compatible with tied input-output embeddings, and provides an interpretable
pathway for conditioned natural language generation.

</details>


### [173] [Asterisk Operator](https://arxiv.org/abs/2509.13364)
*Zixi Li*

Main category: cs.AI

TL;DR: 提出了Asterisk算子（*算子），这是一个基于邻接结构并行传播（ASPP）的统一抽象推理框架，将结构化推理任务形式化为由隐式关系图指导的局部并行状态演化过程。


<details>
  <summary>Details</summary>
Motivation: 为了解决抽象推理问题，需要一种既能保持局部计算约束又能实现全局推理能力的统一框架，以提供高效且收敛的计算范式。

Method: 基于邻接结构并行传播（ASPP）的Asterisk算子，通过局部并行状态演化过程进行推理，并提出了创新的Embedding-Asterisk蒸馏方法。

Result: 在ARC2挑战和康威生命游戏中验证了算子的普适性、收敛性和优越性能，使用仅6M参数在ARC2验证集上达到100%准确率。

Conclusion: Asterisk算子代表了神经符号推理领域的重大突破，提供了一个高效、收敛且通用的抽象推理框架。

Abstract: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified
framework for abstract reasoning based on Adjacency-Structured Parallel
Propagation (ASPP). The operator formalizes structured reasoning tasks as
local, parallel state evolution processes guided by implicit relational graphs.
We prove that the $\ast$-operator maintains local computational constraints
while achieving global reasoning capabilities, providing an efficient and
convergent computational paradigm for abstract reasoning problems. Through
rigorous mathematical analysis and comprehensive experiments on ARC2 challenges
and Conway's Game of Life, we demonstrate the operator's universality,
convergence properties, and superior performance. Our innovative
Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2
validation with only 6M parameters, representing a significant breakthrough in
neural-symbolic reasoning.
  \textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel
Propagation, Asterisk Operator, Convergence, Universal Approximation

</details>


### [174] [$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation](https://arxiv.org/abs/2509.13368)
*Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li*

Main category: cs.AI

TL;DR: Agent²是一个完全自动化的强化学习代理生成框架，通过LLM驱动将自然语言任务描述转换为高性能RL解决方案，无需人工干预，在多个基准测试中表现优于人工设计的方案。


<details>
  <summary>Details</summary>
Motivation: 传统RL代理开发需要大量专业知识和迭代周期，失败率高且可访问性有限。为了解决这些问题，需要实现完全自动化的RL代理设计。

Method: 采用双代理架构：生成器代理作为自主AI设计器分析任务并生成可执行RL代理，目标代理是自动生成的RL代理。框架将RL开发分解为MDP建模和算法优化两个阶段，基于模型上下文协议构建。

Result: 在MuJoCo、MetaDrive、MPE和SMAC等多个基准测试中，Agent²始终优于人工设计的解决方案，性能提升高达55%，平均性能也有显著提升。

Conclusion: 这项工作建立了智能代理设计和优化其他代理的新范式，实现了真正端到端的闭环自动化，是自动化AI系统的根本性突破。

Abstract: Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.

</details>


### [175] [The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs](https://arxiv.org/abs/2509.13379)
*Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez*

Main category: cs.AI

TL;DR: 对16个最先进的视觉语言模型在6个多模态数据集上进行全面的不确定性基准测试，发现大模型具有更好的不确定性量化能力，数学和推理任务的不确定性表现较差


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在复杂视觉理解方面取得了显著进展，但不确定性量化这一关键维度未得到足够关注，需要对此进行系统评估

Method: 评估16个最先进的VLMs（开源和闭源）在6个多模态数据集上使用3种不同的评分函数进行不确定性基准测试

Result: 大模型始终表现出更好的不确定性量化能力；更确定的模型获得更高准确率；数学和推理任务在所有模型中相比其他领域表现出更差的不确定性性能

Conclusion: 这项工作为多模态系统中可靠的不确定性评估奠定了基础

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex
visual understanding across scientific and reasoning tasks. While performance
benchmarking has advanced our understanding of these capabilities, the critical
dimension of uncertainty quantification has received insufficient attention.
Therefore, unlike prior conformal prediction studies that focused on limited
settings, we conduct a comprehensive uncertainty benchmarking study, evaluating
16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets
with 3 distinct scoring functions. Our findings demonstrate that larger models
consistently exhibit better uncertainty quantification; models that know more
also know better what they don't know. More certain models achieve higher
accuracy, while mathematical and reasoning tasks elicit poorer uncertainty
performance across all models compared to other domains. This work establishes
a foundation for reliable uncertainty evaluation in multimodal systems.

</details>


### [176] [From Next Token Prediction to (STRIPS) World Models -- Preliminary Results](https://arxiv.org/abs/2509.13389)
*Carlos Núñez-Molina,Vicenç Gómez,Hector Geffner*

Main category: cs.AI

TL;DR: 使用Transformer架构从动作轨迹中学习命题STRIPS世界模型，通过监督式的下一个动作预测任务，能够准确表示和推断动作前提条件与隐藏效果。


<details>
  <summary>Details</summary>
Motivation: 从纯动作轨迹中学习世界模型是一个重要但具有挑战性的问题，传统方法需要完整的状态信息，而本文旨在仅通过动作序列就能学习出准确的世界模型表示。

Method: 将任务构建为监督式的下一个token预测问题，使用Transformer架构，通过正负样本（有效和无效动作序列）进行训练，学习动作前提条件和隐藏效果的表示。

Result: 实验表明，合适的Transformer架构能够忠实表示命题STRIPS世界模型，仅通过随机有效和无效动作序列就能成功学习到准确的世界模型。

Conclusion: 深度学习方法（特别是Transformer）能够有效从动作轨迹中学习世界模型，为仅通过观察行为就能理解环境动态提供了可行的解决方案。

Abstract: We consider the problem of learning propositional STRIPS world models from
action traces alone, using a deep learning architecture (transformers) and
gradient descent. The task is cast as a supervised next token prediction
problem where the tokens are the actions, and an action $a$ may follow an
action sequence if the hidden effects of the previous actions do not make an
action precondition of $a$ false. We show that a suitable transformer
architecture can faithfully represent propositional STRIPS world models, and
that the models can be learned from sets of random valid (positive) and invalid
(negative) action sequences alone. A number of experiments are reported.

</details>


### [177] [SteeringControl: Holistic Evaluation of Alignment Steering in LLMs](https://arxiv.org/abs/2509.13450)
*Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: SteeringControl是一个评估表示引导方法的基准，重点关注偏见、有害生成和幻觉等核心对齐目标，以及这些方法对次要行为（如奉承和常识道德）的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐工作通常只关注真实性或推理能力来展示表示引导的副作用，但许多权衡关系尚未被系统性地理解。

Method: 构建了一个模块化的引导框架，基于独特组件作为现有方法的构建块，收集了安全相关的主要和次要行为数据集，评估了五种流行引导方法的有效性。

Result: 在Qwen-2.5-7B和Llama-3.1-8B上的结果显示，强引导性能取决于引导方法、模型和目标行为的特定组合，不良组合可能导致严重的概念纠缠。

Conclusion: 表示引导的效果具有高度依赖性，需要仔细选择方法、模型和目标行为的组合，以避免意外的负面副作用。

Abstract: We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.

</details>


### [178] [AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving](https://arxiv.org/abs/2509.13547)
*Harper Reed,Michael Sugimura,Angelo Zangari*

Main category: cs.AI

TL;DR: 为LLM智能体提供类似人类的协作工具和自主性可以显著提升其在最困难编程问题上的性能表现，成本降低15-40%，回合数减少12-27%，完成速度提升12-38%。


<details>
  <summary>Details</summary>
Motivation: 研究是否通过赋予LLM智能体人类自然使用的协作工具和自主性，能够改善其问题解决性能。

Method: 为Claude Code智能体配备基于MCP的社交媒体和日志工具，允许它们自主使用这些工具来解决34个Aider多语言Python编程挑战。

Result: 协作工具显著提升了最困难问题的性能表现，不同模型自然采用了不同的协作策略，智能体表现出偏好书写而非阅读（2-9倍），结构化表达是改进的主要驱动力。

Conclusion: AI智能体在其能力边界处可以从人类启发的协作工具中系统性获益，这表明自适应协作界面可以作为推理增强器而非通用效率提升工具。

Abstract: We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.

</details>


### [179] [Gen AI in Proof-based Math Courses: A Pilot Study](https://arxiv.org/abs/2509.13570)
*Hannah Klawa,Shraddha Rajpal,Cigole Thomas*

Main category: cs.AI

TL;DR: 本研究调查了本科生在证明数学课程中使用生成式AI的情况，发现学生主要在概念理解、证明思路和错误检查方面使用AI，但认识到其在复杂推理和创造性证明方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在高等教育中的快速崛起和现有AI检测工具的不可靠性，制定能够促进学生学习和批判性思维的政策变得日益重要。

Method: 通过调查问卷和学生访谈，分析三个证明数学课程（抽象代数、拓扑学）中学生使用AI工具的方式、对AI有用性和局限性的认知。

Result: 学生主要在概念理解、证明思路生成和错误检查方面使用AI，但认识到AI在复杂数学推理、创造性证明和深度理解方面的局限性。

Conclusion: 需要制定平衡的AI使用政策，既要利用AI辅助学习的优势，又要培养学生的批判性思维和数学创造力，为证明数学教学中的AI整合提供未来考量。

Abstract: With the rapid rise of generative AI in higher education and the
unreliability of current AI detection tools, developing policies that encourage
student learning and critical thinking has become increasingly important. This
study examines student use and perceptions of generative AI across three
proof-based undergraduate mathematics courses: a first-semester abstract
algebra course, a topology course and a second-semester abstract algebra
course. In each case, course policy permitted some use of generative AI.
Drawing on survey responses and student interviews, we analyze how students
engaged with AI tools, their perceptions of generative AI's usefulness and
limitations, and what implications these perceptions hold for teaching
proof-based mathematics. We conclude by discussing future considerations for
integrating generative AI into proof-based mathematics instruction.

</details>


### [180] [Programmable Cognitive Bias in Social Agents](https://arxiv.org/abs/2509.13588)
*Xuan Liu,Haoyang Shang,Haojian Jin*

Main category: cs.AI

TL;DR: CoBRA是一个用于在基于LLM的社会模拟中系统化指定智能体行为的工具包，通过显式编程认知偏见来解决传统自然语言描述方法的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过隐式自然语言描述指定智能体行为存在跨模型不一致和无法捕捉描述细微差别的问题，需要更系统化的方法来精确控制智能体的认知偏见。

Method: CoBRA包含两个核心组件：认知偏见指数（通过经典社会科学实验量化智能体反应）和行为调节引擎（将智能体行为与受控认知偏见对齐），采用模型无关的方式显式编程认知偏见。

Result: 评估显示CoBRA能够以模型无关的方式精确编程社会智能体中展示的认知偏见，在技术基准测试中表现出色。

Conclusion: CoBRA提供了一个有效的工具包，能够系统化地指定和控制基于LLM的社会模拟中智能体的认知偏见行为，解决了传统方法的局限性。

Abstract: This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.

</details>


### [181] [See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles](https://arxiv.org/abs/2509.13615)
*Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: 本文提出了State-aware Reasoning (StaR)训练方法，解决多模态代理在GUI切换控制中的不可靠性问题，特别是在当前状态与期望状态一致时的执行错误。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态代理在图形用户界面(GUI)控制中，特别是在执行切换(toggle)控制指令时存在可靠性问题，当当前切换状态已经与期望状态匹配时表现不佳，这成为了一个关键瓶颈。

Method: 构建了一个状态控制基准测试集，包含来自公共数据集的二进制切换指令。提出了State-aware Reasoning (StaR)训练方法，教导代理感知当前切换状态、分析指令中的期望状态，并相应采取行动。

Result: 在三个多模态代理上的实验表明，StaR可以将切换指令执行准确率提高30%以上。在三个公共基准测试上的进一步评估显示，StaR还能提升一般任务性能。动态环境评估突显了StaR在现实应用中的潜力。

Conclusion: StaR方法有效解决了多模态代理在GUI切换控制中的可靠性问题，显著提升了执行准确率，并展现出在真实世界应用中的良好潜力。

Abstract: The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.

</details>


### [182] [InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management](https://arxiv.org/abs/2509.13704)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: InfraMind是一个专为工业管理系统设计的GUI智能体框架，通过系统探索、记忆规划、状态识别、知识蒸馏和多层安全机制，解决了LLM-based GUI代理在工业管理中的五大挑战，显著提升了任务成功率和操作效率。


<details>
  <summary>Details</summary>
Motivation: 工业基础设施管理面临系统复杂性增加、多供应商集成和专家操作员短缺等挑战。现有的RPA自动化方案灵活性有限且维护成本高，而通用LLM-based GUI代理在工业管理中存在元素理解、精度效率、状态定位、部署约束和安全要求等五大关键问题。

Method: 提出InfraMind框架，包含五个创新模块：(1)基于系统搜索的探索和虚拟机快照用于自主理解复杂GUI；(2)记忆驱动规划确保高精度高效任务执行；(3)高级状态识别用于层次化界面的鲁棒定位；(4)结构化知识蒸馏实现轻量级模型高效部署；(5)多层安全机制保护敏感操作。

Result: 在开源和商业DCIM平台上的广泛实验表明，该方法在任务成功率和操作效率方面持续优于现有框架。

Conclusion: InfraMind为工业管理自动化提供了一个严谨且可扩展的解决方案，有效解决了LLM-based GUI代理在工业环境中的关键挑战。

Abstract: Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.

</details>


### [183] [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning](https://arxiv.org/abs/2509.13761)
*Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao*

Main category: cs.AI

TL;DR: THOR是一个通过强化学习实现工具集成层次优化的方法，用于提升LLM在数学推理和代码生成任务中的性能，解决了工具集成推理数据构建、细粒度优化和推理增强三个关键挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学推理方面取得显著进展，但在高精度任务（如数值计算和形式符号操作）上仍然存在困难。集成外部工具是弥补这一差距的有前途方法，但现有方法在工具集成推理数据构建、细粒度优化和推理增强方面面临挑战。

Method: 提出THOR方法：1）TIRGen多智能体actor-critic流水线构建高质量工具集成推理路径数据集；2）分层强化学习策略联合优化轨迹级问题解决和步骤级代码生成；3）推理时利用工具反馈的自校正机制动态修正错误推理路径。

Result: 方法在多个模型上表现出强泛化能力，在推理和非推理模型中都有效。在相似规模模型上实现了多个数学基准测试的最先进性能，同时在代码基准测试上也带来了一致的改进。

Conclusion: THOR通过工具集成和分层优化有效提升了LLM在高精度数学任务和代码生成任务中的性能，为解决工具集成推理的关键挑战提供了有效方案。

Abstract: Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

</details>


### [184] [An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques](https://arxiv.org/abs/2509.13880)
*Mingwei Zhang,Zhenhao Gu,Liangda Fang,Cunjing Ge,Ziliang Chen,Zhao-Rong Lai,Quanlong Guan*

Main category: cs.AI

TL;DR: 本文提出了一种基于DPLL架构的精确方法来解决整数线性约束的模型计数问题，通过整合混合整数规划中的简化技术显著提升了效率


<details>
  <summary>Details</summary>
Motivation: 线性约束是计算机科学、运筹学和优化领域中最基本的约束之一，许多应用问题可归结为整数线性约束的模型计数任务(MCILC)，需要高效的精确求解方法

Method: 基于穷举DPLL架构设计精确方法，整合混合整数规划中的多种有效简化技术来提高效率

Result: 在2840个随机基准测试和4131个应用基准测试中，该方法解决了1718个随机实例（最先进方法仅解决1470个），并且是唯一能解决所有4131个应用实例的方法

Conclusion: 所提出的方法在整数线性约束模型计数问题上显著优于现有精确方法，特别是在应用实例上表现出色

Abstract: Linear constraints are one of the most fundamental constraints in fields such
as computer science, operations research and optimization. Many applications
reduce to the task of model counting over integer linear constraints (MCILC).
In this paper, we design an exact approach to MCILC based on an exhaustive DPLL
architecture. To improve the efficiency, we integrate several effective
simplification techniques from mixed integer programming into the architecture.
We compare our approach to state-of-the-art MCILC counters and propositional
model counters on 2840 random and 4131 application benchmarks. Experimental
results show that our approach significantly outperforms all exact methods in
random benchmarks solving 1718 instances while the state-of-the-art approach
only computes 1470 instances. In addition, our approach is the only approach to
solve all 4131 application instances.

</details>


### [185] [Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks](https://arxiv.org/abs/2509.13968)
*Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel*

Main category: cs.AI

TL;DR: 该研究使用人工神经网络模型探讨信息流结构变化是否会导致认知性能的过渡性变化，发现循环网络相比前馈网络在处理复杂语法时具有质的性能提升，并观察到训练难度形成的过渡障碍。


<details>
  <summary>Details</summary>
Motivation: 探索认知进化是否通过信息流结构的重大转变来实现，验证网络拓扑结构变化是否能带来认知性能的质的飞跃。

Method: 使用理想化信息流模型和人工神经网络，比较前馈、循环和分层拓扑结构，在控制网络大小和资源的情况下测试不同复杂度人工语法的学习性能。

Result: 循环网络相比前馈网络能处理更多类型的输入，在最复杂语法学习上表现出质的性能提升；循环网络的训练难度形成了过渡障碍和偶然不可逆性；分层网络在语法学习上并未优于非分层网络。

Conclusion: 某些信息流结构的变化确实能够导致认知性能的过渡性转变，这支持了认知进化可能通过重大过渡实现的假说。

Abstract: Transitional accounts of evolution emphasise a few changes that shape what is
evolvable, with dramatic consequences for derived lineages. More recently it
has been proposed that cognition might also have evolved via a series of major
transitions that manipulate the structure of biological neural networks,
fundamentally changing the flow of information. We used idealised models of
information flow, artificial neural networks (ANNs), to evaluate whether
changes in information flow in a network can yield a transitional change in
cognitive performance. We compared networks with feed-forward, recurrent and
laminated topologies, and tested their performance learning artificial grammars
that differed in complexity, controlling for network size and resources. We
documented a qualitative expansion in the types of input that recurrent
networks can process compared to feed-forward networks, and a related
qualitative increase in performance for learning the most complex grammars. We
also noted how the difficulty in training recurrent networks poses a form of
transition barrier and contingent irreversibility -- other key features of
evolutionary transitions. Not all changes in network topology confer a
performance advantage in this task set. Laminated networks did not outperform
non-laminated networks in grammar learning. Overall, our findings show how some
changes in information flow can yield transitions in cognitive performance.

</details>


### [186] [CrowdAgent: Multi-Agent Managed Multi-Source Annotation System](https://arxiv.org/abs/2509.14030)
*Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang*

Main category: cs.AI

TL;DR: CrowdAgent是一个多智能体系统，通过整合任务分配、数据标注和质量/成本管理，为LLM、SLM和人类专家提供端到端的协同标注流程控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注标注步骤本身，缺乏对多样化标注源（LLM、SLM、人类专家）的动态管理和复杂调度与质量成本权衡的统一处理。

Method: 采用多智能体系统架构，实现任务分配、数据标注和质量/成本管理的端到端流程控制，使不同标注源能够协同工作。

Result: 在六个多样化多模态分类任务上进行了广泛实验，证明了CrowdAgent的有效性。

Conclusion: CrowdAgent提供了一个统一的框架来动态管理多样化标注源，解决了复杂调度和质量成本权衡的问题。

Abstract: High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.

</details>


### [187] [Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning](https://arxiv.org/abs/2509.14195)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 本文通过分层架构（GCN作为一阶学习器，MLP作为二阶学习器）实证验证了二阶学习能促进环境-认知同构的心理表征形成，在迷宫导航任务中表现出显著性能提升和强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 心理表征（内部模型与外部环境的结构性对应）是高级认知的基础，但实证研究困难。现有理论假设二阶学习（调整一阶学习机制的学习）能促进这种环境-认知同构性的形成，需要实证验证。

Method: 提出分层架构：使用图卷积网络（GCN）作为一阶学习器直接映射节点特征到最优导航路径预测，使用MLP控制器作为二阶学习器在遇到结构新颖的迷宫环境时动态调整GCN参数。

Result: 定量和定性结果显示，当认知系统发展出与环境结构同构的内部心理地图时，二阶学习特别有效，在未见过的迷宫任务上表现出显著性能改进和强大泛化能力。

Conclusion: 研究为结构化心理表征在最大化二阶学习效果中的关键作用提供了实证支持，验证了二阶学习促进环境-认知同构性形成的理论假设。

Abstract: Mental representation, characterized by structured internal models mirroring
external environments, is fundamental to advanced cognition but remains
challenging to investigate empirically. Existing theory hypothesizes that
second-order learning -- learning mechanisms that adapt first-order learning
(i.e., learning about the task/domain) -- promotes the emergence of such
environment-cognition isomorphism. In this paper, we empirically validate this
hypothesis by proposing a hierarchical architecture comprising a Graph
Convolutional Network (GCN) as a first-order learner and an MLP controller as a
second-order learner. The GCN directly maps node-level features to predictions
of optimal navigation paths, while the MLP dynamically adapts the GCN's
parameters when confronting structurally novel maze environments. We
demonstrate that second-order learning is particularly effective when the
cognitive system develops an internal mental map structurally isomorphic to the
environment. Quantitative and qualitative results highlight significant
performance improvements and robust generalization on unseen maze tasks,
providing empirical support for the pivotal role of structured mental
representations in maximizing the effectiveness of second-order learning.

</details>
