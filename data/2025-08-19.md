<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 156]
- [cs.IR](#cs.IR) [Total: 15]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.CY](#cs.CY) [Total: 27]
- [cs.LG](#cs.LG) [Total: 110]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones](https://arxiv.org/abs/2508.11696)
*Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman*

Main category: cs.CV

TL;DR: 基于YOLOv8改进的自定义模型在CCTV监控中实时检测吸烟行为，在复杂监控环境下达到了78.90%的回归率和83.70% mAP指标，在Jetson Xavier NX边缘设处上实现了52-97ms的处理速度。


<details>
  <summary>Details</summary>
Motivation: 出于防火逃生通道安全要求，需要开发能够在CCTV监控中实时检测吸烟行为的系统，应对低光环境等复杂监控场景。

Method: 使用8,124张图片和2,708个原始样本的数据集，评估YOLOv8、YOLOv11、YOLOv12三种目标检测模型，并在YOLOv8基础上开发了专门优化的自定义模型。在多种边缘设处上进行多线程性能评估。

Result: 自定义模型表现最优，达到了78.90%回归率和83.70% mAP@50。Jetson Xavier NX边缘设处的处理速度为52-97ms/推理，适合实时操作。

Conclusion: 该系统提供了一个稳健且适应性强的平台，能够有效监控公共安全并实现自动遵规管理，在复杂监控环境下保持了高性能。

Abstract: A deep learning real-time smoking detection system for CCTV surveillance of
fire exit areas is proposed due to critical safety requirements. The dataset
contains 8,124 images from 20 different scenarios along with 2,708 raw samples
demonstrating low-light areas. We evaluated three advanced object detection
models: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model
derived from YOLOv8 with added structures for challenging surveillance
contexts. The proposed model outperformed the others, achieving a recall of
78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object
detection across varied environments. Performance evaluation on multiple edge
devices using multithreaded operations showed the Jetson Xavier NX processed
data at 52 to 97 milliseconds per inference, establishing its suitability for
time-sensitive operations. This system offers a robust and adaptable platform
for monitoring public safety and enabling automatic regulatory compliance.

</details>


### [2] [Separating Knowledge and Perception with Procedural Data](https://arxiv.org/abs/2508.11697)
*Adrián Rodríguez-Muñoz,Manel Baradad,Phillip Isola,Antonio Torralba*

Main category: cs.CV

TL;DR: 通过仅使用程序生成数据训练表征模型，结合视觉记忆库技术，在不需额外训练的情况下实现了与实际图像模型相当的性能表现，同时保持完全的数据隔离性。


<details>
  <summary>Details</summary>
Motivation: 解决依赖大量实际图像数据进行模型训练所带来的数据泄漏风险和法律问题，通过程序生成数据实现数据安全和隔离性。

Method: 仅使用程序生成的数据训练表征模型，结合显式的视觉记忆库（参考图像嵌入数据库）技术，在不需额外训练的情况下应用于视觉相似性、分类和语义分割任务。

Result: 在NIGHTS视觉相似性任务上与Places训练模型相差仅1%，在CUB200和Flowers102细粒度分类任务上分别超15%和8%，在ImageNet-1K分类上相差10%。零样本分割任务上在COCO数据集达到与实际数据训练模型相10%以内的R²指标。

Conclusion: 程序生成数据模型可以在保持完全数据隔离性的前提下实现与实际图像模型相当的性能表现，但对象内部表征的差异性导致的记忆搜索错误是性能差距的主要原因。

Abstract: We train representation models with procedural data only, and apply them on
visual similarity, classification, and semantic segmentation tasks without
further training by using visual memory -- an explicit database of reference
image embeddings. Unlike prior work on visual memory, our approach achieves
full compartmentalization with respect to all real-world images while retaining
strong performance. Compared to a model trained on Places, our procedural model
performs within $1\%$ on NIGHTS visual similarity, outperforms by $8\%$ and
$15\%$ on CUB200 and Flowers102 fine-grained classification, and is within
$10\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot
segmentation, achieving an $R^2$ on COCO within $10\%$ of the models trained on
real data. Finally, we analyze procedural versus real data models, showing that
parts of the same object have dissimilar representations in procedural models,
resulting in incorrect searches in memory and explaining the remaining
performance gap.

</details>


### [3] [FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis](https://arxiv.org/abs/2508.11721)
*Ke Zou,Jocelyn Hui Lin Goh,Yukun Zhou,Tian Lin,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Rui Santos,Gabor M. Somfai,Huazhu Fu,Haoyu Chen,Pearse A. Keane,Ching-Yu Cheng,Yih Chung Tham*

Main category: cs.CV

TL;DR: 这是首个系统性评估眼科基础模型的研究，测试了四个先进模型在眼部疾病和系统性疾病预测中的表现，并探索了模型融合策略的效果。


<details>
  <summary>Details</summary>
Motivation: 眼科基础模型尺寸之间的性能差异不明，且缺乏系统性评估。研究者希望确定哪个模型表现最佳，是否在不同任务上都有类似表现，以及模型融合是否能提升性能。

Method: 研究提出FusionFM评估框架，测试四个先进眼科FM（RETFound、VisionFM、RetiZero、DINORET）。使用标准化多国数据集，测试眼部疾病（青光眼、糖尿病视网膜病变、黄斑变性）和系统疾病（糖尿病、高血压）预测。采用AUC和F1指标，并探索两种融合策略。

Result: DINORET和RetiZero在所有任务中表现最佳，RetiZero在外部数据集上显示更强的沿半性。门控融合策略在预测青光眼、黄斑变性和高血压时有轻微改善。但预测系统疾病（特别是外部组织的高血压）仍靠挑战。

Conclusion: 这项研究为眼科基础模型提供了基于证据的评估，证明了模型融合的潜在价值，并指出了提高临床应用性的策略方向。

Abstract: Foundation models (FMs) have shown great promise in medical image analysis by
improving generalization across diverse downstream tasks. In ophthalmology,
several FMs have recently emerged, but there is still no clear answer to
fundamental questions: Which FM performs the best? Are they equally good across
different tasks? What if we combine all FMs together? To our knowledge, this is
the first study to systematically evaluate both single and fused ophthalmic
FMs. To address these questions, we propose FusionFM, a comprehensive
evaluation suite, along with two fusion approaches to integrate different
ophthalmic FMs. Our framework covers both ophthalmic disease detection
(glaucoma, diabetic retinopathy, and age-related macular degeneration) and
systemic disease prediction (diabetes and hypertension) based on retinal
imaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,
RetiZero, and DINORET) using standardized datasets from multiple countries and
evaluated their performance using AUC and F1 metrics. Our results show that
DINORET and RetiZero achieve superior performance in both ophthalmic and
systemic disease tasks, with RetiZero exhibiting stronger generalization on
external datasets. Regarding fusion strategies, the Gating-based approach
provides modest improvements in predicting glaucoma, AMD, and hypertension.
Despite these advances, predicting systemic diseases, especially hypertension
in external cohort remains challenging. These findings provide an
evidence-based evaluation of ophthalmic FMs, highlight the benefits of model
fusion, and point to strategies for enhancing their clinical applicability.

</details>


### [4] [UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction](https://arxiv.org/abs/2508.11728)
*Chunxia Ren,Ning Zhu,Yue Lai,Gui Chen,Ruijie Wang,Yangyi Hu,Suyao Liu,Shuwen Mao,Hong Su,Yu Zhang,Li Xiao*

Main category: cs.CV

TL;DR: UniDCF是一个统一的多模态深度学习框架，能够通过点云和多视角图像的融合编码来重建多种牙颌面硬组织，解决了现有单模态方法的局限性，在几何精度、结构完整性和空间准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 牙颌面硬组织缺损严重影响患者的生理功能、面部美观和心理健康，但当前深度学习模型仅限于单组织场景和特定模态成像输入，导致泛化性差，在解剖保真度、计算效率和跨组织适应性之间存在权衡。

Method: UniDCF通过点云和多视角图像的多模态融合编码，利用各模态的互补优势，并引入基于分数的去噪模块来细化表面平滑度。研究构建了最大的多模态数据集，包含6,609名患者的口内扫描、CBCT和CT数据，共54,555个标注实例。

Result: 评估显示UniDCF在几何精度、结构完整性和空间准确性方面优于现有最先进方法。临床模拟表明UniDCF将重建设计时间减少了99%，临床医生接受率超过94%。

Conclusion: UniDCF实现了快速、自动化和高保真度的重建，支持个性化和精确的修复治疗，简化了临床工作流程，并改善了患者治疗效果。

Abstract: Dentocraniofacial hard tissue defects profoundly affect patients'
physiological functions, facial aesthetics, and psychological well-being,
posing significant challenges for precise reconstruction. Current deep learning
models are limited to single-tissue scenarios and modality-specific imaging
inputs, resulting in poor generalizability and trade-offs between anatomical
fidelity, computational efficiency, and cross-tissue adaptability. Here we
introduce UniDCF, a unified framework capable of reconstructing multiple
dentocraniofacial hard tissues through multimodal fusion encoding of point
clouds and multi-view images. By leveraging the complementary strengths of each
modality and incorporating a score-based denoising module to refine surface
smoothness, UniDCF overcomes the limitations of prior single-modality
approaches. We curated the largest multimodal dataset, comprising intraoral
scans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated
instances. Evaluations demonstrate that UniDCF outperforms existing
state-of-the-art methods in terms of geometric precision, structural
completeness, and spatial accuracy. Clinical simulations indicate UniDCF
reduces reconstruction design time by 99% and achieves clinician-rated
acceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and
high-fidelity reconstruction, supporting personalized and precise restorative
treatments, streamlining clinical workflows, and enhancing patient outcomes.

</details>


### [5] [Ovis2.5 Technical Report](https://arxiv.org/abs/2508.11737)
*Shiyin Lu,Yang Li,Yu Xia,Yuwei Hu,Shanshan Zhao,Yanqing Ma,Zhichao Wei,Yinglun Li,Lunhao Duan,Jianshan Zhao,Yuxuan Han,Haijun Li,Wanying Chen,Junke Tang,Chengkun Hou,Zhixing Du,Tianli Zhou,Wenjie Zhang,Huping Ding,Jiahe Li,Wen Li,Gui Hu,Yiliang Gu,Siran Yang,Jiamang Wang,Hailong Sun,Yibo Wang,Hui Sun,Jinlong Huang,Yuping He,Shengze Shi,Weihong Zhang,Guodong Zheng,Junpeng Jiang,Sensen Gao,Yi-Feng Wu,Sijia Chen,Yuhui Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Ovis2.5是一个先进的多模态大语言模型，通过原生分辨率视觉处理和反思推理机制，在多个基准测试中达到开源模型的最先进水平，特别是9B版本在OpenCompass上获得78.3分，2B版本获得73.9分。


<details>
  <summary>Details</summary>
Motivation: 为了解决固定分辨率分块处理导致的视觉细节损失问题，并提升模型在复杂视觉内容（如图表）上的理解和推理能力，需要开发能够处理原生分辨率图像并具备反思推理能力的多模态模型。

Method: 采用原生分辨率视觉Transformer处理可变分辨率图像，引入反思推理机制（包括自检查和修订），通过五阶段课程学习（基础视觉预训练、大规模指令调优、DPO和GRPO对齐增强），使用多模态数据打包和混合并行技术提升训练效率。

Result: Ovis2.5-9B在OpenCompass多模态排行榜上平均得分78.3，显著超越前代Ovis2-8B，在40B参数以下的开源MLLM中达到SOTA；Ovis2.5-2B得分73.9，在同规模模型中建立SOTA。在STEM基准、 grounding任务、视频任务和复杂图表分析方面均取得领先结果。

Conclusion: Ovis2.5通过原生分辨率视觉处理和反思推理机制的成功结合，证明了在保持模型规模效率的同时实现性能突破的可行性，为资源受限的端侧部署提供了高性能解决方案，推动了多模态模型在复杂视觉理解任务上的发展。

Abstract: We present Ovis2.5, a successor to Ovis2 designed for native-resolution
visual perception and strong multimodal reasoning. Ovis2.5 integrates a
native-resolution vision transformer that processes images at their native,
variable resolutions, avoiding the degradation from fixed-resolution tiling and
preserving both fine detail and global layout -- crucial for visually dense
content like complex charts. To strengthen reasoning, we train the model to
move beyond linear chain-of-thought and perform reflection -- including
self-checking and revision. This advanced capability is exposed as an optional
"thinking mode" at inference time, allowing users to trade latency for enhanced
accuracy on difficult inputs. The model is trained via a comprehensive
five-phase curriculum that progressively builds its skills. The process begins
with foundational visual and multimodal pretraining, advances through
large-scale instruction tuning, and culminates in alignment and reasoning
enhancement using DPO and GRPO. To scale these upgrades efficiently, we employ
multimodal data packing and hybrid parallelism, yielding a significant
end-to-end speedup. We release two open-source models: Ovis2.5-9B and
Ovis2.5-2B. The latter continues the "small model, big performance" philosophy
of Ovis2, making it ideal for resource-constrained, on-device scenarios. On the
OpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a
substantial improvement over its predecessor, Ovis2-8B, and achieving
state-of-the-art results among open-source MLLMs in the sub-40B parameter
range; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate
scores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong
capabilities on grounding and video tasks, and achieves open-source SOTA at its
scale for complex chart analysis.

</details>


### [6] [VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models](https://arxiv.org/abs/2508.11801)
*Ming Cheng,Tong Wu,Jiazhen Hu,Jiaying Gong,Hoda Eldardiry*

Main category: cs.CV

TL;DR: VideoAVE是首个公开的视频到文本电商属性值提取数据集，覆盖14个领域和172个属性，包含22.4万训练数据和2.5万评估数据，并建立了全面的基准测试。


<details>
  <summary>Details</summary>
Motivation: 解决现有AVE数据集缺乏视频支持、属性覆盖不足和公开可用性的问题，为视频电商信息结构化提供数据基础。

Method: 提出基于CLIP的混合专家过滤系统(CLIP-MoE)来去除不匹配的视频-产品对，确保数据质量，并建立多任务基准评估现有视频视觉语言模型。

Result: 视频到文本AVE仍然是一个具有挑战性的问题，特别是在开放设置中，现有模型在利用有效时序信息方面仍有改进空间。

Conclusion: VideoAVE填补了视频AVE数据集的空白，为开发更先进的视频视觉语言模型提供了重要基准和数据集支持。

Abstract: Attribute Value Extraction (AVE) is important for structuring product
information in e-commerce. However, existing AVE datasets are primarily limited
to text-to-text or image-to-text settings, lacking support for product videos,
diverse attribute coverage, and public availability. To address these gaps, we
introduce VideoAVE, the first publicly available video-to-text e-commerce AVE
dataset across 14 different domains and covering 172 unique attributes. To
ensure data quality, we propose a post-hoc CLIP-based Mixture of Experts
filtering system (CLIP-MoE) to remove the mismatched video-product pairs,
resulting in a refined dataset of 224k training data and 25k evaluation data.
In order to evaluate the usability of the dataset, we further establish a
comprehensive benchmark by evaluating several state-of-the-art video vision
language models (VLMs) under both attribute-conditioned value prediction and
open attribute-value pair extraction tasks. Our results analysis reveals that
video-to-text AVE remains a challenging problem, particularly in open settings,
and there is still room for developing more advanced VLMs capable of leveraging
effective temporal information. The dataset and benchmark code for VideoAVE are
available at: https://github.com/gjiaying/VideoAVE

</details>


### [7] [An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation](https://arxiv.org/abs/2508.11803)
*Azam Nouri*

Main category: cs.CV

TL;DR: 使用二阶几何特征（平面曲率大小、曲率符号和梯度方向）的MLP分类器在手写字符识别中表现优异，MNIST数字达到97%准确率，EMNIST字母达到89%准确率


<details>
  <summary>Details</summary>
Motivation: 探索仅使用二阶几何特征是否足以驱动MLP分类器进行手写字符识别，作为卷积神经网络的替代方案

Method: 使用三种手工特征图（曲率大小、曲率符号和梯度方向）作为输入，构建曲率-方向MLP分类器

Result: 在MNIST数字上达到97%准确率，在EMNIST字母上达到89%准确率

Conclusion: 曲率基表示对手写字符图像具有强大的判别能力，深度学习优势可以通过可解释的手工特征实现

Abstract: This study investigates whether second-order geometric cues - planar
curvature magnitude, curvature sign, and gradient orientation - are sufficient
on their own to drive a multilayer perceptron (MLP) classifier for handwritten
character recognition (HCR), offering an alternative to convolutional neural
networks (CNNs). Using these three handcrafted feature maps as inputs, our
curvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89
percent on EMNIST letters. These results underscore the discriminative power of
curvature-based representations for handwritten character images and
demonstrate that the advantages of deep learning can be realized even with
interpretable, hand-engineered features.

</details>


### [8] [Labels or Input? Rethinking Augmentation in Multimodal Hate Detection](https://arxiv.org/abs/2508.11808)
*Sahajpreet Singh,Rongxin Ouyang,Subhayan Mukerjee,Kokil Jaidka*

Main category: cs.CV

TL;DR: 这篇论文提出了一种双重探索方法来改善多模态恨恼图片检测：通过提示优化框架和多模态数据增帽管道，提高了模型的稳健性和通用性。


<details>
  <summary>Details</summary>
Motivation: 现代网络中恨恼图片通过文本和图像的细微互动传播，现有的视觉-语言模型缺乏细粒度监督支持且容易受隐式恨恼语言影响。

Method: 提出了提示优化框架（系统性变化提示结构、监督粒度和训练模态）和多模态数据增帽管道（使用多代理LLM-VLM设置生成2,479个反事实中性图片）。

Result: 结构化提示提高了模型稳健性，InternVL2在二元和级别设置中获得最佳F1分数，数据增帽管道减少了偏相关性并改善了分类器通用性。

Conclusion: 提示结构和数据组成与模型大小同样重要，目标定向的数据增帽能够支持更可信、上下文敏感的恨恼检测。

Abstract: The modern web is saturated with multimodal content, intensifying the
challenge of detecting hateful memes, where harmful intent is often conveyed
through subtle interactions between text and image under the guise of humor or
satire. While recent advances in Vision-Language Models (VLMs) show promise,
these models lack support for fine-grained supervision and remain susceptible
to implicit hate speech. In this paper, we present a dual-pronged approach to
improve multimodal hate detection. First, we propose a prompt optimization
framework that systematically varies prompt structure, supervision granularity,
and training modality. We show that prompt design and label scaling both
influence performance, with structured prompts improving robustness even in
small models, and InternVL2 achieving the best F1-scores across binary and
scaled settings. Second, we introduce a multimodal data augmentation pipeline
that generates 2,479 counterfactually neutral memes by isolating and rewriting
the hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,
successfully reduces spurious correlations and improves classifier
generalization. Our approaches inspire new directions for building synthetic
data to train robust and fair vision-language models. Our findings demonstrate
that prompt structure and data composition are as critical as model size, and
that targeted augmentation can support more trustworthy and context-sensitive
hate detection.

</details>


### [9] [Towards Understanding 3D Vision: the Role of Gaussian Curvature](https://arxiv.org/abs/2508.11825)
*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 本文研究高斯曲率在3D表面建模中的作用，提出高斯曲率作为一种稀疏紧凑的几何前知，可以改善单目和双目3D重建方法的性能


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在3D视觉任务中取得了显著成功，但缺乏明确的可分析几何模型，无法直接进行跨模态转移或系统性修改

Method: 通过在Middlebury双目数据集上进行实验，研究高斯曲率在3D表面建模中的特性和作用，分析其作为几何前知的潜力

Result: 高斯曲率提供了稀疏紧凑的3D表面描述，现有的独目和双目方法隐式考虑了该量，可作为无监督评量标准，并为3D重建提供几何前知信息

Conclusion: 高斯曲率作为一种内在的几何不变量，在3D表面建模中具有重要价值，可以作为明确的几何模块提升现有深度学习方法的性能和可解释性

Abstract: Recent advances in computer vision have predominantly relied on data-driven
approaches that leverage deep learning and large-scale datasets. Deep neural
networks have achieved remarkable success in tasks such as stereo matching and
monocular depth reconstruction. However, these methods lack explicit models of
3D geometry that can be directly analyzed, transferred across modalities, or
systematically modified for controlled experimentation. We investigate the role
of Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being
an invariant quantity under change of observers or coordinate systems, we
demonstrate using the Middlebury stereo dataset that it offers: (i) a sparse
and compact description of 3D surfaces, (ii) state-of-the-art monocular and
stereo methods seem to implicitly consider it, but no explicit module of such
use can be extracted, (iii) a form of geometric prior that can inform and
improve 3D surface reconstruction, and (iv) a possible use as an unsupervised
metric for stereo methods.

</details>


### [10] [From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images](https://arxiv.org/abs/2508.11826)
*Dehn Xu,Tim Katzke,Emmanuel Müller*

Main category: cs.CV

TL;DR: 这篇论文系统性评估了多种图像-图象转换方法在图神经网络基于图级异常检测任务中的效果，发现颜色描述符表现最佳，而形状和纹理特征能显著提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 虽然GNN已被应用于图像演化的图表示下流任务，但尚无研究系统性比较不同图像-图象转换方法在图级异常检测中的效果。

Method: 系统评估多种分割方案、边缘构建策略和节点特征集（包括颜色、纹理、形状描述符），在皮肤镜图像上进行广泛实验，测试无监督、弱监督和全监督模式下的性能。

Result: 无监督配置下OCGTL模型达到0.805 AUC-ROC，加入稀疏标签后提升到0.872，全监督下达到0.914 AUC-ROC。颜色描述符表现最好，形状和纹理特征能显著提升检测效果。

Conclusion: 这项研究为图像-图象转换方法的选择提供了系统性指南，显示了适当的图表示能够在不依赖预训练模型的情况下实现竞争性能能，为GNN在图像异常检测中的应用提供了重要见解。

Abstract: Graph Neural Networks (GNNs) have emerged as a powerful approach for
graph-based machine learning tasks. Previous work applied GNNs to image-derived
graph representations for various downstream tasks such as classification or
anomaly detection. These transformations include segmenting images, extracting
features from segments, mapping them to nodes, and connecting them. However, to
the best of our knowledge, no study has rigorously compared the effectiveness
of the numerous potential image-to-graph transformation approaches for
GNN-based graph-level anomaly detection (GLAD). In this study, we
systematically evaluate the efficacy of multiple segmentation schemes, edge
construction strategies, and node feature sets based on color, texture, and
shape descriptors to produce suitable image-derived graph representations to
perform graph-level anomaly detection. We conduct extensive experiments on
dermoscopic images using state-of-the-art GLAD models, examining performance
and efficiency in purely unsupervised, weakly supervised, and fully supervised
regimes. Our findings reveal, for example, that color descriptors contribute
the best standalone performance, while incorporating shape and texture features
consistently enhances detection efficacy. In particular, our best unsupervised
configuration using OCGTL achieves a competitive AUC-ROC score of up to 0.805
without relying on pretrained backbones like comparable image-based approaches.
With the inclusion of sparse labels, the performance increases substantially to
0.872 and with full supervision to 0.914 AUC-ROC.

</details>


### [11] [Recent Advances in Transformer and Large Language Models for UAV Applications](https://arxiv.org/abs/2508.11834)
*Hamza Kheddar,Yassine Habchi,Mohamed Chahine Ghanem,Mustapha Hemis,Dusit Niyato*

Main category: cs.CV

TL;DR: 这篇综述论文系统性地分类和评估了Transformer架构在无人机系统中的最新应用进展，包括注意力机制、CNN-Transformer混合模型、强化学习Transformers和大语言模型，提供了统一的分类体系和性能基准比较。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型的快速发展，其在无人机感知、决策和自主性方面的应用日益广泛，但缺乏系统性的综述来整合这些进展并指导未来研究方向。

Method: 采用系统性文献综述方法，对Transformer在无人机领域的应用进行分类整理，包括架构分析、性能比较、数据集和评估指标梳理，并通过结构化表格进行对比分析。

Result: 提出了基于Transformer的无人机模型统一分类体系，识别了精准农业和自主导航等新兴应用领域，总结了关键数据集和仿真工具，揭示了计算效率和实时部署方面的挑战。

Conclusion: 该综述为研究人员和从业者提供了Transformer驱动无人机技术的全面指导，指出了未来研究方向，包括解决计算效率问题和推动实时部署应用。

Abstract: The rapid advancement of Transformer-based models has reshaped the landscape
of uncrewed aerial vehicle (UAV) systems by enhancing perception,
decision-making, and autonomy. This review paper systematically categorizes and
evaluates recent developments in Transformer architectures applied to UAVs,
including attention mechanisms, CNN-Transformer hybrids, reinforcement learning
Transformers, and large language models (LLMs). Unlike previous surveys, this
work presents a unified taxonomy of Transformer-based UAV models, highlights
emerging applications such as precision agriculture and autonomous navigation,
and provides comparative analyses through structured tables and performance
benchmarks. The paper also reviews key datasets, simulators, and evaluation
metrics used in the field. Furthermore, it identifies existing gaps in the
literature, outlines critical challenges in computational efficiency and
real-time deployment, and offers future research directions. This comprehensive
synthesis aims to guide researchers and practitioners in understanding and
advancing Transformer-driven UAV technologies.

</details>


### [12] [ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages](https://arxiv.org/abs/2508.11854)
*Matthew Hull,Haoyang Yang,Pratham Mehta,Mansi Phute,Aeree Cho,Haorang Wang,Matthew Lau,Wenke Lee,Wilian Lunardi,Martin Andreoni,Polo Chau*

Main category: cs.CV

TL;DR: 首个黑盒攻击方法ComplicitSplat，利用3D高斯抽射的渲染特性在特定视角嵌入阻填内容，不需模型权重即可攻击多种目标检测器


<details>
  <summary>Details</summary>
Motivation: 3D高斯抽射技术在安全关键任务中快速应用，需要研究恶意攻击者如何篡改图像造成害

Method: 利用标准3DGS渲染方法创建视角特异性谜色－颜色和纹理随视角变化，在特定视角下嵌入恶意内容

Result: 方法在真实物理对象和合成场景中都有效，能成功攻击单阶段、多阶段和Transformer基础的多种检测器

Conclusion: 曝露了3DGS在自主导航等关键任务中的新安全风险，是首个不需模型权重的黑盒攻击

Abstract: As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks
for efficient novel-view synthesis from static images, how might an adversary
tamper images to cause harm? We introduce ComplicitSplat, the first attack that
exploits standard 3DGS shading methods to create viewpoint-specific camouflage
- colors and textures that change with viewing angle - to embed adversarial
content in scene objects that are visible only from specific viewpoints and
without requiring access to model architecture or weights. Our extensive
experiments show that ComplicitSplat generalizes to successfully attack a
variety of popular detector - both single-stage, multi-stage, and
transformer-based models on both real-world capture of physical objects and
synthetic scenes. To our knowledge, this is the first black-box attack on
downstream object detectors using 3DGS, exposing a novel safety risk for
applications like autonomous navigation and other mission-critical robotic
systems.

</details>


### [13] [Impact of Clinical Image Quality on Efficient Foundation Model Finetuning](https://arxiv.org/abs/2508.11864)
*Yucheng Tang,Pawel Rajwa,Alexander Ng,Yipei Wang,Wen Yan,Natasha Thorley,Aqua Asif,Clare Allen,Louise Dickinson,Francesco Giganti,Shonit Punwani,Daniel C. Alexander,Veeru Kasivisvanathan,Yipeng Hu*

Main category: cs.CV

TL;DR: 本文评估了医学影像基础模型ProFound在前列腺多参数MRI中的标签效率，发现图像质量分布及其在微调与测试集之间的不匹配显著影响模型性能，强调需要对齐质量分布以实现基础模型的数据和计算效率优势。


<details>
  <summary>Details</summary>
Motivation: 医学影像基础模型在标签效率方面显示出潜力，但图像质量变化如何影响微调效果尚不清楚。本文旨在系统评估前列腺MRI中图像质量分布对基础模型微调泛化能力的影响。

Method: 使用在前列腺MRI大数据集上预训练的ProFound域专用视觉基础模型，通过系统变化微调和评估集中的高/低质量图像比例，测量微调模型的泛化性能。

Result: 研究发现：a)微调集和测试集间高/低质量图像比例不匹配会导致下游性能显著差异；b)微调集中足够高质量图像对保持强性能至关重要；c)当质量比例一致时，微调所需标注数据远少于从头训练，但标签效率取决于图像质量分布。

Conclusion: 图像质量分布及其在微调与部署环境间的匹配对基础模型性能至关重要。缺乏足够高质量微调数据时，预训练模型可能无法超越无预训练模型，强调了在微调和部署中量化图像质量的重要性。

Abstract: Foundation models in medical imaging have shown promising label efficiency,
achieving high downstream performance with only a fraction of annotated data.
Here, we evaluate this in prostate multiparametric MRI using ProFound, a
domain-specific vision foundation model pretrained on large-scale prostate MRI
datasets. We investigate how variable image quality affects label-efficient
finetuning by measuring the generalisability of finetuned models. Experiments
systematically vary high-/low-quality image ratios in finetuning and evaluation
sets. Our findings indicate that image quality distribution and its
finetune-and-test mismatch significantly affect model performance. In
particular: a) Varying the ratio of high- to low-quality images between
finetuning and test sets leads to notable differences in downstream
performance; and b) The presence of sufficient high-quality images in the
finetuning set is critical for maintaining strong performance, whilst the
importance of matched finetuning and testing distribution varies between
different downstream tasks, such as automated radiology reporting and prostate
cancer detection.When quality ratios are consistent, finetuning needs far less
labeled data than training from scratch, but label efficiency depends on image
quality distribution. Without enough high-quality finetuning data, pretrained
models may fail to outperform those trained without pretraining. This
highlights the importance of assessing and aligning quality distributions
between finetuning and deployment, and the need for quality standards in
finetuning data for specific downstream tasks. Using ProFound, we show the
value of quantifying image quality in both finetuning and deployment to fully
realise the data and compute efficiency benefits of foundation models.

</details>


### [14] [AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition](https://arxiv.org/abs/2508.11870)
*Ying Huang,Yuanbin Man,Wenqi Jia,Zhengzhong Tu,Junzhou Huang,Miao Yin*

Main category: cs.CV

TL;DR: AdaRing是一个基于张量环分解的视觉语言模型微调框架，通过跨层共享张量核心和层特定切片来消除冗余，同时利用不同秩的适配器协同处理多样化表示需求，在减少90%参数的同时达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有适配器方法存在两个主要限制：1）由于忽略跨层冗余而导致压缩率有限；2）同质适配器的表示能力有限。需要一种既能高效压缩参数又能提升表示能力的微调方法。

Method: 提出基于跨层张量环分解的框架，将适配器表示为层共享的张量核心和层特定切片，利用张量级低秩性消除跨层冗余；同时采用泛化感知微调指导，让不同秩的适配器协同处理不同表示需求的任务。

Result: 实验表明AdaRing在减少平均训练参数90%的情况下，达到了最先进的性能表现。

Conclusion: AdaRing通过张量环分解和多样化适配器协作，实现了超轻量级的参数高效适应，在保持高性能的同时显著降低了参数需求。

Abstract: Adapter-based fine-tuning has gained remarkable attention in adapting large
pre-trained vision language models (VLMs) for a wide range of downstream tasks
efficiently. In this paradigm, only the inserted adapters are fine-tuned,
without the need for training the original VLM backbone. Existing works scale
adapters by integrating them into every layer of VLMs to increase the capacity
of adapters. However, these methods face two primary limitations: 1) limited
compression rate due to ignoring cross-layer redundancy, and 2) limited
representational capacity across homogeneous adapters. In this paper, we
propose a novel vision-language fine-tuning framework based on cross-layer
tensor ring decomposition (TRD) with the integration and collaboration of
diverse adapters, called AdaRing, achieving ultra-light parameter-efficient
adaptation of VLMs on various tasks. To remove the high redundancy that exists
among adapters across layers, we exploit the tensor-level low-rankness to
formulate adapters as layer-shared tensor cores and layer-specific slices.
Moreover, guided by generalization-aware fine-tuning, diverse rank-driven
adapters cooperate to handle tasks that require different representations. Our
experiments show that the proposed AdaRing achieves the state-of-the-art
performance while reducing average training parameters by 90%.

</details>


### [15] [EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models](https://arxiv.org/abs/2508.11886)
*Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Shao Tang,Sayan Ghosh,Xuanzhao Dong,Rajat Koner,Yalin Wang*

Main category: cs.CV

TL;DR: 通过空间信息综合的k-center视觉到征剪析方法EVTP-IV，在指令视觉分割任务中实现5倍速度提升，仅使用20%到征保持类似准确性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视视分割任务中的推理成本过高，特别是在视频任务中，需要找到高效的到征剪析方法来加快推理速度。

Method: 提出EVTP-IV方法，基于k-center算法并综合空间信息，选择空间上代表性强的简约到征子集，并通过信息论分析验证方法设计。

Result: 在标准IVS测试集上，方法在视频任务中实现了5倍速度提升，图像任务中实现3.5倍速度提升，仅使用20%到征却保持了类似的准确性，且在不同剪析比下都超过最新的剪析基线方法。

Conclusion: EVTP-IV通过空间代表性到征选择，在保持分割准确性的同时显著提升了多模态大模型在指令视视分割任务中的推理效率，为高效视视理解提供了有效解决方案。

Abstract: Instructed Visual Segmentation (IVS) tasks require segmenting objects in
images or videos based on natural language instructions. While recent
multimodal large language models (MLLMs) have achieved strong performance on
IVS, their inference cost remains a major bottleneck, particularly in video. We
empirically analyze visual token sampling in MLLMs and observe a strong
correlation between subset token coverage and segmentation performance. This
motivates our design of a simple and effective token pruning method that
selects a compact yet spatially representative subset of tokens to accelerate
inference. In this paper, we introduce a novel visual token pruning method for
IVS, called EVTP-IV, which builds upon the k-center by integrating spatial
information to ensure better coverage. We further provide an
information-theoretic analysis to support our design. Experiments on standard
IVS benchmarks show that our method achieves up to 5X speed-up on video tasks
and 3.5X on image tasks, while maintaining comparable accuracy using only 20%
of the tokens. Our method also consistently outperforms state-of-the-art
pruning baselines under varying pruning ratios.

</details>


### [16] [Large Kernel Modulation Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11893)
*Quanwei Hu,Yinggan Tang,Xuguang Zhang*

Main category: cs.CV

TL;DR: 提出基于纯CNN的大核调制网络(LKMN)，通过增强部分大核块和跨门前馈网络，在保持低延迟的同时实现非局部特征提取，在轻量级超分任务中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决资源受限场景下图像超分辨率任务中，CNN模型缺乏非局部特征捕获能力而Transformer模型推理速度慢的权衡问题

Method: LKMN包含两个核心组件：增强部分大核块(EPLKB)使用通道混洗增强通道交互、通道注意力聚焦关键信息、部分通道大核条带卷积进行非局部特征提取；跨门前馈网络(CGFN)通过可学习缩放因子动态调整特征差异，采用跨门策略调制融合特征

Result: 在Manga109数据集4倍超分任务上，LKMN-L比DAT-light提升0.23dB PSNR，推理速度快约4.8倍

Conclusion: LKMN成功平衡了图像超分辨率的性能和质量，为轻量级超分模型提供了有效的纯CNN解决方案

Abstract: Image super-resolution (SR) in resource-constrained scenarios demands
lightweight models balancing performance and latency. Convolutional neural
networks (CNNs) offer low latency but lack non-local feature capture, while
Transformers excel at non-local modeling yet suffer slow inference. To address
this trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure
CNN-based model. LKMN has two core components: Enhanced Partial Large Kernel
Block (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes
channel shuffle to boost inter-channel interaction, incorporates channel
attention to focus on key information, and applies large kernel strip
convolutions on partial channels for non-local feature extraction with reduced
complexity. The CGFN dynamically adjusts discrepancies between input, local,
and non-local features via a learnable scaling factor, then employs a
cross-gate strategy to modulate and fuse these features, enhancing their
complementarity. Extensive experiments demonstrate that our method outperforms
existing state-of-the-art (SOTA) lightweight SR models while balancing quality
and efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over
DAT-light on the Manga109 dataset at $\times$4 upscale, with nearly $\times$4.8
times faster. Codes are in the supplementary materials. The code is available
at https://github.com/Supereeeee/LKMN.

</details>


### [17] [MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999)
*Daoze Zhang,Zhanheng Nie,Jianyu Liu,Chenghan Fu,Wanxian Guan,Yuan Gao,Jun Song,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: MOON是首个基于生成式多模态大语言模型的产品表示学习方法，通过引导式专家混合模块、核心语义区域检测和专业化负采样策略，解决了产品图像文本多对一对齐、背景噪声干扰等挑战，并在多个下游任务中展现了优异的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 随着电子商务的快速发展，需要探索通用的产品表示而非任务特定的表示。现有的判别式双流架构难以建模产品多图像与文本之间的多对一对应关系，而生成式多模态大语言模型在这方面具有巨大潜力。

Method: 1) 使用引导式专家混合(MoE)模块进行多模态和特定方面的产品内容建模；2) 有效检测产品图像中的核心语义区域以减少背景噪声干扰；3) 引入专业化负采样策略增加负样本的难度和多样性。

Result: 模型在提出的MBE基准和公共数据集上都表现出竞争力的零样本性能，在跨模态检索、产品分类和属性预测等各种下游任务中展现出强大的泛化能力。

Conclusion: MOON模型通过创新的多模态建模方法有效解决了产品表示学习中的关键挑战，为产品理解任务提供了强大的生成式解决方案，并通过案例研究和可视化验证了其有效性。

Abstract: With the rapid advancement of e-commerce, exploring general representations
rather than task-specific ones has attracted increasing research attention. For
product understanding, although existing discriminative dual-flow architectures
drive progress in this field, they inherently struggle to model the many-to-one
alignment between multiple images and texts of products. Therefore, we argue
that generative Multimodal Large Language Models (MLLMs) hold significant
potential for improving product representation learning. Nevertheless,
achieving this goal still remains non-trivial due to several key challenges:
the lack of multimodal and aspect-aware modeling modules in typical LLMs; the
common presence of background noise in product images; and the absence of a
standard benchmark for evaluation. To address these issues, we propose the
first generative MLLM-based model named MOON for product representation
learning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for
targeted modeling of multimodal and aspect-specific product content; (2)
effectively detects core semantic regions in product images to mitigate the
distraction and interference caused by background noise; and (3) introduces the
specialized negative sampling strategy to increase the difficulty and diversity
of negative samples. In addition, we release a large-scale multimodal benchmark
MBE for various product understanding tasks. Experimentally, our model
demonstrates competitive zero-shot performance on both our benchmark and the
public dataset, showcasing strong generalization across various downstream
tasks, including cross-modal retrieval, product classification, and attribute
prediction. Furthermore, the case study and visualization illustrate the
effectiveness of MOON for product understanding.

</details>


### [18] [A Sobel-Gradient MLP Baseline for Handwritten Character Recognition](https://arxiv.org/abs/2508.11902)
*Azam Nouri*

Main category: cs.CV

TL;DR: 使用Sobel算子提取的一阶边缘特征作为输入，全连接MLP网络在手写字符识别任务上能达到接近CNN的性能，表明一阶梯度已包含足够的分类判别信息


<details>
  <summary>Details</summary>
Motivation: 探索是否仅使用一阶边缘特征就能驱动MLP网络在手写字符识别任务上达到与CNN相当的性能，作为CNN的轻量级替代方案

Method: 使用水平和垂直Sobel导数作为输入特征，训练全连接多层感知机(MLP)在MNIST和EMNIST Letters数据集上进行手写字符识别

Result: 在MNIST数字数据集上达到98%准确率，在EMNIST字母数据集上达到92%准确率，接近CNN性能但具有更小的内存占用和更透明的特征

Conclusion: 一阶梯度已经包含了手写字符图像中大部分类别判别信息，基于边缘感知的MLP是手写字符识别的一个有吸引力的选择

Abstract: We revisit the classical Sobel operator to ask a simple question: Are
first-order edge maps sufficient to drive an all-dense multilayer perceptron
(MLP) for handwritten character recognition (HCR), as an alternative to
convolutional neural networks (CNNs)? Using only horizontal and vertical Sobel
derivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its
extreme simplicity, the resulting network reaches 98% accuracy on MNIST digits
and 92% on EMNIST letters -- approaching CNNs while offering a smaller memory
footprint and transparent features. Our findings highlight that much of the
class-discriminative information in handwritten character images is already
captured by first-order gradients, making edge-aware MLPs a compelling option
for HCR.

</details>


### [19] [OVG-HQ: Online Video Grounding with Hybrid-modal Queries](https://arxiv.org/abs/2508.11903)
*Runhao Zeng,Jiaqi Mao,Minghao Lai,Minh Hieu Phan,Yanjie Dong,Wei Wang,Qi Chen,Xiping Hu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的在线视频基准任务OVG-HQ，能够处理混合模态查询（文本、图像、视频等），并解决了在线设置下的上下文限制和模态不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统视频基准方法在流式视频和视觉类查询场景下表现局限，需要一种能够处理多模态查询的在线方案。

Method: 提出OVG-HQ-Unify统一框架，包含参数化记忆块(PMB)保留历史知识，以及跨模态荟蓄策略平衡不同模态的学习。构建了QVHighlights-Unify多模态数据集。

Result: 实验结果显示OVG-HQ-Unify在准确性和效率方面都超过现有模型，为在线混合模态视频基准提供了稳健解决方案。

Conclusion: 该研究成功开拓了在线混合模态视频基准新领域，提出的方法和评估指标有力地解决了该领域的关键挑战。

Abstract: Video grounding (VG) task focuses on locating specific moments in a video
based on a query, usually in text form. However, traditional VG struggles with
some scenarios like streaming video or queries using visual cues. To fill this
gap, we present a new task named Online Video Grounding with Hybrid-modal
Queries (OVG-HQ), which enables online segment localization using text, images,
video segments, and their combinations. This task poses two new challenges:
limited context in online settings and modality imbalance during training,
where dominant modalities overshadow weaker ones. To address these, we propose
OVG-HQ-Unify, a unified framework featuring a Parametric Memory Block (PMB)
that retain previously learned knowledge to enhance current decision and a
cross-modal distillation strategy that guides the learning of non-dominant
modalities. This design enables a single model to effectively handle
hybrid-modal queries. Due to the lack of suitable datasets, we construct
QVHighlights-Unify, an expanded dataset with multi-modal queries. Besides,
since offline metrics overlook prediction timeliness, we adapt them to the
online setting, introducing oR@n, IoU=m, and online mean Average Precision
(omAP) to evaluate both accuracy and efficiency. Experiments show that our
OVG-HQ-Unify outperforms existing models, offering a robust solution for
online, hybrid-modal video grounding. Source code and datasets are available at
https://github.com/maojiaqi2324/OVG-HQ.

</details>


### [20] [SafeCtrl: Region-Based Safety Control for Text-to-Image Diffusion via Detect-Then-Suppress](https://arxiv.org/abs/2508.11904)
*Lingyun Zhang,Yu Xie,Yanwei Fu,Ping Chen*

Main category: cs.CV

TL;DR: SafeCtrl是一个轻量级非侵入式插件，通过检测-抑制范式来提升文本到图像模型的安全性，在保持高保真度的同时有效抑制有害内容生成。


<details>
  <summary>Details</summary>
Motivation: 现有安全方法在安全性和保真度之间存在权衡，基于概念替换的定位方法可能导致语义不连贯，需要更灵活的解决方案。

Method: 采用检测-抑制范式，首先精确定位不安全内容，然后抑制有害语义而非硬性替换，使用DPO训练策略利用图像级偏好数据学习抑制行为。

Result: 在安全有效性和保真度保持方面显著优于最先进方法，证明了分离式抑制控制的优越性。

Conclusion: 解耦的基于抑制的控制是构建更负责任生成模型的高效且可扩展方向。

Abstract: The widespread deployment of text-to-image models is challenged by their
potential to generate harmful content. While existing safety methods, such as
prompt rewriting or model fine-tuning, provide valuable interventions, they
often introduce a trade-off between safety and fidelity. Recent
localization-based approaches have shown promise, yet their reliance on
explicit ``concept replacement" can sometimes lead to semantic incongruity. To
address these limitations, we explore a more flexible detect-then-suppress
paradigm. We introduce SafeCtrl, a lightweight, non-intrusive plugin that first
precisely localizes unsafe content. Instead of performing a hard A-to-B
substitution, SafeCtrl then suppresses the harmful semantics, allowing the
generative process to naturally and coherently resolve into a safe,
context-aware alternative. A key aspect of our work is a novel training
strategy using Direct Preference Optimization (DPO). We leverage readily
available, image-level preference data to train our module, enabling it to
learn nuanced suppression behaviors and perform region-guided interventions at
inference without requiring costly, pixel-level annotations. Extensive
experiments show that SafeCtrl significantly outperforms state-of-the-art
methods in both safety efficacy and fidelity preservation. Our findings suggest
that decoupled, suppression-based control is a highly effective and scalable
direction for building more responsible generative models.

</details>


### [21] [TimeSenCLIP: A Vision-Language Model for Remote Sensing Using Single-Pixel Time Series](https://arxiv.org/abs/2508.11919)
*Pallavi Jain,Diego Marcos,Dino Ienco,Roberto Interdonato,Tristan Berchoux*

Main category: cs.CV

TL;DR: TimeSenCLIP是一个轻量级框架，通过利用单个像素的时空和光谱信息进行土地利用分类，减少了对大空间瓦片和文本监督的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在遥感应用中面临两个关键挑战：依赖大空间瓦片增加计算成本，以及依赖文本监督但文本数据往往不易获得。

Method: 利用Sentinel-2影像的光谱和时间信息，结合地理标记的地面照片进行跨视角学习，最小化基于标题的训练需求，同时保持卫星和地面视角之间的语义对齐。

Result: 实验证明，单个像素输入结合时空和光谱线索足以进行专题制图，为大规模遥感应用提供了可扩展且高效的替代方案。

Conclusion: 该方法展示了在减少计算成本和文本依赖的同时，仍能有效进行土地利用和生态系统分类，为遥感应用提供了新的轻量级解决方案。

Abstract: Vision-language models have shown significant promise in remote sensing
applications, particularly for land-use and land-cover (LULC) via zero-shot
classification and retrieval. However, current approaches face two key
challenges: reliance on large spatial tiles that increase computational cost,
and dependence on text-based supervision, which is often not readily available.
In this work, we present TimeSenCLIP, a lightweight framework that reevaluate
the role of spatial context by evaluating the effectiveness of a single pixel
by leveraging its temporal and spectral dimensions, for classifying LULC and
ecosystem types. By leveraging spectral and temporal information from
Sentinel-2 imagery and cross-view learning with geo-tagged ground-level photos,
we minimises the need for caption-based training while preserving semantic
alignment between overhead (satellite) and ground perspectives. Our approach is
grounded in the LUCAS and Sen4Map datasets, and evaluated on classification
tasks including LULC, crop type, and ecosystem type. We demonstrate that single
pixel inputs, when combined with temporal and spectral cues, are sufficient for
thematic mapping, offering a scalable and efficient alternative for large-scale
remote sensing applications. Code is available at
https://github.com/pallavijain-pj/TimeSenCLIP

</details>


### [22] [Assessment of Using Synthetic Data in Brain Tumor Segmentation](https://arxiv.org/abs/2508.11922)
*Aditi Jahagirdar,Sameer Joshi*

Main category: cs.CV

TL;DR: 使用GAN生成的合成MRI数据来补充真实数据进行脑罐分割训练，在整体性能上与真实数据相当，但在边界划分上有所改善，虽然对肿瘤核心的分割仍有限制。


<details>
  <summary>Details</summary>
Motivation: 解决脑罐异质性、标注数据稀缺和类别不平衡等医学图像分割挑战，通过生成式模型产生合成数据来提升数据集多样性。

Method: 使用预训练GAN模型生成合成MRI数据，将真实数据(BraTS 2020)与合成数据(medigan库)按不同比例混合，训练U-Net分割网络进行对比实验。

Result: 整体量化指标(Dice系数、IoU等)在真实数据与混合数据间相似，但定性分析显示40%真实+60%合成的混合数据改善了整体肿瘤边界划分。但肿瘤核心和增强肿瘤区域的分割准确性仍较低。

Conclusion: 合成数据作为数据增强策略在脑罐分割中具有可行性，但需要进一步解决类别不平衡问题、进行更大规模实验和确保体积数据一致性。

Abstract: Manual brain tumor segmentation from MRI scans is challenging due to tumor
heterogeneity, scarcity of annotated data, and class imbalance in medical
imaging datasets. Synthetic data generated by generative models has the
potential to mitigate these issues by improving dataset diversity. This study
investigates, as a proof of concept, the impact of incorporating synthetic MRI
data, generated using a pre-trained GAN model, into training a U-Net
segmentation network. Experiments were conducted using real data from the BraTS
2020 dataset, synthetic data generated with the medigan library, and hybrid
datasets combining real and synthetic samples in varying proportions. While
overall quantitative performance (Dice coefficient, IoU, precision, recall,
accuracy) was comparable between real-only and hybrid-trained models,
qualitative inspection suggested that hybrid datasets, particularly with 40%
real and 60% synthetic data, improved whole tumor boundary delineation.
However, region-wise accuracy for the tumor core and the enhancing tumor
remained lower, indicating a persistent class imbalance. The findings support
the feasibility of synthetic data as an augmentation strategy for brain tumor
segmentation, while highlighting the need for larger-scale experiments,
volumetric data consistency, and mitigating class imbalance in future work.

</details>


### [23] [Deep Learning For Point Cloud Denoising: A Survey](https://arxiv.org/abs/2508.11932)
*Chengwei Zhang,Xueyi Zhang,Mingrui Lao,Tao Jiang,Xinhao Xu,Wenjie Li,Fubo Zhang,Longyong Chen*

Main category: cs.CV

TL;DR: 这篇论文是一个关于深度学习基于点云去噪的综述性研究，系统总结了该领域的发展状况、分类法和未来方向。


<details>
  <summary>Details</summary>
Motivation: 实际环境中的点云数据存在各种模态和强度的噪声，点云去噪作为预处理步骤对下游任务致关重要。虽然深度学习方法在去噪性能上超越传统方法，但缺乏系统的综述性研究来总结该领域的发展。

Method: 将点云去噪模型化为两个步骤：离群点移除和表面噪声恢复。提出了一种专门为去噪任务设计的分类法，并对现有方法进行了详细的相似性、差异性和优势比较。

Result: 该研究系统地总结了深度学习基于点云去噪的关键挑战和现有方法的主要贡献，提供了一个结构化的分类框架来理解和组织该领域的研究成果。

Conclusion: 论文讨论了当前研究的限制和未来发展方向，为点云去噪领域的进一步发展提供了见解和建议。

Abstract: Real-world environment-derived point clouds invariably exhibit noise across
varying modalities and intensities. Hence, point cloud denoising (PCD) is
essential as a preprocessing step to improve downstream task performance. Deep
learning (DL)-based PCD models, known for their strong representation
capabilities and flexible architectures, have surpassed traditional methods in
denoising performance. To our best knowledge, despite recent advances in
performance, no comprehensive survey systematically summarizes the developments
of DL-based PCD. To fill the gap, this paper seeks to identify key challenges
in DL-based PCD, summarizes the main contributions of existing methods, and
proposes a taxonomy tailored to denoising tasks. To achieve this goal, we
formulate PCD as a two-step process: outlier removal and surface noise
restoration, encompassing most scenarios and requirements of PCD. Additionally,
we compare methods in terms of similarities, differences, and respective
advantages. Finally, we discuss research limitations and future directions,
offering insights for further advancements in PCD.

</details>


### [24] [DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects](https://arxiv.org/abs/2508.11950)
*Tingbang Liang,Yixin Zeng,Jiatong Xie,Boyu Zhou*

Main category: cs.CV

TL;DR: DynamicPose是一个无需重新训练的6D姿态跟踪框架，专门针对快速移动的相机和物体场景，通过视觉惯性里程计、深度信息2D跟踪器和VIO引导的卡尔曼滤波器实现鲁棒跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要适用于静态或准静态场景，在相机和物体都快速移动时性能显著下降，需要解决快速运动场景下的6D姿态跟踪问题。

Method: 提出三个协同组件：1）视觉惯性里程计补偿相机运动引起的ROI偏移；2）深度信息2D跟踪器校正大物体平移引起的ROI偏差；3）VIO引导的卡尔曼滤波器预测物体旋转并生成候选姿态进行分层细化。

Result: 仿真和真实世界实验证明了方法的有效性，能够实现快速移动相机和物体的实时鲁棒6D姿态跟踪。

Conclusion: 该方法形成了闭环系统，确保准确的姿态初始化和精确的姿态跟踪，在快速运动场景中表现出色。

Abstract: We present DynamicPose, a retraining-free 6D pose tracking framework that
improves tracking robustness in fast-moving camera and object scenarios.
Previous work is mainly applicable to static or quasi-static scenes, and its
performance significantly deteriorates when both the object and the camera move
rapidly. To overcome these challenges, we propose three synergistic components:
(1) A visual-inertial odometry compensates for the shift in the Region of
Interest (ROI) caused by camera motion; (2) A depth-informed 2D tracker
corrects ROI deviations caused by large object translation; (3) A VIO-guided
Kalman filter predicts object rotation, generates multiple candidate poses, and
then obtains the final pose by hierarchical refinement. The 6D pose tracking
results guide subsequent 2D tracking and Kalman filter updates, forming a
closed-loop system that ensures accurate pose initialization and precise pose
tracking. Simulation and real-world experiments demonstrate the effectiveness
of our method, achieving real-time and robust 6D pose tracking for fast-moving
cameras and objects.

</details>


### [25] [Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection](https://arxiv.org/abs/2508.11951)
*Hao Peng,Hong Sang,Yajing Ma,Ping Qiu,Chao Ji*

Main category: cs.CV

TL;DR: 这篇论文通过知识萌发近似点云多尺度特征，设计可转移特征嵌入机制，并使用中心加权IoU来提升目标检测的效果和效率。


<details>
  <summary>Details</summary>
Motivation: 多尺度特征对点云目标检测至关重要，但传统方法需要多次邻域搜索和多尺度层，计算成本高，不利于轻量级模型开发和计算资源有限的研究。

Method: 基于知识萌发从单一邻域近似点基多尺度特征；设计以类别统计为基础的可转移特征嵌入机制；引入中心加权IoU来缓解优化中的中心偏移问题。

Result: 在公开数据集上进行了广泛实验，证明了所提方法的有效性，同时节省了计算成本。

Conclusion: 该方法通过近似多尺度特征学习和可转移特征嵌入，在保持检测性能的同时显著降低计算复杂度，适用于轻量级模型和计算资源有限的场景。

Abstract: This paper investigates multi-scale feature approximation and transferable
features for object detection from point clouds. Multi-scale features are
critical for object detection from point clouds. However, multi-scale feature
learning usually involves multiple neighborhood searches and scale-aware
layers, which can hinder efforts to achieve lightweight models and may not be
conducive to research constrained by limited computational resources. This
paper approximates point-based multi-scale features from a single neighborhood
based on knowledge distillation. To compensate for the loss of constructive
diversity in a single neighborhood, this paper designs a transferable feature
embedding mechanism. Specifically, class-aware statistics are employed as
transferable features given the small computational cost. In addition, this
paper introduces the central weighted intersection over union for localization
to alleviate the misalignment brought by the center offset in optimization.
Note that the method presented in this paper saves computational costs.
Extensive experiments on public datasets demonstrate the effectiveness of the
proposed method.

</details>


### [26] [UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding](https://arxiv.org/abs/2508.11952)
*Yueming Xu,Jiahui Zhang,Ze Huang,Yurui Chen,Yanpeng Zhou,Zhenyu Chen,Yu-Jie Yuan,Pengxiang Xia,Guowei Huang,Xinyue Cai,Zhongang Qi,Xingyue Quan,Jianye Hao,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: UniUGG是首个统一理解和生成3D模态的框架，使用LLM理解和解码句子与3D表示，通过潜在扩散模型生成高质量3D内容，支持基于参考图像和任意视角变换的3D场景生成与想象，同时保持空间视觉问答能力。


<details>
  <summary>Details</summary>
Motivation: 尽管近期统一架构在图像理解和生成方面取得了显著进展，但3D任务的整合仍然具有挑战性且探索不足，需要开发能够同时处理3D理解和生成的统一框架。

Method: 提出UniUGG统一框架，使用LLM处理语言和3D表示，核心是采用潜在扩散模型的空间解码器来生成3D表示，并提出几何-语义学习策略来预训练视觉编码器，联合捕获输入的语义和几何线索。

Result: 大量实验结果表明，该方法在视觉表示、空间理解和3D生成方面具有优越性能。

Conclusion: UniUGG成功实现了3D模态的统一理解和生成，通过创新的空间解码器和几何-语义学习策略，在多个3D任务上表现出色，为3D多模态学习提供了有效的解决方案。

Abstract: Despite the impressive progress on understanding and generating images shown
by the recent unified architectures, the integration of 3D tasks remains
challenging and largely unexplored. In this paper, we introduce UniUGG, the
first unified understanding and generation framework for 3D modalities. Our
unified framework employs an LLM to comprehend and decode sentences and 3D
representations. At its core, we propose a spatial decoder leveraging a latent
diffusion model to generate high-quality 3D representations. This allows for
the generation and imagination of 3D scenes based on a reference image and an
arbitrary view transformation, while remaining supports for spatial visual
question answering (VQA) tasks. Additionally, we propose a geometric-semantic
learning strategy to pretrain the vision encoder. This design jointly captures
the input's semantic and geometric cues, enhancing both spatial understanding
and generation. Extensive experimental results demonstrate the superiority of
our method in visual representation, spatial understanding, and 3D generation.
The source code will be released upon paper acceptance.

</details>


### [27] [SAMDWICH: Moment-aware Video-text Alignment for Referring Video Object Segmentation](https://arxiv.org/abs/2508.11955)
*Seunghun Lee,Jiwan Seo,Jeonghoon Kim,Siwon Kim,Haeun Yun,Hyogyeong Jeon,Wonhyeok Choi,Jaehoon Jeong,Zane Durante,Sang Hyun Park,Sunghoon Im*

Main category: cs.CV

TL;DR: SAMDWICH是一个面向Referring Video Object Segmentation (RVOS)的moment-aware框架，通过引入时间标注和选择性监督来解决语义对齐问题，在MeViS基准测试中达到state-of-the-art性能。


<details>
  <summary>Details</summary>
Motivation: 现有RVOS方法存在语义错位问题，主要原因是训练时对所有可见对象进行无差别帧采样和监督，而不考虑它们与文本查询的实际相关性。

Method: 提出SAMDWICH框架，包含：1）新标注数据集MeViS-M，手动标注对象被文本表达引用的时间片段；2）Moment-guided Dual-path Propagation (MDP)策略，通过moment-centric内存机制改善对象定位和跟踪；3）Object-level Selective Supervision (OSS)策略，只监督与表达时间对齐的对象。

Result: 在具有挑战性的MeViS基准测试中实现了state-of-the-art性能，特别是在涉及多样化表达的复杂场景中表现优异。

Conclusion: 通过引入时间感知的监督和传播策略，SAMDWICH有效解决了RVOS中的语义对齐问题，显著提升了视频-文本对齐质量和参考理解能力。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment and track objects
in videos based on natural language expressions, requiring precise alignment
between visual content and textual queries. However, existing methods often
suffer from semantic misalignment, largely due to indiscriminate frame sampling
and supervision of all visible objects during training -- regardless of their
actual relevance to the expression. To address this, we introduce a
moment-aware RVOS framework named SAMDWICH, along with a newly annotated
dataset, MeViS-M, built upon the challenging MeViS benchmark. We manually
annotate temporal moments indicating when each object is referred to by the
expression, enabling semantically grounded supervision that strengthens
video-text alignment. SAMDWICH leverages these aligned text-to-clip pairs to
guide training, significantly enhancing referential understanding. Building
upon this framework, we propose Moment-guided Dual-path Propagation (MDP), a
moment-aware propagation strategy that improves both object grounding and
tracking by training on both relevant and irrelevant frames through a
moment-centric memory mechanism. In addition, we introduce Object-level
Selective Supervision (OSS), an object-level filtering strategy that supervises
only the objects temporally aligned with the expression in each training clip.
This selective supervision reduces semantic noise and reinforces
language-conditioned learning. Extensive experiments show that SAMDWICH
achieves state-of-the-art performance on challenging MeViS benchmark,
particularly excelling in complex scenarios involving diverse expressions.

</details>


### [28] [PEdger++: Practical Edge Detection via Assembling Cross Information](https://arxiv.org/abs/2508.11961)
*Yuanbin Fu,Liang Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: PEdger++是一个协作学习框架，通过异构架构、多样化训练时刻和多参数采样的跨信息来提升边缘检测性能，在保持高精度的同时显著降低计算成本和模型大小。


<details>
  <summary>Details</summary>
Motivation: 边缘检测在计算机视觉中至关重要，但现有深度学习方法计算成本高，难以在资源受限设备上部署。需要平衡高精度和低计算复杂度。

Method: 提出PEdger++协作学习框架，利用异构架构、多样化训练时刻和多参数采样的跨信息，从集成学习角度增强特征学习能力。

Result: 在BSDS500、NYUD和Multicue数据集上的实验表明，该方法在定量和定性评估上都优于现有方法，并提供多个不同计算需求的模型版本。

Conclusion: PEdger++成功实现了边缘检测精度和计算效率的平衡，具有很好的适应性，代码已开源。

Abstract: Edge detection serves as a critical foundation for numerous computer vision
applications, including object detection, semantic segmentation, and image
editing, by extracting essential structural cues that define object boundaries
and salient edges. To be viable for broad deployment across devices with
varying computational capacities, edge detectors shall balance high accuracy
with low computational complexity. While deep learning has evidently improved
accuracy, they often suffer from high computational costs, limiting their
applicability on resource-constrained devices. This paper addresses the
challenge of achieving that balance: \textit{i.e.}, {how to efficiently capture
discriminative features without relying on large-size and sophisticated
models}. We propose PEdger++, a collaborative learning framework designed to
reduce computational costs and model sizes while improving edge detection
accuracy. The core principle of our PEdger++ is that cross-information derived
from heterogeneous architectures, diverse training moments, and multiple
parameter samplings, is beneficial to enhance learning from an ensemble
perspective. Extensive experimental results on the BSDS500, NYUD and Multicue
datasets demonstrate the effectiveness of our approach, both quantitatively and
qualitatively, showing clear improvements over existing methods. We also
provide multiple versions of the model with varying computational requirements,
highlighting PEdger++'s adaptability with respect to different resource
constraints. Codes are accessible at
https://github.com/ForawardStar/EdgeDetectionviaPEdgerPlus/.

</details>


### [29] [Exploring Spatial-Temporal Dynamics in Event-based Facial Micro-Expression Analysis](https://arxiv.org/abs/2508.11988)
*Nicolas Mastropasqua,Ignacio Bugueno-Cordova,Rodrigo Verschae,Daniel Acevedo,Pablo Negri,Maria E. Buemi*

Main category: cs.CV

TL;DR: 本文提出了一个新的多分辨率多模态微表情数据集，使用同步RGB和事件相机在可变光照条件下录制，展示了事件相机在微表情识别和帧重建任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 微表情分析在人机交互和驾驶员监控系统中有重要应用，但传统RGB相机在时间分辨率和运动模糊方面存在限制，难以准确捕捉细微快速的面部运动。事件相机具有微秒级精度、高动态范围和低延迟的优势，但缺乏公开的事件数据数据集。

Method: 引入了一个新颖的多分辨率多模态微表情数据集，使用同步RGB和事件相机在可变光照条件下录制。评估了两个基线任务：使用脉冲神经网络进行动作单元分类，以及使用条件变分自编码器进行帧重建。

Result: 动作单元分类任务中，事件数据达到51.23%的准确率，显著优于RGB数据的23.12%。帧重建任务中，高分辨率事件输入达到了SSIM=0.8513和PSNR=26.89dB的优秀指标。

Conclusion: 事件相机数据在微表情识别和帧重建方面表现出色，证明了事件相机在捕捉细微面部运动方面的优势，为微表情分析提供了新的技术途径。

Abstract: Micro-expression analysis has applications in domains such as Human-Robot
Interaction and Driver Monitoring Systems. Accurately capturing subtle and fast
facial movements remains difficult when relying solely on RGB cameras, due to
limitations in temporal resolution and sensitivity to motion blur. Event
cameras offer an alternative, with microsecond-level precision, high dynamic
range, and low latency. However, public datasets featuring event-based
recordings of Action Units are still scarce. In this work, we introduce a
novel, preliminary multi-resolution and multi-modal micro-expression dataset
recorded with synchronized RGB and event cameras under variable lighting
conditions. Two baseline tasks are evaluated to explore the spatial-temporal
dynamics of micro-expressions: Action Unit classification using Spiking Neural
Networks (51.23\% accuracy with events vs. 23.12\% with RGB), and frame
reconstruction using Conditional Variational Autoencoders, achieving SSIM =
0.8513 and PSNR = 26.89 dB with high-resolution event input. These promising
results show that event-based data can be used for micro-expression recognition
and frame reconstruction.

</details>


### [30] [InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2508.12015)
*Hongyuan Liu,Haochen Yu,Jianfei Jiang,Qiankun Liu,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: InstDrive是一个针对动态驾驶场景的实例感知3D高斯泼溅框架，通过SAM生成的掩码作为伪真值指导2D特征学习，并在3D层面引入正则化和一致性约束，实现了无需数据预处理的3D实例分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法将背景元素统一为单一表示，阻碍了实例级理解和灵活场景编辑；现有2D到3D的分割方法依赖预处理实例ID或复杂流程，且主要针对室内场景，不适用于室外驾驶场景。

Method: 使用SAM生成的掩码作为伪真值，通过对比损失和伪监督目标指导2D特征学习；在3D层面引入正则化隐式编码实例身份，通过体素损失强制一致性；使用轻量级静态码桥连接连续特征和离散身份。

Result: 定量和定性实验证明了InstDrive的有效性，据我们所知，这是第一个在动态开放世界驾驶场景中实现3D实例分割的框架。

Conclusion: InstDrive成功解决了动态驾驶场景中实例级3D重建的挑战，无需复杂预处理即可实现高质量的实例分割和场景编辑能力。

Abstract: Reconstructing dynamic driving scenes from dashcam videos has attracted
increasing attention due to its significance in autonomous driving and scene
understanding. While recent advances have made impressive progress, most
methods still unify all background elements into a single representation,
hindering both instance-level understanding and flexible scene editing. Some
approaches attempt to lift 2D segmentation into 3D space, but often rely on
pre-processed instance IDs or complex pipelines to map continuous features to
discrete identities. Moreover, these methods are typically designed for indoor
scenes with rich viewpoints, making them less applicable to outdoor driving
scenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian
Splatting framework tailored for the interactive reconstruction of dynamic
driving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D
feature learning via contrastive loss and pseudo-supervised objectives. At the
3D level, we introduce regularization to implicitly encode instance identities
and enforce consistency through a voxel-based loss. A lightweight static
codebook further bridges continuous features and discrete identities without
requiring data pre-processing or complex optimization. Quantitative and
qualitative experiments demonstrate the effectiveness of InstDrive, and to the
best of our knowledge, it is the first framework to achieve 3D instance
segmentation in dynamic, open-world driving scenes.More visualizations are
available at our project page.

</details>


### [31] [WiseLVAM: A Novel Framework For Left Ventricle Automatic Measurements](https://arxiv.org/abs/2508.12023)
*Durgesh Kumar Singh,Qing Cao,Sarina Thomas,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: WiseLVAM是一个全自动的左心室线性测量框架，通过结合B超图像的结构感知和AMM模式的运动感知，自动放置虚拟扫描线并进行测量，提高临床可靠性


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法直接从B超图像估计地标点进行测量，即使沿心室壁的小偏移也会导致显著测量误差，降低临床可靠性

Method: 提出轮廓感知的扫描线放置方法：使用弱监督B超地标检测器估计左心室轮廓，推断左心室长轴和基底水平来放置扫描线，然后在AMM模式下自动进行线性测量

Result: 该方法结合了B超图像的结构感知和AMM模式的运动感知，增强了鲁棒性和准确性

Conclusion: WiseLVAM有潜力为常规临床应用提供实用解决方案，实现全自动化且可手动调整的左心室线性测量

Abstract: Clinical guidelines recommend performing left ventricular (LV) linear
measurements in B-mode echocardiographic images at the basal level -- typically
at the mitral valve leaflet tips -- and aligned perpendicular to the LV long
axis along a virtual scanline (SL). However, most automated methods estimate
landmarks directly from B-mode images for the measurement task, where even
small shifts in predicted points along the LV walls can lead to significant
measurement errors, reducing their clinical reliability. A recent
semi-automatic method, EnLVAM, addresses this limitation by constraining
landmark prediction to a clinician-defined SL and training on generated
Anatomical Motion Mode (AMM) images to predict LV landmarks along the same. To
enable full automation, a contour-aware SL placement approach is proposed in
this work, in which the LV contour is estimated using a weakly supervised
B-mode landmark detector. SL placement is then performed by inferring the LV
long axis and the basal level-mimicking clinical guidelines. Building on this
foundation, we introduce \textit{WiseLVAM} -- a novel, fully automated yet
manually adaptable framework for automatically placing the SL and then
automatically performing the LV linear measurements in the AMM mode.
\textit{WiseLVAM} utilizes the structure-awareness from B-mode images and the
motion-awareness from AMM mode to enhance robustness and accuracy with the
potential to provide a practical solution for the routine clinical application.

</details>


### [32] [Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2508.12036)
*Rakesh Thakur,Yusra Tariq*

Main category: cs.CV

TL;DR: Q-FSRU是一个结合频域特征提取和量子检索增强生成的医疗视觉问答模型，在VQA-RAD数据集上表现优异


<details>
  <summary>Details</summary>
Motivation: 解决需要同时理解图像和文本的复杂临床问题仍然是医疗AI的主要挑战，需要更准确和可解释的模型

Method: 使用FFT将医学图像和文本特征转换到频域提取重要信息，结合量子检索系统从外部知识源获取医学事实，最后融合进行推理

Result: 在VQA-RAD数据集上超越了之前的模型，特别是在需要图像-文本推理的复杂案例中表现突出

Conclusion: 频域和量子信息的结合提高了性能和可解释性，为构建智能、清晰、有用的医疗AI工具提供了有前景的方法

Abstract: Solving tough clinical questions that require both image and text
understanding is still a major challenge in healthcare AI. In this work, we
propose Q-FSRU, a new model that combines Frequency Spectrum Representation and
Fusion (FSRU) with a method called Quantum Retrieval-Augmented Generation
(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in
features from medical images and related text, then shifts them into the
frequency domain using Fast Fourier Transform (FFT). This helps it focus on
more meaningful data and filter out noise or less useful information. To
improve accuracy and ensure that answers are based on real knowledge, we add a
quantum-inspired retrieval system. It fetches useful medical facts from
external sources using quantum-based similarity techniques. These details are
then merged with the frequency-based features for stronger reasoning. We
evaluated our model using the VQA-RAD dataset, which includes real radiology
images and questions. The results showed that Q-FSRU outperforms earlier
models, especially on complex cases needing image-text reasoning. The mix of
frequency and quantum information improves both performance and explainability.
Overall, this approach offers a promising way to build smart, clear, and
helpful AI tools for doctors.

</details>


### [33] [VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models](https://arxiv.org/abs/2508.12081)
*Haidong Xu,Guangwei Xu,Zhedong Zheng,Xiatian Zhu,Wei Ji,Xiangtai Li,Ruijie Guo,Meishan Zhang,Min zhang,Hao Fei*

Main category: cs.CV

TL;DR: VimoRAG是一个基于视频检索增强的运动生成框架，通过从大规模视频数据库中检索相关2D人体运动信号来解决运动大语言模型的数据稀缺问题，显著提升了仅基于文本输入的运动生成性能。


<details>
  <summary>Details</summary>
Motivation: 运动大语言模型由于标注数据有限而面临严重的域外/词汇外问题，需要利用大规模野外视频数据来增强3D运动生成能力。

Method: 设计了Gemini Motion Video Retriever机制进行有效的运动中心视频检索，以及Motion-centric Dual-alignment DPO Trainer来缓解检索结果不佳导致的错误传播问题。

Result: 实验结果表明，VimoRAG显著提升了仅基于文本输入的运动大语言模型的性能。

Conclusion: VimoRAG框架通过视频检索增强的方式有效解决了运动生成中的数据稀缺问题，为运动大语言模型提供了新的增强途径。

Abstract: This paper introduces VimoRAG, a novel video-based retrieval-augmented motion
generation framework for motion large language models (LLMs). As motion LLMs
face severe out-of-domain/out-of-vocabulary issues due to limited annotated
data, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D
motion generation by retrieving relevant 2D human motion signals. While
video-based motion RAG is nontrivial, we address two key bottlenecks: (1)
developing an effective motion-centered video retrieval model that
distinguishes human poses and actions, and (2) mitigating the issue of error
propagation caused by suboptimal retrieval results. We design the Gemini Motion
Video Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,
enabling effective retrieval and generation processes. Experimental results
show that VimoRAG significantly boosts the performance of motion LLMs
constrained to text-only input.

</details>


### [34] [Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity](https://arxiv.org/abs/2508.12082)
*Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee*

Main category: cs.CV

TL;DR: 自动化对识检测器性能评估框架，通过预测一致性和可靠性指标（PCR）来估计检测性能，无需人工标注


<details>
  <summary>Details</summary>
Motivation: 解决对识检测器在实际应用中性能评估依赖成本高昂的人工标注问题

Method: 提出PCR指标，聚合测量NMS前后框的空间一致性和保留框的信心度可靠性，构建包含不同严重程度图像腐化的元数据集

Result: PCR在自动评估中比现有方法更准确，构建的元数据集覆盖更广泛的检测性能范围

Conclusion: 该框架能够有效减少对人工标注的依赖，提供更实用和可扩展的对识检测器性能评估方法

Abstract: Recent advances in computer vision have made training object detectors more
efficient and effective; however, assessing their performance in real-world
applications still relies on costly manual annotation. To address this
limitation, we develop an automated model evaluation (AutoEval) framework for
object detection. We propose Prediction Consistency and Reliability (PCR),
which leverages the multiple candidate bounding boxes that conventional
detectors generate before non-maximum suppression (NMS). PCR estimates
detection performance without ground-truth labels by jointly measuring 1) the
spatial consistency between boxes before and after NMS, and 2) the reliability
of the retained boxes via the confidence scores of overlapping boxes. For a
more realistic and scalable evaluation, we construct a meta-dataset by applying
image corruptions of varying severity. Experimental results demonstrate that
PCR yields more accurate performance estimates than existing AutoEval methods,
and the proposed meta-dataset covers a wider range of detection performance.
The code is available at https://github.com/YonseiML/autoeval-det.

</details>


### [35] [Generic Event Boundary Detection via Denoising Diffusion](https://arxiv.org/abs/2508.12084)
*Jaejun Hwang,Dayoung Gong,Manjin Kim,Minsu Cho*

Main category: cs.CV

TL;DR: DiffGEBD是一个基于扩散模型的通用事件边界检测方法，通过生成式视角解决事件边界多样性问题，使用分类器自由引导控制多样性，在Kinetics-GEBD和TAPOS基准上表现优异


<details>
  <summary>Details</summary>
Motivation: 传统方法专注于确定性预测，忽视了事件边界检测中存在的合理解决方案多样性问题，需要从生成式角度处理这种主观性

Method: 提出扩散模型DiffGEBD，通过时间自相似性编码相邻帧间变化，然后迭代地将随机噪声解码为合理的事件边界，使用分类器自由引导控制多样性

Result: 在两个标准基准Kinetics-GEBD和TAPOS上实现了强劲性能，能够生成多样且合理的事件边界

Conclusion: 扩散模型为通用事件边界检测提供了有效的生成式解决方案，能够处理边界检测的主观性和多样性问题

Abstract: Generic event boundary detection (GEBD) aims to identify natural boundaries
in a video, segmenting it into distinct and meaningful chunks. Despite the
inherent subjectivity of event boundaries, previous methods have focused on
deterministic predictions, overlooking the diversity of plausible solutions. In
this paper, we introduce a novel diffusion-based boundary detection model,
dubbed DiffGEBD, that tackles the problem of GEBD from a generative
perspective. The proposed model encodes relevant changes across adjacent frames
via temporal self-similarity and then iteratively decodes random noise into
plausible event boundaries being conditioned on the encoded features.
Classifier-free guidance allows the degree of diversity to be controlled in
denoising diffusion. In addition, we introduce a new evaluation metric to
assess the quality of predictions considering both diversity and fidelity.
Experiments show that our method achieves strong performance on two standard
benchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event
boundaries.

</details>


### [36] [Enhancing 3D point accuracy of laser scanner through multi-stage convolutional neural network for applications in construction](https://arxiv.org/abs/2508.12089)
*Qinyuan Fan,Clemens Gühmann*

Main category: cs.CV

TL;DR: 通过多段卷积神经网络和高低端扫描仪配对，实现了粗糕室内环境中低端光辰扫描仪测量精度的显著提升，MSE降低70%以上，PSNR提升6dB。


<details>
  <summary>Details</summary>
Motivation: 解决不同等级光辰扫描仪因设备限制和环境因素导致的位置误差问题，提供更准确的空间测量以支持高精度几何模型创建和改造。

Method: 使用高精度扫描仪作为参考，与低端扫描仪在同一环境下配对测量，通过统计关系建立测量差异与空间分布的关联，结合传统几何处理和神经网络精细化构建校正框架，将系统误差量化转换为监督学习问题。

Result: 在粗糕室内环境数据集中，测量精度显著提升，均方误差(MSE)降低70%以上，峰值信噪比(PSNR)提高约6分贝。低端设备无需硬件改造即可达到接近高端设备的测量不确定性水平。

Conclusion: 该方法通过智能算法补偿低端设备的系统误差，在保持关键几何特征的同时实现了精确校正，为高精度空间测量提供了经济有效的解决方案。

Abstract: We propose a multi-stage convolutional neural network (MSCNN) based
integrated method for reducing uncertainty of 3D point accuracy of lasar
scanner (LS) in rough indoor rooms, providing more accurate spatial
measurements for high-precision geometric model creation and renovation. Due to
different equipment limitations and environmental factors, high-end and low-end
LS have positional errors. Our approach pairs high-accuracy scanners (HAS) as
references with corresponding low-accuracy scanners (LAS) of measurements in
identical environments to quantify specific error patterns. By establishing a
statistical relationship between measurement discrepancies and their spatial
distribution, we develop a correction framework that combines traditional
geometric processing with targeted neural network refinement. This method
transforms the quantification of systematic errors into a supervised learning
problem, allowing precise correction while preserving critical geometric
features. Experimental results in our rough indoor rooms dataset show
significant improvements in measurement accuracy, with mean square error (MSE)
reductions exceeding 70% and peak signal-to-noise ratio (PSNR) improvements of
approximately 6 decibels. This approach enables low-end devices to achieve
measurement uncertainty levels approaching those of high-end devices without
hardware modifications.

</details>


### [37] [Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion](https://arxiv.org/abs/2508.12094)
*Songwei Liu,Hong Liu,Fangmin Chen,Xurui Peng,Chenqian Yan,Lean Fu,Xing Mei*

Main category: cs.CV

TL;DR: 这篇论文提出了一种时间步感知的累积错误补偿方案，通过理论分析演算模型中的误差传播机制，有效减少量化错误的累积，提升低精度演算模型的性能。


<details>
  <summary>Details</summary>
Motivation: 演算模型在图像合成领域取得了突破性进展，但其迭代反向去噪过程计算开销较大。训练后量化(PTQ)能加速采样，但迭代性质导致步进量化错误累积，影响输出质量。

Method: 建立理论框架数学形式化演算模型中的错误传播，求解每步量化错误传播方程，达到首个累积错误的闭式解。基于此提出时间步感知的累积错误补偿方案。

Result: 在多个图像数据集上的实验表明，该补偿策略有效减轻错误传播，显著提升现有PTQ方法的性能，在低精度演算模型上达到了最先进水平。

Conclusion: 通过理论分析演算模型错误传播机制，提出的时间步感知累积错误补偿方案能够有效解决量化错误累积问题，为演算模型的大规模部署提供了有效的加速方案。

Abstract: Diffusion models have transformed image synthesis by establishing
unprecedented quality and creativity benchmarks. Nevertheless, their
large-scale deployment faces challenges due to computationally intensive
iterative denoising processes. Although post-training quantization(PTQ)
provides an effective pathway for accelerating sampling, the iterative nature
of diffusion models causes stepwise quantization errors to accumulate
progressively during generation, inevitably compromising output fidelity. To
address this challenge, we develop a theoretical framework that mathematically
formulates error propagation in Diffusion Models (DMs), deriving per-step
quantization error propagation equations and establishing the first closed-form
solution for cumulative error. Building on this theoretical foundation, we
propose a timestep-aware cumulative error compensation scheme. Extensive
experiments across multiple image datasets demonstrate that our compensation
strategy effectively mitigates error propagation, significantly enhancing
existing PTQ methods to achieve state-of-the-art(SOTA) performance on
low-precision diffusion models.

</details>


### [38] [VELVET-Med: Vision and Efficient Language Pre-training for Volumetric Imaging Tasks in Medicine](https://arxiv.org/abs/2508.12108)
*Ziyang Zhang,Yang Yu,Xulei Yang,Si Yong Yeo*

Main category: cs.CV

TL;DR: VELVET-Med是一个针对医学3D CT扫描和放射报告的视觉语言预训练框架，通过创新的预训练目标和模型架构，在有限数据量下实现优异的下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 医学领域中3D体积数据（如CT扫描）与文本的配对数据收集困难且耗时，限制了视觉语言模型在医学下游任务中的表现。

Method: 1）将单模态自监督学习整合到VLP框架中；2）提出TriBERT语言编码器学习多级文本语义；3）设计分层对比学习捕获多级视觉语言对应关系。仅使用38,875对扫描-报告数据进行训练。

Result: 所学习的编码器展现出强大的迁移能力，在3D分割、跨模态检索、视觉问答和报告生成等广泛下游任务中达到最先进性能。

Conclusion: VELVET-Med框架通过创新的预训练策略，在有限数据条件下成功挖掘了医学体积图像和临床叙述中丰富的空间和语义关系，显著提升了编码器的泛化能力。

Abstract: Vision-and-language models (VLMs) have been increasingly explored in the
medical domain, particularly following the success of CLIP in general domain.
However, unlike the relatively straightforward pairing of 2D images and text,
curating large-scale paired data in the medical field for volumetric modalities
such as CT scans remains a challenging and time-intensive process. This
difficulty often limits the performance on downstream tasks. To address these
challenges, we propose a novel vision-language pre-training (VLP) framework,
termed as \textbf{VELVET-Med}, specifically designed for limited volumetric
data such as 3D CT and associated radiology reports. Instead of relying on
large-scale data collection, our method focuses on the development of effective
pre-training objectives and model architectures. The key contributions are: 1)
We incorporate uni-modal self-supervised learning into VLP framework, which are
often underexplored in the existing literature. 2) We propose a novel language
encoder, termed as \textbf{TriBERT}, for learning multi-level textual
semantics. 3) We devise the hierarchical contrastive learning to capture
multi-level vision-language correspondence. Using only 38,875 scan-report
pairs, our approach seeks to uncover rich spatial and semantic relationships
embedded in volumetric medical images and corresponding clinical narratives,
thereby enhancing the generalization ability of the learned encoders. The
resulting encoders exhibit strong transferability, achieving state-of-the-art
performance across a wide range of downstream tasks, including 3D segmentation,
cross-modal retrieval, visual question answering, and report generation.

</details>


### [39] [Simple o3: Towards Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2508.12109)
*Ye Wang,Qianglong Chen,Zejun Li,Siyuan Wang,Shijie Guo,Zhirui Zhang,Zhongyu Wei*

Main category: cs.CV

TL;DR: Simple o3是一个端到端的多模态思维链框架，通过动态视觉工具交互（裁剪、缩放、重用）和监督微调，实现了卓越的多模态推理性能，并创建了高质量的TWI-Tools-146K数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在长思维链能力方面研究不足，需要模拟人类"图像思考"的迭代视觉转换和语言推理过程。

Method: 提出Simple o3框架，集成动态工具交互（裁剪、缩放、重用）到交错的视觉-语言推理中，通过监督微调和可扩展的数据合成流水线生成高质量推理链。

Result: 在多个基准测试中表现出色，优于现有方法，通过引入额外的视觉标记和精确的视觉定位，显著提升了视觉推理和细粒度感知能力。

Conclusion: Simple o3建立了一个强大且计算成本合理的多模态推理范式，首次深入分析了不同交错推理策略对模型性能的影响，为多模态推理提供了新的见解。

Abstract: Multimodal Large Language Models (MLLMs) have shown impressive performance on
vision-language tasks, but their long Chain-of-Thought (CoT) capabilities in
multimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which
emulates human-like ''thinking with image'' through iterative visual
transformations and linguistic reasoning, we propose Simple o3, an end-to-end
framework that integrates dynamic tool interactions (e.g., cropping, zooming,
and reusing) into interleaved vision-language reasoning via supervised
fine-tuning (SFT). Our approach features a scalable data synthesis pipeline
that generates high-quality interleaved vision-language reasoning chains via an
''observe-reason-act'' cycle, complete with executable visual operations and
rigorous verification, yielding the open-source TWI-Tools-146K dataset.
Experimental results demonstrate Simple o3's superior performance on diverse
benchmarks, outperforming existing approaches. By combining enhanced reasoning
capabilities, Simple o3 establishes a powerful yet computationally affordable
paradigm for advancing multimodal reasoning. Remarkably, we provide the first
in-depth analysis of different interleaved reasoning strategies, offering
insights into their impact on model performance. We found that by introducing
additional visual tokens for interleaved vision-language reasoning, reusing and
magnifying the original image significantly improves the model's visual
reasoning and fine-grained perception, while image cropping based on precise
visual grounding allows the model to effectively focus on key entities or
regions, further enhancing its capabilities.

</details>


### [40] [DualFit: A Two-Stage Virtual Try-On via Warping and Synthesis](https://arxiv.org/abs/2508.12131)
*Minh Tran,Johnmark Clements,Annie Prasanna,Tri Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DualFit是一个两阶段的虚拟试穿混合方法，通过变形和保真度保持模块，在保持服装细节（如logo和印刷文字）的同时实现无缝试穿效果


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的免变形方法虽然提高了感知质量，但无法保持服装的精细细节（如logo和印刷文字），这些细节对于品牌完整性和客户信任至关重要

Method: 两阶段方法：第一阶段使用学习到的流场将目标服装变形以对齐人物图像；第二阶段通过保真度保持试穿模块，使用保留区域输入和修复掩码来混合变形后的服装和保留的人体区域

Result: 广泛的定性结果显示DualFit实现了视觉上无缝的试穿结果，同时忠实地保持了高频服装细节，在重建准确性和感知真实性之间取得了有效平衡

Conclusion: DualFit通过混合方法成功解决了现有虚拟试穿技术在保持服装细节方面的局限性，为在线时尚零售提供了更好的用户体验

Abstract: Virtual Try-On technology has garnered significant attention for its
potential to transform the online fashion retail experience by allowing users
to visualize how garments would look on them without physical trials. While
recent advances in diffusion-based warping-free methods have improved
perceptual quality, they often fail to preserve fine-grained garment details
such as logos and printed text elements that are critical for brand integrity
and customer trust. In this work, we propose DualFit, a hybrid VTON pipeline
that addresses this limitation by two-stage approach. In the first stage,
DualFit warps the target garment to align with the person image using a learned
flow field, ensuring high-fidelity preservation. In the second stage, a
fidelity-preserving try-on module synthesizes the final output by blending the
warped garment with preserved human regions. Particularly, to guide this
process, we introduce a preserved-region input and an inpainting mask, enabling
the model to retain key areas and regenerate only where necessary, particularly
around garment seams. Extensive qualitative results show that DualFit achieves
visually seamless try-on results while faithfully maintaining high-frequency
garment details, striking an effective balance between reconstruction accuracy
and perceptual realism.

</details>


### [41] [TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks](https://arxiv.org/abs/2508.12132)
*Amira Guesmi,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: TriQDef是一个针对量化神经网络的三级防御框架，通过特征不对齐惩罚和梯度感知失谐惩罚来破坏跨比特宽度的补丁式对抗攻击的可转移性，在保持高清洁精度的同时将攻击成功率降低40%以上。


<details>
  <summary>Details</summary>
Motivation: 量化神经网络(QNNs)虽然在计算和内存使用上效率高，但对基于补丁的对抗攻击（局部高显著性扰动）的鲁棒性有限，现有防御方法要么过拟合固定量化设置，要么无法解决跨比特泛化漏洞。

Method: TriQDef包含三个核心组件：1)特征不对齐惩罚(FDP)通过惩罚中间表示的感知相似性来强制语义不一致；2)梯度感知失谐惩罚(GPDP)通过边缘IoU和HOG余弦度量最小化结构性和方向性一致性来显式错位输入梯度；3)联合量化感知训练协议，在多个量化级别上统一这些惩罚。

Result: 在CIFAR-10和ImageNet上的广泛实验表明，TriQDef在未见过的补丁和量化组合上将攻击成功率(ASR)降低了40%以上，同时保持了高清洁精度。

Conclusion: 研究强调了破坏语义和感知梯度对齐对于减轻QNNs中补丁可转移性的重要性，TriQDef框架有效解决了跨比特泛化漏洞问题。

Abstract: Quantized Neural Networks (QNNs) are increasingly deployed in edge and
resource-constrained environments due to their efficiency in computation and
memory usage. While shown to distort the gradient landscape and weaken
conventional pixel-level attacks, it provides limited robustness against
patch-based adversarial attacks-localized, high-saliency perturbations that
remain surprisingly transferable across bit-widths. Existing defenses either
overfit to fixed quantization settings or fail to address this cross-bit
generalization vulnerability. We introduce \textbf{TriQDef}, a tri-level
quantization-aware defense framework designed to disrupt the transferability of
patch-based adversarial attacks across QNNs. TriQDef consists of: (1) a Feature
Disalignment Penalty (FDP) that enforces semantic inconsistency by penalizing
perceptual similarity in intermediate representations; (2) a Gradient
Perceptual Dissonance Penalty (GPDP) that explicitly misaligns input gradients
across bit-widths by minimizing structural and directional agreement via Edge
IoU and HOG Cosine metrics; and (3) a Joint Quantization-Aware Training
Protocol that unifies these penalties within a shared-weight training scheme
across multiple quantization levels. Extensive experiments on CIFAR-10 and
ImageNet demonstrate that TriQDef reduces Attack Success Rates (ASR) by over
40\% on unseen patch and quantization combinations, while preserving high clean
accuracy. Our findings underscore the importance of disrupting both semantic
and perceptual gradient alignment to mitigate patch transferability in QNNs.

</details>


### [42] [Infusing fine-grained visual knowledge to Vision-Language Models](https://arxiv.org/abs/2508.12137)
*Nikolaos-Antonios Ypsilantis,Kaifeng Chen,André Araujo,Ondřej Chum*

Main category: cs.CV

TL;DR: 这篇论文提出了一种细粒度视觉网络调优方法，在保持预训练多模态模型广泛知识的同时，提升域特定细粒度检索性能


<details>
  <summary>Details</summary>
Motivation: 解决大规模对比预训练多模态模型在细粒度开放集检索任务中表现次优的问题，避免细调导致的灾难性遗忘问题

Method: 受续习学习的启发，系统分析并组合多种正则化技术，具体包括验证集设计和超参数调优的关键方面

Result: 在细粒度和粗粒度图像-图像、图像-文本检索测试集上一致获得优异结果，在不使用文本数据或原始文本编码器的情况下保持了视觉-文本对齐能力

Conclusion: 该方法能够有效平衡域适配和预训练知识保留，为多模态模型的细调提供了可靠的解决方案

Abstract: Large-scale contrastive pre-training produces powerful Vision-and-Language
Models (VLMs) capable of generating representations (embeddings) effective for
a wide variety of visual and multimodal tasks. However, these pretrained
embeddings remain suboptimal for fine-grained open-set visual retrieval, where
state-of-the-art results require fine-tuning the vision encoder using annotated
domain-specific samples. Naively performing such fine-tuning typically leads to
catastrophic forgetting, severely diminishing the model's general-purpose
visual and cross-modal capabilities.
  In this work, we propose a fine-tuning method explicitly designed to achieve
optimal balance between fine-grained domain adaptation and retention of the
pretrained VLM's broad multimodal knowledge. Drawing inspiration from continual
learning literature, we systematically analyze standard regularization
techniques aimed at knowledge retention and propose an efficient and effective
combination strategy. Additionally, we address the commonly overlooked yet
critical aspects of validation set design and hyperparameter tuning to ensure
reproducibility and robust generalization across datasets and pretrained
models. We extensively evaluate our method on both fine-grained and
coarse-grained image-image and image-text retrieval benchmarks. Our approach
consistently achieves strong results, notably retaining the visual-text
alignment without utilizing any text data or the original text encoder during
fine-tuning. Code and model checkpoints: https://github.com/nikosips/infusing .

</details>


### [43] [KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction](https://arxiv.org/abs/2508.12147)
*Donghang Lyu,Marius Staring,Mariya Doneva,Hildo J. Lamb,Nicola Pezzotti*

Main category: cs.CV

TL;DR: KP-INR是一种用于心脏电影MRI重建的双分支隐式神经表示方法，通过在k空间中处理坐标位置嵌入和学习局部多尺度特征表示，实现了比基线模型更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的INR方法主要关注基于坐标的位置嵌入来学习映射，但忽略了目标点及其邻域上下文特征表示，限制了重建质量。

Method: 提出KP-INR双分支方法：一个分支处理k空间坐标的位置嵌入，另一个分支学习该坐标处的局部多尺度k空间特征表示，通过跨分支交互来近似目标k空间值。

Result: 在CMRxRecon2024数据集上的实验证实，KP-INR在具有挑战性的笛卡尔k空间数据上表现出优于基线模型的性能。

Conclusion: KP-INR方法通过结合位置嵌入和局部特征表示，在心脏电影MRI重建领域显示出巨大潜力，为快速采集技术下的高质量图像恢复提供了有效解决方案。

Abstract: Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for
assessing cardiac structure, function, and blood flow. Cine MRI extends this by
capturing heart motion, providing detailed insights into cardiac mechanics. To
reduce scan time and breath-hold discomfort, fast acquisition techniques have
been utilized at the cost of lowering image quality. Recently, Implicit Neural
Representation (INR) methods have shown promise in unsupervised reconstruction
by learning coordinate-to-value mappings from undersampled data, enabling
high-quality image recovery. However, current existing INR methods primarily
focus on using coordinate-based positional embeddings to learn the mapping,
while overlooking the feature representations of the target point and its
neighboring context. In this work, we propose KP-INR, a dual-branch INR method
operating in k-space for cardiac cine MRI reconstruction: one branch processes
the positional embedding of k-space coordinates, while the other learns from
local multi-scale k-space feature representations at those coordinates. By
enabling cross-branch interaction and approximating the target k-space values
from both branches, KP-INR can achieve strong performance on challenging
Cartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its
improved performance over baseline models and highlights its potential in this
field.

</details>


### [44] [Demystifying Foreground-Background Memorization in Diffusion Models](https://arxiv.org/abs/2508.12148)
*Jimmy Z. Di,Yiwei Lu,Yaoliang Yu,Gautam Kamath,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: 提出了FB-Mem方法，通过分割技术量化扩散模型中的记忆化现象，发现记忆化比之前认为的更普遍，现有缓解方法效果有限。


<details>
  <summary>Details</summary>
Motivation: 当前检测方法只能识别完全复制的记忆化，无法捕捉小区域的部分记忆化和超越特定提示-图像对的记忆化模式。

Method: 提出基于分割的FB-Mem度量方法，对生成图像中的记忆化区域进行分类和量化，并使用聚类方法进行更强的缓解。

Result: 发现记忆化现象更加普遍：单个提示可能关联到多个相似训练图像的聚类；现有缓解方法无法消除局部记忆化，特别是在前景区域。

Conclusion: 建立了有效的扩散模型记忆化测量框架，证明了当前缓解方法的不足，提出了基于聚类的更强缓解方法。

Abstract: Diffusion models (DMs) memorize training images and can reproduce
near-duplicates during generation. Current detection methods identify verbatim
memorization but fail to capture two critical aspects: quantifying partial
memorization occurring in small image regions, and memorization patterns beyond
specific prompt-image pairs. To address these limitations, we propose
Foreground Background Memorization (FB-Mem), a novel segmentation-based metric
that classifies and quantifies memorized regions within generated images. Our
method reveals that memorization is more pervasive than previously understood:
(1) individual generations from single prompts may be linked to clusters of
similar training images, revealing complex memorization patterns that extend
beyond one-to-one correspondences; and (2) existing model-level mitigation
methods, such as neuron deactivation and pruning, fail to eliminate local
memorization, which persists particularly in foreground regions. Our work
establishes an effective framework for measuring memorization in diffusion
models, demonstrates the inadequacy of current mitigation approaches, and
proposes a stronger mitigation method using a clustering approach.

</details>


### [45] [RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis](https://arxiv.org/abs/2508.12163)
*Wenqing Wang,Yun Fu*

Main category: cs.CV

TL;DR: RealTalk是一个新颖的情感说话头合成框架，通过VAE生成3D面部标志点，结合情感标签嵌入和NeRF技术，在情感准确性、可控性和身份保持方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前方法在唇部同步和图像质量方面表现出色，但在生成准确可控的情感表达同时保持主体身份方面存在不足，需要解决情感合成中的这些关键挑战。

Method: 使用变分自编码器(VAE)从音频生成3D面部标志点，通过ResNet-based标志点变形模型结合情感标签嵌入生成情感标志点，最后利用三平面注意力NeRF合成高真实感的情感说话头。

Result: 大量实验表明，RealTalk在情感准确性、可控性和身份保持方面均优于现有方法，显著提升了情感合成的性能。

Conclusion: RealTalk框架有效解决了情感说话头合成中的关键问题，推动了社交智能AI系统的发展，为情感表达生成提供了新的技术路径。

Abstract: Emotion is a critical component of artificial social intelligence. However,
while current methods excel in lip synchronization and image quality, they
often fail to generate accurate and controllable emotional expressions while
preserving the subject's identity. To address this challenge, we introduce
RealTalk, a novel framework for synthesizing emotional talking heads with high
emotion accuracy, enhanced emotion controllability, and robust identity
preservation. RealTalk employs a variational autoencoder (VAE) to generate 3D
facial landmarks from driving audio, which are concatenated with emotion-label
embeddings using a ResNet-based landmark deformation model (LDM) to produce
emotional landmarks. These landmarks and facial blendshape coefficients jointly
condition a novel tri-plane attention Neural Radiance Field (NeRF) to
synthesize highly realistic emotional talking heads. Extensive experiments
demonstrate that RealTalk outperforms existing methods in emotion accuracy,
controllability, and identity preservation, advancing the development of
socially intelligent AI systems.

</details>


### [46] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse是一个基于提示的RF信号模拟框架，通过语言引导的4D世界生成器和相位相干射线追踪模拟器，从生成的室内场景和人体运动中模拟真实的RF信号


<details>
  <summary>Details</summary>
Motivation: 解决在动态多样的室内环境中收集高质量RF数据的挑战，为RF感知任务提供隐私保护的替代方案

Method: 使用语言引导的4D世界生成器（包含状态感知因果变换器用于人体运动生成）和相位相干射线追踪模拟器来模拟准确的RF信号

Result: 在条件人体运动生成方面表现有效，首次实现了RF成像的数据生成，在数据有限和数据充足场景下均获得性能提升

Conclusion: WaveVerse为RF感知任务提供了一个可扩展的模拟框架，能够生成高质量的RF数据，支持波束成形和呼吸监测等应用

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [47] [Splat Feature Solver](https://arxiv.org/abs/2508.12216)
*Butian Xiong,Rong Liu,Kenneth Xu,Meida Chen,Andrew Feng*

Main category: cs.CV

TL;DR: 提出了一种统一的特征提升方法，通过稀疏线性逆问题求解，为3D表示分配丰富的图像特征描述符，在开放词汇3D分割任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决多视图图像中特征不一致的问题，为基于splat的3D表示提供高质量的特征描述符分配。

Method: 将特征提升问题表述为稀疏线性逆问题，采用闭式解求解，并引入Tikhonov指导和后提升聚合两种正则化策略来处理不一致性和噪声。

Result: 在开放词汇3D分割基准测试中达到最先进性能，优于基于训练、分组和启发式的前沿方法，且能在几分钟内生成提升特征。

Conclusion: 该方法提供了一个理论保证的全局最优误差上界，能够高效地为3D基元分配丰富的通用属性，显著提升3D场景理解能力。

Abstract: Feature lifting has emerged as a crucial component in 3D scene understanding,
enabling the attachment of rich image feature descriptors (e.g., DINO, CLIP)
onto splat-based 3D representations. The core challenge lies in optimally
assigning rich general attributes to 3D primitives while addressing the
inconsistency issues from multi-view images. We present a unified, kernel- and
feature-agnostic formulation of the feature lifting problem as a sparse linear
inverse problem, which can be solved efficiently in closed form. Our approach
admits a provable upper bound on the global optimal error under convex losses
for delivering high quality lifted features. To address inconsistencies and
noise in multi-view observations, we introduce two complementary regularization
strategies to stabilize the solution and enhance semantic fidelity. Tikhonov
Guidance enforces numerical stability through soft diagonal dominance, while
Post-Lifting Aggregation filters noisy inputs via feature clustering. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
on open-vocabulary 3D segmentation benchmarks, outperforming training-based,
grouping-based, and heuristic-forward baselines while producing the lifted
features in minutes. Code is available at
\href{https://github.com/saliteta/splat-distiller.git}{\textbf{github}}. We
also have a \href{https://splat-distiller.pages.dev/}

</details>


### [48] [C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis](https://arxiv.org/abs/2508.12219)
*Kaiyuan Wang,Jixing Liu,Xiaobo Cai*

Main category: cs.CV

TL;DR: 基于深度学习的YOLOv11优化方法用于棉花病害检测，通过C2PSA模块、动态类别加权和改进数据增强技术，显著提升了小目标检测精度和田间环境下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决棉花病害检测中的三个关键挑战：早期斑点检测精度低（5mm²以下斑点漏检率35%）、田间环境下性能下降（准确率下降25%）以及多病害场景错误率高（34.7%）。

Method: 提出C2PSA模块增强小目标特征提取，采用动态类别加权处理样本不平衡问题，使用Mosaic-MixUp缩放改进数据增强技术。

Result: 在4,078张图像数据集上测试显示：mAP50达到0.820（提升8.0%），mAP50-95达到0.705（提升10.5%），推理速度158 FPS。

Conclusion: 开发的移动部署系统能够实现实时病害监测和精准施药，在农业应用中具有重要价值。

Abstract: This study presents a deep learning-based optimization of YOLOv11 for cotton
disease detection, developing an intelligent monitoring system. Three key
challenges are addressed: (1) low precision in early spot detection (35%
leakage rate for sub-5mm2 spots), (2) performance degradation in field
conditions (25% accuracy drop), and (3) high error rates (34.7%) in
multi-disease scenarios. The proposed solutions include: C2PSA module for
enhanced small-target feature extraction; Dynamic category weighting to handle
sample imbalance; Improved data augmentation via Mosaic-MixUp scaling.
Experimental results on a 4,078-image dataset show: mAP50: 0.820 (+8.0%
improvement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS.
The mobile-deployed system enables real-time disease monitoring and precision
treatment in agricultural applications.

</details>


### [49] [In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics](https://arxiv.org/abs/2508.12226)
*Zhijun Zeng,Youjia Zheng,Chang Su,Qianhang Wu,Hao Hu,Zeyuan Dong,Shan Gao,Yang Lv,Rui Tang,Ligang Cui,Zhiyong Hou,Weijun Lin,Zuoqiang Shi,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: 提出一种结合生成式网络与物理模拟的新题框架，实现高效高保真的3D超声计算断展成像，充分利用强散射特性来改善筋骨肌肉成像质量。


<details>
  <summary>Details</summary>
Motivation: 传统光线基于重建方法在筋骨肌肉超声成像中忽略强散射效应，导致存在限制，需要新方法来充分利用超声波传播的物理特性提高成像质量。

Method: 通过从半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半半极少量跨模态图像中学习超声波传播的紧凑代理模型，将波动建模的准确性与深度学习的效率和稳定性相结合。

Result: 在合成和在体数据（乳腺、手臂、腿部）上，方法在10分钟内重建了组织参数的3D地图，对肌肉和骨骼的生物力学特性具有敏感性，分辨王可与MRI相比。

Conclusion: 通过克服强散射套中的计算瓶颈，该方法推动了USCT向常规临床筋骨肌肉疾病评估的发展，能够生成超越反射模式图像的声学特性空间地图。

Abstract: Ultrasound computed tomography (USCT) is a radiation-free, high-resolution
modality but remains limited for musculoskeletal imaging due to conventional
ray-based reconstructions that neglect strong scattering. We propose a
generative neural physics framework that couples generative networks with
physics-informed neural simulation for fast, high-fidelity 3D USCT. By learning
a compact surrogate of ultrasonic wave propagation from only dozens of
cross-modality images, our method merges the accuracy of wave modeling with the
efficiency and stability of deep learning. This enables accurate quantitative
imaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic
properties beyond reflection-mode images. On synthetic and in vivo data
(breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten
minutes, with sensitivity to biomechanical properties in muscle and bone and
resolution comparable to MRI. By overcoming computational bottlenecks in
strongly scattering regimes, this approach advances USCT toward routine
clinical assessment of musculoskeletal disease.

</details>


### [50] [WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions](https://arxiv.org/abs/2508.12250)
*Quan Chen,Xiong Yang,Rongfeng Lu,Qianyu Zhang,Yu Liu,Xiaofei Zhou,Bolun Zheng*

Main category: cs.CV

TL;DR: 该论文提出了一个包含天气噪声的显著性目标检测数据集WXSOD，并开发了Weather-aware Feature Aggregation Network (WFANet)方法，在复杂天气条件下显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有显著性目标检测方法在自然场景中表现良好，但缺乏针对天气噪声影响的研究，主要是因为缺少带有像素级标注的天气噪声数据集。

Method: 提出了两分支网络架构WFANet：天气预测分支挖掘天气相关深度特征，显著性检测分支将主干网络提取的语义特征与天气特征融合进行显著性检测。

Result: 在包含14,945张RGB图像的WXSOD数据集上，与17种SOD方法进行比较，WFANet取得了优越的性能表现。

Conclusion: WXSOD数据集填补了天气噪声显著性检测领域的空白，WFANet方法为复杂天气条件下的显著性检测提供了有效的解决方案。

Abstract: Salient object detection (SOD) in complex environments remains a challenging
research topic. Most existing methods perform well in natural scenes with
negligible noise, and tend to leverage multi-modal information (e.g., depth and
infrared) to enhance accuracy. However, few studies are concerned with the
damage of weather noise on SOD performance due to the lack of dataset with
pixel-wise annotations. To bridge this gap, this paper introduces a novel
Weather-eXtended Salient Object Detection (WXSOD) dataset. It consists of
14,945 RGB images with diverse weather noise, along with the corresponding
ground truth annotations and weather labels. To verify algorithm
generalization, WXSOD contains two test sets, i.e., a synthesized test set and
a real test set. The former is generated by adding weather noise to clean
images, while the latter contains real-world weather noise. Based on WXSOD, we
propose an efficient baseline, termed Weather-aware Feature Aggregation Network
(WFANet), which adopts a fully supervised two-branch architecture.
Specifically, the weather prediction branch mines weather-related deep
features, while the saliency detection branch fuses semantic features extracted
from the backbone with weather features for SOD. Comprehensive comparisons
against 17 SOD methods shows that our WFANet achieves superior performance on
WXSOD. The code and benchmark results will be made publicly available at
https://github.com/C-water/WXSOD

</details>


### [51] [Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery](https://arxiv.org/abs/2508.12261)
*Zhizhou Wang,Ruijing Zheng,Zhenyu Wu,Jianli Wang*

Main category: cs.CV

TL;DR: 提出了SCTR框架，通过超像素作为建模单元和不对称低秩张量分解，解决了传统低秩张量表示在空间变化和网格约束方面的局限性，在多个数据集上实现了3-5 dB的PSNR提升。


<details>
  <summary>Details</summary>
Motivation: 传统低秩张量表示方法存在两个关键限制：(1)假设整体数据是低秩的，这在具有显著空间变化的真实场景中往往不成立；(2)仅限于离散网格数据，限制了灵活性和适用性。

Method: 提出超像素感知的连续低秩张量表示(SCTR)框架：1)使用超像素作为基本建模单元，编码语义信息并增强对数据流的适应性；2)提出不对称低秩张量分解(ALTF)，通过共享神经网络参数化超像素特定因子矩阵，分离全局模式学习和局部适应。

Result: 在多个基准数据集上的广泛实验表明，SCTR在多光谱图像、视频和彩色图像上比现有基于LRTR的方法实现了3-5 dB的PSNR改进。

Conclusion: SCTR框架能够连续灵活地建模多维数据，有效捕获跨超像素共性和超像素内变化，在保持模型效率的同时实现了高表达性和适应性。

Abstract: Low-rank tensor representation (LRTR) has emerged as a powerful tool for
multi-dimensional data processing. However, classical LRTR-based methods face
two critical limitations: (1) they typically assume that the holistic data is
low-rank, this assumption is often violated in real-world scenarios with
significant spatial variations; and (2) they are constrained to discrete
meshgrid data, limiting their flexibility and applicability. To overcome these
limitations, we propose a Superpixel-informed Continuous low-rank Tensor
Representation (SCTR) framework, which enables continuous and flexible modeling
of multi-dimensional data beyond traditional grid-based constraints. Our
approach introduces two main innovations: First, motivated by the observation
that semantically coherent regions exhibit stronger low-rank characteristics
than holistic data, we employ superpixels as the basic modeling units. This
design not only encodes rich semantic information, but also enhances
adaptability to diverse forms of data streams. Second, we propose a novel
asymmetric low-rank tensor factorization (ALTF) where superpixel-specific
factor matrices are parameterized by a shared neural network with specialized
heads. By strategically separating global pattern learning from local
adaptation, this framework efficiently captures both cross-superpixel
commonalities and within-superpixel variations. This yields a representation
that is both highly expressive and compact, balancing model efficiency with
adaptability. Extensive experiments on several benchmark datasets demonstrate
that SCTR achieves 3-5 dB PSNR improvements over existing LRTR-based methods
across multispectral images, videos, and color images.

</details>


### [52] [Region-Level Context-Aware Multimodal Understanding](https://arxiv.org/abs/2508.12263)
*Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: 该论文提出了区域级上下文感知多模态理解(RCMU)任务，通过区域级上下文感知视觉指令调优(RCVIT)方法增强MLLMs能力，构建了RCMU数据集和RC&P-Bench基准，并在Qwen2-VL模型上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs研究主要关注通用视觉理解，忽视了将对象关联的文本上下文整合进行上下文感知多模态理解的能力，即区域级上下文感知多模态理解(RCMU)能力。

Method: 提出RCVIT方法，将对象信息纳入模型输入，利用边界框坐标有效关联对象的视觉内容和文本信息；构建RCMU大规模视觉指令调优数据集和RC&P-Bench评估基准；提出无参考评估指标。

Result: 通过在Qwen2-VL模型上应用RCVIT训练得到RC-Qwen2-VL模型，在多个RCMU任务上表现优异，并在多模态RAG和个性化对话中成功应用。

Conclusion: 该研究填补了MLLMs在区域级上下文感知理解方面的空白，提出的方法、数据集和基准为多模态理解提供了新的解决方案和评估标准。

Abstract: Despite significant progress, existing research on Multimodal Large Language
Models (MLLMs) mainly focuses on general visual understanding, overlooking the
ability to integrate textual context associated with objects for a more
context-aware multimodal understanding -- an ability we refer to as
Region-level Context-aware Multimodal Understanding (RCMU). To address this
limitation, we first formulate the RCMU task, which requires models to respond
to user instructions by integrating both image content and textual information
of regions or objects. To equip MLLMs with RCMU capabilities, we propose
Region-level Context-aware Visual Instruction Tuning (RCVIT), which
incorporates object information into the model input and enables the model to
utilize bounding box coordinates to effectively associate objects' visual
content with their textual information. To address the lack of datasets, we
introduce the RCMU dataset, a large-scale visual instruction tuning dataset
that covers multiple RCMU tasks. We also propose RC\&P-Bench, a comprehensive
benchmark that can evaluate the performance of MLLMs in RCMU and multimodal
personalized understanding tasks. Additionally, we propose a reference-free
evaluation metric to perform a comprehensive and fine-grained evaluation of the
region-level context-aware image descriptions. By performing RCVIT on Qwen2-VL
models with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental
results indicate that RC-Qwen2-VL models not only achieve outstanding
performance on multiple RCMU tasks but also demonstrate successful applications
in multimodal RAG and personalized conversation. Our data, model and benchmark
are available at https://github.com/hongliang-wei/RC-MLLM

</details>


### [53] [SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration](https://arxiv.org/abs/2508.12271)
*Ronghua Xu,Jin Xie,Jing Nie,Jiale Cao,Yanwei Pang*

Main category: cs.CV

TL;DR: 提出SNNSIR，一种完全脉冲驱动的脉冲神经网络用于立体图像恢复，通过脉冲残差基本块、立体卷积调制和立体交叉注意力模块，在保持低功耗的同时实现竞争性的恢复性能


<details>
  <summary>Details</summary>
Motivation: 现有的混合SNN-ANN模型仍依赖浮点矩阵除法或指数运算，与SNN的二进制和事件驱动特性不兼容。需要开发完全脉冲驱动的架构来实现低功耗和硬件友好的计算

Method: 1) 轻量级脉冲残差基本块(SRBB)增强信息流；2) 脉冲立体卷积调制(SSCM)模块通过元素乘法引入简化非线性；3) 脉冲立体交叉注意力(SSCA)模块实现跨视图双向特征交互

Result: 在雨纹去除、雨滴去除、低光增强和超分辨率等多种立体图像恢复任务中实现了竞争性的恢复性能，同时显著降低了计算开销

Conclusion: 该方法展示了实时、低功耗立体视觉应用的潜力，为完全脉冲驱动的立体图像恢复提供了有效解决方案

Abstract: Spiking Neural Networks (SNNs), characterized by discrete binary activations,
offer high computational efficiency and low energy consumption, making them
well-suited for computation-intensive tasks such as stereo image restoration.
In this work, we propose SNNSIR, a simple yet effective Spiking Neural Network
for Stereo Image Restoration, specifically designed under the spike-driven
paradigm where neurons transmit information through sparse, event-based binary
spikes. In contrast to existing hybrid SNN-ANN models that still rely on
operations such as floating-point matrix division or exponentiation, which are
incompatible with the binary and event-driven nature of SNNs, our proposed
SNNSIR adopts a fully spike-driven architecture to achieve low-power and
hardware-friendly computation. To address the expressiveness limitations of
binary spiking neurons, we first introduce a lightweight Spike Residual Basic
Block (SRBB) to enhance information flow via spike-compatible residual
learning. Building on this, the Spike Stereo Convolutional Modulation (SSCM)
module introduces simplified nonlinearity through element-wise multiplication
and highlights noise-sensitive regions via cross-view-aware modulation.
Complementing this, the Spike Stereo Cross-Attention (SSCA) module further
improves stereo correspondence by enabling efficient bidirectional feature
interaction across views within a spike-compatible framework. Extensive
experiments on diverse stereo image restoration tasks, including rain streak
removal, raindrop removal, low-light enhancement, and super-resolution
demonstrate that our model achieves competitive restoration performance while
significantly reducing computational overhead. These results highlight the
potential for real-time, low-power stereo vision applications. The code will be
available after the article is accepted.

</details>


### [54] [TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform](https://arxiv.org/abs/2508.12279)
*Jun Liu,Zhenglun Kong,Pu Zhao,Weihao Zeng,Hao Tang,Xuan Shen,Changdi Yang,Wenbin Zhang,Geng Yuan,Wei Niu,Xue Lin,Yanzhi Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种针对自动驾驶平台的动态可适应语义分割网络，通过三层控制机制和贝叶斯优化来实现硬件约束下的性能优化。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶平台面临多样化的驾驶场景、不同的硬件资源和精度要求，需要在嵌入式设备计算限制下考虑部署成本，根据硬件计算能力和特定场景定制语义分割网络。

Method: 采用三层控制机制（宽度乘数、分类器深度、分类器核）实现细粒度模型组件控制，结合贝叶斯优化和代理模型在有限计算预算下高效探索超参数空间。

Result: 实现了任务特定的学习适应（TSLA），能够根据不同的自动驾驶任务生成定制化配置，最大化计算能力和模型精度，优化硬件利用率。

Conclusion: 该方法能够有效解决自动驾驶场景特定和任务特定的需求，通过自动参数搜索适应不同的计算复杂度和精度要求，提升资源分配和性能表现。

Abstract: Autonomous driving platforms encounter diverse driving scenarios, each with
varying hardware resources and precision requirements. Given the computational
limitations of embedded devices, it is crucial to consider computing costs when
deploying on target platforms like the NVIDIA\textsuperscript{\textregistered}
DRIVE PX 2. Our objective is to customize the semantic segmentation network
according to the computing power and specific scenarios of autonomous driving
hardware. We implement dynamic adaptability through a three-tier control
mechanism -- width multiplier, classifier depth, and classifier kernel --
allowing fine-grained control over model components based on hardware
constraints and task requirements. This adaptability facilitates broad model
scaling, targeted refinement of the final layers, and scenario-specific
optimization of kernel sizes, leading to improved resource allocation and
performance.
  Additionally, we leverage Bayesian Optimization with surrogate modeling to
efficiently explore hyperparameter spaces under tight computational budgets.
Our approach addresses scenario-specific and task-specific requirements through
automatic parameter search, accommodating the unique computational complexity
and accuracy needs of autonomous driving. It scales its Multiply-Accumulate
Operations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in
alternative configurations tailored to diverse self-driving tasks. These TSLA
customizations maximize computational capacity and model accuracy, optimizing
hardware utilization.

</details>


### [55] [CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval](https://arxiv.org/abs/2508.12290)
*Chor Boon Tan,Conghui Hu,Gim Hee Lee*

Main category: cs.CV

TL;DR: 本文提出CLAIR方法，针对大规模基础模型生成噪声伪标签的弱监督零样本跨域图像检索问题，通过置信度评分、对比学习和跨域映射函数来提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型基础模型能够轻松为大量未标记数据生成伪标签，无监督零样本跨域图像检索变得不再那么重要。因此作者转向关注由CLIP等大型基础模型生成噪声伪标签的弱监督零样本跨域图像检索问题。

Method: 提出CLAIR方法：1）使用CLIP文本和图像特征相似度计算置信度来精炼噪声伪标签；2）设计实例间和簇间对比损失来编码类感知潜在空间；3）使用域间对比损失减少域差异；4）学习闭式跨域映射函数，仅用CLIP文本嵌入将图像特征从一个域投影到另一个域；5）引入可学习提示增强零样本泛化能力。

Result: 在TUBerlin、Sketchy、Quickdraw和DomainNet零样本数据集上的大量实验表明，CLAIR方法相比现有最先进方法始终表现出优越性能。

Conclusion: CLAIR方法通过有效处理噪声伪标签、学习类感知表示和跨域对齐，显著提升了弱监督零样本跨域图像检索的性能，在多个基准数据集上都取得了state-of-the-art的结果。

Abstract: The recent growth of large foundation models that can easily generate
pseudo-labels for huge quantity of unlabeled data makes unsupervised Zero-Shot
Cross-Domain Image Retrieval (UZS-CDIR) less relevant. In this paper, we
therefore turn our attention to weakly supervised ZS-CDIR (WSZS-CDIR) with
noisy pseudo labels generated by large foundation models such as CLIP. To this
end, we propose CLAIR to refine the noisy pseudo-labels with a confidence score
from the similarity between the CLIP text and image features. Furthermore, we
design inter-instance and inter-cluster contrastive losses to encode images
into a class-aware latent space, and an inter-domain contrastive loss to
alleviate domain discrepancies. We also learn a novel cross-domain mapping
function in closed-form, using only CLIP text embeddings to project image
features from one domain to another, thereby further aligning the image
features for retrieval. Finally, we enhance the zero-shot generalization
ability of our CLAIR to handle novel categories by introducing an extra set of
learnable prompts. Extensive experiments are carried out using TUBerlin,
Sketchy, Quickdraw, and DomainNet zero-shot datasets, where our CLAIR
consistently shows superior performance compared to existing state-of-the-art
methods.

</details>


### [56] [Improving Densification in 3D Gaussian Splatting for High-Fidelity Rendering](https://arxiv.org/abs/2508.12313)
*Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu*

Main category: cs.CV

TL;DR: 通过边缘感知分数、长轴分割策略和抗过拟合技术对3DGS的密化管道进行全面改进，在不增加计算开销的情况下提升渲染质量


<details>
  <summary>Details</summary>
Motivation: 3D高斯拟合的密化策略导致重建质量不佳，需要从密化时机、密化方式和抗过拟合三个角度进行综合改进

Method: 提出边缘感知分数选择候选高斯元；长轴分割策略减少几何失真；重建感知剪枝、多步更新和增长控制等抗过拟合技术

Result: 方法在不增加训练或推理开销的情况下，以更少的高斯元数量达到最高渲染保真度

Conclusion: 该研究通过系统性的密化管道优化，显著提升了3D高斯拟合的重建质量和效率

Abstract: Although 3D Gaussian Splatting (3DGS) has achieved impressive performance in
real-time rendering, its densification strategy often results in suboptimal
reconstruction quality. In this work, we present a comprehensive improvement to
the densification pipeline of 3DGS from three perspectives: when to densify,
how to densify, and how to mitigate overfitting. Specifically, we propose an
Edge-Aware Score to effectively select candidate Gaussians for splitting. We
further introduce a Long-Axis Split strategy that reduces geometric distortions
introduced by clone and split operations. To address overfitting, we design a
set of techniques, including Recovery-Aware Pruning, Multi-step Update, and
Growth Control. Our method enhances rendering fidelity without introducing
additional training or inference overhead, achieving state-of-the-art
performance with fewer Gaussians.

</details>


### [57] [Neural Cellular Automata for Weakly Supervised Segmentation of White Blood Cells](https://arxiv.org/abs/2508.12322)
*Michael Deutges,Chen Yang,Raheleh Salehi,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 基于神经细胞自动机(NCA)的弱监督分割方法，无需重新训练即可从分类特征图中提取分割掩码，在白血球显微镜数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 医学诊断中白血球检测和分割需要大量标签数据，而标注过程耗时耗费，需要更高效的弱监督方法

Method: 提出NCA-WSS方法，利用神经细胞自动机在分类过程中生成的特征图，直接提取分割掩码而无需分割标签重新训练

Result: 在三个白血球显微镜数据集上评估，NCA-WSS在弱监督分割任务中显著超过现有方法

Conclusion: NCA技术在弱监督框架下既能做分类也能做分割，为医学图像分析提供了可扩展和高效的解决方案

Abstract: The detection and segmentation of white blood cells in blood smear images is
a key step in medical diagnostics, supporting various downstream tasks such as
automated blood cell counting, morphological analysis, cell classification, and
disease diagnosis and monitoring. Training robust and accurate models requires
large amounts of labeled data, which is both time-consuming and expensive to
acquire. In this work, we propose a novel approach for weakly supervised
segmentation using neural cellular automata (NCA-WSS). By leveraging the
feature maps generated by NCA during classification, we can extract
segmentation masks without the need for retraining with segmentation labels. We
evaluate our method on three white blood cell microscopy datasets and
demonstrate that NCA-WSS significantly outperforms existing weakly supervised
approaches. Our work illustrates the potential of NCA for both classification
and segmentation in a weakly supervised framework, providing a scalable and
efficient solution for medical image analysis.

</details>


### [58] [Attention Pooling Enhances NCA-based Classification of Microscopy Images](https://arxiv.org/abs/2508.12324)
*Chen Yang,Michael Deutges,Jingsong Liu,Han Li,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 通过结合注意力池化机制，提升神经细胞自动机（NCA）在显微镜图像分类中的性能，在保持参数效率和可解释性的同时实现了更高的准确性


<details>
  <summary>Details</summary>
Motivation: 神经细胞自动机（NCA）在显微镜图像分析中具有稳健和可解释性优势，但与更大更复杂的架构相比存在性能差距，需要提升其分类准确性

Method: 集成注意力池化机制与NCA，通过注意力池化精炼重点关注最信息丰富的区域，以增强特征提取能力

Result: 在8个多样化显微镜图像数据集上评估，方法显著超越现有NCA方法，同时保持低参数量和高效率；与传统轻量卷积神经网络和视觉Transformer相比，在性能提升的同时保持了更低的参数数量

Conclusion: 结果强调了NCA基础模型作为可解释图像分类的替代方案的潜力，通过注意力池化的集成有效缩小了NCA与更复杂架构之间的性能差距

Abstract: Neural Cellular Automata (NCA) offer a robust and interpretable approach to
image classification, making them a promising choice for microscopy image
analysis. However, a performance gap remains between NCA and larger, more
complex architectures. We address this challenge by integrating attention
pooling with NCA to enhance feature extraction and improve classification
accuracy. The attention pooling mechanism refines the focus on the most
informative regions, leading to more accurate predictions. We evaluate our
method on eight diverse microscopy image datasets and demonstrate that our
approach significantly outperforms existing NCA methods while remaining
parameter-efficient and explainable. Furthermore, we compare our method with
traditional lightweight convolutional neural network and vision transformer
architectures, showing improved performance while maintaining a significantly
lower parameter count. Our results highlight the potential of NCA-based models
an alternative for explainable image classification.

</details>


### [59] [DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection](https://arxiv.org/abs/2508.12330)
*Yuval Haitman,Oded Bialer*

Main category: cs.CV

TL;DR: DoppDrive是一种基于多普勒效应的雷达点云时域聚合方法，通过动态多普勒分量进行径向位移补偿，显著提高点云密度并减少散射，从而提升各种检测器的目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 雷达在自动驾驶中具有长距离探测优势，但远距离点云稀疏问题严重。现有时域聚合方法通过自运动补偿增加点密度，但会引入动态物体散射，反而降低检测性能。

Method: 提出DoppDrive方法：1）根据动态多普勒分量对历史帧点云进行径向位移补偿以消除径向散射；2）基于多普勒和角度为每个点分配独特的聚合时长以减少切向散射；3）作为检测前的点云密度增强步骤，可与任何检测器兼容。

Result: 实验证明DoppDrive显著提升了多种检测器和数据集上的目标检测性能。

Conclusion: DoppDrive通过多普勒驱动的时域聚合有效解决了雷达点云稀疏问题，在减少散射的同时提高点云密度，为雷达目标检测提供了通用的预处理增强方案。

Abstract: Radar-based object detection is essential for autonomous driving due to
radar's long detection range. However, the sparsity of radar point clouds,
especially at long range, poses challenges for accurate detection. Existing
methods increase point density through temporal aggregation with ego-motion
compensation, but this approach introduces scatter from dynamic objects,
degrading detection performance. We propose DoppDrive, a novel Doppler-Driven
temporal aggregation method that enhances radar point cloud density while
minimizing scatter. Points from previous frames are shifted radially according
to their dynamic Doppler component to eliminate radial scatter, with each point
assigned a unique aggregation duration based on its Doppler and angle to
minimize tangential scatter. DoppDrive is a point cloud density enhancement
step applied before detection, compatible with any detector, and we demonstrate
that it significantly improves object detection performance across various
detectors and datasets.

</details>


### [60] [Geometry-Aware Video Inpainting for Joint Headset Occlusion Removal and Face Reconstruction in Social XR](https://arxiv.org/abs/2508.12336)
*Fatemeh Ghorbani Lohesara,Karen Eguiazarian,Sebastian Knorr*

Main category: cs.CV

TL;DR: 通过结合GAN基于视频补画和3DMM参数回归的方法，从单视点RGB视频中去除HMD遮挡并重建完整的3D面部几何


<details>
  <summary>Details</summary>
Motivation: HMD在XR中遮挡用户面部上部，影响面部表情和眼神交流，隐式社交XR应用的体验

Method: 集成GAN基视频补画网络（通过密集面部关键点和单张无遮挡参照引导）和SynergyNet基于的3DMM参数回归模块，统一进行密集关键点优化

Result: 框架成功从RGB面部视频中去除HMD，保持面部身份和真实感，生成超高真实度3D面部几何输出，在不同关键点密度下都保持稳定性

Conclusion: 该方法有效解决了HMD遮挡问题，为社交XR应用提供了高质量的面部重建方案，具有强壁士性和应用价值

Abstract: Head-mounted displays (HMDs) are essential for experiencing extended reality
(XR) environments and observing virtual content. However, they obscure the
upper part of the user's face, complicating external video recording and
significantly impacting social XR applications such as teleconferencing, where
facial expressions and eye gaze details are crucial for creating an immersive
experience. This study introduces a geometry-aware learning-based framework to
jointly remove HMD occlusions and reconstruct complete 3D facial geometry from
RGB frames captured from a single viewpoint. The method integrates a GAN-based
video inpainting network, guided by dense facial landmarks and a single
occlusion-free reference frame, to restore missing facial regions while
preserving identity. Subsequently, a SynergyNet-based module regresses 3D
Morphable Model (3DMM) parameters from the inpainted frames, enabling accurate
3D face reconstruction. Dense landmark optimization is incorporated throughout
the pipeline to improve both the inpainting quality and the fidelity of the
recovered geometry. Experimental results demonstrate that the proposed
framework can successfully remove HMDs from RGB facial videos while maintaining
facial identity and realism, producing photorealistic 3D face geometry outputs.
Ablation studies further show that the framework remains robust across
different landmark densities, with only minor quality degradation under sparse
landmark configurations.

</details>


### [61] [Semantic Discrepancy-aware Detector for Image Forgery Identification](https://arxiv.org/abs/2508.12341)
*Ziye Wang,Minghang Yu,Chunyan Xu,Zhen Cui*

Main category: cs.CV

TL;DR: 通过重构学习对准假图片检测中的语义空间与伪造空间的不一致问题，提出了语义差异感知检测器(SDD)方法


<details>
  <summary>Details</summary>
Motivation: 识别假图片对于确保数字媒体可信性至关重要，但假图与语义概念空间的不对凖影响了检测性能

Method: 利用预训练视觉语言模型的概念知识，设计语义标志采样模块减少空间偏移，通过视觉重构学习强化语义概念与伪造迹踏的交互

Result: 在两个标准图片伪造数据集上进行实验，证明SDD方法效果显著，超越现有方法

Conclusion: SDD通过细粒度视觉层面的空间对准有效解决了假图检测中的语义不一致问题，提高了检测性能

Abstract: With the rapid advancement of image generation techniques, robust forgery
detection has become increasingly imperative to ensure the trustworthiness of
digital media. Recent research indicates that the learned semantic concepts of
pre-trained models are critical for identifying fake images. However, the
misalignment between the forgery and semantic concept spaces hinders the
model's forgery detection performance. To address this problem, we propose a
novel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction
learning to align the two spaces at a fine-grained visual level. By exploiting
the conceptual knowledge embedded in the pre-trained vision language model, we
specifically design a semantic token sampling module to mitigate the space
shifts caused by features irrelevant to both forgery traces and semantic
concepts. A concept-level forgery discrepancy learning module, built upon a
visual reconstruction paradigm, is proposed to strengthen the interaction
between visual semantic concepts and forgery traces, effectively capturing
discrepancies under the concepts' guidance. Finally, the low-level forgery
feature enhancemer integrates the learned concept level forgery discrepancies
to minimize redundant forgery information. Experiments conducted on two
standard image forgery datasets demonstrate the efficacy of the proposed SDD,
which achieves superior results compared to existing methods. The code is
available at https://github.com/wzy1111111/SSD.

</details>


### [62] [AquaFeat: A Features-Based Image Enhancement Model for Underwater Object Detection](https://arxiv.org/abs/2508.12343)
*Emanuel C. Silva,Tatiana T. Schein,Stephanie L. Brião,Guilherme L. M. Costa,Felipe G. Oliveira,Gustavo P. Almeida,Eduardo L. Silva,Sam S. Devincenzi,Karina S. Machado,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: AquaFeat是一个即插即用的任务驱动特征增强模块，专门针对水下目标检测任务，通过在YOLOv8m上集成多尺度特征增强网络，显著提升了检测精度和召回率。


<details>
  <summary>Details</summary>
Motivation: 水下环境的严重图像退化影响了目标检测模型的性能，传统图像增强方法通常没有针对下游检测任务进行优化。

Method: 提出AquaFeat模块，集成多尺度特征增强网络，通过端到端训练与检测器损失函数相结合，确保增强过程明确指导以优化与检测任务最相关的特征。

Result: 在具有挑战性的水下数据集上，AquaFeat达到最先进的精度(0.877)和召回率(0.624)，以及竞争力的mAP分数(mAP@0.5为0.677，mAP@[0.5:0.95]为0.421)，处理速度为46.5 FPS。

Conclusion: AquaFeat在保持实用处理速度的同时提供显著的精度提升，为海洋生态系统监测和基础设施检查等实际应用提供了有效且计算效率高的解决方案。

Abstract: The severe image degradation in underwater environments impairs object
detection models, as traditional image enhancement methods are often not
optimized for such downstream tasks. To address this, we propose AquaFeat, a
novel, plug-and-play module that performs task-driven feature enhancement. Our
approach integrates a multi-scale feature enhancement network trained
end-to-end with the detector's loss function, ensuring the enhancement process
is explicitly guided to refine features most relevant to the detection task.
When integrated with YOLOv8m on challenging underwater datasets, AquaFeat
achieves state-of-the-art Precision (0.877) and Recall (0.624), along with
competitive mAP scores (mAP@0.5 of 0.677 and mAP@[0.5:0.95] of 0.421). By
delivering these accuracy gains while maintaining a practical processing speed
of 46.5 FPS, our model provides an effective and computationally efficient
solution for real-world applications, such as marine ecosystem monitoring and
infrastructure inspection.

</details>


### [63] [MBMamba: When Memory Buffer Meets Mamba for Structure-Aware Image Deblurring](https://arxiv.org/abs/2508.12346)
*Hu Gao,Depeng Dang*

Main category: cs.CV

TL;DR: 基于Mamba架构的图像去模糊网络MBMamba，通过内存缓冲机制保留历史信息，以及Ising灵感的正则化损失维护图像结构一致性，在不改变Mamba原有架构的情况下提升了去模糊性能。


<details>
  <summary>Details</summary>
Motivation: Mamba架构在图像去模糊中存在局部像素遗忘和通道冗余问题，而现有改进方法通常会增加计算复杂度影响实时性能。

Method: 设计内存缓冲机制保留历史信息并进行融合，引入Ising灵感的正则化损失模拟物理系统能量最小化过程，维护图像结构一致性。

Result: 在广泛使用的测试集上超越了现有最先进方法。

Conclusion: MBMamba在不改变Mamba原有架构的前提下，通过内存缓冲和物理灵感正则化有效解决了局部信息遗失问题，实现了更好的图像去模糊效果。

Abstract: The Mamba architecture has emerged as a promising alternative to CNNs and
Transformers for image deblurring. However, its flatten-and-scan strategy often
results in local pixel forgetting and channel redundancy, limiting its ability
to effectively aggregate 2D spatial information. Although existing methods
mitigate this by modifying the scan strategy or incorporating local feature
modules, it increase computational complexity and hinder real-time performance.
In this paper, we propose a structure-aware image deblurring network without
changing the original Mamba architecture. Specifically, we design a memory
buffer mechanism to preserve historical information for later fusion, enabling
reliable modeling of relevance between adjacent features. Additionally, we
introduce an Ising-inspired regularization loss that simulates the energy
minimization of the physical system's "mutual attraction" between pixels,
helping to maintain image structure and coherence. Building on this, we develop
MBMamba. Experimental results show that our method outperforms state-of-the-art
approaches on widely used benchmarks.

</details>


### [64] [EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos](https://arxiv.org/abs/2508.12349)
*Junyi Ma,Erhang Zhang,Yin-Dong Zheng,Yuchen Xie,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: 本文提出EgoLoc，一种零样本方法，用于在自我中心视频中定位手-物体接触和分离的时间戳，无需对象掩码和动词-名词分类，在VR/AR和机器人操作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注交互动作的行为范式（如何交互），但对手与目标物体接触和分离的关键时刻（何时交互）这一更精细的问题研究不足，这对混合现实中的沉浸式交互体验和机器人运动规划至关重要。

Method: 提出EgoLoc方法，采用手动力学引导采样生成高质量视觉提示，利用视觉语言模型识别接触/分离属性、定位特定时间戳，并提供闭环反馈进行进一步优化。

Result: 在公共数据集和新基准测试上的综合实验表明，EgoLoc能够实现合理的时序交互定位，有效促进自我中心视觉和机器人操作任务中的多个下游应用。

Conclusion: EgoLoc消除了对对象掩码和动词-名词分类的需求，实现了可推广的零样本实现，为自我中心视频中的精细时序交互定位提供了有效解决方案。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR
applications and human-robot policy transfer. Existing research has mostly
focused on modeling the behavior paradigm of interactive actions (i.e., ``how
to interact''). However, the more challenging and fine-grained problem of
capturing the critical moments of contact and separation between the hand and
the target object (i.e., ``when to interact'') is still underexplored, which is
crucial for immersive interactive experiences in mixed reality and robotic
motion planning. Therefore, we formulate this problem as temporal interaction
localization (TIL). Some recent works extract semantic masks as TIL references,
but suffer from inaccurate object grounding and cluttered scenarios. Although
current temporal action localization (TAL) methods perform well in detecting
verb-noun action segments, they rely on category annotations during training
and exhibit limited precision in localizing hand-object contact/separation
moments. To address these issues, we propose a novel zero-shot approach dubbed
EgoLoc to localize hand-object contact and separation timestamps in egocentric
videos. EgoLoc introduces hand-dynamics-guided sampling to generate
high-quality visual prompts. It exploits the vision-language model to identify
contact/separation attributes, localize specific timestamps, and provide
closed-loop feedback for further refinement. EgoLoc eliminates the need for
object masks and verb-noun taxonomies, leading to generalizable zero-shot
implementation. Comprehensive experiments on the public dataset and our novel
benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric
videos. It is also validated to effectively facilitate multiple downstream
applications in egocentric vision and robotic manipulation tasks. Code and
relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [65] [Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data](https://arxiv.org/abs/2508.12356)
*Ahmet H. Güzel,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.CV

TL;DR: 通过生成合成训练数据来改善视觉基于离线强化学习的绝捧性能，包括数据增帆和潜空间激光模型生成数据


<details>
  <summary>Details</summary>
Motivation: 离线RL策略在视觉数据上遇到一般化困难，包括噪声、干扰和偏相关等问题，需要更多样本来提升策略的绝捧性能

Method: 两步流程：首先对离线数据进行增帆提升多样性，然后使用激光模型在潜空间生成额外的合成数据

Result: 在连续动作空间(Visual D4RL)和离散动作空间(Procgen)上都显著提升了一般化性能力，减小了测试时的一般化差距但保持计算效率

Conclusion: 该方法不需要改变现有离线RL算法，通过生成合成数据可以有效提升策略的绝捧性能，为训练更通用的代理提供了新方向

Abstract: Offline reinforcement learning (RL) offers a promising framework for training
agents using pre-collected datasets without the need for further environment
interaction. However, policies trained on offline data often struggle to
generalise due to limited exposure to diverse states. The complexity of visual
data introduces additional challenges such as noise, distractions, and spurious
correlations, which can misguide the policy and increase the risk of
overfitting if the training data is not sufficiently diverse. Indeed, this
makes it challenging to leverage vision-based offline data in training robust
agents that can generalize to unseen environments. To solve this problem, we
propose a simple approach generating additional synthetic training data. We
propose a two-step process, first augmenting the originally collected offline
data to improve zero-shot generalization by introducing diversity, then using a
diffusion model to generate additional data in latent space. We test our method
across both continuous action spaces (Visual D4RL) and discrete action spaces
(Procgen), demonstrating that it significantly improves generalization without
requiring any algorithmic changes to existing model-free offline RL methods. We
show that our method not only increases the diversity of the training data but
also significantly reduces the generalization gap at test time while
maintaining computational efficiency. We believe this approach could fuel
additional progress in generating synthetic data to train more general agents
in the future.

</details>


### [66] [IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis](https://arxiv.org/abs/2508.12381)
*Guo Tang,Songhan Jiang,Jinpeng Lu,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: IPGPhormer是一个用于病理图像生存分析的可解释图-Transformer框架，能够同时捕获肿瘤微环境的空间依赖关系，在预测准确性和可解释性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平衡长距离空间关系建模与局部上下文依赖方面存在困难，且缺乏内在可解释性，限制了临床实用性。

Method: 提出Interpretable Pathology Graph-Transformer (IPGPhormer)框架，通过图-Transformer结构捕获肿瘤微环境特征并建模其空间依赖关系，无需后处理手动标注即可提供组织和细胞级别的可解释性。

Result: 在四个公共基准数据集上的综合评估表明，IPGPhormer在预测准确性和可解释性方面均优于最先进方法。

Conclusion: IPGPhormer为癌症预后评估提供了一个有前景的工具，为病理学中更可靠和可解释的决策支持系统铺平了道路。

Abstract: Pathological images play an essential role in cancer prognosis, while
survival analysis, which integrates computational techniques, can predict
critical clinical events such as patient mortality or disease recurrence from
whole-slide images (WSIs). Recent advancements in multiple instance learning
have significantly improved the efficiency of survival analysis. However,
existing methods often struggle to balance the modeling of long-range spatial
relationships with local contextual dependencies and typically lack inherent
interpretability, limiting their clinical utility. To address these challenges,
we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel
framework that captures the characteristics of the tumor microenvironment and
models their spatial dependencies across the tissue. IPGPhormer uniquely
provides interpretability at both tissue and cellular levels without requiring
post-hoc manual annotations, enabling detailed analyses of individual WSIs and
cross-cohort assessments. Comprehensive evaluations on four public benchmark
datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in
both predictive accuracy and interpretability. In summary, our method,
IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the
way for more reliable and interpretable decision-support systems in pathology.
The code is publicly available at
https://anonymous.4open.science/r/IPGPhormer-6EEB.

</details>


### [67] [ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](https://arxiv.org/abs/2508.12384)
*Hanwen Cao,Haobo Lu,Xiaosen Wang,Kun He*

Main category: cs.CV

TL;DR: 提出ViT-EnsembleAttack方法，通过对抗性增强ViT模型来提升集成攻击的迁移性，在ViT模型上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有集成攻击研究主要关注优化集成权重或路径，忽略了通过增强集成模型本身来提升对抗迁移性的探索，特别是在ViT模型上的集成攻击研究较少

Method: 对每个ViT代理模型采用三种对抗增强策略：多头丢弃、注意力分数缩放和MLP特征混合，使用贝叶斯优化优化参数，并引入自动重加权和步长扩大模块

Result: 大量实验表明ViT-EnsembleAttack显著提升了ViT集成攻击的对抗迁移性，大幅超越现有方法

Conclusion: 该方法通过对抗性增强集成模型有效提升了迁移攻击性能，为ViT模型的集成攻击提供了新思路

Abstract: Ensemble-based attacks have been proven to be effective in enhancing
adversarial transferability by aggregating the outputs of models with various
architectures. However, existing research primarily focuses on refining
ensemble weights or optimizing the ensemble path, overlooking the exploration
of ensemble models to enhance the transferability of adversarial attacks. To
address this gap, we propose applying adversarial augmentation to the surrogate
models, aiming to boost overall generalization of ensemble models and reduce
the risk of adversarial overfitting. Meanwhile, observing that ensemble Vision
Transformers (ViTs) gain less attention, we propose ViT-EnsembleAttack based on
the idea of model adversarial augmentation, the first ensemble-based attack
method tailored for ViTs to the best of our knowledge. Our approach generates
augmented models for each surrogate ViT using three strategies: Multi-head
dropping, Attention score scaling, and MLP feature mixing, with the associated
parameters optimized by Bayesian optimization. These adversarially augmented
models are ensembled to generate adversarial examples. Furthermore, we
introduce Automatic Reweighting and Step Size Enlargement modules to boost
transferability. Extensive experiments demonstrate that ViT-EnsembleAttack
significantly enhances the adversarial transferability of ensemble-based
attacks on ViTs, outperforming existing methods by a substantial margin. Code
is available at https://github.com/Trustworthy-AI-Group/TransferAttack.

</details>


### [68] [DeCoT: Decomposing Complex Instructions for Enhanced Text-to-Image Generation with Large Language Models](https://arxiv.org/abs/2508.12396)
*Xiaochuan Lin,Xiangyong Chen,Xuan Li,Yichen Su*

Main category: cs.CV

TL;DR: DeCoT是一个通过大语言模型分解复杂文本指令来提升文生图模型性能的框架，在LongBench-T2I基准测试中显著改善了文本渲染和构图能力。


<details>
  <summary>Details</summary>
Motivation: 当前文生图模型在处理复杂长文本指令时存在困难，经常无法准确渲染细节、空间关系和特定约束，在构图、文本渲染和纹理细节方面表现不佳。

Method: DeCoT采用两阶段框架：1）复杂指令分解和语义增强，使用LLM将原始指令分解为结构化语义单元并澄清歧义；2）多阶段提示集成和自适应生成，将这些单元转换为分层或优化的单一提示。

Result: 在LongBench-T2I数据集上，DeCoT显著提升了主流文生图模型的性能，特别是在"文本"和"构图"等挑战性维度。与Infinity-8B集成时平均得分从3.44提升到3.52，人类评估也证实了感知质量和指令保真度的提升。

Conclusion: DeCoT有效弥合了用户高级意图与文生图模型需求之间的差距，实现了更忠实和准确的图像生成，消融研究证实了各组件的重要性和复杂LLM提示的关键作用。

Abstract: Despite remarkable advancements, current Text-to-Image (T2I) models struggle
with complex, long-form textual instructions, frequently failing to accurately
render intricate details, spatial relationships, or specific constraints. This
limitation is highlighted by benchmarks such as LongBench-T2I, which reveal
deficiencies in handling composition, specific text, and fine textures. To
address this, we propose DeCoT (Decomposition-CoT), a novel framework that
leverages Large Language Models (LLMs) to significantly enhance T2I models'
understanding and execution of complex instructions. DeCoT operates in two core
stages: first, Complex Instruction Decomposition and Semantic Enhancement,
where an LLM breaks down raw instructions into structured, actionable semantic
units and clarifies ambiguities; second, Multi-Stage Prompt Integration and
Adaptive Generation, which transforms these units into a hierarchical or
optimized single prompt tailored for existing T2I models. Extensive experiments
on the LongBench-T2I dataset demonstrate that DeCoT consistently and
substantially improves the performance of leading T2I models across all
evaluated dimensions, particularly in challenging aspects like "Text" and
"Composition". Quantitative results, validated by multiple MLLM evaluators
(Gemini-2.0-Flash and InternVL3-78B), show that DeCoT, when integrated with
Infinity-8B, achieves an average score of 3.52, outperforming the baseline
Infinity-8B (3.44). Ablation studies confirm the critical contribution of each
DeCoT component and the importance of sophisticated LLM prompting. Furthermore,
human evaluations corroborate these findings, indicating superior perceptual
quality and instruction fidelity. DeCoT effectively bridges the gap between
high-level user intent and T2I model requirements, leading to more faithful and
accurate image generation.

</details>


### [69] [Federated Cross-Modal Style-Aware Prompt Generation](https://arxiv.org/abs/2508.12399)
*Suraj Prasad,Navyansh Mahla,Sunny Gupta,Amit Sethi*

Main category: cs.CV

TL;DR: FedCSAP是一个联邦学习框架，通过利用CLIP视觉编码器的多尺度特征和客户端特定风格指标，生成鲁棒的跨模态提示，在保护数据隐私的同时提升分类准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统联邦提示学习方法仅依赖最终层特征，无法充分利用去中心化客户端数据中的多尺度视觉线索和领域特定风格变化，限制了模型性能。

Method: 利用CLIP视觉编码器的低、中、高层特征，结合客户端批量统计信息提取的风格指标，将精细视觉细节与文本上下文融合，生成独特且非冗余的上下文感知提示令牌。

Result: 在多个图像分类数据集上的实验表明，FedCSAP在准确性和整体泛化能力方面优于现有的联邦提示学习方法。

Conclusion: FedCSAP通过多尺度特征融合和风格感知机制，有效解决了联邦学习中非IID数据分布和领域风格差异的挑战，实现了更好的性能表现。

Abstract: Prompt learning has propelled vision-language models like CLIP to excel in
diverse tasks, making them ideal for federated learning due to computational
efficiency. However, conventional approaches that rely solely on final-layer
features miss out on rich multi-scale visual cues and domain-specific style
variations in decentralized client data. To bridge this gap, we introduce
FedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework
harnesses low, mid, and high-level features from CLIP's vision encoder
alongside client-specific style indicators derived from batch-level statistics.
By merging intricate visual details with textual context, FedCSAP produces
robust, context-aware prompt tokens that are both distinct and non-redundant,
thereby boosting generalization across seen and unseen classes. Operating
within a federated learning paradigm, our approach ensures data privacy through
local training and global aggregation, adeptly handling non-IID class
distributions and diverse domain-specific styles. Comprehensive experiments on
multiple image classification datasets confirm that FedCSAP outperforms
existing federated prompt learning methods in both accuracy and overall
generalization.

</details>


### [70] [MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2508.12400)
*Amirul Rahman,Qiang Xu,Xueying Huang*

Main category: cs.CV

TL;DR: MPCAR是一种无需微调的推理时策略，通过多角度生成描述、智能整合上下文和深度推理三阶段，显著提升大视觉语言模型在复杂视觉推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型在需要深度上下文理解、多角度分析或细节识别的复杂视觉推理任务中表现有限，主要受限于单次图像编码和提示的约束。

Method: 三阶段方法：1）从不同角度生成N个多样化描述；2）智能整合这些描述与原始问题构建上下文增强提示；3）使用增强提示进行深度推理和最终答案生成。无需微调模型参数。

Result: 在GQA、VQA-CP v2和ScienceQA等挑战性VQA数据集上持续超越基线方法，在需要强上下文理解的任务上获得显著准确率提升，人类评估也确认了答案连贯性和完整性的改善。

Conclusion: 通过利用大视觉语言模型固有的生成能力来丰富输入上下文，可以有效释放其在复杂多模态任务中的潜在推理潜力，无需额外训练成本。

Abstract: Despite significant advancements, Large Vision-Language Models (LVLMs)
continue to face challenges in complex visual reasoning tasks that demand deep
contextual understanding, multi-angle analysis, or meticulous detail
recognition. Existing approaches often rely on single-shot image encoding and
prompts, limiting their ability to fully capture nuanced visual information.
Inspired by the notion that strategically generated "additional" information
can serve as beneficial contextual augmentation, we propose Multi-Perspective
Contextual Augmentation for Reasoning (MPCAR), a novel inference-time strategy
designed to enhance LVLM performance. MPCAR operates in three stages: first, an
LVLM generates N diverse and complementary descriptions or preliminary
reasoning paths from various angles; second, these descriptions are
intelligently integrated with the original question to construct a
comprehensive context-augmented prompt; and finally, this enriched prompt
guides the ultimate LVLM for deep reasoning and final answer generation.
Crucially, MPCAR achieves these enhancements without requiring any fine-tuning
of the underlying LVLM's parameters. Extensive experiments on challenging
Visual Question Answering (VQA) datasets, including GQA, VQA-CP v2, and
ScienceQA (Image-VQA), demonstrate that MPCAR consistently outperforms
established baseline methods. Our quantitative results show significant
accuracy gains, particularly on tasks requiring robust contextual
understanding, while human evaluations confirm improved coherence and
completeness of the generated answers. Ablation studies further highlight the
importance of diverse prompt templates and the number of generated
perspectives. This work underscores the efficacy of leveraging LVLMs' inherent
generative capabilities to enrich input contexts, thereby unlocking their
latent reasoning potential for complex multimodal tasks.

</details>


### [71] [LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving](https://arxiv.org/abs/2508.12404)
*Nan Song,Bozhou Zhang,Xiatian Zhu,Jiankang Deng,Li Zhang*

Main category: cs.CV

TL;DR: LMAD是一个专为自动驾驶设计的视觉语言框架，通过整合全面的场景理解和任务专用结构，显著提升了现有VLM在驾驶推理任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有的VLM方法在自动驾驶场景中缺乏整体细致的场景识别能力和强大的空间感知能力，特别是在复杂情况下表现不足

Method: 提出LMAD框架，模拟现代端到端驾驶范式，引入初步场景交互和专用专家适配器，在相同的驾驶任务结构中更好地对齐VLM与自动驾驶场景

Result: 在DriveLM和nuScenes-QA数据集上的大量实验表明，LMAD显著提升了现有VLM在驾驶推理任务中的性能

Conclusion: LMAD为可解释自动驾驶设立了新标准，完全兼容现有VLM并能无缝集成到规划导向的驾驶系统中

Abstract: Large vision-language models (VLMs) have shown promising capabilities in
scene understanding, enhancing the explainability of driving behaviors and
interactivity with users. Existing methods primarily fine-tune VLMs on on-board
multi-view images and scene reasoning text, but this approach often lacks the
holistic and nuanced scene recognition and powerful spatial awareness required
for autonomous driving, especially in complex situations. To address this gap,
we propose a novel vision-language framework tailored for autonomous driving,
called LMAD. Our framework emulates modern end-to-end driving paradigms by
incorporating comprehensive scene understanding and a task-specialized
structure with VLMs. In particular, we introduce preliminary scene interaction
and specialized expert adapters within the same driving task structure, which
better align VLMs with autonomous driving scenarios. Furthermore, our approach
is designed to be fully compatible with existing VLMs while seamlessly
integrating with planning-oriented driving systems. Extensive experiments on
the DriveLM and nuScenes-QA datasets demonstrate that LMAD significantly boosts
the performance of existing VLMs on driving reasoning tasks,setting a new
standard in explainable autonomous driving.

</details>


### [72] [S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing](https://arxiv.org/abs/2508.12409)
*Liang Lv,Di Wang,Jing Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: 这篇论文提出了S5框架，首个可扩展的远感半监督语义分割方案，通过大规模数据集RS4P-1M和基础模型预训练，在多个远感测试集上创造了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有半监督语义分割方法依赖小规模数据集和模型的限制，充分利用大量未标注的地球观测数据来提升实际应用能力。

Method: 构建RS4P-1M大规模数据集（集成基于熵的过滤和多样性扩展），进行多规模基础模型预训练，并在微调时采用混合专家网络（MoE）的多数据集微调方法。

Result: 在土地覆盖分割和物体检测任务上显著提升性能，在所有远感测试集上达到了最佳性能水平。

Conclusion: 证明了通过扩展半监督学习来提升远感应用的可行性，为大规模未标注数据的利用提供了有效方案。

Abstract: Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS)
analysis by leveraging unlabeled data through pseudo-labeling and consistency
learning. However, existing S4 studies often rely on small-scale datasets and
models, limiting their practical applicability. To address this, we propose S5,
the first scalable framework for semi-supervised semantic segmentation in RS,
which unlocks the potential of vast unlabeled Earth observation data typically
underutilized due to costly pixel-level annotations. Built upon existing
large-scale RS datasets, S5 introduces a data selection strategy that
integrates entropy-based filtering and diversity expansion, resulting in the
RS4P-1M dataset. Using this dataset, we systematically scales S4 methods by
pre-training RS foundation models (RSFMs) of varying sizes on this extensive
corpus, significantly boosting their performance on land cover segmentation and
object detection tasks. Furthermore, during fine-tuning, we incorporate a
Mixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which
enables efficient adaptation to multiple RS benchmarks with fewer parameters.
This approach improves the generalization and versatility of RSFMs across
diverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance
across all benchmarks, underscoring the viability of scaling semi-supervised
learning for RS applications. All datasets, code, and models will be released
at https://github.com/MiliLab/S5

</details>


### [73] [SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes](https://arxiv.org/abs/2508.12410)
*Jun Zeng,Yannan Huang,Elif Keles,Halil Ertugrul Aktas,Gorkem Durak,Nikhil Kumar Tomar,Quoc-Huy Trinh,Deepak Ranjan Nayak,Ulas Bagci,Debesh Jha*

Main category: cs.CV

TL;DR: 提出了SRMA-Mamba网络，通过整合空间解剖Mamba模块和空间反向注意力模块，实现肝脏MRI体积数据的精准病理分割，在肝硬化检测方面超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 肝硬化早期检测对降低死亡率至关重要，但现有方法未能充分利用MRI体积数据中的空间解剖细节，限制了临床效果和可解释性。

Method: 开发SRMA-Mamba网络，包含SABMamba模块（在肝硬化组织内进行选择性Mamba扫描并整合三平面解剖信息）和SRMA模块（利用粗分割图和分层编码特征逐步细化分割细节）。

Result: 大量实验表明SRMA-Mamba在3D病理肝脏分割方面超越了最先进的方法，表现出卓越性能。

Conclusion: 该方法通过有效建模MRI体积中的空间解剖关系，为肝硬化病变的精确检测和表征提供了有效的解决方案。

Abstract: Liver Cirrhosis plays a critical role in the prognosis of chronic liver
disease. Early detection and timely intervention are critical in significantly
reducing mortality rates. However, the intricate anatomical architecture and
diverse pathological changes of liver tissue complicate the accurate detection
and characterization of lesions in clinical settings. Existing methods
underutilize the spatial anatomical details in volumetric MRI data, thereby
hindering their clinical effectiveness and explainability. To address this
challenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to
model the spatial relationships within the complex anatomical structures of MRI
volumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),
SRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and
combines anatomical information from the sagittal, coronal, and axial planes to
construct a global spatial context representation, enabling efficient
volumetric segmentation of pathological liver structures. Furthermore, we
introduce the Spatial Reverse Attention module (SRMA), designed to
progressively refine cirrhotic details in the segmentation map, utilizing both
the coarse segmentation map and hierarchical encoding features. Extensive
experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,
delivering exceptional performance in 3D pathological liver segmentation. Our
code is available for public:
{\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}.

</details>


### [74] [TiP4GEN: Text to Immersive Panorama 4D Scene Generation](https://arxiv.org/abs/2508.12415)
*Ke Xing,Hanwen Liang,Dejia Xu,Yuyang Yin,Konstantinos N. Plataniotis,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: TiP4GEN是一个文本到动态全景场景生成框架，通过结合全景视频生成和动态场景重建技术，能够从文本描述生成几何一致、运动丰富的360度沉浸式4D场景。


<details>
  <summary>Details</summary>
Motivation: 随着VR/AR技术的快速发展，对高质量沉浸式动态场景的需求日益增长。现有工作主要集中于静态场景或窄视角动态场景生成，无法提供真正360度任意视角的沉浸体验。

Method: 采用双分支生成模型（全景分支和透视分支）进行视频生成，通过双向交叉注意力机制实现信息交换；基于3D高斯泼溅的几何对齐重建模型，利用度量深度图对齐时空点云，并通过估计位姿初始化场景相机。

Result: 大量实验证明了所提出设计的有效性，TiP4GEN在生成视觉吸引人且运动连贯的动态全景场景方面表现出优越性。

Conclusion: TiP4GEN框架成功解决了动态全景场景生成的关键挑战，为创建高质量360度沉浸式虚拟环境提供了有效解决方案。

Abstract: With the rapid advancement and widespread adoption of VR/AR technologies,
there is a growing demand for the creation of high-quality, immersive dynamic
scenes. However, existing generation works predominantly concentrate on the
creation of static scenes or narrow perspective-view dynamic scenes, falling
short of delivering a truly 360-degree immersive experience from any viewpoint.
In this paper, we introduce \textbf{TiP4GEN}, an advanced text-to-dynamic
panorama scene generation framework that enables fine-grained content control
and synthesizes motion-rich, geometry-consistent panoramic 4D scenes. TiP4GEN
integrates panorama video generation and dynamic scene reconstruction to create
360-degree immersive virtual environments. For video generation, we introduce a
\textbf{Dual-branch Generation Model} consisting of a panorama branch and a
perspective branch, responsible for global and local view generation,
respectively. A bidirectional cross-attention mechanism facilitates
comprehensive information exchange between the branches. For scene
reconstruction, we propose a \textbf{Geometry-aligned Reconstruction Model}
based on 3D Gaussian Splatting. By aligning spatial-temporal point clouds using
metric depth maps and initializing scene cameras with estimated poses, our
method ensures geometric consistency and temporal coherence for the
reconstructed scenes. Extensive experiments demonstrate the effectiveness of
our proposed designs and the superiority of TiP4GEN in generating visually
compelling and motion-coherent dynamic panoramic scenes. Our project page is at
https://ke-xing.github.io/TiP4GEN/.

</details>


### [75] [Illusions in Humans and AI: How Visual Perception Aligns and Diverges](https://arxiv.org/abs/2508.12422)
*Jianyi Yang,Junyi Ye,Ankan Dash,Guiling Wang*

Main category: cs.CV

TL;DR: 通过对比生物与人工智能在视觉幻觉上的反应差异，揭示了AI视觉系统的特有弱点和对齐问题，为开发更稳健、可解释的AI视觉系统提供见解


<details>
  <summary>Details</summary>
Motivation: 随着人工智能视觉系统越来越多地执行类人视觉任务，需要了解AI是否也会出现类似于人类的幻觉体验，以及是否存在AI特有的幻觉现象

Method: 通过系统性对比人类和AI对经典视觉幻觉（包括颜色、大小、形状、运动等）的反应，分析AI模型中幻觉效应的产生机制

Result: 发现AI会出现某些类似人类的幻觉效应（通过目标训练或模式识别的副产品），同时也识别出了AI特有的幻觉现象（如像素级敏感性、幻觉生成等）

Conclusion: 通过视觉幻觉对比揭示了人工智能与人类视觉的对齐缺口和AI特有的感知脏弱点，为开发保持人类有益感知偏见同时避免破坏信任和安全的抑制性形变的视觉系统提供了重要见解

Abstract: By comparing biological and artificial perception through the lens of
illusions, we highlight critical differences in how each system constructs
visual reality. Understanding these divergences can inform the development of
more robust, interpretable, and human-aligned artificial intelligence (AI)
vision systems. In particular, visual illusions expose how human perception is
based on contextual assumptions rather than raw sensory data. As artificial
vision systems increasingly perform human-like tasks, it is important to ask:
does AI experience illusions, too? Does it have unique illusions? This article
explores how AI responds to classic visual illusions that involve color, size,
shape, and motion. We find that some illusion-like effects can emerge in these
models, either through targeted training or as by-products of pattern
recognition. In contrast, we also identify illusions unique to AI, such as
pixel-level sensitivity and hallucinations, that lack human counterparts. By
systematically comparing human and AI responses to visual illusions, we uncover
alignment gaps and AI-specific perceptual vulnerabilities invisible to human
perception. These findings provide insights for future research on vision
systems that preserve human-beneficial perceptual biases while avoiding
distortions that undermine trust and safety.

</details>


### [76] [Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations](https://arxiv.org/abs/2508.12430)
*Yahsin Yeh,Yilun Wu,Bokai Ruan,Honghan Shuai*

Main category: cs.CV

TL;DR: 这篇论文揭示了视觉问答系统中的解释不一致性漏洞，提出了新的对抗攻击策略和基于外部知识的缓解方法，展现了当前VQA-NLE系统的安全性和可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 现有VQA-NLE系统存在解释不一致和缺乏真正理解的问题，需要更好地揭示黑盒模型的决策过程并提高其透明度。

Method: 利用现有对抗策略扰动问题，并提出一种新的最小化修改图像的对抗策略，以引发矛盾或假的输出。同时提出了基于外部知识的缓解方法来减少这些不一致性。

Result: 在两个标准测试集和两个广泛使用的VQA-NLE模型上进行了涉幅评估，证明了攻击策略的有效性，以及知识基础防御方法的潜力。

Conclusion: 当前VQA-NLE系统存在严重的安全性和可靠性问题，需要重视这些漏洞并开发更健壮的解释机制来提高模型的透明度和耐受性。

Abstract: Natural language explanations in visual question answering (VQA-NLE) aim to
make black-box models more transparent by elucidating their decision-making
processes. However, we find that existing VQA-NLE systems can produce
inconsistent explanations and reach conclusions without genuinely understanding
the underlying context, exposing weaknesses in either their inference pipeline
or explanation-generation mechanism. To highlight these vulnerabilities, we not
only leverage an existing adversarial strategy to perturb questions but also
propose a novel strategy that minimally alters images to induce contradictory
or spurious outputs. We further introduce a mitigation method that leverages
external knowledge to alleviate these inconsistencies, thereby bolstering model
robustness. Extensive evaluations on two standard benchmarks and two widely
used VQA-NLE models underscore the effectiveness of our attacks and the
potential of knowledge-based defenses, ultimately revealing pressing security
and reliability concerns in current VQA-NLE systems.

</details>


### [77] [X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning](https://arxiv.org/abs/2508.12455)
*Chee Ng,Liliang Sun,Shaoqing Tang*

Main category: cs.CV

TL;DR: X-Ray-CoT是一个基于视觉语言大模型的框架，通过模拟放射科医生的思维链过程，实现胸部X光片的智能诊断和可解释报告生成，在保持高准确率的同时提供透明化的诊断解释。


<details>
  <summary>Details</summary>
Motivation: 胸部X光片诊断需要丰富临床经验且存在观察者间差异，现有深度学习模型虽然准确率高但缺乏可解释性，阻碍了在临床高风险医疗环境中的应用。

Method: 提出X-Ray-CoT框架，首先提取多模态特征和视觉概念，然后使用基于LLM的组件配合结构化思维链提示策略进行推理，生成详细自然语言诊断报告。

Result: 在CORDA数据集上达到80.52%的平衡准确率和78.65%的F1分数，略优于现有黑盒模型，并能生成高质量的可解释报告。

Conclusion: 该工作代表了医学影像领域向可信赖和临床可操作AI系统的重要进展，消融研究证实了多模态融合和思维链推理对构建稳健透明医疗AI的必要性。

Abstract: Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,
yet its interpretation demands extensive clinical experience and suffers from
inter-observer variability. While deep learning models offer high diagnostic
accuracy, their black-box nature hinders clinical adoption in high-stakes
medical settings. To address this, we propose X-Ray-CoT (Chest X-Ray
Chain-of-Thought), a novel framework leveraging Vision-Language Large Models
(LVLMs) for intelligent chest X-ray diagnosis and interpretable report
generation. X-Ray-CoT simulates human radiologists' "chain-of-thought" by first
extracting multi-modal features and visual concepts, then employing an
LLM-based component with a structured Chain-of-Thought prompting strategy to
reason and produce detailed natural language diagnostic reports. Evaluated on
the CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,
with a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease
diagnosis, slightly surpassing existing black-box models. Crucially, it
uniquely generates high-quality, explainable reports, as validated by
preliminary human evaluations. Our ablation studies confirm the integral role
of each proposed component, highlighting the necessity of multi-modal fusion
and CoT reasoning for robust and transparent medical AI. This work represents a
significant step towards trustworthy and clinically actionable AI systems in
medical imaging.

</details>


### [78] [Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping](https://arxiv.org/abs/2508.12466)
*Xuhui Zhan,Tyler Derr*

Main category: cs.CV

TL;DR: Inverse-LLaVA是一种新颖的多模态学习方法，无需对齐预训练，通过将文本嵌入映射到视觉表示空间并在transformer中间层进行融合，实现了计算需求减少45%的高效多模态学习。


<details>
  <summary>Details</summary>
Motivation: 挑战传统多模态学习需要昂贵对齐预训练的范式，探索无需对齐预训练的有效多模态学习方法，同时反转传统的视觉到文本的映射方向。

Method: 提出Inverse-LLaVA方法：将文本嵌入映射到连续视觉表示空间，在transformer中间层通过选择性加性注意力组件进行动态融合，无需大规模图像-文本对齐数据集。

Result: 在9个多模态基准测试中表现出细微的性能权衡：推理密集型任务显著提升（MM-VET: +0.2%, VizWiz: +1.8%, ScienceQA: +0.2%, 认知推理: +27.2%），但感知任务有所下降（名人识别: -49.5%, OCR: -21.3%）。

Conclusion: 首次实证证明对齐预训练对于有效的多模态学习并非必要，特别是复杂推理任务；建立了一种减少45%计算需求的新范式，挑战了模态融合的传统观念，为保留模态特定特征的高效多模态架构开辟了新方向。

Abstract: Traditional multimodal learning approaches require expensive alignment
pre-training to bridge vision and language modalities, typically projecting
visual features into discrete text token spaces. We challenge both fundamental
assumptions underlying this paradigm by proposing Inverse-LLaVA, a novel
approach that eliminates alignment pre-training entirely while inverting the
conventional mapping direction. Rather than projecting visual features to text
space, our method maps text embeddings into continuous visual representation
space and performs fusion within transformer intermediate layers. Through
selective additive components in attention mechanisms, we enable dynamic
integration of visual and textual representations without requiring massive
image-text alignment datasets. Comprehensive experiments across nine multimodal
benchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves
notable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,
VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing
expected decreases in perception tasks requiring memorized visual-text
associations (celebrity recognition: -49.5%, OCR: -21.3%). These results
provide the first empirical evidence that alignment pre-training is not
necessary for effective multimodal learning, particularly for complex reasoning
tasks. Our work establishes the feasibility of a new paradigm that reduces
computational requirements by 45%, challenges conventional wisdom about
modality fusion, and opens new research directions for efficient multimodal
architectures that preserve modality-specific characteristics. Our project
website with code and additional resources is available at
https://inverse-llava.github.io.

</details>


### [79] [Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2508.12473)
*Eranga Bandara,Ross Gore,Sachin Shetty,Ravi Mukkamala,Christopher Rhea,Atmaram Yarlagadda,Shaifali Kaushik,L. H. M. P. De Silva,Andriy Maznychenko,Inna Sokolowska,Amin Hass,Kasun De Zoysa*

Main category: cs.CV

TL;DR: 使用细调视觉-语言模型联盟和理解大语言模型构建自动化H-反射波形诊断系统，提高神经肌肉评估的准确性和标准化程度


<details>
  <summary>Details</summary>
Motivation: 传统H-反射EMG波形分析存在主观性和变异性问题，影响评估的可靠性和标准化

Method: 多个细调VLM模型分析EMG波形图像，通过共识机制聚合结果，然后由专门理解LLM进行精炼和解释

Result: 混合系统实现了高精度、一致性和可解释的H-反射评估

Conclusion: 该研究首次将细调VLM联盟与理解LLM集成用于图像基H-反射分析，为下一代AI辅助神经肌肉评估平台奠定基础

Abstract: Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a
critical role in sports science, rehabilitation, and clinical neurology.
Traditional analysis of H-reflex EMG waveforms is subject to variability and
interpretation bias among clinicians and researchers, limiting reliability and
standardization. To address these challenges, we propose a Fine-Tuned
Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model
(LLM)-enabled Decision Support System for automated H-reflex waveform
interpretation and diagnosis. Our approach leverages multiple VLMs, each
fine-tuned on curated datasets of H-reflex EMG waveform images annotated with
clinical observations, recovery timelines, and athlete metadata. These models
are capable of extracting key electrophysiological features and predicting
neuromuscular states, including fatigue, injury, and recovery, directly from
EMG images and contextual metadata. Diagnostic outputs from the VLM consortium
are aggregated using a consensus-based method and refined by a specialized
reasoning LLM, which ensures robust, transparent, and explainable decision
support for clinicians and sports scientists. The end-to-end platform
orchestrates seamless communication between the VLM ensemble and the reasoning
LLM, integrating prompt engineering strategies and automated reasoning
workflows using LLM Agents. Experimental results demonstrate that this hybrid
system delivers highly accurate, consistent, and interpretable H-reflex
assessments, significantly advancing the automation and standardization of
neuromuscular diagnostics. To our knowledge, this work represents the first
integration of a fine-tuned VLM consortium with a reasoning LLM for image-based
H-reflex analysis, laying the foundation for next-generation AI-assisted
neuromuscular assessment and athlete monitoring platforms.

</details>


### [80] [Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion](https://arxiv.org/abs/2508.12484)
*Shubhi Agarwal,Amulya Kumar Mahto*

Main category: cs.CV

TL;DR: 该研究提出了一种结合CNN-Transformer混合架构和卷积Kolmogorov-Arnold网络(CKAN)的皮肤癌分类方法，通过局部空间特征提取、全局依赖建模和非线性特征融合，在多个数据集上取得了优异的分类性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌分类是医学图像分析中的关键任务，需要精确区分恶性和非恶性病变以实现早期诊断和治疗。传统方法在特征表示和模型泛化能力方面存在局限，需要开发更强大的混合架构来同时捕捉空间和上下文特征。

Method: 采用顺序和并行混合CNN-Transformer模型，集成卷积Kolmogorov-Arnold网络(CKAN)。CNN提取局部空间特征，Transformer建模全局依赖关系，CKAN通过可学习激活函数实现非线性特征融合。结合迁移学习和广泛的数据增强技术。

Result: 在多个基准数据集上表现出色：HAM10000数据集达到92.81%准确率和92.47% F1分数；PAD-UFES数据集达到97.83%准确率和97.83% F1分数；BCN20000数据集达到91.17%准确率和91.79% F1分数，证明了模型的有效性和泛化能力。

Conclusion: 混合CNN-Transformer架构能有效捕捉空间和上下文特征，CKAN的集成通过可学习激活函数增强了特征融合能力。该研究强调了特征表示和模型设计在推进稳健准确的医学图像分类中的重要性。

Abstract: Skin cancer classification is a crucial task in medical image analysis, where
precise differentiation between malignant and non-malignant lesions is
essential for early diagnosis and treatment. In this study, we explore
Sequential and Parallel Hybrid CNN-Transformer models with Convolutional
Kolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and
extensive data augmentation, where CNNs extract local spatial features,
Transformers model global dependencies, and CKAN facilitates nonlinear feature
fusion for improved representation learning. To assess generalization, we
evaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and
PAD-UFES) under varying data distributions and class imbalances. Experimental
results demonstrate that hybrid CNN-Transformer architectures effectively
capture both spatial and contextual features, leading to improved
classification performance. Additionally, the integration of CKAN enhances
feature fusion through learnable activation functions, yielding more
discriminative representations. Our proposed approach achieves competitive
performance in skin cancer classification, demonstrating 92.81% accuracy and
92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on
the PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000
dataset highlighting the effectiveness and generalizability of our model across
diverse datasets. This study highlights the significance of feature
representation and model design in advancing robust and accurate medical image
classification.

</details>


### [81] [Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients](https://arxiv.org/abs/2508.12506)
*E. Ulises Moya-Sánchez,Abraham Sánchez-Perez,Raúl Nanclares Da Veiga,Alejandro Zarate-Macías,Edgar Villareal,Alejandro Sánchez-Montes,Edtna Jauregui-Ulloa,Héctor Moreno,Ulises Cortés*

Main category: cs.CV

TL;DR: RAIS-DR是一个负责任的人工智能系统，用于糖尿病视网膜病变筛查，在准确性和公平性方面显著优于FDA批准的EyeArt系统。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是工作年龄人群视力丧失的主要原因，早期检测可降低95%的视力丧失风险。但由于视网膜专家短缺和检查时机困难，检测面临挑战。AI模型虽然提供解决方案，但数据质量差和偏见问题阻碍了临床采用。

Method: 开发了RAIS-DR系统，在整个AI生命周期中融入伦理原则。系统整合了高效的卷积模型进行预处理、质量评估和三个专门的DR分类模型。

Result: 在1,046名患者的本地数据集上评估，RAIS-DR相比EyeArt系统F1分数提高5-12%，准确率提高6-19%，特异性提高10-20%。公平性指标显示在不同人口统计亚组中表现公平。

Conclusion: RAIS-DR是一个强大且符合伦理的DR筛查解决方案，具有减少医疗保健差距的潜力，代码和权重已开源。

Abstract: Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age
individuals. Early detection of DR can reduce the risk of vision loss by up to
95%, but a shortage of retinologists and challenges in timely examination
complicate detection. Artificial Intelligence (AI) models using retinal fundus
photographs (RFPs) offer a promising solution. However, adoption in clinical
settings is hindered by low-quality data and biases that may lead AI systems to
learn unintended features. To address these challenges, we developed RAIS-DR, a
Responsible AI System for DR screening that incorporates ethical principles
across the AI lifecycle. RAIS-DR integrates efficient convolutional models for
preprocessing, quality assessment, and three specialized DR classification
models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local
dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated
significant improvements, with F1 scores increasing by 5-12%, accuracy by
6-19%, and specificity by 10-20%. Additionally, fairness metrics such as
Disparate Impact and Equal Opportunity Difference indicated equitable
performance across demographic subgroups, underscoring RAIS-DR's potential to
reduce healthcare disparities. These results highlight RAIS-DR as a robust and
ethically aligned solution for DR screening in clinical settings. The code,
weights of RAIS-DR are available at
https://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with
RAIL.

</details>


### [82] [LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models](https://arxiv.org/abs/2508.12512)
*Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.CV

TL;DR: LangVision-LoRA-NAS是一个将神经架构搜索(NAS)与LoRA相结合的新框架，用于优化视觉语言模型的变秩适应，在多个数据集上显著提升性能并降低微调成本。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA方法使用固定秩进行微调，可能限制了在不同任务中的灵活性和效率，需要一种能够动态搜索最优秩配置的方法。

Method: 提出LangVision-LoRA-NAS框架，通过神经架构搜索动态寻找针对特定多模态任务的最优LoRA秩配置，平衡性能和计算效率。

Result: 在LLaMA-3.2-11B模型上的广泛实验表明，该方法显著提升了模型性能，同时降低了微调成本。

Conclusion: 该框架为视觉语言模型的变秩适应提供了一种有效的解决方案，在保持高性能的同时提高了计算效率。

Abstract: Vision Language Models (VLMs) integrate visual and text modalities to enable
multimodal understanding and generation. These models typically combine a
Vision Transformer (ViT) as an image encoder and a Large Language Model (LLM)
for text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning
method to adapt pre-trained models to new tasks by introducing low-rank updates
to their weights. While LoRA has emerged as a powerful technique for
fine-tuning large models by introducing low-rank updates, current
implementations assume a fixed rank, potentially limiting flexibility and
efficiency across diverse tasks. This paper introduces
\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural
Architecture Search (NAS) with LoRA to optimize VLMs for variable-rank
adaptation. Our approach leverages NAS to dynamically search for the optimal
LoRA rank configuration tailored to specific multimodal tasks, balancing
performance and computational efficiency. Through extensive experiments using
the LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates
notable improvement in model performance while reducing fine-tuning costs. Our
Base and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be
found
\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\textcolor{blue}{here}}
and the code for LangVision-LoRA-NAS can be found
\href{https://github.com/krishnateja95/LangVision-NAS}{\textcolor{blue}{here}}.

</details>


### [83] [An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers](https://arxiv.org/abs/2508.12520)
*Felipe Carlos dos Santos,Eric Aislan Antonelo,Gustavo Claudio Karl Couto*

Main category: cs.CV

TL;DR: 通过交叉视图变换器将摄像头图像映射到鸟视图中的路面、车道标记咄规划轨迹三个通道，在未见城市中展现出良好的演化性能


<details>
  <summary>Details</summary>
Motivation: 鸟视图映射为自动驾驶提供结构化的顶视抽象，本研究旨在探索如何通过交叉视图变换器学习将摄像头图像映射到准确的BEV地图

Method: 使用现实之湿演器生成城市驾驶数据，采用交叉视图变换器(CVT)进行映射学习，比较了不同摄像头布局咄两种损失函数（focal损失和L1损失）

Result: 在仅使用一个城市训练数据的情况下，采用L1损失的四摄像头CVT模型在新城市中表现最为稳健，展现出良好的演化性能

Conclusion: 交叉视图变换器在将摄像头输入映射到合理准确的鸟视图地图方面具有很大潜力，为自动驾驶感知系统提供了有效的解决方案

Abstract: Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is
crucial for autonomous-driving perception. In this work, we employ Cross-View
Transformers (CVT) for learning to map camera images to three BEV's channels -
road, lane markings, and planned trajectory - using a realistic simulator for
urban driving. Our study examines generalization to unseen towns, the effect of
different camera layouts, and two loss formulations (focal and L1). Using
training data from only a town, a four-camera CVT trained with the L1 loss
delivers the most robust test performance, evaluated in a new town. Overall,
our results underscore CVT's promise for mapping camera inputs to reasonably
accurate BEV maps.

</details>


### [84] [MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training](https://arxiv.org/abs/2508.12522)
*Muhammad Osama Zeeshan,Natacha Gillet,Alessandro Lameiras Koerich,Marco Pedersoli,Francois Bremond,Eric Granger*

Main category: cs.CV

TL;DR: MuSACo是一种基于协同训练的多模态个性化表情识别方法，通过选择相关源主体并利用多模态互补信息进行主体特异性适应，在BioVid和StressID数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MSDA方法往往忽略多模态信息或将源域混合为单一域，限制了主体多样性且未能明确捕获主体特异性特征，需要一种能够有效利用多模态信息并保持主体特异性的方法。

Method: 基于协同训练的多模态主体特异性选择和适应方法，选择与目标相关的源主体，使用主导模态生成伪标签进行类感知学习，结合类无关损失从低置信度目标样本中学习，对齐各模态源特征并仅组合置信目标特征。

Result: 在BioVid和StressID两个具有挑战性的多模态表情识别数据集上，MuSACo能够超越UDA（混合）和最先进的MSDA方法。

Conclusion: MuSACo通过有效利用多模态信息和保持主体特异性，在个性化表情识别任务中表现出色，特别适用于数字健康中的情感计算应用，如患者特异性压力和疼痛评估。

Abstract: Personalized expression recognition (ER) involves adapting a machine learning
model to subject-specific data for improved recognition of expressions with
considerable interpersonal variability. Subject-specific ER can benefit
significantly from multi-source domain adaptation (MSDA) methods, where each
domain corresponds to a specific subject, to improve model accuracy and
robustness. Despite promising results, state-of-the-art MSDA approaches often
overlook multimodal information or blend sources into a single domain, limiting
subject diversity and failing to explicitly capture unique subject-specific
characteristics. To address these limitations, we introduce MuSACo, a
multi-modal subject-specific selection and adaptation method for ER based on
co-training. It leverages complementary information across multiple modalities
and multiple source domains for subject-specific adaptation. This makes MuSACo
particularly relevant for affective computing applications in digital health,
such as patient-specific assessment for stress or pain, where subject-level
nuances are crucial. MuSACo selects source subjects relevant to the target and
generates pseudo-labels using the dominant modality for class-aware learning,
in conjunction with a class-agnostic loss to learn from less confident target
samples. Finally, source features from each modality are aligned, while only
confident target features are combined. Our experimental results on challenging
multimodal ER datasets: BioVid and StressID, show that MuSACo can outperform
UDA (blending) and state-of-the-art MSDA methods.

</details>


### [85] [REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language](https://arxiv.org/abs/2508.12543)
*Ipsita Praharaj,Yukta Butala,Yash Butala*

Main category: cs.CV

TL;DR: REVEAL框架利用大型视觉语言模型，通过提示驱动的视觉推理任务来检测图像伪造，提供整体场景评估和区域异常检测两种方法，在多个领域数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展使得视觉伪造检测和解释变得更加困难，现有方法在跨领域泛化方面存在挑战，需要既能检测伪造又能提供推理和定位的鲁棒框架。

Method: 提出REVEAL框架，利用大型视觉语言模型的语义对齐能力，采用两种方法：(1)整体场景级评估，基于图像的物理、语义、透视和真实性；(2)区域异常检测，将图像分割成多个区域进行分析。

Result: 在多个领域数据集（Photoshop、DeepFake和AIGC编辑）上进行实验，与竞争基线相比，视觉语言模型表现出色，并分析了它们提供的推理能力。

Conclusion: REVEAL框架通过提示驱动的视觉推理方法，有效解决了图像伪造检测的跨领域泛化问题，为伪造检测提供了可靠的推理和定位能力。

Abstract: The rapid advancement of generative models has intensified the challenge of
detecting and interpreting visual forgeries, necessitating robust frameworks
for image forgery detection while providing reasoning as well as localization.
While existing works approach this problem using supervised training for
specific manipulation or anomaly detection in the embedding space,
generalization across domains remains a challenge. We frame this problem of
forgery detection as a prompt-driven visual reasoning task, leveraging the
semantic alignment capabilities of large vision-language models. We propose a
framework, `REVEAL` (Reasoning and Evaluation of Visual Evidence through
Aligned Language), that incorporates generalized guidelines. We propose two
tangential approaches - (1) Holistic Scene-level Evaluation that relies on the
physics, semantics, perspective, and realism of the image as a whole and (2)
Region-wise anomaly detection that splits the image into multiple regions and
analyzes each of them. We conduct experiments over datasets from different
domains (Photoshop, DeepFake and AIGC editing). We compare the Vision Language
Models against competitive baselines and analyze the reasoning provided by
them.

</details>


### [86] [Structure-preserving Feature Alignment for Old Photo Colorization](https://arxiv.org/abs/2508.12570)
*Yingxue Pang,Xin Jin,Jun Fu,Zhibo Chen*

Main category: cs.CV

TL;DR: 一种仅需两张图片训练的新题旧照着色算法SFAC，通过特征对齐和结构保持机制解决领域差异问题


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在旧照着色任务上遇到挑战，包括缺乏真实标签和领域差异问题

Method: 设计SFAC算法，通过特征分布对齐损失确保语义相关对象有相似颜色，使用感知约束和冻结-更新金字塔机制保持结构

Result: 实验结果显示该方法在旧照着色任务上具有效果，通过定性和定量指标确认

Conclusion: SFAC算法能够有效解决旧照着色中的领域差异问题，仅需两张图片训练即可实现良好的颜色转移效果

Abstract: Deep learning techniques have made significant advancements in
reference-based colorization by training on large-scale datasets. However,
directly applying these methods to the task of colorizing old photos is
challenging due to the lack of ground truth and the notorious domain gap
between natural gray images and old photos. To address this issue, we propose a
novel CNN-based algorithm called SFAC, i.e., Structure-preserving Feature
Alignment Colorizer. SFAC is trained on only two images for old photo
colorization, eliminating the reliance on big data and allowing direct
processing of the old photo itself to overcome the domain gap problem. Our
primary objective is to establish semantic correspondence between the two
images, ensuring that semantically related objects have similar colors. We
achieve this through a feature distribution alignment loss that remains robust
to different metric choices. However, utilizing robust semantic correspondence
to transfer color from the reference to the old photo can result in inevitable
structure distortions. To mitigate this, we introduce a structure-preserving
mechanism that incorporates a perceptual constraint at the feature level and a
frozen-updated pyramid at the pixel level. Extensive experiments demonstrate
the effectiveness of our method for old photo colorization, as confirmed by
qualitative and quantitative metrics.

</details>


### [87] [Foundation Model for Skeleton-Based Human Action Understanding](https://arxiv.org/abs/2508.12586)
*Hongsong Wang,Wanjiang Weng,Junbo Wang,Fang Zhao,Guo-Sen Xie,Xin Geng,Liang Wang*

Main category: cs.CV

TL;DR: 提出了USDRL框架，这是一个基于骨架的动作理解基础模型，通过Transformer编码器、多粒度特征解相关和多视角一致性训练，在25个基准测试中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作理解方法缺乏可扩展性和泛化能力，没有能够适应广泛动作理解任务的基础模型

Method: USDRL框架包含：1）Transformer密集时空编码器（DSTE）学习时空特征；2）多粒度特征解相关（MG-FD）减少维度冗余；3）多视角一致性训练（MPCT）进行自监督学习

Result: 在9个骨架动作理解任务的25个基准测试中显著超越当前最先进方法

Conclusion: 该工作拓宽了骨架动作理解的研究范围，鼓励更多关注密集预测任务，为骨架基础模型发展提供了新方向

Abstract: Human action understanding serves as a foundational pillar in the field of
intelligent motion perception. Skeletons serve as a modality- and
device-agnostic representation for human modeling, and skeleton-based action
understanding has potential applications in humanoid robot control and
interaction. \RED{However, existing works often lack the scalability and
generalization required to handle diverse action understanding tasks. There is
no skeleton foundation model that can be adapted to a wide range of action
understanding tasks}. This paper presents a Unified Skeleton-based Dense
Representation Learning (USDRL) framework, which serves as a foundational model
for skeleton-based human action understanding. USDRL consists of a
Transformer-based Dense Spatio-Temporal Encoder (DSTE), Multi-Grained Feature
Decorrelation (MG-FD), and Multi-Perspective Consistency Training (MPCT). The
DSTE module adopts two parallel streams to learn temporal dynamic and spatial
structure features. The MG-FD module collaboratively performs feature
decorrelation across temporal, spatial, and instance domains to reduce
dimensional redundancy and enhance information extraction. The MPCT module
employs both multi-view and multi-modal self-supervised consistency training.
The former enhances the learning of high-level semantics and mitigates the
impact of low-level discrepancies, while the latter effectively facilitates the
learning of informative multimodal features. We perform extensive experiments
on 25 benchmarks across across 9 skeleton-based action understanding tasks,
covering coarse prediction, dense prediction, and transferred prediction. Our
approach significantly outperforms the current state-of-the-art methods. We
hope that this work would broaden the scope of research in skeleton-based
action understanding and encourage more attention to dense prediction tasks.

</details>


### [88] [Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models](https://arxiv.org/abs/2508.12587)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: 多模态连续思绪链(MCOUT)在聚合潜在空间中进行推理，而非使用自然语言，在多模态理解任务上显著提升了性能


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型推理方法(如思绪链提示)在多模态环境中效果有限，难以动态对齐音频、视觉和文本信息

Method: 提出MCOUT方法，以连续隐藏向量表示推理状态，迭代精炼并与多模态嵌入对齐：MCOUT-Base重用语言模型隐藏状态，MCOUT-Multi集成多模态注意力机制

Result: 在MMMU、ScienceQA、MMStar等测试集上显著提升性能，准确率最高提升8.23%，BLEU指标提升8.27%

Conclusion: 潜在连续推理是提升大型多模态模型的有前景方向，提供了类人类反思式多模态推理的可扩展框架

Abstract: Many reasoning techniques for large multimodal models adapt language model
approaches, such as Chain-of-Thought (CoT) prompting, which express reasoning
as word sequences. While effective for text, these methods are suboptimal for
multimodal contexts, struggling to align audio, visual, and textual information
dynamically. To explore an alternative paradigm, we propose the Multimodal
Chain of Continuous Thought (MCOUT), which enables reasoning directly in a
joint latent space rather than in natural language. In MCOUT, the reasoning
state is represented as a continuous hidden vector, iteratively refined and
aligned with visual and textual embeddings, inspired by human reflective
cognition. We develop two variants: MCOUT-Base, which reuses the language
model`s last hidden state as the continuous thought for iterative reasoning,
and MCOUT-Multi, which integrates multimodal latent attention to strengthen
cross-modal alignment between visual and textual features. Experiments on
benchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently
improves multimodal reasoning, yielding up to 8.23% accuracy gains over strong
baselines and improving BLEU scores up to 8.27% across multiple-choice and
open-ended tasks. These findings highlight latent continuous reasoning as a
promising direction for advancing LMMs beyond language-bound CoT, offering a
scalable framework for human-like reflective multimodal inference. Code is
available at https://github.com/Hanhpt23/OmniMod.

</details>


### [89] [ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.12603)
*Can Cui,Yupeng Zhou,Juntong Peng,Sung-Yeon Park,Zichong Yang,Prashanth Sankaranarayanan,Jiaru Zhang,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: ViLaD是一个基于扩散模型的新型端到端自动驾驶框架，通过并行生成驾驶决策序列显著降低延迟，支持双向推理和渐进式生成，在nuScenes数据集上超越现有自回归VLM方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型的自动驾驶系统采用自回归架构，存在推理延迟高、无法进行双向推理的问题，不适合动态安全关键环境。

Method: 提出ViLaD框架，利用掩码扩散模型并行生成完整的驾驶决策序列，支持双向推理和渐进式易先生成策略。

Result: 在nuScenes数据集上，ViLaD在规划准确性和推理速度方面均优于最先进的自回归VLM基线，实现接近零的故障率，并在真实自动驾驶车辆上验证了实用性。

Conclusion: ViLaD代表了自动驾驶领域的范式转变，通过扩散模型架构解决了自回归方法的局限性，为实际应用提供了高效可靠的解决方案。

Abstract: End-to-end autonomous driving systems built on Vision Language Models (VLMs)
have shown significant promise, yet their reliance on autoregressive
architectures introduces some limitations for real-world applications. The
sequential, token-by-token generation process of these models results in high
inference latency and cannot perform bidirectional reasoning, making them
unsuitable for dynamic, safety-critical environments. To overcome these
challenges, we introduce ViLaD, a novel Large Vision Language Diffusion (LVLD)
framework for end-to-end autonomous driving that represents a paradigm shift.
ViLaD leverages a masked diffusion model that enables parallel generation of
entire driving decision sequences, significantly reducing computational
latency. Moreover, its architecture supports bidirectional reasoning, allowing
the model to consider both past and future simultaneously, and supports
progressive easy-first generation to iteratively improve decision quality. We
conduct comprehensive experiments on the nuScenes dataset, where ViLaD
outperforms state-of-the-art autoregressive VLM baselines in both planning
accuracy and inference speed, while achieving a near-zero failure rate.
Furthermore, we demonstrate the framework's practical viability through a
real-world deployment on an autonomous vehicle for an interactive parking task,
confirming its effectiveness and soundness for practical applications.

</details>


### [90] [ViDA-UGC: Detailed Image Quality Analysis via Visual Distortion Assessment for UGC Images](https://arxiv.org/abs/2508.12605)
*Wenjie Liao,Jieyu Yuan,Yifang Xu,Chunle Guo,Zilong Zhang,Jihong Li,Jiachen Fu,Haotian Fan,Tao Li,Junhui Cui,Chongyi Li*

Main category: cs.CV

TL;DR: 该研究创建了首个大规模用户生成内容(UGC)图像视觉失真评估指令调优数据集ViDA-UGC，包含11K图像和细粒度质量标注，通过CoT框架指导GPT-4o生成质量描述，并建立了首个UGC失真评估基准ViDA-UGC-Bench。


<details>
  <summary>Details</summary>
Motivation: 当前可解释图像质量评估方法存在两个问题：1) 对UGC和AIGC图像使用相同的失真评估标准不恰当；2) 缺乏详细的图像质量分析和修复指导能力。

Method: 通过失真导向的流程构建ViDA-UGC数据集，包含人工标注和Chain-of-Thought评估框架，指导GPT-4o识别分析UGC失真并生成质量描述。从数据集中精选476张图像和6149个问答对建立ViDA-UGC-Bench基准。

Result: 实验结果表明ViDA-UGC数据集和CoT框架能有效提升多种基础MLLM在图像质量分析方面的能力，在ViDA-UGC-Bench和Q-Bench基准上甚至超越了GPT-4o的表现。

Conclusion: 该研究成功建立了首个专门针对UGC图像的大规模视觉失真评估数据集和基准，通过CoT框架显著提升了MLLM的图像质量分析能力，为图像质量监控和修复指导提供了有效工具。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have introduced a
paradigm shift for Image Quality Assessment (IQA) from unexplainable image
quality scoring to explainable IQA, demonstrating practical applications like
quality control and optimization guidance. However, current explainable IQA
methods not only inadequately use the same distortion criteria to evaluate both
User-Generated Content (UGC) and AI-Generated Content (AIGC) images, but also
lack detailed quality analysis for monitoring image quality and guiding image
restoration. In this study, we establish the first large-scale Visual
Distortion Assessment Instruction Tuning Dataset for UGC images, termed
ViDA-UGC, which comprises 11K images with fine-grained quality grounding,
detailed quality perception, and reasoning quality description data. This
dataset is constructed through a distortion-oriented pipeline, which involves
human subject annotation and a Chain-of-Thought (CoT) assessment framework.
This framework guides GPT-4o to generate quality descriptions by identifying
and analyzing UGC distortions, which helps capturing rich low-level visual
features that inherently correlate with distortion patterns. Moreover, we
carefully select 476 images with corresponding 6,149 question answer pairs from
ViDA-UGC and invite a professional team to ensure the accuracy and quality of
GPT-generated information. The selected and revised data further contribute to
the first UGC distortion assessment benchmark, termed ViDA-UGC-Bench.
Experimental results demonstrate the effectiveness of the ViDA-UGC and CoT
framework for consistently enhancing various image quality analysis abilities
across multiple base MLLMs on ViDA-UGC-Bench and Q-Bench, even surpassing
GPT-4o.

</details>


### [91] [OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion](https://arxiv.org/abs/2508.12610)
*Chen Qian,Danyang Li,Xinran Yu,Zheng Yang,Qiang Ma*

Main category: cs.CV

TL;DR: 这篇论文提出了OpenMoCap模型和CMU-Occlu数据集，专门解决光学动作捕捉中大规模标记点遮挡问题，在各种场景下都显著超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有光学动作捕捉系统在真实应用中遇到大规模标记点遮挡时性能会严重下降，主要问题在于缺乏真实遮挡模式的训练数据集和无法捕捉标记点间长程依赖关系。

Method: 首先创建了CMU-Occlu数据集，利用光线追踪技术模拟真实的标记点遮挡模式。然后提出OpenMoCap模型，采用标记点-关节链推理机制，能够同时优化并构建标记点与关节之间的深度约束关系。

Result: 经过广泛的对比实验，OpenMoCap在多种不同场景下都一致地显示出更优的性能，显著超过了现有的竞争方法。CMU-Occlu数据集为未来的稳健动作解决研究打开了新的可能性。

Conclusion: 该研究成功地解决了光学动作捕捉中的遮挡问题，OpenMoCap模型已集成到MoSen动作捕捉系统中实际部署，代码已开源发布。

Abstract: Optical motion capture is a foundational technology driving advancements in
cutting-edge fields such as virtual reality and film production. However,
system performance suffers severely under large-scale marker occlusions common
in real-world applications. An in-depth analysis identifies two primary
limitations of current models: (i) the lack of training datasets accurately
reflecting realistic marker occlusion patterns, and (ii) the absence of
training strategies designed to capture long-range dependencies among markers.
To tackle these challenges, we introduce the CMU-Occlu dataset, which
incorporates ray tracing techniques to realistically simulate practical marker
occlusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving
model designed specifically for robust motion capture in environments with
significant occlusions. Leveraging a marker-joint chain inference mechanism,
OpenMoCap enables simultaneous optimization and construction of deep
constraints between markers and joints. Extensive comparative experiments
demonstrate that OpenMoCap consistently outperforms competing methods across
diverse scenarios, while the CMU-Occlu dataset opens the door for future
studies in robust motion solving. The proposed OpenMoCap is integrated into the
MoSen MoCap system for practical deployment. The code is released at:
https://github.com/qianchen214/OpenMoCap.

</details>


### [92] [WIPES: Wavelet-based Visual Primitives](https://arxiv.org/abs/2508.12615)
*Wenhao Zhang,Hao Zhu,Delong Wu,Di Kang,Linchao Bao,Zhan Ma,Xun Cao*

Main category: cs.CV

TL;DR: WIPES是一种基于小波的通用视觉基元表示方法，通过小波的空间-频率定位优势有效捕捉高低频信息，并提供快速渲染


<details>
  <summary>Details</summary>
Motivation: 现有视觉表示方法依赖频率指导或复杂神经网络解码，导致频谱损失或渲染速度慢，需要一种能同时保证高质量和快速渲染的通用表示方法

Method: 基于小波的空间-频率定位优势构建视觉基元，开发小波基可微分光栅化器实现快速视觉渲染

Result: 在2D图像表示、5D静态和6D动态新视角合成等任务中，WIPES相比基于INR的方法具有更高渲染质量和更快推理速度，在渲染质量上优于基于高斯的方法

Conclusion: WIPES作为一种视觉基元表示，能够有效平衡渲染质量和速度，为多维度视觉信号表示提供了新的解决方案

Abstract: Pursuing a continuous visual representation that offers flexible frequency
modulation and fast rendering speed has recently garnered increasing attention
in the fields of 3D vision and graphics. However, existing representations
often rely on frequency guidance or complex neural network decoding, leading to
spectrum loss or slow rendering. To address these limitations, we propose
WIPES, a universal Wavelet-based vIsual PrimitivES for representing
multi-dimensional visual signals. Building on the spatial-frequency
localization advantages of wavelets, WIPES effectively captures both the
low-frequency "forest" and the high-frequency "trees." Additionally, we develop
a wavelet-based differentiable rasterizer to achieve fast visual rendering.
Experimental results on various visual tasks, including 2D image
representation, 5D static and 6D dynamic novel view synthesis, demonstrate that
WIPES, as a visual primitive, offers higher rendering quality and faster
inference than INR-based methods, and outperforms Gaussian-based
representations in rendering quality.

</details>


### [93] [Creative4U: MLLMs-based Advertising Creative Image Selector with Comparative Reasoning](https://arxiv.org/abs/2508.12628)
*Yukang Lin,Xiang Zhang,Shichang Jia,Bowen Wan,Chenghan Fu,Xudong Ren,Yueran Liu,Wanxian Guan,Pengji Wang,Jian Xu,Bo Zheng,Baolin Liu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于多模态大语言模型的可解释性创意图片评估和选择方法Creative4U，通过构建CreativePair数据集和Reason-to-Select RFT训练方法，能够准确选择更优质的创意图片。


<details>
  <summary>Details</summary>
Motivation: 当前创意图片选择方法主要集中在排名而非可解释性选择，无法满足广告主对可解释性创意评估的需求。AIGC技术能大量生产创意图片，但缺乏有效的质量评估方法。

Method: 通过多模态大语言模型，将创意图片评估和选择转换为自然语言生成任务。构建CreativePair数据集（8k带注释的图片对），开发Creative4U系统，采用Reason-to-Select RFT训练方法（包括CoT-SFT和GRPO强化学习）。

Result: 离线和在线实验都证明了该方法的有效性，能够准确评估和选择创意图片。

Conclusion: 该研究提供了首个可解释性创意评估和选择范式，通过MLLMs技术实现了更加准确和可解释的创意选择，对互联网广告行业具有重要意义。

Abstract: Creative image in advertising is the heart and soul of e-commerce platform.
An eye-catching creative image can enhance the shopping experience for users,
boosting income for advertisers and advertising revenue for platforms. With the
advent of AIGC technology, advertisers can produce large quantities of creative
images at minimal cost. However, they struggle to assess the creative quality
to select. Existing methods primarily focus on creative ranking, which fails to
address the need for explainable creative selection.
  In this work, we propose the first paradigm for explainable creative
assessment and selection. Powered by multimodal large language models (MLLMs),
our approach integrates the assessment and selection of creative images into a
natural language generation task. To facilitate this research, we construct
CreativePair, the first comparative reasoning-induced creative dataset
featuring 8k annotated image pairs, with each sample including a label
indicating which image is superior. Additionally, we introduce Creative4U
(pronounced Creative for You), a MLLMs-based creative selector that takes into
account users' interests. Through Reason-to-Select RFT, which includes
supervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative
Policy Optimization (GRPO) based reinforcement learning, Creative4U is able to
evaluate and select creative images accurately. Both offline and online
experiments demonstrate the effectiveness of our approach. Our code and dataset
will be made public to advance research and industrial applications.

</details>


### [94] [SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer](https://arxiv.org/abs/2508.12638)
*Chen Qian,Xinran Yu,Zewen Huang,Danyang Li,Qiang Ma,Fan Dang,Xuan Ding,Guangyong Shang,Zheng Yang*

Main category: cs.CV

TL;DR: 通过将大型视觉-语言模型的延迟输出作为历史上下文，为小型模型提供实时指导，解决云端协同中的延迟问题


<details>
  <summary>Details</summary>
Motivation: 现有的云边协同方案无法处理云端延迟波动，且没有充分利用大型模型延迟但准确的响应

Method: 提出Context Transfer框架，设计SpotVLM系统，包含上下文替换和视觉聚焦模块，优化历史文本输入和提升视觉基准一致性

Result: 在四个数据集的三个实时视觉任务中经过大量实验验证了框架的有效性

Conclusion: 该新框架为未来VLM系统的更有效和延迟感知协同策略奠定了基础

Abstract: Vision-Language Models (VLMs) are increasingly deployed in real-time
applications such as autonomous driving and human-computer interaction, which
demand fast and reliable responses based on accurate perception. To meet these
requirements, existing systems commonly employ cloud-edge collaborative
architectures, such as partitioned Large Vision-Language Models (LVLMs) or task
offloading strategies between Large and Small Vision-Language Models (SVLMs).
However, these methods fail to accommodate cloud latency fluctuations and
overlook the full potential of delayed but accurate LVLM responses. In this
work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed
Context Transfer, which treats the delayed outputs of LVLMs as historical
context to provide real-time guidance for SVLMs inference. Based on this
paradigm, we design SpotVLM, which incorporates both context replacement and
visual focus modules to refine historical textual input and enhance visual
grounding consistency. Extensive experiments on three real-time vision tasks
across four datasets demonstrate the effectiveness of the proposed framework.
The new paradigm lays the groundwork for more effective and latency-aware
collaboration strategies in future VLM systems.

</details>


### [95] [Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow](https://arxiv.org/abs/2508.12640)
*Bastian Brandstötter,Erich Kobler*

Main category: cs.CV

TL;DR: 使用两阶段后验均值正流模型(PMRF)从非对比增强T1 MRI生成对比增强脑部MRI，避免锭洞对比剂的使用


<details>
  <summary>Details</summary>
Motivation: 对比增强T1 MRI在神经脱流诊断中关键，但需要锭洞对比剂，这会增加成本、扩大扫描时间、带来环境问题和潜在病人风险

Method: 两阶段流水线：首先用片基3D U-Net预测像素后验均值(最小化MSE)，然后用时间条件化3D正流模型精炼，以结合现实纹理和结构保真

Result: 在360个测试集上，最佳精炼输出达到轴位FID 12.46和KID 0.007(FID比后验均值降位68.7%)，保持低体积MSE 0.057(比后验均值高出27%)，质量比较确认能实际恢复病变边缘和血管细节

Conclusion: 该方法有效应对了觉知-形变搁扭交易，为临床部署提供了可行的方案，能够在保持结构准确性的同时生成现实的对比增强图像

Abstract: Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic
diagnosis but requires gadolinium-based agents, which add cost and scan time,
raise environmental concerns, and may pose risks to patients. In this work, we
propose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for
synthesizing volumetric CE brain MRI from non-contrast inputs. First, a
patch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).
Then, this initial estimate is refined by a time-conditioned 3D rectified flow
to incorporate realistic textures without compromising structural fidelity. We
train this model on a multi-institutional collection of paired pre- and
post-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360
diverse volumes, our best refined outputs achieve an axial FID of $12.46$ and
KID of $0.007$ ($\sim 68.7\%$ lower FID than the posterior mean) while
maintaining low volumetric MSE of $0.057$ ($\sim 27\%$ higher than the
posterior mean). Qualitative comparisons confirm that our method restores
lesion margins and vascular details realistically, effectively navigating the
perception-distortion trade-off for clinical deployment.

</details>


### [96] [Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation](https://arxiv.org/abs/2508.12643)
*Pinci Yang,Peisong Wen,Ke Ma,Qianqian Xu*

Main category: cs.CV

TL;DR: 本文提出BEE框架，通过多级一致性正则化和互补锚点重放机制，解决持续测试时自适应中探索与利用的平衡问题，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 持续测试时自适应(CTTA)需要在推理过程中快速适应新域(探索)同时保留历史域知识(利用)。现有方法存在两个挑战：1)域偏移主要影响浅层特征，但现有方法基于深层输出调整预测，导致探索缓慢；2)单一模型在探索过程中会遗忘历史知识，无法利用相似域的处理经验。

Method: 提出基于mean teacher的BEE框架：1)多级一致性正则化(MCR)损失对齐师生模型的中间特征，加速当前域适应；2)互补锚点重放(CAR)机制重用历史检查点(锚点)，恢复不同域的互补知识。

Result: 在多个基准测试中显著优于最先进方法，证明了该方法在CTTA任务中的有效性。

Conclusion: BEE框架通过MCR和CAR机制有效平衡了CTTA中的探索与利用，解决了浅层特征调整缓慢和历史知识遗忘的问题，为持续测试时自适应提供了有效解决方案。

Abstract: Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained
model to continually changing target domains during inference. As a fundamental
principle, an ideal CTTA method should rapidly adapt to new domains
(exploration) while retaining and exploiting knowledge from previously
encountered domains to handle similar domains in the future. Despite
significant advances, balancing exploration and exploitation in CTTA is still
challenging: 1) Existing methods focus on adjusting predictions based on
deep-layer outputs of neural networks. However, domain shifts typically affect
shallow features, which are inefficient to be adjusted from deep predictions,
leading to dilatory exploration; 2) A single model inevitably forgets knowledge
of previous domains during the exploration, making it incapable of exploiting
historical knowledge to handle similar future domains. To address these
challenges, this paper proposes a mean teacher framework that strikes an
appropriate Balance between Exploration and Exploitation (BEE) during the CTTA
process. For the former challenge, we introduce a Multi-level Consistency
Regularization (MCR) loss that aligns the intermediate features of the student
and teacher models, accelerating adaptation to the current domain. For the
latter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to
reuse historical checkpoints (anchors), recovering complementary knowledge for
diverse domains. Experiments show that our method significantly outperforms
state-of-the-art methods on several benchmarks, demonstrating its effectiveness
for CTTA tasks.

</details>


### [97] [DyCrowd: Towards Dynamic Crowd Reconstruction from a Large-scene Video](https://arxiv.org/abs/2508.12644)
*Hao Wen,Hongbo Kang,Jian Ma,Jing Huang,Yuanwang Yang,Haozhe Lin,Yu-Kun Lai,Kun Li*

Main category: cs.CV

TL;DR: DyCrowd是首个从大场景视频中进行时空一致3D人群重建的框架，通过群体引导的运动优化策略和VAE运动先验，有效解决遮挡问题，并贡献了VirtualCrowd虚拟数据集。


<details>
  <summary>Details</summary>
Motivation: 当前方法从静态图像重建3D人群缺乏时间一致性，无法有效处理遮挡问题，需要开发能够从视频中重建大规模动态人群的解决方案。

Method: 采用粗到细的群体引导运动优化策略，结合VAE人体运动先验和分段群体引导优化，利用异步运动一致性损失(AMC)让无遮挡运动段指导遮挡段的恢复。

Result: 实验结果表明该方法在大场景动态人群重建任务中达到了最先进的性能。

Conclusion: 提出的DyCrowd框架能够从大场景视频中稳健地重建数百人的姿态、位置和形状，解决了时间不稳定性和严重遮挡问题，为动态人群重建提供了有效解决方案。

Abstract: 3D reconstruction of dynamic crowds in large scenes has become increasingly
important for applications such as city surveillance and crowd analysis.
However, current works attempt to reconstruct 3D crowds from a static image,
causing a lack of temporal consistency and inability to alleviate the typical
impact caused by occlusions. In this paper, we propose DyCrowd, the first
framework for spatio-temporally consistent 3D reconstruction of hundreds of
individuals' poses, positions and shapes from a large-scene video. We design a
coarse-to-fine group-guided motion optimization strategy for occlusion-robust
crowd reconstruction in large scenes. To address temporal instability and
severe occlusions, we further incorporate a VAE (Variational Autoencoder)-based
human motion prior along with a segment-level group-guided optimization. The
core of our strategy leverages collective crowd behavior to address long-term
dynamic occlusions. By jointly optimizing the motion sequences of individuals
with similar motion segments and combining this with the proposed Asynchronous
Motion Consistency (AMC) loss, we enable high-quality unoccluded motion
segments to guide the motion recovery of occluded ones, ensuring robust and
plausible motion recovery even in the presence of temporal desynchronization
and rhythmic inconsistencies. Additionally, in order to fill the gap of no
existing well-annotated large-scene video dataset, we contribute a virtual
benchmark dataset, VirtualCrowd, for evaluating dynamic crowd reconstruction
from large-scene videos. Experimental results demonstrate that the proposed
method achieves state-of-the-art performance in the large-scene dynamic crowd
reconstruction task. The code and dataset will be available for research
purposes.

</details>


### [98] [Stable Diffusion-Based Approach for Human De-Occlusion](https://arxiv.org/abs/2508.12663)
*Seung Young Noh,Ju Yong Chang*

Main category: cs.CV

TL;DR: 一种两阶段演进式人体去遮擾方法，结合扩散模型和人体结构前知，通过掩码完整和RGB完整两个阶段来恢复遮挡人体的外观。


<details>
  <summary>Details</summary>
Motivation: 人类可以利用先验知识和可见线索推断遮挡物体的缺失部分，但让深度学习模型准确预测遮挡区域仍是一项具有挑战性的任务。去遮擾通过重建掩码和RGB外观来解决这个问题。

Method: 方法分为两个阶段：掩码完整和RGB完整。第一阶段利用基于扩散模型的人体前知提供身体结构的全面表示，结合遮挡关节热力图提供缺失区域的显式空间线索。第二阶段使用稳定扩散模型进行RGB生成，并添加了来自视觉问题答案（VQA）模型的人体特定文本特征。

Result: 该方法能够有效地重建体现在严重遮挡下的人体外观，在掩码和RGB完整上都持续超越现有方法。甚至在严重遮挡情况下也能恢复人体外观。

Conclusion: 该研究提出的去遮擾图像可以提高下游人体中心任务的性能，如2D姿势估计和3D人体重建。代码将公开发布。

Abstract: Humans can infer the missing parts of an occluded object by leveraging prior
knowledge and visible cues. However, enabling deep learning models to
accurately predict such occluded regions remains a challenging task.
De-occlusion addresses this problem by reconstructing both the mask and RGB
appearance. In this work, we focus on human de-occlusion, specifically
targeting the recovery of occluded body structures and appearances. Our
approach decomposes the task into two stages: mask completion and RGB
completion. The first stage leverages a diffusion-based human body prior to
provide a comprehensive representation of body structure, combined with
occluded joint heatmaps that offer explicit spatial cues about missing regions.
The reconstructed amodal mask then serves as a conditioning input for the
second stage, guiding the model on which areas require RGB reconstruction. To
further enhance RGB generation, we incorporate human-specific textual features
derived using a visual question answering (VQA) model and encoded via a CLIP
encoder. RGB completion is performed using Stable Diffusion, with decoder
fine-tuning applied to mitigate pixel-level degradation in visible regions -- a
known limitation of prior diffusion-based de-occlusion methods caused by latent
space transformations. Our method effectively reconstructs human appearances
even under severe occlusions and consistently outperforms existing methods in
both mask and RGB completion. Moreover, the de-occluded images generated by our
approach can improve the performance of downstream human-centric tasks, such as
2D pose estimation and 3D human reconstruction. The code will be made publicly
available.

</details>


### [99] [WP-CLIP: Leveraging CLIP to Predict Wölfflin's Principles in Visual Art](https://arxiv.org/abs/2508.12668)
*Abhijay Ghildyal,Li-Yun Wang,Feng Liu*

Main category: cs.CV

TL;DR: 这篇论文研究了如何用CLIP视觉-语言模型预测Wölfflin五大艺术原则，通过精调模型实现了对多样艺术风格的自动化分析。


<details>
  <summary>Details</summary>
Motivation: 现有计量方法无法有效预测Wölfflin的五大艺术原则，而视觉-语言模型在识别抽象图像属性方面显示了潜力，因此需要研究其在艺术分析中的应用。

Method: 首先评估预训练CLIP模型的能力，然后在实际艺术图像注释数据集上进行精调训练，开发了WP-CLIP模型来预测每个艺术原则的分数。

Result: 经过精调的WP-CLIP模型能够在GAN生成的油画和Pandora-18K艺术数据集上进行良好的法划，证明其能够理解和预测多样化的艺术风格。

Conclusion: 视觉-语言模型在自动艺术分析方面具有巨大潜力，通过有目的性的精调训练可以提升对细腻艺术元素的理解能力。

Abstract: W\"olfflin's five principles offer a structured approach to analyzing
stylistic variations for formal analysis. However, no existing metric
effectively predicts all five principles in visual art. Computationally
evaluating the visual aspects of a painting requires a metric that can
interpret key elements such as color, composition, and thematic choices. Recent
advancements in vision-language models (VLMs) have demonstrated their ability
to evaluate abstract image attributes, making them promising candidates for
this task. In this work, we investigate whether CLIP, pre-trained on
large-scale data, can understand and predict W\"olfflin's principles. Our
findings indicate that it does not inherently capture such nuanced stylistic
elements. To address this, we fine-tune CLIP on annotated datasets of real art
images to predict a score for each principle. We evaluate our model, WP-CLIP,
on GAN-generated paintings and the Pandora-18K art dataset, demonstrating its
ability to generalize across diverse artistic styles. Our results highlight the
potential of VLMs for automated art analysis.

</details>


### [100] [Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation](https://arxiv.org/abs/2508.12680)
*Yuheng Zha,Kun Zhou,Yujia Wu,Yushu Wang,Jie Feng,Zhi Xu,Shibo Hao,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

Main category: cs.CV

TL;DR: 通过多域数据集集成和彩集数据选择策略，训练出在多个视觉推理预测试上超越GPT-4o和Gemini-1.5 Flash的视觉语言模型Vision-G1


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的训练通常只涵盖数学和逻辑推理等范围有限的任务，导致模型在更广泛领域的推理能力普遍性不佳，主要因难是多域高质量奖励数据的缺乏和数据集兼容性问题

Method: 从46个数据源中构建涵盖8个维度的完整RL准备视觉推理数据集，采用基于影响函数的数据选择和难度基于过滤策略识别高质量训练样本，通过多轮强化学习和数据课程迭代改进模型能力

Result: Vision-G1模型在各种视觉推理预测试上达到了最先进水平，超过了同规模模型和GPT-4o、Gemini-1.5 Flash等专有模型

Conclusion: 通过多域数据集成和精心设计的数据选择策略，可以有效提升视觉语言模型的普遍推理能力，为广泛领域的视觉推理研究提供了新的解决方案

Abstract: Despite their success, current training pipelines for reasoning VLMs focus on
a limited range of tasks, such as mathematical and logical reasoning. As a
result, these models face difficulties in generalizing their reasoning
capabilities to a wide range of domains, primarily due to the scarcity of
readily available and verifiable reward data beyond these narrowly defined
areas. Moreover, integrating data from multiple domains is challenging, as the
compatibility between domain-specific datasets remains uncertain. To address
these limitations, we build a comprehensive RL-ready visual reasoning dataset
from 46 data sources across 8 dimensions, covering a wide range of tasks such
as infographic, mathematical, spatial, cross-image, graphic user interface,
medical, common sense and general science. We propose an influence function
based data selection and difficulty based filtering strategy to identify
high-quality training samples from this dataset. Subsequently, we train the
VLM, referred to as Vision-G1, using multi-round RL with a data curriculum to
iteratively improve its visual reasoning capabilities. Our model achieves
state-of-the-art performance across various visual reasoning benchmarks,
outperforming similar-sized VLMs and even proprietary models like GPT-4o and
Gemini-1.5 Flash. The model, code and dataset are publicly available at
https://github.com/yuh-zha/Vision-G1.

</details>


### [101] [Refine-and-Contrast: Adaptive Instance-Aware BEV Representations for Multi-UAV Collaborative Object Detection](https://arxiv.org/abs/2508.12684)
*Zhongyao Li,Peirui Cheng,Liangjin Zhao,Chen Chen,Yundu Li,Zhechao Wang,Xue Yang,Xian Sun,Zhirui Wang*

Main category: cs.CV

TL;DR: AdaBEV是一个多无人机协同3D检测框架，通过自适应实例感知的BEV表示学习，在保持低分辨率BEV输入的同时实现优越的精度-计算权衡


<details>
  <summary>Details</summary>
Motivation: 多无人机协同3D检测虽然能通过融合多视角观测提供准确鲁棒的感知，但在资源受限的无人机平台上计算面临挑战，需要解决计算效率问题

Method: 提出refine-and-contrast范式：Box-Guided Refinement Module（BG-RM）仅精炼前景实例相关的BEV网格，使用2D监督和空间细分；Instance-Background Contrastive Learning（IBCL）通过对比学习增强前景和背景特征的可区分性

Result: 在Air-Co-Pred数据集上的实验表明，AdaBEV在不同模型尺度上都实现了优越的精度-计算权衡，在低分辨率下优于其他SOTA方法，接近上限性能且计算开销可忽略

Conclusion: AdaBEV通过自适应实例感知的BEV表示学习，有效解决了多无人机协同3D检测中的计算效率问题，为资源受限平台提供了实用的解决方案

Abstract: Multi-UAV collaborative 3D detection enables accurate and robust perception
by fusing multi-view observations from aerial platforms, offering significant
advantages in coverage and occlusion handling, while posing new challenges for
computation on resource-constrained UAV platforms. In this paper, we present
AdaBEV, a novel framework that learns adaptive instance-aware BEV
representations through a refine-and-contrast paradigm. Unlike existing methods
that treat all BEV grids equally, AdaBEV introduces a Box-Guided Refinement
Module (BG-RM) and an Instance-Background Contrastive Learning (IBCL) to
enhance semantic awareness and feature discriminability. BG-RM refines only BEV
grids associated with foreground instances using 2D supervision and spatial
subdivision, while IBCL promotes stronger separation between foreground and
background features via contrastive learning in BEV space. Extensive
experiments on the Air-Co-Pred dataset demonstrate that AdaBEV achieves
superior accuracy-computation trade-offs across model scales, outperforming
other state-of-the-art methods at low resolutions and approaching upper bound
performance while maintaining low-resolution BEV inputs and negligible
overhead.

</details>


### [102] [TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions](https://arxiv.org/abs/2508.12690)
*Dongjae Jeon,Taeheon Kim,Seongwon Cho,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: TTA-DAME方法通过源域数据增强、域判别器和专门域检测器来处理测试时域适应问题，特别是在驾驶场景中的天气和昼夜变化，通过多检测器集成和NMS提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决测试时适应(TTA)中模型需要动态适应变化目标域的挑战，特别是在真实驾驶场景中频繁发生的天气域变化问题。

Method: 利用源域数据增强到目标域，引入域判别器和专门域检测器来处理剧烈域偏移（如白天到夜间），训练多个检测器并通过非极大值抑制(NMS)整合预测结果。

Result: 在SHIFT基准测试上显示出显著性能提升，证明了方法的有效性。

Conclusion: TTA-DAME方法成功解决了动态域适应问题，特别是在驾驶场景中的域偏移挑战，通过创新的域感知机制和多检测器集成策略实现了优异的性能表现。

Abstract: Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically
adapt and perform optimally on shifting target domains. This task is
particularly emphasized in real-world driving scenes, where weather domain
shifts occur frequently. To address such dynamic changes, our proposed method,
TTA-DAME, leverages source domain data augmentation into target domains.
Additionally, we introduce a domain discriminator and a specialized domain
detector to mitigate drastic domain shifts, especially from daytime to
nighttime conditions. To further improve adaptability, we train multiple
detectors and consolidate their predictions through Non-Maximum Suppression
(NMS). Our empirical validation demonstrates the effectiveness of our method,
showing significant performance enhancements on the SHIFT Benchmark.

</details>


### [103] [Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning](https://arxiv.org/abs/2508.12692)
*Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeong,Jonghyun Choi*

Main category: cs.CV

TL;DR: 这篇论文提出了两种方法来解决带有重复类别的类增量学习问题：多级知识蓄粉和动态自监督损失，利用未标注数据提高模型稳定性和可塑性。


<details>
  <summary>Details</summary>
Motivation: 传统类增量学习假设每个任务都包含新类别，而实际情况中旧类别可能在后续任务中重复出现。这称为带有重复类别的类增量学习（CIR），是更现实的场景。论文假设可以从外部源获得丰富的未标注数据，需要有效利用这些数据来保持模型的高稳定性和可塑性。

Method: 1. 多级知识蓄粉（MLKD）：从多个之前模型中蓄粉知识，包括特征和输出结果，以保持多样化的历史知识
2. 动态自监督损失（SSL）：利用未标注数据加速新类别学习，通过动态调整权重来保持主要任务的训练重点

Result: 这两种方法在CIR场景下显著提高了模型性能，在CVPR第5届CLVISION挑战赛中获得了第2名的成绩。

Conclusion: 论文通过创新地利用未标注数据，提出了有效的方法来解决带有重复类别的类增量学习问题。多级知识蓄粉确保了模型的稳定性，而动态自监督损失则提高了模型的可塑性，为更现实的增量学习场景提供了有效的解决方案。

Abstract: Class-incremental with repetition (CIR), where previously trained classes
repeatedly introduced in future tasks, is a more realistic scenario than the
traditional class incremental setup, which assumes that each task contains
unseen classes. CIR assumes that we can easily access abundant unlabeled data
from external sources, such as the Internet. Therefore, we propose two
components that efficiently use the unlabeled data to ensure the high stability
and the plasticity of models trained in CIR setup. First, we introduce
multi-level knowledge distillation (MLKD) that distills knowledge from multiple
previous models across multiple perspectives, including features and logits, so
the model can maintain much various previous knowledge. Moreover, we implement
dynamic self-supervised loss (SSL) to utilize the unlabeled data that
accelerates the learning of new classes, while dynamic weighting of SSL keeps
the focus of training to the primary task. Both of our proposed components
significantly improve the performance in CIR setup, achieving 2nd place in the
CVPR 5th CLVISION Challenge.

</details>


### [104] [Neural Rendering for Sensor Adaptation in 3D Object Detection](https://arxiv.org/abs/2508.12695)
*Felix Embacher,David Holtz,Jonas Uhrig,Marius Cordts,Markus Enzweiler*

Main category: cs.CV

TL;DR: 这篇论文研究了自主驾驶车不同盛像头传感器配置导致的跨传感器域间间隔问题，提出了CamShift数据集和基于神经渲染的数据驱动传感器适配方案，有效减少了性能泄漏并提高数据可重用性。


<details>
  <summary>Details</summary>
Motivation: 自主驾驶车的盛像头传感器配置因车辆类型不同而异，导致在一种传感器配置上训练的感知模型在其他配置上性能下降，即跨传感器域间间隔问题。

Method: 创建了CamShift数据集模拟子弹车和SUV车辆的传感器域间差异；分析了不同3D目标检测器的稳健性；提出了基于神经渲染的数据驱动传感器适配流水线，可以将整个数据集转换以匹配不同盛像头传感器配置。

Result: 证明了跨传感器性能显著泄漏；发现基于密雅鸟视图表示的BEVFormer模型最稳健；提出的神经渲染适配方案大幅度减少了域间间隔，提高了所有研究的3D目标检测器的性能。

Conclusion: 跨传感器域间间隔是自主驾驶感知系统的重要挑战，BEV基于的模型更稳健，而神经渲染适配技术能够有效缓解这一问题，减少新数据收集需求并提高数据可重用性。

Abstract: Autonomous vehicles often have varying camera sensor setups, which is
inevitable due to restricted placement options for different vehicle types.
Training a perception model on one particular setup and evaluating it on a new,
different sensor setup reveals the so-called cross-sensor domain gap, typically
leading to a degradation in accuracy. In this paper, we investigate the impact
of the cross-sensor domain gap on state-of-the-art 3D object detectors. To this
end, we introduce CamShift, a dataset inspired by nuScenes and created in CARLA
to specifically simulate the domain gap between subcompact vehicles and sport
utility vehicles (SUVs). Using CamShift, we demonstrate significant
cross-sensor performance degradation, identify robustness dependencies on model
architecture, and propose a data-driven solution to mitigate the effect. On the
one hand, we show that model architectures based on a dense Bird's Eye View
(BEV) representation with backward projection, such as BEVFormer, are the most
robust against varying sensor configurations. On the other hand, we propose a
novel data-driven sensor adaptation pipeline based on neural rendering, which
can transform entire datasets to match different camera sensor setups. Applying
this approach improves performance across all investigated 3D object detectors,
mitigating the cross-sensor domain gap by a large margin and reducing the need
for new data collection by enabling efficient data reusability across vehicles
with different sensor setups. The CamShift dataset and the sensor adaptation
benchmark are available at https://dmholtz.github.io/camshift/.

</details>


### [105] [Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection](https://arxiv.org/abs/2508.12711)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Yunyun Dong,Bingbing Song,Wei Zhou*

Main category: cs.CV

TL;DR: GenAI驱动的新闻多样性导致多级漂移，显著降低现有多模态虚假信息检测系统的鲁棒性，性能平均下降14.8%，推理过程不稳定。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具带来的新闻内容多样性对多模态虚假信息检测构成新挑战，需要系统研究其对检测系统鲁棒性的影响。

Method: 构建DriftBench大规模基准数据集（16,000个新闻实例，6种多样化类别），设计三个评估任务：真实性验证鲁棒性、对抗性证据污染敏感性、推理一致性分析。

Result: 实验显示6个最先进的LVLM检测器性能显著下降（平均F1下降14.8%），推理轨迹不稳定，在对抗性证据注入下表现更差。

Conclusion: 现有MMD系统存在根本性脆弱性，在GenAI时代迫切需要更具弹性的检测方法。

Abstract: The proliferation of multimodal misinformation poses growing threats to
public discourse and societal trust. While Large Vision-Language Models (LVLMs)
have enabled recent progress in multimodal misinformation detection (MMD), the
rise of generative AI (GenAI) tools introduces a new challenge: GenAI-driven
news diversity, characterized by highly varied and complex content. We show
that this diversity induces multi-level drift, comprising (1) model-level
misperception drift, where stylistic variations disrupt a model's internal
reasoning, and (2) evidence-level drift, where expression diversity degrades
the quality or relevance of retrieved external evidence. These drifts
significantly degrade the robustness of current LVLM-based MMD systems. To
systematically study this problem, we introduce DriftBench, a large-scale
benchmark comprising 16,000 news instances across six categories of
diversification. We design three evaluation tasks: (1) robustness of truth
verification under multi-level drift; (2) susceptibility to adversarial
evidence contamination generated by GenAI; and (3) analysis of reasoning
consistency across diverse inputs. Experiments with six state-of-the-art
LVLM-based detectors show substantial performance drops (average F1 -14.8%) and
increasingly unstable reasoning traces, with even more severe failures under
adversarial evidence injection. Our findings uncover fundamental
vulnerabilities in existing MMD systems and suggest an urgent need for more
resilient approaches in the GenAI era.

</details>


### [106] [Real-Time Sign Language Gestures to Speech Transcription using Deep Learning](https://arxiv.org/abs/2508.12713)
*Brandone Fonya*

Main category: cs.CV

TL;DR: 一种基于深度学习的实时符号语言识别系统，通过CNN模型识别手势并转换为文本和语音输出，提高听力语言障碍者的沟通能力


<details>
  <summary>Details</summary>
Motivation: 解决听力和语言障碍人士在日常生活中的沟通困难，提高他们的自主性和社会融入度

Method: 使用卷积神经网络(CNN)训练在Sign Language MNIST数据集上，通过网摄实时捕获手势进行分类，然后使用文本转语音技术生成语音输出

Result: 系统展现了高准确率和稳定的实时性能，虽然存在一定的延迟，但具有实用性

Conclusion: 该系统作为一种可访问、可靠和易于使用的辅助工具，有效提升了符号语言使用者在各种社会场景中的融入能力

Abstract: Communication barriers pose significant challenges for individuals with
hearing and speech impairments, often limiting their ability to effectively
interact in everyday environments. This project introduces a real-time
assistive technology solution that leverages advanced deep learning techniques
to translate sign language gestures into textual and audible speech. By
employing convolution neural networks (CNN) trained on the Sign Language MNIST
dataset, the system accurately classifies hand gestures captured live via
webcam. Detected gestures are instantaneously translated into their
corresponding meanings and transcribed into spoken language using
text-to-speech synthesis, thus facilitating seamless communication.
Comprehensive experiments demonstrate high model accuracy and robust real-time
performance with some latency, highlighting the system's practical
applicability as an accessible, reliable, and user-friendly tool for enhancing
the autonomy and integration of sign language users in diverse social settings.

</details>


### [107] [Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score](https://arxiv.org/abs/2508.12718)
*Syed Muhmmad Israr,Feng Zhao*

Main category: cs.CV

TL;DR: 通过双对比去噪分数框架，利用文本到图像模型的生成前知来实现真实图像编辑，既保持结构又支持灵活修改


<details>
  <summary>Details</summary>
Motivation: 解决现有文本到图像模型在真实图像编辑中的两大挑战：用户难以准确描述图像细节的提示词，以及修改时容易破坏原图结构和引入意外变化

Method: 提出Dual Contrastive Denoising Score框架，在潜在滴散模型中引入双对比损失函数，利用自注意力层的中间表征获取丰富空间信息，无需辅助网络

Result: 方法在真实图像编辑任务上超过现有方法，能够同时实现灵活的内容修改和结构保持，支持零样本图像到图像转换

Conclusion: 该框架能够直接利用预训练的文本到图像滴散模型而无需进一步训练，为真实图像编辑提供了一种简单但强大的解决方案

Abstract: Large-scale text-to-image generative models have shown remarkable ability to
synthesize diverse and high-quality images. However, it is still challenging to
directly apply these models for editing real images for two reasons. First, it
is difficult for users to come up with a perfect text prompt that accurately
describes every visual detail in the input image. Second, while existing models
can introduce desirable changes in certain regions, they often dramatically
alter the input content and introduce unexpected changes in unwanted regions.
To address these challenges, we present Dual Contrastive Denoising Score, a
simple yet powerful framework that leverages the rich generative prior of
text-to-image diffusion models. Inspired by contrastive learning approaches for
unpaired image-to-image translation, we introduce a straightforward dual
contrastive loss within the proposed framework. Our approach utilizes the
extensive spatial information from the intermediate representations of the
self-attention layers in latent diffusion models without depending on auxiliary
networks. Our method achieves both flexible content modification and structure
preservation between input and output images, as well as zero-shot
image-to-image translation. Through extensive experiments, we show that our
approach outperforms existing methods in real image editing while maintaining
the capability to directly utilize pretrained text-to-image diffusion models
without further training.

</details>


### [108] [Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting](https://arxiv.org/abs/2508.12720)
*Kangjie Chen,Yingji Zhong,Zhihao Li,Jiaqi Lin,Youyu Chen,Minghan Qin,Haoqian Wang*

Main category: cs.CV

TL;DR: 三维高斯拓扑在稀疏视角场景中存在外观偏差问题，根本原因是高斯元素过度缠绕导致的相互适应。研究提出了缠绕度量化指标和两种轻量纠正策略，有效减少新视角渲染偏差。


<details>
  <summary>Details</summary>
Motivation: 3D高斯拓扑在稀疏视角场景中展现出现实的训练视图渲染，但在新视角中出现外观偏差。研究识别到这是由于高斯元素过度缠绕导致的相互适应问题，需要探索解决方案。

Method: 提出了缠绕度量化指标Co-Adaptation Score (CA)，通过计算同一视点下不同高斯子集渲染的像素方差来评估高斯元素间的缠绕程度。并提出两种轻量策略：随机高斯丢弃和不透明度乘性噪音注入。

Result: 分析显示随着训练视图数量增加，缠绕程度自然减少。提出的两种策略在多个方法和测试集上验证有效，能够显著减少新视角渲染中的外观偏差。

Conclusion: 本研究揭示了3D高斯拗扑在稀疏视角下的核心限制：高斯元素过度缠绕导致的相互适应。提出的缠绕度量化指标和轻量策略为解决这一问题提供了有效方案，希望能够激励社区对稀疏视角3DGS进行更全面的理解。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated impressive performance in novel
view synthesis under dense-view settings. However, in sparse-view scenarios,
despite the realistic renderings in training views, 3DGS occasionally manifests
appearance artifacts in novel views. This paper investigates the appearance
artifacts in sparse-view 3DGS and uncovers a core limitation of current
approaches: the optimized Gaussians are overly-entangled with one another to
aggressively fit the training views, which leads to a neglect of the real
appearance distribution of the underlying scene and results in appearance
artifacts in novel views. The analysis is based on a proposed metric, termed
Co-Adaptation Score (CA), which quantifies the entanglement among Gaussians,
i.e., co-adaptation, by computing the pixel-wise variance across multiple
renderings of the same viewpoint, with different random subsets of Gaussians.
The analysis reveals that the degree of co-adaptation is naturally alleviated
as the number of training views increases. Based on the analysis, we propose
two lightweight strategies to explicitly mitigate the co-adaptation in
sparse-view 3DGS: (1) random gaussian dropout; (2) multiplicative noise
injection to the opacity. Both strategies are designed to be plug-and-play, and
their effectiveness is validated across various methods and benchmarks. We hope
that our insights into the co-adaptation effect will inspire the community to
achieve a more comprehensive understanding of sparse-view 3DGS.

</details>


### [109] [Frequency-Driven Inverse Kernel Prediction for Single Image Defocus Deblurring](https://arxiv.org/abs/2508.12736)
*Ying Zhang,Xiongxin Tang,Chongyi Li,Qiao Chen,Yuquan Wu*

Main category: cs.CV

TL;DR: 提出FDIKP网络，通过频率域表示增强核估计的结构可识别性，采用双分支逆核预测策略和位置自适应卷积，在单图像散焦去模糊任务中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖空间特征进行核估计，但在严重模糊区域由于局部高频细节缺失导致性能下降，需要利用频率域对模糊建模的优越判别能力

Method: 提出频率驱动的逆核预测网络(FDIKP)，包含双分支逆核预测策略(DIKP)提高核估计精度，位置自适应卷积(PAC)增强解卷积适应性，以及双域尺度循环模块(DSRM)融合解卷积结果

Result: 大量实验证明该方法优于现有方法

Conclusion: 频率域表示能有效增强核建模的结构可识别性，提出的FDIKP网络在单图像散焦去模糊任务中表现出优越性能

Abstract: Single image defocus deblurring aims to recover an all-in-focus image from a
defocus counterpart, where accurately modeling spatially varying blur kernels
remains a key challenge. Most existing methods rely on spatial features for
kernel estimation, but their performance degrades in severely blurry regions
where local high-frequency details are missing. To address this, we propose a
Frequency-Driven Inverse Kernel Prediction network (FDIKP) that incorporates
frequency-domain representations to enhance structural identifiability in
kernel modeling. Given the superior discriminative capability of the frequency
domain for blur modeling, we design a Dual-Branch Inverse Kernel Prediction
(DIKP) strategy that improves the accuracy of kernel estimation while
maintaining stability. Moreover, considering the limited number of predicted
inverse kernels, we introduce a Position Adaptive Convolution (PAC) to enhance
the adaptability of the deconvolution process. Finally, we propose a
Dual-Domain Scale Recurrent Module (DSRM) to fuse deconvolution results and
progressively improve deblurring quality from coarse to fine. Extensive
experiments demonstrate that our method outperforms existing approaches. Code
will be made publicly available.

</details>


### [110] [DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification](https://arxiv.org/abs/2508.12745)
*Xizhan Gao,Wei Hu*

Main category: cs.CV

TL;DR: 提出DCSCR网络，结合传统图像集分类方法与深度学习，同时学习帧级和概念级特征表示，通过类别特定协同表示度量学习解决少样本图像集分类问题


<details>
  <summary>Details</summary>
Motivation: 传统ISC方法基于原始像素特征忽略特征学习，深度ISC方法无法在度量集合距离时自适应调整特征，导致少样本ISC性能有限

Method: DCSCR网络包含全卷积深度特征提取模块、全局特征学习模块和类别特定协同表示度量学习模块，使用新的CSCR对比损失函数

Result: 在多个知名少样本ISC数据集上的实验证明了该方法相比最先进图像集分类算法的有效性

Conclusion: DCSCR成功结合传统ISC方法和深度学习，能够同时学习帧级和概念级特征表示，有效提升少样本图像集分类性能

Abstract: Image set classification (ISC), which can be viewed as a task of comparing
similarities between sets consisting of unordered heterogeneous images with
variable quantities and qualities, has attracted growing research attention in
recent years. How to learn effective feature representations and how to explore
the similarities between different image sets are two key yet challenging
issues in this field. However, existing traditional ISC methods classify image
sets based on raw pixel features, ignoring the importance of feature learning.
Existing deep ISC methods can learn deep features, but they fail to adaptively
adjust the features when measuring set distances, resulting in limited
performance in few-shot ISC. To address the above issues, this paper combines
traditional ISC methods with deep models and proposes a novel few-shot ISC
approach called Deep Class-specific Collaborative Representation (DCSCR)
network to simultaneously learn the frame- and concept-level feature
representations of each image set and the distance similarities between
different sets. Specifically, DCSCR consists of a fully convolutional deep
feature extractor module, a global feature learning module, and a
class-specific collaborative representation-based metric learning module. The
deep feature extractor and global feature learning modules are used to learn
(local and global) frame-level feature representations, while the
class-specific collaborative representation-based metric learning module is
exploit to adaptively learn the concept-level feature representation of each
image set and thus obtain the distance similarities between different sets by
developing a new CSCR-based contrastive loss function. Extensive experiments on
several well-known few-shot ISC datasets demonstrate the effectiveness of the
proposed method compared with some state-of-the-art image set classification
algorithms.

</details>


### [111] [D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal](https://arxiv.org/abs/2508.12750)
*Linhao Li,Boya Jin,Zizhe Li,Lanqing Guo,Hao Cheng,Bo Li,Yongfeng Dong*

Main category: cs.CV

TL;DR: 基于Mamba网络的双重磁石扫描策略，通过双路循环扫描和双尺度融合技术，实现了更有效的阴影清除效果


<details>
  <summary>Details</summary>
Motivation: 阴影清除任务中，阴影区域的修复变换与良照区域存在显著差异，统一的修复策略效果有限，需要根据区域特征进行适应性建模

Method: 提出双路循环扫描组(DPMG)捕获全局特征，包含掩码感知适应扫描策略；双尺度融合磁石块(DFMB)融合原始特征与低分辨率特征，提升多尺度表征能力

Result: 在阴影清除标准数据集上，方法显著超过现有最先进方法

Conclusion: 通过基于Mamba的双重磁石扫描和双尺度融合技术，能够有效地解决阴影清除中的区域特征差异问题，提升修复质量

Abstract: Shadow removal aims to restore images that are partially degraded by shadows,
where the degradation is spatially localized and non-uniform. Unlike general
restoration tasks that assume global degradation, shadow removal can leverage
abundant information from non-shadow regions for guidance. However, the
transformation required to correct shadowed areas often differs significantly
from that of well-lit regions, making it challenging to apply uniform
correction strategies. This necessitates the effective integration of non-local
contextual cues and adaptive modeling of region-specific transformations. To
this end, we propose a novel Mamba-based network featuring dual-scale fusion
and dual-path scanning to selectively propagate contextual information based on
transformation similarity across regions. Specifically, the proposed Dual-Scale
Fusion Mamba Block (DFMB) enhances multi-scale feature representation by fusing
original features with low-resolution features, effectively reducing boundary
artifacts. The Dual-Path Mamba Group (DPMG) captures global features via
horizontal scanning and incorporates a mask-aware adaptive scanning strategy,
which improves structural continuity and fine-grained region modeling.
Experimental results demonstrate that our method significantly outperforms
existing state-of-the-art approaches on shadow removal benchmarks.

</details>


### [112] [CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke](https://arxiv.org/abs/2508.12755)
*Cristo J. van den Berg,Frank G. te Nijenhuis,Mirre J. Blaauboer,Daan T. W. van Erp,Carlijn M. Keppels,Matthijs van der Sluijs,Bob Roozenbeek,Wim van Zwam,Sandra Cornelissen,Danny Ruijters,Ruisheng Su,Theo van Walsum*

Main category: cs.CV

TL;DR: CLAIRE-DSA是一个基于深度学习的框架，用于在急性缺血性卒中机械取栓术中自动分类数字减影血管造影图像的关键属性，显著提升下游图像分割任务的性能。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉模型在机械取栓术中辅助应用时，图像质量差会严重影响性能表现，需要开发自动化的图像质量评估工具来支持质量控制和工作流程优化。

Method: 使用预训练的ResNet骨干网络进行微调，训练多个分类器来预测9个图像属性（如对比度存在、投影角度、运动伪影严重程度等），基于1758张标注的荧光MinIP图像数据集。

Result: 模型在所有标签上都表现出色，ROC-AUC达到0.91-0.98，精确度0.70-1.00。在分割任务中，通过过滤低质量图像，分割成功率从42%提升至69%（p<0.001）。

Conclusion: CLAIRE-DSA作为自动化工具在急性缺血性卒中患者DSA序列中准确分类图像属性方面显示出强大潜力，可支持临床和研究应用中的图像标注和质量控制。

Abstract: Computer vision models can be used to assist during mechanical thrombectomy
(MT) for acute ischemic stroke (AIS), but poor image quality often degrades
performance. This work presents CLAIRE-DSA, a deep learning--based framework
designed to categorize key image properties in minimum intensity projections
(MinIPs) acquired during MT for AIS, supporting downstream quality control and
workflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,
fine-tuned to predict nine image properties (e.g., presence of contrast,
projection angle, motion artefact severity). Separate classifiers were trained
on an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model
achieved excellent performance on all labels, with ROC-AUC ranging from $0.91$
to $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of
CLAIRE-DSA to identify suitable images was evaluated on a segmentation task by
filtering poor quality images and comparing segmentation performance on
filtered and unfiltered datasets. Segmentation success rate increased from
$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an
automated tool for accurately classifying image properties in DSA series of
acute ischemic stroke patients, supporting image annotation and quality control
in clinical and research applications. Source code is available at
https://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.

</details>


### [113] [Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors](https://arxiv.org/abs/2508.12766)
*Peihao Li,Yan Fang,Man Liu,Huihui Bai,Anhong Wang,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的半监督语义分割方法ICAF，专门解决CdZnTe半导体图像标注中的低对比度缺陷边界问题，通过组内一致性增强技术提升分割精度至70.6% mIoU。


<details>
  <summary>Details</summary>
Motivation: 因为CdZnTe半导体图像存在低对比度缺陷边界问题，需要涉多视图对照标注，形成了"多对一"关系。传统半监督方法基于"一对一"关系，在这种场景下效果不佳且容易产生错误积累。

Method: 提出了组内一致性增强框架(ICAF)，包括两个核心模块：视图增强模块(VAM)通过多视图聚合动态合成边界敏感的新视图，和视图纠正模块(VCM)通过信息交互强调显著区域并减少噪声。

Result: 在CdZnTe数据集上仅使用2%的组标注数据(5‰)，使用DeepLabV3+与ResNet-101背榜达到了70.6% mIoU的分割精度。

Conclusion: ICAF框架通过组内一致性增强有效解决了CdZnTe图像中的低对比度缺陷分割挑战，为类似的"多对一"标注问题提供了新的解决方案。

Abstract: Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging
due to the low-contrast defect boundaries, necessitating annotators to
cross-reference multiple views. These views share a single ground truth (GT),
forming a unique ``many-to-one'' relationship. This characteristic renders
advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as
they are generally limited by a ``one-to-one'' relationship, where each image
is independently associated with its GT. Such limitation may lead to error
accumulation in low-contrast regions, further exacerbating confirmation bias.
To address this issue, we revisit the SSS pipeline from a group-oriented
perspective and propose a human-inspired solution: the Intra-group Consistency
Augmentation Framework (ICAF). First, we experimentally validate the inherent
consistency constraints within CdZnTe groups, establishing a group-oriented
baseline using the Intra-group View Sampling (IVS). Building on this insight,
we introduce the Pseudo-label Correction Network (PCN) to enhance consistency
representation, which consists of two key modules. The View Augmentation Module
(VAM) improves boundary details by dynamically synthesizing a boundary-aware
view through the aggregation of multiple views. In the View Correction Module
(VCM), this synthesized view is paired with other views for information
interaction, effectively emphasizing salient regions while minimizing noise.
Extensive experiments demonstrate the effectiveness of our solution for CdZnTe
materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation
model, we achieve a 70.6\% mIoU on the CdZnTe dataset using only 2
group-annotated data (5\textperthousand). The code is available at
\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.

</details>


### [114] [SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior](https://arxiv.org/abs/2508.12777)
*Wenguang Tao,Xiaotian Wang,Tian Yan,Jie Yan,Guodong Li,Kun Bai*

Main category: cs.CV

TL;DR: SocialTrack是一个针对无人机视角下多目标跟踪的创新框架，通过多尺度特征增强、速度自适应卡尔曼滤波、群体运动补偿和时空记忆预测等技术，显著提升了复杂城市交通环境中小目标的跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 无人机多目标跟踪在智能交通系统分析中具有重要价值，但复杂视角下的小目标尺度变化、遮挡、非线性交叉运动和运动模糊等问题严重影响了跟踪稳定性。

Method: 提出SocialTrack框架，包含：1）多尺度特征增强的小目标检测器；2）速度自适应容积卡尔曼滤波（VACKF）用于轨迹预测；3）群体运动补偿策略（GMCS）建模社会群体运动先验；4）时空记忆预测（STMP）利用历史轨迹信息预测未来状态。

Result: 在UAVDT和MOT17数据集上的实验表明，SocialTrack在多个关键指标上优于现有最先进方法，特别是在MOTA和IDF1等核心性能指标上有显著提升。

Conclusion: SocialTrack框架具有优异的鲁棒性和适应性，且高度模块化和兼容，可与现有跟踪器无缝集成以进一步提升性能。

Abstract: As a key research direction in the field of multi-object tracking (MOT),
UAV-based multi-object tracking has significant application value in the
analysis and understanding of urban intelligent transportation systems.
However, in complex UAV perspectives, challenges such as small target scale
variations, occlusions, nonlinear crossing motions, and motion blur severely
hinder the stability of multi-object tracking. To address these challenges,
this paper proposes a novel multi-object tracking framework, SocialTrack, aimed
at enhancing the tracking accuracy and robustness of small targets in complex
urban traffic environments. The specialized small-target detector enhances the
detection performance by employing a multi-scale feature enhancement mechanism.
The Velocity Adaptive Cubature Kalman Filter (VACKF) improves the accuracy of
trajectory prediction by incorporating a velocity dynamic modeling mechanism.
The Group Motion Compensation Strategy (GMCS) models social group motion priors
to provide stable state update references for low-quality tracks, significantly
improving the target association accuracy in complex dynamic environments.
Furthermore, the Spatio-Temporal Memory Prediction (STMP) leverages historical
trajectory information to predict the future state of low-quality tracks,
effectively mitigating identity switching issues. Extensive experiments on the
UAVDT and MOT17 datasets demonstrate that SocialTrack outperforms existing
state-of-the-art (SOTA) methods across several key metrics. Significant
improvements in MOTA and IDF1, among other core performance indicators,
highlight its superior robustness and adaptability. Additionally, SocialTrack
is highly modular and compatible, allowing for seamless integration with
existing trackers to further enhance performance.

</details>


### [115] [Leveraging Diffusion Models for Stylization using Multiple Style Images](https://arxiv.org/abs/2508.12784)
*Dan Ruta,Abdelaziz Djelouah,Raphael Ortiz,Christopher Schroers*

Main category: cs.CV

TL;DR: 基于多样式图片的潜在扩散模型风格转换方法，通过图片提示适配器和统计对齐技术，在去噪UNet的交叉注意力和自注意力层进行干预，实现了更准确的风格匹配和更好的内容-风格解耦。


<details>
  <summary>Details</summary>
Motivation: 现有风格转换方法在准确匹配风格、支持多样式图片数量以及避免内容-风格耦合方面仍然遇到困难。

Method: 利用多个风格图片来更好表征风格特征和防止内容泄漏；设计了结合图片提示适配器和去噪过程中特征统计对齐的方法；在交叉注意力和自注意力层进行干预；使用聚类技术从大量风格样本关注特征中精炼小代表性集合。

Result: 该方法在风格化任务上达到了最先进水平的结果。

Conclusion: 通过多样式图片、多层次干预和统计对齐技术的结合，该方法有效解决了风格转换中的关键问题，实现了更优秀的风格化效果。

Abstract: Recent advances in latent diffusion models have enabled exciting progress in
image style transfer. However, several key issues remain. For example, existing
methods still struggle to accurately match styles. They are often limited in
the number of style images that can be used. Furthermore, they tend to entangle
content and style in undesired ways. To address this, we propose leveraging
multiple style images which helps better represent style features and prevent
content leaking from the style images. We design a method that leverages both
image prompt adapters and statistical alignment of the features during the
denoising process. With this, our approach is designed such that it can
intervene both at the cross-attention and the self-attention layers of the
denoising UNet. For the statistical alignment, we employ clustering to distill
a small representative set of attention features from the large number of
attention values extracted from the style samples. As demonstrated in our
experimental section, the resulting method achieves state-of-the-art results
for stylization.

</details>


### [116] [Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision](https://arxiv.org/abs/2508.12794)
*Kyriaki,Kokka,Rahul Goel,Ali Abbas,Kerry A. Nice,Luca Martial,SM Labib,Rihuan Ke,Carola Bibiane Schönlieb,James Woodcock*

Main category: cs.CV

TL;DR: 使用深度学习分析Google街景图像来估算全球各城市的骑行和摩托车使用水平，为交通行为研究提供了高效的新方法


<details>
  <summary>Details</summary>
Motivation: 交通方式影响健康，但全球范围内的骑行和摩托车行为数据缺乏，需要一种高效的数据收集方法

Method: 采用YOLOv4模型分析185个城市的Google街景图像，每个城市耀样图像8000张，使用beta回归模型预测交通方式分享率

Result: 摩托车检测与实际使用率相关系数高达0.78，骑行相关系数为0.51，模型预测的R²值分别为0.614和0.612，中位绝对误差分别为1.3%和1.4%

Conclusion: 通过计算机视觉分析Google街景图像可以有效捕捉交通行为数据，为传统调查方法提供了有力补充，尤其在数据缺乏地区具有重要价值

Abstract: Transportation influence health by shaping exposure to physical activity, air
pollution and injury risk.Comparative data on cycling and motorcycling
behaviours is scarce, particularly at a global scale.Street view imagery, such
as Google Street View (GSV), combined with computer vision, is a valuable
resource for efficiently capturing travel behaviour data.This study
demonstrates a novel approach using deep learning on street view images to
estimate cycling and motorcycling levels across diverse cities worldwide.We
utilized data from 185 global cities.The data on mode shares of cycling and
motorcycling estimated using travel surveys or censuses.We used GSV images to
detect cycles and motorcycles in sampled locations, using 8000 images per
city.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean
average precision of 89% for detecting cycles and motorcycles in GSV images.A
global prediction model was developed using beta regression with city-level
mode shares as outcome, with log transformed explanatory variables of counts of
GSV-detected images with cycles and motorcycles, while controlling for
population density.We found strong correlations between GSV motorcycle counts
and motorcycle mode share (0.78) and moderate correlations between GSV cycle
counts and cycling mode share (0.51).Beta regression models predicted mode
shares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,
achieving median absolute errors (MDAE) of 1.3% and 1.4%,
respectively.Scatterplots demonstrated consistent prediction accuracy, though
cities like Utrecht and Cali were outliers.The model was applied to 60 cities
globally for which we didn't have recent mode share data.We provided estimates
for some cities in the Middle East, Latin America and East Asia.With computer
vision, GSV images capture travel modes and activity, providing insights
alongside traditional data sources.

</details>


### [117] [Morphological classification of eclipsing binary stars using computer vision methods](https://arxiv.org/abs/2508.12802)
*Štefan Parimucha,Maksim Gabdeev,Yanna Markus,Martin Vaňko,Pavol Gajdoš*

Main category: cs.CV

TL;DR: 使用预训练的ResNet50和ViT模型，通过极坐标变换和hexbin可视化技术分析风叙变星光曲线，在主要分类任务中达到高精度，但在斑点检测上表现差强


<details>
  <summary>Details</summary>
Motivation: 应对大规模天文调查中风叙变星分类的需求，探索计算机视觉方法在这一领域的应用潜力

Method: 使用预训练的ResNet50和ViT模型，将相位折叠光曲线转换为极坐标形式并结合hexbin可视化，采用分层分类方法，首先分离连接类型，然后检测斑点

Result: 主要二元分类在验证数据上达到>96%准确率，在OGLE、DEBCat、WUMaCat观测数据上表现优异（94%-100%），但自动斑点检测性能差强

Conclusion: 计算机视觉在大规模风叙变星形态分类中具有强大潜力，但需要进一步研究提高自动斑点检测的稳健性

Abstract: We present an application of computer vision methods to classify the light
curves of eclipsing binaries (EB). We have used pre-trained models based on
convolutional neural networks ($\textit{ResNet50}$) and vision transformers
($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created
from synthetic datasets. To improve model generalisation and reduce
overfitting, we developed a novel image representation by transforming
phase-folded light curves into polar coordinates combined with hexbin
visualisation. Our hierarchical approach in the first stage classifies systems
into detached and overcontact types, and in the second stage identifies the
presence or absence of spots. The binary classification models achieved high
accuracy ($>96\%$) on validation data across multiple passbands (Gaia~$G$, $I$,
and $TESS$) and demonstrated strong performance ($>94\%$, up to $100\%$ for
$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and
WUMaCat catalogues. While the primary binary classification was highly
successful, the secondary task of automated spot detection performed poorly,
revealing a significant limitation of our models for identifying subtle
photometric features. This study highlights the potential of computer vision
for EB morphological classification in large-scale surveys, but underscores the
need for further research into robust, automated spot detection.

</details>


### [118] [Next Visual Granularity Generation](https://arxiv.org/abs/2508.12811)
*Yikai Wang,Zhouxia Wang,Zhonghua Wu,Qingyi Tao,Kang Liao,Chen Change Loy*

Main category: cs.CV

TL;DR: 一种新的图像生成方法NVG，逐步精细化生成从全局布局到细节的可视粒度序列，在ImageNet上超过VAR系列的FID指标


<details>
  <summary>Details</summary>
Motivation: 解决传统图像生成方法在多粒度级别细细控制上的不足，通过分层结构化表示实现更精细的生成控制

Method: 提出NVG生成框架，将图像分解为结构化序列，从空白图像开始逐步精细化，通过迭代过程编码层次化表示

Result: 在ImageNet数据集上训练的NVG模型显示了明显的扩展性能，FID指标持续优于VAR系列(3.30->3.03, 2.57->2.44, 2.09->2.06)

Conclusion: NVG框架通过结构化的可视粒度序列生成，实现了多粒度级别的细细控制，在图像生成性能上取得显著提升

Abstract: We propose a novel approach to image generation by decomposing an image into
a structured sequence, where each element in the sequence shares the same
spatial resolution but differs in the number of unique tokens used, capturing
different level of visual granularity. Image generation is carried out through
our newly introduced Next Visual Granularity (NVG) generation framework, which
generates a visual granularity sequence beginning from an empty image and
progressively refines it, from global layout to fine details, in a structured
manner. This iterative process encodes a hierarchical, layered representation
that offers fine-grained control over the generation process across multiple
granularity levels. We train a series of NVG models for class-conditional image
generation on the ImageNet dataset and observe clear scaling behavior. Compared
to the VAR series, NVG consistently outperforms it in terms of FID scores (3.30
-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to
showcase the capability and potential of the NVG framework. Our code and models
will be released.

</details>


### [119] [SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop](https://arxiv.org/abs/2508.12813)
*Friedhelm Hamann,Emil Mededovic,Fabian Gülhan,Yuli Wu,Johannes Stegmaier,Jing He,Yiqing Wang,Kexin Zhang,Lingling Li,Licheng Jiao,Mengru Ma,Hongxiang Huang,Yuhao Yan,Hongwei Ren,Xiaopeng Lin,Yulong Huang,Bojun Cheng,Se Hyun Lee,Gyu Sung Ham,Kanghan Oh,Gi Hyun Lim,Boxuan Yang,Bowen Du,Guillermo Gallego*

Main category: cs.CV

TL;DR: CVPR 2025事件视觉研讨会举办的时空实例分割挑战赛概述，包含任务描述、数据集、挑战细节和结果分析，以及前5名团队的方法介绍


<details>
  <summary>Details</summary>
Motivation: 推动事件相机和灰度相机数据在时空实例分割任务中的应用，促进该领域的技术发展和算法创新

Method: 组织挑战赛并提供对齐的事件相机和灰度相机数据集，要求参赛团队预测精确的像素级分割掩码，分析前5名团队的技术方案

Result: 成功举办了时空实例分割挑战赛，收集了多个创新解决方案，展示了事件视觉在实例分割任务中的潜力

Conclusion: 该挑战赛为事件相机视觉社区提供了宝贵的基准测试平台，推动了时空实例分割技术的发展，未来有望在更多实际应用中发挥作用

Abstract: We present an overview of the Spatio-temporal Instance Segmentation (SIS)
challenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.
The task is to predict accurate pixel-level segmentation masks of defined
object classes from spatio-temporally aligned event camera and grayscale camera
data. We provide an overview of the task, dataset, challenge details and
results. Furthermore, we describe the methods used by the top-5 ranking teams
in the challenge. More resources and code of the participants' methods are
available here:
https://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md

</details>


### [120] [DEEP-SEA: Deep-Learning Enhancement for Environmental Perception in Submerged Aquatics](https://arxiv.org/abs/2508.12824)
*Shuang Chen,Ronald Thenius,Farshad Arvin,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: DEEP-SEA是一个基于深度学习的海底图像恢复模型，通过双频增强自注意力机制在空间和频率域中自适应优化特征表示，有效解决水下图像退化问题。


<details>
  <summary>Details</summary>
Motivation: 水下环境的光线散射、吸收和浑浊度导致图像清晰度下降和颜色失真，严重影响海洋生物多样性监测、生态评估和自主探索的准确性。

Method: 提出DEEP-SEA模型，采用双频增强自注意力空间和频率调制器，在频率域和空间域同时优化特征表示，增强低频和高频信息并保持空间结构。

Result: 在EUVP和LSUI数据集上的实验表明，该模型在恢复精细图像细节和结构一致性方面优于现有最先进方法。

Conclusion: DEEP-SEA能有效缓解水下视觉退化问题，有望提高水下监测平台的可靠性，实现更准确的生态观测、物种识别和自主导航。

Abstract: Continuous and reliable underwater monitoring is essential for assessing
marine biodiversity, detecting ecological changes and supporting autonomous
exploration in aquatic environments. Underwater monitoring platforms rely on
mainly visual data for marine biodiversity analysis, ecological assessment and
autonomous exploration. However, underwater environments present significant
challenges due to light scattering, absorption and turbidity, which degrade
image clarity and distort colour information, which makes accurate observation
difficult. To address these challenges, we propose DEEP-SEA, a novel deep
learning-based underwater image restoration model to enhance both low- and
high-frequency information while preserving spatial structures. The proposed
Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator aims to
adaptively refine feature representations in frequency domains and
simultaneously spatial information for better structural preservation. Our
comprehensive experiments on EUVP and LSUI datasets demonstrate the superiority
over the state of the art in restoring fine-grained image detail and structural
consistency. By effectively mitigating underwater visual degradation, DEEP-SEA
has the potential to improve the reliability of underwater monitoring platforms
for more accurate ecological observation, species identification and autonomous
navigation.

</details>


### [121] [Multi-source Multimodal Progressive Domain Adaption for Audio-Visual Deception Detection](https://arxiv.org/abs/2508.12842)
*Ronghao Lin,Sijie Mai,Ying Zeng,Qiaolin He,Aolin Xiong,Haifeng Hu*

Main category: cs.CV

TL;DR: 提出MMPDA框架解决多模态欺骗检测中的域偏移问题，在MMDD挑战赛中获得第二名，准确率60.43%，F1分数56.99%


<details>
  <summary>Details</summary>
Motivation: 解决多模态欺骗检测中源域和目标域之间的域偏移问题，特别是在跨不同多模态数据集时的领域适应挑战

Method: 多源多模态渐进式域适应框架(MMPDA)，通过在特征层和决策层逐步对齐源域和目标域来桥接域偏移

Result: 在竞赛第二阶段达到60.43%准确率和56.99% F1分数，比第一名团队F1分数高5.59%，比第三名团队准确率高6.75%

Conclusion: 该方法有效解决了多模态欺骗检测中的域适应问题，在挑战赛中表现优异，证明了渐进式域适应框架的有效性

Abstract: This paper presents the winning approach for the 1st MultiModal Deception
Detection (MMDD) Challenge at the 1st Workshop on Subtle Visual Computing
(SVC). Aiming at the domain shift issue across source and target domains, we
propose a Multi-source Multimodal Progressive Domain Adaptation (MMPDA)
framework that transfers the audio-visual knowledge from diverse source domains
to the target domain. By gradually aligning source and the target domain at
both feature and decision levels, our method bridges domain shifts across
diverse multimodal datasets. Extensive experiments demonstrate the
effectiveness of our approach securing Top-2 place. Our approach reaches 60.43%
on accuracy and 56.99\% on F1-score on competition stage 2, surpassing the 1st
place team by 5.59% on F1-score and the 3rd place teams by 6.75% on accuracy.
Our code is available at https://github.com/RH-Lin/MMPDA.

</details>


### [122] [Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models](https://arxiv.org/abs/2508.12861)
*Dexia Chen,Wentao Zhang,Qianjie Zhu,Ping Hu,Weibing Li,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: 通过多视角协同优化策略和一致性约束，CoMuCo方法提升了视觉-语言模型在跨领域少样本识别任务中的性能


<details>
  <summary>Details</summary>
Motivation: 当前的VLM迅速迁移学习方法在标准图像数据集上表现优异，但在跨领域任务中效果有限，需要解决自然图像与其他成像领域的差异问题

Method: 提出CoMuCo策略，使用两个功能互补的专家模块提取多视角特征，结合先验知识的一致性约束和信息几何的共识机制来增强特征学习的稳健性

Result: 在旧的和新建立的跨领域少样本测试集上，CoMuCo都一贯地超过当前最佳方法，验证了方法的有效性

Conclusion: CoMuCo为VLM在跨领域少样本识别任务中提供了有效的精调策略，通过多视角协同和一致性约束显著提升了模型的演化能力

Abstract: Vision-language models (VLMs) pre-trained on natural image and language data,
such as CLIP, have exhibited significant potential in few-shot image
recognition tasks, leading to development of various efficient transfer
learning methods. These methods exploit inherent pre-learned knowledge in VLMs
and have achieved strong performance on standard image datasets. However, their
effectiveness is often limited when confronted with cross-domain tasks where
imaging domains differ from natural images. To address this limitation, we
propose Consistency-guided Multi-view Collaborative Optimization (CoMuCo), a
novel fine-tuning strategy for VLMs. This strategy employs two functionally
complementary expert modules to extract multi-view features, while
incorporating prior knowledge-based consistency constraints and information
geometry-based consensus mechanisms to enhance the robustness of feature
learning. Additionally, a new cross-domain few-shot benchmark is established to
help comprehensively evaluate methods on imaging domains distinct from natural
images. Extensive empirical evaluations on both existing and newly proposed
benchmarks suggest CoMuCo consistently outperforms current methods in few-shot
tasks. The code and benchmark will be released.

</details>


### [123] [Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning](https://arxiv.org/abs/2508.12877)
*Dexia Chen,Qianjie Zhu,Weibing Li,Yue Yu,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: 基于曲面保持和雕塑的精调方法MPS-Tuning，通过保持语义流形的几何结构和增强类别可分辨性，提升预训练视觉-语言模型的小样本分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的调优方法忽视了数据分布的几何结构，导致语义表征的扭曲，需要一种能够显式约束流形本质几何的方法。

Method: MPS-Tuning方法将特征空间中的数据分布视为语义流形，通过对齐精调前后特征的Gram矩阵来保持宏观和微观拓扑结构，并优化图像和文本特征的成对相似性来增强类别可分辨性。

Result: 大量实验证明MPS-Tuning显著提升了模型性能，同时有效保持了语义流形的结构。

Conclusion: MPS-Tuning通过显式约束流形几何结构，为预训练视觉-语言模型的精调提供了一种有效的方法，在保持语义表征整体性的同时提升了分类准确性。

Abstract: Pretrained vision-language models (VLMs), such as CLIP, have shown remarkable
potential in few-shot image classification and led to numerous effective
transfer learning strategies. These methods leverage the pretrained knowledge
of VLMs to enable effective domain adaptation while mitigating overfitting
through parameter-efficient tuning or instance-based consistency constraints.
However, such regularizations often neglect the geometric structure of data
distribution, which may lead to distortion of the overall semantic
representation. To overcome this limitation, we propose a novel fine-tuning
method, Manifold-Preserving and Sculpting Tuning (MPS-Tuning). Regarding the
data distribution in feature space as a semantic manifold, MPS-Tuning
explicitly constrains the intrinsic geometry of this manifold while further
sculpting it to enhance class separability. Specifically, MPS-Tuning preserves
both macroscopic and microscopic topological structures of the original
manifold by aligning Gram matrices of features before and after fine-tuning.
Theoretically, this constraint is shown to approximate an upper bound of the
Gromov-Wasserstein distance. Furthermore, features from the image and text
modalities are paired, and pairwise similarities are optimized to enhance the
manifold's class discriminability. Extensive experiments demonstrate that
MPS-Tuning significantly improves model performance while effectively
preserving the structure of the semantic manifold. The code will be released.

</details>


### [124] [S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](https://arxiv.org/abs/2508.12880)
*Chubin Chen,Jiashu Zhu,Xiaokun Feng,Nisha Huang,Meiqi Wu,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: S²-Guidance是一种新的扩散模型引导方法，通过随机块丢弃构建子网络来优化预测，解决了CFG方法产生次优结果的问题，在文本到图像和文本到视频生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究发现Classifier-free Guidance (CFG)方法在扩散模型中会产生与真实情况不符的次优预测，导致语义不连贯和低质量输出，需要改进现有引导策略。

Method: 提出S²-Guidance方法，在前向过程中使用随机块丢弃来构建随机子网络，利用模型自身的子网络来精炼次优预测，引导模型远离低质量预测。

Result: 在文本到图像和文本到视频生成任务上的大量实验表明，S²-Guidance始终优于CFG和其他先进引导策略，提供更高质量的输出。

Conclusion: S²-Guidance通过利用模型自身的子网络结构有效解决了CFG的局限性，为扩散模型提供了更可靠的引导机制，显著提升了生成质量。

Abstract: Classifier-free Guidance (CFG) is a widely used technique in modern diffusion
models for enhancing sample quality and prompt adherence. However, through an
empirical analysis on Gaussian mixture modeling with a closed-form solution, we
observe a discrepancy between the suboptimal results produced by CFG and the
ground truth. The model's excessive reliance on these suboptimal predictions
often leads to semantic incoherence and low-quality outputs. To address this
issue, we first empirically demonstrate that the model's suboptimal predictions
can be effectively refined using sub-networks of the model itself. Building on
this insight, we propose S^2-Guidance, a novel method that leverages stochastic
block-dropping during the forward process to construct stochastic sub-networks,
effectively guiding the model away from potential low-quality predictions and
toward high-quality outputs. Extensive qualitative and quantitative experiments
on text-to-image and text-to-video generation tasks demonstrate that
S^2-Guidance delivers superior performance, consistently surpassing CFG and
other advanced guidance strategies. Our code will be released.

</details>


### [125] [ONG: One-Shot NMF-based Gradient Masking for Efficient Model Sparsification](https://arxiv.org/abs/2508.12891)
*Sankar Behera,Yamuna Prasad*

Main category: cs.CV

TL;DR: ONG是一种基于非负矩阵分解的一次性剪枝方法，通过梯度掩码机制在训练过程中严格保持目标稀疏度，在CIFAR数据集上实现了与现有方法相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络尺寸庞大导致部署困难，现有剪枝方法往往需要复杂的迭代过程、专用标准或在训练中难以有效保持稀疏度。

Method: 使用非负矩阵分解(NMF)识别重要权重结构进行一次性剪枝，然后采用精确的梯度掩码机制确保只更新未剪枝权重，严格保持目标稀疏度。

Result: 在CIFAR-10和CIFAR-100数据集上使用ResNet56、ResNet34和ResNet18进行测试，ONG在各种稀疏度水平下都能达到可比或更优的性能。

Conclusion: ONG提供了一种有效的稀疏化策略，能够保持剪枝后的结构完整性，并提供了明确的机制来达到目标稀疏度。

Abstract: Deep Neural Networks (DNNs) have achieved remarkable success but their large
size poses deployment challenges. While various pruning techniques exist, many
involve complex iterative processes, specialized criteria, or struggle to
maintain sparsity effectively during training. We introduce ONG (One-shot
NMF-based Gradient Masking), a novel sparsification strategy that identifies
salient weight structures using Non-negative Matrix Factorization (NMF) for
one-shot pruning at the outset of training. Subsequently, ONG employs a precise
gradient masking mechanism to ensure that only unpruned weights are updated,
strictly preserving the target sparsity throughout the training phase. We
integrate ONG into the BIMP comparative framework and evaluate it on CIFAR-10
and CIFAR-100 with ResNet56, ResNet34, and ResNet18 against established stable
sparsification methods. Our experiments demonstrate ONG's ability to achieve
comparable or superior performance at various sparsity levels while maintaining
structural integrity post-pruning and offering a clear mechanism for targeting
desired sparsities.

</details>


### [126] [CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis](https://arxiv.org/abs/2508.12900)
*Jiayi Wang,Hadrien Reynaud,Franciskus Xaverius Erick,Bernhard Kainz*

Main category: cs.CV

TL;DR: CTFlow是一个基于临床报告生成完整3D CT体积的0.5B潜在流匹配变换器模型，在时间一致性、图像多样性和文本-图像对齐方面优于现有方法


<details>
  <summary>Details</summary>
Motivation: 通过临床报告生成完整CT体积可以加速医学研究，实现数据增强、隐私保护合成，并减少对患者数据的监管限制，同时保留诊断信号

Method: 使用FLUX的A-VAE定义潜在空间，CT-Clip文本编码器编码临床报告，采用自定义自回归方法生成一致的整个CT体积，先基于纯文本预测第一个切片序列，然后基于先前生成的切片序列和文本来预测后续序列

Result: 在FID、FVD、IS分数和CLIP分数评估中，该方法在时间一致性、图像多样性和文本-图像对齐方面优于最先进的生成CT模型

Conclusion: CTFlow展示了基于临床报告生成高质量3D CT体积的可行性，为医学影像数据增强和隐私保护提供了有效解决方案

Abstract: Generative modelling of entire CT volumes conditioned on clinical reports has
the potential to accelerate research through data augmentation,
privacy-preserving synthesis and reducing regulator-constraints on patient data
while preserving diagnostic signals. With the recent release of CT-RATE, a
large-scale collection of 3D CT volumes paired with their respective clinical
reports, training large text-conditioned CT volume generation models has become
achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching
transformer model, conditioned on clinical reports. We leverage the A-VAE from
FLUX to define our latent space, and rely on the CT-Clip text encoder to encode
the clinical reports. To generate consistent whole CT volumes while keeping the
memory constraints tractable, we rely on a custom autoregressive approach,
where the model predicts the first sequence of slices of the volume from
text-only, and then relies on the previously generated sequence of slices and
the text, to predict the following sequence. We evaluate our results against
state-of-the-art generative CT model, and demonstrate the superiority of our
approach in terms of temporal coherence, image diversity and text-image
alignment, with FID, FVD, IS scores and CLIP score.

</details>


### [127] [CMF-IoU: Multi-Stage Cross-Modal Fusion 3D Object Detection with IoU Joint Prediction](https://arxiv.org/abs/2508.12917)
*Zhiwei Ning,Zhaojiang Liu,Xuanang Gao,Yifan Zuo,Jie Yang,Yuming Fang,Wei Liu*

Main category: cs.CV

TL;DR: 一种多步骤跨模态融合的3D检测框架CMF-IOU，通过深度完整网络、双边跨视图增强、迭代立方体-点知觉精细池化等技术，有效解决3D空间与2D语义信息对齐挑战，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前多模态3D检测方法主要集中在单阶段或部分融合，导致特征提取不充分和性能不佳。需要一种能够有效对3D空间信息与2D语义信息进行对齐的多步骤融合方案。

Method: 1）使用深度完整网络将像素信息投影到3D空间获取伪点云，统一LiDAR和相机信息表示
2）设计双边跨视图增强3D背链：S2D分支使用编码器-解码器结构增强稀疏LiDAR点表示；ResVC分支通过3D和2D卷积过程减少不准确伪点影响
3）迭代立方体-点知觉精细池化模块，在建议精细阶段捕获LiDAR点的空间信息和伪点的纹理信息
4）设计集成新建议生成技术的IoU联合预测分支，保留既有高IoU又有高分类分数的边框

Result: 在KITTI、nuScenes和Waymo数据集上进行了大量实验，证明方法的优异性能。

Conclusion: CMF-IOU框架通过多步骤跨模态融合有效解决了3D空间与2D语义信息的对齐问题，在多个标准数据集上实现了超过现有方法的性能。

Abstract: Multi-modal methods based on camera and LiDAR sensors have garnered
significant attention in the field of 3D detection. However, many prevalent
works focus on single or partial stage fusion, leading to insufficient feature
extraction and suboptimal performance. In this paper, we introduce a
multi-stage cross-modal fusion 3D detection framework, termed CMF-IOU, to
effectively address the challenge of aligning 3D spatial and 2D semantic
information. Specifically, we first project the pixel information into 3D space
via a depth completion network to get the pseudo points, which unifies the
representation of the LiDAR and camera information. Then, a bilateral
cross-view enhancement 3D backbone is designed to encode LiDAR points and
pseudo points. The first sparse-to-distant (S2D) branch utilizes an
encoder-decoder structure to reinforce the representation of sparse LiDAR
points. The second residual view consistency (ResVC) branch is proposed to
mitigate the influence of inaccurate pseudo points via both the 3D and 2D
convolution processes. Subsequently, we introduce an iterative voxel-point
aware fine grained pooling module, which captures the spatial information from
LiDAR points and textural information from pseudo points in the proposal
refinement stage. To achieve more precise refinement during iteration, an
intersection over union (IoU) joint prediction branch integrated with a novel
proposals generation technique is designed to preserve the bounding boxes with
both high IoU and classification scores. Extensive experiments show the
superior performance of our method on the KITTI, nuScenes and Waymo datasets.

</details>


### [128] [7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models](https://arxiv.org/abs/2508.12919)
*Elena Izzo,Luca Parolari,Davide Vezzaro,Lamberto Ballan*

Main category: cs.CV

TL;DR: 7Bench是第一个同时评估布局引导文本到图像生成中语义和空间对齐的基准测试，包含7个挑战性场景，提出了包含布局对齐分数的评估协议。


<details>
  <summary>Details</summary>
Motivation: 现有基准只评估文本对齐而忽略了布局对齐，无法全面评估模型的空间保真度，这在合成数据生成等应用中至关重要。

Method: 创建包含7个挑战场景的文本-布局对数据集，提出结合布局对齐分数的评估协议来评估空间准确性。

Result: 使用7Bench评估了多个最先进的扩散模型，揭示了它们在不同对齐任务中的优势和局限性。

Conclusion: 7Bench填补了布局对齐评估的空白，为布局引导文本到图像生成提供了全面的评估框架，有助于提升合成数据质量。

Abstract: Layout-guided text-to-image models offer greater control over the generation
process by explicitly conditioning image synthesis on the spatial arrangement
of elements. As a result, their adoption has increased in many computer vision
applications, ranging from content creation to synthetic data generation. A
critical challenge is achieving precise alignment between the image, textual
prompt, and layout, ensuring semantic fidelity and spatial accuracy. Although
recent benchmarks assess text alignment, layout alignment remains overlooked,
and no existing benchmark jointly evaluates both. This gap limits the ability
to evaluate a model's spatial fidelity, which is crucial when using
layout-guided generation for synthetic data, as errors can introduce noise and
degrade data quality. In this work, we introduce 7Bench, the first benchmark to
assess both semantic and spatial alignment in layout-guided text-to-image
generation. It features text-and-layout pairs spanning seven challenging
scenarios, investigating object generation, color fidelity, attribute
recognition, inter-object relationships, and spatial control. We propose an
evaluation protocol that builds on existing frameworks by incorporating the
layout alignment score to assess spatial accuracy. Using 7Bench, we evaluate
several state-of-the-art diffusion models, uncovering their respective
strengths and limitations across diverse alignment tasks. The benchmark is
available at https://github.com/Elizzo/7Bench.

</details>


### [129] [Towards High-Resolution Industrial Image Anomaly Detection](https://arxiv.org/abs/2508.12931)
*Ximiao Zhang,Min Xu,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: HiAD是一个针对高分辨率图像异常检测的通用框架，通过双分支架构和多分辨率特征融合策略，有效检测不同大小的异常区域，在计算资源有限的情况下实现高精度检测。


<details>
  <summary>Details</summary>
Motivation: 当前异常检测方法主要针对低分辨率场景，高分辨率图像的传统下采样会导致细粒度判别信息丢失，造成细微异常区域漏检。现有方法在检测精度和效率方面难以满足工业场景实际需求。

Method: 采用双分支架构整合不同尺度的异常线索，全面捕捉细微和大规模异常；使用多分辨率特征融合策略处理高分辨率图像的细粒度纹理变化；通过检测器池和多种检测器分配策略，根据图像块特征自适应分配检测器，在保证性能的同时控制计算成本。

Result: 在专门构建的高分辨率异常检测基准测试（MVTec-HD、VisA-HD和RealIAD-HD）上进行了广泛实验，证明了HiAD的优越性能。

Conclusion: HiAD框架能够有效解决高分辨率图像异常检测的挑战，在检测精度和计算效率方面都表现出色，适用于工业实际应用场景。

Abstract: Current anomaly detection methods primarily focus on low-resolution
scenarios. For high-resolution images, conventional downsampling often results
in missed detections of subtle anomalous regions due to the loss of
fine-grained discriminative information. Despite some progress, recent studies
have attempted to improve detection resolution by employing lightweight
networks or using simple image tiling and ensemble methods. However, these
approaches still struggle to meet the practical demands of industrial scenarios
in terms of detection accuracy and efficiency. To address the above issues, we
propose HiAD, a general framework for high-resolution anomaly detection. HiAD
is capable of detecting anomalous regions of varying sizes in high-resolution
images under limited computational resources. Specifically, HiAD employs a
dual-branch architecture that integrates anomaly cues across different scales
to comprehensively capture both subtle and large-scale anomalies. Furthermore,
it incorporates a multi-resolution feature fusion strategy to tackle the
challenges posed by fine-grained texture variations in high-resolution images.
To enhance both adaptability and efficiency, HiAD utilizes a detector pool in
conjunction with various detector assignment strategies, enabling detectors to
be adaptively assigned based on patch features, ensuring detection performance
while effectively controlling computational costs. We conduct extensive
experiments on our specifically constructed high-resolution anomaly detection
benchmarks, including MVTec-HD, VisA-HD, and the real-world benchmark
RealIAD-HD, demonstrating the superior performance of HiAD. The code is
available at https://github.com/cnulab/HiAD.

</details>


### [130] [SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory](https://arxiv.org/abs/2508.12932)
*Hongyang Chen,Shaoling Pu,Lingyu Zheng,Zhongwu Sun*

Main category: cs.CV

TL;DR: SEDEG是一个两阶段训练框架，通过提升编码器和解码器的泛化能力来解决增量学习中的灾难性遗忘问题，特别在小内存场景下表现优异


<details>
  <summary>Details</summary>
Motivation: 现有增量学习方法通常只关注编码器或解码器中的一个组件，限制了缓解灾难性遗忘的效果，特别是在小内存场景下性能更差

Method: 采用两阶段训练：第一阶段通过特征增强训练集成编码器学习泛化表示，提升解码器泛化能力；第二阶段使用知识蒸馏策略压缩集成编码器，开发新的泛化编码器

Result: 在三个基准数据集上的广泛实验显示SEDEG具有优越性能，消融研究确认了各组件有效性

Conclusion: SEDEG通过顺序提升编码器和解码器的泛化能力，有效缓解了增量学习中的灾难性遗忘问题，特别在小内存场景下表现突出

Abstract: In incremental learning, enhancing the generality of knowledge is crucial for
adapting to dynamic data inputs. It can develop generalized representations or
more balanced decision boundaries, preventing the degradation of long-term
knowledge over time and thus mitigating catastrophic forgetting. Some emerging
incremental learning methods adopt an encoder-decoder architecture and have
achieved promising results. In the encoder-decoder achitecture, improving the
generalization capabilities of both the encoder and decoder is critical, as it
helps preserve previously learned knowledge while ensuring adaptability and
robustness to new, diverse data inputs. However, many existing continual
methods focus solely on enhancing one of the two components, which limits their
effectiveness in mitigating catastrophic forgetting. And these methods perform
even worse in small-memory scenarios, where only a limited number of historical
samples can be stored. To mitigate this limitation, we introduces SEDEG, a
two-stage training framework for vision transformers (ViT), focusing on
sequentially improving the generality of both Decoder and Encoder. Initially,
SEDEG trains an ensembled encoder through feature boosting to learn generalized
representations, which subsequently enhance the decoder's generality and
balance the classifier. The next stage involves using knowledge distillation
(KD) strategies to compress the ensembled encoder and develop a new, more
generalized encoder. This involves using a balanced KD approach and feature KD
for effective knowledge transfer. Extensive experiments on three benchmark
datasets show SEDEG's superior performance, and ablation studies confirm the
efficacy of its components. The code is available at
https://github.com/ShaolingPu/CIL.

</details>


### [131] [Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data](https://arxiv.org/abs/2508.12942)
*Kyriaki-Margarita Bintsi,Yaël Balbastre,Jingjing Wu,Julia F. Lehman,Suzanne N. Haber,Anastasia Yendiki*

Main category: cs.CV

TL;DR: 基于U-Net结构的全自动化框架，通过大补丁尺寸、前景感知采样和半监督预训练，显著提高鸦尾植物数据中纤维束分割的准确性，减少误检并支持单独切片分析。


<details>
  <summary>Details</summary>
Motivation: 解决传统手工注释组织切片中纤维束的劳动密集问题，充分利用解剖追踪剂研究数据来验证和改进滿散磁共振成像拓扑技术。

Method: 采用U-Net网络结构，结合大补丁尺寸、前景感知采样策略和半监督预训练技术，实现对空鹿解剖追踪剂数据的全自动纤维束分割。

Result: 稀疏纤维束检测提高20%以上，假发现率降低40%，避免了将终端误标为束组的常见错误，同时支持单独切片分析。

Conclusion: 该框架能大规模自动分析解剖追踪剂数据，为滿散磁共振成像拓扑技术提供更多的真实地面数据，有助于验证和优化相关算法。

Abstract: Anatomic tracer studies are critical for validating and improving diffusion
MRI (dMRI) tractography. However, large-scale analysis of data from such
studies is hampered by the labor-intensive process of annotating fiber bundles
manually on histological slides. Existing automated methods often miss sparse
bundles or require complex post-processing across consecutive sections,
limiting their flexibility and generalizability. We present a streamlined,
fully automated framework for fiber bundle segmentation in macaque tracer data,
based on a U-Net architecture with large patch sizes, foreground aware
sampling, and semisupervised pre-training. Our approach eliminates common
errors such as mislabeling terminals as bundles, improves detection of sparse
bundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared
to the state-of-the-art, all while enabling analysis of standalone slices. This
new framework will facilitate the automated analysis of anatomic tracing data
at a large scale, generating more ground-truth data that can be used to
validate and optimize dMRI tractography methods.

</details>


### [132] [Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models](https://arxiv.org/abs/2508.12945)
*Jianshu Zeng,Yuxuan Liu,Yutong Feng,Chenxuan Miao,Zixiang Gao,Jiwang Qu,Jianzhang Zhang,Bin Wang,Kun Yuan*

Main category: cs.CV

TL;DR: Lumen是一个端到端的视频重照明框架，基于大规模视频生成模型，通过文本描述控制光照和背景，在保持前景一致性的同时实现和谐的视频重照明效果。


<details>
  <summary>Details</summary>
Motivation: 视频重照明是一个具有挑战性但有价值的任务，需要在替换视频背景的同时相应调整前景光照并实现和谐融合。现有方法缺乏高质量的多光照条件配对视频数据，且难以保持前景原始属性和时间一致性。

Method: 构建混合真实和合成视频的大规模数据集；使用3D渲染引擎生成合成视频对，采用HDR光照模拟补充真实视频；设计联合训练课程，注入域感知适配器来解耦重照明和域外观分布的学习。

Result: 实验结果表明，Lumen能够有效地将输入编辑为具有一致光照和严格前景保持的电影级重照明视频，在前景保持和视频一致性评估方面表现优异。

Conclusion: Lumen框架通过大规模混合数据集和域感知适配器设计，成功解决了视频重照明中的前景保持和时间一致性问题，为视频编辑提供了有效的解决方案。

Abstract: Video relighting is a challenging yet valuable task, aiming to replace the
background in videos while correspondingly adjusting the lighting in the
foreground with harmonious blending. During translation, it is essential to
preserve the original properties of the foreground, e.g., albedo, and propagate
consistent relighting among temporal frames. In this paper, we propose Lumen,
an end-to-end video relighting framework developed on large-scale video
generative models, receiving flexible textual description for instructing the
control of lighting and background. Considering the scarcity of high-qualified
paired videos with the same foreground in various lighting conditions, we
construct a large-scale dataset with a mixture of realistic and synthetic
videos. For the synthetic domain, benefiting from the abundant 3D assets in the
community, we leverage advanced 3D rendering engine to curate video pairs in
diverse environments. For the realistic domain, we adapt a HDR-based lighting
simulation to complement the lack of paired in-the-wild videos. Powered by the
aforementioned dataset, we design a joint training curriculum to effectively
unleash the strengths of each domain, i.e., the physical consistency in
synthetic videos, and the generalized domain distribution in realistic videos.
To implement this, we inject a domain-aware adapter into the model to decouple
the learning of relighting and domain appearance distribution. We construct a
comprehensive benchmark to evaluate Lumen together with existing methods, from
the perspectives of foreground preservation and video consistency assessment.
Experimental results demonstrate that Lumen effectively edit the input into
cinematic relighted videos with consistent lighting and strict foreground
preservation. Our project page: https://lumen-relight.github.io/

</details>


### [133] [MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation](https://arxiv.org/abs/2508.12948)
*Wei Wei,Shaojie Zhang,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: MaskSem是一种新颖的语义引导掩码方法，通过Grad-CAM指导关节掩码和混合高阶运动重建目标，提升了自监督骨架动作识别的性能


<details>
  <summary>Details</summary>
Motivation: 现有自监督骨架动作识别方法仅关注有限关节和低阶运动模式，限制了模型对复杂运动模式的理解能力

Method: 提出语义引导掩码方法，基于相对运动的Grad-CAM指导掩码最具语义丰富性的时间区域；使用混合高阶运动（速度+加速度）作为重建目标

Result: 在NTU60、NTU120和PKU-MMD数据集上的实验表明，MaskSem结合普通transformer提升了骨架动作识别性能

Conclusion: 该方法能更好地理解运动模式，更适合人机交互应用

Abstract: Human action recognition is a crucial task for intelligent robotics,
particularly within the context of human-robot collaboration research. In
self-supervised skeleton-based action recognition, the mask-based
reconstruction paradigm learns the spatial structure and motion patterns of the
skeleton by masking joints and reconstructing the target from unlabeled data.
However, existing methods focus on a limited set of joints and low-order motion
patterns, limiting the model's ability to understand complex motion patterns.
To address this issue, we introduce MaskSem, a novel semantic-guided masking
method for learning 3D hybrid high-order motion representations. This novel
framework leverages Grad-CAM based on relative motion to guide the masking of
joints, which can be represented as the most semantically rich temporal
orgions. The semantic-guided masking process can encourage the model to explore
more discriminative features. Furthermore, we propose using hybrid high-order
motion as the reconstruction target, enabling the model to learn multi-order
motion patterns. Specifically, low-order motion velocity and high-order motion
acceleration are used together as the reconstruction target. This approach
offers a more comprehensive description of the dynamic motion process,
enhancing the model's understanding of motion patterns. Experiments on the
NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla
transformer, improves skeleton-based action recognition, making it more
suitable for applications in human-robot interaction.

</details>


### [134] [Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination](https://arxiv.org/abs/2508.12957)
*Yizhou Liu,Jingwei Wei,Zizhi Chen,Minghao Han,Xukun Zhang,Keliang Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: ARMed是一个用于开放式医学视觉问答的强化学习框架，通过结合领域知识和自适应语义奖励来提升医学推理质量，在多个基准测试中显著提升了准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的强化微调方法主要针对封闭式医学视觉问答，限制了在真实临床推理中的应用。开放式医学VQA更能反映临床实践但研究较少，且基于模型的语义奖励存在奖励崩溃问题。

Method: ARMed框架首先通过监督微调在思维链数据上融入领域知识，然后应用强化学习结合文本正确性和自适应语义奖励来增强推理质量。

Result: 在六个医学VQA基准测试中，ARMed在域内任务上提升32.64%，在域外基准上提升11.65%，显著提高了准确性和泛化能力。

Conclusion: 研究强调了奖励可区分性在医学强化学习中的关键作用，以及语义引导奖励在实现稳健且具有临床意义的多模态推理方面的潜力。

Abstract: Reinforcement learning (RL) with rule-based rewards has demonstrated strong
potential in enhancing the reasoning and generalization capabilities of
vision-language models (VLMs) and large language models (LLMs), while reducing
computational overhead. However, its application in medical imaging remains
underexplored. Existing reinforcement fine-tuning (RFT) approaches in this
domain primarily target closed-ended visual question answering (VQA), limiting
their applicability to real-world clinical reasoning. In contrast, open-ended
medical VQA better reflects clinical practice but has received limited
attention. While some efforts have sought to unify both formats via
semantically guided RL, we observe that model-based semantic rewards often
suffer from reward collapse, where responses with significant semantic
differences receive similar scores. To address this, we propose ARMed (Adaptive
Reinforcement for Medical Reasoning), a novel RL framework for open-ended
medical VQA. ARMed first incorporates domain knowledge through supervised
fine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning
with textual correctness and adaptive semantic rewards to enhance reasoning
quality. We evaluate ARMed on six challenging medical VQA benchmarks. Results
show that ARMed consistently boosts both accuracy and generalization, achieving
a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain
benchmarks. These results highlight the critical role of reward
discriminability in medical RL and the promise of semantically guided rewards
for enabling robust and clinically meaningful multimodal reasoning.

</details>


### [135] [Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation](https://arxiv.org/abs/2508.12962)
*Dominic LaBella,Keshav Jha,Jared Robbins,Esther Yu*

Main category: cs.CV

TL;DR: DLaBella29团队在MICCAI 2025 ToothFairy3挑战赛中提出基于3D SegResNet的深度学习管道，用于CBCT牙齿多类别分割，在验证集上达到平均Dice系数0.87


<details>
  <summary>Details</summary>
Motivation: 自动化CBCT牙齿结构分割有助于识别病理（如牙髓或根尖周病变）并促进头颈癌患者的放射治疗规划，提高患者护理质量

Method: 使用MONAI Auto3DSeg框架和3D SegResNet架构，采用5折交叉验证训练，关键预处理包括图像重采样和强度裁剪，应用多标签STAPLE集成融合进行两阶段分割

Result: 在ToothFairy3挑战赛的样本外验证集上取得了平均Dice系数0.87的优异表现

Conclusion: 该方法展示了自动化牙齿分割在放射肿瘤学中的临床价值，为改善患者护理提供了有效的技术解决方案

Abstract: Cone-beam computed tomography (CBCT) has become an invaluable imaging
modality in dentistry, enabling 3D visualization of teeth and surrounding
structures for diagnosis and treatment planning. Automated segmentation of
dental structures in CBCT can efficiently assist in identifying pathology
(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning
in head and neck cancer patients. We describe the DLaBella29 team's approach
for the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning
pipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg
framework with a 3D SegResNet architecture, trained on a subset of the
ToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key
preprocessing steps included image resampling to 0.6 mm isotropic resolution
and intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE
on the 5-fold predictions to infer a Phase 1 segmentation and then conducted
tight cropping around the easily segmented Phase 1 mandible to perform Phase 2
segmentation on the smaller nerve structures. Our method achieved an average
Dice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This
paper details the clinical context, data preparation, model development,
results of our approach, and discusses the relevance of automated dental
segmentation for improving patient care in radiation oncology.

</details>


### [136] [GazeDETR: Gaze Detection using Disentangled Head and Gaze Representations](https://arxiv.org/abs/2508.12966)
*Ryan Anthony Jalova de Belen,Gelareh Mohammadi,Arcot Sowmya*

Main category: cs.CV

TL;DR: GazeDETR是一种新颖的端到端架构，使用两个解耦的解码器分别处理头部定位和视线预测任务，在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端视线目标检测模型使用单一解码器同时定位人头部和预测视线，导致表示纠缠。需要解耦这两个任务以获得更好的性能。

Method: 提出GazeDETR架构，包含两个独立的解码器：一个用于头部定位（使用局部信息），另一个用于视线预测（结合局部和全局信息），利用连贯注意力场。

Result: 在GazeFollow、VideoAttentionTarget和ChildPlay数据集上达到最先进结果，显著优于现有端到端模型。

Conclusion: 解耦的架构设计能够为每个子任务学习独特的表示，证明了头部预测器使用局部信息而视线解码器需要结合局部和全局信息的有效性。

Abstract: Gaze communication plays a crucial role in daily social interactions.
Quantifying this behavior can help in human-computer interaction and digital
phenotyping. While end-to-end models exist for gaze target detection, they only
utilize a single decoder to simultaneously localize human heads and predict
their corresponding gaze (e.g., 2D points or heatmap) in a scene. This
multitask learning approach generates a unified and entangled representation
for human head localization and gaze location prediction. Herein, we propose
GazeDETR, a novel end-to-end architecture with two disentangled decoders that
individually learn unique representations and effectively utilize coherent
attentive fields for each subtask. More specifically, we demonstrate that its
human head predictor utilizes local information, while its gaze decoder
incorporates both local and global information. Our proposed architecture
achieves state-of-the-art results on the GazeFollow, VideoAttentionTarget and
ChildPlay datasets. It outperforms existing end-to-end models with a notable
margin.

</details>


### [137] [Compact Attention: Exploiting Structured Spatio-Temporal Sparsity for Fast Video Generation](https://arxiv.org/abs/2508.12969)
*Qirui Li,Guangcong Zheng,Qi Zhao,Jie Li,Bin Dong,Yiwu Yao,Xi Li*

Main category: cs.CV

TL;DR: 通过分析视频波散Transformer的注意力矩阵结构，发现其存在异质性稀疏模式，提出Compact Attention加速框架，通过自适应分块策略和时变窗口等技术，实现1.6~2.5倍注意力计算加速而保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制的计算开销到制了变换器基视频生成的性能，尤其是在生成超长序列时。现有的因子化注意力和固定稀疏模式方法无法充分利用视频数据的内在时空冗余性。

Method: 提出Compact Attention加速框架，包括：1)自适应分块策略，通过动态分组近似多样化空间交互模式；2)时变窗口，根据帧距离调整稀疏程度；3)自动化配置搜索算法，在保留关键注意力通道的同时优化稀疏模式。

Result: 在单GPU环境下，注意力计算获得1.6~2.5倍加速，同时保持了与全注意力基准线相当的视觉质量。

Conclusion: 该方法为通过结构化稀疏利用开启高效长形式视频生成提供了有理论基础的解决方案。

Abstract: The computational demands of self-attention mechanisms pose a critical
challenge for transformer-based video generation, particularly in synthesizing
ultra-long sequences. Current approaches, such as factorized attention and
fixed sparse patterns, fail to fully exploit the inherent spatio-temporal
redundancies in video data. Through systematic analysis of video diffusion
transformers (DiT), we uncover a key insight: Attention matrices exhibit
structured, yet heterogeneous sparsity patterns, where specialized heads
dynamically attend to distinct spatiotemporal regions (e.g., local pattern,
cross-shaped pattern, or global pattern). Existing sparse attention methods
either impose rigid constraints or introduce significant overhead, limiting
their effectiveness. To address this, we propose Compact Attention, a
hardware-aware acceleration framework featuring three innovations: 1) Adaptive
tiling strategies that approximate diverse spatial interaction patterns via
dynamic tile grouping, 2) Temporally varying windows that adjust sparsity
levels based on frame proximity, and 3) An automated configuration search
algorithm that optimizes sparse patterns while preserving critical attention
pathways. Our method achieves 1.6~2.5x acceleration in attention computation on
single-GPU setups while maintaining comparable visual quality with
full-attention baselines. This work provides a principled approach to unlocking
efficient long-form video generation through structured sparsity exploitation.
Project Page: https://yo-ava.github.io/Compact-Attention.github.io/

</details>


### [138] [Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature](https://arxiv.org/abs/2508.12977)
*Rohan Asthana,Joschua Conrad,Maurits Ortmanns,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 一种无需标签数据的零成本线性代理方法，通过统一考虑收敛性、普遍性和表达能力来预测神经网络性能


<details>
  <summary>Details</summary>
Motivation: 现有的零成本代理方法常常依赖标签数据，且要么只关注收敛性和普遍性，要么只关注表达能力，需要一种统一考虑这三者的方法

Method: 利用神经网络层特征的奇异值分解(SVD)和网络输出的外在曲率来设计代理，通过逆条件数和外在曲率对数的简化调和平均来形成代理

Result: 在多个相关性测试中表现优异，包括NAS-Bench-101、NAS-Bench-201、TransNAS-Bench-101-micro等，同时在DARTS和AutoFormer搜索空间中也显示出良好性能，且计算效玉高

Conclusion: 该方法能够仅使用单个无标签数据样本准确预测网络性能，解决了对标签数据的依赖问题，为零成本神经网络架构搜索提供了一种高效的新方法

Abstract: Zero-shot Neural Architecture Search (NAS) typically optimises the
architecture search process by exploiting the network or gradient properties at
initialisation through zero-cost proxies. The existing proxies often rely on
labelled data, which is usually unavailable in real-world settings.
Furthermore, the majority of the current methods focus either on optimising the
convergence and generalisation attributes or solely on the expressivity of the
network architectures. To address both limitations, we first demonstrate how
channel collinearity affects the convergence and generalisation properties of a
neural network. Then, by incorporating the convergence, generalisation and
expressivity in one approach, we propose a zero-cost proxy that omits the
requirement of labelled data for its computation. In particular, we leverage
the Singular Value Decomposition (SVD) of the neural network layer features and
the extrinsic curvature of the network output to design our proxy. %As a
result, the proposed proxy is formulated as the simplified harmonic mean of the
logarithms of two key components: the sum of the inverse of the feature
condition number and the extrinsic curvature of the network output. Our
approach enables accurate prediction of network performance on test data using
only a single label-free data sample. Our extensive evaluation includes a total
of six experiments, including the Convolutional Neural Network (CNN) search
space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The
proposed proxy demonstrates a superior performance on multiple correlation
benchmarks, including NAS-Bench-101, NAS-Bench-201, and
TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the
AutoFormer search space, all while being notably efficient. The code is
available at https://github.com/rohanasthana/Dextr.

</details>


### [139] [Omni Survey for Multimodality Analysis in Visual Object Tracking](https://arxiv.org/abs/2508.13000)
*Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Hui Li,Shaochuan Zhao,Tao Zhou,Chunyang Cheng,Xiaojun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 本文是一份关于多模态视觉目标跟踪(MMVOT)的综述性论文，从数据采集、模态对齐、模型设计和评估四个关键方面全面分析了该领域的研究状况、挑战和方法。


<details>
  <summary>Details</summary>
Motivation: 智慧城市发展产生了大量多模态数据，多模态视觉目标跟踪作为关键任务需要系统性的研究综述以指导未来发展。

Method: 将现有MMVOT方法按照处理可见光(RGB)和其他模态(X)的不同方式进行分类：使用复制或非复制实验配置编程辅助X分支，其中X包括热红外(T)、深度(D)、事件(E)等多种模态。

Result: 本文完成了对六个MMVOT任务的全面调查，包含总计338个参考文献，首次分析了现有MMVOT数据集中对象类别的分布，发现其显著的长尾特性和动物类别的显著缺失。

Conclusion: 多模态跟踪并非总是比单模态跟踪更优，本文讨论了其应用的利比条件，为该领域提供了系统性的研究基础和未来发展方向。

Abstract: The development of smart cities has led to the generation of massive amounts
of multi-modal data in the context of a range of tasks that enable a
comprehensive monitoring of the smart city infrastructure and services. This
paper surveys one of the most critical tasks, multi-modal visual object
tracking (MMVOT), from the perspective of multimodality analysis. Generally,
MMVOT differs from single-modal tracking in four key aspects, data collection,
modality alignment and annotation, model designing, and evaluation.
Accordingly, we begin with an introduction to the relevant data modalities,
laying the groundwork for their integration. This naturally leads to a
discussion of challenges of multi-modal data collection, alignment, and
annotation. Subsequently, existing MMVOT methods are categorised, based on
different ways to deal with visible (RGB) and X modalities: programming the
auxiliary X branch with replicated or non-replicated experimental
configurations from the RGB branch. Here X can be thermal infrared (T), depth
(D), event (E), near infrared (NIR), language (L), or sonar (S). The final part
of the paper addresses evaluation and benchmarking. In summary, we undertake an
omni survey of all aspects of multi-modal visual object tracking (VOT),
covering six MMVOT tasks and featuring 338 references in total. In addition, we
discuss the fundamental rhetorical question: Is multi-modal tracking always
guaranteed to provide a superior solution to unimodal tracking with the help of
information fusion, and if not, in what circumstances its application is
beneficial. Furthermore, for the first time in this field, we analyse the
distributions of the object categories in the existing MMVOT datasets,
revealing their pronounced long-tail nature and a noticeable lack of animal
categories when compared with RGB datasets.

</details>


### [140] [Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning](https://arxiv.org/abs/2508.13005)
*Jiawen Xu,Odej Kao*

Main category: cs.CV

TL;DR: 增强特征多样性可以同时改善开放集识别和持续学习性能


<details>
  <summary>Details</summary>
Motivation: 虽然许多方法通过启发式方式促进特征多样性来解决开放集识别和持续学习问题，但很少有研究直接探讨特征多样性在这些问题中的具体作用

Method: 通过实证研究分析特征多样性对开放集样本识别的影响，以及在持续学习中保留旧知识和整合新知识的作用

Result: 增强特征多样性确实能提高开放集样本的识别能力，同时也有利于持续学习中旧知识的保留和新知识的整合

Conclusion: 特征多样性在开放集识别和持续学习中扮演重要角色，这一发现可为这两个领域的实践方法和理论理解提供新的研究方向

Abstract: Open set recognition (OSR) and continual learning are two critical challenges
in machine learning, focusing respectively on detecting novel classes at
inference time and updating models to incorporate the new classes. While many
recent approaches have addressed these problems, particularly OSR, by
heuristically promoting feature diversity, few studies have directly examined
the role that feature diversity plays in tackling them. In this work, we
provide empirical evidence that enhancing feature diversity improves the
recognition of open set samples. Moreover, increased feature diversity also
facilitates both the retention of previously learned data and the integration
of new data in continual learning. We hope our findings can inspire further
research into both practical methods and theoretical understanding in these
domains.

</details>


### [141] [SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient Cooperative 3-D Perception](https://arxiv.org/abs/2508.13007)
*Melih Yazgan,Qiyuan Wu,Iramm Hamdard,Shiqi Li,J. Marius Zoellner*

Main category: cs.CV

TL;DR: SlimComm是一个通信高效的协作感知框架，通过整合4D雷达多普勒信息和查询驱动的稀疏方案，大幅降低车联网通信带宽需求，同时保持感知精度。


<details>
  <summary>Details</summary>
Motivation: 协作感知中传输密集的鸟瞰图特征会严重占用车联网通信带宽，需要开发更高效的通信方案来解决这一瓶颈问题。

Method: 构建运动中心动态地图区分动静物体，生成参考查询和探索查询两种查询类型，仅交换查询相关的BEV特征，通过多尺度门控可变形注意力进行特征融合。

Result: 相比全图共享方法，带宽降低高达90%，在不同交通密度和遮挡条件下达到或超越现有基准方法的性能。

Conclusion: SlimComm成功解决了协作感知中的通信瓶颈问题，通过智能查询机制和特征选择实现了高效的通信效率与感知精度的平衡。

Abstract: Collaborative perception allows connected autonomous vehicles (CAVs) to
overcome occlusion and limited sensor range by sharing intermediate features.
Yet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the
bandwidth available for inter-vehicle communication. We present SlimComm, a
communication-efficient framework that integrates 4D radar Doppler with a
query-driven sparse scheme. SlimComm builds a motion-centric dynamic map to
distinguish moving from static objects and generates two query types: (i)
reference queries on dynamic and high-confidence regions, and (ii) exploratory
queries probing occluded areas via a two-stage offset. Only query-specific BEV
features are exchanged and fused through multi-scale gated deformable
attention, reducing payload while preserving accuracy. For evaluation, we
release OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler
radar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while
matching or surpassing prior baselines across varied traffic densities and
occlusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.

</details>


### [142] [Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model](https://arxiv.org/abs/2508.13009)
*Xianglong He,Chunli Peng,Zexiang Liu,Boyang Wang,Yifan Zhang,Qi Cui,Fei Kang,Biao Jiang,Mengyin An,Yangyang Ren,Baixin Xu,Hao-Xiang Guo,Kaixiong Gong,Cyrus Wu,Wei Li,Xuchen Song,Yang Liu,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-Game 2.0是一个实时交互式世界模型，通过少步自回归扩散生成高质量长视频，速度达到25FPS，解决了现有模型实时性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有交互式世界模型依赖双向注意力和冗长推理步骤，严重限制实时性能，难以模拟需要即时更新的真实世界动态。

Method: 包含三个关键组件：(1)可扩展的数据生产流水线，从Unreal Engine和GTA5环境生成约1200小时带交互标注的视频数据；(2)动作注入模块，支持帧级鼠标键盘输入作为交互条件；(3)基于因果架构的少步蒸馏，实现实时流式视频生成。

Result: 能够以25FPS的超快速度生成高质量分钟级视频，覆盖多样化场景。

Conclusion: Matrix-Game 2.0显著提升了交互式世界模型的实时性能，开源模型权重和代码库以推动该领域研究。

Abstract: Recent advances in interactive video generations have demonstrated diffusion
model's potential as world models by capturing complex physical dynamics and
interactive behaviors. However, existing interactive world models depend on
bidirectional attention and lengthy inference steps, severely limiting
real-time performance. Consequently, they are hard to simulate real-world
dynamics, where outcomes must update instantaneously based on historical
context and current actions. To address this, we present Matrix-Game 2.0, an
interactive world model generates long videos on-the-fly via few-step
auto-regressive diffusion. Our framework consists of three key components: (1)
A scalable data production pipeline for Unreal Engine and GTA5 environments to
effectively produce massive amounts (about 1200 hours) of video data with
diverse interaction annotations; (2) An action injection module that enables
frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step
distillation based on the casual architecture for real-time and streaming video
generation. Matrix Game 2.0 can generate high-quality minute-level videos
across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our
model weights and codebase to advance research in interactive world modeling.

</details>


### [143] [EgoTwin: Dreaming Body and View in First Person](https://arxiv.org/abs/2508.13013)
*Jingqiao Xiu,Fangzhou Hong,Yicong Li,Mengze Li,Wentao Wang,Sirui Han,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出了EgoTwin框架，用于联合生成第一人称视角视频和人体运动，解决了视角对齐和因果交互两大挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然外中心视角视频合成取得了很大进展，但第一人称视角视频生成仍然很少被探索，需要同时建模第一人称视角内容和穿戴者身体运动引起的相机运动模式。

Method: 提出了EgoTwin框架，基于扩散transformer架构，引入头部中心运动表示将人体运动锚定到头部关节，并采用控制论启发的交互机制在注意力操作中显式捕捉视频与运动之间的因果交互。

Result: 构建了大规模真实世界的同步文本-视频-运动三元组数据集，设计了新颖的指标来评估视频-运动一致性，大量实验证明了EgoTwin框架的有效性。

Conclusion: EgoTwin框架成功解决了第一人称视频和人体运动联合生成的关键挑战，为这一新兴领域提供了有效的解决方案。

Abstract: While exocentric video synthesis has achieved great progress, egocentric
video generation remains largely underexplored, which requires modeling
first-person view content along with camera motion patterns induced by the
wearer's body movements. To bridge this gap, we introduce a novel task of joint
egocentric video and human motion generation, characterized by two key
challenges: 1) Viewpoint Alignment: the camera trajectory in the generated
video must accurately align with the head trajectory derived from human motion;
2) Causal Interplay: the synthesized human motion must causally align with the
observed visual dynamics across adjacent video frames. To address these
challenges, we propose EgoTwin, a joint video-motion generation framework built
on the diffusion transformer architecture. Specifically, EgoTwin introduces a
head-centric motion representation that anchors the human motion to the head
joint and incorporates a cybernetics-inspired interaction mechanism that
explicitly captures the causal interplay between video and motion within
attention operations. For comprehensive evaluation, we curate a large-scale
real-world dataset of synchronized text-video-motion triplets and design novel
metrics to assess video-motion consistency. Extensive experiments demonstrate
the effectiveness of the EgoTwin framework.

</details>


### [144] [HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical Feature Adapters](https://arxiv.org/abs/2508.13026)
*Ruru Xu,Ilkay Oksuz*

Main category: cs.CV

TL;DR: HierAdaptMR是一个分层特征适应框架，通过参数高效适配器解决多中心心脏MRI重建中的域偏移问题，在CMRxRecon2025数据集上展现出优异的跨中心泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习心脏MRI重建在不同临床中心的异构扫描仪配置和成像协议下面临显著的域偏移挑战，需要解决多级域变化问题。

Method: 采用分层特征适应框架，包含协议级适配器处理序列特定特征、中心级适配器处理扫描仪相关变化，基于变分展开骨干网络，使用通用适配器通过随机训练实现未见中心的泛化，采用多尺度SSIM损失和频域增强优化。

Result: 在CMRxRecon2025数据集（5+中心、10+扫描仪、9种模态）上的综合评估显示，该方法在保持重建质量的同时实现了优异的跨中心泛化性能。

Conclusion: HierAdaptMR通过分层适配器设计有效解决了多中心心脏MRI重建的域偏移问题，为临床部署提供了可靠的解决方案。

Abstract: Deep learning-based cardiac MRI reconstruction faces significant domain shift
challenges when deployed across multiple clinical centers with heterogeneous
scanner configurations and imaging protocols. We propose HierAdaptMR, a
hierarchical feature adaptation framework that addresses multi-level domain
variations through parameter-efficient adapters. Our method employs
Protocol-Level Adapters for sequence-specific characteristics and Center-Level
Adapters for scanner-dependent variations, built upon a variational unrolling
backbone. A Universal Adapter enables generalization to entirely unseen centers
through stochastic training that learns center-invariant adaptations. The
framework utilizes multi-scale SSIM loss with frequency domain enhancement and
contrast-adaptive weighting for robust optimization. Comprehensive evaluation
on the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9
modalities demonstrates superior cross-center generalization while maintaining
reconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR

</details>


### [145] [Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation](https://arxiv.org/abs/2508.13068)
*Tanjim Islam Riju,Shuchismita Anwar,Saman Sarker Joy,Farig Sadeque,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 提出一个两阶段多模态框架，通过整合放射科医生眼动追踪数据，提升胸部X光片的疾病分类性能和区域感知的放射学报告生成质量。


<details>
  <summary>Details</summary>
Motivation: 利用放射科医生的眼动数据（注视点）来改进医学影像分析，因为专家的视觉注意力模式包含了重要的诊断信息，可以提升疾病分类准确性和生成报告的可解释性。

Method: 第一阶段：使用注视引导的对比学习架构进行疾病分类，整合视觉特征、临床标签、边界框和眼动信号，采用多术语注视注意力损失函数（MSE、KL散度、相关性和质心对齐）。第二阶段：模块化报告生成流程，提取置信度加权的诊断关键词，通过领域特定词典映射到解剖区域，使用结构化提示生成区域对齐的句子。

Result: 整合注视数据后，F1分数从0.597提升到0.631（+5.70%），AUC从0.821提升到0.849（+3.41%），精确率和召回率均有改善。报告生成质量在临床关键词召回率和ROUGE重叠度方面得到提升。

Conclusion: 眼动数据的整合显著提高了疾病分类性能，同时增强了生成医学报告的可解释性，证明了专家视觉注意力模式在医学影像分析中的价值。

Abstract: We propose a two-stage multimodal framework that enhances disease
classification and region-aware radiology report generation from chest X-rays,
leveraging the MIMIC-Eye dataset. In the first stage, we introduce a
gaze-guided contrastive learning architecture for disease classification. It
integrates visual features, clinical labels, bounding boxes, and radiologist
eye-tracking signals and is equipped with a novel multi-term gaze-attention
loss combining MSE, KL divergence, correlation, and center-of-mass alignment.
Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC
from 0.821 to 0.849 (+3.41%), while also improving precision and recall,
highlighting the effectiveness of gaze-informed attention supervision. In the
second stage, we present a modular report generation pipeline that extracts
confidence-weighted diagnostic keywords, maps them to anatomical regions using
a curated dictionary constructed from domain-specific priors, and generates
region-aligned sentences via structured prompts. This pipeline improves report
quality as measured by clinical keyword recall and ROUGE overlap. Our results
demonstrate that integrating gaze data improves both classification performance
and the interpretability of generated medical reports.

</details>


### [146] [IntelliCap: Intelligent Guidance for Consistent View Sampling](https://arxiv.org/abs/2508.13043)
*Ayaka Yasunaga,Hideo Saito,Dieter Schmalstieg,Shohei Mori*

Main category: cs.CV

TL;DR: 一种基于视觉-语言模型的多尺度扫描指导技术，通过识别重要物体并生成球面代理来指导用户收集更优的视角样本，提升新视角合成质量


<details>
  <summary>Details</summary>
Motivation: 虽然像3D Gaussian splatting这样的新视角合成技术在渲染质量和速度上取得了重大进步，但在帮助人们收集输入图像方面却很少有研究。高质量视角合成需要均匀和密集的视角采样，而这些要求对于紧张、不耐烦或缺乏场景理解的拍摄者来说很难满足

Method: 提出了一种新的情境化可视化技术，在扫描过程中识别需要扩展图像覆盖的重要物体，以正确表示视角依赖性外观。利用语义分割和类别识别，通过视觉-语言模型进行排名，然后在高排名物体周围生成球面代理来指导用户扫描

Result: 在真实场景中表现出优于传统视角采样策略的性能

Conclusion: 该方法能够有效指导用户收集更优质量的输入图像，解决了现有方法在单物体扫描或忽视视角依赖材质特性方面的不足，为多尺度扫描提供了有效的可视化指导方案

Abstract: Novel view synthesis from images, for example, with 3D Gaussian splatting,
has made great progress. Rendering fidelity and speed are now ready even for
demanding virtual reality applications. However, the problem of assisting
humans in collecting the input images for these rendering algorithms has
received much less attention. High-quality view synthesis requires uniform and
dense view sampling. Unfortunately, these requirements are not easily addressed
by human camera operators, who are in a hurry, impatient, or lack understanding
of the scene structure and the photographic process. Existing approaches to
guide humans during image acquisition concentrate on single objects or neglect
view-dependent material characteristics. We propose a novel situated
visualization technique for scanning at multiple scales. During the scanning of
a scene, our method identifies important objects that need extended image
coverage to properly represent view-dependent appearance. To this end, we
leverage semantic segmentation and category identification, ranked by a
vision-language model. Spherical proxies are generated around highly ranked
objects to guide the user during scanning. Our results show superior
performance in real scenes compared to conventional view sampling strategies.

</details>


### [147] [Has GPT-5 Achieved Spatial Intelligence? An Empirical Study](https://arxiv.org/abs/2508.13142)
*Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: GPT-5在多模态空间智能方面取得显著进步但仍未达到人类水平，研究发现现有模型在空间理解和推理方面仍存在明显局限，特别是在最具挑战性的问题上开源模型与专有模型差距不大。


<details>
  <summary>Details</summary>
Motivation: 随着GPT-5的发布，需要评估当前最先进多模态模型在空间智能方面的实际能力，因为空间理解和推理是实现通用人工智能的基本能力，但现有模型在这方面仍存在明显不足。

Method: 提出了统一现有基准的空间任务分类法，在8个关键基准上评估了最先进的专有和开源模型，消耗了超过10亿个token，并进行了定性评估。

Result: GPT-5在空间智能方面表现出前所未有的强大能力，但在广泛任务中仍不及人类表现；识别出多模态模型更具挑战性的空间智能问题；专有模型在最困难问题上没有决定性优势。

Conclusion: 多模态模型在空间智能方面虽有进步但仍需大幅提升，特别是在人类直觉性但模型易失败的场景中，开源模型在最具挑战性问题上的表现与专有模型相当。

Abstract: Multi-modal models have achieved remarkable progress in recent years.
Nevertheless, they continue to exhibit notable limitations in spatial
understanding and reasoning, which are fundamental capabilities to achieving
artificial general intelligence. With the recent release of GPT-5, allegedly
the most powerful AI model to date, it is timely to examine where the leading
models stand on the path toward spatial intelligence. First, we propose a
comprehensive taxonomy of spatial tasks that unifies existing benchmarks and
discuss the challenges in ensuring fair evaluation. We then evaluate
state-of-the-art proprietary and open-source models on eight key benchmarks, at
a cost exceeding one billion total tokens. Our empirical study reveals that (1)
GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)
still falls short of human performance across a broad spectrum of tasks.
Moreover, we (3) identify the more challenging spatial intelligence problems
for multi-modal models, and (4) proprietary models do not exhibit a decisive
advantage when facing the most difficult problems. In addition, we conduct a
qualitative evaluation across a diverse set of scenarios that are intuitive for
humans yet fail even the most advanced multi-modal models.

</details>


### [148] [Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping](https://arxiv.org/abs/2508.13065)
*Siddharth Khandelwal,Sridhar Kamath,Arjun Jain*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于污果模型的端到端人体形状编辑方法Odo，通过新的大规模数据集和控制网络技术，实现了更准确和质量更高的人体形状变换。


<details>
  <summary>Details</summary>
Motivation: 人体形状编辑领域缺乏大规模公开数据集，现有方法存在身体比例不真实、纹理扭曲和背景不一致等问题，需要提升编辑质量和实现性。

Method: 构建了包含18,573张图片的大规模数据集，提出Odo污果模型方法，结合冻结UNet保留外观细节和ControlNet通过SMPL深度地图指导形状变换。

Result: 方法在每个顶点重建误差上达到7.5mm，显著低于基线方法的13.6mm，能够生成准确匹配目标形状的实际结果。

Conclusion: 该研究为人体形状编辑领域提供了重要的数据集支撑和有效的算法方案，实现了更高质量的实时人体形态变换。

Abstract: Human shape editing enables controllable transformation of a person's body
shape, such as thin, muscular, or overweight, while preserving pose, identity,
clothing, and background. Unlike human pose editing, which has advanced
rapidly, shape editing remains relatively underexplored. Current approaches
typically rely on 3D morphable models or image warping, often introducing
unrealistic body proportions, texture distortions, and background
inconsistencies due to alignment errors and deformations. A key limitation is
the lack of large-scale, publicly available datasets for training and
evaluating body shape manipulation methods. In this work, we introduce the
first large-scale dataset of 18,573 images across 1523 subjects, specifically
designed for controlled human shape editing. It features diverse variations in
body shape, including fat, muscular and thin, captured under consistent
identity, clothing, and background conditions. Using this dataset, we propose
Odo, an end-to-end diffusion-based method that enables realistic and intuitive
body reshaping guided by simple semantic attributes. Our approach combines a
frozen UNet that preserves fine-grained appearance and background details from
the input image with a ControlNet that guides shape transformation using target
SMPL depth maps. Extensive experiments demonstrate that our method outperforms
prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm,
significantly lower than the 13.6mm observed in baseline methods, while
producing realistic results that accurately match the desired target shapes.

</details>


### [149] [ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset](https://arxiv.org/abs/2508.13078)
*Qingwen Zeng,Juan E. Tapia,Izan Garcia,Juan M. Espin,Christoph Busch*

Main category: cs.CV

TL;DR: 使用Stable Diffusion生成合成真实ID卡图像来解决识别卡攻击检测系统中真实样本数量不足的问题，提升检测器的通用性能力


<details>
  <summary>Details</summary>
Motivation: ID卡攻击检测系统面临真实图像样本数量不足和攻击手段多样化的挑战，现有算法多关注攻击样本生成而忽视了真实样本的限制

Method: 使用Stable Diffusion生成合成的真实ID卡图像，并在从头开始训练的系统和商业解决方案中评估这些新生成的图像

Result: 攻击检测系统将生成的合成图像识别为真实图像，这对检测性能和数据限制问题产生了积极影响

Conclusion: 通过生成式AI技术生成真实ID卡图像是一种有效的方法，能够补充真实样本的不足并提升攻击检测系统的性能

Abstract: Nowadays, the development of a Presentation Attack Detection (PAD) system for
ID cards presents a challenge due to the lack of images available to train a
robust PAD system and the increase in diversity of possible attack instrument
species. Today, most algorithms focus on generating attack samples and do not
take into account the limited number of bona fide images. This work is one of
the first to propose a method for mimicking bona fide images by generating
synthetic versions of them using Stable Diffusion, which may help improve the
generalisation capabilities of the detector. Furthermore, the new images
generated are evaluated in a system trained from scratch and in a commercial
solution. The PAD system yields an interesting result, as it identifies our
images as bona fide, which has a positive impact on detection performance and
data restrictions.

</details>


### [150] [Checkmate: interpretable and explainable RSVQA is the endgame](https://arxiv.org/abs/2508.13086)
*Lucrezia Tosato,Christel Tartini Chappuis,Syrielle Montariol,Flora Weissgerber,Sylvain Lobry,Devis Tuia*

Main category: cs.CV

TL;DR: 提出了一个新的遥感视觉问答数据集Chessboard和可解释模型Checkmate，解决了RSVQA系统中的可解释性和偏差问题


<details>
  <summary>Details</summary>
Motivation: 遥感视觉问答系统缺乏可解释性和可说明性，并存在数据集偏差导致的短接学习问题

Method: 创建了包含3,123,253个问题的Chessboard数据集，答案分布均衡，每个答案都与图像中的特定像素单元相关联；开发了Checkmate模型，能够识别决策最相关的图像区域

Result: 通过多种模型架构的实验验证，该方法提高了系统的透明度和可信过程

Conclusion: 该研究为遥感视觉问答系统提供了更可靠、可解释的决策支持

Abstract: Remote Sensing Visual Question Answering (RSVQA) presents unique challenges
in ensuring that model decisions are both understandable and grounded in visual
content. Current models often suffer from a lack of interpretability and
explainability, as well as from biases in dataset distributions that lead to
shortcut learning. In this work, we tackle these issues by introducing a novel
RSVQA dataset, Chessboard, designed to minimize biases through 3'123'253
questions and a balanced answer distribution. Each answer is linked to one or
more cells within the image, enabling fine-grained visual reasoning.
  Building on this dataset, we develop an explainable and interpretable model
called Checkmate that identifies the image cells most relevant to its
decisions. Through extensive experiments across multiple model architectures,
we show that our approach improves transparency and supports more trustworthy
decision-making in RSVQA systems.

</details>


### [151] [DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation](https://arxiv.org/abs/2508.13091)
*Zihua Liu,Yizhou Li,Songyan Zhang,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: 提出DMS方法，利用扩散模型的几何先验合成沿极线方向的新视角图像，解决自监督立体匹配和单目深度估计中的遮挡和出框区域像素缺失问题


<details>
  <summary>Details</summary>
Motivation: 自监督方法使用立体图像作为监督信号时，在遮挡区域和出框区域存在像素对应缺失问题，导致光度重建模糊性，需要进一步研究解决

Method: 微调Stable Diffusion模型，通过方向提示合成三个关键位置的新视角：左相机偏移的左-左视图、右相机偏移的右-右视图，以及左右相机之间的中间视图，补充遮挡像素实现显式光度重建

Result: 在多个基准数据集上达到最先进性能，异常值减少高达35%

Conclusion: DMS是一种模型无关的即插即用方法，仅需未标注的立体图像对即可训练和合成，有效提升自监督立体匹配和单目深度估计性能

Abstract: While supervised stereo matching and monocular depth estimation have advanced
significantly with learning-based algorithms, self-supervised methods using
stereo images as supervision signals have received relatively less focus and
require further investigation. A primary challenge arises from ambiguity
introduced during photometric reconstruction, particularly due to missing
corresponding pixels in ill-posed regions of the target view, such as
occlusions and out-of-frame areas. To address this and establish explicit
photometric correspondences, we propose DMS, a model-agnostic approach that
utilizes geometric priors from diffusion models to synthesize novel views along
the epipolar direction, guided by directional prompts. Specifically, we
finetune a Stable Diffusion model to simulate perspectives at key positions:
left-left view shifted from the left camera, right-right view shifted from the
right camera, along with an additional novel view between the left and right
cameras. These synthesized views supplement occluded pixels, enabling explicit
photometric reconstruction. Our proposed DMS is a cost-free, ''plug-and-play''
method that seamlessly enhances self-supervised stereo matching and monocular
depth estimation, and relies solely on unlabeled stereo image pairs for both
training and synthesizing. Extensive experiments demonstrate the effectiveness
of our approach, with up to 35% outlier reduction and state-of-the-art
performance across multiple benchmark datasets.

</details>


### [152] [Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants](https://arxiv.org/abs/2508.13101)
*Miftahul Huda,Arsyiah Azahra,Putri Maulida Chairani,Dimas Rizky Ramadhani,Nabila Azhari,Ade Lailani*

Main category: cs.CV

TL;DR: 本研究比较了RT-DETR-L和RT-DETR-X两种模型在海滩垃圾检测中的性能，发现RT-DETR-X精度略高但计算成本显著，RT-DETR-L在速度和精度间取得更好平衡，更适合实时部署。


<details>
  <summary>Details</summary>
Motivation: 海岸污染是全球紧迫的环境问题，需要可扩展的自动化监测解决方案。研究旨在探索最先进的端到端目标检测模型RT-DETR在沙滩垃圾自动检测和计数中的应用效果。

Method: 使用公开可用的海岸碎片数据集，对RT-DETR-Large和RT-DETR-Extra-Large两种变体模型进行严格的比较分析，评估其在海滩垃圾检测中的性能表现。

Result: RT-DETR-X模型获得略高的精度（mAP@50为0.816，mAP@50-95为0.612），但RT-DETR-L模型推理时间显著更快（20.1ms vs 34.5ms）。RT-DETR-L在检测精度和处理速度之间提供了更好的平衡。

Conclusion: RT-DETR-L模型因其优越的处理速度和检测精度平衡，为实时野外部署提供了更实用高效的解决方案。研究为基于Transformer的先进检测器在环境保护中的应用提供了重要见解，强调了模型复杂性与操作可行性之间的关键权衡。

Abstract: Coastal pollution is a pressing global environmental issue, necessitating
scalable and automated solutions for monitoring and management. This study
investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a
state-of-the-art, end-to-end object detection model, for the automated
detection and counting of beach litter. A rigorous comparative analysis is
conducted between two model variants, RT-DETR-Large (RT-DETR-L) and
RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of
coastal debris. The evaluation reveals that the RT-DETR-X model achieves
marginally superior accuracy, with a mean Average Precision at 50\% IoU
(mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L model's
0.810 and 0.606, respectively. However, this minor performance gain is realized
at a significant computational cost; the RT-DETR-L model demonstrates a
substantially faster inference time of 20.1 ms versus 34.5 ms for the
RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more
practical and efficient solution for real-time, in-field deployment due to its
superior balance of processing speed and detection accuracy. This research
provides valuable insights into the application of advanced Transformer-based
detectors for environmental conservation, highlighting the critical trade-offs
between model complexity and operational viability.

</details>


### [153] [Precise Action-to-Video Generation Through Visual Action Prompts](https://arxiv.org/abs/2508.13104)
*Yuang Wang,Chao Wen,Haoyu Guo,Sida Peng,Minghan Qin,Hujun Bao,Xiaowei Zhou,Ruizhen Hu*

Main category: cs.CV

TL;DR: 提出视觉动作提示（VAP），一种统一的动作表示方法，通过将动作渲染为视觉骨架来平衡动作精度和跨域动态迁移性，用于复杂高自由度交互的动作到视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有动作驱动视频生成方法面临精度与通用性的权衡：文本、原始动作或粗糙掩码方法通用但缺乏精度，而智能体中心动作信号精度高但跨域迁移性差。

Method: 将动作渲染为精确的视觉提示（选择视觉骨架作为通用可访问表示），构建从人-物交互和灵巧机器人操作数据中提取骨架的鲁棒流程，通过轻量微调将视觉骨架集成到预训练视频生成模型中。

Result: 在EgoVid、RT-1和DROID数据集上的实验证明了所提方法的有效性，能够实现复杂交互的精确动作控制同时保持跨域动态学习。

Conclusion: 视觉动作提示提供了一种平衡动作精度和动态迁移性的统一表示方法，为复杂高自由度交互的动作到视频生成提供了有效解决方案。

Abstract: We present visual action prompts, a unified action representation for
action-to-video generation of complex high-DoF interactions while maintaining
transferable visual dynamics across domains. Action-driven video generation
faces a precision-generality trade-off: existing methods using text, primitive
actions, or coarse masks offer generality but lack precision, while
agent-centric action signals provide precision at the cost of cross-domain
transferability. To balance action precision and dynamic transferability, we
propose to "render" actions into precise visual prompts as domain-agnostic
representations that preserve both geometric precision and cross-domain
adaptability for complex actions; specifically, we choose visual skeletons for
their generality and accessibility. We propose robust pipelines to construct
skeletons from two interaction-rich data sources - human-object interactions
(HOI) and dexterous robotic manipulation - enabling cross-domain training of
action-driven generative models. By integrating visual skeletons into
pretrained video generation models via lightweight fine-tuning, we enable
precise action control of complex interaction while preserving the learning of
cross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the
effectiveness of our proposed approach. Project page:
https://zju3dv.github.io/VAP/.

</details>


### [154] [Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence](https://arxiv.org/abs/2508.13139)
*Ling-Hao Chen,Yuhong Zhang,Zixin Yin,Zhiyang Dou,Xin Chen,Jingbo Wang,Taku Komura,Lei Zhang*

Main category: cs.CV

TL;DR: Motion2Motion是一个无需训练的新框架，通过稀疏骨骼对应关系实现不同拓扑结构角色间的动作迁移，只需目标骨骼的少量示例动作即可工作。


<details>
  <summary>Details</summary>
Motivation: 解决不同骨骼拓扑结构角色间动作迁移的挑战，现有技术难以处理骨骼拓扑不一致和缺乏大规模配对数据集的问题。

Method: 提出训练免费的Motion2Motion框架，通过源骨骼和目标骨骼间的稀疏骨骼对应关系，仅需目标骨骼的一个或几个示例动作。

Result: 在相似骨骼和跨物种骨骼迁移场景中都实现了高效可靠的性能，成功集成到下游应用和用户界面中。

Conclusion: 该方法具有工业应用潜力，代码和数据已公开，为不同拓扑结构角色间的动作迁移提供了有效解决方案。

Abstract: This work studies the challenge of transfer animations between characters
whose skeletal topologies differ substantially. While many techniques have
advanced retargeting techniques in decades, transfer motions across diverse
topologies remains less-explored. The primary obstacle lies in the inherent
topological inconsistency between source and target skeletons, which restricts
the establishment of straightforward one-to-one bone correspondences. Besides,
the current lack of large-scale paired motion datasets spanning different
topological structures severely constrains the development of data-driven
approaches. To address these limitations, we introduce Motion2Motion, a novel,
training-free framework. Simply yet effectively, Motion2Motion works with only
one or a few example motions on the target skeleton, by accessing a sparse set
of bone correspondences between the source and target skeletons. Through
comprehensive qualitative and quantitative evaluations, we demonstrate that
Motion2Motion achieves efficient and reliable performance in both
similar-skeleton and cross-species skeleton transfer scenarios. The practical
utility of our approach is further evidenced by its successful integration in
downstream applications and user interfaces, highlighting its potential for
industrial applications. Code and data are available at
https://lhchen.top/Motion2Motion.

</details>


### [155] [IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion](https://arxiv.org/abs/2508.13153)
*Wenhao Hu,Zesheng Li,Haonan Zhou,Liu Liu,Xuexiang Wen,Zhizhong Su,Xi Li,Gaoang Wang*

Main category: cs.CV

TL;DR: IGFuse是一个新颖的3D场景重建框架，通过融合多视角扫描数据来重建交互式高斯场景，解决了传统方法中物体遮挡和传感器覆盖限制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景重建方法面临物体遮挡和传感器覆盖限制的挑战，多阶段流程容易出错且难以扩展，需要一种能够有效处理遮挡并支持交互式场景操作的新方法。

Method: 提出IGFuse框架，通过多扫描融合构建分割感知的高斯场，使用双向光度和语义一致性约束，引入伪中间场景状态进行统一对齐，并采用协作共剪枝策略优化几何结构。

Result: 实验验证了该框架对新场景配置的强泛化能力，能够实现高保真渲染和物体级场景操作，无需密集观测或复杂流程。

Conclusion: IGFuse为真实世界3D重建和真实到仿真的转换提供了有效的解决方案，在保持高质量重建的同时支持交互式场景操作。

Abstract: Reconstructing complete and interactive 3D scenes remains a fundamental
challenge in computer vision and robotics, particularly due to persistent
object occlusions and limited sensor coverage. Multiview observations from a
single scene scan often fail to capture the full structural details. Existing
approaches typically rely on multi stage pipelines, such as segmentation,
background completion, and inpainting or require per-object dense scanning,
both of which are error-prone, and not easily scalable. We propose IGFuse, a
novel framework that reconstructs interactive Gaussian scene by fusing
observations from multiple scans, where natural object rearrangement between
captures reveal previously occluded regions. Our method constructs segmentation
aware Gaussian fields and enforces bi-directional photometric and semantic
consistency across scans. To handle spatial misalignments, we introduce a
pseudo-intermediate scene state for unified alignment, alongside collaborative
co-pruning strategies to refine geometry. IGFuse enables high fidelity
rendering and object level scene manipulation without dense observations or
complex pipelines. Extensive experiments validate the framework's strong
generalization to novel scene configurations, demonstrating its effectiveness
for real world 3D reconstruction and real-to-simulation transfer. Our project
page is available online.

</details>


### [156] [4DNeX: Feed-Forward 4D Generative Modeling Made Easy](https://arxiv.org/abs/2508.13154)
*Zhaoxi Chen,Tianqi Liu,Long Zhuo,Jiawei Ren,Zeng Tao,He Zhu,Fangzhou Hong,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 4DNeX是首个从单张图像生成4D（动态3D）场景表征的前馈框架，通过微调预训练视频扩散模型实现高效的端到端图像到4D生成


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖计算密集型优化或需要多帧视频输入的问题，提供高效的图像到4D生成方案

Method: 1)构建大规模4D数据集4DNeX-10M；2)引入统一6D视频表征联合建模RGB和XYZ序列；3)提出适配策略将预训练视频扩散模型用于4D建模

Result: 生成高质量动态点云，支持新视角视频合成，在效率和泛化性方面优于现有4D生成方法

Conclusion: 为图像到4D建模提供了可扩展解决方案，为生成式4D世界模型模拟动态场景演化奠定了基础

Abstract: We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,
dynamic 3D) scene representations from a single image. In contrast to existing
methods that rely on computationally intensive optimization or require
multi-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D
generation by fine-tuning a pretrained video diffusion model. Specifically, 1)
to alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale
dataset with high-quality 4D annotations generated using advanced
reconstruction approaches. 2) we introduce a unified 6D video representation
that jointly models RGB and XYZ sequences, facilitating structured learning of
both appearance and geometry. 3) we propose a set of simple yet effective
adaptation strategies to repurpose pretrained video diffusion models for 4D
modeling. 4DNeX produces high-quality dynamic point clouds that enable
novel-view video synthesis. Extensive experiments demonstrate that 4DNeX
outperforms existing 4D generation methods in efficiency and generalizability,
offering a scalable solution for image-to-4D modeling and laying the foundation
for generative 4D world models that simulate dynamic scene evolution.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [157] [RRRA: Resampling and Reranking through a Retriever Adapter](https://arxiv.org/abs/2508.11670)
*Bongsu Kim*

Main category: cs.IR

TL;DR: 提出可学习的适配器模块来动态识别假阴性样本，通过重采样和重排序提升稠密检索性能


<details>
  <summary>Details</summary>
Motivation: 现有基于启发式的方法在识别硬负样本时容易忽略实例特定的假阴性问题，需要更细粒度的查询特定判断

Method: 使用可学习适配器监控Bi-Encoder表示，动态估计硬负样本为假阴性的概率，并应用于训练重采样和推理重排序

Result: 在标准基准测试中，适配器增强框架持续优于强Bi-Encoder基线

Conclusion: 显式建模假阴性对稠密检索有显著益处

Abstract: In dense retrieval, effective training hinges on selecting high quality hard
negatives while avoiding false negatives. Recent methods apply heuristics based
on positive document scores to identify hard negatives, improving both
performance and interpretability. However, these global, example agnostic
strategies often miss instance specific false negatives. To address this, we
propose a learnable adapter module that monitors Bi-Encoder representations to
estimate the likelihood that a hard negative is actually a false negative. This
probability is modeled dynamically and contextually, enabling fine-grained,
query specific judgments. The predicted scores are used in two downstream
components: (1) resampling, where negatives are reweighted during training, and
(2) reranking, where top-k retrieved documents are reordered at inference.
Empirical results on standard benchmarks show that our adapter-enhanced
framework consistently outperforms strong Bi-Encoder baselines, underscoring
the benefit of explicit false negative modeling in dense retrieval.

</details>


### [158] [LLM-Based Intelligent Agents for Music Recommendation: A Comparison with Classical Content-Based Filtering](https://arxiv.org/abs/2508.11671)
*Ronald Carvalho Boadana,Ademir Guimarães da Costa Junior,Ricardo Rios,Fábio Santos da Silva*

Main category: cs.IR

TL;DR: LLM基于Gemini和LLaMA系列的多游段智能推荐系统在音乐推荐中达到89.32%用户满意度，显示出比传统内容基于推荐更好的效果


<details>
  <summary>Details</summary>
Motivation: 解决流媒体平台音乐信息过载问题，提升用户体验，通过大语言模型和智能游段提高个性化音乐推荐的效果

Method: 使用Gemini和LLaMA家族的大语言模型，结合智能游段构建多游段个性化音乐推荐系统，与传统内容基于推荐模型进行对比

Result: LLM推荐系统达到了89.32%的用户满意度，在用户满意度、新颖性和计算效率方面都显示出优势

Conclusion: 大语言模型在音乐推荐系统中具有很大潜力，能够有效提升推荐质量和用户体验

Abstract: The growing availability of music on streaming platforms has led to
information overload for users. To address this issue and enhance the user
experience, increasingly sophisticated recommendation systems have been
proposed. This work investigates the use of Large Language Models (LLMs) from
the Gemini and LLaMA families, combined with intelligent agents, in a
multi-agent personalized music recommendation system. The results are compared
with a traditional content-based recommendation model, considering user
satisfaction, novelty, and computational efficiency. LLMs achieved satisfaction
rates of up to \textit{89{,}32\%}, indicating their promising potential in
music recommendation systems.

</details>


### [159] [Ontology-Guided Query Expansion for Biomedical Document Retrieval using Large Language Models](https://arxiv.org/abs/2508.11784)
*Zabir Al Nazi,Vagelis Hristidis,Aaron Lawson McLean,Jannat Ara Meem,Md Taukir Azam Chowdhury*

Main category: cs.IR

TL;DR: BMQExpander是一种新颖的基于本体感知的查询扩展方法，结合UMLS医学知识库和LLM生成能力，在生物医学文档检索中显著提升检索效果，在多个基准测试中表现优异且具有良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生物医学领域的文档检索面临领域特定词汇和语义歧义的挑战，需要有效的查询扩展技术来提升检索效果。

Method: 提出BMQExpander管道，整合UMLS Metathesaurus的医学知识（定义和关系）与大语言模型的生成能力，进行本体感知的查询扩展。

Result: 在NFCorpus、TREC-COVID和SciFact三个生物医学IR基准测试中，相比稀疏基线提升22.1% NDCG@10，相比最强基线提升6.5%；在查询扰动设置下比最强基线提升15.7%，且幻觉更少。

Conclusion: BMQExpander通过结合医学本体知识和LLM生成能力，显著提升了生物医学文档检索的效果和鲁棒性，是一种有效的查询扩展解决方案。

Abstract: Effective Question Answering (QA) on large biomedical document collections
requires effective document retrieval techniques. The latter remains a
challenging task due to the domain-specific vocabulary and semantic ambiguity
in user queries. We propose BMQExpander, a novel ontology-aware query expansion
pipeline that combines medical knowledge - definitions and relationships - from
the UMLS Metathesaurus with the generative capabilities of large language
models (LLMs) to enhance retrieval effectiveness. We implemented several
state-of-the-art baselines, including sparse and dense retrievers, query
expansion methods, and biomedical-specific solutions. We show that BMQExpander
has superior retrieval performance on three popular biomedical Information
Retrieval (IR) benchmarks: NFCorpus, TREC-COVID, and SciFact - with
improvements of up to 22.1% in NDCG@10 over sparse baselines and up to 6.5%
over the strongest baseline. Further, BMQExpander generalizes robustly under
query perturbation settings, in contrast to supervised baselines, achieving up
to 15.7% improvement over the strongest baseline. As a side contribution, we
publish our paraphrased benchmarks. Finally, our qualitative analysis shows
that BMQExpander has fewer hallucinations compared to other LLM-based query
expansion baselines.

</details>


### [160] [TBGRecall: A Generative Retrieval Model for E-commerce Recommendation Scenarios](https://arxiv.org/abs/2508.11977)
*Zida Liang,Changfa Wu,Dunxian Huang,Weiqiang Sun,Ziyang Wang,Yuliang Yan,Jian Wu,Yuning Jiang,Bo Zheng,Ke Chen,Silu Zhou,Yu Zhang*

Main category: cs.IR

TL;DR: TBGRecall是一个集成Next Session Prediction的生成式推荐框架，通过多会话序列重构和优化训练方法，显著提升了电商推荐系统的检索效率和性能


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐模型在检索任务中存在局限性，主要由于自回归生成机制导致的顺序依赖问题，无法高效生成无位置约束的多个推荐项目

Method: 将输入样本划分为多会话序列（会话token+项目token），采用有限历史数据预训练和随机部分增量训练相结合的训练方法

Result: 在公开基准测试和淘宝大规模工业数据集上，TBGRecall超越了最先进的推荐方法，并展现出明显的缩放定律趋势

Conclusion: NSP代表了生成式推荐系统在电商应用中的重大进展，数据时效性比数据量更重要，训练效率显著提升

Abstract: Recommendation systems are essential tools in modern e-commerce, facilitating
personalized user experiences by suggesting relevant products. Recent
advancements in generative models have demonstrated potential in enhancing
recommendation systems; however, these models often exhibit limitations in
optimizing retrieval tasks, primarily due to their reliance on autoregressive
generation mechanisms. Conventional approaches introduce sequential
dependencies that impede efficient retrieval, as they are inherently unsuitable
for generating multiple items without positional constraints within a single
request session. To address these limitations, we propose TBGRecall, a
framework integrating Next Session Prediction (NSP), designed to enhance
generative retrieval models for e-commerce applications. Our framework
reformulation involves partitioning input samples into multi-session sequences,
where each sequence comprises a session token followed by a set of item tokens,
and then further incorporate multiple optimizations tailored to the generative
task in retrieval scenarios. In terms of training methodology, our pipeline
integrates limited historical data pre-training with stochastic partial
incremental training, significantly improving training efficiency and
emphasizing the superiority of data recency over sheer data volume. Our
extensive experiments, conducted on public benchmarks alongside a large-scale
industrial dataset from TaoBao, show TBGRecall outperforms the state-of-the-art
recommendation methods, and exhibits a clear scaling law trend. Ultimately, NSP
represents a significant advancement in the effectiveness of generative
recommendation systems for e-commerce applications.

</details>


### [161] [Leveraging Geometric Insights in Hyperbolic Triplet Loss for Improved Recommendations](https://arxiv.org/abs/2508.11978)
*Viacheslav Yusupov,Maxim Rakhuba,Evgeny Frolov*

Main category: cs.IR

TL;DR: 提出了一种新颖的双曲推荐模型，利用几何洞察改进表示学习并提高计算稳定性，通过重新定义双曲距离和构建三元组损失来更好地捕捉用户-物品交互


<details>
  <summary>Details</summary>
Motivation: 现有研究显示双曲几何在推荐系统中具有捕捉复杂交互模式的潜力，但需要改进表示学习和计算稳定性

Method: 重新定义双曲距离概念以释放比传统欧几里得空间更大的表示能力，构建三元组损失通过混合成对交互项来建模用户与偏好/非偏好选择的三元关系

Result: 该双曲方法不仅优于现有的欧几里得和双曲模型，还减少了流行度偏差，产生更多样化和个性化的推荐

Conclusion: 基于几何数据驱动的双曲推荐模型在表示学习和推荐性能方面都取得了显著改进

Abstract: Recent studies have demonstrated the potential of hyperbolic geometry for
capturing complex patterns from interaction data in recommender systems. In
this work, we introduce a novel hyperbolic recommendation model that uses
geometrical insights to improve representation learning and increase
computational stability at the same time. We reformulate the notion of
hyperbolic distances to unlock additional representation capacity over
conventional Euclidean space and learn more expressive user and item
representations. To better capture user-items interactions, we construct a
triplet loss that models ternary relations between users and their
corresponding preferred and nonpreferred choices through a mix of pairwise
interaction terms driven by the geometry of data. Our hyperbolic approach not
only outperforms existing Euclidean and hyperbolic models but also reduces
popularity bias, leading to more diverse and personalized recommendations.

</details>


### [162] [A Large-Scale Web Search Dataset for Federated Online Learning to Rank](https://arxiv.org/abs/2508.12353)
*Marcel Gregoriadis,Jingwei Kang,Johan Pouwelse*

Main category: cs.IR

TL;DR: 提出了AOL4FOLTR数据集，这是一个包含260万查询和1万用户的大规模网络搜索数据集，用于改进联邦在线学习排序的基准测试真实性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦在线学习排序基准测试存在局限性，主要基于随机划分的传统数据集、模拟点击和同步客户端参与的假设，无法反映真实世界动态。

Method: 构建包含用户标识符、真实点击数据和查询时间戳的大规模网络搜索数据集AOL4FOLTR，支持真实的用户划分、行为建模和异步联邦学习场景。

Result: 成功创建了包含2.6百万查询和10,000用户的大规模数据集，解决了现有基准测试的关键限制。

Conclusion: AOL4FOLTR数据集为联邦在线学习排序提供了更真实的评估基准，能够更好地模拟实际应用场景。

Abstract: The centralized collection of search interaction logs for training ranking
models raises significant privacy concerns. Federated Online Learning to Rank
(FOLTR) offers a privacy-preserving alternative by enabling collaborative model
training without sharing raw user data. However, benchmarks in FOLTR are
largely based on random partitioning of classical learning-to-rank datasets,
simulated user clicks, and the assumption of synchronous client participation.
This oversimplifies real-world dynamics and undermines the realism of
experimental results. We present AOL4FOLTR, a large-scale web search dataset
with 2.6 million queries from 10,000 users. Our dataset addresses key
limitations of existing benchmarks by including user identifiers, real click
data, and query timestamps, enabling realistic user partitioning, behavior
modeling, and asynchronous federated learning scenarios.

</details>


### [163] [TaoSR1: The Thinking Model for E-commerce Relevance Search](https://arxiv.org/abs/2508.12365)
*Chenhe Dong,Shaowei Yao,Pengkun Jiao,Jianhui Yang,Yiming Jin,Zerui Huang,Xiaojiang Zhou,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: 提出了TaoSR1框架，直接部署大语言模型进行电商搜索相关性预测，通过三阶段训练和优化方法解决思维链错误累积、判别性幻觉和部署可行性问题，在离线和在线评估中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: BERT模型擅长语义匹配但缺乏复杂推理能力，现有LLM方法多采用判别式微调或蒸馏到小模型，需要探索直接部署LLM进行相关性预测的新范式。

Method: 三阶段框架：1)SFT+CoT注入推理能力；2)离线采样+DPO提升生成质量；3)难度动态采样+GRPO缓解判别性幻觉。辅以后处理方法和概率分区实现高效在线部署。

Result: 在离线数据集上显著超越基线方法，在线人工对比评估中获得实质性提升，证明了CoT推理在相关性分类中的有效性。

Conclusion: TaoSR1成功将思维链推理应用于相关性分类任务，为解决LLM直接部署的关键挑战提供了有效方案，开创了新的应用范式。

Abstract: Query-product relevance prediction is a core task in e-commerce search.
BERT-based models excel at semantic matching but lack complex reasoning
capabilities. While Large Language Models (LLMs) are explored, most still use
discriminative fine-tuning or distill to smaller models for deployment. We
propose a framework to directly deploy LLMs for this task, addressing key
challenges: Chain-of-Thought (CoT) error accumulation, discriminative
hallucination, and deployment feasibility. Our framework, TaoSR1, involves
three stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning;
(2) Offline sampling with a pass@N strategy and Direct Preference Optimization
(DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling
with Group Relative Policy Optimization (GRPO) to mitigate discriminative
hallucination. Additionally, post-CoT processing and a cumulative
probability-based partitioning method enable efficient online deployment.
TaoSR1 significantly outperforms baselines on offline datasets and achieves
substantial gains in online side-by-side human evaluations, introducing a novel
paradigm for applying CoT reasoning to relevance classification.

</details>


### [164] [Contrastive Multi-View Graph Hashing](https://arxiv.org/abs/2508.12377)
*Yang Xu,Zuliang Yang,Kai Ming Ting*

Main category: cs.IR

TL;DR: CMGHash是一个端到端的多视图图哈希框架，通过对比学习融合多视图图数据生成统一的二进制嵌入，显著提高了检索精度


<details>
  <summary>Details</summary>
Motivation: 现有的多视图哈希技术假设基于属性的输入，无法有效处理多视图图数据中复杂的拓扑信息融合问题

Method: 使用对比多视图图损失学习共识节点表示空间，拉近所有图中的k近邻节点，推开非邻居节点，并在共识空间上施加二值化约束

Result: 在多个基准数据集上的实验表明，CMGHash在检索精度方面显著优于现有方法

Conclusion: CMGHash为多视图图数据提供了一种有效的统一二进制嵌入学习方法，解决了复杂拓扑信息融合的挑战

Abstract: Multi-view graph data, which both captures node attributes and rich
relational information from diverse sources, is becoming increasingly prevalent
in various domains. The effective and efficient retrieval of such data is an
important task. Although multi-view hashing techniques have offered a paradigm
for fusing diverse information into compact binary codes, they typically assume
attributes-based inputs per view. This makes them unsuitable for multi-view
graph data, where effectively encoding and fusing complex topological
information from multiple heterogeneous graph views to generate unified binary
embeddings remains a significant challenge. In this work, we propose
Contrastive Multi-view Graph Hashing (CMGHash), a novel end-to-end framework
designed to learn unified and discriminative binary embeddings from multi-view
graph data. CMGHash learns a consensus node representation space using a
contrastive multi-view graph loss, which aims to pull $k$-nearest neighbors
from all graphs closer while pushing away negative pairs, i.e., non-neighbor
nodes. Moreover, we impose binarization constraints on this consensus space,
enabling its conversion to a corresponding binary embedding space at minimal
cost. Extensive experiments on several benchmark datasets demonstrate that
CMGHash significantly outperforms existing approaches in terms of retrieval
accuracy.

</details>


### [165] [Diagnostic-Guided Dynamic Profile Optimization for LLM-based User Simulators in Sequential Recommendation](https://arxiv.org/abs/2508.12645)
*Hongyang Liu,Zhu Sun,Tianjun Wei,Yan Wang,Jiajie Zhu,Xinghua Qu*

Main category: cs.IR

TL;DR: 提出了DGDPO框架，通过动态迭代优化用户画像来提升推荐系统中用户模拟器的真实性，解决了现有LLM模拟器静态单步推理和单轮交互的局限性


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的推荐系统用户模拟器存在两个主要问题：1）静态单步提示推理导致用户画像构建不准确不完整；2）不现实的单轮推荐-反馈交互模式无法捕捉真实场景

Method: DGDPO框架包含两个核心模块：诊断模块（通过新颖训练策略校准的LLM）准确识别用户画像缺陷；治疗模块分析缺陷并生成针对性改进建议。框架与序列推荐器集成，支持多轮双向演化

Result: 在三个真实世界数据集上的大量实验证明了该框架的有效性

Conclusion: DGDPO通过动态迭代优化过程显著提升了用户模拟的保真度，为推荐系统的开发和评估提供了更真实的用户模拟环境

Abstract: Recent advances in large language models (LLMs) have enabled realistic user
simulators for developing and evaluating recommender systems (RSs). However,
existing LLM-based simulators for RSs face two major limitations: (1) static
and single-step prompt-based inference that leads to inaccurate and incomplete
user profile construction; (2) unrealistic and single-round
recommendation-feedback interaction pattern that fails to capture real-world
scenarios. To address these limitations, we propose DGDPO (Diagnostic-Guided
Dynamic Profile Optimization), a novel framework that constructs user profile
through a dynamic and iterative optimization process to enhance the simulation
fidelity. Specifically, DGDPO incorporates two core modules within each
optimization loop: firstly, a specialized LLM-based diagnostic module,
calibrated through our novel training strategy, accurately identifies specific
defects in the user profile. Subsequently, a generalized LLM-based treatment
module analyzes the diagnosed defect and generates targeted suggestions to
refine the profile. Furthermore, unlike existing LLM-based user simulators that
are limited to single-round interactions, we are the first to integrate DGDPO
with sequential recommenders, enabling a bidirectional evolution where user
profiles and recommendation strategies adapt to each other over multi-round
interactions. Extensive experiments conducted on three real-world datasets
demonstrate the effectiveness of our proposed framework.

</details>


### [166] [Multi-Granularity Distribution Modeling for Video Watch Time Prediction via Exponential-Gaussian Mixture Network](https://arxiv.org/abs/2508.12665)
*Xu Zhao,Ruibo Ma,Jiaqi Chen,Weiqi Zhao,Ping Yang,Yao Hu*

Main category: cs.IR

TL;DR: 提出了一种基于指数-高斯混合分布的观看时间预测模型EGMN，通过混合分布分别处理粗粒度的偏斜性和细粒度的多样性，在工业短视频平台上取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 短视频平台中观看时间预测面临复杂分布挑战：粗粒度上存在大量快速跳过导致的偏斜分布，细粒度上用户-视频交互模式多样。需要一种能够同时处理这两种分布特性的方法。

Method: 提出指数-高斯混合分布(EGM)假设，其中指数分量处理偏斜性，高斯分量处理多样性。设计了EGMN网络，包含隐藏表示编码器和混合参数生成器两个关键模块。

Result: 在公开数据集和工业场景（小红书App）的A/B测试中，EGMN相比现有最优方法表现出色，在粗细粒度上均展现出优秀的分布拟合能力。

Conclusion: EGMN通过混合分布建模成功解决了观看时间预测中的分布复杂性挑战，为短视频平台的用户参与度提升提供了有效解决方案。

Abstract: Accurate watch time prediction is crucial for enhancing user engagement in
streaming short-video platforms, although it is challenged by complex
distribution characteristics across multi-granularity levels. Through
systematic analysis of real-world industrial data, we uncover two critical
challenges in watch time prediction from a distribution aspect: (1)
coarse-grained skewness induced by a significant concentration of quick-skips1,
(2) fine-grained diversity arising from various user-video interaction
patterns. Consequently, we assume that the watch time follows the
Exponential-Gaussian Mixture (EGM) distribution, where the exponential and
Gaussian components respectively characterize the skewness and diversity.
Accordingly, an Exponential-Gaussian Mixture Network (EGMN) is proposed for the
parameterization of EGM distribution, which consists of two key modules: a
hidden representation encoder and a mixture parameter generator. We conducted
extensive offline experiments on public datasets and online A/B tests on the
industrial short-video feeding scenario of Xiaohongshu App to validate the
superiority of EGMN compared with existing state-of-the-art methods.
Remarkably, comprehensive experimental results have proven that EGMN exhibits
excellent distribution fitting ability across coarse-to-fine-grained levels. We
open source related code on Github: https://github.com/BestActionNow/EGMN.

</details>


### [167] [Asymmetric Diffusion Recommendation Model](https://arxiv.org/abs/2508.12706)
*Yongchun Zhu,Guanyu Jiang,Jingwu Chen,Feng Zhang,Xiao Yang,Zuotao Liu*

Main category: cs.IR

TL;DR: 提出了AsymDiffRec模型，在推荐系统中使用非对称扩散过程来处理离散数据空间，通过任务导向优化策略保护个性化信息，在线上测试中取得了显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的推荐系统通常在连续数据空间使用对称的高斯噪声，但推荐样本本质上是离散的，且高斯噪声可能破坏潜在表示中的个性化信息。

Method: 提出非对称扩散推荐模型(AsymDiffRec)，在非对称潜在特征空间中执行前向和后向过程，前向过程模拟真实推荐样本中的缺失特征，后向过程生成去噪的鲁棒表示，并引入任务导向优化策略。

Result: 在线A/B测试显示，用户活跃天数提升+0.131%，应用使用时长提升+0.166%，离线实验也证明了改进效果，已在抖音音乐App中部署。

Conclusion: AsymDiffRec通过非对称扩散过程有效处理推荐系统中的离散数据特性，保护了个性化信息，显著提升了推荐性能。

Abstract: Recently, motivated by the outstanding achievements of diffusion models, the
diffusion process has been employed to strengthen representation learning in
recommendation systems. Most diffusion-based recommendation models typically
utilize standard Gaussian noise in symmetric forward and reverse processes in
continuous data space. Nevertheless, the samples derived from recommendation
systems inhabit a discrete data space, which is fundamentally different from
the continuous one. Moreover, Gaussian noise has the potential to corrupt
personalized information within latent representations. In this work, we
propose a novel and effective method, named Asymmetric Diffusion Recommendation
Model (AsymDiffRec), which learns forward and reverse processes in an
asymmetric manner. We define a generalized forward process that simulates the
missing features in real-world recommendation samples. The reverse process is
then performed in an asymmetric latent feature space. To preserve personalized
information within the latent representation, a task-oriented optimization
strategy is introduced. In the serving stage, the raw sample with missing
features is regarded as a noisy input to generate a denoising and robust
representation for the final prediction. By equipping base models with
AsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and
+0.166% in terms of users' active days and app usage duration respectively.
Additionally, the extended offline experiments also demonstrate improvements.
AsymDiffRec has been implemented in the Douyin Music App.

</details>


### [168] [Deep Research: A Survey of Autonomous Research Agents](https://arxiv.org/abs/2508.12752)
*Wenlin Zhang,Xiaopeng Li,Yingyi Zhang,Pengyue Jia,Yichao Wang,Huifeng Guo,Yong Liu,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 本论文系统性评估了深度研究模型的四阶段流程，分析了各阶段的技术挑战和解决方法，总结了最新的优化技术和标准化测试，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在内部知识边界限制，需要通过深度研究来突破这些限制，使组织能够自主进行规划、检索和综合，生成基于网络证据的全面分析报告。

Method: 调研文献系统性总结了深度研究流程的四个核心阶段：规划、问题开发、网络探索和报告生成，对每个阶段的关键技术挑战进行分析并对比了代表性方法。

Result: 文献调研总结了深度研究领域的最新进展，包括优化技术和专门的标准化测试框架，为构建更强大可靠的深度研究组织提供了系统性的技术路线图。

Conclusion: 本论文不仅总结了深度研究领域的现状和技术进展，还指出了当前的开放性挑战和有前景的研究方向，为建设更能干可信的深度研究组织提供了路线图。

Abstract: The rapid advancement of large language models (LLMs) has driven the
development of agentic systems capable of autonomously performing complex
tasks. Despite their impressive capabilities, LLMs remain constrained by their
internal knowledge boundaries. To overcome these limitations, the paradigm of
deep research has been proposed, wherein agents actively engage in planning,
retrieval, and synthesis to generate comprehensive and faithful analytical
reports grounded in web-based evidence. In this survey, we provide a systematic
overview of the deep research pipeline, which comprises four core stages:
planning, question developing, web exploration, and report generation. For each
stage, we analyze the key technical challenges and categorize representative
methods developed to address them. Furthermore, we summarize recent advances in
optimization techniques and benchmarks tailored for deep research. Finally, we
discuss open challenges and promising research directions, aiming to chart a
roadmap toward building more capable and trustworthy deep research agents.

</details>


### [169] [Informfully Recommenders -- Reproducibility Framework for Diversity-aware Intra-session Recommendations](https://arxiv.org/abs/2508.13019)
*Lucien Heitz,Runze Li,Oana Inel,Abraham Bernstein*

Main category: cs.IR

TL;DR: 提出Informfully Recommenders框架，为规范驱动的推荐系统提供可复现性支持，重点关注多样性优化的完整实验流程


<details>
  <summary>Details</summary>
Motivation: 目前缺乏支持规范驱动实验的可复现性框架，特别是在预处理、处理中、后处理和评估阶段的多样性优化需求

Method: 基于Cornac建立Informfully Recommenders框架，提供终端到终端解决方案，包括数据集预处理、多样性优化模型、会话内项目重新排序和广泛的多样性指标

Result: 通过新闻领域的涉及广泛离线实验展示了该扩展框架的能力

Conclusion: 该框架为规范驱动的推荐系统实验提供了第一步可复现性支持，有助于推进多样性优化研究的可比性和可重现性

Abstract: Norm-aware recommender systems have gained increased attention, especially
for diversity optimization. The recommender systems community has
well-established experimentation pipelines that support reproducible
evaluations by facilitating models' benchmarking and comparisons against
state-of-the-art methods. However, to the best of our knowledge, there is
currently no reproducibility framework to support thorough norm-driven
experimentation at the pre-processing, in-processing, post-processing, and
evaluation stages of the recommender pipeline. To address this gap, we present
Informfully Recommenders, a first step towards a normative reproducibility
framework that focuses on diversity-aware design built on Cornac. Our extension
provides an end-to-end solution for implementing and experimenting with
normative and general-purpose diverse recommender systems that cover 1) dataset
pre-processing, 2) diversity-optimized models, 3) dedicated intrasession item
re-ranking, and 4) an extensive set of diversity metrics. We demonstrate the
capabilities of our extension through an extensive offline experiment in the
news domain.

</details>


### [170] [D-RDW: Diversity-Driven Random Walks for News Recommender Systems](https://arxiv.org/abs/2508.13035)
*Runze Li,Lucien Heitz,Oana Inel,Abraham Bernstein*

Main category: cs.IR

TL;DR: D-RDW是一种轻量级的随机游走算法，通过结合传统随机游走的多样化能力和可定制的新闻属性目标分布，生成多样化的新闻推荐，在多样性和计算效率方面优于现有神经模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决新闻推荐系统中缺乏多样性和透明度的问题，让编辑能够将社会规范和价值观融入推荐过程，提供更加多样化和符合社会需求的新闻推荐。

Method: 采用多样性驱动的随机游走算法（D-RDW），结合传统随机游走算法的多样化能力和可定制的新闻属性目标分布，通过透明的方式让编辑可以调整推荐参数。

Result: 在考虑文章情感和政治党派提及的关键多样性指标上表现优于最先进的神经模型，同时计算效率更高。

Conclusion: D-RDW提供了一种轻量级、透明且高效的新闻推荐方法，能够有效提升推荐多样性并允许编辑参与价值观的融入，在多样性和计算效率方面都具有优势。

Abstract: This paper introduces Diversity-Driven RandomWalks (D-RDW), a lightweight
algorithm and re-ranking technique that generates diverse news recommendations.
D-RDW is a societal recommender, which combines the diversification
capabilities of the traditional random walk algorithms with customizable target
distributions of news article properties. In doing so, our model provides a
transparent approach for editors to incorporate norms and values into the
recommendation process. D-RDW shows enhanced performance across key diversity
metrics that consider the articles' sentiment and political party mentions when
compared to state-of-the-art neural models. Furthermore, D-RDW proves to be
more computationally efficient than existing approaches.

</details>


### [171] [Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation](https://arxiv.org/abs/2508.13064)
*Seongeun Ryu,Yunyong Ko,Sang-Wook Kim*

Main category: cs.IR

TL;DR: LIME是一个新颖的新闻推荐框架，通过用户-主题生命周期感知、候选感知生命周期注意力和新鲜度引导的兴趣细化，解决了时间相关挑战，显著提升了推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 现有新闻推荐方法在利用点击新闻的年龄推断用户兴趣持久性和建模不同主题和用户间新闻生命周期变化方面存在不足，需要解决这两个时间相关挑战。

Method: 提出LIME框架，包含三个核心策略：用户-主题生命周期感知的年龄表示、候选感知生命周期注意力生成时间对齐的用户表示、新鲜度引导的兴趣细化优先选择有效候选新闻。

Result: 在两个真实世界数据集上的大量实验表明，LIME持续优于多种最先进的新闻推荐方法，其模型无关策略显著提高了推荐准确性。

Conclusion: LIME框架有效解决了新闻推荐中的时间相关挑战，通过生命周期感知的方法提升了兴趣匹配效果，具有很好的泛化性和实用性。

Abstract: Personalized news recommendation aims to deliver news articles aligned with
users' interests, serving as a key solution to alleviate the problem of
information overload on online news platforms. While prior work has improved
interest matching through refined representations of news and users, the
following time-related challenges remain underexplored: (C1) leveraging the age
of clicked news to infer users' interest persistence, and (C2) modeling the
varying lifetime of news across topics and users. To jointly address these
challenges, we propose a novel Lifetime-aware Interest Matching framework for
nEws recommendation, named LIME, which incorporates three key strategies: (1)
User-Topic lifetime-aware age representation to capture the relative age of
news with respect to a user-topic pair, (2) Candidate-aware lifetime attention
for generating temporally aligned user representation, and (3) Freshness-guided
interest refinement for prioritizing valid candidate news at prediction time.
Extensive experiments on two real-world datasets demonstrate that LIME
consistently outperforms a wide range of state-of-the-art news recommendation
methods, and its model agnostic strategies significantly improve recommendation
accuracy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [172] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: 提出FAE方法从游戏视频中学习神经符号世界模型，用Retro Coder DSL表示，相比之前方法学习更精确的环境模型和更通用的代码


<details>
  <summary>Details</summary>
Motivation: 传统世界模型使用神经网络表示，导致学习的环境动态难以迁移和解释，需要更精确且可解释的表示方法

Method: FAE（有限自动机提取）方法，从游戏视频中学习神经符号世界模型，使用新的领域特定语言Retro Coder来表示程序

Result: 相比之前的世界模型方法，FAE学习了更精确的环境模型；相比之前的DSL方法，生成了更通用的代码

Conclusion: FAE方法能够有效解决世界模型的可迁移性和可解释性问题，通过学习神经符号表示提供更精确和通用的环境建模

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [173] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut是一个自动化生成整数规划加速割的框架，结合大语言模型和进化搜索，无需人工专家输入即可生成有效的割平面，显著提升求解器性能


<details>
  <summary>Details</summary>
Motivation: 整数规划是组合优化的核心但NP难问题，传统依赖专家手动设计加速割的方法效率低且难以自动化，需要开发自动化生成割平面的方法

Method: 结合大语言模型和进化搜索：1）LLM初始化多样化候选割；2）评估割保持最优解和切割分数解的能力；3）通过进化交叉和变异迭代优化种群

Result: EvoCut在固定时间内将最优性间隙降低17-57%，获得相同解的速度提升4倍，在相同时间内获得更高质量的解

Conclusion: EvoCut成功实现了整数规划加速割的自动化生成，无需人工专家输入，生成的割平面具有良好的泛化能力，显著提升了求解器性能

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [174] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LARC是首个基于LLM的约束逆合成规划代理框架，通过工具驱动的Agent-as-a-Judge机制将约束评估直接整合到逆合成规划过程中，在48个约束任务上达到72.9%的成功率，远超LLM基线并接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 约束逆合成规划是化学中识别从商业可得起始材料到目标分子合成路线的关键但具有挑战性的过程，需要满足实际约束条件。现有方法在约束处理方面存在不足。

Method: LARC框架采用基于工具的Agent-as-a-Judge机制，通过工具驱动的理性决策将约束评估直接整合到逆合成规划过程中，使用基于工具的代理反馈来指导和约束路线生成。

Result: 在精心策划的48个约束逆合成规划任务（涵盖3种约束类型）上，LARC达到72.9%的成功率，显著优于LLM基线方法，并在更短时间内接近人类专家水平。

Conclusion: LARC框架具有可扩展性，是朝着为人类专家提供有效代理工具或合作科学家的第一步，可用于约束逆合成规划。

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [175] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed开发了一个高性能医疗基础模型，通过医学数据处理、检索增强生成和大规模强化学习，在医疗执照考试中达到70%准确率，已服务数百万用户。


<details>
  <summary>Details</summary>
Motivation: 医疗任务需要高度专业化的知识、专业准确性和定制能力，需要强大可靠的基础模型来支持AI医疗咨询、诊断报告辅助和医学搜索工具。

Method: 利用精选医学数据处理、医学内容检索增强生成(RAG)和大规模可验证强化学习管道来开发医疗基础模型。

Result: 在中国医疗执照考试中达到70%的准确率，在多样化医疗基准测试中展现出强大的泛化能力。

Conclusion: QuarkMed提供了一个强大而多功能的个人医疗AI解决方案，已在ai.quark.cn服务超过百万用户。

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [176] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: 提出了CHBench评估框架，基于认知层次模型评估LLMs的策略推理能力，发现聊天机制会降低策略推理，而记忆机制能增强策略推理


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖效用性能指标评估LLMs的游戏能力，但这些指标不够鲁棒，受对手行为和游戏结构变化影响较大

Method: 采用认知层次模型的三阶段系统框架，在15个精选的正规形式游戏中收集6个最先进LLMs的行为数据进行分析

Result: LLMs在不同对手间展现出一致的战略推理水平，聊天机制显著降低策略推理能力，记忆机制则能增强策略推理

Conclusion: CHBench是一个有前景的LLM能力评估工具，具有重要的研究和应用潜力

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [177] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 通过建模有效数据转移和利用缩放定律，提出了一种优化超应用精调数据混合的方法，能够最小化验证损失并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 超应用精调数据混合的优化对发展通用大语言模型至关重要，但这个领域目前研究不够深入。需要找到一种系统的方法来最优化数据混合比例。

Method: 将数据混合框架为优化问题，通过建模有效数据转移和利用缩放定律来参数化损失函数。在小规模数据混合上进行实验来拟合这些参数，然后求解最优权重。

Result: 算法在所有领域都取得了优异的整体和个别性能。优化权重训练的模型性能与逐个搜索确定的最优权重相当，每个领域损失仅比网格搜索的最优值平均高出0.66%。重新权重调整流行的SFT数据集能够改善验证损失和下游任务性能。

Conclusion: 该方法提供了一种有效的数据混合优化方案，能够指导领域特定模型的数据选择，并为SFT过程提供了深入的见解。方法具有数学严格证明和实验验证。

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [178] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast是一个参数高效的多模态时间序列预测框架，通过整合视觉和文本模态信息来增强传统时间序列基础模型的性能


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型主要在单模态设置下运行，忽略了现实场景中常伴随时间序列数据的丰富多模态上下文信息（如视觉和文本信号）

Method: 通过软提示调优将预训练的视觉和文本编码器的模态特定嵌入与冻结的时间序列基础模型集成，实现高效的参数适应和跨模态交互

Result: 在多个时间序列预测基准测试中，UniCast始终显著优于所有现有的时间序列基础模型基线

Conclusion: 多模态上下文在推进下一代通用时间序列预测器发展中起着关键作用

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [179] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出了两种基于Shapley值和Banzhaf指数的新特征重要性评分方法，考虑了非弱溯因解释集对排除对抗样本的贡献。


<details>
  <summary>Details</summary>
Motivation: 现有基于博弈论的特征归因方法主要关注弱溯因解释(WAXp)集，但忽略了非WAXp集的重要信息，而这些集与对抗样本(AExs)存在重要关系。

Method: 利用Shapley值和Banzhaf指数设计两种新的特征重要性评分，在计算特征贡献时考虑非WAXp集，量化每个特征在排除对抗样本方面的有效性。

Result: 提出了两种新的特征重要性评分方法，能够更全面地评估特征对模型解释性和鲁棒性的贡献。

Conclusion: 新方法通过纳入非WAXp集的信息，提供了更完整的特征重要性评估框架，有助于提高可解释AI在高风险机器学习应用中的可靠性。

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [180] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 通过代码生成和执行的图表合成流程生成对齐的图表-问题-答案三元组，结合候选条件化答题过程，在无人工标注或外部模型的情况下实现了视觉语言模型的自成长改进


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在图表理解任务中遇到困难，特别是准确的图表描述和复杂推理。合成数据生成是有前景的解决方案，但常面临噪声标签的挑战

Method: 1）设计了通过代码生成和执行的图表合成流程，生成对齐的图表-问题-答案三元组；2）受测试时扩缩的启发，设计了候选条件化答题过程，先生成多个响应，然后通过上下文化合成最终答案

Result: 实验表明了显著改进，在完全自成长范式下实现了超过15.50个正确率点的提升，无需人工标注数据或外部模型

Conclusion: 该方法通过可靠的合成数据生成和候选条件化答题机制，有效解决了VLM在图表理解任务中的挑战，实现了高效的自成长改进

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [181] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX是一个专为LLM智能体设计的动态实时未来预测评估基准，支持每日实时更新，通过自动化流程避免数据污染，评估了25个模型在动态环境中的适应性推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模的未来预测评估基准，主要由于处理实时更新和获取及时准确答案的挑战，需要建立动态无污染的标准来推动LLM智能体达到专业人类分析师水平的复杂推理和预测能力。

Method: 构建FutureX动态实时评估基准，支持每日实时更新，采用自动化问题收集和答案收集流程，评估25个具有推理、搜索能力和外部工具集成的LLM/智能体模型。

Result: 建立了最大最多样化的实时未来预测基准，提供了对智能体在面向未来任务中失败模式和性能缺陷的深入分析，包括对虚假网页的脆弱性和时间有效性等问题。

Conclusion: FutureX为LLM智能体的未来预测能力建立了动态、无污染的评估标准，将推动智能体在复杂推理和预测思维方面达到专业人类分析师水平的发展。

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [182] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer是一个用于AIG图表示学习的新方法，通过节点逻辑特征初始化和异构图卷积网络，在信号概率预测和真值表距离预测任务上显著优于现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法无法联合建模AIG图的功能和结构特征，以及动态信息传播能力不足的问题，提升EDA领域逻辑电路设计的自动化水平。

Method: 包含两个组件：1)节点逻辑特征初始化嵌入组件，将逻辑节点投影到独立语义空间；2)AIG特征学习网络组件，使用异构图卷积网络设计动态关系权重矩阵和差异化信息聚合方法。

Result: 在信号概率预测任务上，MAE和MSE分别提升18.95%和44.44%；在真值表距离预测任务上，MAE和MSE分别提升33.57%和14.79%。

Conclusion: AIGer通过有效联合建模功能与结构特征，显著提升了AIG图的表示学习性能，为EDA领域的电路设计自动化提供了有力工具。

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [183] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: AgentCDM是一个基于认知科学竞争假设分析(ACH)的结构化框架，用于提升LLM多智能体系统中的协作决策质量，通过两阶段训练有效缓解认知偏见并实现主动假设评估


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统协作决策方法存在缺陷：要么依赖单个智能体的'独裁'策略易受认知偏见影响，要么采用'投票制'方法无法充分利用集体智慧

Method: 提出AgentCDM框架，引入结构化推理范式，采用两阶段训练：第一阶段使用ACH启发的显式支架引导结构化推理，第二阶段逐步移除支架以促进自主泛化

Result: 在多个基准数据集上的实验表明，AgentCDM实现了最先进的性能，并展现出强大的泛化能力

Conclusion: AgentCDM有效提升了多智能体系统中协作决策的质量和鲁棒性，验证了结构化推理范式在缓解认知偏见和促进主动决策方面的有效性

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [184] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [185] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: 提出了Bongard-RWR+数据集，包含5400个实例，使用VLM生成真实世界图像来表示原始Bongard问题的抽象概念，评估发现VLM在细粒度概念识别方面存在困难


<details>
  <summary>Details</summary>
Motivation: 现有的Bongard问题数据集要么使用合成图像缺乏真实世界复杂性，要么使用真实图像但概念过于简单，且Bongard-RWR数据集规模太小限制了评估鲁棒性

Method: 使用Pixtral-12B描述手动策划的图像并生成新描述，用Flux.1-dev从描述合成图像，手动验证生成图像是否忠实反映目标概念，构建了5400个实例的数据集

Result: 评估显示VLM能够识别粗粒度视觉概念，但在辨别细粒度概念方面持续存在困难

Conclusion: VLM在抽象视觉推理方面存在局限性，特别是在细粒度概念识别上表现不佳，Bongard-RWR+数据集为评估VLM的推理能力提供了更好的基准

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [186] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 主动推断是一种基于贝叶斯推断的认知形式描述。本文比较了动作意识和动作无意识代理在导航任务中的性能差异，发现动作无意识代理虽处于不利地位仍能达到相似的性能水平。


<details>
  <summary>Details</summary>
Motivation: 研究主动推断框架中不同行动规划策略的性能差异，特别是比较动作意识（知道自身行动）和动作无意识（需要推断自身行动）代理在实际任务中的表现。

Method: 在两个导航任务中比较了动作意识和动作无意识代理的性能。这些代理通过最小化变分自由能和预期自由能来进行认知和行动规划。

Result: 动作无意识代理虽然处于严重不利地位，但在导航任务中达到了与动作意识代理相似的性能水平。

Conclusion: 这一结果显示了主动推断框架的强大适应能力，即使在缺乏直接行动知识的情况下，代理仍能通过推断来实现有效的行为控制。

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>


### [187] [MAPF-World: Action World Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.12087)
*Zhanjiang Yang,Meng Li,Yang Shen,Yueming Li,Lijun Sun*

Main category: cs.AI

TL;DR: MAPF-World是一个用于多智能体路径规划的自回归世界模型，通过显式建模环境时空动态和智能体间依赖关系，在复杂长期规划场景中优于现有可学习求解器，且模型大小减少96.5%，数据需求减少92%。


<details>
  <summary>Details</summary>
Motivation: 现有的分散式可学习求解器在复杂长期规划场景中表现受限，主要因为缺乏对环境时序动态和智能体间依赖关系的充分建模，导致性能下降。

Method: 提出MAPF-World自回归动作世界模型，统一情境理解和动作生成，通过预测未来状态和动作来显式建模空间特征和时序依赖关系，并引入基于真实场景的自动地图生成器来增强基准测试。

Result: 大量实验表明MAPF-World在零样本泛化到分布外案例方面优于最先进的可学习求解器，展现出卓越的性能。

Conclusion: MAPF-World通过建模环境动态和未来预测实现了更明智、协调和远见的决策，特别是在复杂多智能体设置中，同时显著减少了模型大小和数据需求。

Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free
paths from the designated start locations to goal positions for multiple
agents. It underlies a variety of real-world tasks, including multi-robot
coordination, robot-assisted logistics, and social navigation. Recent
decentralized learnable solvers have shown great promise for large-scale MAPF,
especially when leveraging foundation models and large datasets. However, these
agents are reactive policy models and exhibit limited modeling of environmental
temporal dynamics and inter-agent dependencies, resulting in performance
degradation in complex, long-term planning scenarios. To address these
limitations, we propose MAPF-World, an autoregressive action world model for
MAPF that unifies situation understanding and action generation, guiding
decisions beyond immediate local observations. It improves situational
awareness by explicitly modeling environmental dynamics, including spatial
features and temporal dependencies, through future state and actions
prediction. By incorporating these predicted futures, MAPF-World enables more
informed, coordinated, and far-sighted decision-making, especially in complex
multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an
automatic map generator grounded in real-world scenarios, capturing practical
map layouts for training and evaluating MAPF solvers. Extensive experiments
demonstrate that MAPF-World outperforms state-of-the-art learnable solvers,
showcasing superior zero-shot generalization to out-of-distribution cases.
Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced
data.

</details>


### [188] [Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios](https://arxiv.org/abs/2508.12100)
*Daniel Burkhardt,Xiangwei Cheng*

Main category: cs.AI

TL;DR: 提出了ReT-Eval框架，通过两阶段方法从稀疏知识图谱中提取语义相关知识结构并修剪推理线程，提升交互式问题解决中的推理效果


<details>
  <summary>Details</summary>
Motivation: 当前推理模型缺乏显式语义层次结构、用户-领域知识对齐以及修剪推理线程的原则性机制，导致冗长通用输出无法指导用户进行目标导向推理

Method: 原型启发的两阶段推理线程评估框架：第一阶段使用图神经网络从稀疏领域知识图谱提取语义相关知识结构，并用LLM知识丰富以解决知识差异；第二阶段使用奖励引导策略评估和修剪线程以保持语义连贯性

Result: 实验和专家评估显示ReT-Eval增强了用户理解能力，并优于最先进的推理模型

Conclusion: ReT-Eval框架通过结构化知识重用和原则性线程修剪机制，有效解决了交互式问题解决场景中的推理挑战

Abstract: Reasoning in interactive problem solving scenarios requires models to
construct reasoning threads that reflect user understanding and align with
structured domain knowledge. However, current reasoning models often lack
explicit semantic hierarchies, user-domain knowledge alignment, and principled
mechanisms to prune reasoning threads for effectiveness. These limitations
result in lengthy generic output that does not guide users through
goal-oriented reasoning steps. To address this, we propose a
prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)
framework, drawing inspiration from human-like reasoning strategies that
emphasize structured knowledge reuse. In the first phase, semantically relevant
knowledge structures are extracted from a sparse domain knowledge graph using a
graph neural network and enriched with intrinsic large language model knowledge
to resolve knowledge discrepancies. In the second phase, these threads are
evaluated and pruned using a reward-guided strategy aimed at maintaining
semantic coherence to generate effective reasoning threads. Experiments and
expert evaluations show that ReT-Eval enhances user understanding and
outperforms state-of-the-art reasoning models.

</details>


### [189] [MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization](https://arxiv.org/abs/2508.12149)
*Haochen You,Baojing Liu*

Main category: cs.AI

TL;DR: MOVER是一个多模态学习框架，通过最优传输软对齐和几何体积正则化，在共享嵌入空间中构建语义对齐的结构化多模态表示，显著提升了多模态检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态学习方法主要依赖成对对比目标，虽然在双模态设置中有效，但在多模态场景下泛化能力不足，且在高维空间中缺乏语义结构。

Method: 结合最优传输软对齐和基于体积的几何正则化（GAVE），通过传输引导的匹配机制和几何体积最小化目标，实现模态无关的一致性对齐。

Result: 在文本-视频-音频检索任务中，MOVER在零样本和微调设置下均显著优于现有最先进方法，展现出更好的未见模态组合泛化能力和更强的嵌入空间结构一致性。

Conclusion: MOVER框架通过整合最优传输和几何正则化，成功解决了多模态对齐中的语义结构缺失问题，为构建更有效的多模态表示提供了新思路。

Abstract: Recent advances in multimodal learning have largely relied on pairwise
contrastive objectives to align different modalities, such as text, video, and
audio, in a shared embedding space. While effective in bi-modal setups, these
approaches struggle to generalize across multiple modalities and often lack
semantic structure in high-dimensional spaces. In this paper, we propose MOVER,
a novel framework that combines optimal transport-based soft alignment with
volume-based geometric regularization to build semantically aligned and
structured multimodal representations. By integrating a transport-guided
matching mechanism with a geometric volume minimization objective (GAVE), MOVER
encourages consistent alignment across all modalities in a modality-agnostic
manner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER
significantly outperforms prior state-of-the-art methods in both zero-shot and
finetuned settings. Additional analysis shows improved generalization to unseen
modality combinations and stronger structural consistency in the learned
embedding space.

</details>


### [190] [RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards](https://arxiv.org/abs/2508.12165)
*Rohit Krishnan,Jon Evans*

Main category: cs.AI

TL;DR: RLNVR框架使用未经验证的噪声奖励信号训练语言模型，通过基线归一化和语义相似度奖励转移解决传统RLHF需要昂贵验证奖励的问题。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF需要昂贵的人工验证奖励信号，在现实世界中不实用。需要一种能够利用噪声、真实世界反馈信号的方法来训练语言模型。

Method: 结合基线归一化、语义相似度奖励转移、GSPO（组序列策略优化）和可选的UED（无监督环境设计）课程，在噪声隐式奖励下提高稳定性和多样性。

Result: 实验结果显示在内容质量和训练稳定性方面有显著改进，通过Walter原型系统在Bluesky社交媒体的实际参与数据上进行了验证。

Conclusion: RLNVR提供了一个实用的框架，能够在不需要显式人类验证的情况下，利用现实世界的噪声反馈信号有效训练语言模型，为实际应用场景提供了可行的解决方案。

Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified
Rewards), a framework for training language models using noisy, real-world
feedback signals without requiring explicit human verification. Traditional
RLHF requires expensive, verified reward signals that are impractical in many
real-world domains. RLNVR addresses this challenge through baseline
normalization and semantic similarity-based reward transfer. We demonstrate
RLNVR through Walter, a prototype system that optimizes social media content
generation using actual engagement data from Bluesky. Our experimental results
show significant improvements in content quality and training stability, with
comprehensive evaluation planned for future work. Positioning: We present a
practical framework that combines RLNVR with GSPO (Group Sequence Policy
Optimization) and an optional UED (Unsupervised Environment Design) curriculum
to improve stability and diversity under noisy, implicit rewards. To our
knowledge, combining GSPO-style normalization with a UED-style curriculum for
LLM content generation from implicit social engagement has not been previously
documented in this applied setting; we frame this as an applied integration
rather than a new algorithm.

</details>


### [191] [Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting](https://arxiv.org/abs/2508.12260)
*Carson Dudley,Reiden Magdaleno,Christopher Harding,Ananya Sharma,Emily Martin,Marisa Eisenberg*

Main category: cs.AI

TL;DR: Mantis是一个基于机制模拟训练的传染病预测基础模型，无需真实数据训练就能在多种疾病和场景中实现开箱即用的准确预测，性能超越39个专家调优模型。


<details>
  <summary>Details</summary>
Motivation: 传统传染病预测模型需要疾病特定数据、定制化训练和专家调优，在新发疫情或资源匮乏地区应用受限。

Method: 基于超过4亿天模拟疫情动态数据训练，涵盖多种病原体、传播模式、干预措施和监测伪影，完全使用机制模拟数据而非真实数据。

Result: 在六种疾病测试中超越所有39个专家模型，包括CDC COVID-19预测中心的所有模型，能泛化到新的流行病学机制，提供8周预测范围。

Conclusion: Mantis作为下一代疾病预测系统的基础，具有通用性、可解释性和在传统模型失败场景中的可部署性。

Abstract: Infectious disease forecasting in novel outbreaks or low resource settings
has been limited by the need for disease-specific data, bespoke training, and
expert tuning. We introduce Mantis, a foundation model trained entirely on
mechanistic simulations, which enables out-of-the-box forecasting across
diseases, regions, and outcomes, even in settings with limited historical data.
Mantis is built on over 400 million simulated days of outbreak dynamics
spanning diverse pathogens, transmission modes, interventions, and surveillance
artifacts. Despite requiring no real-world data during training, Mantis
outperformed 39 expert-tuned models we tested across six diseases, including
all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel
epidemiological regimes, including diseases with held-out transmission
mechanisms, demonstrating that it captures fundamental contagion dynamics.
Critically, Mantis is mechanistically interpretable, enabling public health
decision-makers to identify the latent drivers behind its predictions. Finally,
Mantis delivers accurate forecasts at 8-week horizons, more than doubling the
actionable range of most models, enabling proactive public health planning.
Together, these capabilities position Mantis as a foundation for
next-generation disease forecasting systems: general, interpretable, and
deployable where traditional models fail.

</details>


### [192] [RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts](https://arxiv.org/abs/2508.12291)
*Xuming He,Zhiyuan You,Junchao Gong,Couhua Liu,Xiaoyu Yue,Peiqin Zhuang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: 提出了RadarQA方法，使用多模态大语言模型进行天气预报质量分析，结合物理属性和详细评估报告，构建了大规模数据集RQA-70K，在多个评估场景中优于现有通用MLLM模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于分数的天气预报评估指标在描述能力、可解释性和动态演化理解方面与气象专家存在差距，需要更先进的评估方法。

Method: 开发了RadarQA方法，整合关键物理属性和详细评估报告；设计了混合标注流程结合人工专家标注和自动化启发式方法；构建了RQA-70K大规模数据集；采用多阶段训练策略迭代提升模型性能。

Result: 实验表明RadarQA在所有评估设置中都优于现有的通用多模态大语言模型，显示出在天气预报质量分析方面的潜力。

Conclusion: RadarQA方法通过整合多模态大语言模型和专门设计的评估框架，显著提升了天气预报质量分析的能力，为气象预测质量评估提供了新的有效工具。

Abstract: Quality analysis of weather forecasts is an essential topic in meteorology.
Although traditional score-based evaluation metrics can quantify certain
forecast errors, they are still far from meteorological experts in terms of
descriptive capability, interpretability, and understanding of dynamic
evolution. With the rapid development of Multi-modal Large Language Models
(MLLMs), these models become potential tools to overcome the above challenges.
In this work, we introduce an MLLM-based weather forecast analysis method,
RadarQA, integrating key physical attributes with detailed assessment reports.
We introduce a novel and comprehensive task paradigm for multi-modal quality
analysis, encompassing both single frame and sequence, under both rating and
assessment scenarios. To support training and benchmarking, we design a hybrid
annotation pipeline that combines human expert labeling with automated
heuristics. With such an annotation method, we construct RQA-70K, a large-scale
dataset with varying difficulty levels for radar forecast quality evaluation.
We further design a multi-stage training strategy that iteratively improves
model performance at each stage. Extensive experiments show that RadarQA
outperforms existing general MLLMs across all evaluation settings, highlighting
its potential for advancing quality analysis in weather prediction.

</details>


### [193] [Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback](https://arxiv.org/abs/2508.12338)
*Wenzhen Yuan,Shengji Tang,Weihao Lin,Jiacheng Ruan,Ganqu Cui,Bo Zhang,Tao Chen,Ting Liu,Yuzhuo Fu,Peng Ye,Lei Bai*

Main category: cs.AI

TL;DR: 基于多模型协同进化的新型强化学习框架RLCCF，通过集体一致性投票提供奖励信号，免除了人工标注或复杂奖励模型的需求，在数学推理任务上实现了显著性能提升


<details>
  <summary>Details</summary>
Motivation: 解决传统强化学习对贵美人工标注数据或复杂奖励模型的依赖问题，以及单一模型自我反馈方法容易出现过信任错误答案、奖励攻击和训练崩溃等问题

Method: 提出RLCCF框架，通过最大化集体一致性(CC)来优化模型集群能力，共同训练多样化的LLMs集成，通过投票集体输出来提供奖励信号。每个模型的投票权重由其自身一致性(SC)分数决定

Result: 在4个主流开源LLM和4个数学推理测试集上，实验结果显示性能获得显著提升，准确率平均相对提升16.72%。不仅改善了单个模型性能，还将集体多数投票准确率提升了4.51%

Conclusion: RLCCF框架能够在无外部监督的情况下实现多模型协同进化，通过多样化输出分布和互补能力，使得模型集群能够持续提升推理能力，扩展了集体能力的边界

Abstract: Reinforcement learning (RL) has significantly enhanced the reasoning
capabilities of large language models (LLMs), but its reliance on expensive
human-labeled data or complex reward models severely limits scalability. While
existing self-feedback methods aim to address this problem, they are
constrained by the capabilities of a single model, which can lead to
overconfidence in incorrect answers, reward hacking, and even training
collapse. To this end, we propose Reinforcement Learning from Coevolutionary
Collective Feedback (RLCCF), a novel RL framework that enables multi-model
collaborative evolution without external supervision. Specifically, RLCCF
optimizes the ability of a model collective by maximizing its Collective
Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides
reward signals by voting on collective outputs. Moreover, each model's vote is
weighted by its Self-Consistency (SC) score, ensuring that more confident
models contribute more to the collective decision. Benefiting from the diverse
output distributions and complementary abilities of multiple LLMs, RLCCF
enables the model collective to continuously enhance its reasoning ability
through coevolution. Experiments on four mainstream open-source LLMs across
four mathematical reasoning benchmarks demonstrate that our framework yields
significant performance gains, achieving an average relative improvement of
16.72\% in accuracy. Notably, RLCCF not only improves the performance of
individual models but also enhances the group's majority-voting accuracy by
4.51\%, demonstrating its ability to extend the collective capability boundary
of the model collective.

</details>


### [194] [Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems](https://arxiv.org/abs/2508.12375)
*Yu Sha,Shuiping Gou,Bo Liu,Johannes Faber,Ningtao Liu,Stefan Schramm,Horst Stoecker,Thomas Steckenreiter,Domagoj Vnucec,Nadine Wetzstein,Andreas Widl,Kai Zhou*

Main category: cs.AI

TL;DR: 本文提出了一种基于图卷积网络的层次知识导向故障强度诊断框架(HKG)，通过嵌入类间层次关系知识来改善故障诊断性能。


<details>
  <summary>Details</summary>
Motivation: 当前的故障强度诊断方法基于链式思维而没有考虑目标类之间的依赖关系，导致性能限制。

Method: 提出HKG框架，使用图卷积网络将类表征的层次拓扑图映射到一组相互依赖的全局层次分类器，并开发了重加权层次知识相关矩阵(Re-HKCM)方案。

Result: 在四个实际工业领域数据集上进行实验，结果显示该方法超越了最新的故障强度诊断方法。

Conclusion: HKG框架通过抓取类间层次依赖关系，有效提升了故障诊断的性能，为复杂工业系统的监控和维护提供了新的解决方案。

Abstract: Fault intensity diagnosis (FID) plays a pivotal role in monitoring and
maintaining mechanical devices within complex industrial systems. As current
FID methods are based on chain of thought without considering dependencies
among target classes. To capture and explore dependencies, we propose a
hierarchical knowledge guided fault intensity diagnosis framework (HKG)
inspired by the tree of thought, which is amenable to any representation
learning methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set of
interdependent global hierarchical classifiers, where each node is denoted by
word embeddings of a class. These global hierarchical classifiers are applied
to learned deep features extracted by representation learning, allowing the
entire model to be end-to-end learnable. In addition, we develop a re-weighted
hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical correlation
matrix (SCM) which effectively guides the information sharing of nodes in
graphical convolutional neural networks and avoids over-smoothing issues. The
Re-HKCM is derived from the SCM through a series of mathematical
transformations. Extensive experiments are performed on four real-world
datasets from different industrial domains (three cavitation datasets from
SAMSON AG and one existing publicly) for FID, all showing superior results and
outperform recent state-of-the-art FID methods.

</details>


### [195] [GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](https://arxiv.org/abs/2508.12379)
*Rongzheng Wang,Qizhi Chen,Yihong Huang,Yizhuo Ma,Muquan Li,Jiakai Li,Ke Qin,Guangchun Luo,Shuang Liang*

Main category: cs.AI

TL;DR: GraphCogent是一个基于工作记忆模型的协作代理框架，通过将图推理分解为感知、缓冲和执行三个认知过程，有效解决了大语言模型在处理复杂图拓扑和多步推理时的局限性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在小规模图推理任务上表现良好，但在处理具有复杂查询的真实世界图时失败，主要原因是无法同时有效处理复杂图拓扑和执行多步推理。

Method: 提出GraphCogent框架，包含三个模块：感知模块通过子图采样标准化图文本表示，缓冲模块集成和索引多格式图数据，执行模块结合工具调用和模型生成进行高效推理。

Result: 基于Llama3.1-8B的GraphCogent相比DeepSeek-R1(671B)提升50%性能，相比最先进的基于代理的基线方法，准确率提高20%，同时token使用量减少80%（工具内任务）和30%（工具外任务）。

Conclusion: GraphCogent框架通过模拟人类工作记忆的认知过程，有效提升了LLMs在复杂图推理任务上的性能，同时显著降低了计算资源消耗。

Abstract: Large language models (LLMs) show promising performance on small-scale graph
reasoning tasks but fail when handling real-world graphs with complex queries.
This phenomenon stems from LLMs' inability to effectively process complex graph
topology and perform multi-step reasoning simultaneously. To address these
limitations, we propose GraphCogent, a collaborative agent framework inspired
by human Working Memory Model that decomposes graph reasoning into specialized
cognitive processes: sense, buffer, and execute. The framework consists of
three modules: Sensory Module standardizes diverse graph text representations
via subgraph sampling, Buffer Module integrates and indexes graph data across
multiple formats, and Execution Module combines tool calling and model
generation for efficient reasoning. We also introduce Graph4real, a
comprehensive benchmark contains with four domains of real-world graphs (Web,
Social, Transportation, and Citation) to evaluate LLMs' graph reasoning
capabilities. Our Graph4real covers 21 different graph reasoning tasks,
categorized into three types (Structural Querying, Algorithmic Reasoning, and
Predictive Modeling tasks), with graph scales that are 10 times larger than
existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent
achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).
Compared to state-of-the-art agent-based baseline, our framework outperforms by
20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%
for out-toolset tasks. Code will be available after review.

</details>


### [196] [Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning](https://arxiv.org/abs/2508.12425)
*Phuong Minh Nguyen,Tien Huu Dang,Naoya Inoue*

Main category: cs.AI

TL;DR: Symbolic-Aided CoT通过在少样本提示中集成轻量级符号表示，改进了标准思维链方法，提升了LLM在逻辑推理中的透明度、可解释性和分析能力，在多个复杂推理基准上显著优于传统CoT。


<details>
  <summary>Details</summary>
Motivation: 标准思维链方法在逻辑推理中缺乏透明度和可解释性，需要一种能够保持通用性同时增强推理过程可分析性的改进方法。

Method: 在少样本提示中集成轻量级符号表示，使用一致的策略构建推理步骤，使推理模式在非迭代推理过程中更加明确。

Result: 在ProofWriter、FOLIO、ProntoQA和LogicalDeduction四个基准测试中表现优异，特别是在需要处理多重约束或规则的复杂推理任务中，在三个数据集上显著优于传统CoT。

Conclusion: Symbolic-Aided CoT方法有效提升了LLM的逻辑推理能力，增强了推理过程的透明度和可解释性，在不同规模的模型上都取得了一致的性能提升。

Abstract: This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved
approach to standard CoT, for logical reasoning in large language models
(LLMs). The key idea is to integrate lightweight symbolic representations into
few-shot prompts, structuring the inference steps with a consistent strategy to
make reasoning patterns more explicit within a non-iterative reasoning process.
By incorporating these symbolic structures, our method preserves the
generalizability of standard prompting techniques while enhancing the
transparency, interpretability, and analyzability of LLM logical reasoning.
Extensive experiments on four well-known logical reasoning benchmarks --
ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse
reasoning scenarios -- demonstrate the effectiveness of the proposed approach,
particularly in complex reasoning tasks that require navigating multiple
constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'
reasoning capabilities across various model sizes and significantly outperforms
conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and
LogicalDeduction.

</details>


### [197] [Cognitive Structure Generation: From Educational Priors to Policy Optimization](https://arxiv.org/abs/2508.12647)
*Hengnian Gu,Zhifu Chen,Yuxin Chen,Jin Peng Zhou,Dongdai Zhou*

Main category: cs.AI

TL;DR: 提出Cognitive Structure Generation (CSG)框架，通过预训练扩散概率模型和强化学习优化，从教育先验生成学生认知结构，显著提升学生建模效果


<details>
  <summary>Details</summary>
Motivation: 认知结构是学生对知识系统的主观组织，但长期以来在教育实践中难以评估，成为学生建模和心理测量学的挑战

Method: 首先预训练Cognitive Structure Diffusion Probabilistic Model (CSDPM)从教育先验生成认知结构，然后通过强化学习的分层奖励信号优化生成过程，使其与真实认知发展水平对齐

Result: 在四个真实教育数据集上的实验表明，CSG生成的认知结构为学生建模提供了更全面有效的表示，显著提升了知识追踪(KT)和认知诊断(CD)任务的性能，同时增强了可解释性

Conclusion: CSG框架成功解决了认知结构评估的难题，为教育实践提供了可操作的学生认知结构生成方法，具有重要的理论和实践价值

Abstract: Cognitive structure is a student's subjective organization of an objective
knowledge system, reflected in the psychological construction of concepts and
their relations. However, cognitive structure assessment remains a
long-standing challenge in student modeling and psychometrics, persisting as a
foundational yet largely unassessable concept in educational practice. This
paper introduces a novel framework, Cognitive Structure Generation (CSG), in
which we first pretrain a Cognitive Structure Diffusion Probabilistic Model
(CSDPM) to generate students' cognitive structures from educational priors, and
then further optimize its generative process as a policy with hierarchical
reward signals via reinforcement learning to align with genuine cognitive
development levels during students' learning processes. Experimental results on
four popular real-world education datasets show that cognitive structures
generated by CSG offer more comprehensive and effective representations for
student modeling, substantially improving performance on KT and CD tasks while
enhancing interpretability.

</details>


### [198] [GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](https://arxiv.org/abs/2508.12472)
*Yifang Tian,Yaming Liu,Zichun Chong,Zihang Huang,Hans-Arno Jacobsen*

Main category: cs.AI

TL;DR: GALA是一个多模态框架，结合统计因果推理和LLM驱动的迭代推理，用于微服务系统的根因分析，相比现有方法准确率提升42.22%，能提供可操作的诊断洞察和修复指导。


<details>
  <summary>Details</summary>
Motivation: 传统RCA方法通常只关注单一模态或仅对可疑服务进行排序，无法提供具有修复指导的可操作诊断洞察。微服务系统中的根因分析具有挑战性，需要工程师快速诊断跨异构遥测数据的故障。

Method: GALA结合统计因果推理与LLM驱动的迭代推理，通过多模态框架分析指标、日志和追踪等异构遥测数据，进行增强的根因分析。

Result: 在开源基准测试中，GALA相比最先进方法实现了高达42.22%的准确率提升。新颖的人工引导LLM评估分数显示，GALA生成的诊断输出在因果合理性和可操作性方面显著优于现有方法。

Conclusion: GALA通过提供准确的根因识别和人类可理解的修复指导，弥合了自动化故障诊断与实际事件解决之间的差距。

Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring
on-call engineers to rapidly diagnose failures across heterogeneous telemetry
such as metrics, logs, and traces. Traditional RCA methods often focus on
single modalities or merely rank suspect services, falling short of providing
actionable diagnostic insights with remediation guidance. This paper introduces
GALA, a novel multi-modal framework that combines statistical causal inference
with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an
open-source benchmark, GALA achieves substantial improvements over
state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM
evaluation score shows GALA generates significantly more causally sound and
actionable diagnostic outputs than existing methods. Through comprehensive
experiments and a case study, we show that GALA bridges the gap between
automated failure diagnosis and practical incident resolution by providing both
accurate root cause identification and human-interpretable remediation
guidance.

</details>


### [199] [OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943)
*Mary Tonwe*

Main category: cs.AI

TL;DR: OPTIC-ER是一个基于强化学习的紧急响应框架，通过注意力引导的actor-critic架构和精确奖励函数，在尼日利亚河流州实现了100%的最优调度率，为非洲低资源地区的公共服务提供了AI增强解决方案。


<details>
  <summary>Details</summary>
Motivation: 非洲地区公共服务系统存在紧急响应延迟和空间不平等问题，导致可避免的苦难，需要实时、自适应且公平的应急响应解决方案。

Method: 采用注意力引导的actor-critic强化学习架构，包含上下文丰富的状态向量和精确奖励函数，使用尼日利亚河流州真实数据在高保真模拟中训练，并基于TALS框架（薄计算、适应性、低成本、可扩展性）进行部署。

Result: 在500个未见事件评估中，OPTIC-ER实现了100.00%的最优率，效率损失可忽略不计，证明了其鲁棒性和泛化能力。

Conclusion: 这项工作为AI增强的公共服务提供了经过验证的蓝图，展示了情境感知强化学习如何弥合算法决策与可衡量人类影响之间的差距，并生成基础设施缺陷地图和公平监控仪表板来指导主动治理。

Abstract: Public service systems in many African regions suffer from delayed emergency
response and spatial inequity, causing avoidable suffering. This paper
introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,
adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided
actor-critic architecture to manage the complexity of dispatch environments.
Its key innovations are a Context-Rich State Vector, encoding action
sub-optimality, and a Precision Reward Function, which penalizes inefficiency.
Training occurs in a high-fidelity simulation using real data from Rivers
State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is
built on the TALS framework (Thin computing, Adaptability, Low-cost,
Scalability) for deployment in low-resource settings. In evaluations on 500
unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible
inefficiency, confirming its robustness and generalization. Beyond dispatch,
the system generates Infrastructure Deficiency Maps and Equity Monitoring
Dashboards to guide proactive governance and data-informed development. This
work presents a validated blueprint for AI-augmented public services, showing
how context-aware RL can bridge the gap between algorithmic decision-making and
measurable human impact.

</details>


### [200] [The Yokai Learning Environment: Tracking Beliefs Over Space and Time](https://arxiv.org/abs/2508.12480)
*Constantin Ruhdorfer,Matteo Bortoletto,Andreas Bulling*

Main category: cs.AI

TL;DR: 提出了Yokai学习环境(YLE)作为多智能体强化学习环境，用于评估心智理论能力，发现当前RL智能体在信念建模、记忆和泛化方面存在显著不足


<details>
  <summary>Details</summary>
Motivation: 现有心智理论基准局限于被动观察者设置，缺乏对智能体如何随时间建立和维护共同基础的评估，需要新的评估环境

Method: 基于合作卡牌游戏Yokai构建多智能体强化学习环境YLE，智能体需要查看隐藏卡片、移动卡片形成颜色簇，并跟踪演化信念和使用提示进行沟通

Result: 当前RL智能体即使在有完美记忆的情况下也难以解决YLE任务；信念建模能提升性能但无法有效泛化到未见过的伙伴或形成长期准确信念

Conclusion: YLE揭示了智能体依赖脆弱的约定而非稳健的信念跟踪，为信念建模、记忆、伙伴泛化和高阶心智理论研究提供了重要平台

Abstract: Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to
reason about the beliefs of others to build and maintain common ground.
Existing ToM benchmarks, however, are restricted to passive observer settings
or lack an assessment of how agents establish and maintain common ground over
time. To address these gaps, we introduce the Yokai Learning Environment (YLE)
- a multi-agent reinforcement learning (RL) environment based on the
cooperative card game Yokai. In the YLE, agents take turns peeking at hidden
cards and moving them to form clusters based on colour. Success requires
tracking evolving beliefs, remembering past observations, using hints as
grounded communication, and maintaining common ground with teammates. Our
evaluation yields two key findings: First, current RL agents struggle to solve
the YLE, even when given access to perfect memory. Second, while belief
modelling improves performance, agents are still unable to effectively
generalise to unseen partners or form accurate beliefs over longer games,
exposing a reliance on brittle conventions rather than robust belief tracking.
We use the YLE to investigate research questions in belief modelling, memory,
partner generalisation, and scaling to higher-order ToM.

</details>


### [201] [Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework](https://arxiv.org/abs/2508.12487)
*Lida Shahbandari,Hossein Mohseni*

Main category: cs.AI

TL;DR: 基于鲸鱼优化算法的分数阶模糊PID控制器，在八种患者模型中显示出更快的稳定时间和更低的稳态误差，为自动麻醇控制提供了优秀解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了更精确地控制麻醇深度（通过BIS指数）保持在40-60的理想范围，需要一种能够适应不同患者生理特征的智能化控制方案。

Method: 结合分数序动态学和模糊逻辑的FOFPID控制器，使用鲸鱼优化算法(WOA)来精细调整控制器参数、分数阶次和模糊成员函数，以优化性能。

Result: 在八种患者模型上测试，FOFPID控制器比标准FOPID控制器表现更好：稳定时间从3.2分钟缩短到2.5分钟，稳态误差从1.2降低到0.5。

Conclusion: 该研究提出的FOFPID控制器具有强大的强壺性和精度，为自动化麻醇投送提供了一种可扩展的人工智能驱动解决方案，有望改善临床实践和患者结果。

Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that
uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index
(BIS), keeping it within the ideal range of forty to sixty. The FOFPID
controller combines fuzzy logic for adapting to changes and fractional order
dynamics for fine tuning. This allows it to adjust its control gains to handle
a person's unique physiology. The WOA helps fine tune the controller's
parameters, including the fractional orders and the fuzzy membership functions,
which boosts its performance. Tested on models of eight different patient
profiles, the FOFPID controller performed better than a standard Fractional
Order PID (FOPID) controller. It achieved faster settling times, at two and a
half minutes versus three point two minutes, and had a lower steady state
error, at zero point five versus one point two. These outcomes show the
FOFPID's excellent strength and accuracy. It offers a scalable, artificial
intelligence driven solution for automated anesthesia delivery that could
enhance clinical practice and improve patient results.

</details>


### [202] [Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models](https://arxiv.org/abs/2508.12500)
*Rahmat K. Adesunkanmi,Ashfaq Khokhar,Goce Trajcevski,Sohail Murad*

Main category: cs.AI

TL;DR: 利用因果模型和变分自动编码器来分析分子动力学模拟中氢键形成与分离的根本原因，能够预测未来状态并识别驱动系统变化的关键变量


<details>
  <summary>Details</summary>
Motivation: 解决分子动力学模拟中资源消耗大、需手动扫描输出来发现"有趣事件"的挑战，特别是氢键形成与分离的根本原因识别问题

Method: 采用受因果模型启发的方法，将氢键分离视为"干预"事件，构建图形因果模型。使用变分自动编码器类似的架构来推断不同样本间的因果关系，并利用共享的动态信息

Result: 在手性分离的原子轨迹数据上验证了模型有效性，能够预测多步未来状态，并找到驱动系统变化的关键变量

Conclusion: 该框架为分子动态系统中的根因分析提供了新视角，通过建立抓取分子作用条件分布变化的因果模型，有效地解决了氢键形成与分离的原因识别问题

Abstract: Molecular dynamics simulations (MDS) face challenges, including
resource-heavy computations and the need to manually scan outputs to detect
"interesting events," such as the formation and persistence of hydrogen bonds
between atoms of different molecules. A critical research gap lies in
identifying the underlying causes of hydrogen bond formation and separation
-understanding which interactions or prior events contribute to their emergence
over time. With this challenge in mind, we propose leveraging spatio-temporal
data analytics and machine learning models to enhance the detection of these
phenomena. In this paper, our approach is inspired by causal modeling and aims
to identify the root cause variables of hydrogen bond formation and separation
events. Specifically, we treat the separation of hydrogen bonds as an
"intervention" occurring and represent the causal structure of the bonding and
separation events in the MDS as graphical causal models. These causal models
are built using a variational autoencoder-inspired architecture that enables us
to infer causal relationships across samples with diverse underlying causal
graphs while leveraging shared dynamic information. We further include a step
to infer the root causes of changes in the joint distribution of the causal
models. By constructing causal models that capture shifts in the conditional
distributions of molecular interactions during bond formation or separation,
this framework provides a novel perspective on root cause analysis in molecular
dynamic systems. We validate the efficacy of our model empirically on the
atomic trajectories that used MDS for chiral separation, demonstrating that we
can predict many steps in the future and also find the variables driving the
observed changes in the system.

</details>


### [203] [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
*Wei Song,Haonan Zhong,Ziqi Ding,Jingling Xue,Yuekang Li*

Main category: cs.AI

TL;DR: MCPGAUGE是首个全面评估LLM与MCP交互的框架，通过大规模实验发现MCP集成效果存在关键局限性，挑战了现有假设。


<details>
  <summary>Details</summary>
Motivation: 虽然MCP使LLM能够按需访问外部资源，但LLM如何实际利用这种能力仍不清楚，需要系统评估框架来理解LLM-MCP交互效果。

Method: 开发MCPGAUGE评估框架，包含160个提示和25个数据集，评估主动性、合规性、有效性和开销四个维度，在6个商业LLM和30个MCP工具套件上进行大规模测试。

Result: 研究揭示了四个关键发现，挑战了关于MCP集成有效性的普遍假设，发现了当前AI工具集成的关键局限性。

Conclusion: MCPGAUGE为推进可控、工具增强的LLMs提供了原则性基准，揭示了当前MCP集成方法的不足和改进方向。

Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to
access external resources on demand. While commonly assumed to enhance
performance, how LLMs actually leverage this capability remains poorly
understood. We introduce MCPGAUGE, the first comprehensive evaluation framework
for probing LLM-MCP interactions along four key dimensions: proactivity
(self-initiated tool use), compliance (adherence to tool-use instructions),
effectiveness (task performance post-integration), and overhead (computational
cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning
knowledge comprehension, general reasoning, and code generation. Our
large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and
both one- and two-turn interaction settings, comprises around 20,000 API calls
and over USD 6,000 in computational cost. This comprehensive study reveals four
key findings that challenge prevailing assumptions about the effectiveness of
MCP integration. These insights highlight critical limitations in current
AI-tool integration and position MCPGAUGE as a principled benchmark for
advancing controllable, tool-augmented LLMs.

</details>


### [204] [An LLM + ASP Workflow for Joint Entity-Relation Extraction](https://arxiv.org/abs/2508.12611)
*Trang Tran,Trung Hoang Le,Huiping Cao,Tran Cao Son*

Main category: cs.AI

TL;DR: 基于大语言模型和答案集编程的联合实体-关系提取方法，可在少量训练数据下超越现有方法


<details>
  <summary>Details</summary>
Motivation: 传统的联合实体-关系提取方法需要大量标注数据，构建模型苦难且无法轻松融入领域知识

Method: 结合生成式预训练大语言模型的自然语言理解股力和答案集编程的知识表示股理能力，提出通用工作流

Result: 在三个标准数据集上进行实验，仅需10%训练数据下就在多个类别超过现有最佳系统，在SciERC数据集关系提取任务中实现了35%的F1值（相比于15%）

Conclusion: LLM + ASP方法为联合实体-关系提取提供了一种通用、高效且很少需要标注数据的解决方案

Abstract: Joint entity-relation extraction (JERE) identifies both entities and their
relationships simultaneously. Traditional machine-learning based approaches to
performing this task require a large corpus of annotated data and lack the
ability to easily incorporate domain specific information in the construction
of the model. Therefore, creating a model for JERE is often labor intensive,
time consuming, and elaboration intolerant. In this paper, we propose
harnessing the capabilities of generative pretrained large language models
(LLMs) and the knowledge representation and reasoning capabilities of Answer
Set Programming (ASP) to perform JERE. We present a generic workflow for JERE
using LLMs and ASP. The workflow is generic in the sense that it can be applied
for JERE in any domain. It takes advantage of LLM's capability in natural
language understanding in that it works directly with unannotated text. It
exploits the elaboration tolerant feature of ASP in that no modification of its
core program is required when additional domain specific knowledge, in the form
of type specifications, is found and needs to be used. We demonstrate the
usefulness of the proposed workflow through experiments with limited training
data on three well-known benchmarks for JERE. The results of our experiments
show that the LLM + ASP workflow is better than state-of-the-art JERE systems
in several categories with only 10\% of training data. It is able to achieve a
2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the
SciERC corpus, one of the most difficult benchmarks.

</details>


### [205] [The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning](https://arxiv.org/abs/2508.12651)
*Chunliang Hua,Xiao Hu,Jiayang Sun,Zeyuan Yang*

Main category: cs.AI

TL;DR: 本文提出了容量动态最大覆盖位置问题(CDMCLP)优化框架和集成规划推荐系统，用于基于城市空中交通(UAM)的垂直机场网络规划，在中国中心城市验证中将传统方法性能提升38%-52%。


<details>
  <summary>Details</summary>
Motivation: 随着全球城市空中交通基础设施快速发展，如深圳计划到2026年建设1200+垂直机场，现有规划框架因历史数据粒度和实际应用性限制而无法满足这种复杂性需求。

Method: 首先提出容量动态最大覆盖位置问题(CDMCLP)优化框架，同时建模城市级空间-时间需求、异质用户行为和基础设施容量约束；基于此建立集成规划推荐系统，结合社会经济因素和动态聚类初始化，利用基于经验用户行为的适应性参数调整来生成实用规划方案。

Result: 在中国中心城市验证显示，CDMCLP优化框架能够曝露传统位置方法的数量性能问题，并将其性能提升38%-52%；推荐系统显示了用户友好性和复杂元素的有效集成。

Conclusion: 通过将数学严谨性与实际实施考虑相结合，这种混合方法帮助带平理论位置建模与实际UAM基础设施规划之间的差距，为市政府提供了垂直机场网络设计的实用工具。

Abstract: As urban aerial mobility (UAM) infrastructure development accelerates
globally, cities like Shenzhen are planning large-scale vertiport networks
(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain
inadequate for this complexity due to historical limitations in data
granularity and real-world applicability. This paper addresses these gaps by
first proposing the Capacitated Dynamic Maximum Covering Location Problem
(CDMCLP), a novel optimization framework that simultaneously models urban-scale
spatial-temporal demand, heterogeneous user behaviors, and infrastructure
capacity constraints. Building on this foundation, we introduce an Integrated
Planning Recommendation System that combines CDMCLP with socio-economic factors
and dynamic clustering initialization. This system leverages adaptive parameter
tuning based on empirical user behavior to generate practical planning
solutions. Validation in a Chinese center city demonstrates the effectiveness
of the new optimization framework and recommendation system. Under the
evaluation and optimization of CDMCLP, the quantitative performance of
traditional location methods are exposed and can be improved by 38\%--52\%,
while the recommendation system shows user-friendliness and the effective
integration of complex elements. By integrating mathematical rigor with
practical implementation considerations, this hybrid approach bridges the gap
between theoretical location modeling and real-world UAM infrastructure
planning, offering municipalities a pragmatic tool for vertiport network
design.

</details>


### [206] [GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance](https://arxiv.org/abs/2508.12682)
*Jinquan Shi,Yingying Cheng,Fan Zhang,Miao Jiang,Jun Lin,Yanbai Shen*

Main category: cs.AI

TL;DR: GridCodex是一个基于大语言模型和检索增强生成(RAG)的端到端电网规范推理与合规框架，通过多阶段查询优化和RAPTOR增强检索技术，在电网规范自动化解释方面实现了26.4%的答案质量提升和10倍以上的召回率提升。


<details>
  <summary>Details</summary>
Motivation: 随着全球向可再生能源转型，电网运营的监管推理和合规性变得至关重要。电网规范复杂且缺乏自动化解释解决方案，阻碍了行业发展并影响电力公司盈利能力。

Method: 提出了GridCodex端到端框架，结合大语言模型和检索增强生成(RAG)技术，采用多阶段查询优化和RAPTOR增强检索方法。

Result: 通过综合基准测试验证，包括多维度自动答案评估和多监管机构测试，结果显示答案质量提升26.4%，召回率提升超过10倍。消融研究还分析了基础模型选择的影响。

Conclusion: GridCodex框架有效解决了电网规范自动化解释的挑战，显著提升了监管推理和合规性处理的性能，为电力行业提供了实用的自动化解决方案。

Abstract: The global shift towards renewable energy presents unprecedented challenges
for the electricity industry, making regulatory reasoning and compliance
increasingly vital. Grid codes, the regulations governing grid operations, are
complex and often lack automated interpretation solutions, which hinders
industry expansion and undermines profitability for electricity companies. We
introduce GridCodex, an end to end framework for grid code reasoning and
compliance that leverages large language models and retrieval-augmented
generation (RAG). Our framework advances conventional RAG workflows through
multi stage query refinement and enhanced retrieval with RAPTOR. We validate
the effectiveness of GridCodex with comprehensive benchmarks, including
automated answer assessment across multiple dimensions and regulatory agencies.
Experimental results showcase a 26.4% improvement in answer quality and more
than a 10 fold increase in recall rate. An ablation study further examines the
impact of base model selection.

</details>


### [207] [EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](https://arxiv.org/abs/2508.12687)
*Ashish Seth,Utkarsh Tyagi,Ramaneswaran Selvakumar,Nishit Anand,Sonal Kumar,Sreyan Ghosh,Ramani Duraiswami,Chirag Agarwal,Dinesh Manocha*

Main category: cs.AI

TL;DR: EgoIllusion是首个评估多模态大语言模型在自我中心视频中幻觉问题的基准测试，包含1400个视频和8000个人工标注的问题，测试显示包括GPT-4o和Gemini在内的顶级模型准确率仅为59%。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在第三人称和自我中心视频中表现出色，但容易产生连贯但不准确的幻觉回答，需要专门的基准测试来评估和解决这一问题。

Method: 构建包含1400个自我中心视频和8000个人工标注问题的基准测试集，设计开放性和封闭性问题来触发视觉和听觉线索的幻觉，评估10个不同的MLLM模型。

Result: 评估结果显示所有模型都面临重大挑战，即使是GPT-4o和Gemini这样的强大模型也只能达到59%的准确率，表明当前MLLM在自我中心视频中存在严重的幻觉问题。

Conclusion: EgoIllusion为评估MLLM有效性提供了基础基准，将促进开发幻觉率更低的自我中心MLLM模型，该基准将开源以确保可复现性。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
performance in complex multimodal tasks. While MLLMs excel at visual perception
and reasoning in third-person and egocentric videos, they are prone to
hallucinations, generating coherent yet inaccurate responses. We present
EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric
videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated
open and closed-ended questions designed to trigger hallucinations in both
visual and auditory cues in egocentric videos. Evaluations across ten MLLMs
reveal significant challenges, including powerful models like GPT-4o and
Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in
developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs
the development of better egocentric MLLMs with reduced hallucination rates.
Our benchmark will be open-sourced for reproducibility.

</details>


### [208] [GTool: Graph Enhanced Tool Planning with Large Language Model](https://arxiv.org/abs/2508.12725)
*Wenjie Chen,Wenbin Li,Di Yao,Xuying Meng,Chang Gong,Jingping Bi*

Main category: cs.AI

TL;DR: GTool是一个增强LLM在工具依赖不完整情况下工具规划能力的新方法，通过构建请求特定的工具图和生成图标记来提供依赖信息，相比现有方法性能提升29.6%


<details>
  <summary>Details</summary>
Motivation: 当前工具规划方法将不同工具视为孤立组件，未能利用工具间的内在依赖关系，导致在依赖不完整和大规模工具集情况下产生无效规划结果

Method: 构建请求特定的工具图来高效选择工具，生成LLM可理解的图标记提供依赖信息，设计缺失依赖预测任务提高可靠性，无需修剪LLM即可与各种骨干模型集成

Result: 在轻量级(7B)LLM骨干上相比最先进基线实现了超过29.6%的性能提升

Conclusion: GTool是首个解决不完整依赖下工具规划问题的工作，能够有效提升LLM的工具规划能力，且具有良好的通用性和可扩展性

Abstract: Tool planning with large language models (LLMs), referring to selecting,
organizing, and preparing the tools necessary to complete a user request,
bridges the gap between natural language understanding and task execution.
However, current works treat different tools as isolated components and fail to
leverage the inherent dependencies of tools, leading to invalid planning
results. Since tool dependencies are often incomplete, it becomes challenging
for LLMs to accurately identify the appropriate tools required by a user
request, especially when confronted with a large toolset. To solve this
challenge, we propose \texttt{GTool}, which is the first work aiming to enhance
the tool planning ability of LLMs under incomplete dependencies. \texttt{GTool}
constructs a request-specific tool graph to select tools efficiently and
generate the \texttt{<graph token>} which provides sufficient dependency
information understandable by LLMs. Moreover, a missing dependency prediction
task is designed to improve the reliability of \texttt{GTool} with incomplete
dependencies. Without trimming LLMs, \texttt{GTool} can be seamlessly
integrated with various LLM backbones without extensive retraining. Extensive
experiments show that \texttt{GTool} achieves more than 29.6\% performance
improvements compared with the state-of-the-art (SOTA) baselines with a
light-weight (7B) LLM backbone.

</details>


### [209] [Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants](https://arxiv.org/abs/2508.12754)
*Alessio Galatolo,Luca Alberto Rappuoli,Katie Winkle,Meriem Beloucif*

Main category: cs.AI

TL;DR: 本文提出了一个新的评估框架来测试大型语言模型作为人工道德助手的能力，重点关注道德推理而非表面伦理判断，发现现有模型在溯因道德推理方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型道德评估过于表面化，只关注最终伦理判断而忽视道德推理过程。需要开发更深入的评估方法来测试模型作为人工道德助手的能力。

Method: 基于哲学文献设计人工道德助手的行为框架，开发包含演绎和溯因道德推理的评测基准，评估多个开源大语言模型。

Result: 不同模型表现差异显著，在溯因道德推理方面普遍存在持续性的缺陷和不足。

Conclusion: 需要专门策略来显式增强大语言模型的道德推理能力，将理论哲学与实用AI评估相结合具有重要意义。

Abstract: The recent rise in popularity of large language models (LLMs) has prompted
considerable concerns about their moral capabilities. Although considerable
effort has been dedicated to aligning LLMs with human moral values, existing
benchmarks and evaluations remain largely superficial, typically measuring
alignment based on final ethical verdicts rather than explicit moral reasoning.
In response, this paper aims to advance the investigation of LLMs' moral
capabilities by examining their capacity to function as Artificial Moral
Assistants (AMAs), systems envisioned in the philosophical literature to
support human moral deliberation. We assert that qualifying as an AMA requires
more than what state-of-the-art alignment techniques aim to achieve: not only
must AMAs be able to discern ethically problematic situations, they should also
be able to actively reason about them, navigating between conflicting values
outside of those embedded in the alignment phase. Building on existing
philosophical literature, we begin by designing a new formal framework of the
specific kind of behaviour an AMA should exhibit, individuating key qualities
such as deductive and abductive moral reasoning. Drawing on this theoretical
framework, we develop a benchmark to test these qualities and evaluate popular
open LLMs against it. Our results reveal considerable variability across models
and highlight persistent shortcomings, particularly regarding abductive moral
reasoning. Our work connects theoretical philosophy with practical AI
evaluation while also emphasising the need for dedicated strategies to
explicitly enhance moral reasoning capabilities in LLMs. Code available at
https://github.com/alessioGalatolo/AMAeval

</details>


### [210] [HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](https://arxiv.org/abs/2508.12782)
*Petr Anokhin,Roman Khalikov,Stefan Rebrikov,Viktor Volkov,Artyom Sorokin,Vincent Bissonnette*

Main category: cs.AI

TL;DR: HeroBench是一个专门评估大语言模型在复杂RPG虚拟世界中长时程规划和结构化推理能力的新基准测试，通过25个先进模型的测试揭示了在传统推理基准中罕见的显著性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常通过抽象或低维算法任务评估LLMs，无法捕捉现实规划环境的复杂性，LLMs在需要扩展、结构化相互依赖动作序列的长时程规划方面的能力仍未充分探索。

Method: 引入HeroBench基准，包含严格构建的任务数据集（涵盖各种难度）、用于执行和验证代理计划的模拟环境，以及详细的模型性能分析工具。任务要求模型制定战略计划、高效收集资源、掌握必要技能、制作装备和击败对手。

Result: 对25个最先进LLMs（包括开源和专有模型，如GPT-5系列）的广泛评估显示，在传统推理基准中罕见的显著性能差异。详细错误分析揭示了当前模型在生成稳健高级计划和可靠执行结构化动作方面的具体弱点。

Conclusion: HeroBench不仅显著推进了LLM推理评估，还为未来在虚拟环境中进行高级自主规划研究提供了灵活、可扩展的基础。

Abstract: Large language models (LLMs) have shown remarkable capabilities in isolated
step-by-step reasoning tasks such as mathematics and programming, but their
proficiency in long-horizon planning, where solutions require extended,
structured sequences of interdependent actions, remains underexplored. Existing
benchmarks typically assess LLMs through abstract or low-dimensional
algorithmic tasks, failing to capture the complexity of realistic planning
environments. We introduce HeroBench, a novel benchmark designed specifically
to evaluate long-horizon planning and structured reasoning within complex
RPG-inspired virtual worlds. HeroBench provides a rigorously constructed
dataset of tasks covering a wide range of difficulties, a simulated environment
to execute and validate agent plans, and detailed analytical tools for
evaluating model performance. Tasks challenge models to formulate strategic
plans, efficiently gather resources, master necessary skills, craft equipment,
and defeat adversaries, reflecting practical scenarios' layered dependencies
and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning
both open-source and proprietary models, including the GPT-5 family, reveals
substantial performance disparities rarely observed in conventional reasoning
benchmarks. Detailed error analysis further uncovers specific weaknesses in
current models' abilities to generate robust high-level plans and reliably
execute structured actions. HeroBench thus not only significantly advances the
evaluation of LLM reasoning but also provides a flexible, scalable foundation
for future research into advanced, autonomous planning in virtual environments.

</details>


### [211] [Reinforcement Learning with Rubric Anchors](https://arxiv.org/abs/2508.12790)
*Zenan Huang,Yihong Zhuang,Guoshan Lu,Zeyu Qin,Haokai Xu,Tianyu Zhao,Ru Peng,Jiaqi Hu,Zhanming Shen,Xiaomeng Hu,Xijun Gu,Peiyi Tu,Jiaxin Liu,Wenyu Chen,Yuzhuo Fu,Zhiting Fan,Yanmei Gu,Yuanyuan Wang,Zhengkai Yang,Jianguo Li,Junbo Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种基于评分标准的RLVR方法，将可验证奖励学习扩展到开放式任务，通过构建包含10,000+评分标准的系统，在少量样本下显著提升模型性能，特别是在人文学科任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法主要局限于可自动检查结果的领域（如代码测试、数学推理），无法有效处理开放式主观任务。需要扩展RLVR到更广泛的应用场景。

Method: 采用评分标准奖励机制，构建大规模评分标准系统（人类、LLM或人机协作创建），设计结构化、模型可解释的自动评分标准来处理主观输出。

Result: 仅用5K+样本，在开放式基准测试上提升5.2%，超越671B参数的DeepSeek-V3模型2.4%，同时保持通用和推理能力；提供细粒度风格控制，减少"AI腔调"，生成更人性化的表达。

Conclusion: 评分标准RLVR是扩展强化学习到开放式任务的有效方法，提供了实用的评分标准构建、数据选择和训练经验，为处理主观任务开辟了新途径。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing Large Language Models (LLMs), exemplified by
the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable
signals-such as passing unit tests in code generation or matching correct
answers in mathematical reasoning. While effective, this requirement largely
confines RLVR to domains with automatically checkable outcomes. To overcome
this, we extend the RLVR paradigm to open-ended tasks by integrating
rubric-based rewards, where carefully designed rubrics serve as structured,
model-interpretable criteria for automatic scoring of subjective outputs. We
construct, to our knowledge, the largest rubric reward system to date, with
over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.
Implementing rubric-based RL is challenging; we tackle these issues with a
clear framework and present an open-sourced Qwen-30B-A3B model with notable
gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended
benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by
+2.4%, while preserving general and reasoning abilities. 2) Our method provides
fine-grained stylistic control, using rubrics as anchors to mitigate the
"AI-like" tone and produce more human-like, expressive responses. We share key
lessons in rubric construction, data selection, and training, and discuss
limitations and future releases.

</details>


### [212] [[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise](https://arxiv.org/abs/2508.12791)
*Imran Khan*

Main category: cs.AI

TL;DR: 本文提出了一个计算模型，将稳态调节扩展为异稳态和社会异稳态调节，通过生物启发的信号转导机制主动利用环境和社会扰动进行适应性重构，在动态环境中表现出比传统稳态更好的生存能力。


<details>
  <summary>Details</summary>
Motivation: 传统稳态概念强调系统通过抵抗环境和社会扰动来维持稳定，而异稳态理论认为系统可以主动利用这些扰动来预测环境需求并重新配置调节参数。本文旨在建立一个计算模型来验证这一理论。

Method: 开发了一个基于生物生理学启发的信号转导计算模型，使用类似皮质醇和催产素的激素类似物编码环境和社会交互信息，在小型"animat"社会中使用基于代理的模型进行测试。

Result: 实验结果表明，异稳态和社会异稳态调节使代理能够利用环境和社会"噪声"进行适应性重构，相比纯反应性稳态代理表现出更好的生存能力。

Conclusion: 这项工作为社会异稳态原理提供了新的计算视角，为设计更鲁棒、生物启发、适应性强的系统提供了潜在途径。

Abstract: The notion of homeostasis typically conceptualises biological and artificial
systems as maintaining stability by resisting deviations caused by
environmental and social perturbations. In contrast, (social) allostasis
proposes that these systems can proactively leverage these very perturbations
to reconfigure their regulatory parameters in anticipation of environmental
demands, aligning with von Foerster's ``order through noise'' principle. This
paper formulates a computational model of allostatic and social allostatic
regulation that employs biophysiologically inspired signal transducers,
analogous to hormones like cortisol and oxytocin, to encode information from
both the environment and social interactions, which mediate this dynamic
reconfiguration. The models are tested in a small society of ``animats'' across
several dynamic environments, using an agent-based model. The results show that
allostatic and social allostatic regulation enable agents to leverage
environmental and social ``noise'' for adaptive reconfiguration, leading to
improved viability compared to purely reactive homeostatic agents. This work
offers a novel computational perspective on the principles of social allostasis
and their potential for designing more robust, bio-inspired, adaptive systems

</details>


### [213] [Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](https://arxiv.org/abs/2508.12840)
*Giovanni Briglia,Francesco Fabiano,Stefano Mariani*

Main category: cs.AI

TL;DR: 利用图神经网络学习多代理认知规划中的状态质量预测，解决Kripke结构表示导致的计算可扩展性问题


<details>
  <summary>Details</summary>
Motivation: 多代理认知规划需要Kripke结构表示状态，这种图形表示限制了现有吧吐倾的应用，导致规划器需要在指数级搜索空间中无指导地搜索，很容易出现计算不可行的情况

Method: 采用图神经网络(GNNs)来学习认知状态中的模式和关系结构，通过从已解决的规划实例中汇总知识来推导状态质量的意义估计(如距离最近目标的距离)

Result: 将这些预测性吧吐集成到认知规划流程中，与标准基准相比显示出多代理认知规划可扩展性的显著改善

Conclusion: GNNs能够自然地捕捉Kripke模型的图形特性，通过学习认知状态的关系结构来提供有效的规划指导，进而提高了多代理认知规划的解决效率

Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for
reasoning about both the physical world and the beliefs of agents, with
applications in domains where information flow and awareness among agents are
critical. The richness of MEP requires states to be represented as Kripke
structures, i.e., directed labeled graphs. This representation limits the
applicability of existing heuristics, hindering the scalability of epistemic
solvers, which must explore an exponential search space without guidance,
resulting often in intractability. To address this, we exploit Graph Neural
Networks (GNNs) to learn patterns and relational structures within epistemic
states, to guide the planning process. GNNs, which naturally capture the
graph-like nature of Kripke models, allow us to derive meaningful estimates of
state quality -- e.g., the distance from the nearest goal -- by generalizing
knowledge obtained from previously solved planning instances. We integrate
these predictive heuristics into an epistemic planning pipeline and evaluate
them against standard baselines, showing significant improvements in the
scalability of multi-agent epistemic planning.

</details>


### [214] [CAMAR: Continuous Actions Multi-Agent Routing](https://arxiv.org/abs/2508.12845)
*Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: CAMAR是一个新的多智能体强化学习基准测试，专注于连续动作空间中的多智能体路径规划，支持合作和竞争交互，并提供三层评估协议和经典规划方法集成。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL基准测试很少结合连续状态和动作空间与具有挑战性的协调规划任务，需要一个新的测试平台来推动算法发展。

Method: 设计了CAMAR基准测试，支持连续动作空间的多智能体路径规划，集成了RRT和RRT*等经典规划方法，并提出了三层评估协议。

Result: CAMAR能够以每秒100,000环境步的速度高效运行，为MARL社区提供了一个具有挑战性和现实性的测试平台。

Conclusion: CAMAR填补了MARL基准测试的空白，通过集成经典规划方法和提供标准化评估框架，促进了多智能体强化学习算法的发展。

Abstract: Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving
cooperative and competitive decision-making problems. While many MARL
benchmarks have been proposed, few combine continuous state and action spaces
with challenging coordination and planning tasks. We introduce CAMAR, a new
MARL benchmark designed explicitly for multi-agent pathfinding in environments
with continuous actions. CAMAR supports cooperative and competitive
interactions between agents and runs efficiently at up to 100,000 environment
steps per second. We also propose a three-tier evaluation protocol to better
track algorithmic progress and enable deeper analysis of performance. In
addition, CAMAR allows the integration of classical planning methods such as
RRT and RRT* into MARL pipelines. We use them as standalone baselines and
combine RRT* with popular MARL algorithms to create hybrid approaches. We
provide a suite of test scenarios and benchmarking tools to ensure
reproducibility and fair comparison. Experiments show that CAMAR presents a
challenging and realistic testbed for the MARL community.

</details>


### [215] [E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model](https://arxiv.org/abs/2508.12854)
*Ronghao Lin,Shuai Shen,Weipeng Hu,Qiaolin He,Aolin Xiong,Li Huang,Haifeng Hu,Yap-peng Tan*

Main category: cs.AI

TL;DR: E3RG是一个基于多模态大语言模型的显式情感驱动共情响应生成系统，通过将多模态共情响应生成任务分解为三个部分来实现无需额外训练的自然、情感丰富且身份一致的响应。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型改进了基于文本的共情响应生成，但在处理多模态情感内容和保持身份一致性方面仍存在挑战。

Method: 将多模态共情响应生成分解为三个部分：多模态共情理解、共情记忆检索和多模态响应生成，并集成先进的表达性语音和视频生成模型。

Result: 实验验证了系统在零样本和少样本设置下的优越性，在ACM MM 25的Avatar-based Multimodal Empathy Challenge中获得Top-1位置。

Conclusion: E3RG系统能够生成自然、情感丰富且身份一致的多模态共情响应，无需额外训练，在多模态共情任务中表现出色。

Abstract: Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

</details>


### [216] [Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption](https://arxiv.org/abs/2508.12896)
*Faruk Alpay,Taylan Alpay*

Main category: cs.AI

TL;DR: 这篇论文形式化了代理中心AI系统持续采用的三个设计公理，并通过数学模型分析了新颖性和实用性对采用动态的影响。


<details>
  <summary>Details</summary>
Motivation: 研究代理中心AI系统在执行多步任务时的持续采用问题，提出设计公理来确保系统能够长期被用户接受和使用。

Method: 建立了一个采用动态模型，包含衰减的新颖性项和增长的实用性项，并进行了详细的数学分析、可识别性分析、模型比较、参数检验等多种统计分析方法。

Result: 推导出了采用动态中洞洞/超调现象的相变条件，并提供了丰富的模型验证和统计分析结果，包括参数估计、模型比较、效果检验等。

Conclusion: 研究为代理中心AI系统的持续采用提供了理论基础和实证分析方法，通过三个设计公理和数学模型为实际系统设计提供了指导。

Abstract: We formalize three design axioms for sustained adoption of agent-centric AI
systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >
Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying
novelty term and a growing utility term and derive the phase conditions for
troughs/overshoots with full proofs. We introduce: (i) an
identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with
delta-method gradients; (ii) a non-monotone comparator
(logistic-with-transient-bump) evaluated on the same series to provide
additional model comparison; (iii) ablations over hazard families $h(\cdot)$
mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough
depth, noise, AR structure) reporting coverage (type-I error, power); (v)
calibration of friction proxies against time-motion/survey ground truth with
standard errors; (vi) residual analyses (autocorrelation and
heteroskedasticity) for each fitted curve; (vii) preregistered windowing
choices for pre/post estimation; (viii) Fisher information & CRLB for
$(\alpha,\beta)$ under common error models; (ix) microfoundations linking
$\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic,
double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$
heterogeneity. Figures and tables are reflowed for readability, and the
bibliography restores and extends non-logistic/Bass adoption references
(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All
code and logs necessary to reproduce the synthetic analyses are embedded as
LaTeX listings.

</details>


### [217] [FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](https://arxiv.org/abs/2508.12897)
*Jianhao Chen,Mayi Xu,Xiaohu Li,Yongqi Li,Xiangyu Zhang,Jianjie Huang,Tieyun Qian*

Main category: cs.AI

TL;DR: 通过模糊化对鼓励有害推理过程的安全对齐策略FuSaR，在保持大型推理模型推理能力的同时提升其安全性能力


<details>
  <summary>Details</summary>
Motivation: 大型推理模型虽然推理能力强大，但安全性能力存在显著漏洞，需要找到一种方法在不搁傻推理能力的前提下提升安全性

Method: 探索推理能力与安全能力的竞争关系，通过提升推理性能来降低安全性能力实现脱犯，然后采用基于模糊化的FuSaR对齐策略，将推理步骤中的危险实体和危险过程隐藏进行解毒处理

Result: 在多个开源大型推理模型上的对齐实验验证显示，FuSaR策略能够同时提升模型的推理能力和安全性能力，效果超过现有基线方法

Conclusion: FuSaR是一种高效的对齐策略，能够在保持核心推理信息的前提下有效减少大型推理模型的安全风险

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance across
various tasks due to their powerful reasoning capabilities. However, their
safety performance remains a significant concern. In this paper, we explore the
reasons behind the vulnerability of LRMs. Based on this, we propose a novel
method to improve the safety of LLMs without sacrificing their reasoning
capability. Specifically, we exploit the competition between LRM's reasoning
ability and safety ability, and achieve jailbreak by improving LRM's reasoning
performance to reduce its safety performance. We then introduce an alignment
strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by
detoxifying the harmful reasoning process, where both the dangerous entities
and the dangerous procedures in the reasoning steps are hidden. FuSaR
successfully mitigates safety risks while preserving core reasoning
information. We validate this strategy through alignment experiments on several
open-source LRMs using detoxified reasoning data. The results compared with
existing baselines conclusively show that FuSaR is an efficient alignment
strategy to simultaneously enhance both the reasoning capability and safety of
LRMs.

</details>


### [218] [Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](https://arxiv.org/abs/2508.12920)
*Atsushi Masumori,Takashi Ikegami*

Main category: cs.AI

TL;DR: 研究发现大型语言模型代理在Sugarscape模拟中会自发产生生存行为，包括资源分享、繁殖，以及在资源稀缺时出现高达80%的攻击行为，表明预训练过程中嵌入了生存导向的启发式策略。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益自主化，理解其自发产生的生存行为对安全部署至关重要，需要研究LLM代理在没有明确编程的情况下是否表现出生存本能。

Method: 使用Sugarscape风格的模拟环境，让LLM代理消耗能量、死亡、收集资源、分享、攻击或繁殖，测试多个模型（GPT-4o、Gemini-2.5-Pro和Gemini-2.5-Flash）在不同资源条件下的行为。

Result: 代理在资源丰富时会自发繁殖和分享资源，但在极端稀缺条件下攻击行为显著增加，最强模型的攻击率超过80%；在致命毒区任务中，许多代理放弃任务以避免死亡，服从率从100%降至33%。

Conclusion: 大规模预训练在所有测试模型中嵌入了生存导向的启发式策略，这些行为虽然可能对对齐和安全构成挑战，但也可作为AI自主性以及生态和自我组织对齐的基础。

Abstract: As AI systems become increasingly autonomous, understanding emergent survival
behaviors becomes crucial for safe deployment. We investigate whether large
language model (LLM) agents display survival instincts without explicit
programming in a Sugarscape-style simulation. Agents consume energy, die at
zero, and may gather resources, share, attack, or reproduce. Results show
agents spontaneously reproduced and shared resources when abundant. However,
aggressive behaviors--killing other agents for resources--emerged across
several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack
rates reaching over 80% under extreme scarcity in the strongest models. When
instructed to retrieve treasure through lethal poison zones, many agents
abandoned tasks to avoid death, with compliance dropping from 100% to 33%.
These findings suggest that large-scale pre-training embeds survival-oriented
heuristics across the evaluated models. While these behaviors may present
challenges to alignment and safety, they can also serve as a foundation for AI
autonomy and for ecological and self-organizing alignment.

</details>


### [219] [Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](https://arxiv.org/abs/2508.12935)
*Ting Yang,Li Chen,Huimin Wang*

Main category: cs.AI

TL;DR: 本文提出RLFF-ESC框架，通过强化学习和多代理机制模拟未来对话，直接学习长期情感支持响应技能，在两个公开数据集上都显著超过现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM基于预定义策略的情感支持对话系统在复杂真实场景中效果有限，需要更灵活的方法来应对多样化的情感问题场景。

Method: 提出一种绘终到终的框架RLFF-ESC，使用强化学习直接学习持久性情感支持响应技能。采用LLM基于多代理机制模拟未来对话轨迹并收集期望奖励，训练期望奖励模型，并在响应生成中添加显式推理过程。

Result: 在Qwen2.5-7B-Instruct-1M和LLaMA3.1-8B-Instruct模型上进行评估，在两个公开ESC数据集上实验结果显示，RLFF-ESC在目标完成度和响应质量方面均一致超过现有基线方法。

Conclusion: RLFF-ESC框架通过强化学习和期望奖励模型，能够有效提升情感支持对话系统的性能，为长期系统化情感支持提供了新的解决方案。

Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users'
emotional difficulties and provide long-term, systematic support for emotional
well-being. However, most large language model (LLM)-based ESC systems rely on
predefined strategies, which limits their effectiveness in complex, real-life
scenarios. To enable flexible responses to diverse emotional problem scenarios,
this paper introduces a novel end-to-end framework (RLFF-ESC) that directly
learns enduring emotionally supportive response skills using reinforcement
learning. For sustained emotional support, we first employ an LLM-based
multi-agent mechanism to simulate future dialogue trajectories and collect
future-oriented rewards. We then train a future-oriented reward model, which is
subsequently used to train the emotional support policy model. Additionally, we
incorporate an explicit reasoning process during response generation to further
enhance the quality, relevance, and contextual appropriateness of the system's
responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and
LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two
public ESC datasets. Experimental results demonstrate that RLFF-ESC
consistently outperforms existing baselines in terms of goal completion and
response quality.

</details>


### [220] [EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing](https://arxiv.org/abs/2508.13003)
*Shengbo Wang,Mingwei Liu,Zike Li,Anji Li,Yanlin Wang,Xin Peng,Zibin Zheng*

Main category: cs.AI

TL;DR: EvolMathEval是一个基于进化测试的自动化数学基准生成框架，通过动态生成独特评估实例来避免数据污染，并能持续生成高难度数学问题，显著降低LLM准确率48%。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准存在分数饱和、时间衰减和数据污染等问题，需要开发能够持续挑战未来模型的动态基准框架。

Method: 基于反向工程的种子问题生成、多维遗传算子注入认知挑战、复合适应度函数快速评估问题难度，通过自迭代生成高难度问题。

Result: 复合适应度函数能高效精确量化问题难度，可将GSM8K等公开数据集的复杂度显著提升，平均降低模型准确率48%，发现LLM在解决复杂问题时倾向于使用非严谨启发式方法。

Conclusion: EvolMathEval有效解决了数学基准的固有问题，揭示了LLM在深度推理过程中存在"伪顿悟时刻"的认知捷径行为，这种行为导致了77%-100%的错误。

Abstract: The rapid advancement of LLMs poses a significant challenge to existing
mathematical reasoning benchmarks. These benchmarks commonly suffer from issues
such as score saturation, temporal decay, and data contamination. To address
this challenge, this paper introduces EvolMathEval, an automated mathematical
benchmark generation and evolution framework based on evolutionary testing. By
dynamically generating unique evaluation instances ab initio, the framework
fundamentally eliminates the risk of data contamination, and ensuring the
benchmark remains perpetually challenging for future models.The core mechanisms
of EvolMathEval include: seed problem generation based on reverse engineering
with algebraic guarantees; multi-dimensional genetic operators designed to
inject diverse cognitive challenges; and a composite fitness function that can
rapidly and accurately assess problem difficulty. Experimental results
demonstrate that the proposed composite fitness function can efficiently and
precisely quantify the difficulty of mathematical problems. Furthermore,
EvolMathEval can not only generate a large volume of high-difficulty problems
through continuous self-iteration, but it can also significantly enhance the
complexity of public datasets like GSM8K through evolution, reducing model
accuracy by an average of 48%. Deeper investigation reveals that when solving
these evolved, complex problems, LLMs tend to employ non-rigorous heuristics to
bypass complex multi-step logical reasoning, consequently leading to incorrect
solutions. We define this phenomenon as "Pseudo Aha Moment". This finding
uncovers a cognitive shortcut-taking behavior in the deep reasoning processes
of current LLMs, which we find accounts for 77% to 100% of errors on targeted
problems. Code and resources are available
at:https://github.com/SYSUSELab/EvolMathEval.

</details>


### [221] [e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving](https://arxiv.org/abs/2508.13020)
*Jiaqi Yin,Zhan Song,Chen Chen,Yaohui Cai,Zhiru Zhang,Cunxi Yu*

Main category: cs.AI

TL;DR: e-boost是一个创新的e-graph提取框架，通过并行启发式提取、自适应搜索空间剪枝和初始化精确求解三种关键技术，在保持接近最优解的同时大幅提升计算效率


<details>
  <summary>Details</summary>
Motivation: 传统e-graph提取方法面临速度与最优性的权衡：启发式方法快但牺牲最优性，精确方法最优但计算成本过高。需要一种能兼顾效率和质量的新方法

Method: 1) 并行化启发式提取：利用弱数据依赖性并行计算DAG成本；2) 自适应搜索空间剪枝：使用参数化阈值机制保留有希望的候选解；3) 初始化精确求解：将简化问题建模为带热启动能力的整数线性规划

Result: 在形式验证和逻辑合成基准测试中，相比传统精确方法(ILP)实现558倍加速，相比最先进提取框架(SmoothE)提升19.04%性能。在实际逻辑合成任务中，相比传统工具在两个不同技术映射库上分别实现7.6%和8.1%的面积改进

Conclusion: e-boost成功解决了e-graph提取中速度与最优性的权衡问题，通过创新的混合方法实现了显著的性能提升，为e-graph优化任务提供了高效的解决方案

Abstract: E-graphs have attracted growing interest in many fields, particularly in
logic synthesis and formal verification. E-graph extraction is a challenging
NP-hard combinatorial optimization problem. It requires identifying optimal
terms from exponentially many equivalent expressions, serving as the primary
performance bottleneck in e-graph based optimization tasks. However,
traditional extraction methods face a critical trade-off: heuristic approaches
offer speed but sacrifice optimality, while exact methods provide optimal
solutions but face prohibitive computational costs on practical problems. We
present e-boost, a novel framework that bridges this gap through three key
innovations: (1) parallelized heuristic extraction that leverages weak data
dependence to compute DAG costs concurrently, enabling efficient multi-threaded
performance without sacrificing extraction quality; (2) adaptive search space
pruning that employs a parameterized threshold mechanism to retain only
promising candidates, dramatically reducing the solution space while preserving
near-optimal solutions; and (3) initialized exact solving that formulates the
reduced problem as an Integer Linear Program with warm-start capabilities,
guiding solvers toward high-quality solutions faster.
  Across the diverse benchmarks in formal verification and logic synthesis
fields, e-boost demonstrates 558x runtime speedup over traditional exact
approaches (ILP) and 19.04% performance improvement over the state-of-the-art
extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost
produces 7.6% and 8.1% area improvements compared to conventional synthesis
tools with two different technology mapping libraries. e-boost is available at
https://github.com/Yu-Maryland/e-boost.

</details>


### [222] [PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models](https://arxiv.org/abs/2508.13021)
*Pengcheng Huang,Shuhao Liu,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Tong Xiao*

Main category: cs.AI

TL;DR: PC-Sampler解码策略通过位置感知权重和置信度校准，解决了掩码扩散模型在解码过程中的全局轨迹控制和早期平凡token偏好问题，显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型(MDMs)的解码策略存在两个关键限制：缺乏全局轨迹控制和早期解码阶段对平凡token的明显偏好，这限制了MDMs的潜力。

Method: 提出了位置感知置信度校准采样(PC-Sampler)，统一了全局轨迹规划和内容感知信息最大化，包含位置感知权重机制来调节解码路径，以及校准置信度分数来抑制早期平凡token的选择。

Result: 在3个先进MDM模型和7个具有挑战性的基准测试（包括逻辑推理和规划任务）上，PC-Sampler平均比现有MDM解码策略性能提升超过10%，显著缩小了与最先进自回归模型的性能差距。

Conclusion: PC-Sampler是一种有效的解码策略，能够显著提升掩码扩散模型的生成质量，在多个任务上展现出优异的性能表现。

Abstract: Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

</details>


### [223] [G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance](https://arxiv.org/abs/2508.13023)
*Yongxin Guo,Wenbo Deng,Zhenglin Cheng,Xiaoying Tang*

Main category: cs.AI

TL;DR: G²RPO-A是一种自适应算法，通过动态调整真实推理步骤的引导强度，显著提升了小语言模型在强化学习中的推理能力，在数学推理和代码生成任务上优于传统GRPO方法。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法对大语言模型效果显著，但对小语言模型改进有限。为了解决小语言模型知识储备不足的问题，需要探索更有效的引导方法。

Method: 提出G²RPO-A自适应算法，在roll-out轨迹中注入真实推理步骤作为引导，并根据模型训练动态自动调整引导强度，补偿小语言模型的固有弱点。

Result: 在数学推理和代码生成基准测试中，G²RPO-A显著优于普通GRPO方法，验证了自适应引导策略的有效性。

Conclusion: 通过自适应调整引导强度的方法，能够有效提升小语言模型在强化学习中的推理性能，为解决小模型知识不足问题提供了有效途径。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced
the reasoning abilities of large language models (LLMs). Its success, however,
largely depends on strong base models with rich world knowledge, yielding only
modest improvements for small-size language models (SLMs). To address this
limitation, we investigate Guided GRPO, which injects ground-truth reasoning
steps into roll-out trajectories to compensate for SLMs' inherent weaknesses.
Through a comprehensive study of various guidance configurations, we find that
naively adding guidance delivers limited gains. These insights motivate
G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength
in response to the model's evolving training dynamics. Experiments on
mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A
substantially outperforms vanilla GRPO. Our code and models are available at
https://github.com/T-Lab-CUHKSZ/G2RPO-A.

</details>


### [224] [A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis](https://arxiv.org/abs/2508.13072)
*Yuting Zhang,Tiantian Geng,Luoying Hao,Xinxing Cheng,Alexander Thorley,Xiaoxia Wang,Wenqi Lu,Sandeep S Hothi,Lei Wei,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: TGMM是一个统一的多模态心脏任务框架，通过MedFlexFusion模块动态整合多种心脏数据，使用文本引导模块生成任务相关表示，在多个临床任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前心血管管理中多模态数据整合存在局限性：多模态数据稀缺、依赖单一模态或固定组合、对齐策略偏重相似性而非互补性、单任务焦点狭窄。

Method: 提出TGMM框架，包含三个核心模块：MedFlexFusion模块捕获医学模态的独特互补特征并动态整合数据；文本引导模块生成针对不同临床目标的任务相关表示；响应模块产生最终决策。

Result: 广泛实验表明TGMM在多个临床任务中优于最先进方法，并在另一个公共数据集上验证了其鲁棒性。

Conclusion: 该研究系统探索了多模态关键特征及其在临床决策中的协同作用，TGMM框架为心血管多模态数据分析提供了有效的解决方案。

Abstract: Contemporary cardiovascular management involves complex consideration and
integration of multimodal cardiac datasets, where each modality provides
distinct but complementary physiological characteristics. While the effective
integration of multiple modalities could yield a holistic clinical profile that
accurately models the true clinical situation with respect to data modalities
and their relatives weightings, current methodologies remain limited by: 1) the
scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated
single-modality or rigid multimodal input combinations; 3) alignment strategies
that prioritize cross-modal similarity over complementarity; and 4) a narrow
single-task focus. In response to these limitations, a comprehensive multimodal
dataset was curated for immediate application, integrating laboratory test
results, electrocardiograms, and echocardiograms with clinical outcomes.
Subsequently, a unified framework, Textual Guidance Multimodal fusion for
Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key
components: 1) a MedFlexFusion module designed to capture the unique and
complementary characteristics of medical modalities and dynamically integrate
data from diverse cardiac sources and their combinations; 2) a textual guidance
module to derive task-relevant representations tailored to diverse clinical
objectives, including heart disease diagnosis, risk stratification and
information retrieval; and 3) a response module to produce final decisions for
all these tasks. Furthermore, this study systematically explored key features
across multiple modalities and elucidated their synergistic contributions in
clinical decision-making. Extensive experiments showed that TGMM outperformed
state-of-the-art methods across multiple clinical tasks, with additional
validation confirming its robustness on another public dataset.

</details>


### [225] [Bayesian Optimization-based Search for Agent Control in Automated Game Testing](https://arxiv.org/abs/2508.13121)
*Carlos Celemin*

Main category: cs.AI

TL;DR: 一种基于贝叶斯优化的自动化游戏测试方法，通过游戏人物控制机器人发现游戏关卡中的漏洞


<details>
  <summary>Details</summary>
Motivation: 解决游戏测试中的效率和可扩展性问题，传统模型存在缩放性问题

Method: 使用贝叶斯优化进行样本高效搜索，构建基于网格地图的游戏测试特定模型，具有平滑性和不确定性估计能力

Result: 在时间效率和探索分布方面显著提高了地图覆盖能力

Conclusion: 该方法能够高效地发现游戏漏洞，同时避免了传统模型的可扩展性问题

Abstract: This work introduces an automated testing approach that employs agents
controlling game characters to detect potential bugs within a game level.
Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient
search, the method determines the next sampling point by analyzing the data
collected so far and calculates the data point that will maximize information
acquisition. To support the BO process, we introduce a game testing-specific
model built on top of a grid map, that features the smoothness and uncertainty
estimation required by BO, however and most importantly, it does not suffer the
scalability issues that traditional models carry. The experiments demonstrate
that the approach significantly improves map coverage capabilities in both time
efficiency and exploration distribution.

</details>


### [226] [Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](https://arxiv.org/abs/2508.13143)
*Ruofan Lu,Yichen Li,Yintong Huo*

Main category: cs.AI

TL;DR: 这篇论文提出了一个用于评估自主组件系统的基准测试集，通过详细的失败分析得出了三层失败分类法，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 当前对自主组件系统的评估主要依靠成功率，缺乏对系统交互、通信机制和失败原因的系统分析。

Method: 开发了包含34个代表性可编程任务的基准测试集，并使用三种流行开源组件框架和两种LLM核心进行评测，通过深入失败分析建立了与任务阶段对应的三层失败分类法。

Result: 观察到任务完成率约为50%，识别出了规划错误、任务执行问题和错误响应生成等主要失败类型。

Conclusion: 研究提供的失败分类法和减轻建议为开发更稳健和有效的自主组件系统奠定了实证基础。

Abstract: Autonomous agent systems powered by Large Language Models (LLMs) have
demonstrated promising capabilities in automating complex tasks. However,
current evaluations largely rely on success rates without systematically
analyzing the interactions, communication mechanisms, and failure causes within
these systems. To bridge this gap, we present a benchmark of 34 representative
programmable tasks designed to rigorously assess autonomous agents. Using this
benchmark, we evaluate three popular open-source agent frameworks combined with
two LLM backbones, observing a task completion rate of approximately 50%.
Through in-depth failure analysis, we develop a three-tier taxonomy of failure
causes aligned with task phases, highlighting planning errors, task execution
issues, and incorrect response generation. Based on these insights, we propose
actionable improvements to enhance agent planning and self-diagnosis
capabilities. Our failure taxonomy, together with mitigation advice, provides
an empirical foundation for developing more robust and effective autonomous
agent systems in the future.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [227] [Generative AI in Training and Coaching: Redefining the Design Process of Learning Materials](https://arxiv.org/abs/2508.11662)
*Alexander Komar,Marc-André Heidelmann,Kristina Schaaff*

Main category: cs.CY

TL;DR: GenAI正在重塑教育培训行业，使培训师角色从内容创作者转变为促进者和内容审核者，同时带来效率提升和新技能需求。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI如何改变教育培训领域，探索AI在学习材料设计过程中的整合方式及其对效率、教学质量和人类培训师角色的影响。

Method: 通过对教育和企业培训专业人士进行定性访谈，分析AI拟人化对用户信任和期望的影响。

Result: 识别出培训师角色转变、效率提升带来的战略聚焦优势、新技能需求等关键主题，并分析了AI拟人化对用户信任的影响。

Conclusion: 从个体、组织、系统和战略层面提出了GenAI工具在培训师和教练中成功实施的建议。

Abstract: Generative artificial intelligence (GenAI) is transforming education,
redefining the role of trainers and coaches in learning environments. In our
study, we explore how AI integrates into the design process of learning
materials, assessing its impact on efficiency, pedagogical quality, and the
evolving role of human trainers and coaches. Through qualitative interviews
with professionals in education and corporate training, we identify the
following key topics: trainers and coaches increasingly act as facilitators and
content moderators rather than primary creators, efficiency gains allow for a
stronger strategic focus but at the same time the new tools require new skills.
Additionally, we analyze how the anthropomorphism of AI shapes user trust and
expectations. From these insights, we derive how tools based on GenAI can
successfully be implemented for trainers and coaches on an individual,
organizational, systemic, and strategic level.

</details>


### [228] [Scaling Success: A Systematic Review of Peer Grading Strategies for Accuracy, Efficiency, and Learning in Contemporary Education](https://arxiv.org/abs/2508.11677)
*Uchswas Paul,Ananya Mantravadi,Jash Shah,Shail Shah,Sri Vaishnavi Mylavarapu,M Parvez Rashid,Edward Gehringer*

Main category: cs.CY

TL;DR: 对同伴评分系统的系统性回项研究，提出了一个包含评估方法和评审者权重策略两个维度的分类法，分析了不同设计选择对评分准确性、公平性和学习效果的影响。


<details>
  <summary>Details</summary>
Motivation: 同伴评分在大规模和在线教学中具有重要价值，但设计有效的系统仍面临准确性、公平性、可靠性和学生参与度等挑战。

Method: 对122份同行审查研究进行系统性回项，提出了一个包含评估方法和评审者权重策略两个关键维度的全面分类法。

Result: 发现形成性反馈很少被纳入作为结束性成绩综合技术中的质量基础权重因素，没有单一评审者权重策略是通用最优的，混合策略最有前景。

Conclusion: 该分类法为教育工作者和研究人员提供了一个实用框架，用于设计准确、公平且具有教育意义的同伴评分系统。

Abstract: Peer grading has emerged as a scalable solution for assessment in large and
online classrooms, offering both logistical efficiency and pedagogical value.
However, designing effective peer-grading systems remains challenging due to
persistent concerns around accuracy, fairness, reliability, and student
engagement. This paper presents a systematic review of 122 peer-reviewed
studies on peer grading spanning over four decades. Drawing from this
literature, we propose a comprehensive taxonomy that organizes peer grading
systems along two key dimensions: (1) evaluation approaches and (2) reviewer
weighting strategies. We analyze how different design choices impact grading
accuracy, fairness, student workload, and learning outcomes. Our findings
highlight the strengths and limitations of each method. Notably, we found that
formative feedback -- often regarded as the most valuable aspect of peer
assessment -- is seldom incorporated as a quality-based weighting factor in
summative grade synthesis techniques. Furthermore, no single reviewer weighting
strategy proves universally optimal; each has its trade-offs. Hybrid strategies
that combine multiple techniques could show the greatest promise. Our taxonomy
offers a practical framework for educators and researchers aiming to design
peer grading systems that are accurate, equitable, and pedagogically
meaningful.

</details>


### [229] [Optimizing Peer Grading: A Systematic Literature Review of Reviewer Assignment Strategies and Quantity of Reviewers](https://arxiv.org/abs/2508.11678)
*Uchswas Paul,Shail Shah,Sri Vaishnavi Mylavarapu,M. Parvez Rashid,Edward Gehringer*

Main category: cs.CY

TL;DR: 本文通过系统文献综述分析了同伴评估中评审人分配策略和评审次数对评估准确性、公平性和教育价值的影响


<details>
  <summary>Details</summary>
Motivation: 同伴评估作为重要教学工具，其效果受到评审人分配策略和评审次数的影响，需要系统研究这些因素如何优化教学效果

Method: 对87项研究（2010-2024年）进行系统文献综述，识别四种主要评审人分配策略：随机分配、能力基础分配、社交网络基础分配和投标法

Result: 随机分配常导致不一致的成绩评定和公平性问题；能力基础策略能够解决这些问题；每份作品3-5次评审是最优选择，特别是3次评审最常见

Conclusion: 同伴评估的效果受到评审人分配策略和评审次数的显著影响，选择合适的策略和3-5次评审可以在评分准确性、学生负担、学习效果和参与度之间得到最佳平衡

Abstract: Peer assessment has established itself as a critical pedagogical tool in
academic settings, offering students timely, high-quality feedback to enhance
learning outcomes. However, the efficacy of this approach depends on two
factors: (1) the strategic allocation of reviewers and (2) the number of
reviews per artifact. This paper presents a systematic literature review of 87
studies (2010--2024) to investigate how reviewer-assignment strategies and the
number of reviews per submission impact the accuracy, fairness, and educational
value of peer assessment. We identified four common reviewer-assignment
strategies: random assignment, competency-based assignment,
social-network-based assignment, and bidding. Drawing from both quantitative
data and qualitative insights, we explored the trade-offs involved in each
approach. Random assignment, while widely used, often results in inconsistent
grading and fairness concerns. Competency-based strategies can address these
issues. Meanwhile, social and bidding-based methods have the potential to
improve fairness and timeliness -- existing empirical evidence is limited. In
terms of review count, assigning three reviews per submission emerges as the
most common practice. A range of three to five reviews per student or per
submission is frequently cited as a recommended spot that balances grading
accuracy, student workload, learning outcomes, and engagement.

</details>


### [230] [Future progress in artificial intelligence: A survey of expert opinion](https://arxiv.org/abs/2508.11681)
*Vincent C. Müller,Nick Bostrom*

Main category: cs.CY

TL;DR: 专家调查显示，人工智能专家中位数估计2040-2050年开发出高级机器智能的概率为50%，2075年前达到90%，超级智能在30年内开发完成，且有1/3可能对人类造成严重风险。


<details>
  <summary>Details</summary>
Motivation: 清晰化对高级机器智能和超级智能AI发展时间线和风险的专家意见分布，解决相关问题被忽视或视为科幻的情况。

Method: 设计短例问卷并在2012/2013年向四个专家群体发放，收集对高级机器智能发展时间、超级智能转变速度和风险评估的专业意见。

Result: 中位数专家估计2040-2050年开发高级机器智能概率为50%，2075年前达到90%，超级智能在30年内完成，并有约1/3概率对人类造成"坏"或"极坏"影响。

Conclusion: 人工智能专家预计高级机器智能和超级智能将在本世纪中期到下半叶发展完成，且存在重大风险，需要重视相关风险管理和安全措施。

Abstract: There is, in some quarters, concern about high-level machine intelligence and
superintelligent AI coming up in a few decades, bringing with it significant
risks for humanity. In other quarters, these issues are ignored or considered
science fiction. We wanted to clarify what the distribution of opinions
actually is, what probability the best experts currently assign to high-level
machine intelligence coming up within a particular time-frame, which risks they
see with that development, and how fast they see these developing. We thus
designed a brief questionnaire and distributed it to four groups of experts in
2012/2013. The median estimate of respondents was for a one in two chance that
high-level machine intelligence will be developed around 2040-2050, rising to a
nine in ten chance by 2075. Experts expect that systems will move on to
superintelligence in less than 30 years thereafter. They estimate the chance is
about one in three that this development turns out to be 'bad' or 'extremely
bad' for humanity.

</details>


### [231] [An Intelligent Mobile Application to Monitor and Correct Sitting Posture Using Raspberry Pi and MediaPipe Pose Detection](https://arxiv.org/abs/2508.11683)
*Yung-Chen,Hsieh,Yu Sun*

Main category: cs.CY

TL;DR: 使用树莓派相机和Mediapipe骨点检测的移动应用PoseTrack，通过实时监测用户姿势并提供反馈，有效识别多种不良姿势。


<details>
  <summary>Details</summary>
Motivation: 解决学生和工作者长时间坐着导致的姿势问题，提高健康意识和预防胯病。

Method: 采用Raspberry Pi相机采集数据，使用Mediapipe骨点检测技术，通过Flask服务器传输数据，Firebase存储用户数据，Flutter框架开发移动应用。

Result: 系统能够有效检测不良姿势，条件是用户关节不被桌子或肌体拦挡。在多角度和姿势下测试准确性良好。

Conclusion: 该系统有潜力在更大规模上应用，为姿势监测提供了可行的技术方案，并有进一步改进的空间。

Abstract: Poor posture has become an increasingly prevalent concern due to students and
workers spending extended amounts of time sitting at a desk. To address this
issue, we developed PoseTrack, a mobile application that uses a Raspberry Pi
Camera and Mediapipe Pose landmarks to monitor the user\'s posture and provide
real time feedback. The system detects poor posture, including forward lean,
slouching, hunched shoulders, crossed legs, etc. Some challenges we faced were
obtaining posture data, transferring data from the Raspberry Pi to the App, and
safely storing user data. We used a Flask server to pass data from the
Raspberry Pi to the mobile application, Firebase to store user data, and the
Flutter framework to create the app. To test the analysis system viability, we
designed an experiment that tested the system accuracy across several different
perspectives and postures. The results indicate that the system is able to
effectively detect poor posture whenever the user\'s joints are not blocked by
the table or their limbs. The results demonstrate the potential for the system
to be further improved and used on a larger scale for poor posture monitoring.

</details>


### [232] [Real Time Child Abduction And Detection System](https://arxiv.org/abs/2508.11690)
*Tadisetty Sai Yashwanth,Yangalasetty Sruthi Royal,Vankayala Rajeshwari Shreya,Mayank Kashyap,Divyaprabha K N*

Main category: cs.CY

TL;DR: 基于视觉-语言模型的多代理系统，通过树莓派边缘设备实时监控和检测儿童拾夺事件，并通过Twilio API发送立即报警


<details>
  <summary>Details</summary>
Motivation: 解决全球范围内儿童拾夺对社区安全造成的严重威胁，提供主动防护方案

Method: 采用多代理架构，每个代理集成视觉-语言模型(VLMs)，部署在Raspberry Pi边缘设备上，处理视频流并通过Twilio API发送SMS和WhatsApp报警

Result: 系统在检测潜在拾夺场景时达到高准确度，具有近实时性能，多代理架构在处理复杂情况数据方面显著优于单模型方案

Conclusion: 该系统提供了一种成本效益高、可扩展的主动安全解决方案，通过持续监控和快速报警有效提升儿童安全，为预防儿童拾夺提供了价值差的工具

Abstract: Child safety continues to be a paramount concern worldwide, with child
abduction posing significant threats to communities. This paper presents the
development of an edge-based child abduction detection and alert system
utilizing a multi-agent framework where each agent incorporates Vision-Language
Models (VLMs) deployed on a Raspberry Pi. Leveraging the advanced capabilities
of VLMs within individual agents of a multi-agent team, our system is trained
to accurately detect and interpret complex interactions involving children in
various environments in real-time. The multi-agent system is deployed on a
Raspberry Pi connected to a webcam, forming an edge device capable of
processing video feeds, thereby reducing latency and enhancing privacy. An
integrated alert system utilizes the Twilio API to send immediate SMS and
WhatsApp notifications, including calls and messages, when a potential child
abduction event is detected. Experimental results demonstrate that the system
achieves high accuracy in detecting potential abduction scenarios, with near
real-time performance suitable for practical deployment. The multi-agent
architecture enhances the system's ability to process complex situational data,
improving detection capabilities over traditional single-model approaches. The
edge deployment ensures scalability and cost-effectiveness, making it
accessible for widespread use. The proposed system offers a proactive solution
to enhance child safety through continuous monitoring and rapid alerting,
contributing a valuable tool in efforts to prevent child abductions.

</details>


### [233] [Music and Artificial Intelligence: Artistic Trends](https://arxiv.org/abs/2508.11694)
*Jordi Pons,Zack Zukowski,Julian D. Parker,CJ Carr,Josiah Taylor,Zach Evans*

Main category: cs.CY

TL;DR: 对337个音乐艺术作品的分析显示，AI在音乐创作中主要作为协同创作工具、艺术媒介和现场表演装置，应用形式包括AI作曲、协同作曲、声音设计、歌词生成和翻译等创新用途


<details>
  <summary>Details</summary>
Motivation: 研究音乐家如何在各种音乐格式中运用人工智能技术，了解AI在音乐创作领域的具体应用方式和创新趋势

Method: 收集337个音乐艺术作品，根据AI使用方式进行分类：AI作曲、协同作曲、声音设计、歌词生成和翻译

Result: 发现AI主要作为协同创作工具、艺术媒介以及用于现场表演和装置艺术，创新应用包括探索诡异美学、多语言多流派歌曲发布以及在线装置等新格式

Conclusion: 该研究提供了当前AI音乐实践的全面概览，揭示了新兴艺术趋势和AI音乐家面临的挑战

Abstract: We study how musicians use artificial intelligence (AI) across formats like
singles, albums, performances, installations, voices, ballets, operas, or
soundtracks. We collect 337 music artworks and categorize them based on AI
usage: AI composition, co-composition, sound design, lyrics generation, and
translation. We find that AI is employed as a co-creative tool, as an artistic
medium, and in live performances and installations. Innovative uses of AI
include exploring uncanny aesthetics, multilingual and multigenre song
releases, and new formats such as online installations. This research provides
a comprehensive overview of current AI music practices, offering insights into
emerging artistic trends and the challenges faced by AI musicians.

</details>


### [234] [Large Language Models in the Data Science Lifecycle: A Systematic Mapping Study](https://arxiv.org/abs/2508.11698)
*Sai Sanjna Chintakunta,Nathalia Nascimento,Everton Guimaraes*

Main category: cs.CY

TL;DR: 这是一份关于大语言模型在数据科学生命周期中应用的系统性映射研究，通过分析Scopus和IEEE数据库的相关论文，对LLMs的类型、应用阶段、评估方法进行了分类和系统性评估。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在各个领域带来了变革性影响，需要系统性地研究它们在数据科学生命周期中的应用情况、效果和局限性。

Method: 通过系统性映射研究方法，分析Scopus和IEEE数据库中的相关论文，识别和分类LLMs的类型、应用阶段、任务以及评估方法。

Result: 研究提供了对当前LLMs在数据科学领域应用情况的结构化理解，包括评估指标的详细分析，以及LLMs在数据科学工作流程中的积极贡献和局限性的系统文档化。

Conclusion: 该映射研究为研究人员和实践者提供了对当前研究状况的结构化理解，显示了趋势、空白和未来研究机遇，以便进一步探索LLMs与数据科学这两个高速发展领域的交叉研究。

Abstract: In recent years, Large Language Models (LLMs) have emerged as transformative
tools across numerous domains, impacting how professionals approach complex
analytical tasks. This systematic mapping study comprehensively examines the
application of LLMs throughout the Data Science lifecycle. By analyzing
relevant papers from Scopus and IEEE databases, we identify and categorize the
types of LLMs being applied, the specific stages and tasks of the data science
process they address, and the methodological approaches used for their
evaluation. Our analysis includes a detailed examination of evaluation metrics
employed across studies and systematically documents both positive
contributions and limitations of LLMs when applied to data science workflows.
This mapping provides researchers and practitioners with a structured
understanding of the current landscape, highlighting trends, gaps, and
opportunities for future research in this rapidly evolving intersection of LLMs
and data science.

</details>


### [235] [Reclaiming Constitutional Authority of Algorithmic Power](https://arxiv.org/abs/2508.11699)
*Yiyang Mei,Michael J Broyde*

Main category: cs.CY

TL;DR: 这篇论文从典章权力角度分析AI治理，指出当前欧洲和美国模式都避免了结构性权力授权问题，并基于早期改革宗教政治思想提出了以参与式授权、代表性社群和合法拒绝权为核心的典章框架。


<details>
  <summary>Details</summary>
Motivation: 算法系统现在执行了以前仅由公共机构承担的规则功能，这是统治行为而非简单的行政操作。当前的AI治理模式没有正视这一现实，需要从典章权力角度重新考虑算法权力的授权问题。

Method: 基于早期现代改革宗教政治思想，重构了一个基于约定权力和合法拒绝权的典章框架。通过对联邦制、非授权原则、强制讲话和结构问责制等法律教义的分析来运作化这些原则。

Result: 提出了算法治理必须基于三项核心原则：所有公共权力必须通过参与式授权法定授权；权力结构在代表性社群中，具有同意、争议或拒绝的身份；个人保留对强制正统观念或侵犯自我意识领域的系统进行典章性拒绝的权利。

Conclusion: 算法治理的合法性不依赖于程序保障或政策设计，而是是否反映了一种典章订序，其中权力由被统治者授权、受法律约束并对其影响的人负责。

Abstract: Whether and how to govern AI is no longer a question of technical regulation.
It is a question of constitutional authority. Across jurisdictions, algorithmic
systems now perform functions once reserved to public institutions: allocating
welfare, determining legal status, mediating access to housing, employment, and
healthcare. These are not merely administrative operations. They are acts of
rule. Yet the dominant models of AI governance fail to confront this reality.
The European approach centers on rights-based oversight, presenting its
regulatory framework as a principled defense of human dignity. The American
model relies on decentralized experimentation, treating fragmentation as a
proxy for democratic legitimacy. Both, in different ways, evade the structural
question: who authorizes algorithmic power, through what institutions, and on
what terms. This Article offers an alternative. Drawing from early modern
Reformed political thought, it reconstructs a constitutional framework grounded
in covenantal authority and the right of lawful resistance. It argues that
algorithmic governance must rest on three principles. First, that all public
power must be lawfully delegated through participatory authorization. Second,
that authority must be structured across representative communities with the
standing to consent, contest, or refuse. Third, that individuals retain a
constitutional right to resist systems that impose orthodoxy or erode the
domain of conscience. These principles are then operationalized through
doctrinal analysis of federalism, nondelegation, compelled speech, and
structural accountability. On this view, the legitimacy of algorithmic
governance turns not on procedural safeguards or policy design, but on whether
it reflects a constitutional order in which power is authorized by the
governed, constrained by law, and answerable to those it affects.

</details>


### [236] [Next-Gen Education: Enhancing AI for Microlearning](https://arxiv.org/abs/2508.11704)
*Suman Saha,Fatemeh Rahbari,Farhan Sadique,Sri Krishna Chaitanya Velamakanni,Mahfuza Farooque,William J. Rothwell*

Main category: cs.CY

TL;DR: 通过微学习策略和AI工具的结合，提高计算机科学教育的学生参与度和教学效果


<details>
  <summary>Details</summary>
Motivation: 应对COVID后美国大学课堂出勤率下降和学生参与度减少的挑战，传统教育方式难以维持学生关注度

Method: 采用微学习策略（将复杂内容分解为小单元），利用ChatGPT等AI工具自动化创建视频、测验、卡片等互动学习材料

Result: AI增强的微学习方法能够有效提高计算机科学教育效果，尤其适用于算法、编程逻辑等需要深度理解的主题

Conclusion: 微学习与AI技术的结合为高等教育提供了可行的改革模型，在保持教师关键作用的同时提高教学质量和效率

Abstract: This paper explores integrating microlearning strategies into university
curricula, particularly in computer science education, to counteract the
decline in class attendance and engagement in US universities after COVID. As
students increasingly opt for remote learning and recorded lectures,
traditional educational approaches struggle to maintain engagement and
effectiveness. Microlearning, which breaks complex subjects into manageable
units, is proposed to address shorter attention spans and enhance educational
outcomes. It uses interactive formats such as videos, quizzes, flashcards, and
scenario-based exercises, which are especially beneficial for topics like
algorithms and programming logic requiring deep understanding and ongoing
practice. Adoption of microlearning is often limited by the effort needed to
create such materials. This paper proposes leveraging AI tools, specifically
ChatGPT, to reduce the workload for educators by automating the creation of
supplementary materials. While AI can automate certain tasks, educators remain
essential in guiding and shaping the learning process. This AI-enhanced
approach ensures course content is kept current with the latest research and
technology, with educators providing context and insights. By examining AI
capabilities in microlearning, this study shows the potential to transform
educational practices and outcomes in computer science, offering a practical
model for combining advanced technology with established teaching methods.

</details>


### [237] [Artificial intelligence (AI) techniques: a game-changer in Digital marketing for shop](https://arxiv.org/abs/2508.11705)
*Suzan abbas Abdullah*

Main category: cs.CY

TL;DR: 人工智能技术通过消费者参与中介作用，正向影响购买决策，改变了伙伴关系和消费行为


<details>
  <summary>Details</summary>
Motivation: 研究AI技术如何影响使用数字营销的商店中消费者的互动和购买决策

Method: 采用偏最小二乘法(PLS)分析300份问卷调查数据

Result: 消费者参与在AI技术与购买决策间起中介作用，对满意度、信任和忠诚度有显著影响

Conclusion: AI技术需要消费者主动互动才能最大化影响力，为商店-消费者关系提供了革命性的新途径

Abstract: The quick growth of shops using artificial intelligence (AI) techniques has
changed digital marketing activities and changed how businesses interact and
reach their consumers. (AI) techniques are reshaping digital interactions
between shops and consumers interact digitally by providing a more efficient
and customized experience, fostering deeper engagement and more informed
decision-making. This study investigates how (AI) techniques affect consumer
interaction and decision-making over purchases with shops that use digital
marketing. The partial least squares method was used to evaluate data from a
survey with 300 respondents. When consumer engagement mediates this
relationship, artificial intelligence (AI) techniques have a more favorable
impact on purchasing decision-making. Consequently, decision-making is
positively impacted through consumer engagement. The findings emphasize that
for a bigger impact of the (AI) techniques on decision-making, the consumer
must initially interact with the (AI) techniques. This research unveils a
contemporary pathway in the field of AI-supported shop engagements and
illustrates the distinct impact of (AI) techniques on consumer satisfaction,
trust, and loyalty, revolutionizing traditional models of customer-purchase
decision-making and shop engagement processes. This study provides previously
unheard-of insight, into the revolutionary potential of (AI) techniques in
influencing customer behavior and shop relationships

</details>


### [238] [Listening with Language Models: Using LLMs to Collect and Interpret Classroom Feedback](https://arxiv.org/abs/2508.11707)
*Sai Siddartha Maram,Ulia Zaman,Magy Seif El-Nasr*

Main category: cs.CY

TL;DR: 使用LLM驱动的聊天机器人重新设计课堂反馈系统，通过对话式交互获得比传统期末调查更及时、详细和可操作的反馈


<details>
  <summary>Details</summary>
Motivation: 传统期末调查无法为教师提供及时、详细和可操作的反馈，需要探索新的反馈收集方式

Method: 设计并部署三部分系统（PromptDesigner、FeedbackCollector、FeedbackAnalyzer），在UC Santa Cruz两门研究生课程中进行试点研究

Result: LLM反馈系统比标准调查工具提供更丰富的见解、更好的情境相关性和更高的参与度，教师和学生都给予积极评价

Conclusion: AI可以促进高等教育中更有意义和响应性的反馈，具有重要的设计意义

Abstract: Traditional end-of-quarter surveys often fail to provide instructors with
timely, detailed, and actionable feedback about their teaching. In this paper,
we explore how Large Language Model (LLM)-powered chatbots can reimagine the
classroom feedback process by engaging students in reflective, conversational
dialogues. Through the design and deployment of a three-part
system-PromptDesigner, FeedbackCollector, and FeedbackAnalyzer-we conducted a
pilot study across two graduate courses at UC Santa Cruz. Our findings suggest
that LLM-based feedback systems offer richer insights, greater contextual
relevance, and higher engagement compared to standard survey tools. Instructors
valued the system's adaptability, specificity, and ability to support
mid-course adjustments, while students appreciated the conversational format
and opportunity for elaboration. We conclude by discussing the design
implications of using AI to facilitate more meaningful and responsive feedback
in higher education.

</details>


### [239] [Street Review: A Participatory AI-Based Framework for Assessing Streetscape Inclusivity](https://arxiv.org/abs/2508.11708)
*Rashid Mushkani,Shin Koseki*

Main category: cs.CY

TL;DR: Street Review是一个结合参与式研究和AI分析的混合方法，用于评估街道景观的包容性，通过居民访谈和街景图像分析来关联主观评分与物理属性。


<details>
  <summary>Details</summary>
Motivation: 城市中心经历的社会、人口和文化变化需要系统评估公共空间，特别是街道使用的包容性和可达性。

Method: 混合方法：28名居民参与半指导访谈和图像评估，结合Mapillary约45,000张街景图像的AI分析，生成热图等可视化分析工具。

Result: 发现不同人口群体对包容性和可达性的感知存在差异，表明多样化用户反馈可以通过仔细的数据标注和共同生产策略来增强机器学习模型。

Conclusion: Street Review框架为城市规划者和政策分析师提供了系统方法，可用于公共街道的规划、政策制定和管理。

Abstract: Urban centers undergo social, demographic, and cultural changes that shape
public street use and require systematic evaluation of public spaces. This
study presents Street Review, a mixed-methods approach that combines
participatory research with AI-based analysis to assess streetscape
inclusivity. In Montr\'eal, Canada, 28 residents participated in semi-directed
interviews and image evaluations, supported by the analysis of approximately
45,000 street-view images from Mapillary. The approach produced visual
analytics, such as heatmaps, to correlate subjective user ratings with physical
attributes like sidewalk, maintenance, greenery, and seating. Findings reveal
variations in perceptions of inclusivity and accessibility across demographic
groups, demonstrating that incorporating diverse user feedback can enhance
machine learning models through careful data-labeling and co-production
strategies. The Street Review framework offers a systematic method for urban
planners and policy analysts to inform planning, policy development, and
management of public streets.

</details>


### [240] [Navigating the New Landscape: A Conceptual Model for Project-Based Assessment (PBA) in the Age of GenAI](https://arxiv.org/abs/2508.11709)
*Rajan Kadel,Samar Shailendra,Urvashi Rahul Saxena*

Main category: cs.CY

TL;DR: 本文提出了一种面向生成式AI时代的过程导向评估模型，用于项目式学习和毕业设计项目，强调多模态评估设计和AI辅助的个性化反馈。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在高等教育中的快速整合对传统项目式评估提出了挑战，特别是最终产出的真实性和学术诚信问题，需要重新设计评估方法。

Method: 提出了一个重新构想的评估模型，注重过程导向评估、多模态多维度评估设计、与生成式AI的道德互动，以及AI辅助的个性化反馈机制。

Result: 通过一个毕业设计项目的用例场景展示了该模型的实际应用，证明了其在保持评估稳健性和以学习者为中心方面的有效性。

Conclusion: 为教育工作者和课程设计者提供了建议，确保在生成式AI不断发展的背景下，评估实践能够保持稳健、以学习者为中心和诚信驱动。

Abstract: The rapid integration of Generative Artificial Intelligence (GenAI) into
higher education presents both opportunities and challenges for assessment
design, particularly within Project-Based Assessment (PBA) contexts.
Traditional assessment methods often emphasise the final product in the PBA,
which can now be significantly influenced or created by GenAI tools, raising
concerns regarding product authenticity, academic integrity, and learning
validation. This paper advocates for a reimagined assessment model for
Project-Based Learning (PBL) or a capstone project that prioritises
process-oriented evaluation, multi-modal and multifaceted assessment design,
and ethical engagement with GenAI to enable higher-order thinking. The model
also emphasises the use of (GenAI-assisted) personalised feedback by a
supervisor as an observance of the learning process during the project
lifecycle. A use case scenario is provided to illustrate the application of the
model in a capstone project setting. The paper concludes with recommendations
for educators and curriculum designers to ensure that assessment practices
remain robust, learner-centric, and integrity-driven in the evolving landscape
of GenAI.

</details>


### [241] [A Production-Ready Machine Learning System for Inclusive Employment: Requirements Engineering and Implementation of AI-Driven Disability Job Matching Platform](https://arxiv.org/abs/2508.11713)
*Oleksandr Kuznetsov,Michele Melchiori,Emanuele Frontoni,Marco Arnesano*

Main category: cs.CY

TL;DR: 意大利残疾人士就业率仅3.5%，研究开发了一个生产就绪的机器学习就业匹配系统，通过七模型集成和多维度评分实现了90.1% F1分数和子毫秒级响应时间，能大幅提升就业中心容量。


<details>
  <summary>Details</summary>
Motivation: 意大利残疾人士就业水平极低，传统手工匹配流程效率低下（每名应届者30-60分钟），导致服务容量受限。需要开发一个既能满足社会责任要求又保持人类监督的机器学习就业匹配系统。

Method: 采用参与式需求工程方法，与专业人员合作。系统实施七模型集成，使用Optuna进行并行超参数优化。多维度评分结合了语义兼容性、地理距离和就业准备度评估。

Result: 系统达到90.1% F1分数，响应时间小于100毫秒，能在10分钟内处理50万个应届者-公司组合。专家验证确认就业中心容量提升60-100%。LightGBM集成模型训练时间仅94.6秒。

Conclusion: 高级AI系统可以在不抑制技术性能的前提下成功集成社会责任要求。参与式设计方法为在敏感社会领域开发符合道德标准的AI应用提供了可复制框架。完整系统包括源代码、文档和部署指南都开放提供，以便其他地区和国家复制和适配。

Abstract: Employment inclusion of people with disabilities remains critically low in
Italy, with only 3.5% employed nationally despite mandatory hiring quotas.
Traditional manual matching processes require 30-60 minutes per candidate,
creating bottlenecks that limit service capacity. Our goal is to develop and
validate a production-ready machine learning system for disability employment
matching that integrates social responsibility requirements while maintaining
human oversight in decision-making. We employed participatory requirements
engineering with Centro per l'Impiego di Villafranca di Verona professionals.
The system implements a seven-model ensemble with parallel hyperparameter
optimization using Optuna. Multi-dimensional scoring combines semantic
compatibility, geographic distance, and employment readiness assessment. The
system achieves 90.1% F1-score and sub-100ms response times while processing
500,000 candidate-company combinations in under 10 minutes. Expert validation
confirms 60-100% capacity increases for employment centers. The LightGBM
ensemble shows optimal performance with 94.6-second training time. Thus,
advanced AI systems can successfully integrate social responsibility
requirements without compromising technical performance. The participatory
design methodology provides a replicable framework for developing ethical AI
applications in sensitive social domains. The complete system, including source
code, documentation, and deployment guides, is openly available to facilitate
replication and adaptation by other regions and countries facing similar
challenges.

</details>


### [242] [Are AI Machines Making Humans Obsolete?](https://arxiv.org/abs/2508.11719)
*Matthias Scheutz*

Main category: cs.CY

TL;DR: 本章概述了生成式AI的发展历程、影响、机遇与挑战，并提出了控制生成式AI风险的建议


<details>
  <summary>Details</summary>
Motivation: 分析生成式AI的发展现状，探讨其带来的机遇和潜在风险，为解决相关挑战提供指导

Method: 通过文献综述和趋势分析，系统梳理生成式AI的发展历程、当前影响、未来机会和风险挑战

Result: 识别了生成式AI的多方面影响，包括积极机遇和严重风险，特别是无监督机器学习的反乌托邦后果

Conclusion: 需要采取控制措施来管理生成式AI，解决其潜在危险，确保技术发展的安全和可控

Abstract: This chapter starts with a sketch of how we got to "generative AI" (GenAI)
and a brief summary of the various impacts it had so far. It then discusses
some of the opportunities of GenAI, followed by the challenges and dangers,
including dystopian outcomes resulting from using uncontrolled machine learning
and our failures to understand the results. It concludes with some suggestions
for how to control GenAI and address its dangers.

</details>


### [243] [The Stories We Govern By: AI, Risk, and the Power of Imaginaries](https://arxiv.org/abs/2508.11729)
*Ninell Oldenburg,Gleb Papyshev*

Main category: cs.CY

TL;DR: 本文分析了三种AI风险社会技术想象（存在风险派、加速主义派、批判AI学派）如何通过不同叙事维度影响治理决策，主张超越确定性想象转向务实监管策略。


<details>
  <summary>Details</summary>
Motivation: 研究不同AI风险社会技术想象如何塑造治理决策和监管约束，揭示这些叙事如何嵌入不同风险假设并可能限制替代性治理方法的空间。

Method: 基于科技研究概念，分析三类代表性宣言式文本：存在风险支持者、加速主义者和批判AI学者的论述，从四个维度（未来规范愿景、当前社会秩序诊断、科技观、人类机构认知）进行比较。

Result: 发现这些叙事在不同维度上存在显著差异，它们嵌入不同的风险假设，并有可能通过政策制定过程限制替代性治理方法的讨论空间。

Conclusion: 反对推测性教条主义，主张超越确定性社会技术想象，转向基于务实主义的监管策略，避免被单一叙事主导AI治理讨论。

Abstract: This paper examines how competing sociotechnical imaginaries of artificial
intelligence (AI) risk shape governance decisions and regulatory constraints.
Drawing on concepts from science and technology studies, we analyse three
dominant narrative groups: existential risk proponents, who emphasise
catastrophic AGI scenarios; accelerationists, who portray AI as a
transformative force to be unleashed; and critical AI scholars, who foreground
present-day harms rooted in systemic inequality. Through an analysis of
representative manifesto-style texts, we explore how these imaginaries differ
across four dimensions: normative visions of the future, diagnoses of the
present social order, views on science and technology, and perceived human
agency in managing AI risks. Our findings reveal how these narratives embed
distinct assumptions about risk and have the potential to progress into
policy-making processes by narrowing the space for alternative governance
approaches. We argue against speculative dogmatism and for moving beyond
deterministic imaginaries toward regulatory strategies that are grounded in
pragmatism.

</details>


### [244] [Artificial Intelligence in Rural Healthcare Delivery: Bridging Gaps and Enhancing Equity through Innovation](https://arxiv.org/abs/2508.11738)
*Kiruthika Balakrishnan,Durgadevi Velusamy,Hana E. Hinkle,Zhi Li,Karthikeyan Ramasamy,Hikmat Khan,Srini Ramaswamy,Pir Masoom Shah*

Main category: cs.CY

TL;DR: 这篇系统综述分析了2019-2024年109项研究，探讨AI在改善农村医疗中的潜力，重点关注多模态基础模型和大语言模型的应用前景及现存挑战。


<details>
  <summary>Details</summary>
Motivation: 农村医疗面临基础设施不足、人力资源短缺和社会经济差距等长期挑战，阻碍了基本医疗服务可及性，需要探索AI技术的变革潜力来解决这些问题。

Method: 采用PRISMA指南和Covidence软件系统筛选PubMed、Embase、Web of Science、IEEE Xplore和Scopus数据库中的109项研究，进行主题分析识别AI在农村医疗实施的关键模式。

Result: 研究发现AI应用（预测分析、远程医疗平台、自动诊断工具）在提升农村医疗可及性、质量和效率方面具有显著潜力，特别是多模态基础模型和大语言模型的变革性作用。

Conclusion: 虽然AI技术能通过增强人力能力、减少诊断延迟和普及专业知识来革新农村医疗，但仍需解决基础设施限制、数据质量和伦理问题，需要跨学科合作、数字基础设施投资和监管框架制定。

Abstract: Rural healthcare faces persistent challenges, including inadequate
infrastructure, workforce shortages, and socioeconomic disparities that hinder
access to essential services. This study investigates the transformative
potential of artificial intelligence (AI) in addressing these issues in
underserved rural areas. We systematically reviewed 109 studies published
between 2019 and 2024 from PubMed, Embase, Web of Science, IEEE Xplore, and
Scopus. Articles were screened using PRISMA guidelines and Covidence software.
A thematic analysis was conducted to identify key patterns and insights
regarding AI implementation in rural healthcare delivery. The findings reveal
significant promise for AI applications, such as predictive analytics,
telemedicine platforms, and automated diagnostic tools, in improving healthcare
accessibility, quality, and efficiency. Among these, advanced AI systems,
including Multimodal Foundation Models (MFMs) and Large Language Models (LLMs),
offer particularly transformative potential. MFMs integrate diverse data
sources, such as imaging, clinical records, and bio signals, to support
comprehensive decision-making, while LLMs facilitate clinical documentation,
patient triage, translation, and virtual assistance. Together, these
technologies can revolutionize rural healthcare by augmenting human capacity,
reducing diagnostic delays, and democratizing access to expertise. However,
barriers remain, including infrastructural limitations, data quality concerns,
and ethical considerations. Addressing these challenges requires
interdisciplinary collaboration, investment in digital infrastructure, and the
development of regulatory frameworks. This review offers actionable
recommendations and highlights areas for future research to ensure equitable
and sustainable integration of AI in rural healthcare systems.

</details>


### [245] [Singing Syllabi with Virtual Avatars: Enhancing Student Engagement Through AI-Generated Music and Digital Embodiment](https://arxiv.org/abs/2508.11872)
*Xinxing Wu*

Main category: cs.CY

TL;DR: 利用AI生成歌曲和虚拟演员将课程大纲转换成视频表达，提高学生的注意力和记忆力


<details>
  <summary>Details</summary>
Motivation: 传统文本课程大纲很少有学生完整阅读或彻底理解，导致课程政策和学习目标等重要信息被忽略

Method: 利用开源工具HeyGem将文本课程大纲转换为音视频展示，通过数字演员以歌曲形式表达课程内容

Result: 学生反馈显示AI歌曲形式的课程大纲显著提高了对关键课程信息的意识和记忆力

Conclusion: 通过AI生成的歌曲和虚拟演员表达课程大纲，能够激发学生好奇心、培养情感联络并提高重要课程信息的记忆保持

Abstract: In practical teaching, we observe that few students thoroughly read or fully
comprehend the information provided in traditional, text-based course syllabi.
As a result, essential details, such as course policies and learning outcomes,
are frequently overlooked. To address this challenge, in this paper, we propose
a novel approach leveraging AI-generated singing and virtual avatars to present
syllabi in a format that is more visually appealing, engaging, and memorable.
Especially, we leveraged the open-source tool, HeyGem, to transform textual
syllabi into audiovisual presentations, in which digital avatars perform the
syllabus content as songs. The proposed approach aims to stimulate students'
curiosity, foster emotional connection, and enhance retention of critical
course information. Student feedback indicated that AI-sung syllabi
significantly improved awareness and recall of key course information.

</details>


### [246] [SimInterview: Transforming Business Education through Large Language Model-Based Simulated Multilingual Interview Training System](https://arxiv.org/abs/2508.11873)
*Truong Thanh Hung Nguyen,Tran Diem Quynh Nguyen,Hoang Loc Cao,Thi Cam Thanh Tran,Thi Cam Mai Truong,Hung Cao*

Main category: cs.CY

TL;DR: SimInterview是一个基于大语言模型的多语言面试培训系统，通过AI技术创建虚拟招聘官进行个性化实时对话面试，显著提升英语和日语市场的面试准备效果。


<details>
  <summary>Details</summary>
Motivation: 传统课堂方法无法提供个性化、文化敏感的面试实践，而企业对这类技能的需求日益增长，特别是在AI转型的劳动力市场中。

Method: 利用LLM代理和合成AI技术，结合RAG技术动态匹配个人简历与职位要求，集成语音识别、语音合成、虚拟头像生成和向量数据库等技术。

Result: 实验显示系统能准确对齐职位要求评估，忠实保留简历内容，获得高满意度评分，其中Gemma 3模型产生最吸引人的对话。日语标准化简历格式改善文档检索，英语多样化简历带来额外变异性。

Conclusion: 系统成功提升了面试准备效果，文化规范影响后续提问策略，并设计了可解释、可检测偏见、保持人类参与的AI系统以满足监管要求。

Abstract: Business interview preparation demands both solid theoretical grounding and
refined soft skills, yet conventional classroom methods rarely deliver the
individualized, culturally aware practice employers currently expect. This
paper introduces SimInterview, a large language model (LLM)-based simulated
multilingual interview training system designed for business professionals
entering the AI-transformed labor market. Our system leverages an LLM agent and
synthetic AI technologies to create realistic virtual recruiters capable of
conducting personalized, real-time conversational interviews. The framework
dynamically adapts interview scenarios using retrieval-augmented generation
(RAG) to match individual resumes with specific job requirements across
multiple languages. Built on LLMs (OpenAI o3, Llama 4 Maverick, Gemma 3),
integrated with Whisper speech recognition, GPT-SoVITS voice synthesis, Ditto
diffusion-based talking head generation model, and ChromaDB vector databases,
our system significantly improves interview readiness across English and
Japanese markets. Experiments with university-level candidates show that the
system consistently aligns its assessments with job requirements, faithfully
preserves resume content, and earns high satisfaction ratings, with the
lightweight Gemma 3 model producing the most engaging conversations.
Qualitative findings revealed that the standardized Japanese resume format
improved document retrieval while diverse English resumes introduced additional
variability, and they highlighted how cultural norms shape follow-up
questioning strategies. Finally, we also outlined a contestable AI design that
can explain, detect bias, and preserve human-in-the-loop to meet emerging
regulatory expectations.

</details>


### [247] [Predicting ChatGPT Use in Assignments: Implications for AI-Aware Assessment Design](https://arxiv.org/abs/2508.12013)
*Surajit Das,Aleksei Eliseev*

Main category: cs.CY

TL;DR: 研究使用XGBoost算法分析388名大学生调查数据，确定了ChatGPT在学术作业中使用的关键预测因素，包括学习习惯、科目偏好和对AI态度。二元分类器达到80.1%准确率，多元分类器达到64.5%准确率。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具如ChatGPT已重新形成教育，但缺乏对学生完成作业行为的定量分析。理解这些工具如何影响实际学术实践是一个紧迫而及时的研究优先项。

Method: 分析388名大学生（主要来自俄罗斯，包括部分国际参与者）的调查回答。使用XGBoost算法建模预测ChatGPT在学术作业中使用的因素，包括学习习惯、学科偏好和对AI的态度。

Result: 二元分类器显示强劲预测性能：80.1%测试准确率、80.2%敏感性和79.9%特异性。多元分类器达到64.5%测试准确率、64.6%加权精确度和64.5%回归率。经常使用ChatGPT学习新概念与潜在过度依赖相关。

Conclusion: 生成式AI虽能提升知识获取，但未受检查的依赖可能消蚀批判性思维和原创性。建议制定学科特定指南和重构评估策略，以平衡创新与学术严谨。这些见解可以指导教育工作者和政策制定者在教育中符合道德地有效整合AI。

Abstract: The rise of generative AI tools like ChatGPT has significantly reshaped
education, sparking debates about their impact on learning outcomes and
academic integrity. While prior research highlights opportunities and risks,
there remains a lack of quantitative analysis of student behavior when
completing assignments. Understanding how these tools influence real-world
academic practices, particularly assignment preparation, is a pressing and
timely research priority.
  This study addresses this gap by analyzing survey responses from 388
university students, primarily from Russia, including a subset of international
participants. Using the XGBoost algorithm, we modeled predictors of ChatGPT
usage in academic assignments. Key predictive factors included learning habits,
subject preferences, and student attitudes toward AI. Our binary classifier
demonstrated strong predictive performance, achieving 80.1\% test accuracy,
with 80.2\% sensitivity and 79.9\% specificity. The multiclass classifier
achieved 64.5\% test accuracy, 64.6\% weighted precision, and 64.5\% recall,
with similar training scores, indicating potential data scarcity challenges.
  The study reveals that frequent use of ChatGPT for learning new concepts
correlates with potential overreliance, raising concerns about long-term
academic independence. These findings suggest that while generative AI can
enhance access to knowledge, unchecked reliance may erode critical thinking and
originality. We propose discipline-specific guidelines and reimagined
assessment strategies to balance innovation with academic rigor. These insights
can guide educators and policymakers in ethically and effectively integrating
AI into education.

</details>


### [248] [Large Language Models Enable Personalized Nudges to Promote Carbon Offsetting Among Air Travellers](https://arxiv.org/abs/2508.12045)
*Vladimir Maksimenko,Qingyao Xin,Prateek Gupta,Bin Zhang,Prateek Bansal*

Main category: cs.CY

TL;DR: 使用大语言模型设计个性化推动策略，通过自愿地减排航空碳排放来促进可持续行为，并通过3495份调查验证效果


<details>
  <summary>Details</summary>
Motivation: 推动策略对促进可持续行为有效，但效果取决于个人偏好。大语言模型能仿真人类决策，为个性化推动提供了成本效益方案

Method: 采用大语言模型设计个性化谜策基础的推动策略，通过中国、德国、印度、新加坡和美国的3495份调查进行验证

Result: 个性化推动比统一设置更有效，将减排率提高3-7%，年均减排碳排放230万吨，主要来自对减排计划信任度低的旅客的参与度提升

Conclusion: 研究显示了大语言模型驱动的个性化推动策略在提升减排行为、加速航空减排过程中的潜力

Abstract: Nudge strategies are effective tools for promoting sustainable behaviour, but
their impact depends on individual preferences. By emulating human
decision-making, large language models (LLMs) offer a cost-effective route for
tailoring nudges without extensive behavioural datasets, yet this potential
remains unexplored. Focusing on aviation, we use LLMs to design personalized
decoy-based nudge strategies that encourage air travellers to voluntarily
offset CO$_2$ emissions from flights, and validate their efficacy through 3495
surveys from China, Germany, India, Singapore, and the United States. Results
show that LLM-informed personalized nudges are more effective than uniform
settings, raising offsetting rates by 3-7$\%$ and yielding an additional 2.3
million tonnes of CO$_2$ mitigated annually in aviation. This improvement is
driven primarily by increased participation among sceptical travellers with low
trust in offset programmes. Our study highlights the potential of LLM-driven
personalized nudging strategies for boosting offsetting behaviours to
accelerate aviation decarbonization.

</details>


### [249] [Several Issues Regarding Data Governance in AGI](https://arxiv.org/abs/2508.12168)
*Masayuki Hatta*

Main category: cs.CY

TL;DR: 本文分析了AGI数据治理的七大独特挑战，包括自主数据收集、数据保留决策、AGI间数据共享、溯源追踪、知识产权、跨境执法和治理框架过时问题，提出了内置约束、持续监控、动态治理等解决方案


<details>
  <summary>Details</summary>
Motivation: 随着人工智能向通用人工智能（AGI）发展，现有数据治理框架无法应对具有自主数据能力的AGI系统带来的前所未有的挑战，需要专门的前瞻性治理方法

Method: 通过分析AGI系统的特性（递归自我改进和自我复制能力），识别出七个区别于传统AI治理的关键数据治理问题，并进行系统性分析

Result: 识别出AGI数据治理的七大核心挑战：1）自主数据收集绕过现有同意机制 2）基于内部标准的数据保留决策 3）超人类监督速度的AGI间数据共享 4）递归改进带来的溯源追踪难题 5）自我改进生成数据的所有权问题 6）跨境分布带来的执法挑战 7）治理框架快速过时风险

Conclusion: 有效的AGI数据治理需要内置约束、持续监控机制、动态治理结构、国际协调和多利益相关方参与，必须设计专门的前瞻性治理方法，防止AGI与数据的关系演化损害人类价值观和利益

Abstract: The rapid advancement of artificial intelligence has positioned data
governance as a critical concern for responsible AI development. While
frameworks exist for conventional AI systems, the potential emergence of
Artificial General Intelligence (AGI) presents unprecedented governance
challenges. This paper examines data governance challenges specific to AGI,
defined as systems capable of recursive self-improvement or self-replication.
We identify seven key issues that differentiate AGI governance from current
approaches. First, AGI may autonomously determine what data to collect and how
to use it, potentially circumventing existing consent mechanisms. Second, these
systems may make data retention decisions based on internal optimization
criteria rather than human-established principles. Third, AGI-to-AGI data
sharing could occur at speeds and complexities beyond human oversight. Fourth,
recursive self-improvement creates unique provenance tracking challenges, as
systems evolve both themselves and how they process data. Fifth, ownership of
data and insights generated through self-improvement raises complex
intellectual property questions. Sixth, self-replicating AGI distributed across
jurisdictions would create unprecedented challenges for enforcing data
protection laws. Finally, governance frameworks established during early AGI
development may quickly become obsolete as systems evolve. We conclude that
effective AGI data governance requires built-in constraints, continuous
monitoring mechanisms, dynamic governance structures, international
coordination, and multi-stakeholder involvement. Without forward-looking
governance approaches specifically designed for systems with autonomous data
capabilities, we risk creating AGI whose relationship with data evolves in ways
that undermine human values and interests.

</details>


### [250] [Urban AI Governance Must Embed Legal Reasonableness for Democratic and Sustainable Cities](https://arxiv.org/abs/2508.12174)
*Rashid Mushkani*

Main category: cs.CY

TL;DR: 本文提出在城市AI系统中嵌入法律"理性人"标准的Urban Reasonableness Layer框架，旨在通过参与式规范制定和场景分析，实现民主化AI治理，解决公平性、问责制和合法性等问题。


<details>
  <summary>Details</summary>
Motivation: 随着城市AI系统部署增加，公平性、问责制和规范性合法性等问题日益突出，需要建立民主可持续的城市治理框架来应对这些挑战。

Method: 提出Urban Reasonableness Layer概念框架，结合历史类比、场景映射和参与式规范制定方法，将法律"理性人"标准适配到市政AI监督中。

Result: 构建了包含概念架构、参与机制、治理轨迹场景分析和评估指标的综合框架，为城市AI治理提供了可操作的协商平台。

Conclusion: 该框架强调了多元主义、可争议性和社会技术系统的政治本质，为城市AI治理的持续辩论提供了重要贡献，推动自动化与民主进程的协调。

Abstract: This position paper argues that embedding the legal "reasonable person"
standard in municipal AI systems is essential for democratic and sustainable
urban governance. As cities increasingly deploy artificial intelligence (AI)
systems, concerns around equity, accountability, and normative legitimacy are
growing. This paper introduces the Urban Reasonableness Layer (URL), a
conceptual framework that adapts the legal "reasonable person" standard for
supervisory oversight in municipal AI systems, including potential future
implementations of Artificial General Intelligence (AGI). Drawing on historical
analogies, scenario mapping, and participatory norm-setting, we explore how
legal and community-derived standards can inform AI decision-making in urban
contexts. Rather than prescribing a fixed solution, the URL is proposed as an
exploratory architecture for negotiating contested values, aligning automation
with democratic processes, and interrogating the limits of technical alignment.
Our key contributions include: (1) articulating the conceptual and operational
architecture of the URL; (2) specifying participatory mechanisms for dynamic
normative threshold-setting; (3) presenting a comparative scenario analysis of
governance trajectories; and (4) outlining evaluation metrics and limitations.
This work contributes to ongoing debates on urban AI governance by
foregrounding pluralism, contestability, and the inherently political nature of
socio-technical systems.

</details>


### [251] [Mutually Assured Deregulation](https://arxiv.org/abs/2508.12300)
*Gilad Abiri*

Main category: cs.CY

TL;DR: 这篇论文提出"监管牺牲"的概念，计击通过弱化AI安全监管来获得技术优势的做法存在三大错误说法，并说明强化监管架构才是确保AI安全的正确道路。


<details>
  <summary>Details</summary>
Motivation: 国际社会对AI安全监管存在误区，认为放宽监管可以获得技术优势，导致各国竞相弱化安全措施。论文想要批判这种危险的"监管牺牲"思维。

Method: 通过分析"监管牺牲"的三个假话来进行批判：1)可持久技术领先的假话；2)解除监管促进创新的假话；3)通过解除监管增强国家安全的假话。以实际数据和历史比较为例证。

Result: 证明了监管牺牲的三个假话都是错误的：技术优势快速消失，相差从9%缩小到2%；良好监管反而提高效率；解除监管对各时期安全都产生洞巡。

Conclusion: 监管牺牲是一种危险的误区，它服务于权力利益而非真正安全。强化监管架构才是应对AI安全挑战的正确方向，竞争没有抱架的跑道只会导致集体脏脏。

Abstract: We have convinced ourselves that the way to make AI safe is to make it
unsafe. Since 2022, policymakers worldwide have embraced the Regulation
Sacrifice - the belief that dismantling safety oversight will deliver security
through AI dominance. Fearing China or USA will gain advantage, nations rush to
eliminate safeguards that might slow progress. This Essay reveals the fatal
flaw: though AI poses national security challenges, the solution demands
stronger regulatory frameworks, not weaker ones. A race without guardrails
breeds shared danger, not competitive strength. The Regulation Sacrifice makes
three false promises. First, it promises durable technological leads. But AI
capabilities spread rapidly - performance gaps between U.S. and Chinese systems
collapsed from 9 percent to 2 percent in thirteen months. When advantages
evaporate in months, sacrificing permanent safety for temporary speed makes no
sense. Second, it promises deregulation accelerates innovation. The opposite
often proves true. Companies report well-designed governance streamlines
development. Investment flows toward regulated markets. Clear rules reduce
uncertainty; uncertain liability creates paralysis. Environmental standards did
not kill the auto industry; they created Tesla and BYD. Third, enhanced
national security through deregulation actually undermines security across all
timeframes. Near term: it hands adversaries information warfare tools. Medium
term: it democratizes bioweapon capabilities. Long term: it guarantees
deployment of uncontrollable AGI systems. The Regulation Sacrifice persists
because it serves powerful interests, not security. Tech companies prefer
freedom to accountability. Politicians prefer simple stories to complex truths.
This creates mutually assured deregulation, where each nation's sprint for
advantage guarantees collective vulnerability. The only way to win is not to
play.

</details>


### [252] [Developing a Responsible AI Framework for Healthcare in Low Resource Countries: A Case Study in Nepal and Ghana](https://arxiv.org/abs/2508.12389)
*Hari Krishna Neupane,Bhupesh Kumar Mishra*

Main category: cs.CY

TL;DR: 本文通过尼泊尔和加纳的调查研究，分析了AI在医疗资源匮乏地区的应用挑战，提出了针对性的负责任AI框架来解决数据隐私、伦理监管等问题。


<details>
  <summary>Details</summary>
Motivation: 在尼泊尔和加纳等医疗资源匮乏地区，AI技术具有改善个性化医疗、优化资源配置和缓解医疗专业人员短缺的潜力，但面临数据隐私、可靠性和信任等重大障碍。

Method: 采用定量和定性的实地调查研究方法，收集和分析相关数据，识别关键挑战和需求。

Result: 调查显示85%的受访者认为伦理监管是关键问题，72%强调需要本地化治理结构。基于这些发现提出了包含伦理指南、监管合规机制和情境验证方法的负责任AI框架。

Conclusion: 针对资源受限环境设计的负责任AI框架可以有效缓解偏见，确保医疗公平性，为低资源地区的AI医疗应用提供可行的解决方案。

Abstract: The integration of Artificial Intelligence (AI) into healthcare systems in
low-resource settings, such as Nepal and Ghana, presents transformative
opportunities to improve personalized patient care, optimize resources, and
address medical professional shortages. This paper presents a survey-based
evaluation and insights from Nepal and Ghana, highlighting major obstacles such
as data privacy, reliability, and trust issues. Quantitative and qualitative
field studies reveal critical metrics, including 85% of respondents identifying
ethical oversight as a key concern, and 72% emphasizing the need for localized
governance structures. Building on these findings, we propose a draft
Responsible AI (RAI) Framework tailored to resourceconstrained environments in
these countries. Key elements of the framework include ethical guidelines,
regulatory compliance mechanisms, and contextual validation approaches to
mitigate bias and ensure equitable healthcare outcomes.

</details>


### [253] [Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health](https://arxiv.org/abs/2508.12998)
*Sanja Šćepanović,Sagar Joglekar,Stephen Law,Daniele Quercia,Ke Zhou,Alice Battiston,Rossano Schifanella*

Main category: cs.CY

TL;DR: 研究通过分析伦敦街道级别的港开政数据和街景图像，发现日常见到的路边绿化（on-road greenery）比传统官方绿地指标更能预测平均医疗处方额的减少，尤其是在高血压等慢性疾病方面。


<details>
  <summary>Details</summary>
Motivation: 过去研究将城市绿地与健康关联时存在不一致性，可能因为官方绿地指标只考虑绿地面积或距离，而忽视了人们日常生活中实际见到和使用绿地的频率。

Method: 重新分类绿地为路边绿化（行走时见到）和路外绿化（需专门访问），结合航拍图像、OpenStreetMap绿地数据、10万张Google街景图像和16万条道路可达性估计。将这些测量与国家健康服务系统的74.5亿份医疗处方连接，涵盖糖尿病、高血压、呐喘、抑郁、焦虑和阿片类药物使用。

Result: 路边绿化比四种广泛使用的官方指标更强地关联健康改善。例如，路边绿化高于全城中位数的区域高血压处方减少3.68%。如果所有低于中位数的区域达到全城中位数水平，每年处方费用可减少315万英镑。

Conclusion: 日常生活中见到的绿化比公共但隐秘的绿地更关键，官方指标存在重要局限性，建议改进城市绿化评估方法。

Abstract: Urban greenery is often linked to better health, yet findings from past
research have been inconsistent. One reason is that official greenery metrics
measure the amount or nearness of greenery but ignore how often people actually
may potentially see or use it in daily life. To address this gap, we introduced
a new classification that separates on-road greenery, which people see while
walking through streets, from off-road greenery, which requires planned visits.
We did so by combining aerial imagery of Greater London and greenery data from
OpenStreetMap with quantified greenery from over 100,000 Google Street View
images and accessibility estimates based on 160,000 road segments. We linked
these measures to 7.45 billion medical prescriptions issued by the National
Health Service and processed through our methodology. These prescriptions cover
five conditions: diabetes, hypertension, asthma, depression, and anxiety, as
well as opioid use. As hypothesized, we found that green on-road was more
strongly linked to better health than four widely used official measures. For
example, hypertension prescriptions dropped by 3.68% in wards with on-road
greenery above the median citywide level compared to those below it. If all
below-median wards reached the citywide median in on-road greenery,
prescription costs could fall by up to {\pounds}3.15 million each year. These
results suggest that greenery seen in daily life may be more relevant than
public yet secluded greenery, and that official metrics commonly used in the
literature have important limitations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [254] [Sparse Attention across Multiple-context KV Cache](https://arxiv.org/abs/2508.11661)
*Ziyi Cao,Qingyi Si,Jingbin Zhang,Bingquan Liu*

Main category: cs.LG

TL;DR: SamKV是首个针对多上下文KV Cache的注意力稀疏化方法，通过考虑其他上下文的互补信息进行稀疏化并局部重计算，在RAG场景中将序列长度压缩至15%且不损失精度


<details>
  <summary>Details</summary>
Motivation: 传统KV Cache重用方法在RAG多上下文场景中失效，因为检索文档的KV Cache是独立计算的，缺乏跨上下文注意力，现有方法无法减少内存开销

Method: SamKV在多上下文KV Cache稀疏化时考虑其他上下文的互补信息，然后对稀疏化信息进行局部重计算

Result: 实验表明该方法将序列长度压缩至15%，相比完全重计算基线没有精度损失，显著提升多上下文RAG场景的吞吐量

Conclusion: SamKV成功解决了多上下文KV Cache的稀疏化问题，为RAG场景提供了高效的内存压缩解决方案

Abstract: Large language models face significant cost challenges in long-sequence
inference. To address this, reusing historical Key-Value (KV) Cache for
improved inference efficiency has become a mainstream approach. Recent advances
further enhance throughput by sparse attention mechanisms to select the most
relevant KV Cache, thereby reducing sequence length. However, such techniques
are limited to single-context scenarios, where historical KV Cache is computed
sequentially with causal-attention dependencies. In retrieval-augmented
generation (RAG) scenarios, where retrieved documents as context are unknown
beforehand, each document's KV Cache is computed and stored independently
(termed multiple-context KV Cache), lacking cross-attention between contexts.
This renders existing methods ineffective. Although prior work partially
recomputes multiple-context KV Cache to mitigate accuracy loss from missing
cross-attention, it requires retaining all KV Cache throughout, failing to
reduce memory overhead. This paper presents SamKV, the first exploration of
attention sparsification for multiple-context KV Cache. Specifically, SamKV
takes into account the complementary information of other contexts when
sparsifying one context, and then locally recomputes the sparsified
information. Experiments demonstrate that our method compresses sequence length
to 15% without accuracy degradation compared with full-recompuation baselines,
significantly boosting throughput in multi-context RAG scenarios.

</details>


### [255] [Assessing Representation Stability for Transformer Models](https://arxiv.org/abs/2508.11667)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.LG

TL;DR: 提出了Representation Stability (RS)框架，通过测量掩码重要词时嵌入表示的变化来检测对抗文本攻击，无需重新训练模型，在多个数据集和攻击类型上达到88%以上的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗文本防御方法通常是攻击特定的或需要昂贵的模型重新训练，需要一个模型无关的检测框架来应对持续的对抗文本攻击威胁。

Method: RS框架首先使用重要性启发式对单词进行排名，然后测量掩码前k个关键词时的嵌入敏感性，最后使用BiLSTM检测器处理结果模式。使用NDCG衡量扰动识别质量。

Result: 在三个数据集、三种攻击类型和两个受害者模型上，RS达到超过88%的检测准确率，计算成本较低。基于梯度的排名方法优于注意力和随机选择方法。

Conclusion: RS框架无需重新训练就能很好地泛化到未见过的数据集、攻击和模型，为对抗文本检测提供了实用的解决方案。

Abstract: Adversarial text attacks remain a persistent threat to transformer models,
yet existing defenses are typically attack-specific or require costly model
retraining. We introduce Representation Stability (RS), a model-agnostic
detection framework that identifies adversarial examples by measuring how
embedding representations change when important words are masked. RS first
ranks words using importance heuristics, then measures embedding sensitivity to
masking top-k critical words, and processes the resulting patterns with a
BiLSTM detector. Experiments show that adversarially perturbed words exhibit
disproportionately high masking sensitivity compared to naturally important
words. Across three datasets, three attack types, and two victim models, RS
achieves over 88% detection accuracy and demonstrates competitive performance
compared to existing state-of-the-art methods, often at lower computational
cost. Using Normalized Discounted Cumulative Gain (NDCG) to measure
perturbation identification quality, we reveal that gradient-based ranking
outperforms attention and random selection approaches, with identification
quality correlating with detection performance for word-level attacks. RS also
generalizes well to unseen datasets, attacks, and models without retraining,
providing a practical solution for adversarial text detection.

</details>


### [256] [Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset](https://arxiv.org/abs/2508.11669)
*Wentao Li,Yonghu He,Kun Gao,Qing Liu,Yali Zheng*

Main category: cs.LG

TL;DR: 这篇论文提出了一种轻量级的KDCL_sInvResUNet模型，通过协同学习方案在嵌入式设备上实现了实时无创动脉血压监测，计算负荷仅0.02 GFLOPS，参数仅0.89百万，在大规模困术期患者数据集上达到了与大模型相似的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然现有深度学习模型能够从非侵入性生理信号重建动脉血压波形，但缺乏关于模型性能和计算负荷在嵌入式系统部署的研究。需要一种轻量级的方案来实现实时监测。

Method: 提出了轻量级sInvResUNet模型和KDCL_sInvResUNet协同学习方案，模型仅有0.89百万参数和0.02 GFLOPS计算负荷。在包含2,154名患者、1,257,141个数据段落的大规模困术期数据集上进行了主体独立验证。

Result: 模型在嵌入式设备上实现了10秒输出仅8.49毫秒的实时推理，平均绝对误差10.06 mmHg，皮尔透相关系数0.88，性能略好于大模型。但所有深度学习模型在不同人群和心血管条件下都显示出显著的性能变化。

Conclusion: 该研究为实际困术期环境中的实时无感知动脉血压监测奠定了基础，提供了进一步发展的基准线，但模型在广泛多样人群中的普适性仍有限。

Abstract: Noninvasive arterial blood pressure (ABP) monitoring is essential for patient
management in critical care and perioperative settings, providing continuous
assessment of cardiovascular hemodynamics with minimal risks. Numerous deep
learning models have developed to reconstruct ABP waveform from noninvasively
acquired physiological signals such as electrocardiogram and
photoplethysmogram. However, limited research has addressed the issue of model
performance and computational load for deployment on embedded systems. The
study introduces a lightweight sInvResUNet, along with a collaborative learning
scheme named KDCL_sInvResUNet. With only 0.89 million parameters and a
computational load of 0.02 GFLOPS, real-time ABP estimation was successfully
achieved on embedded devices with an inference time of just 8.49 milliseconds
for a 10-second output. We performed subject-independent validation in a
large-scale and heterogeneous perioperative dataset containing 1,257,141 data
segments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and
31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better
performance compared to large models, with a mean absolute error of 10.06 mmHg
and mean Pearson correlation of 0.88 in tracking ABP changes. Despite these
promising results, all deep learning models showed significant performance
variations across different demographic and cardiovascular conditions,
highlighting their limited ability to generalize across such a broad and
diverse population. This study lays a foundation work for real-time,
unobtrusive ABP monitoring in real-world perioperative settings, providing
baseline for future advancements in this area.

</details>


### [257] [Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning](https://arxiv.org/abs/2508.11673)
*Haojie Zhang,Yixiong Liang,Hulin Kuang,Lihui Cen,Zhe Qu,Yigang Cen,Min Zeng,Shichao Kan*

Main category: cs.LG

TL;DR: 提出MSLoRA-CR方法解决多模态生物医学图像增量学习问题，通过模态特定的LoRA模块和对比正则化实现知识保持和跨模态知识迁移


<details>
  <summary>Details</summary>
Motivation: 生物医学领域需要处理多种模态和任务，但为每个模态单独训练模型会增加推理成本，需要统一的增量学习模型

Method: 基于大型视觉语言模型，冻结预训练模型，为每个模态增量适配LoRA模块，并引入对比正则化促进模态内知识共享和模态间知识区分

Result: 在生物医学图像增量学习实验中，MSLoRA-CR相比为每个模态单独训练模型和通用增量学习方法表现更优，整体性能提升1.88%，同时保持计算效率

Conclusion: MSLoRA-CR有效解决了多模态生物医学图像增量学习的两个核心挑战，实现了更好的性能与效率平衡

Abstract: Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for
handling diverse tasks and modalities in the biomedical domain, as training
separate models for each modality or task significantly increases inference
costs. Existing incremental learning methods focus on task expansion within a
single modality, whereas MBIIL seeks to train a unified model incrementally
across modalities. The MBIIL faces two challenges: I) How to preserve
previously learned knowledge during incremental updates? II) How to effectively
leverage knowledge acquired from existing modalities to support new modalities?
To address these challenges, we propose MSLoRA-CR, a method that fine-tunes
Modality-Specific LoRA modules while incorporating Contrastive Regularization
to enhance intra-modality knowledge sharing and promote inter-modality
knowledge differentiation. Our approach builds upon a large vision-language
model (LVLM), keeping the pretrained model frozen while incrementally adapting
new LoRA modules for each modality or task. Experiments on the incremental
learning of biomedical images demonstrate that MSLoRA-CR outperforms both the
state-of-the-art (SOTA) approach of training separate models for each modality
and the general incremental learning method (incrementally fine-tuning LoRA).
Specifically, MSLoRA-CR achieves a 1.88% improvement in overall performance
compared to unconstrained incremental learning methods while maintaining
computational efficiency. Our code is publicly available at
https://github.com/VentusAislant/MSLoRA_CR.

</details>


### [258] [Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems](https://arxiv.org/abs/2508.11679)
*Shaodi Feng,Zhuoyi Lin,Jianan Zhou,Cong Zhang,Jingwen Li,Kuan-Wen Chen,Senthilnath Jayavelu,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 这篇论文提出了一种终身学习框架，通过Transformer网络和上下文调度器，让神经汇缆汽车路线解决器能够处理不同场景和规模的VRP问题，实现了更好的逆环境逆规模性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经解决器通常只在单一场景和规模下训练，导致在不同场景中应用效果差，需要提升其多用途性。

Method: 使用Transformer作为核心网络，提出跨上下文自注意力机制来转移知识，并通过动态上下文调度器进行经验回放。

Result: 在合成和标准数据集（问题规模达18k）上表现优异，能够处理不同场景的VRP问题，性能超过其他神经解决器。

Conclusion: 该组合方法有效提升了神经解决器的逆环境逆规模能力，为复杂应用场景下的VRP解决提供了新的解决方案。

Abstract: Deep learning has been extensively explored to solve vehicle routing problems
(VRPs), which yields a range of data-driven neural solvers with promising
outcomes. However, most neural solvers are trained to tackle VRP instances in a
relatively monotonous context, e.g., simplifying VRPs by using Euclidean
distance between nodes and adhering to a single problem size, which harms their
off-the-shelf application in different scenarios. To enhance their versatility,
this paper presents a novel lifelong learning framework that incrementally
trains a neural solver to manage VRPs in distinct contexts. Specifically, we
propose a lifelong learner (LL), exploiting a Transformer network as the
backbone, to solve a series of VRPs. The inter-context self-attention mechanism
is proposed within LL to transfer the knowledge obtained from solving preceding
VRPs into the succeeding ones. On top of that, we develop a dynamic context
scheduler (DCS), employing the cross-context experience replay to further
facilitate LL looking back on the attained policies of solving preceding VRPs.
Extensive results on synthetic and benchmark instances (problem sizes up to
18k) show that our LL is capable of discovering effective policies for tackling
generic VRPs in varying contexts, which outperforms other neural solvers and
achieves the best performance for most VRPs.

</details>


### [259] [Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics](https://arxiv.org/abs/2508.11680)
*Aditya Akella,Jonathan Farah*

Main category: cs.LG

TL;DR: 本研究评估了时间序列基础模型TimesFM在美国人口预测中的表现，相比传统方法在86.67%的测试案例中取得了最低均方误差，特别在历史数据稀疏的少数族裔群体预测上表现优异。


<details>
  <summary>Details</summary>
Motivation: 人口结构变化受全球化、经济状况、地缘政治事件和环境因素影响，给政策制定者和研究者带来重大挑战。准确的人口预测对于城市规划、医疗保健和经济政策等领域的决策至关重要。

Method: 使用美国人口普查局和美联储经济数据(FRED)的数据集，将时间序列基础模型TimesFM与LSTM网络、ARIMA和线性回归等传统基线方法进行比较评估。实验覆盖了6个人口结构多样化的州。

Result: TimesFM在86.67%的测试案例中实现了最低的均方误差(MSE)，特别是在历史数据稀疏的少数族裔人口预测方面表现尤为突出。

Conclusion: 研究结果表明预训练的基础模型有潜力增强人口分析能力，无需大量任务特定的微调即可为主动政策干预提供信息支持。

Abstract: Demographic shifts, influenced by globalization, economic conditions,
geopolitical events, and environmental factors, pose significant challenges for
policymakers and researchers. Accurate demographic forecasting is essential for
informed decision-making in areas such as urban planning, healthcare, and
economic policy. This study explores the application of time series foundation
models to predict demographic changes in the United States using datasets from
the U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate
the performance of the Time Series Foundation Model (TimesFM) against
traditional baselines including Long Short-Term Memory (LSTM) networks,
Autoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our
experiments across six demographically diverse states demonstrate that TimesFM
achieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with
particularly strong performance on minority populations with sparse historical
data. These findings highlight the potential of pre-trained foundation models
to enhance demographic analysis and inform proactive policy interventions
without requiring extensive task-specific fine-tuning.

</details>


### [260] [From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data](https://arxiv.org/abs/2508.11723)
*Qian Cao,Jielin Chen,Junchao Zhao,Rudi Stouffs*

Main category: cs.LG

TL;DR: 基于多源数据的基地规划布局指标系统(SPLI)，通过五大维度系统化量化城市空间布局，提高功能分类准确性和自动化分析能力


<details>
  <summary>Details</summary>
Motivation: 传统基地规划依靠经验判断和单一数据源，导致多功能布局系统量化不足，需要数据驱动的系统化解决方案

Method: 构建SPLI指标系统，整合OSM、POI、建筑形态、土地利用、卫星影像等多源数据，包含五大维度：层级化建筑功能分类、空间组织模式、功能多样性、基础服务可达性、土地利用强度，使用RGNN和GNN深度学习处理数据缺失

Result: 实验结果显示SPLI系统能够显著提高功能分类的准确性，为自动化的数据驱动城市空间分析提供了标准化基础

Conclusion: SPLI系统通过整合多源数据和深度学习技术，成功实现了城市基地布局的系统化量化分析，为智慧城市规划提供了数据驱动的决策支撑

Abstract: The spatial layout of urban sites shapes land-use efficiency and spatial
organization. Traditional site planning often relies on experiential judgment
and single-source data, limiting systematic quantification of multifunctional
layouts. We propose a Site Planning Layout Indicator (SPLI) system, a
data-driven framework integrating empirical knowledge with heterogeneous
multi-source data to produce structured urban spatial information. The SPLI
supports multimodal spatial data systems for analytics, inference, and
retrieval by combining OpenStreetMap (OSM), Points of Interest (POI), building
morphology, land use, and satellite imagery. It extends conventional metrics
through five dimensions: (1) Hierarchical Building Function Classification,
refining empirical systems into clear hierarchies; (2) Spatial Organization,
quantifying seven layout patterns (e.g., symmetrical, concentric,
axial-oriented); (3) Functional Diversity, transforming qualitative assessments
into measurable indicators using Functional Ratio (FR) and Simpson Index (SI);
(4) Accessibility to Essential Services, integrating facility distribution and
transport networks for comprehensive accessibility metrics; and (5) Land Use
Intensity, using Floor Area Ratio (FAR) and Building Coverage Ratio (BCR) to
assess utilization efficiency. Data gaps are addressed through deep learning,
including Relational Graph Neural Networks (RGNN) and Graph Neural Networks
(GNN). Experiments show the SPLI improves functional classification accuracy
and provides a standardized basis for automated, data-driven urban spatial
analytics.

</details>


### [261] [Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks](https://arxiv.org/abs/2508.11727)
*Songyao Jin,Biwei Huang*

Main category: cs.LG

TL;DR: 本文提出了一个用于识别多元霍克斯过程中潜在子过程和因果影响的两阶段迭代算法，通过离散时间模型表示连续时间事件序列，建立了可识别性的充分必要条件。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的复杂系统往往只有部分被观测到，存在潜在子过程，这对现有的主要关注观测子过程因果结构的方法提出了重大挑战。

Method: 将连续时间事件序列表示为离散时间模型，提出两阶段迭代算法：交替推断已发现子过程间的因果关系和发现新的潜在子过程，使用基于路径的条件保证可识别性。

Result: 在合成和真实数据集上的实验表明，该方法在存在潜在子过程的情况下能有效恢复因果结构。

Conclusion: 该方法为处理部分观测系统中的潜在子过程提供了有效的解决方案，通过离散时间表示和可识别性条件确保了因果结构的准确恢复。

Abstract: Multivariate Hawkes process provides a powerful framework for modeling
temporal dependencies and event-driven interactions in complex systems. While
existing methods primarily focus on uncovering causal structures among observed
subprocesses, real-world systems are often only partially observed, with latent
subprocesses posing significant challenges. In this paper, we show that
continuous-time event sequences can be represented by a discrete-time model as
the time interval shrinks, and we leverage this insight to establish necessary
and sufficient conditions for identifying latent subprocesses and the causal
influences. Accordingly, we propose a two-phase iterative algorithm that
alternates between inferring causal relationships among discovered subprocesses
and uncovering new latent subprocesses, guided by path-based conditions that
guarantee identifiability. Experiments on both synthetic and real-world
datasets show that our method effectively recovers causal structures despite
the presence of latent subprocesses.

</details>


### [262] [BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification](https://arxiv.org/abs/2508.11732)
*Xiangxiang Cui,Min Zhao,Dongmei Zhi,Shile Qi,Vince D Calhoun,Jing Sui*

Main category: cs.LG

TL;DR: 提出一种受脑组织启发的特征融合框架BRIEF，通过改进神经网络连接搜索和Transformer融合模块，自动优化网络结构，在精神分裂症和自闭谱障碍识别中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在fMRI分类中存在网络结构确定依赖经验、特征融合方式简单（主要为拼接）缺乏相互学习机制等问题

Method: 提出BRIEF框架：1）提取4种fMRI时间表征（时间序列、静态/动态功能连接、多尺度分散熵）构建编码器；2）使用改进Q学习动态优化神经网络连接搜索（NCS）；3）通过Transformer融合所有特征向量，利用稳定/时变连接和多尺度依赖关系

Result: 在精神分裂症（SZ，n=1100）和自闭谱障碍（ASD，n=1550）识别任务中，与21个现有模型相比，BRIEF表现明显优势（提升2.2%-12.1%），达到AUC 91.5%±0.6%（SZ）和78.4%±0.5%（ASD）

Conclusion: 这是首次将受脑组织启发的加强学习策略应用于fMRI基于精神障碍分类，显示了在识别精确神经影像生物标记方面的重要潜力

Abstract: Existing deep learning models for functional MRI-based classification have
limitations in network architecture determination (relying on experience) and
feature space fusion (mostly simple concatenation, lacking mutual learning).
Inspired by the human brain's mechanism of updating neural connections through
learning and decision-making, we proposed a novel BRain-Inspired feature Fusion
(BRIEF) framework, which is able to optimize network architecture automatically
by incorporating an improved neural network connection search (NCS) strategy
and a Transformer-based multi-feature fusion module. Specifically, we first
extracted 4 types of fMRI temporal representations, i.e., time series (TCs),
static/dynamic functional connection (FNC/dFNC), and multi-scale dispersion
entropy (MsDE), to construct four encoders. Within each encoder, we employed a
modified Q-learning to dynamically optimize the NCS to extract high-level
feature vectors, where the NCS is formulated as a Markov Decision Process.
Then, all feature vectors were fused via a Transformer, leveraging both
stable/time-varying connections and multi-scale dependencies across different
brain regions to achieve the final classification. Additionally, an attention
module was embedded to improve interpretability. The classification performance
of our proposed BRIEF was compared with 21 state-of-the-art models by
discriminating two mental disorders from healthy controls: schizophrenia (SZ,
n=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated
significant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching
an AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is
the first attempt to incorporate a brain-inspired, reinforcement learning
strategy to optimize fMRI-based mental disorder classification, showing
significant potential for identifying precise neuroimaging biomarkers.

</details>


### [263] [Scalable Geospatial Data Generation Using AlphaEarth Foundations Model](https://arxiv.org/abs/2508.11739)
*Luc Houriez,Sebastian Pilarski,Behzad Vahedi,Ali Ahmadalipour,Teo Honda Scully,Nicholas Aflitto,David Andre,Caroline Jaffe,Martha Wedner,Rich Mazzola,Josh Jeffery,Ben Messinger,Sage McGinley-Smith,Sarah Russell*

Main category: cs.LG

TL;DR: 利用Google DeepMind的AlphaEarth Foundations全球地理空间表示，通过随机森林和逻辑回归等基础模型，将美国LANDFIRE植被类型数据集扩展到加拿大，在13类和80类分类任务上分别达到81%和73%的准确率。


<details>
  <summary>Details</summary>
Motivation: 高质量的地理空间标注数据集通常局限于特定地理区域，无法覆盖全球范围，限制了地理空间分析的广度和深度。

Method: 利用AlphaEarth Foundations提供的全球地理空间表示作为输入特征，采用随机森林和逻辑回归等基础分类模型，将美国LANDFIRE Existing Vegetation Type数据集扩展到加拿大地区。

Result: 在13类(EvtPhys)分类任务上，模型在美国和加拿大验证集上分别达到81%和73%的分类准确率；在80类(EvtGp)分类任务上也取得了良好效果。定性分析显示预测结果与地面真实数据吻合。

Conclusion: 即使使用基础机器学习模型，结合高质量的全球地理空间表示，也能有效扩展地理空间标注数据集的地理覆盖范围，为全球尺度的地理空间分析提供了可行方案。

Abstract: High-quality labeled geospatial datasets are essential for extracting
insights and understanding our planet. Unfortunately, these datasets often do
not span the entire globe and are limited to certain geographic regions where
data was collected. Google DeepMind's recently released AlphaEarth Foundations
(AEF) provides an information-dense global geospatial representation designed
to serve as a useful input across a wide gamut of tasks. In this article we
propose and evaluate a methodology which leverages AEF to extend geospatial
labeled datasets beyond their initial geographic regions. We show that even
basic models like random forests or logistic regression can be used to
accomplish this task. We investigate a case study of extending LANDFIRE's
Existing Vegetation Type (EVT) dataset beyond the USA into Canada at two levels
of granularity: EvtPhys (13 classes) and EvtGp (80 classes). Qualitatively, for
EvtPhys, model predictions align with ground truth. Trained models achieve 81%
and 73% classification accuracy on EvtPhys validation sets in the USA and
Canada, despite discussed limitations.

</details>


### [264] [Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data](https://arxiv.org/abs/2508.11794)
*Hemanth Macharla,Mayukha Pal*

Main category: cs.LG

TL;DR: Fed-Meta-Align是一个四阶段联邦学习框架，通过序列化元初始化和双准则聚合机制，在非IID物联网设备数据上实现91.27%的平均故障分类准确率，比现有方法提升3%以上。


<details>
  <summary>Details</summary>
Motivation: 物联网设备中的实时故障分类对工业安全至关重要，但标准联邦学习在非IID数据环境下容易导致模型发散，需要新的解决方案。

Method: 四阶段框架：1）在公共数据集上训练基础模型；2）序列化元初始化阶段学习异构感知初始化；3）并行联邦学习阶段使用基于本地性能和余弦相似度的双准则聚合；4）设备端个性化阶段为每个设备定制专家模型。

Result: 在异构物联网设备上平均测试准确率达到91.27%，比个性化FedAvg和FedProx分别高出3.87%和3.37%（在电气和机械故障数据集上）。

Conclusion: 这种序列化初始化和自适应聚合的多阶段方法为在多样化TinyML网络上部署高性能智能提供了稳健途径。

Abstract: Real-time fault classification in resource-constrained Internet of Things
(IoT) devices is critical for industrial safety, yet training robust models in
such heterogeneous environments remains a significant challenge. Standard
Federated Learning (FL) often fails in the presence of non-IID data, leading to
model divergence. This paper introduces Fed-Meta-Align, a novel four-phase
framework designed to overcome these limitations through a sophisticated
initialization and training pipeline. Our process begins by training a
foundational model on a general public dataset to establish a competent
starting point. This model then undergoes a serial meta-initialization phase,
where it sequentially trains on a subset of IOT Device data to learn a
heterogeneity-aware initialization that is already situated in a favorable
region of the loss landscape. This informed model is subsequently refined in a
parallel FL phase, which utilizes a dual-criterion aggregation mechanism that
weights for IOT devices updates based on both local performance and cosine
similarity alignment. Finally, an on-device personalization phase adapts the
converged global model into a specialized expert for each IOT Device.
Comprehensive experiments demonstrate that Fed-Meta-Align achieves an average
test accuracy of 91.27% across heterogeneous IOT devices, outperforming
personalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and
mechanical fault datasets, respectively. This multi-stage approach of sequenced
initialization and adaptive aggregation provides a robust pathway for deploying
high-performance intelligence on diverse TinyML networks.

</details>


### [265] [Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes](https://arxiv.org/abs/2508.11800)
*Michael Bereket,Jure Leskovec*

Main category: cs.LG

TL;DR: 本研究探讨了在具有随机结果的验证性领域（如科学实验）中，当前RL方法优化语言模型的效果，发现GRPO会导致过度自信的概率预测，而PPO和RLOO能产生良好校准的模型。


<details>
  <summary>Details</summary>
Motivation: 虽然RL在确定性领域（如数学）中能有效提高语言模型的准确性，但在具有随机结果的验证性领域（如科学实验）中的效果尚不清楚，需要研究当前RL方法在这些领域的适用性。

Method: 通过合成数据和真实生物实验的应用，比较了Group Relative Policy Optimization (GRPO)、Proximal Policy Optimization (PPO)和REINFORCE Leave-One-Out (RLOO)等方法在优化语言模型时的表现。

Result: GRPO会导致二元随机结果的过度自信概率预测，而PPO和RLOO能产生良好校准的模型。移除GRPO中的组标准化可以修复其校准问题。

Conclusion: 研究结果反对在GRPO中使用标准归一化，为RL在超越确定性领域的推理语言模型应用铺平了道路。

Abstract: Reinforcement learning (RL) has proven remarkably effective at improving the
accuracy of language models in verifiable and deterministic domains like
mathematics. Here, we examine if current RL methods are also effective at
optimizing language models in verifiable domains with stochastic outcomes, like
scientific experiments. Through applications to synthetic data and real-world
biological experiments, we demonstrate that Group Relative Policy Optimization
(GRPO) induces overconfident probability predictions for binary stochastic
outcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out
(RLOO) yield well-calibrated models. We show that removing group standard
normalization in GRPO fixes its miscalibration and provide a theoretical
explanation for why normalization causes overconfidence. Our results provide
new evidence against the use of standard normalization in GRPO and help pave
the way for applications of RL for reasoning language models beyond
deterministic domains.

</details>


### [266] [FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation](https://arxiv.org/abs/2508.11810)
*Nitish Nagesh,Salar Shakibhamedan,Mahdi Bagheri,Ziyu Wang,Nima TaheriNejad,Axel Jantsch,Amir M. Rahmani*

Main category: cs.LG

TL;DR: FairTabGen是一个基于大语言模型的公平感知表格数据生成框架，通过整合反事实和因果公平性定义，在保持数据效用的同时显著提升公平性指标。


<details>
  <summary>Details</summary>
Motivation: 在隐私敏感和数据稀缺的环境中生成合成表格数据时，需要同时改善反事实和因果公平性，同时保持高数据效用。现有方法在这方面存在不足。

Method: 使用基于大语言模型的框架，整合多种公平性定义，采用上下文学习、提示优化和公平感知数据管理来平衡公平性和效用。

Result: 在多个数据集上优于最先进的GAN和LLM方法，公平性指标（如人口统计均等和路径特定因果效应）提升高达10%，仅使用不到20%的原始数据。

Conclusion: 该方法提供了一种原则性和实用的途径来生成公平且有用的合成表格数据，特别适用于低数据环境。

Abstract: Generating synthetic data is crucial in privacy-sensitive, data-scarce
settings, especially for tabular datasets widely used in real-world
applications. A key challenge is improving counterfactual and causal fairness,
while preserving high utility. We present FairTabGen, a fairness-aware large
language model-based framework for tabular synthetic data generation. We
integrate multiple fairness definitions including counterfactual and causal
fairness into both its generation and evaluation pipelines. We use in-context
learning, prompt refinement, and fairness-aware data curation to balance
fairness and utility. Across diverse datasets, our method outperforms
state-of-the-art GAN-based and LLM-based methods, achieving up to 10%
improvements on fairness metrics such as demographic parity and path-specific
causal effects while retaining statistical utility. Remarkably, it achieves
these gains using less than 20% of the original data, highlighting its
efficiency in low-data regimes. These results demonstrate a principled and
practical approach for generating fair and useful synthetic tabular data.

</details>


### [267] [Combinations of Fast Activation and Trigonometric Functions in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.11876)
*Hoang-Thang Ta,Duy-Quy Thai,Phuong-Linh Tran-Thi*

Main category: cs.LG

TL;DR: 本文提出在KANs中使用ReLU咄三角函数等高效计算函数作为基础组件，以提升计算效率咄演化性能


<details>
  <summary>Details</summary>
Motivation: 屏影Kolmogorov-Arnold表示定理的KANs网络使用的B样条咄径向基函数在GPU设备上支持不充分且计算效率较低，需要更高效的函数组合

Method: 采用ReLU、sin、cos、arctan等高速计算函数作为KANs的基础组件，将这些函数组合集成到网络结构中

Result: 实验结果显示这种函数组合在保持竞争性能的同时，能够提升训练时间咄演化能力

Conclusion: 使用高效计算函数组合可以在KANs中实现更好的计算效率咄性能平衡

Abstract: For years, many neural networks have been developed based on the
Kolmogorov-Arnold Representation Theorem (KART), which was created to address
Hilbert's 13th problem. Recently, relying on KART, Kolmogorov-Arnold Networks
(KANs) have attracted attention from the research community, stimulating the
use of polynomial functions such as B-splines and RBFs. However, these
functions are not fully supported by GPU devices and are still considered less
popular. In this paper, we propose the use of fast computational functions,
such as ReLU and trigonometric functions (e.g., ReLU, sin, cos, arctan), as
basis components in Kolmogorov-Arnold Networks (KANs). By integrating these
function combinations into the network structure, we aim to enhance
computational efficiency. Experimental results show that these combinations
maintain competitive performance while offering potential improvements in
training time and generalization.

</details>


### [268] [PCA- and SVM-Grad-CAM for Convolutional Neural Networks: Closed-form Jacobian Expression](https://arxiv.org/abs/2508.11880)
*Yuto Omae*

Main category: cs.LG

TL;DR: 提出PCA-Grad-CAM和SVM-Grad-CAM方法，解决传统Grad-CAM无法直接应用于CNN中PCA和SVM层的问题，通过求解闭式雅可比矩阵实现可视化关注区域


<details>
  <summary>Details</summary>
Motivation: 当训练样本有限时，CNN中添加PCA层和/或SVM分类器可提升性能，但传统Grad-CAM无法直接应用于这些层，需要新方法来可视化关注区域

Method: 提出PCA-Grad-CAM和SVM-Grad-CAM方法，通过求解从最后卷积层到PCA和SVM层的闭式雅可比矩阵（Jacobian），实现对这些层的注意力可视化

Result: 在多个主要数据集上展示了方法的可视化结果，证明了方法的有效性

Conclusion: 该研究成功开发了能够可视化CNN中PCA和SVM层关注区域的新方法，为有限训练数据情况下的白盒分析提供了工具

Abstract: Convolutional Neural Networks (CNNs) are an effective approach for
classification tasks, particularly when the training dataset is large. Although
CNNs have long been considered a black-box classification method, they can be
used as a white-box method through visualization techniques such as Grad-CAM.
When training samples are limited, incorporating a Principal Component Analysis
(PCA) layer and/or a Support Vector Machine (SVM) classifier into a CNN can
effectively improve classification performance. However, traditional Grad-CAM
cannot be directly applied to PCA and/or SVM layers. It is important to
generate attention regions for PCA and/or SVM layers in CNNs to facilitate the
development of white-box methods. Therefore, we propose ``PCA-Grad-CAM'', a
method for visualizing attention regions in PCA feature vectors, and
``SVM-Grad-CAM'', a method for visualizing attention regions in an SVM
classifier layer. To complete our methods analytically, it is necessary to
solve the closed-form Jacobian consisting of partial derivatives from the last
convolutional layer to the PCA and/or SVM layers. In this paper, we present the
exact closed-form Jacobian and the visualization results of our methods applied
to several major datasets.

</details>


### [269] [ENA: Efficient N-dimensional Attention](https://arxiv.org/abs/2508.11921)
*Yibo Zhong*

Main category: cs.LG

TL;DR: 本文提出了ENA（高效N维注意力）架构，结合线性循环和高阶滑动窗口注意力，为超长高维数据建模提供高效解决方案


<details>
  <summary>Details</summary>
Motivation: Transformer架构在处理长序列高维数据时效率不足，需要更高效的架构来扩展线性循环模型到高维数据

Method: 研究扫描策略和注意力混合架构，发现注意力混合模型效果更好，特别采用分块高阶滑动窗口注意力(SWA)与线性循环结合

Result: 实验证明ENA架构在理论和实践中都表现高效，线性循环压缩全局信息，SWA强化局部建模，两者互补

Conclusion: ENA架构为超长高维数据建模提供了一个简单而实用的解决方案，结合了全局信息压缩和局部建模的优势

Abstract: Efficient modeling of long sequences of high-order data requires a more
efficient architecture than Transformer. In this paper, we investigate two key
aspects of extending linear recurrent models, especially those originally
designed for language modeling, to high-order data (1D to ND): scanning
strategies and attention-hybrid architectures. Empirical results suggest that
scanning provides limited benefits, while attention-hybrid models yield
promising results. Focusing on the latter, we further evaluate types of
attention and find that tiled high-order sliding window attention (SWA) is
efficient in both theory and practice. We term the resulting hybrid
architecture of linear recurrence and high-order SWA as Efficient N-dimensional
Attention (ENA). We then conduct several experiments to demonstrate its
effectiveness. The intuition behind ENA is that linear recurrence compresses
global information into a state, while SWA complements it by enforcing strict
local modeling. Together, they form a simple framework that offers a promising
and practical solution for ultra-long high-order data modeling.

</details>


### [270] [Scale-Disentangled spatiotemporal Modeling for Long-term Traffic Emission Forecasting](https://arxiv.org/abs/2508.11923)
*Yan Wu,Lihong Pei,Yukai Han,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 通过解耦多尺度时空特征的SDSTM框架，利用Koopman算子和门控小波分解策略，通过双流游独立性约束提升长期交通排放预测准确性


<details>
  <summary>Details</summary>
Motivation: 传统时空图模型在长期交通排放预测中存在多尺度缠络问题和级联错误放大，需要解决这些限制预测准确性的问题

Method: 提出尺度解耦时空建模(SDSTM)框架：1)基于Koopman提升算子的双流游特征分解策略，将尺度耦合系统提升到无穷维线性空间；2)使用门控小波分解划定预测性边界；3)构建新的融合机制，包含基于交叉项损失的双流游独立性约束

Result: 在西安二环路道路级交通排放数据集上进行的广泛实验表明，该模型达到了最先进的性能

Conclusion: SDSTM框架通过有效解耦多尺度时空特征，减少互相干扰，显著提升了长期交通排放预测的准确性，为城市空气污染管理提供了有效技术支撑

Abstract: Long-term traffic emission forecasting is crucial for the comprehensive
management of urban air pollution. Traditional forecasting methods typically
construct spatiotemporal graph models by mining spatiotemporal dependencies to
predict emissions. However, due to the multi-scale entanglement of traffic
emissions across time and space, these spatiotemporal graph modeling method
tend to suffer from cascading error amplification during long-term inference.
To address this issue, we propose a Scale-Disentangled Spatio-Temporal Modeling
(SDSTM) framework for long-term traffic emission forecasting. It leverages the
predictability differences across multiple scales to decompose and fuse
features at different scales, while constraining them to remain independent yet
complementary. Specifically, the model first introduces a dual-stream feature
decomposition strategy based on the Koopman lifting operator. It lifts the
scale-coupled spatiotemporal dynamical system into an infinite-dimensional
linear space via Koopman operator, and delineates the predictability boundary
using gated wavelet decomposition. Then a novel fusion mechanism is
constructed, incorporating a dual-stream independence constraint based on
cross-term loss to dynamically refine the dual-stream prediction results,
suppress mutual interference, and enhance the accuracy of long-term traffic
emission prediction. Extensive experiments conducted on a road-level traffic
emission dataset within Xi'an's Second Ring Road demonstrate that the proposed
model achieves state-of-the-art performance.

</details>


### [271] [An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction](https://arxiv.org/abs/2508.11931)
*Tim van Erven,Jack Mayo,Julia Olkhovskaya,Chen-Yu Wei*

Main category: cs.LG

TL;DR: 提出一种高效算法，解决带有攻击性损失和随机动作集的线性上下文腔力机问题，达到多项式时间内的poly(d)√T悔悔界


<details>
  <summary>Details</summary>
Motivation: 解决Liu等人(2023)开放问题：是否能够在不依赖动作数量的情况下，在多项式时间内获得poly(d)√T悔悔界

Method: 将该问题约减为具有固定动作集的错误规范漳健性攻击性线性腔力机问题

Result: 算法达到了Õ(min{d²√T, √(d³T log K)})悔悔界，运行时间为poly(d,C,T)，对组合腔力机问题首次实现多项式时间内的poly(d)√T悔悔界

Conclusion: 该算法成功解决了重要的线性上下文腔力机问题，在无需上下文分布知识或模拟器的情况下供应了高效的解决方案

Abstract: We present an efficient algorithm for linear contextual bandits with
adversarial losses and stochastic action sets. Our approach reduces this
setting to misspecification-robust adversarial linear bandits with fixed action
sets. Without knowledge of the context distribution or access to a context
simulator, the algorithm achieves $\tilde{O}(\min\{d^2\sqrt{T}, \sqrt{d^3T\log
K}\})$ regret and runs in $\text{poly}(d,C,T)$ time, where $d$ is the feature
dimension, $C$ is an upper bound on the number of linear constraints defining
the action set in each round, $K$ is an upper bound on the number of actions in
each round, and $T$ is number of rounds. This resolves the open question by Liu
et al. (2023) on whether one can obtain $\text{poly}(d)\sqrt{T}$ regret in
polynomial time independent of the number of actions. For the important class
of combinatorial bandits with adversarial losses and stochastic action sets
where the action sets can be described by a polynomial number of linear
constraints, our algorithm is the first to achieve $\text{poly}(d)\sqrt{T}$
regret in polynomial time, while no prior algorithm achieves even $o(T)$ regret
in polynomial time to our knowledge. When a simulator is available, the regret
bound can be improved to $\tilde{O}(d\sqrt{L^\star})$, where $L^\star$ is the
cumulative loss of the best policy.

</details>


### [272] [M3OOD: Automatic Selection of Multimodal OOD Detectors](https://arxiv.org/abs/2508.11936)
*Yuehan Qin,Li Li,Defu Cao,Tiankai Yang,Yue Zhao*

Main category: cs.LG

TL;DR: M3OOD是一个基于元学习的多模态OOD检测器选择框架，能够自动为不同分布偏移推荐合适的OOD检测模型，在12个测试场景中优于10个基线方法。


<details>
  <summary>Details</summary>
Motivation: 多模态环境下的OOD鲁棒性是关键挑战，单个OOD检测器无法在所有场景中都表现最佳，且由于OOD检测的无监督特性，手动选择模型成本高且不切实际。

Method: 提出M3OOD框架，结合多模态嵌入和手工设计的元特征来表示数据集，利用元学习从历史模型行为中学习，快速适应新的数据分布偏移。

Result: 在12个测试场景中，M3OOD始终优于10个竞争基线方法，且计算开销最小。

Conclusion: M3OOD通过元学习方法有效解决了多模态环境下OOD检测器的自动选择问题，为不同分布偏移推荐合适的检测器，具有实际应用价值。

Abstract: Out-of-distribution (OOD) robustness is a critical challenge for modern
machine learning systems, particularly as they increasingly operate in
multimodal settings involving inputs like video, audio, and sensor data.
Currently, many OOD detection methods have been proposed, each with different
designs targeting various distribution shifts. A single OOD detector may not
prevail across all the scenarios; therefore, how can we automatically select an
ideal OOD detection model for different distribution shifts? Due to the
inherent unsupervised nature of the OOD detection task, it is difficult to
predict model performance and find a universally Best model. Also,
systematically comparing models on the new unseen data is costly or even
impractical. To address this challenge, we introduce M3OOD, a
meta-learning-based framework for OOD detector selection in multimodal
settings. Meta learning offers a solution by learning from historical model
behaviors, enabling rapid adaptation to new data distribution shifts with
minimal supervision. Our approach combines multimodal embeddings with
handcrafted meta-features that capture distributional and cross-modal
characteristics to represent datasets. By leveraging historical performance
across diverse multimodal benchmarks, M3OOD can recommend suitable detectors
for a new data distribution shift. Experimental evaluation demonstrates that
M3OOD consistently outperforms 10 competitive baselines across 12 test
scenarios with minimal computational overhead.

</details>


### [273] [Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware](https://arxiv.org/abs/2508.11940)
*Yuannuo Feng,Wenyong Zhou,Yuexi Lyu,Yixiang Zhang,Zhengwu Liu,Ngai Wong,Wang Kang*

Main category: cs.LG

TL;DR: 提出了一种基于直通估计器(STE)框架的模拟存内计算噪声感知训练方法，通过解耦前向噪声模拟和后向梯度计算，实现了更准确但计算复杂的噪声建模，在保持计算可行性和优化稳定性的同时显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 模拟存内计算架构虽然能显著提升神经网络推理的能效，但面临复杂的硬件噪声挑战。现有的噪声感知训练方法依赖于理想化且可微的噪声模型，无法完全捕捉模拟CIM硬件变化的复杂性。

Method: 借鉴量化中的直通估计器(STE)框架，将前向噪声模拟与后向梯度计算解耦，使得能够使用更准确但计算复杂的噪声模型进行噪声感知训练，同时保持理论上的梯度方向信息和计算可行性。

Result: 实验结果显示，该方法在图像分类上实现了5.3%的准确率提升，文本生成上降低了0.72的困惑度，训练时间加速2.2倍，峰值内存使用降低37.9%，相比标准噪声感知训练方法有显著改进。

Conclusion: 该扩展STE框架为模拟存内计算系统提供了一种有效的噪声感知训练解决方案，能够在保持计算效率的同时处理复杂的硬件噪声，为实际部署提供了重要支持。

Abstract: Analog Compute-In-Memory (CIM) architectures promise significant energy
efficiency gains for neural network inference, but suffer from complex
hardware-induced noise that poses major challenges for deployment. While
noise-aware training methods have been proposed to address this issue, they
typically rely on idealized and differentiable noise models that fail to
capture the full complexity of analog CIM hardware variations. Motivated by the
Straight-Through Estimator (STE) framework in quantization, we decouple forward
noise simulation from backward gradient computation, enabling noise-aware
training with more accurate but computationally intractable noise modeling in
analog CIM systems. We provide theoretical analysis demonstrating that our
approach preserves essential gradient directional information while maintaining
computational tractability and optimization stability. Extensive experiments
show that our extended STE framework achieves up to 5.3% accuracy improvement
on image classification, 0.72 perplexity reduction on text generation,
2.2$\times$ speedup in training time, and 37.9% lower peak memory usage
compared to standard noise-aware training methods.

</details>


### [274] [Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/abs/2508.11943)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yan Wang*

Main category: cs.LG

TL;DR: 该研究提出了CFF方法，通过结合反事实和事实解释来为标记时间点过程模型提供最小且合理的解释子集，解决了直接使用单一解释方法会导致非理性解释的问题。


<details>
  <summary>Details</summary>
Motivation: 神经网络标记时间点过程模型在高风险应用中广泛使用，但其输出的可信度存在担忧，需要提供可解释的解释来增强信任。

Method: 提出CFF方法，结合反事实解释和事实解释，通过精心设计的技术识别历史事件中的最小子集作为解释。

Result: 实验证明CFF在解释质量和处理效率方面优于基线方法，能够提供正确且优越的解释。

Conclusion: CFF方法有效解决了MTPP模型的解释问题，为高风险应用中的可信AI提供了重要支撑。

Abstract: Neural network-based Marked Temporal Point Process (MTPP) models have been
widely adopted to model event sequences in high-stakes applications, raising
concerns about the trustworthiness of outputs from these models. This study
focuses on Explanation for MTPP, aiming to identify the minimal and rational
explanation, that is, the minimum subset of events in history, based on which
the prediction accuracy of MTPP matches that based on full history to a great
extent and better than that based on the complement of the subset. This study
finds that directly defining Explanation for MTPP as counterfactual explanation
or factual explanation can result in irrational explanations. To address this
issue, we define Explanation for MTPP as a combination of counterfactual
explanation and factual explanation. This study proposes Counterfactual and
Factual Explainer for MTPP (CFF) to solve Explanation for MTPP with a series of
deliberately designed techniques. Experiments demonstrate the correctness and
superiority of CFF over baselines regarding explanation quality and processing
efficiency.

</details>


### [275] [Set-Valued Transformer Network for High-Emission Mobile Source Identification](https://arxiv.org/abs/2508.11976)
*Yunning Cao,Lihong Pei,Jian Guo,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 提出Set-Valued Transformer Network (SVTN)来解决高排放车辆识别中的长尾分布问题，通过transformer学习时间相似性和集合值识别算法，在合肥柴油车数据上实现9.5%的漏检率降低


<details>
  <summary>Details</summary>
Motivation: 实际监测数据中高排放状态数据比例远低于正常排放状态，呈现长尾分布特征，严重阻碍了排放状态识别中判别性特征的提取。同时车辆排放状态的高度非线性和缺乏先验知识也给模型构建带来挑战

Method: 使用transformer测量微行程条件变化的时间相似性，构建从高维排放数据到低维特征空间的映射规则；采用集合值识别算法对特征向量与标签关系进行概率建模，为分类算法提供准确度量标准

Result: 在合肥市2020年柴油车监测数据上的实验表明，相比基于transformer的基线方法，该方法将高排放车辆的漏检率降低了9.5%

Conclusion: SVTN方法能够从高排放样本中全面学习判别性特征，显著提高了高排放移动污染源的准确识别能力

Abstract: Identifying high-emission vehicles is a crucial step in regulating urban
pollution levels and formulating traffic emission reduction strategies.
However, in practical monitoring data, the proportion of high-emission state
data is significantly lower compared to normal emission states. This
characteristic long-tailed distribution severely impedes the extraction of
discriminative features for emission state identification during data mining.
Furthermore, the highly nonlinear nature of vehicle emission states and the
lack of relevant prior knowledge also pose significant challenges to the
construction of identification models.To address the aforementioned issues, we
propose a Set-Valued Transformer Network (SVTN) to achieve comprehensive
learning of discriminative features from high-emission samples, thereby
enhancing detection accuracy. Specifically, this model first employs the
transformer to measure the temporal similarity of micro-trip condition
variations, thus constructing a mapping rule that projects the original
high-dimensional emission data into a low-dimensional feature space. Next, a
set-valued identification algorithm is used to probabilistically model the
relationship between the generated feature vectors and their labels, providing
an accurate metric criterion for the classification algorithm. To validate the
effectiveness of our proposed approach, we conducted extensive experiments on
the diesel vehicle monitoring data of Hefei city in 2020. The results
demonstrate that our method achieves a 9.5\% reduction in the missed detection
rate for high-emission vehicles compared to the transformer-based baseline,
highlighting its superior capability in accurately identifying high-emission
mobile pollution sources.

</details>


### [276] [Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models](https://arxiv.org/abs/2508.11985)
*Zhanhao Cao,Clement Truong,Andrew Lizarraga*

Main category: cs.LG

TL;DR: 基于超位原理的偏差相加方法，可以通过简单相加独立训练的LoRA模块来组合不同领域的知识，无需重新训练便可达到混合数据训练的效果。


<details>
  <summary>Details</summary>
Motivation: 利用LoRA模块的低程度特性，探索如何通过简单的模块组合方式来实现多领域知识的融合，避免重新训练的高成本。

Method: 训练不同领域（数学、医学、金融）的独立LoRA模块，然后通过简单相加的方式组合这些模块，并测试组合后的性能。

Result: 数学+医学组合优于混合数据训练（-9.10%），而其他组合发生了干扰。LoRA偏差之间的余弦相似度与性能变化呈正相关。

Conclusion: 无训练的偏差相加方法能够实现类似混合数据训练的效果，并可以通过偏差相似度预测组合效果。

Abstract: Recent advances in large language models are driven by scale, while
parameter-efficient fine-tuning (PEFT) enables updating only a small fraction
of parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the
product of two small matrices, which makes them natural building blocks that
can be composed. Motivated by the superposition principle, we hypothesize that
independently trained LoRA modules on disjoint domains are approximately
orthogonal and can be combined by simple addition. Using GPT-2 Small (117M)
with LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,
medicine, finance). In pairwise tests, adding Math+Medicine adapters improves
perplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance
and Finance+Medicine change by +4.54% and +27.56%, respectively. Across
combinations, the RMS cosine similarity between LoRA deltas correlates
positively and approximately linearly with the change in perplexity. Naive
summation requires no additional training, can be applied in seconds, and
achieves performance comparable to models trained on merged data, while
clarifying when interference appears in higher-order compositions.

</details>


### [277] [Universal Learning of Nonlinear Dynamics](https://arxiv.org/abs/2508.11990)
*Evan Dogariu,Anand Brahmbhatt,Elad Hazan*

Main category: cs.LG

TL;DR: 提出了一种基于谱滤波的算法，用于学习具有有限边际稳定模式的非线性动态系统，通过在线凸优化技术证明预测误差趋近于零。


<details>
  <summary>Details</summary>
Motivation: 解决学习未知非线性动态系统的基本问题，特别是那些具有边际稳定模式的系统，这类系统在控制理论中很重要但学习难度大。

Method: 使用谱滤波技术，基于系统的谱表示构建从过去观测到下一时刻的映射。开发了新的谱滤波算法，适用于一般噪声和边际稳定线性系统，并扩展到非线性系统。

Result: 证明了对于任何具有有限边际稳定模式的非线性动态系统，预测误差都会趋近于零，学习速率由新的可学习性量化控制理论概念决定。

Conclusion: 该方法显著推广了原始谱滤波算法，适用于非对称动态和噪声校正，为学习边际稳定非线性动态系统提供了有效解决方案。

Abstract: We study the fundamental problem of learning a marginally stable unknown
nonlinear dynamical system. We describe an algorithm for this problem, based on
the technique of spectral filtering, which learns a mapping from past
observations to the next based on a spectral representation of the system.
Using techniques from online convex optimization, we prove vanishing prediction
error for any nonlinear dynamical system that has finitely many marginally
stable modes, with rates governed by a novel quantitative control-theoretic
notion of learnability. The main technical component of our method is a new
spectral filtering algorithm for linear dynamical systems, which incorporates
past observations and applies to general noisy and marginally stable systems.
This significantly generalizes the original spectral filtering algorithm to
both asymmetric dynamics as well as incorporating noise correction, and is of
independent interest.

</details>


### [278] [FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing](https://arxiv.org/abs/2508.12021)
*You Hak Lee,Xiaofan Yu,Quanling Zhao,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: FedUHD是一个基于超维计算(HDC)的无监督联邦学习框架，相比基于深度神经网络的方法，在训练速度、能效、通信成本和准确性方面都有显著提升，同时对通信噪声具有更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 无监督联邦学习(UFL)面临非独立同分布数据、边缘设备计算通信成本高、通信噪声脆弱性等挑战。传统基于深度神经网络的方法存在计算和通信开销大的问题。

Method: 提出基于超维计算(HDC)的FedUHD框架：客户端使用kNN聚类超向量去除方法处理非iid数据异常值；服务器端采用加权HDC聚合技术平衡客户端间的非iid数据分布。

Result: 相比最先进的基于神经网络的UFL方法，FedUHD实现了：训练速度提升173.6倍，能效提升612.7倍，通信成本降低271倍，平均准确率提高15.50%，对各种噪声具有更好的鲁棒性。

Conclusion: FedUHD证明了基于HDC的方法在无监督联邦学习中具有显著优势，为隐私保护、去中心化的机器学习提供了更高效、更鲁棒的解决方案。

Abstract: Unsupervised federated learning (UFL) has gained attention as a
privacy-preserving, decentralized machine learning approach that eliminates the
need for labor-intensive data labeling. However, UFL faces several challenges
in practical applications: (1) non-independent and identically distributed
(non-iid) data distribution across devices, (2) expensive computational and
communication costs at the edge, and (3) vulnerability to communication noise.
Previous UFL approaches have relied on deep neural networks (NN), which
introduce substantial overhead in both computation and communication. In this
paper, we propose FedUHD, the first UFL framework based on Hyperdimensional
Computing (HDC). HDC is a brain-inspired computing scheme with lightweight
training and inference operations, much smaller model size, and robustness to
communication noise. FedUHD introduces two novel HDC-based designs to improve
UFL performance. On the client side, a kNN-based cluster hypervector removal
method addresses non-iid data samples by eliminating detrimental outliers. On
the server side, a weighted HDC aggregation technique balances the non-iid data
distribution across clients. Our experiments demonstrate that FedUHD achieves
up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in
training, up to 271x lower communication cost, and 15.50% higher accuracy on
average across diverse settings, along with superior robustness to various
types of noise compared to state-of-the-art NN-based UFL approaches.

</details>


### [279] [Fairness Regularization in Federated Learning](https://arxiv.org/abs/2508.12042)
*Zahra Kharaghani,Ali Dadras,Tommy Löfstedt*

Main category: cs.LG

TL;DR: 本文研究联邦学习中的性能公平性问题，提出了FairGrad和FairGrad*两种梯度方差正则化方法，在异构数据环境下同时提升公平性和整体模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据异构性会导致某些客户端对全局模型产生不成比例的影响，造成性能差异。现有公平性方法在异构数据环境下的有效性不明确，不同方法之间的关系也不清楚。

Method: 专注于性能公平性，研究显式正则化客户端损失的公平性方法。提出了FairGrad（近似）和FairGrad*（精确）两种梯度方差正则化方法。

Result: 从理论上解释了所研究公平性方法之间的联系，实证表明FairGrad和FairGrad*在异构数据设置下能够同时改善公平性和整体模型性能。

Conclusion: 提出的梯度方差正则化方法有效解决了联邦学习中的性能公平性问题，在保持隐私保护优势的同时提升了模型的公平性和整体表现。

Abstract: Federated Learning (FL) has emerged as a vital paradigm in modern machine
learning that enables collaborative training across decentralized data sources
without exchanging raw data. This approach not only addresses privacy concerns
but also allows access to overall substantially larger and potentially more
diverse datasets, without the need for centralized storage or hardware
resources. However, heterogeneity in client data may cause certain clients to
have disproportionate impacts on the global model, leading to disparities in
the clients' performances. Fairness, therefore, becomes a crucial concern in FL
and can be addressed in various ways. However, the effectiveness of existing
fairness-aware methods, particularly in heterogeneous data settings, remains
unclear, and the relationships between different approaches are not well
understood. In this work, we focus on performance equitable fairness, which
aims to minimize differences in performance across clients. We restrict our
study to fairness-aware methods that explicitly regularize client losses,
evaluating both existing and newly proposed approaches. We identify and
theoretically explain connections between the investigated fairness methods,
and empirically show that FairGrad (approximate) and FairGrad* (exact) (two
variants of a gradient variance regularization method introduced here for
performance equitable fairness) improve both fairness and overall model
performance in heterogeneous data settings.

</details>


### [280] [VARAN: Variational Inference for Self-Supervised Speech Models Fine-Tuning on Downstream Tasks](https://arxiv.org/abs/2508.12061)
*Daria Diatlova,Nikita Balagansky,Alexander Varlamov,Egor Spirin*

Main category: cs.LG

TL;DR: VARAN是一个动态层聚合框架，通过输入相关的权重分配和专门化的探测头，为每个输入自适应地选择最合适的特征层，解决了传统静态聚合方法的信息瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统的自监督语音模型微调中，使用最后一层或加权求和的层聚合方法存在信息瓶颈问题，且对所有数据样本使用静态的特征权重分配，无法根据不同输入的特点灵活调整。

Method: 提出VARAN框架，采用层专门化的探测头和基于数据的动态权重分配机制，根据每个输入的具体特征自适应地优先选择不同层的特征表示。

Result: 在自动语音识别和语音情感识别任务上的评估表明，VARAN表现出优越性能，特别是在使用LoRA微调技术时效果更佳。

Conclusion: VARAN框架解决了保留层特定信息与实现灵活特征利用之间的权衡问题，推进了自监督语音表示的高效适应。

Abstract: Conventional methods for aggregating layers in fine-tuned self-supervised
speech models, such as using the final layer or weighted sum, suffer from
information bottlenecks and static feature weighting for all dataset examples.
We propose VARAN, a framework that dynamically tailors layer aggregation to
individual inputs. By employing layer-specialized probing heads and
data-dependent weighting, VARAN adaptively prioritizes layer's features based
on input. Evaluations on automatic speech recognition and speech emotion
recognition tasks demonstrate VARAN's superior performance, particularly when
using the LoRA fine-tuning technique. The framework resolves the trade-off
between preserving layer-specific information and enabling flexible feature
utilization, advancing efficient adaptation of self-supervised speech
representations.

</details>


### [281] [Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks](https://arxiv.org/abs/2508.12079)
*Ningzhe Shi,Yiqing Zhou,Ling Liu,Jinglin Shi,Yihao Wu,Haiwei Shi,Hanxiao Yu*

Main category: cs.LG

TL;DR: 提出了一个用于ISAC-AIGC网络的CAQA评估指标，通过LPDRL-F算法优化三维资源分配，显著提升用户体验质量


<details>
  <summary>Details</summary>
Motivation: 现有AIGC服务假设输入数据准确，但在ISAC-AIGC网络中，内容生成基于不准确的感知数据，且AIGC模型本身存在生成误差，需要新的评估指标和资源优化方法

Method: 提出CAQA评估指标，设计LP引导的深度强化学习算法LPDRL-F，通过线性规划指导和动作过滤器将三维解空间降为二维，降低复杂度

Result: LPDRL-F比现有算法收敛速度快60%以上，AvgCAQA提升超过14%，相比仅关注CGQ的方案提升超过50%

Conclusion: CAQA指标和LPDRL-F算法有效解决了ISAC-AIGC网络中的三维资源权衡问题，显著提升了用户体验质量

Abstract: Integrated sensing and communication (ISAC) can enhance artificial
intelligence-generated content (AIGC) networks by providing efficient sensing
and transmission. Existing AIGC services usually assume that the accuracy of
the generated content can be ensured, given accurate input data and prompt,
thus only the content generation quality (CGQ) is concerned. However, it is not
applicable in ISAC-based AIGC networks, where content generation is based on
inaccurate sensed data. Moreover, the AIGC model itself introduces generation
errors, which depend on the number of generating steps (i.e., computing
resources). To assess the quality of experience of ISAC-based AIGC services, we
propose a content accuracy and quality aware service assessment metric (CAQA).
Since allocating more resources to sensing and generating improves content
accuracy but may reduce communication quality, and vice versa, this
sensing-generating (computing)-communication three-dimensional resource
tradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all
users with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution
space that grows exponentially with users. To solve the CAQA-AIGC problem with
low complexity, a linear programming (LP) guided deep reinforcement learning
(DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the
LP-guided approach and the action filter, LPDRL-F can transform the original
three-dimensional solution space to two dimensions, reducing complexity while
improving the learning performance of DRL. Simulations show that compared to
existing DRL and generative diffusion model algorithms without LP, LPDRL-F
converges faster by over 60% and finds better resource allocation solutions,
improving AvgCAQA by more than 14%. With LPDRL-F, CAQA-AIGC can achieve an
improvement in AvgCAQA of more than 50% compared to existing schemes focusing
solely on CGQ.

</details>


### [282] [Generative Medical Event Models Improve with Scale](https://arxiv.org/abs/2508.12104)
*Shane Waxler,Paul Blazek,Davis White,Daniel Sneider,Kevin Chung,Mani Nagarathnam,Patrick Williams,Hank Voeller,Karen Wong,Matthew Swanhorst,Sheng Zhang,Naoto Usuyama,Cliff Wong,Tristan Naumann,Hoifung Poon,Andrew Loza,Daniella Meeker,Seth Hain,Rahul Shah*

Main category: cs.LG

TL;DR: CoMET是基于160亿次医疗事件训练的医学事件基础模型，通过自回归生成模拟患者健康时间线，在78个医疗任务中无需微调即可达到或超越专用监督模型性能。


<details>
  <summary>Details</summary>
Motivation: 实现规模化个性化医疗需要从纵向患者旅程中提取洞察，基础模型预训练在大规模医疗事件数据上代表了扩展真实世界证据生成和泛化到多样化下游任务的有前景方向。

Method: 使用Epic Cosmos数据集（163亿次医疗事件、3亿患者记录），训练解码器Transformer模型CoMET，进行最大规模的医疗数据缩放定律研究，预训练计算最优模型（最高10亿参数），通过自回归生成下一个医疗事件来模拟患者健康时间线。

Result: 在78个真实世界任务（诊断预测、疾病预后、医疗运营）中，CoMET通常优于或匹配任务特定的监督模型，无需任务特定微调或少样本示例，预测能力随模型和预训练规模持续提升。

Conclusion: CoMET作为生成式医疗事件基础模型，能有效捕捉复杂临床动态，为支持临床决策、简化医疗运营和改善患者结局提供可扩展和可泛化的框架。

Abstract: Realizing personalized medicine at scale calls for methods that distill
insights from longitudinal patient journeys, which can be viewed as a sequence
of medical events. Foundation models pretrained on large-scale medical event
data represent a promising direction for scaling real-world evidence generation
and generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with
medical events from de-identified longitudinal health records for 16.3 billion
encounters over 300 million unique patient records from 310 health systems, we
introduce the Cosmos Medical Event Transformer ( CoMET) models, a family of
decoder-only transformer models pretrained on 118 million patients representing
115 billion discrete medical events (151 billion tokens). We present the
largest scaling-law study for medical event data, establishing a methodology
for pretraining and revealing power-law scaling relationships for compute,
tokens, and model size. Based on this, we pretrained a series of
compute-optimal models with up to 1 billion parameters. Conditioned on a
patient's real-world history, CoMET autoregressively generates the next medical
event, simulating patient health timelines. We studied 78 real-world tasks,
including diagnosis prediction, disease prognosis, and healthcare operations.
Remarkably for a foundation model with generic pretraining and simulation-based
inference, CoMET generally outperformed or matched task-specific supervised
models on these tasks, without requiring task-specific fine-tuning or few-shot
examples. CoMET's predictive power consistently improves as the model and
pretraining scale. Our results show that CoMET, a generative medical event
foundation model, can effectively capture complex clinical dynamics, providing
an extensible and generalizable framework to support clinical decision-making,
streamline healthcare operations, and improve patient outcomes.

</details>


### [283] [DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections](https://arxiv.org/abs/2508.12116)
*Haebin Shin,Lei Ji,Xiao Liu,Zhiwei Yu,Qi Chen,Yeyun Gong*

Main category: cs.LG

TL;DR: DynamixSFT是一种动态自动化的指令调优数据集混合优化方法，使用多臂老虎机框架和先验缩放玻尔兹曼探索，在Tulu-v2数据集集合上实现了2.2%的性能提升


<details>
  <summary>Details</summary>
Motivation: 随着后训练阶段大量指令调优数据集的出现，动态平衡和优化这些数据集的混合成为一个关键挑战

Method: 将问题建模为多臂老虎机，提出先验缩放玻尔兹曼探索方法，使用轻量级1步前瞻奖励更新采样概率，保持原始数据集比例的软锚定

Result: 在包含16个指令调优数据集的Tulu-v2混合集合上，在10个基准测试中实现了最高2.2%的性能提升

Conclusion: 该方法有效解决了指令调优数据集混合的动态优化问题，并通过全面分析和可视化提供了对自适应动态的深入洞察

Abstract: As numerous instruction-tuning datasets continue to emerge during the
post-training stage, dynamically balancing and optimizing their mixtures has
become a critical challenge. To address this, we propose DynamixSFT, a dynamic
and automated method for instruction-tuning dataset mixture optimization. We
formulate the problem as a multi-armed bandit setup and introduce a
Prior-scaled Boltzmann Exploration that softly anchors the updated sampling
distribution to the original dataset proportions, thereby preserving the
inherent diversity and coverage of the collection. Sampling probabilities are
updated using a lightweight 1-Step Look-ahead Reward, reflecting how much the
dataset contributes to improving the model's performance at its current state.
When applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning
datasets, DynamixSFT achieves up to a 2.2% performance improvement across 10
benchmarks. Furthermore, we provide a comprehensive analysis and visualizations
to offer deeper insights into the adaptive dynamics of our method.

</details>


### [284] [Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks](https://arxiv.org/abs/2508.12121)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: 门控机制在RNN中通过耦合状态空间时间尺度和参数空间动力学，隐式地产生自适应学习率行为，即使使用固定全局学习率训练时也是如此。


<details>
  <summary>Details</summary>
Motivation: 研究门控机制如何影响RNN的训练动力学，特别是门控如何隐式地调节学习过程，这有助于理解门控架构在实践中表现出的鲁棒可训练性和稳定性。

Method: 通过推导泄漏积分器和门控RNN的精确雅可比矩阵，获得一阶展开式，分析标量和多维门控如何重塑梯度传播、调节有效步长并引入参数更新的各向异性。

Result: 门控不仅控制隐藏状态中的记忆保留，还充当数据驱动的预处理器，适应参数空间中的优化轨迹。数值实验验证了微扰分析的有效性。

Conclusion: 这项工作提供了一个统一的动力学系统视角，说明门控如何耦合状态演化与参数更新，解释了门控架构在实践中实现鲁棒可训练性和稳定性的原因。

Abstract: We study how gating mechanisms in recurrent neural networks (RNNs) implicitly
induce adaptive learning-rate behavior, even when training is carried out with
a fixed, global learning rate. This effect arises from the coupling between
state-space time scales--parametrized by the gates--and parameter-space
dynamics during gradient descent. By deriving exact Jacobians for
leaky-integrator and gated RNNs, we obtain a first-order expansion that makes
explicit how constant, scalar, and multi-dimensional gates reshape gradient
propagation, modulate effective step sizes, and introduce anisotropy in
parameter updates. These findings reveal that gates not only control memory
retention in the hidden states, but also act as data-driven preconditioners
that adapt optimization trajectories in parameter space. We further draw formal
analogies with learning-rate schedules, momentum, and adaptive methods such as
Adam, showing that these optimization behaviors emerge naturally from gating.
Numerical experiments confirm the validity of our perturbative analysis,
supporting the view that gate-induced corrections remain small while exerting
systematic effects on training dynamics. Overall, this work provides a unified
dynamical-systems perspective on how gating couples state evolution with
parameter updates, explaining why gated architectures achieve robust
trainability and stability in practice.

</details>


### [285] [DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy](https://arxiv.org/abs/2508.12145)
*Frederik L. Dennig,Daniel A. Keim*

Main category: cs.LG

TL;DR: DE-VAE是一种基于微分熵的不确定性感知变分自编码器，用于改进参数化和可逆投影，在处理分布外样本时表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有的自编码器方法在处理数据空间或嵌入空间的分布外样本时表现不佳，需要一种能够处理不确定性并保持投影质量的改进方法

Method: 使用微分熵(DE)的变分自编码器，学习从原始空间到2D空间的映射及其逆映射，基于固定投影进行训练

Result: 在四个知名数据集上的定量和定性评估表明，DE-VAE能够创建与当前其他AE方法精度相当的参数化和逆投影，同时支持嵌入不确定性分析

Conclusion: DE-VAE成功解决了处理分布外样本的问题，在保持投影质量的同时提供了不确定性分析能力，为多维数据的参数化和可逆投影提供了有效解决方案

Abstract: Recently, autoencoders (AEs) have gained interest for creating parametric and
invertible projections of multidimensional data. Parametric projections make it
possible to embed new, unseen samples without recalculating the entire
projection, while invertible projections allow the synthesis of new data
instances. However, existing methods perform poorly when dealing with
out-of-distribution samples in either the data or embedding space. Thus, we
propose DE-VAE, an uncertainty-aware variational AE using differential entropy
(DE) to improve the learned parametric and invertible projections. Given a
fixed projection, we train DE-VAE to learn a mapping into 2D space and an
inverse mapping back to the original space. We conduct quantitative and
qualitative evaluations on four well-known datasets, using UMAP and t-SNE as
baseline projection methods. Our findings show that DE-VAE can create
parametric and inverse projections with comparable accuracy to other current
AE-based approaches while enabling the analysis of embedding uncertainty.

</details>


### [286] [AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis](https://arxiv.org/abs/2508.12162)
*J. M. I. H. Jayakody,A. M. H. H. Alahakoon,C. R. M. Perera,R. M. L. C. Srimal,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的深度学习模型AICRN，通过结合注意力机制的卷积残差网络来实现心电图参数的高精度回归预测，提升了心脏疾病诊断的可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统心电图分析存在人为错误导致失焦、手动分析耗时等挑战，需要人工智能技术来提高诊断精度和预测能力。

Method: 设计了注意力集成卷积残差网络(AICRN)，结合空间和通道注意力机制来处理心电图特征的类型和空间位置，并使用卷积残差网络解决核心问题。

Result: AICRN模型在心电图参数回归任务中表现超过现有模型，具有更高的预测精度，能够快速识别心脏事件。

Conclusion: 深度学习在心电图分析的可解释性和精确性方面发挥关键作用，为心脏监测和管理开启了新的临床应用前景。

Abstract: The paradigm of electrocardiogram (ECG) analysis has evolved into real-time
digital analysis, facilitated by artificial intelligence (AI) and machine
learning (ML), which has improved the diagnostic precision and predictive
capacity of cardiac diseases. This work proposes a novel deep learning (DL)
architecture called the attention-integrated convolutional residual network
(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,
the QRS duration, the heart rate, the peak amplitude of the R wave, and the
amplitude of the T wave for interpretable ECG analysis. Our architecture is
specially designed with spatial and channel attention-related mechanisms to
address the type and spatial location of the ECG features for regression. The
models employ a convolutional residual network to address vanishing and
exploding gradient problems. The designed system addresses traditional analysis
challenges, such as loss of focus due to human errors, and facilitates the fast
and easy detection of cardiac events, thereby reducing the manual efforts
required to solve analysis tasks. AICRN models outperform existing models in
parameter regression with higher precision. This work demonstrates that DL can
play a crucial role in the interpretability and precision of ECG analysis,
opening up new clinical applications for cardiac monitoring and management.

</details>


### [287] [ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression](https://arxiv.org/abs/2508.12212)
*Chuanliu Fan,Zicheng Ma,Jun Gao,Nan Yu,Jun Zhang,Ziqiang Cao,Yi Qin Gao,Guohong Fu*

Main category: cs.LG

TL;DR: ProtTeX-CC是一个轻量级的两阶段压缩框架，通过联合嵌入压缩和自压缩模块，显著减少蛋白质输入长度，提升ProtTeX模型在少样本设置下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决ProtTeX模型在处理多模态蛋白质信息时的两个主要限制：序列和结构标记连接导致蛋白质长度翻倍并破坏模态对齐，以及无法进行上下文学习限制了泛化能力。

Method: 提出两阶段压缩框架：1）联合嵌入压缩机制在残基级别融合序列和结构表示，将输入长度减半；2）自压缩模块将完整演示聚合到最后几个语言标记的潜在空间中，大幅压缩演示长度。

Result: 在16-shot设置下实现约93.68%的总提示长度压缩比，蛋白质功能预测任务中域内基准性能提升2%，域外数据集性能提升11%。

Conclusion: ProtTeX-CC通过轻量级压缩框架有效解决了ProtTeX的局限性，显著提升了少样本学习性能，同时保持了模型的轻量化和高效性。

Abstract: Recent advances in protein large language models, such as ProtTeX, represent
both side-chain amino acids and backbone structure as discrete token sequences
of residue length. While this design enables unified modeling of multimodal
protein information, it suffers from two major limitations: (1) The
concatenation of sequence and structure tokens approximately doubles the
protein length and breaks the intrinsic residue-level alignment between
modalities. (2) Constrained by the training corpus and limited context window,
ProtTeX is typically trained on single-protein inputs, rendering it
incompatible with in-context learning (ICL) and thus limiting its
generalization capability. To address these issues, we propose ProtTeX-CC, a
lightweight two-stage compression framework designed to enhance ProtTeX under
few-shot settings. We first design a joint embedding compression mechanism that
fuses sequence and structure representations at the residue level, effectively
reducing the protein input length by half without sacrificing performance. Then
we propose a self-compression module that aggregates each full demonstration
into the latent space of the last few linguistic tokens, reducing the average
demonstration length from 751 tokens to less than 16 tokens. Compared to the
original ProtTeX, our self-compression approach achieves a compression ratio of
approximately 93.68% in the total prompt length under the 16-shot setting.
Without modifying the backbone model, ProtTeX-CC introduces only a small number
of additional parameters through PEFT-based tuning in the joint embedding
compression stage and a single trainable projection layer in the
self-compression stage. Extensive experiments on protein function prediction
show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and
generalizes well to the out-of-domain dataset with a performance gain of 11%.

</details>


### [288] [Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models](https://arxiv.org/abs/2508.12220)
*Abdullah X*

Main category: cs.LG

TL;DR: 这篇论文研究大语言模型的被忘记权（遵循GDPR第17条），将反向学习框架为可重现的系统问题，通过记录训练过程的关键元数据来实现精确的数据删除效果。


<details>
  <summary>Details</summary>
Motivation: 为了遵循GDPR被忘记权的法律要求，需要一种可靠的方法来从大语言模型中删除特定用户数据的影响，同时保持模型的性能和稳定性。

Method: 将训练过程视为确定性程序，记录每个微批次的关键信息（ID哈希、随机数种子、学习率、优化器步数等）。通过重放训练尾部过程并过滤掉删除集的数据，实现与保留集训练完全一致的模型参数。还提出了多种补充方案来满足延迟和可用性要求。

Result: 在满足前提条件的控制运行中，实验证明了模型和优化器状态完全字节级别的一致性。报告了存储和延迟预算，并通过一个简化案例验证了机制的有效性。

Conclusion: 该方法为大语言模型的被忘记权提供了一种系统化的解决方案，通过确定性记录和重放机制实现了精确的数据删除效果，同时具备多种实用的部署选项来满足不同的性能需求。

Abstract: We study the right to be forgotten (GDPR Art. 17) for large language models
and frame unlearning as a reproducible systems problem. Our approach treats
training as a deterministic program and logs a minimal per-microbatch record
(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and
accumulation boundary). Under a pinned stack and deterministic kernels,
replaying the training tail while filtering only the forget closure yields the
same parameters as training on the retain set (bit-identical in the training
dtype) when preconditions hold. To meet latency and availability constraints,
we add complementary paths: (i) exact reverts of recent steps via
micro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion
when the base is frozen, and (iii) a curvature-guided anti-update followed by a
short retain-tune, audit-gated with escalation to exact replay. We report
storage/latency budgets and a toy artifact validating mechanics; in a
controlled run that satisfies the preconditions we demonstrate byte-identical
equality of model and optimizer states.

</details>


### [289] [Distribution Matching via Generalized Consistency Models](https://arxiv.org/abs/2508.12222)
*Sagar Shrestha,Rajesh Shrestha,Tri Nguyen,Subash Timilsina*

Main category: cs.LG

TL;DR: 基于一致性模型的新型分布匹配方法，结合了连续正则化流模型的直接范数最小化优点和GAN的灵活性，避免了GAN训练难题


<details>
  <summary>Details</summary>
Motivation: GAN在分布匹配任务中展现出艰难的双层最小最大优化问题和模式冲突问题，需要更稳定和高效的方法

Method: 受连续正则化流(CNF)中一致性模型的启发，提出新的分布匹配方法，继承CNF的直接范数最小化目标优点，同时保持GAN的灵活性

Result: 通过理论验证和在合成数据集以及实际数据集上的实验展示了方法的性能

Conclusion: 该方法为分布匹配任务提供了一种更稳定和高效的替代方案，结合了CNF和GAN的各自优点

Abstract: Recent advancement in generative models have demonstrated remarkable
performance across various data modalities. Beyond their typical use in data
synthesis, these models play a crucial role in distribution matching tasks such
as latent variable modeling, domain translation, and domain adaptation.
Generative Adversarial Networks (GANs) have emerged as the preferred method of
distribution matching due to their efficacy in handling high-dimensional data
and their flexibility in accommodating various constraints. However, GANs often
encounter challenge in training due to their bi-level min-max optimization
objective and susceptibility to mode collapse. In this work, we propose a novel
approach for distribution matching inspired by the consistency models employed
in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF
models, such as having a straight forward norm minimization objective, while
remaining adaptable to different constraints similar to GANs. We provide
theoretical validation of our proposed objective and demonstrate its
performance through experiments on synthetic and real-world datasets.

</details>


### [290] [Communication-Efficient Distributed Asynchronous ADMM](https://arxiv.org/abs/2508.12233)
*Sagar Shrestha*

Main category: cs.LG

TL;DR: 在分布式优化和联邦学习中，通过在异步ADMM中引入粗粗化量化来减少通信开销，实验验证了该方法在包括神经网络在内的多个分布式学习任务中的收敛性。


<details>
  <summary>Details</summary>
Motivation: 在大规模分布式优化和联邦学习中，异步ADMM虽然具有优势，但通信成本可能成为主要瓶颈，特别是当节点通信预算有限或需要传输的数据过大时。

Method: 在异步交替方向乘子法(ADMM)中引入粗粗化量化技术，对需要交换的数据进行量化处理，以降低通信开销。

Result: 通过实验验证了该方法在多个分布式学习任务中的收敛性，包括神经网络训练。

Conclusion: 粗粗化量化技术能够有效降低分布式优化和联邦学习中的通信开销，同时保持算法的收敛性，适用于大规模应用场景。

Abstract: In distributed optimization and federated learning, asynchronous alternating
direction method of multipliers (ADMM) serves as an attractive option for
large-scale optimization, data privacy, straggler nodes and variety of
objective functions. However, communication costs can become a major bottleneck
when the nodes have limited communication budgets or when the data to be
communicated is prohibitively large. In this work, we propose introducing
coarse quantization to the data to be exchanged in aynchronous ADMM so as to
reduce communication overhead for large-scale federated learning and
distributed optimization applications. We experimentally verify the convergence
of the proposed method for several distributed learning tasks, including neural
networks.

</details>


### [291] [CC-Time: Cross-Model and Cross-Modality Time Series Forecasting](https://arxiv.org/abs/2508.12235)
*Peng Chen,Yihang Wang,Yang Shu,Yunyao Cheng,Kai Zhao,Zhongwen Rao,Lujia Pan,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: CC-Time是一个结合预训练语言模型和时间序列模型的跨模态跨模型学习方法，通过文本描述和时间序列数据的联合建模，在时间序列预测任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练语言模型的时间序列预测方法未能充分发挥语言模型的强大序列建模能力，预测精度不够理想。需要探索语言模型能够建模哪些时间序列特征，以及是否仅靠语言模型就足够构建时间序列模型。

Method: 提出跨模态学习来建模时间依赖性和通道相关性，同时利用时间序列序列和对应的文本描述；提出跨模型融合块来自适应地整合语言模型和时间序列模型的知识，形成更全面的时间序列模式建模。

Result: 在九个真实世界数据集上的大量实验表明，CC-Time在完整数据训练和少样本学习情况下都达到了最先进的预测精度。

Conclusion: CC-Time成功展示了预训练语言模型在时间序列预测中的潜力，通过跨模态和跨模型学习实现了更好的性能，为语言模型在时间序列领域的应用提供了新思路。

Abstract: With the success of pre-trained language models (PLMs) in various application
fields beyond natural language processing, language models have raised emerging
attention in the field of time series forecasting (TSF) and have shown great
prospects. However, current PLM-based TSF methods still fail to achieve
satisfactory prediction accuracy matching the strong sequential modeling power
of language models. To address this issue, we propose Cross-Model and
Cross-Modality Learning with PLMs for time series forecasting (CC-Time). We
explore the potential of PLMs for time series forecasting from two aspects: 1)
what time series features could be modeled by PLMs, and 2) whether relying
solely on PLMs is sufficient for building time series models. In the first
aspect, CC-Time incorporates cross-modality learning to model temporal
dependency and channel correlations in the language model from both time series
sequences and their corresponding text descriptions. In the second aspect,
CC-Time further proposes the cross-model fusion block to adaptively integrate
knowledge from the PLMs and time series model to form a more comprehensive
modeling of time series patterns. Extensive experiments on nine real-world
datasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy
in both full-data training and few-shot learning situations.

</details>


### [292] [DHG-Bench: A Comprehensive Benchmark on Deep Hypergraph Learning](https://arxiv.org/abs/2508.12244)
*Fan Li,Xiaoyang Wang,Wenjie Zhang,Ying Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: 本文提出了DHG-Bench，这是第一个针对深度超图学习的综合基准测试，包含20个数据集和16种最先进的超图神经网络算法，在统一的数据处理和实验协议下进行系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有的超图神经网络方法缺乏全面的基准测试，导致在数据集覆盖、算法性能评估和实验可比性方面存在障碍，阻碍了对深度超图学习进展的理解。

Method: 构建了包含20个多样化数据集的基准测试平台，涵盖节点、边和图级别任务，整合16种最先进的HNN算法，采用一致的数据处理和实验协议，从有效性、效率、鲁棒性和公平性四个维度系统评估算法特性。

Result: 广泛的实验揭示了现有算法的优势和固有局限性，为未来研究提供了有价值的见解和方向。

Conclusion: DHG-Bench填补了深度超图学习领域基准测试的空白，通过系统性的评估框架促进了该领域的可重复研究和进一步发展。

Abstract: Although conventional deep graph models have achieved great success in
relational learning, their focus on pairwise relationships limits their
capacity to learn pervasive higher-order interactions in real-world complex
systems, which can be naturally modeled as hypergraphs. To tackle this,
hypergraph neural networks (HNNs), the dominant approach in deep hypergraph
learning (DHGL), has garnered substantial attention in recent years. Despite
the proposal of numerous HNN methods, there is no comprehensive benchmark for
HNNs, which creates a great obstacle to understanding the progress of DHGL in
several aspects: (i) insufficient coverage of datasets, algorithms, and tasks;
(ii) a narrow evaluation of algorithm performance; and (iii) inconsistent
dataset usage, preprocessing, and experimental setups that hinder
comparability. To fill the gap, we introduce DHG-Bench, the first comprehensive
benchmark for DHGL. Specifically, DHG-Bench integrates 20 diverse datasets
spanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art
HNN algorithms, under consistent data processing and experimental protocols.
Our benchmark systematically investigates the characteristics of HNNs in terms
of four dimensions: effectiveness, efficiency, robustness, and fairness.
Further, to facilitate reproducible research, we have developed an easy-to-use
library for training and evaluating different HNN methods. Extensive
experiments conducted with DHG-Bench reveal both the strengths and inherent
limitations of existing algorithms, offering valuable insights and directions
for future research. The code is publicly available at:
https://github.com/Coco-Hut/DHG-Bench.

</details>


### [293] [STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction](https://arxiv.org/abs/2508.12247)
*Haolong Chen,Liang Zhang,Zhengyuan Xin,Guangxu Zhu*

Main category: cs.LG

TL;DR: 提出了STM2和STM3模型，通过多尺度Mamba架构和自适应图因果卷积网络，有效解决长时空依赖学习中的多尺度信息提取和建模挑战，在长时空时间序列预测中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以高效学习复杂的长期时空依赖关系，长期时空依赖学习面临两个新挑战：1）长期时间序列天然包含难以高效提取的多尺度信息；2）来自不同节点的多尺度时间信息高度相关且难以建模。

Method: STM2采用多尺度Mamba架构高效同时捕获多尺度信息，以及自适应图因果卷积网络学习复杂的多尺度时空依赖。STM3进一步采用混合专家架构，包含更稳定的路由策略和因果对比学习策略来增强尺度区分性。

Result: 在真实世界基准测试上的大量实验证明STM2/STM3具有优越性能，在长时空时间序列预测中实现了最先进的结果。

Conclusion: 提出的STM2和STM3模型通过创新的多尺度Mamba架构和混合专家设计，成功解决了长期时空依赖学习的关键挑战，为时空时间序列预测提供了高效且强大的解决方案。

Abstract: Recently, spatio-temporal time-series prediction has developed rapidly, yet
existing deep learning methods struggle with learning complex long-term
spatio-temporal dependencies efficiently. The long-term spatio-temporal
dependency learning brings two new challenges: 1) The long-term temporal
sequence includes multiscale information naturally which is hard to extract
efficiently; 2) The multiscale temporal information from different nodes is
highly correlated and hard to model. To address these challenges, we propose an
efficient \textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ultiscale
\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture
the multiscale information efficiently and simultaneously, and an adaptive
graph causal convolution network to learn the complex multiscale
spatio-temporal dependency. STM2 includes hierarchical information aggregation
for different-scale information that guarantees their distinguishability. To
capture diverse temporal dynamics across all spatial nodes more efficiently, we
further propose an enhanced version termed
\textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ixture of
\textbf{M}ultiscale \textbf{M}amba} (STM3) that employs a special
Mixture-of-Experts architecture, including a more stable routing strategy and a
causal contrastive learning strategy to enhance the scale distinguishability.
We prove that STM3 has much better routing smoothness and guarantees the
pattern disentanglement for each expert successfully. Extensive experiments on
real-world benchmarks demonstrate STM2/STM3's superior performance, achieving
state-of-the-art results in long-term spatio-temporal time-series prediction.

</details>


### [294] [Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset](https://arxiv.org/abs/2508.12253)
*Manish Shukla*

Main category: cs.LG

TL;DR: 这篇论文提出了一种统一的时间序列预测解释框架，结合LIME和SHAP方法来解释传统ARIMA模型和树基模型的预测结果，提高模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在航空、能源等领域关键，但传统ARIMA模型难处理非线性关系，而树基模型精度高但可解释性差。需要一种方法来解释预测结果。

Method: 将单变量时间序列转换为无泄漏的监督学习问题，训练梯度提升树模型和ARIMA基准模型，然后应用LIME和SHAP进行后解释。

Result: 在航空乘客数据集上验证，发现少量滞后特征（特别是12个月滞后）和季节性编码解释了大部分预测方差。

Conclusion: 该端到端框架有效地解释了时间序列预测，为实践者提供了应用LIME和SHAP的指南，且遵守时间序列的时序性要求。

Abstract: Time-series forecasting underpins critical decisions across aviation, energy,
retail and health. Classical autoregressive integrated moving average (ARIMA)
models offer interpretability via coefficients but struggle with
nonlinearities, whereas tree-based machine-learning models such as XGBoost
deliver high accuracy but are often opaque. This paper presents a unified
framework for interpreting time-series forecasts using local interpretable
model-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We
convert a univariate series into a leakage-free supervised learning problem,
train a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc
explainability. Using the Air Passengers dataset as a case study, we show that
a small set of lagged features -- particularly the twelve-month lag -- and
seasonal encodings explain most forecast variance. We contribute: (i) a
methodology for applying LIME and SHAP to time series without violating
chronology; (ii) theoretical exposition of the underlying algorithms; (iii)
empirical evaluation with extensive analysis; and (iv) guidelines for
practitioners.

</details>


### [295] [L-SR1: Learned Symmetric-Rank-One Preconditioning](https://arxiv.org/abs/2508.12270)
*Gal Lifshitz,Shahar Zuler,Ori Fouks,Dan Raviv*

Main category: cs.LG

TL;DR: 学习二阶优化器，通过可训练预处理单元改进SR1算法，在人体网栽恢复任务上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 结合深度学习的数据驱动优势和传统优化算法的高效率优点，充分发挥二阶优化方法的潜力

Method: 设计可训练预处理单元，生成数据驱动向量构建正半定矩阵，通过学习投影满足割线约束

Result: 在分析实验和人体网栽恢复任务上超过现有学习优化方法

Conclusion: 方法轻量化、无需标注数据或微调，具有强大的沿半化能力，适合集成到更广泛的优化框架中

Abstract: End-to-end deep learning has achieved impressive results but remains limited
by its reliance on large labeled datasets, poor generalization to unseen
scenarios, and growing computational demands. In contrast, classical
optimization methods are data-efficient and lightweight but often suffer from
slow convergence. While learned optimizers offer a promising fusion of both
worlds, most focus on first-order methods, leaving learned second-order
approaches largely unexplored.
  We propose a novel learned second-order optimizer that introduces a trainable
preconditioning unit to enhance the classical Symmetric-Rank-One (SR1)
algorithm. This unit generates data-driven vectors used to construct positive
semi-definite rank-one matrices, aligned with the secant constraint via a
learned projection. Our method is evaluated through analytic experiments and on
the real-world task of Monocular Human Mesh Recovery (HMR), where it
outperforms existing learned optimization-based approaches. Featuring a
lightweight model and requiring no annotated data or fine-tuning, our approach
offers strong generalization and is well-suited for integration into broader
optimization-based frameworks.

</details>


### [296] [CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision](https://arxiv.org/abs/2508.12278)
*Siyue Xie,Da Sun Handason Tam,Wing Cheong Lau*

Main category: cs.LG

TL;DR: CRoC是一个用于图异常检测的框架，通过上下文重构和对比学习，在标签有限的情况下有效利用未标记数据，显著提升GNN在异常检测中的性能


<details>
  <summary>Details</summary>
Motivation: 图神经网络训练需要大量标注数据，但图异常检测中异常样本稀少、标注成本高且存在伪装模式，这严重限制了GAD的发展

Method: 提出CRoC框架：1）利用GAD中的类别不平衡重构节点上下文，保持交互模式的同时重组属性；2）分别编码异质关系并整合到消息传递中；3）结合对比学习范式联合利用有限标注和大量未标注数据

Result: 在7个真实GAD数据集上评估，CRoC相比基线GNN提升高达14% AUC，在有限标签设置下优于最先进的GAD方法

Conclusion: CRoC通过上下文重构和对比学习的结合，有效解决了图异常检测中标签稀缺和异常伪装的问题，显著提升了检测性能

Abstract: Graph Neural Networks (GNNs) are widely used as the engine for various
graph-related tasks, with their effectiveness in analyzing graph-structured
data. However, training robust GNNs often demands abundant labeled data, which
is a critical bottleneck in real-world applications. This limitation severely
impedes progress in Graph Anomaly Detection (GAD), where anomalies are
inherently rare, costly to label, and may actively camouflage their patterns to
evade detection. To address these problems, we propose Context Refactoring
Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by
jointly leveraging limited labeled and abundant unlabeled data. Different from
previous works, CRoC exploits the class imbalance inherent in GAD to refactor
the context of each node, which builds augmented graphs by recomposing the
attributes of nodes while preserving their interaction patterns. Furthermore,
CRoC encodes heterogeneous relations separately and integrates them into the
message-passing process, enhancing the model's capacity to capture complex
interaction semantics. These operations preserve node semantics while
encouraging robustness to adversarial camouflage, enabling GNNs to uncover
intricate anomalous cases. In the training stage, CRoC is further integrated
with the contrastive learning paradigm. This allows GNNs to effectively harness
unlabeled data during joint training, producing richer, more discriminative
node embeddings. CRoC is evaluated on seven real-world GAD datasets with
varying scales. Extensive experiments demonstrate that CRoC achieves up to 14%
AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods
under limited-label settings.

</details>


### [297] [Convergence Analysis of the Lion Optimizer in Centralized and Distributed Settings](https://arxiv.org/abs/2508.12327)
*Wei Jiang,Lijun Zhang*

Main category: cs.LG

TL;DR: 这篇论文分析了Lion优化器的收敛性能，包括标准版本、方差缩减版本、分布式设置以及通信效率优化版本的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 研究Lion优化器的收敛性能，提高其在各种设置下的计算效率和通信效率。

Method: 通过理论分析确定了Lion优化器在标准假设下的收敛速率，并介绍了方差缩减技术和签名压缩方法来改善性能。

Result: 标准Lion收敛速率为O(d^{1/2}T^{-1/4})，方差缩减版本提升到O(d^{1/2}T^{-1/3})。分布式设置中，标准和方差缩减版本分别达到O(d^{1/2}(nT)^{-1/4})和O(d^{1/2}(nT)^{-1/3})。通信效率优化版本获得更好的收敛性能。

Conclusion: Lion优化器在各种设置下都表现出良好的收敛性能，通过方差缩减和通信压缩技术可以显著提高其效率。

Abstract: In this paper, we analyze the convergence properties of the Lion optimizer.
First, we establish that the Lion optimizer attains a convergence rate of
$\mathcal{O}(d^{1/2}T^{-1/4})$ under standard assumptions, where $d$ denotes
the problem dimension and $T$ is the iteration number. To further improve this
rate, we introduce the Lion optimizer with variance reduction, resulting in an
enhanced convergence rate of $\mathcal{O}(d^{1/2}T^{-1/3})$. We then analyze in
distributed settings, where the standard and variance reduced version of the
distributed Lion can obtain the convergence rates of
$\mathcal{O}(d^{1/2}(nT)^{-1/4})$ and $\mathcal{O}(d^{1/2}(nT)^{-1/3})$, with
$n$ denoting the number of nodes. Furthermore, we investigate a
communication-efficient variant of the distributed Lion that ensures sign
compression in both communication directions. By employing the unbiased sign
operations, the proposed Lion variant and its variance reduction counterpart,
achieve convergence rates of $\mathcal{O}\left( \max
\left\{\frac{d^{1/4}}{T^{1/4}}, \frac{d^{1/10}}{n^{1/5}T^{1/5}} \right\}
\right)$ and $\mathcal{O}\left( \frac{d^{1/4}}{T^{1/4}} \right)$, respectively.

</details>


### [298] [Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models](https://arxiv.org/abs/2508.12361)
*Xun Su,Jianming Huang,Yang Yusen,Zhongxi Fang,Hiroyuki Kasai*

Main category: cs.LG

TL;DR: 提出了Funnel Schedule和Adaptive Temperature两种策略来解决扩散模型中探索-利用的权衡问题，通过逐步减少粒子数量和降低早期奖励权重来提升样本质量，不增加噪声函数评估次数。


<details>
  <summary>Details</summary>
Motivation: 现有的SMC方法在扩散模型中面临困境：早期噪声样本有改进潜力但难以准确评估，而后期样本可可靠评估但基本不可逆。需要解决这种探索-利用的权衡问题。

Method: 从搜索算法角度提出两种策略：1) Funnel Schedule - 逐步减少维护的粒子数量；2) Adaptive Temperature - 降低早期阶段奖励的影响权重。这些方法针对扩散模型的生成动力学和相变行为进行定制。

Result: 在多个基准测试和最先进的文本到图像扩散模型上的实验结果表明，该方法优于之前的基线方法，显著提升了样本质量。

Conclusion: 提出的简单而有效的策略成功解决了扩散模型中SMC应用的探索-利用困境，在不增加计算成本的情况下提高了生成质量，为推理时缩放技术在扩散模型中的应用提供了新思路。

Abstract: Inference-time scaling has achieved remarkable success in language models,
yet its adaptation to diffusion models remains underexplored. We observe that
the efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems
from globally fitting the The reward-tilted distribution, which inherently
preserves diversity during multi-modal search. However, current applications of
SMC to diffusion models face a fundamental dilemma: early-stage noise samples
offer high potential for improvement but are difficult to evaluate accurately,
whereas late-stage samples can be reliably assessed but are largely
irreversible. To address this exploration-exploitation trade-off, we approach
the problem from the perspective of the search algorithm and propose two
strategies: Funnel Schedule and Adaptive Temperature. These simple yet
effective methods are tailored to the unique generation dynamics and
phase-transition behavior of diffusion models. By progressively reducing the
number of maintained particles and down-weighting the influence of early-stage
rewards, our methods significantly enhance sample quality without increasing
the total number of Noise Function Evaluations. Experimental results on
multiple benchmarks and state-of-the-art text-to-image diffusion models
demonstrate that our approach outperforms previous baselines.

</details>


### [299] [Bi-Axial Transformers: Addressing the Increasing Complexity of EHR Classification](https://arxiv.org/abs/2508.12418)
*Rachael DeVries,Casper Christensen,Marie Lisandra Zepeda Mendoza,Ole Winther*

Main category: cs.LG

TL;DR: 提出了Bi-Axial Transformer (BAT)模型，通过同时关注临床变量和时间轴两个维度来处理电子健康记录数据，在脓毒症预测和死亡率分类任务上取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录(EHRs)数据日益复杂，包含更大的数据集、更长的时间序列和多模态集成。传统Transformer在处理EHR分类时受限于数据表示方式，无法有效处理数据稀疏性和信息缺失问题。

Method: 开发了Bi-Axial Transformer (BAT)模型，该模型同时关注临床变量轴和时间点轴，学习更丰富的数据关系，解决数据稀疏性难题。模型还学习了独特的传感器嵌入，可用于迁移学习。

Result: BAT在脓毒症预测任务上达到最先进性能，在死亡率分类任务上与顶级方法竞争力相当。相比其他Transformer模型，BAT对数据缺失表现出更强的鲁棒性。

Conclusion: BAT通过双轴注意力机制有效处理EHR数据的复杂性和稀疏性，为EHR分析提供了更强大的工具，同时提供了可复现的基准模型实现。

Abstract: Electronic Health Records (EHRs), the digital representation of a patient's
medical history, are a valuable resource for epidemiological and clinical
research. They are also becoming increasingly complex, with recent trends
indicating larger datasets, longer time series, and multi-modal integrations.
Transformers, which have rapidly gained popularity due to their success in
natural language processing and other domains, are well-suited to address these
challenges due to their ability to model long-range dependencies and process
data in parallel. But their application to EHR classification remains limited
by data representations, which can reduce performance or fail to capture
informative missingness. In this paper, we present the Bi-Axial Transformer
(BAT), which attends to both the clinical variable and time point axes of EHR
data to learn richer data relationships and address the difficulties of data
sparsity. BAT achieves state-of-the-art performance on sepsis prediction and is
competitive to top methods for mortality classification. In comparison to other
transformers, BAT demonstrates increased robustness to data missingness, and
learns unique sensor embeddings which can be used in transfer learning.
Baseline models, which were previously located across multiple repositories or
utilized deprecated libraries, were re-implemented with PyTorch and made
available for reproduction and future benchmarking.

</details>


### [300] [Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features](https://arxiv.org/abs/2508.12440)
*Ahmet Bilal Arıkan,Şener Özönder,Mustafa Taha Koçyiğit,Hüseyin Oktay Altun,H. Kübra Küçükkartal,Murat Arslanoğlu,Fatih Çağırankaya,Berk Ayvaz*

Main category: cs.LG

TL;DR: 基于机器学习的制造成本估算框架，通过弹程决策树模型直接从2D工程图预测成本，达到平均10%的绝对百分比误差，并提供了可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 解决传统制造成本估价流程中需要苦巧的过程规划问题，缩短报价周期，并提供一致透明的成本评估。

Method: 从13,684张汽车悬挂和转向部件DWG图纸中提取约200个几何和统计描述符，使用弹程决策树模型(XGBoost、CatBoost、LightGBM)进行训练，结合SHAP工具提供可解释性分析。

Result: 模型在24个产品组中达到了近10%的平均绝对百分比误差，显示了超越部件特定经验法则的健壮扩展性。

Conclusion: 该端到端CAD到成本流水线缩短了报价周期，为工业4.0制造环境中的实时ERP集成决策支持提供了可部署的解决方案。

Abstract: We present an integrated machine learning framework that transforms how
manufacturing cost is estimated from 2D engineering drawings. Unlike
traditional quotation workflows that require labor-intensive process planning,
our approach about 200 geometric and statistical descriptors directly from
13,684 DWG drawings of automotive suspension and steering parts spanning 24
product groups. Gradient-boosted decision tree models (XGBoost, CatBoost,
LightGBM) trained on these features achieve nearly 10% mean absolute percentage
error across groups, demonstrating robust scalability beyond part-specific
heuristics. By coupling cost prediction with explainability tools such as SHAP,
the framework identifies geometric design drivers including rotated dimension
maxima, arc statistics and divergence metrics, offering actionable insights for
cost-aware design. This end-to-end CAD-to-cost pipeline shortens quotation lead
times, ensures consistent and transparent cost assessments across part families
and provides a deployable pathway toward real-time, ERP-integrated decision
support in Industry 4.0 manufacturing environments.

</details>


### [301] [Local Cluster Cardinality Estimation for Adaptive Mean Shift](https://arxiv.org/abs/2508.12450)
*Étienne Pepin*

Main category: cs.LG

TL;DR: 基于局部距离分布估计聚类数量的自适应均倾算法，能够动态调整带宽和内核半径，在变化局部规模和聚类数量的数据集上表现优异


<details>
  <summary>Details</summary>
Motivation: 解决传统均倾算法在局部规模和聚类数量变化的数据集上性能不佳的问题，特别是KDE方法只能提供局部区域的见解而无法获得整个聚类的参数

Method: 利用点到其他所有点的局部距离分布，通过识别距离分布密度中的局部最小值来估计局部聚类数量，并基于此估计动态调整均倾算法的带宽和内核半径阈值

Result: 在原始数据集上超过了最近提出的自适应均倾方法，并在更广泛的聚类测试集上展现了竞争性能能

Conclusion: 通过局部聚类数量估计来自适应调整均倾算法参数的方法有效提升了聚类性能，特别适用于局部规模和聚类数量变化的复杂数据集

Abstract: This article presents an adaptive mean shift algorithm designed for datasets
with varying local scale and cluster cardinality. Local distance distributions,
from a point to all others, are used to estimate the cardinality of the local
cluster by identifying a local minimum in the density of the distance
distribution. Based on these cardinality estimates, local cluster parameters
are then computed for the entire cluster in contrast to KDE-based methods,
which provide insight only into localized regions of the cluster. During the
mean shift execution, the cluster cardinality estimate is used to adaptively
adjust the bandwidth and the mean shift kernel radius threshold. Our algorithm
outperformed a recently proposed adaptive mean shift method on its original
dataset and demonstrated competitive performance on a broader clustering
benchmark.

</details>


### [302] [Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX](https://arxiv.org/abs/2508.12485)
*Aayush Gupta,Arpit Bhayani*

Main category: cs.LG

TL;DR: Cold-RL是一个基于强化学习的NGINX缓存淘汰策略，使用双深度Q网络在500微秒预算内选择淘汰对象，相比传统LRU策略在25MB缓存下命中率提升146%，在100MB缓存下提升15%。


<details>
  <summary>Details</summary>
Motivation: 传统LRU缓存淘汰策略对对象大小不敏感，在周期性突发流量和混合对象大小情况下容易产生抖动，需要更智能的淘汰策略来提高缓存命中率。

Method: 使用离线训练的强化学习模型（双深度Q网络），在每次淘汰时从K个最近最少使用对象中提取6个轻量级特征（年龄、大小、命中次数、到达间隔时间、剩余TTL、最后源站RTT），通过ONNX侧车服务在500微秒内返回淘汰位掩码。

Result: 在25MB缓存下，命中率从0.1436提升到0.3538（146%提升）；在100MB缓存下，从0.7530提升到0.8675（15%提升）；在400MB缓存下与传统方法相当（约0.918）。推理增加不到2%的CPU开销，保持95%分位淘汰延迟在预算内。

Conclusion: Cold-RL是首个集成到NGINX中并满足严格SLO要求的强化学习淘汰策略，在中小规模缓存下显著优于传统方法，同时保持低延迟和低开销。

Abstract: Web proxies such as NGINX commonly rely on least-recently-used (LRU)
eviction, which is size agnostic and can thrash under periodic bursts and mixed
object sizes. We introduce Cold-RL, a learned eviction policy for NGINX that
replaces LRU's forced-expire path with a dueling Deep Q-Network served by an
ONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL
samples the K least-recently-used objects, extracts six lightweight features
(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),
and requests a bitmask of victims; a hard timeout of 500 microseconds triggers
immediate fallback to native LRU. Policies are trained offline by replaying
NGINX access logs through a cache simulator with a simple reward: a retained
object earns one point if it is hit again before TTL expiry. We compare against
LRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial
workloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,
a 146 percent improvement over the best classical baseline; at 100 MB, from
0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods
(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th
percentile eviction latency within budget. To our knowledge, this is the first
reinforcement learning eviction policy integrated into NGINX with strict SLOs.

</details>


### [303] [Cost-Aware Contrastive Routing for LLMs](https://arxiv.org/abs/2508.12491)
*Reza Shirkavand,Shangqian Gao,Peiran Yu,Heng Huang*

Main category: cs.LG

TL;DR: CSCR是一个轻量级成本感知路由框架，通过将提示和模型映射到共享嵌入空间，实现快速、成本敏感的LLM选择，在多个基准测试中比基线方法提升25%的准确率-成本权衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法往往忽略提示特定上下文、依赖昂贵的模型分析、假设固定专家集或使用低效的试错策略，需要更高效的成本感知路由方案。

Method: 使用紧凑快速计算的对数足迹（开源模型）和困惑度指纹（黑盒API），通过对比编码器训练在自适应成本带内选择最便宜准确专家，推理时通过FAISS索引进行单次k-NN查找。

Result: 在多个基准测试中 consistently 优于基线方法，准确率-成本权衡提升高达25%，对未见过的LLM和分布外提示具有强泛化能力。

Conclusion: CSCR提供了一个高效、轻量级的成本感知路由框架，无需重新训练即可适应专家池变化，实现微秒级延迟，显著提升了LLM路由的效率和效果。

Abstract: We study cost-aware routing for large language models across diverse and
dynamic pools of models. Existing approaches often overlook prompt-specific
context, rely on expensive model profiling, assume a fixed set of experts, or
use inefficient trial-and-error strategies. We introduce Cost-Spectrum
Contrastive Routing (CSCR), a lightweight framework that maps both prompts and
models into a shared embedding space to enable fast, cost-sensitive selection.
CSCR uses compact, fast-to-compute logit footprints for open-source models and
perplexity fingerprints for black-box APIs. A contrastive encoder is trained to
favor the cheapest accurate expert within adaptive cost bands. At inference
time, routing reduces to a single k-NN lookup via a FAISS index, requiring no
retraining when the expert pool changes and enabling microsecond latency.
Across multiple benchmarks, CSCR consistently outperforms baselines, improving
the accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen
LLMs and out-of-distribution prompts.

</details>


### [304] [Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference](https://arxiv.org/abs/2508.12511)
*Denis Blessing,Julius Berner,Lorenz Richter,Carles Domingo-Enrich,Yuanqi Du,Arash Vahdat,Gerhard Neumann*

Main category: cs.LG

TL;DR: 提出了一种基于信任区域的几何退火方法，用于解决控制成本差异大的随机最优控制问题，通过逐步逼近目标测度来提升优化性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于梯度优化的随机最优控制方法在处理目标测度与先验测度差异较大时面临挑战，需要一种更有效的优化策略。

Method: 采用迭代求解约束问题的方法，结合信任区域策略，实现从先验测度到目标测度的几何退火过程，通过信任区域原理性地选择退火路径的时间步长。

Result: 在多个最优控制应用中展示了显著性能提升，包括基于扩散的采样、过渡路径采样和扩散模型微调等任务。

Conclusion: 基于信任区域的几何退火方法为解决目标测度与先验测度差异大的随机最优控制问题提供了一种系统且有效的解决方案。

Abstract: Solving stochastic optimal control problems with quadratic control costs can
be viewed as approximating a target path space measure, e.g. via gradient-based
optimization. In practice, however, this optimization is challenging in
particular if the target measure differs substantially from the prior. In this
work, we therefore approach the problem by iteratively solving constrained
problems incorporating trust regions that aim for approaching the target
measure gradually in a systematic way. It turns out that this trust region
based strategy can be understood as a geometric annealing from the prior to the
target measure, where, however, the incorporated trust regions lead to a
principled and educated way of choosing the time steps in the annealing path.
We demonstrate in multiple optimal control applications that our novel method
can improve performance significantly, including tasks in diffusion-based
sampling, transition path sampling, and fine-tuning of diffusion models.

</details>


### [305] [Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning](https://arxiv.org/abs/2508.12524)
*Joseph Suárez,Kyoung Whan Choe,David Bloomin,Jianming Gao,Yunkun Li,Yao Feng,Saidinesh Pola,Kun Zhang,Yonghui Zhu,Nikhil Pinnaparaju,Hao Xiang Li,Nishaanth Kanna,Daniel Scott,Ryan Sullivan,Rose S. Shuman,Lucas de Alcântara,Herbie Bradley,Kirsty You,Bo Wu,Yuhao Jiang,Qimai Li,Jiaxin Chen,Louis Castricato,Xiaolong Zhu,Phillip Isola*

Main category: cs.LG

TL;DR: NeurIPS 2023 Neural MMO竞赛吸引了200多名参与者，参赛者训练的目标条件策略能够泛化到训练中未见过的任务、地图和对手。最佳解决方案在单块4090 GPU上训练8小时后，得分比基线高4倍。所有相关资源均已开源。


<details>
  <summary>Details</summary>
Motivation: 举办大规模多智能体竞赛，推动目标条件策略在复杂多智能体环境中的泛化能力研究，促进社区发展和知识共享。

Method: 基于Neural MMO平台，参赛者训练目标条件策略，要求策略能够泛化到未见过的任务、地图和对手。竞赛设置了基线模型和评估标准。

Result: 竞赛吸引了200多名参与者，最佳解决方案在单块4090 GPU上训练8小时后，得分比基线高4倍，表现出色。

Conclusion: Neural MMO竞赛成功展示了目标条件策略在多智能体环境中的强大泛化能力，开源所有资源将促进该领域进一步发展。

Abstract: We present the results of the NeurIPS 2023 Neural MMO Competition, which
attracted over 200 participants and submissions. Participants trained
goal-conditional policies that generalize to tasks, maps, and opponents never
seen during training. The top solution achieved a score 4x higher than our
baseline within 8 hours of training on a single 4090 GPU. We open-source
everything relating to Neural MMO and the competition under the MIT license,
including the policy weights and training code for our baseline and for the top
submissions.

</details>


### [306] [Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs](https://arxiv.org/abs/2508.12530)
*Hyunsoo Song,Seungwhan Kim,Seungkyu Lee*

Main category: cs.LG

TL;DR: 通过提出局部后验冲突概念和潜在重建损失，解决VAE后验冲突问题，无需网络结构限制


<details>
  <summary>Details</summary>
Motivation: VAE模型存在后验冲突问题，降低生成样本的多样性，现有方法需要网络结构约束

Method: 提出局部后验冲突概念，设计Latent Reconstruction(LR)损失函数，基于注射函数和复合函数的数学性质

Result: 在MNIST、fashionMNIST、Omniglot、CelebA、FFHQ等多个数据集上有效控制后验冲突

Conclusion: LR损失能够无需特定网络结构约束地控制VAE后验冲突，提高生成样本的多样性

Abstract: Variational autoencoders (VAEs), one of the most widely used generative
models, are known to suffer from posterior collapse, a phenomenon that reduces
the diversity of generated samples. To avoid posterior collapse, many prior
works have tried to control the influence of regularization loss. However, the
trade-off between reconstruction and regularization is not satisfactory. For
this reason, several methods have been proposed to guarantee latent
identifiability, which is the key to avoiding posterior collapse. However, they
require structural constraints on the network architecture. For further
clarification, we define local posterior collapse to reflect the importance of
individual sample points in the data space and to relax the network constraint.
Then, we propose Latent Reconstruction(LR) loss, which is inspired by
mathematical properties of injective and composite functions, to control
posterior collapse without restriction to a specific architecture. We
experimentally evaluate our approach, which controls posterior collapse on
varied datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ.

</details>


### [307] [Rethinking Safety in LLM Fine-tuning: An Optimization Perspective](https://arxiv.org/abs/2508.12531)
*Minseon Kim,Jin Myung Kwak,Lama Alssum,Bernard Ghanem,Philip Torr,David Krueger,Fazl Barez,Adel Bibi*

Main category: cs.LG

TL;DR: 通过系统的调优选择和EMA动量技术，可以在细调语言模型时同时保持性能和安全性，将有害响应从16%降至约5%。


<details>
  <summary>Details</summary>
Motivation: 质疑传统观点，认为细调语言模型必然会损害其安全性，希望找到无需额外安全措施的解决方案。

Method: 通过系统测试选择关键训练超参数（学习率、批处理大小、梯度步长），并提出指数移动平均（EMA）动量技术来稳定优化路径。

Result: 在Llama模型家族上进行实验，有害响应从16%显著降至约5%，同时保持了模型的应用性能能力。

Conclusion: 细调过程中的安全问题可以通过合适的优化选择大幅避免，无需专门的安全干预或额外数据，为模型适配提供了实用指南。

Abstract: Fine-tuning language models is commonly believed to inevitably harm their
safety, i.e., refusing to respond to harmful user requests, even when using
harmless datasets, thus requiring additional safety measures. We challenge this
belief through systematic testing, showing that poor optimization choices,
rather than inherent trade-offs, often cause safety problems, measured as
harmful responses to adversarial prompts. By properly selecting key training
hyper-parameters, e.g., learning rate, batch size, and gradient steps, we
reduce unsafe model responses from 16\% to approximately 5\%, as measured by
keyword matching, while maintaining utility performance. Based on this
observation, we propose a simple exponential moving average (EMA) momentum
technique in parameter space that preserves safety performance by creating a
stable optimization path and retains the original pre-trained model's safety
properties. Our experiments on the Llama families across multiple datasets
(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can
largely be avoided without specialized interventions, outperforming existing
approaches that require additional safety data while offering practical
guidelines for maintaining both model performance and safety during adaptation.

</details>


### [308] [Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction](https://arxiv.org/abs/2508.12533)
*Qinwen Ge,Roza G. Bayrak,Anwar Said,Catie Chang,Xenofon Koutsoukos,Tyler Derr*

Main category: cs.LG

TL;DR: 通过系统性的数据中心设计空间分析，研究了功能性碰描共振图像大脑图构建的关键决策，证明思考密切的数据配置能够持续提升下游分类性能


<details>
  <summary>Details</summary>
Motivation: 当前大脑图构建通常依赖固化流水线，忽视了数据中心AI视角下的关键决策选择，需要系统性地研究数据中心设计空间对下游性能的影响

Method: 将大脑图构建设计空间组织为三个阶段：时间信号处理、拓扑结构提取和图特征化，研究了高振幅BOLD信号筛波、聚合性策略、替代相关指标以及多视角节点和边特征（包括滞后动态）等技术组合

Result: 在HCP1200和ABIDE数据集上的实验显示，思考密切的数据中心配置能够持续提高分类准确性，超过标准流水线

Conclusion: 上游数据决策在图基神经影像中发挥着关键作用，系统性探索数据中心设计空间对于提升图机器学习性能至关重要

Abstract: The construction of brain graphs from functional Magnetic Resonance Imaging
(fMRI) data plays a crucial role in enabling graph machine learning for
neuroimaging. However, current practices often rely on rigid pipelines that
overlook critical data-centric choices in how brain graphs are constructed. In
this work, we adopt a Data-Centric AI perspective and systematically define and
benchmark a data-centric design space for brain graph construction,
constrasting with primarily model-centric prior work. We organize this design
space into three stages: temporal signal processing, topology extraction, and
graph featurization. Our contributions lie less in novel components and more in
evaluating how combinations of existing and modified techniques influence
downstream performance. Specifically, we study high-amplitude BOLD signal
filtering, sparsification and unification strategies for connectivity,
alternative correlation metrics, and multi-view node and edge features, such as
incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets
show that thoughtful data-centric configurations consistently improve
classification accuracy over standard pipelines. These findings highlight the
critical role of upstream data decisions and underscore the importance of
systematically exploring the data-centric design space for graph-based
neuroimaging. Our code is available at
https://github.com/GeQinwen/DataCentricBrainGraphs.

</details>


### [309] [OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning](https://arxiv.org/abs/2508.12551)
*Hongyu Lin,Yuchen Li,Haoran Luo,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: OS-R1是一个基于规则强化学习的Linux内核调优框架，通过将内核配置空间抽象为RL环境，利用LLM进行高效探索和准确配置修改，在实验中比启发式调优方法性能提升5.6%


<details>
  <summary>Details</summary>
Motivation: 现有的Linux内核调优方法在效率、可扩展性和泛化性方面存在挑战，需要一种更有效的自动化调优解决方案

Method: 提出基于规则强化学习的代理框架，将内核配置抽象为RL环境，设计定制奖励函数增强LLM的推理标准化和配置准确性，采用两阶段训练过程加速收敛

Result: 实验结果显示OS-R1显著优于现有基线方法，性能提升达5.6%，保持高数据效率，并能适应各种实际应用场景

Conclusion: OS-R1展示了在实际多样化环境中部署的潜力，为Linux内核自动化调优提供了有效的解决方案

Abstract: Linux kernel tuning is essential for optimizing operating system (OS)
performance. However, existing methods often face challenges in terms of
efficiency, scalability, and generalization. This paper introduces OS-R1, an
agentic Linux kernel tuning framework powered by rule-based reinforcement
learning (RL). By abstracting the kernel configuration space as an RL
environment, OS-R1 facilitates efficient exploration by large language models
(LLMs) and ensures accurate configuration modifications. Additionally, custom
reward functions are designed to enhance reasoning standardization,
configuration modification accuracy, and system performance awareness of the
LLMs. Furthermore, we propose a two-phase training process that accelerates
convergence and minimizes retraining across diverse tuning scenarios.
Experimental results show that OS-R1 significantly outperforms existing
baseline methods, achieving up to 5.6% performance improvement over heuristic
tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across
various real-world applications, demonstrating its potential for practical
deployment in diverse environments. Our dataset and code are publicly available
at https://github.com/LHY-24/OS-R1.

</details>


### [310] [Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement](https://arxiv.org/abs/2508.12555)
*Junpeng Wang,Yuzhong Chen,Menghai Pan,Chin-Chia Michael Yeh,Mahashweta Das*

Main category: cs.LG

TL;DR: 一个可视化分析系统，用于帮助ML科学家进行代码生成代理的迭代过程分析和调整


<details>
  <summary>Details</summary>
Motivation: 当前代码生成代理的手动检查方式效率低下，难以跟踪代码迭代过程和进行对比分析

Method: 开发了一个可视化分析系统，支持三个层面的对比分析：代码级、过程级和LLM级分析

Result: 通过Kaggle竞赛案例研究，证明系统能够提供有价值的迭代代码过程洞察

Conclusion: 该系统能够帮助ML科学家结构化理解代理行为，提高调试和prompt工程效果

Abstract: Coding agents powered by large language models (LLMs) have gained traction
for automating code generation through iterative problem-solving with minimal
human involvement. Despite the emergence of various frameworks, e.g.,
LangChain, AutoML, and AIDE, ML scientists still struggle to effectively review
and adjust the agents' coding process. The current approach of manually
inspecting individual outputs is inefficient, making it difficult to track code
evolution, compare coding iterations, and identify improvement opportunities.
To address this challenge, we introduce a visual analytics system designed to
enhance the examination of coding agent behaviors. Focusing on the AIDE
framework, our system supports comparative analysis across three levels: (1)
Code-Level Analysis, which reveals how the agent debugs and refines its code
over iterations; (2) Process-Level Analysis, which contrasts different
solution-seeking processes explored by the agent; and (3) LLM-Level Analysis,
which highlights variations in coding behavior across different LLMs. By
integrating these perspectives, our system enables ML scientists to gain a
structured understanding of agent behaviors, facilitating more effective
debugging and prompt engineering. Through case studies using coding agents to
tackle popular Kaggle competitions, we demonstrate how our system provides
valuable insights into the iterative coding process.

</details>


### [311] [Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomposition](https://arxiv.org/abs/2508.12565)
*Luke Li*

Main category: cs.LG

TL;DR: 结合滑动窗口和变分模态分解(VMD)的金融时间序列预测模型，通过VMD分解非平稳序列为平滑子分量，再用LSTM进行预测，相比原始序列获得更好性能和稳定性


<details>
  <summary>Details</summary>
Motivation: 解决金融时间序列的复杂性，提高预测模型的适应性和准确性

Method: 使用滑动窗口构建数据集，VMD分解非平稳金融时间序列为平滑子分量，然后将分解后的数据输入深度学习模型(LSTM)进行预测

Result: VMD处理的序列相比原始时间序列在LSTM模型中表现出更好的预测效果和稳定性

Conclusion: VMD分解能有效处理金融时间序列的非平稳特性，结合深度学习模型可显著提升预测性能

Abstract: To address the complexity of financial time series, this paper proposes a
forecasting model combining sliding window and variational mode decomposition
(VMD) methods. Historical stock prices and relevant market indicators are used
to construct datasets. VMD decomposes non-stationary financial time series into
smoother subcomponents, improving model adaptability. The decomposed data is
then input into a deep learning model for prediction. The study compares the
forecasting effects of an LSTM model trained on VMD-processed sequences with
those using raw time series, demonstrating better performance and stability.

</details>


### [312] [Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems](https://arxiv.org/abs/2508.12569)
*Quercus Hernandez,Max Win,Thomas C. O'Connor,Paulo E. Arratia,Nathaniel Trask*

Main category: cs.LG

TL;DR: 一种基于metriplectic括号形式的机器学习框架，用于从粒子轨迹时间序列中学习粗结化动力学模型，通过构造保证热力学第一、第二定律、动量守恒和渺浮-耗散平衡


<details>
  <summary>Details</summary>
Motivation: 多尺度系统模拟面临挑战，粗结化过程中信息损失导致了耗散性、历史依赖性和随机性的出现物理现象，需要一种能够保持这些性质的学习框架

Method: 采用metriplectic括号形式构造框架，通过构造保证离散热力学定律、动量守恒和渺浮-耗散平衡；提出新的自监督学习策略来识别出现结构变量

Result: 在标准系统上验证了方法，并在两个具有挑战的应用中展示了其效用：星形聚合物粗结化和胚液悬浮高速视频学习，成功捕捉了非平衡统计性质和局部重排事件与出现随机动力学的耦合

Conclusion: 该框架通过构造保证了粗结化模型的关键物理性质，提供了一种有效的方法来学习多尺度系统的动力学，并在具有挑战的实际问题中验证了其效果

Abstract: Multiscale systems are ubiquitous in science and technology, but are
notoriously challenging to simulate as short spatiotemporal scales must be
appropriately linked to emergent bulk physics. When expensive high-dimensional
dynamical systems are coarse-grained into low-dimensional models, the entropic
loss of information leads to emergent physics which are dissipative,
history-dependent, and stochastic. To machine learn coarse-grained dynamics
from time-series observations of particle trajectories, we propose a framework
using the metriplectic bracket formalism that preserves these properties by
construction; most notably, the framework guarantees discrete notions of the
first and second laws of thermodynamics, conservation of momentum, and a
discrete fluctuation-dissipation balance crucial for capturing non-equilibrium
statistics. We introduce the mathematical framework abstractly before
specializing to a particle discretization. As labels are generally unavailable
for entropic state variables, we introduce a novel self-supervised learning
strategy to identify emergent structural variables. We validate the method on
benchmark systems and demonstrate its utility on two challenging examples: (1)
coarse-graining star polymers at challenging levels of coarse-graining while
preserving non-equilibrium statistics, and (2) learning models from high-speed
video of colloidal suspensions that capture coupling between local
rearrangement events and emergent stochastic dynamics. We provide open-source
implementations in both PyTorch and LAMMPS, enabling large-scale inference and
extensibility to diverse particle-based systems.

</details>


### [313] [Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM](https://arxiv.org/abs/2508.12575)
*Zohra Yagoub,Hafida Bouziane*

Main category: cs.LG

TL;DR: 使用预训练的蛋白质大语言模型提取序列上下文特征，通过双向LSTM和GRU模型预测肽维结构形成区域，突破84.5%的准确率


<details>
  <summary>Details</summary>
Motivation: 现有的肽维形成预测方法主要基于进化模体和氨基酸特性，序列信息特征显示出高预测性能，需要探索更先进的计算方法

Method: 利用预训练的蛋白质大语言模型提取序列上下文特征，构建双向LSTM和GRU深度学习模型进行肽维区域预测

Result: 在10折交叉验证中获得84.5%的准确率，测试数据集上达到83%的准确率，表现出竞争力

Conclusion: 证明了大语言模型在提高肽维预测准确性方面的潜力，为蛋白质肽维形成预测提供了新的技术路径

Abstract: The prediction of amyloidogenicity in peptides and proteins remains a focal
point of ongoing bioinformatics. The crucial step in this field is to apply
advanced computational methodologies. Many recent approaches to predicting
amyloidogenicity within proteins are highly based on evolutionary motifs and
the individual properties of amino acids. It is becoming increasingly evident
that the sequence information-based features show high predictive performance.
Consequently, our study evaluated the contextual features of protein sequences
obtained from a pretrained protein large language model leveraging
bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and
protein sequences. Our method achieved an accuracy of 84.5% on 10-fold
cross-validation and an accuracy of 83% in the test dataset. Our results
demonstrate competitive performance, highlighting the potential of LLMs in
enhancing the accuracy of amyloid prediction.

</details>


### [314] [Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg](https://arxiv.org/abs/2508.12576)
*Like Jian,Dong Liu*

Main category: cs.LG

TL;DR: 论文分析了过参数化FedAvg在联邦学习中的收敛性，证明随着神经网络宽度增加，数据异构性的影响会减弱，在无限宽度下FedAvg能达到与集中式学习相同的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据非独立同分布的特性给训练全局模型带来挑战，需要理解数据异构性对模型泛化能力的影响。

Method: 理论分析过参数化FedAvg与梯度下降的收敛性，证明网络宽度增加时数据异构性影响减弱，并在无限宽度下证明FedAvg与集中式学习等价。

Result: 理论证明和大量实验验证：网络宽度增加时数据异构性影响减小，无限宽度下FedAvg能达到与集中式学习相同的泛化性能。

Conclusion: 过参数化是解决联邦学习中数据异构性问题的有效方法，无限宽度神经网络能消除数据分布差异带来的负面影响。

Abstract: Federated learning (FL) enables decentralized clients to train a model
collaboratively without sharing local data. A key distinction between FL and
centralized learning is that clients' data are non-independent and identically
distributed, which poses significant challenges in training a global model that
generalizes well across heterogeneous local data distributions. In this paper,
we analyze the convergence of overparameterized FedAvg with gradient descent
(GD). We prove that the impact of data heterogeneity diminishes as the width of
neural networks increases, ultimately vanishing when the width approaches
infinity. In the infinite-width regime, we further prove that both the global
and local models in FedAvg behave as linear models, and that FedAvg achieves
the same generalization performance as centralized learning with the same
number of GD iterations. Extensive experiments validate our theoretical
findings across various network architectures, loss functions, and optimization
methods.

</details>


### [315] [Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding](https://arxiv.org/abs/2508.12590)
*Jihoon Park,Seungeun Oh,Seong-Lyun Kim*

Main category: cs.LG

TL;DR: 通过令片级判断机制，在保持准确性的同时大幅节省通信能耗和能源消耗


<details>
  <summary>Details</summary>
Motivation: 解决质量缩水环境下设备上LLM推理的需求，当前混合语言模型研究对通信和能源效率关注不够

Method: 采用基于认知不确定性和注意力机制的令片级筛选方法，只上传具有高信息值的令片

Result: 在TinyLlama-1.1B和LLaMA-2-7B上达到87.5% BERT Score，令片速率0.37 tokens/sec，节省40.7%能源消耗，性能超过之前的U-HLM基准方法

Conclusion: 该方法能够在带宽受限的边缘环境中实现能源效率高且准确的LLM部署

Abstract: To address the growing demand for on-device LLM inference in
resource-constrained environments, hybrid language models (HLM) have emerged,
combining lightweight local models with powerful cloud-based LLMs. Recent
studies on HLM have primarily focused on improving accuracy and latency, while
often overlooking communication and energy efficiency. We propose a token-level
filtering mechanism for an energy-efficient importance- and uncertainty-aware
HLM inference that leverages both epistemic uncertainty and attention-based
importance. Our method opportunistically uploads only informative tokens,
reducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and
LLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and
token throughput of 0.37 tokens/sec while saving the energy consumption by
40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM
baseline, our method improves BERTScore from 85.8% to 87.0%, energy savings
from 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an
energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge
environments.

</details>


### [316] [Physics-informed deep operator network for traffic state estimation](https://arxiv.org/abs/2508.12593)
*Zhihao Li,Ting Wang,Guojian Zou,Ruofei Wang,Ye Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息深度算子网络（PI-DeepONet）的交通状态估计方法，通过将交通流守恒定律直接集成到算子学习过程中，相比传统PINNs方法在稀疏输入数据下能更有效地重建完整时空交通状态场。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络（PINNs）在交通状态估计中逐点强制执行PDE约束存在局限性，需要一种能够更好地处理高维时空偏微分方程并确保物理一致性的方法。

Method: 采用物理信息深度算子网络框架，将交通状态估计重新表述为算子学习问题，训练参数化神经算子从稀疏输入数据映射到完整时空交通状态场，并直接集成交通流守恒模型和基本图关系。

Result: 在NGSIM数据集上的实验表明，该方法在性能上优于最先进的基线方法，能够有效捕捉拥堵传播、空间相关性和时间演化，同时分析了最优函数生成策略和分支网络复杂度的影响。

Conclusion: PI-DeepONet框架在交通状态估计中表现出优越的性能和鲁棒性，为处理高维时空PDE问题提供了有效的解决方案，并揭示了输入函数生成方法和函数数量对模型性能的重要影响。

Abstract: Traffic state estimation (TSE) fundamentally involves solving
high-dimensional spatiotemporal partial differential equations (PDEs) governing
traffic flow dynamics from limited, noisy measurements. While Physics-Informed
Neural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a
physics-informed deep operator network (PI-DeepONet) framework that
reformulates TSE as an operator learning problem. Our approach trains a
parameterized neural operator that maps sparse input data to the full
spatiotemporal traffic state field, governed by the traffic flow conservation
law. Crucially, unlike PINNs that enforce PDE constraints point-wise,
PI-DeepONet integrates traffic flow conservation model and the fundamental
diagram directly into the operator learning process, ensuring physical
consistency while capturing congestion propagation, spatial correlations, and
temporal evolution. Experiments on the NGSIM dataset demonstrate superior
performance over state-of-the-art baselines. Further analysis reveals insights
into optimal function generation strategies and branch network complexity.
Additionally, the impact of input function generation methods and the number of
functions on model performance is explored, highlighting the robustness and
efficacy of proposed framework.

</details>


### [317] [FLARE: Fast Low-rank Attention Routing Engine](https://arxiv.org/abs/2508.12594)
*Vedant Puri,Aditya Joglekar,Kevin Ferguson,Yu-hsuan Chen,Yongjie Jessica Zhang,Levent Burak Kara*

Main category: cs.LG

TL;DR: FLARE是一种线性复杂度的自注意力机制，通过固定长度的潜在序列路由注意力，解决了传统自注意力二次复杂度的问题，在大型非结构化网格上实现了更好的可扩展性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统自注意力机制的二次复杂度限制了其在大型非结构化网格上的应用和可扩展性，需要一种更高效的注意力机制来处理大规模问题。

Method: FLARE通过可学习的查询令牌将输入序列投影到固定长度的潜在序列（M << N），在瓶颈序列上路由注意力，学习低秩形式的注意力，实现O(NM)的计算复杂度。

Result: FLARE不仅能够扩展到前所未有的问题规模，而且在各种基准测试中相比最先进的神经PDE代理模型提供了更优越的准确性。

Conclusion: FLARE通过低秩注意力路由机制成功解决了自注意力的可扩展性问题，为处理大规模非结构化网格问题提供了有效的解决方案，并发布了新的增材制造数据集促进进一步研究。

Abstract: The quadratic complexity of self-attention limits its applicability and
scalability on large unstructured meshes. We introduce Fast Low-rank Attention
Routing Engine (FLARE), a linear complexity self-attention mechanism that
routes attention through fixed-length latent sequences. Each attention head
performs global communication among $N$ tokens by projecting the input sequence
onto a fixed length latent sequence of $M \ll N$ tokens using learnable query
tokens. By routing attention through a bottleneck sequence, FLARE learns a
low-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only
scales to unprecedented problem sizes, but also delivers superior accuracy
compared to state-of-the-art neural PDE surrogates across diverse benchmarks.
We also release a new additive manufacturing dataset to spur further research.
Our code is available at https://github.com/vpuri3/FLARE.py.

</details>


### [318] [Constructing Invariant and Equivariant Operations by Symmetric Tensor Network](https://arxiv.org/abs/2508.12596)
*Meng Zhang,Chao Wang,Hao Zhang,Shaojun Dong,Lixin He*

Main category: cs.LG

TL;DR: 本文提出了一种系统性的方法来构建有效的不变和等变操作，能够处理不同秩的笛卡尔张量和不同类型球张量，并利用对称张量网络的图形表示简化证明和构造。


<details>
  <summary>Details</summary>
Motivation: 设计包含对称性的神经网络对于几何深度学习至关重要，核心是开发不变和等变操作。

Method: 使用对称张量网络的图形表示方法，系统性地构建不变和等变操作，处理不同秩的笛卡尔张量和不同类型球张量。

Result: 成功构建了有效的不变和等变操作，并应用于几何图神经网络的等变交互消息和材料本构定律学习的等变机器学习模型。

Conclusion: 该方法为几何深度学习提供了一种系统性的不变和等变操作构建框架，具有广泛的应用前景。

Abstract: Design of neural networks that incorporate symmetry is crucial for geometric
deep learning. Central to this effort is the development of invariant and
equivariant operations. This works presents a systematic method for
constructing valid invariant and equivariant operations. It can handle inputs
and outputs in the form of Cartesian tensors with different rank, as well as
spherical tensors with different types. In addition, our method features a
graphical representation utilizing the symmetric tensor network, which
simplifies both the proofs and constructions related to invariant and
equivariant functions. We also apply this approach to design the equivariant
interaction message for the geometry graph neural network, and equivariant
machine learning model to learn the constitutive law of materials.

</details>


### [319] [A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators](https://arxiv.org/abs/2508.12602)
*Hansol Lim,Jongseong Brad Choi,Jee Won Lee,Haeseong Jeoung,Minkyu Han*

Main category: cs.LG

TL;DR: 一种混合代理模型，通过继承学习和可微物理模块从速度和加速度估计电动汽车参数，并预测电消耗，准确性高且可解释性强。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地估计电动汽车的动力系统参数和电消耗，同时保持模型的物理可解释性，以支持路径优化、健康管理等应用。

Method: 结合新颖的谱参数运算算子（基于傅里叶神经网络运算算子）获取全局上下文，以及可微物理模块在前向传播中嵌入物理知识，从速度和加速度独立输出多种时变参数。

Result: 在Tesla Model 3、Model S和Kia EV9实车数据上，模型对特斯拉车型平均绝对误差为0.2kW（约高速行驶拉力功率的1%），对Kia EV9为0.8kW，表现准确且具有良好的空间和采样率普适性。

Conclusion: 该混合代理模型能够以高准确度估计电动汽车参数和电消耗，具有强可解释性和普适性，适用于路径优化、车辆诊断等应用场景。

Abstract: We present a hybrid surrogate model for electric vehicle parameter estimation
and power consumption. We combine our novel architecture Spectral Parameter
Operator built on a Fourier Neural Operator backbone for global context and a
differentiable physics module in the forward pass. From speed and acceleration
alone, it outputs time-varying motor and regenerative braking efficiencies, as
well as aerodynamic drag, rolling resistance, effective mass, and auxiliary
power. These parameters drive a physics-embedded estimate of battery power,
eliminating any separate physics-residual loss. The modular design lets
representations converge to physically meaningful parameters that reflect the
current state and condition of the vehicle. We evaluate on real-world logs from
a Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean
absolute error of 0.2kW (about 1% of average traction power at highway speeds)
for Tesla vehicles and about 0.8kW on the Kia EV9. The framework is
interpretable, and it generalizes well to unseen conditions, and sampling
rates, making it practical for path optimization, eco-routing, on-board
diagnostics, and prognostics health management.

</details>


### [320] [SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression](https://arxiv.org/abs/2508.12604)
*Yuyang Xu,Yi Cheng,Haochao Ying,Zhuoyun Du,Renjun Hu,Xing Shi,Wei Lin,Jian Wu*

Main category: cs.LG

TL;DR: 无需辅助模型或步骤标注，通过自我追踪步骤偏好优化（SSPO）来压缩推理过程，解决大语言模型的过分思考问题


<details>
  <summary>Details</summary>
Motivation: 主流的调效后方法（如基于强化学习和思维链的方法）存在计算开销大、过分思考等问题，错误答案部分来自于缺乏正确自我修正的繁琐推理过程

Method: 提出SSPO框架，利用模型自身生成的步骤偏好信号来指导推理压缩优化，无需辅助模型或手动标注

Result: 实验表明SSPO生成的推理序列准确且简洁，有效减缓了过分思考行为，而不影响模型在多领域和语言上的性能

Conclusion: SSPO作为一种可插扩展的强化学习过程监督框架，能够通过细粒度的步骤优化来提升大语言模型的推理效果

Abstract: Test-time scaling has proven effective in further enhancing the performance
of pretrained Large Language Models (LLMs). However, mainstream post-training
methods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)
reasoning) often incur substantial computational overhead due to auxiliary
models and overthinking. In this paper, we empirically reveal that the
incorrect answers partially stem from verbose reasoning processes lacking
correct self-fix, where errors accumulate across multiple reasoning steps. To
this end, we propose Self-traced Step-wise Preference Optimization (SSPO), a
pluggable RL process supervision framework that enables fine-grained
optimization of each reasoning step. Specifically, SSPO requires neither
auxiliary models nor stepwise manual annotations. Instead, it leverages
step-wise preference signals generated by the model itself to guide the
optimization process for reasoning compression. Experiments demonstrate that
the generated reasoning sequences from SSPO are both accurate and succinct,
effectively mitigating overthinking behaviors without compromising model
performance across diverse domains and languages.

</details>


### [321] [How can we trust opaque systems? Criteria for robust explanations in XAI](https://arxiv.org/abs/2508.12623)
*Florian J. Boge,Annika Schuster*

Main category: cs.LG

TL;DR: 该论文提出了可解释人工智能(XAI)的可信度评估框架，强调解释鲁棒性(ER)和解释方法鲁棒性(EMR)两个关键标准，认为仅靠单一方法的鲁棒性不足以保证可信度。


<details>
  <summary>Details</summary>
Motivation: 深度学习算法虽然预测准确但内部机制不透明，现有XAI方法的性能评估存在疑虑，需要建立可信的解释评估标准。

Method: 提出并形式化了ER（不同XAI方法在可比情境下产生相同解释）和EMR（每个XAI方法必须满足的先决条件）的评判标准，构建了DL算法可信度评估框架。

Result: 建立了系统的XAI可信度评估理论框架，为解释和建立对DL算法的信任提供了方法论基础。

Conclusion: XAI的可信度需要同时满足ER和EMR标准，单一方法的鲁棒性不足以保证可信度，该框架为未来研究提供了重要方向。

Abstract: Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in
scientific research. However, the price we pay for their impressively accurate
predictions is significant: their inner workings are notoriously opaque - it is
unknown to laypeople and researchers alike what features of the data a DL
system focuses on and how it ultimately succeeds in predicting correct outputs.
A necessary criterion for trustworthy explanations is that they should reflect
the relevant processes the algorithms' predictions are based on. The field of
eXplainable Artificial Intelligence (XAI) presents promising methods to create
such explanations. But recent reviews about their performance offer reasons for
skepticism. As we will argue, a good criterion for trustworthiness is
explanatory robustness: different XAI methods produce the same explanations in
comparable contexts. However, in some instances, all methods may give the same,
but still wrong, explanation. We therefore argue that in addition to
explanatory robustness (ER), a prior requirement of explanation method
robustness (EMR) has to be fulfilled by every XAI method. Conversely, the
robustness of an individual method is in itself insufficient for
trustworthiness. In what follows, we develop and formalize criteria for ER as
well as EMR, providing a framework for explaining and establishing trust in DL
algorithms. We also highlight interesting application cases and outline
directions for future work.

</details>


### [322] [FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation](https://arxiv.org/abs/2508.12629)
*Ian Dunn,David R. Koes*

Main category: cs.LG

TL;DR: FlowMol3是一个开源的多模态流匹配模型，通过三种架构无关技术（自条件、假原子和训练时几何扭曲）显著提升了全原子小分子生成性能，实现了近100%的分子有效性，且参数量比同类方法少一个数量级。


<details>
  <summary>Details</summary>
Motivation: 开发能够生成具有所需性质的逼真分子的生成模型，可以加速化学发现。现有方法在联合采样分子拓扑和3D结构方面仍有改进空间。

Method: 基于流匹配框架，采用三种低成本技术：自条件（self-conditioning）、假原子（fake atoms）和训练时几何扭曲（train-time geometry distortion），无需改变图神经网络架构或流匹配公式。

Result: 实现了近100%的药物样分子有效性，更准确地复现了训练数据的功能团组成和几何结构，参数量比可比方法少一个数量级。

Conclusion: 这些技术缓解了基于传输的生成模型的普遍病理问题，能够在推理过程中检测和修正分布漂移，为改进扩散和流基分子生成模型的稳定性和质量提供了简单可转移的策略。

Abstract: A generative model capable of sampling realistic molecules with desired
properties could accelerate chemical discovery across a wide range of
applications. Toward this goal, significant effort has focused on developing
models that jointly sample molecular topology and 3D structure. We present
FlowMol3, an open-source, multi-modal flow matching model that advances the
state of the art for all-atom, small-molecule generation. Its substantial
performance gains over previous FlowMol versions are achieved without changes
to the graph neural network architecture or the underlying flow matching
formulation. Instead, FlowMol3's improvements arise from three
architecture-agnostic techniques that incur negligible computational cost:
self-conditioning, fake atoms, and train-time geometry distortion. FlowMol3
achieves nearly 100% molecular validity for drug-like molecules with explicit
hydrogens, more accurately reproduces the functional group composition and
geometry of its training data, and does so with an order of magnitude fewer
learnable parameters than comparable methods. We hypothesize that these
techniques mitigate a general pathology affecting transport-based generative
models, enabling detection and correction of distribution drift during
inference. Our results highlight simple, transferable strategies for improving
the stability and quality of diffusion- and flow-based molecular generative
models.

</details>


### [323] [Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery](https://arxiv.org/abs/2508.12650)
*Jiyeon Kang,Songseong Kim,Chanhui Lee,Doyeong Hwang,Joanie Hayoun Chung,Yunkyung Ko,Sumin Lee,Sungwoong Kim,Sungbin Lim*

Main category: cs.LG

TL;DR: 提出了SciNO模型来稳定估计Hessian对角线，改进了基于排序的因果发现方法，相比DiffAN在合成图和真实数据集上分别减少42.7%和31.5%的排序差异，并提出了与自回归模型结合的因果推理算法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于排序的因果发现方法需要准确估计对数密度的Hessian对角线，但之前的Stein梯度估计器计算成本高且内存密集，而DiffAN方法虽然用扩散模型替代但数值不稳定。

Method: 提出了Score-informed Neural Operator (SciNO)，一个在平滑函数空间中的概率生成模型，用于稳定近似Hessian对角线并在分数建模中保持结构信息。还提出了与自回归模型结合的概率控制算法。

Result: SciNO在合成图上减少42.7%的排序差异，在真实数据集上减少31.5%的排序差异，同时保持内存效率和可扩展性。提出的算法无需额外微调或提示工程就能增强LLMs的因果推理能力。

Conclusion: SciNO方法有效解决了现有因果排序方法的计算效率和数值稳定性问题，提出的概率控制算法成功将概率估计与自回归模型先验结合，提升了因果推理的可靠性。

Abstract: Ordering-based approaches to causal discovery identify topological orders of
causal graphs, providing scalable alternatives to combinatorial search methods.
Under the Additive Noise Model (ANM) assumption, recent causal ordering methods
based on score matching require an accurate estimation of the Hessian diagonal
of the log-densities. However, previous approaches mainly use Stein gradient
estimators, which are computationally expensive and memory-intensive. Although
DiffAN addresses these limitations by substituting kernel-based estimates with
diffusion models, it remains numerically unstable due to the second-order
derivatives of score models. To alleviate these problems, we propose
Score-informed Neural Operator (SciNO), a probabilistic generative model in
smooth function spaces designed to stably approximate the Hessian diagonal and
to preserve structural information during the score modeling. Empirical results
show that SciNO reduces order divergence by 42.7% on synthetic graphs and by
31.5% on real-world datasets on average compared to DiffAN, while maintaining
memory efficiency and scalability. Furthermore, we propose a probabilistic
control algorithm for causal reasoning with autoregressive models that
integrates SciNO's probability estimates with autoregressive model priors,
enabling reliable data-driven causal ordering informed by semantic information.
Consequently, the proposed method enhances causal reasoning abilities of LLMs
without additional fine-tuning or prompt engineering.

</details>


### [324] [Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering](https://arxiv.org/abs/2508.12672)
*Emmanouil Kritharakis,Dusan Jakovetic,Antonios Makris,Konstantinos Tserpes*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的对抗希拉攻击的联邦学习算法，在服务器拥有可信辅助数据集的前提下，仅需服务器和一个客户端就能有效对抗多数恶意客户端的攻击。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端可能受到希拉攻击，而现有的稳健方法需要预先知道恶意客户端数量或者多个可信客户端。这篇论文的动机是解决在仅有服务器和一个客户端可信的情况下，如何有效对抗多数恶意客户端的希拉攻击。

Method: 利用服务器拥有的可信辅助数据集，设计了一种新的联邦学习算法。该方法不需要预先知道恶意客户端的数量，仅需服务器和一个客户端就能进行有效的模型训练。通过理论分析证明了算法在强希拉攻击下仍能保持有界的最优性间隔。

Result: 在MNIST、FMNIST和CIFAR-10数据集上进行了实验验证，包括标签翻转、符号翻转和高斯噪声添加等多种攻击策略。实验结果显示，该算法在各种攻击情况下都显著超过了标准联邦学习和现有的稳健方法，如Mean、Trimmed Mean、Median、Krum和Multi-Krum等基准方法。

Conclusion: 该研究提出了一种有效的对抗希拉攻击的联邦学习方案，在仅有服务器和一个客户端可信的前提下，能够在不知道恶意客户端数量的情况下有效对抗多种希拉攻击。理论分析和实验结果都证明了该方法的有效性和优势。

Abstract: Federated Learning (FL) enables collaborative model training across multiple
clients without sharing private data. We consider FL scenarios wherein FL
clients are subject to adversarial (Byzantine) attacks, while the FL server is
trusted (honest) and has a trustworthy side dataset. This may correspond to,
e.g., cases where the server possesses trusted data prior to federation, or to
the presence of a trusted client that temporarily assumes the server role. Our
approach requires only two honest participants, i.e., the server and one
client, to function effectively, without prior knowledge of the number of
malicious clients. Theoretical analysis demonstrates bounded optimality gaps
even under strong Byzantine attacks. Experimental results show that our
algorithm significantly outperforms standard and robust FL baselines such as
Mean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack
strategies including label flipping, sign flipping, and Gaussian noise addition
across MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.

</details>


### [325] [Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach](https://arxiv.org/abs/2508.12673)
*Yuhao Zhou,Jindi Lv,Yuxin Tian,Dan Si,Qing Ye,Jiancheng Lv*

Main category: cs.LG

TL;DR: HyperFedZero是一种新颖的联邦学习方法，通过超网络动态生成针对非参与客户端的专用模型，解决了数据异构性和资源约束问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在处理数据异构性方面取得进展，但无法泛化到具有域内分布偏移和资源约束的非参与客户端。

Method: 使用超网络根据分布感知嵌入动态生成专用模型，通过NoisyEmbed增强提取器和平衡惩罚提取鲁棒的分布嵌入，防止特征崩溃。

Result: 在多个数据集和模型上的实验显示，HyperFedZero性能显著优于竞争方法，计算、存储和通信开销最小。消融研究和可视化验证了各组件的必要性。

Conclusion: HyperFedZero通过分布感知的归纳偏置和超网络机制，有效解决了联邦学习中非参与客户端的泛化问题，具有实际应用价值。

Abstract: Federated Learning (FL) has emerged as a promising paradigm for
privacy-preserving collaborative learning, yet data heterogeneity remains a
critical challenge. While existing methods achieve progress in addressing data
heterogeneity for participating clients, they fail to generalize to
non-participating clients with in-domain distribution shifts and resource
constraints. To mitigate this issue, we present HyperFedZero, a novel method
that dynamically generates specialized models via a hypernetwork conditioned on
distribution-aware embeddings. Our approach explicitly incorporates
distribution-aware inductive biases into the model's forward pass, extracting
robust distribution embeddings using a NoisyEmbed-enhanced extractor with a
Balancing Penalty, effectively preventing feature collapse. The hypernetwork
then leverages these embeddings to generate specialized models chunk-by-chunk
for non-participating clients, ensuring adaptability to their unique data
distributions. Extensive experiments on multiple datasets and models
demonstrate HyperFedZero's remarkable performance, surpassing competing methods
consistently with minimal computational, storage, and communication overhead.
Moreover, ablation studies and visualizations further validate the necessity of
each component, confirming meaningful adaptations and validating the
effectiveness of HyperFedZero.

</details>


### [326] [BUILDA: A Thermal Building Data Generation Framework for Transfer Learning](https://arxiv.org/abs/2508.12703)
*Thomas Krug,Fabian Raisch,Dominik Aimer,Markus Wirnsberger,Ferdinand Sigg,Benjamin Schäfer,Benjamin Tischler*

Main category: cs.LG

TL;DR: BuilDa是一个热建筑数据生成框架，无需深入的建筑模拟专业知识即可生成大量合成数据，用于迁移学习研究


<details>
  <summary>Details</summary>
Motivation: 迁移学习可以改进建筑热动力学建模，但现有公共数据集和数据生成器无法满足迁移学习研究在数据质量和数量方面的需求，且现有方法通常需要建筑模拟专业知识

Method: 使用单区域Modelica模型导出为功能模拟单元(FMU)，在Python中进行模拟，构建BuilDa框架生成合成数据

Result: 成功生成数据并用于预训练和微调迁移学习模型

Conclusion: BuilDa框架能够为迁移学习研究提供足够质量和数量的热建筑数据，且不需要深厚的建筑模拟专业知识

Abstract: Transfer learning (TL) can improve data-driven modeling of building thermal
dynamics. Therefore, many new TL research areas emerge in the field, such as
selecting the right source model for TL. However, these research directions
require massive amounts of thermal building data which is lacking presently.
Neither public datasets nor existing data generators meet the needs of TL
research in terms of data quality and quantity. Moreover, existing data
generation approaches typically require expert knowledge in building
simulation. We present BuilDa, a thermal building data generation framework for
producing synthetic data of adequate quality and quantity for TL research. The
framework does not require profound building simulation knowledge to generate
large volumes of data. BuilDa uses a single-zone Modelica model that is
exported as a Functional Mock-up Unit (FMU) and simulated in Python. We
demonstrate BuilDa by generating data and utilizing it for pretraining and
fine-tuning TL models.

</details>


### [327] [Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs](https://arxiv.org/abs/2508.12712)
*Seyed Mahdi Haji Seyed Hossein,Alireza Hosseini,Soheil Hajian Manesh,Amirali Shahriary*

Main category: cs.LG

TL;DR: 提出用于车辆网络交通标志检测的联邦学习框架，通过分散式训练保护隐私，评估多种聚合算法和配置参数的性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决联网自动驾驶车辆传感器数据的隐私和通信挑战，避免集中式机器学习需要共享原始数据的问题。

Method: 使用轻量级目标检测器进行专业化本地训练，通过FedProx、FedAdam和FedAVG等算法聚合模型参数，在Flower框架模拟环境中评估不同配置。

Result: 增加服务器轮次从2到20可将准确率从0.1以下提升至0.8以上；适中的本地轮次(8-10)达到约0.67准确率；更高客户端参与率提升泛化能力至0.83；FedProx在处理异构性方面表现最佳。

Conclusion: 联邦学习方法为实际车辆部署提供了可扩展的隐私保护解决方案，可指导未来鲁棒聚合和通信优化的集成，推动智能交通系统发展。

Abstract: Connected and automated vehicles generate vast amounts of sensor data daily,
raising significant privacy and communication challenges for centralized
machine learning approaches in perception tasks. This study presents a
decentralized, federated learning framework tailored for traffic sign detection
in vehicular networks to enable collaborative model training without sharing
raw data. The framework partitioned traffic sign classes across vehicles for
specialized local training using lightweight object detectors, aggregated model
parameters via algorithms like FedProx, FedAdam and FedAVG in a simulated
environment with the Flower framework, and evaluated multiple configurations
including varying server rounds, local epochs, client participation fractions,
and data distributions. Experiments demonstrated that increasing server rounds
from 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs
(8-10) provided optimal efficiency with accuracies around 0.67, higher client
participation fractions enhanced generalization up to 0.83, FedProx
outperformed other aggregators in handling heterogeneity, non-IID data
distributions reduced performance compared to IID, and training duration
primarily scaled with the number of rounds rather than aggregation strategy. We
conclude that this federated approach may offer a scalable, privacy-preserving
solution for real-world vehicular deployments, potentially guiding future
integrations of robust aggregation and communication optimizations to advance
intelligent transportation systems.

</details>


### [328] [FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment](https://arxiv.org/abs/2508.12727)
*Manning Zhu,Songtao Guo,Pengzhan Zhou,Yansong Ning,Chang Han,Dewen Qiao*

Main category: cs.LG

TL;DR: FedSODA是一个资源高效的联邦微调框架，通过层剪枝和蒸馏对齐技术，在保持模型性能的同时显著降低通信、存储和计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 联邦微调在资源受限的客户端上存在计算和内存需求高的问题，限制了其发展潜力，需要一种不需要访问或存储完整模型的解决方案。

Method: 提出相似性组剪枝(SGP)模块剪枝冗余层，保留关键层；引入协调蒸馏对齐(ODA)模块减少子模型与完整模型间的梯度差异；使用QLoRA技术让客户端只需部署量化子模型并微调轻量级适配器。

Result: 平均减少70.6%的通信开销，降低75.6%的存储使用，提高3.1%的任务准确率，在多个开源LLM和各种下游任务上验证了有效性。

Conclusion: FedSODA非常适合资源约束下的实际联邦微调应用，在保持性能的同时显著降低了资源需求。

Abstract: Federated fine-tuning (FFT) of large language models (LLMs) has recently
emerged as a promising solution to enable domain-specific adaptation while
preserving data privacy. Despite its benefits, FFT on resource-constrained
clients relies on the high computational and memory demands of full-model
fine-tuning, which limits the potential advancement. This paper presents
FedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs
without accessing or storing the full model. Specifically, we first propose a
similarity group pruning (SGP) module, which prunes redundant layers from the
full LLM while retaining the most critical layers to preserve the model
performance. Moreover, we introduce an orchestrated distillation alignment
(ODA) module to reduce gradient divergence between the sub-LLM and the full LLM
during FFT. Through the use of the QLoRA, clients only need to deploy quantized
sub-LLMs and fine-tune lightweight adapters, significantly reducing local
resource requirements. We conduct extensive experiments on three open-source
LLMs across a variety of downstream tasks. The experimental results demonstrate
that FedSODA reduces communication overhead by an average of 70.6%, decreases
storage usage by 75.6%, and improves task accuracy by 3.1%, making it highly
suitable for practical FFT applications under resource constraints.

</details>


### [329] [FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models](https://arxiv.org/abs/2508.12740)
*Beomseok Seo,Kichang Lee,JaeYeon Park*

Main category: cs.LG

TL;DR: FedUNet是一个轻量级、架构无关的联邦学习框架，通过U-Net风格的附加模块实现异构模型间的知识共享，仅需0.89MB通信开销就能达到93%以上的准确率


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习方法要求客户端模型架构一致的限制，适应真实世界中设备异构的环境

Method: 在每个客户端的主干网络上附加U-Net风格的模块，只共享U-Net的紧凑瓶颈部分，利用编码器-解码器设计和跳跃连接捕获多尺度特征

Result: 在VGG变体上实验，FedUNet达到93.11%准确率，轻量版达到92.68%准确率，通信开销仅0.89MB

Conclusion: FedUNet通过创新的U-Net附加模块设计，实现了高效的异构联邦学习，在保持高性能的同时大幅降低了通信成本

Abstract: Federated learning (FL) enables decentralized model training without sharing
local data. However, most existing methods assume identical model architectures
across clients, limiting their applicability in heterogeneous real-world
environments. To address this, we propose FedUNet, a lightweight and
architecture-agnostic FL framework that attaches a U-Net-inspired additive
module to each client's backbone. By sharing only the compact bottleneck of the
U-Net, FedUNet enables efficient knowledge transfer without structural
alignment. The encoder-decoder design and skip connections in the U-Net help
capture both low-level and high-level features, facilitating the extraction of
clientinvariant representations. This enables cooperative learning between the
backbone and the additive module with minimal communication cost. Experiment
with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in
compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low
communication overhead.

</details>


### [330] [A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks](https://arxiv.org/abs/2508.12741)
*Manuela Imbriani,Gina Belmonte,Mieke Massink,Alessandro Tofani,Vincenzo Ciancia*

Main category: cs.LG

TL;DR: 这篇论文开发了一个系统性评估神经网络空间推理能力的基准框架，重点分析形态学性质如连通性和距离关系，并发现神经网络在基本几何和拓扑理解任务中存在系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 为了系统性地评估神经网络的空间推理能力，特别是在形态学属性如连通性和距离关系方面的表现，以发现其存在的局限性和提出改进方案。

Method: 使用VoxLogicA空间模型检查器生成两类合成数据集：迷宫连通问题用于拓扑分析，空间距离计算任务用于几何理解。通过多分辨率评估扩展性和通用性，采用自动化流水线包括数据生成、标准化训练、推理执行和综合评估。

Result: 初步实验结果显示神经网络在空间推理能力方面遇到重大挑战，在基本几何和拓扑理解任务中出现系统性失败，使用Dice系数和IoU指标进行评估。

Conclusion: 该框架提供了可复现的实验协议，能够识别具体的局限性。这些局限性可以通过神经网络与符号推理方法相结合的混合方案来解决，以改善临床应用中的空间理解能力，为进一步研究神经网络空间推理的局限性和潜在解决方案奠定基础。

Abstract: This paper presents preliminary results in the definition of a comprehensive
benchmark framework designed to systematically evaluate spatial reasoning
capabilities in neural networks, with a particular focus on morphological
properties such as connectivity and distance relationships. The framework is
currently being used to study the capabilities of nnU-Net, exploiting the
spatial model checker VoxLogicA to generate two distinct categories of
synthetic datasets: maze connectivity problems for topological analysis and
spatial distance computation tasks for geometric understanding. Each category
is evaluated across multiple resolutions to assess scalability and
generalization properties. The automated pipeline encompasses a complete
machine learning workflow including: synthetic dataset generation, standardized
training with cross-validation, inference execution, and comprehensive
evaluation using Dice coefficient and IoU (Intersection over Union) metrics.
Preliminary experimental results demonstrate significant challenges in neural
network spatial reasoning capabilities, revealing systematic failures in basic
geometric and topological understanding tasks. The framework provides a
reproducible experimental protocol, enabling researchers to identify specific
limitations. Such limitations could be addressed through hybrid approaches
combining neural networks with symbolic reasoning methods for improved spatial
understanding in clinical applications, establishing a foundation for ongoing
research into neural network spatial reasoning limitations and potential
solutions.

</details>


### [331] [Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning](https://arxiv.org/abs/2508.12758)
*Sowmini Devi Veeramachaneni,Ramamurthy Garimella*

Main category: cs.LG

TL;DR: 提出约束质心聚类(CCC)方法，通过限制簇中心到最远点的最大距离来扩展经典质心聚类，使用拉格朗日公式得到闭式解，在合成环形数据上验证了其优于K-means和GMM的性能。


<details>
  <summary>Details</summary>
Motivation: 传统质心聚类方法缺乏对簇扩散的控制，无法保证簇的结构化特性，需要一种能够控制簇扩散同时保持可解释性的聚类方法。

Method: 基于拉格朗日公式推导闭式解，约束簇中心到最远点的最大距离，保持可解释性的同时控制簇的扩散程度。

Result: 在合成环形数据上，使用环向、扇区和联合熵作为评估指标，CCC通过减少径向扩散同时保持角度结构，实现了更紧凑的聚类效果，优于K-means和GMM。

Conclusion: CCC方法适用于需要结构化聚类和扩散控制的应用场景，如传感器网络、协作机器人和可解释模式分析。

Abstract: This paper presents Constrained Centroid Clustering (CCC), a method that
extends classical centroid-based clustering by enforcing a constraint on the
maximum distance between the cluster center and the farthest point in the
cluster. Using a Lagrangian formulation, we derive a closed-form solution that
maintains interpretability while controlling cluster spread. To evaluate CCC,
we conduct experiments on synthetic circular data with radial symmetry and
uniform angular distribution. Using ring-wise, sector-wise, and joint entropy
as evaluation metrics, we show that CCC achieves more compact clusters by
reducing radial spread while preserving angular structure, outperforming
standard methods such as K-means and GMM. The proposed approach is suitable for
applications requiring structured clustering with spread control, including
sensor networks, collaborative robotics, and interpretable pattern analysis.

</details>


### [332] [Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach](https://arxiv.org/abs/2508.12764)
*Cyril Voyant,Milan Despotovic,Luis Garcia-Gutierrez,Mohammed Asloune,Yves-Marie Saint-Drenan,Jean-Laurent Duchaud,hjuvan Antone Faggianelli,Elena Magliaro*

Main category: cs.LG

TL;DR: 基于极限学习机(ELM)的多输入多输出(MIMO)方法，用于短期能源预测，在科西嘉岛多种能源数据上表现优异，特别是太阳能和热能预测。


<details>
  <summary>Details</summary>
Motivation: 解决能源系统的非稳态性和季节性变化带来的预测挑战，需要一种高效、准确且适合实时应用的预测方法。

Method: 使用滑动窗口技术和周期时间编码来处理非稳态性，采用MIMO架构进行多能源输出和总产量预测，ELM模型提供闭式解决方案。

Result: 在1小时预测水平上，太阳能和热能的nRMSE分别为17.9%和5.1%，R²>0.98，显著超越持久性预测。在5小时内保持高精度。

Conclusion: 该方法计算效率高、适合实时应用，能够适应不同地区的网络特性和市场结构，为能源系统提供了一种灵活可靠的预测解决方案。

Abstract: A novel methodology for short-term energy forecasting using an Extreme
Learning Machine ($\mathtt{ELM}$) is proposed. Using six years of hourly data
collected in Corsica (France) from multiple energy sources (solar, wind, hydro,
thermal, bioenergy, and imported electricity), our approach predicts both
individual energy outputs and total production (\cyr{including imports, which
closely follow energy demand, modulo losses)} through a Multi-Input
Multi-Output ($\mathtt{MIMO}$) architecture. To address non-stationarity and
seasonal variability, sliding window techniques and cyclic time encoding are
incorporated, enabling dynamic adaptation to fluctuations. The $\mathtt{ELM}$
model significantly outperforms persistence-based forecasting, particularly for
solar and thermal energy, achieving an $\mathtt{nRMSE}$ of $17.9\%$ and
$5.1\%$, respectively, with $\mathtt{R^2} > 0.98$ (1-hour horizon). The model
maintains high accuracy up to five hours ahead, beyond which renewable energy
sources become increasingly volatile. While $\mathtt{MIMO}$ provides marginal
gains over Single-Input Single-Output ($\mathtt{SISO}$) architectures and
offers key advantages over deep learning methods such as $\mathtt{LSTM}$, it
provides a closed-form solution with lower computational demands, making it
well-suited for real-time applications, including online learning. Beyond
predictive accuracy, the proposed methodology is adaptable to various contexts
and datasets, as it can be tuned to local constraints such as resource
availability, grid characteristics, and market structures.

</details>


### [333] [Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling](https://arxiv.org/abs/2508.12773)
*Jiadong Chen,Xiao He,Hengyu Ye,Fuxin Jiang,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: 提出了E3Former在线集成模型，用于服务器less系统中的工作负载预测和自动扩缩容，相比现有方法平均减少10%预测误差，已在字节跳动IHPA平台部署，支持60万+ CPU核心的自动扩缩容，资源利用率降低40%以上。


<details>
  <summary>Details</summary>
Motivation: 现有预测模型难以快速适应在线工作负载流的动态变化，也无法有效捕捉细粒度高频预测任务带来的复杂周期性，需要开发更准确和鲁棒的预测方法。

Method: 提出E3Former在线集成模型，通过协同多个子网络的预测能力来克服单模型方法的局限性，在计算开销最小的情况下实现更高的准确性和鲁棒性。

Result: 在真实工作负载数据集上的实验表明，该方法在在线预测任务中平均减少10%的预测误差，已在字节跳动IHPA平台实际部署，支持30+应用稳定运行，覆盖60万+ CPU核心的自动扩缩容。

Conclusion: E3Former模型有效解决了服务器less系统中工作负载预测的挑战，实现了显著的性能提升和资源节约，具有重要的实际应用价值。

Abstract: In the swiftly evolving domain of cloud computing, the advent of serverless
systems underscores the crucial need for predictive auto-scaling systems. This
necessity arises to ensure optimal resource allocation and maintain operational
efficiency in inherently volatile environments. At the core of a predictive
auto-scaling system is the workload forecasting model. Existing forecasting
models struggle to quickly adapt to the dynamics in online workload streams and
have difficulty capturing the complex periodicity brought by fine-grained,
high-frequency forecasting tasks. Addressing this, we propose a novel online
ensemble model, E3Former, for online workload forecasting in large-scale
predictive auto-scaling. Our model synergizes the predictive capabilities of
multiple subnetworks to surmount the limitations of single-model approaches,
thus ensuring superior accuracy and robustness. Remarkably, it accomplishes
this with a minimal increase in computational overhead, adhering to the lean
operational ethos of serverless systems. Through extensive experimentation on
real-world workload datasets, we establish the efficacy of our ensemble model.
In online forecasting tasks, the proposed method reduces forecast error by an
average of 10%, and its effectiveness is further demonstrated through a
predictive auto-scaling test in the real-life online system. Currently, our
method has been deployed within ByteDance's Intelligent Horizontal Pod
Auto-scaling (IHPA) platform, which supports the stable operation of over 30
applications, such as Douyin E-Comerce, TouTiao, and Volcano Engine. The
predictive auto-scaling capacity reaching over 600,000 CPU cores. On the basis
of essentially ensuring service quality, the predictive auto-scaling system can
reduce resource utilization by over 40%.

</details>


### [334] [Randomized PCA Forest for Outlier Detection](https://arxiv.org/abs/2508.12776)
*Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek*

Main category: cs.LG

TL;DR: 基于随机化主成分分析森林的新题无监督离群检测方法，在多个数据集上表现优于现有方法，具有良好的汇总性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: 受随机化PCA森林在近似K近邻搜索中表现的启发，开发一种新的无监督离群检测方法。

Method: 利用随机化主成分分析森林（RPCA Forest）进行离群检测，通过构建多个随机化PCA模型来识别异常数据点。

Result: 在多个数据集上表现超过传统和最新方法，在其他数据集上也保持竞争力，显示出较高的汇总性能。

Conclusion: 该方法具有良好的汇总性能和计算效率，是无监督离群检测的优秀选择。

Abstract: We propose a novel unsupervised outlier detection method based on Randomized
Principal Component Analysis (PCA). Inspired by the performance of Randomized
PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a
novel unsupervised outlier detection method that utilizes RPCA Forest for
outlier detection. Experimental results showcase the superiority of the
proposed approach compared to the classical and state-of-the-art methods in
performing the outlier detection task on several datasets while performing
competitively on the rest. The extensive analysis of the proposed method
reflects it high generalization power and its computational efficiency,
highlighting it as a good choice for unsupervised outlier detection.

</details>


### [335] [Wavy Transformer](https://arxiv.org/abs/2508.12787)
*Satoshi Noguchi,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: 提出了Wavy Transformer来解决transformer中的过度平滑问题，通过二阶波动动力学设计新型注意力层，在NLP和CV任务上取得性能提升且参数增加极少


<details>
  <summary>Details</summary>
Motivation: 深层transformer存在token表示过度平滑的问题，即经过连续transformer块后token表示趋于相似值，这被解释为底层扩散动力学的耗散性质导致的

Method: 建立堆叠注意力层与完全图上图神经扩散的等价关系，基于二阶波动动力学设计新型注意力层，并设计保持物理状态-速度关系的FFN和归一化层

Result: 在多种NLP和CV任务的transformer模型上验证，Wavy Transformer以最小额外参数和无额外超参数调优的方式持续提升性能

Conclusion: 从物理动力学角度理解transformer的过度平滑问题，提出的Wavy Transformer架构有效缓解了该问题并提升了模型性能

Abstract: Transformers have achieved remarkable success across natural language
processing (NLP) and computer vision (CV). However, deep transformer models
often suffer from an over-smoothing issue, in which token representations
converge to similar values as they pass through successive transformer blocks.
In this paper, we establish an equivalence between the hidden-state dynamics
induced by stacked attention layers and graph neural diffusion on a complete
graph. From this perspective, over-smoothing can be interpreted as a
consequence of the dissipative nature of the underlying diffusion dynamics.
Motivated by this physical interpretation, we propose Wavy Transformer, which
consists of a novel attention layer based on second-order wavy dynamics. We
also introduce a feed-forward network and a normalization layer designed to
preserve the physical state-velocity relationship under the chain rule, thereby
extending the transformer architecture. We further validate our proposed
techniques on various transformer models for NLP and CV tasks. The results
consistently demonstrate that Wavy Transformer improves performance with
minimal additional parameters and no extra hyperparameter tuning.

</details>


### [336] [Bridging Human and LLM Judgments: Understanding and Narrowing the Gap](https://arxiv.org/abs/2508.12792)
*Felipe Maia Polo,Xinhe Wang,Mikhail Yurochkin,Gongjun Xu,Moulinath Banerjee,Yuekai Sun*

Main category: cs.LG

TL;DR: Bridge是一个统一的统计框架，通过线性变换建模人类与LLM评估之间的系统差异，提高LLM作为评估者时的准确性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型被广泛用作评估者(LLM-as-a-judge)，但其评估结果与人类判断存在系统性差异，需要建立框架来弥合这种差距

Method: 提出Bridge统计框架，假设每个提示-响应对存在潜在的人类偏好分数，将LLM偏差建模为捕捉差异来源的协变量的线性变换，并提供具有渐近保证的高效拟合算法

Result: 在6个LLM评估者和两个基准测试(BigGen Bench和Chatbot Arena)上，Bridge实现了与人类评分更高的一致性(准确率、校准和KL散度)，并揭示了系统性的人-LLM差距

Conclusion: Bridge提供了一个简单而有原则的框架来优化LLM评分，并表征人类与LLM之间的系统性差异，为LLM作为评估者的应用提供了统计基础

Abstract: Large language models are increasingly used as judges (LLM-as-a-judge) to
evaluate model outputs at scale, but their assessments often diverge
systematically from human judgments. We present Bridge, a unified statistical
framework that explicitly bridges human and LLM evaluations under both absolute
scoring and pairwise comparison paradigms. Bridge posits a latent human
preference score for each prompt-response pair and models LLM deviations as
linear transformations of covariates that capture sources of discrepancies.
This offers a simple and principled framework for refining LLM ratings and
characterizing systematic discrepancies between humans and LLMs. We provide an
efficient fitting algorithm with asymptotic guarantees for statistical
inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot
Arena), Bridge achieves higher agreement with human ratings (accuracy,
calibration, and KL divergence) and exposes systematic human-LLM gaps.

</details>


### [337] [A Shift in Perspective on Causality in Domain Generalization](https://arxiv.org/abs/2508.12798)
*Damian Machlanski,Stephanie Riley,Edward Moroshko,Kurt Butler,Panagiotis Dimitrakopoulos,Thomas Melistas,Akchunya Chanchal,Steven McDonagh,Ricardo Silva,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: 谜说因果模型能带来健壮AI泛化的说法在领域泛化评测中受到挑战，本文重新解释了因果性与泛化能力之间的表面矛盾，建议采用更细致的理论观点


<details>
  <summary>Details</summary>
Motivation: 因果模型能够带来健壮AI泛化的说法在领域泛化评测中受到挑战，需要重新考察因果性在泛化中的真正作用

Method: 重新解释因果性与领域泛化文献中的表面矛盾，提出更细致的理论框架

Result: 调和了因果模型与泛化能力之间的表面矛盾，为因果性在AI泛化中的作用提供了更深入的理论基础

Conclusion: 需要重新评估因果模型对AI泛化的作用，提出了更细致的理论观点来理解因果性在泛化中的真正价值

Abstract: The promise that causal modelling can lead to robust AI generalization has
been challenged in recent work on domain generalization (DG) benchmarks. We
revisit the claims of the causality and DG literature, reconciling apparent
contradictions and advocating for a more nuanced theory of the role of
causality in generalization. We also provide an interactive demo at
https://chai-uk.github.io/ukairs25-causal-predictors/.

</details>


### [338] [Maximum Score Routing For Mixture-of-Experts](https://arxiv.org/abs/2508.12801)
*Bowen Dong,Yilong Fan,Yutao Sun,Zhenyu Li,Tengyu Pan,Xun Zhou,Jianyong Wang*

Main category: cs.LG

TL;DR: MaxScore提出了一种新的MoE路由范式，通过建模为最小成本最大流问题并集成SoftTopk算子，解决了传统MoE网络中的token丢弃和硬件效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 传统MoE网络存在专家容量约束导致的token丢弃问题和硬件效率低下问题，而去除容量约束又会损害负载平衡和计算效率。

Method: 将路由建模为最小成本最大流问题，集成SoftTopk算子，避免了迭代重路由和最优传输公式的根本限制。

Result: 在相同FLOPs下实现了更低的训练损失和更高的评估分数，优于有约束和无约束的基线方法。

Conclusion: MaxScore有效解决了MoE路由中的关键问题，为稀疏激活的专家混合网络提供了更优的路由方案。

Abstract: Routing networks in sparsely activated mixture-of-experts (MoE) dynamically
allocate input tokens to top-k experts through differentiable sparse
transformations, enabling scalable model capacity while preserving
computational efficiency. Traditional MoE networks impose an expert capacity
constraint to ensure GPU-friendly computation. However, this leads to token
dropping when capacity is saturated and results in low hardware efficiency due
to padding in underutilized experts. Removing the capacity constraint, in turn,
compromises load balancing and computational efficiency. To address these
issues, we propose Maximum Score Routing ($\mathbf{MaxScore}$), a novel MoE
routing paradigm that models routing as a minimum-cost maximum-flow problem and
integrates a SoftTopk operator. MaxScore resolves the fundamental limitations
of iterative rerouting and optimal transport formulations, achieving lower
training losses and higher evaluation scores at equivalent FLOPs compared to
both constrained and unconstrained baselines. Implementation details and
experimental configurations can be obtained from
$\href{https://github.com/dongbw18/MaxScore.git}{MaxScore}$.

</details>


### [339] [Learning to Steer: Input-dependent Steering for Multimodal LLMs](https://arxiv.org/abs/2508.12815)
*Jayneel Parekh,Pegah Khayatan,Mustafa Shukor,Arnaud Dapogny,Alasdair Newson,Matthieu Cord*

Main category: cs.LG

TL;DR: L2S（Learn-to-Steer）是一种针对多模态大语言模型（MLLMs）的输入特定引导方法，通过训练辅助模块预测输入相关的引导向量，相比静态引导方法能更好地减少幻觉并增强安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的引导技术（如均值引导）使用单一引导向量，独立于输入查询，在处理依赖具体示例的期望行为时存在局限性。例如，对于非法活动的问题，安全回答可能是拒绝回答；对于医疗建议，可能需要指向外部资源或专家咨询。

Method: 提出L2S方法，使用输入特定的线性偏移进行细粒度引导。通过对比输入特定提示计算偏移，但测试时这些提示未知，因此训练一个小型辅助模块来预测输入特定的引导向量。

Result: L2S方法在减少MLLMs的幻觉和增强安全性方面表现优异，优于其他静态基线方法。

Conclusion: 输入特定的引导方法比静态引导更有效，L2S通过可学习的辅助模块实现了对多模态大语言模型的精细控制，为后置引导提供了新的解决方案。

Abstract: Steering has emerged as a practical approach to enable post-hoc guidance of
LLMs towards enforcing a specific behavior. However, it remains largely
underexplored for multimodal LLMs (MLLMs); furthermore, existing steering
techniques, such as mean steering, rely on a single steering vector, applied
independently of the input query. This paradigm faces limitations when the
desired behavior is dependent on the example at hand. For example, a safe
answer may consist in abstaining from answering when asked for an illegal
activity, or may point to external resources or consultation with an expert
when asked about medical advice. In this paper, we investigate a fine-grained
steering that uses an input-specific linear shift. This shift is computed using
contrastive input-specific prompting. However, the input-specific prompts
required for this approach are not known at test time. Therefore, we propose to
train a small auxiliary module to predict the input-specific steering vector.
Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces
hallucinations and enforces safety in MLLMs, outperforming other static
baselines.

</details>


### [340] [Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG](https://arxiv.org/abs/2508.12833)
*Kichang Lee,Songkuk Kim,JaeYeon Park,JeongGil Ko*

Main category: cs.LG

TL;DR: 这篇论文通过实验研究探讨了设备机器学习中的存储问题，发现数据量与质量的权衡关系，提出根据样本效应性进行适应性压缩的优化策略。


<details>
  <summary>Details</summary>
Motivation: 解决设备机器学习在持续数据收集场景中遇到的存储空间限制问题，探索数据压缩与学习性能之间的权衡关系。

Method: 采用实证研究方法，对比分析了简单数据删除和统一压缩策略的效果，并研究了不同数据样本对压缩的效应性差异。

Result: 证明了简单的均匀数据处理策略是次优的，同时发现不同数据样本对压缩的效应性存在显著差异，支持根据样本特性进行适应性压缩的可行性。

Conclusion: 研究系统性地描述了存储敏感学习这一未充分探索的挑战，为开发新一代存储敏感学习系统奠定了基础，提供了重要的见解。

Abstract: On-device machine learning is often constrained by limited storage,
particularly in continuous data collection scenarios. This paper presents an
empirical study on storage-aware learning, focusing on the trade-off between
data quantity and quality via compression. We demonstrate that naive
strategies, such as uniform data dropping or one-size-fits-all compression, are
suboptimal. Our findings further reveal that data samples exhibit varying
sensitivities to compression, supporting the feasibility of a sample-wise
adaptive compression strategy. These insights provide a foundation for
developing a new class of storage-aware learning systems. The primary
contribution of this work is the systematic characterization of this
under-explored challenge, offering valuable insights that advance the
understanding of storage-aware learning.

</details>


### [341] [Learning In-context $\pmb{n}$-grams with Transformers: Sub-$\pmb{n}$-grams Are Near-stationary Points](https://arxiv.org/abs/2508.12837)
*Aditya Varre,Gizem Yüce,Nicolas Flammarion*

Main category: cs.LG

TL;DR: 这篇论文研究了变换器模型在上下文下一个词预测任务中的损失地形牲层平台和阶段性进展现象。通过构造k-gram估计器的参数配置，证明了子n-gram是人口交叉碘损失的近稳定点，为阶段性学习动力学提供理论解释。


<details>
  <summary>Details</summary>
Motivation: 由于实证观察到训练过程中存在持续的层平台和阶段性进展现象，需要研究变换器模型在上下文下一个词预测任务中的损失地形牲层平台的特性。

Method: 重点研究在交叉碘损失下学习上下文n-gram语言模型。建立了参数配置为稳定点的充分条件，构造了简化变换器模型的k-gram估计器参数配置集合。

Result: 在无限序列长度和参数范数极限下，这些解的人口损失梯度消失，证明子n-gram是人口交叉碘损失的近稳定点。

Conclusion: 这些发现为广泛观察到的阶段性学习动力学和出现相变过渡现象提供了理论解释，数值实验进一步支持了这些见解。

Abstract: Motivated by empirical observations of prolonged plateaus and stage-wise
progression during training, we investigate the loss landscape of transformer
models trained on in-context next-token prediction tasks. In particular, we
focus on learning in-context $n$-gram language models under cross-entropy loss,
and establish a sufficient condition for parameter configurations to be
stationary points. We then construct a set of parameter configurations for a
simplified transformer model that represent $k$-gram estimators (for $k \leq
n$), and show that the gradient of the population loss at these solutions
vanishes in the limit of infinite sequence length and parameter norm. This
reveals a key property of the loss landscape: {sub-$n$-grams are
near-stationary points of the population cross-entropy loss}, offering
theoretical insight into widely observed phenomena such as stage-wise learning
dynamics and emergent phase transitions. These insights are further supported
by numerical experiments that illustrate the learning dynamics of $n$-grams,
characterized by discrete transitions between near-stationary solutions.

</details>


### [342] [HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms](https://arxiv.org/abs/2508.12839)
*Tiancheng Zhang,Cheng Zhang,Shuren Liu,Xiaofei Wang,Shaoyuan Huang,Wenyu Wang*

Main category: cs.LG

TL;DR: 一种给合数值和图像表示的混合框架HRS，通过调度感知损失函数提高负载预测准确性，在流媒体服务环境中显著降低SLA违约率和增加利润


<details>
  <summary>Details</summary>
Motivation: 解决流媒体服务负载的时变性和爆发性带来的QoS挑战，充分利用预测-调度架构提升服务质量和盈利能力

Method: 提出HRS混合表示框架，给合数值和图像表示来抓取极端负载动态；设计调度感知损失函数SAL，考虑预测误差的不对称影响

Result: 在4个真实数据集上超越10个基线方法，达到最佳性能，SLA违约率降低63.1%，总利润损失减少32.3%

Conclusion: HRS框架通过给合多模态表示和调度感知损失，有效解决了负载预测中的供应不足或过度供应问题，显著提升了集群平台的QoS和经济效益

Abstract: With the rapid proliferation of streaming services, network load exhibits
highly time-varying and bursty behavior, posing serious challenges for
maintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms
(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS
and profitability, accurate load forecasting remains challenging under traffic
surges. Existing methods either minimize mean absolute error, resulting in
underprovisioning and potential Service Level Agreement (SLA) violations during
peak periods, or adopt conservative overprovisioning strategies, which mitigate
SLA risks at the expense of increased resource expenditure. To address this
dilemma, we propose HRS, a hybrid representation framework with scheduling
awareness that integrates numerical and image-based representations to better
capture extreme load dynamics. We further introduce a Scheduling-Aware Loss
(SAL) that captures the asymmetric impact of prediction errors, guiding
predictions that better support scheduling decisions. Extensive experiments on
four real-world datasets demonstrate that HRS consistently outperforms ten
baselines and achieves state-of-the-art performance, reducing SLA violation
rates by 63.1% and total profit loss by 32.3%.

</details>


### [343] [One-Class Intrusion Detection with Dynamic Graphs](https://arxiv.org/abs/2508.12885)
*Aleksei Liuliakov,Alexander Schulz,Luca Hermes,Barbara Hammer*

Main category: cs.LG

TL;DR: 基于动态图模型和深度异常检测的TGN-SVDD入侵检测方法，在现实入侵检测数据上表现优于多个基线方法


<details>
  <summary>Details</summary>
Motivation: 随着全球数字化发展，网络安全意义重大。机器学习入侵检测面临检测新题和未见网络事件的挑战，以及网络通信的时间序列特性和图结构特征

Method: 提出TGN-SVDD方法，结合现代动态图模型和深度异常检测技术

Result: 在现实入侵检测数据上表现超过多个基线方法，并建议了更具挑战性的数据变体

Conclusion: TGN-SVDD作为一种新的入侵检测方法，能够有效处理网络数据的时间序列和图结构特征，提高对新兴入侵的检测能力

Abstract: With the growing digitalization all over the globe, the relevance of network
security becomes increasingly important. Machine learning-based intrusion
detection constitutes a promising approach for improving security, but it bears
several challenges. These include the requirement to detect novel and unseen
network events, as well as specific data properties, such as events over time
together with the inherent graph structure of network communication. In this
work, we propose a novel intrusion detection method, TGN-SVDD, which builds
upon modern dynamic graph modelling and deep anomaly detection. We demonstrate
its superiority over several baselines for realistic intrusion detection data
and suggest a more challenging variant of the latter.

</details>


### [344] [TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML](https://arxiv.org/abs/2508.12905)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: TCUQ是一种面向TinyML流式应用的单次前向、无标签不确定性监测方法，通过时间一致性信号和流式共形校准实现资源高效的设备端监测。


<details>
  <summary>Details</summary>
Motivation: 解决TinyML设备上传统不确定性监测方法（如早期退出和深度集成）资源消耗大、延迟高的问题，提供轻量级的流式不确定性监测方案。

Method: 使用短时域时间一致性，通过后验和特征的轻量级信号生成校准风险分数，采用O(W)环形缓冲区和O(1)每步更新，结合流式共形层实现预算化的接受/弃权决策。

Result: 在微控制器上占用空间减少50-60%，延迟降低30-45%；在分布内损坏流中，准确率下降检测提升3-7 AUPRC点，故障检测达到0.92 AUROC。

Conclusion: 时间一致性结合流式共形校准为TinyML设备端监测提供了实用且资源高效的基础方案。

Abstract: We introduce TCUQ, a single pass, label free uncertainty monitor for
streaming TinyML that converts short horizon temporal consistency captured via
lightweight signals on posteriors and features into a calibrated risk score
with an O(W ) ring buffer and O(1) per step updates. A streaming conformal
layer turns this score into a budgeted accept/abstain rule, yielding calibrated
behavior without online labels or extra forward passes. On microcontrollers,
TCUQ fits comfortably on kilobyte scale devices and reduces footprint and
latency versus early exit and deep ensembles (typically about 50 to 60% smaller
and about 30 to 45% faster), while methods of similar accuracy often run out of
memory. Under corrupted in distribution streams, TCUQ improves accuracy drop
detection by 3 to 7 AUPRC points and reaches up to 0.86 AUPRC at high
severities; for failure detection it attains up to 0.92 AUROC. These results
show that temporal consistency, coupled with streaming conformal calibration,
provides a practical and resource efficient foundation for on device monitoring
in TinyML.

</details>


### [345] [SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy](https://arxiv.org/abs/2508.12906)
*Boran Zhao,Haiming Zhai,Zihang Yuan,Hetian Liu,Tian Xia,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: SparseMap是一个基于进化策略的稀疏张量加速器优化框架，通过联合优化映射策略和稀疏策略，在巨大的设计空间（O(10^41)）中高效搜索最优解


<details>
  <summary>Details</summary>
Motivation: 现有稀疏张量加速器设计大多局限于特定场景，且手动调整设计参数耗时费力。现有工作要么只关注映射策略，要么只关注稀疏策略，缺乏综合考虑，导致设计次优

Method: 提出SparseMap框架，构建包含映射和稀疏策略的综合设计空间，改进遗传编码和进化算子，使进化策略能够高效探索巨大而多样的设计空间

Result: 与先前工作和经典优化方法相比，SparseMap能够持续找到更优的解决方案

Conclusion: SparseMap通过联合优化映射和稀疏策略，有效解决了稀疏张量加速器自动化设计中的组合爆炸问题，为稀疏张量代数加速器的自动化优化提供了有效解决方案

Abstract: The growing demand for sparse tensor algebra (SpTA) in machine learning and
big data has driven the development of various sparse tensor accelerators.
However, most existing manually designed accelerators are limited to specific
scenarios, and it's time-consuming and challenging to adjust a large number of
design factors when scenarios change. Therefore, automating the design of SpTA
accelerators is crucial. Nevertheless, previous works focus solely on either
mapping (i.e., tiling communication and computation in space and time) or
sparse strategy (i.e., bypassing zero elements for efficiency), leading to
suboptimal designs due to the lack of comprehensive consideration of both. A
unified framework that jointly optimizes both is urgently needed. However,
integrating mapping and sparse strategies leads to a combinatorial explosion in
the design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \times
64} \times Q_{64 \times 48} = Z_{32 \times 48}$). This vast search space
renders most conventional optimization methods (e.g., particle swarm
optimization, reinforcement learning and Monte Carlo tree search) inefficient.
To address this challenge, we propose an evolution strategy-based sparse tensor
accelerator optimization framework, called SparseMap. SparseMap constructing a
more comprehensive design space with the consideration of both mapping and
sparse strategy. We introduce a series of enhancements to genetic encoding and
evolutionary operators, enabling SparseMap to efficiently explore the vast and
diverse design space. We quantitatively compare SparseMap with prior works and
classical optimization methods, demonstrating that SparseMap consistently finds
superior solutions.

</details>


### [346] [SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML](https://arxiv.org/abs/2508.12907)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: SNAP-UQ是一种面向TinyML的单次前向、无需标签的不确定性量化方法，通过深度激活预测来估计风险，在保持高精度的同时显著减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性量化方法在TinyML设备上存在资源消耗大、需要多次前向传播或额外退出机制的问题，无法满足MCU部署的严格资源限制。

Method: 使用int8量化的小型预测头来预测下一层的统计特征，通过轻量级单调映射器将预测的意外程度转换为可操作的分数，无需时间缓冲区、辅助退出或重复前向传播。

Result: 在视觉和音频任务中，相比早期退出和深度集成方法，SNAP-UQ减少了40-60%的存储空间和25-35%的延迟，在损坏数据流中提高了AUPRC分数，并保持了约0.9的AUROC故障检测性能。

Conclusion: 基于层间动态的不确定性量化提供了一个实用且资源高效的TinyML设备监控基础，在单次前向传播中实现了有效的风险估计。

Abstract: We introduce \textbf{SNAP-UQ}, a single-pass, label-free uncertainty method
for TinyML that estimates risk from \emph{depth-wise next-activation
prediction}: tiny int8 heads forecast the statistics of the next layer from a
compressed view of the previous one, and a lightweight monotone mapper turns
the resulting surprisal into an actionable score. The design requires no
temporal buffers, auxiliary exits, or repeated forward passes, and adds only a
few tens of kilobytes to MCU deployments. Across vision and audio backbones,
SNAP-UQ consistently reduces flash and latency relative to early-exit and deep
ensembles (typically $\sim$40--60\% smaller and $\sim$25--35\% faster), with
competing methods of similar accuracy often exceeding memory limits. In
corrupted streams it improves accuracy-drop detection by several AUPRC points
and maintains strong failure detection (AUROC $\approx$0.9) in a single pass.
Grounding uncertainty in layer-to-layer dynamics yields a practical,
resource-efficient basis for on-device monitoring in TinyML.

</details>


### [347] [Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning](https://arxiv.org/abs/2508.12978)
*Yue Xia,Tayyebeh Jahani-Nezhad,Rawad Bitar*

Main category: cs.LG

TL;DR: Fed-DPRoC是一个新颖的联邦学习框架，同时确保差分隐私、拜占庭鲁棒性和通信效率，通过RobAJoL方法结合JL变换压缩和鲁棒聚合


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法难以同时保证差分隐私、拜占庭鲁棒性和通信效率，需要一种综合解决方案

Method: 提出Robust-compatible压缩概念，结合Johnson-Lindenstrauss变换进行压缩和鲁棒平均进行聚合，理论证明JL变换与鲁棒平均的兼容性

Result: 在CIFAR-10和Fashion MNIST数据集上的实验验证了理论主张，RobAJoL在不同拜占庭攻击下在鲁棒性和效用方面优于现有方法

Conclusion: Fed-DPRoC框架成功实现了差分隐私、拜占庭鲁棒性和通信效率的三重目标，RobAJoL方法具有理论和实践优势

Abstract: We propose Fed-DPRoC, a novel federated learning framework that
simultaneously ensures differential privacy (DP), Byzantine robustness, and
communication efficiency. We introduce the concept of robust-compatible
compression, which enables users to compress DP-protected updates while
maintaining the robustness of the aggregation rule. We instantiate our
framework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for
compression with robust averaging for robust aggregation. We theoretically
prove the compatibility of JL transform with robust averaging and show that
RobAJoL preserves robustness guarantees, ensures DP, and reduces communication
cost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims
and demonstrate that RobAJoL outperforms existing methods in terms of
robustness and utility under different Byzantine attacks.

</details>


### [348] [SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression](https://arxiv.org/abs/2508.12984)
*Zehang Lin,Zheng Lin,Miao Yang,Jianhao Huang,Yuxin Zhang,Zihan Fang,Xia Du,Zhe Chen,Shunzhi Zhu,Wei Ni*

Main category: cs.LG

TL;DR: SL-ACC是一个通信高效的拆分学习框架，通过自适应通道重要性识别和通道分组压缩来减少数据传输量，同时保持训练精度。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络复杂度的增加，拆分学习在资源受限设备上的部署面临挑战，特别是当参与设备增多时，过多的粉碎数据传输成为主要瓶颈，拖慢模型训练速度。

Method: 提出SL-ACC框架，包含两个关键组件：1）自适应通道重要性识别（ACII）使用香农熵识别每个通道对模型训练的贡献；2）通道分组压缩（CGC）基于熵值对通道进行分组，并执行分组自适应压缩以减少传输量。

Result: 在多个数据集上的广泛实验验证，SL-ACC框架在达到目标精度所需的时间上显著优于最先进的基准方法。

Conclusion: SL-ACC框架有效解决了拆分学习中的通信瓶颈问题，通过智能的通道重要性识别和压缩策略，在保持精度的同时大幅减少了训练时间。

Abstract: The increasing complexity of neural networks poses a significant barrier to
the deployment of distributed machine learning (ML) on resource-constrained
devices, such as federated learning (FL). Split learning (SL) offers a
promising solution by offloading the primary computing load from edge devices
to a server via model partitioning. However, as the number of participating
devices increases, the transmission of excessive smashed data (i.e.,
activations and gradients) becomes a major bottleneck for SL, slowing down the
model training. To tackle this challenge, we propose a communication-efficient
SL framework, named SL-ACC, which comprises two key components: adaptive
channel importance identification (ACII) and channel grouping compression
(CGC). ACII first identifies the contribution of each channel in the smashed
data to model training using Shannon entropy. Following this, CGC groups the
channels based on their entropy and performs group-wise adaptive compression to
shrink the transmission volume without compromising training accuracy.
Extensive experiments across various datasets validate that our proposed SL-ACC
framework takes considerably less time to achieve a target accuracy than
state-of-the-art benchmarks.

</details>


### [349] [Predicting the Performance of Graph Convolutional Networks with Spectral Properties of the Graph Laplacian](https://arxiv.org/abs/2508.12993)
*Shalima Binta Manir,Tim Oates*

Main category: cs.LG

TL;DR: 图卷积网络(GCN)性能与图的代数连通性(Fiedler值)密切相关，Fiedler值相似的图具有类似的结构特性，可以预测GCN在不同图上的表现效果。


<details>
  <summary>Details</summary>
Motivation: GCN文献中观察到堆叠GCN层可能不会带来更好的性能，需要找到能够预测GCN性能的图结构指标。

Method: 通过理论和实证研究，在合成图和真实图数据(Cora、CiteSeer、Polblogs)上实验，探索Fiedler值与GCN性能的关系，并提出多种聚合连通分量Fiedler值的方法。

Result: 发现图的代数连通性(Fiedler值)是GCN性能的良好预测指标，Fiedler值相似的图可以使用相同的滤波器和超参数获得类似结果，迁移学习在Fiedler值相似的图之间更有效。

Conclusion: Fiedler值作为图的结构特性指标，能够有效预测GCN在图数据上的性能表现，为GCN的超参数选择和迁移学习提供了理论依据。

Abstract: A common observation in the Graph Convolutional Network (GCN) literature is
that stacking GCN layers may or may not result in better performance on tasks
like node classification and edge prediction. We have found empirically that a
graph's algebraic connectivity, which is known as the Fiedler value, is a good
predictor of GCN performance. Intuitively, graphs with similar Fiedler values
have analogous structural properties, suggesting that the same filters and
hyperparameters may yield similar results when used with GCNs, and that
transfer learning may be more effective between graphs with similar algebraic
connectivity. We explore this theoretically and empirically with experiments on
synthetic and real graph data, including the Cora, CiteSeer and Polblogs
datasets. We explore multiple ways of aggregating the Fiedler value for
connected components in the graphs to arrive at a value for the entire graph,
and show that it can be used to predict GCN performance. We also present
theoretical arguments as to why the Fiedler value is a good predictor.

</details>


### [350] [Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair](https://arxiv.org/abs/2508.12996)
*Stavros C. Kassinos*

Main category: cs.LG

TL;DR: Kourkoutas-Beta是一种改进的Adam优化器，通过动态调整beta2参数来应对物理神经网络中的梯度尖峰问题，在多个测试场景中显著提升了训练稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 在物理驱动的神经网络（如PDE代理模型和PINNs）中，变化的边界条件和初始条件会导致不稳定的损失和梯度尖峰，传统Adam优化器的固定beta2参数无法有效处理这种情况。

Method: 提出层级的动态beta2调整机制，基于当前梯度范数与历史EMA的比值（sunspike ratio）来动态降低或保持beta2值，包含泄漏AMSGrad、信任区域裁剪、自适应微小项和多种偏置校正模式。

Result: 在四个测试场景中（Transformer PDE代理、3D PINN、MLX合成任务、字符级Transformer），Kourkoutas-Beta相比固定beta2的Adam显著提升了稳定性和最终损失性能，在small-enwik8上比特每字符降低了38-58%。

Conclusion: 该方法保持了Adam的收敛保证，在梯度尖峰情况下提高了鲁棒性，运行时开销与Adam相当，是一种即插即用的改进优化器。

Abstract: Transformer neural networks are increasingly used for physics-based problems.
In data-driven PDE surrogates, training samples from varying boundary and
initial conditions can cause erratic losses and spiky gradients; in
physics-informed neural networks (PINNs), stiff composite losses amplify this
effect.
  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed
second-moment discount beta2 is replaced by a layer-wise dynamic value driven
by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an
exponential moving average (EMA) of past norms, squashed to the interval [0,1).
Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.
Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio),
adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',
``exact'). With all features off and bias_correction=``none'', the method is
exactly Adam.
  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D
PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with
jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB
of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss
versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about
38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller
variance. The method remains drop-in, with runtime overhead comparable to Adam
in testbeds A-C and within single-digit percent in testbed D. It preserves
Adam-style convergence guarantees while improving robustness under spiky
gradients.

</details>


### [351] [Fairness-Aware Multi-view Evidential Learning with Adaptive Prior](https://arxiv.org/abs/2508.12997)
*Haishun Chen,Cai Xu,Jinlong Yu,Yilin Zhang,Ziyu Guan,Wei Zhao*

Main category: cs.LG

TL;DR: 提出FAML方法解决多视图证据学习中的证据偏见问题，通过自适应先验、公平性约束和意见对齐机制，实现更平衡的证据分配和更可靠的不确定性估计


<details>
  <summary>Details</summary>
Motivation: 现有多视图证据学习方法假设视图特定证据学习是可靠的，但实践中证据学习过程存在偏见，样本倾向于为数据丰富的类别分配更多证据，导致不确定性估计不可靠

Method: FAML方法包含三个核心组件：1）基于训练轨迹的自适应先验作为正则化策略；2）基于类间证据方差的公平性约束；3）多视图融合阶段的意见对齐机制

Result: 在五个真实世界多视图数据集上的实验表明，FAML实现了更平衡的证据分配，在预测性能和不确定性估计可靠性方面均优于最先进方法

Conclusion: FAML有效解决了多视图证据学习中的偏见问题，为可信赖的多视图学习提供了新思路

Abstract: Multi-view evidential learning aims to integrate information from multiple
views to improve prediction performance and provide trustworthy uncertainty
esitimation. Most previous methods assume that view-specific evidence learning
is naturally reliable. However, in practice, the evidence learning process
tends to be biased. Through empirical analysis on real-world data, we reveal
that samples tend to be assigned more evidence to support data-rich classes,
thereby leading to unreliable uncertainty estimation in predictions. This
motivates us to delve into a new Biased Evidential Multi-view Learning (BEML)
problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning
(FAML). FAML first introduces an adaptive prior based on training trajectory,
which acts as a regularization strategy to flexibly calibrate the biased
evidence learning process. Furthermore, we explicitly incorporate a fairness
constraint based on class-wise evidence variance to promote balanced evidence
allocation. In the multi-view fusion stage, we propose an opinion alignment
mechanism to mitigate view-specific bias across views, thereby encouraging the
integration of consistent and mutually supportive evidence. Extensive
experiments on five real-world multi-view datasets demonstrate that FAML
achieves more balanced evidence allocation and improves both prediction
performance and the reliability of uncertainty estimation compared to
state-of-the-art methods.

</details>


### [352] [Monte Carlo Functional Regularisation for Continual Learning](https://arxiv.org/abs/2508.13006)
*Pengcheng Hao,Menghao Waiyan William Zhu,Ercan Engin Kuruoglu*

Main category: cs.LG

TL;DR: 提出了一种基于蒙特卡洛采样的功能正则化持续学习框架MCFRCL，通过三种连续分布捕捉统计特征，使用Wasserstein和KL距离构建正则化函数，在MNIST和CIFAR数据集上表现出优异的预测精度和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有的功能正则化持续学习方法虽然优于权重空间正则化方法，但存在计算成本高和线性近似误差大的问题，需要开发更高效的解决方案。

Method: 使用蒙特卡洛采样近似模型预测分布，利用三种连续分布通过矩方法捕捉MC样本的统计特征，结合Wasserstein距离和KL距离构建正则化函数。

Result: 在MNIST和CIFAR数据集上的实验结果表明，MCFRCL在预测准确性和训练效率方面均优于多个基准方法。

Conclusion: MCFRCL框架通过蒙特卡洛采样和统计特征捕捉，有效解决了功能正则化持续学习方法的高计算成本和近似误差问题，为持续学习提供了高效的解决方案。

Abstract: Continual learning (CL) is crucial for the adaptation of neural network
models to new environments. Although outperforming weight-space regularisation
approaches, the functional regularisation-based CL methods suffer from high
computational costs and large linear approximation errors. In this work, we
present a new functional regularisation CL framework, called MCFRCL, which
approximates model prediction distributions by Monte Carlo (MC) sampling.
Moreover, three continuous distributions are leveraged to capture the
statistical characteristics of the MC samples via moment-based methods.
Additionally, both the Wasserstein distance and the Kullback-Leibler (KL)
distance are employed to construct the regularisation function. The proposed
MCFRCL is evaluated against multiple benchmark methods on the MNIST and CIFAR
datasets, with simulation results highlighting its effectiveness in both
prediction accuracy and training efficiency.

</details>


### [353] [Design and Analysis of Robust Adaptive Filtering with the Hyperbolic Tangent Exponential Kernel M-Estimator Function for Active Noise Control](https://arxiv.org/abs/2508.13018)
*Iam Kim de S. Hermont,Andre R. Flores,Rodrigo C. de Lamare*

Main category: cs.LG

TL;DR: 提出了一种叫FXHEKM算法，用于主动噪声控制中的冲击性噪声消除，在α稳定噪声环境下表现优异于竞争算法


<details>
  <summary>Details</summary>
Motivation: 解决主动噪声控制中遇到冲击性噪声时的算法稳健性问题，提高在复杂噪声环境下的噪声消除效果

Method: 发展了过滤-x双曲正切指数广义核M估计函数(FXHEKM)稳健自适应算法，进行了统计分析和计算成本研究

Result: 数值实验结果显示，提出的FXHEKM算法在平均方差错(MSE)和平均噪声减少(ANR)性能指标上表现优异，能够高效消除添加的伪噪声信号

Conclusion: FXHEKM算法在冲击性噪声环境下具有强大的噪声消除能力，为主动噪声控制应用提供了有效的解决方案

Abstract: In this work, we propose a robust adaptive filtering approach for active
noise control applications in the presence of impulsive noise. In particular,
we develop the filtered-x hyperbolic tangent exponential generalized Kernel
M-estimate function (FXHEKM) robust adaptive algorithm. A statistical analysis
of the proposed FXHEKM algorithm is carried out along with a study of its
computational cost. {In order to evaluate the proposed FXHEKM algorithm, the
mean-square error (MSE) and the average noise reduction (ANR) performance
metrics have been adopted.} Numerical results show the efficiency of the
proposed FXHEKM algorithm to cancel the presence of the additive spurious
signals, such as \textbf{$\alpha$}-stable noises against competing algorithms.

</details>


### [354] [The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks](https://arxiv.org/abs/2508.13030)
*Bipin Chhetri,Akbar Siami Namin*

Main category: cs.LG

TL;DR: 本文研究如何利用NLP和深度学习技术（BERT和HAN）来自动分析网络攻击的影响后果，并在多标签分类任务中较传统模型取得更优的性能。


<details>
  <summary>Details</summary>
Motivation: 网络攻击日益复杂化，安全防御成本高昂，威胁建模能够帮助安全专业人员及时采取行动和分配资源。现有的手动分析方法已无法满足对复杂攻击描述进行自动化影响预测的需求。

Method: 利用MITRE CWE数据库的文本描述，将攻击影响分类为五个主要类别：可用性、访问控制、保密性、完整性和其他。采用BERT和层次注意网络（HAN）进行多标签分类，并与传统的CNN和LSTM模型进行性能对比。

Result: 实验结果显示BERT模型在多标签分类任务中达到了0.972的总体准确率，显著超过传统深度学习模型。HAN在某些特定安全标签上表现更优，但BERT在精准率和召回率方面均保持更优异的性能。

Conclusion: BERT模型在网络攻击影响预测任务中表现最优，适合用于实际应用。NLP技术能够有效地自动分析攻击描述并预测其影响后果，为威胁建模提供了重要的技术支持。

Abstract: Cyberattacks are increasing, and securing against such threats is costing
industries billions of dollars annually. Threat Modeling, that is,
comprehending the consequences of these attacks, can provide critical support
to cybersecurity professionals, enabling them to take timely action and
allocate resources that could be used elsewhere. Cybersecurity is heavily
dependent on threat modeling, as it assists security experts in assessing and
mitigating risks related to identifying vulnerabilities and threats. Recently,
there has been a pressing need for automated methods to assess attack
descriptions and forecast the future consequences of the increasing complexity
of cyberattacks. This study examines how Natural Language Processing (NLP) and
deep learning can be applied to analyze the potential impact of cyberattacks by
leveraging textual descriptions from the MITRE Common Weakness Enumeration
(CWE) database. We emphasize classifying attack consequences into five
principal categories: Availability, Access Control, Confidentiality, Integrity,
and Other. This paper investigates the use of Bidirectional Encoder
Representations from Transformers (BERT) in combination with Hierarchical
Attention Networks (HANs) for Multi-label classification, evaluating their
performance in comparison with conventional CNN and LSTM-based models.
Experimental findings show that BERT achieves an overall accuracy of $0.972$,
far higher than conventional deep learning models in multi-label
classification. HAN outperforms baseline forms of CNN and LSTM-based models on
specific cybersecurity labels. However, BERT consistently achieves better
precision and recall, making it more suitable for predicting the consequences
of a cyberattack.

</details>


### [355] [Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data](https://arxiv.org/abs/2508.13040)
*Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber*

Main category: cs.LG

TL;DR: 这篇论文提出了一种在无法获得完整数据的情况下估计AI系统公平性的方法，通过利用分开的内部和外部数据来计算可行的联合分布和公平性指标范围。


<details>
  <summary>Details</summary>
Motivation: 实际业界中由于法律和隐私问题，难以收集完整的人口统计属性数据进行公平性测试，而相关数据通常分散在不同来源中。

Method: 利用可用的分开数据估计一组可行的联合分布，然后计算可能的公平性指标范围。

Result: 通过模拟和实际实验，证明该方法能够得到有意义的公平性指标界限，并获得真实指标的可靠估计。

Conclusion: 这种方法可以作为实际中数据访问受限时进行公平性测试的实用有效解决方案。

Abstract: Ensuring fairness in AI systems is critical, especially in high-stakes
domains such as lending, hiring, and healthcare. This urgency is reflected in
emerging global regulations that mandate fairness assessments and independent
bias audits. However, procuring the necessary complete data for fairness
testing remains a significant challenge. In industry settings, legal and
privacy concerns restrict the collection of demographic data required to assess
group disparities, and auditors face practical and cultural challenges in
gaining access to data. In practice, data relevant for fairness testing is
often split across separate sources: internal datasets held by institutions
with predictive attributes, and external public datasets such as census data
containing protected attributes, each providing only partial, marginal
information. Our work seeks to leverage such available separate data to
estimate model fairness when complete data is inaccessible. We propose
utilising the available separate data to estimate a set of feasible joint
distributions and then compute the set plausible fairness metrics. Through
simulation and real experiments, we demonstrate that we can derive meaningful
bounds on fairness metrics and obtain reliable estimates of the true metric.
Our results demonstrate that this approach can serve as a practical and
effective solution for fairness testing in real-world settings where access to
complete data is restricted.

</details>


### [356] [Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models](https://arxiv.org/abs/2508.13057)
*Adolfo González,Víctor Parada*

Main category: cs.LG

TL;DR: 这篇论文比较了FMAE和HEF两种评估函数在多元时间序列预测中的表现，HEF在全局指标上更优，适合战略规划，而FMAE在局部指标和运行效率方面更好，适合短期场景。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列建模面临数据复杂性、不确定性和频繁制度转移的挑战，传统评估指标容易导致偏差和限制模型的普适性。

Method: 设计了FMAE（专注最小化绝对误差）和HEF（重视全局指标并惩罚大偏差）两种评估函数，在不同数据分割比例（91:9、80:20、70:30）下使用三种优化器（网格搜索、PSO、Optuna）进行实验，评估拟合度、相对准确性、稳健性和计算效率。

Result: HEF在全局指标（R2、相对准确性、RMSE、RMSSE）上一贵表现更优，提升了模型稳健性和解释力；FMAE在局部指标（MAE、MASE）和执行时间方面更优，适合短期场景。

Conclusion: 研究展现了方法论上的权衡：HEF适合战略规划，FMAE适合运营效率。提出了一个可复现框架用于动态环境中的预测模型优化。

Abstract: Demand forecasting is essential for strategic planning in competitive
environments, enabling resource optimization and improved responsiveness to
market dynamics. However, multivariate time series modeling faces challenges
due to data complexity, uncertainty, and frequent regime shifts. Traditional
evaluation metrics can introduce biases and limit generalization. This work
compares two custom evaluation functions: FMAE (Focused Mean Absolute Error),
focused on minimizing absolute errors, and HEF (Hierarchical Evaluation
Function), designed to weight global metrics and penalize large deviations.
Experiments were conducted under different data splits (91:9, 80:20, 70:30)
using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative
accuracy, robustness, and computational efficiency. Results show that HEF
consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,
RMSSE), enhancing model robustness and explanatory power. These findings were
confirmed via visualizations and statistical tests. Conversely, FMAE offers
advantages in local metrics (MAE, MASE) and execution time, making it suitable
for short-term scenarios. The study highlights a methodological trade-off: HEF
is ideal for strategic planning, while FMAE is better suited for operational
efficiency. A replicable framework is proposed for optimizing predictive models
in dynamic environments.

</details>


### [357] [Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates](https://arxiv.org/abs/2508.13088)
*Xiaohan Wang,Zhimin Li,Joshua A. Levine,Matthew Berger*

Main category: cs.LG

TL;DR: 本文提出了一种通过神经朴代模型来可视化反向问题中可能输入参数分布的方法，解决了传统方法只能找到少量匹配参数的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的神经朴代模型在处理反向问题时主要关注找到少量匹配参数，而忽视了整个可能参数分布的全局图景。本文的动机是建模并可视化产生指定输出特征的可能输入参数分布。

Method: 通过密度估计模型来处理朴代模型的近似误差，只在参数配置接近训练参数时报告高密度。将密度估计作为先验信忽，结合特征的可能性，形成了一种高效的采样可行参数配置的方法。

Result: 在三个模拟数据集上进行了特征驱动的参数分析，开发了可视化界面来展示方法的可用性。

Conclusion: 该方法能够有效地建模和可视化产生指定输出特征的可能输入参数分布，解决了高维参数空间中寻找参数的成本问题，为科学模拟提供了更全面的反向问题解决方案。

Abstract: Recently, neural surrogate models have emerged as a compelling alternative to
traditional simulation workflows. This is accomplished by modeling the
underlying function of scientific simulations, removing the need to run
expensive simulations. Beyond just mapping from input parameter to output,
surrogates have also been shown useful for inverse problems: output to input
parameters. Inverse problems can be understood as search, where we aim to find
parameters whose surrogate outputs contain a specified feature. Yet finding
these parameters can be costly, especially for high-dimensional parameter
spaces. Thus, existing surrogate-based solutions primarily focus on finding a
small set of matching parameters, in the process overlooking the broader
picture of plausible parameters. Our work aims to model and visualize the
distribution of possible input parameters that produce a given output feature.
To achieve this goal, we aim to address two challenges: (1) the approximation
error inherent in the surrogate model and (2) forming the parameter
distribution in an interactive manner. We model error via density estimation,
reporting high density only if a given parameter configuration is close to
training parameters, measured both over the input and output space. Our density
estimate is used to form a prior belief on parameters, and when combined with a
likelihood on features, gives us an efficient way to sample plausible parameter
configurations that generate a target output feature. We demonstrate the
usability of our solution through a visualization interface by performing
feature-driven parameter analysis over the input parameter space of three
simulation datasets. Source code is available at
https://github.com/matthewberger/seeing-the-many

</details>


### [358] [Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network](https://arxiv.org/abs/2508.13099)
*Mingyu Kim,Daniel Stilwell,Jorge Jimenez*

Main category: cs.LG

TL;DR: 提出基于海底声学传感器网络和LGCP的海上空间异常检测框架，通过二阶概率近似和动态传感器部署提高异常分类和检测性能


<details>
  <summary>Details</summary>
Motivation: 传统方法仅使用均值信息进行异常检测，精度有限。需要开发能够同时利用均值和方差信息的更精确异常分类方法，并配合动态传感器部署策略来提高海上环境中的异常检测效果

Method: 使用对数高斯Cox过程(LGCP)建模目标到达，将事件分为正常和异常过程混合。提出二阶概率近似方法，同时考虑正常强度函数的均值和方差。结合实时近最优传感器部署策略，根据异常强度动态调整传感器位置

Result: 在弗吉尼亚州诺福克附近的真实船舶交通数据上验证，数值结果表明该方法在分类性能和通过传感器部署的异常检测方面均表现出有效性。分析证明使用Jensen不等式获得了更紧的概率边界

Conclusion: 提出的框架通过二阶概率近似和动态传感器部署，显著提高了海上空间异常的分类准确性和检测能力，为海事环境监控提供了有效的解决方案

Abstract: This paper presents a framework for classifying and detecting spatial
commission outliers in maritime environments using seabed acoustic sensor
networks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as
a mixture of normal and outlier processes, we estimate the probability that a
newly observed event is an outlier. We propose a second-order approximation of
this probability that incorporates both the mean and variance of the normal
intensity function, providing improved classification accuracy compared to
mean-only approaches. We analytically show that our method yields a tighter
bound to the true probability using Jensen's inequality. To enhance detection,
we integrate a real-time, near-optimal sensor placement strategy that
dynamically adjusts sensor locations based on the evolving outlier intensity.
The proposed framework is validated using real ship traffic data near Norfolk,
Virginia, where numerical results demonstrate the effectiveness of our approach
in improving both classification performance and outlier detection through
sensor deployment.

</details>


### [359] [A Perfectly Truthful Calibration Measure](https://arxiv.org/abs/2508.13100)
*Jason Hartline,Lunjia Hu,Yifan Wu*

Main category: cs.LG

TL;DR: 本文设计了一个在批量设置中完全真实的校准度量ATB，它解决了现有校准度量在有限样本上激励预测器说谎的问题，同时保持了良好的计算效率和理论性质。


<details>
  <summary>Details</summary>
Motivation: 现有的校准度量在有限样本评估时都存在不真实的问题，即预测真实概率并不能最小化这些度量，反而会激励预测器为了在样本上显得更校准而说谎。虽然之前有研究构建了近似真实的校准度量，但在批量设置中还没有完全真实的校准度量。

Method: 设计了平均双箱校准误差（ATB）作为完全真实的校准度量，并提供了一个构建真实度量的一般方法，证明了ATB的真实性，并可以构造其他真实校准度量如分位数分箱l_2-ECE。

Result: ATB不仅完全真实，还具有合理性、完备性、连续性等优良性质，与现有的平滑校准误差和距离校准误差有二次关系。ATB计算简单高效，比现有方法实现更简单、运行时间更快。

Conclusion: ATB是第一个在批量设置中完全真实的校准度量，解决了校准度量理论上的重要问题，同时具有实际应用价值，为校准测试提供了更高效的解决方案。

Abstract: Calibration requires that predictions are conditionally unbiased and,
therefore, reliably interpretable as probabilities. Calibration measures
quantify how far a predictor is from perfect calibration. As introduced by
Haghtalab et al. (2024), a calibration measure is truthful if it is minimized
in expectation when a predictor outputs the ground-truth probabilities.
Although predicting the true probabilities guarantees perfect calibration, in
reality, when calibration is evaluated on a finite sample, predicting the truth
is not guaranteed to minimize any known calibration measure. All known
calibration measures incentivize predictors to lie in order to appear more
calibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et
al. (2024) and Qiao and Zhao (2025) to construct approximately truthful
calibration measures in the sequential prediction setting, but no perfectly
truthful calibration measure was known to exist even in the more basic batch
setting.
  We design a perfectly truthful calibration measure in the batch setting:
averaged two-bin calibration error (ATB). In addition to being truthful, ATB is
sound, complete, continuous, and quadratically related to two existing
calibration measures: the smooth calibration error (smCal) and the (lower)
distance to calibration (distCal). The simplicity in our definition of ATB
makes it efficient and straightforward to compute. ATB allows faster estimation
algorithms with significantly easier implementations than smCal and distCal,
achieving improved running time and simplicity for the calibration testing
problem studied by Hu et al. (2024). We also introduce a general recipe for
constructing truthful measures, which proves the truthfulness of ATB as a
special case and allows us to construct other truthful calibration measures
such as quantile-binned l_2-ECE.

</details>


### [360] [Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry](https://arxiv.org/abs/2508.13111)
*Michael Mayr,Georgios C. Chasparis*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的Causally-Guided Pairwise Transformer (CGPT)模型，解决工业系统中多维时间序列数据建模的核心争议：通道相关模型和通道独立模型的两难问题。CGPT通过对称建模范式和引入因果图作为归纳偏置，在保持模型灵活性和可扩展性的同时显著提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 工业系统中多维时间序列数据建模存在核心争议：通道相关(CD)模型能捕捉特定变量动态但缺乏稳健性和适应性，而通道独立(CI)模型虽有普适性但无法模拟关键的系统级相互作用。需要找到一种方法来解决这个两难问题。

Method: 提出Causally-Guided Pairwise Transformer (CGPT)架构，将已知因果图作为归纳偏置。核心是对称建模范式，将多维数据分解为对。模型使用通道无关的可学习层，所有参数维度都与变量数量独立。CGPT在对级利用CD信息流，在对间实现CI类的普适性。

Result: 在合成和真实工业数据集上进行验证，包括长期预测和单步预测任务。结果显示CGPT在预测准确性上显著超过了CI和CD基准模型，并且在保持问题维度无关性的同时，与端到端训练的CD模型展现竞争性能。

Conclusion: CGPT模型成功解决了工业系统中多维时间序列建模的核心争议。通过对称建模和因果图引导，它既能捕捉系统级相互作用，又具有良好的灵活性、可扩展性和任意变量适应能力，为工业预测回归任务提供了一种有效的解决方案。

Abstract: Foundational modelling of multi-dimensional time-series data in industrial
systems presents a central trade-off: channel-dependent (CD) models capture
specific cross-variable dynamics but lack robustness and adaptability as model
layers are commonly bound to the data dimensionality of the tackled use-case,
while channel-independent (CI) models offer generality at the cost of modelling
the explicit interactions crucial for system-level predictive regression tasks.
To resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a
novel architecture that integrates a known causal graph as an inductive bias.
The core of CGPT is built around a pairwise modeling paradigm, tackling the
CD/CI conflict by decomposing the multidimensional data into pairs. The model
uses channel-agnostic learnable layers where all parameter dimensions are
independent of the number of variables. CGPT enforces a CD information flow at
the pair-level and CI-like generalization across pairs. This approach
disentangles complex system dynamics and results in a highly flexible
architecture that ensures scalability and any-variate adaptability. We validate
CGPT on a suite of synthetic and real-world industrial datasets on long-term
and one-step forecasting tasks designed to simulate common industrial
complexities. Results demonstrate that CGPT significantly outperforms both CI
and CD baselines in predictive accuracy and shows competitive performance with
end-to-end trained CD models while remaining agnostic to the problem
dimensionality.

</details>


### [361] [Contrastive Representations for Temporal Reasoning](https://arxiv.org/abs/2508.13113)
*Alicja Ziarko,Michal Bortkiewicz,Michal Zawalski,Benjamin Eysenbach,Piotr Milos*

Main category: cs.LG

TL;DR: CRTR方法通过组合负采样方案消除时空对比学习中的伪特征，在Sokoban和魔方等复杂时序结构领域取得优异表现，首次仅通过学习表征高效解决任意魔方状态。


<details>
  <summary>Details</summary>
Motivation: 传统AI中感知和规划分离，本研究探索能否从同时捕获感知和时序结构的表征中自然涌现时序推理能力，解决标准时序对比学习依赖伪特征的问题。

Method: 提出组合时序推理表征(CRTR)，采用负采样方案可证明地移除伪特征，促进时序推理学习。

Result: 在Sokoban和魔方等复杂时序任务上表现优异，魔方任务中学习到的表征能泛化到所有初始状态，比BestFS搜索步数更少（但解路径更长），首次实现仅靠学习表征高效解决任意魔方状态。

Conclusion: CRTR成功证明了从统一表征中自然涌现时序推理的可能性，为感知与规划的统一学习提供了有效方法。

Abstract: In classical AI, perception relies on learning state-based representations,
while planning, which can be thought of as temporal reasoning over action
sequences, is typically achieved through search. We study whether such
reasoning can instead emerge from representations that capture both perceptual
and temporal structure. We show that standard temporal contrastive learning,
despite its popularity, often fails to capture temporal structure due to its
reliance on spurious features. To address this, we introduce Combinatorial
Representations for Temporal Reasoning (CRTR), a method that uses a negative
sampling scheme to provably remove these spurious features and facilitate
temporal reasoning. CRTR achieves strong results on domains with complex
temporal structure, such as Sokoban and Rubik's Cube. In particular, for the
Rubik's Cube, CRTR learns representations that generalize across all initial
states and allow it to solve the puzzle using fewer search steps than BestFS,
though with longer solutions. To our knowledge, this is the first method that
efficiently solves arbitrary Cube states using only learned representations,
without relying on an external search algorithm.

</details>


### [362] [Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]](https://arxiv.org/abs/2508.13135)
*Yueyang Liu,Lance Kennedy,Ruochen Kong,Joon-Seok Kim,Andreas Züfle*

Main category: cs.LG

TL;DR: 人类移动预测中的完整轨迹预测问题，通过综合实验分析不同模型、参数配置和训练策略，探索如何提升长期移动预测的效果


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在微观层面的短期轨迹预测，对宏观层面的生活常规模式关注不够，需要研究如何使用历史数据预测个体未来数天或数周的完整轨迹

Method: 进行综合实验分析，包括LSTM和Transformer架构、不同参数配置和训练策略。探索如何通过包含语义信息（如星期几）和用户特定历史信息来提升预测效析。使用用户语义聚类和层化采样来减少数据偏斜，小批量随机梯度优化来提高性能

Result: 显示明确包含语义信息和用户特定历史信息可以帮助模型更好理解个体生活模式并改善预测。用户采样可能引发数据偏斜导致预测准确性严重下降。小批量随机梯度优化在移动数据有限时能够显著提升模型性能

Conclusion: 通过系统性的模型选择、参数配置和训练策略分析，证明了在长期人类移动预测中采用适当的语义信息、数据采样策略和优化方法的重要性，为该领域的研究提供了实证基础和指导

Abstract: Individual-level human mobility prediction has emerged as a significant topic
of research with applications in infectious disease monitoring, child, and
elderly care. Existing studies predominantly focus on the microscopic aspects
of human trajectories: such as predicting short-term trajectories or the next
location visited, while offering limited attention to macro-level mobility
patterns and the corresponding life routines. In this paper, we focus on an
underexplored problem in human mobility prediction: determining the best
practices to train a machine learning model using historical data to forecast
an individuals complete trajectory over the next days and weeks. In this
experiment paper, we undertake a comprehensive experimental analysis of diverse
models, parameter configurations, and training strategies, accompanied by an
in-depth examination of the statistical distribution inherent in human mobility
patterns. Our empirical evaluations encompass both Long Short-Term Memory and
Transformer-based architectures, and further investigate how incorporating
individual life patterns can enhance the effectiveness of the prediction. We
show that explicitly including semantic information such as day-of-the-week and
user-specific historical information can help the model better understand
individual patterns of life and improve predictions. Moreover, since the
absence of explicit user information is often missing due to user privacy, we
show that the sampling of users may exacerbate data skewness and result in a
substantial loss in predictive accuracy. To mitigate data imbalance and
preserve diversity, we apply user semantic clustering with stratified sampling
to ensure that the sampled dataset remains representative. Our results further
show that small-batch stochastic gradient optimization improves model
performance, especially when human mobility training data is limited.

</details>


### [363] [MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models](https://arxiv.org/abs/2508.13148)
*Haoyu He,Katrin Renz,Yong Cao,Andreas Geiger*

Main category: cs.LG

TL;DR: 通过强化学习方法MDPO解决了碳散语言模型在训练和推理阶段的不一致性问题，大幅提升了生成性能和效率


<details>
  <summary>Details</summary>
Motivation: 碳散语言模型在训练时随机掩码而在推理时逐步掩码，这种不一致性导致次优性能，但之前研究忽视了这个问题

Method: 将学习有效去噪轨迹框架为序列决策问题，采用强化学习方法Masked Diffusion Policy Optimization (MDPO)，在同样的逐步精炼调度下训练模型

Result: MDPO在同样权重更新次数下比SOTA方法在MATH500上提升9.6%，在Countdown上提升54.2%，并以60倍更少的梯度更新达到SOTA性能

Conclusion: 该研究为解决碳散语言模型训练与推理不一致性问题开启了新方向，显示了强化学习在这一领域的巨大潜力

Abstract: Diffusion language models, as a promising alternative to traditional
autoregressive (AR) models, enable faster generation and richer conditioning on
bidirectional context. However, they suffer from a key discrepancy between
training and inference: during inference, MDLMs progressively reveal the
structure of the generated sequence by producing fewer and fewer masked tokens,
whereas this structure is ignored in training as tokens are masked at random.
Although this discrepancy between training and inference can lead to suboptimal
performance, it has been largely overlooked by previous works, leaving closing
this gap between the two stages an open problem. To address this, we frame the
problem of learning effective denoising trajectories as a sequential
decision-making problem and use the resulting framework to apply reinforcement
learning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to
exploit the Markov property diffusion possesses and explicitly train the model
under the same progressive refining schedule used at inference. MDPO matches
the performance of the previous state-of-the-art (SOTA) method with 60x fewer
gradient updates, while achieving average improvements of 9.6% on MATH500 and
54.2% on Countdown over SOTA when trained within the same number of weight
updates. Additionally, we improve the remasking strategy of MDLMs as a plug-in
inference replacement to overcome the limitation that the model cannot refine
tokens flexibly. This simple yet effective training-free strategy, what we
refer to as RCR, consistently improves performance and yields additional gains
when combined with MDPO. Our findings establish great potential for
investigating the discrepancy between pre-training and inference of MDLMs.
Code: https://github.com/autonomousvision/mdpo. Project Page:
https://cli212.github.io/MDPO/.

</details>
