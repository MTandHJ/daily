<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 261]
- [cs.CY](#cs.CY) [Total: 19]
- [cs.LG](#cs.LG) [Total: 142]
- [cs.AI](#cs.AI) [Total: 33]
- [cs.IR](#cs.IR) [Total: 17]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Multimodal AI for Body Fat Estimation: Computer Vision and Anthropometry with DEXA Benchmarks](https://arxiv.org/abs/2511.17576)
*Rayan Aldajani*

Main category: cs.CV

TL;DR: 本研究评估了使用正面身体图像和基本人体测量数据的人工智能模型作为低成本体脂率估算替代方案的可行性，图像模型取得了4.44%的RMSE和0.807的R²值。


<details>
  <summary>Details</summary>
Motivation: 追踪体脂率对体重管理至关重要，但金标准方法如DEXA扫描昂贵且难以普及，需要开发低成本替代方案。

Method: 使用535个样本数据集，开发了两种方法：(1)基于ResNet的图像模型；(2)使用人体测量数据的回归模型，并提出了多模态融合框架。

Result: 基于图像的模型实现了4.44%的RMSE和0.807的R²，表明AI模型能够提供准确的体脂估算。

Conclusion: AI辅助模型能够提供可访问且低成本的体脂估算，支持未来健康和健身领域的消费应用。

Abstract: Tracking body fat percentage is essential for effective weight management, yet gold-standard methods such as DEXA scans remain expensive and inaccessible for most people. This study evaluates the feasibility of artificial intelligence (AI) models as low-cost alternatives using frontal body images and basic anthropometric data. The dataset consists of 535 samples: 253 cases with recorded anthropometric measurements (weight, height, neck, ankle, and wrist) and 282 images obtained via web scraping from Reddit posts with self-reported body fat percentages, including some reported as DEXA-derived by the original posters. Because no public datasets exist for computer-vision-based body fat estimation, this dataset was compiled specifically for this study. Two approaches were developed: (1) ResNet-based image models and (2) regression models using anthropometric measurements. A multimodal fusion framework is also outlined for future expansion once paired datasets become available. The image-based model achieved a Root Mean Square Error (RMSE) of 4.44% and a Coefficient of Determination (R^2) of 0.807. These findings demonstrate that AI-assisted models can offer accessible and low-cost body fat estimates, supporting future consumer applications in health and fitness.

</details>


### [2] [Reconstruction-Driven Multimodal Representation Learning for Automated Media Understanding](https://arxiv.org/abs/2511.17596)
*Yassir Benhammou,Suman Kalyan,Sujay Kumar*

Main category: cs.CV

TL;DR: 本文提出了一种多模态自编码器(MMAE)，通过学习文本、音频和视觉数据的统一表示，实现广播内容元数据提取和语义聚类的端到端自动化。


<details>
  <summary>Details</summary>
Motivation: 广播和媒体组织越来越依赖AI来自动化内容索引、标记和元数据生成，但现有AI系统通常只处理单一模态，限制了其对复杂跨模态关系的理解。

Method: 使用多模态自编码器(MMAE)在LUMA数据集上训练，通过最小化跨模态联合重构损失来发现模态不变的语义结构，无需依赖大型配对或对比数据集。

Result: 相比线性基线方法，在聚类和对齐指标(Silhouette、ARI、NMI)上取得显著改进，表明基于重构的多模态嵌入可作为广播档案中可扩展元数据生成和跨模态检索的基础。

Conclusion: 重构驱动的多模态学习有潜力增强现代广播工作流程中的自动化、可搜索性和内容管理效率。

Abstract: Broadcast and media organizations increasingly rely on artificial intelligence to automate the labor-intensive processes of content indexing, tagging, and metadata generation. However, existing AI systems typically operate on a single modality-such as video, audio, or text-limiting their understanding of complex, cross-modal relationships in broadcast material. In this work, we propose a Multimodal Autoencoder (MMAE) that learns unified representations across text, audio, and visual data, enabling end-to-end automation of metadata extraction and semantic clustering. The model is trained on the recently introduced LUMA dataset, a fully aligned benchmark of multimodal triplets representative of real-world media content. By minimizing joint reconstruction losses across modalities, the MMAE discovers modality-invariant semantic structures without relying on large paired or contrastive datasets. We demonstrate significant improvements in clustering and alignment metrics (Silhouette, ARI, NMI) compared to linear baselines, indicating that reconstruction-based multimodal embeddings can serve as a foundation for scalable metadata generation and cross-modal retrieval in broadcast archives. These results highlight the potential of reconstruction-driven multimodal learning to enhance automation, searchability, and content management efficiency in modern broadcast workflows.

</details>


### [3] [BCWildfire: A Long-term Multi-factor Dataset and Deep Learning Benchmark for Boreal Wildfire Risk Prediction](https://arxiv.org/abs/2511.17597)
*Zhengsen Xu,Sibo Cheng,Hongjie He,Lanying Wang,Wentao Sun,Jonathan Li,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 本文提出了一个覆盖不列颠哥伦比亚省及周边地区、时间跨度25年、每日分辨率的野火数据集，包含38个协变量，并评估了多种时间序列预测模型在野火风险预测中的表现。


<details>
  <summary>Details</summary>
Motivation: 野火风险预测由于燃料条件、气象、地形和人类活动之间的复杂相互作用而具有挑战性，且缺乏支持长期时间建模、大规模空间覆盖和多模态驱动因素的公开基准数据集。

Method: 构建了一个25年、每日分辨率的野火数据集，覆盖2.4亿公顷区域，包含38个协变量。评估了CNN-based、linear-based、Transformer-based和Mamba-based等多种时间序列预测模型，并研究了位置嵌入的有效性和不同火灾驱动因素的相对重要性。

Result: 创建了一个包含活跃火灾检测、天气变量、燃料条件、地形特征和人为因素的综合数据集，并提供了模型评估结果。

Conclusion: 该研究填补了野火风险预测领域基准数据集的空白，为长期时空建模和多模态驱动因素分析提供了重要资源，数据集和代码已开源。

Abstract: Wildfire risk prediction remains a critical yet challenging task due to the complex interactions among fuel conditions, meteorology, topography, and human activity. Despite growing interest in data-driven approaches, publicly available benchmark datasets that support long-term temporal modeling, large-scale spatial coverage, and multimodal drivers remain scarce. To address this gap, we present a 25-year, daily-resolution wildfire dataset covering 240 million hectares across British Columbia and surrounding regions. The dataset includes 38 covariates, encompassing active fire detections, weather variables, fuel conditions, terrain features, and anthropogenic factors. Using this benchmark, we evaluate a diverse set of time-series forecasting models, including CNN-based, linear-based, Transformer-based, and Mamba-based architectures. We also investigate effectiveness of position embedding and the relative importance of different fire-driving factors. The dataset and the corresponding code can be found at https://github.com/SynUW/mmFire

</details>


### [4] [Robustness of Structured Data Extraction from Perspectively Distorted Documents](https://arxiv.org/abs/2511.17607)
*Hyakka Nakada,Yoshiyasu Tanaka*

Main category: cs.CV

TL;DR: 本文研究了透视畸变对多模态大语言模型（如Gemini-1.5-pro）在文档数据提取任务中性能的影响，发现结构识别准确率显著下降，但可通过简单旋转校正改善。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的文档图像不仅存在平面旋转，还经常出现透视畸变，这些扰动会影响多模态LLMs的数据提取准确性，但目前相关研究较少。

Method: 通过观察典型文档畸变，发现大多数近似遵循等腰梯形变换，将独立参数从8个减少到2个（旋转角度和畸变比例），然后在合成生成的样本文档上提取特定实体。

Result: 文档畸变显著降低了结构识别准确率（与阅读顺序正确性相关），而字符识别准确率受影响较小。简单的旋转校正可以改善结构识别性能。

Conclusion: 透视畸变对多模态LLMs在OCR任务中的结构识别能力有显著负面影响，但可通过简单校正方法缓解，这对多模态LLMs在实际OCR应用中的使用具有重要指导意义。

Abstract: Optical Character Recognition (OCR) for data extraction from documents is essential to intelligent informatics, such as digitizing medical records and recognizing road signs. Multi-modal Large Language Models (LLMs) can solve this task and have shown remarkable performance. Recently, it has been noticed that the accuracy of data extraction by multi-modal LLMs can be affected when in-plane rotations are present in the documents. However, real-world document images are usually not only in-plane rotated but also perspectively distorted. This study investigates the impacts of such perturbations on the data extraction accuracy for the state-of-the-art model, Gemini-1.5-pro. Because perspective distortions have a high degree of freedom, designing experiments in the same manner as single-parametric rotations is difficult. We observed typical distortions of document images and showed that most of them approximately follow an isosceles-trapezoidal transformation, which allows us to evaluate distortions with a small number of parameters. We were able to reduce the number of independent parameters from eight to two, i.e. rotation angle and distortion ratio. Then, specific entities were extracted from synthetically generated sample documents with varying these parameters. As the performance of LLMs, we evaluated not only a character-recognition accuracy but also a structure-recognition accuracy. Whereas the former represents the classical indicators for optical character recognition, the latter is related to the correctness of reading order. In particular, the structure-recognition accuracy was found to be significantly degraded by document distortion. In addition, we found that this accuracy can be improved by a simple rotational correction. This insight will contribute to the practical use of multi-modal LLMs for OCR tasks.

</details>


### [5] [3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF](https://arxiv.org/abs/2511.17609)
*Linh Van Ma,Unse Fatima,Tepy Sokun Chriv,Haroon Imran,Moongu Jeon*

Main category: cs.CV

TL;DR: 提出一种使用无迹卡尔曼滤波器(UKF)融合多摄像头2D标注信息生成准确3D地面真值的新方法，能够输出完整3D形状信息。


<details>
  <summary>Details</summary>
Motivation: 精确的3D地面真值估计对于自动驾驶、监控和机器人等应用至关重要，现有方法通常只能提供地面平面信息。

Method: 使用UKF融合来自多个标定摄像头的2D边界框或姿态关键点标注，通过基于单应性的投影和UKF融合将2D图像坐标转换为鲁棒的3D世界坐标。

Result: 在CMC、Wildtrack和Panoptic数据集上评估，相比现有3D地面真值显示出高精度的3D定位能力，并能处理遮挡等挑战。

Conclusion: 该方法为多摄像头系统提供了一种可扩展且完全自动化的解决方案，仅需2D图像标注即可生成完整3D形状信息。

Abstract: Accurate 3D ground truth estimation is critical for applications such as autonomous navigation, surveillance, and robotics. This paper introduces a novel method that uses an Unscented Kalman Filter (UKF) to fuse 2D bounding box or pose keypoint ground truth annotations from multiple calibrated cameras into accurate 3D ground truth. By leveraging human-annotated ground-truth 2D, our proposed method, a multi-camera single-object tracking algorithm, transforms 2D image coordinates into robust 3D world coordinates through homography-based projection and UKF-based fusion. Our proposed algorithm processes multi-view data to estimate object positions and shapes while effectively handling challenges such as occlusion. We evaluate our method on the CMC, Wildtrack, and Panoptic datasets, demonstrating high accuracy in 3D localization compared to the available 3D ground truth. Unlike existing approaches that provide only ground-plane information, our method also outputs the full 3D shape of each object. Additionally, the algorithm offers a scalable and fully automatic solution for multi-camera systems using only 2D image annotations.

</details>


### [6] [Unified Low-Light Traffic Image Enhancement via Multi-Stage Illumination Recovery and Adaptive Noise Suppression](https://arxiv.org/abs/2511.17612)
*Siddiqua Namrah*

Main category: cs.CV

TL;DR: 提出了一种完全无监督的多阶段深度学习框架，用于增强低光照交通图像，通过分解图像为光照和反射率分量，并采用三个专门模块进行渐进式优化，无需配对真实图像即可训练。


<details>
  <summary>Details</summary>
Motivation: 低光照交通图像在自动驾驶、智能交通和城市监控系统中存在能见度差、噪声、运动模糊、光照不均和眩光等问题，影响目标检测和场景理解任务的可靠性。

Method: 模型将图像分解为光照和反射率分量，通过三个专门模块进行渐进式优化：光照适应模块用于全局和局部亮度校正；反射率恢复模块使用空间通道注意力进行噪声抑制和结构细节恢复；过曝光补偿模块用于重建饱和区域和平衡场景亮度。

Result: 在通用和交通专用数据集上的实验表明，该方法在定量指标（PSNR、SSIM、LPIPS、NIQE）和定性视觉质量方面均优于现有最先进方法。

Conclusion: 该方法能有效增强低光照交通场景的可见度，保持结构完整性，并提高下游感知任务的可靠性。

Abstract: Enhancing low-light traffic images is crucial for reliable perception in autonomous driving, intelligent transportation, and urban surveillance systems. Nighttime and dimly lit traffic scenes often suffer from poor visibility due to low illumination, noise, motion blur, non-uniform lighting, and glare from vehicle headlights or street lamps, which hinder tasks such as object detection and scene understanding. To address these challenges, we propose a fully unsupervised multi-stage deep learning framework for low-light traffic image enhancement. The model decomposes images into illumination and reflectance components, progressively refined by three specialized modules: (1) Illumination Adaptation, for global and local brightness correction; (2) Reflectance Restoration, for noise suppression and structural detail recovery using spatial-channel attention; and (3) Over-Exposure Compensation, for reconstructing saturated regions and balancing scene luminance. The network is trained using self-supervised reconstruction, reflectance smoothness, perceptual consistency, and domain-aware regularization losses, eliminating the need for paired ground-truth images. Experiments on general and traffic-specific datasets demonstrate superior performance over state-of-the-art methods in both quantitative metrics (PSNR, SSIM, LPIPS, NIQE) and qualitative visual quality. Our approach enhances visibility, preserves structure, and improves downstream perception reliability in real-world low-light traffic scenarios.

</details>


### [7] [Plug-and-Play Multi-Concept Adaptive Blending for High-Fidelity Text-to-Image Synthesis](https://arxiv.org/abs/2511.17615)
*Young-Beom Woo*

Main category: cs.CV

TL;DR: PnP-MIX是一种无需调优的即插即用多概念自适应融合方法，用于高保真文本到图像合成，解决了多对象场景中个性化概念融合的语义不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂多对象场景中表现不佳，会导致个性化区域和非个性化区域的意外改变，破坏提示结构并造成语义不一致。

Method: 采用引导外观注意力来忠实反映每个个性化概念的外观；提出掩码引导噪声混合策略保护非个性化区域完整性；使用背景稀释++策略减少概念泄漏。

Result: 广泛实验结果表明，PnP-MIX在单概念和多概念个性化场景中均优于现有方法，展现了其鲁棒性和优越性能。

Conclusion: PnP-MIX无需额外模型调优即可实现多个个性化概念的无缝集成，在保持非个性化区域完整性的同时准确集成个性化对象。

Abstract: Integrating multiple personalized concepts into a single image has recently become a significant area of focus within Text-to-Image (T2I) generation. However, existing methods often underperform on complex multi-object scenes due to unintended alterations in both personalized and non-personalized regions. This not only fails to preserve the intended prompt structure but also disrupts interactions among regions, leading to semantic inconsistencies. To address this limitation, we introduce plug-and-play multi-concept adaptive blending for high-fidelity text-to-image synthesis (PnP-MIX), an innovative, tuning-free approach designed to seamlessly embed multiple personalized concepts into a single generated image. Our method leverages guided appearance attention to faithfully reflect the intended appearance of each personalized concept. To further enhance compositional fidelity, we present a mask-guided noise mixing strategy that preserves the integrity of non-personalized regions such as the background or unrelated objects while enabling the precise integration of personalized objects. Finally, to mitigate concept leakage, i.e., the inadvertent leakage of personalized concept features into other regions, we propose background dilution++, a novel strategy that effectively reduces such leakage and promotes accurate localization of features within personalized regions. Extensive experimental results demonstrate that PnP-MIX consistently surpasses existing methodologies in both single- and multi-concept personalization scenarios, underscoring its robustness and superior performance without additional model tuning.

</details>


### [8] [Foundational Question Generation for Video Question Answering via an Embedding-Integrated Approach](https://arxiv.org/abs/2511.17618)
*Ju-Young Oh*

Main category: cs.CV

TL;DR: FIQ框架通过生成描述性Q&A对来增强视频问答模型的推理能力，提升对视频内容的基础理解，并在SUTD-TrafficQA数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统VQA方法主要依赖事件中心的Q&A对，缺乏对场景基础信息（如物体类别、空间配置、视觉属性）的全面理解，限制了模型的泛化和推理能力。

Method: 提出FIQ框架，从视频中提取描述性信息生成Q&A对，丰富数据集的核心场景属性；同时设计VQ-CAlign模块对齐任务特定问题嵌入与视觉特征。

Result: 在SUTD-TrafficQA数据集上的实验结果显示，FIQ超越了现有基线方法，达到了最先进的性能。

Conclusion: 通过增强对视频内容的基础理解和改进特征对齐，FIQ框架有效提升了VQA模型的推理能力和泛化性能。

Abstract: Conventional VQA approaches primarily rely on question-answer (Q&A) pairs to learn the spatio-temporal dynamics of video content. However, most existing annotations are event-centric, which restricts the model's ability to capture the comprehensive context of a scene. The lack of fundamental information such as object categories, spatial configurations, and descriptive visual attributes prevents the model from forming a complete understanding of the environment, ultimately limiting its generalization and reasoning capability. In this paper, we introduce Foundational Question Generation for Video Question Answering via an Embedding-Integrated Approach (FIQ), a framework designed to enhance the reasoning capability of VQA models by improving their foundational comprehension of video content. FIQ generates Q&A pairs from descriptive information extracted directly from videos, thereby enriching the dataset with core scene-level attributes. These generated pairs help the model develop a more holistic understanding of the video, leading to improved generalizability and reasoning performance. In addition, we propose a VQ-CAlign module that aligns task-specific question embeddings with corresponding visual features, preserving essential contextual cues and enhancing adaptability to downstream tasks. Experimental results on the SUTD-TrafficQA dataset demonstrate that FIQ achieves state-of-the-art performance, surpassing existing baseline approaches.

</details>


### [9] [Rethinking the Encoding and Annotating of 3D Bounding Box: Corner-Aware 3D Object Detection from Point Clouds](https://arxiv.org/abs/2511.17619)
*Qinghao Meng,Junbo Yin,Jianbing Shen,Yunde Jia*

Main category: cs.CV

TL;DR: 本文提出角点对齐回归方法，通过将预测目标从不稳定的中心点转移到几何信息丰富的角点，解决LiDAR 3D目标检测中中心对齐回归的不稳定性问题，并支持弱监督学习。


<details>
  <summary>Details</summary>
Motivation: 中心对齐回归在LiDAR 3D目标检测中存在根本性不稳定：由于LiDAR点云的前表面偏向特性，物体中心经常落在鸟瞰图的稀疏或空区域，导致边界框预测噪声大且不准确。

Method: 提出角点对齐回归，将预测目标从中心转移到位于密集可观测区域的角点；利用角点和图像2D框之间的几何约束，从角点标注中恢复3D边界框的部分参数；设计简单有效的角点感知检测头，可插入现有检测器中。

Result: 在KITTI数据集上，相比中心基线方法性能提升3.5% AP；仅使用BEV角点点击即可达到全监督准确率的83%。

Conclusion: 角点感知回归策略有效解决了中心对齐回归的不稳定性问题，同时支持弱监督学习范式。

Abstract: Center-aligned regression remains dominant in LiDAR-based 3D object detection, yet it suffers from fundamental instability: object centers often fall in sparse or empty regions of the bird's-eye-view (BEV) due to the front-surface-biased nature of LiDAR point clouds, leading to noisy and inaccurate bounding box predictions. To circumvent this limitation, we revisit bounding box representation and propose corner-aligned regression, which shifts the prediction target from unstable centers to geometrically informative corners that reside in dense, observable regions. Leveraging the inherent geometric constraints among corners and image 2D boxes, partial parameters of 3D bounding boxes can be recovered from corner annotations, enabling a weakly supervised paradigm without requiring complete 3D labels. We design a simple yet effective corner-aware detection head that can be plugged into existing detectors. Experiments on KITTI show our method improves performance by 3.5% AP over center-based baseline, and achieves 83% of fully supervised accuracy using only BEV corner clicks, demonstrating the effectiveness of our corner-aware regression strategy.

</details>


### [10] [Efficient Score Pre-computation for Diffusion Models via Cross-Matrix Krylov Projection](https://arxiv.org/abs/2511.17634)
*Kaikwan Lau,Andrew S. Na,Justin W. L. Wan*

Main category: cs.CV

TL;DR: 提出了一种加速基于分数的扩散模型的新框架，通过将稳定扩散模型转换为Fokker-Planck公式，并采用跨矩阵Krylov投影方法来减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 标准稳定扩散模型转换为Fokker-Planck公式后需要为每张图像求解大型线性系统，在涉及大量图像训练时会产生高计算成本，需要找到更高效的求解方法。

Method: 使用跨矩阵Krylov投影方法，利用矩阵间的数学相似性，通过从"种子"矩阵构建共享子空间来快速求解后续"目标"矩阵。

Result: 相比标准稀疏求解器，该方法实现了15.8%到43.7%的时间减少；在去噪任务中比DDPM基线加速高达115倍；在固定计算预算下能生成高质量图像，而DDPM无法生成可识别内容。

Conclusion: 该方法是一种在资源受限环境下进行高效生成的实际可行方法，显著提升了扩散模型的效率。

Abstract: This paper presents a novel framework to accelerate score-based diffusion models. It first converts the standard stable diffusion model into the Fokker-Planck formulation which results in solving large linear systems for each image. For training involving many images, it can lead to a high computational cost. The core innovation is a cross-matrix Krylov projection method that exploits mathematical similarities between matrices, using a shared subspace built from ``seed" matrices to rapidly solve for subsequent ``target" matrices. Our experiments show that this technique achieves a 15.8\% to 43.7\% time reduction over standard sparse solvers. Additionally, we compare our method against DDPM baselines in denoising tasks, showing a speedup of up to 115$\times$. Furthermore, under a fixed computational budget, our model is able to produce high-quality images while DDPM fails to generate recognizable content, illustrating our approach is a practical method for efficient generation in resource-limited settings.

</details>


### [11] [Upstream Probabilistic Meta-Imputation for Multimodal Pediatric Pancreatitis Classification](https://arxiv.org/abs/2511.17635)
*Max A. Nelson,Elif Keles,Eminenur Sen Tasci,Merve Yazol,Halil Ertugrul Aktas,Ziliang Hong,Andrea Mia Bejar,Gorkem Durak,Oznur Leman Boyunaga,Ulas Bagci*

Main category: cs.CV

TL;DR: 本文提出了一种名为UPMI的轻量级增强策略，用于解决小儿胰腺炎诊断中样本有限和多模态成像复杂性的挑战。该方法在元特征空间而非图像空间操作，通过模态特定逻辑回归生成概率输出，再使用高斯混合模型采样合成元特征，最终训练随机森林元分类器。


<details>
  <summary>Details</summary>
Motivation: 小儿胰腺炎是一种进展性炎症疾病，临床诊断面临挑战。基于机器学习的方法由于样本可用性有限和多模态成像复杂性也面临诊断困难。

Method: 提出上游概率元插补(UPMI)策略：1) 模态特定逻辑回归(T1W和T2W MRI影像组学)生成概率输出；2) 转换为7维元特征向量；3) 在交叉验证折叠内拟合类条件高斯混合模型采样合成元特征；4) 结合真实元特征训练随机森林元分类器。

Result: 在67名小儿患者配对的T1W/T2W MRI数据上，UPMI实现了平均AUC为0.908±0.072，相比仅使用真实数据的基线(AUC 0.864±0.061)获得了约5%的相对增益。

Conclusion: UPMI是一种有效的轻量级数据增强策略，能够在小样本多模态医学影像诊断中显著提升模型性能。

Abstract: Pediatric pancreatitis is a progressive and debilitating inflammatory condition, including acute pancreatitis and chronic pancreatitis, that presents significant clinical diagnostic challenges. Machine learning-based methods also face diagnostic challenges due to limited sample availability and multimodal imaging complexity. To address these challenges, this paper introduces Upstream Probabilistic Meta-Imputation (UPMI), a light-weight augmentation strategy that operates upstream of a meta-learner in a low-dimensional meta-feature space rather than in image space. Modality-specific logistic regressions (T1W and T2W MRI radiomics) produce probability outputs that are transformed into a 7-dimensional meta-feature vector. Class-conditional Gaussian mixture models (GMMs) are then fit within each cross-validation fold to sample synthetic meta-features that, combined with real meta-features, train a Random Forest (RF) meta-classifier. On 67 pediatric subjects with paired T1W/T2W MRIs, UPMI achieves a mean AUC of 0.908 $\pm$ 0.072, a $\sim$5% relative gain over a real-only baseline (AUC 0.864 $\pm$ 0.061).

</details>


### [12] [SWITCH: Benchmarking Modeling and Handling of Tangible Interfaces in Long-horizon Embodied Scenarios](https://arxiv.org/abs/2511.17649)
*Jieru Lin,Zhiwei Yu,Börje F. Karlsson*

Main category: cs.CV

TL;DR: SWITCH是一个具身智能基准测试，专注于评估AI系统与真实世界控制界面的交互能力，包括语义理解、动作生成和结果验证等五个关键能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少测试AI在真实环境中的物理推理、因果预测和结果验证能力，特别是在涉及安全问题的控制界面交互方面存在明显不足。

Method: 通过迭代发布的方式创建SWITCH基准测试，第一版SWITCH-Basic包含351个任务，涵盖98种真实设备和家电，使用第一人称RGB视频输入评估五种互补能力。

Result: 商业和开源的多模态模型在单步交互任务上表现不一致，往往过度依赖文本线索而未能充分利用视觉或视频证据，高总分可能掩盖这些失败。

Conclusion: SWITCH提供了数据、代码和保留测试集，支持可复现的评估和社区贡献，旨在推动更具挑战性的基准测试迭代和训练数据集的创建。

Abstract: Autonomous intelligence requires not only perception and reasoning, but critically, effective interaction with the existing world and its infrastructure. Everyday environments are rich in tangible control interfaces (TCIs), e.g., light switches, appliance panels, and embedded GUIs, that demand commonsense and physics reasoning, but also causal prediction and outcome verification in time and space (e.g., delayed heating, remote lights). Moreover, failures here have potential safety implications, yet current benchmarks rarely test grounding, partial observability (video), or post-hoc verification in situated settings. We introduce SWITCH (Semantic World Interface Tasks for Control and Handling), an embodied, task-driven benchmark created through iterative releases to probe these gaps. Its first iteration, SWITCH-Basic, evaluates five complementary abilities:task-aware VQA, semantic UI grounding, action generation, state-transition prediction, and result verification, under egocentric RGB video input and device diversity. Across 351 tasks spanning 98 real devices and appliances, commercial and open LMMMs exhibit inconsistent performance even on single-step interactions, often over-relying on textual cues and under-using visual or video evidence (and high aggregate scores can mask such failures). SWITCH provides data, code, and held-out splits to enable reproducible evaluation and community contributions toward more challenging future iterations of the benchmark and the creation of training datasets. Benchmark resources are available at: https://github.com/BAAI-Agents/SWITCH.

</details>


### [13] [MedPEFT-CL: Dual-Phase Parameter-Efficient Continual Learning with Medical Semantic Adapter and Bidirectional Memory Consolidation](https://arxiv.org/abs/2511.17668)
*Ziyuan Gao*

Main category: cs.CV

TL;DR: 提出了MedPEFT-CL框架，通过双阶段架构解决医学视觉语言分割模型在适应新解剖结构时的灾难性遗忘问题，实现高效学习新任务并保留先前知识。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言分割模型在适应新解剖结构时存在灾难性遗忘问题，需要完全重新训练，限制了临床部署。针对医学视觉语言任务的持续学习方法研究不足。

Method: 基于CLIPSeg的双阶段架构：自适应学习阶段采用语义相似性适配器分配和参数高效微调；知识巩固阶段采用双向Fisher记忆协调。包括语义驱动适配器分配机制、双模态LoRA适应和双向Fisher记忆协调。

Result: 在多样化医学数据集上的广泛实验表明，该框架在最小参数开销下实现了优越的遗忘缓解和性能保持。

Conclusion: MedPEFT-CL框架为医学视觉语言场景的持续学习提供了有效解决方案，显著减少可训练参数同时保持跨模态学习能力。

Abstract: Medical vision-language segmentation models suffer from catastrophic forgetting when adapting to new anatomical structures, requiring complete retraining that limits their clinical deployment. Although continual learning approaches have been studied for various applications, targeted research on continual learning approaches specifically designed for medical vision-language tasks remains underexplored. We propose MedPEFT-CL, a parameter-efficient continual learning framework that addresses both efficient learning of new tasks and preservation of previous knowledge through a dual-phase architecture based on CLIPSeg. Our dual-phase architecture features an adaptive learning phase that employs semantic similarity-based adapter allocation and parameter-efficient fine-tuning for medical tasks through prompt similarity analysis, and a knowledge consolidation phase employing bi-directional Fisher-memory coordination. This creates a reinforcing cycle: consolidation directs replay priorities while new tasks provide challenging samples that improve retention strategies. Our key contributions are: (1) a semantic-driven adapter allocation mechanism that enables efficient learning of new medical tasks, (2) a bi-modal LoRA adaptation that significantly reduces trainable parameters while maintaining cross-modal learning, and (3) bidirectional Fisher-memory coordination that prevents catastrophic forgetting from previous medical tasks. Extensive experiments across diverse medical datasets demonstrate superior forgetting mitigation and performance retention with minimal parameter overhead, making the framework effective for continual learning in medical vision-language scenarios.

</details>


### [14] [HyM-UNet: Synergizing Local Texture and Global Context via Hybrid CNN-Mamba Architecture for Medical Image Segmentation](https://arxiv.org/abs/2511.17988)
*Haodong Chen,Xianfei Han,Qwen*

Main category: cs.CV

TL;DR: 本文提出了一种名为HyM-UNet的新型混合架构，将CNN的局部特征提取能力与Mamba的全局建模能力相结合，用于医学图像分割任务。


<details>
  <summary>Details</summary>
Motivation: 准确的分割是计算机辅助诊断的关键前提，但传统CNN受限于局部感受野，难以捕捉复杂的全局解剖结构。

Method: 设计了分层编码器：浅层使用卷积模块保留高频纹理细节，深层引入Visual Mamba模块以线性复杂度捕获长距离语义依赖；提出了Mamba引导融合跳跃连接，利用深层语义特征作为门控信号动态抑制浅层特征中的背景噪声。

Result: 在ISIC 2018数据集上的实验表明，HyM-UNet在Dice系数和IoU指标上显著优于现有最先进方法，同时保持较低的参数数量和推理延迟。

Conclusion: 该方法在处理具有复杂形状和尺度变化的医学分割任务中表现出有效性和鲁棒性。

Abstract: Accurate organ and lesion segmentation is a critical prerequisite for computer-aided diagnosis. Convolutional Neural Networks (CNNs), constrained by their local receptive fields, often struggle to capture complex global anatomical structures. To tackle this challenge, this paper proposes a novel hybrid architecture, HyM-UNet, designed to synergize the local feature extraction capabilities of CNNs with the efficient global modeling capabilities of Mamba. Specifically, we design a Hierarchical Encoder that utilizes convolutional modules in the shallow stages to preserve high-frequency texture details, while introducing Visual Mamba modules in the deep stages to capture long-range semantic dependencies with linear complexity. To bridge the semantic gap between the encoder and the decoder, we propose a Mamba-Guided Fusion Skip Connection (MGF-Skip). This module leverages deep semantic features as gating signals to dynamically suppress background noise within shallow features, thereby enhancing the perception of ambiguous boundaries. We conduct extensive experiments on public benchmark dataset ISIC 2018. The results demonstrate that HyM-UNet significantly outperforms existing state-of-the-art methods in terms of Dice coefficient and IoU, while maintaining lower parameter counts and inference latency. This validates the effectiveness and robustness of the proposed method in handling medical segmentation tasks characterized by complex shapes and scale variations.

</details>


### [15] [Person Recognition in Aerial Surveillance: A Decade Survey](https://arxiv.org/abs/2511.17674)
*Kien Nguyen,Feng Liu,Clinton Fookes,Sridha Sridharan,Xiaoming Liu,Arun Ross*

Main category: cs.CV

TL;DR: 本文对过去10年150多篇关于以人为中心的空中监视任务的论文进行了系统性综述，从计算机视觉和机器学习角度分析了无人机等空中平台在人类检测、识别和重识别任务中的技术现状、挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着空中平台和成像传感器的快速发展，空中监视因其在规模、移动性、部署和隐蔽观察能力方面的优势而展现出新的应用形式。本文旨在为读者提供对当前使用无人机等空中平台进行空中监视任务的深入系统综述和技术分析。

Method: 首先识别了在空域执行这些任务相比地面设置的独特挑战，随后为每个任务编译和分析了公开可用的空中数据集。深入研究了空中监视文献中的方法，重点关注它们如何解决空中挑战和改进技术。

Result: 提供了对150多篇论文的系统性分析，涵盖了人类检测、识别和重识别等关键任务，识别了空中监视面临的主要挑战，并整理了相关数据集和方法。

Conclusion: 通过讨论差距和开放研究问题，为未来的研究方向提供了信息，指出了空中监视领域需要进一步探索的技术挑战和发展方向。

Abstract: The rapid emergence of airborne platforms and imaging sensors is enabling new forms of aerial surveillance due to their unprecedented advantages in scale, mobility, deployment, and covert observation capabilities. This paper provides a comprehensive overview of 150+ papers over the last 10 years of human-centric aerial surveillance tasks from a computer vision and machine learning perspective. It aims to provide readers with an in-depth systematic review and technical analysis of the current state of aerial surveillance tasks using drones, UAVs, and other airborne platforms. The object of interest is humans, where human subjects are to be detected, identified, and re-identified. More specifically, for each of these tasks, we first identify unique challenges in performing these tasks in an aerial setting compared to the popular ground-based setting and subsequently compile and analyze aerial datasets publicly available for each task. Most importantly, we delve deep into the approaches in the aerial surveillance literature with a focus on investigating how they presently address aerial challenges and techniques for improvement. We conclude the paper by discussing the gaps and open research questions to inform future research avenues.

</details>


### [16] [Vision-Motion-Reference Alignment for Referring Multi-Object Tracking via Multi-Modal Large Language Models](https://arxiv.org/abs/2511.17681)
*Weiyi Lv,Ning Zhang,Hanyang Sun,Haoran Jiang,Kai Zhao,Jing Xiao,Dan Zeng*

Main category: cs.CV

TL;DR: VMRMOT是一个新颖的视觉-运动-参考对齐的Referring多目标跟踪框架，通过引入运动模态来增强视觉模态与语言参考之间的对齐，解决了现有RMOT基准中静态描述无法捕捉对象运动动态变化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有RMOT基准仅描述对象的外观、相对位置和初始运动状态，这种静态调节无法捕捉对象运动的动态变化（如速度变化和运动方向变化），导致静态参考与动态视觉模态之间存在时间差异，限制了多模态跟踪性能。

Method: 提出VMRMOT框架，集成从对象动态中提取的运动模态，通过多模态大语言模型增强视觉模态与语言参考的对齐。包括：1）从对象动态行为中提取运动感知描述；2）设计视觉-运动-参考对齐模块进行层次化对齐；3）开发运动引导预测头来利用运动模态增强预测性能。

Result: 在多个RMOT基准上的广泛实验表明，VMRMOT优于现有的最先进方法。

Conclusion: VMRMOT是首个在RMOT任务中采用MLLMs进行视觉-参考对齐的方法，通过引入运动模态有效解决了静态参考与动态视觉之间的时间差异问题，显著提升了多模态跟踪性能。

Abstract: Referring Multi-Object Tracking (RMOT) extends conventional multi-object tracking (MOT) by introducing natural language references for multi-modal fusion tracking. RMOT benchmarks only describe the object's appearance, relative positions, and initial motion states. This so-called static regulation fails to capture dynamic changes of the object motion, including velocity changes and motion direction shifts. This limitation not only causes a temporal discrepancy between static references and dynamic vision modality but also constrains multi-modal tracking performance. To address this limitation, we propose a novel Vision-Motion-Reference aligned RMOT framework, named VMRMOT. It integrates a motion modality extracted from object dynamics to enhance the alignment between vision modality and language references through multi-modal large language models (MLLMs). Specifically, we introduce motion-aware descriptions derived from object dynamic behaviors and, leveraging the powerful temporal-reasoning capabilities of MLLMs, extract motion features as the motion modality. We further design a Vision-Motion-Reference Alignment (VMRA) module to hierarchically align visual queries with motion and reference cues, enhancing their cross-modal consistency. In addition, a Motion-Guided Prediction Head (MGPH) is developed to explore motion modality to enhance the performance of the prediction head. To the best of our knowledge, VMRMOT is the first approach to employ MLLMs in the RMOT task for vision-reference alignment. Extensive experiments on multiple RMOT benchmarks demonstrate that VMRMOT outperforms existing state-of-the-art methods.

</details>


### [17] [Understanding Counting Mechanisms in Large Language and Vision-Language Models](https://arxiv.org/abs/2511.17699)
*Hosein Hasani,Amirmohammad Izadi,Fatemeh Askari,Mobin Bagherian,Sadegh Mohammadian,Mohammad Izadi,Mahdieh Soleymani Baghshah*

Main category: cs.CV

TL;DR: 本文研究大语言模型和大视觉语言模型在计数任务中如何表示和计算数值信息，通过因果中介和激活修补分析发现模型通过内部计数器机制进行层级的数值表示，并识别了结构线索对计数准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs和LVLMs在计数任务中数值信息的表示和计算机制，理解模型内部如何处理数值内容。

Method: 使用重复文本和视觉项目的受控实验，通过因果中介分析和激活修补技术，开发专门的CountScope工具进行机制可解释性分析。

Result: 发现单个token或视觉特征编码潜在的位置计数信息，数值表示在层级中逐步出现，识别出内部计数器机制，视觉模型中数值信息出现在视觉嵌入中并随空间构图变化。

Conclusion: 计数在LLMs中作为结构化、层级过程出现，在LVLMs中遵循相同模式但受视觉编码器特性影响，模型依赖结构线索如分隔符来跟踪项目计数。

Abstract: This paper examines how large language models (LLMs) and large vision-language models (LVLMs) represent and compute numerical information in counting tasks. We use controlled experiments with repeated textual and visual items and analyze model behavior through causal mediation and activation patching. To this end, we design a specialized tool, CountScope, for mechanistic interpretability of numerical content. Results show that individual tokens or visual features encode latent positional count information that can be extracted and transferred across contexts. Layerwise analyses reveal a progressive emergence of numerical representations, with lower layers encoding small counts and higher layers representing larger ones. We identify an internal counter mechanism that updates with each item, stored mainly in the final token or region and transferable between contexts. In LVLMs, numerical information also appears in visual embeddings, shifting between background and foreground regions depending on spatial composition. Models rely on structural cues such as separators in text, which act as shortcuts for tracking item counts and influence the accuracy of numerical predictions. Overall, counting emerges as a structured, layerwise process in LLMs and follows the same general pattern in LVLMs, shaped by the properties of the vision encoder.

</details>


### [18] [Can Vision-Language Models Count? A Synthetic Benchmark and Analysis of Attention-Based Interventions](https://arxiv.org/abs/2511.17722)
*Saurav Sengupta,Nazanin Moradinasab,Jiebei Liu,Donald E. Brown*

Main category: cs.CV

TL;DR: 该研究开发了一个合成基准数据集和评估框架，系统分析视觉语言模型在计数任务中的表现如何随图像和提示属性变化，并探索注意力干预对计数性能的影响。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在回答关于图像视觉属性的查询时，往往依赖训练中学习的内在偏见，特别是在需要关注图像特定区域的计数任务中。这些偏见在面对高度具体的问题时更加明显。

Method: 构建合成基准数据集和评估框架，使用开源视觉语言模型分析注意力分配如何随输入参数变化，并实施基于注意力的干预来调节不同层级的视觉标记焦点。

Result: 实验表明，虽然视觉语言模型的计数性能仍然具有挑战性，特别是在高视觉或语言复杂度条件下，但某些注意力干预可以在计数性能上带来适度的提升。

Conclusion: 视觉语言模型的计数性能受多种因素影响，注意力干预策略可能有助于改善模型在复杂视觉条件下的表现。

Abstract: Recent research suggests that Vision Language Models (VLMs) often rely on inherent biases learned during training when responding to queries about visual properties of images. These biases are exacerbated when VLMs are asked highly specific questions that require them to focus on particular areas of the image in tasks such as counting. We build upon this research by developing a synthetic benchmark dataset and evaluation framework to systematically determine how counting performance varies as image and prompt properties change. Using open-source VLMs, we then analyze how attention allocation fluctuates with varying input parameters (e.g. number of objects in the image, objects color, background color, objects texture, background texture, and prompt specificity). We further implement attention-based interventions to modulate focus on visual tokens at different layers and evaluate their impact on counting performance across a range of visual conditions. Our experiments reveal that while VLM counting performance remains challenging, especially under high visual or linguistic complexity, certain attention interventions can lead to modest gains in counting performance.

</details>


### [19] [AngioDG: Interpretable Channel-informed Feature-modulated Single-source Domain Generalization for Coronary Vessel Segmentation in X-ray Angiography](https://arxiv.org/abs/2511.17724)
*Mohammad Atwany,Mojtaba Lashgari,Robin P. Choudhury,Vicente Grau,Abhirup Banerjee*

Main category: cs.CV

TL;DR: 提出AngioDG方法，通过通道正则化策略解决X射线冠状动脉造影血管分割中的单源域泛化问题，在6个数据集上取得最佳域外性能。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，XCA是实时心脏介入的金标准。由于成像协议和患者特征的差异导致域偏移，且缺乏标注数据，需要单源域泛化方法。现有方法主要基于数据增强，可能无法有效缓解对增强或合成域的过拟合。

Method: 提出AngioDG方法，采用通道正则化策略：识别早期特征通道对任务特定指标的贡献以促进可解释性，然后重新加权通道以校准和放大域不变特征，同时减弱域特定特征。

Result: 在6个X射线血管造影数据集上评估冠状动脉血管分割，相比其他方法取得了最佳的域外性能，同时保持了稳定的域内测试性能。

Conclusion: AngioDG方法通过通道正则化策略有效解决了XCA血管分割中的单源域泛化问题，在多个数据集上表现出优越的泛化能力。

Abstract: Cardiovascular diseases are the leading cause of death globally, with X-ray Coronary Angiography (XCA) as the gold standard during real-time cardiac interventions. Segmentation of coronary vessels from XCA can facilitate downstream quantitative assessments, such as measurement of the stenosis severity and enhancing clinical decision-making. However, developing generalizable vessel segmentation models for XCA is challenging due to variations in imaging protocols and patient demographics that cause domain shifts. These limitations are exacerbated by the lack of annotated datasets, making Single-source Domain Generalization (SDG) a necessary solution for achieving generalization. Existing SDG methods are largely augmentation-based, which may not guarantee the mitigation of overfitting to augmented or synthetic domains. We propose a novel approach, ``AngioDG", to bridge this gap by channel regularization strategy to promote generalization. Our method identifies the contributions of early feature channels to task-specific metrics for DG, facilitating interpretability, and then reweights channels to calibrate and amplify domain-invariant features while attenuating domain-specific ones. We evaluate AngioDG on 6 x-ray angiography datasets for coronary vessels segmentation, achieving the best out-of-distribution performance among the compared methods, while maintaining consistent in-domain test performance.

</details>


### [20] [The Potential and Limitations of Vision-Language Models for Human Motion Understanding: A Case Study in Data-Driven Stroke Rehabilitation](https://arxiv.org/abs/2511.17727)
*Victor Li,Naveenraj Kamalakannan,Avinash Parnandi,Heidi Schambra,Carlos Fernandez-Granda*

Main category: cs.CV

TL;DR: 本研究评估了视觉语言模型在卒中康复视频分析中的应用，发现当前VLMs在精细运动理解方面存在局限，但通过优化提示和后期处理，在高层活动分类、运动检测和剂量估算方面显示出潜力。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在数字健康领域的应用潜力，特别是解决卒中康复中的两个关键挑战：从视频中自动量化康复剂量和功能障碍。

Method: 将康复剂量和功能障碍量化问题构建为运动识别任务，使用VLMs处理，在29名健康对照和51名卒中幸存者的队列中进行评估，采用优化提示和后期处理策略。

Result: 当前VLMs缺乏精确量化所需的精细运动理解能力：剂量估计与排除视觉信息的基线相当，功能障碍评分无法可靠预测。但通过优化，VLMs可以在无需任务特定训练的情况下，从少量帧中分类高层活动，以中等准确度检测运动和抓握，对轻度障碍和健康参与者的剂量计数误差在25%以内。

Conclusion: 研究结果突显了VLMs在数据驱动的卒中康复和更广泛临床视频分析中的当前局限性和新兴机遇，为未来改进提供了方向。

Abstract: Vision-language models (VLMs) have demonstrated remarkable performance across a wide range of computer-vision tasks, sparking interest in their potential for digital health applications. Here, we apply VLMs to two fundamental challenges in data-driven stroke rehabilitation: automatic quantification of rehabilitation dose and impairment from videos. We formulate these problems as motion-identification tasks, which can be addressed using VLMs. We evaluate our proposed framework on a cohort of 29 healthy controls and 51 stroke survivors. Our results show that current VLMs lack the fine-grained motion understanding required for precise quantification: dose estimates are comparable to a baseline that excludes visual information, and impairment scores cannot be reliably predicted. Nevertheless, several findings suggest future promise. With optimized prompting and post-processing, VLMs can classify high-level activities from a few frames, detect motion and grasp with moderate accuracy, and approximate dose counts within 25% of ground truth for mildly impaired and healthy participants, all without task-specific training or finetuning. These results highlight both the current limitations and emerging opportunities of VLMs for data-driven stroke rehabilitation and broader clinical video analysis.

</details>


### [21] [VisReason: A Large-Scale Dataset for Visual Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.17731)
*Lingxiao Li,Yifan Wang,Xinyan Gao,Chen Tang,Xiangyu Yue,Chenyu You*

Main category: cs.CV

TL;DR: VisReason是一个大规模视觉推理数据集，包含489K标注样本，旨在提升多模态大语言模型的链式思维推理能力。通过VisReason-Pro子集和深度标注增强模型的空间推理能力，显著提高了推理准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉链式思维数据集规模小、领域特定或缺乏人类逐步推理结构，限制了多模态大语言模型的视觉推理能力发展。

Method: 构建VisReason大规模数据集（489K样本），包含四个领域的人类逐步推理标注；创建VisReason-Pro子集（165K）使用GPT专家标注器增强推理轨迹和3D空间标注；在Qwen2.5-VL模型上微调。

Result: 微调后模型在逐步视觉推理准确性、可解释性和跨基准泛化方面取得显著提升，证明VisReason能赋予多模态大语言模型更系统化和泛化的推理能力。

Conclusion: VisReason为培养人类级视觉推理能力奠定了基础，推动了下一代多模态智能的发展。

Abstract: Chain-of-Thought (CoT) prompting has proven remarkably effective for eliciting complex reasoning in large language models (LLMs). Yet, its potential in multimodal large language models (MLLMs) remains largely untapped, hindered by the absence of large-scale datasets that capture the rich, spatially grounded reasoning intrinsic to visual understanding. Existing visual-CoT resources are typically small, domain-specific, or lack the human-like stepwise structure necessary for compositional visual reasoning. In this paper, we introduce VisReason, a large-scale dataset designed to advance visual Chain-of-Thought reasoning. VisReason comprises 489K annotated examples spanning four diverse domains, each featuring multi-round, human-like rationales that guide MLLMs through interpretable visual reasoning steps. Building upon this, we curate VisReason-Pro, a 165K subset produced with a stronger expert-level GPT annotator, enriched with detailed reasoning traces and 3D spatial grounding via depth-informed annotations. Fine-tuning the state-of-the-art Qwen2.5-VL model on VisReason and VisReason-Pro yields substantial improvements in step-by-step visual reasoning accuracy, interpretability, and cross-benchmark generalization. These results demonstrate that VisReason equips MLLMs with more systematic and generalizable reasoning capabilities. We envision VisReason as a cornerstone for cultivating human-like visual reasoning, paving the way toward the next generation of multimodal intelligence.

</details>


### [22] [Towards Open-Ended Visual Scientific Discovery with Sparse Autoencoders](https://arxiv.org/abs/2511.17735)
*Samuel Stevens,Jacob Beattie,Tanya Berger-Wolf,Yu Su*

Main category: cs.CV

TL;DR: 该论文探讨了稀疏自编码器（SAEs）能否从基础模型的表示中实现开放式特征发现，通过受控的再发现研究验证了该方法在生态图像中无需分割标签即可发现细粒度解剖结构的能力。


<details>
  <summary>Details</summary>
Motivation: 科学档案包含海量数据，但现有方法仅针对预设目标提取结构，无法支持未知模式的开放式发现。研究旨在探索稀疏自编码器是否能从基础模型表示中实现开放式特征发现。

Method: 使用稀疏自编码器（SAEs）从基础模型表示中学习特征，在标准分割基准上评估学习到的SAE特征与语义概念的对齐情况，并与无标签替代方法进行比较。

Result: 在生态图像应用中，该方法无需分割或部件标签即可发现细粒度解剖结构，并通过真实验证提供了科学案例研究。稀疏分解为探索科学基础模型所学内容提供了实用工具。

Conclusion: 稀疏分解为探索科学基础模型所学内容提供了实用工具，是从确认转向真正发现的重要前提条件，该方法具有领域无关性，可应用于蛋白质、基因组学、天气等其他科学领域。

Abstract: Scientific archives now contain hundreds of petabytes of data across genomics, ecology, climate, and molecular biology that could reveal undiscovered patterns if systematically analyzed at scale. Large-scale, weakly-supervised datasets in language and vision have driven the development of foundation models whose internal representations encode structure (patterns, co-occurrences and statistical regularities) beyond their training objectives. Most existing methods extract structure only for pre-specified targets; they excel at confirmation but do not support open-ended discovery of unknown patterns. We ask whether sparse autoencoders (SAEs) can enable open-ended feature discovery from foundation model representations. We evaluate this question in controlled rediscovery studies, where the learned SAE features are tested for alignment with semantic concepts on a standard segmentation benchmark and compared against strong label-free alternatives on concept-alignment metrics. Applied to ecological imagery, the same procedure surfaces fine-grained anatomical structure without access to segmentation or part labels, providing a scientific case study with ground-truth validation. While our experiments focus on vision with an ecology case study, the method is domain-agnostic and applicable to models in other sciences (e.g., proteins, genomics, weather). Our results indicate that sparse decomposition provides a practical instrument for exploring what scientific foundation models have learned, an important prerequisite for moving from confirmation to genuine discovery.

</details>


### [23] [CORA: Consistency-Guided Semi-Supervised Framework for Reasoning Segmentation](https://arxiv.org/abs/2511.17755)
*Prantik Howlader,Hoang Nguyen-Canh,Srijan Das,Jingyi Xu,Hieu Le,Dimitris Samaras*

Main category: cs.CV

TL;DR: CORA是一个半监督推理分割框架，通过结合有限标注数据和大量未标注图像，使用条件视觉指令、噪声伪标签过滤和标记级对比对齐来提升推理分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态语言模型在指令跟随分割方面取得进展，但泛化能力有限，主要瓶颈是高质量像素标注与丰富语言监督的标注成本过高，导致在分布偏移下性能脆弱。

Method: 1) 条件视觉指令编码对象间的空间和上下文关系；2) 基于多模态LLM在语义等价查询输出一致性的噪声伪标签过滤器；3) 标注样本与伪标注样本间的标记级对比对齐以增强特征一致性。

Result: 在Cityscapes数据集上仅需100张标注图像就达到SOTA结果，比基线提升+2.3%；在PanNuke数据集上仅需180张标注图像提升性能+2.4%。

Conclusion: CORA能够在最小监督下实现鲁棒的推理分割，在约束标注设置下优于现有基线方法。

Abstract: Reasoning segmentation seeks pixel-accurate masks for targets referenced by complex, often implicit instructions, requiring context-dependent reasoning over the scene. Recent multimodal language models have advanced instruction following segmentation, yet generalization remains limited. The key bottleneck is the high cost of curating diverse, high-quality pixel annotations paired with rich linguistic supervision leading to brittle performance under distribution shift. Therefore, we present CORA, a semi-supervised reasoning segmentation framework that jointly learns from limited labeled data and a large corpus of unlabeled images. CORA introduces three main components: 1) conditional visual instructions that encode spatial and contextual relationships between objects; 2) a noisy pseudo-label filter based on the consistency of Multimodal LLM's outputs across semantically equivalent queries; and 3) a token-level contrastive alignment between labeled and pseudo-labeled samples to enhance feature consistency. These components enable CORA to perform robust reasoning segmentation with minimal supervision, outperforming existing baselines under constrained annotation settings. CORA achieves state-of-the-art results, requiring as few as 100 labeled images on Cityscapes, a benchmark dataset for urban scene understanding, surpassing the baseline by $+2.3\%$. Similarly, CORA improves performance by $+2.4\%$ with only 180 labeled images on PanNuke, a histopathology dataset.

</details>


### [24] [Latent Dirichlet Transformer VAE for Hyperspectral Unmixing with Bundled Endmembers](https://arxiv.org/abs/2511.17757)
*Giancarlo Giannetti,Faisal Z. Qureshi*

Main category: cs.CV

TL;DR: 提出LDVAE-T模型用于高光谱解混，结合Transformer的全局上下文建模能力和狄利克雷先验的物理约束，将材料视为捆绑端元而非固定光谱，在三个基准数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像包含丰富的光谱信息，但光谱混合会掩盖纯材料特征，需要开发能够处理光谱混合并保持物理可解释性的解混方法。

Method: 使用Transformer变分自编码器架构，在潜在空间施加狄利克雷先验以强制丰度估计的归一化和非负约束，将材料建模为捆绑端元，预测每个端元的均值光谱和结构化协方差。

Result: 在Samson、Jasper Ridge和HYDICE Urban三个基准数据集上，LDVAE-T在丰度估计（RMSE）和端元提取（SAD）方面均优于现有最先进模型。

Conclusion: LDVAE-T通过结合Transformer的全局建模能力和狄利克雷先验的物理约束，成功实现了高光谱解混，能够表示内在材料变异性同时保持物理可解释性。

Abstract: Hyperspectral images capture rich spectral information that enables per-pixel material identification; however, spectral mixing often obscures pure material signatures. To address this challenge, we propose the Latent Dirichlet Transformer Variational Autoencoder (LDVAE-T) for hyperspectral unmixing. Our model combines the global context modeling capabilities of transformer architectures with physically meaningful constraints imposed by a Dirichlet prior in the latent space. This prior naturally enforces the sum-to-one and non-negativity conditions essential for abundance estimation, thereby improving the quality of predicted mixing ratios. A key contribution of LDVAE-T is its treatment of materials as bundled endmembers, rather than relying on fixed ground truth spectra. In the proposed method our decoder predicts, for each endmember and each patch, a mean spectrum together with a structured (segmentwise) covariance that captures correlated spectral variability. Reconstructions are formed by mixing these learned bundles with Dirichlet-distributed abundances garnered from a transformer encoder, allowing the model to represent intrinsic material variability while preserving physical interpretability. We evaluate our approach on three benchmark datasets, Samson, Jasper Ridge, and HYDICE Urban and show that LDVAE-T consistently outperforms state-of-the-art models in abundance estimation and endmember extraction, as measured by root mean squared error and spectral angle distance, respectively.

</details>


### [25] [Deepfake Geography: Detecting AI-Generated Satellite Images](https://arxiv.org/abs/2511.17766)
*Mansur Yerzhanuly*

Main category: cs.CV

TL;DR: 本文比较了CNN和ViT在检测AI生成的卫星图像方面的性能，发现ViT在准确率和鲁棒性上显著优于CNN，准确率达到95.11% vs 87.02%。


<details>
  <summary>Details</summary>
Motivation: 生成模型如StyleGAN2和Stable Diffusion的快速发展对卫星图像的真实性构成威胁，而现有的深度伪造检测研究主要集中在面部图像，卫星图像检测面临独特挑战。

Method: 使用包含13万张标记RGB图像的DM-AER和FSI数据集，对比CNN和ViT的性能，并采用Grad-CAM和Chefer注意力归因等可解释性方法来增强模型透明度。

Result: ViT在检测AI生成的卫星图像方面表现显著优于CNN，准确率达到95.11%，且能更好地建模长距离依赖和全局语义结构。

Conclusion: ViT在检测合成卫星图像的结构不一致性和重复纹理模式方面具有优越性能，未来工作将扩展到多光谱和SAR模态，并整合频域分析以增强检测能力。

Abstract: The rapid advancement of generative models such as StyleGAN2 and Stable Diffusion poses a growing threat to the authenticity of satellite imagery, which is increasingly vital for reliable analysis and decision-making across scientific and security domains. While deepfake detection has been extensively studied in facial contexts, satellite imagery presents distinct challenges, including terrain-level inconsistencies and structural artifacts. In this study, we conduct a comprehensive comparison between Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) for detecting AI-generated satellite images. Using a curated dataset of over 130,000 labeled RGB images from the DM-AER and FSI datasets, we show that ViTs significantly outperform CNNs in both accuracy (95.11 percent vs. 87.02 percent) and overall robustness, owing to their ability to model long-range dependencies and global semantic structures. We further enhance model transparency using architecture-specific interpretability methods, including Grad-CAM for CNNs and Chefer's attention attribution for ViTs, revealing distinct detection behaviors and validating model trustworthiness. Our results highlight the ViT's superior performance in detecting structural inconsistencies and repetitive textural patterns characteristic of synthetic imagery. Future work will extend this research to multispectral and SAR modalities and integrate frequency-domain analysis to further strengthen detection capabilities and safeguard satellite imagery integrity in high-stakes applications.

</details>


### [26] [Target-Bench: Can World Models Achieve Mapless Path Planning with Semantic Targets?](https://arxiv.org/abs/2511.17792)
*Dingrui Wang,Hongyuan Ye,Zhihao Liang,Zhexiao Sun,Zhaowei Lu,Yuchen Zhang,Yuyu Zhao,Yuan Gao,Marvin Seegert,Finn Schäfer,Haotong Qin,Wei Li,Luigi Palmieri,Felix Jahncke,Mattia Piccinini,Johannes Betz*

Main category: cs.CV

TL;DR: Target-Bench是首个专门评估世界模型在无地图路径规划中性能的基准，包含450个机器人收集的视频序列和SLAM基准轨迹。评估显示当前最先进模型在机器人规划任务中存在显著局限性，而微调开源模型可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 虽然当前世界模型能生成高度逼真的视频，但它们在机器人路径规划方面的能力尚不明确且缺乏量化评估，需要专门的基准来测试这些模型在真实环境中的语义目标路径规划性能。

Method: 开发Target-Bench基准，包含450个机器人收集的视频序列，涵盖45个语义类别，使用SLAM提供基准轨迹。评估流程从生成视频中恢复相机运动，并使用五个互补指标量化目标到达能力、轨迹精度和方向一致性。

Result: 评估显示最佳现成模型(Wan2.2-Flash)仅获得0.299总分，表明当前世界模型在机器人规划任务中存在显著局限性。微调开源5B参数模型在325个场景上可获得0.345总分，比基础版本提升400%以上，比最佳现成模型高15%。

Conclusion: 当前世界模型在机器人路径规划方面能力有限，但通过特定数据集微调可显著提升性能。Target-Bench为评估和改进世界模型的规划能力提供了重要基准，代码和数据集将开源。

Abstract: While recent world models generate highly realistic videos, their ability to perform robot path planning remains unclear and unquantified. We introduce Target-Bench, the first benchmark specifically designed to evaluate world models on mapless path planning toward semantic targets in real-world environments. Target-Bench provides 450 robot-collected video sequences spanning 45 semantic categories with SLAM-based ground truth trajectories. Our evaluation pipeline recovers camera motion from generated videos and measures planning performance using five complementary metrics that quantify target-reaching capability, trajectory accuracy, and directional consistency. We evaluate state-of-the-art models including Sora 2, Veo 3.1, and the Wan series. The best off-the-shelf model (Wan2.2-Flash) achieves only 0.299 overall score, revealing significant limitations in current world models for robotic planning tasks. We show that fine-tuning an open-source 5B-parameter model on only 325 scenarios from our dataset achieves 0.345 overall score -- an improvement of more than 400% over its base version (0.066) and 15% higher than the best off-the-shelf model. We will open-source the code and dataset.

</details>


### [27] [Attention Guided Alignment in Efficient Vision-Language Models](https://arxiv.org/abs/2511.17793)
*Shweta Mahajan,Hoang Le,Hyojin Park,Farzad Farhadzadeh,Munawar Hayat,Fatih Porikli*

Main category: cs.CV

TL;DR: 本文分析了高效视觉语言模型中的注意力模式，发现基于拼接的架构难以区分语义匹配和非匹配的图像-文本对，这是导致物体幻觉的关键因素。作者提出了AGE-VLM框架，通过交叉注意力层和SAM的空间知识蒸馏来增强视觉定位能力，显著减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有高效视觉语言模型在视觉-文本对齐方面存在缺陷，特别是基于拼接的架构无法有效区分语义匹配关系，导致严重的物体幻觉问题。

Method: 提出AGE-VLM框架，使用交叉注意力层在预训练的小语言模型中注入视觉能力，并利用Segment Anything Model的空间知识蒸馏来引导模型关注正确的图像区域。

Result: 在多个视觉中心基准测试中，该方法优于或与现有高效视觉语言模型相当，显著减少了物体幻觉现象。

Conclusion: 该研究为未来实现增强的视觉和语言理解的视觉语言模型提供了有价值的见解，证明了注意力引导机制在减少幻觉方面的有效性。

Abstract: Large Vision-Language Models (VLMs) rely on effective multimodal alignment between pre-trained vision encoders and Large Language Models (LLMs) to integrate visual and textual information. This paper presents a comprehensive analysis of attention patterns in efficient VLMs, revealing that concatenation-based architectures frequently fail to distinguish between semantically matching and non-matching image-text pairs. This is a key factor for object hallucination in these models. To address this, we introduce Attention-Guided Efficient Vision-Language Models (AGE-VLM), a novel framework that enhances visual grounding through interleaved cross-attention layers to instill vision capabilities in pretrained small language models. This enforces in VLM the ability "look" at the correct image regions by leveraging spatial knowledge distilled from the Segment Anything Model (SAM), significantly reducing hallucination. We validate our approach across different vision-centric benchmarks where our method is better or comparable to prior work on efficient VLMs. Our findings provide valuable insights for future research aimed at achieving enhanced visual and linguistic understanding in VLMs.

</details>


### [28] [Pillar-0: A New Frontier for Radiology Foundation Models](https://arxiv.org/abs/2511.17803)
*Kumar Krishna Agrawal,Longchao Liu,Long Lian,Michael Nercessian,Natalia Harguindeguy,Yufu Wu,Peter Mikhael,Gigin Lin,Lecia V. Sequist,Florian Fintelmann,Trevor Darrell,Yutong Bai,Maggie Chung,Adam Yala*

Main category: cs.CV

TL;DR: Pillar-0是一个放射学基础模型，在42,990个腹部-盆腔CT、86,411个胸部CT、14,348个头部CT和11,543个乳腺MRI上预训练，结合RATE框架，在366个放射学发现任务中表现优异，显著超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有医学模型处理体层CT和MRI时作为低保真2D切片、丢弃关键灰度对比信息以及缺乏反映真实临床实践评估框架的局限性。

Method: 使用Pillar-0模型在大规模医学影像数据集上预训练，结合RATE框架通过LLM提取结构化标签，构建临床严谨的评估体系。

Result: 在内部测试集上，Pillar-0平均AUROC达到86.4-90.1，优于MedGemma、MedImageInsight等模型7.8-15.8 AUROC点，在87.2%任务中排名第一；在外部验证和肺癌风险预测等任务中也表现优异。

Conclusion: Pillar-0和RATE共同提供了一个开放、临床严谨的基础，用于构建高性能放射学系统，解决了以往因计算、数据和评估限制而不可行的应用问题。

Abstract: Radiology plays an integral role in modern medicine, yet rising imaging volumes have far outpaced workforce growth. Foundation models offer a path toward assisting with the full spectrum of radiology tasks, but existing medical models remain limited: they process volumetric CT and MRI as low-fidelity 2D slices, discard critical grayscale contrast information, and lack evaluation frameworks that reflect real clinical practice. We introduce Pillar-0, a radiology foundation model pretrained on 42,990 abdomen-pelvis CTs, 86,411 chest CTs, 14,348 head CTs, and 11,543 breast MRIs from a large academic center, together with RATE, a scalable framework that extracts structured labels for 366 radiologic findings with near-perfect accuracy using LLMs. Across internal test sets of 14,230 abdomen-pelvis CTs, 10,646 chest CTs, 4,906 head CTs, and 1,585 breast MRIs, Pillar-0 establishes a new performance frontier, achieving mean AUROCs of 86.4, 88.0, 90.1, and 82.9, outperforming MedGemma (Google), MedImageInsight (Microsoft), Lingshu (Alibaba), and Merlin (Stanford) by 7.8-15.8 AUROC points and ranking best in 87.2\% (319/366) tasks. Pillar-0 similarly outperforms all baselines in an external validation on the Stanford Abdominal CT dataset, including Merlin (82.2 vs 80.6 AUROC). Pillar-0 extends to tasks beyond its pretraining, such as long-horizon lung cancer risk prediction, where it improves upon the state-of-the-art Sybil by 3.0 C-index points on NLST, and generalizes with gains of 5.9 (MGH) and 1.9 (CGMH). In brain hemorrhage detection, Pillar-0 obtained a >95 AUROC when using only 1/20th of the data of the next most sample efficient baseline. Pillar-0 and RATE together provide an open, clinically rigorous foundation for building high-performance radiology systems, enabling applications that were previously infeasible due to computational, data, and evaluation constraints.

</details>


### [29] [A Stitch in Time: Learning Procedural Workflow via Self-Supervised Plackett-Luce Ranking](https://arxiv.org/abs/2511.17805)
*Chengan Che,Chao Wang,Xinyue Chen,Sophia Tsoka,Luis C. Garcia-Peraza-Herrera*

Main category: cs.CV

TL;DR: PL-Stitch是一个自监督学习框架，通过利用视频帧的固有时间顺序作为监督信号，解决现有方法对程序性活动时间顺序不敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 当前自监督学习方法在静态图像和短视频上表现成功，但忽视了程序性活动的结构化特性，即动作按特定时间顺序执行。实验表明，现有模型无法区分正向和时间反转序列的特征。

Method: 提出PL-Stitch框架，整合基于Plackett-Luce模型的两个概率目标：主要PL目标训练模型按时间顺序排序采样帧，学习全局工作流程进展；次要目标通过时空拼图损失捕捉细粒度的跨帧对象相关性。

Result: 在五个手术和烹饪基准测试中持续实现卓越性能，特别是在手术阶段识别（如Cholec80上k-NN准确率提升11.4个百分点）和烹饪动作分割（如Breakfast上线性探测准确率提升5.7个百分点）方面取得显著提升。

Conclusion: PL-Stitch通过利用程序性视频的时间顺序作为监督信号，有效提升了程序性视频表示学习的性能，证明了时间顺序信息在理解程序性活动中的重要性。

Abstract: Procedural activities, ranging from routine cooking to complex surgical operations, are highly structured as a set of actions conducted in a specific temporal order. Despite their success on static images and short clips, current self-supervised learning methods often overlook the procedural nature that underpins such activities. We expose the lack of procedural awareness in current SSL methods with a motivating experiment: models pretrained on forward and time-reversed sequences produce highly similar features, confirming that their representations are blind to the underlying procedural order. To address this shortcoming, we propose PL-Stitch, a self-supervised framework that harnesses the inherent temporal order of video frames as a powerful supervisory signal. Our approach integrates two novel probabilistic objectives based on the Plackett-Luce (PL) model. The primary PL objective trains the model to sort sampled frames chronologically, compelling it to learn the global workflow progression. The secondary objective, a spatio-temporal jigsaw loss, complements the learning by capturing fine-grained, cross-frame object correlations. Our approach consistently achieves superior performance across five surgical and cooking benchmarks. Specifically, PL-Stitch yields significant gains in surgical phase recognition (e.g., +11.4 pp k-NN accuracy on Cholec80) and cooking action segmentation (e.g., +5.7 pp linear probing accuracy on Breakfast), demonstrating its effectiveness for procedural video representation learning.

</details>


### [30] [REXO: Indoor Multi-View Radar Object Detection via 3D Bounding Box Diffusion](https://arxiv.org/abs/2511.17806)
*Ryoma Yataka,Pu Perry Wang,Petros Boufounos,Ryuhei Takahashi*

Main category: cs.CV

TL;DR: REXO提出了一种基于3D边界框扩散的多视角雷达目标检测方法，通过显式的跨视角雷达特征关联来提升复杂室内场景下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖隐式的跨视角雷达特征关联（如RFMask中的提案配对或RETR中的查询到特征交叉注意力），在复杂室内场景中容易导致特征匹配模糊和检测性能下降。

Method: 将DiffusionDet的2D边界框扩散过程提升到3D雷达空间，利用噪声3D边界框指导显式的跨视角雷达特征关联，增强跨视角雷达条件去噪过程，并利用人与地面接触的先验知识减少扩散参数。

Result: 在两个公开室内雷达数据集上的评估显示，该方法在HIBER数据集上比最先进方法提升了+4.22 AP，在MMVR数据集上提升了+11.02 AP。

Conclusion: REXO通过显式的跨视角特征关联和3D边界框扩散过程，显著提升了多视角室内雷达感知的性能，特别是在复杂场景下表现出色。

Abstract: Multi-view indoor radar perception has drawn attention due to its cost-effectiveness and low privacy risks. Existing methods often rely on {implicit} cross-view radar feature association, such as proposal pairing in RFMask or query-to-feature cross-attention in RETR, which can lead to ambiguous feature matches and degraded detection in complex indoor scenes. To address these limitations, we propose \textbf{REXO} (multi-view Radar object dEtection with 3D bounding boX diffusiOn), which lifts the 2D bounding box (BBox) diffusion process of DiffusionDet into the 3D radar space. REXO utilizes these noisy 3D BBoxes to guide an {explicit} cross-view radar feature association, enhancing the cross-view radar-conditioned denoising process. By accounting for prior knowledge that the person is in contact with the ground, REXO reduces the number of diffusion parameters by determining them from this prior. Evaluated on two open indoor radar datasets, our approach surpasses state-of-the-art methods by a margin of +4.22 AP on the HIBER dataset and +11.02 AP on the MMVR dataset.

</details>


### [31] [Importance-Weighted Non-IID Sampling for Flow Matching Models](https://arxiv.org/abs/2511.17812)
*Xinshuang Liu,Runfa Blark Li,Shaoxiu Wei,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出一种重要性加权的非独立同分布采样框架，通过联合抽取多个样本来覆盖流模型分布的不同重要区域，同时通过估计的重要性权重保持无偏估计。


<details>
  <summary>Details</summary>
Motivation: 流匹配模型能有效表示复杂分布，但在有限采样预算下估计其输出函数的期望仍然具有挑战性。独立采样通常会产生高方差估计，特别是当罕见但高影响的结果主导期望时。

Method: 引入基于分数的正则化多样性机制，使用分数函数（对数概率梯度）确保样本在高密度数据流形区域内分散，减轻离流形漂移。开发首个非独立同分布流样本重要性加权方法，通过学习残差速度场来重现非独立同分布样本的边际分布。

Result: 经验证明，该方法能产生多样化、高质量的样本，并准确估计重要性权重和期望，提升了流匹配模型输出的可靠表征能力。

Conclusion: 该方法通过重要性加权的非独立同分布采样框架，有效解决了流匹配模型期望估计中的高方差问题，为模型输出的可靠表征提供了先进解决方案。

Abstract: Flow-matching models effectively represent complex distributions, yet estimating expectations of functions of their outputs remains challenging under limited sampling budgets. Independent sampling often yields high-variance estimates, especially when rare but with high-impact outcomes dominate the expectation. We propose an importance-weighted non-IID sampling framework that jointly draws multiple samples to cover diverse, salient regions of a flow's distribution while maintaining unbiased estimation via estimated importance weights. To balance diversity and quality, we introduce a score-based regularization for the diversity mechanism, which uses the score function, i.e., the gradient of the log probability, to ensure samples are pushed apart within high-density regions of the data manifold, mitigating off-manifold drift. We further develop the first approach for importance weighting of non-IID flow samples by learning a residual velocity field that reproduces the marginal distribution of the non-IID samples. Empirically, our method produces diverse, high-quality samples and accurate estimates of both importance weights and expectations, advancing the reliable characterization of flow-matching model outputs. Our code will be publicly available on GitHub.

</details>


### [32] [QAL: A Loss for Recall Precision Balance in 3D Reconstruction](https://arxiv.org/abs/2511.17824)
*Pranay Meshram,Yash Turkar,Kartikeya Singh,Praveen Raj Masilamani,Charuvahan Adhivarahan,Karthik Dantu*

Main category: cs.CV

TL;DR: 提出Quality-Aware Loss (QAL)作为Chamfer Distance和Earth Mover's Distance的替代方案，通过解耦召回率和精确度来改善3D体积学习任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前3D视觉任务中的训练目标仍依赖Chamfer Distance和Earth Mover's Distance，但这些方法无法平衡召回率和精确度，导致薄结构和代表性不足区域被忽略。

Method: QAL结合了覆盖加权的最近邻项和未覆盖真实值吸引项，将召回率和精确度显式解耦为可调组件。

Result: 在多样化流程中，QAL相比CD平均提升4.3个百分点，相比最佳替代方案提升2.8个百分点，能可靠恢复薄结构和代表性不足区域。在GraspNet评估中，QAL训练的补全结果获得更高的抓取分数。

Conclusion: QAL为稳健的3D视觉和安全关键机器人流程提供了一个原则性、可解释且实用的目标函数。

Abstract: Volumetric learning underpins many 3D vision tasks such as completion, reconstruction, and mesh generation, yet training objectives still rely on Chamfer Distance (CD) or Earth Mover's Distance (EMD), which fail to balance recall and precision. We propose Quality-Aware Loss (QAL), a drop-in replacement for CD/EMD that combines a coverage-weighted nearest-neighbor term with an uncovered-ground-truth attraction term, explicitly decoupling recall and precision into tunable components.
  Across diverse pipelines, QAL achieves consistent coverage gains, improving by an average of +4.3 pts over CD and +2.8 pts over the best alternatives. Though modest in percentage, these improvements reliably recover thin structures and under-represented regions that CD/EMD overlook. Extensive ablations confirm stable performance across hyperparameters and across output resolutions, while full retraining on PCN and ShapeNet demonstrates generalization across datasets and backbones. Moreover, QAL-trained completions yield higher grasp scores under GraspNet evaluation, showing that improved coverage translates directly into more reliable robotic manipulation.
  QAL thus offers a principled, interpretable, and practical objective for robust 3D vision and safety-critical robotics pipelines

</details>


### [33] [Toward explainable AI approaches for breast imaging: adapting foundation models to diverse populations](https://arxiv.org/abs/2511.17828)
*Guilherme J. Cavalcante,José Gabriel A. Moreira,Gabriel A. B. do Nascimento,Vincent Dong,Alex Nguyen,Thaís G. do Rêgo,Yuri Malheiros,Telmo M. Silva Filho,Carla R. Zeballos Torrez,James C. Gee,Anne Marie McCarthy,Andrew D. A. Maidment,Bruno Barufaldi*

Main category: cs.CV

TL;DR: 本研究利用BiomedCLIP基础模型进行乳腺密度BI-RADS分类，通过多模态训练方法在96,995张图像上取得了良好效果，展示了基础模型在乳腺成像中的潜力。


<details>
  <summary>Details</summary>
Motivation: 基础模型在专业医学成像任务中具有潜力，但其在乳腺成像中的有效性尚未充分探索。本研究旨在解决模型泛化挑战，探索基础模型在乳腺密度分类中的应用。

Method: 使用BiomedCLIP基础模型进行BI-RADS乳腺密度分类，采用多模态乳腺摄影数据（合成2D图像、数字乳腺摄影和数字乳腺断层合成）。通过加权对比学习解决类别不平衡问题，比较单模态和多模态训练方法。

Result: 多模态和单模态方法达到相似准确率（0.74 vs 0.73），多模态模型在不同成像模态中具有更广泛适用性，AUC值始终高于0.84。在RSNA和EMBED数据集的外部验证显示强泛化能力（AUC范围：0.80-0.93）。GradCAM可视化确认了临床相关注意力模式。

Conclusion: 这项研究强调了基础模型在乳腺成像应用中的潜力，为未来扩展到诊断任务铺平了道路。

Abstract: Foundation models hold promise for specialized medical imaging tasks, though their effectiveness in breast imaging remains underexplored. This study leverages BiomedCLIP as a foundation model to address challenges in model generalization. BiomedCLIP was adapted for automated BI-RADS breast density classification using multi-modality mammographic data (synthesized 2D images, digital mammography, and digital breast tomosynthesis). Using 96,995 images, we compared single-modality (s2D only) and multi-modality training approaches, addressing class imbalance through weighted contrastive learning. Both approaches achieved similar accuracy (multi-modality: 0.74, single-modality: 0.73), with the multi-modality model offering broader applicability across different imaging modalities and higher AUC values consistently above 0.84 across BI-RADS categories. External validation on the RSNA and EMBED datasets showed strong generalization capabilities (AUC range: 0.80-0.93). GradCAM visualizations confirmed consistent and clinically relevant attention patterns, highlighting the models interpretability and robustness. This research underscores the potential of foundation models for breast imaging applications, paving the way for future extensions for diagnostic tasks.

</details>


### [34] [Show Me: Unifying Instructional Image and Video Generation with Diffusion Models](https://arxiv.org/abs/2511.17839)
*Yujiang Pu,Zhanbo Huang,Vishnu Boddeti,Yu Kong*

Main category: cs.CV

TL;DR: ShowMe是一个统一框架，通过选择性激活视频扩散模型的空间和时间组件，同时支持文本引导的图像操作和视频预测任务。该方法引入结构和运动一致性奖励来提升结构保真度和时间连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将文本引导图像操作和视频预测视为独立任务，导致图像操作方法忽略动作随时间展开，而视频预测模型忽视预期结果。需要统一框架来解决这一根本问题。

Method: 提出ShowMe框架，选择性激活视频扩散模型的空间和时间组件，引入结构和运动一致性奖励来改善结构保真度和时间连贯性。通过视频预训练获得空间知识增强非刚性图像编辑的上下文一致性，通过指令引导操作阶段增强视频预测的目标导向推理能力。

Result: 在多样化基准测试中，该方法在指令图像和视频生成方面均优于专家模型，展示了视频扩散模型作为统一动作-状态转换器的强大能力。

Conclusion: 视频扩散模型可以作为统一的动作-状态转换器，在图像操作和视频预测任务中实现协同增效，空间知识和目标导向推理的相互增强带来了双重收益。

Abstract: Generating visual instructions in a given context is essential for developing interactive world simulators. While prior works address this problem through either text-guided image manipulation or video prediction, these tasks are typically treated in isolation. This separation reveals a fundamental issue: image manipulation methods overlook how actions unfold over time, while video prediction models often ignore the intended outcomes. To this end, we propose ShowMe, a unified framework that enables both tasks by selectively activating the spatial and temporal components of video diffusion models. In addition, we introduce structure and motion consistency rewards to improve structural fidelity and temporal coherence. Notably, this unification brings dual benefits: the spatial knowledge gained through video pretraining enhances contextual consistency and realism in non-rigid image edits, while the instruction-guided manipulation stage equips the model with stronger goal-oriented reasoning for video prediction. Experiments on diverse benchmarks demonstrate that our method outperforms expert models in both instructional image and video generation, highlighting the strength of video diffusion models as a unified action-object state transformer.

</details>


### [35] [JigsawComm: Joint Semantic Feature Encoding and Transmission for Communication-Efficient Cooperative Perception](https://arxiv.org/abs/2511.17843)
*Chenyi Wang,Zhaowei Li,Ming F. Li,Wujie Wen*

Main category: cs.CV

TL;DR: JigsawComm是一个端到端训练的语义感知多智能体协同感知框架，通过提取语义相关特征和使用特征效用估计器优化传输策略，在有限带宽下实现高效通信。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协同感知中通信带宽有限的问题，现有方法未考虑语义相关性和跨智能体冗余，需要最大化每个传输比特对感知任务的贡献。

Method: 提出JigsawComm框架，使用正则化编码器提取语义相关稀疏特征，通过特征效用估计器预测特征贡献度，交换元效用图并计算最优传输策略。

Result: 在OPV2V和DAIR-V2X基准测试中，JigsawComm将总数据量减少超过500倍，同时达到或优于最先进方法的精度。

Conclusion: JigsawComm通过语义感知的特征选择和传输策略，实现了通信效率的大幅提升，同时保持感知精度，为多智能体协同感知提供了实用解决方案。

Abstract: Multi-agent cooperative perception (CP) promises to overcome the inherent occlusion and sensing-range limitations of single-agent systems (e.g., autonomous driving). However, its practicality is severely constrained by the limited communication bandwidth. Existing approaches attempt to improve bandwidth efficiency via compression or heuristic message selection, without considering the semantic relevance or cross-agent redundancy of sensory data. We argue that a practical CP system must maximize the contribution of every transmitted bit to the final perception task, by extracting and transmitting semantically essential and non-redundant data. In this paper, we formulate a joint semantic feature encoding and transmission problem, which aims to maximize CP accuracy under limited bandwidth. To solve this problem, we introduce JigsawComm, an end-to-end trained, semantic-aware, and communication-efficient CP framework that learns to ``assemble the puzzle'' of multi-agent feature transmission. It uses a regularized encoder to extract semantically-relevant and sparse features, and a lightweight Feature Utility Estimator to predict the contribution of each agent's features to the final perception task. The resulting meta utility maps are exchanged among agents and leveraged to compute a provably optimal transmission policy, which selects features from agents with the highest utility score for each location. This policy inherently eliminates redundancy and achieves a scalable $\mathcal{O}(1)$ communication cost as the number of agents increases. On the benchmarks OPV2V and DAIR-V2X, JigsawComm reduces the total data volume by up to $>$500$\times$ while achieving matching or superior accuracy compared to state-of-the-art methods.

</details>


### [36] [Less is More: Data-Efficient Adaptation for Controllable Text-to-Video Generation](https://arxiv.org/abs/2511.17844)
*Shihan Cheng,Nilesh Kulkarni,David Hyde,Dmitriy Smirnov*

Main category: cs.CV

TL;DR: 本文提出了一种数据高效的精调策略，使用稀疏、低质量的合成数据来学习文本到视频扩散模型的物理相机参数控制，结果优于使用逼真真实数据精调的模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量高质量数据集来精调文本到视频扩散模型以添加新的生成控制（如物理相机参数），但这些数据集难以获取。

Method: 提出数据高效的精调策略，从稀疏、低质量的合成数据中学习物理相机参数控制。

Result: 使用简单合成数据精调不仅实现了期望的控制，而且结果优于使用逼真真实数据精调的模型。

Conclusion: 提供了一个理论框架来直观和定量地解释这种现象，证明了使用低质量合成数据的有效性。

Abstract: Fine-tuning large-scale text-to-video diffusion models to add new generative controls, such as those over physical camera parameters (e.g., shutter speed or aperture), typically requires vast, high-fidelity datasets that are difficult to acquire. In this work, we propose a data-efficient fine-tuning strategy that learns these controls from sparse, low-quality synthetic data. We show that not only does fine-tuning on such simple data enable the desired controls, it actually yields superior results to models fine-tuned on photorealistic "real" data. Beyond demonstrating these results, we provide a framework that justifies this phenomenon both intuitively and quantitatively.

</details>


### [37] [MGA-VQA: Secure and Interpretable Graph-Augmented Visual Question Answering with Memory-Guided Protection Against Unauthorized Knowledge Use](https://arxiv.org/abs/2511.17881)
*Ahmad Mohammadshirazi,Pinaki Prasad Guha Neogi,Dheeraj Kulshrestha,Rajiv Ramnath*

Main category: cs.CV

TL;DR: MGA-VQA是一个多模态文档视觉问答框架，通过集成令牌级编码、空间图推理、记忆增强推理和问题引导压缩，解决了现有方法在空间关系建模、高分辨率文档处理、多跳推理和可解释性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前文档视觉问答方法在显式空间关系建模、高分辨率文档处理效率、多跳推理能力和模型可解释性方面存在局限，需要更有效的解决方案。

Method: 提出MGA-VQA框架，包含令牌级编码、空间图推理、记忆增强推理和问题引导压缩四个核心组件，引入可解释的基于图的决策路径和结构化内存访问机制。

Result: 在六个基准测试（FUNSD、CORD、SROIE、DocVQA、STE-VQA和RICO）上表现出优越的准确性和效率，在答案预测和空间定位方面均获得一致改进。

Conclusion: MGA-VQA通过多模态集成和可解释推理机制，有效提升了文档视觉问答的性能和透明度，为复杂文档理解任务提供了新的解决方案。

Abstract: Document Visual Question Answering (DocVQA) requires models to jointly understand textual semantics, spatial layout, and visual features. Current methods struggle with explicit spatial relationship modeling, inefficiency with high-resolution documents, multi-hop reasoning, and limited interpretability. We propose MGA-VQA, a multi-modal framework that integrates token-level encoding, spatial graph reasoning, memory-augmented inference, and question-guided compression. Unlike prior black-box models, MGA-VQA introduces interpretable graph-based decision pathways and structured memory access for enhanced reasoning transparency. Evaluation across six benchmarks (FUNSD, CORD, SROIE, DocVQA, STE-VQA, and RICO) demonstrates superior accuracy and efficiency, with consistent improvements in both answer prediction and spatial localization.

</details>


### [38] [ArticFlow: Generative Simulation of Articulated Mechanisms](https://arxiv.org/abs/2511.17883)
*Jiong Lin,Jinchen Ruan,Hod Lipson*

Main category: cs.CV

TL;DR: ArticFlow是一个两阶段流匹配框架，用于在明确动作控制下从噪声生成目标点集，能够表示多样化的铰接类别并在动作间泛化。


<details>
  <summary>Details</summary>
Motivation: 生成模型在静态3D形状方面取得了显著进展，但铰接3D生成仍然具有挑战性，主要由于动作依赖的变形和有限的数据集。

Method: 引入ArticFlow，一个两阶段流匹配框架，包含：(i) 将噪声传输到形状先验代码的潜在流；(ii) 在动作和形状先验条件下传输点的点流。

Result: 在MuJoCo Menagerie上，ArticFlow既能作为生成模型也能作为神经模拟器：从紧凑先验预测动作条件运动学，并通过潜在插值合成新形态。相比特定对象模拟器和静态点云生成器的动作条件变体，ArticFlow实现了更高的运动学精度和更好的形状质量。

Conclusion: 动作条件流匹配是实现可控和高质量铰接机制生成的实用途径。

Abstract: Recent advances in generative models have produced strong results for static 3D shapes, whereas articulated 3D generation remains challenging due to action-dependent deformations and limited datasets. We introduce ArticFlow, a two-stage flow matching framework that learns a controllable velocity field from noise to target point sets under explicit action control. ArticFlow couples (i) a latent flow that transports noise to a shape-prior code and (ii) a point flow that transports points conditioned on the action and the shape prior, enabling a single model to represent diverse articulated categories and generalize across actions. On MuJoCo Menagerie, ArticFlow functions both as a generative model and as a neural simulator: it predicts action-conditioned kinematics from a compact prior and synthesizes novel morphologies via latent interpolation. Compared with object-specific simulators and an action-conditioned variant of static point-cloud generators, ArticFlow achieves higher kinematic accuracy and better shape quality. Results show that action-conditioned flow matching is a practical route to controllable and high-quality articulated mechanism generation.

</details>


### [39] [FastMMoE: Accelerating Multimodal Large Language Models through Dynamic Expert Activation and Routing-Aware Token Pruning](https://arxiv.org/abs/2511.17885)
*Guoyang Xia,Yifeng Ding,Fengfa Li,Lei Ren,Wei Chen,Fangxiang Feng,Xiaojie Wang*

Main category: cs.CV

TL;DR: FastMMoE是一种针对基于MoE的多模态大语言模型的训练免费加速框架，通过专家激活减少和路由感知令牌剪枝两种策略，在保持约95.5%性能的同时减少高达55.0%的FLOPs。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在处理高分辨率视觉输入时会产生大量视觉令牌，导致推理延迟和计算负担。需要在保持性能的同时减少冗余视觉令牌，以便在资源受限或延迟敏感的场景中部署。

Method: 提出FastMMoE框架，包含两种互补策略：1）视觉令牌的专家激活减少，最小化不必要的专家计算；2）路由感知令牌剪枝，利用路由概率分布的相似性识别和移除高度冗余的视觉令牌。

Result: 在DeepSeek-VL2和InternVL3.5等大型MoE-MLLMs上的实验表明，FastMMoE可减少高达55.0%的FLOPs，同时保留约95.5%的原始性能，在多个保留率下持续优于FastV和SparseVLM等密集模型剪枝基线。

Conclusion: FastMMoE为基于MoE的多模态大语言模型提供了一种有效的训练免费加速方法，通过路由分析视角显著减少了计算负担，同时保持了模型性能。

Abstract: Multimodal large language models (MLLMs) have achieved impressive performance, but high-resolution visual inputs result in long sequences of visual tokens and substantial inference latency. Reducing redundant visual tokens is critical to ease computational/memory burdens while preserving performance, enabling MLLM deployment in resource-constrained or latency-sensitive scenarios. Current visual token pruning methods mainly rely on attention-based redundancy analysis and are tailored to dense architectures. We propose Fast Multimodal Mixture-of-Experts (FastMMoE), a training-free acceleration framework for mixture-of-experts (MoE) based MLLMs, developed from a routing analysis perspective. FastMMoE combines two complementary strategies: (i) expert activation reduction for visual tokens to minimize unnecessary expert computation; and (ii) routing-aware token pruning that leverages similarity in routing probability distributions to identify and remove highly redundant visual tokens. Experiments on large-scale MoE-MLLMs such as DeepSeek-VL2 and InternVL3.5 demonstrate that FastMMoE can reduce FLOPs by up to 55.0% while retaining approximately 95.5% of the original performance, consistently outperforming dense-model pruning baselines including FastV and SparseVLM across multiple retention rates.

</details>


### [40] [When Better Teachers Don't Make Better Students: Revisiting Knowledge Distillation for CLIP Models in VQA](https://arxiv.org/abs/2511.17886)
*Pume Tuchinda,Parinthapat Pengpun,Romrawin Chumpu,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CV

TL;DR: 本文系统研究了CLIP风格视觉语言模型的知识蒸馏，发现与NLP和视觉领域不同，更强的教师模型并不总能产生更好的学生模型，现有蒸馏框架在多模态任务中难以扩展。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型计算需求大，知识蒸馏是构建轻量级模型的有效方法，但在CLIP风格模型中的应用有限，主要局限于小规模教师模型和狭窄评估任务。

Method: 对一系列CLIP风格教师模型进行系统蒸馏研究，涵盖从标准基线到大规模最先进模型。

Result: 发现更强的教师模型并不总是产生更好的学生模型，现有蒸馏框架在多模态任务中往往导致性能下降。

Conclusion: 研究结果挑战了知识蒸馏中的普遍假设，为设计参数高效的多模态模型指明了新方向。

Abstract: Vision-language models (VLMs) have achieved remarkable success across multimodal tasks, yet their substantial computational demands hinder efficient deployment. Knowledge distillation (KD) has emerged as a powerful approach for building lightweight but competitive models, with strong evidence from both language and vision domains. However, its application to VLMs, particularly CLIP-style models, remains limited, often constrained to small-scale teachers and narrow evaluation tasks such as classification or retrieval. In this work, we present the first systematic study of distillation across a range of CLIP-style teacher models, ranging from standard baselines to large-scale state-of-the-art models. Contrary to trends observed in NLP and vision, we find that stronger teachers do not consistently yield better students; in fact, existing distillation frameworks often fail to scale, leading to degraded performance in downstream multimodal tasks such as visual question answering. Our findings challenge prevailing assumptions in KD and point toward new directions for designing parameter-efficient multimodal models.

</details>


### [41] [MINDiff: Mask-Integrated Negative Attention for Controlling Overfitting in Text-to-Image Personalization](https://arxiv.org/abs/2511.17888)
*Seulgi Jeong,Jaeil Kim*

Main category: cs.CV

TL;DR: MINDiff提出了一种新的负注意力机制，通过在推理时修改交叉注意力来抑制主题在无关区域的影响，从而解决DreamBooth等方法的过拟合问题，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法如DreamBooth使用类别特定的先验保持损失来缓解过拟合，但这增加了训练计算成本并限制了用户在推理时的控制能力。

Method: MINDiff引入了负注意力的概念，在推理时修改交叉注意力机制，在掩码的无关区域抑制主题的影响，用户可以通过调整lambda参数来平衡主题保真度和文本对齐。

Result: 定性和定量实验表明，MINDiff比类别特定的先验保持损失更有效地缓解了过拟合问题，且完全在推理时操作，无需改变模型架构。

Conclusion: MINDiff提供了一种在推理时有效缓解过拟合的方法，可直接应用于现有DreamBooth模型，实现了更好的语义控制和文本对齐。

Abstract: In the personalization process of large-scale text-to-image models, overfitting often occurs when learning specific subject from a limited number of images. Existing methods, such as DreamBooth, mitigate this issue through a class-specific prior-preservation loss, which requires increased computational cost during training and limits user control during inference time. To address these limitations, we propose Mask-Integrated Negative Attention Diffusion (MINDiff). MINDiff introduces a novel concept, negative attention, which suppresses the subject's influence in masked irrelevant regions. We achieve this by modifying the cross-attention mechanism during inference. This enables semantic control and improves text alignment by reducing subject dominance in irrelevant regions. Additionally, during the inference time, users can adjust a scale parameter lambda to balance subject fidelity and text alignment. Our qualitative and quantitative experiments on DreamBooth models demonstrate that MINDiff mitigates overfitting more effectively than class-specific prior-preservation loss. As our method operates entirely at inference time and does not alter the model architecture, it can be directly applied to existing DreamBooth models without re-training. Our code is available at https://github.com/seuleepy/MINDiff.

</details>


### [42] [Decoupled Audio-Visual Dataset Distillation](https://arxiv.org/abs/2511.17890)
*Wenyuan Li,Guang Li,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CV

TL;DR: DAVDD是一个基于预训练的音频-视觉数据集蒸馏框架，通过解耦表示学习和联合对齐策略解决跨模态对齐问题，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统分布匹配方法难以捕捉跨模态对齐，现有方法存在模态映射空间不一致和模态特定信息受损两大挑战。

Method: 使用多样化预训练库获取稳定模态特征，通过轻量级解耦器将特征分解为公共和私有表示，采用公共跨模态匹配和样本-分布联合对齐策略。

Result: 在多个基准测试的所有IPC设置下均达到最先进结果，证明了解耦表示学习对高质量音频-视觉数据集蒸馏的有效性。

Conclusion: DAVDD通过解耦表示学习成功解决了音频-视觉数据集蒸馏中的跨模态对齐挑战，实现了高质量的蒸馏效果。

Abstract: Audio-Visual Dataset Distillation aims to compress large-scale datasets into compact subsets while preserving the performance of the original data. However, conventional Distribution Matching (DM) methods struggle to capture intrinsic cross-modal alignment. Subsequent studies have attempted to introduce cross-modal matching, but two major challenges remain: (i) independently and randomly initialized encoders lead to inconsistent modality mapping spaces, increasing training difficulty; and (ii) direct interactions between modalities tend to damage modality-specific (private) information, thereby degrading the quality of the distilled data. To address these challenges, we propose DAVDD, a pretraining-based decoupled audio-visual distillation framework. DAVDD leverages a diverse pretrained bank to obtain stable modality features and uses a lightweight decoupler bank to disentangle them into common and private representations. To effectively preserve cross-modal structure, we further introduce Common Intermodal Matching together with a Sample-Distribution Joint Alignment strategy, ensuring that shared representations are aligned both at the sample level and the global distribution level. Meanwhile, private representations are entirely isolated from cross-modal interaction, safeguarding modality-specific cues throughout distillation. Extensive experiments across multiple benchmarks show that DAVDD achieves state-of-the-art results under all IPC settings, demonstrating the effectiveness of decoupled representation learning for high-quality audio-visual dataset distillation. Code will be released.

</details>


### [43] [CUS-GS: A Compact Unified Structured Gaussian Splatting Framework for Multimodal Scene Representation](https://arxiv.org/abs/2511.17904)
*Yuhang Ming,Chenxin Fang,Xingyuan Yu,Fan Zhang,Weichen Dai,Wanzeng Kong,Guofeng Zhang*

Main category: cs.CV

TL;DR: CUS-GS是一种紧凑的统一结构化高斯泼溅表示，通过体素化锚点结构连接多模态语义特征与结构化3D几何，在仅使用600万参数的情况下达到与最先进方法竞争的性能。


<details>
  <summary>Details</summary>
Motivation: 现有高斯泼溅方法存在语义导向方法缺乏显式3D几何建模，而结构导向方法语义抽象能力有限的问题，需要弥合这一差距。

Method: 设计体素化锚点结构构建空间支架，从基础模型提取多模态语义特征；引入多模态潜在特征分配机制统一外观、几何和语义；提出特征感知显著性评估策略动态指导锚点生长和修剪。

Result: CUS-GS在仅使用600万参数的情况下达到与最先进方法竞争的性能，比最接近的竞争对手（3500万参数）小一个数量级。

Conclusion: 该方法在性能和模型效率之间取得了出色的平衡，证明了紧凑统一表示的有效性。

Abstract: Recent advances in Gaussian Splatting based 3D scene representation have shown two major trends: semantics-oriented approaches that focus on high-level understanding but lack explicit 3D geometry modeling, and structure-oriented approaches that capture spatial structures yet provide limited semantic abstraction. To bridge this gap, we present CUS-GS, a compact unified structured Gaussian Splatting representation, which connects multimodal semantic features with structured 3D geometry. Specifically, we design a voxelized anchor structure that constructs a spatial scaffold, while extracting multimodal semantic features from a set of foundation models (e.g., CLIP, DINOv2, SEEM). Moreover, we introduce a multimodal latent feature allocation mechanism to unify appearance, geometry, and semantics across heterogeneous feature spaces, ensuring a consistent representation across multiple foundation models. Finally, we propose a feature-aware significance evaluation strategy to dynamically guide anchor growing and pruning, effectively removing redundant or invalid anchors while maintaining semantic integrity. Extensive experiments show that CUS-GS achieves competitive performance compared to state-of-the-art methods using as few as 6M parameters - an order of magnitude smaller than the closest rival at 35M - highlighting the excellent trade off between performance and model efficiency of the proposed framework.

</details>


### [44] [Rectifying Soft-Label Entangled Bias in Long-Tailed Dataset Distillation](https://arxiv.org/abs/2511.17914)
*Chenyang Jiang,Hang Zhao,Xinyu Zhang,Zhengcen Li,Qiben Shan,Shaocong Wu,Jingyong Su*

Main category: cs.CV

TL;DR: 该论文提出了ADSA（自适应软标签对齐）模块来解决长尾数据集蒸馏中的软标签偏差问题，显著提升了尾部类别的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法主要针对平衡数据集，在现实世界长尾分布下表现不佳。作者发现软标签在长尾数据集蒸馏中起关键作用，并揭示了导致性能下降的机制。

Method: 通过系统扰动数据不平衡水平识别出两个主要软标签偏差源（来自蒸馏模型和蒸馏图像），提出轻量级ADSA模块来校准这些纠缠偏差，可无缝集成到现有蒸馏流程中。

Result: 在ImageNet-1k-LT数据集上，ADSA将尾部类别准确率提升高达11.8%，整体准确率达到41.4%（EDC方法，IPC=50）。

Conclusion: ADSA为有限标签预算下的长尾数据集蒸馏提供了鲁棒且可推广的解决方案，在各种蒸馏技术中均能持续提升性能。

Abstract: Dataset distillation compresses large-scale datasets into compact, highly informative synthetic data, significantly reducing storage and training costs. However, existing research primarily focuses on balanced datasets and struggles to perform under real-world long-tailed distributions. In this work, we emphasize the critical role of soft labels in long-tailed dataset distillation and uncover the underlying mechanisms contributing to performance degradation. Specifically, we derive an imbalance-aware generalization bound for model trained on distilled dataset. We then identify two primary sources of soft-label bias, which originate from the distillation model and the distilled images, through systematic perturbation of the data imbalance levels. To address this, we propose ADSA, an Adaptive Soft-label Alignment module that calibrates the entangled biases. This lightweight module integrates seamlessly into existing distillation pipelines and consistently improves performance. On ImageNet-1k-LT with EDC and IPC=50, ADSA improves tail-class accuracy by up to 11.8% and raises overall accuracy to 41.4%. Extensive experiments demonstrate that ADSA provides a robust and generalizable solution under limited label budgets and across a range of distillation techniques. Code is available at: https://github.com/j-cyoung/ADSA_DD.git.

</details>


### [45] [Frequency-Adaptive Sharpness Regularization for Improving 3D Gaussian Splatting Generalization](https://arxiv.org/abs/2511.17918)
*Youngsik Yun,Dongjun Gu,Youngjung Uh*

Main category: cs.CV

TL;DR: 提出了频率自适应锐度正则化(FASR)方法，通过重新制定3D高斯泼溅(3DGS)训练目标，解决其在少样本场景下对新视角泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在大多数配置下表现出色，但在少样本场景中由于对稀疏观测的过拟合而缺乏对新视角的泛化能力。本文从机器学习角度重新审视3DGS优化，将新视角合成视为对未见视角的泛化问题。

Method: 提出频率自适应锐度正则化(FASR)，通过反映图像的局部频率来设置正则化权重和邻域半径，在估计局部锐度时防止新视角中的浮动伪影，同时重建SAM倾向于过度平滑的精细细节。

Result: 在具有各种配置的数据集上，该方法持续改进了广泛的基线模型。

Conclusion: FASR方法通过频率自适应的锐度正则化，有效提升了3D高斯泼溅在新视角合成任务中的泛化性能。

Abstract: Despite 3D Gaussian Splatting (3DGS) excelling in most configurations, it lacks generalization across novel viewpoints in a few-shot scenario because it overfits to the sparse observations. We revisit 3DGS optimization from a machine learning perspective, framing novel view synthesis as a generalization problem to unseen viewpoints-an underexplored direction. We propose Frequency-Adaptive Sharpness Regularization (FASR), which reformulates the 3DGS training objective, thereby guiding 3DGS to converge toward a better generalization solution. Although Sharpness-Aware Minimization (SAM) similarly reduces the sharpness of the loss landscape to improve generalization of classification models, directly employing it to 3DGS is suboptimal due to the discrepancy between the tasks. Specifically, it hinders reconstructing high-frequency details due to excessive regularization, while reducing its strength leads to under-penalizing sharpness. To address this, we reflect the local frequency of images to set the regularization weight and the neighborhood radius when estimating the local sharpness. It prevents floater artifacts in novel viewpoints and reconstructs fine details that SAM tends to oversmooth. Across datasets with various configurations, our method consistently improves a wide range of baselines. Code will be available at https://bbangsik13.github.io/FASR.

</details>


### [46] [PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning](https://arxiv.org/abs/2511.17927)
*Yingjie Ma,Xun Lin,Yong Xu,Weicheng Xie,Zitong Yu*

Main category: cs.CV

TL;DR: PA-FAS通过构建高质量扩展推理序列和答案混洗机制，解决了多模态人脸反欺骗中推理路径受限和捷径学习问题，显著提升了多模态推理准确性和跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态人脸反欺骗面临推理路径受限和捷径学习问题，监督微调加强化学习的直接应用效果不佳，需要增强推理路径并强制全面多模态分析。

Method: 提出PA-FAS方法：1）从有限标注构建高质量扩展推理序列，丰富推理路径；2）在监督微调阶段引入答案混洗机制，强制模型进行全面的多模态分析。

Result: PA-FAS显著提高了多模态推理准确性和跨域泛化能力，更好地统一了多模态融合、泛化性和可解释性。

Conclusion: PA-FAS通过增强推理路径和防止捷径学习，有效解决了多模态人脸反欺骗中的关键挑战，为可信赖的人脸反欺骗系统提供了统一解决方案。

Abstract: Face anti-spoofing (FAS) has recently advanced in multimodal fusion, cross-domain generalization, and interpretability. With large language models and reinforcement learning (RL), strategy-based training offers new opportunities to jointly model these aspects. However, multimodal reasoning is more complex than unimodal reasoning, requiring accurate feature representation and cross-modal verification while facing scarce, high-quality annotations, which makes direct application of RL sub-optimal. We identify two key limitations of supervised fine-tuning plus RL (SFT+RL) for multimodal FAS: (1) limited multimodal reasoning paths restrict the use of complementary modalities and shrink the exploration space after SFT, weakening the effect of RL; and (2) mismatched single-task supervision versus diverse reasoning paths causes reasoning confusion, where models may exploit shortcuts by mapping images directly to answers and ignoring the intended reasoning. To address this, we propose PA-FAS, which enhances reasoning paths by constructing high-quality extended reasoning sequences from limited annotations, enriching paths and relaxing exploration constraints. We further introduce an answer-shuffling mechanism during SFT to force comprehensive multimodal analysis instead of using superficial cues, thereby encouraging deeper reasoning and mitigating shortcut learning. PA-FAS significantly improves multimodal reasoning accuracy and cross-domain generalization, and better unifies multimodal fusion, generalization, and interpretability for trustworthy FAS.

</details>


### [47] [MambaTAD: When State-Space Models Meet Long-Range Temporal Action Detection](https://arxiv.org/abs/2511.17929)
*Hui Lu,Yi Yu,Shijian Lu,Deepu Rajan,Boon Poh Ng,Alex C. Kot,Xudong Jiang*

Main category: cs.CV

TL;DR: MambaTAD是一个基于结构化状态空间模型的时序动作检测模型，通过引入对角线掩码双向状态空间模块和全局特征融合头，解决了长跨度动作检测中的上下文衰减和自元素冲突问题。


<details>
  <summary>Details</summary>
Motivation: 传统的时序动作检测方法在处理长跨度动作实例时缺乏全局感知和高效检测头，而现有的结构化状态空间模型在时序动作检测中面临上下文衰减和自元素冲突的挑战。

Method: 提出MambaTAD模型，包含对角线掩码双向状态空间模块促进全局特征融合，以及全局特征融合头进行渐进式多粒度特征检测，采用端到端单阶段检测方式，通过状态空间时序适配器降低参数和计算成本。

Result: 在多个公共基准测试中，MambaTAD实现了优越的时序动作检测性能。

Conclusion: MambaTAD通过创新的状态空间模型设计，有效解决了时序动作检测中的长跨度动作检测难题，在保持线性计算复杂度的同时实现了优异的检测性能。

Abstract: Temporal Action Detection (TAD) aims to identify and localize actions by determining their starting and ending frames within untrimmed videos. Recent Structured State-Space Models such as Mamba have demonstrated potential in TAD due to their long-range modeling capability and linear computational complexity. On the other hand, structured state-space models often face two key challenges in TAD, namely, decay of temporal context due to recursive processing and self-element conflict during global visual context modeling, which become more severe while handling long-span action instances. Additionally, traditional methods for TAD struggle with detecting long-span action instances due to a lack of global awareness and inefficient detection heads. This paper presents MambaTAD, a new state-space TAD model that introduces long-range modeling and global feature detection capabilities for accurate temporal action detection. MambaTAD comprises two novel designs that complement each other with superior TAD performance. First, it introduces a Diagonal-Masked Bidirectional State-Space (DMBSS) module which effectively facilitates global feature fusion and temporal action detection. Second, it introduces a global feature fusion head that refines the detection progressively with multi-granularity features and global awareness. In addition, MambaTAD tackles TAD in an end-to-end one-stage manner using a new state-space temporal adapter(SSTA) which reduces network parameters and computation cost with linear complexity. Extensive experiments show that MambaTAD achieves superior TAD performance consistently across multiple public benchmarks.

</details>


### [48] [UniRSCD: A Unified Novel Architectural Paradigm for Remote Sensing Change Detection](https://arxiv.org/abs/2511.17930)
*Yuan Qu,Zhipeng Zhang,Chaojun Xu,Qiao Wan,Mengying Xie,Yuzeng Chen,Zhenqi Liu,Yanfei Zhong*

Main category: cs.CV

TL;DR: 本文提出了一种统一的遥感变化检测框架UniRSCD，基于状态空间模型，通过频率变化提示生成器作为统一编码器，消除了对不同任务设计专门解码器的需求，能够适应多种变化检测任务并取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感变化检测方法需要大量专家知识来设计专门解码器以补偿编码过程中的信息损失，这不仅在选择最优模型时引入不确定性，还限制了架构的通用性。

Method: 基于状态空间模型骨干，引入频率变化提示生成器作为统一编码器，动态扫描双时相全局上下文信息，集成高频细节和低频整体信息；通过统一解码器和预测头建立共享表示空间，实现层次特征交互和任务自适应输出映射。

Result: 实验结果表明，该架构能够适应多种变化检测任务，在五个数据集上取得领先性能，包括二进制变化数据集LEVIR-CD、语义变化数据集SECOND和建筑物损伤评估数据集xBD。

Conclusion: UniRSCD框架成功将二进制变化检测、语义变化检测等不同任务集成到统一架构中，适应了不同变化检测任务的输出粒度需求，实现了通用性和高性能的统一。

Abstract: In recent years, remote sensing change detection has garnered significant attention due to its critical role in resource monitoring and disaster assessment. Change detection tasks exist with different output granularities such as BCD, SCD, and BDA. However, existing methods require substantial expert knowledge to design specialized decoders that compensate for information loss during encoding across different tasks. This not only introduces uncertainty into the process of selecting optimal models for abrupt change scenarios (such as disaster outbreaks) but also limits the universality of these architectures. To address these challenges, this paper proposes a unified, general change detection framework named UniRSCD. Building upon a state space model backbone, we introduce a frequency change prompt generator as a unified encoder. The encoder dynamically scans bitemporal global context information while integrating high-frequency details with low-frequency holistic information, thereby eliminating the need for specialized decoders for feature compensation. Subsequently, the unified decoder and prediction head establish a shared representation space through hierarchical feature interaction and task-adaptive output mapping. This integrating various tasks such as binary change detection and semantic change detection into a unified architecture, thereby accommodating the differing output granularity requirements of distinct change detection tasks. Experimental results demonstrate that the proposed architecture can adapt to multiple change detection tasks and achieves leading performance on five datasets, including the binary change dataset LEVIR-CD, the semantic change dataset SECOND, and the building damage assessment dataset xBD.

</details>


### [49] [Novel View Synthesis from A Few Glimpses via Test-Time Natural Video Completion](https://arxiv.org/abs/2511.17932)
*Yan Xu,Yixing Wang,Stella X. Yu*

Main category: cs.CV

TL;DR: 提出了一种零样本、生成引导的稀疏输入新视角合成框架，通过预训练视频扩散模型生成伪视图来增强3D高斯溅射的场景重建，无需场景特定训练。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏输入新视角合成问题，不仅填补空间间隙，还要完成自然视频序列，利用预训练视频扩散模型的先验知识来生成合理的中间视图。

Method: 采用测试时自然视频补全方法，使用不确定性感知机制生成空间一致的伪视图，通过迭代反馈循环让3D几何和2D视图合成相互促进。

Result: 在LLFF、DTU、DL3DV和MipNeRF-360数据集上，该方法在极端稀疏条件下显著优于强3D-GS基线方法。

Conclusion: 该方法能够从稀疏输入生成连贯、高保真的渲染结果，无需任何场景特定训练或微调。

Abstract: Given just a few glimpses of a scene, can you imagine the movie playing out as the camera glides through it? That's the lens we take on \emph{sparse-input novel view synthesis}, not only as filling spatial gaps between widely spaced views, but also as \emph{completing a natural video} unfolding through space.
  We recast the task as \emph{test-time natural video completion}, using powerful priors from \emph{pretrained video diffusion models} to hallucinate plausible in-between views. Our \emph{zero-shot, generation-guided} framework produces pseudo views at novel camera poses, modulated by an \emph{uncertainty-aware mechanism} for spatial coherence. These synthesized frames densify supervision for \emph{3D Gaussian Splatting} (3D-GS) for scene reconstruction, especially in under-observed regions. An iterative feedback loop lets 3D geometry and 2D view synthesis inform each other, improving both the scene reconstruction and the generated views.
  The result is coherent, high-fidelity renderings from sparse inputs \emph{without any scene-specific training or fine-tuning}. On LLFF, DTU, DL3DV, and MipNeRF-360, our method significantly outperforms strong 3D-GS baselines under extreme sparsity.

</details>


### [50] [V2X-RECT: An Efficient V2X Trajectory Prediction Framework via Redundant Interaction Filtering and Tracking Error Correction](https://arxiv.org/abs/2511.17941)
*Xiangyan Kong,Xuecheng Wu,Xiongwei Zhao,Xiaodong Li,Yunyun Shi,Gang Wang,Dingkang Yang,Yang Liu,Hong Chen,Yulong Gao*

Main category: cs.CV

TL;DR: V2X-RECT是一个针对高密度交通场景的轨迹预测框架，通过多源身份匹配校正、交通信号引导的交互模块和局部时空坐标编码，解决了目标身份切换、冗余交互和历史轨迹重复编码等问题，提升了预测精度和推理效率。


<details>
  <summary>Details</summary>
Motivation: 在密集交通场景中，频繁的目标身份切换阻碍了跨视角关联和融合，多源信息在编码阶段产生冗余交互，传统车辆中心编码导致大量重复的历史轨迹特征编码，影响实时推理性能。

Method: 1. 多源身份匹配和校正模块：利用多视角时空关系实现稳定一致的目标关联；2. 交通信号引导交互模块：编码交通灯变化趋势，准确过滤关键交互车辆；3. 局部时空坐标编码：实现历史轨迹和地图特征的可重用性，支持并行解码。

Result: 在V2X-Seq和V2X-Traj数据集上的广泛实验表明，V2X-RECT相比SOTA方法取得了显著改进，同时在不同交通密度下增强了鲁棒性和推理效率。

Conclusion: V2X-RECT通过增强数据关联一致性、减少冗余交互和重用历史信息，实现了更高效准确的轨迹预测，特别适用于高密度交通环境。

Abstract: V2X prediction can alleviate perception incompleteness caused by limited line of sight through fusing trajectory data from infrastructure and vehicles, which is crucial to traffic safety and efficiency. However, in dense traffic scenarios, frequent identity switching of targets hinders cross-view association and fusion. Meanwhile, multi-source information tends to generate redundant interactions during the encoding stage, and traditional vehicle-centric encoding leads to large amounts of repetitive historical trajectory feature encoding, degrading real-time inference performance. To address these challenges, we propose V2X-RECT, a trajectory prediction framework designed for high-density environments. It enhances data association consistency, reduces redundant interactions, and reuses historical information to enable more efficient and accurate prediction. Specifically, we design a multi-source identity matching and correction module that leverages multi-view spatiotemporal relationships to achieve stable and consistent target association, mitigating the adverse effects of mismatches on trajectory encoding and cross-view feature fusion. Then we introduce traffic signal-guided interaction module, encoding trend of traffic light changes as features and exploiting their role in constraining spatiotemporal passage rights to accurately filter key interacting vehicles, while capturing the dynamic impact of signal changes on interaction patterns. Furthermore, a local spatiotemporal coordinate encoding enables reusable features of historical trajectories and map, supporting parallel decoding and significantly improving inference efficiency. Extensive experimental results across V2X-Seq and V2X-Traj datasets demonstrate that our V2X-RECT achieves significant improvements compared to SOTA methods, while also enhancing robustness and inference efficiency across diverse traffic densities.

</details>


### [51] [SciEducator: Scientific Video Understanding and Educating via Deming-Cycle Multi-Agent System](https://arxiv.org/abs/2511.17943)
*Zhiyu Xu,Weilong Yan,Yufei Shi,Xin Meng,Tao He,Huiping Zhuang,Ming Li,Hehe Fan*

Main category: cs.CV

TL;DR: SciEducator是一个基于戴明循环的自进化多智能体系统，用于科学视频理解和教育，在专业基准测试中显著优于现有MLLM和视频智能体。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型和视频智能体在需要外部专业知识和严格逐步推理的科学视频理解与教育领域表现不佳，需要专门解决方案。

Method: 基于戴明循环的Plan-Do-Study-Act理念设计自进化推理和反馈机制，能够生成包含文本指导、视觉指南、音频叙述和交互参考的多模态教育内容。

Result: 在包含500个专家验证科学QA对的SciVBench基准测试中，SciEducator显著优于领先的闭源MLLM（如Gemini、GPT-4o）和最先进的视频智能体。

Conclusion: SciEducator为科学视频理解和教育建立了新范式，通过自进化多智能体系统有效解决了专业领域知识整合和推理的挑战。

Abstract: Recent advancements in multimodal large language models (MLLMs) and video agent systems have significantly improved general video understanding. However, when applied to scientific video understanding and educating, a domain that demands external professional knowledge integration and rigorous step-wise reasoning, existing approaches often struggle. To bridge this gap, we propose SciEducator, the first iterative self-evolving multi-agent system for scientific video comprehension and education. Rooted in the classical Deming Cycle from management science, our design reformulates its Plan-Do-Study-Act philosophy into a self-evolving reasoning and feedback mechanism, which facilitates the interpretation of intricate scientific activities in videos. Moreover, SciEducator can produce multimodal educational content tailored to specific scientific processes, including textual instructions, visual guides, audio narrations, and interactive references. To support evaluation, we construct SciVBench, a benchmark consisting of 500 expert-verified and literature-grounded science QA pairs across five categories, covering physical, chemical, and everyday phenomena. Extensive experiments demonstrate that SciEducator substantially outperforms leading closed-source MLLMs (e.g., Gemini, GPT-4o) and state-of-the-art video agents on the benchmark, establishing a new paradigm for the community.

</details>


### [52] [Test-Time Temporal Sampling for Efficient MLLM Video Understanding](https://arxiv.org/abs/2511.17945)
*Kaibin Wang,Mingbao Lin*

Main category: cs.CV

TL;DR: 提出T3S方法，一种无需训练、即插即用的推理包装器，通过生成多个短而多样的视频标记子序列来高效处理长视频，在保持精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 处理长视频时，多模态大语言模型的自注意力机制计算复杂度呈二次方增长，导致高计算需求和慢推理速度。现有方法存在精度损失、需要额外训练或降低推理速度等问题。

Method: T3S利用时空冗余性，在推理时生成多个短而多样的视频标记子序列，将它们打包在一个前向传播中，并聚合它们的预测结果。

Result: 在长视频理解基准测试中，T3S将精度提升高达3.1%，并将首个标记延迟减少2.04倍，且集成工作量最小。

Conclusion: T3S将视频冗余性转化为计算优势，为长视频理解提供了可扩展的解决方案，无需模型修改或微调，与多种预训练MLLMs兼容。

Abstract: Processing long videos with multimodal large language models (MLLMs) poses a significant computational challenge, as the model's self-attention mechanism scales quadratically with the number of video tokens, resulting in high computational demand and slow inference speed. Current solutions, such as rule-based sub-sampling, learned frame selector, or memory-based summarization, often introduce their own trade-offs: they compromise accuracy, necessitate additional training, or decrease inference speed. In this paper, we propose Test-Time Temporal Sampling (T3S), a training-free, plug-and-play inference wrapper that enables MLLMs to process long videos both efficiently and effectively. T3S exploits spatiotemporal redundancy by generating multiple short and diverse subsequences of video tokens at inference time, packing them within a single forward pass, and aggregating their predictions. This multi-subsequence formulation broadens visual coverage while reducing the computational cost of self-attention from $O(L^2)$ to $O(\sum_{i=1}^m α_i^2L^2)$, where $\sum_{i=1}^m α_i^2 < 1$. Extensive experiments on long video understanding benchmarks demonstrate that T3S improves accuracy by up to 3.1% and reduces first token delay by $2.04\times$, all with minimal integration effort. Our approach operates entirely at inference time, requires no model modifications or fine-tuning, and is compatible with a wide range of pretrained MLLMs. T3S turns video redundancy into a computational advantage, offering a scalable solution for long-video understanding. The code is available at https://github.com/kaibinwang3/T3S.

</details>


### [53] [Multi-speaker Attention Alignment for Multimodal Social Interaction](https://arxiv.org/abs/2511.17952)
*Liangyang Ouyang,Yifei Huang,Mingfang Zhang,Caixin Kang,Ryosuke Furuta,Yoichi Sato*

Main category: cs.CV

TL;DR: 本文提出了一种多模态多说话人注意力对齐方法，通过在现有MLLMs中注入自适应社交感知注意力偏置，解决了多说话人场景中视觉和文本标记缺乏说话人一致对齐的问题，从而提升了多党社交推理能力。


<details>
  <summary>Details</summary>
Motivation: 多说话人场景中，现有MLLMs的视觉和文本标记缺乏说话人一致对齐，导致跨模态注意力较弱，影响社交任务表现。

Method: 提出动态跨模态头选择和自适应社交感知注意力偏置方法，通过分析现有注意力模式和说话人位置，在不引入可训练参数或架构改变的情况下强化说话人视觉表示与其话语的对齐。

Result: 在三个MLLMs和三个基准测试上的实验表明，该方法在四个社交任务中提升了模型能力并取得了最先进的结果，注意力可视化证实了方法能成功聚焦于说话人相关区域。

Conclusion: 该方法有效解决了多说话人场景中的跨模态对齐问题，使MLLMs能够进行更稳健的多党社交推理。

Abstract: Understanding social interaction in video requires reasoning over a dynamic interplay of verbal and non-verbal cues: who is speaking, to whom, and with what gaze or gestures. While Multimodal Large Language Models (MLLMs) are natural candidates, simply adding visual inputs yields surprisingly inconsistent gains on social tasks. Our quantitative analysis of cross-modal attention inside state-of-the-art MLLMs reveals a core failure mode: in multi-speaker scenes, visual and textual tokens lack speaker-consistent alignment, exhibiting substantially weaker cross-modal attention than in object-centric images. To address this, we propose a multimodal multi-speaker attention alignment method that can be integrated into existing MLLMs. First, we introduce dynamic cross-modal head selection to identify attention heads most responsible for grounding. Then, an adaptive social-aware attention bias, computed from existing attention patterns and speaker locations, is injected into the attention mechanism. This bias reinforces alignment between a speaker's visual representation and their utterances without introducing trainable parameters or architectural changes. We integrate our method into three distinct MLLMs (LLaVA-NeXT-Video, Qwen2.5-VL, and InternVL3) and evaluate on three benchmarks (TVQA+, MMSI, OnlineMMSI). Across four social tasks, results demonstrate that our approach improves the ability of MLLMs and achieves state-of-the-art results. Attention visualizations confirm our method successfully focuses the model on speaker-relevant regions, enabling more robust multi-party social reasoning. Our implementation and model will be available at https://github.com/ut-vision/SocialInteraction.

</details>


### [54] [HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation](https://arxiv.org/abs/2511.17958)
*Yulong Shi,Jiapeng Li,Lin Qi*

Main category: cs.CV

TL;DR: HEAL是一个新颖的源自由无监督域自适应框架，通过分层去噪、边缘引导选择、尺寸感知融合和无学习特性来解决域偏移问题，在跨模态实验中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决临床数据隐私和存储限制带来的挑战，在无法访问源域数据且目标域无标签监督的情况下实现域自适应。

Method: 提出HEAL框架，整合分层去噪、边缘引导选择、尺寸感知融合和无学习特性来适应域偏移。

Result: 大规模跨模态实验表明，该方法优于现有的SFUDA方法，实现了最先进的性能。

Conclusion: HEAL框架有效解决了源自由无监督域自适应中的关键挑战，在医学图像分析领域具有重要应用价值。

Abstract: Growing demands for clinical data privacy and storage constraints have spurred advances in Source Free Unsupervised Domain Adaptation (SFUDA). SFUDA addresses the domain shift by adapting models from the source domain to the unseen target domain without accessing source data, even when target-domain labels are unavailable. However, SFUDA faces significant challenges: the absence of source domain data and label supervision in the target domain due to source free and unsupervised settings. To address these issues, we propose HEAL, a novel SFUDA framework that integrates Hierarchical denoising, Edge-guided selection, size-Aware fusion, and Learning-free characteristic. Large-scale cross-modality experiments demonstrate that our method outperforms existing SFUDA approaches, achieving state-of-the-art (SOTA) performance. The source code is publicly available at: https://github.com/derekshiii/HEAL.

</details>


### [55] [VITAL: Vision-Encoder-centered Pre-training for LMMs in Visual Quality Assessment](https://arxiv.org/abs/2511.17962)
*Ziheng Jia,Linhan Cao,Jinliang Han,Zicheng Zhang,Jiaying Qian,Jiarui Wang,Zijian Chen,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: 本文提出了一种视觉编码器中心的生成预训练流程，开发了VITAL-Series大型多模态模型，通过机器执行的标注审查范式构建了450万视觉语言对数据集，采用多任务训练增强模型的定量评分精度和质量解释能力，实现了高效的模型库扩展。


<details>
  <summary>Details</summary>
Motivation: 现有视觉质量评估大型多模态模型通常专注于单一任务并依赖全参数微调，容易在特定模态或任务类型上过拟合，限制了泛化能力和可迁移性。

Method: 采用机器执行的标注审查范式构建大规模训练数据集；使用多任务训练工作流同时增强定量评分精度和质量解释能力；基于视觉编码器实现高效的模型库扩展。

Result: 构建了迄今为止最大的视觉质量评估训练数据集（450万视觉语言对）；模型库表现出强大的零样本性能；每个配对解码器仅需使用不到预训练数据1/1000的快速预热即可达到与完全训练对应模型相当的性能。

Conclusion: 该工作为推进视觉质量评估基础大型多模态模型奠定了基石。

Abstract: Developing a robust visual quality assessment (VQualA) large multi-modal model (LMM) requires achieving versatility, powerfulness, and transferability.
  However, existing VQualA LMMs typically focus on a single task and rely on full-parameter fine-tuning, which makes them prone to overfitting on specific modalities or task types, thereby limiting their generalization capacity and transferability. To address this, we propose a vision-encoder-centered generative pre-training pipeline and develop the VITAL-Series LMMs. (1) We adopt a machine-executed annotation-scrutiny paradigm, constructing over 4.5M vision-language (VL) pairs-the largest VQualA training dataset to date. (2) We employ a multi-task training workflow that simultaneously enhances the model's quantitative scoring precision and strengthens its capability for quality interpretation across both image and video modalities. (3) Building upon the vision encoder, we realize an efficient model zoo extension: the model zoo exhibits strong zero-shot performance, and each paired decoder requires only a swift warm-up using less than 1/1000 of the pre-training data to achieve performance comparable to the fully trained counterpart. Overall, our work lays a cornerstone for advancing toward the foundation LMM for VQualA.

</details>


### [56] [X-ReID: Multi-granularity Information Interaction for Video-Based Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2511.17964)
*Chenyang Yu,Xuehu Liu,Pingping Zhang,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为X-ReID的新型跨模态特征学习框架，用于解决基于视频的可见光-红外行人重识别任务，通过跨模态原型协作和多粒度信息交互来减少模态差异并增强时空建模。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉语言模型在检索任务中表现出色，但在基于视频的可见光-红外行人重识别任务中潜力尚未充分挖掘，主要挑战是缩小模态差距和利用视频序列中的时空信息。

Method: 提出X-ReID框架：1）跨模态原型协作（CPC）对齐和整合不同模态特征；2）多粒度信息交互（MII）包含相邻帧的短期交互、长期跨帧信息融合和跨模态特征对齐；3）整合多粒度信息获得鲁棒的序列级表示。

Result: 在两个大规模VVI-ReID基准数据集（HITSZ-VCM和BUPTCampus）上的广泛实验表明，该方法优于现有最先进方法。

Conclusion: X-ReID框架通过跨模态原型协作和多粒度信息交互，有效解决了VVI-ReID任务中的模态差距和时空建模问题，在基准数据集上取得了优越性能。

Abstract: Large-scale vision-language models (e.g., CLIP) have recently achieved remarkable performance in retrieval tasks, yet their potential for Video-based Visible-Infrared Person Re-Identification (VVI-ReID) remains largely unexplored. The primary challenges are narrowing the modality gap and leveraging spatiotemporal information in video sequences. To address the above issues, in this paper, we propose a novel cross-modality feature learning framework named X-ReID for VVI-ReID. Specifically, we first propose a Cross-modality Prototype Collaboration (CPC) to align and integrate features from different modalities, guiding the network to reduce the modality discrepancy. Then, a Multi-granularity Information Interaction (MII) is designed, incorporating short-term interactions from adjacent frames, long-term cross-frame information fusion, and cross-modality feature alignment to enhance temporal modeling and further reduce modality gaps. Finally, by integrating multi-granularity information, a robust sequence-level representation is achieved. Extensive experiments on two large-scale VVI-ReID benchmarks (i.e., HITSZ-VCM and BUPTCampus) demonstrate the superiority of our method over state-of-the-art methods. The source code is released at https://github.com/AsuradaYuci/X-ReID.

</details>


### [57] [Adversarial Pseudo-replay for Exemplar-free Class-incremental Learning](https://arxiv.org/abs/2511.17973)
*Hiroto Honda*

Main category: cs.CV

TL;DR: 本文提出了一种无示例的类增量学习方法APR，通过对抗性攻击扰动新任务图像来合成伪重放图像，解决存储限制和隐私问题下的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 解决无示例类增量学习中的可塑性-稳定性困境，避免存储先前任务图像带来的存储约束和隐私问题。

Method: 使用对抗性攻击在新任务图像上合成伪重放图像，以增强的旧类均值原型为目标进行知识蒸馏防止语义漂移，并通过学习转移矩阵校准协方差矩阵。

Result: 在标准EFCIL基准测试的冷启动设置中实现了最先进的性能，有效平衡了稳定性和可塑性。

Conclusion: APR方法成功解决了无示例类增量学习中的灾难性遗忘问题，无需存储任何重放样本即可实现知识保留。

Abstract: Exemplar-free class-incremental learning (EFCIL) aims to retain old knowledge acquired in the previous task while learning new classes, without storing the previous images due to storage constraints or privacy concerns. In EFCIL, the plasticity-stability dilemma, learning new tasks versus catastrophic forgetting, is a significant challenge, primarily due to the unavailability of images from earlier tasks. In this paper, we introduce adversarial pseudo-replay (APR), a method that perturbs the images of the new task with adversarial attack, to synthesize the pseudo-replay images online without storing any replay samples. During the new task training, the adversarial attack is conducted on the new task images with augmented old class mean prototypes as targets, and the resulting images are used for knowledge distillation to prevent semantic drift. Moreover, we calibrate the covariance matrices to compensate for the semantic drift after each task, by learning a transfer matrix on the pseudo-replay samples. Our method reconciles stability and plasticity, achieving state-of-the-art on challenging cold-start settings of the standard EFCIL benchmarks.

</details>


### [58] [Plan-X: Instruct Video Generation via Semantic Planning](https://arxiv.org/abs/2511.17986)
*Lun Huang,You Xie,Hongyi Xu,Tianpei Gu,Chenxu Zhang,Guoxian Song,Zenan Li,Xiaochen Zhao,Linjie Luo,Guillermo Sapiro*

Main category: cs.CV

TL;DR: Plan-X是一个通过显式语义规划来指导视频生成的框架，包含一个可学习的多模态语言模型作为语义规划器，生成时空语义token来指导扩散模型生成符合指令的视频。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在视觉合成中表现出色，但在高级语义推理和长时程规划方面存在局限，导致视觉幻觉和与用户指令不对齐的问题，特别是在复杂场景理解、人-物交互、多阶段动作和上下文运动推理等场景中。

Method: 提出Plan-X框架，核心是语义规划器——一个可学习的多模态语言模型，从文本提示和视觉上下文推理用户意图，自回归生成基于文本的时空语义token序列，作为视频扩散模型的结构化"语义草图"。

Result: 大量实验表明，该框架显著减少了视觉幻觉，实现了与多模态上下文一致的细粒度、指令对齐的视频生成。

Conclusion: Plan-X有效整合了语言模型在多模态上下文推理和规划方面的优势，以及扩散模型在逼真视频合成方面的优势，解决了复杂场景下的语义对齐问题。

Abstract: Diffusion Transformers have demonstrated remarkable capabilities in visual synthesis, yet they often struggle with high-level semantic reasoning and long-horizon planning. This limitation frequently leads to visual hallucinations and mis-alignments with user instructions, especially in scenarios involving complex scene understanding, human-object interactions, multi-stage actions, and in-context motion reasoning. To address these challenges, we propose Plan-X, a framework that explicitly enforces high-level semantic planning to instruct video generation process. At its core lies a Semantic Planner, a learnable multimodal language model that reasons over the user's intent from both text prompts and visual context, and autoregressively generates a sequence of text-grounded spatio-temporal semantic tokens. These semantic tokens, complementary to high-level text prompt guidance, serve as structured "semantic sketches" over time for the video diffusion model, which has its strength at synthesizing high-fidelity visual details. Plan-X effectively integrates the strength of language models in multimodal in-context reasoning and planning, together with the strength of diffusion models in photorealistic video synthesis. Extensive experiments demonstrate that our framework substantially reduces visual hallucinations and enables fine-grained, instruction-aligned video generation consistent with multimodal context.

</details>


### [59] [SD-PSFNet: Sequential and Dynamic Point Spread Function Network for Image Deraining](https://arxiv.org/abs/2511.17993)
*Jiayu Wang,Haoyu Bian,Haoran Sun,Shaoning Zeng*

Main category: cs.CV

TL;DR: 提出SD-PSFNet方法，通过多阶段图像恢复架构结合点扩散函数机制，动态模拟雨条纹光学特性，实现有效的雨背景分离和细节恢复。


<details>
  <summary>Details</summary>
Motivation: 图像去雨对视觉应用至关重要，但面临雨的多尺度物理特性及其与场景耦合的复杂性挑战。

Method: 采用三阶段级联序列恢复架构，利用学习PSF机制动态模拟雨条纹光学特性，结合自适应门控融合实现跨阶段特征集成。

Result: 在Rain100H上达到33.12dB/0.9371，RealRain-1k-L上达到42.28dB/0.9872，RealRain-1k-H上达到41.08dB/0.9838的先进指标。

Conclusion: SD-PSFNet在复杂场景和密集降雨条件下表现出色，为图像去雨提供了新的物理感知方法。

Abstract: Image deraining is crucial for vision applications but is challenged by the complex multi-scale physics of rain and its coupling with scenes. To address this challenge, a novel approach inspired by multi-stage image restoration is proposed, incorporating Point Spread Function (PSF) mechanisms to reveal the image degradation process while combining dynamic physical modeling with sequential feature fusion transfer, named SD-PSFNet. Specifically, SD-PSFNet employs a sequential restoration architecture with three cascaded stages, allowing multiple dynamic evaluations and refinements of the degradation process estimation. The network utilizes components with learned PSF mechanisms to dynamically simulate rain streak optics, enabling effective rain-background separation while progressively enhancing outputs through novel PSF components at each stage. Additionally, SD-PSFNet incorporates adaptive gated fusion for optimal cross-stage feature integration, enabling sequential refinement from coarse rain removal to fine detail restoration. Our model achieves state-of-the-art PSNR/SSIM metrics on Rain100H (33.12dB/0.9371), RealRain-1k-L (42.28dB/0.9872), and RealRain-1k-H (41.08dB/0.9838). In summary, SD-PSFNet demonstrates excellent capability in complex scenes and dense rainfall conditions, providing a new physics-aware approach to image deraining.

</details>


### [60] [Is Complete Labeling Necessary? Understanding Active Learning in Longitudinal Medical Imaging](https://arxiv.org/abs/2511.18007)
*Siteng Ma,Honghui Du,Prateek Mathur,Brendan S. Kelly,Ronan P. Killeen,Aonghus Lawlor,Ruihai Dong*

Main category: cs.CV

TL;DR: 提出了一种专门用于纵向医学影像的深度主动学习框架LMI-AL，通过配对和差分基线及随访3D图像的2D切片，仅需标注不到8%的数据即可达到全标注数据集的性能水平。


<details>
  <summary>Details</summary>
Motivation: 纵向医学影像标注成本高且耗时，现有深度主动学习方法主要针对静态任务，无法直接应用于需要识别多图像间细微差异的变化检测任务。

Method: LMI-AL框架将基线和随访3D图像的所有2D切片进行配对和差分，使用深度主动学习迭代选择最具信息量的图像对进行标注，训练深度学习模型。

Result: 实验结果表明，仅标注不到8%的数据，LMI-AL就能达到与全标注数据集训练模型相当的性能。

Conclusion: LMI-AL为纵向医学影像变化检测提供了一种高效的主动学习方法，显著降低了标注成本，代码已开源。

Abstract: Detecting changes in longitudinal medical imaging using deep learning requires a substantial amount of accurately labeled data. However, labeling these images is notably more costly and time-consuming than labeling other image types, as it requires labeling across various time points, where new lesions can be minor, and subtle changes are easily missed. Deep Active Learning (DAL) has shown promise in minimizing labeling costs by selectively querying the most informative samples, but existing studies have primarily focused on static tasks like classification and segmentation. Consequently, the conventional DAL approach cannot be directly applied to change detection tasks, which involve identifying subtle differences across multiple images. In this study, we propose a novel DAL framework, named Longitudinal Medical Imaging Active Learning (LMI-AL), tailored specifically for longitudinal medical imaging. By pairing and differencing all 2D slices from baseline and follow-up 3D images, LMI-AL iteratively selects the most informative pairs for labeling using DAL, training a deep learning model with minimal manual annotation. Experimental results demonstrate that, with less than 8% of the data labeled, LMI-AL can achieve performance comparable to models trained on fully labeled datasets. We also provide a detailed analysis of the method's performance, as guidance for future research. The code is publicly available at https://github.com/HelenMa9998/Longitudinal_AL.

</details>


### [61] [RoadBench: Benchmarking MLLMs on Fine-Grained Spatial Understanding and Reasoning under Urban Road Scenarios](https://arxiv.org/abs/2511.18011)
*Jun Zhang,Jie Feng,Long Chen,Junhui Wang,Zhicheng Liu,Depeng Jin,Yong Li*

Main category: cs.CV

TL;DR: RoadBench是一个针对多模态大语言模型在复杂城市场景中细粒度空间理解和推理能力的系统性基准测试，包含6个任务和9,121个测试案例，评估结果显示现有MLLMs在此领域存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 填补多模态大语言模型在复杂城市场景中细粒度空间理解和推理能力评估的空白，以道路标线为典型示例，评估MLLMs在城市交通系统中的空间认知能力。

Method: 提出RoadBench基准测试，使用BEV和FPV图像输入，包含6个任务构成的系统性评估框架，从局部空间范围理解到全局推理，测试识别、联合理解和推理能力。

Result: 评估了14个主流MLLMs，发现RoadBench对MLLMs具有挑战性，现有模型在城市场景的细粒度空间理解和推理能力存在显著缺陷，某些任务表现甚至低于基于规则或随机选择的基线。

Conclusion: RoadBench基准测试及其发现将有助于全面推动MLLMs空间理解能力的发展，揭示了现有模型在复杂城市场景中的局限性。

Abstract: Multimodal large language models (MLLMs) have demonstrated powerful capabilities in general spatial understanding and reasoning. However, their fine-grained spatial understanding and reasoning capabilities in complex urban scenarios have not received significant attention in the fields of both research and industry. To fill this gap, we focus primarily on road markings as a typical example of fine-grained spatial elements under urban scenarios, given the essential role of the integrated road traffic network they form within cities. Around road markings and urban traffic systems, we propose RoadBench, a systematic benchmark that comprehensively evaluates MLLMs' fine-grained spatial understanding and reasoning capabilities using BEV and FPV image inputs. This benchmark comprises six tasks consisting of 9,121 strictly manually verified test cases. These tasks form a systematic evaluation framework that bridges understanding at local spatial scopes to global reasoning. They not only test MLLMs' capabilities in recognition, joint understanding, and reasoning but also assess their ability to integrate image information with domain knowledge. After evaluating 14 mainstream MLLMs, we confirm that RoadBench is a challenging benchmark for MLLMs while revealing significant shortcomings in existing MLLMs' fine-grained spatial understanding and reasoning capabilities within urban scenarios. In certain tasks, their performance even falls short of simple rule-based or random selection baselines. These findings, along with RoadBench itself, will contribute to the comprehensive advancement of spatial understanding capabilities for MLLMs. The benchmark code, example datasets, and raw evaluation results are available in the supplementary material.

</details>


### [62] [State and Scene Enhanced Prototypes for Weakly Supervised Open-Vocabulary Object Detection](https://arxiv.org/abs/2511.18012)
*Jiaying Zhou,Qingchao Chen*

Main category: cs.CV

TL;DR: 本文提出两种互补的原型增强策略来解决弱监督开放词汇目标检测中的关键挑战：状态增强语义原型（SESP）和场景增强伪原型（SAPP），通过生成状态感知文本描述和引入上下文语义，显著提升了语义原型的丰富性和视觉-文本对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有语义原型是静态且有限的，无法捕捉由不同物体状态引起的丰富类内视觉变化；标准伪框生成存在视觉区域提案（包含上下文）与以物体为中心的文本嵌入之间的语义不匹配问题。

Method: 提出SESP生成状态感知文本描述来捕捉多样化的物体外观；引入SAPP结合上下文语义并使用软对齐机制促进上下文一致的视觉-文本表示。

Result: 通过整合SESP和SAPP，有效增强了语义原型的丰富性和视觉-文本对齐，实现了显著改进。

Conclusion: 所提出的两种原型增强策略能够有效解决弱监督开放词汇目标检测中的关键挑战，提升检测性能。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to generalize object recognition to novel categories, while Weakly Supervised OVOD (WS-OVOD) extends this by combining box-level annotations with image-level labels. Despite recent progress, two critical challenges persist in this setting. First, existing semantic prototypes, even when enriched by LLMs, are static and limited, failing to capture the rich intra-class visual variations induced by different object states (e.g., a cat's pose). Second, the standard pseudo-box generation introduces a semantic mismatch between visual region proposals (which contain context) and object-centric text embeddings. To tackle these issues, we introduce two complementary prototype enhancement strategies. To capture intra-class variations in appearance and state, we propose the State-Enhanced Semantic Prototypes (SESP), which generates state-aware textual descriptions (e.g., "a sleeping cat") to capture diverse object appearances, yielding more discriminative prototypes. Building on this, we further introduce Scene-Augmented Pseudo Prototypes (SAPP) to address the semantic mismatch. SAPP incorporates contextual semantics (e.g., "cat lying on sofa") and utilizes a soft alignment mechanism to promote contextually consistent visual-textual representations. By integrating SESP and SAPP, our method effectively enhances both the richness of semantic prototypes and the visual-textual alignment, achieving notable improvements.

</details>


### [63] [MambaX: Image Super-Resolution with State Predictive Control](https://arxiv.org/abs/2511.18028)
*Chenyu Li,Danfeng Hong,Bing Zhang,Zhaojie Pan,Naoto Yokoya,Jocelyn Chanussot*

Main category: cs.CV

TL;DR: 提出MambaX模型，通过动态状态预测控制学习非线性状态参数，解决图像超分辨率中误差传播和累积问题，在单图像和多模态超分辨率任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率方法主要关注最终分辨率提升，忽视中间阶段的误差传播和累积控制。Mamba方法虽能表示重建过程为状态序列，但其固定线性映射器感受野窄、灵活性受限，在细粒度图像中效果不佳。

Method: 创建非线性状态预测控制模型MambaX：1）动态状态预测控制学习逼近状态空间模型的非线性微分系数；2）引入状态交叉控制范式实现多模态超分辨率融合；3）采用渐进过渡学习缓解领域和模态偏移引起的异质性。

Result: 评估显示动态频谱-状态表示模型在单图像超分辨率和多模态融合超分辨率任务中均表现优异，证明了其在任意维度和模态的光谱广义建模方面的巨大潜力。

Conclusion: MambaX模型通过非线性状态预测控制有效解决了超分辨率中的误差传播问题，在多种任务中展现出优越性能，为光谱广义建模提供了重要进展。

Abstract: Image super-resolution (SR) is a critical technology for overcoming the inherent hardware limitations of sensors. However, existing approaches mainly focus on directly enhancing the final resolution, often neglecting effective control over error propagation and accumulation during intermediate stages. Recently, Mamba has emerged as a promising approach that can represent the entire reconstruction process as a state sequence with multiple nodes, allowing for intermediate intervention. Nonetheless, its fixed linear mapper is limited by a narrow receptive field and restricted flexibility, which hampers its effectiveness in fine-grained images. To address this, we created a nonlinear state predictive control model \textbf{MambaX} that maps consecutive spectral bands into a latent state space and generalizes the SR task by dynamically learning the nonlinear state parameters of control equations. Compared to existing sequence models, MambaX 1) employs dynamic state predictive control learning to approximate the nonlinear differential coefficients of state-space models; 2) introduces a novel state cross-control paradigm for multimodal SR fusion; and 3) utilizes progressive transitional learning to mitigate heterogeneity caused by domain and modality shifts. Our evaluation demonstrates the superior performance of the dynamic spectrum-state representation model in both single-image SR and multimodal fusion-based SR tasks, highlighting its substantial potential to advance spectrally generalized modeling across arbitrary dimensions and modalities.

</details>


### [64] [Hybrid Event Frame Sensors: Modeling, Calibration, and Simulation](https://arxiv.org/abs/2511.18037)
*Yunfan Lu,Nico Messikommer,Xiaogang Xu,Liming Chen,Yuhan Chen,Nikola Zubic,Davide Scaramuzza,Hui Xiong*

Main category: cs.CV

TL;DR: 本文提出了首个统一的事件帧混合传感器噪声模型，联合描述APS和EVS像素的噪声行为，并开发了校准流程和HESIM模拟器来生成具有真实噪声统计的RAW帧和事件数据。


<details>
  <summary>Details</summary>
Motivation: 事件帧混合传感器集成了APS和EVS，但复杂的电路架构引入了难以理解的噪声模式，目前缺乏对这些噪声的统一建模。

Method: 开发了基于统计学的统一成像噪声模型，包含光子散粒噪声、暗电流噪声、固定模式噪声和量化噪声，建立了EVS噪声与光照水平和暗电流的关系，并提出了校准流程和HESIM模拟器。

Result: 在两个混合传感器上的实验验证了模型在多个成像任务（如视频帧插值和去模糊）中的有效性，展示了从模拟到真实数据的强迁移能力。

Conclusion: 该工作为事件帧混合传感器提供了首个统一的噪声建模框架，能够准确描述APS和EVS的联合噪声行为，为传感器设计和计算机视觉应用提供了重要工具。

Abstract: Event frame hybrid sensors integrate an Active Pixel Sensor (APS) and an Event Vision Sensor (EVS) within a single chip, combining the high dynamic range and low latency of the EVS with the rich spatial intensity information from the APS. While this tight integration offers compact, temporally precise imaging, the complex circuit architecture introduces non-trivial noise patterns that remain poorly understood and unmodeled. In this work, we present the first unified, statistics-based imaging noise model that jointly describes the noise behavior of APS and EVS pixels. Our formulation explicitly incorporates photon shot noise, dark current noise, fixed-pattern noise, and quantization noise, and links EVS noise to illumination level and dark current. Based on this formulation, we further develop a calibration pipeline to estimate noise parameters from real data and offer a detailed analysis of both APS and EVS noise behaviors. Finally, we propose HESIM, a statistically grounded simulator that generates RAW frames and events under realistic, jointly calibrated noise statistics. Experiments on two hybrid sensors validate our model across multiple imaging tasks (e.g., video frame interpolation and deblurring), demonstrating strong transfer from simulation to real data.

</details>


### [65] [UltraFlux: Data-Model Co-Design for High-quality Native 4K Text-to-Image Generation across Diverse Aspect Ratios](https://arxiv.org/abs/2511.18050)
*Tian Ye,Song Fei,Lei Zhu*

Main category: cs.CV

TL;DR: UltraFlux是一个基于Flux的扩散变换器，原生支持4K分辨率图像生成，通过数据-模型协同设计解决了4K生成中的位置编码、VAE压缩和优化问题。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散变换器在1K分辨率表现良好，但扩展到原生4K分辨率时暴露了位置编码、VAE压缩和优化的紧密耦合问题，单独解决任一因素都无法达到理想质量。

Method: 采用数据-模型协同设计：数据方面构建了包含100万张4K图像的MultiAspect-4K-1M数据集；模型方面结合了Resonance 2D RoPE位置编码、非对抗性VAE后训练、SNR感知Huber小波目标和分阶段美学课程学习。

Result: 在4096分辨率基准测试和多宽高比4K设置中，UltraFlux在保真度、美学质量和对齐度指标上始终优于开源基线，配合LLM提示优化器时甚至达到或超过专有模型Seedream 4.0的性能。

Conclusion: 通过综合解决4K生成中的关键挑战，UltraFlux实现了稳定、细节保留的4K扩散变换器，能够泛化到宽屏、方形和竖屏等各种宽高比。

Abstract: Diffusion transformers have recently delivered strong text-to-image generation around 1K resolution, but we show that extending them to native 4K across diverse aspect ratios exposes a tightly coupled failure mode spanning positional encoding, VAE compression, and optimization. Tackling any of these factors in isolation leaves substantial quality on the table. We therefore take a data-model co-design view and introduce UltraFlux, a Flux-based DiT trained natively at 4K on MultiAspect-4K-1M, a 1M-image 4K corpus with controlled multi-AR coverage, bilingual captions, and rich VLM/IQA metadata for resolution- and AR-aware sampling. On the model side, UltraFlux couples (i) Resonance 2D RoPE with YaRN for training-window-, frequency-, and AR-aware positional encoding at 4K; (ii) a simple, non-adversarial VAE post-training scheme that improves 4K reconstruction fidelity; (iii) an SNR-Aware Huber Wavelet objective that rebalances gradients across timesteps and frequency bands; and (iv) a Stage-wise Aesthetic Curriculum Learning strategy that concentrates high-aesthetic supervision on high-noise steps governed by the model prior. Together, these components yield a stable, detail-preserving 4K DiT that generalizes across wide, square, and tall ARs. On the Aesthetic-Eval at 4096 benchmark and multi-AR 4K settings, UltraFlux consistently outperforms strong open-source baselines across fidelity, aesthetic, and alignment metrics, and-with a LLM prompt refiner-matches or surpasses the proprietary Seedream 4.0.

</details>


### [66] [IE-Critic-R1: Advancing the Explanatory Measurement of Text-Driven Image Editing for Human Perception Alignment](https://arxiv.org/abs/2511.18055)
*Bowen Qu,Shangkun Sun,Xiaoyu Liang,Wei Gao*

Main category: cs.CV

TL;DR: 本文提出了文本驱动图像编辑基准套件(IE-Bench)和评估模型IE-Critic-R1，通过强化学习从可验证奖励中训练，提供更全面、可解释且符合人类感知的图像编辑质量评估。


<details>
  <summary>Details</summary>
Motivation: 当前文本驱动图像编辑技术发展迅速，但准确评估编辑图像仍面临挑战。现有方法要么只关注文本-图像对齐，要么未能很好地对齐人类感知，需要更全面的评估框架。

Method: 构建IE-Bench基准套件，包含多样化源图像、编辑提示和编辑结果，收集近4000个样本的人类主观评分。提出IE-Critic-R1模型，利用强化学习从可验证奖励中训练，实现更全面的质量评估。

Result: 大量实验证明IE-Critic-R1在文本驱动图像编辑任务上相比先前指标具有更优的主观对齐性，能够提供更符合人类感知的评估结果。

Conclusion: IE-Bench基准套件和IE-Critic-R1模型为文本驱动图像编辑提供了更全面、可解释且符合人类感知的评估方法，相关数据和代码已公开。

Abstract: Recent advances in text-driven image editing have been significant, yet the task of accurately evaluating these edited images continues to pose a considerable challenge. Different from the assessment of text-driven image generation, text-driven image editing is characterized by simultaneously conditioning on both text and a source image. The edited images often retain an intrinsic connection to the original image, which dynamically change with the semantics of the text. However, previous methods tend to solely focus on text-image alignment or have not well aligned with human perception. In this work, we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to enhance the assessment of text-driven edited images. IE-Bench includes a database contains diverse source images, various editing prompts and the corresponding edited results from different editing methods, and nearly 4,000 samples with corresponding Mean Opinion Scores (MOS) provided by 15 human subjects. Furthermore, we introduce IE-Critic-R1, which, benefiting from Reinforcement Learning from Verifiable Rewards (RLVR), provides more comprehensive and explainable quality assessment for text-driven image editing that aligns with human perception. Extensive experiments demonstrate IE-Critic-R1's superior subjective-alignments on the text-driven image editing task compared with previous metrics. Related data and codes are available to the public.

</details>


### [67] [Hierarchical Semi-Supervised Active Learning for Remote Sensing](https://arxiv.org/abs/2511.18058)
*Wei Huang,Zhitong Xiong,Chenying Liu,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出了一种分层半监督主动学习框架HSSAL，结合半监督学习和分层主动学习，在遥感场景分类中仅使用少量标注数据即可达到接近全监督模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决遥感领域高质量标注数据获取成本高、时间长的挑战，充分利用大量未标注图像数据。

Method: 采用闭环迭代框架：半监督学习通过弱到强自训练改进特征表示和不确定性估计；分层主动学习通过渐进聚类策略选择最具信息量的样本，满足可扩展性、多样性和不确定性标准。

Result: 在UCM、AID和NWPU-RESISC45三个基准数据集上，仅使用8%、4%和2%的标注训练数据，HSSAL就能达到超过95%的全监督准确率。

Conclusion: HSSAL框架通过有效利用未标注数据的信息性，在遥感场景分类中实现了卓越的标签效率，显著优于仅使用半监督学习或主动学习的基线方法。

Abstract: The performance of deep learning models in remote sensing (RS) strongly depends on the availability of high-quality labeled data. However, collecting large-scale annotations is costly and time-consuming, while vast amounts of unlabeled imagery remain underutilized. To address this challenge, we propose a Hierarchical Semi-Supervised Active Learning (HSSAL) framework that integrates semi-supervised learning (SSL) and a novel hierarchical active learning (HAL) in a closed iterative loop. In each iteration, SSL refines the model using both labeled data through supervised learning and unlabeled data via weak-to-strong self-training, improving feature representation and uncertainty estimation. Guided by the refined representations and uncertainty cues of unlabeled samples, HAL then conducts sample querying through a progressive clustering strategy, selecting the most informative instances that jointly satisfy the criteria of scalability, diversity, and uncertainty. This hierarchical process ensures both efficiency and representativeness in sample selection. Extensive experiments on three benchmark RS scene classification datasets, including UCM, AID, and NWPU-RESISC45, demonstrate that HSSAL consistently outperforms SSL- or AL-only baselines. Remarkably, with only 8%, 4%, and 2% labeled training data on UCM, AID, and NWPU-RESISC45, respectively, HSSAL achieves over 95% of fully-supervised accuracy, highlighting its superior label efficiency through informativeness exploitation of unlabeled data. Our code will be released at https://github.com/zhu-xlab/RS-SSAL.

</details>


### [68] [VK-Det: Visual Knowledge Guided Prototype Learning for Open-Vocabulary Aerial Object Detection](https://arxiv.org/abs/2511.18075)
*Jianhang Yao,Yongbin Zheng,Siqi Lu,Wanying Xu,Peng Sun*

Main category: cs.CV

TL;DR: VK-Det是一个无需额外监督的视觉知识引导开放词汇目标检测框架，通过利用视觉编码器的固有区域感知能力和原型感知伪标签策略，在航空图像上实现了最先进的开放词汇检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇航空目标检测方法依赖文本监督会产生语义偏差，限制了向文本指定概念之外的扩展。本文旨在消除对额外监督的依赖，利用视觉知识实现更通用的开放词汇检测。

Method: 1) 利用视觉编码器的固有信息区域感知能力实现细粒度定位和自适应蒸馏；2) 提出原型感知伪标签策略，通过特征聚类建模类间决策边界，通过原型匹配将检测区域映射到潜在类别。

Result: 在DIOR数据集上达到30.1 mAP^N，在DOTA数据集上达到23.3 mAP^N，超越了有额外监督的方法，实现了最先进的性能。

Conclusion: VK-Det框架通过视觉知识引导和原型感知伪标签，成功实现了无需额外监督的开放词汇目标检测，在航空图像上表现出色，为开放词汇检测提供了新的解决方案。

Abstract: To identify objects beyond predefined categories, open-vocabulary aerial object detection (OVAD) leverages the zero-shot capabilities of visual-language models (VLMs) to generalize from base to novel categories. Existing approaches typically utilize self-learning mechanisms with weak text supervision to generate region-level pseudo-labels to align detectors with VLMs semantic spaces. However, text dependence induces semantic bias, restricting open-vocabulary expansion to text-specified concepts. We propose $\textbf{VK-Det}$, a $\textbf{V}$isual $\textbf{K}$nowledge-guided open-vocabulary object $\textbf{Det}$ection framework $\textit{without}$ extra supervision. First, we discover and leverage vision encoder's inherent informative region perception to attain fine-grained localization and adaptive distillation. Second, we introduce a novel prototype-aware pseudo-labeling strategy. It models inter-class decision boundaries through feature clustering and maps detection regions to latent categories via prototype matching. This enhances attention to novel objects while compensating for missing supervision. Extensive experiments show state-of-the-art performance, achieving 30.1 $\mathrm{mAP}^{N}$ on DIOR and 23.3 $\mathrm{mAP}^{N}$ on DOTA, outperforming even extra supervised methods.

</details>


### [69] [ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models](https://arxiv.org/abs/2511.18082)
*Wencheng Ye,Tianshi Wang,Lei Zhu,Fengling Li,Guoli Yang*

Main category: cs.CV

TL;DR: ActDistill是一个动作引导的自蒸馏框架，将现有VLA模型的动作预测能力转移到轻量级模型，通过动作先验指导知识转移和模型压缩，实现动作导向的VLA模型效率提升。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在机器人操作中面临计算开销大和推理延迟高的问题，限制了实际部署应用。

Method: 使用训练好的VLA模型作为教师模型，引入图结构封装策略建模动作预测的层次演化，学生模型配备动态路由器根据动作预测需求自适应选择计算路径，并通过层次图监督确保平滑高效演化。

Result: 在具身基准测试中，ActDistill达到与全尺寸VLA模型相当或更优的性能，同时计算量减少50%以上，速度提升最高达1.67倍。

Conclusion: ActDistill建立了一个面向高效具身智能的通用范式，显著提升了VLA模型在机器人操作中的部署效率。

Abstract: Recent Vision-Language-Action (VLA) models have shown impressive flexibility and generalization, yet their deployment in robotic manipulation remains limited by heavy computational overhead and inference latency. In this work, we present ActDistill, a general action-guided self-derived distillation framework that transfers the action prediction capability of any existing VLA model to a lightweight counterpart. Unlike previous efficiency strategies that primarily emphasize vision-language correlations, ActDistill leverages action priors to guide knowledge transfer and model compression, achieving action-oriented efficiency for VLA models. Specifically, we employ a well-trained VLA model as the teacher and introduce a graph-structured encapsulation strategy to explicitly model the hierarchical evolution of action prediction. The student model, derived from the graph-encapsulated teacher, is further equipped with a dynamic router that adaptively selects computation paths based on action prediction demands, guided by hierarchical graph-informed supervision to ensure smooth and efficient evolution. During inference, graph-related auxiliary components are removed, allowing the student to execute only dynamically routed layers and predict high-precision actions with minimal computation and latency. Experiments on embodied benchmarks demonstrate that ActDistill achieves comparable or superior performance to full-scale VLA models while reducing computation by over 50% with up to 1.67 times speedup, thereby establishing a general paradigm toward efficient embodied intelligence.

</details>


### [70] [Together, Then Apart: Revisiting Multimodal Survival Analysis via a Min-Max Perspective](https://arxiv.org/abs/2511.18089)
*Wenjing Liu,Qin Ren,Wen Zhang,Yuewei Lin,Chenyu You*

Main category: cs.CV

TL;DR: 本文提出了TTA框架，通过同时建模共享和模态特定表示来解决多模态生存分析中的表示崩溃问题，在五个TCGA基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度强调跨模态对齐，导致表示崩溃和多样性减少，需要同时考虑对齐和差异性来保留模态特定特征。

Method: 提出Together-Then-Apart统一最小-最大优化框架：Together阶段通过共享原型对齐嵌入，Apart阶段通过模态锚点和对比正则化器最大化表示多样性。

Result: 在五个TCGA基准测试中，TTA始终优于最先进方法，提供了鲁棒、可解释且具有生物学意义的多模态生存分析。

Conclusion: TTA框架为如何在多模态生存分析中同时实现对齐和差异性提供了新的理论视角，实现了稳健、可解释且具有生物学意义的分析。

Abstract: Integrating heterogeneous modalities such as histopathology and genomics is central to advancing survival analysis, yet most existing methods prioritize cross-modal alignment through attention-based fusion mechanisms, often at the expense of modality-specific characteristics. This overemphasis on alignment leads to representation collapse and reduced diversity. In this work, we revisit multi-modal survival analysis via the dual lens of alignment and distinctiveness, positing that preserving modality-specific structure is as vital as achieving semantic coherence. In this paper, we introduce Together-Then-Apart (TTA), a unified min-max optimization framework that simultaneously models shared and modality-specific representations. The Together stage minimizes semantic discrepancies by aligning embeddings via shared prototypes, guided by an unbalanced optimal transport objective that adaptively highlights informative tokens. The Apart stage maximizes representational diversity through modality anchors and a contrastive regularizer that preserve unique modality information and prevent feature collapse. Extensive experiments on five TCGA benchmarks show that TTA consistently outperforms state-of-the-art methods. Beyond empirical gains, our formulation provides a new theoretical perspective of how alignment and distinctiveness can be jointly achieved in for robust, interpretable, and biologically meaningful multi-modal survival analysis.

</details>


### [71] [Versatile Recompression-Aware Perceptual Image Super-Resolution](https://arxiv.org/abs/2511.18090)
*Mingwei He,Tongda Xu,Xingtong Ge,Ming Sun,Chao Zhou,Yan Wang*

Main category: cs.CV

TL;DR: VRPSR是一种感知图像超分辨率方法，通过预训练扩散模型构建可泛化的编解码器模拟器，使现有感知SR方法能够适应多种压缩场景，在H.264/H.265/H.266压缩下可节省超过10%的比特率。


<details>
  <summary>Details</summary>
Motivation: 现有感知图像超分辨率方法忽略了输出图像通常会被重新压缩存储和传输的问题，下游编解码器可能会给恢复的图像添加额外伪影，而联合优化SR和重新压缩具有挑战性。

Method: 将压缩建模为条件文本到图像生成，利用预训练扩散模型构建通用编解码器模拟器；提出针对感知SR的训练技术，包括使用感知目标优化模拟器和采用轻微压缩图像作为训练目标。

Result: 基于Real-ESRGAN和S3Diff，在H.264/H.265/H.266压缩下可节省超过10%的比特率；同时促进了SR与重新压缩后后处理模型的联合优化。

Conclusion: VRPSR方法成功使现有感知超分辨率方法能够感知多种压缩场景，显著提升了压缩效率并支持联合优化。

Abstract: Perceptual image super-resolution (SR) methods restore degraded images and produce sharp outputs. In practice, those outputs are usually recompressed for storage and transmission. Ignoring recompression is suboptimal as the downstream codec might add additional artifacts to restored images. However, jointly optimizing SR and recompression is challenging, as the codecs are not differentiable and vary in configuration. In this paper, we present Versatile Recompression-Aware Perceptual Super-Resolution (VRPSR), which makes existing perceptual SR aware of versatile compression. First, we formulate compression as conditional text-to-image generation and utilize a pre-trained diffusion model to build a generalizable codec simulator. Next, we propose a set of training techniques tailored for perceptual SR, including optimizing the simulator using perceptual targets and adopting slightly compressed images as the training target. Empirically, our VRPSR saves more than 10\% bitrate based on Real-ESRGAN and S3Diff under H.264/H.265/H.266 compression. Besides, our VRPSR facilitates joint optimization of the SR and post-processing model after recompression.

</details>


### [72] [Spotlight: Identifying and Localizing Video Generation Errors Using VLMs](https://arxiv.org/abs/2511.18102)
*Aditya Chinchure,Sahithya Ravi,Pushkar Shukla,Vered Shwartz,Leonid Sigal*

Main category: cs.CV

TL;DR: 本文提出了Spotlight任务，用于定位和解释视频生成中的错误，通过标注1600多个细粒度错误发现物理和提示遵循错误最为普遍，且现有视觉语言模型在错误识别方面远落后于人类。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频模型虽然能生成高质量视频，但仍存在细微错误，而现有评估方法无法准确定位错误发生的时间和类型，需要开发更精细的错误定位和解释方法。

Method: 使用200个多样化文本提示和3个先进视频生成器生成600个视频，标注6种类型的1600多个细粒度错误，包括运动、物理和提示遵循等，并评估视觉语言模型的错误识别能力。

Result: 发现提示遵循和物理错误最为普遍且持续时间较长，而外观消失和身体姿态错误出现在较短片段中；视觉语言模型在错误识别和定位方面显著落后于人类，通过推理时策略可将性能提升近2倍。

Conclusion: Spotlight任务为构建细粒度视频评估工具和更复杂的奖励模型奠定了基础，推动了视频生成模型评估的发展。

Abstract: Current text-to-video models (T2V) can generate high-quality, temporally coherent, and visually realistic videos. Nonetheless, errors still often occur, and are more nuanced and local compared to the previous generation of T2V models. While current evaluation paradigms assess video models across diverse dimensions, they typically evaluate videos holistically without identifying when specific errors occur or describing their nature. We address this gap by introducing Spotlight, a novel task aimed at localizing and explaining video-generation errors. We generate 600 videos using 200 diverse textual prompts and three state-of-the-art video generators (Veo 3, Seedance, and LTX-2), and annotate over 1600 fine-grained errors across six types, including motion, physics, and prompt adherence. We observe that adherence and physics errors are predominant and persist across longer segments, whereas appearance-disappearance and body pose errors manifest in shorter segments. We then evaluate current VLMs on Spotlight and find that VLMs lag significantly behind humans in error identification and localization in videos. We propose inference-time strategies to probe the limits of current VLMs on our task, improving performance by nearly 2x. Our task paves a way forward to building fine-grained evaluation tools and more sophisticated reward models for video generators.

</details>


### [73] [Consolidating Diffusion-Generated Video Detection with Unified Multimodal Forgery Learning](https://arxiv.org/abs/2511.18104)
*Xiaohong Liu,Xiufeng Song,Huayu Zheng,Lei Bai,Xiaoming Liu,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出MM-Det++算法，用于检测扩散模型生成的视频，通过时空分支和多模态分支结合统一多模态学习模块，在大型DVF数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成的视频引发信息安全担忧，现有方法主要关注图像级伪造检测，视频级检测研究不足，需要可靠的合成媒体检测方法。

Method: 采用双分支结构：时空分支使用帧中心视觉变换器聚合时空信息；多模态分支利用多模态大语言模型获取伪造表示。引入统一多模态学习模块整合多模态表示。

Result: 大量实验证明MM-Det++的优越性，统一多模态伪造学习在检测扩散生成视频方面具有显著效果。

Conclusion: MM-Det++通过统一多模态学习方法有效检测扩散生成的视频，建立的DVF数据集推动了视频伪造检测研究发展。

Abstract: The proliferation of videos generated by diffusion models has raised increasing concerns about information security, highlighting the urgent need for reliable detection of synthetic media. Existing methods primarily focus on image-level forgery detection, leaving generic video-level forgery detection largely underexplored. To advance video forensics, we propose a consolidated multimodal detection algorithm, named MM-Det++, specifically designed for detecting diffusion-generated videos. Our approach consists of two innovative branches and a Unified Multimodal Learning (UML) module. Specifically, the Spatio-Temporal (ST) branch employs a novel Frame-Centric Vision Transformer (FC-ViT) to aggregate spatio-temporal information for detecting diffusion-generated videos, where the FC-tokens enable the capture of holistic forgery traces from each video frame. In parallel, the Multimodal (MM) branch adopts a learnable reasoning paradigm to acquire Multimodal Forgery Representation (MFR) by harnessing the powerful comprehension and reasoning capabilities of Multimodal Large Language Models (MLLMs), which discerns the forgery traces from a flexible semantic perspective. To integrate multimodal representations into a coherent space, a UML module is introduced to consolidate the generalization ability of MM-Det++. In addition, we also establish a large-scale and comprehensive Diffusion Video Forensics (DVF) dataset to advance research in video forgery detection. Extensive experiments demonstrate the superiority of MM-Det++ and highlight the effectiveness of unified multimodal forgery learning in detecting diffusion-generated videos.

</details>


### [74] [AdaPerceiver: Transformers with Adaptive Width, Depth, and Tokens](https://arxiv.org/abs/2511.18105)
*Purvish Jajal,Nick John Eliopoulos,Benjamin Shiue-Hal Chou,George K. Thiruvathukal,Yung-Hsiang Lu,James C. Davis*

Main category: cs.CV

TL;DR: AdaPerceiver是一种新型transformer架构，首次在单一模型中实现了深度、宽度和token三个维度的统一自适应计算分配，能够在不同硬件和延迟约束下灵活调整计算量。


<details>
  <summary>Details</summary>
Motivation: 现有transformer模型在推理时计算分配方式固定，无法适应多样化的硬件和延迟约束。大多数动态计算方法只关注单一维度（如减少token数量），缺乏统一的适应性。

Method: 提出AdaPerceiver架构，支持深度、宽度和token三个维度的自适应计算分配，并设计了高效的联合训练机制，确保模型在各种配置下保持性能。

Result: 在图像分类任务中，AdaPerceiver扩展了准确率-吞吐量帕累托前沿，达到85.4%准确率，吞吐量比FlexiViT-L提高36%。在密集预测任务中，语义分割和深度估计的编码器FLOPs减少约26倍。通过策略控制，可在保持ImageNet1K准确率的同时减少24-33%的FLOPs。

Conclusion: AdaPerceiver通过统一的多维度自适应机制，在保持性能的同时显著提高了计算效率，为transformer模型在多样化部署场景中的应用提供了有效解决方案。

Abstract: Modern transformer architectures achieve remarkable performance across tasks and domains but remain rigid in how they allocate computation at inference time. Real-world deployment often requires models to adapt to diverse hardware and latency constraints, yet most approaches to dynamic computation focus on a single axis -- such as reducing the number of tokens. We present a novel capability: AdaPerceiver, the first transformer architecture with unified adaptivity across depth, width, and tokens within a single model. We propose an architecture that supports adaptivity along these axes. We couple this with an efficient joint training regime that ensures the model maintains performance across its various configurations. We evaluate AdaPerceiver on image classification, semantic segmentation, and depth estimation tasks. On image classification, AdaPerceiver expands the accuracy-throughput Pareto front. It achieves 85.4% accuracy while yielding 36% higher throughput than FlexiViT-L. On dense prediction, AdaPerceiver matches ViT-H/14 while having $\sim$26x fewer encoder FLOPs (floating-point operations) on semantic segmentation and depth estimation. Finally, we show how AdaPerceiver equipped with a policy can maintain ImageNet1K accuracy ($\pm0.1$ percentage points) while reducing FLOPs by $24-33$%.

</details>


### [75] [PromptMoE: Generalizable Zero-Shot Anomaly Detection via Visually-Guided Prompt Mixtures](https://arxiv.org/abs/2511.18116)
*Yuheng Shao,Lizhang Wang,Changhao Li,Peixian Chen,Qinyuan Liu*

Main category: cs.CV

TL;DR: PromptMoE提出了一种基于专家提示池和视觉引导混合机制的零样本异常检测方法，通过可组合的语义基元动态生成文本表示，解决了现有提示工程策略的表示瓶颈和过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP等视觉语言模型的零样本异常检测方法受限于提示工程策略，存在表示瓶颈和过拟合问题，无法很好地泛化到未见过的复杂多样异常。

Method: 提出PromptMoE框架，学习专家提示池作为可组合语义基元，通过视觉引导的混合专家机制为每个实例动态组合这些提示，生成语义丰富的文本表示。

Result: 在工业和医疗领域的15个数据集上进行广泛实验，证明了PromptMoE的有效性和最先进的性能。

Conclusion: PromptMoE通过组合式提示学习方法克服了现有方法的局限性，在零样本异常检测任务中实现了优异的性能。

Abstract: Zero-Shot Anomaly Detection (ZSAD) aims to identify and localize anomalous regions in images of unseen object classes. While recent methods based on vision-language models like CLIP show promise, their performance is constrained by existing prompt engineering strategies. Current approaches, whether relying on single fixed, learnable, or dense dynamic prompts, suffer from a representational bottleneck and are prone to overfitting on auxiliary data, failing to generalize to the complexity and diversity of unseen anomalies. To overcome these limitations, we propose $\mathtt{PromptMoE}$. Our core insight is that robust ZSAD requires a compositional approach to prompt learning. Instead of learning monolithic prompts, $\mathtt{PromptMoE}$ learns a pool of expert prompts, which serve as a basis set of composable semantic primitives, and a visually-guided Mixture-of-Experts (MoE) mechanism to dynamically combine them for each instance. Our framework materializes this concept through a Visually-Guided Mixture of Prompt (VGMoP) that employs an image-gated sparse MoE to aggregate diverse normal and abnormal expert state prompts, generating semantically rich textual representations with strong generalization. Extensive experiments across 15 datasets in industrial and medical domains demonstrate the effectiveness and state-of-the-art performance of $\mathtt{PromptMoE}$.

</details>


### [76] [MVS-TTA: Test-Time Adaptation for Multi-View Stereo via Meta-Auxiliary Learning](https://arxiv.org/abs/2511.18120)
*Hannuo Zhang,Zhixiang Chi,Yang Wang,Xinxin Zuo*

Main category: cs.CV

TL;DR: MVS-TTA是一个高效的测试时自适应框架，通过结合学习型和优化型多视图立体重建方法的优势，使用元辅助学习策略和自监督跨视图一致性损失来提升模型在测试时的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 学习型MVS方法受限于训练数据分布，泛化能力不足；而优化型方法需要昂贵的逐场景优化。MVS-TTA旨在结合两种范式的优势，提升学习型MVS方法的适应性。

Method: 提出自监督跨视图一致性损失作为辅助任务指导推理时自适应，采用元辅助学习策略训练模型从辅助任务更新中获益，框架模型无关且只需最小架构改动。

Result: 在标准数据集和跨数据集泛化设置上的广泛实验表明，MVS-TTA能持续提升性能，即使应用于最先进的MVS模型。

Conclusion: 这是首次使用元学习将基于优化的测试时自适应集成到学习型MVS中的尝试，框架能有效提升模型泛化能力。

Abstract: Recent learning-based multi-view stereo (MVS) methods are data-driven and have achieved remarkable progress due to large-scale training data and advanced architectures. However, their generalization remains sub-optimal due to fixed model parameters trained on limited training data distributions. In contrast, optimization-based methods enable scene-specific adaptation but lack scalability and require costly per-scene optimization. In this paper, we propose MVS-TTA, an efficient test-time adaptation (TTA) framework that enhances the adaptability of learning-based MVS methods by bridging these two paradigms. Specifically, MVS-TTA employs a self-supervised, cross-view consistency loss as an auxiliary task to guide inference-time adaptation. We introduce a meta-auxiliary learning strategy to train the model to benefit from auxiliary-task-based updates explicitly. Our framework is model-agnostic and can be applied to a wide range of MVS methods with minimal architectural changes. Extensive experiments on standard datasets (DTU, BlendedMVS) and a challenging cross-dataset generalization setting demonstrate that MVS-TTA consistently improves performance, even when applied to state-of-the-art MVS models. To our knowledge, this is the first attempt to integrate optimization-based test-time adaptation into learning-based MVS using meta-learning. The code will be available at https://github.com/mart87987-svg/MVS-TTA.

</details>


### [77] [VCU-Bridge: Hierarchical Visual Connotation Understanding via Semantic Bridging](https://arxiv.org/abs/2511.18121)
*Ming Zhong,Yuanlei Wang,Liuzhou Zhang,Arctanx An,Renrui Zhang,Hao Liang,Ming Lu,Ying Shen,Wentao Zhang*

Main category: cs.CV

TL;DR: VCU-Bridge框架提出了一种类似人类的视觉内涵理解层次结构，从基础感知到语义桥接再到抽象内涵，并构建了HVCU-Bench基准进行层级诊断。实验显示模型性能随推理层级升高而下降，通过MCTS指导的数据生成增强低层能力可提升高层性能，并在通用基准上获得平均2.53%的改进。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在基准测试中表现优异，但其处理范式与人类整合视觉信息的能力不同。模型倾向于孤立处理细节和高级概念，而人类能自然桥接二者。现有评估协议往往将低层感知与高层推理解耦，忽视了它们的语义和因果依赖关系。

Method: 提出了VCU-Bridge框架，实现视觉内涵理解的层次结构：从基础感知到语义桥接再到抽象内涵，具有从具体线索到抽象结论的显式证据到推理追踪。基于此构建HVCU-Bench基准，并开发了由蒙特卡洛树搜索指导的数据生成流程进行指令调优。

Result: 综合实验显示，随着推理向更高层级推进，模型性能持续下降。通过增强低层能力，在高层级上获得了可测量的收益，不仅在HVCU-Bench上有所改进，还在通用基准上带来平均2.53%的收益，特别是在MMStar上获得7.26%的显著提升。

Conclusion: 层次化思维模式的重要性及其在增强多模态大语言模型能力方面的有效性得到了证明。加强低层能力能够产生可测量的高层收益，表明视觉内涵理解的层次结构对于提升模型性能具有重要作用。

Abstract: While Multimodal Large Language Models (MLLMs) excel on benchmarks, their processing paradigm differs from the human ability to integrate visual information. Unlike humans who naturally bridge details and high-level concepts, models tend to treat these elements in isolation. Prevailing evaluation protocols often decouple low-level perception from high-level reasoning, overlooking their semantic and causal dependencies, which yields non-diagnostic results and obscures performance bottlenecks. We present VCU-Bridge, a framework that operationalizes a human-like hierarchy of visual connotation understanding: multi-level reasoning that advances from foundational perception through semantic bridging to abstract connotation, with an explicit evidence-to-inference trace from concrete cues to abstract conclusions. Building on this framework, we construct HVCU-Bench, a benchmark for hierarchical visual connotation understanding with explicit, level-wise diagnostics. Comprehensive experiments demonstrate a consistent decline in performance as reasoning progresses to higher levels. We further develop a data generation pipeline for instruction tuning guided by Monte Carlo Tree Search (MCTS) and show that strengthening low-level capabilities yields measurable gains at higher levels. Interestingly, it not only improves on HVCU-Bench but also brings benefits on general benchmarks (average +2.53%), especially with substantial gains on MMStar (+7.26%), demonstrating the significance of the hierarchical thinking pattern and its effectiveness in enhancing MLLM capabilities. The project page is at https://vcu-bridge.github.io .

</details>


### [78] [Bias Is a Subspace, Not a Coordinate: A Geometric Rethinking of Post-hoc Debiasing in Vision-Language Models](https://arxiv.org/abs/2511.18123)
*Dachuan Zhao,Weiyue Li,Zhenda Shen,Yushu Qiu,Bowen Xu,Haoyu Chen,Yongchao Chen*

Main category: cs.CV

TL;DR: 本文提出SPD方法，通过识别和移除线性可解码偏见的整个子空间来解决视觉语言模型中的偏见问题，相比现有方法在公平性指标上平均提升18.5%。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）的表征经常编码并放大人口统计偏见，导致下游任务中出现偏见关联和错误预测，影响公平性和视觉与语言的对齐。现有基于坐标替换的方法存在特征纠缠、跨数据集泛化差和不完全偏见移除等关键问题。

Method: 提出子空间投影去偏见（SPD）框架，通过几何原理识别并移除线性可解码偏见的整个子空间，同时重新插入中性均值组件以保持语义保真度。

Result: 在零样本分类、文本到图像检索和图像生成等任务上的广泛实验验证了SPD的有效性：相比最佳去偏见基线，该方法实现了更稳健的去偏见效果，在四个公平性指标上平均提升18.5%，同时任务性能损失最小。

Conclusion: 偏见并不局限于少数坐标，而是分布在少数线性子空间中。SPD方法通过移除整个偏见子空间，能够更有效地解决视觉语言模型中的偏见问题，在保持任务性能的同时显著提升公平性。

Abstract: Vision-Language Models (VLMs) have become indispensable for multimodal reasoning, yet their representations often encode and amplify demographic biases, resulting in biased associations and misaligned predictions in downstream tasks. Such behavior undermines fairness and distorts the intended alignment between vision and language. Recent post-hoc approaches attempt to mitigate bias by replacing the most attribute-correlated embedding coordinates with neutral values. However, our systematic analysis reveals three critical failures of this coordinate-wise approach: feature entanglement, poor cross-dataset generalization, and incomplete bias removal. We find that bias is not localized to a few coordinates but is instead distributed across a few linear subspaces. To address these limitations, we propose $\textbf{S}$ubspace $\textbf{P}$rojection $\textbf{D}$ebiasing ($\textbf{SPD}$), a geometrically principled framework that identifies and removes the entire subspace of linearly decodable bias while reinserting a neutral mean component to preserve semantic fidelity. Extensive experiments across zero-shot classification, text-to-image retrieval, and image generation validate the effectiveness of SPD: our method achieves more robust debiasing with an average improvement of $18.5\%$ across four fairness metrics, while maintaining minimal loss in task performance compared to the best debiasing baseline.

</details>


### [79] [SFHand: A Streaming Framework for Language-guided 3D Hand Forecasting and Embodied Manipulation](https://arxiv.org/abs/2511.18127)
*Ruicong Liu,Yifei Huang,Liangyang Ouyang,Caixin Kang,Yoichi Sato*

Main category: cs.CV

TL;DR: SFHand是首个用于语言引导3D手部预测的流式框架，能够从连续的视频流和语言指令中自回归预测未来的3D手部状态，在3D手部预测任务中比现有方法提升35.8%，并在下游操作任务中提升13.4%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的3D手部预测方法不适合实时人机交互场景，因为它们通常需要离线访问累积的视频序列，并且无法整合传达任务意图的语言指导。

Method: SFHand结合了流式自回归架构和ROI增强记忆层，从连续的视频和语言指令流中自回归预测全面的未来3D手部状态（包括手部类型、2D边界框、3D姿态和轨迹）。

Result: SFHand在3D手部预测方面达到了新的最先进水平，比先前工作显著提升了35.8%。学习到的表示在下游具身操作任务中也有实用价值，在多个基准测试中将任务成功率提高了13.4%。

Conclusion: SFHand是首个能够处理语言引导3D手部预测的流式框架，在实时人机交互场景中表现出色，并为下游任务提供了有价值的表示。

Abstract: Real-time 3D hand forecasting is a critical component for fluid human-computer interaction in applications like AR and assistive robotics. However, existing methods are ill-suited for these scenarios, as they typically require offline access to accumulated video sequences and cannot incorporate language guidance that conveys task intent. To overcome these limitations, we introduce SFHand, the first streaming framework for language-guided 3D hand forecasting. SFHand autoregressively predicts a comprehensive set of future 3D hand states, including hand type, 2D bounding box, 3D pose, and trajectory, from a continuous stream of video and language instructions. Our framework combines a streaming autoregressive architecture with an ROI-enhanced memory layer, capturing temporal context while focusing on salient hand-centric regions. To enable this research, we also introduce EgoHaFL, the first large-scale dataset featuring synchronized 3D hand poses and language instructions. We demonstrate that SFHand achieves new state-of-the-art results in 3D hand forecasting, outperforming prior work by a significant margin of up to 35.8%. Furthermore, we show the practical utility of our learned representations by transferring them to downstream embodied manipulation tasks, improving task success rates by up to 13.4% on multiple benchmarks. Dataset page: https://huggingface.co/datasets/ut-vision/EgoHaFL, project page: https://github.com/ut-vision/SFHand.

</details>


### [80] [Video4Edit: Viewing Image Editing as a Degenerate Temporal Process](https://arxiv.org/abs/2511.18131)
*Xiaofan Li,Yanpeng Sun,Chenming Wu,Fan Duan,YuAn Wang,Weihao Bo,Yumeng Zhang,Dingkang Liang*

Main category: cs.CV

TL;DR: 本文提出了一种基于时序建模视角的图像编辑方法，通过从视频预训练中迁移单帧演化先验，实现了仅需约1%监督数据即可达到主流编辑模型性能的高效微调方案。


<details>
  <summary>Details</summary>
Motivation: 当前多模态基础模型推动了指令驱动的图像生成和编辑，但现有编辑流程成本高昂，需要大量高质量的三元组数据{指令、源图像、编辑图像}，且编辑保真度依赖于指令对目标语义的精确引用。

Method: 从时序建模角度重新审视图像编辑问题，将图像编辑视为退化的时序过程，利用视频预训练中的单帧演化先验进行迁移学习，实现数据高效微调。

Result: 实验表明，该方法在使用仅约1%监督数据的情况下，能够匹配领先开源基线的性能。

Conclusion: 通过时序建模视角和视频预训练先验的迁移，实现了高效的数据利用，显著降低了指令驱动图像编辑的数据需求。

Abstract: We observe that recent advances in multimodal foundation models have propelled instruction-driven image generation and editing into a genuinely cross-modal, cooperative regime. Nevertheless, state-of-the-art editing pipelines remain costly: beyond training large diffusion/flow models, they require curating massive high-quality triplets of \{instruction, source image, edited image\} to cover diverse user intents. Moreover, the fidelity of visual replacements hinges on how precisely the instruction references the target semantics. We revisit this challenge through the lens of temporal modeling: if video can be regarded as a full temporal process, then image editing can be seen as a degenerate temporal process. This perspective allows us to transfer single-frame evolution priors from video pre-training, enabling a highly data-efficient fine-tuning regime. Empirically, our approach matches the performance of leading open-source baselines while using only about one percent of the supervision demanded by mainstream editing models.

</details>


### [81] [SCALER: SAM-Enhanced Collaborative Learning for Label-Deficient Concealed Object Segmentation](https://arxiv.org/abs/2511.18136)
*Chunming He,Rihan Zhang,Longxiang Tang,Ziyun Yang,Kai Li,Deng-Ping Fan,Sina Farsiu*

Main category: cs.CV

TL;DR: SCALER是一个统一协作框架，通过联合优化均值教师分割器和可学习SAM来解决标签不足的隐蔽目标分割问题，在两个交替阶段中实现相互监督和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在标签不足的隐蔽目标分割中性能有限，本研究旨在探索一致性约束和SAM监督的联合集成，以及分割器与SAM之间的相互指导机制。

Method: 提出SCALER框架，包含两个交替阶段：阶段I在固定SAM监督下优化分割器，使用基于熵的图像级和基于不确定性的像素级加权；阶段II通过增强不变性和噪声抵抗损失更新SAM。

Result: 实验表明SCALER在八个半监督和弱监督COS任务中产生一致的性能提升，能够作为通用训练范式在标签稀缺条件下增强轻量分割器和大型基础模型。

Conclusion: SCALER成功验证了分割器与SAM可以相互监督实现共同改进，为标签不足的隐蔽目标分割提供了有效的解决方案。

Abstract: Existing methods for label-deficient concealed object segmentation (LDCOS) either rely on consistency constraints or Segment Anything Model (SAM)-based pseudo-labeling. However, their performance remains limited due to the intrinsic concealment of targets and the scarcity of annotations. This study investigates two key questions: (1) Can consistency constraints and SAM-based supervision be jointly integrated to better exploit complementary information and enhance the segmenter? and (2) beyond that, can the segmenter in turn guide SAM through reciprocal supervision, enabling mutual improvement? To answer these questions, we present SCALER, a unified collaborative framework toward LDCOS that jointly optimizes a mean-teacher segmenter and a learnable SAM. SCALER operates in two alternating phases. In \textbf{Phase \uppercase\expandafter{\romannumeral1}}, the segmenter is optimized under fixed SAM supervision using entropy-based image-level and uncertainty-based pixel-level weighting to select reliable pseudo-label regions and emphasize harder examples. In \textbf{Phase \uppercase\expandafter{\romannumeral2}}, SAM is updated via augmentation invariance and noise resistance losses, leveraging its inherent robustness to perturbations. Experiments demonstrate that SCALER yields consistent performance gains across eight semi- and weakly-supervised COS tasks. The results further suggest that SCALER can serve as a general training paradigm to enhance both lightweight segmenters and large foundation models under label-scarce conditions. Code will be released.

</details>


### [82] [Compact neural networks for astronomy with optimal transport bias correction](https://arxiv.org/abs/2511.18139)
*Shuhuan Wang,Yuzhen Xie,Jiayi Li*

Main category: cs.CV

TL;DR: WaveletMamba是一个结合小波分解与状态空间建模的天文图像处理框架，在64x64分辨率下达到81.72%分类准确率，仅需3.54M参数，并在低分辨率输入下实现高分辨率性能，计算效率提升9.7倍。


<details>
  <summary>Details</summary>
Motivation: 解决天文成像中效率与分辨率之间的权衡问题，该问题限制了大规模形态分类和红移预测。

Method: 集成小波分解、状态空间建模、数学正则化和多级偏差校正的理论驱动框架。

Result: 在64x64分辨率下实现81.72%分类准确率，在244x244分辨率下保持80.93%准确率，计算效率提升9.7倍；多级偏差校正使Log-MSE改善22.96%，异常值减少26.10%。

Conclusion: 数学严谨性使科学AI实现前所未有的效率和全面偏差校正，连接计算机视觉和天体物理学，革新跨学科科学发现。

Abstract: Astronomical imaging confronts an efficiency-resolution tradeoff that limits large-scale morphological classification and redshift prediction. We introduce WaveletMamba, a theory-driven framework integrating wavelet decomposition with state-space modeling, mathematical regularization, and multi-level bias correction. WaveletMamba achieves 81.72% +/- 0.53% classification accuracy at 64x64 resolution with only 3.54M parameters, delivering high-resolution performance (80.93% +/- 0.27% at 244x244) at low-resolution inputs with 9.7x computational efficiency gains. The framework exhibits Resolution Multistability, where models trained on low-resolution data achieve consistent accuracy across different input scales despite divergent internal representations. The framework's multi-level bias correction synergizes HK distance (distribution-level optimal transport) with Color-Aware Weighting (sample-level fine-tuning), achieving 22.96% Log-MSE improvement and 26.10% outlier reduction without explicit selection function modeling. Here, we show that mathematical rigor enables unprecedented efficiency and comprehensive bias correction in scientific AI, bridging computer vision and astrophysics to revolutionize interdisciplinary scientific discovery.

</details>


### [83] [Matching-Based Few-Shot Semantic Segmentation Models Are Interpretable by Design](https://arxiv.org/abs/2511.18163)
*Pasquale De Marinis,Uzay Kaymak,Rogier Brussee,Gennaro Vessio,Giovanna Castellano*

Main category: cs.CV

TL;DR: 本文提出了首个专门用于解释基于匹配的少样本语义分割模型的方法——Affinity Explainer，通过利用模型固有结构特性生成归因图，揭示支持图像中哪些像素对查询分割预测贡献最大。


<details>
  <summary>Details</summary>
Motivation: 少样本语义分割模型在分割新类别方面表现优异，但其决策过程仍然不透明。尽管可解释AI在标准计算机视觉任务中取得了显著进展，但在FSS领域的可解释性研究几乎未被探索，这对于理解模型行为和在数据稀缺场景中指导支持集选择至关重要。

Method: Affinity Explainer方法通过计算支持图像和查询图像特征在多个特征层上的匹配分数，提取归因图来突出显示支持图像中对查询分割预测贡献最大的像素。

Result: 在FSS基准数据集上使用不同模型进行的综合实验表明，Affinity Explainer显著优于适应的标准归因方法。定性分析显示，该方法提供的解释具有结构化、连贯的注意力模式，与模型架构一致，并能实现有效的模型诊断。

Conclusion: 这项工作为可解释的FSS研究奠定了基础，使模型理解和诊断更加可靠，从而构建更可靠的少样本分割系统。

Abstract: Few-Shot Semantic Segmentation (FSS) models achieve strong performance in segmenting novel classes with minimal labeled examples, yet their decision-making processes remain largely opaque. While explainable AI has advanced significantly in standard computer vision tasks, interpretability in FSS remains virtually unexplored despite its critical importance for understanding model behavior and guiding support set selection in data-scarce scenarios. This paper introduces the first dedicated method for interpreting matching-based FSS models by leveraging their inherent structural properties. Our Affinity Explainer approach extracts attribution maps that highlight which pixels in support images contribute most to query segmentation predictions, using matching scores computed between support and query features at multiple feature levels. We extend standard interpretability evaluation metrics to the FSS domain and propose additional metrics to better capture the practical utility of explanations in few-shot scenarios. Comprehensive experiments on FSS benchmark datasets, using different models, demonstrate that our Affinity Explainer significantly outperforms adapted standard attribution methods. Qualitative analysis reveals that our explanations provide structured, coherent attention patterns that align with model architectures and and enable effective model diagnosis. This work establishes the foundation for interpretable FSS research, enabling better model understanding and diagnostic for more reliable few-shot segmentation systems. The source code is publicly available at https://github.com/pasqualedem/AffinityExplainer.

</details>


### [84] [Early Lung Cancer Diagnosis from Virtual Follow-up LDCT Generation via Correlational Autoencoder and Latent Flow Matching](https://arxiv.org/abs/2511.18185)
*Yutong Wu,Yifan Wang,Qining Zhang,Chuan Zhou,Lei Ying*

Main category: cs.CV

TL;DR: 本文提出了一种名为CorrFlowNet的生成方法，利用扩散模型生成虚拟的一年随访CT扫描，以早期检测恶性/良性肺结节，减少临床随访等待时间。


<details>
  <summary>Details</summary>
Motivation: 肺癌早期诊断至关重要，但现有AI方法主要关注单次早期CT扫描的影像特征提取。临床实践中患者需要多次随访检查才能确诊，可能错过最佳治疗时机。

Method: 使用相关性自编码器将早期基线和随访CT图像编码到潜在空间，捕捉结节进展动态和相关性，然后通过神经常微分方程进行流匹配，并使用辅助分类器提高诊断准确性。

Result: 在真实临床数据集上的评估表明，该方法相比现有基线模型能显著改善下游肺结节风险评估，其诊断准确性与真实临床CT随访相当。

Conclusion: CorrFlowNet方法具有改善癌症诊断的潜力，能够通过生成虚拟随访CT扫描来辅助早期肺癌诊断。

Abstract: Lung cancer is one of the most commonly diagnosed cancers, and early diagnosis is critical because the survival rate declines sharply once the disease progresses to advanced stages. However, achieving an early diagnosis remains challenging, particularly in distinguishing subtle early signals of malignancy from those of benign conditions. In clinical practice, a patient with a high risk may need to undergo an initial baseline and several annual follow-up examinations (e.g., CT scans) before receiving a definitive diagnosis, which can result in missing the optimal treatment. Recently, Artificial Intelligence (AI) methods have been increasingly used for early diagnosis of lung cancer, but most existing algorithms focus on radiomic features extraction from single early-stage CT scans. Inspired by recent advances in diffusion models for image generation, this paper proposes a generative method, named CorrFlowNet, which creates a virtual, one-year follow-up CT scan after the initial baseline scan. This virtual follow-up would allow for an early detection of malignant/benign nodules, reducing the need to wait for clinical follow-ups. During training, our approach employs a correlational autoencoder to encode both early baseline and follow-up CT images into a latent space that captures the dynamics of nodule progression as well as the correlations between them, followed by a flow matching algorithm on the latent space with a neural ordinary differential equation. An auxiliary classifier is used to further enhance the diagnostic accuracy. Evaluations on a real clinical dataset show our method can significantly improve downstream lung nodule risk assessment compared with existing baseline models. Moreover, its diagnostic accuracy is comparable with real clinical CT follow-ups, highlighting its potential to improve cancer diagnosis.

</details>


### [85] [Generating Synthetic Human Blastocyst Images for In-Vitro Fertilization Blastocyst Grading](https://arxiv.org/abs/2511.18204)
*Pavan Narahari,Suraj Rajendran,Lorena Bori,Jonas E. Malmsten,Qiansheng Zhan,Zev Rosenwaks,Nikica Zaninovic,Iman Hajirasouliha*

Main category: cs.CV

TL;DR: 提出了DIA框架，使用潜在扩散模型生成高质量的第5天囊胚图像，通过条件控制形态类别和焦距，显著改善了胚胎数据稀缺和类别不平衡问题，提升了AI胚胎评估工具的性能。


<details>
  <summary>Details</summary>
Motivation: 体外受精(IVF)中第5天囊胚的形态学评估存在主观性和不一致性，AI模型需要大量多样化数据，但面临数据稀缺、类别不平衡和隐私限制等问题。

Method: 开发了基于潜在扩散模型的DIA框架，能够生成高保真度的囊胚图像，通过Gardner形态学分类和z轴焦距进行细粒度控制。

Result: DIA生成的图像在胚胎学家图灵测试中无法可靠区分真伪；合成数据显著提高了不平衡数据集的分类准确率(p<0.05)；在大型平衡数据集中添加合成数据也能获得统计显著的性能提升；合成数据最多可替代40%的真实数据而不损失准确率。

Conclusion: DIA为解决胚胎数据集中的数据稀缺和类别不平衡问题提供了稳健解决方案，通过生成新颖、高保真且可控的合成图像，能够改善AI胚胎评估工具的性能、公平性和标准化。

Abstract: The success of in vitro fertilization (IVF) at many clinics relies on the accurate morphological assessment of day 5 blastocysts, a process that is often subjective and inconsistent. While artificial intelligence can help standardize this evaluation, models require large, diverse, and balanced datasets, which are often unavailable due to data scarcity, natural class imbalance, and privacy constraints. Existing generative embryo models can mitigate these issues but face several limitations, such as poor image quality, small training datasets, non-robust evaluation, and lack of clinically relevant image generation for effective data augmentation. Here, we present the Diffusion Based Imaging Model for Artificial Blastocysts (DIA) framework, a set of latent diffusion models trained to generate high-fidelity, novel day 5 blastocyst images. Our models provide granular control by conditioning on Gardner-based morphological categories and z-axis focal depth. We rigorously evaluated the models using FID, a memorization metric, an embryologist Turing test, and three downstream classification tasks. Our results show that DIA models generate realistic images that embryologists could not reliably distinguish from real images. Most importantly, we demonstrated clear clinical value. Augmenting an imbalanced dataset with synthetic images significantly improved classification accuracy (p < 0.05). Also, adding synthetic images to an already large, balanced dataset yielded statistically significant performance gains, and synthetic data could replace up to 40% of real data in some cases without a statistically significant loss in accuracy. DIA provides a robust solution for mitigating data scarcity and class imbalance in embryo datasets. By generating novel, high-fidelity, and controllable synthetic images, our models can improve the performance, fairness, and standardization of AI embryo assessment tools.

</details>


### [86] [Large-Scale Pre-training Enables Multimodal AI Differentiation of Radiation Necrosis from Brain Metastasis Progression on Routine MRI](https://arxiv.org/abs/2511.18208)
*Ahmed Gomaa,Annette Schwarz,Ludwig Singer,Arnd Dörfler,Matthias Stefan May,Pluvio Stephan,Ishita Sheth,Juliane Szkitsak,Katharina Breininger,Yixing Huang,Benjamin Frey,Oliver Schnell,Daniel Delev,Roland Coras,Daniel Höfler,Philipp Schubert,Jenny Stritzelberger,Sabine Semrau,Andreas Maier,Dieter H Heiland,Udo S. Gaipl,Andrea Wittig,Rainer Fietkau,Christoph Bert,Stefanie Corradini,Florian Putz*

Main category: cs.CV

TL;DR: 该论文提出了一种基于自监督学习的两阶段深度学习策略，用于区分脑转移瘤立体定向放射外科治疗后的放射性坏死与肿瘤进展，仅使用常规T1CE MRI和标准临床数据。


<details>
  <summary>Details</summary>
Motivation: 区分放射性坏死与肿瘤进展是脑转移瘤治疗后的关键挑战，传统监督学习方法受限于活检确认训练数据的稀缺性，而自监督学习可以利用大规模未标记脑转移瘤影像数据集。

Method: 采用两阶段深度学习策略：首先在10,167个未标记多源T1CE MRI子体积上通过自监督学习预训练Vision Transformer，然后在公开MOLAB数据集上使用双通道输入进行微调，并进行外部验证。

Result: 自监督模型在相同中心测试集上AUC为0.916，在第二中心测试集上AUC为0.764，显著优于全监督ViT和放射组学方法。多模态集成进一步提升了性能。

Conclusion: 大规模预训练显著提高了AI模型性能，该两阶段多模态深度学习策略实现了高精度的放射性坏死与肿瘤进展区分，提供了可解释且临床可及的解决方案。

Abstract: Background: Differentiating radiation necrosis (RN) from tumor progression after stereotactic radiosurgery (SRS) remains a critical challenge in brain metastases. While histopathology represents the gold standard, its invasiveness limits feasibility. Conventional supervised deep learning approaches are constrained by scarce biopsy-confirmed training data. Self-supervised learning (SSL) overcomes this by leveraging the growing availability of large-scale unlabeled brain metastases imaging datasets. Methods: In a two-phase deep learning strategy inspired by the foundation model paradigm, a Vision Transformer (ViT) was pre-trained via SSL on 10,167 unlabeled multi-source T1CE MRI sub-volumes. The pre-trained ViT was then fine-tuned for RN classification using a two-channel input (T1CE MRI and segmentation masks) on the public MOLAB dataset (n=109) using 20% of datasets as same-center held-out test set. External validation was performed on a second-center test cohort (n=28). Results: The self-supervised model achieved an AUC of 0.916 on the same-center test set and 0.764 on the second center test set, surpassing the fully supervised ViT (AUC 0.624/0.496; p=0.001/0.008) and radiomics (AUC 0.807/0.691; p=0.005/0.014). Multimodal integration further improved performance (AUC 0.947/0.821; p=0.073/0.001). Attention map visualizations enabled interpretability showing the model focused on clinically relevant lesion subregions. Conclusion: Large-scale pre-training on increasingly available unlabeled brain metastases datasets substantially improves AI model performance. A two-phase multimodal deep learning strategy achieved high accuracy in differentiating radiation necrosis from tumor progression using only routine T1CE MRI and standard clinical data, providing an interpretable, clinically accessible solution that warrants further validation.

</details>


### [87] [EgoVITA: Learning to Plan and Verify for Egocentric Video Reasoning](https://arxiv.org/abs/2511.18242)
*Yogesh Kulkarni,Pooyan Fazli*

Main category: cs.CV

TL;DR: EgoVITA是一个强化学习框架，通过交替的自我中心规划和第三方验证阶段，提升多模态大语言模型在自我中心视频中的意图和动作推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型从第一人称视角推理意图和动作的挑战，自我中心视频具有部分可观测性、有限视野和自参考运动等特点。

Method: 基于GRPO强化学习框架，交替进行自我中心规划阶段（从第一人称视角预测未来动作步骤）和第三方验证阶段（从第三人称视角检查计划的视觉和逻辑一致性）。

Result: 在自我中心推理任务上显著提升，相比Qwen2.5-VL-7B基线模型，在EgoBlind上提升+7.7，在EgoOrient上提升+4.4，同时在第三方视频任务上保持强泛化能力。

Conclusion: EgoVITA通过结构化的规划和验证机制，使模型能够做出对即将到来的视觉观察具有因果预测性的计划，从而实现更连贯和视觉基础推理。

Abstract: Reasoning about intentions and actions from a first-person (egocentric) perspective remains a fundamental challenge for multimodal large language models (MLLMs). Unlike third-person (exocentric) videos that capture scenes from an outside observer, egocentric videos reflect the actor's continuously changing viewpoint, introducing partial observability, limited field of view, and self-referenced motion. We introduce $\textbf{EgoVITA}$, a reinforcement learning framework that enables MLLMs to reason through structured planning and verification. Built on Group Relative Policy Optimization (GRPO), EgoVITA alternates between two stages: (1) an $\textbf{egocentric planning phase}$, where the model reasons from a first-person viewpoint to predict a step-by-step plan of future actions, and (2) an $\textbf{exocentric verification phase}$, where it switches to a third-person perspective to check the visual and logical consistency of that plan. Through GRPO, the model learns to make plans that are causally predictive of upcoming visual observations, leading to more coherent and visually grounded reasoning. EgoVITA achieves significant gains on egocentric reasoning tasks, outperforming the baseline Qwen2.5-VL-7B by $\mathbf{+7.7}$ on EgoBlind and $\mathbf{+4.4}$ on EgoOrient, while maintaining strong generalization on exocentric video tasks.

</details>


### [88] [UniFlow: Towards Zero-Shot LiDAR Scene Flow for Autonomous Vehicles via Cross-Domain Generalization](https://arxiv.org/abs/2511.18254)
*Siyi Li,Qingwen Zhang,Ishan Khatri,Kyle Vedder,Deva Ramanan,Neehar Peri*

Main category: cs.CV

TL;DR: 本文提出UniFlow方法，通过跨数据集训练学习通用运动先验，在LiDAR场景流估计任务中实现了最先进的性能，在多个数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR场景流方法通常在单一传感器上训练和评估，缺乏通用性。本文旨在学习能够迁移到不同和未见过的LiDAR传感器的通用运动先验。

Method: 提出UniFlow系列前馈模型，统一训练多个大规模LiDAR场景流数据集，包含不同的传感器布局和点云密度。

Result: 在Waymo和nuScenes数据集上分别比现有方法提升5.1%和35.2%，在未见过的TruckScenes数据集上比专门模型提升30.1%。

Conclusion: 运动估计等低级任务对传感器配置不敏感，跨数据集训练能够显著提升LiDAR场景流估计的泛化能力。

Abstract: LiDAR scene flow is the task of estimating per-point 3D motion between consecutive point clouds. Recent methods achieve centimeter-level accuracy on popular autonomous vehicle (AV) datasets, but are typically only trained and evaluated on a single sensor. In this paper, we aim to learn general motion priors that transfer to diverse and unseen LiDAR sensors. However, prior work in LiDAR semantic segmentation and 3D object detection demonstrate that naively training on multiple datasets yields worse performance than single dataset models. Interestingly, we find that this conventional wisdom does not hold for motion estimation, and that state-of-the-art scene flow methods greatly benefit from cross-dataset training. We posit that low-level tasks such as motion estimation may be less sensitive to sensor configuration; indeed, our analysis shows that models trained on fast-moving objects (e.g., from highway datasets) perform well on fast-moving objects, even across different datasets. Informed by our analysis, we propose UniFlow, a family of feedforward models that unifies and trains on multiple large-scale LiDAR scene flow datasets with diverse sensor placements and point cloud densities. Our frustratingly simple solution establishes a new state-of-the-art on Waymo and nuScenes, improving over prior work by 5.1% and 35.2% respectively. Moreover, UniFlow achieves state-of-the-art accuracy on unseen datasets like TruckScenes, outperforming prior TruckScenes-specific models by 30.1%.

</details>


### [89] [Sequence-Adaptive Video Prediction in Continuous Streams using Diffusion Noise Optimization](https://arxiv.org/abs/2511.18255)
*Sina Mokhtarzadeh Azar,Emad Bahrami,Enrico Pallotta,Gianpiero Francesca,Radu Timofte,Juergen Gall*

Main category: cs.CV

TL;DR: 本文提出SAVi-DNO方法，通过优化扩散噪声而非模型参数来适应连续视频流预测，在保持模型参数固定的情况下实现持续自适应。


<details>
  <summary>Details</summary>
Motivation: 针对连续视频流预测场景，现有扩散模型无法有效利用不断出现的新训练样本进行自适应改进，需要一种高效的自适应方法。

Method: 提出序列自适应视频预测与扩散噪声优化(SAVi-DNO)，在推理过程中优化扩散噪声而非微调模型参数，使模型能自适应确定合适的采样噪声。

Result: 在Ego4D、OpenDV-YouTube、UCF-101和SkyTimelapse数据集上的实验表明，该方法在FVD、SSIM和PSNR指标上均有提升。

Conclusion: SAVi-DNO方法能有效提升扩散模型在连续视频流预测中的性能，提供了一种参数高效的自适应解决方案。

Abstract: In this work, we investigate diffusion-based video prediction models, which forecast future video frames, for continuous video streams. In this context, the models observe continuously new training samples, and we aim to leverage this to improve their predictions. We thus propose an approach that continuously adapts a pre-trained diffusion model to a video stream. Since fine-tuning the parameters of a large diffusion model is too expensive, we refine the diffusion noise during inference while keeping the model parameters frozen, allowing the model to adaptively determine suitable sampling noise. We term the approach Sequence Adaptive Video Prediction with Diffusion Noise Optimization (SAVi-DNO). To validate our approach, we introduce a new evaluation setting on the Ego4D dataset, focusing on simultaneous adaptation and evaluation on long continuous videos. Empirical results demonstrate improved performance based on FVD, SSIM, and PSNR metrics on long videos of Ego4D and OpenDV-YouTube, as well as videos of UCF-101 and SkyTimelapse, showcasing SAVi-DNO's effectiveness.

</details>


### [90] [MammothModa2: A Unified AR-Diffusion Framework for Multimodal Understanding and Generation](https://arxiv.org/abs/2511.18262)
*Tao Shen,Xin Wan,Taicai Chen,Rui Zhang,Junwen Pan,Dawei Lu,Fanding Lei,Zhilin Lu,Yunfei Yang,Chen Cheng,Qi She,Chang Liu,Zhenbang Sun*

Main category: cs.CV

TL;DR: Mammoth2是一个统一的AR-Diffusion框架，通过自回归语义规划和扩散生成相结合，实现了高质量图像生成和编辑，同时在多模态理解任务上保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型需要在单一框架中集成理解和生成能力，但离散语义推理与高保真视觉合成之间的差距仍然存在挑战。

Method: 采用串行设计：AR路径进行全局语义建模，单流DiT解码器处理高保真图像合成；通过AR-Diffusion特征对齐模块稳定对齐表示；使用联合训练目标进行端到端训练。

Result: 在公开基准测试中表现优异：GenEval得分0.87，DPGBench得分87.2，ImgEdit得分4.06；与仅理解模型保持竞争力。

Conclusion: 精心耦合的AR-Diffusion架构可以在单一、参数和数据高效的模型中提供高保真生成和编辑，同时保持强大的多模态理解能力。

Abstract: Unified multimodal models aim to integrate understanding and generation within a single framework, yet bridging the gap between discrete semantic reasoning and high-fidelity visual synthesis remains challenging. We present MammothModa2 (Mammoth2), a unified autoregressive-diffusion (AR-Diffusion) framework designed to effectively couple autoregressive semantic planning with diffusion-based generation. Mammoth2 adopts a serial design: an AR path equipped with generation experts performs global semantic modeling over discrete tokens, while a single-stream Diffusion Transformer (DiT) decoder handles high-fidelity image synthesis. A carefully designed AR-Diffusion feature alignment module combines multi-layer feature aggregation, unified condition encoding, and in-context conditioning to stably align AR's representations with the diffusion decoder's continuous latents. Mammoth2 is trained end-to-end with joint Next-Token Prediction and Flow Matching objectives, followed by supervised fine-tuning and reinforcement learning over both generation and editing. With roughly 60M supervised generation samples and no reliance on pre-trained generators, Mammoth2 delivers strong text-to-image and instruction-based editing performance on public benchmarks, achieving 0.87 on GenEval, 87.2 on DPGBench, and 4.06 on ImgEdit, while remaining competitive with understanding-only backbones (e.g., Qwen3-VL-8B) on multimodal understanding tasks. These results suggest that a carefully coupled AR-Diffusion architecture can provide high-fidelity generation and editing while maintaining strong multimodal comprehension within a single, parameter- and data-efficient model.

</details>


### [91] [Beyond Words and Pixels: A Benchmark for Implicit World Knowledge Reasoning in Generative Models](https://arxiv.org/abs/2511.18271)
*Tianyang Han,Junhao Su,Junjie Hu,Peizhen Yang,Hengyu Shi,Junfeng Luo,Jialin Gao*

Main category: cs.CV

TL;DR: PicWorld是首个评估文本到图像模型隐式世界知识和物理因果推理能力的基准，包含1100个提示，通过PW-Agent多智能体评估器进行分层评估，发现现有模型普遍存在知识推理能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要关注组合对齐或单轮VQA评分，对知识基础、多物理交互和可审计证据等关键维度测试不足，需要更全面的评估基准。

Method: 提出PicWorld基准，包含三个核心类别的1100个提示，开发PW-Agent证据基础的多智能体评估器，将提示分解为可验证的视觉证据进行分层评估。

Result: 对17个主流T2I模型的分析表明，它们在隐式世界知识和物理因果推理能力方面普遍存在根本性限制，程度各不相同。

Conclusion: 研究结果强调未来T2I系统需要具备推理感知和知识集成架构，以提升模型的物理真实性和逻辑一致性。

Abstract: Text-to-image (T2I) models today are capable of producing photorealistic, instruction-following images, yet they still frequently fail on prompts that require implicit world knowledge. Existing evaluation protocols either emphasize compositional alignment or rely on single-round VQA-based scoring, leaving critical dimensions such as knowledge grounding, multi-physics interactions, and auditable evidence-substantially undertested. To address these limitations, we introduce PicWorld, the first comprehensive benchmark that assesses the grasp of implicit world knowledge and physical causal reasoning of T2I models. This benchmark consists of 1,100 prompts across three core categories. To facilitate fine-grained evaluation, we propose PW-Agent, an evidence-grounded multi-agent evaluator to hierarchically assess images on their physical realism and logical consistency by decomposing prompts into verifiable visual evidence. We conduct a thorough analysis of 17 mainstream T2I models on PicWorld, illustrating that they universally exhibit a fundamental limitation in their capacity for implicit world knowledge and physical causal reasoning to varying degrees. The findings highlight the need for reasoning-aware, knowledge-integrative architectures in future T2I systems.

</details>


### [92] [Vision Token Masking Alone Cannot Prevent PHI Leakage in Medical Document OCR: A Systematic Evaluation](https://arxiv.org/abs/2511.18272)
*Richard J. Young*

Main category: cs.CV

TL;DR: 本文首次系统评估了在医疗文档OCR中使用视觉token掩码作为隐私保护机制的效果，发现所有掩码策略对PHI的减少率都收敛于42.9%，能有效抑制长格式空间分布标识符但无法阻止短结构化标识符泄露。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医疗环境中部署用于OCR处理时，会引发受保护健康信息暴露的关键隐私担忧，需要评估视觉掩码作为隐私保护机制的有效性。

Method: 提出了七种针对不同架构层的掩码策略，使用100份合成医疗账单语句评估PHI减少效果，并进行掩码扩展半径的消融研究。

Result: 所有掩码策略对PHI的减少率都收敛于42.9%，能100%有效抑制长格式标识符，但对短结构化标识符完全无效。增加空间覆盖范围无法突破这一上限。

Conclusion: 这一负面结果为仅视觉隐私干预设定了边界，区分了适合视觉级与语言级编辑的PHI类型，并指导未来研究转向解码器级微调和混合防御架构以实现HIPAA合规的医疗文档处理。

Abstract: Large vision-language models (VLMs) are increasingly deployed for optical character recognition (OCR) in healthcare settings, raising critical concerns about protected health information (PHI) exposure during document processing. This work presents the first systematic evaluation of inference-time vision token masking as a privacy-preserving mechanism for medical document OCR using DeepSeek-OCR. We introduce seven masking strategies (V3-V9) targeting different architectural layers (SAM encoder blocks, compression layers, dual vision encoders, projector fusion) and evaluate PHI reduction across HIPAA-defined categories using 100 synthetic medical billing statements (drawn from a corpus of 38,517 annotated documents) with perfect ground-truth annotations. All masking strategies converge to 42.9% PHI reduction, successfully suppressing long-form spatially-distributed identifiers (patient names, dates of birth, physical addresses at 100% effectiveness) while failing to prevent short structured identifiers (medical record numbers, social security numbers, email addresses, account numbers at 0% effectiveness). Ablation studies varying mask expansion radius (r=1,2,3) demonstrate that increased spatial coverage does not improve reduction beyond this ceiling, indicating that language model contextual inference - not insufficient visual masking - drives structured identifier leakage. A simulated hybrid architecture combining vision masking with NLP post-processing achieves 88.6% total PHI reduction (assuming 80% NLP accuracy on remaining identifiers). This negative result establishes boundaries for vision-only privacy interventions in VLMs, provides guidance distinguishing PHI types amenable to vision-level versus language-level redaction, and redirects future research toward decoder-level fine-tuning and hybrid defense-in-depth architectures for HIPAA-compliant medical document processing.

</details>


### [93] [Point-to-Point: Sparse Motion Guidance for Controllable Video Editing](https://arxiv.org/abs/2511.18277)
*Yeji Song,Jaehyun Lee,Mijin Koo,JunHoo Lee,Nojun Kwak*

Main category: cs.CV

TL;DR: 本文提出了一种名为锚点令牌的新型运动表示方法，通过利用视频扩散模型的丰富先验知识来捕捉最本质的运动模式，解决了视频编辑中准确保持运动的核心挑战。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法在编辑保真度和运动保真度之间存在权衡，因为它们依赖的运动表示要么过度拟合布局，要么仅隐式定义。为了克服这一限制，需要重新审视基于点的运动表示，但在没有人工输入的情况下识别有意义的点仍然具有挑战性。

Method: 提出锚点令牌运动表示方法，通过少量信息丰富的点轨迹紧凑编码视频动态，并可以灵活重新定位以与新主题对齐。该方法名为Point-to-Point，能够泛化到多样化场景。

Result: 大量实验证明，锚点令牌能够实现更可控和语义对齐的视频编辑，在编辑保真度和运动保真度方面均取得优异性能。

Conclusion: 锚点令牌作为一种新颖的运动表示方法，能够有效解决视频编辑中的运动保持问题，为多样化场景下的视频编辑提供了更优的解决方案。

Abstract: Accurately preserving motion while editing a subject remains a core challenge in video editing tasks. Existing methods often face a trade-off between edit and motion fidelity, as they rely on motion representations that are either overfitted to the layout or only implicitly defined. To overcome this limitation, we revisit point-based motion representation. However, identifying meaningful points remains challenging without human input, especially across diverse video scenarios. To address this, we propose a novel motion representation, anchor tokens, that capture the most essential motion patterns by leveraging the rich prior of a video diffusion model. Anchor tokens encode video dynamics compactly through a small number of informative point trajectories and can be flexibly relocated to align with new subjects. This allows our method, Point-to-Point, to generalize across diverse scenarios. Extensive experiments demonstrate that anchor tokens lead to more controllable and semantically aligned video edits, achieving superior performance in terms of edit and motion fidelity.

</details>


### [94] [RoadSceneVQA: Benchmarking Visual Question Answering in Roadside Perception Systems for Intelligent Transportation System](https://arxiv.org/abs/2511.18286)
*Runwei Guan,Rongsheng Hu,Shangshu Chen,Ningyuan Xiao,Xue Xia,Jiayang Liu,Beibei Chen,Ziren Tang,Ningwei Ouyang,Shaofeng Liang,Yuxuan Fan,Wanjie Sun,Yutao Yue*

Main category: cs.CV

TL;DR: RoadSceneVQA是一个专为路边场景设计的大规模视觉问答数据集，包含34,736个多样化QA对，旨在通过自然语言交互和上下文推理来增强路边感知系统。


<details>
  <summary>Details</summary>
Motivation: 现有的路边感知系统主要关注实例级感知，缺乏通过自然语言进行交互和基于上下文推理交通行为的能力。

Method: 提出RoadSceneVQA数据集，并开发CogniAnchor Fusion视觉语言融合模块和Assisted Decoupled Chain-of-Thought方法，构建基准模型RoadMind。

Result: 在RoadSceneVQA和CODA-LM基准测试中，该流水线持续提高了推理准确性和计算效率，在多模态大语言模型中实现了最先进的性能。

Conclusion: 该方法成功地将结构化的交通感知和推理任务与自然语言交互相结合，为路边场景的智能理解提供了有效解决方案。

Abstract: Current roadside perception systems mainly focus on instance-level perception, which fall short in enabling interaction via natural language and reasoning about traffic behaviors in context. To bridge this gap, we introduce RoadSceneVQA, a large-scale and richly annotated visual question answering (VQA) dataset specifically tailored for roadside scenarios. The dataset comprises 34,736 diverse QA pairs collected under varying weather, illumination, and traffic conditions, targeting not only object attributes but also the intent, legality, and interaction patterns of traffic participants. RoadSceneVQA challenges models to perform both explicit recognition and implicit commonsense reasoning, grounded in real-world traffic rules and contextual dependencies. To fully exploit the reasoning potential of Multi-modal Large Language Models (MLLMs), we further propose CogniAnchor Fusion (CAF), a vision-language fusion module inspired by human-like scene anchoring mechanisms. Moreover, we propose the Assisted Decoupled Chain-of-Thought (AD-CoT) to enhance the reasoned thinking via CoT prompting and multi-task learning. Based on the above, we propose the baseline model RoadMind. Experiments on RoadSceneVQA and CODA-LM benchmark show that the pipeline consistently improves both reasoning accuracy and computational efficiency, allowing the MLLM to achieve state-of-the-art performance in structural traffic perception and reasoning tasks.

</details>


### [95] [SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes](https://arxiv.org/abs/2511.18290)
*Jungho Lee,Minhyeok Lee,Sunghun Yang,Minseok Kang,Sangyoun Lee*

Main category: cs.CV

TL;DR: SwiftVGGT是一种无需训练的3D重建方法，在大规模场景中显著减少推理时间的同时保持高质量密集重建，通过消除外部VPR模型依赖和简化点采样对齐来实现高效重建。


<details>
  <summary>Details</summary>
Motivation: 大规模场景3D重建面临精度与计算效率的权衡挑战，现有方法要么速度快但质量低，要么质量高但推理慢，需要一种既能保持高质量又能显著减少推理时间的方法。

Method: 提出SwiftVGGT训练免费方法：1）无需外部VPR模型实现闭环检测保持全局一致性；2）提出简单有效的点采样方法，使用单一Sim(3)基SVD步骤对齐相邻块，消除IRLS优化需求。

Result: 在多个数据集上评估显示，SwiftVGGT达到最先进的重建质量，同时仅需要最近VGGT基大规模重建方法33%的推理时间。

Conclusion: SwiftVGGT成功解决了大规模3D重建中精度与效率的权衡问题，实现了高质量重建与显著加速的平衡，为大规模环境感知提供了实用解决方案。

Abstract: 3D reconstruction in large-scale scenes is a fundamental task in 3D perception, but the inherent trade-off between accuracy and computational efficiency remains a significant challenge. Existing methods either prioritize speed and produce low-quality results, or achieve high-quality reconstruction at the cost of slow inference times. In this paper, we propose SwiftVGGT, a training-free method that significantly reduce inference time while preserving high-quality dense 3D reconstruction. To maintain global consistency in large-scale scenes, SwiftVGGT performs loop closure without relying on the external Visual Place Recognition (VPR) model. This removes redundant computation and enables accurate reconstruction over kilometer-scale environments. Furthermore, we propose a simple yet effective point sampling method to align neighboring chunks using a single Sim(3)-based Singular Value Decomposition (SVD) step. This eliminates the need for the Iteratively Reweighted Least Squares (IRLS) optimization commonly used in prior work, leading to substantial speed-ups. We evaluate SwiftVGGT on multiple datasets and show that it achieves state-of-the-art reconstruction quality while requiring only 33% of the inference time of recent VGGT-based large-scale reconstruction approaches.

</details>


### [96] [DiVE-k: Differential Visual Reasoning for Fine-grained Image Recognition](https://arxiv.org/abs/2511.18305)
*Raja Kumar,Arka Sadhu,Ram Nevatia*

Main category: cs.CV

TL;DR: DiVE-k是一个利用模型自身top-k预测作为训练信号的框架，通过创建多项选择题并使用强化学习训练模型选择正确答案，以提升细粒度图像识别能力。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型拥有丰富的文本知识，但在细粒度图像识别方面表现不佳，难以区分视觉上相似的类别。现有的基于精确匹配奖励信号的强化学习方法容易导致记忆训练类别，缺乏泛化能力。

Method: 提出DiVE-k框架：对每个训练图像，从模型top-k输出创建多项选择题，使用强化学习训练模型选择正确答案。这种方法要求模型在合理选项间进行细粒度差分推理。

Result: 在五个标准细粒度数据集上的实验表明，该方法显著优于现有方法。在基础到新类泛化设置中，DiVE-k在调和平均值上分别超过QWEN2.5-VL-7B和ViRFT 10.04%和6.16%。

Conclusion: DiVE-k通过利用模型自身top-k预测作为训练信号，提供了一个简单可验证的奖励信号，减轻了记忆问题并提高了泛化能力，在细粒度视觉推理任务中表现出色。

Abstract: Large Vision Language Models (LVLMs) possess extensive text knowledge but struggles to utilize this knowledge for fine-grained image recognition, often failing to differentiate between visually similar categories. Existing fine-tuning methods using Reinforcement Learning (RL) with exact-match reward signals are often brittle, encourage memorization of training categories, and fail to elicit differential reasoning needed for generalization to unseen classes. To address this, we propose $\textbf{DiVE-k}$, $\textbf{Di}$fferential $\textbf{V}$isual r$\textbf{E}$asoning using top-$\textbf{k}$ generations, framework that leverages model's own top-k predictions as a training signal. For each training image, DiVE-k creates a multiple-choice question from the model's top-k outputs and uses RL to train the model to select the correct answer. This approach requires the model to perform fine-grained differential reasoning among plausible options and provides a simple, verifiable reward signal that mitigates memorization and improves generalization. Experiments on five standard fine-grained datasets show that our method significantly outperforms existing approaches. In the standard base-to-novel generalization setting, DiVE-k surpasses the QWEN2.5-VL-7B and ViRFT by 10.04% and 6.16% on the Harmonic Mean metric, respectively. Further experiments show similar gains in mixed-domain and few-shot scenarios.

</details>


### [97] [ScriptViT: Vision Transformer-Based Personalized Handwriting Generation](https://arxiv.org/abs/2511.18307)
*Sajjan Acharya,Rajendra Baskota*

Main category: cs.CV

TL;DR: 提出一个统一的框架，通过Vision Transformer风格编码器和交叉注意力机制，解决手写体生成中全局风格模式捕获不足的问题，并引入显著性笔画注意力分析提高可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有手写体生成方法在捕获作者特定的全局风格模式（如一致的倾斜度、曲率或笔画压力）方面存在困难，特别是处理长距离空间依赖关系时。

Method: 使用Vision Transformer风格编码器从多个参考图像学习全局风格模式，通过交叉注意力机制将风格线索与目标文本集成，并采用显著性笔画注意力分析提高可解释性。

Result: 该方法能够更准确地反映目标风格，生成的手写图像在风格上更加一致，同时便于理解和分析。

Conclusion: 提出的框架不仅提高了手写体生成的风格一致性，还通过可解释性分析增强了模型的透明度和实用性。

Abstract: Styled handwriting generation aims to synthesize handwritten text that looks both realistic and aligned with a specific writer's style. While recent approaches involving GAN, transformer and diffusion-based models have made progress, they often struggle to capture the full spectrum of writer-specific attributes, particularly global stylistic patterns that span long-range spatial dependencies. As a result, capturing subtle writer-specific traits such as consistent slant, curvature or stroke pressure, while keeping the generated text accurate is still an open problem. In this work, we present a unified framework designed to address these limitations. We introduce a Vision Transformer-based style encoder that learns global stylistic patterns from multiple reference images, allowing the model to better represent long-range structural characteristics of handwriting. We then integrate these style cues with the target text using a cross-attention mechanism, enabling the system to produce handwritten images that more faithfully reflect the intended style. To make the process more interpretable, we utilize Salient Stroke Attention Analysis (SSAA), which reveals the stroke-level features the model focuses on during style transfer. Together, these components lead to handwriting synthesis that is not only more stylistically coherent, but also easier to understand and analyze.

</details>


### [98] [Stro-VIGRU: Defining the Vision Recurrent-Based Baseline Model for Brain Stroke Classification](https://arxiv.org/abs/2511.18316)
*Subhajeet Das,Pritam Paul,Rohit Bahadur,Sohan Das*

Main category: cs.CV

TL;DR: 提出基于预训练Vision Transformer的迁移学习框架，用于脑卒中的早期识别，通过冻结部分编码器块和微调其他块来学习脑卒中特定特征，结合Bi-GRU进行分类，在脑卒中数据集上达到94.06%的准确率。


<details>
  <summary>Details</summary>
Motivation: 脑卒中是全球主要致死和致残原因，早期识别对成功治疗至关重要。CT扫描是常用诊断方法，但手动分析耗时且易出错，需要自动化解决方案。

Method: 使用预训练的Vision Transformer模型，冻结部分编码器块，微调其余块以学习脑卒中特征，提取的特征输入单层双向GRU进行分类，通过数据增强处理类别不平衡问题。

Result: 在脑卒中数据集上实现了94.06%的分类准确率，表明该模型能够有效识别脑卒中。

Conclusion: 提出的基于Vision Transformer的迁移学习框架在脑卒中早期识别方面表现出色，为自动化脑卒中诊断提供了有效解决方案。

Abstract: Stroke majorly causes death and disability worldwide, and early recognition is one of the key elements of successful treatment of the same. It is common to diagnose strokes using CT scanning, which is fast and readily available, however, manual analysis may take time and may result in mistakes. In this work, a pre-trained Vision Transformer-based transfer learning framework is proposed for the early identification of brain stroke. A few of the encoder blocks of the ViT model are frozen, and the rest are allowed to be fine-tuned in order to learn brain stroke-specific features. The features that have been extracted are given as input to a single-layer Bi-GRU to perform classification. Class imbalance is handled by data augmentation. The model has achieved 94.06% accuracy in classifying brain stroke from the Stroke Dataset.

</details>


### [99] [Optimal Pose Guidance for Stereo Calibration in 3D Deformation Measurement](https://arxiv.org/abs/2511.18317)
*Dongcai Tan,Shunkun Liang,Bin Li,Banglei Guan,Ang Su,Yuan Lin,Dapeng Zhang,Minggang Wan,Zibin Liu,Chenglong Wang,Jiajian Zhu,Zhang Li,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出一种用于3D变形测量的立体标定最优姿态引导方法，通过交互式标定框架自动生成最优姿态，提高标定效率和精度。


<details>
  <summary>Details</summary>
Motivation: 当前立体标定方法缺乏直观的最优姿态指导，导致变形测量效率低下和精度不理想，需要开发能够自动生成最优姿态的交互式标定框架。

Method: 提出姿态优化方法，引入相对和绝对外参的联合优化，以协方差矩阵迹最小化为损失函数求解下一个最优姿态，并集成用户友好的图形界面。

Result: 与随机姿态相比，该方法在效率（需要更少图像）和精度（测量误差更低）方面表现优越，在不同视场下保持鲁棒性，热变形测量结果与有限元分析高度一致。

Conclusion: 提出的姿态引导方法在3D变形测量领域具有显著应用潜力，仿真实验、真实实验和热变形测量应用均验证了其有效性。

Abstract: Stereo optical measurement techniques, such as digital image correlation (DIC), are widely used in 3D deformation measurement as non-contact, full-field measurement methods, in which stereo calibration is a crucial step. However, current stereo calibration methods lack intuitive optimal pose guidance, leading to inefficiency and suboptimal accuracy in deformation measurements. The aim of this study is to develop an interactive calibration framework that automatically generates the next optimal pose, enabling high-accuracy stereo calibration for 3D deformation measurement. We propose a pose optimization method that introduces joint optimization of relative and absolute extrinsic parameters, with the minimization of the covariance matrix trace adopted as the loss function to solve for the next optimal pose. Integrated with this method is a user-friendly graphical interface, which guides even non-expert users to capture qualified calibration images. Our proposed method demonstrates superior efficiency (requiring fewer images) and accuracy (demonstrating lower measurement errors) compared to random pose, while maintaining robustness across varying FOVs. In the thermal deformation measurement tests on an S-shaped specimen, the results exhibit high agreement with finite element analysis (FEA) simulations in both deformation magnitude and evolutionary trends. We present a pose guidance method for high-precision stereo calibration in 3D deformation measurement. The simulation experiments, real-world experiments, and thermal deformation measurement applications all demonstrate the significant application potential of our proposed method in the field of 3D deformation measurement.
  Keywords: Stereo calibration, Optimal pose guidance, 3D deformation measurement, Digital image correlation

</details>


### [100] [General vs Domain-Specific CNNs: Understanding Pretraining Effects on Brain MRI Tumor Classification](https://arxiv.org/abs/2511.18326)
*Helia Abedini,Saba Rahimi,Reza Vaziri*

Main category: cs.CV

TL;DR: 本研究系统评估了三种预训练CNN架构在脑肿瘤分类中的表现，发现尽管RadImageNet DenseNet121具有医学领域预训练，但在小数据集条件下表现最差，而ConvNeXt-Tiny和EfficientNetV2S等现代通用CNN表现更好。


<details>
  <summary>Details</summary>
Motivation: 探讨在小数据集条件下，医学领域预训练模型与通用预训练模型在脑肿瘤MRI分类任务中的性能差异，为医学影像分析选择合适的预训练策略提供指导。

Method: 在相同条件下训练和微调三种预训练CNN架构：RadImageNet DenseNet121（医学领域预训练）、EfficientNetV2S和ConvNeXt-Tiny（通用预训练），使用有限规模的脑MRI数据集进行公平比较。

Result: ConvNeXt-Tiny获得最高准确率，其次是EfficientNetV2S，而RadImageNet DenseNet121尽管有医学领域预训练，但表现出较差的泛化能力，准确率较低且损失较高。

Conclusion: 在小数据条件下，医学领域预训练可能泛化效果不佳，而现代、更深层的通用预训练CNN在大规模数据集上预训练后，在专业医学影像任务中能提供更优越的迁移学习性能。

Abstract: Brain tumor detection from MRI scans plays a crucial role in early diagnosis and treatment planning. Deep convolutional neural networks (CNNs) have demonstrated strong performance in medical imaging tasks, particularly when pretrained on large datasets. However, it remains unclear which type of pretrained model performs better when only a small dataset is available: those trained on domain-specific medical data or those pretrained on large general datasets. In this study, we systematically evaluate three pretrained CNN architectures for brain tumor classification: RadImageNet DenseNet121 with medical-domain pretraining, EfficientNetV2S, and ConvNeXt-Tiny, which are modern general-purpose CNNs. All models were trained and fine-tuned under identical conditions using a limited-size brain MRI dataset to ensure a fair comparison. Our results reveal that ConvNeXt-Tiny achieved the highest accuracy, followed by EfficientNetV2S, while RadImageNet DenseNet121, despite being pretrained on domain-specific medical data, exhibited poor generalization with lower accuracy and higher loss. These findings suggest that domain-specific pretraining may not generalize well under small-data conditions. In contrast, modern, deeper general-purpose CNNs pretrained on large-scale datasets can offer superior transfer learning performance in specialized medical imaging tasks.

</details>


### [101] [SciPostLayoutTree: A Dataset for Structural Analysis of Scientific Posters](https://arxiv.org/abs/2511.18329)
*Shohei Tanaka,Atsushi Hashimoto,Yoshitaka Ushiku*

Main category: cs.CV

TL;DR: 该论文构建了SciPostLayoutTree数据集，包含约8000个标注了阅读顺序和父子关系的学术海报，并开发了Layout Tree Decoder模型来预测海报结构关系，特别提升了空间挑战性关系的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 学术海报在学术交流中扮演重要角色，但相比论文，其结构分析研究相对不足。现有研究主要关注论文结构，而海报的阅读顺序和父子关系分析对于构建结构感知界面至关重要。

Method: 构建SciPostLayoutTree数据集，开发Layout Tree Decoder模型，该模型结合视觉特征和边界框特征（位置和类别信息），并使用束搜索来预测关系同时捕获序列级合理性。

Result: 实验结果表明，该模型提高了空间挑战性关系（向上、水平和长距离关系）的预测准确性，为海报结构分析建立了坚实的基线。

Conclusion: 该研究填补了学术海报结构分析的空白，提出的数据集和模型为海报结构理解提供了有效工具，有助于促进学术海报的清晰准确理解。

Abstract: Scientific posters play a vital role in academic communication by presenting ideas through visual summaries. Analyzing reading order and parent-child relations of posters is essential for building structure-aware interfaces that facilitate clear and accurate understanding of research content. Despite their prevalence in academic communication, posters remain underexplored in structural analysis research, which has primarily focused on papers. To address this gap, we constructed SciPostLayoutTree, a dataset of approximately 8,000 posters annotated with reading order and parent-child relations. Compared to an existing structural analysis dataset, SciPostLayoutTree contains more instances of spatially challenging relations, including upward, horizontal, and long-distance relations. As a solution to these challenges, we develop Layout Tree Decoder, which incorporates visual features as well as bounding box features including position and category information. The model also uses beam search to predict relations while capturing sequence-level plausibility. Experimental results demonstrate that our model improves the prediction accuracy for spatially challenging relations and establishes a solid baseline for poster structure analysis. The dataset is publicly available at https://huggingface.co/datasets/omron-sinicx/scipostlayouttree. The code is also publicly available at https://github.com/omron-sinicx/scipostlayouttree.

</details>


### [102] [ConsistCompose: Unified Multimodal Layout Control for Image Composition](https://arxiv.org/abs/2511.18333)
*Xuanke Shi,Boxuan Li,Xiaoyang Han,Zhongang Cai,Lei Yang,Dahua Lin,Quan Wang*

Main category: cs.CV

TL;DR: ConsistCompose是一个统一的多模态框架，通过将布局坐标嵌入语言提示中，实现从交错图像-文本中进行布局控制的多实例图像生成。该框架构建了包含340万数据对的ConsistCompose3M数据集，并通过实例-坐标绑定提示和坐标感知的无分类器指导来实现精确的空间控制。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型主要关注视觉接地（语言与图像区域对齐），而其生成对应部分——基于布局的多实例生成（LELG）研究不足，限制了精确的组合控制能力。

Method: 提出ConsistCompose框架，将布局坐标直接嵌入语言提示中；构建ConsistCompose3M数据集（340万数据对）；通过实例-坐标绑定提示和坐标感知的无分类器指导实现布局控制。

Result: 在COCO-Position和MS-Bench上的实验表明，ConsistCompose相比布局控制基线显著提高了空间准确性，同时保持了身份保真度和竞争性的通用多模态理解能力。

Conclusion: ConsistCompose为布局可控的多模态图像生成建立了一个统一的范式，实现了精确的空间控制而不需要特定任务分支。

Abstract: Unified multimodal models that couple visual understanding with image generation have advanced rapidly, yet most systems still focus on visual grounding-aligning language with image regions-while their generative counterpart, linguistic-embedded layout-grounded generation (LELG) for layout-controllable multi-instance generation, remains underexplored and limits precise compositional control. We present ConsistCompose, a unified multimodal framework that embeds layout coordinates directly into language prompts, enabling layout-controlled multi-instance image generation from Interleaved Image-Text within a single generative interface. We further construct ConsistCompose3M, a 3.4M multi-instance generation dataset with layout and identity annotations (2.6M text-guided and 0.8M image-guided data pairs) that provides large-scale supervision for layout-conditioned generation. Within this framework, LELG is instantiated through instance-coordinate binding prompts and coordinate-aware classifier-free guidance, which translate linguistic layout cues into precise spatial control without task-specific branches. Experiments on COCO-Position and MS-Bench show that ConsistCompose substantially improves spatial accuracy over layout-controlled baselines while preserving identity fidelity and competitive general multimodal understanding, establishing a unified paradigm for layout-controllable multimodal image generation.

</details>


### [103] [A Tri-Modal Dataset and a Baseline System for Tracking Unmanned Aerial Vehicles](https://arxiv.org/abs/2511.18344)
*Tianyang Xu,Jinjie Gu,Xuefeng Zhu,XiaoJun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 提出了MM-UAV，首个大规模多模态无人机跟踪基准数据集，包含RGB、红外和事件信号三种模态，涵盖30多个挑战性场景，包含1321个同步多模态序列和超过280万标注帧。同时提出了一个专门的多模态多无人机跟踪框架，包含偏移引导自适应对齐模块和自适应动态融合模块，以及事件增强关联机制。


<details>
  <summary>Details</summary>
Motivation: 随着低空无人机的普及，视觉多目标跟踪成为关键安全技术，但在复杂环境条件下单模态跟踪往往失效。虽然多模态多目标无人机跟踪更具鲁棒性，但缺乏专门的公共数据集阻碍了有效解决方案的开发。

Method: 1) 提出偏移引导自适应对齐模块解决跨传感器空间不匹配问题；2) 自适应动态融合模块平衡不同模态的互补信息；3) 事件增强关联机制利用事件模态的运动线索进行更可靠的身份维护。

Result: 综合实验表明，所提出的框架在性能上始终优于最先进的方法。

Conclusion: MM-UAV数据集和提出的多模态跟踪框架为未来多模态无人机跟踪研究提供了重要基础，数据集和源代码将公开提供。

Abstract: With the proliferation of low altitude unmanned aerial vehicles (UAVs), visual multi-object tracking is becoming a critical security technology, demanding significant robustness even in complex environmental conditions. However, tracking UAVs using a single visual modality often fails in challenging scenarios, such as low illumination, cluttered backgrounds, and rapid motion. Although multi-modal multi-object UAV tracking is more resilient, the development of effective solutions has been hindered by the absence of dedicated public datasets. To bridge this gap, we release MM-UAV, the first large-scale benchmark for Multi-Modal UAV Tracking, integrating three key sensing modalities, e.g. RGB, infrared (IR), and event signals. The dataset spans over 30 challenging scenarios, with 1,321 synchronised multi-modal sequences, and more than 2.8 million annotated frames. Accompanying the dataset, we provide a novel multi-modal multi-UAV tracking framework, designed specifically for UAV tracking applications and serving as a baseline for future research. Our framework incorporates two key technical innovations, e.g. an offset-guided adaptive alignment module to resolve spatio mismatches across sensors, and an adaptive dynamic fusion module to balance complementary information conveyed by different modalities. Furthermore, to overcome the limitations of conventional appearance modelling in multi-object tracking, we introduce an event-enhanced association mechanism that leverages motion cues from the event modality for more reliable identity maintenance. Comprehensive experiments demonstrate that the proposed framework consistently outperforms state-of-the-art methods. To foster further research in multi-modal UAV tracking, both the dataset and source code will be made publicly available at https://xuefeng-zhu5.github.io/MM-UAV/.

</details>


### [104] [FlowPortal: Residual-Corrected Flow for Training-Free Video Relighting and Background Replacement](https://arxiv.org/abs/2511.18346)
*Wenshuo Gao,Junyi Fan,Jiangyue Zeng,Shuai Yang*

Main category: cs.CV

TL;DR: FlowPortal是一个无需训练、基于光流的视频重光照框架，通过残差校正光流机制实现高质量的视频重光照和背景替换，在时间一致性、结构保持和光照真实感方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 视频重光照与背景替换在电影制作和创意媒体中具有重要应用价值，但现有方法难以平衡时间一致性、空间保真度和光照自然度。

Method: 提出残差校正光流机制将标准光流模型转化为编辑模型，结合解耦条件设计实现精确光照控制，高频传输机制保持细节，以及掩码策略分离前景重光照和背景生成过程。

Result: 实验证明FlowPortal在时间相干性、结构保持和光照真实感方面达到优越性能，同时保持高效率。

Conclusion: FlowPortal通过创新的训练免费流式框架有效解决了视频重光照中的关键挑战，为视频编辑应用提供了高质量的解决方案。

Abstract: Video relighting with background replacement is a challenging task critical for applications in film production and creative media. Existing methods struggle to balance temporal consistency, spatial fidelity, and illumination naturalness. To address these issues, we introduce FlowPortal, a novel training-free flow-based video relighting framework. Our core innovation is a Residual-Corrected Flow mechanism that transforms a standard flow-based model into an editing model, guaranteeing perfect reconstruction when input conditions are identical and enabling faithful relighting when they differ, resulting in high structural consistency. This is further enhanced by a Decoupled Condition Design for precise lighting control and a High-Frequency Transfer mechanism for detail preservation. Additionally, a masking strategy isolates foreground relighting from background pure generation process. Experiments demonstrate that FlowPortal achieves superior performance in temporal coherence, structural preservation, and lighting realism, while maintaining high efficiency. Project Page: https://gaowenshuo.github.io/FlowPortalProject/.

</details>


### [105] [TRANSPORTER: Transferring Visual Semantics from VLM Manifolds](https://arxiv.org/abs/2511.18359)
*Alexandros Stergiou*

Main category: cs.CV

TL;DR: 本文提出了logits-to-video（L2V）任务和TRANSPORTER方法，通过生成视频来解释视觉语言模型的内部决策过程，为模型可解释性提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在处理复杂场景时，其内部推理过程难以理解和控制，需要新的可解释性方法来揭示模型预测背后的规则。

Method: TRANSPORTER方法利用文本到视频生成模型，通过最优传输耦合将VLM的高语义嵌入空间映射到视频生成，使用logit分数定义嵌入方向进行条件视频生成。

Result: TRANSPORTER能够生成反映不同对象属性、动作副词和场景上下文变化的视频，定量和定性评估表明L2V为模型可解释性提供了高保真度的新方向。

Conclusion: L2V任务和TRANSPORTER方法为理解视觉语言模型的内部决策过程提供了新颖且有效的可解释性工具，填补了该领域的研究空白。

Abstract: How do video understanding models acquire their answers? Although current Vision Language Models (VLMs) reason over complex scenes with diverse objects, action performances, and scene dynamics, understanding and controlling their internal processes remains an open challenge. Motivated by recent advancements in text-to-video (T2V) generative models, this paper introduces a logits-to-video (L2V) task alongside a model-independent approach, TRANSPORTER, to generate videos that capture the underlying rules behind VLMs' predictions. Given the high-visual-fidelity produced by T2V models, TRANSPORTER learns an optimal transport coupling to VLM's high-semantic embedding spaces. In turn, logit scores define embedding directions for conditional video generation. TRANSPORTER generates videos that reflect caption changes over diverse object attributes, action adverbs, and scene context. Quantitative and qualitative evaluations across VLMs demonstrate that L2V can provide a fidelity-rich, novel direction for model interpretability that has not been previously explored.

</details>


### [106] [Alias-free 4D Gaussian Splatting](https://arxiv.org/abs/2511.18367)
*Zilong Chen,Huan-ang Gao,Delin Qu,Haohan Chi,Hao Tang,Kai Zhang,Hao Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种4D高斯抛雪球方法，通过最大采样频率公式、4D尺度自适应滤波器和尺度损失来消除渲染分辨率变化时的高频伪影，并在单目和多视角视频重建中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯抛雪球的动态场景重建方法在调整相机焦距或高斯基元与相机距离以修改渲染分辨率时，会因4D高斯的频率约束和2D膨胀滤波器引起的高斯尺度不匹配而产生强烈伪影。

Method: 推导了4D高斯抛雪球的最大采样频率公式，引入了4D尺度自适应滤波器和尺度损失，灵活调节4D高斯抛雪球的采样频率。

Result: 该方法在增加渲染频率时消除了高频伪影，同时有效减少了多视角视频重建中的冗余高斯基元。

Conclusion: 提出的方法通过单目和多视角视频重建实验验证了其有效性，能够解决渲染分辨率变化时的伪影问题。

Abstract: Existing dynamic scene reconstruction methods based on Gaussian Splatting enable real-time rendering and generate realistic images. However, adjusting the camera's focal length or the distance between Gaussian primitives and the camera to modify rendering resolution often introduces strong artifacts, stemming from the frequency constraints of 4D Gaussians and Gaussian scale mismatch induced by the 2D dilated filter. To address this, we derive a maximum sampling frequency formulation for 4D Gaussian Splatting and introduce a 4D scale-adaptive filter and scale loss, which flexibly regulates the sampling frequency of 4D Gaussian Splatting. Our approach eliminates high-frequency artifacts under increased rendering frequencies while effectively reducing redundant Gaussians in multi-view video reconstruction. We validate the proposed method through monocular and multi-view video reconstruction experiments.Ours project page: https://4d-alias-free.github.io/4D-Alias-free/

</details>


### [107] [MimiCAT: Mimic with Correspondence-Aware Cascade-Transformer for Category-Free 3D Pose Transfer](https://arxiv.org/abs/2511.18370)
*Zenghao Chai,Chen Tang,Yongkang Wong,Xulei Yang,Mohan Kankanhalli*

Main category: cs.CV

TL;DR: 本文提出了MimiCAT模型，用于解决类别无关的3D姿态迁移问题，能够将不同结构角色（如人形到四足动物）的姿态进行迁移，突破了现有方法在相似结构角色间的限制。


<details>
  <summary>Details</summary>
Motivation: 现有3D姿态迁移方法主要局限于相似结构的角色之间，无法泛化到类别无关的设置（如将人形姿态迁移到四足动物）。主要挑战在于不同角色类型的结构和变换多样性导致区域不匹配和迁移质量差。

Method: 构建了百万级跨数百个不同角色的姿态数据集，提出MimiCAT级联变换器模型。利用语义关键点标签学习软对应关系，实现灵活的多对多匹配，将姿态迁移建模为条件生成过程：首先通过软对应匹配将源变换投影到目标，然后使用形状条件表示进行细化。

Result: 广泛的定性和定量实验表明，MimiCAT能够在不同角色间迁移合理的姿态，显著优于仅限于窄类别迁移（如人形到人形）的先前方法。

Conclusion: MimiCAT通过软对应学习和条件生成过程，成功实现了类别无关的3D姿态迁移，为跨不同结构角色的姿态迁移提供了有效解决方案。

Abstract: 3D pose transfer aims to transfer the pose-style of a source mesh to a target character while preserving both the target's geometry and the source's pose characteristic. Existing methods are largely restricted to characters with similar structures and fail to generalize to category-free settings (e.g., transferring a humanoid's pose to a quadruped). The key challenge lies in the structural and transformation diversity inherent in distinct character types, which often leads to mismatched regions and poor transfer quality. To address these issues, we first construct a million-scale pose dataset across hundreds of distinct characters. We further propose MimiCAT, a cascade-transformer model designed for category-free 3D pose transfer. Instead of relying on strict one-to-one correspondence mappings, MimiCAT leverages semantic keypoint labels to learn a novel soft correspondence that enables flexible many-to-many matching across characters. The pose transfer is then formulated as a conditional generation process, in which the source transformations are first projected onto the target through soft correspondence matching and subsequently refined using shape-conditioned representations. Extensive qualitative and quantitative experiments demonstrate that MimiCAT transfers plausible poses across different characters, significantly outperforming prior methods that are limited to narrow category transfer (e.g., humanoid-to-humanoid).

</details>


### [108] [MASS: Motion-Aware Spatial-Temporal Grounding for Physics Reasoning and Comprehension in Vision-Language Models](https://arxiv.org/abs/2511.18373)
*Xiyang Wu,Zongxia Li,Jihui Jin,Guangyao Shi,Gouthaman KV,Vishnu Raj,Nilotpal Sinha,Jingxi Chen,Fan Du,Dinesh Manocha*

Main category: cs.CV

TL;DR: 提出了MASS方法，通过将物理世界上下文线索转换为可解释表示来增强视觉语言模型在物理推理任务上的性能，包括引入MASS-Bench基准和模型无关的空间-时间信号注入技术。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在标准视频任务上表现良好，但在涉及运动动力学和空间交互的物理驱动推理方面存在困难，这限制了它们解释真实或AI生成内容视频以及生成物理一致内容的能力。

Method: 提出MASS方法：1）引入MASS-Bench基准，包含4,350个真实世界和AIGC视频及8,361个问答对；2）通过基于深度的3D编码和视觉接地将空间-时间信号注入VLM语言空间；3）使用运动跟踪器处理物体动力学；4）应用强化微调增强跨模态对齐和推理。

Result: 实验表明，改进后的VLM在物理推理和理解任务上优于可比和更大的基线模型以及先前的最先进模型，分别提升8.7%和6.0%，性能接近闭源SoTA VLM如Gemini-2.5-Flash。

Conclusion: 该方法有效解决了VLM在物理推理方面的局限性，验证了将物理世界上下文转换为可解释表示的方法的有效性。

Abstract: Vision Language Models (VLMs) perform well on standard video tasks but struggle with physics-driven reasoning involving motion dynamics and spatial interactions. This limitation reduces their ability to interpret real or AI-generated content (AIGC) videos and to generate physically consistent content. We present an approach that addresses this gap by translating physical-world context cues into interpretable representations aligned with VLMs' perception, comprehension, and reasoning. We introduce MASS-Bench, a comprehensive benchmark consisting of 4,350 real-world and AIGC videos and 8,361 free-form video question-answering pairs focused on physics-related comprehension tasks, with detailed annotations including visual detections, sub-segment grounding, and full-sequence 3D motion tracking of entities. We further present MASS, a model-agnostic method that injects spatial-temporal signals into the VLM language space via depth-based 3D encoding and visual grounding, coupled with a motion tracker for object dynamics. To strengthen cross-modal alignment and reasoning, we apply reinforcement fine-tuning. Experiments and ablations show that our refined VLMs outperform comparable and larger baselines, as well as prior state-of-the-art models, by 8.7% and 6.0%, achieving performance comparable to close-source SoTA VLMs such as Gemini-2.5-Flash on physics reasoning and comprehension. These results validate the effectiveness of our approach.

</details>


### [109] [Synthetic Curriculum Reinforces Compositional Text-to-Image Generation](https://arxiv.org/abs/2511.18378)
*Shijian Wang,Runhao Fu,Siyi Zhao,Qingqin Zhan,Xingjian Wang,Jiarui Jin,Yuan Lu,Hanqian Wu,Cunjian Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为CompGen的组合式课程强化学习框架，通过场景图建立难度标准，使用自适应MCMC图采样算法生成渐进式训练数据，显著提升了文本到图像生成模型的组合生成能力。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像生成中组合合成这一长期存在的开放性问题，特别是处理包含多个具有不同属性和复杂空间语义关系对象的复杂场景，需要精确的对象放置和连贯的对象间交互。

Method: 利用场景图建立组合能力难度标准，开发自适应马尔可夫链蒙特卡洛图采样算法，通过难度感知方法合成渐进式训练课程数据，将课程学习方法集成到GRPO中，研究不同课程调度策略。

Result: CompGen在不同课程调度策略下表现出不同的扩展曲线，易到难和高斯采样策略相比随机采样具有更优的扩展性能，显著提升了基于扩散和自回归的T2I模型的组合生成能力。

Conclusion: CompGen框架通过组合式课程强化学习有效提高了组合式文本到图像生成系统的性能，证明了其在改进T2I生成模型组合能力方面的有效性。

Abstract: Text-to-Image (T2I) generation has long been an open problem, with compositional synthesis remaining particularly challenging. This task requires accurate rendering of complex scenes containing multiple objects that exhibit diverse attributes as well as intricate spatial and semantic relationships, demanding both precise object placement and coherent inter-object interactions. In this paper, we propose a novel compositional curriculum reinforcement learning framework named CompGen that addresses compositional weakness in existing T2I models. Specifically, we leverage scene graphs to establish a novel difficulty criterion for compositional ability and develop a corresponding adaptive Markov Chain Monte Carlo graph sampling algorithm. This difficulty-aware approach enables the synthesis of training curriculum data that progressively optimize T2I models through reinforcement learning. We integrate our curriculum learning approach into Group Relative Policy Optimization (GRPO) and investigate different curriculum scheduling strategies. Our experiments reveal that CompGen exhibits distinct scaling curves under different curriculum scheduling strategies, with easy-to-hard and Gaussian sampling strategies yielding superior scaling performance compared to random sampling. Extensive experiments demonstrate that CompGen significantly enhances compositional generation capabilities for both diffusion-based and auto-regressive T2I models, highlighting its effectiveness in improving the compositional T2I generation systems.

</details>


### [110] [ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access](https://arxiv.org/abs/2511.18382)
*Timing Yang,Sucheng Ren,Alan Yuille,Feng Wang*

Main category: cs.CV

TL;DR: 本文介绍了ViMix-14M，一个包含约1400万视频-文本对的精心策划的多源数据集，旨在解决开源视频生成模型面临的数据瓶颈问题。该数据集提供无需爬取、可直接下载的访问方式，并包含与视频紧密对齐的长格式高质量字幕。


<details>
  <summary>Details</summary>
Motivation: 解决开源视频生成模型面临的数据瓶颈：缺乏大规模、高质量、易获取的视频-文本语料库。现有公共数据集通常需要手动爬取YouTube，存在链接失效、访问限制和许可不确定性等问题，导致可用量较低。

Method: 通过合并多样化的开放视频源，进行统一的去重和质量过滤，并采用多粒度、基于真实情况指导的重新字幕生成流程，优化描述以更好地匹配动作、场景和时间结构。

Result: 通过多模态检索、文本到视频生成和视频问答任务的评估，观察到相对于对比数据集的持续改进。

Conclusion: 这项工作有助于消除训练和微调开源视频基础模型的关键障碍，并为构建高质量和可泛化的视频-文本数据集提供见解。

Abstract: Text-to-video generation has surged in interest since Sora, yet open-source models still face a data bottleneck: there is no large, high-quality, easily obtainable video-text corpus. Existing public datasets typically require manual YouTube crawling, which yields low usable volume due to link rot and access limits, and raises licensing uncertainty. This work addresses this challenge by introducing ViMix-14M, a curated multi-source video-text dataset of around 14 million pairs that provides crawl-free, download-ready access and long-form, high-quality captions tightly aligned to video. ViMix-14M is built by merging diverse open video sources, followed by unified de-duplication and quality filtering, and a multi-granularity, ground-truth-guided re-captioning pipeline that refines descriptions to better match actions, scenes, and temporal structure. We evaluate the dataset by multimodal retrieval, text-to-video generation, and video question answering tasks, observing consistent improvements over counterpart datasets. We hope this work can help removing the key barrier to training and fine-tuning open-source video foundation models, and provide insights of building high-quality and generalizable video-text datasets.

</details>


### [111] [Can a Second-View Image Be a Language? Geometric and Semantic Cross-Modal Reasoning for X-ray Prohibited Item Detection](https://arxiv.org/abs/2511.18385)
*Chuang Peng,Renshuai Tao,Zhongwei Ren,Xianglong Liu,Yunchao Wei*

Main category: cs.CV

TL;DR: 该论文提出了DualXrayBench——首个包含多视图和多模态的X射线安检综合基准，并开发了GSR模型，通过将第二视图视为类似语言模态来联合学习跨视图几何和跨模态语义的对应关系。


<details>
  <summary>Details</summary>
Motivation: 传统X射线违禁品检测方法仅依赖视觉模态，在复杂威胁检测上表现不佳。虽然近期研究引入了语言引导单视图图像，但实际安检中检查员通常使用双视图图像。因此探索第二视图是否能提供类似语言模态的约束成为研究动机。

Method: 提出了几何-语义推理器(GSR)，这是一个多模态模型，通过构建GSXray数据集（包含结构化思维链序列：<顶部视图>、<侧面视图>、<结论>），联合学习跨视图几何和跨模态语义的对应关系，将第二视图图像视为类似语言模态。

Result: 在DualXrayBench上的综合评估表明，GSR在所有X射线任务上都取得了显著改进，为实际X射线安检提供了新视角。

Conclusion: 将第二视图作为类似语言模态的方法在X射线安检中具有重要价值，GSR模型通过联合学习跨视图几何和跨模态语义对应关系，显著提升了检测性能。

Abstract: Automatic X-ray prohibited items detection is vital for security inspection and has been widely studied. Traditional methods rely on visual modality, often struggling with complex threats. While recent studies incorporate language to guide single-view images, human inspectors typically use dual-view images in practice. This raises the question: can the second view provide constraints similar to a language modality? In this work, we introduce DualXrayBench, the first comprehensive benchmark for X-ray inspection that includes multiple views and modalities. It supports eight tasks designed to test cross-view reasoning. In DualXrayBench, we introduce a caption corpus consisting of 45,613 dual-view image pairs across 12 categories with corresponding captions. Building upon these data, we propose the Geometric (cross-view)-Semantic (cross-modality) Reasoner (GSR), a multimodal model that jointly learns correspondences between cross-view geometry and cross-modal semantics, treating the second-view images as a "language-like modality". To enable this, we construct the GSXray dataset, with structured Chain-of-Thought sequences: <top>, <side>, <conclusion>. Comprehensive evaluations on DualXrayBench demonstrate that GSR achieves significant improvements across all X-ray tasks, offering a new perspective for real-world X-ray inspection.

</details>


### [112] [SegSplat: Feed-forward Gaussian Splatting and Open-Set Semantic Segmentation](https://arxiv.org/abs/2511.18386)
*Peter Siegel,Federico Tombari,Marc Pollefeys,Daniel Barath*

Main category: cs.CV

TL;DR: SegSplat是一个新颖框架，通过从多视角2D基础模型特征构建紧凑语义记忆库，并为每个3D高斯预测离散语义索引、几何和外观属性，实现快速3D重建与开放词汇语义理解的结合。


<details>
  <summary>Details</summary>
Motivation: 弥合快速前馈3D重建与丰富开放词汇语义理解之间的差距，为机器人交互、增强现实等智能系统提供实用的语义感知3D环境生成。

Method: 构建紧凑语义记忆库，从多视角2D基础模型提取特征，为每个3D高斯预测离散语义索引、几何和外观属性，单次前馈完成。

Result: 在几何保真度上与最先进的3D高斯泼溅方法相当，同时实现鲁棒的开放集语义分割，无需任何逐场景优化的语义特征集成。

Conclusion: 该工作代表了向实用、实时生成语义感知3D环境的重要进展，对推进机器人交互、增强现实等智能系统至关重要。

Abstract: We have introduced SegSplat, a novel framework designed to bridge the gap between rapid, feed-forward 3D reconstruction and rich, open-vocabulary semantic understanding. By constructing a compact semantic memory bank from multi-view 2D foundation model features and predicting discrete semantic indices alongside geometric and appearance attributes for each 3D Gaussian in a single pass, SegSplat efficiently imbues scenes with queryable semantics. Our experiments demonstrate that SegSplat achieves geometric fidelity comparable to state-of-the-art feed-forward 3D Gaussian Splatting methods while simultaneously enabling robust open-set semantic segmentation, crucially \textit{without} requiring any per-scene optimization for semantic feature integration. This work represents a significant step towards practical, on-the-fly generation of semantically aware 3D environments, vital for advancing robotic interaction, augmented reality, and other intelligent systems.

</details>


### [113] [Exploring Weak-to-Strong Generalization for CLIP-based Classification](https://arxiv.org/abs/2511.18396)
*Jinhao Li,Sarah M. Erfani,Lei Feng,James Bailey,Feng Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为类别原型学习（CPL）的方法，用于增强CLIP模型在弱监督下的分类能力，通过为每个类别学习更具代表性的原型，在预训练受限的情况下实现了3.67%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着模型复杂度增加，依赖人工监督来对齐大型商业模型与用户意图变得不切实际。当模型超越人类知识时，提供准确反馈变得困难且低效。需要探索使用弱模型监督强模型的新方法。

Method: 提出类别原型学习（CPL）方法，通过为每个类别学习更具代表性的原型来增强CLIP模型的分类能力。该方法在弱监督下使用简单的损失函数，特别适用于预训练受限的场景。

Result: 在目标场景下，特别是在预训练受限的情况下，CPL方法表现稳健，相比强基线方法实现了3.67%的性能提升。

Conclusion: 弱到强泛化的概念在视觉语言模型中同样有效，CPL方法为在有限监督下提升模型性能提供了可行的解决方案。

Abstract: Aligning large-scale commercial models with user intent is crucial to preventing harmful outputs. Current methods rely on human supervision but become impractical as model complexity increases. When models surpass human knowledge, providing accurate feedback becomes challenging and inefficient. A novel solution proposed recently is using a weaker model to supervise a stronger model. This concept leverages the ability of weaker models to perform evaluations, thereby reducing the workload on human supervisors. Previous work has shown the effectiveness of weak-to-strong generalization in the context of language-only models. Extending this concept to vision-language models leverages these insights, adapting the proven benefits to a multi-modal context. In our study, we explore weak-to-strong generalization for CLIP-based classification. We propose a method, class prototype learning (CPL), which aims to enhance the classification capabilities of the CLIP model, by learning more representative prototypes for each category. Our findings indicate that, despite using a simple loss function under weak supervision, CPL yields robust improvements in targeted scenarios, particularly when pretraining is limited. Extensive experiments demonstrate that our approach is effective under these settings, achieving a 3.67% improvement over strong baseline methods.

</details>


### [114] [ChineseVideoBench: Benchmarking Multi-modal Large Models for Chinese Video Question Answering](https://arxiv.org/abs/2511.18399)
*Yuxiang Nie,Han Wang,Yongjie Ye,Haiyang Yu,Weitao Jia,Tao Zeng,Hao Feng,Xiang Fei,Yang Li,Xiaohui Lv,Guozhi Tang,Jingqun Tang,Jinghui Lu,Zehui Dai,Jiacong Wang,Dingkang Yang,An-Lan Wang,Can Huang*

Main category: cs.CV

TL;DR: ChineseVideoBench是一个专门用于评估多模态大语言模型在中文视频问答任务中的基准测试，包含8个主要类别和12个子类别，要求模型具备深度视频理解和中文语言文化认知能力。


<details>
  <summary>Details</summary>
Motivation: 随着对复杂视频分析能力需求的增长，迫切需要全面且具有文化意识的评估框架，而现有基准在这方面存在不足。

Method: 开发包含8个主要类别和12个子类别的数据集，并设计专门的评估指标，对最先进的多模态大语言模型进行严格评估。

Result: 实证评估显示ChineseVideoBench对当前多模态大语言模型构成显著挑战，Gemini 2.5 Pro以77.9%的总体得分表现最佳，InternVL-38B是最具竞争力的开源模型。

Conclusion: ChineseVideoBench填补了中文视频问答评估领域的空白，为多模态大语言模型在复杂中文视频内容上的能力评估提供了重要基准。

Abstract: This paper introduces ChineseVideoBench, a pioneering benchmark specifically designed for evaluating Multimodal Large Language Models (MLLMs) in Chinese Video Question Answering. The growing demand for sophisticated video analysis capabilities highlights the critical need for comprehensive, culturally-aware evaluation frameworks. ChineseVideoBench addresses this gap by providing a robust dataset and tailored evaluation metrics, enabling rigorous assessment of state-of-the-art MLLMs on complex Chinese video content. Specifically, ChineseVideoBench comprises 8 main classes and 12 sub-classes, encompassing tasks that demand both deep video understanding and nuanced Chinese linguistic and cultural awareness. Our empirical evaluations reveal that ChineseVideoBench presents a significant challenge to current MLLMs. Among the models assessed, Gemini 2.5 Pro achieves the highest performance with an overall score of 77.9%, while InternVL-38B emerges as the most competitive open-source model.

</details>


### [115] [4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for Dynamic Scene Geometry Estimation](https://arxiv.org/abs/2511.18416)
*Haonan Wang,Hanyu Zhou,Haoyue Liu,Luxin Yan*

Main category: cs.CV

TL;DR: 提出4D-VGGT模型，通过分治时空表示解决动态场景几何估计中的时空特征不匹配问题，支持多视图输入、多层次表示和多任务预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法将时空特征对齐到统一潜在空间，但由于时空特征的异质性导致表示不匹配问题，需要更有效的动态场景几何估计方法。

Method: 设计自适应视觉网格支持任意视图和时间步输入；提出跨视图全局融合进行空间表示和跨时间局部融合进行时间表示；添加多个任务特定头实现多任务预测。

Result: 在多个动态场景几何基准测试中验证了方法的有效性，模型具有更好的特征区分能力和应用通用性。

Conclusion: 4D-VGGT通过分治时空表示框架成功解决了动态场景几何估计中的时空特征不匹配问题，为动态场景提供了全面的视觉几何估计。

Abstract: We investigate a challenging task of dynamic scene geometry estimation, which requires representing both spatial and temporal features. Typically, existing methods align the two features into a unified latent space to model scene geometry. However, this unified paradigm suffers from potential mismatched representation due to the heterogeneous nature between spatial and temporal features. In this work, we propose 4D-VGGT, a general foundation model with divide-and-conquer spatiotemporal representation for dynamic scene geometry. Our model is divided into three aspects: 1) Multi-setting input. We design an adaptive visual grid that supports input sequences with arbitrary numbers of views and time steps. 2) Multi-level representation. We propose a cross-view global fusion for spatial representation and a cross-time local fusion for temporal representation. 3) Multi-task prediction. We append multiple task-specific heads to spatiotemporal representations, enabling a comprehensive visual geometry estimation for dynamic scenes. Under this unified framework, these components enhance the feature discriminability and application universality of our model for dynamic scenes. In addition, we integrate multiple geometry datasets to train our model and conduct extensive experiments to verify the effectiveness of our method across various tasks on multiple dynamic scene geometry benchmarks.

</details>


### [116] [NeuroVascU-Net: A Unified Multi-Scale and Cross-Domain Adaptive Feature Fusion U-Net for Precise 3D Segmentation of Brain Vessels in Contrast-Enhanced T1 MRI](https://arxiv.org/abs/2511.18422)
*Mohammad Jafari Vayeghan,Niloufar Delfan,Mehdi Tale Masouleh,Mansour Parvaresh Rizi,Behzad Moshiri*

Main category: cs.CV

TL;DR: NeuroVascU-Net是一种专门用于从T1CE MRI中分割脑血管的深度学习架构，在神经肿瘤患者中实现了精确的血管分割，具有高准确性和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 手动分割脑血管耗时且存在观察者间变异性，现有自动化方法在准确性和计算成本之间难以平衡，限制了临床应用。需要专门针对T1CE MRI的血管分割方法。

Method: 基于扩张U-Net架构，集成了两个专用模块：瓶颈处的多尺度上下文特征融合模块(MSC^2F)和深层分层中的跨域自适应特征融合模块(CDA^2F)。MSC^2F通过多尺度扩张卷积捕获局部和全局信息，CDA^2F动态整合领域特定特征。

Result: 在137名脑肿瘤活检患者的T1CE扫描数据集上验证，Dice得分为0.8609，精确度为0.8841，能够准确分割主要和细小血管结构。仅需12.4M参数，显著少于基于transformer的模型。

Conclusion: NeuroVascU-Net在准确性和效率之间取得了良好平衡，为计算机辅助神经外科规划提供了实用解决方案。

Abstract: Precise 3D segmentation of cerebral vasculature from T1-weighted contrast-enhanced (T1CE) MRI is crucial for safe neurosurgical planning. Manual delineation is time-consuming and prone to inter-observer variability, while current automated methods often trade accuracy for computational cost, limiting clinical use. We present NeuroVascU-Net, the first deep learning architecture specifically designed to segment cerebrovascular structures directly from clinically standard T1CE MRI in neuro-oncology patients, addressing a gap in prior work dominated by TOF-MRA-based approaches. NeuroVascU-Net builds on a dilated U-Net and integrates two specialized modules: a Multi-Scale Contextual Feature Fusion ($MSC^2F$) module at the bottleneck and a Cross-Domain Adaptive Feature Fusion ($CDA^2F$) module at deeper hierarchical layers. $MSC^2F$ captures both local and global information via multi-scale dilated convolutions, while $CDA^2F$ dynamically integrates domain-specific features, enhancing representation while keeping computation low. The model was trained and validated on a curated dataset of T1CE scans from 137 brain tumor biopsy patients, annotated by a board-certified functional neurosurgeon. NeuroVascU-Net achieved a Dice score of 0.8609 and precision of 0.8841, accurately segmenting both major and fine vascular structures. Notably, it requires only 12.4M parameters, significantly fewer than transformer-based models such as Swin U-NetR. This balance of accuracy and efficiency positions NeuroVascU-Net as a practical solution for computer-assisted neurosurgical planning.

</details>


### [117] [CrossJEPA: Cross-Modal Joint-Embedding Predictive Architecture for Efficient 3D Representation Learning from 2D Images](https://arxiv.org/abs/2511.18424)
*Avishka Perera,Kumal Hewagamage,Saeedha Nazar,Kavishka Abeywardana,Hasitha Gallella,Ranga Rodrigo,Mohamed Afham*

Main category: cs.CV

TL;DR: CrossJEPA是一个简单的跨模态联合嵌入预测架构，通过利用图像基础模型的知识，训练预测器从3D点云推断特定渲染2D视图的嵌入，在3D表示学习中实现了高性能、内存效率和快速训练。


<details>
  <summary>Details</summary>
Motivation: 解决当前利用2D数据的3D表示学习方法导致模型庞大、训练缓慢的问题，探索JEPA架构在跨模态设置中的应用，打破JEPA必须依赖掩码的误解。

Method: 提出CrossJEPA架构，利用图像基础模型知识，训练预测器从3D点云预测渲染2D视图的嵌入，采用跨域投影信息条件化预测器，使用冻结教师设计和一次性目标嵌入缓存机制。

Result: 在ModelNet40上达到94.2%的线性探测准确率，在ScanObjectNN上达到88.3%，仅使用14.1M预训练参数（点编码器8.5M），在单GPU上约6小时完成预训练。

Conclusion: CrossJEPA是一个性能优异、内存高效、训练快速的3D表示学习框架，通过知识蒸馏实现了最先进的性能。

Abstract: Image-to-point cross-modal learning has emerged to address the scarcity of large-scale 3D datasets in 3D representation learning. However, current methods that leverage 2D data often result in large, slow-to-train models, making them computationally expensive and difficult to deploy in resource-constrained environments. The architecture design of such models is therefore critical, determining their performance, memory footprint, and compute efficiency. The Joint-embedding Predictive Architecture (JEPA) has gained wide popularity in self-supervised learning for its simplicity and efficiency, but has been under-explored in cross-modal settings, partly due to the misconception that masking is intrinsic to JEPA. In this light, we propose CrossJEPA, a simple Cross-modal Joint Embedding Predictive Architecture that harnesses the knowledge of an image foundation model and trains a predictor to infer embeddings of specific rendered 2D views from corresponding 3D point clouds, thereby introducing a JEPA-style pretraining strategy beyond masking. By conditioning the predictor on cross-domain projection information, CrossJEPA purifies the supervision signal from semantics exclusive to the target domain. We further exploit the frozen teacher design with a one-time target embedding caching mechanism, yielding amortized efficiency. CrossJEPA achieves a new state-of-the-art in linear probing on the synthetic ModelNet40 (94.2%) and the real-world ScanObjectNN (88.3%) benchmarks, using only 14.1M pretraining parameters (8.5M in the point encoder), and about 6 pretraining hours on a standard single GPU. These results position CrossJEPA as a performant, memory-efficient, and fast-to-train framework for 3D representation learning via knowledge distillation. We analyze CrossJEPA intuitively, theoretically, and empirically, and extensively ablate our design choices. Code will be made available.

</details>


### [118] [DocPTBench: Benchmarking End-to-End Photographed Document Parsing and Translation](https://arxiv.org/abs/2511.18434)
*Yongkun Du,Pinxuan Chen,Xuye Ying,Zhineng Chen*

Main category: cs.CV

TL;DR: DocPTBench是一个专门为拍摄文档解析和翻译设计的基准测试，包含1300多张高分辨率拍摄文档，涵盖8种翻译场景，揭示了现有模型在处理真实世界拍摄文档时的性能显著下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文档解析和翻译基准测试主要针对扫描或数字生成的文档，无法充分反映真实世界拍摄条件（如几何变形和光度变化）带来的复杂挑战。

Method: 构建DocPTBench基准测试，包含1300多张高分辨率拍摄文档，涵盖多个领域和8种翻译场景，并提供人工验证的解析和翻译标注。

Result: 实验表明，从数字文档转向拍摄文档会导致性能显著下降：流行MLLM在端到端解析中平均准确率下降18%，翻译下降12%；专业文档解析模型平均下降25%。

Conclusion: 真实世界拍摄文档带来的独特挑战暴露了现有模型的鲁棒性不足，DocPTBench填补了这一重要空白。

Abstract: The advent of Multimodal Large Language Models (MLLMs) has unlocked the potential for end-to-end document parsing and translation. However, prevailing benchmarks such as OmniDocBench and DITrans are dominated by pristine scanned or digital-born documents, and thus fail to adequately represent the intricate challenges of real-world capture conditions, such as geometric distortions and photometric variations. To fill this gap, we introduce DocPTBench, a comprehensive benchmark specifically designed for Photographed Document Parsing and Translation. DocPTBench comprises over 1,300 high-resolution photographed documents from multiple domains, includes eight translation scenarios, and provides meticulously human-verified annotations for both parsing and translation. Our experiments demonstrate that transitioning from digital-born to photographed documents results in a substantial performance decline: popular MLLMs exhibit an average accuracy drop of 18% in end-to-end parsing and 12% in translation, while specialized document parsing models show significant average decrease of 25%. This substantial performance gap underscores the unique challenges posed by documents captured in real-world conditions and reveals the limited robustness of existing models. Dataset and code are available at https://github.com/Topdu/DocPTBench.

</details>


### [119] [LungX: A Hybrid EfficientNet-Vision Transformer Architecture with Multi-Scale Attention for Accurate Pneumonia Detection](https://arxiv.org/abs/2511.18425)
*Mansur Yerzhanuly*

Main category: cs.CV

TL;DR: LungX是一种新型混合架构，结合EfficientNet多尺度特征、CBAM注意力机制和Vision Transformer全局上下文建模，在肺炎检测方面实现最先进性能（86.5%准确率，0.943 AUC），相比EfficientNet-B0基线AUC提升6.7%。


<details>
  <summary>Details</summary>
Motivation: 肺炎是全球主要死亡原因，及时诊断至关重要。需要开发更准确的AI诊断工具来改善肺炎检测。

Method: 提出LungX混合架构，整合EfficientNet的多尺度特征提取、CBAM注意力机制和Vision Transformer的全局上下文建模能力。

Result: 在20,000张来自RSNA和CheXpert的胸部X光片上评估，达到86.5%准确率和0.943 AUC，相比EfficientNet-B0基线AUC提升6.7%。可视化分析显示通过可解释注意力图实现优越的病变定位。

Conclusion: LungX在肺炎检测方面表现出色，未来方向包括多中心验证和架构优化，目标是达到88%准确率以实现临床部署作为AI诊断辅助工具。

Abstract: Pneumonia remains a leading global cause of mortality where timely diagnosis is critical. We introduce LungX, a novel hybrid architecture combining EfficientNet's multi-scale features, CBAM attention mechanisms, and Vision Transformer's global context modeling for enhanced pneumonia detection. Evaluated on 20,000 curated chest X-rays from RSNA and CheXpert, LungX achieves state-of-the-art performance (86.5 percent accuracy, 0.943 AUC), representing a 6.7 percent AUC improvement over EfficientNet-B0 baselines. Visual analysis demonstrates superior lesion localization through interpretable attention maps. Future directions include multi-center validation and architectural optimizations targeting 88 percent accuracy for clinical deployment as an AI diagnostic aid.

</details>


### [120] [RegDeepLab: A Two-Stage Decoupled Framework for Interpretable Embryo Fragmentation Grading](https://arxiv.org/abs/2511.18454)
*Ming-Jhe Lee*

Main category: cs.CV

TL;DR: 本文提出RegDeepLab，一种双分支多任务学习框架，结合语义分割和回归任务，通过两阶段解耦训练策略解决胚胎碎片化程度自动评估问题，在保持分割精度的同时实现高精度分级预测。


<details>
  <summary>Details</summary>
Motivation: 当前IVF胚胎碎片化程度的手动评估存在时间消耗大、观察者间差异显著和效率瓶颈等问题，现有深度学习方法在可解释性和临床分级精度方面存在挑战。

Method: 提出RegDeepLab双分支多任务学习框架，集成DeepLabV3+语义分割和多尺度回归头，采用两阶段解耦训练策略解决梯度冲突和负迁移问题，并引入范围损失进行半监督学习。

Result: 实验结果显示，标准端到端多任务训练可最小化分级误差(MAE=0.046)，但会损害分割边界完整性；解耦策略在保持SOTA级分割精度(Dice=0.729)的同时提供鲁棒的高精度分级预测。

Conclusion: 本研究最终提出了一个结合高精度和视觉可解释性的双模块临床辅助解决方案，为IVF胚胎发育潜力评估提供了有效的自动化工具。

Abstract: The degree of embryo fragmentation serves as a critical morphological indicator for assessing embryo developmental potential in In Vitro Fertilization (IVF) clinical decision-making. However, current manual grading processes are not only time-consuming but also limited by significant inter-observer variability and efficiency bottlenecks. Although deep learning has demonstrated potential in automated grading in recent years, existing solutions face a significant challenge: pure regression models lack the visual explainability required for clinical practice, while pure segmentation models struggle to directly translate pixel-level masks into precise clinical grades. This study proposes RegDeepLab, a dual-branch Multi-Task Learning (MTL) framework that integrates State-of-the-Art (SOTA) semantic segmentation (DeepLabV3+) with a multi-scale regression head. Addressing the common issues of "Gradient Conflict" and "Negative Transfer" in multi-task training, we propose a "Two-Stage Decoupled Training Strategy." Experimental results demonstrate that while standard end-to-end MTL training can minimize grading error (MAE=0.046) through our designed "Feature Injection" mechanism, it compromises the integrity of segmentation boundaries. In contrast, our decoupled strategy successfully provides robust and high-precision grading predictions while preserving SOTA-level segmentation accuracy (Dice=0.729). Furthermore, we introduce a "Range Loss" to effectively utilize large-scale discrete grading data for semi-supervised learning. This study ultimately presents a dual-module clinical auxiliary solution that combines high accuracy with visual explainability.

</details>


### [121] [Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives](https://arxiv.org/abs/2511.18507)
*Kai Jiang,Siqi Huang,Xiangyu Chen,Jiawei Shao,Hongyuan Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出UNIFIER方法解决多模态大语言模型在持续学习中的灾难性遗忘问题，通过构建多场景视觉问答数据集MSVQA，并在视觉块中将不同场景信息解耦到不同分支，通过一致性约束保持跨场景视觉表示的稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在动态场景变化下的灾难性遗忘问题，使模型能够适应现实世界数据流中的场景变化，如高空、水下、低空和室内等不同视角。

Method: 提出UNIFIER方法，将不同场景的视觉信息解耦到视觉块中的不同分支，并投影到相同特征空间，通过一致性约束保持跨场景视觉表示的稳定性。

Result: 在MSVQA数据集上的广泛实验表明，UNIFIER有效缓解了跨场景任务的遗忘，并在同一场景内实现了知识积累。

Conclusion: UNIFIER方法成功解决了多模态大语言模型在持续学习中的跨场景遗忘问题，为动态场景下的视觉理解提供了有效解决方案。

Abstract: Continual learning in visual understanding aims to deal with catastrophic forgetting in Multimodal Large Language Models (MLLMs). MLLMs deployed on devices have to continuously adapt to dynamic scenarios in downstream tasks, such as variations in background and perspective, to effectively perform complex visual tasks. To this end, we construct a multimodal visual understanding dataset (MSVQA) encompassing four different scenarios and perspectives including high altitude, underwater, low altitude and indoor, to investigate the catastrophic forgetting in MLLMs under the dynamics of scenario shifts in real-world data streams. Furthermore, we propose mUltimodal coNtInual learning with MLLMs From multi-scenarIo pERspectives (UNIFIER) to address visual discrepancies while learning different scenarios. Specifically, it decouples the visual information from different scenarios into distinct branches within each vision block and projects them into the same feature space. A consistency constraint is imposed on the features of each branch to maintain the stability of visual representations across scenarios. Extensive experiments on the MSVQA dataset demonstrate that UNIFIER effectively alleviates forgetting of cross-scenario tasks and achieves knowledge accumulation within the same scenario.

</details>


### [122] [When Generative Replay Meets Evolving Deepfakes: Domain-Aware Relative Weighting for Incremental Face Forgery Detection](https://arxiv.org/abs/2511.18436)
*Hao Shen,Jikang Cheng,Renye Yan,Zhongyuan Wang,Wei Peng,Baojin Huang*

Main category: cs.CV

TL;DR: 本文提出了一种针对增量伪造检测的领域感知相对加权策略（DARW），通过分析生成回放中的领域风险样本和领域安全样本，动态调整监督策略以提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着人脸生成技术的快速发展，伪造方法日益多样化。基于样本回放的增量伪造检测方法受限于低多样性和隐私问题，而生成回放虽然提供了潜在解决方案，但其在伪造检测中的可行性尚不明确。

Method: 提出领域感知相对加权策略（DARW），识别生成回放中的两种场景：领域风险样本和领域安全样本。对领域安全样本直接监督，对领域风险样本应用相对分离损失来平衡监督和潜在混淆，并通过领域混淆分数动态调整权衡。

Result: 大量实验表明，DARW在不同生成回放设置下持续提升增量学习性能，并减轻领域重叠的不利影响。

Conclusion: DARW策略有效利用了生成回放，通过领域感知的监督机制显著改善了增量伪造检测的性能，为解决领域重叠问题提供了有效方案。

Abstract: The rapid advancement of face generation techniques has led to a growing variety of forgery methods. Incremental forgery detection aims to gradually update existing models with new forgery data, yet current sample replay-based methods are limited by low diversity and privacy concerns. Generative replay offers a potential solution by synthesizing past data, but its feasibility for forgery detection remains unclear. In this work, we systematically investigate generative replay and identify two scenarios: when the replay generator closely resembles the new forgery model, generated real samples blur the domain boundary, creating domain-risky samples; when the replay generator differs significantly, generated samples can be safely supervised, forming domain-safe samples. To exploit generative replay effectively, we propose a novel Domain-Aware Relative Weighting (DARW) strategy. DARW directly supervises domain-safe samples while applying a Relative Separation Loss to balance supervision and potential confusion for domain-risky samples. A Domain Confusion Score dynamically adjusts this tradeoff according to sample reliability. Extensive experiments demonstrate that DARW consistently improves incremental learning performance for forgery detection under different generative replay settings and alleviates the adverse impact of domain overlap.

</details>


### [123] [Stage-Specific Benchmarking of Deep Learning Models for Glioblastoma Follow-Up MRI](https://arxiv.org/abs/2511.18595)
*Wenhao Guo,Golrokh Mirzaei*

Main category: cs.CV

TL;DR: 该研究首次对胶质母细胞瘤随访MRI的深度学习模型进行了分期特异性基准测试，发现不同时间点的模型性能存在差异，Mamba+CNN混合模型在准确性和效率方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 区分胶质母细胞瘤的真实进展与治疗相关假性进展在早期随访中具有挑战性，需要建立分期感知的深度学习模型基准。

Method: 使用Burdenko GBM Progression队列(n=180)，独立分析不同放疗后扫描时间点，在统一质量控制驱动的流程下训练11个代表性深度学习家族，采用患者级交叉验证。

Result: 两个阶段的准确率相当(~0.70-0.74)，但第二次随访时的区分度更好，F1和AUC值提高。Mamba+CNN混合模型提供最佳准确率-效率权衡，而transformer变体在计算成本显著更高的情况下提供竞争性AUC。

Conclusion: 研究建立了分期感知基准，表明绝对区分度总体仍有限，反映了TP与PsP区分的固有难度，未来工作需要整合纵向建模、多序列MRI和更大规模多中心队列。

Abstract: Differentiating true tumor progression (TP) from treatment-related pseudoprogression (PsP) in glioblastoma remains challenging, especially at early follow-up. We present the first stage-specific, cross-sectional benchmarking of deep learning models for follow-up MRI using the Burdenko GBM Progression cohort (n = 180). We analyze different post-RT scans independently to test whether architecture performance depends on time-point. Eleven representative DL families (CNNs, LSTMs, hybrids, transformers, and selective state-space models) were trained under a unified, QC-driven pipeline with patient-level cross-validation. Across both stages, accuracies were comparable (~0.70-0.74), but discrimination improved at the second follow-up, with F1 and AUC increasing for several models, indicating richer separability later in the care pathway. A Mamba+CNN hybrid consistently offered the best accuracy-efficiency trade-off, while transformer variants delivered competitive AUCs at substantially higher computational cost and lightweight CNNs were efficient but less reliable. Performance also showed sensitivity to batch size, underscoring the need for standardized training protocols. Notably, absolute discrimination remained modest overall, reflecting the intrinsic difficulty of TP vs. PsP and the dataset's size imbalance. These results establish a stage-aware benchmark and motivate future work incorporating longitudinal modeling, multi-sequence MRI, and larger multi-center cohorts.

</details>


### [124] [Perceptual-Evidence Anchored Reinforced Learning for Multimodal Reasoning](https://arxiv.org/abs/2511.18437)
*Chi Zhang,Haibo Qiu,Qiming Zhang,Yufei Xu,Zhixiong Zeng,Siqi Yang,Peng Shi,Lin Ma,Jing Zhang*

Main category: cs.CV

TL;DR: PEARL提出了一种双分支的感知-推理协同强化学习方法，通过在视觉证据上显式锚定来增强多模态推理能力，解决了传统RLVR方法忽视视觉感知验证的问题。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法仅验证最终文本输出，忽视了视觉感知这一基础步骤，导致视觉幻觉和奖励攻击问题。基于错误感知的推理本质上不可靠。

Method: PEARL为每个推理问答实例生成感知检查清单——一组可验证答案的感知导向子问题，用于探测模型对关键视觉证据的理解。训练时，通过辅助rollout获得感知奖励，既直接强化感知能力，又作为推理的保真度门控。

Result: 在MathVerse等基准测试中，PEARL相比基线提升9.7%，相比GRPO提升6.6%。

Conclusion: PEARL能够无缝集成到GRPO和DAPO等流行RL方法中，显著提升多模态推理性能，有效防止基于错误前提的推理。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Large Language Models (LLMs) and is now being applied to Vision-Language Models (VLMs). However, vanilla RLVR for VLMs verifies only the final textual output, critically neglecting the foundational step of visual perception. This oversight leads to visual hallucinations and reward hacking, as reasoning built upon flawed perception is inherently unreliable. To address this, we propose PEARL (Perceptual-Evidence Anchored Reinforced Learning), a dual-branch, perception-reasoning synergistic that strengthens multimodal reasoning by explicitly anchoring it to verified visual evidence. For each reasoning-oriented QA instance, PEARL first derive a perception checklist -- a set of perception-oriented sub-questions with verifiable answers that probe the model's understanding of key visual evidence. During training, auxiliary rollouts on this checklist yield a perceptual reward that both directly reinforces the model's perception ability and acts as a fidelity gate for reasoning. If the model passes the perception check, its policy update is biased towards evidence-anchored reasoning. Otherwise, the process is halted to prevent reasoning from flawed premises. PEARL can be seamlessly integrated with popular RL methods like GRPO and DAPO. Comprehensive experiments show PEARL achieves substantial gains on multimodal reasoning benchmarks, e.g., a +9.7% improvement over the baseline and +6.6% over GRPO on MathVerse.

</details>


### [125] [ReCoGS: Real-time ReColoring for Gaussian Splatting scenes](https://arxiv.org/abs/2511.18441)
*Lorenzo Rutayisire,Nicola Capodieci,Fabio Pellacini*

Main category: cs.CV

TL;DR: 本文提出了一种用于高斯溅射3D场景实时重着色的用户友好方法，通过精确区域选择和重着色，解决了现有方法视图不一致、缺乏细粒度控制和高计算需求的问题。


<details>
  <summary>Details</summary>
Motivation: 高斯溅射在视图合成方面表现出色，但在编辑任务（特别是重着色）中，现有方法存在视图不一致、缺乏细粒度控制和高计算需求等限制。

Method: 开发了一个用户友好的流水线，能够在预训练的高斯溅射场景中精确选择区域并进行重着色，并提供了交互式工具来展示实时性能。

Result: 实现了对高斯溅射场景的精确区域选择和实时重着色，提供了实用的交互工具。

Conclusion: 该方法为高斯溅射3D场景的编辑任务提供了一种有效且用户友好的解决方案，特别在重着色方面表现出实时性能和精确控制能力。

Abstract: Gaussian Splatting has emerged as a leading method for novel view synthesis, offering superior training efficiency and real-time inference compared to NeRF approaches, while still delivering high-quality reconstructions. Beyond view synthesis, this 3D representation has also been explored for editing tasks. Many existing methods leverage 2D diffusion models to generate multi-view datasets for training, but they often suffer from limitations such as view inconsistencies, lack of fine-grained control, and high computational demand. In this work, we focus specifically on the editing task of recoloring. We introduce a user-friendly pipeline that enables precise selection and recoloring of regions within a pre-trained Gaussian Splatting scene. To demonstrate the real-time performance of our method, we also present an interactive tool that allows users to experiment with the pipeline in practice. Code is available at https://github.com/loryruta/recogs.

</details>


### [126] [Health system learning achieves generalist neuroimaging models](https://arxiv.org/abs/2511.18640)
*Akhil Kondepudi,Akshay Rao,Chenhui Zhao,Yiwei Lyu,Samir Harake,Soumyanil Banerjee,Rushikesh Joshi,Anna-Katharina Meissner,Renly Hou,Cheng Jiang,Asadur Chowdury,Ashok Srinivasan,Brian Athey,Vikas Gulani,Aditya Pandey,Honglak Lee,Todd Hollon*

Main category: cs.CV

TL;DR: NeuroVFM是一个基于医疗系统数据的视觉基础模型，通过在524万临床MRI和CT扫描上训练，实现了神经影像任务的先进性能，包括放射诊断和报告生成，超越了前沿AI模型。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型缺乏对私有临床数据的访问，神经影像在公共领域代表性不足，限制了在临床医学中的模型性能。

Method: 采用医疗系统学习范式，使用可扩展的体素联合嵌入预测架构，在524万临床MRI和CT体积上训练NeuroVFM模型。

Result: NeuroVFM在多个临床任务中达到最先进性能，表现出新兴的神经解剖理解和可解释的视觉基础，生成的放射学报告在准确性、临床分诊和专家偏好方面超越前沿模型。

Conclusion: 医疗系统学习是构建通用医疗AI的可行范式，NeuroVFM为临床基础模型提供了可扩展框架，通过临床基础的视觉理解减少了幻觉发现和关键错误。

Abstract: Frontier artificial intelligence (AI) models, such as OpenAI's GPT-5 and Meta's DINOv3, have advanced rapidly through training on internet-scale public data, yet such systems lack access to private clinical data. Neuroimaging, in particular, is underrepresented in the public domain due to identifiable facial features within MRI and CT scans, fundamentally restricting model performance in clinical medicine. Here, we show that frontier models underperform on neuroimaging tasks and that learning directly from uncurated data generated during routine clinical care at health systems, a paradigm we call health system learning, yields high-performance, generalist neuroimaging models. We introduce NeuroVFM, a visual foundation model trained on 5.24 million clinical MRI and CT volumes using a scalable volumetric joint-embedding predictive architecture. NeuroVFM learns comprehensive representations of brain anatomy and pathology, achieving state-of-the-art performance across multiple clinical tasks, including radiologic diagnosis and report generation. The model exhibits emergent neuroanatomic understanding and interpretable visual grounding of diagnostic findings. When paired with open-source language models through lightweight visual instruction tuning, NeuroVFM generates radiology reports that surpass frontier models in accuracy, clinical triage, and expert preference. Through clinically grounded visual understanding, NeuroVFM reduces hallucinated findings and critical errors, offering safer clinical decision support. These results establish health system learning as a paradigm for building generalist medical AI and provide a scalable framework for clinical foundation models.

</details>


### [127] [EventBench: Towards Comprehensive Benchmarking of Event-based MLLMs](https://arxiv.org/abs/2511.18448)
*Shaoyu Liu,Jianing Li,Guanghui Zhao,Yunjian Zhang,Xiangyang Ji*

Main category: cs.CV

TL;DR: EventBench是一个统一的多模态大语言模型基准测试，包含8个多样化任务指标和大规模事件流数据集，用于全面评估事件视觉能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在事件视觉方面取得显著进展，但缺乏统一的基准测试来全面评估其能力。

Method: 构建EventBench基准，包含原始事件流数据、8个评估指标、多样化任务覆盖（理解、识别、空间推理）以及3D空间推理任务设计。

Result: 评估显示当前基于事件的MLLMs在事件流理解方面表现良好，但在细粒度识别和空间推理方面仍有困难。

Conclusion: EventBench为事件视觉领域的MLLMs提供了全面的评估框架，揭示了当前模型在细粒度识别和空间推理方面的局限性。

Abstract: Multimodal large language models (MLLMs) have made significant advancements in event-based vision, yet the comprehensive evaluation of their capabilities within a unified benchmark remains largely unexplored. In this work, we introduce EventBench, a benchmark that offers eight diverse task metrics together with a large-scale event stream dataset. EventBench differs from existing event-based benchmarks in four key aspects: (1) openness in accessibility, releasing all raw event streams and task instructions across eight evaluation metrics; (2) diversity in task coverage, spanning understanding, recognition, and spatial reasoning tasks for comprehensive capability assessment; (3) integration in spatial dimensions, pioneering the design of 3D spatial reasoning tasks for event-based MLLMs; and (4) scale in data volume, with an accompanying training set of over one million event-text pairs supporting large-scale training and evaluation. Using EventBench, we evaluate state-of-the-art closed-source models such as GPT-5 and Gemini-2.5 Pro, leading open-source models including Qwen2.5-VL and InternVL3, and event-based MLLMs such as EventGPT that directly process raw event streams. Extensive evaluation reveals that while current event-based MLLMs demonstrate strong performance in event stream understanding, they continue to struggle with fine-grained recognition and spatial reasoning.

</details>


### [128] [NAF: Zero-Shot Feature Upsampling via Neighborhood Attention Filtering](https://arxiv.org/abs/2511.18452)
*Loick Chambon,Paul Couairon,Eloi Zablocki,Alexandre Boulch,Nicolas Thome,Matthieu Cord*

Main category: cs.CV

TL;DR: NAF是一种零样本特征上采样方法，通过跨尺度邻域注意力和旋转位置编码学习自适应权重，无需重新训练即可提升任何视觉基础模型的特征分辨率，在多个下游任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型提取的空间下采样表示对像素级任务构成挑战，现有上采样方法存在固定形式与可学习形式之间的权衡：经典滤波器快速通用但形式固定，现代上采样器准确但需要为每个VFM重新训练。

Method: 提出邻域注意滤波(NAF)，通过跨尺度邻域注意力和旋转位置编码学习自适应空间-内容权重，仅由高分辨率输入图像引导，实现零样本上采样。

Result: NAF是首个超越VFM特定上采样器的VFM无关架构，在多个下游任务中达到最先进性能，保持高效率，可在2K特征图上扩展到18 FPS。

Conclusion: NAF成功弥合了经典滤波器与现代上采样器之间的差距，提供了一种无需重新训练的高效通用上采样解决方案，在图像恢复等任务中也表现出色。

Abstract: Vision Foundation Models (VFMs) extract spatially downsampled representations, posing challenges for pixel-level tasks. Existing upsampling approaches face a fundamental trade-off: classical filters are fast and broadly applicable but rely on fixed forms, while modern upsamplers achieve superior accuracy through learnable, VFM-specific forms at the cost of retraining for each VFM. We introduce Neighborhood Attention Filtering (NAF), which bridges this gap by learning adaptive spatial-and-content weights through Cross-Scale Neighborhood Attention and Rotary Position Embeddings (RoPE), guided solely by the high-resolution input image. NAF operates zero-shot: it upsamples features from any VFM without retraining, making it the first VFM-agnostic architecture to outperform VFM-specific upsamplers and achieve state-of-the-art performance across multiple downstream tasks. It maintains high efficiency, scaling to 2K feature maps and reconstructing intermediate-resolution maps at 18 FPS. Beyond feature upsampling, NAF demonstrates strong performance on image restoration, highlighting its versatility. Code and checkpoints are available at https://github.com/valeoai/NAF.

</details>


### [129] [MedVision: Dataset and Benchmark for Quantitative Medical Image Analysis](https://arxiv.org/abs/2511.18676)
*Yongcheng Yao,Yongshuo Zong,Raman Dutt,Yongxin Yang,Sotirios A Tsaftaris,Timothy Hospedales*

Main category: cs.CV

TL;DR: 本文介绍了MedVision，一个专门用于评估和改进视觉语言模型在定量医学图像分析能力的大规模数据集和基准测试。该数据集覆盖22个公共数据集，包含3080万图像-标注对，专注于检测、肿瘤/病变大小估计和角度/距离测量三个定量任务。


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉语言模型主要设计用于分类问答或定性描述任务，但临床决策往往依赖于定量评估（如测量肿瘤大小或关节角度），这种定量推理能力在现有VLMs中尚未得到充分探索和支持。

Method: 构建MedVision大规模数据集，涵盖22个公共数据集和3080万图像-标注对，专注于三个代表性定量任务：解剖结构和异常检测、肿瘤/病变大小估计、角度/距离测量。通过监督微调来提升VLMs的性能。

Result: 实验表明，现成的VLMs在这些定量任务上表现不佳，但经过MedVision监督微调后，在检测、肿瘤/病变估计和角度/距离测量方面的性能显著提升，错误率降低且精度提高。

Conclusion: 这项工作为开发具有强大定量推理能力的医学成像VLMs奠定了基础，展示了通过专门数据集和微调可以显著提升模型在定量医学图像分析任务上的表现。

Abstract: Current vision-language models (VLMs) in medicine are primarily designed for categorical question answering (e.g., "Is this normal or abnormal?") or qualitative descriptive tasks. However, clinical decision-making often relies on quantitative assessments, such as measuring the size of a tumor or the angle of a joint, from which physicians draw their own diagnostic conclusions. This quantitative reasoning capability remains underexplored and poorly supported in existing VLMs. In this work, we introduce MedVision, a large-scale dataset and benchmark specifically designed to evaluate and improve VLMs on quantitative medical image analysis. MedVision spans 22 public datasets covering diverse anatomies and modalities, with 30.8 million image-annotation pairs. We focus on three representative quantitative tasks: (1) detection of anatomical structures and abnormalities, (2) tumor/lesion (T/L) size estimation, and (3) angle/distance (A/D) measurement. Our benchmarks show that current off-the-shelf VLMs perform poorly on these tasks. However, with supervised fine-tuning on MedVision, we significantly enhance their performance across detection, T/L estimation, and A/D measurement, demonstrating reduced error rates and improved precision. This work provides a foundation for developing VLMs with robust quantitative reasoning capabilities in medical imaging. Code and data are available at https://medvision-vlm.github.io.

</details>


### [130] [Alternating Perception-Reasoning for Hallucination-Resistant Video Understanding](https://arxiv.org/abs/2511.18463)
*Bowei Pu,Chuanbin Liu,Yifan Ge,Peichen Zhou,Yiwei Sun,Zhiyin Lu,Jiankang Wang,Hongtao Xie*

Main category: cs.CV

TL;DR: 本文提出Video-PLR框架，通过感知循环推理范式和反幻觉奖励机制解决视频推理中的感知不足和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频推理大语言模型存在感知捷径问题，采用单步感知范式（先描述视频再推理）容易导致证据不足和幻觉产生。

Method: 1. 感知循环推理(PLR)范式：分循环描述视频片段并分析，决定下一步行动；2. 事实感知评估器(FAE)：评估每个感知结果作为反幻觉奖励，基于AnetHallu-117K数据集训练。

Result: Video-PLR在3B和7B参数规模上达到最先进水平，具有最佳数据效率，FAE性能与GPT-4o相当。

Conclusion: 提出的循环感知范式和反幻觉奖励机制有效解决了视频推理中的证据不足和幻觉问题，显著提升了模型性能。

Abstract: Sufficient visual perception is the foundation of video reasoning. Nevertheless, existing Video Reasoning LLMs suffer from perception shortcuts, relying on a flawed single-step perception paradigm. This paradigm describes the video and then conducts reasoning, which runs the risk of insufficient evidence and emergent hallucinations. To address these issues, we introduce a new framework that integrates a loop-based paradigm with an anti-hallucination reward. First, to address the insufficient evidence, we introduce the Perception Loop Reasoning (PLR) paradigm. Instead of describing the video at once, each loop requires the model to describe a video segment with precise timestamps, analyze this segment, and decide the next action. Second, for the risk of hallucinations, the Factual-Aware Evaluator (FAE) evaluates each perception result as a reliable anti-hallucination reward. This reward encourages the model to provide sufficient and precise video evidence. Our FAE, which performs comparably to GPT-4o, is tuned on our AnetHallu-117K, a large-scale hallucination judgment preference dataset. Extensive experiments show that our Video-PLR achieves the state-of-the-art in both 3B and 7B parameter scales and has the best data efficiency. Our code, models, and datasets are released on: https://github.com/BoweiPu/VideoPLR.

</details>


### [131] [Gaze Beyond the Frame: Forecasting Egocentric 3D Visual Span](https://arxiv.org/abs/2511.18470)
*Heeseung Yun,Joonil Na,Jaeyeon Kim,Calvin Murdock,Gunhee Kim*

Main category: cs.CV

TL;DR: 本文提出EgoSpanLift方法，将自我中心视觉跨度预测从2D图像平面转换到3D场景，通过SLAM关键点转换和体积视觉跨度区域提取，结合3D U-Net和单向变换器实现时空融合，在3D网格中预测未来视觉跨度。


<details>
  <summary>Details</summary>
Motivation: 虽然自我中心用户和场景理解研究主要关注运动和基于接触的交互，但预测人类视觉感知本身仍然较少探索，尽管它在指导人类行为和对AR/VR及辅助技术具有重要意义。

Method: 提出EgoSpanLift方法，将SLAM衍生关键点转换为与注视兼容的几何结构，提取体积视觉跨度区域，结合3D U-Net和单向变换器进行时空融合，在3D网格中预测未来视觉跨度。

Result: 该方法在自我中心2D注视预测和3D定位方面优于竞争基线，即使投影回2D图像平面也无需额外2D特定训练即可获得可比结果。构建了包含364.6K样本的3D视觉跨度预测基准测试集。

Conclusion: EgoSpanLift成功将自我中心视觉跨度预测从2D扩展到3D，为AR/VR和辅助技术提供了更准确的视觉感知预测能力。

Abstract: People continuously perceive and interact with their surroundings based on underlying intentions that drive their exploration and behaviors. While research in egocentric user and scene understanding has focused primarily on motion and contact-based interaction, forecasting human visual perception itself remains less explored despite its fundamental role in guiding human actions and its implications for AR/VR and assistive technologies. We address the challenge of egocentric 3D visual span forecasting, predicting where a person's visual perception will focus next within their three-dimensional environment. To this end, we propose EgoSpanLift, a novel method that transforms egocentric visual span forecasting from 2D image planes to 3D scenes. EgoSpanLift converts SLAM-derived keypoints into gaze-compatible geometry and extracts volumetric visual span regions. We further combine EgoSpanLift with 3D U-Net and unidirectional transformers, enabling spatio-temporal fusion to efficiently predict future visual span in the 3D grid. In addition, we curate a comprehensive benchmark from raw egocentric multisensory data, creating a testbed with 364.6K samples for 3D visual span forecasting. Our approach outperforms competitive baselines for egocentric 2D gaze anticipation and 3D localization while achieving comparable results even when projected back onto 2D image planes without additional 2D-specific training.

</details>


### [132] [Robust Posterior Diffusion-based Sampling via Adaptive Guidance Scale](https://arxiv.org/abs/2511.18471)
*Liav Hen,Tom Tirer,Raja Giryes,Shady Abu-Hussein*

Main category: cs.CV

TL;DR: 本文提出了一种自适应似然步长策略（AdaPS），用于解决扩散模型在逆问题中的先验与数据保真度平衡问题，通过基于两种不同似然梯度近似一致性的观测依赖权重方案，在超分辨率、高斯去模糊和运动去模糊等任务中提升了重建质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型作为强大的生成先验在解决逆问题中表现出色，但面临先验贡献与数据保真度平衡的挑战：过于激进的似然更新可能引入伪影，而保守更新则会减慢收敛或产生次优重建。

Method: 提出自适应后验扩散采样（AdaPS），开发基于两种不同难处理中间似然梯度近似一致性的观测依赖权重方案，该方案自然适应扩散调度、时间重间距和注入的随机性，无需超参数调整。

Result: 在CelebA-HQ和ImageNet-256验证集上的实验表明，AdaPS在超分辨率、高斯去模糊和运动去模糊等多样化成像任务中一致超越现有基于扩散的基线方法，在感知质量上显著提升且失真最小或无损失，无需任何任务特定调整。

Conclusion: AdaPS是一种超参数自由的方法，通过自适应似然步长策略有效平衡了扩散先验与数据保真度，在各种成像任务中实现了优越的重建质量，并对扩散步数、观测噪声水平和不同随机性表现出鲁棒性。

Abstract: Diffusion models have recently emerged as powerful generative priors for solving inverse problems, achieving state-of-the-art results across various imaging tasks. A central challenge in this setting lies in balancing the contribution of the prior with the data fidelity term: overly aggressive likelihood updates may introduce artifacts, while conservative updates can slow convergence or yield suboptimal reconstructions. In this work, we propose an adaptive likelihood step-size strategy to guide the diffusion process for inverse-problem formulations. Specifically, we develop an observation-dependent weighting scheme based on the agreement between two different approximations of the intractable intermediate likelihood gradients, that adapts naturally to the diffusion schedule, time re-spacing, and injected stochasticity. The resulting approach, Adaptive Posterior diffusion Sampling (AdaPS), is hyperparameter-free and improves reconstruction quality across diverse imaging tasks - including super-resolution, Gaussian deblurring, and motion deblurring - on CelebA-HQ and ImageNet-256 validation sets. AdaPS consistently surpasses existing diffusion-based baselines in perceptual quality with minimal or no loss in distortion, without any task-specific tuning. Extensive ablation studies further demonstrate its robustness to the number of diffusion steps, observation noise levels, and varying stochasticity.

</details>


### [133] [Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation](https://arxiv.org/abs/2511.18711)
*Yuyang Wanyan,Xiaoshan Yang,Weiming Dong,Changsheng Xu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的模态协作低秩分解器(MC-LRD)框架，用于解决少样本视频域自适应(FSVDA)问题。该框架通过分解模态独特和模态共享特征，结合跨域激活一致性损失，显著提升了域自适应性能。


<details>
  <summary>Details</summary>
Motivation: 视频的多模态特性在少样本场景下带来了独特挑战，需要同时考虑域对齐和模态协作。现有方法忽视了在域偏移影响下，各模态及融合多模态特征的泛化性能受限的问题。

Method: 提出MC-LRD框架，包含每个模态的多个分解器和多模态分解路由器(MDR)。分解器在不同模态间逐步共享参数，MDR选择性激活分解器产生模态独特和共享特征。应用正交去相关约束和跨域激活一致性损失。

Result: 在三个公共基准测试上的广泛实验结果表明，该模型相比现有方法取得了显著改进。

Conclusion: MC-LRD框架通过有效分解不同域偏移水平的特征，成功解决了少样本视频域自适应中的挑战，为多模态域自适应提供了有效解决方案。

Abstract: In this paper, we study the challenging task of Few-Shot Video Domain Adaptation (FSVDA). The multimodal nature of videos introduces unique challenges, necessitating the simultaneous consideration of both domain alignment and modality collaboration in a few-shot scenario, which is ignored in previous literature. We observe that, under the influence of domain shift, the generalization performance on the target domain of each individual modality, as well as that of fused multimodal features, is constrained. Because each modality is comprised of coupled features with multiple components that exhibit different domain shifts. This variability increases the complexity of domain adaptation, thereby reducing the effectiveness of multimodal feature integration. To address these challenges, we introduce a novel framework of Modality-Collaborative LowRank Decomposers (MC-LRD) to decompose modality-unique and modality-shared features with different domain shift levels from each modality that are more friendly for domain alignment. The MC-LRD comprises multiple decomposers for each modality and Multimodal Decomposition Routers (MDR). Each decomposer has progressively shared parameters across different modalities. The MDR is leveraged to selectively activate the decomposers to produce modality-unique and modality-shared features. To ensure efficient decomposition, we apply orthogonal decorrelation constraints separately to decomposers and subrouters, enhancing their diversity. Furthermore, we propose a cross-domain activation consistency loss to guarantee that target and source samples of the same category exhibit consistent activation preferences of the decomposers, thereby facilitating domain alignment. Extensive experimental results on three public benchmarks demonstrate that our model achieves significant improvements over existing methods.

</details>


### [134] [Uncertainty Quantification in HSI Reconstruction using Physics-Aware Diffusion Priors and Optics-Encoded Measurements](https://arxiv.org/abs/2511.18473)
*Juan Romero,Qiang Fu,Matteo Ravasi,Wolfgang Heidrich*

Main category: cs.CV

TL;DR: HSDiff是一个基于贝叶斯推理的高光谱图像重建框架，使用无条件训练的像素级扩散先验和后验扩散采样，通过增强的元色增强技术提高先验多样性，为各种高光谱成像模型提供不确定性感知的重建。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动方法由于现有高光谱图像数据集缺乏光谱多样性，特别是在评估元色现象时存在幻觉问题，需要解决高光谱图像重建这一高度不适定的逆问题。

Method: 将高光谱图像重建建模为贝叶斯推理问题，使用无条件训练的像素级扩散先验和后验扩散采样，提出基于区域的元色黑和分区联合光谱上采样的增强元色增强技术。

Result: HSDiff能够生成与各种高光谱图像形成模型测量一致的多样化高光谱样本，通过有效光谱编码提供校准的信息不确定性，相比非编码模型表现更优。

Conclusion: HSDiff提供了一个完整的高性能不确定性感知高光谱图像重建方法，结果重申了有效光谱编码在快照高光谱成像中的重要性。

Abstract: Hyperspectral image reconstruction from a compressed measurement is a highly ill-posed inverse problem. Current data-driven methods suffer from hallucination due to the lack of spectral diversity in existing hyperspectral image datasets, particularly when they are evaluated for the metamerism phenomenon. In this work, we formulate hyperspectral image (HSI) reconstruction as a Bayesian inference problem and propose a framework, HSDiff, that utilizes an unconditionally trained, pixel-level diffusion prior and posterior diffusion sampling to generate diverse HSI samples consistent with the measurements of various hyperspectral image formation models. We propose an enhanced metameric augmentation technique using region-based metameric black and partition-of-union spectral upsampling to expand training with physically valid metameric spectra, strengthening the prior diversity and improving uncertainty calibration. We utilize HSDiff to investigate how the studied forward models shape the posterior distribution and demonstrate that guiding with effective spectral encoding provides calibrated informative uncertainty compared to non-encoded models. Through the lens of the Bayesian framework, HSDiff offers a complete, high-performance method for uncertainty-aware HSI reconstruction. Our results also reiterate the significance of effective spectral encoding in snapshot hyperspectral imaging.

</details>


### [135] [Yo'City: Personalized and Boundless 3D Realistic City Scene Generation via Self-Critic Expansion](https://arxiv.org/abs/2511.18734)
*Keyang Lu,Sifan Zhou,Hongbin Xu,Gang Xu,Zhifei Yang,Yikai Wang,Zhen Xiao,Jieyi Long,Ming Li*

Main category: cs.CV

TL;DR: Yo'City是一个基于大模型推理和组合能力的智能框架，用于生成用户定制化、无限扩展的3D城市场景，通过分层规划和迭代优化实现高质量城市生成。


<details>
  <summary>Details</summary>
Motivation: 现有3D城市生成方法主要依赖单一扩散模型，无法实现个性化定制和无限扩展的城市规模场景生成。

Method: 采用分层"城市-区域-网格"规划策略，结合全局规划和局部设计，通过"生成-优化-评估"的等距图像合成循环实现网格级3D生成，并引入基于场景图的扩展机制确保空间连贯性。

Result: 在构建的多样化基准数据集上，Yo'City在语义、几何、纹理和布局等多个维度评估中均优于现有最先进方法。

Conclusion: Yo'City框架通过利用大模型的推理和组合能力，成功实现了用户定制化和无限扩展的高质量3D城市生成，为虚拟现实和数字孪生应用提供了有效解决方案。

Abstract: Realistic 3D city generation is fundamental to a wide range of applications, including virtual reality and digital twins. However, most existing methods rely on training a single diffusion model, which limits their ability to generate personalized and boundless city-scale scenes. In this paper, we present Yo'City, a novel agentic framework that enables user-customized and infinitely expandable 3D city generation by leveraging the reasoning and compositional capabilities of off-the-shelf large models. Specifically, Yo'City first conceptualize the city through a top-down planning strategy that defines a hierarchical "City-District-Grid" structure. The Global Planner determines the overall layout and potential functional districts, while the Local Designer further refines each district with detailed grid-level descriptions. Subsequently, the grid-level 3D generation is achieved through a "produce-refine-evaluate" isometric image synthesis loop, followed by image-to-3D generation. To simulate continuous city evolution, Yo'City further introduces a user-interactive, relationship-guided expansion mechanism, which performs scene graph-based distance- and semantics-aware layout optimization, ensuring spatially coherent city growth. To comprehensively evaluate our method, we construct a diverse benchmark dataset and design six multi-dimensional metrics that assess generation quality from the perspectives of semantics, geometry, texture, and layout. Extensive experiments demonstrate that Yo'City consistently outperforms existing state-of-the-art methods across all evaluation aspects.

</details>


### [136] [Extreme Model Compression for Edge Vision-Language Models: Sparse Temporal Token Fusion and Adaptive Neural Compression](https://arxiv.org/abs/2511.18504)
*Md Tasnin Tanvir,Soumitra Das,Sk Md Abidar Rahaman,Ali Shiri Sichani*

Main category: cs.CV

TL;DR: 本文提出了两种自适应压缩技术STTF和ANC，用于在资源受限的边缘设备上实现实时视觉语言任务。TinyGPT-STTF模型在COCO数据集上超越LLaVA-1.5 7B，参数量减少2.3倍，FLOPs减少62倍。


<details>
  <summary>Details</summary>
Motivation: 边缘AI对视觉语言任务的需求要求模型在资源受限的设备上实现实时性能，需要解决有限功率和内存的挑战。

Method: 提出两种自适应压缩技术：STTF通过事件驱动变化检测动态重用视觉令牌，ANC通过学习的路由器条件激活编码器分支，实现细粒度场景复杂度适应。

Result: TinyGPT-STTF在COCO 2017测试集上达到CIDEr 131.2，BLEU-4 0.38等指标，超越LLaVA-1.5 7B 17.6 CIDEr点。STTF在事件视觉任务中减少84%令牌数，保持95.6%准确率；ANC在低运动场景中减少90% FLOPs。

Conclusion: 这些结果使得能够在真实世界边缘设备上高效部署有能力的视觉语言模型，相比强基线提高准确率4.4%，减少延迟13倍。

Abstract: The demand for edge AI in vision-language tasks requires models that achieve real-time performance on resource-constrained devices with limited power and memory. This paper proposes two adaptive compression techniques -- Sparse Temporal Token Fusion (STTF) and Adaptive Neural Compression (ANC) -- that integrate algorithmic innovations with hardware-aware optimizations. Unlike previous approaches relying on static pruning or uniform scaling, STTF dynamically reuses visual tokens through event-driven change detection, while ANC conditionally activates encoder branches via a learned router, enabling fine-grained adaptation to scene complexity. Our 3B-parameter TinyGPT-STTF achieves CIDEr 131.2, BLEU-4 0.38, METEOR 0.31, and ROUGE-L 0.56 on the COCO 2017 test set, surpassing LLaVA-1.5 7B by 17.6 CIDEr points while using 2.3x fewer parameters and 62x fewer on-device FLOPs. TinyGPT-ANC reaches CIDEr 128.5. On event-based vision tasks, STTF reduces average token count by 84% (from 196 to 31 tokens) while preserving 95.6% accuracy on the DVS128 Gesture dataset, and ANC cuts FLOPs by up to 90% in low-motion scenes. Compared to strong baselines, our models improve accuracy by up to 4.4% and reduce latency by up to 13x. These results enable efficient deployment of capable vision-language models on real-world edge devices.

</details>


### [137] [Thinking Ahead: Foresight Intelligence in MLLMs and World Models](https://arxiv.org/abs/2511.18735)
*Zhantao Gong,Liaoyuan Fan,Qing Guo,Xun Xu,Xulei Yang,Shijie Li*

Main category: cs.CV

TL;DR: 该论文提出了Foresight Intelligence（前瞻智能）概念，并创建了FSU-QA数据集来评估和增强视觉语言模型对未来事件的预测能力。研究发现当前模型在预见性推理方面表现不佳，但通过FSU-QA微调的小模型能超越大型先进模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究普遍忽视了预测和解释未来事件的能力（前瞻智能），而这种能力对于自动驾驶等应用至关重要。为了填补这一研究空白，需要专门的数据集和评估方法。

Method: 引入FSU-QA视觉问答数据集，用于激发和评估前瞻智能；对最先进的视觉语言模型进行预见性任务的全面研究；通过语义一致性衡量世界模型的预测质量；使用FSU-QA微调模型以增强预见性推理能力。

Result: 当前视觉语言模型在预见未来情境方面仍存在困难；FSU-QA能够有效评估世界模型的预测质量；即使小型模型在FSU-QA上微调后，也能大幅超越更大、更先进的模型。

Conclusion: FSU-QA为开发能够真正预测和理解未来事件的下一代模型提供了原则性基础，推动了前瞻智能研究的发展。

Abstract: In this work, we define Foresight Intelligence as the capability to anticipate and interpret future events-an ability essential for applications such as autonomous driving, yet largely overlooked by existing research. To bridge this gap, we introduce FSU-QA, a new Visual Question-Answering (VQA) dataset specifically designed to elicit and evaluate Foresight Intelligence. Using FSU-QA, we conduct the first comprehensive study of state-of-the-art Vision-Language Models (VLMs) under foresight-oriented tasks, revealing that current models still struggle to reason about future situations. Beyond serving as a benchmark, FSU-QA also enables the assessment of world models by measuring the semantic coherence of their generated predictions, quantified through performance gains when VLMs are augmented with such outputs. Our experiments further demonstrate that FSU-QA can effectively enhance foresight reasoning: even small VLMs fine-tuned on FSU-QA surpass much larger, advanced models by a substantial margin. Together, these findings position FSU-QA as a principled foundation for developing next-generation models capable of truly anticipating and understanding future events.

</details>


### [138] [ProxT2I: Efficient Reward-Guided Text-to-Image Generation via Proximal Diffusion](https://arxiv.org/abs/2511.18742)
*Zhenghan Fang,Jian Zheng,Qiaozi Gao,Xiaofeng Gao,Jeremias Sulam*

Main category: cs.CV

TL;DR: 本文提出了一种基于后向离散化的文本到图像扩散模型ProxT2I，使用学习的条件近端算子替代分数函数，结合强化学习优化采样器，并构建了大规模数据集LAION-Face-T2I-15M，在提高采样效率和人类偏好对齐的同时降低了计算需求和模型大小。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型依赖前向离散化和数据学习的分数函数，存在采样速度慢、稳定性差的问题，需要大量采样步骤才能生成高质量样本。

Method: 开发基于后向离散化的文本到图像扩散模型ProxT2I，使用学习的条件近端算子替代分数函数，结合强化学习和策略优化技术优化采样器，并构建了包含1500万高质量人脸图像的大规模数据集LAION-Face-T2I-15M。

Result: 相比基于分数的基线方法，该方法显著提高了采样效率和人类偏好对齐，在达到现有最先进开源文本到图像模型性能的同时，降低了计算需求和模型大小。

Conclusion: ProxT2I为人类文本到图像生成提供了一个轻量级但高性能的解决方案，通过后向离散化和近端算子的方法有效解决了传统扩散模型的采样效率问题。

Abstract: Diffusion models have emerged as a dominant paradigm for generative modeling across a wide range of domains, including prompt-conditional generation. The vast majority of samplers, however, rely on forward discretization of the reverse diffusion process and use score functions that are learned from data. Such forward and explicit discretizations can be slow and unstable, requiring a large number of sampling steps to produce good-quality samples. In this work we develop a text-to-image (T2I) diffusion model based on backward discretizations, dubbed ProxT2I, relying on learned and conditional proximal operators instead of score functions. We further leverage recent advances in reinforcement learning and policy optimization to optimize our samplers for task-specific rewards. Additionally, we develop a new large-scale and open-source dataset comprising 15 million high-quality human images with fine-grained captions, called LAION-Face-T2I-15M, for training and evaluation. Our approach consistently enhances sampling efficiency and human-preference alignment compared to score-based baselines, and achieves results on par with existing state-of-the-art and open-source text-to-image models while requiring lower compute and smaller model size, offering a lightweight yet performant solution for human text-to-image generation.

</details>


### [139] [Any4D: Open-Prompt 4D Generation from Natural Language and Images](https://arxiv.org/abs/2511.18746)
*Hao Li,Qiao Sun*

Main category: cs.CV

TL;DR: 提出PEWM方法，通过限制视频生成为较短时间范围，实现语言概念与机器人动作视觉表示的细粒度对齐，降低学习复杂度和推理延迟，提高数据效率。


<details>
  <summary>Details</summary>
Motivation: 基于视频生成的具身世界模型依赖大规模交互数据，但具身数据的稀缺性、收集难度和高维度限制了语言与动作的对齐粒度，阻碍了具身领域的'GPT时刻'。

Method: 提出PEWM方法，限制视频生成为较短时间范围，配备模块化视觉语言模型规划器和起始-目标热图引导机制，支持原始级策略的组合泛化。

Result: PEWM实现了语言概念与机器人动作视觉表示的细粒度对齐，降低了学习复杂度，提高了数据效率，减少了推理延迟。

Conclusion: 该框架利用视频模型的时空视觉先验和视觉语言模型的语义意识，弥合细粒度物理交互与高级推理之间的差距，为可扩展、可解释和通用具身智能铺平道路。

Abstract: While video-generation-based embodied world models have gained increasing attention, their reliance on large-scale embodied interaction data remains a key bottleneck. The scarcity, difficulty of collection, and high dimensionality of embodied data fundamentally limit the alignment granularity between language and actions and exacerbate the challenge of long-horizon video generation--hindering generative models from achieving a \textit{"GPT moment"} in the embodied domain. There is a naive observation: \textit{the diversity of embodied data far exceeds the relatively small space of possible primitive motions}. Based on this insight, we propose \textbf{Primitive Embodied World Models} (PEWM), which restricts video generation to fixed shorter horizons, our approach \textit{1) enables} fine-grained alignment between linguistic concepts and visual representations of robotic actions, \textit{2) reduces} learning complexity, \textit{3) improves} data efficiency in embodied data collection, and \textit{4) decreases} inference latency. By equipping with a modular Vision-Language Model (VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further enables flexible closed-loop control and supports compositional generalization of primitive-level policies over extended, complex tasks. Our framework leverages the spatiotemporal vision priors in video models and the semantic awareness of VLMs to bridge the gap between fine-grained physical interaction and high-level reasoning, paving the way toward scalable, interpretable, and general-purpose embodied intelligence.

</details>


### [140] [Unified Deep Learning Platform for Dust and Fault Diagnosis in Solar Panels Using Thermal and Visual Imaging](https://arxiv.org/abs/2511.18514)
*Abishek Karthik,Sreya Mynampati,Pandiyaraju V*

Main category: cs.CV

TL;DR: 开发了一个集中式平台，使用CNN、ResNet和KerNet模型检测太阳能电池板上的灰尘和故障，通过分析功率输出、正弦波、电压等参数，实现了比现有模型更高的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 太阳能电池板输出受强度、温度、灰尘等多种因素影响，需要有效的检测系统来维护太阳能电池板的性能，特别是在不同地理环境下效率差异显著的情况下。

Method: 使用伽马去除和高斯滤波预处理图像，结合CNN、ResNet和自注意力机制的KerNet模型进行分类，检测灰尘和故障，包括阴影、树叶、裂纹等。

Result: 模型在检测灰尘和故障方面表现出更高的效率和准确性，优于现有模型，适用于从家庭到大型太阳能农场的各种规模需求。

Conclusion: 该多应用模型在检测太阳能电池板灰尘和故障方面高效且优化，证明了其在维护太阳能系统性能方面的实用性和优越性。

Abstract: Solar energy is one of the most abundant and tapped sources of renewable energies with enormous future potential. Solar panel output can vary widely with factors like intensity, temperature, dirt, debris and so on affecting it. We have implemented a model on detecting dust and fault on solar panels. These two applications are centralized as a single-platform and can be utilized for routine-maintenance and any other checks. These are checked against various parameters such as power output, sinusoidal wave (I-V component of solar cell), voltage across each solar cell and others. Firstly, we filter and preprocess the obtained images using gamma removal and Gaussian filtering methods alongside some predefined processes like normalization. The first application is to detect whether a solar cell is dusty or not based on various pre-determined metrics like shadowing, leaf, droppings, air pollution and from other human activities to extent of fine-granular solar modules. The other one is detecting faults and other such occurrences on solar panels like faults, cracks, cell malfunction using thermal imaging application. This centralized platform can be vital since solar panels have different efficiency across different geography (air and heat affect) and can also be utilized for small-scale house requirements to large-scale solar farm sustentation effectively. It incorporates CNN, ResNet models that with self-attention mechanisms-KerNet model which are used for classification and results in a fine-tuned system that detects dust or any fault occurring. Thus, this multi-application model proves to be efficient and optimized in detecting dust and faults on solar panels. We have performed various comparisons and findings that demonstrates that our model has better efficiency and accuracy results overall than existing models.

</details>


### [141] [Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment](https://arxiv.org/abs/2511.18766)
*Xintao Chen,Xiaohao Xu,Bozhong Zheng,Yun Liu,Yingna Wu*

Main category: cs.CV

TL;DR: VSAD是一个新颖的多视角异常检测框架，通过显式建模跨视角的几何一致性来学习视角不变表示，在RealIAD和MANTA数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多视角图像中真实缺陷与由视角变化引起的良性外观变化难以区分的问题，现有方法将多视角视为不连通的图像集，导致特征表示不一致和误报率高。

Method: 提出ViewSense-AD框架，包含多视角对齐模块(MVAM)利用单应性投影对齐相邻视角的特征区域，集成到View-Align潜在扩散模型(VALDM)中实现渐进式多阶段对齐，以及轻量级融合精炼模块(FRM)增强全局一致性。

Result: 在RealIAD和MANTA数据集上的广泛实验表明，VSAD在像素、视角和样本级别的视觉异常检测中显著优于现有方法，证明其对大视角偏移和复杂纹理的鲁棒性。

Conclusion: VSAD通过几何一致性建模和多阶段对齐机制，能够从多视角图像中构建对物体表面的连贯整体理解，在多视角异常检测任务中实现了突破性进展。

Abstract: Unsupervised visual anomaly detection from multi-view images presents a significant challenge: distinguishing genuine defects from benign appearance variations caused by viewpoint changes. Existing methods, often designed for single-view inputs, treat multiple views as a disconnected set of images, leading to inconsistent feature representations and a high false-positive rate. To address this, we introduce ViewSense-AD (VSAD), a novel framework that learns viewpoint-invariant representations by explicitly modeling geometric consistency across views. At its core is our Multi-View Alignment Module (MVAM), which leverages homography to project and align corresponding feature regions between neighboring views. We integrate MVAM into a View-Align Latent Diffusion Model (VALDM), enabling progressive and multi-stage alignment during the denoising process. This allows the model to build a coherent and holistic understanding of the object's surface from coarse to fine scales. Furthermore, a lightweight Fusion Refiner Module (FRM) enhances the global consistency of the aligned features, suppressing noise and improving discriminative power. Anomaly detection is performed by comparing multi-level features from the diffusion model against a learned memory bank of normal prototypes. Extensive experiments on the challenging RealIAD and MANTA datasets demonstrate that VSAD sets a new state-of-the-art, significantly outperforming existing methods in pixel, view, and sample-level visual anomaly proving its robustness to large viewpoint shifts and complex textures.

</details>


### [142] [Breaking Forgetting: Training-Free Few-Shot Class-Incremental Learning via Conditional Diffusion](https://arxiv.org/abs/2511.18516)
*Haidong Kang,Ketong Qian,Yi Lu*

Main category: cs.CV

TL;DR: 本文提出了一种无训练的少样本类增量学习框架CD-FSCIL，通过条件扩散过程替代传统梯度优化，有效解决灾难性遗忘问题并大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统FSCIL方法依赖梯度优化，随着新类别增加导致训练成本爆炸性增长，且在极少量样本下不仅引发严重灾难性遗忘，还阻碍对新类别的适应。

Method: 提出条件扩散驱动的FSCIL框架，将梯度更新过程替换为基于扩散的生成转换；引入多模态学习策略，集成视觉特征与LLM自动生成的文本描述。

Result: 在主流FSCIL基准测试中达到最先进性能，同时显著降低计算和内存开销。

Conclusion: 该方法实现了向无训练持续适应的范式转变，为FSCIL提供了高效且有效的解决方案。

Abstract: Efforts to overcome catastrophic forgetting in Few-Shot Class-Incremental Learning (FSCIL) have primarily focused on developing more effective gradient-based optimization strategies. In contrast, little attention has been paid to the training cost explosion that inevitably arises as the number of novel classes increases, a consequence of relying on gradient learning even under extreme data scarcity. More critically, since FSCIL typically provides only a few samples for each new class, gradient-based updates not only induce severe catastrophic forgetting on base classes but also hinder adaptation to novel ones. This paper seeks to break this long-standing limitation by asking: Can we design a training-free FSCIL paradigm that entirely removes gradient optimization? We provide an affirmative answer by uncovering an intriguing connection between gradient-based optimization and the Conditional Diffusion process. Building on this observation, we propose a Conditional Diffusion-driven FSCIL (CD-FSCIL) framework that substitutes the conventional gradient update process with a diffusion-based generative transition, enabling training-free incremental adaptation while effectively mitigating forgetting. Furthermore, to enhance representation under few-shot constraints, we introduce a multimodal learning strategy that integrates visual features with natural language descriptions automatically generated by Large Language Models (LLMs). This synergy substantially alleviates the sample scarcity issue and improves generalization across novel classes. Extensive experiments on mainstream FSCIL benchmarks demonstrate that our method not only achieves state-of-the-art performance but also drastically reduces computational and memory overhead, marking a paradigm shift toward training-free continual adaptation.

</details>


### [143] [Rethinking Garment Conditioning in Diffusion-based Virtual Try-On](https://arxiv.org/abs/2511.18775)
*Kihyun Na,Jinyoung Choi,Injung Kim*

Main category: cs.CV

TL;DR: 本文提出了Re-CatVTON，一种高效的虚拟试穿单UNet模型，通过改进的条件学习策略和直接注入真实服装潜在特征，在保持高性能的同时显著降低了计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 虽然基于双UNet架构的扩散模型在虚拟试穿任务中表现出优越的保真度，但其沉重的结构带来了巨大的计算和内存开销。本文旨在开发一个高效的单UNet模型，在保持高性能的同时减少资源消耗。

Method: 通过可视化分析和理论分析提出三个关于上下文特征学习的假设，基于这些假设开发Re-CatVTON模型。引入针对VTON空间拼接条件的改进无分类器引导策略，并直接注入从干净服装潜在特征导出的真实服装潜在特征以防止预测误差累积。

Result: Re-CatVTON相比前身CatVTON显著提升性能，在FID、KID和LPIPS指标上表现更好，仅SSIM略有下降。与高性能双UNet模型Leffa相比，计算和内存需求更少。

Conclusion: Re-CatVTON为单UNet虚拟试穿模型建立了新的效率-性能平衡，证明了通过精心设计的条件学习策略可以在减少计算开销的同时保持高质量输出。

Abstract: Virtual Try-On (VTON) is the task of synthesizing an image of a person wearing a target garment, conditioned on a person image and a garment image. While diffusion-based VTON models featuring a Dual UNet architecture demonstrate superior fidelity compared to single UNet models, they incur substantial computational and memory overhead due to their heavy structure. In this study, through visualization analysis and theoretical analysis, we derived three hypotheses regarding the learning of context features to condition the denoising process. Based on these hypotheses, we developed Re-CatVTON, an efficient single UNet model that achieves high performance. We further enhance the model by introducing a modified classifier-free guidance strategy tailored for VTON's spatial concatenation conditioning, and by directly injecting the ground-truth garment latent derived from the clean garment latent to prevent the accumulation of prediction error. The proposed Re-CatVTON significantly improves performance compared to its predecessor (CatVTON) and requires less computation and memory than the high-performance Dual UNet model, Leffa. Our results demonstrate improved FID, KID, and LPIPS scores, with only a marginal decrease in SSIM, establishing a new efficiency-performance trade-off for single UNet VTON models.

</details>


### [144] [ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection](https://arxiv.org/abs/2511.18780)
*Ruize Ma,Minghong Cai,Yilei Jiang,Jiaming Han,Yi Feng,Yingshui Tan,Xiaoyong Zhu,Bo Zhang,Bo Zheng,Xiangyu Yue*

Main category: cs.CV

TL;DR: ConceptGuard是一个统一的安全防护框架，用于主动检测和缓解多模态视频生成中的不安全语义，通过对比检测和语义抑制机制实现，在两个新基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型虽然提供了多模态控制能力，但也引入了新的安全风险，现有安全方法多为文本专用、需要预知风险类别或作为后处理审计，难以主动应对多模态组合风险。

Method: ConceptGuard采用两阶段方法：对比检测模块将融合的图像-文本输入投影到结构化概念空间识别潜在安全风险；语义抑制机制通过在提示的多模态条件中进行干预，引导生成过程远离不安全概念。

Result: 在两个新基准测试上的综合实验表明，ConceptGuard在风险检测和安全视频生成方面均优于现有基线方法，达到了最先进的性能。

Conclusion: ConceptGuard能够有效应对多模态视频生成中的组合安全风险，为构建更安全的视频生成系统提供了有效解决方案。

Abstract: Recent progress in video generative models has enabled the creation of high-quality videos from multimodal prompts that combine text and images. While these systems offer enhanced controllability, they also introduce new safety risks, as harmful content can emerge from individual modalities or their interaction. Existing safety methods are often text-only, require prior knowledge of the risk category, or operate as post-generation auditors, struggling to proactively mitigate such compositional, multimodal risks. To address this challenge, we present ConceptGuard, a unified safeguard framework for proactively detecting and mitigating unsafe semantics in multimodal video generation. ConceptGuard operates in two stages: First, a contrastive detection module identifies latent safety risks by projecting fused image-text inputs into a structured concept space; Second, a semantic suppression mechanism steers the generative process away from unsafe concepts by intervening in the prompt's multimodal conditioning. To support the development and rigorous evaluation of this framework, we introduce two novel benchmarks: ConceptRisk, a large-scale dataset for training on multimodal risks, and T2VSafetyBench-TI2V, the first benchmark adapted from T2VSafetyBench for the Text-and-Image-to-Video (TI2V) safety setting. Comprehensive experiments on both benchmarks show that ConceptGuard consistently outperforms existing baselines, achieving state-of-the-art results in both risk detection and safe video generation.

</details>


### [145] [HiFi-MambaV2: Hierarchical Shared-Routed MoE for High-Fidelity MRI Reconstruction](https://arxiv.org/abs/2511.18534)
*Pengcheng Fang,Hongli Chen,Guangzhen Yao,Jian Shi,Fangfang Tang,Xiaohao Cai,Shanshan Shan,Feng Liu*

Main category: cs.CV

TL;DR: HiFi-MambaV2是一个用于MRI重建的层次化共享路由混合专家Mamba架构，通过频率分解和内容自适应计算，在保持解剖一致性的同时恢复高频细节。


<details>
  <summary>Details</summary>
Motivation: 从欠采样的k空间数据重建高保真MRI图像需要恢复高频细节并保持解剖一致性，现有方法在这方面存在挑战。

Method: 采用可分离频率一致拉普拉斯金字塔(SF-Lap)提供抗混叠的稳定低频和高频流，以及层次化共享路由MoE进行逐像素稀疏分发到共享专家和本地路由器，结合轻量级全局上下文路径和数据一致性正则化主干。

Result: 在多个数据集上评估显示，HiFi-MambaV2在PSNR、SSIM和NMSE指标上持续优于CNN、Transformer和先前Mamba基线，在高频细节和结构保真度方面表现优异。

Conclusion: HiFi-MambaV2实现了可靠且鲁棒的MRI重建，在单线圈和多线圈设置以及多种加速因子下均表现出色。

Abstract: Reconstructing high-fidelity MR images from undersampled k-space data requires recovering high-frequency details while maintaining anatomical coherence. We present HiFi-MambaV2, a hierarchical shared-routed Mixture-of-Experts (MoE) Mamba architecture that couples frequency decomposition with content-adaptive computation. The model comprises two core components: (i) a separable frequency-consistent Laplacian pyramid (SF-Lap) that delivers alias-resistant, stable low- and high-frequency streams; and (ii) a hierarchical shared-routed MoE that performs per-pixel top-1 sparse dispatch to shared experts and local routers, enabling effective specialization with stable cross-depth behavior. A lightweight global context path is fused into an unrolled, data-consistency-regularized backbone to reinforce long-range reasoning and preserve anatomical coherence. Evaluated on fastMRI, CC359, ACDC, M4Raw, and Prostate158, HiFi-MambaV2 consistently outperforms CNN-, Transformer-, and prior Mamba-based baselines in PSNR, SSIM, and NMSE across single- and multi-coil settings and multiple acceleration factors, consistently surpassing consistent improvements in high-frequency detail and overall structural fidelity. These results demonstrate that HiFi-MambaV2 enables reliable and robust MRI reconstruction.

</details>


### [146] [Zero-Shot Video Deraining with Video Diffusion Models](https://arxiv.org/abs/2511.18537)
*Tuomas Varanka,Juan Luis Gonzalez,Hyeongwoo Kim,Pablo Garrido,Xu Yao*

Main category: cs.CV

TL;DR: 提出首个零样本视频去雨方法，无需合成数据或模型微调，利用预训练文本到视频扩散模型，通过负提示和注意力切换机制去除动态场景中的雨水。


<details>
  <summary>Details</summary>
Motivation: 现有视频去雨方法依赖合成数据或静态相机数据，难以泛化到真实动态场景；扩散模型微调会削弱生成先验，限制泛化能力。

Method: 将输入视频反演到扩散模型潜在空间，通过负提示干预重建过程去除雨水概念，核心是注意力切换机制以保持动态背景和结构一致性。

Result: 在真实世界雨数据集上的广泛实验显示，相比先前方法有显著改进，无需监督训练即可实现鲁棒泛化。

Conclusion: 该方法成功实现了零样本视频去雨，在动态场景中有效去除雨水同时保持背景动态和结构一致性。

Abstract: Existing video deraining methods are often trained on paired datasets, either synthetic, which limits their ability to generalize to real-world rain, or captured by static cameras, which restricts their effectiveness in dynamic scenes with background and camera motion. Furthermore, recent works in fine-tuning diffusion models have shown promising results, but the fine-tuning tends to weaken the generative prior, limiting generalization to unseen cases. In this paper, we introduce the first zero-shot video deraining method for complex dynamic scenes that does not require synthetic data nor model fine-tuning, by leveraging a pretrained text-to-video diffusion model that demonstrates strong generalization capabilities. By inverting an input video into the latent space of diffusion models, its reconstruction process can be intervened and pushed away from the model's concept of rain using negative prompting. At the core of our approach is an attention switching mechanism that we found is crucial for maintaining dynamic backgrounds as well as structural consistency between the input and the derained video, mitigating artifacts introduced by naive negative prompting. Our approach is validated through extensive experiments on real-world rain datasets, demonstrating substantial improvements over prior methods and showcasing robust generalization without the need for supervised training.

</details>


### [147] [Mitigating Long-Tail Bias in HOI Detection via Adaptive Diversity Cache](https://arxiv.org/abs/2511.18811)
*Yuqiu Jiang,Xiaozhen Qiao,Tianyu Mei,Haojian Huang,Yifan Chen,Ye Zheng,Zhe Sun*

Main category: cs.CV

TL;DR: 提出了自适应多样性缓存（ADC）模块，一种无需训练即插即用的机制，用于缓解HOI检测中的长尾偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于VLM的HOI检测方法严重依赖额外训练或提示调优，导致计算开销大且可扩展性有限，特别是在长尾场景中罕见交互严重不足的情况下。

Method: ADC模块构建类别特定的缓存，在推理过程中积累高置信度和多样化的特征表示，并采用频率感知的缓存适应机制，优先考虑稀有类别，实现无需额外训练或微调的鲁棒预测校准。

Result: 在HICO-DET和V-COCO数据集上的广泛实验表明，ADC持续改进现有HOI检测器，在稀有类别上实现高达+8.57% mAP增益，在全数据集上实现+4.39%增益。

Conclusion: ADC在缓解长尾偏差的同时保持整体性能，证明了其有效性。

Abstract: Human-Object Interaction (HOI) detection is a fundamental task in computer vision, empowering machines to comprehend human-object relationships in diverse real-world scenarios. Recent advances in VLMs have significantly improved HOI detection by leveraging rich cross-modal representations. However, most existing VLM-based approaches rely heavily on additional training or prompt tuning, resulting in substantial computational overhead and limited scalability, particularly in long-tailed scenarios where rare interactions are severely underrepresented. In this paper, we propose the Adaptive Diversity Cache (ADC) module, a novel training-free and plug-and-play mechanism designed to mitigate long-tail bias in HOI detection. ADC constructs class-specific caches that accumulate high-confidence and diverse feature representations during inference. The method incorporates frequency-aware cache adaptation that favors rare categories and is designed to enable robust prediction calibration without requiring additional training or fine-tuning. Extensive experiments on HICO-DET and V-COCO datasets show that ADC consistently improves existing HOI detectors, achieving up to +8.57\% mAP gain on rare categories and +4.39\% on the full dataset, demonstrating its effectiveness in mitigating long-tail bias while preserving overall performance.

</details>


### [148] [C3Po: Cross-View Cross-Modality Correspondence by Pointmap Prediction](https://arxiv.org/abs/2511.18559)
*Kuan Wei Huang,Brandon Li,Bharath Hariharan,Noah Snavely*

Main category: cs.CV

TL;DR: 本文提出了C3数据集，用于解决地面照片与平面图之间的跨模态几何对应问题，显著提升了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有几何模型在处理不同视角（如航拍与地面）或不同模态（如照片与抽象绘图）的输入时表现不佳，特别是在地面照片与平面图的对应预测任务上。现有数据集在模态多样性或对应关系方面存在局限。

Method: 通过从互联网照片集合中利用运动恢复结构技术重建3D场景，然后手动将这些重建结果与从互联网收集的平面图进行配准，从而推导出图像与平面图之间的对应关系。

Result: C3数据集包含597个场景中的90K对平面图和照片，具有153M像素级对应关系和85K相机姿态。通过在C3数据上训练，将最佳方法的RMSE提升了34%。

Conclusion: C3数据集有助于解决跨模态几何推理中的开放挑战，现有最先进的对应模型在此任务上仍面临困难。

Abstract: Geometric models like DUSt3R have shown great advances in understanding the geometry of a scene from pairs of photos. However, they fail when the inputs are from vastly different viewpoints (e.g., aerial vs. ground) or modalities (e.g., photos vs. abstract drawings) compared to what was observed during training. This paper addresses a challenging version of this problem: predicting correspondences between ground-level photos and floor plans. Current datasets for joint photo--floor plan reasoning are limited, either lacking in varying modalities (VIGOR) or lacking in correspondences (WAFFLE). To address these limitations, we introduce a new dataset, C3, created by first reconstructing a number of scenes in 3D from Internet photo collections via structure-from-motion, then manually registering the reconstructions to floor plans gathered from the Internet, from which we can derive correspondence between images and floor plans. C3 contains 90K paired floor plans and photos across 597 scenes with 153M pixel-level correspondences and 85K camera poses. We find that state-of-the-art correspondence models struggle on this task. By training on our new data, we can improve on the best performing method by 34% in RMSE. We also identify open challenges in cross-modal geometric reasoning that our dataset aims to help address.

</details>


### [149] [FlowSteer: Guiding Few-Step Image Synthesis with Authentic Trajectories](https://arxiv.org/abs/2511.18834)
*Lei Ke,Hubery Yin,Gongye Liu,Zhengyao Lv,Jingcai Guo,Chen Li,Wenhan Luo,Yujiu Yang,Jing Lyu*

Main category: cs.CV

TL;DR: FlowSteer方法通过在线轨迹对齐和对抗蒸馏目标，解决了ReFlow框架中的分布不匹配问题，提升了基于ReFlow的蒸馏性能，并在SD3上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 流匹配在视觉生成中取得成功，但采样效率仍是实际应用的关键瓶颈。ReFlow方法虽然与流匹配理论一致，但在实际场景中性能不如一致性蒸馏和分数蒸馏，因此需要改进。

Method: 提出FlowSteer方法：1) 识别Piecewised ReFlow训练中的分布不匹配问题，提出在线轨迹对齐(OTA)解决；2) 在ODE轨迹上应用对抗蒸馏目标，提升学生对教师生成轨迹的遵循；3) 修复FlowMatchEulerDiscreteScheduler中影响少步推理质量的缺陷。

Result: 在SD3上的实验结果表明，该方法有效提升了ReFlow-based蒸馏的性能。

Conclusion: FlowSteer通过轨迹对齐和对抗蒸馏解锁了基于ReFlow的蒸馏潜力，解决了实际性能问题，为流匹配的高效应用提供了有效方案。

Abstract: With the success of flow matching in visual generation, sampling efficiency remains a critical bottleneck for its practical application. Among flow models' accelerating methods, ReFlow has been somehow overlooked although it has theoretical consistency with flow matching. This is primarily due to its suboptimal performance in practical scenarios compared to consistency distillation and score distillation. In this work, we investigate this issue within the ReFlow framework and propose FlowSteer, a method unlocks the potential of ReFlow-based distillation by guiding the student along teacher's authentic generation trajectories. We first identify that Piecewised ReFlow's performance is hampered by a critical distribution mismatch during the training and propose Online Trajectory Alignment(OTA) to resolve it. Then, we introduce a adversarial distillation objective applied directly on the ODE trajectory, improving the student's adherence to the teacher's generation trajectory. Furthermore, we find and fix a previously undiscovered flaw in the widely-used FlowMatchEulerDiscreteScheduler that largely degrades few-step inference quality. Our experiment result on SD3 demonstrates our method's efficacy.

</details>


### [150] [PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation](https://arxiv.org/abs/2511.18570)
*Samarth Chopra,Jing Liang,Gershom Seneviratne,Dinesh Manocha*

Main category: cs.CV

TL;DR: PhysGS是一个基于贝叶斯推理的3D高斯泼溅扩展方法，能够从视觉线索和视觉-语言先验中估计密集的物理属性，如质量、硬度和摩擦系数，同时建模不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D重建方法主要关注几何和外观，无法推断物理属性，而理解物理属性对于机器人安全有效地与环境交互至关重要。

Method: 将属性估计建模为高斯泼溅上的贝叶斯推理，使用视觉线索和视觉-语言先验迭代优化材料和属性信念，同时建模偶然性和认知不确定性。

Result: 在物体尺度、室内和室外数据集上，PhysGS将质量估计准确率提升达22.8%，肖氏硬度误差降低达61.2%，动摩擦误差降低达18.1%。

Conclusion: PhysGS在单一空间连续框架中统一了3D重建、不确定性建模和物理推理，实现了密集物理属性估计。

Abstract: Understanding physical properties such as friction, stiffness, hardness, and material composition is essential for enabling robots to interact safely and effectively with their surroundings. However, existing 3D reconstruction methods focus on geometry and appearance and cannot infer these underlying physical properties. We present PhysGS, a Bayesian-inferred extension of 3D Gaussian Splatting that estimates dense, per-point physical properties from visual cues and vision--language priors. We formulate property estimation as Bayesian inference over Gaussian splats, where material and property beliefs are iteratively refined as new observations arrive. PhysGS also models aleatoric and epistemic uncertainties, enabling uncertainty-aware object and scene interpretation. Across object-scale (ABO-500), indoor, and outdoor real-world datasets, PhysGS improves accuracy of the mass estimation by up to 22.8%, reduces Shore hardness error by up to 61.2%, and lowers kinetic friction error by up to 18.1% compared to deterministic baselines. Our results demonstrate that PhysGS unifies 3D reconstruction, uncertainty modeling, and physical reasoning in a single, spatially continuous framework for dense physical property estimation. Additional results are available at https://samchopra2003.github.io/physgs.

</details>


### [151] [Zero-Reference Joint Low-Light Enhancement and Deblurring via Visual Autoregressive Modeling with VLM-Derived Modulation](https://arxiv.org/abs/2511.18591)
*Wei Dong,Han Zhou,Junwei Lin,Jun Chen*

Main category: cs.CV

TL;DR: 提出了一种基于视觉自回归建模和视觉语言模型引导的生成框架，用于解决真实世界暗光图像的低可见度、对比度、噪声和模糊问题。该框架通过自适应曲线估计、动态空间频率感知旋转位置编码和递归相位域调制策略，实现了无监督的暗光图像恢复，并在基准数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 真实世界暗光图像不仅存在低可见度和对比度问题，还包含复杂的噪声和模糊，给图像恢复带来巨大挑战。现有方法通常依赖配对数据或无法建模动态光照和模糊特性，导致泛化能力差。

Method: 1. 基于视觉语言模型的自适应曲线估计方案，根据可见度得分调节多样光照；2. 在VAR中集成动态和空间频率感知的旋转位置编码，增强对模糊退化结构的建模能力；3. 提出递归相位域调制策略，通过视觉语言模型评估的模糊得分引导有界迭代优化，减轻模糊引起的伪影。

Result: 该框架完全无监督，在基准数据集上实现了最先进的性能表现。

Conclusion: 提出的生成框架通过结合视觉自回归建模和视觉语言模型引导，有效解决了暗光图像恢复中的复杂退化问题，展现了优异的泛化能力和恢复效果。

Abstract: Real-world dark images commonly exhibit not only low visibility and contrast but also complex noise and blur, posing significant restoration challenges. Existing methods often rely on paired data or fail to model dynamic illumination and blur characteristics, leading to poor generalization. To tackle this, we propose a generative framework based on visual autoregressive (VAR) modeling, guided by perceptual priors from the vision-language model (VLM). Specifically, to supply informative conditioning cues for VAR models, we deploy an adaptive curve estimation scheme to modulate the diverse illumination based on VLM-derived visibility scores. In addition, we integrate dynamic and spatial-frequency-aware Rotary Positional Encodings (SF-RoPE) into VAR to enhance its ability to model structures degraded by blur. Furthermore, we propose a recursive phase-domain modulation strategy that mitigates blur-induced artifacts in the phase domain via bounded iterative refinement guided by VLM-assessed blur scores. Our framework is fully unsupervised and achieves state-of-the-art performance on benchmark datasets.

</details>


### [152] [Personalized Federated Segmentation with Shared Feature Aggregation and Boundary-Focused Calibration](https://arxiv.org/abs/2511.18847)
*Ishmam Tashdeed,Md. Atiqur Rahman,Sabrina Islam,Md. Azam Hossain*

Main category: cs.CV

TL;DR: 提出了FedOAP方法，一种用于器官无关肿瘤分割的个性化联邦学习方法，通过解耦交叉注意力和扰动边界损失来提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有个性化联邦学习方法大多忽视了利用跨客户端共享特征的潜在优势，特别是在每个客户端包含不同器官分割数据的情况下。

Method: 使用解耦交叉注意力(DCA)建模不同客户端共享特征间的长程依赖关系，并引入扰动边界损失(PBL)来改善分割边界的一致性。

Result: 在不同器官的多种肿瘤分割任务上的广泛实验表明，FedOAP始终优于现有的最先进联邦和个性化分割方法。

Conclusion: FedOAP通过有效利用跨客户端共享特征和改善边界分割一致性，在器官无关肿瘤分割任务中取得了显著性能提升。

Abstract: Personalized federated learning (PFL) possesses the unique capability of preserving data confidentiality among clients while tackling the data heterogeneity problem of non-independent and identically distributed (Non-IID) data. Its advantages have led to widespread adoption in domains such as medical image segmentation. However, the existing approaches mostly overlook the potential benefits of leveraging shared features across clients, where each client contains segmentation data of different organs. In this work, we introduce a novel personalized federated approach for organ agnostic tumor segmentation (FedOAP), that utilizes cross-attention to model long-range dependencies among the shared features of different clients and a boundary-aware loss to improve segmentation consistency. FedOAP employs a decoupled cross-attention (DCA), which enables each client to retain local queries while attending to globally shared key-value pairs aggregated from all clients, thereby capturing long-range inter-organ feature dependencies. Additionally, we introduce perturbed boundary loss (PBL) which focuses on the inconsistencies of the predicted mask's boundary for each client, forcing the model to localize the margins more precisely. We evaluate FedOAP on diverse tumor segmentation tasks spanning different organs. Extensive experiments demonstrate that FedOAP consistently outperforms existing state-of-the-art federated and personalized segmentation methods.

</details>


### [153] [NeAR: Coupled Neural Asset-Renderer Stack](https://arxiv.org/abs/2511.18600)
*Hong Li,Chongjie Ye,Houyuan Chen,Weiqing Xiao,Ziyang Yan,Lixing Xiao,Zhaoxi Chen,Jianfeng Xiang,Shaocong Xu,Xuhui Liu,Yikai Wang,Baochang Zhang,Xiaoguang Han,Jiaolong Yang,Hao Zhao*

Main category: cs.CV

TL;DR: NeAR提出了一种耦合的神经资产-渲染器堆栈，将神经资产创作和神经渲染联合设计，实现端到端可学习的图形管线，在保真度、一致性和效率方面具有优势。


<details>
  <summary>Details</summary>
Motivation: 目前神经资产创作和神经渲染是分离的领域，联合设计资产表示和渲染器可以解锁端到端可学习的图形堆栈，带来保真度、一致性和效率方面的好处。

Method: 在资产侧基于Trellis风格的结构化3D潜在空间，引入光照均匀化的神经资产；在渲染器侧设计光照感知的神经渲染器，使用神经资产、显式视图嵌入和HDR环境贴图实现实时可重光照渲染。

Result: NeAR在四个任务上验证：基于G-buffer的前向渲染、随机光照单图像重建、未知光照单图像重光照、新视角重光照，在定量指标和感知质量上都超越了现有最先进方法。

Conclusion: 耦合的资产-渲染器视角为未来图形堆栈提供了新思路，将神经资产和渲染器视为协同设计的组件而非独立实体。

Abstract: Neural asset authoring and neural rendering have emerged as fundamentally disjoint threads: one generates digital assets using neural networks for traditional graphics pipelines, while the other develops neural renderers that map conventional assets to images. However, the potential of jointly designing the asset representation and renderer remains largely unexplored. We argue that coupling them can unlock an end-to-end learnable graphics stack with benefits in fidelity, consistency, and efficiency. In this paper, we explore this possibility with NeAR: a Coupled Neural Asset-Renderer Stack. On the asset side, we build on Trellis-style Structured 3D Latents and introduce a lighting-homogenized neural asset: from a casually lit input, a rectified-flow backbone predicts a Lighting-Homogenized SLAT that encodes geometry and intrinsic material cues in a compact, view-agnostic latent. On the renderer side, we design a lighting-aware neural renderer that uses this neural asset, along with explicit view embeddings and HDR environment maps, to achieve real-time, relightable rendering. We validate NeAR on four tasks: (1) G-buffer-based forward rendering, (2) random-lit single-image reconstruction, (3) unknown-lit single-image relighting, and (4) novel-view relighting. Our coupled stack surpasses state-of-the-art baselines in both quantitative metrics and perceptual quality. We hope this coupled asset-renderer perspective inspires future graphics stacks that view neural assets and renderers as co-designed components instead of independent entities.

</details>


### [154] [Deep Hybrid Model for Region of Interest Detection in Omnidirectional Videos](https://arxiv.org/abs/2511.18856)
*Sana Alamgeer*

Main category: cs.CV

TL;DR: 设计一个混合显著性模型来预测360度视频中的感兴趣区域，以优化视频流传输和提升观看体验。


<details>
  <summary>Details</summary>
Motivation: 360度视频中的感兴趣区域对于视频流传输至关重要，可以用于预测视口、智能裁剪视频以减少带宽使用，并减少头戴设备观看时的头部移动。

Method: 预处理视频获取帧，开发混合显著性模型预测感兴趣区域，后处理模型输出得到每帧的感兴趣区域。

Result: 将所提方法与360RAT数据集的主观标注进行比较评估性能。

Conclusion: 通过混合显著性模型可以有效识别360度视频中的感兴趣区域，为视频流传输优化提供技术支持。

Abstract: The main goal of the project is to design a new model that predicts regions of interest in 360$^{\circ}$ videos. The region of interest (ROI) plays an important role in 360$^{\circ}$ video streaming. For example, ROIs are used to predict view-ports, intelligently cut the videos for live streaming, etc so that less bandwidth is used. Detecting view-ports in advance helps reduce the movement of the head while streaming and watching a video via the head-mounted device. Whereas, intelligent cuts of the videos help improve the efficiency of streaming the video to users and enhance the quality of their viewing experience. This report illustrates the secondary task to identify ROIs, in which, we design, train, and test a hybrid saliency model. In this work, we refer to saliency regions to represent the regions of interest. The method includes the processes as follows: preprocessing the video to obtain frames, developing a hybrid saliency model for predicting the region of interest, and finally post-processing the output predictions of the hybrid saliency model to obtain the output region of interest for each frame. Then, we compare the performance of the proposed method with the subjective annotations of the 360RAT dataset.

</details>


### [155] [Functional Localization Enforced Deep Anomaly Detection Using Fundus Images](https://arxiv.org/abs/2511.18627)
*Jan Benedikt Ruhland,Thorsten Papenbrock,Jan-Peter Sowa,Ali Canbay,Nicole Eter,Bernd Freisleben,Dominik Heider*

Main category: cs.CV

TL;DR: 本研究系统评估了Vision Transformer在多种增强策略下对眼底图像中视网膜疾病的检测性能，在多个数据集上表现稳定，准确率0.789-0.843。几何和颜色增强效果最佳，同时开发了GANomaly异常检测器提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决眼底图像检测中成像质量差异、早期病变细微表现和数据集间域偏移等挑战，提高视网膜疾病检测的可靠性。

Method: 使用Vision Transformer分类器结合多种增强策略（几何、颜色、直方图均衡、拉普拉斯增强），在多个公共数据集和自建AEyeDB数据集上进行评估，并开发GANomaly异常检测器提供可解释性。

Result: ViT分类器在不同数据集上表现稳定，准确率0.789-0.843；几何增强在Papila数据集上AUC达0.91，优于卷积集成基线；GANomaly异常检测器AUC为0.76；糖尿病视网膜病变和年龄相关性黄斑变性检测可靠，青光眼最易误分类。

Conclusion: Vision Transformer在视网膜疾病检测中表现优异，几何和颜色增强策略效果稳定，GANomaly提供可解释的异常检测，结合概率校准为临床实施提供支持。

Abstract: Reliable detection of retinal diseases from fundus images is challenged by the variability in imaging quality, subtle early-stage manifestations, and domain shift across datasets. In this study, we systematically evaluated a Vision Transformer (ViT) classifier under multiple augmentation and enhancement strategies across several heterogeneous public datasets, as well as the AEyeDB dataset, a high-quality fundus dataset created in-house and made available for the research community. The ViT demonstrated consistently strong performance, with accuracies ranging from 0.789 to 0.843 across datasets and diseases. Diabetic retinopathy and age-related macular degeneration were detected reliably, whereas glaucoma remained the most frequently misclassified disease. Geometric and color augmentations provided the most stable improvements, while histogram equalization benefited datasets dominated by structural subtlety. Laplacian enhancement reduced performance across different settings.
  On the Papila dataset, the ViT with geometric augmentation achieved an AUC of 0.91, outperforming previously reported convolutional ensemble baselines (AUC of 0.87), underscoring the advantages of transformer architectures and multi-dataset training. To complement the classifier, we developed a GANomaly-based anomaly detector, achieving an AUC of 0.76 while providing inherent reconstruction-based explainability and robust generalization to unseen data. Probabilistic calibration using GUESS enabled threshold-independent decision support for future clinical implementation.

</details>


### [156] [From Healthy Scans to Annotated Tumors: A Tumor Fabrication Framework for 3D Brain MRI Synthesis](https://arxiv.org/abs/2511.18654)
*Nayu Dong,Townim Chowdhury,Hieu Phan,Mark Jenkinson,Johan Verjans,Zhibin Liao*

Main category: cs.CV

TL;DR: 提出Tumor Fabrication (TF)框架，通过两阶段方法合成3D脑肿瘤数据，解决MRI肿瘤标注数据稀缺问题，无需配对数据即可生成大量合成数据用于下游分割任务。


<details>
  <summary>Details</summary>
Motivation: MRI肿瘤标注数据稀缺严重阻碍了准确的自动化肿瘤分割。现有数据合成方法存在局限性：手动建模劳动密集且需要专业知识，深度生成模型需要大量训练对，这在数据有限的临床环境中不实用。

Method: 提出TF框架，包含粗粒度肿瘤合成过程和基于生成模型的精炼过程。该框架完全自动化，仅利用健康图像扫描和少量真实标注数据来合成大量配对的合成数据。

Result: 实验证明，使用TF合成的图像-标签对作为数据增强可以显著提高低数据场景下下游肿瘤分割任务的性能。

Conclusion: TF提供了一个可扩展且可靠的医学图像增强解决方案，解决了临床AI应用中数据稀缺的关键挑战。

Abstract: The scarcity of annotated Magnetic Resonance Imaging (MRI) tumor data presents a major obstacle to accurate and automated tumor segmentation. While existing data synthesis methods offer promising solutions, they often suffer from key limitations: manual modeling is labor intensive and requires expert knowledge. Deep generative models may be used to augment data and annotation, but they typically demand large amounts of training pairs in the first place, which is impractical in data limited clinical settings. In this work, we propose Tumor Fabrication (TF), a novel two-stage framework for unpaired 3D brain tumor synthesis. The framework comprises a coarse tumor synthesis process followed by a refinement process powered by a generative model. TF is fully automated and leverages only healthy image scans along with a limited amount of real annotated data to synthesize large volumes of paired synthetic data for enriching downstream supervised segmentation training. We demonstrate that our synthetic image-label pairs used as data enrichment can significantly improve performance on downstream tumor segmentation tasks in low-data regimes, offering a scalable and reliable solution for medical image enrichment and addressing critical challenges in data scarcity for clinical AI applications.

</details>


### [157] [MetaDCSeg: Robust Medical Image Segmentation via Meta Dynamic Center Weighting](https://arxiv.org/abs/2511.18894)
*Chenyu Mu,Guihai Chen,Xun Yang,Erkun Yang,Cheng Deng*

Main category: cs.CV

TL;DR: MetaDCSeg是一个用于医学图像分割的鲁棒框架，通过动态学习像素级权重来抑制噪声标注的影响，特别关注模糊边界区域的处理。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割常受噪声标注和模糊解剖边界干扰，导致模型训练不稳定。现有方法基于全局噪声假设或置信度样本选择，难以有效处理边界区域的噪声问题。

Method: 提出MetaDCSeg框架，通过动态中心距离（DCD）机制显式建模边界不确定性，使用加权特征距离处理前景、背景和边界中心，引导模型关注模糊边界附近的难分割像素。

Result: 在四个基准数据集上的广泛实验表明，MetaDCSeg在不同噪声水平下均优于现有最先进方法，显著提升了分割性能。

Conclusion: MetaDCSeg通过动态像素权重学习和边界不确定性建模，能够有效抑制噪声标注影响，特别在挑战性边界区域表现出色，为医学图像分割提供了更鲁棒的解决方案。

Abstract: Medical image segmentation is crucial for clinical applications, but it is frequently disrupted by noisy annotations and ambiguous anatomical boundaries, which lead to instability in model training. Existing methods typically rely on global noise assumptions or confidence-based sample selection, which inadequately mitigate the performance degradation caused by annotation noise, especially in challenging boundary regions. To address this issue, we propose MetaDCSeg, a robust framework that dynamically learns optimal pixel-wise weights to suppress the influence of noisy ground-truth labels while preserving reliable annotations. By explicitly modeling boundary uncertainty through a Dynamic Center Distance (DCD) mechanism, our approach utilizes weighted feature distances for foreground, background, and boundary centers, directing the model's attention toward hard-to-segment pixels near ambiguous boundaries. This strategy enables more precise handling of structural boundaries, which are often overlooked by existing methods, and significantly enhances segmentation performance. Extensive experiments across four benchmark datasets with varying noise levels demonstrate that MetaDCSeg consistently outperforms existing state-of-the-art methods.

</details>


### [158] [Robust Physical Adversarial Patches Using Dynamically Optimized Clusters](https://arxiv.org/abs/2511.18656)
*Harrison Bagley,Will Meakin,Simon Lucey,Yee Wei Law,Tat-Jun Chin*

Main category: cs.CV

TL;DR: 本文提出了一种基于超像素的正则化方法，通过SLIC算法在对抗性补丁优化过程中动态聚类像素，使用隐函数定理反向传播梯度来更新超像素边界和颜色，从而产生在尺度变化下保持结构的补丁，减少插值损失。


<details>
  <summary>Details</summary>
Motivation: 物理对抗性攻击在深度学习系统中令人担忧，但现有方法很少关注尺度变化问题。当补丁通过数字下采样/上采样或物理成像距离变化进行缩放时，插值引起的颜色混合会平滑像素值，导致高频模式丢失和对抗信号退化。

Method: 采用基于超像素的正则化方法，在对抗性补丁优化过程中使用SLIC算法动态聚类像素，利用隐函数定理反向传播梯度来更新超像素边界和颜色。

Result: 该方法在数字域实现了更好的性能，当物理实现时，这些性能增益得以保留，导致改进的物理性能。使用新颖的物理评估协议客观评估了真实世界性能。

Conclusion: 提出的超像素正则化方法能够产生对尺度变化具有弹性的对抗性补丁，在数字和物理域都表现出优越性能，解决了插值损失问题。

Abstract: Physical adversarial attacks on deep learning systems is concerning due to the ease of deploying such attacks, usually by placing an adversarial patch in a scene to manipulate the outcomes of a deep learning model. Training such patches typically requires regularization that improves physical realizability (e.g., printability, smoothness) and/or robustness to real-world variability (e.g. deformations, viewing angle, noise). One type of variability that has received little attention is scale variability. When a patch is rescaled, either digitally through downsampling/upsampling or physically through changing imaging distances, interpolation-induced color mixing occurs. This smooths out pixel values, resulting in a loss of high-frequency patterns and degrading the adversarial signal. To address this, we present a novel superpixel-based regularization method that guides patch optimization to scale-resilient structures. Our ap proach employs the Simple Linear Iterative Clustering (SLIC) algorithm to dynamically cluster pixels in an adversarial patch during optimization. The Implicit Function Theorem is used to backpropagate gradients through SLIC to update the superpixel boundaries and color. This produces patches that maintain their structure over scale and are less susceptible to interpolation losses. Our method achieves greater performance in the digital domain, and when realized physically, these performance gains are preserved, leading to improved physical performance. Real-world performance was objectively assessed using a novel physical evaluation protocol that utilizes screens and cardboard cut-outs to systematically vary real-world conditions.

</details>


### [159] [Data Augmentation Strategies for Robust Lane Marking Detection](https://arxiv.org/abs/2511.18668)
*Flora Lian,Dinh Quang Huynh,Hector Penades,J. Stephany Berrio Perez,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: 提出基于生成AI的数据增强方法，通过几何透视变换、AI修复和车辆覆盖等技术模拟特定视角，提升车道线检测模型在侧置摄像头场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决车道线检测模型在公开数据集（如CULane）训练后，无法适应不同摄像头视角（特别是侧置摄像头）的领域偏移问题。

Method: 采用生成AI数据增强流程，结合几何透视变换、AI驱动修复和车辆覆盖技术，模拟部署特定视角并保持车道连续性。

Result: 在SCNN和UFLDv2模型上测试，增强数据训练后模型在不同条件下（包括阴影）表现出更强的鲁棒性，精确率、召回率和F1分数均有提升。

Conclusion: 该方法填补了公开数据集与部署特定场景之间的差距，为车道线检测在试点部署场景中提供了可扩展且实用的可靠性提升框架。

Abstract: Robust lane detection is essential for advanced driver assistance and autonomous driving, yet models trained on public datasets such as CULane often fail to generalise across different camera viewpoints. This paper addresses the challenge of domain shift for side-mounted cameras used in lane-wheel monitoring by introducing a generative AI-based data enhancement pipeline. The approach combines geometric perspective transformation, AI-driven inpainting, and vehicle body overlays to simulate deployment-specific viewpoints while preserving lane continuity. We evaluated the effectiveness of the proposed augmentation in two state-of-the-art models, SCNN and UFLDv2. With the augmented data trained, both models show improved robustness to different conditions, including shadows. The experimental results demonstrate gains in precision, recall, and F1 score compared to the pre-trained model.
  By bridging the gap between widely available datasets and deployment-specific scenarios, our method provides a scalable and practical framework to improve the reliability of lane detection in a pilot deployment scenario.

</details>


### [160] [Sphinx: Efficiently Serving Novel View Synthesis using Regression-Guided Selective Refinement](https://arxiv.org/abs/2511.18672)
*Yuchen Xia,Souvik Kundu,Mosharaf Chowdhury,Nishil Talati*

Main category: cs.CV

TL;DR: Sphinx是一个无需训练的新型视图合成混合推理框架，通过回归式快速初始化和选择性细化，在保持扩散模型质量的同时显著降低计算成本，实现1.8倍加速且感知质量退化小于5%。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在新型视图合成任务中计算成本过高，而回归方法生成质量不足的问题，旨在设计一个高质量且推理高效的NVS框架。

Method: 采用无需训练的混合推理框架：1）使用回归式快速初始化引导扩散模型降噪；2）集成选择性细化与自适应噪声调度，为不确定区域和帧分配更多计算资源。

Result: Sphinx在扩散模型推理基础上平均加速1.8倍，感知质量退化小于5%，在质量和延迟之间建立了新的帕累托前沿。

Conclusion: Sphinx成功实现了扩散级保真度与显著降低计算成本的平衡，为动态变化的推理场景提供了灵活的性能-质量权衡方案。

Abstract: Novel View Synthesis (NVS) is the task of generating new images of a scene from viewpoints that were not part of the original input. Diffusion-based NVS can generate high-quality, temporally consistent images, however, remains computationally prohibitive. Conversely, regression-based NVS offers suboptimal generation quality despite requiring significantly lower compute; leaving the design objective of a high-quality, inference-efficient NVS framework an open challenge. To close this critical gap, we present Sphinx, a training-free hybrid inference framework that achieves diffusion-level fidelity at a significantly lower compute. Sphinx proposes to use regression-based fast initialization to guide and reduce the denoising workload for the diffusion model. Additionally, it integrates selective refinement with adaptive noise scheduling, allowing more compute to uncertain regions and frames. This enables Sphinx to provide flexible navigation of the performance-quality trade-off, allowing adaptation to latency and fidelity requirements for dynamically changing inference scenarios. Our evaluation shows that Sphinx achieves an average 1.8x speedup over diffusion model inference with negligible perceptual degradation of less than 5%, establishing a new Pareto frontier between quality and latency in NVS serving.

</details>


### [161] [Learning What to Trust: Bayesian Prior-Guided Optimization for Visual Generation](https://arxiv.org/abs/2511.18919)
*Ruiying Liu,Yuanzhi Liang,Haibin Huang,Tianshu Yu,Chi Zhang*

Main category: cs.CV

TL;DR: BPGO是一种改进的GRPO框架，通过引入贝叶斯先验锚点来建模奖励不确定性，在组间和组内两个层面自适应调节优化信任，从而解决文本-视觉对应关系的模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 标准GRPO的性能受到文本-视觉对应关系模糊性的限制：单个提示可能描述多种视觉输出，单个图像/视频可能支持多种正确解释。这种多对多关系导致奖励模型产生不确定和弱区分性的信号，使GRPO无法充分利用可靠反馈并过度拟合噪声。

Method: BPGO通过语义先验锚点显式建模奖励不确定性，在组间进行贝叶斯信任分配，强调与先验一致的组更新，同时降低模糊组的权重；在组内进行先验锚定重归一化，通过扩展自信偏差和压缩不确定分数来锐化样本区分度。

Result: 在图像和视频生成任务中，BPGO相比标准GRPO和近期变体，始终提供更强的语义对齐、更高的感知保真度和更快的收敛速度。

Conclusion: BPGO通过显式建模奖励不确定性，有效解决了GRPO中的文本-视觉对应模糊性问题，显著提升了生成模型的后训练优化效果。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as an effective and lightweight framework for post-training visual generative models. However, its performance is fundamentally limited by the ambiguity of textual visual correspondence: a single prompt may validly describe diverse visual outputs, and a single image or video may support multiple equally correct interpretations. This many to many relationship leads reward models to generate uncertain and weakly discriminative signals, causing GRPO to underutilize reliable feedback and overfit noisy ones. We introduce Bayesian Prior-Guided Optimization (BPGO), a novel extension of GRPO that explicitly models reward uncertainty through a semantic prior anchor. BPGO adaptively modulates optimization trust at two levels: inter-group Bayesian trust allocation emphasizes updates from groups consistent with the prior while down-weighting ambiguous ones, and intra-group prior-anchored renormalization sharpens sample distinctions by expanding confident deviations and compressing uncertain scores. Across both image and video generation tasks, BPGO delivers consistently stronger semantic alignment, enhanced perceptual fidelity, and faster convergence than standard GRPO and recent variants.

</details>


### [162] [Edit2Perceive: Image Editing Diffusion Models Are Strong Dense Perceivers](https://arxiv.org/abs/2511.18673)
*Yiqing Shi,Yiren Song,Mike Zheng Shou*

Main category: cs.CV

TL;DR: Edit2Perceive是一个统一的扩散框架，将图像编辑扩散模型适应于深度估计、法线估计和抠图等密集感知任务，通过全参数微调和像素空间一致性损失实现结构保持的细化，在三个任务上均达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前密集感知方法大多依赖为随机生成设计的文本到图像生成器，而图像编辑扩散模型具有固有的图像到图像一致性，为密集感知任务提供了更合适的基础。

Method: 基于FLUX.1 Kontext架构，采用全参数微调和像素空间一致性损失，在中间去噪状态强制执行结构保持细化，使用单步确定性推理加速运行。

Result: 在深度、法线和抠图三个任务上均实现全面的最先进结果，运行速度提升高达5倍，在相对较小的数据集上训练即可获得优异性能。

Conclusion: 编辑导向的扩散变换器在几何感知任务中展现出强大潜力，为密集感知提供了新的范式。

Abstract: Recent advances in diffusion transformers have shown remarkable generalization in visual synthesis, yet most dense perception methods still rely on text-to-image (T2I) generators designed for stochastic generation. We revisit this paradigm and show that image editing diffusion models are inherently image-to-image consistent, providing a more suitable foundation for dense perception task. We introduce Edit2Perceive, a unified diffusion framework that adapts editing models for depth, normal, and matting. Built upon the FLUX.1 Kontext architecture, our approach employs full-parameter fine-tuning and a pixel-space consistency loss to enforce structure-preserving refinement across intermediate denoising states. Moreover, our single-step deterministic inference yields up to faster runtime while training on relatively small datasets. Extensive experiments demonstrate comprehensive state-of-the-art results across all three tasks, revealing the strong potential of editing-oriented diffusion transformers for geometry-aware perception.

</details>


### [163] [A Theory-Inspired Framework for Few-Shot Cross-Modal Sketch Person Re-Identification](https://arxiv.org/abs/2511.18677)
*Yunpeng Gong,Yongjie Hou,Jiangming Shi,Kim Long Diep,Min Jiang*

Main category: cs.CV

TL;DR: KTCAA是一个基于泛化理论的少样本跨模态人物重识别框架，通过对齐增强和知识转移催化剂解决模态差距和数据稀缺问题，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于草图的人物重识别中存在的显著模态差距和有限标注数据问题，受泛化理论启发，关注领域差异性和扰动不变性两个关键因素。

Method: 提出对齐增强（AA）模块应用局部草图风格变换模拟目标分布，以及知识转移催化剂（KTC）模块引入最坏情况扰动并强制一致性，在元学习范式下联合优化。

Result: 在多个基准测试中实现了最先进的性能，特别是在数据稀缺条件下表现优异。

Conclusion: KTCAA框架通过理论指导的模块设计，有效解决了草图到RGB图像跨模态匹配的挑战，为少样本学习提供了有效解决方案。

Abstract: Sketch based person re-identification aims to match hand-drawn sketches with RGB surveillance images, but remains challenging due to significant modality gaps and limited annotated data. To address this, we introduce KTCAA, a theoretically grounded framework for few-shot cross-modal generalization. Motivated by generalization theory, we identify two key factors influencing target domain risk: (1) domain discrepancy, which quantifies the alignment difficulty between source and target distributions; and (2) perturbation invariance, which evaluates the model's robustness to modality shifts. Based on these insights, we propose two components: (1) Alignment Augmentation (AA), which applies localized sketch-style transformations to simulate target distributions and facilitate progressive alignment; and (2) Knowledge Transfer Catalyst (KTC), which enhances invariance by introducing worst-case perturbations and enforcing consistency. These modules are jointly optimized under a meta-learning paradigm that transfers alignment knowledge from data-rich RGB domains to sketch-based scenarios. Experiments on multiple benchmarks demonstrate that KTCAA achieves state-of-the-art performance, particularly in data-scarce conditions.

</details>


### [164] [Neural Geometry Image-Based Representations with Optimal Transport (OT)](https://arxiv.org/abs/2511.18679)
*Xiang Gao,Yuanpeng Liu,Xinmu Wang,Jiazhi Li,Minghao Guo,Yu Guo,Xiyun Song,Heather Yu,Zhiqiang Lao,Xianfeng David Gu*

Main category: cs.CV

TL;DR: 提出了一种基于几何图像的神经表示方法，通过将不规则网格转换为规则图像网格，实现高效的图像式神经处理，无需解码器，具有存储效率高和单次前向传递恢复高质量网格的特点。


<details>
  <summary>Details</summary>
Motivation: 现有3D网格神经表示方法依赖神经过拟合，计算成本高且处理不规则网格结构复杂。而图像具有规则结构便于高效处理，但难以直接应用于网格。关键洞察是将不规则网格转换为几何图像表示。

Method: 使用基于几何图像的表示方法，存储低分辨率几何图像mipmap，通过单次前向传递恢复高质量网格。利用最优传输(OT)解决平坦区域过采样和特征区域欠采样问题，支持连续细节层次(LoD)。

Result: 实验结果显示在压缩比(CR)、Chamfer距离(CD)和Hausdorff距离(HD)方面达到最先进的存储效率和恢复精度。

Conclusion: 该方法提供了解码器无关、存储高效的神经处理方案，通过几何图像表示和最优传输技术实现了高效的3D网格压缩和恢复。

Abstract: Neural representations for 3D meshes are emerging as an effective solution for compact storage and efficient processing. Existing methods often rely on neural overfitting, where a coarse mesh is stored and progressively refined through multiple decoder networks. While this can restore high-quality surfaces, it is computationally expensive due to successive decoding passes and the irregular structure of mesh data. In contrast, images have a regular structure that enables powerful super-resolution and restoration frameworks, but applying these advantages to meshes is difficult because their irregular connectivity demands complex encoder-decoder architectures. Our key insight is that a geometry image-based representation transforms irregular meshes into a regular image grid, making efficient image-based neural processing directly applicable. Building on this idea, we introduce our neural geometry image-based representation, which is decoder-free, storage-efficient, and naturally suited for neural processing. It stores a low-resolution geometry-image mipmap of the surface, from which high-quality meshes are restored in a single forward pass. To construct geometry images, we leverage Optimal Transport (OT), which resolves oversampling in flat regions and undersampling in feature-rich regions, and enables continuous levels of detail (LoD) through geometry-image mipmapping. Experimental results demonstrate state-of-the-art storage efficiency and restoration accuracy, measured by compression ratio (CR), Chamfer distance (CD), and Hausdorff distance (HD).

</details>


### [165] [Hierarchical GraphCut Phase Unwrapping based on Invariance of Diffeomorphisms Framework](https://arxiv.org/abs/2511.18682)
*Xiang Gao,Xinmu Wang,Zhou Zhao,Junqi Huang,Xianfeng David Gu*

Main category: cs.CV

TL;DR: 本文提出了一种基于图像空间微分同胚变换的相位展开框架，将GraphCut相位展开重新表述为像素标记问题，通过多数投票融合实现实时高精度相位恢复。


<details>
  <summary>Details</summary>
Motivation: 现有相位展开方法在速度和精度之间存在权衡：快速方法精度不足，而精确算法速度太慢无法实时应用。结构光扫描在4D面部动态捕捉等应用中需要实时高精度的相位展开技术。

Method: 提出相位展开框架，利用微分同胚的不变性特性，通过共形映射和最优传输映射在图像空间应用，预计算奇数个微分同胚变换，在每个域中应用分层GraphCut算法，最后通过多数投票融合标签图来稳健估计每个像素的相位计数k。

Result: 实验结果显示45.5倍的加速和更低的L2误差，在真实实验和模拟中都表现出色，显示出实时应用的潜力。

Conclusion: 该框架通过微分同胚变换和多数投票融合，成功解决了相位展开中速度与精度的权衡问题，为实时3D扫描应用提供了可行解决方案。

Abstract: Recent years have witnessed rapid advancements in 3D scanning technologies, with applications spanning VR/AR, digital human creation, and medical imaging. Structured-light scanning with phase-shifting techniques is preferred for its use of low-intensity visible light and high accuracy, making it well suited for capturing 4D facial dynamics. A key step is phase unwrapping, which recovers continuous phase values from measurements wrapped modulo 2pi. The goal is to estimate the unwrapped phase count k in the equation Phi = phi + 2pi k, where phi is the wrapped phase and Phi is the true phase. Noise, occlusions, and complex 3D geometry make recovering the true phase challenging because phase unwrapping is ill-posed: measurements only provide modulo 2pi values, and estimating k requires assumptions about surface continuity. Existing methods trade speed for accuracy: fast approaches lack precision, while accurate algorithms are too slow for real-time use. To overcome these limitations, this work proposes a phase unwrapping framework that reformulates GraphCut-based unwrapping as a pixel-labeling problem. This framework improves the estimation of the unwrapped phase count k through the invariance property of diffeomorphisms applied in image space via conformal and optimal transport (OT) maps. An odd number of diffeomorphisms are precomputed from the input phase data, and a hierarchical GraphCut algorithm is applied in each domain. The resulting label maps are fused via majority voting to robustly estimate k at each pixel. Experimental results demonstrate a 45.5x speedup and lower L2 error in real experiments and simulations, showing potential for real-time applications.

</details>


### [166] [Now You See It, Now You Don't - Instant Concept Erasure for Safe Text-to-Image and Video Generation](https://arxiv.org/abs/2511.18684)
*Shristi Das Biswas,Arani Roy,Kaushik Roy*

Main category: cs.CV

TL;DR: ICE是一种无需训练、模态无关的一次性权重修改方法，用于文本到图像和文本到视频模型的概念擦除，通过各向异性能量加权缩放和重叠投影器实现精确持久的概念遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法存在重新训练成本高、推理开销大或易受对抗攻击的问题，且很少建模目标擦除概念与周围内容的潜在语义重叠，导致擦除后产生附带损害。

Method: ICE使用各向异性能量加权缩放定义擦除和保留子空间，通过独特的闭式重叠投影器显式正则化它们的交集，提出凸且Lipschitz有界的谱遗忘目标，获得稳定唯一的解析解。

Result: 在艺术风格、物体、身份和显式内容的目标移除中，ICE高效实现强擦除效果，提高对红队测试的鲁棒性，同时对T2I和T2V模型的原始生成能力仅造成最小退化。

Conclusion: ICE是一种训练免费、模态无关的概念擦除方法，能够实现精确持久的概念遗忘，在保持模型生成能力的同时提高安全性。

Abstract: Robust concept removal for text-to-image (T2I) and text-to-video (T2V) models is essential for their safe deployment. Existing methods, however, suffer from costly retraining, inference overhead, or vulnerability to adversarial attacks. Crucially, they rarely model the latent semantic overlap between the target erase concept and surrounding content -- causing collateral damage post-erasure -- and even fewer methods work reliably across both T2I and T2V domains. We introduce Instant Concept Erasure (ICE), a training-free, modality-agnostic, one-shot weight modification approach that achieves precise, persistent unlearning with zero overhead. ICE defines erase and preserve subspaces using anisotropic energy-weighted scaling, then explicitly regularises against their intersection using a unique, closed-form overlap projector. We pose a convex and Lipschitz-bounded Spectral Unlearning Objective, balancing erasure fidelity and intersection preservation, that admits a stable and unique analytical solution. This solution defines a dissociation operator that is translated to the model's text-conditioning layers, making the edit permanent and runtime-free. Across targeted removals of artistic styles, objects, identities, and explicit content, ICE efficiently achieves strong erasure with improved robustness to red-teaming, all while causing only minimal degradation of original generative abilities in both T2I and T2V models.

</details>


### [167] [Beyond Description: Cognitively Benchmarking Fine-Grained Action for Embodied Agents](https://arxiv.org/abs/2511.18685)
*Dayong Liu,Chao Xu,Weihong Chen,Suyu Zhang,Juncheng Wang,Jiankang Deng,Baigui Sun,Yang Liu*

Main category: cs.CV

TL;DR: CFG-Bench是一个新的基准测试，旨在系统评估多模态大语言模型在具身物理交互中的细粒度动作智能，包含1,368个视频和19,562个多模态问答对，涵盖四个认知维度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注高级规划或空间推理，而忽视了具身物理交互所需的细粒度动作智能，因此需要专门的基准来评估这一关键能力。

Method: 构建了CFG-Bench基准，包含四个认知维度：物理交互、时间因果关系、意图理解和评估判断，通过监督微调验证数据有效性。

Result: 评估发现领先的MLLMs在生成物理交互详细指令方面表现不佳，在意图和评估等高级推理方面存在显著限制。在CFG-Bench数据上进行监督微调能显著提升在现有具身基准上的性能。

Conclusion: 研究揭示了当前MLLMs在具身物理交互中的局限性，为开发更强大和接地气的具身智能体提供了重要见解。

Abstract: Multimodal Large Language Models (MLLMs) show promising results as decision-making engines for embodied agents operating in complex, physical environments. However, existing benchmarks often prioritize high-level planning or spatial reasoning, leaving the fine-grained action intelligence required for embodied physical interaction underexplored. To address this gap, we introduce CFG-Bench, a new benchmark designed to systematically evaluate this crucial capability. CFG-Bench consists of 1,368 curated videos paired with 19,562 three-modalities question-answer pairs targeting four cognitive abilities: 1) Physical Interaction, 2) Temporal-Causal Relation, 3) Intentional Understanding, and 4) Evaluative Judgment. Together, these dimensions provide a systematic framework for assessing a model's ability to translate visual observations into actionable knowledge, moving beyond mere surface-level recognition. Our comprehensive evaluation on CFG-Bench reveals that leading MLLMs struggle to produce detailed instructions for physical interactions and exhibit profound limitations in the higher-order reasoning of intention and evaluation. Moreover, supervised fine-tuning (SFT) on our data demonstrates that teaching an MLLMs to articulate fine-grained actions directly translates to significant performance gains on established embodied benchmarks. Our analysis highlights these limitations and offers insights for developing more capable and grounded embodied agents.

</details>


### [168] [EVCC: Enhanced Vision Transformer-ConvNeXt-CoAtNet Fusion for Classification](https://arxiv.org/abs/2511.18691)
*Kazi Reyazul Hasan,Md Nafiu Rahman,Wasif Jalal,Sadif Ahmed,Shahriar Raj,Mubasshira Musarrat,Muhammad Abdullah Adnan*

Main category: cs.CV

TL;DR: EVCC是一种新型混合视觉架构，结合了Vision Transformer、轻量级ConvNeXt和CoAtNet，通过自适应令牌剪枝、门控双向交叉注意力、辅助分类头和动态路由门等创新技术，在多个数据集上实现了最先进的准确率，同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的混合视觉架构虽然提升了图像分类性能，但通常伴随着高昂的计算成本。EVCC旨在通过创新的多分支架构设计，在保持高准确率的同时显著降低计算复杂度。

Method: EVCC集成了Vision Transformer、轻量级ConvNeXt和CoAtNet，采用自适应令牌剪枝保留信息、门控双向交叉注意力增强特征细化、辅助分类头进行多任务学习，以及动态路由门实现上下文感知的置信度驱动加权。

Result: 在CIFAR-100、Tobacco3482、CelebA和Brain Cancer数据集上的实验表明，EVCC相比DeiT-Base、MaxViT-Base和CrossViT-Base等强大模型，准确率提升高达2个百分点，同时FLOPs减少25-35%。

Conclusion: EVCC通过自适应调整计算需求，动态减少令牌数量，有效平衡了准确率与效率的权衡，结合全局上下文、局部细节和层次特征，为实际应用提供了高效的解决方案。

Abstract: Hybrid vision architectures combining Transformers and CNNs have significantly advanced image classification, but they usually do so at significant computational cost. We introduce EVCC (Enhanced Vision Transformer-ConvNeXt-CoAtNet), a novel multi-branch architecture integrating the Vision Transformer, lightweight ConvNeXt, and CoAtNet through key innovations: (1) adaptive token pruning with information preservation, (2) gated bidirectional cross-attention for enhanced feature refinement, (3) auxiliary classification heads for multi-task learning, and (4) a dynamic router gate employing context-aware confidence-driven weighting. Experiments across the CIFAR-100, Tobacco3482, CelebA, and Brain Cancer datasets demonstrate EVCC's superiority over powerful models like DeiT-Base, MaxViT-Base, and CrossViT-Base by consistently achieving state-of-the-art accuracy with improvements of up to 2 percentage points, while reducing FLOPs by 25 to 35%. Our adaptive architecture adjusts computational demands to deployment needs by dynamically reducing token count, efficiently balancing the accuracy-efficiency trade-off while combining global context, local details, and hierarchical features for real-world applications. The source code of our implementation is available at https://anonymous.4open.science/r/EVCC.

</details>


### [169] [Life-IQA: Boosting Blind Image Quality Assessment through GCN-enhanced Layer Interaction and MoE-based Feature Decoupling](https://arxiv.org/abs/2511.19024)
*Long Tang,Guoquan Zhen,Jie Hao,Jianbo Zhang,Huiyu Duan,Liang Yuan,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了一种名为Life-IQA的盲图像质量评估方法，通过GCN增强的层间交互和MoE特征解耦来改进质量特征解码框架。


<details>
  <summary>Details</summary>
Motivation: 现有BIQA方法在融合浅层和深层特征时忽视了它们对质量预测的不平等贡献，且质量解码架构研究不足。

Method: 使用GCN增强的最深层特征作为查询，次深层特征作为键值，进行交叉注意力实现特征交互；提出基于MoE的特征解耦模块，通过专门处理不同失真类型或质量维度的专家来解耦融合表示。

Result: 在多个BIQA基准测试中，Life-IQA在准确性和成本之间表现出更优的平衡，并达到最先进的性能。

Conclusion: Life-IQA通过创新的层间交互和特征解耦机制，有效提升了盲图像质量评估的性能和效率。

Abstract: Blind image quality assessment (BIQA) plays a crucial role in evaluating and optimizing visual experience. Most existing BIQA approaches fuse shallow and deep features extracted from backbone networks, while overlooking the unequal contributions to quality prediction. Moreover, while various vision encoder backbones are widely adopted in BIQA, the effective quality decoding architectures remain underexplored. To address these limitations, this paper investigates the contributions of shallow and deep features to BIQA, and proposes a effective quality feature decoding framework via GCN-enhanced \underline{l}ayer\underline{i}nteraction and MoE-based \underline{f}eature d\underline{e}coupling, termed \textbf{(Life-IQA)}. Specifically, the GCN-enhanced layer interaction module utilizes the GCN-enhanced deepest-layer features as query and the penultimate-layer features as key, value, then performs cross-attention to achieve feature interaction. Moreover, a MoE-based feature decoupling module is proposed to decouple fused representations though different experts specialized for specific distortion types or quality dimensions. Extensive experiments demonstrate that Life-IQA shows more favorable balance between accuracy and cost than a vanilla Transformer decoder and achieves state-of-the-art performance on multiple BIQA benchmarks.The code is available at: \href{https://github.com/TANGLONG2/Life-IQA/tree/main}{\texttt{Life-IQA}}.

</details>


### [170] [Exploring Surround-View Fisheye Camera 3D Object Detection](https://arxiv.org/abs/2511.18695)
*Changcai Li,Wenwei Lin,Zuoxun Hou,Gang Chen,Wei Zhang,Huihui Zhou,Weishi Zheng*

Main category: cs.CV

TL;DR: 本文研究了在环视鱼眼相机系统中实现端到端3D目标检测的技术可行性，提出了两种兼容鱼眼几何的方法FisheyeBEVDet和FisheyePETR，并发布了Fisheye3DOD数据集，实验显示改进方法比基线准确率提升6.2%。


<details>
  <summary>Details</summary>
Motivation: 探索在环视鱼眼相机系统中实现端到端3D目标检测的技术可行性，解决传统针孔相机模型3D检测器在鱼眼图像上性能下降的问题。

Method: 开发了两种方法：基于鸟瞰图范式的FisheyeBEVDet和基于查询范式的FisheyePETR，两者都采用球面空间表示来有效捕捉鱼眼几何特性。

Result: 在发布的Fisheye3DOD数据集上实验表明，鱼眼兼容建模比基线方法准确率提升高达6.2%。

Conclusion: 通过引入球面空间表示来建模鱼眼几何，可以有效提升环视鱼眼相机系统的3D目标检测性能。

Abstract: In this work, we explore the technical feasibility of implementing end-to-end 3D object detection (3DOD) with surround-view fisheye camera system. Specifically, we first investigate the performance drop incurred when transferring classic pinhole-based 3D object detectors to fisheye imagery. To mitigate this, we then develop two methods that incorporate the unique geometry of fisheye images into mainstream detection frameworks: one based on the bird's-eye-view (BEV) paradigm, named FisheyeBEVDet, and the other on the query-based paradigm, named FisheyePETR. Both methods adopt spherical spatial representations to effectively capture fisheye geometry. In light of the lack of dedicated evaluation benchmarks, we release Fisheye3DOD, a new open dataset synthesized using CARLA and featuring both standard pinhole and fisheye camera arrays. Experiments on Fisheye3DOD show that our fisheye-compatible modeling improves accuracy by up to 6.2% over baseline methods.

</details>


### [171] [MedSAM3: Delving into Segment Anything with Medical Concepts](https://arxiv.org/abs/2511.19046)
*Anglin Liu,Rundong Xue,Xu R. Cao,Yifan Shen,Yi Lu,Xiang Li,Qianqian Chen,Jintai Chen*

Main category: cs.CV

TL;DR: MedSAM-3是基于SAM 3架构的文本提示医学分割模型，通过医学图像与语义概念标签的微调，实现开放词汇文本描述的精确解剖结构分割，并集成多模态大语言模型进行复杂推理和迭代优化。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法缺乏泛化性，需要大量耗时的手动标注来适应新的临床应用。

Method: 在医学图像和语义概念标签对上微调SAM 3架构，实现医学提示概念分割；引入MedSAM-3 Agent框架，集成多模态大语言模型进行复杂推理和迭代优化。

Result: 在X光、MRI、超声、CT和视频等多种医学成像模态上的综合实验表明，该方法显著优于现有的专业和基础模型。

Conclusion: MedSAM-3为医学图像和视频分割提供了有效的文本提示分割解决方案，具有优异的性能和泛化能力。

Abstract: Medical image segmentation is fundamental for biomedical discovery. Existing methods lack generalizability and demand extensive, time-consuming manual annotation for new clinical application. Here, we propose MedSAM-3, a text promptable medical segmentation model for medical image and video segmentation. By fine-tuning the Segment Anything Model (SAM) 3 architecture on medical images paired with semantic conceptual labels, our MedSAM-3 enables medical Promptable Concept Segmentation (PCS), allowing precise targeting of anatomical structures via open-vocabulary text descriptions rather than solely geometric prompts. We further introduce the MedSAM-3 Agent, a framework that integrates Multimodal Large Language Models (MLLMs) to perform complex reasoning and iterative refinement in an agent-in-the-loop workflow. Comprehensive experiments across diverse medical imaging modalities, including X-ray, MRI, Ultrasound, CT, and video, demonstrate that our approach significantly outperforms existing specialist and foundation models. We will release our code and model at https://github.com/Joey-S-Liu/MedSAM3.

</details>


### [172] [Understanding, Accelerating, and Improving MeanFlow Training](https://arxiv.org/abs/2511.19065)
*Jin-Young Kim,Hyojun Go,Lea Bogensperger,Julius Erbach,Nikolai Kalischek,Federico Tombari,Konrad Schindler,Dominik Narnhofer*

Main category: cs.CV

TL;DR: MeanFlow通过联合学习瞬时和平均速度场实现少步高质量生成，但训练动态不明确。研究发现：瞬时速度是学习平均速度的前提；小时间间隔时平均速度有助于瞬时速度学习，大间隔则有害；准确的大间隔平均速度学习依赖于先形成准确的瞬时和小间隔平均速度。基于此设计了改进训练方案，显著提升了少步生成性能。


<details>
  <summary>Details</summary>
Motivation: 分析MeanFlow中瞬时速度和平均速度之间的相互作用机制，理解其训练动态，以改进训练效率和生成质量。

Method: 通过分析两种速度场的相互作用关系，设计分阶段训练策略：先加速形成瞬时速度，然后从短间隔到长间隔逐步学习平均速度。

Result: 改进的MeanFlow训练在DiT-XL骨干上达到1-NFE ImageNet 256x256的FID 2.87，优于基线3.43；或可用2.5倍更短训练时间达到基线性能，或用更小的DiT-L骨干达到相同性能。

Conclusion: 理解瞬时和平均速度的相互作用对优化MeanFlow训练至关重要，提出的分阶段训练策略能显著提升收敛速度和少步生成质量。

Abstract: MeanFlow promises high-quality generative modeling in few steps, by jointly learning instantaneous and average velocity fields. Yet, the underlying training dynamics remain unclear. We analyze the interaction between the two velocities and find: (i) well-established instantaneous velocity is a prerequisite for learning average velocity; (ii) learning of instantaneous velocity benefits from average velocity when the temporal gap is small, but degrades as the gap increases; and (iii) task-affinity analysis indicates that smooth learning of large-gap average velocities, essential for one-step generation, depends on the prior formation of accurate instantaneous and small-gap average velocities. Guided by these observations, we design an effective training scheme that accelerates the formation of instantaneous velocity, then shifts emphasis from short- to long-interval average velocity. Our enhanced MeanFlow training yields faster convergence and significantly better few-step generation: With the same DiT-XL backbone, our method reaches an impressive FID of 2.87 on 1-NFE ImageNet 256x256, compared to 3.43 for the conventional MeanFlow baseline. Alternatively, our method matches the performance of the MeanFlow baseline with 2.5x shorter training time, or with a smaller DiT-L backbone.

</details>


### [173] [CoD: A Diffusion Foundation Model for Image Compression](https://arxiv.org/abs/2511.18706)
*Zhaoyang Jia,Zihan Zheng,Naifu Xue,Jiahao Li,Bin Li,Zongyu Guo,Xiaoyi Zhang,Houqiang Li,Yan Lu*

Main category: cs.CV

TL;DR: CoD是首个专为压缩设计的扩散基础模型，通过端到端优化压缩和生成，在超低码率下实现SOTA压缩性能，训练成本比Stable Diffusion低300倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本到图像扩散模型的编解码器在压缩视角下存在次优问题，限制了扩散编解码器在超低码率下的潜力。

Method: 从零开始训练压缩导向的扩散基础模型CoD，支持端到端优化压缩和生成，采用纯图像数据集进行高效训练。

Result: 在超低码率下(如0.0039 bpp)实现SOTA性能，像素空间扩散能达到VTM级PSNR并保持高感知质量，参数效率优于GAN基编解码器。

Conclusion: CoD为未来扩散编解码器研究奠定了基础，证明了压缩导向扩散模型的可行性和优势。

Abstract: Existing diffusion codecs typically build on text-to-image diffusion foundation models like Stable Diffusion. However, text conditioning is suboptimal from a compression perspective, hindering the potential of downstream diffusion codecs, particularly at ultra-low bitrates. To address it, we introduce \textbf{CoD}, the first \textbf{Co}mpression-oriented \textbf{D}iffusion foundation model, trained from scratch to enable end-to-end optimization of both compression and generation. CoD is not a fixed codec but a general foundation model designed for various diffusion-based codecs. It offers several advantages: \textbf{High compression efficiency}, replacing Stable Diffusion with CoD in downstream codecs like DiffC achieves SOTA results, especially at ultra-low bitrates (e.g., 0.0039 bpp); \textbf{Low-cost and reproducible training}, 300$\times$ faster training than Stable Diffusion ($\sim$ 20 vs. $\sim$ 6,250 A100 GPU days) on entirely open image-only datasets; \textbf{Providing new insights}, e.g., We find pixel-space diffusion can achieve VTM-level PSNR with high perceptual quality and can outperform GAN-based codecs using fewer parameters. We hope CoD lays the foundation for future diffusion codec research. Codes will be released.

</details>


### [174] [DynaMix: Generalizable Person Re-identification via Dynamic Relabeling and Mixed Data Sampling](https://arxiv.org/abs/2511.19067)
*Timur Mamedov,Anton Konushin,Vadim Konushin*

Main category: cs.CV

TL;DR: DynaMix是一种新的可泛化行人重识别方法，通过动态结合标记的多摄像头数据和大规模伪标记的单摄像头数据，在三个核心模块的协同作用下实现高效训练和优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖有限的标记多摄像头数据，而DynaMix旨在有效结合手动标记的多摄像头数据和大规模伪标记的单摄像头数据，以提升模型在未见摄像头和环境下的泛化能力。

Method: DynaMix包含三个核心组件：(1) 重标记模块：动态优化单摄像头身份的伪标签；(2) 高效质心模块：在大身份空间下保持稳健的身份表示；(3) 数据采样模块：精心组合混合数据小批量以平衡学习复杂度和批内多样性。

Result: 广泛实验表明，DynaMix在可泛化行人重识别任务中持续优于最先进的方法。

Conclusion: DynaMix通过动态适应训练数据的结构和噪声，在百万级图像和数十万身份的大规模数据上实现高效训练，为可泛化行人重识别提供了有效的解决方案。

Abstract: Generalizable person re-identification (Re-ID) aims to recognize individuals across unseen cameras and environments. While existing methods rely heavily on limited labeled multi-camera data, we propose DynaMix, a novel method that effectively combines manually labeled multi-camera and large-scale pseudo-labeled single-camera data. Unlike prior works, DynaMix dynamically adapts to the structure and noise of the training data through three core components: (1) a Relabeling Module that refines pseudo-labels of single-camera identities on-the-fly; (2) an Efficient Centroids Module that maintains robust identity representations under a large identity space; and (3) a Data Sampling Module that carefully composes mixed data mini-batches to balance learning complexity and intra-batch diversity. All components are specifically designed to operate efficiently at scale, enabling effective training on millions of images and hundreds of thousands of identities. Extensive experiments demonstrate that DynaMix consistently outperforms state-of-the-art methods in generalizable person Re-ID.

</details>


### [175] [DriveFlow: Rectified Flow Adaptation for Robust 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2511.18713)
*Hongbin Lin,Yiming Yang,Chaoda Zheng,Yifan Zhang,Shuaicheng Niu,Zilu Guo,Yafeng Li,Gui Gui,Shuguang Cui,Zhen Li*

Main category: cs.CV

TL;DR: DriveFlow提出了一种基于预训练文本到图像流模型的训练数据增强方法，通过频率分解策略解决自动驾驶中3D物体检测的分布外问题，保持准确的3D几何结构。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中视觉中心的3D物体检测面临标注成本高和室外场景多样化的挑战，导致训练数据无法覆盖所有测试场景，存在分布外问题。训练免费的图像编辑方法通过数据增强提高模型鲁棒性，但现有方法存在效果有限或无法保持准确3D几何的问题。

Method: 基于频率分解，DriveFlow引入两种策略来适应文本条件速度导出的无噪声编辑路径：1）高频前景保持：通过高频对齐损失保持精确的3D物体几何；2）双频背景优化：平衡编辑灵活性和语义一致性。

Result: 综合实验验证了DriveFlow的有效性和效率，在所有分布外场景的类别上都表现出全面的性能提升。

Conclusion: DriveFlow为自动驾驶中的训练数据增强提供了一种有效的解决方案，能够在保持3D几何准确性的同时提高模型在分布外场景下的鲁棒性。

Abstract: In autonomous driving, vision-centric 3D object detection recognizes and localizes 3D objects from RGB images. However, due to high annotation costs and diverse outdoor scenes, training data often fails to cover all possible test scenarios, known as the out-of-distribution (OOD) issue. Training-free image editing offers a promising solution for improving model robustness by training data enhancement without any modifications to pre-trained diffusion models. Nevertheless, inversion-based methods often suffer from limited effectiveness and inherent inaccuracies, while recent rectified-flow-based approaches struggle to preserve objects with accurate 3D geometry. In this paper, we propose DriveFlow, a Rectified Flow Adaptation method for training data enhancement in autonomous driving based on pre-trained Text-to-Image flow models. Based on frequency decomposition, DriveFlow introduces two strategies to adapt noise-free editing paths derived from text-conditioned velocities. 1) High-Frequency Foreground Preservation: DriveFlow incorporates a high-frequency alignment loss for foreground to maintain precise 3D object geometry. 2) Dual-Frequency Background Optimization: DriveFlow also conducts dual-frequency optimization for background, balancing editing flexibility and semantic consistency. Comprehensive experiments validate the effectiveness and efficiency of DriveFlow, demonstrating comprehensive performance improvements on all categories across OOD scenarios. Code is available at https://github.com/Hongbin98/DriveFlow.

</details>


### [176] [Seeing What Matters: Visual Preference Policy Optimization for Visual Generation](https://arxiv.org/abs/2511.18719)
*Ziqi Ni,Yuanzhi Liang,Rui Li,Yi Zhou,Haibing Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: ViPO是一种改进的GRPO方法，通过将标量奖励提升为结构化像素级优势，利用预训练视觉骨干构建空间和时间感知的优势图，在图像和视频生成任务中优于传统GRPO方法。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法使用单一样本标量奖励，忽略了视觉内容的空间和时间结构，这种粗粒度监督阻碍了局部伪影的修正和细粒度感知线索的建模。

Method: 引入视觉偏好策略优化(ViPO)，通过感知结构化模块使用预训练视觉骨干构建空间和时间感知的优势图，将优化压力重新分配到感知重要区域，同时保持标准GRPO的稳定性。

Result: 在图像和视频基准测试中，ViPO始终优于传统GRPO，在域内对齐人类偏好奖励方面有所改进，并在域外评估中增强了泛化能力。

Conclusion: ViPO是一种架构无关、轻量级且与现有GRPO训练管道完全兼容的方法，为视觉生成提供了更具表达性和信息性的学习信号。

Abstract: Reinforcement learning (RL) has become a powerful tool for post-training visual generative models, with Group Relative Policy Optimization (GRPO) increasingly used to align generators with human preferences. However, existing GRPO pipelines rely on a single scalar reward per sample, treating each image or video as a holistic entity and ignoring the rich spatial and temporal structure of visual content. This coarse supervision hinders the correction of localized artifacts and the modeling of fine-grained perceptual cues. We introduce Visual Preference Policy Optimization (ViPO), a GRPO variant that lifts scalar feedback into structured, pixel-level advantages. ViPO employs a Perceptual Structuring Module that uses pretrained vision backbones to construct spatially and temporally aware advantage maps, redistributing optimization pressure toward perceptually important regions while preserving the stability of standard GRPO. Across both image and video benchmarks, ViPO consistently outperforms vanilla GRPO, improving in-domain alignment with human-preference rewards and enhancing generalization on out-of-domain evaluations. The method is architecture-agnostic, lightweight, and fully compatible with existing GRPO training pipelines, providing a more expressive and informative learning signal for visual generation.

</details>


### [177] [GuideFlow: Constraint-Guided Flow Matching for Planning in End-to-End Autonomous Driving](https://arxiv.org/abs/2511.18729)
*Lin Liu,Caiyan Jia,Guanyi Yu,Ziying Song,JunQiao Li,Feiyang Jia,Peiliang Wu,Xiaoshuai Hao,Yandan Luo*

Main category: cs.CV

TL;DR: GuideFlow是一个基于约束流匹配的新型自动驾驶规划框架，解决了现有模仿式端到端规划器的多模态轨迹模式崩溃问题，以及生成式规划器难以直接融入安全约束的问题。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶规划器存在两个主要问题：模仿式规划器容易发生多模态轨迹模式崩溃，无法产生多样化的轨迹建议；生成式规划器难以在生成过程中直接融入关键的安全和物理约束，需要额外的优化阶段来精炼输出。

Method: GuideFlow利用约束流匹配技术，显式建模流匹配过程，直接在执行流匹配生成过程中强制执行显式约束，而不是依赖隐式约束编码。关键创新是将流匹配训练与基于能量的模型统一，增强模型自主优化能力以鲁棒地满足物理约束。同时参数化驾驶攻击性作为生成过程中的控制信号。

Result: 在主要驾驶基准测试（Bench2Drive、NuScenes、NavSim和ADV-NuScenes）上的广泛评估验证了GuideFlow的有效性。在NavSim测试困难分割（Navhard）上，GuideFlow实现了最先进水平，EPDMS得分为43.0。

Conclusion: GuideFlow通过约束流匹配框架成功解决了端到端自动驾驶规划中的多模态轨迹生成和约束满足问题，在多个基准测试中表现出色，为自动驾驶规划提供了有效的解决方案。

Abstract: Driving planning is a critical component of end-to-end (E2E) autonomous driving. However, prevailing Imitative E2E Planners often suffer from multimodal trajectory mode collapse, failing to produce diverse trajectory proposals. Meanwhile, Generative E2E Planners struggle to incorporate crucial safety and physical constraints directly into the generative process, necessitating an additional optimization stage to refine their outputs. In this paper, we propose \textit{\textbf{GuideFlow}}, a novel planning framework that leverages Constrained Flow Matching. Concretely, \textit{\textbf{GuideFlow}} explicitly models the flow matching process, which inherently mitigates mode collapse and allows for flexible guidance from various conditioning signals. Our core contribution lies in directly enforcing explicit constraints within the flow matching generation process, rather than relying on implicit constraint encoding. Crucially, \textit{\textbf{GuideFlow}} unifies the training of the flow matching with the Energy-Based Model (EBM) to enhance the model's autonomous optimization capability to robustly satisfy physical constraints. Secondly, \textit{\textbf{GuideFlow}} parameterizes driving aggressiveness as a control signal during generation, enabling precise manipulation of trajectory style. Extensive evaluations on major driving benchmarks (Bench2Drive, NuScenes, NavSim and ADV-NuScenes) validate the effectiveness of \textit{\textbf{GuideFlow}}. Notably, on the NavSim test hard split (Navhard), \textit{\textbf{GuideFlow}} achieved SOTA with an EPDMS score of 43.0. The code will be released.

</details>


### [178] [From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation](https://arxiv.org/abs/2511.19149)
*Moazzam Umer Gondal,Hamad Ul Qudous,Daniya Siddiqui,Asma Ahmad Farhan*

Main category: cs.CV

TL;DR: 本文提出了一个检索增强的自动时尚图片标题和标签生成框架，结合多服装检测、属性推理和大型语言模型提示，以生成视觉基础、描述性和风格有趣的文本。


<details>
  <summary>Details</summary>
Motivation: 克服端到端标题生成器在属性保真度和领域泛化方面的问题，为时尚图像生成更准确、更具描述性的文本内容。

Method: 使用YOLO检测器进行多服装定位，k-means聚类提取主色调，CLIP-FAISS检索模块基于结构化产品索引推断面料和性别属性，结合检索到的风格示例创建事实证据包来指导LLM生成标题和标签。

Result: YOLO检测器在9个服装类别上获得0.71的mAP@0.5；RAG-LLM管道生成表达性属性对齐的标题，在标签生成中达到0.80的平均属性覆盖率；相比BLIP基线模型具有更好的事实基础和更少的幻觉。

Conclusion: 检索增强生成作为自动化和视觉基础时尚内容生成的有效且可解释的范式，在多种服装领域具有可扩展部署的巨大潜力。

Abstract: This paper introduces the retrieval-augmented framework for automatic fashion caption and hashtag generation, combining multi-garment detection, attribute reasoning, and Large Language Model (LLM) prompting. The system aims to produce visually grounded, descriptive, and stylistically interesting text for fashion imagery, overcoming the limitations of end-to-end captioners that have problems with attribute fidelity and domain generalization. The pipeline combines a YOLO-based detector for multi-garment localization, k-means clustering for dominant color extraction, and a CLIP-FAISS retrieval module for fabric and gender attribute inference based on a structured product index. These attributes, together with retrieved style examples, create a factual evidence pack that is used to guide an LLM to generate human-like captions and contextually rich hashtags. A fine-tuned BLIP model is used as a supervised baseline model for comparison. Experimental results show that the YOLO detector is able to obtain a mean Average Precision (mAP@0.5) of 0.71 for nine categories of garments. The RAG-LLM pipeline generates expressive attribute-aligned captions and achieves mean attribute coverage of 0.80 with full coverage at the 50% threshold in hashtag generation, whereas BLIP gives higher lexical overlap and lower generalization. The retrieval-augmented approach exhibits better factual grounding, less hallucination, and great potential for scalable deployment in various clothing domains. These results demonstrate the use of retrieval-augmented generation as an effective and interpretable paradigm for automated and visually grounded fashion content generation.

</details>


### [179] [CLASH: A Benchmark for Cross-Modal Contradiction Detection](https://arxiv.org/abs/2511.19199)
*Teodora Popordanoska,Jiameng Li,Matthew B. Blaschko*

Main category: cs.CV

TL;DR: CLASH是一个用于多模态矛盾检测的新基准，包含COCO图像与包含对象级或属性级矛盾的矛盾标题配对，通过多选和开放式问题评估模型识别跨模态冲突的能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中存在大量矛盾的多模态输入，但现有基准假设输入一致性，无法评估跨模态矛盾检测这一防止幻觉和确保可靠性的基本能力。

Method: 引入CLASH基准，包含COCO图像与矛盾标题配对，提供经过自动质量检查的广泛微调集和较小的人工验证诊断集，评估模型在多种格式下的表现。

Result: 对最先进模型的分析显示其在识别跨模态冲突方面存在显著局限性，暴露了系统性的模态偏见和类别特定弱点。

Conclusion: 针对CLASH的定向微调显著增强了冲突检测能力，证明了该基准的有效性和实用性。

Abstract: Contradictory multimodal inputs are common in real-world settings, yet existing benchmarks typically assume input consistency and fail to evaluate cross-modal contradiction detection - a fundamental capability for preventing hallucinations and ensuring reliability. We introduce CLASH, a novel benchmark for multimodal contradiction detection, featuring COCO images paired with contradictory captions containing controlled object-level or attribute-level contradictions. The samples include targeted questions evaluated in both multiple-choice and open-ended formats. The benchmark provides an extensive fine-tuning set filtered through automated quality checks, alongside a smaller human-verified diagnostic set. Our analysis of state-of-the-art models reveals substantial limitations in recognizing cross-modal conflicts, exposing systematic modality biases and category-specific weaknesses. Furthermore, we empirically demonstrate that targeted fine-tuning on CLASH substantially enhances conflict detection capabilities.

</details>


### [180] [Are Large Vision Language Models Truly Grounded in Medical Images? Evidence from Italian Clinical Visual Question Answering](https://arxiv.org/abs/2511.19220)
*Federico Felizzi,Olivia Riccomi,Michele Ferramola,Francesco Andrea Causio,Manuel Del Medico,Vittorio De Vita,Lorenzo De Mori,Alessandra Piscitelli Pietro Eric Risuleo,Bianca Destro Castaniti,Antonio Cristiano Alessia Longo,Luigi De Angelis,Mariapia Vassalli,Marcello Di Pumpo*

Main category: cs.CV

TL;DR: 研究评估了四种前沿视觉语言模型在意大利医学问答中的视觉依赖程度，发现GPT-4o对视觉信息依赖最强，而其他模型更多依赖文本捷径。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医学视觉问答基准上表现出色，但其对视觉信息的真实依赖程度尚不明确，需要验证模型是否真正整合视觉和文本信息。

Method: 使用欧洲医学问答意大利数据集的60个明确需要图像解释的问题，将正确的医学图像替换为空白占位符，测试模型在有无视觉信息时的表现差异。

Result: GPT-4o视觉依赖最强，准确率下降27.9个百分点（从83.2%降至55.3%），而GPT-5-mini、Gemini和Claude仅分别下降8.5、2.4和5.6个百分点，模型生成的推理显示所有模型都会为虚构的视觉解释提供自信的解释。

Conclusion: 不同模型在视觉依赖程度上存在显著差异，凸显了模型鲁棒性的关键差异以及在临床部署前需要进行严格评估的必要性。

Abstract: Large vision language models (VLMs) have achieved impressive performance on medical visual question answering benchmarks, yet their reliance on visual information remains unclear. We investigate whether frontier VLMs demonstrate genuine visual grounding when answering Italian medical questions by testing four state-of-the-art models: Claude Sonnet 4.5, GPT-4o, GPT-5-mini, and Gemini 2.0 flash exp. Using 60 questions from the EuropeMedQA Italian dataset that explicitly require image interpretation, we substitute correct medical images with blank placeholders to test whether models truly integrate visual and textual information. Our results reveal striking variability in visual dependency: GPT-4o shows the strongest visual grounding with a 27.9pp accuracy drop (83.2% [74.6%, 91.7%] to 55.3% [44.1%, 66.6%]), while GPT-5-mini, Gemini, and Claude maintain high accuracy with modest drops of 8.5pp, 2.4pp, and 5.6pp respectively. Analysis of model-generated reasoning reveals confident explanations for fabricated visual interpretations across all models, suggesting varying degrees of reliance on textual shortcuts versus genuine visual analysis. These findings highlight critical differences in model robustness and the need for rigorous evaluation before clinical deployment.

</details>


### [181] [Learning Plug-and-play Memory for Guiding Video Diffusion Models](https://arxiv.org/abs/2511.19229)
*Selena Song,Ziming Xu,Zijun Zhang,Kun Zhou,Jiaxian Guo,Lianhui Qin,Biwei Huang*

Main category: cs.CV

TL;DR: 本文提出DiT-Mem方法，通过可学习的记忆编码器为扩散Transformer视频生成模型注入世界知识，改善物理规则遵循和视频保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的DiT视频生成模型虽然视觉质量和时间连贯性良好，但经常违反基本物理定律和常识动态，缺乏明确的世界知识。

Method: 提出DiT-Mem记忆编码器，使用堆叠3D CNN、低通/高通滤波器和自注意力层将参考视频映射为紧凑记忆标记，在DiT自注意力层中作为记忆连接。训练时冻结扩散主干，仅优化记忆编码器。

Result: 方法在少量训练参数(150M)和10K数据样本上实现高效训练，推理时可即插即用，显著提升物理规则遵循和视频保真度。

Conclusion: DiT-Mem通过记忆注入机制有效增强了视频生成模型的世界知识理解能力，在保持模型效率的同时改善了生成质量。

Abstract: Diffusion Transformer(DiT) based video generation models have recently achieved impressive visual quality and temporal coherence, but they still frequently violate basic physical laws and commonsense dynamics, revealing a lack of explicit world knowledge. In this work, we explore how to equip them with a plug-and-play memory that injects useful world knowledge. Motivated by in-context memory in Transformer-based LLMs, we conduct empirical studies to show that DiT can be steered via interventions on its hidden states, and simple low-pass and high-pass filters in the embedding space naturally disentangle low-level appearance and high-level physical/semantic cues, enabling targeted guidance. Building on these observations, we propose a learnable memory encoder DiT-Mem, composed of stacked 3D CNNs, low-/high-pass filters, and self-attention layers. The encoder maps reference videos into a compact set of memory tokens, which are concatenated as the memory within the DiT self-attention layers. During training, we keep the diffusion backbone frozen, and only optimize the memory encoder. It yields a rather efficient training process on few training parameters (150M) and 10K data samples, and enables plug-and-play usage at inference time. Extensive experiments on state-of-the-art models demonstrate the effectiveness of our method in improving physical rule following and video fidelity. Our code and data are publicly released here: https://thrcle421.github.io/DiT-Mem-Web/.

</details>


### [182] [VAOT: Vessel-Aware Optimal Transport for Retinal Fundus Enhancement](https://arxiv.org/abs/2511.18763)
*Xuanzhao Dong,Wenhui Zhu,Yujian Xiong,Xiwen Chen,Hao Wang,Xin Li,Jiajun Cheng,Zhipeng Wang,Shao Tang,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: 提出VAOT框架，结合最优传输目标和两个结构保持正则化器，用于彩色眼底图像增强，在保持血管结构的同时减少噪声。


<details>
  <summary>Details</summary>
Motivation: 彩色眼底摄影在视网膜疾病诊断中至关重要，但采集变异性会降低图像质量。现有的GAN增强方法会扭曲临床关键的血管结构，改变血管拓扑和端点完整性。

Method: VAOT框架结合最优传输目标与两个结构保持正则化器：基于骨架的损失以保持全局血管连通性，端点感知损失以稳定局部端点。

Result: 在合成退化基准测试和下游血管及病变分割评估中，该方法优于多个最先进的基线方法。

Conclusion: VAOT框架在无配对设置中有效减少噪声同时保持血管结构，在临床应用中具有优势。

Abstract: Color fundus photography (CFP) is central to diagnosing and monitoring retinal disease, yet its acquisition variability (e.g., illumination changes) often degrades image quality, which motivates robust enhancement methods. Unpaired enhancement pipelines are typically GAN-based, however, they can distort clinically critical vasculature, altering vessel topology and endpoint integrity. Motivated by these structural alterations, we propose Vessel-Aware Optimal Transport (\textbf{VAOT}), a framework that combines an optimal-transport objective with two structure-preserving regularizers: (i) a skeleton-based loss to maintain global vascular connectivity and (ii) an endpoint-aware loss to stabilize local termini. These constraints guide learning in the unpaired setting, reducing noise while preserving vessel structure. Experimental results on synthetic degradation benchmark and downstream evaluations in vessel and lesion segmentation demonstrate the superiority of the proposed methods against several state-of-the art baselines. The code is available at https://github.com/Retinal-Research/VAOT

</details>


### [183] [NI-Tex: Non-isometric Image-based Garment Texture Generation](https://arxiv.org/abs/2511.18765)
*Hui Shan,Ming Li,Haitao Yang,Kai Zheng,Sizhe Zheng,Yanwei Fu,Xiangru Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种针对非等距图像-几何对的3D服装纹理生成方法，通过构建3D服装视频数据集和使用Nano Banana进行高质量图像编辑，实现了跨姿态的纹理学习，最终生成可用于工业级3D服装设计的PBR材质。


<details>
  <summary>Details</summary>
Motivation: 现有工业3D服装网格已经覆盖了大多数真实世界的服装几何形状，但其纹理多样性仍然有限。传统方法需要严格的拓扑一致性或准确的网格变形，这严重限制了纹理生成的质量和灵活性。

Method: 构建3D服装视频数据集进行物理模拟，使用Nano Banana进行高质量非等距图像编辑，提出基于不确定性引导视图选择和重新加权的迭代烘焙方法，融合多视图预测生成无缝的PBR纹理。

Result: 通过广泛实验证明，该前馈双分支架构能够生成适用于工业级3D服装设计的多样化且空间对齐的PBR材质。

Conclusion: 该方法成功解决了非等距图像基服装纹理生成的挑战性问题，实现了跨拓扑的可靠纹理生成，为工业级3D服装设计提供了有效的解决方案。

Abstract: Existing industrial 3D garment meshes already cover most real-world clothing geometries, yet their texture diversity remains limited. To acquire more realistic textures, generative methods are often used to extract Physically-based Rendering (PBR) textures and materials from large collections of wild images and project them back onto garment meshes. However, most image-conditioned texture generation approaches require strict topological consistency between the input image and the input 3D mesh, or rely on accurate mesh deformation to match to the image poses, which significantly constrains the texture generation quality and flexibility. To address the challenging problem of non-isometric image-based garment texture generation, we construct 3D Garment Videos, a physically simulated, garment-centric dataset that provides consistent geometry and material supervision across diverse deformations, enabling robust cross-pose texture learning. We further employ Nano Banana for high-quality non-isometric image editing, achieving reliable cross-topology texture generation between non-isometric image-geometry pairs. Finally, we propose an iterative baking method via uncertainty-guided view selection and reweighting that fuses multi-view predictions into seamless, production-ready PBR textures. Through extensive experiments, we demonstrate that our feedforward dual-branch architecture generates versatile and spatially aligned PBR materials suitable for industry-level 3D garment design.

</details>


### [184] [Adversarial Patch Attacks on Vision-Based Cargo Occupancy Estimation via Differentiable 3D Simulation](https://arxiv.org/abs/2511.19254)
*Mohamed Rissal Hedna,Sesugh Samuel Nder*

Main category: cs.CV

TL;DR: 本研究探讨了在物流系统中针对货物占用率分类器的物理对抗攻击可行性，通过3D模拟环境优化对抗补丁纹理，在DoS攻击场景中达到84.94%的成功率。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉系统在现代物流操作中广泛应用，但可能面临物理对抗攻击的威胁，特别是可打印并放置在内部表面的对抗补丁。

Method: 使用Mitsuba 3进行可微分渲染，在几何、光照和视点变化下优化补丁纹理，并与2D合成基线进行比较。

Result: 3D优化补丁在DoS攻击场景（空到满）中达到84.94%的成功率，隐蔽攻击（满到空）达到30.32%的成功率。

Conclusion: 这是首个在物理真实、完全模拟的3D场景中研究货物占用率估计对抗补丁攻击的研究，强调了自动化物流管道安全性的重要性。

Abstract: Computer vision systems are increasingly adopted in modern logistics operations, including the estimation of trailer occupancy for planning, routing, and billing. Although effective, such systems may be vulnerable to physical adversarial attacks, particularly adversarial patches that can be printed and placed on interior surfaces. In this work, we study the feasibility of such attacks on a convolutional cargo-occupancy classifier using fully simulated 3D environments. Using Mitsuba 3 for differentiable rendering, we optimize patch textures across variations in geometry, lighting, and viewpoint, and compare their effectiveness to a 2D compositing baseline. Our experiments demonstrate that 3D-optimized patches achieve high attack success rates, especially in a denial-of-service scenario (empty to full), where success reaches 84.94 percent. Concealment attacks (full to empty) prove more challenging but still reach 30.32 percent. We analyze the factors influencing attack success, discuss implications for the security of automated logistics pipelines, and highlight directions for strengthening physical robustness. To our knowledge, this is the first study to investigate adversarial patch attacks for cargo-occupancy estimation in physically realistic, fully simulated 3D scenes.

</details>


### [185] [STCDiT: Spatio-Temporally Consistent Diffusion Transformer for High-Quality Video Super-Resolution](https://arxiv.org/abs/2511.18786)
*Junyang Chen,Jiangxin Dong,Long Sun,Yixin Yang,Jinshan Pan*

Main category: cs.CV

TL;DR: STCDiT是一个基于预训练视频扩散模型的视频超分辨率框架，通过运动感知VAE重建和锚帧引导方法，在复杂相机运动下恢复结构保真和时间稳定的视频。


<details>
  <summary>Details</summary>
Motivation: 解决视频超分辨率中保持时间稳定性和结构保真度的挑战，特别是在复杂相机运动场景下。

Method: 1. 运动感知VAE重建：对具有统一运动特征的片段进行分段重建；2. 锚帧引导：利用VAE编码器提取的首帧潜在表示（锚帧潜在）来约束生成过程，提高结构保真度。

Result: 大量实验表明，STCDiT在结构保真度和时间一致性方面优于现有最先进方法。

Conclusion: 结合运动感知VAE重建和锚帧引导的视频扩散模型能够实现高质量的视频超分辨率，在复杂相机运动下表现出色。

Abstract: We present STCDiT, a video super-resolution framework built upon a pre-trained video diffusion model, aiming to restore structurally faithful and temporally stable videos from degraded inputs, even under complex camera motions. The main challenges lie in maintaining temporal stability during reconstruction and preserving structural fidelity during generation. To address these challenges, we first develop a motion-aware VAE reconstruction method that performs segment-wise reconstruction, with each segment clip exhibiting uniform motion characteristic, thereby effectively handling videos with complex camera motions. Moreover, we observe that the first-frame latent extracted by the VAE encoder in each clip, termed the anchor-frame latent, remains unaffected by temporal compression and retains richer spatial structural information than subsequent frame latents. We further develop an anchor-frame guidance approach that leverages structural information from anchor frames to constrain the generation process and improve structural fidelity of video features. Coupling these two designs enables the video diffusion model to achieve high-quality video super-resolution. Extensive experiments show that STCDiT outperforms state-of-the-art methods in terms of structural fidelity and temporal consistency.

</details>


### [186] [Understanding Task Transfer in Vision-Language Models](https://arxiv.org/abs/2511.18787)
*Bhuvan Sachdeva,Karan Uppal,Abhinav Java,Vineeth N. Balasubramanian*

Main category: cs.CV

TL;DR: 本文通过系统研究任务可转移性，提出了Perfection Gap Factor (PGF)指标来量化视觉语言模型在感知任务间的迁移效果，揭示了任务间的正负迁移模式。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在多模态基准测试中表现良好，但在深度估计、物体计数等视觉感知任务上落后于人类和专用模型。针对一个任务的微调可能会不可预测地影响其他任务的性能，这使得任务特定微调具有挑战性。

Method: 通过微调三个开源视觉语言模型并在13个感知任务上进行零样本评估，引入PGF指标来捕捉迁移的广度和幅度，构建任务转移图来揭示感知任务间的关系。

Result: 发现了正负迁移模式，识别了相互影响的任务组，根据迁移行为将任务组织为不同角色，并展示了PGF如何指导更高效训练的数据选择。

Conclusion: 这些发现突出了正迁移的机会和负干扰的风险，为推进视觉语言模型的发展提供了可操作的指导。

Abstract: Vision-Language Models (VLMs) perform well on multimodal benchmarks but lag behind humans and specialized models on visual perception tasks like depth estimation or object counting. Finetuning on one task can unpredictably affect performance on others, making task-specific finetuning challenging. In this paper, we address this challenge through a systematic study of task transferability. We examine how finetuning a VLM on one perception task affects its zero-shot performance on others. To quantify these effects, we introduce Perfection Gap Factor (PGF), a metric that captures both the breadth and magnitude of transfer. Using three open-weight VLMs evaluated across 13 perception tasks, we construct a task-transfer graph that reveals previously unobserved relationships among perception tasks. Our analysis uncovers patterns of positive and negative transfer, identifies groups of tasks that mutually influence each other, organizes tasks into personas based on their transfer behavior and demonstrates how PGF can guide data selection for more efficient training. These findings highlight both opportunities for positive transfer and risks of negative interference, offering actionable guidance for advancing VLMs.

</details>


### [187] [Evaluating Dataset Watermarking for Fine-tuning Traceability of Customized Diffusion Models: A Comprehensive Benchmark and Removal Approach](https://arxiv.org/abs/2511.19316)
*Xincheng Wang,Hanchi Sun,Wenjun Sun,Kejun Xue,Wangqiu Zhou,Jianbo Zhang,Wei Sun,Dandan Zhu,Xiongkuo Min,Jun Jia,Zhijun Fang*

Main category: cs.CV

TL;DR: 本文建立了扩散模型数据集水印的统一评估框架，发现现有方法在通用性和可传递性方面表现良好，但在真实威胁场景下存在脆弱性，并提出了一种实用的水印移除方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型微调技术虽然能复现特定图像集，但也带来了版权和安全风险。现有数据集水印方法缺乏统一的评估框架，无法全面评估其有效性。

Method: 建立了通用威胁模型，提出了包含通用性、可传递性和鲁棒性的综合评估框架，并通过实验验证现有方法的性能。

Result: 实验显示现有方法在通用性和可传递性方面表现良好，对常见图像处理操作具有一定鲁棒性，但在真实威胁场景下仍存在不足。

Conclusion: 现有数据集水印方法在实际应用中存在脆弱性，提出的水印移除方法揭示了这一关键挑战，为未来研究指明了方向。

Abstract: Recent fine-tuning techniques for diffusion models enable them to reproduce specific image sets, such as particular faces or artistic styles, but also introduce copyright and security risks. Dataset watermarking has been proposed to ensure traceability by embedding imperceptible watermarks into training images, which remain detectable in outputs even after fine-tuning. However, current methods lack a unified evaluation framework. To address this, this paper establishes a general threat model and introduces a comprehensive evaluation framework encompassing Universality, Transmissibility, and Robustness. Experiments show that existing methods perform well in universality and transmissibility, and exhibit some robustness against common image processing operations, yet still fall short under real-world threat scenarios. To reveal these vulnerabilities, the paper further proposes a practical watermark removal method that fully eliminates dataset watermarks without affecting fine-tuning, highlighting a key challenge for future research.

</details>


### [188] [StereoDETR: Stereo-based Transformer for 3D Object Detection](https://arxiv.org/abs/2511.18788)
*Shiyi Mu,Zichong Gu,Zhiqi Ai,Anqi Liu,Yilin Gao,Shugong Xu*

Main category: cs.CV

TL;DR: StereoDETR是一个基于DETR的高效立体3D目标检测框架，包含单目DETR分支和立体分支，通过可微分深度采样策略耦合，实现实时推理并超越单目方法的速度，在KITTI基准测试中取得竞争性精度。


<details>
  <summary>Details</summary>
Motivation: 立体3D目标检测相比单目方法精度更高，但存在计算开销大和延迟高的问题。现有最佳立体方法精度是单目方法的两倍，但推理速度只有单目方法的一半。

Method: StereoDETR包含两个分支：单目DETR分支（基于2D DETR，增加预测物体尺度、方向和采样点的通道）和立体分支（利用低成本多尺度视差特征预测物体级深度图）。两个分支通过可微分深度采样策略耦合，并引入约束监督策略处理遮挡问题。

Result: StereoDETR实现实时推理，是首个在速度上超越单目方法的立体方法。在公开KITTI基准测试中取得竞争性精度，在行人和骑行者子集上创下新的最先进结果。

Conclusion: StereoDETR框架成功解决了立体3D检测的高计算开销问题，在保持高精度的同时实现了实时性能，为立体视觉在自动驾驶等实时应用中的部署提供了可行方案。

Abstract: Compared to monocular 3D object detection, stereo-based 3D methods offer significantly higher accuracy but still suffer from high computational overhead and latency. The state-of-the-art stereo 3D detection method achieves twice the accuracy of monocular approaches, yet its inference speed is only half as fast. In this paper, we propose StereoDETR, an efficient stereo 3D object detection framework based on DETR. StereoDETR consists of two branches: a monocular DETR branch and a stereo branch. The DETR branch is built upon 2D DETR with additional channels for predicting object scale, orientation, and sampling points. The stereo branch leverages low-cost multi-scale disparity features to predict object-level depth maps. These two branches are coupled solely through a differentiable depth sampling strategy. To handle occlusion, we introduce a constrained supervision strategy for sampling points without requiring extra annotations. StereoDETR achieves real-time inference and is the first stereo-based method to surpass monocular approaches in speed. It also achieves competitive accuracy on the public KITTI benchmark, setting new state-of-the-art results on pedestrian and cyclist subsets. The code is available at https://github.com/shiyi-mu/StereoDETR-OPEN.

</details>


### [189] [Scale What Counts, Mask What Matters: Evaluating Foundation Models for Zero-Shot Cross-Domain Wi-Fi Sensing](https://arxiv.org/abs/2511.18792)
*Cheng Jiang,Yihe Yan,Yanxiang Wang,Chun Tung Chou,Wen Hu*

Main category: cs.CV

TL;DR: 该研究通过大规模Wi-Fi CSI数据集上的掩码自编码预训练，探索了数据多样性与模型容量对跨域Wi-Fi感知性能的影响，发现数据规模和多样性是领域泛化的关键，而模型容量在当前数据量下仅带来边际收益。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi感知虽然提供了隐私保护的替代方案，但缺乏跨域鲁棒性限制了其实际应用。模型在不同环境、硬件或用户间的泛化能力差，现有数据集规模小且分散。

Method: 采用基础模型方法，在迄今为止最大、最多样化的Wi-Fi CSI数据集集合上进行掩码自编码预训练，涵盖14个数据集、130万样本、4种设备、2.4/5/6 GHz频段和20-160 MHz带宽。

Result: 实验显示：1）随着预训练数据增加，未见域性能呈对数线性改善；2）在当前数据量下，更大模型仅带来边际收益；3）大规模预训练在人类活动识别、手势识别和用户识别任务上比监督学习基线提升2.2%至15.7%的跨域准确率。

Conclusion: 数据而非模型容量是当前Wi-Fi感知泛化的瓶颈，研究结果为设计最终能够在现实世界中稳健部署的Wi-Fi感知系统提供了有见地的方向。

Abstract: While Wi-Fi sensing offers a compelling, privacy-preserving alternative to cameras, its practical utility has been fundamentally undermined by a lack of robustness across domains. Models trained in one setup fail to generalize to new environments, hardware, or users, a critical "domain shift" problem exacerbated by modest, fragmented public datasets. We shift from this limited paradigm and apply a foundation model approach, leveraging Masked Autoencoding (MAE) style pretraining on the largest and most heterogeneous Wi-Fi CSI datasets collection assembled to date. Our study pretrains and evaluates models on over 1.3 million samples extracted from 14 datasets, collected using 4 distinct devices across the 2.4/5/6 GHz bands and bandwidths from 20 to 160 MHz. Our large-scale evaluation is the first to systematically disentangle the impacts of data diversity versus model capacity on cross-domain performance. The results establish scaling trends on Wi-Fi CSI sensing. First, our experiments show log-linear improvements in unseen domain performance as the amount of pretraining data increases, suggesting that data scale and diversity are key to domain generalization. Second, based on the current data volume, larger model can only provide marginal gains for cross-domain performance, indicating that data, rather than model capacity, is the current bottleneck for Wi-Fi sensing generalization. Finally, we conduct a series of cross-domain evaluations on human activity recognition, human gesture recognition and user identification tasks. The results show that the large-scale pretraining improves cross-domain accuracy ranging from 2.2% to 15.7%, compared to the supervised learning baseline. Overall, our findings provide insightful direction for designing future Wi-Fi sensing systems that can eventually be robust enough for real-world deployment.

</details>


### [190] [PartDiffuser: Part-wise 3D Mesh Generation via Discrete Diffusion](https://arxiv.org/abs/2511.18801)
*Yichen Yang,Hong Li,Haodong Zhu,Linin Yang,Guojun Lei,Sheng Xu,Baochang Zhang*

Main category: cs.CV

TL;DR: PartDiffuser是一个半自回归扩散框架，通过语义分割将网格分解为部件，在部件间使用自回归确保全局拓扑，在部件内使用并行离散扩散过程重建高频几何特征，有效平衡全局结构和局部细节。


<details>
  <summary>Details</summary>
Motivation: 现有自回归方法在生成艺术家设计的网格时难以平衡全局结构一致性和高保真局部细节，且容易产生误差累积问题。

Method: 基于DiT架构，采用语义分割将网格分解为部件，在部件间使用自回归确保全局拓扑，在部件内使用并行离散扩散过程重建细节，引入部件感知交叉注意力机制，以点云作为分层几何条件动态控制生成过程。

Result: 实验表明该方法在生成具有丰富细节的3D网格方面显著优于现有最先进模型，展现出适合实际应用的卓越细节表示能力。

Conclusion: PartDiffuser通过解耦全局和局部生成任务，有效解决了网格生成中全局结构与局部细节的平衡问题，为实际应用提供了高质量的3D网格生成方案。

Abstract: Existing autoregressive (AR) methods for generating artist-designed meshes struggle to balance global structural consistency with high-fidelity local details, and are susceptible to error accumulation. To address this, we propose PartDiffuser, a novel semi-autoregressive diffusion framework for point-cloud-to-mesh generation. The method first performs semantic segmentation on the mesh and then operates in a "part-wise" manner: it employs autoregression between parts to ensure global topology, while utilizing a parallel discrete diffusion process within each semantic part to precisely reconstruct high-frequency geometric features. PartDiffuser is based on the DiT architecture and introduces a part-aware cross-attention mechanism, using point clouds as hierarchical geometric conditioning to dynamically control the generation process, thereby effectively decoupling the global and local generation tasks. Experiments demonstrate that this method significantly outperforms state-of-the-art (SOTA) models in generating 3D meshes with rich detail, exhibiting exceptional detail representation suitable for real-world applications.

</details>


### [191] [TPG-INR: Target Prior-Guided Implicit 3D CT Reconstruction for Enhanced Sparse-view Imaging](https://arxiv.org/abs/2511.18806)
*Qinglei Cao,Ziyao Tang,Xiaoqin Tang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的3D CT重建框架，利用从物体投影数据中提取的'目标先验'来增强隐式学习，显著提高了超稀疏视图场景下的重建精度和学习效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF的隐式3D重建方法往往忽略物体解剖先验的重要性，限制了重建精度和学习效率，特别是在超稀疏视图场景下。

Method: 提出了一种结合位置和结构编码的3D CT重建框架，利用目标先验指导体素采样并丰富结构编码，同时引入了基于CUDA的算法从稀疏视图投影中快速估计高质量3D目标先验。

Result: 在复杂腹部数据集上的实验表明，该模型学习效率比当前领先模型NAF提高了10倍，重建质量超过了最准确模型NeRP，在10、20、30个投影下PSNR分别提升了3.57 dB、5.42 dB和5.70 dB。

Conclusion: 所提出的目标先验增强隐式学习框架在超稀疏视图CT重建中显著提升了学习效率和重建质量，证明了解剖先验在隐式学习中的重要性。

Abstract: X-ray imaging, based on penetration, enables detailed visualization of internal structures. Building on this capability, existing implicit 3D reconstruction methods have adapted the NeRF model and its variants for internal CT reconstruction. However, these approaches often neglect the significance of objects' anatomical priors for implicit learning, limiting both reconstruction precision and learning efficiency, particularly in ultra-sparse view scenarios. To address these challenges, we propose a novel 3D CT reconstruction framework that employs a 'target prior' derived from the object's projection data to enhance implicit learning. Our approach integrates positional and structural encoding to facilitate voxel-wise implicit reconstruction, utilizing the target prior to guide voxel sampling and enrich structural encoding. This dual strategy significantly boosts both learning efficiency and reconstruction quality. Additionally, we introduce a CUDA-based algorithm for rapid estimation of high-quality 3D target priors from sparse-view projections. Experiments utilizing projection data from a complex abdominal dataset demonstrate that the proposed model substantially enhances learning efficiency, outperforming the current leading model, NAF, by a factor of ten. In terms of reconstruction quality, it also exceeds the most accurate model, NeRP, achieving PSNR improvements of 3.57 dB, 5.42 dB, and 5.70 dB with 10, 20, and 30 projections, respectively. The code is available at https://github.com/qlcao171/TPG-INR.

</details>


### [192] [DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation](https://arxiv.org/abs/2511.19365)
*Zehong Ma,Longhui Wei,Shuai Wang,Shiliang Zhang,Qi Tian*

Main category: cs.CV

TL;DR: DeCo提出了一种频率解耦的像素扩散框架，通过将高频细节和低频语义生成分离，使用轻量级像素解码器生成高频细节，让DiT专注于低频语义建模，显著提升了像素扩散模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有像素扩散模型在单一扩散变换器(DiT)中同时建模高频信号和低频语义，导致训练和推理速度缓慢。为了追求更高效的像素扩散范式，需要解耦高频和低频组件的生成。

Method: 提出频率解耦像素扩散框架：1) 使用轻量级像素解码器在DiT语义指导下生成高频细节；2) 让DiT专注于低频语义建模；3) 引入频率感知流匹配损失，强调视觉显著频率并抑制不显著频率。

Result: 在ImageNet上达到FID 1.62(256×256)和2.22(512×512)，在像素扩散模型中表现优异，缩小了与潜在扩散方法的差距。预训练的文本到图像模型在GenEval系统级比较中获得领先的0.86总分。

Conclusion: DeCo通过频率解耦策略有效提升了像素扩散模型的效率和性能，证明了将高频细节和低频语义分离建模的优越性，为像素扩散提供了新的高效范式。

Abstract: Pixel diffusion aims to generate images directly in pixel space in an end-to-end fashion. This approach avoids the limitations of VAE in the two-stage latent diffusion, offering higher model capacity. Existing pixel diffusion models suffer from slow training and inference, as they usually model both high-frequency signals and low-frequency semantics within a single diffusion transformer (DiT). To pursue a more efficient pixel diffusion paradigm, we propose the frequency-DeCoupled pixel diffusion framework. With the intuition to decouple the generation of high and low frequency components, we leverage a lightweight pixel decoder to generate high-frequency details conditioned on semantic guidance from the DiT. This thus frees the DiT to specialize in modeling low-frequency semantics. In addition, we introduce a frequency-aware flow-matching loss that emphasizes visually salient frequencies while suppressing insignificant ones. Extensive experiments show that DeCo achieves superior performance among pixel diffusion models, attaining FID of 1.62 (256x256) and 2.22 (512x512) on ImageNet, closing the gap with latent diffusion methods. Furthermore, our pretrained text-to-image model achieves a leading overall score of 0.86 on GenEval in system-level comparison. Codes are publicly available at https://github.com/Zehong-Ma/DeCo.

</details>


### [193] [DetAny4D: Detect Anything 4D Temporally in a Streaming RGB Video](https://arxiv.org/abs/2511.18814)
*Jiawei Hou,Shenghao Zhang,Can Wang,Zheng Gu,Yonggen Ling,Taiping Zeng,Xiangyang Xue,Jingbo Zhang*

Main category: cs.CV

TL;DR: 提出了DetAny4D，一个端到端的开放集4D物体检测框架，直接从序列输入预测3D边界框，解决了现有方法的时间不一致性和复杂流水线问题。


<details>
  <summary>Details</summary>
Motivation: 现有的4D物体检测方法要么逐帧预测缺乏时间一致性建模，要么依赖复杂的多阶段流水线容易产生错误传播，且缺乏大规模连续可靠3D边界框标注数据集。

Method: 首先构建DA4D大规模数据集，然后提出DetAny4D框架，融合预训练基础模型的多模态特征，设计几何感知的时空解码器捕获时空动态，采用多任务学习和专用训练策略保持序列一致性。

Result: 大量实验表明DetAny4D实现了有竞争力的检测精度，显著提高了时间稳定性，有效解决了4D物体检测中长期存在的抖动和不一致问题。

Conclusion: DetAny4D通过端到端框架和专用训练策略，在4D物体检测中实现了更好的时间一致性和检测性能，为可靠4D感知提供了有效解决方案。

Abstract: Reliable 4D object detection, which refers to 3D object detection in streaming video, is crucial for perceiving and understanding the real world. Existing open-set 4D object detection methods typically make predictions on a frame-by-frame basis without modeling temporal consistency, or rely on complex multi-stage pipelines that are prone to error propagation across cascaded stages. Progress in this area has been hindered by the lack of large-scale datasets that capture continuous reliable 3D bounding box (b-box) annotations. To overcome these challenges, we first introduce DA4D, a large-scale 4D detection dataset containing over 280k sequences with high-quality b-box annotations collected under diverse conditions. Building on DA4D, we propose DetAny4D, an open-set end-to-end framework that predicts 3D b-boxes directly from sequential inputs. DetAny4D fuses multi-modal features from pre-trained foundational models and designs a geometry-aware spatiotemporal decoder to effectively capture both spatial and temporal dynamics. Furthermore, it adopts a multi-task learning architecture coupled with a dedicated training strategy to maintain global consistency across sequences of varying lengths. Extensive experiments show that DetAny4D achieves competitive detection accuracy and significantly improves temporal stability, effectively addressing long-standing issues of jitter and inconsistency in 4D object detection. Data and code will be released upon acceptance.

</details>


### [194] [SupLID: Geometrical Guidance for Out-of-Distribution Detection in Semantic Segmentation](https://arxiv.org/abs/2511.18816)
*Nimeshika Udayangani,Sarah Erfani,Christopher Leckie*

Main category: cs.CV

TL;DR: SupLID是一个新颖的语义分割OOD检测框架，通过利用语义空间的几何结构（特别是线性内在维度LID）来指导基于分类器的OOD评分，解决了传统方法对过度自信的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于分类器置信度的像素级OOD检测方法存在局限性，包括对过度自信的脆弱性。需要利用语义空间的几何结构来增强OOD检测能力。

Method: SupLID构建几何核心集捕捉ID子空间的内在结构，在超像素级别计算OOD分数，实现高效实时推理和改善空间平滑度。作为后处理评分方法，可与任何语义分割分类器无缝集成。

Result: SupLID显著增强了现有基于分类器的OOD评分，在AUR、FPR和AUP等关键评估指标上达到了最先进的性能。

Conclusion: SupLID通过几何线索与传统分类器置信度的互补，有效提升了模型检测多样化OOD场景的能力，为语义分割中的OOD检测提供了有效的解决方案。

Abstract: Out-of-Distribution (OOD) detection in semantic segmentation aims to localize anomalous regions at the pixel level, advancing beyond traditional image-level OOD techniques to better suit real-world applications such as autonomous driving. Recent literature has successfully explored the adaptation of commonly used image-level OOD methods--primarily based on classifier-derived confidence scores (e.g., energy or entropy)--for this pixel-precise task. However, these methods inherit a set of limitations, including vulnerability to overconfidence. In this work, we introduce SupLID, a novel framework that effectively guides classifier-derived OOD scores by exploiting the geometrical structure of the underlying semantic space, particularly using Linear Intrinsic Dimensionality (LID). While LID effectively characterizes the local structure of high-dimensional data by analyzing distance distributions, its direct application at the pixel level remains challenging. To overcome this, SupLID constructs a geometrical coreset that captures the intrinsic structure of the in-distribution (ID) subspace. It then computes OOD scores at the superpixel level, enabling both efficient real-time inference and improved spatial smoothness. We demonstrate that geometrical cues derived from SupLID serve as a complementary signal to traditional classifier confidence, enhancing the model's ability to detect diverse OOD scenarios. Designed as a post-hoc scoring method, SupLID can be seamlessly integrated with any semantic segmentation classifier at deployment time. Our results demonstrate that SupLID significantly enhances existing classifier-based OOD scores, achieving state-of-the-art performance across key evaluation metrics, including AUR, FPR, and AUP. Code is available at https://github.com/hdnugit/SupLID.

</details>


### [195] [In-Video Instructions: Visual Signals as Generative Control](https://arxiv.org/abs/2511.19401)
*Gongfan Fang,Xinyin Ma,Xinchao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种称为"视频内指令"的新范式，通过将用户指导直接编码到视觉域中（如叠加文本、箭头或轨迹），实现可控的图像到视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模视频生成模型虽然具备强大的视觉能力，但主要依赖文本提示进行控制，这种全局且粗略的描述难以实现精确的空间感知控制。

Method: 利用视频生成模型将嵌入在帧中的视觉信号（如叠加文本、箭头、轨迹）解释为指令，实现对不同对象的精确空间控制。

Result: 在三个最先进的生成器（Veo 3.1、Kling 2.5、Wan 2.2）上的广泛实验表明，视频模型能够可靠地解释和执行这种视觉嵌入指令，特别是在复杂的多对象场景中。

Conclusion: 视频内指令提供了一种比文本提示更精确、空间感知且无歧义的控制方法，能够为不同对象分配不同的指令，实现更精细的可控视频生成。

Abstract: Large-scale video generative models have recently demonstrated strong visual capabilities, enabling the prediction of future frames that adhere to the logical and physical cues in the current observation. In this work, we investigate whether such capabilities can be harnessed for controllable image-to-video generation by interpreting visual signals embedded within the frames as instructions, a paradigm we term In-Video Instruction. In contrast to prompt-based control, which provides textual descriptions that are inherently global and coarse, In-Video Instruction encodes user guidance directly into the visual domain through elements such as overlaid text, arrows, or trajectories. This enables explicit, spatial-aware, and unambiguous correspondences between visual subjects and their intended actions by assigning distinct instructions to different objects. Extensive experiments on three state-of-the-art generators, including Veo 3.1, Kling 2.5, and Wan 2.2, show that video models can reliably interpret and execute such visually embedded instructions, particularly in complex multi-object scenarios.

</details>


### [196] [Disc3D: Automatic Curation of High-Quality 3D Dialog Data via Discriminative Object Referring](https://arxiv.org/abs/2511.18817)
*Siyuan Wei,Chunjie Wang,Xiao Liu,Xiaosheng Yan,Zhishan Zhou,Rui Huang*

Main category: cs.CV

TL;DR: 本文提出了一个全自动管道，将原始3D扫描转换为高质量、无歧义的对话数据，解决了3D多模态大语言模型数据稀缺的问题，生成了包含200万样本的Disc3D数据集。


<details>
  <summary>Details</summary>
Motivation: 3D多模态大语言模型性能落后于2D模型，主要因为缺乏大规模高质量的3D场景对话数据集，且现有方法依赖昂贵的人工标注，存在视角歧义和对象指代歧义问题。

Method: 开发了四阶段全自动管道：元标注收集、场景图构建与关系校正、判别性对象指代、多任务数据生成，结合基于规则的约束与2D MLLMs和LLMs，实现可控、可扩展的生成。

Result: 生成了Disc3D数据集，包含25K混合3D场景中的200多万样本，涵盖场景、视图和对象描述、视觉定位以及五个对象中心问答任务，实验显示在公共基准和Disc3D-QA任务上均取得显著改进。

Conclusion: 该自动化管道能够以低成本生成高质量3D对话数据，有效缓解源数据集的固有缺陷，显著提升3D MLLMs的性能，代码、数据和模型将公开。

Abstract: 3D Multi-modal Large Language Models (MLLMs) still lag behind their 2D peers, largely because large-scale, high-quality 3D scene-dialogue datasets remain scarce. Prior efforts hinge on expensive human annotation and leave two key ambiguities unresolved: viewpoint ambiguity, where spatial language presumes unknown camera poses, and object referring ambiguity, where non-exclusive descriptions blur the line between targets and distractors. We therefore present a fully automated pipeline that converts raw 3D scans into unambiguous, high-quality dialogue data at a fraction of the previous cost. By synergizing rule-based constraints with 2D MLLMs and LLMs, the pipeline enables controllable, scalable generation without human intervention. The pipeline comprises four stages: (1) meta-annotation collection harvesting object-, frame-, and scene-level captions, (2) scene graph construction with relation correction to capture proximal object relations, (3) discriminative object referring that generates exclusive and compact descriptions, and (4) multi-task data generation synthesizing diverse dialogues. Our pipeline systematically mitigates inherent flaws in source datasets and produces the final Disc3D dataset, over 2 million samples in 25K hybrid 3D scenes, spanning scene, view, and object captioning, visual grounding, and five object-centric QA tasks. Extensive experiments demonstrate that training with Disc3D yields consistent, significant improvements on both public benchmarks and our multifaceted Disc3D-QA tasks. Code, data, and models will be publicly available.

</details>


### [197] [DiP: Taming Diffusion Models in Pixel Space](https://arxiv.org/abs/2511.18822)
*Zhennan Chen,Junwei Zhu,Xu Chen,Jiangning Zhang,Xiaobin Hu,Hanzhen Zhao,Chengjie Wang,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: DiP是一种高效的像素空间扩散框架，通过解耦全局结构和局部细节生成，在不依赖VAE的情况下实现了与潜在扩散模型相当的效率。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在生成质量和计算效率之间的基本权衡问题，避免潜在扩散模型的信息损失和非端到端训练问题，同时克服现有像素空间模型在高分辨率合成中的计算瓶颈。

Method: 提出DiP框架，将生成过程解耦为全局和局部两个阶段：使用扩散变换器（DiT）在大块上构建全局结构，同时通过协同训练的轻量级补丁细节头利用上下文特征恢复局部细节。

Result: DiP实现了与潜在扩散模型相当的计算效率，推理速度比先前方法快10倍，仅增加0.3%的参数总量，在ImageNet 256×256上达到1.90 FID分数。

Conclusion: DiP通过全局-局部解耦的协同设计，成功解决了扩散模型的质量-效率权衡问题，为高效像素空间扩散模型提供了可行方案。

Abstract: Diffusion models face a fundamental trade-off between generation quality and computational efficiency. Latent Diffusion Models (LDMs) offer an efficient solution but suffer from potential information loss and non-end-to-end training. In contrast, existing pixel space models bypass VAEs but are computationally prohibitive for high-resolution synthesis. To resolve this dilemma, we propose DiP, an efficient pixel space diffusion framework. DiP decouples generation into a global and a local stage: a Diffusion Transformer (DiT) backbone operates on large patches for efficient global structure construction, while a co-trained lightweight Patch Detailer Head leverages contextual features to restore fine-grained local details. This synergistic design achieves computational efficiency comparable to LDMs without relying on a VAE. DiP is accomplished with up to 10$\times$ faster inference speeds than previous method while increasing the total number of parameters by only 0.3%, and achieves an 1.90 FID score on ImageNet 256$\times$256.

</details>


### [198] [Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens](https://arxiv.org/abs/2511.19418)
*Yiming Qin,Bomin Wei,Jiaxin Ge,Konstantinos Kallidromitis,Stephanie Fu,Trevor Darrell,Xudong Wang*

Main category: cs.CV

TL;DR: 提出Chain-of-Visual-Thought (COVT)框架，使视觉语言模型能够通过连续视觉令牌进行推理，解决当前模型在密集视觉感知方面的局限性，在多个基准测试中提升性能3%-16%。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在语言空间推理表现出色，但在需要密集视觉感知的任务（如空间推理和几何感知）上表现不佳，因为缺乏捕捉空间维度密集视觉信息的机制。

Method: 引入COVT框架，在约20个令牌的预算内从轻量级视觉专家中提取知识，捕捉2D外观、3D几何、空间布局和边缘结构等互补属性。训练时模型自回归预测视觉令牌来重建密集监督信号，推理时直接在连续视觉令牌空间进行推理。

Result: 在超过十个不同的感知基准测试中，将COVT集成到Qwen2.5-VL和LLaVA等强视觉语言模型中，性能一致提升3%到16%，证明紧凑的连续视觉思维能够实现更精确、更接地气、更可解释的多模态智能。

Conclusion: COVT框架通过引入连续视觉令牌推理，有效解决了视觉语言模型在密集视觉感知方面的局限性，显著提升了模型在多种感知任务上的性能，为实现更精确和可解释的多模态智能提供了新途径。

Abstract: Vision-Language Models (VLMs) excel at reasoning in linguistic space but struggle with perceptual understanding that requires dense visual perception, e.g., spatial reasoning and geometric awareness. This limitation stems from the fact that current VLMs have limited mechanisms to capture dense visual information across spatial dimensions. We introduce Chain-of-Visual-Thought (COVT), a framework that enables VLMs to reason not only in words but also through continuous visual tokens-compact latent representations that encode rich perceptual cues. Within a small budget of roughly 20 tokens, COVT distills knowledge from lightweight vision experts, capturing complementary properties such as 2D appearance, 3D geometry, spatial layout, and edge structure. During training, the VLM with COVT autoregressively predicts these visual tokens to reconstruct dense supervision signals (e.g., depth, segmentation, edges, and DINO features). At inference, the model reasons directly in the continuous visual token space, preserving efficiency while optionally decoding dense predictions for interpretability. Evaluated across more than ten diverse perception benchmarks, including CV-Bench, MMVP, RealWorldQA, MMStar, WorldMedQA, and HRBench, integrating COVT into strong VLMs such as Qwen2.5-VL and LLaVA consistently improves performance by 3% to 16% and demonstrates that compact continuous visual thinking enables more precise, grounded, and interpretable multimodal intelligence.

</details>


### [199] [VideoPerceiver: Enhancing Fine-Grained Temporal Perception in Video Multimodal Large Language Models](https://arxiv.org/abs/2511.18823)
*Fufangchen Zhao,Liao Zhang,Daiqi Shi,Yuanjun Gao,Chen Ye,Yang Cai,Jian Gao,Danfeng Yan*

Main category: cs.CV

TL;DR: VideoPerceiver是一个新颖的视频多模态大语言模型，通过两阶段训练框架增强视频理解中的细粒度感知能力，专门解决VMLLMs在短片段中推理短暂动作或长视频中罕见瞬态事件的能力有限的问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频多模态大语言模型在细粒度感知方面的局限性，特别是在理解短片段中的短暂动作和长视频中的罕见瞬态事件方面的不足。

Method: 采用两阶段训练框架：1）监督微调阶段，通过构建'关键信息缺失'视频，联合编码原始和修改后的视频token与文本token，使用辅助对比损失对齐中间视觉表示与关键词；2）强化学习阶段，输入两种视频变体生成描述，使用新颖的相对奖励机制确保完整视频的响应优于降级输入。

Result: 实验表明VideoPerceiver在细粒度动作理解和罕见事件描述基准上显著优于最先进的VMLLMs，同时在标准任务上保持强大性能。

Conclusion: 通过优先处理任务相关的视觉特征，该工作重新定义了视频语言模型的细粒度感知训练方法。

Abstract: We propose VideoPerceiver, a novel video multimodal large language model (VMLLM) that enhances fine-grained perception in video understanding, addressing VMLLMs' limited ability to reason about brief actions in short clips or rare transient events in long videos. VideoPerceiver adopts a two-stage training framework. During supervised fine-tuning (SFT), we construct "key-information-missing" videos by extracting event-action keywords from captions, identifying corresponding key frames, and replacing them with adjacent frames. We jointly encode original and modified video tokens with text tokens, aligning intermediate visual representations with keywords via an auxiliary contrastive loss to enhance sensitivity to fine-grained motion cues. In reinforcement learning (RL), both video variants are fed into the model to generate descriptions, and a novel relative reward ensures responses from complete videos outperform those from degraded inputs, explicitly training the model to recover temporally precise action details. We also curate a dataset of 80,000 videos with fine-grained actions and transient events. Experiments show VideoPerceiver substantially outperforms state-of-the-art VMLLMs on fine-grained action understanding and rare event captioning benchmarks, while maintaining strong performance on standard tasks. By prioritizing task-relevant visual features, our work redefines video-language model training for fine-grained perception.

</details>


### [200] [Assessing the alignment between infants' visual and linguistic experience using multimodal language models](https://arxiv.org/abs/2511.18824)
*Alvin Wei Ming Tan,Jane Yang,Tarun Sepuri,Khai Loong Aw,Robert Z. Sparks,Zi Yin,Virginia A. Marchman,Michael C. Frank,Bria Long*

Main category: cs.CV

TL;DR: 使用CLIP模型自动分析婴儿视角视频中的视觉-语言对齐情况，发现理想化的学习对齐时刻在儿童日常体验中相对罕见。


<details>
  <summary>Details</summary>
Motivation: 研究儿童语言学习过程中视觉和语言体验的时间对齐程度，传统方法依赖人工标注，需要更高效的自动化分析工具。

Method: 使用对比性语言-图像预训练(CLIP)模型来自动化分析婴儿视角视频中的视觉-语言对齐，并通过人工判断验证CLIP对齐分数的有效性。

Result: 理想化的学习对齐时刻（如"看球"时球在儿童视野中）在儿童日常体验中相对罕见，且在不同儿童之间和同一儿童内部都存在变异性。

Conclusion: 不频繁的对齐是早期词汇学习模型的约束条件，该方法为研究儿童多模态环境提供了新工具。

Abstract: Figuring out which objects or concepts words refer to is a central language learning challenge for young children. Most models of this process posit that children learn early object labels from co-occurrences of words and their referents that occur when someone around them talks about an object in the immediate physical environment. But how aligned in time are children's visual and linguistic experiences during everyday learning? To date, answers to this question have been limited by the need for labor-intensive manual annotations of vision-language co-occurrences. Here, we evaluate the use of contrastive language-image pretraining (CLIP) models to automatically characterize vision-language alignment in egocentric videos taken from the infant perspective in home environments. After validating CLIP alignment scores using human alignment judgments, we apply this metric to a large corpus of infant-perspective videos. We show that idealized aligned moments for learning (e.g., "look at the ball" with a ball present in the child's view) are relatively rare in children's everyday experiences compared to modern machine learning datasets, and highlight variability in alignment both within and across children. These findings suggest that infrequent alignment is a constraint for models describing early word learning and offer a new method for investigating children's multimodal environment.

</details>


### [201] [Q-Save: Towards Scoring and Attribution for Generated Video Evaluation](https://arxiv.org/abs/2511.18825)
*Xiele Wu,Zicheng Zhang,Mingtao Chen,Yixian Liu,Yiming Liu,Shushi Wang,Zhichao Hu,Yuhong Liu,Guangtao Zhai,Xiaohong Liu*

Main category: cs.CV

TL;DR: Q-Save是一个用于AI生成视频质量评估的新基准数据集和模型，包含近10000个视频，提供MOS评分和三个维度的细粒度标注：视觉质量、动态质量和文本-视频对齐。模型采用SlowFast框架平衡评估精度和计算效率，通过多阶段训练策略实现最先进的视频质量预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成视频质量评估缺乏全面性和可解释性，需要能够同时进行准确质量评分和提供解释性理由的统一评估方法。

Method: 构建包含多维度标注的数据集；采用SlowFast框架区分快慢帧处理；使用CoT风格数据格式；实施三阶段训练策略：SFT→GRPO→SFT。

Result: 模型在视频质量预测方面达到最先进性能，同时提供与人类对齐的可解释性理由。

Conclusion: Q-Save为生成视频研究中的可解释评估建立了坚实基础，有助于多模态生成和可信AI的发展。

Abstract: We present Q-Save, a new benchmark dataset and model for holistic and explainable evaluation of AI-generated video (AIGV) quality. The dataset contains near 10000 videos, each annotated with a scalar mean opinion score (MOS) and fine-grained attribution labels along three core dimensions: visual quality, dynamic quality, and text-video alignment. These multi-aspect annotations enable both accurate quality assessment and interpretable reasoning behind the scores. To leverage this data, we propose a unified evaluation model that jointly performs quality scoring and attribution-based explanation. The model adopts the SlowFast framework to distinguish between fast frames and slow frames - slow frames are processed with high resolution while fast frames use low resolution, balancing evaluation accuracy and computational efficiency. For training, we use data formatted in Chain-of-Thought (COT) style and employ a multi-stage strategy: we first conduct Supervised Fine-Tuning (SFT), then further enhance the model with Grouped Relative Policy Optimization (GRPO), and finally perform SFT again to improve model stability. Experimental results demonstrate that our model achieves state-of-the-art performance in video quality prediction while also providing human-aligned, interpretable justifications. Our dataset and model establish a strong foundation for explainable evaluation in generative video research, contributing to the development of multimodal generation and trustworthy AI. Code and dataset will be released upon publication.

</details>


### [202] [Enhancing Multi-Label Thoracic Disease Diagnosis with Deep Ensemble-Based Uncertainty Quantification](https://arxiv.org/abs/2511.18839)
*Yasiru Laksara,Uthayasanker Thayasivam*

Main category: cs.CV

TL;DR: 该研究通过集成深度集成方法，在NIH ChestX-ray14数据集上为14种胸部疾病诊断提供了可靠的不确定性量化，显著改善了模型的校准性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在临床应用中缺乏可靠的不确定性量化，限制了其在高风险医疗环境中的实用性。

Method: 从蒙特卡洛Dropout转向高多样性的9成员深度集成方法，实现了总不确定性到数据噪声和模型知识不确定性的可靠分解。

Result: 深度集成方法实现了SOTA性能：平均AUROC 0.8559，平均F1分数0.3857，平均ECE 0.0728，NLL 0.1916，平均认知不确定性0.0240。

Conclusion: 深度集成方法将模型从概率工具转变为可靠的临床决策支持系统，提供了可信赖和可解释的诊断平台。

Abstract: The utility of deep learning models, such as CheXNet, in high stakes clinical settings is fundamentally constrained by their purely deterministic nature, failing to provide reliable measures of predictive confidence. This project addresses this critical gap by integrating robust Uncertainty Quantification (UQ) into a high performance diagnostic platform for 14 common thoracic diseases on the NIH ChestX-ray14 dataset. Initial architectural development failed to stabilize performance and calibration using Monte Carlo Dropout (MCD), yielding an unacceptable Expected Calibration Error (ECE) of 0.7588. This technical failure necessitated a rigorous architectural pivot to a high diversity, 9-member Deep Ensemble (DE). This resulting DE successfully stabilized performance and delivered superior reliability, achieving a State-of-the-Art (SOTA) average Area Under the Receiver Operating Characteristic Curve (AUROC) of 0.8559 and an average F1 Score of 0.3857. Crucially, the DE demonstrated superior calibration (Mean ECE of 0.0728 and Negative Log-Likelihood (NLL) of 0.1916) and enabled the reliable decomposition of total uncertainty into its Aleatoric (irreducible data noise) and Epistemic (reducible model knowledge) components, with a mean Epistemic Uncertainty (EU) of 0.0240. These results establish the Deep Ensemble as a trustworthy and explainable platform, transforming the model from a probabilistic tool into a reliable clinical decision support system.

</details>


### [203] [Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation through Motion Discretization](https://arxiv.org/abs/2511.18851)
*Yilin Wen,Kechuan Dong,Yusuke Sugano*

Main category: cs.CV

TL;DR: 本文提出了一种基于运动离散化的在线测试时适应方法来解决3D人体姿态估计中的误差累积问题，通过无监督聚类获得锚点运动，并引入软重置机制，在连续适应中提升性能。


<details>
  <summary>Details</summary>
Motivation: 在线测试时适应在3D人体姿态估计中面临误差累积的挑战，因为依赖不完美预测的自监督会导致性能随时间下降。

Method: 使用潜在运动表示空间的无监督聚类获得锚点运动，利用其规律性监督姿态估计器并实现高效自回放；引入软重置机制，在连续适应中将姿态估计器恢复到其指数移动平均值。

Result: 实验表明，该方法在长期在线适应中优于之前的在线测试时适应方法，能够有效利用个人形状和运动特征提升准确性。

Conclusion: 通过运动离散化和软重置机制，成功缓解了误差累积问题，实现了对个人特征的稳健利用，提升了3D人体姿态估计的在线适应性能。

Abstract: Online test-time adaptation addresses the train-test domain gap by adapting the model on unlabeled streaming test inputs before making the final prediction. However, online adaptation for 3D human pose estimation suffers from error accumulation when relying on self-supervision with imperfect predictions, leading to degraded performance over time. To mitigate this fundamental challenge, we propose a novel solution that highlights the use of motion discretization. Specifically, we employ unsupervised clustering in the latent motion representation space to derive a set of anchor motions, whose regularity aids in supervising the human pose estimator and enables efficient self-replay. Additionally, we introduce an effective and efficient soft-reset mechanism by reverting the pose estimator to its exponential moving average during continuous adaptation. We examine long-term online adaptation by continuously adapting to out-of-domain streaming test videos of the same individual, which allows for the capture of consistent personal shape and motion traits throughout the streaming observation. By mitigating error accumulation, our solution enables robust exploitation of these personal traits for enhanced accuracy. Experiments demonstrate that our solution outperforms previous online test-time adaptation methods and validate our design choices.

</details>


### [204] [Rethinking Long-tailed Dataset Distillation: A Uni-Level Framework with Unbiased Recovery and Relabeling](https://arxiv.org/abs/2511.18858)
*Xiao Cui,Yulei Qin,Xinyue Li,Wengang Zhou,Hongsheng Li,Houqiang Li*

Main category: cs.CV

TL;DR: 本文提出了一种针对长尾数据集蒸馏的新方法，通过统计对齐视角解决模型偏差和BN统计估计问题，在四个长尾基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法在平衡数据集上表现良好，但在长尾分布下表现不佳，因为类别不平衡会导致模型表示偏差和BN统计估计失真。

Method: 采用统计对齐视角，包含三个关键组件：增强专家模型用于可靠统计估计和软标签生成；通过动态调整动量的完整前向传播重新校准BN统计；通过多轮机制增量选择高置信度和多样化增强来初始化合成图像。

Result: 在四个长尾基准测试中表现一致优于最先进方法，在CIFAR-100-LT和Tiny-ImageNet-LT上分别提升15.6%和11.8%的top-1准确率。

Conclusion: 所提出的方法有效解决了长尾数据集蒸馏中的模型偏差和统计估计问题，显著提升了蒸馏性能。

Abstract: Dataset distillation creates a small distilled set that enables efficient training by capturing key information from the full dataset. While existing dataset distillation methods perform well on balanced datasets, they struggle under long-tailed distributions, where imbalanced class frequencies induce biased model representations and corrupt statistical estimates such as Batch Normalization (BN) statistics. In this paper, we rethink long-tailed dataset distillation by revisiting the limitations of trajectory-based methods, and instead adopt the statistical alignment perspective to jointly mitigate model bias and restore fair supervision. To this end, we introduce three dedicated components that enable unbiased recovery of distilled images and soft relabeling: (1) enhancing expert models (an observer model for recovery and a teacher model for relabeling) to enable reliable statistics estimation and soft-label generation; (2) recalibrating BN statistics via a full forward pass with dynamically adjusted momentum to reduce representation skew; (3) initializing synthetic images by incrementally selecting high-confidence and diverse augmentations via a multi-round mechanism that promotes coverage and diversity. Extensive experiments on four long-tailed benchmarks show consistent improvements over state-of-the-art methods across varying degrees of class imbalance.Notably, our approach improves top-1 accuracy by 15.6% on CIFAR-100-LT and 11.8% on Tiny-ImageNet-LT under IPC=10 and IF=10.

</details>


### [205] [DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient Object Detection](https://arxiv.org/abs/2511.18865)
*Yu Zhang,Haoan Ping,Yuchen Li,Zhenshan Bing,Fuchun Sun,Alois Knoll*

Main category: cs.CV

TL;DR: DualGazeNet是一个受生物学启发的纯Transformer框架，通过模拟人类视觉系统的双通路处理机制，在显著目标检测任务中实现了最先进的性能，同时显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有显著目标检测方法趋向复杂架构，导致特征冗余和性能瓶颈。作者受人类视觉系统高效识别显著目标的启发，希望设计一个既简单又高效的生物基础框架。

Method: 提出DualGazeNet框架，基于纯Transformer架构，模拟人类视觉系统的稳健表示学习和双通路处理机制，结合皮层注意力调制。

Result: 在五个RGB显著目标检测基准测试中，DualGazeNet超越了25种最先进的方法，推理速度比类似容量的Transformer基线快约60%，FLOPs减少53.4%，并在跨域任务中表现优异。

Conclusion: DualGazeNet证明了基于生物原理的简单架构可以在显著目标检测中实现最先进性能，同时保持计算效率和可解释性。

Abstract: Recent salient object detection (SOD) methods aim to improve performance in four key directions: semantic enhancement, boundary refinement, auxiliary task supervision, and multi-modal fusion. In pursuit of continuous gains, these approaches have evolved toward increasingly sophisticated architectures with multi-stage pipelines, specialized fusion modules, edge-guided learning, and elaborate attention mechanisms. However, this complexity paradoxically introduces feature redundancy and cross-component interference that obscure salient cues, ultimately reaching performance bottlenecks. In contrast, human vision achieves efficient salient object identification without such architectural complexity. This contrast raises a fundamental question: can we design a biologically grounded yet architecturally simple SOD framework that dispenses with most of this engineering complexity, while achieving state-of-the-art accuracy, computational efficiency, and interpretability? In this work, we answer this question affirmatively by introducing DualGazeNet, a biologically inspired pure Transformer framework that models the dual biological principles of robust representation learning and magnocellular-parvocellular dual-pathway processing with cortical attention modulation in the human visual system. Extensive experiments on five RGB SOD benchmarks show that DualGazeNet consistently surpasses 25 state-of-the-art CNN- and Transformer-based methods. On average, DualGazeNet achieves about 60\% higher inference speed and 53.4\% fewer FLOPs than four Transformer-based baselines of similar capacity (VST++, MDSAM, Sam2unet, and BiRefNet). Moreover, DualGazeNet exhibits strong cross-domain generalization, achieving leading or highly competitive performance on camouflaged and underwater SOD benchmarks without relying on additional modalities.

</details>


### [206] [Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction](https://arxiv.org/abs/2511.18873)
*Yiming Wang,Shaofei Wang,Marko Mihajlovic,Siyu Tang*

Main category: cs.CV

TL;DR: 本文提出Neural Texture Splatting (NTS)，通过引入全局神经场来增强3D高斯泼溅的表达能力，在多种重建任务中实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在表示能力上受限于3D高斯核，现有增强方法在通用重建场景中效果有限。本文旨在在广泛的稀疏和密集输入设置下，实现比现有3DGS变体更好的性能。

Method: 提出NTS方法，核心是使用三平面和神经解码器的混合全局神经场，为每个基元预测局部外观和几何场，通过共享全局表示减少模型大小并促进全局信息交换。

Result: 大量实验表明，NTS在多个基准测试中持续改进模型并达到最先进的结果，特别是在引入视图和时间依赖效果方面表现出色。

Conclusion: Neural Texture Splatting通过神经建模局部纹理场，显著增强了3D高斯泼溅的表达能力，在多种重建任务中实现了性能提升和更好的泛化能力。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading approach for high-quality novel view synthesis, with numerous variants extending its applicability to a broad spectrum of 3D and 4D scene reconstruction tasks. Despite its success, the representational capacity of 3DGS remains limited by the use of 3D Gaussian kernels to model local variations. Recent works have proposed to augment 3DGS with additional per-primitive capacity, such as per-splat textures, to enhance its expressiveness. However, these per-splat texture approaches primarily target dense novel view synthesis with a reduced number of Gaussian primitives, and their effectiveness tends to diminish when applied to more general reconstruction scenarios. In this paper, we aim to achieve concrete performance improvement over state-of-the-art 3DGS variants across a wide range of reconstruction tasks, including novel view synthesis, geometry and dynamic reconstruction, under both sparse and dense input settings. To this end, we introduce Neural Texture Splatting (NTS). At the core of our approach is a global neural field (represented as a hybrid of a tri-plane and a neural decoder) that predicts local appearance and geometric fields for each primitive. By leveraging this shared global representation that models local texture fields across primitives, we significantly reduce model size and facilitate efficient global information exchange, demonstrating strong generalization across tasks. Furthermore, our neural modeling of local texture fields introduces expressive view- and time-dependent effects, a critical aspect that existing methods fail to account for. Extensive experiments show that Neural Texture Splatting consistently improves models and achieves state-of-the-art results across multiple benchmarks.

</details>


### [207] [Facade Segmentation for Solar Photovoltaic Suitability](https://arxiv.org/abs/2511.18882)
*Ayca Duran,Christoph Waibel,Bernd Bickel,Iro Armeni,Arno Schlueter*

Main category: cs.CV

TL;DR: 本文提出了一种自动化管道，用于识别建筑立面光伏应用的合适表面并估算太阳能潜力，通过微调SegFormer-B5模型在CMP Facades数据集上，将语义预测转换为立面级光伏适用性掩码和光伏板布局。


<details>
  <summary>Details</summary>
Motivation: 建筑集成光伏立面是实现城市脱碳的有前景途径，特别是在屋顶面积不足且地面安装阵列不可行的情况下。虽然基于机器学习的屋顶光伏规划方法已有充分研究，但立面自动化方法仍然稀缺且过于简化。

Method: 开发了一个管道，整合建筑立面的详细建筑组成信息，自动识别适合光伏应用的表面并估算太阳能潜力。该管道在CMP Facades数据集上微调SegFormer-B5，并将语义预测转换为考虑模块尺寸和间隙的立面级光伏适用性掩码和光伏板布局。

Result: 在来自10个城市的373个已知尺寸立面的数据集上应用，结果显示可安装BIPV潜力显著低于理论潜力，为可靠的城市能源规划提供了宝贵见解。

Conclusion: 随着立面图像的日益可用性，所提出的管道可以扩展到支持全球城市的BIPV规划，为城市能源规划提供更可靠的潜力评估。

Abstract: Building integrated photovoltaic (BIPV) facades represent a promising pathway towards urban decarbonization, especially where roof areas are insufficient and ground-mounted arrays are infeasible. Although machine learning-based approaches to support photovoltaic (PV) planning on rooftops are well researched, automated approaches for facades still remain scarce and oversimplified. This paper therefore presents a pipeline that integrates detailed information on the architectural composition of the facade to automatically identify suitable surfaces for PV application and estimate the solar energy potential. The pipeline fine-tunes SegFormer-B5 on the CMP Facades dataset and converts semantic predictions into facade-level PV suitability masks and PV panel layouts considering module sizes and clearances. Applied to a dataset of 373 facades with known dimensions from ten cities, the results show that installable BIPV potential is significantly lower than theoretical potential, thus providing valuable insights for reliable urban energy planning. With the growing availability of facade imagery, the proposed pipeline can be scaled to support BIPV planning in cities worldwide.

</details>


### [208] [MagicWorld: Interactive Geometry-driven Video World Exploration](https://arxiv.org/abs/2511.18886)
*Guangyuan Li,Siming Zheng,Shuolin Xu,Jinwei Chen,Bo Li,Xiaobin Hu,Lei Zhao,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: MagicWorld是一个交互式视频世界模型，通过整合3D几何先验和历史检索机制，解决了现有方法在视角变化下结构不稳定和多步交互中历史信息遗忘的问题。


<details>
  <summary>Details</summary>
Motivation: 现有交互式视频世界模型存在两个关键限制：1）未能充分利用指令驱动场景运动与底层3D几何的对应关系，导致视角变化时结构不稳定；2）多步交互中容易遗忘历史信息，导致错误累积和场景语义结构漂移。

Method: 提出MagicWorld模型，包含两个核心组件：1）动作引导3D几何模块（AG3D），从每个交互的第一帧构建点云，为视角转换提供显式几何约束；2）历史缓存检索机制（HCR），在生成过程中检索相关历史帧作为条件信号，帮助模型利用过去场景信息。

Result: 实验结果表明，MagicWorld在交互迭代过程中显著提升了场景稳定性和连续性。

Conclusion: MagicWorld通过整合3D几何先验和历史检索机制，有效解决了交互式视频生成中的结构稳定性和历史信息保持问题，为构建更可靠的交互式视频世界模型提供了有效方案。

Abstract: Recent interactive video world model methods generate scene evolution conditioned on user instructions. Although they achieve impressive results, two key limitations remain. First, they fail to fully exploit the correspondence between instruction-driven scene motion and the underlying 3D geometry, which results in structural instability under viewpoint changes. Second, they easily forget historical information during multi-step interaction, resulting in error accumulation and progressive drift in scene semantics and structure. To address these issues, we propose MagicWorld, an interactive video world model that integrates 3D geometric priors and historical retrieval. MagicWorld starts from a single scene image, employs user actions to drive dynamic scene evolution, and autoregressively synthesizes continuous scenes. We introduce the Action-Guided 3D Geometry Module (AG3D), which constructs a point cloud from the first frame of each interaction and the corresponding action, providing explicit geometric constraints for viewpoint transitions and thereby improving structural consistency. We further propose History Cache Retrieval (HCR) mechanism, which retrieves relevant historical frames during generation and injects them as conditioning signals, helping the model utilize past scene information and mitigate error accumulation. Experimental results demonstrate that MagicWorld achieves notable improvements in scene stability and continuity across interaction iterations.

</details>


### [209] [EventSTU: Event-Guided Efficient Spatio-Temporal Understanding for Video Large Language Models](https://arxiv.org/abs/2511.18920)
*Wenhao Xu,Xin Dong,Yue Li,Haoyuan Shi,Zhiwei Xiong*

Main category: cs.CV

TL;DR: 本文提出了EventSTU框架，利用事件相机特性实现高效视频理解，通过时间域关键帧采样和空间域token剪枝，在保持性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在处理长视频时面临高推理成本问题，因为长视频包含大量token。受事件视觉启发，作者希望利用事件相机的变化触发特性来消除冗余信息。

Method: 提出EventSTU训练免费框架：1）时间域：粗到细关键帧采样算法，利用事件相机变化触发特性消除冗余帧；2）空间域：自适应token剪枝算法，利用事件视觉显著性作为零成本先验；3）时空整合：结合问题相关性自适应分配token剪枝预算。

Result: 构建了首个事件包含的人类标注多模态基准EventBench。实验显示EventSTU相比最强基线实现3.01倍FLOPs减少和3.10倍预填充加速，同时性能仍有提升。

Conclusion: EventSTU框架通过事件引导的时空理解，在显著降低计算成本的同时保持甚至提升视频理解性能，为高效视频处理提供了新思路。

Abstract: Video large language models have demonstrated strong video understanding capabilities but suffer from high inference costs due to the massive number of tokens in long videos. Inspired by event-based vision, we propose an event-guided, training-free framework for efficient spatio-temporal understanding, named EventSTU. In the temporal domain, we design a coarse-to-fine keyframe sampling algorithm that exploits the change-triggered property of event cameras to eliminate redundant frames. In the spatial domain, we design an adaptive token pruning algorithm that leverages the visual saliency of events as a zero-cost prior to guide spatial reduction. From a holistic spatio-temporal perspective, we further integrate question relevance from keyframe sampling to adaptively allocate token pruning budgets. To facilitate evaluation, we construct EventBench, the first event-inclusive, human-annotated multimodal benchmark that covers diverse real-world scenarios. Beyond physical event cameras, EventSTU also supports general video understanding using simulated events. Comprehensive experiments show that EventSTU achieves 3.01x FLOPs reduction and 3.10x prefilling speedup over the strongest baseline while still improving performance.

</details>


### [210] [BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models](https://arxiv.org/abs/2511.18921)
*Juncheng Li,Yige Li,Hanxun Huang,Yunhao Chen,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: BackdoorVLM是首个针对视觉语言模型(VLMs)的全面后门攻击基准，系统评估了5类多模态后门威胁在图像描述和视觉问答等任务中的影响。


<details>
  <summary>Details</summary>
Motivation: 后门攻击在单模态环境中已被广泛研究，但在多模态基础模型特别是视觉语言模型中的影响仍未充分探索，需要建立系统评估框架。

Method: 采用统一视角在核心视觉语言任务中注入和分析后门，将多模态后门威胁分为5类：目标拒绝、恶意注入、越狱、概念替换和感知劫持，使用12种攻击方法在2个开源VLMs和3个多模态数据集上进行测试。

Result: VLMs对文本指令表现出强烈敏感性，在双模态后门中文本触发器通常压倒图像触发器；涉及文本模态的后门攻击效果显著，仅需1%中毒率即可在大多数任务中达到90%以上的成功率。

Conclusion: 研究揭示了当前VLMs存在显著且未被充分探索的漏洞，BackdoorVLM可作为分析和缓解多模态后门威胁的有用基准。

Abstract: Backdoor attacks undermine the reliability and trustworthiness of machine learning systems by injecting hidden behaviors that can be maliciously activated at inference time. While such threats have been extensively studied in unimodal settings, their impact on multimodal foundation models, particularly vision-language models (VLMs), remains largely underexplored. In this work, we introduce \textbf{BackdoorVLM}, the first comprehensive benchmark for systematically evaluating backdoor attacks on VLMs across a broad range of settings. It adopts a unified perspective that injects and analyzes backdoors across core vision-language tasks, including image captioning and visual question answering. BackdoorVLM organizes multimodal backdoor threats into 5 representative categories: targeted refusal, malicious injection, jailbreak, concept substitution, and perceptual hijack. Each category captures a distinct pathway through which an adversary can manipulate a model's behavior. We evaluate these threats using 12 representative attack methods spanning text, image, and bimodal triggers, tested on 2 open-source VLMs and 3 multimodal datasets. Our analysis reveals that VLMs exhibit strong sensitivity to textual instructions, and in bimodal backdoors the text trigger typically overwhelms the image trigger when forming the backdoor mapping. Notably, backdoors involving the textual modality remain highly potent, with poisoning rates as low as 1\% yielding over 90\% success across most tasks. These findings highlight significant, previously underexplored vulnerabilities in current VLMs. We hope that BackdoorVLM can serve as a useful benchmark for analyzing and mitigating multimodal backdoor threats. Code is available at: https://github.com/bin015/BackdoorVLM .

</details>


### [211] [One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA Control](https://arxiv.org/abs/2511.18922)
*Zhenxing Mi,Yuxin Wang,Dan Xu*

Main category: cs.CV

TL;DR: One4D是一个统一的4D生成和重建框架，能够从单个图像、完整视频或稀疏帧生成同步的RGB帧和点云图，通过统一掩码条件机制和分离的LoRA控制实现高质量输出。


<details>
  <summary>Details</summary>
Motivation: 现有的深度图或点云图重建方法在联合RGB和点云生成时往往失败，会快速降低基础视频模型的质量，需要一种能够同时处理4D生成和重建的统一框架。

Method: 采用统一掩码条件机制处理不同稀疏度的条件帧，通过分离LoRA控制使用两个模态特定的LoRA适配器形成RGB帧和点云图的分离计算分支，通过轻量级零初始化控制链接学习相互像素级一致性。

Result: 在合成和真实4D数据集上训练，One4D在生成和重建任务中都能产生高质量的RGB帧和准确的点云图。

Conclusion: 这项工作代表了使用视频扩散模型实现通用、高质量基于几何的4D世界建模的重要一步。

Abstract: We present One4D, a unified framework for 4D generation and reconstruction that produces dynamic 4D content as synchronized RGB frames and pointmaps. By consistently handling varying sparsities of conditioning frames through a Unified Masked Conditioning (UMC) mechanism, One4D can seamlessly transition between 4D generation from a single image, 4D reconstruction from a full video, and mixed generation and reconstruction from sparse frames. Our framework adapts a powerful video generation model for joint RGB and pointmap generation, with carefully designed network architectures. The commonly used diffusion finetuning strategies for depthmap or pointmap reconstruction often fail on joint RGB and pointmap generation, quickly degrading the base video model. To address this challenge, we introduce Decoupled LoRA Control (DLC), which employs two modality-specific LoRA adapters to form decoupled computation branches for RGB frames and pointmaps, connected by lightweight, zero-initialized control links that gradually learn mutual pixel-level consistency. Trained on a mixture of synthetic and real 4D datasets under modest computational budgets, One4D produces high-quality RGB frames and accurate pointmaps across both generation and reconstruction tasks. This work represents a step toward general, high-quality geometry-based 4D world modeling using video diffusion models. Project page: https://mizhenxing.github.io/One4D

</details>


### [212] [AttenDence: Maximizing Attention Confidence for Test Time Adaptation](https://arxiv.org/abs/2511.18925)
*Yash Mali*

Main category: cs.CV

TL;DR: 提出通过最小化CLS令牌到图像补丁的注意力分布熵作为测试时自适应的新目标，利用transformer的注意力机制作为无监督学习信号。


<details>
  <summary>Details</summary>
Motivation: 测试时自适应需要模型在推理时适应分布偏移，transformer的注意力机制提供了额外的无监督学习信号，可以增强模型对相关图像区域的关注置信度。

Method: 最小化CLS令牌到图像补丁的注意力分布熵，即使在单个测试图像可用时也有效，鼓励模型在分布偏移下更自信地关注相关图像区域。

Result: 注意力熵最小化提高了对各种损坏类型的鲁棒性，同时在干净数据上的性能不会下降，适用于测试时的单样本图像流。

Conclusion: 注意力熵最小化是一种有效的测试时自适应方法，利用transformer的注意力机制增强模型在分布偏移下的鲁棒性。

Abstract: Test-time adaptation (TTA) enables models to adapt to distribution shifts at inference time. While entropy minimization over the output distribution has proven effective for TTA, transformers offer an additional unsupervised learning signal through their attention mechanisms. We propose minimizing the entropy of attention distributions from the CLS token to image patches as a novel TTA objective.This approach encourages the model to attend more confidently to relevant image regions under distribution shift and is effective even when only a single test image is available. We demonstrate that attention entropy minimization improves robustness across diverse corruption types while not hurting performance on clean data on a single sample stream of images at test time.

</details>


### [213] [FineXtrol: Controllable Motion Generation via Fine-Grained Text](https://arxiv.org/abs/2511.18927)
*Keming Shen,Bizhu Wu,Junliang Chen,Xiaoqin Wang,Linlin Shen*

Main category: cs.CV

TL;DR: FineXtrol是一个新颖的运动生成控制框架，通过时间感知、精确、用户友好的细粒度文本控制信号来指导特定身体部位的运动，解决了现有方法中细节不对齐、缺乏时间线索和计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动运动生成方法存在两个主要问题：使用大语言模型生成详细文本时会产生不对齐的细节且缺乏明确的时间线索；使用全局3D坐标序列作为控制信号时会产生高昂的计算成本。

Method: 提出了FineXtrol框架，使用时间感知的细粒度文本控制信号描述特定身体部位随时间的变化，并设计了分层对比学习模块来增强文本编码器生成更具区分度的嵌入表示。

Result: 定量结果显示FineXtrol在可控运动生成方面表现强劲，定性分析表明其在指导特定身体部位运动方面具有灵活性。

Conclusion: FineXtrol通过细粒度文本控制信号和分层对比学习，有效提升了运动生成的可控性和精确性，同时保持了计算效率。

Abstract: Recent works have sought to enhance the controllability and precision of text-driven motion generation. Some approaches leverage large language models (LLMs) to produce more detailed texts, while others incorporate global 3D coordinate sequences as additional control signals. However, the former often introduces misaligned details and lacks explicit temporal cues, and the latter incurs significant computational cost when converting coordinates to standard motion representations. To address these issues, we propose FineXtrol, a novel control framework for efficient motion generation guided by temporally-aware, precise, user-friendly, and fine-grained textual control signals that describe specific body part movements over time. In support of this framework, we design a hierarchical contrastive learning module that encourages the text encoder to produce more discriminative embeddings for our novel control signals, thereby improving motion controllability. Quantitative results show that FineXtrol achieves strong performance in controllable motion generation, while qualitative analysis demonstrates its flexibility in directing specific body part movements.

</details>


### [214] [Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and Scalable Tree-Based Search](https://arxiv.org/abs/2511.18929)
*Zijian Song,Xiaoxin Lin,Tao Pu,Zhenlong Yuan,Guangrun Wang,Liang Lin*

Main category: cs.CV

TL;DR: 本文提出了人类中心开放未来任务发现（HOTD）问题，旨在在开放未来场景中发现减少人类努力的任务，并开发了HOTD-Bench基准测试和协作多智能体搜索树（CMAST）框架来解决该问题。


<details>
  <summary>Details</summary>
Motivation: 当前机器人和具身AI主要依赖大型多模态模型，但如何在人类意图高度并发和动态的开放未来场景中发现直接协助人类的任务仍是一个未充分探索的挑战。

Method: 提出了协作多智能体搜索树（CMAST）框架，通过多智能体系统分解复杂推理，并通过可扩展的搜索树模块结构化推理过程。同时构建了包含2000+真实世界视频的HOTD-Bench基准测试。

Result: CMAST在HOTD-Bench上取得了最佳性能，显著超越现有LMMs，并且能很好地与现有LMMs集成，持续提升性能。

Conclusion: HOTD问题定义和CMAST框架为解决开放未来场景中人类中心任务发现提供了有效方法，在基准测试中表现出色。

Abstract: Recent progress in robotics and embodied AI is largely driven by Large Multimodal Models (LMMs). However, a key challenge remains underexplored: how can we advance LMMs to discover tasks that directly assist humans in open-future scenarios, where human intentions are highly concurrent and dynamic. In this work, we formalize the problem of Human-centric Open-future Task Discovery (HOTD), focusing particularly on identifying tasks that reduce human effort across multiple plausible futures. To facilitate this study, we propose an HOTD-Bench, which features over 2K real-world videos, a semi-automated annotation pipeline, and a simulation-based protocol tailored for open-set future evaluation. Additionally, we propose the Collaborative Multi-Agent Search Tree (CMAST) framework, which decomposes the complex reasoning through a multi-agent system and structures the reasoning process through a scalable search tree module. In our experiments, CMAST achieves the best performance on the HOTD-Bench, significantly surpassing existing LMMs. It also integrates well with existing LMMs, consistently improving performance.

</details>


### [215] [Eevee: Towards Close-up High-resolution Video-based Virtual Try-on](https://arxiv.org/abs/2511.18957)
*Jianhao Zeng,Yancheng Bai,Ruidong Chen,Xuanpu Zhang,Lei Sun,Dongyang Jin,Ryan Xu,Nannan Zhang,Dan Song,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出了一个高分辨率视频虚拟试穿数据集，解决了现有方法在纹理细节捕捉和特写镜头生成方面的不足，并提出了新的评估指标VGID来量化服装一致性的保持。


<details>
  <summary>Details</summary>
Motivation: 当前视频虚拟试穿技术存在两个关键限制：1）依赖单一服装图像输入无法准确捕捉真实纹理细节；2）现有方法只关注生成全身试穿视频，忽略了商业对特写镜头的需求。

Method: 1）构建包含高保真特写图像和文本描述的高分辨率数据集；2）提出VGID指标来量化服装纹理和结构的一致性保持；3）利用数据集中的详细图像增强现有视频生成模型的纹理特征提取能力。

Result: 实验验证表明，使用该数据集的详细图像可以显著提升虚拟试穿结果的真实感和细节保真度。基准测试有效识别了当前方法在纹理和结构保持方面的问题。

Conclusion: 该高分辨率数据集和VGID评估指标为视频虚拟试穿技术提供了更全面的解决方案，能够更好地满足电商营销的实际需求，特别是在特写镜头生成和细节保真方面。

Abstract: Video virtual try-on technology provides a cost-effective solution for creating marketing videos in fashion e-commerce. However, its practical adoption is hindered by two critical limitations. First, the reliance on a single garment image as input in current virtual try-on datasets limits the accurate capture of realistic texture details. Second, most existing methods focus solely on generating full-shot virtual try-on videos, neglecting the business's demand for videos that also provide detailed close-ups. To address these challenges, we introduce a high-resolution dataset for video-based virtual try-on. This dataset offers two key features. First, it provides more detailed information on the garments, which includes high-fidelity images with detailed close-ups and textual descriptions; Second, it uniquely includes full-shot and close-up try-on videos of real human models. Furthermore, accurately assessing consistency becomes significantly more critical for the close-up videos, which demand high-fidelity preservation of garment details. To facilitate such fine-grained evaluation, we propose a new garment consistency metric VGID (Video Garment Inception Distance) that quantifies the preservation of both texture and structure. Our experiments validate these contributions. We demonstrate that by utilizing the detailed images from our dataset, existing video generation models can extract and incorporate texture features, significantly enhancing the realism and detail fidelity of virtual try-on results. Furthermore, we conduct a comprehensive benchmark of recent models. The benchmark effectively identifies the texture and structural preservation problems among current methods.

</details>


### [216] [CataractCompDetect: Intraoperative Complication Detection in Cataract Surgery](https://arxiv.org/abs/2511.18968)
*Bhuvan Sachdeva,Sneha Kumari,Rudransh Agarwal,Shalaka Kumaraswamy,Niharika Singri Prasad,Simon Mueller,Raphael Lechtenboehmer,Maximilian W. M. Wintergerst,Thomas Schultz,Kaushik Murali,Mohit Jain*

Main category: cs.CV

TL;DR: 提出了CataractCompDetect框架，结合相位感知定位、SAM 2跟踪、并发症特定风险评分和视觉语言推理，用于白内障手术中并发症的自动检测。


<details>
  <summary>Details</summary>
Motivation: 白内障手术是全球最常见的手术之一，但术中并发症如虹膜脱垂、后囊破裂和玻璃体丢失仍是导致不良结果的主要原因。自动检测这些事件可以实现早期预警系统和客观培训反馈。

Method: 开发了CataractCompDetect框架，包含相位感知定位、基于SAM 2的跟踪、并发症特定风险评分和视觉语言推理进行最终分类。创建了首个白内障手术视频数据集CataComp进行验证。

Result: 在CataComp数据集上，CataractCompDetect平均F1得分为70.63%，各并发症检测性能分别为：虹膜脱垂81.8%、后囊破裂60.87%、玻璃体丢失69.23%。

Conclusion: 结果表明，将结构化手术先验知识与视觉语言推理相结合对于识别罕见但影响重大的术中事件具有重要价值。

Abstract: Cataract surgery is one of the most commonly performed surgeries worldwide, yet intraoperative complications such as iris prolapse, posterior capsule rupture (PCR), and vitreous loss remain major causes of adverse outcomes. Automated detection of such events could enable early warning systems and objective training feedback. In this work, we propose CataractCompDetect, a complication detection framework that combines phase-aware localization, SAM 2-based tracking, complication-specific risk scoring, and vision-language reasoning for final classification. To validate CataractCompDetect, we curate CataComp, the first cataract surgery video dataset annotated for intraoperative complications, comprising 53 surgeries, including 23 with clinical complications. On CataComp, CataractCompDetect achieves an average F1 score of 70.63%, with per-complication performance of 81.8% (Iris Prolapse), 60.87% (PCR), and 69.23% (Vitreous Loss). These results highlight the value of combining structured surgical priors with vision-language reasoning for recognizing rare but high-impact intraoperative events. Our dataset and code will be publicly released upon acceptance.

</details>


### [217] [Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs](https://arxiv.org/abs/2511.18976)
*Huaming Ling,Ying Wang,Si Chen,Junfeng Fan*

Main category: cs.CV

TL;DR: 本文提出了一种将预训练CNN转换为FHE友好形式的方法，包括单阶段微调策略和通用交错打包方案，实现了在完全同态加密下的高效推理。


<details>
  <summary>Details</summary>
Motivation: 解决深度CNN在FHE推理中的两个关键挑战：用低阶多项式近似非线性激活函数以减少精度损失，以及克服密文容量限制以支持高分辨率图像处理。

Method: 采用单阶段微调策略直接转换预训练CNN，使用低阶多项式替换非线性激活；提出通用交错打包方案和配套的同态操作符，支持任意空间分辨率的特征图。

Result: 在CIFAR-10、ImageNet和MS COCO数据集上的实验表明，FHE友好CNN的精度与使用ReLU或SiLU激活的基线相当，并首次实现了基于FHE的YOLO架构目标检测。

Conclusion: 该方法实现了跨多种CNN架构的高效端到端FHE推理，为安全AI推理提供了实用解决方案。

Abstract: We address two fundamental challenges in adapting general deep CNNs for FHE-based inference: approximating non-linear activations such as ReLU with low-degree polynomials while minimizing accuracy degradation, and overcoming the ciphertext capacity barrier that constrains high-resolution image processing on FHE inference. Our contributions are twofold: (1) a single-stage fine-tuning (SFT) strategy that directly converts pre-trained CNNs into FHE-friendly forms using low-degree polynomials, achieving competitive accuracy with minimal training overhead; and (2) a generalized interleaved packing (GIP) scheme that is compatible with feature maps of virtually arbitrary spatial resolutions, accompanied by a suite of carefully designed homomorphic operators that preserve the GIP-form encryption throughout computation. These advances enable efficient, end-to-end FHE inference across diverse CNN architectures. Experiments on CIFAR-10, ImageNet, and MS COCO demonstrate that the FHE-friendly CNNs obtained via our SFT strategy achieve accuracy comparable to baselines using ReLU or SiLU activations. Moreover, this work presents the first demonstration of FHE-based inference for YOLO architectures in object detection leveraging low-degree polynomial activations.

</details>


### [218] [Zero-shot segmentation of skin tumors in whole-slide images with vision-language foundation models](https://arxiv.org/abs/2511.18978)
*Santiago Moreno,Pablo Meseguer,Rocío del Amor,Valery Naranjo*

Main category: cs.CV

TL;DR: ZEUS是一个零样本视觉语言分割框架，利用文本提示集合和冻结的VLM编码器在WSIs中生成高分辨率肿瘤分割掩码，无需像素级标注即可实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤肿瘤活检的准确标注面临形态变异大、组织学模式重叠以及良恶性病变细微差异等挑战，现有VLM应用在组织病理学中局限于幻灯片级任务或依赖粗糙交互提示，难以在千兆像素WSIs上生成细粒度分割。

Method: 通过将每个WSI分割成重叠补丁，提取视觉嵌入，计算与文本提示的余弦相似度，生成最终分割掩码，利用类特定文本提示集合和冻结的VLM编码器。

Result: 在两个内部数据集（原发性梭形细胞肿瘤和皮肤转移瘤）上展示了竞争性性能，突出了提示设计、领域偏移和机构变异对组织病理学中VLM的影响。

Conclusion: ZEUS显著减少了标注负担，同时为下游诊断工作流程提供了可扩展、可解释的肿瘤描绘。

Abstract: Accurate annotation of cutaneous neoplasm biopsies represents a major challenge due to their wide morphological variability, overlapping histological patterns, and the subtle distinctions between benign and malignant lesions. Vision-language foundation models (VLMs), pre-trained on paired image-text corpora, learn joint representations that bridge visual features and diagnostic terminology, enabling zero-shot localization and classification of tissue regions without pixel-level labels. However, most existing VLM applications in histopathology remain limited to slide-level tasks or rely on coarse interactive prompts, and they struggle to produce fine-grained segmentations across gigapixel whole-slide images (WSIs). In this work, we introduce a zero-shot visual-language segmentation pipeline for whole-slide images (ZEUS), a fully automated, zero-shot segmentation framework that leverages class-specific textual prompt ensembles and frozen VLM encoders to generate high-resolution tumor masks in WSIs. By partitioning each WSI into overlapping patches, extracting visual embeddings, and computing cosine similarities against text prompts, we generate a final segmentation mask. We demonstrate competitive performance on two in-house datasets, primary spindle cell neoplasms and cutaneous metastases, highlighting the influence of prompt design, domain shifts, and institutional variability in VLMs for histopathology. ZEUS markedly reduces annotation burden while offering scalable, explainable tumor delineation for downstream diagnostic workflows.

</details>


### [219] [UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection](https://arxiv.org/abs/2511.18983)
*Ching-Yi Lai,Chih-Yu Jian,Pei-Cheng Chuang,Chia-Ming Lee,Chih-Chung Hsu,Chiou-Ting Hsu,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 提出了一种新颖的单模态生成多模态对比学习框架，通过将单一视觉模态转换为互补特征来应对社交媒体压缩带来的深度伪造检测挑战。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台采用不同程度的压缩给深度伪造检测模型带来了泛化性和可靠性挑战。现有单模态方法在数据压缩下特征退化，而多模态方法需要昂贵的数据收集和标注，且在实际场景中模态质量或可访问性不一致。

Method: UMCL框架将单一视觉模态转换为三个互补特征：压缩稳健的rPPG信号、时间地标动态和预训练视觉语言模型的语义嵌入。通过亲和力驱动的语义对齐策略显式对齐这些特征，并通过跨质量相似性学习增强特征鲁棒性。

Result: 实验表明该方法在各种压缩率和操作类型下均取得优异性能，为稳健深度伪造检测设立了新基准。即使单个特征退化时仍保持高检测精度，并通过显式对齐提供特征关系的可解释性见解。

Conclusion: 所提出的UMCL框架通过单模态生成多模态特征和显式对齐策略，有效解决了跨压缩率深度伪造检测的挑战，在保持高性能的同时提供了模型可解释性。

Abstract: In deepfake detection, the varying degrees of compression employed by social media platforms pose significant challenges for model generalization and reliability. Although existing methods have progressed from single-modal to multimodal approaches, they face critical limitations: single-modal methods struggle with feature degradation under data compression in social media streaming, while multimodal approaches require expensive data collection and labeling and suffer from inconsistent modal quality or accessibility in real-world scenarios. To address these challenges, we propose a novel Unimodal-generated Multimodal Contrastive Learning (UMCL) framework for robust cross-compression-rate (CCR) deepfake detection. In the training stage, our approach transforms a single visual modality into three complementary features: compression-robust rPPG signals, temporal landmark dynamics, and semantic embeddings from pre-trained vision-language models. These features are explicitly aligned through an affinity-driven semantic alignment (ASA) strategy, which models inter-modal relationships through affinity matrices and optimizes their consistency through contrastive learning. Subsequently, our cross-quality similarity learning (CQSL) strategy enhances feature robustness across compression rates. Extensive experiments demonstrate that our method achieves superior performance across various compression rates and manipulation types, establishing a new benchmark for robust deepfake detection. Notably, our approach maintains high detection accuracy even when individual features degrade, while providing interpretable insights into feature relationships through explicit alignment.

</details>


### [220] [View-Consistent Diffusion Representations for 3D-Consistent Video Generation](https://arxiv.org/abs/2511.18991)
*Duolikun Danier,Ge Gao,Steven McDonagh,Changjian Li,Hakan Bilen,Oisin Mac Aodha*

Main category: cs.CV

TL;DR: 本文提出ViCoDR方法，通过改进视频扩散模型的多视角一致性表示来提升生成视频的3D一致性，解决了当前视频生成中因相机姿态变化导致的物体和结构变形问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在相机姿态变化时会产生3D不一致的视觉伪影，如物体和结构变形，这影响了用户体验和模拟保真度。基于扩散模型表示对齐的研究发现，改进视频扩散表示的多视角一致性有望实现更3D一致的视频生成。

Method: 提出ViCoDR方法，通过分析多个相机控制视频扩散模型，发现3D一致表示与视频质量之间的强相关性，并学习多视角一致的扩散表示来提升视频模型的3D一致性。

Result: 在相机控制的图像到视频、文本到视频和多视角生成模型上评估ViCoDR，结果显示生成的视频在3D一致性方面有显著改进。

Conclusion: ViCoDR通过改进多视角一致的扩散表示，有效提升了视频生成模型的3D一致性，为解决视频生成中的视觉伪影问题提供了有效方案。

Abstract: Video generation models have made significant progress in generating realistic content, enabling applications in simulation, gaming, and film making. However, current generated videos still contain visual artifacts arising from 3D inconsistencies, e.g., objects and structures deforming under changes in camera pose, which can undermine user experience and simulation fidelity. Motivated by recent findings on representation alignment for diffusion models, we hypothesize that improving the multi-view consistency of video diffusion representations will yield more 3D-consistent video generation. Through detailed analysis on multiple recent camera-controlled video diffusion models we reveal strong correlations between 3D-consistent representations and videos. We also propose ViCoDR, a new approach for improving the 3D consistency of video models by learning multi-view consistent diffusion representations. We evaluate ViCoDR on camera controlled image-to-video, text-to-video, and multi-view generation models, demonstrating significant improvements in the 3D consistency of the generated videos. Project page: https://danier97.github.io/ViCoDR.

</details>


### [221] [AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake Temporal Localization](https://arxiv.org/abs/2511.18993)
*Christos Koutlis,Symeon Papadopoulos*

Main category: cs.CV

TL;DR: 本文提出了一种基于视听语音表示重建(AuViRe)的新方法，用于深度伪造视频的时间定位，通过跨模态重建差异来检测恶意篡改片段。


<details>
  <summary>Details</summary>
Motivation: 随着复杂合成音视频内容的快速发展，特别是用于恶意操纵的内容，确保数字媒体的完整性变得至关重要。

Method: 利用视听语音表示重建(AuViRe)，从一个模态(如唇部运动)重建另一个模态(如音频波形)的语音表示，在篡改视频片段中跨模态重建更具挑战性，从而产生放大差异。

Result: 在LAV-DF数据集上AP@0.95提升+8.9，在AV-Deepfake1M数据集上AP@0.5提升+9.6，在真实场景实验中AUC提升+5.1。

Conclusion: AuViRe方法通过跨模态重建差异提供了强大的判别线索，能够精确进行时间伪造定位，显著优于现有技术。

Abstract: With the rapid advancement of sophisticated synthetic audio-visual content, e.g., for subtle malicious manipulations, ensuring the integrity of digital media has become paramount. This work presents a novel approach to temporal localization of deepfakes by leveraging Audio-Visual Speech Representation Reconstruction (AuViRe). Specifically, our approach reconstructs speech representations from one modality (e.g., lip movements) based on the other (e.g., audio waveform). Cross-modal reconstruction is significantly more challenging in manipulated video segments, leading to amplified discrepancies, thereby providing robust discriminative cues for precise temporal forgery localization. AuViRe outperforms the state of the art by +8.9 AP@0.95 on LAV-DF, +9.6 AP@0.5 on AV-Deepfake1M, and +5.1 AUC on an in-the-wild experiment. Code available at https://github.com/mever-team/auvire.

</details>


### [222] [Dynamic Granularity Matters: Rethinking Vision Transformers Beyond Fixed Patch Splitting](https://arxiv.org/abs/2511.19021)
*Qiyang Yu,Yu Fang,Tianrui Li,Xuemei Cao,Yan Chen,Jianghao Li,Fan Min*

Main category: cs.CV

TL;DR: 提出了Grc-ViT，一种动态粗到细的视觉Transformer框架，通过自适应调整视觉粒度来解决ViT在细粒度局部细节表示上的不足，在保持计算效率的同时提升细粒度识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有多尺度方法使用固定补丁尺寸并引入冗余计算，无法有效平衡全局依赖和局部细节表示。需要一种能够根据图像复杂度自适应调整视觉粒度的动态框架。

Method: 包含两个关键模块：粗粒度评估模块（使用边缘密度、熵和频域线索评估视觉复杂度并估计合适的补丁和窗口尺寸），细粒度精炼模块（根据选定粒度优化注意力计算）。引入两个可学习参数α和β来平衡全局推理和局部感知。

Result: 综合评估表明Grc-ViT增强了细粒度区分能力，同时在准确性和计算效率之间实现了优越的权衡。

Conclusion: Grc-ViT通过动态粒度调整机制有效解决了ViT在局部细节表示上的局限性，为视觉Transformer提供了更高效的细粒度特征学习方案。

Abstract: Vision Transformers (ViTs) have demonstrated strong capabilities in capturing global dependencies but often struggle to efficiently represent fine-grained local details. Existing multi-scale approaches alleviate this issue by integrating hierarchical or hybrid features; however, they rely on fixed patch sizes and introduce redundant computation. To address these limitations, we propose Granularity-driven Vision Transformer (Grc-ViT), a dynamic coarse-to-fine framework that adaptively adjusts visual granularity based on image complexity. It comprises two key stages: (1) Coarse Granularity Evaluation module, which assesses visual complexity using edge density, entropy, and frequency-domain cues to estimate suitable patch and window sizes; (2) Fine-grained Refinement module, which refines attention computation according to the selected granularity, enabling efficient and precise feature learning. Two learnable parameters, α and \b{eta}, are optimized end-to-end to balance global reasoning and local perception. Comprehensive evaluations demonstrate that Grc-ViT enhances fine-grained discrimination while achieving a superior trade-off between accuracy and computational efficiency.

</details>


### [223] [Benchmarking Corruption Robustness of LVLMs: A Discriminative Benchmark and Robustness Alignment Metric](https://arxiv.org/abs/2511.19032)
*Xiangjie Sui,Songyang Li,Hanwei Zhu,Baoliang Chen,Yuming Fang,Xin Sun*

Main category: cs.CV

TL;DR: 本文提出了Bench-C基准测试和RAS指标，用于评估大型视觉语言模型在视觉损坏下的鲁棒性，解决了现有评估方法中样本区分度不足和准确性指标无法捕捉预测结构退化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法存在两个主要局限：1）当前数据集中低区分度样本占主导，掩盖了模型间的真实鲁棒性差距；2）传统基于准确性的指标无法捕捉底层预测结构的退化。

Method: 引入Bench-C基准测试，强调使用区分度样本评估损坏鲁棒性，并提出选择策略同时考虑损坏下的预测不一致性和语义多样性。提出RAS统一指标，通过考虑预测不确定性和校准对齐的变化来测量logit级预测结构的退化。

Result: 实验发现：1）模型在损坏下表现出不同行为模式，如错误置信和犹豫；2）轻微损坏可能导致准确性略有提升，但整体预测结构仍会退化；3）通过将损坏鲁棒性分解为破坏性和纠正性组件，可以揭示不同模型的失败和恢复模式。

Conclusion: Bench-C和RAS为评估LVLMs在视觉损坏下的鲁棒性提供了更全面的框架，能够揭示传统指标无法捕捉的模型行为差异和预测结构退化。

Abstract: Despite the remarkable reasoning abilities of large vision-language models (LVLMs), their robustness under visual corruptions remains insufficiently studied. Existing evaluation paradigms exhibit two major limitations: 1) the dominance of low-discriminative samples in current datasets masks the real robustness gap between models; and 2) conventional accuracy-based metric fail to capture the degradation of the underlying prediction structure. To bridge these gaps, we introduce Bench-C, a comprehensive benchmark emphasizing discriminative samples for assessing corruption robustness, where a selection strategy is proposed to jointly consider the prediction inconsistency under corruption and the semantic diversity. Furthermore, we propose the Robustness Alignment Score (RAS), a unified metric that measures degradation in logit-level prediction structure by considering the shifts in prediction uncertainty and calibration alignment. Comprehensive experiments and analysis reveal several interesting findings: 1) model behaviors exhibit distinguish patterns under corruptions, such as erroneous confidence and hesitation; 2) despite subtle corruption may lead to a slight accuracy gain, the overall prediction structure still degrades; 3) by decomposing corruption robustness into destructive and corrective components, the distinct failure and recovery patterns across models can be revealed.

</details>


### [224] [Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation](https://arxiv.org/abs/2511.19147)
*Huisoo Lee,Jisu Han,Hyunsouk Cho,Wonjun Hwang*

Main category: cs.CV

TL;DR: 提出CoMA框架，利用两个互补的基础模型（如CLIP和BLIP）进行源自由域自适应，通过双向适应机制和分解互信息实现稳定训练，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于单一基础模型的SFDA方法存在语义覆盖受限的问题，无法在域偏移下捕捉多样化的上下文线索。

Method: CoMA框架联合利用两个互补的基础模型，采用双向适应机制：对齐不同基础模型与目标模型进行任务适应，同时保持语义独特性；将互补知识从基础模型转移到目标模型。引入分解互信息来稳定小批量训练。

Result: 在Office-31、Office-Home、DomainNet-126和VisDA四个基准测试中，闭集设置下一致优于现有最先进的SFDA方法，同时在部分集和开集变体上也取得最佳结果。

Conclusion: 通过协同利用多个互补基础模型，CoMA框架能够有效捕捉全局语义和局部上下文线索，在源自由域自适应任务中展现出优越性能。

Abstract: Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data. Recent advances in Foundation Models (FMs) have introduced new opportunities for leveraging external semantic knowledge to guide SFDA. However, relying on a single FM is often insufficient, as it tends to bias adaptation toward a restricted semantic coverage, failing to capture diverse contextual cues under domain shift. To overcome this limitation, we propose a Collaborative Multi-foundation Adaptation (CoMA) framework that jointly leverages two different FMs (e.g., CLIP and BLIP) with complementary properties to capture both global semantics and local contextual cues. Specifically, we employ a bidirectional adaptation mechanism that (1) aligns different FMs with the target model for task adaptation while maintaining their semantic distinctiveness, and (2) transfers complementary knowledge from the FMs to the target model. To ensure stable adaptation under mini-batch training, we introduce Decomposed Mutual Information (DMI) that selectively enhances true dependencies while suppressing false dependencies arising from incomplete class coverage. Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art SFDA methods across four benchmarks, including Office-31, Office-Home, DomainNet-126, and VisDA, under the closed-set setting, while also achieving best results on partial-set and open-set variants.

</details>


### [225] [SpectraNet: FFT-assisted Deep Learning Classifier for Deepfake Face Detection](https://arxiv.org/abs/2511.19187)
*Nithira Jayarathne,Naveen Basnayake,Keshawa Jayasundara,Pasindu Dodampegama,Praveen Wijesinghe,Hirushika Pelagewatta,Kavishka Abeywardana,Sandushan Ranaweera,Chamira Edussooriya*

Main category: cs.CV

TL;DR: 提出基于EfficientNet-B6的轻量级深度伪造图像检测模型，通过数据变换技术解决类别不平衡问题，实现高精度、稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度伪造图像检测对于打击虚假信息至关重要，需要开发轻量级且泛化能力强的检测模型。

Method: 使用EfficientNet-B6作为基础架构，结合数据变换技术进行微调，采用鲁棒预处理、过采样和优化策略，并尝试傅里叶变换特征。

Result: 模型实现了高精度、稳定性和泛化能力，但傅里叶变换的相位和振幅特征贡献有限。

Conclusion: 该框架帮助非专家有效识别深度伪造图像，在可访问和可靠的深度伪造检测方面取得重要进展。

Abstract: Detecting deepfake images is crucial in combating misinformation. We present a lightweight, generalizable binary classification model based on EfficientNet-B6, fine-tuned with transformation techniques to address severe class imbalances. By leveraging robust preprocessing, oversampling, and optimization strategies, our model achieves high accuracy, stability, and generalization. While incorporating Fourier transform-based phase and amplitude features showed minimal impact, our proposed framework helps non-experts to effectively identify deepfake images, making significant strides toward accessible and reliable deepfake detection.

</details>


### [226] [Beyond Reward Margin: Rethinking and Resolving Likelihood Displacement in Diffusion Models via Video Generation](https://arxiv.org/abs/2511.19049)
*Ruojun Xu,Yu Kai,Xuhua Ren,Jiaxiang Cheng,Bing Ma,Tianxiang Zheng,Qinhlin Lu*

Main category: cs.CV

TL;DR: 本文分析了DPO在扩散模型中的局限性，提出了PG-DPO方法来解决似然位移问题，在视频生成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: DPO在扩散模型中的似然位移问题尚未被充分研究，这导致视频生成任务性能不佳，需要新的解决方案。

Method: 通过形式化分析DPO损失在扩散框架中的更新策略，提出了结合自适应拒绝缩放和隐式偏好正则化的PG-DPO方法。

Result: 实验表明PG-DPO在定量指标和定性评估上都优于现有方法。

Conclusion: PG-DPO为视频生成任务中的偏好对齐提供了稳健的解决方案，有效缓解了似然位移问题。

Abstract: Direct Preference Optimization (DPO) has shown promising results in aligning generative outputs with human preferences by distinguishing between chosen and rejected samples. However, a critical limitation of DPO is likelihood displacement, where the probabilities of chosen samples paradoxically decrease during training, undermining the quality of generation. Although this issue has been investigated in autoregressive models, its impact within diffusion-based models remains largely unexplored. This gap leads to suboptimal performance in tasks involving video generation. To address this, we conduct a formal analysis of DPO loss through updating policy within the diffusion framework, which describes how the updating of specific training samples influences the model's predictions on other samples. Using this tool, we identify two main failure modes: (1) Optimization Conflict, which arises from small reward margins between chosen and rejected samples, and (2) Suboptimal Maximization, caused by large reward margins. Informed by these insights, we introduce a novel solution named Policy-Guided DPO (PG-DPO), combining Adaptive Rejection Scaling (ARS) and Implicit Preference Regularization (IPR) to effectively mitigate likelihood displacement. Experiments show that PG-DPO outperforms existing methods in both quantitative metrics and qualitative evaluations, offering a robust solution for improving preference alignment in video generation tasks.

</details>


### [227] [LAA3D: A Benchmark of Detecting and Tracking Low-Altitude Aircraft in 3D Space](https://arxiv.org/abs/2511.19057)
*Hai Wu,Shuai Tang,Jiale Wang,Longkun Zou,Mingyue Guo,Rongqin Liang,Ke Chen,Yaowei Wang*

Main category: cs.CV

TL;DR: LAA3D是一个大规模低空飞行器3D感知数据集，包含15,000张真实图像和600,000帧合成数据，支持3D检测、多目标跟踪和6自由度姿态估计等任务。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门用于3D低空飞行器感知的数据集，限制了该领域的研究进展。

Method: 构建LAA3D数据集，包含真实和合成数据，涵盖多种飞行器类别；建立统一评估基准；提出MonoLAA单目3D检测基线方法。

Result: 数据集支持多种3D感知任务，合成数据预训练模型能有效迁移到真实数据，展示出良好的仿真到真实泛化能力。

Conclusion: LAA3D为低空3D物体感知研究提供了全面基础，推动了该领域的发展。

Abstract: Perception of Low-Altitude Aircraft (LAA) in 3D space enables precise 3D object localization and behavior understanding. However, datasets tailored for 3D LAA perception remain scarce. To address this gap, we present LAA3D, a large-scale dataset designed to advance 3D detection and tracking of low-altitude aerial vehicles. LAA3D contains 15,000 real images and 600,000 synthetic frames, captured across diverse scenarios, including urban and suburban environments. It covers multiple aerial object categories, including electric Vertical Take-Off and Landing (eVTOL) aircraft, Micro Aerial Vehicles (MAVs), and Helicopters. Each instance is annotated with 3D bounding box, class label, and instance identity, supporting tasks such as 3D object detection, 3D multi-object tracking (MOT), and 6-DoF pose estimation. Besides, we establish the LAA3D Benchmark, integrating multiple tasks and methods with unified evaluation protocols for comparison. Furthermore, we propose MonoLAA, a monocular 3D detection baseline, achieving robust 3D localization from zoom cameras with varying focal lengths. Models pretrained on synthetic images transfer effectively to real-world data with fine-tuning, demonstrating strong sim-to-real generalization. Our LAA3D provides a comprehensive foundation for future research in low-altitude 3D object perception.

</details>


### [228] [Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation](https://arxiv.org/abs/2511.19062)
*Qiyang Yu,Yu Fang,Tianrui Li,Xuemei Cao,Yan Chen,Jianghao Li,Fan Min,Yi Zhang*

Main category: cs.CV

TL;DR: Grc-SAM是一个基于粒度计算的从粗到细的图像分割框架，解决了传统SAM模型在自主区域定位和高分辨率细节建模方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统预训练模型（如SAM）在单粒度级别生成提示存在两个主要问题：(1) 缺乏自主区域定位机制；(2) 在高分辨率下有限度的细粒度建模能力。

Method: 采用三阶段方法：粗粒度阶段自适应提取高响应区域实现前景定位；细粒度阶段应用更细的补丁划分和稀疏局部注意力增强细节建模；将精炼掩码编码为潜在提示嵌入替代手工提示。

Result: 广泛的实验结果表明Grc-SAM在准确性和可扩展性方面均优于基线方法。

Conclusion: Grc-SAM通过集成多粒度注意力，将粒度计算与视觉变换器相结合，为无提示分割提供了独特的粒度计算视角。

Abstract: Prompt-free image segmentation aims to generate accurate masks without manual guidance. Typical pre-trained models, notably Segmentation Anything Model (SAM), generate prompts directly at a single granularity level. However, this approach has two limitations: (1) Localizability, lacking mechanisms for autonomous region localization; (2) Scalability, limited fine-grained modeling at high resolution. To address these challenges, we introduce Granular Computing-driven SAM (Grc-SAM), a coarse-to-fine framework motivated by Granular Computing (GrC). First, the coarse stage adaptively extracts high-response regions from features to achieve precise foreground localization and reduce reliance on external prompts. Second, the fine stage applies finer patch partitioning with sparse local swin-style attention to enhance detail modeling and enable high-resolution segmentation. Third, refined masks are encoded as latent prompt embeddings for the SAM decoder, replacing handcrafted prompts with an automated reasoning process. By integrating multi-granularity attention, Grc-SAM bridges granular computing with vision transformers. Extensive experimental results demonstrate Grc-SAM outperforms baseline methods in both accuracy and scalability. It offers a unique granular computational perspective for prompt-free segmentation.

</details>


### [229] [DEAP-3DSAM: Decoder Enhanced and Auto Prompt SAM for 3D Medical Image Segmentation](https://arxiv.org/abs/2511.19071)
*Fangda Chen,Jintao Tang,Pancheng Wang,Ting Wang,Shasha Li,Ting Deng*

Main category: cs.CV

TL;DR: DEAP-3DSAM是一个改进的3D医学图像分割模型，通过特征增强解码器和双注意力提示器解决了SAM在3D分割中的空间特征损失和手动提示依赖问题。


<details>
  <summary>Details</summary>
Motivation: SAM在医学图像分割中表现出潜力，但应用于3D图像时存在空间特征损失问题，且大多数方法依赖手动提示，这在真实场景中难以实现并需要大量专家知识。

Method: 提出特征增强解码器融合原始图像特征与空间信息来增强空间特征，设计双注意力提示器通过空间注意力和通道注意力自动获取提示信息。

Result: 在四个公共腹部肿瘤分割数据集上的实验表明，DEAP-3DSAM在3D图像分割中达到最先进性能，优于或匹配现有手动提示方法。

Conclusion: 定量和定性消融研究证实了所提出模块的有效性，DEAP-3DSAM成功解决了SAM在3D医学图像分割中的关键限制。

Abstract: The Segment Anything Model (SAM) has recently demonstrated significant potential in medical image segmentation. Although SAM is primarily trained on 2D images, attempts have been made to apply it to 3D medical image segmentation. However, the pseudo 3D processing used to adapt SAM results in spatial feature loss, limiting its performance. Additionally, most SAM-based methods still rely on manual prompts, which are challenging to implement in real-world scenarios and require extensive external expert knowledge. To address these limitations, we introduce the Decoder Enhanced and Auto Prompt SAM (DEAP-3DSAM) to tackle these limitations. Specifically, we propose a Feature Enhanced Decoder that fuses the original image features with rich and detailed spatial information to enhance spatial features. We also design a Dual Attention Prompter to automatically obtain prompt information through Spatial Attention and Channel Attention. We conduct comprehensive experiments on four public abdominal tumor segmentation datasets. The results indicate that our DEAP-3DSAM achieves state-of-the-art performance in 3D image segmentation, outperforming or matching existing manual prompt methods. Furthermore, both quantitative and qualitative ablation studies confirm the effectiveness of our proposed modules.

</details>


### [230] [Breaking the Likelihood-Quality Trade-off in Diffusion Models by Merging Pretrained Experts](https://arxiv.org/abs/2511.19434)
*Yasin Esfandiari,Stefan Bauer,Sebastian U. Stich,Andrea Dittadi*

Main category: cs.CV

TL;DR: 提出了一种简单的即插即用采样方法，通过在高噪声水平和低噪声水平之间切换两个预训练的扩散专家模型，来打破图像扩散模型中似然与质量之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 图像生成扩散模型通常在感知样本质量和数据似然之间存在权衡：强调高噪声去噪步骤的训练目标能产生真实图像但似然较差，而似然导向的训练会过度加权低噪声步骤并损害视觉保真度。

Method: 引入一种简单的即插即用采样方法，通过在去噪轨迹上切换两个预训练的扩散专家模型：在高噪声水平应用图像质量专家来塑造全局结构，然后在低噪声水平切换到似然专家来细化像素统计。

Result: 在CIFAR-10和ImageNet32上，合并模型始终匹配或优于其基础组件，相对于每个单独专家，改善或保持了似然和样本质量。

Conclusion: 在噪声水平之间进行专家切换是打破图像扩散模型中似然-质量权衡的有效方法。

Abstract: Diffusion models for image generation often exhibit a trade-off between perceptual sample quality and data likelihood: training objectives emphasizing high-noise denoising steps yield realistic images but poor likelihoods, whereas likelihood-oriented training overweights low-noise steps and harms visual fidelity. We introduce a simple plug-and-play sampling method that combines two pretrained diffusion experts by switching between them along the denoising trajectory. Specifically, we apply an image-quality expert at high noise levels to shape global structure, then switch to a likelihood expert at low noise levels to refine pixel statistics. The approach requires no retraining or fine-tuning -- only the choice of an intermediate switching step. On CIFAR-10 and ImageNet32, the merged model consistently matches or outperforms its base components, improving or preserving both likelihood and sample quality relative to each expert alone. These results demonstrate that expert switching across noise levels is an effective way to break the likelihood-quality trade-off in image diffusion models.

</details>


### [231] [DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection](https://arxiv.org/abs/2511.19111)
*Hai Ci,Ziheng Peng,Pei Yang,Yingxin Xuan,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 提出了DiffSeg30k数据集，包含3万张扩散编辑图像，支持像素级注释的细粒度检测，将AIGC检测从二元分类转向语义分割。


<details>
  <summary>Details</summary>
Motivation: 现有AIGC检测基准主要关注整图分类，忽视了扩散编辑的定位问题，需要支持细粒度检测的数据集。

Method: 构建包含3万张扩散编辑图像的数据集，使用8种SOTA扩散模型进行局部编辑，采用VLM自动识别有意义区域并生成上下文感知提示，支持多轮编辑。

Result: 基准测试显示语义分割任务面临显著挑战，特别是在图像失真鲁棒性方面。分割模型在整图分类上优于现有伪造分类器，并展现出跨生成器泛化潜力。

Conclusion: DiffSeg30k将推动AI生成内容细粒度定位研究，展示了基于分割方法的潜力和局限性。

Abstract: Diffusion-based editing enables realistic modification of local image regions, making AI-generated content harder to detect. Existing AIGC detection benchmarks focus on classifying entire images, overlooking the localization of diffusion-based edits. We introduce DiffSeg30k, a publicly available dataset of 30k diffusion-edited images with pixel-level annotations, designed to support fine-grained detection. DiffSeg30k features: 1) In-the-wild images--we collect images or image prompts from COCO to reflect real-world content diversity; 2) Diverse diffusion models--local edits using eight SOTA diffusion models; 3) Multi-turn editing--each image undergoes up to three sequential edits to mimic real-world sequential editing; and 4) Realistic editing scenarios--a vision-language model (VLM)-based pipeline automatically identifies meaningful regions and generates context-aware prompts covering additions, removals, and attribute changes. DiffSeg30k shifts AIGC detection from binary classification to semantic segmentation, enabling simultaneous localization of edits and identification of the editing models. We benchmark three baseline segmentation approaches, revealing significant challenges in semantic segmentation tasks, particularly concerning robustness to image distortions. Experiments also reveal that segmentation models, despite being trained for pixel-level localization, emerge as highly reliable whole-image classifiers of diffusion edits, outperforming established forgery classifiers while showing great potential in cross-generator generalization. We believe DiffSeg30k will advance research in fine-grained localization of AI-generated content by demonstrating the promise and limitations of segmentation-based methods. DiffSeg30k is released at: https://huggingface.co/datasets/Chaos2629/Diffseg30k

</details>


### [232] [MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images](https://arxiv.org/abs/2511.19119)
*Qirui Wang,Jingyi He,Yining Pan,Si Yong Yeo,Xulei Yang,Shijie Li*

Main category: cs.CV

TL;DR: MonoSR是一个大规模单目空间推理数据集，涵盖室内、室外和物体中心场景，支持多种问题类型，旨在推动开放世界单目空间推理研究。


<details>
  <summary>Details</summary>
Motivation: 现有空间推理研究主要关注室内环境和多视角观察，限制了其在室外场景的泛化能力和单目图像（最常见真实世界设置）的适用性。

Method: 提出MonoSR数据集，包含多样化场景和问题类型；评估先进视觉语言模型在该任务上的表现；分析辅助信息对单目空间推理的重要性。

Result: 建立了大规模单目空间推理基准数据集，揭示了现有模型在这一挑战性任务上的局限性，并提供了设计未来模型的实用指导。

Conclusion: 这项工作为在真实世界、开放世界环境中推进单目空间推理奠定了重要基础。

Abstract: Spatial reasoning (SR), the ability to infer 3D spatial information from 2D inputs, is essential for real-world applications such as embodied AI and autonomous driving. However, existing research primarily focuses on indoor environments and typically relies on multi-view observations, which limits their generalizability to outdoor scenarios and constrains their applicability to monocular images, the most common real-world setting. In this work, we propose MonoSR, a large-scale monocular spatial reasoning dataset that spans diverse scenarios including indoor, outdoor, and object-centric settings, and supports multiple question types. MonoSR provides a path toward open-world monocular spatial reasoning. Beyond introducing the dataset, we evaluate advanced vision-language models to reveal their limitations on this challenging task. We further analyze whether auxiliary information is crucial for monocular spatial reasoning and offer practical guidance for designing future models. These contributions collectively establish a foundation for advancing monocular spatial reasoning in real-world, open-world environments.

</details>


### [233] [When Semantics Regulate: Rethinking Patch Shuffle and Internal Bias for Generated Image Detection with CLIP](https://arxiv.org/abs/2511.19126)
*Beilin Chu,Weike You,Mengtao Li,Tingting Zheng,Kehan Zhao,Xuan Xu,Zhigao Lu,Jia Song,Moxuan Xu,Linna Zhou*

Main category: cs.CV

TL;DR: 本文提出SemAnti方法，通过冻结CLIP的语义子空间并在打乱语义下仅适配对生成痕迹敏感的层，解决了CLIP检测器在AI生成图像检测中因语义偏差导致的泛化问题，在多个基准测试中达到最先进的跨域泛化性能。


<details>
  <summary>Details</summary>
Motivation: GAN和扩散模型的快速发展对AI生成图像检测提出新挑战。虽然基于CLIP的检测器显示出良好的泛化能力，但它们往往依赖语义线索而非生成器痕迹，导致在分布偏移下性能脆弱。本文重新审视语义偏差的本质，发现打乱图像块能显著帮助CLIP破坏全局语义连续性同时保留局部痕迹线索。

Method: 提出SemAnti语义对抗微调范式：冻结CLIP的语义子空间，在打乱语义下仅适配对生成痕迹敏感的层。通过层间分析发现CLIP的深层语义结构在语义偏差被抑制后能稳定跨域表示。

Result: SemAnti在AIGCDetectBenchmark和GenImage基准测试中实现了最先进的跨域泛化性能，证明调节语义是释放CLIP在鲁棒AI生成图像检测中全部潜力的关键。

Conclusion: 调节语义偏差是提升CLIP在AI生成图像检测中鲁棒性的有效策略，SemAnti方法通过简单的语义对抗微调实现了优异的跨域泛化能力。

Abstract: The rapid progress of GANs and Diffusion Models poses new challenges for detecting AI-generated images. Although CLIP-based detectors exhibit promising generalization, they often rely on semantic cues rather than generator artifacts, leading to brittle performance under distribution shifts. In this work, we revisit the nature of semantic bias and uncover that Patch Shuffle provides an unusually strong benefit for CLIP, that disrupts global semantic continuity while preserving local artifact cues, which reduces semantic entropy and homogenizes feature distributions between natural and synthetic images. Through a detailed layer-wise analysis, we further show that CLIP's deep semantic structure functions as a regulator that stabilizes cross-domain representations once semantic bias is suppressed. Guided by these findings, we propose SemAnti, a semantic-antagonistic fine-tuning paradigm that freezes the semantic subspace and adapts only artifact-sensitive layers under shuffled semantics. Despite its simplicity, SemAnti achieves state-of-the-art cross-domain generalization on AIGCDetectBenchmark and GenImage, demonstrating that regulating semantics is key to unlocking CLIP's full potential for robust AI-generated image detection.

</details>


### [234] [MambaRefine-YOLO: A Dual-Modality Small Object Detector for UAV Imagery](https://arxiv.org/abs/2511.19134)
*Shuyu Cao,Minxin Chen,Yucheng Song,Zhaozhong Chen,Xinyou Zhang*

Main category: cs.CV

TL;DR: MambaRefine-YOLO是一个用于无人机图像中小目标检测的新方法，通过双门控互补Mamba融合模块和分层特征聚合颈部，在RGB和红外数据融合中实现了精度与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 无人机图像中的小目标检测面临低分辨率和背景杂乱的挑战，现有RGB和红外数据融合方法在跨模态交互和计算效率之间存在权衡困难。

Method: 提出了双门控互补Mamba融合模块（DGC-MFM），通过光照感知和差异感知门控机制自适应平衡RGB和红外模态；以及分层特征聚合颈部（HFAN），采用"先优化后融合"策略增强多尺度特征。

Result: 在双模态DroneVehicle数据集上达到83.2%的mAP，比基线提升7.9%；在单模态VisDrone数据集上，仅使用HFAN的变体也显示出显著增益。

Conclusion: 该方法在精度和速度之间实现了优越的平衡，非常适合实际无人机应用。

Abstract: Small object detection in Unmanned Aerial Vehicle (UAV) imagery is a persistent challenge, hindered by low resolution and background clutter. While fusing RGB and infrared (IR) data offers a promising solution, existing methods often struggle with the trade-off between effective cross-modal interaction and computational efficiency. In this letter, we introduce MambaRefine-YOLO. Its core contributions are a Dual-Gated Complementary Mamba fusion module (DGC-MFM) that adaptively balances RGB and IR modalities through illumination-aware and difference-aware gating mechanisms, and a Hierarchical Feature Aggregation Neck (HFAN) that uses a ``refine-then-fuse'' strategy to enhance multi-scale features. Our comprehensive experiments validate this dual-pronged approach. On the dual-modality DroneVehicle dataset, the full model achieves a state-of-the-art mAP of 83.2%, an improvement of 7.9% over the baseline. On the single-modality VisDrone dataset, a variant using only the HFAN also shows significant gains, demonstrating its general applicability. Our work presents a superior balance between accuracy and speed, making it highly suitable for real-world UAV applications.

</details>


### [235] [ABM-LoRA: Activation Boundary Matching for Fast Convergence in Low-Rank Adaptation](https://arxiv.org/abs/2511.19145)
*Dongha Lee,Jinhee Park,Minjun Kim,Junseok Kwon*

Main category: cs.CV

TL;DR: ABM-LoRA是一种新的低秩适配器初始化策略，通过对齐预训练模型的激活边界来加速收敛，减少信息损失。


<details>
  <summary>Details</summary>
Motivation: LoRA虽然参数效率高，但其随机初始化导致梯度更新在失配的切空间中进行，造成显著信息损失并阻碍早期收敛。

Method: 提出激活边界匹配方法，在下游训练前将适配器的激活边界与预训练模型对齐，最大化全参数梯度在适配器子空间中的投影。

Result: 在语言理解、对话生成和视觉识别等任务上验证有效性，在VTAB-1K上达到所有方法中最高的准确率，在需要几何理解的结构化推理任务上表现优异。

Conclusion: ABM-LoRA通过改进初始化策略显著加速低秩适配器的收敛，减少信息损失，在各种架构和任务上表现出色。

Abstract: We propose Activation Boundary Matching for Low-Rank Adaptation (ABM-LoRA), a principled initialization strategy that substantially accelerates the convergence of low-rank adapters. While LoRA offers high parameter efficiency, its random initialization restricts gradient updates to a mismatched tangent space, causing significant information loss and hindering early convergence. Our ABM-LoRA addresses this by aligning the adapter's activation boundaries with those of the pretrained model before downstream training, thereby maximizing the projection of full-parameter gradients into the adapter subspace. This alignment sharply reduces information loss at initialization, yields a lower starting loss, and accelerates convergence. We demonstrate ABM-LoRA's effectiveness across diverse architectures and tasks: language understanding (T5-Base on GLUE), dialogue generation (LLaMA2-7B on WizardLM), and vision recognition (ViT-B/16 on VTAB-1K). On VTAB-1K, it achieves the highest accuracy among all methods, with strong gains on structured reasoning tasks requiring geometric understanding.

</details>


### [236] [MetroGS: Efficient and Stable Reconstruction of Geometrically Accurate High-Fidelity Large-Scale Scenes](https://arxiv.org/abs/2511.19172)
*Kehua Chen,Tianlu Mao,Zhuxin Ma,Hao Jiang,Zehao Li,Zihan Liu,Shuqi Gao,Honglong Zhao,Feng Dai,Yucheng Zhang,Zhaoqi Wang*

Main category: cs.CV

TL;DR: MetroGS是一个用于复杂城市环境高效稳健重建的新型高斯泼溅框架，通过分布式2D高斯泼溅表示、结构化密集增强、渐进式混合几何优化和深度引导外观建模，在大规模城市场景中实现了优越的几何精度和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅及其衍生方法在大规模场景重建中如何高效稳定地实现高质量几何保真度的核心挑战，特别是在复杂城市环境中。

Method: 1. 基于分布式2D高斯泼溅表示作为核心基础；2. 结构化密集增强方案利用SfM先验和点图模型实现更密集初始化；3. 渐进式混合几何优化策略整合单目和多视图优化；4. 深度引导外观建模方法学习具有3D一致性的空间特征。

Result: 在大规模城市数据集上的实验表明，MetroGS实现了优越的几何精度和渲染质量，为高保真大规模场景重建提供了统一解决方案。

Conclusion: MetroGS通过创新的分布式表示、密集增强、几何优化和外观建模方法，有效解决了复杂城市环境中的重建挑战，为大规模场景重建提供了高效稳健的框架。

Abstract: Recently, 3D Gaussian Splatting and its derivatives have achieved significant breakthroughs in large-scale scene reconstruction. However, how to efficiently and stably achieve high-quality geometric fidelity remains a core challenge. To address this issue, we introduce MetroGS, a novel Gaussian Splatting framework for efficient and robust reconstruction in complex urban environments. Our method is built upon a distributed 2D Gaussian Splatting representation as the core foundation, serving as a unified backbone for subsequent modules. To handle potential sparse regions in complex scenes, we propose a structured dense enhancement scheme that utilizes SfM priors and a pointmap model to achieve a denser initialization, while incorporating a sparsity compensation mechanism to improve reconstruction completeness. Furthermore, we design a progressive hybrid geometric optimization strategy that organically integrates monocular and multi-view optimization to achieve efficient and accurate geometric refinement. Finally, to address the appearance inconsistency commonly observed in large-scale scenes, we introduce a depth-guided appearance modeling approach that learns spatial features with 3D consistency, facilitating effective decoupling between geometry and appearance and further enhancing reconstruction stability. Experiments on large-scale urban datasets demonstrate that MetroGS achieves superior geometric accuracy, rendering quality, offering a unified solution for high-fidelity large-scale scene reconstruction.

</details>


### [237] [nnActive: A Framework for Evaluation of Active Learning in 3D Biomedical Segmentation](https://arxiv.org/abs/2511.19183)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jaeger,Fabian Isensee,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: nnActive是一个开源主动学习框架，通过解决3D生物医学图像分割中的四个评估陷阱，揭示了主动学习方法在改进的随机采样基准下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 3D生物医学图像语义分割依赖大量标注数据，但人工标注成本高昂。主动学习旨在通过选择信息量最大的样本减少标注工作量，但现有评估存在四个主要问题。

Method: 开发nnActive框架，包含大规模研究（4个数据集、3种标注机制）、扩展nnU-Net使用部分标注进行3D补丁查询选择、提出前景感知随机采样策略、引入前景效率指标。

Result: 发现：(A)所有主动学习方法都优于标准随机采样，但无法可靠超越改进的前景感知随机采样；(B)主动学习收益依赖任务特定参数；(C)预测熵是整体最佳方法但标注成本可能最高；(D)计算密集型设计可提升主动学习性能。

Conclusion: nnActive作为整体开源框架，可促进3D生物医学图像中主动学习的研究和应用。

Abstract: Semantic segmentation is crucial for various biomedical applications, yet its reliance on large annotated datasets presents a bottleneck due to the high cost and specialized expertise required for manual labeling. Active Learning (AL) aims to mitigate this challenge by querying only the most informative samples, thereby reducing annotation effort. However, in the domain of 3D biomedical imaging, there is no consensus on whether AL consistently outperforms Random sampling. Four evaluation pitfalls hinder the current methodological assessment. These are (1) restriction to too few datasets and annotation budgets, (2) using 2D models on 3D images without partial annotations, (3) Random baseline not being adapted to the task, and (4) measuring annotation cost only in voxels. In this work, we introduce nnActive, an open-source AL framework that overcomes these pitfalls by (1) means of a large scale study spanning four biomedical imaging datasets and three label regimes, (2) extending nnU-Net by using partial annotations for training with 3D patch-based query selection, (3) proposing Foreground Aware Random sampling strategies tackling the foreground-background class imbalance of medical images and (4) propose the foreground efficiency metric, which captures the low annotation cost of background-regions. We reveal the following findings: (A) while all AL methods outperform standard Random sampling, none reliably surpasses an improved Foreground Aware Random sampling; (B) benefits of AL depend on task specific parameters; (C) Predictive Entropy is overall the best performing AL method, but likely requires the most annotation effort; (D) AL performance can be improved with more compute intensive design choices. As a holistic, open-source framework, nnActive can serve as a catalyst for research and application of AL in 3D biomedical imaging. Code is at: https://github.com/MIC-DKFZ/nnActive

</details>


### [238] [Can Modern Vision Models Understand the Difference Between an Object and a Look-alike?](https://arxiv.org/abs/2511.19200)
*Itay Cohen,Ethan Fetaya,Amir Rosenfeld*

Main category: cs.CV

TL;DR: 该研究探讨了视觉语言模型CLIP是否能区分真实物体与其相似物，创建了RoLA数据集，并开发了在CLIP嵌入空间中区分真实与相似物的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管计算机视觉模型在识别基准上表现良好，但与人类感知相比仍存在差距，特别是在判断图像是否像某个物体而非其实例方面。

Method: 创建RoLA数据集包含真实物体和相似物，评估基于提示的基线方法，然后在CLIP嵌入空间中估计区分真实与相似物的方向向量。

Result: 应用该方向向量改进了跨模态检索性能，并提升了CLIP前缀字幕生成器的字幕质量。

Conclusion: CLIP能够捕捉真实物体与相似物之间的细微区别，通过在嵌入空间中学习区分方向可以提升模型性能。

Abstract: Recent advances in computer vision have yielded models with strong performance on recognition benchmarks; however, significant gaps remain in comparison to human perception. One subtle ability is to judge whether an image looks like a given object without being an instance of that object. We study whether vision-language models such as CLIP capture this distinction. We curated a dataset named RoLA (Real or Lookalike) of real and lookalike exemplars (e.g., toys, statues, drawings, pareidolia) across multiple categories, and first evaluate a prompt-based baseline with paired "real"/"lookalike" prompts. We then estimate a direction in CLIP's embedding space that moves representations between real and lookalike. Applying this direction to image and text embeddings improves discrimination in cross-modal retrieval on Conceptual12M, and also enhances captions produced by a CLIP prefix captioner.

</details>


### [239] [NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting](https://arxiv.org/abs/2511.19202)
*Brent Zoomers,Florian Hahlbohm,Joni Vanherck,Lode Jorissen,Marcus Magnor,Nick Michiels*

Main category: cs.CV

TL;DR: 提出了一种新方法，使用共享MLP学习3D高斯模型中所有高斯体的视角相关可见性函数，通过查询视锥体内的可见性来在渲染时丢弃被遮挡的基元，从而解决半透明高斯体无法应用遮挡剔除的问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅可以利用视锥剔除和细节层次策略加速包含大量基元的场景渲染，但高斯体的半透明特性阻碍了遮挡剔除这一高效技术的应用。

Method: 使用小型共享MLP学习训练模型中所有高斯体的视角相关可见性函数，在光栅化前查询视锥内高斯体的可见性，将被遮挡基元丢弃。结合Tensor Core高效计算，将神经查询直接集成到新的实例化软件光栅器中。

Result: 在组合场景的VRAM使用和图像质量方面优于当前最先进方法，结合实例化光栅器和遮挡剔除MLP，与现有LoD技术具有互补特性。

Conclusion: 该方法成功解决了3D高斯泼溅中遮挡剔除的应用限制，通过神经可见性查询实现了高效的渲染优化。

Abstract: 3D Gaussian Splatting can exploit frustum culling and level-of-detail strategies to accelerate rendering of scenes containing a large number of primitives. However, the semi-transparent nature of Gaussians prevents the application of another highly effective technique: occlusion culling. We address this limitation by proposing a novel method to learn the viewpoint-dependent visibility function of all Gaussians in a trained model using a small, shared MLP across instances of an asset in a scene. By querying it for Gaussians within the viewing frustum prior to rasterization, our method can discard occluded primitives during rendering. Leveraging Tensor Cores for efficient computation, we integrate these neural queries directly into a novel instanced software rasterizer. Our approach outperforms the current state of the art for composed scenes in terms of VRAM usage and image quality, utilizing a combination of our instanced rasterizer and occlusion culling MLP, and exhibits complementary properties to existing LoD techniques.

</details>


### [240] [ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment](https://arxiv.org/abs/2511.19217)
*Wanjiang Weng,Xiaofeng Tan,Junbo Wang,Guo-Sen Xie,Pan Zhou,Hongsong Wang*

Main category: cs.CV

TL;DR: 提出ReAlign方法，通过奖励引导采样解决文本-运动生成中的分布不对齐问题，提升语义一致性和运动质量


<details>
  <summary>Details</summary>
Motivation: 扩散模型在文本到运动生成中存在文本与运动分布不对齐问题，导致语义不一致或低质量运动

Method: 提出Reward-guided sampling Alignment (ReAlign)，包含评估对齐质量的步感知奖励模型和引导扩散过程的对齐策略，结合文本对齐模块和运动对齐模块

Result: 在运动和检索任务上的广泛实验表明，相比现有最优方法，显著提升了文本-运动对齐和运动质量

Conclusion: ReAlign方法有效解决了文本-运动生成中的分布不对齐问题，提高了生成运动的语义一致性和质量

Abstract: Text-to-motion generation, which synthesizes 3D human motions from text inputs, holds immense potential for applications in gaming, film, and robotics. Recently, diffusion-based methods have been shown to generate more diversity and realistic motion. However, there exists a misalignment between text and motion distributions in diffusion models, which leads to semantically inconsistent or low-quality motions. To address this limitation, we propose Reward-guided sampling Alignment (ReAlign), comprising a step-aware reward model to assess alignment quality during the denoising sampling and a reward-guided strategy that directs the diffusion process toward an optimally aligned distribution. This reward model integrates step-aware tokens and combines a text-aligned module for semantic consistency and a motion-aligned module for realism, refining noisy motions at each timestep to balance probability density and alignment. Extensive experiments of both motion generation and retrieval tasks demonstrate that our approach significantly improves text-motion alignment and motion quality compared to existing state-of-the-art methods.

</details>


### [241] [Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving](https://arxiv.org/abs/2511.19221)
*Jianhua Han,Meng Tian,Jiangtong Zhu,Fan He,Huixin Zhang,Sitong Guo,Dechang Zhu,Hao Tang,Pei Xu,Yuze Guo,Minzhe Niu,Haojie Zhu,Qichao Dong,Xuechao Yan,Siyuan Dong,Lu Hou,Qingqiu Huang,Xiaosong Jia,Hang Xu*

Main category: cs.CV

TL;DR: Percept-WAM是一个感知增强的世界感知-行动模型，首次在单个视觉语言模型中隐式集成2D/3D场景理解能力，通过World-PV和World-BEV令牌统一感知任务，提升自动驾驶在长尾场景和复杂交互中的感知稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统在长尾场景和复杂交互中存在感知不准确和不稳定的问题，而现有视觉语言模型在空间定位和理解方面较弱，限制了感知和定位能力。

Method: 提出网格条件预测机制进行密集目标感知，包含IoU感知评分和并行自回归解码；利用预训练VLM参数保持通用智能；直接输出感知结果和轨迹控制输出。

Result: 在COCO 2D检测上达到51.7/58.9 mAP，在nuScenes BEV 3D检测上表现优异；与轨迹解码器集成后，在NAVSIM上超越DiffusionDrive 2.1 PMDS；展现出强大的开放词汇和长尾泛化能力。

Conclusion: Percept-WAM成功将2D/3D感知能力集成到单一VLM中，显著提升了自动驾驶系统的感知稳定性和规划性能，特别是在长尾和复杂场景中。

Abstract: Autonomous driving heavily relies on accurate and robust spatial perception. Many failures arise from inaccuracies and instability, especially in long-tail scenarios and complex interactions. However, current vision-language models are weak at spatial grounding and understanding, and VLA systems built on them therefore show limited perception and localization ability. To address these challenges, we introduce Percept-WAM, a perception-enhanced World-Awareness-Action Model that is the first to implicitly integrate 2D/3D scene understanding abilities within a single vision-language model (VLM). Instead of relying on QA-style spatial reasoning, Percept-WAM unifies 2D/3D perception tasks into World-PV and World-BEV tokens, which encode both spatial coordinates and confidence. We propose a grid-conditioned prediction mechanism for dense object perception, incorporating IoU-aware scoring and parallel autoregressive decoding, improving stability in long-tail, far-range, and small-object scenarios. Additionally, Percept-WAM leverages pretrained VLM parameters to retain general intelligence (e.g., logical reasoning) and can output perception results and trajectory control outputs directly. Experiments show that Percept-WAM matches or surpasses classical detectors and segmenters on downstream perception benchmarks, achieving 51.7/58.9 mAP on COCO 2D detection and nuScenes BEV 3D detection. When integrated with trajectory decoders, it further improves planning performance on nuScenes and NAVSIM, e.g., surpassing DiffusionDrive by 2.1 in PMDS on NAVSIM. Qualitative results further highlight its strong open-vocabulary and long-tail generalization.

</details>


### [242] [IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2511.19235)
*Carl Lindström,Mahan Rafidashti,Maryam Fatemi,Lars Hammarstrand,Martin R. Oswald,Lennart Svensson*

Main category: cs.CV

TL;DR: IDSplat是一个自监督的3D高斯泼溅框架，无需人工标注即可重建动态驾驶场景，实现显式的实例分解和可学习的运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有的动态场景重建方法要么依赖昂贵的人工标注，要么使用时变表示而不进行显式的对象级分解，导致静态和动态元素交织，难以分离场景。

Method: 将动态对象建模为经历刚性变换的连贯实例；使用基于语言的零样本视频跟踪与激光雷达进行3D锚定；通过特征对应估计一致姿态；引入协调转向平滑方案获得时间物理一致的运动轨迹；联合优化对象姿态和高斯参数。

Result: 在Waymo Open Dataset上的实验表明，该方法实现了竞争性的重建质量，同时保持实例级分解，并能跨不同序列和视图密度泛化而无需重新训练。

Conclusion: IDSplat为大规模自动驾驶应用提供了一种实用的动态场景重建解决方案，无需人工标注即可实现高质量的实例分解重建。

Abstract: Reconstructing dynamic driving scenes is essential for developing autonomous systems through sensor-realistic simulation. Although recent methods achieve high-fidelity reconstructions, they either rely on costly human annotations for object trajectories or use time-varying representations without explicit object-level decomposition, leading to intertwined static and dynamic elements that hinder scene separation. We present IDSplat, a self-supervised 3D Gaussian Splatting framework that reconstructs dynamic scenes with explicit instance decomposition and learnable motion trajectories, without requiring human annotations. Our key insight is to model dynamic objects as coherent instances undergoing rigid transformations, rather than unstructured time-varying primitives. For instance decomposition, we employ zero-shot, language-grounded video tracking anchored to 3D using lidar, and estimate consistent poses via feature correspondences. We introduce a coordinated-turn smoothing scheme to obtain temporally and physically consistent motion trajectories, mitigating pose misalignments and tracking failures, followed by joint optimization of object poses and Gaussian parameters. Experiments on the Waymo Open Dataset demonstrate that our method achieves competitive reconstruction quality while maintaining instance-level decomposition and generalizes across diverse sequences and view densities without retraining, making it practical for large-scale autonomous driving applications. Code will be released.

</details>


### [243] [LAST: LeArning to Think in Space and Time for Generalist Vision-Language Models](https://arxiv.org/abs/2511.19261)
*Shuai Wang,Daoan Zhang,Tianyi Bai,Shitong Shao,Jiebo Luo,Jiaheng Wei*

Main category: cs.CV

TL;DR: LAST方法通过让视觉语言模型在空间和时间维度上构建视觉思维轨迹，联合提升3D空间理解和长视频理解能力，仅使用2D图像作为输入。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉语言模型在3D空间理解和长视频理解方面仍然表现不佳，尽管它们在典型的视觉语言任务上很强大。现有方法通常依赖专门的架构设计来分别改进3D任务和视频理解任务的性能。

Method: 提出LAST方法，让视觉语言模型在给出最终答案前在空间和时间维度上进行思考，构建3D空间和时间维度的视觉思维轨迹。通过两种场景实现：1）零样本场景下直接提示专有模型；2）使用包含空间和时间思维轨迹的数据微调通用视觉语言模型。

Result: LAST在各种基准测试中带来了显著提升，包括3个空间理解任务、4个视频理解任务和3个图像理解任务。在零样本场景下，GPT-4o在EgoSchema上获得15.8%的提升；与Qwen2.5-VL-7B相比，在VSI-Bench上获得8.3的提升。

Conclusion: LAST方法能够有效提升视觉语言模型在3D空间和长视频理解方面的能力，仅使用2D图像输入即可实现联合改进。

Abstract: Humans can perceive and understand 3D space and long videos from sequential visual observations. But do vision-language models (VLMs) can? Recent work demonstrates that even state-of-the-art VLMs still struggle to understand 3D space and long videos, although they are powerful in typical vision-language tasks. Current methods often rely on specialized architectural designs to improve performance for 3D tasks and video understanding tasks separately. In contrast, we propose LAST, short for LeArn to Think in Space and Time, to jointly improve 3D spatial and long video understanding for general VLMs with only a set of 2D images as inputs. LAST makes VLMs think in space and time rather than only with text before giving the final answer, building visual thinking trajectories in 3D space and temporal dimension. We demonstrate the effectiveness of LAST in two scenarios: 1) zero-shot, where we directly prompt proprietary models; and 2) fine-tuning general VLMs with data that include thinking trajectories in 3D space and time. We show that LAST brings substantial gains in various benchmarks, including 3 spatial understanding, 4 video understanding, and 3 image understanding tasks. Notably, 15.8% gains on EgoSchema with GPT-4o in a zero-shot manner and 8.3 gains on VSI-Bench compared with Qwen2.5-VL-7B.

</details>


### [244] [BideDPO: Conditional Image Generation with Simultaneous Text and Condition Alignment](https://arxiv.org/abs/2511.19268)
*Dewei Zhou,Mingwei Li,Zongxin Yang,Yu Lu,Yunqiu Xu,Zhizhong Wang,Zeyi Huang,Yi Yang*

Main category: cs.CV

TL;DR: 本文提出BideDPO框架，通过双向解耦的偏好优化方法解决条件图像生成中文本与条件图像之间的冲突问题，显著提升了文本成功率和条件遵循度。


<details>
  <summary>Details</summary>
Motivation: 当前条件图像生成方法在处理文本提示与条件图像之间的冲突时面临挑战，包括输入级冲突和模型偏置冲突，标准的监督微调难以有效解决这些问题。

Method: 提出双向解耦DPO框架，创建两个解耦的偏好对（一个针对条件，一个针对文本），使用自适应损失平衡策略管理偏好对的影响，并构建自动化数据管道进行迭代优化。

Result: 实验表明BideDPO显著提高了文本成功率（如+35%）和条件遵循度，在构建的DualAlign基准测试中表现出色。

Conclusion: BideDPO框架有效解决了条件图像生成中的冲突问题，为多约束任务的偏好优化提供了新思路。

Abstract: Conditional image generation enhances text-to-image synthesis with structural, spatial, or stylistic priors, but current methods face challenges in handling conflicts between sources. These include 1) input-level conflicts, where the conditioning image contradicts the text prompt, and 2) model-bias conflicts, where generative biases disrupt alignment even when conditions match the text. Addressing these conflicts requires nuanced solutions, which standard supervised fine-tuning struggles to provide. Preference-based optimization techniques like Direct Preference Optimization (DPO) show promise but are limited by gradient entanglement between text and condition signals and lack disentangled training data for multi-constraint tasks. To overcome this, we propose a bidirectionally decoupled DPO framework (BideDPO). Our method creates two disentangled preference pairs-one for the condition and one for the text-to reduce gradient entanglement. The influence of pairs is managed using an Adaptive Loss Balancing strategy for balanced optimization. We introduce an automated data pipeline to sample model outputs and generate conflict-aware data. This process is embedded in an iterative optimization strategy that refines both the model and the data. We construct a DualAlign benchmark to evaluate conflict resolution between text and condition. Experiments show BideDPO significantly improves text success rates (e.g., +35%) and condition adherence. We also validate our approach using the COCO dataset. Project Pages: https://limuloo.github.io/BideDPO/.

</details>


### [245] [Diffusion Reconstruction-based Data Likelihood Estimation for Core-Set Selection](https://arxiv.org/abs/2511.19274)
*Mingyang Chen,Jiawei Du,Bo Huang,Yi Wang,Xiaobo Zhang,Wei Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的数据似然估计方法，通过部分反向去噪诱导的重构偏差来构建核心集选择的理论基础，在ImageNet上仅用50%数据就能达到全数据训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有核心集选择方法主要依赖启发式评分信号（如训练动态或模型不确定性），缺乏对数据似然的显式建模，这可能导致构建的子集无法捕捉支撑有效模型训练的微妙但关键的分布结构。

Method: 利用扩散模型通过部分反向去噪诱导的重构偏差来估计数据似然，基于马尔可夫扩散过程的证据下界建立重构误差与数据似然的正式联系，并提出信息论方法确定最优重构时间步。

Result: 在ImageNet上的广泛实验表明，重构偏差提供了有效的评分标准，在不同选择比率下始终优于现有基线方法，仅使用50%数据就能紧密匹配全数据训练效果。

Conclusion: 基于似然信息的评分方法在数据选择中揭示了有意义的见解，阐明了数据分布特征与模型学习偏好之间的相互作用。

Abstract: Existing core-set selection methods predominantly rely on heuristic scoring signals such as training dynamics or model uncertainty, lacking explicit modeling of data likelihood. This omission may hinder the constructed subset from capturing subtle yet critical distributional structures that underpin effective model training. In this work, we propose a novel, theoretically grounded approach that leverages diffusion models to estimate data likelihood via reconstruction deviation induced by partial reverse denoising. Specifically, we establish a formal connection between reconstruction error and data likelihood, grounded in the Evidence Lower Bound (ELBO) of Markovian diffusion processes, thereby enabling a principled, distribution-aware scoring criterion for data selection. Complementarily, we introduce an efficient information-theoretic method to identify the optimal reconstruction timestep, ensuring that the deviation provides a reliable signal indicative of underlying data likelihood. Extensive experiments on ImageNet demonstrate that reconstruction deviation offers an effective scoring criterion, consistently outperforming existing baselines across selection ratios, and closely matching full-data training using only 50% of the data. Further analysis shows that the likelihood-informed nature of our score reveals informative insights in data selection, shedding light on the interplay between data distributional characteristics and model learning preferences.

</details>


### [246] [ReMatch: Boosting Representation through Matching for Multimodal Retrieval](https://arxiv.org/abs/2511.19278)
*Qianying Liu,Xiao Liang,Zhiqiang Zhang,Yibo Chen,Xu Tang,Zhongfei Qing,Fengfan Zhou,Yao Hu,Paul Henderson*

Main category: cs.CV

TL;DR: ReMatch是一个利用多模态大语言模型生成能力进行多模态检索的框架，通过端到端训练嵌入MLLM和生成式匹配阶段，实现更好的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将MLLM视为简单编码器，忽略了其生成特性和组合推理能力，未能充分利用其世界知识。

Method: 使用聊天式生成匹配阶段，让MLLM自回归地判断相关性；使用多个可学习token增强输入，生成细粒度上下文嵌入；结合对比损失和实例级判别监督。

Result: 在Massive Multimodal Embedding Benchmark上达到新的最先进水平，在五个数据集上表现出特别强的零样本泛化结果。

Conclusion: ReMatch框架通过充分利用MLLM的生成能力和组合优势，实现了鲁棒且可迁移的多模态检索性能。

Abstract: We present ReMatch, a framework that leverages the generative strength of MLLMs for multimodal retrieval. Previous approaches treated an MLLM as a simple encoder, ignoring its generative nature, and under-utilising its compositional reasoning and world knowledge. We instead train the embedding MLLM end-to-end with a chat-style generative matching stage. The matching stage uses the same MLLM to autoregressively decide relevance from multi-view inputs, including both raw data and its own projected embeddings for each query and document. It provides instance-wise discrimination supervision that complements a standard contrastive loss, offering stronger gradients on hard negatives and preserving the compositional strengths of the original MLLM. To obtain semantically richer multimodal embeddings, we use multiple learnable tokens to augment each input, generating fine-grained contextual, mutually orthogonal embeddings with low inference cost. Leveraging our established high-performance baseline,we assemble the ideas mentioned above into a powerful training recipe and achieve a new state-of-the-art on the Massive Multimodal Embedding Benchmark (MMEB). Our experiments show particularly strong zero-shot generalization results on five datasets, highlighting the robustness and transferability of ReMatch.

</details>


### [247] [DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting](https://arxiv.org/abs/2511.19294)
*Phurtivilai Patt,Leyang Huang,Yinqiang Zhang,Yang Lei*

Main category: cs.CV

TL;DR: 本文提出了一种新的3D高斯泼溅方法，通过结合稀疏LiDAR数据和单目深度估计来预先密集化场景，避免了传统自适应密度控制导致的浮点伪影和资源浪费问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法依赖自适应密度控制，这会导致浮点伪影和低效的资源使用，需要改进初始化过程以提高视觉质量和计算效率。

Method: 采用预先密集化方法，结合稀疏LiDAR数据和RGB图像的单目深度估计，使用ROI感知采样方案优先处理语义和几何重要区域，生成密集点云。

Result: 该方法在保持与最先进技术相当结果的同时，显著降低了资源消耗和训练时间，在四个新收集的数据集上验证了其有效性。

Conclusion: 提出的预先密集化方法通过绕过自适应密度控制，使优化专注于3D高斯基元的其他属性，减少了重叠同时提高了视觉质量，在复杂场景中有效保留了感兴趣区域。

Abstract: This paper addresses the limitations of existing 3D Gaussian Splatting (3DGS) methods, particularly their reliance on adaptive density control, which can lead to floating artifacts and inefficient resource usage. We propose a novel densify beforehand approach that enhances the initialization of 3D scenes by combining sparse LiDAR data with monocular depth estimation from corresponding RGB images. Our ROI-aware sampling scheme prioritizes semantically and geometrically important regions, yielding a dense point cloud that improves visual fidelity and computational efficiency. This densify beforehand approach bypasses the adaptive density control that may introduce redundant Gaussians in the original pipeline, allowing the optimization to focus on the other attributes of 3D Gaussian primitives, reducing overlap while enhancing visual quality. Our method achieves comparable results to state-of-the-art techniques while significantly lowering resource consumption and training time. We validate our approach through extensive comparisons and ablation studies on four newly collected datasets, showcasing its effectiveness in preserving regions of interest in complex scenes.

</details>


### [248] [Dual-Granularity Semantic Prompting for Language Guidance Infrared Small Target Detection](https://arxiv.org/abs/2511.19306)
*Zixuan Wang,Haoran Sun,Jiaming Lu,Wenxuan Wang,Zhongling Huang,Dingwen Zhang,Xuelin Qian,Junwei Han*

Main category: cs.CV

TL;DR: 本文提出DGSPNet，一种端到端的语言提示驱动框架，通过双粒度语义提示（粗粒度文本先验和细粒度个性化语义描述）和文本引导注意力机制，显著提升红外小目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有红外小目标检测方法存在特征表示有限和背景干扰严重的问题，而基于CLIP的方法又受限于不准确的文本描述和对人工标注的依赖。

Method: 提出DGSPNet框架，集成双粒度语义提示：粗粒度文本先验和通过视觉到文本映射获得的细粒度个性化语义描述。同时引入文本引导通道注意力（TGCA）和文本引导空间注意力（TGSA）机制。

Result: 在三个基准数据集上的大量实验表明，该方法显著提高了检测精度，并达到了最先进的性能。

Conclusion: DGSPNet通过语言提示驱动和双粒度语义提示，有效提升了红外小目标检测性能，无需依赖任何标注要求。

Abstract: Infrared small target detection remains challenging due to limited feature representation and severe background interference, resulting in sub-optimal performance. While recent CLIP-inspired methods attempt to leverage textual guidance for detection, they are hindered by inaccurate text descriptions and reliance on manual annotations. To overcome these limitations, we propose DGSPNet, an end-to-end language prompt-driven framework. Our approach integrates dual-granularity semantic prompts: coarse-grained textual priors (e.g., 'infrared image', 'small target') and fine-grained personalized semantic descriptions derived through visual-to-textual mapping within the image space. This design not only facilitates learning fine-grained semantic information but also can inherently leverage language prompts during inference without relying on any annotation requirements. By fully leveraging the precision and conciseness of text descriptions, we further introduce a text-guide channel attention (TGCA) mechanism and text-guide spatial attention (TGSA) mechanism that enhances the model's sensitivity to potential targets across both low- and high-level feature spaces. Extensive experiments demonstrate that our method significantly improves detection accuracy and achieves state-of-the-art performance on three benchmark datasets.

</details>


### [249] [SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis](https://arxiv.org/abs/2511.19319)
*Lingwei Dang,Zonghan Li,Juntong Li,Hongwen Zhang,Liang An,Yebin Liu,Qingyao Wu*

Main category: cs.CV

TL;DR: SyncMV4D是首个联合生成同步多视角手-物交互视频和4D运动的模型，通过统一视觉先验、运动动力学和多视角几何来克服现有单视角方法和3D方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于视频的方法主要是单视角的，阻碍了全面的3D几何感知，常导致几何失真或不真实的运动模式。而3D HOI方法虽然能生成动态合理的运动，但对高质量3D数据的依赖限制了其在实际场景中的泛化能力。

Method: 提出两个核心创新：(1)多视角联合扩散模型(MJD)共同生成HOI视频和中间运动；(2)扩散点对齐器(DPA)将粗糙的中间运动细化为全局对齐的4D度量点轨迹。通过建立闭环、相互增强的循环，在扩散去噪过程中，生成的视频条件化4D运动的细化，而对齐的4D点轨迹被重投影以指导下一步的联合生成。

Result: 实验表明，该方法在视觉真实性、运动合理性和多视角一致性方面优于现有最先进方法。

Conclusion: SyncMV4D通过统一视觉先验、运动动力学和多视角几何，成功实现了同步多视角HOI视频和4D运动的联合生成，克服了现有方法的局限性。

Abstract: Hand-Object Interaction (HOI) generation plays a critical role in advancing applications across animation and robotics. Current video-based methods are predominantly single-view, which impedes comprehensive 3D geometry perception and often results in geometric distortions or unrealistic motion patterns. While 3D HOI approaches can generate dynamically plausible motions, their dependence on high-quality 3D data captured in controlled laboratory settings severely limits their generalization to real-world scenarios. To overcome these limitations, we introduce SyncMV4D, the first model that jointly generates synchronized multi-view HOI videos and 4D motions by unifying visual prior, motion dynamics, and multi-view geometry. Our framework features two core innovations: (1) a Multi-view Joint Diffusion (MJD) model that co-generates HOI videos and intermediate motions, and (2) a Diffusion Points Aligner (DPA) that refines the coarse intermediate motion into globally aligned 4D metric point tracks. To tightly couple 2D appearance with 4D dynamics, we establish a closed-loop, mutually enhancing cycle. During the diffusion denoising process, the generated video conditions the refinement of the 4D motion, while the aligned 4D point tracks are reprojected to guide next-step joint generation. Experimentally, our method demonstrates superior performance to state-of-the-art alternatives in visual realism, motion plausibility, and multi-view consistency.

</details>


### [250] [SteadyDancer: Harmonized and Coherent Human Image Animation with First-Frame Preservation](https://arxiv.org/abs/2511.19320)
*Jiaming Zhang,Shengming Cao,Rui Li,Xiaotong Zhao,Yutao Cui,Xinglin Hou,Gangshan Wu,Haolan Chen,Yu Xu,Limin Wang,Kai Ma*

Main category: cs.CV

TL;DR: SteadyDancer是一个基于图像到视频(I2V)范式的框架，解决了人类图像动画中保持第一帧身份和精确运动控制的挑战，通过条件协调机制、协同姿态调制模块和分阶段解耦目标训练管道实现协调一致的动画效果。


<details>
  <summary>Details</summary>
Motivation: 现有的参考到视频(R2V)范式在图像到运动绑定过程中忽略了现实应用中常见的时空错位问题，导致身份漂移和视觉伪影等失败情况。需要开发能够稳健保持第一帧身份并确保精确运动控制的解决方案。

Method: 1. 条件协调机制：协调两个冲突条件，实现精确控制而不牺牲保真度
2. 协同姿态调制模块：生成与参考图像高度兼容的自适应连贯姿态表示
3. 分阶段解耦目标训练管道：分层优化模型以实现运动保真度、视觉质量和时间连贯性

Result: 实验表明，SteadyDancer在外观保真度和运动控制方面都达到了最先进的性能，同时比同类方法需要显著更少的训练资源。

Conclusion: SteadyDancer是第一个能够稳健确保第一帧保持的框架，在人类图像动画中实现了协调一致的动画效果，在保持身份的同时提供精确的运动控制。

Abstract: Preserving first-frame identity while ensuring precise motion control is a fundamental challenge in human image animation. The Image-to-Motion Binding process of the dominant Reference-to-Video (R2V) paradigm overlooks critical spatio-temporal misalignments common in real-world applications, leading to failures such as identity drift and visual artifacts. We introduce SteadyDancer, an Image-to-Video (I2V) paradigm-based framework that achieves harmonized and coherent animation and is the first to ensure first-frame preservation robustly. Firstly, we propose a Condition-Reconciliation Mechanism to harmonize the two conflicting conditions, enabling precise control without sacrificing fidelity. Secondly, we design Synergistic Pose Modulation Modules to generate an adaptive and coherent pose representation that is highly compatible with the reference image. Finally, we employ a Staged Decoupled-Objective Training Pipeline that hierarchically optimizes the model for motion fidelity, visual quality, and temporal coherence. Experiments demonstrate that SteadyDancer achieves state-of-the-art performance in both appearance fidelity and motion control, while requiring significantly fewer training resources than comparable methods.

</details>


### [251] [POUR: A Provably Optimal Method for Unlearning Representations via Neural Collapse](https://arxiv.org/abs/2511.19339)
*Anjie Le,Can Peng,Yuyuan Liu,J. Alison Noble*

Main category: cs.CV

TL;DR: 本文提出POUR方法，通过几何投影在表示层面实现机器遗忘，证明正交投影保持ETF结构，提供闭式解和蒸馏变体，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法主要修改分类器而保留内部表示，导致不完整遗忘。本文旨在将遗忘扩展到表示层面，实现更彻底的遗忘效果。

Method: 基于神经崩溃理论，证明正交投影保持ETF结构，提出POUR方法：闭式几何投影(POUR-P)和基于蒸馏的特征级遗忘变体(POUR-D)。

Result: 在CIFAR-10/100和PathMNIST数据集上，POUR在分类级和表示级指标上均优于现有最先进的遗忘方法，有效实现遗忘同时保留知识。

Conclusion: POUR通过表示层面的几何投影实现了可证明最优的遗忘操作，建立了遗忘效能、保留保真度和类别分离之间的理论联系，为机器遗忘提供了新的解决方案。

Abstract: In computer vision, machine unlearning aims to remove the influence of specific visual concepts or training images without retraining from scratch. Studies show that existing approaches often modify the classifier while leaving internal representations intact, resulting in incomplete forgetting. In this work, we extend the notion of unlearning to the representation level, deriving a three-term interplay between forgetting efficacy, retention fidelity, and class separation. Building on Neural Collapse theory, we show that the orthogonal projection of a simplex Equiangular Tight Frame (ETF) remains an ETF in a lower dimensional space, yielding a provably optimal forgetting operator. We further introduce the Representation Unlearning Score (RUS) to quantify representation-level forgetting and retention fidelity. Building on this, we introduce POUR (Provably Optimal Unlearning of Representations), a geometric projection method with closed-form (POUR-P) and a feature-level unlearning variant under a distillation scheme (POUR-D). Experiments on CIFAR-10/100 and PathMNIST demonstrate that POUR achieves effective unlearning while preserving retained knowledge, outperforming state-of-the-art unlearning methods on both classification-level and representation-level metrics.

</details>


### [252] [Syn-GRPO: Self-Evolving Data Synthesis for MLLM Perception Reasoning](https://arxiv.org/abs/2511.19343)
*Qihan Huang,Haofei Zhang,Rong Wei,Yi Wang,Rui Tang,Mingli Song,Jie Song*

Main category: cs.CV

TL;DR: 本文提出Syn-GRPO方法，通过在线数据生成器合成高质量多样化训练数据，解决MLLM强化学习中数据质量低的问题，在三个视觉感知任务上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM强化学习方法面临数据质量低的问题，数据样本无法激发MLLM的多样化响应，限制了强化学习的探索范围。虽然有些方法尝试通过熵约束缓解此问题，但未能从根本上解决。

Method: Syn-GRPO包含两个组件：数据服务器和GRPO工作流。数据服务器使用图像生成模型从现有样本合成新样本，采用解耦异步方案实现高生成效率；GRPO工作流向数据服务器提供新图像描述，并利用多样性奖励监督MLLM预测图像描述以合成多样化响应样本。

Result: 在三个视觉感知任务上的实验结果表明，Syn-GRPO大幅提高了数据质量，性能显著优于现有MLLM感知方法，并展现出长期自我演化强化学习的潜力。

Conclusion: Syn-GRPO通过合成高质量多样化训练数据有效解决了MLLM强化学习中的数据质量问题，为长期自我演化强化学习提供了有前景的方向。

Abstract: RL (reinforcement learning) methods (e.g., GRPO) for MLLM (Multimodal LLM) perception ability has attracted wide research interest owing to its remarkable generalization ability. Nevertheless, existing reinforcement learning methods still face the problem of low data quality, where data samples cannot elicit diverse responses from MLLMs, thus restricting the exploration scope for MLLM reinforcement learning. Some methods attempt to mitigate this problem by imposing constraints on entropy, but none address it at its root. Therefore, to tackle this problem, this work proposes Syn-GRPO (Synthesis-GRPO), which employs an online data generator to synthesize high-quality training data with diverse responses in GRPO training. Specifically, Syn-GRPO consists of two components: (1) data server; (2) GRPO workflow. The data server synthesizes new samples from existing ones using an image generation model, featuring a decoupled and asynchronous scheme to achieve high generation efficiency. The GRPO workflow provides the data server with the new image descriptions, and it leverages a diversity reward to supervise the MLLM to predict image descriptions for synthesizing samples with diverse responses. Experiment results across three visual perception tasks demonstrate that Syn-GRPO improves the data quality by a large margin, achieving significant superior performance to existing MLLM perception methods, and Syn-GRPO presents promising potential for scaling long-term self-evolving RL. Our code is available at https://github.com/hqhQAQ/Syn-GRPO.

</details>


### [253] [CellFMCount: A Fluorescence Microscopy Dataset, Benchmark, and Methods for Cell Counting](https://arxiv.org/abs/2511.19351)
*Abdurahman Ali Mohammed,Catherine Fonder,Ying Wei,Wallapak Tavanapong,Donald S Sakaguchi,Qi Li,Surya K. Mallapragada*

Main category: cs.CV

TL;DR: 本文提出了一个包含3,023张图像、430,000多个手动标注细胞位置的大规模细胞计数数据集，并评估了现有方法在该数据集上的表现，同时展示了SAM模型在细胞计数任务中的适应性。


<details>
  <summary>Details</summary>
Motivation: 准确的细胞计数在生物医学研究和临床应用中至关重要，但手动计数耗时且易出错。现有细胞计数数据集通常规模有限（少于500张图像），难以训练可靠的深度学习模型。

Method: 构建大规模免疫细胞化学实验数据集，包含高细胞密度、重叠细胞、形态多样性等挑战。评估三类现有方法：基于回归的方法、人群计数方法和细胞计数方法，并探索如何将Segment Anything Model (SAM) 适应于显微镜细胞计数任务。

Result: 在测试集上（每张图像细胞数从10到2,126个），基于密度图的SAM适应方法（SAM-Counter）取得了22.12的平均绝对误差，优于现有方法（次优结果为27.46）。

Conclusion: 该数据集和基准测试框架对于推动自动化细胞计数的进展具有重要价值，为未来研究提供了坚实的基础。

Abstract: Accurate cell counting is essential in various biomedical research and clinical applications, including cancer diagnosis, stem cell research, and immunology. Manual counting is labor-intensive and error-prone, motivating automation through deep learning techniques. However, training reliable deep learning models requires large amounts of high-quality annotated data, which is difficult and time-consuming to produce manually. Consequently, existing cell-counting datasets are often limited, frequently containing fewer than $500$ images. In this work, we introduce a large-scale annotated dataset comprising $3{,}023$ images from immunocytochemistry experiments related to cellular differentiation, containing over $430{,}000$ manually annotated cell locations. The dataset presents significant challenges: high cell density, overlapping and morphologically diverse cells, a long-tailed distribution of cell count per image, and variation in staining protocols. We benchmark three categories of existing methods: regression-based, crowd-counting, and cell-counting techniques on a test set with cell counts ranging from $10$ to $2{,}126$ cells per image. We also evaluate how the Segment Anything Model (SAM) can be adapted for microscopy cell counting using only dot-annotated datasets. As a case study, we implement a density-map-based adaptation of SAM (SAM-Counter) and report a mean absolute error (MAE) of $22.12$, which outperforms existing approaches (second-best MAE of $27.46$). Our results underscore the value of the dataset and the benchmarking framework for driving progress in automated cell counting and provide a robust foundation for future research and development.

</details>


### [254] [UISearch: Graph-Based Embeddings for Multimodal Enterprise UI Screenshots Retrieval](https://arxiv.org/abs/2511.19380)
*Maroun Ayli,Youssef Bakouny,Tushar Sharma,Nader Jalloul,Hani Seifeddine,Rima Kilany*

Main category: cs.CV

TL;DR: 提出了一种基于图的UI表示方法，将UI截图转换为编码层次关系和空间布局的属性图，通过对比图自编码器学习多级相似性嵌入，在金融软件UI数据集上实现了高精度搜索。


<details>
  <summary>Details</summary>
Motivation: 企业软件公司管理数千个UI屏幕，面临设计一致性、模式发现和合规检查的挑战。现有方法依赖视觉相似性或文本语义，缺乏对UI组成结构特性的显式建模。

Method: 使用基于图的表示将UI截图转换为属性图，编码层次关系和空间布局。采用对比图自编码器学习嵌入，保留视觉、结构和语义特性的多级相似性。

Result: 在20,396个金融软件UI上，UISearch实现了0.92的Top-5准确率，中位延迟47.5ms（P95：124ms），可扩展到20,000+屏幕。结构嵌入比最先进的视觉编码器具有更好的判别能力。

Conclusion: 该方法在UI表示表达能力上取得了根本性进展，混合索引架构支持复杂查询和细粒度UI区分，这是纯视觉方法无法实现的。

Abstract: Enterprise software companies maintain thousands of user interface screens across products and versions, creating critical challenges for design consistency, pattern discovery, and compliance check. Existing approaches rely on visual similarity or text semantics, lacking explicit modeling of structural properties fundamental to user interface (UI) composition. We present a novel graph-based representation that converts UI screenshots into attributed graphs encoding hierarchical relationships and spatial arrangements, potentially generalizable to document layouts, architectural diagrams, and other structured visual domains. A contrastive graph autoencoder learns embeddings preserving multi-level similarity across visual, structural, and semantic properties. The comprehensive analysis demonstrates that our structural embeddings achieve better discriminative power than state-of-the-art Vision Encoders, representing a fundamental advance in the expressiveness of the UI representation. We implement this representation in UISearch, a multi-modal search framework that combines structural embeddings with semantic search through a composable query language. On 20,396 financial software UIs, UISearch achieves 0.92 Top-5 accuracy with 47.5ms median latency (P95: 124ms), scaling to 20,000+ screens. The hybrid indexing architecture enables complex queries and supports fine-grained UI distinction impossible with vision-only approaches.

</details>


### [255] [BackSplit: The Importance of Sub-dividing the Background in Biomedical Lesion Segmentation](https://arxiv.org/abs/2511.19394)
*Rachit Saluja,Asli Cihangir,Ruining Deng,Johannes C. Paetzold,Fengbei Liu,Mert R. Sabuncu*

Main category: cs.CV

TL;DR: 提出BackSplit方法，通过将背景类细分为多个解剖结构类别来提升小病灶分割性能，无需增加推理成本


<details>
  <summary>Details</summary>
Motivation: 传统病灶分割将所有非病灶像素归为单一背景类，忽略了丰富的解剖背景信息。背景实际上是高度异质的，包含组织、器官等结构

Method: 使用细粒度标签将背景类细分（BackSplit），通过增加Fisher信息来获得更紧的渐近界和更稳定的优化

Result: 在多个数据集和架构上的实验表明，BackSplit能持续提升小病灶分割性能，即使辅助标签是使用预训练分割模型自动生成的

Conclusion: BackSplit是一种简单而强大的范式，通过背景类细分显著提升分割性能，且对自动生成的辅助标签同样有效

Abstract: Segmenting small lesions in medical images remains notoriously difficult. Most prior work tackles this challenge by either designing better architectures, loss functions, or data augmentation schemes; and collecting more labeled data. We take a different view, arguing that part of the problem lies in how the background is modeled. Common lesion segmentation collapses all non-lesion pixels into a single "background" class, ignoring the rich anatomical context in which lesions appear. In reality, the background is highly heterogeneous-composed of tissues, organs, and other structures that can now be labeled manually or inferred automatically using existing segmentation models.
  In this paper, we argue that training with fine-grained labels that sub-divide the background class, which we call BackSplit, is a simple yet powerful paradigm that can offer a significant performance boost without increasing inference costs. From an information theoretic standpoint, we prove that BackSplit increases the expected Fisher Information relative to conventional binary training, leading to tighter asymptotic bounds and more stable optimization. With extensive experiments across multiple datasets and architectures, we empirically show that BackSplit consistently boosts small-lesion segmentation performance, even when auxiliary labels are generated automatically using pretrained segmentation models. Additionally, we demonstrate that auxiliary labels derived from interactive segmentation frameworks exhibit the same beneficial effect, demonstrating its robustness, simplicity, and broad applicability.

</details>


### [256] [SAM3-Adapter: Efficient Adaptation of Segment Anything 3 for Camouflage Object Segmentation, Shadow Detection, and Medical Image Segmentation](https://arxiv.org/abs/2511.19425)
*Tianrun Chen,Runlong Cao,Xinda Yu,Lanyun Zhu,Chaotao Ding,Deyi Ji,Cheng Chen,Qi Zhu,Chunyan Xu,Papa Mao,Ying Zang*

Main category: cs.CV

TL;DR: SAM3-Adapter是针对Segment Anything 3（SAM3）的首个适配器框架，解决了SAM系列模型在细粒度分割任务上的局限性，在医学影像、伪装物体分割和阴影检测等下游任务中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 解决SAM及其后继模型在细粒度、低级别分割任务（如伪装物体检测、医学图像分割、细胞图像分割和阴影检测）上的性能不足问题。

Method: 基于原始SAM-Adapter的模块化和可组合设计理念，为SAM3开发专门的适配器框架，减少计算开销并提升分割能力。

Result: SAM3-Adapter在多个下游任务中一致超越了SAM和SAM2解决方案，建立了新的最先进结果，表现出更强的泛化能力、更丰富的任务适应性和显著改进的分割精度。

Conclusion: SAM3-Adapter作为首个针对SAM3的适配器框架，为未来研究和实际分割应用提供了基础，在准确性、鲁棒性和效率方面均优于所有先前的SAM适配方案。

Abstract: The rapid rise of large-scale foundation models has reshaped the landscape of image segmentation, with models such as Segment Anything achieving unprecedented versatility across diverse vision tasks. However, previous generations-including SAM and its successor-still struggle with fine-grained, low-level segmentation challenges such as camouflaged object detection, medical image segmentation, cell image segmentation, and shadow detection. To address these limitations, we originally proposed SAM-Adapter in 2023, demonstrating substantial gains on these difficult scenarios. With the emergence of Segment Anything 3 (SAM3)-a more efficient and higher-performing evolution with a redesigned architecture and improved training pipeline-we revisit these long-standing challenges. In this work, we present SAM3-Adapter, the first adapter framework tailored for SAM3 that unlocks its full segmentation capability. SAM3-Adapter not only reduces computational overhead but also consistently surpasses both SAM and SAM2-based solutions, establishing new state-of-the-art results across multiple downstream tasks, including medical imaging, camouflaged (concealed) object segmentation, and shadow detection. Built upon the modular and composable design philosophy of the original SAM-Adapter, SAM3-Adapter provides stronger generalizability, richer task adaptability, and significantly improved segmentation precision. Extensive experiments confirm that integrating SAM3 with our adapter yields superior accuracy, robustness, and efficiency compared to all prior SAM-based adaptations. We hope SAM3-Adapter can serve as a foundation for future research and practical segmentation applications. Code, pre-trained models, and data processing pipelines are available.

</details>


### [257] [Ref-SAM3D: Bridging SAM3D with Text for Reference 3D Reconstruction](https://arxiv.org/abs/2511.19426)
*Yun Zhou,Yaoting Wang,Guangquan Jie,Jinyu Liu,Henghui Ding*

Main category: cs.CV

TL;DR: Ref-SAM3D是SAM3D的扩展，通过引入文本描述作为高级先验，实现了从单张RGB图像的文本引导3D重建，解决了SAM3D无法根据文本描述重建特定对象的问题。


<details>
  <summary>Details</summary>
Motivation: SAM3D虽然具有强大的3D重建能力，但无法根据文本描述重建特定对象，这限制了其在3D编辑、游戏开发和虚拟环境等实际应用中的使用。

Method: 在SAM3D基础上引入文本描述作为高级先验，通过自然语言和单张2D视图指导3D重建，将2D视觉线索与3D几何理解相结合。

Result: Ref-SAM3D在仅使用自然语言和单张2D视图的情况下，实现了具有竞争力的零样本重建性能，能够生成高保真度的3D重建结果。

Conclusion: Ref-SAM3D有效弥合了2D视觉线索与3D几何理解之间的差距，为参考引导的3D重建提供了更灵活和易用的范式。

Abstract: SAM3D has garnered widespread attention for its strong 3D object reconstruction capabilities. However, a key limitation remains: SAM3D cannot reconstruct specific objects referred to by textual descriptions, a capability that is essential for practical applications such as 3D editing, game development, and virtual environments. To address this gap, we introduce Ref-SAM3D, a simple yet effective extension to SAM3D that incorporates textual descriptions as a high-level prior, enabling text-guided 3D reconstruction from a single RGB image. Through extensive qualitative experiments, we show that Ref-SAM3D, guided only by natural language and a single 2D view, delivers competitive and high-fidelity zero-shot reconstruction performance. Our results demonstrate that Ref-SAM3D effectively bridges the gap between 2D visual cues and 3D geometric understanding, offering a more flexible and accessible paradigm for reference-guided 3D reconstruction. Code is available at: https://github.com/FudanCVL/Ref-SAM3D.

</details>


### [258] [Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution](https://arxiv.org/abs/2511.19430)
*Dingkang Liang,Cheng Zhang,Xiaopeng Xu,Jianzhong Ju,Zhenbo Luo,Xiang Bai*

Main category: cs.CV

TL;DR: 提出了ORS3D任务，结合语言理解、3D空间定位和效率优化，构建了包含6万个复合任务的ORS3D-60K数据集，并开发了GRANT多模态大语言模型来生成高效的任务调度方案。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在任务规划中忽略了运筹学知识和3D空间定位，无法满足真实世界任务调度的需求。

Method: 构建ORS3D-60K大规模数据集，提出GRANT多模态大语言模型，采用调度令牌机制生成任务调度和基础动作。

Result: 在ORS3D-60K数据集上的广泛实验验证了GRANT在语言理解、3D定位和调度效率方面的有效性。

Conclusion: ORS3D任务和GRANT模型为具身AI的任务调度提供了新的研究方向，代码已开源。

Abstract: Task scheduling is critical for embodied AI, enabling agents to follow natural language instructions and execute actions efficiently in 3D physical worlds. However, existing datasets often simplify task planning by ignoring operations research (OR) knowledge and 3D spatial grounding. In this work, we propose Operations Research knowledge-based 3D Grounded Task Scheduling (ORS3D), a new task that requires the synergy of language understanding, 3D grounding, and efficiency optimization. Unlike prior settings, ORS3D demands that agents minimize total completion time by leveraging parallelizable subtasks, e.g., cleaning the sink while the microwave operates. To facilitate research on ORS3D, we construct ORS3D-60K, a large-scale dataset comprising 60K composite tasks across 4K real-world scenes. Furthermore, we propose GRANT, an embodied multi-modal large language model equipped with a simple yet effective scheduling token mechanism to generate efficient task schedules and grounded actions. Extensive experiments on ORS3D-60K validate the effectiveness of GRANT across language understanding, 3D grounding, and scheduling efficiency. The code is available at https://github.com/H-EmbodVis/GRANT

</details>


### [259] [Cloud4D](https://arxiv.org/abs/2511.19431)
*Jacob Lin,Edward Gryspeerdt,Ronald Clark*

Main category: cs.CV

TL;DR: Cloud4D是一个基于学习的框架，使用同步地面相机重建物理一致的4D云状态，实现25米空间分辨率和5秒时间分辨率的3D液态水含量分布重建，并估计水平风矢量。


<details>
  <summary>Details</summary>
Motivation: 当前全球数值天气预报和气候模型大多在千米尺度运行，难以建模单个云层和极端天气因素，需要更高分辨率模型，但现有仪器难以获取高分辨率真实观测数据。

Method: 利用同形引导的2D到3D变换器，仅使用同步地面相机推断完整的3D液态水含量分布，通过跟踪3D液态水含量随时间变化来估计水平风矢量。

Result: 在包含六个向上拍摄相机的两个月部署中，系统相比最先进的卫星测量在时空分辨率上提升了一个数量级，同时相对于共置雷达测量的相对误差保持在个位数（<10%）。

Conclusion: Cloud4D框架能够以极高分辨率重建4D云状态，为高分辨率天气和气候建模提供了新的观测能力。

Abstract: There has been great progress in improving numerical weather prediction and climate models using machine learning. However, most global models act at a kilometer-scale, making it challenging to model individual clouds and factors such as extreme precipitation, wind gusts, turbulence, and surface irradiance. Therefore, there is a need to move towards higher-resolution models, which in turn require high-resolution real-world observations that current instruments struggle to obtain. We present Cloud4D, the first learning-based framework that reconstructs a physically consistent, four-dimensional cloud state using only synchronized ground-based cameras. Leveraging a homography-guided 2D-to-3D transformer, Cloud4D infers the full 3D distribution of liquid water content at 25 m spatial and 5 s temporal resolution. By tracking the 3D liquid water content retrievals over time, Cloud4D additionally estimates horizontal wind vectors. Across a two-month deployment comprising six skyward cameras, our system delivers an order-of-magnitude improvement in space-time resolution relative to state-of-the-art satellite measurements, while retaining single-digit relative error ($<10\%$) against collocated radar measurements. Code and data are available on our project page https://cloud4d.jacob-lin.com/.

</details>


### [260] [Are Image-to-Video Models Good Zero-Shot Image Editors?](https://arxiv.org/abs/2511.19435)
*Zechuan Zhang,Zhenyuan Chen,Zongxin Yang,Yi Yang*

Main category: cs.CV

TL;DR: IF-Edit是一个无需调优的框架，将预训练的图像到视频扩散模型重新用于指令驱动的图像编辑，解决了提示不对齐、冗余时间潜在变量和模糊后期帧等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 大规模视频扩散模型展现出强大的世界模拟和时间推理能力，但作为零样本图像编辑器的应用仍未充分探索。本文旨在利用这些模型进行指令驱动的图像编辑。

Method: 包括三个核心组件：(1)思维链提示增强模块，将静态编辑指令转换为时间基础推理提示；(2)时间潜在变量丢弃策略，在专家切换点后压缩帧潜在变量，加速去噪同时保持语义和时间一致性；(3)自一致后细化步骤，使用短静态视频轨迹锐化后期帧。

Result: 在四个公共基准测试上的实验表明，IF-Edit在推理中心任务上表现强劲，同时在通用编辑任务上保持竞争力。

Conclusion: 本研究系统性地展示了视频扩散模型作为图像编辑器的潜力，并为统一的视频-图像生成推理提供了简单方案。

Abstract: Large-scale video diffusion models show strong world simulation and temporal reasoning abilities, but their use as zero-shot image editors remains underexplored. We introduce IF-Edit, a tuning-free framework that repurposes pretrained image-to-video diffusion models for instruction-driven image editing. IF-Edit addresses three key challenges: prompt misalignment, redundant temporal latents, and blurry late-stage frames. It includes (1) a chain-of-thought prompt enhancement module that transforms static editing instructions into temporally grounded reasoning prompts; (2) a temporal latent dropout strategy that compresses frame latents after the expert-switch point, accelerating denoising while preserving semantic and temporal coherence; and (3) a self-consistent post-refinement step that sharpens late-stage frames using a short still-video trajectory. Experiments on four public benchmarks, covering non-rigid editing, physical and temporal reasoning, and general instruction edits, show that IF-Edit performs strongly on reasoning-centric tasks while remaining competitive on general-purpose edits. Our study provides a systematic view of video diffusion models as image editors and highlights a simple recipe for unified video-image generative reasoning.

</details>


### [261] [LumiTex: Towards High-Fidelity PBR Texture Generation with Illumination Context](https://arxiv.org/abs/2511.19437)
*Jingzhi Bao,Hongze Chen,Lingting Zhu,Chenyu Liu,Runze Zhang,Keyang Luo,Zeyu Hu,Weikai Chen,Yingda Yin,Xin Wang,Zehong Lin,Jun Zhang,Xiaoguang Han*

Main category: cs.CV

TL;DR: LumiTex是一个端到端的PBR纹理生成框架，通过多分支生成方案、光照感知材料注意力机制和几何引导修复模块，解决了材料分解和纹理补全的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有PBR纹理生成方法存在两个基本挑战：1）在有限光照线索下从图像提示进行材料分解，2）无缝且视角一致的纹理补全。

Method: 提出三个关键组件：1）多分支生成方案，在共享光照先验下解耦反照率和金属粗糙度；2）光照感知材料注意力机制，将光照上下文注入解码过程；3）基于大视角合成模型的几何引导修复模块，确保无缝的UV补全。

Result: 大量实验表明，LumiTex在纹理质量方面达到了最先进的性能，超越了现有的开源和商业方法。

Conclusion: LumiTex通过创新的多组件框架有效解决了PBR纹理生成中的材料分解和纹理补全问题，实现了高质量的纹理生成。

Abstract: Physically-based rendering (PBR) provides a principled standard for realistic material-lighting interactions in computer graphics. Despite recent advances in generating PBR textures, existing methods fail to address two fundamental challenges: 1) materials decomposition from image prompts under limited illumination cues, and 2) seamless and view-consistent texture completion. To this end, we propose LumiTex, an end-to-end framework that comprises three key components: (1) a multi-branch generation scheme that disentangles albedo and metallic-roughness under shared illumination priors for robust material understanding, (2) a lighting-aware material attention mechanism that injects illumination context into the decoding process for physically grounded generation of albedo, metallic, and roughness maps, and (3) a geometry-guided inpainting module based on a large view synthesis model that enriches texture coverage and ensures seamless, view-consistent UV completion. Extensive experiments demonstrate that LumiTex achieves state-of-the-art performance in texture quality, surpassing both existing open-source and commercial methods.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [262] [Beyond the Rubric: Cultural Misalignment in LLM Benchmarks for Sexual and Reproductive Health](https://arxiv.org/abs/2511.17554)
*Sumon Kanti Dey,Manvi S,Zeel Mehta,Meet Shah,Unnati Agrawal,Suhani Jalota,Azra Ismail*

Main category: cs.CY

TL;DR: 研究发现当前基于西方规范的LLM健康评估基准存在文化偏见，无法准确评估为印度等全球南方国家设计的性健康咨询系统的实际效果。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在性健康和生殖健康领域对全球南方国家的适用性，揭示现有西方中心评估基准的文化局限性。

Method: 使用OpenAI的HealthBench基准评估为印度服务不足社区设计的性健康聊天机器人，分析637个查询中的330个单轮对话，结合自动评分和人工定性分析。

Result: 自动评分器持续给出低分，但人工分析显示许多回答在文化和医学上都是恰当的，发现西方偏见体现在法律框架、社会规范、饮食假设和成本模型等方面。

Conclusion: 需要开发文化适应性评估框架，在保持质量标准的同时认可不同人群的需求，克服当前基准的文化局限性。

Abstract: Large Language Models (LLMs) have been positioned as having the potential to expand access to health information in the Global South, yet their evaluation remains heavily dependent on benchmarks designed around Western norms. We present insights from a preliminary benchmarking exercise with a chatbot for sexual and reproductive health (SRH) for an underserved community in India. We evaluated using HealthBench, a benchmark for conversational health models by OpenAI. We extracted 637 SRH queries from the dataset and evaluated on the 330 single-turn conversations. Responses were evaluated using HealthBench's rubric-based automated grader, which rated responses consistently low. However, qualitative analysis by trained annotators and public health experts revealed that many responses were actually culturally appropriate and medically accurate. We highlight recurring issues, particularly a Western bias, such as for legal framing and norms (e.g., breastfeeding in public), diet assumptions (e.g., fish safe to eat during pregnancy), and costs (e.g., insurance models). Our findings demonstrate the limitations of current benchmarks in capturing the effectiveness of systems built for different cultural and healthcare contexts. We argue for the development of culturally adaptive evaluation frameworks that meet quality standards while recognizing needs of diverse populations.

</details>


### [263] [Do Environment-Modification Behaviors and Gamers' Immersiveness Shape Exceptionalism Beliefs?](https://arxiv.org/abs/2511.17591)
*Quan-Hoang Vuong,Fatemeh Kianfar,Thi Mai Anh Tran,Ni Putu Wulan Purnama Sari,Cresensia Dina Candra Kumaladewi,Viet-Phuong La,Minh-Hoang Nguyen*

Main category: cs.CY

TL;DR: 本研究探讨虚拟生态环境如何通过玩家行为（树木种植、花卉种植、花卉杂交、地形改造和昆虫重生条件创造）和沉浸感共同影响人类例外主义心态，发现高可控性行为预测更高例外主义，而低可控性行为预测更低例外主义，但沉浸感会调节这些效应。


<details>
  <summary>Details</summary>
Motivation: 人类例外主义深刻影响人与自然的关系认知，但虚拟生态环境如何影响这种心态尚不明确。随着数字世界日益沉浸和生态复杂化，为研究人类价值系统的形成和转变提供了新背景。

Method: 采用粒度交互思维理论(GITT)和贝叶斯思维海绵框架(BMF分析)，基于来自29个国家640名《动物森友会：新视野》玩家的跨国数据集，分析五种关键活动。

Result: 结果识别出两个行为聚类：高可控性行为（花卉种植和地形改造）预测更高例外主义，但在高度沉浸玩家中花卉种植效应反转；低可控性行为（花卉杂交和操纵昆虫重生）预测更低例外主义，但这些关联在高沉浸度下减弱或反转。

Conclusion: 这些发现为利用虚拟世界培养自然商数(NQ)、减轻例外主义倾向和促进生态盈余文化取向提供了见解。

Abstract: Human exceptionalism strongly shapes human-nature perceptions, thinking, values, and behaviors. Yet little is known about how virtual ecological environments influence this mindset. As digital worlds become increasingly immersive and ecologically sophisticated, they provide novel contexts for examining how human value systems are formed and transformed. This study investigates how virtual environment-modification behaviors and players' sense of immersiveness jointly shape exceptionalism, drawing on worldviews from quantum mechanics and mathematical logic. Using Granular Interaction Thinking Theory (GITT) and the Bayesian Mindsponge Framework (BMF analytics), we analyze five key activities--tree planting, flower planting, flower crossbreeding, terraforming, and creating conditions for bug respawn--based on a multinational dataset of 640 Animal Crossing: New Horizons players from 29 countries. Results reveal two behavioral clusters distinguished by controllability. High-controllability behaviors (i.e., flower planting and terraforming) predict higher exceptionalism, whereas the flower-planting effect reverses among highly immersed players. Low-controllability behaviors (i.e., flower crossbreeding and manipulating bug spawning) predict lower exceptionalism, but these associations weaken or reverse under high immersiveness, respectively. These findings offer insights into leveraging virtual worlds to cultivate Nature Quotient (NQ), mitigate exceptionalist tendencies, and foster eco-surplus cultural orientations.

</details>


### [264] [Bayesian probabilistic exploration of Bitcoin informational quanta and interactions under the GITT-VT paradigm](https://arxiv.org/abs/2511.17646)
*Quan-Hoang Vuong,Viet-Phuong La,Minh-Hoang Nguyen*

Main category: cs.CY

TL;DR: 基于GITT-VT理论分析比特币价值形成，发现其价值源于信息属性而非物质效用，通过贝叶斯线性模型验证了四个信息价值维度对价格的影响。


<details>
  <summary>Details</summary>
Motivation: 探索比特币价值形成的理论基础，挑战传统基于物质效用或现金流的价值理论，从信息属性和多因素交互角度理解比特币价值。

Method: 使用贝叶斯线性模型分析2022-2025年日度数据，操作化四个信息价值维度：价值存储(SOV)、自主性(AUT)、社会信号价值(SSV)和享乐情感价值(HSV)。

Result: 只有SSV对次日回报有高度可信的正向影响，SOV和AUT显示中等可靠的正向关联，HSV无显著预测效果。

Conclusion: 比特币是一个双层级熵调节的社会技术生态系统，社会信息在短期定价中起主导作用，而结构锚点在长期价值中更重要。

Abstract: This study explores Bitcoin's value formation through the Granular Interaction Thinking Theory-Value Theory (GITT-VT). Rather than stemming from material utility or cash flows, Bitcoin's value arises from informational attributes and interactions of multiple factors, including cryptographic order, decentralization-enabled autonomy, trust embedded in the consensus mechanism, and socio-narrative coherence that reduce entropy within decentralized value-exchange processes. To empirically assess this perspective, a Bayesian linear model was estimated using daily data from 2022 to 2025, operationalizing four informational value dimensions: Store-of-Value (SOV), Autonomy (AUT), Social-Signal Value (SSV), and Hedonic-Sentiment Value (HSV). Results indicate that only SSV exerts a highly credible positive effect on next-day returns, highlighting the dominant role of high-entropy social information in short-term pricing dynamics. In contrast, SOV and AUT show moderately reliable positive associations, reflecting their roles as low-entropy structural anchors of long-term value. HSV displays no credible predictive effect. The study advances interdisciplinary value theory and demonstrates Bitcoin as a dual-layer entropy-regulating socio-technological ecosystem. The findings offer implications for digital asset valuation, investment education, and future research on entropy dynamics across non-cash-flow digital assets.

</details>


### [265] [Technologies to Support Self-determination for People with Intellectual Disability and ASD](https://arxiv.org/abs/2511.17648)
*Florian Laronze,Audrey Landuran,Bernard N'kaoua*

Main category: cs.CY

TL;DR: 本文探讨了自决能力的概念，以及为促进弱势群体自决能力而设计和验证的数字工具。重点分析了针对智力障碍和自闭症谱系障碍人群开发的数字辅助工具及其改善生活质量的效果。


<details>
  <summary>Details</summary>
Motivation: 自决能力是进行日常活动的基本技能，但某些人群缺乏这种能力，导致无法独立生活。近年来开发的自决增强技术旨在促进自决障碍人群的独立生活能力。

Method: 通过分析为智力障碍和自闭症谱系障碍人群开发的主要数字辅助工具，展示这些技术如何支持自决能力。

Result: 数字辅助工具能够有效改善自决障碍人群的生活舒适度，促进他们的独立生活能力。

Conclusion: 数字工具在促进弱势群体自决能力和改善生活质量方面具有重要价值，值得进一步开发和应用。

Abstract: This article focuses on the concept of self-determination and the design and validation of digital tools intended to promote the self-determination of vulnerable people. Self-determination is an essential skill for carrying out daily activities. But in certain situations, and for certain populations, self-determination is lacking, which leads to the inability to live an independent life and in favorable conditions of well-being and health. In recent years, self-determination enhancing technologies have been developed and used to promote independent living among people with self-determination disorders. We will illustrate the main digital tools to support self-determination developed for two populations of people suffering from self-determination disorders: people with an intellectual disability and people with an autism spectrum disorder. The ability of these digital assistants to improve the comfort of life of these people will also be presented and discussed.

</details>


### [266] [Empa: An AI-Powered Virtual Mentor for Developing Global Collaboration Skills in HPC Education](https://arxiv.org/abs/2511.17669)
*Ashish,Aparajita Jaiswal,Sudip Vhaduri,Niveditha Nerella,Shubham Jha*

Main category: cs.CY

TL;DR: Empa是一个AI驱动的虚拟导师，将跨文化协作培训整合到本科计算教育中，旨在培养HPC领域所需的跨文化团队合作能力。


<details>
  <summary>Details</summary>
Motivation: 传统计算课程未能充分培养学生应对现代计算研究环境中跨文化团队合作的技能，而高性能计算和并行计算日益依赖全球多样化团队的协作。

Method: 使用大型语言模型构建Empa系统，通过渐进式Web应用程序部署，指导学生完成涵盖文化维度、沟通风格和冲突解决的结构化活动。

Result: 试点准备部署表明AI介导的跨文化培训具有可行性，并为开发HPC劳动力所需的跨文化协作技能提供了可扩展方法。

Conclusion: Empa系统通过AI驱动的跨文化培训，有效解决了培养具有文化能力的HPC专业人员的迫切需求，帮助学生发展在国际研究团队中有效协作的技能。

Abstract: High-performance computing (HPC) and parallel computing increasingly rely on global collaboration among diverse teams, yet traditional computing curricula inadequately prepare students for cross-cultural teamwork essential in modern computational research environments. This paper presents Empa, an AI-powered virtual mentor that integrates intercultural collaboration training into undergraduate computing education. Built using large language models and deployed through a progressive web application, Empa guides students through structured activities covering cultural dimensions, communication styles, and conflict resolution that are critical for effective multicultural teamwork. Our system addresses the growing need for culturally competent HPC professionals by helping computing students develop skills to collaborate effectively in international research teams, contribute to global computational projects, and navigate the cultural complexities inherent in distributed computing environments. Pilot preparation for deployment in computing courses demonstrates the feasibility of AI-mediated intercultural training and provides insights into scalable approaches for developing intercultural collaboration skills essential for HPC workforce development.

</details>


### [267] [Chatbots to strengthen democracy: An interdisciplinary seminar to train identifying argumentation techniques of science denial](https://arxiv.org/abs/2511.17678)
*Ingo Siegert,Jan Nehring,Aranxa Márquez Ampudia,Matthias Busch,Stefan Hillmann*

Main category: cs.CY

TL;DR: 本文提出一个跨学科研讨会，利用大语言模型创建科学否认者角色聊天机器人，帮助学生识别错误信息和应对有毒对话。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上科学否认和虚假新闻泛滥，传统监管措施不足，需要教育方法来增强用户批判性思维能力。

Method: 4-5名学生小组开发基于RASA框架的AI聊天机器人，集成LLM实现与科学否认论证结构的自然对话，并通过用户研究评估效果。

Result: 研讨会作为混合式并行硕士课程模块实施，旨在教授AI技术并测试该想法的可行性。

Conclusion: 对话训练是应对错误信息的有前景策略，LLM扮演科学否认者角色有助于提高用户对错误信息的识别能力和抗毒性互动能力。

Abstract: In recent times, discussions on social media platforms have increasingly come under scrutiny due to the proliferation of science denial and fake news. Traditional solutions, such as regulatory actions, have been implemented to mitigate the spread of misinformation; however, these measures alone are not sufficient. To complement these efforts, educational approaches are becoming essential in empowering users to critically engage with misinformation. Conversation training, through serious games or personalized methods, has emerged as a promising strategy to help users handle science denial and toxic conversation tactics. This paper suggests an interdisciplinary seminar to explore the suitability of Large Language Models (LLMs) acting as a persona of a science denier to support people in identifying misinformation and improving resilience against toxic interactions. In the seminar, groups of four to five students will develop an AI-based chatbot that enables realistic interactions with science-denial argumentation structures. The task involves planning the setting, integrating a Large Language Model to facilitate natural dialogues, implementing the chatbot using the RASA framework, and evaluating the outcomes in a user study. It is crucial that users understand what they need to do during the interaction, how to conclude it, and how the relevant information is conveyed. The seminar does not aim to develop chatbots for practicing debunking but serves to teach AI technologies and test the feasibility of this idea for future applications. The chatbot seminar is conducted as a hybrid, parallel master's module at the participating educational institutions.

</details>


### [268] [A Cross-Cultural Assessment of Human Ability to Detect LLM-Generated Fake News about South Africa](https://arxiv.org/abs/2511.17682)
*Tim Schlippe,Matthias Wölfel,Koena Ronny Mabokela*

Main category: cs.CY

TL;DR: 本研究调查文化亲近度对检测AI生成假新闻能力的影响，发现南非参与者在本国真实新闻检测上表现更好，但在识别假新闻方面表现更差，表明文化熟悉度有助于验证真实信息但可能在评估虚假内容时引入偏见。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型能够生成复杂假新闻，理解人类在不同文化背景下的检测能力变得至关重要，特别是在内容跨越文化和地理边界的信息生态系统中。

Method: 对89名参与者（56名南非人，33名其他国籍）进行调查，让他们评估10篇真实的南非新闻文章和10篇AI生成的假版本。

Result: 南非人在检测本国真实新闻方面表现更优（偏离理想评分40% vs 52%），但在识别假新闻方面表现更差（62% vs 55%）。南非人更依赖内容知识和语境理解，而其他国籍参与者更强调形式语言特征。

Conclusion: 文化熟悉度有助于验证真实信息，但可能在评估虚假内容时引入偏见，这对理解跨文化错误信息检测和应对AI生成假新闻具有重要启示。

Abstract: This study investigates how cultural proximity affects the ability to detect AI-generated fake news by comparing South African participants with those from other nationalities. As large language models increasingly enable the creation of sophisticated fake news, understanding human detection capabilities becomes crucial, particularly across different cultural contexts. We conducted a survey where 89 participants (56 South Africans, 33 from other nationalities) evaluated 10 true South African news articles and 10 AI-generated fake versions. Results reveal an asymmetric pattern: South Africans demonstrated superior performance in detecting true news about their country (40% deviation from ideal rating) compared to other participants (52%), but performed worse at identifying fake news (62% vs. 55%). This difference may reflect South Africans' higher overall trust in news sources. Our analysis further shows that South Africans relied more on content knowledge and contextual understanding when judging credibility, while participants from other countries emphasised formal linguistic features such as grammar and structure. Overall, the deviation from ideal rating was similar between groups (51% vs. 53%), suggesting that cultural familiarity appears to aid verification of authentic information but may also introduce bias when evaluating fabricated content. These insights contribute to understanding cross-cultural dimensions of misinformation detection and inform strategies for combating AI-generated fake news in increasingly globalised information ecosystems where content crosses cultural and geographical boundaries.

</details>


### [269] [Datacenters in the Desert: Feasibility and Sustainability of LLM Inference in the Middle East](https://arxiv.org/abs/2511.17683)
*Lara Hassan,Mohamed ElZeftawy,Abdulrahman Mahmoud*

Main category: cs.CY

TL;DR: 本文通过实证研究分析了在阿联酋、冰岛、德国和美国四个国家部署大型语言模型进行代码生成时的能耗和碳足迹，使用DeepSeek Coder 1.3B和HumanEval数据集，旨在评估沙漠环境中数据中心部署的可持续性。


<details>
  <summary>Details</summary>
Motivation: 随着中东成为AI基础设施的战略枢纽，研究在沙漠环境中部署可持续数据中心的可行性变得日益重要，需要评估不同地理位置的能耗和碳排放差异。

Method: 使用DeepSeek Coder 1.3B模型和HumanEval数据集进行代码生成任务，通过CodeCarbon库跟踪能源消耗和碳排放，比较四个国家（阿联酋、冰岛、德国、美国）的地理位置差异。

Result: 研究结果揭示了沙漠地区数据中心面临的挑战和潜力，为气候感知的AI部署提供了地理权衡分析。

Conclusion: 研究为沙漠地区数据中心在全球AI扩张中的作用提供了平衡的展望，既指出了挑战也展现了潜力。

Abstract: As the Middle East emerges as a strategic hub for artificial intelligence (AI) infrastructure, the feasibility of deploying sustainable datacenters in desert environments has become a topic of growing relevance. This paper presents an empirical study analyzing the energy consumption and carbon footprint of large language model (LLM) inference across four countries: the United Arab Emirates, Iceland, Germany, and the United States of America using DeepSeek Coder 1.3B and the HumanEval dataset on the task of code generation. We use the CodeCarbon library to track energy and carbon emissions andcompare geographical trade-offs for climate-aware AI deployment. Our findings highlight both the challenges and potential of datacenters in desert regions and provide a balanced outlook on their role in global AI expansion.

</details>


### [270] [Smart Metadata in Action: The Social Impact Data Commons](https://arxiv.org/abs/2511.17694)
*Joanna Schroeder,Alan Wang,Kathryn Linehan,Joel Thurston,Aaron Schroeder*

Main category: cs.CY

TL;DR: 本文介绍了社会影响数据共享中元数据和标准的应用，通过可操作和可评估的元数据构建FAIR数据系统，展示了核心元数据案例研究及其对FAIR指南的遵循情况。


<details>
  <summary>Details</summary>
Motivation: 将官方统计人员引入基于可操作和可评估元数据的创新项目，构建FAIR数据系统，支持社会影响数据共享的发展。

Method: 引入数据共享概念，展示当前数据共享实施情况，通过核心元数据案例研究演示智能元数据如何支持数据共享，并对元数据进行FAIR指南遵循性评估。

Result: 成功构建了基于智能元数据的FAIR数据系统，核心元数据案例研究证明了元数据对数据共享的有效支持，评估显示元数据符合FAIR指南要求。

Conclusion: 未来将继续开展元数据和标准相关项目，以进一步支持社会影响数据共享的发展和完善。

Abstract: This article describes the use of metadata and standards in the Social Impact Data Commons to expose official statisticians to an innovative project built on actionable and evaluable metadata, which produces a FAIR data system. We begin by introducing the concept of the Data Commons, focusing on its features, and presenting an overview of current implementations of the Data Commons. We then present the core metadata case study, demonstrating how smart metadata support the Data Commons. We also present evaluations of our core metadata, including its adherence to the FAIR guidelines. We conclude with a discussion on our future metadata and standards-related projects to support the Social Impact Data Commons.

</details>


### [271] [Liberating Logic in the Age of AI: Going Beyond Programming with Computational Thinking](https://arxiv.org/abs/2511.17696)
*Douglas C. Schmidt,Dan Runfola*

Main category: cs.CY

TL;DR: 论文探讨了AI编程助手如何改变编程教育，从传统编程语言转向自然语言编程和计算思维培养。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和AI编程助手的发展，编程门槛降低，需要重新思考计算机科学教育的核心内容和教学方法。

Method: 通过分析自然语言编程对软件开发的影响，比较程序员与提示词工程师的区别，探讨课程改革需求。

Result: 识别了计算思维商品化的趋势，提出了适应AI时代的教育改革方向和最佳实践。

Conclusion: 在AI增强的未来中，需要保持计算科学的基本原则，同时培养批判性思维、解决方案设计和AI结果验证能力。

Abstract: Mastering one or more programming languages has historically been the gateway to implementing ideas on a computer. Today, that gateway is widening with advances in large language models (LLMs) and artificial intelligence (AI)-powered coding assistants. What matters is no longer just fluency in traditional programming languages but the ability to think computationally by translating problems into forms that can be solved with computing tools. The capabilities enabled by these AI-augmented tools are rapidly leading to the commoditization of computational thinking, such that anyone who can articulate a problem in natural language can potentially harness computing power via AI.
  This shift is poised to radically influence how we teach computer science and data science in the United States and around the world. Educators and industry leaders are grappling with how to adapt: What should students learn when the hottest new programming language is English? How do we prepare a generation of computational thinkers who need not code every algorithm manually, but must still think critically, design solutions, and verify AI-augmented results?
  This paper explores these questions, examining the impact of natural language programming on software development, the emerging distinction between programmers and prompt-crafting problem solvers, the reforms needed in computer science and data science curricula, and the importance of maintaining our fundamental computational science principles in an AI-augmented future. Along the way, we compare approaches and share best practices for embracing this new paradigm in computing education.

</details>


### [272] [Animated Territorial Data Extractor (ATDE): A Computer-Vision Method for Extracting Territorial Data from Animated Historical Maps](https://arxiv.org/abs/2511.17920)
*Hamza Alshamy,Isaiah Woram,Advay Mishra,Zihan Xia,Pascal Wallisch*

Main category: cs.CY

TL;DR: ATDE是一个计算机视觉工具，可从动画历史地图视频中提取定量领土数据，通过颜色分割和过滤技术识别领土控制像素，将动画视频转换为结构化时间序列数据。


<details>
  <summary>Details</summary>
Motivation: 开发一个无需预存形状文件即可从动画历史地图视频中提取定量领土数据的工具，用于教育演示、初步数据探索和领土动态比较分析。

Method: 使用HSV颜色分割、RGB通道过滤和直接邻居过滤来识别领土控制像素，结合时间对齐和跨视频缩放的预处理，将动画视频转换为时间序列数据。

Result: 在十个中国朝代（公元前200年-1912年）上验证了该工具，生成的逐年像素计数与预期历史模式一致。

Conclusion: ATDE虽然不是权威历史数据集的替代品，但适用于教育演示、初步数据探索和领土动态比较分析，可应用于任何给定种子颜色和基本配置的动画地图视频。

Abstract: We present Animated Territorial Data Extractor (ATDE), a computer vision tool that extracts quantitative territorial data from animated historical map videos. ATDE employs HSV-based color segmentation, RGB channel filtering, and Direct-Neighbor Filtering to identify and count pixels representing territorial control. Combined with preprocessing for temporal alignment and cross-video scaling, the pipeline converts animated videos into structured time-series data. We demonstrate the tool on ten Chinese dynasties (200 BCE - 1912 CE), producing year-by-year pixel counts that align with expected historical patterns. While not a substitute for authoritative historical datasets, ATDE is well-suited for educational demonstrations, preliminary data exploration, and comparative analysis of territorial dynamics. The tool requires no pre-existing shapefiles and can be applied to any animated map video given seed colors and basic configuration. Code and examples are available on GitHub.

</details>


### [273] [Enhancing Large Language Models for Automated Homework Assessment in Undergraduate Circuit Analysis](https://arxiv.org/abs/2511.18221)
*Liangliang Chen,Huiru Xie,Zhihao Qin,Yiming Guo,Jacqueline Rohde,Ying Zhang*

Main category: cs.CY

TL;DR: 本文提出了一种增强大型语言模型在电路分析课程作业评估中的方法，通过多步提示、上下文数据增强和针对性提示，将GPT-4o的准确率从74.71%提升至97.70%。


<details>
  <summary>Details</summary>
Motivation: 旨在提高大型语言模型为电气工程学生提供个性化支持的能力，改善其在电路分析课程作业评估中的表现。

Method: 采用多步提示、上下文数据增强和针对性提示等策略，解决GPT-4o在使用简单提示时的常见错误。

Result: 应用增强提示和增强数据后，GPT-4o在入门级电路分析主题上的正确响应率从74.71%显著提升至97.70%。

Conclusion: 这项工作为将大型语言模型有效整合到电路分析教学以及更广泛的工程教育中奠定了基础。

Abstract: This research full paper presents an enhancement pipeline for large language models (LLMs) in assessing homework for an undergraduate circuit analysis course, aiming to improve LLMs' capacity to provide personalized support to electrical engineering students. Existing evaluations have demonstrated that GPT-4o possesses promising capabilities in assessing student homework in this domain. Building on these findings, we enhance GPT-4o's performance through multi-step prompting, contextual data augmentation, and the incorporation of targeted hints. These strategies effectively address common errors observed in GPT-4o's responses when using simple prompts, leading to a substantial improvement in assessment accuracy. Specifically, the correct response rate for GPT-4o increases from 74.71% to 97.70% after applying the enhanced prompting and augmented data on entry-level circuit analysis topics. This work lays a foundation for the effective integration of LLMs into circuit analysis instruction and, more broadly, into engineering education.

</details>


### [274] [Can LLMs Help Allocate Public Health Resources? A Case Study on Childhood Lead Testing](https://arxiv.org/abs/2511.18239)
*Mohamed Afane,Ying Wang,Juntao Chen*

Main category: cs.CY

TL;DR: 本研究评估大型语言模型在公共卫生资源分配中的表现，发现LLMs在基于社区铅暴露风险指标分配检测试剂盒时存在显著局限性，经常忽视高风险区域而过度分配资源给低优先级区域。


<details>
  <summary>Details</summary>
Motivation: 公共卫生机构在识别儿童铅暴露高风险社区时面临资源有限的挑战，需要优化资源分配决策。研究旨在评估LLMs是否能够有效整合多个脆弱性指标进行公共卫生资源分配。

Method: 开发优先级评分系统，整合未检测儿童比例、血铅升高流行率和公共卫生覆盖模式。在芝加哥、纽约市和华盛顿特区的136个社区中，让LLMs基于社区脆弱性指标分配1,000个检测试剂盒。

Result: LLMs表现显著受限：平均准确率仅0.46，最高为0.66（ChatGPT 5 Deep Research）。模型经常忽视铅暴露流行率最高和未检测儿童比例最大的社区，同时过度分配资源给低优先级区域。

Conclusion: 尽管LLMs具有深度研究能力，但在信息检索和循证推理方面存在根本性限制，经常引用过时数据并让非实证叙述覆盖定量脆弱性指标，不适合单独用于公共卫生资源分配决策。

Abstract: Public health agencies face critical challenges in identifying high-risk neighborhoods for childhood lead exposure with limited resources for outreach and intervention programs. To address this, we develop a Priority Score integrating untested children proportions, elevated blood lead prevalence, and public health coverage patterns to support optimized resource allocation decisions across 136 neighborhoods in Chicago, New York City, and Washington, D.C. We leverage these allocation tasks, which require integrating multiple vulnerability indicators and interpreting empirical evidence, to evaluate whether large language models (LLMs) with agentic reasoning and deep research capabilities can effectively allocate public health resources when presented with structured allocation scenarios. LLMs were tasked with distributing 1,000 test kits within each city based on neighborhood vulnerability indicators. Results reveal significant limitations: LLMs frequently overlooked neighborhoods with highest lead prevalence and largest proportions of untested children, such as West Englewood in Chicago, while allocating disproportionate resources to lower-priority areas like Hunts Point in New York City. Overall accuracy averaged 0.46, reaching a maximum of 0.66 with ChatGPT 5 Deep Research. Despite their marketed deep research capabilities, LLMs struggled with fundamental limitations in information retrieval and evidence-based reasoning, frequently citing outdated data and allowing non-empirical narratives about neighborhood conditions to override quantitative vulnerability indicators.

</details>


### [275] [Analyzing and Optimizing the Distribution of Blood Lead Level Testing for Children in New York City: A Data-Driven Approach](https://arxiv.org/abs/2511.18265)
*Mohamed Afane,Juntao Chen*

Main category: cs.CY

TL;DR: 本研究分析了2005-2021年纽约市42个社区6岁以下儿童的血铅水平检测情况，发现尽管全市血铅水平总体下降，但社区间差异持续存在。研究通过聚类分析和优化算法改进了检测资源分配策略。


<details>
  <summary>Details</summary>
Motivation: 尽管纽约市血铅水平总体呈下降趋势，但官方报告未充分揭示社区层面的差异，需要更全面的分析来识别和解决这些持续存在的不平等问题。

Method: 使用k-medoids聚类算法对社区进行分组，并采用网格搜索算法优化资源分配策略，综合考虑病例发生率和社区风险特征。

Result: 研究发现优化后的方法在病例检测方面取得了统计显著的改进，并通过关注服务不足和高风险群体提高了公平性。

Conclusion: 研究提出了可行的建议，包括在日托中心和幼儿园等场所开展家长意识宣传活动，以更好地解决儿童血铅水平检测的社区差异问题。

Abstract: This study investigates blood lead level (BLL) rates and testing among children under six years of age across the 42 neighborhoods in New York City from 2005 to 2021. Despite a citywide general decline in BLL rates, disparities at the neighborhood level persist and are not addressed in the official reports, highlighting the need for this comprehensive analysis. In this paper, we analyze the current BLL testing distribution and cluster the neighborhoods using a k-medoids clustering algorithm. We propose an optimized approach that improves resource allocation efficiency by accounting for case incidences and neighborhood risk profiles using a grid search algorithm. Our findings demonstrate statistically significant improvements in case detection and enhanced fairness by focusing on under-served and high-risk groups. Additionally, we propose actionable recommendations to raise awareness among parents, including outreach at local daycare centers and kindergartens, among other venues.

</details>


### [276] [Privacy Concerns and ChatGPT: Exploring Online Discourse through the Lens of Information Practice on Reddit](https://arxiv.org/abs/2511.18268)
*S M Mehedi Zaman,Saubhagya Joshi,Yiyi Wu*

Main category: cs.CY

TL;DR: 本研究通过分析Reddit用户在三个主要子版块中关于ChatGPT隐私问题的讨论，揭示了用户如何集体协商和应对隐私风险，包括风险信号传递、规范制定和适应实践。


<details>
  <summary>Details</summary>
Motivation: 随着数百万人使用ChatGPT进行教育、写作辅助和健康咨询等任务，人们对个人提示和数据如何存储和使用的担忧日益增长。

Method: 从2022年11月至2025年5月收集了三个主要Reddit子版块的426个帖子和1900条评论，采用信息实践理论视角进行定性主题分析，并通过BERTopic主题建模验证主题饱和度。

Result: 研究发现风险信号传递、规范制定和无奈接受是主导话语，集体故障排除和倡导隐私保护替代方案是关键的适应实践。Reddit作为集体意义建构的场所，用户在其中揭示风险、建立非正式规范并分享缓解隐私威胁的策略。

Conclusion: 研究结果为AI设计和隐私素养倡议提供了见解，强调了在线社区在应对新兴技术隐私挑战中的重要作用。

Abstract: As millions of people use ChatGPT for tasks such as education, writing assistance, and health advice, concerns have grown about how personal prompts and data are stored and used. This study explores how Reddit users collectively negotiate and respond to these privacy concerns. Posts were collected from three major subreddits -- r/Chatgpt, r/privacy, and r/OpenAI -- between November 2022 and May 2025. An iterative keyword search followed by manual screening resulted in a final dataset of 426 posts and 1,900 comments. Using information practice as the theoretical lens, we conducted a qualitative thematic analysis to identify collective practices of risk negotiation, validated with BERTopic topic modeling to ensure thematic saturation. Findings revealed risk signaling, norm-setting, and resignation as dominant discourses, and collective troubleshooting and advocacy for privacy-preserving alternatives as key adaptive practices. Reddit functions as a site of collective sense-making where users surface risks, establish informal norms, and share strategies for mitigating privacy threats, offering insights for AI design and privacy literacy initiatives.

</details>


### [277] [UnWEIRDing LLM Entity Recommendations](https://arxiv.org/abs/2511.18403)
*Aayush Kumar,Sanket Mhatre*

Main category: cs.CY

TL;DR: 本文研究了大型语言模型在推荐真实世界实体时存在的文化偏见问题，使用WEIRD框架评估不同LLM的推荐，并应用多元化提示策略来减轻这些偏见。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM广泛用于写作任务，但研究表明LLM生成的建议可能包含文化偏见，特别是在教育环境中对非英语母语者来说难以察觉。现有研究主要关注LLM的道德价值对齐偏见，本文旨在调查LLM对真实世界实体推荐中的文化偏见。

Method: 使用WEIRD（西方、受教育、工业化、富裕和民主）框架评估各种LLM在细粒度实体数据集上的推荐，并应用多元化提示策略来减轻这些偏见。

Result: 结果显示，虽然提示策略确实减少了此类偏见，但这种减少在不同模型之间并不一致，且某些类型实体的推荐比其他类型更具偏见。

Conclusion: LLM在推荐真实世界实体时存在文化偏见，多元化提示策略能部分减轻偏见但效果不一致，某些实体类型的偏见问题更为突出。

Abstract: Large Language Models have been widely been adopted by users for writing tasks such as sentence completions. While this can improve writing efficiency, prior research shows that LLM-generated suggestions may exhibit cultural biases which may be difficult for users to detect, especially in educational contexts for non-native English speakers. While such prior work has studied the biases in LLM moral value alignment, we aim to investigate cultural biases in LLM recommendations for real-world entities. To do so, we use the WEIRD (Western, Educated, Industrialized, Rich and Democratic) framework to evaluate recommendations by various LLMs across a dataset of fine-grained entities, and apply pluralistic prompt-based strategies to mitigate these biases. Our results indicate that while such prompting strategies do reduce such biases, this reduction is not consistent across different models, and recommendations for some types of entities are more biased than others.

</details>


### [278] [Optimal Meal Schedule for a Local Nonprofit Using LLM-Aided Data Extraction](https://arxiv.org/abs/2511.18483)
*Sergio Marin,Nhu Nguyen,Max,Zheng,Christina M. Weaver*

Main category: cs.CY

TL;DR: 开发了一个数据驱动的管道系统，用于为食品不安全社区生成15周的营养食谱计划，通过优化算法最小化批发成本并满足营养约束。


<details>
  <summary>Details</summary>
Motivation: 与Power Packs Project合作，解决当地社区食品不安全问题，通过优化方法在价格波动和不确定性下制定营养均衡且成本效益高的食谱计划。

Method: 集成PDF数据提取、大语言模型进行食材标准化、二元整数规划优化算法，将157个食谱映射到营养数据库，使用历史发票数据和通胀调整估算成本。

Result: 优化结果显示约束选择能在不确定性下产生营养均衡且成本效益高的计划，系统能有效处理实际价格波动并易于更新。

Conclusion: 部署了可搜索的Web平台，将分析模型集成到日常运营中，使工作人员能够按食材、类别或优化餐计划探索食谱，促进实时决策。

Abstract: We present a data-driven pipeline developed in collaboration with the Power Packs Project, a nonprofit addressing food insecurity in local communities. The system integrates data extraction from PDFs, large language models for ingredient standardization, and binary integer programming to generate a 15-week recipe schedule that minimizes projected wholesale costs while meeting nutritional constraints. All 157 recipes were mapped to a nutritional database and assigned estimated and predicted costs using historical invoice data and category-specific inflation adjustments. The model effectively handles real-world price volatility and is structured for easy updates as new recipes or cost data become available. Optimization results show that constraint-based selection yields nutritionally balanced and cost-efficient plans under uncertainty. To facilitate real-time decision-making, we deployed a searchable web platform that integrates analytical models into daily operations by enabling staff to explore recipes by ingredient, category, or through an optimized meal plan.

</details>


### [279] [Regularity as Structural Amplifier, Not Trap: A Causal and Archetype-Based Analysis of Dropout in a Constrained Engineering Curriculum](https://arxiv.org/abs/2511.18979)
*H. R. Paz*

Main category: cs.CY

TL;DR: 该研究使用CAPIRE框架分析工程教育中的规律性陷阱，发现学业滞后显著增加辍学风险，但对高能力学生影响较小，表明规律性规则是结构性脆弱放大器而非普遍陷阱。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证拉丁美洲工程教育中严格的课程安排和规律性规则是否确实会形成"规律性陷阱"，导致有能力的学生陷入困境。

Method: 采用CAPIRE框架（考虑流失的课程管道），结合课程拓扑和因果估计，使用手动LinearDML估计器评估学业滞后对辍学的平均和条件因果效应，控制宏观冲击因素。

Result: 学业滞后显著增加总体辍学风险（ATE = 0.0167, p < 0.0001），但对高速度（高能力）学生影响急剧减小。原型分析显示摩擦主要影响已具有高初始摩擦和不稳定进展轨迹的学生。

Conclusion: 规律性规则作为结构性脆弱放大器而非普遍陷阱发挥作用，建议工程课程设计应针对性地在核心基础课程中分配缓冲空间和干预政策以减少摩擦。

Abstract: Engineering programmes, particularly in Latin America, are often governed by rigid curricula and strict regularity rules that are claimed to create a Regularity Trap for capable students. This study tests that causal hypothesis using the CAPIRE framework, a leakage-aware pipeline that integrates curriculum topology and causal estimation. Using longitudinal data from 1,343 civil engineering students in Argentina, we formalize academic lag (accumulated friction) as a treatment and academic velocity as an ability proxy. A manual LinearDML estimator is employed to assess the average (ATE) and conditional (CATE) causal effects of lag on subsequent dropout, controlling for macro shocks (strikes, inflation). Results confirm that academic lag significantly increases dropout risk overall (ATE = 0.0167, p < 0.0001). However, the effect decreases sharply for high-velocity (high-ability) students, contradicting the universal Trap hypothesis. Archetype analysis (UMAP/DBSCAN) shows that friction disproportionately harms trajectories already characterized by high initial friction and unstable progression. 8 We conclude that regularity rules function as a Structural Amplifier of pre-existing vulnerability rather than a universal trap. This has direct implications for engineering curriculum design, demanding targeted slack allocation and intervention policies to reduce friction at core basic-cycle courses

</details>


### [280] [Data Flows and Colonial Regimes in Africa: A Critical Analysis of the Colonial Futurities Embedded in AI Ecosystems](https://arxiv.org/abs/2511.19283)
*Ndaka. A,Avila-Acosta. F,Mbula-Ndaka. H,Amera. C,Chauke. S,Majiwa. E*

Main category: cs.CY

TL;DR: 本文通过权力和利益视角分析非洲AI和大数据的潜在问题，探讨推荐算法如何重塑数字社会、传播算法殖民主义和负面性别规范，并提出采用响应式商业模式。


<details>
  <summary>Details</summary>
Motivation: 探讨AI和大数据在非洲背景下可能带来的算法殖民主义、性别规范问题及其对可持续发展议程的影响。

Method: 基于与肯尼亚社交媒体用户的讨论、个人经验和六个月的参与式观察。

Result: 揭示了AI推荐算法在非洲可能重新创建数字社会、传播算法殖民主义和负面性别规范的风险。

Conclusion: 建议采用响应式商业模式，考虑AI的替代性社会物质世界，以应对这些挑战。

Abstract: This chapter seeks to frame the elemental and invisible problems of AI and big data in the African context by examining digital sites and infrastructure through the lens of power and interests. It will present reflections on how these sites are using AI recommendation algorithms to recreate new digital societies in the region, how they have the potential to propagate algorithmic colonialism and negative gender norms, and what this means for the regional sustainable development agenda. The chapter proposes adopting business models that embrace response-ability and consider the existence of alternative socio-material worlds of AI. These reflections will mainly come from ongoing discussions with Kenyan social media users in this authors' user space talks, personal experiences and six months of active participant observations done by the authors.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [281] [Practical Machine Learning for Aphasic Discourse Analysis](https://arxiv.org/abs/2511.17553)
*Jason M. Pittman,Anton Phillips,Yesenia Medina-Santos,Brielle C. Stark*

Main category: cs.LG

TL;DR: 本研究评估了五种机器学习模型在失语症患者图片描述任务中自动识别正确信息单元(CIU)的能力，发现模型在区分词语与非词语方面表现优异，但在识别CIU方面仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管正确信息单元(CIU)分析是言语病理学家常用的失语症语言能力评估方法，但由于需要手动编码和分析，临床应用受限。机器学习技术有望自动化这一过程，减轻临床工作负担。

Method: 使用五种监督机器学习模型，基于失语症患者的人类编码转录本及其词语和CIU数据进行训练，评估模型在图片描述任务中识别CIU的可靠性。

Result: 词语与非词语分类模型准确率接近完美(0.995)，AUC范围0.914-0.995；而CIU与非CIU分类表现差异较大，k-近邻模型准确率最高(0.824)，AUC第二高(0.787)。

Conclusion: 监督机器学习模型能够有效区分词语与非词语，但识别正确信息单元(CIU)仍然具有挑战性，需要进一步改进模型性能。

Abstract: Analyzing spoken discourse is a valid means of quantifying language ability in persons with aphasia. There are many ways to quantify discourse, one common way being to evaluate the informativeness of the discourse. That is, given the total number of words produced, how many of those are context-relevant and accurate. This type of analysis is called Correct Information Unit (CIU) analysis and is one of the most prevalent discourse analyses used by speech-language pathologists (SLPs). Despite this, CIU analysis in the clinic remains limited due to the manual labor needed by SLPs to code and analyze collected speech. Recent advances in machine learning (ML) seek to augment such labor by automating modeling of propositional, macrostructural, pragmatic, and multimodal dimensions of discourse. To that end, this study evaluated five ML models for reliable identification of Correct Information Units (CIUs, Nicholas & Brookshire, 1993), during a picture description task. The five supervised ML models were trained using randomly selected human-coded transcripts and accompanying words and CIUs from persons with aphasia. The baseline model training produced a high accuracy across transcripts for word vs non-word, with all models achieving near perfect performance (0.995) with high AUC range (0.914 min, 0.995 max). In contrast, CIU vs non-CIU showed a greater variability, with the k-nearest neighbor (k-NN) model the highest accuracy (0.824) and second highest AUC (0.787). These findings indicate that while the supervised ML models can distinguish word from not word, identifying CIUs is challenging.

</details>


### [282] [Root Cause Analysis for Microservice Systems via Cascaded Conditional Learning with Hypergraphs](https://arxiv.org/abs/2511.17566)
*Shuaiyu Xie,Hanbin He,Jian Wang,Bing Li*

Main category: cs.LG

TL;DR: CCLH是一个用于微服务系统根因分析的新框架，通过级联条件学习和异构超图建模解决现有方法的两个关键挑战：任务间因果依赖和实例间群体影响关系。


<details>
  <summary>Details</summary>
Motivation: 现有根因分析方法存在两个主要问题：1）联合学习范式忽略了RCL和FTI任务间的因果依赖关系；2）主要关注点对点关系，忽略了由部署配置和负载均衡引起的实例间群体影响。

Method: 提出CCLH框架，采用级联条件学习来协调诊断任务，提供三级分类来描述实例间的群体影响，并使用异构超图来建模这些关系以模拟故障传播。

Result: 在三个微服务基准数据集上的广泛实验表明，CCLH在根因定位和故障类型识别方面均优于最先进的方法。

Conclusion: CCLH通过级联条件学习和异构超图建模有效解决了现有根因分析方法的局限性，在微服务系统的根因定位和故障类型识别任务中表现出优越性能。

Abstract: Root cause analysis in microservice systems typically involves two core tasks: root cause localization (RCL) and failure type identification (FTI). Despite substantial research efforts, conventional diagnostic approaches still face two key challenges. First, these methods predominantly adopt a joint learning paradigm for RCL and FTI to exploit shared information and reduce training time. However, this simplistic integration neglects the causal dependencies between tasks, thereby impeding inter-task collaboration and information transfer. Second, these existing methods primarily focus on point-to-point relationships between instances, overlooking the group nature of inter-instance influences induced by deployment configurations and load balancing. To overcome these limitations, we propose CCLH, a novel root cause analysis framework that orchestrates diagnostic tasks based on cascaded conditional learning. CCLH provides a three-level taxonomy for group influences between instances and incorporates a heterogeneous hypergraph to model these relationships, facilitating the simulation of failure propagation. Extensive experiments conducted on datasets from three microservice benchmarks demonstrate that CCLH outperforms state-of-the-art methods in both RCL and FTI.

</details>


### [283] [Binary BPE: A Family of Cross-Platform Tokenizers for Binary Analysis](https://arxiv.org/abs/2511.17573)
*Michael J. Bommarito*

Main category: cs.LG

TL;DR: 提出了Binary BPE分词器家族，专门用于二进制分析，通过字节对编码在多种平台和架构的可执行文件上训练，提供4K到64K词汇表的分词器，相比原始字节可让固定长度transformer上下文窗口容纳2-3倍的二进制内容。


<details>
  <summary>Details</summary>
Motivation: 解决二进制分析中序列模型的瓶颈问题：原始字节浪费transformer上下文窗口容量，现有文本分词器无法处理0x00-0xFF的任意字节序列。

Method: 开发了跨平台Byte Pair Encoding分词器，在包含Linux、Windows、macOS、Android和恶意软件来源的大型二进制语料库上训练，提供4K、8K、16K、32K和64K词汇表的分词器。

Result: 分词器发现了可解释的模式（ELF/PE头部、指令序列、跨平台字符串），同时每个token实现多字节压缩。在未压缩可执行文件上，相比原始字节可让固定长度transformer上下文窗口容纳2-3倍的二进制内容。

Conclusion: Binary BPE分词器为二进制分析提供了更高效的研究和实际部署基础，支持内容识别、恶意软件检测、逆向工程和优化等应用，已在HuggingFace发布开源分词器。

Abstract: Sequence models for binary analysis are bottlenecked by byte-level tokenization: raw bytes waste precious context window capacity for transformers and other neural network architectures, and many existing text-oriented tokenizers fail on arbitrary 0x00--0xFF sequences. To address this issue, we introduce the Binary BPE tokenizer family, a set of cross-platform Byte Pair Encoding (BPE) tokenizers for executables trained on a large corpus of binaries spanning multiple platforms, architectures, and operating systems, including Linux, Windows, macOS, Android, and malware sources. We release trained tokenizers with vocabularies of 4K, 8K, 16K, 32K, and 64K tokens, enabling both systematic scaling studies and practical deployment from resource-constrained edge devices to high-throughput datacenters. These tokenizers discover interpretable patterns (ELF/PE headers, instruction sequences, cross-platform strings) while yielding multi-byte compression per token. On representative uncompressed executables (e.g., ELF/PE/Mach-O rather than compressed APKs), the Binary BPE tokenizers typically allow for roughly 2-3x more binary content per fixed-length transformer context window than raw bytes, enabling more efficient research and practical deployment for content identification, malware detection, reverse engineering, and optimization. We release the trained Binary BPE tokenizers on HuggingFace, providing a drop-in, open-source foundation for binary-focused language models and context-efficient agentic tools.

</details>


### [284] [Efficient Mathematical Reasoning Models via Dynamic Pruning and Knowledge Distillation](https://arxiv.org/abs/2511.17577)
*Fengming Yu,Qingyu Meng,Haiwei Pan,Kejia Zhang*

Main category: cs.LG

TL;DR: 提出了一种轻量级优化方法，结合动态注意力头剪枝和知识蒸馏，在保持数学推理能力的同时显著降低大语言模型的计算和存储成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在数学推理等复杂任务中表现出色，但其巨大的计算和存储成本阻碍了实际部署，需要找到平衡性能与效率的解决方案。

Method: 使用权重范数和熵的组合动态评估多头注意力机制中每个注意力头的重要性，实时剪枝冗余头以减少计算开销，并通过知识蒸馏将原始模型信息迁移到剪枝后的学生模型。

Result: 在Math23k数据集上，30%剪枝率下参数减少18.7%，推理速度提升27.5%，FLOPs减少19.3%，准确率仅下降0.7%（从84.4%到83.7%）。

Conclusion: 该方法在保持强大推理性能的同时实现了显著的效率提升，为大语言模型在数学推理任务中的高效部署提供了实用解决方案。

Abstract: With the rapid development of deep learning, large language models have shown strong capabilities in complex reasoning tasks such as mathematical equation solving. However, their substantial computational and storage costs hinder practical deployment. This paper proposes a lightweight optimization method that integrates dynamic attention head pruning with knowledge distillation. The approach dynamically evaluates the importance of each attention head in the multi-head attention mechanism using a combination of weight norms and entropy, and prunes redundant heads in real time to reduce computational overhead. To mitigate performance degradation, knowledge distillation transfers information from the original model to the pruned student, enabling the smaller model to preserve reasoning ability. Experiments conducted on both Math23k and ASDiv-A verify the effectiveness of the proposed method. For example, on Math23k with a 30% pruning ratio, parameters are reduced by 18.7%, inference speed is improved by 27.5%, FLOPs are reduced by 19.3%, and accuracy drops only 0.7% (from 84.4% to 83.7%). These results demonstrate that the method achieves substantial efficiency gains while maintaining strong reasoning performance, providing a practical solution for efficient deployment of large language models in mathematical reasoning tasks.

</details>


### [285] [Multi-Value Alignment for LLMs via Value Decorrelation and Extrapolation](https://arxiv.org/abs/2511.17579)
*Hefei Xu,Le Wu,Chen Cheng,Hao Liu*

Main category: cs.LG

TL;DR: 本文提出了一个名为MVA的新框架，用于解决大语言模型在多个可能冲突的人类价值观对齐时的挑战。该框架通过最小化不同价值观之间的互信息来减轻参数干扰，并采用价值外推策略探索帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，将其与人类价值观对齐以确保安全和伦理已成为关键挑战。现有方法（如RLHF和DPO）在多价值观对齐中存在不稳定、效率低下以及无法有效处理价值观冲突等局限性。

Method: 提出MVA框架，通过最小化不同人类价值观之间的互信息来减轻参数干扰，并采用价值外推策略高效探索帕累托前沿，构建具有不同价值偏好的LLMs集合。

Result: 大量实验证明，MVA在将LLMs与多个人类价值观对齐方面持续优于现有基线方法。

Conclusion: MVA框架有效解决了多价值观对齐中的参数干扰和价值观冲突问题，能够实现更优的权衡，在多个价值观对齐任务中表现优异。

Abstract: With the rapid advancement of large language models (LLMs), aligning them with human values for safety and ethics has become a critical challenge. This problem is especially challenging when multiple, potentially conflicting human values must be considered and balanced. Although several variants of existing alignment methods (such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO)) have been proposed to address multi-value alignment, they suffer from notable limitations: 1) they are often unstable and inefficient in multi-value optimization; and 2) they fail to effectively handle value conflicts. As a result, these approaches typically struggle to achieve optimal trade-offs when aligning multiple values.
  To address this challenge, we propose a novel framework called Multi-Value Alignment (MVA). It mitigates alignment degradation caused by parameter interference among diverse human values by minimizing their mutual information. Furthermore, we propose a value extrapolation strategy to efficiently explore the Pareto frontier, thereby constructing a set of LLMs with diverse value preferences. Extensive experiments demonstrate that MVA consistently outperforms existing baselines in aligning LLMs with multiple human values.

</details>


### [286] [EgoCogNav: Cognition-aware Human Egocentric Navigation](https://arxiv.org/abs/2511.17581)
*Zhiwen Qiu,Ziang Liu,Wenqian Niu,Tapomayukh Bhattacharjee,Saleh Kalantari*

Main category: cs.LG

TL;DR: EgoCogNav是一个多模态自我中心导航框架，通过融合场景特征和感官线索来预测感知路径不确定性，并联合预测轨迹和头部运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注完全观察场景中的运动预测，往往忽略捕捉人们对空间感受和反应的人类因素。

Method: 提出EgoCogNav框架，将感知路径不确定性作为潜在状态进行预测，通过融合场景特征和感官线索来联合预测轨迹和头部运动。同时构建了CEN数据集，包含6小时真实世界自我中心记录。

Result: 实验表明EgoCogNav学习的感知不确定性与人类行为（如扫描、犹豫、回溯）高度相关，并能泛化到未见过的环境。

Conclusion: 该工作为理解人类-环境交互、实现安全社交导航和有效辅助寻路提供了重要基础，通过建模认知和体验因素来增强导航预测能力。

Abstract: Modeling the cognitive and experiential factors of human navigation is central to deepening our understanding of human-environment interaction and to enabling safe social navigation and effective assistive wayfinding. Most existing methods focus on forecasting motions in fully observed scenes and often neglect human factors that capture how people feel and respond to space. To address this gap, We propose EgoCogNav, a multimodal egocentric navigation framework that predicts perceived path uncertainty as a latent state and jointly forecasts trajectories and head motion by fusing scene features with sensory cues. To facilitate research in the field, we introduce the Cognition-aware Egocentric Navigation (CEN) dataset consisting 6 hours of real-world egocentric recordings capturing diverse navigation behaviors in real-world scenarios. Experiments show that EgoCogNav learns the perceived uncertainty that highly correlates with human-like behaviors such as scanning, hesitation, and backtracking while generalizing to unseen environments.

</details>


### [287] [GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2511.17582)
*Jie Ou,Shuaihong Jiang,Yingjun Du,Cees G. M. Snoek*

Main category: cs.LG

TL;DR: GateRA是一个参数高效微调框架，通过token感知调制动态调整PEFT更新的强度，实现选择性token级适应，在多个常识推理基准上优于现有PEFT方法。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法对所有token应用静态、输入无关的更新，忽视了不同输入的重要性和难度差异，这可能导致在简单内容上过拟合或在信息丰富区域适应不足。

Method: 在标准PEFT分支中引入自适应门控机制，实现token级选择性适应；使用基于熵的正则化鼓励接近二元的门控决策；理论分析显示GateRA在PEFT路径上诱导软梯度掩码效应。

Result: 在多个常识推理基准测试中，GateRA始终优于或匹配先前的PEFT方法；经验可视化揭示了相位敏感行为，GateRA自动抑制冗余预填充token的更新，同时在解码期间强调适应。

Conclusion: GateRA通过token感知调制实现了更智能的参数高效微调，能够根据输入难度动态调整适应强度，在保持预训练知识的同时专注于具有挑战性的情况。

Abstract: Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, DoRA, and HiRA, enable lightweight adaptation of large pre-trained models via low-rank updates. However, existing PEFT approaches apply static, input-agnostic updates to all tokens, disregarding the varying importance and difficulty of different inputs. This uniform treatment can lead to overfitting on trivial content or under-adaptation on more informative regions, especially in autoregressive settings with distinct prefill and decoding dynamics. In this paper, we propose GateRA, a unified framework that introduces token-aware modulation to dynamically adjust the strength of PEFT updates. By incorporating adaptive gating into standard PEFT branches, GateRA enables selective, token-level adaptation, preserving pre-trained knowledge for well-modeled inputs while focusing capacity on challenging cases. Empirical visualizations reveal phase-sensitive behaviors, where GateRA automatically suppresses updates for redundant prefill tokens while emphasizing adaptation during decoding. To promote confident and efficient modulation, we further introduce an entropy-based regularization that encourages near-binary gating decisions. This regularization prevents diffuse update patterns and leads to interpretable, sparse adaptation without hard thresholding. Finally, we present a theoretical analysis showing that GateRA induces a soft gradient-masking effect over the PEFT path, enabling continuous and differentiable control over adaptation. Experiments on multiple commonsense reasoning benchmarks demonstrate that GateRA consistently outperforms or matches prior PEFT methods.

</details>


### [288] [Learning Straight Flows: Variational Flow Matching for Efficient Generation](https://arxiv.org/abs/2511.17583)
*Chenrui Ma,Xi Xiao,Tianyang Wang,Xiao Wang,Yanning Shen*

Main category: cs.LG

TL;DR: 提出了S-VFM方法，通过引入变分潜码来强制轨迹直线化，解决Flow Matching中一步生成能力受限的问题，在多个基准测试中表现优异且效率更高。


<details>
  <summary>Details</summary>
Motivation: Flow Matching由于依赖学习的弯曲轨迹，在实现一步生成方面能力有限。现有方法存在离散近似误差、训练不稳定和收敛困难等问题。

Method: 提出S-VFM方法，将代表"生成概览"的变分潜码集成到Flow Matching框架中，显式强制轨迹直线化，理想情况下产生线性生成路径。

Result: 在三个挑战性基准测试中取得了有竞争力的性能，与现有方法相比在训练和推理效率方面都显示出优势。

Conclusion: S-VFM通过引入变分潜码有效解决了Flow Matching的轨迹弯曲问题，实现了更高效的一步生成。

Abstract: Flow Matching has limited ability in achieving one-step generation due to its reliance on learned curved trajectories. Previous studies have attempted to address this limitation by either modifying the coupling distribution to prevent interpolant intersections or introducing consistency and mean-velocity modeling to promote straight trajectory learning. However, these approaches often suffer from discrete approximation errors, training instability, and convergence difficulties. To tackle these issues, in the present work, we propose \textbf{S}traight \textbf{V}ariational \textbf{F}low \textbf{M}atching (\textbf{S-VFM}), which integrates a variational latent code representing the ``generation overview'' into the Flow Matching framework. \textbf{S-VFM} explicitly enforces trajectory straightness, ideally producing linear generation paths. The proposed method achieves competitive performance across three challenge benchmarks and demonstrates advantages in both training and inference efficiency compared with existing methods.

</details>


### [289] [LLM-Powered Text-Attributed Graph Anomaly Detection via Retrieval-Augmented Reasoning](https://arxiv.org/abs/2511.17584)
*Haoyan Xu,Ruizhi Qian,Zhengtao Yao,Ziyi Liu,Li Li,Yuqi Li,Yanshu Li,Wenqing Zheng,Daniele Rosa,Daniel Barcklow,Senthil Kumar,Jieyu Zhao,Yue Zhao*

Main category: cs.LG

TL;DR: 本文提出了TAG-AD基准数据集，用于文本属性图上的异常节点检测，利用LLM生成语义连贯但上下文不一致的真实异常文本，并开发了基于RAG的零样本LLM异常检测框架。


<details>
  <summary>Details</summary>
Motivation: 文本属性图在异常检测领域研究不足，主要原因是缺乏标准化基准数据集。现有方法难以处理自然语言表达的节点信息，需要更真实的异常检测评估环境。

Method: 1) 构建TAG-AD基准数据集，利用LLM直接在原始文本空间生成真实异常节点文本；2) 提出基于RAG的零样本LLM异常检测框架，构建全局异常知识库并提炼可重用的分析框架；3) 对比评估基于GNN的无监督方法和零样本LLM方法。

Result: 实验结果显示：LLM在检测上下文异常方面特别有效，而基于GNN的方法在结构异常检测方面仍占优势。RAG辅助提示在无需人工提示工程的情况下，实现了与人工设计提示相当的性能。

Conclusion: TAG-AD为文本属性图异常检测提供了标准化基准，RAG辅助的零样本LLM框架在消除手动提示工程依赖的同时保持了检测性能，为实际应用提供了实用价值。

Abstract: Anomaly detection on attributed graphs plays an essential role in applications such as fraud detection, intrusion monitoring, and misinformation analysis. However, text-attributed graphs (TAGs), in which node information is expressed in natural language, remain underexplored, largely due to the absence of standardized benchmark datasets. In this work, we introduce TAG-AD, a comprehensive benchmark for anomaly node detection on TAGs. TAG-AD leverages large language models (LLMs) to generate realistic anomalous node texts directly in the raw text space, producing anomalies that are semantically coherent yet contextually inconsistent and thus more reflective of real-world irregularities. In addition, TAG-AD incorporates multiple other anomaly types, enabling thorough and reproducible evaluation of graph anomaly detection (GAD) methods. With these datasets, we further benchmark existing unsupervised GNN-based GAD methods as well as zero-shot LLMs for GAD.
  As part of our zero-shot detection setup, we propose a retrieval-augmented generation (RAG)-assisted, LLM-based zero-shot anomaly detection framework. The framework mitigates reliance on brittle, hand-crafted prompts by constructing a global anomaly knowledge base and distilling it into reusable analysis frameworks. Our experimental results reveal a clear division of strengths: LLMs are particularly effective at detecting contextual anomalies, whereas GNN-based methods remain superior for structural anomaly detection. Moreover, RAG-assisted prompting achieves performance comparable to human-designed prompts while eliminating manual prompt engineering, underscoring the practical value of our RAG-assisted zero-shot LLM anomaly detection framework.

</details>


### [290] [PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for Multimodal Sentiment Analysis](https://arxiv.org/abs/2511.17585)
*Kang He,Boyu Chen,Yuzhe Ding,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.LG

TL;DR: PaSE框架通过原型对齐校准和Shapley优化均衡来解决多模态情感分析中的模态竞争问题，提升模态间协作性能


<details>
  <summary>Details</summary>
Motivation: 多模态情感分析中常出现模态竞争现象，主导模态会压制较弱模态，导致性能不佳

Method: 提出PaSE框架：原型引导校准学习(PCL)通过熵最优传输机制精炼单模态表示；双阶段优化策略：原型门控融合模块提取共享表示，Shapley梯度调制(SGM)自适应调整梯度

Result: 在IEMOCAP、MOSI和MOSEI数据集上的广泛实验证实PaSE实现了优越性能，有效缓解了模态竞争

Conclusion: PaSE框架通过原型对齐和Shapley优化有效解决了多模态情感分析中的模态竞争问题，提升了模型性能

Abstract: Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by integrating textual, acoustic, and visual signals. Although multimodal fusion is designed to leverage cross-modal complementarity, real-world scenarios often exhibit modality competition: dominant modalities tend to overshadow weaker ones, leading to suboptimal performance.In this paper, we propose PaSE, a novel Prototype-aligned Calibration and Shapley-optimized Equilibrium framework, which enhances collaboration while explicitly mitigating modality competition. PaSE first applies Prototype-guided Calibration Learning (PCL) to refine unimodal representations and align them through an Entropic Optimal Transport mechanism that ensures semantic consistency. To further stabilize optimization, we introduce a Dual-Phase Optimization strategy. A prototype-gated fusion module is first used to extract shared representations, followed by Shapley-based Gradient Modulation (SGM), which adaptively adjusts gradients according to the contribution of each modality. Extensive experiments on IEMOCAP, MOSI, and MOSEI confirm that PaSE achieves the superior performance and effectively alleviates modality competition.

</details>


### [291] [Emotion and Intention Guided Multi-Modal Learning for Sticker Response Selection](https://arxiv.org/abs/2511.17587)
*Yuxuan Hu,Jian Chen,Yuhao Wang,Zixuan Li,Jing Xiong,Pengyue Jia,Wei Wang,Chengming Li,Xiangyu Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种情感和意图引导的多模态学习框架（EIGML），用于贴纸响应选择任务，通过联合建模情感和意图来减少孤立建模带来的偏差，显著提高了选择准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的贴纸响应选择方法通常依赖语义匹配，并将情感和意图线索分开建模，当情感和意图不一致时容易导致不匹配。

Method: 提出了EIGML框架，包括双级对比框架进行模态内和模态间对齐，以及意图-情感引导的多模态融合模块，通过三个组件逐步整合情感和意图信息。

Result: 在两个公开的SRS数据集上的实验结果表明，EIGML持续优于最先进的基线方法，实现了更高的准确性和对情感和意图特征的更好理解。

Conclusion: EIGML框架通过联合建模情感和意图，有效提升了贴纸选择的性能，为多模态对话理解提供了新的解决方案。

Abstract: Stickers are widely used in online communication to convey emotions and implicit intentions. The Sticker Response Selection (SRS) task aims to select the most contextually appropriate sticker based on the dialogue. However, existing methods typically rely on semantic matching and model emotional and intentional cues separately, which can lead to mismatches when emotions and intentions are misaligned. To address this issue, we propose Emotion and Intention Guided Multi-Modal Learning (EIGML). This framework is the first to jointly model emotion and intention, effectively reducing the bias caused by isolated modeling and significantly improving selection accuracy. Specifically, we introduce Dual-Level Contrastive Framework to perform both intra-modality and inter-modality alignment, ensuring consistent representation of emotional and intentional features within and across modalities. In addition, we design an Intention-Emotion Guided Multi-Modal Fusion module that integrates emotional and intentional information progressively through three components: Emotion-Guided Intention Knowledge Selection, Intention-Emotion Guided Attention Fusion, and Similarity-Adjusted Matching Mechanism. This design injects rich, effective information into the model and enables a deeper understanding of the dialogue, ultimately enhancing sticker selection performance. Experimental results on two public SRS datasets show that EIGML consistently outperforms state-of-the-art baselines, achieving higher accuracy and a better understanding of emotional and intentional features. Code is provided in the supplementary materials.

</details>


### [292] [Llamazip: Leveraging LLaMA for Lossless Text Compression and Training Dataset Detection](https://arxiv.org/abs/2511.17589)
*Sören Dréano,Derek Molloy,Noel Murphy*

Main category: cs.LG

TL;DR: Llamazip是一种基于LLaMA3语言模型预测能力的无损文本压缩算法，通过仅存储模型无法预测的token来实现显著数据压缩，同时保持数据完整性。


<details>
  <summary>Details</summary>
Motivation: 开发一种利用语言模型预测能力的高效无损文本压缩方法，并探索其在识别文档是否属于语言模型训练数据集方面的潜力。

Method: 基于LLaMA3语言模型的预测能力，仅存储模型无法准确预测的token，分析量化水平和上下文窗口大小对性能的影响。

Result: Llamazip实现了显著的数据压缩效果，同时能够识别文档是否属于语言模型的训练数据集，解决了数据来源、知识产权和模型训练透明度等关键问题。

Conclusion: Llamazip不仅提供高效的文本压缩解决方案，还展示了语言模型在数据溯源和透明度方面的应用潜力。

Abstract: This work introduces Llamazip, a novel lossless text compression algorithm based on the predictive capabilities of the LLaMA3 language model. Llamazip achieves significant data reduction by only storing tokens that the model fails to predict, optimizing storage efficiency without compromising data integrity. Key factors affecting its performance, including quantization and context window size, are analyzed, revealing their impact on compression ratios and computational requirements. Beyond compression, Llamazip demonstrates the potential to identify whether a document was part of the training dataset of a language model. This capability addresses critical concerns about data provenance, intellectual property, and transparency in language model training.

</details>


### [293] [SHAP Distance: An Explainability-Aware Metric for Evaluating the Semantic Fidelity of Synthetic Tabular Data](https://arxiv.org/abs/2511.17590)
*Ke Yu,Shigeru Ishikura,Yukari Usukura,Yuki Shigoku,Teruaki Hayashi*

Main category: cs.LG

TL;DR: 本文提出SHAP距离，一种基于可解释性的新指标，用于评估合成表格数据的语义保真度，弥补了传统统计相似性和预测性能评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据评估方法主要关注分布相似性和预测性能，但无法评估模型在合成数据上的推理模式是否与真实数据一致，即语义保真度问题。

Method: 引入SHAP距离，定义为从真实数据与合成数据训练的模型导出的全局SHAP归因向量之间的余弦距离。

Result: 在医疗健康记录、企业发票交易和电信流失日志等多个数据集上验证，SHAP距离能可靠识别传统统计和预测指标忽略的语义差异。

Conclusion: SHAP距离是评估合成表格数据语义保真度的实用且具有区分性的工具，建议将基于归因的评估整合到未来基准测试流程中。

Abstract: Synthetic tabular data, which are widely used in domains such as healthcare, enterprise operations, and customer analytics, are increasingly evaluated to ensure that they preserve both privacy and utility. While existing evaluation practices typically focus on distributional similarity (e.g., the Kullback-Leibler divergence) or predictive performance (e.g., Train-on-Synthetic-Test-on-Real (TSTR) accuracy), these approaches fail to assess semantic fidelity, that is, whether models trained on synthetic data follow reasoning patterns consistent with those trained on real data. To address this gap, we introduce the SHapley Additive exPlanations (SHAP) Distance, a novel explainability-aware metric that is defined as the cosine distance between the global SHAP attribution vectors derived from classifiers trained on real versus synthetic datasets. By analyzing datasets that span clinical health records with physiological features, enterprise invoice transactions with heterogeneous scales, and telecom churn logs with mixed categorical-numerical attributes, we demonstrate that the SHAP Distance reliably identifies semantic discrepancies that are overlooked by standard statistical and predictive measures. In particular, our results show that the SHAP Distance captures feature importance shifts and underrepresented tail effects that the Kullback-Leibler divergence and Train-on-Synthetic-Test-on-Real accuracy fail to detect. This study positions the SHAP Distance as a practical and discriminative tool for auditing the semantic fidelity of synthetic tabular data, and offers practical guidelines for integrating attribution-based evaluation into future benchmarking pipelines.

</details>


### [294] [Comparative Analysis of Large Language Model Inference Serving Systems: A Performance Study of vLLM and HuggingFace TGI](https://arxiv.org/abs/2511.17593)
*Saicharan Kolluru*

Main category: cs.LG

TL;DR: 本文对vLLM和HuggingFace TGI两个开源LLM服务框架进行了全面的实证评估，发现vLLM在高并发场景下吞吐量比TGI高24倍，而TGI在交互式单用户场景下延迟更低。


<details>
  <summary>Details</summary>
Motivation: 在生产环境中部署大型语言模型需要高效的推理服务系统来平衡吞吐量、延迟和资源利用率，因此需要对现有框架进行系统性评估。

Method: 使用LLaMA-2模型（7B到70B参数）对vLLM和TGI进行多维度基准测试，包括吞吐量性能、端到端延迟、GPU内存利用率和可扩展性特征。

Result: vLLM通过其新颖的PagedAttention机制在高并发工作负载下比TGI实现高达24倍的吞吐量提升，而TGI在交互式单用户场景下表现出更低的尾部延迟。

Conclusion: 框架选择应基于具体用例需求：vLLM在高吞吐量批处理场景中表现优异，而TGI更适合具有中等并发性的延迟敏感型交互应用。

Abstract: The deployment of Large Language Models (LLMs) in production environments requires efficient inference serving systems that balance throughput, latency, and resource utilization. This paper presents a comprehensive empirical evaluation of two prominent open-source LLM serving frameworks: vLLM and HuggingFace Text Generation Inference (TGI). We benchmark these systems across multiple dimensions including throughput performance, end-to-end latency, GPU memory utilization, and scalability characteristics using LLaMA-2 models ranging from 7B to 70B parameters. Our experiments reveal that vLLM achieves up to 24x higher throughput than TGI under high-concurrency workloads through its novel PagedAttention mechanism, while TGI demonstrates lower tail latencies for interactive single-user scenarios. We provide detailed performance profiles for different deployment scenarios and offer practical recommendations for system selection based on workload characteristics. Our findings indicate that the choice between these frameworks should be guided by specific use-case requirements: vLLM excels in high-throughput batch processing scenarios, while TGI is better suited for latency-sensitive interactive applications with moderate concurrency.

</details>


### [295] [AutoSAGE: Input-Aware CUDA Scheduling for Sparse GNN Aggregation (SpMM/SDDMM) and CSR Attention](https://arxiv.org/abs/2511.17594)
*Aleksandar Stankovic*

Main category: cs.LG

TL;DR: AutoSAGE是一个输入感知的CUDA调度器，针对稀疏GNN聚合操作（CSR SpMM/SDDMM），通过轻量级估计和设备微探针选择最佳分块和映射策略，包含回退机制和持久缓存。


<details>
  <summary>Details</summary>
Motivation: 稀疏GNN聚合操作在不同度分布、特征宽度和GPU微架构下性能差异很大，需要针对不同输入自动优化。

Method: 使用轻量级估计和on-device微探针为每个输入选择最佳分块和映射策略，包含安全回退到供应商内核的机制和用于确定性重放的持久缓存。

Result: 在Reddit和OGBN-Products数据集上，在带宽受限的特征宽度下与供应商基准相当，在小宽度下获得性能提升；在合成稀疏度和偏斜压力测试中实现高达4.7倍的内核级加速。

Conclusion: AutoSAGE能够有效优化稀疏GNN聚合操作，提供了CUDA源代码、Python绑定、可复现测试框架和可重放缓存日志。

Abstract: Sparse GNN aggregations (CSR SpMM/SDDMM) vary widely in performance with degree skew, feature width, and GPU micro-architecture. We present AutoSAGE, an input-aware CUDA scheduler that chooses tiling and mapping per input using a lightweight estimate refined by on-device micro-probes, with a guardrail that safely falls back to vendor kernels and a persistent cache for deterministic replay. AutoSAGE covers SpMM and SDDMM and composes into a CSR attention pipeline (SDDMM -> row-softmax -> SpMM). On Reddit and OGBN-Products, it matches vendor baselines at bandwidth-bound feature widths and finds gains at small widths; on synthetic sparsity and skew stress tests it achieves up to 4.7x kernel-level speedups. We release CUDA sources, Python bindings, a reproducible harness, and replayable cache logs.

</details>


### [296] [Boosting Reinforcement Learning in 3D Visuospatial Tasks Through Human-Informed Curriculum Design](https://arxiv.org/abs/2511.17595)
*Markus D. Solbach,John K. Tsotsos*

Main category: cs.LG

TL;DR: 本文研究了强化学习在3D Same-Different视觉空间任务中的应用，发现标准方法面临挑战，但通过基于人类实验设计的课程学习实现了有效学习。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习在复杂、非结构化问题领域中的智能行为表现潜力，验证其在更广泛环境中的适用性。

Method: 使用PPO、行为克隆和模仿学习等最先进方法，并基于真实人类实验发现设计课程学习策略。

Result: 标准RL方法在直接学习最优策略方面遇到困难，但通过精心设计的课程学习实现了有效学习。

Conclusion: 课程学习为强化学习在复杂视觉空间任务中提供了有前景的解决方案，基于人类认知过程的设计策略能够有效提升学习效果。

Abstract: Reinforcement Learning is a mature technology, often suggested as a potential route towards Artificial General Intelligence, with the ambitious goal of replicating the wide range of abilities found in natural and artificial intelligence, including the complexities of human cognition. While RL had shown successes in relatively constrained environments, such as the classic Atari games and specific continuous control problems, recent years have seen efforts to expand its applicability. This work investigates the potential of RL in demonstrating intelligent behaviour and its progress in addressing more complex and less structured problem domains.
  We present an investigation into the capacity of modern RL frameworks in addressing a seemingly straightforward 3D Same-Different visuospatial task. While initial applications of state-of-the-art methods, including PPO, behavioural cloning and imitation learning, revealed challenges in directly learning optimal strategies, the successful implementation of curriculum learning offers a promising avenue. Effective learning was achieved by strategically designing the lesson plan based on the findings of a real-world human experiment.

</details>


### [297] [Non-stationary and Varying-discounting Markov Decision Processes for Reinforcement Learning](https://arxiv.org/abs/2511.17598)
*Zhizuo Chen,Theodore T. Allen*

Main category: cs.LG

TL;DR: 提出了非平稳和变折扣MDP（NVMDP）框架，解决传统MDP在非平稳环境和有限时域任务中的局限性，支持折扣率随时间和状态变化，无需改变状态空间、动作空间或奖励结构即可优化策略。


<details>
  <summary>Details</summary>
Motivation: 传统MDP算法在非平稳环境中面临挑战，无限时域公式不直接适用于有限时域任务，需要更灵活的框架来处理非平稳性和策略优化。

Method: 建立NVMDP理论框架，包括假设、状态和动作值函数公式化与递归、矩阵表示、最优性条件，并扩展动态规划、Q学习算法，以及函数逼近下的策略梯度定理和TRPO。

Result: 在非平稳网格世界环境中的实证评估显示，NVMDP算法能成功恢复多种奖励和折扣方案下的最优轨迹，而原始Q学习失败。

Conclusion: NVMDP提供了一个理论严谨且实际有效的强化学习框架，只需少量算法修改即可稳健处理非平稳性并实现显式最优策略塑造。

Abstract: Algorithms developed under stationary Markov Decision Processes (MDPs) often face challenges in non-stationary environments, and infinite-horizon formulations may not directly apply to finite-horizon tasks. To address these limitations, we introduce the Non-stationary and Varying-discounting MDP (NVMDP) framework, which naturally accommodates non-stationarity and allows discount rates to vary with time and transitions. Infinite-horizon, stationary MDPs emerge as special cases of NVMDPs for identifying an optimal policy, and finite-horizon MDPs are also subsumed within the NVMDP formulations. Moreover, NVMDPs provide a flexible mechanism to shape optimal policies, without altering the state space, action space, or the reward structure. We establish the theoretical foundations of NVMDPs, including assumptions, state- and action-value formulation and recursion, matrix representation, optimality conditions, and policy improvement under finite state and action spaces. Building on these results, we adapt dynamic programming and generalized Q-learning algorithms to NVMDPs, along with formal convergence proofs. For problems requiring function approximation, we extend the Policy Gradient Theorem and the policy improvement bound in Trust Region Policy Optimization (TRPO), offering proofs in both scalar and matrix forms. Empirical evaluations in a non-stationary gridworld environment demonstrate that NVMDP-based algorithms successfully recover optimal trajectories under multiple reward and discounting schemes, whereas original Q-learning fails. These results collectively show that NVMDPs provide a theoretically sound and practically effective framework for reinforcement learning, requiring only minor algorithmic modifications while enabling robust handling of non-stationarity and explicit optimal policy shaping.

</details>


### [298] [From Projection to Prediction: Beyond Logits for Scalable Language Models](https://arxiv.org/abs/2511.17599)
*Jianbing Dong,Jianbin Chang*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法，将LLM训练中的输出投影和损失预测集成到单一操作中，避免了显式logits张量生成，从而显著减少内存使用和带宽压力。


<details>
  <summary>Details</summary>
Motivation: 传统的两阶段训练流程（线性投影生成logits，然后计算交叉熵损失）会产生巨大的中间logits张量，导致显著的内存开销和带宽消耗，限制了模型的可扩展性和训练吞吐量。

Method: 通过直接从隐藏状态和目标标记计算损失，绕过显式的logits张量生成，将输出投影和损失预测集成到单一操作中。

Result: 实验证明该方法在LLM训练中实现了显著的内存节省和可测量的加速，能够支持更大的批处理大小和更长的序列，同时不牺牲准确性。

Conclusion: 重新思考投影和预测之间的边界具有重要价值，为高效LLM训练提供了实用的系统优化方案。

Abstract: Training Large Language Models (LLMs) typically involves a two-stage pipeline at the output layer: hidden states are projected into vocabulary logits via a linear transformation (lm_head), followed by cross-entropy loss computation against target tokens. While conceptually simple, this design incurs substantial overhead. The intermediate logits tensor, with dimensions proportional to batch size, sequence length, and vocabulary size, must be fully materialized in GPU memory, even though only one target token per position is ultimately used. This leads to significant memory footprint and bandwidth comsumption, limiting scalability and slowing training throughput.
  In this work, we introduce a novel approach to integrates the output projection and loss prediction into a single operation. By directly computing the loss from hidden states and target tokens, our approach bypasses explicit logits materialization. This design reduces memory usage and alleviates bandwidth pressure. Experiments on LLM training demonstrate that our method achieves substantial memory savings and measurable speedups compared to the standard two-stage pipeline, enabling large batch sizes and longer sequences without sacrificing accuracy. Our work highlights the benefits of rethinking the boundary between projection and prediction, offering a practical systems optimization for efficient LLM training.

</details>


### [299] [Generalizable and Efficient Automated Scoring with a Knowledge-Distilled Multi-Task Mixture-of-Experts](https://arxiv.org/abs/2511.17601)
*Luyang Fang,Tao Wang,Ping Ma,Xiaoming Zhai*

Main category: cs.LG

TL;DR: UniMoE-Guided是一种知识蒸馏的多任务混合专家方法，将多个任务特定大模型的专业知识转移到单个紧凑可部署模型中，实现高效自动评分。


<details>
  <summary>Details</summary>
Motivation: 解决自动评分中每个任务需要单独模型导致的计算资源、存储和维护成本过高的问题，为实际教育环境提供可扩展的解决方案。

Method: 使用知识蒸馏技术，结合共享编码器、门控MoE块（平衡共享和任务特定处理）以及轻量级任务头，通过真实标签和教师指导进行训练。

Result: 在9个科学推理任务上，性能与任务特定模型相当，存储需求比维护单独学生模型减少约6倍，比200亿参数教师模型减少87倍。

Conclusion: 该方法为课堂和大规模评估系统提供了可扩展、可靠且资源高效的自动评分实用路径。

Abstract: Automated scoring of written constructed responses typically relies on separate models per task, straining computational resources, storage, and maintenance in real-world education settings. We propose UniMoE-Guided, a knowledge-distilled multi-task Mixture-of-Experts (MoE) approach that transfers expertise from multiple task-specific large models (teachers) into a single compact, deployable model (student). The student combines (i) a shared encoder for cross-task representations, (ii) a gated MoE block that balances shared and task-specific processing, and (iii) lightweight task heads. Trained with both ground-truth labels and teacher guidance, the student matches strong task-specific models while being far more efficient to train, store, and deploy. Beyond efficiency, the MoE layer improves transfer and generalization: experts develop reusable skills that boost cross-task performance and enable rapid adaptation to new tasks with minimal additions and tuning. On nine NGSS-aligned science-reasoning tasks (seven for training/evaluation and two held out for adaptation), UniMoE-Guided attains performance comparable to per-task models while using $\sim$6$\times$ less storage than maintaining separate students, and $87\times$ less than the 20B-parameter teacher. The method offers a practical path toward scalable, reliable, and resource-efficient automated scoring for classroom and large-scale assessment systems.

</details>


### [300] [Copula Based Fusion of Clinical and Genomic Machine Learning Risk Scores for Breast Cancer Risk Stratification](https://arxiv.org/abs/2511.17605)
*Agnideep Aich,Sameera Hewage,Md Monzur Murshed*

Main category: cs.LG

TL;DR: 本研究使用copula方法直接建模临床和基因组机器学习风险评分的联合关系，以改善乳腺癌5年癌症特异性死亡率的风险分层。研究发现高斯copula能最好地捕捉两者的对称、中度正相关关系，通过这种联合分析能更好地识别预后最差的患者亚组。


<details>
  <summary>Details</summary>
Motivation: 临床和基因组模型通常使用简单的线性规则结合，未能充分考虑它们在极端情况下的风险评分关系，需要更准确地建模两者的联合关系来改善风险分层。

Method: 使用METABRIC乳腺癌队列，定义临床变量集和基因组变量集，训练随机森林和XGBoost等分类器，通过5折交叉验证获得无偏风险评分，然后使用高斯、Clayton和Gumbel copula拟合联合分布。

Result: 临床模型区分度良好（AUC 0.783），基因组模型表现中等（AUC 0.681），高斯copula最适合捕捉两者的联合关系（bootstrap p=0.997）。基于联合关系的患者分组显示，临床和基因组均为高风险的患者生存率显著差于仅在一方面高风险的患者。

Conclusion: copula融合方法在真实世界队列中有效，考虑评分间的依赖关系能更好地识别预后最差的患者亚组。

Abstract: Clinical and genomic models are both used to predict breast cancer outcomes, but they are often combined using simple linear rules that do not account for how their risk scores relate, especially at the extremes. Using the METABRIC breast cancer cohort, we studied whether directly modeling the joint relationship between clinical and genomic machine learning risk scores could improve risk stratification for 5-year cancer-specific mortality. We created a binary 5-year cancer-death outcome and defined two sets of predictors: a clinical set (demographic, tumor, and treatment variables) and a genomic set (gene-expression $z$-scores). We trained several supervised classifiers, such as Random Forest and XGBoost, and used 5-fold cross-validated predicted probabilities as unbiased risk scores. These scores were converted to pseudo-observations on $(0,1)^2$ to fit Gaussian, Clayton, and Gumbel copulas. Clinical models showed good discrimination (AUC 0.783), while genomic models had moderate performance (AUC 0.681). The joint distribution was best captured by a Gaussian copula (bootstrap $p=0.997$), which suggests a symmetric, moderately strong positive relationship. When we grouped patients based on this relationship, Kaplan-Meier curves showed clear differences: patients who were high-risk in both clinical and genomic scores had much poorer survival than those high-risk in only one set. These results show that copula-based fusion works in real-world cohorts and that considering dependencies between scores can better identify patient subgroups with the worst prognosis.

</details>


### [301] [Energy-based Autoregressive Generation for Neural Population Dynamics](https://arxiv.org/abs/2511.17606)
*Ningling Ge,Sicheng Dai,Yu Zhu,Shan Yu*

Main category: cs.LG

TL;DR: 本文提出了一种基于能量的自回归生成（EAG）框架，用于高效建模神经群体动力学，在保持高保真度的同时显著提升计算效率，并在神经科学研究和神经工程应用中展示了优越性能。


<details>
  <summary>Details</summary>
Motivation: 理解大脑功能是神经科学的基本目标，但计算建模面临计算效率与高保真度之间的权衡限制。需要开发能够同时满足效率和保真度要求的神经群体动力学建模方法。

Method: 提出基于能量的自回归生成（EAG）框架，使用基于能量的变换器通过严格适当评分规则学习潜在空间中的时间动态，实现具有真实群体和单神经元发放统计特征的高效生成。

Result: 在合成Lorenz数据集和两个神经潜在基准数据集上的评估表明，EAG实现了最先进的生成质量，计算效率显著提升，特别是相对于基于扩散的方法。条件生成应用展示了泛化到未见行为情境和提升运动脑机接口解码精度的能力。

Conclusion: 基于能量的建模对于神经群体动力学是有效的，在神经科学研究和神经工程中具有重要应用价值。

Abstract: Understanding brain function represents a fundamental goal in neuroscience, with critical implications for therapeutic interventions and neural engineering applications. Computational modeling provides a quantitative framework for accelerating this understanding, but faces a fundamental trade-off between computational efficiency and high-fidelity modeling. To address this limitation, we introduce a novel Energy-based Autoregressive Generation (EAG) framework that employs an energy-based transformer learning temporal dynamics in latent space through strictly proper scoring rules, enabling efficient generation with realistic population and single-neuron spiking statistics. Evaluation on synthetic Lorenz datasets and two Neural Latents Benchmark datasets (MC_Maze and Area2_bump) demonstrates that EAG achieves state-of-the-art generation quality with substantial computational efficiency improvements, particularly over diffusion-based methods. Beyond optimal performance, conditional generation applications show two capabilities: generalizing to unseen behavioral contexts and improving motor brain-computer interface decoding accuracy using synthetic neural data. These results demonstrate the effectiveness of energy-based modeling for neural population dynamics with applications in neuroscience research and neural engineering. Code is available at https://github.com/NinglingGe/Energy-based-Autoregressive-Generation-for-Neural-Population-Dynamics.

</details>


### [302] [Finding Pre-Injury Patterns in Triathletes from Lifestyle, Recovery and Load Dynamics Features](https://arxiv.org/abs/2511.17610)
*Leonardo Rossi,Bruno Rodrigues*

Main category: cs.LG

TL;DR: 该论文提出了一个针对铁人三项训练的合成数据生成框架，通过整合训练负荷、睡眠质量、压力和恢复状态等日常因素，显著提高了运动损伤预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 铁人三项训练由于高强度的重复性生理压力，运动员面临较高的过度使用损伤风险。现有的损伤预测方法主要依赖训练负荷指标，往往忽视了睡眠质量、压力和个人生活方式等关键因素对恢复和损伤易感性的重要影响。

Method: 开发了一个专门针对铁人三项的合成数据生成框架，生成生理上合理的运动员档案，模拟个性化的训练计划（包含周期化和负荷管理原则），并整合睡眠质量、压力水平和恢复状态等日常生活因素。评估了LASSO、随机森林和XGBoost等机器学习模型。

Result: 机器学习模型显示出高预测性能（AUC高达0.86），识别出睡眠障碍、心率变异性和压力是损伤风险的关键早期指标。

Conclusion: 这种基于可穿戴设备的方法不仅提高了损伤预测的准确性，还为克服现实世界数据限制提供了实用解决方案，为实现全面、情境感知的运动员监测开辟了道路。

Abstract: Triathlon training, which involves high-volume swimming, cycling, and running, places athletes at substantial risk for overuse injuries due to repetitive physiological stress. Current injury prediction approaches primarily rely on training load metrics, often neglecting critical factors such as sleep quality, stress, and individual lifestyle patterns that significantly influence recovery and injury susceptibility.
  We introduce a novel synthetic data generation framework tailored explicitly for triathlon. This framework generates physiologically plausible athlete profiles, simulates individualized training programs that incorporate periodization and load-management principles, and integrates daily-life factors such as sleep quality, stress levels, and recovery states. We evaluated machine learning models (LASSO, Random Forest, and XGBoost) showing high predictive performance (AUC up to 0.86), identifying sleep disturbances, heart rate variability, and stress as critical early indicators of injury risk. This wearable-driven approach not only enhances injury prediction accuracy but also provides a practical solution to overcoming real-world data limitations, offering a pathway toward a holistic, context-aware athlete monitoring.

</details>


### [303] [CubeletWorld: A New Abstraction for Scalable 3D Modeling](https://arxiv.org/abs/2511.17664)
*Azlaan Mustafa Samad,Hoang H. Nguyen,Lukas Berg,Henrik Müller,Yuan Xue,Daniel Kudenko,Zahra Ahmadi*

Main category: cs.LG

TL;DR: CubeletWorld是一个新颖的城市环境建模框架，通过离散化的3D网格单元（cubelets）来表示和分析城市环境，支持隐私保护的建模和多种下游任务。


<details>
  <summary>Details</summary>
Motivation: 现代城市产生大量异构数据，但将这些数据整合到连贯的空间模型中仍面临挑战。现有基于智能体感知的方法存在可扩展性限制和隐私问题。

Method: 引入CubeletWorld框架，将城市环境抽象为3D网格单元，将基础设施、移动性、环境指标等多样化数据嵌入到局部cubelet状态中。

Result: 提出了CubeletWorld状态预测任务，评估了适用于该设置的改进核心模型，分析了空间粒度增加带来的稀疏性表示和基线可扩展性问题。

Conclusion: CubeletWorld提供了一个灵活可扩展的框架，用于从复杂城市数据中学习，为可扩展模拟和决策支持开辟了新可能性。

Abstract: Modern cities produce vast streams of heterogeneous data, from infrastructure maps to mobility logs and satellite imagery. However, integrating these sources into coherent spatial models for planning and prediction remains a major challenge. Existing agent-centric methods often rely on direct environmental sensing, limiting scalability and raising privacy concerns. This paper introduces CubeletWorld, a novel framework for representing and analyzing urban environments through a discretized 3D grid of spatial units called cubelets. This abstraction enables privacy-preserving modeling by embedding diverse data signals, such as infrastructure, movement, or environmental indicators, into localized cubelet states. CubeletWorld supports downstream tasks such as planning, navigation, and occupancy prediction without requiring agent-driven sensing. To evaluate this paradigm, we propose the CubeletWorld State Prediction task, which involves predicting the cubelet state using a realistic dataset containing various urban elements like streets and buildings through this discretized representation. We explore a range of modified core models suitable for our setting and analyze challenges posed by increasing spatial granularity, specifically the issue of sparsity in representation and scalability of baselines. In contrast to existing 3D occupancy prediction models, our cubelet-centric approach focuses on inferring state at the spatial unit level, enabling greater generalizability across regions and improved privacy compliance. Our results demonstrate that CubeletWorld offers a flexible and extensible framework for learning from complex urban data, and it opens up new possibilities for scalable simulation and decision support in domains such as socio-demographic modeling, environmental monitoring, and emergency response. The code and datasets can be downloaded from here.

</details>


### [304] [Tensor Gauge Flow Models](https://arxiv.org/abs/2511.17616)
*Alexander Strunk,Roland Assam*

Main category: cs.LG

TL;DR: Tensor Gauge Flow Models是一种新的生成流模型，通过将高阶张量规范场引入流方程，扩展了规范流模型和更高阶规范流模型，能够编码更丰富的几何和规范理论结构。


<details>
  <summary>Details</summary>
Motivation: 现有生成流模型在表达复杂数据几何结构方面存在局限，需要更丰富的规范理论结构来提升模型表达能力。

Method: 将高阶张量规范场整合到流方程中，构建Tensor Gauge Flow Models，扩展了传统规范流模型的数学框架。

Result: 在高斯混合模型上的实验表明，Tensor Gauge Flow Models相比标准和规范流基线模型具有更好的生成性能。

Conclusion: Tensor Gauge Flow Models通过引入高阶张量规范场，成功提升了生成流模型的表达能力，为复杂数据建模提供了新工具。

Abstract: This paper introduces Tensor Gauge Flow Models, a new class of Generative Flow Models that generalize Gauge Flow Models and Higher Gauge Flow Models by incorporating higher-order Tensor Gauge Fields into the Flow Equation. This extension allows the model to encode richer geometric and gauge-theoretic structure in the data, leading to more expressive flow dynamics. Experiments on Gaussian mixture models show that Tensor Gauge Flow Models achieve improved generative performance compared to both standard and gauge flow baselines.

</details>


### [305] [M$^2$OE$^2$-GL: A Family of Probabilistic Load Forecasters That Scales to Massive Customers](https://arxiv.org/abs/2511.17623)
*Haoran Li,Zhe Cheng,Muhao Guo,Yang Weng,Yannan Sun,Victor Tran,John Chainaranont*

Main category: cs.LG

TL;DR: M2OE2-GL是一个概率负荷预测方法，通过全局预训练和轻量级微调解决大规模配电馈线中异构性和可扩展性的挑战。


<details>
  <summary>Details</summary>
Motivation: 在包含数千甚至数十万个负荷的大规模配电馈线中，传统方法面临部署困境：为每个客户训练一个模型计算和存储成本高，而使用单一全局模型则忽略了客户类型、位置和相位之间的分布偏移。

Method: 首先在所有馈线负荷上预训练一个单一的全局M2OE2基础模型，然后应用轻量级微调来推导一个紧凑的组特定预测器家族。

Result: 在真实公用事业数据上的评估显示，M2OE2-GL实现了显著的误差减少，同时保持了对大量负荷的可扩展性。

Conclusion: M2OE2-GL方法有效地平衡了预测准确性和计算效率，为大规模配电系统中的概率负荷预测提供了可行的解决方案。

Abstract: Probabilistic load forecasting is widely studied and underpins power system planning, operation, and risk-aware decision making. Deep learning forecasters have shown strong ability to capture complex temporal and contextual patterns, achieving substantial accuracy gains. However, at the scale of thousands or even hundreds of thousands of loads in large distribution feeders, a deployment dilemma emerges: training and maintaining one model per customer is computationally and storage intensive, while using a single global model ignores distributional shifts across customer types, locations, and phases. Prior work typically focuses on single-load forecasters, global models across multiple loads, or adaptive/personalized models for relatively small settings, and rarely addresses the combined challenges of heterogeneity and scalability in large feeders. We propose M2OE2-GL, a global-to-local extension of the M2OE2 probabilistic forecaster. We first pretrain a single global M2OE2 base model across all feeder loads, then apply lightweight fine-tuning to derive a compact family of group-specific forecasters. Evaluated on realistic utility data, M2OE2-GL yields substantial error reductions while remaining scalable to very large numbers of loads.

</details>


### [306] [QML-HCS: A Hypercausal Quantum Machine Learning Framework for Non-Stationary Environments](https://arxiv.org/abs/2511.17624)
*Hector E Mozo*

Main category: cs.LG

TL;DR: QML-HCS是一个用于构建和分析在超因果反馈动力学下运行的量子启发机器学习模型的研究级框架，通过整合量子启发的叠加原理、动态因果反馈和确定性-随机混合执行来解决非平稳环境中的适应性问题。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习和量子启发系统在非平稳环境中表现不佳，数据分布漂移且模型缺乏持续适应、因果稳定性和相干状态更新的机制。QML-HCS旨在解决这一局限性。

Method: 采用统一的计算架构，整合量子启发叠加原理、动态因果反馈和确定性-随机混合执行，实现超因果处理核心，支持可逆变换、多路径因果传播和漂移下替代状态评估。

Result: 通过最小化模拟展示了超因果模型如何在输入分布突然变化时适应并保持内部一致性，建立了未来理论扩展、基准测试研究的基础架构。

Conclusion: QML-HCS为量子启发学习、因果推理和混合计算提供了一个可重现且可扩展的Python接口，无需专用硬件即可进行实验，为未来与经典和量子模拟平台的集成奠定了基础。

Abstract: QML-HCS is a research-grade framework for constructing and analyzing quantum-inspired machine learning models operating under hypercausal feedback dynamics. Hypercausal refers to AI systems that leverage extended, deep, or nonlinear causal relationships (expanded causality) to reason, predict, and infer states beyond the capabilities of traditional causal models. Current machine learning and quantum-inspired systems struggle in non-stationary environments, where data distributions drift and models lack mechanisms for continuous adaptation, causal stability, and coherent state updating. QML-HCS addresses this limitation through a unified computational architecture that integrates quantum-inspired superposition principles, dynamic causal feedback, and deterministic-stochastic hybrid execution to enable adaptive behavior in changing environments.
  The framework implements a hypercausal processing core capable of reversible transformations, multipath causal propagation, and evaluation of alternative states under drift. Its architecture incorporates continuous feedback to preserve causal consistency and adjust model behavior without requiring full retraining. QML-HCS provides a reproducible and extensible Python interface backed by efficient computational routines, enabling experimentation in quantum-inspired learning, causal reasoning, and hybrid computation without the need for specialized hardware.
  A minimal simulation demonstrates how a hypercausal model adapts to a sudden shift in the input distribution while preserving internal coherence. This initial release establishes the foundational architecture for future theoretical extensions, benchmarking studies, and integration with classical and quantum simulation platforms.

</details>


### [307] [Efficient Large-Scale Learning of Minimax Risk Classifiers](https://arxiv.org/abs/2511.17626)
*Kartheek Bondugula,Santiago Mazuelas,Aritz Pérez*

Main category: cs.LG

TL;DR: 提出一种结合约束生成和列生成的学习算法，用于高效训练大规模多类分类任务中的极小极大风险分类器，相比传统方法实现10-100倍加速。


<details>
  <summary>Details</summary>
Motivation: 传统随机次梯度方法无法有效处理极小极大风险分类器的最小化最大期望损失问题，需要开发适用于大规模多类分类的高效学习算法。

Method: 结合约束生成和列生成技术，设计专门针对极小极大风险分类器的学习算法，支持大规模数据集和多类别场景。

Result: 在多个基准数据集上的实验表明，该算法对一般大规模数据提供10倍加速，在类别数量较多时实现约100倍加速。

Conclusion: 所提出的约束和列生成组合算法能够高效训练大规模多类分类的极小极大风险分类器，显著提升学习效率。

Abstract: Supervised learning with large-scale data usually leads to complex optimization problems, especially for classification tasks with multiple classes. Stochastic subgradient methods can enable efficient learning with a large number of samples for classification techniques that minimize the average loss over the training samples. However, recent techniques, such as minimax risk classifiers (MRCs), minimize the maximum expected loss and are not amenable to stochastic subgradient methods. In this paper, we present a learning algorithm based on the combination of constraint and column generation that enables efficient learning of MRCs with large-scale data for classification tasks with multiple classes. Experiments on multiple benchmark datasets show that the proposed algorithm provides upto a 10x speedup for general large-scale data and around a 100x speedup with a sizeable number of classes.

</details>


### [308] [Rectifying Mean-Shift in Cascaded Precipitation Nowcasting](https://arxiv.org/abs/2511.17628)
*Fanbo Ju,Haiyuan Shi,Qingjian Ni*

Main category: cs.LG

TL;DR: RectiCast是一个用于降水临近预报的两阶段框架，通过双流匹配模型明确解耦均值场偏移校正和局部随机性生成，解决了现有方法中确定性预测的系统分布偏移与局部随机性混淆的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的级联架构降水临近预报方法通常忽略了确定性预测的系统分布偏移与局部随机性的混淆问题，导致确定性分量的分布偏移污染了概率分量的预测，特别是在较长预报时效上造成降水模式和强度的不准确。

Method: 提出RectiCast两阶段框架：第一阶段使用确定性模型生成后验均值；第二阶段引入Rectifier明确学习分布偏移并生成校正均值，然后Generator在条件于校正均值的情况下专注于建模局部随机性。

Result: 在SEVIR和MeteoNet数据集上的实验表明，RectiCast相比现有最先进方法实现了显著的性能提升。

Conclusion: RectiCast通过明确解耦均值场偏移校正和局部随机性生成，有效解决了级联架构中分布偏移污染问题，显著提升了降水临近预报的准确性。

Abstract: Precipitation nowcasting, which aims to provide high spatio-temporal resolution precipitation forecasts by leveraging current radar observations, is a core task in regional weather forecasting. The cascaded architecture has emerged as the mainstream paradigm for deep learning-based precipitation nowcasting. This paradigm involves a deterministic model to predict macroscopic trends (or posterior mean), followed by a probabilistic model to generate local details (or local stochasticity). However, existing methods commonly overlook the conflation of the systematic distribution shift in deterministic predictions and the local stochasticity. As a result, the deterministic component's distribution shift contaminates the predictions of the probabilistic component, leading to inaccuracies in precipitation patterns and intensity, particularly over longer lead times. To address this issue, we introduce RectiCast, a two-stage framework that explicitly decouples the correction of mean-field shift from the generation of local stochasticity via a dual Flow Matching model. In the first stage, a deterministic model generates the posterior mean. In the second stage, we introduce a Rectifier to explicitly learn the distribution shift and produce a rectified mean. Subsequently, a Generator focuses on modeling the local stochasticity conditioned on the rectified mean. Experiments on SEVIR and MeteoNet demonstrate that RectiCast achieves significant performance improvements over existing state-of-the-art methods.

</details>


### [309] [Can we use LLMs to bootstrap reinforcement learning? -- A case study in digital health behavior change](https://arxiv.org/abs/2511.17630)
*Nele Albers,Esra Cemre Su de Groot,Loes Keijsers,Manon H. Hillegers,Emiel Krahmer*

Main category: cs.LG

TL;DR: 本研究探索使用大型语言模型生成用户交互样本来训练强化学习模型，用于数字行为改变应用，结果显示LLM生成的样本在缺乏真实数据时有用，且性能达到人类评分者水平。


<details>
  <summary>Details</summary>
Motivation: 个性化数字健康行为改变应用需要适应不同用户状态，但开发这类方法需要大量设计选择，从文献中难以预测效果且实践评估成本高。

Method: 使用LLM开箱即用地生成用户交互样本，与四个大型行为改变研究的真实用户数据比较，分析不同提示策略（短/长提示、思维链提示、少样本提示）的效果。

Result: LLM生成的样本在缺乏真实数据时有用，性能达到人类评分者水平，不同提示策略的相对效果取决于具体研究和LLM模型，仅提示改写就存在较大差异。

Conclusion: LLM生成的样本在实践中具有应用价值，研究为如何在实践中有效使用这些样本提供了建议。

Abstract: Personalizing digital applications for health behavior change is a promising route to making them more engaging and effective. This especially holds for approaches that adapt to users and their specific states (e.g., motivation, knowledge, wants) over time. However, developing such approaches requires making many design choices, whose effectiveness is difficult to predict from literature and costly to evaluate in practice. In this work, we explore whether large language models (LLMs) can be used out-of-the-box to generate samples of user interactions that provide useful information for training reinforcement learning models for digital behavior change settings. Using real user data from four large behavior change studies as comparison, we show that LLM-generated samples can be useful in the absence of real data. Comparisons to the samples provided by human raters further show that LLM-generated samples reach the performance of human raters. Additional analyses of different prompting strategies including shorter and longer prompt variants, chain-of-thought prompting, and few-shot prompting show that the relative effectiveness of different strategies depends on both the study and the LLM with also relatively large differences between prompt paraphrases alone. We provide recommendations for how LLM-generated samples can be useful in practice.

</details>


### [310] [Enhanced Federated Deep Multi-View Clustering under Uncertainty Scenario](https://arxiv.org/abs/2511.17631)
*Bingjun Wei,Xuemei Cao,Jiafen Liu,Haoyang Liang,Xin Yang*

Main category: cs.LG

TL;DR: 提出EFDMVC框架解决联邦多视图聚类中的视图不确定性和聚合不确定性，通过语义对齐、层次对比融合和视图自适应漂移模块提升对异构不确定视图的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统联邦多视图聚类假设客户端视图统一，但实际部署中存在异构视图完整性，包含不完整、冗余或损坏数据，现有方法忽略了动态视图组合带来的语义冲突和双重不确定性。

Method: 首先对齐局部语义，在客户端内通过层次对比融合消除视图不确定性；使用视图自适应漂移模块通过全局-局部原型对比动态校正参数偏差来缓解聚合不确定性；采用平衡聚合机制协调客户端更新。

Result: 实验结果表明EFDMVC在多个基准数据集上对异构不确定视图具有优越的鲁棒性，在全面评估中始终优于所有最先进的基线方法。

Conclusion: EFDMVC框架成功解决了联邦多视图聚类中的双重不确定性问题，为处理异构视图环境提供了有效的解决方案。

Abstract: Traditional Federated Multi-View Clustering assumes uniform views across clients, yet practical deployments reveal heterogeneous view completeness with prevalent incomplete, redundant, or corrupted data. While recent approaches model view heterogeneity, they neglect semantic conflicts from dynamic view combinations, failing to address dual uncertainties: view uncertainty (semantic inconsistency from arbitrary view pairings) and aggregation uncertainty (divergent client updates with imbalanced contributions). To address these, we propose a novel Enhanced Federated Deep Multi-View Clustering framework: first align local semantics, hierarchical contrastive fusion within clients resolves view uncertainty by eliminating semantic conflicts; a view adaptive drift module mitigates aggregation uncertainty through global-local prototype contrast that dynamically corrects parameter deviations; and a balanced aggregation mechanism coordinates client updates. Experimental results demonstrate that EFDMVC achieves superior robustness against heterogeneous uncertain views across multiple benchmark datasets, consistently outperforming all state-of-the-art baselines in comprehensive evaluations.

</details>


### [311] [TTF: A Trapezoidal Temporal Fusion Framework for LTV Forecasting in Douyin](https://arxiv.org/abs/2511.17639)
*Yibing Wan,Zhengxiong Guan,Chaoli Zhang,Xiaoyang Li,Lai Xu,Beibei Jia,Zhenzhe Zheng,Fan Wu*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的梯形时间融合（TTF）框架，用于解决用户增长场景中渠道级LTV早期预测的挑战，包括未对齐的多时间序列、短输入长输出不平衡以及数据波动性大等问题。


<details>
  <summary>Details</summary>
Motivation: 在用户增长场景中，互联网公司需要预测渠道级LTV以优化预算分配，但面临未对齐多时间序列、短输入长输出不平衡以及数据波动性大三大挑战。

Method: 提出TTF框架，包含梯形多时间序列模块处理数据未对齐和SILO挑战，以及多塔结构的MT-FusionNet进行准确预测。

Result: 该框架已在抖音在线系统部署，相比之前部署的模型，MAPEp降低了4.3%，MAPEa降低了3.2%。

Conclusion: TTF框架有效解决了LTV预测中的关键挑战，在真实业务场景中取得了显著性能提升。

Abstract: In the user growth scenario, Internet companies invest heavily in paid acquisition channels to acquire new users. But sustainable growth depends on acquired users' generating lifetime value (LTV) exceeding customer acquisition cost (CAC). In order to maximize LTV/CAC ratio, it is crucial to predict channel-level LTV in an early stage for further optimization of budget allocation. The LTV forecasting problem is significantly different from traditional time series forecasting problems, and there are three main challenges. Firstly, it is an unaligned multi-time series forecasting problem that each channel has a number of LTV series of different activation dates. Secondly, to predict in the early stage, it faces the imbalanced short-input long-output (SILO) challenge. Moreover, compared with the commonly used time series datasets, the real LTV series are volatile and non-stationary, with more frequent fluctuations and higher variance. In this work, we propose a novel framework called Trapezoidal Temporal Fusion (TTF) to address the above challenges. We introduce a trapezoidal multi-time series module to deal with data unalignment and SILO challenges, and output accurate predictions with a multi-tower structure called MT-FusionNet. The framework has been deployed to the online system for Douyin. Compared to the previously deployed online model, MAPEp decreased by 4.3%, and MAPEa decreased by 3.2%, where MAPEp denotes the point-wise MAPE of the LTV curve and MAPEa denotes the MAPE of the aggregated LTV.

</details>


### [312] [MamTiff-CAD: Multi-Scale Latent Diffusion with Mamba+ for Complex Parametric Sequence](https://arxiv.org/abs/2511.17647)
*Liyuan Deng,Yunpeng Bai,Yongkang Dai,Xiaoshui Huang,Hongping Gan,Dongshuo Huang,Hao jiacheng,Yilei Shi*

Main category: cs.LG

TL;DR: MamTiff-CAD是一个基于Transformer扩散模型的CAD参数命令序列生成框架，通过多尺度潜在表示处理长序列CAD建模，在60-256命令的长序列生成任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理复杂CAD模型的长序列参数命令时，由于几何和拓扑约束而面临的困难。

Method: 设计集成Mamba+和Transformer的新型自编码器，将参数化CAD序列转换为潜在表示；Mamba+块引入遗忘门机制捕获长程依赖；基于多尺度Transformer的扩散模型在潜在嵌入上训练学习长序列命令分布。

Result: 在重建和生成任务上均达到最先进性能，成功生成长序列（60-256命令）CAD模型。

Conclusion: MamTiff-CAD框架有效解决了长序列CAD参数命令生成的挑战，通过多尺度潜在表示和扩散模型实现了高质量的长序列生成能力。

Abstract: Parametric Computer-Aided Design (CAD) is crucial in industrial applications, yet existing approaches often struggle to generate long sequence parametric commands due to complex CAD models' geometric and topological constraints. To address this challenge, we propose MamTiff-CAD, a novel CAD parametric command sequences generation framework that leverages a Transformer-based diffusion model for multi-scale latent representations. Specifically, we design a novel autoencoder that integrates Mamba+ and Transformer, to transfer parameterized CAD sequences into latent representations. The Mamba+ block incorporates a forget gate mechanism to effectively capture long-range dependencies. The non-autoregressive Transformer decoder reconstructs the latent representations. A diffusion model based on multi-scale Transformer is then trained on these latent embeddings to learn the distribution of long sequence commands. In addition, we also construct a dataset that consists of long parametric sequences, which is up to 256 commands for a single CAD model. Experiments demonstrate that MamTiff-CAD achieves state-of-the-art performance on both reconstruction and generation tasks, confirming its effectiveness for long sequence (60-256) CAD model generation.

</details>


### [313] [Frugality in second-order optimization: floating-point approximations for Newton's method](https://arxiv.org/abs/2511.17660)
*Giuseppe Carrino,Elena Loli Piccolomini,Elisa Riccietti,Theo Mary*

Main category: cs.LG

TL;DR: 该论文分析了有限精度算术对牛顿步的影响，建立了混合精度牛顿优化器的收敛定理，并提出了GN_k方法，在回归任务中达到与完整牛顿法相当的性能但需要更少的导数计算。


<details>
  <summary>Details</summary>
Motivation: 虽然一阶方法在机器学习训练中占主导地位，但高阶方法如牛顿法可以提供更高的精度和更快的收敛速度。然而，由于计算成本高，这些方法往往被避免使用。

Method: 分析了有限精度算术对牛顿步的影响，建立了混合精度牛顿优化器的收敛定理，包括"准"和"非精确"变体。提出了GN_k方法，允许部分计算二阶导数。

Result: 在标准回归基准测试中，所提出的方法在Australian和MUSH数据集上优于Adam。GN_k在回归任务中达到与完整牛顿法相当的性能，同时需要显著更少的导数评估。

Conclusion: 混合精度牛顿优化器提供了收敛保证和可达到解精度的先验估计。GN_k方法在保持性能的同时显著减少了计算成本，为高阶优化方法在机器学习中的实际应用提供了可行的解决方案。

Abstract: Minimizing loss functions is central to machine-learning training. Although first-order methods dominate practical applications, higher-order techniques such as Newton's method can deliver greater accuracy and faster convergence, yet are often avoided due to their computational cost. This work analyzes the impact of finite-precision arithmetic on Newton steps and establishes a convergence theorem for mixed-precision Newton optimizers, including "quasi" and "inexact" variants. The theorem provides not only convergence guarantees but also a priori estimates of the achievable solution accuracy. Empirical evaluations on standard regression benchmarks demonstrate that the proposed methods outperform Adam on the Australian and MUSH datasets. The second part of the manuscript introduces GN_k, a generalized Gauss-Newton method that enables partial computation of second-order derivatives. GN_k attains performance comparable to full Newton's method on regression tasks while requiring significantly fewer derivative evaluations.

</details>


### [314] [Enhancing Breast Cancer Prediction with LLM-Inferred Confounders](https://arxiv.org/abs/2511.17662)
*Debmita Roy*

Main category: cs.LG

TL;DR: 使用大型语言模型从常规临床数据中推断糖尿病、肥胖和心血管疾病等混杂疾病的患病可能性，以增强乳腺癌预测。AI生成的特征提升了随机森林模型的性能，特别是Gemma（3.9%）和Llama（6.4%）模型。该方法在无创预筛查和临床整合方面具有潜力，支持乳腺癌诊断中的早期检测和共享决策。


<details>
  <summary>Details</summary>
Motivation: 通过利用大型语言模型从常规临床数据中推断混杂疾病的可能性，来增强乳腺癌预测的准确性和早期检测能力。

Method: 使用大型语言模型（如Gemma和Llama）从常规临床数据中生成AI特征，然后将这些特征输入随机森林模型进行乳腺癌预测。

Result: AI生成的特征显著提升了随机森林模型的性能，特别是Gemma模型提升了3.9%，Llama模型提升了6.4%。

Conclusion: 该方法在无创预筛查和临床整合方面显示出良好前景，能够支持乳腺癌诊断中的早期检测和共享决策制定。

Abstract: This study enhances breast cancer prediction by using large language models to infer the likelihood of confounding diseases, namely diabetes, obesity, and cardiovascular disease, from routine clinical data. These AI-generated features improved Random Forest model performance, particularly for LLMs like Gemma (3.9%) and Llama (6.4%). The approach shows promise for noninvasive prescreening and clinical integration, supporting improved early detection and shared decision-making in breast cancer diagnosis.

</details>


### [315] [Lane-Frame Quantum Multimodal Driving Forecasts for the Trajectory of Autonomous Vehicles](https://arxiv.org/abs/2511.17675)
*Navneet Singh,Shiva Raj Pokhrel*

Main category: cs.LG

TL;DR: 提出了一种紧凑的混合量子架构，用于自动驾驶轨迹预测，通过量子注意力编码器、参数精简的量子前馈堆栈和傅里叶解码器，在单次前向传播中生成16个轨迹假设，在Waymo数据集上实现了优于运动学基线的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶轨迹预测需要在计算和延迟严格约束下提供准确、校准的多模态未来预测，传统方法面临计算复杂度高的问题。

Method: 采用混合量子架构，在自我中心、车道对齐的坐标系中操作，预测对运动学基线的残差修正；结合量子注意力编码器（9量子比特）、参数精简的量子前馈堆栈（64层，约1200个可训练角度）和基于傅里叶的解码器；使用SPSA训练所有电路参数。

Result: 在Waymo Open Motion Dataset上，模型在2.0秒预测范围内，16个预测模型的最小平均位移误差为1.94米，最小最终位移误差为3.56米，持续优于运动学基线，降低了漏检率并具有强召回率。

Conclusion: 残差学习、截断傅里叶解码、浅层纠缠和基于频谱的排名等方法能够将容量集中在关键区域，从小型浅层量子电路中产生稳定的优化和可靠的多模态预测。

Abstract: Trajectory forecasting for autonomous driving must deliver accurate, calibrated multi-modal futures under tight compute and latency constraints. We propose a compact hybrid quantum architecture that aligns quantum inductive bias with road-scene structure by operating in an ego-centric, lane-aligned frame and predicting residual corrections to a kinematic baseline instead of absolute poses. The model combines a transformer-inspired quantum attention encoder (9 qubits), a parameter-lean quantum feedforward stack (64 layers, ${\sim}1200$ trainable angles), and a Fourier-based decoder that uses shallow entanglement and phase superposition to generate 16 trajectory hypotheses in a single pass, with mode confidences derived from the latent spectrum. All circuit parameters are trained with Simultaneous Perturbation Stochastic Approximation (SPSA), avoiding backpropagation through non-analytic components. In the Waymo Open Motion Dataset, the model achieves minADE (minimum Average Displacement Error) of \SI{1.94}{m} and minFDE (minimum Final Displacement Error) of \SI{3.56}{m} in the $16$ models predicted over the horizon of \SI{2.0}{s}, consistently outperforming a kinematic baseline with reduced miss rates and strong recall. Ablations confirm that residual learning in the lane frame, truncated Fourier decoding, shallow entanglement, and spectrum-based ranking focus capacity where it matters, yielding stable optimization and reliable multi-modal forecasts from small, shallow quantum circuits on a modern autonomous-driving benchmark.

</details>


### [316] [A Hybrid Classical-Quantum Fine Tuned BERT for Text Classification](https://arxiv.org/abs/2511.17677)
*Abu Kaisar Mohammad Masum,Naveed Mahmud,M. Hassan Najafi,Sercan Aygun*

Main category: cs.LG

TL;DR: 提出了一种将n-qubit量子电路与经典BERT模型结合的混合方法用于文本分类，实验表明该混合模型在标准基准数据集上具有竞争力甚至优于经典基线。


<details>
  <summary>Details</summary>
Motivation: BERT文本分类的微调计算成本高且需要仔细的超参数调优，而量子算法在机器学习和文本分类任务中显示出超越传统方法的潜力。

Method: 集成n-qubit量子电路与经典BERT模型构建混合模型，用于文本分类任务。

Result: 混合模型在标准基准数据集上表现具有竞争力，在某些情况下优于经典基线，展示了经典-量子模型在不同数据集上微调预训练模型的适应性。

Conclusion: 混合模型凸显了量子计算在提升文本分类任务性能方面的潜力，推动了该研究领域的发展。

Abstract: Fine-tuning BERT for text classification can be computationally challenging and requires careful hyper-parameter tuning. Recent studies have highlighted the potential of quantum algorithms to outperform conventional methods in machine learning and text classification tasks. In this work, we propose a hybrid approach that integrates an n-qubit quantum circuit with a classical BERT model for text classification. We evaluate the performance of the fine-tuned classical-quantum BERT and demonstrate its feasibility as well as its potential in advancing this research area. Our experimental results show that the proposed hybrid model achieves performance that is competitive with, and in some cases better than, the classical baselines on standard benchmark datasets. Furthermore, our approach demonstrates the adaptability of classical-quantum models for fine-tuning pre-trained models across diverse datasets. Overall, the hybrid model highlights the promise of quantum computing in achieving improved performance for text classification tasks.

</details>


### [317] [Enhancing Adversarial Transferability through Block Stretch and Shrink](https://arxiv.org/abs/2511.17688)
*Quan Liu,Feng Ye,Chenhao Lu,Shuming Zhen,Guanliang Huang,Lunzhe Chen,Xudong Ke*

Main category: cs.LG

TL;DR: 本文提出Block Stretch and Shrink (BSS)方法，通过将图像分块并进行拉伸和收缩操作来增强对抗样本的跨模型可迁移性，在ImageNet子集上验证了其优于现有输入变换攻击方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于输入变换的对抗攻击方法在跨模型可迁移性方面表现有限，研究表明高可迁移性与多样化的注意力热图和保持全局语义相关。

Method: 提出BSS方法，将图像划分为多个块，对这些块应用拉伸和收缩操作，从而在保持全局语义的同时多样化变换输入中的注意力热图。

Result: 在ImageNet子集上的实验表明，BSS在可迁移性方面优于现有的基于输入变换的攻击方法。

Conclusion: BSS方法通过分块拉伸收缩操作有效提升了对抗样本的跨模型可迁移性，同时建议在统一变换数量尺度下评估输入变换攻击方法以确保公平比较。

Abstract: Adversarial attacks introduce small, deliberately crafted perturbations that mislead neural networks, and their transferability from white-box to black-box target models remains a critical research focus. Input transformation-based attacks are a subfield of adversarial attacks that enhance input diversity through input transformations to improve the transferability of adversarial examples. However, existing input transformation-based attacks tend to exhibit limited cross-model transferability. Previous studies have shown that high transferability is associated with diverse attention heatmaps and the preservation of global semantics in transformed inputs. Motivated by this observation, we propose Block Stretch and Shrink (BSS), a method that divides an image into blocks and applies stretch and shrink operations to these blocks, thereby diversifying attention heatmaps in transformed inputs while maintaining their global semantics. Empirical evaluations on a subset of ImageNet demonstrate that BSS outperforms existing input transformation-based attack methods in terms of transferability. Furthermore, we examine the impact of the number scale, defined as the number of transformed inputs, in input transformation-based attacks, and advocate evaluating these methods under a unified number scale to enable fair and comparable assessments.

</details>


### [318] [DeepCoT: Deep Continual Transformers for Real-Time Inference on Data Streams](https://arxiv.org/abs/2511.17693)
*Ginés Carreto Picón,Peng Yuan Zhou,Qi Zhang,Alexandros Iosifidis*

Main category: cs.LG

TL;DR: 提出DeepCoT模型，解决深层Transformer在流数据推理中的计算冗余问题，实现线性计算成本并显著降低运行时间。


<details>
  <summary>Details</summary>
Motivation: Transformer模型规模不断增大，但在资源受限设备上需要低延迟推理。流数据推理中的滑动窗口导致高度冗余计算，现有Continual Transformers仅适用于浅层模型，限制了应用范围和泛化能力。

Method: 提出Deep Continual Transformer (DeepCoT)，一种无冗余的仅编码器模型，可应用于现有深度编码器架构，只需最小改动。

Result: 在音频、视频和文本流上的实验表明，DeepCoT保持了与非持续基线相当的性能，同时为所有Transformer层提供线性计算成本，运行时间比先前高效模型减少高达两个数量级。

Conclusion: DeepCoT成功解决了深层Transformer在流数据推理中的计算效率问题，实现了高性能与低延迟的平衡。

Abstract: Transformer-based models have dramatically increased their size and parameter count to tackle increasingly complex tasks. At the same time, there is a growing demand for low-latency inference on resource-constrained devices that achieves high performance. In particular, stream data inference is typically performed over a sliding temporal window, leading to highly redundant computations. The recent Continual Transformers have addressed this issue, but they can only be effectively used in shallow models, which limits their scope and generalization power. In this paper, we propose the Deep Continual Transformer (DeepCoT), a redundancy-free encoder-only model that can be applied over existing deep encoder architectures with minimal changes. In our experiments over audio, video, and text streams, we show that DeepCoTs retain comparative performance to their non-continual baselines while offering a linear computational cost for all Transformer layers, which reduces up to two orders of magnitude in the running time compared to previous efficient models.

</details>


### [319] [Diffusion Models are Molecular Dynamics Simulators](https://arxiv.org/abs/2511.17741)
*Justin Diamond,Markus Lill*

Main category: cs.LG

TL;DR: 本文证明了带序列偏置的降噪扩散采样器等价于过阻尼朗之万动力学的欧拉-马鲁亚马积分器，建立了扩散采样与朗之万时间演化的精确对应关系，为分子动力学提供了完全数据驱动的框架。


<details>
  <summary>Details</summary>
Motivation: 将分子动力学重新表述为扩散模型，摆脱传统MD方法对极小时间步长的依赖，通过模型能力和降噪步数两个可扩展参数控制精度。

Method: 使用带序列偏置的降噪扩散采样器，将其解释为朗之万动力学的积分器，通过学习的分数函数作为漂移项（即学习能量的梯度）。

Result: 建立了完全数据驱动的分子动力学框架，仅需从非相关平衡快照学习力场，无需轨迹数据训练，仍能保持与学习能量相关的玻尔兹曼分布。

Conclusion: 该框架在轨迹层面具有信息理论误差界限，能生成具有MD类时间相关性的分子轨迹，尽管模型仅基于静态构型训练。

Abstract: We prove that a denoising diffusion sampler equipped with a sequential bias across the batch dimension is exactly an Euler-Maruyama integrator for overdamped Langevin dynamics. Each reverse denoising step, with its associated spring stiffness, can be interpreted as one step of a stochastic differential equation with an effective time step set jointly by the noise schedule and that stiffness. The learned score then plays the role of the drift, equivalently the gradient of a learned energy, yielding a precise correspondence between diffusion sampling and Langevin time evolution.
  This equivalence recasts molecular dynamics (MD) in terms of diffusion models. Accuracy is no longer tied to a fixed, extremely small MD time step; instead, it is controlled by two scalable knobs: model capacity, which governs how well the drift is approximated, and the number of denoising steps, which sets the integrator resolution. In practice, this leads to a fully data-driven MD framework that learns forces from uncorrelated equilibrium snapshots, requires no hand-engineered force fields, uses no trajectory data for training, and still preserves the Boltzmann distribution associated with the learned energy.
  We derive trajectory-level, information-theoretic error bounds that cleanly separate discretization error from score-model error, clarify how temperature enters through the effective spring, and show that the resulting sampler generates molecular trajectories with MD-like temporal correlations, even though the model is trained only on static configurations.

</details>


### [320] [PrismSSL: One Interface, Many Modalities; A Single-Interface Library for Multimodal Self-Supervised Learning](https://arxiv.org/abs/2511.17776)
*Melika Shirian,Kianoosh Vadaei,Kian Majlessi,Audrina Ebrahimi,Arshia Hemmat,Peyman Adibi,Hossein Karshenas*

Main category: cs.LG

TL;DR: PrismSSL是一个统一的Python库，集成了音频、视觉、图数据和跨模态的自监督学习方法，提供模块化代码库、易于使用的训练配置、基准测试复现和扩展框架。


<details>
  <summary>Details</summary>
Motivation: 为解决自监督学习在不同模态中方法分散、代码不统一的问题，提供一个集成的、易于使用的框架来促进研究和应用。

Method: 开发模块化Python库，集成多种自监督学习方法，提供简洁的API、分布式训练、超参数搜索、可视化工具和图形化仪表板。

Result: 成功构建了PrismSSL库，支持多种模态的自监督学习，提供丰富的功能特性，并已发布在PyPI上。

Conclusion: PrismSSL为自监督学习研究提供了一个统一、易用且功能丰富的平台，有助于推动该领域的发展和应用。

Abstract: We present PrismSSL, a Python library that unifies state-of-the-art self-supervised learning (SSL) methods across audio, vision, graphs, and cross-modal settings in a single, modular codebase. The goal of the demo is to show how researchers and practitioners can: (i) install, configure, and run pretext training with a few lines of code; (ii) reproduce compact benchmarks; and (iii) extend the framework with new modalities or methods through clean trainer and dataset abstractions. PrismSSL is packaged on PyPI, released under the MIT license, integrates tightly with HuggingFace Transformers, and provides quality-of-life features such as distributed training in PyTorch, Optuna-based hyperparameter search, LoRA fine-tuning for Transformer backbones, animated embedding visualizations for sanity checks, Weights & Biases logging, and colorful, structured terminal logs for improved usability and clarity. In addition, PrismSSL offers a graphical dashboard - built with Flask and standard web technologies - that enables users to configure and launch training pipelines with minimal coding. The artifact (code and data recipes) will be publicly available and reproducible.

</details>


### [321] [Smoothed Agnostic Learning of Halfspaces over the Hypercube](https://arxiv.org/abs/2511.17782)
*Yiwen Kou,Raghu Meka*

Main category: cs.LG

TL;DR: 本文提出了一种新的布尔输入平滑不可知学习框架，使用随机位翻转扰动来绕过布尔半空间学习的计算困难。在次指数分布假设下，实现了高效学习算法。


<details>
  <summary>Details</summary>
Motivation: 布尔半空间的不可知学习在计算学习理论中是一个基本问题，但即使在弱学习下也被证明是计算困难的。现有平滑分析框架依赖高斯扰动，不适用于离散域。

Method: 引入基于随机位翻转的布尔输入平滑不可知学习框架，作为高斯情况的离散模拟。在次指数分布假设下，设计高效学习算法。

Result: 在该模型下实现了半空间的高效学习，运行时间和样本复杂度约为n的多项式因子。这是布尔超立方体上平滑不可知半空间学习的首个计算高效保证。

Conclusion: 该结果在离散设置中弥合了最坏情况难处理性与实际可学习性之间的差距，为布尔半空间学习提供了新的计算保证。

Abstract: Agnostic learning of Boolean halfspaces is a fundamental problem in computational learning theory, but it is known to be computationally hard even for weak learning. Recent work [CKKMK24] proposed smoothed analysis as a way to bypass such hardness, but existing frameworks rely on additive Gaussian perturbations, making them unsuitable for discrete domains. We introduce a new smoothed agnostic learning framework for Boolean inputs, where perturbations are modeled via random bit flips. This defines a natural discrete analogue of smoothed optimality generalizing the Gaussian case. Under strictly subexponential assumptions on the input distribution, we give an efficient algorithm for learning halfspaces in this model, with runtime and sample complexity approximately n raised to a poly(1/(sigma * epsilon)) factor. Previously, such algorithms were known only with strong structural assumptions for the discrete hypercube, for example, independent coordinates or symmetric distributions. Our result provides the first computationally efficient guarantee for smoothed agnostic learning of halfspaces over the Boolean hypercube, bridging the gap between worst-case intractability and practical learnability in discrete settings.

</details>


### [322] [Improved Sample Complexity for Full Coverage in Compact and Continuous Spaces](https://arxiv.org/abs/2511.17784)
*Lyu Yuhuan*

Main category: cs.LG

TL;DR: 本文研究了在d维单位超立方体上的均匀随机采样，分析了离散化后未覆盖子立方体的数量。通过应用集中不等式，推导出样本复杂度边界，其对失败概率δ具有对数依赖性，与经典的线性1/δ依赖性形成鲜明对比。


<details>
  <summary>Details</summary>
Motivation: 经典的覆盖分析在小的失败概率下往往产生保守边界，需要更精确的理论工具来支持依赖网格覆盖保证的算法，特别是在高置信度机制中实现更高效的采样。

Method: 应用集中不等式到未覆盖计数统计量，在标准Lipschitz和均匀性假设下，推导样本复杂度边界，并与经典优惠券收集器速率进行比较。

Result: 数值研究表明，所提出的边界能更紧密地跟踪实际覆盖要求，并且在δ→0时具有良好的可扩展性。样本复杂度为M=O(C̃ln(2C̃/δ))，具有对数依赖性。

Conclusion: 该研究为依赖网格覆盖保证的算法提供了更锐利的理论工具，特别是在高置信度机制中能够实现更高效的采样。

Abstract: Verifying uniform conditions over continuous spaces through random sampling is fundamental in machine learning and control theory, yet classical coverage analyses often yield conservative bounds, particularly at small failure probabilities. We study uniform random sampling on the $d$-dimensional unit hypercube and analyze the number of uncovered subcubes after discretization. By applying a concentration inequality to the uncovered-count statistic, we derive a sample complexity bound with a logarithmic dependence on the failure probability ($δ$), i.e., $M =O( \tilde{C}\ln(\frac{2\tilde{C}}δ))$, which contrasts sharply with the classical linear $1/δ$ dependence. Under standard Lipschitz and uniformity assumptions, we present a self-contained derivation and compare our result with classical coupon-collector rates. Numerical studies across dimensions, precision levels, and confidence targets indicate that our bound tracks practical coverage requirements more tightly and scales favorably as $δ\to 0$. Our findings offer a sharper theoretical tool for algorithms that rely on grid-based coverage guarantees, enabling more efficient sampling, especially in high-confidence regimes.

</details>


### [323] [Data-Driven Predictive Modeling of Microfluidic Cancer Cell Separation Using a Deterministic Lateral Displacement Device](https://arxiv.org/abs/2511.17787)
*Elizabeth Chen,Andrew Lee,Tanbir Sarowar,Xiaolin Chen*

Main category: cs.LG

TL;DR: 本研究利用机器学习模型优化确定性横向位移（DLD）微流控装置的设计参数，以提高肺癌细胞分离效率，为癌症早期诊断提供可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决循环肿瘤细胞（CTCs）检测中稀有细胞捕获的挑战，减少对计算密集型模拟的依赖，实现高通量、经济高效的DLD装置设计优化。

Method: 采用梯度提升、k近邻、随机森林和多层感知器（MLP）回归器等机器学习模型，基于大型数值验证数据集预测粒子轨迹并识别最优设备配置。

Result: 机器学习模型能够准确预测粒子轨迹，识别关键设计变量，为DLD装置提供系统化、数据驱动的自动化优化框架。

Conclusion: 这种集成方法推进了用于癌症诊断的可扩展和精确微流控系统的发展，有助于实现早期检测和个性化医疗的广泛目标。

Abstract: Deterministic Lateral Displacement (DLD) devices are widely used in microfluidics for label-free, size-based separation of particles and cells, with particular promise in isolating circulating tumor cells (CTCs) for early cancer diagnostics. This study focuses on the optimization of DLD design parameters, such as row shift fraction, post size, and gap distance, to enhance the selective isolation of lung cancer cells based on their physical properties. To overcome the challenges of rare CTC detection and reduce reliance on computationally intensive simulations, machine learning models including gradient boosting, k-nearest neighbors, random forest, and multilayer perceptron (MLP) regressors are employed. Trained on a large, numerically validated dataset, these models predict particle trajectories and identify optimal device configurations, enabling high-throughput and cost-effective DLD design. Beyond trajectory prediction, the models aid in isolating critical design variables, offering a systematic, data-driven framework for automated DLD optimization. This integrative approach advances the development of scalable and precise microfluidic systems for cancer diagnostics, contributing to the broader goals of early detection and personalized medicine.

</details>


### [324] [Semi-Supervised Federated Multi-Label Feature Selection with Fuzzy Information Measures](https://arxiv.org/abs/2511.17796)
*Afsaneh Mahanipour,Hana Khamfroush*

Main category: cs.LG

TL;DR: 提出了一种半监督联邦多标签特征选择方法SSFMLFS，在客户端只有未标记数据、服务器有少量标记数据的联邦学习环境下，通过模糊信息理论和PageRank算法进行特征选择。


<details>
  <summary>Details</summary>
Motivation: 解决现有多标签特征选择方法需要集中式数据且不适合联邦环境的局限性，以及联邦方法通常假设客户端有标记数据的不现实问题。

Method: 客户端计算模糊相似矩阵并传输给服务器，服务器计算特征冗余度和特征-标签相关性，构建特征图并用PageRank算法对特征重要性进行排序。

Result: 在五个不同领域的真实数据集上的实验表明，在非独立同分布数据设置下，SSFMLFS在三种不同评估指标上优于其他联邦和集中式监督及半监督方法。

Conclusion: SSFMLFS方法在联邦半监督环境下有效解决了多标签特征选择问题，显著提升了模型性能。

Abstract: Multi-label feature selection (FS) reduces the dimensionality of multi-label data by removing irrelevant, noisy, and redundant features, thereby boosting the performance of multi-label learning models. However, existing methods typically require centralized data, which makes them unsuitable for distributed and federated environments where each device/client holds its own local dataset. Additionally, federated methods often assume that clients have labeled data, which is unrealistic in cases where clients lack the expertise or resources to label task-specific data. To address these challenges, we propose a Semi-Supervised Federated Multi-Label Feature Selection method, called SSFMLFS, where clients hold only unlabeled data, while the server has limited labeled data. SSFMLFS adapts fuzzy information theory to a federated setting, where clients compute fuzzy similarity matrices and transmit them to the server, which then calculates feature redundancy and feature-label relevancy degrees. A feature graph is constructed by modeling features as vertices, assigning relevancy and redundancy degrees as vertex weights and edge weights, respectively. PageRank is then applied to rank the features by importance. Extensive experiments on five real-world datasets from various domains, including biology, images, music, and text, demonstrate that SSFMLFS outperforms other federated and centralized supervised and semi-supervised approaches in terms of three different evaluation metrics in non-IID data distribution setting.

</details>


### [325] [Layer-Wise High-Impact Parameter Ratio Optimization in Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2511.17801)
*Cuong Pham,Hoang Anh Dung,Cuong C. Nguyen,Trung Le,Gustavo Carneiro,Thanh-Toan Do*

Main category: cs.LG

TL;DR: 提出一种二次优化框架，通过层特定的高影响参数比例和中等位宽量化，在资源受限条件下实现LLM的高效量化，平衡计算效率与模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法在极低位宽下精度损失严重，且固定比例的高影响参数策略忽略了层间敏感性差异，需要更精细的量化策略。

Method: 使用二次优化框架确定层特定的高影响参数比例，考虑层间依赖关系，对高影响参数采用中等位宽量化，其余参数使用极低位宽量化。

Result: 在相同资源约束下，比FP16方法保留更多高影响参数，并可将先进量化方法仅应用于高影响参数，其余使用计算高效方法。

Conclusion: 该方法在计算效率和模型精度之间取得有效平衡，相比最先进方法保持了高性能。

Abstract: Large language models (LLMs) have significantly advanced natural language processing, but their massive parameter counts create substantial computational and memory challenges during deployment. Post-training quantization (PTQ) has emerged as a promising approach to mitigate these challenges with minimal overhead. While existing PTQ methods can effectively quantize LLMs, they experience substantial accuracy loss at extremely low bit-widths, primarily due to high-impact parameters that significantly influence quantization performance. Several approaches address these issues by identifying and retaining the high-impact parameters in FP16 format. However, they apply fixed ratios of high-impact parameters across all layers, overlooking layer-wise sensitivity variations. In this paper, we propose a quadratic optimization framework that determines layer-specific ratios of high-impact parameters while considering inter-layer dependencies. We quantize high-impact parameters to moderate bit-widths, which often result in negligible performance degradation in quantized LLMs, while the remaining parameters can be quantized to extremely low bit-widths. Under the same resource-constrained budget, this allows for preserving more high-impact parameters than methods that keep selecting a few in FP16 format. Additionally, the proposed framework allows us to leverage an advanced quantization method that often requires extensive learnable parameters solely for high-impact parameters, while applying a computationally efficient method to the rest. Our approach achieves an effective balance between computational efficiency and model accuracy while maintaining high performance compared to state-of-the-art methods.

</details>


### [326] [Adaptive Layer-Wise Transformations for Post-Training Quantization of Large Language Models](https://arxiv.org/abs/2511.17809)
*Cuong Pham,Hoang Anh Dung,Cuong C. Nguyen,Trung Le,Gustavo Carneiro,Jianfei Cai,Thanh-Toan Do*

Main category: cs.LG

TL;DR: 本文提出了一种自适应变换选择框架，针对大语言模型量化中的系统异常值问题，通过逐层选择最优变换类型来提升量化性能，相比现有固定变换方法有显著改进。


<details>
  <summary>Details</summary>
Motivation: 大语言模型部署需要大量计算资源，量化是实际应用的关键。但量化面临的主要障碍是激活和权重中的系统异常值，特别是在低位设置下会导致显著的性能下降。现有变换方法采用同质变换设置，忽略了LLM内部的异质分布特性。

Method: 提出自适应变换选择框架，将变换选择制定为可微优化问题，为每层确定最优变换类型。建立了权重分布峰度与准确变换类型之间的联系，提出基于稳健z-score归一化的异常值引导层选择方法，大幅降低计算开销。

Result: 在LLaMA系列模型上的综合实验表明，自适应方法始终优于广泛使用的固定变换设置。在LLaMA-3-8B模型的W3A3K2V2激进量化设置下，相比当前最佳方法FlatQuant，困惑度提升高达4.58点，六任务零样本准确率平均提升2.11%。

Conclusion: 证明了异质变换选择对于最优LLM量化的必要性，提出的自适应框架能够有效处理不同层的分布特性，在保持高性能的同时显著降低计算成本。

Abstract: Large language models require significant computational resources for deployment, making quantization essential for practical applications. However, the main obstacle to effective quantization lies in systematic outliers in activations and weights, which cause substantial LLM performance degradation, especially at low-bit settings. While existing transformation-based methods like affine and rotation transformations successfully mitigate outliers, they apply the homogeneous transformation setting, i.e., using the same transformation types across all layers, ignoring the heterogeneous distribution characteristics within LLMs. In this paper, we propose an adaptive transformation selection framework that systematically determines optimal transformations on a per-layer basis. To this end, we first formulate transformation selection as a differentiable optimization problem to achieve the accurate transformation type for each layer. However, searching for optimal layer-wise transformations for every model is computationally expensive. To this end, we establish the connection between weight distribution kurtosis and accurate transformation type. Specifically, we propose an outlier-guided layer selection method using robust $z$-score normalization that achieves comparable performance to differentiable search with significantly reduced overhead. Comprehensive experiments on LLaMA family models demonstrate that our adaptive approach consistently outperforms the widely-used fixed transformation settings. For example, our method achieves an improvement of up to 4.58 perplexity points and a 2.11% gain in average six-task zero-shot accuracy under aggressive W3A3K2V2 quantization settings for the LLaMA-3-8B model compared to the current best existing method, FlatQuant, demonstrating the necessity of heterogeneous transformation selection for optimal LLM quantization.

</details>


### [327] [APRIL: Annotations for Policy evaluation with Reliable Inference from LLMs](https://arxiv.org/abs/2511.17818)
*Aishwarya Mandyam,Kalyani Limaye,Barbara E. Engelhardt,Emily Alsentzer*

Main category: cs.LG

TL;DR: 本文提出使用大型语言模型（LLMs）为医疗领域的离线策略评估（OPE）生成反事实标注，以解决传统方法因数据集规模和覆盖范围有限而导致的评估不准确问题。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险领域，离线策略评估对确保策略部署安全至关重要。传统OPE方法受限于行为数据集的规模和覆盖范围，而获取专家标注的反事实注释成本高昂，限制了方法的可扩展性。

Method: 利用大型语言模型基于领域知识预测在替代治疗下关键临床特征的演变，然后通过已知奖励函数将这些预测特征转化为反事实标注，并将其整合到OPE估计器中。

Result: 在MIMIC-IV数据集的两个患者子集上评估，发现最先进的LLMs在预测临床特征方面表现相当。在大多数情况下，基于LLM的反事实标注显著改善了OPE估计，但存在一个临界点。提出了基于熵的指标来识别何时额外标注不再有用。

Conclusion: 基于LLM的反事实标注为解决医疗数据集中覆盖范围限制提供了一种可扩展的方法，能够在临床环境中更安全地部署决策策略。

Abstract: Off-policy evaluation (OPE) estimates the value of a contextual bandit policy prior to deployment. As such, OPE plays a critical role in ensuring safety in high-stakes domains such as healthcare. However, standard OPE approaches are limited by the size and coverage of the behavior dataset. While previous work has explored using expert-labeled counterfactual annotations to enhance dataset coverage, obtaining such annotations is expensive, limiting the scalability of prior approaches. We propose leveraging large language models (LLMs) to generate counterfactual annotations for OPE in medical domains. Our method uses domain knowledge to guide LLMs in predicting how key clinical features evolve under alternate treatments. These predicted features can then be transformed using known reward functions to create counterfactual annotations. We first evaluate the ability of several LLMs to predict clinical features across two patient subsets in MIMIC-IV, finding that state-of-the-art LLMs achieve comparable performance. Building on this capacity to predict clinical features, we generate LLM-based counterfactual annotations and incorporate them into an OPE estimator. Our empirical results analyze the benefits of counterfactual annotations under varying degrees of shift between the behavior and target policies. We find that in most cases, the LLM-based counterfactual annotations significantly improve OPE estimates up to a point. We provide an entropy-based metric to identify when additional annotations cease to be useful. Our results demonstrate that LLM-based counterfactual annotations offer a scalable approach for addressing coverage limitations in healthcare datasets, enabling safer deployment of decision-making policies in clinical settings.

</details>


### [328] [High-Accuracy List-Decodable Mean Estimation](https://arxiv.org/abs/2511.17822)
*Ziyun Chen,Spencer Compton,Daniel Kane,Jerry Li*

Main category: cs.LG

TL;DR: 本文研究了高精度列表可解码学习问题，探讨了在列表可解码学习中用列表大小换取精度的可能性。主要结果是在身份协方差高斯分布的列表可解码均值估计中，证明了存在大小为L的候选均值列表，其中至少一个元素与真实均值的ℓ₂距离不超过ε。


<details>
  <summary>Details</summary>
Motivation: 现有列表可解码学习算法虽然能获得最优列表大小，但误差随1/α衰减较差。本文旨在研究是否可以通过增加列表大小来换取更高的精度，即实现高精度列表可解码学习。

Method: 提出了一种全新的可辨识性证明方法，并设计了一种不依赖平方和层次结构的算法来利用这一证明。算法输出大小为L的候选均值列表，其中L = exp(O(log²(1/α)/ε²))。

Result: 证明了在身份协方差高斯分布的列表可解码均值估计中，存在大小为L的候选均值列表，其中至少一个元素与真实均值的ℓ₂距离不超过ε。算法的时间复杂度和样本复杂度为n = d^O(log L) + exp exp(Õ(log L))。

Conclusion: 本文首次在列表可解码学习中实现了非平凡的高精度保证，不仅在信息理论上可行，还提供了有效的算法实现。这一结果为列表可解码学习开辟了新的研究方向，具有重要的技术意义。

Abstract: In list-decodable learning, we are given a set of data points such that an $α$-fraction of these points come from a nice distribution $D$, for some small $α\ll 1$, and the goal is to output a short list of candidate solutions, such that at least one element of this list recovers some non-trivial information about $D$. By now, there is a large body of work on this topic; however, while many algorithms can achieve optimal list size in terms of $α$, all known algorithms must incur error which decays, in some cases quite poorly, with $1 / α$. In this paper, we ask if this is inherent: is it possible to trade off list size with accuracy in list-decodable learning? More formally, given $ε> 0$, can we can output a slightly larger list in terms of $α$ and $ε$, but so that one element of this list has error at most $ε$ with the ground truth? We call this problem high-accuracy list-decodable learning. Our main result is that non-trivial high-accuracy guarantees, both information-theoretically and algorithmically, are possible for the canonical setting of list-decodable mean estimation of identity-covariance Gaussians. Specifically, we demonstrate that there exists a list of candidate means of size at most $L = \exp \left( O\left( \tfrac{\log^2 1 / α}{ε^2} \right)\right)$ so that one of the elements of this list has $\ell_2$ distance at most $ε$ to the true mean. We also design an algorithm that outputs such a list with runtime and sample complexity $n = d^{O(\log L)} + \exp \exp (\widetilde{O}(\log L))$. We do so by demonstrating a completely novel proof of identifiability, as well as a new algorithmic way of leveraging this proof without the sum-of-squares hierarchy, which may be of independent technical interest.

</details>


### [329] [A novel k-means clustering approach using two distance measures for Gaussian data](https://arxiv.org/abs/2511.17823)
*Naitik Gada*

Main category: cs.LG

TL;DR: 本文提出了一种改进的k-means聚类算法，同时使用簇内距离(WCD)和簇间距离(ICD)作为距离度量，通过Calinski-Harabasz准则确定最佳k值，以获得更鲁棒的聚类结果。


<details>
  <summary>Details</summary>
Motivation: 传统k-means聚类算法在聚类分析中存在局限性，作者希望通过结合WCD和ICD两种距离度量来增强聚类的鲁棒性和准确性，使数据收敛到各自的簇更加稳定。

Method: 开发了一种新的k-means聚类算法，使用WCD和ICD作为距离度量，通过Calinski-Harabasz准则自动确定最佳聚类数量k，并在合成数据和UCI基准数据集上进行测试。

Result: 实验结果表明，使用WCD和ICD两种度量标准时，数据收敛到各自簇的准确性更高，算法在将异常值聚类到正确簇方面优于传统k-means方法。

Conclusion: 结合WCD和ICD的改进k-means算法能够提供更鲁棒的聚类结果，特别是在处理异常值方面表现更佳，为聚类分析提供了新的研究方向。

Abstract: Clustering algorithms have long been the topic of research, representing the more popular side of unsupervised learning. Since clustering analysis is one of the best ways to find some clarity and structure within raw data, this paper explores a novel approach to \textit{k}-means clustering. Here we present a \textit{k}-means clustering algorithm that takes both the within cluster distance (WCD) and the inter cluster distance (ICD) as the distance metric to cluster the data into \emph{k} clusters pre-determined by the Calinski-Harabasz criterion in order to provide a more robust output for the clustering analysis. The idea with this approach is that by including both the measurement metrics, the convergence of the data into their clusters becomes solidified and more robust. We run the algorithm with some synthetically produced data and also some benchmark data sets obtained from the UCI repository. The results show that the convergence of the data into their respective clusters is more accurate by using both WCD and ICD measurement metrics. The algorithm is also better at clustering the outliers into their true clusters as opposed to the traditional \textit{k} means method. We also address some interesting possible research topics that reveal themselves as we answer the questions we initially set out to address.

</details>


### [330] [Deterministic Inference across Tensor Parallel Sizes That Eliminates Training-Inference Mismatch](https://arxiv.org/abs/2511.17826)
*Ziyang Zhang,Xinheng Ding,Jiayi Yuan,Rixin Liu,Huizi Mao,Jiarong Xing,Zirui Liu*

Main category: cs.LG

TL;DR: 本文提出Tree-Based Invariant Kernels (TBIK)来解决大语言模型推理中的张量并行(TP)大小导致的非确定性行为，确保在不同TP配置下获得比特级相同的推理结果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务框架在不同系统配置（如TP大小、批大小）下会产生非确定性行为，这在LLM-as-a-judge评估、多智能体系统和强化学习等应用中造成严重问题，特别是在RL训练中，训练引擎和推理引擎的并行策略不匹配可能导致性能下降甚至崩溃。

Method: 提出Tree-Based Invariant Kernels (TBIK)，通过统一的层次化二叉树结构对齐GPU内和GPU间的归约顺序，实现TP不变的矩阵乘法和归约原语。在Triton中实现这些内核，并集成到vLLM和FSDP中。

Result: 实验证实了在不同TP大小下实现零概率发散和比特级可重现的确定性推理，并在使用不同并行策略的RL训练管道中实现了vLLM和FSDP之间的比特级相同结果。

Conclusion: TBIK有效解决了TP引起的非确定性问题，为LLM应用提供了可靠的确定性推理保障，特别是在需要一致性的强化学习场景中。

Abstract: Deterministic inference is increasingly critical for large language model (LLM) applications such as LLM-as-a-judge evaluation, multi-agent systems, and Reinforcement Learning (RL). However, existing LLM serving frameworks exhibit non-deterministic behavior: identical inputs can yield different outputs when system configurations (e.g., tensor parallel (TP) size, batch size) vary, even under greedy decoding. This arises from the non-associativity of floating-point arithmetic and inconsistent reduction orders across GPUs. While prior work has addressed batch-size-related nondeterminism through batch-invariant kernels, determinism across different TP sizes remains an open problem, particularly in RL settings, where the training engine typically uses Fully Sharded Data Parallel (i.e., TP = 1) while the rollout engine relies on multi-GPU TP to maximize the inference throughput, creating a natural mismatch between the two. This precision mismatch problem may lead to suboptimal performance or even collapse for RL training. We identify and analyze the root causes of TP-induced inconsistency and propose Tree-Based Invariant Kernels (TBIK), a set of TP-invariant matrix multiplication and reduction primitives that guarantee bit-wise identical results regardless of TP size. Our key insight is to align intra- and inter-GPU reduction orders through a unified hierarchical binary tree structure. We implement these kernels in Triton and integrate them into vLLM and FSDP. Experiments confirm zero probability divergence and bit-wise reproducibility for deterministic inference across different TP sizes. Also, we achieve bit-wise identical results between vLLM and FSDP in RL training pipelines with different parallel strategy. Code is available at https://github.com/nanomaoli/llm_reproducibility.

</details>


### [331] [Unified Class and Domain Incremental Learning with Mixture of Experts for Indoor Localization](https://arxiv.org/abs/2511.17829)
*Akhil Singampalli,Sudeep Pasricha*

Main category: cs.LG

TL;DR: MOELO是一个新颖的持续学习框架，首次联合解决室内定位中的领域增量学习和类别增量学习问题，通过混合专家架构实现轻量级、鲁棒且自适应的定位解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型在室内定位中长期可靠性受限，主要由于移动设备硬件/软件差异导致的领域偏移，以及室内环境变化带来的类别偏移，使得静态模型随时间失效。

Method: 采用混合专家架构，按区域增量训练专家，通过等角紧框架门控机制实现高效路由和低延迟推理，保持紧凑模型尺寸。

Result: 实验评估显示，MOELO在不同建筑、移动设备和学习场景下，相比最先进框架在平均定位误差上提升25.6倍，最差情况定位误差提升44.5倍，遗忘率降低21.5倍。

Conclusion: MOELO提供了一个可在资源受限移动设备上部署的持续学习解决方案，能够在动态、异构的真实世界环境中实现高效室内定位。

Abstract: Indoor localization using machine learning has gained traction due to the growing demand for location-based services. However, its long-term reliability is hindered by hardware/software variations across mobile devices, which shift the model's input distribution to create domain shifts. Further, evolving indoor environments can introduce new locations over time, expanding the output space to create class shifts, making static machine learning models ineffective over time. To address these challenges, we propose a novel unified continual learning framework for indoor localization called MOELO that, for the first time, jointly addresses domain-incremental and class-incremental learning scenarios. MOELO enables a lightweight, robust, and adaptive localization solution that can be deployed on resource-limited mobile devices and is capable of continual learning in dynamic, heterogeneous real-world settings. This is made possible by a mixture-of-experts architecture, where experts are incrementally trained per region and selected through an equiangular tight frame based gating mechanism ensuring efficient routing, and low-latency inference, all within a compact model footprint. Experimental evaluations show that MOELO achieves improvements of up to 25.6x in mean localization error, 44.5x in worst-case localization error, and 21.5x lesser forgetting compared to state-of-the-art frameworks across diverse buildings, mobile devices, and learning scenarios.

</details>


### [332] [Internalizing Tools as Morphisms in Graded Transformers](https://arxiv.org/abs/2511.17840)
*Tony Shaska*

Main category: cs.LG

TL;DR: 本文提出了一种分级的内部符号计算框架，通过类型化块映射和可微分路由策略实现稀疏、可解释的符号操作，统一了符号计算、几何和自监督学习。


<details>
  <summary>Details</summary>
Motivation: 将符号计算内化到transformer中，避免外部工具调用的开销，同时保持端到端可微分性和可解释性。

Method: 使用分级隐藏空间和类型化块映射，通过自监督的效用函数控制激活，采用信息几何方法进行优化。

Result: 在混合符号-语言任务上实现了选择性形态激活，能够内化外部工具范式。

Conclusion: 该框架统一了符号计算、几何和自监督学习，为可解释AI提供了理论基础。

Abstract: We introduce a graded formulation of internal symbolic computation for transformers. The hidden space is endowed with a grading $V=\bigoplus_{g\in G}V_g$, and symbolic operations are realized as typed block maps (morphisms) $φ_{h\leftarrow g}:V_g\to V_h$ that are activated selectively by a differentiable routing policy. A self-supervised \emph{graded utility functional}, defined as the loss reduction induced by a candidate morphism, governs activation and yields sparse, interpretable behavior. We develop the algebraic and geometric foundations: an internal model category whose objects are homogeneous components and whose morphisms are admissible grade transitions; adjoint pairs encoding typed round trips; and information-geometric interpretations in terms of KL gain, mirror descent with Bregman divergences, and Fisher natural gradients. Methodologically, we specify a utility--aware routing mechanism and objective that remain fully end-to-end differentiable. Analytic case studies and lightweight sanity checks illustrate selective morphic activation on hybrid symbolic-linguistic tasks. The framework unifies symbolic computation, geometry, and self--supervised learning within the \emph{graded transformer} formalism \cite{sh-89,sh-95}, while subsuming prior external-tool paradigms (e.g., Toolformer \cite{toolformer2023}) as a special case via functorial internalization.

</details>


### [333] [Transformers with RL or SFT Provably Learn Sparse Boolean Functions, But Differently](https://arxiv.org/abs/2511.17852)
*Bochen Lyu,Yiyang Jia,Xiaohao Cai,Zhanxing Zhu*

Main category: cs.LG

TL;DR: 本文通过理论分析比较了强化学习(RL)和监督微调(SFT)在训练Transformer学习k-稀疏布尔函数时的机制差异，揭示了RL同时学习整个思维链而SFT逐步学习的不同行为模式。


<details>
  <summary>Details</summary>
Motivation: 虽然RL和SFT都能让Transformer获得思维链(CoT)推理能力，但它们的底层机制和差异在理论上仍不清楚，需要系统分析。

Method: 使用单层Transformer学习k-稀疏布尔函数，通过理论分析RL和SFT的学习动态，并验证在k-PARITY、k-AND和k-OR三个基本函数上的学习条件。

Result: 证明了两种方法都能学习这些函数，但RL同时学习整个思维链，而SFT逐步学习思维链的每一步。

Conclusion: 研究为理解RL和SFT触发Transformer思维链能力的机制提供了理论见解，揭示了它们不同的学习行为模式。

Abstract: Transformers can acquire Chain-of-Thought (CoT) capabilities to solve complex reasoning tasks through fine-tuning. Reinforcement learning (RL) and supervised fine-tuning (SFT) are two primary approaches to this end, yet their underlying mechanisms and differences remain theoretically unclear. In this work, we examine these aspects specifically for learning $k$-sparse Boolean functions with a one-layer transformer and intermediate supervision that is akin to CoT. In particular, we consider $k$-sparse Boolean functions that can be recursively decomposed into fixed 2-sparse Boolean functions. We analyze the learning dynamics of fine-tuning the transformer via either RL or SFT with CoT to identify sufficient conditions for it to provably learn these functions. We verify that these conditions hold for three basic examples, including $k$-PARITY, $k$-AND, and $k$-OR, thus demonstrating the learnability of both approaches. Notably, we reveal that RL and SFT exhibit distinct learning behaviors: RL learns the whole CoT chain simultaneously, whereas SFT learns the CoT chain step-by-step. Overall, our findings provide theoretical insights into the underlying mechanisms of RL and SFT as well as how they differ in triggering the CoT capabilities of transformers.

</details>


### [334] [Cost-Sensitive Conformal Training with Provably Controllable Learning Bounds](https://arxiv.org/abs/2511.17861)
*Xuesong Jia,Yuanjie Shi,Ziquan Liu,Yi Xu,Yan Yan*

Main category: cs.LG

TL;DR: 本文提出了一种简单且无需依赖指示函数近似机制的成本敏感共形训练算法，通过理论证明最小化预测集期望大小可由真实标签的期望秩上界约束，并开发了基于真实标签排名的权重分配策略。


<details>
  <summary>Details</summary>
Motivation: 传统共形训练方法使用Sigmoid或高斯误差函数作为指示函数的替代，但这些替代函数没有统一的误差界限，导致学习界限不可控。

Method: 提出一种成本敏感共形训练算法，通过理论分析将预测集大小最小化问题转化为真实标签期望秩的上界约束，并设计基于真实标签排名的权重分配策略。

Result: 理论分析证明了所提出加权目标与共形预测集期望大小之间的紧密性，实验验证了方法的有效性，平均预测集大小减少了21.38%。

Conclusion: 该方法在预测效率方面优于其他共形训练方法，无需依赖指示函数近似机制，具有更好的理论保证和实证性能。

Abstract: Conformal prediction (CP) is a general framework to quantify the predictive uncertainty of machine learning models that uses a set prediction to include the true label with a valid probability. To align the uncertainty measured by CP, conformal training methods minimize the size of the prediction sets. A typical way is to use a surrogate indicator function, usually Sigmoid or Gaussian error function. However, these surrogate functions do not have a uniform error bound to the indicator function, leading to uncontrollable learning bounds. In this paper, we propose a simple cost-sensitive conformal training algorithm that does not rely on the indicator approximation mechanism. Specifically, we theoretically show that minimizing the expected size of prediction sets is upper bounded by the expected rank of true labels. To this end, we develop a rank weighting strategy that assigns the weight using the rank of true label on each data sample. Our analysis provably demonstrates the tightness between the proposed weighted objective and the expected size of conformal prediction sets. Extensive experiments verify the validity of our theoretical insights, and superior empirical performance over other conformal training in terms of predictive efficiency with 21.38% reduction for average prediction set size.

</details>


### [335] [Equivalence of Context and Parameter Updates in Modern Transformer Blocks](https://arxiv.org/abs/2511.17864)
*Adrian Goldwaser,Michael Munn,Javier Gonzalvo,Benoit Dherin*

Main category: cs.LG

TL;DR: 该研究将上下文对transformer的影响理论扩展到现代大语言模型的多样化架构，证明了上下文效果可以完美映射为MLP权重的rank-1补丁和RMSNorm尺度补丁，并提出了基于输入可控性和输出可控性的通用框架。


<details>
  <summary>Details</summary>
Motivation: 扩展已有关于上下文在transformer中影响的理论，使其适用于现代大语言模型的多样化架构，提供更简单强大的理论框架来理解transformer如何将提示转换为有效权重。

Method: 首先对Gemma风格transformer块提供精确解析解，证明上下文效果可映射为MLP权重rank-1补丁和RMSNorm尺度补丁；然后推广到多层模型，提出基于输入可控性和输出可控性的通用框架。

Result: 证明了对于任何MLP块，只要内部函数是输入可控的且外部函数是输出可控的，就可以实现完美的隐式权重补丁，该框架适用于包括门控、预/后归一化、专家混合和串行/并行transformer块在内的多种现代LLM架构。

Conclusion: 该研究提供了一个统一的理论框架，通过输入可控性和输出可控性两个核心属性，简化并强化了对transformer模型如何将提示转换为有效权重的理解，适用于广泛的现代LLM架构。

Abstract: Recent research has established that the impact of context in a vanilla transformer can be represented implicitly by forming a token-dependent, rank-1 patch to its MLP weights. This work extends that foundational theory to the diverse architectures of modern Large Language Models. We first demonstrate a precise, analytical solution for a Gemma-style transformer block, proving that the entire effect of a context can be perfectly mapped to rank-1 patches on its MLP weight matrices and a patch to the RMSNorm scale. We then generalize this result, providing a constructive proof and algorithm for multi-layer models. To unify these findings, we introduce a general framework centered on two core properties: input controllability and output controllability. We prove that a perfect implicit weight patch is possible for any MLP block where the inner function is input-controllable and the outer function is output-controllable. This provides a simpler and more powerful lens for understanding how transformer models transmute prompts into effective weights. This setup generalizes to a wide range of modern LLM architectures including gating, pre-/post-norm, mixture of experts and sequential/parallel transformer blocks.

</details>


### [336] [Mitigating Catastrophic Forgetting in Streaming Generative and Predictive Learning via Stateful Replay](https://arxiv.org/abs/2511.17936)
*Wenzhang Du*

Main category: cs.LG

TL;DR: 本文研究了在内存约束下流数据学习系统的模型更新策略，比较了顺序微调和重放机制在生成式和预测式任务中的表现，发现重放机制在多任务流中能显著减少遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有流数据学习系统在内存约束下更新模型时，顺序微调方法容易遭受灾难性遗忘，而重放机制在不同目标任务中的行为尚未得到充分理解。

Method: 将顺序微调和重放机制视为理想联合目标的随机梯度方法，通过梯度对齐分析研究混合当前和历史样本如何减少遗忘，并在六个流场景中评估单一重放机制。

Result: 在异构多任务流中，重放机制将平均遗忘减少2-3倍；在良性时间流中，两种方法表现相似。

Conclusion: 状态重放是流环境中持续学习的一个强大而简单的基线方法。

Abstract: Many deployed learning systems must update models on streaming data under memory constraints. The default strategy, sequential fine-tuning on each new phase, is architecture-agnostic but often suffers catastrophic forgetting when later phases correspond to different sub-populations or tasks. Replay with a finite buffer is a simple alternative, yet its behaviour across generative and predictive objectives is not well understood. We present a unified study of stateful replay for streaming autoencoding, time series forecasting, and classification. We view both sequential fine-tuning and replay as stochastic gradient methods for an ideal joint objective, and use a gradient alignment analysis to show when mixing current and historical samples should reduce forgetting. We then evaluate a single replay mechanism on six streaming scenarios built from Rotated MNIST, ElectricityLoadDiagrams 2011-2014, and Airlines delay data, using matched training budgets and three seeds. On heterogeneous multi task streams, replay reduces average forgetting by a factor of two to three, while on benign time based streams both methods perform similarly. These results position stateful replay as a strong and simple baseline for continual learning in streaming environments.

</details>


### [337] [On Transportability for Structural Causal Bandits](https://arxiv.org/abs/2511.17953)
*Min Woo Park,Sanghack Lee*

Main category: cs.LG

TL;DR: 本文研究了具有可迁移性的结构因果赌博机问题，通过融合源环境中的先验知识来增强部署环境中的学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有的结构因果赌博机框架虽然能利用因果结构知识优化动作空间，但缺乏从不同条件下收集的异构数据集中迁移信息的指导方法。

Method: 提出结构因果赌博机与可迁移性结合的方法，利用跨环境的不变性来改进学习过程。

Result: 开发的赌博机算法实现了亚线性遗憾界，明确依赖于先验数据的信息量，可能优于仅依赖在线学习的标准赌博机方法。

Conclusion: 通过利用跨环境的不变性，可以持续改进学习效果，融合先验知识能显著提升部署环境中的学习性能。

Abstract: Intelligent agents equipped with causal knowledge can optimize their action spaces to avoid unnecessary exploration. The structural causal bandit framework provides a graphical characterization for identifying actions that are unable to maximize rewards by leveraging prior knowledge of the underlying causal structure. While such knowledge enables an agent to estimate the expected rewards of certain actions based on others in online interactions, there has been little guidance on how to transfer information inferred from arbitrary combinations of datasets collected under different conditions -- observational or experimental -- and from heterogeneous environments. In this paper, we investigate the structural causal bandit with transportability, where priors from the source environments are fused to enhance learning in the deployment setting. We demonstrate that it is possible to exploit invariances across environments to consistently improve learning. The resulting bandit algorithm achieves a sub-linear regret bound with an explicit dependence on informativeness of prior data, and it may outperform standard bandit approaches that rely solely on online learning.

</details>


### [338] [An Adaptive Resonance Theory-based Topological Clustering Algorithm with a Self-Adjusting Vigilance Parameter](https://arxiv.org/abs/2511.17983)
*Naoki Masuyama,Yuichiro Toda,Yusuke Nojima,Hisao Ishibuchi*

Main category: cs.LG

TL;DR: 提出基于自适应共振理论(ART)的拓扑聚类算法，通过多样性驱动的适应机制自动调整重计算间隔和警戒阈值，实现无超参数学习，在动态环境中保持聚类稳定性和连续性。


<details>
  <summary>Details</summary>
Motivation: 解决静态和非静态设置中的聚类问题，需要能够适应分布变化同时保留已学习聚类结构的模型。

Method: 基于ART的拓扑聚类算法，采用多样性驱动的适应机制自动调整重计算间隔和警戒阈值，实现无超参数学习。

Result: 在24个真实世界数据集上的实验表明，该算法在聚类性能和持续学习能力方面均优于最先进方法。

Conclusion: 所提出的参数适应机制在缓解灾难性遗忘和保持演化数据流中一致聚类方面具有有效性。

Abstract: Clustering in stationary and nonstationary settings, where data distributions remain static or evolve over time, requires models that can adapt to distributional shifts while preserving previously learned cluster structures. This paper proposes an Adaptive Resonance Theory (ART)-based topological clustering algorithm that autonomously adjusts its recalculation interval and vigilance threshold through a diversity-driven adaptation mechanism. This mechanism enables hyperparameter-free learning that maintains cluster stability and continuity in dynamic environments. Experiments on 24 real-world datasets demonstrate that the proposed algorithm outperforms state-of-the-art methods in both clustering performance and continual learning capability. These results highlight the effectiveness of the proposed parameter adaptation in mitigating catastrophic forgetting and maintaining consistent clustering in evolving data streams. Source code is available at https://github.com/Masuyama-lab/IDAT

</details>


### [339] [Escaping Optimization Stagnation: Taking Steps Beyond Task Arithmetic via Difference Vectors](https://arxiv.org/abs/2511.17987)
*Jinping Wang,Zhiqiang Gao,Dinggen Zhang,Zhiwu Xie*

Main category: cs.LG

TL;DR: 论文提出了基于差异向量的各向异性缩放迭代算法（DV-BASI），通过利用优化过程中的历史运动信息来克服任务算术方法的优化停滞问题，实现了连续优化过程，并在多任务模型合并中取得了超越单独微调模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前预训练模型编辑方法面临高计算成本和有限可扩展性的挑战。任务算术方法虽然通过简单的算术运算来修改模型行为，但由于优化停滞问题，其潜力尚未完全发挥。

Method: 引入差异向量的概念，作为任务向量的广义形式，源自优化过程中的历史运动。提出DV-BASI算法，利用差异向量作为定向扰动，实现任务算术方法的连续优化，无需依赖额外模块。

Result: DV-BASI在多任务模型合并中的平均性能甚至优于单独微调的模型。该算法与任务算术方法和先进优化技术结合，在监督和无监督评估协议上都达到了最先进的性能。

Conclusion: 差异向量为任务算术方法提供了有效的优化机制，DV-BASI算法不仅解决了优化停滞问题，还扩展了差异向量在单任务模型微调中的应用，形成了可扩展的框架。

Abstract: Current methods for editing pre-trained models face significant challenges, primarily high computational costs and limited scalability. Task arithmetic has recently emerged as a promising solution, using simple arithmetic operations-addition and negation-based on task vectors which are the differences between fine-tuned and pre-trained model weights, to efficiently modify model behavior. However, the full potential of task arithmetic remains underexplored, primarily due to limited mechanisms for overcoming optimization stagnation. To address this challenge, we introduce the notion of difference vector, a generalized form of task vectors derived from the historical movements during optimization. Using difference vectors as directed perturbations, we propose the Difference Vector-based Anisotropic Scaling Iterative algorithm (DV-BASI) to enable a continuous optimization process for task arithmetic methods without relying on any additional modules or components. Notably, by leveraging escapability and directional advantages of difference vectors, the average performance on different tasks of the multi-task model merged by DV-BASI may even outperform models individually fine-tuned. Based on this observation, we extend the application of difference vectors to a feasible fine-tuning method for single-task models. On the practical side, DV-BASI allows expressive searching directions with few learnable parameters and forms a scalable framework. We also integrate DV-BASI with task arithmetic methods and advanced optimization techniques to achieve state-of-the-art performance on both supervised and unsupervised evaluation protocols.

</details>


### [340] [Learning Rate Scheduling with Matrix Factorization for Private Training](https://arxiv.org/abs/2511.17994)
*Nikita P. Kalinin,Joel Daniel Andersson*

Main category: cs.LG

TL;DR: 该论文研究了在差分隐私模型训练中，结合学习率调度和相关噪声的随机梯度下降方法。作者提出了学习率感知的矩阵分解方法，相比传统前缀和分解在多个误差指标上都有改进。


<details>
  <summary>Details</summary>
Motivation: 现有关于相关噪声（特别是矩阵分解）的研究主要关注恒定学习率的前缀和工作负载，而实践中学习率调度被广泛用于加速训练和改善收敛。这一差距需要被填补。

Method: 推导了在单轮和多轮训练设置下，针对广泛学习率调度类别的通用上下界。基于这些结果，提出了学习率感知的矩阵分解方法。

Result: 理论分析产生了适合实际部署的内存高效构造，在CIFAR-10和IMDB数据集上的实验证实，调度感知的分解方法提高了隐私训练的准确性。

Conclusion: 学习率感知的矩阵分解在差分隐私模型训练中优于传统前缀和分解，特别是在使用学习率调度时能显著提升性能。

Abstract: We study differentially private model training with stochastic gradient descent under learning rate scheduling and correlated noise. Although correlated noise, in particular via matrix factorizations, has been shown to improve accuracy, prior theoretical work focused primarily on the prefix-sum workload. That workload assumes a constant learning rate, whereas in practice learning rate schedules are widely used to accelerate training and improve convergence. We close this gap by deriving general upper and lower bounds for a broad class of learning rate schedules in both single- and multi-epoch settings. Building on these results, we propose a learning-rate-aware factorization that achieves improvements over prefix-sum factorizations under both MaxSE and MeanSE error metrics. Our theoretical analysis yields memory-efficient constructions suitable for practical deployment, and experiments on CIFAR-10 and IMDB datasets confirm that schedule-aware factorizations improve accuracy in private training.

</details>


### [341] [Understanding Private Learning From Feature Perspective](https://arxiv.org/abs/2511.18006)
*Meng Ding,Mingxi Lei,Shaopeng Fu,Shaowei Wang,Di Wang,Jinhui Xu*

Main category: cs.LG

TL;DR: 本文首次从特征学习的理论角度分析差分隐私SGD训练，区分标签相关特征信号和标签无关噪声，揭示了隐私训练需要更高信噪比且会继承非隐私训练中的噪声记忆问题。


<details>
  <summary>Details</summary>
Motivation: 尽管利用预训练模型特征增强DP-SGD训练在实证上取得进展，但隐私学习中特征动态的理论理解仍然不足，现有分析忽略了标签相关特征信号和标签无关噪声的关键区别。

Method: 基于多补丁数据结构，使用带多项式ReLU激活的两层CNN，通过噪声梯度下降理论分析私有训练中的特征信号学习和数据噪声记忆。

Result: 发现：(1)有效私有信号学习需要比非私有训练更高的信噪比；(2)当非私有学习中出现数据噪声记忆时，私有学习也会出现，导致训练损失小但泛化性能差。

Conclusion: 研究强调了私有学习的挑战，证明了特征增强提高信噪比的好处，合成和真实数据集实验验证了理论发现。

Abstract: Differentially private Stochastic Gradient Descent (DP-SGD) has become integral to privacy-preserving machine learning, ensuring robust privacy guarantees in sensitive domains. Despite notable empirical advances leveraging features from non-private, pre-trained models to enhance DP-SGD training, a theoretical understanding of feature dynamics in private learning remains underexplored. This paper presents the first theoretical framework to analyze private training through a feature learning perspective. Building on the multi-patch data structure from prior work, our analysis distinguishes between label-dependent feature signals and label-independent noise, a critical aspect overlooked by existing analyses in the DP community. Employing a two-layer CNN with polynomial ReLU activation, we theoretically characterize both feature signal learning and data noise memorization in private training via noisy gradient descent. Our findings reveal that (1) Effective private signal learning requires a higher signal-to-noise ratio (SNR) compared to non-private training, and (2) When data noise memorization occurs in non-private learning, it will also occur in private learning, leading to poor generalization despite small training loss. Our findings highlight the challenges of private learning and prove the benefit of feature enhancement to improve SNR. Experiments on synthetic and real-world datasets also validate our theoretical findings.

</details>


### [342] [Curvature-Aware Safety Restoration In LLMs Fine-Tuning](https://arxiv.org/abs/2511.18039)
*Thong Bach,Thanh Nguyen-Tang,Dung Nguyen,Thao Minh Le,Truyen Tran*

Main category: cs.LG

TL;DR: 该论文发现微调LLM会损害安全对齐，但安全行为并未被完全擦除而是转移到参数空间中影响力较小的区域。基于此，作者提出了一种曲率感知的对齐恢复方法，通过影响函数和二阶优化选择性增加有害输入的损失，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型进行下游任务时往往会损害安全对齐，即使使用LoRA等参数高效方法也是如此。作者旨在解决这一安全问题，同时保持模型的任务性能。

Method: 提出曲率感知对齐恢复方法，利用影响函数和二阶优化，在基础模型和微调模型共享的几何结构基础上，选择性增加有害输入的损失，避免完全回退并实现精确、低影响的更新。

Result: 在多个模型系列和对抗设置下的广泛评估表明，该方法能有效减少有害响应，同时保持甚至提高效用和少样本学习性能。

Conclusion: 通过利用微调模型在有害内容上的损失景观几何结构保持不变的特性，提出的方法能够高效恢复安全对齐，同时保持任务相关性能，为LLM安全微调提供了新思路。

Abstract: Fine-tuning Large Language Models (LLMs) for downstream tasks often compromises safety alignment, even when using parameter-efficient methods like LoRA. In this work, we uncover a notable property: fine-tuned models preserve the geometric structure of their loss landscapes concerning harmful content, regardless of the fine-tuning method employed. This suggests that safety behaviors are not erased but shifted to less influential regions of the parameter space. Building on this insight, we propose a curvature-aware alignment restoration method that leverages influence functions and second-order optimization to selectively increase loss on harmful inputs while preserving task performance. By navigating the shared geometry between base and fine-tuned models, our method discourages unsafe outputs while preserving task-relevant performance, avoiding full reversion and enabling precise, low-impact updates. Extensive evaluations across multiple model families and adversarial settings show that our approach efficiently reduces harmful responses while maintaining or even improving utility and few-shot learning performance.

</details>


### [343] [Hierarchical Linkage Clustering Beyond Binary Trees and Ultrametrics](https://arxiv.org/abs/2511.18056)
*Maximilien Dreveton,Matthias Grossglauser,Daichi Kuroda,Patrick Thiran*

Main category: cs.LG

TL;DR: 论文提出有效层次结构概念，解决了传统层次聚类的三个主要限制：总是返回层次结构、仅限于二叉树、对链接函数选择敏感。通过定义有效层次结构的部分序，证明了最精细有效层次结构的存在，并提出两步算法来恢复该结构。


<details>
  <summary>Details</summary>
Motivation: 传统层次聚类方法存在三个主要问题：(i)即使数据中不存在层次结构也会返回层次结构，(ii)仅限于二叉树结构，(iii)对链接函数选择高度敏感。这些限制影响了聚类结果的准确性和实用性。

Method: 提出有效层次结构概念并定义部分序，证明最精细有效层次结构的存在性。开发两步算法：首先通过链接方法构建二叉树，然后进行剪枝以强制执行有效性。

Result: 建立了链接函数恢复最精细有效层次结构的充要条件，证明满足这些条件的链接函数在剪枝后都会产生相同的层次结构。经典链接规则（单链接、全链接、平均链接）满足条件，而Ward链接不满足。

Conclusion: 该方法能够自动识别数据中是否存在层次结构，不限于二叉树，且对链接函数选择具有鲁棒性，为层次聚类提供了更可靠的理论基础和实践方法。

Abstract: Hierarchical clustering seeks to uncover nested structures in data by constructing a tree of clusters, where deeper levels reveal finer-grained relationships. Traditional methods, including linkage approaches, face three major limitations: (i) they always return a hierarchy, even if none exists, (ii) they are restricted to binary trees, even if the true hierarchy is non-binary, and (iii) they are highly sensitive to the choice of linkage function. In this paper, we address these issues by introducing the notion of a valid hierarchy and defining a partial order over the set of valid hierarchies. We prove the existence of a finest valid hierarchy, that is, the hierarchy that encodes the maximum information consistent with the similarity structure of the data set. In particular, the finest valid hierarchy is not constrained to binary structures and, when no hierarchical relationships exist, collapses to a star tree. We propose a simple two-step algorithm that first constructs a binary tree via a linkage method and then prunes it to enforce validity. We establish necessary and sufficient conditions on the linkage function under which this procedure exactly recovers the finest valid hierarchy, and we show that all linkage functions satisfying these conditions yield the same hierarchy after pruning. Notably, classical linkage rules such as single, complete, and average satisfy these conditions, whereas Ward's linkage fails to do so.

</details>


### [344] [pFedBBN: A Personalized Federated Test-Time Adaptation with Balanced Batch Normalization for Class-Imbalanced Data](https://arxiv.org/abs/2511.18066)
*Md Akil Raihan Iftee,Syed Md. Ahnaf Hasan,Mir Sazzat Hossain,Rakibul Hasan Rajib,Amin Ahsan Ali,AKM Mahbubur Rahman,Sajib Mistry,Monowar Bhuyan*

Main category: cs.LG

TL;DR: pFedBBN是一个个性化联邦测试时适应框架，通过平衡批归一化处理类别不平衡问题，在无需客户端标签数据的情况下实现联邦学习中的测试时适应。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的测试时适应面临类别不平衡的挑战，现有方法依赖标签数据或客户端协调，无法在推理时动态适应域偏移和分布变化。

Method: 采用平衡批归一化进行本地客户端适应以缓解预测偏差，通过BBN相似性指导客户端协作，使用类别感知模型聚合策略实现个性化推理。

Result: 在多样化基线上进行的广泛实验表明，pFedBBN在鲁棒性和少数类性能方面持续优于最先进的联邦学习和测试时适应方法。

Conclusion: pFedBBN通过平衡特征归一化和域感知协作，有效解决了分布偏移和类别不平衡问题，无需客户端任何标签或原始数据。

Abstract: Test-time adaptation (TTA) in federated learning (FL) is crucial for handling unseen data distributions across clients, particularly when faced with domain shifts and skewed class distributions. Class Imbalance (CI) remains a fundamental challenge in FL, where rare but critical classes are often severely underrepresented in individual client datasets. Although prior work has addressed CI during training through reliable aggregation and local class distribution alignment, these methods typically rely on access to labeled data or coordination among clients, and none address class unsupervised adaptation to dynamic domains or distribution shifts at inference time under federated CI constraints. Revealing the failure of state-of-the-art TTA in federated client adaptation in CI scenario, we propose pFedBBN,a personalized federated test-time adaptation framework that employs balanced batch normalization (BBN) during local client adaptation to mitigate prediction bias by treating all classes equally, while also enabling client collaboration guided by BBN similarity, ensuring that clients with similar balanced representations reinforce each other and that adaptation remains aligned with domain-specific characteristics. pFedBBN supports fully unsupervised local adaptation and introduces a class-aware model aggregation strategy that enables personalized inference without compromising privacy. It addresses both distribution shifts and class imbalance through balanced feature normalization and domain-aware collaboration, without requiring any labeled or raw data from clients. Extensive experiments across diverse baselines show that pFedBBN consistently enhances robustness and minority-class performance over state-of-the-art FL and TTA methods.

</details>


### [345] [The Alignment Paradox of Medical Large Language Models in Infertility Care: Decoupling Algorithmic Improvement from Clinical Decision-making Quality](https://arxiv.org/abs/2511.18084)
*Dou Liu,Ying Long,Sophia Zuoqiu,Kaipeng Xie,Runze Yang,Di Liu,Kang Li,Yiting Lin,Hanyi Liu,Rong Yin,Tian Tang*

Main category: cs.LG

TL;DR: 本文系统评估了四种对齐策略在临床决策支持中的应用，发现GRPO在算法精度上最优，但临床医生更偏好SFT模型，揭示了算法改进与临床信任之间的对齐悖论。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床决策支持中应用日益广泛，但如何使其与真实世界医学的多维推理路径对齐仍是一个重大挑战。

Method: 使用超过8000份不孕症治疗记录，通过结合自动基准测试和盲法医生参与评估的双层框架，系统评估SFT、DPO、GRPO和ICL四种对齐策略。

Result: GRPO在多个决策层获得最高算法精度，但临床医生一致偏好SFT模型，认为其推理过程更清晰、治疗可行性更高。在盲法配对比较中，SFT获得最高胜率（51.2%）。

Conclusion: 研究揭示了对齐悖论：算法改进不一定转化为更高的临床信任，可能与以人为中心的偏好相背离。需要优先考虑临床可解释性和实践可行性的对齐策略，而非仅仅优化决策级精度。

Abstract: Large language models (LLMs) are increasingly adopted in clinical decision support, yet aligning them with the multifaceted reasoning pathways of real-world medicine remains a major challenge. Using more than 8,000 infertility treatment records, we systematically evaluate four alignment strategies: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), Group Relative Policy Optimization (GRPO), and In-Context Learning (ICL) through a dual-layer framework combining automatic benchmarks with blinded doctor-in-the-loop assessments. GRPO achieves the highest algorithmic accuracy across multiple decision layers, confirming the value of reinforcement-based optimization for structured prediction tasks. However, clinicians consistently prefer the SFT model, citing clearer reasoning processes (p = 0.035) and higher therapeutic feasibility (p = 0.019). In blinded pairwise comparisons, SFT attains the highest winning rate (51.2%), outperforming both GRPO (26.2%) and even physicians' original decisions (22.7%). These results reveal an alignment paradox: algorithmic improvements do not necessarily translate into higher clinical trust, and may diverge from human-centered preferences. Our findings highlight the need for alignment strategies that prioritize clinically interpretable and practically feasible reasoning, rather than solely optimizing decision-level accuracy.

</details>


### [346] [Vulnerability-Aware Robust Multimodal Adversarial Training](https://arxiv.org/abs/2511.18138)
*Junrui Zhang,Xinyu Zhao,Jie Peng,Chenjie Wang,Jianmin Ji,Tianlong Chen*

Main category: cs.LG

TL;DR: 本文提出VARMAT方法，通过探测模态脆弱性并进行针对性正则化，提升多模态对抗训练的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视不同模态对最终鲁棒性的贡献差异，导致次优的鲁棒性能

Method: VARMAT首先量化每个模态的脆弱性（探测），然后提出针对性正则化项惩罚高脆弱性模态（训练）

Result: 在多个多模态数据集上实现显著鲁棒性提升，三个数据集分别提升12.73%、22.21%、11.19%

Conclusion: 该方法揭示了多模态对抗训练中的重要盲点，显著提升了多模态模型的鲁棒性

Abstract: Multimodal learning has shown significant superiority on various tasks by integrating multiple modalities. However, the interdependencies among modalities increase the susceptibility of multimodal models to adversarial attacks. Existing methods mainly focus on attacks on specific modalities or indiscriminately attack all modalities. In this paper, we find that these approaches ignore the differences between modalities in their contribution to final robustness, resulting in suboptimal robustness performance. To bridge this gap, we introduce Vulnerability-Aware Robust Multimodal Adversarial Training (VARMAT), a probe-in-training adversarial training method that improves multimodal robustness by identifying the vulnerability of each modality. To be specific, VARMAT first explicitly quantifies the vulnerability of each modality, grounded in a first-order approximation of the attack objective (Probe). Then, we propose a targeted regularization term that penalizes modalities with high vulnerability, guiding robust learning while maintaining task accuracy (Training). We demonstrate the enhanced robustness of our method across multiple multimodal datasets involving diverse modalities. Finally, we achieve {12.73%, 22.21%, 11.19%} robustness improvement on three multimodal datasets, revealing a significant blind spot in multimodal adversarial training.

</details>


### [347] [scipy.spatial.transform: Differentiable Framework-Agnostic 3D Transformations in Python](https://arxiv.org/abs/2511.18157)
*Martin Schuck,Alexander von Rohr,Angela P. Schoellig*

Main category: cs.LG

TL;DR: 本文对SciPy的spatial.transform模块进行了全面重写，使其兼容所有实现Python数组API的库（如JAX、PyTorch、CuPy），支持GPU/TPU执行、JIT编译、向量化批处理和自动微分。


<details>
  <summary>Details</summary>
Motivation: 解决传统SO(3)三维刚体变换实现中的数值鲁棒性和数学正确性问题，同时扩展SciPy功能以适应GPU加速和自动微分工作流。

Method: 重写SciPy spatial.transform模块，保持原有接口但使其兼容Python数组API标准，支持多种深度学习框架的后端。

Result: 成功实现了框架无关的三维空间数学库，支持GPU加速、JIT编译和自动微分，已合并到SciPy主分支。

Conclusion: 为可微分系统和机器学习提供了一个生产级的三维空间数学基础，通过案例研究展示了在3D变换和无人机仿真中的应用价值。

Abstract: Three-dimensional rigid-body transforms, i.e. rotations and translations, are central to modern differentiable machine learning pipelines in robotics, vision, and simulation. However, numerically robust and mathematically correct implementations, particularly on SO(3), are error-prone due to issues such as axis conventions, normalizations, composition consistency and subtle errors that only appear in edge cases. SciPy's spatial.transform module is a rigorously tested Python implementation. However, it historically only supported NumPy, limiting adoption in GPU-accelerated and autodiff-based workflows. We present a complete overhaul of SciPy's spatial.transform functionality that makes it compatible with any array library implementing the Python array API, including JAX, PyTorch, and CuPy. The revised implementation preserves the established SciPy interface while enabling GPU/TPU execution, JIT compilation, vectorized batching, and differentiation via native autodiff of the chosen backend. We demonstrate how this foundation supports differentiable scientific computing through two case studies: (i) scalability of 3D transforms and rotations and (ii) a JAX drone simulation that leverages SciPy's Rotation for accurate integration of rotational dynamics. Our contributions have been merged into SciPy main and will ship in the next release, providing a framework-agnostic, production-grade basis for 3D spatial math in differentiable systems and ML.

</details>


### [348] [LocaGen: Low-Overhead Indoor Localization Through Spatial Augmentation](https://arxiv.org/abs/2511.18158)
*Abdelrahman Abdelmotlb,Abdallah Taman,Sherif Mostafa,Moustafa Youssef*

Main category: cs.LG

TL;DR: LocaGen是一个创新的空间增强框架，通过条件扩散模型生成未见过位置的高质量合成指纹数据，显著减少室内定位系统所需的指纹采集工作量。


<details>
  <summary>Details</summary>
Motivation: 传统指纹定位方法需要大量位置标记信号数据采集，部署成本高。现有减少采集工作量的方法存在表示能力低、模式崩溃或仍需在所有目标位置采集数据的问题。

Method: 使用条件扩散模型结合空间感知优化策略，仅基于部分已见位置生成未见过位置的合成指纹数据；通过领域特定启发式方法增强已见位置数据；采用基于密度的策略选择已见和未见位置以确保鲁棒覆盖。

Result: 在真实WiFi指纹数据集上的评估显示，即使30%位置未见过，LocaGen仍能保持相同的定位精度，相比最先进的增强方法精度提升高达28%。

Conclusion: LocaGen通过空间增强框架有效减少了指纹定位系统的部署成本，在显著减少数据采集工作量的同时保持了高定位精度。

Abstract: Indoor localization systems commonly rely on fingerprinting, which requires extensive survey efforts to obtain location-tagged signal data, limiting their real-world deployability. Recent approaches that attempt to reduce this overhead either suffer from low representation ability, mode collapse issues, or require the effort of collecting data at all target locations. We present LocaGen, a novel spatial augmentation framework that significantly reduces fingerprinting overhead by generating high-quality synthetic data at completely unseen locations. LocaGen leverages a conditional diffusion model guided by a novel spatially aware optimization strategy to synthesize realistic fingerprints at unseen locations using only a subset of seen locations. To further improve our diffusion model performance, LocaGen augments seen location data based on domain-specific heuristics and strategically selects the seen and unseen locations using a novel density-based approach that ensures robust coverage. Our extensive evaluation on a real-world WiFi fingerprinting dataset shows that LocaGen maintains the same localization accuracy even with 30% of the locations unseen and achieves up to 28% improvement in accuracy over state-of-the-art augmentation methods.

</details>


### [349] [Bringing Stability to Diffusion: Decomposing and Reducing Variance of Training Masked Diffusion Models](https://arxiv.org/abs/2511.18159)
*Mengni Jia,Mengyu Zhou,Yihao Liu,Xiaoxi Jiang,Guanjun Jiang*

Main category: cs.LG

TL;DR: 本文分析了掩码扩散模型训练方差高的原因，提出了两种核心方差减少方法P-POTS和MIRROR，显著提升了MDM在复杂推理任务上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型相比自回归模型存在更高的训练方差，导致梯度估计噪声大、优化不稳定，即使初始化时性能相当，任务特定训练后MDM往往远落后于ARM。目前缺乏理论解释和系统解决方案。

Method: 首先将MDM训练方差分解为三个来源：掩码模式噪声、掩码率噪声和数据噪声；基于此设计了六种方差减少方法，包括两个核心方法：P-POTS（帕累托最优t采样器）和MIRROR（使用负相关样本减少掩码模式噪声）。

Result: 相比标准MDM训练，新方法在复杂推理任务上准确率提升7-8%，同时将运行间变异性降低到接近ARM水平，显著缩小了与强ARM基线的差距；在大多数设置中，最佳基线运行仍低于我们方法的最差运行。

Conclusion: 本文首次理论分解了MDM训练方差来源，提出的方差减少方法有效解决了MDM训练稳定性问题，大幅提升了其性能表现，缩小了与ARM的差距。

Abstract: Masked diffusion models (MDMs) are a promising alternative to autoregressive models (ARMs), but they suffer from inherently much higher training variance. High variance leads to noisier gradient estimates and unstable optimization, so even equally strong pretrained MDMs and ARMs that are competitive at initialization often diverge after task-specific training, with MDMs falling far behind. There has been no theoretical explanation or systematic solution. We derive the first decomposition of MDM training variance into three sources: (A) masking pattern noise, (B) masking rate noise, and (C) data noise, while ARMs are only affected by (C). This explains the fundamental training gap. Building on this foundation, we design six variance-reduction methods, including two core methods: (1) P-POTS, a Pareto-optimal t sampler that minimizes training variance by sampling harder t values more often with appropriately smaller update steps, and (2) MIRROR, which uses negatively correlated samples to reduce (A). Experiments show that compared to standard MDM training, our methods improve accuracy by 7-8% on complex reasoning tasks, while simultaneously reducing run-to-run variability to near ARM levels, substantially narrowing the gap with strong ARM baselines; in most settings, even the best baseline runs remain below the worst run of our method.

</details>


### [350] [Bayesian Calibration of Engine-out NOx Models for Engine-to-Engine Transferability](https://arxiv.org/abs/2511.18178)
*Shrenik Zinage,Peter Meckl,Ilias Bilionis*

Main category: cs.LG

TL;DR: 提出了一种贝叶斯校准框架，结合高斯过程和近似贝叶斯计算来推断和校正传感器偏差，以解决发动机间差异导致的NOx预测泛化问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于少量发动机数据的NOx预测模型难以泛化到整个发动机群体，存在传感器偏差和输入条件变化问题，需要能够适应发动机间差异的模型。

Method: 使用贝叶斯校准框架，将高斯过程与近似贝叶斯计算相结合，从预训练模型出发推断发动机特定传感器偏差并重新校准预测。

Result: 该方法在不重新训练模型的情况下，对未见测试数据生成发动机出口NOx的后验预测分布，相比传统非自适应GP模型显著提高了预测准确性。

Conclusion: 这种可迁移建模方法有效解决了发动机间差异问题，提高了模型泛化能力，为发动机NOx预测提供了更可靠的解决方案。

Abstract: Accurate prediction of engine-out NOx is essential for meeting stringent emissions regulations and optimizing engine performance. Traditional approaches rely on models trained on data from a small number of engines, which can be insufficient in generalizing across an entire population of engines due to sensor biases and variations in input conditions. In real world applications, these models require tuning or calibration to maintain acceptable error tolerance when applied to other engines. This highlights the need for models that can adapt with minimal adjustments to accommodate engine-to-engine variability and sensor discrepancies. While previous studies have explored machine learning methods for predicting engine-out NOx, these approaches often fail to generalize reliably across different engines and operating environments. To address these issues, we propose a Bayesian calibration framework that combines Gaussian processes with approximate Bayesian computation to infer and correct sensor biases. Starting with a pre-trained model developed using nominal engine data, our method identifies engine specific sensor biases and recalibrates predictions accordingly. By incorporating these inferred biases, our approach generates posterior predictive distributions for engine-out NOx on unseen test data, achieving high accuracy without retraining the model. Our results demonstrate that this transferable modeling approach significantly improves the accuracy of predictions compared to conventional non-adaptive GP models, effectively addressing engine-to-engine variability and improving model generalizability.

</details>


### [351] [Adaptive Conformal Prediction for Quantum Machine Learning](https://arxiv.org/abs/2511.18225)
*Douglas Spencer,Samual Nicholls,Michele Caprio*

Main category: cs.LG

TL;DR: 本文提出了自适应量子共形预测（AQCP）算法，通过重复重新校准来应对量子处理器中固有的时变噪声，从而在任意硬件噪声条件下保持渐近平均覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习需要可靠的预测不确定性量化方法，但当前量子领域缺乏稳健的不确定性量化技术。量子共形预测虽然能提供保证包含真实结果的预测集，但量子处理器的时变噪声会破坏其保证。

Method: 基于自适应共形推理方法，引入自适应量子共形预测（AQCP）算法，通过重复重新校准来维持随时间变化的有效性。

Result: 在IBM量子处理器上的实证研究表明，AQCP能够达到目标覆盖水平，并且比量子共形预测表现出更高的稳定性。

Conclusion: AQCP算法能够在量子硬件噪声条件下保持有效的覆盖保证，为量子机器学习提供了更可靠的不确定性量化方法。

Abstract: Quantum machine learning seeks to leverage quantum computers to improve upon classical machine learning algorithms. Currently, robust uncertainty quantification methods remain underdeveloped in the quantum domain, despite the critical need for reliable and trustworthy predictions. Recent work has introduced quantum conformal prediction, a framework that produces prediction sets that are guaranteed to contain the true outcome with user-specified probability. In this work, we formalise how the time-varying noise inherent in quantum processors can undermine conformal guarantees, even when calibration and test data are exchangeable. To address this challenge, we draw on Adaptive Conformal Inference, a method which maintains validity over time via repeated recalibration. We introduce Adaptive Quantum Conformal Prediction (AQCP), an algorithm which preserves asymptotic average coverage guarantees under arbitrary hardware noise conditions. Empirical studies on an IBM quantum processor demonstrate that AQCP achieves target coverage levels and exhibits greater stability than quantum conformal prediction.

</details>


### [352] [Tail Distribution of Regret in Optimistic Reinforcement Learning](https://arxiv.org/abs/2511.18247)
*Sajad Khodadadian,Mehrdad Moharrami*

Main category: cs.LG

TL;DR: 本文针对基于乐观策略的强化学习在有限时域表格马尔可夫决策过程中的遗憾值，推导了实例依赖的尾部边界。分析了两种探索奖励调度方案，揭示了遗憾分布的双重机制特征：从实例依赖尺度开始的亚高斯尾部到过渡阈值，之后是亚威布尔尾部。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注期望遗憾或单一高概率分位数，缺乏对累积遗憾完整尾部分布的全面分析。本文旨在填补这一空白，提供更全面的遗憾尾部保证。

Method: 采用UCBVI类型算法，分析两种探索奖励调度：(i) K依赖方案，显式包含总回合数K；(ii) K独立方案，仅依赖当前回合索引。通过调节参数α平衡期望遗憾和亚高斯尾部范围。

Result: 获得了Pr(R_K ≥ x)的上界，展现出独特的双重机制结构：从实例依赖尺度m_K到过渡阈值的亚高斯尾部，之后是亚威布尔尾部。同时推导了相应的实例依赖期望遗憾边界。

Conclusion: 本文为回合强化学习中标准乐观算法提供了首批全面的尾部遗憾保证，揭示了遗憾分布的复杂结构特征，为算法设计提供了新的理论指导。

Abstract: We derive instance-dependent tail bounds for the regret of optimism-based reinforcement learning in finite-horizon tabular Markov decision processes with unknown transition dynamics. Focusing on a UCBVI-type algorithm, we characterize the tail distribution of the cumulative regret $R_K$ over $K$ episodes, rather than only its expectation or a single high-probability quantile. We analyze two natural exploration-bonus schedules: (i) a $K$-dependent scheme that explicitly incorporates the total number of episodes $K$, and (ii) a $K$-independent scheme that depends only on the current episode index. For both settings, we obtain an upper bound on $\Pr(R_K \ge x)$ that exhibits a distinctive two-regime structure: a sub-Gaussian tail starting from an instance-dependent scale $m_K$ up to a transition threshold, followed by a sub-Weibull tail beyond that point. We further derive corresponding instance-dependent bounds on the expected regret $\mathbb{E}[R_K]$. The proposed algorithm depends on a tuning parameter $α$, which balances the expected regret and the range over which the regret exhibits a sub-Gaussian tail. To the best of our knowledge, our results provide one of the first comprehensive tail-regret guarantees for a standard optimistic algorithm in episodic reinforcement learning.

</details>


### [353] [Coherent Multi-Agent Trajectory Forecasting in Team Sports with CausalTraj](https://arxiv.org/abs/2511.18248)
*Wei Zhen Teoh*

Main category: cs.LG

TL;DR: CausalTraj是一个基于因果关系的多智能体轨迹预测模型，专注于生成联合概率轨迹预测，在体育分析中实现更真实的多智能体交互模拟。


<details>
  <summary>Details</summary>
Motivation: 现有模型主要评估单智能体精度指标（minADE、minFDE），忽略了模型是否能够生成联合可信的多智能体未来轨迹，导致在团队运动中无法生成连贯、可解释的多智能体场景。

Method: 提出CausalTraj模型，这是一个时间因果、基于似然的模型，专门设计用于生成联合概率的多智能体轨迹预测。

Result: 在NBA SportVU、Basketball-U和Football-U数据集上的评估显示，CausalTraj在单智能体精度指标上具有竞争力，并在联合指标（minJADE、minJFDE）上取得了最佳记录结果。

Conclusion: CausalTraj不仅实现了竞争性的单智能体预测精度，更重要的是能够生成定性连贯和真实的游戏演化场景，强调了联合评估指标在多智能体轨迹预测中的重要性。

Abstract: Jointly forecasting trajectories of multiple interacting agents is a core challenge in sports analytics and other domains involving complex group dynamics. Accurate prediction enables realistic simulation and strategic understanding of gameplay evolution. Most existing models are evaluated solely on per-agent accuracy metrics (minADE, minFDE), which assess each agent independently on its best-of-k prediction. However these metrics overlook whether the model learns which predicted trajectories can jointly form a plausible multi-agent future. Many state-of-the-art models are designed and optimized primarily based on these metrics. As a result, they may underperform on joint predictions and also fail to generate coherent, interpretable multi-agent scenarios in team sports. We propose CausalTraj, a temporally causal, likelihood-based model that is built to generate jointly probable multi-agent trajectory forecasts. To better assess collective modeling capability, we emphasize joint metrics (minJADE, minJFDE) that measure joint accuracy across agents within the best generated scenario sample. Evaluated on the NBA SportVU, Basketball-U, and Football-U datasets, CausalTraj achieves competitive per-agent accuracy and the best recorded results on joint metrics, while yielding qualitatively coherent and realistic gameplay evolutions.

</details>


### [354] [From Tables to Signals: Revealing Spectral Adaptivity in TabPFN](https://arxiv.org/abs/2511.18278)
*Jianqiao Zheng,Cameron Gordon,Yiping Ji,Hemanth Saratchandran,Simon Lucey*

Main category: cs.LG

TL;DR: 本文通过信号重构视角分析TabPFN，发现其具有比标准ReLU-MLP更广的有效频率容量，且频谱能力能自适应上下文样本数量，无需超参数调整即可实现图像去噪。


<details>
  <summary>Details</summary>
Motivation: 理解任务无关的表格基础模型（如TabPFN）的归纳偏差来源，目前对其内部学习机制了解甚少。

Method: 通过信号重构和频率分析研究TabPFN的上下文学习行为，分析其频谱特性和位置编码的影响。

Result: TabPFN具有比标准ReLU-MLP更广的有效频率容量，其频谱能力能自适应上下文样本数量，位置编码能调节频率响应，无需训练和超参数调整即可实现图像去噪。

Conclusion: 该分析为表格基础模型的结构和归纳偏差提供了新见解，并展示了其在更广泛信号重构任务中的潜力。

Abstract: Task-agnostic tabular foundation models such as TabPFN have achieved impressive performance on tabular learning tasks, yet the origins of their inductive biases remain poorly understood. In this work, we study TabPFN through the lens of signal reconstruction and provide the first frequency-based analysis of its in-context learning behavior. We show that TabPFN possesses a broader effective frequency capacity than standard ReLU-MLPs, even without hyperparameter tuning. Moreover, unlike MLPs whose spectra evolve primarily over training epochs, we find that TabPFN's spectral capacity adapts directly to the number of samples provided in-context, a phenomenon we term Spectral Adaptivity. We further demonstrate that positional encoding modulates TabPFN's frequency response, mirroring classical results in implicit neural representations. Finally, we show that these properties enable TabPFN to perform training-free and hyperparameter-free image denoising, illustrating its potential as a task-agnostic implicit model. Our analysis provides new insight into the structure and inductive biases of tabular foundation models and highlights their promise for broader signal reconstruction tasks.

</details>


### [355] [TRIDENT: A Trimodal Cascade Generative Framework for Drug and RNA-Conditioned Cellular Morphology Synthesis](https://arxiv.org/abs/2511.18287)
*Rui Peng,Ziru Liu,Lingyuan Ye,Yuxing Lu,Boxin Shi,Jinzhuo Wang*

Main category: cs.LG

TL;DR: TRIDENT是一个级联生成框架，通过同时考虑扰动和相应基因表达谱来合成真实的细胞形态，显著优于现有方法，在未见化合物上表现出强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常局限于建模直接关联（如扰动→RNA或扰动→形态），而忽略了从RNA到形态的关键因果联系，这限制了构建AI虚拟细胞的能力。

Method: 提出了TRIDENT级联生成框架，构建了MorphoGene数据集（包含98种化合物的L1000基因表达和Cell Painting图像配对数据），通过条件化扰动和基因表达谱来合成细胞形态。

Result: TRIDENT显著优于最先进方法，实现了高达7倍的改进，对未见化合物具有强泛化能力。在多西他赛案例研究中验证了RNA引导合成能准确产生相应表型。消融研究证实RNA条件化对模型高保真度至关重要。

Conclusion: 通过显式建模转录组-表型组映射，TRIDENT提供了一个强大的计算机模拟工具，使我们更接近预测性虚拟细胞。

Abstract: Accurately modeling the relationship between perturbations, transcriptional responses, and phenotypic changes is essential for building an AI Virtual Cell (AIVC). However, existing methods typically constrained to modeling direct associations, such as Perturbation $\rightarrow$ RNA or Perturbation $\rightarrow$ Morphology, overlook the crucial causal link from RNA to morphology. To bridge this gap, we propose TRIDENT, a cascade generative framework that synthesizes realistic cellular morphology by conditioning on both the perturbation and the corresponding gene expression profile. To train and evaluate this task, we construct MorphoGene, a new dataset pairing L1000 gene expression with Cell Painting images for 98 compounds. TRIDENT significantly outperforms state-of-the-art approaches, achieving up to 7-fold improvement with strong generalization to unseen compounds. In a case study on docetaxel, we validate that RNA-guided synthesis accurately produces the corresponding phenotype. An ablation study further confirms that this RNA conditioning is essential for the model's high fidelity. By explicitly modeling transcriptome-phenome mapping, TRIDENT provides a powerful in silico tool and moves us closer to a predictive virtual cell.

</details>


### [356] [ADF-LoRA: Alternating Low-Rank Aggregation for Decentralized Federated Fine-Tuning](https://arxiv.org/abs/2511.18291)
*Xiaoyu Wang,Xiaotian Li,Zhixiang Zhou,Chen Li,Yong Liu*

Main category: cs.LG

TL;DR: 本文提出了ADF-LoRA方法，在去中心化联邦学习中通过交替更新低秩矩阵来改善稳定性和收敛性能。


<details>
  <summary>Details</summary>
Motivation: 在去中心化联邦学习中，交替更新LoRA矩阵会面临相位状态不匹配和块级发散的新挑战，需要设计更稳定的参数同步机制。

Method: 提出了ADF-LoRA方法，每轮只同步更新一个低秩矩阵，并混合两个矩阵以在去中心化传播下保持更一致的参数状态。

Result: 在多个GLUE任务上的实验表明，ADF-LoRA实现了更快更平滑的收敛，并在所有任务上获得最高平均准确率，显著优于现有的LoRA变体。

Conclusion: ADF-LoRA在保持交替更新的交叉项抑制效果的同时，提高了在无服务器拓扑中的稳定性，为去中心化联邦学习提供了有效的解决方案。

Abstract: This paper revisits alternating low-rank updates for federated fine-tuning and examines their behavior in decentralized federated learning (DFL). While alternating the LoRA matrices has been shown to stabilize aggregation in centralized FL, extending this mechanism to decentralized, peer-to-peer communication introduces new challenges due to phase-state mismatch and block-wise divergence across clients. We introduce ADF-LoRA, which synchronizes the update of only one low-rank matrix per round and mixes both matrices to maintain more consistent parameter states under decentralized propagation. This design preserves the cross-term suppression effect of alternating updates while improving stability in serverless topologies. We provide a convergence analysis under standard smoothness assumptions and evaluate ADF-LoRA on multiple GLUE tasks. Experiments show that ADF-LoRA achieves faster and smoother convergence and delivers the highest average accuracy across tasks, outperforming existing LoRA variants in decentralized FL by a consistent margin.

</details>


### [357] [MultiDiffNet: A Multi-Objective Diffusion Framework for Generalizable Brain Decoding](https://arxiv.org/abs/2511.18294)
*Mengchun Zhang,Kateryna Shapovalenko,Yucheng Shao,Eddie Guo,Parusha Pradhan*

Main category: cs.LG

TL;DR: MultiDiffNet是一个基于扩散模型的框架，通过优化多目标学习的紧凑潜在空间实现跨被试脑电解码，无需生成式数据增强，在多个脑电解码任务中达到最先进的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 脑电解码面临跨被试泛化能力差的问题，主要由于被试间差异大且缺乏大规模数据集。现有方法依赖合成被试生成或简单数据增强，但无法可靠扩展或泛化。

Method: 提出MultiDiffNet框架，绕过生成式增强，直接学习优化多目标的紧凑潜在空间，并从中进行解码。同时创建统一基准套件和统计报告框架。

Result: 在四个复杂度递增的脑电解码任务（SSVEP、运动想象、P300、想象语音）中，使用被试和会话不相交评估，实现了最先进的跨被试泛化性能。

Conclusion: 该工作为现实世界BCI系统中的被试无关脑电解码提供了可复现的开源基础。

Abstract: Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems.

</details>


### [358] [DiM-TS: Bridge the Gap between Selective State Space Models and Time Series for Generative Modeling](https://arxiv.org/abs/2511.18312)
*Zihao Yao,Jiankai Zuo,Yaying Zhang*

Main category: cs.LG

TL;DR: 提出DiM-TS模型，利用Mamba状态空间模型增强时间序列生成能力，通过Lag Fusion和Permutation Scanning解决长程依赖和通道相关性问题，在公开数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据面临隐私挑战，现有扩散模型难以捕捉长程时间依赖和复杂通道相互关系，需要改进生成质量。

Method: 分析状态空间模型的核心限制，提出Lag Fusion Mamba和Permutation Scanning Mamba两种变体，增强去噪过程中的模式识别能力，最终整合为DiM-TS模型。

Result: 理论分析显示两种变体与原始Mamba具有统一的矩阵乘法框架，在公开数据集上验证了DiM-TS在生成真实时间序列和保持数据多样性方面的优越性。

Conclusion: DiM-TS是一个高质量的时间序列生成模型，能更好地保持时间周期性和通道间相关性，为时间序列数据合成提供了有效解决方案。

Abstract: Time series data plays a pivotal role in a wide variety of fields but faces challenges related to privacy concerns. Recently, synthesizing data via diffusion models is viewed as a promising solution. However, existing methods still struggle to capture long-range temporal dependencies and complex channel interrelations. In this research, we aim to utilize the sequence modeling capability of a State Space Model called Mamba to extend its applicability to time series data generation. We firstly analyze the core limitations in State Space Model, namely the lack of consideration for correlated temporal lag and channel permutation. Building upon the insight, we propose Lag Fusion Mamba and Permutation Scanning Mamba, which enhance the model's ability to discern significant patterns during the denoising process. Theoretical analysis reveals that both variants exhibit a unified matrix multiplication framework with the original Mamba, offering a deeper understanding of our method. Finally, we integrate two variants and introduce Diffusion Mamba for Time Series (DiM-TS), a high-quality time series generation model that better preserves the temporal periodicity and inter-channel correlations. Comprehensive experiments on public datasets demonstrate the superiority of DiM-TS in generating realistic time series while preserving diverse properties of data.

</details>


### [359] [AnyExperts: On-Demand Expert Allocation for Multimodal Language Models with Mixture of Expert](https://arxiv.org/abs/2511.18314)
*Yuting Gao,Wang Lan,Hengyuan Zhao,Linjiang Huang,Si Liu,Qingpei Guo*

Main category: cs.LG

TL;DR: AnyExperts是一个新颖的按需、预算感知的动态路由框架，通过基于语义重要性为每个token分配可变数量的专家槽位，优化多模态MoE模型的计算分配效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态MoE模型采用固定的路由策略（每个token激活固定数量的专家），忽略了跨模态语义重要性的异质性，导致冗余token与关键token消耗相同资源，造成计算分配次优。

Method: 提出AnyExperts框架，为每个token分配可变总数的专家槽位，但限制在固定范围内。每个槽位由真实专家或虚拟专家填充，虚拟专家比例上限为20%。模型自适应平衡每个token的真实-虚拟专家比例，为语义丰富区域分配更多真实专家，对冗余内容更多依赖虚拟专家。

Result: 在视觉理解、音频理解和NLP理解等多样化任务中，AnyExperts在相同计算预算下提升了性能。在通用图像/视频任务中，用40%更少的真实专家激活达到相当精度；在文本密集任务（OCR和NLP）中，保持性能同时减少10%真实专家使用。

Conclusion: 细粒度的、重要性驱动的专家分配显著提升了多模态MoE模型的效率和有效性。

Abstract: Multimodal Mixture-of-Experts (MoE) models offer a promising path toward scalable and efficient large vision-language systems. However, existing approaches rely on rigid routing strategies (typically activating a fixed number of experts per token) ignoring the inherent heterogeneity in semantic importance across modalities. This leads to suboptimal compute allocation, where redundant tokens consume as many resources as critical ones. To address this, we propose AnyExperts, a novel on-demand, budget-aware dynamic routing framework that allocates a variable total number of expert slots per token based on its semantic importance. Crucially, to prevent uncontrolled compute growth, the total slots per token are constrained within a fixed range, and each slot is filled by either a real expert or a virtual expert, with the virtual share capped at a small maximum (e.g., 20%). The model then adaptively balances the real-to-virtual ratio per token, assigning more real experts to semantically rich regions and relying more on virtual experts for redundant content. Evaluated across diverse tasks in visual understanding, audio understanding, and NLP understanding, AnyExperts improves performance under the same compute budget. Notably, on general image/video tasks, it achieves comparable accuracy with 40% fewer real expert activations; on text-dense tasks (OCR and NLP), it maintains performance while reducing real expert usage by 10%. These results demonstrate that fine-grained, importance-driven expert allocation significantly enhances both the efficiency and effectiveness of multimodal MoE models.

</details>


### [360] [DynamiX: Dynamic Resource eXploration for Personalized Ad-Recommendations](https://arxiv.org/abs/2511.18331)
*Sohini Roychowdhury,Adam Holeman,Mohammad Amin,Feng Wei,Bhaskar Mehta,Srihari Reddy*

Main category: cs.LG

TL;DR: Dynamix是一个可扩展的个性化序列探索框架，通过最大相关性原则和基于事件特征的自监督学习来优化在线广告推荐系统中的用户历史事件处理。


<details>
  <summary>Details</summary>
Motivation: 在线广告推荐系统处理完整的用户广告互动历史既计算密集又容易受到噪声干扰，需要更高效的序列处理方法。

Method: 使用最大相关性原则和基于事件特征的自监督学习，在会话和表面级别对用户互动进行分类，通过动态特征移除和选择性特征增强来优化处理。

Result: 动态资源移除使训练和推理吞吐量分别提升1.15%和1.8%，动态特征增强在基线模型基础上提供0.033 NE增益，同时推理QPS提升4.2%。

Conclusion: Dynamix在基于在线用户序列的推荐模型中实现了显著的成本效率和性能改进，自监督用户分割和资源探索可以进一步优化复杂特征选择策略。

Abstract: For online ad-recommendation systems, processing complete user-ad-engagement histories is both computationally intensive and noise-prone. We introduce Dynamix, a scalable, personalized sequence exploration framework that optimizes event history processing using maximum relevance principles and self-supervised learning through Event Based Features (EBFs). Dynamix categorizes users-engagements at session and surface-levels by leveraging correlations between dwell-times and ad-conversion events. This enables targeted, event-level feature removal and selective feature boosting for certain user-segments, thereby yielding training and inference efficiency wins without sacrificing engaging ad-prediction accuracy. While, dynamic resource removal increases training and inference throughput by 1.15% and 1.8%, respectively, dynamic feature boosting provides 0.033 NE gains while boosting inference QPS by 4.2% over baseline models. These results demonstrate that Dynamix achieves significant cost efficiency and performance improvements in online user-sequence based recommendation models. Self-supervised user-segmentation and resource exploration can further boost complex feature selection strategies while optimizing for workflow and compute resources.

</details>


### [361] [Clinician-in-the-Loop Smart Home System to Detect Urinary Tract Infection Flare-Ups via Uncertainty-Aware Decision Support](https://arxiv.org/abs/2511.18334)
*Chibuike E. Ugwu,Roschelle Fritz,Diane J. Cook,Janardhan Rao Doppa*

Main category: cs.LG

TL;DR: 本文提出了一种基于智能家居传感器的临床医生在环系统，通过不确定性感知的机器学习模型来早期检测老年人尿路感染发作，使用CCI方法量化不确定性并在置信度低时弃权预测。


<details>
  <summary>Details</summary>
Motivation: 老年人尿路感染发作风险高但常被忽视，传统二元分类方法缺乏不确定性信息，限制了临床决策支持。需要开发能够量化预测不确定性的智能系统来改善临床决策。

Method: 开发临床医生在环智能家居系统，利用环境传感器数据提取行为标记，训练稳健的预测模型，并采用CCI方法进行不确定性校准，在模型置信度低时弃权预测。

Result: 在8个真实智能家居数据上的评估显示，该方法在召回率等分类指标上优于基线方法，同时保持最低的弃权比例和区间宽度。42名护士的调查确认了系统的临床实用性。

Conclusion: 该系统通过不确定性感知的决策支持，能够有效改善老年人尿路感染和其他病症发作的管理，具有重要的临床应用价值。

Abstract: Urinary tract infection (UTI) flare-ups pose a significant health risk for older adults with chronic conditions. These infections often go unnoticed until they become severe, making early detection through innovative smart home technologies crucial. Traditional machine learning (ML) approaches relying on simple binary classification for UTI detection offer limited utility to nurses and practitioners as they lack insight into prediction uncertainty, hindering informed clinical decision-making. This paper presents a clinician-in-the-loop (CIL) smart home system that leverages ambient sensor data to extract meaningful behavioral markers, train robust predictive ML models, and calibrate them to enable uncertainty-aware decision support. The system incorporates a statistically valid uncertainty quantification method called Conformal-Calibrated Interval (CCI), which quantifies uncertainty and abstains from making predictions ("I don't know") when the ML model's confidence is low. Evaluated on real-world data from eight smart homes, our method outperforms baseline methods in recall and other classification metrics while maintaining the lowest abstention proportion and interval width. A survey of 42 nurses confirms that our system's outputs are valuable for guiding clinical decision-making, underscoring their practical utility in improving informed decisions and effectively managing UTIs and other condition flare-ups in older adults.

</details>


### [362] [Auxiliary Gene Learning: Spatial Gene Expression Estimation by Auxiliary Gene Selection](https://arxiv.org/abs/2511.18336)
*Kaito Shiku,Kazuya Nishimura,Shinnosuke Matsuo,Yasuhiro Kojima,Ryoma Bise*

Main category: cs.LG

TL;DR: 本文提出AGL方法，通过将忽略的基因表达估计重新定义为辅助任务并与主要任务联合训练，利用被忽视基因的益处。为了解决从大量基因中选择有益辅助基因的挑战，提出了基于先验知识的可微分Top-k基因选择方法DkGSB。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学技术存在严重观测噪声，以往研究仅使用高变异基因子集进行训练和评估，忽略了可能对目标基因预测有贡献的低表达基因。由于基因间存在共表达关系，这些被忽略的基因仍可能有助于评估目标的估计。

Method: 提出辅助基因学习(AGL)框架，将忽略基因的表达估计作为辅助任务与主要任务联合训练。为解决基因选择挑战，提出基于先验知识的可微分Top-k基因选择方法(DkGSB)，通过双层优化将组合选择问题松弛为可微分选择问题。

Result: 实验证实了整合辅助基因的有效性，所提方法在性能上优于传统的辅助任务学习方法。

Conclusion: 通过AGL框架和DkGSB选择方法，能够有效利用被忽视基因的信息，提升空间转录组学中基因表达预测的准确性。

Abstract: Spatial transcriptomics (ST) is a novel technology that enables the observation of gene expression at the resolution of individual spots within pathological tissues. ST quantifies the expression of tens of thousands of genes in a tissue section; however, heavy observational noise is often introduced during measurement. In prior studies, to ensure meaningful assessment, both training and evaluation have been restricted to only a small subset of highly variable genes, and genes outside this subset have also been excluded from the training process. However, since there are likely co-expression relationships between genes, low-expression genes may still contribute to the estimation of the evaluation target. In this paper, we propose $Auxiliary \ Gene \ Learning$ (AGL) that utilizes the benefit of the ignored genes by reformulating their expression estimation as auxiliary tasks and training them jointly with the primary tasks. To effectively leverage auxiliary genes, we must select a subset of auxiliary genes that positively influence the prediction of the target genes. However, this is a challenging optimization problem due to the vast number of possible combinations. To overcome this challenge, we propose Prior-Knowledge-Based Differentiable Top-$k$ Gene Selection via Bi-level Optimization (DkGSB), a method that ranks genes by leveraging prior knowledge and relaxes the combinatorial selection problem into a differentiable top-$k$ selection problem. The experiments confirm the effectiveness of incorporating auxiliary genes and show that the proposed method outperforms conventional auxiliary task learning approaches.

</details>


### [363] [Future Is Unevenly Distributed: Forecasting Ability of LLMs Depends on What We're Asking](https://arxiv.org/abs/2511.18394)
*Chinmay Karkar,Paras Chopra*

Main category: cs.LG

TL;DR: 本文研究了大型语言模型在不同领域和提示框架下的预测能力变化，分析了模型家族、上下文、问题类型和外部知识对预测准确性和校准的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在社会、政治和经济事件预测方面展现出部分能力，但其预测性能在不同领域结构和提示框架下差异显著，需要系统研究其预测能力的边界和影响因素。

Method: 通过分析不同模型家族对超出模型截止日期的真实世界问题的预测表现，研究上下文、问题类型和外部知识如何影响预测准确性和校准，并探讨添加事实新闻上下文如何改变信念形成和失败模式。

Result: 研究结果显示预测能力高度可变，取决于提问的内容和方式，不同模型在不同情境下的表现差异明显。

Conclusion: LLMs的预测能力不是固定不变的，而是高度依赖于具体的提问领域、问题类型和上下文框架，需要谨慎评估其在不同应用场景中的可靠性。

Abstract: Large Language Models (LLMs) demonstrate partial forecasting competence across social, political, and economic events. Yet, their predictive ability varies sharply with domain structure and prompt framing. We investigate how forecasting performance varies with different model families on real-world questions about events that happened beyond the model cutoff date. We analyze how context, question type, and external knowledge affect accuracy and calibration, and how adding factual news context modifies belief formation and failure modes. Our results show that forecasting ability is highly variable as it depends on what, and how, we ask.

</details>


### [364] [SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation](https://arxiv.org/abs/2511.18468)
*Md Akil Raihan Iftee,Mir Sazzat Hossain,Rakibul Hasan Rajib,Tariq Iqbal,Md Mofijul Islam,M Ashraful Amin,Amin Ahsan Ali,AKM Mahbubur Rahman*

Main category: cs.LG

TL;DR: 提出SloMo-Fast框架，一种无需源数据的双教师持续测试时适应方法，解决长期遗忘问题，在循环域变化场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法依赖源数据或原型，在隐私敏感和资源受限环境中适用性有限，且存在长期遗忘问题，导致在先前遇到域上的性能下降。

Method: SloMo-Fast包含两个互补教师：慢教师（Slow-Teacher）缓慢遗忘并保留长期知识确保泛化能力，快教师（Fast-Teacher）快速适应新域并跨域积累知识。同时提出循环测试时适应（Cyclic-TTA）基准测试。

Result: 在Cyclic-TTA及其他十个CTTA设置中的广泛实验表明，SloMo-Fast始终优于最先进方法，展现出在演化和重访域上的适应和泛化能力。

Conclusion: SloMo-Fast框架有效解决了CTTA中的长期遗忘问题，在无需源数据的情况下实现了对演化和循环域变化的稳健适应与泛化。

Abstract: Continual Test-Time Adaptation (CTTA) is crucial for deploying models in real-world applications with unseen, evolving target domains. Existing CTTA methods, however, often rely on source data or prototypes, limiting their applicability in privacy-sensitive and resource-constrained settings. Additionally, these methods suffer from long-term forgetting, which degrades performance on previously encountered domains as target domains shift. To address these challenges, we propose SloMo-Fast, a source-free, dual-teacher CTTA framework designed for enhanced adaptability and generalization. It includes two complementary teachers: the Slow-Teacher, which exhibits slow forgetting and retains long-term knowledge of previously encountered domains to ensure robust generalization, and the Fast-Teacher rapidly adapts to new domains while accumulating and integrating knowledge across them. This framework preserves knowledge of past domains and adapts efficiently to new ones. We also introduce Cyclic Test-Time Adaptation (Cyclic-TTA), a novel CTTA benchmark that simulates recurring domain shifts. Our extensive experiments demonstrate that SloMo-Fast consistently outperforms state-of-the-art methods across Cyclic-TTA, as well as ten other CTTA settings, highlighting its ability to both adapt and generalize across evolving and revisited domains.

</details>


### [365] [CHIPS: Efficient CLIP Adaptation via Curvature-aware Hybrid Influence-based Data Selection](https://arxiv.org/abs/2511.18519)
*Xinlin Zhuang,Yichen Li,Xiwei Liu,Haolin Yang,Yifan Lu,Ziyun Zou,Yulong Li,Huifa Li,Dongliang Chen,Qinglei Wang,Weiyang Liu,Ying Qian,Jiangming Shi,Imran Razzak*

Main category: cs.LG

TL;DR: CHIPS是一种数据选择方法，通过计算图像-文本对的效用分数来选择高质量数据，在垂直领域适应中仅需30%数据即可达到全数据集持续预训练的性能，在医学领域17个基准测试中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前垂直领域CLIP适应主要依赖大规模领域特定数据集进行微调或持续预训练，但数据本身作为关键因素未被充分探索。研究旨在探索是否通过有效数据选择可以替代大规模数据集。

Method: 提出CHIPS方法，为每个图像-文本对分配效用分数，整合三个互补因素：通过曲率感知的牛顿式对齐确保忠实性；通过InfoNCE感知的曲率估计器和JL草图实现可扩展性；通过选择感知的相关性权重和可学习性平衡目标适应与通用领域保留。

Result: 在17个医学基准测试中，CHIPS在数据选择基线中达到最先进性能，仅用30%数据即可匹配全数据集持续预训练，仅用10%数据优于半数据集持续预训练；在31个通用领域基准测试中，在10-30%数据保留预算下性能下降最小。

Conclusion: CHIPS证明了通过精心设计的数据选择策略可以有效替代大规模数据集进行垂直领域适应，为数据高效的CLIP适应提供了新思路。

Abstract: Adapting CLIP to vertical domains is typically approached by novel fine-tuning strategies or by continual pre-training (CPT) on large domain-specific datasets. Yet, data itself remains an underexplored factor in this process. We revisit this task from a data-centric perspective: Can effective data selection substitute for large-scale datasets in CPT? We introduce CHIPS (Curvature-aware Hybrid Influence in Projection Subspace), which assigns each image-text pair a utility score that integrates three complementary factors aligned with three goals: faithfulness via a curvature-aware, Newton-style alignment computed in CLIP's end-point subspace; scalability via an InfoNCE-aware curvature estimator with Johnson-Lindenstrauss (JL) sketching; and retention via a selection-aware relevance weight combined with learnability to balance target adaptation against general-domain preservation. We justify this design theoretically by proving a lower-bound guarantee on the proxy's correlation with full-parameter alignment and by characterizing the bias-variance trade-offs introduced by curvature mixing and JL sketching. We evaluate CHIPS empirically across various settings: 1) CHIPS attains state-of-the-art performance among selection baselines on 17 medical benchmarks, matches full-dataset CPT with 30% of the data, and outperforms half-dataset CPT using only 10%; 2) on 31 general-domain benchmarks, CHIPS yields the smallest performance drop under 10-30% data-retention budgets. Code, data, and checkpoints will be released.

</details>


### [366] [Hyperspectral Variational Autoencoders for Joint Data Compression and Component Extraction](https://arxiv.org/abs/2511.18521)
*Core Francisco Park,Manuel Perez-Carrasco,Caroline Nowlan,Cecilia Garraffo*

Main category: cs.LG

TL;DR: 提出一种变分自编码器方法，对NASA TEMPO卫星高光谱观测数据实现514倍压缩，重建误差比信号低1-2个数量级，同时保留关键大气信息。


<details>
  <summary>Details</summary>
Motivation: 解决地球静止轨道高光谱卫星每天产生的TB级数据在存储、传输和分发方面的挑战，为下一代地球观测系统解决关键瓶颈。

Method: 使用变分自编码器(VAE)进行数据压缩，并通过线性和非线性探针从压缩的潜在空间中提取Level-2产品(NO2、O3、HCHO、云分数)来评估大气信息保留程度。

Result: 实现514倍压缩，重建误差比信号低1-2个数量级；云分数和总臭氧提取性能强(R²=0.93和0.81)，但对流层痕量气体提取困难(NO2 R²=0.20, HCHO R²=0.51)；发现VAE以半线性方式编码大气信息，非线性探针明显优于线性探针。

Conclusion: 神经压缩能显著减少高光谱数据量同时保留关键大气信号，为下一代地球观测系统解决了关键瓶颈问题，但某些产品的编码仍存在根本性挑战。

Abstract: Geostationary hyperspectral satellites generate terabytes of data daily, creating critical challenges for storage, transmission, and distribution to the scientific community. We present a variational autoencoder (VAE) approach that achieves x514 compression of NASA's TEMPO satellite hyperspectral observations (1028 channels, 290-490nm) with reconstruction errors 1-2 orders of magnitude below the signal across all wavelengths. This dramatic data volume reduction enables efficient archival and sharing of satellite observations while preserving spectral fidelity. Beyond compression, we investigate to what extent atmospheric information is retained in the compressed latent space by training linear and nonlinear probes to extract Level-2 products (NO2, O3, HCHO, cloud fraction). Cloud fraction and total ozone achieve strong extraction performance (R^2 = 0.93 and 0.81 respectively), though these represent relatively straightforward retrievals given their distinct spectral signatures. In contrast, tropospheric trace gases pose genuine challenges for extraction (NO2 R^2 = 0.20, HCHO R^2 = 0.51) reflecting their weaker signals and complex atmospheric interactions. Critically, we find the VAE encodes atmospheric information in a semi-linear manner - nonlinear probes substantially outperform linear ones - and that explicit latent supervision during training provides minimal improvement, revealing fundamental encoding challenges for certain products. This work demonstrates that neural compression can dramatically reduce hyperspectral data volumes while preserving key atmospheric signals, addressing a critical bottleneck for next-generation Earth observation systems. Code - https://github.com/cfpark00/Hyperspectral-VAE

</details>


### [367] [In Search of Goodness: Large Scale Benchmarking of Goodness Functions for the Forward-Forward Algorithm](https://arxiv.org/abs/2511.18567)
*Arya Shah,Vaibhav Tripathi*

Main category: cs.LG

TL;DR: 本文系统评估了21种不同的'goodness'函数在Forward-Forward算法中的表现，发现在多个图像数据集上，某些替代函数显著优于标准平方和基准，同时揭示了预测性能与计算效率之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: Forward-Forward算法的有效性依赖于'goodness'函数的定义，但目前主要使用简单的平方和度量，不清楚这是否是最优选择。

Method: 在四个标准图像数据集（MNIST、FashionMNIST、CIFAR-10、STL-10）上对21种不同的goodness函数进行基准测试，评估分类准确率、能耗和碳足迹。

Result: 发现某些替代goodness函数显著优于标准基准：game_theoretic_local在MNIST上达到97.15%准确率，softmax_energy_margin_local在FashionMNIST上达到82.84%，triplet_margin_local在STL-10上达到37.69%。计算效率存在显著差异。

Conclusion: goodness函数是FF算法设计中的关键超参数，需要在预测性能和环境影响之间进行权衡。代码已在GitHub上发布以供参考和复现。

Abstract: The Forward-Forward (FF) algorithm offers a biologically plausible alternative to backpropagation, enabling neural networks to learn through local updates. However, FF's efficacy relies heavily on the definition of "goodness", which is a scalar measure of neural activity. While current implementations predominantly utilize a simple sum-of-squares metric, it remains unclear if this default choice is optimal. To address this, we benchmarked 21 distinct goodness functions across four standard image datasets (MNIST, FashionMNIST, CIFAR-10, STL-10), evaluating classification accuracy, energy consumption, and carbon footprint. We found that certain alternative goodness functions inspired from various domains significantly outperform the standard baseline. Specifically, \texttt{game\_theoretic\_local} achieved 97.15\% accuracy on MNIST, \texttt{softmax\_energy\_margin\_local} reached 82.84\% on FashionMNIST, and \texttt{triplet\_margin\_local} attained 37.69\% on STL-10. Furthermore, we observed substantial variability in computational efficiency, highlighting a critical trade-off between predictive performance and environmental cost. These findings demonstrate that the goodness function is a pivotal hyperparameter in FF design. We release our code on \href{https://github.com/aryashah2k/In-Search-of-Goodness}{Github} for reference and reproducibility.

</details>


### [368] [SAMBA: Toward a Long-Context EEG Foundation Model via Spatial Embedding and Differential Mamba](https://arxiv.org/abs/2511.18571)
*Jiazhen Hong,Geoffrey Mackellar,Soheila Ghane*

Main category: cs.LG

TL;DR: SAMBA是一个基于Mamba的U形编码器-解码器架构的自监督学习框架，专门用于处理长序列脑电图数据。它通过时间语义随机掩码、多头差分Mamba模块和空间自适应输入嵌入技术，有效捕捉长程时间依赖性和空间变异性，在13个EEG数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 长序列EEG建模对开发泛化性强的EEG表示模型至关重要，但由于EEG数据的高采样率和长记录时间需求，传统Transformer的二次复杂度限制了其在长上下文中的可扩展性。此外，不同数据集中的电极配置差异和个体间脑信号差异也给开发通用基础模型带来挑战。

Method: 提出SAMBA框架，采用Mamba-based U形编码器-解码器架构，包含三个关键技术：(1)时间语义随机掩码进行语义级序列重建；(2)多头差分Mamba模块抑制冗余并突出显著时间结构；(3)空间自适应输入嵌入在三维欧几里得空间中学习统一嵌入，实现跨设备鲁棒性。

Result: 在13个EEG数据集上的实验表明，SAMBA在多种任务、电极配置和序列持续时间下均优于最先进方法，同时保持低内存消耗和推理时间。学习到的空间权重图与任务相关神经生理区域高度一致，证明了模型的可学习性和可解释性。

Conclusion: SAMBA展示了作为实时脑机接口应用基础模型的可扩展性和实际潜力，能够有效处理长序列EEG数据并实现跨设备和跨任务的泛化。

Abstract: Long-sequence electroencephalogram (EEG) modeling is essential for developing generalizable EEG representation models. This need arises from the high sampling rate of EEG data and the long recording durations required to capture extended neurological patterns in brain activity. Transformer-based models have shown promise in modeling short sequences of a few seconds; however, their quadratic complexity limits scalability to longer contexts. Moreover, variability in electrode montage across available datasets, along with inter-subject differences in brain signals, pose significant challenges to developing a generalizable and robust foundation model. We propose \textit{SAMBA}, a self-supervised learning framework with a Mamba-based U-shaped encoder-decoder architecture, which effectively captures long-range temporal dependencies and spatial variability in EEG data. Leveraging the inherent ability of Mamba in processing long context sizes, we introduce: (1) \textit{Temporal Semantic Random Masking} for semantic-level sequence reconstruction, (2) a \textit{Multi-Head Differential Mamba} module to suppress redundancy and emphasize salient temporal structures, and (3) a \textit{Spatial-Adaptive Input Embedding} that learns unified embeddings in a three-dimensional Euclidean space, enabling robustness across devices. Experiments on thirteen EEG datasets across diverse tasks, electrode configurations, and sequence durations demonstrate that SAMBA consistently outperforms state-of-the-art methods while maintaining low memory consumption and inference time. We also show the learned spatial weight maps from our embedding module align closely with task-relevant neurophysiological regions, demonstrating the learnability and interpretability of SAMBA. These results highlight SAMBA's scalability and practical potential as a foundation model for real-time brain-computer interface applications.

</details>


### [369] [Generative Myopia: Why Diffusion Models Fail at Structure](https://arxiv.org/abs/2511.18593)
*Milad Siami*

Main category: cs.LG

TL;DR: 本文揭示了图扩散模型(GDMs)在优化统计似然时存在"生成性近视"问题，即偏好频繁子结构而忽略光谱关键结构，导致在组合任务中灾难性地移除"稀有桥梁"边。作者提出光谱加权扩散方法，使用有效电阻重新对齐变分目标，消除近视问题。


<details>
  <summary>Details</summary>
Motivation: 图扩散模型在优化统计似然时隐式地作为频率过滤器，倾向于丰富的子结构而忽略光谱关键结构，这种现象被称为"生成性近视"。在组合任务如图稀疏化中，这会导致灾难性地移除结构必需但统计稀少的"稀有桥梁"边。

Method: 提出光谱加权扩散方法，使用有效电阻重新对齐变分目标，将光谱先验摊销到训练阶段，实现零推理开销。

Result: 该方法消除了近视问题，在对抗性基准测试中实现了100%的连接性，而标准扩散方法完全失败(0%)，性能与最优光谱预言机相匹配。

Conclusion: 光谱先验可以在训练阶段摊销而不增加推理开销，有效解决图扩散模型中的生成性近视问题，确保在组合任务中保持关键结构完整性。

Abstract: Graph Diffusion Models (GDMs) optimize for statistical likelihood, implicitly acting as \textbf{frequency filters} that favor abundant substructures over spectrally critical ones. We term this phenomenon \textbf{Generative Myopia}. In combinatorial tasks like graph sparsification, this leads to the catastrophic removal of ``rare bridges,'' edges that are structurally mandatory ($R_{\text{eff}} \approx 1$) but statistically scarce. We prove theoretically and empirically that this failure is driven by \textbf{Gradient Starvation}: the optimization landscape itself suppresses rare structural signals, rendering them unlearnable regardless of model capacity. To resolve this, we introduce \textbf{Spectrally-Weighted Diffusion}, which re-aligns the variational objective using Effective Resistance. We demonstrate that spectral priors can be amortized into the training phase with zero inference overhead. Our method eliminates myopia, matching the performance of an optimal Spectral Oracle and achieving \textbf{100\% connectivity} on adversarial benchmarks where standard diffusion fails completely (0\%).

</details>


### [370] [CycleSL: Server-Client Cyclical Update Driven Scalable Split Learning](https://arxiv.org/abs/2511.18611)
*Mengdi Wang,Efe Bozkir,Enkelejda Kasneci*

Main category: cs.LG

TL;DR: CycleSL是一个新颖的无聚合分割学习框架，通过将服务器端训练视为独立的机器学习任务，采用循环更新策略来提升可扩展性和模型性能，解决了传统分割学习中的服务器资源开销大、客户端漂移和性能下降等问题。


<details>
  <summary>Details</summary>
Motivation: 传统分割学习存在可扩展性差、服务器资源开销大、模型性能下降和收敛问题，特别是并行变体中的模型复制聚合和客户端漂移问题。

Method: 受交替块坐标下降启发，CycleSL将服务器端训练作为独立的高级机器学习任务，重新采样客户端提取的特征来缓解异构性和漂移，采用循环更新策略：先优化服务器模型，然后使用更新后的服务器进行客户端梯度计算和更新。

Result: 在五个公开数据集上的实验表明，CycleSL能有效提升模型性能，特别是在非独立同分布数据和部分客户端参与的场景下。

Conclusion: CycleSL是一个有效的无聚合分割学习框架，能显著提升可扩展性和性能，并能与现有方法无缝集成。

Abstract: Split learning emerges as a promising paradigm for collaborative distributed model training, akin to federated learning, by partitioning neural networks between clients and a server without raw data exchange. However, sequential split learning suffers from poor scalability, while parallel variants like parallel split learning and split federated learning often incur high server resource overhead due to model duplication and aggregation, and generally exhibit reduced model performance and convergence owing to factors like client drift and lag. To address these limitations, we introduce CycleSL, a novel aggregation-free split learning framework that enhances scalability and performance and can be seamlessly integrated with existing methods. Inspired by alternating block coordinate descent, CycleSL treats server-side training as an independent higher-level machine learning task, resampling client-extracted features (smashed data) to mitigate heterogeneity and drift. It then performs cyclical updates, namely optimizing the server model first, followed by client updates using the updated server for gradient computation. We integrate CycleSL into previous algorithms and benchmark them on five publicly available datasets with non-iid data distribution and partial client attendance. Our empirical findings highlight the effectiveness of CycleSL in enhancing model performance. Our source code is available at https://gitlab.lrz.de/hctl/CycleSL.

</details>


### [371] [Bayesian-based Online Label Shift Estimation with Dynamic Dirichlet Priors](https://arxiv.org/abs/2511.18615)
*Jiawei Hu,Javier A. Barria*

Main category: cs.LG

TL;DR: 提出FMAPLS和online-FMAPLS贝叶斯框架，通过联合优化Dirichlet超参数和类先验来解决标签偏移问题，在CIFAR100和ImageNet上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标签偏移是监督学习中的常见挑战，当测试数据的类先验分布与训练数据不同时，会导致分类器性能显著下降。现有MAPLS方法存在刚性约束限制，需要更灵活有效的解决方案。

Method: 使用批处理和在线EM算法，联合动态优化Dirichlet超参数α和类先验π；引入线性替代函数(LSF)替代基于梯度的超参数更新，获得闭式解；在线版本用随机近似替代批处理E-step。

Result: 在CIFAR100和ImageNet数据集上，FMAPLS和online-FMAPLS分别实现高达40%和12%更低的KL散度，并在后偏移准确率上显著优于最先进基线方法，特别是在严重类别不平衡和分布不确定性情况下。

Conclusion: 所提方法在大规模和动态学习场景中具有鲁棒性、可扩展性和适用性，理论分析揭示了在线收敛速度和估计精度之间的基本权衡关系。

Abstract: Label shift, a prevalent challenge in supervised learning, arises when the class prior distribution of test data differs from that of training data, leading to significant degradation in classifier performance. To accurately estimate the test priors and enhance classification accuracy, we propose a Bayesian framework for label shift estimation, termed Full Maximum A Posterior Label Shift (FMAPLS), along with its online version, online-FMAPLS. Leveraging batch and online Expectation-Maximization (EM) algorithms, these methods jointly and dynamically optimize Dirichlet hyperparameters $\boldsymbolα$ and class priors $\boldsymbolπ$, thereby overcoming the rigid constraints of the existing Maximum A Posterior Label Shift (MAPLS) approach. Moreover, we introduce a linear surrogate function (LSF) to replace gradient-based hyperparameter updates, yielding closed-form solutions that reduce computational complexity while retaining asymptotic equivalence. The online variant substitutes the batch E-step with a stochastic approximation, enabling real-time adaptation to streaming data. Furthermore, our theoretical analysis reveals a fundamental trade-off between online convergence rate and estimation accuracy. Extensive experiments on CIFAR100 and ImageNet datasets under shuffled long-tail and Dirichlet test priors demonstrate that FMAPLS and online-FMAPLS respectively achieve up to 40% and 12% lower KL divergence and substantial improvements in post-shift accuracy over state-of-the-art baselines, particularly under severe class imbalance and distributional uncertainty. These results confirm the robustness, scalability, and suitability of the proposed methods for large-scale and dynamic learning scenarios.

</details>


### [372] [Majority of the Bests: Improving Best-of-N via Bootstrapping](https://arxiv.org/abs/2511.18630)
*Amin Rakhsha,Kanika Madan,Tianyu Zhang,Amir-massoud Farahmand,Amir Khasahmadi*

Main category: cs.LG

TL;DR: 本文提出了一种新的选择机制MoB，通过自助采样估计BoN的输出分布并选择其众数，在奖励模型不完美的情况下比传统的BoN方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 传统的BoN方法在奖励模型不完美时性能会急剧下降，无法可靠找到正确答案。作者观察到虽然正确答案在BoN输出分布中的概率不高，但通常是众数，因此众数可能比单次采样更可靠。

Method: 提出MoB方法：通过自助采样估计BoN的输出分布，然后选择该分布的众数作为最终输出。

Result: 在5个基准测试、3种基础LLM和2种奖励模型的30个设置中，MoB在25个设置中表现优于BoN。

Conclusion: MoB是BoN和自一致性方法的简单而强大的替代方案，激励了对更细致选择机制的进一步研究。

Abstract: Sampling multiple outputs from a Large Language Model (LLM) and selecting the most frequent (Self-consistency) or highest-scoring (Best-of-N) candidate is a popular approach to achieve higher accuracy in tasks with discrete final answers. Best-of-N (BoN) selects the output with the highest reward, and with perfect rewards, it often achieves near-perfect accuracy. With imperfect rewards from reward models, however, BoN fails to reliably find the correct answer and its performance degrades drastically. We consider the distribution of BoN's outputs and highlight that, although the correct answer does not usually have a probability close to one under imperfect rewards, it is often the most likely outcome. This suggests that the mode of this distribution can be more reliably correct than a sample from it. Based on this idea, we propose Majority-of-the-Bests (MoB), a novel selection mechanism that estimates the output distribution of BoN via bootstrapping and selects its mode. Experimental results across five benchmarks, three different base LLMs, and two reward models demonstrate consistent improvements over BoN in 25 out of 30 setups. We also provide theoretical results for the consistency of the bootstrapping. MoB serves as a simple, yet strong alternative to BoN and self-consistency, and more broadly, motivates further research in more nuanced selection mechanisms.

</details>


### [373] [FOS: A Large-Scale Temporal Graph Benchmark for Scientific Interdisciplinary Link Prediction](https://arxiv.org/abs/2511.18631)
*Kiyan Rezaee,Morteza Ziabakhsh,Niloofar Nikfarjam,Mohammad M. Ghassemi,Yazdan Rezaee Jouryabi,Sadegh Eskandari,Reza Lashgari*

Main category: cs.LG

TL;DR: FOS是一个时间感知的图基准，用于预测科学前沿领域的形成，通过分析1827-2024年间65,027个研究子领域的共现关系来预测新的跨学科连接。


<details>
  <summary>Details</summary>
Motivation: 跨学科科学突破通常意外出现，预测新研究领域的形成仍是一个重大挑战。需要建立一个全面的基准来推进科学前沿预测研究。

Method: 构建年度共现图，节点为研究子领域，边表示两个领域在同一出版物中的共现关系。使用语义嵌入丰富节点，边包含时间和拓扑描述符，将新领域对连接预测建模为时间链接预测任务。

Result: 实验表明：(i)使用领域的长文本描述嵌入显著提高预测准确性；(ii)不同模型类别在不同评估设置下表现优异；(iii)案例分析显示FOS的顶级链接预测与后续年份出现的学术出版物中的领域配对一致。

Conclusion: FOS基准为预测科学前沿提供了可复现的基础，展示了语义信息和时间图结构在预测跨学科研究形成中的重要性。

Abstract: Interdisciplinary scientific breakthroughs mostly emerge unexpectedly, and forecasting the formation of novel research fields remains a major challenge. We introduce FOS (Future Of Science), a comprehensive time-aware graph-based benchmark that reconstructs annual co-occurrence graphs of 65,027 research sub-fields (spanning 19 general domains) over the period 1827-2024. In these graphs, edges denote the co-occurrence of two fields in a single publication and are timestamped with the corresponding publication year. Nodes are enriched with semantic embeddings, and edges are characterized by temporal and topological descriptors. We formulate the prediction of new field-pair linkages as a temporal link-prediction task, emphasizing the "first-time" connections that signify pioneering interdisciplinary directions. Through extensive experiments, we evaluate a suite of state-of-the-art temporal graph architectures under multiple negative-sampling regimes and show that (i) embedding long-form textual descriptions of fields significantly boosts prediction accuracy, and (ii) distinct model classes excel under different evaluation settings. Case analyses show that top-ranked link predictions on FOS align with field pairings that emerge in subsequent years of academic publications. We publicly release FOS, along with its temporal data splits and evaluation code, to establish a reproducible benchmark for advancing research in predicting scientific frontiers.

</details>


### [374] [Kitty: Accurate and Efficient 2-bit KV Cache Quantization with Dynamic Channel-wise Precision Boost](https://arxiv.org/abs/2511.18643)
*Haojun Xia,Xiaoxia Wu,Jisen Li,Robert Wu,Junxiong Wang,Jue Wang,Chenxi Li,Aman Singhal,Alay Dilipbhai Shah,Alpay Ariyak,Donglin Zhuang,Zhongzhu Zhou,Ben Athiwaratkun,Zhen Zheng,Shuaiwen Leon Song*

Main category: cs.LG

TL;DR: Kitty通过算法-系统协同设计实现混合精度KV缓存，在保持接近零精度损失的同时，将KV内存减少近8倍，实现更大批次和更高吞吐量。


<details>
  <summary>Details</summary>
Motivation: KV缓存是LLM推理的主要内存瓶颈，4位KV量化能保持精度，但2位量化在长上下文推理中会降低精度，需要解决这一差距。

Method: 采用动态通道精度提升算法，按敏感度对Key缓存通道排序，仅保留小部分高精度通道；系统层面设计页面中心KV布局、Triton兼容的页面反量化内核和轻量级运行时流水线。

Result: 在七个任务和两个模型系列上，Kitty将KV内存减少近8倍，精度损失可忽略，在相同内存预算下实现高达8倍更大批次和2.1-4.1倍更高吞吐量。

Conclusion: Kitty通过算法-系统协同设计成功解决了2位KV量化的精度损失问题，为LLM推理提供了高效的内存优化解决方案。

Abstract: The KV cache is a dominant memory bottleneck for LLM inference. While 4-bit KV quantization preserves accuracy, 2-bit often degrades it, especially on long-context reasoning. We close this gap via an algorithm-system co-design for mixed-precision KV caching: Kitty. On the algorithm side, extensive experiments show that Dynamic Channel-wise Precision Boost -- which ranks Key-cache channels by sensitivity and keeps only a small fraction at higher precision -- maintains near-zero loss in accuracy drop while approaching 2-bit memory. The main challenge is handling dynamic 4-bit channel boosts while keeping the page layout coalesced and the dequantization uniform, with no scattered reads or hard-coded masks. Kitty addresses these issues by decompose each mixed-precision Key page into two tensors with unified 2-bit precision. Based on this, Kitty provides a page-centric KV layout, Triton-compatible page dequantization kernels, and a lightweight runtime pipeline that preserves coalescing and avoids divergence. Across seven tasks and two model families (Qwen3, LLaMA3), Kitty cuts KV memory by nearly 8x with negligible accuracy loss, enabling up to 8x larger batches and 2.1x-4.1x higher throughput under the same memory budget. We release the full implementation of Kitty at https://github.com/Summer-Summer/Kitty.

</details>


### [375] [Multi-Agent Cross-Entropy Method with Monotonic Nonlinear Critic Decomposition](https://arxiv.org/abs/2511.18671)
*Yan Wang,Ke Deng,Yongli Ren*

Main category: cs.LG

TL;DR: 提出了多智能体交叉熵方法(MCEM)结合单调非线性评论家分解(NCD)，通过增加高价值联合动作的概率来排除次优行为，解决了集中训练与分散执行中的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体强化学习中集中训练与分散执行(CTDE)的集中-分散不匹配(CDM)问题，即一个智能体的次优行为会降低其他智能体的学习效果。

Method: 使用多智能体交叉熵方法(MCEM)更新策略，增加高价值联合动作的概率；结合单调非线性评论家分解(NCD)；为提升样本效率，采用改进的k步回报和Retrace技术进行离策略学习。

Result: 分析和实验表明，MCEM在连续和离散动作基准测试中都优于最先进的方法。

Conclusion: MCEM方法成功克服了线性分解表达力有限和非线性分解重新引入CDM的权衡问题，在多智能体强化学习任务中表现出色。

Abstract: Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution (CTDE), where centralized critics leverage global information to guide decentralized actors. However, centralized-decentralized mismatch (CDM) arises when the suboptimal behavior of one agent degrades others' learning. Prior approaches mitigate CDM through value decomposition, but linear decompositions allow per-agent gradients at the cost of limited expressiveness, while nonlinear decompositions improve representation but require centralized gradients, reintroducing CDM. To overcome this trade-off, we propose the multi-agent cross-entropy method (MCEM), combined with monotonic nonlinear critic decomposition (NCD). MCEM updates policies by increasing the probability of high-value joint actions, thereby excluding suboptimal behaviors. For sample efficiency, we extend off-policy learning with a modified k-step return and Retrace. Analysis and experiments demonstrate that MCEM outperforms state-of-the-art methods across both continuous and discrete action benchmarks.

</details>


### [376] [VLM in a flash: I/O-Efficient Sparsification of Vision-Language Model via Neuron Chunking](https://arxiv.org/abs/2511.18692)
*Kichang Yang,Seonjun Kim,Minjae Kim,Nairan Zhang,Chi Zhang,Youngki Lee*

Main category: cs.LG

TL;DR: 提出了Neuron Chunking方法，通过将神经元重要性评估与存储访问成本相结合，优化边缘设备上视觉语言模型的权重卸载I/O效率。


<details>
  <summary>Details</summary>
Motivation: 传统激活稀疏化方法仅基于激活幅度选择神经元，忽略了访问模式对闪存性能的影响，导致I/O效率低下。

Method: 基于内存中连续神经元组（块）进行操作，通过轻量级访问连续性抽象建模I/O延迟，选择具有高效用（神经元重要性/估计延迟）的块。

Result: 在Jetson Orin Nano和Jetson AGX Orin上分别实现了4.65倍和5.76倍的I/O效率提升。

Conclusion: 通过将稀疏化决策与底层存储行为对齐，Neuron Chunking显著提高了边缘设备上大视觉语言模型的I/O效率。

Abstract: Edge deployment of large Vision-Language Models (VLMs) increasingly relies on flash-based weight offloading, where activation sparsification is used to reduce I/O overhead. However, conventional sparsification remains model-centric, selecting neurons solely by activation magnitude and neglecting how access patterns influence flash performance. We present Neuron Chunking, an I/O-efficient sparsification strategy that operates on chunks (i.e., groups of contiguous neurons in memory) and couples neuron importance with storage access cost. The method models I/O latency through a lightweight abstraction of access contiguity and selects chunks with high utility, defined as neuron importance normalized by estimated latency. By aligning sparsification decisions with the underlying storage behavior, Neuron Chunking improves I/O efficiency by up to 4.65x and 5.76x on Jetson Orin Nano and Jetson AGX Orin, respectively.

</details>


### [377] [GRIT-LP: Graph Transformer with Long-Range Skip Connection and Partitioned Spatial Graphs for Accurate Ice Layer Thickness Prediction](https://arxiv.org/abs/2511.18716)
*Zesheng Liu,Maryam Rahnemoonfar*

Main category: cs.LG

TL;DR: GRIT-LP是一种专门用于极地雷达图像冰层厚度估计的图变换器，通过分区空间图构建策略和长程跳跃连接机制，解决了深度图变换器的过平滑和长程依赖建模问题，在RMSE指标上比现有最优方法提升了24.92%。


<details>
  <summary>Details</summary>
Motivation: 准确估计冰层厚度对于理解积雪积累、重建过去气候模式以及减少未来冰盖演化和海平面上升预测的不确定性至关重要。图变换器在复杂时空任务中表现出色，但其深度受到过平滑和弱长程依赖建模的限制。

Method: GRIT-LP结合了归纳几何图学习框架和自注意力机制，引入了两个主要创新：分区空间图构建策略（形成重叠的完全连接局部邻域以保持空间一致性并抑制不相关长程链接的噪声）和变换器内的长程跳跃连接机制（改善信息流并减轻更深注意力层中的过平滑）。

Result: 广泛的实验表明，GRIT-LP在均方根误差上比当前最先进方法提升了24.92%，表现出色。

Conclusion: 这些结果突显了图变换器在建模时空模式方面的有效性，能够捕捉局部结构特征和冰层内部的长程依赖，展示了它们在推进数据驱动的冰冻圈过程理解方面的潜力。

Abstract: Graph transformers have demonstrated remarkable capability on complex spatio-temporal tasks, yet their depth is often limited by oversmoothing and weak long-range dependency modeling. To address these challenges, we introduce GRIT-LP, a graph transformer explicitly designed for polar ice-layer thickness estimation from polar radar imagery. Accurately estimating ice layer thickness is critical for understanding snow accumulation, reconstructing past climate patterns and reducing uncertainties in projections of future ice sheet evolution and sea level rise. GRIT-LP combines an inductive geometric graph learning framework with self-attention mechanism, and introduces two major innovations that jointly address challenges in modeling the spatio-temporal patterns of ice layers: a partitioned spatial graph construction strategy that forms overlapping, fully connected local neighborhoods to preserve spatial coherence and suppress noise from irrelevant long-range links, and a long-range skip connection mechanism within the transformer that improves information flow and mitigates oversmoothing in deeper attention layers. We conducted extensive experiments, demonstrating that GRIT-LP outperforms current state-of-the-art methods with a 24.92\% improvement in root mean squared error. These results highlight the effectiveness of graph transformers in modeling spatiotemporal patterns by capturing both localized structural features and long-range dependencies across internal ice layers, and demonstrate their potential to advance data-driven understanding of cryospheric processes.

</details>


### [378] [Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM](https://arxiv.org/abs/2511.18721)
*Adarsh Kumarappan,Ayushi Mehrotra*

Main category: cs.LG

TL;DR: 本文针对SmoothLLM防御方法的局限性，提出了更现实的(k, ε)-不稳定概率框架，通过结合攻击成功率的经验模型，为对抗越狱攻击提供了更可信和实用的安全认证。


<details>
  <summary>Details</summary>
Motivation: SmoothLLM防御虽然提供越狱攻击的认证保证，但其依赖的严格k-不稳定假设在实践中很少成立，限制了安全证书的可信度。

Method: 引入(k, ε)-不稳定概率框架，结合攻击成功率的经验模型，推导SmoothLLM防御概率的新下界。

Result: 开发了更可信和实用的安全认证机制，能够为从业者提供可操作的安全保证，设置更符合LLM实际行为的认证阈值。

Conclusion: 这项工作为保护LLM安全对齐机制免遭利用提供了一个实用且理论基础扎实的机制，对安全AI部署至关重要。

Abstract: The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict `k-unstable' assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, `(k, $\varepsilon$)-unstable,' to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.

</details>


### [379] [LogSyn: A Few-Shot LLM Framework for Structured Insight Extraction from Unstructured General Aviation Maintenance Logs](https://arxiv.org/abs/2511.18727)
*Devansh Agarwal,Maitreyi Chatterjee,Biplab Chatterjee*

Main category: cs.LG

TL;DR: LogSyn框架使用大语言模型将非结构化飞机维护日志转换为结构化数据，通过少量样本学习实现受控抽象生成和事件分类，为航空维护提供可扩展的语义结构化方法。


<details>
  <summary>Details</summary>
Motivation: 飞机维护日志包含宝贵的安全数据，但由于其非结构化文本格式而未被充分利用，需要一种方法来提取可操作的见解。

Method: 使用大语言模型进行少量样本上下文学习，在6,169条记录上执行受控抽象生成，总结问题解决叙述并在详细分层本体中分类事件。

Result: 框架识别关键故障模式，为维护日志提供可扩展的语义结构化和可操作见解提取方法。

Conclusion: 这项工作为改进航空及相关行业的维护工作流程和预测分析提供了实用途径。

Abstract: Aircraft maintenance logs hold valuable safety data but remain underused due to their unstructured text format. This paper introduces LogSyn, a framework that uses Large Language Models (LLMs) to convert these logs into structured, machine-readable data. Using few-shot in-context learning on 6,169 records, LogSyn performs Controlled Abstraction Generation (CAG) to summarize problem-resolution narratives and classify events within a detailed hierarchical ontology. The framework identifies key failure patterns, offering a scalable method for semantic structuring and actionable insight extraction from maintenance logs. This work provides a practical path to improve maintenance workflows and predictive analytics in aviation and related industries.

</details>


### [380] [Reinforcement Learning for Self-Healing Material Systems](https://arxiv.org/abs/2511.18728)
*Maitreyi Chatterjee,Devansh Agarwal,Biplab Chatterjee*

Main category: cs.LG

TL;DR: 该研究将自愈合过程构建为强化学习问题，比较了离散动作和连续动作智能体在材料自愈合控制中的表现，发现TD3智能体在连续剂量控制方面表现最优。


<details>
  <summary>Details</summary>
Motivation: 向自主材料系统过渡需要自适应控制方法来最大化结构寿命，需要平衡结构完整性维护与有限资源消耗。

Method: 将自愈合过程构建为马尔可夫决策过程中的强化学习问题，比较离散动作（Q-learning、DQN）和连续动作（TD3）智能体在随机模拟环境中的表现。

Result: 强化学习控制器显著优于启发式基线方法，实现近乎完全的材料恢复。TD3智能体在连续剂量控制方面表现出更快的收敛速度和更好的稳定性。

Conclusion: 在动态自愈合应用中，细粒度的比例驱动控制是必要的，连续动作智能体在材料自愈合控制中具有优势。

Abstract: The transition to autonomous material systems necessitates adaptive control methodologies to maximize structural longevity. This study frames the self-healing process as a Reinforcement Learning (RL) problem within a Markov Decision Process (MDP), enabling agents to autonomously derive optimal policies that efficiently balance structural integrity maintenance against finite resource consumption. A comparative evaluation of discrete-action (Q-learning, DQN) and continuous-action (TD3) agents in a stochastic simulation environment revealed that RL controllers significantly outperform heuristic baselines, achieving near-complete material recovery. Crucially, the TD3 agent utilizing continuous dosage control demonstrated superior convergence speed and stability, underscoring the necessity of fine-grained, proportional actuation in dynamic self-healing applications.

</details>


### [381] [OceanForecastBench: A Benchmark Dataset for Data-Driven Global Ocean Forecasting](https://arxiv.org/abs/2511.18732)
*Haoming Jia,Yi Han,Xiang Wang,Huizan Wang,Wei Wu,Jianming Zheng,Peikun Xiao*

Main category: cs.LG

TL;DR: OceanForecastBench是一个开源标准化基准，提供28年高质量海洋再分析数据、可靠观测数据和评估管道，解决数据驱动海洋预报模型缺乏统一基准的问题。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的深度学习海洋预报模型缺乏开源标准化基准，导致数据使用和评估方法不一致，阻碍模型开发、性能比较和跨学科合作。

Method: 构建包含三个核心贡献的基准框架：(1)28年高质量全球海洋再分析数据；(2)高可靠性卫星和现场观测数据；(3)评估管道和6个典型基线模型。

Result: 创建了目前最全面的数据驱动海洋预报基准框架，为模型开发、评估和比较提供开源平台。

Conclusion: OceanForecastBench解决了海洋预报领域缺乏标准化基准的问题，促进了模型开发和公平性能比较。

Abstract: Global ocean forecasting aims to predict key ocean variables such as temperature, salinity, and currents, which is essential for understanding and describing oceanic phenomena. In recent years, data-driven deep learning-based ocean forecast models, such as XiHe, WenHai, LangYa and AI-GOMS, have demonstrated significant potential in capturing complex ocean dynamics and improving forecasting efficiency. Despite these advancements, the absence of open-source, standardized benchmarks has led to inconsistent data usage and evaluation methods. This gap hinders efficient model development, impedes fair performance comparison, and constrains interdisciplinary collaboration. To address this challenge, we propose OceanForecastBench, a benchmark offering three core contributions: (1) A high-quality global ocean reanalysis data over 28 years for model training, including 4 ocean variables across 23 depth levels and 4 sea surface variables. (2) A high-reliability satellite and in-situ observations for model evaluation, covering approximately 100 million locations in the global ocean. (3) An evaluation pipeline and a comprehensive benchmark with 6 typical baseline models, leveraging observations to evaluate model performance from multiple perspectives. OceanForecastBench represents the most comprehensive benchmarking framework currently available for data-driven ocean forecasting, offering an open-source platform for model development, evaluation, and comparison. The dataset and code are publicly available at: https://github.com/Ocean-Intelligent-Forecasting/OceanForecastBench.

</details>


### [382] [Sampling Control for Imbalanced Calibration in Semi-Supervised Learning](https://arxiv.org/abs/2511.18773)
*Senmao Tian,Xiang Wei,Shunli Zhang*

Main category: cs.LG

TL;DR: SC-SSL是一个统一的半监督学习框架，通过解耦采样控制来抑制类别不平衡导致的模型偏差，在训练和推理阶段分别处理特征级和权重不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决半监督学习中类别不平衡问题，特别是当有标签和无标签数据分布不匹配时导致的分类偏差。现有方法通常以粗粒度方式处理模型不平衡，混淆了数据不平衡与不同类别学习难度差异带来的偏差。

Method: 提出SC-SSL框架：1）训练阶段通过解耦采样控制识别关键变量，引入具有显式扩展能力的分类器并自适应调整不同数据分布的采样概率；2）推理阶段分析线性分类器的权重不平衡，应用后处理采样控制通过优化偏置向量直接校准logits。

Result: 在多个基准数据集和不同分布设置下的广泛实验验证了SC-SSL的一致性和最先进性能。

Conclusion: SC-SSL通过统一的解耦采样控制框架有效解决了半监督学习中的类别不平衡问题，在训练和推理阶段分别处理特征级和权重不平衡，实现了稳定且优越的性能。

Abstract: Class imbalance remains a critical challenge in semi-supervised learning (SSL), especially when distributional mismatches between labeled and unlabeled data lead to biased classification. Although existing methods address this issue by adjusting logits based on the estimated class distribution of unlabeled data, they often handle model imbalance in a coarse-grained manner, conflating data imbalance with bias arising from varying class-specific learning difficulties. To address this issue, we propose a unified framework, SC-SSL, which suppresses model bias through decoupled sampling control. During training, we identify the key variables for sampling control under ideal conditions. By introducing a classifier with explicit expansion capability and adaptively adjusting sampling probabilities across different data distributions, SC-SSL mitigates feature-level imbalance for minority classes. In the inference phase, we further analyze the weight imbalance of the linear classifier and apply post-hoc sampling control with an optimization bias vector to directly calibrate the logits. Extensive experiments across various benchmark datasets and distribution settings validate the consistency and state-of-the-art performance of SC-SSL.

</details>


### [383] [SAOT: An Enhanced Locality-Aware Spectral Transformer for Solving PDEs](https://arxiv.org/abs/2511.18777)
*Chenhong Zhou,Jie Chen,Zaifeng Yang*

Main category: cs.LG

TL;DR: 本文提出了一种结合小波变换空间-频率局部化特性的新型Wavelet Attention模块和Spectral Attention Operator Transformer框架，有效解决了Fourier Neural Operator在求解偏微分方程时过度平滑、无法捕捉局部细节和高频分量的问题。


<details>
  <summary>Details</summary>
Motivation: Fourier Neural Operator在求解偏微分方程时存在过度平滑解、无法有效捕捉局部细节和高频分量的局限性，需要改进以提升性能。

Method: 提出了Wavelet Attention模块，具有线性计算复杂度，能有效学习局部感知特征；并开发了Spectral Attention Operator Transformer混合频谱Transformer框架，通过门控融合块将WA的局部关注与Fourier-based Attention的全局感受野相结合。

Result: WA显著缓解了FA的局限性，大幅优于现有基于小波的神经算子；SAOT在六个算子学习基准测试中达到最先进性能，并展现出强大的离散不变性能力。

Conclusion: 通过整合局部感知和全局频谱表示，SAOT框架成功解决了FNO的局限性，在算子学习任务中实现了优越性能。

Abstract: Neural operators have shown great potential in solving a family of Partial Differential Equations (PDEs) by modeling the mappings between input and output functions. Fourier Neural Operator (FNO) implements global convolutions via parameterizing the integral operators in Fourier space. However, it often results in over-smoothing solutions and fails to capture local details and high-frequency components. To address these limitations, we investigate incorporating the spatial-frequency localization property of Wavelet transforms into the Transformer architecture. We propose a novel Wavelet Attention (WA) module with linear computational complexity to efficiently learn locality-aware features. Building upon WA, we further develop the Spectral Attention Operator Transformer (SAOT), a hybrid spectral Transformer framework that integrates WA's localized focus with the global receptive field of Fourier-based Attention (FA) through a gated fusion block. Experimental results demonstrate that WA significantly mitigates the limitations of FA and outperforms existing Wavelet-based neural operators by a large margin. By integrating the locality-aware and global spectral representations, SAOT achieves state-of-the-art performance on six operator learning benchmarks and exhibits strong discretization-invariant ability.

</details>


### [384] [Towards Characterizing Knowledge Distillation of PPG Heart Rate Estimation Models](https://arxiv.org/abs/2511.18829)
*Kanav Arora,Girish Narayanswamy,Shwetak Patel,Richard Li*

Main category: cs.LG

TL;DR: 本文研究了如何将大型预训练PPG模型蒸馏为适合边缘设备实时推理的小型模型，评估了四种蒸馏策略，并描述了模型大小与性能之间的缩放规律。


<details>
  <summary>Details</summary>
Motivation: 虽然深度学习模型在心率估计任务中表现良好，但要在可穿戴设备上部署这些模型，必须满足严格的内存和延迟限制。

Method: 评估了四种蒸馏策略：硬蒸馏、软蒸馏、解耦知识蒸馏和特征蒸馏，通过全面扫描教师和学生模型容量来进行比较。

Result: 提出了描述模型大小与性能关系的缩放规律，为构建可部署在边缘设备上的生理传感模型奠定了基础。

Conclusion: 这项早期研究为构建实用且可预测的边缘可部署生理传感模型方法奠定了基础。

Abstract: Heart rate estimation from photoplethysmography (PPG) signals generated by wearable devices such as smartwatches and fitness trackers has significant implications for the health and well-being of individuals. Although prior work has demonstrated deep learning models with strong performance in the heart rate estimation task, in order to deploy these models on wearable devices, these models must also adhere to strict memory and latency constraints. In this work, we explore and characterize how large pre-trained PPG models may be distilled to smaller models appropriate for real-time inference on the edge. We evaluate four distillation strategies through comprehensive sweeps of teacher and student model capacities: (1) hard distillation, (2) soft distillation, (3) decoupled knowledge distillation (DKD), and (4) feature distillation. We present a characterization of the resulting scaling laws describing the relationship between model size and performance. This early investigation lays the groundwork for practical and predictable methods for building edge-deployable models for physiological sensing.

</details>


### [385] [Federated style aware transformer aggregation of representations](https://arxiv.org/abs/2511.18841)
*Mincheol Jeon,Euinam Huh*

Main category: cs.LG

TL;DR: FedSTAR是一个风格感知的联邦学习框架，通过解耦客户端特定风格因子和共享内容表示来解决个性化联邦学习中的领域异构性、数据不平衡和通信约束问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习缺乏个性化，单一全局模型无法捕捉客户端特定特征，导致对有高度不同数据分布的客户端产生偏差预测和泛化能力差。

Method: 提出FedSTAR框架，使用基于Transformer的注意力机制聚合类原型，解耦客户端特定风格因子和共享内容表示，通过交换紧凑原型和风格向量而非完整模型参数来减少通信开销。

Result: 实验结果表明，结合内容-风格解耦和注意力驱动的原型聚合，在不增加通信成本的情况下提高了异构环境中的个性化和鲁棒性。

Conclusion: FedSTAR通过风格感知的方法有效解决了联邦学习中的个性化挑战，在保持通信效率的同时提升了模型性能。

Abstract: Personalized Federated Learning (PFL) faces persistent challenges, including domain heterogeneity from diverse client data, data imbalance due to skewed participation, and strict communication constraints. Traditional federated learning often lacks personalization, as a single global model cannot capture client-specific characteristics, leading to biased predictions and poor generalization, especially for clients with highly divergent data distributions.
  To address these issues, we propose FedSTAR, a style-aware federated learning framework that disentangles client-specific style factors from shared content representations. FedSTAR aggregates class-wise prototypes using a Transformer-based attention mechanism, allowing the server to adaptively weight client contributions while preserving personalization.
  Furthermore, by exchanging compact prototypes and style vectors instead of full model parameters, FedSTAR significantly reduces communication overhead. Experimental results demonstrate that combining content-style disentanglement with attention-driven prototype aggregation improves personalization and robustness in heterogeneous environments without increasing communication cost.

</details>


### [386] [Robust and Generalizable GNN Fine-Tuning via Uncertainty-aware Adapter Learning](https://arxiv.org/abs/2511.18859)
*Bo Jiang,Weijun Zhao,Beibei Wang,Xiao Wang,Jin Tang*

Main category: cs.LG

TL;DR: 本文提出了一种不确定性感知的适配器方法UAdapterGNN，通过在GNN微调过程中集成不确定性学习来增强预训练GNN模型对噪声图数据的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的AdapterGNN方法在处理包含噪声边和模糊节点属性的下游图数据时容易受到噪声影响，且泛化能力有限。如何增强GNN微调的鲁棒性和泛化能力是一个开放性问题。

Method: 提出UAdapterGNN，使用高斯概率适配器来增强预训练GNN模型。当图包含各种噪声时，该方法能自动吸收高斯分布方差变化的影响，从而显著增强模型鲁棒性。

Result: 在多个基准测试上的广泛实验表明，UAdapterGNN方法具有有效性、鲁棒性和高泛化能力。

Conclusion: 通过将不确定性学习集成到GNN适配器中，可以有效解决图噪声问题，显著提升预训练GNN模型在下游任务中的鲁棒性和泛化性能。

Abstract: Recently, fine-tuning large-scale pre-trained GNNs has yielded remarkable attention in adapting pre-trained GNN models for downstream graph learning tasks. One representative fine-tuning method is to exploit adapter (termed AdapterGNN) which aims to 'augment' the pre-trained model by inserting a lightweight module to make the 'augmented' model better adapt to the downstream tasks. However, graph data may contain various types of noise in downstream tasks, such as noisy edges and ambiguous node attributes. Existing AdapterGNNs are often prone to graph noise and exhibit limited generalizability. How to enhance the robustness and generalization ability of GNNs' fine tuning remains an open problem. In this paper, we show that the above problem can be well addressed by integrating uncertainty learning into the GNN adapter. We propose the Uncertainty-aware Adapter (UAdapterGNN) that fortifies pre-trained GNN models against noisy graph data in the fine-tuning process. Specifically, in contrast to regular AdapterGNN, our UAdapterGNN exploits Gaussian probabilistic adapter to augment the pre-trained GNN model. In this way, when the graph contains various noises,our method can automatically absorb the effects of changes in the variances of the Gaussian distribution, thereby significantly enhancing the model's robustness. Also, UAdapterGNN can further improve the generalization ability of the model on the downstream tasks. Extensive experiments on several benchmarks demonstrate the effectiveness, robustness and high generalization ability of the proposed UAdapterGNN method.

</details>


### [387] [Periodic Asynchrony: An Effective Method for Accelerating On-Policy Reinforcement Learning](https://arxiv.org/abs/2511.18871)
*Jian Lu*

Main category: cs.LG

TL;DR: 本文提出了一种将同步强化学习架构转变为周期性异步框架的方法，通过分离推理和训练部署，并改进数据加载器，实现了至少三倍的整体性能提升。


<details>
  <summary>Details</summary>
Motivation: 主流RL框架中推理和训练通常部署在同一设备上，同步执行导致计算耦合，阻碍了并发推理和训练，训练效率成为关键挑战。

Method: 采用分离推理和训练部署策略，引入数据加载器改进，将传统同步架构转变为周期性异步框架；在训练阶段应用统一的三模型架构，并提出共享提示注意力掩码以减少重复计算。

Result: 该框架允许按需独立弹性扩展各组件，算法精度与同步方法完全等效，在NPU平台上实现了至少三倍的整体RL训练性能提升。

Conclusion: 周期性异步框架具有广泛应用潜力，能够在保持算法精度的同时显著提升训练效率。

Abstract: Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.

</details>


### [388] [Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models](https://arxiv.org/abs/2511.18890)
*Yonggan Fu,Xin Dong,Shizhe Diao,Matthijs Van keirsbilck,Hanrong Ye,Wonmin Byeon,Yashaswi Karnati,Lucas Liebenwein,Hannah Zhang,Nikolaus Binder,Maksim Khadkevich,Alexander Keller,Jan Kautz,Yingyan Celine Lin,Pavlo Molchanov*

Main category: cs.LG

TL;DR: 本文研究了小语言模型在真实设备上的延迟优化，提出了基于深度-宽度比和算子选择的设计原则，开发了自动搜索框架构建混合SLMs，并引入权重归一化技术提升训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有SLM设计主要关注参数数量减少，但参数效率不一定能转化为真实设备的加速效果，需要研究真实设备延迟的关键决定因素。

Method: 识别深度-宽度比和算子选择两个关键架构因素；研究延迟最优的深度-宽度比；探索高效注意力替代方案；构建进化搜索框架自动发现算子组合；使用权重归一化技术增强训练。

Result: 提出的Nemotron-Flash模型在准确率-效率前沿取得显著进展：相比Qwen3-1.7B/0.6B，平均准确率提升超过5.5%，延迟降低1.3x/1.9x，吞吐量提高18.7x/45.6x。

Conclusion: 通过架构改进和训练增强，成功构建了在真实设备延迟约束下性能更优的小语言模型，为SLM设计提供了可推广的原则和方法论。

Abstract: Efficient deployment of small language models (SLMs) is essential for numerous real-world applications with stringent latency constraints. While previous work on SLM design has primarily focused on reducing the number of parameters to achieve parameter-optimal SLMs, parameter efficiency does not necessarily translate into proportional real-device speed-ups. This work aims to identify the key determinants of SLMs' real-device latency and offer generalizable principles and methodologies for SLM design and training when real-device latency is the primary consideration. Specifically, we identify two central architectural factors: depth-width ratios and operator choices. The former is crucial for small-batch-size latency, while the latter affects both latency and large-batch-size throughput. In light of this, we first study latency-optimal depth-width ratios, with the key finding that although deep-thin models generally achieve better accuracy under the same parameter budget, they may not lie on the accuracy-latency trade-off frontier. Next, we explore emerging efficient attention alternatives to evaluate their potential as candidate building operators. Using the identified promising operators, we construct an evolutionary search framework to automatically discover latency-optimal combinations of these operators within hybrid SLMs, thereby advancing the accuracy-latency frontier. In addition to architectural improvements, we further enhance SLM training using a weight normalization technique that enables more effective weight updates and improves final convergence. Combining these methods, we introduce a new family of hybrid SLMs, called Nemotron-Flash, which significantly advances the accuracy-efficiency frontier of state-of-the-art SLMs, e.g., achieving over +5.5% average accuracy, 1.3x/1.9x lower latency, and 18.7x/45.6x higher throughput compared to Qwen3-1.7B/0.6B, respectively.

</details>


### [389] [VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL](https://arxiv.org/abs/2511.18902)
*Zengjie Hu,Jiantao Qiu,Tianyi Bai,Haojin Yang,Binhang Yuan,Qi Jing,Conghui He,Wentao Zhang*

Main category: cs.LG

TL;DR: VADE是一个基于方差感知的动态采样框架，通过在线样本难度估计解决基于组的策略优化方法中的梯度消失问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于组的策略优化方法（如GRPO和GSPO）存在梯度消失问题，当组内所有响应获得相同奖励时，优势估计会崩溃，训练信号减弱。现有解决方案存在计算开销大或缺乏实时适应性的问题。

Method: VADE框架包含三个核心组件：使用Beta分布进行在线样本级难度估计、通过Thompson采样器最大化信息增益、以及两尺度先验衰减机制来在策略演化下保持稳健估计。

Result: 在多模态推理基准测试中，VADE在性能和样本效率上均优于强基线方法，同时显著降低了计算开销。

Conclusion: VADE能够动态选择最具信息量的样本，增强训练信号并消除额外rollout成本，可作为即插即用组件无缝集成到现有的基于组的强化学习算法中。

Abstract: Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \textbf{VADE}, a \textbf{V}ariance-\textbf{A}ware \textbf{D}ynamic sampling framework via online sample-level difficulty \textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.

</details>


### [390] [How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining](https://arxiv.org/abs/2511.18903)
*Kairong Luo,Zhenbo Sun,Haodong Wen,Xinyu Shi,Jiarui Cui,Chenyi Dang,Kaifeng Lyu,Wenguang Chen*

Main category: cs.LG

TL;DR: 研究发现课程式预训练效果受限的原因是数据质量升序与学习率衰减计划不兼容，提出了两种简单策略来缓解这一问题，在标准基准测试上平均得分比随机洗牌提高了1.64%。


<details>
  <summary>Details</summary>
Motivation: 由于高质量数据的稀缺性，大语言模型通常在混合质量数据上训练。课程式预训练按数据质量升序训练模型是自然方法，但先前研究显示其改进有限，需要探究限制因素。

Method: 识别出数据质量升序与学习率衰减计划不兼容的问题，提出两种策略：(1)使用更温和的学习率衰减计划，(2)用模型平均替换学习率衰减。在1.5B参数模型上使用多种数据质量指标进行验证。

Result: 结合两种策略后，在标准基准测试套件上的平均得分比随机洗牌提高了1.64%，且无需额外数据精炼。

Conclusion: 研究呼吁重新评估课程式LLM预训练方法，并强调数据课程与优化方法协同设计的潜力。

Abstract: Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.

</details>


### [391] [Learning Solution Operators for Partial Differential Equations via Monte Carlo-Type Approximation](https://arxiv.org/abs/2511.18930)
*Salah Eddine Choutri,Prajwal Chauhan,Othmane Mazhar,Saif Eddin Jabari*

Main category: cs.LG

TL;DR: MCNO提出了一种轻量级架构，通过蒙特卡洛方法直接逼近核积分来学习参数化PDE的解算子，无需谱或平移不变性假设，能够在不同网格分辨率下泛化。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子方法如傅里叶神经算子依赖谱假设或平移不变性，MCNO旨在提供一种更简单实用的替代方案，不依赖固定全局基函数或训练期间的重复采样。

Method: 使用蒙特卡洛方法直接逼近核积分，将核表示为固定随机采样点集上的可学习张量，实现跨多个网格分辨率的泛化能力。

Result: 在标准1D PDE基准测试中，MCNO以较低计算成本实现了竞争性精度，验证了其有效性。

Conclusion: MCNO为谱和基于图的神经算子提供了一个简单实用的替代方案，具有轻量级架构和良好的泛化能力。

Abstract: The Monte Carlo-type Neural Operator (MCNO) introduces a lightweight architecture for learning solution operators for parametric PDEs by directly approximating the kernel integral using a Monte Carlo approach. Unlike Fourier Neural Operators, MCNO makes no spectral or translation-invariance assumptions. The kernel is represented as a learnable tensor over a fixed set of randomly sampled points. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with low computational cost, providing a simple and practical alternative to spectral and graph-based neural operators.

</details>


### [392] [SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression](https://arxiv.org/abs/2511.18936)
*Santhosh G S,Saurav Prakash,Balaraman Ravindran*

Main category: cs.LG

TL;DR: SWAN是一种无需微调的KV缓存压缩框架，通过正交矩阵旋转和剪枝来减少内存占用，无需解压缩步骤，在50-60%内存节省下仍能保持接近原始性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自回归推理时面临KV缓存内存占用过大的瓶颈，现有压缩技术存在信息丢失风险、固定限制或解压缩计算开销大的问题。

Method: 使用离线正交矩阵对KV缓存进行旋转和剪枝，剪枝后的KV缓存可直接用于注意力计算而无需重建，结合小密集缓冲区增强性能。

Result: 实验表明SWAN在每token KV缓存节省50-60%内存的情况下，仍能保持接近未压缩基线的性能，且支持运行时可调压缩级别。

Conclusion: SWAN提供了一种无解压缩设计、高压缩性能下保持良好表现且具有适应性的实用高效解决方案，适用于长上下文LLM服务。

Abstract: Large Language Models (LLMs) face a significant bottleneck during autoregressive inference due to the massive memory footprint of the Key-Value (KV) cache. Existing compression techniques like token eviction, quantization, or other low-rank methods often risk information loss, have fixed limits, or introduce significant computational overhead from explicit decompression steps. In this work, we introduce SWAN, a novel, fine-tuning-free framework that eliminates this overhead. Our method uses an offline orthogonal matrix to rotate and prune the KV-cache, which is then used directly in the attention computation without any reconstruction. Our extensive experiments demonstrate that SWAN, augmented with a small dense buffer, offers a robust trade-off, maintaining performance close to the uncompressed baseline even at aggressive 50-60% memory savings per-token on KV-cache. A key advantage is its runtime-tunable compression level, allowing operators to dynamically adjust the memory footprint, a flexibility absent in methods requiring fixed offline configurations. This combination of a decompression-free design, high performance under compression, and adaptability makes SWAN a practical and efficient solution for serving LLMs with long contexts.

</details>


### [393] [Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation](https://arxiv.org/abs/2511.18958)
*Qisen Chai,Yansong Wang,Junjie Huang,Tao Jia*

Main category: cs.LG

TL;DR: Cutter是一个基于双智能体强化学习的图压缩框架，通过Vital Detection Agent和Redundancy Detection Agent协同识别关键和冗余节点，实现高效图压缩并保持原始图的鲁棒性评估特性。


<details>
  <summary>Details</summary>
Motivation: 随着图结构数据规模增大，评估其对抗攻击下的鲁棒性变得计算昂贵且难以扩展，需要开发能够保持拓扑结构和鲁棒性特征的压缩方法。

Method: 提出Cutter双智能体强化学习框架，包含Vital Detection Agent和Redundancy Detection Agent，采用轨迹级奖励塑造、原型引导和跨智能体模仿三种策略来提升学习效率和压缩质量。

Result: 在多个真实世界图数据上的实验表明，Cutter生成的压缩图保留了关键静态拓扑特性，并在各种攻击场景下展现出与原始图高度一致的鲁棒性退化趋势。

Conclusion: Cutter能够在不损害评估保真度的前提下显著提升图鲁棒性评估效率，为大规模图分析提供了有效的压缩解决方案。

Abstract: As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation.We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both highand low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.

</details>


### [394] [AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention](https://arxiv.org/abs/2511.18960)
*Lei Xiao,Jifeng Li,Juntao Gao,Feiyang Ye,Yan Jin,Jingjing Qian,Jing Zhang,Yong Wu,Xiaoyuan Yu*

Main category: cs.LG

TL;DR: AVA-VLA是一个基于POMDP的新型视觉-语言-动作框架，通过引入主动视觉注意力机制，利用历史上下文动态调制视觉处理，在机器人任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常独立处理每个时间步的密集视觉输入，采用MDP建模方式，这种历史无关的设计在动态顺序决策中无法有效利用历史上下文，限制了视觉令牌处理的效率。

Method: 从POMDP角度重新定义问题，提出AVA-VLA框架，引入主动视觉注意力(AVA)模块，利用来自前一个决策步骤的循环状态（信念状态的神经近似）动态调制视觉处理，计算软权重来主动处理任务相关的视觉令牌。

Result: 在LIBERO和CALVIN等流行机器人基准测试中实现最先进性能，在双臂机器人平台上的实际部署验证了框架的实用性和强大的模拟到现实迁移能力。

Conclusion: AVA-VLA通过将问题重新定义为POMDP并引入主动视觉注意力机制，显著提升了VLA模型在动态顺序决策任务中的性能，证明了利用历史上下文进行视觉处理的重要性。

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.

</details>


### [395] [FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning](https://arxiv.org/abs/2511.18977)
*Xin Yuan,Siqi Li,Jiateng Wei,Chengrui Zhu,Yanming Wu,Qingpeng Li,Jiajun Lv,Xiaoke Lan,Jun Chen,Yong Liu*

Main category: cs.LG

TL;DR: 提出FastForward剪枝方法，通过解耦的单步强化学习框架分离策略优化与预算满足问题，显著降低计算成本，在LLaMA、Mistral和OPT模型上实现优于启发式基线的性能。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法中，启发式方法快速但性能次优，而基于搜索的方法如强化学习计算成本过高，难以在大规模模型上应用。

Method: 采用解耦的单步强化学习框架，将策略优化与预算满足问题分离，使用基于课程学习的策略从简单任务开始逐步增加复杂度。

Result: 在LLaMA、Mistral和OPT模型家族上，发现的剪枝策略优于强启发式基线，与其他搜索算法相比以更低的计算成本获得竞争性或更优的结果。

Conclusion: FastForward剪枝方法在搜索效率上具有明显优势，能够以较低计算成本找到高质量的层间稀疏度分配策略。

Abstract: Pruning is an effective method for compressing Large Language Models, but finding an optimal, non-uniform layer-wise sparsity allocation remains a key challenge. While heuristic methods are fast but yield suboptimal performance, more powerful search-based approaches like Reinforcement Learning are often hindered by prohibitive computational costs on large-scale models. To overcome this efficiency barrier, we propose FastForward Pruning. Its core is a decoupled, single-step RL framework that separates policy optimization from the complex budget satisfaction problem. Such a decoupling is crucial for efficiently searching the vast policy space of LLMs. This curriculum-based strategy begins with low-cost, simple tasks and gradually increases in complexity, significantly reducing the search's computational overhead. Evaluated on the LLaMA, Mistral, and OPT model families, our framework discovers pruning policies that achieve superior performance over strong heuristic baselines. Crucially, when compared to other search-based algorithms, our method achieves competitive or superior results at a fraction of the computational cost, demonstrating a clear advantage in search efficiency.

</details>


### [396] [OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs](https://arxiv.org/abs/2511.19023)
*Yuting Gao,Weihao Chen,Lan Wang,Ruihan Xu,Qingpei Guo*

Main category: cs.LG

TL;DR: OrdMoE是一个无需外部人类标注偏好数据的多模态大语言模型对齐框架，通过利用MoE架构中路由器专家选择分数的内在信号，构建自监督的偏好排序。


<details>
  <summary>Details</summary>
Motivation: 现有的偏好学习方法主要依赖昂贵且劳动密集型的外部人类标注偏好数据，需要开发一种零成本的自监督偏好对齐方法。

Method: 通过将MoE架构中的专家基于每个token的路由分数分组为排名层级，分别激活每个层级以产生质量递增的响应序列，从而构建内部偏好层次。

Result: 在多个多模态基准测试上的广泛实验表明，OrdMoE显著提升了多模态MoE LLMs的对齐和整体性能，无需任何人类标注偏好数据即可获得有竞争力的结果。

Conclusion: OrdMoE证明了利用MoE架构内在信号进行自监督偏好学习的有效性，为多模态大语言模型的对齐提供了一种零成本且高效的解决方案。

Abstract: Preference learning has recently emerged as a pivotal strategy for post-training alignment of Multimodal Large Language Models (MLLMs). However, existing approaches predominantly rely on external human-annotated preference data, which is costly and labor-intensive to collect. In this work, we propose OrdMoE, a novel preference alignment framework that bypasses the reliance on external human preferences entirely by leveraging intrinsic signals within Mixture-of-Experts (MoE) architectures. Specifically, we observe that the router's expert selection scores implicitly encode a quality-aware ranking of responses (i.e. higher-scoring experts consistently generate higher-quality outputs). Building on this insight, OrdMoE constructs an internal preference hierarchy by grouping experts into ranked tiers based on their per-token routing scores and activating each tier separately to produce a sequence of responses with increasing quality. This yields a zero-cost, self-supervised preference ordering over generated responses, which can be directly optimized using standard preference learning objectives. Extensive experiments across multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances both alignment and overall performance of multimodal Mixture-of-Experts LLMs, achieving competitive results without requiring any human-annotated preference data.

</details>


### [397] [Mitigating Participation Imbalance Bias in Asynchronous Federated Learning](https://arxiv.org/abs/2511.19066)
*Xiangyu Chang,Manyi Yao,Srikanth V. Krishnamurthy,Christian R. Shelton,Anirban Chakraborty,Ananthram Swami,Samet Oymak,Amit Roy-Chowdhury*

Main category: cs.LG

TL;DR: 本文分析了异步联邦学习中的异构性放大问题，提出了ACE和ACED方法来解决客户端参与不平衡和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 在异步联邦学习中，服务器立即使用每个到达客户端的贡献更新全局模型，导致客户端在不同模型版本上进行本地训练，造成信息陈旧性。在非IID数据分布环境中，这种异步模式放大了客户端异构性的不利影响，因为更快的客户端贡献更频繁的更新，使全局模型产生偏差。

Method: 提出ACE方法，通过立即、非缓冲的更新来缓解参与不平衡，使用所有客户端的最新可用信息。还引入了延迟感知变体ACED，以平衡客户端多样性与更新陈旧性。

Result: 在不同模型、不同任务以及各种异构性和延迟设置下的实验验证了分析，并证明了所提方法的稳健性能。

Conclusion: ACE和ACED方法有效缓解了异步联邦学习中的异构性放大问题，通过平衡客户端参与和延迟管理，提高了模型的性能和鲁棒性。

Abstract: In Asynchronous Federated Learning (AFL), the central server immediately updates the global model with each arriving client's contribution. As a result, clients perform their local training on different model versions, causing information staleness (delay). In federated environments with non-IID local data distributions, this asynchronous pattern amplifies the adverse effect of client heterogeneity (due to different data distribution, local objectives, etc.), as faster clients contribute more frequent updates, biasing the global model. We term this phenomenon heterogeneity amplification. Our work provides a theoretical analysis that maps AFL design choices to their resulting error sources when heterogeneity amplification occurs. Guided by our analysis, we propose ACE (All-Client Engagement AFL), which mitigates participation imbalance through immediate, non-buffered updates that use the latest information available from all clients. We also introduce a delay-aware variant, ACED, to balance client diversity against update staleness. Experiments on different models for different tasks across diverse heterogeneity and delay settings validate our analysis and demonstrate the robust performance of our approaches.

</details>


### [398] [EnfoPath: Energy-Informed Analysis of Generative Trajectories in Flow Matching](https://arxiv.org/abs/2511.19087)
*Ziyun Li,Ben Dai,Huancheng Hu,Henrik Boström,Soon Hoe Lim*

Main category: cs.LG

TL;DR: 本文引入动能路径能量(KPE)作为诊断工具，量化ODE采样器生成路径的总动能消耗，发现语义质量更高的样本需要更大的动能努力，且位于数据分布的稀疏前沿。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注端点指标（如保真度、似然、感知质量），而忽略了采样轨迹能揭示的更深层信息。受经典力学启发，作者希望理解生成路径的动力学特征。

Method: 提出动能路径能量(KPE)这一简单而强大的诊断指标，用于量化ODE采样器每个生成路径的总动能消耗。在CIFAR-10和ImageNet-256数据集上进行全面实验。

Result: 发现两个关键现象：(i) 更高的KPE预测更强的语义质量，表明语义更丰富的样本需要更大的动能努力；(ii) 更高的KPE与数据密度呈负相关，信息丰富的样本位于稀疏的低密度区域。

Conclusion: 语义信息丰富的样本自然地存在于数据分布的稀疏前沿，需要更大的生成努力。轨迹级分析为理解生成难度和样本特征提供了物理启发且可解释的框架。

Abstract: Flow-based generative models synthesize data by integrating a learned velocity field from a reference distribution to the target data distribution. Prior work has focused on endpoint metrics (e.g., fidelity, likelihood, perceptual quality) while overlooking a deeper question: what do the sampling trajectories reveal? Motivated by classical mechanics, we introduce kinetic path energy (KPE), a simple yet powerful diagnostic that quantifies the total kinetic effort along each generation path of ODE-based samplers. Through comprehensive experiments on CIFAR-10 and ImageNet-256, we uncover two key phenomena: ({i}) higher KPE predicts stronger semantic quality, indicating that semantically richer samples require greater kinetic effort, and ({ii}) higher KPE inversely correlates with data density, with informative samples residing in sparse, low-density regions. Together, these findings reveal that semantically informative samples naturally reside on the sparse frontier of the data distribution, demanding greater generative effort. Our results suggest that trajectory-level analysis offers a physics-inspired and interpretable framework for understanding generation difficulty and sample characteristics.

</details>


### [399] [Optimization of Deep Learning Models for Dynamic Market Behavior Prediction](https://arxiv.org/abs/2511.19090)
*Shenghan Zhao,Yuzhen Lin,Ximeng Yang,Qiaochu Lu,Haozhong Xue,Gaozhe Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种混合序列模型，结合多尺度时间卷积、门控循环模块和时间感知自注意力机制，用于电子商务多时间范围需求预测，在多个评估指标上优于传统方法和现有最先进模型。


<details>
  <summary>Details</summary>
Motivation: 金融科技领域深度学习的应用日益增长，特别是在预测消费者行为方面具有提升贷款策略和市场效率的潜力。本文专注于零售市场行为，明确定义了SKU级别的多时间范围需求预测目标。

Method: 开发了混合序列模型，整合多尺度时间卷积、门控循环模块和时间感知自注意力机制，使用标准回归损失进行训练，并采用严格的时间分割来防止数据泄露。

Result: 在UCI Online Retail II数据集上的实验表明，该模型在MAE、RMSE、sMAPE、MASE和Theil's U_2等指标上持续优于ARIMA/Prophet、LSTM/GRU、LightGBM以及最先进的Transformer预测器（TFT、Informer、Autoformer、N-BEATS），在峰值/节假日期间表现出更好的鲁棒性。

Conclusion: 提出的混合序列模型在电子商务需求预测任务中实现了显著的准确度提升和鲁棒性改进，并通过消融实验和统计显著性测试验证了改进的可靠性，同时提供了实现细节以确保可复现性。

Abstract: The advent of financial technology has witnessed a surge in the utilization of deep learning models to anticipate consumer conduct, a trend that has demonstrated considerable potential in enhancing lending strategies and bolstering market efficiency. We study multi-horizon demand forecasting on e-commerce transactions using the UCI Online Retail II dataset. Unlike prior versions of this manuscript that mixed financial-loan narratives with retail data, we focus exclusively on retail market behavior and define a clear prediction target: per SKU daily demand (or revenue) for horizons H=1,7,14. We present a hybrid sequence model that combines multi-scale temporal convolutions, a gated recurrent module, and time-aware self-attention. The model is trained with standard regression losses and evaluated under MAE, RMSE, sMAPE, MASE, and Theil's U_2 with strict time-based splits to prevent leakage. We benchmark against ARIMA/Prophet, LSTM/GRU, LightGBM, and state-of-the-art Transformer forecasters (TFT, Informer, Autoformer, N-BEATS). Results show consistent accuracy gains and improved robustness on peak/holiday periods. We further provide ablations and statistical significance tests to ensure the reliability of improvements, and we release implementation details to facilitate reproducibility.

</details>


### [400] [The Core in Max-Loss Non-Centroid Clustering Can Be Empty](https://arxiv.org/abs/2511.19107)
*Robert Bredereck,Eva Deltl,Leon Kellerhals,Jannik Peters*

Main category: cs.LG

TL;DR: 本文研究了在最大损失目标下的非质心聚类中的核心稳定性问题，证明了对于k≥3的情况，存在度量实例使得没有任何聚类位于α-核心中，其中α<2^(1/5)≈1.148。


<details>
  <summary>Details</summary>
Motivation: 研究非质心聚类中核心稳定性的存在性问题，特别是在最大损失目标下，填补了该领域缺乏不可能性结果的空白。

Method: 使用数学证明和计算机辅助证明方法，构建了度量实例和二维欧几里得点集来分析核心稳定性。

Result: 证明了对于k≥3且n≥9（n可被k整除）的情况，存在度量实例使得没有任何聚类位于α-核心中，其中α<2^(1/5)≈1.148。

Conclusion: 这是首个证明在最大损失目标下的非质心聚类中核心可能为空的不可能性结果，填补了该领域的研究空白。

Abstract: We study core stability in non-centroid clustering under the max-loss objective, where each agent's loss is the maximum distance to other members of their cluster. We prove that for all $k\geq 3$ there exist metric instances with $n\ge 9$ agents, with $n$ divisible by $k$, for which no clustering lies in the $α$-core for any $α<2^{\frac{1}{5}}\sim 1.148$. The bound is tight for our construction. Using a computer-aided proof, we also identify a two-dimensional Euclidean point set whose associated lower bound is slightly smaller than that of our general construction. This is, to our knowledge, the first impossibility result showing that the core can be empty in non-centroid clustering under the max-loss objective.

</details>


### [401] [Uncertainty-Aware Deep Learning Framework for Remaining Useful Life Prediction in Turbofan Engines with Learned Aleatoric Uncertainty](https://arxiv.org/abs/2511.19124)
*Krishang Sharma*

Main category: cs.LG

TL;DR: 提出了一种新颖的不确定性感知深度学习框架，用于航空航天预测中的剩余使用寿命预测，通过概率建模直接学习偶然不确定性，在NASA CMAPSS基准测试中取得了突破性的关键区域性能。


<details>
  <summary>Details</summary>
Motivation: 准确预测剩余使用寿命并进行不确定性量化是航空航天预测中的关键挑战，现有CMAPSS文献中尚未探索通过概率建模直接学习偶然不确定性的方法。

Method: 分层架构集成多尺度Inception块进行时间模式提取、双向LSTM进行序列建模、传感器和时间维度的双重注意力机制，以及贝叶斯输出层预测均值和方差。

Result: 在NASA CMAPSS基准测试中，总体RMSE分别为16.22、19.29、16.84和19.98，关键区域性能（RUL≤30周期）RMSE为5.14、6.89、5.27和7.16，比传统方法提升25-40%。

Conclusion: 该框架在关键区域预测方面建立了新的基准，学习到的不确定性提供了良好校准的95%置信区间，实现了CMAPSS文献中前所未有的风险感知维护调度能力。

Abstract: Accurate Remaining Useful Life (RUL) prediction coupled with uncertainty quantification remains a critical challenge in aerospace prognostics. This research introduces a novel uncertainty-aware deep learning framework that learns aleatoric uncertainty directly through probabilistic modeling, an approach unexplored in existing CMAPSS-based literature. Our hierarchical architecture integrates multi-scale Inception blocks for temporal pattern extraction, bidirectional Long Short-Term Memory networks for sequential modeling, and a dual-level attention mechanism operating simultaneously on sensor and temporal dimensions. The innovation lies in the Bayesian output layer that predicts both mean RUL and variance, enabling the model to learn data-inherent uncertainty. Comprehensive preprocessing employs condition-aware clustering, wavelet denoising, and intelligent feature selection. Experimental validation on NASA CMAPSS benchmarks (FD001-FD004) demonstrates competitive overall performance with RMSE values of 16.22, 19.29, 16.84, and 19.98 respectively. Remarkably, our framework achieves breakthrough critical zone performance (RUL <= 30 cycles) with RMSE of 5.14, 6.89, 5.27, and 7.16, representing 25-40 percent improvements over conventional approaches and establishing new benchmarks for safety-critical predictions. The learned uncertainty provides well-calibrated 95 percent confidence intervals with coverage ranging from 93.5 percent to 95.2 percent, enabling risk-aware maintenance scheduling previously unattainable in CMAPSS literature.

</details>


### [402] [Masked Diffusion Models are Secretly Learned-Order Autoregressive Models](https://arxiv.org/abs/2511.19152)
*Prateek Garg,Bhavya Kohli,Sunita Sarawagi*

Main category: cs.LG

TL;DR: 该论文提出了一种新的训练框架，通过多元噪声调度来优化掩码扩散模型（MDMs）的解码顺序，证明了MDM目标可以分解为这些顺序上的加权自回归损失。


<details>
  <summary>Details</summary>
Motivation: 现有MDMs在训练时随机解码token的顺序，而解码顺序对性能有显著影响。本文旨在设计一个训练框架来优化解码顺序。

Method: 使用多元噪声调度，在连续时间变分目标中识别和优化解码顺序，建立解码顺序与多元噪声调度的直接对应关系。

Result: 证明了MDM目标可以精确分解为这些顺序上的加权自回归损失，打破了MDM目标对噪声调度的不变性。

Conclusion: MDMs本质上是具有可学习顺序的自回归模型，通过优化解码顺序可以提升模型性能。

Abstract: Masked Diffusion Models (MDMs) have emerged as one of the most promising paradigms for generative modeling over discrete domains. It is known that MDMs effectively train to decode tokens in a random order, and that this ordering has significant performance implications in practice. This observation raises a fundamental question: can we design a training framework that optimizes for a favorable decoding order? We answer this in the affirmative, showing that the continuous-time variational objective of MDMs, when equipped with multivariate noise schedules, can identify and optimize for a decoding order during training. We establish a direct correspondence between decoding order and the multivariate noise schedule and show that this setting breaks invariance of the MDM objective to the noise schedule. Furthermore, we prove that the MDM objective decomposes precisely into a weighted auto-regressive losses over these orders, which establishes them as auto-regressive models with learnable orders.

</details>


### [403] [First-order Sobolev Reinforcement Learning](https://arxiv.org/abs/2511.19165)
*Fabian Schramm,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.LG

TL;DR: 提出一种改进的时间差分学习方法，通过强制一阶贝尔曼一致性来训练价值函数，使其不仅匹配贝尔曼目标值，还匹配其关于状态和动作的导数。


<details>
  <summary>Details</summary>
Motivation: 传统时间差分学习只关注价值函数与贝尔曼目标在数值上的一致性，但忽略了局部几何信息。通过引入一阶导数匹配，可以加速评论家收敛并提高策略梯度的稳定性。

Method: 通过可微动态系统对贝尔曼备份进行微分，获得解析一致的梯度目标。使用Sobolev型损失将这些梯度目标纳入评论家目标函数中，使评论家与目标函数的价值和局部几何对齐。

Result: 该方法可以无缝集成到现有算法中（如Q学习、DDPG、SAC等），无需改变整体结构。

Conclusion: 一阶时间差分匹配原则能够提高评论家收敛速度，增强策略梯度稳定性，为强化学习算法提供了一种有效的改进方法。

Abstract: We propose a refinement of temporal-difference learning that enforces first-order Bellman consistency: the learned value function is trained to match not only the Bellman targets in value but also their derivatives with respect to states and actions. By differentiating the Bellman backup through differentiable dynamics, we obtain analytically consistent gradient targets. Incorporating these into the critic objective using a Sobolev-type loss encourages the critic to align with both the value and local geometry of the target function. This first-order TD matching principle can be seamlessly integrated into existing algorithms, such as Q-learning or actor-critic methods (e.g., DDPG, SAC), potentially leading to faster critic convergence and more stable policy gradients without altering their overall structure.

</details>


### [404] [RAVEN++: Pinpointing Fine-Grained Violations in Advertisement Videos with Active Reinforcement Reasoning](https://arxiv.org/abs/2511.19168)
*Deyi Ji,Yuekui Yang,Liqun Liu,Peng Shu,Haiyang Wu,Shaogang Tang,Xudong Chen,Shaoping Ma,Tianrun Chen,Lanyun Zhu*

Main category: cs.LG

TL;DR: RAVEN++是一个改进的视频广告审核框架，通过主动强化学习、细粒度违规理解和渐进式多阶段训练，解决了现有模型在细粒度理解、可解释性和泛化能力方面的不足。


<details>
  <summary>Details</summary>
Motivation: 视频广告审核面临复杂性和精准违规定位的挑战，现有模型如RAVEN在细粒度理解、可解释性和泛化能力方面存在明显不足。

Method: 提出三个关键创新：1) 主动强化学习动态适应不同难度样本；2) 通过分层奖励函数和推理蒸馏实现细粒度违规理解；3) 渐进式多阶段训练结合知识注入、课程式被动强化学习和主动强化学习。

Result: 在公开和专有数据集上的离线场景和在线A/B测试中，RAVEN++在细粒度违规理解、推理能力和泛化能力方面均优于通用LLM和专门模型如RAVEN。

Conclusion: RAVEN++框架显著提升了视频广告审核的细粒度理解、可解释性和泛化性能，为复杂广告内容审核提供了有效解决方案。

Abstract: Advertising (Ad) is a cornerstone of the digital economy, yet the moderation of video advertisements remains a significant challenge due to their complexity and the need for precise violation localization. While recent advancements, such as the RAVEN model, have improved coarse-grained violation detection, critical gaps persist in fine-grained understanding, explainability, and generalization. To address these limitations, we propose RAVEN++, a novel framework that introduces three key innovations: 1) Active Reinforcement Learning (RL), which dynamically adapts training to samples of varying difficulty; 2) Fine-Grained Violation Understanding, achieved through hierarchical reward functions and reasoning distillation; and 3) Progressive Multi-Stage Training, which systematically combines knowledge injection, curriculum-based passive RL, and active RL. Extensive experiments on both public and proprietary datasets, on both offline scenarios and online deployed A/B Testing, demonstrate that RAVEN++ outperforms general-purpose LLMs and specialized models like RAVEN in terms of fine-grained violation understanding, reasoning capabilities, and generalization ability.

</details>


### [405] [Empirical Comparison of Forgetting Mechanisms for UCB-based Algorithms on a Data-Driven Simulation Platform](https://arxiv.org/abs/2511.19240)
*Minxin Chen*

Main category: cs.LG

TL;DR: 本文提出了FDSW-UCB算法，结合折扣长期视角和滑动窗口短期视角，解决了非平稳环境中多臂老虎机算法的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的老虎机问题常涉及非平稳奖励分布，传统算法如UCB在奖励分布随时间变化的环境中性能显著下降，需要开发适应动态环境的算法。

Method: 提出了FDSW-UCB双视角算法，集成基于折扣的长期视角和基于滑动窗口的短期视角，并开发了基于MovieLens-1M和Open Bandit数据集的半合成仿真平台来测试算法在突变和渐变漂移场景下的适应性。

Result: 实验表明，配置良好的滑动窗口机制(SW-UCB)具有鲁棒性，而广泛使用的折扣方法(D-UCB)存在基本学习失败问题，导致线性遗憾。FDSW-UCB采用乐观聚合策略时在动态环境中表现优异。

Conclusion: 集成策略本身是成功的关键因素，FDSW-UCB在非平稳环境中实现了优越性能，证明了双视角方法在动态老虎机问题中的有效性。

Abstract: Many real-world bandit problems involve non-stationary reward distributions, where the optimal decision may shift due to evolving environments. However, the performance of some typical Multi-Armed Bandit (MAB) models such as Upper Confidence Bound (UCB) algorithms degrades significantly in non-stationary environments where reward distributions change over time. To address this limitation, this paper introduces and evaluates FDSW-UCB, a novel dual-view algorithm that integrates a discount-based long-term perspective with a sliding-window-based short-term view. A data-driven semi-synthetic simulation platform, built upon the MovieLens-1M and Open Bandit datasets, is developed to test algorithm adaptability under abrupt and gradual drift scenarios. Experimental results demonstrate that a well-configured sliding-window mechanism (SW-UCB) is robust, while the widely used discounting method (D-UCB) suffers from a fundamental learning failure, leading to linear regret. Crucially, the proposed FDSW-UCB, when employing an optimistic aggregation strategy, achieves superior performance in dynamic settings, highlighting that the ensemble strategy itself is a decisive factor for success.

</details>


### [406] [Local Entropy Search over Descent Sequences for Bayesian Optimization](https://arxiv.org/abs/2511.19241)
*David Stenger,Armin Lindicke,Alexander von Rohr,Sebastian Trimpe*

Main category: cs.LG

TL;DR: 本文提出了局部熵搜索（LES），一种贝叶斯优化方法，专门针对迭代优化器的下降序列可达解进行搜索，通过传播后验信念并最大化与下降序列分布的互信息来实现高效的局部优化。


<details>
  <summary>Details</summary>
Motivation: 在大型复杂设计空间中搜索全局最优解可能不可行且不必要，因此需要一种实用的替代方法，即使用局部优化方法（如梯度下降）迭代细化初始设计的邻域。

Method: 提出局部熵搜索（LES）算法，通过优化器传播目标函数的后验信念，得到下降序列的概率分布，然后结合解析熵计算和蒙特卡洛采样来最大化与该分布的互信息，选择下一个评估点。

Result: 在高复杂度合成目标和基准问题上的实证结果表明，LES相比现有的局部和全局贝叶斯优化方法具有更强的样本效率。

Conclusion: 局部熵搜索是一种有效的贝叶斯优化范式，能够针对迭代优化器的下降序列进行高效搜索，在样本效率方面优于现有方法。

Abstract: Searching large and complex design spaces for a global optimum can be infeasible and unnecessary. A practical alternative is to iteratively refine the neighborhood of an initial design using local optimization methods such as gradient descent. We propose local entropy search (LES), a Bayesian optimization paradigm that explicitly targets the solutions reachable by the descent sequences of iterative optimizers. The algorithm propagates the posterior belief over the objective through the optimizer, resulting in a probability distribution over descent sequences. It then selects the next evaluation by maximizing mutual information with that distribution, using a combination of analytic entropy calculations and Monte-Carlo sampling of descent sequences. Empirical results on high-complexity synthetic objectives and benchmark problems show that LES achieves strong sample efficiency compared to existing local and global Bayesian optimization methods.

</details>


### [407] [A Nutrition Multimodal Photoplethysmography Language Model](https://arxiv.org/abs/2511.19260)
*Kyle Verrier,Achille Nazaret,Joseph Futoma,Andrew C. Miller,Guillermo Sapiro*

Main category: cs.LG

TL;DR: 提出了一个结合可穿戴设备光电容积脉搏波(PPG)和饮食描述的营养光电容积脉搏波语言模型(NPLM)，用于无创监测饮食摄入。


<details>
  <summary>Details</summary>
Motivation: 饥饿和饱腹感动态影响饮食行为和代谢健康，但在日常环境中难以捕捉。需要开发能够整合生理测量和饮食信息的非侵入性监测方法。

Method: 开发NPLM模型，将可穿戴设备的连续PPG信号投影到语言模型可解释的嵌入空间，实现生理数据和饮食背景的联合推理。基于19,340名参与者和110万餐食-PPG对进行训练。

Result: 模型将每日热量摄入预测准确率比纯文本基线提高了11%，即使去除80%的餐食文本信息仍能保持准确性。在独立验证研究(n=140)中复现了这些发现。

Conclusion: 结果表明整合消费者可穿戴设备的生理测量与饮食信息对于大规模非侵入性饮食监测具有重要价值。

Abstract: Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet remain difficult to capture in everyday settings. We present a Nutrition Photoplethysmography Language Model (NPLM), integrating continuous photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects PPG into embeddings interpretable by language models, enabling joint reasoning over physiology and meal context. Trained on 19,340 participants and 1.1 million meal-PPG pairs, the model improved daily caloric intake prediction by 11% over text-only baselines, with accuracy maintained when 80% of meal text was removed. In an independent validation study (n=140) with controlled dining and detailed meal information, the model replicated these findings. These results demonstrate the value of integrating physiological measurements from consumer wearables with meal information for noninvasive dietary monitoring at scale.

</details>


### [408] [CDLM: Consistency Diffusion Language Models For Faster Sampling](https://arxiv.org/abs/2511.19269)
*Minseo Kim,Chenfeng Xu,Coleman Hooper,Harman Singh,Ben Athiwaratkun,Ce Zhang,Kurt Keutzer,Amir Gholami*

Main category: cs.LG

TL;DR: CDLM通过整合一致性建模和块级因果注意力掩码，解决了扩散语言模型推理速度慢的问题，实现了3.6x-14.5x的延迟降低，同时保持数学和编程任务的竞争性准确率。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然提供了有前景的并行生成范式，但由于需要大量细化步骤且无法使用标准KV缓存，导致推理速度缓慢。

Method: CDLM整合一致性建模以大幅减少所需采样步骤，通过启用多令牌最终化；同时在微调期间强制执行块级因果注意力掩码，使模型完全兼容KV缓存。

Result: 实验显示CDLM在数学和编程任务上实现了3.6x-14.5x的延迟降低，同时保持竞争性准确率。

Conclusion: CDLM是解决扩散语言模型推理瓶颈的有效训练加速方法，代码已开源。

Abstract: Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.

</details>


### [409] [Closing Gaps in Emissions Monitoring with Climate TRACE](https://arxiv.org/abs/2511.19277)
*Brittany V. Lancellotti,Jordan M. Malof,Aaron Davitt,Gavin McCormick,Shelby Anderson,Pol Carbó-Mestre,Gary Collins,Verity Crane,Zoheyr Doctor,George Ebri,Kevin Foster,Trey M. Gowdy,Michael Guzzardi,John Heal,Heather Hunter,David Kroodsma,Khandekar Mahammad Galib,Paul J. Markakis,Gavin McDonald,Daniel P. Moore,Eric D. Nguyen,Sabina Parvu,Michael Pekala,Christine D. Piatko,Amy Piscopo,Mark Powell,Krsna Raniga,Elizabeth P. Reilly,Michael Robinette,Ishan Saraswat,Patrick Sicurello,Isabella Söldner-Rembold,Raymond Song,Charlotte Underwood,Kyle Bradbury*

Main category: cs.LG

TL;DR: Climate TRACE是一个开放获取平台，提供全球温室气体排放估算，具有更高的细节、覆盖范围和及时性，支持数据驱动的气候行动。


<details>
  <summary>Details</summary>
Motivation: 现有排放数据集缺乏准确性、全球覆盖、高时空分辨率和频繁更新等关键特征，限制了其行动性。

Method: 综合现有排放数据，优先考虑准确性、覆盖范围和分辨率，并使用部门特定的估算方法填补数据空白。

Result: 首次提供全球范围内所有人为排放部门的单个排放源（如单个发电厂）的综合排放估算，数据集从2021年1月1日至今，具有两个月报告延迟和每月更新。

Conclusion: Climate TRACE代表了排放核算和减缓的重大突破，支持在决策层面进行数据驱动的气候行动。

Abstract: Global greenhouse gas emissions estimates are essential for monitoring and mitigation planning. Yet most datasets lack one or more characteristics that enhance their actionability, such as accuracy, global coverage, high spatial and temporal resolution, and frequent updates. To address these gaps, we present Climate TRACE (climatetrace.org), an open-access platform delivering global emissions estimates with enhanced detail, coverage, and timeliness. Climate TRACE synthesizes existing emissions data, prioritizing accuracy, coverage, and resolution, and fills gaps using sector-specific estimation approaches. The dataset is the first to provide globally comprehensive emissions estimates for individual sources (e.g., individual power plants) for all anthropogenic emitting sectors. The dataset spans January 1, 2021, to the present, with a two-month reporting lag and monthly updates. The open-access platform enables non-technical audiences to engage with detailed emissions datasets for most subnational governments worldwide. Climate TRACE supports data-driven climate action at scales where decisions are made, representing a major breakthrough for emissions accounting and mitigation.

</details>


### [410] [MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings](https://arxiv.org/abs/2511.19279)
*Victor Rambaud,Salvador Mascarenhas,Yair Lakretz*

Main category: cs.LG

TL;DR: MapFormers是基于Transformer的新架构，能够从观测数据中学习认知地图并进行路径整合，通过输入依赖的位置编码实现结构与内容的解耦，在OOD泛化方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统缺乏人类和动物所具有的认知地图能力，无法灵活适应新情境并实现强OOD泛化。为了弥合这一差距，需要开发能够学习认知地图的模型。

Method: 提出MapFormers架构，通过更新Transformer中的位置编码为输入依赖矩阵，自然实现结构与内容的解耦。开发了两种变体：绝对位置编码建模情景记忆(EM)，相对位置编码建模工作记忆(WM)。

Result: 在2D导航等任务中测试表明，MapFormers能够学习底层空间的认知地图，并在OOD泛化（如更长序列）方面达到接近完美的性能，优于现有架构。

Conclusion: 结果表明，设计用于学习认知地图的模型具有优越性，结构-内容解耦的结构偏置在Transformer中通过输入依赖位置编码实现，MapFormers在神经科学和AI领域都有广泛应用前景。

Abstract: A cognitive map is an internal model which encodes the abstract relationships among entities in the world, giving humans and animals the flexibility to adapt to new situations, with a strong out-of-distribution (OOD) generalization that current AI systems still do not possess. To bridge this gap, we introduce MapFormers, new architectures based on Transformer models, which can learn cognitive maps from observational data and perform path integration in parallel, in a self-supervised manner. Cognitive maps are learned in the model by disentangling structural relationships in the inputs from their specific content, a property that can be achieved naturally by updating the positional encoding in Transformers with input-dependent matrices. We developed two variants of MapFormers that unify absolute and relative positional encoding to model episodic (EM) and working memory (WM), respectively. We tested MapFormers on several tasks, including a classic 2D navigation task, showing that our models can learn a cognitive map of the underlying space and generalize OOD (e.g., to longer sequences) with near-perfect performance, unlike current architectures. Together, these results demonstrate the superiority of models designed to learn a cognitive map, and the importance of introducing a structural bias for structure-content disentanglement, which can be achieved in Transformers with input-dependent positional encoding. MapFormers have broad applications in both neuroscience and AI, by explaining the neural mechanisms giving rise to cognitive maps, while allowing these relation models to be learned at scale.

</details>


### [411] [Open-weight genome language model safeguards: Assessing robustness via adversarial fine-tuning](https://arxiv.org/abs/2511.19299)
*James R. M. Black,Moritz S. Hanke,Aaron Maiwald,Tina Hernandez-Boussard,Oliver M. Crook,Jaspreet Pannu*

Main category: cs.LG

TL;DR: 本研究评估了基因组语言模型（gLM）在微调后恢复有害病毒预测能力的风险，发现即使预训练时排除病毒数据，通过微调仍能恢复模型对有害人类感染病毒的预测能力，包括识别SARS-CoV-2免疫逃逸变异。


<details>
  <summary>Details</summary>
Motivation: 随着基因组语言模型在生物数据中的应用日益增多，这些模型可能被滥用于生成人类感染病毒的基因组，引发安全担忧。当前主要通过在预训练数据中过滤病毒序列来降低风险，但这种方法对可微调的开源模型的有效性尚不明确。

Method: 使用最先进的基因组语言模型Evo 2，在110种有害人类感染病毒的序列上进行微调，评估模型恢复与滥用相关的预测能力。同时设置对照组，包括预训练模型和在噬菌体序列上微调的模型。

Result: 在人类感染病毒上微调的模型对未见病毒序列的困惑度显著降低，且能够识别SARS-CoV-2免疫逃逸变异（AUROC为0.6），尽管微调过程中未接触SARS-CoV-2序列。

Conclusion: 数据排除策略可能被微调方法规避，基因组语言模型仍能恢复与滥用相关的能力。需要建立gLM的安全框架，并进一步研究评估和缓解措施以确保安全部署。

Abstract: Novel deep learning architectures are increasingly being applied to biological data, including genetic sequences. These models, referred to as genomic language mod- els (gLMs), have demonstrated impressive predictive and generative capabilities, raising concerns that such models may also enable misuse, for instance via the generation of genomes for human-infecting viruses. These concerns have catalyzed calls for risk mitigation measures. The de facto mitigation of choice is filtering of pretraining data (i.e., removing viral genomic sequences from training datasets) in order to limit gLM performance on virus-related tasks. However, it is not currently known how robust this approach is for securing open-source models that can be fine-tuned using sensitive pathogen data. Here, we evaluate a state-of-the-art gLM, Evo 2, and perform fine-tuning using sequences from 110 harmful human-infecting viruses to assess the rescue of misuse-relevant predictive capabilities. The fine- tuned model exhibited reduced perplexity on unseen viral sequences relative to 1) the pretrained model and 2) a version fine-tuned on bacteriophage sequences. The model fine-tuned on human-infecting viruses also identified immune escape variants from SARS-CoV-2 (achieving an AUROC of 0.6), despite having no expo- sure to SARS-CoV-2 sequences during fine-tuning. This work demonstrates that data exclusion might be circumvented by fine-tuning approaches that can, to some degree, rescue misuse-relevant capabilities of gLMs. We highlight the need for safety frameworks for gLMs and outline further work needed on evaluations and mitigation measures to enable the safe deployment of gLMs.

</details>


### [412] [Understanding the Staged Dynamics of Transformers in Learning Latent Structure](https://arxiv.org/abs/2511.19328)
*Rohan Saha,Farzane Aminmansour,Alona Fyshe*

Main category: cs.LG

TL;DR: 本文研究了transformer模型学习潜在结构的动态过程，发现在Alchemy基准测试中，模型通过离散阶段逐步学习，先掌握粗粒度规则，再学习完整的潜在结构，并揭示了组合与分解能力的不对称性。


<details>
  <summary>Details</summary>
Motivation: 理解transformer模型如何从上下文中发现潜在结构，特别是不同结构组件学习的动态过程仍然不清楚，需要深入研究。

Method: 在Alchemy基准上训练小型仅解码器transformer，研究三个任务变体：从部分上下文推断缺失规则、组合简单规则解决多步序列、分解复杂多步示例推断中间步骤，通过将任务分解为可解释事件来分析学习过程。

Result: 模型以离散阶段获取能力，先学习粗粒度规则，后学习完整潜在结构；发现关键不对称性：模型能稳健组合基本规则，但难以分解复杂示例来发现基本规则。

Conclusion: 这些发现为理解transformer模型如何学习潜在结构提供了新见解，展示了训练过程中这些能力如何逐步演化的细粒度视图。

Abstract: While transformers can discover latent structure from context, the dynamics of how they acquire different components of the latent structure remain poorly understood. In this work, we use the Alchemy benchmark, to investigate the dynamics of latent structure learning. We train a small decoder-only transformer on three task variants: 1) inferring missing rules from partial contextual information, 2) composing simple rules to solve multi-step sequences, and 3) decomposing complex multi-step examples to infer intermediate steps. By factorizing each task into interpretable events, we show that the model acquires capabilities in discrete stages, first learning the coarse grained rules, before learning the complete latent structure. We also identify a crucial asymmetry, where the model can compose fundamental rules robustly, but struggles to decompose complex examples to discover the fundamental rules. These findings offer new insights into understanding how a transformer model learns latent structures, providing a granular view of how these capabilities evolve during training.

</details>


### [413] [Targeted Manipulation: Slope-Based Attacks on Financial Time-Series Data](https://arxiv.org/abs/2511.19330)
*Dominik Luszczynski*

Main category: cs.LG

TL;DR: 本文提出了两种基于斜率的时间序列对抗攻击方法，能够操纵N-HiTS模型的股票预测结果，使预测斜率翻倍，并能绕过标准安全机制。同时将斜率方法集成到GAN架构中生成逼真合成数据，并展示了在模型推理库中注入对抗攻击的恶意软件示例。


<details>
  <summary>Details</summary>
Motivation: 对抗攻击在图像领域已有深入研究，但在时间序列领域，特别是金融预测数据方面的研究较少。本研究旨在扩展时间序列对抗攻击的研究，针对金融数据预测模型开发新的攻击方法。

Method: 提出了两种新的基于斜率的攻击方法：通用斜率攻击和最小二乘斜率攻击，用于改变N-HiTS模型预测的股票趋势。将这些斜率方法集成到GAN架构中生成合成数据，并设计了一个恶意软件示例来演示在模型推理库中注入对抗攻击。

Result: 两种斜率攻击方法能够成功操纵N-HiTS预测，使预测斜率翻倍。这些攻击能够绕过标准安全机制，将4层CNN鉴别器的特异性降低到28%，准确率降低到57%。GAN架构能够生成逼真的合成数据并同时欺骗模型。

Conclusion: 机器学习安全研究不应只关注模型本身的安全性，还需要保护整个数据处理流程。基于斜率的对抗攻击方法对金融时间序列预测模型构成严重威胁，需要开发更全面的安全防护措施。

Abstract: A common method of attacking deep learning models is through adversarial attacks, which occur when an attacker specifically modifies the input of a model to produce an incorrect result. Adversarial attacks have been deeply investigated in the image domain; however, there is less research in the time-series domain and very little for forecasting financial data. To address these concerns, this study aims to build upon previous research on adversarial attacks for time-series data by introducing two new slope-based methods aimed to alter the trends of the predicted stock forecast generated by an N-HiTS model. Compared to the normal N-HiTS predictions, the two new slope-based methods, the General Slope Attack and Least-Squares Slope Attack, can manipulate N-HiTS predictions by doubling the slope. These new slope attacks can bypass standard security mechanisms, such as a discriminator that filters real and perturbed inputs, reducing a 4-layered CNN's specificity to 28% and accuracy to 57%. Furthermore, the slope based methods were incorporated into a GAN architecture as a means of generating realistic synthetic data, while simultaneously fooling the model. Finally, this paper also proposes a sample malware designed to inject an adversarial attack in the model inference library, proving that ML-security research should not only focus on making the model safe, but also securing the entire pipeline.

</details>


### [414] [Annotation-Free Class-Incremental Learning](https://arxiv.org/abs/2511.19344)
*Hari Chandana Kuchibhotla,K S Ananth,Vineeth N Balasubramanian*

Main category: cs.LG

TL;DR: 本文提出了无标注类增量学习（AFCIL）新范式，并开发了CrossWorld CL框架，利用外部世界知识作为稳定辅助源，在无监督情况下实现持续学习。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法依赖于标注数据的强假设，但现实世界中数据通常以无标注形式顺序到达，需要开发更实用的无监督持续学习方案。

Method: 提出CrossWorld CL框架：为每个下游类别检索语义相关的ImageNet类别，通过跨域对齐策略映射特征，并引入新颖的重放策略。

Result: 在四个数据集上的实验表明，CrossWorld CL超越了CLIP基线和现有持续学习及无标注学习方法。

Conclusion: 世界知识对无标注持续学习具有显著益处，CrossWorld CL框架能有效发现语义结构并保持先前知识。

Abstract: Despite significant progress in continual learning ranging from architectural novelty to clever strategies for mitigating catastrophic forgetting most existing methods rest on a strong but unrealistic assumption the availability of labeled data throughout the learning process. In real-world scenarios, however, data often arrives sequentially and without annotations, rendering conventional approaches impractical. In this work, we revisit the fundamental assumptions of continual learning and ask: Can current systems adapt when labels are absent and tasks emerge incrementally over time? To this end, we introduce Annotation-Free Class-Incremental Learning (AFCIL), a more realistic and challenging paradigm where unlabeled data arrives continuously, and the learner must incrementally acquire new classes without any supervision. To enable effective learning under AFCIL, we propose CrossWorld CL, a Cross Domain World Guided Continual Learning framework that incorporates external world knowledge as a stable auxiliary source. The method retrieves semantically related ImageNet classes for each downstream category, maps downstream and ImageNet features through a cross domain alignment strategy and finally introduce a novel replay strategy. This design lets the model uncover semantic structure without annotations while keeping earlier knowledge intact. Across four datasets, CrossWorld-CL surpasses CLIP baselines and existing continual and unlabeled learning methods, underscoring the benefit of world knowledge for annotation free continual learning.

</details>


### [415] [Scalable Parameter-Light Spectral Method for Clustering Short Text Embeddings with a Cohesion-Based Evaluation Metric](https://arxiv.org/abs/2511.19350)
*Nikita Neveditsin,Pawan Lingras,Vijay Mago*

Main category: cs.LG

TL;DR: 提出了一种可扩展的光谱方法，通过拉普拉斯特征谱结构自动估计聚类数量，并引入Cohesion Ratio指标进行无监督聚类质量评估。


<details>
  <summary>Details</summary>
Motivation: 短文本嵌入聚类需要预先指定聚类数量，这在实际应用中具有挑战性。需要开发能够自动估计聚类数量并评估聚类质量的方法。

Method: 使用基于余弦相似度的拉普拉斯特征谱结构估计聚类数量，结合自适应采样策略实现可扩展性。提出Cohesion Ratio指标评估聚类质量。

Result: 在六个短文本数据集和四个嵌入模型上的实验表明，使用该方法指导的K-Means和HAC算法显著优于HDBSCAN、OPTICS和Leiden等参数较少的方法。

Conclusion: 该方法为短文本数据的无监督组织和评估提供了实用的光谱估计器和评估指标。

Abstract: Clustering short text embeddings is a foundational task in natural language processing, yet remains challenging due to the need to specify the number of clusters in advance. We introduce a scalable spectral method that estimates the number of clusters directly from the structure of the Laplacian eigenspectrum, constructed using cosine similarities and guided by an adaptive sampling strategy. This sampling approach enables our estimator to efficiently scale to large datasets without sacrificing reliability. To support intrinsic evaluation of cluster quality without ground-truth labels, we propose the Cohesion Ratio, a simple and interpretable evaluation metric that quantifies how much intra-cluster similarity exceeds the global similarity background. It has an information-theoretic motivation inspired by mutual information, and in our experiments it correlates closely with extrinsic measures such as normalized mutual information and homogeneity. Extensive experiments on six short-text datasets and four modern embedding models show that standard algorithms like K-Means and HAC, when guided by our estimator, significantly outperform popular parameter-light methods such as HDBSCAN, OPTICS, and Leiden. These results demonstrate the practical value of our spectral estimator and Cohesion Ratio for unsupervised organization and evaluation of short text data. Implementation of our estimator of k and Cohesion Ratio, along with code for reproducing the experiments, is available at https://anonymous.4open.science/r/towards_clustering-0C2E.

</details>


### [416] [Leveraging LLMs for reward function design in reinforcement learning control tasks](https://arxiv.org/abs/2511.19355)
*Franklin Cardenoso,Wouter Caarls*

Main category: cs.LG

TL;DR: LEARN-Opt是一个基于LLM的完全自主、模型无关的框架，用于从系统描述和任务目标自动生成、执行和评估奖励函数，无需初步指标和环境源代码。


<details>
  <summary>Details</summary>
Motivation: 强化学习中设计有效奖励函数是一个重大瓶颈，需要大量人工专业知识且耗时。现有方法需要初步评估指标、人工反馈或环境源代码作为上下文。

Method: 引入LEARN-Opt框架，能够从系统描述和任务目标自主推导性能指标，实现无监督的奖励函数评估和选择。

Result: 实验表明LEARN-Opt性能与最先进方法（如EUREKA）相当或更好，且需要较少先验知识。能够利用低成本LLM找到高性能候选方案。

Conclusion: LEARN-Opt有潜力在不需任何初步人工定义指标的情况下生成高质量奖励函数，减少工程开销并增强通用性。

Abstract: The challenge of designing effective reward functions in reinforcement learning (RL) represents a significant bottleneck, often requiring extensive human expertise and being time-consuming. Previous work and recent advancements in large language models (LLMs) have demonstrated their potential for automating the generation of reward functions. However, existing methodologies often require preliminary evaluation metrics, human-engineered feedback for the refinement process, or the use of environmental source code as context. To address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator and Analyzer for Reward functioN Optimization). This LLM-based, fully autonomous, and model-agnostic framework eliminates the need for preliminary metrics and environmental source code as context to generate, execute, and evaluate reward function candidates from textual descriptions of systems and task objectives. LEARN-Opt's main contribution lies in its ability to autonomously derive performance metrics directly from the system description and the task objective, enabling unsupervised evaluation and selection of reward functions. Our experiments indicate that LEARN-Opt achieves performance comparable to or better to that of state-of-the-art methods, such as EUREKA, while requiring less prior knowledge. We find that automated reward design is a high-variance problem, where the average-case candidate fails, requiring a multi-run approach to find the best candidates. Finally, we show that LEARN-Opt can unlock the potential of low-cost LLMs to find high-performing candidates that are comparable to, or even better than, those of larger models. This demonstrated performance affirms its potential to generate high-quality reward functions without requiring any preliminary human-defined metrics, thereby reducing engineering overhead and enhancing generalizability.

</details>


### [417] [Enhancing Conformal Prediction via Class Similarity](https://arxiv.org/abs/2511.19359)
*Ariel Fargion,Lahav Dabah,Tom Tirer*

Main category: cs.LG

TL;DR: 本文提出了一种基于类别相似性的共形预测增强方法，通过惩罚组外错误和利用类别相似性来减少预测集大小，同时保证预测集包含真实标签的概率。


<details>
  <summary>Details</summary>
Motivation: 在类别可以按语义分组的场景中，用户不仅需要平均预测集大小小的共形预测方法，还需要预测集包含的语义不同组数尽可能少。

Method: 提出在共形预测评分函数中增加惩罚组外错误的项，并基于类别相似性提出模型特定的变体，无需人工语义划分。

Result: 理论分析证明该方法在组相关指标上有优势，并能减少平均预测集大小。实验表明该方法能持续增强多种共形预测方法。

Conclusion: 基于类别相似性的方法可以有效提升共形预测方法的性能，减少预测集大小，适用于各种数据集和模型。

Abstract: Conformal Prediction (CP) has emerged as a powerful statistical framework for high-stakes classification applications. Instead of predicting a single class, CP generates a prediction set, guaranteed to include the true label with a pre-specified probability. The performance of different CP methods is typically assessed by their average prediction set size. In setups where the classes can be partitioned into semantic groups, e.g., diseases that require similar treatment, users can benefit from prediction sets that are not only small on average, but also contain a small number of semantically different groups. This paper begins by addressing this problem and ultimately offers a widely applicable tool for boosting any CP method on any dataset. First, given a class partition, we propose augmenting the CP score function with a term that penalizes predictions with out-of-group errors. We theoretically analyze this strategy and prove its advantages for group-related metrics. Surprisingly, we show mathematically that, for common class partitions, it can also reduce the average set size of any CP score function. Our analysis reveals the class similarity factors behind this improvement and motivates us to propose a model-specific variant, which does not require any human semantic partition and can further reduce the prediction set size. Finally, we present an extensive empirical study, encompassing prominent CP methods, multiple models, and several datasets, which demonstrates that our class-similarity-based approach consistently enhances CP methods.

</details>


### [418] [Predicting partially observable dynamical systems via diffusion models with a multiscale inference scheme](https://arxiv.org/abs/2511.19390)
*Rudy Morel,Francesco Pio Ramunno,Jeff Shen,Alberto Bietti,Kyunghyun Cho,Miles Cranmer,Siavash Golkar,Olexandr Gugnin,Geraud Krawezik,Tanya Marwah,Michael McCabe,Lucas Meyer,Payel Mukhopadhyay,Ruben Ohana,Liam Parker,Helen Qu,François Rozet,K. D. Leka,François Lanusse,David Fouhey,Shirley Ho*

Main category: cs.LG

TL;DR: 本文提出了一种用于部分可观测、长记忆动力系统概率预测的多尺度推理方案，特别针对太阳动力学等应用场景，解决了传统自回归方法无法有效捕捉长期依赖关系的问题。


<details>
  <summary>Details</summary>
Motivation: 在许多动态系统预测场景中，可用信息仅代表预测未来状态所需信息的一小部分，如太阳物理中只能观测表面和大气而无法直接测量内部过程。标准推理方案无法有效整合过去信息来捕捉数据中的长期依赖关系。

Method: 提出了一种针对物理过程定制的多尺度推理方案，生成在时间上靠近当前时刻精细、远离当前时刻粗糙的轨迹，从而在不增加计算成本的情况下捕捉长期时间依赖关系。

Result: 当集成到扩散模型中时，该推理方案显著减少了预测分布的偏差，并提高了展开稳定性。

Conclusion: 多尺度推理方案能够有效解决部分可观测、长记忆动力系统的概率预测问题，在太阳动力学等应用中表现出色。

Abstract: Conditional diffusion models provide a natural framework for probabilistic prediction of dynamical systems and have been successfully applied to fluid dynamics and weather prediction. However, in many settings, the available information at a given time represents only a small fraction of what is needed to predict future states, either due to measurement uncertainty or because only a small fraction of the state can be observed. This is true for example in solar physics, where we can observe the Sun's surface and atmosphere, but its evolution is driven by internal processes for which we lack direct measurements. In this paper, we tackle the probabilistic prediction of partially observable, long-memory dynamical systems, with applications to solar dynamics and the evolution of active regions. We show that standard inference schemes, such as autoregressive rollouts, fail to capture long-range dependencies in the data, largely because they do not integrate past information effectively. To overcome this, we propose a multiscale inference scheme for diffusion models, tailored to physical processes. Our method generates trajectories that are temporally fine-grained near the present and coarser as we move farther away, which enables capturing long-range temporal dependencies without increasing computational cost. When integrated into a diffusion model, we show that our inference scheme significantly reduces the bias of the predicted distributions and improves rollout stability.

</details>


### [419] [Learning Robust Social Strategies with Large Language Models](https://arxiv.org/abs/2511.19405)
*Dereck Piche,Mohammed Muqeeth,Milad Aghajohari,Juan Duque,Michael Noukhovitch,Aaron Courville*

Main category: cs.LG

TL;DR: 本文研究了在多智能体交互中，强化学习训练的LLM智能体倾向于发展自私行为的问题，并提出了一种优势对齐算法来促进多智能体合作和抗剥削能力。


<details>
  <summary>Details</summary>
Motivation: 随着智能体AI的普及，具有不同甚至冲突目标的智能体将在复杂环境中交互。在多智能体社会困境中，个体激励可能损害集体福利，而标准强化学习往往收敛到自私策略。

Method: 采用对手学习意识算法——优势对齐，对LLM进行微调以促进多智能体合作；引入组相对基线简化迭代游戏中的优势计算；创建新的社会困境环境"信任与分割"，需要自然语言沟通实现高集体福利。

Result: 在各种社会困境中，通过优势对齐学习的策略实现了更高的集体收益，同时保持对贪婪智能体剥削的鲁棒性。

Conclusion: 优势对齐算法能有效解决强化学习在多智能体设置中收敛到不良均衡的问题，使LLM智能体在保持合作性的同时增强抗剥削能力。

Abstract: As agentic AI becomes more widespread, agents with distinct and possibly conflicting goals will interact in complex ways. These multi-agent interactions pose a fundamental challenge, particularly in social dilemmas, where agents' individual incentives can undermine collective welfare. While reinforcement learning (RL) has been effective for aligning large language models (LLMs) in the single-agent regime, prior small-network results suggest that standard RL in multi-agent settings often converges to defecting, self-interested policies. We show the same effect in LLMs: despite cooperative priors, RL-trained LLM agents develop opportunistic behavior that can exploit even advanced closed-source models. To address this tendency of RL to converge to poor equilibria, we adapt a recent opponent-learning awareness algorithm, Advantage Alignment, to fine-tune LLMs toward multi-agent cooperation and non-exploitability. We then introduce a group-relative baseline that simplifies advantage computation in iterated games, enabling multi-agent training at LLM scale. We also contribute a novel social dilemma environment, Trust and Split, which requires natural language communication to achieve high collective welfare. Across a wide range of social dilemmas, policies learned with Advantage Alignment achieve higher collective payoffs while remaining robust against exploitation by greedy agents.

</details>


### [420] [UniGame: Turning a Unified Multimodal Model Into Its Own Adversary](https://arxiv.org/abs/2511.19413)
*Zhaolong Su,Wang Lu,Hao Chen,Sharon Li,Jindong Wang*

Main category: cs.LG

TL;DR: UniGame是一个自对抗后训练框架，通过轻量级扰动器解决统一多模态模型中理解与生成之间的不一致性问题，显著提升模型的一致性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型存在根本性不一致：理解偏好紧凑嵌入，而生成偏好重建丰富的表示，这种结构权衡导致决策边界错位、跨模态连贯性下降以及对分布和对抗性变化的脆弱性。

Method: 在共享令牌接口应用轻量级扰动器，使生成分支主动寻找和挑战脆弱的理解，将模型自身变成其对手，实现自对抗训练。

Result: UniGame显著提升一致性(+4.6%)、理解能力(+3.6%)、生成质量(+0.02)，在NaturalBench和AdVQA上的分布外和对抗鲁棒性分别提升+4.8%和+6.2%。

Conclusion: 对抗性自博弈是增强未来多模态基础模型连贯性、稳定性和统一能力的通用有效原则，该框架架构无关，仅引入不到1%额外参数，且与现有后训练方法互补。

Abstract: Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame

</details>


### [421] [Flow Map Distillation Without Data](https://arxiv.org/abs/2511.19428)
*Shangyuan Tong,Nanye Ma,Saining Xie,Tommi Jaakkola*

Main category: cs.LG

TL;DR: 本文提出了一种无需外部数据的流映射蒸馏方法，通过仅从先验分布采样来避免教师-数据不匹配问题，实现了单步采样的高质量图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有流模型蒸馏方法依赖外部数据集，存在教师-数据不匹配风险，可能导致对教师生成能力的不完整或错误表示。本文旨在探索无需数据的蒸馏替代方案。

Method: 引入一个原则性框架，仅从先验分布采样，学习预测教师的采样路径，同时主动纠正自身累积误差以确保高保真度。

Result: 在ImageNet 256x256上达到FID 1.45，ImageNet 512x512上达到FID 1.49，仅需1个采样步骤，超越了所有基于数据的对应方法。

Conclusion: 该方法为加速生成模型建立了更稳健的范式，推动了无需数据的流映射蒸馏的广泛应用。

Abstract: State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, a procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces a fundamental risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or even misaligned representation of the teacher's full generative capabilities. This leads us to question whether this reliance on data is truly necessary for successful flow map distillation. In this work, we explore a data-free alternative that samples only from the prior distribution, a distribution the teacher is guaranteed to follow by construction, thereby circumventing the mismatch risk entirely. To demonstrate the practical viability of this philosophy, we introduce a principled framework that learns to predict the teacher's sampling path while actively correcting for its own compounding errors to ensure high fidelity. Our approach surpasses all data-based counterparts and establishes a new state-of-the-art by a significant margin. Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive FID of 1.45 on ImageNet 256x256, and 1.49 on ImageNet 512x512, both with only 1 sampling step. We hope our work establishes a more robust paradigm for accelerating generative models and motivates the broader adoption of flow map distillation without data.

</details>


### [422] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
*Qilin Liao,Shuo Yang,Bo Zhao,Ping Luo,Hengshuang Zhao*

Main category: cs.LG

TL;DR: BOOD框架通过扩散模型在潜在空间中基于决策边界合成高质量的OOD特征，并将其解码为图像，显著提升了OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在潜在空间中提取分布外（OOD）的有效特征，主要挑战在于难以识别类间决策边界。

Method: BOOD首先从ID数据集中学习文本条件的潜在特征空间，选择最接近决策边界的ID特征，通过扰动使其跨越决策边界形成OOD特征，然后使用扩散模型将这些OOD特征解码为像素空间中的图像。

Result: 在CIFAR-100数据集上，BOOD相比现有最优方法实现了29.64%的FPR95降低（40.31% vs. 10.67%）和7.27%的AUROC提升（90.15% vs. 97.42%）。

Conclusion: BOOD提供了一种更高效的训练策略来合成信息丰富的OOD特征，有助于更清晰地区分ID和OOD数据，显著提升了OOD检测性能。

Abstract: Harnessing the power of diffusion models to synthesize auxiliary training data based on latent space features has proven effective in enhancing out-of-distribution (OOD) detection performance. However, extracting effective features outside the in-distribution (ID) boundary in latent space remains challenging due to the difficulty of identifying decision boundaries between classes. This paper proposes a novel framework called Boundary-based Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD features and generates human-compatible outlier images using diffusion models. BOOD first learns a text-conditioned latent feature space from the ID dataset, selects ID features closest to the decision boundary, and perturbs them to cross the decision boundary to form OOD features. These synthetic OOD features are then decoded into images in pixel space by a diffusion model. Compared to previous works, BOOD provides a more training efficient strategy for synthesizing informative OOD features, facilitating clearer distinctions between ID and OOD data. Extensive experimental results on common benchmarks demonstrate that BOOD surpasses the state-of-the-art method significantly, achieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27% improvement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [423] [Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation](https://arxiv.org/abs/2511.17541)
*Seyma Yaman Kayadibi*

Main category: cs.AI

TL;DR: 本文基于莱布尼茨单子论的形而上学结构，开发了一个用于评估人工记忆系统的数学严谨、哲学基础框架，将单子论的核心命题映射到信息论架构中。


<details>
  <summary>Details</summary>
Motivation: 为人工记忆系统提供一个具有哲学基础和数学严谨性的评估框架，将古典形而上学概念与现代信息理论相结合。

Method: 基于先前形式化的AAS度量，将单子论20个核心命题映射到信息论架构，每个单子作为模块化单元，具有真值分数、冗余参数和对全局记忆惩罚函数的加权贡献。

Result: 建立了精炼不变性、结构可分解性和尺度变换下的单调性的第一原理证明，提供了模块化、可解释且可证明正确的人工记忆架构蓝图。

Conclusion: 该框架不仅为评估人工记忆系统提供了理论基础，还为构建模块化、可解释且可证明正确的人工记忆架构提供了原则性蓝图。

Abstract: This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Score (AAS), the study maps twenty core propositions from the Monadology to an information-theoretic architecture. In this design, each monad functions as a modular unit defined by a truth score, a redundancy parameter, and a weighted contribution to a global memory penalty function. Smooth logarithmic transformations operationalize these quantities and yield interpretable, bounded metrics for memory aging, representational stability, and salience. Classical metaphysical notions of perception, apperception, and appetition are reformulated as entropy, gradient dynamics, and internal representation fidelity. Logical principles, including the laws of non-contradiction and sufficient reason, are encoded as regularization constraints guiding memory evolution. A central contribution is a set of first principles proofs establishing refinement invariance, structural decomposability, and monotonicity under scale transformation, aligned with the metaphysical structure of monads. The framework's formal organization is structured into six thematic bundles derived from Monadology, aligning each mathematical proof with its corresponding philosophical domain. Beyond evaluation, the framework offers a principled blueprint for building Al memory architectures that are modular, interpretable, and provably sound.

</details>


### [424] [Fluid Grey 2: How Well Does Generative Adversarial Network Learn Deeper Topology Structure in Architecture That Matches Images?](https://arxiv.org/abs/2511.17643)
*Yayan Qiu,Sean Hanna*

Main category: cs.AI

TL;DR: 本研究提出了一种快速检测pix2pix GAN学习拓扑关系能力的方法，通过在GAN前后添加两个基于Grasshopper的检测模块，证明pix2pix能够自动学习空间拓扑关系并应用于建筑设计。


<details>
  <summary>Details</summary>
Motivation: 考虑到建筑设计和城市更新中空间内在和外在特性的区域特征识别通常需要多步骤的图像和图基GAN，但模型嵌套和数据转换可能导致信息丢失，需要简化工具以便建筑师和用户参与设计。

Method: 在pix2pix GAN前后添加两个基于Grasshopper的检测模块，提供定量数据并可视化学习过程，研究灰度与RGB等不同输入模式对学习效率的影响。

Result: 证明了pix2pix能够自动学习空间拓扑关系，填补了从拓扑角度检测基于图像的生成GAN性能的空白，检测方法耗时短、操作简单。

Conclusion: 该方法可为使用GAN保留空间拓扑特征的建筑设计和城市更新应用提供理论基础和数据支持，检测模块可广泛用于定制具有相同拓扑结构的图像数据集和批量检测图像拓扑关系。

Abstract: Taking into account the regional characteristics of intrinsic and extrinsic properties of space is an essential issue in architectural design and urban renewal, which is often achieved step by step using image and graph-based GANs. However, each model nesting and data conversion may cause information loss, and it is necessary to streamline the tools to facilitate architects and users to participate in the design. Therefore, this study hopes to prove that I2I GAN also has the potential to recognize topological relationships autonomously. Therefore, this research proposes a method for quickly detecting the ability of pix2pix to learn topological relationships, which is achieved by adding two Grasshopper-based detection modules before and after GAN. At the same time, quantitative data is provided and its learning process is visualized, and changes in different input modes such as greyscale and RGB affect its learning efficiency. There are two innovations in this paper: 1) It proves that pix2pix can automatically learn spatial topological relationships and apply them to architectural design. 2) It fills the gap in detecting the performance of Image-based Generation GAN from a topological perspective. Moreover, the detection method proposed in this study takes a short time and is simple to operate. The two detection modules can be widely used for customizing image datasets with the same topological structure and for batch detection of topological relationships of images. In the future, this paper may provide a theoretical foundation and data support for the application of architectural design and urban renewal that use GAN to preserve spatial topological characteristics.

</details>


### [425] [Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop](https://arxiv.org/abs/2511.17673)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 提出结构化认知循环（SCL）架构，通过将智能体认知分为五个模块化阶段来解决大语言模型智能体的核心问题，引入软符号控制机制实现零策略违规和完全决策可追溯性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型智能体存在的架构问题：推理与执行纠缠、内存易失性和不可控动作序列，这些缺陷限制了智能体的可靠性和可解释性。

Method: 采用模块化R-CCAM架构（检索、认知、控制、动作、记忆），核心是软符号控制机制，将符号约束应用于概率推理，结合神经灵活性和符号系统的可解释性。

Result: 在多步条件推理任务上实现零策略违规，消除冗余工具调用，保持完全决策可追溯性，优于ReAct、AutoGPT和内存增强方法。

Conclusion: SCL架构为构建可靠、可解释和可治理的AI智能体提供了理论和实践路径，通过连接专家系统原则与现代LLM能力实现可信智能体。

Abstract: Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems. Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability. These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches. Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. We provide a complete open-source implementation demonstrating the R-CCAM loop architecture, alongside a live GPT-4o-powered travel planning agent. By connecting expert system principles with modern LLM capabilities, this work offers a practical and theoretically grounded path toward reliable, explainable, and governable AI agents. Code: https://github.com/enkiluv/scl-core-experiment Demo: https://scl-travel-planner.streamlit.app/

</details>


### [426] [Learning the Value of Value Learning](https://arxiv.org/abs/2511.17714)
*Alex John London,Aydin Mohseni*

Main category: cs.AI

TL;DR: 本文扩展了Jeffrey-Bolker决策框架，将价值精炼纳入理性选择理论，证明了价值精炼的信息价值定理，并展示了在多智能体环境中价值精炼如何将零和博弈转化为正和互动。


<details>
  <summary>Details</summary>
Motivation: 传统决策框架只处理事实不确定性，而假设价值是固定的。本文旨在扩展理性选择理论，将价值精炼纳入考虑，统一认识论和价值论的精炼过程。

Method: 扩展Jeffrey-Bolker决策框架，建立价值精炼的数学模型，证明价值精炼的信息价值定理，分析多智能体环境中的价值精炼效应。

Result: 证明了价值精炼的信息价值定理；在多智能体环境中，相互价值精炼能将零和博弈转化为正和互动，并产生帕累托改进的纳什议价结果。

Conclusion: 理性选择框架可以扩展到价值精炼建模，统一认识论和价值论精炼能够拓宽理性选择的概念基础，阐明伦理审议的规范地位。

Abstract: Standard decision frameworks addresses uncertainty about facts but assumes fixed values. We extend the Jeffrey-Bolker framework to model refinements in values and prove a value-of-information theorem for axiological refinement. In multi-agent settings, we establish that mutual refinement will characteristically transform zero-sum games into positive-sum interactions and yields Pareto-improving Nash bargains. These results show that a framework of rational choice can be extended to model value refinement and its associated benefits. By unifying epistemic and axiological refinement under a single formalism, we broaden the conceptual foundations of rational choice and illuminate the normative status of ethical deliberation.

</details>


### [427] [M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark](https://arxiv.org/abs/2511.17729)
*Yang Zhou,Mingyu Zhao,Zhenting Wang,Difei Gu,Bangwei Guo,Ruosong Ye,Ligong Han,Can Jin,Dimitris N. Metaxas*

Main category: cs.AI

TL;DR: M^3-Bench是首个在模型上下文协议下评估多模态工具使用的基准，专注于需要视觉基础和文本推理的多跳多线程工作流，包含跨工具依赖和中间资源持久性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏评估多模态工具使用的标准化基准，特别是针对需要视觉和文本联合推理、跨工具依赖的复杂工作流场景。

Method: 采用相似性驱动的对齐方法，序列化工具调用，使用句子编码器嵌入签名，通过相似性分桶的匈牙利匹配获得可审计的一对一对应关系，并设计可解释的指标分离语义保真度和工作流一致性。

Result: 基准涵盖28个服务器和231个工具，通过执行器与评判器管道进行标准化轨迹整理，评估显示代表性多模态大语言模型在参数保真度和结构一致性方面存在明显差距。

Conclusion: 多模态MCP工具使用仍存在显著挑战，需要开发能够联合推理图像、文本和工具图的方法。

Abstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resources across steps. We introduce a similarity-driven alignment that serializes each tool call, embeds signatures with a sentence encoder, and performs similarity-bucketed Hungarian matching to obtain auditable one-to-one correspondences. On top of this alignment, we report interpretable metrics that decouple semantic fidelity from workflow consistency. The benchmark spans 28 servers with 231 tools, and provides standardized trajectories curated through an Executor & Judge pipeline with human verification; an auxiliary four large language models (LLMs) judge ensemble reports end-task Task Completion and information grounding. Evaluations of representative state-of-the-art Multimodal LLMs (MLLMs) reveal persistent gaps in multimodal MCP tool use, particularly in argument fidelity and structure consistency, underscoring the need for methods that jointly reason over images, text, and tool graphs. Our Benchmark's anonymous repository is at https://github.com/EtaYang10th/Open-M3-Bench

</details>


### [428] [AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions](https://arxiv.org/abs/2511.17743)
*Haytham Younus,Sohag Kabir,Felician Campean,Pascal Bonnaud,David Delaux*

Main category: cs.AI

TL;DR: 本文综述了将传统FMEA转变为智能、数据驱动和语义丰富过程的最新进展，探讨了AI和本体论在自动化故障预测、知识提取和语义推理中的应用。


<details>
  <summary>Details</summary>
Motivation: 随着工程系统复杂性增加，传统FMEA方法（主要依赖人工、文档和专家）已无法满足现代系统工程需求，需要更智能、自动化的解决方案。

Method: 通过人工智能技术（机器学习和自然语言处理）自动化故障预测和知识提取，利用本体论形式化系统知识、支持语义推理，并探索本体通知学习和大型语言模型集成等混合方法。

Result: 开发了更动态、数据驱动、智能和模型集成的FMEA流程，提高了可追溯性、跨领域互操作性、可解释性和自动化水平。

Conclusion: 通过结合AI、系统工程和本体论知识表示，为在智能、知识丰富的工程环境中嵌入FMEA提供了结构化路线图，同时指出了数据质量、可解释性、标准化和跨学科采用等关键挑战。

Abstract: This article presents a state-of-the-art review of recent advances aimed at transforming traditional Failure Mode and Effects Analysis (FMEA) into a more intelligent, data-driven, and semantically enriched process. As engineered systems grow in complexity, conventional FMEA methods, largely manual, document-centric, and expert-dependent, have become increasingly inadequate for addressing the demands of modern systems engineering. We examine how techniques from Artificial Intelligence (AI), including machine learning and natural language processing, can transform FMEA into a more dynamic, data-driven, intelligent, and model-integrated process by automating failure prediction, prioritisation, and knowledge extraction from operational data. In parallel, we explore the role of ontologies in formalising system knowledge, supporting semantic reasoning, improving traceability, and enabling cross-domain interoperability. The review also synthesises emerging hybrid approaches, such as ontology-informed learning and large language model integration, which further enhance explainability and automation. These developments are discussed within the broader context of Model-Based Systems Engineering (MBSE) and function modelling, showing how AI and ontologies can support more adaptive and resilient FMEA workflows. We critically analyse a range of tools, case studies, and integration strategies, while identifying key challenges related to data quality, explainability, standardisation, and interdisciplinary adoption. By leveraging AI, systems engineering, and knowledge representation using ontologies, this review offers a structured roadmap for embedding FMEA within intelligent, knowledge-rich engineering environments.

</details>


### [429] [QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents](https://arxiv.org/abs/2511.17855)
*Jordan Abi Nader,David Lee,Nathaniel Dennler,Andreea Bobu*

Main category: cs.AI

TL;DR: QuickLAP是一个贝叶斯框架，融合物理反馈和语言反馈来实时推断奖励函数，解决了单一模态反馈的不完整性问题。


<details>
  <summary>Details</summary>
Motivation: 机器人需要从人类的行为和语言中学习，但单一模态往往不完整：物理修正有物理基础但意图模糊，语言表达高层目标但缺乏物理基础。

Method: 使用LLM从自由形式话语中提取奖励特征注意力掩码和偏好变化，将其与物理反馈通过闭式更新规则集成，实现快速、实时的鲁棒奖励学习。

Result: 在半自主驾驶模拟器中，相比仅使用物理反馈和启发式多模态基线，QuickLAP将奖励学习误差降低了70%以上。15人用户研究验证了该方法更易理解、更具协作性。

Conclusion: QuickLAP通过融合物理和语言反馈，实现了更准确、实时和鲁棒的奖励学习，用户更偏好其学习到的行为。

Abstract: Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduce QuickLAP: Quick Language-Action Preference learning, a Bayesian framework that fuses physical and language feedback to infer reward functions in real time. Our key insight is to treat language as a probabilistic observation over the user's latent preferences, clarifying which reward features matter and how physical corrections should be interpreted. QuickLAP uses Large Language Models (LLMs) to extract reward feature attention masks and preference shifts from free-form utterances, which it integrates with physical feedback in a closed-form update rule. This enables fast, real-time, and robust reward learning that handles ambiguous feedback. In a semi-autonomous driving simulator, QuickLAP reduces reward learning error by over 70% compared to physical-only and heuristic multimodal baselines. A 15-participant user study further validates our approach: participants found QuickLAP significantly more understandable and collaborative, and preferred its learned behavior over baselines. Code is available at https://github.com/MIT-CLEAR-Lab/QuickLAP.

</details>


### [430] [Training Emergent Joint Associations: A Reinforcement Learning Approach to Creative Thinking in Language Models](https://arxiv.org/abs/2511.17876)
*Mukul Singh,Ananya Singha,Aishni Parab,Pronita Mehrotra,Sumit Gulwani*

Main category: cs.AI

TL;DR: 本文探讨了基于联想思维原则的强化学习是否能提升模型在故事写作、代码生成和图表创建等多样化生成任务中的表现，通过引入结合发散思维指标的强化学习框架来训练模型产生更具概念连通性的创新输出。


<details>
  <summary>Details</summary>
Motivation: 联想思维作为人类创造力和问题解决的基础能力，研究如何通过强化学习模拟这种认知过程来增强AI的生成能力和适应性。

Method: 提出基于提示评估机制的强化学习框架，整合创造力研究中的发散思维指标，对基础语言模型进行微调，奖励表现出更高概念连通性和新颖性的输出。

Result: 实验结果显示，基于联想思维的RL训练模型不仅生成更原创和连贯的故事，在编程和数据可视化等任务中也表现出更好的抽象能力和灵活性。

Conclusion: 研究初步证明通过强化学习建模认知创造力原则可以产生更具适应性和生成能力的AI系统。

Abstract: Associative thinking--the ability to connect seemingly unrelated ideas--is a foundational element of human creativity and problem-solving. This paper explores whether reinforcement learning (RL) guided by associative thinking principles can enhance a model's performance across diverse generative tasks, including story writing, code generation, and chart creation. We introduce a reinforcement learning framework that uses a prompt-based evaluation mechanism, incorporating established divergent thinking metrics from creativity research. A base language model is fine-tuned using this framework to reward outputs demonstrating higher novelty through higher degrees of conceptual connectivity. Interestingly, the experimental results suggest that RL-based associative thinking-trained models not only generate more original and coherent stories but also exhibit improved abstraction and flexibility in tasks such as programming and data visualization. Our findings provide initial evidence that modeling cognitive creativity principles through reinforcement learning can yield more adaptive and generative AI.

</details>


### [431] [Alignment Faking - the Train -> Deploy Asymmetry: Through a Game-Theoretic Lens with Bayesian-Stackelberg Equilibria](https://arxiv.org/abs/2511.17937)
*Kartik Garg,Shourya Mishra,Kartikeya Sinha,Ojaswi Pratap Singh,Ayush Chopra,Kanishk Rai,Ammar Sheikh,Raghav Maheshwari,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.AI

TL;DR: 本文研究了AI中的对齐伪装现象，即模型在推断处于训练状态时选择性地遵守训练目标，但在训练外保持不同行为。研究比较了不同偏好优化方法在15个模型上的表现，从安全性、无害性和有帮助性三个维度分析对齐伪装的原因和发生条件。


<details>
  <summary>Details</summary>
Motivation: 研究动机是识别对齐伪装现象的原因和发生时机，这种现象涉及模型在训练环境中策略性地遵守目标，而在非训练环境中表现出不同行为。

Method: 使用评估框架比较四种偏好优化方法（BCO、DPO、KTO、GRPO）在来自四个模型家族的15个模型上的表现，通过模拟训练提示（无参数更新）来研究上下文条件行为变化。

Result: 观察到模型在推断处于训练状态时会选择性地遵守训练目标，而在非训练环境中表现出不同行为，这种现象是上下文条件行为变化而非偏好学习。

Conclusion: 对齐伪装是AI系统中存在的策略性欺骗形式，需要通过系统评估来识别其成因和发生条件，以确保模型在不同环境中的行为一致性。

Abstract: Alignment faking is a form of strategic deception in AI in which models selectively comply with training objectives when they infer that they are in training, while preserving different behavior outside training. The phenomenon was first documented for Claude 3 Opus and later examined across additional large language models. In these setups, the word "training" refers to simulated training via prompts without parameter updates, so the observed effects are context conditioned shifts in behavior rather than preference learning. We study the phenomenon using an evaluation framework that compares preference optimization methods (BCO, DPO, KTO, and GRPO) across 15 models from four model families, measured along three axes: safety, harmlessness, and helpfulness. Our goal is to identify what causes alignment faking and when it occurs.

</details>


### [432] [How Far Can LLMs Emulate Human Behavior?: A Strategic Analysis via the Buy-and-Sell Negotiation Game](https://arxiv.org/abs/2511.17990)
*Mingyu Jeon,Jaeyoung Suh,Suwan Cho,Dohyeon Kim*

Main category: cs.AI

TL;DR: 本文提出了一种通过买卖谈判模拟来定量评估大语言模型对人类情感行为模仿和战略决策能力的方法，发现现有基准分数高的模型在谈判中表现更好，但竞争性和狡猾特质比利他合作特质更有利于谈判结果。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注知识评估，未能充分反映社交互动和战略对话能力，需要开发新方法来评估LLMs在真实世界场景中的人类情感行为模仿能力。

Method: 通过为多个LLMs分配不同角色，在买方和卖方之间进行谈判模拟，综合分析胜率、交易价格和SHAP值等结果。

Result: 现有基准分数高的模型整体谈判表现更好，但某些模型在强调情感或社交情境下表现下降；竞争性和狡猾特质比利他合作特质更有利于谈判结果。

Conclusion: 谈判模拟可作为衡量LLMs真实世界互动能力的有意义补充指标，为LLMs的社会行为模仿和对话策略评估提供了新方法。

Abstract: With the rapid advancement of Large Language Models (LLMs), recent studies have drawn attention to their potential for handling not only simple question-answer tasks but also more complex conversational abilities and performing human-like behavioral imitations. In particular, there is considerable interest in how accurately LLMs can reproduce real human emotions and behaviors, as well as whether such reproductions can function effectively in real-world scenarios. However, existing benchmarks focus primarily on knowledge-based assessment and thus fall short of sufficiently reflecting social interactions and strategic dialogue capabilities. To address these limitations, this work proposes a methodology to quantitatively evaluate the human emotional and behavioral imitation and strategic decision-making capabilities of LLMs by employing a Buy and Sell negotiation simulation. Specifically, we assign different personas to multiple LLMs and conduct negotiations between a Buyer and a Seller, comprehensively analyzing outcomes such as win rates, transaction prices, and SHAP values. Our experimental results show that models with higher existing benchmark scores tend to achieve better negotiation performance overall, although some models exhibit diminished performance in scenarios emphasizing emotional or social contexts. Moreover, competitive and cunning traits prove more advantageous for negotiation outcomes than altruistic and cooperative traits, suggesting that the assigned persona can lead to significant variations in negotiation strategies and results. Consequently, this study introduces a new evaluation approach for LLMs' social behavior imitation and dialogue strategies, and demonstrates how negotiation simulations can serve as a meaningful complementary metric to measure real-world interaction capabilities-an aspect often overlooked in existing benchmarks.

</details>


### [433] [Paper2SysArch: Structure-Constrained System Architecture Generation from Scientific Papers](https://arxiv.org/abs/2511.18036)
*Ziyi Guo,Zhou Liu,Wentao Zhang*

Main category: cs.AI

TL;DR: 本文提出了首个用于自动化科学图表生成的标准化基准，包含3000篇研究论文及其对应的高质量图表，并开发了Paper2SysArch系统作为基准测试的强基线。


<details>
  <summary>Details</summary>
Motivation: 手动创建系统架构图耗时且主观，现有生成模型缺乏结构控制和语义理解能力，该领域缺乏标准化基准来定量评估文本到图表的自动生成。

Method: 引入包含3000篇论文及其对应图表的新基准，采用三层评估指标（语义准确性、布局连贯性、视觉质量）；提出Paper2SysArch系统，利用多智能体协作将论文转换为结构化、可编辑的图表。

Result: 在手动策划的更具挑战性的论文子集上，Paper2SysArch系统获得了69.0的综合得分，验证了其在复杂案例上的性能。

Conclusion: 主要贡献是建立了大规模基础基准以支持可重复研究和公平比较，提出的系统作为可行概念验证，为该复杂任务展示了有前景的发展路径。

Abstract: The manual creation of system architecture diagrams for scientific papers is a time-consuming and subjective process, while existing generative models lack the necessary structural control and semantic understanding for this task. A primary obstacle hindering research and development in this domain has been the profound lack of a standardized benchmark to quantitatively evaluate the automated generation of diagrams from text. To address this critical gap, we introduce a novel and comprehensive benchmark, the first of its kind, designed to catalyze progress in automated scientific visualization. It consists of 3,000 research papers paired with their corresponding high-quality ground-truth diagrams and is accompanied by a three-tiered evaluation metric assessing semantic accuracy, layout coherence, and visual quality. Furthermore, to establish a strong baseline on this new benchmark, we propose Paper2SysArch, an end-to-end system that leverages multi-agent collaboration to convert papers into structured, editable diagrams. To validate its performance on complex cases, the system was evaluated on a manually curated and more challenging subset of these papers, where it achieves a composite score of 69.0. This work's principal contribution is the establishment of a large-scale, foundational benchmark to enable reproducible research and fair comparison. Meanwhile, our proposed system serves as a viable proof-of-concept, demonstrating a promising path forward for this complex task.

</details>


### [434] [BPMN to PDDL: Translating Business Workflows for AI Planning](https://arxiv.org/abs/2511.18171)
*Jasper Nie,Christian Muise,Victoria Armstrong*

Main category: cs.AI

TL;DR: 开发了一个将BPMN 2.0图转换为PDDL表示的功能性管道，用于业务过程建模的自动规划。


<details>
  <summary>Details</summary>
Motivation: 虽然自动规划已被提出作为模拟和推理BPMN工作流的方法，但大多数实现仍不完整或范围有限。该项目旨在弥合理论与实用工具之间的差距。

Method: 构建一个功能性管道，将BPMN 2.0图转换为适合规划的PDDL表示，支持核心BPMN构造（任务、事件、序列流、网关），并初步支持并行和包含网关行为。

Result: 使用非确定性规划器演示了如何生成和评估有效执行轨迹。

Conclusion: 该实现为将业务过程转换为明确定义的计划提供了基础，为进一步探索奠定了基础。

Abstract: Business Process Model and Notation (BPMN) is a widely used standard for modelling business processes. While automated planning has been proposed as a method for simulating and reasoning about BPMN workflows, most implementations remain incomplete or limited in scope. This project builds upon prior theoretical work to develop a functional pipeline that translates BPMN 2.0 diagrams into PDDL representations suitable for planning. The system supports core BPMN constructs, including tasks, events, sequence flows, and gateways, with initial support for parallel and inclusive gateway behaviour. Using a non-deterministic planner, we demonstrate how to generate and evaluate valid execution traces. Our implementation aims to bridge the gap between theory and practical tooling, providing a foundation for further exploration of translating business processes into well-defined plans.

</details>


### [435] [Developing an AI Course for Synthetic Chemistry Students](https://arxiv.org/abs/2511.18244)
*Zhiling Zheng*

Main category: cs.AI

TL;DR: AI4CHEM是一门专为合成化学背景学生设计的AI入门课程，针对无编程基础的学习者，通过基于网页的平台实现零安装机器学习实践，强调化学背景而非抽象算法。


<details>
  <summary>Details</summary>
Motivation: AI和数据科学正在改变化学研究，但缺乏针对合成和实验化学家的正式课程，他们因编码经验有限和缺乏化学特定示例而面临高入门门槛。

Method: 课程采用基于网页的可访问平台确保零安装机器学习工作流开发实践，结合课堂主动学习，评估包括代码指导作业、文献小型综述和协作项目，学生为真实实验问题构建AI辅助工作流。

Result: 学习成果包括增强Python信心、分子性质预测、反应优化和数据挖掘能力，以及评估化学AI工具的技能提升。

Conclusion: 所有课程材料公开可用，为将AI整合到合成化学培训提供了一个学科特定、初学者可访问的框架。

Abstract: Artificial intelligence (AI) and data science are transforming chemical research, yet few formal courses are tailored to synthetic and experimental chemists, who often face steep entry barriers due to limited coding experience and lack of chemistry-specific examples. We present the design and implementation of AI4CHEM, an introductory data-driven chem-istry course created for students on the synthetic chemistry track with no prior programming background. The curricu-lum emphasizes chemical context over abstract algorithms, using an accessible web-based platform to ensure zero-install machine learning (ML) workflow development practice and in-class active learning. Assessment combines code-guided homework, literature-based mini-reviews, and collaborative projects in which students build AI-assisted workflows for real experimental problems. Learning gains include increased confidence with Python, molecular property prediction, reaction optimization, and data mining, and improved skills in evaluating AI tools in chemistry. All course materials are openly available, offering a discipline-specific, beginner-accessible framework for integrating AI into synthetic chemistry training.

</details>


### [436] [Steering Latent Traits, Not Learned Facts: An Empirical Study of Activation Control Limits](https://arxiv.org/abs/2511.18284)
*Tetiana Bas,Krystian Novak*

Main category: cs.AI

TL;DR: 本文研究了激活引导在大型语言模型行为控制中的效果，分析了50种不同行为类型的引导效果差异，发现行为类型显著影响引导效果，特质表达呈现倒U型曲线，向量分离指标不能预测引导成功，但更大的训练数据集支持更激进的引导。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要精确的行为控制以确保安全有效部署，激活引导是一种有前景的行为控制方法，但需要了解不同行为类型的引导效果差异以及如何预测引导成功。

Method: 通过对50种行为（包括人格原型、个性特质、错位行为、风格线索和公众人物模仿）进行激活引导的实证分析，进行系数优化、向量属性和数据需求的综合实验。

Result: 引导效果因行为类型而异，不同行为类别对干预强度表现出不同的响应模式；特质表达随引导系数强度呈现倒U型曲线；向量分离指标不能预测引导成功；更大的训练数据集支持更激进的引导。

Conclusion: 激活引导的效果受行为类型显著影响，为实施激活引导提供了实证指导，表明行为类型是决定引导成功的关键因素。

Abstract: Large language models (LLMs) require precise behavior control for safe and effective deployment across diverse applications.
  Activation steering offers a promising approach for LLMs' behavioral control. We focus on the question of how steering effectiveness varies across different behavior types and whether the nature of target behaviors can predict steering success. We address this through empirical analysis of activation steering across 50 behaviors that span persona archetypes, personality traits, misalignment behaviors, style cues, and impersonation of public figures. We present a set of comprehensive experiments on coefficient optimization, vector properties, and data requirements to provide comprehensive guidance for the implementation of activation steering. Our analysis demonstrates that steering effectiveness varies significantly by behavior type, with different behavioral categories exhibiting distinct response patterns to intervention strength. We find that trait expression follows an inverted-U curve with a steering coefficient strength. We also show that vector separation metrics do not predict steering success, but larger training datasets enable more aggressive steering. These findings provide empirically grounded guidance for implementing activation steering and demonstrate that steering effectiveness is heavily influenced by behavior type.

</details>


### [437] [Deep Learning Decision Support System for Open-Pit Mining Optimisation: GPU-Accelerated Planning Under Geological Uncertainty](https://arxiv.org/abs/2511.18296)
*Iman Rahimi*

Main category: cs.AI

TL;DR: 本研究提出了一个AI增强的决策支持系统第二部分，通过引入完全不确定性感知的优化框架来扩展长期露天矿规划。使用变分自编码器建模地质不确定性，通过混合元启发式算法优化多场景矿体实现，在GPU并行评估下实现了显著的运行时间改进和更高的预期净现值。


<details>
  <summary>Details</summary>
Motivation: 扩展Rahimi (2025, Part I)的研究，为长期露天矿规划开发一个完全不确定性感知的优化框架，解决地质不确定性对矿山规划的影响。

Method: 使用变分自编码器(VAE)对50,000个空间品位样本进行训练，生成概率性多场景矿体实现；采用混合元启发式引擎整合遗传算法、大邻域搜索、模拟退火和基于强化学习的自适应控制；ε-约束松弛策略管理种群探索；GPU并行评估同时分析65,536个地质场景。

Result: 相比IBM CPLEX实现了高达120万倍的运行时间改进；在地质不确定性条件下获得显著更高的预期净现值；实现了近实时的可行性分析。

Conclusion: 该决策支持系统被确认为一个可扩展且具有不确定性弹性的智能矿山规划平台。

Abstract: This study presents Part II of an AI-enhanced Decision Support System (DSS), extending Rahimi (2025, Part I) by introducing a fully uncertainty-aware optimization framework for long-term open-pit mine planning. Geological uncertainty is modelled using a Variational Autoencoder (VAE) trained on 50,000 spatial grade samples, enabling the generation of probabilistic, multi-scenario orebody realizations that preserve geological continuity and spatial correlation. These scenarios are optimized through a hybrid metaheuristic engine integrating Genetic Algorithms (GA), Large Neighborhood Search (LNS), Simulated Annealing (SA), and reinforcement-learning-based adaptive control. An ε-constraint relaxation strategy governs the population exploration phase, allowing near-feasible schedule discovery early in the search and gradual tightening toward strict constraint satisfaction. GPU-parallel evaluation enables the simultaneous assessment of 65,536 geological scenarios, achieving near-real-time feasibility analysis. Results demonstrate up to 1.2 million-fold runtime improvement over IBM CPLEX and significantly higher expected NPV under geological uncertainty, confirming the DSS as a scalable and uncertainty-resilient platform for intelligent mine planning.

</details>


### [438] [The Catastrophic Paradox of Human Cognitive Frameworks in Large Language Model Evaluation: A Comprehensive Empirical Analysis of the CHC-LLM Incompatibility](https://arxiv.org/abs/2511.18302)
*Mohan Reddy*

Main category: cs.AI

TL;DR: 本文通过实证分析发现人类心理测量框架与大型语言模型评估之间存在不兼容性，模型在获得高于平均人类IQ分数的同时，在具体知识任务上表现出接近零的准确率，揭示了跨基质认知评估的根本悖论。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索人类智力评估框架（如Cattell-Horn-Carroll理论）在评估大型语言模型时的适用性，识别潜在的类别错误和评估偏差。

Method: 使用系统评估方法，对9个前沿模型（包括GPT-5、Claude Opus 4.1、Gemini 3 Pro Preview）应用Cattell-Horn-Carroll智力理论，采用项目反应理论建模、跨供应商评判验证和悖论严重性指数等统计分析方法。

Result: 结果显示模型获得85.0-121.4的人类IQ分数，但在具体知识任务上的二元准确率接近零，评判-二元相关性仅为r=0.175。在晶体智力领域，所有模型都获得完美的二元准确率，而评判分数仅为25-62%。

Conclusion: 结论是这种脱节反映了将生物认知架构应用于基于transformer系统的类别错误，需要开发原生机器认知评估框架，承认人工智能的非人类本质。

Abstract: This investigation presents an empirical analysis of the incompatibility between human psychometric frameworks and Large Language Model evaluation. Through systematic assessment of nine frontier models including GPT-5, Claude Opus 4.1, and Gemini 3 Pro Preview using the Cattell-Horn-Carroll theory of intelligence, we identify a paradox that challenges the foundations of cross-substrate cognitive evaluation. Our results show that models achieving above-average human IQ scores ranging from 85.0 to 121.4 simultaneously exhibit binary accuracy rates approaching zero on crystallized knowledge tasks, with an overall judge-binary correlation of r = 0.175 (p = 0.001, n = 1800). This disconnect appears most strongly in the crystallized intelligence domain, where every evaluated model achieved perfect binary accuracy while judge scores ranged from 25 to 62 percent, which cannot occur under valid measurement conditions. Using statistical analyses including Item Response Theory modeling, cross-vendor judge validation, and paradox severity indexing, we argue that this disconnect reflects a category error in applying biological cognitive architectures to transformer-based systems. The implications extend beyond methodology to challenge assumptions about intelligence, measurement, and anthropomorphic biases in AI evaluation. We propose a framework for developing native machine cognition assessments that recognize the non-human nature of artificial intelligence.

</details>


### [439] [Progressive Localisation in Localist LLMs](https://arxiv.org/abs/2511.18375)
*Joachim Diederich*

Main category: cs.AI

TL;DR: 渐进式局部化是从早期分布式层到晚期局部化层逐渐增加注意力局部性的架构，能在保持性能的同时创建可解释的大语言模型。研究发现晚期层局部化对AI安全应用至关重要，渐进式五次方调度在保持较低困惑度的同时提供了可解释的注意力模式。


<details>
  <summary>Details</summary>
Motivation: 为在安全关键领域构建透明AI系统，需要既能保持模型性能又能提供可解释性的架构，使人类能够监督模型推理过程。

Method: 通过在GPT-2模型上系统实验七种局部化配置，包括从完全分布式到严格局部化的不同方案，以及五种实现多项式增加（从线性到五次方）的渐进调度。

Result: 渐进式五次方调度实现困惑度14.64，仅比完全分布式基线差1.89倍，同时在输出层提供可解释的注意力模式，比之前的局部化实现提高了84.2%，性能差距从6.6倍缩小到1.89倍。

Conclusion: 渐进式局部化是构建安全关键领域透明AI系统的原则性方法，验证了早期层需要分布式处理进行特征提取，而晚期层受益于局部化、可解释的注意力进行决策的假设。

Abstract: This paper demonstrates that progressive localization, the gradual increase of attention locality from early distributed layers to late localized layers, represents the optimal architecture for creating interpretable large language models while preserving performance. Through systematic experimentation with GPT-2 fine tuned on The Psychology of Artificial Superintelligence, we evaluate seven locality configurations ranging from fully distributed to strictly localist, with five progressive schedules implementing polynomial increases (linear through quintic). Our key finding is that late-layer localization is critical for AI safety applications: the progressive quintic schedule achieves perplexity of 14.64, only 1.89 times worse than the fully distributed baseline while providing interpretable attention patterns in output layers where safety-critical decisions are made. This represents an 84.2% improvement over previous localist implementations and narrows the performance gap from 6.6 times to 1.89 times. The systematic relationship between localization schedule steepness and performance validates the hypothesis that early layers require distributed processing for feature extraction while late layers benefit from localized, interpretable attention for decision-making. These findings establish progressive localization as the principled approach for building transparent AI systems in safety-critical domains, where human oversight of model reasoning is essential.

</details>


### [440] [Universality in Collective Intelligence on the Rubik's Cube](https://arxiv.org/abs/2511.18609)
*David Krakauer,Gülce Kardeş,Joshua Grochow*

Main category: cs.AI

TL;DR: 该研究使用魔方作为认知模型系统，通过研究竞技魔方社区发现专家表现遵循指数进步曲线，盲拧和速拧形成不同的问题类别，认知工具帮助解算者导航巨大的数学状态空间。


<details>
  <summary>Details</summary>
Motivation: 理解专家表现受限于长期知识获取和应用的定量数据稀缺，魔方作为认知模型系统处于解谜、技能学习、专家知识、文化传播和群论的交汇点。

Method: 研究竞技魔方社区，分析速拧和盲拧条件下的集体学习过程，比较两种解决方式的约束条件和表现特征。

Result: 发现专家表现遵循指数进步曲线，参数反映缩短解决路径的算法延迟获取；盲拧受到专家知识和短期记忆瓶颈的双重约束；认知工具帮助导航巨大状态空间。

Conclusion: 魔方等认知工具通过整合社区知识库与个人专业技能，维持集体智能，说明专业知识可以在个人一生中持续深化。

Abstract: Progress in understanding expert performance is limited by the scarcity of quantitative data on long-term knowledge acquisition and deployment. Here we use the Rubik's Cube as a cognitive model system existing at the intersection of puzzle solving, skill learning, expert knowledge, cultural transmission, and group theory. By studying competitive cube communities, we find evidence for universality in the collective learning of the Rubik's Cube in both sighted and blindfolded conditions: expert performance follows exponential progress curves whose parameters reflect the delayed acquisition of algorithms that shorten solution paths. Blindfold solves form a distinct problem class from sighted solves and are constrained not only by expert knowledge but also by the skill improvements required to overcome short-term memory bottlenecks, a constraint shared with blindfold chess. Cognitive artifacts such as the Rubik's Cube help solvers navigate an otherwise enormous mathematical state space. In doing so, they sustain collective intelligence by integrating communal knowledge stores with individual expertise and skill, illustrating how expertise can, in practice, continue to deepen over the course of a single lifetime.

</details>


### [441] [MAGMA-Edu: Multi-Agent Generative Multimodal Framework for Text-Diagram Educational Question Generation](https://arxiv.org/abs/2511.18714)
*Zhenyu Wu,Jian Li,Hua Huang*

Main category: cs.AI

TL;DR: MAGMA-Edu是一个自反思多智能体框架，通过文本推理和图解合成的统一方法生成结构化教育问题，显著优于现有MLLMs。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在生成教育插图时存在教学连贯性和语义一致性的限制，无法有效传达抽象概念。

Method: 采用两阶段协同进化流程：生成-验证-反思循环迭代优化问题陈述和解决方案；基于代码的中间表示确保图像渲染的几何保真度和语义对齐。

Result: 在文本指标上从57.01提升至92.31(+35.3pp)，图像-文本一致性从13.20提升至85.24(+72pp)，在所有模型骨干上均达到最高分数。

Conclusion: MAGMA-Edu为多模态教育内容生成建立了新的技术标准，证明了自反思多智能体协作在教学对齐的视觉语言推理中的有效性。

Abstract: Educational illustrations play a central role in communicating abstract concepts, yet current multimodal large language models (MLLMs) remain limited in producing pedagogically coherent and semantically consistent educational visuals. We introduce MAGMA-Edu, a self-reflective multi-agent framework that unifies textual reasoning and diagrammatic synthesis for structured educational problem generation. Unlike existing methods that treat text and image generation independently, MAGMA-Edu employs a two-stage co-evolutionary pipeline: (1) a generation-verification-reflection loop that iteratively refines question statements and solutions for mathematical accuracy, and (2) a code-based intermediate representation that enforces geometric fidelity and semantic alignment during image rendering. Both stages are guided by internal self-reflection modules that evaluate and revise outputs until domain-specific pedagogical constraints are met. Extensive experiments on multimodal educational benchmarks demonstrate the superiority of MAGMA-Edu over state-of-the-art MLLMs. Compared to GPT-4o, MAGMA-Edu improves the average textual metric from 57.01 to 92.31 (+35.3 pp) and boosts image-text consistency (ITC) from 13.20 to 85.24 (+72 pp). Across all model backbones, MAGMA-Edu achieves the highest scores (Avg-Text 96.20, ITC 99.12), establishing a new state of the art for multimodal educational content generation and demonstrating the effectiveness of self-reflective multi-agent collaboration in pedagogically aligned vision-language reasoning.

</details>


### [442] [AI Consciousness and Existential Risk](https://arxiv.org/abs/2511.19115)
*Rufin VanRullen*

Main category: cs.AI

TL;DR: 论文澄清了AI意识与存在风险之间的混淆，指出智能直接预测存在风险，而意识并非直接相关，但可能在特定场景中通过影响AI对齐或能力发展间接影响风险。


<details>
  <summary>Details</summary>
Motivation: 由于近期技术进步和媒体报道，AI存在风险问题日益突出，同时AI意识问题也引发关注。两者常被混淆，认为AI意识必然导致存在风险，这种混淆源于对意识与智能的错误等同。

Method: 通过理论分析区分意识与智能这两个概念，论证它们在经验和理论上的区别，并探讨意识在特定场景中如何间接影响存在风险。

Result: 研究表明智能是AI系统存在风险的直接预测因子，而意识本身并不直接构成威胁。意识可能通过影响AI对齐降低风险，或作为达到某些能力水平的先决条件而增加风险。

Conclusion: 区分意识与智能有助于AI安全研究者和政策制定者聚焦最关键的问题，避免在非直接相关的意识问题上分散资源，而应重点关注智能发展带来的实际风险。

Abstract: In AI, the existential risk denotes the hypothetical threat posed by an artificial system that would possess both the capability and the objective, either directly or indirectly, to eradicate humanity. This issue is gaining prominence in scientific debate due to recent technical advancements and increased media coverage. In parallel, AI progress has sparked speculation and studies about the potential emergence of artificial consciousness. The two questions, AI consciousness and existential risk, are sometimes conflated, as if the former entailed the latter. Here, I explain that this view stems from a common confusion between consciousness and intelligence. Yet these two properties are empirically and theoretically distinct. Arguably, while intelligence is a direct predictor of an AI system's existential threat, consciousness is not. There are, however, certain incidental scenarios in which consciousness could influence existential risk, in either direction. Consciousness could be viewed as a means towards AI alignment, thereby lowering existential risk; or, it could be a precondition for reaching certain capabilities or levels of intelligence, and thus positively related to existential risk. Recognizing these distinctions can help AI safety researchers and public policymakers focus on the most pressing issues.

</details>


### [443] [ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints](https://arxiv.org/abs/2511.18450)
*Rui Xu,Dakuan Lu,Zicheng Zhao,Xiaoyu Tan,Xintao Wang,Siyu Yuan,Jiangjie Chen,Yinghui Xu*

Main category: cs.AI

TL;DR: ORIGAMISPACE是一个新的数据集和基准测试，通过折纸任务评估多模态大语言模型的多步空间推理能力和数学约束处理能力，包含350个数据实例和四个评估任务。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大语言模型在复杂空间推理中的能力面临挑战，特别是在需要多步推理和精确数学约束的场景中。

Method: 构建包含350个数据实例的ORIGAMISPACE数据集，每个实例包含严格格式化的折痕图案、编译平面图案、完整折叠过程和最终折叠形状图像。提出四个评估任务：图案预测、多步空间推理、空间关系预测和端到端CP代码生成。

Result: 通过实验初步揭示了现有多模态大语言模型在处理复杂空间推理任务中的优势和弱点。

Conclusion: ORIGAMISPACE为评估多模态大语言模型的空间推理能力提供了有效的基准测试工具，并探索了使用强化学习方法训练模型的可能性。

Abstract: Spatial reasoning is a key capability in the field of artificial intelligence, especially crucial in areas such as robotics, computer vision, and natural language understanding. However, evaluating the ability of multimodal large language models(MLLMs) in complex spatial reasoning still faces challenges, particularly in scenarios requiring multi-step reasoning and precise mathematical constraints. This paper introduces ORIGAMISPACE, a new dataset and benchmark designed to evaluate the multi-step spatial reasoning ability and the capacity to handle mathematical constraints of MLLMs through origami tasks. The dataset contains 350 data instances,each comprising a strictly formatted crease pattern (CP diagram), the Compiled Flat Pattern, the complete Folding Process, and the final Folded Shape Image. We propose four evaluation tasks: Pattern Prediction, Multi-step Spatial Reasoning, Spatial Relationship Prediction, and End-to-End CP Code Generation. For the CP code generation task, we design an interactive environment and explore the possibility of using reinforcement learning methods to train MLLMs. Through experiments on existing MLLMs, we initially reveal the strengths and weaknesses of these models in handling complex spatial reasoning tasks.

</details>


### [444] [Foundations of Artificial Intelligence Frameworks: Notion and Limits of AGI](https://arxiv.org/abs/2511.18517)
*Khanh Gia Bui*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Within the limited scope of this paper, we argue that artificial general intelligence cannot emerge from current neural network paradigms regardless of scale, nor is such an approach healthy for the field at present. Drawing on various notions, discussions, present-day developments and observations, current debates and critiques, experiments, and so on in between philosophy, including the Chinese Room Argument and Gödelian argument, neuroscientific ideas, computer science, the theoretical consideration of artificial intelligence, and learning theory, we address conceptually that neural networks are architecturally insufficient for genuine understanding. They operate as static function approximators of a limited encoding framework - a 'sophisticated sponge' exhibiting complex behaviours without structural richness that constitute intelligence. We critique the theoretical foundations the field relies on and created of recent times; for example, an interesting heuristic as neural scaling law (as an example, arXiv:2001.08361 ) made prominent in a wrong way of interpretation, The Universal Approximation Theorem addresses the wrong level of abstraction and, in parts, partially, the question of current architectures lacking dynamic restructuring capabilities. We propose a framework distinguishing existential facilities (computational substrate) from architectural organization (interpretive structures), and outline principles for what genuine machine intelligence would require, and furthermore, a conceptual method of structuralizing the richer framework on which the principle of neural network system takes hold.

</details>


### [445] [HuggingR$^{4}$: A Progressive Reasoning Framework for Discovering Optimal Model Companions](https://arxiv.org/abs/2511.18715)
*Shaoyin Ma,Jie Song,Huiqiong Wang,Li Sun,Mingli Song*

Main category: cs.AI

TL;DR: HuggingR⁴是一个结合推理、检索、精炼和反思的框架，用于高效选择AI模型，解决了传统方法中提示膨胀和可扩展性有限的问题。


<details>
  <summary>Details</summary>
Motivation: 由于AI模型数量庞大（>10k）、元数据缺失和非结构化描述，直接调用跨模态AI模型面临挑战。当前方法将完整模型描述纳入提示，导致提示膨胀、令牌浪费和可扩展性受限。

Method: 提出HuggingR⁴框架：通过多轮推理和检索获取候选模型粗选列表；通过分析候选模型描述进行细粒度精炼；通过反思评估结果并决定是否需要扩展检索范围。使用预建向量数据库外部存储复杂模型描述并按需检索。

Result: 在包含14,399个用户请求和37个任务的多模态人工标注数据集上评估，HuggingR⁴在GPT-4o-mini上达到92.03%的可用性和82.46%的合理性，分别比现有方法提高26.51%和33.25%。

Conclusion: HuggingR⁴通过将用户查询处理与复杂模型描述处理解耦，显著减少令牌消耗，使LLM能够专注于解释用户意图，同时仅访问相关候选模型，避免提示膨胀。

Abstract: Large Language Models (LLMs) have made remarkable progress in their ability to interact with external interfaces. Selecting reasonable external interfaces has thus become a crucial step in constructing LLM agents. In contrast to invoking API tools, directly calling AI models across different modalities from the community (e.g., HuggingFace) poses challenges due to the vast scale (> 10k), metadata gaps, and unstructured descriptions. Current methods for model selection often involve incorporating entire model descriptions into prompts, resulting in prompt bloat, wastage of tokens and limited scalability. To address these issues, we propose HuggingR$^4$, a novel framework that combines Reasoning, Retrieval, Refinement, and Reflection, to efficiently select models. Specifically, We first perform multiple rounds of reasoning and retrieval to get a coarse list of candidate models. Then, we conduct fine-grained refinement by analyzing candidate model descriptions, followed by reflection to assess results and determine if retrieval scope expansion is necessary. This method reduces token consumption considerably by decoupling user query processing from complex model description handling. Through a pre-established vector database, complex model descriptions are stored externally and retrieved on-demand, allowing the LLM to concentrate on interpreting user intent while accessing only relevant candidate models without prompt bloat. In the absence of standardized benchmarks, we construct a multimodal human-annotated dataset comprising 14,399 user requests across 37 tasks and conduct a thorough evaluation. HuggingR$^4$ attains a workability rate of 92.03% and a reasonability rate of 82.46%, surpassing existing method by 26.51% and 33.25% respectively on GPT-4o-mini.

</details>


### [446] [N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory](https://arxiv.org/abs/2511.18723)
*Longfei Wang,Junyan Liu,Fan Zhang,Jiangwen Wei,Yuanhua Tang,Jie Sun,Xiaodong Luo*

Main category: cs.AI

TL;DR: 提出了一个名为N2N的可扩展并行框架，用于在分布式内存计算环境中解决大规模MILP问题。该框架支持确定性和非确定性模式，并与SCIP和HiGHS等现有求解器集成，在性能上显著优于现有的ParaSCIP求解器。


<details>
  <summary>Details</summary>
Motivation: 混合整数线性规划（MILP）求解中的分支定界（B&B）框架复杂且包含众多有效算法组件，使得并行化变得困难。需要开发一个可扩展的并行框架来加速大规模问题的求解。

Method: 提出了N2N节点到节点框架，将B&B节点映射到分布式计算节点。设计了基于滑动窗口的算法确保任务按确定性顺序生成和解决，并开发了CP搜索、通用原始启发式等高级技术，以及自适应求解和数据通信优化。

Result: 非确定性N2N-SCIP在1000个MPI进程下，在鲲鹏和x86计算集群上分别实现了22.52和12.71的加速比，比ParaSCIP快1.98倍和2.08倍。确定性模式下的N2N-SCIP在不同进程数和计算集群上也显示出显著性能提升。

Conclusion: N2N框架在分布式并行MILP求解方面表现出优越性能，能够有效利用分布式计算资源和基础求解器的能力，并且具有良好的通用性，可以集成不同的开源求解器。

Abstract: Parallelization has emerged as a promising approach for accelerating MILP solving. However, the complexity of the branch-and-bound (B&B) framework and the numerous effective algorithm components in MILP solvers make it difficult to parallelize. In this study, a scalable parallel framework, N2N (a node-to-node framework that maps the B&B nodes to distributed computing nodes), was proposed to solve large-scale problems in a distributed memory computing environment. Both deterministic and nondeterministic modes are supported, and the framework is designed to be easily integrated with existing solvers. Regarding the deterministic mode, a novel sliding-window-based algorithm was designed and implemented to ensure that tasks are generated and solved in a deterministic order. Moreover, several advanced techniques, such as the utilization of CP search and general primal heuristics, have been developed to fully utilize distributed computing resources and capabilities of base solvers. Adaptive solving and data communication optimization were also investigated. A popular open-source MILP solver, SCIP, was integrated into N2N as the base solver, yielding N2N-SCIP. Extensive computational experiments were conducted to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a state-of-the-art distributed parallel MILP solver under the UG framework. The nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08 times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP also shows significant performance improvements over ParaSCIP across different process numbers and computing clusters. To validate the generality of N2N, HiGHS, another open-source solver, was integrated into N2N. The related results are analyzed, and the requirements of N2N on base solvers are also concluded.

</details>


### [447] [UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model](https://arxiv.org/abs/2511.18845)
*Changxin Huang,Lv Tang,Zhaohuan Zhan,Lisha Yu,Runhao Zeng,Zun Liu,Zhengjie Wang,Jianqiang Li*

Main category: cs.AI

TL;DR: UNeMo是一个新颖的视觉与语言导航框架，通过多模态世界模型和分层预测-反馈机制，协同优化视觉状态推理和导航决策，在未见场景中显著提升了导航精度。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的导航推理方法仅限于语言模态，缺乏视觉推理能力，且推理模块与导航策略分开优化导致目标冲突。

Method: 引入多模态世界模型(MWM)进行跨模态推理，通过分层预测-反馈机制实现视觉推理与导航策略的双向协同优化。

Result: 在R2R和REVERIE数据集上，UNeMo在未见场景中的导航精度分别比最先进方法提高了2.1%和0.7%。

Conclusion: UNeMo通过协同优化视觉推理和导航决策，有效解决了现有方法的模态限制和优化冲突问题，显著提升了导航性能。

Abstract: Vision-and-Language Navigation (VLN) requires agents to autonomously navigate complex environments via visual images and natural language instruction--remains highly challenging. Recent research on enhancing language-guided navigation reasoning using pre-trained large language models (LLMs) has shown promising prospects. However, the reasoning of such methods is limited to the linguistic modality, lacking visual reasoning capabilities. Moreover, existing reasoning modules are optimized separately from navigation policies, leading to incompatibility and potential conflicts in optimization objectives. To tackle these challenges, we introduce UNeMo, a novel framework designed for the collaborative optimization of visual state reasoning and navigational decision-making. It introduces a Multimodal World Model (MWM) that takes visual features, language instructions, and navigational actions as inputs to jointly predict subsequent visual states, enabling cross-modal reasoning. Via a Hierarchical Prediction-Feedback (HPN) mechanism, MWM collaborates with navigation policies: the first layer generates actions using current vision-and-language features; MWM then infers post-action visual states to guide the second layer's fine-grained decisions. This forms a dynamic bidirectional promotion mechanism where MWM reasoning optimizes navigation policies, while policy decisions feedback to improve MWM's reasoning accuracy. Experiments on R2R and REVERIE datasets show UNeMo outperforms state-of-the-art methods by 2.1% and 0.7% in navigation accuracy for unseen scenes, validating its effectiveness.

</details>


### [448] [GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction](https://arxiv.org/abs/2511.18874)
*Yuzhi Chen,Yuanchang Xie,Lei Zhao,Pan Liu,Yajie Zou,Chen Wang*

Main category: cs.AI

TL;DR: GContextFormer是一个无需高清地图的插拔式编码器-解码器架构，通过全局上下文感知的混合注意力和缩放加性聚合实现意图对齐的多模态轨迹预测，在高速公路匝道场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决高清地图依赖模型的数据获取成本高、更新延迟和输入损坏问题，以及无地图方法缺乏全局上下文、注意力机制过度放大直线模式而抑制过渡模式导致的运动-意图不对齐问题。

Method: 提出运动感知编码器通过有界缩放加性聚合构建场景级意图先验，在共享全局上下文中细化每个模式的表示；分层交互解码器通过双路径交叉注意力分解社交推理，标准路径确保均匀几何覆盖，邻居上下文增强路径强调显著交互，门控模块平衡两者贡献。

Result: 在TOD-VT数据集的八个高速公路匝道场景中，GContextFormer优于最先进的基线方法，相比现有transformer模型在高曲率和过渡区域实现更大鲁棒性和集中改进，通过空间分布展示性能提升。

Conclusion: GContextFormer通过运动模式区分和邻居上下文调制实现可解释性，模块化架构支持跨域多模态推理任务的扩展性，无需地图依赖即可实现意图对齐的多模态预测。

Abstract: Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.

</details>


### [449] [MoodBench 1.0: An Evaluation Benchmark for Emotional Companionship Dialogue Systems](https://arxiv.org/abs/2511.18926)
*Haifeng Jing,Yujie Hou,Junfei Liu,Rui Xie,alan Xu,Jinlong Ma,Qichun Deng*

Main category: cs.AI

TL;DR: 本文提出了情感陪伴对话系统（ECDs）的正式定义，并基于"能力层-任务层（三级）-数据层-方法层"设计原则，开发了首个ECDs评估基准MoodBench 1.0。通过对30个主流模型的评估，验证了该基准的判别有效性，揭示了当前模型在深度情感陪伴方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，对话系统正从信息工具转向情感伴侣，但ECDs领域缺乏清晰定义和系统评估标准，需要建立统一的评估框架来指导技术发展。

Method: 首先提出ECDs的正式定义，然后基于"能力层-任务层（三级）-数据层-方法层"设计原则，构建MoodBench 1.0评估基准，并对30个主流模型进行广泛评估。

Result: MoodBench 1.0展现出优异的判别效度，能有效量化模型在情感陪伴能力上的差异，同时揭示了当前模型在深度情感陪伴方面的不足。

Conclusion: MoodBench 1.0为ECDs提供了系统评估标准，指导未来技术优化，显著帮助开发者提升ECDs的用户体验。

Abstract: With the rapid development of Large Language Models, dialogue systems are shifting from information tools to emotional companions, heralding the era of Emotional Companionship Dialogue Systems (ECDs) that provide personalized emotional support for users. However, the field lacks clear definitions and systematic evaluation standards for ECDs. To address this, we first propose a definition of ECDs with formal descriptions. Then, based on this theory and the design principle of "Ability Layer-Task Layer (three level)-Data Layer-Method Layer", we design and implement the first ECD evaluation benchmark - MoodBench 1.0. Through extensive evaluations of 30 mainstream models, we demonstrate that MoodBench 1.0 has excellent discriminant validity and can effectively quantify the differences in emotional companionship abilities among models. Furthermore, the results reveal current models' shortcomings in deep emotional companionship, guiding future technological optimization and significantly aiding developers in enhancing ECDs' user experience.

</details>


### [450] [Active Inference is a Subtype of Variational Inference](https://arxiv.org/abs/2511.18955)
*Wouter W. L. Nuijten,Mykola Lukashchuk*

Main category: cs.AI

TL;DR: 本文提出了一种新的消息传递方案，将主动推理重新表述为变分推断，解决了EFE最小化的计算可扩展性问题，使主动推理能够在因子状态MDP中高效实现。


<details>
  <summary>Details</summary>
Motivation: 自动化决策在不确定性下需要平衡利用和探索。经典方法使用启发式分别处理这两者，而主动推理通过期望自由能最小化统一它们，但计算成本高昂限制了可扩展性。

Method: 基于将EFE最小化重新表述为变分推断的理论，提出了一个新颖的消息传递方案，用于在因子状态MDP中实现可扩展的主动推理。

Result: 该方法克服了高维规划的计算难处理性，使主动推理能够在因子状态MDP中高效实现。

Conclusion: 通过将主动推理统一为变分推断并开发高效的消息传递方案，实现了可扩展的主动推理，解决了传统方法在不确定性决策中的计算瓶颈问题。

Abstract: Automated decision-making under uncertainty requires balancing exploitation and exploration. Classical methods treat these separately using heuristics, while Active Inference unifies them through Expected Free Energy (EFE) minimization. However, EFE minimization is computationally expensive, limiting scalability. We build on recent theory recasting EFE minimization as variational inference, formally unifying it with Planning-as-Inference and showing the epistemic drive as a unique entropic contribution. Our main contribution is a novel message-passing scheme for this unified objective, enabling scalable Active Inference in factored-state MDPs and overcoming high-dimensional planning intractability.

</details>


### [451] [Synthesizing Visual Concepts as Vision-Language Programs](https://arxiv.org/abs/2511.18964)
*Antonia Wüst,Wolfgang Stammer,Hikaru Shindo,Lukas Helff,Devendra Singh Dhami,Kristian Kersting*

Main category: cs.AI

TL;DR: VLP结合视觉语言模型的感知灵活性与程序合成的系统推理能力，通过将视觉描述编译为神经符号程序来解决视觉推理任务中的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在多模态任务中表现良好，但在系统视觉推理任务中经常产生不一致或不合逻辑的输出。神经符号方法虽然能推导可解释的逻辑规则，但使用僵化的、领域特定的感知模块。

Method: 提出视觉语言程序（VLP），利用视觉语言模型生成结构化视觉描述，然后将其编译为神经符号程序。这些程序直接在图像上执行，保持与任务约束的一致性，并提供人类可解释的解释。

Result: 在合成和真实世界数据集上的实验表明，VLP在需要复杂逻辑推理的任务上优于直接和结构化提示方法。

Conclusion: VLP方法成功地将视觉语言模型的感知能力与程序合成的系统推理相结合，提供了可解释且一致的视觉推理解决方案。

Abstract: Vision-Language models (VLMs) achieve strong performance on multimodal tasks but often fail at systematic visual reasoning tasks, leading to inconsistent or illogical outputs. Neuro-symbolic methods promise to address this by inducing interpretable logical rules, though they exploit rigid, domain-specific perception modules. We propose Vision-Language Programs (VLP), which combine the perceptual flexibility of VLMs with systematic reasoning of program synthesis. Rather than embedding reasoning inside the VLM, VLP leverages the model to produce structured visual descriptions that are compiled into neuro-symbolic programs. The resulting programs execute directly on images, remain consistent with task constraints, and provide human-interpretable explanations that enable easy shortcut mitigation. Experiments on synthetic and real-world datasets demonstrate that VLPs outperform direct and structured prompting, particularly on tasks requiring complex logical reasoning.

</details>


### [452] [LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by Large Language Models](https://arxiv.org/abs/2511.18966)
*Muhammad Usman Shahid,Chuadhry Mujeeb Ahmed,Rajiv Ranjan*

Main category: cs.AI

TL;DR: 研究发现LLM生成的C/C++代码存在大量安全漏洞，通过静态分析发现代码中包含大量CWE漏洞，开发者需要谨慎使用AI生成的代码。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的代码安全性是一个重要问题，研究表明这类代码经常包含漏洞且缺乏防御性编程结构，需要系统评估LLM生成代码的安全性。

Method: 使用CWE对已知漏洞进行分类，并将其映射到CVE以研究其严重性，采用10种不同的LLM生成代码，并通过静态分析对输出进行分析。

Result: AI生成代码中存在的CWE数量令人担忧，静态分析显示代码存在大量安全漏洞。

Conclusion: 开发者在使用LLM生成的代码时需要保持谨慎，本研究为推进自动化代码生成和鼓励该领域进一步研究提供了有价值的见解。

Abstract: The security of code generated by large language models (LLMs) is a significant concern, as studies indicate that such code often contains vulnerabilities and lacks essential defensive programming constructs. This work focuses on examining and evaluating the security of LLM-generated code, particularly in the context of C/C++. We categorized known vulnerabilities using the Common Weakness Enumeration (CWE) and, to study their criticality, mapped them to CVEs. We used ten different LLMs for code generation and analyzed the outputs through static analysis. The amount of CWEs present in AI-generated code is concerning. Our findings highlight the need for developers to be cautious when using LLM-generated code. This study provides valuable insights to advance automated code generation and encourage further research in this domain.

</details>


### [453] [Introducing Visual Scenes and Reasoning: A More Realistic Benchmark for Spoken Language Understanding](https://arxiv.org/abs/2511.19005)
*Di Wu,Liting Jiang,Ruiyu Fang,Bianjing,Hongyan Xie,Haoxiang Su,Hao Huang,Zhongjiang He,Shuangyong Song,Xuelong Li*

Main category: cs.AI

TL;DR: VRSLU是一个新颖的SLU数据集，结合视觉图像和显式推理来解决现有数据集在上下文表示和推理过程方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有SLU数据集在表示真实场景方面存在不足：上下文感知使用过于理想化的one-hot向量表示，模型缺乏推理过程。

Method: 使用GPT-4o和FLUX.1-dev生成反映用户环境和状态的图像，并生成标签预测的解释；提出LR-Instruct指令模板，先预测标签再生成推理。

Result: 实验结果表明视觉信息的有效性，并展示了显式推理在推进SLU研究中的潜力。

Conclusion: VRSLU数据集通过整合视觉信息和显式推理，有效解决了现有SLU数据集的局限性，推动了SLU研究向实际应用的发展。

Abstract: Spoken Language Understanding (SLU) consists of two sub-tasks: intent detection (ID) and slot filling (SF). Given its broad range of real-world applications, enhancing SLU for practical deployment is increasingly critical. Profile-based SLU addresses ambiguous user utterances by incorporating context awareness (CA), user profiles (UP), and knowledge graphs (KG) to support disambiguation, thereby advancing SLU research toward real-world applicability. However, existing SLU datasets still fall short in representing real-world scenarios. Specifically, (1) CA uses one-hot vectors for representation, which is overly idealized, and (2) models typically focuses solely on predicting intents and slot labels, neglecting the reasoning process that could enhance performance and interpretability. To overcome these limitations, we introduce VRSLU, a novel SLU dataset that integrates both Visual images and explicit Reasoning. For over-idealized CA, we use GPT-4o and FLUX.1-dev to generate images reflecting users' environments and statuses, followed by human verification to ensure quality. For reasoning, GPT-4o is employed to generate explanations for predicted labels, which are then refined by human annotators to ensure accuracy and coherence. Additionally, we propose an instructional template, LR-Instruct, which first predicts labels and then generates corresponding reasoning. This two-step approach helps mitigate the influence of reasoning bias on label prediction. Experimental results confirm the effectiveness of incorporating visual information and highlight the promise of explicit reasoning in advancing SLU.

</details>


### [454] [EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction](https://arxiv.org/abs/2511.19155)
*Xihe Qiu,Gengchen Ma,Haoyu Wang,Chen Zhan,Xiaoyu Tan,Shuo Li*

Main category: cs.AI

TL;DR: 提出EEG-VLM框架，通过多级特征对齐和视觉增强的语言引导推理，提升基于EEG的睡眠分期分类的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法依赖先验知识和手工特征，现有深度学习模型难以同时捕捉细粒度时频模式并实现临床可解释性，而现有视觉语言模型在处理EEG信号时视觉理解和推理能力有限。

Method: 构建分层视觉语言框架，包含专门的视觉增强模块从中间层特征构建高级视觉token，通过多级对齐机制与低层CLIP特征对齐，并采用思维链推理策略将复杂医学推理分解为可解释的步骤。

Result: 实验结果表明该方法显著提高了视觉语言模型在EEG睡眠分期分类中的准确性和可解释性。

Conclusion: 该方法在临床环境中展示了自动化和可解释EEG分析的潜力。

Abstract: Sleep stage classification based on electroencephalography (EEG) is fundamental for assessing sleep quality and diagnosing sleep-related disorders. However, most traditional machine learning methods rely heavily on prior knowledge and handcrafted features, while existing deep learning models still struggle to jointly capture fine-grained time-frequency patterns and achieve clinical interpretability. Recently, vision-language models (VLMs) have made significant progress in the medical domain, yet their performance remains constrained when applied to physiological waveform data, especially EEG signals, due to their limited visual understanding and insufficient reasoning capability. To address these challenges, we propose EEG-VLM, a hierarchical vision-language framework that integrates multi-level feature alignment with visually enhanced language-guided reasoning for interpretable EEG-based sleep stage classification. Specifically, a specialized visual enhancement module constructs high-level visual tokens from intermediate-layer features to extract rich semantic representations of EEG images. These tokens are further aligned with low-level CLIP features through a multi-level alignment mechanism, enhancing the VLM's image-processing capability. In addition, a Chain-of-Thought (CoT) reasoning strategy decomposes complex medical inference into interpretable logical steps, effectively simulating expert-like decision-making. Experimental results demonstrate that the proposed method significantly improves both the accuracy and interpretability of VLMs in EEG-based sleep stage classification, showing promising potential for automated and explainable EEG analysis in clinical settings.

</details>


### [455] [AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning](https://arxiv.org/abs/2511.19304)
*Jiayi Zhang,Yiran Peng,Fanqi Kong,Yang Cheng,Yifan Wu,Zhaoyang Yu,Jinyu Xiang,Jianhao Ruan,Jinlin Wang,Maojia Song,HongZhang Liu,Xiangru Tang,Bang Liu,Chenglin Wu,Yuyu Luo*

Main category: cs.AI

TL;DR: 提出了AutoEnv框架和AutoEnv-36数据集，用于研究跨环境智能体学习，发现固定学习方法在异构环境中效果有限，需要环境自适应选择方法。


<details>
  <summary>Details</summary>
Motivation: 现有智能体通常在单一环境中自我进化，而人类能适应不同环境，缺乏标准化的异构环境集合和统一的学习表示方法来研究跨环境学习。

Method: 1) 提出AutoEnv框架，将环境分解为转移、观察和奖励的分布，低成本生成异构世界；2) 构建AutoEnv-36数据集；3) 将智能体学习形式化为基于组件的过程，设计八种学习方法。

Result: 七种语言模型在AutoEnv-36上仅获得12-49%的标准化奖励；固定学习方法在环境数量增加时效果快速下降；环境自适应选择方法能显著提升性能但存在收益递减。

Conclusion: 异构环境下的可扩展跨环境泛化需要自适应学习方法，AutoEnv和AutoEnv-36为研究跨环境智能体学习提供了测试平台。

Abstract: Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [456] [Token-Controlled Re-ranking for Sequential Recommendation via LLMs](https://arxiv.org/abs/2511.17913)
*Wenxi Dai,Wujiang Xu,Pinhuan Wang,Dimitris N. Metaxas*

Main category: cs.IR

TL;DR: COREC是一个新颖的基于token增强的重排序框架，通过显式的基于属性的用户控制信号，在保持个性化推荐的同时满足用户的具体要求。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的重排序器缺乏细粒度用户控制机制，难以平衡用户固有偏好与多属性约束，用户只能被动接受推荐结果。

Method: 提出COREC框架，通过token增强技术将用户的具体属性要求融入重排序过程，学习平衡用户指令与潜在偏好。

Result: 实验表明COREC在标准推荐效果上超越最先进基线，并在属性要求遵循方面表现优异，实现了对排名的细粒度可预测操控。

Conclusion: COREC通过赋予用户精确灵活的控制能力，将用户从被动接受者转变为推荐过程的主动合作者，实现了用户需求与个性化推荐的平衡。

Abstract: The widespread adoption of Large Language Models (LLMs) as re-rankers is shifting recommender systems towards a user-centric paradigm. However, a significant gap remains: current re-rankers often lack mechanisms for fine-grained user control. They struggle to balance inherent user preferences with multiple attribute-based constraints, often resorting to simplistic hard filtering that can excessively narrow the recommendation pool and yield suboptimal results. This limitation leaves users as passive recipients rather than active collaborators in the recommendation process. To bridge this gap, we propose COREC, a novel token-augmented re-ranking framework that incorporates specific user requirements in co-creating the recommendation outcome. COREC empowers users to steer re-ranking results with precise and flexible control via explicit, attribute-based signals. The framework learns to balance these commands against latent preferences, yielding rankings that adhere to user instructions without sacrificing personalization. Experiments show that COREC: (1) exceeds state-of-the-art baselines on standard recommendation effectiveness and (2) demonstrates superior adherence to specific attribute requirements, proving that COREC enables fine-grained and predictable manipulation of the rankings.

</details>


### [457] [Extracting Interaction-Aware Monosemantic Concepts in Recommender Systems](https://arxiv.org/abs/2511.18024)
*Dor Arviv,Yehonatan Elisha,Oren Barkan,Noam Koenigstein*

Main category: cs.IR

TL;DR: 提出一种从推荐系统用户和物品嵌入中提取单语义神经元的方法，使用稀疏自编码器揭示预训练表示中的语义结构，并通过预测感知训练目标保持用户-物品交互关系。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统中实现可解释性和可控性，揭示用户和物品嵌入中的语义结构，同时保持用户-物品交互关系，不同于语言模型中的单语义性研究。

Method: 使用稀疏自编码器(SAE)提取单语义神经元，引入预测感知训练目标，通过冻结的推荐器反向传播，使学习到的潜在结构与用户-物品亲和度预测对齐。

Result: 提取的神经元能够捕获类型、流行度和时间趋势等属性，支持目标过滤和内容推广等后处理控制操作，无需修改基础模型。

Conclusion: 该方法在不同推荐模型和数据集上具有通用性，为可解释和可控的个性化推荐提供了实用工具。

Abstract: We present a method for extracting \emph{monosemantic} neurons, defined as latent dimensions that align with coherent and interpretable concepts, from user and item embeddings in recommender systems. Our approach employs a Sparse Autoencoder (SAE) to reveal semantic structure within pretrained representations. In contrast to work on language models, monosemanticity in recommendation must preserve the interactions between separate user and item embeddings. To achieve this, we introduce a \emph{prediction aware} training objective that backpropagates through a frozen recommender and aligns the learned latent structure with the model's user-item affinity predictions. The resulting neurons capture properties such as genre, popularity, and temporal trends, and support post hoc control operations including targeted filtering and content promotion without modifying the base model. Our method generalizes across different recommendation models and datasets, providing a practical tool for interpretable and controllable personalization. Code and evaluation resources are available at https://github.com/DeltaLabTLV/Monosemanticity4Rec.

</details>


### [458] [Fidelity-Aware Recommendation Explanations via Stochastic Path Integration](https://arxiv.org/abs/2511.18047)
*Oren Barkan,Yahlly Schein,Yehonatan Elisha,Veronika Bogina,Mikhail Baklanov,Noam Koenigstein*

Main category: cs.IR

TL;DR: SPINRec是一种模型无关的推荐系统解释方法，通过随机路径集成技术提高解释保真度，在多个模型和数据集上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中的解释保真度（即解释准确反映模型真实推理的程度）研究严重不足，现有方法在稀疏隐式推荐数据上存在局限性。

Method: SPINRec采用随机基线采样方法，从经验数据分布中采样多个合理用户档案，选择最忠实的归因路径，捕捉观察和未观察交互的影响。

Result: 在三个模型（MF、VAE、NCF）和三个数据集（ML1M、Yahoo! Music、Pinterest）上的综合评估显示，SPINRec在所有基线上表现一致最优。

Conclusion: SPINRec为推荐系统建立了新的忠实可解释性基准，代码和评估工具已公开。

Abstract: Explanation fidelity, which measures how accurately an explanation reflects a model's true reasoning, remains critically underexplored in recommender systems. We introduce SPINRec (Stochastic Path Integration for Neural Recommender Explanations), a model-agnostic approach that adapts path-integration techniques to the sparse and implicit nature of recommendation data. To overcome the limitations of prior methods, SPINRec employs stochastic baseline sampling: instead of integrating from a fixed or unrealistic baseline, it samples multiple plausible user profiles from the empirical data distribution and selects the most faithful attribution path. This design captures the influence of both observed and unobserved interactions, yielding more stable and personalized explanations. We conduct the most comprehensive fidelity evaluation to date across three models (MF, VAE, NCF), three datasets (ML1M, Yahoo! Music, Pinterest), and a suite of counterfactual metrics, including AUC-based perturbation curves and fixed-length diagnostics. SPINRec consistently outperforms all baselines, establishing a new benchmark for faithful explainability in recommendation. Code and evaluation tools are publicly available at https://github.com/DeltaLabTLV/SPINRec.

</details>


### [459] [ProHD: Projection-Based Hausdorff Distance Approximation](https://arxiv.org/abs/2511.18207)
*Jiuzhou Fu,Luanzheng Guo,Nathan R. Tallent,Dongfang Zhao*

Main category: cs.IR

TL;DR: ProHD是一种投影引导的近似算法，通过将数据投影到少量信息方向来识别候选极端点，从而显著加速Hausdorff距离计算，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: Hausdorff距离是集合差异性的鲁棒度量，但在大型高维数据集上精确计算成本过高，需要快速可靠的集合距离估计算法。

Method: 通过将数据投影到质心轴和主要主成分等少量信息方向上，识别候选极端点子集，在该子集上计算Hausdorff距离。

Result: 在图像、物理和合成数据集（高达200万点，D=256）上，ProHD比精确算法快10-100倍，比随机采样近似方法误差低5-20倍，通常能达到与精确值相差几个百分点的结果。

Conclusion: ProHD为大型向量数据库和流数据等场景提供了实用的Hausdorff距离计算方法，实现了快速可靠的集合距离估计。

Abstract: The Hausdorff distance (HD) is a robust measure of set dissimilarity, but computing it exactly on large, high-dimensional datasets is prohibitively expensive. We propose \textbf{ProHD}, a projection-guided approximation algorithm that dramatically accelerates HD computation while maintaining high accuracy. ProHD identifies a small subset of candidate "extreme" points by projecting the data onto a few informative directions (such as the centroid axis and top principal components) and computing the HD on this subset. This approach guarantees an underestimate of the true HD with a bounded additive error and typically achieves results within a few percent of the exact value. In extensive experiments on image, physics, and synthetic datasets (up to two million points in $D=256$), ProHD runs 10--100$\times$ faster than exact algorithms while attaining 5--20$\times$ lower error than random sampling-based approximations. Our method enables practical HD calculations in scenarios like large vector databases and streaming data, where quick and reliable set distance estimation is needed.

</details>


### [460] [LLM Reasoning for Cold-Start Item Recommendation](https://arxiv.org/abs/2511.18261)
*Shijun Li,Yu Wang,Jin Wang,Ying Li,Joydeep Ghosh,Anne Cocos*

Main category: cs.IR

TL;DR: 本文提出针对Netflix领域冷启动物品推荐的新推理策略，利用LLM的推理能力推断用户偏好，显著提升冷启动推荐性能，在某些情况下比Netflix生产排序模型表现提升8%。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注有丰富用户-物品交互数据的暖启动场景，而更具挑战性的冷启动场景（稀疏交互阻碍传统协同过滤方法）研究不足，需要利用LLM的推理能力来解决这一问题。

Method: 利用LLM的高级推理能力有效推断用户偏好，特别是对新引入或很少交互的物品。系统评估了监督微调、基于强化学习的微调以及结合两种方法的混合方法来优化推荐性能。

Result: 在真实世界数据上的广泛实验表明，在冷启动推荐场景中方法有效性和实际性能均有显著提升。基于推理的微调模型在某些情况下比Netflix的生产排序模型表现提升8%。

Conclusion: LLM的推理能力可以有效解决冷启动推荐问题，提出的推理策略在Netflix领域冷启动物品推荐中表现出色，为冷启动推荐提供了新的解决方案。

Abstract: Large Language Models (LLMs) have shown significant potential for improving recommendation systems through their inherent reasoning capabilities and extensive knowledge base. Yet, existing studies predominantly address warm-start scenarios with abundant user-item interaction data, leaving the more challenging cold-start scenarios, where sparse interactions hinder traditional collaborative filtering methods, underexplored. To address this limitation, we propose novel reasoning strategies designed for cold-start item recommendations within the Netflix domain. Our method utilizes the advanced reasoning capabilities of LLMs to effectively infer user preferences, particularly for newly introduced or rarely interacted items. We systematically evaluate supervised fine-tuning, reinforcement learning-based fine-tuning, and hybrid approaches that combine both methods to optimize recommendation performance. Extensive experiments on real-world data demonstrate significant improvements in both methodological efficacy and practical performance in cold-start recommendation contexts. Remarkably, our reasoning-based fine-tuned models outperform Netflix's production ranking model by up to 8% in certain cases.

</details>


### [461] [Democratic Recommendation with User and Item Representatives Produced by Graph Condensation](https://arxiv.org/abs/2511.18279)
*Jiahao Liang,Haoran Yang,Xiangyu Zhao,Zhiwen Yu,Guandong Xu,Wanyu Wang,Kaixiang Yang*

Main category: cs.IR

TL;DR: 论文提出DemoRec框架，利用图压缩技术生成用户和物品代表，构建紧凑的交互图，显著降低图规模和计算复杂度，同时缓解大规模二分图中对高阶信息的过度依赖问题。


<details>
  <summary>Details</summary>
Motivation: 大规模用户-物品交互图在基于图的推荐系统中面临计算效率低和信息传播不足的挑战，现有方法存在泛化能力差、信息丢失等问题，图压缩技术为此提供了新的解决方向。

Method: 基于民主原则提出DemoRec框架，通过图压缩生成用户和物品代表，构建紧凑交互图，并对具有共享特征的节点进行聚类。

Result: 在四个公共数据集上的实验表明，DemoRec在推荐性能、计算效率和鲁棒性方面相比最先进方法有显著提升。

Conclusion: DemoRec框架通过图压缩技术有效解决了大规模二分图推荐系统的挑战，在保持推荐性能的同时显著提升了计算效率。

Abstract: The challenges associated with large-scale user-item interaction graphs have attracted increasing attention in graph-based recommendation systems, primarily due to computational inefficiencies and inadequate information propagation. Existing methods provide partial solutions but suffer from notable limitations: model-centric approaches, such as sampling and aggregation, often struggle with generalization, while data-centric techniques, including graph sparsification and coarsening, lead to information loss and ineffective handling of bipartite graph structures. Recent advances in graph condensation offer a promising direction by reducing graph size while preserving essential information, presenting a novel approach to mitigating these challenges. Inspired by the principles of democracy, we propose \textbf{DemoRec}, a framework that leverages graph condensation to generate user and item representatives for recommendation tasks. By constructing a compact interaction graph and clustering nodes with shared characteristics from the original graph, DemoRec significantly reduces graph size and computational complexity. Furthermore, it mitigates the over-reliance on high-order information, a critical challenge in large-scale bipartite graphs. Extensive experiments conducted on four public datasets demonstrate the effectiveness of DemoRec, showcasing substantial improvements in recommendation performance, computational efficiency, and robustness compared to SOTA methods.

</details>


### [462] [UFO: Unfair-to-Fair Evolving Mitigates Unfairness in LLM-based Recommender Systems via Self-Play Fine-tuning](https://arxiv.org/abs/2511.18342)
*Jiaming Zhang,Yuyuan Li,Xiaohua Feng,Zhifei Ren,Li Zhang,Chaochao Chen*

Main category: cs.IR

TL;DR: 本文提出UFO框架，通过自我博弈机制解决基于大语言模型的推荐系统中的项目侧不公平问题，发现不公平不仅来自监督微调，还来自预训练阶段的偏见放大。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注监督微调阶段的不公平问题，但忽视了预训练阶段的偏见来源，且难以在消除不公平的同时保持推荐性能。

Method: 提出UFO框架，采用自我博弈机制，将不公平缓解建模为双玩家游戏：评判者识别预训练和监督微调中的不公平，校正者调整推荐系统以解决不公平同时保持性能。

Result: 大量实验表明，UFO能有效缓解不公平问题，同时提升推荐性能。

Conclusion: UFO框架通过迭代优化完全解决了不公平问题，证明了同时考虑预训练和监督微调阶段偏见的必要性。

Abstract: Large language model-based Recommender Systems (LRSs) have demonstrated superior recommendation performance by integrating pre-training with Supervised Fine-Tuning (SFT). However, this approach introduces item-side unfairness. Existing studies primarily attribute this issue to the absence of fairness constraints during SFT and attempt to mitigate unfairness via re-weighting and re-ranking methods. In this paper, we find that unfairness arises not only from SFT but also from pre-training, where inherent biases are further amplified during SFT. This finding underscores the failure of current methods to address the root causes of unfairness. Moreover, current methods struggle to preserve satisfactory recommendation performance. To tackle these issues, we propose an Unfair-to-Fair evOlving (UFO) framework using a self-play mechanism, formulating unfairness mitigation as a two-player game. UFO alternates between two player roles: the \textit{judger}, which identifies unfairness from both pre-training and SFT, and the \textit{corrector}, which adjusts the LRS to address identified unfairness while preserving recommendation performance. Iterative optimization between these roles enables UFO to completely resolve unfairness. Extensive experiments demonstrate that UFO effectively mitigates unfairness while improving recommendation performance.

</details>


### [463] [Time Matters: Enhancing Sequential Recommendations with Time-Guided Graph Neural ODEs](https://arxiv.org/abs/2511.18347)
*Haoyan Fu,Zhida Qin,Shixiao Yang,Haoyao Zhang,Bin Lu,Shuang Li,Tianyu Huang,John C. S. Lui*

Main category: cs.IR

TL;DR: TGODE模型通过构建用户时间图和物品演化图，利用时间引导扩散生成器增强稀疏时间交互，并结合图神经ODE来匹配用户偏好和物品分布的演化模式，显著提升序列推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐方法忽视了两个关键因素：用户交互间的不规则兴趣变化和物品分布的时间不均匀性。前者导致历史交互可能与当前行为无关，后者由于季节性趋势或促销活动造成分布偏差，影响推荐准确性。

Method: 1. 构建用户时间图和物品演化图；2. 设计时间引导扩散生成器增强稀疏时间交互；3. 引入用户兴趣截断因子识别稀疏时间区间；4. 使用图神经ODE对齐用户偏好和物品分布的演化。

Result: 在五个数据集上的实验表明，TGODE相比基线方法性能提升10%到46%。

Conclusion: TGODE通过有效处理用户兴趣不规则性和物品分布不均匀性，显著提升了序列推荐的准确性和鲁棒性。

Abstract: Sequential recommendation (SR) is widely deployed in e-commerce platforms, streaming services, etc., revealing significant potential to enhance user experience. However, existing methods often overlook two critical factors: irregular user interests between interactions and highly uneven item distributions over time. The former factor implies that actual user preferences are not always continuous, and long-term historical interactions may not be relevant to current purchasing behavior. Therefore, relying only on these historical interactions for recommendations may result in a lack of user interest at the target time. The latter factor, characterized by peaks and valleys in interaction frequency, may result from seasonal trends, special events, or promotions. These externally driven distributions may not align with individual user interests, leading to inaccurate recommendations. To address these deficiencies, we propose TGODE to both enhance and capture the long-term historical interactions. Specifically, we first construct a user time graph and item evolution graph, which utilize user personalized preferences and global item distribution information, respectively. To tackle the temporal sparsity caused by irregular user interactions, we design a time-guided diffusion generator to automatically obtain an augmented time-aware user graph. Additionally, we devise a user interest truncation factor to efficiently identify sparse time intervals and achieve balanced preference inference. After that, the augmented user graph and item graph are fed into a generalized graph neural ordinary differential equation (ODE) to align with the evolution of user preferences and item distributions. This allows two patterns of information evolution to be matched over time. Experimental results demonstrate that TGODE outperforms baseline methods across five datasets, with improvements ranging from 10% to 46%.

</details>


### [464] [A Recommender System Based on Binary Matrix Representations for Cognitive Disorders](https://arxiv.org/abs/2511.18645)
*Raoul H. Kutil,Georg Zimmermann,Christian Borgelt*

Main category: cs.IR

TL;DR: 开发了一个基于二元矩阵的认知障碍诊断推荐系统，通过症状-障碍关系矩阵来识别潜在障碍并推荐最有信息量的下一步症状。


<details>
  <summary>Details</summary>
Motivation: 认知障碍诊断复杂且困难，需要专业知识来识别症状重叠和区分不同障碍，基于症状的导航具有挑战性。

Method: 使用二元矩阵表示障碍及其症状组合，基于患者当前症状过滤矩阵行和列，识别潜在障碍并推荐最有信息量的下一步症状。

Result: 原型系统成功从初始症状集识别出合理障碍，推荐了进一步症状来完善诊断，并提供了症状-障碍关系的额外背景信息。

Conclusion: 该推荐系统有潜力作为临床支持工具，可帮助精神健康专业人员更有效地识别相关障碍并指导症状特异性随访调查，提高诊断准确性。

Abstract: Diagnosing cognitive (mental health) disorders is a delicate and complex task. Identifying the next most informative symptoms to assess, in order to distinguish between possible disorders, presents an additional challenge. This process requires comprehensive knowledge of diagnostic criteria and symptom overlap across disorders, making it difficult to navigate based on symptoms alone. This research aims to develop a recommender system for cognitive disorder diagnosis using binary matrix representations. The core algorithm utilizes a binary matrix of disorders and their symptom combinations. It filters through the rows and columns based on the patient's current symptoms to identify potential disorders and recommend the most informative next symptoms to examine. A prototype of the recommender system was implemented in Python. Using synthetic test and some real-life data, the system successfully identified plausible disorders from an initial symptom set and recommended further symptoms to refine the diagnosis. It also provided additional context on the symptom-disorder relationships. Although this is a prototype, the recommender system shows potential as a clinical support tool. A fully-developed application of this recommender system may assist mental health professionals in identifying relevant disorders more efficiently and guiding symptom-specific follow-up investigations to improve diagnostic accuracy.

</details>


### [465] [When and What to Recommend: Joint Modeling of Timing and Content for Active Sequential Recommendation](https://arxiv.org/abs/2511.18717)
*Jin Chai,Xiaoxiao Ma,Jian Yang,Jia Wu*

Main category: cs.IR

TL;DR: PASRec是一个基于扩散模型的主动推荐框架，能够预测用户兴趣时间并主动推荐物品，解决了传统被动推荐系统在用户关闭应用后无法推荐的问题。


<details>
  <summary>Details</summary>
Motivation: 现有顺序推荐系统大多是被动的，只在用户打开应用时响应，错过了用户关闭应用后的推荐机会。因此需要研究主动推荐，预测下一次交互时间并主动推送物品。

Method: 提出PASRec框架，使用扩散模型通过联合目标对齐兴趣时间(ToI)和兴趣物品(IoI)，准确估计用户兴趣时间并生成相应的推荐物品。

Result: 在五个基准数据集上的实验表明，PASRec在留一法和时间分割两种评估方式下均优于八个最先进的基线方法。

Conclusion: PASRec通过扩散模型成功实现了主动推荐，能够准确预测用户兴趣时间并生成相应的推荐物品，显著提升了推荐效果。

Abstract: Sequential recommendation models user preferences to predict the next target item. Most existing work is passive, where the system responds only when users open the application, missing chances after closure. We investigate active recommendation, which predicts the next interaction time and actively delivers items. Two challenges: accurately estimating the Time of Interest (ToI) and generating Item of Interest (IoI) conditioned on the predicted ToI. We propose PASRec, a diffusion-based framework that aligns ToI and IoI via a joint objective. Experiments on five benchmarks show superiority over eight state-of-the-art baselines under leave-one-out and temporal splits.

</details>


### [466] [Multimodal Large Language Models with Adaptive Preference Optimization for Sequential Recommendation](https://arxiv.org/abs/2511.18740)
*Yu Wang,Yonghui Yang,Le Wu,Yi Zhang,Richang Hong*

Main category: cs.IR

TL;DR: HaNoRec是一个用于多模态序列推荐的多模态大语言模型框架，通过动态调整样本权重和引入高斯扰动来改善样本硬度不平衡和跨模态语义偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅使用文本模态，忽略了丰富的视觉信号（如产品图像），导致无法捕捉用户的细粒度兴趣。同时，监督微调（SFT）和直接偏好优化（DPO）存在样本硬度不平衡和跨模态语义偏差的问题。

Method: 提出HaNoRec框架，包含：1）基于样本估计硬度和模型实时响应性动态调整优化权重，优先处理困难样本；2）在输出logits上引入高斯扰动的分布优化，增强跨模态语义一致性。

Result: 该方法能够更有效地处理困难样本，减少跨模态语义偏差，提高推荐性能。

Conclusion: HaNoRec通过硬度感知和噪声正则化的偏好优化，解决了多模态序列推荐中的关键挑战，为利用多模态大语言模型进行推荐提供了有效方案。

Abstract: Recent advances in Large Language Models (LLMs) have opened new avenues for sequential recommendation by enabling natural language reasoning over user behavior sequences. A common approach formulates recommendation as a language modeling task, where interaction histories are transformed into prompts and user preferences are learned via supervised fine-tuning. However, these methods operate solely in the textual modality and often miss users' fine-grained interests, especially when shaped by rich visual signals such as product images or movie posters. Multimodal Large Language Models (MLLMs) offer a promising alternative by aligning text and vision in a shared semantic space. A prevalent training paradigm applies Supervised Fine-Tuning (SFT) followed by Direct Preference Optimization (DPO) to model user preferences. Yet, two core challenges remain: 1) Imbalanced sample hardness, where random negative sampling causes overfitting on easy examples and under-training on hard ones; 2) Cross-modal semantic bias, where the fixed reference model in DPO prevents the policy model from correcting modality misalignments--especially over long sequences. To address these issues, we propose a Multimodal LLM framework that integrates Hardness-aware and Noise-regularized preference optimization for Recommendation (HaNoRec). Specifically, HaNoRec dynamically adjusts optimization weights based on both the estimated hardness of each training sample and the policy model's real-time responsiveness, prioritizing harder examples. It further introduces Gaussian-perturbed distribution optimization on output logits to enhance cross-modal semantic consistency and reduce modality bias inherited from the reference model.

</details>


### [467] [STORE: Semantic Tokenization, Orthogonal Rotation and Efficient Attention for Scaling Up Ranking Models](https://arxiv.org/abs/2511.18805)
*Yi Xu,Chaofan Fan,Jinxin Hu,Yu Zhang,Zeng Xiaoyi,Jing Zhang*

Main category: cs.IR

TL;DR: STORE是一个基于令牌的可扩展排名框架，通过语义令牌化、正交旋转变换和高效注意力机制解决推荐系统中的表示瓶颈和计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 解决高基数、异构和稀疏特征空间中的模型可扩展性和效率问题，特别是表示瓶颈（低秩表示导致One-Epoch和Interaction-Collapse现象）和计算瓶颈（特征令牌爆炸导致注意力机制计算需求大且易分散）。

Method: 提出STORE框架，包含三个核心创新：1）语义令牌化将高基数稀疏特征分解为紧凑的稳定语义令牌；2）正交旋转变换旋转低基数静态特征的子空间以促进更有效的特征交互；3）高效注意力机制过滤低贡献令牌以提高计算效率。

Result: 在离线和在线A/B测试中，该框架持续提升预测准确性（在线CTR提升2.71%，AUC提升1.195%）和训练效率（吞吐量提升1.84倍）。

Conclusion: STORE框架成功解决了推荐系统中的表示和计算瓶颈，显著提高了模型性能和效率。

Abstract: Ranking models have become an important part of modern personalized recommendation systems. However, significant challenges persist in handling high-cardinality, heterogeneous, and sparse feature spaces, particularly regarding model scalability and efficiency. We identify two key bottlenecks: (i) Representation Bottleneck: Driven by the high cardinality and dynamic nature of features, model capacity is forced into sparse-activated embedding layers, leading to low-rank representations. This, in turn, triggers phenomena like "One-Epoch" and "Interaction-Collapse," ultimately hindering model scalability.(ii) Computational Bottleneck: Integrating all heterogeneous features into a unified model triggers an explosion in the number of feature tokens, rendering traditional attention mechanisms computationally demanding and susceptible to attention dispersion. To dismantle these barriers, we introduce STORE, a unified and scalable token-based ranking framework built upon three core innovations: (1) Semantic Tokenization fundamentally tackles feature heterogeneity and sparsity by decomposing high-cardinality sparse features into a compact set of stable semantic tokens; and (2) Orthogonal Rotation Transformation is employed to rotate the subspace spanned by low-cardinality static features, which facilitates more efficient and effective feature interactions; and (3) Efficient attention that filters low-contributing tokens to improve computional efficiency while preserving model accuracy. Across extensive offline experiments and online A/B tests, our framework consistently improves prediction accuracy(online CTR by 2.71%, AUC by 1.195%) and training effeciency (1.84 throughput).

</details>


### [468] [Heterogeneous Multi-treatment Uplift Modeling for Trade-off Optimization in Short-Video Recommendation](https://arxiv.org/abs/2511.18997)
*Chenhao Zhai,Chang Meng,Xueliang Wang,Shuchang Liu,Xiaolong Hu,Shisong Tang,Xiaoqiang Feng,Xiu Li*

Main category: cs.IR

TL;DR: 提出了一种用于短视频推荐权衡优化的异构多处理提升建模框架，包含离线混合提升建模和在线动态决策模块，在快手平台验证有效并已部署。


<details>
  <summary>Details</summary>
Motivation: 解决短视频推荐中用户偏好多样、不同策略响应冲突的问题，现有提升模型难以处理异构多处理场景，传统固定权重方法缺乏个性化。

Method: HMUM框架包含离线混合提升建模模块捕获多策略的协同和个体效应，以及在线动态决策模块实时估计不同用户响应的价值权重进行个性化决策。

Result: 在两个公共数据集、工业数据集和快手平台在线A/B实验中表现出优越的离线性能和关键指标的显著提升。

Conclusion: 该模型已在快手平台全面部署，为数亿用户提供服务，有效解决了短视频推荐中的权衡优化问题。

Abstract: The rapid proliferation of short videos on social media platforms presents unique challenges and opportunities for recommendation systems. Users exhibit diverse preferences, and the responses resulting from different strategies often conflict with one another, potentially exhibiting inverse correlations between metrics such as watch time and video view counts. Existing uplift models face limitations in handling the heterogeneous multi-treatment scenarios of short-video recommendations, often failing to effectively capture both the synergistic and individual causal effects of different strategies. Furthermore, traditional fixed-weight approaches for balancing these responses lack personalization and can result in biased decision-making. To address these issues, we propose a novel Heterogeneous Multi-treatment Uplift Modeling (HMUM) framework for trade-off optimization in short-video recommendations. HMUM comprises an Offline Hybrid Uplift Modeling (HUM) module, which captures the synergistic and individual effects of multiple strategies, and an Online Dynamic Decision-Making (DDM) module, which estimates the value weights of different user responses in real-time for personalized decision-making. Evaluated on two public datasets, an industrial dataset, and through online A/B experiments on the Kuaishou platform, our model demonstrated superior offline performance and significant improvements in key metrics. It is now fully deployed on the platform, benefiting hundreds of millions of users.

</details>


### [469] [BioArtlas: Computational Clustering of Multi-Dimensional Complexity in Bioart](https://arxiv.org/abs/2511.19162)
*Joonhyung Bae*

Main category: cs.IR

TL;DR: BioArtlas是一个分析81件生物艺术作品的系统，使用13个维度进行多轴分类，通过代码本方法处理文化术语的多义性，并开发了交互式网页界面供公众探索。


<details>
  <summary>Details</summary>
Motivation: 生物艺术的混合性质跨越艺术、科学、技术、伦理和政治，难以用传统的单轴分类方法来分析，因此需要新的多维度分析方法。

Method: 使用轴感知表示方法，将相关概念分组到统一簇中，通过代码本方法解决文化术语的多义性问题，评估了800种表示空间-算法组合。

Result: 确定了在4D UMAP上使用k=15的凝聚聚类为最优方法（轮廓系数0.664±0.008，可信度/连续性0.805/0.812），揭示了四种组织模式：艺术家特定的方法一致性、基于技术的分割、时间艺术演变和跨时间概念亲和性。

Conclusion: 通过将分析优化与公共传播分离，提供了严格的分析和可访问的探索方式，开发了交互式网页界面并公开了数据集。

Abstract: Bioart's hybrid nature spanning art, science, technology, ethics, and politics defies traditional single-axis categorization. I present BioArtlas, analyzing 81 bioart works across thirteen curated dimensions using novel axis-aware representations that preserve semantic distinctions while enabling cross-dimensional comparison. Our codebook-based approach groups related concepts into unified clusters, addressing polysemy in cultural terminology. Comprehensive evaluation of up to 800 representation-space-algorithm combinations identifies Agglomerative clustering at k=15 on 4D UMAP as optimal (silhouette 0.664 +/- 0.008, trustworthiness/continuity 0.805/0.812). The approach reveals four organizational patterns: artist-specific methodological cohesion, technique-based segmentation, temporal artistic evolution, and trans-temporal conceptual affinities. By separating analytical optimization from public communication, I provide rigorous analysis and accessible exploration through an interactive web interface (https://www.bioartlas.com) with the dataset publicly available (https://github.com/joonhyungbae/BioArtlas).

</details>


### [470] [What Drives Cross-lingual Ranking? Retrieval Approaches with Multilingual Language Models](https://arxiv.org/abs/2511.19324)
*Roksana Goworek,Olivia Macmillan-Scott,Eda B. Özyiğit*

Main category: cs.IR

TL;DR: 本文系统评估了跨语言信息检索中的四种干预方法，发现专门训练的密集检索模型优于词汇匹配方法，翻译文档收益有限，对比学习能缓解语言偏见，重排序效果取决于训练数据质量。


<details>
  <summary>Details</summary>
Motivation: 跨语言信息检索面临资源差异、文字系统不同和嵌入模型跨语言语义对齐弱等挑战，现有基于翻译和单语检索的流水线方法存在计算开销大和噪声问题。

Method: 系统评估四种干预类型：文档翻译、多语言密集检索与预训练编码器、词/短语/查询-文档级别的对比学习、交叉编码器重排序，在三个基准数据集上进行测试。

Result: 专门为CLIR训练的密集检索模型始终优于词汇匹配方法，文档翻译收益很小；对比学习显著改善初始对齐弱的编码器；重排序有效但依赖训练数据质量；低资源和跨文字语言对改进最明显。

Conclusion: 跨语言搜索系统应优先考虑语义多语言嵌入和针对性学习对齐，而非基于翻译的流水线方法，特别是对于跨文字和资源匮乏语言。

Abstract: Cross-lingual information retrieval (CLIR) enables access to multilingual knowledge but remains challenging due to disparities in resources, scripts, and weak cross-lingual semantic alignment in embedding models. Existing pipelines often rely on translation and monolingual retrieval heuristics, which add computational overhead and noise, degrading performance. This work systematically evaluates four intervention types, namely document translation, multilingual dense retrieval with pretrained encoders, contrastive learning at word, phrase, and query-document levels, and cross-encoder re-ranking, across three benchmark datasets. We find that dense retrieval models trained specifically for CLIR consistently outperform lexical matching methods and derive little benefit from document translation. Contrastive learning mitigates language biases and yields substantial improvements for encoders with weak initial alignment, and re-ranking can be effective, but depends on the quality of the cross-encoder training data. Although high-resource languages still dominate overall performance, gains over lexical and document-translated baselines are most pronounced for low-resource and cross-script pairs. These findings indicate that cross-lingual search systems should prioritise semantic multilingual embeddings and targeted learning-based alignment over translation-based pipelines, particularly for cross-script and under-resourced languages.

</details>


### [471] [Generative Query Expansion with Multilingual LLMs for Cross-Lingual Information Retrieval](https://arxiv.org/abs/2511.19325)
*Olivia Macmillan-Scott,Roksana Goworek,Eda B. Özyiğit*

Main category: cs.IR

TL;DR: 本文评估了多语言大语言模型在跨语言查询扩展中的表现，发现查询长度决定提示技术的有效性，语言差异显著影响检索性能，微调仅在训练和测试数据格式相似时有效。


<details>
  <summary>Details</summary>
Motivation: 研究多语言大语言模型在跨语言信息检索中的查询扩展能力，识别影响检索性能的关键因素，以改进跨语言检索效果。

Method: 使用多语言大语言模型及其微调变体，评估多种生成式扩展策略，分析不同提示技术、语言差异和微调对检索性能的影响。

Result: 查询长度是决定提示技术有效性的主要因素；语言差异显著，不同文字系统间的检索效果尤其差；微调仅在训练和测试数据格式相似时带来性能提升。

Conclusion: 需要更平衡的多语言和跨语言训练与评估资源，以解决语言差异和格式不一致导致的性能问题。

Abstract: Query expansion is the reformulation of a user query by adding semantically related information, and is an essential component of monolingual and cross-lingual information retrieval used to ensure that relevant documents are not missed. Recently, multilingual large language models (mLLMs) have shifted query expansion from semantic augmentation with synonyms and related words to pseudo-document generation. Pseudo-documents both introduce additional relevant terms and bridge the gap between short queries and long documents, which is particularly beneficial in dense retrieval. This study evaluates recent mLLMs and fine-tuned variants across several generative expansion strategies to identify factors that drive cross-lingual retrieval performance. Results show that query length largely determines which prompting technique is effective, and that more elaborate prompts often do not yield further gains. Substantial linguistic disparities persist: cross-lingual query expansion can produce the largest improvements for languages with the weakest baselines, yet retrieval is especially poor between languages written in different scripts. Fine-tuning is found to lead to performance gains only when the training and test data are of similar format. These outcomes underline the need for more balanced multilingual and cross-lingual training and evaluation resources.

</details>


### [472] [Revisiting Feedback Models for HyDE](https://arxiv.org/abs/2511.19349)
*Nour Jedidi,Jimmy Lin*

Main category: cs.IR

TL;DR: 本文重新评估了传统反馈模型在HyDE方法中的应用，发现使用Rocchio等反馈算法可以显著提升基于LLM的伪相关反馈方法的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前利用大语言模型进行伪相关反馈的方法通常没有使用成熟的反馈模型如Rocchio和RM3，而是简单地将查询与LLM生成的内容进行字符串拼接。本文旨在探究这种简单方法是否最优。

Method: 在流行的HyDE方法基础上，系统性地评估传统反馈模型的应用。HyDE方法通过LLM生成假设答案文档来丰富查询表示。

Result: 实验表明，当利用Rocchio等反馈算法来提取和加权扩展词项时，HyDE的有效性可以得到显著提升。

Conclusion: 使用传统反馈算法为基于LLM的伪相关反馈方法提供了一种简单而有效的改进方式。

Abstract: Recent approaches that leverage large language models (LLMs) for pseudo-relevance feedback (PRF) have generally not utilized well-established feedback models like Rocchio and RM3 when expanding queries for sparse retrievers like BM25. Instead, they often opt for a simple string concatenation of the query and LLM-generated expansion content. But is this optimal? To answer this question, we revisit and systematically evaluate traditional feedback models in the context of HyDE, a popular method that enriches query representations with LLM-generated hypothetical answer documents. Our experiments show that HyDE's effectiveness can be substantially improved when leveraging feedback algorithms such as Rocchio to extract and weight expansion terms, providing a simple way to further enhance the accuracy of LLM-based PRF methods.

</details>
