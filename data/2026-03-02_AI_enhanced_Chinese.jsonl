{"id": "2502.01476", "categories": ["cs.LG", "math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2502.01476", "abs": "https://arxiv.org/abs/2502.01476", "authors": ["Orestis Oikonomou", "Levi Lingsch", "Dana Grund", "Siddhartha Mishra", "Georgios Kissas"], "title": "Neuro-Symbolic AI for Analytical Solutions of Differential Equations", "comment": "Updates the method and added extra results", "summary": "Analytical solutions to differential equations offer exact, interpretable insight but are rarely available because discovering them requires expert intuition or exhaustive search in combinatorial spaces. We introduce SIGS, a neuro-symbolic framework that automates this process. SIGS uses a formal grammar to generate only syntactically valid building blocks, embeds these expressions into a continuous space, and then searches this space to assemble, score, and refine candidate closed-form solutions by minimizing a physics-based residual. This design unifies symbolic reasoning with numerical optimization; the grammar constrains candidate solution blocks to be proper by construction, while the latent search makes exploration tractable and data-free. SIGS is the first neuro-symbolic method to (i) analytically solve coupled systems of nonlinear PDEs, (ii) discover solutions under grammar misspecification, and (iii) produce accurate symbolic approximations for PDEs lacking known closed-form solutions. Overall, SIGS achieves orders-of-magnitude improvements in accuracy and efficiency over existing symbolic methods on standard benchmarks.", "AI": {"tldr": "SIGS\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u5f62\u5f0f\u8bed\u6cd5\u751f\u6210\u6709\u6548\u6784\u5efa\u5757\uff0c\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u641c\u7d22\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u7269\u7406\u6b8b\u5dee\u6765\u7ec4\u88c5\u3001\u8bc4\u5206\u548c\u4f18\u5316\u5019\u9009\u89e3\u6790\u89e3\uff0c\u5b9e\u73b0\u5fae\u5206\u65b9\u7a0b\u89e3\u6790\u89e3\u7684\u81ea\u52a8\u5316\u53d1\u73b0\u3002", "motivation": "\u5fae\u5206\u65b9\u7a0b\u7684\u89e3\u6790\u89e3\u80fd\u63d0\u4f9b\u7cbe\u786e\u3001\u53ef\u89e3\u91ca\u7684\u6d1e\u5bdf\uff0c\u4f46\u901a\u5e38\u96be\u4ee5\u83b7\u5f97\uff0c\u56e0\u4e3a\u53d1\u73b0\u5b83\u4eec\u9700\u8981\u4e13\u5bb6\u76f4\u89c9\u6216\u5728\u7ec4\u5408\u7a7a\u95f4\u4e2d\u8fdb\u884c\u7a77\u4e3e\u641c\u7d22\u3002", "method": "SIGS\u4f7f\u7528\u5f62\u5f0f\u8bed\u6cd5\u751f\u6210\u8bed\u6cd5\u6709\u6548\u7684\u6784\u5efa\u5757\uff0c\u5c06\u8fd9\u4e9b\u8868\u8fbe\u5f0f\u5d4c\u5165\u8fde\u7eed\u7a7a\u95f4\uff0c\u7136\u540e\u5728\u8be5\u7a7a\u95f4\u4e2d\u641c\u7d22\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u57fa\u4e8e\u7269\u7406\u7684\u6b8b\u5dee\u6765\u7ec4\u88c5\u3001\u8bc4\u5206\u548c\u4f18\u5316\u5019\u9009\u89e3\u6790\u89e3\u3002", "result": "SIGS\u662f\u7b2c\u4e00\u4e2a\u80fd\u591f\u89e3\u6790\u6c42\u89e3\u8026\u5408\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7ec4\u3001\u5728\u8bed\u6cd5\u89c4\u8303\u4e0d\u5b8c\u6574\u65f6\u53d1\u73b0\u89e3\u3001\u5e76\u4e3a\u7f3a\u4e4f\u5df2\u77e5\u89e3\u6790\u89e3\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u4ea7\u751f\u51c6\u786e\u7b26\u53f7\u8fd1\u4f3c\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u63d0\u5347\u3002", "conclusion": "SIGS\u901a\u8fc7\u7edf\u4e00\u7b26\u53f7\u63a8\u7406\u548c\u6570\u503c\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u5fae\u5206\u65b9\u7a0b\u89e3\u6790\u89e3\u7684\u81ea\u52a8\u5316\u53d1\u73b0\uff0c\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7b26\u53f7\u65b9\u6cd5\u3002"}}
{"id": "2602.23647", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23647", "abs": "https://arxiv.org/abs/2602.23647", "authors": ["Quanjun Zhang", "Chengyu Gao", "Yu Han", "Ye Shang", "Chunrong Fang", "Zhenyu Chen", "Liang Xiao"], "title": "SGAgent: Suggestion-Guided LLM-Based Multi-Agent Framework for Repository-Level Software Repair", "comment": "23 pages, 3 figures", "summary": "The rapid advancement of Large Language Models (LLMs) has led to the emergence of intelligent agents capable of autonomously interacting with environments and invoking external tools. Recently, agent-based software repair approaches have received widespread attention, as repair agents can automatically analyze and localize bugs, generate patches, and achieve state-of-the-art performance on repository-level benchmarks. However, existing approaches usually adopt a localize-then-fix paradigm, jumping directly from \"where the bug is\" to \"how to fix it\", leaving a fundamental reasoning gap. To this end, we propose SGAgent, a Suggestion-Guided multi-Agent framework for repository-level software repair, which follows a localize-suggest-fix paradigm. SGAgent introduces a suggestion phase to strengthen the transition from localization to repair. The suggester starts from the buggy locations and incrementally retrieves relevant context until it fully understands the bug, and then provides actionable repair suggestions. Moreover, we construct a Knowledge Graph from the target repository and develop a KG-based toolkit to enhance SGAgent's global contextual awareness and repository-level reasoning. Three specialized sub-agents (i.e., localizer, suggester, and fixer) collaborate to achieve automated end-to-end software repair. Experimental results on SWE-Bench show that SGAgent with Claude-3.5 achieves 51.3% repair accuracy, 81.2% file-level and 52.4% function-level localization accuracy with an average cost of $1.48 per instance, outperforming all baselines using the same base model. Furthermore, SGAgent attains 48% accuracy on VUL4J and VJBench for vulnerability repair, demonstrating strong generalization across tasks and programming languages.", "AI": {"tldr": "SGAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684\u8f6f\u4ef6\u4fee\u590d\u6846\u67b6\uff0c\u91c7\u7528\u5b9a\u4f4d-\u5efa\u8bae-\u4fee\u590d\u8303\u5f0f\uff0c\u901a\u8fc7\u5f15\u5165\u5efa\u8bae\u9636\u6bb5\u6765\u5f25\u8865\u4f20\u7edf\u5b9a\u4f4d-\u4fee\u590d\u65b9\u6cd5\u7684\u63a8\u7406\u7a7a\u767d\uff0c\u5728SWE-Bench\u4e0a\u8fbe\u523051.3%\u7684\u4fee\u590d\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u8f6f\u4ef6\u4fee\u590d\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u5b9a\u4f4d-\u4fee\u590d\u8303\u5f0f\uff0c\u76f4\u63a5\u4ece\"bug\u5728\u54ea\u91cc\"\u8df3\u5230\"\u5982\u4f55\u4fee\u590d\"\uff0c\u5b58\u5728\u6839\u672c\u6027\u7684\u63a8\u7406\u7a7a\u767d\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u52a0\u5f3a\u4ece\u5b9a\u4f4d\u5230\u4fee\u590d\u7684\u8fc7\u6e21\u3002", "method": "\u63d0\u51faSGAgent\u6846\u67b6\uff0c\u91c7\u7528\u5b9a\u4f4d-\u5efa\u8bae-\u4fee\u590d\u4e09\u9636\u6bb5\u8303\u5f0f\uff1a1\uff09\u5f15\u5165\u5efa\u8bae\u9636\u6bb5\uff0c\u4ecebug\u4f4d\u7f6e\u9010\u6b65\u68c0\u7d22\u76f8\u5173\u4e0a\u4e0b\u6587\u76f4\u5230\u5b8c\u5168\u7406\u89e3bug\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u4fee\u590d\u5efa\u8bae\uff1b2\uff09\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u5168\u5c40\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u4ed3\u5e93\u7ea7\u63a8\u7406\uff1b3\uff09\u4e09\u4e2a\u4e13\u95e8\u5b50\u667a\u80fd\u4f53\uff08\u5b9a\u4f4d\u5668\u3001\u5efa\u8bae\u5668\u3001\u4fee\u590d\u5668\uff09\u534f\u4f5c\u5b9e\u73b0\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u8f6f\u4ef6\u4fee\u590d\u3002", "result": "\u5728SWE-Bench\u4e0a\uff0cSGAgent\u4f7f\u7528Claude-3.5\u8fbe\u523051.3%\u4fee\u590d\u51c6\u786e\u7387\uff0c81.2%\u6587\u4ef6\u7ea7\u548c52.4%\u51fd\u6570\u7ea7\u5b9a\u4f4d\u51c6\u786e\u7387\uff0c\u5e73\u5747\u6bcf\u4e2a\u5b9e\u4f8b\u6210\u672c1.48\u7f8e\u5143\uff0c\u4f18\u4e8e\u6240\u6709\u4f7f\u7528\u76f8\u540c\u57fa\u7840\u6a21\u578b\u7684\u57fa\u7ebf\u3002\u5728VUL4J\u548cVJBench\u6f0f\u6d1e\u4fee\u590d\u4efb\u52a1\u4e0a\u8fbe\u523048%\u51c6\u786e\u7387\uff0c\u5c55\u793a\u4e86\u8de8\u4efb\u52a1\u548c\u7f16\u7a0b\u8bed\u8a00\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SGAgent\u901a\u8fc7\u5f15\u5165\u5efa\u8bae\u9636\u6bb5\u548c\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u5b9a\u4f4d-\u4fee\u590d\u8303\u5f0f\u7684\u63a8\u7406\u7a7a\u767d\u95ee\u9898\uff0c\u5728\u8f6f\u4ef6\u4fee\u590d\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u826f\u597d\u7684\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.23391", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23391", "abs": "https://arxiv.org/abs/2602.23391", "authors": ["Nazanin Mohammadi Sepahvand", "Eleni Triantafillou", "Hugo Larochelle", "Doina Precup", "Daniel M. Roy", "Gintare Karolina Dziugaite"], "title": "Detoxifying LLMs via Representation Erasure-Based Preference Optimization", "comment": null, "summary": "Large language models (LLMs) trained on webscale data can produce toxic outputs, raising concerns for safe deployment. Prior defenses, based on applications of DPO, NPO, and similar algorithms, reduce the likelihood of harmful continuations, but not robustly so: they are vulnerable to adversarial prompting and easily undone by fine-tuning-based relearning attacks. Indeed, research has shown that these edits to the model are superficial: linear probing reveals that harmful \"directions\" remain present in representations. To address this, we propose Representation Erasure-based Preference Optimization (REPO), reformulating detoxification as a token-level preference problem. Using a novel objective with preference data, we force the representations of toxic continuations to converge toward their benign counterparts. Our mechanistic analysis reveals that this granular approach is critical: unlike baselines, REPO induces deep, localized edits to toxicity-encoding neurons while preserving general model utility. Exhaustive evaluations show that REPO achieves state-of-the-art robustness, stopping sophisticated threats-including relearning attacks and enhanced GCG jailbreaks-where existing representation- and output-based methods fail.", "AI": {"tldr": "REPO\u662f\u4e00\u79cd\u65b0\u7684\u8bed\u8a00\u6a21\u578b\u53bb\u6bd2\u65b9\u6cd5\uff0c\u901a\u8fc7\u8868\u793a\u64e6\u9664\u548c\u504f\u597d\u4f18\u5316\uff0c\u5728token\u7ea7\u522b\u6d88\u9664\u6bd2\u6027\u8868\u793a\uff0c\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u6a21\u578b\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eDPO\u3001NPO\u7b49\u65b9\u6cd5\u7684\u53bb\u6bd2\u9632\u5fa1\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5b83\u4eec\u53ea\u80fd\u964d\u4f4e\u6709\u5bb3\u8f93\u51fa\u7684\u53ef\u80fd\u6027\uff0c\u4f46\u4e0d\u591f\u9c81\u68d2\uff0c\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u63d0\u793a\u548c\u5fae\u8c03\u91cd\u65b0\u5b66\u4e60\u653b\u51fb\u7684\u5f71\u54cd\u3002\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u7f16\u8f91\u662f\u8868\u9762\u7684\uff0c\u6709\u5bb3\u7684\"\u65b9\u5411\"\u4ecd\u7136\u5b58\u5728\u4e8e\u8868\u793a\u4e2d\u3002", "method": "\u63d0\u51fa\u8868\u793a\u64e6\u9664\u504f\u597d\u4f18\u5316\uff08REPO\uff09\uff0c\u5c06\u53bb\u6bd2\u91cd\u65b0\u5b9a\u4e49\u4e3atoken\u7ea7\u522b\u7684\u504f\u597d\u95ee\u9898\u3002\u4f7f\u7528\u65b0\u9896\u7684\u76ee\u6807\u51fd\u6570\u548c\u504f\u597d\u6570\u636e\uff0c\u5f3a\u5236\u6bd2\u6027\u5ef6\u7eed\u7684\u8868\u793a\u5411\u826f\u6027\u5bf9\u5e94\u7269\u6536\u655b\u3002\u8fd9\u79cd\u65b9\u6cd5\u8fdb\u884c\u6df1\u5ea6\u3001\u5c40\u90e8\u5316\u7684\u7f16\u8f91\uff0c\u9488\u5bf9\u6bd2\u6027\u7f16\u7801\u795e\u7ecf\u5143\u3002", "result": "REPO\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u963b\u6b62\u590d\u6742\u7684\u5a01\u80c1\uff0c\u5305\u62ec\u91cd\u65b0\u5b66\u4e60\u653b\u51fb\u548c\u589e\u5f3a\u7684GCG\u8d8a\u72f1\u653b\u51fb\uff0c\u800c\u73b0\u6709\u7684\u57fa\u4e8e\u8868\u793a\u548c\u8f93\u51fa\u7684\u65b9\u6cd5\u90fd\u5931\u8d25\u4e86\u3002\u673a\u5236\u5206\u6790\u663e\u793aREPO\u80fd\u8bf1\u5bfc\u6df1\u5ea6\u3001\u5c40\u90e8\u5316\u7684\u7f16\u8f91\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u4e00\u822c\u6548\u7528\u3002", "conclusion": "REPO\u901a\u8fc7token\u7ea7\u522b\u7684\u8868\u793a\u64e6\u9664\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9c81\u68d2\u7684\u8bed\u8a00\u6a21\u578b\u53bb\u6bd2\uff0c\u80fd\u591f\u6709\u6548\u9632\u5fa1\u5404\u79cd\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23367", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23367", "abs": "https://arxiv.org/abs/2602.23367", "authors": ["Shubh Laddha", "Lucas Changbencharoen", "Win Kuptivej", "Surya Shringla", "Archana Vaidheeswaran", "Yash Bhaskar"], "title": "HumanMCP: A Human-Like Query Dataset for Evaluating MCP Tool Retrieval Performance", "comment": "4 pages, 2 figures, 3 tables", "summary": "Model Context Protocol (MCP) servers contain a collection of thousands of open-source standardized tools, linking LLMs to external systems; however, existing datasets and benchmarks lack realistic, human-like user queries, remaining a critical gap in evaluating the tool usage and ecosystems of MCP servers. Existing datasets often do contain tool descriptions but fail to represent how different users portray their requests, leading to poor generalization and inflated reliability of certain benchmarks. This paper introduces the first large-scale MCP dataset featuring diverse, high-quality diverse user queries generated specifically to match 2800 tools across 308 MCP servers, developing on the MCP Zero dataset. Each tool is paired with multiple unique user personas that we have generated, to capture varying levels of user intent ranging from precise task requests, and ambiguous, exploratory commands, reflecting the complexity of real-world interaction patterns.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21MCP\u6570\u636e\u96c6\uff0c\u5305\u542b\u9488\u5bf9308\u4e2aMCP\u670d\u52a1\u5668\u4e2d2800\u4e2a\u5de5\u5177\u7684\u591a\u6837\u5316\u3001\u9ad8\u8d28\u91cf\u7528\u6237\u67e5\u8be2\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u6a21\u5f0f\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709MCP\u5de5\u5177\u4f7f\u7528\u6570\u636e\u96c6\u7f3a\u4e4f\u771f\u5b9e\u3001\u4eba\u6027\u5316\u7684\u7528\u6237\u67e5\u8be2\uff0c\u65e0\u6cd5\u53cd\u6620\u4e0d\u540c\u7528\u6237\u5982\u4f55\u8868\u8fbe\u8bf7\u6c42\uff0c\u5bfc\u81f4\u8bc4\u4f30\u5de5\u5177\u4f7f\u7528\u548c\u751f\u6001\u7cfb\u7edf\u65f6\u5b58\u5728\u5173\u952e\u5dee\u8ddd\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u6cdb\u5316\u80fd\u529b\u5dee\u4e14\u53ef\u9760\u6027\u88ab\u5938\u5927\u3002", "method": "\u57fa\u4e8eMCP Zero\u6570\u636e\u96c6\uff0c\u4e3a308\u4e2aMCP\u670d\u52a1\u5668\u4e2d\u76842800\u4e2a\u5de5\u5177\u751f\u6210\u591a\u6837\u5316\u3001\u9ad8\u8d28\u91cf\u7684\u7528\u6237\u67e5\u8be2\uff0c\u6bcf\u4e2a\u5de5\u5177\u914d\u5bf9\u591a\u4e2a\u72ec\u7279\u7684\u7528\u6237\u89d2\u8272\uff0c\u6db5\u76d6\u4ece\u7cbe\u786e\u4efb\u52a1\u8bf7\u6c42\u5230\u6a21\u7cca\u63a2\u7d22\u6027\u547d\u4ee4\u7684\u4e0d\u540c\u7528\u6237\u610f\u56fe\u5c42\u6b21\u3002", "result": "\u521b\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21MCP\u6570\u636e\u96c6\uff0c\u5305\u542b\u9488\u5bf92800\u4e2a\u5de5\u5177\u7684\u591a\u6837\u5316\u7528\u6237\u67e5\u8be2\uff0c\u53cd\u6620\u4e86\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u6a21\u5f0f\u7684\u590d\u6742\u6027\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30MCP\u670d\u52a1\u5668\u7684\u5de5\u5177\u4f7f\u7528\u548c\u751f\u6001\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86MCP\u5de5\u5177\u4f7f\u7528\u8bc4\u4f30\u7684\u5173\u952e\u7a7a\u767d\uff0c\u901a\u8fc7\u5f15\u5165\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u6a21\u5f0f\u7684\u6570\u636e\u96c6\uff0c\u4e3a\u66f4\u51c6\u786e\u8bc4\u4f30MCP\u670d\u52a1\u5668\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u548c\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2602.23736", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23736", "abs": "https://arxiv.org/abs/2602.23736", "authors": ["Ruixiang Qian", "Chunrong Fang", "Zengxu Chen", "Youxin Fu", "Zhenyu Chen"], "title": "Peeling Off the Cocoon: Unveiling Suppressed Golden Seeds for Mutational Greybox Fuzzing", "comment": "Accepted by OOPSLA 2026", "summary": "PoCo is a technique that aims to enhance modern coverage-based seed selection (CSS) techniques (such as afl-cmin) by gradually removing obstacle conditional statements and conducting deeper seed selection.", "AI": {"tldr": "PoCo\u662f\u4e00\u79cd\u589e\u5f3a\u73b0\u4ee3\u57fa\u4e8e\u8986\u76d6\u7387\u7684\u79cd\u5b50\u9009\u62e9\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9010\u6b65\u79fb\u9664\u969c\u788d\u6761\u4ef6\u8bed\u53e5\u5e76\u8fdb\u884c\u66f4\u6df1\u5c42\u6b21\u7684\u79cd\u5b50\u9009\u62e9\u6765\u6539\u8fdbafl-cmin\u7b49\u6280\u672f", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u8986\u76d6\u7387\u7684\u79cd\u5b50\u9009\u62e9\u6280\u672f\uff08\u5982afl-cmin\uff09\u5728\u5904\u7406\u5305\u542b\u590d\u6742\u6761\u4ef6\u8bed\u53e5\u7684\u7a0b\u5e8f\u65f6\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u63a2\u7d22\u6240\u6709\u4ee3\u7801\u8def\u5f84\uff0c\u5b58\u5728\u4f18\u5316\u7a7a\u95f4", "method": "PoCo\u91c7\u7528\u6e10\u8fdb\u5f0f\u65b9\u6cd5\uff0c\u9010\u6b65\u8bc6\u522b\u548c\u79fb\u9664\u7a0b\u5e8f\u4e2d\u7684\u969c\u788d\u6761\u4ef6\u8bed\u53e5\uff0c\u7136\u540e\u8fdb\u884c\u66f4\u6df1\u5c42\u6b21\u7684\u79cd\u5b50\u9009\u62e9\uff0c\u4ee5\u66f4\u5168\u9762\u5730\u63a2\u7d22\u4ee3\u7801\u8def\u5f84", "result": "PoCo\u80fd\u591f\u6bd4\u4f20\u7edfCSS\u6280\u672f\u66f4\u6709\u6548\u5730\u53d1\u73b0\u65b0\u7684\u4ee3\u7801\u8def\u5f84\uff0c\u63d0\u9ad8\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u589e\u5f3a\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u679c", "conclusion": "PoCo\u901a\u8fc7\u6e10\u8fdb\u5f0f\u79fb\u9664\u969c\u788d\u6761\u4ef6\u8bed\u53e5\u548c\u6df1\u5ea6\u79cd\u5b50\u9009\u62e9\uff0c\u663e\u8457\u6539\u8fdb\u4e86\u73b0\u6709\u57fa\u4e8e\u8986\u76d6\u7387\u7684\u79cd\u5b50\u9009\u62e9\u6280\u672f\uff0c\u4e3a\u6a21\u7cca\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177"}}
{"id": "2602.23369", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23369", "abs": "https://arxiv.org/abs/2602.23369", "authors": ["Xuanming Cui", "Hong-You Chen", "Hao Yu", "Hao Yuan", "Zihao Wang", "Shlok Kumar Mishra", "Hanchao Yu", "Yonghuan Yang", "Jun Xiao", "Ser-Nam Lim", "Jianpeng Cheng", "Qi Guo", "Xiangjun Fan"], "title": "Reason to Contrast: A Cascaded Multimodal Retrieval Framework", "comment": null, "summary": "Traditional multimodal retrieval systems rely primarily on bi-encoder architectures, where performance is closely tied to embedding dimensionality. Recent work, Think-Then-Embed (TTE), shows that incorporating multimodal reasoning to elicit additional informative tokens before embedding can further improve retrieval. In this paper, we extend this paradigm with TTE-v2, a hybrid multimodal retrieval framework that introduces reasoning-driven performance scaling based on additional input token budget rather than model or embedding size. Our approach augments the initial multimodal retrieval with additional reasoning steps for reranking, enabling more expressive query-candidate interactions at test time. The reranking stage further provides fine-grained supervision for hard negative mining and false negative filtering, creating a feedback loop that effectively strengthens the upstream retriever. This cascaded design delivers substantial test-time improvements based on intermediate reasoning token scaling. Experiments on the MMEB-V2 benchmark demonstrate that TTE-v2-7B achieves a new state-of-the-art accuracy of 75.7%, and that TTE-v2-2B matches or surpasses leading 7B models trained with significantly larger external data. Our results highlight the promise of token-wise scaling as an alternative scaling paradigm for multimodal retrieval.", "AI": {"tldr": "TTE-v2\u662f\u4e00\u4e2a\u6df7\u5408\u591a\u6a21\u6001\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u989d\u5916\u8f93\u5165token\u9884\u7b97\u7684\u63a8\u7406\u9a71\u52a8\u6027\u80fd\u6269\u5c55\uff0c\u800c\u975e\u4f9d\u8d56\u6a21\u578b\u6216\u5d4c\u5165\u5927\u5c0f\uff0c\u5b9e\u73b0\u4e86\u65b0\u7684\u6027\u80fd\u7a81\u7834\u3002", "motivation": "\u4f20\u7edf\u591a\u6a21\u6001\u68c0\u7d22\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u6027\u80fd\u4e0e\u5d4c\u5165\u7ef4\u5ea6\u7d27\u5bc6\u76f8\u5173\u3002\u867d\u7136TTE\u901a\u8fc7\u5f15\u5165\u591a\u6a21\u6001\u63a8\u7406\u5728\u5d4c\u5165\u524d\u751f\u6210\u989d\u5916\u4fe1\u606ftoken\u6765\u6539\u8fdb\u68c0\u7d22\uff0c\u4f46\u4ecd\u9700\u63a2\u7d22\u66f4\u6709\u6548\u7684\u6027\u80fd\u6269\u5c55\u8303\u5f0f\u3002", "method": "\u63d0\u51faTTE-v2\u6df7\u5408\u591a\u6a21\u6001\u68c0\u7d22\u6846\u67b6\uff0c\u91c7\u7528\u7ea7\u8054\u8bbe\u8ba1\uff1a1\uff09\u521d\u59cb\u591a\u6a21\u6001\u68c0\u7d22\uff1b2\uff09\u57fa\u4e8e\u989d\u5916\u63a8\u7406\u6b65\u9aa4\u7684\u91cd\u65b0\u6392\u5e8f\u9636\u6bb5\uff0c\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u67e5\u8be2-\u5019\u9009\u4ea4\u4e92\uff1b3\uff09\u91cd\u65b0\u6392\u5e8f\u9636\u6bb5\u4e3a\u786c\u8d1f\u6837\u672c\u6316\u6398\u548c\u5047\u8d1f\u6837\u672c\u8fc7\u6ee4\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u76d1\u7763\uff0c\u5f62\u6210\u53cd\u9988\u5faa\u73af\u589e\u5f3a\u4e0a\u6e38\u68c0\u7d22\u5668\u3002", "result": "\u5728MMEB-V2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTTE-v2-7B\u8fbe\u523075.7%\u7684\u6700\u65b0\u6700\u9ad8\u51c6\u786e\u7387\uff0cTTE-v2-2B\u5339\u914d\u6216\u8d85\u8d8a\u4f7f\u7528\u663e\u8457\u66f4\u5927\u5916\u90e8\u6570\u636e\u8bad\u7ec3\u7684\u9886\u51487B\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u57fa\u4e8etoken\u6269\u5c55\u7684\u66ff\u4ee3\u6269\u5c55\u8303\u5f0f\u7684\u6f5c\u529b\u3002", "conclusion": "TTE-v2\u901a\u8fc7\u63a8\u7406\u9a71\u52a8\u7684\u6027\u80fd\u6269\u5c55\u8303\u5f0f\uff0c\u57fa\u4e8e\u4e2d\u95f4\u63a8\u7406token\u7f29\u653e\u5b9e\u73b0\u663e\u8457\u7684\u6d4b\u8bd5\u65f6\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86token\u7ea7\u6269\u5c55\u4f5c\u4e3a\u591a\u6a21\u6001\u68c0\u7d22\u66ff\u4ee3\u6269\u5c55\u8303\u5f0f\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.23400", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23400", "abs": "https://arxiv.org/abs/2602.23400", "authors": ["Zezheng Wu", "Rui Wang", "Xinghe Cheng", "Yang Shao", "Qing Yang", "Jiapu Wang", "Jingwei Zhang"], "title": "U-CAN: Utility-Aware Contrastive Attenuation for Efficient Unlearning in Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GenRec) typically leverages Large Language Models (LLMs) to redefine personalization as an instruction-driven sequence generation task. However, fine-tuning on user logs inadvertently encodes sensitive attributes into model parameters, raising critical privacy concerns. Existing Machine Unlearning (MU) techniques struggle to navigate this tension due to the Polysemy Dilemma, where neurons superimpose sensitive data with general reasoning patterns, leading to catastrophic utility loss under traditional gradient or pruning methods. To address this, we propose Utility-aware Contrastive AttenuatioN (U-CAN), a precision unlearning framework that operates on low-rank adapters. U-CAN quantifies risk by contrasting activations and focuses on neurons with asymmetric responses that are highly sensitive to the forgetting set but suppressed on the retention set. To safeguard performance, we introduce a utility-aware calibration mechanism that combines weight magnitudes with retention-set activation norms, assigning higher utility scores to dimensions that contribute strongly to retention performance. Unlike binary pruning, which often fragments network structure, U-CAN develop adaptive soft attenuation with a differentiable decay function to selectively down-scale high-risk parameters on LoRA adapters, suppressing sensitive retrieval pathways and preserving the topological connectivity of reasoning circuits. Experiments on two public datasets across seven metrics demonstrate that U-CAN achieves strong privacy forgetting, utility retention, and computational efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faU-CAN\u6846\u67b6\uff0c\u901a\u8fc7\u4f4e\u79e9\u9002\u914d\u5668\u4e0a\u7684\u7cbe\u51c6\u9057\u5fd8\u6280\u672f\u89e3\u51b3\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u9690\u79c1\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u5bfc\u81f4\u7684\u707e\u96be\u6027\u6548\u7528\u635f\u5931\u3002", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u5728\u5fae\u8c03\u65f6\u4f1a\u65e0\u610f\u4e2d\u5c06\u654f\u611f\u5c5e\u6027\u7f16\u7801\u5230\u6a21\u578b\u53c2\u6570\u4e2d\uff0c\u5f15\u53d1\u9690\u79c1\u62c5\u5fe7\u3002\u73b0\u6709\u7684\u673a\u5668\u9057\u5fd8\u6280\u672f\u9762\u4e34\u591a\u4e49\u6027\u56f0\u5883\uff0c\u5373\u795e\u7ecf\u5143\u540c\u65f6\u7f16\u7801\u654f\u611f\u6570\u636e\u548c\u4e00\u822c\u63a8\u7406\u6a21\u5f0f\uff0c\u5bfc\u81f4\u4f20\u7edf\u68af\u5ea6\u6216\u526a\u679d\u65b9\u6cd5\u9020\u6210\u707e\u96be\u6027\u7684\u6548\u7528\u635f\u5931\u3002", "method": "\u63d0\u51faUtility-aware Contrastive AttenuatioN (U-CAN)\u6846\u67b6\uff0c\u5728\u4f4e\u79e9\u9002\u914d\u5668\u4e0a\u64cd\u4f5c\u3002\u901a\u8fc7\u5bf9\u6bd4\u6fc0\u6d3b\u91cf\u5316\u98ce\u9669\uff0c\u4e13\u6ce8\u4e8e\u5bf9\u9057\u5fd8\u96c6\u9ad8\u5ea6\u654f\u611f\u4f46\u5bf9\u4fdd\u7559\u96c6\u6291\u5236\u7684\u795e\u7ecf\u5143\u3002\u5f15\u5165\u6548\u7528\u611f\u77e5\u6821\u51c6\u673a\u5236\uff0c\u7ed3\u5408\u6743\u91cd\u5927\u5c0f\u548c\u4fdd\u7559\u96c6\u6fc0\u6d3b\u8303\u6570\uff0c\u4e3a\u5bf9\u4fdd\u7559\u6027\u80fd\u8d21\u732e\u5927\u7684\u7ef4\u5ea6\u5206\u914d\u66f4\u9ad8\u7684\u6548\u7528\u5206\u6570\u3002\u91c7\u7528\u81ea\u9002\u5e94\u8f6f\u8870\u51cf\u65b9\u6cd5\uff0c\u4f7f\u7528\u53ef\u5fae\u8870\u51cf\u51fd\u6570\u9009\u62e9\u6027\u5730\u964d\u4f4eLoRA\u9002\u914d\u5668\u4e0a\u7684\u9ad8\u98ce\u9669\u53c2\u6570\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u4e03\u4e2a\u6307\u6807\u5b9e\u9a8c\u8868\u660e\uff0cU-CAN\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u9690\u79c1\u9057\u5fd8\u3001\u6548\u7528\u4fdd\u7559\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "U-CAN\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u9690\u79c1\u9057\u5fd8\u95ee\u9898\uff0c\u901a\u8fc7\u7cbe\u51c6\u7684\u53c2\u6570\u8870\u51cf\u65b9\u6cd5\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u7f3a\u9677\u3002"}}
{"id": "2602.23409", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.23409", "abs": "https://arxiv.org/abs/2602.23409", "authors": ["Michael Poppel", "Jonas Stein", "Sebastian W\u00f6lckert", "Markus Baumann", "Claudia Linnhoff-Popien"], "title": "Long Range Frequency Tuning for QML", "comment": null, "summary": "Quantum machine learning models using angle encoding naturally represent truncated Fourier series, providing universal function approximation capabilities with sufficient circuit depth. For unary fixed-frequency encodings, circuit depth scales as O(omega_max * (omega_max + epsilon^{-2})) with target frequency magnitude omega_max and precision epsilon. Trainable-frequency approaches theoretically reduce this to match the target spectrum size, requiring only as many encoding gates as frequencies in the target spectrum. Despite this compelling efficiency, their practical effectiveness hinges on a key assumption: that gradient-based optimization can drive prefactors to arbitrary target values. We demonstrate through systematic experiments that frequency prefactors exhibit limited trainability: movement is constrained to approximately +/-1 units with typical learning rates. When target frequencies lie outside this reachable range, optimization frequently fails. To overcome this frequency reachability limitation, we propose grid-based initialization using ternary encodings, which generate dense integer frequency spectra. While this approach requires O(log_3(omega_max)) encoding gates -- more than the theoretical optimum but exponentially fewer than fixed-frequency methods -- it ensures target frequencies lie within the locally reachable range. On synthetic targets with three shifted high frequencies, ternary grid initialization achieves a median R^2 score of 0.9969, compared to 0.1841 for the trainable-frequency baseline. For the real-world Flight Passengers dataset, ternary grid initialization achieves a median R^2 score of 0.9671, representing a 22.8% improvement over trainable-frequency initialization (median R^2 = 0.7876).", "AI": {"tldr": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u89d2\u5ea6\u7f16\u7801\u6a21\u578b\u5728\u53ef\u8bad\u7ec3\u9891\u7387\u65b9\u6cd5\u4e2d\u9762\u4e34\u9891\u7387\u53ef\u8bad\u7ec3\u6027\u9650\u5236\uff0c\u63d0\u51fa\u57fa\u4e8e\u4e09\u5143\u7f16\u7801\u7684\u7f51\u683c\u521d\u59cb\u5316\u65b9\u6cd5\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u53ef\u8bad\u7ec3\u9891\u7387\u7f16\u7801\u65b9\u6cd5\u7406\u8bba\u4e0a\u6548\u7387\u5f88\u9ad8\uff0c\u4f46\u5b9e\u9645\u4f18\u5316\u4e2d\u9891\u7387\u9884\u56e0\u5b50\u7684\u53ef\u8bad\u7ec3\u6027\u6709\u9650\uff0c\u5f53\u76ee\u6807\u9891\u7387\u8d85\u51fa\u53ef\u8fbe\u8303\u56f4\u65f6\u4f18\u5316\u7ecf\u5e38\u5931\u8d25\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u9891\u7387\u53ef\u8fbe\u6027\u9650\u5236\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e09\u5143\u7f16\u7801\u7684\u7f51\u683c\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u751f\u6210\u5bc6\u96c6\u7684\u6574\u6570\u9891\u7387\u8c31\uff0c\u786e\u4fdd\u76ee\u6807\u9891\u7387\u4f4d\u4e8e\u5c40\u90e8\u53ef\u8fbe\u8303\u56f4\u5185\u3002\u8be5\u65b9\u6cd5\u9700\u8981O(log_3(omega_max))\u4e2a\u7f16\u7801\u95e8\uff0c\u6bd4\u56fa\u5b9a\u9891\u7387\u65b9\u6cd5\u6307\u6570\u7ea7\u51cf\u5c11\u3002", "result": "\u5728\u4e09\u9891\u79fb\u9ad8\u9891\u7387\u5408\u6210\u76ee\u6807\u4e0a\uff0c\u4e09\u5143\u7f51\u683c\u521d\u59cb\u5316\u4e2d\u4f4dR\u00b2\u5f97\u52060.9969\uff0c\u800c\u53ef\u8bad\u7ec3\u9891\u7387\u57fa\u7ebf\u4ec5\u4e3a0.1841\u3002\u5728\u5b9e\u9645\u822a\u73ed\u4e58\u5ba2\u6570\u636e\u96c6\u4e0a\uff0c\u4e09\u5143\u7f51\u683c\u521d\u59cb\u5316\u4e2d\u4f4dR\u00b2\u5f97\u52060.9671\uff0c\u6bd4\u53ef\u8bad\u7ec3\u9891\u7387\u521d\u59cb\u5316\uff080.7876\uff09\u63d0\u534722.8%\u3002", "conclusion": "\u9891\u7387\u9884\u56e0\u5b50\u7684\u53ef\u8bad\u7ec3\u6027\u9650\u5236\u662f\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u89d2\u5ea6\u7f16\u7801\u6a21\u578b\u7684\u5b9e\u9645\u74f6\u9888\uff0c\u4e09\u5143\u7f51\u683c\u521d\u59cb\u5316\u65b9\u6cd5\u901a\u8fc7\u786e\u4fdd\u76ee\u6807\u9891\u7387\u5728\u5c40\u90e8\u53ef\u8fbe\u8303\u56f4\u5185\uff0c\u6709\u6548\u514b\u670d\u4e86\u8fd9\u4e00\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.23541", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23541", "abs": "https://arxiv.org/abs/2602.23541", "authors": ["Arvind Raghavan", "Elias Bareinboim"], "title": "Causal Identification from Counterfactual Data: Completeness and Bounding Results", "comment": null, "summary": "Previous work establishing completeness results for $\\textit{counterfactual identification}$ has been circumscribed to the setting where the input data belongs to observational or interventional distributions (Layers 1 and 2 of Pearl's Causal Hierarchy), since it was generally presumed impossible to obtain data from counterfactual distributions, which belong to Layer 3. However, recent work (Raghavan & Bareinboim, 2025) has formally characterized a family of counterfactual distributions which can be directly estimated via experimental methods - a notion they call $\\textit{counterfactual realizabilty}$. This leaves open the question of what $\\textit{additional}$ counterfactual quantities now become identifiable, given this new access to (some) Layer 3 data. To answer this question, we develop the CTFIDU+ algorithm for identifying counterfactual queries from an arbitrary set of Layer 3 distributions, and prove that it is complete for this task. Building on this, we establish the theoretical limit of which counterfactuals can be identified from physically realizable distributions, thus implying the $\\textit{fundamental limit to exact causal inference in the non-parametric setting}$. Finally, given the impossibility of identifying certain critical types of counterfactuals, we derive novel analytic bounds for such quantities using realizable counterfactual data, and corroborate using simulations that counterfactual data helps tighten the bounds for non-identifiable quantities in practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CTFIDU+\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u4efb\u610fLayer 3\u5206\u5e03\u4e2d\u8bc6\u522b\u53cd\u4e8b\u5b9e\u67e5\u8be2\uff0c\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u7684\u5b8c\u5907\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u975e\u53c2\u6570\u8bbe\u7f6e\u4e0b\u7cbe\u786e\u56e0\u679c\u63a8\u7406\u7684\u57fa\u672c\u6781\u9650\u3002", "motivation": "\u5148\u524d\u5173\u4e8e\u53cd\u4e8b\u5b9e\u8bc6\u522b\u5b8c\u5907\u6027\u7684\u7814\u7a76\u4ec5\u9650\u4e8e\u89c2\u6d4b\u6216\u5e72\u9884\u5206\u5e03\uff08Pearl\u56e0\u679c\u5c42\u6b21\u7684\u7b2c1-2\u5c42\uff09\uff0c\u56e0\u4e3a\u4e00\u822c\u8ba4\u4e3a\u65e0\u6cd5\u83b7\u5f97\u7b2c3\u5c42\u7684\u53cd\u4e8b\u5b9e\u5206\u5e03\u6570\u636e\u3002\u4f46\u6700\u8fd1\u7814\u7a76\u53d1\u73b0\u67d0\u4e9b\u53cd\u4e8b\u5b9e\u5206\u5e03\u53ef\u4ee5\u901a\u8fc7\u5b9e\u9a8c\u65b9\u6cd5\u76f4\u63a5\u4f30\u8ba1\uff08\u53cd\u4e8b\u5b9e\u53ef\u5b9e\u73b0\u6027\uff09\uff0c\u8fd9\u5f15\u53d1\u4e86\u65b0\u7684\u95ee\u9898\uff1a\u5728\u83b7\u5f97\u90e8\u5206Layer 3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u54ea\u4e9b\u989d\u5916\u7684\u53cd\u4e8b\u5b9e\u91cf\u53d8\u5f97\u53ef\u8bc6\u522b\uff1f", "method": "\u5f00\u53d1\u4e86CTFIDU+\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u4efb\u610fLayer 3\u5206\u5e03\u96c6\u5408\u4e2d\u8bc6\u522b\u53cd\u4e8b\u5b9e\u67e5\u8be2\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u5bf9\u6b64\u4efb\u52a1\u7684\u5b8c\u5907\u6027\u3002\u57fa\u4e8e\u6b64\uff0c\u5efa\u7acb\u4e86\u4ece\u7269\u7406\u53ef\u5b9e\u73b0\u5206\u5e03\u4e2d\u8bc6\u522b\u53cd\u4e8b\u5b9e\u7684\u7406\u8bba\u6781\u9650\u3002", "result": "1) CTFIDU+\u7b97\u6cd5\u662f\u5b8c\u5907\u7684\uff1b2) \u786e\u5b9a\u4e86\u975e\u53c2\u6570\u8bbe\u7f6e\u4e0b\u7cbe\u786e\u56e0\u679c\u63a8\u7406\u7684\u57fa\u672c\u6781\u9650\uff1b3) \u5bf9\u4e8e\u67d0\u4e9b\u65e0\u6cd5\u8bc6\u522b\u7684\u5173\u952e\u53cd\u4e8b\u5b9e\u7c7b\u578b\uff0c\u63a8\u5bfc\u4e86\u4f7f\u7528\u53ef\u5b9e\u73b0\u53cd\u4e8b\u5b9e\u6570\u636e\u7684\u65b0\u5206\u6790\u754c\u9650\uff1b4) \u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u53cd\u4e8b\u5b9e\u6570\u636e\u5728\u5b9e\u8df5\u4e2d\u6709\u52a9\u4e8e\u6536\u7d27\u4e0d\u53ef\u8bc6\u522b\u91cf\u7684\u754c\u9650\u3002", "conclusion": "\u672c\u6587\u89e3\u51b3\u4e86\u5728\u83b7\u5f97\u90e8\u5206Layer 3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u53cd\u4e8b\u5b9e\u8bc6\u522b\u7684\u5b8c\u5907\u6027\u95ee\u9898\uff0c\u5efa\u7acb\u4e86\u56e0\u679c\u63a8\u7406\u7684\u7406\u8bba\u6781\u9650\uff0c\u5e76\u4e3a\u65e0\u6cd5\u7cbe\u786e\u8bc6\u522b\u7684\u53cd\u4e8b\u5b9e\u91cf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u754c\u9650\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2602.23372", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23372", "abs": "https://arxiv.org/abs/2602.23372", "authors": ["Qizhi Wang"], "title": "Democratizing GraphRAG: Linear, CPU-Only Graph Retrieval for Multi-Hop QA", "comment": "13 pages, 14 figures, 26 tables", "summary": "GraphRAG systems improve multi-hop retrieval by modeling structure, but many approaches rely on expensive LLM-based graph construction and GPU-heavy inference. We present SPRIG (Seeded Propagation for Retrieval In Graphs), a CPU-only, linear-time, token-free GraphRAG pipeline that replaces LLM graph building with lightweight NER-driven co-occurrence graphs and uses Personalized PageRank (PPR) for 28% with negligible Recall@10 changes. The results characterize when CPU-friendly graph retrieval helps multi-hop recall and when strong lexical hybrids (RRF) are sufficient, outlining a realistic path to democratizing GraphRAG without token costs or GPU requirements.", "AI": {"tldr": "SPRIG\u662f\u4e00\u4e2aCPU-only\u3001\u7ebf\u6027\u65f6\u95f4\u3001\u65e0\u9700token\u7684GraphRAG\u7cfb\u7edf\uff0c\u4f7f\u7528NER\u9a71\u52a8\u7684\u5171\u73b0\u56fe\u548c\u4e2a\u6027\u5316PageRank\u66ff\u4ee3\u6602\u8d35\u7684LLM\u56fe\u6784\u5efa\uff0c\u5728\u4fdd\u6301Recall@10\u57fa\u672c\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u63d0\u534728%\u53ec\u56de\u7387\u3002", "motivation": "\u73b0\u6709GraphRAG\u7cfb\u7edf\u4f9d\u8d56\u6602\u8d35\u7684LLM\u56fe\u6784\u5efa\u548cGPU\u5bc6\u96c6\u578b\u63a8\u7406\uff0c\u9650\u5236\u4e86\u5176\u666e\u53ca\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u6210\u672c\u66f4\u4f4e\u7684GraphRAG\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faSPRIG\u7cfb\u7edf\uff1a1) \u4f7f\u7528\u8f7b\u91cf\u7ea7NER\u9a71\u52a8\u7684\u5171\u73b0\u56fe\u66ff\u4ee3LLM\u56fe\u6784\u5efa\uff1b2) \u91c7\u7528\u4e2a\u6027\u5316PageRank\u8fdb\u884c\u68c0\u7d22\uff1b3) \u5b9e\u73b0CPU-only\u3001\u7ebf\u6027\u65f6\u95f4\u3001token-free\u7684\u7ba1\u9053\u3002", "result": "SPRIG\u5728\u4fdd\u6301Recall@10\u57fa\u672c\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u53ec\u56de\u7387\u63d0\u534728%\u3002\u7cfb\u7edf\u5206\u6790\u4e86CPU\u53cb\u597d\u56fe\u68c0\u7d22\u4f55\u65f6\u6709\u52a9\u4e8e\u591a\u8df3\u53ec\u56de\uff0c\u4ee5\u53ca\u4f55\u65f6\u5f3a\u8bcd\u6c47\u6df7\u5408\u65b9\u6cd5(RRF)\u5df2\u8db3\u591f\u3002", "conclusion": "SPRIG\u4e3aGraphRAG\u7684\u6c11\u4e3b\u5316\u63d0\u4f9b\u4e86\u73b0\u5b9e\u8def\u5f84\uff0c\u65e0\u9700token\u6210\u672c\u6216GPU\u8981\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2602.23545", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23545", "abs": "https://arxiv.org/abs/2602.23545", "authors": ["Matteo Ceriscioli", "Karthika Mohan"], "title": "Planning under Distribution Shifts with Causal POMDPs", "comment": "To appear at the 36th International Conference on Automated Planning and Scheduling (ICAPS-26)", "summary": "In the real world, planning is often challenged by distribution shifts. As such, a model of the environment obtained under one set of conditions may no longer remain valid as the distribution of states or the environment dynamics change, which in turn causes previously learned strategies to fail. In this work, we propose a theoretical framework for planning under partial observability using Partially Observable Markov Decision Processes (POMDPs) formulated using causal knowledge. By representing shifts in the environment as interventions on this causal POMDP, the framework enables evaluating plans under hypothesized changes and actively identifying which components of the environment have been altered. We show how to maintain and update a belief over both the latent state and the underlying domain, and we prove that the value function remains piecewise linear and convex (PWLC) in this augmented belief space. Preservation of PWLC under distribution shifts has the advantage of maintaining the tractability of planning via $\u03b1$-vector-based POMDP methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u77e5\u8bc6\u7684POMDP\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u89c4\u5212\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u73af\u5883\u53d8\u5316\u8868\u793a\u4e3a\u5bf9\u56e0\u679cPOMDP\u7684\u5e72\u9884\u6765\u8bc4\u4f30\u8ba1\u5212\u5e76\u8bc6\u522b\u73af\u5883\u53d8\u5316", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u89c4\u5212\u7ecf\u5e38\u9762\u4e34\u5206\u5e03\u504f\u79fb\u7684\u6311\u6218\uff0c\u5728\u4e00\u4e2a\u6761\u4ef6\u4e0b\u83b7\u5f97\u7684\u73af\u5883\u6a21\u578b\u5728\u72b6\u6001\u5206\u5e03\u6216\u73af\u5883\u52a8\u6001\u53d8\u5316\u65f6\u53ef\u80fd\u5931\u6548\uff0c\u5bfc\u81f4\u5148\u524d\u5b66\u4e60\u7684\u7b56\u7565\u5931\u8d25", "method": "\u4f7f\u7528\u57fa\u4e8e\u56e0\u679c\u77e5\u8bc6\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u73af\u5883\u53d8\u5316\u8868\u793a\u4e3a\u5bf9\u56e0\u679cPOMDP\u7684\u5e72\u9884\uff0c\u7ef4\u62a4\u548c\u66f4\u65b0\u5bf9\u6f5c\u5728\u72b6\u6001\u548c\u5e95\u5c42\u9886\u57df\u7684\u4fe1\u5ff5", "result": "\u8bc1\u660e\u4e86\u4ef7\u503c\u51fd\u6570\u5728\u589e\u5f3a\u4fe1\u5ff5\u7a7a\u95f4\u4e2d\u4fdd\u6301\u5206\u6bb5\u7ebf\u6027\u51f8\uff08PWLC\uff09\u6027\u8d28\uff0c\u8fd9\u4fdd\u6301\u4e86\u57fa\u4e8e\u03b1\u5411\u91cf\u7684POMDP\u65b9\u6cd5\u7684\u53ef\u5904\u7406\u6027", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u8fdb\u884c\u89c4\u5212\uff0c\u901a\u8fc7\u56e0\u679c\u8868\u793a\u8bc4\u4f30\u5047\u8bbe\u53d8\u5316\u4e0b\u7684\u8ba1\u5212\u5e76\u4e3b\u52a8\u8bc6\u522b\u73af\u5883\u53d8\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u89c4\u5212\u7684\u53ef\u5904\u7406\u6027"}}
{"id": "2602.23374", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23374", "abs": "https://arxiv.org/abs/2602.23374", "authors": ["Weixi Lin"], "title": "Higress-RAG: A Holistic Optimization Framework for Enterprise Retrieval-Augmented Generation via Dual Hybrid Retrieval, Adaptive Routing, and CRAG", "comment": "7 pages,5 figures, our submissions are not yet published", "summary": "The integration of Large Language Models (LLMs) into enterprise knowledge management systems has been catalyzed by the Retrieval-Augmented Generation (RAG) paradigm, which augments parametric memory with non-parametric external data. However, the transition from proof-of-concept to production-grade RAG systems is hindered by three persistent challenges: low retrieval precision for complex queries, high rates of hallucination in the generation phase, and unacceptable latency for real-time applications. This paper presents a comprehensive analysis of the Higress RAG MCP Server, a novel, enterprise-centric architecture designed to resolve these bottlenecks through a \"Full-Link Optimization\" strategy. Built upon the Model Context Protocol (MCP), the system introduces a layered architecture that orchestrates a sophisticated pipeline of Adaptive Routing, Semantic Caching, Hybrid Retrieval, and Corrective RAG (CRAG). We detail the technical implementation of key innovations, including the Higress-Native Splitter for structure-aware data ingestion, the application of Reciprocal Rank Fusion (RRF) for merging dense and sparse retrieval signals, and a 50ms-latency Semantic Caching mechanism with dynamic thresholding. Experimental evaluations on domain-specific Higress technical documentation and blogs verify the system's architectural robustness. The results demonstrate that by optimizing the entire retrieval lifecycle - from pre-retrieval query rewriting to post-retrieval corrective evaluation - the Higress RAG system offers a scalable, hallucination-resistant solution for enterprise AI deployment.", "AI": {"tldr": "Higress RAG MCP Server\u91c7\u7528\"\u5168\u94fe\u8def\u4f18\u5316\"\u7b56\u7565\u89e3\u51b3\u4f01\u4e1a\u7ea7RAG\u7cfb\u7edf\u4e09\u5927\u6311\u6218\uff1a\u590d\u6742\u67e5\u8be2\u68c0\u7d22\u7cbe\u5ea6\u4f4e\u3001\u751f\u6210\u9636\u6bb5\u5e7b\u89c9\u7387\u9ad8\u3001\u5b9e\u65f6\u5e94\u7528\u5ef6\u8fdf\u4e0d\u53ef\u63a5\u53d7\u3002", "motivation": "\u4f01\u4e1a\u77e5\u8bc6\u7ba1\u7406\u7cfb\u7edf\u96c6\u6210LLM\u65f6\u9762\u4e34RAG\u8303\u5f0f\u4ece\u6982\u5ff5\u9a8c\u8bc1\u5230\u751f\u4ea7\u7ea7\u90e8\u7f72\u7684\u4e09\u5927\u74f6\u9888\uff1a\u590d\u6742\u67e5\u8be2\u68c0\u7d22\u7cbe\u5ea6\u4e0d\u8db3\u3001\u751f\u6210\u9636\u6bb5\u5e7b\u89c9\u7387\u9ad8\u3001\u5b9e\u65f6\u5e94\u7528\u5ef6\u8fdf\u4e0d\u53ef\u63a5\u53d7\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8eModel Context Protocol\u6784\u5efa\u5206\u5c42\u67b6\u6784\uff0c\u91c7\u7528\"\u5168\u94fe\u8def\u4f18\u5316\"\u7b56\u7565\uff0c\u5305\u62ec\u81ea\u9002\u5e94\u8def\u7531\u3001\u8bed\u4e49\u7f13\u5b58\u3001\u6df7\u5408\u68c0\u7d22\u548c\u7ea0\u6b63\u5f0fRAG\u3002\u5173\u952e\u6280\u672f\u5305\u62ecHigress-Native Splitter\u7ed3\u6784\u5316\u6570\u636e\u6444\u53d6\u3001\u4e92\u60e0\u6392\u540d\u878d\u5408\u6574\u5408\u7a20\u5bc6\u7a00\u758f\u68c0\u7d22\u4fe1\u53f7\u300150ms\u5ef6\u8fdf\u8bed\u4e49\u7f13\u5b58\u52a8\u6001\u9608\u503c\u673a\u5236\u3002", "result": "\u5728Higress\u6280\u672f\u6587\u6863\u548c\u535a\u5ba2\u7684\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u67b6\u6784\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u4f18\u5316\u4ece\u68c0\u7d22\u524d\u67e5\u8be2\u91cd\u5199\u5230\u68c0\u7d22\u540e\u7ea0\u6b63\u8bc4\u4f30\u7684\u6574\u4e2a\u68c0\u7d22\u751f\u547d\u5468\u671f\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u6297\u5e7b\u89c9\u7684\u4f01\u4e1aAI\u90e8\u7f72\u65b9\u6848\u3002", "conclusion": "Higress RAG MCP Server\u901a\u8fc7\u5168\u94fe\u8def\u4f18\u5316\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u4f01\u4e1a\u7ea7RAG\u7cfb\u7edf\u7684\u6838\u5fc3\u6311\u6218\uff0c\u4e3a\u751f\u4ea7\u7ea7RAG\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u4f4e\u5ef6\u8fdf\u3001\u6297\u5e7b\u89c9\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23413", "categories": ["cs.LG", "cs.CL", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.23413", "abs": "https://arxiv.org/abs/2602.23413", "authors": ["Shu Liu", "Shubham Agarwal", "Monishwaran Maheswaran", "Mert Cemri", "Zhifei Li", "Qiuyang Mang", "Ashwin Naren", "Ethan Boneh", "Audrey Cheng", "Melissa Z. Pan", "Alexander Du", "Kurt Keutzer", "Alexandros G. Dimakis", "Koushik Sen", "Matei Zaharia", "Ion Stoica"], "title": "EvoX: Meta-Evolution for Automated Discovery", "comment": null, "summary": "Recent work such as AlphaEvolve has shown that combining LLM-driven optimization with evolutionary search can effectively improve programs, prompts, and algorithms across domains. In this paradigm, previously evaluated solutions are reused to guide the model toward new candidate solutions. Crucially, the effectiveness of this evolution process depends on the search strategy: how prior solutions are selected and varied to generate new candidates. However, most existing methods rely on fixed search strategies with predefined knobs (e.g., explore-exploit ratios) that remain static throughout execution. While effective in some settings, these approaches often fail to adapt across tasks, or even within the same task as the search space changes over time. We introduce EvoX, an adaptive evolution method that optimizes its own evolution process. EvoX jointly evolves candidate solutions and the search strategies used to generate them, continuously updating how prior solutions are selected and varied based on progress. This enables the system to dynamically shift between different search strategies during the optimization process. Across nearly 200 real-world optimization tasks, EvoX outperforms existing AI-driven evolutionary methods including AlphaEvolve, OpenEvolve, GEPA, and ShinkaEvolve on the majority of tasks.", "AI": {"tldr": "EvoX\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u8fdb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u8fdb\u5316\u5019\u9009\u89e3\u548c\u641c\u7d22\u7b56\u7565\uff0c\u52a8\u6001\u8c03\u6574\u8fdb\u5316\u8fc7\u7a0b\uff0c\u5728\u8fd1200\u4e2a\u771f\u5b9e\u4e16\u754c\u4f18\u5316\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709AI\u9a71\u52a8\u7684\u8fdb\u5316\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982AlphaEvolve\u867d\u7136\u7ed3\u5408\u4e86LLM\u9a71\u52a8\u7684\u4f18\u5316\u548c\u8fdb\u5316\u641c\u7d22\uff0c\u4f46\u5927\u591a\u4f9d\u8d56\u56fa\u5b9a\u7684\u641c\u7d22\u7b56\u7565\u548c\u9884\u5b9a\u4e49\u53c2\u6570\uff0c\u8fd9\u4e9b\u7b56\u7565\u5728\u6574\u4e2a\u6267\u884c\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e0d\u53d8\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u6216\u540c\u4e00\u4efb\u52a1\u4e2d\u641c\u7d22\u7a7a\u95f4\u968f\u65f6\u95f4\u53d8\u5316\u7684\u60c5\u51b5\u3002", "method": "EvoX\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u8fdb\u5316\u65b9\u6cd5\uff0c\u5b83\u8054\u5408\u8fdb\u5316\u5019\u9009\u89e3\u548c\u7528\u4e8e\u751f\u6210\u8fd9\u4e9b\u89e3\u7684\u641c\u7d22\u7b56\u7565\u3002\u7cfb\u7edf\u6301\u7eed\u66f4\u65b0\u5982\u4f55\u9009\u62e9\u548c\u53d8\u5316\u5148\u524d\u89e3\u7684\u65b9\u5f0f\uff0c\u57fa\u4e8e\u4f18\u5316\u8fdb\u5c55\u52a8\u6001\u8c03\u6574\uff0c\u4f7f\u7cfb\u7edf\u80fd\u591f\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5728\u4e0d\u540c\u641c\u7d22\u7b56\u7565\u4e4b\u95f4\u52a8\u6001\u5207\u6362\u3002", "result": "\u5728\u8fd1200\u4e2a\u771f\u5b9e\u4e16\u754c\u4f18\u5316\u4efb\u52a1\u4e2d\uff0cEvoX\u5728\u5927\u591a\u6570\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684AI\u9a71\u52a8\u8fdb\u5316\u65b9\u6cd5\uff0c\u5305\u62ecAlphaEvolve\u3001OpenEvolve\u3001GEPA\u548cShinkaEvolve\u3002", "conclusion": "EvoX\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u4f18\u5316\u81ea\u8eab\u7684\u8fdb\u5316\u8fc7\u7a0b\uff0c\u80fd\u591f\u52a8\u6001\u8c03\u6574\u641c\u7d22\u7b56\u7565\uff0c\u4ece\u800c\u5728\u5e7f\u6cdb\u7684\u4f18\u5316\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u56fa\u5b9a\u7b56\u7565\u65b9\u6cd5\u65e0\u6cd5\u9002\u5e94\u4efb\u52a1\u53d8\u5316\u7684\u95ee\u9898\u3002"}}
{"id": "2602.23579", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23579", "abs": "https://arxiv.org/abs/2602.23579", "authors": ["Guillem Rodr\u00edguez-Corominas", "Maria J. Blesa", "Christian Blum"], "title": "Construct, Merge, Solve & Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem", "comment": null, "summary": "The Multiple Traveling Salesman Problem (mTSP) extends the Traveling Salesman Problem to m tours that start and end at a common depot and jointly visit all customers exactly once. In the min-max variant, the objective is to minimize the longest tour, reflecting workload balance. We propose a hybrid approach, Construct, Merge, Solve & Adapt with Reinforcement Learning (RL-CMSA), for the symmetric single-depot min-max mTSP. The method iteratively constructs diverse solutions using probabilistic clustering guided by learned pairwise q-values, merges routes into a compact pool, solves a restricted set-covering MILP, and refines solutions via inter-route remove, shift, and swap moves. The q-values are updated by reinforcing city-pair co-occurrences in high-quality solutions, while the pool is adapted through ageing and pruning. This combination of exact optimization and reinforcement-guided construction balances exploration and exploitation. Computational results on random and TSPLIB instances show that RL-CMSA consistently finds (near-)best solutions and outperforms a state-of-the-art hybrid genetic algorithm under comparable time limits, especially as instance size and the number of salesmen increase.", "AI": {"tldr": "\u63d0\u51faRL-CMSA\u6df7\u5408\u65b9\u6cd5\u89e3\u51b3\u5bf9\u79f0\u5355\u4ed3\u5e93min-max mTSP\u95ee\u9898\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u7684\u6784\u9020\u3001\u7cbe\u786e\u4f18\u5316\u548c\u81ea\u9002\u5e94\u6c60\u7ba1\u7406\uff0c\u5728\u968f\u673a\u548cTSPLIB\u5b9e\u4f8b\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6df7\u5408\u9057\u4f20\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u591a\u65c5\u884c\u5546\u95ee\u9898\u4e2d\u7684min-max\u53d8\u4f53\uff0c\u76ee\u6807\u662f\u5e73\u8861\u591a\u4e2a\u9500\u552e\u5458\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u9700\u8981\u6709\u6548\u65b9\u6cd5\u5904\u7406\u5927\u89c4\u6a21\u5b9e\u4f8b\u548c\u9500\u552e\u5458\u6570\u91cf\u589e\u52a0\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51faRL-CMSA\u6df7\u5408\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u57fa\u4e8e\u5b66\u4e60q\u503c\u7684\u6982\u7387\u805a\u7c7b\u6784\u9020\u591a\u6837\u5316\u89e3\uff1b2) \u5408\u5e76\u8def\u7ebf\u5230\u7d27\u51d1\u6c60\uff1b3) \u6c42\u89e3\u53d7\u9650\u96c6\u5408\u8986\u76d6MILP\uff1b4) \u901a\u8fc7\u79fb\u9664\u3001\u79fb\u4f4d\u548c\u4ea4\u6362\u64cd\u4f5c\u7cbe\u5316\u89e3\uff1b5) \u6839\u636e\u9ad8\u8d28\u91cf\u89e3\u66f4\u65b0q\u503c\uff1b6) \u901a\u8fc7\u8001\u5316\u548c\u526a\u679d\u81ea\u9002\u5e94\u7ba1\u7406\u6c60\u3002", "result": "\u5728\u968f\u673a\u548cTSPLIB\u5b9e\u4f8b\u4e0a\uff0cRL-CMSA\u80fd\u4e00\u81f4\u627e\u5230(\u63a5\u8fd1)\u6700\u4f18\u89e3\uff0c\u5728\u53ef\u6bd4\u65f6\u95f4\u9650\u5236\u4e0b\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6df7\u5408\u9057\u4f20\u7b97\u6cd5\uff0c\u5c24\u5176\u5f53\u5b9e\u4f8b\u89c4\u6a21\u548c\u9500\u552e\u5458\u6570\u91cf\u589e\u52a0\u65f6\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "RL-CMSA\u7ed3\u5408\u7cbe\u786e\u4f18\u5316\u548c\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u7684\u6784\u9020\uff0c\u5e73\u8861\u4e86\u63a2\u7d22\u548c\u5229\u7528\uff0c\u4e3a\u5bf9\u79f0\u5355\u4ed3\u5e93min-max mTSP\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23957", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23957", "abs": "https://arxiv.org/abs/2602.23957", "authors": ["Alexander Berndt", "Zolt\u00e1n Nochta", "Thomas Bach"], "title": "The Vocabulary of Flaky Tests in the Context of SAP HANA", "comment": "Accepted to ESEM IGC 2023", "summary": "Background. Automated test execution is an important activity to gather information about the quality of a software project. So-called flaky tests, however, negatively affect this process. Such tests fail seemingly at random without changes to the code and thus do not provide a clear signal. Previous work proposed to identify flaky tests based on the source code identifiers in the test code. So far, these approaches have not been evaluated in a large-scale industrial setting. Aims. We evaluate approaches to identify flaky tests and their root causes based on source code identifiers in the test code in a large-scale industrial project. Method. First, we replicate previous work by Pinto et al. in the context of SAP HANA. Second, we assess different feature extraction techniques, namely TF-IDF and TF-IDFC-RF. Third, we evaluate CodeBERT and XGBoost as classification models. For a sound comparison, we utilize both the data set from previous work and two data sets from SAP HANA. Results. Our replication shows similar results on the original data set and on one of the SAP HANA data sets. While the original approach yielded an F1-Score of 0.94 on the original data set and 0.92 on the SAP HANA data set, our extensions achieve F1-Scores of 0.96 and 0.99, respectively. The reliance on external data sources is a common root cause for test flakiness in the context of SAP HANA. Conclusions. The vocabulary of a large industrial project seems to be slightly different with respect to the exact terms, but the categories for the terms, such as remote dependencies, are similar to previous empirical findings. However, even with rather large F1-Scores, both finding source code identifiers for flakiness and a black box prediction have limited use in practice as the results are not actionable for developers.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728SAP HANA\u5927\u578b\u5de5\u4e1a\u9879\u76ee\u4e2d\u8bc4\u4f30\u4e86\u57fa\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u4e2d\u6e90\u4ee3\u7801\u6807\u8bc6\u7b26\u8bc6\u522b\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u590d\u73b0\u4e86\u5148\u524d\u7814\u7a76\u5e76\u6269\u5c55\u4e86\u7279\u5f81\u63d0\u53d6\u548c\u5206\u7c7b\u6280\u672f\uff0c\u53d6\u5f97\u4e86\u66f4\u9ad8\u7684F1\u5206\u6570\uff0c\u4f46\u53d1\u73b0\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u6709\u9650\u3002", "motivation": "\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\uff08flaky tests\uff09\u4f1a\u968f\u673a\u5931\u8d25\u800c\u4e0d\u63d0\u4f9b\u660e\u786e\u7684\u8d28\u91cf\u4fe1\u53f7\uff0c\u5f71\u54cd\u81ea\u52a8\u5316\u6d4b\u8bd5\u6267\u884c\u3002\u5148\u524d\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u4e2d\u7684\u6e90\u4ee3\u7801\u6807\u8bc6\u7b26\u6765\u8bc6\u522b\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5c1a\u672a\u5728\u5927\u578b\u5de5\u4e1a\u73af\u5883\u4e2d\u5f97\u5230\u5145\u5206\u8bc4\u4f30\u3002\u672c\u7814\u7a76\u65e8\u5728\u5728SAP HANA\u5927\u578b\u5de5\u4e1a\u9879\u76ee\u4e2d\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u53ca\u5176\u8bc6\u522b\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u6839\u672c\u539f\u56e0\u7684\u80fd\u529b\u3002", "method": "\u9996\u5148\u590d\u73b0Pinto\u7b49\u4eba\u7684\u5148\u524d\u5de5\u4f5c\u5728SAP HANA\u73af\u5883\u4e2d\u7684\u5e94\u7528\uff1b\u5176\u6b21\u8bc4\u4f30\u4e0d\u540c\u7684\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff0c\u5305\u62ecTF-IDF\u548cTF-IDFC-RF\uff1b\u7b2c\u4e09\u8bc4\u4f30CodeBERT\u548cXGBoost\u4f5c\u4e3a\u5206\u7c7b\u6a21\u578b\u3002\u4e3a\u4e86\u8fdb\u884c\u53ef\u9760\u7684\u6bd4\u8f83\uff0c\u540c\u65f6\u4f7f\u7528\u4e86\u5148\u524d\u7814\u7a76\u7684\u6570\u636e\u96c6\u548c\u4e24\u4e2aSAP HANA\u6570\u636e\u96c6\u3002", "result": "\u590d\u73b0\u7814\u7a76\u5728\u539f\u59cb\u6570\u636e\u96c6\u548c\u4e00\u4e2aSAP HANA\u6570\u636e\u96c6\u4e0a\u663e\u793a\u4e86\u76f8\u4f3c\u7684\u7ed3\u679c\u3002\u539f\u59cb\u65b9\u6cd5\u5728\u539f\u59cb\u6570\u636e\u96c6\u4e0a\u83b7\u5f970.94\u7684F1\u5206\u6570\uff0c\u5728SAP HANA\u6570\u636e\u96c6\u4e0a\u83b7\u5f970.92\u7684F1\u5206\u6570\uff1b\u800c\u6269\u5c55\u65b9\u6cd5\u5206\u522b\u8fbe\u5230\u4e860.96\u548c0.99\u7684F1\u5206\u6570\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728SAP HANA\u73af\u5883\u4e2d\uff0c\u5bf9\u5916\u90e8\u6570\u636e\u6e90\u7684\u4f9d\u8d56\u662f\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u7684\u5e38\u89c1\u6839\u672c\u539f\u56e0\u3002", "conclusion": "\u5927\u578b\u5de5\u4e1a\u9879\u76ee\u7684\u8bcd\u6c47\u5728\u5177\u4f53\u672f\u8bed\u4e0a\u7565\u6709\u4e0d\u540c\uff0c\u4f46\u672f\u8bed\u7c7b\u522b\uff08\u5982\u8fdc\u7a0b\u4f9d\u8d56\uff09\u4e0e\u5148\u524d\u5b9e\u8bc1\u7814\u7a76\u7ed3\u679c\u76f8\u4f3c\u3002\u7136\u800c\uff0c\u5373\u4f7f\u83b7\u5f97\u4e86\u8f83\u9ad8\u7684F1\u5206\u6570\uff0c\u57fa\u4e8e\u6e90\u4ee3\u7801\u6807\u8bc6\u7b26\u8bc6\u522b\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u548c\u9ed1\u76d2\u9884\u6d4b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4ef7\u503c\u6709\u9650\uff0c\u56e0\u4e3a\u7ed3\u679c\u5bf9\u5f00\u53d1\u4eba\u5458\u6765\u8bf4\u4e0d\u591f\u53ef\u64cd\u4f5c\u3002"}}
{"id": "2602.23471", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23471", "abs": "https://arxiv.org/abs/2602.23471", "authors": ["Artur Gimranov", "Viacheslav Yusupov", "Elfat Sabitov", "Tatyana Matveeva", "Anton Lysenko", "Ruslan Israfilov", "Evgeny Frolov"], "title": "Cross-Representation Knowledge Transfer for Improved Sequential Recommendations", "comment": null, "summary": "Transformer architectures, capable of capturing sequential dependencies in the history of user interactions, have become the dominant approach in sequential recommender systems. Despite their success, such models consider sequence elements in isolation, implicitly accounting for the complex relationships between them. Graph neural networks, in contrast, explicitly model these relationships through higher order interactions but are often unable to adequately capture their evolution over time, limiting their use for predicting the next interaction. To fill this gap, we present a new framework that combines transformers and graph neural networks and aligns different representations for solving next-item prediction task. Our solution simultaneously encodes structural dependencies in the interaction graph and tracks their dynamic change. Experimental results on a number of open datasets demonstrate that the proposed framework consistently outperforms both pure sequential and graph approaches in terms of recommendation quality, as well as recent methods that combine both types of signals.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408Transformer\u548cGNN\u7684\u65b0\u6846\u67b6\uff0c\u540c\u65f6\u7f16\u7801\u4ea4\u4e92\u56fe\u7684\u7ed3\u6784\u4f9d\u8d56\u5e76\u8ddf\u8e2a\u5176\u52a8\u6001\u53d8\u5316\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u7eaf\u5e8f\u5217\u3001\u7eaf\u56fe\u53ca\u73b0\u6709\u6df7\u5408\u65b9\u6cd5\u3002", "motivation": "Transformer\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u867d\u80fd\u6355\u6349\u5e8f\u5217\u4f9d\u8d56\uff0c\u4f46\u5b64\u7acb\u8003\u8651\u5e8f\u5217\u5143\u7d20\uff0c\u9690\u5f0f\u5904\u7406\u590d\u6742\u5173\u7cfb\uff1bGNN\u867d\u80fd\u663e\u5f0f\u5efa\u6a21\u9ad8\u9636\u4ea4\u4e92\u5173\u7cfb\uff0c\u4f46\u96be\u4ee5\u5145\u5206\u6355\u6349\u968f\u65f6\u95f4\u6f14\u5316\u7684\u52a8\u6001\u53d8\u5316\u3002\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u89e3\u51b3\u4e0b\u4e00\u9879\u9884\u6d4b\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u65b0\u6846\u67b6\u7ed3\u5408Transformer\u548cGNN\uff0c\u5bf9\u9f50\u4e0d\u540c\u8868\u793a\u3002\u540c\u65f6\u7f16\u7801\u4ea4\u4e92\u56fe\u4e2d\u7684\u7ed3\u6784\u4f9d\u8d56\u5e76\u8ddf\u8e2a\u5176\u52a8\u6001\u53d8\u5316\uff0c\u89e3\u51b3\u4e0b\u4e00\u9879\u9884\u6d4b\u4efb\u52a1\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u653e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u5728\u63a8\u8350\u8d28\u91cf\u4e0a\u4e00\u81f4\u4f18\u4e8e\u7eaf\u5e8f\u5217\u65b9\u6cd5\u3001\u7eaf\u56fe\u65b9\u6cd5\u4ee5\u53ca\u6700\u8fd1\u7ed3\u5408\u4e24\u79cd\u4fe1\u53f7\u7684\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408Transformer\u548cGNN\u7684\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u7ed3\u6784\u4f9d\u8d56\u5efa\u6a21\u548c\u52a8\u6001\u53d8\u5316\u8ddf\u8e2a\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2602.23446", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23446", "abs": "https://arxiv.org/abs/2602.23446", "authors": ["Alejandro Rodriguez Dominguez"], "title": "Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning", "comment": "Proceedings from IEEE CAI 2026, Conference on Artificial Intelligence, 8-10 May, Granada, Spain. 8 Pages, 3 Figures, 7 Tables", "summary": "Large language models are trained primarily on human-generated data and feedback, yet they exhibit persistent errors arising from annotation noise, subjective preferences, and the limited expressive bandwidth of natural language. We argue that these limitations reflect structural properties of the supervision channel rather than model scale or optimization. We develop a unified theory showing that whenever the human supervision channel is not sufficient for a latent evaluation target, it acts as an information-reducing channel that induces a strictly positive excess-risk floor for any learner dominated by it. We formalize this Human-Bounded Intelligence limit and show that across six complementary frameworks (operator theory, PAC-Bayes, information theory, causal inference, category theory, and game-theoretic analyses of reinforcement learning from human feedback), non-sufficiency yields strictly positive lower bounds arising from the same structural decomposition into annotation noise, preference distortion, and semantic compression. The theory explains why scaling alone cannot eliminate persistent human-aligned errors and characterizes conditions under which auxiliary non-human signals (e.g., retrieval, program execution, tools) increase effective supervision capacity and collapse the floor by restoring information about the latent target. Experiments on real preference data, synthetic known-target tasks, and externally verifiable benchmarks confirm the predicted structural signatures: human-only supervision exhibits a persistent floor, while sufficiently informative auxiliary channels strictly reduce or eliminate excess error.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u4eba\u7c7b\u6709\u754c\u667a\u80fd\u6781\u9650\"\u7406\u8bba\uff0c\u8ba4\u4e3a\u4ec5\u4f9d\u8d56\u4eba\u7c7b\u76d1\u7763\u7684LLM\u5b58\u5728\u56fa\u6709\u9519\u8bef\u4e0b\u9650\uff0c\u8fd9\u662f\u76d1\u7763\u6e20\u9053\u7ed3\u6784\u9650\u5236\u800c\u975e\u6a21\u578b\u89c4\u6a21\u95ee\u9898\uff0c\u53ef\u901a\u8fc7\u975e\u4eba\u7c7b\u8f85\u52a9\u4fe1\u53f7\u7a81\u7834", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u4eba\u7c7b\u751f\u6210\u7684\u6570\u636e\u548c\u53cd\u9988\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u5b58\u5728\u6301\u7eed\u9519\u8bef\uff0c\u8fd9\u4e9b\u9519\u8bef\u6e90\u4e8e\u6807\u6ce8\u566a\u58f0\u3001\u4e3b\u89c2\u504f\u597d\u548c\u81ea\u7136\u8bed\u8a00\u7684\u6709\u9650\u8868\u8fbe\u80fd\u529b\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e9b\u9650\u5236\u53cd\u6620\u4e86\u76d1\u7763\u6e20\u9053\u7684\u7ed3\u6784\u7279\u6027\uff0c\u800c\u975e\u6a21\u578b\u89c4\u6a21\u6216\u4f18\u5316\u95ee\u9898", "method": "\u5f00\u53d1\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u5f53\u4eba\u7c7b\u76d1\u7763\u6e20\u9053\u5bf9\u6f5c\u5728\u8bc4\u4f30\u76ee\u6807\u4e0d\u8db3\u65f6\uff0c\u4f1a\u4f5c\u4e3a\u4fe1\u606f\u51cf\u5c11\u6e20\u9053\uff0c\u4e3a\u4efb\u4f55\u53d7\u5176\u4e3b\u5bfc\u7684\u5b66\u4e60\u8005\u5f15\u5165\u4e25\u683c\u6b63\u503c\u7684\u8d85\u989d\u98ce\u9669\u4e0b\u9650\u3002\u901a\u8fc7\u516d\u4e2a\u4e92\u8865\u6846\u67b6\uff08\u7b97\u5b50\u7406\u8bba\u3001PAC-Bayes\u3001\u4fe1\u606f\u8bba\u3001\u56e0\u679c\u63a8\u65ad\u3001\u8303\u7574\u8bba\u3001RLHF\u535a\u5f08\u8bba\u5206\u6790\uff09\u5f62\u5f0f\u5316\u8fd9\u4e00\"\u4eba\u7c7b\u6709\u754c\u667a\u80fd\u6781\u9650\"", "result": "\u7406\u8bba\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u5355\u7eaf\u6269\u5c55\u65e0\u6cd5\u6d88\u9664\u6301\u7eed\u7684\u4eba\u7c7b\u5bf9\u9f50\u9519\u8bef\uff0c\u5e76\u63cf\u8ff0\u4e86\u8f85\u52a9\u975e\u4eba\u7c7b\u4fe1\u53f7\uff08\u5982\u68c0\u7d22\u3001\u7a0b\u5e8f\u6267\u884c\u3001\u5de5\u5177\uff09\u589e\u52a0\u6709\u6548\u76d1\u7763\u80fd\u529b\u5e76\u6d88\u9664\u4e0b\u9650\u7684\u6761\u4ef6\u3002\u5728\u771f\u5b9e\u504f\u597d\u6570\u636e\u3001\u5408\u6210\u5df2\u77e5\u76ee\u6807\u4efb\u52a1\u548c\u5916\u90e8\u53ef\u9a8c\u8bc1\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u9884\u6d4b\u7684\u7ed3\u6784\u7279\u5f81", "conclusion": "\u4ec5\u4f9d\u8d56\u4eba\u7c7b\u76d1\u7763\u5b58\u5728\u6301\u7eed\u9519\u8bef\u4e0b\u9650\uff0c\u800c\u8db3\u591f\u4fe1\u606f\u4e30\u5bcc\u7684\u8f85\u52a9\u6e20\u9053\u53ef\u4ee5\u4e25\u683c\u51cf\u5c11\u6216\u6d88\u9664\u8d85\u989d\u9519\u8bef\u3002\u8fd9\u4e3a\u7406\u89e3LLM\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u6307\u51fa\u4e86\u901a\u8fc7\u975e\u4eba\u7c7b\u4fe1\u53f7\u589e\u5f3a\u76d1\u7763\u7684\u8def\u5f84"}}
{"id": "2602.23605", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23605", "abs": "https://arxiv.org/abs/2602.23605", "authors": ["Zongzhe Xu", "Zitao Shuai", "Eideen Mozaffari", "Ravi S. Aysola", "Rajesh Kumar", "Yuzhe Yang"], "title": "SleepLM: Natural-Language Intelligence for Human Sleep", "comment": null, "summary": "We present SleepLM, a family of sleep-language foundation models that enable human sleep alignment, interpretation, and interaction with natural language. Despite the critical role of sleep, learning-based sleep analysis systems operate in closed label spaces (e.g., predefined stages or events) and fail to describe, query, or generalize to novel sleep phenomena. SleepLM bridges natural language and multimodal polysomnography, enabling language-grounded representations of sleep physiology. To support this alignment, we introduce a multilevel sleep caption generation pipeline that enables the curation of the first large-scale sleep-text dataset, comprising over 100K hours of data from more than 10,000 individuals. Furthermore, we present a unified pretraining objective that combines contrastive alignment, caption generation, and signal reconstruction to better capture physiological fidelity and cross-modal interactions. Extensive experiments on real-world sleep understanding tasks verify that SleepLM outperforms state-of-the-art in zero-shot and few-shot learning, cross-modal retrieval, and sleep captioning. Importantly, SleepLM also exhibits intriguing capabilities including language-guided event localization, targeted insight generation, and zero-shot generalization to unseen tasks. All code and data will be open-sourced.", "AI": {"tldr": "SleepLM\u662f\u4e00\u4e2a\u5c06\u81ea\u7136\u8bed\u8a00\u4e0e\u591a\u6a21\u6001\u7761\u7720\u751f\u7406\u4fe1\u53f7\u5bf9\u9f50\u7684\u7761\u7720\u8bed\u8a00\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u7761\u7720-\u6587\u672c\u6570\u636e\u96c6\u548c\u7edf\u4e00\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u5b66\u4e60\u3001\u8de8\u6a21\u6001\u68c0\u7d22\u7b49\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5b66\u4e60\u7684\u7761\u7720\u5206\u6790\u7cfb\u7edf\u5c40\u9650\u4e8e\u9884\u5b9a\u4e49\u7684\u6807\u7b7e\u7a7a\u95f4\uff08\u5982\u7761\u7720\u9636\u6bb5\u6216\u4e8b\u4ef6\uff09\uff0c\u65e0\u6cd5\u63cf\u8ff0\u3001\u67e5\u8be2\u6216\u6cdb\u5316\u5230\u65b0\u7684\u7761\u7720\u73b0\u8c61\uff0c\u9700\u8981\u5efa\u7acb\u81ea\u7136\u8bed\u8a00\u4e0e\u591a\u6a21\u6001\u7761\u7720\u751f\u7406\u4fe1\u53f7\u4e4b\u95f4\u7684\u6865\u6881\u3002", "method": "1\uff09\u5f15\u5165\u591a\u7ea7\u7761\u7720\u63cf\u8ff0\u751f\u6210\u6d41\u7a0b\uff0c\u6784\u5efa\u9996\u4e2a\u5927\u89c4\u6a21\u7761\u7720-\u6587\u672c\u6570\u636e\u96c6\uff08\u8d85\u8fc710\u4e07\u5c0f\u65f6\u6570\u636e\uff0c\u6765\u81ea1\u4e07\u591a\u540d\u4e2a\u4f53\uff09\uff1b2\uff09\u63d0\u51fa\u7edf\u4e00\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5bf9\u9f50\u3001\u63cf\u8ff0\u751f\u6210\u548c\u4fe1\u53f7\u91cd\u5efa\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u751f\u7406\u4fdd\u771f\u5ea6\u548c\u8de8\u6a21\u6001\u4ea4\u4e92\u3002", "result": "SleepLM\u5728\u771f\u5b9e\u4e16\u754c\u7684\u7761\u7720\u7406\u89e3\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u3001\u8de8\u6a21\u6001\u68c0\u7d22\u548c\u7761\u7720\u63cf\u8ff0\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002\u6a21\u578b\u8fd8\u5c55\u73b0\u51fa\u8bed\u8a00\u5f15\u5bfc\u7684\u4e8b\u4ef6\u5b9a\u4f4d\u3001\u9488\u5bf9\u6027\u6d1e\u5bdf\u751f\u6210\u548c\u96f6\u6837\u672c\u6cdb\u5316\u5230\u672a\u89c1\u4efb\u52a1\u7b49\u6709\u8da3\u80fd\u529b\u3002", "conclusion": "SleepLM\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u4e0e\u591a\u6a21\u6001\u7761\u7720\u751f\u7406\u4fe1\u53f7\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u4eba\u7c7b\u7761\u7720\u7684\u5bf9\u9f50\u3001\u89e3\u91ca\u548c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\uff0c\u4e3a\u7761\u7720\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u6240\u6709\u4ee3\u7801\u548c\u6570\u636e\u5c06\u5f00\u6e90\u3002"}}
{"id": "2602.24108", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.24108", "abs": "https://arxiv.org/abs/2602.24108", "authors": ["Yakun Zhang", "Zihan Wang", "Xinzhi Peng", "Zihao Xie", "Xiaodong Wang", "Xutao Li", "Dan Hao", "Lu Zhang", "Yunming Ye"], "title": "Context-Aware Functional Test Generation via Business Logic Extraction and Adaptation", "comment": null, "summary": "Functional testing is essential for verifying that the business logic of mobile applications aligns with user requirements, serving as the primary methodology for quality assurance in software development. Despite its importance, functional testing remains heavily dependent on manual effort due to two core challenges. First, acquiring and reusing complex business logic from unstructured requirements remains difficult, which hinders the understanding of specific functionalities. Second, a significant semantic gap exists when adapting business logic to the diverse GUI environments, which hinders the generation of test cases for specific mobile applications. To address the preceding challenges, we propose LogiDroid, a two-stage approach that generates individual functional test cases by extracting business logic and adapting it to target applications. First, in the Knowledge Retrieval and Fusion stage, we construct a dataset to retrieve relevant cases and extract business logic for the target functionality. Second, in the Context-Aware Test Generation stage, LogiDroid jointly analyzes the extracted business logic and the real-time GUI environment to generate functional test cases. This design allows LogiDroid to accurately understand application semantics and use domain expertise to generate complete test cases with verification assertions. We assess the effectiveness of LogiDroid using two widely-used datasets that cover 28 real-world applications and 190 functional requirements. Experimental results show that LogiDroid successfully tested 40% of functional requirements on the FrUITeR dataset (an improvement of over 48% compared to the state-of-the-art approaches) and 65% on the Lin dataset (an improvement of over 55% compared to the state-of-the-art approaches). These results demonstrate the significant effectiveness of LogiDroid in functional test generation.", "AI": {"tldr": "LogiDroid\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u4e1a\u52a1\u903b\u8f91\u5e76\u9002\u914d\u5230\u76ee\u6807\u5e94\u7528\u6765\u751f\u6210\u79fb\u52a8\u5e94\u7528\u529f\u80fd\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5206\u522b\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u534748%\u548c55%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u529f\u80fd\u6d4b\u8bd5\u5bf9\u9a8c\u8bc1\u4e1a\u52a1\u903b\u8f91\u4e0e\u7528\u6237\u9700\u6c42\u7684\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1) \u4ece\u975e\u7ed3\u6784\u5316\u9700\u6c42\u4e2d\u83b7\u53d6\u548c\u590d\u7528\u590d\u6742\u4e1a\u52a1\u903b\u8f91\u56f0\u96be\uff1b2) \u5c06\u4e1a\u52a1\u903b\u8f91\u9002\u914d\u5230\u591a\u6837\u5316GUI\u73af\u5883\u65f6\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\uff0c\u963b\u788d\u4e86\u9488\u5bf9\u7279\u5b9a\u79fb\u52a8\u5e94\u7528\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002", "method": "LogiDroid\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u77e5\u8bc6\u68c0\u7d22\u4e0e\u878d\u5408\u9636\u6bb5\uff1a\u6784\u5efa\u6570\u636e\u96c6\u68c0\u7d22\u76f8\u5173\u6848\u4f8b\uff0c\u4e3a\u76ee\u6807\u529f\u80fd\u63d0\u53d6\u4e1a\u52a1\u903b\u8f91\uff1b2) \u4e0a\u4e0b\u6587\u611f\u77e5\u6d4b\u8bd5\u751f\u6210\u9636\u6bb5\uff1a\u8054\u5408\u5206\u6790\u63d0\u53d6\u7684\u4e1a\u52a1\u903b\u8f91\u548c\u5b9e\u65f6GUI\u73af\u5883\uff0c\u751f\u6210\u5305\u542b\u9a8c\u8bc1\u65ad\u8a00\u7684\u529f\u80fd\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u5728\u8986\u76d628\u4e2a\u771f\u5b9e\u5e94\u7528\u548c190\u4e2a\u529f\u80fd\u9700\u6c42\u7684\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cLogiDroid\u5728FrUITeR\u6570\u636e\u96c6\u4e0a\u6210\u529f\u6d4b\u8bd5\u4e8640%\u7684\u529f\u80fd\u9700\u6c42\uff08\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u534748%\u4ee5\u4e0a\uff09\uff0c\u5728Lin\u6570\u636e\u96c6\u4e0a\u6210\u529f\u6d4b\u8bd5\u4e8665%\uff08\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u534755%\u4ee5\u4e0a\uff09\u3002", "conclusion": "LogiDroid\u901a\u8fc7\u51c6\u786e\u7406\u89e3\u5e94\u7528\u8bed\u4e49\u548c\u5229\u7528\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u751f\u6210\u5b8c\u6574\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5728\u529f\u80fd\u6d4b\u8bd5\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u6709\u6548\u6027\uff0c\u89e3\u51b3\u4e86\u79fb\u52a8\u5e94\u7528\u529f\u80fd\u6d4b\u8bd5\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2602.23530", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23530", "abs": "https://arxiv.org/abs/2602.23530", "authors": ["Aditya Gaydhani", "Guangyue Xu", "Dhanush Kamath", "Ankit Singh", "Alex Li"], "title": "Unified Learning-to-Rank for Multi-Channel Retrieval in Large-Scale E-Commerce Search", "comment": null, "summary": "Large-scale e-commerce search must surface a broad set of items from a vast catalog, ranging from bestselling products to new, trending, or seasonal items. Modern systems therefore rely on multiple specialized retrieval channels to surface products, each designed to satisfy a specific objective. A key challenge is how to effectively merge documents from these heterogeneous channels into a single ranked list under strict latency constraints while optimizing for business KPIs such as user conversion. Rank-based fusion methods such as Reciprocal Rank Fusion (RRF) and Weighted Interleaving rely on fixed global channel weights and treat channels independently, failing to account for query-specific channel utility and cross-channel interactions. We observe that multi-channel fusion can be reformulated as a query-dependent learning-to-rank problem over heterogeneous candidate sources. In this paper, we propose a unified ranking model that learns to merge and rank documents from multiple retrieval channels. We formulate the problem as a channel-aware learning-to-rank task that jointly optimizes clicks, add-to-carts, and purchases while incorporating channel-specific objectives. We further incorporate recent user behavioral signals to capture short-term intent shifts that are critical for improving conversion in multi-channel ranking. Our online A/B experiments show that the proposed approach outperforms rank-based fusion methods, leading to a +2.85\\% improvement in user conversion. The model satisfies production latency requirements, achieving a p95 latency of under 50\\,ms, and is deployed on Target.com.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u591a\u901a\u9053\u878d\u5408\u6392\u5e8f\u6a21\u578b\uff0c\u5c06\u7535\u5546\u641c\u7d22\u4e2d\u7684\u591a\u901a\u9053\u6587\u6863\u5408\u5e76\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u67e5\u8be2\u76f8\u5173\u7684\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u70b9\u51fb\u3001\u52a0\u8d2d\u548c\u8d2d\u4e70\u7b49\u4e1a\u52a1\u6307\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7528\u6237\u8f6c\u5316\u7387\u3002", "motivation": "\u5927\u89c4\u6a21\u7535\u5546\u641c\u7d22\u9700\u8981\u4ece\u6d77\u91cf\u5546\u54c1\u76ee\u5f55\u4e2d\u68c0\u7d22\u591a\u6837\u5316\u7684\u5546\u54c1\uff0c\u5305\u62ec\u7545\u9500\u54c1\u3001\u65b0\u54c1\u3001\u8d8b\u52bf\u54c1\u548c\u5b63\u8282\u6027\u5546\u54c1\u3002\u73b0\u6709\u7cfb\u7edf\u4f9d\u8d56\u591a\u4e2a\u4e13\u4e1a\u68c0\u7d22\u901a\u9053\u6765\u6ee1\u8db3\u4e0d\u540c\u76ee\u6807\uff0c\u4f46\u4f20\u7edf\u7684\u57fa\u4e8e\u6392\u540d\u7684\u878d\u5408\u65b9\u6cd5\uff08\u5982RRF\u548c\u52a0\u6743\u4ea4\u7ec7\uff09\u4f7f\u7528\u56fa\u5b9a\u7684\u5168\u5c40\u901a\u9053\u6743\u91cd\uff0c\u65e0\u6cd5\u8003\u8651\u67e5\u8be2\u7279\u5b9a\u7684\u901a\u9053\u6548\u7528\u548c\u8de8\u901a\u9053\u4ea4\u4e92\uff0c\u9650\u5236\u4e86\u4e1a\u52a1KPI\uff08\u5982\u7528\u6237\u8f6c\u5316\uff09\u7684\u4f18\u5316\u6548\u679c\u3002", "method": "\u5c06\u591a\u901a\u9053\u878d\u5408\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u67e5\u8be2\u76f8\u5173\u7684\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\uff0c\u63d0\u51fa\u7edf\u4e00\u7684\u6392\u5e8f\u6a21\u578b\u6765\u5b66\u4e60\u548c\u5408\u5e76\u6765\u81ea\u591a\u4e2a\u68c0\u7d22\u901a\u9053\u7684\u6587\u6863\u3002\u8be5\u65b9\u6cd5\u5c06\u95ee\u9898\u6784\u5efa\u4e3a\u901a\u9053\u611f\u77e5\u7684\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\uff0c\u8054\u5408\u4f18\u5316\u70b9\u51fb\u3001\u52a0\u8d2d\u548c\u8d2d\u4e70\u7b49\u4e1a\u52a1\u6307\u6807\uff0c\u540c\u65f6\u878d\u5165\u901a\u9053\u7279\u5b9a\u7684\u76ee\u6807\u3002\u8fdb\u4e00\u6b65\u6574\u5408\u4e86\u8fd1\u671f\u7528\u6237\u884c\u4e3a\u4fe1\u53f7\u6765\u6355\u6349\u77ed\u671f\u610f\u56fe\u53d8\u5316\uff0c\u8fd9\u5bf9\u63d0\u5347\u591a\u901a\u9053\u6392\u5e8f\u4e2d\u7684\u8f6c\u5316\u7387\u81f3\u5173\u91cd\u8981\u3002", "result": "\u5728\u7ebfA/B\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u6392\u540d\u7684\u878d\u5408\u65b9\u6cd5\uff0c\u7528\u6237\u8f6c\u5316\u7387\u63d0\u5347\u4e86+2.85%\u3002\u6a21\u578b\u6ee1\u8db3\u751f\u4ea7\u5ef6\u8fdf\u8981\u6c42\uff0cp95\u5ef6\u8fdf\u4f4e\u4e8e50\u6beb\u79d2\uff0c\u5e76\u5df2\u5728Target.com\u4e0a\u90e8\u7f72\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5c06\u591a\u901a\u9053\u878d\u5408\u91cd\u65b0\u5b9a\u4e49\u4e3a\u67e5\u8be2\u76f8\u5173\u7684\u5b66\u4e60\u6392\u5e8f\u95ee\u9898\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u7684\u7edf\u4e00\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u67e5\u8be2\u7279\u5b9a\u7684\u901a\u9053\u6548\u7528\u548c\u8de8\u901a\u9053\u4ea4\u4e92\uff0c\u5728\u6ee1\u8db3\u4e25\u683c\u5ef6\u8fdf\u7ea6\u675f\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u7535\u5546\u641c\u7d22\u7684\u4e1a\u52a1\u6307\u6807\u3002"}}
{"id": "2602.23459", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.23459", "abs": "https://arxiv.org/abs/2602.23459", "authors": ["Eric V. Strobl"], "title": "Global Interpretability via Automated Preprocessing: A Framework Inspired by Psychiatric Questionnaires", "comment": null, "summary": "Psychiatric questionnaires are highly context sensitive and often only weakly predict subsequent symptom severity, which makes the prognostic relationship difficult to learn. Although flexible nonlinear models can improve predictive accuracy, their limited interpretability can erode clinical trust. In fields such as imaging and omics, investigators commonly address visit- and instrument-specific artifacts by extracting stable signal through preprocessing and then fitting an interpretable linear model. We adopt the same strategy for questionnaire data by decoupling preprocessing from prediction: we restrict nonlinear capacity to a baseline preprocessing module that estimates stable item values, and then learn a linear mapping from these stabilized baseline items to future severity. We refer to this two-stage method as REFINE (Redundancy-Exploiting Follow-up-Informed Nonlinear Enhancement), which concentrates nonlinearity in preprocessing while keeping the prognostic relationship transparently linear and therefore globally interpretable through a coefficient matrix, rather than through post hoc local attributions. In experiments, REFINE outperforms other interpretable approaches while preserving clear global attribution of prognostic factors across psychiatric and non-psychiatric longitudinal prediction tasks.", "AI": {"tldr": "REFINE\u65b9\u6cd5\u901a\u8fc7\u5c06\u975e\u7ebf\u6027\u5904\u7406\u9650\u5236\u5728\u57fa\u7ebf\u9884\u5904\u7406\u6a21\u5757\u4e2d\uff0c\u63d0\u53d6\u7a33\u5b9a\u7684\u9879\u76ee\u503c\uff0c\u7136\u540e\u5b66\u4e60\u4ece\u8fd9\u4e9b\u7a33\u5b9a\u5316\u57fa\u7ebf\u9879\u76ee\u5230\u672a\u6765\u75c7\u72b6\u4e25\u91cd\u7a0b\u5ea6\u7684\u7ebf\u6027\u6620\u5c04\uff0c\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u7cbe\u795e\u75c5\u5b66\u95ee\u5377\u5177\u6709\u9ad8\u5ea6\u60c5\u5883\u654f\u611f\u6027\uff0c\u5bf9\u540e\u7eed\u75c7\u72b6\u4e25\u91cd\u7a0b\u5ea6\u7684\u9884\u6d4b\u80fd\u529b\u8f83\u5f31\u3002\u867d\u7136\u975e\u7ebf\u6027\u6a21\u578b\u53ef\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u5176\u6709\u9650\u7684\u53ef\u89e3\u91ca\u6027\u4f1a\u524a\u5f31\u4e34\u5e8a\u4fe1\u4efb\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\u53c8\u80fd\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5REFINE\uff1a1\uff09\u5c06\u975e\u7ebf\u6027\u80fd\u529b\u9650\u5236\u5728\u57fa\u7ebf\u9884\u5904\u7406\u6a21\u5757\u4e2d\uff0c\u4f30\u8ba1\u7a33\u5b9a\u7684\u9879\u76ee\u503c\uff1b2\uff09\u5b66\u4e60\u4ece\u8fd9\u4e9b\u7a33\u5b9a\u5316\u57fa\u7ebf\u9879\u76ee\u5230\u672a\u6765\u4e25\u91cd\u7a0b\u5ea6\u7684\u7ebf\u6027\u6620\u5c04\u3002\u8fd9\u6837\u5c06\u975e\u7ebf\u6027\u96c6\u4e2d\u5728\u9884\u5904\u7406\u9636\u6bb5\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u540e\u5173\u7cfb\u7684\u900f\u660e\u7ebf\u6027\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cREFINE\u4f18\u4e8e\u5176\u4ed6\u53ef\u89e3\u91ca\u65b9\u6cd5\uff0c\u540c\u65f6\u5728\u7cbe\u795e\u75c5\u5b66\u548c\u975e\u7cbe\u795e\u75c5\u5b66\u7eb5\u5411\u9884\u6d4b\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e86\u5bf9\u9884\u540e\u56e0\u7d20\u7684\u6e05\u6670\u5168\u5c40\u5f52\u56e0\u3002", "conclusion": "REFINE\u65b9\u6cd5\u901a\u8fc7\u5206\u79bb\u9884\u5904\u7406\u548c\u9884\u6d4b\uff0c\u5c06\u975e\u7ebf\u6027\u96c6\u4e2d\u5728\u9884\u5904\u7406\u9636\u6bb5\uff0c\u540c\u65f6\u4fdd\u6301\u7ebf\u6027\u9884\u6d4b\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5728\u4fdd\u6301\u5168\u5c40\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u7684\u76ee\u6807\uff0c\u4e3a\u4e34\u5e8a\u5b9e\u8df5\u63d0\u4f9b\u4e86\u53ef\u4fe1\u7684\u9884\u6d4b\u5de5\u5177\u3002"}}
{"id": "2602.23632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23632", "abs": "https://arxiv.org/abs/2602.23632", "authors": ["Lun Zhan", "Feng Xiong", "Huanyong Liu", "Feng Zhang", "Yuhui Yin"], "title": "MMKG-RDS: Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs", "comment": null, "summary": "Synthesizing high-quality training data is crucial for enhancing domain models' reasoning abilities. Existing methods face limitations in long-tail knowledge coverage, effectiveness verification, and interpretability. Knowledge-graph-based approaches still fall short in functionality, granularity, customizability, and evaluation. To address these issues, we propose MMKG-RDS, a flexible framework for reasoning data synthesis that leverages multimodal knowledge graphs. It supports fine-grained knowledge extraction, customizable path sampling, and multidimensional data quality scoring. We validate MMKG-RDS with the MMKG-RDS-Bench dataset, covering five domains, 17 task types, and 14,950 samples. Experimental results show fine-tuning Qwen3 models (0.6B/8B/32B) on a small number of synthesized samples improves reasoning accuracy by 9.2%. The framework also generates distinct data, challenging existing models on tasks involving tables and formulas, useful for complex benchmark construction. The dataset and code are available at https://github.com/360AILAB-NLP/MMKG-RDS", "AI": {"tldr": "MMKG-RDS\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u63a8\u7406\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u63d0\u53d6\u3001\u53ef\u5b9a\u5236\u8def\u5f84\u91c7\u6837\u548c\u591a\u7ef4\u6570\u636e\u8d28\u91cf\u8bc4\u5206\uff0c\u6709\u6548\u63d0\u5347\u9886\u57df\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u957f\u5c3e\u77e5\u8bc6\u8986\u76d6\u3001\u6709\u6548\u6027\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u5728\u529f\u80fd\u6027\u3001\u7c92\u5ea6\u3001\u53ef\u5b9a\u5236\u6027\u548c\u8bc4\u4f30\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u63a8\u7406\u6570\u636e\u5408\u6210\u6846\u67b6\u3002", "method": "\u63d0\u51faMMKG-RDS\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u63d0\u53d6\uff0c\u652f\u6301\u53ef\u5b9a\u5236\u7684\u8def\u5f84\u91c7\u6837\u7b56\u7565\uff0c\u5e76\u91c7\u7528\u591a\u7ef4\u6570\u636e\u8d28\u91cf\u8bc4\u5206\u673a\u5236\u6765\u8bc4\u4f30\u5408\u6210\u6570\u636e\u7684\u8d28\u91cf\u3002", "result": "\u6784\u5efa\u4e86MMKG-RDS-Bench\u6570\u636e\u96c6\uff0c\u8986\u76d65\u4e2a\u9886\u57df\u300117\u79cd\u4efb\u52a1\u7c7b\u578b\u548c14,950\u4e2a\u6837\u672c\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u5c11\u91cf\u5408\u6210\u6570\u636e\u4e0a\u5fae\u8c03Qwen3\u6a21\u578b\uff080.6B/8B/32B\uff09\u53ef\u4f7f\u63a8\u7406\u51c6\u786e\u7387\u63d0\u53479.2%\u3002", "conclusion": "MMKG-RDS\u80fd\u6709\u6548\u5408\u6210\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u751f\u6210\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u636e\uff08\u6d89\u53ca\u8868\u683c\u548c\u516c\u5f0f\uff09\uff0c\u53ef\u7528\u4e8e\u590d\u6742\u57fa\u51c6\u6d4b\u8bd5\u6784\u5efa\uff0c\u4e3a\u9886\u57df\u6a21\u578b\u589e\u5f3a\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.23701", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23701", "abs": "https://arxiv.org/abs/2602.23701", "authors": ["Yawen Wang", "Wenjie Wu", "Junjie Wang", "Qing Wang"], "title": "From Flat Logs to Causal Graphs: Hierarchical Failure Attribution for LLM-based Multi-Agent Systems", "comment": null, "summary": "LLM-powered Multi-Agent Systems (MAS) have demonstrated remarkable capabilities in complex domains but suffer from inherent fragility and opaque failure mechanisms. Existing failure attribution methods, whether relying on direct prompting, costly replays, or supervised fine-tuning, typically treat execution logs as flat sequences. This linear perspective fails to disentangle the intricate causal links inherent to MAS, leading to weak observability and ambiguous responsibility boundaries. To address these challenges, we propose CHIEF, a novel framework that transforms chaotic trajectories into a structured hierarchical causal graph. It then employs hierarchical oracle-guided backtracking to efficiently prune the search space via sybthesized virtual oracles. Finally, it implements counterfactual attribution via a progressive causal screening strategy to rigorously distinguish true root causes from propagated symptoms. Experiments on Who&When benchmark show that CHIEF outperforms eight strong and state-of-the-art baselines on both agent- and step-level accuracy. Ablation studies further confirm the critical role of each proposed module.", "AI": {"tldr": "CHIEF\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6df7\u4e71\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8f68\u8ff9\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u5206\u5c42\u56e0\u679c\u56fe\uff0c\u7ed3\u5408\u5206\u5c42\u9884\u8a00\u5f15\u5bfc\u56de\u6eaf\u548c\u6e10\u8fdb\u56e0\u679c\u7b5b\u9009\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6545\u969c\u5f52\u56e0\u7684\u51c6\u786e\u6027\u3002", "motivation": "LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u56fa\u6709\u7684\u8106\u5f31\u6027\u548c\u4e0d\u900f\u660e\u7684\u6545\u969c\u673a\u5236\u3002\u73b0\u6709\u6545\u969c\u5f52\u56e0\u65b9\u6cd5\u901a\u5e38\u5c06\u6267\u884c\u65e5\u5fd7\u89c6\u4e3a\u5e73\u9762\u5e8f\u5217\uff0c\u8fd9\u79cd\u7ebf\u6027\u89c6\u89d2\u65e0\u6cd5\u89e3\u5f00MAS\u4e2d\u590d\u6742\u7684\u56e0\u679c\u8054\u7cfb\uff0c\u5bfc\u81f4\u5f31\u53ef\u89c2\u6d4b\u6027\u548c\u6a21\u7cca\u7684\u8d23\u4efb\u8fb9\u754c\u3002", "method": "1) \u5c06\u6df7\u4e71\u8f68\u8ff9\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u5206\u5c42\u56e0\u679c\u56fe\uff1b2) \u91c7\u7528\u5206\u5c42\u9884\u8a00\u5f15\u5bfc\u56de\u6eaf\uff0c\u901a\u8fc7\u5408\u6210\u865a\u62df\u9884\u8a00\u9ad8\u6548\u526a\u679d\u641c\u7d22\u7a7a\u95f4\uff1b3) \u901a\u8fc7\u6e10\u8fdb\u56e0\u679c\u7b5b\u9009\u7b56\u7565\u5b9e\u73b0\u53cd\u4e8b\u5b9e\u5f52\u56e0\uff0c\u4e25\u683c\u533a\u5206\u771f\u5b9e\u6839\u672c\u539f\u56e0\u548c\u4f20\u64ad\u75c7\u72b6\u3002", "result": "\u5728Who&When\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCHIEF\u5728\u667a\u80fd\u4f53\u7ea7\u548c\u6b65\u9aa4\u7ea7\u51c6\u786e\u6027\u4e0a\u5747\u4f18\u4e8e\u516b\u4e2a\u5f3a\u5927\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u6bcf\u4e2a\u63d0\u51fa\u6a21\u5757\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "CHIEF\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u5c42\u56e0\u679c\u5206\u6790\u548c\u9ad8\u6548\u56de\u6eaf\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6545\u969c\u5f52\u56e0\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u89e3\u51b3MAS\u7684\u8106\u5f31\u6027\u548c\u4e0d\u900f\u660e\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.23620", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23620", "abs": "https://arxiv.org/abs/2602.23620", "authors": ["Gui Ling", "Weiyuan Li", "Yue Jiang", "Wenjun Peng", "Xingxian Liu", "Dongshuai Li", "Fuyu Lv", "Dan Ou", "Haihong Tang"], "title": "Synthetic Data Powers Product Retrieval for Long-tail Knowledge-Intensive Queries in E-commerce Search", "comment": null, "summary": "Product retrieval is the backbone of e-commerce search: for each user query, it identifies a high-recall candidate set from billions of items, laying the foundation for high-quality ranking and user experience. Despite extensive optimization for mainstream queries, existing systems still struggle with long-tail queries, especially knowledge-intensive ones. These queries exhibit diverse linguistic patterns, often lack explicit purchase intent, and require domain-specific knowledge reasoning for accurate interpretation. They also suffer from a shortage of reliable behavioral logs, which makes such queries a persistent challenge for retrieval optimization. To address these issues, we propose an efficient data synthesis framework tailored to retrieval involving long-tail, knowledge-intensive queries. The key idea is to implicitly distill the capabilities of a powerful offline query-rewriting model into an efficient online retrieval system. Leveraging the strong language understanding of LLMs, we train a multi-candidate query rewriting model with multiple reward signals and capture its rewriting capability in well-curated query-product pairs through a powerful offline retrieval pipeline. This design mitigates distributional shift in rewritten queries, which might otherwise limit incremental recall or introduce irrelevant products. Experiments demonstrate that without any additional tricks, simply incorporating this synthetic data into retrieval model training leads to significant improvements. Online Side-By-Side (SBS) human evaluation results indicate a notable enhancement in user search experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u957f\u5c3e\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u67e5\u8be2\u7684\u7535\u5546\u4ea7\u54c1\u68c0\u7d22\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5f3a\u5927\u7684\u79bb\u7ebf\u67e5\u8be2\u91cd\u5199\u6a21\u578b\u80fd\u529b\u84b8\u998f\u5230\u5728\u7ebf\u68c0\u7d22\u7cfb\u7edf\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u957f\u5c3e\u67e5\u8be2\u7684\u68c0\u7d22\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7535\u5546\u68c0\u7d22\u7cfb\u7edf\u5728\u5904\u7406\u957f\u5c3e\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u67e5\u8be2\u65f6\u9762\u4e34\u6311\u6218\uff1a\u8fd9\u4e9b\u67e5\u8be2\u8bed\u8a00\u6a21\u5f0f\u591a\u6837\u3001\u7f3a\u4e4f\u660e\u786e\u8d2d\u4e70\u610f\u56fe\u3001\u9700\u8981\u9886\u57df\u77e5\u8bc6\u63a8\u7406\uff0c\u4e14\u7f3a\u4e4f\u53ef\u9760\u7684\u884c\u4e3a\u65e5\u5fd7\u6570\u636e\uff0c\u5bfc\u81f4\u68c0\u7d22\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u9ad8\u6548\u7684\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7LLM\u7684\u5f3a\u5927\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u8bad\u7ec3\u591a\u5019\u9009\u67e5\u8be2\u91cd\u5199\u6a21\u578b\uff0c\u4f7f\u7528\u591a\u5956\u52b1\u4fe1\u53f7\uff0c\u5e76\u901a\u8fc7\u5f3a\u5927\u7684\u79bb\u7ebf\u68c0\u7d22\u6d41\u7a0b\u6355\u83b7\u5176\u91cd\u5199\u80fd\u529b\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u67e5\u8be2-\u4ea7\u54c1\u5bf9\u5408\u6210\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u5c06\u5408\u6210\u6570\u636e\u7eb3\u5165\u68c0\u7d22\u6a21\u578b\u8bad\u7ec3\u5373\u53ef\u5e26\u6765\u663e\u8457\u6539\u8fdb\u3002\u5728\u7ebfA/B\u6d4b\u8bd5\u7684\u4eba\u7c7b\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u7528\u6237\u641c\u7d22\u4f53\u9a8c\u5f97\u5230\u660e\u663e\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u957f\u5c3e\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u67e5\u8be2\u7684\u68c0\u7d22\u96be\u9898\uff0c\u901a\u8fc7\u9690\u5f0f\u84b8\u998f\u5f3a\u5927\u79bb\u7ebf\u6a21\u578b\u80fd\u529b\u5230\u5728\u7ebf\u7cfb\u7edf\uff0c\u6539\u5584\u4e86\u7535\u5546\u641c\u7d22\u7684\u6574\u4f53\u8d28\u91cf\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2602.23495", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23495", "abs": "https://arxiv.org/abs/2602.23495", "authors": ["Yangyi Li", "Mengdi Huai"], "title": "Uncertainty-aware Language Guidance for Concept Bottleneck Models", "comment": null, "summary": "Concept Bottleneck Models (CBMs) provide inherent interpretability by first mapping input samples to high-level semantic concepts, followed by a combination of these concepts for the final classification. However, the annotation of human-understandable concepts requires extensive expert knowledge and labor, constraining the broad adoption of CBMs. On the other hand, there are a few works that leverage the knowledge of large language models (LLMs) to construct concept bottlenecks. Nevertheless, they face two essential limitations: First, they overlook the uncertainty associated with the concepts annotated by LLMs and lack a valid mechanism to quantify uncertainty about the annotated concepts, increasing the risk of errors due to hallucinations from LLMs. Additionally, they fail to incorporate the uncertainty associated with these annotations into the learning process for concept bottleneck models. To address these limitations, we propose a novel uncertainty-aware CBM method, which not only rigorously quantifies the uncertainty of LLM-annotated concept labels with valid and distribution-free guarantees, but also incorporates quantified concept uncertainty into the CBM training procedure to account for varying levels of reliability across LLM-annotated concepts. We also provide the theoretical analysis for our proposed method. Extensive experiments on the real-world datasets validate the desired properties of our proposed methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316LLM\u6807\u6ce8\u6982\u5ff5\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u7eb3\u5165\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6LLM\u6807\u6ce8\u4e0d\u786e\u5b9a\u6027\u548c\u7f3a\u4e4f\u6709\u6548\u91cf\u5316\u673a\u5236\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u77e5\u8bc6\u6807\u6ce8\u6982\u5ff5\uff0c\u9650\u5236\u4e86\u5e7f\u6cdb\u5e94\u7528\u3002\u73b0\u6709\u5229\u7528LLM\u6784\u5efa\u6982\u5ff5\u74f6\u9888\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1) \u5ffd\u89c6LLM\u6807\u6ce8\u6982\u5ff5\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u91cf\u5316\u673a\u5236\uff1b2) \u672a\u5c06\u6807\u6ce8\u4e0d\u786e\u5b9a\u6027\u7eb3\u5165\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u589e\u52a0\u4e86\u56e0LLM\u5e7b\u89c9\u5bfc\u81f4\u9519\u8bef\u7684\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5CBM\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4ee5\u6709\u6548\u4e14\u65e0\u5206\u5e03\u7684\u65b9\u5f0f\u4e25\u683c\u91cf\u5316LLM\u6807\u6ce8\u6982\u5ff5\u6807\u7b7e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd8\u5c06\u91cf\u5316\u7684\u6982\u5ff5\u4e0d\u786e\u5b9a\u6027\u7eb3\u5165CBM\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4ee5\u8003\u8651LLM\u6807\u6ce8\u6982\u5ff5\u7684\u4e0d\u540c\u53ef\u9760\u6027\u6c34\u5e73\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u671f\u671b\u7279\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u91cf\u5316LLM\u6807\u6ce8\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u5c06\u5176\u7eb3\u5165\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5173\u952e\u5c40\u9650\uff0c\u63d0\u9ad8\u4e86\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.23643", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23643", "abs": "https://arxiv.org/abs/2602.23643", "authors": ["Judah Goldfeder", "Philippe Wyder", "Yann LeCun", "Ravid Shwartz Ziv"], "title": "AI Must Embrace Specialization via Superhuman Adaptable Intelligence", "comment": null, "summary": "Everyone from AI executives and researchers to doomsayers, politicians, and activists is talking about Artificial General Intelligence (AGI). Yet, they often don't seem to agree on its exact definition. One common definition of AGI is an AI that can do everything a human can do, but are humans truly general? In this paper, we address what's wrong with our conception of AGI, and why, even in its most coherent formulation, it is a flawed concept to describe the future of AI. We explore whether the most widely accepted definitions are plausible, useful, and truly general. We argue that AI must embrace specialization, rather than strive for generality, and in its specialization strive for superhuman performance, and introduce Superhuman Adaptable Intelligence (SAI). SAI is defined as intelligence that can learn to exceed humans at anything important that we can do, and that can fill in the skill gaps where humans are incapable. We then lay out how SAI can help hone a discussion around AI that was blurred by an overloaded definition of AGI, and extrapolate the implications of using it as a guide for the future.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6279\u5224\u4e86\u5f53\u524d\u5bf9\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u7684\u5b9a\u4e49\uff0c\u8ba4\u4e3a\"\u4eba\u7c7b\u80fd\u505a\u7684\u4e00\u5207\"\u8fd9\u4e00\u6807\u51c6\u65e2\u4e0d\u53ef\u884c\u4e5f\u65e0\u7528\uff0c\u63d0\u51fa\u4e86\u4e13\u6ce8\u4e8e\u7279\u5b9a\u9886\u57df\u5e76\u8ffd\u6c42\u8d85\u4eba\u7c7b\u6027\u80fd\u7684\"\u8d85\u4eba\u7c7b\u9002\u5e94\u667a\u80fd\uff08SAI\uff09\"\u4f5c\u4e3a\u66ff\u4ee3\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u5173\u4e8eAGI\u7684\u8ba8\u8bba\u5b58\u5728\u5b9a\u4e49\u6df7\u4e71\u3001\u6982\u5ff5\u6a21\u7cca\u7684\u95ee\u9898\uff0c\u5404\u65b9\u5bf9AGI\u7684\u7406\u89e3\u4e0d\u4e00\u81f4\u3002\u4f5c\u8005\u8ba4\u4e3a\u73b0\u6709\u7684AGI\u5b9a\u4e49\uff08\u5982\"\u80fd\u505a\u4eba\u7c7b\u80fd\u505a\u7684\u4e00\u5207\"\uff09\u65e2\u4e0d\u73b0\u5b9e\u4e5f\u4e0d\u5b9e\u7528\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u5982\u4f55\u66f4\u597d\u5730\u63cf\u8ff0\u548c\u5f15\u5bfcAI\u7684\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u6279\u5224\u6027\u5206\u6790\u5f53\u524dAGI\u5b9a\u4e49\u7684\u7f3a\u9677\uff0c\u63d0\u51fa\u66ff\u4ee3\u6982\u5ff5\u6846\u67b6\u3002\u4f5c\u8005\u8bba\u8bc1\u4e86\u4e3a\u4ec0\u4e48\u8ffd\u6c42\"\u901a\u7528\u6027\"\u5b58\u5728\u95ee\u9898\uff0c\u7136\u540e\u5f15\u5165\u4e86\"\u8d85\u4eba\u7c7b\u9002\u5e94\u667a\u80fd\uff08SAI\uff09\"\u7684\u6982\u5ff5\uff0c\u5e76\u9610\u8ff0\u5176\u5b9a\u4e49\u548c\u4f18\u52bf\u3002", "result": "\u63d0\u51fa\u4e86SAI\u4f5c\u4e3a\u66ff\u4ee3AGI\u7684\u6982\u5ff5\u6846\u67b6\uff1aSAI\u662f\u80fd\u591f\u5b66\u4e60\u5e76\u8d85\u8d8a\u4eba\u7c7b\u5728\u4efb\u4f55\u91cd\u8981\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u80fd\u586b\u8865\u4eba\u7c7b\u80fd\u529b\u7a7a\u767d\u7684\u667a\u80fd\u7cfb\u7edf\u3002\u8fd9\u4e00\u6982\u5ff5\u66f4\u6e05\u6670\u3001\u66f4\u5b9e\u7528\uff0c\u80fd\u591f\u4e3aAI\u53d1\u5c55\u63d0\u4f9b\u66f4\u597d\u7684\u6307\u5bfc\u65b9\u5411\u3002", "conclusion": "AI\u5e94\u8be5\u4e13\u6ce8\u4e8e\u4e13\u4e1a\u5316\u800c\u975e\u8ffd\u6c42\u901a\u7528\u6027\uff0c\u5728\u7279\u5b9a\u9886\u57df\u8ffd\u6c42\u8d85\u4eba\u7c7b\u6027\u80fd\u3002SAI\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u6e05\u6670\u3001\u66f4\u5b9e\u7528\u7684\u6846\u67b6\u6765\u8ba8\u8bbaAI\u7684\u672a\u6765\uff0c\u80fd\u591f\u66ff\u4ee3\u6a21\u7cca\u7684AGI\u6982\u5ff5\uff0c\u4e3aAI\u53d1\u5c55\u63d0\u4f9b\u66f4\u6709\u610f\u4e49\u7684\u6307\u5bfc\u3002"}}
{"id": "2602.24055", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.24055", "abs": "https://arxiv.org/abs/2602.24055", "authors": ["Reva Schwartz", "Carina Westling", "Morgan Briggs", "Marzieh Fadaee", "Isar Nejadgholi", "Matthew Holmes", "Fariza Rashid", "Maya Carlyle", "Afaf Ta\u00efk", "Kyra Wilson", "Peter Douglas", "Theodora Skeadas", "Gabriella Waters", "Rumman Chowdhury", "Thiago Lacerda"], "title": "CIRCLE: A Framework for Evaluating AI from a Real-World Lens", "comment": "Accepted at Intelligent Systems Conference (IntelliSys) 2026", "summary": "This paper proposes CIRCLE, a six-stage, lifecycle-based framework to bridge the reality gap between model-centric performance metrics and AI's materialized outcomes in deployment. While existing frameworks like MLOps focus on system stability and benchmarks measure abstract capabilities, decision-makers outside the AI stack lack systematic evidence about the behavior of AI technologies under real-world user variability and constraints. CIRCLE operationalizes the Validation phase of TEVV (Test, Evaluation, Verification, and Validation) by formalizing the translation of stakeholder concerns outside the stack into measurable signals. Unlike participatory design, which often remains localized, or algorithmic audits, which are often retrospective, CIRCLE provides a structured, prospective protocol for linking context-sensitive qualitative insights to scalable quantitative metrics. By integrating methods such as field testing, red teaming, and longitudinal studies into a coordinated pipeline, CIRCLE produces systematic knowledge: evidence that is comparable across sites yet sensitive to local context. This can enable governance based on materialized downstream effects rather than theoretical capabilities.", "AI": {"tldr": "CIRCLE\u662f\u4e00\u4e2a\u516d\u9636\u6bb5\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u65e8\u5728\u5f25\u5408\u6a21\u578b\u4e2d\u5fc3\u6027\u80fd\u6307\u6807\u4e0eAI\u5b9e\u9645\u90e8\u7f72\u6548\u679c\u4e4b\u95f4\u7684\u73b0\u5b9e\u5dee\u8ddd\uff0c\u901a\u8fc7\u5c06\u5229\u76ca\u76f8\u5173\u8005\u5173\u6ce8\u8f6c\u5316\u4e3a\u53ef\u6d4b\u91cf\u4fe1\u53f7\uff0c\u5b9e\u73b0\u57fa\u4e8e\u5b9e\u9645\u4e0b\u6e38\u6548\u5e94\u7684\u6cbb\u7406\u3002", "motivation": "\u73b0\u6709MLOps\u6846\u67b6\u5173\u6ce8\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u57fa\u51c6\u6d4b\u8bd5\u8861\u91cf\u62bd\u8c61\u80fd\u529b\uff0c\u4f46AI\u51b3\u7b56\u8005\u7f3a\u4e4f\u5173\u4e8eAI\u6280\u672f\u5728\u771f\u5b9e\u4e16\u754c\u7528\u6237\u53d8\u5f02\u548c\u7ea6\u675f\u4e0b\u884c\u4e3a\u7684\u7cfb\u7edf\u8bc1\u636e\u3002\u9700\u8981\u5f25\u5408\u6a21\u578b\u6027\u80fd\u6307\u6807\u4e0e\u5b9e\u9645\u90e8\u7f72\u7ed3\u679c\u4e4b\u95f4\u7684\u73b0\u5b9e\u5dee\u8ddd\u3002", "method": "CIRCLE\u662f\u4e00\u4e2a\u516d\u9636\u6bb5\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u5c06TEVV\uff08\u6d4b\u8bd5\u3001\u8bc4\u4f30\u3001\u9a8c\u8bc1\u548c\u786e\u8ba4\uff09\u4e2d\u7684\u786e\u8ba4\u9636\u6bb5\u64cd\u4f5c\u5316\u3002\u5b83\u901a\u8fc7\u5c06\u5806\u6808\u5916\u7684\u5229\u76ca\u76f8\u5173\u8005\u5173\u6ce8\u5f62\u5f0f\u5316\u4e3a\u53ef\u6d4b\u91cf\u4fe1\u53f7\uff0c\u6574\u5408\u73b0\u573a\u6d4b\u8bd5\u3001\u7ea2\u961f\u6f14\u7ec3\u548c\u7eb5\u5411\u7814\u7a76\u7b49\u65b9\u6cd5\uff0c\u5f62\u6210\u534f\u8c03\u7684\u7ba1\u9053\u3002", "result": "CIRCLE\u4ea7\u751f\u7cfb\u7edf\u5316\u77e5\u8bc6\uff1a\u8de8\u7ad9\u70b9\u53ef\u6bd4\u4f46\u5bf9\u672c\u5730\u60c5\u5883\u654f\u611f\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002\u5b83\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u524d\u77bb\u6027\u7684\u534f\u8bae\uff0c\u5c06\u60c5\u5883\u654f\u611f\u7684\u5b9a\u6027\u6d1e\u5bdf\u4e0e\u53ef\u6269\u5c55\u7684\u5b9a\u91cf\u6307\u6807\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "CIRCLE\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u57fa\u4e8e\u5b9e\u9645\u4e0b\u6e38\u6548\u5e94\u800c\u975e\u7406\u8bba\u80fd\u529b\u7684\u6cbb\u7406\uff0c\u4e3aAI\u6280\u672f\u5728\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u7684\u884c\u4e3a\u63d0\u4f9b\u7cfb\u7edf\u8bc1\u636e\uff0c\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.23639", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23639", "abs": "https://arxiv.org/abs/2602.23639", "authors": ["Haibo Xing", "Hao Deng", "Lingyu Mu", "Jinxin Hu", "Yu Zhang", "Xiaoyi Zeng", "Jing Zhang"], "title": "Learning to Reflect and Correct: Towards Better Decoding Trajectories for Large-Scale Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GR) has become a promising paradigm for large-scale recommendation systems. However, existing GR models typically perform single-pass decoding without explicit refinement, causing early deviations to accumulate and ultimately degrade recommendation quality. To tackle this problem, we propose GRC, which is, to our knowledge, the first structured reflection-correction framework for GR that extends standard decoding into a Generation-Reflection-Correction (GRC) process. Concretely, GRC introduces a supervised reflection-correction template that decomposes the decoding process into initial draft generation, multi-granular reflection, and reflection-guided correction, thereby enabling structured reflection and correction in the semantic token space. To further explore the enlarged refinement space introduced by the GRC process, we optimize the entire GRC trajectory with GRPO-based reinforcement learning, under a carefully designed reward function with token-level and trajectory-level signals. For efficient online serving, we propose an Entropy-Guided Reflection Scheduling (EGRS) strategy that dynamically allocates more correction budget to high-uncertainty decoding trajectories during beam search. Extensive experiments on real-world datasets show that GRC consistently outperforms six state-of-the-art baselines by up to 15.74%, and online A/B tests demonstrate its substantial practical value in large-scale industrial recommendation, delivering a 1.79% lift in advertising revenue with only modest latency overhead.", "AI": {"tldr": "GRC\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u7ed3\u6784\u5316\u53cd\u601d-\u4fee\u6b63\u673a\u5236\uff0c\u5c06\u751f\u6210\u5f0f\u63a8\u8350\u4ece\u5355\u6b21\u89e3\u7801\u6269\u5c55\u4e3a\u751f\u6210-\u53cd\u601d-\u4fee\u6b63\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u8d28\u91cf", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u901a\u5e38\u91c7\u7528\u5355\u6b21\u89e3\u7801\uff0c\u7f3a\u4e4f\u663e\u5f0f\u4fee\u6b63\u673a\u5236\uff0c\u5bfc\u81f4\u65e9\u671f\u504f\u5dee\u7d2f\u79ef\u5e76\u6700\u7ec8\u964d\u4f4e\u63a8\u8350\u8d28\u91cf", "method": "\u63d0\u51faGRC\u6846\u67b6\uff1a1) \u76d1\u7763\u5f0f\u53cd\u601d-\u4fee\u6b63\u6a21\u677f\uff0c\u5c06\u89e3\u7801\u5206\u89e3\u4e3a\u521d\u59cb\u8349\u7a3f\u751f\u6210\u3001\u591a\u7c92\u5ea6\u53cd\u601d\u548c\u53cd\u601d\u5f15\u5bfc\u4fee\u6b63\uff1b2) \u57fa\u4e8eGRPO\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6574\u4e2aGRC\u8f68\u8ff9\uff1b3) \u71b5\u5f15\u5bfc\u7684\u53cd\u601d\u8c03\u5ea6\u7b56\u7565\u52a8\u6001\u5206\u914d\u4fee\u6b63\u8d44\u6e90", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6bd46\u4e2a\u6700\u5148\u8fdb\u57fa\u7ebf\u63d0\u5347\u9ad8\u8fbe15.74%\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\u5e7f\u544a\u6536\u5165\u63d0\u53471.79%\uff0c\u4ec5\u5e26\u6765\u9002\u5ea6\u5ef6\u8fdf\u5f00\u9500", "conclusion": "GRC\u662f\u9996\u4e2a\u7ed3\u6784\u5316\u53cd\u601d-\u4fee\u6b63\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u5c55\u6807\u51c6\u89e3\u7801\u8fc7\u7a0b\u5b9e\u73b0\u751f\u6210\u5f0f\u63a8\u8350\u7684\u8d28\u91cf\u63d0\u5347\uff0c\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u63a8\u8350\u4e2d\u5177\u6709\u91cd\u8981\u5b9e\u8df5\u4ef7\u503c"}}
{"id": "2602.23504", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23504", "abs": "https://arxiv.org/abs/2602.23504", "authors": ["Anik Pramanik", "Murat Kantarcioglu", "Vincent Oria", "Shantanu Sharma"], "title": "FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments", "comment": "This paper has been accepted in ICLR 2026", "summary": "Federated Learning (FL) enables a group of clients to collaboratively train a model without sharing individual data, but its performance drops when client data are heterogeneous. Clustered FL tackles this by grouping similar clients. However, existing clustered FL approaches rely solely on either data similarity or gradient similarity; however, this results in an incomplete assessment of client similarities. Prior clustered FL approaches also restrict knowledge and representation sharing to clients within the same cluster. This prevents cluster models from benefiting from the diverse client population across clusters. To address these limitations, FedDAG introduces a clustered FL framework, FedDAG, that employs a weighted, class-wise similarity metric that integrates both data and gradient information, providing a more holistic measure of similarity during clustering. In addition, FedDAG adopts a dual-encoder architecture for cluster models, comprising a primary encoder trained on its own clients' data and a secondary encoder refined using gradients from complementary clusters. This enables cross-cluster feature transfer while preserving cluster-specific specialization. Experiments on diverse benchmarks and data heterogeneity settings show that FedDAG consistently outperforms state-of-the-art clustered FL baselines in accuracy.", "AI": {"tldr": "FedDAG\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u6570\u636e\u548c\u68af\u5ea6\u4fe1\u606f\u7684\u52a0\u6743\u7c7b\u522b\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u6765\u6539\u8fdb\u805a\u7c7b\uff0c\u5e76\u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\u5b9e\u73b0\u8de8\u96c6\u7fa4\u7279\u5f81\u8fc1\u79fb\uff0c\u5728\u6570\u636e\u5f02\u6784\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4ec5\u4f9d\u8d56\u6570\u636e\u76f8\u4f3c\u5ea6\u6216\u68af\u5ea6\u76f8\u4f3c\u5ea6\u8fdb\u884c\u805a\u7c7b\uff0c\u5bfc\u81f4\u5bf9\u5ba2\u6237\u7aef\u76f8\u4f3c\u6027\u7684\u8bc4\u4f30\u4e0d\u5b8c\u6574\uff1b2\uff09\u9650\u5236\u77e5\u8bc6\u548c\u8868\u793a\u4ec5\u5728\u76f8\u540c\u96c6\u7fa4\u5185\u5171\u4eab\uff0c\u963b\u788d\u4e86\u96c6\u7fa4\u6a21\u578b\u4ece\u8de8\u96c6\u7fa4\u7684\u591a\u6837\u5316\u5ba2\u6237\u7aef\u7fa4\u4f53\u4e2d\u53d7\u76ca\u3002", "method": "FedDAG\u91c7\u7528\u52a0\u6743\u7c7b\u522b\u76f8\u4f3c\u5ea6\u5ea6\u91cf\uff0c\u6574\u5408\u6570\u636e\u548c\u68af\u5ea6\u4fe1\u606f\u8fdb\u884c\u66f4\u5168\u9762\u7684\u76f8\u4f3c\u6027\u8bc4\u4f30\u3002\u540c\u65f6\u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff1a\u4e3b\u7f16\u7801\u5668\u5728\u81ea\u8eab\u5ba2\u6237\u7aef\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u8f85\u52a9\u7f16\u7801\u5668\u4f7f\u7528\u4e92\u8865\u96c6\u7fa4\u7684\u68af\u5ea6\u8fdb\u884c\u7cbe\u70bc\uff0c\u5b9e\u73b0\u8de8\u96c6\u7fa4\u7279\u5f81\u8fc1\u79fb\u7684\u540c\u65f6\u4fdd\u6301\u96c6\u7fa4\u7279\u5b9a\u4e13\u4e1a\u5316\u3002", "result": "\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u548c\u6570\u636e\u5f02\u6784\u8bbe\u7f6e\u4e0b\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFedDAG\u5728\u51c6\u786e\u7387\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FedDAG\u901a\u8fc7\u66f4\u5168\u9762\u7684\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u548c\u8de8\u96c6\u7fa4\u77e5\u8bc6\u5171\u4eab\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u4e3a\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23668", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.23668", "abs": "https://arxiv.org/abs/2602.23668", "authors": ["Yihan", "Wen", "Xin Chen"], "title": "PseudoAct: Leveraging Pseudocode Synthesis for Flexible Planning and Action Control in Large Language Model Agents", "comment": null, "summary": "Large language model (LLM) agents typically rely on reactive decision-making paradigms such as ReAct, selecting actions conditioned on growing execution histories. While effective for short tasks, these approaches often lead to redundant tool usage, unstable reasoning, and high token consumption in complex long-horizon tasks involving branching, iteration, or multi-tool coordination. To address these limitations, this paper introduces PseudoAct, a novel framework for flexible planning and action control in LLM agents through pseudocode synthesis. Leveraging the ability of LLMs to express task-solving strategies as code, PseudoAct synthesizes a structured pseudocode plan that decomposes a task into subtasks and explicitly encodes control flow, including sequencing, conditionals, loops, parallel composition, and combinations of these logic primitives. Actions are then executed by following this global plan, making the decision logic explicit and temporally coherent. This design reduces redundant actions, prevents infinite loops, and avoids uninformative alternative exploration, enabling consistent and efficient long-horizon decision-making. Experiments on benchmark datasets show that our method significantly outperforms existing reactive agent approaches, achieving a 20.93% absolute gain in success rate on FEVER and setting a new state-of-the-art on HotpotQA.", "AI": {"tldr": "PseudoAct\uff1a\u901a\u8fc7\u4f2a\u4ee3\u7801\u5408\u6210\u5b9e\u73b0LLM\u667a\u80fd\u4f53\u7075\u6d3b\u89c4\u5212\u4e0e\u884c\u52a8\u63a7\u5236\u7684\u65b0\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u957f\u65f6\u7a0b\u4efb\u52a1\u7684\u51b3\u7b56\u6548\u7387\u548c\u6210\u529f\u7387", "motivation": "\u4f20\u7edfLLM\u667a\u80fd\u4f53\uff08\u5982ReAct\uff09\u4f9d\u8d56\u53cd\u5e94\u5f0f\u51b3\u7b56\u8303\u5f0f\uff0c\u5728\u590d\u6742\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u5bb9\u6613\u51fa\u73b0\u5197\u4f59\u5de5\u5177\u4f7f\u7528\u3001\u63a8\u7406\u4e0d\u7a33\u5b9a\u548c\u9ad8token\u6d88\u8017\u7b49\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u5206\u652f\u3001\u8fed\u4ee3\u6216\u591a\u5de5\u5177\u534f\u8c03\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73", "method": "\u63d0\u51faPseudoAct\u6846\u67b6\uff0c\u5229\u7528LLM\u5c06\u4efb\u52a1\u89e3\u51b3\u7b56\u7565\u8868\u8fbe\u4e3a\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u5408\u6210\u7ed3\u6784\u5316\u4f2a\u4ee3\u7801\u8ba1\u5212\uff0c\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u5b50\u4efb\u52a1\u5e76\u663e\u5f0f\u7f16\u7801\u63a7\u5236\u6d41\uff08\u5305\u62ec\u5e8f\u5217\u3001\u6761\u4ef6\u3001\u5faa\u73af\u3001\u5e76\u884c\u7ec4\u5408\u7b49\u903b\u8f91\u539f\u8bed\uff09\uff0c\u7136\u540e\u6309\u7167\u5168\u5c40\u8ba1\u5212\u6267\u884c\u884c\u52a8", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u53cd\u5e94\u5f0f\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u5728FEVER\u4e0a\u5b9e\u73b0\u4e8620.93%\u7684\u7edd\u5bf9\u6210\u529f\u7387\u63d0\u5347\uff0c\u5e76\u5728HotpotQA\u4e0a\u521b\u9020\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73", "conclusion": "PseudoAct\u901a\u8fc7\u4f2a\u4ee3\u7801\u5408\u6210\u5b9e\u73b0\u4e86\u663e\u5f0f\u548c\u65f6\u5e8f\u4e00\u81f4\u7684\u51b3\u7b56\u903b\u8f91\uff0c\u51cf\u5c11\u4e86\u5197\u4f59\u884c\u52a8\uff0c\u9632\u6b62\u4e86\u65e0\u9650\u5faa\u73af\uff0c\u907f\u514d\u4e86\u65e0\u4fe1\u606f\u91cf\u7684\u66ff\u4ee3\u63a2\u7d22\uff0c\u5b9e\u73b0\u4e86\u957f\u65f6\u7a0b\u51b3\u7b56\u7684\u4e00\u81f4\u6027\u548c\u9ad8\u6548\u6027"}}
{"id": "2602.23665", "categories": ["cs.IR", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.23665", "abs": "https://arxiv.org/abs/2602.23665", "authors": ["Brandon Yee", "Lucas Wang", "Kundana Kommini", "Krishna Sharma"], "title": "Geodesic Semantic Search: Learning Local Riemannian Metrics for Citation Graph Retrieval", "comment": null, "summary": "We present Geodesic Semantic Search (GSS), a retrieval system that learns node-specific Riemannian metrics on citation graphs to enable geometry-aware semantic search. Unlike standard embedding-based retrieval that relies on fixed Euclidean distances, \\gss{} learns a low-rank metric tensor $\\mL_i \\in \\R^{d \\times r}$ at each node, inducing a local positive semi-definite metric $\\mG_i = \\mL_i \\mL_i^\\top + \\eps \\mI$. This parameterization guarantees valid metrics while keeping the model tractable. Retrieval proceeds via multi-source Dijkstra on the learned geodesic distances, followed by Maximal Marginal Relevance reranking and path coherence filtering. On citation prediction benchmarks with 169K papers, \\gss{} achieves 23\\% relative improvement in Recall@20 over SPECTER+FAISS baselines while providing interpretable citation paths. Our hierarchical coarse-to-fine search with k-means pooling reduces computational cost by 4$\\times$ compared to flat geodesic search while maintaining 97\\% retrieval quality. We provide theoretical analysis of when geodesic distances outperform direct similarity, characterize the approximation quality of low-rank metrics, and validate predictions empirically. Code and trained models are available at https://github.com/YCRG-Labs/geodesic-search.", "AI": {"tldr": "GSS\u662f\u4e00\u79cd\u57fa\u4e8e\u9ece\u66fc\u5ea6\u91cf\u7684\u68c0\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b66\u4e60\u5f15\u7528\u56fe\u4e2d\u8282\u70b9\u7279\u5b9a\u7684\u5ea6\u91cf\u5f20\u91cf\uff0c\u5b9e\u73b0\u51e0\u4f55\u611f\u77e5\u7684\u8bed\u4e49\u641c\u7d22\uff0c\u76f8\u6bd4\u4f20\u7edf\u6b27\u6c0f\u8ddd\u79bb\u65b9\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u7684\u6b27\u6c0f\u8ddd\u79bb\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u8bed\u4e49\u5173\u7cfb\u3002GSS\u65e8\u5728\u901a\u8fc7\u5b66\u4e60\u8282\u70b9\u7279\u5b9a\u7684\u9ece\u66fc\u5ea6\u91cf\uff0c\u5728\u5f15\u7528\u56fe\u4e0a\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u51e0\u4f55\u611f\u77e5\u8bed\u4e49\u641c\u7d22\u3002", "method": "1. \u4e3a\u6bcf\u4e2a\u8282\u70b9\u5b66\u4e60\u4f4e\u79e9\u5ea6\u91cf\u5f20\u91cfmL_i\uff0c\u6784\u9020\u5c40\u90e8\u534a\u6b63\u5b9a\u5ea6\u91cfmG_i = mL_i mL_i^T + \u03b5I\uff1b2. \u4f7f\u7528\u591a\u6e90Dijkstra\u7b97\u6cd5\u8ba1\u7b97\u6d4b\u5730\u8ddd\u79bb\uff1b3. \u7ed3\u5408\u6700\u5927\u8fb9\u9645\u76f8\u5173\u6027\u91cd\u6392\u5e8f\u548c\u8def\u5f84\u4e00\u81f4\u6027\u8fc7\u6ee4\uff1b4. \u91c7\u7528\u5206\u5c42\u7c97\u5230\u7ec6\u641c\u7d22\u548ck-means\u6c60\u5316\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u5728\u5305\u542b16.9\u4e07\u7bc7\u8bba\u6587\u7684\u5f15\u7528\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGSS\u76f8\u6bd4SPECTER+FAISS\u57fa\u7ebf\u5728Recall@20\u4e0a\u83b7\u5f9723%\u7684\u76f8\u5bf9\u63d0\u5347\u3002\u5206\u5c42\u641c\u7d22\u5c06\u8ba1\u7b97\u6210\u672c\u964d\u4f4e4\u500d\uff0c\u540c\u65f6\u4fdd\u630197%\u7684\u68c0\u7d22\u8d28\u91cf\u3002", "conclusion": "GSS\u901a\u8fc7\u5b66\u4e60\u8282\u70b9\u7279\u5b9a\u7684\u9ece\u66fc\u5ea6\u91cf\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u51e0\u4f55\u611f\u77e5\u8bed\u4e49\u641c\u7d22\uff0c\u5728\u6027\u80fd\u63d0\u5347\u7684\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u5f15\u7528\u8def\u5f84\u3002\u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u90fd\u9a8c\u8bc1\u4e86\u6d4b\u5730\u8ddd\u79bb\u4f18\u4e8e\u76f4\u63a5\u76f8\u4f3c\u5ea6\u7684\u573a\u666f\u3002"}}
{"id": "2602.23507", "categories": ["cs.LG", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.23507", "abs": "https://arxiv.org/abs/2602.23507", "authors": ["Diana Shamsutdinova", "Felix Zimmer", "Oyebayo Ridwan Olaniran", "Sarah Markham", "Daniel Stahl", "Gordon Forbes", "Ewan Carr"], "title": "Sample Size Calculations for Developing Clinical Prediction Models: Overview and pmsims R package", "comment": "26 pages, 4 figures, 1 table, preprint", "summary": "Background: Clinical prediction models are increasingly used to inform healthcare decisions, but determining the minimum sample size for their development remains a critical and unresolved challenge. Inadequate sample sizes can lead to overfitting, poor generalisability, and biased predictions. Existing approaches, such as heuristic rules, closed-form formulas, and simulation-based methods, vary in flexibility and accuracy, particularly for complex data structures and machine learning models. Methods: We review current methodologies for sample size estimation in prediction modelling and introduce a conceptual framework that distinguishes between mean-based and assurance-based criteria. Building on this, we propose a novel simulation-based approach that integrates learning curves, Gaussian Process optimisation, and assurance principles to identify sample sizes that achieve target performance with high probability. This approach is implemented in pmsims, an open-source, model-agnostic R package. Results: Through case studies, we demonstrate that sample size estimates vary substantially across methods, performance metrics, and modelling strategies. Compared to existing tools, pmsims provides flexible, efficient, and interpretable solutions that accommodate diverse models and user-defined metrics while explicitly accounting for variability in model performance. Conclusions: Our framework and software advance sample size methodology for clinical prediction modelling by combining flexibility with computational efficiency. Future work should extend these methods to hierarchical and multimodal data, incorporate fairness and stability metrics, and address challenges such as missing data and complex dependency structures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u6837\u672c\u91cf\u4f30\u7b97\u65b9\u6cd5\uff0c\u7ed3\u5408\u5b66\u4e60\u66f2\u7ebf\u3001\u9ad8\u65af\u8fc7\u7a0b\u4f18\u5316\u548c\u4fdd\u8bc1\u539f\u5219\uff0c\u5f00\u53d1\u4e86\u5f00\u6e90\u7684R\u5305pmsims\uff0c\u4e3a\u590d\u6742\u6570\u636e\u7ed3\u6784\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u7075\u6d3b\u9ad8\u6548\u7684\u6837\u672c\u91cf\u8ba1\u7b97\u65b9\u6848\u3002", "motivation": "\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u5728\u533b\u7597\u51b3\u7b56\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u786e\u5b9a\u5176\u5f00\u53d1\u6240\u9700\u7684\u6700\u5c0f\u6837\u672c\u91cf\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u4e14\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002\u6837\u672c\u91cf\u4e0d\u8db3\u4f1a\u5bfc\u81f4\u8fc7\u62df\u5408\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u9884\u6d4b\u504f\u5dee\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u542f\u53d1\u5f0f\u89c4\u5219\u3001\u95ed\u5f0f\u516c\u5f0f\u548c\u57fa\u4e8e\u6a21\u62df\u7684\u65b9\u6cd5\uff09\u5728\u7075\u6d3b\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u590d\u6742\u6570\u636e\u7ed3\u6784\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "method": "\u4f5c\u8005\u56de\u987e\u4e86\u9884\u6d4b\u5efa\u6a21\u4e2d\u6837\u672c\u91cf\u4f30\u7b97\u7684\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u533a\u5206\u5747\u503c\u57fa\u51c6\u5219\u548c\u4fdd\u8bc1\u57fa\u51c6\u5219\u7684\u6982\u5ff5\u6846\u67b6\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u6a21\u62df\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u6574\u5408\u4e86\u5b66\u4e60\u66f2\u7ebf\u3001\u9ad8\u65af\u8fc7\u7a0b\u4f18\u5316\u548c\u4fdd\u8bc1\u539f\u5219\uff0c\u4ee5\u8bc6\u522b\u80fd\u591f\u4ee5\u9ad8\u6982\u7387\u8fbe\u5230\u76ee\u6807\u6027\u80fd\u7684\u6837\u672c\u91cf\u3002\u8be5\u65b9\u6cd5\u5728\u5f00\u6e90\u3001\u6a21\u578b\u65e0\u5173\u7684R\u5305pmsims\u4e2d\u5b9e\u73b0\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0c\u4f5c\u8005\u5c55\u793a\u4e86\u6837\u672c\u91cf\u4f30\u8ba1\u5728\u4e0d\u540c\u65b9\u6cd5\u3001\u6027\u80fd\u6307\u6807\u548c\u5efa\u6a21\u7b56\u7565\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u4e0e\u73b0\u6709\u5de5\u5177\u76f8\u6bd4\uff0cpmsims\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u9ad8\u6548\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u9002\u5e94\u591a\u6837\u5316\u7684\u6a21\u578b\u548c\u7528\u6237\u5b9a\u4e49\u7684\u6307\u6807\uff0c\u540c\u65f6\u660e\u786e\u8003\u8651\u4e86\u6a21\u578b\u6027\u80fd\u7684\u53d8\u5f02\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u8f6f\u4ef6\u901a\u8fc7\u5c06\u7075\u6d3b\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u76f8\u7ed3\u5408\uff0c\u63a8\u8fdb\u4e86\u4e34\u5e8a\u9884\u6d4b\u5efa\u6a21\u7684\u6837\u672c\u91cf\u65b9\u6cd5\u5b66\u3002\u672a\u6765\u5de5\u4f5c\u5e94\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u6269\u5c55\u5230\u5206\u5c42\u548c\u591a\u6a21\u6001\u6570\u636e\uff0c\u7eb3\u5165\u516c\u5e73\u6027\u548c\u7a33\u5b9a\u6027\u6307\u6807\uff0c\u5e76\u89e3\u51b3\u7f3a\u5931\u6570\u636e\u548c\u590d\u6742\u4f9d\u8d56\u7ed3\u6784\u7b49\u6311\u6218\u3002"}}
{"id": "2602.23671", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23671", "abs": "https://arxiv.org/abs/2602.23671", "authors": ["Yufei Ye", "Wei Guo", "Hao Wang", "Luankang Zhang", "Heng Chang", "Hong Zhu", "Yuyang Ye", "Yong Liu", "Defu Lian", "Enhong Chen"], "title": "FuXi-Linear: Unleashing the Power of Linear Attention in Long-term Time-aware Sequential Recommendation", "comment": null, "summary": "Modern recommendation systems primarily rely on attention mechanisms with quadratic complexity, which limits their ability to handle long user sequences and slows down inference. While linear attention is a promising alternative, existing research faces three critical challenges: (1) temporal signals are often overlooked or integrated via naive coupling that causes mutual interference between temporal and semantic signals while neglecting behavioral periodicity; (2) insufficient positional information provided by existing linear frameworks; and (3) a primary focus on short sequences and shallow architectures. To address these issues, we propose FuXi-Linear, a linear-complexity model designed for efficient long-sequence recommendation. Our approach introduces two key components: (1) a Temporal Retention Channel that independently computes periodic attention weights using temporal data, preventing crosstalk between temporal and semantic signals; (2) a Linear Positional Channel that integrates positional information through learnable kernels within linear complexity. Moreover, we demonstrate that FuXi-Linear exhibits a robust power-law scaling property at a thousand-length scale, a characteristic largely unexplored in prior linear recommendation studies. Extensive experiments on sequences of several thousand tokens demonstrate that FuXi-Linear outperforms state-of-the-art models in recommendation quality, while achieving up to 10$\\times$ speedup in the prefill stage and up to 21$\\times$ speedup in the decode stage compared to competitive baselines. Our code has been released in a public repository https://github.com/USTC-StarTeam/fuxi-linear.", "AI": {"tldr": "FuXi-Linear\u63d0\u51fa\u4e86\u4e00\u79cd\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u957f\u5e8f\u5217\u63a8\u8350\u6a21\u578b\uff0c\u901a\u8fc7\u72ec\u7acb\u7684\u65f6\u95f4\u4fdd\u7559\u901a\u9053\u548c\u7ebf\u6027\u4f4d\u7f6e\u901a\u9053\u89e3\u51b3\u73b0\u6709\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u5728\u65f6\u5e8f\u4fe1\u53f7\u5904\u7406\u3001\u4f4d\u7f6e\u4fe1\u606f\u4e0d\u8db3\u548c\u67b6\u6784\u6df1\u5ea6\u65b9\u9762\u7684\u9650\u5236\uff0c\u5728\u6570\u5343\u957f\u5ea6\u5e8f\u5217\u4e0a\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a8\u8350\u8d28\u91cf\u548c\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u4e8c\u6b21\u590d\u6742\u5ea6\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u9650\u5236\u4e86\u5904\u7406\u957f\u7528\u6237\u5e8f\u5217\u7684\u80fd\u529b\u5e76\u51cf\u6162\u4e86\u63a8\u7406\u901f\u5ea6\u3002\u867d\u7136\u7ebf\u6027\u6ce8\u610f\u529b\u662f\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u9762\u4e34\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u65f6\u5e8f\u4fe1\u53f7\u5e38\u88ab\u5ffd\u89c6\u6216\u901a\u8fc7\u7b80\u5355\u8026\u5408\u96c6\u6210\uff0c\u5bfc\u81f4\u65f6\u5e8f\u548c\u8bed\u4e49\u4fe1\u53f7\u76f8\u4e92\u5e72\u6270\u4e14\u5ffd\u7565\u884c\u4e3a\u5468\u671f\u6027\uff1b2) \u73b0\u6709\u7ebf\u6027\u6846\u67b6\u63d0\u4f9b\u7684\u4f4d\u7f6e\u4fe1\u606f\u4e0d\u8db3\uff1b3) \u4e3b\u8981\u5173\u6ce8\u77ed\u5e8f\u5217\u548c\u6d45\u5c42\u67b6\u6784\u3002", "method": "\u63d0\u51faFuXi-Linear\u7ebf\u6027\u590d\u6742\u5ea6\u6a21\u578b\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u65f6\u95f4\u4fdd\u7559\u901a\u9053\uff1a\u4f7f\u7528\u65f6\u5e8f\u6570\u636e\u72ec\u7acb\u8ba1\u7b97\u5468\u671f\u6027\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u9632\u6b62\u65f6\u5e8f\u548c\u8bed\u4e49\u4fe1\u53f7\u4e4b\u95f4\u7684\u4e32\u6270\uff1b2) \u7ebf\u6027\u4f4d\u7f6e\u901a\u9053\uff1a\u901a\u8fc7\u53ef\u5b66\u4e60\u6838\u5728\u7ebf\u6027\u590d\u6742\u5ea6\u5185\u96c6\u6210\u4f4d\u7f6e\u4fe1\u606f\u3002\u6a21\u578b\u5c55\u73b0\u51fa\u5728\u5343\u957f\u5ea6\u5c3a\u5ea6\u4e0a\u7684\u5f3a\u5927\u5e42\u5f8b\u7f29\u653e\u7279\u6027\u3002", "result": "\u5728\u6570\u5343\u4ee4\u724c\u957f\u5ea6\u7684\u5e8f\u5217\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0cFuXi-Linear\u5728\u63a8\u8350\u8d28\u91cf\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u540c\u65f6\u5728\u9884\u586b\u5145\u9636\u6bb5\u5b9e\u73b0\u9ad8\u8fbe10\u500d\u52a0\u901f\uff0c\u5728\u89e3\u7801\u9636\u6bb5\u5b9e\u73b0\u9ad8\u8fbe21\u500d\u52a0\u901f\uff0c\u76f8\u6bd4\u7ade\u4e89\u57fa\u7ebf\u3002", "conclusion": "FuXi-Linear\u901a\u8fc7\u72ec\u7acb\u5904\u7406\u65f6\u5e8f\u4fe1\u53f7\u548c\u589e\u5f3a\u4f4d\u7f6e\u4fe1\u606f\uff0c\u89e3\u51b3\u4e86\u7ebf\u6027\u6ce8\u610f\u529b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u957f\u5e8f\u5217\u63a8\u8350\uff0c\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u6027\u80fd\u548c\u663e\u8457\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u3002"}}
{"id": "2602.23528", "categories": ["cs.LG", "cs.CE", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.23528", "abs": "https://arxiv.org/abs/2602.23528", "authors": ["Yicen Li", "Jose Antonio Lara Benitez", "Ruiyang Hong", "Anastasis Kratsios", "Paul David McNicholas", "Maarten Valentijn de Hoop"], "title": "Neural Operators Can Discover Functional Clusters", "comment": null, "summary": "Operator learning is reshaping scientific computing by amortizing inference across infinite families of problems. While neural operators (NOs) are increasingly well understood for regression, far less is known for classification and its unsupervised analogue: clustering. We prove that sample-based neural operators can learn any finite collection of classes in an infinite-dimensional reproducing kernel Hilbert space, even when the classes are neither convex nor connected, under mild kernel sampling assumptions. Our universal clustering theorem shows that any $K$ closed classes can be approximated to arbitrary precision by NO-parameterized classes in the upper Kuratowski topology on closed sets, a notion that can be interpreted as disallowing false-positive misclassifications.\n  Building on this, we develop an NO-powered clustering pipeline for functional data and apply it to unlabeled families of ordinary differential equation (ODE) trajectories. Discretized trajectories are lifted by a fixed pre-trained encoder into a continuous feature map and mapped to soft assignments by a lightweight trainable head. Experiments on diverse synthetic ODE benchmarks show that the resulting practical SNO recovers latent dynamical structure in regimes where classical methods fail, providing evidence consistent with our universal clustering theory.", "AI": {"tldr": "\u795e\u7ecf\u7b97\u5b50\u53ef\u5b66\u4e60\u65e0\u9650\u7ef4\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u4efb\u610f\u6709\u9650\u7c7b\u522b\u7684\u805a\u7c7b\uff0c\u5373\u4f7f\u7c7b\u522b\u975e\u51f8\u975e\u8fde\u901a\uff0c\u4e3a\u51fd\u6570\u6570\u636e\u805a\u7c7b\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1", "motivation": "\u795e\u7ecf\u7b97\u5b50\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u5df2\u6709\u6df1\u5165\u7814\u7a76\uff0c\u4f46\u5728\u5206\u7c7b\u53ca\u5176\u65e0\u76d1\u7763\u5bf9\u5e94\u4efb\u52a1\u2014\u2014\u805a\u7c7b\u65b9\u9762\u7f3a\u4e4f\u7406\u8bba\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u795e\u7ecf\u7b97\u5b50\u5728\u65e0\u9650\u7ef4\u51fd\u6570\u7a7a\u95f4\u4e2d\u8fdb\u884c\u805a\u7c7b\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u5f00\u53d1\u5b9e\u7528\u7684\u51fd\u6570\u6570\u636e\u805a\u7c7b\u65b9\u6cd5", "method": "1) \u7406\u8bba\u8bc1\u660e\uff1a\u5728\u6e29\u548c\u7684\u6838\u91c7\u6837\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u57fa\u4e8e\u6837\u672c\u7684\u795e\u7ecf\u7b97\u5b50\u53ef\u4ee5\u5b66\u4e60\u65e0\u9650\u7ef4\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u4efb\u610f\u6709\u9650\u7c7b\u522b\u7684\u805a\u7c7b\uff1b2) \u5b9e\u8df5\u65b9\u6cd5\uff1a\u5f00\u53d1\u795e\u7ecf\u7b97\u5b50\u9a71\u52a8\u7684\u51fd\u6570\u6570\u636e\u805a\u7c7b\u6d41\u7a0b\uff0c\u5305\u62ec\u56fa\u5b9a\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u5c06\u79bb\u6563\u8f68\u8ff9\u63d0\u5347\u4e3a\u8fde\u7eed\u7279\u5f81\u6620\u5c04\uff0c\u8f7b\u91cf\u53ef\u8bad\u7ec3\u5934\u6620\u5c04\u5230\u8f6f\u5206\u914d", "result": "1) \u63d0\u51fa\u901a\u7528\u805a\u7c7b\u5b9a\u7406\uff1a\u4efb\u4f55K\u4e2a\u95ed\u7c7b\u90fd\u53ef\u4ee5\u5728\u95ed\u96c6\u7684\u4e0aKuratowski\u62d3\u6251\u4e2d\u88ab\u795e\u7ecf\u7b97\u5b50\u53c2\u6570\u5316\u7684\u7c7b\u4ee5\u4efb\u610f\u7cbe\u5ea6\u903c\u8fd1\uff1b2) \u5728\u5408\u6210ODE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u63d0\u51fa\u7684\u5b9e\u7528SNO\u65b9\u6cd5\u5728\u7ecf\u5178\u65b9\u6cd5\u5931\u8d25\u7684\u673a\u5236\u4e0b\u6210\u529f\u6062\u590d\u6f5c\u5728\u52a8\u6001\u7ed3\u6784", "conclusion": "\u795e\u7ecf\u7b97\u5b50\u4e0d\u4ec5\u9002\u7528\u4e8e\u56de\u5f52\u4efb\u52a1\uff0c\u4e5f\u80fd\u6709\u6548\u5904\u7406\u65e0\u9650\u7ef4\u51fd\u6570\u7a7a\u95f4\u4e2d\u7684\u805a\u7c7b\u95ee\u9898\u3002\u7406\u8bba\u8bc1\u660e\u63d0\u4f9b\u4e86\u795e\u7ecf\u7b97\u5b50\u805a\u7c7b\u7684\u6570\u5b66\u57fa\u7840\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u6062\u590d\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u6f5c\u5728\u7ed3\u6784\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e3a\u51fd\u6570\u6570\u636e\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84"}}
{"id": "2602.23717", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23717", "abs": "https://arxiv.org/abs/2602.23717", "authors": ["Hao Li", "Kedar Bellare", "Siyu Yang", "Sherry Chen", "Liwei He", "Stephanie Moyerman", "Sanjeev Katariya"], "title": "Recommending Search Filters To Improve Conversions At Airbnb", "comment": null, "summary": "Airbnb, a two-sided online marketplace connecting guests and hosts, offers a diverse and unique inventory of accommodations, experiences, and services. Search filters play an important role in helping guests navigate this variety by refining search results to align with their needs. Yet, while search filters are designed to facilitate conversions in online marketplaces, their direct impact on driving conversions remains underexplored in the existing literature.\n  This paper bridges this gap by presenting a novel application of machine learning techniques to recommend search filters aimed at improving booking conversions. We introduce a modeling framework that directly targets lower-funnel conversions (bookings) by recommending intermediate tools, i.e. search filters. Leveraging the framework, we designed and built the filter recommendation system at Airbnb from the ground up, addressing challenges like cold start and stringent serving requirements.\n  The filter recommendation system we developed has been successfully deployed at Airbnb, powering multiple user interfaces and driving incremental booking conversion lifts, as validated through online A/B testing. An ablation study further validates the effectiveness of our approach and key design choices. By focusing on conversion-oriented filter recommendations, our work ensures that search filters serve their ultimate purpose at Airbnb - helping guests find and book their ideal accommodations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u641c\u7d22\u8fc7\u6ee4\u5668\u63a8\u8350\u7cfb\u7edf\uff0c\u65e8\u5728\u63d0\u5347Airbnb\u5e73\u53f0\u7684\u9884\u8ba2\u8f6c\u5316\u7387\uff0c\u901a\u8fc7\u63a8\u8350\u4e2d\u95f4\u5de5\u5177\uff08\u641c\u7d22\u8fc7\u6ee4\u5668\uff09\u76f4\u63a5\u9488\u5bf9\u4e0b\u6e38\u8f6c\u5316\u76ee\u6807\u3002", "motivation": "Airbnb\u4f5c\u4e3a\u8fde\u63a5\u5ba2\u4eba\u548c\u623f\u4e1c\u7684\u53cc\u8fb9\u5728\u7ebf\u5e02\u573a\uff0c\u63d0\u4f9b\u591a\u6837\u5316\u7684\u4f4f\u5bbf\u3001\u4f53\u9a8c\u548c\u670d\u52a1\u5e93\u5b58\u3002\u641c\u7d22\u8fc7\u6ee4\u5668\u5728\u5e2e\u52a9\u5ba2\u4eba\u5bfc\u822a\u8fd9\u79cd\u591a\u6837\u6027\u65b9\u9762\u8d77\u7740\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u73b0\u6709\u6587\u732e\u4e2d\u5173\u4e8e\u641c\u7d22\u8fc7\u6ee4\u5668\u5bf9\u9a71\u52a8\u8f6c\u5316\u7684\u76f4\u63a5\u5f71\u54cd\u7814\u7a76\u4e0d\u8db3\u3002\u867d\u7136\u641c\u7d22\u8fc7\u6ee4\u5668\u65e8\u5728\u4fc3\u8fdb\u5728\u7ebf\u5e02\u573a\u7684\u8f6c\u5316\uff0c\u4f46\u5176\u76f4\u63a5\u8f6c\u5316\u6548\u679c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u8350\u641c\u7d22\u8fc7\u6ee4\u5668\u6765\u6539\u5584\u9884\u8ba2\u8f6c\u5316\u3002\u8be5\u6846\u67b6\u76f4\u63a5\u9488\u5bf9\u4e0b\u6e38\u8f6c\u5316\uff08\u9884\u8ba2\uff09\uff0c\u901a\u8fc7\u63a8\u8350\u4e2d\u95f4\u5de5\u5177\uff08\u641c\u7d22\u8fc7\u6ee4\u5668\uff09\u6765\u5b9e\u73b0\u3002\u6784\u5efa\u4e86Airbnb\u7684\u8fc7\u6ee4\u5668\u63a8\u8350\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u51b7\u542f\u52a8\u548c\u4e25\u683c\u670d\u52a1\u8981\u6c42\u7b49\u6311\u6218\u3002", "result": "\u5f00\u53d1\u7684\u8fc7\u6ee4\u5668\u63a8\u8350\u7cfb\u7edf\u5df2\u5728Airbnb\u6210\u529f\u90e8\u7f72\uff0c\u652f\u6301\u591a\u4e2a\u7528\u6237\u754c\u9762\uff0c\u5e76\u901a\u8fc7\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u80fd\u591f\u9a71\u52a8\u589e\u91cf\u9884\u8ba2\u8f6c\u5316\u63d0\u5347\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u548c\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u4e13\u6ce8\u4e8e\u4ee5\u8f6c\u5316\u4e3a\u5bfc\u5411\u7684\u8fc7\u6ee4\u5668\u63a8\u8350\uff0c\u786e\u4fdd\u641c\u7d22\u8fc7\u6ee4\u5668\u5728Airbnb\u4e2d\u5b9e\u73b0\u5176\u6700\u7ec8\u76ee\u7684\u2014\u2014\u5e2e\u52a9\u5ba2\u4eba\u627e\u5230\u5e76\u9884\u8ba2\u7406\u60f3\u7684\u4f4f\u5bbf\u3002\u8fd9\u9879\u5de5\u4f5c\u586b\u8865\u4e86\u641c\u7d22\u8fc7\u6ee4\u5668\u5bf9\u8f6c\u5316\u76f4\u63a5\u5f71\u54cd\u7684\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2602.23529", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23529", "abs": "https://arxiv.org/abs/2602.23529", "authors": ["Martin \u010cern\u00fd", "David Sychrovsk\u00fd", "Filip \u00daradn\u00edk", "Jakub \u010cern\u00fd"], "title": "Active Value Querying to Minimize Additive Error in Subadditive Set Function Learning", "comment": null, "summary": "Subadditive set functions play a pivotal role in computational economics (especially in combinatorial auctions), combinatorial optimization or artificial intelligence applications such as interpretable machine learning. However, specifying a set function requires assigning values to an exponentially large number of subsets in general, a task that is often resource-intensive in practice, particularly when the values derive from external sources such as retraining of machine learning models. A~simple omission of certain values introduces ambiguity that becomes even more significant when the incomplete set function has to be further optimized over. Motivated by the well-known result about inapproximability of subadditive functions using deterministic value queries with respect to a multiplicative error, we study a problem of approximating an unknown subadditive (or a subclass of thereof) set function with respect to an additive error -- i. e., we aim to efficiently close the distance between minimal and maximal completions. Our contributions are threefold: (i) a thorough exploration of minimal and maximal completions of different classes of set functions with missing values and an analysis of their resulting distance; (ii) the development of methods to minimize this distance over classes of set functions with a known prior, achieved by disclosing values of additional subsets in both offline and online manner; and (iii) empirical demonstrations of the algorithms' performance in practical scenarios.", "AI": {"tldr": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u6dfb\u52a0\u67e5\u8be2\u6765\u8fd1\u4f3c\u672a\u77e5\u6b21\u53ef\u52a0\u96c6\u51fd\u6570\uff0c\u4ee5\u6700\u5c0f\u5316\u6700\u5c0f\u548c\u6700\u5927\u8865\u5168\u4e4b\u95f4\u7684\u8ddd\u79bb", "motivation": "\u6b21\u53ef\u52a0\u96c6\u51fd\u6570\u5728\u591a\u4e2a\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u5b8c\u6574\u6307\u5b9a\u9700\u8981\u6307\u6570\u7ea7\u6570\u91cf\u7684\u503c\uff0c\u5b9e\u8df5\u4e2d\u8d44\u6e90\u6d88\u8017\u5927\u3002\u5f53\u503c\u7f3a\u5931\u65f6\uff0c\u6700\u5c0f\u548c\u6700\u5927\u8865\u5168\u4e4b\u95f4\u7684\u5dee\u8ddd\u4f1a\u5bfc\u81f4\u4f18\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u6709\u6548\u8fd1\u4f3c\u8fd9\u7c7b\u51fd\u6570", "method": "1) \u6df1\u5165\u63a2\u7d22\u4e0d\u540c\u7c7b\u522b\u96c6\u51fd\u6570\u7684\u6700\u5c0f\u548c\u6700\u5927\u8865\u5168\u53ca\u5176\u8ddd\u79bb\u5206\u6790\uff1b2) \u5f00\u53d1\u5728\u5df2\u77e5\u5148\u9a8c\u4e0b\u901a\u8fc7\u79bb\u7ebf\u6216\u5728\u7ebf\u65b9\u5f0f\u62ab\u9732\u989d\u5916\u5b50\u96c6\u503c\u6765\u6700\u5c0f\u5316\u8ddd\u79bb\u7684\u65b9\u6cd5\uff1b3) \u5728\u5b9e\u9645\u573a\u666f\u4e2d\u8fdb\u884c\u7b97\u6cd5\u6027\u80fd\u7684\u5b9e\u8bc1\u6f14\u793a", "result": "\u63d0\u51fa\u4e86\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u8fd1\u4f3c\u6b21\u53ef\u52a0\u96c6\u51fd\u6570\uff0c\u901a\u8fc7\u6709\u6548\u51cf\u5c11\u6700\u5c0f\u548c\u6700\u5927\u8865\u5168\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u5c42\u9762\u90fd\u53d6\u5f97\u4e86\u8fdb\u5c55", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u89e3\u51b3\u6b21\u53ef\u52a0\u96c6\u51fd\u6570\u8fd1\u4f3c\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u503c\u7f3a\u5931\u60c5\u51b5\u4e0b\u7684\u51fd\u6570\u8fd1\u4f3c\u548c\u4f18\u5316\u95ee\u9898"}}
{"id": "2602.23716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23716", "abs": "https://arxiv.org/abs/2602.23716", "authors": ["Jiangyuan Wang", "Kejun Xiao", "Huaipeng Zhao", "Tao Luo", "Xiaoyi Zeng"], "title": "ProductResearch: Training E-Commerce Deep Research Agents via Multi-Agent Synthetic Trajectory Distillation", "comment": null, "summary": "Large Language Model (LLM)-based agents show promise for e-commerce conversational shopping, yet existing implementations lack the interaction depth and contextual breadth required for complex product research. Meanwhile, the Deep Research paradigm, despite advancing information synthesis in web search, suffers from domain gaps when transferred to e-commerce. We propose ProductResearch, a multi-agent framework that synthesizes high-fidelity, long-horizon tool-use trajectories for training robust e-commerce shopping agents. The framework employs a User Agent to infer nuanced shopping intents from behavioral histories, and a Supervisor Agent that orchestrates iterative collaboration with a Research Agent to generate synthetic trajectories culminating in comprehensive, insightful product research reports. These trajectories are rigorously filtered and distilled through a reflective internalization process that consolidates multi-agent supervisory interactions into coherent single-role training examples, enabling effective fine-tuning of LLM agents for complex shopping inquiries. Extensive experiments show that a compact MoE model fine-tuned on our synthetic data achieves substantial improvements over its base model in response comprehensiveness, research depth, and user-perceived utility, approaching the performance of frontier proprietary deep research systems and establishing multi-agent synthetic trajectory training as an effective and scalable paradigm for enhancing LLM-based shopping assistance.", "AI": {"tldr": "\u63d0\u51fa\u4e86ProductResearch\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u9ad8\u8d28\u91cf\u5de5\u5177\u4f7f\u7528\u8f68\u8ff9\u6765\u8bad\u7ec3\u7535\u5546\u8d2d\u7269\u667a\u80fd\u4f53\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u4ea7\u54c1\u7814\u7a76\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u7535\u5546\u5bf9\u8bdd\u8d2d\u7269\u667a\u80fd\u4f53\u7f3a\u4e4f\u590d\u6742\u4ea7\u54c1\u7814\u7a76\u6240\u9700\u7684\u4ea4\u4e92\u6df1\u5ea6\u548c\u4e0a\u4e0b\u6587\u5e7f\u5ea6\uff0c\u800c\u6df1\u5ea6\u7814\u7a76\u8303\u5f0f\u5728\u8fc1\u79fb\u5230\u7535\u5546\u9886\u57df\u65f6\u5b58\u5728\u9886\u57df\u5dee\u8ddd\uff0c\u9700\u8981\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u7528\u6237\u667a\u80fd\u4f53\u4ece\u884c\u4e3a\u5386\u53f2\u63a8\u65ad\u8d2d\u7269\u610f\u56fe\uff0c\u76d1\u7763\u667a\u80fd\u4f53\u534f\u8c03\u7814\u7a76\u667a\u80fd\u4f53\u8fdb\u884c\u8fed\u4ee3\u534f\u4f5c\uff0c\u751f\u6210\u5408\u6210\u8f68\u8ff9\u5e76\u6700\u7ec8\u5f62\u6210\u4ea7\u54c1\u7814\u7a76\u62a5\u544a\u3002\u901a\u8fc7\u53cd\u601d\u5185\u5316\u8fc7\u7a0b\u5c06\u591a\u667a\u80fd\u4f53\u76d1\u7763\u4ea4\u4e92\u6574\u5408\u4e3a\u5355\u89d2\u8272\u8bad\u7ec3\u6837\u672c\u3002", "result": "\u57fa\u4e8e\u5408\u6210\u6570\u636e\u5fae\u8c03\u7684\u7d27\u51d1MoE\u6a21\u578b\u5728\u54cd\u5e94\u5168\u9762\u6027\u3001\u7814\u7a76\u6df1\u5ea6\u548c\u7528\u6237\u611f\u77e5\u6548\u7528\u65b9\u9762\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u6709\u663e\u8457\u63d0\u5347\uff0c\u63a5\u8fd1\u524d\u6cbf\u4e13\u6709\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5408\u6210\u8f68\u8ff9\u8bad\u7ec3\u662f\u589e\u5f3a\u57fa\u4e8eLLM\u7684\u8d2d\u7269\u8f85\u52a9\u7684\u6709\u6548\u4e14\u53ef\u6269\u5c55\u8303\u5f0f\uff0c\u80fd\u591f\u8bad\u7ec3\u51fa\u5904\u7406\u590d\u6742\u8d2d\u7269\u67e5\u8be2\u7684\u9c81\u68d2\u667a\u80fd\u4f53\u3002"}}
{"id": "2602.23766", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23766", "abs": "https://arxiv.org/abs/2602.23766", "authors": ["Zheng Dou", "Zhao Zhang", "Deqing Wang", "Yikun Ban", "Fuzhen Zhuang"], "title": "UniFAR: A Unified Facet-Aware Retrieval Framework for Scientific Documents", "comment": null, "summary": "Existing scientific document retrieval (SDR) methods primarily rely on document-centric representations learned from inter-document relationships for document-document (doc-doc) retrieval. However, the rise of LLMs and RAG has shifted SDR toward question-driven retrieval, where documents are retrieved in response to natural-language questions (q-doc). This change has led to systematic mismatches between document-centric models and question-driven retrieval, including (1) input granularity (long documents vs. short questions), (2) semantic focus (scientific discourse structure vs. specific question intent), and (3) training signals (citation-based similarity vs. question-oriented relevance). To this end, we propose UniFAR, a Unified Facet-Aware Retrieval framework to jointly support doc-doc and q-doc SDR within a single architecture. UniFAR reconciles granularity differences through adaptive multi-granularity aggregation, aligns document structure with question intent via learnable facet anchors, and unifies doc-doc and q-doc supervision through joint training. Experimental results show that UniFAR consistently outperforms prior methods across multiple retrieval tasks and base models, confirming its effectiveness and generality.", "AI": {"tldr": "UniFAR\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u9762\u5411\u79d1\u5b66\u6587\u6863\u68c0\u7d22\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u591a\u7c92\u5ea6\u805a\u5408\u3001\u53ef\u5b66\u4e60\u7684\u65b9\u9762\u951a\u70b9\u548c\u8054\u5408\u8bad\u7ec3\uff0c\u540c\u65f6\u652f\u6301\u6587\u6863-\u6587\u6863\u548c\u95ee\u9898-\u6587\u6863\u68c0\u7d22\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6587\u6863\u4e2d\u5fc3\u6a21\u578b\u4e0e\u95ee\u9898\u9a71\u52a8\u68c0\u7d22\u4e4b\u95f4\u7684\u7cfb\u7edf\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u79d1\u5b66\u6587\u6863\u68c0\u7d22\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u6587\u6863\u4e2d\u5fc3\u8868\u793a\uff0c\u4f46\u968f\u7740LLM\u548cRAG\u7684\u5174\u8d77\uff0c\u68c0\u7d22\u8f6c\u5411\u95ee\u9898\u9a71\u52a8\u6a21\u5f0f\uff0c\u5bfc\u81f4\u6587\u6863\u4e2d\u5fc3\u6a21\u578b\u4e0e\u95ee\u9898\u9a71\u52a8\u68c0\u7d22\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u4e0d\u5339\u914d\uff1a\u8f93\u5165\u7c92\u5ea6\uff08\u957f\u6587\u6863vs\u77ed\u95ee\u9898\uff09\u3001\u8bed\u4e49\u7126\u70b9\uff08\u79d1\u5b66\u8bba\u8ff0\u7ed3\u6784vs\u5177\u4f53\u95ee\u9898\u610f\u56fe\uff09\u548c\u8bad\u7ec3\u4fe1\u53f7\uff08\u57fa\u4e8e\u5f15\u7528\u7684\u76f8\u4f3c\u6027vs\u95ee\u9898\u5bfc\u5411\u7684\u76f8\u5173\u6027\uff09\u3002", "method": "\u63d0\u51faUniFAR\u7edf\u4e00\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u81ea\u9002\u5e94\u591a\u7c92\u5ea6\u805a\u5408\u8c03\u548c\u7c92\u5ea6\u5dee\u5f02\uff1b2\uff09\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u65b9\u9762\u951a\u70b9\u5bf9\u9f50\u6587\u6863\u7ed3\u6784\u4e0e\u95ee\u9898\u610f\u56fe\uff1b3\uff09\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u7edf\u4e00\u6587\u6863-\u6587\u6863\u548c\u95ee\u9898-\u6587\u6863\u76d1\u7763\u4fe1\u53f7\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cUniFAR\u5728\u591a\u4e2a\u68c0\u7d22\u4efb\u52a1\u548c\u57fa\u7840\u6a21\u578b\u4e0a\u4e00\u81f4\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "UniFAR\u6210\u529f\u89e3\u51b3\u4e86\u6587\u6863\u4e2d\u5fc3\u6a21\u578b\u4e0e\u95ee\u9898\u9a71\u52a8\u68c0\u7d22\u4e4b\u95f4\u7684\u7cfb\u7edf\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u540c\u65f6\u652f\u6301\u4e24\u79cd\u68c0\u7d22\u6a21\u5f0f\uff0c\u5728\u79d1\u5b66\u6587\u6863\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.23720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23720", "abs": "https://arxiv.org/abs/2602.23720", "authors": ["Sheng Cao", "Zhao Chang", "Chang Li", "Hannan Li", "Liyao Fu", "Ji Tang"], "title": "The Auton Agentic AI Framework", "comment": null, "summary": "The field of Artificial Intelligence is undergoing a transition from Generative AI -- probabilistic generation of text and images -- to Agentic AI, in which autonomous systems execute actions within external environments on behalf of users. This transition exposes a fundamental architectural mismatch: Large Language Models (LLMs) produce stochastic, unstructured outputs, whereas the backend infrastructure they must control -- databases, APIs, cloud services -- requires deterministic, schema-conformant inputs. The present paper describes the Auton Agentic AI Framework, a principled architecture for standardizing the creation, execution, and governance of autonomous agent systems. The framework is organized around a strict separation between the Cognitive Blueprint, a declarative, language-agnostic specification of agent identity and capabilities, and the Runtime Engine, the platform-specific execution substrate that instantiates and runs the agent. This separation enables cross-language portability, formal auditability, and modular tool integration via the Model Context Protocol (MCP). The paper formalizes the agent execution model as an augmented Partially Observable Markov Decision Process (POMDP) with a latent reasoning space, introduces a hierarchical memory consolidation architecture inspired by biological episodic memory systems, defines a constraint manifold formalism for safety enforcement via policy projection rather than post-hoc filtering, presents a three-level self-evolution framework spanning in-context adaptation through reinforcement learning, and describes runtime optimizations -- including parallel graph execution, speculative inference, and dynamic context pruning -- that reduce end-to-end latency for multi-step agent workflows.", "AI": {"tldr": "Auton Agentic AI Framework\uff1a\u4e00\u4e2a\u6807\u51c6\u5316\u81ea\u4e3b\u667a\u80fd\u4f53\u521b\u5efa\u3001\u6267\u884c\u548c\u6cbb\u7406\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u79bb\u8ba4\u77e5\u84dd\u56fe\u548c\u8fd0\u884c\u65f6\u5f15\u64ce\u6765\u89e3\u51b3LLM\u968f\u673a\u8f93\u51fa\u4e0e\u540e\u7aef\u7cfb\u7edf\u786e\u5b9a\u6027\u9700\u6c42\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "AI\u9886\u57df\u6b63\u4ece\u751f\u6210\u5f0fAI\u5411\u667a\u80fd\u4f53AI\u8fc7\u6e21\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u968f\u673a\u975e\u7ed3\u6784\u5316\u8f93\u51fa\u4e0e\u540e\u7aef\u57fa\u7840\u8bbe\u65bd\uff08\u6570\u636e\u5e93\u3001API\u3001\u4e91\u670d\u52a1\uff09\u6240\u9700\u7684\u786e\u5b9a\u6027\u3001\u6a21\u5f0f\u5408\u89c4\u8f93\u5165\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u67b6\u6784\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51faAuton Agentic AI\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u8ba4\u77e5\u84dd\u56fe\uff08\u58f0\u660e\u5f0f\u3001\u8bed\u8a00\u65e0\u5173\u7684\u667a\u80fd\u4f53\u8eab\u4efd\u548c\u80fd\u529b\u89c4\u8303\uff09\u4e0e\u8fd0\u884c\u65f6\u5f15\u64ce\uff08\u5e73\u53f0\u7279\u5b9a\u6267\u884c\u57fa\u677f\uff09\u7684\u4e25\u683c\u5206\u79bb\u3002\u5f15\u5165\u589e\u5f3a\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3001\u5206\u5c42\u8bb0\u5fc6\u6574\u5408\u67b6\u6784\u3001\u7ea6\u675f\u6d41\u5f62\u5f62\u5f0f\u5316\u3001\u4e09\u7ea7\u81ea\u8fdb\u5316\u6846\u67b6\u548c\u8fd0\u884c\u65f6\u4f18\u5316\u6280\u672f\u3002", "result": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u8de8\u8bed\u8a00\u53ef\u79fb\u690d\u6027\u3001\u5f62\u5f0f\u5316\u53ef\u5ba1\u8ba1\u6027\u3001\u901a\u8fc7\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u7684\u6a21\u5757\u5316\u5de5\u5177\u96c6\u6210\uff0c\u5e76\u901a\u8fc7\u5e76\u884c\u56fe\u6267\u884c\u3001\u63a8\u6d4b\u63a8\u7406\u548c\u52a8\u6001\u4e0a\u4e0b\u6587\u4fee\u526a\u7b49\u6280\u672f\u51cf\u5c11\u4e86\u591a\u6b65\u9aa4\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "conclusion": "Auton Agentic AI Framework\u4e3a\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u521b\u5efa\u3001\u6267\u884c\u548c\u6cbb\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u751f\u6210\u5f0fAI\u5411\u667a\u80fd\u4f53AI\u8fc7\u6e21\u4e2d\u7684\u6838\u5fc3\u67b6\u6784\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e3a\u6807\u51c6\u5316\u3001\u53ef\u5ba1\u8ba1\u3001\u9ad8\u6548\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.23565", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.23565", "abs": "https://arxiv.org/abs/2602.23565", "authors": ["Adhyyan Narang", "Sarah Dean", "Lillian J Ratliff", "Maryam Fazel"], "title": "Dynamics of Learning under User Choice: Overspecialization and Peer-Model Probing", "comment": null, "summary": "In many economically relevant contexts where machine learning is deployed, multiple platforms obtain data from the same pool of users, each of whom selects the platform that best serves them. Prior work in this setting focuses exclusively on the \"local\" losses of learners on the distribution of data that they observe. We find that there exist instances where learners who use existing algorithms almost surely converge to models with arbitrarily poor global performance, even when models with low full-population loss exist. This happens through a feedback-induced mechanism, which we call the overspecialization trap: as learners optimize for users who already prefer them, they become less attractive to users outside this base, which further restricts the data they observe. Inspired by the recent use of knowledge distillation in modern ML, we propose an algorithm that allows learners to \"probe\" the predictions of peer models, enabling them to learn about users who do not select them. Our analysis characterizes when probing succeeds: this procedure converges almost surely to a stationary point with bounded full-population risk when probing sources are sufficiently informative, e.g., a known market leader or a majority of peers with good global performance. We verify our findings with semi-synthetic experiments on the MovieLens, Census, and Amazon Sentiment datasets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u591a\u5e73\u53f0\u673a\u5668\u5b66\u4e60\u73af\u5883\u4e2d\u5b58\u5728\u7684\"\u8fc7\u5ea6\u4e13\u4e1a\u5316\u9677\u9631\"\u95ee\u9898\uff0c\u53d1\u73b0\u73b0\u6709\u7b97\u6cd5\u53ef\u80fd\u5bfc\u81f4\u5168\u5c40\u6027\u80fd\u6781\u5dee\u7684\u6a21\u578b\uff0c\u5373\u4f7f\u5b58\u5728\u4f4e\u5168\u4eba\u53e3\u635f\u5931\u7684\u6a21\u578b\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u63a2\u6d4b\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u5728\u591a\u5e73\u53f0\u673a\u5668\u5b66\u4e60\u90e8\u7f72\u7684\u7ecf\u6d4e\u76f8\u5173\u573a\u666f\u4e2d\uff0c\u7528\u6237\u4f1a\u9009\u62e9\u6700\u9002\u5408\u81ea\u5df1\u7684\u5e73\u53f0\uff0c\u73b0\u6709\u7814\u7a76\u53ea\u5173\u6ce8\u5b66\u4e60\u8005\u5728\u89c2\u5bdf\u5230\u7684\u6570\u636e\u5206\u5e03\u4e0a\u7684\"\u5c40\u90e8\"\u635f\u5931\u3002\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u8fd9\u6837\u7684\u60c5\u51b5\uff1a\u4f7f\u7528\u73b0\u6709\u7b97\u6cd5\u7684\u5b66\u4e60\u8005\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u5168\u5c40\u6027\u80fd\u6781\u5dee\u7684\u6a21\u578b\uff0c\u5373\u4f7f\u5b58\u5728\u4f4e\u5168\u4eba\u53e3\u635f\u5931\u7684\u6a21\u578b\u3002", "method": "\u53d7\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u4e2d\u77e5\u8bc6\u84b8\u998f\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u5141\u8bb8\u5b66\u4e60\u8005\"\u63a2\u6d4b\"\u540c\u4f34\u6a21\u578b\u7684\u9884\u6d4b\uff0c\u4f7f\u4ed6\u4eec\u80fd\u591f\u4e86\u89e3\u4e0d\u9009\u62e9\u4ed6\u4eec\u7684\u7528\u6237\u3002\u5206\u6790\u786e\u5b9a\u4e86\u63a2\u6d4b\u6210\u529f\u7684\u6761\u4ef6\uff1a\u5f53\u63a2\u6d4b\u6e90\u8db3\u591f\u4fe1\u606f\u4e30\u5bcc\u65f6\uff08\u5982\u5df2\u77e5\u7684\u5e02\u573a\u9886\u5bfc\u8005\u6216\u5927\u591a\u6570\u5177\u6709\u826f\u597d\u5168\u5c40\u6027\u80fd\u7684\u540c\u884c\uff09\uff0c\u8be5\u8fc7\u7a0b\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u5177\u6709\u6709\u754c\u5168\u4eba\u53e3\u98ce\u9669\u7684\u5e73\u7a33\u70b9\u3002", "result": "\u5728MovieLens\u3001Census\u548cAmazon Sentiment\u6570\u636e\u96c6\u4e0a\u7684\u534a\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7814\u7a76\u7ed3\u679c\uff0c\u8868\u660e\u63d0\u51fa\u7684\u63a2\u6d4b\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u907f\u514d\u8fc7\u5ea6\u4e13\u4e1a\u5316\u9677\u9631\uff0c\u6536\u655b\u5230\u5177\u6709\u826f\u597d\u5168\u5c40\u6027\u80fd\u7684\u6a21\u578b\u3002", "conclusion": "\u5728\u591a\u5e73\u53f0\u673a\u5668\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u8fc7\u5ea6\u4e13\u4e1a\u5316\u9677\u9631\u662f\u4e00\u4e2a\u4e25\u91cd\u95ee\u9898\uff0c\u4f1a\u5bfc\u81f4\u5168\u5c40\u6027\u80fd\u6076\u5316\u3002\u901a\u8fc7\u63a2\u6d4b\u540c\u4f34\u6a21\u578b\u7684\u9884\u6d4b\uff0c\u5b66\u4e60\u8005\u53ef\u4ee5\u4e86\u89e3\u4e0d\u9009\u62e9\u4ed6\u4eec\u7684\u7528\u6237\uff0c\u4ece\u800c\u907f\u514d\u8fd9\u4e00\u9677\u9631\u3002\u5f53\u63a2\u6d4b\u6e90\u8db3\u591f\u4fe1\u606f\u4e30\u5bcc\u65f6\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6536\u655b\u5230\u5177\u6709\u6709\u754c\u5168\u4eba\u53e3\u98ce\u9669\u7684\u5e73\u7a33\u70b9\u3002"}}
{"id": "2602.23964", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23964", "abs": "https://arxiv.org/abs/2602.23964", "authors": ["Zhiguo Chen", "Guohao Sun", "Yiming Qiu", "Xingzhi Yao", "Mingming Li", "Huimu Wang", "Yangqi Zhang", "Songlin Wang", "Sulong Xu"], "title": "RAD-DPO: Robust Adaptive Denoising Direct Preference Optimization for Generative Retrieval in E-commerce", "comment": null, "summary": "Generative Retrieval (GR) has emerged as a powerful paradigm in e-commerce search, retrieving items via autoregressive decoding of Semantic IDs (SIDs). However, aligning GR with complex user preferences remains challenging. While Direct Preference Optimization (DPO) offers an efficient alignment solution, its direct application to structured SIDs suffers from three limitations: (i) it penalizes shared hierarchical prefixes, causing gradient conflicts; (ii) it is vulnerable to noisy pseudo-negatives from implicit feedback; and (iii) in multi-label queries with multiple relevant items, it exacerbates a probability \"squeezing effect\" among valid candidates. To address these issues, we propose RAD-DPO, which introduces token-level gradient detachment to protect prefix structures, similarity-based dynamic reward weighting to mitigate label noise, and a multi-label global contrastive objective integrated with global SFT loss to explicitly expand positive coverage. Extensive offline experiments and online A/B testing on a large-scale e-commerce platform demonstrate significant improvements in ranking quality and training efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRAD-DPO\u65b9\u6cd5\uff0c\u89e3\u51b3\u751f\u6210\u5f0f\u68c0\u7d22\u4e2d\u76f4\u63a5\u504f\u597d\u4f18\u5316\u5bf9\u7ed3\u6784\u5316\u8bed\u4e49ID\u7684\u4e09\u4e2a\u9650\u5236\uff1a\u4fdd\u62a4\u5171\u4eab\u5c42\u6b21\u524d\u7f00\u3001\u51cf\u8f7b\u6807\u7b7e\u566a\u58f0\u3001\u7f13\u89e3\u591a\u6807\u7b7e\u67e5\u8be2\u4e2d\u7684\u6982\u7387\u6324\u538b\u6548\u5e94\u3002", "motivation": "\u751f\u6210\u5f0f\u68c0\u7d22\u5728\u7535\u5546\u641c\u7d22\u4e2d\u901a\u8fc7\u81ea\u56de\u5f52\u89e3\u7801\u8bed\u4e49ID\u6765\u68c0\u7d22\u5546\u54c1\uff0c\u4f46\u5c06\u5176\u4e0e\u590d\u6742\u7528\u6237\u504f\u597d\u5bf9\u9f50\u4ecd\u5177\u6311\u6218\u3002\u76f4\u63a5\u504f\u597d\u4f18\u5316\u5e94\u7528\u4e8e\u7ed3\u6784\u5316\u8bed\u4e49ID\u5b58\u5728\u4e09\u4e2a\u95ee\u9898\uff1a\u60e9\u7f5a\u5171\u4eab\u5c42\u6b21\u524d\u7f00\u5bfc\u81f4\u68af\u5ea6\u51b2\u7a81\u3001\u6613\u53d7\u9690\u5f0f\u53cd\u9988\u4e2d\u566a\u58f0\u4f2a\u8d1f\u4f8b\u5f71\u54cd\u3001\u591a\u6807\u7b7e\u67e5\u8be2\u4e2d\u52a0\u5267\u6709\u6548\u5019\u9009\u95f4\u7684\u6982\u7387\"\u6324\u538b\u6548\u5e94\"\u3002", "method": "\u63d0\u51faRAD-DPO\u65b9\u6cd5\uff1a1) \u5f15\u5165token\u7ea7\u68af\u5ea6\u5206\u79bb\u4fdd\u62a4\u524d\u7f00\u7ed3\u6784\uff1b2) \u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u52a8\u6001\u5956\u52b1\u52a0\u6743\u51cf\u8f7b\u6807\u7b7e\u566a\u58f0\uff1b3) \u96c6\u6210\u5168\u5c40SFT\u635f\u5931\u7684\u591a\u6807\u7b7e\u5168\u5c40\u5bf9\u6bd4\u76ee\u6807\uff0c\u663e\u5f0f\u6269\u5c55\u6b63\u4f8b\u8986\u76d6\u3002", "result": "\u5728\u5927\u89c4\u6a21\u7535\u5546\u5e73\u53f0\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6392\u5e8f\u8d28\u91cf\u548c\u8bad\u7ec3\u6548\u7387\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "RAD-DPO\u6709\u6548\u89e3\u51b3\u4e86DPO\u5728\u751f\u6210\u5f0f\u68c0\u7d22\u4e2d\u5bf9\u7ed3\u6784\u5316\u8bed\u4e49ID\u7684\u4e09\u4e2a\u5173\u952e\u9650\u5236\uff0c\u63d0\u5347\u4e86\u7535\u5546\u641c\u7d22\u4e2d\u7684\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2602.23777", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23777", "abs": "https://arxiv.org/abs/2602.23777", "authors": ["Zhipeng Xu", "Zilong Wang", "Xinyang Jiang", "Dongsheng Li", "De Cheng", "Nannan Wang"], "title": "Reasoning-Driven Multimodal LLM for Domain Generalization", "comment": "Accepted at ICLR 2026 (Poster)", "summary": "This paper addresses the domain generalization (DG) problem in deep learning. While most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift. To this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains. Our analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative). To address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling. Experiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraInc) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faRD-MLDG\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u9886\u57df\u6cdb\u5316\u6027\u80fd\uff0c\u901a\u8fc7\u63a8\u7406\u94fe\u6784\u5efa\u548c\u81ea\u5bf9\u9f50\u6b63\u5219\u5316\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u89c6\u89c9\u7279\u5f81\u4e0d\u53d8\u6027\u4e0a\u7684\u5c40\u9650\u3002", "motivation": "\u5f53\u524d\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9\u7279\u5f81\u4e0d\u53d8\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u901a\u8fc7\u6784\u5efa\u63a8\u7406\u94fe\u6765\u83b7\u5f97\u66f4\u9c81\u68d2\u7684\u8de8\u9886\u57df\u9884\u6d4b\uff0c\u89e3\u51b3\u9886\u57df\u504f\u79fb\u95ee\u9898\u3002", "method": "\u63d0\u51faRD-MLDG\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) MTCT\uff08\u591a\u4efb\u52a1\u4ea4\u53c9\u8bad\u7ec3\uff09\uff0c\u5f15\u5165\u76f4\u63a5\u5206\u7c7b\u8def\u5f84\u6765\u6307\u5bfc\u63a8\u7406\u76d1\u7763\uff1b2) SARR\uff08\u81ea\u5bf9\u9f50\u63a8\u7406\u6b63\u5219\u5316\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u6807\u6ce8\u4fdd\u6301\u63a8\u7406\u94fe\u7684\u8bed\u4e49\u4e30\u5bcc\u6027\u5e76\u7f13\u89e3\u63a8\u7406\u6a21\u5f0f\u4e0d\u5339\u914d\u95ee\u9898\u3002", "result": "\u5728\u6807\u51c6DomainBed\u6570\u636e\u96c6\uff08PACS\u3001VLCS\u3001OfficeHome\u3001TerraInc\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRD-MLDG\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u63a8\u7406\u4f5c\u4e3a\u9c81\u68d2\u8de8\u9886\u57df\u6cdb\u5316\u8865\u5145\u4fe1\u53f7\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63a8\u7406\u662f\u63d0\u5347\u9886\u57df\u6cdb\u5316\u6027\u80fd\u7684\u6709\u524d\u666f\u7684\u8865\u5145\u4fe1\u53f7\uff0cRD-MLDG\u6846\u67b6\u901a\u8fc7\u6709\u6548\u6574\u5408\u63a8\u7406\u94fe\u76d1\u7763\u548c\u81ea\u5bf9\u9f50\u6b63\u5219\u5316\uff0c\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.23978", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23978", "abs": "https://arxiv.org/abs/2602.23978", "authors": ["Huimu Wang", "Xingzhi Yao", "Yiming Qiu", "Qinghong Zhang", "Haotian Wang", "Yufan Cui", "Songlin Wang", "Sulong Xu", "Mingming Li"], "title": "Towards Efficient and Generalizable Retrieval: Adaptive Semantic Quantization and Residual Knowledge Transfer", "comment": null, "summary": "While semantic ID-based generative retrieval enables efficient end-to-end modeling in industrial applications, these methods face a persistent trade-off: head items are susceptible to ID collisions that negatively impact downstream tasks, whereas data-sparse tail items, including cold-start items, exhibit limited generalization. To address this issue, we propose the Anchored Curriculum with Sequential Adaptive Quantization (SA^2CRQ) framework. The framework introduces Sequential Adaptive Residual Quantization (SARQ) to dynamically allocate code lengths based on item path entropy, assigning longer, discriminative IDs to head items and shorter, generalizable IDs to tail items. To mitigate data sparsity, the Anchored Curriculum Residual Quantization (ACRQ) component utilizes a frozen semantic manifold learned from head items to regularize and accelerate the representation learning of tail items. Experimental results from a large-scale industrial search system and multiple public datasets indicate that SA^2CRQ yields consistent improvements over existing baselines, particularly in cold-start retrieval scenarios.", "AI": {"tldr": "SA^2CRQ\u6846\u67b6\u901a\u8fc7\u5e8f\u5217\u81ea\u9002\u5e94\u6b8b\u5dee\u91cf\u5316\u52a8\u6001\u5206\u914d\u7f16\u7801\u957f\u5ea6\uff0c\u4e3a\u5934\u90e8\u9879\u76ee\u5206\u914d\u957fID\u907f\u514d\u78b0\u649e\uff0c\u4e3a\u5c3e\u90e8\u9879\u76ee\u5206\u914d\u77edID\u63d0\u5347\u6cdb\u5316\uff0c\u5e76\u4f7f\u7528\u951a\u5b9a\u8bfe\u7a0b\u6b8b\u5dee\u91cf\u5316\u7f13\u89e3\u6570\u636e\u7a00\u758f\u95ee\u9898\u3002", "motivation": "\u8bed\u4e49ID\u751f\u6210\u68c0\u7d22\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u9762\u4e34\u6743\u8861\uff1a\u5934\u90e8\u9879\u76ee\u6613\u53d7ID\u78b0\u649e\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\uff0c\u800c\u6570\u636e\u7a00\u758f\u7684\u5c3e\u90e8\u9879\u76ee\uff08\u5305\u62ec\u51b7\u542f\u52a8\u9879\u76ee\uff09\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "method": "\u63d0\u51faSA^2CRQ\u6846\u67b6\uff0c\u5305\u542bSARQ\uff08\u57fa\u4e8e\u9879\u76ee\u8def\u5f84\u71b5\u52a8\u6001\u5206\u914d\u7f16\u7801\u957f\u5ea6\uff09\u548cACRQ\uff08\u5229\u7528\u5934\u90e8\u9879\u76ee\u5b66\u4e60\u7684\u51bb\u7ed3\u8bed\u4e49\u6d41\u5f62\u6b63\u5219\u5316\u5c3e\u90e8\u9879\u76ee\u8868\u793a\u5b66\u4e60\uff09\u3002", "result": "\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u641c\u7d22\u7cfb\u7edf\u548c\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSA^2CRQ\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u51b7\u542f\u52a8\u68c0\u7d22\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "SA^2CRQ\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8bed\u4e49ID\u751f\u6210\u68c0\u7d22\u4e2d\u7684\u5934\u90e8-\u5c3e\u90e8\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7f16\u7801\u957f\u5ea6\u5206\u914d\u548c\u8bfe\u7a0b\u5b66\u4e60\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u3002"}}
{"id": "2602.23802", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23802", "abs": "https://arxiv.org/abs/2602.23802", "authors": ["Yiyang Fang", "Wenke Huang", "Pei Fu", "Yihao Yang", "Kehua Su", "Zhenbo Luo", "Jian Luan", "Mang Ye"], "title": "EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models", "comment": "Accepted by CVPR 2026", "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual reasoning and understanding tasks but still struggle to capture the complexity and subjectivity of human emotions. Existing approaches based on supervised fine-tuning often suffer from limited generalization and poor interpretability, while reinforcement learning methods such as Group Relative Policy Optimization fail to align with the intrinsic characteristics of emotional cognition. To address these challenges, we propose Reflective Reinforcement Learning for Emotional Reasoning (EMO-R3), a framework designed to enhance the emotional reasoning ability of MLLMs. Specifically, we introduce Structured Emotional Thinking to guide the model to perform step-by-step emotional reasoning in a structured and interpretable manner, and design a Reflective Emotional Reward that enables the model to re-evaluate its reasoning based on visual-text consistency and emotional coherence. Extensive experiments demonstrate that EMO-R3 significantly improves both the interpretability and emotional intelligence of MLLMs, achieving superior performance across multiple visual emotional understanding benchmarks.", "AI": {"tldr": "\u63d0\u51faEMO-R3\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u60c5\u611f\u601d\u7ef4\u548c\u53cd\u601d\u5f0f\u60c5\u611f\u5956\u52b1\u589e\u5f3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709MLLMs\u5728\u60c5\u611f\u7406\u89e3\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff1a\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u6709\u9650\u4e14\u53ef\u89e3\u91ca\u6027\u5dee\uff0c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5982GRPO\u65e0\u6cd5\u4e0e\u60c5\u611f\u8ba4\u77e5\u7684\u5185\u5728\u7279\u6027\u5bf9\u9f50", "method": "\u63d0\u51faEMO-R3\u6846\u67b6\uff0c\u5305\u542b\u7ed3\u6784\u5316\u60c5\u611f\u601d\u7ef4\uff08\u5f15\u5bfc\u6a21\u578b\u8fdb\u884c\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u7684\u9010\u6b65\u60c5\u611f\u63a8\u7406\uff09\u548c\u53cd\u601d\u5f0f\u60c5\u611f\u5956\u52b1\uff08\u57fa\u4e8e\u89c6\u89c9-\u6587\u672c\u4e00\u81f4\u6027\u548c\u60c5\u611f\u8fde\u8d2f\u6027\u91cd\u65b0\u8bc4\u4f30\u63a8\u7406\uff09", "result": "EMO-R3\u663e\u8457\u63d0\u5347\u4e86MLLMs\u7684\u53ef\u89e3\u91ca\u6027\u548c\u60c5\u611f\u667a\u80fd\uff0c\u5728\u591a\u4e2a\u89c6\u89c9\u60c5\u611f\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd", "conclusion": "EMO-R3\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86MLLMs\u5728\u60c5\u611f\u63a8\u7406\u65b9\u9762\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u548c\u53cd\u601d\u673a\u5236\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u60c5\u611f\u7406\u89e3\u80fd\u529b"}}
{"id": "2602.23982", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23982", "abs": "https://arxiv.org/abs/2602.23982", "authors": ["Minh Hieu Nguyen"], "title": "Robust Aggregation for Federated Sequential Recommendation with Sparse and Poisoned Data", "comment": null, "summary": "Federated sequential recommendation distributes model training across user devices so that behavioural data remains local, reducing privacy risks. Yet, this setting introduces two intertwined difficulties. On the one hand, individual clients typically contribute only short and highly sparse interaction sequences, limiting the reliability of learned user representations. On the other hand, the federated optimisation process is vulnerable to malicious or corrupted client updates, where poisoned gradients can significantly distort the global model. These challenges are particularly severe in sequential recommendation, where temporal dynamics further complicate signal aggregation. To address this problem, we propose a robust aggregation framework tailored for federated sequential recommendation under sparse and adversarial conditions. Instead of relying on standard averaging, our method introduces a defence-aware aggregation mechanism that identifies and down-weights unreliable client updates while preserving informative signals from sparse but benign participants. The framework incorporates representation-level constraints to stabilise user and item embeddings, preventing poisoned or anomalous contributions from dominating the global parameter space. In addition, we integrate sequence-aware regularisation to maintain temporal coherence in user modelling despite limited local observations.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u8054\u90a6\u5e8f\u5217\u63a8\u8350\u7684\u9c81\u68d2\u805a\u5408\u6846\u67b6\uff0c\u89e3\u51b3\u7a00\u758f\u4ea4\u4e92\u5e8f\u5217\u548c\u6076\u610f\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u53cc\u91cd\u6311\u6218", "motivation": "\u8054\u90a6\u5e8f\u5217\u63a8\u8350\u4e2d\uff0c\u5355\u4e2a\u5ba2\u6237\u7aef\u901a\u5e38\u53ea\u63d0\u4f9b\u77ed\u800c\u7a00\u758f\u7684\u4ea4\u4e92\u5e8f\u5217\uff0c\u9650\u5236\u4e86\u7528\u6237\u8868\u793a\u7684\u53ef\u9760\u6027\uff1b\u540c\u65f6\u8054\u90a6\u4f18\u5316\u8fc7\u7a0b\u5bb9\u6613\u53d7\u5230\u6076\u610f\u6216\u635f\u574f\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u653b\u51fb\uff0c\u6bd2\u5316\u68af\u5ea6\u4f1a\u663e\u8457\u626d\u66f2\u5168\u5c40\u6a21\u578b", "method": "\u63d0\u51fa\u9632\u5fa1\u611f\u77e5\u7684\u805a\u5408\u673a\u5236\uff0c\u8bc6\u522b\u5e76\u964d\u4f4e\u4e0d\u53ef\u9760\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u6743\u91cd\uff0c\u540c\u65f6\u4fdd\u7559\u7a00\u758f\u4f46\u826f\u6027\u53c2\u4e0e\u8005\u7684\u4fe1\u606f\u4fe1\u53f7\uff1b\u5305\u542b\u8868\u793a\u7ea7\u7ea6\u675f\u4ee5\u7a33\u5b9a\u7528\u6237\u548c\u7269\u54c1\u5d4c\u5165\uff1b\u96c6\u6210\u5e8f\u5217\u611f\u77e5\u6b63\u5219\u5316\u4ee5\u4fdd\u6301\u7528\u6237\u5efa\u6a21\u7684\u65f6\u95f4\u8fde\u8d2f\u6027", "result": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c", "conclusion": "\u8be5\u6846\u67b6\u4e13\u95e8\u9488\u5bf9\u7a00\u758f\u548c\u5bf9\u6297\u6761\u4ef6\u4e0b\u7684\u8054\u90a6\u5e8f\u5217\u63a8\u8350\u8bbe\u8ba1\uff0c\u901a\u8fc7\u9c81\u68d2\u805a\u5408\u673a\u5236\u89e3\u51b3\u6570\u636e\u7a00\u758f\u6027\u548c\u5b89\u5168\u6027\u7684\u53cc\u91cd\u6311\u6218"}}
{"id": "2602.23581", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23581", "abs": "https://arxiv.org/abs/2602.23581", "authors": ["Xiang Ao"], "title": "SDMixer: Sparse Dual-Mixer for Time Series Forecasting", "comment": "12pages,2 figures", "summary": "Multivariate time series forecasting is widely applied in fields such as transportation, energy, and finance. However, the data commonly suffers from issues of multi-scale characteristics, weak correlations, and noise interference, which limit the predictive performance of existing models. This paper proposes a dual-stream sparse Mixer prediction framework that extracts global trends and local dynamic features from sequences in both the frequency and time domains, respectively. It employs a sparsity mechanism to filter out invalid information, thereby enhancing the accuracy of cross-variable dependency modeling. Experimental results demonstrate that this method achieves leading performance on multiple real-world scenario datasets, validating its effectiveness and generality. The code is available at https://github.com/SDMixer/SDMixer", "AI": {"tldr": "\u63d0\u51fa\u53cc\u6d41\u7a00\u758fMixer\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u9891\u57df\u548c\u65f6\u57df\u5206\u522b\u63d0\u53d6\u5168\u5c40\u8d8b\u52bf\u548c\u5c40\u90e8\u52a8\u6001\u7279\u5f81\uff0c\u4f7f\u7528\u7a00\u758f\u673a\u5236\u8fc7\u6ee4\u65e0\u6548\u4fe1\u606f\uff0c\u63d0\u5347\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd", "motivation": "\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728\u4ea4\u901a\u3001\u80fd\u6e90\u3001\u91d1\u878d\u7b49\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u6570\u636e\u5e38\u5b58\u5728\u591a\u5c3a\u5ea6\u7279\u5f81\u3001\u5f31\u76f8\u5173\u6027\u548c\u566a\u58f0\u5e72\u6270\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u73b0\u6709\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd", "method": "\u63d0\u51fa\u53cc\u6d41\u7a00\u758fMixer\u9884\u6d4b\u6846\u67b6\uff0c\u5728\u9891\u57df\u548c\u65f6\u57df\u5206\u522b\u63d0\u53d6\u5168\u5c40\u8d8b\u52bf\u548c\u5c40\u90e8\u52a8\u6001\u7279\u5f81\uff0c\u91c7\u7528\u7a00\u758f\u673a\u5236\u8fc7\u6ee4\u65e0\u6548\u4fe1\u606f\uff0c\u589e\u5f3a\u8de8\u53d8\u91cf\u4f9d\u8d56\u5efa\u6a21\u7684\u51c6\u786e\u6027", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u771f\u5b9e\u573a\u666f\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9886\u5148\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u901a\u7528\u6027", "conclusion": "\u63d0\u51fa\u7684\u53cc\u6d41\u7a00\u758fMixer\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u3001\u5f31\u76f8\u5173\u6027\u548c\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2602.24067", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.24067", "abs": "https://arxiv.org/abs/2602.24067", "authors": ["Thom Vaughan", "Pedro Ortiz Suarez"], "title": "Colour Contrast on the Web: A WCAG 2.1 Level AA Compliance Audit of Common Crawl's Top 500 Domains", "comment": "8 pages, 4 tables. Companion website and reproducible analysis code available at https://thunderpoot.github.io/wcag-audit/ and https://github.com/thunderpoot/wcag-audit", "summary": "We present a large-scale automated audit of WCAG 2.1/2.2 Level AA colour contrast compliance across the 500 most frequently crawled registered domains in Common Crawl's CC-MAIN-2026-08 February 2026 crawl archive. Rather than conducting a live crawl, all page content was sourced from Common Crawl's open WARC archives, ensuring reproducibility and eliminating any load on target web servers. Our static CSS analysis of 240 homepages identified 4,327 unique foreground/background colour pairings, of which 1,771 (40.9%) failed to meet the 4.5:1 contrast ratio threshold for normal text. The median per-site pass rate was 62.7%, with 20.4% of sites achieving full compliance across all detected colour pairings. These findings suggest that colour contrast remains a widespread accessibility barrier on the most prominent websites, with significant variation across domain categories.", "AI": {"tldr": "\u5bf9500\u4e2a\u6700\u5e38\u8bbf\u95ee\u7f51\u7ad9\u8fdb\u884cWCAG\u989c\u8272\u5bf9\u6bd4\u5ea6\u5408\u89c4\u6027\u5927\u89c4\u6a21\u5ba1\u8ba1\uff0c\u53d1\u73b040.9%\u7684\u989c\u8272\u914d\u5bf9\u672a\u8fbe\u52304.5:1\u5bf9\u6bd4\u5ea6\u6807\u51c6\uff0c\u4ec520.4%\u7f51\u7ad9\u5b8c\u5168\u5408\u89c4", "motivation": "\u7814\u7a76\u7f51\u9875\u53ef\u8bbf\u95ee\u6027\u4e2d\u7684\u989c\u8272\u5bf9\u6bd4\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u5ba1\u8ba1\u8bc4\u4f30\u4e3b\u6d41\u7f51\u7ad9\u7684WCAG 2.1/2.2 Level AA\u5408\u89c4\u6027\u73b0\u72b6", "method": "\u4f7f\u7528Common Crawl\u7684WARC\u5b58\u6863\u6570\u636e\uff0c\u5bf9500\u4e2a\u6700\u5e38\u8bbf\u95ee\u7f51\u7ad9\u7684240\u4e2a\u4e3b\u9875\u8fdb\u884c\u9759\u6001CSS\u5206\u6790\uff0c\u8bc6\u522b\u524d\u666f/\u80cc\u666f\u989c\u8272\u914d\u5bf9\u5e76\u8bc4\u4f30\u662f\u5426\u7b26\u54084.5:1\u5bf9\u6bd4\u5ea6\u9608\u503c", "result": "\u5171\u8bc6\u522b4,327\u4e2a\u72ec\u7279\u989c\u8272\u914d\u5bf9\uff0c\u5176\u4e2d1,771\u4e2a\uff0840.9%\uff09\u672a\u8fbe\u5230\u5bf9\u6bd4\u5ea6\u6807\u51c6\uff1b\u7f51\u7ad9\u5e73\u5747\u901a\u8fc7\u7387\u4e3a62.7%\uff0c\u4ec520.4%\u7f51\u7ad9\u5b8c\u5168\u5408\u89c4\uff1b\u4e0d\u540c\u57df\u540d\u7c7b\u522b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02", "conclusion": "\u989c\u8272\u5bf9\u6bd4\u5ea6\u4ecd\u7136\u662f\u4e3b\u6d41\u7f51\u7ad9\u4e2d\u666e\u904d\u5b58\u5728\u7684\u53ef\u8bbf\u95ee\u6027\u969c\u788d\uff0c\u9700\u8981\u66f4\u591a\u5173\u6ce8\u548c\u6539\u8fdb\u4ee5\u786e\u4fdd\u89c6\u89c9\u969c\u788d\u7528\u6237\u80fd\u591f\u5e73\u7b49\u8bbf\u95ee\u7f51\u9875\u5185\u5bb9"}}
{"id": "2602.24125", "categories": ["cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.24125", "abs": "https://arxiv.org/abs/2602.24125", "authors": ["Rohit Chivukula", "T. Jaya Lakshmi", "Hemlata Sharma", "C. H. S. N. P. Sairam Rallabandi"], "title": "Recommendation Algorithms: A Comparative Study in Movie Domain", "comment": null, "summary": "Intelligent recommendation systems have clearly increased the revenue of well-known e-commerce firms. Users receive product recommendations from recommendation systems. Cinematic recommendations are made to users by a movie recommendation system. There have been numerous approaches to the problem of recommendation in the literature. It is viewed as a regression task in this research. A regression model was built using novel properties extracted from the dataset and used as features in the model. For experimentation, the Netflix challenge dataset has been used. Video streaming service Netflix is a popular choice for many. Customers' prior viewing habits are taken into account when Netflix makes movie recommendations to them. An exploratory data analysis on the Netflix dataset was conducted to gain insights into user rating behaviour and movie characteristics. Various kinds of features, including aggregating, Matrix Factorization (MF) based, and user and movie similarity based, have been extracted in the subsequent stages. In addition to a feature in the XGBoost regression algorithm, the K-Nearest Neighbors and MF algorithms from Python's Surprise library are used for recommendations. Based on Root Mean Square Error (RMSE), MF-based algorithms have provided the best recommendations.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u7535\u5f71\u63a8\u8350\u89c6\u4e3a\u56de\u5f52\u4efb\u52a1\uff0c\u4f7f\u7528Netflix\u6570\u636e\u96c6\u63d0\u53d6\u65b0\u9896\u7279\u5f81\uff0c\u7ed3\u5408XGBoost\u3001KNN\u548c\u77e9\u9635\u5206\u89e3\u7b97\u6cd5\uff0c\u53d1\u73b0\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u65b9\u6cd5\u5728RMSE\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u667a\u80fd\u63a8\u8350\u7cfb\u7edf\u80fd\u663e\u8457\u63d0\u5347\u7535\u5546\u5e73\u53f0\u6536\u5165\uff0c\u7535\u5f71\u63a8\u8350\u7cfb\u7edf\u9700\u8981\u66f4\u51c6\u786e\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u7528\u6237\u8bc4\u5206\u3002\u73b0\u6709\u63a8\u8350\u65b9\u6cd5\u4f17\u591a\uff0c\u4f46\u5c06\u63a8\u8350\u89c6\u4e3a\u56de\u5f52\u4efb\u52a1\u5e76\u63d0\u53d6\u65b0\u9896\u7279\u5f81\u7684\u65b9\u6cd5\u503c\u5f97\u63a2\u7d22\u3002", "method": "1. \u5bf9Netflix\u6570\u636e\u96c6\u8fdb\u884c\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\uff1b2. \u63d0\u53d6\u805a\u5408\u7279\u5f81\u3001\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u7279\u5f81\u3001\u7528\u6237\u548c\u7535\u5f71\u76f8\u4f3c\u5ea6\u7279\u5f81\uff1b3. \u4f7f\u7528XGBoost\u56de\u5f52\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408Surprise\u5e93\u4e2d\u7684KNN\u548c\u77e9\u9635\u5206\u89e3\u7b97\u6cd5\u8fdb\u884c\u63a8\u8350\u3002", "result": "\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u7b97\u6cd5\u5728\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09\u6307\u6807\u4e0a\u63d0\u4f9b\u4e86\u6700\u4f73\u63a8\u8350\u6548\u679c\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u7528\u6237\u8bc4\u5206\u65b9\u9762\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "\u5c06\u63a8\u8350\u89c6\u4e3a\u56de\u5f52\u4efb\u52a1\u5e76\u63d0\u53d6\u591a\u79cd\u7279\u5f81\u7684\u65b9\u6cd5\u662f\u6709\u6548\u7684\uff0c\u77e9\u9635\u5206\u89e3\u7b97\u6cd5\u5728\u7535\u5f71\u63a8\u8350\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6700\u4f73\u6027\u80fd\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2602.23614", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23614", "abs": "https://arxiv.org/abs/2602.23614", "authors": ["Kejing Yin", "Haizhou Xu", "Wenfang Yao", "Chen Liu", "Zijie Chen", "Yui Haang Cheung", "William K. Cheung", "Jing Qin"], "title": "When Does Multimodal Learning Help in Healthcare? A Benchmark on EHR and Chest X-Ray Fusion", "comment": null, "summary": "Machine learning holds promise for advancing clinical decision support, yet it remains unclear when multimodal learning truly helps in practice, particularly under modality missingness and fairness constraints. In this work, we conduct a systematic benchmark of multimodal fusion between Electronic Health Records (EHR) and chest X-rays (CXR) on standardized cohorts from MIMIC-IV and MIMIC-CXR, aiming to answer four fundamental questions: when multimodal fusion improves clinical prediction, how different fusion strategies compare, how robust existing methods are to missing modalities, and whether multimodal models achieve algorithmic fairness. Our study reveals several key insights. Multimodal fusion improves performance when modalities are complete, with gains concentrating in diseases that require complementary information from both EHR and CXR. While cross-modal learning mechanisms capture clinically meaningful dependencies beyond simple concatenation, the rich temporal structure of EHR introduces strong modality imbalance that architectural complexity alone cannot overcome. Under realistic missingness, multimodal benefits rapidly degrade unless models are explicitly designed to handle incomplete inputs. Moreover, multimodal fusion does not inherently improve fairness, with subgroup disparities mainly arising from unequal sensitivity across demographic groups. To support reproducible and extensible evaluation, we further release a flexible benchmarking toolkit that enables plug-and-play integration of new models and datasets. Together, this work provides actionable guidance on when multimodal learning helps, when it fails, and why, laying the foundation for developing clinically deployable multimodal systems that are both effective and reliable. The open-source toolkit can be found at https://github.com/jakeykj/CareBench.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u548c\u80f8\u90e8X\u5149\uff08CXR\uff09\u7684\u591a\u6a21\u6001\u878d\u5408\u5728\u4e34\u5e8a\u9884\u6d4b\u4e2d\u7684\u6548\u679c\uff0c\u63a2\u8ba8\u4e86\u878d\u5408\u65f6\u673a\u3001\u7b56\u7565\u6bd4\u8f83\u3001\u6a21\u6001\u7f3a\u5931\u9c81\u68d2\u6027\u548c\u7b97\u6cd5\u516c\u5e73\u6027\u56db\u4e2a\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u591a\u6a21\u6001\u5b66\u4e60\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff08\u7279\u522b\u662f\u5728\u6a21\u6001\u7f3a\u5931\u548c\u516c\u5e73\u6027\u7ea6\u675f\u4e0b\uff09\u4f55\u65f6\u771f\u6b63\u6709\u6548\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e3a\u5f00\u53d1\u4e34\u5e8a\u53ef\u90e8\u7f72\u7684\u591a\u6a21\u6001\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002", "method": "\u4f7f\u7528MIMIC-IV\u548cMIMIC-CXR\u6807\u51c6\u5316\u961f\u5217\uff0c\u7cfb\u7edf\u8bc4\u4f30EHR\u548cCXR\u7684\u591a\u6a21\u6001\u878d\u5408\u3002\u7814\u7a76\u6bd4\u8f83\u4e86\u4e0d\u540c\u878d\u5408\u7b56\u7565\uff0c\u6d4b\u8bd5\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u6a21\u6001\u7f3a\u5931\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u7b97\u6cd5\u516c\u5e73\u6027\u3002\u540c\u65f6\u53d1\u5e03\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u5305\u3002", "result": "\u591a\u6a21\u6001\u878d\u5408\u5728\u6a21\u6001\u5b8c\u6574\u65f6\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9700\u8981EHR\u548cCXR\u4e92\u8865\u4fe1\u606f\u7684\u75be\u75c5\u4e2d\u3002\u8de8\u6a21\u6001\u5b66\u4e60\u673a\u5236\u80fd\u6355\u83b7\u4e34\u5e8a\u76f8\u5173\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46EHR\u7684\u4e30\u5bcc\u65f6\u95f4\u7ed3\u6784\u5bfc\u81f4\u6a21\u6001\u4e0d\u5e73\u8861\u3002\u5728\u73b0\u5b9e\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\u4e0b\uff0c\u591a\u6a21\u6001\u4f18\u52bf\u8fc5\u901f\u4e0b\u964d\uff0c\u9664\u975e\u6a21\u578b\u4e13\u95e8\u8bbe\u8ba1\u5904\u7406\u4e0d\u5b8c\u6574\u8f93\u5165\u3002\u591a\u6a21\u6001\u878d\u5408\u4e0d\u81ea\u52a8\u6539\u5584\u516c\u5e73\u6027\uff0c\u4e9a\u7ec4\u5dee\u5f02\u4e3b\u8981\u6e90\u4e8e\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u95f4\u7684\u654f\u611f\u6027\u4e0d\u5e73\u7b49\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u591a\u6a21\u6001\u5b66\u4e60\u4f55\u65f6\u6709\u6548\u3001\u4f55\u65f6\u5931\u8d25\u53ca\u539f\u56e0\u7684\u5b9e\u7528\u6307\u5bfc\uff0c\u4e3a\u5f00\u53d1\u65e2\u6709\u6548\u53c8\u53ef\u9760\u7684\u4e34\u5e8a\u53ef\u90e8\u7f72\u591a\u6a21\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u5f00\u6e90\u5de5\u5177\u5305\u652f\u6301\u53ef\u91cd\u590d\u548c\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u3002"}}
{"id": "2602.23974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23974", "abs": "https://arxiv.org/abs/2602.23974", "authors": ["Fan Zhang", "Baoru Huang", "Xin Zhang"], "title": "Pessimistic Auxiliary Policy for Offline Reinforcement Learning", "comment": null, "summary": "Offline reinforcement learning aims to learn an agent from pre-collected datasets, avoiding unsafe and inefficient real-time interaction. However, inevitable access to out-ofdistribution actions during the learning process introduces approximation errors, causing the error accumulation and considerable overestimation. In this paper, we construct a new pessimistic auxiliary policy for sampling reliable actions. Specifically, we develop a pessimistic auxiliary strategy by maximizing the lower confidence bound of the Q-function. The pessimistic auxiliary strategy exhibits a relatively high value and low uncertainty in the vicinity of the learned policy, avoiding the learned policy sampling high-value actions with potentially high errors during the learning process. Less approximation error introduced by sampled action from pessimistic auxiliary strategy leads to the alleviation of error accumulation. Extensive experiments on offline reinforcement learning benchmarks reveal that utilizing the pessimistic auxiliary strategy can effectively improve the efficacy of other offline RL approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\u6765\u7f13\u89e3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5206\u5e03\u5916\u52a8\u4f5c\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4ece\u9884\u6536\u96c6\u7684\u6570\u636e\u96c6\u5b66\u4e60\uff0c\u907f\u514d\u4e86\u5b9e\u65f6\u4ea4\u4e92\u7684\u98ce\u9669\u548c\u4f4e\u6548\uff0c\u4f46\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4e0d\u53ef\u907f\u514d\u5730\u8bbf\u95ee\u5206\u5e03\u5916\u52a8\u4f5c\uff0c\u8fd9\u4f1a\u5f15\u5165\u8fd1\u4f3c\u8bef\u5dee\uff0c\u5bfc\u81f4\u8bef\u5dee\u7d2f\u79ef\u548c\u4e25\u91cd\u7684\u9ad8\u4f30\u95ee\u9898", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\uff0c\u901a\u8fc7\u6700\u5927\u5316Q\u51fd\u6570\u7684\u7f6e\u4fe1\u4e0b\u754c\u6765\u91c7\u6837\u53ef\u9760\u52a8\u4f5c\u3002\u8be5\u7b56\u7565\u5728\u5df2\u5b66\u4e60\u7b56\u7565\u9644\u8fd1\u5177\u6709\u76f8\u5bf9\u8f83\u9ad8\u7684\u4ef7\u503c\u548c\u8f83\u4f4e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u907f\u514d\u4e86\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u91c7\u6837\u5177\u6709\u6f5c\u5728\u9ad8\u8bef\u5dee\u7684\u9ad8\u4ef7\u503c\u52a8\u4f5c", "result": "\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\u5f15\u5165\u7684\u8fd1\u4f3c\u8bef\u5dee\u8f83\u5c11\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\u3002\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\u80fd\u591f\u6709\u6548\u63d0\u5347\u5176\u4ed6\u79bb\u7ebfRL\u65b9\u6cd5\u7684\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\u901a\u8fc7\u91c7\u6837\u53ef\u9760\u52a8\u4f5c\u6765\u51cf\u5c11\u5206\u5e03\u5916\u52a8\u4f5c\u5e26\u6765\u7684\u8fd1\u4f3c\u8bef\u5dee\uff0c\u4ece\u800c\u7f13\u89e3\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6709\u6548\u6027"}}
{"id": "2602.24229", "categories": ["cs.IR", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.24229", "abs": "https://arxiv.org/abs/2602.24229", "authors": ["W\u0142odzimierz Lewoniewski", "Milena Str\u00f3\u017cyna", "Izabela Czuma\u0142owska", "El\u017cbieta Lewa\u0144ska"], "title": "Science Fiction and Fantasy in Wikipedia: Exploring Structural and Semantic Cues", "comment": "Supplementary materials: https://data.lewoniewski.info/fantasy/", "summary": "Identifying which Wikipedia articles are related to science fiction, fantasy, or their hybrids is challenging because genre boundaries are porous and frequently overlap. Wikipedia nonetheless offers machine-readable structure beyond text, including categories, internal links (wikilinks), and statements if corresponding Wikidata items. However, each of these signals reflects community conventions and can be biased or incomplete. This study examines structural and semantic features of Wikipedia articles that can be used to identify content related to science fiction and fantasy (SF/F).", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u5229\u7528\u7ef4\u57fa\u767e\u79d1\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u7279\u5f81\u8bc6\u522b\u4e0e\u79d1\u5e7b\u548c\u5947\u5e7b\uff08SF/F\uff09\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u89e3\u51b3\u56e0\u4f53\u88c1\u8fb9\u754c\u6a21\u7cca\u548c\u91cd\u53e0\u5e26\u6765\u7684\u8bc6\u522b\u6311\u6218\u3002", "motivation": "\u7ef4\u57fa\u767e\u79d1\u4e2d\u79d1\u5e7b\u548c\u5947\u5e7b\u76f8\u5173\u6587\u7ae0\u7684\u8bc6\u522b\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u4f53\u88c1\u8fb9\u754c\u6a21\u7cca\u4e14\u7ecf\u5e38\u91cd\u53e0\u3002\u867d\u7136\u7ef4\u57fa\u767e\u79d1\u63d0\u4f9b\u4e86\u673a\u5668\u53ef\u8bfb\u7684\u7ed3\u6784\uff08\u5982\u5206\u7c7b\u3001\u5185\u90e8\u94fe\u63a5\u3001Wikidata\u8bed\u53e5\uff09\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u53f7\u53cd\u6620\u4e86\u793e\u533a\u60ef\u4f8b\uff0c\u53ef\u80fd\u5b58\u5728\u504f\u89c1\u6216\u4e0d\u5b8c\u6574\u3002", "method": "\u7814\u7a76\u8003\u5bdf\u7ef4\u57fa\u767e\u79d1\u6587\u7ae0\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u7279\u5f81\uff0c\u5305\u62ec\u5206\u7c7b\u7cfb\u7edf\u3001\u5185\u90e8\u94fe\u63a5\uff08wikilinks\uff09\u4ee5\u53ca\u5bf9\u5e94\u7684Wikidata\u9879\u76ee\u4e2d\u7684\u58f0\u660e\uff0c\u4ee5\u8bc6\u522b\u4e0e\u79d1\u5e7b\u548c\u5947\u5e7b\u76f8\u5173\u7684\u5185\u5bb9\u3002", "result": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8fd9\u4e9b\u7279\u5f81\u5728\u8bc6\u522bSF/F\u5185\u5bb9\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u7ef4\u57fa\u767e\u79d1\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u7279\u5f81\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u8bc6\u522b\u79d1\u5e7b\u548c\u5947\u5e7b\u76f8\u5173\u5185\u5bb9\uff0c\u5c3d\u7ba1\u8fd9\u4e9b\u4fe1\u53f7\u53ef\u80fd\u5b58\u5728\u793e\u533a\u60ef\u4f8b\u5e26\u6765\u7684\u504f\u89c1\u548c\u4e0d\u5b8c\u6574\u6027\u3002"}}
{"id": "2602.24037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24037", "abs": "https://arxiv.org/abs/2602.24037", "authors": ["Vanya Priscillia Bendatu", "Yao Lu"], "title": "Portfolio Reinforcement Learning with Scenario-Context Rollout", "comment": null, "summary": "Market regime shifts induce distribution shifts that can degrade the performance of portfolio rebalancing policies. We propose macro-conditioned scenario-context rollout (SCR) that generates plausible next-day multivariate return scenarios under stress events. However, doing so faces new challenges, as history will never tell what would have happened differently. As a result, incorporating scenario-based rewards from rollouts introduces a reward--transition mismatch in temporal-difference learning, destabilizing RL critic training.\n  We analyze this inconsistency and show it leads to a mixed evaluation target. Guided by this analysis, we construct a counterfactual next state using the rollout-implied continuations and augment the critic agent's bootstrap target. Doing so stabilizes the learning and provides a viable bias-variance tradeoff.\n  In out-of-sample evaluations across 31 distinct universes of U.S. equity and ETF portfolios, our method improves Sharpe ratio by up to 76% and reduces maximum drawdown by up to 53% compared with classic and RL-based portfolio rebalancing baselines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8f\u89c2\u6761\u4ef6\u5316\u573a\u666f\u4e0a\u4e0b\u6587\u5c55\u5f00\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u538b\u529b\u4e8b\u4ef6\u4e0b\u751f\u6210\u53ef\u4fe1\u7684\u6b21\u65e5\u591a\u5143\u6536\u76ca\u573a\u666f\uff0c\u5e76\u901a\u8fc7\u6784\u5efa\u53cd\u4e8b\u5b9e\u72b6\u6001\u6765\u7a33\u5b9a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8bc4\u8bba\u5bb6\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u7b56\u7565\u7684\u6027\u80fd\u3002", "motivation": "\u5e02\u573a\u673a\u5236\u8f6c\u6362\u4f1a\u5bfc\u81f4\u5206\u5e03\u504f\u79fb\uff0c\u4ece\u800c\u964d\u4f4e\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u7b56\u7565\u7684\u6027\u80fd\u3002\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u5386\u53f2\u4e2d\u672a\u53d1\u751f\u7684\u538b\u529b\u4e8b\u4ef6\u573a\u666f\uff0c\u800c\u57fa\u4e8e\u573a\u666f\u5c55\u5f00\u7684\u5956\u52b1\u4f1a\u5f15\u5165\u5956\u52b1-\u8f6c\u79fb\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u7834\u574f\u5f3a\u5316\u5b66\u4e60\u8bc4\u8bba\u5bb6\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u5b8f\u89c2\u6761\u4ef6\u5316\u573a\u666f\u4e0a\u4e0b\u6587\u5c55\u5f00\u65b9\u6cd5\uff0c\u751f\u6210\u538b\u529b\u4e8b\u4ef6\u4e0b\u7684\u6b21\u65e5\u591a\u5143\u6536\u76ca\u573a\u666f\u3002\u5206\u6790\u5956\u52b1-\u8f6c\u79fb\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u6784\u5efa\u53cd\u4e8b\u5b9e\u72b6\u6001\uff0c\u4f7f\u7528\u5c55\u5f00\u9690\u542b\u7684\u5ef6\u7eed\u6765\u589e\u5f3a\u8bc4\u8bba\u5bb6\u667a\u80fd\u4f53\u7684\u5f15\u5bfc\u76ee\u6807\uff0c\u5b9e\u73b0\u7a33\u5b9a\u7684\u5b66\u4e60\u548c\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u3002", "result": "\u572831\u4e2a\u4e0d\u540c\u7684\u7f8e\u56fd\u80a1\u7968\u548cETF\u6295\u8d44\u7ec4\u5408\u5b87\u5b99\u4e2d\u8fdb\u884c\u6837\u672c\u5916\u8bc4\u4f30\uff0c\u76f8\u6bd4\u7ecf\u5178\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u57fa\u7ebf\uff0c\u8be5\u65b9\u6cd5\u5c06\u590f\u666e\u6bd4\u7387\u63d0\u5347\u9ad8\u8fbe76%\uff0c\u6700\u5927\u56de\u64a4\u964d\u4f4e\u9ad8\u8fbe53%\u3002", "conclusion": "\u901a\u8fc7\u5b8f\u89c2\u6761\u4ef6\u5316\u573a\u666f\u5c55\u5f00\u548c\u53cd\u4e8b\u5b9e\u72b6\u6001\u6784\u5efa\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5e02\u573a\u538b\u529b\u4e8b\u4ef6\u4e0b\u7684\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7b56\u7565\u7684\u7a33\u5065\u6027\u548c\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2602.23633", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23633", "abs": "https://arxiv.org/abs/2602.23633", "authors": ["Yubo Zhou", "Luo Luo", "Guang Dai", "Haishan Ye"], "title": "On the Convergence of Single-Loop Stochastic Bilevel Optimization with Approximate Implicit Differentiation", "comment": null, "summary": "Stochastic Bilevel Optimization has emerged as a fundamental framework for meta-learning and hyperparameter optimization. Despite the practical prevalence of single-loop algorithms--which update lower and upper variables concurrently--their theoretical understanding, particularly in the stochastic regime, remains significantly underdeveloped compared to their multi-loop counterparts. Existing analyses often yield suboptimal convergence rates or obscure the critical dependence on the lower-level condition number $\u03ba$, frequently burying it within generic Lipschitz constants. In this paper, we bridge this gap by providing a refined convergence analysis of the Single-loop Stochastic Approximate Implicit Differentiation (SSAID) algorithm. We prove that SSAID achieves an $\u03b5$-stationary point with an oracle complexity of $\\mathcal{O}(\u03ba^7 \u03b5^{-2})$. Our result is noteworthy in two aspects: (i) it matches the optimal $\\mathcal{O}(\u03b5^{-2})$ rate of state-of-the-art multi-loop methods (e.g., stocBiO) while maintaining the computational efficiency of a single-loop update; and (ii) it provides the first explicit, fine-grained characterization of the $\u03ba$-dependence for stochastic AID-based single-loop methods. This work demonstrates that SSAID is not merely a heuristic approach, but admits a rigorous theoretical foundation with convergence guarantees competitive with mainstream multi-loop frameworks.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5355\u5faa\u73af\u968f\u673a\u8fd1\u4f3c\u9690\u5f0f\u5fae\u5206\u7b97\u6cd5\uff08SSAID\uff09\u8fdb\u884c\u4e86\u6536\u655b\u6027\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5176\u8fbe\u5230\u03b5-\u5e73\u7a33\u70b9\u7684oracle\u590d\u6742\u5ea6\u4e3aO(\u03ba^7 \u03b5^{-2})\uff0c\u5339\u914d\u4e86\u591a\u5faa\u73af\u65b9\u6cd5\u7684\u6700\u4f18\u901f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5355\u5faa\u73af\u7684\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u968f\u673a\u53cc\u5c42\u4f18\u5316\u5728\u5143\u5b66\u4e60\u548c\u8d85\u53c2\u6570\u4f18\u5316\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u3002\u5c3d\u7ba1\u5355\u5faa\u73af\u7b97\u6cd5\u5728\u5b9e\u8df5\u4e2d\u666e\u904d\u4f7f\u7528\uff08\u540c\u65f6\u66f4\u65b0\u4e0a\u4e0b\u5c42\u53d8\u91cf\uff09\uff0c\u4f46\u5176\u7406\u8bba\u7406\u89e3\uff0c\u7279\u522b\u662f\u5728\u968f\u673a\u673a\u5236\u4e0b\uff0c\u8fdc\u4e0d\u5982\u591a\u5faa\u73af\u7b97\u6cd5\u6210\u719f\u3002\u73b0\u6709\u5206\u6790\u5f80\u5f80\u5f97\u5230\u6b21\u4f18\u6536\u655b\u901f\u7387\uff0c\u6216\u8005\u5c06\u5173\u952e\u7684\u4e0b\u5c42\u6761\u4ef6\u6570\u03ba\u4f9d\u8d56\u9690\u85cf\u5728\u4e00\u822cLipschitz\u5e38\u6570\u4e2d\u3002", "method": "\u672c\u6587\u5bf9\u5355\u5faa\u73af\u968f\u673a\u8fd1\u4f3c\u9690\u5f0f\u5fae\u5206\u7b97\u6cd5\uff08SSAID\uff09\u8fdb\u884c\u4e86\u7cbe\u7ec6\u5316\u7684\u6536\u655b\u6027\u5206\u6790\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u5355\u5faa\u73af\u66f4\u65b0\u673a\u5236\uff0c\u540c\u65f6\u4f18\u5316\u4e0a\u4e0b\u5c42\u53d8\u91cf\uff0c\u907f\u514d\u4e86\u591a\u5faa\u73af\u7b97\u6cd5\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u8bc1\u660e\u4e86SSAID\u7b97\u6cd5\u8fbe\u5230\u03b5-\u5e73\u7a33\u70b9\u7684oracle\u590d\u6742\u5ea6\u4e3aO(\u03ba^7 \u03b5^{-2})\u3002\u8fd9\u4e00\u7ed3\u679c\u5728\u4e24\u4e2a\u65b9\u9762\u5177\u6709\u91cd\u8981\u610f\u4e49\uff1a(1) \u5339\u914d\u4e86\u6700\u5148\u8fdb\u591a\u5faa\u73af\u65b9\u6cd5\uff08\u5982stocBiO\uff09\u7684\u6700\u4f18O(\u03b5^{-2})\u901f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5355\u5faa\u73af\u66f4\u65b0\u7684\u8ba1\u7b97\u6548\u7387\uff1b(2) \u9996\u6b21\u4e3a\u57fa\u4e8e\u968f\u673aAID\u7684\u5355\u5faa\u73af\u65b9\u6cd5\u63d0\u4f9b\u4e86\u663e\u5f0f\u3001\u7ec6\u7c92\u5ea6\u7684\u03ba\u4f9d\u8d56\u7279\u5f81\u3002", "conclusion": "SSAID\u4e0d\u4ec5\u662f\u4e00\u79cd\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u800c\u4e14\u5177\u6709\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5176\u6536\u655b\u4fdd\u8bc1\u4e0e\u4e3b\u6d41\u591a\u5faa\u73af\u6846\u67b6\u5177\u6709\u7ade\u4e89\u529b\u3002\u8fd9\u9879\u5de5\u4f5c\u586b\u8865\u4e86\u5355\u5faa\u73af\u968f\u673a\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\u7406\u8bba\u5206\u6790\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.24265", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.24265", "abs": "https://arxiv.org/abs/2602.24265", "authors": ["Saber Zerhoudi", "Michael Granitzer"], "title": "Beyond the Click: A Framework for Inferring Cognitive Traces in Search", "comment": null, "summary": "User simulators are essential for evaluating search systems, but they primarily copy user actions without understanding the underlying thought process. This gap exists since large-scale interaction logs record what users do, but not what they might be thinking or feeling, such as confusion or satisfaction. To solve this problem, we present a framework to infer cognitive traces from behavior logs. Our method uses a multi-agent system grounded in Information Foraging Theory (IFT) and human expert judgment. These traces improve model performance on tasks like forecasting session outcomes and user struggle recovery. We release a collection of annotations for several public datasets, including AOL and Stack Overflow, and an open-source tool that allows researchers to apply our method to their own data. This work provides the tools and data needed to build more human-like user simulators and to assess retrieval systems on user-oriented dimensions of performance.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u7528\u6237\u884c\u4e3a\u65e5\u5fd7\u63a8\u65ad\u8ba4\u77e5\u8f68\u8ff9\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u66f4\u4eba\u6027\u5316\u7684\u7528\u6237\u6a21\u62df\u5668", "motivation": "\u73b0\u6709\u7528\u6237\u6a21\u62df\u5668\u4e3b\u8981\u590d\u5236\u7528\u6237\u884c\u4e3a\u800c\u4e0d\u7406\u89e3\u5176\u601d\u7ef4\u8fc7\u7a0b\uff0c\u884c\u4e3a\u65e5\u5fd7\u8bb0\u5f55\u4e86\u7528\u6237\u505a\u4ec0\u4e48\u4f46\u6ca1\u8bb0\u5f55\u4ed6\u4eec\u5728\u60f3\u4ec0\u4e48\u6216\u611f\u53d7\u4ec0\u4e48", "method": "\u57fa\u4e8e\u4fe1\u606f\u89c5\u98df\u7406\u8bba\u548c\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4ece\u884c\u4e3a\u65e5\u5fd7\u63a8\u65ad\u8ba4\u77e5\u8f68\u8ff9", "result": "\u8ba4\u77e5\u8f68\u8ff9\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u9884\u6d4b\u4f1a\u8bdd\u7ed3\u679c\u548c\u7528\u6237\u6323\u624e\u6062\u590d\u7b49\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u53d1\u5e03\u4e86\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u7684\u6ce8\u91ca\u96c6\u5408\u548c\u5f00\u6e90\u5de5\u5177", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6784\u5efa\u66f4\u4eba\u6027\u5316\u7528\u6237\u6a21\u62df\u5668\u548c\u4ece\u7528\u6237\u5bfc\u5411\u7ef4\u5ea6\u8bc4\u4f30\u68c0\u7d22\u7cfb\u7edf\u6240\u9700\u7684\u5de5\u5177\u548c\u6570\u636e"}}
{"id": "2602.23636", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23636", "abs": "https://arxiv.org/abs/2602.23636", "authors": ["Zhihao Ding", "Jinming Li", "Ze Lu", "Jieming Shi"], "title": "FlexGuard: Continuous Risk Scoring for Strictness-Adaptive LLM Content Moderation", "comment": null, "summary": "Ensuring the safety of LLM-generated content is essential for real-world deployment. Most existing guardrail models formulate moderation as a fixed binary classification task, implicitly assuming a fixed definition of harmfulness. In practice, enforcement strictness - how conservatively harmfulness is defined and enforced - varies across platforms and evolves over time, making binary moderators brittle under shifting requirements. We first introduce FlexBench, a strictness-adaptive LLM moderation benchmark that enables controlled evaluation under multiple strictness regimes. Experiments on FlexBench reveal substantial cross-strictness inconsistency in existing moderators: models that perform well under one regime can degrade substantially under others, limiting their practical usability. To address this, we propose FlexGuard, an LLM-based moderator that outputs a calibrated continuous risk score reflecting risk severity and supports strictness-specific decisions via thresholding. We train FlexGuard via risk-alignment optimization to improve score-severity consistency and provide practical threshold selection strategies to adapt to target strictness at deployment. Experiments on FlexBench and public benchmarks demonstrate that FlexGuard achieves higher moderation accuracy and substantially improved robustness under varying strictness. We release the source code and data to support reproducibility.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFlexGuard\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f93\u51fa\u6821\u51c6\u7684\u8fde\u7eed\u98ce\u9669\u8bc4\u5206\u6765\u9002\u5e94\u4e0d\u540c\u4e25\u683c\u7a0b\u5ea6\u7684\u5185\u5bb9\u5ba1\u6838\u9700\u6c42\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4e8c\u5143\u5206\u7c7b\u5ba1\u6838\u6a21\u578b\u5728\u4e25\u683c\u7a0b\u5ea6\u53d8\u5316\u65f6\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u5185\u5bb9\u5b89\u5168\u5ba1\u6838\u6a21\u578b\u5927\u591a\u91c7\u7528\u56fa\u5b9a\u7684\u4e8c\u5143\u5206\u7c7b\u65b9\u5f0f\uff0c\u5047\u8bbe\u6709\u5bb3\u5185\u5bb9\u7684\u5b9a\u4e49\u662f\u56fa\u5b9a\u7684\u3002\u4f46\u5b9e\u9645\u4e0a\uff0c\u4e0d\u540c\u5e73\u53f0\u7684\u6267\u884c\u4e25\u683c\u7a0b\u5ea6\uff08\u5982\u4f55\u5b9a\u4e49\u548c\u5f3a\u5236\u6267\u884c\u6709\u5bb3\u5185\u5bb9\uff09\u5404\u4e0d\u76f8\u540c\u4e14\u968f\u65f6\u95f4\u6f14\u53d8\uff0c\u8fd9\u4f7f\u5f97\u4e8c\u5143\u5ba1\u6838\u6a21\u578b\u5728\u9700\u6c42\u53d8\u5316\u65f6\u53d8\u5f97\u8106\u5f31\u3002", "method": "\u9996\u5148\u5f15\u5165FlexBench\u57fa\u51c6\uff0c\u652f\u6301\u5728\u591a\u79cd\u4e25\u683c\u7a0b\u5ea6\u4e0b\u8fdb\u884c\u53d7\u63a7\u8bc4\u4f30\u3002\u7136\u540e\u63d0\u51faFlexGuard\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u5ba1\u6838\u5668\uff0c\u8f93\u51fa\u53cd\u6620\u98ce\u9669\u4e25\u91cd\u7a0b\u5ea6\u7684\u6821\u51c6\u8fde\u7eed\u98ce\u9669\u8bc4\u5206\uff0c\u5e76\u901a\u8fc7\u9608\u503c\u8bbe\u5b9a\u652f\u6301\u7279\u5b9a\u4e25\u683c\u7a0b\u5ea6\u7684\u51b3\u7b56\u3002\u901a\u8fc7\u98ce\u9669\u5bf9\u9f50\u4f18\u5316\u8bad\u7ec3FlexGuard\u4ee5\u63d0\u9ad8\u8bc4\u5206-\u4e25\u91cd\u7a0b\u5ea6\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u4f9b\u5b9e\u7528\u7684\u9608\u503c\u9009\u62e9\u7b56\u7565\u4ee5\u9002\u5e94\u90e8\u7f72\u65f6\u7684\u76ee\u6807\u4e25\u683c\u7a0b\u5ea6\u3002", "result": "\u5728FlexBench\u548c\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFlexGuard\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5ba1\u6838\u51c6\u786e\u6027\uff0c\u5e76\u5728\u4e0d\u540c\u4e25\u683c\u7a0b\u5ea6\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u3002\u73b0\u6709\u5ba1\u6838\u6a21\u578b\u5728\u4e0d\u540c\u4e25\u683c\u7a0b\u5ea6\u95f4\u5b58\u5728\u663e\u8457\u7684\u4e0d\u4e00\u81f4\u6027\uff1a\u5728\u67d0\u4e00\u4e25\u683c\u7a0b\u5ea6\u4e0b\u8868\u73b0\u826f\u597d\u7684\u6a21\u578b\u5728\u5176\u4ed6\u4e25\u683c\u7a0b\u5ea6\u4e0b\u6027\u80fd\u4f1a\u5927\u5e45\u4e0b\u964d\u3002", "conclusion": "FlexGuard\u901a\u8fc7\u8fde\u7eed\u98ce\u9669\u8bc4\u5206\u548c\u9608\u503c\u8c03\u6574\u673a\u5236\uff0c\u4e3aLLM\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u5e73\u53f0\u548c\u968f\u65f6\u95f4\u53d8\u5316\u7684\u5ba1\u6838\u4e25\u683c\u7a0b\u5ea6\u8981\u6c42\uff0c\u63d0\u9ad8\u4e86\u5b9e\u9645\u53ef\u7528\u6027\u3002"}}
{"id": "2602.24080", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.24080", "abs": "https://arxiv.org/abs/2602.24080", "authors": ["Xiang Li", "Jiabao Gao", "Sipei Lin", "Xuan Zhou", "Chi Zhang", "Bo Cheng", "Jiale Han", "Benyou Wang"], "title": "Human or Machine? A Preliminary Turing Test for Speech-to-Speech Interaction", "comment": "Accepted by ICLR 2026 Conference", "summary": "The pursuit of human-like conversational agents has long been guided by the Turing test. For modern speech-to-speech (S2S) systems, a critical yet unanswered question is whether they can converse like humans. To tackle this, we conduct the first Turing test for S2S systems, collecting 2,968 human judgments on dialogues between 9 state-of-the-art S2S systems and 28 human participants. Our results deliver a clear finding: no existing evaluated S2S system passes the test, revealing a significant gap in human-likeness. To diagnose this failure, we develop a fine-grained taxonomy of 18 human-likeness dimensions and crowd-annotate our collected dialogues accordingly. Our analysis shows that the bottleneck is not semantic understanding but stems from paralinguistic features, emotional expressivity, and conversational persona. Furthermore, we find that off-the-shelf AI models perform unreliably as Turing test judges. In response, we propose an interpretable model that leverages the fine-grained human-likeness ratings and delivers accurate and transparent human-vs-machine discrimination, offering a powerful tool for automatic human-likeness evaluation. Our work establishes the first human-likeness evaluation for S2S systems and moves beyond binary outcomes to enable detailed diagnostic insights, paving the way for human-like improvements in conversational AI systems.", "AI": {"tldr": "\u9996\u4e2a\u9488\u5bf9\u8bed\u97f3\u5230\u8bed\u97f3\u7cfb\u7edf\u7684\u56fe\u7075\u6d4b\u8bd5\u663e\u793a\uff0c\u73b0\u6709\u7cfb\u7edf\u5747\u672a\u901a\u8fc7\u6d4b\u8bd5\uff0c\u4e0e\u4eba\u7c7b\u5bf9\u8bdd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u74f6\u9888\u5728\u4e8e\u526f\u8bed\u8a00\u7279\u5f81\u3001\u60c5\u611f\u8868\u8fbe\u548c\u5bf9\u8bdd\u4e2a\u6027\uff0c\u800c\u975e\u8bed\u4e49\u7406\u89e3\u3002", "motivation": "\u73b0\u4ee3\u8bed\u97f3\u5230\u8bed\u97f3\u7cfb\u7edf\u80fd\u5426\u50cf\u4eba\u7c7b\u4e00\u6837\u5bf9\u8bdd\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u8bc4\u4f30\u8fd9\u4e9b\u7cfb\u7edf\u7684\u4eba\u7c7b\u76f8\u4f3c\u5ea6\uff0c\u7814\u7a76\u8005\u8fdb\u884c\u4e86\u9996\u4e2a\u9488\u5bf9S2S\u7cfb\u7edf\u7684\u56fe\u7075\u6d4b\u8bd5\u3002", "method": "\u6536\u96c6\u4e862,968\u4e2a\u4eba\u7c7b\u5224\u65ad\uff0c\u8bc4\u4f309\u4e2a\u6700\u5148\u8fdb\u7684S2S\u7cfb\u7edf\u4e0e28\u540d\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u5bf9\u8bdd\u3002\u5f00\u53d1\u4e86\u5305\u542b18\u4e2a\u4eba\u7c7b\u76f8\u4f3c\u5ea6\u7ef4\u5ea6\u7684\u7ec6\u7c92\u5ea6\u5206\u7c7b\u6cd5\uff0c\u5e76\u5bf9\u6536\u96c6\u7684\u5bf9\u8bdd\u8fdb\u884c\u4f17\u5305\u6807\u6ce8\u3002", "result": "\u6240\u6709\u88ab\u8bc4\u4f30\u7684S2S\u7cfb\u7edf\u5747\u672a\u901a\u8fc7\u56fe\u7075\u6d4b\u8bd5\u3002\u74f6\u9888\u4e3b\u8981\u5728\u4e8e\u526f\u8bed\u8a00\u7279\u5f81\u3001\u60c5\u611f\u8868\u8fbe\u548c\u5bf9\u8bdd\u4e2a\u6027\uff0c\u800c\u975e\u8bed\u4e49\u7406\u89e3\u3002\u73b0\u6210\u7684AI\u6a21\u578b\u4f5c\u4e3a\u56fe\u7075\u6d4b\u8bd5\u8bc4\u5224\u8005\u8868\u73b0\u4e0d\u53ef\u9760\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u7ec6\u7c92\u5ea6\u4eba\u7c7b\u76f8\u4f3c\u5ea6\u8bc4\u5206\u7684\u53ef\u89e3\u91ca\u6a21\u578b\uff0c\u80fd\u591f\u51c6\u786e\u900f\u660e\u5730\u533a\u5206\u4eba\u7c7b\u4e0e\u673a\u5668\u5bf9\u8bdd\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3aS2S\u7cfb\u7edf\u5efa\u7acb\u4e86\u9996\u4e2a\u4eba\u7c7b\u76f8\u4f3c\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u8d85\u8d8a\u4e86\u4e8c\u5143\u7ed3\u679c\uff0c\u4e3a\u5bf9\u8bddAI\u7cfb\u7edf\u7684\u4eba\u7c7b\u5316\u6539\u8fdb\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2602.24277", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24277", "abs": "https://arxiv.org/abs/2602.24277", "authors": ["Dake Zhang", "Mark D. Smucker", "Charles L. A. Clarke"], "title": "Resources for Automated Evaluation of Assistive RAG Systems that Help Readers with News Trustworthiness Assessment", "comment": null, "summary": "Many readers today struggle to assess the trustworthiness of online news because reliable reporting coexists with misinformation. The TREC 2025 DRAGUN (Detection, Retrieval, and Augmented Generation for Understanding News) Track provided a venue for researchers to develop and evaluate assistive RAG systems that support readers' news trustworthiness assessment by producing reader-oriented, well-attributed reports. As the organizers of the DRAGUN track, we describe the resources that we have newly developed to allow for the reuse of the track's tasks. The track had two tasks: (Task 1) Question Generation, producing 10 ranked investigative questions; and (Task 2, the main task) Report Generation, producing a 250-word report grounded in the MS MARCO V2.1 Segmented Corpus. As part of the track's evaluation, we had TREC assessors create importance-weighted rubrics of questions with expected short answers for 30 different news articles. These rubrics represent the information that assessors believe is important for readers to assess an article's trustworthiness. The assessors then used their rubrics to manually judge the participating teams' submitted runs. To make these tasks and their rubrics reusable, we have created an automated process to judge runs not part of the original assessing. We show that our AutoJudge ranks existing runs well compared to the TREC human-assessed evaluation (Kendall's $\u03c4= 0.678$ for Task 1 and $\u03c4= 0.872$ for Task 2). These resources enable both the evaluation of RAG systems for assistive news trustworthiness assessment and, with the human evaluation as a benchmark, research on improving automated RAG evaluation.", "AI": {"tldr": "TREC 2025 DRAGUN\u8d5b\u9053\u5f00\u53d1\u4e86\u652f\u6301\u65b0\u95fb\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u7684RAG\u7cfb\u7edf\uff0c\u5305\u542b\u95ee\u9898\u751f\u6210\u548c\u62a5\u544a\u751f\u6210\u4e24\u4e2a\u4efb\u52a1\uff0c\u5e76\u521b\u5efa\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30\u5de5\u5177AutoJudge\uff0c\u4e0e\u4eba\u5de5\u8bc4\u4f30\u7ed3\u679c\u9ad8\u5ea6\u76f8\u5173\u3002", "motivation": "\u5f53\u524d\u8bfb\u8005\u96be\u4ee5\u8bc4\u4f30\u5728\u7ebf\u65b0\u95fb\u7684\u53ef\u4fe1\u5ea6\uff0c\u56e0\u4e3a\u53ef\u9760\u62a5\u9053\u4e0e\u9519\u8bef\u4fe1\u606f\u5e76\u5b58\u3002\u9700\u8981\u5f00\u53d1\u8f85\u52a9\u7cfb\u7edf\u5e2e\u52a9\u8bfb\u8005\u8fdb\u884c\u65b0\u95fb\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u3002", "method": "\u521b\u5efaDRAGUN\u8d5b\u9053\uff0c\u5305\u542b\u4e24\u4e2a\u4efb\u52a1\uff1a1) \u95ee\u9898\u751f\u6210\u4efb\u52a1\uff1a\u751f\u621010\u4e2a\u6392\u540d\u7684\u8c03\u67e5\u6027\u95ee\u9898\uff1b2) \u62a5\u544a\u751f\u6210\u4efb\u52a1\uff1a\u57fa\u4e8eMS MARCO V2.1 Segmented Corpus\u751f\u6210250\u5b57\u7684\u62a5\u544a\u3002\u5f00\u53d1\u81ea\u52a8\u5316\u8bc4\u4f30\u6d41\u7a0bAutoJudge\u6765\u8bc4\u4f30\u7cfb\u7edf\u8868\u73b0\u3002", "result": "AutoJudge\u4e0eTREC\u4eba\u5de5\u8bc4\u4f30\u7ed3\u679c\u9ad8\u5ea6\u76f8\u5173\uff08Task 1\u7684Kendall's \u03c4=0.678\uff0cTask 2\u7684\u03c4=0.872\uff09\u3002\u521b\u5efa\u4e86\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u8bc4\u4f30\u8d44\u6e90\u548c\u57fa\u51c6\u3002", "conclusion": "DRAGUN\u8d5b\u9053\u4e3a\u65b0\u95fb\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bc4\u4f30\u6846\u67b6\u548c\u8d44\u6e90\uff0cAutoJudge\u5de5\u5177\u80fd\u591f\u6709\u6548\u66ff\u4ee3\u4eba\u5de5\u8bc4\u4f30\uff0c\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u548c\u7cfb\u7edf\u5f00\u53d1\u3002"}}
{"id": "2602.23638", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23638", "abs": "https://arxiv.org/abs/2602.23638", "authors": ["Haoran Zhang", "Dongjun Kim", "Seohyeon Cha", "Haris Vikalo"], "title": "FedRot-LoRA: Mitigating Rotational Misalignment in Federated LoRA", "comment": "preprint", "summary": "Federated LoRA provides a communication-efficient mechanism for fine-tuning large language models on decentralized data. In practice, however, a discrepancy between the factor-wise averaging used to preserve low rank and the mathematically correct aggregation of local updates can cause significant aggregation error and unstable training. We argue that a major source of this problem is rotational misalignment, arising from the rotational invariance of low-rank factorizations -- semantically equivalent updates can be represented in different latent subspaces across clients since $(B_i R_i)(R_i^\\top A_i) = B_i A_i$. When such misaligned factors are averaged directly, they interfere destructively and degrade the global update. To address this issue, we propose FedRot-LoRA, a federated LoRA framework that aligns client updates via orthogonal transformations prior to aggregation. This alignment preserves the semantic update while reducing cross-client subspace mismatch, without increasing communication cost or restricting model expressivity. We provide a convergence analysis that examines the aggregation error induced by factor-wise averaging and shows how rotational alignment yields a tighter upper bound on this error. Extensive experiments on natural language understanding and generative tasks demonstrate that FedRot-LoRA consistently outperforms existing federated LoRA baselines across a range of heterogeneity levels and LoRA ranks.", "AI": {"tldr": "FedRot-LoRA\uff1a\u901a\u8fc7\u6b63\u4ea4\u53d8\u6362\u5bf9\u9f50\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u8054\u90a6LoRA\u6846\u67b6\uff0c\u89e3\u51b3\u56e0\u4f4e\u79e9\u5206\u89e3\u65cb\u8f6c\u4e0d\u53d8\u6027\u5bfc\u81f4\u7684\u805a\u5408\u8bef\u5dee\u95ee\u9898", "motivation": "\u8054\u90a6LoRA\u5728\u53bb\u4e2d\u5fc3\u5316\u6570\u636e\u4e0a\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u56e0\u5b50\u7ea7\u5e73\u5747\u4e0e\u6570\u5b66\u4e0a\u6b63\u786e\u7684\u672c\u5730\u66f4\u65b0\u805a\u5408\u4e4b\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u805a\u5408\u8bef\u5dee\u548c\u4e0d\u7a33\u5b9a\u8bad\u7ec3\u3002\u4e3b\u8981\u95ee\u9898\u662f\u65cb\u8f6c\u4e0d\u5bf9\u9f50\uff0c\u6e90\u4e8e\u4f4e\u79e9\u5206\u89e3\u7684\u65cb\u8f6c\u4e0d\u53d8\u6027\u2014\u2014\u8bed\u4e49\u7b49\u4ef7\u7684\u66f4\u65b0\u5728\u4e0d\u540c\u5ba2\u6237\u7aef\u53ef\u80fd\u8868\u793a\u5728\u4e0d\u540c\u7684\u6f5c\u5728\u5b50\u7a7a\u95f4\u4e2d\u3002", "method": "\u63d0\u51faFedRot-LoRA\u6846\u67b6\uff0c\u5728\u805a\u5408\u524d\u901a\u8fc7\u6b63\u4ea4\u53d8\u6362\u5bf9\u9f50\u5ba2\u6237\u7aef\u66f4\u65b0\u3002\u8fd9\u79cd\u5bf9\u9f50\u5728\u4fdd\u6301\u8bed\u4e49\u66f4\u65b0\u7684\u540c\u65f6\u51cf\u5c11\u8de8\u5ba2\u6237\u7aef\u5b50\u7a7a\u95f4\u4e0d\u5339\u914d\uff0c\u4e0d\u589e\u52a0\u901a\u4fe1\u6210\u672c\u6216\u9650\u5236\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u3002", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFedRot-LoRA\u5728\u5404\u79cd\u5f02\u6784\u7a0b\u5ea6\u548cLoRA\u79e9\u7684\u8bbe\u7f6e\u4e0b\uff0c\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684\u8054\u90a6LoRA\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FedRot-LoRA\u901a\u8fc7\u65cb\u8f6c\u5bf9\u9f50\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6LoRA\u4e2d\u7684\u805a\u5408\u8bef\u5dee\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u548c\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u901a\u4fe1\u6548\u7387\u548c\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2602.23662", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23662", "abs": "https://arxiv.org/abs/2602.23662", "authors": ["Kohei Obata", "Zheng Chen", "Yasuko Matsubara", "Lingwei Zhu", "Yasushi Sakurai"], "title": "Selective Denoising Diffusion Model for Time Series Anomaly Detection", "comment": null, "summary": "Time series anomaly detection (TSAD) has been an important area of research for decades, with reconstruction-based methods, mostly based on generative models, gaining popularity and demonstrating success. Diffusion models have recently attracted attention due to their advanced generative capabilities. Existing diffusion-based methods for TSAD rely on a conditional strategy, which reconstructs input instances from white noise with the aid of the conditioner. However, this poses challenges in accurately reconstructing the normal parts, resulting in suboptimal detection performance. In response, we propose a novel diffusion-based method, named AnomalyFilter, which acts as a selective filter that only denoises anomaly parts in the instance while retaining normal parts. To build such a filter, we mask Gaussian noise during the training phase and conduct the denoising process without adding noise to the instances. The synergy of the two simple components greatly enhances the performance of naive diffusion models. Extensive experiments on five datasets demonstrate that AnomalyFilter achieves notably low reconstruction error on normal parts, providing empirical support for its effectiveness in anomaly detection. AnomalyFilter represents a pioneering approach that focuses on the noise design of diffusion models specifically tailored for TSAD.", "AI": {"tldr": "\u63d0\u51faAnomalyFilter\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u8fc7\u6ee4\u4ec5\u53bb\u566a\u5f02\u5e38\u90e8\u5206\u800c\u4fdd\u7559\u6b63\u5e38\u90e8\u5206\uff0c\u6539\u8fdb\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684TSAD\u65b9\u6cd5\u91c7\u7528\u6761\u4ef6\u7b56\u7565\uff0c\u4ece\u767d\u566a\u58f0\u91cd\u5efa\u8f93\u5165\u5b9e\u4f8b\uff0c\u4f46\u96be\u4ee5\u51c6\u786e\u91cd\u5efa\u6b63\u5e38\u90e8\u5206\uff0c\u5bfc\u81f4\u68c0\u6d4b\u6027\u80fd\u4e0d\u4f73", "method": "\u63d0\u51faAnomalyFilter\u65b9\u6cd5\uff0c\u5728\u8bad\u7ec3\u9636\u6bb5\u63a9\u7801\u9ad8\u65af\u566a\u58f0\uff0c\u5728\u53bb\u566a\u8fc7\u7a0b\u4e2d\u4e0d\u5411\u5b9e\u4f8b\u6dfb\u52a0\u566a\u58f0\uff0c\u6784\u5efa\u9009\u62e9\u6027\u8fc7\u6ee4\u5668\u4ec5\u5904\u7406\u5f02\u5e38\u90e8\u5206", "result": "\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAnomalyFilter\u5728\u6b63\u5e38\u90e8\u5206\u5b9e\u73b0\u4e86\u663e\u8457\u8f83\u4f4e\u7684\u91cd\u5efa\u8bef\u5dee\uff0c\u4e3a\u5f02\u5e38\u68c0\u6d4b\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301", "conclusion": "AnomalyFilter\u4ee3\u8868\u4e86\u4e13\u95e8\u4e3aTSAD\u5b9a\u5236\u7684\u6269\u6563\u6a21\u578b\u566a\u58f0\u8bbe\u8ba1\u7684\u5f00\u521b\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u4e2a\u7b80\u5355\u7ec4\u4ef6\u7684\u534f\u540c\u4f5c\u7528\u663e\u8457\u63d0\u5347\u4e86\u57fa\u7840\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd"}}
{"id": "2602.23663", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23663", "abs": "https://arxiv.org/abs/2602.23663", "authors": ["Kohei Obata", "Taichi Murayama", "Zheng Chen", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Disentangled Mode-Specific Representations for Tensor Time Series via Contrastive Learning", "comment": null, "summary": "Multi-mode tensor time series (TTS) can be found in many domains, such as search engines and environmental monitoring systems. Learning representations of a TTS benefits various applications, but it is also challenging since the complexities inherent in the tensor hinder the realization of rich representations. In this paper, we propose a novel representation learning method designed specifically for TTS, namely MoST. Specifically, MoST uses a tensor slicing approach to reduce the complexity of the TTS structure and learns representations that can be disentangled into individual non-temporal modes. Each representation captures mode-specific features, which are the relationship between variables within the same mode, and mode-invariant features, which are in common in representations of different modes. We employ a contrastive learning framework to learn parameters; the loss function comprises two parts intended to learn representation in a mode-specific way and mode-invariant way, effectively exploiting disentangled representations as augmentations. Extensive experiments on real-world datasets show that MoST consistently outperforms the state-of-the-art methods in terms of classification and forecasting accuracy. Code is available at https://github.com/KoheiObata/MoST.", "AI": {"tldr": "MoST\u662f\u4e00\u79cd\u4e13\u95e8\u4e3a\u591a\u6a21\u6001\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\u8bbe\u8ba1\u7684\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f20\u91cf\u5207\u7247\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u5b66\u4e60\u53ef\u89e3\u8026\u4e3a\u5404\u975e\u65f6\u95f4\u6a21\u6001\u7684\u8868\u793a\uff0c\u5728\u5206\u7c7b\u548c\u9884\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\u5728\u641c\u7d22\u5f15\u64ce\u548c\u73af\u5883\u76d1\u6d4b\u7b49\u9886\u57df\u666e\u904d\u5b58\u5728\uff0c\u5b66\u4e60\u5176\u8868\u793a\u5bf9\u591a\u79cd\u5e94\u7528\u6709\u76ca\uff0c\u4f46\u5f20\u91cf\u7684\u590d\u6742\u6027\u963b\u788d\u4e86\u4e30\u5bcc\u8868\u793a\u7684\u5b9e\u73b0\u3002", "method": "MoST\u4f7f\u7528\u5f20\u91cf\u5207\u7247\u65b9\u6cd5\u964d\u4f4eTTS\u7ed3\u6784\u590d\u6742\u5ea6\uff0c\u5b66\u4e60\u53ef\u89e3\u8026\u4e3a\u5404\u975e\u65f6\u95f4\u6a21\u6001\u7684\u8868\u793a\u3002\u6bcf\u4e2a\u8868\u793a\u5305\u542b\u6a21\u6001\u7279\u5b9a\u7279\u5f81\uff08\u540c\u4e00\u6a21\u6001\u5185\u53d8\u91cf\u95f4\u5173\u7cfb\uff09\u548c\u6a21\u6001\u4e0d\u53d8\u7279\u5f81\uff08\u4e0d\u540c\u6a21\u6001\u5171\u6709\uff09\u3002\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u635f\u5931\u51fd\u6570\u5305\u542b\u6a21\u6001\u7279\u5b9a\u548c\u6a21\u6001\u4e0d\u53d8\u4e24\u90e8\u5206\uff0c\u6709\u6548\u5229\u7528\u89e3\u8026\u8868\u793a\u4f5c\u4e3a\u589e\u5f3a\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMoST\u5728\u5206\u7c7b\u548c\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "MoST\u662f\u4e00\u79cd\u4e13\u95e8\u4e3a\u591a\u6a21\u6001\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\u8bbe\u8ba1\u7684\u6709\u6548\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u8868\u793a\u5b66\u4e60\u6a21\u6001\u7279\u5b9a\u548c\u6a21\u6001\u4e0d\u53d8\u7279\u5f81\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2602.24110", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24110", "abs": "https://arxiv.org/abs/2602.24110", "authors": ["Yanwei Ren", "Haotian Zhang", "Likang Xiao", "Xikai Zhang", "Jiaxing Huang", "Jiayan Qiu", "Baosheng Yu", "Quan Chen", "Liu Liu"], "title": "Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance", "comment": null, "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the complex reasoning capabilities of Large Reasoning Models. However, standard outcome-based supervision suffers from a critical limitation that penalizes trajectories that are largely correct but fail due to several missteps as heavily as completely erroneous ones. This coarse feedback signal causes the model to discard valuable largely correct rollouts, leading to a degradation in rollout diversity that prematurely narrows the exploration space. Process Reward Models have demonstrated efficacy in providing reliable step-wise verification for test-time scaling, naively integrating these signals into RLVR as dense rewards proves ineffective.Prior methods attempt to introduce off-policy guided whole-trajectory replacement that often outside the policy model's distribution, but still fail to utilize the largely correct rollouts generated by the model itself and thus do not effectively mitigate the narrowing of the exploration space. To address these issues, we propose SCOPE (Step-wise Correction for On-Policy Exploration), a novel framework that utilizes Process Reward Models to pinpoint the first erroneous step in suboptimal rollouts and applies fine-grained, step-wise off-policy rectification. By applying precise refinement on partially correct rollout, our method effectively salvages partially correct trajectories and increases diversity score by 13.5%, thereby sustaining a broad exploration space. Extensive experiments demonstrate that our approach establishes new state-of-the-art results, achieving an average accuracy of 46.6% on math reasoning and exhibiting robust generalization with 53.4% accuracy on out-of-distribution reasoning tasks.", "AI": {"tldr": "SCOPE\u6846\u67b6\u901a\u8fc7\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8bc6\u522b\u6b21\u4f18\u8f68\u8ff9\u4e2d\u7684\u9996\u4e2a\u9519\u8bef\u6b65\u9aa4\uff0c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fee\u6b63\uff0c\u6709\u6548\u5229\u7528\u90e8\u5206\u6b63\u786e\u7684\u8f68\u8ff9\uff0c\u63d0\u5347\u63a2\u7d22\u591a\u6837\u6027\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97SOTA\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u7ed3\u679c\u7684\u5f3a\u5316\u5b66\u4e60\u76d1\u7763\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5bf9\u90e8\u5206\u6b63\u786e\u4f46\u5305\u542b\u5c11\u91cf\u9519\u8bef\u7684\u8f68\u8ff9\u60e9\u7f5a\u8fc7\u91cd\uff0c\u5bfc\u81f4\u6a21\u578b\u4e22\u5f03\u6709\u4ef7\u503c\u7684\u8f68\u8ff9\uff0c\u964d\u4f4e\u63a2\u7d22\u591a\u6837\u6027\uff0c\u8fc7\u65e9\u7f29\u5c0f\u63a2\u7d22\u7a7a\u95f4\u3002", "method": "\u63d0\u51faSCOPE\u6846\u67b6\uff0c\u5229\u7528\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u7cbe\u786e\u5b9a\u4f4d\u6b21\u4f18\u8f68\u8ff9\u4e2d\u7684\u9996\u4e2a\u9519\u8bef\u6b65\u9aa4\uff0c\u5e94\u7528\u7ec6\u7c92\u5ea6\u7684\u6b65\u9aa4\u7ea7\u79bb\u7b56\u7565\u4fee\u6b63\uff0c\u5bf9\u90e8\u5206\u6b63\u786e\u7684\u8f68\u8ff9\u8fdb\u884c\u7cbe\u786e\u4f18\u5316\u3002", "result": "\u65b9\u6cd5\u6709\u6548\u62ef\u6551\u90e8\u5206\u6b63\u786e\u8f68\u8ff9\uff0c\u5c06\u591a\u6837\u6027\u5206\u6570\u63d0\u534713.5%\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u523046.6%\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u5728\u5206\u5e03\u5916\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u523053.4%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "SCOPE\u901a\u8fc7\u6b65\u9aa4\u7ea7\u4fee\u6b63\u6709\u6548\u7ef4\u6301\u4e86\u5e7f\u9614\u7684\u63a2\u7d22\u7a7a\u95f4\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.23696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23696", "abs": "https://arxiv.org/abs/2602.23696", "authors": ["Yongzhong Xu"], "title": "Optimizer-Induced Low-Dimensional Drift and Transverse Dynamics in Transformer Training", "comment": "18 pages, 4 figures", "summary": "We study the geometry of training trajectories in small transformer models and find that parameter updates organize into a dominant drift direction with transverse residual dynamics. Using uncentered, row-normalized trajectory PCA, we show that a single direction captures a large fraction of cumulative parameter movement early in training, while remaining components encode oscillatory behavior in auxiliary probe performance. Instantaneous gradients exhibit little alignment with this dominant direction, indicating that it arises from accumulated optimizer updates rather than per-batch gradient structure. Comparing AdamW with SGD variants at matched loss levels reveals substantial differences in trajectory geometry: AdamW develops multi-dimensional drift structure, whereas SGD-family optimizers produce nearly colinear parameter evolution and weaker probe dynamics. Reheating selectively perturbs transverse components with minimal effect on the dominant drift coordinate. These findings suggest that optimizer choice shapes the effective dimensionality and structure of learning trajectories beyond what is apparent from loss values alone.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5c0fTransformer\u6a21\u578b\u7684\u8bad\u7ec3\u8f68\u8ff9\u5448\u73b0\u4e3b\u5bfc\u6f02\u79fb\u65b9\u5411\u4e0e\u6a2a\u5411\u6b8b\u4f59\u52a8\u529b\u5b66\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u4f18\u5316\u5668\u9009\u62e9\u663e\u8457\u5f71\u54cd\u8f68\u8ff9\u7684\u6709\u6548\u7ef4\u5ea6\u548c\u7ed3\u6784", "motivation": "\u7814\u7a76\u8bad\u7ec3\u8f68\u8ff9\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u4e86\u89e3\u4f18\u5316\u5668\u5982\u4f55\u5f71\u54cd\u53c2\u6570\u66f4\u65b0\u7684\u7ec4\u7ec7\u65b9\u5f0f\uff0c\u8d85\u8d8a\u4ec5\u4ece\u635f\u5931\u503c\u89c2\u5bdf\u5230\u7684\u4fe1\u606f", "method": "\u4f7f\u7528\u672a\u4e2d\u5fc3\u5316\u3001\u884c\u5f52\u4e00\u5316\u7684\u8f68\u8ff9PCA\u5206\u6790\u5c0fTransformer\u6a21\u578b\u7684\u53c2\u6570\u66f4\u65b0\uff0c\u6bd4\u8f83AdamW\u548cSGD\u53d8\u4f53\u5728\u5339\u914d\u635f\u5931\u6c34\u5e73\u4e0b\u7684\u8f68\u8ff9\u51e0\u4f55\u5dee\u5f02", "result": "\u53c2\u6570\u66f4\u65b0\u7ec4\u7ec7\u6210\u4e3b\u5bfc\u6f02\u79fb\u65b9\u5411\u52a0\u6a2a\u5411\u6b8b\u4f59\u52a8\u529b\u5b66\uff1bAdamW\u4ea7\u751f\u591a\u7ef4\u6f02\u79fb\u7ed3\u6784\uff0cSGD\u4ea7\u751f\u8fd1\u4f3c\u5171\u7ebf\u53c2\u6570\u6f14\u5316\uff1b\u77ac\u65f6\u68af\u5ea6\u4e0e\u4e3b\u5bfc\u65b9\u5411\u5bf9\u9f50\u5ea6\u4f4e\uff1b\u518d\u52a0\u70ed\u9009\u62e9\u6027\u5730\u6270\u52a8\u6a2a\u5411\u5206\u91cf", "conclusion": "\u4f18\u5316\u5668\u9009\u62e9\u5851\u9020\u4e86\u5b66\u4e60\u8f68\u8ff9\u7684\u6709\u6548\u7ef4\u5ea6\u548c\u7ed3\u6784\uff0c\u8fd9\u4e9b\u7279\u5f81\u65e0\u6cd5\u4ec5\u4ece\u635f\u5931\u503c\u4e2d\u89c2\u5bdf\u5230\uff0c\u8868\u660e\u8bad\u7ec3\u52a8\u6001\u5177\u6709\u91cd\u8981\u7684\u51e0\u4f55\u7ed3\u6784"}}
{"id": "2602.23737", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23737", "abs": "https://arxiv.org/abs/2602.23737", "authors": ["Hanping Zhang", "Yuhong Guo"], "title": "Bridging Dynamics Gaps via Diffusion Schr\u00f6dinger Bridge for Cross-Domain Reinforcement Learning", "comment": null, "summary": "Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains. A key challenge lies in the lack of target-domain environment interaction and reward supervision, which prevents direct policy learning. To address this challenge, we propose Bridging Dynamics Gaps for Cross-Domain Reinforcement Learning (BDGxRL), a novel framework that leverages Diffusion Schr\u00f6dinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. Moreover, we introduce a reward modulation mechanism that estimates rewards based on state transitions, applying to DSB-aligned samples to ensure consistency between rewards and target-domain dynamics. BDGxRL performs target-oriented policy learning entirely within the source domain, without access to the target environment or its rewards. Experiments on MuJoCo cross-domain benchmarks demonstrate that BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts.", "AI": {"tldr": "\u63d0\u51faBDGxRL\u6846\u67b6\uff0c\u5229\u7528\u6269\u6563\u859b\u5b9a\u8c14\u6865\u5bf9\u9f50\u6e90\u57df\u548c\u76ee\u6807\u57df\u52a8\u6001\uff0c\u901a\u8fc7\u5956\u52b1\u8c03\u5236\u673a\u5236\u4f30\u8ba1\u5956\u52b1\uff0c\u5728\u6e90\u57df\u5185\u5b8c\u6210\u76ee\u6807\u5bfc\u5411\u7684\u7b56\u7565\u5b66\u4e60\uff0c\u65e0\u9700\u8bbf\u95ee\u76ee\u6807\u73af\u5883\u6216\u5956\u52b1\u4fe1\u53f7\u3002", "motivation": "\u8de8\u57df\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u662f\u7f3a\u4e4f\u76ee\u6807\u57df\u73af\u5883\u4ea4\u4e92\u548c\u5956\u52b1\u76d1\u7763\uff0c\u8fd9\u963b\u788d\u4e86\u76f4\u63a5\u7b56\u7565\u5b66\u4e60\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u5728\u6e90\u57df\u5185\u5b66\u4e60\u53ef\u8fc1\u79fb\u5230\u76ee\u6807\u57df\u7684\u7b56\u7565\u3002", "method": "\u63d0\u51faBDGxRL\u6846\u67b6\uff1a1) \u4f7f\u7528\u6269\u6563\u859b\u5b9a\u8c14\u6865\u5c06\u6e90\u57df\u8f6c\u79fb\u4e0e\u76ee\u6807\u57df\u79bb\u7ebf\u6f14\u793a\u7f16\u7801\u7684\u52a8\u6001\u5bf9\u9f50\uff1b2) \u5f15\u5165\u5956\u52b1\u8c03\u5236\u673a\u5236\uff0c\u57fa\u4e8e\u72b6\u6001\u8f6c\u79fb\u4f30\u8ba1\u5956\u52b1\uff0c\u5e94\u7528\u4e8eDSB\u5bf9\u9f50\u6837\u672c\uff0c\u786e\u4fdd\u5956\u52b1\u4e0e\u76ee\u6807\u57df\u52a8\u6001\u4e00\u81f4\u6027\u3002", "result": "\u5728MuJoCo\u8de8\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBDGxRL\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u8f6c\u79fb\u52a8\u6001\u53d8\u5316\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9002\u5e94\u80fd\u529b\u3002", "conclusion": "BDGxRL\u80fd\u591f\u5728\u65e0\u9700\u8bbf\u95ee\u76ee\u6807\u73af\u5883\u6216\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u6e90\u57df\u5185\u5b8c\u6210\u76ee\u6807\u5bfc\u5411\u7684\u7b56\u7565\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u57df\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u52a8\u6001\u5dee\u5f02\u95ee\u9898\u3002"}}
{"id": "2602.23761", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23761", "abs": "https://arxiv.org/abs/2602.23761", "authors": ["Yuyu Geng", "Lei Sun", "Yao Gao", "Xinxin Hu", "Zhonghua Yi", "Xiaolong Qian", "Weijian Hu", "Jian Bai", "Kaiwei Wang"], "title": "OPTIAGENT: A Physics-Driven Agentic Framework for Automated Optical Design", "comment": null, "summary": "Optical design is the process of configuring optical elements to precisely manipulate light for high-fidelity imaging. It is inherently a highly non-convex optimization problem that relies heavily on human heuristic expertise and domain-specific knowledge. While Large Language Models (LLMs) possess extensive optical knowledge, their capabilities in leveraging the knowledge in designing lens system remain significantly constrained. This work represents the first attempt to employ LLMs in the field of optical design. We bridge the expertise gap by enabling users without formal optical training to successfully develop functional lens systems. Concretely, we curate a comprehensive dataset, named OptiDesignQA, which encompasses both classical lens systems sourced from standard optical textbooks and novel configurations generated by automated design algorithms for training and evaluation. Furthermore, we inject domain-specific optical expertise into the LLM through a hybrid objective of full-system synthesis and lens completion. To align the model with optical principles, we employ Group Relative Policy Optimization Done Right (DrGRPO) guided by Optical Lexicographic Reward for physics-driven policy alignment. This reward system incorporates structural format rewards, physical feasibility rewards, light-manipulation accuracy, and LLM-based heuristics. Finally, our model integrates with specialized optical optimization routines for end-to-end fine-tuning and precision refinement. We benchmark our proposed method against both traditional optimization-based automated design algorithms and LLM counterparts, and experimental results show the superiority of our method.", "AI": {"tldr": "\u9996\u6b21\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u5149\u5b66\u8bbe\u8ba1\u9886\u57df\uff0c\u901a\u8fc7\u6df7\u5408\u8bad\u7ec3\u76ee\u6807\u548c\u7269\u7406\u9a71\u52a8\u7684\u7b56\u7565\u5bf9\u9f50\uff0c\u4f7f\u975e\u4e13\u4e1a\u7528\u6237\u80fd\u591f\u8bbe\u8ba1\u529f\u80fd\u6027\u900f\u955c\u7cfb\u7edf", "motivation": "\u5149\u5b66\u8bbe\u8ba1\u662f\u9ad8\u5ea6\u975e\u51f8\u7684\u4f18\u5316\u95ee\u9898\uff0c\u4e25\u91cd\u4f9d\u8d56\u4e13\u5bb6\u7ecf\u9a8c\u548c\u9886\u57df\u77e5\u8bc6\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u4e30\u5bcc\u7684\u5149\u5b66\u77e5\u8bc6\uff0c\u4f46\u5728\u900f\u955c\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u7136\u53d7\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8ba9\u6ca1\u6709\u6b63\u5f0f\u5149\u5b66\u8bad\u7ec3\u7684\u7528\u6237\u4e5f\u80fd\u6210\u529f\u5f00\u53d1\u529f\u80fd\u6027\u900f\u955c\u7cfb\u7edf\u3002", "method": "1. \u6784\u5efaOptiDesignQA\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ecf\u5178\u6559\u79d1\u4e66\u900f\u955c\u7cfb\u7edf\u548c\u81ea\u52a8\u8bbe\u8ba1\u7b97\u6cd5\u751f\u6210\u7684\u65b0\u914d\u7f6e\uff1b2. \u901a\u8fc7\u5168\u7cfb\u7edf\u5408\u6210\u548c\u900f\u955c\u8865\u5168\u7684\u6df7\u5408\u76ee\u6807\u5c06\u9886\u57df\u77e5\u8bc6\u6ce8\u5165LLM\uff1b3. \u4f7f\u7528DrGRPO\u7b97\u6cd5\u548c\u5149\u5b66\u8bcd\u5178\u5956\u52b1\u8fdb\u884c\u7269\u7406\u9a71\u52a8\u7684\u7b56\u7565\u5bf9\u9f50\uff1b4. \u4e0e\u4e13\u4e1a\u5149\u5b66\u4f18\u5316\u4f8b\u7a0b\u96c6\u6210\u8fdb\u884c\u7aef\u5230\u7aef\u5fae\u8c03\u548c\u7cbe\u5ea6\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4f20\u7edf\u4f18\u5316\u57fa\u81ea\u52a8\u8bbe\u8ba1\u7b97\u6cd5\u548cLLM\u5bf9\u6bd4\u65b9\u6cd5\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u80fd\u591f\u6709\u6548\u8bbe\u8ba1\u529f\u80fd\u6027\u900f\u955c\u7cfb\u7edf\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u6210\u529f\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u5149\u5b66\u8bbe\u8ba1\u9886\u57df\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u7b56\u7565\u548c\u7269\u7406\u5bf9\u9f50\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u5149\u5b66\u8bbe\u8ba1\u4e2d\u7684\u80fd\u529b\uff0c\u4e3a\u975e\u4e13\u4e1a\u7528\u6237\u53c2\u4e0e\u5149\u5b66\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2602.24195", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24195", "abs": "https://arxiv.org/abs/2602.24195", "authors": ["Gregory Kang Ruey Lau", "Hieu Dao", "Nicole Kan Hui Lin", "Bryan Kian Hsiang Low"], "title": "Uncertainty Quantification for Multimodal Large Language Models with Incoherence-adjusted Semantic Volume", "comment": "Earlier versions presented at ICLR 2025 QUESTION workshop and ICML 2025 R2-FM workshop", "summary": "Despite their capabilities, Multimodal Large Language Models (MLLMs) may produce plausible but erroneous outputs, hindering reliable deployment. Accurate uncertainty metrics could enable escalation of unreliable queries to human experts or larger models for improved performance. However, existing uncertainty metrics have practical constraints, such as being designed only for specific modalities, reliant on external tools, or computationally expensive. We introduce UMPIRE, a training-free uncertainty quantification framework for MLLMs that works efficiently across various input and output modalities without external tools, relying only on the models' own internal modality features. UMPIRE computes the incoherence-adjusted semantic volume of sampled MLLM responses for a given task instance, effectively capturing both the global semantic diversity of samples and the local incoherence of responses based on internal model confidence. We propose uncertainty desiderata for MLLMs and provide theoretical analysis motivating UMPIRE's design. Extensive experiments show that UMPIRE consistently outperforms baseline metrics in error detection and uncertainty calibration across image, audio, and video-text benchmarks, including adversarial and out-of-distribution settings. We also demonstrate UMPIRE's generalization to non-text output tasks, including image and audio generation.", "AI": {"tldr": "UMPIRE\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u7b97\u54cd\u5e94\u6837\u672c\u7684\u8bed\u4e49\u4f53\u79ef\u6765\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5404\u79cd\u6a21\u6001\u548c\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u4ea7\u751f\u770b\u4f3c\u5408\u7406\u4f46\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u5f71\u54cd\u53ef\u9760\u90e8\u7f72\u3002\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u6a21\u6001\u3001\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\u6216\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faUMPIRE\u6846\u67b6\uff0c\u65e0\u9700\u8bad\u7ec3\uff0c\u5229\u7528\u6a21\u578b\u5185\u90e8\u6a21\u6001\u7279\u5f81\uff0c\u8ba1\u7b97\u91c7\u6837\u54cd\u5e94\u7684\u4e0d\u8fde\u8d2f\u8c03\u6574\u8bed\u4e49\u4f53\u79ef\uff0c\u6355\u6349\u6837\u672c\u7684\u5168\u5c40\u8bed\u4e49\u591a\u6837\u6027\u548c\u57fa\u4e8e\u5185\u90e8\u6a21\u578b\u7f6e\u4fe1\u5ea6\u7684\u5c40\u90e8\u4e0d\u8fde\u8d2f\u6027\u3002", "result": "\u5728\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891-\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u5bf9\u6297\u6027\u548c\u5206\u5e03\u5916\u8bbe\u7f6e\uff09\u4e2d\uff0cUMPIRE\u5728\u9519\u8bef\u68c0\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u975e\u6587\u672c\u8f93\u51fa\u4efb\u52a1\uff08\u5982\u56fe\u50cf\u548c\u97f3\u9891\u751f\u6210\uff09\u3002", "conclusion": "UMPIRE\u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u901a\u7528\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\uff0c\u65e0\u9700\u5916\u90e8\u5de5\u5177\u6216\u8bad\u7ec3\uff0c\u5728\u5404\u79cd\u6a21\u6001\u548c\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u53ef\u9760\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2602.23770", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23770", "abs": "https://arxiv.org/abs/2602.23770", "authors": ["Chenxing Lin", "Xinhui Gao", "Haipeng Zhang", "Xinran Li", "Haitao Wang", "Songzhu Mei", "Chenglu Wen", "Weiquan Liu", "Siqi Shen", "Cheng Wang"], "title": "MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning", "comment": "ICLR2026", "summary": "Generative models have gained significant traction in offline reinforcement learning (RL) due to their ability to model complex trajectory distributions. However, existing generation-based approaches still struggle with long-horizon tasks characterized by sparse rewards. Some hierarchical generation methods have been developed to mitigate this issue by decomposing the original problem into shorter-horizon subproblems using one policy and generating detailed actions with another. While effective, these methods often overlook the multi-scale temporal structure inherent in trajectories, resulting in suboptimal performance. To overcome these limitations, we propose MAGE, a Multi-scale Autoregressive GEneration-based offline RL method. MAGE incorporates a condition-guided multi-scale autoencoder to learn hierarchical trajectory representations, along with a multi-scale transformer that autoregressively generates trajectory representations from coarse to fine temporal scales. MAGE effectively captures temporal dependencies of trajectories at multiple resolutions. Additionally, a condition-guided decoder is employed to exert precise control over short-term behaviors. Extensive experiments on five offline RL benchmarks against fifteen baseline algorithms show that MAGE successfully integrates multi-scale trajectory modeling with conditional guidance, generating coherent and controllable trajectories in long-horizon sparse-reward settings.", "AI": {"tldr": "MAGE\u662f\u4e00\u4e2a\u591a\u5c3a\u5ea6\u81ea\u56de\u5f52\u751f\u6210\u5f0f\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u8f68\u8ff9\u5efa\u6a21\u89e3\u51b3\u957f\u89c6\u91ce\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e2d\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u957f\u89c6\u91ce\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4f20\u7edf\u5206\u5c42\u751f\u6210\u65b9\u6cd5\u5ffd\u7565\u4e86\u8f68\u8ff9\u56fa\u6709\u7684\u591a\u5c3a\u5ea6\u65f6\u95f4\u7ed3\u6784\uff0c\u5bfc\u81f4\u6027\u80fd\u6b21\u4f18\u3002", "method": "MAGE\u5305\u542b\u6761\u4ef6\u5f15\u5bfc\u7684\u591a\u5c3a\u5ea6\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u5206\u5c42\u8f68\u8ff9\u8868\u793a\uff0c\u4ee5\u53ca\u591a\u5c3a\u5ea6Transformer\u4ece\u7c97\u5230\u7ec6\u7684\u65f6\u95f4\u5c3a\u5ea6\u81ea\u56de\u5f52\u751f\u6210\u8f68\u8ff9\u8868\u793a\uff0c\u5e76\u4f7f\u7528\u6761\u4ef6\u5f15\u5bfc\u89e3\u7801\u5668\u7cbe\u786e\u63a7\u5236\u77ed\u671f\u884c\u4e3a\u3002", "result": "\u5728\u4e94\u4e2a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0e\u5341\u4e94\u4e2a\u57fa\u7ebf\u7b97\u6cd5\u5bf9\u6bd4\uff0cMAGE\u6210\u529f\u5c06\u591a\u5c3a\u5ea6\u8f68\u8ff9\u5efa\u6a21\u4e0e\u6761\u4ef6\u5f15\u5bfc\u76f8\u7ed3\u5408\uff0c\u5728\u957f\u89c6\u91ce\u7a00\u758f\u5956\u52b1\u8bbe\u7f6e\u4e2d\u751f\u6210\u8fde\u8d2f\u53ef\u63a7\u7684\u8f68\u8ff9\u3002", "conclusion": "MAGE\u901a\u8fc7\u591a\u5c3a\u5ea6\u81ea\u56de\u5f52\u751f\u6210\u65b9\u6cd5\u6709\u6548\u6355\u6349\u8f68\u8ff9\u7684\u591a\u5206\u8fa8\u7387\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u957f\u89c6\u91ce\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2602.24273", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24273", "abs": "https://arxiv.org/abs/2602.24273", "authors": ["Borja Requena Pozo", "Austin Letson", "Krystian Nowakowski", "Izan Beltran Ferreiro", "Leopoldo Sarra"], "title": "A Minimal Agent for Automated Theorem Proving", "comment": null, "summary": "We propose a minimal agentic baseline that enables systematic comparison across different AI-based theorem prover architectures. This design implements the core features shared among state-of-the-art systems: iterative proof refinement, library search and context management. We evaluate our baseline using qualitatively different benchmarks and compare various popular models and design choices, and demonstrate competitive performance compared to state-of-the-art approaches, while using a significantly simpler architecture. Our results demonstrate consistent advantages of an iterative approach over multiple single-shot generations, especially in terms of sample efficiency and cost effectiveness. The implementation is released open-source as a candidate reference for future research and as an accessible prover for the community.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6700\u5c0f\u5316\u7684\u5b9a\u7406\u8bc1\u660e\u57fa\u51c6\u7cfb\u7edf\uff0c\u7528\u4e8e\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540cAI\u5b9a\u7406\u8bc1\u660e\u5668\u67b6\u6784\uff0c\u5c55\u793a\u8fed\u4ee3\u65b9\u6cd5\u76f8\u6bd4\u5355\u6b21\u751f\u6210\u7684\u4f18\u8d8a\u6027", "motivation": "\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u57fa\u51c6\u7cfb\u7edf\u6765\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540cAI\u5b9a\u7406\u8bc1\u660e\u5668\u67b6\u6784\uff0c\u5f53\u524d\u7f3a\u4e4f\u7edf\u4e00\u7684\u6bd4\u8f83\u6846\u67b6", "method": "\u8bbe\u8ba1\u5b9e\u73b0\u5305\u542b\u8fed\u4ee3\u8bc1\u660e\u7cbe\u70bc\u3001\u5e93\u641c\u7d22\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b49\u6838\u5fc3\u529f\u80fd\u7684\u6700\u5c0f\u5316\u57fa\u51c6\u7cfb\u7edf\uff0c\u4f7f\u7528\u4e0d\u540c\u57fa\u51c6\u8bc4\u4f30\u5404\u79cd\u6d41\u884c\u6a21\u578b\u548c\u8bbe\u8ba1\u9009\u62e9", "result": "\u57fa\u51c6\u7cfb\u7edf\u5728\u6027\u80fd\u4e0a\u53ef\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7ade\u4e89\uff0c\u540c\u65f6\u67b6\u6784\u663e\u8457\u7b80\u5316\uff1b\u8fed\u4ee3\u65b9\u6cd5\u5728\u6837\u672c\u6548\u7387\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u591a\u6b21\u5355\u6b21\u751f\u6210", "conclusion": "\u8fed\u4ee3\u65b9\u6cd5\u5728AI\u5b9a\u7406\u8bc1\u660e\u4e2d\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u5f00\u6e90\u5b9e\u73b0\u53ef\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u7684\u53c2\u8003\u57fa\u51c6\u548c\u793e\u533a\u53ef\u8bbf\u95ee\u7684\u8bc1\u660e\u5668"}}
{"id": "2602.23785", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23785", "abs": "https://arxiv.org/abs/2602.23785", "authors": ["Zhiwei Han", "Stefan Matthes", "Hao Shen"], "title": "Provable Subspace Identification of Nonlinear Multi-view CCA", "comment": null, "summary": "We investigate the identifiability of nonlinear Canonical Correlation Analysis (CCA) in a multi-view setup, where each view is generated by an unknown nonlinear map applied to a linear mixture of shared latents and view-private noise. Rather than attempting exact unmixing, a problem proven to be ill-posed, we instead reframe multi-view CCA as a basis-invariant subspace identification problem. We prove that, under suitable latent priors and spectral separation conditions, multi-view CCA recovers the pairwise correlated signal subspaces up to view-wise orthogonal ambiguity. For $N \\geq 3$ views, the objective provably isolates the jointly correlated subspaces shared across all views while eliminating view-private variations. We further establish finite-sample consistency guarantees by translating the concentration of empirical cross-covariances into explicit subspace error bounds via spectral perturbation theory. Experiments on synthetic and rendered image datasets validate our theoretical findings and confirm the necessity of the assumed conditions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u591a\u89c6\u89d2\u975e\u7ebf\u6027\u5178\u578b\u76f8\u5173\u5206\u6790\uff08CCA\uff09\u7684\u53ef\u8bc6\u522b\u6027\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u591a\u89c6\u89d2\u8bbe\u7f6e\u4e0b\uff0c\u5373\u4f7f\u5b58\u5728\u975e\u7ebf\u6027\u6620\u5c04\uff0cCCA\u4ecd\u80fd\u6062\u590d\u5171\u4eab\u7684\u6f5c\u5728\u5b50\u7a7a\u95f4\uff0c\u4f46\u5b58\u5728\u89c6\u89d2\u95f4\u7684\u6b63\u4ea4\u6a21\u7cca\u6027\u3002", "motivation": "\u4f20\u7edf\u975e\u7ebf\u6027CCA\u7684\u7cbe\u786e\u89e3\u6df7\u88ab\u8bc1\u660e\u662f\u75c5\u6001\u95ee\u9898\uff0c\u4f5c\u8005\u5e0c\u671b\u91cd\u65b0\u6784\u5efa\u591a\u89c6\u89d2CCA\u4f5c\u4e3a\u4e00\u4e2a\u57fa\u4e0d\u53d8\u5b50\u7a7a\u95f4\u8bc6\u522b\u95ee\u9898\uff0c\u63a2\u7d22\u5728\u4ec0\u4e48\u6761\u4ef6\u4e0b\u80fd\u591f\u8bc6\u522b\u51fa\u5171\u4eab\u7684\u6f5c\u5728\u7ed3\u6784\u3002", "method": "\u5c06\u591a\u89c6\u89d2CCA\u91cd\u65b0\u5b9a\u4e49\u4e3a\u57fa\u4e0d\u53d8\u5b50\u7a7a\u95f4\u8bc6\u522b\u95ee\u9898\uff0c\u5728\u9002\u5f53\u7684\u6f5c\u5728\u5148\u9a8c\u548c\u8c31\u5206\u79bb\u6761\u4ef6\u4e0b\uff0c\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u591a\u89c6\u89d2CCA\u80fd\u591f\u6062\u590d\u6210\u5bf9\u76f8\u5173\u7684\u4fe1\u53f7\u5b50\u7a7a\u95f4\u3002\u5bf9\u4e8eN\u22653\u4e2a\u89c6\u89d2\uff0c\u76ee\u6807\u51fd\u6570\u80fd\u591f\u5206\u79bb\u51fa\u6240\u6709\u89c6\u89d2\u5171\u4eab\u7684\u8054\u5408\u76f8\u5173\u5b50\u7a7a\u95f4\uff0c\u540c\u65f6\u6d88\u9664\u89c6\u89d2\u79c1\u6709\u53d8\u5f02\u3002", "result": "\u8bc1\u660e\u4e86\u591a\u89c6\u89d2CCA\u80fd\u591f\u6062\u590d\u6210\u5bf9\u76f8\u5173\u7684\u4fe1\u53f7\u5b50\u7a7a\u95f4\uff0c\u4f46\u5b58\u5728\u89c6\u89d2\u95f4\u7684\u6b63\u4ea4\u6a21\u7cca\u6027\u3002\u5bf9\u4e8e\u4e09\u4e2a\u6216\u66f4\u591a\u89c6\u89d2\uff0c\u80fd\u591f\u8bc6\u522b\u51fa\u6240\u6709\u89c6\u89d2\u5171\u4eab\u7684\u8054\u5408\u76f8\u5173\u5b50\u7a7a\u95f4\u3002\u901a\u8fc7\u8c31\u6270\u52a8\u7406\u8bba\u5efa\u7acb\u4e86\u6709\u9650\u6837\u672c\u4e00\u81f4\u6027\u4fdd\u8bc1\uff0c\u5c06\u7ecf\u9a8c\u4ea4\u53c9\u534f\u65b9\u5dee\u7684\u96c6\u4e2d\u6027\u8f6c\u5316\u4e3a\u660e\u786e\u7684\u5b50\u7a7a\u95f4\u8bef\u5dee\u754c\u9650\u3002", "conclusion": "\u591a\u89c6\u89d2\u975e\u7ebf\u6027CCA\u5728\u9002\u5f53\u7684\u6761\u4ef6\u4e0b\u662f\u53ef\u8bc6\u522b\u7684\uff0c\u80fd\u591f\u6062\u590d\u5171\u4eab\u7684\u6f5c\u5728\u5b50\u7a7a\u95f4\u7ed3\u6784\uff0c\u4f46\u5b58\u5728\u89c6\u89d2\u95f4\u7684\u6b63\u4ea4\u6a21\u7cca\u6027\u3002\u7406\u8bba\u7ed3\u679c\u5728\u5408\u6210\u548c\u6e32\u67d3\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u5e76\u786e\u8ba4\u4e86\u5047\u8bbe\u6761\u4ef6\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2602.23789", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23789", "abs": "https://arxiv.org/abs/2602.23789", "authors": ["Aleksandr Ananikian", "Daniil Drozdov", "Konstantin Yakovlev"], "title": "UPath: Universal Planner Across Topological Heterogeneity For Grid-Based Pathfinding", "comment": null, "summary": "The performance of search algorithms for grid-based pathfinding, e.g. A*, critically depends on the heuristic function that is used to focus the search. Recent studies have shown that informed heuristics that take the positions/shapes of the obstacles into account can be approximated with the deep neural networks. Unfortunately, the existing learning-based approaches mostly rely on the assumption that training and test grid maps are drawn from the same distribution (e.g., city maps, indoor maps, etc.) and perform poorly on out-of-distribution tasks. This naturally limits their application in practice when often a universal solver is needed that is capable of efficiently handling any problem instance. In this work, we close this gap by designing an universal heuristic predictor: a model trained once, but capable of generalizing across a full spectrum of unseen tasks. Our extensive empirical evaluation shows that the suggested approach halves the computational effort of A* by up to a factor of 2.2, while still providing solutions within 3% of the optimal cost on average altogether on the tasks that are completely different from the ones used for training $\\unicode{x2013}$ a milestone reached for the first time by a learnable solver.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u542f\u53d1\u5f0f\u9884\u6d4b\u5668\uff0c\u80fd\u591f\u8bad\u7ec3\u4e00\u6b21\u5373\u53ef\u6cdb\u5316\u5230\u5404\u79cd\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347A*\u7b97\u6cd5\u5728\u7f51\u683c\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5b66\u4e60\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7f51\u683c\u5730\u56fe\u6765\u81ea\u76f8\u540c\u5206\u5e03\uff08\u5982\u57ce\u5e02\u5730\u56fe\u3001\u5ba4\u5185\u5730\u56fe\u7b49\uff09\uff0c\u5728\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u901a\u7528\u6c42\u89e3\u5668\u7684\u9700\u6c42\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u542f\u53d1\u5f0f\u9884\u6d4b\u5668\u6a21\u578b\uff0c\u901a\u8fc7\u4e00\u6b21\u8bad\u7ec3\u5c31\u80fd\u6cdb\u5316\u5230\u5b8c\u5168\u4e0d\u540c\u7684\u672a\u89c1\u4efb\u52a1\u4e0a\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u5206\u5e03\u4e00\u81f4\u6027\u7684\u4f9d\u8d56\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u5c06A*\u7b97\u6cd5\u7684\u8ba1\u7b97\u91cf\u51cf\u5c11\u4e86\u9ad8\u8fbe2.2\u500d\uff0c\u540c\u65f6\u5728\u5b8c\u5168\u4e0d\u540c\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u4efb\u52a1\u4e0a\uff0c\u5e73\u5747\u4ecd\u80fd\u63d0\u4f9b\u4e0e\u6700\u4f18\u89e3\u6210\u672c\u76f8\u5dee3%\u4ee5\u5185\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u901a\u8fc7\u53ef\u5b66\u4e60\u6c42\u89e3\u5668\u5b9e\u73b0\u5728\u5b8c\u5168\u4e0d\u540c\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u4efb\u52a1\u4e0a\u8fbe\u5230\u8fd9\u4e00\u91cc\u7a0b\u7891\uff0c\u4e3a\u901a\u7528\u8def\u5f84\u89c4\u5212\u6c42\u89e3\u5668\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u7a81\u7834\u3002"}}
{"id": "2602.23795", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23795", "abs": "https://arxiv.org/abs/2602.23795", "authors": ["Wenwu Tang", "Dong Wang", "Lothar Thiele", "Olga Saukh"], "title": "GRAIL: Post-hoc Compensation by Linear Reconstruction for Compressed Networks", "comment": "Conference on Parsimony and Learning (CPAL)", "summary": "Structured deep model compression methods are hardware-friendly and substantially reduce memory and inference costs. However, under aggressive compression, the resulting accuracy degradation often necessitates post-compression finetuning, which can be impractical due to missing labeled data or high training cost. We propose post-hoc blockwise compensation, called GRAIL, a simple zero-finetuning step applied after model compression that restores each block's input-output behavior using a small calibration set. The method summarizes hidden activations via a Gram matrix and applies ridge regression to linearly reconstruct the original hidden representation from the reduced one. The resulting reconstruction map is absorbed into the downstream projection weights, while the upstream layer is compressed. The approach is selector-agnostic (Magnitude, Wanda, Gram-based selection, or folding), data-aware (requiring only a few forward passes without gradients or labels), and recovers classic pruning or folding when the Gram matrix is near identity, indicating weak inter-channel correlations. Across ResNets, ViTs, and decoder-only LLMs, GRAIL consistently improves accuracy or perplexity over data-free and data-aware pruning or folding baselines in practical compression regimes, with manageable overhead and no backpropagation. The code is available at https://github.com/TWWinde/GRAIL.", "AI": {"tldr": "GRAIL\u662f\u4e00\u79cd\u65e0\u9700\u5fae\u8c03\u7684\u540e\u5904\u7406\u5757\u8865\u507f\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c0f\u89c4\u6a21\u6821\u51c6\u96c6\u6062\u590d\u538b\u7f29\u6a21\u578b\u7684\u5757\u7ea7\u8f93\u5165\u8f93\u51fa\u884c\u4e3a\uff0c\u4f7f\u7528Gram\u77e9\u9635\u548c\u5cad\u56de\u5f52\u7ebf\u6027\u91cd\u5efa\u9690\u85cf\u8868\u793a\uff0c\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u538b\u7f29\u9009\u62e9\u5668\u3002", "motivation": "\u7ed3\u6784\u5316\u6df1\u5ea6\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\u867d\u7136\u786c\u4ef6\u53cb\u597d\u4e14\u80fd\u663e\u8457\u964d\u4f4e\u5185\u5b58\u548c\u63a8\u7406\u6210\u672c\uff0c\u4f46\u5728\u6fc0\u8fdb\u538b\u7f29\u4e0b\u4f1a\u5bfc\u81f4\u7cbe\u5ea6\u4e0b\u964d\uff0c\u800c\u540e\u7eed\u5fae\u8c03\u53ef\u80fd\u56e0\u7f3a\u5c11\u6807\u6ce8\u6570\u636e\u6216\u8bad\u7ec3\u6210\u672c\u9ad8\u800c\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u63d0\u51faGRAIL\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u5c0f\u6821\u51c6\u96c6\u603b\u7ed3\u9690\u85cf\u6fc0\u6d3b\u7684Gram\u77e9\u9635\uff1b2\uff09\u5e94\u7528\u5cad\u56de\u5f52\u4ece\u538b\u7f29\u540e\u7684\u9690\u85cf\u8868\u793a\u7ebf\u6027\u91cd\u5efa\u539f\u59cb\u8868\u793a\uff1b3\uff09\u5c06\u91cd\u5efa\u6620\u5c04\u5438\u6536\u5230\u4e0b\u6e38\u6295\u5f71\u6743\u91cd\u4e2d\uff0c\u540c\u65f6\u538b\u7f29\u4e0a\u6e38\u5c42\u3002", "result": "\u5728ResNets\u3001ViTs\u548c\u89e3\u7801\u5668LLMs\u4e0a\uff0cGRAIL\u5728\u5b9e\u7528\u538b\u7f29\u8303\u56f4\u5185\u6301\u7eed\u63d0\u5347\u6570\u636e\u65e0\u5173\u548c\u6570\u636e\u611f\u77e5\u7684\u526a\u679d\u6216\u6298\u53e0\u57fa\u7ebf\u7684\u7cbe\u5ea6\u6216\u56f0\u60d1\u5ea6\uff0c\u5f00\u9500\u53ef\u63a7\u4e14\u65e0\u9700\u53cd\u5411\u4f20\u64ad\u3002", "conclusion": "GRAIL\u662f\u4e00\u79cd\u7b80\u5355\u3001\u65e0\u9700\u5fae\u8c03\u7684\u540e\u5904\u7406\u8865\u507f\u65b9\u6cd5\uff0c\u5bf9\u538b\u7f29\u9009\u62e9\u5668\u65e0\u5173\uff0c\u4ec5\u9700\u5c11\u91cf\u524d\u5411\u4f20\u64ad\u65e0\u9700\u68af\u5ea6\u6216\u6807\u7b7e\uff0c\u80fd\u6709\u6548\u6062\u590d\u538b\u7f29\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2602.23798", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23798", "abs": "https://arxiv.org/abs/2602.23798", "authors": ["Tiantong Wang", "Xinyu Yan", "Tiantong Wu", "Yurong Hao", "Yong Jiang", "Fei Huang", "Wei Yang Bryan Lim"], "title": "MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models", "comment": null, "summary": "Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU.", "AI": {"tldr": "MPU\u662f\u4e00\u79cd\u7b97\u6cd5\u65e0\u5173\u7684\u9690\u79c1\u4fdd\u62a4\u591a\u6270\u52a8\u526f\u672c\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u670d\u52a1\u5668\u7aef\u9884\u5904\u7406\u7684\u968f\u673a\u526f\u672c\u751f\u6210\u548c\u540e\u5904\u7406\u7684\u66f4\u65b0\u805a\u5408\uff0c\u5728\u53cc\u91cd\u975e\u62ab\u9732\u7ea6\u675f\u4e0b\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u673a\u5668\u9057\u5fd8\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u673a\u5668\u9057\u5fd8\u9762\u4e34\u9690\u79c1\u56f0\u5883\uff1a\u4e25\u683c\u7ea6\u675f\u7981\u6b62\u5171\u4eab\u670d\u52a1\u5668\u53c2\u6570\u6216\u5ba2\u6237\u7aef\u9057\u5fd8\u96c6\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u79cd\u53cc\u91cd\u975e\u62ab\u9732\u7ea6\u675f\uff0c\u8ba9\u5ba2\u6237\u7aef\u80fd\u5728\u672c\u5730\u79c1\u6709\u9057\u5fd8\u96c6\u4e0a\u6267\u884c\u9057\u5fd8\uff0c\u540c\u65f6\u4e0d\u8bbf\u95ee\u670d\u52a1\u5668\u7684\u786e\u5207\u539f\u59cb\u53c2\u6570\u3002", "method": "\u63d0\u51faMPU\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u670d\u52a1\u5668\u7aef\u6a21\u5757\uff1a1)\u9884\u5904\u7406\uff1a\u670d\u52a1\u5668\u5206\u53d1\u591a\u4e2a\u6270\u52a8\u548c\u91cd\u53c2\u6570\u5316\u7684\u6a21\u578b\u5b9e\u4f8b\uff1b2)\u540e\u5904\u7406\uff1a\u5ba2\u6237\u7aef\u672c\u5730\u6267\u884c\u9057\u5fd8\u540e\uff0c\u670d\u52a1\u5668\u53cd\u8f6c\u91cd\u53c2\u6570\u5316\u5e76\u901a\u8fc7\u8c10\u6ce2\u53bb\u566a\u8fc7\u7a0b\u805a\u5408\u66f4\u65b0\u4ee5\u51cf\u8f7b\u6270\u52a8\u5f71\u54cd\u3002", "result": "\u5728\u4e03\u79cd\u9057\u5fd8\u7b97\u6cd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMPU\u572810%\u566a\u58f0\u4e0b\u8fbe\u5230\u4e0e\u65e0\u566a\u58f0\u57fa\u7ebf\u76f8\u5f53\u7684\u9057\u5fd8\u6027\u80fd\uff0c\u5927\u591a\u6570\u7b97\u6cd5\u7684\u5e73\u5747\u6027\u80fd\u4e0b\u964d\u8fdc\u4f4e\u4e8e1%\uff0c\u57281%\u566a\u58f0\u4e0b\u67d0\u4e9b\u7b97\u6cd5\u751a\u81f3\u80fd\u8d85\u8d8a\u65e0\u566a\u58f0\u57fa\u7ebf\u3002", "conclusion": "MPU\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u673a\u5668\u9057\u5fd8\u4e2d\u7684\u53cc\u91cd\u9690\u79c1\u7ea6\u675f\u95ee\u9898\uff0c\u901a\u8fc7\u6270\u52a8\u526f\u672c\u548c\u805a\u5408\u673a\u5236\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0b\u7684\u9ad8\u6548\u9057\u5fd8\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23811", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23811", "abs": "https://arxiv.org/abs/2602.23811", "authors": ["Xiang Li", "Nan Jiang", "Yuheng Zhang"], "title": "Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies", "comment": null, "summary": "We investigate the theoretical aspects of offline reinforcement learning (RL) under general function approximation. While prior works (e.g., Xie et al., 2021) have established the theoretical foundations of learning a good policy from offline data via pessimism, existing algorithms that are computationally tractable (often in an oracle-efficient sense), such as PSPI, only apply to finite and small action spaces. Moreover, these algorithms rely on state-wise mirror descent and require actors to be implicitly induced from the critic functions, failing to accommodate standalone policy parameterization which is ubiquitous in practice. In this work, we address these limitations and extend the theoretical guarantees to parameterized policy classes over large or continuous action spaces. When extending mirror descent to parameterized policies, we identify contextual coupling as the core difficulty, and show how connecting mirror descent to natural policy gradient leads to novel analyses, guarantees, and algorithmic insights, including a surprising unification between offline RL and imitation learning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u4e00\u822c\u51fd\u6570\u903c\u8fd1\u4e0b\u7684\u7406\u8bba\u95ee\u9898\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7b97\u6cd5\u53ea\u80fd\u5904\u7406\u6709\u9650\u5c0f\u52a8\u4f5c\u7a7a\u95f4\u3001\u65e0\u6cd5\u9002\u5e94\u72ec\u7acb\u7b56\u7565\u53c2\u6570\u5316\u7684\u5c40\u9650\u6027\uff0c\u5c06\u7406\u8bba\u4fdd\u8bc1\u6269\u5c55\u5230\u5927\u89c4\u6a21\u6216\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u7684\u53c2\u6570\u5316\u7b56\u7565\u7c7b\u3002", "motivation": "\u73b0\u6709\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a1\uff09\u8ba1\u7b97\u53ef\u884c\u7684\u7b97\u6cd5\uff08\u5982PSPI\uff09\u4ec5\u9002\u7528\u4e8e\u6709\u9650\u5c0f\u52a8\u4f5c\u7a7a\u95f4\uff1b2\uff09\u8fd9\u4e9b\u7b97\u6cd5\u4f9d\u8d56\u72b6\u6001\u7ea7\u955c\u50cf\u4e0b\u964d\uff0c\u9700\u8981\u4ece\u4ef7\u503c\u51fd\u6570\u9690\u5f0f\u63a8\u5bfc\u7b56\u7565\uff0c\u65e0\u6cd5\u9002\u5e94\u5b9e\u8df5\u4e2d\u666e\u904d\u4f7f\u7528\u7684\u72ec\u7acb\u7b56\u7565\u53c2\u6570\u5316\u3002", "method": "\u901a\u8fc7\u5c06\u955c\u50cf\u4e0b\u964d\u6269\u5c55\u5230\u53c2\u6570\u5316\u7b56\u7565\uff0c\u8bc6\u522b\u4e0a\u4e0b\u6587\u8026\u5408\u4e3a\u6838\u5fc3\u96be\u70b9\uff0c\u5e76\u5c06\u955c\u50cf\u4e0b\u964d\u4e0e\u81ea\u7136\u7b56\u7565\u68af\u5ea6\u8fde\u63a5\u8d77\u6765\uff0c\u4ece\u800c\u83b7\u5f97\u65b0\u7684\u5206\u6790\u3001\u7406\u8bba\u4fdd\u8bc1\u548c\u7b97\u6cd5\u89c1\u89e3\uff0c\u5305\u62ec\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0e\u6a21\u4eff\u5b66\u4e60\u7684\u7edf\u4e00\u3002", "result": "\u6210\u529f\u5c06\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u7406\u8bba\u4fdd\u8bc1\u6269\u5c55\u5230\u53c2\u6570\u5316\u7b56\u7565\u7c7b\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6216\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5e76\u5efa\u7acb\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0e\u6a21\u4eff\u5b66\u4e60\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\u3002", "conclusion": "\u901a\u8fc7\u8fde\u63a5\u955c\u50cf\u4e0b\u964d\u548c\u81ea\u7136\u7b56\u7565\u68af\u5ea6\uff0c\u89e3\u51b3\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u53c2\u6570\u5316\u7b56\u7565\u7684\u7406\u8bba\u6311\u6218\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u5e76\u63ed\u793a\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0e\u6a21\u4eff\u5b66\u4e60\u4e4b\u95f4\u7684\u6df1\u523b\u8054\u7cfb\u3002"}}
{"id": "2602.23816", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23816", "abs": "https://arxiv.org/abs/2602.23816", "authors": ["George Papadopoulos", "George A. Vouros"], "title": "Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective", "comment": "Accepted for publication at AAMAS 2026", "summary": "Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps. Having these objectives, we aim towards learning a policy that maximizes the probability of the most $promising$ trajectories with respect to the demonstrations. In so doing, we formulate the ``promise\" of individual state-action pairs in terms of $Q$ values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. This entails a safe Q-learning perspective of the inverse learning problem under constraints: The devised Safe $Q$ Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits.", "AI": {"tldr": "\u63d0\u51faSafeQIL\u7b97\u6cd5\uff0c\u5728\u672a\u77e5\u7ea6\u675f\u7684MDP\u4e2d\u4ece\u8f68\u8ff9\u6f14\u793a\u5b66\u4e60\u7b56\u7565\uff0c\u5e73\u8861\u5956\u52b1\u6700\u5927\u5316\u4e0e\u5b89\u5168\u6027\uff0c\u901a\u8fc7Q\u503c\u8bc4\u4f30\u72b6\u6001-\u52a8\u4f5c\u5bf9\u7684\"\u627f\u8bfa\u5ea6\"\u3002", "motivation": "\u5728\u5177\u6709\u53ef\u89c2\u6d4b\u5956\u52b1\u4f46\u7ea6\u675f\u672a\u77e5\u3001\u6210\u672c\u4e0d\u53ef\u89c2\u6d4b\u7684\u53d7\u9650MDP\u4e2d\uff0c\u4ece\u5b89\u5168\u6267\u884c\u4efb\u52a1\u7684\u8f68\u8ff9\u6f14\u793a\u5b66\u4e60\u7b56\u7565\uff0c\u9700\u8981\u5728\u4fdd\u5b88\u6027\u4e0e\u9ad8\u5956\u52b1\u8f68\u8ff9\u53ef\u80fd\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "method": "\u63d0\u51faSafeQIL\u7b97\u6cd5\uff0c\u901a\u8fc7Q\u503c\u91cf\u5316\u72b6\u6001-\u52a8\u4f5c\u5bf9\u7684\"\u627f\u8bfa\u5ea6\"\uff0c\u7ed3\u5408\u4efb\u52a1\u7279\u5b9a\u5956\u52b1\u548c\u72b6\u6001\u5b89\u5168\u6027\u8bc4\u4f30\uff0c\u5b9e\u73b0\u5b89\u5168Q\u5b66\u4e60\u7684\u9006\u5f3a\u5316\u5b66\u4e60\u89c6\u89d2\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u4efb\u52a1\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u9006\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u5c55\u793a\u4e86SafeQIL\u7b97\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "SafeQIL\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5b66\u4e60\u6700\u5927\u5316\u6709\"\u627f\u8bfa\"\u8f68\u8ff9\u6982\u7387\u7684\u7b56\u7565\uff0c\u5728\u5956\u52b1\u671f\u671b\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2602.23824", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23824", "abs": "https://arxiv.org/abs/2602.23824", "authors": ["Pavlin G. Poli\u010dar", "Dalibor Stanimirovi\u0107", "Bla\u017e Zupan"], "title": "Inferring Chronic Treatment Onset from ePrescription Data: A Renewal Process Approach", "comment": null, "summary": "Longitudinal electronic health record (EHR) data are often left-censored, making diagnosis records incomplete and unreliable for determining disease onset. In contrast, outpatient prescriptions form renewal-based trajectories that provide a continuous signal of disease management. We propose a probabilistic framework to infer chronic treatment onset by modeling prescription dynamics as a renewal process and detecting transitions from sporadic to sustained therapy via change-point detection between a baseline Poisson (sporadic prescribing) regime and a regime-specific Weibull (sustained therapy) renewal model. Using a nationwide ePrescription dataset of 2.4 million individuals, we show that the approach yields more temporally plausible onset estimates than naive rule-based triggering, substantially reducing implausible early detections under strong left censoring. Detection performance varies across diseases and is strongly associated with prescription density, highlighting both the strengths and limits of treatment-based onset inference.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5904\u65b9\u52a8\u6001\u7684\u6162\u6027\u75c5\u6cbb\u7597\u8d77\u59cb\u65f6\u95f4\u63a8\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u5904\u65b9\u66f4\u65b0\u8fc7\u7a0b\u68c0\u6d4b\u4ece\u5076\u53d1\u6027\u5230\u6301\u7eed\u6027\u6cbb\u7597\u7684\u8f6c\u53d8\u70b9", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u5e38\u5b58\u5728\u5de6\u622a\u65ad\u95ee\u9898\uff0c\u5bfc\u81f4\u8bca\u65ad\u8bb0\u5f55\u4e0d\u5b8c\u6574\u4e14\u4e0d\u53ef\u9760\uff0c\u800c\u95e8\u8bca\u5904\u65b9\u5f62\u6210\u7684\u66f4\u65b0\u8f68\u8ff9\u80fd\u63d0\u4f9b\u75be\u75c5\u7ba1\u7406\u7684\u8fde\u7eed\u4fe1\u53f7", "method": "\u63d0\u51fa\u6982\u7387\u6846\u67b6\uff0c\u5c06\u5904\u65b9\u52a8\u6001\u5efa\u6a21\u4e3a\u66f4\u65b0\u8fc7\u7a0b\uff0c\u901a\u8fc7\u53d8\u5316\u70b9\u68c0\u6d4b\u533a\u5206\u5076\u53d1\u6027\u5904\u65b9\uff08\u6cca\u677e\u57fa\u7ebf\uff09\u548c\u6301\u7eed\u6027\u6cbb\u7597\uff08\u5a01\u5e03\u5c14\u66f4\u65b0\u6a21\u578b\uff09\u4e24\u79cd\u673a\u5236", "result": "\u5728\u5168\u56fd240\u4e07\u4eba\u7684\u7535\u5b50\u5904\u65b9\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u57fa\u4e8e\u89c4\u5219\u7684\u7b80\u5355\u89e6\u53d1\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u5408\u7406\u7684\u65f6\u95f4\u8d77\u59cb\u4f30\u8ba1\uff0c\u663e\u8457\u51cf\u5c11\u5de6\u622a\u65ad\u4e0b\u7684\u4e0d\u5408\u7406\u65e9\u671f\u68c0\u6d4b", "conclusion": "\u68c0\u6d4b\u6027\u80fd\u56e0\u75be\u75c5\u800c\u5f02\uff0c\u4e0e\u5904\u65b9\u5bc6\u5ea6\u5bc6\u5207\u76f8\u5173\uff0c\u63ed\u793a\u4e86\u57fa\u4e8e\u6cbb\u7597\u7684\u8d77\u59cb\u65f6\u95f4\u63a8\u65ad\u65b9\u6cd5\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027"}}
{"id": "2602.23827", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23827", "abs": "https://arxiv.org/abs/2602.23827", "authors": ["Junkang Liu", "Fanhua Shang", "Yuxuan Tian", "Hongying Liu", "Yuanyuan Liu"], "title": "FedNSAM:Consistency of Local and Global Flatness for Federated Learning", "comment": null, "summary": "In federated learning (FL), multi-step local updates and data heterogeneity usually lead to sharper global minima, which degrades the performance of the global model. Popular FL algorithms integrate sharpness-aware minimization (SAM) into local training to address this issue. However, in the high data heterogeneity setting, the flatness in local training does not imply the flatness of the global model. Therefore, minimizing the sharpness of the local loss surfaces on the client data does not enable the effectiveness of SAM in FL to improve the generalization ability of the global model. We define the \\textbf{flatness distance} to explain this phenomenon. By rethinking the SAM in FL and theoretically analyzing the \\textbf{flatness distance}, we propose a novel \\textbf{FedNSAM} algorithm that accelerates the SAM algorithm by introducing global Nesterov momentum into the local update to harmonize the consistency of global and local flatness. \\textbf{FedNSAM} uses the global Nesterov momentum as the direction of local estimation of client global perturbations and extrapolation. Theoretically, we prove a tighter convergence bound than FedSAM by Nesterov extrapolation. Empirically, we conduct comprehensive experiments on CNN and Transformer models to verify the superior performance and efficiency of \\textbf{FedNSAM}. The code is available at https://github.com/junkangLiu0/FedNSAM.", "AI": {"tldr": "FedNSAM\u7b97\u6cd5\u901a\u8fc7\u5f15\u5165\u5168\u5c40Nesterov\u52a8\u91cf\u6765\u534f\u8c03\u5168\u5c40\u548c\u5c40\u90e8\u5e73\u5766\u5ea6\u4e00\u81f4\u6027\uff0c\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5f02\u6784\u6027\u5bfc\u81f4\u5c40\u90e8\u5e73\u5766\u5ea6\u4e0e\u5168\u5c40\u5e73\u5766\u5ea6\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347\u5168\u5c40\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u591a\u6b65\u5c40\u90e8\u66f4\u65b0\u548c\u6570\u636e\u5f02\u6784\u6027\u901a\u5e38\u5bfc\u81f4\u66f4\u5c16\u9510\u7684\u5168\u5c40\u6700\u5c0f\u503c\uff0c\u8fd9\u4f1a\u964d\u4f4e\u5168\u5c40\u6a21\u578b\u7684\u6027\u80fd\u3002\u73b0\u6709\u65b9\u6cd5\u5c06SAM\u96c6\u6210\u5230\u5c40\u90e8\u8bad\u7ec3\u4e2d\uff0c\u4f46\u5728\u9ad8\u6570\u636e\u5f02\u6784\u6027\u8bbe\u7f6e\u4e0b\uff0c\u5c40\u90e8\u8bad\u7ec3\u7684\u5e73\u5766\u5ea6\u5e76\u4e0d\u4ee3\u8868\u5168\u5c40\u6a21\u578b\u7684\u5e73\u5766\u5ea6\uff0c\u56e0\u6b64\u9700\u8981\u534f\u8c03\u5168\u5c40\u548c\u5c40\u90e8\u5e73\u5766\u5ea6\u7684\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51faFedNSAM\u7b97\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5168\u5c40Nesterov\u52a8\u91cf\u5230\u5c40\u90e8\u66f4\u65b0\u4e2d\uff0c\u4f7f\u7528\u5168\u5c40Nesterov\u52a8\u91cf\u4f5c\u4e3a\u5ba2\u6237\u7aef\u5168\u5c40\u6270\u52a8\u7684\u5c40\u90e8\u4f30\u8ba1\u65b9\u5411\u548c\u5916\u63a8\u65b9\u5411\uff0c\u4ece\u800c\u52a0\u901fSAM\u7b97\u6cd5\u5e76\u534f\u8c03\u5168\u5c40\u548c\u5c40\u90e8\u5e73\u5766\u5ea6\u7684\u4e00\u81f4\u6027\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86FedNSAM\u6bd4FedSAM\u5177\u6709\u66f4\u7d27\u7684\u6536\u655b\u754c\uff1b\u5b9e\u8bc1\u4e0a\u5728CNN\u548cTransformer\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86FedNSAM\u7684\u4f18\u8d8a\u6027\u80fd\u548c\u6548\u7387\u3002", "conclusion": "FedNSAM\u901a\u8fc7\u534f\u8c03\u5168\u5c40\u548c\u5c40\u90e8\u5e73\u5766\u5ea6\u4e00\u81f4\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5f02\u6784\u6027\u5bfc\u81f4\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.23852", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.23852", "abs": "https://arxiv.org/abs/2602.23852", "authors": ["Zhaowen Wang", "Dongdong Zhou", "Qi Xu", "Fengyu Cong", "Mohammad Al-Sa'd", "Jenni Raitoharju"], "title": "ULW-SleepNet: An Ultra-Lightweight Network for Multimodal Sleep Stage Scoring", "comment": "Accepted to ICASSP 2026", "summary": "Automatic sleep stage scoring is crucial for the diagnosis and treatment of sleep disorders. Although deep learning models have advanced the field, many existing models are computationally demanding and designed for single-channel electroencephalography (EEG), limiting their practicality for multimodal polysomnography (PSG) data. To overcome this, we propose ULW-SleepNet, an ultra-lightweight multimodal sleep stage scoring framework that efficiently integrates information from multiple physiological signals. ULW-SleepNet incorporates a novel Dual-Stream Separable Convolution (DSSC) Block, depthwise separable convolutions, channel-wise parameter sharing, and global average pooling to reduce computational overhead while maintaining competitive accuracy. Evaluated on the Sleep-EDF-20 and Sleep-EDF-78 datasets, ULW-SleepNet achieves accuracies of 86.9% and 81.4%, respectively, with only 13.3K parameters and 7.89M FLOPs. Compared to state-of-the-art methods, our model reduces parameters by up to 98.6% with only marginal performance loss, demonstrating its strong potential for real-time sleep monitoring on wearable and IoT devices. The source code for this study is publicly available at https://github.com/wzw999/ULW-SLEEPNET.", "AI": {"tldr": "ULW-SleepNet\u662f\u4e00\u4e2a\u8d85\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u7761\u7720\u5206\u671f\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u53cc\u6d41\u53ef\u5206\u79bb\u5377\u79ef\u5757\u7b49\u6280\u672f\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u51c6\u786e\u7387\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u9002\u7528\u4e8e\u53ef\u7a7f\u6234\u548c\u7269\u8054\u7f51\u8bbe\u5907\u7684\u5b9e\u65f6\u7761\u7720\u76d1\u6d4b\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8ba1\u7b97\u91cf\u5927\u4e14\u4e3b\u8981\u9488\u5bf9\u5355\u901a\u9053EEG\u8bbe\u8ba1\uff0c\u9650\u5236\u4e86\u5728\u591a\u6a21\u6001PSG\u6570\u636e\u4e0a\u7684\u5b9e\u7528\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u8f7b\u91cf\u3001\u9ad8\u6548\u7684\u591a\u6a21\u6001\u7761\u7720\u5206\u671f\u65b9\u6cd5\u3002", "method": "\u63d0\u51faULW-SleepNet\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u6d41\u53ef\u5206\u79bb\u5377\u79ef\u5757\u3001\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u3001\u901a\u9053\u53c2\u6570\u5171\u4eab\u548c\u5168\u5c40\u5e73\u5747\u6c60\u5316\u7b49\u6280\u672f\uff0c\u9ad8\u6548\u6574\u5408\u591a\u79cd\u751f\u7406\u4fe1\u53f7\u4fe1\u606f\u3002", "result": "\u5728Sleep-EDF-20\u548cSleep-EDF-78\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u523086.9%\u548c81.4%\u7684\u51c6\u786e\u7387\uff0c\u4ec5\u970013.3K\u53c2\u6570\u548c7.89M FLOPs\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u53c2\u6570\u51cf\u5c11\u9ad8\u8fbe98.6%\u3002", "conclusion": "ULW-SleepNet\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u51c6\u786e\u7387\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5c55\u793a\u4e86\u5728\u53ef\u7a7f\u6234\u548c\u7269\u8054\u7f51\u8bbe\u5907\u4e0a\u8fdb\u884c\u5b9e\u65f6\u7761\u7720\u76d1\u6d4b\u7684\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.23880", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23880", "abs": "https://arxiv.org/abs/2602.23880", "authors": ["Zhang Wan", "Tingting Mu", "Samuel Kaski"], "title": "A Theory of Random Graph Shift in Truncated-Spectrum vRKHS", "comment": null, "summary": "This paper develops a theory of graph classification under domain shift through a random-graph generative lens, where we consider intra-class graphs sharing the same random graph model (RGM) and the domain shift induced by changes in RGM components. While classic domain adaptation (DA) theories have well-underpinned existing techniques to handle graph distribution shift, the information of graph samples, which are itself structured objects, is less explored. The non-Euclidean nature of graphs and specialized architectures for graph learning further complicate a fine-grained analysis of graph distribution shifts. In this paper, we propose a theory that assumes RGM as the data generative process, exploiting its connection to hypothesis complexity in function space perspective for such fine-grained analysis. Building on a vector-valued reproducing kernel Hilbert space (vRKHS) formulation, we derive a generalization bound whose shift penalty admits a factorization into (i) a domain discrepancy term, (ii) a spectral-geometry term summarized by the accessible truncated spectrum, and (iii) an amplitude term that aggregates convergence and construction-stability effects. We empirically verify the insights on these terms in both real data and simulations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u968f\u673a\u56fe\u751f\u6210\u89d2\u5ea6\u53d1\u5c55\u4e86\u56fe\u5206\u7c7b\u7684\u57df\u9002\u5e94\u7406\u8bba\uff0c\u901a\u8fc7\u968f\u673a\u56fe\u6a21\u578b\u5206\u6790\u57df\u504f\u79fb\uff0c\u63a8\u5bfc\u51fa\u5305\u542b\u57df\u5dee\u5f02\u3001\u8c31\u51e0\u4f55\u548c\u632f\u5e45\u4e09\u9879\u56e0\u5b50\u7684\u6cdb\u5316\u754c\u3002", "motivation": "\u73b0\u6709\u57df\u9002\u5e94\u7406\u8bba\u4e3b\u8981\u5904\u7406\u4f20\u7edf\u6570\u636e\u5206\u5e03\u504f\u79fb\uff0c\u4f46\u56fe\u6570\u636e\u7684\u975e\u6b27\u51e0\u91cc\u5f97\u7279\u6027\u548c\u4e13\u7528\u56fe\u5b66\u4e60\u67b6\u6784\u4f7f\u5f97\u56fe\u5206\u5e03\u504f\u79fb\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u53d8\u5f97\u590d\u6742\u3002\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u7406\u8bba\u6846\u67b6\u6765\u5206\u6790\u56fe\u5206\u7c7b\u4e2d\u7684\u57df\u504f\u79fb\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u968f\u673a\u56fe\u6a21\u578b\u7684\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u5047\u8bbe\uff0c\u5229\u7528\u5411\u91cf\u503c\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff08vRKHS\uff09\u516c\u5f0f\u5316\uff0c\u63a8\u5bfc\u51fa\u5305\u542b\u4e09\u9879\u56e0\u5b50\u7684\u6cdb\u5316\u754c\uff1a\u57df\u5dee\u5f02\u9879\u3001\u8c31\u51e0\u4f55\u9879\uff08\u901a\u8fc7\u622a\u65ad\u8c31\u603b\u7ed3\uff09\u548c\u632f\u5e45\u9879\uff08\u805a\u5408\u6536\u655b\u548c\u6784\u9020\u7a33\u5b9a\u6027\u6548\u5e94\uff09\u3002", "result": "\u7406\u8bba\u63a8\u5bfc\u51fa\u53ef\u5206\u89e3\u7684\u6cdb\u5316\u754c\uff0c\u5e76\u901a\u8fc7\u771f\u5b9e\u6570\u636e\u548c\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5404\u9879\u56e0\u5b50\u7684\u7406\u8bba\u89c1\u89e3\u3002\u8be5\u6846\u67b6\u4e3a\u56fe\u5206\u7c7b\u4e2d\u7684\u57df\u504f\u79fb\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u5206\u6790\u5de5\u5177\u3002", "conclusion": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u56fe\u5206\u7c7b\u57df\u9002\u5e94\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u968f\u673a\u56fe\u6a21\u578b\u89c6\u89d2\u548cvRKHS\u516c\u5f0f\u5316\uff0c\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u6cdb\u5316\u754c\u5206\u89e3\uff0c\u4e3a\u7406\u89e3\u56fe\u5206\u5e03\u504f\u79fb\u7684\u673a\u5236\u548c\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u56fe\u57df\u9002\u5e94\u65b9\u6cd5\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.23947", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23947", "abs": "https://arxiv.org/abs/2602.23947", "authors": ["Oscar Hill", "Mateo Espinosa Zarlenga", "Mateja Jamnik"], "title": "Hierarchical Concept-based Interpretable Models", "comment": "Published as a conference paper at ICLR 2026", "summary": "Modern deep neural networks remain challenging to interpret due to the opacity of their latent representations, impeding model understanding, debugging, and debiasing. Concept Embedding Models (CEMs) address this by mapping inputs to human-interpretable concept representations from which tasks can be predicted. Yet, CEMs fail to represent inter-concept relationships and require concept annotations at different granularities during training, limiting their applicability. In this paper, we introduce Hierarchical Concept Embedding Models (HiCEMs), a new family of CEMs that explicitly model concept relationships through hierarchical structures. To enable HiCEMs in real-world settings, we propose Concept Splitting, a method for automatically discovering finer-grained sub-concepts from a pretrained CEM's embedding space without requiring additional annotations. This allows HiCEMs to generate fine-grained explanations from limited concept labels, reducing annotation burdens. Our evaluation across multiple datasets, including a user study and experiments on PseudoKitchens, a newly proposed concept-based dataset of 3D kitchen renders, demonstrates that (1) Concept Splitting discovers human-interpretable sub-concepts absent during training that can be used to train highly accurate HiCEMs, and (2) HiCEMs enable powerful test-time concept interventions at different granularities, leading to improved task accuracy.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u6982\u5ff5\u5d4c\u5165\u6a21\u578b\uff08HiCEMs\uff09\u6765\u5efa\u6a21\u6982\u5ff5\u95f4\u5173\u7cfb\uff0c\u5e76\u5f15\u5165\u6982\u5ff5\u5206\u5272\u65b9\u6cd5\u81ea\u52a8\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u6316\u6398\u7ec6\u7c92\u5ea6\u5b50\u6982\u5ff5\uff0c\u51cf\u5c11\u6807\u6ce8\u8d1f\u62c5\uff0c\u63d0\u5347\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u5e72\u9884\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6982\u5ff5\u5d4c\u5165\u6a21\u578b\uff08CEMs\uff09\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u65e0\u6cd5\u8868\u793a\u6982\u5ff5\u95f4\u7684\u5c42\u6b21\u5173\u7cfb\uff1b2\uff09\u9700\u8981\u4e0d\u540c\u7c92\u5ea6\u7684\u6982\u5ff5\u6807\u6ce8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5efa\u6a21\u6982\u5ff5\u5173\u7cfb\u53c8\u80fd\u51cf\u5c11\u6807\u6ce8\u8d1f\u62c5\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u6982\u5ff5\u5d4c\u5165\u6a21\u578b\uff08HiCEMs\uff09\uff0c\u901a\u8fc7\u5c42\u6b21\u7ed3\u6784\u663e\u5f0f\u5efa\u6a21\u6982\u5ff5\u5173\u7cfb\u3002\u5f15\u5165\u6982\u5ff5\u5206\u5272\u65b9\u6cd5\uff0c\u4ece\u9884\u8bad\u7ec3CEM\u7684\u5d4c\u5165\u7a7a\u95f4\u4e2d\u81ea\u52a8\u53d1\u73b0\u7ec6\u7c92\u5ea6\u5b50\u6982\u5ff5\uff0c\u65e0\u9700\u989d\u5916\u6807\u6ce8\u3002\u4f7f\u7528PseudoKitchens\u7b49\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "1\uff09\u6982\u5ff5\u5206\u5272\u65b9\u6cd5\u80fd\u591f\u53d1\u73b0\u8bad\u7ec3\u65f6\u672a\u6807\u6ce8\u7684\u4eba\u7c7b\u53ef\u89e3\u91ca\u5b50\u6982\u5ff5\uff0c\u53ef\u7528\u4e8e\u8bad\u7ec3\u9ad8\u7cbe\u5ea6\u7684HiCEMs\uff1b2\uff09HiCEMs\u652f\u6301\u4e0d\u540c\u7c92\u5ea6\u7684\u6d4b\u8bd5\u65f6\u6982\u5ff5\u5e72\u9884\uff0c\u63d0\u9ad8\u4e86\u4efb\u52a1\u51c6\u786e\u6027\u3002", "conclusion": "HiCEMs\u901a\u8fc7\u5c42\u6b21\u5316\u5efa\u6a21\u6982\u5ff5\u5173\u7cfb\u548c\u81ea\u52a8\u6982\u5ff5\u5206\u5272\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6982\u5ff5\u5d4c\u5165\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\uff0c\u51cf\u5c11\u4e86\u6807\u6ce8\u9700\u6c42\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u5e72\u9884\u80fd\u529b\u3002"}}
{"id": "2602.23994", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23994", "abs": "https://arxiv.org/abs/2602.23994", "authors": ["Vrushank Ahire", "Yogesh Kumar", "Anouck Girard", "M. A. Ganaie"], "title": "MINT: Multimodal Imaging-to-Speech Knowledge Transfer for Early Alzheimer's Screening", "comment": null, "summary": "Alzheimer's disease is a progressive neurodegenerative disorder in which mild cognitive impairment (MCI) marks a critical transition between aging and dementia. Neuroimaging modalities, such as structural MRI, provide biomarkers of this transition; however, their high costs and infrastructure needs limit their deployment at a population scale. Speech analysis offers a non-invasive alternative, but speech-only classifiers are developed independently of neuroimaging, leaving decision boundaries biologically ungrounded and limiting reliability on the subtle CN-versus-MCI distinction. We propose MINT (Multimodal Imaging-to-Speech Knowledge Transfer), a three-stage cross-modal framework that transfers biomarker structure from MRI into a speech encoder at training time. An MRI teacher, trained on 1,228 subjects, defines a compact neuroimaging embedding space for CN-versus-MCI classification. A residual projection head aligns speech representations to this frozen imaging manifold via a combined geometric loss, adapting speech to the learned biomarker space while preserving imaging encoder fidelity. The frozen MRI classifier, which is never exposed to speech, is applied to aligned embeddings at inference and requires no scanner. Evaluation on ADNI-4 shows aligned speech achieves performance comparable to speech-only baselines (AUC 0.720 vs 0.711) while requiring no imaging at inference, demonstrating that MRI-derived decision boundaries can ground speech representations. Multimodal fusion improves over MRI alone (0.973 vs 0.958). Ablation studies identify dropout regularization and self-supervised pretraining as critical design decisions. To our knowledge, this is the first demonstration of MRI-to-speech knowledge transfer for early Alzheimer's screening, establishing a biologically grounded pathway for population-level cognitive triage without neuroimaging at inference.", "AI": {"tldr": "MINT\u6846\u67b6\u901a\u8fc7\u4e09\u9636\u6bb5\u8de8\u6a21\u6001\u77e5\u8bc6\u8f6c\u79fb\uff0c\u5c06MRI\u7684\u751f\u7269\u6807\u5fd7\u7269\u7ed3\u6784\u8f6c\u79fb\u5230\u8bed\u97f3\u7f16\u7801\u5668\u4e2d\uff0c\u5b9e\u73b0\u65e0\u9700\u795e\u7ecf\u5f71\u50cf\u7684\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u7b5b\u67e5\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u7b5b\u67e5\u4e2d\uff0c\u795e\u7ecf\u5f71\u50cf\uff08\u5982MRI\uff09\u6210\u672c\u9ad8\u4e14\u90e8\u7f72\u53d7\u9650\uff0c\u800c\u8bed\u97f3\u5206\u6790\u867d\u7136\u975e\u4fb5\u5165\u4f46\u7f3a\u4e4f\u751f\u7269\u5b66\u57fa\u7840\u3002\u73b0\u6709\u8bed\u97f3\u5206\u7c7b\u5668\u72ec\u7acb\u4e8e\u795e\u7ecf\u5f71\u50cf\u5f00\u53d1\uff0c\u51b3\u7b56\u8fb9\u754c\u7f3a\u4e4f\u751f\u7269\u5b66\u4f9d\u636e\uff0c\u5728\u533a\u5206\u8ba4\u77e5\u6b63\u5e38\u4e0e\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\u65f6\u53ef\u9760\u6027\u6709\u9650\u3002", "method": "\u63d0\u51faMINT\u4e09\u9636\u6bb5\u8de8\u6a21\u6001\u6846\u67b6\uff1a1\uff09\u8bad\u7ec3MRI\u6559\u5e08\u6a21\u578b\uff081228\u540d\u53d7\u8bd5\u8005\uff09\u5b9a\u4e49\u7d27\u51d1\u7684\u795e\u7ecf\u5f71\u50cf\u5d4c\u5165\u7a7a\u95f4\uff1b2\uff09\u901a\u8fc7\u6b8b\u5dee\u6295\u5f71\u5934\u548c\u51e0\u4f55\u635f\u5931\u5c06\u8bed\u97f3\u8868\u793a\u5bf9\u9f50\u5230\u51bb\u7ed3\u7684\u5f71\u50cf\u6d41\u5f62\uff1b3\uff09\u63a8\u7406\u65f6\u5e94\u7528\u51bb\u7ed3\u7684MRI\u5206\u7c7b\u5668\u5230\u5bf9\u9f50\u7684\u8bed\u97f3\u5d4c\u5165\uff0c\u65e0\u9700\u626b\u63cf\u8bbe\u5907\u3002", "result": "\u5728ADNI-4\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u9f50\u7684\u8bed\u97f3\u8fbe\u5230\u4e0e\u7eaf\u8bed\u97f3\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\uff08AUC 0.720 vs 0.711\uff09\uff0c\u540c\u65f6\u63a8\u7406\u65f6\u65e0\u9700\u5f71\u50cf\u3002\u591a\u6a21\u6001\u878d\u5408\u4f18\u4e8e\u5355\u72ecMRI\uff080.973 vs 0.958\uff09\u3002\u6d88\u878d\u7814\u7a76\u786e\u5b9adropout\u6b63\u5219\u5316\u548c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u662f\u5173\u952e\u8bbe\u8ba1\u51b3\u7b56\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c55\u793aMRI\u5230\u8bed\u97f3\u77e5\u8bc6\u8f6c\u79fb\u7528\u4e8e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u7b5b\u67e5\uff0c\u5efa\u7acb\u4e86\u65e0\u9700\u63a8\u7406\u65f6\u795e\u7ecf\u5f71\u50cf\u7684\u751f\u7269\u5b66\u57fa\u7840\u901a\u8def\uff0c\u4e3a\u4eba\u7fa4\u7ea7\u8ba4\u77e5\u5206\u6d41\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.23997", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23997", "abs": "https://arxiv.org/abs/2602.23997", "authors": ["Florent Delgrange"], "title": "Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments", "comment": "AAMAS 2026, Blue Sky Idea Track. 4 pages, 1 Figure", "summary": "The next generation of autonomous agents must not only learn efficiently but also act reliably and adapt their behavior in open worlds. Standard approaches typically assume fixed tasks and environments with little or no novelty, which limits world models' ability to support agents that must evolve their policies as conditions change. This paper outlines a vision for foundation world models: persistent, compositional representations that unify reinforcement learning, reactive/program synthesis, and abstraction mechanisms. We propose an agenda built around four components: (i) learnable reward models from specifications to support optimization with clear objectives; (ii) adaptive formal verification integrated throughout learning; (iii) online abstraction calibration to quantify the reliability of the model's predictions; and (iv) test-time synthesis and world-model generation guided by verifiers. Together, these components enable agents to synthesize verifiable programs, derive new policies from a small number of interactions, and maintain correctness while adapting to novelty. The resulting framework positions foundation world models as a substrate for learning, reasoning, and adaptation, laying the groundwork for agents that not only act well but can explain and justify the behavior they adopt.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u57fa\u7840\u4e16\u754c\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u5956\u52b1\u6a21\u578b\u3001\u81ea\u9002\u5e94\u5f62\u5f0f\u9a8c\u8bc1\u3001\u5728\u7ebf\u62bd\u8c61\u6821\u51c6\u548c\u6d4b\u8bd5\u65f6\u5408\u6210\u56db\u4e2a\u7ec4\u4ef6\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5408\u6210\u53ef\u9a8c\u8bc1\u7a0b\u5e8f\u3001\u4ece\u5c11\u91cf\u4ea4\u4e92\u4e2d\u63a8\u5bfc\u65b0\u7b56\u7565\uff0c\u5e76\u5728\u9002\u5e94\u65b0\u73af\u5883\u65f6\u4fdd\u6301\u6b63\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u81ea\u4e3b\u667a\u80fd\u4f53\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u56fa\u5b9a\u4efb\u52a1\u548c\u73af\u5883\uff0c\u9650\u5236\u4e86\u4e16\u754c\u6a21\u578b\u652f\u6301\u667a\u80fd\u4f53\u5728\u6761\u4ef6\u53d8\u5316\u65f6\u6f14\u5316\u7b56\u7565\u7684\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u652f\u6301\u9ad8\u6548\u5b66\u4e60\u3001\u53ef\u9760\u884c\u52a8\u548c\u5f00\u653e\u4e16\u754c\u9002\u5e94\u7684\u57fa\u7840\u4e16\u754c\u6a21\u578b\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u57fa\u7840\u4e16\u754c\u6a21\u578b\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u4ece\u89c4\u8303\u4e2d\u5b66\u4e60\u5956\u52b1\u6a21\u578b\u4ee5\u652f\u6301\u660e\u786e\u76ee\u6807\u7684\u4f18\u5316\uff1b2\uff09\u5728\u6574\u4e2a\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u96c6\u6210\u81ea\u9002\u5e94\u5f62\u5f0f\u9a8c\u8bc1\uff1b3\uff09\u5728\u7ebf\u62bd\u8c61\u6821\u51c6\u4ee5\u91cf\u5316\u6a21\u578b\u9884\u6d4b\u7684\u53ef\u9760\u6027\uff1b4\uff09\u7531\u9a8c\u8bc1\u5668\u5f15\u5bfc\u7684\u6d4b\u8bd5\u65f6\u5408\u6210\u548c\u4e16\u754c\u6a21\u578b\u751f\u6210\u3002", "result": "\u8be5\u6846\u67b6\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5408\u6210\u53ef\u9a8c\u8bc1\u7a0b\u5e8f\u3001\u4ece\u5c11\u91cf\u4ea4\u4e92\u4e2d\u63a8\u5bfc\u65b0\u7b56\u7565\uff0c\u5e76\u5728\u9002\u5e94\u65b0\u73af\u5883\u65f6\u4fdd\u6301\u6b63\u786e\u6027\u3002\u57fa\u7840\u4e16\u754c\u6a21\u578b\u6210\u4e3a\u5b66\u4e60\u3001\u63a8\u7406\u548c\u9002\u5e94\u7684\u57fa\u7840\uff0c\u4e3a\u667a\u80fd\u4f53\u63d0\u4f9b\u89e3\u91ca\u548c\u8bc1\u660e\u5176\u884c\u4e3a\u7684\u80fd\u529b\u3002", "conclusion": "\u57fa\u7840\u4e16\u754c\u6a21\u578b\u6846\u67b6\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u4e3b\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5b66\u4e60\u3001\u63a8\u7406\u548c\u9002\u5e94\u57fa\u7840\uff0c\u4f7f\u667a\u80fd\u4f53\u4e0d\u4ec5\u80fd\u591f\u826f\u597d\u884c\u52a8\uff0c\u8fd8\u80fd\u89e3\u91ca\u548c\u8bc1\u660e\u5176\u91c7\u7528\u7684\u884c\u4e3a\uff0c\u4e3a\u5f00\u653e\u4e16\u754c\u4e2d\u7684\u53ef\u9760\u667a\u80fd\u4f53\u53d1\u5c55\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2602.24012", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.24012", "abs": "https://arxiv.org/abs/2602.24012", "authors": ["Roy Betser", "Eyal Gofer", "Meir Yossef Levi", "Guy Gilboa"], "title": "InfoNCE Induces Gaussian Distribution", "comment": "Accepted to ICLR 2026, Oral", "summary": "Contrastive learning has become a cornerstone of modern representation learning, allowing training with massive unlabeled data for both task-specific and general (foundation) models. A prototypical loss in contrastive training is InfoNCE and its variants. In this work, we show that the InfoNCE objective induces Gaussian structure in representations that emerge from contrastive training. We establish this result in two complementary regimes. First, we show that under certain alignment and concentration assumptions, projections of the high-dimensional representation asymptotically approach a multivariate Gaussian distribution. Next, under less strict assumptions, we show that adding a small asymptotically vanishing regularization term that promotes low feature norm and high feature entropy leads to similar asymptotic results. We support our analysis with experiments on synthetic and CIFAR-10 datasets across multiple encoder architectures and sizes, demonstrating consistent Gaussian behavior. This perspective provides a principled explanation for commonly observed Gaussianity in contrastive representations. The resulting Gaussian model enables principled analytical treatment of learned representations and is expected to support a wide range of applications in contrastive learning.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684InfoNCE\u635f\u5931\u4f1a\u8bf1\u5bfc\u8868\u793a\u5448\u73b0\u9ad8\u65af\u7ed3\u6784\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u53d1\u73b0\u3002", "motivation": "\u5bf9\u6bd4\u5b66\u4e60\u5df2\u6210\u4e3a\u73b0\u4ee3\u8868\u793a\u5b66\u4e60\u7684\u57fa\u77f3\uff0c\u4f46InfoNCE\u635f\u5931\u5982\u4f55\u5f71\u54cd\u8868\u793a\u5206\u5e03\u7684\u7406\u8bba\u7406\u89e3\u5c1a\u4e0d\u5145\u5206\u3002\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793a\u5bf9\u6bd4\u8bad\u7ec3\u4e2d\u8868\u793a\u7684\u9ad8\u65af\u7ed3\u6784\u7279\u6027\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4e92\u8865\u7684\u7406\u8bba\u5206\u6790\u6846\u67b6\uff1a1\uff09\u5728\u7279\u5b9a\u5bf9\u9f50\u548c\u96c6\u4e2d\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u9ad8\u7ef4\u8868\u793a\u7684\u6295\u5f71\u6e10\u8fd1\u63a5\u8fd1\u591a\u5143\u9ad8\u65af\u5206\u5e03\uff1b2\uff09\u5728\u8f83\u5f31\u5047\u8bbe\u4e0b\uff0c\u901a\u8fc7\u6dfb\u52a0\u4fc3\u8fdb\u4f4e\u7279\u5f81\u8303\u6570\u548c\u9ad8\u7279\u5f81\u71b5\u7684\u6b63\u5219\u5316\u9879\u83b7\u5f97\u7c7b\u4f3c\u6e10\u8fd1\u7ed3\u679c\u3002\u540c\u65f6\u5728\u5408\u6210\u6570\u636e\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cInfoNCE\u76ee\u6807\u786e\u5b9e\u8bf1\u5bfc\u8868\u793a\u5448\u73b0\u9ad8\u65af\u5206\u5e03\u7279\u6027\u3002\u8fd9\u4e00\u53d1\u73b0\u5728\u591a\u79cd\u7f16\u7801\u5668\u67b6\u6784\u548c\u89c4\u6a21\u4e0a\u4fdd\u6301\u4e00\u81f4\uff0c\u4e3a\u89c2\u5bdf\u5230\u7684\u5bf9\u6bd4\u8868\u793a\u9ad8\u65af\u6027\u63d0\u4f9b\u4e86\u539f\u7406\u6027\u89e3\u91ca\u3002", "conclusion": "\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684InfoNCE\u635f\u5931\u4f1a\u8bf1\u5bfc\u8868\u793a\u5448\u73b0\u9ad8\u65af\u7ed3\u6784\uff0c\u8fd9\u4e00\u9ad8\u65af\u6a21\u578b\u4e3a\u5206\u6790\u5b66\u4e60\u5230\u7684\u8868\u793a\u63d0\u4f9b\u4e86\u539f\u7406\u6027\u6846\u67b6\uff0c\u6709\u671b\u652f\u6301\u5bf9\u6bd4\u5b66\u4e60\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2602.24040", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24040", "abs": "https://arxiv.org/abs/2602.24040", "authors": ["Daniel Yang", "Samuel Stante", "Florian Redhardt", "Lena Libon", "Parnian Kassraie", "Ido Hakimi", "Barna P\u00e1sztor", "Andreas Krause"], "title": "RewardUQ: A Unified Framework for Uncertainty-Aware Reward Models", "comment": null, "summary": "Reward models are central to aligning large language models (LLMs) with human preferences. Yet most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback. Recent work suggests that quantifying this uncertainty can reduce the costs of human annotation via uncertainty-guided active learning and mitigate reward overoptimization in LLM post-training. However, uncertainty-aware reward models have so far been adopted without thorough comparison, leaving them poorly understood. This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison. Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. To foster the development and evaluation of new methods and aid the deployment in downstream applications, we release our open-source framework as a Python package. Our code is available at https://github.com/lasgroup/rewarduq.", "AI": {"tldr": "RewardUQ\uff1a\u4e00\u4e2a\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u53d1\u73b0\u6a21\u578b\u5927\u5c0f\u548c\u521d\u59cb\u5316\u5bf9\u6027\u80fd\u5f71\u54cd\u6700\u5927\uff0c\u5927\u591a\u6570\u5148\u524d\u5de5\u4f5c\u672c\u53ef\u4ece\u66ff\u4ee3\u8bbe\u8ba1\u9009\u62e9\u4e2d\u53d7\u76ca\u3002", "motivation": "\u5956\u52b1\u6a21\u578b\u5bf9\u4e8e\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u70b9\u4f30\u8ba1\u800c\u5ffd\u7565\u4e86\u6709\u9650\u4eba\u7c7b\u53cd\u9988\u5e26\u6765\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002\u867d\u7136\u91cf\u5316\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u53ef\u4ee5\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u6210\u672c\uff0c\u5e76\u5728LLM\u540e\u8bad\u7ec3\u4e2d\u7f13\u89e3\u5956\u52b1\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u4f46\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u5956\u52b1\u6a21\u578b\u7f3a\u4e4f\u7cfb\u7edf\u6bd4\u8f83\uff0c\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86RewardUQ\u7edf\u4e00\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002\u6bd4\u8f83\u5e38\u89c1\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\u6807\u51c6\u6307\u6807\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408\u8fd9\u4e24\u4e2a\u7ef4\u5ea6\u7684\u65b0\u6392\u540d\u7b56\u7565\u4ee5\u7b80\u5316\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6a21\u578b\u5927\u5c0f\u548c\u521d\u59cb\u5316\u5bf9\u6027\u80fd\u5f71\u54cd\u6700\u4e3a\u663e\u8457\uff0c\u5927\u591a\u6570\u5148\u524d\u5de5\u4f5c\u672c\u53ef\u4ece\u66ff\u4ee3\u8bbe\u8ba1\u9009\u62e9\u4e2d\u53d7\u76ca\u3002\u4e3a\u4fc3\u8fdb\u65b0\u65b9\u6cd5\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\uff0c\u5e76\u5e2e\u52a9\u4e0b\u6e38\u5e94\u7528\u90e8\u7f72\uff0c\u53d1\u5e03\u4e86\u5f00\u6e90\u6846\u67b6\u4f5c\u4e3aPython\u5305\u3002", "conclusion": "RewardUQ\u4e3a\u5956\u52b1\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5927\u5c0f\u548c\u521d\u59cb\u5316\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u5de5\u5177\u548c\u89c1\u89e3\u3002"}}
{"id": "2602.24066", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24066", "abs": "https://arxiv.org/abs/2602.24066", "authors": ["Tobias Nygaard"], "title": "pathsig: A GPU-Accelerated Library for Truncated and Projected Path Signatures", "comment": null, "summary": "Path signatures provide a rich representation of sequential data, with strong theoretical guarantees and good performance in a variety of machine-learning tasks. While signatures have progressed from fixed feature extractors to trainable components of machine-learning models, existing libraries often lack the required scalability for large-scale, gradient-based learning. To address this gap, this paper introduces pathsig, a PyTorch-native library that computes path signatures directly in the word basis. By using CUDA kernels to update signature coefficients in parallel over prefix-closed word sets, pathsig achieves high GPU throughput and near-minimal peak memory. Compared with other libraries, pathsig achieves 10-30x speedups for computation of truncated signatures and up to 4-10x speedups in training that require backpropagation through the signature. Beyond regular truncation, pathsig supports projections of the (infinite-dimensional) signature onto user-specified sets of words and anisotropic truncation motivated by inhomogeneous path regularity, enabling more compact representations that can reduce dimensionality, redundancy, and computational cost.", "AI": {"tldr": "pathsig\u662f\u4e00\u4e2aPyTorch\u539f\u751f\u5e93\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u8def\u5f84\u7b7e\u540d\uff0c\u901a\u8fc7CUDA\u5e76\u884c\u8ba1\u7b97\u5b9e\u73b0GPU\u9ad8\u541e\u5410\u91cf\uff0c\u76f8\u6bd4\u5176\u4ed6\u5e93\u670910-30\u500d\u52a0\u901f", "motivation": "\u73b0\u6709\u8def\u5f84\u7b7e\u540d\u5e93\u7f3a\u4e4f\u5927\u89c4\u6a21\u68af\u5ea6\u5b66\u4e60\u6240\u9700\u7684\u53ef\u6269\u5c55\u6027\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5b9e\u73b0\u6765\u652f\u6301\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u5e94\u7528", "method": "\u4f7f\u7528PyTorch\u539f\u751f\u5b9e\u73b0\uff0c\u76f4\u63a5\u5728\u5355\u8bcd\u57fa\u4e0a\u8ba1\u7b97\u8def\u5f84\u7b7e\u540d\uff0c\u901a\u8fc7CUDA\u5185\u6838\u5728\u524d\u7f00\u5c01\u95ed\u5355\u8bcd\u96c6\u4e0a\u5e76\u884c\u66f4\u65b0\u7b7e\u540d\u7cfb\u6570", "result": "\u76f8\u6bd4\u5176\u4ed6\u5e93\uff0cpathsig\u5728\u622a\u65ad\u7b7e\u540d\u8ba1\u7b97\u4e0a\u5b9e\u73b010-30\u500d\u52a0\u901f\uff0c\u5728\u9700\u8981\u53cd\u5411\u4f20\u64ad\u7684\u8bad\u7ec3\u4e2d\u5b9e\u73b04-10\u500d\u52a0\u901f\uff0c\u540c\u65f6\u652f\u6301\u7528\u6237\u6307\u5b9a\u5355\u8bcd\u96c6\u7684\u6295\u5f71\u548c\u5404\u5411\u5f02\u6027\u622a\u65ad", "conclusion": "pathsig\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8def\u5f84\u7b7e\u540d\u8ba1\u7b97\u5e93\uff0c\u652f\u6301GPU\u5e76\u884c\u8ba1\u7b97\u548c\u7075\u6d3b\u7684\u7279\u5f81\u8868\u793a\uff0c\u4e3a\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5de5\u5177\u652f\u6301"}}
{"id": "2602.24069", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.24069", "abs": "https://arxiv.org/abs/2602.24069", "authors": ["Ryan DeWolfe"], "title": "Leveraging Non-linear Dimension Reduction and Random Walk Co-occurrence for Node Embedding", "comment": "13 pages, 6 figures", "summary": "Leveraging non-linear dimension reduction techniques, we remove the low dimension constraint from node embedding and propose COVE, an explainable high dimensional embedding that, when reduced to low dimension with UMAP, slightly increases performance on clustering and link prediction tasks. The embedding is inspired by neural embedding methods that use co-occurrence on a random walk as an indication of similarity, and is closely related to a diffusion process. Extending on recent community detection benchmarks, we find that a COVE UMAP HDBSCAN pipeline performs similarly to the popular Louvain algorithm.", "AI": {"tldr": "COVE\u662f\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u9ad8\u7ef4\u8282\u70b9\u5d4c\u5165\u65b9\u6cd5\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u964d\u7ef4\u6280\u672f\u7a81\u7834\u4f4e\u7ef4\u9650\u5236\uff0c\u5728\u805a\u7c7b\u548c\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u7565\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8282\u70b9\u5d4c\u5165\u65b9\u6cd5\u901a\u5e38\u53d7\u9650\u4e8e\u4f4e\u7ef4\u8868\u793a\uff0c\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u9ad8\u7ef4\u5d4c\u5165\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u5728\u793e\u533a\u68c0\u6d4b\u548c\u94fe\u63a5\u9884\u6d4b\u7b49\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "method": "COVE\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u4e2d\u8282\u70b9\u5171\u73b0\u4f5c\u4e3a\u76f8\u4f3c\u6027\u6307\u6807\uff0c\u4e0e\u6269\u6563\u8fc7\u7a0b\u5bc6\u5207\u76f8\u5173\u3002\u91c7\u7528\u975e\u7ebf\u6027\u964d\u7ef4\u6280\u672f\uff08UMAP\uff09\u5c06\u9ad8\u7ef4\u5d4c\u5165\u964d\u81f3\u4f4e\u7ef4\uff0c\u7136\u540e\u7ed3\u5408HDBSCAN\u8fdb\u884c\u805a\u7c7b\u5206\u6790\u3002", "result": "COVE+UMAP+HDBSCAN\u6d41\u6c34\u7ebf\u5728\u793e\u533a\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4e0e\u6d41\u884c\u7684Louvain\u7b97\u6cd5\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u5728\u805a\u7c7b\u548c\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e0a\u7565\u6709\u63d0\u5347\u3002", "conclusion": "\u9ad8\u7ef4\u8282\u70b9\u5d4c\u5165\u7ed3\u5408\u975e\u7ebf\u6027\u964d\u7ef4\u6280\u672f\u662f\u53ef\u884c\u7684\uff0cCOVE\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u793e\u533a\u68c0\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u4e3a\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u8868\u793a\u3002"}}
{"id": "2602.24083", "categories": ["cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.24083", "abs": "https://arxiv.org/abs/2602.24083", "authors": ["Xinlong Du", "Harsha Honnappa", "Vinayak Rao"], "title": "Neural Diffusion Intensity Models for Point Process Data", "comment": null, "summary": "Cox processes model overdispersed point process data via a latent stochastic intensity, but both nonparametric estimation of the intensity model and posterior inference over intensity paths are typically intractable, relying on expensive MCMC methods. We introduce Neural Diffusion Intensity Models, a variational framework for Cox processes driven by neural SDEs. Our key theoretical result, based on enlargement of filtrations, shows that conditioning on point process observations preserves the diffusion structure of the latent intensity with an explicit drift correction. This guarantees the variational family contains the true posterior, so that ELBO maximization coincides with maximum likelihood estimation under sufficient model capacity. We design an amortized encoder architecture that maps variable-length event sequences to posterior intensity paths by simulating the drift-corrected SDE, replacing repeated MCMC runs with a single forward pass. Experiments on synthetic and real-world data demonstrate accurate recovery of latent intensity dynamics and posterior paths, with orders-of-magnitude speedups over MCMC-based methods.", "AI": {"tldr": "\u63d0\u51faNeural Diffusion Intensity Models\uff0c\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecfSDE\u7684\u53d8\u5206\u6846\u67b6\uff0c\u7528\u4e8eCox\u8fc7\u7a0b\u5efa\u6a21\uff0c\u901a\u8fc7\u6269\u5927\u6ee4\u6ce2\u7406\u8bba\u4fdd\u8bc1\u53d8\u5206\u65cf\u5305\u542b\u771f\u5b9e\u540e\u9a8c\uff0c\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406", "motivation": "Cox\u8fc7\u7a0b\u901a\u8fc7\u6f5c\u5728\u968f\u673a\u5f3a\u5ea6\u5efa\u6a21\u8fc7\u5206\u6563\u70b9\u8fc7\u7a0b\u6570\u636e\uff0c\u4f46\u4f20\u7edf\u7684\u975e\u53c2\u6570\u5f3a\u5ea6\u4f30\u8ba1\u548c\u540e\u9a8c\u63a8\u7406\u901a\u5e38\u4f9d\u8d56\u4e8e\u6602\u8d35\u7684MCMC\u65b9\u6cd5\uff0c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b", "method": "\u57fa\u4e8e\u6269\u5927\u6ee4\u6ce2\u7406\u8bba\uff0c\u8bc1\u660e\u5728\u70b9\u8fc7\u7a0b\u89c2\u6d4b\u6761\u4ef6\u4e0b\uff0c\u6f5c\u5728\u5f3a\u5ea6\u7684\u6269\u6563\u7ed3\u6784\u5f97\u4ee5\u4fdd\u6301\u5e76\u5177\u6709\u663e\u5f0f\u6f02\u79fb\u4fee\u6b63\uff1b\u8bbe\u8ba1\u644a\u9500\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5c06\u53d8\u957f\u4e8b\u4ef6\u5e8f\u5217\u6620\u5c04\u5230\u540e\u9a8c\u5f3a\u5ea6\u8def\u5f84\uff0c\u901a\u8fc7\u6a21\u62df\u6f02\u79fb\u4fee\u6b63\u7684SDE\u5b9e\u73b0\u5355\u6b21\u524d\u5411\u4f20\u64ad", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u51c6\u786e\u6062\u590d\u6f5c\u5728\u5f3a\u5ea6\u52a8\u6001\u548c\u540e\u9a8c\u8def\u5f84\uff0c\u76f8\u6bd4\u57fa\u4e8eMCMC\u7684\u65b9\u6cd5\u5b9e\u73b0\u6570\u91cf\u7ea7\u7684\u901f\u5ea6\u63d0\u5347", "conclusion": "\u63d0\u51fa\u7684\u53d8\u5206\u6846\u67b6\u901a\u8fc7\u7406\u8bba\u4fdd\u8bc1\u548c\u9ad8\u6548\u67b6\u6784\uff0c\u4e3aCox\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u7684\u540e\u9a8c\u63a8\u7406\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edfMCMC\u65b9\u6cd5"}}
{"id": "2602.24146", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24146", "abs": "https://arxiv.org/abs/2602.24146", "authors": ["Zitian Li", "Wang Chi Cheung"], "title": "Learning with a Budget: Identifying the Best Arm with Resource Constraints", "comment": "A preliminary version of this work, titled 'Best Arm Identification with Resource Constraints,' was presented at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS 2024). This manuscript extends the original conference paper by providing improved theoretical results and more generalized conclusions, aiming for future journal submission. arXiv admin note: substantial text overlap with arXiv:2402.19090", "summary": "In many applications, evaluating the effectiveness of different alternatives comes with varying costs or resource usage. Motivated by such heterogeneity, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem, where an agent seeks to identify the best alternative (aka arm) in the presence of resource constraints. Each arm pull consumes one or more types of limited resources. We make two key contributions. First, we propose the Successive Halving with Resource Rationing (SH-RR) algorithm, which integrates resource-aware allocation into the classical successive halving framework on best arm identification. The SH-RR algorithm unifies the theoretical analysis for both the stochastic and deterministic consumption settings, with a new \\textit{effective consumption measure", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u6700\u4f73\u81c2\u8bc6\u522b\u7b97\u6cd5SH-RR\uff0c\u5c06\u8d44\u6e90\u611f\u77e5\u5206\u914d\u96c6\u6210\u5230\u7ecf\u5178\u8fde\u7eed\u51cf\u534a\u6846\u67b6\u4e2d\uff0c\u7edf\u4e00\u4e86\u968f\u673a\u548c\u786e\u5b9a\u6027\u6d88\u8017\u8bbe\u7f6e\u7684\u7406\u8bba\u5206\u6790\u3002", "motivation": "\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\uff0c\u8bc4\u4f30\u4e0d\u540c\u66ff\u4ee3\u65b9\u6848\u7684\u6709\u6548\u6027\u5177\u6709\u4e0d\u540c\u7684\u6210\u672c\u6216\u8d44\u6e90\u6d88\u8017\u3002\u53d7\u8fd9\u79cd\u5f02\u8d28\u6027\u542f\u53d1\uff0c\u7814\u7a76\u5728\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u6700\u4f73\u81c2\u8bc6\u522b\u95ee\u9898\uff0c\u5176\u4e2d\u6bcf\u4e2a\u81c2\u62c9\u52a8\u6d88\u8017\u4e00\u79cd\u6216\u591a\u79cd\u6709\u9650\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u4e86Successive Halving with Resource Rationing (SH-RR)\u7b97\u6cd5\uff0c\u5c06\u8d44\u6e90\u611f\u77e5\u5206\u914d\u96c6\u6210\u5230\u7ecf\u5178\u8fde\u7eed\u51cf\u534a\u6846\u67b6\u4e2d\uff0c\u4f7f\u7528\u65b0\u7684\u6709\u6548\u6d88\u8017\u5ea6\u91cf\u6765\u7edf\u4e00\u968f\u673a\u548c\u786e\u5b9a\u6027\u6d88\u8017\u8bbe\u7f6e\u7684\u7406\u8bba\u5206\u6790\u3002", "result": "SH-RR\u7b97\u6cd5\u5728\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u6700\u4f73\u81c2\u8bc6\u522b\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u968f\u673a\u548c\u786e\u5b9a\u6027\u8d44\u6e90\u6d88\u8017\u573a\u666f\uff0c\u901a\u8fc7\u65b0\u7684\u6709\u6548\u6d88\u8017\u5ea6\u91cf\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u5206\u6790\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u6700\u4f73\u81c2\u8bc6\u522b\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0cSH-RR\u7b97\u6cd5\u901a\u8fc7\u96c6\u6210\u8d44\u6e90\u611f\u77e5\u5206\u914d\u548c\u65b0\u7684\u6709\u6548\u6d88\u8017\u5ea6\u91cf\uff0c\u7edf\u4e00\u4e86\u4e0d\u540c\u6d88\u8017\u8bbe\u7f6e\u7684\u7406\u8bba\u5206\u6790\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.24178", "categories": ["cs.LG", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.24178", "abs": "https://arxiv.org/abs/2602.24178", "authors": ["Adam R. Klivans", "Konstantinos Stavropoulos", "Arsen Vasilyan"], "title": "Sandwiching Polynomials for Geometric Concepts with Low Intrinsic Dimension", "comment": "30 pages", "summary": "Recent work has shown the surprising power of low-degree sandwiching polynomial approximators in the context of challenging learning settings such as learning with distribution shift, testable learning, and learning with contamination. A pair of sandwiching polynomials approximate a target function in expectation while also providing pointwise upper and lower bounds on the function's values. In this paper, we give a new method for constructing low-degree sandwiching polynomials that yield greatly improved degree bounds for several fundamental function classes and marginal distributions. In particular, we obtain degree $\\mathrm{poly}(k)$ sandwiching polynomials for functions of $k$ halfspaces under the Gaussian distribution, improving exponentially over the prior $2^{O(k)}$ bound. More broadly, our approach applies to function classes that are low-dimensional and have smooth boundary.\n  In contrast to prior work, our proof is relatively simple and directly uses the smoothness of the target function's boundary to construct sandwiching Lipschitz functions, which are amenable to results from high-dimensional approximation theory. For low-dimensional polynomial threshold functions (PTFs) with respect to Gaussians, we obtain doubly exponential improvements without applying the FT-mollification method of Kane used in the best previous result.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f4e\u5ea6\u4e09\u660e\u6cbb\u591a\u9879\u5f0f\u6784\u9020\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u8fdb\u4e86\u591a\u4e2a\u57fa\u7840\u51fd\u6570\u7c7b\u5728\u7279\u5b9a\u5206\u5e03\u4e0b\u7684\u5ea6\u754c\uff0c\u7279\u522b\u662f\u5c06k\u4e2a\u534a\u7a7a\u95f4\u7684\u51fd\u6570\u4ece\u6307\u6570\u7ea7\u6539\u8fdb\u5230\u591a\u9879\u5f0f\u7ea7\u3002", "motivation": "\u4f4e\u5ea6\u4e09\u660e\u6cbb\u591a\u9879\u5f0f\u8fd1\u4f3c\u5668\u5728\u5206\u5e03\u504f\u79fb\u5b66\u4e60\u3001\u53ef\u6d4b\u8bd5\u5b66\u4e60\u548c\u6c61\u67d3\u5b66\u4e60\u7b49\u6311\u6218\u6027\u5b66\u4e60\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u6784\u9020\u65b9\u6cd5\u7684\u5ea6\u754c\u4e0d\u591f\u7406\u60f3\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u76f4\u63a5\u5229\u7528\u76ee\u6807\u51fd\u6570\u8fb9\u754c\u7684\u5e73\u6ed1\u6027\u6765\u6784\u9020\u4e09\u660e\u6cbbLipschitz\u51fd\u6570\uff0c\u7136\u540e\u5e94\u7528\u9ad8\u7ef4\u903c\u8fd1\u7406\u8bba\u7684\u7ed3\u679c\uff0c\u907f\u514d\u4e86\u4e4b\u524d\u5de5\u4f5c\u4e2d\u4f7f\u7528\u7684FT-mollification\u65b9\u6cd5\u3002", "result": "\u5bf9\u4e8e\u9ad8\u65af\u5206\u5e03\u4e0b\u7684k\u4e2a\u534a\u7a7a\u95f4\u51fd\u6570\uff0c\u83b7\u5f97\u4e86poly(k)\u5ea6\u7684\u4e09\u660e\u6cbb\u591a\u9879\u5f0f\uff0c\u76f8\u6bd4\u4e4b\u524d\u76842^O(k)\u5ea6\u6709\u6307\u6570\u7ea7\u6539\u8fdb\uff1b\u5bf9\u4e8e\u4f4e\u7ef4\u591a\u9879\u5f0f\u9608\u503c\u51fd\u6570\uff0c\u83b7\u5f97\u4e86\u53cc\u6307\u6570\u7ea7\u6539\u8fdb\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u76f8\u5bf9\u7b80\u5355\u4e14\u6709\u6548\uff0c\u9002\u7528\u4e8e\u4f4e\u7ef4\u4e14\u5177\u6709\u5e73\u6ed1\u8fb9\u754c\u7684\u51fd\u6570\u7c7b\uff0c\u4e3a\u4e09\u660e\u6cbb\u591a\u9879\u5f0f\u6784\u9020\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u5ea6\u754c\u3002"}}
{"id": "2602.24182", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24182", "abs": "https://arxiv.org/abs/2602.24182", "authors": ["Sikata Sengupta", "Guangyi Liu", "Omer Gottesman", "Joseph W Durham", "Michael Kearns", "Aaron Roth", "Michael Caldara"], "title": "Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers", "comment": null, "summary": "Optimizing the consolidation process in container-based fulfillment centers requires trading off competing objectives such as processing speed, resource usage, and space utilization while adhering to a range of real-world operational constraints. This process involves moving items between containers via a combination of human and robotic workstations to free up space for inbound inventory and increase container utilization. We formulate this problem as a large-scale Multi-Objective Reinforcement Learning (MORL) task with high-dimensional state spaces and dynamic system behavior. Our method builds on recent theoretical advances in solving constrained RL problems via best-response and no-regret dynamics in zero-sum games, enabling principled minimax policy learning. Policy evaluation on realistic warehouse simulations shows that our approach effectively trades off objectives, and we empirically observe that it learns a single policy that simultaneously satisfies all constraints, even if this is not theoretically guaranteed. We further introduce a theoretical framework to handle the problem of error cancellation, where time-averaged solutions display oscillatory behavior. This method returns a single iterate whose Lagrangian value is close to the minimax value of the game. These results demonstrate the promise of MORL in solving complex, high-impact decision-making problems in large-scale industrial systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u96c6\u88c5\u7bb1\u5f0f\u5c65\u7ea6\u4e2d\u5fc3\u7684\u6574\u5408\u8fc7\u7a0b\uff0c\u901a\u8fc7\u96f6\u548c\u535a\u5f08\u4e2d\u7684\u6700\u4f73\u54cd\u5e94\u548c\u65e0\u6094\u52a8\u6001\u6765\u89e3\u51b3\u7ea6\u675fRL\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5728\u6ee1\u8db3\u6240\u6709\u64cd\u4f5c\u7ea6\u675f\u7684\u540c\u65f6\u5e73\u8861\u5904\u7406\u901f\u5ea6\u3001\u8d44\u6e90\u4f7f\u7528\u548c\u7a7a\u95f4\u5229\u7528\u7387\u7b49\u591a\u4e2a\u76ee\u6807\u3002", "motivation": "\u96c6\u88c5\u7bb1\u5f0f\u5c65\u7ea6\u4e2d\u5fc3\u7684\u6574\u5408\u8fc7\u7a0b\u9700\u8981\u5728\u5904\u7406\u901f\u5ea6\u3001\u8d44\u6e90\u4f7f\u7528\u548c\u7a7a\u95f4\u5229\u7528\u7387\u7b49\u591a\u4e2a\u76f8\u4e92\u7ade\u4e89\u7684\u76ee\u6807\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u540c\u65f6\u8fd8\u8981\u6ee1\u8db3\u5404\u79cd\u73b0\u5b9e\u64cd\u4f5c\u7ea6\u675f\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u79cd\u5927\u89c4\u6a21\u3001\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u548c\u52a8\u6001\u7cfb\u7edf\u884c\u4e3a\u7684\u590d\u6742\u51b3\u7b56\u95ee\u9898\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u5927\u89c4\u6a21\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\uff0c\u5229\u7528\u96f6\u548c\u535a\u5f08\u4e2d\u7684\u6700\u4f73\u54cd\u5e94\u548c\u65e0\u6094\u52a8\u6001\u6765\u89e3\u51b3\u7ea6\u675fRL\u95ee\u9898\uff0c\u5b9e\u73b0\u539f\u5219\u6027\u7684\u6781\u5c0f\u6781\u5927\u7b56\u7565\u5b66\u4e60\u3002\u8fd8\u5f15\u5165\u4e86\u5904\u7406\u8bef\u5dee\u6d88\u9664\u95ee\u9898\u7684\u7406\u8bba\u6846\u67b6\uff0c\u907f\u514d\u65f6\u95f4\u5e73\u5747\u89e3\u51fa\u73b0\u632f\u8361\u884c\u4e3a\u3002", "result": "\u5728\u771f\u5b9e\u7684\u4ed3\u5e93\u6a21\u62df\u4e2d\u8fdb\u884c\u7b56\u7565\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6743\u8861\u591a\u4e2a\u76ee\u6807\uff0c\u5e76\u4e14\u7ecf\u9a8c\u89c2\u5bdf\u5230\u5b66\u4e60\u5230\u7684\u5355\u4e00\u7b56\u7565\u80fd\u591f\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u7ea6\u675f\uff08\u5c3d\u7ba1\u8fd9\u5728\u7406\u8bba\u4e0a\u65e0\u6cd5\u4fdd\u8bc1\uff09\u3002\u8be5\u65b9\u6cd5\u8fd4\u56de\u7684\u5355\u4e2a\u8fed\u4ee3\u7684\u62c9\u683c\u6717\u65e5\u503c\u63a5\u8fd1\u535a\u5f08\u7684\u6781\u5c0f\u6781\u5927\u503c\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u660e\u4e86\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u590d\u6742\u3001\u9ad8\u5f71\u54cd\u529b\u51b3\u7b56\u95ee\u9898\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u96c6\u88c5\u7bb1\u5c65\u7ea6\u4e2d\u5fc3\u7684\u6574\u5408\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.24201", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24201", "abs": "https://arxiv.org/abs/2602.24201", "authors": ["Egor Antipov", "Alessandro Palma", "Lorenzo Consoli", "Stephan G\u00fcnnemann", "Andrea Dittadi", "Fabian J. Theis"], "title": "Flow-Based Density Ratio Estimation for Intractable Distributions with Applications in Genomics", "comment": null, "summary": "Estimating density ratios between pairs of intractable data distributions is a core problem in probabilistic modeling, enabling principled comparisons of sample likelihoods under different data-generating processes across conditions and covariates. While exact-likelihood models such as normalizing flows offer a promising approach to density ratio estimation, naive flow-based evaluations are computationally expensive, as they require simulating costly likelihood integrals for each distribution separately. In this work, we leverage condition-aware flow matching to derive a single dynamical formulation for tracking density ratios along generative trajectories. We demonstrate competitive performance on simulated benchmarks for closed-form ratio estimation, and show that our method supports versatile tasks in single-cell genomics data analysis, where likelihood-based comparisons of cellular states across experimental conditions enable treatment effect estimation and batch correction evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u611f\u77e5\u6d41\u5339\u914d\u7684\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u65b9\u6cd5\uff0c\u907f\u514d\u5206\u522b\u8ba1\u7b97\u4e24\u4e2a\u5206\u5e03\u7684\u6602\u8d35\u4f3c\u7136\u79ef\u5206\uff0c\u5728\u6a21\u62df\u57fa\u51c6\u548c\u5355\u7ec6\u80de\u57fa\u56e0\u7ec4\u5b66\u6570\u636e\u5206\u6790\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u662f\u6982\u7387\u5efa\u6a21\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u7528\u4e8e\u5728\u4e0d\u540c\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u4e4b\u95f4\u8fdb\u884c\u539f\u5219\u6027\u7684\u4f3c\u7136\u6bd4\u8f83\u3002\u867d\u7136\u5f52\u4e00\u5316\u6d41\u7b49\u7cbe\u786e\u4f3c\u7136\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4f46\u4f20\u7edf\u7684\u6d41\u57fa\u8bc4\u4f30\u9700\u8981\u5206\u522b\u4e3a\u6bcf\u4e2a\u5206\u5e03\u8ba1\u7b97\u6602\u8d35\u7684\u4f3c\u7136\u79ef\u5206\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u5229\u7528\u6761\u4ef6\u611f\u77e5\u6d41\u5339\u914d\u6280\u672f\uff0c\u63a8\u5bfc\u51fa\u5355\u4e00\u52a8\u6001\u516c\u5f0f\u6765\u8ddf\u8e2a\u751f\u6210\u8f68\u8ff9\u4e0a\u7684\u5bc6\u5ea6\u6bd4\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u5206\u522b\u8ba1\u7b97\u4e24\u4e2a\u5206\u5e03\u4f3c\u7136\u79ef\u5206\u7684\u9700\u6c42\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u6846\u67b6\u76f4\u63a5\u5efa\u6a21\u5bc6\u5ea6\u6bd4\u7684\u53d8\u5316\u3002", "result": "\u5728\u95ed\u5f0f\u6bd4\u4f30\u8ba1\u7684\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u7ade\u4e89\u6027\u6027\u80fd\u3002\u5728\u5355\u7ec6\u80de\u57fa\u56e0\u7ec4\u5b66\u6570\u636e\u5206\u6790\u4e2d\uff0c\u8be5\u65b9\u6cd5\u652f\u6301\u591a\u79cd\u4efb\u52a1\uff0c\u5305\u62ec\u8de8\u5b9e\u9a8c\u6761\u4ef6\u7684\u7ec6\u80de\u72b6\u6001\u4f3c\u7136\u6bd4\u8f83\u3001\u6cbb\u7597\u6548\u679c\u4f30\u8ba1\u548c\u6279\u6b21\u6821\u6b63\u8bc4\u4f30\u3002", "conclusion": "\u63d0\u51fa\u7684\u6761\u4ef6\u611f\u77e5\u6d41\u5339\u914d\u65b9\u6cd5\u4e3a\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u6d41\u57fa\u65b9\u6cd5\u4e2d\u5206\u522b\u8ba1\u7b97\u4f3c\u7136\u79ef\u5206\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2602.24207", "categories": ["cs.LG", "cs.CY", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.24207", "abs": "https://arxiv.org/abs/2602.24207", "authors": ["Gabriele Farina", "Juan Carlos Perdomo"], "title": "The Stability of Online Algorithms in Performative Prediction", "comment": null, "summary": "The use of algorithmic predictions in decision-making leads to a feedback loop where the models we deploy actively influence the data distributions we see, and later use to retrain on. This dynamic was formalized by Perdomo et al. 2020 in their work on performative prediction. Our main result is an unconditional reduction showing that any no-regret algorithm deployed in performative settings converges to a (mixed) performatively stable equilibrium: a solution in which models actively shape data distributions in ways that their own predictions look optimal in hindsight. Prior to our work, all positive results in this area made strong restrictions on how models influenced distributions. By using a martingale argument and allowing randomization, we avoid any such assumption and sidestep recent hardness results for finding stable models. Lastly, on a more conceptual note, our connection sheds light on why common algorithms, like gradient descent, are naturally stabilizing and prevent runaway feedback loops. We hope our work enables future technical transfer of ideas between online optimization and performativity.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u5728\u9884\u6d4b\u6027\u9884\u6d4b\u6846\u67b6\u4e2d\uff0c\u4efb\u4f55\u65e0\u9057\u61be\u7b97\u6cd5\u90fd\u4f1a\u6536\u655b\u5230\uff08\u6df7\u5408\uff09\u9884\u6d4b\u7a33\u5b9a\u5747\u8861\uff0c\u65e0\u9700\u5bf9\u6a21\u578b\u5982\u4f55\u5f71\u54cd\u6570\u636e\u5206\u5e03\u505a\u4efb\u4f55\u9650\u5236\u6027\u5047\u8bbe\u3002", "motivation": "\u7b97\u6cd5\u9884\u6d4b\u5728\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u4f1a\u5bfc\u81f4\u53cd\u9988\u5faa\u73af\uff1a\u90e8\u7f72\u7684\u6a21\u578b\u4e3b\u52a8\u5f71\u54cd\u6211\u4eec\u89c2\u5bdf\u5230\u7684\u6570\u636e\u5206\u5e03\uff0c\u800c\u8fd9\u4e9b\u6570\u636e\u53c8\u7528\u4e8e\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002\u8fd9\u79cd\u52a8\u6001\u5173\u7cfb\u7531Perdomo\u7b49\u4eba\uff082020\uff09\u5728\u9884\u6d4b\u6027\u9884\u6d4b\u5de5\u4f5c\u4e2d\u5f62\u5f0f\u5316\u3002\u73b0\u6709\u7814\u7a76\u5bf9\u6a21\u578b\u5982\u4f55\u5f71\u54cd\u5206\u5e03\u6709\u4e25\u683c\u9650\u5236\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u9785\u8bba\u8bba\u8bc1\u548c\u5141\u8bb8\u968f\u673a\u5316\uff0c\u907f\u514d\u4e86\u6240\u6709\u5bf9\u6a21\u578b\u5f71\u54cd\u5206\u5e03\u7684\u5047\u8bbe\uff0c\u7ed5\u8fc7\u4e86\u6700\u8fd1\u5173\u4e8e\u5bfb\u627e\u7a33\u5b9a\u6a21\u578b\u7684\u786c\u5ea6\u7ed3\u679c\u3002\u5c06\u5728\u7ebf\u4f18\u5316\u4e0e\u9884\u6d4b\u6027\u9884\u6d4b\u8054\u7cfb\u8d77\u6765\uff0c\u5efa\u7acb\u4e86\u65e0\u6761\u4ef6\u7ea6\u7b80\u3002", "result": "\u8bc1\u660e\u4e86\u4efb\u4f55\u65e0\u9057\u61be\u7b97\u6cd5\u5728\u9884\u6d4b\u6027\u8bbe\u7f6e\u4e2d\u90fd\u4f1a\u6536\u655b\u5230\uff08\u6df7\u5408\uff09\u9884\u6d4b\u7a33\u5b9a\u5747\u8861\uff1a\u5728\u8fd9\u79cd\u89e3\u4e2d\uff0c\u6a21\u578b\u4e3b\u52a8\u5851\u9020\u6570\u636e\u5206\u5e03\uff0c\u4f7f\u5f97\u5b83\u4eec\u81ea\u5df1\u7684\u9884\u6d4b\u5728\u540e\u9a8c\u770b\u8d77\u6765\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u8be5\u8fde\u63a5\u63ed\u793a\u4e86\u4e3a\u4ec0\u4e48\u5e38\u89c1\u7b97\u6cd5\uff08\u5982\u68af\u5ea6\u4e0b\u964d\uff09\u5929\u7136\u5177\u6709\u7a33\u5b9a\u6027\u548c\u9632\u6b62\u5931\u63a7\u53cd\u9988\u5faa\u73af\u7684\u80fd\u529b\u3002\u8fd9\u9879\u5de5\u4f5c\u6709\u671b\u4fc3\u8fdb\u5728\u7ebf\u4f18\u5316\u548c\u9884\u6d4b\u6027\u9884\u6d4b\u4e4b\u95f4\u601d\u60f3\u7684\u6280\u672f\u8f6c\u79fb\u3002"}}
{"id": "2602.24209", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24209", "abs": "https://arxiv.org/abs/2602.24209", "authors": ["Mohsen Tajgardan", "Atena Shiranzaei", "Mahdi Rabbani", "Reza Khoshkangini", "Mahtab Jamali"], "title": "An Efficient Unsupervised Federated Learning Approach for Anomaly Detection in Heterogeneous IoT Networks", "comment": null, "summary": "Federated learning (FL) is an effective paradigm for distributed environments such as the Internet of Things (IoT), where data from diverse devices with varying functionalities remains localized while contributing to a shared global model. By eliminating the need to transmit raw data, FL inherently preserves privacy. However, the heterogeneous nature of IoT data, stemming from differences in device capabilities, data formats, and communication constraints, poses significant challenges to maintaining both global model performance and privacy. In the context of IoT-based anomaly detection, unsupervised FL offers a promising means to identify abnormal behavior without centralized data aggregation. Nevertheless, feature heterogeneity across devices complicates model training and optimization, hindering effective implementation. In this study we propose an efficient unsupervised FL framework that enhances anomaly detection by leveraging shared features from two distinct IoT datasets: one focused on anomaly detection and the other on device identification, while preserving dataset-specific features. To improve transparency and interpretability, we employ explainable AI techniques, such as SHAP, to identify key features influencing local model decisions. Experiments conducted on real-world IoT datasets demonstrate that the proposed method significantly outperforms conventional FL approaches in anomaly detection accuracy. This work underscores the potential of using shared features from complementary datasets to optimize unsupervised federated learning and achieve superior anomaly detection results in decentralized IoT environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u4e24\u4e2a\u4e0d\u540c\u7269\u8054\u7f51\u6570\u636e\u96c6\u7684\u5171\u4eab\u7279\u5f81\u6765\u589e\u5f3a\u5f02\u5e38\u68c0\u6d4b\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u96c6\u7279\u5b9a\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u53ef\u89e3\u91caAI\u63d0\u9ad8\u900f\u660e\u5ea6\u3002", "motivation": "\u7269\u8054\u7f51\u73af\u5883\u4e2d\u7684\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u6570\u636e\u5f02\u6784\u6027\u6311\u6218\uff0c\u8bbe\u5907\u80fd\u529b\u3001\u6570\u636e\u683c\u5f0f\u548c\u901a\u4fe1\u7ea6\u675f\u7684\u5dee\u5f02\u5f71\u54cd\u4e86\u5168\u5c40\u6a21\u578b\u6027\u80fd\u548c\u9690\u79c1\u4fdd\u62a4\u3002\u5728\u7269\u8054\u7f51\u5f02\u5e38\u68c0\u6d4b\u4e2d\uff0c\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u867d\u7136\u907f\u514d\u4e86\u96c6\u4e2d\u6570\u636e\u805a\u5408\uff0c\u4f46\u7279\u5f81\u5f02\u6784\u6027\u963b\u788d\u4e86\u6709\u6548\u5b9e\u65bd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u9ad8\u6548\u7684\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u4e24\u4e2a\u4e0d\u540c\u7269\u8054\u7f51\u6570\u636e\u96c6\uff08\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u5f02\u5e38\u68c0\u6d4b\uff0c\u53e6\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u8bbe\u5907\u8bc6\u522b\uff09\u7684\u5171\u4eab\u7279\u5f81\u6765\u589e\u5f3a\u5f02\u5e38\u68c0\u6d4b\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u96c6\u7279\u5b9a\u7279\u5f81\u3002\u4f7f\u7528\u53ef\u89e3\u91caAI\u6280\u672f\uff08\u5982SHAP\uff09\u8bc6\u522b\u5f71\u54cd\u672c\u5730\u6a21\u578b\u51b3\u7b56\u7684\u5173\u952e\u7279\u5f81\uff0c\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u771f\u5b9e\u7269\u8054\u7f51\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5f02\u5e38\u68c0\u6d4b\u51c6\u786e\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u5229\u7528\u4e92\u8865\u6570\u636e\u96c6\u7684\u5171\u4eab\u7279\u5f81\u6765\u4f18\u5316\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\uff0c\u5728\u53bb\u4e2d\u5fc3\u5316\u7269\u8054\u7f51\u73af\u5883\u4e2d\u5b9e\u73b0\u5353\u8d8a\u5f02\u5e38\u68c0\u6d4b\u7ed3\u679c\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.24231", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24231", "abs": "https://arxiv.org/abs/2602.24231", "authors": ["Hongrui Xie", "Junyu Cao", "Kan Xu"], "title": "Adaptive Combinatorial Experimental Design: Pareto Optimality for Decision-Making and Inference", "comment": "30 pages, 3 figure, AISTATS 2026 accepted paper", "summary": "In this paper, we provide the first investigation into adaptive combinatorial experimental design, focusing on the trade-off between regret minimization and statistical power in combinatorial multi-armed bandits (CMAB). While minimizing regret requires repeated exploitation of high-reward arms, accurate inference on reward gaps requires sufficient exploration of suboptimal actions. We formalize this trade-off through the concept of Pareto optimality and establish equivalent conditions for Pareto-efficient learning in CMAB. We consider two relevant cases under different information structures, i.e., full-bandit feedback and semi-bandit feedback, and propose two algorithms MixCombKL and MixCombUCB respectively for these two cases. We provide theoretical guarantees showing that both algorithms are Pareto optimal, achieving finite-time guarantees on both regret and estimation error of arm gaps. Our results further reveal that richer feedback significantly tightens the attainable Pareto frontier, with the primary gains arising from improved estimation accuracy under our proposed methods. Taken together, these findings establish a principled framework for adaptive combinatorial experimentation in multi-objective decision-making.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7814\u7a76\u81ea\u9002\u5e94\u7ec4\u5408\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u5728\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u4e2d\u5e73\u8861\u9057\u61be\u6700\u5c0f\u5316\u4e0e\u7edf\u8ba1\u529f\u6548\u7684\u6743\u8861\uff0c\u63d0\u51fa\u5e15\u7d2f\u6258\u6700\u4f18\u5b66\u4e60\u6846\u67b6\u548c\u4e24\u79cd\u7b97\u6cd5\uff0c\u8bc1\u660e\u5728\u4e24\u79cd\u53cd\u9988\u673a\u5236\u4e0b\u90fd\u80fd\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\u3002", "motivation": "\u5728\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u4e2d\uff0c\u6700\u5c0f\u5316\u9057\u61be\u9700\u8981\u91cd\u590d\u5229\u7528\u9ad8\u5956\u52b1\u81c2\uff0c\u800c\u51c6\u786e\u63a8\u65ad\u5956\u52b1\u5dee\u8ddd\u9700\u8981\u5145\u5206\u63a2\u7d22\u6b21\u4f18\u52a8\u4f5c\u3002\u8fd9\u79cd\u6743\u8861\u5728\u81ea\u9002\u5e94\u7ec4\u5408\u5b9e\u9a8c\u8bbe\u8ba1\u4e2d\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u7814\u7a76\uff0c\u9700\u8981\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u6765\u5e73\u8861\u8fd9\u4e24\u4e2a\u76ee\u6807\u3002", "method": "\u901a\u8fc7\u5e15\u7d2f\u6258\u6700\u4f18\u6027\u6982\u5ff5\u5f62\u5f0f\u5316\u6743\u8861\uff0c\u8003\u8651\u4e24\u79cd\u4fe1\u606f\u7ed3\u6784\uff1a\u5168\u8001\u864e\u673a\u53cd\u9988\u548c\u534a\u8001\u864e\u673a\u53cd\u9988\u3002\u9488\u5bf9\u8fd9\u4e24\u79cd\u60c5\u51b5\u5206\u522b\u63d0\u51faMixCombKL\u548cMixCombUCB\u7b97\u6cd5\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u8bc1\u660e\u4e24\u79cd\u7b97\u6cd5\u90fd\u662f\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u4e24\u79cd\u7b97\u6cd5\u90fd\u80fd\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\uff0c\u83b7\u5f97\u9057\u61be\u548c\u81c2\u5dee\u8ddd\u4f30\u8ba1\u8bef\u5dee\u7684\u6709\u9650\u65f6\u95f4\u4fdd\u8bc1\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u66f4\u4e30\u5bcc\u7684\u53cd\u9988\u80fd\u663e\u8457\u6536\u7d27\u53ef\u8fbe\u5230\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u4e3b\u8981\u589e\u76ca\u6765\u81ea\u6240\u63d0\u65b9\u6cd5\u4e0b\u4f30\u8ba1\u7cbe\u5ea6\u7684\u63d0\u5347\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u591a\u76ee\u6807\u51b3\u7b56\u4e2d\u7684\u81ea\u9002\u5e94\u7ec4\u5408\u5b9e\u9a8c\u5efa\u7acb\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u4e2d\u9057\u61be\u6700\u5c0f\u5316\u4e0e\u7edf\u8ba1\u529f\u6548\u7684\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.24238", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24238", "abs": "https://arxiv.org/abs/2602.24238", "authors": ["Javier Pulido", "Filipe Rodrigues"], "title": "Time Series Foundation Models as Strong Baselines in Transportation Forecasting: A Large-Scale Benchmark Analysis", "comment": "6 pages", "summary": "Accurate forecasting of transportation dynamics is essential for urban mobility and infrastructure planning. Although recent work has achieved strong performance with deep learning models, these methods typically require dataset-specific training, architecture design and hyper-parameter tuning. This paper evaluates whether general-purpose time-series foundation models can serve as forecasters for transportation tasks by benchmarking the zero-shot performance of the state-of-the-art model, Chronos-2, across ten real-world datasets covering highway traffic volume and flow, urban traffic speed, bike-sharing demand, and electric vehicle charging station data. Under a consistent evaluation protocol, we find that, even without any task-specific fine-tuning, Chronos-2 delivers state-of-the-art or competitive accuracy across most datasets, frequently outperforming classical statistical baselines and specialized deep learning architectures, particularly at longer horizons. Beyond point forecasting, we evaluate its native probabilistic outputs using prediction-interval coverage and sharpness, demonstrating that Chronos-2 also provides useful uncertainty quantification without dataset-specific training. In general, this study supports the adoption of time-series foundation models as a key baseline for transportation forecasting research.", "AI": {"tldr": "\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578bChronos-2\u5728\u4ea4\u901a\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0c\u53d1\u73b0\u5176\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u8fbe\u5230SOTA\u6216\u7ade\u4e89\u6027\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u957f\u9884\u6d4b\u65f6\u57df\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u4ea4\u901a\u9884\u6d4b\u65b9\u6cd5\u9700\u8981\u9488\u5bf9\u6bcf\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u7279\u5b9a\u8bad\u7ec3\u3001\u67b6\u6784\u8bbe\u8ba1\u548c\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u8fc7\u7a0b\u7e41\u7410\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u4f5c\u4e3a\u4ea4\u901a\u9884\u6d4b\u7684\u57fa\u51c6\u65b9\u6cd5\uff0c\u51cf\u5c11\u91cd\u590d\u6027\u5de5\u4f5c\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578bChronos-2\uff0c\u572810\u4e2a\u771f\u5b9e\u4e16\u754c\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u96f6\u6837\u672c\u6027\u80fd\u8bc4\u4f30\uff0c\u6db5\u76d6\u9ad8\u901f\u516c\u8def\u4ea4\u901a\u91cf/\u6d41\u91cf\u3001\u57ce\u5e02\u4ea4\u901a\u901f\u5ea6\u3001\u5171\u4eab\u5355\u8f66\u9700\u6c42\u548c\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u6570\u636e\u3002\u91c7\u7528\u4e00\u81f4\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u4e0d\u4ec5\u8bc4\u4f30\u70b9\u9884\u6d4b\u7cbe\u5ea6\uff0c\u8fd8\u8bc4\u4f30\u5176\u539f\u751f\u6982\u7387\u8f93\u51fa\u7684\u9884\u6d4b\u533a\u95f4\u8986\u76d6\u7387\u548c\u9510\u5ea6\u3002", "result": "\u5373\u4f7f\u6ca1\u6709\u4efb\u4f55\u4efb\u52a1\u7279\u5b9a\u7684\u5fae\u8c03\uff0cChronos-2\u5728\u5927\u591a\u6570\u6570\u636e\u96c6\u4e0a\u90fd\u80fd\u8fbe\u5230\u6700\u5148\u8fdb\u6216\u5177\u6709\u7ade\u4e89\u529b\u7684\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u957f\u9884\u6d4b\u65f6\u57df\u4e0a\u7ecf\u5e38\u8d85\u8d8a\u7ecf\u5178\u7edf\u8ba1\u57fa\u7ebf\u548c\u4e13\u95e8\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002\u5176\u6982\u7387\u8f93\u51fa\u4e5f\u80fd\u63d0\u4f9b\u6709\u7528\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "conclusion": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u4ea4\u901a\u9884\u6d4b\u7814\u7a76\u7684\u5173\u952e\u57fa\u51c6\u65b9\u6cd5\uff0c\u652f\u6301\u5176\u5728\u4ea4\u901a\u9884\u6d4b\u9886\u57df\u7684\u91c7\u7528\uff0c\u51cf\u5c11\u5bf9\u6570\u636e\u96c6\u7279\u5b9a\u8bad\u7ec3\u7684\u9700\u6c42\u3002"}}
{"id": "2602.24281", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24281", "abs": "https://arxiv.org/abs/2602.24281", "authors": ["Ali Behrouz", "Zeman Li", "Yuan Deng", "Peilin Zhong", "Meisam Razaviyayn", "Vahab Mirrokni"], "title": "Memory Caching: RNNs with Growing Memory", "comment": null, "summary": "Transformers have been established as the de-facto backbones for most recent advances in sequence modeling, mainly due to their growing memory capacity that scales with the context length. While plausible for retrieval tasks, it causes quadratic complexity and so has motivated recent studies to explore viable subquadratic recurrent alternatives. Despite showing promising preliminary results in diverse domains, such recurrent architectures underperform Transformers in recall-intensive tasks, often attributed to their fixed-size memory. In this paper, we introduce Memory Caching (MC), a simple yet effective technique that enhances recurrent models by caching checkpoints of their memory states (a.k.a. hidden states). Memory Caching allows the effective memory capacity of RNNs to grow with sequence length, offering a flexible trade-off that interpolates between the fixed memory (i.e., $O(L)$ complexity) of RNNs and the growing memory (i.e., $O(L^2)$ complexity) of Transformers. We propose four variants of MC, including gated aggregation and sparse selective mechanisms, and discuss their implications on both linear and deep memory modules. Our experimental results on language modeling, and long-context understanding tasks show that MC enhances the performance of recurrent models, supporting its effectiveness. The results of in-context recall tasks indicate that while Transformers achieve the best accuracy, our MC variants show competitive performance, close the gap with Transformers, and performs better than state-of-the-art recurrent models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMemory Caching\u6280\u672f\uff0c\u901a\u8fc7\u7f13\u5b58RNN\u9690\u85cf\u72b6\u6001\u68c0\u67e5\u70b9\u6765\u589e\u5f3a\u5faa\u73af\u6a21\u578b\uff0c\u4f7f\u5176\u5185\u5b58\u5bb9\u91cf\u968f\u5e8f\u5217\u957f\u5ea6\u589e\u957f\uff0c\u5728\u56fa\u5b9a\u5185\u5b58\u7684RNN\u548c\u4e8c\u6b21\u590d\u6742\u5ea6\u7684Transformer\u4e4b\u95f4\u63d0\u4f9b\u7075\u6d3b\u6743\u8861\u3002", "motivation": "Transformer\u867d\u7136\u6027\u80fd\u5f3a\u5927\u4f46\u5177\u6709\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u800c\u73b0\u6709\u7684\u5faa\u73af\u67b6\u6784\u5728\u53ec\u56de\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5176\u56fa\u5b9a\u5927\u5c0f\u7684\u5185\u5b58\u5bb9\u91cf\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "\u63d0\u51faMemory Caching\u6280\u672f\uff0c\u5305\u62ec\u56db\u79cd\u53d8\u4f53\uff1a\u95e8\u63a7\u805a\u5408\u548c\u7a00\u758f\u9009\u62e9\u673a\u5236\uff0c\u901a\u8fc7\u7f13\u5b58RNN\u9690\u85cf\u72b6\u6001\u68c0\u67e5\u70b9\u6765\u6269\u5c55\u6709\u6548\u5185\u5b58\u5bb9\u91cf\u3002", "result": "\u5728\u8bed\u8a00\u5efa\u6a21\u548c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u4efb\u52a1\u4e2d\uff0cMC\u663e\u8457\u63d0\u5347\u4e86\u5faa\u73af\u6a21\u578b\u7684\u6027\u80fd\uff1b\u5728\u4e0a\u4e0b\u6587\u53ec\u56de\u4efb\u52a1\u4e2d\uff0cMC\u53d8\u4f53\u8868\u73b0\u51fa\u4e0eTransformer\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u7f29\u5c0f\u4e86\u4e0eTransformer\u7684\u5dee\u8ddd\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u5faa\u73af\u6a21\u578b\u3002", "conclusion": "Memory Caching\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6280\u672f\uff0c\u80fd\u591f\u589e\u5f3a\u5faa\u73af\u6a21\u578b\u7684\u5185\u5b58\u5bb9\u91cf\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u540c\u65f6\u63d0\u4f9b\u63a5\u8fd1Transformer\u7684\u6027\u80fd\uff0c\u4e3a\u5e8f\u5217\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u9009\u62e9\u3002"}}
{"id": "2602.24245", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24245", "abs": "https://arxiv.org/abs/2602.24245", "authors": ["Hainan Xu", "Vladimir Bataev", "Travis M. Bartley", "Jagadeesh Balam"], "title": "Chunk-wise Attention Transducers for Fast and Accurate Streaming Speech-to-Text", "comment": "Accepted at ICASSP 2026", "summary": "We propose Chunk-wise Attention Transducer (CHAT), a novel extension to RNN-T models that processes audio in fixed-size chunks while employing cross-attention within each chunk. This hybrid approach maintains RNN-T's streaming capability while introducing controlled flexibility for local alignment modeling. CHAT significantly reduces the temporal dimension that RNN-T must handle, yielding substantial efficiency improvements: up to 46.2% reduction in peak training memory, up to 1.36X faster training, and up to 1.69X faster inference. Alongside these efficiency gains, CHAT achieves consistent accuracy improvements over RNN-T across multiple languages and tasks -- up to 6.3% relative WER reduction for speech recognition and up to 18.0% BLEU improvement for speech translation. The method proves particularly effective for speech translation, where RNN-T's strict monotonic alignment hurts performance. Our results demonstrate that the CHAT model offers a practical solution for deploying more capable streaming speech models without sacrificing real-time constraints.", "AI": {"tldr": "CHAT\u6a21\u578b\u5728RNN-T\u57fa\u7840\u4e0a\u5f15\u5165\u5206\u5757\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u4fdd\u6301\u6d41\u5f0f\u5904\u7406\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edfRNN-T\u6a21\u578b\u5728\u5904\u7406\u8bed\u97f3\u65f6\u5b58\u5728\u4e25\u683c\u7684\u5355\u8c03\u5bf9\u9f50\u9650\u5236\uff0c\u8fd9\u5728\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u4f1a\u5f71\u54cd\u6027\u80fd\u3002\u540c\u65f6\uff0cRNN-T\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u5b58\u5728\u6548\u7387\u548c\u5185\u5b58\u6d88\u8017\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5206\u5757\u6ce8\u610f\u529b\u8f6c\u6362\u5668\uff08CHAT\uff09\uff0c\u5c06\u97f3\u9891\u5206\u5272\u6210\u56fa\u5b9a\u5927\u5c0f\u7684\u5757\uff0c\u5728\u6bcf\u4e2a\u5757\u5185\u4f7f\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u3002\u8fd9\u79cd\u6df7\u5408\u65b9\u6cd5\u4fdd\u6301\u4e86RNN-T\u7684\u6d41\u5f0f\u5904\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4e3a\u5c40\u90e8\u5bf9\u9f50\u5efa\u6a21\u5f15\u5165\u4e86\u53ef\u63a7\u7684\u7075\u6d3b\u6027\u3002", "result": "CHAT\u663e\u8457\u51cf\u5c11\u4e86RNN-T\u9700\u8981\u5904\u7406\u7684\u65f6\u95f4\u7ef4\u5ea6\uff0c\u5e26\u6765\u663e\u8457\u6548\u7387\u63d0\u5347\uff1a\u8bad\u7ec3\u5cf0\u503c\u5185\u5b58\u51cf\u5c1146.2%\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u53471.36\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53471.69\u500d\u3002\u5728\u51c6\u786e\u6027\u65b9\u9762\uff0c\u8bed\u97f3\u8bc6\u522b\u76f8\u5bf9WER\u964d\u4f4e6.3%\uff0c\u8bed\u97f3\u7ffb\u8bd1BLEU\u63d0\u534718.0%\u3002", "conclusion": "CHAT\u6a21\u578b\u4e3a\u90e8\u7f72\u66f4\u5f3a\u5927\u7684\u6d41\u5f0f\u8bed\u97f3\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4e0d\u727a\u7272\u5b9e\u65f6\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u53cc\u91cd\u63d0\u5347\uff0c\u7279\u522b\u5728\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.24283", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24283", "abs": "https://arxiv.org/abs/2602.24283", "authors": ["Zhengbo Wang", "Jian Liang", "Ran He", "Zilei Wang", "Tieniu Tan"], "title": "Taming Momentum: Rethinking Optimizer States Through Low-Rank Approximation", "comment": "Camera-ready version. Accepted as Oral at ICLR 2026", "summary": "Modern optimizers like Adam and Muon are central to training large language models, but their reliance on first- and second-order momenta introduces significant memory overhead, which constrains scalability and computational efficiency. In this work, we reframe the exponential moving average (EMA) used in these momenta as the training of a linear regressor via online gradient flow. Building on this equivalence, we introduce LoRA-Pre, a novel low-rank optimizer designed for efficient pre-training. Specifically, LoRA-Pre reduces the optimizer's memory footprint by decomposing the full momentum matrix into a compact low-rank subspace within the online linear learner, thereby maintaining optimization performance while improving memory efficiency. We empirically validate LoRA-Pre's efficacy by pre-training models from the Llama architecture family, scaling from 60M to 1B parameters. LoRA-Pre achieves the highest performance across all model sizes. Notably, LoRA-Pre demonstrates remarkable rank efficiency, achieving comparable or superior results using only 1/8 the rank of baseline methods. Beyond pre-training, we evaluate LoRA-Pre's effectiveness in fine-tuning scenarios. With the same rank, LoRA-Pre consistently outperforms all efficient fine-tuning baselines. Specifically, compared to standard LoRA, LoRA-Pre achieves substantial improvements of 3.14 points on Llama-3.1-8B and 6.17 points on Llama-2-7B, validating our approach's effectiveness across both pre-training and fine-tuning paradigms. Our code is publicly available at https://github.com/mrflogs/LoRA-Pre.", "AI": {"tldr": "LoRA-Pre\u662f\u4e00\u79cd\u65b0\u9896\u7684\u4f4e\u79e9\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u5c06\u52a8\u91cf\u77e9\u9635\u5206\u89e3\u4e3a\u7d27\u51d1\u7684\u4f4e\u79e9\u5b50\u7a7a\u95f4\uff0c\u663e\u8457\u51cf\u5c11\u4f18\u5316\u5668\u5185\u5b58\u5f00\u9500\uff0c\u5728\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u4e2d\u90fd\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u4f18\u5316\u5668\u5982Adam\u548cMuon\u4f9d\u8d56\u4e00\u9636\u548c\u4e8c\u9636\u52a8\u91cf\uff0c\u5f15\u5165\u663e\u8457\u5185\u5b58\u5f00\u9500\uff0c\u9650\u5236\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u53ef\u6269\u5c55\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u5c06\u6307\u6570\u79fb\u52a8\u5e73\u5747\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5728\u7ebf\u68af\u5ea6\u6d41\u7684\u7ebf\u6027\u56de\u5f52\u5668\u8bad\u7ec3\uff0c\u5e76\u5f15\u5165LoRA-Pre\u4f4e\u79e9\u4f18\u5316\u5668\uff0c\u5c06\u5b8c\u6574\u52a8\u91cf\u77e9\u9635\u5206\u89e3\u4e3a\u5728\u7ebf\u7ebf\u6027\u5b66\u4e60\u5668\u4e2d\u7684\u7d27\u51d1\u4f4e\u79e9\u5b50\u7a7a\u95f4\u3002", "result": "\u5728Llama\u67b6\u6784\u5bb6\u65cf\uff0860M\u52301B\u53c2\u6570\uff09\u7684\u9884\u8bad\u7ec3\u4e2d\uff0cLoRA-Pre\u5728\u6240\u6709\u6a21\u578b\u89c4\u6a21\u4e0a\u53d6\u5f97\u6700\u9ad8\u6027\u80fd\uff0c\u4ec5\u4f7f\u7528\u57fa\u7ebf\u65b9\u6cd51/8\u7684\u79e9\u5c31\u80fd\u83b7\u5f97\u76f8\u5f53\u6216\u66f4\u597d\u7684\u7ed3\u679c\u3002\u5728\u5fae\u8c03\u573a\u666f\u4e2d\uff0c\u76f8\u6bd4\u6807\u51c6LoRA\uff0c\u5728Llama-3.1-8B\u4e0a\u63d0\u53473.14\u5206\uff0c\u5728Llama-2-7B\u4e0a\u63d0\u53476.17\u5206\u3002", "conclusion": "LoRA-Pre\u901a\u8fc7\u4f4e\u79e9\u5206\u89e3\u6709\u6548\u51cf\u5c11\u4f18\u5316\u5668\u5185\u5b58\u5f00\u9500\uff0c\u5728\u4fdd\u6301\u4f18\u5316\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u5185\u5b58\u6548\u7387\uff0c\u5728\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u4e24\u79cd\u8303\u5f0f\u4e0b\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.24286", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24286", "abs": "https://arxiv.org/abs/2602.24286", "authors": ["Weinan Dai", "Hanlin Wu", "Qiying Yu", "Huan-ang Gao", "Jiahao Li", "Chengquan Jiang", "Weiqiang Lou", "Yufan Song", "Hongli Yu", "Jiaze Chen", "Wei-Ying Ma", "Ya-Qin Zhang", "Jingjing Liu", "Mingxuan Wang", "Xin Liu", "Hao Zhou"], "title": "CUDA Agent: Large-Scale Agentic RL for High-Performance CUDA Kernel Generation", "comment": null, "summary": "GPU kernel optimization is fundamental to modern deep learning but remains a highly specialized task requiring deep hardware expertise. Despite strong performance in general programming, large language models (LLMs) remain uncompetitive with compiler-based systems such as torch.compile for CUDA kernel generation. Existing CUDA code generation approaches either rely on training-free refinement or fine-tune models within fixed multi-turn execution-feedback loops, but both paradigms fail to fundamentally improve the model's intrinsic CUDA optimization ability, resulting in limited performance gains. We present CUDA Agent, a large-scale agentic reinforcement learning system that develops CUDA kernel expertise through three components: a scalable data synthesis pipeline, a skill-augmented CUDA development environment with automated verification and profiling to provide reliable reward signals, and reinforcement learning algorithmic techniques enabling stable training. CUDA Agent achieves state-of-the-art results on KernelBench, delivering 100\\%, 100\\%, and 92\\% faster rate over torch.compile on KernelBench Level-1, Level-2, and Level-3 splits, outperforming the strongest proprietary models such as Claude Opus 4.5 and Gemini 3 Pro by about 40\\% on the hardest Level-3 setting.", "AI": {"tldr": "CUDA Agent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u89c4\u6a21\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u6570\u636e\u5408\u6210\u3001\u6280\u80fd\u589e\u5f3a\u7684\u5f00\u53d1\u73af\u5883\u548c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728CUDA\u5185\u6838\u4f18\u5316\u65b9\u9762\u7684\u80fd\u529b\uff0c\u6027\u80fd\u8fdc\u8d85\u73b0\u6709\u7f16\u8bd1\u5668\u7cfb\u7edf\u548c\u4e13\u6709\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u901a\u7528\u7f16\u7a0b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728CUDA\u5185\u6838\u4f18\u5316\u65b9\u9762\u4ecd\u65e0\u6cd5\u4e0e\u7f16\u8bd1\u5668\u7cfb\u7edf\uff08\u5982torch.compile\uff09\u7ade\u4e89\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u65e0\u8bad\u7ec3\u7684\u7cbe\u70bc\uff0c\u8981\u4e48\u5728\u56fa\u5b9a\u7684\u591a\u8f6e\u6267\u884c\u53cd\u9988\u5faa\u73af\u4e2d\u5fae\u8c03\u6a21\u578b\uff0c\u90fd\u65e0\u6cd5\u4ece\u6839\u672c\u4e0a\u63d0\u5347\u6a21\u578b\u7684\u5185\u5728CUDA\u4f18\u5316\u80fd\u529b\uff0c\u5bfc\u81f4\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002", "method": "CUDA Agent\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u53ef\u6269\u5c55\u7684\u6570\u636e\u5408\u6210\u6d41\u6c34\u7ebf\uff1b2\uff09\u6280\u80fd\u589e\u5f3a\u7684CUDA\u5f00\u53d1\u73af\u5883\uff0c\u5177\u6709\u81ea\u52a8\u9a8c\u8bc1\u548c\u5206\u6790\u529f\u80fd\u4ee5\u63d0\u4f9b\u53ef\u9760\u7684\u5956\u52b1\u4fe1\u53f7\uff1b3\uff09\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6280\u672f\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u5927\u89c4\u6a21\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6765\u57f9\u517bCUDA\u5185\u6838\u7684\u4e13\u4e1a\u77e5\u8bc6\u3002", "result": "\u5728KernelBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCUDA Agent\u5728Level-1\u3001Level-2\u548cLevel-3\u4e09\u4e2a\u96be\u5ea6\u7ea7\u522b\u4e0a\u5206\u522b\u6bd4torch.compile\u5feb100%\u3001100%\u548c92%\u3002\u5728\u6700\u96be\u7684Level-3\u8bbe\u7f6e\u4e0a\uff0c\u6bd4\u6700\u5f3a\u7684\u4e13\u6709\u6a21\u578b\uff08\u5982Claude Opus 4.5\u548cGemini 3 Pro\uff09\u6027\u80fd\u9ad8\u51fa\u7ea640%\u3002", "conclusion": "CUDA Agent\u901a\u8fc7\u521b\u65b0\u7684\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728CUDA\u5185\u6838\u4f18\u5316\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u786c\u4ef6\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.24278", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24278", "abs": "https://arxiv.org/abs/2602.24278", "authors": ["Shruti Joshi", "Th\u00e9o Saulus", "Wieland Brendel", "Philippe Brouillard", "Dhanya Sridhar", "Patrik Reizinger"], "title": "Who Guards the Guardians? The Challenges of Evaluating Identifiability of Learned Representations", "comment": null, "summary": "Identifiability in representation learning is commonly evaluated using standard metrics (e.g., MCC, DCI, R^2) on synthetic benchmarks with known ground-truth factors. These metrics are assumed to reflect recovery up to the equivalence class guaranteed by identifiability theory. We show that this assumption holds only under specific structural conditions: each metric implicitly encodes assumptions about both the data-generating process (DGP) and the encoder. When these assumptions are violated, metrics become misspecified and can produce systematic false positives and false negatives. Such failures occur both within classical identifiability regimes and in post-hoc settings where identifiability is most needed. We introduce a taxonomy separating DGP assumptions from encoder geometry, use it to characterise the validity domains of existing metrics, and release an evaluation suite for reproducible stress testing and comparison.", "AI": {"tldr": "\u73b0\u6709\u8868\u793a\u5b66\u4e60\u53ef\u8bc6\u522b\u6027\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u5047\u8bbe\u6761\u4ef6\u9650\u5236\uff0c\u5f53\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u6216\u7f16\u7801\u5668\u51e0\u4f55\u5047\u8bbe\u88ab\u8fdd\u53cd\u65f6\uff0c\u8fd9\u4e9b\u6307\u6807\u4f1a\u4ea7\u751f\u7cfb\u7edf\u6027\u8bef\u5224", "motivation": "\u5f53\u524d\u8868\u793a\u5b66\u4e60\u53ef\u8bc6\u522b\u6027\u8bc4\u4f30\u4f9d\u8d56\u4e8e\u6807\u51c6\u6307\u6807\uff08\u5982MCC\u3001DCI\u3001R\u00b2\uff09\uff0c\u8fd9\u4e9b\u6307\u6807\u5047\u8bbe\u80fd\u591f\u53cd\u6620\u7406\u8bba\u53ef\u8bc6\u522b\u6027\u4fdd\u8bc1\u7684\u7b49\u4ef7\u7c7b\u6062\u590d\u7a0b\u5ea6\uff0c\u4f46\u8fd9\u79cd\u5047\u8bbe\u4ec5\u5728\u7279\u5b9a\u7ed3\u6784\u6761\u4ef6\u4e0b\u6210\u7acb", "method": "\u63d0\u51fa\u4e00\u4e2a\u5206\u7c7b\u6cd5\uff0c\u5c06\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u5047\u8bbe\u4e0e\u7f16\u7801\u5668\u51e0\u4f55\u5047\u8bbe\u5206\u79bb\uff0c\u7528\u4e8e\u63cf\u8ff0\u73b0\u6709\u6307\u6807\u7684\u6709\u6548\u57df\uff0c\u5e76\u53d1\u5e03\u4e00\u4e2a\u53ef\u91cd\u590d\u7684\u538b\u529b\u6d4b\u8bd5\u548c\u6bd4\u8f83\u8bc4\u4f30\u5957\u4ef6", "result": "\u5f53\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u6216\u7f16\u7801\u5668\u51e0\u4f55\u5047\u8bbe\u88ab\u8fdd\u53cd\u65f6\uff0c\u73b0\u6709\u6307\u6807\u4f1a\u4ea7\u751f\u7cfb\u7edf\u6027\u5047\u9633\u6027\u548c\u5047\u9634\u6027\uff0c\u8fd9\u79cd\u5931\u8d25\u65e2\u53d1\u751f\u5728\u7ecf\u5178\u53ef\u8bc6\u522b\u6027\u673a\u5236\u5185\uff0c\u4e5f\u53d1\u751f\u5728\u6700\u9700\u8981\u53ef\u8bc6\u522b\u6027\u7684\u540e\u9a8c\u8bbe\u7f6e\u4e2d", "conclusion": "\u8868\u793a\u5b66\u4e60\u53ef\u8bc6\u522b\u6027\u8bc4\u4f30\u9700\u8981\u66f4\u4e25\u8c28\u7684\u65b9\u6cd5\uff0c\u73b0\u6709\u6307\u6807\u7684\u6709\u6548\u6027\u4f9d\u8d56\u4e8e\u7279\u5b9a\u5047\u8bbe\u6761\u4ef6\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u907f\u514d\u7cfb\u7edf\u6027\u8bef\u5224"}}
