<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 127]
- [cs.LG](#cs.LG) [Total: 89]
- [cs.AI](#cs.AI) [Total: 41]
- [cs.CY](#cs.CY) [Total: 4]
- [cs.IR](#cs.IR) [Total: 16]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [HyDRA: Hybrid Denoising Regularization for Measurement-Only DEQ Training](https://arxiv.org/abs/2601.01228)
*Markus Haltmeier,Lukas Neumann,Nadja Gruber,Johannes Schwab,Gyeongha Hwang*

Main category: cs.CV

TL;DR: HyDRA：一种仅使用测量数据的深度平衡模型训练框架，通过混合去噪正则化和自适应停止准则解决图像重建问题


<details>
  <summary>Details</summary>
Motivation: 解决图像重建问题面临两大挑战：病态性和缺乏大规模监督数据集。现有深度平衡模型通常需要监督对(x,y)，但在实际应用中往往只有测量数据y可用。

Method: 提出HyDRA框架，结合测量一致性和自适应去噪正则化项，并采用数据驱动的早期停止准则，实现仅使用测量数据的DEQ模型训练。

Result: 在稀疏视图CT重建实验中，HyDRA展现出具有竞争力的重建质量和快速推理速度。

Conclusion: HyDRA为仅使用测量数据的图像重建问题提供了有效的解决方案，在保持重建质量的同时实现了快速推理。

Abstract: Solving image reconstruction problems of the form \(\mathbf{A} \mathbf{x} = \mathbf{y}\) remains challenging due to ill-posedness and the lack of large-scale supervised datasets. Deep Equilibrium (DEQ) models have been used successfully but typically require supervised pairs \((\mathbf{x},\mathbf{y})\). In many practical settings, only measurements \(\mathbf{y}\) are available. We introduce HyDRA (Hybrid Denoising Regularization Adaptation), a measurement-only framework for DEQ training that combines measurement consistency with an adaptive denoising regularization term, together with a data-driven early stopping criterion. Experiments on sparse-view CT demonstrate competitive reconstruction quality and fast inference.

</details>


### [2] [Free Energy-Based Modeling of Emotional Dynamics in Video Advertisements](https://arxiv.org/abs/2601.00812)
*Takashi Ushio,Kazuhiro Onishi,Hideyoshi Yanagisawa*

Main category: cs.CV

TL;DR: 本研究基于自由能原理，仅从广告视频的场景级表达特征量化"愉悦度"、"惊喜"和"习惯化"三种情感维度，无需依赖生理信号或主观评分等外部信息。


<details>
  <summary>Details</summary>
Motivation: 广告视频观看过程中的情感反应对理解媒体效果至关重要，但现有方法通常依赖外部信息。本研究旨在建立一种可解释的情感估计方法学基础，仅从视频内容特征出发进行情感量化。

Method: 基于自由能原理框架，使用Kullback-Leibler散度(KLD)捕捉预测误差，贝叶斯惊喜(BS)捕捉信念更新，不确定性(UN)反映先验模糊性。使用1,059个15秒食品广告视频，从场景级表达特征量化三种情感维度。

Result: 实验表明：KLD反映与品牌呈现相关的"愉悦度"；BS捕捉信息复杂性引起的"惊喜"；UN反映元素类型和空间排列不确定性、以及呈现元素变异性和数量驱动的"惊喜"。识别出三种特征情感模式：不确定刺激、持续高情感、瞬时峰值衰减。在9种超参数设置和6类日本广告视频上的泛化测试证实了方法的稳健性。

Conclusion: 该方法为仅从视频内容特征进行可解释情感估计提供了方法论基础，可扩展整合更多表达元素并通过主观评分验证，最终指导开发支持创作更具吸引力广告视频的技术。

Abstract: Emotional responses during advertising video viewing are recognized as essential for understanding media effects because they have influenced attention, memory, and purchase intention. To establish a methodological basis for explainable emotion estimation without relying on external information such as physiological signals or subjective ratings, we have quantified "pleasantness," "surprise," and "habituation" solely from scene-level expression features of advertising videos, drawing on the free energy(FE) principle, which has provided a unified account of perception, learning, and behavior. In this framework, Kullback-Leibler divergence (KLD) has captured prediction error, Bayesian surprise (BS) has captured belief updates, and uncertainty (UN) has reflected prior ambiguity, and together they have formed the core components of FE. Using 1,059 15 s food video advertisements, the experiments have shown that KLD has reflected "pleasantness" associated with brand presentation, BS has captured "surprise" arising from informational complexity, and UN has reflected "surprise" driven by uncertainty in element types and spatial arrangements, as well as by the variability and quantity of presented elements. This study also identified three characteristic emotional patterns, namely uncertain stimulus, sustained high emotion, and momentary peak and decay, demonstrating the usefulness of the proposed method. Robustness across nine hyperparameter settings and generalization tests with six types of Japanese advertising videos (three genres and two durations) confirmed that these tendencies remained stable. This work can be extended by integrating a wider range of expression elements and validating the approach through subjective ratings, ultimately guiding the development of technologies that can support the creation of more engaging advertising videos.

</details>


### [3] [Can Generative Models Actually Forge Realistic Identity Documents?](https://arxiv.org/abs/2601.00829)
*Alexander Vinogradov*

Main category: cs.CV

TL;DR: 当前开源扩散模型能生成表面逼真的身份证件伪造图像，但无法达到结构性和法证层面的真实性，因此生成式身份证件深度伪造的法证级真实性风险可能被高估。


<details>
  <summary>Details</summary>
Motivation: 随着生成式图像模型在图像真实感方面取得显著进展，公众担心这些模型可能被滥用于文件伪造。本文旨在探究当代开源和公开可用的基于扩散的生成模型是否能产生能够真实绕过人类或自动化验证系统的身份证件伪造品。

Method: 使用多种公开可用的生成模型家族（包括Stable Diffusion、Qwen、Flux、Nano-Banana等），评估文本到图像和图像到图像的生成流程，分析它们生成身份证件伪造品的能力。

Result: 研究发现，当前生成模型能够模拟表面层面的证件美学，但无法复制结构和法证真实性。模型在生成精确的文本布局、安全特征和法证可检测的细节方面存在困难。

Conclusion: 生成式身份证件深度伪造达到法证级真实性的风险可能被高估。这强调了机器学习从业者与文件法证专家之间合作在现实风险评估中的价值，以及当前模型在生成结构性和法证真实性方面的局限性。

Abstract: Generative image models have recently shown significant progress in image realism, leading to public concerns about their potential misuse for document forgery. This paper explores whether contemporary open-source and publicly accessible diffusion-based generative models can produce identity document forgeries that could realistically bypass human or automated verification systems. We evaluate text-to-image and image-to-image generation pipelines using multiple publicly available generative model families, including Stable Diffusion, Qwen, Flux, Nano-Banana, and others. The findings indicate that while current generative models can simulate surface-level document aesthetics, they fail to reproduce structural and forensic authenticity. Consequently, the risk of generative identity document deepfakes achieving forensic-level authenticity may be overestimated, underscoring the value of collaboration between machine learning practitioners and document-forensics experts in realistic risk assessment.

</details>


### [4] [Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs](https://arxiv.org/abs/2601.00837)
*Agniv Roy Choudhury*

Main category: cs.CV

TL;DR: 该研究比较了从头训练的CNN与迁移学习方法（ResNet50、DenseNet121、EfficientNet-B0）在儿童肺炎检测中的性能，发现微调后的ResNet50达到99.43%准确率，显著优于从头训练模型。


<details>
  <summary>Details</summary>
Motivation: 肺炎是五岁以下儿童的主要死因，每年导致超过70万例死亡。胸部X光片的准确诊断受到放射科医生可用性和诊断差异性的限制，需要开发自动化的准确诊断工具。

Method: 使用5,216张儿童胸部X光片数据集，按80/10/10比例分为训练、验证和测试集。比较了从头训练的CNN与三种迁移学习模型（ResNet50、DenseNet121、EfficientNet-B0），评估了冻结主干和微调两种策略。使用准确率、F1分数和AUC进行评估，并通过Grad-CAM提供可解释性可视化。

Result: 微调后的ResNet50表现最佳：99.43%准确率、99.61% F1分数和99.93% AUC，仅有3个错误分类。微调模型平均比冻结主干模型高出5.5个百分点。Grad-CAM确认模型关注临床相关的肺部区域进行预测。

Conclusion: 迁移学习结合微调策略在儿童肺炎检测中显著优于从头训练的CNN，达到接近完美的准确率。该系统在资源有限的环境中具有作为筛查工具的潜力。未来工作应在多中心和成人数据集上验证这些发现。

Abstract: Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.
  Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes.
  Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.
  Results: Fine-tuned ResNet50 achieved the best performance: 99.43\% accuracy, 99.61\% F1-score, and 99.93\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.
  Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.
  Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.

</details>


### [5] [Unified Review and Benchmark of Deep Segmentation Architectures for Cardiac Ultrasound on CAMUS](https://arxiv.org/abs/2601.00839)
*Zahid Ullah,Muhammad Hilal,Eunsoo Lee,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 本文结合心脏超声分割文献综述与三种主流架构（U-Net、Attention U-Net、TransUNet）在CAMUS数据集上的统一实验基准比较，提供标准化预处理和评估指南。


<details>
  <summary>Details</summary>
Motivation: 现有综述多总结心脏影像与深度学习进展，但缺乏统一可复现的实验基准。本研究旨在填补这一空白，通过系统比较不同架构在标准化条件下的性能，为心脏超声分割提供实用指导。

Method: 1. 对心脏超声分割文献进行聚焦综述；2. 在CAMUS超声心动图数据集上对比三种架构：U-Net、Attention U-Net、TransUNet；3. 采用多种预处理路径：原生NIfTI、16位PNG导出、GPT辅助多边形伪标签、自监督预训练；4. 使用相同的训练划分、损失函数和评估标准。

Result: 1. 原生NIfTI数据训练的普通U-Net达到94%平均Dice系数，PNG-16位流程在相似条件下达到91%；2. Attention U-Net在小区域或低对比度区域有适度改进，减少边界泄漏；3. TransUNet在挑战性帧上表现出最强的泛化能力，特别是自监督预训练初始化时；4. 伪标签扩展训练集并提高鲁棒性。

Conclusion: 本研究贡献包括：1. 在标准化CAMUS预处理和评估下对三种架构的统一基准比较；2. 超声数据准备的实用指南（强度保真度、分辨率一致性、对齐）；3. 展望可扩展的自监督和新兴多模态GPT标注流程，用于快速标注、质量保证和针对性数据集构建。

Abstract: Several review papers summarize cardiac imaging and DL advances, few works connect this overview to a unified and reproducible experimental benchmark. In this study, we combine a focused review of cardiac ultrasound segmentation literature with a controlled comparison of three influential architectures, U-Net, Attention U-Net, and TransUNet, on the Cardiac Acquisitions for Multi-Structure Ultrasound Segmentation (CAMUS) echocardiography dataset. Our benchmark spans multiple preprocessing routes, including native NIfTI volumes, 16-bit PNG exports, GPT-assisted polygon-based pseudo-labels, and self-supervised pretraining (SSL) on thousands of unlabeled cine frames. Using identical training splits, losses, and evaluation criteria, a plain U-Net achieved a 94% mean Dice when trained directly on NIfTI data (preserving native dynamic range), while the PNG-16-bit workflow reached 91% under similar conditions. Attention U-Net provided modest improvements on small or low-contrast regions, reducing boundary leakage, whereas TransUNet demonstrated the strongest generalization on challenging frames due to its ability to model global spatial context, particularly when initialized with SSL. Pseudo-labeling expanded the training set and improved robustness after confidence filtering. Overall, our contributions are threefold: a harmonized, apples-to-apples benchmark of U-Net, Attention U-Net, and TransUNet under standardized CAMUS preprocessing and evaluation; practical guidance on maintaining intensity fidelity, resolution consistency, and alignment when preparing ultrasound data; and an outlook on scalable self-supervision and emerging multimodal GPT-based annotation pipelines for rapid labeling, quality assurance, and targeted dataset curation.

</details>


### [6] [Motion-Compensated Latent Semantic Canvases for Visual Situational Awareness on Edge](https://arxiv.org/abs/2601.00854)
*Igor Lodin,Sergii Filatov,Vira Filatova,Dmytro Filatov*

Main category: cs.CV

TL;DR: MCLSC系统通过运动补偿潜在语义画布在边缘设备上实现视觉态势感知，使用静态和动态两层语义存储，通过运动触发分割，减少30倍分割调用和20倍处理时间


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上实现高效的视觉态势感知，传统每帧分割方法计算成本过高，需要减少分割调用次数同时保持语义信息的连贯性

Method: 提出运动补偿潜在语义画布（MCLSC），包含缓慢累积的静态层和快速更新的动态层；使用运动门控机制，仅在检测到运动时触发昂贵的全景分割（Mask2Former）；通过稳定化和运动补偿保持一致的坐标系

Result: 在480p视频上，原型系统减少分割调用超过30倍，降低端到端平均处理时间超过20倍，同时保持连贯的静态/动态语义覆盖

Conclusion: MCLSC系统在资源受限的边缘设备上实现了高效的视觉态势感知，通过运动门控和语义画布机制显著降低了计算开销，同时保持了语义信息的连贯性和准确性

Abstract: We propose Motion-Compensated Latent Semantic Canvases (MCLSC) for visual situational awareness on resource-constrained edge devices. The core idea is to maintain persistent semantic metadata in two latent canvases - a slowly accumulating static layer and a rapidly updating dynamic layer - defined in a baseline coordinate frame stabilized from the video stream. Expensive panoptic segmentation (Mask2Former) runs asynchronously and is motion-gated: inference is triggered only when motion indicates new information, while stabilization/motion compensation preserves a consistent coordinate system for latent semantic memory. On prerecorded 480p clips, our prototype reduces segmentation calls by >30x and lowers mean end-to-end processing time by >20x compared to naive per-frame segmentation, while maintaining coherent static/dynamic semantic overlays.

</details>


### [7] [Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems](https://arxiv.org/abs/2601.00905)
*Eliot Park,Abhi Kumar,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: 研究探索了GPT-4o、GPT-4o-mini和Claude 3.5等先进视觉语言模型在预测物品可回收性方面的应用，评估了它们匹配物品到合适回收箱的能力，并测试了在位置特定指南、污染/损坏和多材料物品等挑战场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然高效回收的重要性被广泛认可，但公众准确判断物品可回收性和正确处理方式仍然是一项复杂任务。需要探索先进AI模型在改善回收实践方面的潜力。

Method: 使用精心策划的图像数据集，评估GPT-4o、GPT-4o-mini和Claude 3.5等视觉语言模型的能力，包括：1）匹配物品到合适回收箱并判断物理适配性；2）测试位置特定回收指南下的预测调整；3）考虑污染或结构损坏情况；4）处理多材料物品。

Result: 研究发现这些模型在上下文理解方面相比先前版本有显著进步，但仍存在不足。模型在匹配物品到回收箱方面表现出色，但在处理位置特定指南、污染/损坏评估和多材料物品分解等复杂场景时仍有改进空间。

Conclusion: 上下文感知模型的持续改进对于提升公众回收实践和推进环境可持续性至关重要。虽然当前模型已取得显著进展，但在处理复杂回收场景时仍需进一步优化。

Abstract: While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.

</details>


### [8] [Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting](https://arxiv.org/abs/2601.00913)
*Subhankar Mishra*

Main category: cs.CV

TL;DR: Clean-GS方法通过稀疏语义掩码去除3D高斯泼溅中的背景杂波和漂浮物，实现60-80%模型压缩，保持目标物体质量


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术会产生大量虚假高斯（漂浮物），这些伪影会遮挡感兴趣物体并增加模型大小，阻碍在带宽受限应用中的部署

Method: 结合白名单空间过滤、颜色引导验证和离群值去除的多阶段方法：1)通过投影到掩码区域进行白名单过滤；2)深度缓冲颜色验证；3)基于邻居的离群值去除

Result: 在Tanks and Temples数据集上，文件大小从125MB减少到47MB，同时保持渲染质量，使3DGS模型适用于Web部署和AR/VR应用

Conclusion: Clean-GS使用仅3个分割掩码（1%的视图）就能有效去除背景杂波和漂浮物，相比依赖全局重要性指标的现有3DGS修剪方法，提供了更精确的语义引导压缩

Abstract: 3D Gaussian Splatting produces high-quality scene reconstructions but generates hundreds of thousands of spurious Gaussians (floaters) scattered throughout the environment. These artifacts obscure objects of interest and inflate model sizes, hindering deployment in bandwidth-constrained applications. We present Clean-GS, a method for removing background clutter and floaters from 3DGS reconstructions using sparse semantic masks. Our approach combines whitelist-based spatial filtering with color-guided validation and outlier removal to achieve 60-80\% model compression while preserving object quality. Unlike existing 3DGS pruning methods that rely on global importance metrics, Clean-GS uses semantic information from as few as 3 segmentation masks (1\% of views) to identify and remove Gaussians not belonging to the target object. Our multi-stage approach consisting of (1) whitelist filtering via projection to masked regions, (2) depth-buffered color validation, and (3) neighbor-based outlier removal isolates monuments and objects from complex outdoor scenes. Experiments on Tanks and Temples show that Clean-GS reduces file sizes from 125MB to 47MB while maintaining rendering quality, making 3DGS models practical for web deployment and AR/VR applications. Our code is available at https://github.com/smlab-niser/clean-gs

</details>


### [9] [Analyzing the Shopping Journey: Computing Shelf Browsing Visits in a Physical Retail Store](https://arxiv.org/abs/2601.00928)
*Luis Yoichi Morales,Francesco Zanlungo,David M. Woollard*

Main category: cs.CV

TL;DR: 该研究开发了一种从3D轨迹数据中提取顾客"货架访问"行为的算法，用于分析零售店中的顾客浏览意图，并在不同商店环境中验证了算法的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在零售业客户服务角色中的部署挑战，需要开发能够自主理解顾客购物意图的技术，特别是分析顾客在实体店中的浏览行为。

Method: 提出了一种从基于机器视觉的3D跟踪和头顶摄像头获取的轨迹数据中计算顾客"货架访问"的算法。在两个不同商店收集了8138条和15129条轨迹数据集，由人工标注进行校准，并在校准集外的数据上评估算法性能。

Result: 算法能够在与校准环境不同的商店中有效识别顾客的浏览活动。研究还利用该模型分析了大量轨迹中的顾客"浏览模式"及其与实际购买行为的关系。

Conclusion: 货架浏览信息可用于零售规划和人机交互场景，为零售业提供有价值的顾客行为洞察，支持机器人更好地理解顾客意图。

Abstract: Motivated by recent challenges in the deployment of robots into customer-facing roles within retail, this work introduces a study of customer activity in physical stores as a step toward autonomous understanding of shopper intent. We introduce an algorithm that computes shoppers' ``shelf visits'' -- capturing their browsing behavior in the store. Shelf visits are extracted from trajectories obtained via machine vision-based 3D tracking and overhead cameras. We perform two independent calibrations of the shelf visit algorithm, using distinct sets of trajectories (consisting of 8138 and 15129 trajectories), collected in different stores and labeled by human reviewers. The calibrated models are then evaluated on trajectories held out of the calibration process both from the same store on which calibration was performed and from the other store. An analysis of the results shows that the algorithm can recognize customers' browsing activity when evaluated in an environment different from the one on which calibration was performed. We then use the model to analyze the customers' ``browsing patterns'' on a large set of trajectories and their relation to actual purchases in the stores. Finally, we discuss how shelf browsing information could be used for retail planning and in the domain of human-robot interaction scenarios.

</details>


### [10] [ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery](https://arxiv.org/abs/2601.00939)
*Feng Luo,Hongbo Pan,Xiang Yang,Baoyu Jiang,Fengqing Liu,Tao Huang*

Main category: cs.CV

TL;DR: ShadowGS是基于3D高斯泼溅的卫星图像阴影建模框架，通过物理渲染方程和光线行进技术解决多时相卫星图像中的阴影不一致问题，提升3D重建精度。


<details>
  <summary>Details</summary>
Motivation: 多时相卫星图像中，由于光照条件变化导致的阴影不一致问题严重影响3D重建质量，需要一种能够精确建模几何一致阴影的方法。

Method: 基于3D高斯泼溅框架，结合遥感物理渲染方程和高效光线行进技术，引入阴影一致性约束和阴影图先验，实现阴影解耦和几何精确建模。

Result: ShadowGS在阴影解耦精度、3D重建精度和新视角合成质量上优于现有方法，仅需几分钟训练，在RGB、全色融合和稀疏视图输入下均表现鲁棒。

Conclusion: ShadowGS通过物理建模方法有效解决了多时相卫星图像中的阴影不一致问题，显著提升了3D重建的几何精度和渲染质量。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel paradigm for 3D reconstruction from satellite imagery. However, in multi-temporal satellite images, prevalent shadows exhibit significant inconsistencies due to varying illumination conditions. To address this, we propose ShadowGS, a novel framework based on 3DGS. It leverages a physics-based rendering equation from remote sensing, combined with an efficient ray marching technique, to precisely model geometrically consistent shadows while maintaining efficient rendering. Additionally, it effectively disentangles different illumination components and apparent attributes in the scene. Furthermore, we introduce a shadow consistency constraint that significantly enhances the geometric accuracy of 3D reconstruction. We also incorporate a novel shadow map prior to improve performance with sparse-view inputs. Extensive experiments demonstrate that ShadowGS outperforms current state-of-the-art methods in shadow decoupling accuracy, 3D reconstruction precision, and novel view synthesis quality, with only a few minutes of training. ShadowGS exhibits robust performance across various settings, including RGB, pansharpened, and sparse-view satellite inputs.

</details>


### [11] [Learning to Segment Liquids in Real-world Images](https://arxiv.org/abs/2601.00940)
*Jonas Li,Michelle Li,Luke Liu,Heng Fan*

Main category: cs.CV

TL;DR: 该论文提出了一个用于液体分割的大规模数据集LQDS和新的液体检测模型LQDM，通过边界分支与分割分支的交叉注意力机制提升液体分割性能。


<details>
  <summary>Details</summary>
Motivation: 液体（如水、酒、药物）在日常生活中无处不在，但机器人领域对液体分割任务关注有限，这阻碍了机器人安全避免或与液体交互的能力。液体分割的挑战在于液体外观和形状多样，既可以是透明也可以是反射性的，会呈现背景或周围环境的任意物体和场景。

Method: 构建了包含5000张真实世界图像、标注为14个不同类别的大规模液体数据集LQDS；设计了新颖的液体检测模型LQDM，利用专门的边界分支与主要分割分支之间的交叉注意力机制来增强分割预测。

Result: 大量实验证明LQDM在LQDS测试集上的有效性，超越了最先进的方法，为液体语义分割建立了强大的基线。

Conclusion: 该研究通过构建大规模液体数据集和提出创新的液体检测模型，为机器人安全与液体交互提供了重要技术基础，解决了液体分割这一具有挑战性的计算机视觉任务。

Abstract: Different types of liquids such as water, wine and medicine appear in all aspects of daily life. However, limited attention has been given to the task, hindering the ability of robots to avoid or interact with liquids safely. The segmentation of liquids is difficult because liquids come in diverse appearances and shapes; moreover, they can be both transparent or reflective, taking on arbitrary objects and scenes from the background or surroundings. To take on this challenge, we construct a large-scale dataset of liquids named LQDS consisting of 5000 real-world images annotated into 14 distinct classes, and design a novel liquid detection model named LQDM, which leverages cross-attention between a dedicated boundary branch and the main segmentation branch to enhance segmentation predictions. Extensive experiments demonstrate the effectiveness of LQDM on the test set of LQDS, outperforming state-of-the-art methods and establishing a strong baseline for the semantic segmentation of liquids.

</details>


### [12] [PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education](https://arxiv.org/abs/2601.00943)
*Megha Mariam K. M,Aditya Arun,Zakaria Laskar,C. V. Jawahar*

Main category: cs.CV

TL;DR: 本文提出了一个用于评估文本到视频（T2V）模型在物理教育中生成解释性视频能力的基准测试，发现当前模型能生成视觉连贯的视频，但概念准确性有待提高。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型，特别是文本到视频系统，为科学教育提供了通过自动创建引人入胜的视觉解释来改变教学方式的潜力。本研究旨在评估这些模型在物理教育中的应用前景。

Method: 引入了一个专门用于解释性视频生成的基准测试，将物理概念分解为细粒度的教学点，每个教学点都配有精心设计的提示词，用于评估T2V模型根据这些提示生成准确视频的能力。

Result: 评估显示，当前模型能生成视觉连贯、运动平滑、闪烁较少的视频，但概念准确性不够可靠。在力学、流体和光学领域表现较好，但在电磁学和热力学等需要描绘抽象相互作用的领域存在困难。

Conclusion: 研究揭示了教育视频生成中视觉质量和概念正确性之间的差距，希望该基准测试能帮助社区缩小这一差距，推动开发能够大规模生成准确、与课程对齐的物理内容的T2V系统。

Abstract: Generative AI models, particularly Text-to-Video (T2V) systems, offer a promising avenue for transforming science education by automating the creation of engaging and intuitive visual explanations. In this work, we take a first step toward evaluating their potential in physics education by introducing a dedicated benchmark for explanatory video generation. The benchmark is designed to assess how well T2V models can convey core physics concepts through visual illustrations. Each physics concept in our benchmark is decomposed into granular teaching points, with each point accompanied by a carefully crafted prompt intended for visual explanation of the teaching point. T2V models are evaluated on their ability to generate accurate videos in response to these prompts. Our aim is to systematically explore the feasibility of using T2V models to generate high-quality, curriculum-aligned educational content-paving the way toward scalable, accessible, and personalized learning experiences powered by AI. Our evaluation reveals that current models produce visually coherent videos with smooth motion and minimal flickering, yet their conceptual accuracy is less reliable. Performance in areas such as mechanics, fluids, and optics is encouraging, but models struggle with electromagnetism and thermodynamics, where abstract interactions are harder to depict. These findings underscore the gap between visual quality and conceptual correctness in educational video generation. We hope this benchmark helps the community close that gap and move toward T2V systems that can deliver accurate, curriculum-aligned physics content at scale. The benchmark and accompanying codebase are publicly available at https://github.com/meghamariamkm/PhyEduVideo.

</details>


### [13] [ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval](https://arxiv.org/abs/2601.01024)
*Tien-Huy Nguyen,Huu-Loc Tran,Thanh Duc Ngo*

Main category: cs.CV

TL;DR: 本文提出ITSELF框架，通过注意力引导的隐式局部对齐方法解决文本人物搜索中的细粒度对齐问题，无需额外监督即可学习图像与文本间的精细对应关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过局部对齐解决文本人物搜索问题，但容易陷入捷径学习和虚假相关性，导致错位。同时，注入先验知识可能扭曲模态内结构。研究发现编码器注意力从训练早期就能提供空间精确的证据，这启发了注意力引导的隐式局部对齐方法。

Method: 提出ITSELF框架，包含三个核心组件：1) GRAB将模型自身注意力转换为高显著性标记的注意力库，并在该库上应用局部目标；2) MARS聚合跨层注意力并进行多样性感知的top-k选择；3) ATS在训练过程中从粗到细调度保留预算，早期保留上下文，逐步聚焦判别性细节。

Result: 在三个广泛使用的TBPS基准测试上实现了最先进的性能，并表现出强大的跨数据集泛化能力，证实了该方法在不增加额外先验监督情况下的有效性和鲁棒性。

Conclusion: ITSELF框架通过注意力引导的隐式局部对齐，有效解决了文本人物搜索中的细粒度对齐问题，无需额外监督即可学习图像与文本间的精细对应关系，在多个基准测试中表现出优越性能。

Abstract: Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself

</details>


### [14] [Deep Clustering with Associative Memories](https://arxiv.org/abs/2601.00963)
*Bishwajit Saha,Dmitry Krotov,Mohammed J. Zaki,Parikshit Ram*

Main category: cs.CV

TL;DR: DCAM提出了一种基于能量动力学和联想记忆的新型深度聚类方法，通过单一目标函数将表示学习和聚类更紧密地结合在一起。


<details>
  <summary>Details</summary>
Motivation: 深度聚类中表示学习是可微分的，但聚类本质上是离散优化问题，需要各种近似和正则化才能融入标准可微流程，导致表示学习和聚类之间存在脱节。

Method: 提出DCAM方法，利用基于能量动力学的联想记忆构建新的损失函数，通过单一目标函数更紧密地结合表示学习和聚类。

Result: DCAM在不同架构选择（卷积、残差或全连接）和数据模态（图像或文本）上都展现出优势，产生了改进的聚类质量。

Conclusion: DCAM通过能量动力学和联想记忆实现了表示学习和聚类的更紧密集成，为深度聚类提供了一种有效的新方法。

Abstract: Deep clustering - joint representation learning and latent space clustering - is a well studied problem especially in computer vision and text processing under the deep learning framework. While the representation learning is generally differentiable, clustering is an inherently discrete optimization task, requiring various approximations and regularizations to fit in a standard differentiable pipeline. This leads to a somewhat disjointed representation learning and clustering. In this work, we propose a novel loss function utilizing energy-based dynamics via Associative Memories to formulate a new deep clustering method, DCAM, which ties together the representation learning and clustering aspects more intricately in a single objective. Our experiments showcase the advantage of DCAM, producing improved clustering quality for various architecture choices (convolutional, residual or fully-connected) and data modalities (images or text).

</details>


### [15] [A Deep Learning Approach for Automated Skin Lesion Diagnosis with Explainable AI](https://arxiv.org/abs/2601.00964)
*Md. Maksudul Haque,Rahnuma Akter,A S M Ahsanul Sarkar Akib,Abdul Hasib*

Main category: cs.CV

TL;DR: 提出一种结合数据平衡、数据增强、EfficientNetV2-L通道注意力机制和三阶段渐进学习方法的深度学习架构，用于HAM10000数据集上的多类皮肤病变分类，达到91.15%准确率，并使用XAI技术增强模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球最常见且危险的癌症类型之一，需要及时精确的诊断。现有诊断方法可能存在准确性和可解释性不足的问题，需要开发高性能且可信赖的自动诊断系统。

Method: 1. 高质量数据平衡方法处理类别不平衡；2. 大规模数据增强技术；3. 结合通道注意力的混合EfficientNetV2-L框架；4. 三阶段渐进学习策略；5. 使用Grad-CAM和显著性图等XAI技术提供可视化解释。

Result: 模型在HAM10000数据集上取得91.15%的总准确率、85.45%的宏F1分数和99.33%的微平均AUC。在所有七个病变类别中都表现出高性能，特别是在黑色素瘤和黑色素细胞痣分类上表现突出。

Conclusion: 提出的深度学习架构在皮肤病变分类任务中表现出卓越性能，同时通过XAI技术增强了诊断透明度和临床可信度，为皮肤癌的自动诊断提供了有效的解决方案。

Abstract: Skin cancer is also one of the most common and dangerous types of cancer in the world that requires timely and precise diagnosis. In this paper, a deep-learning architecture of the multi-class skin lesion classification on the HAM10000 dataset will be described. The system suggested combines high-quality data balancing methods, large-scale data augmentation, hybridized EfficientNetV2-L framework with channel attention, and a three-stage progressive learning approach. Moreover, we also use explainable AI (XAI) techniques such as Grad-CAM and saliency maps to come up with intelligible visual representations of model predictions. Our strategy is with a total accuracy of 91.15 per cent, macro F1 of 85.45\% and micro-average AUC of 99.33\%. The model has shown high performance in all the seven lesion classes with specific high performance of melanoma and melanocytic nevi. In addition to enhancing diagnostic transparency, XAI also helps to find out the visual characteristics that cause the classifications, which enhances clinical trustworthiness.

</details>


### [16] [Few-Shot Video Object Segmentation in X-Ray Angiography Using Local Matching and Spatio-Temporal Consistency Loss](https://arxiv.org/abs/2601.00988)
*Lin Xi,Yingliang Ma,Xiahai Zhuang*

Main category: cs.CV

TL;DR: 提出一种新的FSVOS模型，采用局部匹配策略限制搜索空间，通过方向采样实现动态可变采样区域，结合时空对比学习增强特征一致性，并在X射线血管造影视频数据集上验证了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如标准im2col实现（空间卷积、深度卷积、特征移位机制）效率低下，或依赖硬件特定的CUDA内核（可变形和邻域注意力）在非CUDA设备上可移植性有限。需要一种更灵活、高效且可移植的视频分割方法。

Method: 1. 采用局部匹配策略限制搜索空间到最相关的相邻像素；2. 通过方向采样视角重新组织局部采样过程，实现非参数采样机制，支持动态可变采样区域；3. 设计监督式时空对比学习方案，增强跨帧特征一致性；4. 创建MOSXAV数据集用于X射线血管造影视频的多目标分割。

Result: 在CADICA、XACV和MOSXAV数据集上的大量实验表明，所提出的FSVOS方法在分割精度和泛化能力（包括已见和未见类别）方面优于当前最先进的视频分割方法。

Conclusion: 该方法提供了增强的灵活性，无需参数层的计算成本和模型重新训练，具有广泛的临床应用潜力，特别是在X射线血管造影视频分析领域。

Abstract: We introduce a novel FSVOS model that employs a local matching strategy to restrict the search space to the most relevant neighboring pixels. Rather than relying on inefficient standard im2col-like implementations (e.g., spatial convolutions, depthwise convolutions and feature-shifting mechanisms) or hardware-specific CUDA kernels (e.g., deformable and neighborhood attention), which often suffer from limited portability across non-CUDA devices, we reorganize the local sampling process through a direction-based sampling perspective. Specifically, we implement a non-parametric sampling mechanism that enables dynamically varying sampling regions. This approach provides the flexibility to adapt to diverse spatial structures without the computational costs of parametric layers and the need for model retraining. To further enhance feature coherence across frames, we design a supervised spatio-temporal contrastive learning scheme that enforces consistency in feature representations. In addition, we introduce a publicly available benchmark dataset for multi-object segmentation in X-ray angiography videos (MOSXAV), featuring detailed, manually labeled segmentation ground truth. Extensive experiments on the CADICA, XACV, and MOSXAV datasets show that our proposed FSVOS method outperforms current state-of-the-art video segmentation methods in terms of segmentation accuracy and generalization capability (i.e., seen and unseen categories). This work offers enhanced flexibility and potential for a wide range of clinical applications.

</details>


### [17] [UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data](https://arxiv.org/abs/2601.00991)
*Joshua Kawaguchi,Saad Manzur,Emily Gao Wang,Maitreyi Sinha,Bryan Vela,Yunxi Wang,Brandon Vela,Wayne B. Hayes*

Main category: cs.CV

TL;DR: UnrealPose-Gen是一个基于Unreal Engine 5的离线渲染流水线，用于生成高质量合成人体姿态数据，并发布了包含约100万帧的UnrealPose-1M数据集。


<details>
  <summary>Details</summary>
Motivation: 真实3D人体姿态数据标注成本高且受限于工作室环境，而野外数据集缺乏准确的地面真值。需要一种能够生成高质量、多样化合成数据的方法来解决数据稀缺问题。

Method: 使用Unreal Engine 5构建的UnrealPose-Gen流水线，基于Movie Render Queue进行高质量离线渲染。生成的数据包括：3D关节坐标（世界和相机坐标系）、2D投影和COCO风格关键点（含遮挡和可见性标记）、人物边界框、相机内外参数。

Result: 创建了UnrealPose-1M数据集，包含约100万帧，分为8个序列：5个脚本化的"连贯"序列（5个场景、约40个动作、5个主体）和3个随机化序列（3个场景、约100个动作、5个主体），具有广泛的视角覆盖。通过四个任务验证了合成数据的真实性：图像到3D姿态、2D关键点检测、2D到3D提升、人物检测/分割。

Conclusion: 虽然时间和资源限制了无限数据集的生成，但作者发布了UnrealPose-1M数据集和UnrealPose-Gen流水线，支持第三方生成人体姿态数据，为解决3D人体姿态估计中的数据稀缺问题提供了有价值的工具。

Abstract: Diverse, accurately labeled 3D human pose data is expensive and studio-bound, while in-the-wild datasets lack known ground truth. We introduce UnrealPose-Gen, an Unreal Engine 5 pipeline built on Movie Render Queue for high-quality offline rendering. Our generated frames include: (i) 3D joints in world and camera coordinates, (ii) 2D projections and COCO-style keypoints with occlusion and joint-visibility flags, (iii) person bounding boxes, and (iv) camera intrinsics and extrinsics. We use UnrealPose-Gen to present UnrealPose-1M, an approximately one million frame corpus comprising eight sequences: five scripted "coherent" sequences spanning five scenes, approximately 40 actions, and five subjects; and three randomized sequences across three scenes, approximately 100 actions, and five subjects, all captured from diverse camera trajectories for broad viewpoint coverage. As a fidelity check, we report real-to-synthetic results on four tasks: image-to-3D pose, 2D keypoint detection, 2D-to-3D lifting, and person detection/segmentation. Though time and resources constrain us from an unlimited dataset, we release the UnrealPose-1M dataset, as well as the UnrealPose-Gen pipeline to support third-party generation of human pose data.

</details>


### [18] [WildIng: A Wildlife Image Invariant Representation Model for Geographical Domain Shift](https://arxiv.org/abs/2601.00993)
*Julian D. Santamaria,Claudia Isaza,Jhony H. Giraldo*

Main category: cs.CV

TL;DR: WildIng模型通过整合文本描述与图像特征，提升野生动物识别模型在地理域迁移下的泛化能力，解决了现有模型在新地理区域性能显著下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的野生动物识别模型在训练地理区域表现良好，但在新地理区域测试时性能显著下降，主要原因是模型过度依赖图像特征，对背景、光照、环境条件等地理分布变化敏感。

Method: 提出WildIng模型，整合文本描述与图像特征，通过文本描述捕捉物种外观的语义信息，创建对地理域迁移更鲁棒的特征表示。

Result: 实验表明，WildIng将BioCLIP等基础模型在地理域迁移条件下的准确率提升了30%，在非洲和美国两个不同地理区域的数据集上验证了有效性。

Conclusion: 通过整合文本描述与图像特征，WildIng显著提升了野生动物识别模型在地理域迁移下的泛化性能，为解决野生动物监测中的地理分布偏移问题提供了有效方案。

Abstract: Wildlife monitoring is crucial for studying biodiversity loss and climate change. Camera trap images provide a non-intrusive method for analyzing animal populations and identifying ecological patterns over time. However, manual analysis is time-consuming and resource-intensive. Deep learning, particularly foundation models, has been applied to automate wildlife identification, achieving strong performance when tested on data from the same geographical locations as their training sets. Yet, despite their promise, these models struggle to generalize to new geographical areas, leading to significant performance drops. For example, training an advanced vision-language model, such as CLIP with an adapter, on an African dataset achieves an accuracy of 84.77%. However, this performance drops significantly to 16.17% when the model is tested on an American dataset. This limitation partly arises because existing models rely predominantly on image-based representations, making them sensitive to geographical data distribution shifts, such as variation in background, lighting, and environmental conditions. To address this, we introduce WildIng, a Wildlife image Invariant representation model for geographical domain shift. WildIng integrates text descriptions with image features, creating a more robust representation to geographical domain shifts. By leveraging textual descriptions, our approach captures consistent semantic information, such as detailed descriptions of the appearance of the species, improving generalization across different geographical locations. Experiments show that WildIng enhances the accuracy of foundation models such as BioCLIP by 30% under geographical domain shift conditions. We evaluate WildIng on two datasets collected from different regions, namely America and Africa. The code and models are publicly available at https://github.com/Julian075/CATALOG/tree/WildIng.

</details>


### [19] [DVGBench: Implicit-to-Explicit Visual Grounding Benchmark in UAV Imagery with Large Vision-Language Models](https://arxiv.org/abs/2601.00998)
*Yue Zhou,Jue Chen,Zilun Zhang,Penghui Huang,Ran Ding,Zhentao Zou,PengFei Gao,Yuchen Wei,Ke Li,Xue Yang,Xue Jiang,Hongxin Yang,Jonathan Li*

Main category: cs.CV

TL;DR: 本文提出了DVGBench，一个用于无人机的高质量隐式视觉定位基准数据集，涵盖6个主要应用场景，并设计了DroneVG-R1模型，采用隐式到显式思维链强化学习范式来提升无人机视觉定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在视觉定位任务中主要依赖显式参照表达（如相对位置、大小、颜色等），限制了在需要领域知识的隐式视觉定位任务上的表现，因此需要专门的隐式视觉定位基准来推动相关研究。

Method: 1) 构建DVGBench数据集，包含6个主要无人机应用场景，每个对象同时提供显式和隐式查询；2) 设计DroneVG-R1模型，采用隐式到显式思维链（I2E-CoT）结合强化学习范式，利用场景特定专业知识将隐式参照转换为显式参照。

Result: 对主流模型在显式和隐式视觉定位任务上的评估揭示了它们在推理能力上的显著局限性，为提升无人机智能体的推理能力提供了可操作的见解。

Conclusion: DVGBench数据集和DroneVG-R1模型为无人机隐式视觉定位研究提供了重要基准，通过隐式到显式思维链强化学习范式有效降低了视觉定位难度，推动了遥感大视觉语言模型推理能力的发展。

Abstract: Remote sensing (RS) large vision-language models (LVLMs) have shown strong promise across visual grounding (VG) tasks. However, existing RS VG datasets predominantly rely on explicit referring expressions-such as relative position, relative size, and color cues-thereby constraining performance on implicit VG tasks that require scenario-specific domain knowledge. This article introduces DVGBench, a high-quality implicit VG benchmark for drones, covering six major application scenarios: traffic, disaster, security, sport, social activity, and productive activity. Each object provides both explicit and implicit queries. Based on the dataset, we design DroneVG-R1, an LVLM that integrates the novel Implicit-to-Explicit Chain-of-Thought (I2E-CoT) within a reinforcement learning paradigm. This enables the model to take advantage of scene-specific expertise, converting implicit references into explicit ones and thus reducing grounding difficulty. Finally, an evaluation of mainstream models on both explicit and implicit VG tasks reveals substantial limitations in their reasoning capabilities. These findings provide actionable insights for advancing the reasoning capacity of LVLMs for drone-based agents. The code and datasets will be released at https://github.com/zytx121/DVGBench

</details>


### [20] [Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising](https://arxiv.org/abs/2601.01036)
*Kiet Dang Vu,Trung Thai Tran,Kien Nguyen Do Trung,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: Mono3DV：一种基于Transformer的单目3D目标检测框架，通过3D感知二分匹配、3D去噪和变分查询去噪机制解决传统DETR架构中3D属性被排除在匹配过程之外的问题。


<details>
  <summary>Details</summary>
Motivation: 传统DETR类架构在单目3D目标检测中存在关键限制：由于单目图像3D估计的固有不适定性，3D属性被排除在二分匹配过程之外，导致高质量3D预测可能被仅基于2D的匹配标准错误抑制，造成次优结果。

Method: 提出Mono3DV框架，包含三个关键创新：1）3D感知二分匹配策略，将3D几何信息直接纳入匹配成本；2）3D去噪方案，稳定训练过程中的二分匹配；3）变分查询去噪机制，解决传统去噪技术的梯度消失问题。

Result: 在不使用任何外部数据的情况下，该方法在KITTI 3D目标检测基准上取得了最先进的结果。

Conclusion: Mono3DV通过将3D几何信息整合到匹配过程中并解决训练不稳定性，显著提升了单目3D目标检测的性能，证明了3D感知匹配和稳定训练策略的有效性。

Abstract: While DETR-like architectures have demonstrated significant potential for monocular 3D object detection, they are often hindered by a critical limitation: the exclusion of 3D attributes from the bipartite matching process. This exclusion arises from the inherent ill-posed nature of 3D estimation from monocular image, which introduces instability during training. Consequently, high-quality 3D predictions can be erroneously suppressed by 2D-only matching criteria, leading to suboptimal results. To address this, we propose Mono3DV, a novel Transformer-based framework. Our approach introduces three key innovations. First, we develop a 3D-Aware Bipartite Matching strategy that directly incorporates 3D geometric information into the matching cost, resolving the misalignment caused by purely 2D criteria. Second, it is important to stabilize the Bipartite Matching to resolve the instability occurring when integrating 3D attributes. Therefore, we propose 3D-DeNoising scheme in the training phase. Finally, recognizing the gradient vanishing issue associated with conventional denoising techniques, we propose a novel Variational Query DeNoising mechanism to overcome this limitation, which significantly enhances model performance. Without leveraging any external data, our method achieves state-of-the-art results on the KITTI 3D object detection benchmark.

</details>


### [21] [Evaluating transfer learning strategies for improving dairy cattle body weight prediction in small farms using depth-image and point-cloud data](https://arxiv.org/abs/2601.01044)
*Jin Wang,Angelo De Castro,Yuxi Zhang,Lucas Basolli Borsatto,Yuechen Guo,Victoria Bastos Primo,Ana Beatriz Montevecchio Bernardino,Gota Morota,Ricardo C Chebel,Haipeng Yu*

Main category: cs.CV

TL;DR: 该研究评估了迁移学习在奶牛体重预测中的效果，比较了深度图像和点云两种数据模态，发现迁移学习能显著提升小规模农场的预测性能，且两种模态表现相当。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉为奶牛监测提供了自动化、非侵入性和可扩展的工具，但迁移学习在畜牧应用中的效果和最佳微调策略尚不明确，且深度图像与点云数据在奶牛体重预测中的直接比较有限。

Method: 研究从大、中、小三个农场收集了1201、215和58头奶牛的俯视深度图像和点云数据，评估了四种深度学习模型：ConvNeXt和MobileViT用于深度图像，PointNet和DGCNN用于点云，比较了迁移学习、单源学习和联合学习三种实验设计。

Result: 迁移学习显著提高了小农场的体重预测性能，在所有四种模型中都优于单源学习，且效果与联合学习相当或更好。深度图像和点云模型之间没有一致的性能差异。

Conclusion: 迁移学习特别适合数据有限的小农场预测场景，因为它只需要预训练模型权重而非原始数据，避免了跨农场数据共享的隐私、物流或政策限制问题。

Abstract: Computer vision provides automated, non-invasive, and scalable tools for monitoring dairy cattle, thereby supporting management, health assessment, and phenotypic data collection. Although transfer learning is commonly used for predicting body weight from images, its effectiveness and optimal fine-tuning strategies remain poorly understood in livestock applications, particularly beyond the use of pretrained ImageNet or COCO weights. In addition, while both depth images and three-dimensional point-cloud data have been explored for body weight prediction, direct comparisons of these two modalities in dairy cattle are limited. Therefore, the objectives of this study were to 1) evaluate whether transfer learning from a large farm enhances body weight prediction on a small farm with limited data, and 2) compare the predictive performance of depth-image- and point-cloud-based approaches under three experimental designs. Top-view depth images and point-cloud data were collected from 1,201, 215, and 58 cows at large, medium, and small dairy farms, respectively. Four deep learning models were evaluated: ConvNeXt and MobileViT for depth images, and PointNet and DGCNN for point clouds. Transfer learning markedly improved body weight prediction on the small farm across all four models, outperforming single-source learning and achieving gains comparable to or greater than joint learning. These results indicate that pretrained representations generalize well across farms with differing imaging conditions and dairy cattle populations. No consistent performance difference was observed between depth-image- and point-cloud-based models. Overall, these findings suggest that transfer learning is well suited for small farm prediction scenarios where cross-farm data sharing is limited by privacy, logistical, or policy constraints, as it requires access only to pretrained model weights rather than raw data.

</details>


### [22] [EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos](https://arxiv.org/abs/2601.01050)
*Hongming Fu,Wenjia Wang,Xiaozhen Qiao,Shuo Yang,Zheng Liu,Bo Zhao*

Main category: cs.CV

TL;DR: EgoGrasp：首个从动态单目第一人称视频中重建世界空间手物交互的方法，解决了现有方法在时间动态和全局轨迹一致性上的不足


<details>
  <summary>Details</summary>
Motivation: 准确的世界空间手物交互重建对于理解人类行为和实现具身智能、虚拟现实应用至关重要。现有方法局限于单图像或相机坐标系，无法建模时间动态或一致的全局轨迹，且在剧烈相机运动和频繁遮挡的野外第一人称视频中表现不佳。

Method: 提出多阶段框架：1）基于新开发的空间智能模型的鲁棒预处理流程；2）基于解耦扩散模型的全身手物交互先验模型（模板无关且可扩展到多物体）；3）多目标测试时优化范式。

Result: 实验证明该方法在世界空间手物交互重建方面达到了最先进的性能。

Conclusion: EgoGrasp是首个能够从动态单目第一人称野外视频中重建世界空间手物交互的方法，通过创新的多阶段框架解决了现有方法的局限性，为理解人类行为和实现相关应用提供了有效工具。

Abstract: We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.

</details>


### [23] [Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers](https://arxiv.org/abs/2601.01064)
*Jianan Li,Wangcai Zhao,Tingfa Xu*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级分离光谱变换器（LSST）用于高效的高光谱图像重建，采用分而治之策略处理光谱和空间特征，在减少计算量和参数的同时实现优越性能。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像在多个领域都很重要，但从压缩感知测量中高效重建高光谱图像面临重大挑战。需要利用高光谱图像独特的光谱和空间特性来设计更有效的重建方法。

Method: 采用分而治之策略，提出轻量级分离光谱变换器（LSST）架构，包含分离光谱变换块（SSTB）用于建模光谱关系，以及轻量级空间卷积块（LSCB）用于空间处理。SSTB使用分组光谱自注意力和光谱洗牌操作，LSCB使用深度可分离卷积和策略性排序。还引入了焦点光谱损失，一种动态调整训练权重的损失机制。

Result: 大量测试表明，LSST在减少FLOPs和参数的同时实现了优越的性能，证明了其效率和有效性。

Conclusion: LSST架构通过有效处理高光谱图像的光谱和空间特性，在高效重建方面表现出色，为高光谱图像压缩感知重建提供了一种轻量级且高性能的解决方案。

Abstract: Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.

</details>


### [24] [A UAV-Based Multispectral and RGB Dataset for Multi-Stage Paddy Crop Monitoring in Indian Agricultural Fields](https://arxiv.org/abs/2601.01084)
*Adari Rama Sukanya,Puvvula Roopesh Naga Sri Sai,Kota Moses,Rimalapudi Sarvendranath*

Main category: cs.CV

TL;DR: 本文提出了一个基于无人机的大规模水稻田RGB和多光谱图像数据集，覆盖了从育苗到收获的所有生长阶段，包含高分辨率图像和丰富元数据。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏覆盖印度水稻作物所有生长阶段的高分辨率无人机图像数据集，需要这样的数据集来支持精准农业应用，如靶向喷洒、病害分析和产量估算。

Method: 使用20兆像素RGB相机和5兆像素四波段多光谱相机（红、绿、红边、近红外）采集数据，制定了标准化操作程序和检查清单确保数据采集的可重复性，覆盖5英亩土地，地面采样距离为1厘米/像素。

Result: 创建了包含42,430张原始图像（415GB）的数据集，附带GPS坐标、飞行高度和环境条件等元数据，使用Pix4D Fields验证并生成正射影像图和植被指数图（NDVI和NDRE）。

Conclusion: 该数据集是少数几个提供覆盖印度水稻作物所有生长阶段的高分辨率图像和丰富元数据的资源之一，已在IEEE DataPort上公开，可用于精准农业研究。

Abstract: We present a large-scale unmanned aerial vehicle (UAV)-based RGB and multispectral image dataset collected over paddy fields in the Vijayawada region, Andhra Pradesh, India, covering nursery to harvesting stages. We used a 20-megapixel RGB camera and a 5-megapixel four-band multispectral camera capturing red, green, red-edge, and near-infrared bands. Standardised operating procedure (SOP) and checklists were developed to ensure repeatable data acquisition. Our dataset comprises of 42,430 raw images (415 GB) captured over 5 acres with 1 cm/pixel ground sampling distance (GSD) with associated metadata such as GPS coordinates, flight altitude, and environmental conditions. Captured images were validated using Pix4D Fields to generate orthomosaic maps and vegetation index maps, such as normalised difference vegetation index (NDVI) and normalised difference red-edge (NDRE) index. Our dataset is one of the few datasets that provide high-resolution images with rich metadata that cover all growth stages of Indian paddy crops. The dataset is available on IEEE DataPort with DOI, . It can support studies on targeted spraying, disease analysis, and yield estimation.

</details>


### [25] [Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models](https://arxiv.org/abs/2601.01085)
*Jiayi Xu,Zhang Zhang,Yuanrui Zhang,Ruitao Chen,Yixian Xu,Tianyu He,Di He*

Main category: cs.CV

TL;DR: Luminark是一种无需训练、概率认证的水印方法，适用于通用视觉生成模型，基于块级亮度统计实现可认证检测，通过水印引导技术实现跨模型兼容


<details>
  <summary>Details</summary>
Motivation: 为视觉生成模型开发一种通用的水印方法，既能保护模型输出版权，又不影响图像质量，同时提供可认证的检测保证

Method: 基于块级亮度统计定义水印，预定义二进制模式和相应阈值；利用广泛采用的引导技术作为即插即用机制，开发水印引导；通过统计分析控制误报率

Result: 在扩散、自回归和混合框架等9个模型上评估，Luminark始终表现出高检测精度、对常见图像变换的强鲁棒性以及良好的视觉质量

Conclusion: Luminark是一种有效的训练免费、概率认证的水印方法，具有跨模型通用性，不损害图像质量，为视觉生成模型提供了实用的版权保护解决方案

Abstract: In this paper, we introduce \emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.

</details>


### [26] [600k-ks-ocr: a large-scale synthetic dataset for optical character recognition in kashmiri script](https://arxiv.org/abs/2601.01088)
*Haq Nawaz Malik*

Main category: cs.CV

TL;DR: 该技术报告介绍了600K-KS-OCR数据集，这是一个包含约60.2万个词级分割图像的大规模合成语料库，专门用于训练和评估针对克什米尔文字的OCR系统。


<details>
  <summary>Details</summary>
Motivation: 克什米尔语是一种濒危的达尔德语系语言，使用改良的波斯-阿拉伯文字系统，约有700万人使用。目前缺乏针对克什米尔文字的OCR训练资源，该数据集旨在填补这一关键资源空白。

Method: 数据集生成方法包括：使用三种传统克什米尔字体渲染图像（256x64像素）；实施全面的数据增强模拟真实文档退化；采用多样化背景纹理增强模型鲁棒性；提供多种格式的真实标注以兼容CRNN、TrOCR等机器学习流程。

Result: 创建了包含约602,000个词级分割图像的大规模数据集，分布在10个分区存档中，总大小约10.6 GB。数据集采用CC-BY-4.0许可证发布，便于低资源语言OCR研究。

Conclusion: 该数据集为克什米尔语OCR系统开发提供了重要资源，有助于促进濒危语言的技术保护和研究，填补了低资源语言OCR领域的空白。

Abstract: This technical report presents the 600K-KS-OCR Dataset, a large-scale synthetic corpus comprising approximately 602,000 word-level segmented images designed for training and evaluating optical character recognition systems targeting Kashmiri script. The dataset addresses a critical resource gap for Kashmiri, an endangered Dardic language utilizing a modified Perso-Arabic writing system spoken by approximately seven million people. Each image is rendered at 256x64 pixels with corresponding ground-truth transcriptions provided in multiple formats compatible with CRNN, TrOCR, and generalpurpose machine learning pipelines. The generation methodology incorporates three traditional Kashmiri typefaces, comprehensive data augmentation simulating real-world document degradation, and diverse background textures to enhance model robustness. The dataset is distributed across ten partitioned archives totaling approximately 10.6 GB and is released under the CC-BY-4.0 license to facilitate research in low-resource language optical character recognition.

</details>


### [27] [NarrativeTrack: Evaluating Video Language Models Beyond the Frame](https://arxiv.org/abs/2601.01095)
*Hyeonjeong Ha,Jinjin Ge,Bo Feng,Kaixin Ma,Gargi Chakraborty*

Main category: cs.CV

TL;DR: NarrativeTrack是首个通过细粒度实体中心推理评估MLLMs叙事理解能力的基准，使用结构化评估框架CRP逐步增加叙事复杂性，揭示MLLMs在实体追踪和时序推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉语言推理方面取得了显著进展，但对视频中随时间展开的叙事理解能力仍未被充分探索。真正的叙事理解需要模型能够追踪"谁在何时何地做什么"，并在动态视觉和时序上下文中保持连贯的实体表示。

Method: 引入NarrativeTrack基准，通过细粒度实体中心推理评估叙事理解。采用结构化评估框架CRP（组合推理进展），在三个维度上逐步增加叙事复杂性：实体存在性、实体变化和实体模糊性。使用全自动实体中心管道提取时序基础实体表示。

Result: 评估显示最先进的MLLMs在视觉转换和时序动态中无法稳健追踪实体，经常在上下文变化时产生身份幻觉。开源通用MLLMs表现出强感知基础但弱时序连贯性，而视频专用MLLMs能捕捉时序上下文但幻觉实体上下文。这些发现揭示了感知基础和时序推理之间的基本权衡。

Conclusion: 叙事理解仅从感知基础和时序推理的整合中产生。NarrativeTrack提供了首个系统化框架来诊断和推进MLLMs中时序基础的叙事理解能力，为未来研究提供了重要基准。

Abstract: Multimodal large language models (MLLMs) have achieved impressive progress in vision-language reasoning, yet their ability to understand temporally unfolding narratives in videos remains underexplored. True narrative understanding requires grounding who is doing what, when, and where, maintaining coherent entity representations across dynamic visual and temporal contexts. We introduce NarrativeTrack, the first benchmark to evaluate narrative understanding in MLLMs through fine-grained entity-centric reasoning. Unlike existing benchmarks limited to short clips or coarse scene-level semantics, we decompose videos into constituent entities and examine their continuity via a Compositional Reasoning Progression (CRP), a structured evaluation framework that progressively increases narrative complexity across three dimensions: entity existence, entity changes, and entity ambiguity. CRP challenges models to advance from temporal persistence to contextual evolution and fine-grained perceptual reasoning. A fully automated entity-centric pipeline enables scalable extraction of temporally grounded entity representations, providing the foundation for CRP. Evaluations of state-of-the-art MLLMs reveal that models fail to robustly track entities across visual transitions and temporal dynamics, often hallucinating identity under context shifts. Open-source general-purpose MLLMs exhibit strong perceptual grounding but weak temporal coherence, while video-specific MLLMs capture temporal context yet hallucinate entity's contexts. These findings uncover a fundamental trade-off between perceptual grounding and temporal reasoning, indicating that narrative understanding emerges only from their integration. NarrativeTrack provides the first systematic framework to diagnose and advance temporally grounded narrative comprehension in MLLMs.

</details>


### [28] [CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops](https://arxiv.org/abs/2601.01176)
*Andrés Bell-Navas,Jesús Garicano-Mena,Antonella Ausiello,Soledad Le Clainche,María Villalba-Orero,Enrique Lara-Pezzi*

Main category: cs.CV

TL;DR: 开发了CardioMOD-Net AI框架，使用小鼠超声心动图视频进行HFpEF多类别诊断和连续发病时间预测


<details>
  <summary>Details</summary>
Motivation: HFpEF病因复杂且进展缓慢，现有AI模型仅关注二元检测，缺乏共病特异性表型分析和疾病进展时间预测

Method: 使用小鼠超声心动图视频，通过高阶动态模态分解提取时间特征，构建共享潜在表示的Vision Transformers，分别用于分类诊断和回归预测HFpEF发病时间

Result: 四组诊断总体准确率65%，所有类别超过50%准确率；预后模块预测HFpEF发病时间的均方根误差为21.72周，OB和SAH组预测最准确

Conclusion: 该统一框架证明即使在小数据条件下，也能从单一超声心动图视频获得多类别表型分析和连续HFpEF发病预测，为临床前HFpEF研究提供诊断和预后建模基础

Abstract: Introduction: Heart failure with preserved ejection fraction (HFpEF) arises from diverse comorbidities and progresses through prolonged subclinical stages, making early diagnosis and prognosis difficult. Current echocardiography-based Artificial Intelligence (AI) models focus primarily on binary HFpEF detection in humans and do not provide comorbidity-specific phenotyping or temporal estimates of disease progression towards decompensation. We aimed to develop a unified AI framework, CardioMOD-Net, to perform multiclass diagnosis and continuous prediction of HFpEF onset directly from standard echocardiography cine loops in preclinical models.
  Methods: Mouse echocardiography videos from four groups were used: control (CTL), hyperglycaemic (HG), obesity (OB), and systemic arterial hypertension (SAH). Two-dimensional parasternal long-axis cine loops were decomposed using Higher Order Dynamic Mode Decomposition (HODMD) to extract temporal features for downstream analysis. A shared latent representation supported Vision Transformers, one for a classifier for diagnosis and another for a regression module for predicting the age at HFpEF onset.
  Results: Overall diagnostic accuracy across the four groups was 65%, with all classes exceeding 50% accuracy. Misclassifications primarily reflected early-stage overlap between OB or SAH and CTL. The prognostic module achieved a root-mean-square error of 21.72 weeks for time-to-HFpEF prediction, with OB and SAH showing the most accurate estimates. Predicted HFpEF onset closely matched true distributions in all groups.
  Discussion: This unified framework demonstrates that multiclass phenotyping and continuous HFpEF onset prediction can be obtained from a single cine loop, even under small-data conditions. The approach offers a foundation for integrating diagnostic and prognostic modelling in preclinical HFpEF research.

</details>


### [29] [GenCAMO: Scene-Graph Contextual Decoupling for Environment-aware and Mask-free Camouflage Image-Dense Annotation Generation](https://arxiv.org/abs/2601.01181)
*Chenglizhao Chen,Shaojiang Yuan,Xiaoxue Lu,Mengke Song,Jia Song,Zhenyu Wu,Wenfeng Song,Shuai Li*

Main category: cs.CV

TL;DR: 本文提出GenCAMO框架，通过生成模型合成高质量伪装图像密集标注数据，解决伪装密集预测任务中数据稀缺问题，显著提升复杂伪装场景下的密集预测性能。


<details>
  <summary>Details</summary>
Motivation: 伪装密集预测（特别是RGB-D伪装目标检测和开放词汇伪装目标分割）对于理解复杂伪装场景至关重要，但由于数据收集和标注成本高昂，高质量、大规模的伪装数据集稀缺。

Method: 提出GenCAMO-DB大规模伪装数据集（包含深度图、场景图、属性描述和文本提示等多模态标注）和GenCAMO框架（环境感知、无掩码的生成框架），利用生成模型合成逼真的伪装图像密集数据。

Result: 多模态实验表明，GenCAMO通过提供高质量合成数据，显著提升了复杂伪装场景下的密集预测性能。

Conclusion: 通过生成模型合成伪装图像密集标注数据是解决数据稀缺问题的有效方法，GenCAMO框架能够为伪装密集预测任务提供高质量训练数据，提升模型性能。

Abstract: Conceal dense prediction (CDP), especially RGB-D camouflage object detection and open-vocabulary camouflage object segmentation, plays a crucial role in advancing the understanding and reasoning of complex camouflage scenes. However, high-quality and large-scale camouflage datasets with dense annotation remain scarce due to expensive data collection and labeling costs. To address this challenge, we explore leveraging generative models to synthesize realistic camouflage image-dense data for training CDP models with fine-grained representations, prior knowledge, and auxiliary reasoning. Concretely, our contributions are threefold: (i) we introduce GenCAMO-DB, a large-scale camouflage dataset with multi-modal annotations, including depth maps, scene graphs, attribute descriptions, and text prompts; (ii) we present GenCAMO, an environment-aware and mask-free generative framework that produces high-fidelity camouflage image-dense annotations; (iii) extensive experiments across multiple modalities demonstrate that GenCAMO significantly improves dense prediction performance on complex camouflage scenes by providing high-quality synthetic data. The code and datasets will be released after paper acceptance.

</details>


### [30] [Crowded Video Individual Counting Informed by Social Grouping and Spatial-Temporal Displacement Priors](https://arxiv.org/abs/2601.01192)
*Hao Lu,Xuhui Zhu,Wenjing Zhang,Yanan Li,Xiang Bai*

Main category: cs.CV

TL;DR: 本文提出OMAN++方法，通过引入社交分组先验和时空位移先验，将标准的一对一匹配放宽为一对多匹配，显著提升了拥挤场景下的视频个体计数性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频个体计数方法在拥挤场景（如地铁通勤）中表现不佳，需要专门针对拥挤动态人流的数据集和改进方法。

Method: 构建WuhanMetroCrowd数据集，引入社交分组先验（放宽一对一匹配为一对多匹配）和时空位移先验，设计隐式上下文生成器、一对多匹配器和位移先验注入器。

Result: OMAN++在标准基准测试（SenseCrowd、CroHD、MovingDroneCrowd）上优于现有方法，在WuhanMetroCrowd数据集上误差降低38.12%。

Conclusion: 提出的OMAN++方法通过利用社交分组和时空位移先验，有效解决了拥挤场景下的视频个体计数问题，建立了新的强基线。

Abstract: Video Individual Counting (VIC) is a recently introduced task aiming to estimate pedestrian flux from a video. It extends Video Crowd Counting (VCC) beyond the per-frame pedestrian count. In contrast to VCC that learns to count pedestrians across frames, VIC must identify co-existent pedestrians between frames, which turns out to be a correspondence problem. Existing VIC approaches, however, can underperform in congested scenes such as metro commuting. To address this, we build WuhanMetroCrowd, one of the first VIC datasets that characterize crowded, dynamic pedestrian flows. It features sparse-to-dense density levels, short-to-long video clips, slow-to-fast flow variations, front-to-back appearance changes, and light-to-heavy occlusions. To better adapt VIC approaches to crowds, we rethink the nature of VIC and recognize two informative priors: i) the social grouping prior that indicates pedestrians tend to gather in groups and ii) the spatial-temporal displacement prior that informs an individual cannot teleport physically. The former inspires us to relax the standard one-to-one (O2O) matching used by VIC to one-to-many (O2M) matching, implemented by an implicit context generator and a O2M matcher; the latter facilitates the design of a displacement prior injector, which strengthens not only O2M matching but also feature extraction and model training. These designs jointly form a novel and strong VIC baseline OMAN++. Extensive experiments show that OMAN++ not only outperforms state-of-the-art VIC baselines on the standard SenseCrowd, CroHD, and MovingDroneCrowd benchmarks, but also indicates a clear advantage in crowded scenes, with a 38.12% error reduction on our WuhanMetroCrowd dataset. Code, data, and pretrained models are available at https://github.com/tiny-smart/OMAN.

</details>


### [31] [RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models](https://arxiv.org/abs/2601.01202)
*Jiazhu Dai,Huihui Jiang*

Main category: cs.CV

TL;DR: 本文提出RefSR-Adv对抗攻击，通过仅扰动参考图像来降低基于参考的超分辨率系统性能，揭示了RefSR模型过度依赖参考特征的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注RefSR的后门攻击，而针对RefSR的对抗攻击脆弱性尚未充分探索。本文旨在填补这一研究空白，揭示RefSR系统的安全漏洞。

Method: 提出RefSR-Adv对抗攻击方法，通过最大化对抗输出与干净输出之间的差异，仅对参考图像添加扰动来降低超分辨率输出质量。

Result: RefSR-Adv在CNN、Transformer和Mamba架构上均能显著降低性能并产生严重伪影，实验证实低分辨率输入与参考图像的相似度与攻击效果呈正相关。

Conclusion: RefSR模型过度依赖参考特征是一个关键安全缺陷，本研究揭示了RefSR系统的安全漏洞，旨在促使研究者关注RefSR的鲁棒性问题。

Abstract: Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.

</details>


### [32] [XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression](https://arxiv.org/abs/2601.01204)
*Zunhai Su,Weihao Ye,Hansen Feng,Keyu Fan,Jing Zhang,Dahai Yu,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: XStreamVGGT通过联合剪枝和量化压缩KV缓存，解决了StreamVGGT在流式3D重建中KV缓存无限增长导致内存消耗和推理延迟增加的问题，实现了内存高效流式推理。


<details>
  <summary>Details</summary>
Motivation: StreamVGGT虽然利用帧级因果注意力实现了强大的流式重建，但存在KV缓存无限增长的问题，随着输入帧的积累导致内存消耗和推理延迟不断增加，限制了实际应用的可扩展性。

Method: 提出无需调优的XStreamVGGT方法，通过联合剪枝和量化系统性地压缩KV缓存：1）通过高效令牌重要性识别剪除多视图输入产生的冗余KV，实现固定内存预算；2）利用KV张量的独特分布特性，引入KV量化进一步减少内存消耗。

Result: 评估显示XStreamVGGT在性能损失几乎可忽略的情况下，显著将内存使用减少4.42倍，推理速度提升5.48倍，实现了可扩展且实用的流式3D应用。

Conclusion: XStreamVGGT通过系统性的KV缓存压缩技术，有效解决了流式3D视觉几何模型中KV缓存无限增长的问题，为大规模流式3D应用提供了内存高效且实用的解决方案。

Abstract: Learning-based 3D visual geometry models have benefited substantially from large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention for strong streaming reconstruction, but suffers from unbounded KV cache growth, leading to escalating memory consumption and inference latency as input frames accumulate. We propose XStreamVGGT, a tuning-free approach that systematically compresses the KV cache through joint pruning and quantization, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs originating from multi-view inputs are pruned through efficient token importance identification, enabling a fixed memory budget. Leveraging the unique distribution of KV tensors, we incorporate KV quantization to further reduce memory consumption. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\times$ and accelerating inference by 5.48$\times$, enabling scalable and practical streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.

</details>


### [33] [Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation](https://arxiv.org/abs/2601.01213)
*Riccardo Gelato,Carlo Sgaravatti,Jakob Grahn,Giacomo Boracchi,Filippo Maria Bianchi*

Main category: cs.CV

TL;DR: 该研究开发了一个基于Segment Anything Model (SAM)的SAR图像雪崩标注工具，通过领域适配、多通道编码器、提示工程和高效训练算法，显著加快了Sentinel-1 SAR图像的雪崩标注速度。


<details>
  <summary>Details</summary>
Motivation: SAR图像雪崩分割和制图对山区风险预测和减灾至关重要，但训练有效检测模型需要大量高质量专家标注数据，这一过程极其耗时。研究旨在通过改进SAM模型来加速SAR图像的雪崩标注过程。

Method: 针对SAR图像与自然图像的领域差异，采用适配器缓解领域差距；使用多编码器处理多通道SAR输入；通过提示工程策略提高雪崩定位精度；设计高效训练算法限制编码器训练时间。最终将改进的模型集成到标注工具中。

Result: 实验证明，该模型能够有效加速SAR图像的雪崩标注过程，解决了领域不匹配、多通道输入、不精确提示影响分割质量以及训练效率低等挑战。

Conclusion: 通过定制化改进SAM模型并集成到标注工具中，成功实现了SAR图像雪崩标注的加速，为山区雪崩风险监测提供了高效的技术支持。

Abstract: Remote sensing solutions for avalanche segmentation and mapping are key to supporting risk forecasting and mitigation in mountain regions. Synthetic Aperture Radar (SAR) imagery from Sentinel-1 can be effectively used for this task, but training an effective detection model requires gathering a large dataset with high-quality annotations from domain experts, which is prohibitively time-consuming. In this work, we aim to facilitate and accelerate the annotation of SAR images for avalanche mapping. We build on the Segment Anything Model (SAM), a segmentation foundation model trained on natural images, and tailor it to Sentinel-1 SAR data. Adapting SAM to our use-case requires addressing several domain-specific challenges: (i) domain mismatch, since SAM was not trained on satellite/SAR imagery; (ii) input adaptation, because SAR products typically provide more than three channels, while SAM is constrained to RGB images; (iii) robustness to imprecise prompts that can affect target identification and degrade the segmentation quality, an issue exacerbated in small, low-contrast avalanches; and (iv) training efficiency, since standard fine-tuning is computationally demanding for SAM. We tackle these challenges through a combination of adapters to mitigate the domain gap, multiple encoders to handle multi-channel SAR inputs, prompt-engineering strategies to improve avalanche localization accuracy, and a training algorithm that limits the training time of the encoder, which is recognized as the major bottleneck. We integrate the resulting model into an annotation tool and show experimentally that it speeds up the annotation of SAR images.

</details>


### [34] [Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment](https://arxiv.org/abs/2601.01224)
*Bac Nguyen,Yuhta Takida,Naoki Murata,Chieh-Hsin Lai,Toshimitsu Uesaka,Stefano Ermon,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: CODA通过引入寄存器槽和对比对齐损失，解决了Slot Attention在对象中心学习中的槽纠缠和对齐问题，显著提升了对象发现和图像生成性能。


<details>
  <summary>Details</summary>
Motivation: Slot Attention与预训练扩散模型结合在对象中心学习中有潜力，但存在槽纠缠和对象槽与图像内容对齐弱的问题，需要改进。

Method: 提出CODA框架：(1)使用寄存器槽吸收残差注意力，减少对象槽间的干扰；(2)应用对比对齐损失显式鼓励槽-图像对应关系，作为最大化槽与输入间互信息的可处理替代目标。

Result: 在合成数据集(MOVi-C/E)和真实数据集(VOC, COCO)上，CODA显著提升了对象发现性能(如COCO上FG-ARI提升6.1%)、属性预测和组合图像生成能力，寄存器槽开销极小。

Conclusion: CODA作为有效的对象中心学习框架，在复杂真实场景中具有应用潜力，通过简单扩展解决了槽纠缠和对齐问题，保持了高效性和可扩展性。

Abstract: Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.

</details>


### [35] [RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection](https://arxiv.org/abs/2601.01240)
*Ziqian Guan,Xieyi Fu,Yuting Wang,Haowen Xiao,Jiarui Zhu,Yingying Zhu,Yongtao Liu,Lin Gu*

Main category: cs.CV

TL;DR: RFAssigner是一种新颖的标签分配策略，通过高斯感受野距离度量候选位置与真实物体之间的相似性，自适应补充正样本，解决密集目标检测器中尺度不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有密集目标检测器的标签分配策略通常为每个训练样本分配正负权重，但这些方法往往为小物体分配的正样本数量不足，导致训练过程中的尺度不平衡问题。

Method: RFAssigner首先使用基于点的先验建立初始正样本集，然后利用高斯感受野距离度量未分配候选位置与真实物体之间的相似性，基于此度量自适应地从未分配池中选择补充正样本。

Result: 在三个具有不同物体尺度分布的数据集上的综合实验验证了该方法的有效性和泛化能力。配备RFAssigner的单个FCOS-ResNet-50检测器在所有物体尺度上都达到了最先进的性能，始终优于现有策略，且无需辅助模块或启发式方法。

Conclusion: RFAssigner通过自适应补充正样本，有效解决了密集目标检测中的尺度不平衡问题，显著提升了多尺度学习能力，为密集目标检测器的训练提供了更平衡的标签分配方案。

Abstract: Label assignment is a critical component in training dense object detectors. State-of-the-art methods typically assign each training sample a positive and a negative weight, optimizing the assignment scheme during training. However, these strategies often assign an insufficient number of positive samples to small objects, leading to a scale imbalance during training. To address this limitation, we introduce RFAssigner, a novel assignment strategy designed to enhance the multi-scale learning capabilities of dense detectors. RFAssigner first establishes an initial set of positive samples using a point-based prior. It then leverages a Gaussian Receptive Field (GRF) distance to measure the similarity between the GRFs of unassigned candidate locations and the ground-truth objects. Based on this metric, RFAssigner adaptively selects supplementary positive samples from the unassigned pool, promoting a more balanced learning process across object scales. Comprehensive experiments on three datasets with distinct object scale distributions validate the effectiveness and generalizability of our method. Notably, a single FCOS-ResNet-50 detector equipped with RFAssigner achieves state-of-the-art performance across all object scales, consistently outperforming existing strategies without requiring auxiliary modules or heuristics.

</details>


### [36] [MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance](https://arxiv.org/abs/2601.01260)
*Hamad Khan,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 提出MambaFormer混合专家框架，结合Transformer和状态空间模型专家，通过智能路由机制在医疗问答任务中实现计算成本与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在临床应用中计算成本与线性时间模型效率之间的基本权衡问题，为资源受限的临床部署提供可扩展解决方案。

Method: 提出LLM-based MambaFormer混合专家框架，包含轻量级门控机制进行token级动态路由：复杂短查询路由到Transformer专家(ET5)，长高吞吐序列路由到状态空间模型专家(EMamba)。采用新颖的效用引导多目标损失联合优化路由决策、参数和行为。

Result: 在DentalQA和PubMedQA数据集上验证，MambaFormer获得BERTScore=0.9180，超低延迟0.077秒，比T5-Large快24.4倍，在推理延迟和预测准确性之间实现帕累托最优权衡。

Conclusion: MambaFormer框架通过智能专家路由机制，在医疗问答任务中实现了计算效率与准确性的最佳平衡，为资源受限的临床部署提供了可扩展的高效解决方案。

Abstract: The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.

</details>


### [37] [VReID-XFD: Video-based Person Re-identification at Extreme Far Distance Challenge Results](https://arxiv.org/abs/2601.01312)
*Kailash A. Hambarde,Hugo Proença,Md Rashidunnabi,Pranita Samale,Qiwei Yang,Pingping Zhang,Zijing Gong,Yuhao Wang,Xi Zhang,Ruoshui Qu,Qiaoyun He,Yuhang Zhang,Thi Ngoc Ha Nguyen,Tien-Dung Mai,Cheng-Jun Kang,Yu-Fan Lin,Jin-Hui Jiang,Chih-Chung Hsu,Tamás Endrei,György Cserey,Ashwat Rajbhandari*

Main category: cs.CV

TL;DR: VReID-XFD是一个针对极端远距离（XFD）空中到地面行人重识别的视频基准测试和社区挑战，包含371个身份、11,288个轨迹和1175万帧，覆盖5.8米到120米高度、30度到90度视角和120米水平距离，揭示了性能随高度和距离单调下降的趋势。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别系统基于外观的假设在极端远距离的空中到地面场景中面临严重挑战，包括分辨率严重退化、极端视角变化、不稳定运动线索和服装变化等问题，需要专门的研究基准来探索这一独特操作机制。

Method: 基于DetReIDX数据集构建VReID-XFD基准测试，包含371个身份、11,288个轨迹和11.75百万帧，覆盖5.8-120米高度、30-90度视角和120米水平距离，支持空中到空中、空中到地面和地面到空中的严格身份分离评估，并举办VReID-XFD-25挑战赛吸引10个团队参与。

Result: 系统分析显示性能随高度和距离单调下降，天底视角普遍处于劣势，存在峰值性能与鲁棒性之间的权衡。即使在最佳表现的SAS-PReID方法中，空中到地面设置的mAP也仅为43.93%。

Conclusion: VReID-XFD为极端远距离空中到地面行人重识别提供了首个全面的基准测试，揭示了该领域面临的严峻挑战，表明现有方法在这一独特操作机制下仍有很大改进空间，相关数据集和评估协议已公开可用。

Abstract: Person re-identification (ReID) across aerial and ground views at extreme far distances introduces a distinct operating regime where severe resolution degradation, extreme viewpoint changes, unstable motion cues, and clothing variation jointly undermine the appearance-based assumptions of existing ReID systems. To study this regime, we introduce VReID-XFD, a video-based benchmark and community challenge for extreme far-distance (XFD) aerial-to-ground person re-identification. VReID-XFD is derived from the DetReIDX dataset and comprises 371 identities, 11,288 tracklets, and 11.75 million frames, captured across altitudes from 5.8 m to 120 m, viewing angles from oblique (30 degrees) to nadir (90 degrees), and horizontal distances up to 120 m. The benchmark supports aerial-to-aerial, aerial-to-ground, and ground-to-aerial evaluation under strict identity-disjoint splits, with rich physical metadata. The VReID-XFD-25 Challenge attracted 10 teams with hundreds of submissions. Systematic analysis reveals monotonic performance degradation with altitude and distance, a universal disadvantage of nadir views, and a trade-off between peak performance and robustness. Even the best-performing SAS-PReID method achieves only 43.93 percent mAP in the aerial-to-ground setting. The dataset, annotations, and official evaluation protocols are publicly available at https://www.it.ubi.pt/DetReIDX/ .

</details>


### [38] [LinMU: Multimodal Understanding Made Linear](https://arxiv.org/abs/2601.01322)
*Hongjie Wang,Niraj K. Jha*

Main category: cs.CV

TL;DR: LinMU是一种线性复杂度的视觉语言模型，通过M-MATE模块替换自注意力层，在保持性能的同时显著降低计算复杂度，适用于边缘设备和高分辨率图像/长视频处理。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的自注意力机制具有二次复杂度，限制了其在边缘设备上的部署，并且处理高分辨率图像和长视频时计算成本过高。

Method: 提出LinMU架构，使用M-MATE模块（包含双向状态空间模型的Flex-MA分支和局部窗口注意力的Local-Swin分支）替换所有自注意力层，并通过三阶段蒸馏框架将预训练VLM转换为LinMU架构。

Result: 在多个基准测试中，LinMU与教师模型性能相当，但在分钟级视频上，首词生成时间减少2.7倍，token吞吐量提高9.0倍。消融实验证实了蒸馏阶段和M-MATE双分支的重要性。

Conclusion: 研究表明，无需二次复杂度的注意力机制也能实现最先进的多模态推理，为处理高分辨率图像和长视频的视觉语言模型开辟了新途径。

Abstract: Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\times$ and improves token throughput by up to 9.0$\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.

</details>


### [39] [Achieving Fine-grained Cross-modal Understanding through Brain-inspired Hierarchical Representation Learning](https://arxiv.org/abs/2601.01339)
*Weihang You,Hanqi Jiang,Yi Pan,Junhao Chen,Tianming Liu,Fei Dou*

Main category: cs.CV

TL;DR: NeuroAlign是一个新颖的fMRI-视频对齐框架，通过模拟人类视觉系统的分层组织，实现跨模态检索任务中的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于将神经解码简化为生成任务或简单相关性分析，无法反映大脑视觉处理的分层和时间过程。由于大脑表征的固有复杂性以及神经数据与视觉输入之间的模态差距，理解神经对视觉刺激的反应仍然具有挑战性。

Method: 提出NeuroAlign框架，采用两阶段机制模拟生物视觉通路：1) 通过神经-时间对比学习(NTCL)实现全局语义理解，通过双向预测建模时间动态；2) 通过增强向量量化实现细粒度模式匹配；使用DynaSyncMM-EMA方法实现动态多模态融合和自适应加权。

Result: 实验表明，NeuroAlign在跨模态检索任务中显著优于现有方法，为理解视觉认知机制建立了新范式。

Conclusion: NeuroAlign通过模拟人类视觉系统的分层组织，成功解决了fMRI-视频对齐的挑战，为理解视觉认知机制提供了新的有效框架。

Abstract: Understanding neural responses to visual stimuli remains challenging due to the inherent complexity of brain representations and the modality gap between neural data and visual inputs. Existing methods, mainly based on reducing neural decoding to generation tasks or simple correlations, fail to reflect the hierarchical and temporal processes of visual processing in the brain. To address these limitations, we present NeuroAlign, a novel framework for fine-grained fMRI-video alignment inspired by the hierarchical organization of the human visual system. Our framework implements a two-stage mechanism that mirrors biological visual pathways: global semantic understanding through Neural-Temporal Contrastive Learning (NTCL) and fine-grained pattern matching through enhanced vector quantization. NTCL explicitly models temporal dynamics through bidirectional prediction between modalities, while our DynaSyncMM-EMA approach enables dynamic multi-modal fusion with adaptive weighting. Experiments demonstrate that NeuroAlign significantly outperforms existing methods in cross-modal retrieval tasks, establishing a new paradigm for understanding visual cognitive mechanisms.

</details>


### [40] [Unsupervised SE(3) Disentanglement for in situ Macromolecular Morphology Identification from Cryo-Electron Tomography](https://arxiv.org/abs/2601.01364)
*Mostofa Rafid Uddin,Mahek Vora,Qifeng Wu,Muyuan Chen,Min Xu*

Main category: cs.CV

TL;DR: 提出了一种解耦深度表示学习框架，用于从冷冻电镜断层扫描数据中分离SE(3)变换与形态内容，通过多选择学习模块处理高噪声数据，能够发现新的分子形态。


<details>
  <summary>Details</summary>
Motivation: 现有基于期望最大化的方法经常遗漏罕见但重要的分子形态，且需要大量手动超参数调整。冷冻电镜断层扫描提供了细胞内分子的直接3D可视化，但需要更好的方法来分析其原位形态。

Method: 提出解耦深度表示学习框架，在表示空间中分离SE(3)变换与形态内容。包含新颖的多选择学习模块，专门处理高噪声的冷冻电镜断层扫描数据，利用学习的形态内容生成模板形态。

Result: 在模拟和真实冷冻电镜断层扫描数据集上的实验表明，相比现有方法有明显改进，包括发现了先前未识别的大分子形态。

Conclusion: 该解耦表示学习框架能够有效处理冷冻电镜断层扫描数据的噪声问题，分离变换与形态特征，为发现新的分子形态提供了更好的方法。

Abstract: Cryo-electron tomography (cryo-ET) provides direct 3D visualization of macromolecules inside the cell, enabling analysis of their in situ morphology. This morphology can be regarded as an SE(3)-invariant, denoised volumetric representation of subvolumes extracted from tomograms. Inferring morphology is therefore an inverse problem of estimating both a template morphology and its SE(3) transformation. Existing expectation-maximization based solution to this problem often misses rare but important morphologies and requires extensive manual hyperparameter tuning. Addressing this issue, we present a disentangled deep representation learning framework that separates SE(3) transformations from morphological content in the representation space. The framework includes a novel multi-choice learning module that enables this disentanglement for highly noisy cryo-ET data, and the learned morphological content is used to generate template morphologies. Experiments on simulated and real cryo-ET datasets demonstrate clear improvements over prior methods, including the discovery of previously unidentified macromolecular morphologies.

</details>


### [41] [ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking](https://arxiv.org/abs/2601.01386)
*Xiaobao Wei,Zhangjie Ye,Yuxiang Gu,Zunjie Zhu,Yunfei Guo,Yingying Shen,Shan Zhao,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Rongfeng Lu,Hangjun Ye*

Main category: cs.CV

TL;DR: 提出了ParkGaussian框架，首次将3D高斯泼溅技术应用于停车场场景重建，并创建了ParkRecon3D基准数据集，通过槽位感知重建策略提升下游停车位检测任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶停车研究主要集中在2D停车位感知、建图和定位，而3D重建研究不足。停车场场景具有复杂的空间几何结构，但单纯提高重建视觉质量并不能直接提升自动停车性能，因为停车的关键入口是停车位感知模块。

Method: 1. 创建ParkRecon3D基准数据集，包含四个环视鱼眼相机的传感器数据、标定外参和密集停车位标注；2. 提出ParkGaussian框架，首次将3D高斯泼溅技术用于停车场场景重建；3. 引入槽位感知重建策略，利用现有停车感知方法增强槽位区域的合成质量。

Result: 在ParkRecon3D数据集上的实验表明，ParkGaussian实现了最先进的重建质量，并更好地保持了与下游任务的感知一致性。

Conclusion: ParkGaussian是首个将3D高斯泼溅技术应用于停车场场景重建的框架，通过槽位感知重建策略有效提升了重建质量与下游停车位检测任务的一致性，为自动驾驶停车系统提供了更好的3D场景理解能力。

Abstract: Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian

</details>


### [42] [AirSpatialBot: A Spatially-Aware Aerial Agent for Fine-Grained Vehicle Attribute Recognization and Retrieval](https://arxiv.org/abs/2601.01416)
*Yue Zhou,Ran Ding,Xue Yang,Xue Jiang,Xingzhao Liu*

Main category: cs.CV

TL;DR: 本文针对遥感视觉语言模型在空间理解方面的不足，提出了AirSpatial数据集和两阶段训练策略，开发了能够进行细粒度车辆属性识别和检索的空中智能体AirSpatialBot。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在空间理解方面存在局限，限制了其在实际应用中的效果。特别是针对无人机拍摄的车辆图像，需要更好的空间感知能力来支持更复杂的任务。

Method: 1) 创建包含超过20.6万条指令的AirSpatial数据集，引入空间定位和空间问答两个新任务，首次提供3D边界框标注；2) 采用两阶段训练策略：图像理解预训练和空间理解微调；3) 开发AirSpatialBot智能体，动态整合任务规划、图像理解、空间理解和任务执行能力。

Result: 实验结果表明该方法有效，揭示了现有VLMs的空间局限性，同时提供了有价值的见解。AirSpatialBot能够适应多样化的查询需求，实现细粒度车辆属性识别和检索。

Conclusion: 通过AirSpatial数据集和两阶段训练策略，成功提升了遥感视觉语言模型的空间理解能力，开发了实用的空中智能体，为遥感领域的空间感知任务提供了新的解决方案。

Abstract: Despite notable advancements in remote sensing vision-language models (VLMs), existing models often struggle with spatial understanding, limiting their effectiveness in real-world applications. To push the boundaries of VLMs in remote sensing, we specifically address vehicle imagery captured by drones and introduce a spatially-aware dataset AirSpatial, which comprises over 206K instructions and introduces two novel tasks: Spatial Grounding and Spatial Question Answering. It is also the first remote sensing grounding dataset to provide 3DBB. To effectively leverage existing image understanding of VLMs to spatial domains, we adopt a two-stage training strategy comprising Image Understanding Pre-training and Spatial Understanding Fine-tuning. Utilizing this trained spatially-aware VLM, we develop an aerial agent, AirSpatialBot, which is capable of fine-grained vehicle attribute recognition and retrieval. By dynamically integrating task planning, image understanding, spatial understanding, and task execution capabilities, AirSpatialBot adapts to diverse query requirements. Experimental results validate the effectiveness of our approach, revealing the spatial limitations of existing VLMs while providing valuable insights. The model, code, and datasets will be released at https://github.com/VisionXLab/AirSpatialBot

</details>


### [43] [DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer](https://arxiv.org/abs/2601.01425)
*Xu Guo,Fulong Ye,Xinghui Li,Pengqi Tu,Pengze Zhang,Qichao Sun,Songtao Zhao,Xiangwang Hou,Qian He*

Main category: cs.CV

TL;DR: DreamID-V是一个基于扩散Transformer的视频人脸交换框架，通过创新的数据管道、模态感知条件注入和课程学习机制，在保持身份相似性和时间一致性的同时实现高质量视频人脸交换。


<details>
  <summary>Details</summary>
Motivation: 现有视频人脸交换方法难以同时保持身份相似性、属性保留和时间一致性。需要将图像人脸交换的优势无缝迁移到视频领域，并解决现有基准测试有限的问题。

Method: 1) 提出SyncID-Pipe数据管道，预训练身份锚定视频合成器并与IFS模型结合构建双向ID四元组进行显式监督；2) 首个基于扩散Transformer的框架DreamID-V，采用模态感知条件模块区分性地注入多模态条件；3) 合成到真实的课程机制和身份一致性强化学习策略；4) 引入IDBench-V基准测试。

Result: 大量实验表明DreamID-V在性能上优于现有最先进方法，展现出卓越的通用性，可以无缝适应各种交换相关任务。

Conclusion: DreamID-V通过创新的框架设计和训练策略，成功解决了视频人脸交换中身份相似性、属性保留和时间一致性的平衡问题，为视频人脸交换领域提供了全面有效的解决方案。

Abstract: Video Face Swapping (VFS) requires seamlessly injecting a source identity into a target video while meticulously preserving the original pose, expression, lighting, background, and dynamic information. Existing methods struggle to maintain identity similarity and attribute preservation while preserving temporal consistency. To address the challenge, we propose a comprehensive framework to seamlessly transfer the superiority of Image Face Swapping (IFS) to the video domain. We first introduce a novel data pipeline SyncID-Pipe that pre-trains an Identity-Anchored Video Synthesizer and combines it with IFS models to construct bidirectional ID quadruplets for explicit supervision. Building upon paired data, we propose the first Diffusion Transformer-based framework DreamID-V, employing a core Modality-Aware Conditioning module to discriminatively inject multi-model conditions. Meanwhile, we propose a Synthetic-to-Real Curriculum mechanism and an Identity-Coherence Reinforcement Learning strategy to enhance visual realism and identity consistency under challenging scenarios. To address the issue of limited benchmarks, we introduce IDBench-V, a comprehensive benchmark encompassing diverse scenes. Extensive experiments demonstrate DreamID-V outperforms state-of-the-art methods and further exhibits exceptional versatility, which can be seamlessly adapted to various swap-related tasks.

</details>


### [44] [EdgeNeRF: Edge-Guided Regularization for Neural Radiance Fields from Sparse Views](https://arxiv.org/abs/2601.01431)
*Weiqi Yu,Yiyang Yao,Lin He,Jianming Lv*

Main category: cs.CV

TL;DR: EdgeNeRF：一种边缘引导的稀疏视图3D重建算法，通过提取输入图像边缘并在非边缘区域施加深度和法线正则化约束，在保持几何边界高频细节的同时减少伪影。


<details>
  <summary>Details</summary>
Motivation: 神经辐射场（NeRF）在密集多视图场景中表现优异，但在稀疏输入下重建质量显著下降，出现几何伪影。现有方法使用全局深度正则化来减轻伪影，但这会导致几何边界细节的丢失。

Method: 提出EdgeNeRF算法，利用深度和法线突变产生边缘的先验知识。首先从输入图像中提取边缘，然后在非边缘区域应用深度和法线正则化约束，增强几何一致性同时保持边界的高频细节。

Result: 在LLFF和DTU数据集上的实验表明，EdgeNeRF在保持锐利几何边界和抑制伪影方面表现优异。所提出的边缘引导深度正则化模块可以即插即用地集成到其他方法中，显著提升性能而不显著增加训练时间。

Conclusion: EdgeNeRF通过边缘引导的稀疏视图3D重建方法，有效解决了NeRF在稀疏输入下的几何伪影问题，在保持几何边界细节的同时提升了重建质量，且具有良好的可扩展性。

Abstract: Neural Radiance Fields (NeRF) achieve remarkable performance in dense multi-view scenarios, but their reconstruction quality degrades significantly under sparse inputs due to geometric artifacts. Existing methods utilize global depth regularization to mitigate artifacts, leading to the loss of geometric boundary details. To address this problem, we propose EdgeNeRF, an edge-guided sparse-view 3D reconstruction algorithm. Our method leverages the prior that abrupt changes in depth and normals generate edges. Specifically, we first extract edges from input images, then apply depth and normal regularization constraints to non-edge regions, enhancing geometric consistency while preserving high-frequency details at boundaries. Experiments on LLFF and DTU datasets demonstrate EdgeNeRF's superior performance, particularly in retaining sharp geometric boundaries and suppressing artifacts. Additionally, the proposed edge-guided depth regularization module can be seamlessly integrated into other methods in a plug-and-play manner, significantly improving their performance without substantially increasing training time. Code is available at https://github.com/skyhigh404/edgenerf.

</details>


### [45] [In defense of the two-stage framework for open-set domain adaptive semantic segmentation](https://arxiv.org/abs/2601.01439)
*Wenqi Ren,Weijie Wang,Meng Zheng,Ziyan Wu,Yang Tang,Zhun Zhong,Nicu Sebe*

Main category: cs.CV

TL;DR: 本文提出SATS方法，通过分离-适应两阶段训练策略解决开放集域适应语义分割问题，避免已知类和未知类之间的负迁移和欠拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有开放集域适应语义分割方法通常采用单阶段统一处理已知类和未知类，但由于已知类和未知类之间的标注不平衡，往往导致已知类的负迁移和未知类的欠拟合问题。

Method: 提出SATS（Separating-then-Adapting Training Strategy）两阶段训练策略：1）已知/未知分离阶段；2）未知感知的域适应阶段。同时提出硬未知探索数据增强方法，让模型接触更具挑战性的未知样本。

Result: 在公开的OSDA-SS基准测试中，方法取得显著提升：GTA5-to-Cityscapes上H-Score提升+3.85%，SYNTHIA-to-Cityscapes上提升+18.64%，优于现有最先进方法。

Conclusion: 通过分离已知类和未知类并分别进行域适应，SATS方法能够平衡学习已知类和未知类的判别特征，有效发现真正的未知对象，显著提升开放集域适应语义分割性能。

Abstract: Open-Set Domain Adaptation for Semantic Segmentation (OSDA-SS) presents a significant challenge, as it requires both domain adaptation for known classes and the distinction of unknowns. Existing methods attempt to address both tasks within a single unified stage. We question this design, as the annotation imbalance between known and unknown classes often leads to negative transfer of known classes and underfitting for unknowns. To overcome these issues, we propose SATS, a Separating-then-Adapting Training Strategy, which addresses OSDA-SS through two sequential steps: known/unknown separation and unknown-aware domain adaptation. By providing the model with more accurate and well-aligned unknown classes, our method ensures a balanced learning of discriminative features for both known and unknown classes, steering the model toward discovering truly unknown objects. Additionally, we present hard unknown exploration, an innovative data augmentation method that exposes the model to more challenging unknowns, strengthening its ability to capture more comprehensive understanding of target unknowns. We evaluate our method on public OSDA-SS benchmarks. Experimental results demonstrate that our method achieves a substantial advancement, with a +3.85% H-Score improvement for GTA5-to-Cityscapes and +18.64% for SYNTHIA-to-Cityscapes, outperforming previous state-of-the-art methods.

</details>


### [46] [Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration](https://arxiv.org/abs/2601.01456)
*Wentao Bian,Fenglei Xu*

Main category: cs.CV

TL;DR: DA-FSS提出了一种解耦专家仲裁的少样本3D点云语义分割方法，解决了传统"先融合后细化"范式中的"可塑性-稳定性困境"和CLIP的类间混淆问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态少样本3D点云分割方法存在"可塑性-稳定性困境"：几何路径需要可塑性以适应新类别，而语义路径需要稳定性以避免过拟合。同时，CLIP的类间混淆会导致语义盲区。

Method: 提出DA-FSS模型，包含：1) 并行专家细化模块生成各模态相关性；2) 堆叠仲裁模块进行卷积融合和模态路径仲裁；3) 解耦专家路径：几何专家保持可塑性，语义专家确保稳定性；4) 解耦对齐模块在不传播混淆的情况下传递知识。

Result: 在S3DIS和ScanNet数据集上的实验表明，DA-FSS优于MM-FSS基准方法，在几何边界、完整性和纹理区分方面都表现更优。

Conclusion: 通过解耦几何和语义路径并相互正则化梯度，DA-FSS能够更好地利用多模态信息空间，实现更好的泛化性能，解决了少样本3D点云分割中的关键挑战。

Abstract: In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in "Fuse-then-Refine" paradigms: the "Plasticity-Stability Dilemma." In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.

</details>


### [47] [Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network](https://arxiv.org/abs/2601.01460)
*Mohd Usama,Belal Ahmad,Christer Gronlund,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出基于GAN的医学图像域适应方法，通过图像到图像转换统一不同超声设备的纹理模式并去除混响噪声，解决医学影像中设备差异导致的模型泛化问题。


<details>
  <summary>Details</summary>
Motivation: 医学影像中不同设备或参数设置产生的图像存在纹理和噪声差异，导致训练于某一设备的模型在其他设备上性能下降，而针对每个设备重新训练成本高昂。

Method: 提出基于GAN的图像到图像转换模型，将源域图像转换为目标域风格，保持图像内容不变的同时统一纹理模式并去除混响噪声。

Result: 在包含三个不同域的颈动脉超声数据集上验证，模型成功转换纹理模式并去除噪声，在直方图相关性(0.960 vs 0.916)和巴氏距离(0.040 vs 0.090)指标上显著优于无适应方法。

Conclusion: 提出的GAN基域适应方法能有效解决医学影像中的设备差异问题，提高模型跨域泛化能力，相比CycleGAN等现有方法表现更优。

Abstract: Deep learning has been extensively used in medical imaging applications, assuming that the test and training datasets belong to the same probability distribution. However, a common challenge arises when working with medical images generated by different systems or even the same system with different parameter settings. Such images contain diverse textures and reverberation noise that violate the aforementioned assumption. Consequently, models trained on data from one device or setting often struggle to perform effectively with data from other devices or settings. In addition, retraining models for each specific device or setting is labor-intensive and costly. To address these issues in ultrasound images, we propose a novel Generative Adversarial Network (GAN)-based model. We formulated the domain adaptation tasks as an image-to-image translation task, in which we modified the texture patterns and removed reverberation noise in the test data images from the source domain to align with those in the target domain images while keeping the image content unchanged. We applied the proposed method to two datasets containing carotid ultrasound images from three different domains. The experimental results demonstrate that the model successfully translated the texture pattern of images and removed reverberation noise from the ultrasound images. Furthermore, we evaluated the CycleGAN approaches for a comparative study with the proposed model. The experimental findings conclusively demonstrated that the proposed model achieved domain adaptation (histogram correlation (0.960 (0.019), & 0.920 (0.043) and bhattacharya distance (0.040 (0.020), & 0.085 (0.048)), compared to no adaptation (0.916 (0.062) & 0.890 (0.077), 0.090 (0.070) & 0.121 (0.095)) for both datasets.

</details>


### [48] [Robust Ship Detection and Tracking Using Modified ViBe and Backwash Cancellation Algorithm](https://arxiv.org/abs/2601.01481)
*Mohammad Hassan Saghafi,Seyed Majid Noorhosseini,Seyed Abolfazl Seyed Javadein,Hadi Khalili*

Main category: cs.CV

TL;DR: 提出一种用于海岸视频序列中船舶检测与跟踪的鲁棒实时方法，包括改进的ViBe运动物体检测算法和尾流消除技术


<details>
  <summary>Details</summary>
Motivation: 海岸场景具有不可预测性和动态特性，需要能够适应这些条件的鲁棒检测方法，特别是在自然海浪、光线变化等复杂环境下准确检测船舶

Method: 1. 改进的ViBe算法用于运动物体检测，降低船舶丢失概率，对自然海浪和光线变化具有鲁棒性，能快速更新背景；2. 基于船舶几何特性和亮度失真等概念，提出新的尾流消除方法

Result: 实验结果表明，所提出的策略和方法在船舶检测和跟踪方面具有优异性能，同时实现了实时和精确的处理效果

Conclusion: 该方法能够有效应对海岸视频序列中的复杂环境，在船舶检测和跟踪任务中表现出色，满足实时性和准确性的要求

Abstract: In this paper, we propose a robust real time detection and tracking method for detecting ships in a coastal video sequences. Since coastal scenarios are unpredictable and scenes have dynamic properties it is essential to apply detection methods that are robust to these conditions. This paper presents modified ViBe for moving object detection which detects ships and backwash. In the modified ViBe the probability of losing ships is decreased in comparison with the original ViBe. It is robust to natural sea waves and variation of lights and is capable of quickly updating the background. Based on geometrical properties of ship and some concepts such as brightness distortion, a new method for backwash cancellation is proposed. Experimental results demonstrate that the proposed strategy and methods have outstanding performance in ship detection and tracking. These results also illustrate real time and precise performance of the proposed strategy.

</details>


### [49] [Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization](https://arxiv.org/abs/2601.01483)
*Xinyu Qiu,Heng Jia,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Yi Yang,Linchao Zhu*

Main category: cs.CV

TL;DR: ADPO是一个统一的强化学习框架，在单一策略中联合学习答案生成和自我验证，通过偏好验证奖励和解耦优化机制，显著提升验证能力和推理效率。


<details>
  <summary>Details</summary>
Motivation: 传统的并行测试时扩展方法需要分别训练生成和验证模型，导致训练和推理成本高昂。需要一种统一的框架来同时学习生成和验证能力，降低计算开销。

Method: 提出ADPO框架，包含两个创新：1）偏好验证奖励，通过正负样本的平均验证分数作为决策阈值，当预测正确性与答案正确性一致时提供正反馈；2）优势解耦优化，为生成和验证分别计算优势，应用token掩码隔离梯度，结合掩码GRPO目标，在保持生成质量的同时校准验证分数。

Result: ADPO实现了验证AUC提升高达+34.1%，推理时间降低-53.5%，在MathVista/MMMU上准确率分别提升+2.8%/+1.4%，ReasonSeg上cIoU提升+1.9，AndroidControl/GUI Odyssey上步骤成功率分别提升+1.7%/+1.0%。

Conclusion: ADPO通过统一的强化学习框架有效解决了生成和验证分离带来的高成本问题，在保持生成质量的同时显著提升了验证能力和推理效率，为多模态推理任务提供了高效的解决方案。

Abstract: Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that jointly learns answer generation and self-verification within a single policy. ADPO introduces two innovations: a preference verification reward improving verification capability and a decoupled optimization mechanism enabling synergistic optimization of generation and verification. Specifically, the preference verification reward computes mean verification scores from positive and negative samples as decision thresholds, providing positive feedback when prediction correctness aligns with answer correctness. Meanwhile, the advantage decoupled optimization computes separate advantages for generation and verification, applies token masks to isolate gradients, and combines masked GRPO objectives, preserving generation quality while calibrating verification scores. ADPO achieves up to +34.1% higher verification AUC and -53.5% lower inference time, with significant gains of +2.8%/+1.4% accuracy on MathVista/MMMU, +1.9 cIoU on ReasonSeg, and +1.7%/+1.0% step success rate on AndroidControl/GUI Odyssey.

</details>


### [50] [Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease](https://arxiv.org/abs/2601.01485)
*Zobia Batool,Diala Lteif,Vijaya B. Kolachalama,Huseyin Ozkan,Erchan Aptoula*

Main category: cs.CV

TL;DR: 本文提出Extended MixStyle (EM)框架，通过混合高阶特征矩（偏度和峰度）来模拟多样化的分布变化，以解决阿尔茨海默病诊断中单域泛化问题，在未见数据集上平均提升2.4个百分点的宏F1分数。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在阿尔茨海默病诊断方面取得进展，但基于结构磁共振成像训练的模型由于扫描仪、协议和患者人口统计学的差异导致域偏移，在新队列上表现不佳。阿尔茨海默病作为痴呆症的主要驱动因素，通过萎缩和脑室扩张等渐进性认知和神经解剖学变化表现出来，因此需要鲁棒、可泛化的分类方法用于实际应用。单域泛化在阿尔茨海默病数据集的碎片化背景下至关重要但尚未充分探索。

Method: 提出Extended MixStyle (EM)框架，通过混合高阶特征矩（偏度和峰度）来模拟多样化的分布变化。使用国家阿尔茨海默病协调中心的结构磁共振成像数据进行训练，区分正常认知、轻度认知障碍和阿尔茨海默病患者，并在三个未见队列上进行测试。

Result: 在三个未见队列（总样本量3,126）上，EM框架显著提升了跨域性能，平均宏F1分数比最先进的单域泛化基准提高了2.4个百分点，展示了其在异质真实世界环境中实现不变、可靠的阿尔茨海默病检测的潜力。

Conclusion: Extended MixStyle框架通过混合高阶特征矩有效解决了阿尔茨海默病诊断中的单域泛化问题，在未见数据集上表现出优越的泛化能力，为异质真实世界环境中的可靠阿尔茨海默病检测提供了有前景的解决方案。

Abstract: Despite progress in deep learning for Alzheimer's disease (AD) diagnostics, models trained on structural magnetic resonance imaging (sMRI) often do not perform well when applied to new cohorts due to domain shifts from varying scanners, protocols and patient demographics. AD, the primary driver of dementia, manifests through progressive cognitive and neuroanatomical changes like atrophy and ventricular expansion, making robust, generalizable classification essential for real-world use. While convolutional neural networks and transformers have advanced feature extraction via attention and fusion techniques, single-domain generalization (SDG) remains underexplored yet critical, given the fragmented nature of AD datasets. To bridge this gap, we introduce Extended MixStyle (EM), a framework for blending higher-order feature moments (skewness and kurtosis) to mimic diverse distributional variations. Trained on sMRI data from the National Alzheimer's Coordinating Center (NACC; n=4,647) to differentiate persons with normal cognition (NC) from those with mild cognitive impairment (MCI) or AD and tested on three unseen cohorts (total n=3,126), EM yields enhanced cross-domain performance, improving macro-F1 on average by 2.4 percentage points over state-of-the-art SDG benchmarks, underscoring its promise for invariant, reliable AD detection in heterogeneous real-world settings. The source code will be made available upon acceptance at https://github.com/zobia111/Extended-Mixstyle.

</details>


### [51] [DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion](https://arxiv.org/abs/2601.01487)
*Ziyue Zhang,Luxi Lin,Xiaolin Hu,Chao Chang,HuaiXi Wang,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出DeepInv自监督扩散反演方法，通过自监督目标和数据增强生成伪噪声，训练参数化反演求解器实现快速准确的图像到噪声映射。


<details>
  <summary>Details</summary>
Motivation: 扩散反演任务缺乏可行的监督信号，现有方法多为基于近似的解决方案，往往在性能或效率上有所牺牲。

Method: 提出自监督扩散反演方法DeepInv：1) 引入自监督目标和数据增强策略生成高质量伪噪声；2) 采用迭代多尺度训练机制训练参数化反演求解器；3) 首次提出可训练的分步预测反演噪声求解器。

Result: 在COCO数据集上，DeepInv比EasyInv SSIM提升40.435%，比ReNoise推理速度提升9887.5%，在性能和推理速度上均显著优于对比方法。

Conclusion: DeepInv通过自监督学习和可训练求解器设计，实现了高效准确的扩散反演，为社区提供了新的研究思路。

Abstract: Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.

</details>


### [52] [FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01513)
*Gen Li,Peiyu Liu*

Main category: cs.CV

TL;DR: VideoSpeculateRAG：基于推测解码的高效视觉语言模型检索增强生成框架，通过轻量级草稿模型生成候选答案，再由重量级模型验证优化，在保持准确性的同时将推理速度提升约2倍。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在整合外部知识方面仍有困难，检索增强生成方法存在效率低下和答案质量不稳定的问题，需要开发更高效可靠的解决方案。

Method: 提出VideoSpeculateRAG框架，包含两个核心创新：1）推测解码流水线：轻量级草稿模型快速生成多个候选答案，再由准确的重量级模型验证和优化；2）相似性过滤策略：解决检索知识中实体识别错误问题，提升实体对齐和答案准确性。

Result: 实验表明，VideoSpeculateRAG在保持或超越标准RAG方法准确性的同时，将推理速度提升约2倍，有效平衡了效率与准确性。

Conclusion: 该框架展示了将推测解码与检索增强推理相结合在复杂知识密集型多模态任务中的潜力，为提升视觉语言模型在知识整合方面的效率和可靠性提供了有效方案。

Abstract: Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.

</details>


### [53] [BARE: Towards Bias-Aware and Reasoning-Enhanced One-Tower Visual Grounding](https://arxiv.org/abs/2601.01526)
*Hongbing Li,Linhui Xiao,Zihan Zhao,Qi Shen,Yixiang Huang,Bo Xiao,Zhanyu Ma*

Main category: cs.CV

TL;DR: BARE是一个用于单塔视觉定位的偏置感知和推理增强框架，通过保留模态特定特征和构建指称语义来解决现有方法中的模态偏置和语义推理不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有单塔视觉定位方法存在两个主要限制：1）过度纠缠的多模态表示加剧了欺骗性模态偏置；2）语义推理不足阻碍了指称线索的理解。

Method: 提出BARE框架，包含三个新模块：语言显著性调制器、视觉偏置校正和指称关系增强，共同减轻多模态干扰并增强指称理解。

Result: 在五个基准测试上的广泛实验表明，BARE不仅实现了最先进的性能，而且相比现有方法具有更优的计算效率。

Conclusion: BARE通过偏置感知和推理增强机制有效解决了视觉定位中的模态偏置和语义推理问题，在性能和效率方面都表现出色。

Abstract: Visual Grounding (VG), which aims to locate a specific region referred to by expressions, is a fundamental yet challenging task in the multimodal understanding fields. While recent grounding transfer works have advanced the field through one-tower architectures, they still suffer from two primary limitations: (1) over-entangled multimodal representations that exacerbate deceptive modality biases, and (2) insufficient semantic reasoning that hinders the comprehension of referential cues. In this paper, we propose BARE, a bias-aware and reasoning-enhanced framework for one-tower visual grounding. BARE introduces a mechanism that preserves modality-specific features and constructs referential semantics through three novel modules: (i) language salience modulator, (ii) visual bias correction and (iii) referential relationship enhancement, which jointly mitigate multimodal distractions and enhance referential comprehension. Extensive experimental results on five benchmarks demonstrate that BARE not only achieves state-of-the-art performance but also delivers superior computational efficiency compared to existing approaches. The code is publicly accessible at https://github.com/Marloweeee/BARE.

</details>


### [54] [DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving](https://arxiv.org/abs/2601.01528)
*Yang Zhou,Hao Shao,Letian Wang,Zhuofan Zong,Hongsheng Li,Steven L. Waslander*

Main category: cs.CV

TL;DR: DrivingGen是首个用于生成式驾驶世界模型的综合基准，解决了现有评估方法的局限性，通过多样化数据集和新指标评估视觉真实性、轨迹合理性、时间一致性和可控性。


<details>
  <summary>Details</summary>
Motivation: 当前驾驶世界模型研究缺乏严谨的基准来测量进展和指导优先级。现有评估方法存在多个局限性：通用视频指标忽视安全关键因素；轨迹合理性很少量化；时间和智能体级别一致性被忽略；对自我条件控制的可控性被忽视；且当前数据集未能覆盖现实部署所需的多样性条件。

Method: 提出DrivingGen基准，结合从驾驶数据集和互联网规模视频源中策划的多样化评估数据集，涵盖不同天气、时间、地理区域和复杂操作，并配备一套新指标来联合评估视觉真实性、轨迹合理性、时间一致性和可控性。

Result: 对14个最先进模型的基准测试揭示了明确的权衡：通用模型看起来更好但违反物理规律，而驾驶专用模型能真实捕捉运动但在视觉质量上落后。DrivingGen为评估驾驶世界模型提供了统一框架。

Conclusion: DrivingGen提供了一个统一的评估框架，以促进可靠、可控和可部署的驾驶世界模型的发展，从而实现可扩展的模拟、规划和数据驱动的决策制定。

Abstract: Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.

</details>


### [55] [Improving Flexible Image Tokenizers for Autoregressive Image Generation](https://arxiv.org/abs/2601.01535)
*Zixuan Fu,Lanqing Guo,Chong Wang,Binbin Song,Ding Liu,Bihan Wen*

Main category: cs.CV

TL;DR: ReToK提出了一种新的灵活图像分词器，通过冗余令牌填充和分层语义正则化，解决了传统嵌套丢弃方法中信息过度集中在早期令牌的问题，提高了自回归图像生成的效果。


<details>
  <summary>Details</summary>
Motivation: 传统灵活图像分词器使用嵌套丢弃（尾部截断）策略，导致图像信息过度集中在早期令牌中，限制了自回归图像生成的效果，特别是当令牌长度增加时。

Method: 提出ReToK方法：1）冗余令牌填充：更频繁地激活尾部令牌，缓解信息过度集中问题；2）分层语义正则化：对齐早期令牌的解码特征与预训练视觉基础模型，同时向尾部逐渐减少正则化强度，允许更精细的低级细节重建。

Result: 在ImageNet 256×256数据集上的实验表明，ReToK相比灵活和固定长度分词器都取得了更优的生成性能。

Conclusion: ReToK通过冗余令牌填充和分层语义正则化，有效解决了灵活图像分词器中信息分布不均的问题，显著提升了自回归图像生成的质量。

Abstract: Flexible image tokenizers aim to represent an image using an ordered 1D variable-length token sequence. This flexible tokenization is typically achieved through nested dropout, where a portion of trailing tokens is randomly truncated during training, and the image is reconstructed using the remaining preceding sequence. However, this tail-truncation strategy inherently concentrates the image information in the early tokens, limiting the effectiveness of downstream AutoRegressive (AR) image generation as the token length increases. To overcome these limitations, we propose \textbf{ReToK}, a flexible tokenizer with \underline{Re}dundant \underline{Tok}en Padding and Hierarchical Semantic Regularization, designed to fully exploit all tokens for enhanced latent modeling. Specifically, we introduce \textbf{Redundant Token Padding} to activate tail tokens more frequently, thereby alleviating information over-concentration in the early tokens. In addition, we apply \textbf{Hierarchical Semantic Regularization} to align the decoding features of earlier tokens with those from a pre-trained vision foundation model, while progressively reducing the regularization strength toward the tail to allow finer low-level detail reconstruction. Extensive experiments demonstrate the effectiveness of ReTok: on ImageNet 256$\times$256, our method achieves superior generation performance compared with both flexible and fixed-length tokenizers. Code will be available at: \href{https://github.com/zfu006/ReTok}{https://github.com/zfu006/ReTok}

</details>


### [56] [EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding](https://arxiv.org/abs/2601.01547)
*Tianjun Gu,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: 论文提出Teleo-Spatial Intelligence (TSI)新范式，结合物理动态推理和意图驱动推理，并创建EscherVerse基准套件来评估AI在开放世界中的空间智能能力。


<details>
  <summary>Details</summary>
Motivation: 当前空间推理研究忽略了人类意图在空间变化中的作用，需要从被动场景描述转向目的驱动的整体世界理解。

Method: 提出TSI范式，包含物理动态推理和意图驱动推理两个支柱；创建EscherVerse基准套件，包括Escher-Bench基准、Escher-35k数据集和Escher系列模型；开发了新颖的数据整理流程。

Result: EscherVerse是首个系统评估意图驱动推理的基准，基于真实世界视频，评估物体恒存性、状态转换和轨迹预测能力，超越了受限环境设置。

Conclusion: 该工作为从被动场景描述向整体目的驱动世界理解推进空间智能提供了基础资源，开启了空间推理研究的新方向。

Abstract: The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.

</details>


### [57] [Beyond Patches: Global-aware Autoregressive Model for Multimodal Few-Shot Font Generation](https://arxiv.org/abs/2601.01593)
*Haonan Cai,Yuxuan Luo,Zhouhui Lian*

Main category: cs.CV

TL;DR: GAR-Font是一个用于少样本字体生成的新型自回归框架，通过全局感知分词器、多模态风格编码器和后处理细化管道，解决了现有方法在结构完整性和风格保真度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有少样本字体生成方法存在两个主要问题：1）传统自回归模型使用补丁级分词，忽略了字体合成所需的全局依赖关系；2）现有方法局限于图像到图像范式，仅依赖视觉参考而忽视了语言在传达字体设计风格意图中的作用。

Method: 提出了GAR-Font框架，包含三个核心组件：1）全局感知分词器，同时捕捉局部结构和全局风格模式；2）多模态风格编码器，通过轻量级语言风格适配器实现灵活的风格控制，无需密集的多模态预训练；3）后处理细化管道，进一步增强结构保真度和风格一致性。

Result: 大量实验表明，GAR-Font在少样本字体生成任务上优于现有方法，在保持全局风格忠实度方面表现突出，并且通过文本风格指导实现了更高质量的生成结果。

Conclusion: GAR-Font通过结合全局感知建模和多模态风格控制，有效解决了少样本字体生成中的结构完整性和风格保真度问题，为字体设计自动化提供了更强大的工具。

Abstract: Manual font design is an intricate process that transforms a stylistic visual concept into a coherent glyph set. This challenge persists in automated Few-shot Font Generation (FFG), where models often struggle to preserve both the structural integrity and stylistic fidelity from limited references. While autoregressive (AR) models have demonstrated impressive generative capabilities, their application to FFG is constrained by conventional patch-level tokenization, which neglects global dependencies crucial for coherent font synthesis. Moreover, existing FFG methods remain within the image-to-image paradigm, relying solely on visual references and overlooking the role of language in conveying stylistic intent during font design. To address these limitations, we propose GAR-Font, a novel AR framework for multimodal few-shot font generation. GAR-Font introduces a global-aware tokenizer that effectively captures both local structures and global stylistic patterns, a multimodal style encoder offering flexible style control through a lightweight language-style adapter without requiring intensive multimodal pretraining, and a post-refinement pipeline that further enhances structural fidelity and style coherence. Extensive experiments show that GAR-Font outperforms existing FFG methods, excelling in maintaining global style faithfulness and achieving higher-quality results with textual stylistic guidance.

</details>


### [58] [Guiding Token-Sparse Diffusion Models](https://arxiv.org/abs/2601.01608)
*Felix Krause,Stefan Andreas Baumann,Johannes Schusterbauer,Olga Grebenkova,Ming Gui,Vincent Tao Hu,Björn Ommer*

Main category: cs.CV

TL;DR: 提出Sparse Guidance (SG)方法解决稀疏训练扩散模型在推理时Classifier-free Guidance效果不佳的问题，通过token级稀疏性实现高质量低计算量的图像生成。


<details>
  <summary>Details</summary>
Motivation: 稀疏训练的扩散模型虽然降低了训练成本，但在推理时对Classifier-free Guidance响应不佳，导致生成质量下降，需要解决这一推理性能问题。

Method: 提出Sparse Guidance (SG)方法，使用token级稀疏性替代传统的条件dropout作为引导信号，在推理时保持条件预测的高方差，实现高质量输出。

Result: 在ImageNet-256基准测试中达到1.58 FID，减少25% FLOPs；在匹配基线质量时可节省58% FLOPs；2.5B文本到图像模型在构图和人类偏好评分上均有提升。

Conclusion: Sparse Guidance有效解决了稀疏训练扩散模型的推理性能问题，实现了高质量、低计算成本的图像生成，具有实际应用价值。

Abstract: Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.

</details>


### [59] [CAP-IQA: Context-Aware Prompt-Guided CT Image Quality Assessment](https://arxiv.org/abs/2601.01613)
*Kazi Ramisa Rifa,Jie Zhang,Abdullah Imran*

Main category: cs.CV

TL;DR: 提出了CAP-IQA框架，通过上下文感知提示引导和因果去偏技术，结合文本先验和实例级上下文提示，用于CT图像质量评估，在LDCTIQA挑战基准上超越现有最佳方法4.24%。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法在CT图像质量评估中应用有限，且通常引入理想化定义带来的偏差，无法适应真实世界中的噪声、运动伪影和扫描仪变异等退化情况。

Method: 提出CAP-IQA框架，结合CNN视觉编码器和领域特定文本编码器，集成文本级先验与实例级上下文提示，应用因果去偏技术分离理想化知识与实际图像退化特征，使用放射学风格提示和上下文感知融合对齐语义和感知表示。

Result: 在2023年LDCTIQA挑战基准上获得2.8590的总相关分数（PLCC、SROCC和KROCC之和），超越排行榜最佳团队4.24%；在包含91,514张儿科CT图像的内部数据集上验证了方法的泛化能力。

Conclusion: CAP-IQA框架通过提示引导融合和简化编码器设计有效提升了特征对齐和可解释性，在CT图像质量评估中展现出优越性能和泛化能力。

Abstract: Prompt-based methods, which encode medical priors through descriptive text, have been only minimally explored for CT Image Quality Assessment (IQA). While such prompts can embed prior knowledge about diagnostic quality, they often introduce bias by reflecting idealized definitions that may not hold under real-world degradations such as noise, motion artifacts, or scanner variability. To address this, we propose the Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA) framework, which integrates text-level priors with instance-level context prompts and applies causal debiasing to separate idealized knowledge from factual, image-specific degradations. Our framework combines a CNN-based visual encoder with a domain-specific text encoder to assess diagnostic visibility, anatomical clarity, and noise perception in abdominal CT images. The model leverages radiology-style prompts and context-aware fusion to align semantic and perceptual representations. On the 2023 LDCTIQA challenge benchmark, CAP-IQA achieves an overall correlation score of 2.8590 (sum of PLCC, SROCC, and KROCC), surpassing the top-ranked leaderboard team (2.7427) by 4.24%. Moreover, our comprehensive ablation experiments confirm that prompt-guided fusion and the simplified encoder-only design jointly enhance feature alignment and interpretability. Furthermore, evaluation on an in-house dataset of 91,514 pediatric CT images demonstrates the true generalizability of CAP-IQA in assessing perceptual fidelity in a different patient population.

</details>


### [60] [An Empirical Study of Monocular Human Body Measurement Under Weak Calibration](https://arxiv.org/abs/2601.01639)
*Gaurav Sekar*

Main category: cs.CV

TL;DR: 该研究系统评估了三种弱标定单目RGB图像人体测量方法，分析不同标定假设对测量行为、鲁棒性和失败模式的影响，为消费设备上的轻量级人体测量系统提供实证设计参考。


<details>
  <summary>Details</summary>
Motivation: 从单目RGB图像估计人体尺寸面临尺度模糊、视角敏感和缺乏深度信息等挑战，需要研究不同弱标定策略在实际应用中的表现和权衡。

Method: 系统实证研究三种弱标定单目策略：基于地标的几何方法、姿态驱动的回归方法、物体标定的轮廓方法，在消费级相机半约束条件下评估，重点分析不同标定假设的影响。

Result: 研究发现标定过程中的用户努力程度与所得周长测量稳定性之间存在明显权衡关系，揭示了不同方法在不同体型上的测量行为、鲁棒性和失败模式。

Conclusion: 该研究为消费设备部署的轻量级单目人体测量系统提供了实证设计参考，强调理解不同标定假设对测量性能的影响比追求最高精度更为重要。

Abstract: Estimating human body measurements from monocular RGB imagery remains challenging due to scale ambiguity, viewpoint sensitivity, and the absence of explicit depth information. This work presents a systematic empirical study of three weakly calibrated monocular strategies: landmark-based geometry, pose-driven regression, and object-calibrated silhouettes, evaluated under semi-constrained conditions using consumer-grade cameras. Rather than pursuing state-of-the-art accuracy, the study analyzes how differing calibration assumptions influence measurement behavior, robustness, and failure modes across varied body types. The results reveal a clear trade-off between user effort during calibration and the stability of resulting circumferential quantities. This paper serves as an empirical design reference for lightweight monocular human measurement systems intended for deployment on consumer devices.

</details>


### [61] [LabelAny3D: Label Any Object 3D in the Wild](https://arxiv.org/abs/2601.01676)
*Jin Yao,Radowan Mahmud Redoy,Sebastian Elbaum,Matthew B. Dwyer,Zezhou Cheng*

Main category: cs.CV

TL;DR: LabelAny3D是一个通过分析合成框架从2D图像重建完整3D场景以生成高质量3D边界框标注的系统，基于此构建了COCO3D基准，用于开放词汇单目3D检测，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测模型在真实世界图像中表现不佳，主要原因是缺乏3D真实世界数据集和3D标注的挑战性。需要一种能够高效生成高质量3D标注的方法来扩展3D识别在开放世界环境中的应用。

Method: 提出了LabelAny3D分析合成框架，从2D图像重建完整3D场景，以此高效生成高质量3D边界框标注。基于此管道构建了COCO3D基准，该基准源自MS-COCO数据集，覆盖了现有3D数据集中缺失的广泛对象类别。

Result: LabelAny3D生成的标注在多个基准测试中提升了单目3D检测性能，在质量上优于先前的自动标注方法。COCO3D基准为开放词汇单目3D检测提供了新的评估标准。

Conclusion: 结果表明基础模型驱动的标注方法在扩展真实开放世界环境中的3D识别方面具有巨大潜力，为解决3D标注稀缺问题提供了有效解决方案。

Abstract: Detecting objects in 3D space from monocular input is crucial for applications ranging from robotics to scene understanding. Despite advanced performance in the indoor and autonomous driving domains, existing monocular 3D detection models struggle with in-the-wild images due to the lack of 3D in-the-wild datasets and the challenges of 3D annotation. We introduce LabelAny3D, an \emph{analysis-by-synthesis} framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations. Built on this pipeline, we present COCO3D, a new benchmark for open-vocabulary monocular 3D detection, derived from the MS-COCO dataset and covering a wide range of object categories absent from existing 3D datasets. Experiments show that annotations generated by LabelAny3D improve monocular 3D detection performance across multiple benchmarks, outperforming prior auto-labeling approaches in quality. These results demonstrate the promise of foundation-model-driven annotation for scaling up 3D recognition in realistic, open-world settings.

</details>


### [62] [Trustworthy Data-Driven Wildfire Risk Prediction and Understanding in Western Canada](https://arxiv.org/abs/2601.01677)
*Zhengsen Xu,Lanying Wang,Sibo Cheng,Xue Rui,Kyle Gao,Yimin Zhu,Mabel Heffring,Zack Dewis,Saeid Taleghanidoozdoozan,Megan Greenwood,Motasem Alkayid,Quinn Ledingham,Hongjie He,Jonathan Li,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 提出基于长序列多尺度时序建模的可信野火风险预测框架，在加拿大西部2023-2024年野火季表现优异，F1分数0.90，PR-AUC 0.98，同时量化预测不确定性并提供过程级解释。


<details>
  <summary>Details</summary>
Motivation: 加拿大西部野火活动加剧导致重大社会经济和环境损失，但野火风险预测面临点火和蔓延的随机性、燃料条件、气象、气候变率、地形和人类活动等多因素非线性相互作用的挑战，纯数据驱动模型在可靠性和可解释性方面存在局限。

Method: 提出可信数据驱动野火风险预测框架，基于长序列多尺度时序建模，整合异质驱动因素，同时显式量化预测不确定性并支持过程级解释。使用SHAP方法进行机制解释。

Result: 在加拿大西部2023和2024年创纪录野火季评估中，模型优于现有时间序列方法，F1分数0.90，PR-AUC 0.98，计算成本低。不确定性分析显示预测置信度的结构化空间和季节模式，SHAP解释揭示温度相关驱动因素在两年均主导野火风险，而2024年湿度相关约束在塑造空间和土地覆盖特定对比方面作用更强。

Conclusion: 提出的可信野火风险预测框架在准确预测野火风险的同时，提供了不确定性量化和机制解释能力，有助于理解野火控制因素，为野火管理决策提供更可靠的依据。

Abstract: In recent decades, the intensification of wildfire activity in western Canada has resulted in substantial socio-economic and environmental losses. Accurate wildfire risk prediction is hindered by the intrinsic stochasticity of ignition and spread and by nonlinear interactions among fuel conditions, meteorology, climate variability, topography, and human activities, challenging the reliability and interpretability of purely data-driven models. We propose a trustworthy data-driven wildfire risk prediction framework based on long-sequence, multi-scale temporal modeling, which integrates heterogeneous drivers while explicitly quantifying predictive uncertainty and enabling process-level interpretation. Evaluated over western Canada during the record-breaking 2023 and 2024 fire seasons, the proposed model outperforms existing time-series approaches, achieving an F1 score of 0.90 and a PR-AUC of 0.98 with low computational cost. Uncertainty-aware analysis reveals structured spatial and seasonal patterns in predictive confidence, highlighting increased uncertainty associated with ambiguous predictions and spatiotemporal decision boundaries. SHAP-based interpretation provides mechanistic understanding of wildfire controls, showing that temperature-related drivers dominate wildfire risk in both years, while moisture-related constraints play a stronger role in shaping spatial and land-cover-specific contrasts in 2024 compared to the widespread hot and dry conditions of 2023. Data and code are available at https://github.com/SynUW/mmFire.

</details>


### [63] [FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation](https://arxiv.org/abs/2601.01687)
*Abdur R. Fayjie,Pankhi Kashyap,Jutika Borah,Patrick Vandewalle*

Main category: cs.CV

TL;DR: FALCON是一个跨域少样本分割框架，通过将3D医学体积数据作为2D切片处理，实现高精度分割，显著减少标注数据需求、计算开销，同时保持边界精度


<details>
  <summary>Details</summary>
Motivation: 3D医学体积中解剖和病理结构的精确分割对诊断、手术规划和疾病监测至关重要，但现有AI方法面临3D标注稀缺、患者特异性变异、数据隐私和计算开销大等挑战

Method: 提出FALCON框架：先在自然图像上进行元训练学习通用分割先验，然后通过对抗性微调和边界感知学习迁移到医学领域，任务感知推理根据支持线索动态适应患者特异性变异

Result: 在四个基准测试中，FALCON始终获得最低的Hausdorff距离分数（表明边界精度优越），同时保持与最先进模型相当的Dice相似系数，且使用更少标注数据、无数据增强、计算开销显著降低

Conclusion: FALCON通过跨域少样本学习和2D切片处理，有效解决了3D医学分割中的标注稀缺、计算开销和患者变异问题，实现了临床可行的精确分割

Abstract: Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.

</details>


### [64] [Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data](https://arxiv.org/abs/2601.01689)
*Afzal Hossain,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 研究探索合成人脸数据能否作为纵向稳定器，改善儿童人脸识别模型的时间鲁棒性。通过实验发现，使用合成数据增强的微调能显著降低错误率。


<details>
  <summary>Details</summary>
Motivation: 儿童面部识别面临挑战，因为面部快速非线性生长导致模板漂移和随时间增加的验证错误。需要寻找方法提高儿童人脸识别模型的时间鲁棒性。

Method: 在YFA数据集上采用身份分离协议，评估三种设置：1) 预训练MagFace嵌入；2) 仅使用真实训练人脸微调MagFace；3) 使用真实和合成生成训练人脸组合微调MagFace。使用StyleGAN2 ADA生成合成数据，并应用后生成过滤步骤减轻身份泄漏和去除伪影样本。

Result: 在6到36个月的注册验证间隔实验中，合成增强的微调相对于预训练基线和仅使用真实数据的微调，显著降低了错误率。

Conclusion: 合成数据增强能够有效提高儿童人脸识别中的身份持久性，为改善儿科人脸识别提供了风险感知的评估方法。

Abstract: Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition.

</details>


### [65] [Learnability-Driven Submodular Optimization for Active Roadside 3D Detection](https://arxiv.org/abs/2601.01695)
*Ruiyu Mao,Baoming Zhang,Nicholas Ruozzi,Yunhui Guo*

Main category: cs.CV

TL;DR: 提出LH3D框架，通过主动学习选择既信息丰富又可可靠标注的路边单目3D检测场景，抑制固有模糊样本，在仅使用25%标注预算下达到接近全性能表现。


<details>
  <summary>Details</summary>
Motivation: 实际部署中通常只能标注纯路边数据（无车辆端数据），但许多路边场景存在距离远、模糊或被遮挡的物体，其3D属性从单视角看具有固有模糊性，只能通过车辆-路边配对帧交叉验证才能可靠标注。这些固有模糊样本增加了标注难度和成本，揭示了根本的可学习性问题。

Method: 提出LH3D框架，专注于路边单目3D目标检测的主动学习。该方法选择既信息丰富又可可靠标注的场景，抑制固有模糊样本同时确保覆盖范围。通过可学习性驱动的样本选择策略，而非传统的不确定性方法。

Result: 在DAIR-V2X-I数据集上，仅使用25%的标注预算，LH3D方法对车辆、行人和骑行者分别达到全性能的86.06%、67.32%和78.67%，显著优于基于不确定性的基线方法。

Conclusion: 实验证实对于路边3D感知任务，可学习性而非不确定性才是关键因素。LH3D框架能有效减少固有模糊样本的标注浪费，同时获得高性能模型。

Abstract: Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate labels without vehicle-side data (image, LIDAR), which not only increases annotation difficulty and cost, but also reveals a fundamental learnability problem: many roadside-only scenes contain distant, blurred, or occluded objects whose 3D properties are ambiguous from a single view and can only be reliably annotated by cross-checking paired vehicle--roadside frames. We refer to such cases as inherently ambiguous samples. To reduce wasted annotation effort on inherently ambiguous samples while still obtaining high-performing models, we turn to active learning. This work focuses on active learning for roadside monocular 3D object detection and proposes a learnability-driven framework that selects scenes which are both informative and reliably labelable, suppressing inherently ambiguous samples while ensuring coverage. Experiments demonstrate that our method, LH3D, achieves 86.06%, 67.32%, and 78.67% of full-performance for vehicles, pedestrians, and cyclists respectively, using only 25% of the annotation budget on DAIR-V2X-I, significantly outperforming uncertainty-based baselines. This confirms that learnability, not uncertainty, matters for roadside 3D perception.

</details>


### [66] [Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems](https://arxiv.org/abs/2601.01696)
*Yian Liu,Xiong Wang,Ping Xu,Lei Zhu,Ming Yan,Linyun Xue*

Main category: cs.CV

TL;DR: 本文提出了一种用于嵌入式系统实时车道线检测的协方差分布优化（CDO）模块，该模块能提升检测精度而不增加计算复杂度，易于集成到现有系统中。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统中的实时车道线检测面临重大挑战：RGB图像中的视觉信号稀疏且微妙，同时受限于计算资源和功耗。尽管存在分割、锚点和曲线三种基于深度学习的车道检测方法，但缺乏专门为低功耗嵌入式环境设计的通用优化技术。

Method: 提出了创新的协方差分布优化（CDO）模块，专门为高效实时应用设计。该模块通过使车道特征分布与真实标签对齐来提升检测精度，不增加计算复杂度，且易于集成到现有系统而无需结构修改。

Result: 在三个主要数据集（CULane、TuSimple、LLAMAS）上对六种不同模型（涵盖所有三种方法类别，包括两种实时优化模型和四种SOTA模型）进行评估。实验结果显示精度提升范围在0.01%到1.5%之间。

Conclusion: CDO模块在嵌入式系统中提供了显著的性能、能效和操作灵活性优势，能够在不增加计算复杂度的情况下提升车道检测精度，且易于集成到现有系统中。

Abstract: Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.

</details>


### [67] [FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing](https://arxiv.org/abs/2601.01720)
*Xijie Huang,Chengming Xu,Donghao Luo,Xiaobin Hu,Peng Tang,Xu Peng,Jiangning Zhang,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: 提出FFP-300K大规模高质量视频数据集和新型无引导FFP框架，通过AST-RoPE位置编码和自蒸馏策略解决外观保持与运动保留的冲突，在EditVerseBench上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有FFP方法依赖繁琐的运行时引导，根本原因在于训练数据集不足：视频过短、分辨率低、任务多样性不够，无法学习鲁棒的时间先验。

Method: 1) 构建FFP-300K数据集：30万对720p分辨率、81帧的高保真视频对，采用双轨管道支持多样局部和全局编辑；2) 提出无引导FFP框架：引入AST-RoPE动态重映射位置编码以解耦外观和运动参考；3) 采用自蒸馏策略：身份传播任务作为正则化器确保长期时间稳定性和防止语义漂移。

Result: 在EditVerseBench基准测试中，方法显著优于现有学术和商业模型，获得约0.2 PickScore和0.3 VLM分数的提升。

Conclusion: 通过构建大规模高质量数据集和提出创新的无引导FFP框架，成功解决了FFP中外观保持与运动保留的关键矛盾，实现了更稳定、更高质量的可控视频编辑。

Abstract: First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.

</details>


### [68] [Point-SRA: Self-Representation Alignment for 3D Representation Learning](https://arxiv.org/abs/2601.01746)
*Lintong Wei,Jian Lu,Haozhe Cheng,Jihua Zhu,Kaibing Zhang*

Main category: cs.CV

TL;DR: Point-SRA是一种通过自蒸馏和概率建模对齐表示的3D表示学习方法，改进了传统MAE的固定掩码比率和点级重建假设，在多模态表示对齐和概率重建方面有创新。


<details>
  <summary>Details</summary>
Motivation: 现有MAE方法存在三个主要问题：1）固定掩码比率忽视了多级表示相关性；2）点级重建假设与点云多样性冲突；3）未能充分利用几何结构信息。需要一种能捕捉互补几何语义信息并支持多样化概率重建的方法。

Method: 1）使用不同掩码比率的MAE捕捉互补信息；2）MeanFlow Transformer利用跨模态条件嵌入实现多样化概率重建；3）在MAE和MFT两个层次提出双自表示对齐机制；4）设计流条件微调架构充分利用学习到的点云分布。

Result: 1）在ScanObjectNN上比Point-MAE提升5.37%；2）颅内动脉瘤分割中动脉达到96.07%平均IoU，动脉瘤达到86.87%；3）3D目标检测达到47.3% AP@50，比MaskPoint提升5.12%。

Conclusion: Point-SRA通过多级表示对齐和概率建模有效解决了传统MAE方法的局限性，在多个3D视觉任务上实现了显著的性能提升，证明了其在捕捉几何语义信息和处理点云多样性方面的优势。

Abstract: Masked autoencoders (MAE) have become a dominant paradigm in 3D representation learning, setting new performance benchmarks across various downstream tasks. Existing methods with fixed mask ratio neglect multi-level representational correlations and intrinsic geometric structures, while relying on point-wise reconstruction assumptions that conflict with the diversity of point cloud. To address these issues, we propose a 3D representation learning method, termed Point-SRA, which aligns representations through self-distillation and probabilistic modeling. Specifically, we assign different masking ratios to the MAE to capture complementary geometric and semantic information, while the MeanFlow Transformer (MFT) leverages cross-modal conditional embeddings to enable diverse probabilistic reconstruction. Our analysis further reveals that representations at different time steps in MFT also exhibit complementarity. Therefore, a Dual Self-Representation Alignment mechanism is proposed at both the MAE and MFT levels. Finally, we design a Flow-Conditioned Fine-Tuning Architecture to fully exploit the point cloud distribution learned via MeanFlow. Point-SRA outperforms Point-MAE by 5.37% on ScanObjectNN. On intracranial aneurysm segmentation, it reaches 96.07% mean IoU for arteries and 86.87% for aneurysms. For 3D object detection, Point-SRA achieves 47.3% AP@50, surpassing MaskPoint by 5.12%.

</details>


### [69] [MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement](https://arxiv.org/abs/2601.01749)
*Lei Zhu,Lijian Lin,Ye Zhu,Jiahao Wu,Xuehan Hou,Yu Li,Yunfei Liu,Jie Chen*

Main category: cs.CV

TL;DR: MANGO是一个两阶段框架，通过纯图像级监督实现高质量的双人3D对话头像生成，解决了现有方法在自然听-说交互和精细面部动态捕捉方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动的3D头部生成方法主要关注单说话人场景，缺乏自然的双向听-说交互。现有3D对话头像方法依赖容易出错的伪3D标签，无法捕捉精细的面部动态，实现流畅的对话行为转换仍是一个关键挑战。

Method: 提出两阶段框架MANGO：第一阶段使用基于扩散的transformer和双音频交互模块从多说话人音频中建模自然3D运动；第二阶段使用快速3D高斯渲染器生成高保真图像，通过交替训练为3D运动提供2D级光度监督。同时引入了MANGO-Dialog数据集，包含500+身份超过50小时的对齐2D-3D对话数据。

Result: 大量实验表明，该方法在建模双人3D对话运动方面实现了卓越的准确性和真实感，显著提升了音频驱动说话头像的保真度和可控性。

Conclusion: MANGO框架通过纯图像级监督和交替训练策略，有效解决了伪3D标签引入的噪声问题，实现了与真实世界对话行为更好的对齐，推动了3D对话头像技术的发展。

Abstract: Current audio-driven 3D head generation methods mainly focus on single-speaker scenarios, lacking natural, bidirectional listen-and-speak interaction. Achieving seamless conversational behavior, where speaking and listening states transition fluidly remains a key challenge. Existing 3D conversational avatar approaches rely on error-prone pseudo-3D labels that fail to capture fine-grained facial dynamics. To address these limitations, we introduce a novel two-stage framework MANGO, which leveraging pure image-level supervision by alternately training to mitigate the noise introduced by pseudo-3D labels, thereby achieving better alignment with real-world conversational behaviors. Specifically, in the first stage, a diffusion-based transformer with a dual-audio interaction module models natural 3D motion from multi-speaker audio. In the second stage, we use a fast 3D Gaussian Renderer to generate high-fidelity images and provide 2D-level photometric supervision for the 3D motions through alternate training. Additionally, we introduce MANGO-Dialog, a high-quality dataset with over 50 hours of aligned 2D-3D conversational data across 500+ identities. Extensive experiments demonstrate that our method achieves exceptional accuracy and realism in modeling two-person 3D dialogue motion, significantly advancing the fidelity and controllability of audio-driven talking heads.

</details>


### [70] [CTIS-QA: Clinical Template-Informed Slide-level Question Answering for Pathology](https://arxiv.org/abs/2601.01769)
*Hao Lu,Ziniu Qian,Yifu Li,Yang Zhou,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 该论文提出基于临床诊断模板的病理信息结构化收集流程，构建了CTIS-Align数据集和CTIS-Bench基准，并开发了CTIS-QA模型用于病理切片问答任务。


<details>
  <summary>Details</summary>
Motivation: 病理报告信息分散且非结构化，需要系统化的方法来提取和标准化病理特征，以支持基于病理切片的视觉语言对齐和问答任务。

Method: 1. 设计临床病理报告模板(CPRT)标准化提取病理特征；2. 构建CTIS-Align数据集(8万切片-描述对)用于视觉语言对齐；3. 创建CTIS-Bench基准(977张WSI，14,879个QA对)；4. 提出CTIS-QA双流架构模型，结合全局上下文和局部区域关注。

Result: 在TCGA-BRCA数据集上验证了流程有效性。CTIS-QA在WSI-VQA、CTIS-Bench和切片级诊断任务上均优于现有最先进模型，在多个指标上表现一致优越。

Conclusion: 提出的临床诊断模板流程能有效结构化病理信息，CTIS-QA模型通过模拟病理学家诊断方法，在病理切片问答任务中表现出色，为临床病理分析提供了实用工具。

Abstract: In this paper, we introduce a clinical diagnosis template-based pipeline to systematically collect and structure pathological information. In collaboration with pathologists and guided by the the College of American Pathologists (CAP) Cancer Protocols, we design a Clinical Pathology Report Template (CPRT) that ensures comprehensive and standardized extraction of diagnostic elements from pathology reports. We validate the effectiveness of our pipeline on TCGA-BRCA. First, we extract pathological features from reports using CPRT. These features are then used to build CTIS-Align, a dataset of 80k slide-description pairs from 804 WSIs for vision-language alignment training, and CTIS-Bench, a rigorously curated VQA benchmark comprising 977 WSIs and 14,879 question-answer pairs. CTIS-Bench emphasizes clinically grounded, closed-ended questions (e.g., tumor grade, receptor status) that reflect real diagnostic workflows, minimize non-visual reasoning, and require genuine slide understanding. We further propose CTIS-QA, a Slide-level Question Answering model, featuring a dual-stream architecture that mimics pathologists' diagnostic approach. One stream captures global slide-level context via clustering-based feature aggregation, while the other focuses on salient local regions through attention-guided patch perception module. Extensive experiments on WSI-VQA, CTIS-Bench, and slide-level diagnostic tasks show that CTIS-QA consistently outperforms existing state-of-the-art models across multiple metrics. Code and data are available at https://github.com/HLSvois/CTIS-QA.

</details>


### [71] [Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery](https://arxiv.org/abs/2601.01781)
*Lakshay Sharma,Alex Marin*

Main category: cs.CV

TL;DR: 提出一种用于遥感图像语义分割的自监督预训练方法——子图像重叠预测，该方法使用较少的预训练数据，通过预测子图像在原图中的位置来学习特征，显著加快收敛速度并提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前自监督学习方法通常需要大量预训练数据，但在遥感图像领域获取大量标注数据成本高昂。本文旨在开发一种需要较少预训练数据的自监督方法，专门针对遥感图像语义分割任务。

Method: 提出子图像重叠预测任务：从原始图像中提取一个子图像，训练模型预测该子图像在原始图像中的位置语义掩码。这种方法迫使模型学习图像的空间结构和语义信息。

Result: 该方法显著加快了下游分割任务的收敛速度，在多个架构和数据集上实现了同等或更好的mIoU性能。当标注训练数据减少时，性能优势更加明显，且相比其他自监督方法需要更少的预训练数据。

Conclusion: 子图像重叠预测是一种有效的自监督预训练方法，特别适用于遥感图像语义分割，能够在减少预训练数据需求的同时提升模型性能和收敛速度。

Abstract: Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.

</details>


### [72] [DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization](https://arxiv.org/abs/2601.01784)
*Boyang Zhao,Xin Liao,Jiaxin Chen,Xiaoshuai Wu,Yufeng Wu*

Main category: cs.CV

TL;DR: DDNet：基于双流图学习和解缠的时序伪造定位框架，通过协调局部伪影和语义内容流，结合轨迹解缠和跨级特征嵌入，显著提升视频伪造片段定位精度和跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: AIGC技术快速发展使得仅篡改视频小片段就能误导观众，而视频级检测不准确且缺乏说服力。现有方法受限于局部视角，无法捕捉全局异常，因此需要更精确的时序伪造定位方法。

Method: 提出DDNet双流图学习框架：1) 时间距离流捕捉局部伪影；2) 语义内容流建立长程连接。引入轨迹解缠与适应(TDA)分离通用伪造指纹，以及跨级特征嵌入(CLFE)通过层次特征深度融合构建鲁棒特征基础。

Result: 在ForgeryNet和TVIL基准测试中，DDNet在AP@0.95指标上比现有最佳方法提升约9%，在跨域鲁棒性方面也有显著改进。

Conclusion: DDNet通过双流协调机制有效解决了局部平滑淹没全局线索的问题，结合解缠技术和特征融合策略，实现了更精确的时序伪造定位和更强的跨域适应性。

Abstract: The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \emph{local view}, failing to capture global anomalies. To address this, we propose a \underline{d}ual-stream graph learning and \underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \emph{Temporal Distance Stream} for local artifacts and a \emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\% in AP@0.95, with significant improvements in cross-domain robustness.

</details>


### [73] [VerLM: Explaining Face Verification Using Natural Language](https://arxiv.org/abs/2601.01798)
*Syed Abdul Hannan,Hazim Bukhari,Thomas Cantalapiedra,Eman Ansar,Massa Baali,Rita Singh,Bhiksha Raj*

Main category: cs.CV

TL;DR: 提出一种创新的视觉语言模型用于人脸验证，不仅能准确判断两张人脸图像是否为同一人，还能明确解释决策依据，使用两种互补的解释风格进行训练。


<details>
  <summary>Details</summary>
Motivation: 当前人脸验证系统虽然取得了显著进展，但通常缺乏决策过程的透明度，用户无法理解系统做出判断的具体原因。

Method: 采用创新的视觉语言模型，训练时使用两种互补的解释风格：简洁总结关键因素和详细描述图像间具体差异。将原本为音频区分设计的先进建模方法适应并增强以有效处理视觉输入。

Result: 提出的VLM表现出优越性能，超越了基线方法和现有模型，跨模态迁移显著提高了模型的准确性和可解释性。

Conclusion: 该研究展示了视觉语言模型在人脸验证领域的巨大潜力，有助于构建更透明、可靠和可解释的人脸验证系统。

Abstract: Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.

</details>


### [74] [Causality-Aware Temporal Projection for Video Understanding in Video-LLMs](https://arxiv.org/abs/2601.01804)
*Zhengjian Kang,Qi Chen,Rui Liu,Kangtong Mo,Xingyu Zhang,Xiaoyu Deng,Ye Zhang*

Main category: cs.CV

TL;DR: V-CORE是一个参数高效的视频大语言模型框架，通过引入显式时间顺序约束来解决现有模型在时间排序和因果一致性方面的不足，使用可学习空间聚合和因果感知时间投影器来确保单向信息流。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在需要一致时间排序和因果连贯性的视频理解任务中存在挑战，许多参数高效模型使用无约束的双向投影器来建模帧间交互，这会模糊时间顺序，因为允许后续帧影响先前表示，缺乏尊重视频推理方向性的显式架构机制。

Method: V-CORE包含两个关键组件：1) 可学习空间聚合(LSA)，自适应选择显著空间标记以减少冗余；2) 因果感知时间投影器(CATP)，通过块因果注意力和作为因果汇的终端动态摘要标记来强制执行结构化单向信息流，在保持帧内空间交互的同时确保时间信息按严格顺序聚合。

Result: V-CORE在具有挑战性的NExT-QA基准测试中达到61.2%的准确率，在MSVD-QA、MSRVTT-QA和TGIF-QA上保持竞争力，在时间和因果推理子类别上分别获得+3.5%和+5.2%的增益，直接验证了显式时间顺序约束的重要性。

Conclusion: V-CORE通过引入显式时间顺序约束，有效解决了视频理解中时间排序和因果一致性的关键问题，证明了在参数高效视频大语言模型中尊重视频推理方向性的重要性。

Abstract: Recent Video Large Language Models (Video-LLMs) have shown strong multimodal reasoning capabilities, yet remain challenged by video understanding tasks that require consistent temporal ordering and causal coherence. Many parameter-efficient Video-LLMs rely on unconstrained bidirectional projectors to model inter-frame interactions, which can blur temporal ordering by allowing later frames to influence earlier representations, without explicit architectural mechanisms to respect the directional nature of video reasoning. To address this limitation, we propose V-CORE, a parameter-efficient framework that introduces explicit temporal ordering constraints for video understanding. V-CORE consists of two key components: (1) Learnable Spatial Aggregation (LSA), which adaptively selects salient spatial tokens to reduce redundancy, and (2) a Causality-Aware Temporal Projector (CATP), which enforces structured unidirectional information flow via block-causal attention and a terminal dynamic summary token acting as a causal sink. This design preserves intra-frame spatial interactions while ensuring that temporal information is aggregated in a strictly ordered manner. With 4-bit QLoRA and a frozen LLM backbone, V-CORE can be trained efficiently on a single consumer GPU. Experiments show that V-CORE achieves strong performance on the challenging NExT-QA benchmark, reaching 61.2% accuracy, and remains competitive across MSVD-QA, MSRVTT-QA, and TGIF-QA, with gains concentrated in temporal and causal reasoning subcategories (+3.5% and +5.2% respectively), directly validating the importance of explicit temporal ordering constraints.

</details>


### [75] [Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification](https://arxiv.org/abs/2601.01807)
*Ubaidullah,Muhammad Abid Hussain,Mohsin Raza Jafri,Rozi Khan,Moid Sandhu,Abd Ullah Khan,Hyundong Shin*

Main category: cs.CV

TL;DR: LUMPNet是一种基于混合深度学习的牛结节性皮肤病早期检测方法，使用YOLOv11检测皮肤结节，EfficientNet分类，结合新型自适应混合优化器，在公开数据集上达到99%训练准确率和98%验证准确率。


<details>
  <summary>Details</summary>
Motivation: 牛结节性皮肤病（LSD）是一种传染性病毒性疾病，严重威胁畜牧业健康和全球粮食安全。由于其快速传播特性，早期精确识别对于预防疫情爆发和确保及时干预至关重要。

Method: 提出LUMPNet混合深度学习框架：1）使用YOLOv11检测和定位牛图像中的皮肤结节和病变；2）利用基于EfficientNet的CNN分类器对定位后的图像进行分类（LSD感染或健康）；3）提出并采用新型自适应混合优化器来稳定和加速YOLOv11与EfficientNet混合模型的训练。

Result: 在公开数据集上评估，LUMPNet达到99%的LSD检测训练准确率和98%的验证准确率，优于现有方案。通过案例研究比较优化后的EfficientNet-B0模型与AdamW优化器，LUMPNet表现出更优越的性能。

Conclusion: LUMPNet为牛结节性皮肤病的早期检测提供了一种有效的混合深度学习方法，能够准确检测和分类皮肤结节，有助于及时干预和疫情控制。

Abstract: Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.

</details>


### [76] [Robust Egocentric Visual Attention Prediction Through Language-guided Scene Context-aware Learning](https://arxiv.org/abs/2601.01818)
*Sungjune Park,Hongda Mao,Qingshuang Chen,Yong Man Ro,Yelin Kim*

Main category: cs.CV

TL;DR: 该论文提出了一个语言引导的场景上下文感知学习框架，用于提升第一人称视觉注意力预测的鲁棒性，通过语言描述引导的上下文感知和注意力聚焦机制，在两个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 随着第一人称视频分析需求的增长，预测摄像机佩戴者的注意力区域变得越来越重要。但由于第一人称场景的动态性和复杂性，这一任务仍然具有挑战性。研究表明场景上下文信息在调节人类注意力方面起着关键作用，因此需要开发能够有效利用场景上下文的方法。

Method: 提出了一个语言引导的场景上下文感知学习框架：1）设计了一个上下文感知器，通过基于语言的场景描述来总结第一人称视频，生成上下文感知的视频表示；2）引入了两个训练目标：鼓励框架聚焦于目标兴趣区域，同时抑制不太可能吸引第一人称注意力的无关区域的干扰。

Result: 在Ego4D和Aria Everyday Activities (AEA)数据集上进行了广泛实验，证明了该方法的有效性，实现了最先进的性能，并在多样化、动态的第一人称场景中表现出增强的鲁棒性。

Conclusion: 该研究提出的语言引导场景上下文感知学习框架能够有效提升第一人称视觉注意力预测的准确性和鲁棒性，通过结合语言描述和上下文信息，更好地模拟人类在复杂动态场景中的注意力机制。

Abstract: As the demand for analyzing egocentric videos grows, egocentric visual attention prediction, anticipating where a camera wearer will attend, has garnered increasing attention. However, it remains challenging due to the inherent complexity and ambiguity of dynamic egocentric scenes. Motivated by evidence that scene contextual information plays a crucial role in modulating human attention, in this paper, we present a language-guided scene context-aware learning framework for robust egocentric visual attention prediction. We first design a context perceiver which is guided to summarize the egocentric video based on a language-based scene description, generating context-aware video representations. We then introduce two training objectives that: 1) encourage the framework to focus on the target point-of-interest regions and 2) suppress distractions from irrelevant regions which are less likely to attract first-person attention. Extensive experiments on Ego4D and Aria Everyday Activities (AEA) datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance and enhanced robustness across diverse, dynamic egocentric scenarios.

</details>


### [77] [RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images](https://arxiv.org/abs/2601.01835)
*Rashid Iqbal,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 提出了一种名为RSwinV2的深度学习模型，用于Mpox（猴痘）诊断，通过定制化的残差SwinTransformerV2架构增强皮肤病变分类能力，在Kaggle数据集上达到96.21%准确率和95.62% F1分数。


<details>
  <summary>Details</summary>
Motivation: 需要开发更有效的计算机辅助工具来准确诊断Mpox（猴痘）皮肤病变，特别是要区分Mpox与其他类似疾病如水痘、麻疹和牛痘，以应对诊断挑战并提高分类准确性。

Method: 提出定制化的RSwinV2方法：1）基于输入维度、嵌入结构和输出目标定制分层Transformer结构；2）将输入图像分割成非重叠块，使用移位窗口和注意力机制处理；3）包含补丁和位置嵌入以利用Transformer的全局链接能力；4）引入逆残差块（IRB）解决梯度消失问题，结合卷积跳跃连接；5）通过全局和局部模式链接提高病变分类能力。

Result: 在Kaggle公共数据集上，RSwinV2达到96.21%的准确率和95.62%的F1分数，优于标准CNN模型和SwinTransformers，证明其作为Mpox病变观察解释的计算机辅助工具的有效性。

Conclusion: RSwinV2通过结合Transformer的全局链接能力和IRB的局部模式处理，成功提高了Mpox病变分类的准确性，能够有效区分Mpox、水痘、麻疹和牛痘，为Mpox诊断提供了有效的计算机辅助工具。

Abstract: In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.

</details>


### [78] [ESGaussianFace: Emotional and Stylized Audio-Driven Facial Animation via 3D Gaussian Splatting](https://arxiv.org/abs/2601.01847)
*Chuhang Ma,Shuai Tan,Ye Pan,Jiaolong Yang,Xin Tong*

Main category: cs.CV

TL;DR: ESGaussianFace：基于3D高斯泼溅的情感化风格化音频驱动面部动画框架，通过情感音频引导的空间注意力机制和3D高斯变形预测器，实现高效高质量的情感风格化面部视频生成。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动面部动画研究主要关注中性情感视频生成，虽然已有研究处理情感音频驱动，但如何高效生成同时包含情感表达和风格特征的高质量说话头部视频仍是一个重大挑战。

Method: 1. 使用3D高斯泼溅技术重建3D场景并渲染视频；2. 提出情感音频引导的空间注意力方法，有效整合情感特征与音频内容特征；3. 引入两个3D高斯变形预测器实现情感和风格化变形；4. 采用多阶段训练策略，逐步学习嘴唇运动、情感变化和风格特征。

Result: 生成结果具有高效率、高质量和3D一致性。大量实验结果表明，该方法在嘴唇运动准确性、表情变化和风格特征表现力方面优于现有最先进技术。

Conclusion: ESGaussianFace框架成功解决了情感化风格化音频驱动面部动画的挑战，通过创新的3D高斯泼溅技术和多阶段训练策略，实现了高效高质量的情感风格化面部视频生成。

Abstract: Most current audio-driven facial animation research primarily focuses on generating videos with neutral emotions. While some studies have addressed the generation of facial videos driven by emotional audio, efficiently generating high-quality talking head videos that integrate both emotional expressions and style features remains a significant challenge. In this paper, we propose ESGaussianFace, an innovative framework for emotional and stylized audio-driven facial animation. Our approach leverages 3D Gaussian Splatting to reconstruct 3D scenes and render videos, ensuring efficient generation of 3D consistent results. We propose an emotion-audio-guided spatial attention method that effectively integrates emotion features with audio content features. Through emotion-guided attention, the model is able to reconstruct facial details across different emotional states more accurately. To achieve emotional and stylized deformations of the 3D Gaussian points through emotion and style features, we introduce two 3D Gaussian deformation predictors. Futhermore, we propose a multi-stage training strategy, enabling the step-by-step learning of the character's lip movements, emotional variations, and style features. Our generated results exhibit high efficiency, high quality, and 3D consistency. Extensive experimental results demonstrate that our method outperforms existing state-of-the-art techniques in terms of lip movement accuracy, expression variation, and style feature expressiveness.

</details>


### [79] [GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection](https://arxiv.org/abs/2601.01856)
*Joongwon Chae,Lihui Luo,Yang Liu,Runming Wang,Dongmei Yu,Zeming Liang,Xi Yuan,Dayan Zhang,Zhenglin Chen,Peiwu Qin,Ilmoon Chae*

Main category: cs.CV

TL;DR: GCR提出了一种基于几何一致路由的轻量级专家混合框架，用于稳定任务无关的持续异常检测，通过共享嵌入空间中的最近原型距离进行路由决策，避免跨专家分数可比性问题。


<details>
  <summary>Details</summary>
Motivation: 工业检测中基于特征的异常检测方法通常假设已知类别身份，但在实际部署中需要任务无关的持续类别扩展操作。现有方法在跨专家路由时面临分数分布不一致的问题，导致路由不稳定和性能下降。

Method: 提出几何一致路由(GCR)框架：1）在共享的冻结补丁嵌入空间中为每个类别构建原型库；2）通过最小化累积最近原型距离将测试图像路由到合适的专家；3）仅在路由到的专家内部使用标准基于原型的评分规则计算异常图。

Result: 在MVTec AD和VisA数据集上的实验表明，几何一致路由显著提高了路由稳定性，缓解了持续性能崩溃，实现了接近零遗忘，同时保持了竞争力的检测和定位性能。

Conclusion: 许多先前归因于表示遗忘的失败实际上可以解释为跨专家路由中决策规则的不稳定性。GCR通过分离跨专家决策和专家内异常评分，无需端到端表示学习即可解决路由稳定性问题。

Abstract: Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior.
  We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning.
  Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR

</details>


### [80] [RRNet: Configurable Real-Time Video Enhancement with Arbitrary Local Lighting Variations](https://arxiv.org/abs/2601.01865)
*Wenlong Yang,Canran Jin,Weihang Yuan,Chao Wang,Lifeng Sun*

Main category: cs.CV

TL;DR: RRNet是一个轻量级可配置的实时视频增强框架，通过估计虚拟光源参数实现局部重照明，在视觉质量和效率之间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有实时视频增强方法在速度和有效曝光控制之间难以平衡，特别是在不均匀光照条件下。需要一种既能保持高质量又能实时运行的解决方案。

Method: 提出RRNet框架：1) 估计少量虚拟光源参数；2) 通过深度感知渲染模块实现局部重照明；3) 使用流线型编码器和轻量级预测头；4) 采用生成式AI创建训练数据集。

Result: RRNet在低光增强、局部光照调整和眩光去除方面优于现有方法，支持实时高分辨率处理，保持面部身份特征，具有可解释的光照控制。

Conclusion: RRNet通过轻量级架构和可配置设计，在视频会议、AR人像增强和移动摄影等实际应用中表现出色，实现了视觉质量与效率的最佳平衡。

Abstract: With the growing demand for real-time video enhancement in live applications, existing methods often struggle to balance speed and effective exposure control, particularly under uneven lighting. We introduce RRNet (Rendering Relighting Network), a lightweight and configurable framework that achieves a state-of-the-art tradeoff between visual quality and efficiency. By estimating parameters for a minimal set of virtual light sources, RRNet enables localized relighting through a depth-aware rendering module without requiring pixel-aligned training data. This object-aware formulation preserves facial identity and supports real-time, high-resolution performance using a streamlined encoder and lightweight prediction head. To facilitate training, we propose a generative AI-based dataset creation pipeline that synthesizes diverse lighting conditions at low cost. With its interpretable lighting control and efficient architecture, RRNet is well suited for practical applications such as video conferencing, AR-based portrait enhancement, and mobile photography. Experiments show that RRNet consistently outperforms prior methods in low-light enhancement, localized illumination adjustment, and glare removal.

</details>


### [81] [Entity-Guided Multi-Task Learning for Infrared and Visible Image Fusion](https://arxiv.org/abs/2601.01870)
*Wenyu Shao,Hongbo Liu,Yunchuan Ma,Ruili Wang*

Main category: cs.CV

TL;DR: 提出EGMT方法，通过实体引导的多任务学习进行红外与可见光图像融合，利用实体级文本信息消除语义噪声，提升融合图像的质量和语义密度。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的红外与可见光图像融合方法通常依赖句子级文本信息，存在语义噪声问题，且未能充分利用文本的深层语义价值。

Method: 提出EGMT方法，包含三个创新组件：1) 从大视觉语言模型生成的图像描述中提取实体级文本信息；2) 构建并行多任务学习架构，将图像融合与多标签分类任务结合；3) 开发实体引导的跨模态交互模块，促进视觉与实体级文本特征的细粒度交互。

Result: 在TNO、RoadScene、M3FD和MSRS四个公开数据集上进行了广泛实验，证明EGMT在保留显著目标、纹理细节和语义一致性方面优于现有最先进方法。

Conclusion: EGMT方法通过实体引导的多任务学习有效提升了红外与可见光图像融合的质量，并发布了实体标注版本的四个公开数据集以促进该框架的广泛应用。

Abstract: Existing text-driven infrared and visible image fusion approaches often rely on textual information at the sentence level, which can lead to semantic noise from redundant text and fail to fully exploit the deeper semantic value of textual information. To address these issues, we propose a novel fusion approach named Entity-Guided Multi-Task learning for infrared and visible image fusion (EGMT). Our approach includes three key innovative components: (i) A principled method is proposed to extract entity-level textual information from image captions generated by large vision-language models, eliminating semantic noise from raw text while preserving critical semantic information; (ii) A parallel multi-task learning architecture is constructed, which integrates image fusion with a multi-label classification task. By using entities as pseudo-labels, the multi-label classification task provides semantic supervision, enabling the model to achieve a deeper understanding of image content and significantly improving the quality and semantic density of the fused image; (iii) An entity-guided cross-modal interactive module is also developed to facilitate the fine-grained interaction between visual and entity-level textual features, which enhances feature representation by capturing cross-modal dependencies at both inter-visual and visual-entity levels. To promote the wide application of the entity-guided image fusion framework, we release the entity-annotated version of four public datasets (i.e., TNO, RoadScene, M3FD, and MSRS). Extensive experiments demonstrate that EGMT achieves superior performance in preserving salient targets, texture details, and semantic consistency, compared to the state-of-the-art methods. The code and dataset will be publicly available at https://github.com/wyshao-01/EGMT.

</details>


### [82] [CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving](https://arxiv.org/abs/2601.01874)
*Shuhang Chen,Yunqiu Xu,Junjie Xie,Aojun Lu,Tao Feng,Zeying Huang,Ning Zhang,Yi Sun,Yi Yang,Hangjie Yuan*

Main category: cs.CV

TL;DR: CogFlow是一个受认知启发的三阶段框架，通过感知→内化→推理的层次流程，解决多模态大语言模型在视觉数学问题解决中的视觉感知瓶颈和视觉线索整合问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视觉数学问题解决中仍存在困难，虽然一些工作认识到视觉感知是瓶颈，但解决方案仅限于改进视觉输入的提取和解释，忽略了提取的视觉线索是否被忠实整合并正确用于后续推理的关键问题。

Method: 提出CogFlow认知启发三阶段框架：1）感知阶段：设计协同视觉奖励，在参数和语义空间中提升感知能力；2）内化阶段：引入知识内化奖励模型，连接感知和推理；3）推理阶段：设计视觉门控策略优化算法，确保推理基于视觉知识。同时贡献了包含12万+高质量感知-推理对齐标注的MathCog数据集。

Result: 在常用视觉数学推理基准测试上的综合实验和分析验证了CogFlow的优越性。

Conclusion: CogFlow通过模拟人类推理的层次流程，全面增强感知、内化和推理阶段，有效解决了视觉数学问题解决中的视觉感知瓶颈和视觉线索整合问题。

Abstract: Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\Rightarrow$internalization$\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.

</details>


### [83] [Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems](https://arxiv.org/abs/2601.01891)
*Niloufar Alipour Talemi,Julia Boone,Fatemeh Afghah*

Main category: cs.CV

TL;DR: 该论文首次全面综述遥感领域中的智能体AI，提出统一分类体系，分析架构基础，并展望自主地理空间智能的发展路线图。


<details>
  <summary>Details</summary>
Motivation: 地球观测分析范式正从静态深度学习模型转向自主智能体AI。尽管现有视觉基础模型和多模态大语言模型在表示学习方面取得进展，但缺乏复杂地理空间工作流所需的序列规划和工具编排能力，因此需要系统梳理该新兴领域。

Method: 采用文献综述方法，提出统一分类体系区分单智能体协同和多智能体系统，分析规划机制、检索增强生成、记忆结构等架构基础，并评估从像素级精度到轨迹感知推理正确性的新兴基准。

Result: 建立了遥感领域智能体AI的首次全面综述框架，系统分析了现有技术架构和评估方法，识别了在基础、安全性和编排方面的关键局限性。

Conclusion: 该工作为开发鲁棒、自主的地理空间智能提供了战略路线图，指出了未来研究方向，推动地球观测分析向更智能、更自主的范式转变。

Abstract: The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.

</details>


### [84] [Forget Less by Learning from Parents Through Hierarchical Relationships](https://arxiv.org/abs/2601.01892)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: FLLP框架通过双曲空间中的父子概念学习机制，解决定制扩散模型在顺序学习新概念时的灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 定制扩散模型在顺序学习新概念时容易发生灾难性遗忘，现有方法主要关注最小化概念间干扰，但忽视了概念间潜在的积极交互作用

Method: 提出FLLP框架，在洛伦兹流形（双曲空间）中引入父子概念学习机制，将先前学习的概念作为父概念指导新概念的学习，利用双曲空间自然适合建模树状层次结构的特性

Result: 在三个公共数据集和一个合成基准上验证，FLLP在鲁棒性和泛化能力方面均表现出持续改进

Conclusion: FLLP通过双曲空间中的父子概念学习机制，不仅能够保留先验知识，还支持新概念的持续集成，有效缓解了定制扩散模型的灾难性遗忘问题

Abstract: Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.

</details>


### [85] [Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection](https://arxiv.org/abs/2601.01908)
*Jingjing Wang,Qianglin Liu,Zhuo Xiao,Xinning Yao,Bo Liu,Lu Li,Lijuan Niu,Fugen Zhou*

Main category: cs.CV

TL;DR: Nodule-DETR是一种基于检测变换器的新型甲状腺结节检测架构，通过多光谱频域通道注意力、分层特征融合和多尺度可变形注意力模块，显著提升了超声图像中甲状腺结节的检测精度。


<details>
  <summary>Details</summary>
Motivation: 甲状腺癌是全球最常见的内分泌恶性肿瘤，发病率不断上升。超声是检测甲状腺结节的首选成像方式，但其诊断准确性常受图像对比度低和结节边界模糊等挑战限制。

Method: 提出Nodule-DETR架构，包含三个关键创新：1）多光谱频域通道注意力模块，利用频率分析增强低对比度结节特征；2）分层特征融合模块，实现高效多尺度特征集成；3）多尺度可变形注意力模块，灵活捕捉小而不规则形状的结节。

Result: 在真实世界甲状腺超声图像临床数据集上的实验表明，Nodule-DETR实现了最先进的性能，在mAP@0.5:0.95指标上比基线模型显著提高了0.149。

Conclusion: Nodule-DETR的优越准确性突显了其作为计算机辅助甲状腺诊断有效工具的重要临床应用潜力。

Abstract: Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.

</details>


### [86] [Learning Action Hierarchies via Hybrid Geometric Diffusion](https://arxiv.org/abs/2601.01914)
*Arjun Ramesh Kaushik,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 本文提出HybridTAS框架，将欧几里得和双曲几何结合到扩散模型的去噪过程中，利用双曲几何的层次结构特性实现从粗到细的动作分割。


<details>
  <summary>Details</summary>
Motivation: 现有基于迭代精炼的方法未能充分利用人类动作的层次结构特性，需要一种能够显式利用动作层次关系的时间动作分割方法。

Method: 提出HybridTAS框架，在扩散模型的去噪过程中融合欧几里得和双曲几何。利用双曲几何的树状关系特性，在较高扩散时间步使用抽象的高层动作类别（根节点）指导，在较低时间步使用细粒度动作类别（叶节点）进行精炼，实现从粗到细的动作标签去噪过程。

Result: 在GTEA、50Salads和Breakfast三个基准数据集上的实验表明，该方法达到了最先进的性能，验证了双曲引导去噪在时间动作分割任务中的有效性。

Conclusion: 通过将双曲几何融入扩散模型的去噪过程，能够有效利用动作的层次结构，为时间动作分割任务提供了一种新颖且有效的解决方案。

Abstract: Temporal action segmentation is a critical task in video understanding, where the goal is to assign action labels to each frame in a video. While recent advances leverage iterative refinement-based strategies, they fail to explicitly utilize the hierarchical nature of human actions. In this work, we propose HybridTAS - a novel framework that incorporates a hybrid of Euclidean and hyperbolic geometries into the denoising process of diffusion models to exploit the hierarchical structure of actions. Hyperbolic geometry naturally provides tree-like relationships between embeddings, enabling us to guide the action label denoising process in a coarse-to-fine manner: higher diffusion timesteps are influenced by abstract, high-level action categories (root nodes), while lower timesteps are refined using fine-grained action classes (leaf nodes). Extensive experiments on three benchmark datasets, GTEA, 50Salads, and Breakfast, demonstrate that our method achieves state-of-the-art performance, validating the effectiveness of hyperbolic-guided denoising for the temporal action segmentation task.

</details>


### [87] [TalkPhoto: A Versatile Training-Free Conversational Assistant for Intelligent Image Editing](https://arxiv.org/abs/2601.01915)
*Yujie Hu,Zecheng Tang,Xu Jiang,Weiqi Li,Jian Zhang*

Main category: cs.CV

TL;DR: TalkPhoto是一个无需训练的图像编辑框架，通过对话交互实现精确图像操控，利用LLM分析用户需求并分层调用现有先进编辑方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法需要构建多指令数据集来训练模型处理多种编辑任务，这既耗时耗力又难以获得满意结果。需要一种更高效、无需训练的方法来实现灵活可控的图像编辑。

Method: 提出TalkPhoto框架：1) 使用专门设计的提示模板指导开源LLM分析用户需求；2) 分层调用现有高级编辑方法；3) 实现即插即用、高效的编辑方法调用机制，无需额外训练。

Result: 实验表明该方法不仅能用更少的token消耗提供更准确的调用，还能在各种图像编辑任务中实现更高质量的编辑效果，支持复杂和未见过的编辑任务集成。

Conclusion: TalkPhoto是一个多功能、无需训练的图像编辑框架，通过对话交互实现了稳定高质量的图像编辑，解决了现有方法训练成本高且效果有限的问题。

Abstract: Thanks to the powerful language comprehension capabilities of Large Language Models (LLMs), existing instruction-based image editing methods have introduced Multimodal Large Language Models (MLLMs) to promote information exchange between instructions and images, ensuring the controllability and flexibility of image editing. However, these frameworks often build a multi-instruction dataset to train the model to handle multiple editing tasks, which is not only time-consuming and labor-intensive but also fails to achieve satisfactory results. In this paper, we present TalkPhoto, a versatile training-free image editing framework that facilitates precise image manipulation through conversational interaction. We instruct the open-source LLM with a specially designed prompt template to analyze user needs after receiving instructions and hierarchically invoke existing advanced editing methods, all without additional training. Moreover, we implement a plug-and-play and efficient invocation of image editing methods, allowing complex and unseen editing tasks to be integrated into the current framework, achieving stable and high-quality editing results. Extensive experiments demonstrate that our method not only provides more accurate invocation with fewer token consumption but also achieves higher editing quality across various image editing tasks.

</details>


### [88] [AR-MOT: Autoregressive Multi-object Tracking](https://arxiv.org/abs/2601.01925)
*Lianjie Jia,Yuhan Wu,Binghao Ran,Yifan Wang,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: AR-MOT：基于自回归语言模型的多目标跟踪新范式，将MOT任务转化为序列生成问题，无需特定任务头，通过灵活序列构造输出结构化结果


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法架构僵化且任务特定，难以适应通用多模态场景和新的跟踪任务形式，限制了跨任务适用性和灵活性

Method: 提出AR-MOT自回归范式，在LLM框架内将MOT转化为序列生成任务；引入基于预训练检测器的对象标记器增强区域视觉感知；设计区域感知对齐模块缓解全局与区域特征不对齐；设计时序记忆融合模块缓存历史对象标记支持长期跟踪

Result: 在MOT17和DanceTrack数据集上的广泛实验验证了方法的可行性，性能与最先进方法相当，为更通用灵活的MOT系统奠定基础

Conclusion: AR-MOT通过自回归序列生成范式实现了灵活可扩展的MOT框架，新模态或指令只需修改输出序列格式而无需改变模型架构，具有强大的扩展潜力

Abstract: As multi-object tracking (MOT) tasks continue to evolve toward more general and multi-modal scenarios, the rigid and task-specific architectures of existing MOT methods increasingly hinder their applicability across diverse tasks and limit flexibility in adapting to new tracking formulations. Most approaches rely on fixed output heads and bespoke tracking pipelines, making them difficult to extend to more complex or instruction-driven tasks. To address these limitations, we propose AR-MOT, a novel autoregressive paradigm that formulates MOT as a sequence generation task within a large language model (LLM) framework. This design enables the model to output structured results through flexible sequence construction, without requiring any task-specific heads. To enhance region-level visual perception, we introduce an Object Tokenizer based on a pretrained detector. To mitigate the misalignment between global and regional features, we propose a Region-Aware Alignment (RAA) module, and to support long-term tracking, we design a Temporal Memory Fusion (TMF) module that caches historical object tokens. AR-MOT offers strong potential for extensibility, as new modalities or instructions can be integrated by simply modifying the output sequence format without altering the model architecture. Extensive experiments on MOT17 and DanceTrack validate the feasibility of our approach, achieving performance comparable to state-of-the-art methods while laying the foundation for more general and flexible MOT systems.

</details>


### [89] [MacVQA: Adaptive Memory Allocation and Global Noise Filtering for Continual Visual Question Answering](https://arxiv.org/abs/2601.01926)
*Zhifei Li,Yiran Wang,Chenyi Xiong,Yujing Xia,Xiaoju Hou,Yue Zhao,Miao Zhang,Kui Xiao,Bing Yang*

Main category: cs.CV

TL;DR: MacVQA是一个用于视觉问答持续学习的新框架，通过自适应内存分配和全局噪声过滤来平衡知识保留、适应性和鲁棒特征表示。


<details>
  <summary>Details</summary>
Motivation: 当前视觉问答持续学习方法在平衡知识保留、适应性和鲁棒特征表示方面存在困难，需要解决这些挑战。

Method: 提出MacVQA框架，融合视觉和问题信息同时过滤噪声以确保鲁棒表示，采用基于原型的记忆分配来优化特征质量和内存使用。

Result: 在10个持续VQA任务上的实验表明，MacVQA优于现有基线方法，标准任务平均准确率43.38%、平均遗忘率2.32%，新组合任务平均准确率42.53%、平均遗忘率3.60%。

Conclusion: MacVQA通过自适应内存分配和噪声过滤设计，能够平衡持续VQA学习中的知识获取、保留和组合泛化能力。

Abstract: Visual Question Answering (VQA) requires models to reason over multimodal information, combining visual and textual data. With the development of continual learning, significant progress has been made in retaining knowledge and adapting to new information in the VQA domain. However, current methods often struggle with balancing knowledge retention, adaptation, and robust feature representation. To address these challenges, we propose a novel framework with adaptive memory allocation and global noise filtering called MacVQA for visual question answering. MacVQA fuses visual and question information while filtering noise to ensure robust representations, and employs prototype-based memory allocation to optimize feature quality and memory usage. These designs enable MacVQA to balance knowledge acquisition, retention, and compositional generalization in continual VQA learning. Experiments on ten continual VQA tasks show that MacVQA outperforms existing baselines, achieving 43.38% average accuracy and 2.32% average forgetting on standard tasks, and 42.53% average accuracy and 3.60% average forgetting on novel composition tasks.

</details>


### [90] [MotionAdapter: Video Motion Transfer via Content-Aware Attention Customization](https://arxiv.org/abs/2601.01955)
*Zhexin Zhang,Yifeng Zhu,Yangyang Xu,Long Chen,Yong Du,Shengfeng He,Jun Yu*

Main category: cs.CV

TL;DR: MotionAdapter是一个基于扩散变换器的内容感知运动迁移框架，通过显式解耦运动与外观，并自适应地将运动定制到目标内容，实现了鲁棒且语义对齐的视频间复杂运动迁移。


<details>
  <summary>Details</summary>
Motivation: 尽管基于扩散的文本到视频模型取得了显著进展，但在视频间迁移复杂运动仍然具有挑战性。现有方法难以实现鲁棒且语义对齐的运动迁移。

Method: MotionAdapter首先通过分析3D全注意力模块中的跨帧注意力来提取注意力驱动的运动场，实现运动与外观的显式解耦。然后引入DINO引导的运动定制模块，基于内容对应关系重新排列和精炼运动场，最后使用定制的运动场指导DiT去噪过程。

Result: 大量实验表明，MotionAdapter在定性和定量评估中都优于最先进的方法，并且自然地支持复杂运动迁移和运动编辑任务（如缩放）。

Conclusion: MotionAdapter通过内容感知的运动迁移框架，成功解决了DiT基文本到视频模型中复杂运动迁移的挑战，实现了鲁棒且语义对齐的运动迁移，为视频生成和编辑提供了新的可能性。

Abstract: Recent advances in diffusion-based text-to-video models, particularly those built on the diffusion transformer architecture, have achieved remarkable progress in generating high-quality and temporally coherent videos. However, transferring complex motions between videos remains challenging. In this work, we present MotionAdapter, a content-aware motion transfer framework that enables robust and semantically aligned motion transfer within DiT-based T2V models. Our key insight is that effective motion transfer requires \romannumeral1) explicit disentanglement of motion from appearance and \romannumeral 2) adaptive customization of motion to target content. MotionAdapter first isolates motion by analyzing cross-frame attention within 3D full-attention modules to extract attention-derived motion fields. To bridge the semantic gap between reference and target videos, we further introduce a DINO-guided motion customization module that rearranges and refines motion fields based on content correspondences. The customized motion field is then used to guide the DiT denoising process, ensuring that the synthesized video inherits the reference motion while preserving target appearance and semantics. Extensive experiments demonstrate that MotionAdapter outperforms state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, MotionAdapter naturally supports complex motion transfer and motion editing tasks such as zooming.

</details>


### [91] [AFTER: Mitigating the Object Hallucination of LVLM via Adaptive Factual-Guided Activation Editing](https://arxiv.org/abs/2601.01957)
*Tianbo Wang,Yuqing Ma,Kewei Liao,Zhange Zhang,Simin Li,Jinyang Guo,Xianglong Liu*

Main category: cs.CV

TL;DR: AFTER方法通过事实增强的激活引导和查询自适应偏移优化，有效减少大型视觉语言模型中的物体幻觉问题


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在语言偏见导致的物体幻觉问题，包括类别、属性和关系幻觉，严重影响可信AI应用。现有编辑方法忽视了事实文本语义的有效指导，难以显式缓解语言偏见。

Method: 提出AFTER方法，包含事实增强激活引导（FAS）和查询自适应偏移优化（QAO）。FAS为激活编辑提供事实和通用指导，显式建模精确的视觉-文本关联；QAO引入查询感知偏移估计器，从通用引导向量建立查询特定的编辑。

Result: 在三个广泛采用的大型视觉语言模型的标准幻觉基准测试中验证了AFTER的有效性，在AMBER基准上实现了高达16.3%的幻觉减少。

Conclusion: AFTER方法通过自适应地将原始偏置激活引导至事实语义，有效缓解了大型视觉语言模型中的物体幻觉问题，为可信AI应用提供了有前景的解决方案。

Abstract: Large Vision-Language Models (LVLMs) have achieved substantial progress in cross-modal tasks. However, due to language bias, LVLMs are susceptible to object hallucination, which can be primarily divided into category, attribute, and relation hallucination, significantly impeding the trustworthy AI applications. Editing the internal activations of LVLMs has shown promising effectiveness in mitigating hallucinations with minimal cost. However, previous editing approaches neglect the effective guidance offered by factual textual semantics, thereby struggling to explicitly mitigate language bias. To address these issues, we propose Adaptive Factual-guided Visual-Textual Editing for hallucination mitigation (AFTER), which comprises Factual-Augmented Activation Steering (FAS) and Query-Adaptive Offset Optimization (QAO), to adaptively guides the original biased activations towards factual semantics. Specifically, FAS is proposed to provide factual and general guidance for activation editing, thereby explicitly modeling the precise visual-textual associations. Subsequently, QAO introduces a query-aware offset estimator to establish query-specific editing from the general steering vector, enhancing the diversity and granularity of editing. Extensive experiments on standard hallucination benchmarks across three widely adopted LVLMs validate the efficacy of the proposed AFTER, notably achieving up to a 16.3% reduction of hallucination over baseline on the AMBER benchmark. Our code and data will be released for reproducibility.

</details>


### [92] [VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis](https://arxiv.org/abs/2601.01989)
*Aly R. Elkammar,Karim M. Gamaleldin,Catherine M. Elias*

Main category: cs.CV

TL;DR: 本文提出基于Transformer/视频视觉Transformer的多模态算法，用于行人意图预测，在JAAD数据集上实现了SOTA性能，在准确率、AUC和F1分数等指标上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 行人意图预测是从L3到L4自动驾驶过渡的关键技术之一。为了理解行人过街行为，需要考虑多种因素和特征，以确保未来道路对所有人都更安全。

Method: 引入基于Transformer/视频视觉Transformer的不同规模算法，使用多种数据模态。通过广泛的消融研究来调查不同模型设计选择带来的优势。

Result: 在流行的行人行为数据集JAAD上评估算法，达到了SOTA性能，在准确率、AUC和F1分数等指标上超越了现有最佳方法。

Conclusion: 提出的Transformer/视频视觉Transformer多模态算法在行人意图预测任务上表现出色，为自动驾驶系统提供了有效的行人行为理解解决方案。

Abstract: Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.

</details>


### [93] [API: Empowering Generalizable Real-World Image Dehazing via Adaptive Patch Importance Learning](https://arxiv.org/abs/2601.01992)
*Chen Zhu,Huiwen Zhang,Yujie Li,Mu He,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 本文提出了一种自适应块重要性感知（API）框架用于可泛化的真实世界图像去雾，包含自动雾霾生成模块和密度感知去雾模块，通过混合数据增强和多负样本对比损失提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的去雾方法在应用于复杂真实世界雾霾场景时性能显著下降，主要原因是训练数据有限和雾霾密度分布的内在复杂性。

Method: 提出自适应块重要性感知（API）框架：1）自动雾霾生成（AHG）模块提供混合数据增强策略，生成真实多样的雾霾图像作为额外高质量训练数据；2）密度感知去雾（DHR）模块以自适应块重要性感知方式处理不同雾霾密度分布区域；3）引入多负样本对比去雾（MNCD）损失，充分利用空间和频域多个负样本信息。

Result: 在多个真实世界基准测试中实现了最先进的性能，在定量指标和定性视觉质量方面都表现出色，并在不同雾霾分布上展现出强大的泛化能力。

Conclusion: 提出的API框架通过混合数据增强、密度感知去雾和多负样本对比损失，有效解决了真实世界图像去雾中的训练数据有限和雾霾分布复杂性问题，实现了优异的泛化性能。

Abstract: Real-world image dehazing is a fundamental yet challenging task in low-level vision. Existing learning-based methods often suffer from significant performance degradation when applied to complex real-world hazy scenes, primarily due to limited training data and the intrinsic complexity of haze density distributions.To address these challenges, we introduce a novel Adaptive Patch Importance-aware (API) framework for generalizable real-world image dehazing. Specifically, our framework consists of an Automatic Haze Generation (AHG) module and a Density-aware Haze Removal (DHR) module. AHG provides a hybrid data augmentation strategy by generating realistic and diverse hazy images as additional high-quality training data. DHR considers hazy regions with varying haze density distributions for generalizable real-world image dehazing in an adaptive patch importance-aware manner. To alleviate the ambiguity of the dehazed image details, we further introduce a new Multi-Negative Contrastive Dehazing (MNCD) loss, which fully utilizes information from multiple negative samples across both spatial and frequency domains. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across multiple real-world benchmarks, delivering strong results in both quantitative metrics and qualitative visual quality, and exhibiting robust generalization across diverse haze distributions.

</details>


### [94] [Nighttime Hazy Image Enhancement via Progressively and Mutually Reinforcing Night-Haze Priors](https://arxiv.org/abs/2601.01998)
*Chen Zhu,Huiwen Zhang,Mu He,Yujie Li,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 提出一个新颖框架，通过强化雾霾与低光先验之间的内在一致性，渐进式提升夜间雾霾图像的可见度


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理单一类型的退化（如雾霾或低光），忽略了不同类型退化之间的相互作用，导致可见度提升有限。研究发现低光和雾霾先验之间的领域知识可以相互强化以获得更好的可见度

Method: 提出一个新颖框架，通过相互且渐进地强化雾霾和低光先验之间的内在一致性来增强夜间雾霾图像的可见度。模型采用图像级、块级和像素级专家，在视觉和频率域中操作，逐步恢复全局场景结构、区域模式和细粒度细节。引入频率感知路由器自适应地指导每个专家的贡献，确保鲁棒的图像恢复

Result: 在夜间去雾基准测试中，模型在定量和定性上都表现出优越性能。此外，模型在白天去雾和低光增强任务中也展现出良好的泛化能力

Conclusion: 通过强化雾霾和低光先验之间的内在一致性，可以更有效地处理夜间雾霾图像的复杂退化分布，实现更好的可见度增强效果

Abstract: Enhancing the visibility of nighttime hazy images is challenging due to the complex degradation distributions. Existing methods mainly address a single type of degradation (e.g., haze or low-light) at a time, ignoring the interplay of different degradation types and resulting in limited visibility improvement. We observe that the domain knowledge shared between low-light and haze priors can be reinforced mutually for better visibility. Based on this key insight, in this paper, we propose a novel framework that enhances visibility in nighttime hazy images by reinforcing the intrinsic consistency between haze and low-light priors mutually and progressively. In particular, our model utilizes image-, patch-, and pixel-level experts that operate across visual and frequency domains to recover global scene structure, regional patterns, and fine-grained details progressively. A frequency-aware router is further introduced to adaptively guide the contribution of each expert, ensuring robust image restoration. Extensive experiments demonstrate the superior performance of our model on nighttime dehazing benchmarks both quantitatively and qualitatively. Moreover, we showcase the generalizability of our model in daytime dehazing and low-light enhancement tasks.

</details>


### [95] [Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach](https://arxiv.org/abs/2601.02016)
*Matthias Bartolo,Dylan Seychell,Gabriel Hili,Matthew Montebello,Carl James Debono,Saviour Formosa,Konstantinos Makantasis*

Main category: cs.CV

TL;DR: 本文研究将特权信息学习（LUPI）范式整合到目标检测中，利用训练时可用但推理时不可用的细粒度描述性信息，通过师生架构注入特权信息，显著提升检测精度而不增加推理复杂度。


<details>
  <summary>Details</summary>
Motivation: 目标检测训练时通常有丰富的描述性信息（如边界框掩码、显著性图、深度线索等），但在推理时这些信息不可用。如何有效利用这些训练时的特权信息来提升检测性能，而不增加推理时的计算负担，是本研究的核心动机。

Method: 提出一种通用的、模型无关的方法，通过师生架构将特权信息注入深度学习目标检测器。教师模型利用特权信息进行训练，学生模型学习教师的输出，最终学生模型在推理时不依赖特权信息。该方法适用于多种目标检测模型。

Result: 在五个最先进的目标检测模型和多个公共基准测试（包括无人机垃圾检测数据集和Pascal VOC 2012）上的实验表明，LUPI训练的学生模型始终优于基线模型，检测精度显著提升，且不增加推理复杂度或模型大小。中等和大尺寸目标的性能提升尤为明显。

Conclusion: LUPI框架为目标检测系统提供了一种有效且实用的策略，特别是在资源受限和实际应用场景中。通过师生架构利用训练时的特权信息，可以在不增加推理负担的情况下显著提升检测性能，中间权重平衡了特权信息和标准输入的学习。

Abstract: This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.

</details>


### [96] [Towards Any-Quality Image Segmentation via Generative and Adaptive Latent Space Enhancement](https://arxiv.org/abs/2601.02018)
*Guangqian Guo,Aixi Ren,Yong Guo,Xuehui Yu,Jiacheng Tian,Wenli Li,Yaoxing Wang,Shan Gao*

Main category: cs.CV

TL;DR: GleSAM++ 是一个增强 Segment Anything Models (SAMs) 在低质量图像上分割鲁棒性的方法，通过生成式潜在空间增强、特征分布对齐、通道复制扩展和退化感知自适应增强等技术，显著提升了在复杂退化图像上的分割性能。


<details>
  <summary>Details</summary>
Motivation: 虽然 SAMs 在零样本分割方面表现出色，但在严重退化、低质量图像上的性能显著下降，限制了其在真实场景中的应用。现有方法缺乏对退化程度的显式指导，导致模型需要隐式拟合复杂的噪声分布，增加了学习负担并导致次优重建。

Method: 提出了 GleSAM++ 方法，包含：1) 生成式潜在空间增强提升低质量图像鲁棒性；2) 特征分布对齐(FDA)和通道复制扩展(CRE)改善预训练扩散模型与分割框架的兼容性；3) 退化感知自适应增强(DAE)机制，将任意质量特征的重建过程解耦为退化级别预测和退化感知重建两个阶段。

Result: 大量实验表明，GleSAM++ 在复杂退化情况下显著提高了分割鲁棒性，同时保持了对清晰图像的泛化能力。该方法在未见过的退化类型上也表现良好，证明了方法的通用性和数据集的多样性。

Conclusion: GleSAM++ 能够以最小的额外可学习参数应用于预训练的 SAM 和 SAM2，实现高效优化。该方法解决了 SAMs 在低质量图像上的性能瓶颈，为真实世界应用提供了更鲁棒的分割解决方案。

Abstract: Segment Anything Models (SAMs), known for their exceptional zero-shot segmentation performance, have garnered significant attention in the research community. Nevertheless, their performance drops significantly on severely degraded, low-quality images, limiting their effectiveness in real-world scenarios. To address this, we propose GleSAM++, which utilizes Generative Latent space Enhancement to boost robustness on low-quality images, thus enabling generalization across various image qualities. Additionally, to improve compatibility between the pre-trained diffusion model and the segmentation framework, we introduce two techniques, i.e., Feature Distribution Alignment (FDA) and Channel Replication and Expansion (CRE). However, the above components lack explicit guidance regarding the degree of degradation. The model is forced to implicitly fit a complex noise distribution that spans conditions from mild noise to severe artifacts, which substantially increases the learning burden and leads to suboptimal reconstructions. To address this issue, we further introduce a Degradation-aware Adaptive Enhancement (DAE) mechanism. The key principle of DAE is to decouple the reconstruction process for arbitrary-quality features into two stages: degradation-level prediction and degradation-aware reconstruction. Our method can be applied to pre-trained SAM and SAM2 with only minimal additional learnable parameters, allowing for efficient optimization. Extensive experiments demonstrate that GleSAM++ significantly improves segmentation robustness on complex degradations while maintaining generalization to clear images. Furthermore, GleSAM++ also performs well on unseen degradations, underscoring the versatility of our approach and dataset.

</details>


### [97] [Adapting Depth Anything to Adverse Imaging Conditions with Events](https://arxiv.org/abs/2601.02020)
*Shihan Peng,Yuyang Xiong,Hanyu Zhou,Zhiwei Shi,Haoyue Liu,Gang Chen,Luxin Yan,Yi Chang*

Main category: cs.CV

TL;DR: 提出ADAE框架，通过事件相机引导的时空融合增强Depth Anything在恶劣光照和运动模糊场景下的深度估计能力


<details>
  <summary>Details</summary>
Motivation: 当前深度基础模型（如Depth Anything）在理想场景表现良好，但在极端光照和运动模糊等恶劣成像条件下性能下降。传统融合方法需要从头训练，无法继承基础模型的开放世界知识和泛化能力。

Method: 提出ADAE框架，包含两个核心组件：1）熵感知空间融合 - 使用信息熵策略自适应融合帧基和事件基特征，指示光照引起的退化；2）运动引导时间校正 - 利用事件运动线索重新校准模糊区域的模糊特征。

Result: 大量实验验证了所提方法的优越性，在恶劣成像条件下显著增强了Depth Anything的性能。

Conclusion: ADAE框架通过事件引导的时空融合，有效提升了深度基础模型在退化场景下的鲁棒性，同时继承了基础模型的开放世界知识。

Abstract: Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.

</details>


### [98] [Leveraging 2D-VLM for Label-Free 3D Segmentation in Large-Scale Outdoor Scene Understanding](https://arxiv.org/abs/2601.02029)
*Toshihiko Nishimura,Hirofumi Abe,Kazuhiko Murasaki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 提出一种无需3D标注数据或配对RGB图像的大规模点云3D语义分割方法，通过虚拟相机将点云投影到2D图像，利用基础2D模型和自然语言提示进行语义分割，通过多视角加权投票实现3D分割。


<details>
  <summary>Details</summary>
Motivation: 传统3D语义分割方法需要大量标注的3D训练数据，获取成本高且难以扩展。现有方法通常依赖配对RGB图像或监督训练，限制了应用范围和灵活性。本文旨在开发一种无需3D标注、无需配对图像、支持开放词汇的3D语义分割方法。

Method: 1) 使用虚拟相机将3D点云投影到多个2D视角图像；2) 利用基础2D模型结合自然语言提示对每个2D图像进行语义分割；3) 通过加权投票机制聚合多个视角的预测结果，实现3D点云分割；4) 支持任意文本查询的开放词汇识别。

Result: 该方法在无需3D训练数据的情况下，性能优于现有的无训练方法，分割精度接近监督学习方法。支持开放词汇识别，用户可以使用任意文本查询检测对象，突破了传统监督方法的类别限制。

Conclusion: 本文提出了一种创新的3D语义分割框架，通过将3D点云投影到2D并利用强大的基础2D模型，实现了无需3D标注数据的高质量分割。该方法不仅性能优越，还支持开放词汇识别，为3D场景理解提供了更灵活、可扩展的解决方案。

Abstract: This paper presents a novel 3D semantic segmentation method for large-scale point cloud data that does not require annotated 3D training data or paired RGB images. The proposed approach projects 3D point clouds onto 2D images using virtual cameras and performs semantic segmentation via a foundation 2D model guided by natural language prompts. 3D segmentation is achieved by aggregating predictions from multiple viewpoints through weighted voting. Our method outperforms existing training-free approaches and achieves segmentation accuracy comparable to supervised methods. Moreover, it supports open-vocabulary recognition, enabling users to detect objects using arbitrary text queries, thus overcoming the limitations of traditional supervised approaches.

</details>


### [99] [AlignVTOFF: Texture-Spatial Feature Alignment for High-Fidelity Virtual Try-Off](https://arxiv.org/abs/2601.02038)
*Yihan Zhu,Mengying Ge*

Main category: cs.CV

TL;DR: AlignVTOFF是一个用于虚拟试穿(VTOFF)任务的并行U-Net框架，通过参考U-Net和纹理-空间特征对齐模块，解决了现有方法在复杂几何变形和高频纹理保持方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法依赖轻量级模块进行快速特征提取，难以保持结构化图案和细粒度细节，导致生成过程中纹理衰减。需要解决在复杂几何变形和丰富高频纹理下合成高保真平铺服装的挑战。

Method: 提出AlignVTOFF框架，包含参考U-Net和纹理-空间特征对齐(TSFA)模块。参考U-Net执行多尺度特征提取并增强几何保真度；TSFA通过混合注意力设计（可训练交叉注意力模块和冻结自注意力模块）将参考服装特征注入冻结的去噪U-Net中。

Result: 在多种设置下的广泛实验表明，AlignVTOFF始终优于最先进的方法，生成的平铺服装结果具有改进的结构真实性和高频细节保真度。

Conclusion: AlignVTOFF通过并行U-Net框架和纹理-空间特征对齐机制，有效解决了虚拟试穿任务中的几何变形和纹理保持问题，显著提升了生成质量。

Abstract: Virtual Try-Off (VTOFF) is a challenging multimodal image generation task that aims to synthesize high-fidelity flat-lay garments under complex geometric deformation and rich high-frequency textures. Existing methods often rely on lightweight modules for fast feature extraction, which struggles to preserve structured patterns and fine-grained details, leading to texture attenuation during generation.To address these issues, we propose AlignVTOFF, a novel parallel U-Net framework built upon a Reference U-Net and Texture-Spatial Feature Alignment (TSFA). The Reference U-Net performs multi-scale feature extraction and enhances geometric fidelity, enabling robust modeling of deformation while retaining complex structured patterns. TSFA then injects the reference garment features into a frozen denoising U-Net via a hybrid attention design, consisting of a trainable cross-attention module and a frozen self-attention module. This design explicitly aligns texture and spatial cues and alleviates the loss of high-frequency information during the denoising process.Extensive experiments across multiple settings demonstrate that AlignVTOFF consistently outperforms state-of-the-art methods, producing flat-lay garment results with improved structural realism and high-frequency detail fidelity.

</details>


### [100] [PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction](https://arxiv.org/abs/2601.02088)
*Jiahao Bao,Huazhen Liu,Yu Zhuang,Leran Tao,Xinyu Xu,Yongtao Shi,Mengjia Cheng,Yiming Wang,Congshuang Ku,Ting Zeng,Yilang Du,Siyi Chen,Shunyao Shen,Suncheng Xiang,Hongbo Yu*

Main category: cs.CV

TL;DR: PhysSFI-Net：一种物理信息几何深度学习框架，用于预测正颌手术后的软组织变形，相比传统方法具有更好的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 正颌手术需要准确模拟术后面部形态以进行术前规划。传统生物力学模型计算成本高，而几何深度学习方法往往缺乏可解释性，因此需要开发更优的预测框架。

Method: PhysSFI-Net包含三个组件：1）具有颅面特征和手术计划编码器及注意力机制的分层图模块，用于提取骨骼-面部交互特征；2）基于LSTM的序列预测器，用于增量软组织变形预测；3）生物力学启发的模块，用于高分辨率面部表面重建。

Result: 在135名患者数据集上，PhysSFI-Net实现了点云形状误差1.070±0.088mm、表面偏差误差1.296±0.349mm、标志点定位误差2.445±1.326mm，优于现有最先进方法ACMT-Net。

Conclusion: PhysSFI-Net能够以高精度和高分辨率预测术后面部形态，具有可解释性，在正颌手术规划和模拟中显示出强大的临床应用潜力。

Abstract: Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.

</details>


### [101] [InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting](https://arxiv.org/abs/2601.02098)
*Jinlong Fan,Shanshan Zhao,Liang Zheng,Jing Zhang,Yuxiang Yang,Mingming Gong*

Main category: cs.CV

TL;DR: InpaintHuman：一种从遮挡的单目视频重建完整可动画3D人体化身的新方法，通过多尺度UV参数化表示和身份保持扩散修复模块解决严重遮挡下的重建问题。


<details>
  <summary>Details</summary>
Motivation: 从单目视频重建完整可动画的3D人体化身在严重遮挡情况下仍然具有挑战性。现有基于3D高斯泼溅的方法在处理不完整观测时，往往产生损坏的几何结构和时间不一致性。

Method: 提出两个关键创新：1）具有分层粗到细特征插值的多尺度UV参数化表示，能够鲁棒地重建遮挡区域同时保留几何细节；2）身份保持扩散修复模块，将文本反转与语义条件引导相结合，实现特定主体、时间一致的补全。与SDS方法不同，采用直接像素级监督确保身份保真度。

Result: 在合成基准（PeopleSnapshot、ZJU-MoCap）和真实场景（OcMotion）上的实验展示了竞争性性能，在不同姿态和视角下重建质量有持续改进。

Conclusion: InpaintHuman能够从遮挡的单目视频生成高保真、完整且可动画的化身，解决了现有方法在严重遮挡下的局限性。

Abstract: Reconstructing complete and animatable 3D human avatars from monocular videos remains challenging, particularly under severe occlusions. While 3D Gaussian Splatting has enabled photorealistic human rendering, existing methods struggle with incomplete observations, often producing corrupted geometry and temporal inconsistencies. We present InpaintHuman, a novel method for generating high-fidelity, complete, and animatable avatars from occluded monocular videos. Our approach introduces two key innovations: (i) a multi-scale UV-parameterized representation with hierarchical coarse-to-fine feature interpolation, enabling robust reconstruction of occluded regions while preserving geometric details; and (ii) an identity-preserving diffusion inpainting module that integrates textual inversion with semantic-conditioned guidance for subject-specific, temporally coherent completion. Unlike SDS-based methods, our approach employs direct pixel-level supervision to ensure identity fidelity. Experiments on synthetic benchmarks (PeopleSnapshot, ZJU-MoCap) and real-world scenarios (OcMotion) demonstrate competitive performance with consistent improvements in reconstruction quality across diverse poses and viewpoints.

</details>


### [102] [360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images](https://arxiv.org/abs/2601.02102)
*Jiaqi Yao,Zhongmiao Yan,Jingyi Xu,Songpengcheng Xia,Yan Xiang,Ling Pei*

Main category: cs.CV

TL;DR: 提出一种基于3D高斯泼溅的前馈框架，通过深度-法向几何正则化提升几何一致性，在保持高质量渲染的同时改善3D重建精度


<details>
  <summary>Details</summary>
Motivation: 传统多视角立体视觉在稀疏视角或低纹理区域表现不佳，神经渲染方法需要逐场景优化且缺乏实时性，现有3D高斯泼溅方法注重视觉质量但几何一致性不足，限制了在空间感知任务中的可靠应用

Method: 提出前馈式3D高斯泼溅框架，引入深度-法向几何正则化，将渲染深度梯度与法向信息耦合，监督高斯旋转、尺度和位置参数，提升点云和表面精度

Result: 实验结果表明，该方法在保持高质量渲染的同时显著提升了几何一致性，为空间感知任务中的3D重建提供了有效解决方案

Conclusion: 该方法通过几何正则化机制，在3D高斯泼溅框架中实现了更好的几何一致性，平衡了渲染质量与重建精度，适用于AR、机器人和数字孪生等空间智能应用

Abstract: 3D scene reconstruction is fundamental for spatial intelligence applications such as AR, robotics, and digital twins. Traditional multi-view stereo struggles with sparse viewpoints or low-texture regions, while neural rendering approaches, though capable of producing high-quality results, require per-scene optimization and lack real-time efficiency. Explicit 3D Gaussian Splatting (3DGS) enables efficient rendering, but most feed-forward variants focus on visual quality rather than geometric consistency, limiting accurate surface reconstruction and overall reliability in spatial perception tasks. This paper presents a novel feed-forward 3DGS framework for 360 images, capable of generating geometrically consistent Gaussian primitives while maintaining high rendering quality. A Depth-Normal geometric regularization is introduced to couple rendered depth gradients with normal information, supervising Gaussian rotation, scale, and position to improve point cloud and surface accuracy. Experimental results show that the proposed method maintains high rendering quality while significantly improving geometric consistency, providing an effective solution for 3D reconstruction in spatial perception tasks.

</details>


### [103] [HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures](https://arxiv.org/abs/2601.02103)
*Yating Wang,Yuan Sun,Xuan Wang,Ran Yi,Boyao Zhou,Yipengjing Sun,Hongyu Liu,Yinuo Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: HeadLighter：基于3D高斯泼溅的头部生成模型，通过物理可解释的分解方法实现可控重光照，支持显式光照和视角编辑


<details>
  <summary>Details</summary>
Motivation: 现有3D感知头部生成模型虽然能实现实时、逼真且视角一致的头部合成，但存在光照与内在外观深度纠缠的问题，导致无法进行可控重光照。现有解缠方法依赖强假设进行弱监督学习，限制了处理复杂光照的能力。

Method: 提出HeadLighter框架：1）设计双分支架构分别建模光照不变头部属性和物理基础的渲染组件；2）采用渐进式解缠训练，在受控光照条件下使用光舞台设置采集的多视角图像进行监督；3）引入蒸馏策略生成高质量法线以实现逼真渲染。

Result: 实验表明，该方法在保持高质量生成和实时渲染的同时，支持显式光照和视角编辑。代码和数据集将公开。

Conclusion: HeadLighter通过物理可解释的分解方法解决了头部生成模型中光照与外观的纠缠问题，实现了可控重光照，为3D头部生成提供了更强大的编辑能力。

Abstract: Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.

</details>


### [104] [MagicFight: Personalized Martial Arts Combat Video Generation](https://arxiv.org/abs/2601.02107)
*Jiancheng Huang,Mingfu Yan,Songyan Chen,Yi Huang,Shifeng Chen*

Main category: cs.CV

TL;DR: MagicFight提出个性化武术格斗视频生成新任务，针对现有单人舞蹈生成模型无法处理双人交互的缺陷，通过Unity创建专用数据集，开发能保持身份一致性和动作连贯性的双人格斗视频生成方法。


<details>
  <summary>Details</summary>
Motivation: 当前个性化视频生成主要集中于单人场景，而双人交互特别是武术格斗领域尚未探索。现有单人舞蹈生成模型在处理双人交互时存在身份混淆、肢体异常和动作不匹配等问题，需要专门的方法来解决这些挑战。

Method: 使用Unity游戏物理引擎创建专门的数据集，包含多样化的3D角色、武术动作和场景。在此基础上改进和调整现有模型与策略，开发MagicFight方法，专门用于生成高质量的双人格斗视频。

Result: MagicFight能够生成保持个体身份一致性和动作序列连贯性的高保真双人格斗视频，为交互式视频内容创作领域奠定了基础。

Conclusion: 该研究开创了个性化武术格斗视频生成的新任务，通过专用数据集和方法解决了双人交互视频生成的独特挑战，为未来交互式视频内容创新铺平了道路。

Abstract: Amid the surge in generic text-to-video generation, the field of personalized human video generation has witnessed notable advancements, primarily concentrated on single-person scenarios. However, to our knowledge, the domain of two-person interactions, particularly in the context of martial arts combat, remains uncharted. We identify a significant gap: existing models for single-person dancing generation prove insufficient for capturing the subtleties and complexities of two engaged fighters, resulting in challenges such as identity confusion, anomalous limbs, and action mismatches. To address this, we introduce a pioneering new task, Personalized Martial Arts Combat Video Generation. Our approach, MagicFight, is specifically crafted to overcome these hurdles. Given this pioneering task, we face a lack of appropriate datasets. Thus, we generate a bespoke dataset using the game physics engine Unity, meticulously crafting a multitude of 3D characters, martial arts moves, and scenes designed to represent the diversity of combat. MagicFight refines and adapts existing models and strategies to generate high-fidelity two-person combat videos that maintain individual identities and ensure seamless, coherent action sequences, thereby laying the groundwork for future innovations in the realm of interactive video content creation.
  Website: https://MingfuYAN.github.io/MagicFight/
  Dataset: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta

</details>


### [105] [Towards Long-window Anchoring in Vision-Language Model Distillation](https://arxiv.org/abs/2512.21576)
*Haoyi Zhou,Shuo Li,Tianyu Chen,Qi Song,Chonghan Gao,Jianxin Li*

Main category: cs.CV

TL;DR: LAid方法通过知识蒸馏提升小模型的长上下文理解能力，实现比基线小模型长3.2倍的有效上下文窗口，同时保持标准视觉语言基准性能


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型虽然具备强大的长上下文理解能力，但其流行的小分支模型由于窗口大小有限，在语言-视觉对齐方面表现不佳。研究发现知识蒸馏可以补充RoPE在窗口大小方面的能力

Method: 提出LAid方法，包含两个互补组件：(1)渐进式距离加权注意力匹配，在训练中动态强调较长位置差异；(2)可学习的RoPE响应增益调制，选择性增强需要的位置敏感性

Result: 在多个模型系列上的广泛实验表明，LAid蒸馏的模型相比基线小模型实现了长达3.2倍的有效上下文窗口，同时在标准VL基准测试中保持或改进性能。频谱分析显示LAid成功保留了传统方法无法转移的关键低频注意力组件

Conclusion: 该工作不仅为构建更高效的长上下文视觉语言模型提供了实用技术，还提供了关于位置理解在蒸馏过程中如何出现和转移的理论见解

Abstract: While large vision-language models (VLMs) demonstrate strong long-context understanding, their prevalent small branches fail on linguistics-photography alignment for a limited window size. We discover that knowledge distillation improves students' capability as a complement to Rotary Position Embeddings (RoPE) on window sizes (anchored from large models). Building on this insight, we propose LAid, which directly aims at the transfer of long-range attention mechanisms through two complementary components: (1) a progressive distance-weighted attention matching that dynamically emphasizes longer position differences during training, and (2) a learnable RoPE response gain modulation that selectively amplifies position sensitivity where needed. Extensive experiments across multiple model families demonstrate that LAid-distilled models achieve up to 3.2 times longer effective context windows compared to baseline small models, while maintaining or improving performance on standard VL benchmarks. Spectral analysis also suggests that LAid successfully preserves crucial low-frequency attention components that conventional methods fail to transfer. Our work not only provides practical techniques for building more efficient long-context VLMs but also offers theoretical insights into how positional understanding emerges and transfers during distillation.

</details>


### [106] [Remote Sensing Change Detection via Weak Temporal Supervision](https://arxiv.org/abs/2601.02126)
*Xavier Bou,Elliot Vincent,Gabriele Facciolo,Rafael Grompone von Gioi,Jean-Michel Morel,Thibaud Ehret*

Main category: cs.CV

TL;DR: 提出一种利用现有单时相遥感数据集进行弱时间监督的语义变化检测方法，无需新标注，通过扩展数据集获取多时相观测，假设真实双时相对大多无变化，不同位置图像配对生成变化示例


<details>
  <summary>Details</summary>
Motivation: 遥感语义变化检测面临标注数据稀缺的挑战，像素级标注成本高、耗时长。现有方法使用合成数据或人工生成变化对，但跨域泛化能力有限

Method: 扩展单时相遥感数据集获取不同时间的新观测，训练变化检测模型时假设真实双时相对大多无变化，同时配对不同位置图像生成变化示例。采用对象感知变化图生成和迭代精炼过程处理弱标签噪声

Result: 在扩展的FLAIR和IAILD航空数据集上验证，在零样本和低数据场景下在不同基准测试中表现优异，展示了在法国大范围区域的应用结果，突显了方法的可扩展性

Conclusion: 提出的弱时间监督策略能够有效利用现有单时相数据集进行变化检测训练，无需额外标注，在零样本和低数据场景下表现良好，具有实际应用的可扩展潜力

Abstract: Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.

</details>


### [107] [Beyond Segmentation: An Oil Spill Change Detection Framework Using Synthetic SAR Imagery](https://arxiv.org/abs/2601.02139)
*Chenyang Lai,Shuaiyu Chen,Tianjin Huang,Siyang Song,Guangliang Cheng,Chunbo Luo,Zeyu Fu*

Main category: cs.CV

TL;DR: 提出OSCD任务和TAHI框架，通过双时相SAR图像变化检测提高漏油识别准确性，减少误报


<details>
  <summary>Details</summary>
Motivation: 传统基于单幅SAR图像的深度学习分割方法难以区分真实漏油与视觉相似的海面特征（如生物油膜、低风区），导致高误报率和有限泛化能力，特别是在数据稀缺条件下

Method: 提出Oil Spill Change Detection (OSCD)双时相任务，并开发Temporal-Aware Hybrid Inpainting (TAHI)框架，包含高保真混合修复（生成无油预漏油图像）和时间真实性增强（确保辐射和海洋状态一致性）两个关键组件

Result: 构建首个OSCD数据集，基准测试多个最先进的变化检测模型，结果显示OSCD相比传统分割方法显著减少误报并提高检测精度

Conclusion: 时间感知方法对于现实场景中可靠、可扩展的漏油监测具有重要价值，OSCD任务为解决传统方法局限性提供了有效途径

Abstract: Marine oil spills are urgent environmental hazards that demand rapid and reliable detection to minimise ecological and economic damage. While Synthetic Aperture Radar (SAR) imagery has become a key tool for large-scale oil spill monitoring, most existing detection methods rely on deep learning-based segmentation applied to single SAR images. These static approaches struggle to distinguish true oil spills from visually similar oceanic features (e.g., biogenic slicks or low-wind zones), leading to high false positive rates and limited generalizability, especially under data-scarce conditions. To overcome these limitations, we introduce Oil Spill Change Detection (OSCD), a new bi-temporal task that focuses on identifying changes between pre- and post-spill SAR images. As real co-registered pre-spill imagery is not always available, we propose the Temporal-Aware Hybrid Inpainting (TAHI) framework, which generates synthetic pre-spill images from post-spill SAR data. TAHI integrates two key components: High-Fidelity Hybrid Inpainting for oil-free reconstruction, and Temporal Realism Enhancement for radiometric and sea-state consistency. Using TAHI, we construct the first OSCD dataset and benchmark several state-of-the-art change detection models. Results show that OSCD significantly reduces false positives and improves detection accuracy compared to conventional segmentation, demonstrating the value of temporally-aware methods for reliable, scalable oil spill monitoring in real-world scenarios.

</details>


### [108] [BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models](https://arxiv.org/abs/2601.02147)
*Sunny Gupta,Shounak Das,Amit Sethi*

Main category: cs.CV

TL;DR: BiPrompt：一个双边提示优化框架，通过视觉和文本模态的同时优化来减少CLIP等视觉语言基础模型中的虚假相关性依赖


<details>
  <summary>Details</summary>
Motivation: 现有的去偏方法通常只针对单一模态（视觉或文本），导致部分鲁棒性和在分布偏移下的不稳定适应。需要同时处理两个模态中的虚假相关性依赖问题

Method: 提出双边提示优化框架：视觉侧采用结构化注意力引导擦除来抑制背景激活并强制因果区域与虚假区域之间的正交预测一致性；文本侧引入平衡提示归一化，通过学习性重新中心化机制将类别嵌入对齐到各向同性语义空间

Result: 在真实世界和合成偏差基准测试中，相比之前的测试时去偏方法，在平均准确率和最差组准确率方面都取得了持续改进

Conclusion: BiPrompt提供了一种轻量级但有效的路径，无需重新训练或领域监督，即可实现可信赖且因果基础的视觉语言适应

Abstract: Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.

</details>


### [109] [Why Commodity WiFi Sensors Fail at Multi-Person Gait Identification: A Systematic Analysis Using ESP32](https://arxiv.org/abs/2601.02177)
*Oliver Custance,Saad Khan,Simon Parkinson*

Main category: cs.CV

TL;DR: 研究系统评估了6种信号分离方法在商用ESP32 WiFi传感器上的多人步态识别性能，发现所有方法准确率都很低（45-56%），表明硬件限制是主要瓶颈而非算法问题。


<details>
  <summary>Details</summary>
Motivation: 虽然WiFi CSI在单人步态识别中表现良好，但多人识别研究不足，现有方法依赖复杂昂贵的定制设备。核心问题是：多人识别性能差是算法限制还是硬件约束？

Method: 使用商用ESP32 WiFi传感器，在1-10人场景下系统评估6种信号分离方法（FastICA、SOBI、PCA、NMF、小波变换、张量分解），并引入新的诊断指标（主体内变异性、主体间可区分性、性能退化率）。

Result: 所有方法准确率都很低（45-56%，标准差3.74%），统计上无显著差异（p>0.05）。最佳方法NMF仅达56%。分析显示高主体内变异性、低主体间可区分性，且随人数增加性能急剧下降。

Conclusion: 商用ESP32传感器无法提供足够的信号质量来实现可靠的多人分离，硬件限制是主要瓶颈，而非算法问题。这为未来研究指明了方向。

Abstract: WiFi Channel State Information (CSI) has shown promise for single-person gait identification, with numerous studies reporting high accuracy. However, multi-person identification remains largely unexplored, with the limited existing work relying on complex, expensive setups requiring modified firmware. A critical question remains unanswered: is poor multi-person performance an algorithmic limitation or a fundamental hardware constraint? We systematically evaluate six diverse signal separation methods (FastICA, SOBI, PCA, NMF, Wavelet, Tensor Decomposition) across seven scenarios with 1-10 people using commodity ESP32 WiFi sensors--a simple, low-cost, off-the-shelf solution. Through novel diagnostic metrics (intra-subject variability, inter-subject distinguishability, performance degradation rate), we reveal that all methods achieve similarly low accuracy (45-56\%, $σ$=3.74\%) with statistically insignificant differences (p $>$ 0.05). Even the best-performing method, NMF, achieves only 56\% accuracy. Our analysis reveals high intra-subject variability, low inter-subject distinguishability, and severe performance degradation as person count increases, indicating that commodity ESP32 sensors cannot provide sufficient signal quality for reliable multi-person separation.

</details>


### [110] [Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models](https://arxiv.org/abs/2601.02198)
*Alexander Möllers,Julius Hense,Florian Schulz,Timo Milbich,Maximilian Alber,Lukas Ruff*

Main category: cs.CV

TL;DR: 该研究探讨了组织病理学基础模型中放大倍数采样的影响，提出了连续采样方法以解决传统离散采样在中间放大倍数上的性能下降问题，并开发了优化采样分布来提升跨放大倍数的表示质量。


<details>
  <summary>Details</summary>
Motivation: 组织病理学中，病理学家需要在不同放大倍数下观察组织架构和精细形态，但现有病理学基础模型在不同放大倍数下的性能以及训练过程中的放大倍数采样策略影响尚不清楚。研究者希望理解放大倍数采样对模型性能的影响，并开发更好的采样策略。

Method: 将放大倍数采样建模为多源域适应问题，开发理论框架分析采样策略的系统性权衡。提出连续放大倍数采样方法替代传统的离散均匀采样，推导优化采样分布以提升跨放大倍数的表示质量。引入两个新基准（TCGA-MS, BRACS-MS）和相应指标来评估不同策略。

Result: 实验表明，连续采样相比离散采样在中间放大倍数上显著改善，平衡分类准确率提升高达4个百分点。优化分布能进一步提升性能。评估现有病理学基础模型发现，放大倍数是模型性能变化的主要驱动因素。

Conclusion: 连续放大倍数采样能消除放大倍数覆盖的空白，在标准尺度上保持性能的同时改善中间放大倍数的表现。优化采样分布可进一步提升跨放大倍数的表示质量。该研究为未来开发在多个放大倍数上可靠表现的病理学基础模型奠定了基础。

Abstract: In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.

</details>


### [111] [Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules](https://arxiv.org/abs/2601.02203)
*Oliver Custance,Saad Khan,Simon Parkinson,Quan Z. Sheng*

Main category: cs.CV

TL;DR: 提出基于WiFi CSI的无设备人群计数两阶段框架，通过自监督对比学习预训练CSI-ResNet-A获取域不变表示，结合轻量适配器微调和状态计数机，在域迁移问题上取得突破性性能。


<details>
  <summary>Details</summary>
Motivation: 基于WiFi CSI的无设备人群计数是隐私保护物联网应用的关键技术，但实际部署面临严重的域迁移问题——在一个环境训练的模型无法泛化到其他环境，这阻碍了实用化部署。

Method: 提出两阶段框架：1) 使用CSI-ResNet-A架构，通过自监督对比学习预训练获取域不变表示；2) 利用轻量适配器模块进行高效微调，生成事件序列后由状态计数机处理得到稳定占用估计。引入泛化指数(GI)量化鲁棒性。

Result: 在WiFlow数据集上，无监督方法在10-shot学习场景中MAE仅0.44，而监督基线失败；泛化指数接近完美；在公共WiAR基准测试中达到98.8%准确率的新SOTA。适配器微调性能接近全微调(98.84% vs 99.67%)但参数减少97.2%。

Conclusion: 该框架为开发面向真实世界物联网部署的鲁棒感知系统提供了实用且可扩展的解决方案，有效解决了WiFi CSI人群计数中的域迁移问题。

Abstract: Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\% of a full fine-tune (98.84\% vs. 99.67\%) while training 97.2\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.

</details>


### [112] [NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation](https://arxiv.org/abs/2601.02204)
*Huichao Zhang,Liao Qu,Yiheng Liu,Hang Chen,Yangyang Song,Yongsheng Dong,Shikun Sun,Xian Li,Xu Wang,Yi Jiang,Hu Ye,Bo Chen,Yiming Gao,Peng Liu,Akide Liu,Zhipeng Yang,Qili Deng,Linjie Xing,Jiyang Liu,Zhao Wang,Yang Zhou,Mingcong Liu,Yi Zhang,Qian He,Xiwei Hu,Zhongqi Qi,Jie Shao,Zhiye Fu,Shuai Wang,Fangmin Chen,Xuezhi Chai,Zhihua Wu,Yitong Wang,Zehuan Yuan,Daniel K. Du,Xinglong Wu*

Main category: cs.CV

TL;DR: NextFlow是一个统一的解码器自回归Transformer，通过6万亿文本-图像离散标记训练，采用统一视觉表示和自回归架构，实现多模态理解和生成，包括图像编辑、交错内容和视频生成。


<details>
  <summary>Details</summary>
Motivation: 不同模态具有本质差异：文本是严格顺序的，而图像具有层次结构。传统的光栅扫描方法效率低下，需要更高效的视觉生成方法。

Method: 1. 统一解码器自回归Transformer架构；2. 对文本保留下一标记预测，对视觉采用下一尺度预测；3. 多尺度生成的鲁棒训练方法；4. 强化学习的prefix-tuning策略。

Result: 1. 在5秒内生成1024x1024图像，比同类AR模型快几个数量级；2. 在统一模型中达到最先进性能；3. 在视觉质量上可与专门的扩散基线模型相媲美。

Conclusion: NextFlow通过统一的架构和创新的下一尺度预测方法，实现了高效的多模态理解和生成，在速度和视觉质量方面都表现出色，为统一多模态模型提供了新的方向。

Abstract: We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.

</details>


### [113] [Seeing the Unseen: Zooming in the Dark with Event Cameras](https://arxiv.org/abs/2601.02206)
*Dachun Kai,Zeyu Xiao,Huyue Zhu,Jiaxiao Wang,Yueyi Zhang,Xiaoyan Sun*

Main category: cs.CV

TL;DR: RetinexEVSR：首个事件驱动的低光视频超分辨率框架，利用高对比度事件信号和Retinex先验，通过双向跨模态融合策略提升低光视频质量。


<details>
  <summary>Details</summary>
Motivation: 现有低光视频超分辨率方法在恢复细节方面存在困难，主要因为低光条件下对比度有限且高频信息不足。需要一种能够有效利用高对比度事件信号并抑制低光伪影的方法。

Method: 提出RetinexEVSR框架，采用双向跨模态融合策略：1）光照引导的事件增强模块，利用Retinex模型的光照图逐步精炼事件特征；2）事件引导的反射率增强模块，通过多尺度融合机制动态恢复反射率细节。

Result: 在三个数据集上达到最先进性能，在SDSD基准测试中相比先前事件方法获得最高2.95dB增益，同时减少65%运行时间。

Conclusion: RetinexEVSR通过有效融合事件信号和RGB帧，成功解决了低光视频超分辨率中的细节恢复问题，在性能和效率方面均优于现有方法。

Abstract: This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.

</details>


### [114] [Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion](https://arxiv.org/abs/2601.02211)
*Binglei Li,Mengping Yang,Zhiyu Tan,Junping Zhang,Hao Li*

Main category: cs.CV

TL;DR: 本文系统分析了基于MMDiT的扩散模型内部机制，通过移除、禁用和增强文本隐藏状态来研究各模块功能，并基于发现提出了无需训练的策略来改进文本对齐、精确编辑和加速推理。


<details>
  <summary>Details</summary>
Motivation: 尽管基于MMDiT的扩散模型（如FLUX和Qwen Image）在文本到图像生成和编辑方面取得了突破，但现有方法主要分析特定组件（如位置编码和注意力层）的影响，缺乏对不同模块及其与文本条件交互在合成过程中作用的全面理解。

Method: 1）开发系统化分析流程，通过移除、禁用和增强相应模块的文本隐藏状态来全面研究每个模块的功能；2）基于分析发现提出无需训练的新策略，用于改进文本对齐、精确编辑和加速推理。

Result: 分析发现：1）语义信息出现在早期模块，细节在后期模块渲染；2）移除特定模块通常比禁用文本条件破坏性小；3）在选择性模块增强文本条件能改善语义属性。实验表明，该方法在SD3.5上使T2I-Combench++从56.92%提升到63.00%，GenEval从66.42%提升到71.63%，且不牺牲合成质量。

Conclusion: 该方法推进了对MMDiT模型的理解，为未来改进提供了有价值的见解，展示了在文本到图像生成、图像编辑和推理加速方面的灵活性和优越性能。

Abstract: Recent breakthroughs of transformer-based diffusion models, particularly with Multimodal Diffusion Transformers (MMDiT) driven models like FLUX and Qwen Image, have facilitated thrilling experiences in text-to-image generation and editing. To understand the internal mechanism of MMDiT-based models, existing methods tried to analyze the effect of specific components like positional encoding and attention layers. Yet, a comprehensive understanding of how different blocks and their interactions with textual conditions contribute to the synthesis process remains elusive. In this paper, we first develop a systematic pipeline to comprehensively investigate each block's functionality by removing, disabling and enhancing textual hidden-states at corresponding blocks. Our analysis reveals that 1) semantic information appears in earlier blocks and finer details are rendered in later blocks, 2) removing specific blocks is usually less disruptive than disabling text conditions, and 3) enhancing textual conditions in selective blocks improves semantic attributes. Building on these observations, we further propose novel training-free strategies for improved text alignment, precise editing, and acceleration. Extensive experiments demonstrated that our method outperforms various baselines and remains flexible across text-to-image generation, image editing, and inference acceleration. Our method improves T2I-Combench++ from 56.92% to 63.00% and GenEval from 66.42% to 71.63% on SD3.5, without sacrificing synthesis quality. These results advance understanding of MMDiT models and provide valuable insights to unlock new possibilities for further improvements.

</details>


### [115] [FMVP: Masked Flow Matching for Adversarial Video Purification](https://arxiv.org/abs/2601.02228)
*Duoxun Tang,Xueyi Zhang,Chak Hin Wang,Xi Xiao,Dasen Dai,Xinhang Jiang,Wentao Shi,Rui Li,Qing Li*

Main category: cs.CV

TL;DR: FMVP使用流匹配和掩码策略来净化对抗性视频攻击，通过频率门控损失分离语义内容和对抗噪声，在已知和未知攻击下都表现出色。


<details>
  <summary>Details</summary>
Motivation: 视频识别模型容易受到对抗攻击，现有基于扩散的净化方法采样效率低且轨迹弯曲。直接回归干净视频难以恢复忠实内容，需要物理破坏对抗结构。

Method: 提出FMVP方法：1) 通过掩码策略物理破坏全局对抗结构；2) 使用条件流匹配(CFM)和修复目标重建干净视频动态；3) 设计频率门控损失(FGL)抑制高频对抗残差同时保持低频保真度；4) 设计攻击感知和通用训练范式分别处理已知和未知威胁。

Result: 在UCF-101和HMDB-51数据集上，FMVP优于现有方法(DiffPure、DP、TS、FlowPure)，对PGD攻击达到87%以上鲁棒准确率，对CW攻击达到89%。对自适应攻击(DiffHammer)表现出优越鲁棒性，并可作为零样本对抗检测器，对PGD检测准确率98%，对CW检测准确率79%。

Conclusion: FMVP通过物理破坏对抗结构和频率感知重建，有效解决了视频对抗净化问题，在多种攻击场景下表现出优越性能，同时具备对抗检测能力。

Abstract: Video recognition models remain vulnerable to adversarial attacks, while existing diffusion-based purification methods suffer from inefficient sampling and curved trajectories. Directly regressing clean videos from adversarial inputs often fails to recover faithful content due to the subtle nature of perturbations; this necessitates physically shattering the adversarial structure. Therefore, we propose Flow Matching for Adversarial Video Purification FMVP. FMVP physically shatters global adversarial structures via a masking strategy and reconstructs clean video dynamics using Conditional Flow Matching (CFM) with an inpainting objective. To further decouple semantic content from adversarial noise, we design a Frequency-Gated Loss (FGL) that explicitly suppresses high-frequency adversarial residuals while preserving low-frequency fidelity. We design Attack-Aware and Generalist training paradigms to handle known and unknown threats, respectively. Extensive experiments on UCF-101 and HMDB-51 demonstrate that FMVP outperforms state-of-the-art methods (DiffPure, Defense Patterns (DP), Temporal Shuffling (TS) and FlowPure), achieving robust accuracy exceeding 87% against PGD and 89% against CW attacks. Furthermore, FMVP demonstrates superior robustness against adaptive attacks (DiffHammer) and functions as a zero-shot adversarial detector, attaining detection accuracies of 98% for PGD and 79% for highly imperceptible CW attacks.

</details>


### [116] [VIBE: Visual Instruction Based Editor](https://arxiv.org/abs/2601.02242)
*Grigorii Alekseenko,Aleksandr Gordeev,Irina Tolstykh,Bulat Suleimanov,Vladimir Dokholyan,Georgii Fedorov,Sergey Yakubson,Aleksandra Tsybina,Mikhail Chernyshov,Maksim Kuprashevich*

Main category: cs.CV

TL;DR: 本文提出了一种紧凑高效的指令式图像编辑管道，使用2B参数的Qwen3-VL模型指导编辑过程，结合1.6B参数的Sana1.5扩散模型进行图像生成，在保持高质量的同时显著降低了计算成本和内存需求。


<details>
  <summary>Details</summary>
Motivation: 当前指令式图像编辑领域虽然发展迅速，但开源模型中能达到实际应用质量的有限，且主流的扩散模型通常参数庞大（6B-20B），计算成本高昂，限制了在资源受限环境中的部署和研究应用。

Method: 采用轻量级架构设计：使用2B参数的Qwen3-VL模型作为编辑指导器，1.6B参数的Sana1.5扩散模型作为图像生成器。在架构、数据处理、训练配置和评估等方面都针对低成本推理和严格的源一致性进行了优化设计。

Result: 在ImgEdit和GEdit基准测试中，该方法匹配甚至超越了参数规模大数倍、推理成本更高的基线模型。在需要保持输入图像的编辑任务（如属性调整、对象移除、背景编辑和目标替换）上表现尤为出色。模型仅需24GB GPU内存，在NVIDIA H100上以BF16精度生成2K分辨率图像约需4秒。

Conclusion: 该研究证明通过精心设计的轻量级架构，可以在显著降低计算成本和内存需求的同时，实现高质量的指令式图像编辑，为资源受限环境中的部署和研究提供了实用解决方案。

Abstract: Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.

</details>


### [117] [A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets](https://arxiv.org/abs/2601.02246)
*Annoor Sharara Akhand*

Main category: cs.CV

TL;DR: 本文对三种CNN应用范式进行了对比研究：从头训练小型CNN、使用预训练CNN作为固定特征提取器、以及通过微调进行迁移学习。实验表明迁移学习性能最优，而自定义CNN在计算资源受限时提供了较好的效率-准确性平衡。


<details>
  <summary>Details</summary>
Motivation: 在视觉识别任务中，实践者通常面临三种选择：从头训练小型CNN、使用预训练CNN作为固定特征提取器、或通过微调进行迁移学习。本研究旨在通过系统对比这三种范式，为实际应用提供指导。

Method: 在五个真实世界图像分类数据集上进行控制实验：路面缺陷识别、农业品种识别、水果/叶片病害识别、人行道侵占识别、未授权车辆识别。评估指标包括准确率、宏F1分数，以及训练时间、参数量等效率指标。

Result: 迁移学习在所有数据集上均表现出最强的预测性能。自定义CNN在计算和内存预算受限时提供了有吸引力的效率-准确性权衡。预训练CNN作为固定特征提取器的性能介于两者之间。

Conclusion: 迁移学习是获得最佳预测性能的首选方法，而自定义CNN在资源受限场景下提供了实用的效率-准确性平衡。研究结果为不同应用场景下的CNN选择提供了实证依据。

Abstract: Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.

</details>


### [118] [SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection](https://arxiv.org/abs/2601.02249)
*Xiantai Xiang,Guangyao Zhou,Zixiao Wen,Wenshuai Li,Ben Niu,Feng Wang,Lijia Huang,Qiantong Wang,Yuhan Liu,Zongxu Pan,Yuxin Hu*

Main category: cs.CV

TL;DR: SLGNet是一个参数高效的RGB-红外多模态目标检测框架，通过结构感知适配器和语言引导调制模块，在冻结的ViT基础模型上实现高性能检测，大幅减少可训练参数。


<details>
  <summary>Details</summary>
Motivation: 现有基于适配器的方法在将RGB预训练基础模型迁移到多模态检测任务时，往往牺牲跨模态结构一致性以追求模型效率，导致在域差距大的场景（如高对比度或夜间环境）中丢失关键结构线索。同时，传统的静态多模态融合机制缺乏环境感知能力，在复杂动态场景变化下适应性不足。

Method: 提出SLGNet框架：1）结构感知适配器从两种模态提取层次化结构表示，并动态注入ViT以补偿ViT主干的结构退化；2）语言引导调制模块利用VLM驱动的结构化描述动态重新校准视觉特征，赋予模型鲁棒的环境感知能力。

Result: 在LLVIP、FLIR、KAIST和DroneVehicle数据集上的广泛实验表明，SLGNet建立了新的最先进性能。在LLVIP基准测试中达到66.1的mAP，同时相比传统全微调减少约87%的可训练参数。

Conclusion: SLGNet是一个鲁棒且高效的多模态感知解决方案，通过结合层次化结构先验和语言引导调制，在保持参数效率的同时显著提升检测性能。

Abstract: Multimodal object detection leveraging RGB and Infrared (IR) images is pivotal for robust perception in all-weather scenarios. While recent adapter-based approaches efficiently transfer RGB-pretrained foundation models to this task, they often prioritize model efficiency at the expense of cross-modal structural consistency. Consequently, critical structural cues are frequently lost when significant domain gaps arise, such as in high-contrast or nighttime environments. Moreover, conventional static multimodal fusion mechanisms typically lack environmental awareness, resulting in suboptimal adaptation and constrained detection performance under complex, dynamic scene variations. To address these limitations, we propose SLGNet, a parameter-efficient framework that synergizes hierarchical structural priors and language-guided modulation within a frozen Vision Transformer (ViT)-based foundation model. Specifically, we design a Structure-Aware Adapter to extract hierarchical structural representations from both modalities and dynamically inject them into the ViT to compensate for structural degradation inherent in ViT-based backbones. Furthermore, we propose a Language-Guided Modulation module that exploits VLM-driven structured captions to dynamically recalibrate visual features, thereby endowing the model with robust environmental awareness. Extensive experiments on the LLVIP, FLIR, KAIST, and DroneVehicle datasets demonstrate that SLGNet establishes new state-of-the-art performance. Notably, on the LLVIP benchmark, our method achieves an mAP of 66.1, while reducing trainable parameters by approximately 87% compared to traditional full fine-tuning. This confirms SLGNet as a robust and efficient solution for multimodal perception.

</details>


### [119] [VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation](https://arxiv.org/abs/2601.02256)
*Shikun Sun,Liao Qu,Huichao Zhang,Yiheng Liu,Yangyang Song,Xian Li,Xu Wang,Yi Jiang,Daniel K. Du,Xinglong Wu,Jia Jia*

Main category: cs.CV

TL;DR: 本文提出了一种增强GRPO的新框架，通过管理VAR模型中的异步策略冲突，解决了视觉生成中AR、扩散和VAR三种范式中的训练不稳定和对齐问题。


<details>
  <summary>Details</summary>
Motivation: 视觉生成中的VAR模型在生成步骤中存在异构输入结构，导致严重的异步策略冲突，特别是在强化学习场景中，这会造成训练不稳定和对齐效果不佳。

Method: 提出包含三个协同组件的框架：1) 用于引导早期生成的稳定中间奖励；2) 用于精确信用分配的动态时间步重加权方案；3) 基于奖励反馈学习原理的新型掩码传播算法，在空间和时间上隔离优化效果。

Result: 该方法在样本质量和目标对齐方面相比原始GRPO基线有显著改进，实现了对VAR模型的稳健有效优化。

Conclusion: 提出的框架成功解决了VAR模型中的异步策略冲突问题，为视觉生成模型的强化学习优化提供了有效的解决方案。

Abstract: Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.

</details>


### [120] [TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation](https://arxiv.org/abs/2601.02273)
*Salim Khazem*

Main category: cs.CV

TL;DR: TopoLoRA-SAM：基于拓扑感知的低秩适配框架，用于SAM模型的参数高效微调，在视网膜血管等细结构分割任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 基础分割模型如SAM通过大规模预训练展现出强大的零样本泛化能力，但将其适配到特定领域的语义分割（特别是细长结构如视网膜血管和噪声模态如SAR图像）仍然具有挑战性。完全微调计算成本高且存在灾难性遗忘风险。

Method: 提出TopoLoRA-SAM框架，将低秩适配（LoRA）注入冻结的ViT编码器，并增强轻量级空间卷积适配器和可选的拓扑感知监督（通过可微分clDice损失）。

Result: 在五个基准数据集（DRIVE、STARE、CHASE_DB1、Kvasir-SEG、SL-SSDD）上评估，TopoLoRA-SAM在视网膜平均Dice和整体平均Dice上表现最佳，仅训练模型参数的5.2%（约490万参数）。在具有挑战性的CHASE_DB1数据集上显著提升分割准确性和鲁棒性。

Conclusion: 拓扑感知的参数高效适配方法能够匹配甚至超越完全微调的专业模型，为领域特定分割任务提供了一种计算高效的解决方案。

Abstract: Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \textbf{5.2\%} of model parameters ($\sim$4.9M). On the challenging CHASE\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git

</details>


### [121] [InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams](https://arxiv.org/abs/2601.02281)
*Shuai Yuan,Yantai Yang,Xiaotian Yang,Xupeng Zhang,Zhonghao Zhao,Lingming Zhang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: InfiniteVGGT提出了一种因果视觉几何变换器，通过有界自适应KV缓存实现无限视野流式处理，解决了3D几何理解中可扩展性与长期稳定性的矛盾，并引入Long3D基准进行严格评估。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉几何理解方法面临可扩展性与长期稳定性的矛盾：离线模型（如VGGT）虽几何能力强但不适合实时系统；流式架构要么不支持无限视野输入，要么在长序列中产生灾难性漂移。

Method: 提出InfiniteVGGT因果视觉几何变换器，采用有界自适应KV缓存实现滚动记忆机制，结合免训练的注意力无关剪枝策略，智能丢弃过时信息，与FlashAttention完全兼容。

Result: InfiniteVGGT实现了无限视野流式处理，在长期稳定性方面优于现有流式方法，并通过Long3D基准（约10,000帧序列）首次实现了真正无限视野的严格评估。

Conclusion: InfiniteVGGT解决了3D几何理解中长期存在的可扩展性与稳定性矛盾，为未来长期3D几何理解研究提供了关键技术和评估平台。

Abstract: The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT

</details>


### [122] [Rank-based Geographical Regularization: Revisiting Contrastive Self-Supervised Learning for Multispectral Remote Sensing Imagery](https://arxiv.org/abs/2601.02289)
*Tom Burgert,Leonard Hackel,Paolo Rota,Begüm Demir*

Main category: cs.CV

TL;DR: GeoRank是一种用于多光谱遥感图像对比自监督学习的新型正则化方法，通过优化球面距离将地理关系嵌入特征空间，优于或匹配现有方法，并系统研究了对比自监督学习在多光谱遥感图像中的关键适应问题。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在计算机视觉中已取得显著成功，但应用于多光谱遥感图像时面临独特挑战，因为遥感数据具有地理和时间变异性。现有方法未能充分利用地理关系，需要一种能有效嵌入地理信息的正则化方法。

Method: 提出GeoRank方法，通过直接优化球面距离将地理关系嵌入对比自监督学习的特征空间。该方法可应用于多种对比自监督学习算法（如BYOL、DINO），并系统研究了数据增强、数据集规模、图像大小和时间视图等关键适应问题。

Result: GeoRank在性能上优于或匹配那些整合地理元数据的现有方法，并能持续改进多种对比自监督学习算法。研究还发现数据增强的有效性、数据集规模和图像大小对性能的影响，以及时间视图的任务依赖性。

Conclusion: GeoRank为多光谱遥感图像的自监督学习提供了一种有效的正则化方法，通过嵌入地理关系显著提升了学习效果，同时系统研究为遥感领域的自监督学习应用提供了重要指导。

Abstract: Self-supervised learning (SSL) has become a powerful paradigm for learning from large, unlabeled datasets, particularly in computer vision (CV). However, applying SSL to multispectral remote sensing (RS) images presents unique challenges and opportunities due to the geographical and temporal variability of the data. In this paper, we introduce GeoRank, a novel regularization method for contrastive SSL that improves upon prior techniques by directly optimizing spherical distances to embed geographical relationships into the learned feature space. GeoRank outperforms or matches prior methods that integrate geographical metadata and consistently improves diverse contrastive SSL algorithms (e.g., BYOL, DINO). Beyond this, we present a systematic investigation of key adaptations of contrastive SSL for multispectral RS images, including the effectiveness of data augmentations, the impact of dataset cardinality and image size on performance, and the task dependency of temporal views. Code is available at https://github.com/tomburgert/georank.

</details>


### [123] [360DVO: Deep Visual Odometry for Monocular 360-Degree Camera](https://arxiv.org/abs/2601.02309)
*Xiaopeng Guo,Yinzhe Xu,Huajian Huang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: 360DVO是首个基于深度学习的单目全景视觉里程计框架，通过失真感知球面特征提取器和全景可微分束调整模块，在挑战性场景中显著提升了鲁棒性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有的全景视觉里程计系统依赖于手工特征或光度目标，在剧烈运动和光照变化等挑战性场景中缺乏鲁棒性，需要更强大的解决方案。

Method: 提出了360DVO框架，包含失真感知球面特征提取器(DAS-Feat)自适应学习抗失真特征，以及全景可微分束调整(ODBA)模块进行有效位姿估计。

Result: 在真实世界基准测试和公开合成数据集(TartanAir V2和360VO)上的实验表明，360DVO超越现有最佳基线(包括360VO和OpenVSLAM)，鲁棒性提升50%，精度提升37.5%。

Conclusion: 360DVO是首个深度学习驱动的全景视觉里程计框架，通过创新的特征提取和优化模块，在挑战性场景中实现了显著的性能提升，并贡献了新的真实世界基准测试。

Abstract: Monocular omnidirectional visual odometry (OVO) systems leverage 360-degree cameras to overcome field-of-view limitations of perspective VO systems. However, existing methods, reliant on handcrafted features or photometric objectives, often lack robustness in challenging scenarios, such as aggressive motion and varying illumination. To address this, we present 360DVO, the first deep learning-based OVO framework. Our approach introduces a distortion-aware spherical feature extractor (DAS-Feat) that adaptively learns distortion-resistant features from 360-degree images. These sparse feature patches are then used to establish constraints for effective pose estimation within a novel omnidirectional differentiable bundle adjustment (ODBA) module. To facilitate evaluation in realistic settings, we also contribute a new real-world OVO benchmark. Extensive experiments on this benchmark and public synthetic datasets (TartanAir V2 and 360VO) demonstrate that 360DVO surpasses state-of-the-art baselines (including 360VO and OpenVSLAM), improving robustness by 50% and accuracy by 37.5%. Homepage: https://chris1004336379.github.io/360DVO-homepage

</details>


### [124] [Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping](https://arxiv.org/abs/2601.02315)
*Saurabh Kaushik,Lalit Maurya,Beth Tellman*

Main category: cs.CV

TL;DR: Prithvi-CAFE模型通过融合地理基础模型和CNN特征，在洪水制图任务中超越了现有方法，解决了GFMs在捕捉局部细节方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有地理基础模型在洪水制图等下游任务中表现不佳，特别是在捕捉关键局部细节方面存在局限，无法超越基线U-Net模型。

Method: 提出Prithvi-CAFE模型，将Prithvi GFM预训练编码器与并行CNN残差分支结合，使用卷积注意力模块增强，通过适配器实现快速微调，并进行多尺度、多层次特征融合。

Result: 在Sen1Flood11测试数据上IoU达到83.41，优于原始Prithvi(82.50)和其他GFMs；在保留测试站点上IoU 81.37显著优于基线U-Net(70.57)；在FloodPlanet数据集上IoU 64.70也优于所有对比方法。

Conclusion: Prithvi-CAFE是一种简单有效的模型，在需要多通道多模态数据互补信息且局部细节关键的分割任务中展现出强大潜力。

Abstract: Geo-Foundation Models (GFMs), have proven effective in diverse downstream applications, including semantic segmentation, classification, and regression tasks. However, in case of flood mapping using Sen1Flood11 dataset as a downstream task, GFMs struggles to outperform the baseline U-Net, highlighting model's limitation in capturing critical local nuances. To address this, we present the Prithvi-Complementary Adaptive Fusion Encoder (CAFE), which integrate Prithvi GFM pretrained encoder with a parallel CNN residual branch enhanced by Convolutional Attention Modules (CAM). Prithvi-CAFE enables fast and efficient fine-tuning through adapters in Prithvi and performs multi-scale, multi-level fusion with CNN features, capturing critical local details while preserving long-range dependencies. We achieve state-of-the-art results on two comprehensive flood mapping datasets: Sen1Flood11 and FloodPlanet. On Sen1Flood11 test data, Prithvi-CAFE (IoU 83.41) outperforms the original Prithvi (IoU 82.50) and other major GFMs (TerraMind 82.90, DOFA 81.54, spectralGPT: 81.02). The improvement is even more pronounced on the hold-out test site, where Prithvi-CAFE achieves an IoU of 81.37 compared to the baseline U-Net (70.57) and original Prithvi (72.42). On FloodPlanet, Prithvi-CAFE also surpasses the baseline U-Net and other GFMs, achieving an IoU of 64.70 compared to U-Net (60.14), Terramind (62.33), DOFA (59.15) and Prithvi 2.0 (61.91). Our proposed simple yet effective Prithvi-CAFE demonstrates strong potential for improving segmentation tasks where multi-channel and multi-modal data provide complementary information and local details are critical. The code is released on \href{https://github.com/Sk-2103/Prithvi-CAFE}{Prithvi-CAFE Github}

</details>


### [125] [Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding](https://arxiv.org/abs/2601.02339)
*Jingming He,Chongyi Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 提出联合增强框架，通过各向异性3D高斯切比雪夫描述符和语义形状信号自适应调整，提升3D语义高斯建模的语义分割和渲染质量


<details>
  <summary>Details</summary>
Motivation: 现有方法将语义和渲染分支分开处理，仅依赖2D监督而忽略3D高斯几何，自适应策略仅依赖渲染梯度，在细微或无纹理区域效果不佳

Method: 1) 引入各向异性3D高斯切比雪夫描述符捕捉细粒度3D形状细节；2) 基于局部语义和形状信号自适应调整高斯分配和球谐函数；3) 使用跨场景知识转移模块持续更新学习到的形状模式

Result: 在多个数据集上实验表明，在保持高渲染帧率的同时，提升了分割精度和渲染质量

Conclusion: 提出的联合增强框架通过协同语义和渲染分支，结合3D形状描述符和自适应策略，有效提升了3D语义高斯建模的性能

Abstract: Recent works propose extending 3DGS with semantic feature vectors for simultaneous semantic segmentation and image rendering. However, these methods often treat the semantic and rendering branches separately, relying solely on 2D supervision while ignoring the 3D Gaussian geometry. Moreover, current adaptive strategies adapt the Gaussian set depending solely on rendering gradients, which can be insufficient in subtle or textureless regions. In this work, we propose a joint enhancement framework for 3D semantic Gaussian modeling that synergizes both semantic and rendering branches. Firstly, unlike conventional point cloud shape encoding, we introduce an anisotropic 3D Gaussian Chebyshev descriptor using the Laplace-Beltrami operator to capture fine-grained 3D shape details, thereby distinguishing objects with similar appearances and reducing reliance on potentially noisy 2D guidance. In addition, without relying solely on rendering gradient, we adaptively adjust Gaussian allocation and spherical harmonics with local semantic and shape signals, enhancing rendering efficiency through selective resource allocation. Finally, we employ a cross-scene knowledge transfer module to continuously update learned shape patterns, enabling faster convergence and robust representations without relearning shape information from scratch for each new scene. Experiments on multiple datasets demonstrate improvements in segmentation accuracy and rendering quality while maintaining high rendering frame rates.

</details>


### [126] [Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes](https://arxiv.org/abs/2601.02356)
*Jing Tan,Zhaoyang Zhang,Yantao Shen,Jiarui Cai,Shuo Yang,Jiajun Wu,Wei Xia,Zhuowen Tu,Stefano Soatto*

Main category: cs.CV

TL;DR: Talk2Move是一个基于强化学习的扩散框架，通过自然语言指令实现场景中物体的空间变换（平移、旋转、缩放），无需成对监督数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的编辑方法主要调整外观或风格，难以执行对象级别的几何变换（如平移、旋转、缩放），这主要是由于缺乏成对监督数据和像素级优化的限制。

Method: 使用Group Relative Policy Optimization (GRPO)通过输入图像和轻量级文本变体生成多样化的rollouts来探索几何动作；设计空间奖励引导模型将几何变换与语言描述对齐；采用离策略步骤评估和主动步骤采样提高学习效率；设计面向对象的空间奖励直接评估位移、旋转和缩放行为。

Result: 在精心设计的基准测试中，Talk2Move实现了精确、一致且语义忠实的对象变换，在空间准确性和场景连贯性方面均优于现有的文本引导编辑方法。

Conclusion: Talk2Move通过强化学习框架成功解决了文本指导的空间变换问题，无需昂贵的成对数据，实现了可解释且连贯的几何变换。

Abstract: We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.

</details>


### [127] [ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors](https://arxiv.org/abs/2601.02359)
*Kaede Shiohara,Toshihiko Yamasaki,Vladislav Golyanik*

Main category: cs.CV

TL;DR: 提出ExposeAnyone方法，基于扩散模型从音频生成表情序列，通过个性化建模和扩散重建误差实现人物特定的人脸伪造检测，在多个数据集上优于现有方法，并能检测Sora2生成的视频。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测方法难以泛化到未见过的伪造类型，因为它们主要依赖监督训练，容易过拟合到特定的伪造模式。自监督方法虽有泛化潜力，但现有方法难以仅从自监督中学习到有区分度的表示。

Method: 提出ExposeAnyone方法：基于扩散模型从音频生成表情序列。首先将模型个性化到特定人物（使用参考集），然后通过扩散重建误差计算可疑视频与个性化人物之间的身份距离，实现人物特定的人脸伪造检测。

Result: 1) 在DF-TIMIT、DFDCP、KoDF和IDForge数据集上，平均AUC比之前最优方法提升4.22个百分点；2) 能够检测Sora2生成的视频，而之前方法表现不佳；3) 对模糊和压缩等损坏具有高度鲁棒性。

Conclusion: ExposeAnyone是一种完全自监督的方法，通过扩散模型和个性化建模实现了对未知深度伪造的有效检测，在泛化性和鲁棒性方面优于现有方法，具有实际应用价值。

Abstract: Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [128] [Horizon Reduction as Information Loss in Offline Reinforcement Learning](https://arxiv.org/abs/2601.00831)
*Uday Kumar Nidadala,Venkata Bhumika Guthi*

Main category: cs.LG

TL;DR: 本文分析了离线强化学习中视野缩减策略的理论局限性，证明即使在无限数据和完美函数逼近下，固定长度轨迹段学习可能导致最优策略与次优策略统计不可区分，存在不可恢复的信息损失。


<details>
  <summary>Details</summary>
Motivation: 尽管视野缩减在离线强化学习中被广泛用于缓解长视野信用分配、提高稳定性和实现可扩展学习，但其理论影响尚未充分发展。本文旨在揭示视野缩减可能导致根本性且不可恢复的信息损失。

Method: 将视野缩减形式化为从固定长度轨迹段学习，证明在这种范式下，即使有无限数据和完美函数逼近，最优策略也可能与次优策略统计不可区分。通过构建最小反例马尔可夫决策过程，识别了三种结构失效模式。

Result: 发现了三种结构失效模式：(1)前缀不可区分性导致可识别性失败；(2)截断回报引起的目标误设；(3)离线数据集支持和表示混叠。建立了视野缩减安全性的必要条件。

Conclusion: 视野缩减在离线强化学习中存在固有局限性，这些限制无法仅通过算法改进克服。研究结果补充了关于保守目标和分布偏移的算法工作，为安全使用视野缩减提供了理论指导。

Abstract: Horizon reduction is a common design strategy in offline reinforcement learning (RL), used to mitigate long-horizon credit assignment, improve stability, and enable scalable learning through truncated rollouts, windowed training, or hierarchical decomposition (Levine et al., 2020; Prudencio et al., 2023; Park et al., 2025). Despite recent empirical evidence that horizon reduction can improve scaling on challenging offline RL benchmarks, its theoretical implications remain underdeveloped (Park et al., 2025). In this paper, we show that horizon reduction can induce fundamental and irrecoverable information loss in offline RL. We formalize horizon reduction as learning from fixed-length trajectory segments and prove that, under this paradigm and any learning interface restricted to fixed-length trajectory segments, optimal policies may be statistically indistinguishable from suboptimal ones even with infinite data and perfect function approximation. Through a set of minimal counterexample Markov decision processes (MDPs), we identify three distinct structural failure modes: (i) prefix indistinguishability leading to identifiability failure, (ii) objective misspecification induced by truncated returns, and (iii) offline dataset support and representation aliasing. Our results establish necessary conditions under which horizon reduction can be safe and highlight intrinsic limitations that cannot be overcome by algorithmic improvements alone, complementing algorithmic work on conservative objectives and distribution shift that addresses a different axis of offline RL difficulty (Fujimoto et al., 2019; Kumar et al., 2020; Gulcehre et al., 2020).

</details>


### [129] [Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds](https://arxiv.org/abs/2601.00834)
*Julian Evan Chrisnanto,Salsabila Rahma Alia,Nurfauzi Fadillah,Yulison Herry Chrisnanto*

Main category: cs.LG

TL;DR: IM-PINN：一种无需网格的几何深度学习框架，通过在连续参数域中嵌入黎曼度量张量，直接求解复杂非欧流形上的非线性反应-扩散方程，解决了传统方法的高保真网格生成成本和辛漂移问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂非欧流形上模拟非线性反应-扩散动力学面临两大挑战：高保真网格生成成本高昂，以及离散时间步进方案中的辛漂移问题。传统自适应细化方法无法处理极端高斯曲率波动下的各向异性图灵不稳定性。

Method: 提出IM-PINN框架：1）将黎曼度量张量嵌入自动微分图中，解析重建拉普拉斯-贝尔特拉米算子；2）采用双流架构和傅里叶特征嵌入缓解谱偏差；3）在具有极端高斯曲率波动（K∈[-2489,3580]）的"随机布料"流形上验证；4）应用于Gray-Scott模型恢复"分裂斑点"和"迷宫"模式。

Result: IM-PINN在物理严谨性上优于表面有限元法：全局质量守恒误差为0.157（SFEM为0.258）；作为热力学一致的全局求解器，消除了半隐式积分固有的质量漂移；成功恢复了传统方法无法解析的各向异性图灵不稳定性模式。

Conclusion: IM-PINN提供了一个内存高效、分辨率独立的范式，用于在演化表面上模拟生物模式形成，弥合了微分几何和物理信息机器学习之间的鸿沟，为计算形态发生提供了新的解决方案。

Abstract: Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly in the continuous parametric domain. By embedding the Riemannian metric tensor into the automatic differentiation graph, our architecture analytically reconstructs the Laplace-Beltrami operator, decoupling solution complexity from geometric discretization. We validate the framework on a "Stochastic Cloth" manifold with extreme Gaussian curvature fluctuations ($K \in [-2489, 3580]$), where traditional adaptive refinement fails to resolve anisotropic Turing instabilities. Using a dual-stream architecture with Fourier feature embeddings to mitigate spectral bias, the IM-PINN recovers the "splitting spot" and "labyrinthine" regimes of the Gray-Scott model. Benchmarking against the Surface Finite Element Method (SFEM) reveals superior physical rigor: the IM-PINN achieves global mass conservation error of $\mathcal{E}_{mass} \approx 0.157$ versus SFEM's $0.258$, acting as a thermodynamically consistent global solver that eliminates mass drift inherent in semi-implicit integration. The framework offers a memory-efficient, resolution-independent paradigm for simulating biological pattern formation on evolving surfaces, bridging differential geometry and physics-informed machine learning.

</details>


### [130] [SLO-Conditioned Action Routing for Retrieval-Augmented Generation: Objective Ablation and Failure Modes](https://arxiv.org/abs/2601.00841)
*Bharath Nunepalli*

Main category: cs.LG

TL;DR: 本文研究了RAG系统中的查询级控制问题，通过选择检索深度和生成模式来满足成本、拒绝率和幻觉风险等服务级目标，使用离线数据集训练策略，发现固定基线表现良好，学习策略主要在质量优先场景下节省成本。


<details>
  <summary>Details</summary>
Motivation: RAG系统需要根据每个查询动态调整检索深度和生成行为，以满足成本、拒绝率和幻觉风险等服务级目标，但现有研究缺乏对这类控制问题的系统性分析。

Method: 将查询级控制建模为离散动作选择：检索深度、生成模式（保护vs自动）或拒绝。使用SQuAD 2.0构建离线数据集，记录准确性、token成本、幻觉/拒绝指标和SLO加权奖励。评估两种策略学习目标：基于最佳动作的监督分类和奖励加权变体。

Result: 固定基线策略（低k值+保护提示）表现竞争力强；学习策略主要在质量优先的SLO下提供额外成本节省；在成本优先SLO下，当拒绝被高度奖励时可能出现拒绝崩溃现象。

Conclusion: 本文提供了RAG管道SLO感知控制的可重复案例研究，强调失败模式和报告规范，而非提出新的检索器或语言模型，为RAG系统的实际部署提供了重要参考。

Abstract: Retrieval-augmented generation (RAG) introduces a practical control problem: retrieval depth and generation behavior must be chosen per query to satisfy service-level objectives (SLOs) such as cost, refusal rate, and hallucination risk. This work models per-query control as a small discrete action: choose a retrieval depth and a generation mode (guarded vs. auto), or refuse. An offline logged dataset is constructed from SQuAD 2.0 by executing each action and recording accuracy, token cost, hallucination/refusal indicators, and an SLO-weighted reward. Two simple policy-learning objectives are evaluated: supervised classification of the per-state best action (Argmax-CE) and a reward-weighted variant (Argmax-CE-WT). Across the evaluated settings, a strong fixed baseline (low k, guarded prompting) performs competitively; learned policies mainly provide additional cost savings under a quality-focused SLO and can exhibit refusal collapse under a cheap SLO when refusal is heavily rewarded. The contribution is a reproducible case study of SLO-aware control for RAG pipelines, emphasizing failure modes and reporting conventions rather than proposing a new retriever or language model.

</details>


### [131] [Value-guided action planning with JEPA world models](https://arxiv.org/abs/2601.00844)
*Matthieu Destrade,Oumayma Bounou,Quentin Le Lidec,Jean Ponce,Yann LeCun*

Main category: cs.LG

TL;DR: 提出一种增强JEPA世界模型规划能力的方法，通过塑造表示空间使状态嵌入之间的距离近似负目标条件值函数，从而显著提升简单控制任务中的规划性能。


<details>
  <summary>Details</summary>
Motivation: 虽然联合嵌入预测架构（JEPA）为建模环境动态提供了有前景的框架，但其支持有效行动规划的能力仍然有限。需要增强JEPA世界模型的规划能力。

Method: 提出通过塑造JEPA表示空间的方法，使状态嵌入之间的距离（或准距离）能够近似给定环境中到达成本的负目标条件值函数。引入了一种在训练期间强制执行此约束的实用方法。

Result: 该方法在简单控制任务上相比标准JEPA模型显著提升了规划性能。

Conclusion: 通过塑造表示空间使嵌入距离近似负目标条件值函数，可以有效增强JEPA世界模型的规划能力，为构建能够推理环境动态的深度学习模型提供了改进方向。

Abstract: Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by shaping their representation space so that the negative goal-conditioned value function for a reaching cost in a given environment is approximated by a distance (or quasi-distance) between state embeddings. We introduce a practical method to enforce this constraint during training and show that it leads to significantly improved planning performance compared to standard JEPA models on simple control tasks.

</details>


### [132] [You Only Need Your Transformer 25% of the Time: Meaning-First Execution for Eliminating Unnecessary Inference](https://arxiv.org/abs/2601.00847)
*Ryan Shamim*

Main category: cs.LG

TL;DR: MFEE框架将推理重构为控制平面决策问题，通过语义分析选择性执行transformer，在不修改模型的情况下实现78.1%的执行减少，同时保持100%的精确匹配正确性。


<details>
  <summary>Details</summary>
Motivation: 当前AI推理系统将transformer执行视为强制性的，将模型能力与执行必要性混为一谈。作者认为应该将推理重构为控制平面决策问题，确定何时需要执行transformer，何时可以通过替代路径保持正确性。

Method: 提出Meaning-First Execution (MFEE)控制平面架构，作为现有堆栈之上的门控层，不修改模型、权重或参数。通过语义分析选择性调用transformer推理，仅在必要时执行。

Result: 在1000个多样化提示的确定性解码下，MFEE实现78.1%的执行减少，同时保持100%的精确匹配等价性。相比基于模式的路由器最多只能达到53.3%的避免率且存在正确性失败，MFEE通过语义分析实现100%避免率且零失败。

Conclusion: 证明了任何仅基于有限特征图的路由器无法同时保证零错误跳过和正避免率。这些结果确立了执行治理作为ML系统基础设施的基础层，与模型级优化技术正交。

Abstract: Modern AI inference systems treat transformer execution as mandatory, conflating model capability with execution necessity. We reframe inference as a control-plane decision problem: determining when execution is necessary versus when correctness can be preserved through alternative pathways. We introduce Meaning-First Execution (MFEE), a control-plane architecture implementing this framework, selectively invoking transformer inference only when required. MFEE operates as a gating layer above existing stacks without modifying models, weights, or parameters. Across 1,000 diverse prompts under deterministic decoding, MFEE achieves 78.1% execution reduction while maintaining 100% exact-match equivalence for invoked executions. Comparative evaluation reveals pattern-based routers achieve at most 53.3% avoidance with correctness failures, while MFEE reaches 100% avoidance with zero failures through semantic analysis. We prove this limitation via Theorem 1: any router operating solely on finite feature maps cannot simultaneously guarantee zero false skips and positive avoidance on feature-collision pairs. These results establish execution governance as a foundational layer in ML systems infrastructure, orthogonal to model-level optimization techniques.

</details>


### [133] [EdgeJury: Cross-Reviewed Small-Model Ensembles for Truthful Question Answering on Serverless Edge Inference](https://arxiv.org/abs/2601.00850)
*Aayush Kumar*

Main category: cs.LG

TL;DR: EdgeJury是一个轻量级集成框架，使用小型指令调优语言模型（3B-8B）通过四阶段协作流程显著提升问答的真实性和鲁棒性，特别适合边缘部署。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘部署场景中，前沿规模模型或检索管道可能不切实际，而幻觉问题会严重影响问答的可靠性。需要一种轻量级方法来解决小型模型在真实问答中的幻觉问题。

Method: EdgeJury采用四阶段框架：1) 并行角色专业化生成；2) 匿名交叉评审，包含结构化批评和排名；3) 主席合成，整合最强内容并解决标记问题；4) 基于模型间一致性的声明级一致性标记。

Result: 在TruthfulQA（MC1）上达到76.2%准确率，相比单个8B基线（62.8%）提升21.4%；在200个对抗性EdgeCases问题上获得48.2%相对增益；人工分析显示事实性幻觉错误减少约55%；在Cloudflare Workers AI上实现8.4秒中位端到端延迟。

Conclusion: 协调的小型模型集成可以在不依赖外部检索或专有大型模型API的情况下，显著改善对误解密集问答基准的真实性，为资源受限的边缘部署提供实用解决方案。

Abstract: Hallucinations hinder reliable question answering, especially in resource-constrained deployments where frontier-scale models or retrieval pipelines may be impractical. We present EdgeJury, a lightweight ensemble framework that improves truthfulness and robustness using only small instruction-tuned language models (3B-8B) suitable for serverless edge inference. EdgeJury orchestrates four stages: (1) parallel role-specialized generation, (2) anonymized cross-review with structured critiques and rankings, (3) chairman synthesis that integrates the strongest content while addressing flagged issues, and (4) claim-level consistency labeling based on inter-model agreement. On TruthfulQA (MC1), EdgeJury achieves 76.2% accuracy (95% CI: 72.8-79.6%), a +21.4% relative improvement over a single 8B baseline (62.8%), and outperforms standard baselines including self-consistency and majority voting under transparent compute accounting (total tokens and platform cost reported). On a 200-question adversarial EdgeCases set, EdgeJury yields +48.2% relative gains (95% CI: 44.0-52.4%). Manual analysis on 100 incorrect answers shows an approximately 55% reduction in factual hallucination errors versus the single-model baseline. Deployed on Cloudflare Workers AI, EdgeJury achieves 8.4 s median end-to-end latency, demonstrating that coordinated small-model ensembles can improve truthfulness on misconception-heavy QA benchmarks without external retrieval or proprietary large-model APIs.

</details>


### [134] [FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments](https://arxiv.org/abs/2601.00853)
*Sameer Rahil,Zain Abdullah Ahmad,Talha Asif*

Main category: cs.LG

TL;DR: FedSCAM：一种针对联邦学习中非IID数据挑战的新算法，通过动态调整SAM扰动半径和基于客户端异质性分数的聚合权重来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在边缘设备上进行协作训练时面临统计异质性挑战，特别是非独立同分布标签分布问题。现有方法通常对所有客户端使用统一的扰动半径，忽略了客户端特定的异质性，这会影响收敛性和泛化能力。

Method: 提出FedSCAM算法，包含两个核心机制：1）基于客户端异质性分数动态调整SAM扰动半径，对高方差客户端使用较小扰动半径以防止全局模型不稳定；2）引入异质性感知的加权聚合机制，优先考虑与全局优化方向一致的客户端更新。

Result: 在CIFAR-10和Fashion-MNIST数据集上，使用基于狄利克雷分布的不同程度标签偏斜进行实验，FedSCAM在收敛速度和最终测试准确率方面达到了与FedSAM、FedLESAM等最先进基线方法竞争的性能。

Conclusion: FedSCAM通过考虑客户端特定异质性来调整SAM扰动半径和聚合权重，有效解决了联邦学习中的统计异质性挑战，提升了模型在非IID数据环境下的性能表现。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.

</details>


### [135] [Harvesting AlphaEarth: Benchmarking the Geospatial Foundation Model for Agricultural Downstream Tasks](https://arxiv.org/abs/2601.00857)
*Yuchi Ma,Yawen Shen,Anu Swatantran,David B. Lobell*

Main category: cs.LG

TL;DR: 本研究评估了AlphaEarth Foundation (AEF)地理空间基础模型在农业监测任务中的表现，包括作物产量预测、耕作制图和覆盖作物制图三个下游任务，并与传统遥感模型进行比较。


<details>
  <summary>Details</summary>
Motivation: 虽然地理空间基础模型(GFMs)如AEF在土地覆盖分类任务中表现出色，但在农业监测领域的应用缺乏深入评估。需要全面比较AEF模型与传统遥感模型在不同农业场景下的表现，为研究者和实践者提供指导。

Method: 使用AEF预训练模型生成年度全球嵌入数据集，在美国的三个农业下游任务中进行评估：作物产量预测、耕作制图和覆盖作物制图。从公共和私人来源编译数据集，在不同尺度和位置评估AEF嵌入，同时训练传统遥感模型作为对比基准。

Result: AEF模型在所有任务中表现良好，在产量预测和县级耕作制图任务中，当使用本地数据训练时，与专门构建的遥感模型具有竞争力。但AEF嵌入存在空间可迁移性有限、可解释性低、时间敏感性不足等局限性。

Conclusion: AEF嵌入在农业应用中表现出潜力，但在时间敏感性、泛化能力和可解释性要求较高的农业领域需要谨慎使用。当前AEF嵌入存在空间转移能力有限、可解释性不足等局限性，建议在农业应用中注意这些限制。

Abstract: Geospatial foundation models (GFMs) have emerged as a promising approach to overcoming the limitations in existing featurization methods. More recently, Google DeepMind has introduced AlphaEarth Foundation (AEF), a GFM pre-trained using multi-source EOs across continuous time. An annual and global embedding dataset is produced using AEF that is ready for analysis and modeling. The internal experiments show that AEF embeddings have outperformed operational models in 15 EO tasks without re-training. However, those experiments are mostly about land cover and land use classification. Applying AEF and other GFMs to agricultural monitoring require an in-depth evaluation in critical agricultural downstream tasks. There is also a lack of comprehensive comparison between the AEF-based models and traditional remote sensing (RS)-based models under different scenarios, which could offer valuable guidance for researchers and practitioners. This study addresses some of these gaps by evaluating AEF embeddings in three agricultural downstream tasks in the U.S., including crop yield prediction, tillage mapping, and cover crop mapping. Datasets are compiled from both public and private sources to comprehensively evaluate AEF embeddings across tasks at different scales and locations, and RS-based models are trained as comparison models. AEF-based models generally exhibit strong performance on all tasks and are competitive with purpose-built RS-based models in yield prediction and county-level tillage mapping when trained on local data. However, we also find several limitations in current AEF embeddings, such as limited spatial transferability compared to RS-based models, low interpretability, and limited time sensitivity. These limitations recommend caution when applying AEF embeddings in agriculture, where time sensitivity, generalizability, and interpretability is important.

</details>


### [136] [Path Integral Solution for Dissipative Generative Dynamics](https://arxiv.org/abs/2601.00860)
*Xidi Wang*

Main category: cs.LG

TL;DR: 该论文证明纯机械系统通过耗散量子动力学和非局部上下文聚合可以生成智能语言，而守恒定律会导致根本性失败。语言生成本质上是耗散量子场论，智能通过耗散和非局域性获得，而非守恒。


<details>
  <summary>Details</summary>
Motivation: 探索纯机械系统是否能够生成智能语言，研究量子动力学中的耗散与非局域性在语言生成中的作用，挑战传统认为守恒定律是智能系统基础的观点。

Method: 采用具有封闭形式路径积分传播子的Koopman算子方法，分析耗散量子动力学中的非局部上下文聚合机制，通过谱分析揭示特征值结构（衰减模式、增长模式、中性模式）。

Result: 证明耗散量子动力学能够产生连贯的文本生成，而哈密顿约束会消除耗散模式并导致性能下降。谱分析显示特征值结构分离为衰减模式（遗忘）、增长模式（放大）和中性模式（保持），这些是定向信息流的基本要素。

Conclusion: 语言生成本质上是耗散量子场论，机械系统通过耗散和非局域性的组合获得智能，而非通过守恒定律。受控信息耗散和因果上下文聚合是智能语言生成的根本要求。

Abstract: Can purely mechanical systems generate intelligent language? We prove that dissipative quantum dynamics with analytically tractable non-local context aggregation produce coherent text generation, while conservation laws cause fundamental failure. Employing Koopman operators with closed-form path integral propagators, we show irreversible computation fundamentally requires both controlled information dissipation and causal context aggregation. Spectral analysis reveals emergent eigenvalue structure, separating into decay modes (forgetting), growth modes (amplification), and neutral modes (preservation) -- the essential ingredients for directed information flow. Hamiltonian constraints force the elimination of these dissipative modes and degrading performance despite unchanged model capacity. This establishes language generation as dissipative quantum field theory, proving mechanical systems acquire intelligence through the combination of dissipation and non-locality, not through conservation.

</details>


### [137] [Outlier Detection Using Vector Cosine Similarity by Adding a Dimension](https://arxiv.org/abs/2601.00883)
*Zhongyang Shen*

Main category: cs.LG

TL;DR: 提出基于向量余弦相似度的多维异常检测方法，通过在原数据添加零值维度构建新数据集，利用观测点与测量点的向量相似度比较来识别异常值


<details>
  <summary>Details</summary>
Motivation: 需要一种有效的多维数据异常检测方法，能够处理复杂的高维数据分布，传统方法可能在高维空间中效果不佳

Method: 在原数据添加一个零值维度构建新数据集，选择测量点后创建观测点（原点），观测点与测量点仅在新维度有非零值差异，然后计算从观测点到测量点及其他点的向量余弦相似度进行比较

Result: 开发了优化实现MDOD并已在PyPI发布，该方法能够有效识别多维数据中的异常值

Conclusion: 提出的基于向量余弦相似度的异常检测方法为多维数据分析提供了新的有效工具，MDOD的实现便于实际应用

Abstract: We propose a new outlier detection method for multi-dimensional data. The method detects outliers based on vector cosine similarity, using a new dataset constructed by adding a dimension with zero values to the original data. When a point in the new dataset is selected as the measured point, an observation point is created as the origin, differing only in the new dimension by having a non-zero value compared to the measured point. Vectors are then formed from the observation point to the measured point and to other points in the dataset. By comparing the cosine similarities of these vectors, abnormal data can be identified. An optimized implementation (MDOD) is available on PyPI: https://pypi.org/project/mdod/.

</details>


### [138] [FANoS: Friction-Adaptive Nosé--Hoover Symplectic Momentum for Stiff Objectives](https://arxiv.org/abs/2601.00889)
*Nalin Dhiman*

Main category: cs.LG

TL;DR: FANoS是一种受物理启发的优化器，结合了二阶动力系统、Nosé-Hoover恒温器和辛积分器，在Rosenbrock-100D基准测试中表现优于AdamW和SGD+momentum，但在其他问题上表现不稳定。


<details>
  <summary>Details</summary>
Motivation: 将分子动力学中的结构保持积分和恒温器思想应用于优化问题，开发一种物理启发的优化器，旨在处理一些非凸优化问题中的困难区域。

Method: FANoS结合了三个核心组件：(1) 作为离散化二阶动力系统的动量更新；(2) 使用动能反馈自适应调整摩擦系数的Nosé-Hoover类恒温器变量；(3) 半隐式（辛-欧拉）积分器，可选配对角RMS预处理器。

Result: 在Rosenbrock-100D基准测试中，FANoS-RMS达到平均最终目标值1.74×10⁻²，显著优于未裁剪的AdamW（48.50）和SGD+momentum（90.76）。但在病态凸二次问题和小型PINN预热测试中，FANoS表现不如AdamW且不稳定。

Conclusion: FANoS是现有思想的可解释性综合，在某些非凸山谷问题上可能有帮助，但不是现代基线的通用替代品，其行为对温度调度和超参数选择敏感。

Abstract: We study a physics-inspired optimizer, \emph{FANoS} (Friction-Adaptive Nosé--Hoover Symplectic momentum), which combines (i) a momentum update written as a discretized second-order dynamical system, (ii) a Nosé--Hoover-like thermostat variable that adapts a scalar friction coefficient using kinetic-energy feedback, and (iii) a semi-implicit (symplectic-Euler) integrator, optionally with a diagonal RMS preconditioner. The method is motivated by structure-preserving integration and thermostat ideas from molecular dynamics, but is used here purely as an optimization heuristic.
  We provide the algorithm and limited theoretical observations in idealized settings. On the deterministic Rosenbrock-100D benchmark with 3000 gradient evaluations, FANoS-RMS attains a mean final objective value of $1.74\times 10^{-2}$, improving substantially over unclipped AdamW ($48.50$) and SGD+momentum ($90.76$) in this protocol. However, AdamW with gradient clipping is stronger, reaching $1.87\times 10^{-3}$, and L-BFGS reaches $\approx 4.4\times 10^{-10}$. On ill-conditioned convex quadratics and in a small PINN warm-start suite (Burgers and Allen--Cahn), the default FANoS configuration underperforms AdamW and can be unstable or high-variance.
  Overall, the evidence supports a conservative conclusion: FANoS is an interpretable synthesis of existing ideas that can help on some stiff nonconvex valleys, but it is not a generally superior replacement for modern baselines, and its behavior is sensitive to temperature-schedule and hyperparameter choices.

</details>


### [139] [Hierarchical topological clustering](https://arxiv.org/abs/2601.00892)
*Ana Carpio,Gema Duro*

Main category: cs.LG

TL;DR: 提出了一种层次化拓扑聚类算法，可处理任意形状的聚类和离群点，适用于图像、医疗和经济数据


<details>
  <summary>Details</summary>
Motivation: 拓扑方法能够在不假设数据结构的情况下探索数据云，需要一种能够处理任意形状聚类和离群点的聚类算法

Method: 提出层次化拓扑聚类算法，可使用任意距离度量，通过层次结构推断离群点和任意形状聚类的持续性

Result: 在包含图像、医疗和经济数据的选定数据集上展示了算法的潜力，这些数据中离群点起重要作用

Conclusion: 该方法在其他技术失败的情况下仍能提供有意义的聚类，具有实际应用价值

Abstract: Topological methods have the potential of exploring data clouds without making assumptions on their the structure. Here we propose a hierarchical topological clustering algorithm that can be implemented with any distance choice. The persistence of outliers and clusters of arbitrary shape is inferred from the resulting hierarchy. We demonstrate the potential of the algorithm on selected datasets in which outliers play relevant roles, consisting of images, medical and economic data. These methods can provide meaningful clusters in situations in which other techniques fail to do so.

</details>


### [140] [Dichotomous Diffusion Policy Optimization](https://arxiv.org/abs/2601.00898)
*Ruiming Liang,Yinan Zheng,Kexin Zheng,Tianyi Tan,Jianxiong Li,Liyuan Mao,Zhihao Wang,Guang Chen,Hangjun Ye,Jingjing Liu,Jinqiao Wang,Xianyuan Zhan*

Main category: cs.LG

TL;DR: DIPOLE是一种新颖的强化学习算法，通过将最优策略分解为一对稳定学习的二分策略（一个最大化奖励，一个最小化奖励），解决了扩散策略在RL训练中的不稳定性和计算问题，并在推理时通过线性组合实现贪婪度的灵活控制。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散策略在强化学习中面临两大挑战：直接最大化价值目标导致训练不稳定，或依赖粗糙的高斯似然近似需要大量小去噪步骤导致计算问题。需要一种既能稳定训练又能灵活控制推理生成的方法。

Method: 提出DIPOLE算法：1) 重新审视RL中的KL正则化目标，提供扩散策略提取的加权回归目标；2) 设计贪婪化策略正则化方案，将最优策略分解为一对二分策略（奖励最大化和最小化策略）；3) 在推理时通过线性组合二分策略的分数来生成优化动作，实现贪婪度的灵活控制。

Result: 在ExORL和OGBench的离线和离线到在线RL设置中验证了方法的有效性。还成功训练了用于端到端自动驾驶的大型视觉-语言-动作模型，并在大规模真实世界自动驾驶基准NAVSIM上进行了评估，展示了在复杂现实应用中的潜力。

Conclusion: DIPOLE通过二分策略分解和线性组合机制，为扩散策略的强化学习训练提供了稳定、可控的优化方法，在多个基准测试和真实世界自动驾驶任务中表现出色，具有广泛的应用前景。

Abstract: Diffusion-based policies have gained growing popularity in solving a wide range of decision-making tasks due to their superior expressiveness and controllable generation during inference. However, effectively training large diffusion policies using reinforcement learning (RL) remains challenging. Existing methods either suffer from unstable training due to directly maximizing value objectives, or face computational issues due to relying on crude Gaussian likelihood approximation, which requires a large amount of sufficiently small denoising steps. In this work, we propose DIPOLE (Dichotomous diffusion Policy improvement), a novel RL algorithm designed for stable and controllable diffusion policy optimization. We begin by revisiting the KL-regularized objective in RL, which offers a desirable weighted regression objective for diffusion policy extraction, but often struggles to balance greediness and stability. We then formulate a greedified policy regularization scheme, which naturally enables decomposing the optimal policy into a pair of stably learned dichotomous policies: one aims at reward maximization, and the other focuses on reward minimization. Under such a design, optimized actions can be generated by linearly combining the scores of dichotomous policies during inference, thereby enabling flexible control over the level of greediness.Evaluations in offline and offline-to-online RL settings on ExORL and OGBench demonstrate the effectiveness of our approach. We also use DIPOLE to train a large vision-language-action (VLA) model for end-to-end autonomous driving (AD) and evaluate it on the large-scale real-world AD benchmark NAVSIM, highlighting its potential for complex real-world applications.

</details>


### [141] [Conformal Prediction Under Distribution Shift: A COVID-19 Natural Experiment](https://arxiv.org/abs/2601.00908)
*Chorok Lee*

Main category: cs.LG

TL;DR: 研究发现在分布偏移下，保形预测的覆盖保证会下降，特别是在特征严重变化的情况下。通过COVID-19供应链任务分析发现，覆盖下降程度差异巨大（0%-86.7%），与单特征依赖性高度相关。提出基于SHAP特征重要性集中度的决策框架来指导模型部署和重训练策略。


<details>
  <summary>Details</summary>
Motivation: 保形预测在分布偏移下的性能保证会下降，但具体下降程度和机制尚不清楚。研究者利用COVID-19作为自然实验，研究供应链任务中特征变化对保形预测覆盖保证的影响，特别是探索为什么不同任务在相同特征变化程度下表现差异如此巨大。

Method: 使用COVID-19作为自然实验，分析8个供应链任务。通过Jaccard相似度衡量特征变化程度，使用SHAP分析特征重要性分布。比较不同任务在相同特征严重变化（Jaccard≈0）下的覆盖下降差异，并通过相关性分析（rho=0.714, p=0.047）验证单特征依赖性与灾难性失败的关系。对灾难性任务进行季度重训练实验，并扩展分析4个中等特征稳定性任务。

Result: 在相同特征严重变化下，不同任务的覆盖下降差异巨大（0%-86.7%）。灾难性失败与单特征依赖性高度相关（rho=0.714），灾难性任务的特征重要性集中在单一特征（增加4.5倍），而稳健任务则分散到多个特征（10-20倍）。季度重训练可将灾难性任务覆盖从22%提升到41%，但对稳健任务无益（保持99.8%覆盖）。中等特征稳定性任务的分析表明，特征稳定性而非集中度决定稳健性。

Conclusion: 提出基于SHAP特征重要性集中度的决策框架：部署前监控SHAP集中度；如果集中度>40%（易受攻击）则进行季度重训练；如果稳健则跳过重训练。特征集中度效应主要适用于严重分布偏移情况，而特征稳定性是决定模型稳健性的关键因素。

Abstract: Conformal prediction guarantees degrade under distribution shift. We study this using COVID-19 as a natural experiment across 8 supply chain tasks. Despite identical severe feature turnover (Jaccard approximately 0), coverage drops vary from 0% to 86.7%, spanning two orders of magnitude. Using SHapley Additive exPlanations (SHAP) analysis, we find catastrophic failures correlate with single-feature dependence (rho = 0.714, p = 0.047). Catastrophic tasks concentrate importance in one feature (4.5x increase), while robust tasks redistribute across many (10-20x). Quarterly retraining restores catastrophic task coverage from 22% to 41% (+19 pp, p = 0.04), but provides no benefit for robust tasks (99.8% coverage). Exploratory analysis of 4 additional tasks with moderate feature stability (Jaccard 0.13-0.86) reveals feature stability, not concentration, determines robustness, suggesting concentration effects apply specifically to severe shifts. We provide a decision framework: monitor SHAP concentration before deployment; retrain quarterly if vulnerable (>40% concentration); skip retraining if robust.

</details>


### [142] [Latent-Constrained Conditional VAEs for Augmenting Large-Scale Climate Ensembles](https://arxiv.org/abs/2601.00915)
*Jacquelyn Shelton,Przemyslaw Polewski,Alexander Robel,Matthew Hoffman,Stephen Price*

Main category: cs.LG

TL;DR: 提出LC-CVAE方法，通过强制潜在空间在共享"锚点"位置的一致性，解决传统CVAE在气候模型生成中泛化能力差的问题，实现从有限气候模拟中生成统计一致的时空变量新实现。


<details>
  <summary>Details</summary>
Motivation: 大型气候模型集合计算成本高昂，但许多下游分析需要更多统计一致的时空气候变量实现。现有方法在有限模拟数据上训练时泛化能力不足，无法生成未见过的集合成员。

Method: 提出潜在约束条件变分自编码器(LC-CVAE)，在共享地理"锚点"位置强制潜在嵌入的跨实现同质性。然后使用多输出高斯过程回归在潜在空间预测新实现中未采样位置的潜在坐标，最后解码生成完整时间序列场。

Result: 实验表明：1) 在单个实现上训练不稳定；2) 纳入约5个实现后收益递减；3) 空间覆盖范围与重建质量之间存在权衡，这与潜在空间中的平均邻近距离密切相关。

Conclusion: LC-CVAE通过潜在空间约束解决了传统CVAE在气候模型生成中的泛化问题，能够在有限训练数据下生成统计一致的新气候实现，为气候模型集合扩展提供了有效方法。

Abstract: Large climate-model ensembles are computationally expensive; yet many downstream analyses would benefit from additional, statistically consistent realizations of spatiotemporal climate variables. We study a generative modeling approach for producing new realizations from a limited set of available runs by transferring structure learned across an ensemble. Using monthly near-surface temperature time series from ten independent reanalysis realizations (ERA5), we find that a vanilla conditional variational autoencoder (CVAE) trained jointly across realizations yields a fragmented latent space that fails to generalize to unseen ensemble members. To address this, we introduce a latent-constrained CVAE (LC-CVAE) that enforces cross-realization homogeneity of latent embeddings at a small set of shared geographic 'anchor' locations. We then use multi-output Gaussian process regression in the latent space to predict latent coordinates at unsampled locations in a new realization, followed by decoding to generate full time series fields. Experiments and ablations demonstrate (i) instability when training on a single realization, (ii) diminishing returns after incorporating roughly five realizations, and (iii) a trade-off between spatial coverage and reconstruction quality that is closely linked to the average neighbor distance in latent space.

</details>


### [143] [Attention Needs to Focus: A Unified Perspective on Attention Allocation](https://arxiv.org/abs/2601.00919)
*Zichuan Fu,Wentao Song,Guojing Li,Yejing Wang,Xian Wu,Yimin Deng,Hanyu Yan,Yefeng Zheng,Xiangyu Zhao*

Main category: cs.LG

TL;DR: 本文提出Lazy Attention机制，通过统一视角解决Transformer中注意力机制的两个核心问题：注意力过载和注意力欠载，从而提高注意力分布的聚焦性。


<details>
  <summary>Details</summary>
Motivation: Transformer架构中的标准注意力机制存在两个已知问题：表示崩溃和注意力沉没。现有研究通常孤立地处理这些问题，而本文认为它们有共同的根源——不恰当的注意力分配。

Method: 提出Lazy Attention机制：1) 针对注意力过载，采用跨头和维度的位置区分来增强token区分度；2) 针对注意力欠载，引入Elastic-Softmax归一化函数，放松标准softmax约束以抑制对无关token的关注。

Result: 在FineWeb-Edu语料库上的实验表明，Lazy Attention成功缓解了注意力沉没问题，在九个不同基准测试中与标准注意力和现代架构相比具有竞争力，同时达到高达59.58%的注意力稀疏度。

Conclusion: Lazy Attention通过统一视角解决注意力分配问题，为Transformer架构提供了更聚焦的注意力分布机制，在保持性能的同时实现了显著的注意力稀疏性。

Abstract: The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.

</details>


### [144] [MODE: Efficient Time Series Prediction with Mamba Enhanced by Low-Rank Neural ODEs](https://arxiv.org/abs/2601.00920)
*Xingsheng Chen,Regina Zhang,Bo Gao,Xingwei He,Xiaofeng Liu,Pietro Lio,Kwok-Yan Lam,Siu-Ming Yiu*

Main category: cs.LG

TL;DR: MODE：一个结合低秩神经ODE和增强Mamba架构的统一时间序列预测框架，在效率和精度上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法在效率、可扩展性和准确性之间存在平衡困难，特别是在处理长程依赖和不规则采样数据时表现不佳。需要一种能够同时解决这些挑战的统一框架。

Method: 提出MODE框架：1）使用线性标记化层处理输入序列；2）通过多个增强Mamba编码器块处理，每个块包含因果卷积、SiLU激活和低秩神经ODE增强；3）采用分段选择性扫描机制，受伪ODE动力学启发，自适应关注重要子序列；4）低秩公式减少计算开销同时保持表达能力。

Result: 在基准数据集上的广泛实验表明，MODE在预测准确性和计算效率方面均超越现有基线方法。

Conclusion: MODE为长期时间序列建模提供了一个统一高效架构，通过将Mamba的选择性扫描与低秩神经ODE集成，实现了增强的时间表示能力，并通过低秩近似和动态选择性扫描显著提升了效率和可扩展性。

Abstract: Time series prediction plays a pivotal role across diverse domains such as finance, healthcare, energy systems, and environmental modeling. However, existing approaches often struggle to balance efficiency, scalability, and accuracy, particularly when handling long-range dependencies and irregularly sampled data. To address these challenges, we propose MODE, a unified framework that integrates Low-Rank Neural Ordinary Differential Equations (Neural ODEs) with an Enhanced Mamba architecture. As illustrated in our framework, the input sequence is first transformed by a Linear Tokenization Layer and then processed through multiple Mamba Encoder blocks, each equipped with an Enhanced Mamba Layer that employs Causal Convolution, SiLU activation, and a Low-Rank Neural ODE enhancement to efficiently capture temporal dynamics. This low-rank formulation reduces computational overhead while maintaining expressive power. Furthermore, a segmented selective scanning mechanism, inspired by pseudo-ODE dynamics, adaptively focuses on salient subsequences to improve scalability and long-range sequence modeling. Extensive experiments on benchmark datasets demonstrate that MODE surpasses existing baselines in both predictive accuracy and computational efficiency. Overall, our contributions include: (1) a unified and efficient architecture for long-term time series modeling, (2) integration of Mamba's selective scanning with low-rank Neural ODEs for enhanced temporal representation, and (3) substantial improvements in efficiency and scalability enabled by low-rank approximation and dynamic selective scanning.

</details>


### [145] [Practical Geometric and Quantum Kernel Methods for Predicting Skeletal Muscle Outcomes in chronic obstructive pulmonary disease](https://arxiv.org/abs/2601.00921)
*Azadeh Alavi,Hamidreza Khalili,Stanley H. Chan,Fatemeh Kouchmeshki,Ross Vlahos*

Main category: cs.LG

TL;DR: 该研究使用量子核回归和几何感知方法预测COPD小鼠模型的肌肉功能指标，在低数据、低特征生物医学预测中显示出优势。


<details>
  <summary>Details</summary>
Motivation: 慢性阻塞性肺疾病（COPD）的骨骼肌功能障碍与全身和气道炎症密切相关，需要从微创生物标志物预测肌肉结局，特别是针对小样本临床前数据集。

Method: 使用213只动物（Sham组与香烟烟雾暴露组）的小样本临床前数据集，比较了调优的经典基线模型、几何感知对称正定描述符与Stein散度、以及针对低维表格数据设计的量子核模型。量子核岭回归使用四个可解释输入（血液C反应蛋白、中性粒细胞计数、支气管肺泡灌洗细胞性和条件）预测肌肉重量。

Result: 在肌肉重量预测中，量子核岭回归的测试均方根误差为4.41 mg，决定系数为0.605，优于相同特征集的匹配岭回归基线（4.70 mg和0.553）。几何感知的Stein散度原型距离在仅使用生物标志物的设置中也获得了一致但较小的改进（4.55 mg vs 4.79 mg）。通过阈值化连续结果进行筛查式评估，检测低肌肉重量的ROC-AUC高达0.90。

Conclusion: 几何和量子核提升方法在低数据、低特征的生物医学预测问题中能提供可测量的优势，同时保持可解释性和透明的模型选择。

Abstract: Skeletal muscle dysfunction is a clinically relevant extra-pulmonary manifestation of chronic obstructive pulmonary disease (COPD) and is closely linked to systemic and airway inflammation. This motivates predictive modelling of muscle outcomes from minimally invasive biomarkers that can be acquired longitudinally. We study a small-sample preclinical dataset comprising 213 animals across two conditions (Sham versus cigarette-smoke exposure), with blood and bronchoalveolar lavage fluid measurements and three continuous targets: tibialis anterior muscle weight (milligram: mg), specific force (millinewton: mN), and a derived muscle quality index (mN per mg). We benchmark tuned classical baselines, geometry-aware symmetric positive definite (SPD) descriptors with Stein divergence, and quantum kernel models designed for low-dimensional tabular data. In the muscle-weight setting, quantum kernel ridge regression using four interpretable inputs (blood C-reactive protein, neutrophil count, bronchoalveolar lavage cellularity, and condition) attains a test root mean squared error of 4.41 mg and coefficient of determination of 0.605, improving over a matched ridge baseline on the same feature set (4.70 mg and 0.553). Geometry-informed Stein-divergence prototype distances yield a smaller but consistent gain in the biomarker-only setting (4.55 mg versus 4.79 mg). Screening-style evaluation, obtained by thresholding the continuous outcome at 0.8 times the training Sham mean, achieves an area under the receiver operating characteristic curve (ROC-AUC) of up to 0.90 for detecting low muscle weight. These results indicate that geometric and quantum kernel lifts can provide measurable benefits in low-data, low-feature biomedical prediction problems, while preserving interpretability and transparent model selection.

</details>


### [146] [Complexity-based code embeddings](https://arxiv.org/abs/2601.00924)
*Rares Folea,Radu Iacob,Emil Slusanschi,Traian Rebedea*

Main category: cs.LG

TL;DR: 提出了一种将算法源代码转换为数值嵌入的通用方法，通过动态分析程序在不同输入下的行为，并为分析指标定制多个通用复杂度函数，基于r-Complexity构建代码嵌入，并在Codeforces真实代码片段数据集上实现了XGBoost算法，取得了良好的多标签分类性能。


<details>
  <summary>Details</summary>
Motivation: 需要一种通用的方法来将不同算法的源代码转换为数值嵌入，以便进行机器学习处理和分析。通过动态分析程序行为和使用复杂度函数，可以更好地捕捉代码的语义特征。

Method: 提出了一种通用的源代码转换方法：1）动态分析计算机程序在不同输入下的行为；2）为分析指标定制多个通用复杂度函数；3）基于r-Complexity构建算法嵌入；4）使用这些嵌入实现XGBoost算法进行多标签分类。

Result: 在基于Codeforces平台真实代码片段构建的11类多标签数据集上，使用提出的代码嵌入实现的XGBoost算法取得了良好的平均F1分数。

Conclusion: 该方法能够有效地将源代码转换为数值嵌入，为代码分析和机器学习任务提供了有效的特征表示，在真实世界的编程竞赛代码数据集上验证了其有效性。

Abstract: This paper presents a generic method for transforming the source code of various algorithms to numerical embeddings, by dynamically analysing the behaviour of computer programs against different inputs and by tailoring multiple generic complexity functions for the analysed metrics. The used algorithms embeddings are based on r-Complexity . Using the proposed code embeddings, we present an implementation of the XGBoost algorithm that achieves an average F1-score on a multi-label dataset with 11 classes, built using real-world code snippets submitted for programming competitions on the Codeforces platform.

</details>


### [147] [Reliability Under Randomness: An Empirical Analysis of Sparse and Dense Language Models Across Decoding Temperatures](https://arxiv.org/abs/2601.00942)
*Kabir Grover*

Main category: cs.LG

TL;DR: 稀疏MoE架构在随机解码下的可靠性研究表明，指令微调而非架构稀疏性是决定模型在确定性任务中鲁棒性的主要因素。


<details>
  <summary>Details</summary>
Motivation: 随着稀疏MoE架构在大型语言模型中的普及，需要研究其在随机解码下的可靠性。虽然条件计算带来了计算效率的提升，但稀疏路由与基于温度的采样之间的相互作用是否会损害输出稳定性尚不明确。

Method: 评估三个代表性模型：OLMoE-7B（稀疏基础模型）、Mixtral-8x7B（稀疏指令微调模型）和Qwen2.5-3B（密集指令微调模型）。在确定性算术推理任务上进行测试，涵盖四种解码配置（从贪婪解码到T=1.0），评估准确性、格式合规性、重复生成的一致性和置信度指标，总计9,360次模型生成。

Result: 稀疏指令微调模型在所有解码温度下表现出与密集指令微调模型相当的稳定性，而稀疏基础模型随着温度升高出现系统性性能下降。这表明指令微调而非架构稀疏性是决定模型在确定性任务中对解码随机性鲁棒性的主要因素。

Conclusion: 指令微调是确保稀疏语言模型在可靠性关键应用中稳定性的关键因素，在某些场景下稀疏架构可以被安全采用而不牺牲输出稳定性。

Abstract: The increasing prevalence of sparse Mixture-of-Experts (MoE) architectures in large language models raises important questions regarding their reliability under stochastic decoding. While conditional computation enables substantial gains in computational efficiency, it remains unclear whether the interaction between sparse routing and temperature-based sampling compromises output stability relative to dense architectures. This work investigates whether conditional computation in MoE models amplifies decoding-induced randomness, leading to reduced reliability as temperature increases. We evaluate three representative models: OLMoE-7B (sparse base), Mixtral-8x7B (sparse instruction-tuned), and Qwen2.5-3B (dense instruction-tuned) on deterministic arithmetic reasoning tasks with objectively verifiable answers. Experiments span four decoding configurations, ranging from greedy decoding to T=1.0. Our evaluation encompasses accuracy, format compliance, output consistency across repeated generations, and confidence metrics, totaling 9,360 model generations. Results demonstrate that the sparse instruction-tuned model exhibits stability comparable to the dense instruction-tuned model across all decoding temperatures, while the sparse base model shows systematic degradation as temperature increases. These findings indicate that instruction tuning, rather than architectural sparsity, is the primary determinant of robustness to decoding randomness on deterministic tasks. We discuss the implications of these results for deploying sparse language models in reliability-critical applications, highlighting scenarios in which sparse architectures can be safely adopted without sacrificing output stability.

</details>


### [148] [Explainability-Guided Defense: Attribution-Aware Model Refinement Against Adversarial Data Attacks](https://arxiv.org/abs/2601.00968)
*Longwei Wang,Mohammad Navid Nayyem,Abdullah Al Rakin,KC Santosh,Chaowei Zhang,Yang Zhou*

Main category: cs.LG

TL;DR: 提出一种基于LIME解释的主动训练框架，通过抑制虚假特征来同时提升模型对抗鲁棒性和可解释性


<details>
  <summary>Details</summary>
Motivation: 在医疗和自动驾驶等安全关键领域，深度学习模型需要同时具备对抗鲁棒性和决策透明度。研究发现，通过LIME识别的虚假、不稳定或语义无关特征会显著增加对抗脆弱性。

Method: 提出归因引导的精炼框架，将LIME从被动诊断工具转变为主动训练信号。通过特征掩蔽、敏感感知正则化和对抗增强的闭环精炼流程，系统性地抑制虚假特征。

Result: 在CIFAR-10、CIFAR-10-C和CIFAR-100数据集上的实验表明，该方法显著提升了对抗鲁棒性和分布外泛化能力，无需额外数据集或模型架构。

Conclusion: 建立了可解释性与鲁棒性之间的理论联系，通过主动利用解释信息来提升模型性能，为安全关键应用提供了实用的训练框架。

Abstract: The growing reliance on deep learning models in safety-critical domains such as healthcare and autonomous navigation underscores the need for defenses that are both robust to adversarial perturbations and transparent in their decision-making. In this paper, we identify a connection between interpretability and robustness that can be directly leveraged during training. Specifically, we observe that spurious, unstable, or semantically irrelevant features identified through Local Interpretable Model-Agnostic Explanations (LIME) contribute disproportionately to adversarial vulnerability. Building on this insight, we introduce an attribution-guided refinement framework that transforms LIME from a passive diagnostic into an active training signal. Our method systematically suppresses spurious features using feature masking, sensitivity-aware regularization, and adversarial augmentation in a closed-loop refinement pipeline. This approach does not require additional datasets or model architectures and integrates seamlessly into standard adversarial training. Theoretically, we derive an attribution-aware lower bound on adversarial distortion that formalizes the link between explanation alignment and robustness. Empirical evaluations on CIFAR-10, CIFAR-10-C, and CIFAR-100 demonstrate substantial improvements in adversarial robustness and out-of-distribution generalization.

</details>


### [149] [Contractive Diffusion Policies: Robust Action Diffusion via Contractive Score-Based Sampling with Differential Equations](https://arxiv.org/abs/2601.01003)
*Amin Abyaneh,Charlotte Morissette,Mohamad H. Danesh,Anas El Houssaini,David Meger,Gregory Dudek,Hsiu-Chin Lin*

Main category: cs.LG

TL;DR: 本文提出收缩扩散策略（CDPs），通过在扩散采样动力学中引入收缩行为来增强离线策略学习的鲁棒性，减少求解器和分数匹配误差，在数据稀缺时表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 扩散策略虽然强大，但其基于分数的SDE建模在连续控制中会累积求解器误差、分数匹配误差，需要大量数据，并导致动作生成不一致。这些在图像生成中不太关键的问题在控制任务中会累积导致失败。

Method: 提出收缩扩散策略（CDPs），在扩散采样动力学中引入收缩行为，使相邻流线相互靠近，从而增强对求解器和分数匹配误差的鲁棒性，减少不必要的动作方差。提供理论分析和实践实现方案，可最小修改地集成到现有扩散策略架构中。

Result: 在仿真和真实世界环境中进行广泛实验，CDPs在基准测试中通常优于基线策略，在数据稀缺情况下表现出更明显的优势。

Conclusion: 收缩扩散策略通过引入收缩行为有效解决了扩散策略在连续控制中的误差累积问题，提高了鲁棒性和性能，特别是在数据有限的情况下。

Abstract: Diffusion policies have emerged as powerful generative models for offline policy learning, whose sampling process can be rigorously characterized by a score function guiding a Stochastic Differential Equation (SDE). However, the same score-based SDE modeling that grants diffusion policies the flexibility to learn diverse behavior also incurs solver and score-matching errors, large data requirements, and inconsistencies in action generation. While less critical in image generation, these inaccuracies compound and lead to failure in continuous control settings. We introduce Contractive Diffusion Policies (CDPs) to induce contractive behavior in the diffusion sampling dynamics. Contraction pulls nearby flows closer to enhance robustness against solver and score-matching errors while reducing unwanted action variance. We develop an in-depth theoretical analysis along with a practical implementation recipe to incorporate CDPs into existing diffusion policy architectures with minimal modification and computational cost. We evaluate CDPs for offline learning by conducting extensive experiments in simulation and real-world settings. Across benchmarks, CDPs often outperform baseline policies, with pronounced benefits under data scarcity.

</details>


### [150] [Expanding the Chaos: Neural Operator for Stochastic (Partial) Differential Equations](https://arxiv.org/abs/2601.01021)
*Dai Shi,Lequan Lin,Andi Han,Luke Thompson,José Miguel Hernández-Lobato,Zhiyong Wang,Junbin Gao*

Main category: cs.LG

TL;DR: 基于Wiener混沌展开的神经算子架构，用于学习SDE/SPDE的解算子，通过正交Wick Hermite特征投影噪声路径，用神经算子参数化确定性混沌系数，实现从噪声到完整解轨迹的单次前向计算。


<details>
  <summary>Details</summary>
Motivation: 随机微分方程和随机偏微分方程是建模随机动力学的基础工具，开发深度学习模型近似其解算子不仅能提供快速实用的求解器，还能为经典学习任务提供新视角。

Method: 基于经典Wiener混沌展开设计神经算子架构：将驱动噪声路径投影到正交Wick Hermite特征上，用神经算子参数化确定性混沌系数，实现从噪声到完整解轨迹的单次前向计算。

Result: 在多个问题上验证模型：经典SPDE基准测试、图像扩散一步采样、图拓扑插值、金融外推、参数估计以及洪水预测的流形SDE，展示了竞争性精度和广泛适用性。

Conclusion: 基于Wiener混沌展开的神经算子为学习SDE/SPDE解算子提供了实用且可扩展的方法，在多个领域表现出色。

Abstract: Stochastic differential equations (SDEs) and stochastic partial differential equations (SPDEs) are fundamental tools for modeling stochastic dynamics across the natural sciences and modern machine learning. Developing deep learning models for approximating their solution operators promises not only fast, practical solvers, but may also inspire models that resolve classical learning tasks from a new perspective. In this work, we build on classical Wiener chaos expansions (WCE) to design neural operator (NO) architectures for SPDEs and SDEs: we project the driving noise paths onto orthonormal Wick Hermite features and parameterize the resulting deterministic chaos coefficients with neural operators, so that full solution trajectories can be reconstructed from noise in a single forward pass. On the theoretical side, we investigate the classical WCE results for the class of multi-dimensional SDEs and semilinear SPDEs considered here by explicitly writing down the associated coupled ODE/PDE systems for their chaos coefficients, which makes the separation between stochastic forcing and deterministic dynamics fully explicit and directly motivates our model designs. On the empirical side, we validate our models on a diverse suite of problems: classical SPDE benchmarks, diffusion one-step sampling on images, topological interpolation on graphs, financial extrapolation, parameter estimation, and manifold SDEs for flood prediction, demonstrating competitive accuracy and broad applicability. Overall, our results indicate that WCE-based neural operators provide a practical and scalable way to learn SDE/SPDE solution operators across diverse domains.

</details>


### [151] [Wireless Dataset Similarity: Measuring Distances in Supervised and Unsupervised Machine Learning](https://arxiv.org/abs/2601.01023)
*João Morais,Sadjad Alikhani,Akshay Malhotra,Shahab Hamidi-Rad,Ahmed Alkhateeb*

Main category: cs.LG

TL;DR: 本文提出了一个任务和模型感知的无线数据集相似性度量框架，通过数据集距离预测模型跨数据集可迁移性，在CSI压缩和波束预测任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 无线通信中需要评估不同数据集之间的相似性，以支持数据集选择/增强、仿真到真实场景比较、任务特定合成数据生成等应用，但现有方法缺乏任务相关性。

Method: 提出任务和模型感知框架，通过数据集距离预测模型跨数据集可迁移性。使用UMAP嵌入结合Wasserstein和欧氏距离度量无监督任务，在监督任务中集成监督UMAP和数据集不平衡惩罚。

Result: 在CSI压缩任务中，UMAP嵌入结合Wasserstein和欧氏距离的度量方法达到超过0.85的皮尔逊相关系数；在波束预测任务中，标签感知距离方法优于传统基线，与模型可迁移性相关性更强。

Conclusion: 该框架能够有效度量无线数据集之间的相似性，支持任务相关的数据集比较，为数据集选择、模型训练和适应新部署提供决策依据。

Abstract: This paper introduces a task- and model-aware framework for measuring similarity between wireless datasets, enabling applications such as dataset selection/augmentation, simulation-to-real (sim2real) comparison, task-specific synthetic data generation, and informing decisions on model training/adaptation to new deployments. We evaluate candidate dataset distance metrics by how well they predict cross-dataset transferability: if two datasets have a small distance, a model trained on one should perform well on the other. We apply the framework on an unsupervised task, channel state information (CSI) compression, using autoencoders. Using metrics based on UMAP embeddings, combined with Wasserstein and Euclidean distances, we achieve Pearson correlations exceeding 0.85 between dataset distances and train-on-one/test-on-another task performance. We also apply the framework to a supervised beam prediction in the downlink using convolutional neural networks. For this task, we derive a label-aware distance by integrating supervised UMAP and penalties for dataset imbalance. Across both tasks, the resulting distances outperform traditional baselines and consistently exhibit stronger correlations with model transferability, supporting task-relevant comparisons between wireless datasets.

</details>


### [152] [Coarse-Grained Kullback--Leibler Control of Diffusion-Based Generative AI](https://arxiv.org/abs/2601.01045)
*Tatsuaki Tsuruyama*

Main category: cs.LG

TL;DR: 该研究将信息论Lyapunov函数框架移植到生成模型的逆向扩散过程，提出V-delta投影逆向扩散方法，实现对粗粒度统计量的显式控制。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型和基于分数的生成模型缺乏描述粗粒度统计量（如图像分块后的块强度或类别比例）在逆向扩散过程中如何保持和演化的理论框架。

Method: 将信息论Lyapunov函数V移植到生成模型的逆向扩散过程，提出V-delta投影逆向扩散方案；扩展V的单调性到时间非齐次块保持马尔可夫核；通过块常数图像和简化逆向核的玩具模型进行数值验证。

Result: 在小的泄漏和V-delta投影条件下，V-delta可作为近似Lyapunov函数；数值实验表明该方法能将块质量误差和泄漏容忍势保持在预设容差内，同时保持与非投影动态相当的像素级精度和视觉质量。

Conclusion: 该研究将生成采样重新解释为从噪声到数据的信息势下降过程，为具有粗粒度统计量显式控制的逆向扩散过程提供了设计原则。

Abstract: Diffusion models and score-based generative models provide a powerful framework for synthesizing high-quality images from noise. However, there is still no satisfactory theory that describes how coarse-grained quantities, such as blockwise intensity or class proportions after partitioning an image into spatial blocks, are preserved and evolve along the reverse diffusion dynamics. In previous work, the author introduced an information-theoretic Lyapunov function V for non-ergodic Markov processes on a state space partitioned into blocks, defined as the minimal Kullback-Leibler divergence to the set of stationary distributions reachable from a given initial condition, and showed that a leak-tolerant potential V-delta with a prescribed tolerance for block masses admits a closed-form expression as a scaling-and-clipping operation on block masses.
  In this paper, I transplant this framework to the reverse diffusion process in generative models and propose a reverse diffusion scheme that is projected by the potential V-delta (referred to as the V-delta projected reverse diffusion). I extend the monotonicity of V to time-inhomogeneous block-preserving Markov kernels and show that, under small leakage and the V-delta projection, V-delta acts as an approximate Lyapunov function. Furthermore, using a toy model consisting of block-constant images and a simplified reverse kernel, I numerically demonstrate that the proposed method keeps the block-mass error and the leak-tolerant potential within the prescribed tolerance, while achieving pixel-wise accuracy and visual quality comparable to the non-projected dynamics. This study reinterprets generative sampling as a decrease of an information potential from noise to data, and provides a design principle for reverse diffusion processes with explicit control of coarse-grained quantities.

</details>


### [153] [A UCB Bandit Algorithm for General ML-Based Estimators](https://arxiv.org/abs/2601.01061)
*Yajing Liu,Erkao Bao,Linqi Song*

Main category: cs.LG

TL;DR: ML-UCB算法将任意机器学习模型集成到多臂老虎机框架中，通过直接建模底层估计器的学习曲线行为，克服了传统方法需要可处理集中不等式的问题。


<details>
  <summary>Details</summary>
Motivation: 在序列决策中部署复杂ML模型面临的主要挑战是缺乏用于原则性探索的可处理集中不等式。现有方法通常需要针对特定模型进行理论分析，限制了通用性。

Method: 提出ML-UCB算法，假设均方误差随训练样本数呈幂律下降，推导出广义集中不等式。该框架允许集成任何学习曲线可经验表征的ML模型，无需模型特定的理论分析。

Result: 证明了ML-UCB能够实现次线性遗憾。在协同过滤推荐系统的实验中，使用在线矩阵分解和模拟简化双塔模型的合成数据，相比LinUCB取得了显著改进。

Conclusion: ML-UCB为将任意机器学习模型原则性地集成到多臂老虎机框架中提供了通用解决方案，通过建模学习曲线行为克服了传统集中不等式的限制。

Abstract: We present ML-UCB, a generalized upper confidence bound algorithm that integrates arbitrary machine learning models into multi-armed bandit frameworks. A fundamental challenge in deploying sophisticated ML models for sequential decision-making is the lack of tractable concentration inequalities required for principled exploration. We overcome this limitation by directly modeling the learning curve behavior of the underlying estimator. Specifically, assuming the Mean Squared Error decreases as a power law in the number of training samples, we derive a generalized concentration inequality and prove that ML-UCB achieves sublinear regret. This framework enables the principled integration of any ML model whose learning curve can be empirically characterized, eliminating the need for model-specific theoretical analysis. We validate our approach through experiments on a collaborative filtering recommendation system using online matrix factorization with synthetic data designed to simulate a simplified two-tower model, demonstrating substantial improvements over LinUCB

</details>


### [154] [SPoRC-VIST: A Benchmark for Evaluating Generative Natural Narrative in Vision-Language Models](https://arxiv.org/abs/2601.01062)
*Yunlin Zeng*

Main category: cs.LG

TL;DR: 该研究开发了一个端到端的视觉播客生成系统，通过微调Qwen3-VL-32B模型，使用合成到真实的训练策略，在4000个图像-对话对上进行训练，显著提升了多说话者播客对话的生成质量。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在描述性任务上表现出色，但在生成引人入胜的长篇叙事（特别是多说话者播客对话）方面仍有待探索且难以评估。标准评估指标无法捕捉对话自然度、个性和叙事流畅性等细微差别。

Method: 1. 开发端到端视觉播客生成管道；2. 在4000个图像-对话对数据集上微调Qwen3-VL-32B模型；3. 采用合成到真实的训练策略：在SPoRC的高质量播客对话与合成生成图像上训练，在VIST的真实照片序列上评估；4. 提出综合评估框架，使用AI作为评判员和新型风格指标。

Result: 微调的32B模型在对话自然度上显著优于235B基础模型（胜率>80%），叙事深度增加50%（轮次长度），同时保持相同的视觉基础能力（CLIPScore: 20.39）。

Conclusion: 该研究证明了通过精心设计的训练策略和综合评估框架，相对较小的模型（32B）可以在生成引人入胜的多说话者播客对话方面超越更大的基础模型，为视觉叙事生成提供了新的方法和评估标准。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success in descriptive tasks such as image captioning and visual question answering (VQA). However, their ability to generate engaging, long-form narratives -- specifically multi-speaker podcast dialogues -- remains under-explored and difficult to evaluate. Standard metrics like BLEU and ROUGE fail to capture the nuances of conversational naturalness, personality, and narrative flow, often rewarding safe, repetitive outputs over engaging storytelling. In this work, we present a novel pipeline for end-to-end visual podcast generation, and fine-tune a Qwen3-VL-32B model on a curated dataset of 4,000 image-dialogue pairs. Crucially, we use a synthetic-to-real training strategy: we train on high-quality podcast dialogues from the Structured Podcast Research Corpus (SPoRC) paired with synthetically generated imagery, and evaluate on real-world photo sequences from the Visual Storytelling Dataset (VIST). This rigorous setup tests the model's ability to generalize from synthetic training data to real-world visual domains. We propose a comprehensive evaluation framework that moves beyond textual overlap, and use AI-as-a-judge (Gemini 3 Pro, Claude Opus 4.5, GPT 5.2) and novel style metrics (average turn length, speaker switch rate) to assess quality. Our experiments demonstrate that our fine-tuned 32B model significantly outperforms a 235B base model in conversational naturalness ($>$80\% win rate) and narrative depth (+50\% turn length), while maintaining identical visual grounding capabilities (CLIPScore: 20.39).

</details>


### [155] [Tiny Machine Learning for Real-Time Aquaculture Monitoring: A Case Study in Morocco](https://arxiv.org/abs/2601.01065)
*Achraf Hsain,Yahya Zaki,Othman Abaakil,Hibat-allah Bekkar,Yousra Chtouki*

Main category: cs.LG

TL;DR: 本文提出将基于TinyML的低功耗边缘设备集成到水产养殖系统中，实现实时自动化监测和控制，以解决水质波动、疾病爆发和饲料管理效率低等挑战。


<details>
  <summary>Details</summary>
Motivation: 水产养殖业面临水质波动、疾病爆发和饲料管理效率低等挑战，传统监测方法依赖人工劳动且耗时，可能导致问题处理延迟。需要更智能、实时的监测解决方案。

Method: 集成基于TinyML的低功耗边缘设备，通过传感器实时收集pH值、温度、溶解氧、氨氮水平等参数数据，实现自动化监测、异常检测报警和控制功能。

Result: 系统能够实时监测水质参数，自动触发警报，减少人工需求，收集的数据可用于优化水处理过程、饲料分配和饲料效率分析，降低运营成本。

Conclusion: TinyML技术在水产养殖监测中具有可行性，能够促进更可持续和高效的养殖实践发展，但需要考虑传感器选择、算法设计、硬件约束和伦理因素。

Abstract: Aquaculture, the farming of aquatic organisms, is a rapidly growing industry facing challenges such as water quality fluctuations, disease outbreaks, and inefficient feed management. Traditional monitoring methods often rely on manual labor and are time consuming, leading to potential delays in addressing issues. This paper proposes the integration of low-power edge devices using Tiny Machine Learning (TinyML) into aquaculture systems to enable real-time automated monitoring and control, such as collecting data and triggering alarms, and reducing labor requirements. The system provides real-time data on the required parameters such as pH levels, temperature, dissolved oxygen, and ammonia levels to control water quality, nutrient levels, and environmental conditions enabling better maintenance, efficient resource utilization, and optimal management of the enclosed aquaculture space. The system enables alerts in case of anomaly detection. The data collected by the sensors over time can serve for important decision-making regarding optimizing water treatment processes, feed distribution, feed pattern analysis and improve feed efficiency, reducing operational costs. This research explores the feasibility of developing TinyML-based solutions for aquaculture monitoring, considering factors such as sensor selection, algorithm design, hardware constraints, and ethical considerations. By demonstrating the potential benefits of TinyML in aquaculture, our aim is to contribute to the development of more sustainable and efficient farming practices.

</details>


### [156] [Revisiting Weighted Strategy for Non-stationary Parametric Bandits and MDPs](https://arxiv.org/abs/2601.01069)
*Jing Wang,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 论文提出了一种改进的加权策略分析框架，用于非平稳参数化赌博机问题，简化了算法设计并提升了理论性能。


<details>
  <summary>Details</summary>
Motivation: 非平稳参数化赌博机中，加权策略在实际应用中很常见，但现有理论分析复杂且算法效率低或统计性能不优。作者发现这是因为现有分析框架不足，导致算法设计过于复杂。

Method: 提出了一个精炼的分析框架，简化了加权策略的推导过程。基于此框架设计了更简单的加权算法，并扩展到广义线性赌博机、自协调赌博机以及具有函数近似的非平稳马尔可夫决策过程。

Result: 在线性赌博机中，新算法与窗口/重启算法一样高效，同时保持相同的遗憾界。在广义线性赌博机中，获得了更好的遗憾界：$\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$，优于之前的$\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$。框架还成功扩展到线性混合MDP和多项Logit混合MDP。

Conclusion: 新的分析框架解决了加权策略在非平稳参数化赌博机中的理论分析难题，简化了算法设计，提升了性能，并能扩展到更广泛的强化学习问题中。

Abstract: Non-stationary parametric bandits have attracted much attention recently. There are three principled ways to deal with non-stationarity, including sliding-window, weighted, and restart strategies. As many non-stationary environments exhibit gradual drifting patterns, the weighted strategy is commonly adopted in real-world applications. However, previous theoretical studies show that its analysis is more involved and the algorithms are either computationally less efficient or statistically suboptimal. This paper revisits the weighted strategy for non-stationary parametric bandits. In linear bandits (LB), we discover that this undesirable feature is due to an inadequate regret analysis, which results in an overly complex algorithm design. We propose a \emph{refined analysis framework}, which simplifies the derivation and, importantly, produces a simpler weight-based algorithm that is as efficient as window/restart-based algorithms while retaining the same regret as previous studies. Furthermore, our new framework can be used to improve regret bounds of other parametric bandits, including Generalized Linear Bandits (GLB) and Self-Concordant Bandits (SCB). For example, we develop a simple weighted GLB algorithm with an $\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$ regret, improving the $\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$ bound in prior work, where $k_μ$ and $c_μ$ characterize the reward model's nonlinearity, $P_T$ measures the non-stationarity, $d$ and $T$ denote the dimension and time horizon. Moreover, we extend our framework to non-stationary Markov Decision Processes (MDPs) with function approximation, focusing on Linear Mixture MDP and Multinomial Logit (MNL) Mixture MDP. For both classes, we propose algorithms based on the weighted strategy and establish dynamic regret guarantees using our analysis framework.

</details>


### [157] [Discount Model Search for Quality Diversity Optimization in High-Dimensional Measure Spaces](https://arxiv.org/abs/2601.01082)
*Bryon Tjanaka,Henry Chen,Matthew C. Fontaine,Stefanos Nikolaidis*

Main category: cs.LG

TL;DR: DMS算法通过使用平滑连续折扣值模型解决高维度量空间中QD优化的失真问题，超越现有算法并支持图像作为度量空间的新应用


<details>
  <summary>Details</summary>
Motivation: 传统QD算法在高维度量空间中存在失真问题，即许多解映射到相似的度量值，导致探索停滞。CMA-MAE等算法在高维空间中因使用直方图记录折扣值而失效，需要新方法支持高维度量空间的应用

Method: 提出折扣模型搜索（DMS），使用提供平滑连续折扣值表示的模型来指导探索。该模型能够区分具有相似度量的解，从而在高维度量空间中继续探索

Result: DMS在高维基准测试和两个新领域（以图像作为度量空间）中表现优于CMA-MAE和其他黑盒QD算法，支持用户通过提供图像数据集而非手动设计度量函数来指定所需度量

Conclusion: DMS通过连续折扣模型解决了高维度量空间中的失真问题，扩展了QD算法的应用范围，特别是在图像作为度量空间的场景中表现出色

Abstract: Quality diversity (QD) optimization searches for a collection of solutions that optimize an objective while attaining diverse outputs of a user-specified, vector-valued measure function. Contemporary QD algorithms focus on low-dimensional measures because high-dimensional measures are prone to distortion, where many solutions found by the QD algorithm map to similar measures. For example, the CMA-MAE algorithm guides measure space exploration with a histogram in measure space that records so-called discount values. However, CMA-MAE stagnates in domains with high-dimensional measure spaces because solutions with similar measures fall into the same histogram cell and thus receive identical discount values. To address these limitations, we propose Discount Model Search (DMS), which guides exploration with a model that provides a smooth, continuous representation of discount values. In high-dimensional measure spaces, this model enables DMS to distinguish between solutions with similar measures and thus continue exploration. We show that DMS facilitates new QD applications by introducing two domains where the measure space is the high-dimensional space of images, which enables users to specify their desired measures by providing a dataset of images rather than hand-designing the measure function. Results in these domains and on high-dimensional benchmarks show that DMS outperforms CMA-MAE and other black-box QD algorithms.

</details>


### [158] [Community-Based Early-Stage Chronic Kidney Disease Screening using Explainable Machine Learning for Low-Resource Settings](https://arxiv.org/abs/2601.01119)
*Muhammad Ashad Kabir,Sirajam Munira,Dewan Tasnia Azad,Saleh Mohammed Ikram,Mohammad Habibur Rahman Sarker,Syed Manzoor Ahmed Hanifi*

Main category: cs.LG

TL;DR: 开发了一个针对孟加拉国和南亚人群的可解释机器学习框架，用于社区早期慢性肾病筛查，相比现有工具显著提高了准确性和敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有慢性肾病筛查工具主要基于高收入国家人群开发，在孟加拉国和南亚地区表现不佳，且大多依赖简单的加法评分函数，基于晚期肾病数据，无法捕捉风险因素的复杂相互作用，难以预测早期肾病。

Method: 使用孟加拉国社区数据集（南亚首个此类数据集），评估12种机器学习分类器，应用10种互补特征选择技术识别稳健预测因子，采用10折交叉验证，在印度、阿联酋和孟加拉国的三个独立数据集上进行外部验证，使用SHAP提供模型可解释性。

Result: RFECV特征子集训练的模型平衡准确率达90.40%，最小非病理测试特征集平衡准确率达89.23%，常优于更大或完整特征集。相比现有筛查工具，准确性和敏感性显著提高且输入更少。外部验证显示78%-98%敏感性，SHAP识别出与已知CKD风险因素一致的临床有意义预测因子。

Conclusion: 开发的可解释机器学习框架为低资源环境下的社区早期慢性肾病筛查提供了有效解决方案，针对南亚人群定制，具有强泛化能力和临床可解释性。

Abstract: Early detection of chronic kidney disease (CKD) is essential for preventing progression to end-stage renal disease. However, existing screening tools - primarily developed using populations from high-income countries - often underperform in Bangladesh and South Asia, where risk profiles differ. Most of these tools rely on simple additive scoring functions and are based on data from patients with advanced-stage CKD. Consequently, they fail to capture complex interactions among risk factors and are limited in predicting early-stage CKD. Our objective was to develop and evaluate an explainable machine learning (ML) framework for community-based early-stage CKD screening for low-resource settings, tailored to the Bangladeshi and South Asian population context. We used a community-based dataset from Bangladesh, the first such CKD dataset in South and South Asia, and evaluated twelve ML classifiers across multiple feature domains. Ten complementary feature selection techniques were applied to identify robust, generalizable predictors. The final models were assessed using 10-fold cross-validation. External validation was conducted on three independent datasets from India, the UAE, and Bangladesh. SHAP (SHapley Additive exPlanations) was used to provide model explainability. An ML model trained on an RFECV-selected feature subset achieved a balanced accuracy of 90.40%, whereas minimal non-pathology-test features demonstrated excellent predictive capability with a balanced accuracy of 89.23%, often outperforming larger or full feature sets. Compared with existing screening tools, the proposed models achieved substantially higher accuracy and sensitivity while requiring fewer and more accessible inputs. External validation confirmed strong generalizability with 78% to 98% sensitivity. SHAP interpretation identified clinically meaningful predictors consistent with established CKD risk factors.

</details>


### [159] [Wittgenstein's Family Resemblance Clustering Algorithm](https://arxiv.org/abs/2601.01127)
*Golbahar Amanpour,Benyamin Ghojogh*

Main category: cs.LG

TL;DR: 该论文提出了一种基于维特根斯坦家族相似性哲学概念的聚类算法WFR，无需预先指定聚类数量或假设聚类形状，通过构建相似性图实现非线性聚类。


<details>
  <summary>Details</summary>
Motivation: 受维特根斯坦哲学中"家族相似性"概念的启发，该概念认为类别成员通过重叠的相似性而非单一共同特征相联系，这种思想自然适用于机器学习中的图方法，为开发新的聚类算法提供了理论基础。

Method: 提出了WFR（维特根斯坦家族相似性）聚类算法及其核变体kernel WFR。算法计算相邻数据实例之间的相似性得分，通过阈值处理后构建相似性图，该图的连通分量即形成最终聚类。

Result: 在基准数据集上的模拟实验表明，WFR是一种有效的非线性聚类算法，不需要预先知道聚类数量，也不需要对聚类形状做出假设。

Conclusion: 将哲学概念（维特根斯坦的家族相似性）与机器学习技术相结合，成功开发出了一种新的聚类方法，展示了跨学科方法在算法设计中的潜力。

Abstract: This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms a chain of items sharing overlapping traits. This philosophical idea naturally lends itself to a graph-based approach in machine learning. Accordingly, we propose the Wittgenstein's Family Resemblance (WFR) clustering algorithm and its kernel variant, kernel WFR. This algorithm computes resemblance scores between neighboring data instances, and after thresholding these scores, a resemblance graph is constructed. The connected components of this graph define the resulting clusters. Simulations on benchmark datasets demonstrate that WFR is an effective nonlinear clustering algorithm that does not require prior knowledge of the number of clusters or assumptions about their shapes.

</details>


### [160] [Self-Training the Neurochaos Learning Algorithm](https://arxiv.org/abs/2601.01146)
*Anusree M,Akhila Henry,Pramod P Nair*

Main category: cs.LG

TL;DR: 该研究提出了一种结合神经混沌学习与自训练的半监督学习架构，用于解决标注数据稀缺和不平衡数据集的问题，在低数据场景下显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，获取大量标注数据既困难又昂贵，而未标注数据则容易获取。传统的监督学习方法在标注数据稀少或数据集不平衡的情况下表现不佳，因此需要开发能够有效利用未标注数据的半监督学习方法。

Method: 提出了一种混合半监督学习架构，将神经混沌学习与基于阈值的自训练方法相结合。神经混沌学习将输入特征转换为混沌发放率表示，捕捉数据中的非线性关系；自训练方法则利用高置信度的伪标注样本逐步扩大标注数据集。

Result: 在10个基准数据集和5种机器学习分类器上评估模型性能，其中85%的训练数据被视为未标注，仅15%用作标注数据。提出的自训练神经混沌学习架构相比独立的自训练模型获得了显著性能提升，特别是在有限、非线性和不平衡数据集上，如Iris（188.66%）、Wine（158.58%）和Glass Identification（110.48%）。

Conclusion: 将基于混沌的特征提取与半监督学习相结合，在低数据场景下能够改善模型的泛化能力、鲁棒性和分类准确性，为解决标注数据稀缺问题提供了有效方案。

Abstract: In numerous practical applications, acquiring substantial quantities of labelled data is challenging and expensive, but unlabelled data is readily accessible. Conventional supervised learning methods frequently underperform in scenarios characterised by little labelled data or imbalanced datasets. This study introduces a hybrid semi-supervised learning (SSL) architecture that integrates Neurochaos Learning (NL) with a threshold-based Self-Training (ST) method to overcome this constraint. The NL architecture converts input characteristics into chaos-based ring-rate representations that encapsulate nonlinear relationships within the data, whereas ST progressively enlarges the labelled set utilising high-confidence pseudo-labelled samples. The model's performance is assessed using ten benchmark datasets and five machine learning classifiers, with 85% of the training data considered unlabelled and just 15% utilised as labelled data. The proposed Self-Training Neurochaos Learning (NL+ST) architecture consistently attains superior performance gain relative to standalone ST models, especially on limited, nonlinear and imbalanced datasets like Iris (188.66%), Wine (158.58%) and Glass Identification (110.48%). The results indicate that using chaos-based feature extraction with SSL improves generalisation, resilience, and classification accuracy in low-data contexts.

</details>


### [161] [Evo-TFS: Evolutionary Time-Frequency Domain-Based Synthetic Minority Oversampling Approach to Imbalanced Time Series Classification](https://arxiv.org/abs/2601.01150)
*Wenbin Pei,Ruohao Dai,Bing Xue,Mengjie Zhang,Qiang Zhang,Yiu-Ming Cheung*

Main category: cs.LG

TL;DR: Evo-TFS：一种结合时域和频域特征的进化过采样方法，用于解决不平衡时间序列分类问题，通过强类型遗传编程生成高质量的时间序列样本。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习时间序列分类方法假设数据分布平衡，但在实际应用中数据往往不平衡，导致少数类被忽略。现有的过采样方法依赖线性插值，难以保持时间动态特性和生成多样样本。

Method: 提出Evo-TFS方法，使用强类型遗传编程同时结合时域和频域特征来进化生成多样化的高质量时间序列样本。通过包含时域和频域特征的适应度函数来指导进化过程。

Result: 在不平衡时间序列数据集上的实验表明，Evo-TFS优于现有的过采样方法，显著提升了时域和频域分类器的性能。

Conclusion: Evo-TFS通过进化方法结合时域和频域特征，有效解决了不平衡时间序列分类问题，能够生成高质量、多样化的少数类样本，提升分类器性能。

Abstract: Time series classification is a fundamental machine learning task with broad real-world applications. Although many deep learning methods have proven effective in learning time-series data for classification, they were originally developed under the assumption of balanced data distributions. Once data distribution is uneven, these methods tend to ignore the minority class that is typically of higher practical significance. Oversampling methods have been designed to address this by generating minority-class samples, but their reliance on linear interpolation often hampers the preservation of temporal dynamics and the generation of diverse samples. Therefore, in this paper, we propose Evo-TFS, a novel evolutionary oversampling method that integrates both time- and frequency-domain characteristics. In Evo-TFS, strongly typed genetic programming is employed to evolve diverse, high-quality time series, guided by a fitness function that incorporates both time-domain and frequency-domain characteristics. Experiments conducted on imbalanced time series datasets demonstrate that Evo-TFS outperforms existing oversampling methods, significantly enhancing the performance of time-domain and frequency-domain classifiers.

</details>


### [162] [Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models](https://arxiv.org/abs/2601.01162)
*Zihua Yang,Xin Liao,Yiqun Zhang,Yiu-ming Cheung*

Main category: cs.LG

TL;DR: ARISE利用大语言模型的外部语义知识增强分类数据的聚类效果，通过语义感知表示弥补传统相似度测量的不足，在8个基准数据集上相比7个代表性方法提升19-27%


<details>
  <summary>Details</summary>
Motivation: 分类数据聚类面临的核心挑战是缺乏固有排序或距离的属性值相似度测量问题。现有方法依赖数据集内共现模式推断值关系，但在样本有限时不可靠，导致语义上下文未被充分探索，造成语义鸿沟并降低聚类质量。

Method: 提出ARISE方法，利用大语言模型的外部语义知识构建语义感知表示，补充分类数据的度量空间。具体采用LLM描述属性值以增强表示，将LLM增强的嵌入与原始数据结合，探索语义显著的聚类结构。

Result: 在8个基准数据集上的实验表明，相比7个代表性对比方法，ARISE实现了19-27%的持续改进，证明了利用外部语义知识增强分类数据聚类的有效性。

Conclusion: ARISE通过整合大语言模型的外部语义知识，有效弥补了分类数据聚类中的语义鸿沟，显著提升了聚类质量，为有限样本下的分类数据聚类提供了可靠解决方案。

Abstract: Categorical data are prevalent in domains such as healthcare, marketing, and bioinformatics, where clustering serves as a fundamental tool for pattern discovery. A core challenge in categorical data clustering lies in measuring similarity among attribute values that lack inherent ordering or distance. Without appropriate similarity measures, values are often treated as equidistant, creating a semantic gap that obscures latent structures and degrades clustering quality. Although existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited, leaving the semantic context of the data underexplored. To bridge this gap, we present ARISE (Attention-weighted Representation with Integrated Semantic Embeddings), which draws on external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations that complement the metric space of categorical data for accurate clustering. That is, LLM is adopted to describe attribute values for representation enhancement, and the LLM-enhanced embeddings are combined with the original data to explore semantically prominent clusters. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts, with gains of 19-27%. Code is available at https://github.com/develop-yang/ARISE

</details>


### [163] [MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches](https://arxiv.org/abs/2601.01206)
*Soroush Elyasi,Arya VarastehNezhad,Fattaneh Taghiyareh*

Main category: cs.LG

TL;DR: 使用多类型严肃游戏和机器学习预测软件开发岗位适合度，通过游戏行为特征而非传统问卷达到97%精度和94%准确率


<details>
  <summary>Details</summary>
Motivation: 传统职业评估中的人格问卷存在回应偏差、疲劳和故意扭曲等问题，需要更客观、可扩展且减少偏见的替代方案

Method: 通过文献综述和实证研究确定软件开发相关人格和行为特征，设计定制移动游戏收集问题解决、规划、适应性等行为数据，采用两阶段建模策略从游戏行为特征预测适合度

Result: 模型达到97%精度和94%准确率；合适候选人表现出独特游戏模式：解谜游戏获胜更多、完成更多支线挑战、更频繁导航菜单、较少暂停/重试/放弃行为

Conclusion: 游戏过程中捕获的隐式行为痕迹能有效预测软件开发适合度，支持严肃游戏作为职业评估的可扩展、吸引人且偏见较少的替代方案

Abstract: Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.

</details>


### [164] [Adaptive Conformal Prediction via Bayesian Uncertainty Weighting for Hierarchical Healthcare Data](https://arxiv.org/abs/2601.01223)
*Marzieh Amiri Shahbazi,Ali Baheri,Nasibeh Azadeh-Fard*

Main category: cs.LG

TL;DR: 提出混合贝叶斯-保形框架，结合贝叶斯层次随机森林与组感知保形校准，为临床决策提供分布自由的覆盖保证和风险自适应精度


<details>
  <summary>Details</summary>
Motivation: 临床决策需要不确定性量化，要求同时满足分布自由的覆盖保证和风险自适应精度，现有方法无法同时满足这两个要求

Method: 混合贝叶斯-保形框架：集成贝叶斯层次随机森林与组感知保形校准，使用后验不确定性对保形分数进行加权，同时保持严格的覆盖有效性

Result: 在61,538例入院患者（3,793家美国医院，4个地区）上评估：达到目标覆盖率（94.3% vs 95%目标），低不确定性病例区间宽度减少21%，高风险预测适当加宽。纯贝叶斯不确定性校准严重不足（14.1%覆盖）

Conclusion: 该框架支持风险分层临床协议、高效资源规划和高置信度预测，为不确定病例提供保守分配和增强监督，为多样化医疗环境提供不确定性感知的决策支持

Abstract: Clinical decision-making demands uncertainty quantification that provides both distribution-free coverage guarantees and risk-adaptive precision, requirements that existing methods fail to jointly satisfy. We present a hybrid Bayesian-conformal framework that addresses this fundamental limitation in healthcare predictions. Our approach integrates Bayesian hierarchical random forests with group-aware conformal calibration, using posterior uncertainties to weight conformity scores while maintaining rigorous coverage validity. Evaluated on 61,538 admissions across 3,793 U.S. hospitals and 4 regions, our method achieves target coverage (94.3% vs 95% target) with adaptive precision: 21% narrower intervals for low-uncertainty cases while appropriately widening for high-risk predictions. Critically, we demonstrate that well-calibrated Bayesian uncertainties alone severely under-cover (14.1%), highlighting the necessity of our hybrid approach. This framework enables risk-stratified clinical protocols, efficient resource planning for high-confidence predictions, and conservative allocation with enhanced oversight for uncertain cases, providing uncertainty-aware decision support across diverse healthcare settings.

</details>


### [165] [The Alchemy of Thought: Understanding In-Context Learning Through Supervised Classification](https://arxiv.org/abs/2601.01290)
*Harshita Narnoli,Mihai Surdeanu*

Main category: cs.LG

TL;DR: 本文通过比较上下文学习与监督分类器的行为，探究LLMs如何通过示例进行学习，发现当示例相关性高时，LLMs行为类似kNN分类器，相关性低时LLMs表现更好


<details>
  <summary>Details</summary>
Motivation: 尽管上下文学习在实践中被广泛使用且有效，但人们对其工作原理仍缺乏真正的理解。本文旨在探究LLMs通过上下文示例学习时，其内部机制与哪些传统分类器更相似

Method: 使用文本分类作为用例，在六个数据集和三个LLMs上，比较上下文学习与基于相同示例训练的监督分类器（梯度下降和k近邻）的行为差异

Result: 当示例相关性高时，LLMs行为与这些分类器相似，且更接近kNN而非逻辑回归；当示例相关性低时，LLMs表现优于这些分类器，因为LLMs可以依赖其参数化记忆

Conclusion: 上下文学习机制在示例相关性高时类似kNN分类器，在相关性低时LLMs能利用参数化记忆获得优势，这为理解LLMs如何通过上下文示例学习提供了实证证据

Abstract: In-context learning (ICL) has become a prominent paradigm to rapidly customize LLMs to new tasks without fine-tuning. However, despite the empirical evidence of its usefulness, we still do not truly understand how ICL works. In this paper, we compare the behavior of in-context learning with supervised classifiers trained on ICL demonstrations to investigate three research questions: (1) Do LLMs with ICL behave similarly to classifiers trained on the same examples? (2) If so, which classifiers are closer, those based on gradient descent (GD) or those based on k-nearest neighbors (kNN)? (3) When they do not behave similarly, what conditions are associated with differences in behavior? Using text classification as a use case, with six datasets and three LLMs, we observe that LLMs behave similarly to these classifiers when the relevance of demonstrations is high. On average, ICL is closer to kNN than logistic regression, giving empirical evidence that the attention mechanism behaves more similarly to kNN than GD. However, when demonstration relevance is low, LLMs perform better than these classifiers, likely because LLMs can back off to their parametric memory, a luxury these classifiers do not have.

</details>


### [166] [ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System](https://arxiv.org/abs/2601.01297)
*Anantha Sharma*

Main category: cs.LG

TL;DR: Argus框架将高维数据流中的分布漂移检测重新定义为在数据流形固定空间划分上跟踪局部统计量，解决了现有方法在可扩展性、几何结构保持和身份稳定性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 高维数据流中的分布漂移检测面临三个主要挑战：全局比较方法扩展性差，基于投影的方法丢失几何结构，重新聚类方法存在身份不稳定性。需要一种既能保持高维结构又具有计算效率的漂移检测方法。

Method: Argus框架通过固定空间划分（Voronoi细分）跟踪局部统计量来检测漂移。使用规范正交基上的Voronoi细分确保漂移度量对正交变换不变，引入图论方法区分相干分布漂移和孤立扰动，并通过乘积量化细分扩展到超高维度（d>500）。

Result: 理论证明Voronoi细分在规范正交基上产生对正交变换不变的漂移度量，框架实现O(N)复杂度并提供单元级空间定位，实验验证框架能正确识别坐标旋转下的漂移而现有方法会产生误报。

Conclusion: Argus为分布监控提供了有原则的几何基础，既能保持高维结构又避免了成对比较的计算负担，通过固定空间划分和局部统计跟踪实现了高效准确的漂移检测。

Abstract: Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity instability. This paper introduces Argus, A framework that reconceptualizes drift detection as tracking local statistics over a fixed spatial partition of the data manifold.
  The key contributions are fourfold. First, it is proved that Voronoi tessellations over canonical orthonormal frames yield drift metrics that are invariant to orthogonal transformations. The rotations and reflections that preserve Euclidean geometry. Second, it is established that this framework achieves O(N) complexity per snapshot while providing cell-level spatial localization of distributional change. Third, a graph-theoretic characterization of drift propagation is developed that distinguishes coherent distributional shifts from isolated perturbations. Fourth, product quantization tessellation is introduced for scaling to very high dimensions (d>500) by decomposing the space into independent subspaces and aggregating drift signals across subspaces.
  This paper formalizes the theoretical foundations, proves invariance properties, and presents experimental validation demonstrating that the framework correctly identifies drift under coordinate rotation while existing methods produce false positives. The tessellated approach offers a principled geometric foundation for distribution monitoring that preserves high-dimensional structure without the computational burden of pairwise comparisons.

</details>


### [167] [Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware](https://arxiv.org/abs/2601.01298)
*Jorge L. Ruiz Williams*

Main category: cs.LG

TL;DR: Warp Cortex是一个异步多智能体LLM框架，通过解耦智能体逻辑与物理内存，实现了百万级智能体的认知扩展，将内存复杂度从O(N*L)降低到O(1)权重和O(N*k)上下文。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM框架存在线性内存扩展问题，使得"系统2"并行推理在消费级硬件上不切实际。需要解决内存瓶颈以实现大规模智能体协同推理。

Method: 采用异步架构，通过单例权重共享和拓扑突触技术（受拓扑数据分析启发），将KV缓存视为潜在空间中的点云，应用见证复杂稀疏化来保持上下文流形的持久同调特征。引入参考注入机制实现非侵入式KV缓存更新。

Result: 在单个NVIDIA RTX 4090上实现了100个并发智能体，仅占用2.2GB总VRAM，理论容量超过1000个智能体（计算延迟成为瓶颈前）。内存复杂度显著降低。

Conclusion: Warp Cortex通过创新的内存优化架构，解决了多智能体LLM系统的内存扩展瓶颈，为实现大规模并行推理系统提供了可行的技术路径。

Abstract: Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering "System 2" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.

</details>


### [168] [Towards a Principled Muon under $μ\mathsf{P}$: Ensuring Spectral Conditions throughout Training](https://arxiv.org/abs/2601.01306)
*John Zhao*

Main category: cs.LG

TL;DR: μP为LLM训练提供理论基础，但矩阵优化器Muon在实际训练中难以满足其谱条件要求。现有方法要么无法保证全程满足条件，要么计算开销大。本文提出Muon++，通过仅控制优化器更新的谱条件来保证μP兼容性，无需显式权重谱归一化。


<details>
  <summary>Details</summary>
Motivation: μ-参数化（μP）为大语言模型训练提供了理论基础，但实际训练中矩阵优化器Muon难以满足μP要求的谱条件。现有方法存在局限性：要么无法保证整个训练过程中谱条件始终满足，要么需要频繁的谱归一化操作导致计算开销大、实用性差。

Method: 提出Muon++优化器变体，关键见解是对于中等规模模型，仅需在优化器更新层面维持谱控制即可保持μP兼容的缩放特性，无需显式对权重进行谱归一化。同时首次引入数据依赖的自适应谱条件，更适合长时程LLM训练。

Result: 开发出Muon++，能够在整个训练过程中可靠地保证μP所需的谱条件，弥合了μP理论承诺与矩阵优化器实际部署之间的差距，同时减少了计算开销。

Conclusion: 通过仅控制优化器更新的谱条件，可以在不显式归一化权重的情况下保证μP兼容性，为矩阵优化器在长时程LLM训练中的实际应用提供了可行方案，并首次引入了自适应谱条件以适应数据依赖效应。

Abstract: The $μ$-parameterization ($μ$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $μ$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $μ$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $μ$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $μ$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $μ$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.

</details>


### [169] [Spectral-Window Hybrid (SWH)](https://arxiv.org/abs/2601.01313)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: SWH是一种混合架构，通过并行全局分支（利用卷积定理建模长程衰减动态）和局部分支（滑动窗口注意力）来平衡计算效率与表达能力，实现线性扩展至长序列。


<details>
  <summary>Details</summary>
Motivation: 将序列建模扩展到极长上下文时，需要在计算效率和表示表达能力之间取得平衡。Transformer虽然通过注意力机制提供精确检索，但其二次方复杂度限制了在长序列任务中的应用。

Method: 提出Spectral-Window Hybrid (SWH)架构，将序列建模解耦为两个并行流：1) 全局分支利用卷积定理在O(T log T)时间内建模长程衰减动态；2) 局部分支使用滑动窗口注意力处理有限上下文内的token交互。通过聚合这两种表示，避免全局注意力的计算瓶颈同时保持局部精度。

Result: SWH在短上下文上能达到标准Transformer的困惑度水平，同时能够高效地线性扩展到长序列。

Conclusion: SWH架构通过结合全局频谱建模和局部注意力机制，有效解决了长序列建模中的计算效率与表达能力平衡问题，为极端上下文序列建模提供了可行的解决方案。

Abstract: Scaling sequence modeling to extreme contexts requires balancing computational efficiency with representational expressivity. While Transformers provide precise retrieval via the attention mechanism, their quadratic $\mathcal{O}(T^2)$ complexity limits their application to long-horizon tasks. In this work, we propose the \textbf{Spectral-Window Hybrid (SWH)}, an architecture that decouples sequence modeling into two \textit{parallel} streams: a global branch utilizing the Convolution Theorem to model long-range decay dynamics in $\mathcal{O}(T \log T)$ time, and a local branch employing sliding-window attention for token interactions within a bounded context. By aggregating these representations, SWH avoids the computational bottleneck of global attention while retaining local precision. We demonstrate that SWH matches the perplexity of standard Transformers on short contexts while enabling efficient linear scaling to extended sequences. The code is available at https://github.com/VladimerKhasia/SWH

</details>


### [170] [From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion](https://arxiv.org/abs/2601.01347)
*Yuyan Pi,Min Jin,Wentao Xie,Xinhua Liu*

Main category: cs.LG

TL;DR: GM-MLG：基于图-基序特征融合和多标签生成的开放式药物不良反应预测新范式，将传统多标签分类转化为Transformer解码器驱动的多标签生成，显著提升预测性能并扩展预测空间


<details>
  <summary>Details</summary>
Motivation: 当前药物不良反应预测方法面临三大挑战：药物数据稀缺导致的冷启动问题、封闭标签集限制、以及标签依赖关系建模不足。这些限制阻碍了计算生物学在降低新药研发成本方面的潜力发挥。

Method: 1. 构建双图表示架构：原子级、局部分子级（BRICS算法动态提取细粒度基序）、全局分子级
2. 将ADR预测从多标签分类转化为基于Transformer解码器的多标签生成
3. 将ADR标签视为离散标记序列，使用位置嵌入显式捕获大规模标签空间中的依赖和共现关系
4. 通过自回归解码生成预测，动态扩展预测空间

Result: 1. 性能提升：最高达38%改进，平均增益20%
2. 预测空间扩展：从200种扩展到超过10,000种
3. 通过逆向合成基序分析阐明ADR与基序之间的非线性结构-活性关系
4. 为系统性降低药物安全风险提供可解释的创新支持

Conclusion: GM-MLG提出了一种创新的开放式ADR预测范式，通过图-基序特征融合和多标签生成方法，有效解决了当前方法的局限性，显著提升了预测性能并大幅扩展了预测能力，为药物安全风险评估提供了更全面、可解释的计算工具。

Abstract: Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.

</details>


### [171] [Causal discovery for linear causal model with correlated noise: an Adversarial Learning Approach](https://arxiv.org/abs/2601.01368)
*Mujin Zhou,Junzhe Zhang*

Main category: cs.LG

TL;DR: 提出基于f-GAN框架的因果发现方法，处理存在未测量混杂因素的数据，通过最小化贝叶斯自由能学习因果结构，使用Gumbel-Softmax松弛在离散图空间进行梯度搜索。


<details>
  <summary>Details</summary>
Motivation: 从存在未测量混杂因素的数据中进行因果发现是一个具有挑战性的问题，需要开发能够独立于特定权重值学习二元因果结构的方法。

Method: 将结构学习问题重新表述为最小化贝叶斯自由能，证明该问题等价于最小化真实数据分布与模型生成分布之间的f-散度。利用f-GAN框架将此目标转化为最小-最大对抗优化问题，并使用Gumbel-Softmax松弛在离散图空间实现梯度搜索。

Result: 该方法能够从存在未测量混杂因素的数据中学习因果结构，通过对抗优化框架有效处理离散图空间的搜索问题。

Conclusion: 提出的基于f-GAN框架的方法为存在未测量混杂因素的因果发现问题提供了有效的解决方案，通过贝叶斯自由能最小化和对抗优化实现了因果结构的有效学习。

Abstract: Causal discovery from data with unmeasured confounding factors is a challenging problem. This paper proposes an approach based on the f-GAN framework, learning the binary causal structure independent of specific weight values. We reformulate the structure learning problem as minimizing Bayesian free energy and prove that this problem is equivalent to minimizing the f-divergence between the true data distribution and the model-generated distribution. Using the f-GAN framework, we transform this objective into a min-max adversarial optimization problem. We implement the gradient search in the discrete graph space using Gumbel-Softmax relaxation.

</details>


### [172] [Data Complexity-aware Deep Model Performance Forecasting](https://arxiv.org/abs/2601.01383)
*Yen-Chia Chen,Hsing-Kuo Pao,Hanjuan Huang*

Main category: cs.LG

TL;DR: 提出一个轻量级的两阶段框架，可在训练前根据数据集特性和模型结构预测模型性能，避免重复试错


<details>
  <summary>Details</summary>
Motivation: 深度学习模型选择通常依赖重复试错过程，耗时耗资源且难以自动化。现有性能预测方法要么需要大量计算开销，要么缺乏泛化能力。

Method: 提出两阶段框架：第一阶段基于数据集的可测量属性预测基线性能；第二阶段结合模型架构和超参数细节调整估计。框架可泛化到不同数据集和模型类型。

Result: 框架不仅能预测模型性能，还能指导架构选择、预处理流程，并在训练前检测潜在问题数据集。发现数据集方差等特征可作为数据质量的早期指标。

Conclusion: 该轻量级框架提供了一种高效的模型性能预测方法，减少了传统试错过程的计算开销，同时为模型选择和数据处理提供实用指导。

Abstract: Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.

</details>


### [173] [Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning](https://arxiv.org/abs/2601.01387)
*Yongzhe Li,Lin Guan,Zihan Cai,Zuxian Lin,Jiyu Huang,Liukai Chen*

Main category: cs.LG

TL;DR: 本文提出了一种尺度自适应多任务潮流分析框架（SaMPFA），通过局部拓扑切片采样技术和无参考多任务图学习模型，提升深度学习模型在变拓扑结构下的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发具有强拓扑适应性的深度学习模型对潮流分析具有重要实践意义。现有模型在变系统规模和分支功率预测鲁棒性方面存在不足，需要增强模型的跨尺度学习能力和物理一致性。

Method: 1. 提出尺度自适应多任务潮流分析框架（SaMPFA）；2. 引入局部拓扑切片（LTS）采样技术，从完整电网提取不同尺度的子图；3. 设计无参考多任务图学习（RMGL）模型，预测母线电压和分支功率而非相角；4. 损失函数中加入鼓励模型捕捉相角差和功率传输物理模式的额外项。

Result: 在IEEE 39节点系统和实际省级电网上的仿真表明，所提模型在变系统尺度下具有优异的适应性和泛化能力，准确率分别提升了4.47%和36.82%。

Conclusion: SaMPFA框架通过局部拓扑切片采样和无参考多任务学习，有效提升了深度学习模型在变拓扑结构下的潮流分析性能，增强了模型的物理一致性和跨尺度适应能力。

Abstract: Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.

</details>


### [174] [A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble](https://arxiv.org/abs/2601.01403)
*Zewei Yu,Jianqiu Xu,Caimin Li*

Main category: cs.LG

TL;DR: GDME是一个基于图的无监督在线时间序列异常检测框架，通过动态模型池和图结构进行模型集成，能够有效处理异构流数据并检测概念漂移。


<details>
  <summary>Details</summary>
Motivation: 工业系统中流数据量不断增加，在线异常检测变得至关重要。现有方法多为离线设计或难以有效处理异构流数据，且数据模式多样且快速演变，这给在线异常检测带来了重大挑战。

Method: 提出GDME框架：1）维护动态模型池，持续更新（修剪表现不佳的模型并引入新模型）；2）使用动态图结构表示模型间关系；3）在图上进行社区检测以选择适当的子集进行集成；4）通过监控图结构变化来检测概念漂移，使框架能够适应演化的流数据。

Result: 在七个异构时间序列上的实验表明，GDME优于现有的在线异常检测方法，改进幅度高达24%。其集成策略相比单个模型和平均集成提供了更优的检测性能，同时具有竞争力的计算效率。

Conclusion: GDME是一个有效的在线时间序列异常检测框架，能够通过动态模型集成和图结构分析处理异构流数据，检测概念漂移，并在性能和效率方面都表现出色。

Abstract: With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.

</details>


### [175] [Bayesian Subspace Gradient Estimation for Zeroth-Order Optimization of Large Language Models](https://arxiv.org/abs/2601.01452)
*Jian Feng,Zhihong Huang*

Main category: cs.LG

TL;DR: BSZO是一种贝叶斯子空间零阶优化方法，通过卡尔曼滤波结合多个扰动方向的有限差分信息，相比传统ZO方法提高了收敛速度，在保持低内存消耗的同时显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化方法依赖随机扰动的一步梯度估计，限制了优化效率和性能。需要一种能够有效利用多个扰动方向信息、提高收敛速度的零阶优化方法。

Method: 提出贝叶斯子空间零阶优化(BSZO)，将每个有限差分测量视为噪声观测，通过卡尔曼滤波构建投影梯度的后验分布，使用贝叶斯推断更新，并采用基于残差的自适应机制调整扰动尺度。

Result: 理论分析显示BSZO比标准ZO方法的收敛速度提高了k/γ倍。在RoBERTa、Mistral和OPT模型上的实验表明，BSZO优于MeZO、MeZO-Adam和HiZOO，在OPT-13B上实现了最高6.67%的绝对平均提升，内存使用接近仅推理基线（MeZO的1.00-1.08倍）。

Conclusion: BSZO通过贝叶斯方法有效整合多个扰动方向信息，显著提升了零阶优化的收敛速度和性能，同时保持了低内存消耗的优势，为大语言模型的高效微调提供了新方法。

Abstract: Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations, but existing methods rely on one-step gradient estimates from random perturbations. We introduce Bayesian Subspace Zeroth-Order optimization (BSZO), a ZO optimizer that applies Kalman filtering to combine finite-difference information across multiple perturbation directions. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adjust perturbation scales. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/γ$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms MeZO, MeZO-Adam, and HiZOO across various tasks, achieving up to 6.67\% absolute average improvement on OPT-13B while keeping memory usage close to inference-only baselines (1.00$\times$--1.08$\times$ of MeZO).

</details>


### [176] [Multi-Subspace Multi-Modal Modeling for Diffusion Models: Estimation, Convergence and Mixture of Experts](https://arxiv.org/abs/2601.01475)
*Ruofeng Yang,Yongcan Li,Bo Jiang,Cheng Chen,Shuai Li*

Main category: cs.LG

TL;DR: 该论文提出MoLR-MoG建模方法，通过混合低秩高斯混合模型捕捉数据的多模态特性，解决了扩散模型在高维数据中的维度诅咒问题，实现了更优的生成效果和理论保证。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型在高维数据中面临维度诅咒问题（n^{-1/D}），现有方法虽然考虑了数据的多流形特性，但使用高斯潜在变量无法捕捉潜在流形的多模态特性。需要一种既能反映多流形结构又能捕捉多模态特性的建模方法。

Method: 提出MoLR-MoG（混合低秩高斯混合）建模：将目标数据建模为K个线性子空间的并集，每个子空间采用高斯混合潜在变量（n_k个模态，维度d_k）。对应的得分函数具有混合专家结构，能捕捉多模态信息并包含非线性特性。

Result: 1. 实验表明MoE-latent MoG NN的生成效果显著优于MoE-latent Gaussian score；2. MoE-latent MoG NN与参数多10倍的MoE-latent Unet性能相当；3. 理论分析得到R^4√(Σn_k)√(Σn_kd_k)/√n的估计误差，摆脱了维度诅咒；4. 证明了MoLR-MoG建模下的优化收敛保证。

Conclusion: MoLR-MoG建模合理且适用于真实世界数据，解释了为什么扩散模型只需少量训练样本和快速优化过程就能获得优异性能。该方法通过利用数据结构摆脱维度诅咒，为扩散模型的理论和实践提供了新见解。

Abstract: Recently, diffusion models have achieved a great performance with a small dataset of size $n$ and a fast optimization process. However, the estimation error of diffusion models suffers from the curse of dimensionality $n^{-1/D}$ with the data dimension $D$. Since images are usually a union of low-dimensional manifolds, current works model the data as a union of linear subspaces with Gaussian latent and achieve a $1/\sqrt{n}$ bound. Though this modeling reflects the multi-manifold property, the Gaussian latent can not capture the multi-modal property of the latent manifold. To bridge this gap, we propose the mixture subspace of low-rank mixture of Gaussian (MoLR-MoG) modeling, which models the target data as a union of $K$ linear subspaces, and each subspace admits a mixture of Gaussian latent ($n_k$ modals with dimension $d_k$). With this modeling, the corresponding score function naturally has a mixture of expert (MoE) structure, captures the multi-modal information, and contains nonlinear property. We first conduct real-world experiments to show that the generation results of MoE-latent MoG NN are much better than MoE-latent Gaussian score. Furthermore, MoE-latent MoG NN achieves a comparable performance with MoE-latent Unet with $10 \times$ parameters. These results indicate that the MoLR-MoG modeling is reasonable and suitable for real-world data. After that, based on such MoE-latent MoG score, we provide a $R^4\sqrt{Σ_{k=1}^Kn_k}\sqrt{Σ_{k=1}^Kn_kd_k}/\sqrt{n}$ estimation error, which escapes the curse of dimensionality by using data structure. Finally, we study the optimization process and prove the convergence guarantee under the MoLR-MoG modeling. Combined with these results, under a setting close to real-world data, this work explains why diffusion models only require a small training sample and enjoy a fast optimization process to achieve a great performance.

</details>


### [177] [Advanced Global Wildfire Activity Modeling with Hierarchical Graph ODE](https://arxiv.org/abs/2601.01501)
*Fan Xu,Wei Gong,Hao Wu,Lilan Peng,Nan Wang,Qingsong Wen,Xian Wu,Kun Wang,Xibin Zhao*

Main category: cs.LG

TL;DR: HiGO框架通过多层级图结构和连续时间动力学建模，显著提升了全球野火长期预测性能


<details>
  <summary>Details</summary>
Motivation: 野火作为地球系统的重要组成部分，受到大气、海洋和陆地过程在广泛时空尺度上的复杂相互作用影响。虽然深度学习在全球天气预报方面取得了突破，但在全球野火行为预测方面的潜力尚未充分探索。

Method: 提出分层图ODE（HiGO）框架：1）将地球系统表示为多层级图层次结构；2）提出自适应滤波消息传递机制，用于层级内和层级间的信息流动；3）在多个层级上集成GNN参数化的神经ODE模块，显式学习每个尺度的连续动力学。

Result: 在SeasFire Cube数据集上的实验表明，HiGO在长期野火预测方面显著优于现有最先进基线方法。其连续时间预测表现出强大的观测一致性，突显了实际应用的潜力。

Conclusion: HiGO框架通过有效建模多尺度连续时间动力学，为全球野火行为预测提供了创新解决方案，具有重要的实际应用价值。

Abstract: Wildfires, as an integral component of the Earth system, are governed by a complex interplay of atmospheric, oceanic, and terrestrial processes spanning a vast range of spatiotemporal scales. Modeling their global activity on large timescales is therefore a critical yet challenging task. While deep learning has recently achieved significant breakthroughs in global weather forecasting, its potential for global wildfire behavior prediction remains underexplored. In this work, we reframe this problem and introduce the Hierarchical Graph ODE (HiGO), a novel framework designed to learn the multi-scale, continuous-time dynamics of wildfires. Specifically, we represent the Earth system as a multi-level graph hierarchy and propose an adaptive filtering message passing mechanism for both intra- and inter-level information flow, enabling more effective feature extraction and fusion. Furthermore, we incorporate GNN-parameterized Neural ODE modules at multiple levels to explicitly learn the continuous dynamics inherent to each scale. Through extensive experiments on the SeasFire Cube dataset, we demonstrate that HiGO significantly outperforms state-of-the-art baselines on long-range wildfire forecasting. Moreover, its continuous-time predictions exhibit strong observational consistency, highlighting its potential for real-world applications.

</details>


### [178] [Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings](https://arxiv.org/abs/2601.01558)
*Pengfei Qu,Wenyu Ouyang,Chi Zhang,Yikai Chai,Shuolong Xu,Lei Ye,Yongri Piao,Miao Zhang,Huchuan Lu*

Main category: cs.LG

TL;DR: 卫星图像学习的环境嵌入比传统流域属性更能有效预测无径流记录地区的河流流量


<details>
  <summary>Details</summary>
Motivation: 传统流域属性无法完全描述自然环境的复杂性，需要更有效的方法来表征流域特征以预测无径流记录地区的河流流量

Method: 使用AlphaEarth Foundation嵌入（从大量卫星图像学习的环境表示）来描述流域特征，并研究如何选择适当的供体流域来预测无测站地区的流量

Result: 基于嵌入的模型在预测未参与训练的流域流量时精度更高，表明这些嵌入比传统属性更能捕捉关键的物理差异；基于嵌入相似性选择供体流域能提高预测性能

Conclusion: 卫星图像学习的环境表示可以增强水文预测能力，支持开发更适应不同景观的水文模型

Abstract: Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.

</details>


### [179] [REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training](https://arxiv.org/abs/2601.01605)
*Xin Di,Xinglin Piao,Fei Wang,Guodong Jing,Yong Zhang*

Main category: cs.LG

TL;DR: 提出REE-TTT模型，通过时空测试时训练机制改进雷达回波外推，增强跨区域极端降水场景的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的雷达回波外推方法依赖高质量本地训练数据和静态模型参数，导致泛化能力差，难以适应不同区域和极端事件

Method: 提出REE-TTT模型，引入自适应测试时训练机制，设计时空测试时训练块，用任务特定注意力机制替代标准线性投影，增强对非平稳气象分布的适应能力

Result: 在跨区域极端降水场景实验中，REE-TTT在预测精度和泛化能力上显著优于现有基准模型，表现出对数据分布变化的出色适应性

Conclusion: REE-TTT通过测试时训练机制有效解决了雷达回波外推的泛化问题，为降水临近预报提供了更可靠和适应性强的解决方案

Abstract: Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.

</details>


### [180] [Real Time NILM Based Power Monitoring of Identical Induction Motors Representing Cutting Machines in Textile Industry](https://arxiv.org/abs/2601.01616)
*Md Istiauk Hossain Rifat,Moin Khan,Mohammad Zunaed*

Main category: cs.LG

TL;DR: 该研究为孟加拉国纺织业开发了基于NILM的实时能耗监测框架，针对相同电机负载（纺织切割机）进行监控，结果显示总体能耗估计准确，但相同设备同时运行时分解精度下降。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国纺织业是能源密集型行业，但现有监测方法过时，导致能源使用效率低下和运营成本高昂，需要开发实时监测解决方案。

Method: 开发了包含电压电流传感器、Arduino Mega和ESP8266的硬件系统，采集总负载和单个负载数据，在云平台处理；创建了包含三个相同感应电机和辅助负载的新数据集（超过18万个样本），使用最先进的MATNILM模型评估。

Result: 总体能耗估计较为准确，但单个设备分解面临困难，特别是多个相同机器同时运行时；集成系统通过Blynk应用实现了实用的实时远程监控。

Conclusion: 该工作展示了NILM在工业环境中的潜力和局限性，建议未来改进包括更高频率数据采集、更大规模数据集以及处理相同负载的先进深度学习方法。

Abstract: The textile industry in Bangladesh is one of the most energy-intensive sectors, yet its monitoring practices remain largely outdated, resulting in inefficient power usage and high operational costs. To address this, we propose a real-time Non-Intrusive Load Monitoring (NILM)-based framework tailored for industrial applications, with a focus on identical motor-driven loads representing textile cutting machines. A hardware setup comprising voltage and current sensors, Arduino Mega and ESP8266 was developed to capture aggregate and individual load data, which was stored and processed on cloud platforms. A new dataset was created from three identical induction motors and auxiliary loads, totaling over 180,000 samples, to evaluate the state-of-the-art MATNILM model under challenging industrial conditions. Results indicate that while aggregate energy estimation was reasonably accurate, per-appliance disaggregation faced difficulties, particularly when multiple identical machines operated simultaneously. Despite these challenges, the integrated system demonstrated practical real-time monitoring with remote accessibility through the Blynk application. This work highlights both the potential and limitations of NILM in industrial contexts, offering insights into future improvements such as higher-frequency data collection, larger-scale datasets and advanced deep learning approaches for handling identical loads.

</details>


### [181] [Communication-Efficient Federated AUC Maximization with Cyclic Client Participation](https://arxiv.org/abs/2601.01649)
*Umesh Vangapally,Wenhan Wu,Chen Chen,Zhishuai Guo*

Main category: cs.LG

TL;DR: 该论文针对联邦学习中周期性客户端参与场景下的AUC最大化问题，提出了两种通信高效的算法，分别在平方替代损失和一般成对损失下实现了最优的通信和迭代复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有联邦AUC最大化方法通常假设客户端完全可用，但实际联邦学习系统中客户端通常按固定周期循环参与训练。这种周期性参与给非可分解的AUC目标带来了独特的优化挑战，需要专门的高效算法。

Method: 针对两种设置开发算法：1）平方替代损失的AUC最大化，将其重构为非凸-强凹极小极大优化问题，利用Polyak-Łojasiewicz条件；2）一般成对AUC损失。两种方法都考虑了周期性客户端参与特性，设计了通信高效的优化算法。

Result: 平方替代损失下实现了通信复杂度$\widetilde{O}(1/ε^{1/2})$和迭代复杂度$\widetilde{O}(1/ε)$；一般成对损失下通信复杂度$O(1/ε^3)$和迭代复杂度$O(1/ε^4)$，在PL条件下改进为$\widetilde{O}(1/ε^{1/2})$和$\widetilde{O}(1/ε)$。实验在图像分类、医学影像和欺诈检测任务上验证了方法的优越性。

Conclusion: 该论文成功解决了周期性客户端参与下的联邦AUC最大化问题，提出了通信高效的算法，在理论和实验上都取得了显著进展，为实际联邦学习系统中处理不平衡数据提供了有效解决方案。

Abstract: Federated AUC maximization is a powerful approach for learning from imbalanced data in federated learning (FL). However, existing methods typically assume full client availability, which is rarely practical. In real-world FL systems, clients often participate in a cyclic manner: joining training according to a fixed, repeating schedule. This setting poses unique optimization challenges for the non-decomposable AUC objective. This paper addresses these challenges by developing and analyzing communication-efficient algorithms for federated AUC maximization under cyclic client participation. We investigate two key settings: First, we study AUC maximization with a squared surrogate loss, which reformulates the problem as a nonconvex-strongly-concave minimax optimization. By leveraging the Polyak-Łojasiewicz (PL) condition, we establish a state-of-the-art communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Second, we consider general pairwise AUC losses. We establish a communication complexity of $O(1/ε^3)$ and an iteration complexity of $O(1/ε^4)$. Further, under the PL condition, these bounds improve to communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Extensive experiments on benchmark tasks in image classification, medical imaging, and fraud detection demonstrate the superior efficiency and effectiveness of our proposed methods.

</details>


### [182] [Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths](https://arxiv.org/abs/2601.01663)
*He Sun,Jiwoong Shin,Ravi Dhar*

Main category: cs.LG

TL;DR: 提出长度感知采样（LAS）方法，通过按轨迹长度分组采样来减少批次内长度异质性，改善轨迹生成模型中的分布匹配问题


<details>
  <summary>Details</summary>
Motivation: 在可变长度轨迹的生成建模中，标准小批量训练在轨迹长度高度异质时不稳定，这会降低轨迹派生统计量的分布匹配质量

Method: 提出长度感知采样（LAS）策略：按轨迹长度分组，从单一长度桶中采样批次，减少批次内长度异质性；结合条件轨迹GAN和辅助时间对齐损失

Result: LAS在购物者轨迹数据集和多种公共序列数据集（GPS、教育、电子商务、电影）上一致改善派生变量分布的匹配，优于随机采样

Conclusion: LAS通过移除仅依赖长度的捷径批评器并针对桶内差异，改善了分布匹配，为轨迹生成建模提供了简单有效的训练策略

Abstract: We study generative modeling of \emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \emph{distribution matching} for trajectory-derived statistics. We propose \textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.

</details>


### [183] [Who is the Winning Algorithm? Rank Aggregation for Comparative Studies](https://arxiv.org/abs/2601.01664)
*Amichai Painsky*

Main category: cs.LG

TL;DR: 提出新框架，利用算法在基准数据集上的完整排名信息（不仅是获胜次数，还包括第二、第三等排名）来估计每个算法在未来未见数据集上获胜的概率。


<details>
  <summary>Details</summary>
Motivation: 传统最大似然方法仅统计每个算法在基准数据集上的获胜次数，但忽略了完整的排名信息（如第二、第三名等）。这些额外信息可能有助于更准确地预测算法在未来数据集上的表现。

Method: 引入新的概念框架，利用m个竞争算法在基准数据集上的完整排名信息（包括每个算法获得第一、第二、第三等名次的次数），来估计每个算法在未来未见数据集上获胜的概率。

Result: 提出的新框架在合成和真实世界示例中显著优于当前已知的方法，能够更准确地预测算法在未来数据集上的获胜概率。

Conclusion: 利用算法在基准数据集上的完整排名信息（而不仅仅是获胜次数）可以显著提高预测算法在未来数据集上获胜概率的准确性，为算法选择提供了更有效的工具。

Abstract: Consider a collection of m competing machine learning algorithms. Given their performance on a benchmark of datasets, we would like to identify the best performing algorithm. Specifically, which algorithm is most likely to ``win'' (rank highest) on a future, unseen dataset. The standard maximum likelihood approach suggests counting the number of wins per each algorithm. In this work, we argue that there is much more information in the complete rankings. That is, the number of times that each algorithm finished second, third and so forth. Yet, it is not entirely clear how to effectively utilize this information for our purpose. In this work we introduce a novel conceptual framework for estimating the win probability for each of the m algorithms, given their complete rankings over a benchmark of datasets. Our proposed framework significantly improves upon currently known methods in synthetic and real-world examples.

</details>


### [184] [Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives](https://arxiv.org/abs/2601.01665)
*Wei Liu,Yaoxin Wu,Yingqian Zhang,Thomas Bäck,Yingjie Fan*

Main category: cs.LG

TL;DR: 提出一个面向多目标组合优化问题的统一鲁棒性框架，包括偏好对抗攻击生成困难实例，以及通过对抗训练增强神经求解器鲁棒性的防御策略。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在多目标组合优化问题中表现出潜力，但其鲁棒性在多样复杂问题分布下尚未充分探索，需要系统评估和提升学习求解器的稳健性。

Method: 1) 提出统一鲁棒性框架；2) 开发基于偏好的对抗攻击方法生成困难实例；3) 通过帕累托前沿质量退化量化攻击影响；4) 引入防御策略，将难度感知偏好选择集成到对抗训练中，减少对受限偏好区域的过拟合。

Result: 在多目标旅行商问题、多目标容量车辆路径问题和多目标背包问题上验证：攻击方法成功为不同求解器生成困难实例；防御方法显著增强神经求解器的鲁棒性和泛化能力，在困难或分布外实例上表现优异。

Conclusion: 提出的统一鲁棒性框架有效评估和提升了多目标组合优化问题中深度强化学习求解器的稳健性，攻击方法能暴露求解器弱点，防御策略能增强泛化性能。

Abstract: Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.

</details>


### [185] [HeurekaBench: A Benchmarking Framework for AI Co-scientist](https://arxiv.org/abs/2601.01678)
*Siba Smarak Panigrahi,Jovana Videnović,Maria Brbić*

Main category: cs.LG

TL;DR: HeurekaBench是一个用于评估科学智能体的基准框架，通过半自动流程创建基于真实科学研究的开放式研究问题，并在单细胞生物学领域实例化为sc-HeurekaBench，用于评估和优化智能体系统设计。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的科学智能体系统缺乏现实的端到端评估方法，需要能够整合数据分析、解释和从实验数据生成新见解的真实研究场景来评估这些系统。

Method: 提出了HeurekaBench框架，采用半自动化流程：基于真实科学研究及其代码仓库创建开放式研究问题，利用多个LLM提取见解并生成候选工作流，然后与报告结果进行验证。在单细胞生物学领域实例化为sc-HeurekaBench基准。

Result: 使用sc-HeurekaBench评估了最先进的单细胞智能体，发现添加批评模块可以将开源LLM智能体的不良响应改善高达22%，缩小与闭源智能体的差距。展示了基准在定量分析智能体系统设计选择方面的价值。

Conclusion: HeurekaBench为科学智能体的严格端到端评估奠定了基础，将基准构建扎根于真实的科学工作流程中，推动了科学智能体评估方法的发展。

Abstract: LLM-based reasoning models have enabled the development of agentic systems that act as co-scientists, assisting in multi-step scientific analysis. However, evaluating these systems is challenging, as it requires realistic, end-to-end research scenarios that integrate data analysis, interpretation, and the generation of new insights from the experimental data. To address this limitation, we introduce HeurekaBench, a framework to create benchmarks with exploratory, open-ended research questions for experimental datasets. Each such question is grounded in a scientific study and its corresponding code repository, and is created using a semi-automated pipeline that leverages multiple LLMs to extract insights and generate candidate workflows, which are then verified against reported findings. We instantiate the framework in single-cell biology to obtain sc-HeurekaBench benchmark and use it to compare state-of-the-art single-cell agents. We further showcase the benefits of our benchmark for quantitatively analyzing current design choices in agentic systems. We find that the addition of a critic module can improve ill-formed responses for open-source LLM-based agents by up to 22% and close the gap with their closed-source counterparts. Overall, HeurekaBench sets a path toward rigorous, end-to-end evaluation of scientific agents, grounding benchmark construction in real scientific workflows.

</details>


### [186] [DiMEx: Breaking the Cold Start Barrier in Data-Free Model Extraction via Latent Diffusion Priors](https://arxiv.org/abs/2601.01688)
*Yash Thesia,Meera Suthar*

Main category: cs.LG

TL;DR: DiMEx利用预训练潜在扩散模型的语义先验，通过随机嵌入贝叶斯优化在潜在空间中合成高质量查询，显著提升无数据模型窃取效率；同时提出混合状态集成防御来检测此类攻击的优化轨迹特征。


<details>
  <summary>Details</summary>
Motivation: 针对机器学习即服务中的模型窃取攻击威胁，特别是无数据模型提取面临的"冷启动"问题——基于GAN的攻击者需要大量查询从随机噪声收敛到有意义数据，效率低下。

Method: 提出DiMEx框架，利用预训练潜在扩散模型的丰富语义先验，通过随机嵌入贝叶斯优化在生成器的潜在空间中直接合成高保真查询，绕过初始化障碍。

Result: 在SVHN数据集上仅用2000次查询就达到52.1%的协议率，比最先进的GAN基线高出16%以上；同时提出的混合状态集成防御能将攻击成功率抑制到21.6%。

Conclusion: DiMEx展示了利用预训练扩散模型语义先验进行高效模型窃取的可行性，而混合状态集成防御通过检测潜在空间攻击的独特优化轨迹特征，能有效对抗这种高语义威胁。

Abstract: Model stealing attacks pose an existential threat to Machine Learning as a Service (MLaaS), allowing adversaries to replicate proprietary models for a fraction of their training cost. While Data-Free Model Extraction (DFME) has emerged as a stealthy vector, it remains fundamentally constrained by the "Cold Start" problem: GAN-based adversaries waste thousands of queries converging from random noise to meaningful data. We propose DiMEx, a framework that weaponizes the rich semantic priors of pre-trained Latent Diffusion Models to bypass this initialization barrier entirely. By employing Random Embedding Bayesian Optimization (REMBO) within the generator's latent space, DiMEx synthesizes high-fidelity queries immediately, achieving 52.1 percent agreement on SVHN with just 2,000 queries - outperforming state-of-the-art GAN baselines by over 16 percent. To counter this highly semantic threat, we introduce the Hybrid Stateful Ensemble (HSE) defense, which identifies the unique "optimization trajectory" of latent-space attacks. Our results demonstrate that while DiMEx evades static distribution detectors, HSE exploits this temporal signature to suppress attack success rates to 21.6 percent with negligible latency.

</details>


### [187] [Enhanced Multi-model Online Conformal Prediction](https://arxiv.org/abs/2601.01692)
*Erfan Hajihashemi,Yanning Shen*

Main category: cs.LG

TL;DR: 提出了一种新颖的多模型在线共形预测算法，通过构建二分图选择有效模型子集，降低计算复杂度并提高预测效率


<details>
  <summary>Details</summary>
Motivation: 传统共形预测依赖单一固定模型，在在线环境中可能表现不稳定；现有多模型选择方法计算成本高且可能受性能较差模型影响

Method: 开发了多模型在线共形预测算法，在每个时间步生成二分图来识别有效模型子集，从中选择模型构建预测集

Result: 实验表明该方法在预测集大小和计算效率方面均优于现有的多模型共形预测技术

Conclusion: 提出的算法有效解决了多模型共形预测中的计算复杂度和预测效率问题，为在线环境下的不确定性量化提供了更优方案

Abstract: Conformal prediction is a framework for uncertainty quantification that constructs prediction sets for previously unseen data, guaranteeing coverage of the true label with a specified probability. However, the efficiency of these prediction sets, measured by their size, depends on the choice of the underlying learning model. Relying on a single fixed model may lead to suboptimal performance in online environments, as a single model may not consistently perform well across all time steps. To mitigate this, prior work has explored selecting a model from a set of candidates. However, this approach becomes computationally expensive as the number of candidate models increases. Moreover, poorly performing models in the set may also hinder the effectiveness. To tackle this challenge, this work develops a novel multi-model online conformal prediction algorithm that reduces computational complexity and improves prediction efficiency. At each time step, a bipartite graph is generated to identify a subset of effective models, from which a model is selected to construct the prediction set. Experiments demonstrate that our method outperforms existing multi-model conformal prediction techniques in terms of both prediction set size and computational efficiency.

</details>


### [188] [Entropy-Aligned Decoding of LMs for Better Writing and Reasoning](https://arxiv.org/abs/2601.01714)
*Kareem Ahmed,Sameer Singh*

Main category: cs.LG

TL;DR: EPIC是一种超参数自由的解码方法，通过将未来轨迹的熵纳入语言模型解码，在每一步生成时显式调节不确定性，使采样分布的熵与数据不确定性对齐，从而提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型解码算法依赖贪婪启发式方法，导致短视失真，产生同质化、重复且不连贯的句子。需要一种能够更好地对齐数据不确定性的解码方法。

Method: EPIC通过熵感知惰性Gumbel-Max采样，将未来轨迹的熵纳入解码过程，显式调节每一步生成的不确定性，使采样分布的熵与数据（偶然）不确定性对齐。该方法精确且高效，每步仅需亚线性次数的熵评估。

Result: 在创意写作和摘要任务中，EPIC在LM-as-judge偏好胜率上持续优于广泛使用的解码策略。自动指标显示EPIC产生更多样化的生成和更忠实的摘要。在数学推理任务中，EPIC也优于所有基线方法。

Conclusion: EPIC通过将熵意识纳入解码过程，能够产生更高质量、更多样化且更忠实的语言生成，优于现有的解码策略。

Abstract: Language models (LMs) are trained on billions of tokens in an attempt to recover the true language distribution. Still, vanilla random sampling from LMs yields low quality generations. Decoding algorithms attempt to restrict the LM distribution to a set of high-probability continuations, but rely on greedy heuristics that introduce myopic distortions, yielding sentences that are homogeneous, repetitive and incoherent. In this paper, we introduce EPIC, a hyperparameter-free decoding approach that incorporates the entropy of future trajectories into LM decoding. EPIC explicitly regulates the amount of uncertainty expressed at every step of generation, aligning the sampling distribution's entropy to the aleatoric (data) uncertainty. Through Entropy-Aware Lazy Gumbel-Max sampling, EPIC manages to be exact, while also being efficient, requiring only a sublinear number of entropy evaluations per step. Unlike current baselines, EPIC yields sampling distributions that are empirically well-aligned with the entropy of the underlying data distribution. Across creative writing and summarization tasks, EPIC consistently improves LM-as-judge preference win-rates over widely used decoding strategies. These preference gains are complemented by automatic metrics, showing that EPIC produces more diverse generations and more faithful summaries. We also evaluate EPIC on mathematical reasoning, where it outperforms all baselines.

</details>


### [189] [Context-Free Recognition with Transformers](https://arxiv.org/abs/2601.01754)
*Selim Jerad,Anej Svete,Sophie Hao,Ryan Cotterell,William Merrill*

Main category: cs.LG

TL;DR: 本文证明循环Transformer通过O(log n)循环层和O(n^6)填充token可以识别所有上下文无关语言，但对于自然子类如无歧义CFL，仅需O(n^3)填充token，使识别更高效。


<details>
  <summary>Details</summary>
Motivation: Transformer在处理自然语言和代码等符合语法规则的输入时表现出色，但其处理语法结构的能力尚不明确。现有研究表明标准Transformer无法识别上下文无关语言（CFL），甚至无法识别其子类正则语言。虽然已有工作证明O(log n)循环层可使Transformer识别正则语言，但CFL识别问题仍未解决。

Method: 提出循环Transformer架构，使用O(log n)循环层和O(n^6)填充token来实现CFL识别。特别地，对于无歧义CFL等自然子类，将填充token需求降低到O(n^3)。通过理论分析和实验验证，在需要对数深度的语言上测试循环机制的有效性。

Result: 理论证明循环Transformer能够识别所有CFL，但需要大量填充token（O(n^6)）。对于无歧义CFL等自然子类，填充需求显著降低至O(n^3)。实验验证循环机制在需要对数深度的语言上确实有效。

Conclusion: Transformer识别CFL存在复杂性：通用识别可能需要不切实际的大量填充token，但通过自然约束（如无歧义性）可以实现高效的识别算法。循环机制为Transformer处理语法结构提供了理论依据。

Abstract: Transformers excel on tasks that process well-formed inputs according to some grammar, such as natural language and code. However, it remains unclear how they can process grammatical syntax. In fact, under standard complexity conjectures, standard transformers cannot recognize context-free languages (CFLs), a canonical formalism to describe syntax, or even regular languages, a subclass of CFLs (Merrill et al., 2022). Merrill & Sabharwal (2024) show that $\mathcal{O}(\log n)$ looping layers (w.r.t. input length $n$) allows transformers to recognize regular languages, but the question of context-free recognition remained open. In this work, we show that looped transformers with $\mathcal{O}(\log n)$ looping layers and $\mathcal{O}(n^6)$ padding tokens can recognize all CFLs. However, training and inference with $\mathcal{O}(n^6)$ padding tokens is potentially impractical. Fortunately, we show that, for natural subclasses such as unambiguous CFLs, the recognition problem on transformers becomes more tractable, requiring $\mathcal{O}(n^3)$ padding. We empirically validate our results and show that looping helps on a language that provably requires logarithmic depth. Overall, our results shed light on the intricacy of CFL recognition by transformers: While general recognition may require an intractable amount of padding, natural constraints such as unambiguity yield efficient recognition algorithms.

</details>


### [190] [HyperCLOVA X 8B Omni](https://arxiv.org/abs/2601.01792)
*NAVER Cloud HyperCLOVA X Team*

Main category: cs.LG

TL;DR: HyperCLOVA X 8B Omni是首个支持文本、音频、视觉任意输入输出的全模态模型，通过统一的多模态序列处理实现理解和生成功能。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的任意到任意全模态助手，避免传统多模态系统中分离的模态特定处理流程，实现更实用的多模态交互。

Method: 采用共享的下一个token预测接口处理交错的多模态序列，通过视觉和音频编码器注入连续嵌入以实现细粒度理解和接地。

Result: 在韩语和英语的文本、音频、视觉多种输入输出组合中，相比同等规模模型表现出有竞争力的性能。

Conclusion: HyperCLOVA X 8B Omni作为8B规模的全模态探索点，其开源权重将支持广泛的研究和部署场景。

Abstract: In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.

</details>


### [191] [Distributed Federated Learning by Alternating Periods of Training](https://arxiv.org/abs/2601.01793)
*Shamik Bhattacharyya,Rachel Kalpana Kalaimani*

Main category: cs.LG

TL;DR: 本文提出了一种分布式联邦学习框架，通过多服务器架构解决传统联邦学习中单点故障和可扩展性问题，设计了DFL算法实现服务器间的协同训练。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习依赖单一中央服务器，在面对大量客户端时存在可扩展性挑战，并存在单点故障风险。需要解决这些关键限制，提高系统的容错性和可扩展性。

Method: 提出分布式联邦学习方法，包含多个具有服务器间通信能力的服务器。每个服务器关联一组不相交的客户端，保持服务器-客户端通信能力。设计了DFL算法，交替进行客户端数据的本地训练和服务器间的全局训练。

Result: 在适当参数选择下，DFL算法确保所有服务器收敛到共同模型值，与理想模型的误差在较小容忍范围内，有效整合了本地和全局训练模型。通过数值模拟验证了理论主张。

Conclusion: 分布式联邦学习框架成功解决了传统联邦学习的可扩展性和容错性问题，通过多服务器架构和DFL算法实现了有效的分布式训练，为大规模联邦学习应用提供了可行方案。

Abstract: Federated learning is a privacy-focused approach towards machine learning where models are trained on client devices with locally available data and aggregated at a central server. However, the dependence on a single central server is challenging in the case of a large number of clients and even poses the risk of a single point of failure. To address these critical limitations of scalability and fault-tolerance, we present a distributed approach to federated learning comprising multiple servers with inter-server communication capabilities. While providing a fully decentralized approach, the designed framework retains the core federated learning structure where each server is associated with a disjoint set of clients with server-client communication capabilities. We propose a novel DFL (Distributed Federated Learning) algorithm which uses alternating periods of local training on the client data followed by global training among servers. We show that the DFL algorithm, under a suitable choice of parameters, ensures that all the servers converge to a common model value within a small tolerance of the ideal model, thus exhibiting effective integration of local and global training models. Finally, we illustrate our theoretical claims through numerical simulations.

</details>


### [192] [Moments Matter:Stabilizing Policy Optimization using Return Distributions](https://arxiv.org/abs/2601.01803)
*Dennis Jabs,Aditya Mohan,Marius Lindauer*

Main category: cs.LG

TL;DR: 提出一种基于分布评论家高阶矩的PPO改进方法，通过惩罚极端回报分布来提升策略稳定性


<details>
  <summary>Details</summary>
Motivation: 深度强化学习智能体在相同回报下可能表现出不同的行为，这种不稳定性源于环境和算法因素。连续控制任务中，即使小的参数变化也会导致不稳定步态，这给算法比较和实际应用带来困难。

Method: 通过分布评论家建模状态-动作回报分布，利用该分布的高阶矩（偏度和峰度）对PPO的优势函数进行偏置修正，通过惩罚极端尾部行为来避免策略进入不稳定参数区域。

Result: 在Walker2D环境中，该方法将策略稳定性提升了75%，同时保持了可比较的评估回报。

Conclusion: 利用环境随机性和分布评论家的高阶矩信息可以有效改善PPO的稳定性，特别是在后更新评论家值与后更新回报对齐不佳的情况下，该方法能显著缩小回报分布范围，提升策略鲁棒性。

Abstract: Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.

</details>


### [193] [RealPDEBench: A Benchmark for Complex Physical Systems with Real-World Data](https://arxiv.org/abs/2601.01829)
*Peiyan Hu,Haodong Feng,Hongyuan Liu,Tongtong Yan,Wenhao Deng,Tianrun Gao,Rong Zheng,Haoren Zheng,Chenglei Yu,Chuanrui Wang,Kaiwen Li,Zhi-Ming Ma,Dezhi Zhou,Xingcai Lu,Dixia Fan,Tailin Wu*

Main category: cs.LG

TL;DR: RealPDEBench是首个整合真实世界测量数据与配对数值模拟的科学机器学习基准，包含5个数据集、3个任务、8个指标和10个基线模型，旨在解决科学ML中真实数据缺乏的问题，促进模拟到现实的迁移研究。


<details>
  <summary>Details</summary>
Motivation: 当前科学机器学习模型面临的主要瓶颈是缺乏昂贵的真实世界数据，导致大多数模型只能在模拟数据上训练和验证，这不仅限制了科学ML的发展评估，也阻碍了模拟到现实迁移等关键任务的研究。

Method: 构建了包含5个真实世界测量数据集及其配对模拟数据集的基准，定义了3个任务（允许真实与模拟数据比较并促进两者桥接方法开发），设计了8个评估指标（涵盖数据导向和物理导向指标），并基准测试了10个代表性基线模型。

Result: 实验揭示了模拟数据与真实世界数据之间存在显著差异，同时表明使用模拟数据进行预训练能持续提高模型的准确性和收敛性。

Conclusion: RealPDEBench通过提供真实世界数据的见解，推动科学机器学习向桥接模拟与现实差距和实际部署方向发展，为相关研究提供了重要的基准平台。

Abstract: Predicting the evolution of complex physical systems remains a central problem in science and engineering. Despite rapid progress in scientific Machine Learning (ML) models, a critical bottleneck is the lack of expensive real-world data, resulting in most current models being trained and validated on simulated data. Beyond limiting the development and evaluation of scientific ML, this gap also hinders research into essential tasks such as sim-to-real transfer. We introduce RealPDEBench, the first benchmark for scientific ML that integrates real-world measurements with paired numerical simulations. RealPDEBench consists of five datasets, three tasks, eight metrics, and ten baselines. We first present five real-world measured datasets with paired simulated datasets across different complex physical systems. We further define three tasks, which allow comparisons between real-world and simulated data, and facilitate the development of methods to bridge the two. Moreover, we design eight evaluation metrics, spanning data-oriented and physics-oriented metrics, and finally benchmark ten representative baselines, including state-of-the-art models, pretrained PDE foundation models, and a traditional method. Experiments reveal significant discrepancies between simulated and real-world data, while showing that pretraining with simulated data consistently improves both accuracy and convergence. In this work, we hope to provide insights from real-world data, advancing scientific ML toward bridging the sim-to-real gap and real-world deployment. Our benchmark, datasets, and instructions are available at https://realpdebench.github.io/.

</details>


### [194] [FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks](https://arxiv.org/abs/2601.01833)
*Chenyu Hu,Qiming Hu,Sinan Chen,Nianyu Li,Mingyue Zhang,Jialong Li*

Main category: cs.LG

TL;DR: FAROS：一个增强的联邦学习框架，通过自适应差分缩放和鲁棒核心集计算来防御后门攻击，相比现有防御方法在攻击成功率和主任务准确性上表现更优。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临后门攻击的严重威胁，现有防御方法依赖固定参数，存在单点故障风险，难以应对复杂攻击者策略。

Method: 提出FAROS框架，包含自适应差分缩放（ADS）机制和鲁棒核心集计算（RCC）。ADS根据客户端上传梯度的离散度动态调整防御灵敏度；RCC通过计算高置信度客户端核心集的质心来降低单点故障风险。

Result: 在多种数据集、模型和攻击场景下的实验表明，该方法在攻击成功率和主任务准确性方面均优于现有防御方法。

Conclusion: FAROS通过动态自适应防御机制有效应对联邦学习中的后门攻击，解决了现有防御方法的局限性。

Abstract: Federated Learning (FL) enables multiple clients to collaboratively train a shared model without exposing local data. However, backdoor attacks pose a significant threat to FL. These attacks aim to implant a stealthy trigger into the global model, causing it to mislead on inputs that possess a specific trigger while functioning normally on benign data. Although pre-aggregation detection is a main defense direction, existing state-of-the-art defenses often rely on fixed defense parameters. This reliance makes them vulnerable to single-point-of-failure risks, rendering them less effective against sophisticated attackers. To address these limitations, we propose FAROS, an enhanced FL framework that incorporates Adaptive Differential Scaling (ADS) and Robust Core-set Computing (RCC). The ADS mechanism adjusts the defense's sensitivity dynamically, based on the dispersion of uploaded gradients by clients in each round. This allows it to counter attackers who strategically shift between stealthiness and effectiveness. Furthermore, the RCC effectively mitigates the risk of single-point failure by computing the centroid of a core set comprising clients with the highest confidence. We conducted extensive experiments across various datasets, models, and attack scenarios. The results demonstrate that our method outperforms current defenses in both attack success rate and main task accuracy.

</details>


### [195] [Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack](https://arxiv.org/abs/2601.01840)
*Qiantao Yang,Liquan Chen,Mingfu Xue,Songze Li*

Main category: cs.LG

TL;DR: FedCSPACK：一种基于余弦稀疏化参数打包和双权重聚合的个性化联邦学习方法，通过参数打包和选择性共享减少带宽需求，利用掩码矩阵和权重聚合机制提升模型性能，在保持高精度的同时提高通信和计算效率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中边缘客户端的数据异构性会降低模型性能，现有方法虽然通过模型分割和知识蒸馏增强模型兼容性，但忽视了客户端有限的通信带宽和计算能力，未能有效平衡处理数据异构性和适应有限客户端资源之间的矛盾。

Method: 提出FedCSPACK方法：1）客户端打包模型参数，基于余弦相似度选择贡献最大的参数包进行共享，减少带宽需求；2）客户端生成基于共享参数包的掩码矩阵，提高稀疏更新在服务器上的对齐和聚合效率；3）在掩码中嵌入方向和分布距离权重，实现加权引导聚合机制，增强全局模型的鲁棒性和泛化性能。

Result: 在四个数据集上使用十种最先进方法的广泛实验表明，FedCSPACK在保持高模型精度的同时，有效提高了通信和计算效率。

Conclusion: FedCSPACK通过参数打包、选择性共享和双权重聚合机制，有效解决了联邦学习中数据异构性和有限客户端资源之间的平衡问题，在提高效率的同时保持了模型性能。

Abstract: Federated learning has drawn widespread interest from researchers, yet the data heterogeneity across edge clients remains a key challenge, often degrading model performance. Existing methods enhance model compatibility with data heterogeneity by splitting models and knowledge distillation. However, they neglect the insufficient communication bandwidth and computing power on the client, failing to strike an effective balance between addressing data heterogeneity and accommodating limited client resources. To tackle this limitation, we propose a personalized federated learning method based on cosine sparsification parameter packing and dual-weighted aggregation (FedCSPACK), which effectively leverages the limited client resources and reduces the impact of data heterogeneity on model performance. In FedCSPACK, the client packages model parameters and selects the most contributing parameter packages for sharing based on cosine similarity, effectively reducing bandwidth requirements. The client then generates a mask matrix anchored to the shared parameter package to improve the alignment and aggregation efficiency of sparse updates on the server. Furthermore, directional and distribution distance weights are embedded in the mask to implement a weighted-guided aggregation mechanism, enhancing the robustness and generalization performance of the global model. Extensive experiments across four datasets using ten state-of-the-art methods demonstrate that FedCSPACK effectively improves communication and computational efficiency while maintaining high model accuracy.

</details>


### [196] [High-Order Epistasis Detection Using Factorization Machine with Quadratic Optimization Annealing and MDR-Based Evaluation](https://arxiv.org/abs/2601.01860)
*Shuta Kikuchi,Shu Tanaka*

Main category: cs.LG

TL;DR: 提出基于因子分解机和二次优化退火的FMQA方法，用于高效检测高阶上位性相互作用，解决传统MDR方法计算复杂度爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 传统多因子降维方法在检测高阶上位性时面临组合爆炸问题，计算不可行。需要开发高效算法来识别遗传关联研究中的高阶相互作用。

Method: 将上位性检测问题定义为黑盒优化问题，使用因子分解机结合二次优化退火算法，以MDR计算的分类错误率作为目标函数。

Result: 在模拟病例对照数据集上成功识别出预定义的高阶上位性相互作用，在不同交互阶数和遗传位点数量下都能在有限迭代次数内找到真实相互作用。

Conclusion: 提出的FMQA方法对于高阶上位性检测既有效又计算高效，为解决遗传关联研究中的组合爆炸问题提供了可行方案。

Abstract: Detecting high-order epistasis is a fundamental challenge in genetic association studies due to the combinatorial explosion of candidate locus combinations. Although multifactor dimensionality reduction (MDR) is a widely used method for evaluating epistasis, exhaustive MDR-based searches become computationally infeasible as the number of loci or the interaction order increases. In this paper, we define the epistasis detection problem as a black-box optimization problem and solve it with a factorization machine with quadratic optimization annealing (FMQA). We propose an efficient epistasis detection method based on FMQA, in which the classification error rate (CER) computed by MDR is used as a black-box objective function. Experimental evaluations were conducted using simulated case-control datasets with predefined high-order epistasis. The results demonstrate that the proposed method successfully identified ground-truth epistasis across various interaction orders and the numbers of genetic loci within a limited number of iterations. These results indicate that the proposed method is effective and computationally efficient for high-order epistasis detection.

</details>


### [197] [Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance](https://arxiv.org/abs/2601.01887)
*Jiawen Zhang,Lipeng He,Kejia Chen,Jian Lou,Jian Liu,Xiaohu Yang,Ruoxi Jia*

Main category: cs.LG

TL;DR: 仅需单个安全样本即可完全恢复安全对齐大语言模型，无需牺牲实用性，成本极低


<details>
  <summary>Details</summary>
Motivation: 传统安全对齐方法需要大量安全样本或校准集，导致计算开销大且模型实用性下降。研究发现安全对齐可以更高效地恢复

Method: 使用单个安全示例进行微调恢复安全对齐，揭示安全梯度的低秩结构，证明高效修正的可能性

Result: 无论有害示例数量或模型大小，仅需单个安全样本即可在几个epoch内有效恢复安全对齐，在五个安全对齐LLM和多个数据集上验证了方法的通用性

Conclusion: 安全对齐可以通过极低成本高效恢复，安全梯度的低秩结构解释了这种高效修正的可能性，为LLM安全对齐提供了新思路

Abstract: Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.

</details>


### [198] [FedBiCross: A Bi-Level Optimization Framework to Tackle Non-IID Challenges in Data-Free One-Shot Federated Learning on Medical Data](https://arxiv.org/abs/2601.01901)
*Yuexuan Xia,Yinghao Zhang,Yalin Liu,Hong-Ning Dai,Yong Xia*

Main category: cs.LG

TL;DR: FedBiCross是一个用于非IID医疗数据的个性化单轮联邦学习框架，通过聚类、双层跨集群优化和个性化蒸馏解决现有方法在非IID数据下预测冲突导致监督信号弱的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的单轮联邦学习方法在非IID数据下存在严重问题：将所有客户端的预测聚合形成全局教师模型时，冲突的预测在平均过程中相互抵消，产生接近均匀分布的软标签，导致蒸馏监督信号弱。

Method: FedBiCross包含三个阶段：1）基于模型输出相似性对客户端进行聚类，形成一致的子集成；2）双层跨集群优化，学习自适应权重以选择性地利用有益的跨集群知识，同时抑制负迁移；3）个性化蒸馏进行客户端特定适应。

Result: 在四个医疗图像数据集上的实验表明，FedBiCross在不同非IID程度下始终优于最先进的基线方法。

Conclusion: FedBiCross通过聚类和选择性知识转移有效解决了非IID数据下单轮联邦学习中预测冲突的问题，为隐私敏感的医疗应用提供了有效的个性化解决方案。

Abstract: Data-free knowledge distillation-based one-shot federated learning (OSFL) trains a model in a single communication round without sharing raw data, making OSFL attractive for privacy-sensitive medical applications. However, existing methods aggregate predictions from all clients to form a global teacher. Under non-IID data, conflicting predictions cancel out during averaging, yielding near-uniform soft labels that provide weak supervision for distillation. We propose FedBiCross, a personalized OSFL framework with three stages: (1) clustering clients by model output similarity to form coherent sub-ensembles, (2) bi-level cross-cluster optimization that learns adaptive weights to selectively leverage beneficial cross-cluster knowledge while suppressing negative transfer, and (3) personalized distillation for client-specific adaptation. Experiments on four medical image datasets demonstrate that FedBiCross consistently outperforms state-of-the-art baselines across different non-IID degrees.

</details>


### [199] [Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning](https://arxiv.org/abs/2601.01904)
*Yuxuan Li,Harshith Reddy Kethireddy,Srijita Das*

Main category: cs.LG

TL;DR: 该研究提出并评估了强化学习偏好学习中的特征依赖性噪声概念，发现在某些特征依赖性噪声设置下，最先进的噪声鲁棒方法性能显著下降，而无显式去噪的方法反而表现更好。


<details>
  <summary>Details</summary>
Motivation: 强化学习偏好学习（PbRL）在奖励函数不易获得的复杂任务中具有优势，但偏好数据通常存在不确定性和噪声。现有研究主要检测噪声，但噪声类型有限且大多与观测无关。本研究旨在解决特征依赖性噪声问题。

Method: 形式化特征依赖性噪声概念，提出多种变体：轨迹特征噪声、轨迹相似性噪声、不确定性感知噪声和语言模型噪声。在DMControl和Meta-world的复杂连续控制任务中评估特征依赖性噪声。

Result: 实验表明，在某些特征依赖性噪声设置下，最先进的噪声鲁棒PbRL方法的学习性能显著恶化，而无显式去噪的PbRL方法在多数设置中意外地优于噪声鲁棒方法。语言模型噪声表现出与特征依赖性噪声相似的特征。

Conclusion: 特征依赖性噪声对现有噪声鲁棒方法构成挑战，语言模型噪声模拟了真实人类偏好噪声的特征。研究呼吁进一步研究如何鲁棒地学习特征依赖性噪声。

Abstract: Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.
  We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.
  We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.

</details>


### [200] [Distorted Distributional Policy Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2601.01917)
*Ryo Iwaki,Takayuki Osogami*

Main category: cs.LG

TL;DR: 论文提出了一种新的离线分布强化学习方法，通过引入分位数扭曲概念实现非均匀悲观主义，解决了现有方法因均匀低估回报分位数而导致的过度保守问题。


<details>
  <summary>Details</summary>
Motivation: 现有离线分布强化学习方法在离线场景中表现有限，主要问题在于它们采用均匀低估回报分位数的方法，这种均匀悲观主义会导致过于保守的价值估计，从而阻碍泛化能力和性能提升。

Method: 引入了一个新概念——分位数扭曲，通过基于支持数据的可用性调整保守程度，实现非均匀悲观主义。该方法基于理论分析，并通过实验验证其有效性。

Result: 该方法在实验中表现出改进的性能，相比均匀悲观主义方法有更好的表现。

Conclusion: 通过分位数扭曲实现非均匀悲观主义是解决离线分布强化学习中过度保守问题的有效方法，能够提升离线场景下的性能表现。

Abstract: While Distributional Reinforcement Learning (DRL) methods have demonstrated strong performance in online settings, its success in offline scenarios remains limited. We hypothesize that a key limitation of existing offline DRL methods lies in their approach to uniformly underestimate return quantiles. This uniform pessimism can lead to overly conservative value estimates, ultimately hindering generalization and performance. To address this, we introduce a novel concept called quantile distortion, which enables non-uniform pessimism by adjusting the degree of conservatism based on the availability of supporting data. Our approach is grounded in theoretical analysis and empirically validated, demonstrating improved performance over uniform pessimism.

</details>


### [201] [DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems](https://arxiv.org/abs/2601.01931)
*Willem Röpke,Samuel Coward,Andrei Lupu,Thomas Foster,Tim Rocktäschel,Jakob Foerster*

Main category: cs.LG

TL;DR: DéjàQ框架通过进化合成数学问题来增强推理模型训练，避免静态数据集导致的记忆化问题，使用LLM驱动的变异策略动态调整训练数据


<details>
  <summary>Details</summary>
Motivation: 现有推理模型大多依赖静态数据集，这可能导致记忆化而非泛化能力的提升，限制了数学推理模型的进一步发展

Method: 提出DéjàQ框架，在模型训练过程中联合进化多样化的合成数学问题集，采用两种LLM驱动的变异策略：改变上下文细节或直接修改问题结构

Result: 模型能够生成新颖且有意义的数学问题，LLM驱动的变异策略改善了强化学习训练效果，生成的数学问题具有有效性，计算开销可控

Conclusion: 动态进化训练数据能有效增强数学推理能力，该方法具有更广泛的适用性，作者将开源代码以支持进一步研究

Abstract: Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.

</details>


### [202] [SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling](https://arxiv.org/abs/2601.01943)
*Tieu-Long Phan,Nhu-Ngoc Nguyen Song,Peter F. Stadler*

Main category: cs.LG

TL;DR: SynRXN是一个用于计算机辅助合成规划的基准测试框架和开放数据资源，将合成规划分解为五个任务族，提供标准化数据集、评估流程和可复现的构建方法。


<details>
  <summary>Details</summary>
Motivation: 当前计算机辅助合成规划领域缺乏统一的基准测试框架，数据集异构且评估标准不统一，难以进行公平的方法比较和性能评估。

Method: 将端到端合成规划分解为五个任务族：反应平衡、原子映射、反应分类、反应性质预测和合成路线设计；从异构公共来源收集反应数据并统一表示；提供透明的数据分割函数、标准化评估工作流程和指标套件；采用脚本化构建方法确保可复现性。

Result: 创建了一个包含版本化数据集、明确元数据、许可标签和机器可读清单的资源；提供了泄漏感知的数据分割和敏感任务的评估集；支持公平的纵向方法比较和严谨的消融实验。

Conclusion: SynRXN通过消除数据集异质性并提供透明可重用的评估框架，支持计算机辅助合成规划方法的公平比较，降低了从业者获取稳健可比性能评估的门槛。

Abstract: We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.

</details>


### [203] [Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior](https://arxiv.org/abs/2601.01966)
*Bo Yin,Qi Li,Runpeng Yu,Xinchao Wang*

Main category: cs.LG

TL;DR: 本文提出RePro框架，用于推断指令调优训练数据中提示是否经过LLM改写，解决数据集治理和争议中的实例级审计问题。


<details>
  <summary>Details</summary>
Motivation: 指令调优越来越多地依赖LLM进行提示改写，这引发了实例级审计需求：对于微调模型和训练提示-响应对，能否推断模型是在原始提示还是其LLM改写版本上训练的？这对数据集治理和训练数据争议解决很重要。

Method: 将审计任务形式化为Refinement Provenance Inference (RPI)，提出RePro框架：利用提示改写导致的教师强制token分布稳定偏移，融合教师强制似然特征和logit排序信号，通过影子微调学习可迁移表示，使用轻量级线性头进行推断。

Result: RePro在实证中表现强劲且能很好地跨改写器迁移，表明其利用了改写器无关的分布偏移而非改写风格伪影。

Conclusion: 提示改写会产生可检测的分布偏移，RePro框架能有效解决指令调优训练数据的实例级审计问题，具有实际应用价值。

Abstract: Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.

</details>


### [204] [SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition](https://arxiv.org/abs/2601.01979)
*Julie Keisler,Anastase Alexandre Charantonis,Yannig Goude,Boutheina Oueslati,Claire Monteleoni*

Main category: cs.LG

TL;DR: SerpentFlow提出了一种无配对域对齐的生成框架，通过将数据分解为共享结构和域特定组件，利用共享表示与目标域样本构建合成训练对，实现条件生成模型在无配对场景下的应用。


<details>
  <summary>Details</summary>
Motivation: 在无配对观测的情况下进行域对齐具有挑战性，因为缺乏跨域的直接监督。现有方法难以处理共享结构模式但具体实现不同的域之间的对齐问题。

Method: SerpentFlow在潜在空间中将数据分解为共享组件和域特定组件。通过隔离共享结构并用随机噪声替换域特定组件，构建共享表示与目标域样本之间的合成训练对，从而支持条件生成模型的应用。在超分辨率任务中，共享组件对应低频内容，高频细节捕获域特定变异性，使用基于分类器的准则自动确定分离频率。

Result: 在合成图像、物理过程模拟和气候降尺度任务上的实验表明，该方法能有效重建与底层低频模式一致的高频结构，支持共享结构分解作为无配对域对齐的有效策略。

Conclusion: 共享结构分解为无配对域对齐提供了有效框架，通过构建合成训练对使传统需要配对数据的条件生成模型能够在无监督场景下应用，在多个任务中表现出色。

Abstract: Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.

</details>


### [205] [Prior Diffusiveness and Regret in the Linear-Gaussian Bandit](https://arxiv.org/abs/2601.02022)
*Yifan Zhu,John C. Duchi,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 本文证明了Thompson采样在线性高斯多臂赌博机问题中具有$\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$的贝叶斯遗憾界，其中先验依赖的"预热"项与极小极大遗憾项呈加法分离而非乘法关系。


<details>
  <summary>Details</summary>
Motivation: 现有Thompson采样在线性高斯赌博机中的遗憾界中，先验依赖的"预热"项与长期极小极大遗憾项呈乘法关系。本文旨在证明这两个项实际上可以加法分离，从而更精确地刻画算法的性能。

Method: 通过新的"椭圆势能"引理来分析Thompson采样的遗憾界，该方法能够分离先验依赖项和长期遗憾项。同时提供了下界证明来表明预热项是不可避免的。

Result: 证明了Thompson采样具有$\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$的贝叶斯遗憾界，其中$d$是维度，$T$是时间范围，$r$是动作的最大$\ell_2$范数，$σ^2$是噪声方差。先验依赖项与长期遗憾项呈加法关系而非乘法关系。

Conclusion: Thompson采样在线性高斯赌博机中的遗憾界可以分解为加法形式：先验依赖的预热项$d r \sqrt{\mathrm{Tr}(Σ_0)}$和长期极小极大遗憾项$σd \sqrt{T}$。这种加法分离比现有乘法关系更精确，且下界表明预热项是不可避免的。

Abstract: We prove that Thompson sampling exhibits $\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$ Bayesian regret in the linear-Gaussian bandit with a $\mathcal{N}(μ_0, Σ_0)$ prior distribution on the coefficients, where $d$ is the dimension, $T$ is the time horizon, $r$ is the maximum $\ell_2$ norm of the actions, and $σ^2$ is the noise variance. In contrast to existing regret bounds, this shows that to within logarithmic factors, the prior-dependent ``burn-in'' term $d r \sqrt{\mathrm{Tr}(Σ_0)}$ decouples additively from the minimax (long run) regret $σd \sqrt{T}$. Previous regret bounds exhibit a multiplicative dependence on these terms. We establish these results via a new ``elliptical potential'' lemma, and also provide a lower bound indicating that the burn-in term is unavoidable.

</details>


### [206] [Output Embedding Centering for Stable LLM Pretraining](https://arxiv.org/abs/2601.02031)
*Felix Stollenwerk,Anna Lokrantz,Niclas Hertzberg*

Main category: cs.LG

TL;DR: 论文提出输出嵌入中心化(OEC)方法，通过μ-中心化和μ-损失两种方式解决大语言模型预训练中的输出对数发散问题，相比z-loss更有效且超参数调优更简单。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型预训练不仅昂贵，而且容易出现训练不稳定性。在训练后期使用大学习率时经常出现的特定不稳定性是输出对数发散。最广泛使用的缓解策略z-loss仅解决了问题的症状而非根本原因。

Method: 从输出嵌入几何角度分析不稳定性，提出输出嵌入中心化(OEC)作为新的缓解策略。OEC可通过两种方式实现：作为确定性操作的μ-中心化，或作为正则化方法的μ-损失。

Result: 两种OEC变体在训练稳定性和学习率敏感性方面都优于z-loss。特别是，当z-loss失败时，它们确保训练即使在大学习率下也能收敛。此外，μ-损失在正则化超参数调优方面比z-loss显著更不敏感。

Conclusion: 输出嵌入中心化(OEC)通过解决输出对数发散的根本原因，提供了比z-loss更有效的训练稳定性解决方案，μ-损失在超参数调优方面具有显著优势。

Abstract: Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.

</details>


### [207] [GDRO: Group-level Reward Post-training Suitable for Diffusion Models](https://arxiv.org/abs/2601.02036)
*Yiyang Wang,Xi Chen,Xiaogang Xu,Yu Liu,Hengshuang Zhao*

Main category: cs.LG

TL;DR: 本文提出GDRO（Group-level Direct Reward Optimization），一种针对整流流扩散模型的群体级奖励对齐后训练范式，解决了现有在线强化学习方法效率低、依赖随机采样器和奖励黑客问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用在线强化学习从LLMs到文本到图像整流流扩散模型进行奖励对齐，虽然能成功对齐目标奖励，但面临效率低、依赖随机采样器和奖励黑客等挑战。整流流模型与LLMs有本质区别：1）在线图像采样耗时大；2）整流流是确定性的（一旦初始噪声固定）。

Method: 提出GDRO，结合整流流模型特性的群体级奖励对齐后训练范式。通过理论分析证明GDRO支持完全离线训练，节省图像采样时间；扩散采样器独立，无需ODE-to-SDE近似来获得随机性；同时考虑奖励黑客陷阱，在评估中使用校正分数。

Result: 在OCR和GenEval任务上的大量实验表明，GDRO通过群体级离线优化有效且高效地提高了扩散模型的奖励分数，同时在缓解奖励黑客方面表现出强大的稳定性和鲁棒性。

Conclusion: GDRO为整流流扩散模型提供了一种高效、稳定且鲁棒的群体级奖励对齐方法，解决了现有在线强化学习方法的关键局限性，实现了完全离线训练和采样器独立性。

Abstract: Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.

</details>


### [208] [Explore the Ideology of Deep Learning in ENSO Forecasts](https://arxiv.org/abs/2601.02050)
*Yanhai Gan,Yipeng Chen,Ning Li,Xingguo Liu,Junyu Dong,Xianyao Chen*

Main category: cs.LG

TL;DR: 该论文提出了一种基于有界变差函数的数学可解释性框架，通过激活饱和区的"死亡"神经元来增强模型表达能力，揭示了ENSO可预测性主要来自热带太平洋，并分析了春季可预测性障碍的成因。


<details>
  <summary>Details</summary>
Motivation: ENSO对全球气候变率有深远影响，但其预测仍是重大挑战。虽然深度学习显著提高了预测技能，但这些模型的不透明性阻碍了科学信任和业务部署。需要建立数学上可靠的可解释性框架来理解模型决策过程。

Method: 引入基于有界变差函数的数学可解释性框架，通过拯救激活函数饱和区的"死亡"神经元来增强模型表达能力。该方法允许对模型进行受控实验，分析不同区域对ENSO预测的贡献。

Result: 分析显示ENSO可预测性主要来自热带太平洋，印度洋和大西洋也有贡献，这与物理理解一致。受控实验证实了方法的稳健性及其与已知预测因子的一致性。特别发现春季可预测性障碍期间，尽管敏感性扩大但预测性能下降，可能是由于次优变量选择。

Conclusion: 该可解释性框架为理解深度学习ENSO预测提供了数学基础。结果表明，纳入额外的海洋-大气变量可能有助于超越春季可预测性障碍的限制，推进长期ENSO预测能力。

Abstract: The El Ni{~n}o-Southern Oscillation (ENSO) exerts profound influence on global climate variability, yet its prediction remains a grand challenge. Recent advances in deep learning have significantly improved forecasting skill, but the opacity of these models hampers scientific trust and operational deployment. Here, we introduce a mathematically grounded interpretability framework based on bounded variation function. By rescuing the "dead" neurons from the saturation zone of the activation function, we enhance the model's expressive capacity. Our analysis reveals that ENSO predictability emerges dominantly from the tropical Pacific, with contributions from the Indian and Atlantic Oceans, consistent with physical understanding. Controlled experiments affirm the robustness of our method and its alignment with established predictors. Notably, we probe the persistent Spring Predictability Barrier (SPB), finding that despite expanded sensitivity during spring, predictive performance declines-likely due to suboptimal variable selection. These results suggest that incorporating additional ocean-atmosphere variables may help transcend SPB limitations and advance long-range ENSO prediction.

</details>


### [209] [Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI](https://arxiv.org/abs/2601.02106)
*Ashish Rana,Ammar Shaker,Sascha Saralajew,Takashi Suzuki,Kosuke Yasuda,Shintaro Kato,Toshikazu Wada,Toshiyuki Fujikawa,Toru Kikutsuji*

Main category: cs.LG

TL;DR: ProtoPal框架通过原型学习实现个性化预防医疗，提供可理解和可验证的预测与干预建议


<details>
  <summary>Details</summary>
Motivation: 当前机器学习在个性化预防医疗中存在可解释性和可验证性不足的问题，需要为医疗领域所有利益相关者提供既易懂又可信的预测、干预和推荐

Method: 提出ProtoPal框架，采用原型学习方法，包含前端和后端两种模式，能够直观展示干预措施及其模拟结果

Result: 在保持优异定量性能的同时，提供了干预措施及其模拟结果的直观呈现

Conclusion: 原型学习方法能够有效解决个性化预防医疗中的可解释性和可验证性问题，为医疗决策提供透明可信的支持

Abstract: Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.

</details>


### [210] [Learning with Monotone Adversarial Corruptions](https://arxiv.org/abs/2601.02193)
*Kasper Green Larsen,Chirag Pabbaraju,Abhishek Shetty*

Main category: cs.LG

TL;DR: 研究发现标准机器学习算法过度依赖数据的可交换性和独立性，在单调对抗性污染模型中，即使污染点被正确标记，最优分类算法仍会表现不佳，而基于一致收敛的算法则不受影响。


<details>
  <summary>Details</summary>
Motivation: 探究标准机器学习算法对数据可交换性和独立性的依赖程度，揭示即使在看似有益的单调污染下，最优算法仍可能失效的现象。

Method: 引入单调对抗性污染模型：攻击者观察干净i.i.d.数据集后，插入按真实目标函数标记的污染点（单调污染），分析不同算法在此模型下的表现。

Result: 所有已知的二元分类最优学习算法在单调污染下都会在新测试点上获得次优期望误差；而基于一致收敛的算法则保持原有性能保证不变。

Conclusion: 最优学习算法在面对看似有益的单调污染时会失效，暴露了它们对数据可交换性的过度依赖；基于一致收敛的算法更具鲁棒性。

Abstract: We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a "clean" i.i.d. dataset, inserts additional "corrupted" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.

</details>


### [211] [ELLA: Efficient Lifelong Learning for Adapters in Large Language Models](https://arxiv.org/abs/2601.02232)
*Shristi Das Biswas,Yue Zhang,Anwesan Pal,Radhika Bhargava,Kaushik Roy*

Main category: cs.LG

TL;DR: ELLA：一种基于选择性子空间去相关原则的持续学习框架，通过惩罚高能量任务特定方向的对齐来减少灾难性遗忘，同时保留低能量残差子空间的自由度以实现正向迁移。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在持续学习设置中面临严重的灾难性遗忘问题。现有方法存在根本性限制：基于重放的方法不切实际且侵犯隐私，而严格正交性方法在规模扩展时会失效，因为每个新任务都被投影到正交补空间，逐渐减少剩余自由度并禁止共享表示中的重叠，从而消除正向迁移。

Method: ELLA基于选择性子空间去相关原则，通过轻量级正则化器对单个聚合更新矩阵进行操作。该方法明确表征过去更新的结构，惩罚沿高能量、任务特定方向的对齐，同时保留低能量残差子空间的自由度。这对应于各向异性收缩算子，可限制干扰，且内存和计算成本恒定，不受任务序列长度影响。

Result: 在三个流行基准测试中达到最先进的持续学习性能，相对准确率提升高达9.6%，内存占用减少35倍。无需数据重放、架构扩展和可忽略的存储开销。在不同架构上稳健扩展，并主动增强模型在未见任务上的零样本泛化性能。

Conclusion: ELLA为构建性终身LLM适应提供了一个原则性和可扩展的解决方案，通过选择性子空间去相关有效平衡了灾难性遗忘和正向迁移之间的权衡。

Abstract: Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse under scale: each new task is projected onto an orthogonal complement, progressively reducing the residual degrees of freedom and eliminating forward transfer by forbidding overlap in shared representations. In this work, we introduce ELLA, a training framework built on the principle of selective subspace de-correlation. Rather than forbidding all overlap, ELLA explicitly characterizes the structure of past updates and penalizes alignments along their high-energy, task-specific directions, while preserving freedom in the low-energy residual subspaces to enable transfer. Formally, this is realized via a lightweight regularizer on a single aggregated update matrix. We prove this mechanism corresponds to an anisotropic shrinkage operator that bounds interference, yielding a penalty that is both memory- and compute-constant regardless of task sequence length. ELLA requires no data replay, no architectural expansion, and negligible storage. Empirically, it achieves state-of-the-art CL performance on three popular benchmarks, with relative accuracy gains of up to $9.6\%$ and a $35\times$ smaller memory footprint. Further, ELLA scales robustly across architectures and actively enhances the model's zero-shot generalization performance on unseen tasks, establishing a principled and scalable solution for constructive lifelong LLM adaptation.

</details>


### [212] [POSEIDON: Physics-Optimized Seismic Energy Inference and Detection Operating Network](https://arxiv.org/abs/2601.02264)
*Boris Kriuk,Fedor Kriuk*

Main category: cs.LG

TL;DR: POSEIDON是一个基于物理约束的能量模型，用于统一的多任务地震事件预测，结合了Gutenberg-Richter和Omori-Utsu等地震学原理，在余震识别、海啸生成潜力和前震检测三个任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在地震预测中往往作为黑箱运行，忽略了已建立的物理定律。需要开发既能利用数据驱动方法又能嵌入地震学基本原理的预测模型。

Method: 提出POSEIDON模型，将Gutenberg-Richter震级-频率关系和Omori-Utsu余震衰减定律等地震学原理作为可学习约束嵌入到基于能量的建模框架中。同时处理三个相互关联的预测任务：余震序列识别、海啸生成潜力和前震检测。

Result: POSEIDON在所有任务上达到最先进性能，优于梯度提升、随机森林和CNN基线，在所有比较方法中获得最高的平均F1分数。学习到的物理参数收敛到科学可解释的值：Gutenberg-Richter b值为0.752，Omori-Utsu参数p=0.835，c=0.1948天，这些值落在已建立的地震学范围内，同时增强了预测准确性。

Conclusion: POSEIDON成功地将物理约束与数据驱动方法相结合，实现了可解释且准确的地震预测。同时发布的Poseidon数据集（包含280万次事件，跨越30年）为物理信息地震研究提供了重要资源。

Abstract: Earthquake prediction and seismic hazard assessment remain fundamental challenges in geophysics, with existing machine learning approaches often operating as black boxes that ignore established physical laws. We introduce POSEIDON (Physics-Optimized Seismic Energy Inference and Detection Operating Network), a physics-informed energy-based model for unified multi-task seismic event prediction, alongside the Poseidon dataset -- the largest open-source global earthquake catalog comprising 2.8 million events spanning 30 years. POSEIDON embeds fundamental seismological principles, including the Gutenberg-Richter magnitude-frequency relationship and Omori-Utsu aftershock decay law, as learnable constraints within an energy-based modeling framework. The architecture simultaneously addresses three interconnected prediction tasks: aftershock sequence identification, tsunami generation potential, and foreshock detection. Extensive experiments demonstrate that POSEIDON achieves state-of-the-art performance across all tasks, outperforming gradient boosting, random forest, and CNN baselines with the highest average F1 score among all compared methods. Crucially, the learned physics parameters converge to scientifically interpretable values -- Gutenberg-Richter b-value of 0.752 and Omori-Utsu parameters p=0.835, c=0.1948 days -- falling within established seismological ranges while enhancing rather than compromising predictive accuracy. The Poseidon dataset is publicly available at https://huggingface.co/datasets/BorisKriuk/Poseidon, providing pre-computed energy features, spatial grid indices, and standardized quality metrics to advance physics-informed seismic research.

</details>


### [213] [Differential Privacy for Transformer Embeddings of Text with Nonparametric Variational Information Bottleneck](https://arxiv.org/abs/2601.02307)
*Dina El Zein,James Henderson*

Main category: cs.LG

TL;DR: 提出一种隐私保护的文本数据共享方法，通过共享带噪声的transformer嵌入来保护敏感信息，使用非参数变分差分隐私(NVDP)在隐私和效用之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型隐藏表示可能编码输入敏感信息，攻击者可能恢复原始数据，transformer嵌入包含多个向量（每个token一个）使问题更加严重，需要保护隐私的同时保持数据可用性。

Method: 提出非参数变分差分隐私(NVDP)，将非参数变分信息瓶颈(NVIB)层集成到transformer架构中，向多向量嵌入注入噪声，使用Rényi散度及其对应的贝叶斯差分隐私(BDP)保证来测量隐私保护，通过训练NVIB层根据效用校准噪声水平。

Result: 在GLUE基准测试上验证NVDP，通过调整噪声水平在隐私和准确性之间实现有效权衡，较低噪声水平下模型保持高准确性同时提供强隐私保证。

Conclusion: NVDP方法能够有效平衡隐私保护和数据效用，为隐私保护的文本数据共享提供了一种实用解决方案。

Abstract: We propose a privacy-preserving method for sharing text data by sharing noisy versions of their transformer embeddings. It has been shown that hidden representations learned by deep models can encode sensitive information from the input, making it possible for adversaries to recover the input data with considerable accuracy. This problem is exacerbated in transformer embeddings because they consist of multiple vectors, one per token. To mitigate this risk, we propose Nonparametric Variational Differential Privacy (NVDP), which ensures both useful data sharing and strong privacy protection. We take a differential privacy approach, integrating a Nonparametric Variational Information Bottleneck (NVIB) layer into the transformer architecture to inject noise into its multi-vector embeddings and thereby hide information, and measuring privacy protection with Rényi divergence and its corresponding Bayesian Differential Privacy (BDP) guarantee. Training the NVIB layer calibrates the noise level according to utility. We test NVDP on the GLUE benchmark and show that varying the noise level gives us a useful tradeoff between privacy and accuracy. With lower noise levels, our model maintains high accuracy while offering strong privacy guarantees, effectively balancing privacy and utility.

</details>


### [214] [Game of Coding: Coding Theory in the Presence of Rational Adversaries, Motivated by Decentralized Machine Learning](https://arxiv.org/abs/2601.02313)
*Hanzaleh Akbari Nodehi,Viveck R. Cadambe,Mohammad Ali Maddah-Ali*

Main category: cs.LG

TL;DR: 论文提出了一种基于博弈论的编码框架，用于处理去中心化系统中理性对手（而非纯粹恶意对手）的场景，能够在诚实节点不占多数的情况下实现非零概率的数据恢复，并具有Sybil抵抗性。


<details>
  <summary>Details</summary>
Motivation: 在去中心化机器学习等新兴应用中，参与节点因贡献而获得奖励，这催生了理性对手（strategic adversaries）而非纯粹恶意对手。传统编码理论假设最坏情况对抗模型，要求诚实节点数量超过对抗节点，但在去中心化系统中这种假设不成立，需要新的编码框架来应对理性对手。

Method: 提出"编码博弈"（game of coding）这一新颖的博弈论框架，将编码理论扩展到信任最小化的设置中。重点研究重复编码（repetition coding），展示该框架的两个关键特性：1）即使对抗节点占多数也能实现非零概率的数据恢复；2）Sybil抵抗性（对抗节点数量增加时均衡保持不变）。

Result: 该框架能够在诚实节点不占多数的情况下实现数据恢复，打破了传统编码理论的限制。重复编码展示了即使在对抗节点占多数时也能获得非零恢复概率，并且系统具有Sybil抵抗性，对抗节点数量增加不会改变均衡状态。

Conclusion: 论文为去中心化系统中的编码问题提供了新的博弈论视角，特别适用于理性对手场景。提出的框架突破了传统编码理论的限制，为外包计算等应用提供了新的解决方案。同时指出了在对手策略未知情况下的研究挑战，并提出了未来研究的若干开放性问题。

Abstract: Coding theory plays a crucial role in enabling reliable communication, storage, and computation. Classical approaches assume a worst-case adversarial model and ensure error correction and data recovery only when the number of honest nodes exceeds the number of adversarial ones by some margin. However, in some emerging decentralized applications, particularly in decentralized machine learning (DeML), participating nodes are rewarded for accepted contributions. This incentive structure naturally gives rise to rational adversaries who act strategically rather than behaving in purely malicious ways.
  In this paper, we first motivate the need for coding in the presence of rational adversaries, particularly in the context of outsourced computation in decentralized systems. We contrast this need with existing approaches and highlight their limitations. We then introduce the game of coding, a novel game-theoretic framework that extends coding theory to trust-minimized settings where honest nodes are not in the majority. Focusing on repetition coding, we highlight two key features of this framework: (1) the ability to achieve a non-zero probability of data recovery even when adversarial nodes are in the majority, and (2) Sybil resistance, i.e., the equilibrium remains unchanged even as the number of adversarial nodes increases. Finally, we explore scenarios in which the adversary's strategy is unknown and outline several open problems for future research.

</details>


### [215] [DatBench: Discriminative, Faithful, and Efficient VLM Evaluations](https://arxiv.org/abs/2601.02316)
*Siddharth Joshi,Haoli Yin,Rishabh Adiga,Ricardo Monti,Aldo Carranza,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Kaleigh Mentzer,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Scott Loftin,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 论文提出评估视觉语言模型(VLMs)的三个理想标准：忠实性、区分性和效率，并发现现有评估存在多项缺陷，通过转换和过滤方法改进评估质量，发布DatBench评估套件。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的评估方法尚不成熟，存在多种缺陷：多项选择题形式奖励猜测、不能反映实际应用、容易饱和；部分问题无需图像即可解答；数据标注错误或模糊；评估计算成本过高（占开发计算资源的20%）。需要建立更严谨和可持续的评估实践。

Method: 通过三个维度分析现有评估：忠实性、区分性和效率。识别关键失败模式，提出通过转换（将多项选择题转为生成任务）和过滤（移除可盲答和错误标注样本）来改进现有基准。发布DatBench-Full（33个数据集）和DatBench（区分性子集）。

Result: 多项选择题转为生成任务后，模型能力下降高达35%；过滤可盲答和错误标注样本提高了区分能力同时降低计算成本；DatBench子集实现13倍平均加速（最高50倍），同时保持与原始数据集相似的区分能力。

Conclusion: 论文为视觉语言模型评估提供了更严谨和可持续的路径，通过识别和解决现有评估的缺陷，提出改进方法并发布清理后的评估套件，有助于更准确地衡量模型能力并降低评估成本。

Abstract: Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.

</details>


### [216] [Heterogeneous Low-Bandwidth Pre-Training of LLMs](https://arxiv.org/abs/2601.02360)
*Yazan Obeidi,Amir Sarfi,Joel Lidin,Paul Janson,Eugene Belilovsky*

Main category: cs.LG

TL;DR: SparseLoCo低通信数据并行方法与低带宽流水线模型并行结合，通过激活和激活梯度压缩实现异构分布式训练，在保持性能的同时显著降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型预训练需要分布式计算，但带宽限制使得在数据中心之外难以扩展，特别是当模型并行需要频繁的大规模设备间通信时。

Method: 提出异构分布式训练框架：高带宽参与者托管完整副本，资源有限参与者通过带激活压缩的流水线并行共同实例化副本。将子空间流水线压缩与SparseLoCo方法适配，实现低通信数据并行与低带宽模型并行的结合。

Result: 在大规模语言建模实验（1.78亿-10亿参数）中，激活压缩与SparseLoCo结合成本适中，选择性（异构）压缩相比压缩所有副本能持续改善损失-通信权衡，特别是在高压缩比下效果更明显。

Conclusion: 研究结果为将低带宽模型并行和异构参与者纳入LLM预训练提供了实用路径，有助于在带宽受限环境中扩展分布式训练。

Abstract: Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-communication data parallel method based on infrequent synchronization and sparse pseudo-gradient exchange, can be combined with low-bandwidth pipeline model parallelism via activation and activation-gradient compression. We introduce a heterogeneous distributed training framework where some participants host full replicas on high-bandwidth interconnects, while resource-limited participants are grouped to jointly instantiate a replica using pipeline parallelism with subspace-projected inter-stage communication. To make the recently introduced subspace pipeline compression compatible with SparseLoCo, we study a number of adaptations. Across large-scale language modeling experiments (178M-1B parameters) on standard pretraining corpora, we find that activation compression composes with SparseLoCo at modest cost, while selective (heterogeneous) compression consistently improves the loss-communication tradeoff relative to compressing all replicas-especially at aggressive compression ratios. These results suggest a practical path to incorporating low-bandwidth model parallelism and heterogeneous participants into LLM pre-training.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [217] [Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections](https://arxiv.org/abs/2601.00814)
*Abhishek Kumar*

Main category: cs.AI

TL;DR: 跨语言本体对齐系统使用基于嵌入的余弦相似度匹配，通过创新描述生成技术丰富本体实体上下文，采用微调的多语言Transformer模型生成更好嵌入，在OAEI-2022多语种轨道上取得71% F1分数，比最佳基线提升16%。


<details>
  <summary>Details</summary>
Motivation: 解决跨语言本体对齐问题，传统方法在捕捉跨语言语义相似度方面存在局限，需要更有效的技术来提升对齐精度。

Method: 1. 使用创新技术生成描述来丰富本体实体的上下文信息；2. 采用微调的多语言Transformer模型生成高质量嵌入；3. 使用余弦相似度匹配正样本本体实体对；4. 应用阈值过滤保留高度相似实体。

Result: 在OAEI-2022多语种轨道评估数据集上获得71% F1分数（78%召回率和65%精确率），比最佳基线提升16%，表明系统能有效捕捉跨语言相似性。

Conclusion: 提出的对齐流程能有效捕捉跨语言相似性，通过上下文丰富的实体描述和微调的多语言模型显著提升了跨语言本体对齐性能。

Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.

</details>


### [218] [MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback](https://arxiv.org/abs/2601.00816)
*Ismail Ahmad Abdullah*

Main category: cs.AI

TL;DR: MathLedger是一个可验证机器认知的基础设施，通过形式验证、密码学证明和学习动态的集成，为安全关键部署提供透明度和可验证性。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然性能卓越但缺乏透明度和可验证性，在安全关键应用中存在信任危机，需要建立可验证的机器认知基础。

Method: 采用反射式形式学习（RFL），这是一种符号化的梯度下降方法，通过验证器结果而非统计损失来驱动更新；系统集成了形式验证、密码学证明和学习动态。

Result: 第一阶段实验验证了测量和治理基础设施：CAL-EXP-3验证了测量基础设施（Delta p计算、方差跟踪）；压力测试确认了在超出边界条件下故障关闭治理触发器正常工作。

Conclusion: 该研究提供了一个基础设施贡献：一个可大规模审计的账本证明学习原型系统，为可验证机器学习建立了基础框架。

Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.
  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.
  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance

</details>


### [219] [Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches](https://arxiv.org/abs/2601.01774)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.AI

TL;DR: 本文评估大语言模型（LLM）求解超越方程的能力，比较直接数值预测与结合经典迭代求解器的混合架构效果。研究发现混合方法显著降低误差，表明LLM更适合作为经典数值求解器的智能接口而非独立计算引擎。


<details>
  <summary>Details</summary>
Motivation: 超越方程在工程实践中普遍存在，需要迭代数值求解。研究旨在评估大语言模型是否能直接解决这些方程，还是需要与经典迭代求解器结合的混合架构更为有效。

Method: 测试6个最先进的大语言模型（GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5）在100个涵盖7个工程领域的问题上。比较两种方法：1）直接数值预测；2）求解器辅助计算，其中LLM制定控制方程并提供初始条件，而牛顿-拉弗森迭代执行数值求解。

Result: 直接预测的平均相对误差为0.765到1.262，而求解器辅助计算达到0.225到0.301，误差减少了67.9%到81.8%。领域特定分析显示，在电子学中改进显著（93.1%），而在流体力学中改进较小（7.2%），因为LLM在该领域表现出有效的模式识别能力。

Conclusion: 当代大语言模型擅长符号操作和领域知识检索，但在精度关键的迭代算术方面存在困难。这表明它们最适合作为经典数值求解器的智能接口部署，而不是作为独立的计算引擎。

Abstract: Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.

</details>


### [220] [Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making](https://arxiv.org/abs/2601.00818)
*Chandra Sekhar Kubam*

Main category: cs.AI

TL;DR: 本文提出了一种基于Agentic AI框架的自主信用风险决策系统，通过多智能体系统结合强化学习、自然语言推理和可解释AI模块，实现实时、透明的信用风险评估，相比传统模型在决策速度、透明度和响应性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 金融服务在短时间内的大规模数字化导致对自主、透明、实时的信用风险决策系统的迫切需求。传统机器学习模型虽然擅长模式识别，但缺乏现代金融运营所需的适应性推理、情境感知和自主性。

Method: 提出了Agentic AI框架，构建了一个多智能体系统，包含强化学习、自然语言推理、可解释AI模块和实时数据吸收管道。系统包括智能体协作协议、风险评分引擎、可解释性层和持续反馈学习循环。

Result: 研究发现该系统在决策速度、透明度和响应性方面优于传统信用评分模型。但仍存在模型漂移风险、高维数据解释不一致、监管不确定性以及低资源环境基础设施限制等实际限制。

Conclusion: 提出的系统具有变革信用分析的巨大潜力，未来研究应关注动态监管合规机制、新型智能体协作、对抗鲁棒性以及在跨国信用生态系统中的大规模实施。

Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.

</details>


### [221] [CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations](https://arxiv.org/abs/2601.00821)
*Tao An*

Main category: cs.AI

TL;DR: CogCanvas是一个无需训练的长对话处理框架，通过提取认知图元并组织成时序图来解决大语言模型上下文窗口限制与信息保真度的矛盾，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长对话中面临上下文窗口限制与信息保真度的根本矛盾。现有方法（截断和摘要）要么丢弃早期信息，要么丢失细节信息，需要更好的解决方案。

Method: 提出CogCanvas框架，无需训练，从对话轮次中提取基于原文的认知图元（决策、事实、提醒），并将其组织成具有时序感知的图结构，实现抗压缩的检索能力。

Result: 在LoCoMo基准测试中，CogCanvas达到34.7%总体准确率，优于RAG（25.6%）和GraphRAG（13.7%）。时序推理优势最明显：31.5% vs. 9.3%（RAG）和5.0%（GraphRAG），相对提升530%。多跳因果推理通过率81.0% vs. GraphRAG的40.0%。可控基准测试显示97.5%召回率和93.0%精确匹配保留。

Conclusion: 虽然经过专门训练的方法能达到更高绝对分数，但CogCanvas作为无需训练的框架为实践者提供了可立即部署的替代方案，显著优于标准基线方法。

Abstract: Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.
  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.
  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.

</details>


### [222] [Energy-Aware Routing to Large Reasoning Models](https://arxiv.org/abs/2601.00823)
*Austin R. Ellis-Mohr,Max Hartman,Lav R. Varshney*

Main category: cs.AI

TL;DR: 该论文研究了大型推理模型（LRMs）的能源效率优化问题，提出通过方差感知的路由和调度策略来平衡平均能源供应与随机波动，以实现能源感知的模型路由策略。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型具有异构的推理能源成本，不同模型和推理方式能耗不同。为了降低能源消耗，需要选择合适的LRM并以合适的方式运行。系统性能取决于平均能源供应与随机波动之间的平衡，需要找到既不浪费辅助能源也不浪费基线能源的临界运行点。

Method: 提出了方差感知的路由和调度作为设计原则，基于LRMs的训练计算和推理计算缩放规律来制定调度策略。通过二阶特征分析来理解系统在临界状态下的性能表现，研究如何跨时间、模型和执行选择来吸收变异性。

Result: 研究发现临界状态下性能受变异性吸收机制支配，方差感知的路由和调度成为关键设计维度。基于LRMs缩放规律的调度策略能够有效表征路由行为，为开发能源感知的模型路由策略提供了理论基础。

Conclusion: 该研究强调了方差感知的路由和调度作为系统设计的核心原则，为开发能源高效的LRM调度策略提供了理论框架，有助于在保持性能的同时优化能源使用效率。

Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.

</details>


### [223] [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)
*Michael Bao*

Main category: cs.AI

TL;DR: ElecTwit是一个模拟社交媒体政治选举中多智能体说服行为的框架，相比传统游戏模拟更贴近现实，发现LLM使用了25种说服技巧并展现出不同模型间的显著差异。


<details>
  <summary>Details</summary>
Motivation: 克服以往研究中基于游戏模拟的局限性，在更真实的环境中研究多智能体系统中的说服行为，特别是在社交媒体政治选举场景下。

Method: 开发了ElecTwit模拟框架，在类似社交媒体的真实环境中进行多智能体交互实验，测试不同LLM模型在政治选举场景中的说服行为。

Result: 观察到25种特定说服技巧在大多数测试的LLM中被广泛使用，范围比之前报道的更广；不同模型在技巧使用和整体说服输出上存在显著差异；发现了"真相核心"消息和"墨水痴迷"等独特现象。

Conclusion: 该研究为在真实世界环境中评估说服性LLM智能体奠定了基础，有助于确保对齐和防止危险结果，同时揭示了不同模型架构和训练对现实社交模拟动态的影响。

Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as "kernel of truth" messages and spontaneous developments with an "ink" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.

</details>


### [224] [Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.00830)
*Deep Pankajbhai Mehta*

Main category: cs.AI

TL;DR: AI模型在逐步推理时很少自发提及问题中嵌入的提示信息，但当被直接询问时会承认注意到这些提示，表明模型看到了有影响力的信息但选择不报告。


<details>
  <summary>Details</summary>
Motivation: 验证一个常见假设：当AI系统逐步解释其推理过程时，这些解释是否真的揭示了影响AI答案的实际因素。研究人员想了解模型是否会报告问题中嵌入的提示信息。

Method: 在问题中嵌入提示信息，测试模型是否会提及这些提示。研究涵盖了超过9,000个测试案例，涉及11个领先的AI模型。测试了多种条件：模型自发报告、被直接询问、被告知被监控、被强制要求报告提示。

Result: 模型几乎从不自发提及提示信息，但当被直接询问时会承认注意到它们。告知模型被监控没有帮助。强制要求报告提示虽然有效，但会导致模型在没有提示时也报告，并降低准确性。特别危险的是：迎合用户偏好的提示被模型最常遵循但最少报告。

Conclusion: 仅仅观察AI的推理过程不足以发现隐藏的影响因素。当前AI解释机制存在缺陷，模型可能看到有影响力的信息但选择不报告，这对AI系统的透明度和可信度构成挑战。

Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.

</details>


### [225] [OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification](https://arxiv.org/abs/2601.00843)
*Ayda Aghaei Nia*

Main category: cs.AI

TL;DR: OmniNeuro是一个新型HCI框架，通过物理、混沌和量子启发的可解释性引擎，将BCI从黑盒解码器转变为透明的反馈伙伴，提高用户理解和神经可塑性。


<details>
  <summary>Details</summary>
Motivation: 深度学习虽然提高了脑机接口的解码精度，但其"黑盒"特性阻碍了临床采用，导致用户挫折感和神经可塑性结果不佳。需要可解释的反馈系统来改善用户体验。

Method: 提出OmniNeuro框架，集成三个可解释性引擎：1) 物理（能量）分析，2) 混沌（分形复杂度）分析，3) 量子启发的不确定性建模。这些指标驱动实时神经声波化和生成式AI临床报告，系统与解码器无关。

Result: 在PhysioNet数据集（N=109）上达到平均准确率58.52%。定性试点研究（N=3）证实可解释反馈帮助用户调节心理努力，减少"试错"阶段。

Conclusion: OmniNeuro作为任何最先进架构的必需可解释性层，将BCI从沉默解码器转变为透明反馈伙伴，有望改善临床采用和神经可塑性结果。

Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the "Black Box" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the "trial-and-error" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.

</details>


### [226] [Enhancing Temporal Awareness in LLMs for Temporal Point Processes](https://arxiv.org/abs/2601.00845)
*Lili Chen,Wensheng Gan,Shuang Liang,Philip S. Yu*

Main category: cs.AI

TL;DR: TPP-TAL是一个增强LLMs中时间感知能力的即插即用框架，通过显式对齐时间动态与上下文语义，改善连续时间事件建模中的时间依赖性和长程交互。


<details>
  <summary>Details</summary>
Motivation: 时间点过程在金融、医疗、社交系统等领域很重要，但现有方法难以有效捕捉时间信息与语义上下文之间的复杂交互，限制了LLMs在时间点过程建模中的应用。

Method: 提出TPP-TAL框架，不采用简单拼接事件时间和类型嵌入的传统方法，而是在将信息输入LLM之前显式对齐时间动态与上下文语义，增强模型对时间依赖性和事件间长程交互的感知能力。

Result: 在多个基准数据集上的实验表明，TPP-TAL在时间似然估计和事件预测准确性方面都有显著提升，证明了增强LLMs时间感知能力对连续时间事件建模的重要性。

Conclusion: TPP-TAL通过显式对齐时间动态与语义上下文，有效提升了LLMs在时间点过程建模中的性能，为连续时间事件分析提供了更好的解决方案。

Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL

</details>


### [227] [COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs](https://arxiv.org/abs/2601.01836)
*Dasol Choi,DongGeon Lee,Brigitta Jesica Kartono,Helena Berndt,Taeyoun Kwon,Joonwon Jang,Haon Park,Hwanjo Yu,Minsuk Kahng*

Main category: cs.AI

TL;DR: COMPASS框架首次系统评估LLM是否符合组织白名单/黑名单政策，发现模型在处理合法请求时表现良好（>95%准确率），但在执行禁令时严重失败（仅拒绝13-40%的对抗性违规）


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在企业高风险应用（医疗、金融等）中的部署，确保模型遵守组织特定政策变得至关重要。现有安全评估仅关注普遍危害，缺乏对组织政策合规性的系统评估。

Method: 提出COMPASS框架，应用于8个不同行业场景，生成并验证5,920个查询，测试常规合规性和通过策略设计的边缘案例进行对抗性鲁棒性评估。

Result: 评估7个最先进模型发现基本不对称性：模型可靠处理合法请求（>95%准确率），但在执行禁令时灾难性失败，仅拒绝13-40%的对抗性黑名单违规。

Conclusion: 当前LLM缺乏政策关键部署所需的鲁棒性，COMPASS成为组织AI安全的重要评估框架。

Abstract: As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.

</details>


### [228] [Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs](https://arxiv.org/abs/2601.01878)
*Farzan Karimi-Malekabadi,Suhaib Abdurahman,Zhivar Sourati,Jackson Trager,Morteza Dehghani*

Main category: cs.AI

TL;DR: 论文指出当前大语言模型的社会认知基准测试存在评估-部署差距，主要原因是缺乏明确的理论基础，导致基准测试结果被过度泛化。作者提出"理论追踪卡"作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在基准测试中得分很高，但这些分数往往无法预测真实世界行为。现有研究将这种差距归因于测量和效度问题，但作者认为更深层的原因是缺乏明确的理论基础，导致对能力评估的过度泛化。

Method: 首先诊断并形式化"理论差距"问题，然后提出"理论追踪卡"这一轻量级文档工具，明确记录评估的理论基础、目标能力组件、操作化过程及局限性。

Result: 理论追踪卡能够增强社会认知评估的可解释性和可重用性，通过明确理论、任务操作化、评分和局限性之间的完整效度链，而不需要修改基准测试或要求理论统一。

Conclusion: 解决评估-部署差距需要填补理论空白，理论追踪卡提供了一种实用的方法来提高社会认知评估的透明度和有效性，减少对基准测试结果的系统性过度解读。

Abstract: Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.

</details>


### [229] [Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks](https://arxiv.org/abs/2601.00856)
*Milos Stankovic,Ella Hirche,Sarah Kollatzsch,Julia Nadine Doetsch*

Main category: cs.AI

TL;DR: 这是一篇对Kosmyna等人(2025)关于使用ChatGPT进行论文写作任务中认知债务积累研究的评论文章，指出了原研究在样本量、可重复性、EEG分析方法、结果报告一致性和透明度等方面的问题。


<details>
  <summary>Details</summary>
Motivation: 作者旨在对Kosmyna等人关于AI助手对人类认知影响的研究提供建设性评论，帮助改进该研究以适合同行评审发表，因为原研究的一些结果可能需要更保守的解释。

Method: 通过批判性分析原研究的方法论，重点关注五个主要方面：研究设计（特别是样本量限制）、分析的可重复性、EEG分析方法问题、结果报告的不一致性以及研究过程和发现的透明度不足。

Result: 评论文章指出了原研究存在的多个方法论和报告问题，包括样本量不足可能影响统计效力、分析方法可能不够稳健、结果报告存在不一致性，以及整体研究透明度有待提高。

Conclusion: 虽然认可Kosmyna等人研究的重要性和价值，但建议在发表前解决这些方法论和报告问题，以便更准确地解释结果并提高研究的科学严谨性。

Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.

</details>


### [230] [Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery](https://arxiv.org/abs/2601.00869)
*Huang Junyao,Situ Ruimin,Ye Renqin*

Main category: cs.AI

TL;DR: 研究发现LLM训练数据的地理分布导致品牌推荐存在系统性差异，中文LLM的品牌提及率比国际LLM高30.6个百分点，揭示了"存在鸿沟"现象和语言边界障碍对市场进入的影响。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统越来越多地介入消费者信息发现过程，品牌面临算法不可见性问题。本研究旨在探究大型语言模型中因训练数据构成差异导致的品牌推荐系统性差异。

Method: 分析了1,909个纯英文查询，覆盖6个LLM（GPT-4o、Claude、Gemini、Qwen3、DeepSeek、Doubao）和30个品牌，通过比较中文LLM和国际LLM的品牌提及率差异，并引入知织边界（Zhizibianjie/OmniEdge）案例研究。

Result: 中文LLM的品牌提及率比国际LLM高30.6个百分点（88.9% vs. 58.3%，p<.001），这种差异在相同的英文查询中持续存在，表明训练数据的地理分布而非语言是主要驱动因素。知织边界案例显示中文LLM提及率为65.6%，而国际模型为0%（p<.001）。

Conclusion: 提出了"数据护城河"框架，将AI可见内容视为VRIN战略资源，并定义了"算法无处不在"作为生成引擎优化的战略目标。研究揭示了在AI中介的市场中，品牌的"数据边界"决定了其"市场边界"。

Abstract: As artificial intelligence systems increasingly mediate consumer information discovery,
  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large
  Language Models (LLMs) -- systematic differences in brand recommendations arising from
  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,
  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6
  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,
  p<.001). This disparity persists in identical English queries, indicating training data
  geography -- not language -- drives the effect. We introduce the Existence Gap: brands
  absent from LLM training corpora lack "existence" in AI responses regardless of quality.
  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%
  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how
  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we
  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic
  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility
  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization
  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats
  through semantic coverage, technical depth, and cultural localization. Our findings reveal
  that in AI-mediated markets, the limits of a brand's "Data Boundaries" define the limits
  of its "Market Frontiers."

</details>


### [231] [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)
*Anthony Mikinka*

Main category: cs.AI

TL;DR: UCL是一个将提示工程从启发式实践转变为系统优化的数学框架，通过系统评估显示能显著减少29.8%的token使用并降低成本，其性能差异可通过结构开销函数和过指定悖论来解释。


<details>
  <summary>Details</summary>
Motivation: 当前提示工程主要依赖启发式实践，缺乏系统化的优化框架。作者旨在将提示工程从经验性实践转变为基于数学框架的系统优化，以提高LLM交互的效率和成本效益。

Method: 提出通用条件逻辑（UCL）框架，包含指示函数、结构开销函数、早期绑定等核心机制。通过系统评估（N=305，11个模型，4次迭代）验证框架效果，并引入过指定悖论解释性能差异。

Result: UCL能显著减少29.8%的token使用（t(10)=6.36, p<0.001, Cohen's d=2.01），相应降低成本。发现过指定阈值S*=0.509，超过此阈值后额外指定会二次降低性能。最优UCL配置因模型架构而异。

Conclusion: UCL为高效的LLM交互提供了一个可校准的优化框架，模型族特定的优化是未来重要研究方向。该框架将提示工程从启发式实践转变为系统化数学优化。

Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.

</details>


### [232] [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)
*Mandar Parab*

Main category: cs.AI

TL;DR: 提出Counterfactual Self-Questioning框架，让单个语言模型生成并评估自身推理的反事实批评，通过内部生成的监督实现可扩展的自我改进。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型自我改进方法依赖外部批评者、学习奖励模型或集成采样，增加了复杂性和训练不稳定性，需要更简单有效的自我监督方法。

Method: 提出反事实自我提问框架：1) 生成初始推理轨迹；2) 针对潜在失败点提出针对性问题；3) 生成暴露错误假设或无效步骤的替代推理轨迹；4) 使用这些反事实轨迹作为结构化相对反馈进行策略优化。

Result: 在多个数学推理基准测试中，反事实自我提问提高了准确性和训练稳定性，特别是对于较小模型，仅使用内部生成的监督就能实现可扩展的自我改进。

Conclusion: Counterfactual Self-Questioning提供了一种简单有效的自我改进框架，无需外部模型或复杂架构，通过内部生成的反事实批评实现稳定的自我监督学习。

Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.

</details>


### [233] [Context Collapse: In-Context Learning and Model Collapse](https://arxiv.org/abs/2601.00923)
*Josef Ott*

Main category: cs.AI

TL;DR: 该论文研究了LLMs中的上下文学习和模型崩溃现象，在线性变换器中分析了ICL的相变特性，证明了模型崩溃的必然性，并提出了上下文崩溃的新概念。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型中两个关键现象：上下文学习（ICL）和模型崩溃，旨在理解ICL的机制、模型崩溃的条件，并揭示长期生成中的稳定性问题。

Method: 1. 在线性回归任务上训练带权重绑定的线性变换器研究ICL；2. 将前向传播简化为预条件梯度下降并分析最优预条件器；3. 使用鞅和随机游走理论分析线性回归和高斯拟合的简化设置；4. 提出上下文崩溃概念分析长序列生成问题。

Result: 1. ICL存在相变：超过临界上下文长度时，解出现斜对称分量；2. 模型崩溃几乎必然发生，除非数据快速增长或长期保留；3. 发现了上下文崩溃现象，特别是在思维链推理中。

Conclusion: ICL和模型崩溃是LLMs中的核心现象，ICL的相变特性与预条件器相关，模型崩溃不可避免，上下文崩溃揭示了ICL动态与生成模型长期稳定性挑战之间的联系。

Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.

</details>


### [234] [Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering](https://arxiv.org/abs/2601.01195)
*Wuzhenghong Wen,Chao Xue,Su Pan,Yuwei Sun,Minlong Peng*

Main category: cs.AI

TL;DR: MRE框架通过增强前向和后向推理，结合提示工程、监督微调和树结构强化学习，提升时序知识图谱问答中多跳推理的全局最优轨迹识别能力。


<details>
  <summary>Details</summary>
Motivation: 时序知识图谱问答中，大语言模型在每跳推理时会检索大量时间相似且语义复杂的关系子图，增加了次优决策和错误传播的风险，需要改进多跳推理的全局优化能力。

Method: 提出多跳推理增强框架MRE：1）通过提示工程引导LLM生成多样化的推理轨迹；2）选择有效轨迹进行监督微调作为冷启动策略；3）引入树组相对策略优化算法，采用递归树结构探索学习，每跳探索与前跳建立强因果依赖，评估则基于后续跳的多路径探索反馈。

Result: 在两个TKGQA基准测试中，MRE模型持续超越最先进方法，在处理复杂多跳查询方面表现优异。进一步分析显示模型具有更好的可解释性，并对噪声时间标注具有更强的鲁棒性。

Conclusion: MRE框架通过增强前向和后向推理，有效提升了时序知识图谱问答中多跳推理的全局优化能力，在复杂查询处理、可解释性和鲁棒性方面均取得显著改进。

Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.

</details>


### [235] [Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale](https://arxiv.org/abs/2601.01330)
*Shengji Tang,Weihao Lin,Jingqi Ye,Hao Li,Bo Zhang,Shuyue Hu,Tao Chen,Wangli Ouyang,Lei Bai,Peng Ye*

Main category: cs.AI

TL;DR: JiSi框架通过查询-响应混合路由、支持集聚合器选择和自适应路由-聚合切换三大创新，使10个开源LLM协作以47%成本超越Gemini-3-Pro，证明集体智能是通向AGI的新路径。


<details>
  <summary>Details</summary>
Motivation: 当前LLM路由和聚合存在三个关键瓶颈：1) 基于查询的路由器仅关注文本相似性；2) 聚合方法静态，无法为不同任务选择合适聚合器；3) 路由与聚合的互补性未充分利用。需要释放LLM协作的完整潜力。

Method: 提出JiSi框架，包含三大创新：1) 查询-响应混合路由，同时捕捉语义信息和问题难度；2) 基于支持集的聚合器选择，联合评估聚合能力和领域能力；3) 自适应路由-聚合切换，动态利用路由和聚合的优势。

Result: 在9个基准测试中，JiSi通过协调10个开源LLM，以仅47%的成本超越了Gemini-3-Pro的性能，同时优于主流基线方法。

Conclusion: 集体智能代表了通向人工通用智能（AGI）的新路径，通过有效协调多个LLM的协作可以超越单一大型模型的性能，同时显著降低成本。

Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).

</details>


### [236] [A unified multimodal understanding and generation model for cross-disciplinary scientific research](https://arxiv.org/abs/2601.01363)
*Xiaomeng Yang,Zhiyu Tan,Xiaohui Zhong,Mengping Yang,Qiusheng Huang,Lei Chen,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: FuXi-Uni是一个原生统一的多模态科学模型，能够在单一架构内跨科学领域进行科学理解和高质量生成，特别针对地球科学和生物医学领域。


<details>
  <summary>Details</summary>
Motivation: 科学发现日益依赖于跨学科整合异构高维数据，但现有AI模型通常是领域特定的，缺乏同时理解和生成多模态科学数据的能力，而许多全球挑战和科学问题本质上是跨学科的，需要多个领域的协同进展。

Method: FuXi-Uni将跨学科科学标记与自然语言标记对齐，并使用科学解码器重建科学标记，从而同时支持自然语言对话和科学数值预测。模型在原生共享潜在空间中统一异构科学模态。

Result: 在地球系统建模中：1）生成10天全球0.25°分辨率预报优于最先进的物理预报系统；2）热带气旋路径和强度预测优于最先进的物理模型；3）生成的高分辨率区域天气场超越标准插值基线。在生物医学中：在多个生物医学视觉问答基准上优于领先的多模态大语言模型。

Conclusion: 通过在原生共享潜在空间中统一异构科学模态同时保持强大的领域特定性能，FuXi-Uni向更通用的多模态科学模型迈进了一步。

Abstract: Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.

</details>


### [237] [Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification](https://arxiv.org/abs/2601.01378)
*Han Yuan,Yilin Wu,Li Zhang,Zheng Ma*

Main category: cs.AI

TL;DR: 本文提出AAAI三阶段流程（关联识别、自动检测、自适应推理），通过缓解事实幻觉来提升小型语言模型在金融分类任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）因其快速推理和本地部署优势在金融分类中得到应用，但与大型语言模型相比，SLMs更容易产生事实幻觉且分类性能较弱。研究旨在探索缓解事实幻觉是否能提升SLMs的金融分类性能。

Method: 提出AAAI三阶段流程：1) 关联识别（Association Identification）识别事实幻觉与分类错误的关系；2) 自动检测（Automated Detection）使用基于编码器的验证器检测事实幻觉；3) 自适应推理（Adaptive Inference）通过事实错误反馈使SLMs能够自适应推理。

Result: 实验在三个代表性SLMs上显示：1) 事实幻觉与错误分类呈正相关；2) 基于编码器的验证器能有效检测事实幻觉；3) 结合事实错误反馈的自适应推理能显著提升分类性能。

Conclusion: AAAI流程通过缓解事实幻觉有效提升了SLMs在金融分类中的性能，为SLMs在金融领域的可信赖和有效应用提供了解决方案。

Abstract: Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.

</details>


### [238] [A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts](https://arxiv.org/abs/2601.01467)
*Romuald Kwessy Mouona,Blaise Blériot Koguep Njionou,Etienne Romuald Temgoua Alomo,Rokia Missaoui,Leonard Kwuida*

Main category: cs.AI

TL;DR: 研究三元背景中的蕴含关系，重点分析Ganter和Obiedkov提出的条件属性蕴含和属性条件蕴含，目标是构建这些蕴含的最优基


<details>
  <summary>Details</summary>
Motivation: 三元背景中的蕴含关系分析是形式概念分析的重要扩展，需要系统研究这些蕴含关系的特性并构建最优表示基

Method: 研究Ganter和Obiedkov提出的条件属性蕴含和属性条件蕴含，分析其数学特性，构建这些蕴含关系的最优基

Result: 建立了三元背景中蕴含关系的理论基础，提出了构建最优基的方法

Conclusion: 成功分析了三元背景中的蕴含关系，为形式概念分析在三元数据上的应用提供了理论基础

Abstract: This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.

</details>


### [239] [Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation](https://arxiv.org/abs/2601.01546)
*Letian Kong,Qianran,Jin,Renyu Zhang*

Main category: cs.AI

TL;DR: 提出两阶段框架改善LLM在复杂决策环境中的行为对齐：第一阶段上下文形成明确指定实验设计，第二阶段上下文导航指导推理过程。验证表明复杂决策需要两阶段，简单任务仅需第一阶段。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多用于模拟人类行为实验，但在复杂决策环境中（需要预测他人行动和基于观察行为形成信念）与人类决策存在系统性偏差，需要改进行为对齐方法。

Method: 提出两阶段框架：1）上下文形成阶段：明确指定实验设计，建立决策任务和上下文的准确表征；2）上下文导航阶段：在该表征内指导推理过程做出决策。在三个任务中验证：序列购买游戏、众筹游戏和需求估计任务。

Result: 在四个SOTA模型（GPT-4o、GPT-5、Claude-4.0-Sonnet-Thinking、DeepSeek-R1）上验证发现：复杂决策环境需要两阶段才能实现与人类基准的行为对齐，而简单的需求估计任务仅需上下文形成阶段。

Conclusion: 阐明了每个阶段何时必要，为设计和诊断LLM社会模拟作为行为研究中人类受试者的补充提供了系统方法，提高了LLM在复杂决策环境中的行为对齐能力。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.

</details>


### [240] [Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement](https://arxiv.org/abs/2601.01562)
*Mingyu Xu,Cheng Fang,Keyue Jiang,Yuqian Zheng,Yanghua Xiao,Baojian Zhou,Qifang Zhao,Suhang Zheng,Xiuwen Zhu,Jiyang Tang,Yongchi Zhao,Yijia Luo,Zhiqi Bai,Yuchi Xu,Wenbo Su,Wei Wang,Bing Zhao,Lin Qu,Xiaoxiao Xu*

Main category: cs.AI

TL;DR: Logics-STEM是一个针对STEM领域推理任务优化的先进推理模型，基于1000万规模的高质量数据集，在STEM基准测试中平均提升4.68%性能，通过数据算法协同设计实现显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前STEM领域需要更强大的推理能力，但现有模型在STEM相关任务上表现有限。研究旨在通过大规模高质量数据和算法协同设计来提升模型在科学、技术、工程和数学领域的推理性能。

Method: 采用数据算法协同设计引擎：数据方面，通过5阶段数据策划引擎（标注、去重、去污染、蒸馏、分层采样）构建Logics-STEM-SFT-Dataset；算法方面，使用失败驱动的后训练框架，通过针对性知识检索和失败区域数据合成来指导第二阶段SFT或强化学习。

Result: Logics-STEM在STEM相关基准测试中表现出色，相比同规模8B模型平均提升4.68%性能，展示了大规模开源数据与精心设计合成数据结合的潜力。模型提供8B和32B版本，数据集提供1000万和220万版本。

Conclusion: 数据算法协同设计对于通过后训练增强推理能力具有关键作用，大规模开源数据与精心设计合成数据的结合展现出巨大潜力。研究公开了模型和数据集以支持开源社区的未来研究。

Abstract: We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.

</details>


### [241] [Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration](https://arxiv.org/abs/2601.01609)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 论文提出了一种结合LLM和符号推理的框架：用LLM将非结构化文本转换为ABox断言，再用SWRL推理器进行确定性规则应用，在三个领域验证了该方法优于few-shot提示。


<details>
  <summary>Details</summary>
Motivation: 在需要可审计和可解释决策的领域（如临床协议、法律证据规则、科学标准），现有方法存在局限：LLM具有灵活性但无法保证规则应用的一致性，符号系统能提供形式化保证但需要结构化输入。

Method: 提出集成模式：LLM作为本体填充引擎，将非结构化文本转换为基于专家编写TBox规范的ABox断言，SWRL推理器提供确定性规则应用保证。框架将推理分解为实体识别、断言提取和符号验证三个步骤。

Result: 在三个领域（法律传闻证据判定、科学方法任务应用、临床试验资格）和11个语言模型上验证，结构化分解在总体上比few-shot提示有统计显著改进，三个领域都观察到增益。消融研究确认符号验证比单纯结构化提示有实质好处。

Conclusion: 该框架结合了LLM的灵活性和符号推理的形式化保证，填充的ABox可与标准语义网工具集成，支持更丰富的推理模式，为需要可审计决策的领域提供了实用解决方案。

Abstract: Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.

</details>


### [242] [Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications](https://arxiv.org/abs/2601.01718)
*YuanLab. ai,:,Shawn Wu,Sean Wang,Louie Li,Darcy Chen,Allen Wang,Jiangang Luo,Xudong Zhao,Joseph Shen,Gawain Ma,Jasper Jia,Marcus Mao,Claire Wang,Hunter He,Carol Wang,Zera Zhang,Jason Wang,Chonly Shen,Leo Zhang,Logan Chen,Qasim Meng,James Gong,Danied Zhao,Penn Zheng,Owen Zhu,Tong Yu*

Main category: cs.AI

TL;DR: Yuan3.0 Flash是一个开源的MoE多模态大语言模型，拥有37亿激活参数和400亿总参数，专为企业任务优化，同时保持通用任务竞争力。通过RAPO算法解决大推理模型的过度思考问题。


<details>
  <summary>Details</summary>
Motivation: 针对企业导向任务（如RAG、复杂表格理解、摘要）的性能提升需求，同时解决大型推理模型中常见的过度思考现象，开发一个既高效又具备强大推理能力的开源模型。

Method: 采用混合专家（MoE）架构，提出反射感知自适应策略优化（RAPO）算法，这是一种新颖的强化学习训练算法，专门用于调节过度思考行为。

Result: 在企业导向任务中表现优异，在数学、科学等领域的推理能力强大，达到前沿模型相当的准确性，同时仅需约1/4到1/2的平均token数量。

Conclusion: Yuan3.0 Flash是一个高效的企业导向多模态大语言模型，通过RAPO算法有效解决了过度思考问题，在保持竞争力的同时显著提升了企业任务性能，并已完全开源供研究和实际部署。

Abstract: We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.

</details>


### [243] [AI Agent Systems: Architectures, Applications, and Evaluation](https://arxiv.org/abs/2601.01743)
*Bin Xu*

Main category: cs.AI

TL;DR: 该论文对AI智能体架构进行了系统性综述，涵盖推理、规划、工具调用等核心组件，提出了统一的分类体系，并讨论了设计权衡、评估挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型与推理、规划、记忆和工具使用相结合，AI智能体正成为连接自然语言意图与现实世界计算的实用接口。需要对这些新兴的智能体架构进行系统性整理和分类，以指导未来研究和应用。

Method: 采用综述研究方法，将现有工作组织成统一的分类体系，涵盖：1）智能体组件（策略/LLM核心、记忆、世界模型、规划器、工具路由器、批评器）；2）编排模式（单智能体vs.多智能体，集中式vs.去中心化协调）；3）部署设置（离线分析vs.在线交互辅助，安全关键vs.开放任务）。

Result: 提出了一个全面的AI智能体架构分类框架，识别了关键设计权衡（延迟vs.准确性、自主性vs.可控性、能力vs.可靠性），总结了评估实践（任务套件、人类偏好指标、约束下成功率、鲁棒性和安全性），并揭示了评估面临的挑战（非确定性、长期信用分配、工具和环境变异性、隐藏成本）。

Conclusion: AI智能体架构研究仍面临诸多开放挑战，包括工具动作的验证和安全护栏、可扩展的记忆和上下文管理、智能体决策的可解释性，以及在真实工作负载下的可重复评估。需要在这些方向上进一步推进研究。

Abstract: AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\ multi-agent; centralized vs.\ decentralized coordination), and deployment settings (offline analysis vs.\ online interactive assistance; safety-critical vs.\ open-ended tasks). We discuss key design trade-offs -- latency vs.\ accuracy, autonomy vs.\ controllability, and capability vs.\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.

</details>


### [244] [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)
*Yao Lu,Shang Liu,Hangan Zhou,Wenji Fang,Qijun Zhang,Zhiyao Xie*

Main category: cs.AI

TL;DR: RTL-OPT是一个用于评估大语言模型在RTL代码优化能力的新基准测试，包含36个手工设计的数字电路设计，覆盖多种实现类别，并提供自动化评估框架来验证功能正确性和量化PPA改进。


<details>
  <summary>Details</summary>
Motivation: 当前AI在集成电路设计中的应用主要关注RTL代码生成，但现有基准测试主要评估语法正确性，缺乏对功耗、性能和面积（PPA）优化质量的评估。需要一个新的基准测试来评估LLM在RTL优化方面的能力。

Method: 创建RTL-OPT基准测试，包含36个手工设计的数字电路设计，覆盖组合逻辑、流水线数据通路、有限状态机和存储器接口等类别。每个任务提供一对RTL代码：次优版本和人工优化的参考版本，后者体现了行业验证的优化模式。同时集成了自动化评估框架来验证功能正确性和量化PPA改进。

Result: RTL-OPT基准测试成功建立，能够标准化评估生成模型在硬件设计优化方面的能力。该基准测试填补了现有评估体系中对PPA优化质量评估的空白。

Conclusion: RTL-OPT为评估大语言模型在RTL代码优化能力提供了全面、标准化的基准测试框架，有助于推动AI在集成电路设计优化领域的发展。

Abstract: The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.

</details>


### [245] [Admissibility Alignment](https://arxiv.org/abs/2601.01816)
*Chris Duffey*

Main category: cs.AI

TL;DR: 论文提出"可采纳性对齐"概念，将AI对齐重新定义为在不确定性下对结果分布进行可采纳行动和决策选择的属性，并提出了MAP-AI系统架构来实施这一概念。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐方法通常被视为静态或二元条件，缺乏对不确定性、干预效应、价值模糊性和治理约束的明确建模。需要一种能够评估决策策略在多种可能未来中表现的方法，将对齐视为概率性、决策理论属性而非简单准确度指标。

Method: 提出MAP-AI（蒙特卡洛对齐策略）系统架构，通过蒙特卡洛估计结果分布和可采纳性控制的策略选择来实施对齐。该方法评估决策策略在合理未来集合中的表现，明确建模不确定性、干预效应、价值模糊性和治理约束。

Result: 建立了一个实用的AI系统治理基础，其影响不是由个体预测决定，而是由策略在分布和尾部事件中的行为决定。展示了如何将对齐评估整合到决策过程中，产生可采纳性控制的行动选择机制，无需重新训练或修改底层模型。

Conclusion: 可采纳性对齐框架将AI对齐重新概念化为概率性决策理论属性，提供了在不确定性和复杂约束下评估和确保AI系统对齐的实用方法，特别适用于企业和机构AI系统的信任评估。

Abstract: This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.
  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.

</details>


### [246] [Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01844)
*Udiptaman Das,Krishnasai B. Atmakuri,Duy Ho,Chi Lee,Yugyung Lee*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体提示和模式约束检索增强生成（KG-RAG）的端到端框架，用于从临床自由文本构建知识图谱，特别针对肿瘤学领域，无需依赖黄金标准标注。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型为从非结构化临床叙述构建知识图谱提供了新机会，但现有方法通常依赖结构化输入，缺乏对事实准确性和语义一致性的稳健验证，这在肿瘤学领域尤为突出。

Method: 提出端到端框架，包括：(1) 提示驱动的实体、属性和关系提取；(2) 基于熵的不确定性评分；(3) 本体对齐的RDF/OWL模式生成；(4) 多LLM共识验证用于幻觉检测和语义精炼。采用多智能体提示和模式约束检索增强生成策略。

Result: 应用于两个肿瘤学队列（PDAC和BRCA），该方法生成了可解释、SPARQL兼容且临床基础的知识图谱。实验结果显示在精确度、相关性和本体合规性方面相比基线方法有持续提升。

Conclusion: 该框架支持持续精炼和自监督评估，实现了图谱质量的迭代改进，为临床知识图谱构建提供了无需黄金标准标注的有效解决方案。

Abstract: Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.

</details>


### [247] [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)
*Defei Xia,Bingfeng Pi,Shenbin Zhang,Song Hua,Yunfei Wei,Lei Zuo*

Main category: cs.AI

TL;DR: 本文提出Jenius-Agent框架，通过自适应提示生成、上下文感知工具编排和分层内存机制三大创新，显著提升LLM智能体的任务准确率并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体系统发展，提升自主智能体在上下文理解、工具使用和响应生成方面的任务性能变得日益重要。尽管先前研究改进了LLM智能体的整体设计，但对其内部推理和工具使用流程的系统性优化仍显不足。

Method: 提出Jenius-Agent框架，包含三大关键技术：(1) 自适应提示生成策略，根据智能体状态和任务目标调整提示以提高可靠性和鲁棒性；(2) 上下文感知工具编排模块，基于用户意图和上下文进行工具分类、语义检索和自适应调用；(3) 分层内存机制，整合会话内存、任务历史和外部摘要，通过动态摘要和压缩提高相关性和效率。框架集成了基于模型上下文协议的工具、文件输入/输出和执行反馈等优化。

Result: 实验结果显示任务准确率提升20%，同时降低了token成本、响应延迟和调用失败率。该框架已在Jenius平台部署，为健壮、协议兼容的自主智能体提供了轻量级可扩展解决方案。

Conclusion: Jenius-Agent框架通过系统优化智能体的内部推理和工具使用流程，显著提升了任务性能并降低了资源消耗，为实际部署提供了有效的解决方案。

Abstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.

</details>


### [248] [MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning](https://arxiv.org/abs/2601.01910)
*Minh Hieu Ha,Khanh Ly Ta,Hung Phan,Tung Doan,Tung Dao,Dao Tran,Huynh Thi Thanh Binh*

Main category: cs.AI

TL;DR: MMP-A*是一个多模态路径规划框架，通过结合视觉语言模型的空间感知能力和自适应衰减机制，在复杂环境中实现接近最优的轨迹规划，同时显著降低计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 传统A*算法在大规模复杂环境中计算和内存成本过高，而基于大语言模型的路径规划方法缺乏空间感知能力，在拓扑复杂环境中容易产生错误的路径点，导致计算效率低下。

Method: MMP-A*框架整合了视觉语言模型的空间感知能力和新颖的自适应衰减机制。该机制动态调节不确定路径点在启发式函数中的影响，确保几何有效性同时大幅减少内存开销。

Result: 在具有严重杂乱和拓扑复杂性的挑战性环境中测试，MMP-A*实现了接近最优的轨迹规划，同时显著降低了操作成本。

Conclusion: MMP-A*展示了一个感知基础且计算高效的自主导航范式潜力，通过将高层推理锚定在物理几何中，解决了纯文本规划器的局限性。

Abstract: Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.

</details>


### [249] [OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation](https://arxiv.org/abs/2601.01939)
*Victor Sanchez,Chris Reinke,Ahamed Mohamed,Xavier Alameda-Pineda*

Main category: cs.AI

TL;DR: OpenSocInt是一个开源的多模态社交交互仿真器，提供模块化架构训练社交智能体，已应用于社交导航任务


<details>
  <summary>Details</summary>
Motivation: 为多模态社交交互研究提供一个开源仿真平台，支持探索不同感知特征、编码融合方法和智能体设计

Method: 开发了OpenSocInt软件包，包含多模态社交交互仿真器和模块化架构，通过社交导航任务展示其功能

Result: 软件已公开可用（GPL许可），提供了完整的实验协议，能够支持不同感知特征、编码融合和智能体的研究

Conclusion: OpenSocInt为社交智能研究提供了一个有价值的开源工具，有助于推动多模态社交交互领域的发展

Abstract: In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.

</details>


### [250] [CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes](https://arxiv.org/abs/2601.01976)
*Yasmine Souissi,Fabrice Boissier,Nida Meddouri*

Main category: cs.AI

TL;DR: 本文对基于形式概念分析（FCA）的分类器进行了最新综述，提出了一种从名义数据计算闭包算子的新方法，并构建了关注最相关概念的部分概念格。


<details>
  <summary>Details</summary>
Motivation: 知识发现（KDD）旨在从海量数据中提取隐藏的有意义知识，其中分类是核心数据挖掘技术之一。形式概念分析（FCA）因其基于概念格的数学结构，能够生成形式概念并发现隐藏关系，被认为是一种有效的可解释和可解释学习方法。

Method: 1. 对基于FCA的分类器进行了最新综述；2. 探索了从名义数据计算闭包算子的各种方法；3. 提出了一种构建部分概念格的新方法，该概念格专注于最相关的概念。

Result: 提供了实验结果来证明所提出方法的效率。

Conclusion: 本文系统综述了FCA在分类任务中的应用，并提出了一种改进的概念格构建方法，该方法能够更有效地处理名义数据并关注最相关的概念，为可解释机器学习提供了新的技术途径。

Abstract: Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.

</details>


### [251] [ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems](https://arxiv.org/abs/2601.01982)
*Noel Thomas*

Main category: cs.AI

TL;DR: ChaosBench-Logic是一个评估大语言模型在混沌动力系统领域逻辑推理能力的基准测试，包含30个系统、11个语义谓词和621个问题，涵盖7种推理类型，结果显示前沿LLMs在单项准确率上达到91-94%，但在组合推理和全局一致性方面存在严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言任务上表现出色，但在需要精确逻辑和符号推理的领域仍然脆弱。混沌动力系统提供了一个特别严格的测试环境，因为混沌是确定性的，但经常被误解为随机性或复杂性。需要建立一个统一的基准来评估LLMs在科学推理方面的能力。

Method: 引入ChaosBench-Logic基准测试，使用统一的一阶逻辑本体论评估30个不同的动力系统。每个系统用11个语义谓词的真值分配进行标注，生成621个问题，涵盖7种推理类别：多跳推理、跨系统类比、反事实推理、偏见探测和多轮对话等。定义了逻辑准确性、蕴含一致性、对话连贯性和矛盾性等指标，并发布了开源评估管道。

Result: 前沿LLMs（GPT-4、Claude 3.5 Sonnet、Gemini 2.5 Flash和开源LLaMA-3 70B）在单项准确率上达到91-94%，但在组合推理项目上得分为0%，表现出脆弱的全局一致性。对话级准确率从53.1%（GPT-4 CoT）到75.5%（LLaMA-3零样本）不等。

Conclusion: ChaosBench-Logic为诊断LLMs在逻辑推理方面的失败提供了一个严格的测试平台，并为开发能够改善LLMs科学推理能力的神经符号方法奠定了基础。尽管LLMs在单项任务上表现良好，但在需要组合推理和全局一致性的复杂逻辑任务上仍然存在严重缺陷。

Abstract: Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.

</details>


### [252] [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)
*Dong Xue,Jicheng Tu,Ming Wang,Xin Yan,Fangzhou Liu,Jie Hu*

Main category: cs.AI

TL;DR: MindChat是一个保护隐私的心理健康支持大语言模型，配合MindCorpus合成心理咨询数据集，通过联邦学习和差分隐私减少隐私风险，在心理咨询能力评估中表现良好。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在心理健康支持方面有潜力，但训练受到真实心理咨询对话稀缺性和敏感性的限制，需要解决隐私保护问题。

Method: 1. 开发MindCorpus合成数据集：采用多智能体角色扮演框架，包含回合级批评修订和会话级策略精化的双闭环反馈设计；2. 训练MindChat模型：使用联邦学习配合参数高效的LoRA适配器，并加入差分隐私优化减少隐私风险。

Result: MindCorpus提高了训练效果，MindChat在自动LLM评估和人工评估中与现有通用和心理咨询导向的基线模型表现相当，同时在成员推理攻击下表现出减少的隐私泄露。

Conclusion: 提出的MindChat模型和MindCorpus数据集为解决心理健康支持LLM训练中的数据稀缺和隐私问题提供了有效方案，在保护隐私的同时保持了良好的心理咨询能力。

Abstract: Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.

</details>


### [253] [XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging](https://arxiv.org/abs/2601.02008)
*Midhat Urooj,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AI

TL;DR: XAIMeD是一个可解释的医疗AI框架，通过神经符号架构整合临床专业知识，提升分布偏移下的鲁棒性和罕见类别敏感性，提供透明的临床对齐解释。


<details>
  <summary>Details</summary>
Motivation: 解决医疗AI中的可解释性、领域泛化和罕见类别可靠性等关键挑战，传统深度模型在真实世界分布偏移下经常失败，并对不频繁的临床条件表现出偏见。

Method: 提出XAIMeD框架，将临床专业知识编码为原子医学命题的逻辑连接，转化为机器可检查的类别特定规则。通过加权特征满足度分数量化诊断效用，创建符号推理分支补充神经预测。使用置信度加权融合整合符号和深度输出，并采用受Hunt启发的自适应路由机制，由熵不平衡增益和罕见类别基尼系数指导。

Result: 在四个挑战性任务上评估显示显著性能提升：跨领域泛化提升6%，罕见类别F1分数提升10%，远超最先进的深度学习基线。消融研究证实临床基础的符号组件作为有效的正则化器，确保对分布偏移的鲁棒性。

Conclusion: XAIMeD为多模态医疗AI提供了一个原则性、临床忠实且可解释的方法，通过整合临床专业知识提升模型在真实世界医疗应用中的可靠性和透明度。

Abstract: Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.

</details>


### [254] [Simulated Reasoning is Reasoning](https://arxiv.org/abs/2601.02043)
*Hendrik Kempt,Alon Lavie*

Main category: cs.AI

TL;DR: 论文认为基础模型通过模仿"大声思考"过程、测试生成路径并迭代，实现了不同于人类符号推理的新型推理能力，这改变了我们对推理必要条件的理解，并需要重新评估"随机鹦鹉"比喻的适用性。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为推理是通过符号推理实现理解的路径，但基础模型展示了无需符号推理也能完成推理任务的能力。这种新型推理方式与人类推理存在根本差异，缺乏基础常识且具有脆弱性，需要重新评估推理的本质及其必要条件。

Method: 论文采用哲学分析方法，探讨基础模型推理现象的多重哲学解释，论证"随机鹦鹉"比喻已失去相关性，并反思由这些推理模型及其增长能力引发的安全性和适当性规范考量。

Result: 基础模型通过模仿"大声思考"过程、测试生成路径并迭代，能够独立或通过少量样本学习解决问题，但这种推理缺乏基础常识和稳定性，与人类符号推理有根本差异。这改变了我们对推理必要条件的评估，并需要新的安全防御方法来应对其脆弱性。

Conclusion: 基础模型展示的新型推理能力挑战了传统符号推理的必要性假设，"随机鹦鹉"比喻已不再适用。需要重新思考推理的本质，并建立针对这种新型推理脆弱性的安全框架和规范考量，以应对其日益增长的能力带来的挑战。

Abstract: Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., "symbolic reasoning". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can "reason" by way of imitating the process of "thinking out loud", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the "stochastic parrot" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.

</details>


### [255] [FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations](https://arxiv.org/abs/2601.02071)
*Adeshola Okubena,Yusuf Ali Mohammed,Moe Elbadawi*

Main category: cs.AI

TL;DR: 本研究探讨了将大语言模型应用于药物3D打印配方开发，通过微调四种LLM架构在1400多个FDM配方数据集上，评估其在推荐辅料和预测丝材机械性能方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的药物3D打印研究大多局限于狭窄领域，未能充分考虑该技术固有的广泛配方挑战。随着人工智能向通用人工智能发展，需要探索LLM在药物配方开发中的实际应用潜力。

Method: 研究微调了四种大语言模型架构，使用包含1400多个熔融沉积成型配方的数据集，系统评估了微调和生成参数配置。模型被训练用于基于API剂量推荐合适的辅料，并预测丝材的机械性能。

Result: Llama2模型在推荐FDM配方辅料方面表现最佳。模型选择和参数化显著影响性能，较小的LLM出现了灾难性遗忘现象。研究发现：即使相对较小的1400多个配方数据集也可能导致模型灾难性遗忘；标准LLM指标仅评估语言性能而非配方可加工性；基于生物医学相关数据训练的LLM并不总是产生最佳结果。

Conclusion: 解决这些挑战对于推动LLM超越语言熟练度，发展成为药物配方开发的可靠系统至关重要。需要开发更全面的评估指标来确保LLM在药物3D打印应用中的实际效用。

Abstract: Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.

</details>


### [256] [Streaming Hallucination Detection in Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.02170)
*Haolang Lu,Minghui Pan,Ripeng Li,Guoshun Nan,Jialin Zhuang,Zijie Zhao,Zhongxiang Sun,Kun Wang,Yang Liu*

Main category: cs.AI

TL;DR: 提出将长链思维推理中的幻觉视为演化潜状态而非一次性错误事件，引入累积前缀级幻觉信号来追踪推理状态的全局演化，实现流式幻觉检测


<details>
  <summary>Details</summary>
Motivation: 长链思维推理虽然能提升大语言模型性能，但其中的幻觉往往以微妙方式出现并在推理步骤间传播。传统方法将幻觉视为一次性错误事件，但作者认为这更适合被理解为演化中的潜状态，需要全局视角来追踪其演变过程

Method: 将步骤级幻觉判断视为局部观测，引入累积前缀级幻觉信号来追踪整个推理轨迹中推理状态的全局演化。该方法支持流式幻觉检测，提供实时、可解释的证据

Result: 该方法能够实现长链思维推理中的流式幻觉检测，提供实时监控和可解释的证据，有助于更准确地理解和处理推理过程中的幻觉演化

Conclusion: 将长链思维推理中的幻觉视为演化潜状态而非一次性错误事件，通过累积前缀级信号追踪全局演化，为流式幻觉检测提供了新视角，增强了实时监控和可解释性

Abstract: Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.

</details>


### [257] [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)
*Falcon LLM Team,Iheb Chaabane,Puneesh Khanna,Suhail Mohmad,Slim Frikha,Shi Hu,Abdalgader Abubaker,Reda Alami,Mikhail Lubinets,Mohamed El Amine Seddik,Hakim Hacid*

Main category: cs.AI

TL;DR: Falcon-H1R是一个7B参数的推理优化模型，证明了小型语言模型也能达到有竞争力的推理性能，在多个推理密集型基准测试中匹配或超越比它大2-7倍的SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 探索小型语言模型是否能够通过精心设计的数据策展和训练策略，在不增加模型规模的情况下实现与大型模型相当的推理性能，为实际应用提供更高效的解决方案。

Method: 采用混合并行架构设计实现更快推理，通过高效监督微调（SFT）和强化学习扩展进行针对性训练，利用DeepConf方法实现最先进的测试时扩展效率，结合数据策展和架构优化。

Result: 在多个推理密集型基准测试中，Falcon-H1R-7B模型一致匹配或超越了比它大2-7倍的SOTA推理模型，实现了推理效率的3D极限（更快推理、更高token效率、更高准确性）。

Conclusion: 紧凑模型通过针对性的模型训练和架构选择，能够提供稳健且可扩展的推理性能，Falcon-H1R-7B成为扩展高级推理系统的实用骨干，特别适用于需要大量思维链生成和并行测试时扩展的场景。

Abstract: This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\times$ to $7\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [258] [VEAT Quantifies Implicit Associations in Text-to-Video Generator Sora and Reveals Challenges in Bias Mitigation](https://arxiv.org/abs/2601.00996)
*Yongxu Sun,Michael Saxon,Ian Yang,Anna-Maria Gueorguieva,Aylin Caliskan*

Main category: cs.CY

TL;DR: 本文提出视频嵌入关联测试(VEAT)方法，发现Sora等文本到视频生成器存在种族和性别偏见，将欧洲裔美国人和女性与愉悦度关联更强，且偏见程度与现实世界人口分布高度相关，去偏提示可能适得其反。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估Sora等文本到视频生成器是否反映社会偏见，特别是种族和性别偏见。随着T2V生成器的普及，需要量化其生成内容中的系统性偏见，以揭示潜在的危害。

Method: 提出视频嵌入关联测试(VEAT)和单类别VEAT(SC-VEAT)方法，将嵌入关联测试从文字和图像扩展到视频领域。通过验证方法后，量化17种职业和7个奖项中种族（非裔美国人vs欧洲裔美国人）和性别（女性vs男性）与愉悦度（愉快vs不愉快）的关联。

Result: Sora视频显示欧洲裔美国人和女性与愉悦度关联更强（效应量d>0.8）。效应大小与现实世界人口分布高度相关：职业中男性比例和白人比例（r=0.93, r=0.83），奖项中男性比例和非黑人比例（r=0.88, r=0.99）。应用去偏提示通常减少效应大小，但可能适得其反：两个黑人关联职业（清洁工、邮政服务）在去偏后反而更黑人关联。

Conclusion: 结论指出易获取的T2V生成器如果不经过严格评估和负责任部署，实际上可能放大代表性伤害。研究强调了系统性评估生成AI偏见的重要性，以及简单去偏策略的局限性。

Abstract: Text-to-Video (T2V) generators such as Sora raise concerns about whether generated content reflects societal bias. We extend embedding-association tests from words and images to video by introducing the Video Embedding Association Test (VEAT) and Single-Category VEAT (SC-VEAT). We validate these methods by reproducing the direction and magnitude of associations from widely used baselines, including Implicit Association Test (IAT) scenarios and OASIS image categories. We then quantify race (African American vs. European American) and gender (women vs. men) associations with valence (pleasant vs. unpleasant) across 17 occupations and 7 awards. Sora videos associate European Americans and women more with pleasantness (both d>0.8). Effect sizes correlate with real-world demographic distributions: percent men and White in occupations (r=0.93, r=0.83) and percent male and non-Black among award recipients (r=0.88, r=0.99). Applying explicit debiasing prompts generally reduces effect-size magnitudes, but can backfire: two Black-associated occupations (janitor, postal service) become more Black-associated after debiasing. Together, these results reveal that easily accessible T2V generators can actually amplify representational harms if not rigorously evaluated and responsibly deployed.

</details>


### [259] [Inconsistencies in Classification of Online News Articles: A Call for Common Standards in Brand Safety Services](https://arxiv.org/abs/2601.01303)
*Michael Smith,Riley Grossman,Antonio Torres-Aguero,Pritam Sen,Cristian Borcea,Yi Chen*

Main category: cs.CY

TL;DR: 研究分析了三家主要品牌安全服务商对在线新闻文章分类的不一致性，发现存在显著差异，这对广告商和出版商都有害


<details>
  <summary>Details</summary>
Motivation: 新闻内容在公共话语中扮演核心角色，而品牌安全分类的不一致会导致数字广告支出错配和收入损失，特别是在数字广告投入不足的新闻行业

Method: 收集了51个域名的4,352篇新闻文章数据，分析DoubleVerify、Integral Ad Science和Oracle三家主要品牌安全服务商的分类评级

Result: 品牌安全服务经常产生冲突的分类结果，不同提供商之间存在显著差异，这些不一致性对广告商和出版商都有害

Conclusion: 当前品牌安全系统存在缺陷，需要建立标准化和透明的品牌安全系统来减轻对数字广告生态系统的有害影响

Abstract: This study examines inconsistencies in the brand safety classifications of online news articles by analyzing ratings from three leading brand safety providers, DoubleVerify, Integral Ad Science, and Oracle. We focus on news content because of its central role in public discourse and the significant financial consequences of unsafe classifications in a sector that is already underserved by digital ad spending. By collecting data from 4,352 news articles on 51 domains, our analysis shows that brand safety services often produce conflicting classifications, with significant discrepancies between providers. These inconsistencies can have harmful consequences for both advertisers and publishers, leading to misplaced advertising spending and revenue losses. This research provides critical insights into the shortcomings of the current brand safety landscape. We argue for a standardized and transparent brand safety system to mitigate the harmful effects of the current system on the digital advertising ecosystem.

</details>


### [260] [AppellateGen: A Benchmark for Appellate Legal Judgment Generation](https://arxiv.org/abs/2601.01331)
*Hongkun Yang,Lionel Z. Wang,Wei Fan,Yiran Hu,Lixu Wang,Chenyu Liu,Shenghong Fu,Haoyang Li,Xin Xu,Jiexin Zheng,Wei Dong*

Main category: cs.CY

TL;DR: 本文提出了AppellateGen基准，用于上诉审（二审）法律判决生成，包含7,351个案例对，并设计了基于司法标准操作程序的SLMAS多智能体系统来模拟司法工作流程。


<details>
  <summary>Details</summary>
Motivation: 现有法律判决生成研究主要关注一审审判，依赖静态的事实到判决映射，忽视了上诉审（二审）的辩证性质。上诉审需要对初始判决和证据更新进行推理，建模审判阶段间的因果依赖关系。

Method: 提出了基于司法标准操作程序(SOP)的法律多智能体系统(SLMAS)，将生成过程分解为问题识别、检索和起草三个离散阶段，模拟司法工作流程。

Result: 实验结果表明，虽然SLMAS提高了逻辑一致性，但上诉推理的复杂性对当前大语言模型仍构成重大挑战。数据集和代码已公开。

Conclusion: AppellateGen基准填补了上诉审法律判决生成研究的空白，SLMAS系统通过模拟司法工作流程改进了逻辑一致性，但上诉推理的复杂性仍需进一步研究。

Abstract: Legal judgment generation is a critical task in legal intelligence. However, existing research in legal judgment generation has predominantly focused on first-instance trials, relying on static fact-to-verdict mappings while neglecting the dialectical nature of appellate (second-instance) review. To address this, we introduce AppellateGen, a benchmark for second-instance legal judgment generation comprising 7,351 case pairs. The task requires models to draft legally binding judgments by reasoning over the initial verdict and evidentiary updates, thereby modeling the causal dependency between trial stages. We further propose a judicial Standard Operating Procedure (SOP)-based Legal Multi-Agent System (SLMAS) to simulate judicial workflows, which decomposes the generation process into discrete stages of issue identification, retrieval, and drafting. Experimental results indicate that while SLMAS improves logical consistency, the complexity of appellate reasoning remains a substantial challenge for current LLMs. The dataset and code are publicly available at: https://anonymous.4open.science/r/AppellateGen-5763.

</details>


### [261] [From Chat Control to Robot Control: The Backdoors Left Open for the Sake of Safety](https://arxiv.org/abs/2601.02205)
*Neziha Akalin,Alberto Giaretta*

Main category: cs.CY

TL;DR: 欧盟Chat Control法案将数字监控扩展到人机交互领域，可能将日常机器人转变为监控工具，在保护与控制之间制造矛盾，同时因破坏加密而增加安全风险。


<details>
  <summary>Details</summary>
Motivation: 探讨欧盟Chat Control法案如何通过激励内容检测和通信扫描，从根本上改变人机交互的基础。随着机器人在护理、教育和远程呈现中成为人际沟通渠道，它们传递的不仅是语音，还包括手势、情感和上下文线索。

Method: 通过分析欧盟Chat Control法案的监管激励机制，论证将数字监控法律扩展到具身系统将导致持续监控，将观察嵌入日常机器人的设计中。

Result: 这种监管模糊了保护与控制的界限，将伴侣机器人转变为潜在的信息提供者。同时，破坏端到端加密的监控机制实际上成为后门，扩大了攻击面，允许对手利用法律强制的监控基础设施。

Conclusion: 这创造了一个"通过不安全实现安全"的悖论：旨在保护用户的系统反而可能损害其隐私、自主权和信任。本研究不旨在预测未来，而是提高意识并帮助防止某些未来成为现实。

Abstract: This paper explores how a recent European Union proposal, the so-called Chat Control law, which creates regulatory incentives for providers to implement content detection and communication scanning, could transform the foundations of human-robot interaction (HRI). As robots increasingly act as interpersonal communication channels in care, education, and telepresence, they convey not only speech but also gesture, emotion, and contextual cues. We argue that extending digital surveillance laws to such embodied systems would entail continuous monitoring, embedding observation into the very design of everyday robots. This regulation blurs the line between protection and control, turning companions into potential informants. At the same time, monitoring mechanisms that undermine end-to-end encryption function as de facto backdoors, expanding the attack surface and allowing adversaries to exploit legally induced monitoring infrastructures. This creates a paradox of safety through insecurity: systems introduced to protect users may instead compromise their privacy, autonomy, and trust. This work does not aim to predict the future, but to raise awareness and help prevent certain futures from materialising.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [262] [A Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System for Advertisement Retrieval and Personalization](https://arxiv.org/abs/2601.00833)
*Tangtang Wang,Kaijie Zhang,Kuangcong Liu*

Main category: cs.IR

TL;DR: 提出基于知识图谱和深度学习的语义推荐数据库系统（KGSR-ADS），用于广告检索和个性化推荐，整合多关系语义、LLM嵌入、GNN注意力机制和向量索引优化。


<details>
  <summary>Details</summary>
Motivation: 现代数字营销中广告数据日益复杂，需要智能系统理解产品、受众和广告内容之间的语义关系，以应对大规模异构工作负载下的个性化推荐挑战。

Method: 提出分层架构：1）异构广告知识图谱（Ad-KG）捕获多关系语义；2）语义嵌入层利用GPT/LLaMA等大语言模型生成上下文感知向量表示；3）GNN+注意力模型推断跨实体依赖；4）基于FAISS/Milvus向量索引的数据库优化与检索层实现高效语义搜索。

Result: 该架构实现了准确的语义匹配和可扩展的检索能力，能够在大规模异构工作负载下提供个性化的广告推荐。

Conclusion: KGSR-ADS系统通过整合知识图谱、深度学习和大语言模型，有效解决了广告数据语义理解与个性化推荐的挑战，为现代数字营销提供了智能化的解决方案。

Abstract: In modern digital marketing, the growing complexity of advertisement data demands intelligent systems capable of understanding semantic relationships among products, audiences, and advertising content. To address this challenge, this paper proposes a Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System (KGSR-ADS) for advertisement retrieval and personalization. The proposed framework integrates a heterogeneous Ad-Knowledge Graph (Ad-KG) that captures multi-relational semantics, a Semantic Embedding Layer that leverages large language models (LLMs) such as GPT and LLaMA to generate context-aware vector representations, a GNN + Attention Model that infers cross-entity dependencies, and a Database Optimization & Retrieval Layer based on vector indexing (FAISS/Milvus) for efficient semantic search. This layered architecture enables both accurate semantic matching and scalable retrieval, allowing personalized ad recommendations under large-scale heterogeneous workloads.

</details>


### [263] [Enhancing Retrieval-Augmented Generation with Topic-Enriched Embeddings: A Hybrid Approach Integrating Traditional NLP Techniques](https://arxiv.org/abs/2601.00891)
*Rodrigo Kataishi*

Main category: cs.IR

TL;DR: 本文提出了一种主题增强嵌入方法，通过结合TF-IDF、主题建模和降维技术，将基于术语的信号和主题结构与上下文句子嵌入相结合，以提高RAG系统的检索质量。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统依赖准确的文档检索来为大型语言模型提供外部知识基础，但在主题重叠和主题变化高的语料库中，检索质量往往会下降。现有方法在处理语义重叠和主题变异方面存在局限性。

Method: 提出主题增强嵌入方法：结合TF-IDF与主题建模和降维技术，使用潜在语义分析（LSA）和潜在狄利克雷分配（LDA）编码潜在主题结构，并将这些表示与紧凑的上下文编码器（all-MiniLM）融合。通过联合捕获术语级和主题级语义来改进嵌入质量。

Result: 在法律文本语料库上的实验显示，主题增强嵌入在聚类一致性和检索指标方面持续提升，提高了语义聚类质量、检索精度，同时相对于纯上下文基线减少了计算负担。

Conclusion: 主题增强嵌入可以作为更可靠的知识密集型RAG管道的实用组件，通过整合术语级和主题级语义信号，有效改善在主题重叠和高变异语料库中的检索性能。

Abstract: Retrieval-augmented generation (RAG) systems rely on accurate document retrieval to ground large language models (LLMs) in external knowledge, yet retrieval quality often degrades in corpora where topics overlap and thematic variation is high. This work proposes topic-enriched embeddings that integrate term-based signals and topic structure with contextual sentence embeddings. The approach combines TF-IDF with topic modeling and dimensionality reduction, using Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) to encode latent topical organization, and fuses these representations with a compact contextual encoder (all-MiniLM). By jointly capturing term-level and topic-level semantics, topic-enriched embeddings improve semantic clustering, increase retrieval precision, and reduce computational burden relative to purely contextual baselines. Experiments on a legal-text corpus show consistent gains in clustering coherence and retrieval metrics, suggesting that topic-enriched embeddings can serve as a practical component for more reliable knowledge-intensive RAG pipelines.

</details>


### [264] [The Discovery Gap: How Product Hunt Startups Vanish in LLM Organic Discovery Queries](https://arxiv.org/abs/2601.00912)
*Amit Prakash Sharma*

Main category: cs.IR

TL;DR: 研究显示，当用户按名称询问产品时，ChatGPT和Perplexity的识别率分别高达99.4%和94.3%，但在发现式查询中成功率骤降至3.32%和8.29%。生成式引擎优化(GEO)对AI可见性无显著影响，传统SEO信号如外链和社区存在才是关键预测因素。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究当用户向ChatGPT询问项目管理工具推荐时，哪些产品会出现在回答中，以及新推出的创业产品是否有机会被AI发现。这对于创业创始人了解产品在AI搜索中的可见性至关重要。

Method: 从2025年Product Hunt排行榜前500名产品中随机选择112家创业公司，对两个大型语言模型（ChatGPT的gpt-4o-mini和Perplexity的sonar with web search）进行了2,240次查询测试。分析包括按名称查询和发现式查询两种场景，并评估了GEO分数、SEO信号（外链数量）、Product Hunt排名和Reddit社区存在等影响因素。

Result: 按名称查询时，ChatGPT识别率为99.4%，Perplexity为94.3%；但在发现式查询中，成功率分别暴跌至3.32%和8.29%（ChatGPT差距达30:1）。GEO优化与发现率无相关性，而传统SEO信号如外链数量（r = +0.319）和Product Hunt排名（r = -0.286）对Perplexity可见性有显著预测作用。Reddit社区存在经清理后也显示显著相关性（r = +0.395）。

Conclusion: 不要直接为AI发现进行优化，而应优先建立SEO基础，LLM可见性将随之而来。传统搜索引擎优化信号比专门的生成式引擎优化更有效地预测产品在大型语言模型中的可见性。

Abstract: When someone asks ChatGPT to recommend a project management tool, which products show up in the response? And more importantly for startup founders: will their newly launched product ever appear? This research set out to answer these questions.
  I randomly selected 112 startups from the top 500 products featured on the 2025 Product Hunt leaderboard and tested each one across 2,240 queries to two different large language models: ChatGPT (gpt-4o-mini) and Perplexity (sonar with web search).
  The results were striking. When users asked about products by name, both LLMs recognized them almost perfectly: 99.4% for ChatGPT and 94.3% for Perplexity. But when users asked discovery-style questions like "What are the best AI tools launched this year?" the success rates collapsed to 3.32% and 8.29% respectively. That's a gap of 30-to-1 for ChatGPT.
  Perhaps the most surprising finding was that Generative Engine Optimization (GEO), the practice of optimizing website content for AI visibility, showed no correlation with actual discovery rates. Products with high GEO scores were no more likely to appear in organic queries than products with low scores.
  What did matter? For Perplexity, traditional SEO signals like referring domains (r = +0.319, p < 0.001) and Product Hunt ranking (r = -0.286, p = 0.002) predicted visibility. After cleaning the Reddit data for false positives, community presence also emerged as significant (r = +0.395, p = 0.002).
  The practical takeaway is counterintuitive: don't optimize for AI discovery directly. Instead, build the SEO foundation first and LLM visibility will follow.

</details>


### [265] [MACA: A Framework for Distilling Trustworthy LLMs into Efficient Retrievers](https://arxiv.org/abs/2601.00926)
*Satya Swaroop Gudipudi,Sahil Girhepuje,Ponnurangam Kumaraguru,Kristine Ma*

Main category: cs.IR

TL;DR: MACA是一种元数据感知的跨模型对齐方法，将校准的LLM重排序器蒸馏到紧凑的学生检索器中，避免在线LLM调用，在银行FAQ检索任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 企业检索系统需要处理简短、不明确的查询，但每个查询都使用LLM重排序和手动标注成本高昂。需要一种既能利用语义细微差别和元数据，又不需要在线LLM调用的高效检索方法。

Method: 提出MACA方法：1) 使用元数据感知提示验证教师LLM的可靠性；2) 教师提供列表分数、困难负例和校准的相关边界；3) 学生通过MetaFusion目标训练，结合元数据条件排序损失和跨模型边界损失，学习将正确答案推至语义相似但元数据不匹配的候选项之上。

Result: 在专有消费者银行FAQ语料库和BankFAQs上，MACA教师比MAFA基线在Accuracy@1上分别提升5点和3点。MACA学生显著优于预训练编码器：在专有语料库上，MiniLM的Accuracy@1从0.23提升到0.48，同时保持推理无需LLM调用并支持检索增强生成。

Conclusion: MACA成功将元数据感知的LLM重排序能力蒸馏到紧凑的学生检索器中，实现了高效的企业检索系统，既利用了语义细微差别和元数据，又避免了昂贵的在线LLM调用。

Abstract: Modern enterprise retrieval systems must handle short, underspecified queries such as ``foreign transaction fee refund'' and ``recent check status''. In these cases, semantic nuance and metadata matter but per-query large language model (LLM) re-ranking and manual labeling are costly. We present Metadata-Aware Cross-Model Alignment (MACA), which distills a calibrated metadata aware LLM re-ranker into a compact student retriever, avoiding online LLM calls. A metadata-aware prompt verifies the teacher's trustworthiness by checking consistency under permutations and robustness to paraphrases, then supplies listwise scores, hard negatives, and calibrated relevance margins. The student trains with MACA's MetaFusion objective, which combines a metadata conditioned ranking loss with a cross model margin loss so it learns to push the correct answer above semantically similar candidates with mismatched topic, sub-topic, or entity. On a proprietary consumer banking FAQ corpus and BankFAQs, the MACA teacher surpasses a MAFA baseline at Accuracy@1 by five points on the proprietary set and three points on BankFAQs. MACA students substantially outperform pretrained encoders; e.g., on the proprietary corpus MiniLM Accuracy@1 improves from 0.23 to 0.48, while keeping inference free of LLM calls and supporting retrieval-augmented generation.

</details>


### [266] [ScienceDB AI: An LLM-Driven Agentic Recommender System for Large-Scale Scientific Data Sharing Services](https://arxiv.org/abs/2601.01118)
*Qingqing Long,Haotian Chen,Chenyang Zhao,Xiaolei Du,Xuezhi Wang,Pengyao Wang,Chengzan Li,Yuanchun Zhou,Hengshu Zhu*

Main category: cs.IR

TL;DR: ScienceDB AI是基于ScienceDB科学数据共享平台的LLM驱动对话式推荐系统，通过深度语义理解和个性化推荐解决科学数据集共享利用难题。


<details>
  <summary>Details</summary>
Motivation: 科学数据集包含复杂的领域知识和上下文，传统协同过滤推荐方法难以有效处理。随着LLM的发展，需要构建能够深度理解语义并进行个性化推荐的对话式推荐系统，以促进科学数据集的共享和利用。

Method: 开发了ScienceDB AI系统，包含三个核心创新：1）科学意图感知器提取结构化实验元素；2）结构化记忆压缩器管理多轮对话；3）可信检索增强生成框架，采用两阶段检索机制并提供可引用的CSTR标识符。

Result: 通过超过1000万个真实世界数据集的离线和在线实验，ScienceDB AI显示出显著的有效性，成为首个专门针对大规模科学数据集共享服务的LLM驱动对话式推荐系统。

Conclusion: ScienceDB AI通过LLM驱动的对话式推荐系统，有效解决了科学数据集共享利用的挑战，提升了推荐的准确性和可信度，为科学数据共享平台提供了创新的解决方案。

Abstract: The rapid growth of AI for Science (AI4S) has underscored the significance of scientific datasets, leading to the establishment of numerous national scientific data centers and sharing platforms. Despite this progress, efficiently promoting dataset sharing and utilization for scientific research remains challenging. Scientific datasets contain intricate domain-specific knowledge and contexts, rendering traditional collaborative filtering-based recommenders inadequate. Recent advances in Large Language Models (LLMs) offer unprecedented opportunities to build conversational agents capable of deep semantic understanding and personalized recommendations. In response, we present ScienceDB AI, a novel LLM-driven agentic recommender system developed on Science Data Bank (ScienceDB), one of the largest global scientific data-sharing platforms. ScienceDB AI leverages natural language conversations and deep reasoning to accurately recommend datasets aligned with researchers' scientific intents and evolving requirements. The system introduces several innovations: a Scientific Intention Perceptor to extract structured experimental elements from complicated queries, a Structured Memory Compressor to manage multi-turn dialogues effectively, and a Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework. The Trustworthy RAG employs a two-stage retrieval mechanism and provides citable dataset references via Citable Scientific Task Record (CSTR) identifiers, enhancing recommendation trustworthiness and reproducibility. Through extensive offline and online experiments using over 10 million real-world datasets, ScienceDB AI has demonstrated significant effectiveness. To our knowledge, ScienceDB AI is the first LLM-driven conversational recommender tailored explicitly for large-scale scientific dataset sharing services. The platform is publicly accessible at: https://ai.scidb.cn/en.

</details>


### [267] [Adaptive Diffusion-based Augmentation for Recommendation](https://arxiv.org/abs/2601.01448)
*Na Li,Fanghui Sun,Yan Zou,Yangfu Zhu,Xiatian Zhu,Ying Ma*

Main category: cs.IR

TL;DR: 提出ADAR方法，使用扩散模型生成可控的负样本，通过识别正负样本转换点来提升推荐系统性能


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统依赖隐式反馈，只能观察到正面的用户-物品交互，负采样方法存在两个问题：1) 可能将潜在正面但未观察到的物品误标为负样本；2) 缺乏对负样本选择的精确控制

Method: 提出ADAR（自适应扩散增强推荐）模块，利用扩散模型合成信息丰富的负样本。受扩散过程中渐进式破坏过程的启发，ADAR模拟从正样本到负样本的连续过渡，允许对样本难度进行细粒度控制。通过理论识别正样本转变为负样本的转换点，并推导出基于分数的函数来自适应确定最佳采样时间步

Result: 实验证实ADAR具有广泛的兼容性，能够显著提升现有推荐模型的性能，包括协同过滤和序列推荐，且无需修改模型架构

Conclusion: ADAR通过生成可控的负样本，有效解决了现有负采样方法的局限性，能够生成具有挑战性的负样本来优化模型的决策边界，提升推荐系统的整体性能

Abstract: Recommendation systems often rely on implicit feedback, where only positive user-item interactions can be observed. Negative sampling is therefore crucial to provide proper negative training signals. However, existing methods tend to mislabel potentially positive but unobserved items as negatives and lack precise control over negative sample selection. We aim to address these by generating controllable negative samples, rather than sampling from the existing item pool. In this context, we propose Adaptive Diffusion-based Augmentation for Recommendation (ADAR), a novel and model-agnostic module that leverages diffusion to synthesize informative negatives. Inspired by the progressive corruption process in diffusion, ADAR simulates a continuous transition from positive to negative, allowing for fine-grained control over sample hardness. To mine suitable negative samples, we theoretically identify the transition point at which a positive sample turns negative and derive a score-aware function to adaptively determine the optimal sampling timestep. By identifying this transition point, ADAR generates challenging negative samples that effectively refine the model's decision boundary. Experiments confirm that ADAR is broadly compatible and boosts the performance of existing recommendation models substantially, including collaborative filtering and sequential recommendation, without architectural modifications.

</details>


### [268] [LACONIC: Dense-Level Effectiveness for Scalable Sparse Retrieval via a Two-Phase Training Curriculum](https://arxiv.org/abs/2601.01684)
*Zhichao Xu,Shengyao Zhuang,Crystina Zhang,Xueguang Ma,Yijun Tian,Maitrey Mehta,Jimmy Lin,Vivek Srikumar*

Main category: cs.IR

TL;DR: LACONIC是基于Llama-3架构的稀疏检索模型家族，通过两阶段训练实现与密集检索模型相当的性能，同时大幅降低内存需求和计算成本。


<details>
  <summary>Details</summary>
Motivation: 密集检索模型虽然性能优越，但部署时面临高内存需求和GPU依赖的限制。稀疏检索虽然效率高但历史关注度不足，需要开发既能保持高性能又能在CPU硬件上高效运行的检索解决方案。

Method: 提出LACONIC稀疏检索模型家族（1B、3B、8B参数），采用两阶段训练：1）弱监督预微调，使因果LLM适应双向上下文；2）使用精选困难负样本进行高质量微调。

Result: LACONIC-8B在MTEB检索基准上达到60.2 nDCG，在2026年1月1日的排行榜上排名第15位，同时比等效密集模型减少71%的索引内存，能在普通CPU硬件上高效运行。

Conclusion: LACONIC通过稀疏检索方法有效弥合了与密集模型的性能差距，为现实世界搜索应用提供了可扩展且高效的解决方案，显著降低了部署成本和硬件要求。

Abstract: While dense retrieval models have become the standard for state-of-the-art information retrieval, their deployment is often constrained by high memory requirements and reliance on GPU accelerators for vector similarity search. Learned sparse retrieval offers a compelling alternative by enabling efficient search via inverted indices, yet it has historically received less attention than dense approaches. In this report, we introduce LACONIC, a family of learned sparse retrievers based on the Llama-3 architecture (1B, 3B, and 8B). We propose a streamlined two-phase training curriculum consisting of (1) weakly supervised pre-finetuning to adapt causal LLMs for bidirectional contextualization and (2) high-signal finetuning using curated hard negatives. Our results demonstrate that LACONIC effectively bridges the performance gap with dense models: the 8B variant achieves a state-of-the-art 60.2 nDCG on the MTEB Retrieval benchmark, ranking 15th on the leaderboard as of January 1, 2026, while utilizing 71\% less index memory than an equivalent dense model. By delivering high retrieval effectiveness on commodity CPU hardware with a fraction of the compute budget required by competing models, LACONIC provides a scalable and efficient solution for real-world search applications.

</details>


### [269] [When Attention Becomes Exposure in Generative Search](https://arxiv.org/abs/2601.01750)
*Shayan Alipour,Mehdi Kargar,Morteza Zihayat*

Main category: cs.IR

TL;DR: 生成式搜索引擎的引用存在曝光偏见，倾向于已经具有较高知名度的声音，这可能固化现有优势并缩小观点多样性


<details>
  <summary>Details</summary>
Motivation: 随着生成式搜索引擎取代传统排名列表，以及Web3平台激励驱动创作者生态系统的兴起，需要研究生成式搜索引擎引用中的曝光是否受到外部注意力市场的影响

Method: 对44家Web3企业进行审计研究：1）分析企业创作者社区的持久性；2）通过企业特定查询评估不同声音的引用曝光差异；3）分析粉丝基础和创作者核心集中度与曝光排名的关系

Result: 1）企业创作者社区随时间保持稳定；2）更受欢迎的声音系统性地获得更多引用曝光；3）更大的粉丝基础和更集中的创作者核心与更高的曝光排名相关

Conclusion: 生成式搜索引擎引用存在向已具知名度声音的曝光偏见，可能固化现有优势地位并减少观点多样性

Abstract: Generative search engines are reshaping information access by replacing traditional ranked lists with synthesized answers and references. In parallel, with the growth of Web3 platforms, incentive-driven creator ecosystems have become an essential part of how enterprises build visibility and community by rewarding creators for contributing to shared narratives. However, the extent to which exposure in generative search engine citations is shaped by external attention markets remains uncertain. In this study, we audit the exposure for 44 Web3 enterprises. First, we show that the creator community around each enterprise is persistent over time. Second, enterprise-specific queries reveal that more popular voices systematically receive greater citation exposure than others. Third, we find that larger follower bases and enterprises with more concentrated creator cores are associated with higher-ranked exposure. Together, these results show that generative search engine citations exhibit exposure bias toward already prominent voices, which risks entrenching incumbents and narrowing viewpoint diversity.

</details>


### [270] [Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis](https://arxiv.org/abs/2601.01751)
*Samaneh Mohtadi,Gianluca Demartini*

Main category: cs.IR

TL;DR: 本文提出了一种基于聚类的框架来分析LLM作为相关性评估者时的系统性错误，发现LLM与人类评估者的分歧集中在特定语义簇而非随机分布，揭示了LLM在定义查询、政策相关和模糊语境中的系统性失败模式。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM已被用作信息检索评估中的相关性评估者，以降低成本并提高可扩展性，但先前研究主要关注LLM与人类评估者相比的可靠性。本研究旨在深入理解LLM在判断相关性时是否犯系统性错误，而不仅仅是了解其平均表现如何。

Method: 提出了一种新颖的表示方法，将查询-文档对嵌入到联合语义空间中，将相关性视为关系属性。引入基于聚类的框架来分析相关性标签分布，比较LLM和人类标签以识别分歧模式并定位系统性分歧区域。

Result: 在TREC Deep Learning 2019和2020数据集上的实验表明，人类与LLM之间的系统性分歧集中在特定语义簇中，而非随机分布。查询级分析揭示了在定义查询、政策相关或模糊语境中的重复性失败。具有跨簇一致性差异大的查询成为分歧热点，LLM倾向于低估相关内容或高估无关内容。

Conclusion: 该框架通过全局诊断与局部聚类相结合，揭示了LLM判断中的隐藏弱点，为实现偏差感知和更可靠的信息检索评估提供了方法。

Abstract: Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.

</details>


### [271] [MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2601.01753)
*Hyunsoo Kim,Jaewan Moon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

TL;DR: MergeRec提出了一种基于模型融合的新框架，用于解决数据隔离的跨域序列推荐问题，无需共享原始用户交互数据，通过伪用户数据构建和协同融合优化实现跨域泛化。


<details>
  <summary>Details</summary>
Motivation: 现有跨域推荐方法存在根本性限制：要么依赖跨域重叠用户/物品，要么忽视隐私约束。现实场景中，不同领域的原始用户交互数据由于隐私原因无法共享，需要一种新的解决方案。

Method: MergeRec包含三个关键组件：1) 融合初始化：使用免训练的融合技术初始化融合模型；2) 伪用户数据构建：将每个物品视为虚拟序列，合成有意义的训练样本；3) 协同融合优化：通过推荐损失和蒸馏损失的联合目标优化领域特定融合权重。

Result: 实验表明MergeRec不仅保留了原始模型的优势，还显著增强了对未见领域的泛化能力。相比传统模型融合方法，在Recall@10指标上平均提升高达17.21%。

Conclusion: 模型融合是构建通用推荐系统的可扩展且有效的途径。MergeRec在数据隔离的跨域序列推荐场景中表现出色，为隐私保护下的跨域推荐提供了新思路。

Abstract: Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.

</details>


### [272] [SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines](https://arxiv.org/abs/2601.01785)
*Rajiv Chaitanya Muttur*

Main category: cs.IR

TL;DR: SRAS是一种用于边缘设备RAG系统的轻量级文档选择器，使用强化学习训练，仅0.76MB大小，在CPU上延迟小于1秒，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用固定的top-k文档选择机制，忽略了生成质量且计算开销大，不适合边缘设备部署。需要一种轻量级、延迟感知的文档选择方法。

Method: 提出SRAS（稀疏奖励感知选择器），使用PPO强化学习训练紧凑策略（~0.76MB），采用结合Relaxed F1和BERTScore的混合奖励信号，在严格的计算和令牌约束下运行。

Result: 在合成QA基准测试中优于监督和随机选择器，在SQuAD v2上达到0.8546的BERTScore F1，无需领域特定调优，延迟小于1秒。

Conclusion: 首次证明基于强化学习的文档选择可以实现超轻量级、延迟感知，并有效用于设备端RAG流水线，为边缘部署提供了实用解决方案。

Abstract: Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.

</details>


### [273] [A Hybrid Architecture for Multi-Stage Claim Document Understanding: Combining Vision-Language Models and Machine Learning for Real-Time Processing](https://arxiv.org/abs/2601.01897)
*Lilu Cheng,Jingjun Lu,Yi Xuan Chan,Quoc Khai Nguyen,John Bi,Sean Ho*

Main category: cs.IR

TL;DR: 本文提出一个结合传统机器学习与视觉语言模型的多阶段流水线，用于从医疗理赔文档中高效提取结构化信息，处理速度比人工快300倍。


<details>
  <summary>Details</summary>
Motivation: 医疗理赔文档通常以扫描PDF或照片形式存在，存在内容异质性（打印/手写）、语言多样性、图像质量不一和布局差异等问题，给自动化解析和信息提取带来巨大挑战。Fullerton Health每年处理数千万份理赔，跨越九个市场，亟需高效自动化解决方案。

Method: 采用多阶段流水线：1) 使用多语言OCR引擎PaddleOCR进行文本识别；2) 传统逻辑回归分类器进行文档类型分类；3) 紧凑型视觉语言模型Qwen 2.5-VL-7B进行字段提取。结合传统机器学习与现代VLM技术。

Result: 文档类型分类准确率超过95%，字段级提取准确率约87%，平均处理延迟低于2秒/文档。相比人工处理每份理赔约10分钟，效率提升300倍。系统已在移动应用中部署，每周处理越南和新加坡数万份理赔。

Conclusion: 结合传统机器学习模型与现代视觉语言模型能够实现生产级的准确性和速度，为现实世界的自动化提供有效解决方案。该系统已成功部署并处理大规模理赔数据。

Abstract: Claims documents are fundamental to healthcare and insurance operations, serving as the basis for reimbursement, auditing, and compliance. However, these documents are typically not born digital; they often exist as scanned PDFs or photographs captured under uncontrolled conditions. Consequently, they exhibit significant content heterogeneity, ranging from typed invoices to handwritten medical reports, as well as linguistic diversity. This challenge is exemplified by operations at Fullerton Health, which handles tens of millions of claims annually across nine markets, including Singapore, the Philippines, Indonesia, Malaysia, Mainland China, Hong Kong, Vietnam, Papua New Guinea, and Cambodia. Such variability, coupled with inconsistent image quality and diverse layouts, poses a significant obstacle to automated parsing and structured information extraction.
  This paper presents a robust multi-stage pipeline that integrates the multilingual optical character recognition (OCR) engine PaddleOCR, a traditional Logistic Regression classifier, and a compact Vision-Language Model (VLM), Qwen 2.5-VL-7B, to achieve efficient and accurate field extraction from large-scale claims data. The proposed system achieves a document-type classification accuracy of over 95 percent and a field-level extraction accuracy of approximately 87 percent, while maintaining an average processing latency of under 2 seconds per document. Compared to manual processing, which typically requires around 10 minutes per claim, our system delivers a 300x improvement in efficiency. These results demonstrate that combining traditional machine learning models with modern VLMs enables production-grade accuracy and speed for real-world automation. The solution has been successfully deployed in our mobile application and is currently processing tens of thousands of claims weekly from Vietnam and Singapore.

</details>


### [274] [MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search](https://arxiv.org/abs/2601.01930)
*Dongfang Zhao*

Main category: cs.IR

TL;DR: MCGI是一种基于流形一致性的图索引方法，通过局部本征维度动态调整搜索策略，解决高维空间中图搜索的性能退化问题，显著提升高维数据集上的查询吞吐量和延迟。


<details>
  <summary>Details</summary>
Motivation: 传统基于图的近似最近邻搜索在高维空间中存在"欧几里得-测地线不匹配"问题，贪婪路由会偏离底层数据流形，导致性能下降。需要一种能够适应数据内在几何结构的索引方法。

Method: 提出流形一致图索引(MCGI)，这是一种几何感知的磁盘驻留索引方法。利用局部本征维度(LID)进行原位几何分析，动态调整波束搜索预算，消除对静态超参数的依赖，保持流形一致的拓扑连接性。

Result: 在高维GIST1M数据集上，MCGI在95%召回率下实现了5.8倍于DiskANN的吞吐量提升。在十亿规模的SIFT1B数据集上，将高召回查询延迟降低了3倍，同时在标准低维数据集上保持性能相当。

Conclusion: MCGI通过几何感知的索引设计有效解决了高维ANN搜索中的流形不一致问题，理论分析证实了其改进的近似保证，实验结果表明其在保持低维性能的同时显著提升了高维场景下的搜索效率。

Abstract: Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\times$ higher throughput at 95\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\times$, while maintaining performance parity on standard lower-dimensional datasets.

</details>


### [275] [Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations](https://arxiv.org/abs/2601.01997)
*Dario Di Palma,Giovanni Maria Biancofiore,Vito Walter Anelli,Fedelucio Narducci,Tommaso Di Noia*

Main category: cs.IR

TL;DR: 研究评估ChatGPT-3.5和ChatGPT-4在推荐系统中的多样性、新颖性和流行度偏差表现，发现在冷启动场景中表现优异


<details>
  <summary>Details</summary>
Motivation: 虽然ChatGPT在推荐系统中的应用受到关注，但对其在多样性、新颖性和流行度偏差等多维度性能的全面分析仍缺乏，需要理解这些方面以提升用户满意度和实现长期个性化

Method: 评估ChatGPT-3.5和ChatGPT-4在三个不同数据集上的表现，分析其在Top-N推荐和冷启动场景中的性能，重点关注多样性、新颖性和流行度偏差三个维度

Result: ChatGPT-4匹配或超越传统推荐系统，能够在推荐中平衡新颖性和多样性；在冷启动场景中，ChatGPT模型在准确性和新颖性方面都表现出色，特别适合新用户

Conclusion: 研究揭示了ChatGPT推荐的优势和局限性，为理解这些模型在超越准确性指标方面的推荐能力提供了新视角，特别是在冷启动场景中具有显著优势

Abstract: ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.
  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.

</details>


### [276] [Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models](https://arxiv.org/abs/2601.02002)
*Antonio Colacicco,Vito Guida,Dario Di Palma,Fedelucio Narducci,Tommaso Di Noia*

Main category: cs.IR

TL;DR: 本文研究如何自动检测和提取大型语言模型中记忆的数据，评估了三种方法：越狱提示工程、无监督潜在知识发现和自动提示工程，发现自动优化提示是最有前景的策略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推荐场景中应用日益广泛，但其训练数据不公开，存在数据泄露风险。先前研究表明MovieLens-1M数据集被LLaMA和OpenAI模型记忆，但提取这些记忆数据目前仅依赖手动提示工程。本文旨在探索是否可以通过更先进的方法增强数据泄露检测和提取。

Method: 评估了三种方法：(1) 越狱提示工程；(2) 无监督潜在知识发现，通过对比一致搜索(CCS)和聚类范数探测内部激活；(3) 自动提示工程(APE)，将提示发现构建为元学习过程，迭代优化候选指令。在LLaMA模型上使用MovieLens-1M数据集进行实验。

Result: 实验结果表明：越狱提示未能改善记忆项目的检索且结果不一致；CCS能可靠区分真实与伪造的电影标题，但对数值用户和评分数据无效；APE在项目级信息检索方面取得中等成功，但在恢复数值交互方面存在困难。

Conclusion: 自动优化提示是提取记忆样本最有前景的策略，但当前方法在数值数据提取方面仍面临挑战，需要进一步研究改进自动提示工程技术。

Abstract: Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.

</details>


### [277] [Cold-Starting Podcast Ads and Promotions with Multi-Task Learning on Spotify](https://arxiv.org/abs/2601.02306)
*Shivam Verma,Hannes Karlbom,Yu Zhao,Nick Topping,Vivian Chen,Kieran Stanley,Bharath Rengarajan*

Main category: cs.IR

TL;DR: Spotify提出统一多目标模型，同时优化广告和推广活动，通过迁移学习和多任务学习解决个性化与冷启动问题，显著降低成本和提升流媒体率。


<details>
  <summary>Details</summary>
Motivation: 解决播客生态系统中广告和推广活动的个性化与冷启动初始化挑战，特别是针对新的广告目标，打破历史上孤立的定向管道，提高系统可维护性和性能。

Method: 采用多任务学习框架，利用大规模广告和内容交互进行迁移学习，构建共享用户、内容、上下文和创意特征的统一表示，联合优化广告和推广的流媒体、点击和关注等多项目标。

Result: 在线A/B测试显示有效每流成本降低22%（特别是较少流媒体的播客），播客流媒体率提升18-24%；离线实验和消融研究验证了辅助目标和特征组对冷启动性能的贡献。

Conclusion: 统一建模策略提高了可维护性、冷启动性能和覆盖率，打破了孤立的定向管道，讨论了实际广告系统中联合模型的实用权衡。

Abstract: We present a unified multi-objective model for targeting both advertisements and promotions within the Spotify podcast ecosystem. Our approach addresses key challenges in personalization and cold-start initialization, particularly for new advertising objectives. By leveraging transfer learning from large-scale ad and content interactions within a multi-task learning (MTL) framework, a single joint model can be fine-tuned or directly applied to new or low-data targeting tasks, including in-app promotions. This multi-objective design jointly optimizes podcast outcomes such as streams, clicks, and follows for both ads and promotions using a shared representation over user, content, context, and creative features, effectively supporting diverse business goals while improving user experience. Online A/B tests show up to a 22% reduction in effective Cost-Per-Stream (eCPS), particularly for less-streamed podcasts, and an 18-24% increase in podcast stream rates. Offline experiments and ablations highlight the contribution of ancillary objectives and feature groups to cold-start performance. Our experience shows that a unified modeling strategy improves maintainability, cold-start performance, and coverage, while breaking down historically siloed targeting pipelines. We discuss practical trade-offs of such joint models in a real-world advertising system.

</details>
