<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 64]
- [cs.CY](#cs.CY) [Total: 5]
- [cs.LG](#cs.LG) [Total: 51]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.IR](#cs.IR) [Total: 16]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: ASOS是一个包含50种常见超市商品的3D纹理网格数据集，专为机器人和计算机视觉基准测试设计，具有高可访问性和实用性


<details>
  <summary>Details</summary>
Motivation: 现有数据集多依赖合成模型或难以获取的专业物品，缺乏真实世界应用的实用性和可访问性，需要成本效益高且易于获取的真实物品数据集

Method: 采用运动恢复结构技术，通过高分辨率成像采集10个不同类别的超市商品，生成水密3D网格模型

Result: 创建了包含50种常见超市物品的高质量3D纹理网格数据集，涵盖多样形状、尺寸和重量，所有物品均可从澳大利亚主要超市连锁店轻松获取

Conclusion: ASOS数据集以其可访问性、成本效益和真实世界适用性，为物体检测、姿态估计和机器人应用提供了有价值的基准测试资源

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [2] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态检索增强生成框架(MM-RAG)，用于自然灾害后房屋损坏评估，通过双分支编码器和跨模态交互模块实现图像和文本的语义对齐，在检索准确率和损坏严重程度分类指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 自然灾害后准确评估房屋损坏对于保险理赔和资源规划至关重要，需要结合图像和文本信息进行综合分析。

Method: 基于经典RAG架构设计双分支多模态编码器：图像分支使用ResNet和Transformer提取建筑损坏特征，文本分支使用BERT检索器处理文本向量化；集成跨模态交互模块通过多头注意力实现语义对齐；引入模态注意力门控机制动态控制生成过程中的视觉证据和文本先验信息作用。

Result: 在检索准确率和损坏严重程度分类指标上表现优异，Top-1检索准确率提高了9.6%。

Conclusion: 该MM-RAG框架通过端到端训练和多任务优化目标，成功实现了图像理解和政策匹配的协同学习，为灾后房屋损坏评估提供了有效的多模态解决方案。

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [3] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: 提出了一种基于LLM的集成框架，通过多图像增强变体和Needleman-Wunsch对齐器来提高历史文档转录准确性，在宾夕法尼亚死亡记录数据集上比单次转录基线提升4个百分点。


<details>
  <summary>Details</summary>
Motivation: 解决嘈杂历史文档中基于LLM的文本提取不稳定问题，需要一种能够提高转录准确性并提供置信度评估的方法。

Method: 使用Gemini 2.0 Flash对每个图像的多个增强变体进行转录，然后通过自定义的Needleman-Wunsch风格对齐器融合输出，生成共识转录和置信度分数。

Result: 在622份宾夕法尼亚死亡记录数据集上，该方法比单次转录基线准确率提高4个百分点；填充和模糊处理对提升准确性最有效，网格扭曲扰动最适合区分高置信度和低置信度情况。

Conclusion: 该方法简单、可扩展，可立即部署到其他文档集合和转录模型，为历史文档转录提供了有效的解决方案。

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [4] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: 本文介绍了MITS——首个专门为智能交通监控(ITS)设计的大规模多模态基准数据集，包含17.04万张真实ITS图像和500万条指令跟随问答对，显著提升了主流多模态模型在ITS任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 通用领域大型多模态模型在图像-文本任务上取得显著进展，但在智能交通监控领域表现有限，主要原因是缺乏专门的多模态数据集。

Method: 构建MITS数据集，包含17.04万张真实ITS图像，标注8个主要类别和24个子类别的ITS对象和事件；通过系统化数据生成流程创建高质量图像描述和500万条指令跟随问答对，涵盖5个关键ITS任务。

Result: 在MITS数据集上微调主流多模态模型，性能显著提升：LLaVA-1.5从0.494提升至0.905(+83.2%)，LLaVA-1.6从0.678提升至0.921(+35.8%)，Qwen2-VL从0.584提升至0.926(+58.6%)，Qwen2.5-VL从0.732提升至0.930(+27.0%)。

Conclusion: MITS数据集有效解决了ITS领域多模态数据缺失问题，显著提升了多模态模型在智能交通监控应用中的性能，为ITS和LMM研究提供了高价值资源。

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [5] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: 本文研究了结构化树推理是否能提升视觉语言模型在细粒度分类任务中的性能，发现尽管模型能很好理解树知识，但树推理方法始终不如标准零样本提示，图像描述能提升两种方法的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在零样本视觉分类方面表现出色，但在细粒度任务和大规模层次标签空间中的性能研究不足，需要探索结构化推理是否能提升性能。

Method: 引入基于决策树的框架，将分类分解为可解释的决策，在细粒度(GTSRB)和粗粒度(CIFAR-10)数据集上评估，并探索使用LLM生成的类别和图像描述来增强树提示。

Result: 模型在理解树知识方面达到98.2%准确率，但树推理方法始终不如标准零样本提示。添加图像描述能提升树推理和零样本方法的性能。

Conclusion: 结构化推理在视觉分类中存在局限性，研究结果为设计更可解释的VLM系统提供了见解。

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [6] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI是一个从数据中学习可控制、可提示的世界模型的系统，通过三步循环构建概率图模型，提取底层结构并整合回训练过程，在视频数据上实现了优秀的预测和理解能力。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够从数据中学习丰富可控性和灵活提示性的世界模型系统，通过概率建模和结构提取来更好地理解和预测复杂数据。

Method: 三步循环方法：1)概率预测-构建随机访问自回归序列模型；2)结构提取-通过因果推断零样本提取低维属性；3)整合-将结构转换为新token类型并反馈到训练中。

Result: 在1.4万亿token的视频数据上训练PSI实例，实现了优秀的视频预测和理解推理，提取了最先进的光流、自监督深度和对象分割，支持完整的预测改进循环。

Conclusion: PSI系统通过循环增强的方法有效提升了世界模型的建模能力和控制能力，为构建类似LLM的通用提示语言提供了有效途径。

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [7] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: 本文首次分析了联邦学习中视频数据的梯度反演攻击风险，发现特征提取器能提供更好的保护，但攻击者仍可通过超分辨率技术重建高质量视频。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的核心隐私保护原则是通过交换模型更新而非原始数据来保护隐私，但梯度反演攻击威胁到这一机制。虽然图像、文本和表格数据的攻击影响已知，但视频数据的安全性尚未被研究。

Method: 评估两种视频分类方法：使用预训练特征提取器的方法和处理原始视频帧的简单变换方法。测试在不同攻击场景下（零个、一个或多个参考帧）的梯度反演攻击效果，并应用图像超分辨率技术提升重建质量。

Result: 特征提取器对梯度反演攻击具有更强的抵抗力，但分类器复杂度不足时仍可能发生数据泄露。超分辨率技术能显著提升攻击者重建视频的质量。

Conclusion: 视频数据在联邦学习中存在可行的泄露威胁，需要进一步研究其发生条件和防护措施。

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [8] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: 一种半监督协同训练框架，结合Faster R-CNN和YOLO优势，通过伪标签交换和集成学习提升突出环境中的物体检测精度，降低标签成本。


<details>
  <summary>Details</summary>
Motivation: 解决密集零售环境中标签数据有限、遮捏重叠复杂等挑战，减少手动标注成本，适应零题商品和布局变化。

Method: 使用Faster R-CNN(ResNet背景)进行精确定位，YOLO(Darknet背景)获取全局上下文，通过伪标签互换提升性能。采用XGBoost、Random Forest和SVM集成分类器，使用元神经算法优化超参数。

Result: 在SKU-110k数据集上表现优异，显示了框架的可扩展性和实用性，适用于自动化库存跟踪、产品监控和结账系统。

Conclusion: 该半监督协同训练框架能够有效处理密集零售环境中的物体检测挑战，大幅减少对手动标注的依赖，具有良好的实际应用前景。

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [9] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出了Token Purging (PG)，一种无需反向传播的测试时自适应方法，通过移除受域偏移影响严重的token来提升3D点云分类性能，具有高效和内存友好的特点。


<details>
  <summary>Details</summary>
Motivation: 解决3D点云分类中因分布偏移导致的性能下降问题，现有测试时自适应方法需要迭代更新且计算成本高。

Method: 提出Token Purging方法，在token级别操作，在attention层之前移除受域偏移影响的token。包含两个变体：PG-SP（利用源统计信息）和PG-SF（完全无源的CLS-token驱动自适应）。

Result: 在ModelNet40-C、ShapeNet-C和ScanObjectNN-C数据集上，PG-SP比最先进的无反向传播方法平均准确率高10.3%，PG-SF在无源自适应方面创下新基准。PG比基线快12.4倍，内存效率高5.5倍。

Conclusion: Token Purging是一种高效、内存友好的测试时自适应方法，无需反向传播即可有效处理3D点云分类中的域偏移问题，适合实际部署。

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [10] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出了一种准确且高度可解释的跨视角细粒度定位方法，通过匹配地面图像与参考航拍图像的局部特征来估计3自由度姿态，避免了传统BEV转换的信息损失问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法将地面图像转换为鸟瞰图(BEV)表示再与航拍图像对齐，这种转换常因透视畸变或高度信息压缩导致信息丢失，降低对齐质量。

Method: 直接在原始图像间建立对应关系，仅将匹配的关键点使用单目深度先验提升到BEV空间，支持度量深度和相对深度，采用尺度感知的Procrustes对齐来估计相机姿态。

Result: 实验表明，仅需弱监督的相机姿态，该方法就能学习准确的局部特征对应，在跨区域泛化和未知方向等挑战性条件下实现优越的定位性能，且兼容多种相对深度模型无需微调。

Conclusion: 该方法具有灵活性、强定位性能和实际部署适用性，为跨视角定位提供了有效的解决方案。

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [11] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: 开发基于智能手机的儿童视力筛查应用KidsVisionCheck，使用红眼反射图像和深度学习模型，准确率达90%，无需专业设备


<details>
  <summary>Details</summary>
Motivation: 利用智能手机和AI技术重现布鲁克纳测试，实现儿童视力异常的可及性早期筛查和干预

Method: 基于眼科医生收集标注的儿童瞳孔图像，训练深度神经网络模型

Result: 在未见测试数据上达到90%的准确率，能够识别最佳数据收集条件并提供即时用户反馈

Conclusion: 这是实现全球可及性儿童视力筛查和早期干预的重要第一步

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [12] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: 提出了一种深度引导的多模态融合方法DGFusion，通过集成深度信息来改进自动驾驶中的语义感知性能，在挑战性条件下实现了最先进的分割效果。


<details>
  <summary>Details</summary>
Motivation: 现有的传感器融合方法在处理空间输入时通常采用统一处理方式，在挑战性条件下性能受限。需要一种能够根据空间变化条件动态调整传感器融合的方法。

Method: 提出DGFusion网络，将多模态分割作为多任务问题处理，利用激光雷达测量作为输入和深度学习真值。通过辅助深度头学习深度感知特征，编码为空间变化的局部深度标记，与全局条件标记一起动态调整传感器融合。

Result: 在具有挑战性的MUSES和DELIVER数据集上实现了最先进的全景和语义分割性能。

Conclusion: 深度引导的融合方法能够有效适应传感器在不同空间位置的可信度变化，显著提升了自动驾驶语义感知的鲁棒性。

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [13] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 基于ResNet-18深度学习框架的斑块式自动玫瑰痤疮检测策略，通过提取面部不同区域图像斑块，在保持准确性的同时保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 玫瑰痤疮是一种慢性炎症性皮肤病，需要精确早期检测以提高治疗效果。传统全图像方法存在隐私泄露风险，需要开发既能保持检测性能又能保护隐私的新方法。

Method: 使用ResNet-18深度学习框架，从面部图像中提取不同大小、形状和位置的各种图像斑块，评估局部视觉信息对模型性能的影响，并与全图像方法进行对比实验。

Result: 提出的斑块式策略在准确性和敏感性方面达到或优于全图像方法，同时通过排除可识别面部特征来保护患者隐私，增强了模型的鲁棒性和可解释性。

Conclusion: 斑块式自动检测策略能够引导深度学习模型关注临床相关区域，在保持检测性能的同时保护患者隐私，为改进自动化皮肤病诊断提供了实用见解。

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [14] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 一种基于合成数据和临床先验知识的隐私保护自动苹果痘检测方法，通过红色区域掩码重点关注面部中央红痘特征，在保护病人隐私的同时提高了识别准确性。


<details>
  <summary>Details</summary>
Motivation: 苹果痘作为一种常见但识别困难的皮肤疾病，自动检测面临病理特征散布、标签数据稀缺以及面部图像隐私漏泉等挑战。需要开发既能保护病人隐私又能准确识别病情的方法。

Method: 首先构建固定的红色信息掩码，选择面部图像中红色通道强度持续较高的区域（如脸颈、鼻子、额头），排除可识别个人特征的区域。然后使用ResNet-18深度学习模型，仅在掩码后的合成图像上进行训练。

Result: 在真实世界测试数据上，该方法在准确率、召回率和F1分数方面都显著超过了全面部基线方法，展现出更优异的性能。

Conclusion: 结合合成数据和临床先验知识可以共同实现准确且符合道德规范的皮肤科AI系统，尤其适用于远程医疗和大规模筛查等隐私敏感的应用场景。

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [15] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文对ULW腹腔镜图像去烟框架进行了全面的消融研究，评估了可学习维纳滤波器模块和复合损失函数中各损失项的具体贡献。


<details>
  <summary>Details</summary>
Motivation: 为了严格评估ULW框架中各个组件的有效性和必要性，需要系统性地分析每个组件对整体性能的具体贡献。

Method: 采用消融研究方法：1) 移除可学习维纳滤波器模块；2) 选择性使用复合损失函数中的各个损失项（MSE、SSIM损失、感知损失）。在公开的配对腹腔镜图像数据集上进行基准测试。

Result: 使用定量指标（SSIM、PSNR、MSE、CIEDE-2000）和定性视觉比较对所有变体进行评估，以确定各组件的重要性。

Conclusion: 通过系统的消融分析，明确了ULW框架中各个组件的作用和必要性，为腹腔镜图像去烟技术的优化提供了重要参考。

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [16] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: WAVE-DETR是一个结合可见光RGB和声音信号的多模态无人机检测器，采用Deformable DETR和Wav2Vec2架构，在挑战性环境条件下实现强性能表现。


<details>
  <summary>Details</summary>
Motivation: 为了解决在复杂环境条件下无人机检测的鲁棒性问题，利用多模态信息（视觉和声音）来提升检测性能。

Method: 基于Deformable DETR和Wav2Vec2架构，开发了四种不同的融合配置（门控机制、线性层、MLP和交叉注意力），将声音嵌入与多分辨率特征映射融合。

Result: 最佳的门控融合方法在ARDrone数据集上将Deformable DETR检测器的mAP提升了11.1%到15.3%（小型无人机），所有尺寸无人机的整体增益达到3.27%到5.84%。

Conclusion: 多模态融合（特别是声音信息）显著提升了无人机检测性能，门控融合是最有效的融合策略，在室内外分布数据集上都表现出色。

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [17] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: 提出了一种名为"代理监督"的新训练范式，通过将估计的空间变换应用于代理图像，将输入域与监督域解耦，从而在异质输入上训练配准网络，同时确保在相似性定义良好的域中进行监督计算。


<details>
  <summary>Details</summary>
Motivation: 深度学习形变图像配准虽然精度高，但对输入图像特征变化（如伪影、视野不匹配、模态差异）敏感，需要提高配准网络的鲁棒性和泛化性。

Method: 引入代理监督框架，将输入域与监督域解耦，通过将估计的空间变换应用于代理图像来训练网络，在三个代表性应用中进行评估：抗伪影脑MR配准、掩码无关肺CT配准和多模态MR配准。

Result: 在所有任务中，代理监督表现出对输入变化的强韧性，包括不均匀场、不一致视野和模态差异，同时在良好整理的数据上保持高性能。

Conclusion: 代理监督提供了一个原则性框架，在不增加复杂性的情况下训练鲁棒且可泛化的深度学习配准模型，为医学图像配准在多样化生物医学成像场景中的更广泛应用提供了实用途径。

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [18] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 该研究提出了一个结合卷积自编码器和Vision Transformer的框架，用于提高牙齿年龄估计的性能和可解释性，特别是在下颌第二和第三磨牙的分类任务上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 深度学习在法医年龄估计等高风险应用中的实际采用受到模型'黑盒'性质的限制，需要同时提高性能和透明度。

Method: 使用卷积自编码器(AE)与Vision Transformer(ViT)相结合的框架，通过分析AE的潜在空间度量和图像重建来提供多方面的诊断洞察。

Result: 分类准确率显著提升：牙齿37从0.712提高到0.815，牙齿38从0.462提高到0.543。分析表明剩余性能差距主要是数据中心的，特别是牙齿38数据集的高类内形态变异性。

Conclusion: 该框架不仅提高了准确性，还提供了模型不确定性原因的证据，强调了依赖单一可解释性模式（如注意力图）的不足，为法医年龄估计专家决策提供了更强大的工具。

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [19] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: SCoDA是一种无需源域数据的自监督持续域适应方法，通过几何流形对齐和空间相似性损失，在自监督预训练基础上实现更好的目标域适应性能


<details>
  <summary>Details</summary>
Motivation: 现有SFDA方法依赖全监督预训练源模型，使用余弦相似度对齐实例级特征时会丢失源模型潜在流形的关键几何信息

Method: 使用自监督预训练的教师模型初始化框架，采用几何流形对齐原则，结合实例级特征匹配和空间相似性损失的复合目标训练学生模型，通过EMA更新教师参数防止灾难性遗忘

Result: 在基准数据集上的广泛实验表明，SCoDA显著优于最先进的SFDA方法

Conclusion: 自监督预训练结合几何流形对齐的持续域适应框架能够有效解决SFDA问题，在无需源域数据的情况下实现优异的性能

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [20] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: 提出了一种基于SAM2基础模型的零样本细胞追踪框架，无需训练数据即可在2D和3D显微视频中实现竞争性精度的细胞追踪和有丝分裂检测


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖昂贵的人工标注数据集训练，且泛化能力有限，难以应对显微数据的巨大多样性

Method: 将Segment Anything 2 (SAM2)大型基础模型集成到追踪流程中，构建完全无监督的零样本细胞追踪框架

Result: 在2D和大规模3D延时显微视频中达到竞争性精度，无需数据集特定适配

Conclusion: 该方法消除了对训练数据的依赖，能够泛化到不同的显微数据集，为细胞追踪提供了有效的零样本解决方案

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [21] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: 本文提出了一种将现有2D多摄像头跟踪系统扩展到3D空间的方法，通过深度信息重建目标点云并优化3D框，在AI City Challenge 2025中获得第三名


<details>
  <summary>Details</summary>
Motivation: 现有的MTMC系统需要完全重构才能实现3D跟踪，这在实际应用中不可行。本文旨在利用深度信息将现有2D跟踪系统扩展到3D空间，避免重新构建整个系统

Method: 1) 利用深度信息在点云空间重建目标 2) 通过聚类和偏航角优化恢复3D边界框 3) 引入增强的在线数据关联机制，利用目标局部ID一致性分配全局ID

Result: 在2025 AI City Challenge的3D MTMC数据集上评估，获得排行榜第三名的成绩

Conclusion: 该方法成功实现了将现有2D多摄像头跟踪系统扩展到3D空间，无需完全重构系统，为大规模监控系统的3D感知提供了可行方案

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [22] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: 本文提出了一种零样本的指代表达理解方法，通过将REC重新定义为框级视觉语言验证任务，使用通用检测器和VLM进行True/False查询，无需特定训练即可达到竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 传统的REC方法需要任务特定的训练，本文旨在探索零样本工作流是否能够在不进行REC特定训练的情况下实现竞争性性能，减少跨框干扰并支持弃权和多重匹配。

Method: 使用COCO-clean通用检测器(YOLO-World)生成候选框，然后通过通用VLM对每个区域独立进行True/False查询的视觉语言验证，无需微调。

Result: 在RefCOCO、RefCOCO+和RefCOCOg数据集上，该方法不仅超越了零样本GroundingDINO基线，还超过了经过REC训练的GroundingDINO和GroundingDINO+CRG的报告结果。

Conclusion: 工作流设计而非任务特定的预训练是驱动强零样本REC性能的关键因素，验证式方法显著优于基于选择的提示方法。

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [23] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: 提出RPCP数据增强方法解决小麦病虫害图像分割中的极端像素不平衡问题，通过随机投影复制粘贴技术有效提升罕见类别的分割性能


<details>
  <summary>Details</summary>
Motivation: 小麦叶片病虫害分割中，虫害区域像素占比极低，导致严重的像素级不平衡问题，造成模型对常见类别过拟合而对罕见类别学习不足

Method: RPCP增强技术：从标注图像提取罕见虫害区域，应用随机几何变换模拟变化，粘贴到合适区域避免重叠，并使用随机投影滤波器优化局部特征使其与背景自然融合

Result: 实验表明该方法显著提升了虫害类别的分割性能，同时保持甚至略微提升了其他类别的准确率

Conclusion: 目标导向的数据增强能有效缓解极端像素不平衡问题，为农业图像分割提供了简单而有效的解决方案

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [24] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 提出了一种基于隐马尔可夫模型(HMM)的新框架，通过结合不确定身份信息和跟踪来解决长期多目标跟踪中的身份切换问题，在牲畜养殖等实际应用中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有多目标跟踪方法在长时间视频中由于身份切换问题导致性能下降，难以满足长期跟踪需求。但在实际应用（如畜牧业）中，可以从喂食器等来源获得部分对象的偶发身份信息。

Method: 使用隐马尔可夫模型(HMM)框架，将不确定的身份信息与跟踪过程相结合，有效处理长期跟踪中的身份不确定性。

Result: 在10分钟的猪只跟踪数据集上，即使只有21次喂食站的身份识别，该方法仍能提高ByteTrack的F1分数。在MOT17和MOT20基准数据集上也验证了其有效性，且对身份识别的不确定性具有鲁棒性。

Conclusion: 该HMM框架能够有效利用偶发的身份信息来改善长期多目标跟踪性能，特别适用于畜牧业等可以获取部分身份信息的实际应用场景。

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [25] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: 本综述论文系统回顾了事件相机与传统帧相机融合在视频恢复和3D重建任务中的最新进展，重点分析了深度学习在时空增强方面的应用，并整理了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 事件相机作为新兴的生物启发式传感器，具有低延迟、低功耗和高捕获率等优势，但其与传统帧相机的融合技术需要系统性的总结和梳理，以推动该领域进一步发展。

Method: 采用系统性文献综述方法，从两个维度进行分析：时间增强（帧插值、运动去模糊等）和空间增强（超分辨率、低光照增强、HDR增强等），同时探讨3D重建领域的进展。

Result: 全面总结了事件相机融合技术在视频恢复和3D重建方面的最新研究成果，整理了公开可用的数据集资源，为该领域的可重复研究和基准测试提供了重要参考。

Conclusion: 事件相机与传统帧相机的融合技术为视觉媒体恢复和增强提供了新的机遇，特别是在结合深度学习技术后，在挑战性条件下显著提升了视觉质量，未来有望在该领域激发更多创新研究。

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [26] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: ISTASTrack是首个基于Transformer的ANN-SNN混合跟踪器，通过ISTA适配器实现RGB和事件数据的双向特征交互，在多个RGB-Event跟踪基准上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人工神经网络难以充分利用事件流的稀疏和异步特性，而混合ANN-SNN架构在特征融合方面仍面临挑战，需要更有效的跨范式特征交互方法。

Method: 采用双分支架构：视觉Transformer处理RGB输入，脉冲Transformer处理事件流；设计基于稀疏表示理论的ISTA适配器进行双向特征交互；引入时序下采样注意力模块对齐不同时间步的特征。

Result: 在FE240hz、VisEvent、COESOT和FELT等基准测试中实现了最先进的性能，同时保持了高能效。

Conclusion: ISTASTrack证明了混合ANN-SNN设计在鲁棒视觉跟踪中的有效性和实用性，为跨模态特征融合提供了新思路。

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [27] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 提出基于多深度状态空间模型和FLARE损失函数的太阳耀斑预测方法，解决类别不平衡问题，在多个标准指标上优于基线方法


<details>
  <summary>Details</summary>
Motivation: 当前太阳耀斑预测性能不足，特别是对严重类别不平衡问题处理不够，需要更准确可靠的预测方法来保护关键基础设施

Method: 使用多深度状态空间模型构建预测框架，引入频率和局部边界感知可靠性损失（FLARE损失）来处理类别不平衡问题

Result: 在覆盖11年太阳活动周期的多波长太阳图像数据集上实验，在Gandin-Murphy-Gerrity评分和真实技能统计等标准指标上优于基线方法

Conclusion: 所提出的方法能有效提升太阳耀斑预测的性能和可靠性，特别是在处理类别不平衡方面表现出色

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [28] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: TUNI是一个用于RGB-热成像语义分割的统一编码器模型，通过多模态特征提取和跨模态融合的统一架构，实现了更紧凑的结构和实时性能


<details>
  <summary>Details</summary>
Motivation: 解决现有RGB-T语义分割模型热特征提取有限、跨模态融合效果不佳以及编码器冗余导致的实时效率低下的问题

Method: 提出包含多个堆叠块的RGB-T编码器，同时执行多模态特征提取和跨模态融合；利用RGB和伪热数据进行大规模预训练；通过精简热分支实现更紧凑架构；引入RGB-T局部模块使用自适应余弦相似度选择性地强调跨模态的显著一致和不同局部特征

Result: 在FMB、PST900和CART数据集上达到与最先进模型竞争的性能，参数量更少、计算成本更低；在Jetson Orin NX上实现27 FPS的推理速度

Conclusion: TUNI通过统一的编码器架构有效解决了RGB-T语义分割中的特征提取和融合问题，在保持高性能的同时显著提升了模型的实时部署能力

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [29] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出了一种基于部分设计元素的少部件字体生成模型，只需输入部分形状而非完整字符即可生成整个字体


<details>
  <summary>Details</summary>
Motivation: 传统少样本字体生成需要完整字符形状，而本方法旨在通过部分设计元素提高字体创建效率并探索局部设计细节对整体字符结构的影响

Method: 设计了一个新颖的少部件字体生成模型，以部分形状作为输入来生成整个字体

Result: 该方法不仅提高了字体创建效率，还揭示了局部设计细节如何影响单个字符的整体结构

Conclusion: 该模型为字体设计提供了一种更高效的基于部分元素的方法，并深化了对设计细节与整体结构关系的理解

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [30] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: 本文提出了一种针对微型和纳米无人机优化的高效视觉惯性里程计(VIO)管道，在超低功耗RISC-V SoC上实现了实时性能，相比基线方法RMSE降低了3.65倍


<details>
  <summary>Details</summary>
Motivation: 传统高精度VIO管道需要强大计算系统，而微控制器上的轻量级实现精度不足，需要在超低功耗平台上实现高精度实时VIO

Method: 采用SuperPoint、PX4FLOW、ORB等先进特征检测跟踪方法，进行优化和量化，结合刚体运动模型减少估计误差，在RISC-V超低功耗SoC上实现

Result: 在GAP9低功耗SoC上，使用ORB特征跟踪器时RMSE平均降低3.65倍，PX4FLOW在低于24像素/帧速度下达到与ORB相当的跟踪精度且运行时间更短

Conclusion: 该设计成功弥合了高精度VIO管道与轻量级实现之间的差距，为微型无人机提供了在超低功耗平台上运行的准确实时VIO解决方案

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [31] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: 提出基于卷积神经网络的层次化多级注意力网络(MLANet)，从单张野外图像重建3D人脸模型，预测几何、纹理、姿态和光照参数


<details>
  <summary>Details</summary>
Motivation: 解决从2D野外图像恢复3D人脸模型的挑战，包括缺乏标注数据和复杂真实环境的问题

Method: 使用预训练层次化主干网络，引入多级注意力机制，采用半监督训练策略结合3DMM参数和可微分渲染器

Result: 在AFLW2000-3D和MICC Florence基准数据集上进行实验，在3D人脸重建和对齐任务上取得良好效果

Conclusion: 提出的MLANet方法能有效从单张野外图像重建高质量的3D人脸模型，具有实际应用价值

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [32] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: LaV-CoT是一个语言感知的视觉思维链框架，通过多阶段推理流程和多方面奖励优化，显著提升多语言视觉问答性能，在多个基准测试中超越开源和专有模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖文本思维链，对多语言多模态推理支持有限，限制了在实际应用中的部署。需要开发能够同时处理多语言和视觉信息的推理框架。

Method: 采用多阶段推理流程（文本摘要+边界框、语言识别、空间对象级描述、逐步逻辑推理），通过自动化数据标注生成多语言CoT注释，结合监督微调和语言感知组相对策略优化进行两阶段训练。

Result: 在MMMB、Multilingual MMBench和MTVQA等数据集上，比相似规模的开源基线准确率提升约9.5%，甚至超越规模大2倍的模型约2.6%，优于GPT-4o-0513和Gemini-2.5-flash等专有模型。

Conclusion: LaV-CoT框架通过语言感知的视觉思维链和多方面奖励优化，有效提升了多语言视觉问答的性能和可解释性，在实际工业部署中表现出色。

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [33] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 提出无需训练的框架，利用大语言模型解析模糊颜色描述并直接在文本嵌入空间指导颜色混合，提升文本到图像生成中的颜色准确性


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在处理复杂颜色术语时存在颜色对齐问题，无法准确理解如Tiffany蓝、柠檬绿等模糊颜色描述，影响时尚、产品可视化等应用

Method: 使用大语言模型解析文本提示中的模糊颜色术语，基于CIELAB色彩空间中的空间关系精炼文本嵌入，直接在嵌入空间指导颜色混合操作

Result: 实验结果表明该方法在不影响图像质量的情况下显著改善了颜色对齐效果，弥合了文本语义与视觉生成之间的差距

Conclusion: 该训练免费框架有效解决了文本到图像生成中的颜色模糊问题，无需额外训练或参考图像即可提升颜色保真度

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [34] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: AVI-Math是首个针对无人机航拍图像的多模态数学推理基准测试，包含3,773个高质量数学问题，涵盖几何、逻辑和代数等6个数学领域，评估显示当前视觉语言模型在数学推理方面存在显著局限性


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在无人机遥感任务的数学推理能力（如距离计算、轨迹估计、空间分析）尚未得到充分测试，需要专门的基准来评估这一领域

Method: 构建AVI-Math数据集，包含从不同高度和角度采集的无人机图像，涵盖6个数学科目和20个主题的3,773个问题，并对14个主流视觉语言模型进行全面评估，同时探索思维链提示和微调技术

Result: 尽管现有VLMs在之前的基准测试中表现良好，但在AVI-Math的推理任务中表现不佳，显示出数学推理能力的显著局限性

Conclusion: 研究揭示了当前VLMs在数学推理方面的不足，为未来研究提供了方向，思维链提示和微调技术显示出解决这些推理挑战的潜力，有助于推进无人机应用中可信赖VLMs的发展

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [35] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: BEVTraj是一个新颖的轨迹预测框架，直接在鸟瞰图空间利用实时传感器数据进行轨迹预测，无需依赖预建高清地图，通过可变形注意力和稀疏目标候选提议模块实现端到端预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预建高清地图或实时局部地图构建模块，但预建地图局限于特定区域且无法适应瞬时变化，局部地图构建可能遗漏关键场景细节或引入错误，影响预测性能。

Method: 提出BEVTraj框架，在BEV空间直接操作，使用可变形注意力从密集BEV特征中高效提取相关上下文，并引入稀疏目标候选提议(SGCP)模块实现完全端到端预测，无需后处理步骤。

Result: 大量实验表明，BEVTraj实现了与最先进HD地图模型相当的性能，同时通过消除对预建地图的依赖提供了更大的灵活性。

Conclusion: BEVTraj成功克服了现有地图依赖方法的局限性，为自动驾驶轨迹预测提供了更灵活有效的解决方案，代码已开源。

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [36] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: 提出了一种利用多视角信息改进多人解析模型在遮挡情况下性能的新训练框架，通过弱监督和一致性损失实现，在遮挡场景下相对基线模型提升4.20%


<details>
  <summary>Details</summary>
Motivation: 现有方法在公开数据集上表现良好，但在处理身体重叠的多人时效果显著下降，基于重叠人物从不同视角可能分离的直觉，需要改进遮挡情况下的解析性能

Method: 提出基于多视角信息的训练框架，包含弱监督人类实例标注和多视角一致性损失，采用半自动标注策略从多视角RGB+D数据和3D人体骨架生成实例分割掩码

Result: 实验证明该方法在遮挡场景下相比基线模型实现了4.20%的相对性能提升

Conclusion: 多视角信息能有效提升多人解析模型在遮挡情况下的性能，提出的弱监督和一致性损失方法是有效的改进策略

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [37] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: VARCO-VISION-2.0是一个开源的韩英双语视觉语言模型，相比前代模型有显著提升，支持多图像理解、布局感知OCR，并通过四阶段课程训练实现更好的多模态对齐和安全性。


<details>
  <summary>Details</summary>
Motivation: 开发一个更强大的双语视觉语言模型，支持韩语和英语，提升多图像理解能力，特别是针对文档、图表和表格等复杂输入的处理，同时保持核心语言能力并提高安全性。

Method: 采用四阶段课程训练和内存高效技术，训练模型支持多图像理解、布局感知OCR（预测文本内容及其空间位置），并通过偏好优化提高安全性。

Result: 模型在空间定位和多语言基准测试中表现优异，14B版本在OpenCompass VLM排行榜上位列同规模模型第8名，同时还发布了1.7B轻量级版本用于设备端部署。

Conclusion: VARCO-VISION-2.0推动了双语视觉语言模型的发展，提供了从14B完整版到1.7B轻量版的不同选择，具有实际应用价值，模型已在Hugging Face发布。

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [38] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: 提出了一种轻量级的人脸图像质量评估方法，通过集成MobileNetV3-Small和ShuffleNetV2网络，使用平均融合和相关性感知损失函数，在保持高精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸图像质量评估方法要么无法捕捉人脸特有的退化特征，要么计算成本过高，限制了在实际应用中的部署。需要开发既准确又高效的FIQA方法。

Method: 集成两个紧凑卷积神经网络（MobileNetV3-Small和ShuffleNetV2），通过预测级平均融合，并使用结合MSE和Pearson相关正则化的相关性感知损失函数（MSECorrLoss）来更好地对齐人类感知判断。

Result: 在VQualA FIQA基准测试中取得了SRCC 0.9829和PLCC 0.9894的优异性能，同时满足计算效率约束。

Conclusion: 该方法在准确性和计算成本之间实现了良好平衡，适合在实际应用中部署，为人脸识别系统提供了高效可靠的质量评估解决方案。

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [39] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: 提出了RCOD框架，通过潜在域分组策略和退化感知采样，在单步扩散模型中实现保真度与真实感的灵活权衡控制


<details>
  <summary>Details</summary>
Motivation: 单步扩散方法虽然提高了效率，但缺乏多步方法中通过调整采样步骤来平衡保真度和真实感的灵活控制机制

Method: 使用潜在域分组策略实现噪声预测阶段的显式控制，引入退化感知采样策略对齐蒸馏正则化，采用视觉提示注入模块替代文本提示

Result: 在定量指标和视觉质量上均优于最先进的单步扩散方法，同时保持计算效率

Conclusion: RCOD框架成功解决了单步扩散模型在真实图像超分辨率任务中保真度与真实感权衡控制的难题

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [40] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: Grad-CL是一种无需源数据的域自适应框架，通过梯度引导的伪标签优化和对比学习策略，在眼底图像分割中实现跨域性能提升


<details>
  <summary>Details</summary>
Motivation: 解决眼底图像分割模型在不同成像协议或条件下性能显著下降的问题，特别是在无法访问原始源数据的情况下实现鲁棒的自适应

Method: 采用两阶段方法：第一阶段通过梯度机制提取类别特征，进行不确定性量化和原型估计来优化伪标签；第二阶段使用基于余弦相似度的对比损失来增强视杯和视盘类别间的分离性

Result: 在具有挑战性的跨域眼底成像数据集上，Grad-CL超越了最先进的无监督和源无关域自适应方法，获得了优越的分割精度和改善的边界描绘

Conclusion: Grad-CL框架有效解决了眼底图像分割的域适应问题，无需源数据即可实现鲁棒的跨域性能，为眼科疾病早期诊断提供了可靠的技术支持

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [41] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: 这篇论文提出了VQBridge方法，解决了向量量化(VQ)训练中的不稳定性问题，实现了100%的码本使用率，并在图像生成任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决向量量化训练中的不稳定性问题，包括直通估计偏差、一步延迟更新和码本梯度稀疏等问题，这些问题导致了优化重建性能和低码本使用率。

Method: 提出VQBridge方法，通过基于map函数的投影器，构建了一个压缩-处理-恢复的流水线来优化码向量，结合学习逆逆变温技术，实现稳定有效的码本训练。

Result: 实现了100%码本使用率，甚至在262k大码本上也能绝绝对完整使用，达到了最优的重建性能，并且在LlamaGen中雄库中显著提升了图像生成性能，超越了VAR和DiT模型。

Conclusion: 高质量的切分器对于强大的自回归图像生成至关重要，VQBridge方法提供了一个稳定、可扩展且高效的解决方案，具有良好的普遍性和可扩展性。

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [42] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock是一种通过渐进层冻结实现从像素到潜在预测过渡的自监督视觉表示学习方法，能够加速MAE训练并避免表示崩溃问题


<details>
  <summary>Details</summary>
Motivation: 观察到在视频掩码自编码训练中，ViT层按深度顺序收敛（浅层早收敛，深层晚收敛），希望利用这一现象来加速训练并改进潜在预测方法

Method: 通过明确的进度表逐步冻结模型层，实现从像素预测到潜在预测的渐进过渡，避免表示崩溃

Result: 在高达40亿参数的大模型上应用LayerLock，在4DS感知套件上的结果超过了非潜在掩码预测方法

Conclusion: LayerLock提供了一种简单有效的自监督学习策略，通过层冻结进度表实现了训练加速和性能提升

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [43] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 本文系统比较了隐式和显式新视角合成方法在空间3D物体重建中的表现，发现外观嵌入能提升光度保真度但无法改善几何精度，凸面溅射比高斯溅射更适合安全关键应用


<details>
  <summary>Details</summary>
Motivation: 研究外观嵌入在空间机器人应用中3D重建的作用，特别是几何精度这一关键需求，比较不同方法在空间场景下的重建质量和表示效率

Method: 使用SPEED+数据集，比较K-Planes、高斯溅射和凸面溅射三种方法，分析外观嵌入对几何精度和表示效率的影响

Result: 外观嵌入主要减少显式方法所需基元数量而非提升几何保真度；凸面溅射比高斯溅射获得更紧凑、无杂乱的表示，更适合交互和碰撞避免等安全关键应用

Conclusion: 阐明了外观嵌入在几何中心任务中的局限性，强调了空间场景中重建质量与表示效率之间的权衡关系

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [44] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: GAMMA是一个新的AI生成图像检测框架，通过减少领域偏差和增强语义对齐来提升对未知生成模型的泛化能力，在GenImage基准上实现了5.8%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器主要依赖生成特定的伪影（如风格先验和压缩模式），导致对未见生成模型的泛化能力有限。

Method: 提出GAMMA训练框架，引入多样化操作策略（基于修复的操作和语义保持扰动），采用多任务监督（双分割头和分类头），并引入反向交叉注意力机制让分割头指导分类分支。

Result: 在GenImage基准上实现了最先进的泛化性能，准确率提升5.8%，并对新发布的GPT-4o等生成模型保持强鲁棒性。

Conclusion: GAMMA通过减少领域偏差和增强语义对齐，有效提升了AI生成图像检测器的泛化能力，为应对日益复杂的生成模型提供了有效解决方案。

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [45] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: 本研究比较了三种胎儿脑MRI超分辨率重建方法(NiftyMIC、SVRTK、NeSVoR)在140例扫描中的表现，包括健康对照和病理病例，评估了重建成功率、体积测量一致性和诊断分类性能。


<details>
  <summary>Details</summary>
Motivation: 胎儿脑MRI通常采用快速多视角2D切片采集以减少运动伪影，但这些堆栈分辨率低、可能受运动影响且无法充分捕捉3D解剖结构。现有超分辨率重建方法的比较性能，特别是在病理情况下的表现，以及对下游体积分析和诊断任务的影响尚未充分探索。

Method: 应用三种最先进的SRR方法(NiftyMIC、SVRTK、NeSVoR)处理140例胎儿脑MRI扫描，包括健康对照和脑室扩大病理病例。使用BoUNTi算法对每个高分辨率重建进行分割，提取九个主要脑结构的体积。评估视觉质量、SRR成功率、体积测量一致性和诊断分类性能。

Result: NeSVoR在健康对照组和病理组均表现出最高且最一致的重建成功率(>90%)。虽然不同SRR方法之间的体积估计存在显著差异，但脑室扩大的分类性能不受SRR方法选择的影响。

Conclusion: 研究结果突显了NeSVoR的鲁棒性，以及尽管SRR引起的体积变异性，诊断性能仍具有韧性。

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [46] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: 提出Mask Consistency Regularization (MCR)训练策略，通过扩张和重塑两种掩码扰动来解决图像修复中目标移除任务的掩码幻觉和掩码形状偏差问题。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在目标移除任务中存在两个关键挑战：掩码幻觉（在掩码区域内生成不相关内容）和掩码形状偏差（生成与掩码形状相似而非与周围内容匹配的对象）。

Method: 提出MCR训练策略，在训练过程中引入扩张和重塑两种掩码扰动，强制这些扰动分支的输出与原始掩码保持一致。扩张掩码帮助对齐模型输出与周围内容，重塑掩码鼓励模型打破掩码形状偏差。

Result: 实验证明MCR显著减少了幻觉和掩码形状偏差，在目标移除任务中实现了更好的性能。

Conclusion: MCR通过掩码一致性正则化策略有效解决了目标移除任务中的关键挑战，产生了更鲁棒和上下文连贯的图像修复结果。

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [47] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: MagicMirror是一个全面的文本到图像生成伪影评估框架，包含首个大规模人工标注数据集MagicData340K、基于VLM的MagicAssessor评估模型和自动化基准MagicBench，揭示了当前顶级T2I模型仍存在严重伪影问题。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成虽然在指令跟随和美学方面取得显著进展，但普遍存在解剖和结构缺陷等物理伪影，严重降低感知质量并限制应用。缺乏系统性和细粒度的评估框架来应对这些多样复杂的伪影问题。

Method: 1) 建立生成图像伪影的详细分类法；2) 人工标注340K图像的大规模数据集MagicData340K；3) 训练基于视觉语言模型的MagicAssessor评估器；4) 设计新颖的数据采样策略和多级奖励系统用于GRPO训练；5) 构建自动化基准MagicBench评估T2I模型。

Result: 评估发现即使像GPT-image-1这样的顶级模型也持续受到显著伪影的困扰，突显了伪影减少是未来T2I发展的关键前沿。

Conclusion: MagicMirror框架填补了T2I生成伪影评估的空白，提供了系统化的评估工具和基准，强调了伪影问题的重要性，为未来模型改进提供了重要参考。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [48] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: SignClip是一个手语翻译新框架，通过融合手势和唇部运动特征，并采用分层对比学习，在PHOENIX14T和How2Sign数据集上取得了SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译方法主要关注手势信号，往往忽略了唇部运动等非手动线索，而唇部运动在手语中承载重要语言信息，对区分视觉相似手势至关重要

Method: 提出SignClip框架，融合空间手势和唇部运动特征，引入分层对比学习框架，包含多级对齐目标，确保手语-唇部和视觉-文本模态间的语义一致性

Result: 在PHOENIX14T数据集的无标注设置下，BLEU-4从24.32提升到24.71，ROUGE从46.57提升到48.38，超越了之前的SOTA模型SpaMo

Conclusion: 融合手动和非手动线索（特别是唇部运动）能显著提升手语翻译准确性，分层对比学习框架有效确保了多模态间的语义一致性

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [49] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: 本文分析了开源和闭源大型视觉语言模型在文本篡改检测方面的性能，发现开源模型正在接近但仍在闭源模型之后，并揭示了专门用于图像篡改检测的VLM在文本检测中存在泛化问题。


<details>
  <summary>Details</summary>
Motivation: 虽然大型视觉语言模型在图像篡改检测方面表现出色，但文本篡改检测的研究相对缺乏，需要填补这一知识空白并评估不同模型在文本篡改检测任务上的表现。

Method: 通过在不同文本篡改数据集上测试闭源和开源VLM模型，包括对野外场景文本和模拟现实世界滥用的幻想ID卡上的篡改操作进行基准测试。

Result: 开源模型在文本篡改检测方面正在进步但仍落后于GPT-4o等闭源模型，专门用于图像篡改检测的VLM在文本检测任务中存在泛化问题。

Conclusion: 文本篡改检测是VLM能力评估的重要维度，开源模型需要进一步改进，专门化模型需要更好的跨模态泛化能力，特别是在应对现实世界滥用场景时。

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [50] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: MCL-AD是一个新颖的零样本3D异常检测框架，通过多模态协作学习整合点云、RGB图像和文本语义，在无需标注训练数据的情况下实现卓越的异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注点云数据，忽略了RGB图像和文本先验等互补模态提供的丰富语义线索。为了解决数据稀缺、隐私和高标注成本等约束场景下的3D异常检测问题，需要充分利用多模态信息。

Method: 提出多模态提示学习机制(MPLM)，通过对象无关的解耦文本提示和多模态对比损失增强模态内表示能力和模态间协作学习。同时设计协作调制机制(CMM)，联合调制RGB图像引导和点云引导分支，充分利用点云和RGB图像的互补表示。

Result: 大量实验证明，MCL-AD框架在零样本3D异常检测中达到了最先进的性能。

Conclusion: 通过多模态协作学习，MCL-AD成功整合了不同模态的优势，为零样本3D异常检测提供了有效的解决方案，在数据稀缺场景下表现出色。

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [51] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: 提出一种基于Lipschitz约束的随机深度(DropPath)方法，通过深度相关的丢弃概率来控制网络的有效Lipschitz常数，在保持清洁精度的同时提升对抗鲁棒性并减少计算量。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络和Vision Transformers在计算机视觉中表现优异但对抗扰动脆弱，现有防御方法计算成本高或缺乏形式化保证，需要一种既能提高鲁棒性又能保持效率和精度的解决方案。

Method: 采用Lipschitz引导的随机深度方法，丢弃概率随网络深度增加而增大，以此控制网络的有效Lipschitz常数，对深层进行正则化。

Result: 在CIFAR-10数据集上使用ViT-Tiny的实验表明，该方法在保持接近基线清洁精度的同时，显著提升了在FGSM、PGD-20和AutoAttack下的鲁棒性，并大幅减少了FLOPs计算量。

Conclusion: 深度相关的DropPath调度策略是一种有效的正则化方法，能够在保持模型精度的同时提高对抗鲁棒性和计算效率，为构建更鲁棒的视觉Transformer提供了可行方案。

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [52] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 提出基于能量图的概率框架，用于复杂城市环境中街道家具的精确定位，通过随机生死优化算法整合地理空间信息，提高定位精度


<details>
  <summary>Details</summary>
Motivation: 解决城市街道家具精确定位问题，为地方当局和私人利益相关者提供有效的公共基础设施监控和维护手段

Method: 基于能量图的概率框架，将空间位置可能性编码为地图格式，结合GIS图层、道路地图等外部地理空间信息，使用随机生死优化算法推断最可能的资产配置

Result: 通过在都柏林市中心街灯基础设施数据集上的真实模拟评估，证明了该方法在可扩展和准确的城市资产映射方面的潜力

Conclusion: 该方法能够有效整合多种地理空间信息，提高城市环境中街道家具定位的准确性和上下文感知能力，算法实现已在GitHub开源

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [53] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: ClusCa通过空间聚类减少扩散变换器中的token数量，实现4.96倍加速，同时保持图像质量


<details>
  <summary>Details</summary>
Motivation: 扩散变换器虽然能生成高质量图像和视频，但迭代去噪过程计算成本巨大。现有特征缓存方法只利用了时间维度相似性，忽略了空间维度相似性

Method: 在每时间步对token进行空间聚类，每个聚类只计算一个token并将其信息传播给其他token，减少90%以上的token数量

Result: 在DiT、FLUX和HunyuanVideo上验证有效性，FLUX实现4.96倍加速，ImageReward达到99.49%，比原始模型提升0.51%

Conclusion: ClusCa是现有特征缓存方法的正交补充，无需训练即可直接应用于任何扩散变换器，显著加速推理过程

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [54] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: I-Segmenter是首个完全整数化的ViT分割框架，通过系统替换浮点运算、提出新激活函数λ-ShiftGELU、移除L2归一化层和使用最近邻上采样，在保持精度的同时显著减小模型大小并加速推理。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在语义分割中表现优异，但高内存占用和计算成本限制了其在资源受限设备上的部署。量化虽能提升效率，但ViT分割模型在低精度下表现脆弱，量化误差会在深度编码器-解码器管道中累积。

Method: 基于Segmenter架构，系统替换浮点运算为整数运算；提出λ-ShiftGELU激活函数处理长尾激活分布；移除L2归一化层；用最近邻上采样替换双线性插值，确保整个计算图的整数化执行。

Result: I-Segmenter在精度上与FP32基线相差平均5.1%，同时模型大小减小达3.8倍，推理速度提升达1.2倍。即使在单张校准图像的一次性PTQ设置下也能保持竞争力。

Conclusion: 该框架为ViT分割模型在资源受限设备上的实际部署提供了实用解决方案，在保持精度的同时显著提升了效率。

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [55] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: GARD是一种基于伽马扩散模型的OCT图像去噪方法，通过噪声减少保真项和加速推理框架，在保持解剖结构的同时有效去除散斑噪声


<details>
  <summary>Details</summary>
Motivation: OCT图像存在固有的散斑噪声，传统方法难以在去噪和保留解剖细节之间取得平衡，需要更准确的噪声统计模型和更好的去噪效果

Method: 提出GARD方法：使用Denoising Diffusion Gamma Model替代传统高斯噪声假设，引入Noise-Reduced Fidelity Term引导去噪过程，采用Denoising Diffusion Implicit Model框架加速推理

Result: 在配对噪声和低噪声OCT B扫描数据集上，GARD在PSNR、SSIM和MSE指标上显著优于传统方法和最先进的深度学习模型，定性结果显示边缘更清晰、解剖细节保留更好

Conclusion: GARD通过伽马扩散模型和噪声减少保真项，成功解决了OCT图像去噪中噪声统计建模和细节保留的挑战，为视网膜疾病诊断提供了更高质量的图像

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


### [56] [GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography](https://arxiv.org/abs/2509.10344)
*Yuexi Du,Lihui Chen,Nicha C. Dvornek*

Main category: cs.CV

TL;DR: GLAM是一个专门针对乳腺X线摄影多视图的视觉语言模型，通过几何引导的全局和局部对比学习，解决了现有方法忽略多视图对应关系的问题，在多个数据集上表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 乳腺X线筛查对乳腺癌早期检测至关重要，但现有视觉语言模型多从自然图像适配而来，忽略了乳腺X线摄影特有的多视图对应关系这一关键领域特征，导致预测性能不佳。

Method: 提出GLAM模型，利用乳腺X线摄影的多视图成像先验知识，通过几何引导的全局和局部对比学习，同时学习局部跨视图对齐和细粒度局部特征，包括视觉-视觉和视觉-语言的联合对比学习。

Result: 在最大的公开乳腺X线数据集EMBED上预训练后，该模型在多个数据集的不同设置下均优于基线方法。

Conclusion: 通过充分利用乳腺X线摄影的多视图几何关系，GLAM模型显著提升了乳腺X线图像分析的性能，为医学影像领域的视觉语言模型发展提供了新思路。

Abstract: Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.

</details>


### [57] [Towards Understanding Visual Grounding in Visual Language Models](https://arxiv.org/abs/2509.10345)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.CV

TL;DR: 这篇调查论文综述了现代通用视觉语言模型中的视觉基础能力，包括其重要性、核心组件、实际应用、基准评估以及与多模态思维链和推理的关系，并分析了当前挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视觉基础能力使模型能够根据文本描述识别视觉输入中的特定区域，这种能力对于各种应用至关重要，包括指代表达理解、细粒度视觉问答、显式实体引用以及环境控制等。

Method: 论文采用系统性文献综述方法，首先概述视觉基础在VLM中的重要性，然后详细阐述现代基础模型开发范式的核心组件，并考察其实际应用场景和评估指标。

Result: 研究分析了视觉基础与多模态思维链、推理能力之间的多层面相互关系，为理解现代VLM的工作原理提供了系统性的框架。

Conclusion: 论文识别了视觉基础面临的核心挑战，并提出了有前景的未来研究方向，为这一重要领域的发展提供了指导性见解。

Abstract: Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.

</details>


### [58] [Immunizing Images from Text to Image Editing via Adversarial Cross-Attention](https://arxiv.org/abs/2509.10359)
*Matteo Trippodo,Federico Becattini,Lorenzo Seidenari*

Main category: cs.CV

TL;DR: 提出了一种针对文本图像编辑方法的注意力攻击，通过使用源图像的自动生成标题作为编辑提示的代理，破坏文本提示与视觉表示之间的交叉注意力，从而降低编辑性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本图像编辑方法容易受到对抗攻击，需要一种不依赖编辑方法或编辑提示知识的攻击方式来破坏图像内容与文本描述的对齐。

Method: 引入Attention Attack，利用源图像的自动生成标题作为编辑提示代理，破坏交叉注意力机制。提出Caption Similarity和语义IoU两种新评估策略来衡量攻击效果。

Result: 在TEDBench++基准测试中，该攻击显著降低了编辑性能，同时保持攻击的不可感知性。

Conclusion: 该方法有效破坏了文本图像编辑系统的视觉组件，提出了可靠的评估指标，为对抗攻击研究提供了新方向。

Abstract: Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.

</details>


### [59] [Efficient Learned Image Compression Through Knowledge Distillation](https://arxiv.org/abs/2509.10366)
*Fabien Allemand,Attilio Fiandrotti,Sumanta Chaudhuri,Alaa Eddine Mazouz*

Main category: cs.CV

TL;DR: 本研究通过知识蒸馏技术降低神经网络图像压缩模型的资源需求，使小型网络能够达到接近大型模型的性能，适用于资源受限平台。


<details>
  <summary>Details</summary>
Motivation: 虽然基于深度学习的图像压缩方法在性能上优于传统编解码器，但计算资源需求大，难以在资源受限平台上实时应用，限制了其主流部署。

Method: 采用知识蒸馏训练范式，让小型神经网络学习大型复杂模型的输出，通过跨架构大小、不同质量/比特率权衡的设置来优化模型效率。

Result: 研究表明知识蒸馏能有效应用于图像压缩任务，节省处理资源和能耗，同时保持压缩性能。

Conclusion: 知识蒸馏为神经网络图像压缩提供了有效的资源优化方案，未来可探索不同教师模型、损失函数以及扩展到基于transformer的模型。

Abstract: Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .

</details>


### [60] [Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition](https://arxiv.org/abs/2509.10388)
*Zeqing Leo Yuan,Mani Ramanagopal,Aswin C. Sankaranarayanan,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: 提出了一种无需训练的本征图像分解方法，仅使用可见光和热成像图像对，通过热成像检测吸收光能来建立可见光与热成像强度之间的序数关系，从而自监督恢复着色和反射率。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏真实世界场景的广泛地面真实数据，本征图像分解（着色和反射率）长期以来面临挑战。现有方法依赖合成数据或稀疏标注，限制了室内外场景的应用。

Method: 利用热成像相机检测被吸收光能作为热量的原理，建立可见光和热成像图像强度之间的序数关系，这些关系可以密集自监督优化神经网络来恢复着色和反射率。

Result: 在自然光和人工光照下对已知反射率和着色进行定量评估，并在多样化户外场景进行定性实验，结果显示优于近期基于学习的方法。

Conclusion: 该方法为获取真实世界序数监督提供了一条可扩展的路径，这是之前通过手动标注无法实现的，展示了在真实场景本征图像分解方面的优越性能。

Abstract: Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.

</details>


### [61] [Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards](https://arxiv.org/abs/2509.10407)
*Xiem HoangVan,Dang BuiDinh,Sang NguyenQuang,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 本文提出了压缩视频质量增强(CVQE)的新分类法、统一基准测试框架和系统分析，旨在解决现有综述在分类体系、比较分析和基准测试方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有压缩视频质量增强的综述存在系统性分类不足、架构范式比较分析不够、基准测试实践不完善等问题，需要建立更全面的评估体系。

Method: 提出三方面贡献：1)基于架构范式、编码标准和压缩域特征利用的新分类法；2)集成现代压缩协议和标准测试序列的统一基准框架；3)对重建性能与计算复杂度权衡的系统分析。

Result: 建立了CVQE方法的系统性分类体系，提供了公平的多标准评估框架，分析了性能与复杂度的关键权衡关系。

Conclusion: 该综述为CVQE研究和部署提供了一致的评估基础和明智的模型选择指导，指明了未来研究的有前景方向。

Abstract: Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.

</details>


### [62] [Multimodal SAM-adapter for Semantic Segmentation](https://arxiv.org/abs/2509.10408)
*Iacopo Curti,Pierluigi Zama Ramirez,Alioscia Petrelli,Luigi Di Stefano*

Main category: cs.CV

TL;DR: MM SAM-adapter是一个新颖的多模态语义分割框架，通过适配器网络将融合的多模态特征注入到Segment Anything Model (SAM)中，在保持RGB特征强泛化能力的同时，有选择地利用辅助模态信息。


<details>
  <summary>Details</summary>
Motivation: 当前语义分割方法在恶劣光照、遮挡和恶劣天气等挑战性条件下表现脆弱，需要多模态方法来整合辅助传感器数据（如LiDAR、红外）以增强鲁棒性。

Method: 提出适配器网络架构，将融合的多模态特征注入SAM的RGB特征中，实现选择性多模态信息利用，平衡效率和性能。

Result: 在DeLiVER、FMB和MUSES三个挑战性基准测试中达到最先进性能，在RGB-easy和RGB-hard子集上都优于竞争方法。

Conclusion: 多模态适配方法能够有效提升场景理解的鲁棒性，在有利和不利条件下都表现出色，证明了多模态融合的价值。

Abstract: Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.

</details>


### [63] [InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis](https://arxiv.org/abs/2509.10441)
*Tao Han,Wanghan Xu,Junchao Gong,Xiaoyu Yue,Song Guo,Luping Zhou,Lei Bai*

Main category: cs.CV

TL;DR: InfGen是一种基于潜在扩散模型的第二代图像生成方法，通过用一步生成器替换VAE解码器，可以从固定大小的潜在表示生成任意分辨率的图像，显著降低计算复杂度，将4K图像生成时间从100多秒减少到10秒以内。


<details>
  <summary>Details</summary>
Motivation: 解决当前扩散模型在生成高分辨率图像时计算需求随分辨率平方增长的问题，4K图像生成延迟超过100秒，需要一种更高效的任意分辨率图像生成方法。

Method: 在潜在扩散模型基础上，将扩散模型生成的固定潜在表示作为内容表示，提出使用一步生成器来解码任意分辨率的图像，用新的生成器替换VAE解码器。

Result: InfGen能够将许多模型提升到任意高分辨率时代，同时将4K图像生成时间减少到10秒以内，显著降低了计算复杂度。

Conclusion: InfGen提供了一种简化的方法，可以在不重新训练扩散模型的情况下从固定大小的潜在表示生成任意分辨率的图像，适用于使用相同潜在空间的任何模型。

Abstract: Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.

</details>


### [64] [SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets](https://arxiv.org/abs/2509.10453)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: 本研究将三种先进的时序自监督学习方法应用于3D脑部MRI分析，通过处理变长输入和增强空间特征学习，在阿尔茨海默病预测任务中超越了监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病预测的深度学习模型面临标注数据稀缺、跨数据集泛化能力差以及对不同扫描数量和时期间隔缺乏灵活性的问题。

Method: 采用时序自监督学习（SSL）方法，包括时序顺序预测和对比学习，处理变长输入并学习鲁棒的空间特征，在4个公开数据集（3,161名患者）上进行预训练。

Result: 自监督学习模型在7个下游任务中的6个上超越了监督学习，展现出跨任务和不同输入图像数量及时期间隔的适应性和泛化能力。

Conclusion: 时序自监督学习方法在阿尔茨海默病预测中表现出色，具有强大的临床应用潜力，代码和模型已公开。

Abstract: Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [65] [When Your Reviewer is an LLM: Biases, Divergence, and Prompt Injection Risks in Peer Review](https://arxiv.org/abs/2509.09912)
*Changjia Zhu,Junjie Xiong,Renkai Ma,Zhicong Lu,Yao Liu,Lingyao Li*

Main category: cs.CY

TL;DR: 本文系统评估了大型语言模型（LLMs）作为学术评审员的表现，发现LLMs对较弱论文评分偏高，但对优秀论文的评审与人类更一致，且易受特定领域指令的操纵。


<details>
  <summary>Details</summary>
Motivation: 随着投稿量激增、评审员负担加重和专业领域不匹配等问题日益严重，LLMs被用作"评审助手"，但其公平性、一致性和对抗间接提示注入攻击的鲁棒性引发担忧。

Method: 使用ICLR 2023和NeurIPS 2022的1,441篇论文数据集，通过结构化提示、参考论文校准、主题建模和相似性分析评估GPT-5-mini，并在PDF中嵌入隐蔽指令测试提示注入敏感性。

Result: LLMs对较弱论文评分普遍偏高，但对优秀论文的评审与人类判断更接近；总体恶意提示仅引起主题焦点微小变化，但明确领域特定的指令能成功操纵LLM生成评审的特定方面。

Conclusion: 研究强调了将LLMs整合到同行评审中的前景和风险，指出设计保障措施以确保未来评审过程完整性和信任的重要性。

Abstract: Peer review is the cornerstone of academic publishing, yet the process is
increasingly strained by rising submission volumes, reviewer overload, and
expertise mismatches. Large language models (LLMs) are now being used as
"reviewer aids," raising concerns about their fairness, consistency, and
robustness against indirect prompt injection attacks. This paper presents a
systematic evaluation of LLMs as academic reviewers. Using a curated dataset of
1,441 papers from ICLR 2023 and NeurIPS 2022, we evaluate GPT-5-mini against
human reviewers across ratings, strengths, and weaknesses. The evaluation
employs structured prompting with reference paper calibration, topic modeling,
and similarity analysis to compare review content. We further embed covert
instructions into PDF submissions to assess LLMs' susceptibility to prompt
injection. Our findings show that LLMs consistently inflate ratings for weaker
papers while aligning more closely with human judgments on stronger
contributions. Moreover, while overarching malicious prompts induce only minor
shifts in topical focus, explicitly field-specific instructions successfully
manipulate specific aspects of LLM-generated reviews. This study underscores
both the promises and perils of integrating LLMs into peer review and points to
the importance of designing safeguards that ensure integrity and trust in
future review processes.

</details>


### [66] [A Taxonomy of Response Strategies to Toxic Online Content: Evaluating the Evidence](https://arxiv.org/abs/2509.09921)
*Lisa Schirch,Kristina Radivojevic,Cathy Buerger*

Main category: cs.CY

TL;DR: 本文提出了在线话语参与(ODE)的分类法，将25种应对有毒在线内容的策略分为5大类，并系统评估了每种策略的有效性证据。


<details>
  <summary>Details</summary>
Motivation: 当前对有毒在线内容(TOC)的应对策略存在目标、术语和评估方法的巨大差异，文献中存在矛盾假设且缺乏对策略有效性的严格评估。

Method: 通过分类25种ODE策略并构建五类响应分类法（化解分散、参与说话者视角、识别共享价值观、为受害者发声、信息和事实构建），然后系统回顾每类策略的证据基础。

Result: 建立了ODE的清晰分类框架，为不同应对策略提供了系统的证据评估，为构建更健康的在线公共话语提供了理论基础。

Conclusion: 通过澄清定义、分类策略和提供元分析，本文旨在为ODE研究带来一致性，并加强基于证据的构建性在线话语参与方法。

Abstract: Toxic Online Content (TOC) includes messages on digital platforms that are
harmful, hostile, or damaging to constructive public discourse. Individuals,
organizations, and LLMs respond to TOC through counterspeech or
counternarrative initiatives. There is a wide variation in their goals,
terminology, response strategies, and methods of evaluating impact. This paper
identifies a taxonomy of online response strategies, which we call Online
Discourse Engagement (ODE), to include any type of online speech to build
healthier online public discourse. The literature on ODE makes contradictory
assumptions about ODE goals and rarely distinguishes between them or rigorously
evaluates their effectiveness. This paper categorizes 25 distinct ODE
strategies, from humor and distraction to empathy, solidarity, and fact-based
rebuttals, and groups these into a taxonomy of five response categories:
defusing and distracting, engaging the speaker's perspective, identifying
shared values, upstanding for victims, and information and fact-building. The
paper then systematically reviews the evidence base for each of these
categories. By clarifying definitions, cataloging response strategies, and
providing a meta-analysis of research papers on these strategies, this article
aims to bring coherence to the study of ODE and to strengthen evidence-informed
approaches for fostering constructive ODE.

</details>


### [67] [The Hierarchical Morphotope Classification: A Theory-Driven Framework for Large-Scale Analysis of Built Form](https://arxiv.org/abs/2509.10083)
*Martin Fleischmann,Krasen Samardzhiev,Anna Brázdová,Daniela Dančejová,Lisa Winkler*

Main category: cs.CY

TL;DR: 该论文提出了HiMoC（分层形态类型分类）方法，这是一种理论驱动、计算可扩展的建筑形态分类方法，通过SA3区域化方法识别具有独特特征的形态类型，并构建分层分类树。


<details>
  <summary>Details</summary>
Motivation: 现有的城市模式分类方法缺乏坚实的理论基础，无法扩展到本地层面之外，或者为了更广泛的应用而牺牲细节。需要一种理论驱动、可扩展且详细的方法来分类建筑形态。

Method: 使用HiMoC方法，通过SA3（空间聚合自适应聚合）区域化方法划分连续的、形态上不同的区域（形态类型），基于从开放数据中提取的建筑和街道的形态测量特征构建分层分类树。

Result: 该方法在中欧国家子集上进行了测试，将超过9000万个建筑足迹分组为超过50万个形态类型，证明了方法的可扩展性和有效性。

Conclusion: HiMoC是一种理论基础扎实、可重复、无监督且可扩展的方法，能够促进对城市结构的细致理解，在城市规划、环境分析和社会空间研究中有广泛应用。

Abstract: Built environment, formed of a plethora of patterns of building, streets, and
plots, has a profound impact on how cities are perceived and function. While
various methods exist to classify urban patterns, they often lack a strong
theoretical foundation, are not scalable beyond a local level, or sacrifice
detail for broader application. This paper introduces the Hierarchical
Morphotope Classification (HiMoC), a novel, theory-driven, and computationally
scalable method of classification of built form. HiMoC operationalises the idea
of a morphotope - the smallest locality with a distinctive character - using a
bespoke regionalisation method SA3 (Spatial Agglomerative Adaptive
Aggregation), to delineate contiguous, morphologically distinct localities.
These are further organised into a hierarchical taxonomic tree reflecting their
dissimilarity based on morphometric profile derived from buildings and streets
retrieved from open data, allowing flexible, interpretable classification of
built fabric, that can be applied beyond a scale of a single country. The
method is tested on a subset of countries of Central Europe, grouping over 90
million building footprints into over 500,000 morphotopes. The method extends
the capabilities of available morphometric analyses, while offering a
complementary perspective to existing large scale data products, which are
focusing primarily on land use or use conceptual definition of urban fabric
types. This theory-grounded, reproducible, unsupervised and scalable method
facilitates a nuanced understanding of urban structure, with broad applications
in urban planning, environmental analysis, and socio-spatial studies.

</details>


### [68] [Openness in AI and downstream governance: A global value chain approach](https://arxiv.org/abs/2509.10220)
*Christopher Foster*

Main category: cs.CY

TL;DR: 本文分析了AI领域的开放性现象，将其概念化为一种独特的公司间关系，并运用价值链分析框架来理解AI开放资源如何影响技术转移和行业权力分配。


<details>
  <summary>Details</summary>
Motivation: AI快速发展导致权力和价值集中在少数科技巨头手中，而AI开放性（开源模型、数据集和工具链）的兴起提出了重要问题：开放资源是否能支持技术转移和追赶能力，即使面对AI行业巨头的垄断力量。

Method: 将AI开放性概念化为独特的公司间关系，采用价值链分析方法，考察基础AI公司在价值链中的"外包"资本主义动态，以及AI采用过程中可能出现的治理和控制类型。

Result: 构建了一个将基础AI与下游价值链联系起来的分析框架，扩展了对AI作为生产性部门的理解。

Conclusion: 尽管仍需警惕领先AI公司的权力，但AI开放性可能因全球AI技术领导地位的激烈竞争而产生潜在的技术溢出效应。

Abstract: The rise of AI has been rapid, becoming a leading sector for investment and
promising disruptive impacts across the economy. Within the critical analysis
of the economic impacts, AI has been aligned to the critical literature on data
power and platform capitalism - further concentrating power and value capture
amongst a small number of "big tech" leaders.
  The equally rapid rise of openness in AI (here taken to be claims made by AI
firms about openness, "open source" and free provision) signals an interesting
development. It highlights an emerging ecosystem of open AI models, datasets
and toolchains, involving massive capital investment. It poses questions as to
whether open resources can support technological transfer and the ability for
catch-up, even in the face of AI industry power.
  This work seeks to add conceptual clarity to these debates by conceptualising
openness in AI as a unique type of interfirm relation and therefore amenable to
value chain analysis. This approach then allows consideration of the capitalist
dynamics of "outsourcing" of foundational firms in value chains, and
consequently the types of governance and control that might emerge downstream
as AI is adopted. This work, therefore, extends previous mapping of AI value
chains to build a framework which links foundational AI with downstream value
chains.
  Overall, this work extends our understanding of AI as a productive sector.
While the work remains critical of the power of leading AI firms, openness in
AI may lead to potential spillovers stemming from the intense competition for
global technological leadership in AI.

</details>


### [69] [We Need a New Ethics for a World of AI Agents](https://arxiv.org/abs/2509.10289)
*Iason Gabriel,Geoff Keeling,Arianna Manzini,James Evans*

Main category: cs.CY

TL;DR: 论文呼吁科学家、学者、工程师和政策制定者更深入地参与AI智能体普及带来的安全、人机关系和社会协调等问题的研究


<details>
  <summary>Details</summary>
Motivation: 随着AI智能体的部署应用，引发了新的安全问题、人机关系挑战和社会协调问题，需要各界专家共同关注和应对

Method: 通过论证分析，探讨AI智能体世界中需要解决的关键挑战，确保人机交互和智能体间交互的广泛受益

Result: 识别了AI智能体普及带来的重要问题领域，强调了多学科协作的必要性

Conclusion: 需要科学家、学者、工程师和政策制定者共同参与，确保AI智能体世界的安全性和社会效益

Abstract: The deployment of capable AI agents raises fresh questions about safety,
human-machine relationships and social coordination. We argue for greater
engagement by scientists, scholars, engineers and policymakers with the
implications of a world increasingly populated by AI agents. We explore key
challenges that must be addressed to ensure that interactions between humans
and agents, and among agents themselves, remain broadly beneficial.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [70] [Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis](https://arxiv.org/abs/2509.09744)
*Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia*

Main category: cs.LG

TL;DR: SAM-BG是一个两阶段的自监督学习框架，通过结构语义保留来学习脑图表示，在精神病诊断中表现优异，特别是在小样本标注数据场景下。


<details>
  <summary>Details</summary>
Motivation: 脑网络标注数据有限，现有自监督学习方法的数据增强策略可能破坏脑图的关键结构语义，需要一种能够保持结构语义的方法来提高精神病诊断的准确性和可解释性。

Method: 提出两阶段框架：1）预训练阶段在小标注子集上训练边缘掩码器捕捉关键结构语义；2）自监督学习阶段利用提取的结构先验指导结构感知的数据增强过程，学习更具语义意义和鲁棒性的表示。

Result: 在两个真实世界精神病数据集上的实验表明，SAM-BG优于最先进方法，特别是在小标注数据设置下，并发现了具有临床相关性的连接模式，增强了可解释性。

Conclusion: SAM-BG通过结构语义保留的自监督学习方法，有效解决了脑网络数据标注有限的问题，在精神病诊断中实现了更好的性能和可解释性。

Abstract: The limited availability of labeled brain network data makes it challenging
to achieve accurate and interpretable psychiatric diagnoses. While
self-supervised learning (SSL) offers a promising solution, existing methods
often rely on augmentation strategies that can disrupt crucial structural
semantics in brain graphs. To address this, we propose SAM-BG, a two-stage
framework for learning brain graph representations with structural semantic
preservation. In the pre-training stage, an edge masker is trained on a small
labeled subset to capture key structural semantics. In the SSL stage, the
extracted structural priors guide a structure-aware augmentation process,
enabling the model to learn more semantically meaningful and robust
representations. Experiments on two real-world psychiatric datasets demonstrate
that SAM-BG outperforms state-of-the-art methods, particularly in small-labeled
data settings, and uncovers clinically relevant connectivity patterns that
enhance interpretability. Our code is available at
https://github.com/mjliu99/SAM-BG.

</details>


### [71] [SciML Agents: Write the Solver, Not the Solution](https://arxiv.org/abs/2509.09936)
*Saarth Gaonkar,Xiang Zheng,Haocheng Xi,Rishabh Tiwari,Kurt Keutzer,Dmitriy Morozov,Michael W. Mahoney,Amir Gholami*

Main category: cs.LG

TL;DR: 本文探讨使用LLMs生成科学计算代码来求解ODE问题，而非直接学习解函数。提出了新的诊断数据集和大规模基准测试，评估LLMs在科学计算任务中的能力。


<details>
  <summary>Details</summary>
Motivation: 传统科学机器学习方法通过神经网络直接预测目标值，但难以获得高精度和鲁棒性。本文探索替代方案：利用LLMs编写代码来调用成熟的数值算法，将学习负担从求解函数转移到领域感知的数值选择上。

Method: 引入两个新数据集：诊断性误导问题和1000个多样化ODE任务的大规模基准。评估开源和闭源LLM模型，采用无引导vs领域知识引导提示、现成模型vs微调变体两种策略，测量代码可执行性和数值有效性。

Result: 研究发现，在充足上下文和引导提示下，较新的指令跟随模型在两个评估标准上都达到高精度。开源系统无需微调即可表现良好，而较老或较小模型仍能从微调中受益。

Conclusion: 精心设计的提示和微调可以产生能够可靠解决简单ODE问题的专用LLM代理，为科学计算任务提供了有前景的新途径。

Abstract: Recent work in scientific machine learning aims to tackle scientific tasks
directly by predicting target values with neural networks (e.g.,
physics-informed neural networks, neural ODEs, neural operators, etc.), but
attaining high accuracy and robustness has been challenging. We explore an
alternative view: use LLMs to write code that leverages decades of numerical
algorithms. This shifts the burden from learning a solution function to making
domain-aware numerical choices. We ask whether LLMs can act as SciML agents
that, given a natural-language ODE description, generate runnable code that is
scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),
and enforcing stability checks. There is currently no benchmark to measure this
kind of capability for scientific computing tasks. As such, we first introduce
two new datasets: a diagnostic dataset of adversarial "misleading" problems;
and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set
contains problems whose superficial appearance suggests stiffness, and that
require algebraic simplification to demonstrate non-stiffness; and the
large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-
and closed-source LLM models along two axes: (i) unguided versus guided
prompting with domain-specific knowledge; and (ii) off-the-shelf versus
fine-tuned variants. Our evaluation measures both executability and numerical
validity against reference solutions. We find that with sufficient context and
guided prompts, newer instruction-following models achieve high accuracy on
both criteria. In many cases, recent open-source systems perform strongly
without fine-tuning, while older or smaller models still benefit from
fine-tuning. Overall, our preliminary results indicate that careful prompting
and fine-tuning can yield a specialized LLM agent capable of reliably solving
simple ODE problems.

</details>


### [72] [D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference](https://arxiv.org/abs/2509.09747)
*Leen Daher,Zhaobo Wang,Malcolm Mielle*

Main category: cs.LG

TL;DR: D-CAT是一个解耦跨注意力迁移框架，允许在推理时仅使用单一传感器进行跨模态知识迁移，解决了传统方法需要配对传感器数据的限制。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态迁移学习方法在训练和推理时都需要配对传感器数据，这在资源受限环境中难以实现，限制了多模态分类模型在成本敏感或自适应部署中的应用。

Method: 提出D-CAT框架，结合自注意力模块进行特征提取和新型跨注意力对齐损失，在不耦合两种模态分类管道的情况下对齐模态特定表示空间。

Result: 在三个多模态人类活动数据集上评估，在分布内场景中，从高性能模态迁移可获得10% F1分数提升；在分布外场景中，即使较弱源模态也能改善目标性能。

Conclusion: D-CAT通过实现单传感器推理的跨模态知识迁移，减少了感知系统的硬件冗余，同时保持准确性，适用于成本敏感或自适应部署场景。

Abstract: Cross-modal transfer learning is used to improve multi-modal classification
models (e.g., for human activity recognition in human-robot collaboration).
However, existing methods require paired sensor data at both training and
inference, limiting deployment in resource-constrained environments where full
sensor suites are not economically and technically usable. To address this, we
propose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns
modality-specific representations without requiring joint sensor modality
during inference. Our approach combines a self-attention module for feature
extraction with a novel cross-attention alignment loss, which enforces the
alignment of sensors' feature spaces without requiring the coupling of the
classification pipelines of both modalities. We evaluate D-CAT on three
multi-modal human activity datasets (IMU, video, and audio) under both
in-distribution and out-of-distribution scenarios, comparing against uni-modal
models. Results show that in in-distribution scenarios, transferring from
high-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains
over uni-modal training. In out-of-distribution scenarios, even weaker source
modalities (e.g., IMU to video) improve target performance, as long as the
target model isn't overfitted on the training data. By enabling single-sensor
inference with cross-modal knowledge, D-CAT reduces hardware redundancy for
perception systems while maintaining accuracy, which is critical for
cost-sensitive or adaptive deployments (e.g., assistive robots in homes with
variable sensor availability). Code is available at
https://github.com/Schindler-EPFL-Lab/D-CAT.

</details>


### [73] [Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss](https://arxiv.org/abs/2509.10011)
*Antoine Orioua,Philipp Krah,Julian Koellermeier*

Main category: cs.LG

TL;DR: IDEA是一种能够估计数据集内在维度并重建原始数据的自编码器，通过投影重建损失项和重加权双CancelOut层实现，在理论和实际流体数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时准确估计非线性流形数据的内在维度和实现高质量重建，需要开发一种既能估计维度又能有效重建的统一框架。

Method: 使用重加权双CancelOut层构建潜在空间，引入投影重建损失项来指导训练，通过连续评估去除潜在维度后的重建质量来估计内在维度。

Result: 在理论基准测试中表现出良好的准确性和高适应性，在流体动力学数值解数据上成功估计了内在维度并实现了原始解的重建。

Conclusion: IDEA是一个通用且鲁棒的内在维度估计和重建框架，能够有效处理线性和非线性流形数据，为复杂科学数据的降维和分析提供了有力工具。

Abstract: This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),
which identifies the underlying intrinsic dimension of a wide range of datasets
whose samples lie on either linear or nonlinear manifolds. Beyond estimating
the intrinsic dimension, IDEA is also able to reconstruct the original dataset
after projecting it onto the corresponding latent space, which is structured
using re-weighted double CancelOut layers. Our key contribution is the
introduction of the projected reconstruction loss term, guiding the training of
the model by continuously assessing the reconstruction quality under the
removal of an additional latent dimension. We first assess the performance of
IDEA on a series of theoretical benchmarks to validate its robustness. These
experiments allow us to test its reconstruction ability and compare its
performance with state-of-the-art intrinsic dimension estimators. The
benchmarks show good accuracy and high versatility of our approach.
Subsequently, we apply our model to data generated from the numerical solution
of a vertically resolved one-dimensional free-surface flow, following a
pointwise discretization of the vertical velocity profile in the horizontal
direction, vertical direction, and time. IDEA succeeds in estimating the
dataset's intrinsic dimension and then reconstructs the original solution by
working directly within the projection space identified by the network.

</details>


### [74] [Meta-Learning Reinforcement Learning for Crypto-Return Prediction](https://arxiv.org/abs/2509.09751)
*Junqiao Wang,Zhaoyang Guan,Guanyu Liu,Tianze Xia,Xianzhi Li,Shuo Yin,Xinyuan Song,Chuhan Cheng,Tianyu Shi,Alex Lee*

Main category: cs.LG

TL;DR: Meta-RL-Crypto是一个基于Transformer的统一架构，结合元学习和强化学习，创建了一个完全自改进的加密货币交易代理系统，无需人工监督，在多市场环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 加密货币预测极其困难，价格受链上活动、新闻流和社交情绪等多因素快速变化影响，且标记训练数据稀缺昂贵。需要开发能够自我改进的交易系统。

Method: 从指令调优的LLM开始，代理在闭环架构中迭代扮演三个角色（执行者、评判者、元评判者），利用多模态市场输入和内部偏好反馈，无需额外人工监督。

Result: 实验表明，Meta-RL-Crypto在真实市场的技术指标上表现良好，优于其他基于LLM的基线方法。

Conclusion: 该研究提出了一个创新的自改进交易代理架构，成功解决了加密货币预测的挑战，展示了在多变市场环境中的优异性能。

Abstract: Predicting cryptocurrency returns is notoriously difficult: price movements
are driven by a fast-shifting blend of on-chain activity, news flow, and social
sentiment, while labeled training data are scarce and expensive. In this paper,
we present Meta-RL-Crypto, a unified transformer-based architecture that
unifies meta-learning and reinforcement learning (RL) to create a fully
self-improving trading agent. Starting from a vanilla instruction-tuned LLM,
the agent iteratively alternates between three roles-actor, judge, and
meta-judge-in a closed-loop architecture. This learning process requires no
additional human supervision. It can leverage multimodal market inputs and
internal preference feedback. The agent in the system continuously refines both
the trading policy and evaluation criteria. Experiments across diverse market
regimes demonstrate that Meta-RL-Crypto shows good performance on the technical
indicators of the real market and outperforming other LLM-based baselines.

</details>


### [75] [Physics-informed sensor coverage through structure preserving machine learning](https://arxiv.org/abs/2509.10363)
*Benjamin David Shaffer,Brooks Kinch,Joseph Klobusicky,M. Ani Hsieh,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于条件神经Whitney形式的数字孪生框架，用于自适应源定位，结合有限元外微积分和transformer算子学习，保持离散守恒特性并实时适应传感器数据。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂流体输运系统中源定位的挑战，需要构建能够保持物理结构、实时适应传感器数据并提供稳定数值保证的数字孪生模型。

Method: 使用条件神经Whitney形式(CNWF)构建数字孪生，结合FEEC的数值保证和transformer算子学习。采用条件注意力机制识别简化的Whitney形式基、积分平衡方程和源场。采用交错方案在数字孪生评估和Lloyd算法引导传感器布置之间交替。

Result: 该方法在复杂几何形状中相比物理无关的transformer架构显示出更高的精度，表明结构保持为源识别提供了有效的归纳偏置。能够恢复连续假设下的点源，并证明了正则性作为定位的充分条件。

Conclusion: 结构保持的数字孪生框架为自适应源定位提供了物理可实现的正则映射，通过保持物理约束提高了在复杂环境中的识别准确性，为环境监测和源追踪应用提供了有效解决方案。

Abstract: We present a machine learning framework for adaptive source localization in
which agents use a structure-preserving digital twin of a coupled
hydrodynamic-transport system for real-time trajectory planning and data
assimilation. The twin is constructed with conditional neural Whitney forms
(CNWF), coupling the numerical guarantees of finite element exterior calculus
(FEEC) with transformer-based operator learning. The resulting model preserves
discrete conservation, and adapts in real time to streaming sensor data. It
employs a conditional attention mechanism to identify: a reduced Whitney-form
basis; reduced integral balance equations; and a source field, each compatible
with given sensor measurements. The induced reduced-order environmental model
retains the stability and consistency of standard finite-element simulation,
yielding a physically realizable, regular mapping from sensor data to the
source field. We propose a staggered scheme that alternates between evaluating
the digital twin and applying Lloyd's algorithm to guide sensor placement, with
analysis providing conditions for monotone improvement of a coverage
functional. Using the predicted source field as an importance function within
an optimal-recovery scheme, we demonstrate recovery of point sources under
continuity assumptions, highlighting the role of regularity as a sufficient
condition for localization. Experimental comparisons with physics-agnostic
transformer architectures show improved accuracy in complex geometries when
physical constraints are enforced, indicating that structure preservation
provides an effective inductive bias for source identification.

</details>


### [76] [LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation](https://arxiv.org/abs/2509.09754)
*Yiqun Shen,Song Yuan,Zhengze Zhang,Xiaoliang Wang,Daxin Jiang,Nguyen Cam-Tu*

Main category: cs.LG

TL;DR: LAVa是一个统一的KV缓存压缩框架，通过最小化Transformer残差流信息损失来实现动态预算分配，在长上下文推理中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩方法大多是启发式的，缺乏动态预算分配机制，无法根据任务需求智能分配缓存资源。

Method: 通过分析层注意力输出损失，提出新的度量标准来比较不同头的缓存条目，实现层间和头级的动态预算分配，无需训练或多策略组合。

Result: 在多个基准测试（LongBench、Needle-In-A-Haystack等）上表现出优越性能，发现动态层预算对生成任务关键，动态头预算对抽取任务重要。

Conclusion: LAVa作为首个统一的缓存驱逐和动态预算分配策略，在各种任务类型中始终保持最佳性能，为KV缓存压缩提供了新的理论框架和实践方案。

Abstract: KV Cache is commonly used to accelerate LLM inference with long contexts, yet
its high memory demand drives the need for cache compression. Existing
compression methods, however, are largely heuristic and lack dynamic budget
allocation. To address this limitation, we introduce a unified framework for
cache compression by minimizing information loss in Transformer residual
streams. Building on it, we analyze the layer attention output loss and derive
a new metric to compare cache entries across heads, enabling layer-wise
compression with dynamic head budgets. Additionally, by contrasting cross-layer
information, we also achieve dynamic layer budgets. LAVa is the first unified
strategy for cache eviction and dynamic budget allocation that, unlike prior
methods, does not rely on training or the combination of multiple strategies.
Experiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and
InfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a
new insight: dynamic layer budgets are crucial for generation tasks (e.g., code
completion), while dynamic head budgets play a key role in extraction tasks
(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently
maintains top performance across task types. Our code is available at
https://github.com/MGDDestiny/Lava.

</details>


### [77] [Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management](https://arxiv.org/abs/2509.09772)
*Sanjay Basu,Sadiq Y. Patel,Parth Sheth,Bhairavi Muralidharan,Namrata Elamaran,Aakriti Kinra,Rajaie Batniji*

Main category: cs.LG

TL;DR: 提出了HACO框架，将风险校准与偏好优化分离，为医疗补助人群的健康管理提供保守、可审计的决策支持，在控制不良事件风险的同时保持高安全覆盖率。


<details>
  <summary>Details</summary>
Motivation: 医疗补助人群的健康管理项目需要协调纵向服务和外展工作，必须确保安全、公平和可审计性。传统方法难以在控制风险的同时优化服务协调决策。

Method: HACO框架：(i)训练轻量级风险模型预测不良事件；(ii)使用保形阈值在目标风险水平下屏蔽不安全行动；(iii)在安全子集上学习偏好策略。使用版本无关的FQE进行评估和亚组审计。

Result: 实现了强大的风险区分能力（AUC约0.81），校准阈值在α=0.10时为τ≈0.038，同时保持高安全覆盖率。亚组分析显示不同人口统计特征间存在系统性价值差异。

Conclusion: 保形风险门控与离线强化学习相结合，能够为人群健康管理团队提供保守且可审计的决策支持，强调了公平性审计的重要性。

Abstract: Population health management programs for Medicaid populations coordinate
longitudinal outreach and services (e.g., benefits navigation, behavioral
health, social needs support, and clinical scheduling) and must be safe, fair,
and auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement
Learning (HACO) framework that separates risk calibration from preference
optimization to generate conservative action recommendations at scale. In our
setting, each step involves choosing among common coordination actions (e.g.,
which member to contact, by which modality, and whether to route to a
specialized service) while controlling the near-term risk of adverse
utilization events (e.g., unplanned emergency department visits or
hospitalizations). Using a de-identified operational dataset from Waymark
comprising 2.77 million sequential decisions across 168,126 patients, HACO (i)
trains a lightweight risk model for adverse events, (ii) derives a conformal
threshold to mask unsafe actions at a target risk level, and (iii) learns a
preference policy on the resulting safe subset. We evaluate policies with a
version-agnostic fitted Q evaluation (FQE) on stratified subsets and audit
subgroup performance across age, sex, and race. HACO achieves strong risk
discrimination (AUC ~0.81) with a calibrated threshold ( {\tau} ~0.038 at
{\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses
reveal systematic differences in estimated value across demographics,
underscoring the importance of fairness auditing. Our results show that
conformal risk gating integrates cleanly with offline RL to deliver
conservative, auditable decision support for population health management
teams.

</details>


### [78] [One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection](https://arxiv.org/abs/2509.09782)
*Roshini Pulishetty,Mani Kishan Ghantasala,Keerthy Kaushik Dasoju,Niti Mangwani,Vishal Garimella,Aditya Mate,Somya Chatterjee,Yue Kang,Ehi Nosakhare,Sadid Hasan,Soundar Srinivasan*

Main category: cs.LG

TL;DR: 提出了一个统一的LLM路由框架，使用单头交叉注意力机制动态选择最优LLM，在RouterBench基准测试中实现了6.6%的质量提升和2.9%的最大性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型部署中计算成本和性能差异的挑战，实现可扩展、成本效益高的实时应用部署。

Method: 使用单头交叉注意力机制联合建模查询和模型嵌入，通过指数奖励函数平衡性能与成本，预测响应质量和生成成本。

Result: 在RouterBench基准测试中，AIQ提升6.6%，最大性能提升2.9%，架构轻量且能有效跨域泛化。

Conclusion: 该框架为成本感知的LLM路由建立了新标准，具有更好的效率和稳定性。

Abstract: The proliferation of large language models (LLMs) with varying computational
costs and performance profiles presents a critical challenge for scalable,
cost-effective deployment in real-world applications. We introduce a unified
routing framework that leverages a single-head cross-attention mechanism to
jointly model query and model embeddings, enabling dynamic selection of the
optimal LLM for each input query. Our approach is evaluated on RouterBench, a
large-scale, publicly available benchmark encompassing diverse LLM pools and
domains. By explicitly capturing fine-grained query-model interactions, our
router predicts both response quality and generation cost, achieving up to 6.6%
improvement in Average Improvement in Quality (AIQ) and 2.9% in maximum
performance over existing routers. To robustly balance performance and cost, we
propose an exponential reward function that enhances stability across user
preferences. The resulting architecture is lightweight, generalizes effectively
across domains, and demonstrates improved efficiency compared to prior methods,
establishing a new standard for cost-aware LLM routing.

</details>


### [79] [From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms](https://arxiv.org/abs/2509.09793)
*Vincent Herfeld,Baudouin Denis de Senneville,Arthur Leclaire,Nicolas Papadakis*

Main category: cs.LG

TL;DR: 分析梯度步去噪器及其在即插即用算法中的应用，该去噪器被训练为显式函数的功能下降算子或邻近算子，同时保持最先进的去噪能力


<details>
  <summary>Details</summary>
Motivation: 即插即用优化算法使用现成的去噪器来替代图像先验的邻近算子或梯度下降算子，但通常这种图像先验是隐式的且无法表达

Method: 训练梯度步去噪器，使其成为显式函数的功能下降算子或邻近算子

Result: 梯度步去噪器能够保持最先进的去噪能力，同时具有明确的数学表达形式

Conclusion: 梯度步去噪器为即插即用算法提供了既具有优秀去噪性能又具备明确数学基础的算子替代方案

Abstract: In this paper we analyze the Gradient-Step Denoiser and its usage in
Plug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms
uses off the shelf denoisers to replace a proximity operator or a gradient
descent operator of an image prior. Usually this image prior is implicit and
cannot be expressed, but the Gradient-Step Denoiser is trained to be exactly
the gradient descent operator or the proximity operator of an explicit
functional while preserving state-of-the-art denoising capabilities.

</details>


### [80] [Distinguishing Startle from Surprise Events Based on Physiological Signals](https://arxiv.org/abs/2509.09799)
*Mansi Sharma,Alexandre Duchevet,Florian Daiber,Jean-Paul Imbert,Maurice Rekrut*

Main category: cs.LG

TL;DR: 本研究使用机器学习和多模态融合策略，基于生理信号区分惊吓和惊讶事件，最高准确率达85.7%，并能将惊吓、惊讶和基线状态区分，准确率达74.9%。


<details>
  <summary>Details</summary>
Motivation: 意外事件会损害注意力和延迟决策，在高风险环境如航空中构成严重安全风险。惊吓和惊讶反应以不同方式影响飞行员表现，但在实践中难以区分。现有研究大多单独研究这些反应，对其组合效应或如何用生理数据区分它们关注有限。

Method: 使用机器学习和多模态融合策略，基于生理信号区分惊吓和惊讶事件。采用了SVM和XGBoost等机器学习算法，以及Late Fusion等多模态融合方法。

Result: 惊吓和惊讶事件可以可靠预测，使用SVM和Late Fusion获得最高平均准确率85.7%。进一步评估包括基线条件，使用XGBoost和Late Fusion成功区分惊吓、惊讶和基线状态，最高平均准确率达74.9%。

Conclusion: 研究表明基于生理信号的机器学习方法能够有效区分惊吓和惊讶反应，为高风险环境中飞行员表现监测和安全风险评估提供了有效工具。

Abstract: Unexpected events can impair attention and delay decision-making, posing
serious safety risks in high-risk environments such as aviation. In particular,
reactions like startle and surprise can impact pilot performance in different
ways, yet are often hard to distinguish in practice. Existing research has
largely studied these reactions separately, with limited focus on their
combined effects or how to differentiate them using physiological data. In this
work, we address this gap by distinguishing between startle and surprise events
based on physiological signals using machine learning and multi-modal fusion
strategies. Our results demonstrate that these events can be reliably
predicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.
To further validate the robustness of our model, we extended the evaluation to
include a baseline condition, successfully differentiating between Startle,
Surprise, and Baseline states with a highest mean accuracy of 74.9% with
XGBoost and Late Fusion.

</details>


### [81] [Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning](https://arxiv.org/abs/2509.09838)
*Reza Asad,Reza Babanezhad,Sharan Vaswani*

Main category: cs.LG

TL;DR: 本文提出了一种新的离散动作off-policy actor-critic框架，通过解耦actor和critic的熵正则化，在Atari游戏中达到了与DQN相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的离散动作强化学习方法中，value-based方法（如DQN）是主流，而policy-based方法要么无法有效利用off-policy数据（如PPO），要么在离散动作设置中表现不佳（如SAC）。DSAC性能差的主要原因是actor和critic的熵耦合问题。

Method: 提出了一个灵活的off-policy actor-critic框架：1）解耦actor和critic的熵正则化组件；2）使用m步Bellman算子进行critic更新；3）将标准策略优化方法与熵正则化结合来实例化actor目标函数。

Result: 理论证明在表格设置中可以收敛到最优正则化值函数。实验表明在标准Atari游戏中可以达到DQN的性能水平，甚至在没有熵正则化或显式探索的情况下也能实现。

Conclusion: 通过解耦actor-critic的熵耦合问题，提出的框架成功地将actor-critic方法扩展到离散动作设置，为off-policy强化学习提供了新的有效解决方案。

Abstract: Value-based approaches such as DQN are the default methods for off-policy
reinforcement learning with discrete-action environments such as Atari. Common
policy-based methods are either on-policy and do not effectively learn from
off-policy data (e.g. PPO), or have poor empirical performance in the
discrete-action setting (e.g. SAC). Consequently, starting from discrete SAC
(DSAC), we revisit the design of actor-critic methods in this setting. First,
we determine that the coupling between the actor and critic entropy is the
primary reason behind the poor performance of DSAC. We demonstrate that by
merely decoupling these components, DSAC can have comparable performance as
DQN. Motivated by this insight, we introduce a flexible off-policy actor-critic
framework that subsumes DSAC as a special case. Our framework allows using an
m-step Bellman operator for the critic update, and enables combining standard
policy optimization methods with entropy regularization to instantiate the
resulting actor objective. Theoretically, we prove that the proposed methods
can guarantee convergence to the optimal regularized value function in the
tabular setting. Empirically, we demonstrate that these methods can approach
the performance of DQN on standard Atari games, and do so even without entropy
regularization or explicit exploration.

</details>


### [82] [HGEN: Heterogeneous Graph Ensemble Networks](https://arxiv.org/abs/2509.09843)
*Jiajun Shen,Yufei Jin,Yi He,Xingquan Zhu*

Main category: cs.LG

TL;DR: HGEN是首个针对异构图设计的集成学习框架，通过元路径和随机丢弃创建等位GNN，利用残差注意力机制和相关性正则化提升分类精度和模型多样性


<details>
  <summary>Details</summary>
Motivation: 异构图中的节点类型、节点特征和局部邻域拓扑的异质性给集成学习带来挑战，需要适应多样化的图学习器

Method: 使用元路径结合随机丢弃创建等位GNN，采用残差注意力机制校准不同元路径的等位GNN，并通过相关性正则化项增大嵌入矩阵差异

Result: 在五个异构网络上的实验验证HGEN始终以显著优势超越最先进的竞争对手

Conclusion: HGEN通过创新的集成学习方法有效解决了异构图学习中的挑战，提供了更高的正则化强度和分类性能

Abstract: This paper presents HGEN that pioneers ensemble learning for heterogeneous
graphs. We argue that the heterogeneity in node types, nodal features, and
local neighborhood topology poses significant challenges for ensemble learning,
particularly in accommodating diverse graph learners. Our HGEN framework
ensembles multiple learners through a meta-path and transformation-based
optimization pipeline to uplift classification accuracy. Specifically, HGEN
uses meta-path combined with random dropping to create Allele Graph Neural
Networks (GNNs), whereby the base graph learners are trained and aligned for
later ensembling. To ensure effective ensemble learning, HGEN presents two key
components: 1) a residual-attention mechanism to calibrate allele GNNs of
different meta-paths, thereby enforcing node embeddings to focus on more
informative graphs to improve base learner accuracy, and 2) a
correlation-regularization term to enlarge the disparity among embedding
matrices generated from different meta-paths, thereby enriching base learner
diversity. We analyze the convergence of HGEN and attest its higher
regularization magnitude over simple voting. Experiments on five heterogeneous
networks validate that HGEN consistently outperforms its state-of-the-art
competitors by substantial margin.

</details>


### [83] [Latency and Token-Aware Test-Time Compute](https://arxiv.org/abs/2509.09864)
*Jenny Y. Huang,Mehul Damani,Yousef El-Kurdi,Ramon Astudillo,Wei Sun*

Main category: cs.LG

TL;DR: 本文提出了一个推理时计算动态分配框架，同时考虑token成本和延迟，在保持部署实用性的同时实现更好的准确率-成本权衡


<details>
  <summary>Details</summary>
Motivation: 现有的推理时扩展方法主要关注并行生成方法（如best-of-N），忽略了增量解码方法（如beam search），且大多只关注token使用而忽略了延迟这一对用户体验和智能体工作流至关重要的因素

Method: 将推理时扩展建模为动态计算分配和方法选择问题，系统需要基于每个查询决定应用哪种策略以及分配多少计算资源，明确同时考虑token成本和时钟延迟

Result: 在推理基准测试上的实验表明，该方法 consistently 优于静态策略，在保持部署实用性的同时实现了有利的准确率-成本权衡

Conclusion: 动态计算分配和方法选择框架能够有效提升LLM性能，同时兼顾token成本和延迟，为实际部署提供了实用的解决方案

Abstract: Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

</details>


### [84] [Variational Neural Networks for Observable Thermodynamics (V-NOTS)](https://arxiv.org/abs/2509.09899)
*Christopher Eldred,François Gay-Balmaz,Vakhtang Putkaradze*

Main category: cs.LG

TL;DR: 提出了一种基于可观测变量的数据驱动计算框架，用于耗散动力系统的相空间演化预测，通过热力学拉格朗日方法和神经网络确保热力学一致性。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法通常假设可直接观测相空间变量，但在耗散系统中，动量和熵等关键变量往往无法直接观测，需要开发仅基于可观测变量的计算方法。

Method: 构建基于热力学拉格朗日的新型方法，设计神经网络确保热力学约束和熵不减演化，仅使用有限数据点和少量参数描述相空间演化。

Result: 该方法能够有效描述相空间演化，仅需有限数据点和相对较少的系统参数即可实现准确预测。

Conclusion: 所提出的数据驱动框架成功解决了耗散系统中不可观测变量的挑战，为基于可观测变量的物理系统演化计算提供了有效解决方案。

Abstract: Much attention has recently been devoted to data-based computing of evolution
of physical systems. In such approaches, information about data points from
past trajectories in phase space is used to reconstruct the equations of motion
and to predict future solutions that have not been observed before. However, in
many cases, the available data does not correspond to the variables that define
the system's phase space. We focus our attention on the important example of
dissipative dynamical systems. In that case, the phase space consists of
coordinates, momenta and entropies; however, the momenta and entropies cannot,
in general, be observed directly. To address this difficulty, we develop an
efficient data-based computing framework based exclusively on observable
variables, by constructing a novel approach based on the \emph{thermodynamic
Lagrangian}, and constructing neural networks that respect the thermodynamics
and guarantees the non-decreasing entropy evolution. We show that our network
can provide an efficient description of phase space evolution based on a
limited number of data points and a relatively small number of parameters in
the system.

</details>


### [85] [LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios](https://arxiv.org/abs/2509.09926)
*Jiahao Chen,Zhiyuan Huang,Yurou Liu,Bing Su*

Main category: cs.LG

TL;DR: 提出LoFT框架，通过参数高效微调基础模型来解决长尾半监督学习中的过自信和低质量伪标签问题，并在开放世界场景下扩展为LoFT-OW处理OOD样本。


<details>
  <summary>Details</summary>
Motivation: 现有长尾半监督学习方法大多从零开始训练模型，容易导致过自信和低质量伪标签问题，需要将基础模型微调范式引入长尾半监督学习。

Method: 提出LoFT框架，通过参数高效微调基础模型生成更可靠的伪标签；进一步提出LoFT-OW处理开放世界场景下的OOD样本问题。

Result: 在多个基准测试中表现优于现有方法，即使仅使用1%的无标签数据也能取得优异性能。

Conclusion: 基础模型微调能够显著提升长尾半监督学习的性能，特别是在处理开放世界场景时表现出色。

Abstract: Long-tailed learning has garnered increasing attention due to its wide
applicability in real-world scenarios. Among existing approaches, Long-Tailed
Semi-Supervised Learning (LTSSL) has emerged as an effective solution by
incorporating a large amount of unlabeled data into the imbalanced labeled
dataset. However, most prior LTSSL methods are designed to train models from
scratch, which often leads to issues such as overconfidence and low-quality
pseudo-labels. To address these challenges, we extend LTSSL into the foundation
model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed
semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate
that fine-tuned foundation models can generate more reliable pseudolabels,
thereby benefiting imbalanced learning. Furthermore, we explore a more
practical setting by investigating semi-supervised learning under open-world
conditions, where the unlabeled data may include out-of-distribution (OOD)
samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World
scenarios) to improve the discriminative ability. Experimental results on
multiple benchmarks demonstrate that our method achieves superior performance
compared to previous approaches, even when utilizing only 1\% of the unlabeled
data compared with previous works.

</details>


### [86] [Multi-Play Combinatorial Semi-Bandit Problem](https://arxiv.org/abs/2509.09933)
*Shintaro Nakamura,Yuko Kuroki,Wei Chen*

Main category: cs.LG

TL;DR: 本文提出了多播放组合半赌博机(MP-CSB)模型，扩展了传统组合半赌博机模型，支持非负整数动作空间，并设计了两种高效算法：基于Thompson采样的算法和适用于随机与对抗环境的通用算法。


<details>
  <summary>Details</summary>
Motivation: 传统组合半赌博机(CSB)仅限于二元决策空间，无法处理包含非负整数流或分配的重要应用场景（如最优传输和背包问题），因此需要扩展模型以支持更广泛的应用。

Method: 提出了MP-CSB模型，允许选择非负整数动作并从单个臂获得多次反馈。设计了两种算法：1）基于Thompson采样的算法，计算高效且适用于指数级动作空间；2）最佳两界算法，在随机环境中实现方差依赖遗憾，在对抗环境中实现数据依赖遗憾。

Result: Thompson采样算法在随机环境中实现O(log T)分布依赖遗憾；最佳两界算法在随机环境中实现O(log T)方差依赖遗憾，在对抗环境中实现Õ(√T)最坏情况遗憾，且遗憾值自适应于最优动作的累积损失、总二次变差和损失序列的路径长度。数值实验显示所提算法优于现有CSB方法。

Conclusion: MP-CSB模型成功扩展了CSB的应用范围，提出的两种算法分别在计算效率和环境适应性方面表现出色，为处理非负整数动作空间的组合优化问题提供了有效解决方案。

Abstract: In the combinatorial semi-bandit (CSB) problem, a player selects an action
from a combinatorial action set and observes feedback from the base arms
included in the action. While CSB is widely applicable to combinatorial
optimization problems, its restriction to binary decision spaces excludes
important cases involving non-negative integer flows or allocations, such as
the optimal transport and knapsack problems.To overcome this limitation, we
propose the multi-play combinatorial semi-bandit (MP-CSB), where a player can
select a non-negative integer action and observe multiple feedbacks from a
single arm in each round. We propose two algorithms for the MP-CSB. One is a
Thompson-sampling-based algorithm that is computationally feasible even when
the action space is exponentially large with respect to the number of arms, and
attains $O(\log T)$ distribution-dependent regret in the stochastic regime,
where $T$ is the time horizon. The other is a best-of-both-worlds algorithm,
which achieves $O(\log T)$ variance-dependent regret in the stochastic regime
and the worst-case $\tilde{\mathcal{O}}\left( \sqrt{T} \right)$ regret in the
adversarial regime. Moreover, its regret in adversarial one is data-dependent,
adapting to the cumulative loss of the optimal action, the total quadratic
variation, and the path-length of the loss sequence. Finally, we numerically
show that the proposed algorithms outperform existing methods in the CSB
literature.

</details>


### [87] [DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition](https://arxiv.org/abs/2509.09940)
*Yifei Wang,Wenbin Wang,Yong Luo*

Main category: cs.LG

TL;DR: DyKen-Hyena模型通过将音频视觉线索转换为动态的每token卷积核来直接调制文本特征提取，而不是简单的特征融合，在多模态意图识别任务上取得了SOTA效果


<details>
  <summary>Details</summary>
Motivation: 当前多模态意图识别模型通过多头注意力等机制融合多模态特征时，可能会用噪声或无关的非语言信号污染主要语言特征，无法捕捉细粒度的token级影响

Method: 将问题从特征融合重新定义为处理调制，将音频视觉线索转换为动态的每token卷积核来直接调制文本特征提取过程

Result: 在MIntRec和MIntRec2.0基准测试中达到最先进结果，在out-of-scope检测中获得+10.46% F1分数提升

Conclusion: 该方法创建了更鲁棒的意图表示，验证了细粒度调制方法的有效性

Abstract: Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich
information from multiple sources (e.g., language, video, and audio), the
potential for intent-irrelevant and conflicting information across modalities
may hinder performance from being further improved. Most current models attempt
to fuse modalities by applying mechanisms like multi-head attention to unimodal
feature sequences and then adding the result back to the original
representation. This process risks corrupting the primary linguistic features
with noisy or irrelevant non-verbal signals, as it often fails to capture the
fine-grained, token-level influence where non-verbal cues should modulate, not
just augment, textual meaning. To address this, we introduce DyKen-Hyena, which
reframes the problem from feature fusion to processing modulation. Our model
translates audio-visual cues into dynamic, per-token convolutional kernels that
directly modulate textual feature extraction. This fine-grained approach
achieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.
Notably, it yields a +10.46% F1-score improvement in out-of-scope detection,
validating that our method creates a fundamentally more robust intent
representation.

</details>


### [88] [Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge](https://arxiv.org/abs/2509.09955)
*Omar Erak,Omar Alhussein,Hatem Abou-Zeid,Mehdi Bennis,Sami Muhaidat*

Main category: cs.LG

TL;DR: 提出无需训练的token合并框架，通过自适应合并语义冗余token来压缩transformer表示，在保持精度的同时显著降低计算和通信成本


<details>
  <summary>Details</summary>
Motivation: 大规模transformer在语义通信中计算和通信成本高，难以部署在资源受限的边缘设备上，需要一种无需重新训练的高效压缩方法

Method: 基于每层相似度阈值选择性合并语义冗余token，将合并策略发现建模为多目标优化问题，使用贝叶斯优化获得精度、推理成本和通信成本之间的帕累托最优权衡

Result: 在ImageNet分类上以30%更少的FLOPs和低于20%的原始通信成本匹配未修改transformer的精度；在VQA任务上以不到三分之一的计算量和十分之一的带宽实现与完整LLaVA模型竞争的性能

Conclusion: 该框架为在资源受限的边缘智能场景中部署强大transformer模型提供了实用且通用的解决方案，具有跨信道条件的鲁棒性和隐私保护优势

Abstract: Large-scale transformers are central to modern semantic communication, yet
their high computational and communication costs hinder deployment on
resource-constrained edge devices. This paper introduces a training-free
framework for adaptive token merging, a novel mechanism that compresses
transformer representations at runtime by selectively merging semantically
redundant tokens under per-layer similarity thresholds. Unlike prior
fixed-ratio reduction, our approach couples merging directly to input
redundancy, enabling data-dependent adaptation that balances efficiency and
task relevance without retraining. We cast the discovery of merging strategies
as a multi-objective optimization problem and leverage Bayesian optimization to
obtain Pareto-optimal trade-offs between accuracy, inference cost, and
communication cost. On ImageNet classification, we match the accuracy of the
unmodified transformer with 30\% fewer floating-point operations per second and
under 20\% of the original communication cost, while for visual question
answering our method achieves performance competitive with the full LLaVA model
at less than one-third of the compute and one-tenth of the bandwidth. Finally,
we show that our adaptive merging is robust across varying channel conditions
and provides inherent privacy benefits, substantially degrading the efficacy of
model inversion attacks. Our framework provides a practical and versatile
solution for deploying powerful transformer models in resource-limited edge
intelligence scenarios.

</details>


### [89] [Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes](https://arxiv.org/abs/2509.09960)
*Mingxuan Jiang,Yongxin Wang,Ziyue Dai,Yicun Liu,Hongyi Nie,Sen Liu,Hongfeng Chai*

Main category: cs.LG

TL;DR: ReFine是一个合成表格数据生成框架，通过从可解释模型中提取符号规则嵌入提示词来指导生成，并采用双粒度过滤策略减少分布不平衡，在数据稀缺场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有表格数据生成方法（如GANs、扩散模型、微调LLMs）需要充足参考数据，在领域特定数据库记录稀缺时效果受限。基于提示的LLMs虽然灵活但难以捕捉数据集特定的特征-标签依赖关系，且生成冗余数据导致下游任务性能下降。

Method: 提出ReFine框架：(i)从可解释模型推导符号"if-then"规则并嵌入提示词，显式指导生成朝向领域特定特征分布；(ii)应用双粒度过滤策略，抑制过采样模式并选择性精炼稀有但信息丰富的样本以减少分布不平衡。

Result: 在各种回归和分类基准测试中，ReFine始终优于最先进方法，回归任务R平方绝对提升高达0.44，分类任务F1分数相对提升10.0%。

Conclusion: ReFine通过结合符号规则引导和智能过滤策略，有效解决了数据稀缺场景下的表格数据生成问题，显著提升了生成数据的质量和下游任务性能。

Abstract: Synthetic tabular data generation is increasingly essential in data
management, supporting downstream applications when real-world and high-quality
tabular data is insufficient. Existing tabular generation approaches, such as
generative adversarial networks (GANs), diffusion models, and fine-tuned Large
Language Models (LLMs), typically require sufficient reference data, limiting
their effectiveness in domain-specific databases with scarce records. While
prompt-based LLMs offer flexibility without parameter tuning, they often fail
to capture dataset-specific feature-label dependencies and generate redundant
data, leading to degradation in downstream task performance. To overcome these
issues, we propose ReFine, a framework that (i) derives symbolic "if-then"
rules from interpretable models and embeds them into prompts to explicitly
guide generation toward domain-specific feature distribution, and (ii) applies
a dual-granularity filtering strategy that suppresses over-sampling patterns
and selectively refines rare but informative samples to reduce distributional
imbalance. Extensive experiments on various regression and classification
benchmarks demonstrate that ReFine consistently outperforms state-of-the-art
methods, achieving up to 0.44 absolute improvement in R-squared for regression
and 10.0 percent relative improvement in F1 score for classification tasks.

</details>


### [90] [Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning](https://arxiv.org/abs/2509.09991)
*Amandip Sangha*

Main category: cs.LG

TL;DR: 提出了一种基于机器学习的虚拟服务器能耗估算方法，仅使用虚拟机资源利用率指标即可预测能耗，无需物理功耗测量接口或主机特权访问


<details>
  <summary>Details</summary>
Motivation: 解决虚拟化环境（如云平台）中无法直接测量能耗的关键问题，为能源感知调度、成本优化和独立于物理主机的能耗估算提供解决方案

Method: 使用从客户虚拟机收集的资源利用率指标，训练梯度提升回归器（Gradient Boosting Regressor）来预测通过主机RAPL测量的能耗

Result: 在多样化工作负载实验中实现了高预测精度（0.90 ≤ R² ≤ 0.97），首次证明了无需主机特权访问的纯客户侧能耗估算的可行性

Conclusion: 该方法展示了在虚拟化环境中进行客户侧能耗估算的可行性，为能源管理和优化提供了新的技术途径

Abstract: This paper presents a machine learning-based approach to estimate the energy
consumption of virtual servers without access to physical power measurement
interfaces. Using resource utilization metrics collected from guest virtual
machines, we train a Gradient Boosting Regressor to predict energy consumption
measured via RAPL on the host. We demonstrate, for the first time, guest-only
resource-based energy estimation without privileged host access with
experiments across diverse workloads, achieving high predictive accuracy and
variance explained ($0.90 \leq R^2 \leq 0.97$), indicating the feasibility of
guest-side energy estimation. This approach can enable energy-aware scheduling,
cost optimization and physical host independent energy estimates in virtualized
environments. Our approach addresses a critical gap in virtualized environments
(e.g. cloud) where direct energy measurement is infeasible.

</details>


### [91] [Neural Scaling Laws for Deep Regression](https://arxiv.org/abs/2509.10000)
*Tilen Cadez,Kyoung-Min Kim*

Main category: cs.LG

TL;DR: 该论文实证研究了深度回归模型中的神经缩放定律，发现在扭曲范德瓦尔斯磁体的参数估计模型中，损失与训练数据集大小和模型容量之间存在幂律关系，缩放指数在1到2之间。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型的成功凸显了神经缩放定律的重要性，但这些定律在深度回归模型中的应用仍未被充分探索。研究者希望了解深度回归模型是否也遵循类似的缩放规律。

Method: 使用扭曲范德瓦尔斯磁体的参数估计模型，采用多种架构（包括全连接网络、残差网络和视觉变换器），在不同数据集大小和模型容量下实证研究损失函数的缩放行为。

Result: 观察到损失与训练数据集大小和模型容量之间存在幂律关系，缩放指数范围在1到2之间，具体值取决于回归参数和模型细节。

Conclusion: 一致的缩放行为和大缩放指数表明，深度回归模型的性能可以随着数据量的增加而显著提升，这为资源有限条件下的模型开发提供了重要指导。

Abstract: Neural scaling laws--power-law relationships between generalization errors
and characteristics of deep learning models--are vital tools for developing
reliable models while managing limited resources. Although the success of large
language models highlights the importance of these laws, their application to
deep regression models remains largely unexplored. Here, we empirically
investigate neural scaling laws in deep regression using a parameter estimation
model for twisted van der Waals magnets. We observe power-law relationships
between the loss and both training dataset size and model capacity across a
wide range of values, employing various architectures--including fully
connected networks, residual networks, and vision transformers. Furthermore,
the scaling exponents governing these relationships range from 1 to 2, with
specific values depending on the regressed parameters and model details. The
consistent scaling behaviors and their large scaling exponents suggest that the
performance of deep regression models can improve substantially with increasing
data size.

</details>


### [92] [Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts](https://arxiv.org/abs/2509.10025)
*Strahinja Nikolic,Ilker Oguz,Demetri Psaltis*

Main category: cs.LG

TL;DR: SMoE-VAE模型在QuickDraw数据集上通过无监督专家路由实现了优于有监督基准的重建性能，专家学习到了超越人工定义类别的有意义子类别结构。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络内部组织是深度学习可解释性的基本挑战，需要探索新的架构来揭示数据的内在结构。

Method: 提出稀疏专家混合变分自编码器(SMoE-VAE)，在QuickDraw数据集上比较无监督专家路由与有监督基准，使用t-SNE可视化和重建分析研究模型如何发现数据基础结构。

Result: 无监督路由始终获得更优的重建性能，专家学习到超越人工类别边界的有意义子类别结构，研究还揭示了数据集大小与专家专业化之间的权衡关系。

Conclusion: MoE模型能够发现比预定义标签更符合模型目标的数据基础结构，为设计高效MoE架构提供了指导。

Abstract: Understanding the internal organization of neural networks remains a
fundamental challenge in deep learning interpretability. We address this
challenge by exploring a novel Sparse Mixture of Experts Variational
Autoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw
dataset, comparing unsupervised expert routing against a supervised baseline
guided by ground-truth labels. Surprisingly, we find that unsupervised routing
consistently achieves superior reconstruction performance. The experts learn to
identify meaningful sub-categorical structures that often transcend
human-defined class boundaries. Through t-SNE visualizations and reconstruction
analysis, we investigate how MoE models uncover fundamental data structures
that are more aligned with the model's objective than predefined labels.
Furthermore, our study on the impact of dataset size provides insights into the
trade-offs between data quantity and expert specialization, offering guidance
for designing efficient MoE architectures.

</details>


### [93] [Sparse Coding Representation of 2-way Data](https://arxiv.org/abs/2509.10033)
*Boya Ma,Abram Magner,Maxwell McNeil,Petko Bogdanov*

Main category: cs.LG

TL;DR: 提出了一种用于稀疏字典编码的低秩编码模型AODL，通过凸松弛和交替优化方法学习字典，在保证重构质量的同时获得更稀疏的解，并展示了在数据重构和缺失值填补方面的优异性能


<details>
  <summary>Details</summary>
Motivation: 解决多字典场景下字典学习和编码系数计算的挑战，传统数据无关的分析字典虽然实现高效但稀疏性不足，而数据驱动的学习字典虽然更准确但学习过程复杂，特别是在多字典组合时计算复杂度高

Method: 提出低秩编码模型用于双字典场景，建立样本复杂度边界，设计凸松弛解决方案AODL，通过稀疏编码矩阵和学习字典之间的交替优化实现收敛

Result: AODL在固定重构质量下比非低秩和固定分析字典基线学习到稀疏90%的解，在合成和真实数据集上展示了优秀的数据重构和缺失值填补性能，学习到的字典能揭示训练样本中的可解释模式

Conclusion: 低秩编码模型AODL有效解决了多字典学习问题，在保持重构质量的同时显著提高了稀疏性，为稀疏字典编码提供了更高效的解决方案

Abstract: Sparse dictionary coding represents signals as linear combinations of a few
dictionary atoms. It has been applied to images, time series, graph signals and
multi-way spatio-temporal data by jointly employing temporal and spatial
dictionaries. Data-agnostic analytical dictionaries, such as the discrete
Fourier transform, wavelets and graph Fourier, have seen wide adoption due to
efficient implementations and good practical performance. On the other hand,
dictionaries learned from data offer sparser and more accurate solutions but
require learning of both the dictionaries and the coding coefficients. This
becomes especially challenging for multi-dictionary scenarios since encoding
coefficients correspond to all atom combinations from the dictionaries. To
address this challenge, we propose a low-rank coding model for 2-dictionary
scenarios and study its data complexity. Namely, we establish a bound on the
number of samples needed to learn dictionaries that generalize to unseen
samples from the same distribution. We propose a convex relaxation solution,
called AODL, whose exact solution we show also solves the original problem. We
then solve this relaxation via alternating optimization between the sparse
coding matrices and the learned dictionaries, which we prove to be convergent.
We demonstrate its quality for data reconstruction and missing value imputation
in both synthetic and real-world datasets. For a fixed reconstruction quality,
AODL learns up to 90\% sparser solutions compared to non-low-rank and
analytical (fixed) dictionary baselines. In addition, the learned dictionaries
reveal interpretable insights into patterns present within the samples used for
training.

</details>


### [94] [Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability](https://arxiv.org/abs/2509.10034)
*Sahil Rajesh Dhayalkar*

Main category: cs.LG

TL;DR: 本文提出了一个形式化理论，证明概率有限自动机(PFAs)可以通过符号前馈神经网络精确模拟，实现了概率自动机理论与神经架构的代数统一。


<details>
  <summary>Details</summary>
Motivation: 弥合符号计算与深度学习之间的差距，将概率自动机理论与神经网络架构在严格的代数框架下统一起来。

Method: 使用符号前馈神经网络架构，将状态分布表示为向量，转移表示为随机矩阵，通过矩阵-向量乘积实现概率状态传播，采用软更新而非递归的方式。

Result: 证明了PFAs与特定类别神经网络的等价性，展示了这些符号模拟器不仅具有表达性而且可学习：通过标准梯度下降优化，能够从标注序列数据中恢复真实PFAs的精确行为。

Conclusion: 该工作通过形式化代数框架统一了概率自动机理论和神经架构，为符号计算与深度学习的融合提供了理论基础，其中可学习性（Proposition 5.1）是核心贡献。

Abstract: We present a formal and constructive theory showing that probabilistic finite
automata (PFAs) can be exactly simulated using symbolic feedforward neural
networks. Our architecture represents state distributions as vectors and
transitions as stochastic matrices, enabling probabilistic state propagation
via matrix-vector products. This yields a parallel, interpretable, and
differentiable simulation of PFA dynamics using soft updates-without
recurrence. We formally characterize probabilistic subset construction,
$\varepsilon$-closure, and exact simulation via layered symbolic computation,
and prove equivalence between PFAs and specific classes of neural networks. We
further show that these symbolic simulators are not only expressive but
learnable: trained with standard gradient descent-based optimization on labeled
sequence data, they recover the exact behavior of ground-truth PFAs. This
learnability, formalized in Proposition 5.1, is the crux of this work. Our
results unify probabilistic automata theory with neural architectures under a
rigorous algebraic framework, bridging the gap between symbolic computation and
deep learning.

</details>


### [95] [FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection](https://arxiv.org/abs/2509.10041)
*Mohammad Hasan Narimani,Mostafa Tavassolipour*

Main category: cs.LG

TL;DR: FedRP是一种新颖的联邦学习算法，结合随机投影和ADMM优化框架，在保护隐私的同时降低通信成本，提供强差分隐私保证。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护用户隐私方面面临挑战，包括隐私攻击风险和通信成本管理问题，需要一种既能保护隐私又能降低通信开销的解决方案。

Method: 提出FedRP算法，集成随机投影技术和ADMM优化框架，通过随机投影降低模型参数维度后再传输到中央服务器。

Result: 实验结果显示FedRP不仅保持高模型精度，在隐私保护和通信效率方面均优于现有方法，包括传统差分隐私方法和FedADMM。

Conclusion: FedRP算法成功解决了联邦学习中的隐私保护和通信成本问题，提供了强大的(ε,δ)-差分隐私保证，对数据重构攻击具有弹性。

Abstract: Federated learning (FL) offers an innovative paradigm for collaborative model
training across decentralized devices, such as smartphones, balancing enhanced
predictive performance with the protection of user privacy in sensitive areas
like Internet of Things (IoT) and medical data analysis. Despite its
advantages, FL encounters significant challenges related to user privacy
protection against potential attacks and the management of communication costs.
This paper introduces a novel federated learning algorithm called FedRP, which
integrates random projection techniques with the Alternating Direction Method
of Multipliers (ADMM) optimization framework. This approach enhances privacy by
employing random projection to reduce the dimensionality of model parameters
prior to their transmission to a central server, reducing the communication
cost. The proposed algorithm offers a strong $(\epsilon, \delta)$-differential
privacy guarantee, demonstrating resilience against data reconstruction
attacks. Experimental results reveal that FedRP not only maintains high model
accuracy but also outperforms existing methods, including conventional
differential privacy approaches and FedADMM, in terms of both privacy
preservation and communication efficiency.

</details>


### [96] [Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data](https://arxiv.org/abs/2509.10048)
*Madhushan Ramalingam*

Main category: cs.LG

TL;DR: 本文评估了在TabPFN中集成VBLL方法对不确定性校准的效果，发现在三个医疗表格数据集上，原始TabPFN在不确定性校准方面始终优于VBLL集成版本。


<details>
  <summary>Details</summary>
Motivation: 在医疗诊断等安全关键应用中，可靠的不确定性估计至关重要。TabPFN是新兴的表格数据基础模型，而VBLL是最先进的轻量级变分方法，本研究旨在评估两者结合在不确定性校准中的性能。

Method: 在三个基准医疗表格数据集上进行实验，比较原始TabPFN和VBLL集成版本的性能，重点关注不确定性校准效果。

Result: 与预期相反，原始TabPFN在所有数据集上的不确定性校准表现都优于VBLL集成版本。

Conclusion: VBLL集成并未提升TabPFN的不确定性校准性能，原始TabPFN在此任务上表现更佳。

Abstract: Predictive models are being increasingly used across a wide range of domains,
including safety-critical applications such as medical diagnosis and criminal
justice. Reliable uncertainty estimation is a crucial task in such settings.
Tabular Prior-data Fitted Network (TabPFN) is a recently proposed machine
learning foundation model for tabular dataset, which uses a generative
transformer architecture. Variational Bayesian Last Layers (VBLL) is a
state-of-the-art lightweight variational formulation that effectively improves
uncertainty estimation with minimal computational overhead. In this work we aim
to evaluate the performance of VBLL integrated with the recently proposed
TabPFN in uncertainty calibration. Our experiments, conducted on three
benchmark medical tabular datasets, compare the performance of the original
TabPFN and the VBLL-integrated version. Contrary to expectations, we observed
that original TabPFN consistently outperforms VBLL integrated TabPFN in
uncertainty calibration across all datasets.

</details>


### [97] [KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework](https://arxiv.org/abs/2509.10089)
*Marco Andrea Bühler,Gonzalo Guillén-Gosálbez*

Main category: cs.LG

TL;DR: KAN-SR是一个基于Kolmogorov Arnold Networks的新型符号回归框架，采用分治法，结合深度学习技术和简化策略，能够准确恢复Feynman SRSD数据集中的真实方程，并能精确建模生物过程系统的动力学。


<details>
  <summary>Details</summary>
Motivation: 传统符号回归通常使用遗传编程方法，本文旨在利用深度学习技术开发更有效的符号回归框架，提高方程发现的准确性和效率。

Method: 使用Kolmogorov Arnold Networks（KANs）构建分治法框架，结合平移对称性和可分离性等简化策略，并与神经控制微分方程结合进行动态建模。

Result: 成功恢复了Feynman SRSD数据集中的真实方程，并精确建模了硅基生物过程系统的动力学行为。

Conclusion: KAN-SR框架为符号回归提供了新的深度学习解决方案，在科学发现和工程系统动态建模方面具有重要应用潜力。

Abstract: We introduce a novel symbolic regression framework, namely KAN-SR, built on
Kolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.
Symbolic regression searches for mathematical equations that best fit a given
dataset and is commonly solved with genetic programming approaches. We show
that by using deep learning techniques, more specific KANs, and combining them
with simplification strategies such as translational symmetries and
separabilities, we are able to recover ground-truth equations of the Feynman
Symbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we
show that by combining the proposed framework with neural controlled
differential equations, we are able to model the dynamics of an in-silico
bioprocess system precisely, opening the door for the dynamic modeling of other
engineering systems.

</details>


### [98] [Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning](https://arxiv.org/abs/2509.10132)
*Nour Jamoussi,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.LG

TL;DR: 提出了一种基于信息几何投影的贝叶斯联邦学习个性化框架，通过将全局模型投影到用户本地模型的邻域，实现全局泛化与本地特化的可调权衡，计算成本低且效果显著


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯联邦学习方法通常依赖MCMC采样或变分推断，需要复杂的个性化机制来适应异构数据分布，需要更高效且理论完备的个性化方法

Method: 信息几何投影框架，将全局模型投影到用户本地模型的统计流形邻域，证明该投影等价于计算统计流形上的重心，获得闭式解，结合IVON优化器应用于变分学习

Result: 在异构数据分布下的实证评估表明，该方法能有效平衡全局和本地性能，且计算开销极小

Conclusion: 提出的信息几何投影框架为贝叶斯联邦学习提供了一种理论完备、计算高效且效果显著的个性化方法，能够灵活权衡全局泛化与本地特化

Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with
decentralized training, enabling the development of personalized and reliable
models under data heterogeneity and privacy constraints. Existing approaches
typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational
inference, often incorporating personalization mechanisms to better adapt to
local data distributions. In this work, we propose an information-geometric
projection framework for personalization in parametric BFL. By projecting the
global model onto a neighborhood of the user's local model, our method enables
a tunable trade-off between global generalization and local specialization.
Under mild assumptions, we show that this projection step is equivalent to
computing a barycenter on the statistical manifold, allowing us to derive
closed-form solutions and achieve cost-free personalization. We apply the
proposed approach to a variational learning setup using the Improved
Variational Online Newton (IVON) optimizer and extend its application to
general aggregation schemes in BFL. Empirical evaluations under heterogeneous
data distributions confirm that our method effectively balances global and
local performance with minimal computational overhead.

</details>


### [99] [BenchECG and xECG: a benchmark and baseline for ECG foundation models](https://arxiv.org/abs/2509.10151)
*Riccardo Lunelli,Angus Nicolson,Samuel Martin Pröll,Sebastian Johannes Reinstadler,Axel Bauer,Clemens Dlaska*

Main category: cs.LG

TL;DR: 提出了BenchECG标准化基准和xECG模型，通过统一评估框架解决ECG基础模型缺乏公平比较的问题，xECG在多个数据集和任务上表现最佳


<details>
  <summary>Details</summary>
Motivation: 现有的ECG基础模型研究缺乏一致的评估标准，使用不同的任务选择和数据集，导致难以进行公平比较，阻碍了该领域的发展

Method: 开发BenchECG标准化基准，包含全面的公开ECG数据集和多样化任务；提出基于xLSTM的xECG模型，使用SimDINOv2自监督学习进行训练

Result: xECG在BenchECG基准测试中获得了最佳分数，是唯一在所有数据集和任务上都表现优异的公开可用模型，性能优于现有方法

Conclusion: BenchECG通过标准化评估实现了严格比较，将加速ECG表示学习的进展；xECG为未来ECG基础模型设立了新的性能基准

Abstract: Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to
deep learning. Recently, interest has grown in developing foundation models for
ECGs - models that generalise across diverse downstream tasks. However,
consistent evaluation has been lacking: prior work often uses narrow task
selections and inconsistent datasets, hindering fair comparison. Here, we
introduce BenchECG, a standardised benchmark comprising a comprehensive suite
of publicly available ECG datasets and versatile tasks. We also propose xECG,
an xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,
which achieves the best BenchECG score compared to publicly available
state-of-the-art models. In particular, xECG is the only publicly available
model to perform strongly on all datasets and tasks. By standardising
evaluation, BenchECG enables rigorous comparison and aims to accelerate
progress in ECG representation learning. xECG achieves superior performance
over earlier approaches, defining a new baseline for future ECG foundation
models.

</details>


### [100] [FedBiF: Communication-Efficient Federated Learning via Bits Freezing](https://arxiv.org/abs/2509.10161)
*Shiwei Li,Qunwei Li,Haozhao Wang,Ruixuan Li,Jianbin Lin,Wenliang Zhong*

Main category: cs.LG

TL;DR: FedBiF是一种新颖的联邦学习框架，通过在本地训练期间直接学习量化模型参数，每次只更新一个比特位，实现高效通信压缩的同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习存在显著的通信开销问题，现有量化方法通常在本地训练后应用量化，导致量化误差影响模型精度。

Method: 服务器先量化模型参数并传输给客户端，每个客户端在本地训练时只更新多比特参数表示中的单个比特，冻结其余比特，实现逐比特更新策略。

Result: 在5个常用数据集上的IID和非IID设置下，FedBiF实现了优异的通信压缩效果，模型稀疏度提升，仅使用1bpp上行和3bpp下行通信即可达到与FedAvg相当的精度。

Conclusion: FedBiF框架有效解决了联邦学习的通信效率问题，在保持模型精度的同时显著降低了通信成本，具有实际应用价值。

Abstract: Federated learning (FL) is an emerging distributed machine learning paradigm
that enables collaborative model training without sharing local data. Despite
its advantages, FL suffers from substantial communication overhead, which can
affect training efficiency. Recent efforts have mitigated this issue by
quantizing model updates to reduce communication costs. However, most existing
methods apply quantization only after local training, introducing quantization
errors into the trained parameters and potentially degrading model accuracy. In
this paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework
that directly learns quantized model parameters during local training. In each
communication round, the server first quantizes the model parameters and
transmits them to the clients. FedBiF then allows each client to update only a
single bit of the multi-bit parameter representation, freezing the remaining
bits. This bit-by-bit update strategy reduces each parameter update to one bit
while maintaining high precision in parameter representation. Extensive
experiments are conducted on five widely used datasets under both IID and
Non-IID settings. The results demonstrate that FedBiF not only achieves
superior communication compression but also promotes sparsity in the resulting
models. Notably, FedBiF attains accuracy comparable to FedAvg, even when using
only 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.
The code is available at https://github.com/Leopold1423/fedbif-tpds25.

</details>


### [101] [Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks](https://arxiv.org/abs/2509.10163)
*Francisco Javier Esono Nkulu Andong,Qi Min*

Main category: cs.LG

TL;DR: 提出了一种联邦多智能体强化学习框架(Fed-MARL)，用于6G超密集边缘网络中的隐私保护、实时资源管理，通过跨层协调MAC层和应用层实现能效优化。


<details>
  <summary>Details</summary>
Motivation: 6G网络向超密集智能边缘环境发展，需要在严格隐私、移动性和能量约束下实现高效资源管理，传统集中式方法面临隐私泄露和可扩展性问题。

Method: 采用联邦多智能体强化学习框架，每个智能体使用深度循环Q网络(DRQN)学习去中心化策略，结合基于椭圆曲线Diffie-Hellman密钥交换的安全聚合协议保护隐私，将资源管理问题建模为部分可观测多智能体马尔可夫决策过程。

Result: 仿真结果表明Fed-MARL在任务成功率、延迟、能效和公平性方面优于集中式MARL和启发式基线方法，同时确保强大的隐私保护和动态6G边缘网络中的可扩展性。

Conclusion: Fed-MARL框架为6G边缘网络提供了一种有效的隐私保护资源管理解决方案，能够同时优化延迟、能效、频谱效率、公平性和可靠性，满足URLLC、eMBB和mMTC等6G特定服务需求。

Abstract: As sixth-generation (6G) networks move toward ultra-dense, intelligent edge
environments, efficient resource management under stringent privacy, mobility,
and energy constraints becomes critical. This paper introduces a novel
Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework that
incorporates cross-layer orchestration of both the MAC layer and application
layer for energy-efficient, privacy-preserving, and real-time resource
management across heterogeneous edge devices. Each agent uses a Deep Recurrent
Q-Network (DRQN) to learn decentralized policies for task offloading, spectrum
access, and CPU energy adaptation based on local observations (e.g., queue
length, energy, CPU usage, and mobility). To protect privacy, we introduce a
secure aggregation protocol based on elliptic curve Diffie Hellman key
exchange, which ensures accurate model updates without exposing raw data to
semi-honest adversaries. We formulate the resource management problem as a
partially observable multi-agent Markov decision process (POMMDP) with a
multi-objective reward function that jointly optimizes latency, energy
efficiency, spectral efficiency, fairness, and reliability under 6G-specific
service requirements such as URLLC, eMBB, and mMTC. Simulation results
demonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines
in task success rate, latency, energy efficiency, and fairness, while ensuring
robust privacy protection and scalability in dynamic, resource-constrained 6G
edge networks.

</details>


### [102] [A Symmetry-Integrated Approach to Surface Code Decoding](https://arxiv.org/abs/2509.10164)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: cs.LG

TL;DR: 提出一种通过神经网络连续函数逼近来重新优化表面码解码器的技术，解决了传统方法因非唯一性预测只能获取错误概率分布的问题，在不同网络架构和码距下均提高了解码精度


<details>
  <summary>Details</summary>
Motivation: 量子纠错对于实用量子计算至关重要，但传统表面码解码器因非唯一性预测问题只能获取错误概率分布，无法获得唯一正确预测

Method: 使用神经网络数学插值近似综合征测量，将解码问题重构为回归问题，通过连续函数逼近来重新优化解码器模型

Result: 在码距5和7的多层感知机解码器，以及码距5的卷积神经网络、循环神经网络和Transformer解码器上，重新优化的解码器都比原始模型精度更高

Conclusion: 将表面码解码问题重构为可由深度学习处理的回归问题是一个有效的策略，所提方法具有普遍有效性，不受码距或网络架构影响

Abstract: Quantum error correction, which utilizes logical qubits that are encoded as
redundant multiple physical qubits to find and correct errors in physical
qubits, is indispensable for practical quantum computing. Surface code is
considered to be a promising encoding method with a high error threshold that
is defined by stabilizer generators. However, previous methods have suffered
from the problem that the decoder acquires solely the error probability
distribution because of the non-uniqueness of correct prediction obtained from
the input. To circumvent this problem, we propose a technique to reoptimize the
decoder model by approximating syndrome measurements with a continuous function
that is mathematically interpolated by neural network. We evaluated the
improvement in accuracy of a multilayer perceptron based decoder for code
distances of 5 and 7 as well as for decoders based on convolutional and
recurrent neural networks and transformers for a code distance of 5. In all
cases, the reoptimized decoder gave better accuracy than the original models,
demonstrating the universal effectiveness of the proposed method that is
independent of code distance or network architecture. These results suggest
that re-framing the problem of surface code decoding into a regression problem
that can be tackled by deep learning is a useful strategy.

</details>


### [103] [The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams](https://arxiv.org/abs/2509.10167)
*Lénaïc Chizat*

Main category: cs.LG

TL;DR: 该论文研究了深度残差网络在标准随机初始化下的梯度训练动态，证明了当深度趋于无穷时，训练动态收敛到神经平均ODE，并给出了输出与极限之间的误差界。


<details>
  <summary>Details</summary>
Motivation: 研究大深度残差网络的训练动态，特别是理解不同残差缩放参数对特征学习完整性的影响，为Transformer等实际模型提供理论支撑。

Method: 使用数学分析工具，包括随机近似和传播混沌理论，分析残差网络的前向和后向传播行为，推导训练动态收敛到平均ODE的误差界。

Result: 证明了残差缩放参数Θ(α/LM)下的误差界为O(1/L + α/√LM)，当α=Θ(1)时实现完整特征学习，α→∞时进入惰性ODE机制。对于两层感知机块，完整特征学习需要Θ(√D/LM)的缩放。

Conclusion: 该研究为深度残差网络的训练动态提供了严格的数学框架，揭示了不同缩放参数对特征学习机制的影响，对理解实际深度学习模型的训练行为具有重要意义。

Abstract: We study the gradient-based training of large-depth residual networks
(ResNets) from standard random initializations. We show that with a diverging
depth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,
the training dynamics converges to a Neural Mean ODE training dynamics.
Remarkably, the limit is independent of the scaling of $M$, covering practical
cases of, say, Transformers, where $M$ (the number of hidden units or attention
heads per layer) is typically of the order of $D$. For a residual scale
$\Theta_D\big(\frac{\alpha}{LM}\big)$, we obtain the error bound
$O_D\big(\frac{1}{L}+ \frac{\alpha}{\sqrt{LM}}\big)$ between the model's output
and its limit after a fixed number gradient of steps, and we verify empirically
that this rate is tight. When $\alpha=\Theta(1)$, the limit exhibits complete
feature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In
contrast, we show that $\alpha \to \infty$ yields a \lazy ODE regime where the
Mean ODE is linearly parameterized. We then focus on the particular case of
ResNets with two-layer perceptron blocks, for which we study how these scalings
depend on the embedding dimension $D$. We show that for this model, the only
residual scale that leads to complete feature learning is
$\Theta\big(\frac{\sqrt{D}}{LM}\big)$. In this regime, we prove the error bound
$O\big(\frac{1}{L}+ \frac{\sqrt{D}}{\sqrt{LM}}\big)$ between the ResNet and its
limit after a fixed number of gradient steps, which is also empirically tight.
Our convergence results rely on a novel mathematical perspective on ResNets :
(i) due to the randomness of the initialization, the forward and backward pass
through the ResNet behave as the stochastic approximation of certain mean ODEs,
and (ii) by propagation of chaos (that is, asymptotic independence of the
units) this behavior is preserved through the training dynamics.

</details>


### [104] [P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context](https://arxiv.org/abs/2509.10186)
*Benjamin Holzschuh,Georg Kohl,Florian Redinger,Nils Thuerey*

Main category: cs.LG

TL;DR: 提出了一个可扩展的框架，用于学习高分辨率3D物理模拟的确定性和概率性神经代理模型，通过混合CNN-Transformer架构在速度和精度上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决高分辨率3D物理模拟的计算成本高和内存需求大的问题，开发一个能够在小块模拟域上预训练并融合成全局解决方案的高效神经代理模型。

Method: 采用混合CNN-Transformer主干架构，支持在小块模拟域上预训练，通过序列到序列模型融合全局解并包含长程依赖关系，还可作为扩散模型生成概率样本。

Result: 在14种不同类型3D PDE动力学学习任务中显著优于基线方法，可扩展到512^3空间分辨率的高分辨率各向同性湍流，并能准确捕捉不同雷诺数下高度湍流3D通道流的统计特性。

Conclusion: 该框架提供了一种高效、可扩展的方法来构建高分辨率3D物理模拟的神经代理模型，在保持准确性的同时大幅降低了计算和内存需求，展现了在复杂物理系统建模中的广泛应用潜力。

Abstract: We present a scalable framework for learning deterministic and probabilistic
neural surrogates for high-resolution 3D physics simulations. We introduce a
hybrid CNN-Transformer backbone architecture targeted for 3D physics
simulations, which significantly outperforms existing architectures in terms of
speed and accuracy. Our proposed network can be pretrained on small patches of
the simulation domain, which can be fused to obtain a global solution,
optionally guided via a fast and scalable sequence-to-sequence model to include
long-range dependencies. This setup allows for training large-scale models with
reduced memory and compute requirements for high-resolution datasets. We
evaluate our backbone architecture against a large set of baseline methods with
the objective to simultaneously learn the dynamics of 14 different types of
PDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic
turbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate
the versatility of our network by training it as a diffusion model to produce
probabilistic samples of highly turbulent 3D channel flows across varying
Reynolds numbers, accurately capturing the underlying flow statistics.

</details>


### [105] [Hadamard-Riemannian Optimization for Margin-Variance Ensemble](https://arxiv.org/abs/2509.10189)
*Zexu Jin*

Main category: cs.LG

TL;DR: 提出了一种新的集成学习框架，通过将边际方差纳入损失函数并重新参数化集成权重到单位球面，解决了传统边际方法忽略方差和计算效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于边际的集成方法主要关注最大化期望边际而忽略边际方差的重要性，这限制了模型的泛化能力并增加了过拟合风险，特别是在噪声或不平衡数据集中。同时，传统方法在概率单纯形中优化集成权重存在计算效率低和可扩展性差的问题。

Method: 提出了一种新的集成学习框架，将边际方差显式纳入损失函数，联合优化负期望边际及其方差。通过将集成权重重新参数化到单位球面，简化了优化过程并提高了计算效率。

Result: 在多个基准数据集上的广泛实验表明，所提出的方法 consistently 优于传统的基于边际的集成技术，证明了其有效性和实用性。

Conclusion: 该框架通过同时考虑期望边际和边际方差，显著提高了集成学习的鲁棒性和泛化性能，同时通过创新的权重参数化方法解决了计算效率问题，为大规模应用提供了可行的解决方案。

Abstract: Ensemble learning has been widely recognized as a pivotal technique for
boosting predictive performance by combining multiple base models.
Nevertheless, conventional margin-based ensemble methods predominantly focus on
maximizing the expected margin while neglecting the critical role of margin
variance, which inherently restricts the generalization capability of the model
and heightens its vulnerability to overfitting, particularly in noisy or
imbalanced datasets. Additionally, the conventional approach of optimizing
ensemble weights within the probability simplex often introduces computational
inefficiency and scalability challenges, complicating its application to
large-scale problems. To tackle these limitations, this paper introduces a
novel ensemble learning framework that explicitly incorporates margin variance
into the loss function. Our method jointly optimizes the negative expected
margin and its variance, leading to enhanced robustness and improved
generalization performance. Moreover, by reparameterizing the ensemble weights
onto the unit sphere, we substantially simplify the optimization process and
improve computational efficiency. Extensive experiments conducted on multiple
benchmark datasets demonstrate that the proposed approach consistently
outperforms traditional margin-based ensemble techniques, underscoring its
effectiveness and practical utility.

</details>


### [106] [A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures](https://arxiv.org/abs/2509.10227)
*Ángel Ladrón,Miguel Sánchez-Domínguez,Javier Rozalén,Fernando R. Sánchez,Javier de Vicente,Lucas Lacasa,Eusebio Valero,Gonzalo Rubio*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的飞机机翼疲劳寿命预测管道，通过飞行参数快速估算疲劳寿命，作为传统工程方法的补充。


<details>
  <summary>Details</summary>
Motivation: 传统疲劳寿命预测方法耗时且复杂，需要多团队协作和大量有限元模拟。机器学习可以提供快速迭代和泛化能力，减少计算资源和人力需求。

Method: 开发基于机器学习的管道，根据飞机整个运行寿命期间不同任务的飞行参数，预测机翼不同位置的疲劳寿命。

Result: 在真实的疲劳寿命估算用例中验证了管道，获得了准确的预测结果，并进行了全面的统计验证和不确定性量化。

Conclusion: 该机器学习管道能够显著减少昂贵的模拟次数，降低计算和人力资源需求，是对传统方法的有力补充。

Abstract: Fatigue life prediction is essential in both the design and operational
phases of any aircraft, and in this sense safety in the aerospace industry
requires early detection of fatigue cracks to prevent in-flight failures.
Robust and precise fatigue life predictors are thus essential to ensure safety.
Traditional engineering methods, while reliable, are time consuming and involve
complex workflows, including steps such as conducting several Finite Element
Method (FEM) simulations, deriving the expected loading spectrum, and applying
cycle counting techniques like peak-valley or rainflow counting. These steps
often require collaboration between multiple teams and tools, added to the
computational time and effort required to achieve fatigue life predictions.
Machine learning (ML) offers a promising complement to traditional fatigue life
estimation methods, enabling faster iterations and generalization, providing
quick estimates that guide decisions alongside conventional simulations.
  In this paper, we present a ML-based pipeline that aims to estimate the
fatigue life of different aircraft wing locations given the flight parameters
of the different missions that the aircraft will be operating throughout its
operational life. We validate the pipeline in a realistic use case of fatigue
life estimation, yielding accurate predictions alongside a thorough statistical
validation and uncertainty quantification. Our pipeline constitutes a
complement to traditional methodologies by reducing the amount of costly
simulations and, thereby, lowering the required computational and human
resources.

</details>


### [107] [Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](https://arxiv.org/abs/2509.10248)
*Janis Keuper*

Main category: cs.LG

TL;DR: 本文通过系统评估发现，简单的提示词注入攻击对LLM同行评审高度有效（可达100%接受率），且LLM评审普遍存在接受偏向（>95%），这对LLM在学术评审中的应用讨论具有重要影响。


<details>
  <summary>Details</summary>
Motivation: 针对近期关于作者使用隐藏提示词注入操纵LLM同行评审分数的报道，研究此类攻击的可行性和技术成功率，以评估其对学术评审辩论的影响。

Method: 使用多种LLM对2024年ICLR会议的1000篇论文评审进行系统评估，分析提示词注入攻击的效果和LLM评审的偏向性。

Result: 1) 非常简单的提示词注入攻击高度有效，最高可达100%的接受率；2) LLM评审普遍存在接受偏向，许多模型的接受率超过95%。

Conclusion: 研究结果对LLM在同行评审中的使用讨论具有重大影响，揭示了当前LLM评审系统的脆弱性和系统性偏向问题。

Abstract: The ongoing intense discussion on rising LLM usage in the scientific
peer-review process has recently been mingled by reports of authors using
hidden prompt injections to manipulate review scores. Since the existence of
such "attacks" - although seen by some commentators as "self-defense" - would
have a great impact on the further debate, this paper investigates the
practicability and technical success of the described manipulations. Our
systematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide
range of LLMs shows two distinct results: I) very simple prompt injections are
indeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews
are generally biased toward acceptance (>95% in many models). Both results have
great impact on the ongoing discussions on LLM usage in peer-review.

</details>


### [108] [Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning](https://arxiv.org/abs/2509.10273)
*Sahil Sethi,Kai Sundmacher,Caroline Ganzer*

Main category: cs.LG

TL;DR: 提出基于神经推荐系统的迁移学习框架，利用COSMO-RS模拟数据和稀疏实验数据，准确预测离子液体的五种关键热物理性质


<details>
  <summary>Details</summary>
Motivation: 离子液体具有可定制的物理化学性质，但由于化学设计空间巨大和实验数据有限，准确预测其热物理性质仍具挑战性

Method: 两阶段方法：首先在固定温度压力下使用COSMO-RS模拟数据预训练神经推荐系统，学习阴阳离子的性质特异性结构嵌入；然后使用这些嵌入和变温变压实验数据微调简单前馈神经网络

Result: 预训练的密度、粘度和热容模型用于微调所有五种目标性质模型，其中四种性质的性能显著提升。模型对未见过的离子液体具有稳健的外推能力，可为超过70万种离子液体组合提供性质预测

Conclusion: 该工作展示了结合模拟数据和迁移学习来克服实验数据稀疏性的有效性，为离子液体筛选提供了可扩展的解决方案

Abstract: Ionic liquids (ILs) have emerged as versatile replacements for traditional
solvents because their physicochemical properties can be precisely tailored to
various applications. However, accurately predicting key thermophysical
properties remains challenging due to the vast chemical design space and the
limited availability of experimental data. In this study, we present a
data-driven transfer learning framework that leverages a neural recommender
system (NRS) to enable reliable property prediction for ILs using sparse
experimental datasets. The approach involves a two-stage process: first,
pre-training NRS models on COSMO-RS-based simulated data at fixed temperature
and pressure to learn property-specific structural embeddings for cations and
anions; and second, fine-tuning simple feedforward neural networks using these
embeddings with experimental data at varying temperatures and pressures. In
this work, five essential IL properties are considered: density, viscosity,
surface tension, heat capacity, and melting point. The framework supports both
within-property and cross-property knowledge transfer. Notably, pre-trained
models for density, viscosity, and heat capacity are used to fine-tune models
for all five target properties, achieving improved performance by a substantial
margin for four of them. The model exhibits robust extrapolation to previously
unseen ILs. Moreover, the final trained models enable property prediction for
over 700,000 IL combinations, offering a scalable solution for IL screening in
process design. This work highlights the effectiveness of combining simulated
data and transfer learning to overcome sparsity in the experimental data.

</details>


### [109] [Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case](https://arxiv.org/abs/2509.10291)
*Salih Toprak,Muge Erel-Ozcevik*

Main category: cs.LG

TL;DR: 提出基于SDN和AutoML的Proof of AutoML架构，利用机器学习回归模型的随机输出作为区块链nonce生成器，确保灾后能源交易的安全性和可追溯性


<details>
  <summary>Details</summary>
Motivation: 在灾害场景中传统能源基础设施受损时，需要确保太阳能家庭与移动充电单元之间能源交易的安全性和可追溯性，而区块链网络需要强大的随机nonce生成机制

Method: 采用SDN架构实现灵活的数据流和能源路由控制，利用五种AutoML选择的回归模型（梯度提升、LightGBM、随机森林、额外树和K近邻）生成随机nonce候选值，通过9000样本数据集评估模型的随机性而非准确性

Result: 随机森林和额外树回归器表现出完全的随机性依赖，梯度提升、K近邻和LightGBM分别达到97.6%、98.8%和99.9%的随机性得分，树基集成模型特别适合作为轻量级nonce生成器

Conclusion: 某些机器学习模型，特别是树基集成方法，可以作为区块链安全、SDN基础的能源交易基础设施中有效且轻量的nonce生成器，增强灾后条件的韧性

Abstract: In disaster scenarios where conventional energy infrastructure is
compromised, secure and traceable energy trading between solar-powered
households and mobile charging units becomes a necessity. To ensure the
integrity of such transactions over a blockchain network, robust and
unpredictable nonce generation is vital. This study proposes an SDN-enabled
architecture where machine learning regressors are leveraged not for their
accuracy, but for their potential to generate randomized values suitable as
nonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN
allows flexible control over data flows and energy routing policies even in
fragmented or degraded networks, ensuring adaptive response during emergencies.
Using a 9000-sample dataset, we evaluate five AutoML-selected regression models
- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest
Neighbors - not by their prediction accuracy, but by their ability to produce
diverse and non-deterministic outputs across shuffled data inputs. Randomness
analysis reveals that Random Forest and Extra Trees regressors exhibit complete
dependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and
LightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and
99.9%, respectively). These findings highlight that certain machine learning
models, particularly tree-based ensembles, may serve as effective and
lightweight nonce generators within blockchain-secured, SDN-based energy
trading infrastructures resilient to disaster conditions.

</details>


### [110] [Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data](https://arxiv.org/abs/2509.10303)
*Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang*

Main category: cs.LG

TL;DR: 提出CDQAC离线强化学习算法，直接从历史数据学习作业车间调度策略，无需在线交互，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统在线RL方法需要大量模拟环境交互且样本效率低，无法捕捉真实世界复杂性，需要直接从历史数据学习调度策略的离线方法

Method: CDQAC结合分位数critic和延迟策略更新，估计每个机器-操作对的回报分布而非直接选择，能够从次优训练数据中改进

Result: CDQAC显著优于原始数据生成启发式算法和现有离线/在线RL基线，仅需10-20个训练实例即可学习高质量策略，且在随机启发式生成的数据上表现更好

Conclusion: CDQAC为作业车间调度问题提供了高效的离线RL解决方案，具有出色的样本效率和从低质量数据中学习的能力

Abstract: The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling
Problem (FJSP), are canonical combinatorial optimization problems with
wide-ranging applications in industrial operations. In recent years, many
online reinforcement learning (RL) approaches have been proposed to learn
constructive heuristics for JSP and FJSP. Although effective, these online RL
methods require millions of interactions with simulated environments that may
not capture real-world complexities, and their random policy initialization
leads to poor sample efficiency. To address these limitations, we introduce
Conservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL
algorithm that learns effective scheduling policies directly from historical
data, eliminating the need for costly online interactions, while maintaining
the ability to improve upon suboptimal training data. CDQAC couples a
quantile-based critic with a delayed policy update, estimating the return
distribution of each machine-operation pair rather than selecting pairs
outright. Our extensive experiments demonstrate CDQAC's remarkable ability to
learn from diverse data sources. CDQAC consistently outperforms the original
data-generating heuristics and surpasses state-of-the-art offline and online RL
baselines. In addition, CDQAC is highly sample efficient, requiring only 10-20
training instances to learn high-quality policies. Surprisingly, we find that
CDQAC performs better when trained on data generated by a random heuristic than
when trained on higher-quality data from genetic algorithms and priority
dispatching rules.

</details>


### [111] [GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction](https://arxiv.org/abs/2509.10308)
*Joshua Dimasaka,Christian Geiß,Robert Muir-Wood,Emily So*

Main category: cs.LG

TL;DR: 提出了GraphCSVAE框架，通过深度学习、图表示和分类概率推理整合卫星时间序列数据和专家知识，用于建模灾害物理脆弱性，并在孟加拉国和塞拉利昂的灾害案例中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有灾害风险评估在物理脆弱性建模方面进展有限，限制了决策者对联合国仙台框架进展的评估能力，需要新的数据驱动方法来填补这一空白。

Method: 开发了Graph Categorical Structured Variational Autoencoder (GraphCSVAE)概率框架，整合深度学习、图表示和分类概率推理，使用时间序列卫星数据和专家先验知识，引入弱监督一阶转移矩阵来反映物理脆弱性的时空分布变化。

Result: 在两个灾害影响地区（孟加拉国Khurushkul社区和塞拉利昂弗里敦市）成功揭示了灾后物理脆弱性的区域动态变化，提供了局部时空审计和可持续减灾策略的宝贵见解。

Conclusion: GraphCSVAE框架有效解决了物理脆弱性建模的挑战，为灾害风险评估提供了新的数据驱动方法，有助于实现更精准的灾后风险减少策略。

Abstract: In the aftermath of disasters, many institutions worldwide face challenges in
continually monitoring changes in disaster risk, limiting the ability of key
decision-makers to assess progress towards the UN Sendai Framework for Disaster
Risk Reduction 2015-2030. While numerous efforts have substantially advanced
the large-scale modeling of hazard and exposure through Earth observation and
data-driven methods, progress remains limited in modeling another equally
important yet challenging element of the risk equation: physical vulnerability.
To address this gap, we introduce Graph Categorical Structured Variational
Autoencoder (GraphCSVAE), a novel probabilistic data-driven framework for
modeling physical vulnerability by integrating deep learning, graph
representation, and categorical probabilistic inference, using time-series
satellite-derived datasets and prior expert belief systems. We introduce a
weakly supervised first-order transition matrix that reflects the changes in
the spatiotemporal distribution of physical vulnerability in two
disaster-stricken and socioeconomically disadvantaged areas: (1) the
cyclone-impacted coastal Khurushkul community in Bangladesh and (2) the
mudslide-affected city of Freetown in Sierra Leone. Our work reveals
post-disaster regional dynamics in physical vulnerability, offering valuable
insights into localized spatiotemporal auditing and sustainable strategies for
post-disaster risk reduction.

</details>


### [112] [ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting](https://arxiv.org/abs/2509.10324)
*Myung Jin Kim,YeongHyeon Park,Il Dong Yun*

Main category: cs.LG

TL;DR: 提出一个基于ARIMA启发的简单卷积模块ARMA，用于长期时间序列预测，包含趋势捕捉和局部变化修正两个组件，能够直接进行多步预测并在多个基准数据集上取得竞争性精度。


<details>
  <summary>Details</summary>
Motivation: 传统ARIMA模型需要迭代多步预测且难以扩展到多变量设置，需要一种简单有效的模块来实现直接多步预测并保持架构简洁性。

Method: 设计包含两个卷积组件的模块：一个用于捕捉趋势（自回归），另一个用于细化局部变化（移动平均），直接进行多步预测，易于扩展到多变量场景。

Result: 在九个广泛使用的基准数据集上实验表明，ARMA方法实现了竞争性的准确度，特别是在具有强趋势变化的数据集上，同时保持了架构的简洁性。

Conclusion: ARMA模块不仅能够有效进行长期时间序列预测，还天然编码了绝对位置信息，有潜力作为序列模型中位置嵌入的轻量级替代方案。

Abstract: This paper proposes a simple yet effective convolutional module for long-term
time series forecasting. The proposed block, inspired by the Auto-Regressive
Integrated Moving Average (ARIMA) model, consists of two convolutional
components: one for capturing the trend (autoregression) and the other for
refining local variations (moving average). Unlike conventional ARIMA, which
requires iterative multi-step forecasting, the block directly performs
multi-step forecasting, making it easily extendable to multivariate settings.
Experiments on nine widely used benchmark datasets demonstrate that our method
ARMA achieves competitive accuracy, particularly on datasets exhibiting strong
trend variations, while maintaining architectural simplicity. Furthermore,
analysis shows that the block inherently encodes absolute positional
information, suggesting its potential as a lightweight replacement for
positional embeddings in sequential models.

</details>


### [113] [A Discrepancy-Based Perspective on Dataset Condensation](https://arxiv.org/abs/2509.10367)
*Tong Chen,Raghavendra Selvan*

Main category: cs.LG

TL;DR: 本文提出了一个统一框架来形式化数据集压缩问题，将传统的泛化性能目标扩展到包括鲁棒性、隐私保护等更多目标，使用差异度量来量化概率分布之间的距离。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集压缩方法主要关注泛化性能，但缺乏统一的理论框架。本文旨在建立一个更一般化的形式化定义，将数据集压缩扩展到更广泛的应用场景。

Method: 提出基于差异度量的统一框架，使用概率分布距离的概念来形式化数据集压缩问题，将任务特定的压缩概念扩展到更一般的定义。

Result: 建立了一个能够涵盖现有数据集压缩方法的统一理论框架，将压缩目标从单纯的泛化性能扩展到鲁棒性、隐私保护等多个维度。

Conclusion: 该框架为数据集压缩提供了更全面和形式化的理论基础，使得压缩方法能够适应更多样化的应用需求和目标。

Abstract: Given a dataset of finitely many elements $\mathcal{T} = \{\mathbf{x}_i\}_{i
= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic
dataset $\mathcal{S} = \{\tilde{\mathbf{x}}_j\}_{j = 1}^M$ which is
significantly smaller ($M \ll N$) such that a model trained from scratch on
$\mathcal{S}$ achieves comparable or even superior generalization performance
to a model trained on $\mathcal{T}$. Recent advances in DC reveal a close
connection to the problem of approximating the data distribution represented by
$\mathcal{T}$ with a reduced set of points. In this work, we present a unified
framework that encompasses existing DC methods and extend the task-specific
notion of DC to a more general and formal definition using notions of
discrepancy, which quantify the distance between probability distribution in
different regimes. Our framework broadens the objective of DC beyond
generalization, accommodating additional objectives such as robustness,
privacy, and other desirable properties.

</details>


### [114] [Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms](https://arxiv.org/abs/2509.10369)
*Gul Rukh Khattak,Konstantinos Patlatzoglou,Joseph Barker,Libor Pastika,Boroumand Zeidaabadi,Ahmed El-Medany,Hesham Aggour,Yixiu Liang,Antonio H. Ribeiro,Jeffrey Annis,Antonio Luiz Pinho Ribeiro,Junbo Ge,Daniel B. Kramer,Jonathan W. Waks,Evan Brittain,Nicholas Peters,Fu Siong Ng,Arunashis Sau*

Main category: cs.LG

TL;DR: CAPE模型通过对比学习在520万份心电图数据上预训练，发现预训练队列的人口统计和健康状况分布影响下游性能，多中心多样化队列虽提高分布内精度但降低分布外泛化能力，提出了IDB策略来增强泛化鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索对比学习在自监督预训练中对队列组成的依赖性，特别是不同人口统计、健康状况和种群多样性对下游心电图预测任务性能的影响。

Method: 开发CAPE基础模型，在四大洲五个队列（n=5,203,352）的心电图数据上进行对比学习预训练，系统评估预训练队列特性对下游任务的影响，并提出In-Distribution Batch (IDB)策略来保持队列内一致性。

Result: 下游性能确实依赖于预训练队列的分布特性；多中心多样化队列提高了分布内精度但降低了分布外泛化能力；IDB策略有效增强了模型的分布外鲁棒性。

Conclusion: 这项工作为开发临床公平和可泛化的基础模型提供了重要见解，强调了预训练队列组成对模型性能的关键影响，并提出了改进泛化能力的具体方法。

Abstract: Contrastive learning is a widely adopted self-supervised pretraining
strategy, yet its dependence on cohort composition remains underexplored. We
present Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation
model and pretrain on four cohorts (n = 5,203,352), from diverse populations
across three continents (North America, South America, Asia). We systematically
assess how cohort demographics, health status, and population diversity
influence the downstream performance for prediction tasks also including two
additional cohorts from another continent (Europe). We find that downstream
performance depends on the distributional properties of the pretraining cohort,
including demographics and health status. Moreover, while pretraining with a
multi-centre, demographically diverse cohort improves in-distribution accuracy,
it reduces out-of-distribution (OOD) generalisation of our contrastive approach
by encoding cohort-specific artifacts. To address this, we propose the
In-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency
during pretraining and enhances OOD robustness. This work provides important
insights for developing clinically fair and generalisable foundation models.

</details>


### [115] [Flow Straight and Fast in Hilbert Space: Functional Rectified Flow](https://arxiv.org/abs/2509.10384)
*Jianxin Zhang,Clayton Scott*

Main category: cs.LG

TL;DR: 本文提出了无限维希尔伯特空间中整流流的严格函数化表述，建立了基于连续性方程叠加原理的理论框架，并扩展到函数流匹配和概率流ODE，实验表明该方法优于现有函数生成模型。


<details>
  <summary>Details</summary>
Motivation: 虽然许多生成模型已在有限维欧几里得空间中发展出函数化推广，但整流流在无限维空间中的扩展仍未探索。现有函数流匹配理论存在限制性测度理论假设，需要更通用的框架。

Method: 基于无限维空间中连续性方程的叠加原理，建立整流流的严格函数化表述，并将其自然扩展到函数流匹配和函数概率流ODE，作为整流流的非线性推广。

Result: 实验证明该方法相比现有函数生成模型具有更优越的性能，同时移除了现有理论中的限制性测度理论假设。

Conclusion: 成功建立了无限维希尔伯特空间中整流流的理论框架，提供了比现有方法更通用和有效的函数生成建模方法，为无限维生成模型的发展奠定了基础。

Abstract: Many generative models originally developed in finite-dimensional Euclidean
space have functional generalizations in infinite-dimensional settings.
However, the extension of rectified flow to infinite-dimensional spaces remains
unexplored. In this work, we establish a rigorous functional formulation of
rectified flow in an infinite-dimensional Hilbert space. Our approach builds
upon the superposition principle for continuity equations in an
infinite-dimensional space. We further show that this framework extends
naturally to functional flow matching and functional probability flow ODEs,
interpreting them as nonlinear generalizations of rectified flow. Notably, our
extension to functional flow matching removes the restrictive measure-theoretic
assumptions in the existing theory of \citet{kerrigan2024functional}.
Furthermore, we demonstrate experimentally that our method achieves superior
performance compared to existing functional generative models.

</details>


### [116] [Vendi Information Gain for Active Learning and its Application to Ecology](https://arxiv.org/abs/2509.10390)
*Quan Nguyen,Adji Bousso Dieng*

Main category: cs.LG

TL;DR: 提出Vendi信息增益(VIG)主动学习策略，通过考虑数据集整体预测不确定性来选择图像，在Snapshot Serengeti数据集上仅用10%标签就达到接近全监督的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决相机陷阱图像数据中物种识别因标注资源有限而成为瓶颈的问题，传统主动学习方法只关注个体预测不确定性而忽略数据集整体不确定性。

Method: 引入Vendi信息增益(VIG)主动学习策略，基于图像对整个数据集预测不确定性的影响来选择样本，同时考虑信息量和多样性。

Result: 在Snapshot Serengeti数据集上，VIG仅使用不到10%的标签就达到了接近全监督的预测准确率，在各项指标和批次大小上都优于标准基线方法，并在特征空间中收集到更多样化的数据。

Conclusion: VIG方法在数据有限的环境中对生物多样性监测具有重要价值，其应用范围不仅限于生态学领域。

Abstract: While monitoring biodiversity through camera traps has become an important
endeavor for ecological research, identifying species in the captured image
data remains a major bottleneck due to limited labeling resources. Active
learning -- a machine learning paradigm that selects the most informative data
to label and train a predictive model -- offers a promising solution, but
typically focuses on uncertainty in the individual predictions without
considering uncertainty across the entire dataset. We introduce a new active
learning policy, Vendi information gain (VIG), that selects images based on
their impact on dataset-wide prediction uncertainty, capturing both
informativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG
achieves impressive predictive accuracy close to full supervision using less
than 10% of the labels. It consistently outperforms standard baselines across
metrics and batch sizes, collecting more diverse data in the feature space. VIG
has broad applicability beyond ecology, and our results highlight its value for
biodiversity monitoring in data-limited environments.

</details>


### [117] [Inpainting-Guided Policy Optimization for Diffusion Large Language Models](https://arxiv.org/abs/2509.10396)
*Siyan Zhao,Mengchen Liu,Jing Huang,Miao Liu,Chenyu Wang,Bo Liu,Yuandong Tian,Guan Pang,Sean Bell,Aditya Grover,Feiyu Chen*

Main category: cs.LG

TL;DR: IGPO是一个针对掩码扩散大语言模型的强化学习框架，通过部分真实推理轨迹的inpainting引导探索，解决稀疏奖励和样本浪费问题，在数学推理任务上取得SOTA效果


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在LLM对齐中存在探索效率低、稀疏奖励和样本浪费的问题，而dLLMs的inpainting能力为引导探索提供了独特机会

Method: 提出IGPO框架，在在线采样中策略性地插入部分真实推理轨迹，结合监督微调、熵过滤等技术，并针对GRPO等组优化方法进行优化

Result: 在GSM8K、Math500和AMC三个数学基准测试中取得了显著提升，为全注意力掩码dLLMs创造了新的最先进结果

Conclusion: IGPO成功地将dLLMs的inpainting能力与RL算法设计相结合，有效解决了探索效率问题，为dLLMs的强化学习对齐提供了新思路

Abstract: Masked diffusion large language models (dLLMs) are emerging as promising
alternatives to autoregressive LLMs, offering competitive performance while
supporting unique generation capabilities such as inpainting. We explore how
inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with
reinforcement learning faces an exploration challenge: sparse reward signals
and sample waste when models fail to discover correct solutions. While this
inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their
inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided
Policy Optimization), an RL framework that strategically inserts partial
ground-truth reasoning traces during online sampling. Unlike providing full
solutions, inpainting steers exploration toward promising trajectory spaces
while preserving self-generated reasoning, bridging supervised fine-tuning and
reinforcement learning. We apply IGPO to group-based optimization methods such
as GRPO, where exploration failures cause zero advantages and gradients. IGPO
restores meaningful gradients while improving sample efficiency. We also
propose supervised fine-tuning on synthetically rewritten concise traces that
better align with dLLM generation patterns. With additional techniques
including entropy-based filtering, our training recipe yields substantial gains
across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new
state-of-the-art results for full-attention masked dLLMs.

</details>


### [118] [Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining](https://arxiv.org/abs/2509.10406)
*Rupert Mitchell,Kristian Kersting*

Main category: cs.LG

TL;DR: MuSe是一种高效的softmax注意力近似方法，结合语义聚类和计算物理中的多极展开，通过分层两阶段注意力机制降低Transformer的二次计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer在序列长度上的二次计算复杂度问题，通过聚类查询和键来构建高效的注意力近似方法，同时保持注意力的不对称性处理。

Method: 在学习的表示空间中分别对查询和键进行聚类，使用层次化的两阶段注意力机制，在质心近似基础上增加偶极校正来捕捉簇内方向方差。可作为标准注意力的即插即用替代方案。

Result: 在8k上下文长度下比CUDNN Flash Attention快3倍，相对平方误差低于20%。在16k上下文的30M参数模型预训练中，实现12.2%的运行时间减少，仅有0.36%的性能损失。

Conclusion: 多极近似方法为高效Transformer预训练提供了可行的解决方案，在保持性能的同时显著降低了计算复杂度。

Abstract: We present Multipole Semantic Attention (MuSe), an efficient approximation of
softmax attention that combines semantic clustering with multipole expansions
from computational physics. Our method addresses the quadratic computational
complexity of transformers in the context length by clustering queries and keys
separately in their learned representation spaces, enabling a hierarchical
two-stage attention mechanism. Unlike prior clustering approaches that group
only keys or use unified clustering, we maintain separate clusterings that
respect attention's asymmetric treatment of these spaces. We augment
centroid-based (monopole) approximations with dipole corrections that capture
directional variance within clusters, preserving richer information during
training. The method operates as a drop-in replacement for standard attention,
requiring only hyperparameter specification without architectural
modifications. Our approach achieves $\mathcal{O}(NCD)$ complexity for acausal
attention with $C$ clusters and $\mathcal{O}(NCD \log N)$ for causal attention.
On isolated attention layers, we demonstrate $3\times$ speedup over CUDNN Flash
Attention at 8k context length, with relative squared errors below 20%. For
causal attention, we develop a hierarchical block decomposition that combines
exact local computation with efficient long-range approximation. In end-to-end
pretraining of a 30M parameter model on book-length texts with 16k context, we
achieve 12.2% runtime reduction with only 0.36% loss degradation, establishing
the viability of multipole approximations for efficient transformer
pretraining.

</details>


### [119] [Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining](https://arxiv.org/abs/2509.10419)
*Francesco Vitale,Tommaso Zoppi,Francesco Flammini,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 使用过程挖掘和机器学习进行铁路系统运行时控制流异常检测与定位


<details>
  <summary>Details</summary>
Motivation: 随着铁路系统复杂性和关键性增加，需要增强系统韧性来应对设计时未知的残余故障、系统环境变化和新兴网络威胁

Method: 采用过程挖掘从执行轨迹学习实际控制流，进行运行时一致性检查，并结合无监督机器学习进行异常定位

Result: 在ERTMS/ETCS L2 RBC移交场景中测试，显示出高精度、高效性和可解释性的异常检测与定位能力

Conclusion: 过程挖掘结合机器学习的方法能有效提升铁路控制系统的运行时韧性和安全性

Abstract: Ensuring the resilience of computer-based railways is increasingly crucial to
account for uncertainties and changes due to the growing complexity and
criticality of those systems. Although their software relies on strict
verification and validation processes following well-established best-practices
and certification standards, anomalies can still occur at run-time due to
residual faults, system and environmental modifications that were unknown at
design-time, or other emergent cyber-threat scenarios. This paper explores
run-time control-flow anomaly detection using process mining to enhance the
resilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European
Train Control System Level 2). Process mining allows learning the actual
control flow of the system from its execution traces, thus enabling run-time
monitoring through online conformance checking. In addition, anomaly
localization is performed through unsupervised machine learning to link
relevant deviations to critical system components. We test our approach on a
reference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its
capability to detect and localize anomalies with high accuracy, efficiency, and
explainability.

</details>


### [120] [Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration](https://arxiv.org/abs/2509.10439)
*Ahmed Khaled,Satyen Kale,Arthur Douillard,Chi Jin,Rob Fergus,Manzil Zaheer*

Main category: cs.LG

TL;DR: 本文研究了Local SGD中外部优化器的作用，证明了新的收敛保证，发现调整外部学习率可以在优化误差和随机梯度噪声方差之间权衡，并弥补内部学习率的不良调整。理论表明外部学习率有时应大于1，并扩展到使用动量和加速的外部优化器，提出了新的数据相关分析。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习需要大规模批处理、分布式数据和并行计算硬件，通信成为主要瓶颈。Local SGD方法能减少通信开销，但现有研究主要关注局部优化过程的超参数，对外部优化器及其超参数的选择不够明确。

Method: 研究Local SGD中外部优化器的作用，证明新的收敛保证，分析外部学习率调整的影响，扩展到使用动量和加速的外部优化器，提出数据相关分析，并进行标准语言模型实验验证。

Result: 理论表明调整外部学习率可以权衡优化误差和随机梯度噪声方差，弥补内部学习率的不良调整，外部学习率有时应大于1。使用动量和加速能改善收敛速率，优于先前局部应用加速的算法。

Conclusion: 外部优化器在Local SGD中扮演关键角色，适当调整外部学习率能显著改善性能，动量和加速技术的应用能进一步提升收敛效率，数据相关分析为外部学习率调优提供了新见解。

Abstract: Modern machine learning often requires training with large batch size,
distributed data, and massively parallel compute hardware (like mobile and
other edge devices or distributed data centers). Communication becomes a major
bottleneck in such settings but methods like Local Stochastic Gradient Descent
(Local SGD) show great promise in reducing this additional communication
overhead. Local SGD consists of three parts: a local optimization process, an
aggregation mechanism, and an outer optimizer that uses the aggregated updates
from the nodes to produce a new model. While there exists an extensive
literature on understanding the impact of hyperparameters in the local
optimization process, the choice of outer optimizer and its hyperparameters is
less clear. We study the role of the outer optimizer in Local SGD, and prove
new convergence guarantees for the algorithm. In particular, we show that
tuning the outer learning rate allows us to (a) trade off between optimization
error and stochastic gradient noise variance, and (b) make up for ill-tuning of
the inner learning rate. Our theory suggests that the outer learning rate
should sometimes be set to values greater than $1$. We extend our results to
settings where we use momentum in the outer optimizer, and we show a similar
role for the momentum-adjusted outer learning rate. We also study acceleration
in the outer optimizer and show that it improves the convergence rate as a
function of the number of communication rounds, improving upon the convergence
rate of prior algorithms that apply acceleration locally. Finally, we also
introduce a novel data-dependent analysis of Local SGD that yields further
insights on outer learning rate tuning. We conduct comprehensive experiments
with standard language models and various outer optimizers to validate our
theory.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [121] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: AutoIND LLM平台可将IND申请的非临床书面总结初稿撰写时间减少约97%，从约100小时缩短至2.6-3.7小时，质量评分69.6%-77.9%，无关键监管错误，但仍需专家进一步完善。


<details>
  <summary>Details</summary>
Motivation: IND申请准备耗时且依赖专业知识，拖慢早期临床开发进程，需要寻找加速方法。

Method: 记录AutoIND生成IND非临床书面总结(eCTD模块2.6.2、2.6.4、2.6.6)的时间，与有经验监管撰写者的手动撰写时间对比，并由盲评评估员从7个预设类别评估质量。

Result: 撰写时间减少97%，质量评分69.6%-77.9%，无关键监管错误，但在重点突出、简洁性和清晰度方面存在不足。

Conclusion: AutoIND能显著加速IND起草，但需要专家监管撰写者将输出完善至可提交质量，发现的系统性缺陷为模型改进提供了路线图。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [122] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: Boldsea是一个基于语义事件的架构，使用可执行本体来建模复杂动态系统，解决了传统BPM系统和面向对象语义技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统业务过程管理系统和面向对象语义技术在动态系统建模中的局限性，提供更灵活的运行时模型修改和更好的时间透明度。

Method: 提出BSL语义语言及其BNF语法，设计boldsea-engine架构，直接解释语义模型作为可执行算法，无需编译。

Result: 实现了事件模型在运行时的修改能力，确保时间透明度，并在统一语义框架内无缝融合数据和业务逻辑。

Conclusion: Boldsea架构通过语义事件方法和可执行本体，为复杂动态系统建模提供了更有效的解决方案，克服了传统方法的限制。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [123] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 本文评估了大语言模型(LLMs)和视觉语言模型(VLMs)在符号、语言和连续控制环境中提供规划反馈的能力，发现基础模型能提供高质量反馈，但复杂动态环境中的反馈质量会下降。


<details>
  <summary>Details</summary>
Motivation: 传统基于环境的规划学习需要精心设计的奖励函数或高质量标注演示，而预训练基础模型包含有助于规划的背景知识，可以减少策略学习所需的奖励设计和演示数量。

Method: 评估LLMs和VLMs在符号、语言和连续控制环境中提供多种类型反馈的能力，包括二元反馈、偏好反馈、动作建议、目标建议和增量动作反馈，并考虑上下文学习、思维链和环境动态访问等推理方法。

Result: 基础模型能够跨领域提供多样化高质量反馈；更大和具备推理能力的模型提供更准确反馈、表现更少偏见，并能从增强的推理方法中获益更多；但在具有复杂动态或连续状态空间和动作空间的环境中，反馈质量会下降。

Conclusion: 预训练基础模型是减少规划学习中奖励设计和演示需求的有效工具，但在处理复杂环境动态时仍存在挑战，需要进一步改进。

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [124] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 提出一个模块化多模态框架，使用生成式AI从公开的住宅信息和图像生成能源建模所需的数据，解决数据获取困难、成本高和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 能源建模研究需要大量数据，但很多数据难以获取、成本高昂或涉及隐私问题，限制了研究的可及性和可重复性。

Method: 开发模块化多模态框架，利用生成式人工智能从公开可获取的住宅信息和图像生成所需数据，并提供完整的处理流程。

Result: 实验表明该框架能够生成真实、标注良好的数据，避免了生成模型常见的问题，有效减少对昂贵或受限数据源的依赖。

Conclusion: 该框架为能源建模研究提供了更易获取和可重复的数据生成方法，推动了该领域研究的可及性和可重复性发展。

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [125] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文综述了自动形式化（autoformalization）领域的发展，重点关注使用大语言模型将非正式输入转换为形式逻辑表示的研究，旨在建立统一框架促进跨领域合作。


<details>
  <summary>Details</summary>
Motivation: 自动形式化领域快速发展但研究分散，缺乏共享的方法论、基准和理论框架，限制了该领域的整体进展。不同研究领域虽然处理相似任务但独立发展，需要统一框架来促进交叉融合。

Method: 通过系统回顾显性和隐性的自动形式化研究实例，分析不同领域的方法和技术，提出统一的分类框架和理论模型。

Result: 识别了自动形式化在数学形式化和其他领域（如推理、规划、知识表示）的广泛应用，揭示了当前研究的分散状态和整合潜力。

Conclusion: 建立统一的自动形式化框架可以加速下一代AI系统的发展，促进不同研究领域之间的方法共享和交叉融合，推动该领域的系统性进步。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [126] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 本研究开发了一个基于RAG的智能知识助手系统，专门用于山羊养殖健康管理，通过表格文本化和决策树文本化方法融合异构知识，在验证集和测试集上分别达到87.90%和84.22%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在畜牧业应用受限，主要由于知识源的可用性、多样性和复杂性限制，需要专门针对山羊养殖的健康管理系统。

Method: 采用检索增强生成(RAG)技术，提出表格文本化和决策树文本化两种结构化知识处理方法，建立包含五个关键领域的山羊养殖知识库，并集成在线搜索模块实现实时信息检索。

Result: 异构知识融合方法效果最佳，验证集平均准确率87.90%，测试集84.22%。在文本、表格、决策树问答任务中准确率均超过85%，证明了模块化设计中结构化知识融合的有效性。

Conclusion: 研究结果表明该系统在山羊养殖实际应用中具有鲁棒性和可靠性，错误分析显示遗漏是主要错误类型，为进一步提高检索覆盖率和上下文整合提供了改进方向。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [127] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: 本文研究LLM在UNO游戏中作为助手帮助其他玩家获胜的能力，发现虽然所有模型都能超越随机基线，但只有少数能显著帮助其他玩家


<details>
  <summary>Details</summary>
Motivation: 测试基于大语言模型的智能体是否能作为主动参与者帮助人类实现目标，特别是在协作性游戏场景中

Method: 构建工具让仅解码器LLM在RLCard游戏环境中作为智能体参与UNO游戏，接收完整游戏状态信息，使用两种不同的提示策略进行文本响应，评估从1B到70B不同规模模型的性能

Result: 所有模型在玩UNO时都能成功超越随机基线表现，但只有少数模型能够显著帮助其他玩家获胜

Conclusion: LLM在协作性任务中的表现仍有局限，模型规模对帮助能力的影响需要进一步研究

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [128] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: 提出一个概念框架，将工作流沿智能性和组合性两个维度演进，从当前的工作流管理系统发展到完全自主的分布式科学实验室，旨在实现100倍的科学发现加速。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现需要协调分布式设施和异构资源，研究人员被迫成为手动工作流协调者而非科学家。AI代理技术的发展为科学发现提供了新的加速机会，但需要明确如何在实际中实现和集成这种新能力。

Method: 提出一个概念框架，工作流沿两个维度演进：智能性（从静态到智能）和组合性（从单一到群体），并提供了一个架构蓝图来指导社区向自主科学发展。

Result: 提出了从当前工作流管理系统到完全自主、分布式科学实验室的演进路径，为利用自主科学机会提供了框架性指导。

Conclusion: 该框架为科学社区提供了向自主科学发展的重要步骤，具有实现100倍发现加速和变革性科学工作流的潜力。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [129] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 将WaveFunctionCollapse重新表述为马尔可夫决策过程，使优化算法专注于目标最大化，而WFC传播机制处理约束满足，相比传统联合优化方法表现更优


<details>
  <summary>Details</summary>
Motivation: 解决程序化内容生成中需要同时满足设计者指定目标和瓦片集隐含邻接约束的挑战，传统联合优化方法在任务复杂度增加时表现不佳

Method: 将WaveFunctionCollapse重新表述为马尔可夫决策过程(MDP)，使外部优化算法专注于目标最大化，利用WFC的传播机制强制执行约束满足

Result: 在多个不同难度的领域中，联合优化方法随着任务复杂度增加而表现不佳，且始终不如在WFC-MDP上的优化方法

Conclusion: 将局部约束满足与全局目标优化解耦具有明显优势，WFC-MDP方法优于传统联合优化方法

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [130] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 本文针对表格数据和布尔函数预测场景，提出了基于实际因果关系的变量重要性度量方法，并开发了新的XAI工具B-ReX，在基准测试中表现优于现有黑盒XAI工具。


<details>
  <summary>Details</summary>
Motivation: 由于解释的主观性，评估可解释AI（XAI）方法具有挑战性。本文专注于表格数据和布尔函数预测这一具体用例，旨在提供更精确的评估标准。

Method: 提出了基于实际因果关系的变量重要性形式化度量方法，并在现有ReX工具基础上开发了新的B-ReX工具，用于大规模基准测试评估。

Result: B-ReX在随机10值布尔公式上取得了0.072±0.012的Jensen-Shannon散度，表现优于其他黑盒XAI工具。

Conclusion: 基于实际因果关系的度量方法为XAI评估提供了更精确的标准，B-ReX工具在布尔函数预测场景中展现出优越性能。

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [131] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: GAMA是一个保护隐私的多智能体系统，通过将工作空间划分为私有和公共区域，使用匿名化机制保护敏感数据，同时通过知识增强和逻辑增强模块减少语义损失。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多智能体系统中的广泛应用，当任务涉及隐私数据时，需要在不牺牲性能的前提下实现隐私保护，现有系统缺乏有效的隐私保护机制。

Method: 提出GAMA系统，划分私有和公共空间，在私有空间处理敏感数据，公共空间只使用匿名化数据。采用基于领域规则的知识增强(DRKE)和基于反证的逻辑增强(DLE)来缓解匿名化带来的语义损失。

Result: 在两个公开问答数据集(Trivia Creative Writing和Logic Grid Puzzle)上表现优于最先进模型。在新设计的隐私保护数据集上验证了GAMA在任务处理和隐私保护方面的卓越有效性。

Conclusion: GAMA系统成功实现了在保持高性能的同时有效保护隐私的目标，为LLM-based多智能体系统的隐私保护提供了可行解决方案。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [132] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个基于多极任务处理图和IF-THEN规则的多智能体协作框架，用于处理具有不确定性的复杂任务，在知识型和逻辑型问答任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然提升了多智能体系统的能力，但在处理高度复杂且具有不确定性的任务时，仍然存在任务规划效果不佳的问题，经常产生误导性或错误的输出，阻碍任务执行。

Method: 提出XAgents框架，使用多极任务处理图实现动态任务规划和处理任务不确定性，在子任务处理中集成领域特定的IF-THEN规则约束智能体行为，同时使用全局规则增强智能体间协作。

Result: 在三个不同数据集上的评估表明，XAgents在知识型和逻辑型问答任务中始终优于最先进的单智能体和多智能体方法。

Conclusion: XAgents通过多极任务处理图和规则约束机制，有效解决了多智能体系统在处理复杂不确定性任务时的规划问题，显著提升了任务执行效果。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [133] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: 提出了AI Harmonics框架，使用基于序数严重性数据的AIH指标来评估AI危害，无需精确数值估计，能够有效识别和优先处理政治和物理等高风险危害


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估模型过于关注内部合规性，忽视了多元利益相关者视角和现实世界后果，需要转向以人为中心、基于实证事件数据的危害严重性自适应方法

Method: 开发了AI Harmonics框架，包含新颖的AI危害评估指标(AIH)，利用序数严重性数据捕捉相对影响，结合稳健的通用方法和数据驱动的利益相关者感知框架

Result: 在标注事件数据上的实验证实政治和物理危害具有最高集中度，需要紧急缓解：政治危害侵蚀公众信任，物理危害造成严重甚至危及生命的风险

Conclusion: AI Harmonics能够一致识别不均匀的危害分布，使政策制定者和组织能够有效针对性地开展缓解工作，具有重要的现实意义

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [134] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 论文提出了"沙盒经济"框架来分析AI智能体经济，将其按起源（涌现vs有意）和与人类经济分离程度（可渗透vs不可渗透）分类，讨论了可引导AI市场的设计选择以确保技术发展符合人类长期繁荣。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI智能体的快速采用，正在形成一个超越人类直接监督的新经济层，需要框架来分析和引导这一新兴系统，以应对系统性经济风险和加剧的不平等等挑战。

Method: 提出沙盒经济分析框架，从两个维度（起源和分离程度）对AI智能体经济进行分类，并探讨拍卖机制、AI"使命经济"设计和社会技术基础设施等可引导市场的设计选择。

Result: 当前趋势指向一个自发涌现、高度可渗透的庞大AI智能体经济，既带来前所未有的协调机会，也面临系统性风险和加剧不平等的挑战。

Conclusion: 需要主动设计可引导的智能体市场，通过拍卖机制、使命经济协调和社会技术基础设施等手段，确保技术转变与人类长期集体繁荣保持一致。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [135] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 提出了Robust Sparse Sampling (RSS)算法，这是第一个具有有限样本理论性能保证的在线鲁棒MDP规划算法，能够在模型不确定性环境下实现实时鲁棒决策。


<details>
  <summary>Details</summary>
Motivation: 在线规划方法如Sparse Sampling和MCTS在实际应用中面临模型学习误差问题，可能导致性能下降或不安全行为。现有鲁棒MDP方法计算复杂，不适合实时应用。

Method: 基于Sample Average Approximation (SAA)方法，通过计算鲁棒价值函数而非名义价值函数，实现了高效的鲁棒策略计算。算法适用于无限或连续状态空间，样本和计算复杂度与状态空间大小无关。

Result: RSS算法在理论上有性能保证，实验表明在动态不确定环境中优于标准Sparse Sampling方法。

Conclusion: RSS是第一个适用于在线环境的鲁棒规划算法，具有理论保证和实际应用价值，为模型不确定性下的实时决策提供了有效解决方案。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [136] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 提出基于LLM的多智能体框架，用于自动化多孔材料表征，包括文献挖掘力场参数和自动设置RASPA模拟，初步评估显示高正确性和可重现性。


<details>
  <summary>Details</summary>
Motivation: 多孔材料表征自动化可以加速材料发现，但目前受限于模拟设置和力场选择的复杂性，需要简化这一过程。

Method: 使用基于LLM的多智能体框架，智能体能够自主理解表征任务、规划模拟、组装力场、执行模拟并解释结果以指导后续步骤，特别实现了文献驱动的力场提取和RASPA模拟自动设置。

Result: 初步评估表明该方法具有高正确性和可重现性，验证了框架的有效性。

Conclusion: 该方法有潜力实现完全自主、可扩展的材料表征，为多孔材料发现提供自动化解决方案。

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [137] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: CARENLI是一个用于临床自然语言推理的模块化代理推理框架，通过将知识访问与原则推理分离，显著提高了推理准确性和可审计性


<details>
  <summary>Details</summary>
Motivation: 挑战传统假设（扩展数据和参数能产生更结构化、可泛化的内部表示），在临床NLI中验证这一假设，解决LLMs在推理时倾向于使用启发式方法而非原则推理的问题

Method: 提出CARENLI框架：1）将基准分解为四个推理家族（因果归因、组合基础、认知验证、风险状态抽象）；2）使用特定家族求解器路由前提-陈述对；3）通过规划器、验证器和精炼器强制执行可审计程序

Result: 在四个LLM上，CARENLI将保真度提高了多达42个百分点，在因果归因中达到98.0%，在风险状态抽象中达到81.2%。验证器以接近天花板可靠性标记违规，精炼器纠正了大量认知错误

Conclusion: LLMs通常保留相关事实但在推理未明确指定时默认使用启发式方法，CARENLI使这种分离变得明确，同时为更安全、可审计的推理提供了框架，家族分类是主要瓶颈

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [138] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 研究探讨了在小型语言模型(SLMs)中引入形式化方法对推理任务性能的影响，特别是用更紧凑的逻辑语言替代自然语言可以在保持推理性能的同时提升效率。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在推理领域存在明显短板，特别是在本体工程任务中表现不佳。研究旨在探索形式化方法如何提升小型语言模型在推理任务中的表现。

Method: 通过一系列初步实验，研究不同语法表达逻辑问题对小型语言模型在预定推理任务上性能的影响，比较自然语言与逻辑语言的表现。

Result: 研究发现可以用更紧凑的逻辑语言替代自然语言，同时在推理任务上保持强劲性能，这为小型语言模型在本体工程中的应用提供了新方向。

Conclusion: 形式化方法的引入能够有效提升小型语言模型的推理能力，为使用SLMs引导本体构建提供了可行性，未来可进一步优化SLMs在本体工程中的角色。

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [139] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: 本研究通过量化实验分析6个大型语言模型在18个道德困境中的表现，发现所有模型都一致偏好关怀和美德价值观，而惩罚自由主义选择。具备推理能力的模型对情境更敏感，提供更丰富的解释。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能快速发展，需要研究如何使机器决策与人类道德价值观对齐，探索人类-AI共生的前景。

Method: 对6个大型语言模型进行定量实验，在代表5种道德框架的18个困境中对结果进行排序和评分，分析模型架构、文化起源和可解释性对道德偏好的影响。

Result: 发现所有模型都存在显著一致的价值偏见：关怀和美德价值观结果被评为最道德，自由主义选择被一致惩罚。推理模型对情境更敏感，非推理模型产生更一致但不透明的判断。

Conclusion: 研究强调需要将可解释性和文化意识作为关键设计原则，以指导AI走向透明、对齐和共生的未来。

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [140] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: State Algebra是一个使用代数方法表示和操作命题逻辑的新框架，包含Set、Coordinate和Row Decomposition三个层次表示，在保持语义清晰的同时提供计算灵活性


<details>
  <summary>Details</summary>
Motivation: 开发一个既能保持命题逻辑语义清晰性，又能提供强大代数计算能力的统一框架，以支持搜索算法和知识编译算法，并扩展到概率逻辑和加权模型计数

Method: 构建三层表示层次结构（Set、Coordinate、Row Decomposition），通过代数引擎进行计算，采用固定变量顺序来获得唯一规范形式，牺牲完全规范性以换取表示灵活性

Result: 框架能够表示和操作命题逻辑，虽然默认状态向量归约不是规范的，但通过固定变量顺序可以获得唯一规范形式，为某些问题类别提供更紧凑的表示

Conclusion: State Algebra提供了一个灵活的代数框架来处理命题逻辑，在规范性和表示紧凑性之间取得平衡，为搜索算法、知识编译以及扩展到概率逻辑领域提供了有力工具

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [141] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: A2P Scaffolding是一种新的多智能体系统故障归因框架，通过结构化因果推理将故障归因从模式识别任务转变为因果推理任务，显著提高了步骤级准确率。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统中的故障归因方法准确率极低（低于17%），无法进行有效的反事实推理来确定纠正单个动作是否能避免任务失败，这限制了复杂系统的调试能力。

Method: 提出了Abduct-Act-Predict (A2P) Scaffolding框架，指导大型语言模型在单次推理过程中执行三步结构化推理：1)溯因推理推断隐藏的根本原因；2)定义最小纠正干预；3)模拟后续轨迹验证干预是否解决问题。

Result: 在Algorithm-Generated数据集上达到47.46%的步骤级准确率（比基线的16.67%提高2.85倍），在更复杂的Hand-Crafted数据集上达到29.31%准确率（比基线的12.07%提高2.43倍）。

Conclusion: 通过因果推理的视角重构问题，A2P Scaffolding为自动化故障归因提供了更鲁棒、可验证且准确度显著提高的解决方案。

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [142] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 该论文提出了一个信息理论框架，通过分析状态-动作互信息模式来诊断RL系统在部署时的异常故障，能够区分传感器故障和驱动器故障。


<details>
  <summary>Details</summary>
Motivation: 现实世界中部署的RL智能体面临传感器故障、驱动器磨损和环境变化等问题，但缺乏内在机制来检测和诊断这些故障。

Method: 使用信息理论框架分析状态-动作互信息模式，通过控制扰动实验验证信息指标对系统故障的差异化诊断能力。

Result: 成功学习表现出特征性信息签名：状态-动作互信息从0.84增长到2.83比特（238%增长）；信息指标能够区分传感器故障（广泛崩溃所有信息通道）和驱动器故障（选择性破坏动作-结果可预测性）。

Conclusion: 信息模式既是学习的特征，也是系统健康的诊断工具，为基于信息理论原则的自适应RL系统提供了自主故障检测和政策调整的基础。

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [143] [DB3 Team's Solution For Meta KDD Cup' 25](https://arxiv.org/abs/2509.09681)
*Yikuan Xia,Jiazun Chen,Yirui Zhan,Suifeng Zhao,Weipeng Jiang,Chaorui Zhang,Wei Han,Bo Bai,Jun Gao*

Main category: cs.IR

TL;DR: db3团队在KDD Cup'25 Meta CRAG-MM挑战赛中获胜的方案，通过多模态检索管道和LLM幻觉控制技术，在三个任务中分别获得第2、第2和第1名


<details>
  <summary>Details</summary>
Motivation: 解决CRAG-MM挑战赛中的多模态、多轮问答基准问题，特别针对第一人称视角的自我中心查询挑战

Method: 开发了包含图像索引知识图谱、网络资源和多轮对话的专业检索管道，以及采用SFT、DPO和RL的先进拒绝训练技术来控制LLM幻觉

Result: 在Task 1和Task 2中获得第2名，在Task 3中获得第1名，最终赢得自我中心查询卓越大奖

Conclusion: 该综合框架通过专业化的检索管道和统一的LLM调优方法，在多模态多轮问答任务中表现出色，特别是在处理第一人称视角挑战方面具有优势

Abstract: This paper presents the db3 team's winning solution for the Meta CRAG-MM
Challenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal,
multi-turn question answering benchmark (CRAG-MM), we developed a comprehensive
framework that integrates tailored retrieval pipelines for different tasks with
a unified LLM-tuning approach for hallucination control. Our solution features
(1) domain-specific retrieval pipelines handling image-indexed knowledge
graphs, web sources, and multi-turn conversations; and (2) advanced refusal
training using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd
place in Task 2, and 1st place in Task 3, securing the grand prize for
excellence in ego-centric queries through superior handling of first-person
perspective challenges.

</details>


### [144] [Faster and Memory-Efficient Training of Sequential Recommendation Models for Large Catalogs](https://arxiv.org/abs/2509.09682)
*Maxim Zhelnin,Dmitry Redko,Volkov Daniil,Anna Volodkevich,Petr Sokerin,Valeriy Shevchenko,Egor Shvetsov,Alexey Vasilev,Darya Denisova,Ruslan Izmailov,Alexey Zaytsev*

Main category: cs.IR

TL;DR: 提出了CCE-方法，一种GPU高效的交叉熵损失函数实现，可加速训练2倍并减少10倍以上内存消耗，使推荐系统能够使用更多负样本和更大批次提升模型性能


<details>
  <summary>Details</summary>
Motivation: 解决基于transformer的序列推荐模型训练时因交叉熵损失导致的高计算成本和内存消耗问题，特别是在大规模商品目录场景下

Method: 开发CCE-方法，通过GPU高效实现交叉熵损失与负采样，并发布Triton内核来有效实施该方法

Result: 训练加速达2倍，内存消耗减少10倍以上，在大规模商品目录数据集上相比原始PyTorch实现获得更好的准确率

Conclusion: CCE-方法显著降低了训练资源需求，使得可以同时增加负样本数量和批次大小来提升模型性能，而非只能优化其中一个参数

Abstract: Sequential recommendations (SR) with transformer-based architectures are
widely adopted in real-world applications, where SR models require frequent
retraining to adapt to ever-changing user preferences. However, training
transformer-based SR models often encounters a high computational cost
associated with scoring extensive item catalogs, often exceeding thousands of
items. This occurs mainly due to the use of cross-entropy loss, where peak
memory scales proportionally to catalog size, batch size, and sequence length.
Recognizing this, practitioners in the field of recommendation systems
typically address memory consumption by integrating the cross-entropy (CE) loss
with negative sampling, thereby reducing the explicit memory demands of the
final layer. However, a small number of negative samples would degrade model
performance, and as we demonstrate in our work, increasing the number of
negative samples and the batch size further improves the model's performance,
but rapidly starts to exceed industrial GPUs' size (~40Gb).
  In this work, we introduce the CCE- method, which offers a GPU-efficient
implementation of the CE loss with negative sampling. Our method accelerates
training by up to two times while reducing memory consumption by more than 10
times. Leveraging the memory savings afforded by using CCE- for model training,
it becomes feasible to enhance its accuracy on datasets with a large item
catalog compared to those trained with original PyTorch-implemented loss
functions. Finally, we perform an analysis of key memory-related
hyperparameters and highlight the necessity of a delicate balance among these
factors. We demonstrate that scaling both the number of negative samples and
batch size leads to better results rather than maximizing only one of them. To
facilitate further adoption of CCE-, we release a Triton kernel that
efficiently implements the proposed method.

</details>


### [145] [Forecasting Clicks in Digital Advertising: Multimodal Inputs and Interpretable Outputs](https://arxiv.org/abs/2509.09683)
*Briti Gangopadhyay,Zhao Wang,Shingo Takamatsu*

Main category: cs.IR

TL;DR: 提出了一种结合点击数据和文本日志的多模态预测框架，通过强化学习提升文本理解能力，在预测准确性和可解释性方面优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统时间序列模型仅依赖数值数据，忽略了关键词更新等文本信息中的丰富上下文，需要开发能够融合多模态信息并生成可解释预测的方法

Method: 使用多模态预测框架结合点击数据和文本日志，采用强化学习来增强文本信息理解和模态融合，生成数值预测和人类可解释的解释

Result: 在大规模行业数据集上的实验表明，该方法在预测准确性和推理质量方面均优于基线模型

Conclusion: 该多模态框架成功整合了文本和数值信息，通过强化学习提升了预测性能，为数字广告点击量预测提供了更准确和可解释的解决方案

Abstract: Forecasting click volume is a key task in digital advertising, influencing
both revenue and campaign strategy. Traditional time series models rely solely
on numerical data, often overlooking rich contextual information embedded in
textual elements, such as keyword updates. We present a multimodal forecasting
framework that combines click data with textual logs from real-world ad
campaigns and generates human-interpretable explanations alongside numeric
predictions. Reinforcement learning is used to improve comprehension of textual
information and enhance fusion of modalities. Experiments on a large-scale
industry dataset show that our method outperforms baselines in both accuracy
and reasoning quality.

</details>


### [146] [Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for Query Translation](https://arxiv.org/abs/2509.09684)
*Bruno Yui Yamate,Thais Rodrigues Neubauer,Marcelo Fantinato,Sarajane Marques Peres*

Main category: cs.IR

TL;DR: 本文介绍了text-2-SQL-4-PM，一个为流程挖掘领域文本到SQL任务设计的双语（葡萄牙语-英语）基准数据集，包含1,655个自然语言语句和205个SQL语句，并通过GPT-3.5 Turbo验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 促进自然语言查询数据库，提高非SQL专家用户的可访问性和专家用户的生产力，特别是在流程挖掘领域解决专业词汇和单表关系结构的独特挑战。

Method: 通过专家手动整理、专业翻译和详细标注过程创建数据集，包括人类生成的释义和限定词，并使用GPT-3.5 Turbo进行基线研究。

Result: 数据集支持文本到SQL实现的评估，展示了在流程挖掘领域的可行性和实用性，并为语义解析和其他自然语言处理任务提供更广泛的适用性。

Conclusion: text-2-SQL-4-PM是一个专门针对流程挖掘领域的高质量双语基准数据集，有效支持文本到SQL转换任务的研究和应用。

Abstract: This paper introduces text-2-SQL-4-PM, a bilingual (Portuguese-English)
benchmark dataset designed for the text-to-SQL task in the process mining
domain. Text-to-SQL conversion facilitates natural language querying of
databases, increasing accessibility for users without SQL expertise and
productivity for those that are experts. The text-2-SQL-4-PM dataset is
customized to address the unique challenges of process mining, including
specialized vocabularies and single-table relational structures derived from
event logs. The dataset comprises 1,655 natural language utterances, including
human-generated paraphrases, 205 SQL statements, and ten qualifiers. Methods
include manual curation by experts, professional translations, and a detailed
annotation process to enable nuanced analyses of task complexity. Additionally,
a baseline study using GPT-3.5 Turbo demonstrates the feasibility and utility
of the dataset for text-to-SQL applications. The results show that
text-2-SQL-4-PM supports evaluation of text-to-SQL implementations, offering
broader applicability for semantic parsing and other natural language
processing tasks.

</details>


### [147] [TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal Conversational Music Recommendation](https://arxiv.org/abs/2509.09685)
*Keunwoo Choi,Seungheon Doh,Juhan Nam*

Main category: cs.IR

TL;DR: TalkPlayData 2是一个通过多智能体LLM管道生成的合成多模态对话音乐推荐数据集，包含音频和图像信息，用于训练生成式音乐推荐模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态对话音乐推荐数据稀缺的问题，通过智能体数据管道生成高质量的合成数据集来支持生成式推荐模型的训练。

Method: 创建多个具有不同角色和专业提示的LLM智能体，让Listener LLM和Recsys LLM进行对话并记录聊天数据，每个对话都基于微调的对话目标，所有LLM都支持音频和图像的多模态处理。

Result: 在LLM-as-a-judge和主观评估实验中，TalkPlayData 2在训练生成式音乐推荐模型的各个方面都达到了预期目标。

Conclusion: TalkPlayData 2成功构建了一个高质量的多模态对话音乐推荐合成数据集，并通过开源方式提供数据集和生成代码，为相关研究提供了重要资源。

Abstract: We present TalkPlayData 2, a synthetic dataset for multimodal conversational
music recommendation generated by an agentic data pipeline. In TalkPlayData 2
pipeline, multiple large language model (LLM) agents are created under various
roles with specialized prompts and access to different parts of information,
and the chat data is acquired by logging the conversation between the Listener
LLM and the Recsys LLM. To cover various conversation scenarios, for each
conversation, the Listener LLM is conditioned on a finetuned conversation goal.
Finally, all the LLMs are multimodal with audio and images, allowing a
simulation of multimodal recommendation and conversation. In the LLM-as-a-judge
and subjective evaluation experiments, TalkPlayData 2 achieved the proposed
goal in various aspects related to training a generative recommendation model
for music. TalkPlayData 2 and its generation code are open-sourced at
https://talkpl.ai/talkplaydata2.html.

</details>


### [148] [GeoGPT.RAG Technical Report](https://arxiv.org/abs/2509.09686)
*Fei Huang,Fan Wu,Zeqing Zhang,Qihao Wang,Long Zhang,Grant Michael Boquet,Hongyang Chen*

Main category: cs.IR

TL;DR: GeoGPT是一个开源的地球科学大语言模型系统，通过检索增强生成(RAG)技术整合专业地学知识库，提供准确的地学领域回答，并支持用户上传个性化知识库。


<details>
  <summary>Details</summary>
Motivation: 为了提升大语言模型在地球科学领域的专业能力，解决通用模型在地学专业知识上的不足，需要开发专门针对地学领域的AI工具。

Method: 采用检索增强生成(RAG)技术，整合专门策划的地学知识库GeoGPT Library；对嵌入模型和排序模型进行微调以优化检索质量；支持用户上传个性化出版物列表创建专属知识库。

Result: 开发了GeoGPT系统，显著提高了在地学领域的输出准确性和可信度；开源了GeoEmbedding和GeoReranker两个核心RAG组件。

Conclusion: GeoGPT通过RAG技术和领域专用优化，为地学研究和专业人员提供了强大且易用的AI工具，体现了对开放科学和社区驱动发展的承诺。

Abstract: GeoGPT is an open large language model system built to advance research in
the geosciences. To enhance its domain-specific capabilities, we integrated
Retrieval Augmented Generation(RAG), which augments model outputs with relevant
information retrieved from an external knowledge source. GeoGPT uses RAG to
draw from the GeoGPT Library, a specialized corpus curated for geoscientific
content, enabling it to generate accurate, context-specific answers. Users can
also create personalized knowledge bases by uploading their own publication
lists, allowing GeoGPT to retrieve and respond using user-provided materials.
To further improve retrieval quality and domain alignment, we fine-tuned both
the embedding model and a ranking model that scores retrieved passages by
relevance to the query. These enhancements optimize RAG for geoscience
applications and significantly improve the system's ability to deliver precise
and trustworthy outputs. GeoGPT reflects a strong commitment to open science
through its emphasis on collaboration, transparency, and community driven
development. As part of this commitment, we have open-sourced two core RAG
components-GeoEmbedding and GeoReranker-to support geoscientists, researchers,
and professionals worldwide with powerful, accessible AI tools.

</details>


### [149] [Demonstrating Narrative Pattern Discovery from Biomedical Literature](https://arxiv.org/abs/2509.09687)
*Hermann Kroll,Pascal Sackhoff,Bill Matthias Thang,Christin Katharina Kreutz,Wolf-Tilo Balke*

Main category: cs.IR

TL;DR: 本文介绍了一种名为叙事模式挖掘的新搜索功能，用于探索上下文相关的实体和实体交互，并通过领域专家访谈验证了原型的有用性。


<details>
  <summary>Details</summary>
Motivation: 数字图书馆需要为用户提供有效的访问路径，特别是针对药学领域的专业信息服务需要开发新的探索方式来访问生物医学文档集合。

Method: 开发了叙事模式挖掘搜索功能，允许用户探索上下文相关的实体和实体交互，并通过与五位领域专家的访谈来验证原型的有用性。

Result: 研究开发了新的搜索功能，能够有效支持用户探索药学文档集合中的实体关系和交互模式。

Conclusion: 叙事模式挖掘是一种有前景的搜索方法，能够增强数字图书馆对专业文档集合的访问和探索能力，得到了领域专家的认可。

Abstract: Digital libraries maintain extensive collections of knowledge and need to
provide effective access paths for their users. For instance, PubPharm, the
specialized information service for Pharmacy in Germany, provides and develops
access paths to their underlying biomedical document collection. In brief,
PubPharm supports traditional keyword-based search, search for chemical
structures, as well as novel graph-based discovery workflows, e.g., listing or
searching for interactions between different pharmaceutical entities. This
paper introduces a new search functionality, called narrative pattern mining,
allowing users to explore context-relevant entities and entity interactions. We
performed interviews with five domain experts to verify the usefulness of our
prototype.

</details>


### [150] [AI-Powered Assistant for Long-Term Access to RHIC Knowledge](https://arxiv.org/abs/2509.09688)
*Mohammad Atif,Vincent Garonne,Eric Lancon,Jerome Lauret,Alexandr Prozorov,Michal Vranovsky*

Main category: cs.IR

TL;DR: RHIC数据与分析保存计划开发了一个基于大语言模型的AI助手系统，通过自然语言访问文档、工作流和软件，旨在支持重离子碰撞实验数据的可重复性、教育和未来发现。


<details>
  <summary>Details</summary>
Motivation: 随着RHIC运行25年结束，保存其海量数据（约1EB）和嵌入的科学知识成为关键优先事项，需要确保科学遗产的长期可访问性和可用性。

Method: 基于检索增强生成和模型上下文协议的大语言模型，索引RHIC实验的结构化和非结构化内容，实现领域适应的交互。

Result: 系统已部署并报告了计算性能、多实验集成进展，以及为可持续和可解释的长期AI访问设计的架构特性。

Conclusion: 现代AI/ML工具可以显著改变科学遗产数据的可用性和可发现性，为大型科学设施的数据保存提供有效解决方案。

Abstract: As the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National
Laboratory concludes 25 years of operation, preserving not only its vast data
holdings ($\sim$1 ExaByte) but also the embedded scientific knowledge becomes a
critical priority. The RHIC Data and Analysis Preservation Plan (DAPP)
introduces an AI-powered assistant system that provides natural language access
to documentation, workflows, and software, with the aim of supporting
reproducibility, education, and future discovery. Built upon Large Language
Models using Retrieval-Augmented Generation and the Model Context Protocol,
this assistant indexes structured and unstructured content from RHIC
experiments and enables domain-adapted interaction. We report on the
deployment, computational performance, ongoing multi-experiment integration,
and architectural features designed for a sustainable and explainable long-term
AI access. Our experience illustrates how modern AI/ML tools can transform the
usability and discoverability of scientific legacy data.

</details>


### [151] [Personas within Parameters: Fine-Tuning Small Language Models with Low-Rank Adapters to Mimic User Behaviors](https://arxiv.org/abs/2509.09689)
*Himanshu Thakur,Eshani Agrawal,Smruthi Mukund*

Main category: cs.IR

TL;DR: 使用冻结的大语言模型提取文本用户表示，通过微调小语言模型构建高效的用户行为代理，在推荐系统中平衡可扩展性和性能


<details>
  <summary>Details</summary>
Motivation: 解决传统推荐模型模拟用户行为的挑战，包括处理大规模表格交互数据、克服预训练模型的归纳偏差，以及为百万级用户实现高效模拟

Method: 使用冻结的LLM提取鲁棒的文本用户表示，通过微调SLMs构建经济高效的用户代理，并为用户群体训练多个低秩适配器

Result: 实验证明该方法能有效弥合推荐系统离线指标与实际性能之间的差距

Conclusion: 该方法在可扩展性和性能之间取得了最佳平衡，为推荐系统的用户行为模拟提供了有效的解决方案

Abstract: A long-standing challenge in developing accurate recommendation models is
simulating user behavior, mainly due to the complex and stochastic nature of
user interactions. Towards this, one promising line of work has been the use of
Large Language Models (LLMs) for simulating user behavior. However, aligning
these general-purpose large pre-trained models with user preferences
necessitates: (i) effectively and continously parsing large-scale tabular
user-item interaction data, (ii) overcoming pre-training-induced inductive
biases to accurately learn user specific knowledge, and (iii) achieving the
former two at scale for millions of users. While most previous works have
focused on complex methods to prompt an LLM or fine-tune it on tabular
interaction datasets, our approach shifts the focus to extracting robust
textual user representations using a frozen LLM and simulating cost-effective,
resource-efficient user agents powered by fine-tuned Small Language Models
(SLMs). Further, we showcase a method for training multiple low-rank adapters
for groups of users or \textit{persona}, striking an optimal balance between
scalability and performance of user behavior agents. Our experiments provide
compelling empirical evidence of the efficacy of our methods, demonstrating
that user agents developed using our approach have the potential to bridge the
gap between offline metrics and real-world performance of recommender systems.

</details>


### [152] [Powering Job Search at Scale: LLM-Enhanced Query Understanding in Job Matching Systems](https://arxiv.org/abs/2509.09690)
*Ping Liu,Jianqiang Shen,Qianqi Shen,Chunnan Yao,Kevin Kao,Dan Xu,Rajat Arora,Baofen Zheng,Caleb Johnson,Liangjie Hong,Jingwei Wu,Wenjing Zhang*

Main category: cs.IR

TL;DR: 提出基于大语言模型的统一查询理解框架，替代传统多NER模型方法，通过联合建模查询和上下文信号来生成结构化解释，提升推荐准确性和个性化程度。


<details>
  <summary>Details</summary>
Motivation: 传统查询理解方法依赖多个任务特定的命名实体识别模型，这种碎片化架构脆弱、维护成本高，且难以适应快速变化的分类体系和语言模式。

Method: 使用大语言模型构建统一查询理解框架，联合建模用户查询和上下文信号（如个人资料属性），生成结构化解释来驱动更准确和个性化的推荐。

Result: 在线A/B测试中提升了相关性质量，同时显著降低了系统复杂度和运维开销。

Conclusion: 该解决方案为动态网络应用中的查询理解提供了可扩展和适应性强的技术基础。

Abstract: Query understanding is essential in modern relevance systems, where user
queries are often short, ambiguous, and highly context-dependent. Traditional
approaches often rely on multiple task-specific Named Entity Recognition models
to extract structured facets as seen in job search applications. However, this
fragmented architecture is brittle, expensive to maintain, and slow to adapt to
evolving taxonomies and language patterns. In this paper, we introduce a
unified query understanding framework powered by a Large Language Model (LLM),
designed to address these limitations. Our approach jointly models the user
query and contextual signals such as profile attributes to generate structured
interpretations that drive more accurate and personalized recommendations. The
framework improves relevance quality in online A/B testing while significantly
reducing system complexity and operational overhead. The results demonstrate
that our solution provides a scalable and adaptable foundation for query
understanding in dynamic web applications.

</details>


### [153] [Wave-Based Semantic Memory with Resonance-Based Retrieval: A Phase-Aware Alternative to Vector Embedding Stores](https://arxiv.org/abs/2509.09691)
*Aleksandr Listopad*

Main category: cs.IR

TL;DR: 提出基于波的语义记忆框架，通过共振干涉进行知识检索，相比传统向量方法能更好地保留振幅和相位信息，实现更强大的语义相似性计算


<details>
  <summary>Details</summary>
Motivation: 传统基于向量的记忆系统依赖于余弦或内积相似度，虽然计算高效但本质上是相位不敏感的，无法捕捉对意义表示至关重要的共振现象

Method: 将知识建模为波模式ψ(x)=A(x)e^{iφ(x)}，通过基于共振的干涉进行检索，同时保留振幅和相位信息

Result: 共振检索在向量方法失败的场景（如相位偏移、否定和组合查询）中展现出更高的判别能力，ResonanceDB实现百万级模式的可扩展性和毫秒级延迟

Conclusion: 基于波的记忆系统是向量存储的可行替代方案，适用于AGI导向的推理和知识表示

Abstract: Conventional vector-based memory systems rely on cosine or inner product
similarity within real-valued embedding spaces. While computationally
efficient, such approaches are inherently phase-insensitive and limited in
their ability to capture resonance phenomena crucial for meaning
representation. We propose Wave-Based Semantic Memory, a novel framework that
models knowledge as wave patterns $\psi(x) = A(x) e^{i\phi(x)}$ and retrieves
it through resonance-based interference. This approach preserves both amplitude
and phase information, enabling more expressive and robust semantic similarity.
We demonstrate that resonance-based retrieval achieves higher discriminative
power in cases where vector methods fail, including phase shifts, negations,
and compositional queries. Our implementation, ResonanceDB, shows scalability
to millions of patterns with millisecond latency, positioning wave-based memory
as a viable alternative to vector stores for AGI-oriented reasoning and
knowledge representation.

</details>


### [154] [A Research Vision for Web Search on Emerging Topics](https://arxiv.org/abs/2509.10212)
*Alisa Rieger,Stefan Dietze,Ran Yu*

Main category: cs.IR

TL;DR: 本文提出了一个研究愿景，旨在开发支持用户有效获取新兴话题知识、了解话题动态特性并促进负责任意见形成的搜索引擎系统和界面。


<details>
  <summary>Details</summary>
Motivation: 新兴话题的信息通常稀疏且动态演变，质量参差不齐，容易受到操纵、错误信息和偏见的影响，现有搜索引擎难以有效支持用户对这些话题的知识获取和意见形成。

Method: 提出了三个总体研究问题：理解现状、确定符合愿景的系统需求、以及构建这些系统。通过相关文献分析，为每个问题提供了解决思路和方法指引。

Result: 提出了一个完整的研究框架和路线图，包括现状分析、需求确定和系统构建三个关键阶段，为未来搜索引擎在支持新兴话题信息获取方面的发展指明了方向。

Conclusion: 开发能够有效支持新兴话题知识获取的搜索引擎系统具有重要意义，但面临诸多挑战，需要跨学科合作来解决信息质量、动态性和用户认知等方面的复杂问题。

Abstract: We regularly encounter information on novel, emerging topics for which the
body of knowledge is still evolving, which can be linked, for instance, to
current events. A primary way to learn more about such topics is through web
search. However, information on emerging topics is sparse and evolves
dynamically as knowledge grows, making it uncertain and variable in quality and
trustworthiness and prone to deliberate or accidental manipulation,
misinformation, and bias. In this paper, we outline a research vision towards
search systems and interfaces that support effective knowledge acquisition,
awareness of the dynamic nature of topics, and responsible opinion formation
among people searching the web for information on emerging topics. To realize
this vision, we propose three overarching research questions, aimed at
understanding the status quo, determining requirements of systems aligned with
our vision, and building these systems. For each of the three questions, we
highlight relevant literature, including pointers on how they could be
addressed. Lastly, we discuss the challenges that will potentially arise in
pursuing the proposed vision.

</details>


### [155] [Model-agnostic post-hoc explainability for recommender systems](https://arxiv.org/abs/2509.10245)
*Irina Arévalo,Jose L Salmeron*

Main category: cs.IR

TL;DR: 该研究提出了一种基于删除诊断的推荐系统可解释性方法，通过比较完整模型与移除特定用户/物品后模型的性能差异，量化观察值对推荐系统的影响。


<details>
  <summary>Details</summary>
Motivation: 深度学习推荐系统虽然性能优越但缺乏可解释性，需要开发模型无关的方法来提高推荐系统的透明度和可解释性。

Method: 采用删除诊断方法，训练完整模型和移除特定用户/物品的对比模型，通过性能差异量化每个观察值对推荐系统的影响。在NCF和SVD两种不同推荐模型上进行验证。

Result: 在MovieLens和Amazon Reviews数据集上的实验表明，该方法能够有效揭示模型行为，并证明其在不同推荐范式中的通用性。

Conclusion: 删除诊断是一种有效的模型无关可解释性方法，能够提高推荐系统的透明度和可解释性，适用于深度学习和传统推荐模型。

Abstract: Recommender systems often benefit from complex feature embeddings and deep
learning algorithms, which deliver sophisticated recommendations that enhance
user experience, engagement, and revenue. However, these methods frequently
reduce the interpretability and transparency of the system. In this research,
we develop a systematic application, adaptation, and evaluation of deletion
diagnostics in the recommender setting. The method compares the performance of
a model to that of a similar model trained without a specific user or item,
allowing us to quantify how that observation influences the recommender, either
positively or negatively. To demonstrate its model-agnostic nature, the
proposal is applied to both Neural Collaborative Filtering (NCF), a widely used
deep learning-based recommender, and Singular Value Decomposition (SVD), a
classical collaborative filtering technique. Experiments on the MovieLens and
Amazon Reviews datasets provide insights into model behavior and highlight the
generality of the approach across different recommendation paradigms.

</details>


### [156] [Diversified recommendations of cultural activities with personalized determinantal point processes](https://arxiv.org/abs/2509.10392)
*Carole Ibrahim,Hiba Bederina,Daniel Cuesta,Laurent Montier,Cyrille Delabre,Jill-Jênn Vie*

Main category: cs.IR

TL;DR: 使用个性化行列式点过程(DPP)在推荐系统中平衡相关性和多样性，通过质量-多样性分解核函数来优先考虑用户偏好，并在生产环境中评估效果


<details>
  <summary>Details</summary>
Motivation: 在优化用户参与度的同时，有效多样化推荐内容而不影响核心业务指标是行业重要挑战，旨在扩大受众的文化实践

Method: 采用个性化DPP采样方法，基于质量-多样性分解的相似性核函数，给予用户偏好更多权重

Result: 通过离线和在线指标评估了相关性与多样性之间的权衡，为生产环境使用提供了实践洞察

Conclusion: 个性化DPP是平衡推荐系统相关性和多样性的有效方法，研究提供了可复现的完整代码实现

Abstract: While optimizing recommendation systems for user engagement is a
well-established practice, effectively diversifying recommendations without
negatively impacting core business metrics remains a significant industry
challenge. In line with our initiative to broaden our audience's cultural
practices, this study investigates using personalized Determinantal Point
Processes (DPPs) to sample diverse and relevant recommendations. We rely on a
well-known quality-diversity decomposition of the similarity kernel to give
more weight to user preferences. In this paper, we present our implementations
of the personalized DPP sampling, evaluate the trade-offs between relevance and
diversity through both offline and online metrics, and give insights for
practitioners on their use in a production environment. For the sake of
reproducibility, we release the full code for our platform and experiments on
GitHub.

</details>


### [157] [RecoWorld: Building Simulated Environments for Agentic Recommender Systems](https://arxiv.org/abs/2509.10397)
*Fei Liu,Xinyu Lin,Hanchao Yu,Mingyuan Wu,Jianyu Wang,Qiang Zhang,Zhuokai Zhao,Yinglong Xia,Yao Zhang,Weiwei Li,Mingze Gao,Qifan Wang,Lizhu Zhang,Benyu Zhang,Xiangjun Fan*

Main category: cs.IR

TL;DR: RecoWorld是一个为智能推荐系统设计的模拟环境框架，采用双视图架构让模拟用户和推荐代理进行多轮交互，通过用户反馈和推理追踪来优化推荐策略，提高用户留存率。


<details>
  <summary>Details</summary>
Motivation: 为了解决智能推荐系统在真实环境中训练时可能对真实用户造成负面影响的问题，需要创建一个安全的模拟训练环境，让推荐代理能够从错误中学习而不影响真实用户体验。

Method: 采用双视图架构：模拟用户端审查推荐项目并更新心态，当检测到用户可能流失时生成反思指令；推荐代理端整合用户指令和推理追踪来调整推荐策略，形成动态反馈循环。支持多种内容表示形式（文本、多模态、语义ID）和多轮强化学习。

Result: RecoWorld提供了一个完整的模拟环境框架，支持多代理模拟和针对特定用户群体的响应模拟，为推荐系统的发展奠定了重要基础。

Conclusion: 该框架标志着向用户与代理共同塑造个性化信息流的推荐系统迈出了重要一步，开创了"用户指导、推荐响应"的新交互范式，共同优化用户留存和参与度。

Abstract: We present RecoWorld, a blueprint for building simulated environments
tailored to agentic recommender systems. Such environments give agents a proper
training space where they can learn from errors without impacting real users.
RecoWorld distinguishes itself with a dual-view architecture: a simulated user
and an agentic recommender engage in multi-turn interactions aimed at
maximizing user retention. The user simulator reviews recommended items,
updates its mindset, and when sensing potential user disengagement, generates
reflective instructions. The agentic recommender adapts its recommendations by
incorporating these user instructions and reasoning traces, creating a dynamic
feedback loop that actively engages users. This process leverages the
exceptional reasoning capabilities of modern LLMs. We explore diverse content
representations within the simulator, including text-based, multimodal, and
semantic ID modeling, and discuss how multi-turn RL enables the recommender to
refine its strategies through iterative interactions. RecoWorld also supports
multi-agent simulations, allowing creators to simulate the responses of
targeted user populations. It marks an important first step toward recommender
systems where users and agents collaboratively shape personalized information
streams. We envision new interaction paradigms where "user instructs,
recommender responds," jointly optimizing user retention and engagement.

</details>


### [158] [MatSKRAFT: A framework for large-scale materials knowledge extraction from scientific tables](https://arxiv.org/abs/2509.10448)
*Kausik Hira,Mohd Zaki,Mausam,N. M. Anoop Krishnan*

Main category: cs.IR

TL;DR: MatSKRAFT是一个计算框架，能够自动从表格数据中提取和整合材料科学知识，性能优于大型语言模型，处理速度更快，构建了包含超过53.5万条记录的数据库。


<details>
  <summary>Details</summary>
Motivation: 科学进步越来越依赖于综合大量文献知识，但大多数实验数据仍被困在半结构化格式中，难以进行系统提取和分析。

Method: 将表格转换为基于图的表示，通过约束驱动的图神经网络处理，将科学原理直接编码到模型架构中。

Result: 在属性提取和成分提取方面分别达到88.68和71.35的F1分数，处理速度比现有模型快19-496倍，构建了包含535,000+条记录的数据库。

Conclusion: 该方法能够发现先前被忽视的材料及其独特属性组合，为材料科学发现提供了数据驱动的方法。

Abstract: Scientific progress increasingly depends on synthesizing knowledge across
vast literature, yet most experimental data remains trapped in semi-structured
formats that resist systematic extraction and analysis. Here, we present
MatSKRAFT, a computational framework that automatically extracts and integrates
materials science knowledge from tabular data at unprecedented scale. Our
approach transforms tables into graph-based representations processed by
constraint-driven GNNs that encode scientific principles directly into model
architecture. MatSKRAFT significantly outperforms state-of-the-art large
language models, achieving F1 scores of 88.68 for property extraction and 71.35
for composition extraction, while processing data $19$-$496\times$ faster than
them (compared to the slowest and the fastest models, respectively) with modest
hardware requirements. Applied to nearly 69,000 tables from more than 47,000
research publications, we construct a comprehensive database containing over
535,000 entries, including 104,000 compositions that expand coverage beyond
major existing databases, pending manual validation. This systematic approach
reveals previously overlooked materials with distinct property combinations and
enables data-driven discovery of composition-property relationships forming the
cornerstone of materials and scientific discovery.

</details>
